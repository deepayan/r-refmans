<!DOCTYPE html><html><head><title>Help for package BGGM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BGGM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BGGM-package'><p>BGGM:  Bayesian Gaussian Graphical Models</p></a></li>
<li><a href='#asd_ocd'><p>Data: Autism and Obssesive Compulsive Disorder</p></a></li>
<li><a href='#bfi'><p>Data: 25 Personality items representing 5 factors</p></a></li>
<li><a href='#bggm_missing'><p>GGM: Missing Data</p></a></li>
<li><a href='#coef.estimate'><p>Compute Regression Parameters for <code>estimate</code> Objects</p></a></li>
<li><a href='#coef.explore'><p>Compute Regression Parameters for <code>explore</code> Objects</p></a></li>
<li><a href='#confirm'><p>GGM: Confirmatory Hypothesis Testing</p></a></li>
<li><a href='#constrained_posterior'><p>Constrained Posterior Distribution</p></a></li>
<li><a href='#convergence'><p>MCMC Convergence</p></a></li>
<li><a href='#csws'><p>Data: Contingencies of Self-Worth Scale (CSWS)</p></a></li>
<li><a href='#depression_anxiety_t1'><p>Data: Depression and Anxiety (Time 1)</p></a></li>
<li><a href='#depression_anxiety_t2'><p>Data: Depression and Anxiety (Time 2)</p></a></li>
<li><a href='#estimate'><p>GGM: Estimation</p></a></li>
<li><a href='#explore'><p>GGM: Exploratory Hypothesis Testing</p></a></li>
<li><a href='#fisher_r_to_z'><p>Fisher Z Transformation</p></a></li>
<li><a href='#fisher_z_to_r'><p>Fisher Z Back Transformation</p></a></li>
<li><a href='#gen_net'><p>Simulate a Partial Correlation Matrix</p></a></li>
<li><a href='#gen_ordinal'><p>Generate Ordinal and Binary data</p></a></li>
<li><a href='#ggm_compare_confirm'><p>GGM Compare: Confirmatory Hypothesis Testing</p></a></li>
<li><a href='#ggm_compare_estimate'><p>GGM Compare: Estimate</p></a></li>
<li><a href='#ggm_compare_explore'><p>GGM Compare: Exploratory Hypothesis Testing</p></a></li>
<li><a href='#ggm_compare_ppc'><p>GGM Compare: Posterior Predictive Check</p></a></li>
<li><a href='#gss'><p>Data: 1994 General Social Survey</p></a></li>
<li><a href='#ifit'><p>Data: ifit Intensive Longitudinal Data</p></a></li>
<li><a href='#impute_data'><p>Obtain Imputed Datasets</p></a></li>
<li><a href='#iri'><p>Data: Interpersonal Reactivity Index (IRI)</p></a></li>
<li><a href='#map'><p>Maximum A Posteriori Precision Matrix</p></a></li>
<li><a href='#pcor_mat'><p>Extract the Partial Correlation Matrix</p></a></li>
<li><a href='#pcor_sum'><p>Partial Correlation Sum</p></a></li>
<li><a href='#pcor_to_cor'><p>Compute Correlations from the Partial Correlations</p></a></li>
<li><a href='#plot_prior'><p>Plot: Prior Distribution</p></a></li>
<li><a href='#plot.confirm'><p>Plot <code>confirm</code> objects</p></a></li>
<li><a href='#plot.ggm_compare_ppc'><p>Plot <code>ggm_compare_ppc</code> Objects</p></a></li>
<li><a href='#plot.pcor_sum'><p>Plot <code>pcor_sum</code> Object</p></a></li>
<li><a href='#plot.predictability'><p>Plot <code>predictability</code> Objects</p></a></li>
<li><a href='#plot.roll_your_own'><p>Plot <code>roll_your_own</code> Objects</p></a></li>
<li><a href='#plot.select'><p>Network Plot for <code>select</code> Objects</p></a></li>
<li><a href='#plot.summary.estimate'><p>Plot <code>summary.estimate</code> Objects</p></a></li>
<li><a href='#plot.summary.explore'><p>Plot <code>summary.explore</code> Objects</p></a></li>
<li><a href='#plot.summary.ggm_compare_estimate'><p>Plot <code>summary.ggm_compare_estimate</code> Objects</p></a></li>
<li><a href='#plot.summary.ggm_compare_explore'><p>Plot <code>summary.ggm_compare_explore</code> Objects</p></a></li>
<li><a href='#plot.summary.select.explore'><p>Plot <code>summary.select.explore</code> Objects</p></a></li>
<li><a href='#plot.summary.var_estimate'><p>Plot <code>summary.var_estimate</code> Objects</p></a></li>
<li><a href='#posterior_predict'><p>Posterior Predictive Distribution</p></a></li>
<li><a href='#posterior_samples'><p>Extract Posterior Samples</p></a></li>
<li><a href='#precision'><p>Precision Matrix Posterior Distribution</p></a></li>
<li><a href='#predict.estimate'><p>Model Predictions for <code>estimate</code> Objects</p></a></li>
<li><a href='#predict.explore'><p>Model Predictions for <code>explore</code> Objects</p></a></li>
<li><a href='#predict.var_estimate'><p>Model Predictions for <code>var_estimate</code> Objects</p></a></li>
<li><a href='#predictability'><p>Predictability: Bayesian Variance Explained (R2)</p></a></li>
<li><a href='#predicted_probability'><p>Predicted Probabilities</p></a></li>
<li><a href='#print.BGGM'><p>Print method for <code>BGGM</code> objects</p></a></li>
<li><a href='#prior_belief_ggm'><p>Prior Belief Gaussian Graphical Model</p></a></li>
<li><a href='#prior_belief_var'><p>Prior Belief Graphical VAR</p></a></li>
<li><a href='#ptsd'><p>Data: Post-Traumatic Stress Disorder</p></a></li>
<li><a href='#ptsd_cor1'><p>Data: Post-Traumatic Stress Disorder (Sample # 1)</p></a></li>
<li><a href='#ptsd_cor2'><p>Data: Post-Traumatic Stress Disorder (Sample # 2)</p></a></li>
<li><a href='#ptsd_cor3'><p>Data: Post-Traumatic Stress Disorder  (Sample # 3)</p></a></li>
<li><a href='#ptsd_cor4'><p>Data: Post-Traumatic Stress Disorder  (Sample # 4)</p></a></li>
<li><a href='#regression_summary'><p>Summarary Method for Multivariate or Univarate Regression</p></a></li>
<li><a href='#roll_your_own'><p>Compute Custom Network Statistics</p></a></li>
<li><a href='#rsa'><p>Data: Resilience Scale of Adults (RSA)</p></a></li>
<li><a href='#Sachs'><p>Data: Sachs Network</p></a></li>
<li><a href='#select'><p>S3 <code>select</code> method</p></a></li>
<li><a href='#select.estimate'><p>Graph Selection for <code>estimate</code> Objects</p></a></li>
<li><a href='#select.explore'><p>Graph selection for <code>explore</code> Objects</p></a></li>
<li><a href='#select.ggm_compare_estimate'><p>Graph Selection for <code>ggm_compare_estimate</code> Objects</p></a></li>
<li><a href='#select.ggm_compare_explore'><p>Graph selection for <code>ggm_compare_explore</code> Objects</p></a></li>
<li><a href='#select.var_estimate'><p>Graph Selection for <code>var.estimate</code> Object</p></a></li>
<li><a href='#summary.coef'><p>Summarize <code>coef</code> Objects</p></a></li>
<li><a href='#summary.estimate'><p>Summary method for <code>estimate.default</code> objects</p></a></li>
<li><a href='#summary.explore'><p>Summary Method for <code>explore.default</code> Objects</p></a></li>
<li><a href='#summary.ggm_compare_estimate'><p>Summary method for <code>ggm_compare_estimate</code> objects</p></a></li>
<li><a href='#summary.ggm_compare_explore'><p>Summary Method for <code>ggm_compare_explore</code> Objects</p></a></li>
<li><a href='#summary.predictability'><p>Summary Method for <code>predictability</code> Objects</p></a></li>
<li><a href='#summary.select.explore'><p>Summary Method for <code>select.explore</code> Objects</p></a></li>
<li><a href='#summary.var_estimate'><p>Summary Method for <code>var_estimate</code> Objects</p></a></li>
<li><a href='#tas'><p>Data: Toronto Alexithymia Scale (TAS)</p></a></li>
<li><a href='#var_estimate'><p>VAR: Estimation</p></a></li>
<li><a href='#weighted_adj_mat'><p>Extract the Weighted Adjacency Matrix</p></a></li>
<li><a href='#women_math'><p>Data: Women and Mathematics</p></a></li>
<li><a href='#zero_order_cors'><p>Zero-Order Correlations</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Gaussian Graphical Models</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-06-21</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit Bayesian Gaussian graphical models. The methods are separated into 
    two Bayesian approaches for inference: hypothesis testing and estimation. There are 
    extensions for confirmatory hypothesis testing, comparing Gaussian graphical models, 
    and node wise predictability. These methods were recently introduced in the Gaussian 
    graphical model literature, including 
    Williams (2019) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fx8dpr">doi:10.31234/osf.io/x8dpr</a>&gt;, 
    Williams and Mulder (2019) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fypxd8">doi:10.31234/osf.io/ypxd8</a>&gt;,
    Williams, Rast, Pericchi, and Mulder (2019) &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fyt386">doi:10.31234/osf.io/yt386</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>BFpack (&ge; 1.2.3), GGally (&ge; 1.4.0), ggplot2 (&ge; 3.2.1),
ggridges (&ge; 0.5.1), grDevices, MASS (&ge; 7.3-51.5), methods,
mvnfast (&ge; 0.2.5), network (&ge; 1.15), reshape (&ge; 0.8.8), Rcpp
(&ge; 1.0.4.6), Rdpack (&ge; 0.11-1), sna (&ge; 2.5), stats, utils,</td>
</tr>
<tr>
<td>Suggests:</td>
<td>abind (&ge; 1.4-5), assortnet (&ge; 0.12), networktools (&ge;
1.3.0), mice (&ge; 3.8.0), psych, knitr, rmarkdown, testthat (&ge;
3.0.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppDist, RcppProgress</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/donaldRwilliams/BGGM/issues">https://github.com/donaldRwilliams/BGGM/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-05 15:38:17 UTC; philippe</td>
</tr>
<tr>
<td>Author:</td>
<td>Donald Williams [aut],
  Joris Mulder [aut],
  Philippe Rast [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Philippe Rast &lt;rast.ph@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-05 20:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BGGM-package'>BGGM:  Bayesian Gaussian Graphical Models</h2><span id='topic+BGGM-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>The <code>R</code> package <strong>BGGM</strong> provides tools for making Bayesian inference in
Gaussian graphical models (GGM). The methods are organized around two general approaches for
Bayesian inference: (1) estimation (Williams 2018) and (2) hypothesis testing
(Williams and Mulder 2019). The key distinction is that the former focuses on either the
posterior or posterior predictive distribution, whereas the latter focuses on model comparison
with the Bayes factor.
</p>
<p>The methods in <strong>BGGM</strong> build upon existing algorithms that are well-known in the literature.
The central contribution of <strong>BGGM</strong> is to extend those approaches:
</p>

<ol>
<li><p> Bayesian estimation with the novel matrix-F prior distribution (Mulder and Pericchi 2018).
</p>

<ul>
<li><p> Estimation <code><a href="#topic+estimate">estimate</a></code>.
</p>
</li></ul>

</li>
<li><p> Bayesian hypothesis testing with the novel matrix-F prior distribution (Mulder and Pericchi 2018).
</p>

<ul>
<li><p> Exploratory hypothesis testing <code><a href="#topic+explore">explore</a></code>.
</p>
</li>
<li><p> Confirmatory hypothesis  testing <code><a href="#topic+confirm">confirm</a></code>.
</p>
</li></ul>

</li>
<li><p> Comparing GGMs (Williams et al. 2020)
</p>

<ul>
<li><p> Partial correlation differences <code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code>.
</p>
</li>
<li><p> Posterior predictive check <code><a href="#topic+ggm_compare_ppc">ggm_compare_ppc</a></code>.
</p>
</li>
<li><p> Exploratory hypothesis testing <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code>.
</p>
</li>
<li><p> Confirmatory hypothesis testing <code><a href="#topic+ggm_compare_confirm">ggm_compare_confirm</a></code>.
</p>
</li></ul>

</li>
<li><p> Extending inference beyond the conditional (in)dependence structure
</p>

<ul>
<li><p> Predictability with Bayesian variance explained (Gelman et al. 2019)
<code><a href="#topic+predictability">predictability</a></code>.
</p>
</li>
<li><p> Posterior uncertainty in the partial correlations <code><a href="#topic+estimate">estimate</a></code>.
</p>
</li>
<li><p> Custom Network Statistics <code><a href="#topic+roll_your_own">roll_your_own</a></code>.
</p>
</li></ul>

</li></ol>

<p>Furthermore, the computationally intensive tasks are written in <code>c++</code> via the <code>R</code>
package <strong>Rcpp</strong> (Eddelbuettel et al. 2011) and the <code>c++</code>
library <strong>Armadillo</strong> (Sanderson and Curtin 2016), there are plotting functions
for each method, control variables can be included in the model, and there is support for
missing values <code><a href="#topic+bggm_missing">bggm_missing</a></code>.
</p>
<p><b>Supported Data Types</b>:
</p>

<ul>
<li><p> Continuous: The continuous method was described in  Williams and Mulder (2019).
</p>
</li>
<li><p> Binary: The binary method builds directly upon in Talhouk et al. (2012),
that, in turn, built upon the approaches of Lawrence et al. (2008) and
Webb and Forster (2008) (to name a few).
</p>
</li>
<li><p> Ordinal: Ordinal data requires sampling thresholds. There are two approach included in <b>BGGM</b>: (1)
the customary approach described in in Albert and Chib (1993) (the default) and
the 'Cowles' algorithm described in in Cowles (1996).
</p>
</li>
<li><p> Mixed: The mixed data (a combination of discrete and continuous) method was introduced
in Hoff (2007). This is a semi-parametric copula model
(i.e., a copula GGM) based on the ranked likelihood. Note that this can be used for data
consisting entirely of ordinal data.
</p>
</li></ul>

<p><b>Additional Features</b>:
</p>
<p>The primary focus of <code>BGGM</code> is Gaussian graphical modeling (the inverse covariance matrix).
The residue is a suite of useful methods not explicitly for GGMs:
</p>

<ol>
<li><p> Bivariate correlations for binary (tetrachoric), ordinal (polychoric), mixed (rank based),
and continuous (Pearson's) data <code><a href="#topic+zero_order_cors">zero_order_cors</a></code>.
</p>
</li>
<li><p> Multivariate regression for binary (probit), ordinal (probit),
mixed (rank likelihood), and continous data (<code><a href="#topic+estimate">estimate</a></code>).
</p>
</li>
<li><p> Multiple regression for binary (probit), ordinal (probit),
mixed (rank likelihood), and continuous data (e.g., <code><a href="#topic+coef.estimate">coef.estimate</a></code>).
</p>
</li></ol>

<p><strong>Note on Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>All of the data types (besides continuous) model latent data. That is, unobserved
(latent) data is assumed to be Gaussian. For example, a tetrachoric correlation
(binary data) is a special case of a polychoric correlation (ordinal data).
Both capture relations between &quot;theorized normally distributed continuous
<strong>latent</strong> variables&quot; (<a href="https://en.wikipedia.org/wiki/Polychoric_correlation">Wikipedia</a>).
In both instances, the corresponding partial correlation between observed variables is conditioned
on the remaining variables in the <em>latent</em> space. This implies that interpretation
is similar to continuous data, but with respect to latent variables. We refer interested users
to page 2364, section 2.2, in  Webb and Forster (2008).
</p>
<p><strong>High Dimensional Data?</strong>
</p>
<p><strong>BGGM</strong> was built specifically for social-behavioral scientists. Of course,
the methods can be used by all researchers. However, there is currently <em>not</em> support
for high-dimensional data (i.e., more variables than observations) that are common
place in the genetics literature. These data are rare in the social-behavioral sciences.
In the future, support for high-dimensional data may be added to <strong>BGGM</strong>.
</p>


<h3>References</h3>

<p>Albert JH, Chib S (1993).
&ldquo;Bayesian analysis of binary and polychotomous response data.&rdquo;
<em>Journal of the American statistical Association</em>, <b>88</b>(422), 669&ndash;679.<br /><br /> Cowles MK (1996).
&ldquo;Accelerating Monte Carlo Markov chain convergence for cumulative-link generalized linear models.&rdquo;
<em>Statistics and Computing</em>, <b>6</b>(2), 101&ndash;111.
<a href="https://doi.org/10.1007/bf00162520">doi:10.1007/bf00162520</a>.<br /><br /> Eddelbuettel D, François R, Allaire J, Ushey K, Kou Q, Russel N, Chambers J, Bates D (2011).
&ldquo;Rcpp: Seamless R and C++ integration.&rdquo;
<em>Journal of Statistical Software</em>, <b>40</b>(8), 1&ndash;18.<br /><br /> Gelman A, Goodrich B, Gabry J, Vehtari A (2019).
&ldquo;R-squared for Bayesian Regression Models.&rdquo;
<em>American Statistician</em>, <b>73</b>(3), 307&ndash;309.
ISSN 15372731.<br /><br /> Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.<br /><br /> Lawrence E, Bingham D, Liu C, Nair VN (2008).
&ldquo;Bayesian inference for multivariate ordinal data using parameter expansion.&rdquo;
<em>Technometrics</em>, <b>50</b>(2), 182&ndash;191.<br /><br /> Mulder J, Pericchi L (2018).
&ldquo;The Matrix-F Prior for Estimating and Testing Covariance Matrices.&rdquo;
<em>Bayesian Analysis</em>, 1&ndash;22.
ISSN 19316690, <a href="https://doi.org/10.1214/17-BA1092">doi:10.1214/17-BA1092</a>.<br /><br /> Sanderson C, Curtin R (2016).
&ldquo;Armadillo: a template-based C++ library for linear algebra.&rdquo;
<em>Journal of Open Source Software</em>, <b>1</b>(2), 26.
<a href="https://doi.org/10.21105/joss.00026">doi:10.21105/joss.00026</a>.<br /><br /> Talhouk A, Doucet A, Murphy K (2012).
&ldquo;Efficient Bayesian inference for multivariate probit models with sparse inverse correlation matrices.&rdquo;
<em>Journal of Computational and Graphical Statistics</em>, <b>21</b>(3), 739&ndash;757.<br /><br /> Webb EL, Forster JJ (2008).
&ldquo;Bayesian model determination for multivariate ordinal and binary data.&rdquo;
<em>Computational statistics &amp; data analysis</em>, <b>52</b>(5), 2632&ndash;2649.
<a href="https://doi.org/10.1016/j.csda.2007.09.008">doi:10.1016/j.csda.2007.09.008</a>.<br /><br /> Williams DR (2018).
&ldquo;Bayesian Estimation for Gaussian Graphical Models: Structure Learning, Predictability, and Network Comparisons.&rdquo;
<em>arXiv</em>.
<a href="https://doi.org/10.31234/OSF.IO/X8DPR">doi:10.31234/OSF.IO/X8DPR</a>.<br /><br /> Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.<br /><br /> Williams DR, Rast P, Pericchi LR, Mulder J (2020).
&ldquo;Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection.&rdquo;
<em>Psychological Methods</em>.
<a href="https://doi.org/10.1037/met0000254">doi:10.1037/met0000254</a>.
</p>

<hr>
<h2 id='asd_ocd'>Data: Autism and Obssesive Compulsive Disorder</h2><span id='topic+asd_ocd'></span>

<h3>Description</h3>

<p>A correlation matrix with 17 variables in total (autsim: 9; OCD: 8).
The sample size was 213.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("asd_ocd")
</code></pre>


<h3>Format</h3>

<p>A correlation matrix including 17 variables. These data were measured on a 4 level likert scale.
</p>


<h3>Details</h3>

<p><strong>Autism</strong>:
</p>

<ul>
<li> <p><code>CI</code>  Circumscribed interests
</p>
</li>
<li> <p><code>UP</code>  Unusual preoccupations
</p>
</li>
<li> <p><code>RO</code>  Repetitive use of objects or interests in parts of objects
</p>
</li>
<li> <p><code>CR</code>  Compulsions and/or rituals
</p>
</li>
<li> <p><code>CI</code>  Unusual sensory interests
</p>
</li>
<li> <p><code>SM</code>  Complex mannerisms or stereotyped body movements
</p>
</li>
<li> <p><code>SU</code>  Stereotyped utterances/delayed echolalia
</p>
</li>
<li> <p><code>NIL</code> Neologisms and/or idiosyncratic language
</p>
</li>
<li> <p><code>VR</code>  Verbal rituals
</p>
</li></ul>

<p><strong>OCD</strong>
</p>

<ul>
<li> <p><code>CD</code> Concern with things touched due to dirt/bacteria
</p>
</li>
<li> <p><code>TB</code> Thoughts of doing something bad around others
</p>
</li>
<li> <p><code>CT</code> Continual thoughts that do not go away
</p>
</li>
<li> <p><code>HP</code> Belief that someone/higher power put reoccurring thoughts in their head
</p>
</li>
<li> <p><code>CW</code> Continual washing
</p>
</li>
<li> <p><code>CCh</code> Continual checking CntCheck
</p>
</li>
<li> <p><code>CC</code> Continual counting/repeating
</p>
</li>
<li> <p><code>RD</code> Repeatedly do things until it feels good or just right
</p>
</li></ul>



<h3>References</h3>

<p>Jones, P. J., Ma, R., &amp; McNally, R. J. (2019). Bridge centrality:
A network approach
to understanding comorbidity. Multivariate behavioral research, 1-15.
</p>
<p>Ruzzano, L., Borsboom, D., &amp; Geurts, H. M. (2015).
Repetitive behaviors in autism and obsessive-compulsive
disorder: New perspectives from a network analysis.
Journal of Autism and Developmental Disorders, 45(1),
192-202. doi:10.1007/s10803-014-2204-9
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("asd_ocd")

# generate continuous
Y &lt;- MASS::mvrnorm(n = 213,
                   mu = rep(0, 17),
                   Sigma = asd_ocd,
                   empirical = TRUE)


</code></pre>

<hr>
<h2 id='bfi'>Data: 25 Personality items representing 5 factors</h2><span id='topic+bfi'></span>

<h3>Description</h3>

<p>This dataset and the corresponding documentation was taken from the <strong>psych</strong> package. We refer users to that
package for further details (Revelle 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("bfi")
</code></pre>


<h3>Format</h3>

<p>A data frame with 25 variables and 2800 observations (including missing values)
</p>


<h3>Details</h3>


<ul>
<li> <p><code>A1</code> Am indifferent to the feelings of others. (q_146)
</p>
</li>
<li> <p><code>A2</code> Inquire about others' well-being. (q_1162)
</p>
</li>
<li> <p><code>A3</code> Know how to comfort others. (q_1206)
</p>
</li>
<li> <p><code>A4</code> Love children. (q_1364)
</p>
</li>
<li> <p><code>A5</code> Make people feel at ease. (q_1419)
</p>
</li>
<li> <p><code>C1</code> Am exacting in my work. (q_124)
</p>
</li>
<li> <p><code>C2</code> Continue until everything is perfect. (q_530)
</p>
</li>
<li> <p><code>C3</code> Do things according to a plan. (q_619)
</p>
</li>
<li> <p><code>C4</code> Do things in a half-way manner. (q_626)
</p>
</li>
<li> <p><code>C5</code> Waste my time. (q_1949)
</p>
</li>
<li> <p><code>E1</code> Don't talk a lot. (q_712)
</p>
</li>
<li> <p><code>E2</code> Find it difficult to approach others. (q_901)
</p>
</li>
<li> <p><code>E3</code> Know how to captivate people. (q_1205)
</p>
</li>
<li> <p><code>E4</code> Make friends easily. (q_1410)
</p>
</li>
<li> <p><code>E5</code> Take charge. (q_1768)
</p>
</li>
<li> <p><code>N1</code> Get angry easily. (q_952)
</p>
</li>
<li> <p><code>N2</code> Get irritated easily. (q_974)
</p>
</li>
<li> <p><code>N3</code> Have frequent mood swings. (q_1099)
</p>
</li>
<li> <p><code>N4</code> Often feel blue. (q_1479)
</p>
</li>
<li> <p><code>N5</code> Panic easily. (q_1505)
</p>
</li>
<li> <p><code>o1</code> Am full of ideas. (q_128)
</p>
</li>
<li> <p><code>o2</code> Avoid difficult reading material.(q_316)
</p>
</li>
<li> <p><code>o3</code> Carry the conversation to a higher level. (q_492)
</p>
</li>
<li> <p><code>o4</code> Spend time reflecting on things. (q_1738)
</p>
</li>
<li> <p><code>o5</code> Will not probe deeply into a subject. (q_1964)
</p>
</li>
<li> <p><code>gender</code> Males = 1, Females =2
</p>
</li>
<li> <p><code>education</code> 1 = HS, 2 = finished HS, 3 = some college, 4 = college graduate 5 = graduate degree
</p>
</li></ul>



<h3>References</h3>

<p>Revelle W (2019).
<em>psych: Procedures for Psychological, Psychometric, and Personality Research</em>.
Northwestern University, Evanston, Illinois.
R package version 1.9.12, <a href="https://CRAN.R-project.org/package=psych">https://CRAN.R-project.org/package=psych</a>.
</p>

<hr>
<h2 id='bggm_missing'>GGM: Missing Data</h2><span id='topic+bggm_missing'></span>

<h3>Description</h3>

<p>Estimation and exploratory hypothesis testing with missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bggm_missing(x, iter = 2000, method = "estimate", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bggm_missing_+3A_x">x</code></td>
<td>
<p>An object of class <code>mid</code> <code><a href="mice.html#topic+mice">mice</a></code>.</p>
</td></tr>
<tr><td><code id="bggm_missing_+3A_iter">iter</code></td>
<td>
<p>Number of iterations for each imputed dataset (posterior samples; defaults to 2000).</p>
</td></tr>
<tr><td><code id="bggm_missing_+3A_method">method</code></td>
<td>
<p>Character string. Which method should be used (default set to <code>estimate</code>)? The current
options are <code>"estimate"</code> and <code>"explore"</code>.</p>
</td></tr>
<tr><td><code id="bggm_missing_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to either
<code><a href="#topic+estimate">estimate</a></code> or <code><a href="#topic+explore">explore</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>estimate</code> or <code>explore</code>.
</p>


<h3>Note</h3>

<p>Currently, <strong>BGGM</strong> is compatible with the package <code><a href="mice.html#topic+mice">mice</a></code> for handling
the missing data. This is accomplished by fitting a model for each imputed dataset
(i.e., more than one to account for uncertainty in the imputation step) and then pooling
the estimates.
</p>
<p>In a future version, an additional option will be added that allows for
imputing the missing values during model fitting. This option will be incorporated directly into
the <code><a href="#topic+estimate">estimate</a></code> or <code><a href="#topic+explore">explore</a></code> functions, such that <code>bggm_missing</code> will
always support missing data with <code><a href="mice.html#topic+mice">mice</a></code>.
</p>
<p><strong>Support</strong>:
</p>
<p>There is limited support for missing data. As of version <code>2.0.0</code>, it is possible to
determine the graphical structure with either  <code><a href="#topic+estimate">estimate</a></code> or <code><a href="#topic+explore">explore</a></code>, in addition
to plotting the graph with <code><a href="#topic+plot.select">plot.select</a></code>. All data types <em>are</em> currently supported.
</p>
<p><strong>Memory Warning</strong>:
A model is fitted for each imputed dataset. This results in a potentially large object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# need this package
library(mice, warn.conflicts = FALSE)

# data
Y &lt;- ptsd[,1:5]

# matrix for indices
mat &lt;- matrix(0, nrow = 221, ncol = 5)

# indices
indices &lt;- which(mat == 0, arr.ind = TRUE)

# 50 NAs
Y[indices[sample(1:nrow(indices), 50),]] &lt;- NA

# impute
x &lt;- mice(Y, m = 5, print = FALSE)

#########################
#######   copula    #####
#########################
# rank based parital correlations

# estimate the model
fit_est &lt;-  bggm_missing(x,
                         method = "estimate",
                         type =  "mixed",
                         iter = 250,
                         progress = FALSE)

# select edge set
E &lt;- select(fit_est)

# plot E
plt_E &lt;- plot(E)$plt

plt_E

</code></pre>

<hr>
<h2 id='coef.estimate'>Compute Regression Parameters for <code>estimate</code> Objects</h2><span id='topic+coef.estimate'></span>

<h3>Description</h3>

<p>There is a direct correspondence between the inverse covariance matrix and
multiple regression (Kwan 2014; Stephens 1998). This readily allows
for converting the GGM parameters to regression coefficients. All data types are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'estimate'
coef(object, iter = NULL, progress = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.estimate_+3A_object">object</code></td>
<td>
<p>An Object of class <code>estimate</code></p>
</td></tr>
<tr><td><code id="coef.estimate_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to the number in the object).</p>
</td></tr>
<tr><td><code id="coef.estimate_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="coef.estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>coef</code>, containting two lists.
</p>

<ul>
<li> <p><code>betas</code> A list of length <em>p</em>, each containing a <em>p</em> - 1 by <code>iter</code> matrix of
posterior samples
</p>
</li>
<li> <p><code>object</code> An object of class <code>estimate</code> (the fitted model).
</p>
</li></ul>



<h3>References</h3>

<p>Kwan CC (2014).
&ldquo;A regression-based interpretation of the inverse of the sample covariance matrix.&rdquo;
<em>Spreadsheets in Education</em>, <b>7</b>(1), 4613.<br /><br /> Stephens G (1998).
&ldquo;On the Inverse of the Covariance Matrix in Portfolio Analysis.&rdquo;
<em>The Journal of Finance</em>, <b>53</b>(5), 1821&ndash;1827.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

#########################
### example 1: binary ###
#########################
# data
Y = matrix( rbinom(100, 1, .5), ncol=4)

# fit model
fit &lt;- estimate(Y, type = "binary",
                iter = 250,
                progress = TRUE)

# summarize the partial correlations
reg &lt;- coef(fit, progress = FALSE)

# summary
summ &lt;- summary(reg)

summ

</code></pre>

<hr>
<h2 id='coef.explore'>Compute Regression Parameters for <code>explore</code> Objects</h2><span id='topic+coef.explore'></span>

<h3>Description</h3>

<p>There is a direct correspondence between the inverse covariance matrix and
multiple regression (Kwan 2014; Stephens 1998). This readily allows
for converting the GGM parameters to regression coefficients. All data types are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'explore'
coef(object, iter = NULL, progress = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.explore_+3A_object">object</code></td>
<td>
<p>An Object of class <code>explore</code>.</p>
</td></tr>
<tr><td><code id="coef.explore_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to the number in the object).</p>
</td></tr>
<tr><td><code id="coef.explore_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="coef.explore_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>coef</code>, containting two lists.
</p>

<ul>
<li> <p><code>betas</code> A list of length <em>p</em>, each containing a <em>p</em> - 1 by <code>iter</code> matrix of
posterior samples
</p>
</li>
<li> <p><code>object</code> An object of class <code>explore</code> (the fitted model).
</p>
</li></ul>



<h3>References</h3>

<p>Kwan CC (2014).
&ldquo;A regression-based interpretation of the inverse of the sample covariance matrix.&rdquo;
<em>Spreadsheets in Education</em>, <b>7</b>(1), 4613.<br /><br /> Stephens G (1998).
&ldquo;On the Inverse of the Covariance Matrix in Portfolio Analysis.&rdquo;
<em>The Journal of Finance</em>, <b>53</b>(5), 1821&ndash;1827.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- ptsd[,1:4]

##########################
### example 1: ordinal ###
##########################

# fit model (note + 1, due to zeros)
fit &lt;- explore(Y + 1,
               type = "ordinal",
               iter = 250,
               progress = FALSE)

# summarize the partial correlations
reg &lt;- coef(fit, progress = FALSE)

# summary
summ &lt;- summary(reg)

summ

</code></pre>

<hr>
<h2 id='confirm'>GGM: Confirmatory Hypothesis Testing</h2><span id='topic+confirm'></span>

<h3>Description</h3>

<p>Confirmatory hypothesis testing in GGMs. Hypotheses are expressed as equality
and/or ineqaulity contraints on the partial correlations of interest. Here the focus is <em>not</em>
on determining the graph (see <code><a href="#topic+explore">explore</a></code>) but testing specific hypotheses related to
the conditional (in)dependence structure. These methods were introduced in
Williams and Mulder (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confirm(
  Y,
  hypothesis,
  prior_sd = 0.5,
  formula = NULL,
  type = "continuous",
  mixed_type = NULL,
  iter = 25000,
  progress = TRUE,
  impute = TRUE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confirm_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="confirm_+3A_hypothesis">hypothesis</code></td>
<td>
<p>Character string. The hypothesis (or hypotheses) to be tested. See details.</p>
</td></tr>
<tr><td><code id="confirm_+3A_prior_sd">prior_sd</code></td>
<td>
<p>Numeric. Scale of the prior distribution, approximately the standard deviation
of a beta distribution (defaults to 0.5).</p>
</td></tr>
<tr><td><code id="confirm_+3A_formula">formula</code></td>
<td>
<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code>. This allows for including
control variables in the model (e.g.,, <code>~ gender * education</code>).</p>
</td></tr>
<tr><td><code id="confirm_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <strong>Y</strong> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>mixed</code>. See the note for further details.</p>
</td></tr>
<tr><td><code id="confirm_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector of length <em>p</em>. An indicator for which varibles should be treated as ranks.
(1 for rank and 0 to assume normality). The default is currently (dev version) to treat all integer variables
as ranks when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="confirm_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 25,000).</p>
</td></tr>
<tr><td><code id="confirm_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="confirm_+3A_impute">impute</code></td>
<td>
<p>Logicial. Should the missing values (<code>NA</code>)
be imputed during model fitting (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="confirm_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed.</p>
</td></tr>
<tr><td><code id="confirm_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hypotheses can be written either with the respective column names or numbers.
For example, <code>1--2</code> denotes the relation between the variables in column 1 and 2.
Note that these must correspond to the upper triangular elements of the correlation
matrix. This is accomplished by ensuring that the first number is smaller than the second number.
This also applies when using column names (i.e,, in reference to the column number).
</p>
<p><strong>One Hypothesis</strong>:
</p>
<p>To test whether some relations are larger than others, while others
are expected to be equal, this can be writting as
</p>

<ul>
<li> <p><code>hyp &lt;-  c(1--2 &gt; 1--3  = 1--4 &gt; 0)</code>,
</p>
</li></ul>

<p>where there is an addition additional contraint that all effects are expected to be positive.
This is then compared to the complement.
</p>
<p><strong>More Than One Hypothesis</strong>:
</p>
<p>The above hypothesis can also be compared to, say, a null model by using &quot;;&quot;
to seperate the hypotheses, for example,
</p>

<ul>
<li>
<p><code>hyp &lt;-  c(1--2 &gt; 1--3  = 1--4 &gt; 0; 1--2 = 1--3  = 1--4 = 0)</code>.
</p>
</li></ul>

<p>Any number of hypotheses can be compared this way.
</p>
<p><strong>Using &quot;&amp;&quot;</strong>
</p>
<p>It is also possible to include <code>&amp;</code>. This allows for testing one constraint <b>and</b>
another contraint as one hypothesis.
</p>

<ul>
<li> <p><code>hyp &lt;- c("A1--A2 &gt; A1--A2 &amp; A1--A3 = A1--A3")</code>
</p>
</li></ul>

<p>Of course, it is then possible to include additional hypotheses by separating them with &quot;;&quot;.
Note also that the column names were used in this example (e.g., <code>A1--A2</code> is the relation
between those nodes).
</p>
<p><strong>Testing Sums</strong>
</p>
<p>It might also be interesting to test the sum of partial correlations. For example, that the
sum of specific relations is larger than the sum of other relations. This can be written as
</p>

<ul>
<li> <p><code>hyp &lt;- c("A1--A2 + A1--A3 &gt; A1--A4 + A1--A5;
                      A1--A2 + A1--A3 = A1--A4 + A1--A5")</code>
</p>
</li></ul>

<p><strong>Potential Delays</strong>:
</p>
<p>There is a chance for a potentially long delay from the time the progress bar finishes
to when the function is done running. This occurs when the hypotheses require further
sampling to be tested, for example, when grouping relations
<code>c("(A1--A2, A1--A3) &gt; (A1--A4, A1--A5)"</code>. This is not an error.
</p>
<p><strong>Controlling for Variables</strong>:
</p>
<p>When controlling for variables, it is assumed that <code>Y</code> includes <em>only</em>
the nodes in the GGM and the control variables. Internally, <code>only</code> the predictors
that are included in <code>formula</code> are removed from <code>Y</code>. This is not behavior of, say,
<code><a href="stats.html#topic+lm">lm</a></code>, but was adopted to ensure  users do not have to write out each variable that
should be included in the GGM. An example is provided below.
</p>
<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables (Hoff 2007). This is based on the
ranked likelihood which requires sampling the ranks for each variable (i.e., the data is not merely
transformed to ranks). This is computationally expensive when there are many levels. For example,
with continuous data, there are as many ranks as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise. This is accomplished by specifying an indicator
vector of length <em>p</em>. A one indicates to use the ranks, whereas a zero indicates to &quot;ignore&quot;
that variable. By default all integer variables are handled as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>



<h3>Value</h3>

<p>The returned object of class <code>confirm</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>out_hyp_prob</code> Posterior hypothesis probabilities.
</p>
</li>
<li> <p><code>info</code> An object of class <code>BF</code> from the R package <strong>BFpack</strong>.
</p>
</li></ul>



<h3>Note</h3>

<p><strong>&quot;Default&quot; Prior</strong>:
</p>
<p>In Bayesian statistics, a default Bayes factor needs to have several properties. I refer
interested users to section 2.2 in Dablander et al. (2020). In
Williams and Mulder (2019), some of these propteries were investigated (e.g.,
model selection consistency). That said, we would not consider this a &quot;default&quot; or &quot;automatic&quot;
Bayes factor and thus we encourage users to perform sensitivity analyses by varying the scale of the prior
distribution.
</p>
<p>Furthermore, it is important to note there is no &quot;correct&quot; prior and, also, there is no need
to entertain the possibility of a &quot;true&quot; model. Rather, the Bayes factor can be interpreted as
which hypothesis best (relative to each other) predicts the observed data
(Section 3.2 in Kass and Raftery 1995).
</p>
<p><strong>Interpretation of Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>See <code><a href="#topic+BGGM-package">BGGM-package</a></code> for details about interpreting GGMs based on latent data
(i.e, all data types besides <code>"continuous"</code>)
</p>


<h3>References</h3>

<p>Dablander F, Bergh Dvd, Ly A, Wagenmakers E (2020).
&ldquo;Default Bayes Factors for Testing the (In) equality of Several Population Variances.&rdquo;
<em>arXiv preprint arXiv:2003.06278</em>.<br /><br /> Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.<br /><br /> Kass RE, Raftery AE (1995).
&ldquo;Bayes Factors.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>90</b>(430), 773&ndash;795.<br /><br /> Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

##########################
### example 1: cheating ##
##########################
# Here a true hypothesis is tested,
# which shows the method works nicely
# (peeked at partials beforehand)

# data
Y &lt;- BGGM::bfi[,1:10]

hypothesis &lt;- c("A1--A2 &lt; A1--A3 &lt; A1--A4 = A1--A5")

# test cheat
test_cheat &lt;-  confirm(Y = Y,
                       type = "continuous",
                       hypothesis  = hypothesis,
                       iter = 250,
                       progress = FALSE)

# print (probabilty of nearly 1 !)
test_cheat

</code></pre>

<hr>
<h2 id='constrained_posterior'>Constrained Posterior Distribution</h2><span id='topic+constrained_posterior'></span>

<h3>Description</h3>

<p>Compute the posterior distribution
with off-diagonal elements of the precision matrix constrained
to zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constrained_posterior(
  object,
  adj,
  method = "direct",
  iter = 5000,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constrained_posterior_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code> or <code>explore</code></p>
</td></tr>
<tr><td><code id="constrained_posterior_+3A_adj">adj</code></td>
<td>
<p>A <code>p</code> by <code>p</code> adjacency matrix. The zero entries denote the
elements that should be constrained to zero.</p>
</td></tr>
<tr><td><code id="constrained_posterior_+3A_method">method</code></td>
<td>
<p>Character string. Which method should be used ? Defaults to
the &quot;direct sampler&quot; (i.e., <code>method = "direct"</code>) described in
page 122, section 2.4,  Lenkoski (2013). The other
option is a Metropolis-Hastings algorithm (<code>MH</code>).
See details.</p>
</td></tr>
<tr><td><code id="constrained_posterior_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="constrained_posterior_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="constrained_posterior_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>contrained</code>, including
</p>

<ul>
<li> <p><code>precision_mean</code> The posterior mean for the precision matrix.
</p>
</li>
<li> <p><code>pcor_mean</code> The posterior mean for the precision matrix.
</p>
</li>
<li> <p><code>precision_samps</code> A 3d array of dimension <code>p</code> by <code>p</code> by <code>iter</code>
including the sampled precision matrices.
</p>
</li>
<li> <p><code>pcor_samps</code> A 3d array of dimension <code>p</code> by <code>p</code> by <code>iter</code>
including sampled partial correlations matrices.
</p>
</li></ul>



<h3>References</h3>

<p>Lenkoski A (2013).
&ldquo;A direct sampler for G-Wishart variates.&rdquo;
<em>Stat</em>, <b>2</b>(1), 119&ndash;128.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# data
Y &lt;- bfi[,1:10]

# sample posterior
fit &lt;- estimate(Y, iter = 100)

# select graph
sel &lt;- select(fit)

# constrained posterior
post &lt;- constrained_posterior(object = fit,
                              adj = sel$adj,
                              iter = 100,
                              progress = FALSE)


</code></pre>

<hr>
<h2 id='convergence'>MCMC Convergence</h2><span id='topic+convergence'></span>

<h3>Description</h3>

<p>Monitor convergence of the MCMC algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convergence(object, param = NULL, type = "trace", print_names = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convergence_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code> or <code>explore</code></p>
</td></tr>
<tr><td><code id="convergence_+3A_param">param</code></td>
<td>
<p>Character string. Names of parameters for which to monitor MCMC convergence.</p>
</td></tr>
<tr><td><code id="convergence_+3A_type">type</code></td>
<td>
<p>Character string. Which type of convergence plot ? The current
options are <code>trace</code> (default) and <code>acf</code>.</p>
</td></tr>
<tr><td><code id="convergence_+3A_print_names">print_names</code></td>
<td>
<p>Logical. Should the parameter names be printed (defaults to <code>FALSE</code>)? This
can be used to first determine the parameter names to specify in <code>type</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code>ggplot</code> objects.
</p>


<h3>Note</h3>

<p>An overview of MCMC diagnostics can be found <a href="https://sbfnk.github.io/mfiidd/mcmc_diagnostics.html">here</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- ptsd[,1:5]

#########################
###### continuous #######
#########################
fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)

# print names first
convergence(fit, print_names = TRUE)

# trace plots
convergence(fit, type = "trace",
            param = c("B1--B2", "B1--B3"))[[1]]

# acf plots
convergence(fit, type = "acf",
            param = c("B1--B2", "B1--B3"))[[1]]

</code></pre>

<hr>
<h2 id='csws'>Data: Contingencies of Self-Worth Scale (CSWS)</h2><span id='topic+csws'></span>

<h3>Description</h3>

<p>A dataset containing items from the Contingencies of Self-Worth Scale (CSWS) scale. There are 35 variables  and
680 observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("csws")
</code></pre>


<h3>Format</h3>

<p>A data frame with 35 variables and 680 observations (7 point Likert scale)
</p>


<h3>Details</h3>


<ul>
<li> <p><code>1</code> When I think I look attractive, I feel good about myself
</p>
</li>
<li> <p><code>2</code> My self-worth is based on God's love
</p>
</li>
<li> <p><code>3</code> I feel worthwhile when I perform better than others on a task or skill.
</p>
</li>
<li> <p><code>4</code> My self-esteem is unrelated to how I feel about the way my body looks.
</p>
</li>
<li> <p><code>5</code> Doing something I know is wrong makes me lose my self-respect
</p>
</li>
<li> <p><code>6</code> I don't care if other people have a negative opinion about me.
</p>
</li>
<li> <p><code>7</code> Knowing that my family members love me makes me feel good about myself.
</p>
</li>
<li> <p><code>8</code> I feel worthwhile when I have God's love.
</p>
</li>
<li> <p><code>9</code> I can’t respect myself if others don't respect me.
</p>
</li>
<li> <p><code>10</code> My self-worth is not influenced by the quality of my relationships with my family members.
</p>
</li>
<li> <p><code>11</code> Whenever I follow my moral principles, my sense of self-respect gets a boost.
</p>
</li>
<li> <p><code>12</code> Knowing that I am better than others on a task raises my self-esteem.
</p>
</li>
<li> <p><code>13</code> My opinion about myself isn't tied to how well I do in school.
</p>
</li>
<li> <p><code>14</code> I couldn't respect myself if I didn't live up to a moral code.
</p>
</li>
<li> <p><code>15</code> I don't care what other people think of me.
</p>
</li>
<li> <p><code>16</code> When my family members are proud of me, my sense of self-worth increases.
</p>
</li>
<li> <p><code>17</code> My self-esteem is influenced by how attractive I think my face or facial features are.
</p>
</li>
<li> <p><code>18</code> My self-esteem would suffer if I didn’t have God's love.
</p>
</li>
<li> <p><code>19</code> Doing well in school gives me a sense of selfrespect.
</p>
</li>
<li> <p><code>20</code> Doing better than others gives me a sense of self-respect.
</p>
</li>
<li> <p><code>21</code> My sense of self-worth suffers whenever I think I don't look good.
</p>
</li>
<li> <p><code>22</code> I feel better about myself when I know I'm doing well academically.
</p>
</li>
<li> <p><code>23</code> What others think of me has no effect on what I think about myself.
</p>
</li>
<li> <p><code>24</code> When I don’t feel loved by my family, my selfesteem goes down.
</p>
</li>
<li> <p><code>25</code> My self-worth is affected by how well I do when I am competing with others.
</p>
</li>
<li> <p><code>26</code> My self-esteem goes up when I feel that God loves me.
</p>
</li>
<li> <p><code>27</code> My self-esteem is influenced by my academic performance.
</p>
</li>
<li> <p><code>28</code> My self-esteem would suffer if I did something unethical.
</p>
</li>
<li> <p><code>29</code> It is important to my self-respect that I have a family that cares about me.
</p>
</li>
<li> <p><code>30</code> My self-esteem does not depend on whether or not I feel attractive.
</p>
</li>
<li> <p><code>31</code> When I think that I’m disobeying God, I feel bad about myself.
</p>
</li>
<li> <p><code>32</code> My self-worth is influenced by how well I do on competitive tasks.
</p>
</li>
<li> <p><code>33</code> I feel bad about myself whenever my academic performance is lacking.
</p>
</li>
<li> <p><code>34</code> My self-esteem depends on whether or not I follow my moral/ethical principles.
</p>
</li>
<li> <p><code>35</code> My self-esteem depends on the opinions others hold of me.
</p>
</li>
<li> <p><code>gender</code> &quot;M&quot; (male) or &quot;F&quot; (female)
</p>
</li></ul>



<h3>Note</h3>

<p>There are seven domains
</p>
<p>FAMILY SUPPORT: items 7, 10, 16, 24, and 29.
</p>
<p>COMPETITION: items 3, 12, 20, 25, and 32.
</p>
<p>APPEARANCE: items 1, 4, 17, 21, and 30.
</p>
<p>GOD'S LOVE: items 2, 8, 18, 26, and 31.
</p>
<p>ACADEMIC COMPETENCE: items 13, 19, 22, 27, and 33.
</p>
<p>VIRTUE: items 5, 11, 14, 28, and 34.
</p>
<p>APPROVAL FROM OTHERS: items: 6, 9, 15, 23, and 35.
</p>


<h3>References</h3>

<p>Briganti, G., Fried, E. I., &amp; Linkowski, P. (2019). Network analysis of Contingencies of Self-Worth
Scale in 680 university students. Psychiatry research, 272, 252-257.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("csws")


</code></pre>

<hr>
<h2 id='depression_anxiety_t1'>Data: Depression and Anxiety (Time 1)</h2><span id='topic+depression_anxiety_t1'></span>

<h3>Description</h3>

<p>A data frame containing 403 observations (n = 403) and 16 variables (p = 16) measured on the 4-point
likert scale (depression: 9; anxiety: 7).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("depression_anxiety_t1")
</code></pre>


<h3>Format</h3>

<p>A data frame containing 403 observations (n = 7466) and 16 variables (p = 16) measured on the 4-point
likert scale.
</p>


<h3>Details</h3>

<p><strong>Depression</strong>:
</p>

<ul>
<li> <p><code>PHQ1</code>  Little interest or pleasure in doing things?
</p>
</li>
<li> <p><code>PHQ2</code>  Feeling down, depressed, or hopeless?
</p>
</li>
<li> <p><code>PHQ3</code>  Trouble falling or staying asleep, or sleeping too much?
</p>
</li>
<li> <p><code>PHQ4</code>  Feeling tired or having little energy?
</p>
</li>
<li> <p><code>PHQ5</code>  Poor appetite or overeating?
</p>
</li>
<li> <p><code>PHQ6</code> Feeling bad about yourself — or that you are a failure or have let
yourself or your family down?
</p>
</li>
<li> <p><code>PHQ7</code>  Trouble concentrating on things, such as reading the newspaper or
watching television?
</p>
</li>
<li> <p><code>PHQ8</code> Moving or speaking so slowly that other people could have noticed? Or so
fidgety or restless that you have been moving a lot more than usual?
</p>
</li>
<li> <p><code>PHQ9</code>  Thoughts that you would be better off dead, or thoughts of hurting yourself
in some way?
</p>
</li></ul>

<p><strong>Anxiety</strong>
</p>

<ul>
<li> <p><code>GAD1</code> Feeling nervous, anxious, or on edge
</p>
</li>
<li> <p><code>GAD2</code> Not being able to stop or control worrying
</p>
</li>
<li> <p><code>GAD3</code> Worrying too much about different things
</p>
</li>
<li> <p><code>GAD4</code> Trouble relaxing
</p>
</li>
<li> <p><code>GAD5</code> Being so restless that it's hard to sit still
</p>
</li>
<li> <p><code>GAD6</code> Becoming easily annoyed or irritable
</p>
</li>
<li> <p><code>GAD7</code> Feeling afraid as if something awful might happen
</p>
</li></ul>



<h3>References</h3>

<p>Forbes, M. K., Baillie, A. J., &amp; Schniering, C. A. (2016). A structural equation modeling
analysis of the relationships between depression,anxiety, and sexual problems over time.
The Journal of Sex Research, 53(8), 942-954.
</p>
<p>Forbes, M. K., Wright, A. G., Markon, K. E., &amp; Krueger, R. F. (2019). Quantifying the reliability and replicability of psychopathology network characteristics.
Multivariate behavioral research, 1-19.
</p>
<p>Jones, P. J., Williams, D. R., &amp; McNally, R. J. (2019). Sampling variability is not nonreplication:
a Bayesian reanalysis of Forbes, Wright, Markon, &amp; Krueger.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("depression_anxiety_t1")
labels&lt;- c("interest", "down", "sleep",
            "tired", "appetite", "selfest",
           "concen", "psychmtr", "suicid",
           "nervous", "unctrworry", "worrylot",
           "relax", "restless", "irritable", "awful")


</code></pre>

<hr>
<h2 id='depression_anxiety_t2'>Data: Depression and Anxiety (Time 2)</h2><span id='topic+depression_anxiety_t2'></span>

<h3>Description</h3>

<p>A data frame containing 403 observations (n = 403) and 16 variables (p = 16) measured on the 4-point
likert scale  (depression: 9; anxiety: 7).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("depression_anxiety_t2")
</code></pre>


<h3>Format</h3>

<p>A data frame containing 403 observations (n = 7466) and 16 variables (p = 16) measured on the 4-point
likert scale.
</p>


<h3>Details</h3>

<p><strong>Depression</strong>:
</p>

<ul>
<li> <p><code>PHQ1</code>  Little interest or pleasure in doing things?
</p>
</li>
<li> <p><code>PHQ2</code>  Feeling down, depressed, or hopeless?
</p>
</li>
<li> <p><code>PHQ3</code>  Trouble falling or staying asleep, or sleeping too much?
</p>
</li>
<li> <p><code>PHQ4</code>  Feeling tired or having little energy?
</p>
</li>
<li> <p><code>PHQ5</code>  Poor appetite or overeating?
</p>
</li>
<li> <p><code>PHQ6</code> Feeling bad about yourself — or that you are a failure or have let
yourself or your family down?
</p>
</li>
<li> <p><code>PHQ7</code>  Trouble concentrating on things, such as reading the newspaper or
watching television?
</p>
</li>
<li> <p><code>PHQ8</code> Moving or speaking so slowly that other people could have noticed? Or so
fidgety or restless that you have been moving a lot more than usual?
</p>
</li>
<li> <p><code>PHQ9</code>  Thoughts that you would be better off dead, or thoughts of hurting yourself
in some way?
</p>
</li></ul>

<p><strong>Anxiety</strong>
</p>

<ul>
<li> <p><code>GAD1</code> Feeling nervous, anxious, or on edge
</p>
</li>
<li> <p><code>GAD2</code> Not being able to stop or control worrying
</p>
</li>
<li> <p><code>GAD3</code> Worrying too much about different things
</p>
</li>
<li> <p><code>GAD4</code> Trouble relaxing
</p>
</li>
<li> <p><code>GAD5</code> Being so restless that it's hard to sit still
</p>
</li>
<li> <p><code>GAD6</code> Becoming easily annoyed or irritable
</p>
</li>
<li> <p><code>GAD7</code> Feeling afraid as if something awful might happen
</p>
</li></ul>



<h3>References</h3>

<p>Forbes, M. K., Baillie, A. J., &amp; Schniering, C. A. (2016). A structural equation modeling
analysis of the relationships between depression,anxiety, and sexual problems over time.
The Journal of Sex Research, 53(8), 942-954.
</p>
<p>Forbes, M. K., Wright, A. G., Markon, K. E., &amp; Krueger, R. F. (2019). Quantifying the reliability and replicability of psychopathology network characteristics.
Multivariate behavioral research, 1-19.
</p>
<p>Jones, P. J., Williams, D. R., &amp; McNally, R. J. (2019). Sampling variability is not nonreplication:
a Bayesian reanalysis of Forbes, Wright, Markon, &amp; Krueger.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("depression_anxiety_t2")
labels&lt;- c("interest", "down", "sleep",
            "tired", "appetite", "selfest",
           "concen", "psychmtr", "suicid",
           "nervous", "unctrworry", "worrylot",
           "relax", "restless", "irritable", "awful")


</code></pre>

<hr>
<h2 id='estimate'>GGM: Estimation</h2><span id='topic+estimate'></span>

<h3>Description</h3>

<p>Estimate the conditional (in)dependence with either an analytic solution or efficiently
sampling from the posterior distribution. These methods were introduced in Williams (2018).
The graph is selected with <code><a href="#topic+select.estimate">select.estimate</a></code> and then plotted with <code><a href="#topic+plot.select">plot.select</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate(
  Y,
  formula = NULL,
  type = "continuous",
  mixed_type = NULL,
  analytic = FALSE,
  prior_sd = sqrt(1/3),
  iter = 5000,
  impute = FALSE,
  progress = TRUE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="estimate_+3A_formula">formula</code></td>
<td>
<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code>. This allows for including
control variables in the model (i.e., <code>~ gender</code>). See the note for further details.</p>
</td></tr>
<tr><td><code id="estimate_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <code>Y</code> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>mixed</code>. Note that mixed can be used for data with only
ordinal variables. See the note for further details.</p>
</td></tr>
<tr><td><code id="estimate_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector. An indicator of length <em>p</em> for which variables should be treated as ranks.
(1 for rank and 0 to assume normality). The default is currently to treat all integer variables as ranks
when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="estimate_+3A_analytic">analytic</code></td>
<td>
<p>Logical. Should the analytic solution be computed (default is <code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="estimate_+3A_prior_sd">prior_sd</code></td>
<td>
<p>Scale of the prior distribution, approximately the standard deviation of a beta distribution
(defaults to sqrt(1/3)).</p>
</td></tr>
<tr><td><code id="estimate_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="estimate_+3A_impute">impute</code></td>
<td>
<p>Logical. Should the missing values (<code>NA</code>)
be imputed during model fitting (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="estimate_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="estimate_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed.</p>
</td></tr>
<tr><td><code id="estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default is to draw samples from the posterior distribution (<code>analytic = FALSE</code>). The samples are
required for computing edge differences (see <code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code>), Bayesian R2 introduced in
Gelman et al. (2019) (see <code><a href="#topic+predictability">predictability</a></code>), etc. If the goal is
to *only* determine the non-zero effects, this can be accomplished by setting <code>analytic = TRUE</code>.
This is particularly useful when a fast solution is needed (see the examples in <code><a href="#topic+ggm_compare_ppc">ggm_compare_ppc</a></code>)
</p>
<p><strong>Controlling for Variables</strong>:
</p>
<p>When controlling for variables, it is assumed that <code>Y</code> includes <em>only</em>
the nodes in the GGM and the control variables. Internally, <code>only</code> the predictors
that are included in <code>formula</code> are removed from <code>Y</code>. This is not behavior of, say,
<code><a href="stats.html#topic+lm">lm</a></code>, but was adopted to ensure  users do not have to write out each variable that
should be included in the GGM. An example is provided below.
</p>
<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables. This is based on the ranked likelihood which requires sampling
the ranks for each variable (i.e., the data is not merely transformed to ranks). This is computationally
expensive when there are many levels. For example, with continuous data, there are as many ranks
as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise (Hoff 2007). This is
accomplished by specifying an indicator vector of length <em>p</em>. A one indicates to use the ranks,
whereas a zero indicates to &quot;ignore&quot; that variable. By default all integer variables are treated as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>

<p><strong>Imputing Missing Values</strong>:
</p>
<p>Missing values are imputed with the approach described in Hoff (2009).
The basic idea is to impute the missing values with the respective posterior pedictive distribution,
given the observed data, as the model is being estimated. Note that the default is <code>TRUE</code>,
but this ignored when there are no missing values. If set to <code>FALSE</code>, and there are missing
values, list-wise deletion is performed with <code>na.omit</code>.
</p>


<h3>Value</h3>

<p>The returned object of class <code>estimate</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>pcor_mat</code> Partial correltion matrix (posterior mean).
</p>
</li>
<li> <p><code>post_samp</code> An object containing the posterior samples.
</p>
</li></ul>



<h3>Note</h3>

<p><strong>Posterior Uncertainty</strong>:
</p>
<p>A key feature of <b>BGGM</b> is that there is a posterior distribution for each partial correlation.
This readily allows for visiualizing uncertainty in the estimates. This feature works
with all data types and is accomplished by plotting the summary of the <code>estimate</code> object
(i.e., <code>plot(summary(fit))</code>). Several examples are provided below.
</p>
<p><strong>Interpretation of Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>See <code><a href="#topic+BGGM-package">BGGM-package</a></code> for details about interpreting GGMs based on latent data
(i.e, all data types besides <code>"continuous"</code>)
</p>


<h3>References</h3>

<p>Gelman A, Goodrich B, Gabry J, Vehtari A (2019).
&ldquo;R-squared for Bayesian Regression Models.&rdquo;
<em>American Statistician</em>, <b>73</b>(3), 307&ndash;309.
ISSN 15372731.<br /><br /> Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.<br /><br /> Hoff PD (2009).
<em>A first course in Bayesian statistical methods</em>, volume 580.
Springer.<br /><br /> Williams DR (2018).
&ldquo;Bayesian Estimation for Gaussian Graphical Models: Structure Learning, Predictability, and Network Comparisons.&rdquo;
<em>arXiv</em>.
<a href="https://doi.org/10.31234/OSF.IO/X8DPR">doi:10.31234/OSF.IO/X8DPR</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

#########################################
### example 1: continuous and ordinal ###
#########################################
# data
Y &lt;- ptsd

# continuous

# fit model
fit &lt;- estimate(Y, type = "continuous",
                iter = 250)

# summarize the partial correlations
summ &lt;- summary(fit)

# plot the summary
plt_summ &lt;- plot(summary(fit))

# select the graph
E &lt;- select(fit)

# plot the selected graph
plt_E &lt;- plot(select(fit))


# ordinal

# fit model (note + 1, due to zeros)
fit &lt;- estimate(Y + 1, type = "ordinal",
                iter = 250)

# summarize the partial correlations
summ &lt;- summary(fit)

# plot the summary
plt &lt;- plot(summary(fit))

# select the graph
E &lt;- select(fit)

# plot the selected graph
plt_E &lt;- plot(select(fit))

##################################
## example 2: analytic solution ##
##################################
# (only continuous)

# data
Y &lt;- ptsd

# fit model
fit &lt;- estimate(Y, analytic = TRUE)

# summarize the partial correlations
summ &lt;- summary(fit)

# plot summary
plt_summ &lt;- plot(summary(fit))

# select graph
E &lt;- select(fit)

# plot the selected graph
plt_E &lt;- plot(select(fit))



</code></pre>

<hr>
<h2 id='explore'>GGM: Exploratory Hypothesis Testing</h2><span id='topic+explore'></span>

<h3>Description</h3>

<p>Learn the conditional (in)dependence structure with the Bayes factor using the matrix-F
prior distribution (Mulder and Pericchi 2018). These methods were introduced in
Williams and Mulder (2019). The graph is selected with <code><a href="#topic+select.explore">select.explore</a></code> and
then plotted with <code><a href="#topic+plot.select">plot.select</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explore(
  Y,
  formula = NULL,
  type = "continuous",
  mixed_type = NULL,
  analytic = FALSE,
  prior_sd = 0.5,
  iter = 5000,
  progress = TRUE,
  impute = FALSE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explore_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="explore_+3A_formula">formula</code></td>
<td>
<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code>. This allows for including
control variables in the model (i.e., <code>~ gender</code>).</p>
</td></tr>
<tr><td><code id="explore_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <code>Y</code> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>mixed</code> (semi-parametric copula). See the note for further details.</p>
</td></tr>
<tr><td><code id="explore_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector. An indicator of length p for which varibles should be treated as ranks.
(1 for rank and 0 to assume normality). The default is to treat all integer variables as ranks
when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="explore_+3A_analytic">analytic</code></td>
<td>
<p>Logical. Should the analytic solution be computed (default is <code>FALSE</code>)?
(currently not implemented)</p>
</td></tr>
<tr><td><code id="explore_+3A_prior_sd">prior_sd</code></td>
<td>
<p>Scale of the prior distribution, approximately the standard deviation
of a beta distribution (defaults to 0.5).</p>
</td></tr>
<tr><td><code id="explore_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="explore_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="explore_+3A_impute">impute</code></td>
<td>
<p>Logicial. Should the missing values (<code>NA</code>)
be imputed during model fitting (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="explore_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed.</p>
</td></tr>
<tr><td><code id="explore_+3A_...">...</code></td>
<td>
<p>Currently ignored (leave empty).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Controlling for Variables</strong>:
</p>
<p>When controlling for variables, it is assumed that <code>Y</code> includes <em>only</em>
the nodes in the GGM and the control variables. Internally, <code>only</code> the predictors
that are included in <code>formula</code> are removed from <code>Y</code>. This is not behavior of, say,
<code><a href="stats.html#topic+lm">lm</a></code>, but was adopted to ensure  users do not have to write out each variable that
should be included in the GGM. An example is provided below.
</p>
<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables. This is based on the ranked likelihood which requires sampling
the ranks for each variable (i.e., the data is not merely transformed to ranks). This is computationally
expensive when there are many levels. For example, with continuous data, there are as many ranks
as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise. This is accomplished by specifying an indicator
vector of length <em>p</em>. A one indicates to use the ranks, whereas a zero indicates to &quot;ignore&quot;
that variable. By default all integer variables are handled as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>

<p><strong>Imputing Missing Values</strong>:
</p>
<p>Missing values are imputed with the approach described in Hoff (2009).
The basic idea is to impute the missing values with the respective posterior pedictive distribution,
given the observed data, as the model is being estimated. Note that the default is <code>TRUE</code>,
but this ignored when there are no missing values. If set to <code>FALSE</code>, and there are missing
values, list-wise deletion is performed with <code>na.omit</code>.
</p>


<h3>Value</h3>

<p>The returned object of class <code>explore</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>pcor_mat</code> partial correltion matrix (posterior mean).
</p>
</li>
<li> <p><code>post_samp</code> an object containing the posterior samples.
</p>
</li></ul>



<h3>Note</h3>

<p><strong>Posterior Uncertainty</strong>:
</p>
<p>A key feature of <b>BGGM</b> is that there is a posterior distribution for each partial correlation.
This readily allows for visiualizing uncertainty in the estimates. This feature works
with all data types and is accomplished by plotting the summary of the <code>explore</code> object
(i.e., <code>plot(summary(fit))</code>). Note that in contrast to <code>estimate</code> (credible intervals),
the posterior standard deviation is plotted for <code>explore</code> objects.
</p>
<p><strong>&quot;Default&quot; Prior</strong>:
</p>
<p>In Bayesian statistics, a default Bayes factor needs to have several properties. I refer
interested users to section 2.2 in Dablander et al. (2020). In
Williams and Mulder (2019), some of these propteries were investigated including
model selection consistency. That said, we would not consider this a &quot;default&quot; (or &quot;automatic&quot;)
Bayes factor and thus we encourage users to perform sensitivity analyses by varying
the scale of the prior distribution.
</p>
<p>Furthermore, it is important to note there is no &quot;correct&quot; prior and, also, there is no need
to entertain the possibility of a &quot;true&quot; model. Rather, the Bayes factor can be interpreted as
which hypothesis best (<strong>relative</strong> to each other) predicts the observed data
(Section 3.2 in Kass and Raftery 1995).
</p>
<p><strong>Interpretation of Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>See <code><a href="#topic+BGGM-package">BGGM-package</a></code> for details about interpreting GGMs based on latent data
(i.e, all data types besides <code>"continuous"</code>)
</p>


<h3>References</h3>

<p>Dablander F, Bergh Dvd, Ly A, Wagenmakers E (2020).
&ldquo;Default Bayes Factors for Testing the (In) equality of Several Population Variances.&rdquo;
<em>arXiv preprint arXiv:2003.06278</em>.<br /><br /> Hoff PD (2009).
<em>A first course in Bayesian statistical methods</em>, volume 580.
Springer.<br /><br /> Kass RE, Raftery AE (1995).
&ldquo;Bayes Factors.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>90</b>(430), 773&ndash;795.<br /><br /> Mulder J, Pericchi L (2018).
&ldquo;The Matrix-F Prior for Estimating and Testing Covariance Matrices.&rdquo;
<em>Bayesian Analysis</em>, 1&ndash;22.
ISSN 19316690, <a href="https://doi.org/10.1214/17-BA1092">doi:10.1214/17-BA1092</a>.<br /><br /> Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

###########################
### example 1:  binary ####
###########################
Y &lt;- women_math[1:500,]

# fit model
fit &lt;- explore(Y, type = "binary",
                iter = 250,
                progress = FALSE)

# summarize the partial correlations
summ &lt;- summary(fit)

# plot the summary
plt_summ &lt;- plot(summary(fit))

# select the graph
E &lt;- select(fit)

# plot the selected graph
plt_E &lt;- plot(E)

plt_E$plt_alt

</code></pre>

<hr>
<h2 id='fisher_r_to_z'>Fisher Z Transformation</h2><span id='topic+fisher_r_to_z'></span>

<h3>Description</h3>

<p>Tranform correlations to Fisher's Z
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisher_r_to_z(r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fisher_r_to_z_+3A_r">r</code></td>
<td>
<p>correlation (can be a vector)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fisher Z transformed correlation(s)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fisher_r_to_z(0.5)
</code></pre>

<hr>
<h2 id='fisher_z_to_r'>Fisher Z Back Transformation</h2><span id='topic+fisher_z_to_r'></span>

<h3>Description</h3>

<p>Back tranform Fisher's Z to correlations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisher_z_to_r(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fisher_z_to_r_+3A_z">z</code></td>
<td>
<p>Fisher Z</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Correlation (s) (backtransformed)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fisher_z_to_r(0.5)
</code></pre>

<hr>
<h2 id='gen_net'>Simulate a Partial Correlation Matrix</h2><span id='topic+gen_net'></span>

<h3>Description</h3>

<p>Simulate a Partial Correlation Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_net(p = 20, edge_prob = 0.3, lb = 0.05, ub = 0.3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_net_+3A_p">p</code></td>
<td>
<p>number of variables (nodes)</p>
</td></tr>
<tr><td><code id="gen_net_+3A_edge_prob">edge_prob</code></td>
<td>
<p>connectivity</p>
</td></tr>
<tr><td><code id="gen_net_+3A_lb">lb</code></td>
<td>
<p>lower bound for the partial correlations</p>
</td></tr>
<tr><td><code id="gen_net_+3A_ub">ub</code></td>
<td>
<p>upper bound for the partial correlations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>

<ul>
<li><p><strong>pcor</strong>: Partial correlation matrix, encoding
the conditional (in)dependence structure.
</p>
</li>
<li><p><strong>cors</strong>: Correlation matrix.
</p>
</li>
<li><p><strong>adj</strong>: Adjacency matrix.
</p>
</li>
<li><p><strong>trys</strong>: Number of attempts to obtain a
positive definite matrix.
</p>
</li></ul>



<h3>Note</h3>

<p>The function checks for a valid matrix (positive definite),
but sometimes this will still fail. For example, for
larger <code>p</code>, to have large partial correlations this
requires a sparse GGM
(accomplished by setting <code>edge_prob</code>
to a small value).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
true_net &lt;- gen_net(p = 10)
</code></pre>

<hr>
<h2 id='gen_ordinal'>Generate Ordinal and Binary data</h2><span id='topic+gen_ordinal'></span>

<h3>Description</h3>

<p>Generate Multivariate Ordinal and Binary data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_ordinal(n, p, levels = 2, cor_mat, empirical = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_ordinal_+3A_n">n</code></td>
<td>
<p>Number of observations (<em>n</em>).</p>
</td></tr>
<tr><td><code id="gen_ordinal_+3A_p">p</code></td>
<td>
<p>Number of variables  (<em>p</em>).</p>
</td></tr>
<tr><td><code id="gen_ordinal_+3A_levels">levels</code></td>
<td>
<p>Number of categories (defaults to 2; binary data).</p>
</td></tr>
<tr><td><code id="gen_ordinal_+3A_cor_mat">cor_mat</code></td>
<td>
<p>A <em>p</em> by <em>p</em> matrix including the true correlation structure.</p>
</td></tr>
<tr><td><code id="gen_ordinal_+3A_empirical">empirical</code></td>
<td>
<p>Logical. If true, <code>cor_mat</code> specifies  the empirical not
population covariance matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <em>n</em> by <em>p</em> data matrix.
</p>


<h3>Note</h3>

<p>In order to allow users to enjoy the functionality of <b>BGGM</b>, we had to make minor changes to the function <code>rmvord_naiv</code>
from the <code>R</code> package <b>orddata</b> (Leisch et al. 2010). All rights to, and credit for, the function <code>rmvord_naiv</code>
belong to the authors of that package.
</p>
<p>This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.
This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
A copy of the GNU General Public License is available online.
</p>


<h3>References</h3>

<p>Leisch F, Kaiser AWS, Hornik K (2010).
<em>orddata: Generation of Artificial Ordinal and Binary Data</em>.
R package version 0.1/r4, <a href="https://R-Forge.R-project.org/projects/orddata/">https://R-Forge.R-project.org/projects/orddata/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################################
######### example 1 ############
################################

main &lt;-  ptsd_cor1[1:5,1:5]
p &lt;- ncol(main)

pcors &lt;- -(cov2cor(solve(main)) -diag(p))
diag(pcors) &lt;- 1
pcors &lt;- ifelse(abs(pcors) &lt; 0.05, 0, pcors)

inv &lt;-  -pcors
diag(inv) &lt;- 1
cors &lt;- cov2cor( solve(inv))

# example data
Y &lt;- BGGM::gen_ordinal(n = 500, p = 5,
                       levels = 2,
                       cor_mat = cors,
                       empirical = FALSE)



################################
######### example 2 ############
################################
# empirical = TRUE

Y &lt;-  gen_ordinal(n = 500,
                  p = 16,
                  levels = 5,
                  cor_mat = ptsd_cor1,
                  empirical = TRUE)

</code></pre>

<hr>
<h2 id='ggm_compare_confirm'>GGM Compare: Confirmatory Hypothesis Testing</h2><span id='topic+ggm_compare_confirm'></span>

<h3>Description</h3>

<p>Confirmatory hypothesis testing for comparing GGMs. Hypotheses are expressed as equality
and/or ineqaulity contraints on the partial correlations of interest. Here the focus is <em>not</em>
on determining the graph (see <code><a href="#topic+explore">explore</a></code>) but testing specific hypotheses related to
the conditional (in)dependence structure. These methods were introduced in
Williams and Mulder (2019) and in Williams et al. (2020)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggm_compare_confirm(
  ...,
  hypothesis,
  formula = NULL,
  type = "continuous",
  mixed_type = NULL,
  prior_sd = 0.5,
  iter = 25000,
  impute = TRUE,
  progress = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggm_compare_confirm_+3A_...">...</code></td>
<td>
<p>At least two matrices (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (nodes).</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_hypothesis">hypothesis</code></td>
<td>
<p>Character string. The hypothesis (or hypotheses) to be tested. See notes for futher details.</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_formula">formula</code></td>
<td>
<p>an object of class <code><a href="stats.html#topic+formula">formula</a></code>. This allows for including
control variables in the model (i.e., <code>~ gender</code>).</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <code>Y</code> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>mixed</code>. Note that mixed can be used for data with only
ordinal variables. See the note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_mixed_type">mixed_type</code></td>
<td>
<p>numeric vector. An indicator of length p for which varibles should be treated as ranks.
(1 for rank and 0 to assume normality). The default is currently (dev version) to treat all integer variables
as ranks when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_prior_sd">prior_sd</code></td>
<td>
<p>Numeric. The scale of the prior distribution (centered at zero),
in reference to a beta distribtuion (defaults to 0.5).</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 25,000).</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_impute">impute</code></td>
<td>
<p>Logicial. Should the missing values (<code>NA</code>)
be imputed during model fitting (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="ggm_compare_confirm_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hypotheses can be written either with the respective column names or numbers.
For example, <code>g1_1--2</code> denotes the relation between the variables in column 1 and 2 for group 1.
The <code>g1_</code> is required and the only difference from <code><a href="#topic+confirm">confirm</a></code> (one group).
Note that these must correspond to the upper triangular elements of the correlation
matrix. This is accomplished by ensuring that the first number is smaller than the second number.
This also applies when using column names (i.e,, in reference to the column number).
</p>
<p><strong>One Hypothesis</strong>:
</p>
<p>To test whether a relation in larger in one group, while both are expected
to be positive,  this can be written as
</p>

<ul>
<li>  <p><code>hyp &lt;-  c(g1_1--2 &gt; g2_1--2 &gt; 0)</code>
</p>
</li></ul>

<p>This is then compared to the complement.
</p>
<p><strong>More Than One Hypothesis</strong>:
</p>
<p>The above hypothesis can also be compared to, say, a null model by using &quot;;&quot;
to seperate the hypotheses, for example,
</p>

<ul>
<li>  <p><code>hyp &lt;-  c(g1_1--2 &gt; g2_1--2 &gt; 0; g1_1--2 = g2_1--2 = 0)</code>.
</p>
</li></ul>

<p>Any number of hypotheses can be compared this way.
</p>
<p><strong>Using &quot;&amp;&quot;</strong>
</p>
<p>It is also possible to include <code>&amp;</code>. This allows for testing one constraint <b>and</b>
another contraint as one hypothesis.
</p>

<ul>
<li> <p><code>hyp &lt;- c("g1_A1--A2 &gt; g2_A1--A2 &amp; g1_A1--A3 = g2_A1--A3")</code>
</p>
</li></ul>

<p>Of course, it is then possible to include additional hypotheses by separating them with &quot;;&quot;.
</p>
<p><strong>Testing Sums</strong>
</p>
<p>It might also be interesting to test the sum of partial correlations. For example, that the
sum of specific relations in one group is larger than the sum in another group.
</p>

<ul>
<li> <p><code>hyp &lt;- c("g1_A1--A2 + g1_A1--A3 &gt; g2_A1--A2 + g2_A1--A3;
                      g1_A1--A2 + g1_A1--A3 = g2_A1--A2 + g2_A1--A3")</code>
</p>
</li></ul>

<p><strong>Potential Delays</strong>:
</p>
<p>There is a chance for a potentially long delay from the time the progress bar finishes
to when the function is done running. This occurs when the hypotheses require further
sampling to be tested, for example, when grouping relations
<code>c("(g1_A1--A2, g2_A2--A3) &gt; (g2_A1--A2, g2_A2--A3)"</code>.
This is not an error.
</p>
<p><strong>Controlling for Variables</strong>:
</p>
<p>When controlling for variables, it is assumed that <code>Y</code> includes <em>only</em>
the nodes in the GGM and the control variables. Internally, <code>only</code> the predictors
that are included in <code>formula</code> are removed from <code>Y</code>. This is not behavior of, say,
<code><a href="stats.html#topic+lm">lm</a></code>, but was adopted to ensure  users do not have to write out each variable that
should be included in the GGM. An example is provided below.
</p>
<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables (Hoff 2007). This is based on the
ranked likelihood which requires sampling the ranks for each variable (i.e., the data is not merely
transformed to ranks). This is computationally expensive when there are many levels. For example,
with continuous data, there are as many ranks as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise. This is accomplished by specifying an indicator
vector of length <em>p</em>. A one indicates to use the ranks, whereas a zero indicates to &quot;ignore&quot;
that variable. By default all integer variables are handled as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>

<p><strong>Imputing Missing Values</strong>:
</p>
<p>Missing values are imputed with the approach described in Hoff (2009).
The basic idea is to impute the missing values with the respective posterior pedictive distribution,
given the observed data, as the model is being estimated. Note that the default is <code>TRUE</code>,
but this ignored when there are no missing values. If set to <code>FALSE</code>, and there are missing
values, list-wise deletion is performed with <code>na.omit</code>.
</p>


<h3>Value</h3>

<p>The returned object of class <code>confirm</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>out_hyp_prob</code> Posterior hypothesis probabilities.
</p>
</li>
<li> <p><code>info</code> An object of class <code>BF</code> from the R package <strong>BFpack</strong>
(Mulder et al. 2019)
</p>
</li></ul>



<h3>Note</h3>

<p><strong>&quot;Default&quot; Prior</strong>:
</p>
<p>In Bayesian statistics, a default Bayes factor needs to have several properties. I refer
interested users to section 2.2 in Dablander et al. (2020). In
Williams and Mulder (2019), some of these propteries were investigated (e.g.,
model selection consistency). That said, we would not consider this a &quot;default&quot; or &quot;automatic&quot;
Bayes factor and thus we encourage users to perform sensitivity analyses by varying the scale of
the prior distribution (<code>prior_sd</code>).
</p>
<p>Furthermore, it is important to note there is no &quot;correct&quot; prior and, also, there is no need
to entertain the possibility of a &quot;true&quot; model. Rather, the Bayes factor can be interpreted as
which hypothesis best (relative to each other) predicts the observed data
(Section 3.2 in Kass and Raftery 1995).
</p>
<p><strong>Interpretation of Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>See <code><a href="#topic+BGGM-package">BGGM-package</a></code> for details about interpreting GGMs based on latent data
(i.e, all data types besides <code>"continuous"</code>)
</p>


<h3>References</h3>

<p>Dablander F, Bergh Dvd, Ly A, Wagenmakers E (2020).
&ldquo;Default Bayes Factors for Testing the (In) equality of Several Population Variances.&rdquo;
<em>arXiv preprint arXiv:2003.06278</em>.<br /><br /> Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.<br /><br /> Hoff PD (2009).
<em>A first course in Bayesian statistical methods</em>, volume 580.
Springer.<br /><br /> Kass RE, Raftery AE (1995).
&ldquo;Bayes Factors.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>90</b>(430), 773&ndash;795.<br /><br /> Mulder J, Gu X, Olsson-Collentine A, Tomarken A, Böing-Messing F, Hoijtink H, Meijerink M, Williams DR, Menke J, Fox J, others (2019).
&ldquo;BFpack: Flexible Bayes Factor Testing of Scientific Theories in R.&rdquo;
<em>arXiv preprint arXiv:1911.07728</em>.<br /><br /> Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.<br /><br /> Williams DR, Rast P, Pericchi LR, Mulder J (2020).
&ldquo;Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection.&rdquo;
<em>Psychological Methods</em>.
<a href="https://doi.org/10.1037/met0000254">doi:10.1037/met0000254</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi

###############################
#### example 1: continuous ####
###############################

# males
Ymale   &lt;- subset(Y, gender == 1,
                  select = -c(education,
                              gender))[,1:5]


# females
Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(education,
                                 gender))[,1:5]

 # exhaustive
 hypothesis &lt;- c("g1_A1--A2 &gt;  g2_A1--A2;
                  g1_A1--A2 &lt;  g2_A1--A2;
                  g1_A1--A2 =  g2_A1--A2")

# test hyp
test &lt;- ggm_compare_confirm(Ymale,  Yfemale,
                            hypothesis = hypothesis,
                            iter = 250,
                            progress = FALSE)

# print (evidence not strong)
test

#########################################
#### example 2: sensitivity to prior ####
#########################################
# continued from example 1

# decrease prior SD
test &lt;- ggm_compare_confirm(Ymale,
                            Yfemale,
                            prior_sd = 0.1,
                            hypothesis = hypothesis,
                            iter = 250,
                            progress = FALSE)

# print
test

# indecrease prior SD
test &lt;- ggm_compare_confirm(Ymale,
                            Yfemale,
                            prior_sd = 0.28,
                            hypothesis = hypothesis,
                            iter = 250,
                            progress = FALSE)

# print
test

################################
#### example 3: mixed data #####
################################

hypothesis &lt;- c("g1_A1--A2 &gt;  g2_A1--A2;
                 g1_A1--A2 &lt;  g2_A1--A2;
                 g1_A1--A2 =  g2_A1--A2")

# test (1000 for example)
test &lt;- ggm_compare_confirm(Ymale,
                            Yfemale,
                            type = "mixed",
                            hypothesis = hypothesis,
                            iter = 250,
                            progress = FALSE)

# print
test

##############################
##### example 4: control #####
##############################
# control for education

# data
Y &lt;- bfi

# males
Ymale   &lt;- subset(Y, gender == 1,
                  select = -c(gender))[,c(1:5, 26)]

# females
Yfemale &lt;- subset(Y, gender == 2,
                  select = -c(gender))[,c(1:5, 26)]

# test
test &lt;- ggm_compare_confirm(Ymale,
                             Yfemale,
                             formula = ~ education,
                             hypothesis = hypothesis,
                             iter = 250,
                             progress = FALSE)
# print
test


#####################################
##### example 5: many relations #####
#####################################

# data
Y &lt;- bfi

hypothesis &lt;- c("g1_A1--A2 &gt; g2_A1--A2 &amp; g1_A1--A3 = g2_A1--A3;
                 g1_A1--A2 = g2_A1--A2 &amp; g1_A1--A3 = g2_A1--A3;
                 g1_A1--A2 = g2_A1--A2 = g1_A1--A3 = g2_A1--A3")

Ymale   &lt;- subset(Y, gender == 1,
                  select = -c(education,
                              gender))[,1:5]


# females
Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(education,
                                 gender))[,1:5]

test &lt;- ggm_compare_confirm(Ymale,
                            Yfemale,
                             hypothesis = hypothesis,
                             iter = 250,
                             progress = FALSE)

# print
test

</code></pre>

<hr>
<h2 id='ggm_compare_estimate'>GGM Compare: Estimate</h2><span id='topic+ggm_compare_estimate'></span>

<h3>Description</h3>

<p>Compare partial correlations that are estimated from any number of groups. This method works for
continuous, binary, ordinal, and mixed data (a combination of categorical and continuous variables).
The approach (i.e., a difference between posterior distributions) was
described in  Williams (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggm_compare_estimate(
  ...,
  formula = NULL,
  type = "continuous",
  mixed_type = NULL,
  analytic = FALSE,
  prior_sd = sqrt(1/3),
  iter = 5000,
  impute = TRUE,
  progress = TRUE,
  seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggm_compare_estimate_+3A_...">...</code></td>
<td>
<p>Matrices (or data frames) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).
Requires at least two.</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_formula">formula</code></td>
<td>
<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code>. This allows for including
control variables in the model (i.e., <code>~ gender</code>). See the note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <strong>Y</strong> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>continuous</code>. See the note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector. An indicator of length <em>p</em> for which varibles should be treated as ranks.
(1 for rank and 0 to use the 'empirical' or observed distribution). The default is currently to treat all integer variables
as ranks when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_analytic">analytic</code></td>
<td>
<p>Logical. Should the analytic solution be computed (default is <code>FALSE</code>)? This is only available
for continous data. Note that if <code>type = "mixed"</code> and <code>analytic = TRUE</code>, the data will
automatically be treated as continuous.</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_prior_sd">prior_sd</code></td>
<td>
<p>The scale of the prior distribution (centered at zero), in reference to a beta distribtuion (defaults to sqrt(1/3)). See note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_impute">impute</code></td>
<td>
<p>Logicial. Should the missing values (<code>NA</code>)
be imputed during model fitting (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="ggm_compare_estimate_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used to compare the partial correlations for any number of groups.
This is accomplished with pairwise comparisons for each relation. In the case of three groups,
for example, group 1 and group 2 are compared, then group 1 and group 3 are compared, and then
group 2 and group 3 are compared. There is a full distibution for each difference that can be
summarized (i.e., <code><a href="#topic+summary.ggm_compare_estimate">summary.ggm_compare_estimate</a></code>) and then visualized
(i.e., <code><a href="#topic+plot.summary.ggm_compare_estimate">plot.summary.ggm_compare_estimate</a></code>). The graph of difference is selected with
<code><a href="#topic+select.ggm_compare_estimate">select.ggm_compare_estimate</a></code>).
</p>
<p><strong>Controlling for Variables</strong>:
</p>
<p>When controlling for variables, it is assumed that <code>Y</code> includes <em>only</em>
the nodes in the GGM and the control variables. Internally, <code>only</code> the predictors
that are included in <code>formula</code> are removed from <code>Y</code>. This is not behavior of, say,
<code><a href="stats.html#topic+lm">lm</a></code>, but was adopted to ensure  users do not have to write out each variable that
should be included in the GGM. An example is provided below.
</p>
<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables. This is based on the ranked likelihood which requires sampling
the ranks for each variable (i.e., the data is not merely transformed to ranks). This is computationally
expensive when there are many levels. For example, with continuous data, there are as many ranks
as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise. This is accomplished by specifying an indicator
vector of length <em>p</em>. A one indicates to use the ranks, whereas a zero indicates to &quot;ignore&quot;
that variable. By default all integer variables are handled as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>

<p><strong>Imputing Missing Values</strong>:
</p>
<p>Missing values are imputed with the approach described in Hoff (2009).
The basic idea is to impute the missing values with the respective posterior pedictive distribution,
given the observed data, as the model is being estimated. Note that the default is <code>TRUE</code>,
but this ignored when there are no missing values. If set to <code>FALSE</code>, and there are missing
values, list-wise deletion is performed with <code>na.omit</code>.
</p>


<h3>Value</h3>

<p>A list of class <code>ggm_compare_estimate</code> containing:
</p>

<ul>
<li> <p><code>pcor_diffs</code> partial correlation differences (posterior distribution)
</p>
</li>
<li> <p><code>p</code> number of variable
</p>
</li>
<li> <p><code>info</code> list containing information about each group (e.g., sample size, etc.)
</p>
</li>
<li> <p><code>iter</code> number of posterior samples
</p>
</li>
<li> <p><code>call</code> <code>match.call</code>
</p>
</li></ul>



<h3>Note</h3>

<p><strong>Mixed Data</strong>:
</p>
<p>The mixed data approach was introduced  in Hoff (2007)
(our paper describing an extension to Bayesian hypothesis testing if forthcoming).
This is a semi-paramateric copula model based on the ranked likelihood. This is computationally
expensive when treating continuous data as ranks. The current default is to treat only integer data as ranks.
This should of course be adjusted for continous data that is skewed. This can be accomplished with the
argument <code>mixed_type</code>. A <code>1</code> in the numeric vector of length <em>p</em>indicates to treat that
respective node as a rank (corresponding to the column number) and a zero indicates to use the observed
(or &quot;emprical&quot;) data.
</p>
<p>It is also important to note that <code>type = "mixed"</code> is not restricted to mixed data (containing a combination of
categorical and continuous): all the nodes can be ordinal or continuous (but again this will take some time).
</p>
<p><strong>Interpretation of Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>See <code><a href="#topic+BGGM-package">BGGM-package</a></code> for details about interpreting GGMs based on latent data
(i.e, all data types besides <code>"continuous"</code>)
</p>
<p><strong>Additional GGM Compare Methods</strong>
</p>
<p>Bayesian hypothesis testing is implemented in <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> and
<code><a href="#topic+ggm_compare_confirm">ggm_compare_confirm</a></code> (Williams and Mulder 2019). The latter allows for confirmatory
hypothesis testing.  An approach based on a posterior predictive check is implemented in <code><a href="#topic+ggm_compare_ppc">ggm_compare_ppc</a></code>
(Williams et al. 2020). This provides  a 'global' test for comparing the entire GGM and a 'nodewise'
test for comparing each variable in the network Williams (2018).
</p>


<h3>References</h3>

<p>Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.<br /><br /> Hoff PD (2009).
<em>A first course in Bayesian statistical methods</em>, volume 580.
Springer.<br /><br /> Williams DR (2018).
&ldquo;Bayesian Estimation for Gaussian Graphical Models: Structure Learning, Predictability, and Network Comparisons.&rdquo;
<em>arXiv</em>.
<a href="https://doi.org/10.31234/OSF.IO/X8DPR">doi:10.31234/OSF.IO/X8DPR</a>.<br /><br /> Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.<br /><br /> Williams DR, Rast P, Pericchi LR, Mulder J (2020).
&ldquo;Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection.&rdquo;
<em>Psychological Methods</em>.
<a href="https://doi.org/10.1037/met0000254">doi:10.1037/met0000254</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data: Remove missings for "ordinal"
Y &lt;- bfi[complete.cases(bfi),]

# males and females
Ymale &lt;- subset(Y, gender == 1,
                   select = -c(gender,
                               education))[,1:10]

Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(gender,
                                 education))[,1:10]

# fit model
fit &lt;- ggm_compare_estimate(Ymale,  Yfemale,
                           type = "ordinal",
                           iter = 250,
                           progress = FALSE)

###########################
### example 2: analytic ###
###########################
# only continuous

# fit model
fit &lt;- ggm_compare_estimate(Ymale, Yfemale,
                            analytic = TRUE)

# summary
summ &lt;- summary(fit)

# plot summary
plt_summ &lt;- plot(summary(fit))

# select
E &lt;- select(fit)

# plot select
plt_E &lt;- plot(select(fit))



</code></pre>

<hr>
<h2 id='ggm_compare_explore'>GGM Compare: Exploratory Hypothesis Testing</h2><span id='topic+ggm_compare_explore'></span>

<h3>Description</h3>

<p>Compare Gaussian graphical models with exploratory hypothesis testing using the matrix-F prior
distribution (Mulder and Pericchi 2018). A test for each partial correlation in the model for any number
of groups. This provides evidence for the null hypothesis of no difference and the alternative hypothesis
of difference. With more than two groups, the test is for <em>all</em> groups simultaneously (i.e., the relation
is the same or different in all groups). This method was introduced in Williams et al. (2020).
For confirmatory hypothesis testing see <code>confirm_groups</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggm_compare_explore(
  ...,
  formula = NULL,
  type = "continuous",
  mixed_type = NULL,
  analytic = FALSE,
  prior_sd = sqrt(1/3),
  iter = 5000,
  progress = TRUE,
  seed = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggm_compare_explore_+3A_...">...</code></td>
<td>
<p>At least two matrices (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_formula">formula</code></td>
<td>
<p>An object of class <code><a href="stats.html#topic+formula">formula</a></code>. This allows for including
control variables in the model (i.e., <code>~ gender</code>).</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <code>Y</code> ? The options include <code>continuous</code>,
<code>binary</code>, or <code>ordinal</code>. See the note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector. An indicator of length p for which varibles should be treated as ranks.
(1 for rank and 0 to assume normality). The default is currently (dev version) to treat all integer variables
as ranks when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_analytic">analytic</code></td>
<td>
<p>logical. Should the analytic solution be computed (default is <code>FALSE</code>) ? See note for details.</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_prior_sd">prior_sd</code></td>
<td>
<p>Numeric. The scale of the prior distribution (centered at zero), in reference to a beta distribtuion.
The 'default' is sqrt(1/3) for a flat prior. See note for further details.</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_iter">iter</code></td>
<td>
<p>number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="ggm_compare_explore_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Controlling for Variables</strong>:
</p>
<p>When controlling for variables, it is assumed that <code>Y</code> includes <em>only</em>
the nodes in the GGM and the control variables. Internally, <code>only</code> the predictors
that are included in <code>formula</code> are removed from <code>Y</code>. This is not behavior of, say,
<code><a href="stats.html#topic+lm">lm</a></code>, but was adopted to ensure  users do not have to write out each variable that
should be included in the GGM. An example is provided below.
</p>
<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables. This is based on the ranked likelihood which requires sampling
the ranks for each variable (i.e., the data is not merely transformed to ranks). This is computationally
expensive when there are many levels. For example, with continuous data, there are as many ranks
as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise. This is accomplished by specifying an indicator
vector of length <em>p</em>. A one indicates to use the ranks, whereas a zero indicates to &quot;ignore&quot;
that variable. By default all integer variables are handled as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> below sqrt(1/3) (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>



<h3>Value</h3>

<p>The returned object of class <code>ggm_compare_explore</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>BF_01</code> A <em>p</em> by <em>p</em> matrix including
the Bayes factor for the null hypothesis.
</p>
</li>
<li> <p><code>pcor_diff</code> A <em>p</em> by <em>p</em> matrix including
the difference in partial correlations (only for two groups).
</p>
</li>
<li> <p><code>samp</code> A list containing the fitted models (of class <code>explore</code>) for each group.
</p>
</li></ul>



<h3>Note</h3>

<p><strong>&quot;Default&quot; Prior</strong>:
</p>
<p>In Bayesian statistics, a default Bayes factor needs to have several properties. I refer
interested users to section 2.2 in Dablander et al. (2020). In
Williams and Mulder (2019), some of these propteries were investigated, such
model selection consistency. That said, we would not consider this a &quot;default&quot; Bayes factor and
thus we encourage users to perform sensitivity analyses by varying the scale of the prior
distribution.
</p>
<p>Furthermore, it is important to note there is no &quot;correct&quot; prior and, also, there is no need
to entertain the possibility of a &quot;true&quot; model. Rather, the Bayes factor can be interpreted as
which hypothesis best (relative to each other) predicts the observed data
(Section 3.2 in Kass and Raftery 1995).
</p>
<p><strong>Interpretation of Conditional (In)dependence Models for Latent Data</strong>:
</p>
<p>See <code><a href="#topic+BGGM-package">BGGM-package</a></code> for details about interpreting GGMs based on latent data
(i.e, all data types besides <code>"continuous"</code>)
</p>


<h3>References</h3>

<p>Dablander F, Bergh Dvd, Ly A, Wagenmakers E (2020).
&ldquo;Default Bayes Factors for Testing the (In) equality of Several Population Variances.&rdquo;
<em>arXiv preprint arXiv:2003.06278</em>.<br /><br /> Kass RE, Raftery AE (1995).
&ldquo;Bayes Factors.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>90</b>(430), 773&ndash;795.<br /><br /> Mulder J, Pericchi L (2018).
&ldquo;The Matrix-F Prior for Estimating and Testing Covariance Matrices.&rdquo;
<em>Bayesian Analysis</em>, 1&ndash;22.
ISSN 19316690, <a href="https://doi.org/10.1214/17-BA1092">doi:10.1214/17-BA1092</a>.<br /><br /> Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.<br /><br /> Williams DR, Rast P, Pericchi LR, Mulder J (2020).
&ldquo;Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection.&rdquo;
<em>Psychological Methods</em>.
<a href="https://doi.org/10.1037/met0000254">doi:10.1037/met0000254</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi[complete.cases(bfi),]

# males and females
Ymale &lt;- subset(Y, gender == 1,
                   select = -c(gender,
                               education))[,1:10]

Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(gender,
                                 education))[,1:10]

##########################
### example 1: ordinal ###
##########################

# fit model
fit &lt;- ggm_compare_explore(Ymale,  Yfemale,
                           type = "ordinal",
                           iter = 250,
                           progress = FALSE)
# summary
summ &lt;- summary(fit)

# edge set
E &lt;- select(fit)


</code></pre>

<hr>
<h2 id='ggm_compare_ppc'>GGM Compare: Posterior Predictive Check</h2><span id='topic+ggm_compare_ppc'></span>

<h3>Description</h3>

<p>Compare GGMs with a posterior predicitve check (Gelman et al. 1996).
This method was introduced in Williams et al. (2020). Currently,
there is a <code>global</code> (the entire GGM) and a <code>nodewise</code> test. The default
is to compare GGMs with respect to the posterior predictive distribution of Kullback
Leibler divergence and the sum of squared errors. It is also possible to compare the
GGMs with a user defined test-statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggm_compare_ppc(
  ...,
  test = "global",
  iter = 5000,
  FUN = NULL,
  custom_obs = NULL,
  loss = TRUE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggm_compare_ppc_+3A_...">...</code></td>
<td>
<p>At least two matrices (or data frames) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="ggm_compare_ppc_+3A_test">test</code></td>
<td>
<p>Which test should be performed (defaults to <code>"global"</code>) ? The options include
<code>global</code> and <code>nodewise</code>.</p>
</td></tr>
<tr><td><code id="ggm_compare_ppc_+3A_iter">iter</code></td>
<td>
<p>Number of replicated datasets used to construct the predictivie distribution
(defaults to 5000).</p>
</td></tr>
<tr><td><code id="ggm_compare_ppc_+3A_fun">FUN</code></td>
<td>
<p>An optional function for comparing GGMs that returns a number. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="ggm_compare_ppc_+3A_custom_obs">custom_obs</code></td>
<td>
<p>Number corresponding to the observed score for comparing the GGMs. This is
required if a function is provided in <code>FUN</code>. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="ggm_compare_ppc_+3A_loss">loss</code></td>
<td>
<p>Logical. If a function is provided, is the measure a &quot;loss function&quot;
(i.e., a large score is bad thing). This determines how the <em>p</em>-value
is computed. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="ggm_compare_ppc_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>FUN</code> argument allows for a user defined test-statisic (the measure used to compare the GGMs).
The function must include only two agruments, each of which corresponds to a dataset. For example,
<code>f &lt;- function(Yg1, Yg2)</code>, where each Y is dataset of dimensions <em>n</em> by <em>p</em>. The
groups are then compare within the function, returning a single number. An example is provided below.
</p>
<p>Further, when using a custom function care must be taken when specifying the argument <code>loss</code>.
We recommended to visualize the results with <code>plot</code> to ensure the <em>p</em>-value was computed
in the right direction.
</p>


<h3>Value</h3>

<p>The returned object of class <code>ggm_compare_ppc</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>
<p><code>test = "global"</code>
</p>

<ul>
<li> <p><code>ppp_jsd</code> posterior predictive <em>p</em>-values (JSD).
</p>
</li>
<li> <p><code>ppp_sse</code> posterior predictive <em>p</em>-values (SSE).
</p>
</li>
<li> <p><code>predictive_jsd</code> list containing the posterior predictive distributions (JSD).
</p>
</li>
<li> <p><code>predictive_sse</code> list containing the posterior predictive distributions (SSE).
</p>
</li>
<li> <p><code>obs_jsd</code> list containing the observed error (JSD).
</p>
</li>
<li> <p><code>obs_sse</code> list containing the observed error (SSE).
</p>
</li></ul>

<p><code>test = "nodewise"</code>
</p>

<ul>
<li> <p><code>ppp_jsd</code> posterior predictive <em>p</em>-values (JSD).
</p>
</li>
<li> <p><code>predictive_jsd</code> list containing the posterior predictive distributions (JSD).
</p>
</li>
<li> <p><code>obs_jsd</code> list containing the observed error (JSD).
</p>
</li></ul>

<p><code>FUN = f()</code>
</p>

<ul>
<li> <p><code>ppp_custom</code> posterior predictive <em>p</em>-values (custom).
</p>
</li>
<li> <p><code>predictive_custom</code> posterior predictive distributions (custom).
</p>
</li>
<li> <p><code>obs_custom</code> observed error (custom).
</p>
</li></ul>



<h3>Note</h3>

<p><strong>Interpretation</strong>:
</p>
<p>The primary test-statistic is symmetric KL-divergence that is termed Jensen-Shannon divergence (JSD).
This is in essence a likelihood ratio that provides the &quot;distance&quot; between two multivariate normal
distributions. The basic idea is to (1) compute the posterior predictive distribution, assuming group equality
(the null model). This provides the error that we would expect to see under the null model; (2) compute
JSD for the observed groups; and (3) compare the observed JSD to the posterior predictive distribution,
from which a posterior predictive <em>p</em>-value is computed.
</p>
<p>For the <code>global</code> check, the sum of squared error is also provided.
This is computed from the partial correlation matrices and it is analagous
to the strength test in van Borkulo et al. (2017). The <code>nodewise</code>
test compares the posterior predictive distribution for each node. This is based on the correspondence
between the inverse covariance matrix and multiple regresssion (Kwan 2014; Stephens 1998).
</p>
<p>If the null model is <code>not</code> rejected, note that this does <code>not</code> provide evidence for equality!
Further, if the null model is rejected, this means that the assumption of group equality is not tenable&ndash;the
groups are different.
</p>
<p><strong>Alternative Methods</strong>:
</p>
<p>There are several methods in <strong>BGGM</strong> for comparing groups. See
<code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code> (posterior differences for the
partial correlations), <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> (exploratory hypothesis testing),
and <code><a href="#topic+ggm_compare_confirm">ggm_compare_confirm</a></code> (confirmatory hypothesis testing).
</p>


<h3>References</h3>

<p>Gelman A, Meng X, Stern H (1996).
&ldquo;Posterior predictive assessment of model fitness via realized discrepancies.&rdquo;
<em>Statistica sinica</em>, 733&ndash;760.<br /><br /> Kwan CC (2014).
&ldquo;A regression-based interpretation of the inverse of the sample covariance matrix.&rdquo;
<em>Spreadsheets in Education</em>, <b>7</b>(1), 4613.<br /><br /> Stephens G (1998).
&ldquo;On the Inverse of the Covariance Matrix in Portfolio Analysis.&rdquo;
<em>The Journal of Finance</em>, <b>53</b>(5), 1821&ndash;1827.<br /><br /> Williams DR, Rast P, Pericchi LR, Mulder J (2020).
&ldquo;Comparing Gaussian graphical models with the posterior predictive distribution and Bayesian model selection.&rdquo;
<em>Psychological Methods</em>.
<a href="https://doi.org/10.1037/met0000254">doi:10.1037/met0000254</a>.<br /><br /> van Borkulo CD, Boschloo L, Kossakowski J, Tio P, Schoevers RA, Borsboom D, Waldorp LJ (2017).
&ldquo;Comparing network structures on three aspects: A permutation test.&rdquo;
<em>Manuscript submitted for publication</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi

#############################
######### global ############
#############################


# males
Ym &lt;- subset(Y, gender == 1,
             select = - c(gender, education))

# females

Yf &lt;- subset(Y, gender == 2,
             select = - c(gender, education))


global_test &lt;- ggm_compare_ppc(Ym, Yf,
                               iter = 250)

global_test


#############################
###### custom function ######
#############################
# example 1

# maximum difference van Borkulo et al. (2017)

f &lt;- function(Yg1, Yg2){

# remove NA
x &lt;- na.omit(Yg1)
y &lt;- na.omit(Yg2)

# nodes
p &lt;- ncol(Yg1)

# identity matrix
I_p &lt;- diag(p)

# partial correlations

pcor_1 &lt;- -(cov2cor(solve(cor(x))) - I_p)
pcor_2 &lt;- -(cov2cor(solve(cor(y))) - I_p)

# max difference
max(abs((pcor_1[upper.tri(I_p)] - pcor_2[upper.tri(I_p)])))

}

# observed difference
obs &lt;- f(Ym, Yf)

global_max &lt;- ggm_compare_ppc(Ym, Yf,
                              iter = 250,
                              FUN = f,
                              custom_obs = obs,
                              progress = FALSE)

global_max


# example 2
# Hamming distance (squared error for adjacency)

f &lt;- function(Yg1, Yg2){

# remove NA
x &lt;- na.omit(Yg1)
y &lt;- na.omit(Yg2)

# nodes
p &lt;- ncol(x)

# identity matrix
I_p &lt;- diag(p)

fit1 &lt;-  estimate(x, analytic = TRUE)
fit2 &lt;-  estimate(y, analytic = TRUE)

sel1 &lt;- select(fit1)
sel2 &lt;- select(fit2)

sum((sel1$adj[upper.tri(I_p)] - sel2$adj[upper.tri(I_p)])^2)

}

# observed difference
obs &lt;- f(Ym, Yf)

global_hd &lt;- ggm_compare_ppc(Ym, Yf,
                            iter = 250,
                            FUN = f,
                            custom_obs  = obs,
                            progress = FALSE)

global_hd


#############################
########  nodewise ##########
#############################

nodewise &lt;- ggm_compare_ppc(Ym, Yf, iter = 250,
                           test = "nodewise")

nodewise



</code></pre>

<hr>
<h2 id='gss'>Data: 1994 General Social Survey</h2><span id='topic+gss'></span>

<h3>Description</h3>

<p>A data frame containing 1002 rows and 7 variables measured on various scales,
including binary and ordered cateogrical (with varying numbers of categories).
There are also missing values in each variable
</p>

<ul>
<li> <p><code>Inc</code>  Income of the respondent in 1000s of dollars, binned into 21 ordered categories.
</p>
</li>
<li> <p><code>DEG</code>   Highest degree ever obtained (none, HS, Associates, Bachelors, or Graduate)
</p>
</li>
<li> <p><code>CHILD</code>  Number of children ever had.
</p>
</li>
<li> <p><code>PINC</code>  Financial status of respondent's parents when respondent was 16 (on a 5-point scale).
</p>
</li>
<li> <p><code>PDEG</code>  Maximum of mother's and father's highest degree
</p>
</li>
<li> <p><code>PCHILD</code>  Number of siblings of the respondent plus one
</p>
</li>
<li> <p><code>AGE</code> Age of the respondent in years.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data("gss")
</code></pre>


<h3>Format</h3>

<p>A data frame containing 1190 observations (n = 1190) and 6 variables (p = 6) measured on the binary scale
(Fowlkes et al. 1988). The variable descriptions were copied from
section 4, Hoff (2007)
</p>


<h3>References</h3>

<p>Fowlkes EB, Freeny AE, Landwehr JM (1988).
&ldquo;Evaluating logistic models for large contingency tables.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>83</b>(403), 611&ndash;622.<br /><br /> Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("gss")
</code></pre>

<hr>
<h2 id='ifit'>Data: ifit Intensive Longitudinal Data</h2><span id='topic+ifit'></span>

<h3>Description</h3>

<p>A data frame containing 8 variables and nearly 200 observations. There are
two subjects, each of which provided data every data for over 90 days. Six variables are from
the PANAS scale (positive and negative affect), the daily number of steps, and the subject id.
</p>

<ul>
<li> <p><code>id</code> Subject id
</p>
</li>
<li> <p><code>interested</code>
</p>
</li>
<li> <p><code>disinterested</code>
</p>
</li>
<li> <p><code>excited</code>
</p>
</li>
<li> <p><code>upset</code>
</p>
</li>
<li> <p><code>strong</code>
</p>
</li>
<li> <p><code>stressed</code>
</p>
</li>
<li> <p><code>steps</code> steps recorded by a fit bit
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data("ifit")
</code></pre>


<h3>Format</h3>

<p>A data frame containing 197 observations and 8 variables. The data have been used in
(O'Laughlin et al. 2020) and  (Williams et al. 2019)
</p>


<h3>References</h3>

<p>O'Laughlin KD, Liu S, Ferrer E (2020).
&ldquo;Use of Composites in Analysis of Individual Time Series: Implications for Person-Specific Dynamic Parameters.&rdquo;
<em>Multivariate Behavioral Research</em>, 1&ndash;18.<br /><br /> Williams DR, Liu S, Martin SR, Rast P (2019).
&ldquo;Bayesian Multivariate Mixed-Effects Location Scale Modeling of Longitudinal Relations among Affective Traits, States, and Physical Activity.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/4kfjp">doi:10.31234/osf.io/4kfjp</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ifit")
</code></pre>

<hr>
<h2 id='impute_data'>Obtain Imputed Datasets</h2><span id='topic+impute_data'></span>

<h3>Description</h3>

<p>Impute missing values, assuming a  multivariate normal distribution, with the posterior
predictive distribution. For binary, ordinal, and mixed (a combination of discrete and continuous)
data, the values are first imputed for the latent data and then converted to the original scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_data(
  Y,
  type = "continuous",
  lambda = NULL,
  mixed_type = NULL,
  iter = 1000,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_data_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="impute_data_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <code>Y</code> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>mixed</code>. Note that mixed can be used for data with only
ordinal variables. See the note for further details.</p>
</td></tr>
<tr><td><code id="impute_data_+3A_lambda">lambda</code></td>
<td>
<p>Numeric. A regularization parameter, which defaults to p + 2. A larger value results
in more shrinkage.</p>
</td></tr>
<tr><td><code id="impute_data_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector. An indicator of length <em>p</em> for which variables should be treated as ranks.
(1 for rank and 0 to assume the observed marginal distribution).
The default is currently to treat all integer variables as ranks when
<code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="impute_data_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 1000).</p>
</td></tr>
<tr><td><code id="impute_data_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Missing values are imputed with the approach described in Hoff (2009).
The basic idea is to impute the missing values with the respective posterior pedictive distribution,
given the observed data, as the model is being estimated. Note that the default is <code>TRUE</code>,
but this ignored when there are no missing values. If set to <code>FALSE</code>, and there are missing
values, list-wise deletion is performed with <code>na.omit</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>mvn_imputation</code>:
</p>

<ul>
<li> <p><code>imputed_datasets</code> An array including the imputed datasets.
</p>
</li></ul>



<h3>References</h3>

<p>Hoff PD (2009).
<em>A first course in Bayesian statistical methods</em>, volume 580.
Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# obs
n &lt;- 5000

# n missing
n_missing &lt;- 1000

# variables
p &lt;- 16

# data
Y &lt;- MASS::mvrnorm(n, rep(0, p), ptsd_cor1)

# for checking
Ymain &lt;- Y

# all possible indices
indices &lt;- which(matrix(0, n, p) == 0,
                 arr.ind = TRUE)

# random sample of 1000 missing values
na_indices &lt;- indices[sample(5:nrow(indices),
                             size = n_missing,
                             replace = FALSE),]

# fill with NA
Y[na_indices] &lt;- NA

# missing = 1
Y_miss &lt;- ifelse(is.na(Y), 1, 0)

# true values (to check)
true &lt;- unlist(sapply(1:p, function(x)
        Ymain[which(Y_miss[,x] == 1),x] ))

# impute
fit_missing &lt;- impute_data(Y, progress = FALSE, iter = 250)

# impute
fit_missing &lt;- impute_data(Y,
                           progress = TRUE,
                           iter = 250)


</code></pre>

<hr>
<h2 id='iri'>Data: Interpersonal Reactivity Index (IRI)</h2><span id='topic+iri'></span>

<h3>Description</h3>

<p>A dataset containing items from the Interpersonal Reactivity Index (IRI; an empathy measure). There are 28 variables  and
1973 observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("iri")
</code></pre>


<h3>Format</h3>

<p>A data frame with 28 variables and 1973 observations (5 point Likert scale)
</p>


<h3>Details</h3>


<ul>
<li> <p><code>1</code> I daydream and fantasize, with some regularity, about things that might happen to me.
</p>
</li>
<li> <p><code>2</code>  I often have tender, concerned feelings for people less fortunate than me.
</p>
</li>
<li> <p><code>3</code> I sometimes find it difficult to see things from the &quot;other guy's&quot; point of view.
</p>
</li>
<li> <p><code>4</code> Sometimes I don't feel very sorry for other people when they are having problems.
</p>
</li>
<li> <p><code>5</code>  I really get involved with the feelings of the characters in a novel.
</p>
</li>
<li> <p><code>6</code> In emergency situations, I feel apprehensive and ill-at-ease.
</p>
</li>
<li> <p><code>7</code>  I am usually objective when I watch a movie or play, and I don't often get completely caught up in it.
</p>
</li>
<li> <p><code>8</code> I try to look at everybody's side of a disagreement before I make a decision.
</p>
</li>
<li> <p><code>9</code>  When I see someone being taken advantage of, I feel kind of protective towards them.
</p>
</li>
<li> <p><code>10</code> I sometimes feel helpless when I am in the middle of a very emotional situation.
</p>
</li>
<li> <p><code>11</code>  I sometimes try to understand my friends better
by imagining how things look from their perspective
</p>
</li>
<li> <p><code>12</code> Becoming extremely involved in a good book or movie is somewhat rare for me.
</p>
</li>
<li> <p><code>13</code> When I see someone get hurt, I tend to remain calm.
</p>
</li>
<li> <p><code>14</code> Other people's misfortunes do not usually disturb me a great deal.
</p>
</li>
<li> <p><code>15</code>  If I'm sure I'm right about something, I don't waste much
time listening to other people's arguments.
</p>
</li>
<li> <p><code>16</code>  After seeing a play or movie, I have felt as though I were one of the characters.
</p>
</li>
<li> <p><code>17</code>  Being in a tense emotional situation scares me.
</p>
</li>
<li> <p><code>18</code>  When I see someone being treated unfairly,
I sometimes don't feel very much pity for them.
</p>
</li>
<li> <p><code>19</code> I am usually pretty effective in dealing with emergencies.
</p>
</li>
<li> <p><code>20</code> I am often quite touched by things that I see happen.
</p>
</li>
<li> <p><code>21</code> I believe that there are two sides to every question and try to look at them both.
</p>
</li>
<li> <p><code>22</code> I would describe myself as a pretty soft-hearted person.
</p>
</li>
<li> <p><code>23</code> When I watch a good movie, I can very easily put myself in
the place of a leading character
</p>
</li>
<li> <p><code>24</code>  I tend to lose control during emergencies.
</p>
</li>
<li> <p><code>25</code> When I'm upset at someone, I usually try to &quot;put myself in his shoes&quot; for a while.
</p>
</li>
<li> <p><code>26</code> When I am reading an interesting story or novel, I imagine how I would feel if the
events in the story were happening to me.
</p>
</li>
<li> <p><code>27</code>  When I see someone who badly needs help in an emergency, I go to pieces.
</p>
</li>
<li> <p><code>28</code> Before criticizing somebody, I try to imagine how I would feel if I were in their place.
</p>
</li>
<li> <p><code>gender</code> &quot;M&quot; (male) or &quot;F&quot; (female)
</p>
</li></ul>



<h3>Note</h3>

<p>There are four domains
</p>
<p>Fantasy: items 1, 5, 7, 12, 16, 23, 26
</p>
<p>Perspective taking: items 3, 8, 11, 15, 21, 25, 28
</p>
<p>Empathic concern: items 2, 4, 9, 14, 18, 20, 22
</p>
<p>Personal distress: items 6, 10, 13, 17, 19, 24, 27,
</p>


<h3>References</h3>

<p>Briganti, G., Kempenaers, C., Braun, S., Fried, E. I., &amp; Linkowski, P. (2018). Network analysis of
empathy items from the interpersonal reactivity index in 1973
young adults. Psychiatry research, 265, 87-92.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iri")

</code></pre>

<hr>
<h2 id='map'>Maximum A Posteriori Precision Matrix</h2><span id='topic+map'></span>

<h3>Description</h3>

<p>Maximum A Posteriori Precision Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>map(Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="map_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>map</code>, including the precision matrix,
partial correlation matrix, and regression parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- BGGM::bfi[, 1:5]

# map
map &lt;- map(Y)
map
</code></pre>

<hr>
<h2 id='pcor_mat'>Extract the Partial Correlation Matrix</h2><span id='topic+pcor_mat'></span>

<h3>Description</h3>

<p>Extract the partial correlation matrix (posterior mean)
from <code><a href="#topic+estimate">estimate</a></code>, <code><a href="#topic+explore">explore</a></code>, <code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code>,
and <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> objects. It is also possible to extract the
partial correlation differences for <code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code> and
<code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcor_mat(object, difference = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcor_mat_+3A_object">object</code></td>
<td>
<p>A model estimated with <strong>BGGM</strong>. All classes are supported, assuming
there is matrix to be extracted.</p>
</td></tr>
<tr><td><code id="pcor_mat_+3A_difference">difference</code></td>
<td>
<p>Logical. Should the difference be returned (defaults to <code>FALSE</code>) ? Note
that this assumes there is a difference (e.g., an object of class <code>ggm_compare_estimate</code>)
and ignored otherwise.</p>
</td></tr>
<tr><td><code id="pcor_mat_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimated partial correlation matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- ptsd[,1:5] + 1

# ordinal
fit &lt;- estimate(Y, type = "ordinal",
                iter = 250,
                progress = FALSE)

pcor_mat(fit)

</code></pre>

<hr>
<h2 id='pcor_sum'>Partial Correlation Sum</h2><span id='topic+pcor_sum'></span>

<h3>Description</h3>

<p>Compute and test partial correlation sums either within or between GGMs
(e.g., different groups), resulting in a posterior distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcor_sum(..., iter = NULL, relations)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcor_sum_+3A_...">...</code></td>
<td>
<p>An object of class <code>estimate</code>. This can be either one or two fitted objects.</p>
</td></tr>
<tr><td><code id="pcor_sum_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to the number in the object).</p>
</td></tr>
<tr><td><code id="pcor_sum_+3A_relations">relations</code></td>
<td>
<p>Character string. Which partial correlations should be summed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some care must be taken when writing the string for <code>partial_sum</code>. Below are several examples
</p>
<p><strong>Just a Sum</strong>:
Perhaps a sum is of interest, and not necessarily the difference of two sums. This can be written as
</p>

<ul>
<li> <p><code>partial_sum &lt;-  c("A1--A2 + A1--A3 + A1--A4")</code>
</p>
</li></ul>

<p>which will sum those relations.
</p>
<p><strong>Comparing Sums</strong>:
When comparing sums, each must be seperated by &quot;<code>;</code>&quot;. For example,
</p>

<ul>
<li> <p><code>partial_sum &lt;-  c("A1--A2 + A1--A3; A1--A2 + A1--A4")</code>
</p>
</li></ul>

<p>which will sum both and compute the difference. Note that there cannot be more than two sums, such
that <code>c("A1--A2 + A1--A3; A1--A2 + A1--A4; A1--A2 + A1--A5")</code> will result in an error.
</p>
<p><strong>Comparing Groups</strong>:
</p>
<p>When more than one fitted object is suppled to <code>object</code> it is assumed that the groups
should be compared for the same sum. Hence, in this case, only the sum needs to be written.
</p>

<ul>
<li> <p><code>partial_sum &lt;-  c("A1--A2 + A1--A3 + A1--A4")</code>
</p>
</li></ul>

<p>The above results in that sum being computed for each group and then compared.
</p>


<h3>Value</h3>

<p>An object of class <code>posterior_sum</code>, including the sum and possibly the difference for
two sums.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- bfi

# males
Y_males &lt;- subset(Y, gender == 1, select = -c(education, gender))[,1:5]

# females
Y_females &lt;- subset(Y, gender == 2, select = -c(education, gender))[,1:5]

# males
fit_males &lt;- estimate(Y_males, seed = 1,
                      progress = FALSE)

# fit females
fit_females &lt;- estimate(Y_females, seed = 2,
                        progress = FALSE)


sums &lt;- pcor_sum(fit_males,
                 fit_females,
                 relations = "A1--A2 + A1--A3")
# print
sums

# plot difference
plot(sums)[[3]]

</code></pre>

<hr>
<h2 id='pcor_to_cor'>Compute Correlations from the Partial Correlations</h2><span id='topic+pcor_to_cor'></span>

<h3>Description</h3>

<p>Convert the partial correlation matrices into correlation matrices. To our knowledge,
this is the only Bayesian
implementation in <code>R</code> that can estiamte Pearson's,  tetrachoric (binary), polychoric
(ordinal with more than two cateogries), and rank based correlation coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcor_to_cor(object, iter = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcor_to_cor_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code> or <code>explore</code></p>
</td></tr>
<tr><td><code id="pcor_to_cor_+3A_iter">iter</code></td>
<td>
<p>numeric. How many iterations (i.e., posterior samples) should be used ?
The default uses all of the samples, but note that this can take a long
time with large matrices.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>R</code> An array including the correlation matrices
(of dimensions <em>p</em> by <em>p</em> by <em>iter</em>)
</p>
</li>
<li> <p><code>R_mean</code> Posterior mean of the correlations (of dimensions <em>p</em> by <em>p</em>)
</p>
</li></ul>



<h3>Note</h3>

<p>The 'default' prior distributions are specified for partial correlations in particular. This
means that the implied prior distribution will not be the same for the correlations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- BGGM::ptsd

#########################
###### continuous #######
#########################

# estimate the model
fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)

# compute correlations
cors &lt;- pcor_to_cor(fit)


#########################
###### ordinal  #########
#########################

# first level must be 1 !
Y &lt;- Y + 1

# estimate the model
fit &lt;- estimate(Y, type =  "ordinal",
                iter = 250,
                progress = FALSE)

# compute correlations
cors &lt;- pcor_to_cor(fit)


#########################
#######   mixed    ######
#########################

# rank based correlations

# estimate the model
fit &lt;- estimate(Y, type =  "mixed",
                iter = 250,
                progress = FALSE)

# compute correlations
cors &lt;- pcor_to_cor(fit)


</code></pre>

<hr>
<h2 id='plot_prior'>Plot: Prior Distribution</h2><span id='topic+plot_prior'></span>

<h3>Description</h3>

<p>Visualize the implied prior distribution for the partial correlations. This is
particularly useful for the Bayesian hypothesis testing methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_prior(prior_sd = 0.5, iter = 5000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_prior_+3A_prior_sd">prior_sd</code></td>
<td>
<p>Scale of the prior distribution, approximately the standard deviation
of a beta distribution (defaults to 0.5).</p>
</td></tr>
<tr><td><code id="plot_prior_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (prior samples; defaults to 5000).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># note: iter = 250 for demonstrative purposes

plot_prior(prior_sd = 0.25, iter = 250)
</code></pre>

<hr>
<h2 id='plot.confirm'>Plot <code>confirm</code> objects</h2><span id='topic+plot.confirm'></span>

<h3>Description</h3>

<p>Plot the posterior hypothesis probabilities as a pie chart, with
each slice corresponding the probability of a given hypothesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'confirm'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.confirm_+3A_x">x</code></td>
<td>
<p>An object of class <code>confirm</code></p>
</td></tr>
<tr><td><code id="plot.confirm_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


#####################################
##### example 1: many relations #####
#####################################

# data
Y &lt;- bfi

hypothesis &lt;- c("g1_A1--A2 &gt; g2_A1--A2 &amp; g1_A1--A3 = g2_A1--A3;
                 g1_A1--A2 = g2_A1--A2 &amp; g1_A1--A3 = g2_A1--A3;
                 g1_A1--A2 = g2_A1--A2 = g1_A1--A3 = g2_A1--A3")

Ymale   &lt;- subset(Y, gender == 1,
                  select = -c(education,
                              gender))[,1:5]


# females
Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(education,
                                 gender))[,1:5]

test &lt;- ggm_compare_confirm(Ymale,
                            Yfemale,
                            hypothesis = hypothesis,
                            iter = 250,
                            progress = FALSE)


# plot
plot(test)

</code></pre>

<hr>
<h2 id='plot.ggm_compare_ppc'>Plot <code>ggm_compare_ppc</code> Objects</h2><span id='topic+plot.ggm_compare_ppc'></span>

<h3>Description</h3>

<p>Plot the predictive check with <code><a href="ggridges.html#topic+ggridges">ggridges</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ggm_compare_ppc'
plot(
  x,
  critical = 0.05,
  col_noncritical = "#84e184A0",
  col_critical = "red",
  point_size = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ggm_compare_ppc_+3A_x">x</code></td>
<td>
<p>An object of class <code>ggm_compare_ppc</code></p>
</td></tr>
<tr><td><code id="plot.ggm_compare_ppc_+3A_critical">critical</code></td>
<td>
<p>Numeric. The 'significance' level
(defaults to <code>0.05</code>).</p>
</td></tr>
<tr><td><code id="plot.ggm_compare_ppc_+3A_col_noncritical">col_noncritical</code></td>
<td>
<p>Character string. Fill color for the non-critical region
(defaults to <code>"#84e184A0"</code>).</p>
</td></tr>
<tr><td><code id="plot.ggm_compare_ppc_+3A_col_critical">col_critical</code></td>
<td>
<p>Character string. Fill color for the critical region
(defaults to <code>"red"</code>).</p>
</td></tr>
<tr><td><code id="plot.ggm_compare_ppc_+3A_point_size">point_size</code></td>
<td>
<p>Numeric. The point size for the observed score
(defaults to <code>2</code>).</p>
</td></tr>
<tr><td><code id="plot.ggm_compare_ppc_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object (or list of objects) of class <code>ggplot</code>.
</p>


<h3>Note</h3>

<p>See
<a href="https://CRAN.R-project.org/package=ggridges/vignettes/introduction.html">ggridges</a> for
many examples.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ggm_compare_ppc">ggm_compare_ppc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- bfi

#############################
######### global ############
#############################
# males
Ym &lt;- subset(Y, gender == 1,
             select = - c(gender, education))

# females

Yf &lt;- subset(Y, gender == 2,
             select = - c(gender, education))


global_test &lt;- ggm_compare_ppc(Ym, Yf,
                               iter = 250,
                               progress = FALSE)

plot(global_test)

</code></pre>

<hr>
<h2 id='plot.pcor_sum'>Plot <code>pcor_sum</code> Object</h2><span id='topic+plot.pcor_sum'></span>

<h3>Description</h3>

<p>Plot <code>pcor_sum</code> Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcor_sum'
plot(x, fill = "#CC79A7", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pcor_sum_+3A_x">x</code></td>
<td>
<p>An object of class <code>posterior_sum</code></p>
</td></tr>
<tr><td><code id="plot.pcor_sum_+3A_fill">fill</code></td>
<td>
<p>Character string. What fill for the histogram
(defaults to colorblind &quot;pink&quot;)?</p>
</td></tr>
<tr><td><code id="plot.pcor_sum_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code>ggplot</code> objects
</p>


<h3>Note</h3>

<p><strong>Examples</strong>:
</p>


<h3>See Also</h3>

<p>pcor_sum
</p>

<hr>
<h2 id='plot.predictability'>Plot <code>predictability</code> Objects</h2><span id='topic+plot.predictability'></span>

<h3>Description</h3>

<p>Plot <code>predictability</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predictability'
plot(
  x,
  type = "error_bar",
  cred = 0.95,
  alpha = 0.5,
  scale = 1,
  width = 0,
  size = 1,
  color = "blue",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.predictability_+3A_x">x</code></td>
<td>
<p>An object of class <code>predictability</code></p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_type">type</code></td>
<td>
<p>Character string. Which type of plot ? The options
are <code>"error_bar"</code> or <code>"ridgeline"</code> (defaults to <code>"error_bar"</code>).</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Transparancey of the ridges</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_scale">scale</code></td>
<td>
<p>Numeric. This controls the overlap of densities
for <code>type = "ridgeline"</code> (defaults to 1).</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_width">width</code></td>
<td>
<p>Numeric. The width of error bar ends (defaults to <code>0</code>)
for <code>type = "error_bar"</code>.</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_size">size</code></td>
<td>
<p>Numeric. The size for the points (defaults to <code>2</code>)
for <code>type = "error_bar"</code>.</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_color">color</code></td>
<td>
<p>Character string. What color for the point (<code>type = "error_bar"</code>) or
tail region (<code>type = "ridgeline"</code> ) ? Defaults to <code>"blue"</code>.</p>
</td></tr>
<tr><td><code id="plot.predictability_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ggplot</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Y &lt;- ptsd[,1:5]

fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

r2 &lt;- predictability(fit, iter = 250,
                     progress = FALSE)

plot(r2)


</code></pre>

<hr>
<h2 id='plot.roll_your_own'>Plot <code>roll_your_own</code> Objects</h2><span id='topic+plot.roll_your_own'></span>

<h3>Description</h3>

<p>Plot <code>roll_your_own</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'roll_your_own'
plot(x, fill = "#CC79A7", alpha = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.roll_your_own_+3A_x">x</code></td>
<td>
<p>An object of class <code>roll_your_own</code></p>
</td></tr>
<tr><td><code id="plot.roll_your_own_+3A_fill">fill</code></td>
<td>
<p>Character string specifying the color for the ridges.</p>
</td></tr>
<tr><td><code id="plot.roll_your_own_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Transparancey of the ridges</p>
</td></tr>
<tr><td><code id="plot.roll_your_own_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ggplot</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
####################################
###### example 1: assortment #######
####################################
# assortment
library(assortnet)

Y &lt;- BGGM::bfi[,1:10]
membership &lt;- c(rep("a", 5), rep("c", 5))

# fit model
fit &lt;- estimate(Y = Y, iter = 250,
                progress = FALSE)

# membership
membership &lt;- c(rep("a", 5), rep("c", 5))

# define function
f &lt;- function(x,...){
 assortment.discrete(x, ...)$r
}

net_stat &lt;- roll_your_own(object = fit,
                          FUN = f,
                          types = membership,
                          weighted = TRUE,
                          SE = FALSE, M = 1,
                          progress = FALSE)

# plot
plot(net_stat)


</code></pre>

<hr>
<h2 id='plot.select'>Network Plot for <code>select</code> Objects</h2><span id='topic+plot.select'></span>

<h3>Description</h3>

<p>Visualize the conditional (in)dependence structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'select'
plot(
  x,
  layout = "circle",
  pos_col = "#009E73",
  neg_col = "#D55E00",
  node_size = 10,
  edge_magnify = 1,
  groups = NULL,
  palette = "Set3",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.select_+3A_x">x</code></td>
<td>
<p>An object of class <code>select</code>.</p>
</td></tr>
<tr><td><code id="plot.select_+3A_layout">layout</code></td>
<td>
<p>Character string. Which graph layout (defaults is <code>circle</code>) ?
See <a href="sna.html#topic+gplot.layout">gplot.layout</a>.</p>
</td></tr>
<tr><td><code id="plot.select_+3A_pos_col">pos_col</code></td>
<td>
<p>Character string. Color for the positive edges (defaults to <code>green</code>).</p>
</td></tr>
<tr><td><code id="plot.select_+3A_neg_col">neg_col</code></td>
<td>
<p>Character string.  Color for the negative edges (defaults to <code>green</code>).</p>
</td></tr>
<tr><td><code id="plot.select_+3A_node_size">node_size</code></td>
<td>
<p>Numeric. The size of the nodes (defaults to <code>10</code>).</p>
</td></tr>
<tr><td><code id="plot.select_+3A_edge_magnify">edge_magnify</code></td>
<td>
<p>Numeric. A value that is multiplied by the edge weights. This increases (&gt; 1) or
decrease (&lt; 1) the line widths (defaults to 1).</p>
</td></tr>
<tr><td><code id="plot.select_+3A_groups">groups</code></td>
<td>
<p>A character string of length <em>p</em> (the number of nodes in the model).
This indicates groups of nodes that should be the same color
(e.g., &quot;clusters&quot; or &quot;communities&quot;).</p>
</td></tr>
<tr><td><code id="plot.select_+3A_palette">palette</code></td>
<td>
<p>A character string sepcifying the palette for the <code>groups</code>.
(default is <code>Set3</code>). See <a href="http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/">palette options here</a>.</p>
</td></tr>
<tr><td><code id="plot.select_+3A_...">...</code></td>
<td>
<p>Additional options passed to <a href="GGally.html#topic+ggnet2">ggnet2</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object (or list of objects) of class <code>ggplot</code>
that can then be further customized.
</p>


<h3>Note</h3>

<p>A more extensive example of a custom plot is
provided <a href="https://donaldrwilliams.github.io/BGGM/articles/netplot.html">here</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#########################
### example 1: one ggm ##
#########################

# data
Y &lt;- bfi[,1:25]

# estimate
fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)

# "communities"
comm &lt;- substring(colnames(Y), 1, 1)

# edge set
E &lt;- select(fit)

# plot edge set
plt_E &lt;- plot(E, edge_magnify = 5,
              palette = "Set1",
              groups = comm)


#############################
### example 2: ggm compare ##
#############################
# compare males vs. females

# data
Y &lt;- bfi[,1:26]

Ym &lt;- subset(Y, gender == 1,
             select = -gender)

Yf &lt;- subset(Y, gender == 2,
              select = -gender)

# estimate
fit &lt;- ggm_compare_estimate(Ym, Yf, iter = 250,
                            progress = FALSE)

# "communities"
comm &lt;- substring(colnames(Ym), 1, 1)

# edge set
E &lt;- select(fit)

# plot edge set
plt_E &lt;- plot(E, edge_magnify = 5,
              palette = "Set1",
              groups = comm)




</code></pre>

<hr>
<h2 id='plot.summary.estimate'>Plot <code>summary.estimate</code> Objects</h2><span id='topic+plot.summary.estimate'></span>

<h3>Description</h3>

<p>Visualize the posterior distributions for each partial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.estimate'
plot(x, color = "black", size = 2, width = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.estimate_+3A_x">x</code></td>
<td>
<p>An object of class <code>summary.estimate</code></p>
</td></tr>
<tr><td><code id="plot.summary.estimate_+3A_color">color</code></td>
<td>
<p>Character string. The color for the error bars.
(defaults to <code>"black"</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.estimate_+3A_size">size</code></td>
<td>
<p>Numeric. The size for the points (defaults to <code>2</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.estimate_+3A_width">width</code></td>
<td>
<p>Numeric. The width of error bar ends (defaults to <code>0</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estimate">estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- ptsd[,1:5]

fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)


plot(summary(fit))



</code></pre>

<hr>
<h2 id='plot.summary.explore'>Plot <code>summary.explore</code> Objects</h2><span id='topic+plot.summary.explore'></span>

<h3>Description</h3>

<p>Visualize the posterior distributions for each partial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.explore'
plot(x, color = "black", size = 2, width = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.explore_+3A_x">x</code></td>
<td>
<p>An object of class <code>summary.explore</code></p>
</td></tr>
<tr><td><code id="plot.summary.explore_+3A_color">color</code></td>
<td>
<p>Character string. The color for the error bars.
(defaults to <code>"black"</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.explore_+3A_size">size</code></td>
<td>
<p>Numeric. The size for the points (defaults to <code>2</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.explore_+3A_width">width</code></td>
<td>
<p>Numeric. The width of error bar ends (defaults to <code>0</code> ).</p>
</td></tr>
<tr><td><code id="plot.summary.explore_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object
</p>


<h3>See Also</h3>

<p><code><a href="#topic+explore">explore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

Y &lt;- ptsd[,1:5]

fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

plt &lt;- plot(summary(fit))

plt

</code></pre>

<hr>
<h2 id='plot.summary.ggm_compare_estimate'>Plot <code>summary.ggm_compare_estimate</code> Objects</h2><span id='topic+plot.summary.ggm_compare_estimate'></span>

<h3>Description</h3>

<p>Visualize the posterior distribution differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.ggm_compare_estimate'
plot(x, color = "black", size = 2, width = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.ggm_compare_estimate_+3A_x">x</code></td>
<td>
<p>An object of class <code>ggm_compare_estimate</code>.</p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_estimate_+3A_color">color</code></td>
<td>
<p>Character string. The color of the points
(defaults to <code>"black"</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_estimate_+3A_size">size</code></td>
<td>
<p>Numeric. The size of the points (defaults to 2).</p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_estimate_+3A_width">width</code></td>
<td>
<p>Numeric. The width of error bar ends (defaults to <code>0</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ggplot</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes
# data
Y &lt;- bfi[complete.cases(bfi),]

# males and females
Ymale &lt;- subset(Y, gender == 1,
                select = -c(gender,
                            education))[,1:10]

Yfemale &lt;- subset(Y, gender == 2,
                  select = -c(gender,
                              education))[,1:10]

# fit model
fit &lt;- ggm_compare_estimate(Ymale,  Yfemale,
                            type = "ordinal",
                            iter = 250,
                            prior_sd = 0.25,
                            progress = FALSE)

plot(summary(fit))


</code></pre>

<hr>
<h2 id='plot.summary.ggm_compare_explore'>Plot <code>summary.ggm_compare_explore</code> Objects</h2><span id='topic+plot.summary.ggm_compare_explore'></span>

<h3>Description</h3>

<p>Visualize the posterior hypothesis probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.ggm_compare_explore'
plot(x, size = 2, color = "black", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.ggm_compare_explore_+3A_x">x</code></td>
<td>
<p>An object of class <code>summary.ggm_compare_explore</code></p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_explore_+3A_size">size</code></td>
<td>
<p>Numeric. The size of the points (defaults to 2).</p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_explore_+3A_color">color</code></td>
<td>
<p>Character string. The color of the points
(defaults to <code>"black"</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.ggm_compare_explore_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi[complete.cases(bfi),]

# males and females
Ymale &lt;- subset(Y, gender == 1,
                   select = -c(gender,
                               education))[,1:10]

Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(gender,
                                 education))[,1:10]

##########################
### example 1: ordinal ###
##########################

# fit model
fit &lt;- ggm_compare_explore(Ymale,  Yfemale,
                           type = "ordinal",
                           iter = 250,
                           progress = FALSE)
# summary
summ &lt;- summary(fit)

plot(summ)

</code></pre>

<hr>
<h2 id='plot.summary.select.explore'>Plot <code>summary.select.explore</code> Objects</h2><span id='topic+plot.summary.select.explore'></span>

<h3>Description</h3>

<p>Visualize the posterior hypothesis probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.select.explore'
plot(x, size = 2, color = "black", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.select.explore_+3A_x">x</code></td>
<td>
<p>An object of class <code>summary.select.explore</code></p>
</td></tr>
<tr><td><code id="plot.summary.select.explore_+3A_size">size</code></td>
<td>
<p>Numeric. The size for the points (defaults to 2).</p>
</td></tr>
<tr><td><code id="plot.summary.select.explore_+3A_color">color</code></td>
<td>
<p>Character string. The Color for the points</p>
</td></tr>
<tr><td><code id="plot.summary.select.explore_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#  data
Y &lt;- bfi[,1:10]

# fit model
fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

# edge set
E &lt;- select(fit,
            alternative = "exhaustive")

plot(summary(E))


</code></pre>

<hr>
<h2 id='plot.summary.var_estimate'>Plot <code>summary.var_estimate</code> Objects</h2><span id='topic+plot.summary.var_estimate'></span>

<h3>Description</h3>

<p>Visualize the posterior distributions of each partial correlation and
regression coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.var_estimate'
plot(x, color = "black", size = 2, width = 0, param = "all", order = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.var_estimate_+3A_x">x</code></td>
<td>
<p>An object of class <code>summary.var_estimate</code></p>
</td></tr>
<tr><td><code id="plot.summary.var_estimate_+3A_color">color</code></td>
<td>
<p>Character string. The color for the error bars.
(defaults to <code>"black"</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.var_estimate_+3A_size">size</code></td>
<td>
<p>Numeric. The size for the points (defaults to <code>2</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.var_estimate_+3A_width">width</code></td>
<td>
<p>Numeric. The width of error bar ends (defaults to <code>0</code>).</p>
</td></tr>
<tr><td><code id="plot.summary.var_estimate_+3A_param">param</code></td>
<td>
<p>Character string. Which parameters should be plotted ? The options
are <code>pcor</code>, <code>beta</code>, or <code>all</code> (default).</p>
</td></tr>
<tr><td><code id="plot.summary.var_estimate_+3A_order">order</code></td>
<td>
<p>Logical. Should the relations be ordered by size (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="plot.summary.var_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code>ggplot</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# data
Y &lt;- subset(ifit, id == 1)[,-1]

# fit model with alias (var_estimate also works)
fit &lt;- var_estimate(Y, progress = FALSE)

plts &lt;- plot(summary(fit))
plts$pcor_plt


</code></pre>

<hr>
<h2 id='posterior_predict'>Posterior Predictive Distribution</h2><span id='topic+posterior_predict'></span>

<h3>Description</h3>

<p>Draw samples from the posterior predictive distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posterior_predict(object, iter = 1000, progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posterior_predict_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code> or <code>explore</code></p>
</td></tr>
<tr><td><code id="posterior_predict_+3A_iter">iter</code></td>
<td>
<p>Numeric. Number of samples from the predictive distribution</p>
</td></tr>
<tr><td><code id="posterior_predict_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 3D array containing the predicted datasets
</p>


<h3>Note</h3>

<p>Currently only implemented for <code>type = "mixed"</code>, <code>type = "ordinal"</code>,
and <code>type = "binary"</code>. Note the term mixed is confusing, in that it can
be used with only, say, ordinal data. In this case, reestimate the model with <code>type = "mixed"</code>
until all data types are supported.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Y &lt;- gss

fit &lt;- estimate(as.matrix(Y),
                impute = TRUE,
               iter = 150, type = "mixed")

yrep &lt;- posterior_predict(fit, iter = 100)

</code></pre>

<hr>
<h2 id='posterior_samples'>Extract Posterior Samples</h2><span id='topic+posterior_samples'></span>

<h3>Description</h3>

<p>Extract posterior samples for all parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posterior_samples(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posterior_samples_+3A_object">object</code></td>
<td>
<p>an object of class <code>estimate</code> or <code>explore</code>.</p>
</td></tr>
<tr><td><code id="posterior_samples_+3A_...">...</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of posterior samples for the partial correlation. Note that if controlling for
variables (e.g., formula <code>~ age</code>), the matrix also includes the coefficients from each
multivariate regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

########################################
### example 1: control  with formula ###
########################################
# (the following works with all data types)

# controlling for gender
Y &lt;- bfi

# to control for only gender
# (remove education)
Y &lt;- subset(Y, select = - education)

# fit model
fit &lt;- estimate(Y, formula = ~ gender,
                iter = 250)

# note regression coefficients
samps &lt;- posterior_samples(fit)

hist(samps[,1])


</code></pre>

<hr>
<h2 id='precision'>Precision Matrix Posterior Distribution</h2><span id='topic+precision'></span>

<h3>Description</h3>

<p>Transform the sampled correlation matrices to
precision matrices (i.e., inverse covariance matrices).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>precision(object, progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="precision_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code>.</p>
</td></tr>
<tr><td><code id="precision_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>precision_mean</code> The mean of the precision matrix (<code>p</code> by <code>p</code> matrix).
</p>
</li>
<li> <p><code>precision</code> 3d array of dimensions <code>p</code> by <code>p</code> by <code>iter</code>
including <strong>unconstrained</strong> (i.e., from th full graph)
precision matrices.
</p>
</li></ul>



<h3>Note</h3>

<p>The estimated precision matrix is the inverse of the <strong>correlation</strong> matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- ptsd

# fit model
fit &lt;- estimate(Y)

# precision matrix
Theta &lt;- precision(fit)



</code></pre>

<hr>
<h2 id='predict.estimate'>Model Predictions for <code>estimate</code> Objects</h2><span id='topic+predict.estimate'></span>

<h3>Description</h3>

<p>Model Predictions for <code>estimate</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'estimate'
predict(
  object,
  newdata = NULL,
  summary = TRUE,
  cred = 0.95,
  iter = NULL,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.estimate_+3A_object">object</code></td>
<td>
<p>object of class <code>estimate</code></p>
</td></tr>
<tr><td><code id="predict.estimate_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame for obtaining predictions (e.g., on test data)</p>
</td></tr>
<tr><td><code id="predict.estimate_+3A_summary">summary</code></td>
<td>
<p>summarize the posterior samples (defaults to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="predict.estimate_+3A_cred">cred</code></td>
<td>
<p>credible interval used for summarizing</p>
</td></tr>
<tr><td><code id="predict.estimate_+3A_iter">iter</code></td>
<td>
<p>number of posterior samples (defaults to all in the object).</p>
</td></tr>
<tr><td><code id="predict.estimate_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="predict.estimate_+3A_...">...</code></td>
<td>
<p>currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary = TRUE</code>: 3D array of dimensions n (observations),
4 (posterior summary),
p (number of nodes). <code>summary = FALSE</code>:
list containing predictions for each variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# # data
Y &lt;- ptsd

fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)

pred &lt;- predict(fit,
                progress = FALSE)


</code></pre>

<hr>
<h2 id='predict.explore'>Model Predictions for <code>explore</code> Objects</h2><span id='topic+predict.explore'></span>

<h3>Description</h3>

<p>Model Predictions for <code>explore</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'explore'
predict(
  object,
  newdata = NULL,
  summary = TRUE,
  cred = 0.95,
  iter = NULL,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.explore_+3A_object">object</code></td>
<td>
<p>object of class <code>explore</code></p>
</td></tr>
<tr><td><code id="predict.explore_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame for obtaining predictions (e.g., on test data)</p>
</td></tr>
<tr><td><code id="predict.explore_+3A_summary">summary</code></td>
<td>
<p>summarize the posterior samples (defaults to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="predict.explore_+3A_cred">cred</code></td>
<td>
<p>credible interval used for summarizing</p>
</td></tr>
<tr><td><code id="predict.explore_+3A_iter">iter</code></td>
<td>
<p>number of posterior samples (defaults to all in the object).</p>
</td></tr>
<tr><td><code id="predict.explore_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="predict.explore_+3A_...">...</code></td>
<td>
<p>currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary = TRUE</code>: 3D array of dimensions n (observations),
4 (posterior summary),
p (number of nodes). <code>summary = FALSE</code>:
list containing predictions for each variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- ptsd

# fit model
fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

# predict
pred &lt;- predict(fit,
                progress = FALSE)


</code></pre>

<hr>
<h2 id='predict.var_estimate'>Model Predictions for <code>var_estimate</code> Objects</h2><span id='topic+predict.var_estimate'></span>

<h3>Description</h3>

<p>Model Predictions for <code>var_estimate</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'var_estimate'
predict(object, summary = TRUE, cred = 0.95, iter = NULL, progress = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.var_estimate_+3A_object">object</code></td>
<td>
<p>object of class <code>var_estimate</code></p>
</td></tr>
<tr><td><code id="predict.var_estimate_+3A_summary">summary</code></td>
<td>
<p>summarize the posterior samples (defaults to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="predict.var_estimate_+3A_cred">cred</code></td>
<td>
<p>credible interval used for summarizing</p>
</td></tr>
<tr><td><code id="predict.var_estimate_+3A_iter">iter</code></td>
<td>
<p>number of posterior samples (defaults to all in the object).</p>
</td></tr>
<tr><td><code id="predict.var_estimate_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="predict.var_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted values for each regression model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- subset(ifit, id == 1)[,-1]

# fit model with alias (var_estimate also works)
fit &lt;- var_estimate(Y, progress = FALSE)

# fitted values
pred &lt;- predict(fit, progress = FALSE)

# predicted values (1st outcome)
pred[,,1]


</code></pre>

<hr>
<h2 id='predictability'>Predictability: Bayesian Variance Explained (R2)</h2><span id='topic+predictability'></span>

<h3>Description</h3>

<p>Compute nodewise predictability or  Bayesian variance explained (R2 Gelman et al. 2019).
In the context of GGMs, this method was described in Williams (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictability(
  object,
  select = FALSE,
  cred = 0.95,
  BF_cut = 3,
  iter = NULL,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictability_+3A_object">object</code></td>
<td>
<p>object of class <code>estimate</code> or <code>explore</code></p>
</td></tr>
<tr><td><code id="predictability_+3A_select">select</code></td>
<td>
<p>logical. Should the graph be selected ? The default is currently <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predictability_+3A_cred">cred</code></td>
<td>
<p>numeric. credible interval between 0 and 1  (default is 0.95) that is used for selecting the graph.</p>
</td></tr>
<tr><td><code id="predictability_+3A_bf_cut">BF_cut</code></td>
<td>
<p>numeric. evidentiary threshold (default is 3).</p>
</td></tr>
<tr><td><code id="predictability_+3A_iter">iter</code></td>
<td>
<p>interger. iterations (posterior samples) used for computing R2.</p>
</td></tr>
<tr><td><code id="predictability_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="predictability_+3A_...">...</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of classes <code>bayes_R2</code> and <code>metric</code>, including
</p>

<ul>
<li> <p><code>scores</code> A list containing the posterior samples of R2. The is one element
</p>
<p>for each node.
</p>
</li></ul>



<h3>Note</h3>

<p><strong>Binary and Ordinal Data</strong>:
</p>
<p>R2 is computed from the latent data.
</p>
<p><strong>Mixed Data</strong>:
</p>
<p>The mixed data approach is somewhat ad-hoc see for example p. 277 in  Hoff (2007). This
is becaue uncertainty in the ranks is not incorporated, which means that variance explained is computed from
the 'empirical' <em>CDF</em>.
</p>
<p><strong>Model Selection</strong>:
</p>
<p>Currently the default to include all nodes in the model when computing R2. This can be changed (i.e., <code>select = TRUE</code>), which
then sets those edges not detected to zero. This is accomplished by subsetting the correlation matrix according to each neighborhood
of relations.
</p>


<h3>References</h3>

<p>Gelman A, Goodrich B, Gabry J, Vehtari A (2019).
&ldquo;R-squared for Bayesian Regression Models.&rdquo;
<em>American Statistician</em>, <b>73</b>(3), 307&ndash;309.
ISSN 15372731.<br /><br /> Hoff PD (2007).
&ldquo;Extending the rank likelihood for semiparametric copula estimation.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>1</b>(1), 265&ndash;283.
<a href="https://doi.org/10.1214/07-AOAS107">doi:10.1214/07-AOAS107</a>.<br /><br /> Williams DR (2018).
&ldquo;Bayesian Estimation for Gaussian Graphical Models: Structure Learning, Predictability, and Network Comparisons.&rdquo;
<em>arXiv</em>.
<a href="https://doi.org/10.31234/OSF.IO/X8DPR">doi:10.31234/OSF.IO/X8DPR</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# data
Y &lt;- ptsd[,1:5]

fit &lt;- estimate(Y, iter = 250, progress = FALSE)

r2 &lt;- predictability(fit, select = TRUE,
                     iter = 250, progress = FALSE)

# summary
r2

</code></pre>

<hr>
<h2 id='predicted_probability'>Predicted Probabilities</h2><span id='topic+predicted_probability'></span>

<h3>Description</h3>

<p>Compute the predicted probabilities for discrete data, with the possibility
of conditional predictive probabilities (i.e., at fixed values of other nodes)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predicted_probability(object, outcome, Y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predicted_probability_+3A_object">object</code></td>
<td>
<p>An object of class <code>posterior_predict</code></p>
</td></tr>
<tr><td><code id="predicted_probability_+3A_outcome">outcome</code></td>
<td>
<p>Character string. Node for which the probabilities are computed.</p>
</td></tr>
<tr><td><code id="predicted_probability_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).
This must include the column names.</p>
</td></tr>
<tr><td><code id="predicted_probability_+3A_...">...</code></td>
<td>
<p>Compute conditional probabilities by specifying a column name in <code>Y</code>
(besides the <code>outcome</code>) and a fixed value. This can include
any number of nodes. See example below. Leave this blank to compute
unconditional probabilities for <code>outcome</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a matrix with the computed probabilities
(a row for each predictive sample and a column for each category).
</p>


<h3>Note</h3>

<p>There are no checks that the conditional probability exists, i.e., suppose
you wish to condition on, say, B3 = 2 and B4 = 1, yet there is no instance in
which B3 is 2 AND B4 is 1. This will result in an uninformative error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Y &lt;- ptsd
fit &lt;- estimate(as.matrix(Y), iter = 150, type = "mixed")

pred &lt;- posterior_predict(fit, iter = 100)

prob &lt;- predicted_probability(pred,
                              Y = Y,
                              outcome = "B3",
                              B4 = 0,
                              B5 = 0)


</code></pre>

<hr>
<h2 id='print.BGGM'>Print method for <code>BGGM</code> objects</h2><span id='topic+print.BGGM'></span>

<h3>Description</h3>

<p>Mainly used to avoid a plethora of different print
functions that overcrowded the documentation in previous versions
of <strong>BGGM</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BGGM'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.BGGM_+3A_x">x</code></td>
<td>
<p>An object of class <code>BGGM</code></p>
</td></tr>
<tr><td><code id="print.BGGM_+3A_...">...</code></td>
<td>
<p>currently ignored</p>
</td></tr>
</table>

<hr>
<h2 id='prior_belief_ggm'>Prior Belief Gaussian Graphical Model</h2><span id='topic+prior_belief_ggm'></span>

<h3>Description</h3>

<p>Incorporate prior information into the estimation of the
conditional dependence structure. This prior information is expressed as
the prior odds that each relation should be included in the graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prior_belief_ggm(Y, prior_ggm, post_odds_cut = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prior_belief_ggm_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by
<em>p</em> (variables/nodes).</p>
</td></tr>
<tr><td><code id="prior_belief_ggm_+3A_prior_ggm">prior_ggm</code></td>
<td>
<p>Matrix of dimensions <em>p</em> by <em>p</em>, encoding the prior
odds for including each relation in the graph (see '<code>Details</code>')</p>
</td></tr>
<tr><td><code id="prior_belief_ggm_+3A_post_odds_cut">post_odds_cut</code></td>
<td>
<p>Numeric. Threshold for including an edge (defaults to 3).
Note <code>post_odds</code> refers to posterior odds.</p>
</td></tr>
<tr><td><code id="prior_belief_ggm_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+explore">explore</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Technically, the prior odds is not for including an edge in the graph,
but for (H1)/p(H0), where H1 captures the hypothesized edge size and H0 is the
null model  (see Williams2019_bf). Accordingly, setting an
entry in <code>prior_ggm</code> to, say, 10, encodes a prior belief that H1 is 10 times
more likely than H0. Further, setting an entry in <code>prior_ggm</code> to 1 results
in equal prior odds (the default in <code><a href="#topic+select.explore">select.explore</a></code>).
</p>


<h3>Value</h3>

<p>An object including:
</p>

<ul>
<li><p><strong>adj</strong>: Adjacency matrix
</p>
</li>
<li><p><strong>post_prob</strong>: Posterior probability for the
alternative hypothesis.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Assume perfect prior information
# synthetic ggm
p &lt;- 20
main &lt;- gen_net()

# prior odds 10:1, assuming graph is known
prior_ggm &lt;- ifelse(main$adj == 1, 10, 1)

# generate data
y &lt;- MASS::mvrnorm(n = 200,
                   mu = rep(0, 20),
                   Sigma = main$cors)

# prior est
prior_est &lt;- prior_belief_ggm(Y = y,
                              prior_ggm = prior_ggm,
                              progress = FALSE)

# check scores
BGGM:::performance(Estimate = prior_est$adj,
                   True = main$adj)

# default in BGGM
default_est &lt;- select(explore(y, progress = FALSE))

# check scores
BGGM:::performance(Estimate = default_est$Adj_10,
                   True = main$adj)


</code></pre>

<hr>
<h2 id='prior_belief_var'>Prior Belief Graphical VAR</h2><span id='topic+prior_belief_var'></span>

<h3>Description</h3>

<p>Prior Belief Graphical VAR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prior_belief_var(
  Y,
  prior_temporal = NULL,
  post_odds_cut = 3,
  est_ggm = TRUE,
  prior_ggm = NULL,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prior_belief_var_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em>
(observations) by <em>p</em> (variables/nodes).</p>
</td></tr>
<tr><td><code id="prior_belief_var_+3A_prior_temporal">prior_temporal</code></td>
<td>
<p>Matrix of dimensions <em>p</em> by <em>p</em>,
encoding the prior odds for including each relation
in the temporal graph (see '<code>Details</code>'). If null
a matrix of 1's is used, resulting in equal prior odds.</p>
</td></tr>
<tr><td><code id="prior_belief_var_+3A_post_odds_cut">post_odds_cut</code></td>
<td>
<p>Numeric. Threshold for including an edge (defaults to 3).
Note <code>post_odds</code> refers to posterior odds.</p>
</td></tr>
<tr><td><code id="prior_belief_var_+3A_est_ggm">est_ggm</code></td>
<td>
<p>Logical. Should the contemporaneous network be estimated
(defaults to <code>TRUE</code>)?</p>
</td></tr>
<tr><td><code id="prior_belief_var_+3A_prior_ggm">prior_ggm</code></td>
<td>
<p>Matrix of dimensions <em>p</em> by <em>p</em>, encoding the prior
odds for including each relation in the graph
(see '<code>Details</code>'). If null a matrix of 1's is used,
resulting in equal prior odds.</p>
</td></tr>
<tr><td><code id="prior_belief_var_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included
(defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="prior_belief_var_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+explore">explore</a></code>. Ignored
if <code>prior_ggm = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Technically, the prior odds is not for including an edge in the graph,
but for (H1)/p(H0), where H1 captures the hypothesized edge size and H0 is the
null model  (see Williams2019_bf). Accordingly, setting an
entry in <code>prior_ggm</code> to, say, 10, encodes a prior belief that H1 is 10 times
more likely than H0. Further, setting an entry in <code>prior_ggm</code> or
<code>prior_var</code> to 1 results in equal prior odds
(the default in <code><a href="#topic+select.explore">select.explore</a></code>).
</p>


<h3>Value</h3>

<p>An object including (<code>est_ggm = FALSE</code>):
</p>

<ul>
<li><p><strong>adj</strong>: Adjacency matrix
</p>
</li>
<li><p><strong>post_prob</strong>: Posterior probability for the
alternative hypothesis.
</p>
</li></ul>

<p>An object including (<code>est_ggm = TRUE</code>):
</p>

<ul>
<li><p><strong>adj_temporal</strong>: Adjacency matrix for the temporal network.
</p>
</li>
<li><p><strong>post_prob_temporal</strong>: Posterior probability for the
alternative hypothesis (temporal edge)
</p>
</li>
<li><p><strong>adj_ggm</strong>: Adjacency matrix for the contemporaneous
network (ggm).
</p>
</li>
<li><p>post_prob_ggm: Posterior probability for the
alternative hypothesis (contemporaneous edge)
</p>
</li></ul>



<h3>Note</h3>

<p>The returned matrices are formatted with the rows indicating
the outcome and the columns the predictor. Hence, adj_temporal[1,4] is the temporal
relation of node 4 predicting node 1. This follows the convention of the
<strong>vars</strong> package (i.e., <code>Acoef</code>).
</p>
<p>Further, in order to compute the Bayes factor the data is
standardized (mean = 0 and standard deviation = 1).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# affect data from 1 person
# (real data)
y &lt;- na.omit(subset(ifit, id == 1)[,2:7])
p &lt;- ncol(y)

# random prior graph
# (dont do this in practice!!)
prior_var = matrix(sample(c(1,10),
                   size = p^2, replace = TRUE),
                   nrow = p, ncol = p)

# fit model
fit &lt;- prior_belief_var(y,
                        prior_temporal = prior_var,
                        post_odds_cut = 3)

</code></pre>

<hr>
<h2 id='ptsd'>Data: Post-Traumatic Stress Disorder</h2><span id='topic+ptsd'></span>

<h3>Description</h3>

<p>A dataset containing items that measure Post-traumatic stress disorder symptoms (Armour et al. 2017).
There are 20 variables (<em>p</em>) and  221 observations (<em>n</em>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ptsd")
</code></pre>


<h3>Format</h3>

<p>A dataframe with 221 rows and 20 variables
</p>


<h3>Details</h3>


<ul>
<li><p> Intrusive Thoughts
</p>
</li>
<li><p> Nightmares
</p>
</li>
<li><p> Flashbacks
</p>
</li>
<li><p> Emotional cue reactivity
</p>
</li>
<li><p> Psychological cue reactivity
</p>
</li>
<li><p> Avoidance of thoughts
</p>
</li>
<li><p> Avoidance of reminders
</p>
</li>
<li><p> Trauma-related amnesia
</p>
</li>
<li><p> Negative beliefs
</p>
</li>
<li><p> Negative trauma-related emotions
</p>
</li>
<li><p> Loss of interest
</p>
</li>
<li><p> Detachment
</p>
</li>
<li><p> Restricted affect
</p>
</li>
<li><p> Irritability/anger
</p>
</li>
<li><p> Self-destructive/reckless behavior
</p>
</li>
<li><p> Hypervigilance
</p>
</li>
<li><p> Exaggerated startle response
</p>
</li>
<li><p> Difficulty concentrating
</p>
</li>
<li><p> Sleep disturbance
</p>
</li></ul>



<h3>References</h3>

<p>Armour C, Fried EI, Deserno MK, Tsai J, Pietrzak RH (2017).
&ldquo;A network analysis of DSM-5 posttraumatic stress disorder symptoms and correlates in US military veterans.&rdquo;
<em>Journal of anxiety disorders</em>, <b>45</b>, 49&ndash;59.
<a href="https://doi.org/10.31234/osf.io/p69m7">doi:10.31234/osf.io/p69m7</a>.
</p>

<hr>
<h2 id='ptsd_cor1'>Data: Post-Traumatic Stress Disorder (Sample # 1)</h2><span id='topic+ptsd_cor1'></span>

<h3>Description</h3>

<p>A correlation matrix that includes 16 variables. The correlation matrix was estimated from 526
individuals (Fried et al. 2018).
</p>


<h3>Format</h3>

<p>A correlation matrix with 16 variables
</p>


<h3>Details</h3>


<ul>
<li><p> Intrusive Thoughts
</p>
</li>
<li><p> Nightmares
</p>
</li>
<li><p> Flashbacks
</p>
</li>
<li><p> Physiological/psychological reactivity
</p>
</li>
<li><p> Avoidance of thoughts
</p>
</li>
<li><p> Avoidance of situations
</p>
</li>
<li><p> Amnesia
</p>
</li>
<li><p> Disinterest in activities
</p>
</li>
<li><p> Feeling detached
</p>
</li>
<li><p> Emotional numbing
</p>
</li>
<li><p> Foreshortened future
</p>
</li>
<li><p> Sleep problems
</p>
</li>
<li><p> Irritability
</p>
</li>
<li><p> Concentration problems
</p>
</li>
<li><p> Hypervigilance
</p>
</li>
<li><p> Startle response
</p>
</li></ul>



<h3>References</h3>

<p>Fried EI, Eidhof MB, Palic S, Costantini G, Huisman-van Dijk HM, Bockting CL, Engelhard I, Armour C, Nielsen AB, Karstoft K (2018).
&ldquo;Replicability and generalizability of posttraumatic stress disorder (PTSD) networks: a cross-cultural multisite study of PTSD symptoms in four trauma patient samples.&rdquo;
<em>Clinical Psychological Science</em>, <b>6</b>(3), 335&ndash;351.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ptsd_cor1)

Y &lt;- MASS::mvrnorm(n = 526,
                   mu = rep(0, 16),
                   Sigma = ptsd_cor1,
                   empirical = TRUE)

</code></pre>

<hr>
<h2 id='ptsd_cor2'>Data: Post-Traumatic Stress Disorder (Sample # 2)</h2><span id='topic+ptsd_cor2'></span>

<h3>Description</h3>

<p>A correlation matrix that includes 16 variables. The correlation matrix
was estimated from 365 individuals (Fried et al. 2018).
</p>


<h3>Format</h3>

<p>A correlation matrix with 16 variables
</p>


<h3>Details</h3>


<ul>
<li><p> Intrusive Thoughts
</p>
</li>
<li><p> Nightmares
</p>
</li>
<li><p> Flashbacks
</p>
</li>
<li><p> Physiological/psychological reactivity
</p>
</li>
<li><p> Avoidance of thoughts
</p>
</li>
<li><p> Avoidance of situations
</p>
</li>
<li><p> Amnesia
</p>
</li>
<li><p> Disinterest in activities
</p>
</li>
<li><p> Feeling detached
</p>
</li>
<li><p> Emotional numbing
</p>
</li>
<li><p> Foreshortened future
</p>
</li>
<li><p> Sleep problems
</p>
</li>
<li><p> Irritability
</p>
</li>
<li><p> Concentration problems
</p>
</li>
<li><p> Hypervigilance
</p>
</li>
<li><p> Startle response
</p>
</li></ul>



<h3>References</h3>

<p>Fried EI, Eidhof MB, Palic S, Costantini G, Huisman-van Dijk HM, Bockting CL, Engelhard I, Armour C, Nielsen AB, Karstoft K (2018).
&ldquo;Replicability and generalizability of posttraumatic stress disorder (PTSD) networks: a cross-cultural multisite study of PTSD symptoms in four trauma patient samples.&rdquo;
<em>Clinical Psychological Science</em>, <b>6</b>(3), 335&ndash;351.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ptsd_cor2)
Y &lt;- MASS::mvrnorm(n = 365,
                   mu = rep(0, 16),
                   Sigma = ptsd_cor2,
                   empirical = TRUE)
</code></pre>

<hr>
<h2 id='ptsd_cor3'>Data: Post-Traumatic Stress Disorder  (Sample # 3)</h2><span id='topic+ptsd_cor3'></span>

<h3>Description</h3>

<p>A correlation matrix that includes 16 variables. The correlation matrix
was estimated from 926 individuals (Fried et al. 2018).
</p>


<h3>Format</h3>

<p>A correlation matrix with 16 variables
</p>


<h3>Details</h3>


<ul>
<li><p> Intrusive Thoughts
</p>
</li>
<li><p> Nightmares
</p>
</li>
<li><p> Flashbacks
</p>
</li>
<li><p> Physiological/psychological reactivity
</p>
</li>
<li><p> Avoidance of thoughts
</p>
</li>
<li><p> Avoidance of situations
</p>
</li>
<li><p> Amnesia
</p>
</li>
<li><p> Disinterest in activities
</p>
</li>
<li><p> Feeling detached
</p>
</li>
<li><p> Emotional numbing
</p>
</li>
<li><p> Foreshortened future
</p>
</li>
<li><p> Sleep problems
</p>
</li>
<li><p> Irritability
</p>
</li>
<li><p> Concentration problems
</p>
</li>
<li><p> Hypervigilance
</p>
</li>
<li><p> Startle response
</p>
</li></ul>



<h3>References</h3>

<p>Fried EI, Eidhof MB, Palic S, Costantini G, Huisman-van Dijk HM, Bockting CL, Engelhard I, Armour C, Nielsen AB, Karstoft K (2018).
&ldquo;Replicability and generalizability of posttraumatic stress disorder (PTSD) networks: a cross-cultural multisite study of PTSD symptoms in four trauma patient samples.&rdquo;
<em>Clinical Psychological Science</em>, <b>6</b>(3), 335&ndash;351.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ptsd_cor3)
Y &lt;- MASS::mvrnorm(n = 926,
                   mu = rep(0, 16),
                   Sigma = ptsd_cor3,
                   empirical = TRUE)

</code></pre>

<hr>
<h2 id='ptsd_cor4'>Data: Post-Traumatic Stress Disorder  (Sample # 4)</h2><span id='topic+ptsd_cor4'></span>

<h3>Description</h3>

<p>A correlation matrix that includes 16 variables. The correlation matrix
was estimated from 965 individuals (Fried et al. 2018).
</p>


<h3>Format</h3>

<p>A correlation matrix with 16 variables
</p>


<h3>Details</h3>


<ul>
<li><p> Intrusive Thoughts
</p>
</li>
<li><p> Nightmares
</p>
</li>
<li><p> Flashbacks
</p>
</li>
<li><p> Physiological/psychological reactivity
</p>
</li>
<li><p> Avoidance of thoughts
</p>
</li>
<li><p> Avoidance of situations
</p>
</li>
<li><p> Amnesia
</p>
</li>
<li><p> Disinterest in activities
</p>
</li>
<li><p> Feeling detached
</p>
</li>
<li><p> Emotional numbing
</p>
</li>
<li><p> Foreshortened future
</p>
</li>
<li><p> Sleep problems
</p>
</li>
<li><p> Irritability
</p>
</li>
<li><p> Concentration problems
</p>
</li>
<li><p> Hypervigilance
</p>
</li>
<li><p> Startle response
</p>
</li></ul>



<h3>References</h3>

<p>Fried EI, Eidhof MB, Palic S, Costantini G, Huisman-van Dijk HM, Bockting CL, Engelhard I, Armour C, Nielsen AB, Karstoft K (2018).
&ldquo;Replicability and generalizability of posttraumatic stress disorder (PTSD) networks: a cross-cultural multisite study of PTSD symptoms in four trauma patient samples.&rdquo;
<em>Clinical Psychological Science</em>, <b>6</b>(3), 335&ndash;351.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ptsd_cor4)
Y &lt;- MASS::mvrnorm(n = 965,
                   mu = rep(0, 16),
                   Sigma = ptsd_cor4,
                   empirical = TRUE)

</code></pre>

<hr>
<h2 id='regression_summary'>Summarary Method for Multivariate or Univarate Regression</h2><span id='topic+regression_summary'></span>

<h3>Description</h3>

<p>Summarary Method for Multivariate or Univarate Regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regression_summary(object, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regression_summary_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code></p>
</td></tr>
<tr><td><code id="regression_summary_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="regression_summary_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length <em>p</em> including the
summaries for each regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi

Y &lt;- subset(Y, select = c("A1", "A2", 
                          "gender", "education"))

fit_mv_ordinal &lt;- estimate(Y, formula = ~ gender + as.factor(education),
                           type = "continuous",
                           iter = 250,
                           progress = TRUE)

regression_summary(fit_mv_ordinal)

</code></pre>

<hr>
<h2 id='roll_your_own'>Compute Custom Network Statistics</h2><span id='topic+roll_your_own'></span>

<h3>Description</h3>

<p>This function allows for computing custom network statistics for
weighted adjacency matrices (partial correlations). The statistics are computed for
each of the sampled matrices, resulting in a distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roll_your_own(
  object,
  FUN,
  iter = NULL,
  select = FALSE,
  cred = 0.95,
  progress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roll_your_own_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code>.</p>
</td></tr>
<tr><td><code id="roll_your_own_+3A_fun">FUN</code></td>
<td>
<p>A custom function for computing the statistic. The first argument must be
a partial correlation matrix.</p>
</td></tr>
<tr><td><code id="roll_your_own_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to the number in the object).</p>
</td></tr>
<tr><td><code id="roll_your_own_+3A_select">select</code></td>
<td>
<p>Logical. Should the graph be selected ? The default is currently <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="roll_your_own_+3A_cred">cred</code></td>
<td>
<p>Numeric. Credible interval between 0 and 1  (default is 0.95) that is used for selecting the graph.</p>
</td></tr>
<tr><td><code id="roll_your_own_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="roll_your_own_+3A_...">...</code></td>
<td>
<p>Arguments passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user has complete control of this function. Hence, care must be taken as to what <code>FUN</code>
returns and in what format. The function should return a single number (one for the entire GGM)
or a vector (one for each node). This ensures that the print and <code><a href="#topic+plot.roll_your_own">plot.roll_your_own</a></code>
will work.
</p>
<p>When <code>select = TRUE</code>, the graph is selected and then the network statistics are computed based on
the weigthed adjacency matrix. This is accomplished internally by multiplying each of the sampled
partial correlation matrices by the adjacency matrix.
</p>


<h3>Value</h3>

<p>An object defined by <code>FUN</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
####################################
###### example 1: assortment #######
####################################
# assortment
library(assortnet)

Y &lt;- BGGM::bfi[,1:10]
membership &lt;- c(rep("a", 5), rep("c", 5))

# fit model
fit &lt;- estimate(Y = Y, iter = 250,
                progress = FALSE)

# membership
membership &lt;- c(rep("a", 5), rep("c", 5))

# define function
f &lt;- function(x,...){
 assortment.discrete(x, ...)$r
}


net_stat &lt;- roll_your_own(object = fit,
                          FUN = f,
                          types = membership,
                          weighted = TRUE,
                          SE = FALSE, M = 1,
                          progress = FALSE)

# print
net_stat


############################################
###### example 2: expected influence #######
############################################
# expected influence from this package
library(networktools)

# data
Y &lt;- depression

# fit model
fit &lt;- estimate(Y = Y, iter = 250)

# define function
f &lt;- function(x,...){
     expectedInf(x,...)$step1
}

# compute
net_stat &lt;- roll_your_own(object = fit,
                          FUN = f,
                          progress = FALSE)

#######################################
### example 3: mixed data &amp; bridge ####
#######################################
# bridge from this package
library(networktools)

# data
Y &lt;- ptsd[,1:7]

fit &lt;- estimate(Y,
                type = "mixed",
                iter = 250)

# clusters
communities &lt;- substring(colnames(Y), 1, 1)

# function is slow
f &lt;- function(x, ...){
 bridge(x, ...)$`Bridge Strength`
}

net_stat &lt;- roll_your_own(fit,
                          FUN = f,
                          select = TRUE,
                          communities = communities,
                          progress = FALSE)



</code></pre>

<hr>
<h2 id='rsa'>Data: Resilience Scale of Adults (RSA)</h2><span id='topic+rsa'></span>

<h3>Description</h3>

<p>A dataset containing items from the Resilience Scale of Adults (RSA). There are 33 items  and
675 observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("rsa")
</code></pre>


<h3>Format</h3>

<p>A data frame with 28 variables and 1973 observations (5 point Likert scale)
</p>


<h3>Details</h3>


<ul>
<li> <p><code>1</code>  My plans for the future are
</p>
</li>
<li> <p><code>2</code>  When something unforeseen happens
</p>
</li>
<li> <p><code>3</code>  My family understanding of what is important in life is
</p>
</li>
<li> <p><code>4</code>  I feel that my future looks
</p>
</li>
<li> <p><code>5</code>  My goals
</p>
</li>
<li> <p><code>6</code>  I can discuss personal issues with
</p>
</li>
<li> <p><code>7</code>  I feel
</p>
</li>
<li> <p><code>8</code>  I enjoy being
</p>
</li>
<li> <p><code>9</code>  Those who are good at encouraging are
</p>
</li>
<li> <p><code>10</code> The bonds among my friends
</p>
</li>
<li> <p><code>11</code> My personal problems
</p>
</li>
<li> <p><code>12</code> When a family member experiences a crisis/emergency
</p>
</li>
<li> <p><code>13</code> My family is characterised by
</p>
</li>
<li> <p><code>14</code> To be flexible in social settings
</p>
</li>
<li> <p><code>15</code> I get support from
</p>
</li>
<li> <p><code>16</code> In difficult periods my family
</p>
</li>
<li> <p><code>17</code> My judgements and decisions
</p>
</li>
<li> <p><code>18</code> New friendships are something
</p>
</li>
<li> <p><code>19</code> When needed, I have
</p>
</li>
<li> <p><code>20</code> I am at my best when I
</p>
</li>
<li> <p><code>21</code> Meeting new people is
</p>
</li>
<li> <p><code>22</code> When I am with others
</p>
</li>
<li> <p><code>23</code> When I start on new things/projects
</p>
</li>
<li> <p><code>24</code> Facing other people, our family acts
</p>
</li>
<li> <p><code>25</code> Belief in myself
</p>
</li>
<li> <p><code>26</code> For me, thinking of good topics of conversation is
</p>
</li>
<li> <p><code>27</code> My close friends/family members
</p>
</li>
<li> <p><code>28</code> I am good at
</p>
</li>
<li> <p><code>29</code> In my family, we like to
</p>
</li>
<li> <p><code>30</code> Rules and regular routines
</p>
</li>
<li> <p><code>31</code> In difficult periods I have a tendency to
</p>
</li>
<li> <p><code>32</code> My goals for the future are
</p>
</li>
<li> <p><code>33</code> Events in my life that I cannot influence
</p>
</li>
<li> <p><code>gender</code> &quot;M&quot; (male) or &quot;F&quot; (female)
</p>
</li></ul>



<h3>Note</h3>

<p>There are 6 domains
</p>
<p>Planned future: items 1, 4, 5, 32
</p>
<p>Perception of self: items 2, 11, 17, 25, 31, 33
</p>
<p>Family cohesion: items 3, 7, 13, 16, 24, 29
</p>
<p>Social resources: items 6, 9, 10, 12, 15, 19, 27
</p>
<p>Social Competence: items 8, 14, 18, 21, 22, 26,
</p>
<p>Structured style: items 23, 28, 30
</p>


<h3>References</h3>

<p>Briganti, G., &amp; Linkowski, P. (2019). Item and domain network structures of the Resilience
Scale for Adults in 675 university students. Epidemiology and psychiatric sciences, 1-9.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("rsa")

</code></pre>

<hr>
<h2 id='Sachs'>Data: Sachs Network</h2><span id='topic+Sachs'></span>

<h3>Description</h3>

<p>Protein expression in human immune system cells
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Sachs")
</code></pre>


<h3>Format</h3>

<p>A data frame containing 7466 cells (n = 7466) and flow cytometry
measurements of 11 (p = 11) phosphorylated proteins and phospholipids
</p>
<p>@references
Sachs, K., Gifford, D., Jaakkola, T., Sorger, P., &amp; Lauffenburger, D. A. (2002).
Bayesian network approach to cell signaling pathway modeling. Sci. STKE, 2002(148), pe38-pe38.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Sachs")

</code></pre>

<hr>
<h2 id='select'>S3 <code>select</code> method</h2><span id='topic+select'></span>

<h3>Description</h3>

<p>S3 select method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select_+3A_object">object</code></td>
<td>
<p>object of class <code>estimate</code> or<code>explore</code></p>
</td></tr>
<tr><td><code id="select_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>select</code> works with the following methods:
</p>

<ul>
<li> <p><code><a href="#topic+select.estimate">select.estimate</a></code>
</p>
</li>
<li> <p><code><a href="#topic+select.explore">select.explore</a></code>
</p>
</li>
<li> <p><code><a href="#topic+select.ggm_compare_estimate">select.ggm_compare_estimate</a></code>
</p>
</li></ul>


<hr>
<h2 id='select.estimate'>Graph Selection for <code>estimate</code> Objects</h2><span id='topic+select.estimate'></span>

<h3>Description</h3>

<p>Provides the selected graph based on credible intervals for
the partial correlations that did not contain zero
(Williams 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'estimate'
select(object, cred = 0.95, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select.estimate_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate.default</code>.</p>
</td></tr>
<tr><td><code id="select.estimate_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for selecting the graph
(defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="select.estimate_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis. It
must be one of &quot;two.sided&quot; (default), &quot;greater&quot;  or &quot;less&quot;.
See note for futher details.</p>
</td></tr>
<tr><td><code id="select.estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This package was built for the social-behavioral sciences in particular. In these applications, there is
strong theory that expects <em>all</em> effects to be positive. This is known as a &quot;positive manifold&quot; and
this notion has a rich tradition in psychometrics. Hence, this can be incorporated into the graph with
<code>alternative = "greater"</code>. This results in the estimated structure including only positive edges.
</p>


<h3>Value</h3>

<p>The returned object of class <code>select.estimate</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>pcor_adj</code> Selected partial correlation matrix (weighted adjacency).
</p>
</li>
<li> <p><code>adj</code> Adjacency matrix for the selected edges
</p>
</li>
<li> <p><code>object</code> An object of class <code>estimate</code> (the fitted model).
</p>
</li></ul>



<h3>References</h3>

<p>Williams DR (2018).
&ldquo;Bayesian Estimation for Gaussian Graphical Models: Structure Learning, Predictability, and Network Comparisons.&rdquo;
<em>arXiv</em>.
<a href="https://doi.org/10.31234/OSF.IO/X8DPR">doi:10.31234/OSF.IO/X8DPR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estimate">estimate</a></code> and <code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code> for several examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi[,1:10]

# estimate
fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)


# select edge set
E &lt;- select(fit)



</code></pre>

<hr>
<h2 id='select.explore'>Graph selection for <code>explore</code> Objects</h2><span id='topic+select.explore'></span>

<h3>Description</h3>

<p>Provides the selected graph based on the Bayes factor
(Williams and Mulder 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'explore'
select(object, BF_cut = 3, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select.explore_+3A_object">object</code></td>
<td>
<p>An object of class <code>explore.default</code></p>
</td></tr>
<tr><td><code id="select.explore_+3A_bf_cut">BF_cut</code></td>
<td>
<p>Numeric. Threshold for including an edge (defaults to 3).</p>
</td></tr>
<tr><td><code id="select.explore_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis. It
must be one of &quot;two.sided&quot; (default), &quot;greater&quot;, &quot;less&quot;,
or &quot;exhaustive&quot;. See note for further details.</p>
</td></tr>
<tr><td><code id="select.explore_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exhaustive provides the posterior hypothesis probabilities for
a positive, negative, or null relation (see Table 3 in Williams and Mulder 2019).
</p>


<h3>Value</h3>

<p>The returned object of class <code>select.explore</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>
<p><code>alternative = "two.sided"</code>
</p>

<ul>
<li> <p><code>pcor_mat_zero</code> Selected partial correlation matrix (weighted adjacency).
</p>
</li>
<li> <p><code>pcor_mat</code> Partial correlation matrix (posterior mean).
</p>
</li>
<li> <p><code>Adj_10</code> Adjacency matrix for the selected edges.
</p>
</li>
<li> <p><code>Adj_01</code> Adjacency matrix for which there was
evidence for the null hypothesis.
</p>
</li></ul>

<p><code>alternative = "greater"</code> and <code>"less"</code>
</p>

<ul>
<li> <p><code>pcor_mat_zero</code> Selected partial correlation matrix (weighted adjacency).
</p>
</li>
<li> <p><code>pcor_mat</code> Partial correlation matrix (posterior mean).
</p>
</li>
<li> <p><code>Adj_20</code> Adjacency matrix for the selected edges.
</p>
</li>
<li> <p><code>Adj_02</code> Adjacency matrix for which there was
evidence for the null hypothesis (see note).
</p>
</li></ul>

<p><code>alternative = "exhaustive"</code>
</p>

<ul>
<li> <p><code>post_prob</code> A data frame that included the posterior hypothesis probabilities.
</p>
</li>
<li> <p><code>neg_mat</code> Adjacency matrix for which there was evidence for negative edges.
</p>
</li>
<li> <p><code>pos_mat</code> Adjacency matrix for which there was evidence for positive edges.
</p>
</li>
<li> <p><code>neg_mat</code> Adjacency matrix for which there was
evidence for the null hypothesis (see note).
</p>
</li>
<li> <p><code>pcor_mat</code> Partial correlation matrix (posterior mean). The weighted adjacency
matrices can be computed by multiplying <code>pcor_mat</code> with an adjacency matrix.
</p>
</li></ul>



<h3>Note</h3>

<p>Care must be taken with the options <code>alternative = "less"</code> and
<code>alternative = "greater"</code>. This is because the full parameter space is not included,
such, for  <code>alternative = "greater"</code>, there can be evidence for the &quot;null&quot; when
the relation is negative. This inference is correct: the null model better predicted
the data than the positive model. But note this is relative and does <strong>not</strong>
provide absolute evidence for the null hypothesis.
</p>


<h3>References</h3>

<p>Williams DR, Mulder J (2019).
&ldquo;Bayesian Hypothesis Testing for Gaussian Graphical Models: Conditional Independence and Order Constraints.&rdquo;
<em>PsyArXiv</em>.
<a href="https://doi.org/10.31234/osf.io/ypxd8">doi:10.31234/osf.io/ypxd8</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+explore">explore</a></code> and <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> for several examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

#################
### example 1 ###
#################

#  data
Y &lt;- bfi[,1:10]

# fit model
fit &lt;- explore(Y, progress = FALSE)

# edge set
E &lt;- select(fit,
            alternative = "exhaustive")


</code></pre>

<hr>
<h2 id='select.ggm_compare_estimate'>Graph Selection for <code>ggm_compare_estimate</code> Objects</h2><span id='topic+select.ggm_compare_estimate'></span>

<h3>Description</h3>

<p>Provides the selected graph (of differences) based on credible intervals for
the partial correlations that did not contain zero
(Williams 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ggm_compare_estimate'
select(object, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select.ggm_compare_estimate_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate.default</code>.</p>
</td></tr>
<tr><td><code id="select.ggm_compare_estimate_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for selecting the graph
(defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="select.ggm_compare_estimate_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned object of class <code>select.ggm_compare_estimate</code> contains a lot of information that
is used for printing and plotting the results. For users of <strong>BGGM</strong>, the following
are the useful objects:
</p>

<ul>
<li> <p><code>mean_diff</code> A list of matrices for each group comparsion (partial correlation differences).
</p>
</li>
<li> <p><code>pcor_adj</code> A list of weighted adjacency matrices for each group comparsion.
</p>
</li>
<li> <p><code>adj</code> A list of adjacency matrices for each group comparsion.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes
##################
### example 1: ###
##################
# data
Y &lt;- bfi

# males and females
Ymale &lt;- subset(Y, gender == 1,
               select = -c(gender,
                           education))

Yfemale &lt;- subset(Y, gender == 2,
                  select = -c(gender,
                              education))

# fit model
fit &lt;- ggm_compare_estimate(Ymale, Yfemale,
                           type = "continuous",
                           iter = 250,
                           progress = FALSE)


E &lt;- select(fit)


</code></pre>

<hr>
<h2 id='select.ggm_compare_explore'>Graph selection for <code>ggm_compare_explore</code> Objects</h2><span id='topic+select.ggm_compare_explore'></span>

<h3>Description</h3>

<p>Provides the selected graph (of differences) based on the Bayes factor
(Williams et al. 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ggm_compare_explore'
select(object, BF_cut = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select.ggm_compare_explore_+3A_object">object</code></td>
<td>
<p>An object of class <code>ggm_compare_explore</code>.</p>
</td></tr>
<tr><td><code id="select.ggm_compare_explore_+3A_bf_cut">BF_cut</code></td>
<td>
<p>Numeric. Threshold for including an edge (defaults to 3).</p>
</td></tr>
<tr><td><code id="select.ggm_compare_explore_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned object of class <code>select.ggm_compare_explore</code> contains
a lot of information that is used for printing and plotting the results.
For users of <strong>BGGM</strong>, the following are the useful objects:
</p>

<ul>
<li> <p><code>adj_10</code> Adjacency matrix for which there was evidence for a difference.
</p>
</li>
<li> <p><code>adj_10</code> Adjacency matrix for which there was evidence for a null relation
</p>
</li>
<li> <p><code>pcor_mat_10</code> Selected partial correlation matrix (weighted adjacency; only for two groups).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+explore">explore</a></code> and <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> for several examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##################
### example 1: ###
##################
# data
Y &lt;- bfi

# males and females
Ymale &lt;- subset(Y, gender == 1,
                   select = -c(gender,
                               education))[,1:10]

Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(gender,
                                 education))[,1:10]

# fit model
fit &lt;- ggm_compare_explore(Ymale, Yfemale,
                           iter = 250,
                           type = "continuous",
                           progress = FALSE)


E &lt;- select(fit, post_prob = 0.50)



</code></pre>

<hr>
<h2 id='select.var_estimate'>Graph Selection for <code>var.estimate</code> Object</h2><span id='topic+select.var_estimate'></span>

<h3>Description</h3>

<p>Graph Selection for <code>var.estimate</code> Object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'var_estimate'
select(object, cred = 0.95, alternative = "two.sided", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select.var_estimate_+3A_object">object</code></td>
<td>
<p>An object of class <code>VAR.estimate</code>.</p>
</td></tr>
<tr><td><code id="select.var_estimate_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for selecting the graph
(defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="select.var_estimate_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis. It
must be one of &quot;two.sided&quot; (default), &quot;greater&quot;  or &quot;less&quot;.
See note for futher details.</p>
</td></tr>
<tr><td><code id="select.var_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>select.var_estimate</code>, including
</p>

<ul>
<li> <p>pcor_adj Adjacency matrix for the partial correlations.
</p>
</li>
<li> <p>beta_adj Adjacency matrix for the regression coefficients.
</p>
</li>
<li> <p>pcor_weighted_adj Weighted adjacency matrix for the partial correlations.
</p>
</li>
<li> <p>beta_weighted_adj Weighted adjacency matrix for the regression coefficients.
</p>
</li>
<li> <p><code>pcor_mu</code> Partial correlation matrix (posterior mean).
</p>
</li>
<li> <p><code>beta_mu</code> A matrix including the regression coefficients (posterior mean).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- subset(ifit, id == 1)[,-1]

# fit model with alias (var_estimate also works)
fit &lt;- var_estimate(Y, progress = FALSE)

# select graphs
select(fit, cred = 0.95)


</code></pre>

<hr>
<h2 id='summary.coef'>Summarize <code>coef</code> Objects</h2><span id='topic+summary.coef'></span>

<h3>Description</h3>

<p>Summarize regression parameters with the posterior mean,
standard deviation, and credible interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coef'
summary(object, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.coef_+3A_object">object</code></td>
<td>
<p>An object of class <code>coef</code>.</p>
</td></tr>
<tr><td><code id="summary.coef_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="summary.coef_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length <em>p</em> including the
summaries for each multiple regression.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+coef.estimate">coef.estimate</a></code> and <code><a href="#topic+coef.explore">coef.explore</a></code> for examples.
</p>

<hr>
<h2 id='summary.estimate'>Summary method for <code>estimate.default</code> objects</h2><span id='topic+summary.estimate'></span>

<h3>Description</h3>

<p>Summarize the posterior distribution of each partial correlation
with the posterior mean and standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'estimate'
summary(object, col_names = TRUE, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.estimate_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code></p>
</td></tr>
<tr><td><code id="summary.estimate_+3A_col_names">col_names</code></td>
<td>
<p>Logical. Should the summary include the column names (default is <code>TRUE</code>)?
Setting to <code>FALSE</code> includes the column numbers (e.g., <code>1--2</code>).</p>
</td></tr>
<tr><td><code id="summary.estimate_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="summary.estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the summarized posterior distributions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estimate">estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- ptsd[,1:5]

fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)

summary(fit)



</code></pre>

<hr>
<h2 id='summary.explore'>Summary Method for <code>explore.default</code> Objects</h2><span id='topic+summary.explore'></span>

<h3>Description</h3>

<p>Summarize the posterior distribution for each partial correlation
with the posterior mean and standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'explore'
summary(object, col_names = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.explore_+3A_object">object</code></td>
<td>
<p>An object of class <code>estimate</code></p>
</td></tr>
<tr><td><code id="summary.explore_+3A_col_names">col_names</code></td>
<td>
<p>Logical. Should the summary include the column names (default is <code>TRUE</code>)?
Setting to <code>FALSE</code> includes the column numbers (e.g., <code>1--2</code>).</p>
</td></tr>
<tr><td><code id="summary.explore_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the summarized posterior distributions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+select.explore">select.explore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

Y &lt;- ptsd[,1:5]

fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

summ &lt;- summary(fit)

summ

</code></pre>

<hr>
<h2 id='summary.ggm_compare_estimate'>Summary method for <code>ggm_compare_estimate</code> objects</h2><span id='topic+summary.ggm_compare_estimate'></span>

<h3>Description</h3>

<p>Summarize the posterior distribution of each partial correlation
difference with the posterior mean and standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ggm_compare_estimate'
summary(object, col_names = TRUE, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ggm_compare_estimate_+3A_object">object</code></td>
<td>
<p>An object of class <code>ggm_compare_estimate</code>.</p>
</td></tr>
<tr><td><code id="summary.ggm_compare_estimate_+3A_col_names">col_names</code></td>
<td>
<p>Logical. Should the summary include the column names (default is <code>TRUE</code>)?
Setting to <code>FALSE</code> includes the column numbers (e.g., <code>1--2</code>).</p>
</td></tr>
<tr><td><code id="summary.ggm_compare_estimate_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="summary.ggm_compare_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the summarized posterior distributions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes
# data
Y &lt;- bfi

# males and females
Ymale &lt;- subset(Y, gender == 1,
                select = -c(gender,
                            education))[,1:5]

Yfemale &lt;- subset(Y, gender == 2,
                  select = -c(gender,
                              education))[,1:5]

# fit model
fit &lt;- ggm_compare_estimate(Ymale,  Yfemale,
                            type = "continuous",
                            iter = 250,
                            progress = FALSE)

summary(fit)

</code></pre>

<hr>
<h2 id='summary.ggm_compare_explore'>Summary Method for <code>ggm_compare_explore</code> Objects</h2><span id='topic+summary.ggm_compare_explore'></span>

<h3>Description</h3>

<p>Summarize the posterior hypothesis probabilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ggm_compare_explore'
summary(object, col_names = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ggm_compare_explore_+3A_object">object</code></td>
<td>
<p>An object of class <code>ggm_compare_explore</code>.</p>
</td></tr>
<tr><td><code id="summary.ggm_compare_explore_+3A_col_names">col_names</code></td>
<td>
<p>Logical. Should the summary include the column names (default is <code>TRUE</code>)?
Setting to <code>FALSE</code> includes the column numbers (e.g., <code>1--2</code>).</p>
</td></tr>
<tr><td><code id="summary.ggm_compare_explore_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.ggm_compare_explore</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

# data
Y &lt;- bfi[complete.cases(bfi),]

# males and females
Ymale &lt;- subset(Y, gender == 1,
                   select = -c(gender,
                               education))[,1:10]

Yfemale &lt;- subset(Y, gender == 2,
                     select = -c(gender,
                                 education))[,1:10]

##########################
### example 1: ordinal ###
##########################

# fit model
fit &lt;- ggm_compare_explore(Ymale,  Yfemale,
                           type = "ordinal",
                           iter = 250,
                           progress = FALSE)
# summary
summ &lt;- summary(fit)

summ

</code></pre>

<hr>
<h2 id='summary.predictability'>Summary Method for <code>predictability</code> Objects</h2><span id='topic+summary.predictability'></span>

<h3>Description</h3>

<p>Summary Method for <code>predictability</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predictability'
summary(object, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.predictability_+3A_object">object</code></td>
<td>
<p>An object of class <code>predictability</code>.</p>
</td></tr>
<tr><td><code id="summary.predictability_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="summary.predictability_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
Y &lt;- ptsd[,1:5]

fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

r2 &lt;- predictability(fit, iter = 250,
                     progress = FALSE)

summary(r2)



</code></pre>

<hr>
<h2 id='summary.select.explore'>Summary Method for <code>select.explore</code> Objects</h2><span id='topic+summary.select.explore'></span>

<h3>Description</h3>

<p>Summary Method for <code>select.explore</code> Objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'select.explore'
summary(object, col_names = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.select.explore_+3A_object">object</code></td>
<td>
<p>object of class <code>select.explore</code>.</p>
</td></tr>
<tr><td><code id="summary.select.explore_+3A_col_names">col_names</code></td>
<td>
<p>Logical.</p>
</td></tr>
<tr><td><code id="summary.select.explore_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame including the posterior mean, standard deviation,
and posterior hypothesis probabilities for each relation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#  data
Y &lt;- bfi[,1:10]

# fit model
fit &lt;- explore(Y, iter = 250,
               progress = FALSE)

# edge set
E &lt;- select(fit,
            alternative = "exhaustive")

summary(E)


</code></pre>

<hr>
<h2 id='summary.var_estimate'>Summary Method for <code>var_estimate</code> Objects</h2><span id='topic+summary.var_estimate'></span>

<h3>Description</h3>

<p>Summarize the posterior distribution of each partial correlation
and regression coefficient with the posterior mean, standard deviation, and
credible intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'var_estimate'
summary(object, cred = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.var_estimate_+3A_object">object</code></td>
<td>
<p>An object of class <code>var_estimate</code></p>
</td></tr>
<tr><td><code id="summary.var_estimate_+3A_cred">cred</code></td>
<td>
<p>Numeric. The credible interval width for summarizing the posterior
distributions (defaults to 0.95; must be between 0 and 1).</p>
</td></tr>
<tr><td><code id="summary.var_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the summarized posterior distributions,
including both the partial correlations and the regression coefficients.
</p>

<ul>
<li> <p><code>pcor_results</code> A data frame including the summarized partial correlations
</p>
</li>
<li> <p><code>beta_results</code> A list containing the summarized regression coefficients (one
data frame for each outcome)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+var_estimate">var_estimate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- subset(ifit, id == 1)[,-1]

# fit model with alias (var_estimate also works)
fit &lt;- var_estimate(Y, progress = FALSE)

# summary ('pcor')
print(
summary(fit, cred = 0.95),
param = "pcor",
)


# summary ('beta')
print(
summary(fit, cred = 0.95),
param = "beta",
)


</code></pre>

<hr>
<h2 id='tas'>Data: Toronto Alexithymia Scale (TAS)</h2><span id='topic+tas'></span>

<h3>Description</h3>

<p>A dataset containing items from the Toronto Alexithymia Scale (TAS). There are 20 variables  and
1925 observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tas")
</code></pre>


<h3>Format</h3>

<p>A data frame with 20 variables and 1925 observations (5 point Likert scale)
</p>


<h3>Details</h3>


<ul>
<li> <p><code>1</code> I am often confused about what emotion I am feeling
</p>
</li>
<li> <p><code>2</code>  It is difficult for me to find the right words for my feelings
</p>
</li>
<li> <p><code>3</code> I have physical sensations that even doctors don’t understand
</p>
</li>
<li> <p><code>4</code> I am able to describe my feelings easily
</p>
</li>
<li> <p><code>5</code> I prefer to analyze problems rather than just describe them
</p>
</li>
<li> <p><code>6</code> When I am upset, I don’t know if I am sad, frightened, or angry
</p>
</li>
<li> <p><code>7</code>  I am often puzzled by sensations in my body
</p>
</li>
<li> <p><code>8</code> I prefer just to let things happen rather than to understand why they turned out that way
</p>
</li>
<li> <p><code>9</code>  I have feelings that I can’t quite identify
</p>
</li>
<li> <p><code>10</code> Being in touch with emotions is essential
</p>
</li>
<li> <p><code>11</code>  I find it hard to describe how I feel about people
</p>
</li>
<li> <p><code>12</code> People tell me to describe my feelings more
</p>
</li>
<li> <p><code>13</code> I don’t know what’s going on inside me
</p>
</li>
<li> <p><code>14</code> I often don’t know why I am angry
</p>
</li>
<li> <p><code>15</code> I prefer talking to people about their daily activities rather than their feelings
</p>
</li>
<li> <p><code>16</code>  I prefer to watch “light” entertainment shows rather than psychological dramas
</p>
</li>
<li> <p><code>17</code> It is difficult for me to reveal my innermost feelings, even to close friends
</p>
</li>
<li> <p><code>18</code>  I can feel close to someone, even in moments of silence
</p>
</li>
<li> <p><code>19</code>  I find examination of my feelings useful in solving personal problems
</p>
</li>
<li> <p><code>20</code> Looking for hidden meanings in movies or plays distracts from their enjoyment
</p>
</li>
<li> <p><code>gender</code> &quot;M&quot; (male) or &quot;F&quot; (female)
</p>
</li></ul>



<h3>Note</h3>

<p>There are three domains
</p>
<p>Difficulty identifying feelings: items 1, 3, 6, 7, 9, 13, 14
</p>
<p>Difficulty describing feelings: items 2, 4, 11, 12, 17
</p>
<p>Externally oriented thinking: items 10, 15, 16, 18, 19
</p>


<h3>References</h3>

<p>Briganti, G., &amp; Linkowski, P. (2019). Network approach to items and domains from
the Toronto Alexithymia Scale. Psychological reports.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("tas")

</code></pre>

<hr>
<h2 id='var_estimate'>VAR: Estimation</h2><span id='topic+var_estimate'></span>

<h3>Description</h3>

<p>Estimate VAR(1) models by efficiently sampling from the posterior distribution. This
provides two graphical structures: (1) a network of undirected relations (the GGM, controlling for the
lagged predictors) and (2) a network of directed relations (the lagged coefficients). Note that
in the graphical modeling literature, this model is also known as a time series chain graphical model
(Abegaz and Wit 2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_estimate(
  Y,
  rho_sd = sqrt(1/3),
  beta_sd = 1,
  iter = 5000,
  progress = TRUE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_estimate_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="var_estimate_+3A_rho_sd">rho_sd</code></td>
<td>
<p>Numeric. Scale of the prior distribution for the partial correlations,
approximately the standard deviation of a beta distribution
(defaults to sqrt(1/3) as this results to delta = 2, and a uniform distribution across the partial correlations).</p>
</td></tr>
<tr><td><code id="var_estimate_+3A_beta_sd">beta_sd</code></td>
<td>
<p>Numeric. Standard deviation of the prior distribution for the regression coefficients
(defaults to 1). The prior is by default centered at zero and follows a normal distribution
(Equation 9, Sinay and Hsu 2014)</p>
</td></tr>
<tr><td><code id="var_estimate_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="var_estimate_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
<tr><td><code id="var_estimate_+3A_seed">seed</code></td>
<td>
<p>An integer for the random seed (defaults to 1).</p>
</td></tr>
<tr><td><code id="var_estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each time series in <code>Y</code> is standardized (mean  = 0; standard deviation = 1).
</p>


<h3>Value</h3>

<p>An object of class <code>var_estimate</code> containing a lot of information that is
used for printing and plotting the results. For users of <strong>BGGM</strong>, the following are the
useful objects:
</p>

<ul>
<li> <p><code>beta_mu</code> A matrix including the regression coefficients (posterior mean).
</p>
</li>
<li> <p><code>pcor_mu</code> Partial correlation matrix (posterior mean).
</p>
</li>
<li> <p><code>fit</code> A list including the posterior samples.
</p>
</li></ul>



<h3>Note</h3>

<p><strong>Regularization</strong>:
</p>
<p>A Bayesian ridge regression can be fitted by decreasing <code>beta_sd</code>
(e.g., <code>beta_sd = 0.25</code>). This could be advantageous for forecasting
(out-of-sample prediction) in particular.
</p>


<h3>References</h3>

<p>Abegaz F, Wit E (2013).
&ldquo;Sparse time series chain graphical models for reconstructing genetic networks.&rdquo;
<em>Biostatistics</em>, <b>14</b>(3), 586&ndash;599.
<a href="https://doi.org/10.1093/biostatistics/kxt005">doi:10.1093/biostatistics/kxt005</a>.<br /><br /> Sinay MS, Hsu JS (2014).
&ldquo;Bayesian inference of a multivariate regression model.&rdquo;
<em>Journal of Probability and Statistics</em>, <b>2014</b>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data
Y &lt;- subset(ifit, id == 1)[,-1]

# use alias (var_estimate also works)
fit &lt;- var_estimate(Y, progress = FALSE)

fit


</code></pre>

<hr>
<h2 id='weighted_adj_mat'>Extract the Weighted Adjacency Matrix</h2><span id='topic+weighted_adj_mat'></span>

<h3>Description</h3>

<p>Extract the weighted adjacency matrix (posterior mean) from
<code><a href="#topic+estimate">estimate</a></code>, <code><a href="#topic+explore">explore</a></code>, <code><a href="#topic+ggm_compare_estimate">ggm_compare_estimate</a></code>,
and <code><a href="#topic+ggm_compare_explore">ggm_compare_explore</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted_adj_mat(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted_adj_mat_+3A_object">object</code></td>
<td>
<p>A model estimated with <strong>BGGM</strong>. All classes are supported, assuming
there is matrix to be extracted.</p>
</td></tr>
<tr><td><code id="weighted_adj_mat_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The weighted adjacency matrix (partial correlation matrix with zeros).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes
Y &lt;- bfi[,1:5]

# estimate
fit &lt;- estimate(Y, iter = 250,
                progress = FALSE)

# select graph
E &lt;- select(fit)

# extract weighted adj matrix
weighted_adj_mat(E)


</code></pre>

<hr>
<h2 id='women_math'>Data: Women and Mathematics</h2><span id='topic+women_math'></span>

<h3>Description</h3>

<p>A data frame containing 1190 observations (n = 1190) and 6 variables (p = 6) measured on the binary scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("women_math")
</code></pre>


<h3>Format</h3>

<p>A data frame containing 1190 observations (n = 1190) and 6 variables (p = 6) measured on the binary scale
(Fowlkes et al. 1988). These data have been analyzed in Tarantola (2004)
and in (Madigan and Raftery 1994). The variable descriptions were copied from  (section 5.2 )
(section 5.2, Talhouk et al. 2012)
</p>


<h3>Details</h3>


<ul>
<li> <p><code>1</code>  Lecture attendance (attend/did not attend)
</p>
</li>
<li> <p><code>2</code>  Gender (male/female)
</p>
</li>
<li> <p><code>3</code>  School type (urban/suburban)
</p>
</li>
<li> <p><code>4</code>  “I will be needing Mathematics in my future work” (agree/disagree)
</p>
</li>
<li> <p><code>5</code>  Subject preference (math/science vs. liberal arts)
</p>
</li>
<li> <p><code>6</code> Future plans (college/job)
</p>
</li></ul>



<h3>References</h3>

<p>Fowlkes EB, Freeny AE, Landwehr JM (1988).
&ldquo;Evaluating logistic models for large contingency tables.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>83</b>(403), 611&ndash;622.<br /><br /> Madigan D, Raftery AE (1994).
&ldquo;Model selection and accounting for model uncertainty in graphical models using Occam's window.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>89</b>(428), 1535&ndash;1546.<br /><br /> Talhouk A, Doucet A, Murphy K (2012).
&ldquo;Efficient Bayesian inference for multivariate probit models with sparse inverse correlation matrices.&rdquo;
<em>Journal of Computational and Graphical Statistics</em>, <b>21</b>(3), 739&ndash;757.<br /><br /> Tarantola C (2004).
&ldquo;MCMC model determination for discrete graphical models.&rdquo;
<em>Statistical Modelling</em>, <b>4</b>(1), 39&ndash;61.
<a href="https://doi.org/10.1191/1471082x04st063oa">doi:10.1191/1471082x04st063oa</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("women_math")
</code></pre>

<hr>
<h2 id='zero_order_cors'>Zero-Order Correlations</h2><span id='topic+zero_order_cors'></span>

<h3>Description</h3>

<p>Estimate zero-order correlations for any type of data. Note zero-order refers to the fact that
no variables are controlled for (i.e., bivariate correlations). To our knowledge, this is the only Bayesian
implementation in <code>R</code> that can estiamte Pearson's,  tetrachoric (binary), polychoric
(ordinal with more than two cateogries), and rank based correlation coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zero_order_cors(
  Y,
  type = "continuous",
  iter = 5000,
  mixed_type = NULL,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zero_order_cors_+3A_y">Y</code></td>
<td>
<p>Matrix (or data frame) of dimensions <em>n</em> (observations) by  <em>p</em> (variables).</p>
</td></tr>
<tr><td><code id="zero_order_cors_+3A_type">type</code></td>
<td>
<p>Character string. Which type of data for <code>Y</code> ? The options include <code>continuous</code>,
<code>binary</code>, <code>ordinal</code>, or <code>mixed</code>. See the note for further details.</p>
</td></tr>
<tr><td><code id="zero_order_cors_+3A_iter">iter</code></td>
<td>
<p>Number of iterations (posterior samples; defaults to 5000).</p>
</td></tr>
<tr><td><code id="zero_order_cors_+3A_mixed_type">mixed_type</code></td>
<td>
<p>Numeric vector. An indicator of length p for which varibles should be treated as ranks.
(1 for rank and 0 to assume normality). The default is currently to treat all integer variables as ranks
when <code>type = "mixed"</code> and <code>NULL</code> otherwise. See note for further details.</p>
</td></tr>
<tr><td><code id="zero_order_cors_+3A_progress">progress</code></td>
<td>
<p>Logical. Should a progress bar be included (defaults to <code>TRUE</code>) ?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Mixed Type</strong>:
</p>
<p>The term &quot;mixed&quot; is somewhat of a misnomer, because the method can be used for data including <em>only</em>
continuous or <em>only</em> discrete variables. This is based on the ranked likelihood which requires sampling
the ranks for each variable (i.e., the data is not merely transformed to ranks). This is computationally
expensive when there are many levels. For example, with continuous data, there are as many ranks
as data points!
</p>
<p>The option <code>mixed_type</code> allows the user to determine  which variable should be treated as ranks
and the &quot;emprical&quot; distribution is used otherwise (Hoff 2007). This is
accomplished by specifying an indicator vector of length <em>p</em>. A one indicates to use the ranks,
whereas a zero indicates to &quot;ignore&quot; that variable. By default all integer variables are treated as ranks.
</p>
<p><strong>Dealing with Errors</strong>:
</p>
<p>An error is most likely to arise when <code>type = "ordinal"</code>. The are two common errors (although still rare):
</p>

<ul>
<li><p> The first is due to sampling the thresholds, especially when the data is heavily skewed.
This can result in an ill-defined matrix. If this occurs, we recommend to first try
decreasing <code>prior_sd</code> (i.e., a more informative prior). If that does not work, then
change the data type to <code>type = mixed</code> which then estimates a copula GGM
(this method can be used for data containing <strong>only</strong> ordinal variable). This should
work without a problem.
</p>
</li>
<li><p>  The second is due to how the ordinal data are categorized. For example, if the error states
that the index is out of bounds, this indicates that the first category is a zero. This is not allowed, as
the first category must be one. This is addressed by adding one (e.g., <code>Y + 1</code>) to the data matrix.
</p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><code>R</code> An array including the correlation matrices
(of dimensions <em>p</em> by <em>p</em> by <em>iter</em>)
</p>
</li>
<li> <p><code>R_mean</code> Posterior mean of the correlations (of dimensions <em>p</em> by <em>p</em>)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# note: iter = 250 for demonstrative purposes

Y &lt;- ptsd[,1:3]

#################################
####### example 1: Pearson's ####
#################################

fit &lt;- zero_order_cors(Y, type = "continuous",
                       iter = 250,
                       progress = FALSE)


#################################
###### example 2: polychoric ####
#################################

fit &lt;- zero_order_cors(Y+1, type = "ordinal",
                       iter = 250,
                       progress = FALSE)


###########################
##### example 3: rank #####
###########################

fit &lt;- zero_order_cors(Y+1, type = "mixed",
                       iter = 250,
                       progress = FALSE)

############################
## example 4: tetrachoric ##
############################

# binary data
Y &lt;- women_math[,1:3]

fit &lt;- zero_order_cors(Y, type = "binary",
                       iter = 250,
                       progress = FALSE)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
