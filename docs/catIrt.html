<!DOCTYPE html><html lang="en"><head><title>Help for package catIrt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {catIrt}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#catIrt-package'><p>Simulate IRT-Based Computerized Adaptive Tests (CATs)</p></a></li>
<li><a href='#catIrt'><p>Simulate Computerized Adaptive Tests (CATs)</p></a></li>
<li><a href='#FI'><p>Calculate Expected and Observed Fisher Information for IRT Models</p></a></li>
<li><a href='#itChoose'><p>Choose the Next Item in a CAT</p></a></li>
<li><a href='#KL'><p>Calculate Kullback-Leibler Divergence for IRT Models</p></a></li>
<li><a href='#mleEst'><p>Estimate Ability in IRT Models</p></a></li>
<li><a href='#simIrt'><p>Simulate Responses to IRT Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Simulate IRT-Based Computerized Adaptive Tests</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Steven Nydick &lt;swnydick@gmail.com&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/swnydick/catIrt">https://github.com/swnydick/catIrt</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/swnydick/catIrt/issues">https://github.com/swnydick/catIrt/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.11.0), numDeriv (&ge; 2012.3-1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>irtoys, ltm, catR</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions designed to simulate data that conform to basic
          unidimensional IRT models (for now 3-parameter binary response models
          and graded response models) along with Post-Hoc CAT simulations of
          those models given various item selection methods, ability estimation
          methods, and termination criteria. See
          Wainer (2000) &lt;<a href="https://doi.org/10.4324%2F9781410605931">doi:10.4324/9781410605931</a>&gt;,
          van der Linden &amp; Pashley (2010) &lt;<a href="https://doi.org/10.1007%2F978-0-387-85461-8_1">doi:10.1007/978-0-387-85461-8_1</a>&gt;,
          and Eggen (1999) &lt;<a href="https://doi.org/10.1177%2F01466219922031365">doi:10.1177/01466219922031365</a>&gt; for more details.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-25 22:16:59 UTC; stevennydick</td>
</tr>
<tr>
<td>Author:</td>
<td>Steven Nydick <a href="https://orcid.org/0000-0002-2908-1188"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-25 22:50:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='catIrt-package'>Simulate IRT-Based Computerized Adaptive Tests (CATs)</h2><span id='topic+catIrt-package'></span>

<h3>Description</h3>

<p><code>catIrt</code> provides methods for simulating Computerized Adaptive Tests,
including response simulation, item selection methods, ability estimation methods,
and test termination methods.  Unique in <code>catIrt</code> is support for the graded
response model (and, soon, other polytomous models) along with expanding support
for classification CAT (including an implementation of the SPRT, GLR, and CI methods).
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package:  </td><td style="text-align: left;"> catIrt</td>
</tr>
<tr>
 <td style="text-align: left;">
Type:     </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version:  </td><td style="text-align: left;"> 0.5-0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date:     </td><td style="text-align: left;"> 2014-10-04</td>
</tr>
<tr>
 <td style="text-align: left;">
License:  </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Maintainer: Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>

<hr>
<h2 id='catIrt'>Simulate Computerized Adaptive Tests (CATs)</h2><span id='topic+catIrt'></span><span id='topic+summary.catIrt'></span><span id='topic+plot.catIrt'></span><span id='topic+print.catIrt'></span>

<h3>Description</h3>

<p><code>catIrt</code> simulates Computerized Adaptive Tests (CATs) given a vector/matrix of
responses or a vector of ability values, a matrix of item parameters, and several
item selection mechanisms, estimation procedures, and termination criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catIrt( params, mod = c("brm", "grm"),
        resp = NULL,
        theta = NULL,
        catStart = list( n.start = 5, init.theta = 0,
                         select = c("UW-FI", "LW-FI", "PW-FI",
                                    "FP-KL", "VP-KL", "FI-KL", "VI-KL",
                                    "random"),
                         at = c("theta", "bounds"),
                         it.range = NULL, n.select = 1,
                         delta = .1,
                         score = c("fixed", "step", "random", "WLE", "BME", "EAP"),
                         range = c(-1, 1),
                         step.size = 3, leave.after.MLE = FALSE ),
        catMiddle = list( select = c("UW-FI", "LW-FI", "PW-FI",
                                     "FP-KL", "VP-KL", "FI-KL", "VI-KL",
                                     "random"),
                          at = c("theta", "bounds"),
                          it.range = NULL, n.select = 1,
                          delta = .1,
                          score = c("MLE", "WLE", "BME", "EAP"),
                          range = c(-6, 6),
                          expos = c("none", "SH") ),
        catTerm = list( term = c("fixed", "precision", "info", "class"),
                        score = c("MLE", "WLE", "BME", "EAP"),
                        n.min = 5, n.max = 50,
                        p.term = list(method = c("threshold", "change"),
                                      crit = .25),
                        i.term = list(method = c("threshold", "change"),
                                      crit = 2), 
                        c.term = list(method = c("SPRT", "GLR", "CI"),
                                      bounds = c(-1, 1),
                                      categ = c(0, 1, 2),
                                      delta = .1,
                                      alpha = .05, beta = .05,
                                      conf.lev = .95) ),
        ddist = dnorm,
        progress = TRUE, ... )
## S3 method for class 'catIrt'
summary( object, group = TRUE, ids = "none", ... )
## S3 method for class 'catIrt'
plot( x, which = "all", ids = "none", 
      conf.lev = .95, legend = TRUE, ask = TRUE, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="catIrt_+3A_object">object</code>, <code id="catIrt_+3A_x">x</code></td>
<td>
<p>a <code>catIrt</code> object.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_params">params</code></td>
<td>
<p><b>numeric:</b> a matrix of item parameters.  If specified as a matrix,
the rows must index the items, and the columns must designate the item
parameters.  For the binary response model, <code>params</code> must either
be a 3-column matrix (if not using item exposure control), a 4-5-column
matrix (with Sympson-Hetter parameters as the last column if using item
exposure control), or a 4-5-column matrix (if including the item number
as the first column).  See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_mod">mod</code></td>
<td>
<p><b>character:</b> a character string indicating the IRT model.  Current support
is for the 3-parameter binary response model (<span class="option">"brm"</span>),
and Samejima's graded response model (<span class="option">"grm"</span>).  The contents
of <code>params</code> must match the designation of <code>mod</code>.  If <code>mod</code> is
left blank, it will be designated the class of <code>resp</code> (if <code>resp</code> inherits
either <span class="option">"brm"</span> or <span class="option">"grm"</span>), and if that fails, it will ask the user (if in
interactive mode) or error.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_resp">resp</code></td>
<td>
<p><b>numeric:</b> either a <code class="reqn">N \times J</code> matrix (where <code class="reqn">N</code> indicates the
number of simulees and <code class="reqn">J</code> indicates the number of items), a <code class="reqn">J</code>
length vector (if there is only one simulee), or NULL if specifying <code>thetas</code>.
For the binary response model (<span class="option">"brm"</span>), <code>resp</code> must solely contain 0s
and 1s.  For the graded response model (<span class="option">"grm"</span>), <code>resp</code> must solely contain
integers <code class="reqn">1, \ldots, K</code>, where <code class="reqn">K</code> is the number of categories, as
indicated by the dimension of <code>params</code>.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_theta">theta</code></td>
<td>
<p><b>numeric:</b> either a <code class="reqn">N</code>-dimensional vector (where <code class="reqn">N</code> indicates the
number of simulees) or NULL if specifying <code>resp</code>.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_catstart">catStart</code></td>
<td>
<p><b>list:</b> a list of options for starting the CAT including:
</p>

<ol>
<li> <p><code>n.start</code>: a scalar indicating the number of items that are used for each 
simulee at the beginning of the CAT.  After <span class="option">n.start</span> reaches the specified value,
the CAT will shift to the middle set of parameters.
</p>
</li>
<li> <p><code>init.theta</code>: a scalar or vector of initial starting estimates of <code class="reqn">\theta</code>.
If <code>init.theta</code> is a scalar, every simulee will have the same starting value.
Otherwise, simulees will have different starting values based on the respective element
of <code>init.theta</code>.
</p>
</li>
<li> <p><code>select</code>: a character string indicating the item selection method for the 
first few items.  Items can be selected either through maximum Fisher information or
Kullback-Leibler divergence methods or randomly.  The Fisher information methods include
</p>

<ul>
<li> <p><span class="option">"UW-FI"</span>: unweighted Fisher information at a point.
</p>
</li>
<li> <p><span class="option">"LW-FI"</span>: Fisher information weighted across the likelihood function.
</p>
</li>
<li> <p><span class="option">"PW-FI"</span>: Fisher information weighted across the posterior distribution of
<code class="reqn">\theta</code>.
</p>
</li></ul>

<p>And the Kullback-Leibler divergence methods include
</p>

<ul>
<li> <p><span class="option">"FP-KL"</span>: pointwise KL divergence between [P +/- delta], where
P is either the current <code class="reqn">\theta</code> estimate or a classification bound.
</p>
</li>
<li> <p><span class="option">"VP-KL"</span>: pointwise KL divergence between [P +/- delta/sqrt(n)], where
n is the number of items given to this point in the CAT.
</p>
</li>
<li> <p><span class="option">"FI-KL"</span>: KL divergence integrated along [P -/+ delta] with respect to P
</p>
</li>
<li> <p><span class="option">"VI-KL"</span>: KL divergence integrated along [P -/+ delta/sqrt(n)] with
respect to P.
</p>
</li></ul>

<p>See <code><a href="#topic+itChoose">itChoose</a></code> for more information.
</p>
</li>
<li> <p><code>at</code>: a character string indicating where to select items.  If <code>select</code>
is <span class="option">"UW-FI"</span> and <code>at</code> is <span class="option">"theta"</span>, then items will be selected
to maximize Fisher information at the proximate <code class="reqn">\theta</code> estimates.
</p>
</li>
<li> <p><code>it.range</code>: Either a 2-element numeric vector indicating the minimum and maximum
allowed difficulty parameters for items selected during the starting portion of the CAT
(only if <code>mod</code> is equal to <span class="option">"brm"</span>) or NULL indicating no item parameter
restrictions.  See <code><a href="#topic+itChoose">itChoose</a></code> for more information.
</p>
</li>
<li> <p><code>n.select</code>: an <em>integer</em> indicating the number of items to select at one time.
For instance, if <code>select</code> is <span class="option">"UW-FI"</span>, <code>at</code> is <span class="option">"theta"</span>, and
<code>n.select</code> is 5, the item choosing function will randomly select between the top
<em>5</em> items that maximize expected Fisher information at proximate <code class="reqn">\theta</code> estimates.
</p>
</li>
<li> <p><code>delta</code>: a scalar indicating the multiplier used in initial item selection if
a Kullback-Leibler method is chosen.
</p>
</li>
<li> <p><code>score</code>: a character string indicating the <code class="reqn">\theta</code> estimation method.  As
of now, the options for scoring the first few items are <span class="option">"fixed"</span> (at 
<code>init.thet</code>), <span class="option">"step"</span> (by adding or subtracting <code>step.size</code> <code class="reqn">\theta</code>
estimates after each item), Weighted Likelihood Estimation (<span class="option">"WLE"</span>), Bayesian Modal
Estimation (<span class="option">"BME"</span>), and Expected A-Posteriori Estimation (<span class="option">"EAP"</span>).  The latter
two allow user specified prior distributions through density (<code>d...</code>) functions.  See
<code><a href="#topic+mleEst">mleEst</a></code> for more information.
</p>
</li>
<li> <p><code>range</code>: a 2-element numeric vector indicating the minimum and maximum that
<code class="reqn">\theta</code> should be estimated in the starting portion of the CAT.
</p>
</li>
<li> <p><code>step.size</code>: a scalar indicating how much to increment or decrement the
estimate of <code class="reqn">\theta</code> if <code>score</code> is set to <span class="option">"step"</span>.
</p>
</li>
<li> <p><code>leave.after.MLE</code>: a logical indicating whether to skip the remainder of the starting
items if the user has a mixed response pattern and/or a finite maximum likelihood estimate
of <code class="reqn">\theta</code> can be achieved.
</p>
</li></ol>

</td></tr>
<tr><td><code id="catIrt_+3A_catmiddle">catMiddle</code></td>
<td>
<p><b>list:</b> a list of options for selecting/scoring during the middle of the CAT,
including:
</p>

<ol>
<li> <p><code>select</code>: a character string indicating the item selection method for the 
remaining items.  See <code>select</code> in <code>catStart</code> for an explanation
of the options.
</p>
</li>
<li> <p><code>at</code>: a character string indicating where to select items.  See <code>select</code> in
<code>catStart</code> for an explanation of the options.
</p>
</li>
<li> <p><code>it.range</code>: Either a 2-element numeric vector indicating the minimum and maximum
allowed difficulty parameters for items selected during the middle portion of the CAT
(only if <code>mod</code> is equal to <span class="option">"brm"</span>) or NULL indicating no item parameter
restrictions.  See <code><a href="#topic+itChoose">itChoose</a></code> for more information.
</p>
</li>
<li> <p><code>n.select</code>: an <em>integer</em> indicating the number of items to select at one time.
</p>
</li>
<li> <p><code>delta</code>: a scalar indicating the multiplier used in middle item selection if
a Kullback-Leibler method is chosen.
</p>
</li>
<li> <p><code>score</code>: a character string indicating the <code class="reqn">\theta</code> estimation method.  As
of now, the options for scoring the remaining items are Maximum Likelihood Estimation 
(<span class="option">"MLE"</span>), Weighted Likelihood Estimation (<span class="option">"WLE"</span>), Bayesian Modal Estimation
(<span class="option">"BME"</span>), and Expected A-Posteriori Estimation (<span class="option">"EAP"</span>).  The latter two allow
user specified prior distributions through density (<code>d...</code>) functions.  See
<code><a href="#topic+mleEst">mleEst</a></code> for more information.
</p>
</li>
<li> <p><code>range</code>: a 2-element numeric vector indicating the minimum and maximum that
<code class="reqn">\theta</code> should be estimated in the middle portion of the CAT.
</p>
</li>
<li> <p><code>expos</code>: a character string indicating whether no item exposure controls should be
implemented (<span class="option">"none"</span>) or whether the CAT should use Sympson-Hetter exposure
controls (<span class="option">"SH"</span>).  If (and only if) <code>expos</code> is equal to <span class="option">"SH"</span>,
the last column of the parameter matrix should indicate the probability of an item
being administered given that it is selected.
</p>
</li></ol>

</td></tr>
<tr><td><code id="catIrt_+3A_catterm">catTerm</code></td>
<td>
<p><b>list:</b> a list of options for stopping/terminating the CAT, including:
</p>

<ol>
<li> <p><code>term</code>: a scalar/vector indicating the termination criterion/criteria. CATs can
be terminated either through a fixed number of items (<span class="option">"fixed"</span>) declared
through the <code>n.max</code> argument; related to SEM of a simulee (<span class="option">"precision"</span>)
declared through the <code>p.term</code> argument; related to the test information of a
simulee at a particular point in the cat (<span class="option">"info"</span>) declared through the
<code>i.term</code> argument; and/or when a simulee falls into a category. If more than
one termination criteria is selected, the CAT will terminate after successfully satisfying
the <em>first</em> of those for a given simulee.
</p>
</li>
<li> <p><code>score</code>: a character string indicating the <code class="reqn">\theta</code> estimation method for all
of the responses in the bank.  <code>score</code> is used to estimate <code class="reqn">\theta</code> given
the entire bank of item responses and parameter set.  If the theta estimated using
all of the responses is far away from <code class="reqn">\theta</code>, the size of the item bank is probably
too small.  The options for <code>score</code> in <code>catTerm</code> are identical to the
options of <code>score</code> in <code>catMiddle</code>.
</p>
</li>
<li> <p><code>n.min</code>: an <em>integer</em> indicating the minimum number of items that a simulee
should &quot;take&quot; before <em>any</em> of the termination criteria are checked.
</p>
</li>
<li> <p><code>n.max</code>: an <em>integer</em> indicating the maximum number of items to administer
before terminating the CAT.
</p>
</li>
<li> <p><code>p.term</code>: a list indicating the parameters of a precision-based stopping rule,
only if <code>term</code> is <span class="option">"precision"</span>, including:
</p>

<ol>
<li> <p><code>method</code>: a character string indicating whether to terminate the CAT when the
SEM dips below a threshold (<span class="option">"threshold"</span>) or changes less than a particular
amount (<span class="option">"change"</span>).
</p>
</li>
<li> <p><code>crit</code>: a scalar indicating either the maximum SEM of a simulee before
terminating the CAT or the maximum change in the simulee's SEM before terminating
the CAT.
</p>
</li></ol>

</li>
<li> <p><code>i.term</code>: a list indicating the parameters of a information-based stopping rule,
only if <code>term</code> is <span class="option">"info"</span>, including:
</p>

<ol>
<li> <p><code>method</code>: a character string indicating whether to terminate the CAT when FI
exceeds a threshold (<span class="option">"threshold"</span>) or changes less than a particular
amount (<span class="option">"change"</span>).
</p>
</li>
<li> <p><code>crit</code>: a scalar indicating either the minimum FI of a simulee before
terminating the CAT or the maximum change in the simulee's FI before terminating
the CAT.
</p>
</li></ol>

</li>
<li> <p><code>c.term</code>: a list indicating the parameters of a classification CAT, only if
<code>term</code> is <span class="option">"class"</span> or any of the selection methods are <code>at</code>
one or more <span class="option">"bounds"</span>, including:
</p>

<ol>
<li> <p><code>method</code>: a scalar indicating the method used for a classification CAT.  As of
now, the classification CAT options are the Sequential Probability Ratio Test
(<span class="option">"SPRT"</span>), the Generalized Likelihood Ratio (<span class="option">"GLR"</span>), or the Confidence 
Interval method (<span class="option">"CI"</span>).
</p>
</li>
<li> <p><code>bounds</code>: a scalar, vector, or matrix of classification bounds.  If specified as a
scalar, there will be one bound for each simulee at that value.  If specified as a
<code class="reqn">N</code>-dimensional vector, there will be one bound for each simulee.  If specified as a
<code class="reqn">k &lt; N</code>-dimensional vector, there will be <code class="reqn">k</code> bounds for each simulee at those values.
And if specified as a <code class="reqn">N \times k</code>-element matrix, there will be <code class="reqn">k</code> bounds for each
simulee.
</p>
</li>
<li> <p><code>categ</code>: a vector indicating the names of the categories into which the simulees
should be classified.  The length of <code>categ</code> should be one greater than the length
of <code>bounds</code>.
</p>
</li>
<li> <p><code>delta</code>: a scalar indicating the half-width of an indifference region when performing
an SPRT-based classification CAT or selecting items by Kullback-Leibler divergence.  See
Eggen (1999) and <code><a href="#topic+KL">KL</a></code> for more information.
</p>
</li>
<li> <p><code>alpha</code>: a scalar indicating the specified Type I error rate for performing an SPRT-
based classification CAT.
</p>
</li>
<li> <p><code>beta</code>: a scalar indicating the specified Type II error rate for performing an SPRT-
based classification CAT.
</p>
</li>
<li> <p><code>conf.lev</code>: a scalar between 0 and 1 indicating the confidence level used when performing
a confidence-based (<span class="option">"CI"</span>) classification CAT.
</p>
</li></ol>

</li></ol>

</td></tr>        
<tr><td><code id="catIrt_+3A_ddist">ddist</code></td>
<td>
<p><b>function:</b> a function indicating how to calculate prior densities
for Bayesian estimation or particular item selection methods.  For instance,
if you wish to specify a normal prior, <code>ddist = dnorm</code>, and if you wish
to specify a uniform prior, <code>ddist = dunif</code>.  Note that it is standard in
R to use <code>d</code>... to indicate a density.  See <code><a href="#topic+itChoose">itChoose</a></code> for
more information.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_which">which</code></td>
<td>
<p><b>numeric:</b> a scalar or vector of integers between 1 and 4, indicating
which plots to include.  The plots are as follows:
</p>

<ol>
<li><p> Bank Information
</p>
</li>
<li><p> Bank SEM
</p>
</li>
<li><p> CAT Information
</p>
</li>
<li><p> CAT SEM
</p>
</li></ol>

<p><code>which</code> can also be &quot;none&quot;, in which case <code>plot.catIrt</code> will
not plot any information functions, or it can be &quot;all&quot;, in which case
<code>plot.catIrt</code> will plot all four information functions.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_group">group</code></td>
<td>
<p><b>logical:</b> TRUE or FALSE indicating whether to display a summary at the
group level.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_ids">ids</code></td>
<td>
<p><b>numeric:</b> a scalar or vector of integers between 1 and the number of
simulees indicating which simulees to plot and/or summarize their CAT
process and <em>all</em> of their <code class="reqn">\theta</code> estimates.  <code>ids</code> can
also be &quot;none&quot; (or, equivalently, NULL) or &quot;all&quot;.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_conf.lev">conf.lev</code></td>
<td>
<p><b>numeric:</b> a scalar between 0 and 1 indicating the desired confidence
level plotted for the individual <code class="reqn">\theta</code> estimates.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_legend">legend</code></td>
<td>
<p><b>logical:</b> TRUE or FALSE indicating whether the plot function should
display a legend on the plot.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_ask">ask</code></td>
<td>
<p><b>logical:</b> TRUE or FALSE indicating whether the plot function should ask
between plots.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_progress">progress</code></td>
<td>
<p><b>logical:</b> TRUE or FALSE indicating whether the <code>catIrt</code> function
should display a progress bar during the CAT.
</p>
</td></tr>
<tr><td><code id="catIrt_+3A_...">...</code></td>
<td>
<p>arguments passed to <code>ddist</code> or <code>plot.catIrt</code>, usually distribution
parameters identified by name or graphical parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>catIrt</code> performs a post-hoc computerized adaptive test (CAT),
with a variety of user specified inputs.  For a given person/simulee (e.g. simulee <code class="reqn">i</code>),
a CAT represents a simple set of stages surrounded by a <code>while</code> loop
(e.g. Weiss and Kingsbury, 1984):
</p>

<ul>
<li><p> Item Selection: The next item is chosen based on a pre-specified criterion/criteria.
For example, the classic item selection mechanism is picking an item such that it
maximizes Fisher Information at the current estimate of <code class="reqn">\theta_i</code>.  Frequently,
content balancing, item constraints, or item exposure will be taken into consideration
at this point (aside from solely picking the &quot;best item&quot; for a given person).
See <code><a href="#topic+itChoose">itChoose</a></code> for current item selection methods.
</p>
</li>
<li><p> Estimation: <code class="reqn">\theta_i</code> is estimated based on updated information, usually relating
to the just-selected item and the response associated with that item. In
a post-hoc CAT, all of the responses already exist, but in a standard CAT, &quot;item administration&quot;
would be between &quot;item selection&quot; and &quot;estimation.&quot;  The classic estimation mechanism
is estimating <code class="reqn">\theta_i</code> based off of maximizing the likelihood given parameters and a set
of responses.  Other estimation mechanisms correct for bias in the maximum likelihood
estimate or add a prior information (such as a prior distribution of <code class="reqn">\theta</code>).
If an estimate is untenable (i.e. it returns a non-sensical value or <code class="reqn">\infty</code>), the estimation
procedure needs to have an alternative estimation mechanism.  See <code><a href="#topic+mleEst">mleEst</a></code> for
current estimation methods.
</p>
</li>
<li><p> Termination: Either the test is terminated based on a pre-specified criterion/critera,
or no termination criteria is satisfied, in which case the loop repeats.  The standard
termination criteria involve a fixed criterion (e.g. administering only 50 items),
or a variable criterion (e.g. continuing until the observed SEM is below .3).  Other
termination criteria relate to cut-point tests (e.g. certification tests, classification tests),
that depend not solely on ability but on whether that ability is estimated to exceed a threshold.
<code>catIrt</code> terminates classification tests based on either the Sequential Probability Ratio Test
(SPRT) (see Eggen, 1999), the Generalized Likelihood Ratio (GLR) (see Thompson, 2009), or the
Confidence Interval Method (see Kingsbury &amp; Weiss, 1983).  Essentially, the SPRT compares the ratio
of two likelihoods (e.g. the likelihood of the data given being in one category vs the likelihood
of the data given being in the other category, as defined by <code class="reqn">B + \delta</code> and
<code class="reqn">B - \delta</code> (where <code class="reqn">B</code> separates the categories and <code class="reqn">\delta</code> is the halfwidth of the
indifference region) and compares that ratio with a ratio of error rates (<code class="reqn">\alpha</code> and
<code class="reqn">\beta</code>) (see Wald, 1945).  The GLR uses the maximum likelihood estimate in place of either
<code class="reqn">B + \delta</code> or <code class="reqn">B - \delta</code>, and the confidence interval method terminates a CAT if the
confidence interval surrounding an estimate of <code class="reqn">\theta</code> is fully within one of the categories.
</p>
</li></ul>

<p>The CAT estimates <code class="reqn">\theta_{i1}</code> (an initial point) based on <code>init.theta</code>, 
and terminates the entire simulation after sequentially terminating each simulee's CAT.
</p>


<h3>Value</h3>

<p>The function <code>catIrt</code> returns a list (of class &quot;catIrt&quot;) with the following elements:
</p>
<table role = "presentation">
<tr><td><code>cat_theta</code></td>
<td>
<p>a vector of final CAT <code class="reqn">\theta</code> estimates.
</p>
</td></tr>
<tr><td><code>cat_categ</code></td>
<td>
<p>a vector indicating the final classification of each simulee in the CAT.  If
<code>term</code> is <em>not</em> <span class="option">"class"</span>, <code>cat_categ</code> will be a vector
of NA values.
</p>
</td></tr>
<tr><td><code>cat_info</code></td>
<td>
<p>a vector of observed Fisher information based on the final CAT <code class="reqn">\theta</code>
estimates and the item responses.
</p>
</td></tr>
<tr><td><code>cat_sem</code></td>
<td>
<p>a vector of observed SEM estimates (or posterior standard deviations) based on the
final CAT <code class="reqn">\theta</code> estimates and the item responses.
</p>
</td></tr>
<tr><td><code>cat_length</code></td>
<td>
<p>a vector indicating the number of items administered to each simulee in the CAT
</p>
</td></tr>
<tr><td><code>cat_term</code></td>
<td>
<p>a vector indicating how each CAT was terminated.
</p>
</td></tr>
<tr><td><code>tot_theta</code></td>
<td>
<p>a vector of <code class="reqn">\theta</code> estimates given the entire item bank.
</p>
</td></tr>
<tr><td><code>tot_categ</code></td>
<td>
<p>a vector indicating the classification of each simulee given the entire item bank.
</p>
</td></tr>
<tr><td><code>tot_info</code></td>
<td>
<p>a vector of observed Fisher information based on the entire item bank worth
of responses.
</p>
</td></tr>
<tr><td><code>tot_sem</code></td>
<td>
<p>a vector of observed SEM estimates based on the entire item bank worth of responses.
</p>
</td></tr>
<tr><td><code>true_theta</code></td>
<td>
<p>a vector of true <code class="reqn">\theta</code> values if specified by the user.
</p>
</td></tr>
<tr><td><code>true_categ</code></td>
<td>
<p>a vector of true classification given <code class="reqn">\theta</code>.
</p>
</td></tr>
<tr><td><code>full_params</code></td>
<td>
<p>the full item bank.
</p>
</td></tr>
<tr><td><code>full_resp</code></td>
<td>
<p>the full set of responses.
</p>
</td></tr>
<tr><td><code>cat_indiv</code></td>
<td>
<p>a list of <code class="reqn">\theta</code> estimates, observed SEM, observed information, the responses
and the parameters chosen for each simulee over the entire CAT.
</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>
<p>a list of model specifications, as designated by the user, so that the
CAT can be easily reproduced.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Both <code>summary.catIrt</code> and <code>plot.catIrt</code> return different objects than the original
<code>catIrt</code> function.  <code>summary.catIrt</code> returns summary labeled summary statistics, and
<code>plot.catIrt</code> returns evaluation points (<code class="reqn">x</code> values, information, and SEM) for each
of the plots.  Moreover, if in interactive mode and missing parts of the <code>catStart</code>, <code>catMiddle</code>,
or <code>catTerm</code> arguments, the <code>catIrt</code> function will interactively ask for each of those
and return the set of arguments in the &quot;catIrt&quot; object.
</p>


<h3>Author(s)</h3>

<p>Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>


<h3>References</h3>

<p>Eggen, T. J. H. M.  (1999).  Item selection in adaptive testing with the sequential probability ratio test.  <em>Applied Psychological Measurement</em>, <em>23</em>, 249 &ndash; 261.
</p>
<p>Kingsbury, G. G., &amp; Weiss (1983).  A comparison of IRT-based adaptive mastery testing and a sequential mastery
testing procedure.  In D. J. Weiss (Ed.), <em>New horizons in testing: Latent trait test theory and computerized adaptive testing</em> (pp. 257&ndash;283).  New York, NY: Academic Press.
</p>
<p>Thompson, N. A. (2009).  Using the generalized likelihood ratio as a termination criterion.  In D. J. Weiss (Ed.),
<em>Proceedings of the 2009 GMAC conference on computerized adaptive testing</em>.
</p>
<p>Wainer, H. (Ed.). (2000). <em>Computerized Adaptive Testing: A Primer (2nd Edition)</em>. Mahwah, NJ: Lawrence Erlbaum Associates.
</p>
<p>Wald, A.  (1945).  Sequential tests of statistical hypotheses.  <em>Annals of Mathematical Statistics</em>, <em>16</em>, 117 &ndash; 186.
</p>
<p>Weiss, D. J., &amp; Kingsbury, G. G. (1984). Application of computerized adaptive testing to educational problems. <em>Journal of Educational Measurement</em>, <em>21</em>, 361-375.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FI">FI</a></code>, <code><a href="#topic+itChoose">itChoose</a></code>, <code><a href="#topic+KL">KL</a></code>, <code><a href="#topic+mleEst">mleEst</a></code>,
<code><a href="#topic+simIrt">simIrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#########################
# Binary Response Model #
#########################
set.seed(888)
# generating random theta:
theta &lt;- rnorm(50)
# generating an item bank under a 2-parameter binary response model:
b.params &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = 0)
# simulating responses:
b.resp &lt;- simIrt(theta = theta, params = b.params, mod = "brm")$resp


## CAT 1 ##
# the typical, classic post-hoc CAT:
catStart1 &lt;- list(init.theta = 0, n.start = 5,
                  select = "UW-FI", at = "theta",
                  n.select = 4, it.range = c(-1, 1),
                  score = "step", range = c(-1, 1),
                  step.size = 3, leave.after.MLE = FALSE)
catMiddle1 &lt;- list(select = "UW-FI", at = "theta",
                   n.select = 1, it.range = NULL,
                   score = "MLE", range = c(-6, 6),
                   expos = "none")
catTerm1 &lt;- list(term = "fixed", n.min = 10, n.max = 50)

cat1 &lt;- catIrt(params = b.params, mod = "brm",
               resp = b.resp,
               catStart = catStart1,
               catMiddle = catMiddle1,
               catTerm = catTerm1)

# we can print, summarize, and plot:
cat1                                        # prints theta because
                                            # we have fewer than
                                            # 200 simulees
summary(cat1, group = TRUE, ids = "none")   # nice summary!

summary(cat1, group = FALSE, ids = 1:4)     # summarizing people too! :)

par(mfrow = c(2, 2))
plot(cat1, ask = FALSE)               # 2-parameter model, so expected FI
                                      # and observed FI are the same
par(mfrow = c(1, 1))

# we can also plot particular simulees:
par(mfrow = c(2, 1))
plot(cat1, which = "none", ids = c(1, 30), ask = FALSE)
par(mfrow = c(1, 1))


## CAT 2 ##
# using Fixed Point KL info rather than Unweighted FI to select items:
catStart2 &lt;- catStart1
catMiddle2 &lt;- catMiddle1
catTerm2 &lt;- catTerm1

catStart2$leave.after.MLE &lt;- TRUE         # leave after mixed response pattern
catMiddle2$select &lt;- "FP-KL"
catMiddle2$at &lt;- "bounds"
catMiddle2$delta &lt;- .2
catTerm2$c.term &lt;- list(bounds = 0)
cat2 &lt;- catIrt(params = b.params, mod = "brm",
               resp = b.resp,
               catStart = catStart2,
               catMiddle = catMiddle2,
               catTerm = catTerm2)
cor(cat1$cat_theta, cat2$cat_theta)       # very close!

summary(cat2, group = FALSE, ids = 1:4)   # rarely 5 starting items!


## CAT 3/4 ##
# using "precision" rather than "fixed" to terminate:
catTerm1$term &lt;- catTerm2$term &lt;- "precision"
catTerm1$p.term &lt;- catTerm2$p.term &lt;- list(method = "threshold", crit = .3)
cat3 &lt;- catIrt(params = b.params, mod = "brm",
               resp = b.resp,
               catStart = catStart1,
               catMiddle = catMiddle1,
               catTerm = catTerm1)
cat4 &lt;- catIrt(params = b.params, mod = "brm",
			   resp = b.resp,
			   catStart = catStart2,
			   catMiddle = catMiddle2,
			   catTerm = catTerm2)

mean(cat3$cat_length - cat4$cat_length) # KL info results in slightly more items


## CAT 5/6 ##
# classification CAT with a boundary of 0 (with default classification stuff):
catTerm5 &lt;- list(term = "class", n.min = 10, n.max = 50,
                 c.term = list(method = "SPRT",
                               bounds = 0, delta = .2,
                               alpha = .10, beta = .10))
cat5 &lt;- catIrt(params = b.params, mod = "brm",
               resp = b.resp,
               catStart = catStart1,
               catMiddle = catMiddle1,
               catTerm = catTerm5)
cat6 &lt;- catIrt(params = b.params, mod = "brm",
               resp = b.resp,
               catStart = catStart1,
               catMiddle = catMiddle2,
               catTerm = catTerm5)

# how many were classified correctly?
mean(cat5$cat_categ == cat5$tot_categ)

# using a different selection mechanism, we get the similar results:
mean(cat6$cat_categ == cat6$tot_categ)


## CAT 7 ##
# we could change estimation to EAP with the default (normal) prior:
catMiddle7 &lt;- catMiddle1
catMiddle7$score &lt;- "EAP"
cat7 &lt;- catIrt(params = b.params, mod = "brm", # much slower!
               resp = b.resp,
               catStart = catStart1,
               catMiddle = catMiddle7,
               catTerm = catTerm1)
cor(cat1$cat_theta, cat7$cat_theta)            # pretty much the same


## CAT 8 ##
# let's specify the prior as something strange:
cat8 &lt;- catIrt(params = b.params, mod = "brm",
               resp = b.resp,
               catStart = catStart1,
               catMiddle = catMiddle7,
               catTerm = catTerm1,
               ddist = dchisq, df = 4)

cat8   # all positive values of "theta"


## CAT 9 ##
# finally, we can have:
#   - more than one termination criteria,
#   - individual bounds per person,
#   - simulating based on theta without a response matrix.
catTerm9 &lt;- list(term = c("fixed", "class"),
                 n.min = 10, n.max = 50,
                 c.term = list(method = "SPRT",
                               bounds = cbind(runif(length(theta), -1, 0),
                                              runif(length(theta), 0, 1)),
                               delta = .2,
                               alpha = .1, beta = .1))
cat9 &lt;- catIrt(params = b.params, mod = "brm",
               resp = NULL, theta = theta,
               catStart = catStart1,
               catMiddle = catMiddle1,
               catTerm = catTerm9)

summary(cat9)   # see "... with Each Termination Criterion"


#########################
# Graded Response Model #
#########################
# generating random theta
theta &lt;- rnorm(201)
# generating an item bank under a graded response model:
g.params &lt;- cbind(a = runif(100, .5, 1.5), b1 = rnorm(100), b2 = rnorm(100),
                                           b3 = rnorm(100), b4 = rnorm(100))

# the graded response model is exactly the same, only slower!
cat10 &lt;- catIrt(params = g.params, mod = "grm",
                resp = NULL, theta = theta,
                catStart = catStart1,
                catMiddle = catMiddle1,
                catTerm = catTerm1)

# warning because it.range cannot be specified for graded response models!

# if there is more than 200 simulees, it doesn't print individual thetas:
cat10


## End(Not run)

# play around with things - CATs are fun - a little frisky, but fun.
</code></pre>

<hr>
<h2 id='FI'>Calculate Expected and Observed Fisher Information for IRT Models</h2><span id='topic+FI'></span><span id='topic+FI.brm'></span><span id='topic+FI.grm'></span>

<h3>Description</h3>

<p><code>FI</code> calculates expected and/or observed Fisher information for various
IRT models given a vector of ability values, a vector/matrix of item
parameters, and an IRT model.  It also calculates test
information and expected/observed standard error of measurement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FI( params, theta, type = c("expected", "observed"), resp = NULL )
## S3 method for class 'brm'
FI( params, theta, type = c("expected", "observed"), resp = NULL )
## S3 method for class 'grm'
FI( params, theta, type = c("expected", "observed"), resp = NULL )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FI_+3A_params">params</code></td>
<td>
<p><b>numeric:</b> a vector or matrix of item parameters.  If specified
as a matrix, the rows must index the items, and the columns
must designate the item parameters.  Furthermore, if calculating
<em>expected</em> information, the number of rows must match the number
of columns of <code>resp</code>.  The class of <code>params</code> must match
the model: either <span class="option">"brm"</span> or <span class="option">"grm"</span>.  For the binary response
model, <code>params</code> must either be a 3-dimensional vector or a 3-column
matrix.  See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="FI_+3A_theta">theta</code></td>
<td>
<p><b>numeric:</b> a vector of ability values, one for each simulee.  If calculating
<em>expected</em> information, the length of <code>theta</code> must match
the number of rows of <code>resp</code>, unless <code>theta</code> is a scalar,
in which case <code>resp</code> could also be a vector of length
<code>nrow(params)</code>.
</p>
</td></tr>
<tr><td><code id="FI_+3A_type">type</code></td>
<td>
<p><b>character:</b> a character string indicating the type of information, either
<span class="option">"expected"</span> or <span class="option">"observed"</span>.  For the 1-parameter and
2-parameter binary response model (of class <span class="option">"brm"</span> with the
third column of <code>params</code> set to 0), both <span class="option">"expected"</span>
and <span class="option">"observed"</span> information are identical. See <b>Details</b>
for more information.
</p>
</td></tr>
<tr><td><code id="FI_+3A_resp">resp</code></td>
<td>
<p><b>numeric:</b> either a <code class="reqn">N \times J</code> matrix (where <code class="reqn">N</code> indicates the
number of simulees and <code class="reqn">J</code> indicates the number of items), a
<code class="reqn">N</code> length vector (if there is only one item) or a <code class="reqn">J</code> length
vector (if there is only one simulee).  For the binary response model
(<span class="option">"brm"</span>), <code>resp</code> must solely contain 0s and 1s.  For the
graded response model (<span class="option">"grm"</span>), <code>resp</code> must solely contain
integers <code class="reqn">1, \ldots, K</code>, where <code class="reqn">K</code> is the number of categories, as
indicated by the dimension of <code>params</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>FI</code> returns item information, test information, and standard error
of measurement for the binary response model (<span class="option">"brm"</span>) or the graded response
model (<span class="option">"grm"</span>).  If the log likelihood is twice differentiable, expected Fisher
information is the negative, expected, second derivative of the log likelihood with respect
to the parameter. For the binary response model, expected item information simplifies to the
following:
</p>
<p style="text-align: center;"><code class="reqn"> I(\theta_i | a_j, b_j, c_j) = \frac{\left(\frac{\partial p_{ij}}{\partial \theta_i}\right)^2}{p_{ij}(1 - p_{ij})} </code>
</p>

<p>where <code class="reqn">\partial p_{ij}/\partial \theta_i</code> is the partial derivative
of <code class="reqn">p_{ij}</code> with respect to <code class="reqn">\theta</code>, and <code class="reqn">p_{ij}</code> is the probability of response, as
indicated in the help page for <code><a href="#topic+simIrt">simIrt</a></code>.
</p>
<p>For the graded response model, expected item information simplifies to the following:
</p>
<p style="text-align: center;"><code class="reqn"> I(\theta_i | a_j, b_{j1}, \ldots, b_{j(k - 1)}) = \sum_k\frac{\left(\frac{\partial P_{ijk}}{\partial \theta_i}\right)^2}{P_{ijk}}</code>
</p>

<p>where <code class="reqn">\partial P_{ijk}/\partial \theta_i</code> is the partial derivative
of <code class="reqn">P_{ijk}</code> with respect to <code class="reqn">\theta</code>, and <code class="reqn">P_{ijk}</code> is the probability of responding
in category k as indicated in the help page for <code><a href="#topic+simIrt">simIrt</a></code>. See van der Linden and Pashley
(2010).
</p>
<p>Observed information is the negative second derivative of the log-likelihood.  For the binary
response model (<span class="option">"brm"</span>) with 2-parameters (such that the third column of the
parameter matrix is set to 0), observed and expected information are identical because the second
derivative of their log-likelihoods do not contain observed data.  See Baker and Kim (2004),
pp. 66 &ndash; 69.
</p>
<p>For all models, test information is defined as the following:
</p>
<p style="text-align: center;"><code class="reqn"> T(\theta_i) = \sum_jI_j(\theta_i) </code>
</p>

<p>where <code class="reqn">I(\theta_i)_j</code> is shorthand for Fisher information of simulee <code class="reqn">i</code> on item <code class="reqn">j</code>.
Finally, the standard error of measurement (SEM) is the inverse, square-root of test information.
<code>FI</code> is frequently used to <em>select</em> items in a CAT and to estimate the precision
of <code class="reqn">\hat{\theta}_i</code> after test termination.
</p>


<h3>Value</h3>

<p><code>FI</code>, <code>FI.brm</code>, and <code>FI.grm</code> return a list of the following elements:
</p>
<table role = "presentation">
<tr><td><code>item</code></td>
<td>
<p>either: (1) a <code class="reqn">N \times J</code> matrix of item information for each simulee to
each item; (2) a <code class="reqn">J</code>-length vector of item information for one simulee to
each item; or (3) an <code class="reqn">N</code>-length vector of item information for all simulees
to one item, depending on the dimensions of <code>params</code> and <code>theta</code>.
</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>an <code class="reqn">N</code>-length vector of test information, one for each simulee. Test
information is the sum of item information across items.  See <b>Details</b> for
more information.
</p>
</td></tr>
<tr><td><code>sem</code></td>
<td>
<p>an <code class="reqn">N</code>-length vector of expected or observed standard error of measurement
for each simulee, which is the inverse-square-root of test information.
See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>either <span class="option">"observed"</span> or <span class="option">"expected"</span>, indicating the <em>type</em>
of information calculated.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>


<h3>References</h3>

<p>Baker, F. B., &amp; Kim, S.-H.  (2004).  <em>Item Response Theory: Parameter Estimation Techniques, Second Edition</em>.  New York, NY: Marcel Dekker, Inc.
</p>
<p>Dodd, B. G., De Ayala, R. J., &amp; Koch, W. R.  (1995).  Computerized adaptive testing with polytomous items.  <em>Applied Psychological Measurement</em>, <em>19</em>, 5 &ndash; 22.
</p>
<p>Embretson, S. E., &amp; Reise, S. P.  (2000).  <em>Item Response Theory for Psychologists</em>.  Mahway, NJ: Lawrence Erlbaum Associates.
</p>
<p>Kullback, S., &amp; Leibler, R. A.  (1951).  On information and sufficiency.  <em>The Annals of Mathematical Statistics</em>, <em>22</em>, 79 &ndash; 86.
</p>
<p>van der Linden, W. J. &amp; Pashley, P. J.  (2010).  Item selection and ability estimation in adaptive testing.  In W. J. van der Linden &amp; C. A. W. Glas (Eds.), <em>Elements of Adaptive Testing</em>.  New York, NY: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catIrt">catIrt</a></code>, <code><a href="#topic+KL">KL</a></code>, <code><a href="#topic+simIrt">simIrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################
# Binary Response Model #
#########################

## 1 ##
set.seed(888)
# generating random theta:
theta &lt;- rnorm(20)
# generating an item bank under a 2-parameter binary response model:
b.params &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = 0)
# simulating responses using random theta:
b.mod &lt;- simIrt(params = b.params, theta = theta, mod = "brm")

# you can indicate class of params or extract it from simIrt object:
class(b.params) &lt;- "brm"

# calculating expected and observed information:
e.info &lt;- FI(params = b.params, theta = theta, type = "expected")
o.info &lt;- FI(params = b.params, theta = theta, type = "observed", resp = b.mod$resp)

# 2-parameter model, so e.info will be equal to o.info:
all(signif(e.info$item) == signif(o.info$item))


## 2 ##
# generating an item bank under a 3-parameter binary response model:
b.params2 &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = .2)
# simulating responses using pre-specified thetas:
b.mod2 &lt;- simIrt(params = b.params2, mod = "brm")

# calculating expected and observed information:
# (if you don't indicate class, you can extract from simIrt object)
e.info2 &lt;- FI(params = b.params2, theta = b.mod2$theta, type = "expected")
o.info2 &lt;- FI(params = b.params2, theta = b.mod2$theta, type = "observed",
                                  resp = b.mod2$resp)

# 3-parameter model, so e.info will not be equal to o.info:
all(signif(e.info2$item) == signif(o.info2$item))


## 3 ##
# if theta is a scalar, item will be a vector and test will be a scalar:
e.info3 &lt;- FI(params = b.params2, theta = 0, type = "expected")
dim(e.info3$item)       # no dimension because it's a vector
length(e.info3$item)    # of length equal to the number of items

# if params is a vector, item will be a matrix with one row:
e.info4 &lt;- FI(params = c(1, 2, 0), theta = c(1, 2), type = "expected")
dim(e.info4$item)

# if you don't class params, FI will assume a binary response model.


#########################
# Graded Response Model #
#########################
set.seed(999)
# generating random theta
theta &lt;- rnorm(10)
# generating an item bank under a graded response model:
g.params &lt;- cbind(a = runif(30, .5, 1.5), b1 = rnorm(30), b2 = rnorm(30),
                                          b3 = rnorm(30), b4 = rnorm(30))
# you can sort the parameters yourself:
g.params &lt;- cbind(g.params[ , 1],
                  t(apply(g.params[ ,2:dim(g.params)[2]], MARGIN = 1,
                                                          FUN = sort)))
# simulating responses using random theta:
g.mod &lt;- simIrt(params = g.params, theta = theta, mod = "grm")

# calculating expected and observed information:
class(g.params) &lt;- "grm"   # always indicate model or extract from simulation.
e.info5 &lt;- FI(params = g.params, theta = theta, type = "expected")
o.info5 &lt;- FI(params = g.params, theta = theta, type = "observed", resp = g.mod$resp)

# grm, so e.info will not be equal to o.info:
all(signif(e.info5$item) == signif(o.info5$item))

# if thet is a vector and params is a vector, item will be a J x N matrix:
dim(e.info5$item)

# if you don't want to sort the parameters, you can extract from simIrt object:
e.info6 &lt;- FI(params = g.mod$params[ , -1], theta = g.mod$theta, type = "expected")

# but you first need to remove column 1 (the item number column).
</code></pre>

<hr>
<h2 id='itChoose'>Choose the Next Item in a CAT</h2><span id='topic+itChoose'></span>

<h3>Description</h3>

<p><code>itChoose</code> chooses the next item in a CAT based on the
remaining items and a variety of item selection algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itChoose( left_par, mod = c("brm", "grm"), 
          numb = 1, n.select = 1,
          cat_par = NULL, cat_resp = NULL, cat_theta = NULL,
          select = c("UW-FI", "LW-FI", "PW-FI",
                     "FP-KL", "VP-KL", "FI-KL", "VI-KL",
                     "random"),
          at = c("theta", "bounds"),
          range = c(-6, 6), it.range = NULL,
          delta = NULL, bounds = NULL,
          ddist = dnorm, quad = 33, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="itChoose_+3A_left_par">left_par</code></td>
<td>
<p><b>numeric:</b> a matrix of item parameters from which to choose
the next item.  The rows must index the items, and the columns must
designate the item parameters (in the appropriate order, see 
<code><a href="#topic+catIrt">catIrt</a></code>).  The first column of <code>left_par</code> must
indicate the <em>item numbers</em>, as <code>itChoose</code> returns not
<em>just</em> the item parameters but also the bank number corresponding
to those parameters.  See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_mod">mod</code></td>
<td>
<p><b>character:</b> a character string indicating the IRT model.  Current support
is for the 3-parameter binary response model (<span class="option">"brm"</span>),
and Samejima's graded response model (<span class="option">"grm"</span>).  The contents
of <code>params</code> must match the designation of <code>mod</code>.  See
<code><a href="#topic+catIrt">catIrt</a></code> or <code><a href="#topic+simIrt">simIrt</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_numb">numb</code></td>
<td>
<p><b>numeric:</b> a scalar indicating the number of items to <em>return</em> to
the user.  If <code>numb</code> is less than <code>n.select</code>, then
<code>itChoose</code> will randomly select <code>numb</code> items from the top
<code>n.select</code> items according to the item selection algorithm.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_n.select">n.select</code></td>
<td>
<p><b>numeric:</b> an <em>integer</em> indicating the number of items to randomly select 
between at one time.  For instance, if <code>select</code> is <span class="option">"UW-FI"</span>, 
<code>at</code> is <span class="option">"theta"</span>, <code>numb</code> is 3, and <code>n.select</code> is 8, 
then <code>itChoose</code> will randomly select <em>3</em> items out of the top <em>8</em> 
items that maximize Fisher information at <code>cat_theta</code>.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_cat_par">cat_par</code></td>
<td>
<p><b>numeric:</b> either NULL or a matrix of item parameters that have already
been administered in the CAT.  <code>cat_par</code> only needs to be specified
if letting <code>select</code> equal either <span class="option">"LW-FI"</span>, <span class="option">"PW-FI"</span>,
<span class="option">"VP-KL"</span> or <span class="option">"VI-KL"</span>.  The format of <code>cat_par</code> must be the
same as the format of <code>left_par</code>. See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_cat_resp">cat_resp</code></td>
<td>
<p><b>numeric:</b> either NULL or a vector of responses corresponding to the items 
specified in <code>cat_par</code>.  <code>cat_par</code> only needs to be specified if
letting <code>select</code> equal either <span class="option">"LW-FI"</span> or <span class="option">"PW-FI"</span>.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_cat_theta">cat_theta</code></td>
<td>
<p><b>numeric:</b> either NULL or a scalar corresponding to the current ability
estimate.  <code>cat_theta</code> is not needed if selecting items at <span class="option">"bounds"</span>
or using <span class="option">"LW-FI"</span> or <span class="option">"PW-FI"</span> as the item selection algorithm.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_select">select</code></td>
<td>
<p><b>character:</b> a character string indicating the desired item selection 
method.  Items can be selected either through maximum Fisher information or
Kullback-Leibler divergence methods or randomly.  The Fisher information methods
include
</p>

<ul>
<li> <p><span class="option">"UW-FI"</span>: unweighted Fisher information at a point.
</p>
</li>
<li> <p><span class="option">"LW-FI"</span>: Fisher information weighted across the likelihood function.
</p>
</li>
<li> <p><span class="option">"PW-FI"</span>: Fisher information weighted across the posterior distribution of
<code class="reqn">\theta</code>.
</p>
</li></ul>

<p>And the Kullback-Leibler divergence methods include
</p>

<ul>
<li> <p><span class="option">"FP-KL"</span>: pointwise KL divergence between [P +/- delta], where
P is either the current <code class="reqn">\theta</code> estimate or a classification bound.
</p>
</li>
<li> <p><span class="option">"VP-KL"</span>: pointwise KL divergence between [P +/- delta/sqrt(n)], where
n is the number of items given to this point in the CAT.
</p>
</li>
<li> <p><span class="option">"FI-KL"</span>: KL divergence integrated along [P -/+ delta] with respect to P
</p>
</li>
<li> <p><span class="option">"VI-KL"</span>: KL divergence integrated along [P -/+ delta/sqrt(n)] with
respect to P.
</p>
</li></ul>

<p>See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_at">at</code></td>
<td>
<p><b>character:</b> a character string indicating where to select items.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_range">range</code></td>
<td>
<p><b>numeric:</b> a 2-element numeric vector indicating the range of values
that <code>itChoose</code> should average over if <code>select</code> equals
<span class="option">"LW-FI"</span> or <span class="option">"PW-FI"</span>.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_it.range">it.range</code></td>
<td>
<p><b>numeric:</b> Either a 2-element numeric vector indicating the minimum
and maximum allowed difficulty parameters for selected items (only if <code>mod</code>
is equal to <span class="option">"brm"</span>) or NULL indicating no item parameter restrictions.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_delta">delta</code></td>
<td>
<p><b>numeric:</b> a scalar indicating the multiplier used in item selection
if a Kullback-Leibler method is chosen.  For fixed-point KL divergence,
<code>delta</code> is frequently .1 or .2, whereas in variable-point KL divergence,
<code>delta</code> usually corresponds to 95 or 97.5 percentiles on a normal distribution.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_bounds">bounds</code></td>
<td>
<p><b>numeric:</b> a vector of fixed-points/bounds from which to select items
if <code>at</code> equals <span class="option">"bounds"</span>.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_ddist">ddist</code></td>
<td>
<p><b>function:</b> a function indicating how to calculate prior densities
if <code>select</code> equals <span class="option">"PW-FI"</span> (i.e., weighting Fisher information
on the posterior distribution).  See <code><a href="#topic+catIrt">catIrt</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_quad">quad</code></td>
<td>
<p><b>numeric:</b> a scalar indicating the number of quadrature points when
<code>select</code> equals <span class="option">"LW-FI"</span> or <span class="option">"PW-FI"</span>.  See <b>Details</b>
for more information.
</p>
</td></tr>
<tr><td><code id="itChoose_+3A_...">...</code></td>
<td>
<p>arguments passed to <code>ddist</code>, usually distribution parameters identified by name.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>itChoose</code> returns the next item(s) to administer in a CAT environment.
The item selection algorithms fall into three major types: Fisher information, Kullback-Leibler
divergence, and random.
</p>

<ul>
<li><p> If choosing items based on Fisher information (<code>select</code> equals <span class="option">"UW-FI"</span>,
<span class="option">"LW-FI"</span>, or <span class="option">"PW-FI"</span>), then items are selected based on some aggregation
of Fisher information (see <code><a href="#topic+FI">FI</a></code>).  The difference between the three Fisher information
methods are the weighting functions used (see van der Linden, 1998; Veerkamp &amp; Berger, 1997).  Let
</p>
<p style="text-align: center;"><code class="reqn"> I(w_{ij} | a_j, b_j, c_j) = \int_{-\infty}^{\infty} w_{ij}I_j(\theta)\mu(d\theta) </code>
</p>

<p>be the &quot;average&quot; Fisher information, weighted by real valued function <code class="reqn">w_{ij}</code>.  Then
all three Fisher information criteria can be explained solely as using different
weights.  Unweighted Fisher information (<span class="option">"UW-FI"</span>) sets <code class="reqn">w_{ij}</code> equal to a Dirac
delta function with all of its mass either on <code>theta</code> (if <code>at</code> equals
<span class="option">"theta"</span>) or the nearest classification bound (if <code>at</code> equals <span class="option">"bounds"</span>).
Likelihood-Weighted Fisher information (<span class="option">"UW-FI"</span>) sets <code class="reqn">w_{ij}</code> equal to the likelihood
function given all of the previously administered items (Veerkamp &amp; Berger, 1997).  And
Posterior-Weighted Fisher information (<span class="option">"PW-FI"</span>) sets <code class="reqn">w_{ij}</code> equal to the likelihood
function times the prior distribution specified in <code>ddist</code> (van der Linden, 1998).  All
three algorithms select items based on maximizing the respective criterion with <span class="option">"UW-FI"</span>
the most popular CAT item selection algorithm and equivalent to maximizing Fisher information
at a point (Pashley &amp; van der Linden, 2010).
</p>
</li>
<li><p> If choosing items based on Kullback-Leibler divergence (<code>select</code> equals <span class="option">"FP-KL"</span>,
<span class="option">"VP-KL"</span>, <span class="option">"FI-KL"</span>, or <span class="option">"VI-KL"</span>), then items are selected based on
some aggregation of KL divergence (see <code><a href="#topic+KL">KL</a></code>).
</p>

<ul>
<li><p> The Pointwise KL divergence criteria (<code>select</code> equals <span class="option">"FP-KL"</span> and 
<span class="option">"VP-KL"</span>) compares KL divergence at two points:
</p>
<p style="text-align: center;"><code class="reqn"> KL(w_{ij} | a_j, b_j, c_j) = KL_j(P + w_{ij} || P - w_{ij}) </code>
</p>

<p>The difference between <span class="option">"FP-KL"</span> and <span class="option">"VP-KL"</span> are the weights used.  Fixed
Pointwise KL divergence (<span class="option">"FP-KL"</span>) sets <code class="reqn">w_{ij}</code> equal to <span class="option">delta</span>, and
Variable Pointwise KL divergence (<span class="option">"VP-KL"</span>) sets <code class="reqn">w_{ij}</code> equal to <span class="option">delta</span>
multiplied by <code class="reqn">1/\sqrt{n}</code>, where <code class="reqn">n</code> is equal to the number of items given to
this point in the CAT (see Chang &amp; Ying, 1996).
</p>
</li>
<li><p> The Integral KL divergence criteria (<code>select</code> equals <span class="option">"FI-KL"</span> and
<span class="option">"VI-KL"</span>) integrates KL divergence across a small area:
</p>
<p style="text-align: center;"><code class="reqn"> KL(w_{ij} | a_j, b_j, c_j) = \int_{P - w_{ij}}^{P + w_{ij}} KL_j(\theta || P) d\theta </code>
</p>

<p>As in Pointwise KL divergence, Fixed Integral KL divergence (<span class="option">"FI-KL"</span>) sets
<code class="reqn">w_{ij}</code> equal to <span class="option">delta</span>, and Variable Integral KL divergence (<span class="option">"VI-KL"</span>)
sets <code class="reqn">w_{ij}</code> equal to <span class="option">delta</span> multiplied by <code class="reqn">1/\sqrt{n}</code> (see Chang &amp; Ying, 1996).
</p>
</li></ul>

<p>All KL divergence criteria set <code class="reqn">P</code> equal to <code>theta</code> (if <code>at</code> equals
<span class="option">"theta"</span>) or the nearest classification bound (if <code>at</code> equals <span class="option">"bounds"</span>)
and select items based on maximizing the respective criterion.
</p>
</li>
<li><p> If <code>select</code> is <span class="option">"random"</span>, then <code>itChoose</code> randomly picks the next item(s)
out of the remaining items in the bank.
</p>
</li></ul>



<h3>Value</h3>

<p><code>itChoose</code> returns a list of the following elements:
</p>
<table role = "presentation">
<tr><td><code>params</code></td>
<td>
<p>a matrix corresponding to the next item or <code>numb</code> items to administer
in a CAT with the first column indicating the item number
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>a vector of corresponding information for the <code>numb</code> items of
<code>params</code>. 
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the type of information returned in <code>info</code>, which is equal to the
item selection algorithm.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>


<h3>References</h3>

<p>Chang, H.-H., &amp; Ying, Z.  (1996).  A global information approach to computerized adaptive testing.  <em>Applied Psychological Measurement</em>, <em>20</em>, 213 &ndash; 229.
</p>
<p>Pashley, P. J., &amp; van der Linden, W. J.  (2010).  Item selection and ability estimation in adaptive testing.  In W. J. van der Linden &amp; C. A. W. Glas (Eds.), <em>Elements of adaptive testing</em> (pp. 3 &ndash; 30).  New York, NY: Springer.
</p>
<p>van der Linden, W. J.  (1998).  Bayesian item selection criteria for adaptive testing.  <em>Psychometrika</em>, <em>63</em>, 201 &ndash; 216.
</p>
<p>Veerkamp, W. J. J., &amp; Berger, M. P. F.  (1997).  Some new item selection criteria for adaptive testing.  <em>Journal of Educational and Behavioral Statistics</em>, <em>22</em>, 203 &ndash; 226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catIrt">catIrt</a></code>, <code><a href="#topic+FI">FI</a></code>, <code><a href="#topic+KL">KL</a></code>,
<code><a href="#topic+mleEst">mleEst</a></code>, <code><a href="#topic+simIrt">simIrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################
# Binary Response Model #
#########################
## Not run: 
set.seed(888)
# generating an item bank under a binary response model:
b.params &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = .2)
# simulating responses using default theta:
b.mod &lt;- simIrt(theta = 0, params = b.params, mod = "brm")

# separating the items into "administered" and "not administered":
left_par &lt;- b.mod$params[1:95, ]
cat_par &lt;- b.mod$params[96:100, ]
cat_resp &lt;- b.mod$resp[ , 96:100]

# running simIrt automatically adds the item numbers to the front!

# attempting each item selection algorithm (except random):
uwfi.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_theta = 0,
                    select = "UW-FI",
                    at = "theta")
lwfi.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_par = cat_par, cat_resp = cat_resp,
                    select = "LW-FI")
pwfi.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_par = cat_par, cat_resp = cat_resp,
                    select = "PW-FI", ddist = dnorm, mean = 0, sd = 1)

fpkl.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_theta = 0,
                    select = "FP-KL",
                    at = "theta", delta = 1.96)
vpkl.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_par = cat_par, cat_theta = 0,
                    select = "VP-KL",
                    at = "theta", delta = 1.96)
fikl.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_theta = 0,
                    select = "FI-KL",
                    at = "theta", delta = 1.96)
vikl.it &lt;- itChoose(left_par = left_par, mod = "brm",
                    numb = 1, n.select = 1,
                    cat_par = cat_par, cat_theta = 0,
                    select = "VI-KL",
                    at = "theta", delta = 1.96)

# which items were the most popular?
uwfi.it$params  # 61 (b close to 0)
lwfi.it$params  # 55 (b close to -2.5)
pwfi.it$params  # 16 (b close to -0.5)
fpkl.it$params  # 61 (b close to 0)
vpkl.it$params  # 61 (b close to 0)
fikl.it$params  # 16 (b close to -0.5)
vikl.it$params  # 16 (b close to -0.5)

# if we pick the top 10 items for "FI-KL":
fikl.it2 &lt;- itChoose(left_par = left_par, mod = "brm",
                     numb = 10, n.select = 10,
                     cat_theta = 0,
                     select = "FI-KL",
                     at = "theta", delta = 1.96)

# we find that item 61 is the third best item
fikl.it2$params

# why did "LW-FI" pick an item with a strange difficulty?
cat_resp

# because cat_resp is mostly 0 ...
# --&gt; so the likelihood is weighted toward negative numbers.

#########################
# Graded Response Model #
#########################
set.seed(999)
# generating an item bank under a graded response model:
g.params &lt;- cbind(runif(100, .5, 1.5), rnorm(100), rnorm(100),
                                       rnorm(100), rnorm(100), rnorm(100))
# simulating responses (so that the parameters are ordered - see simIrt)
left_par &lt;- simIrt(theta = 0, params = g.params, mod = "grm")$params

# now we can choose the best item for theta = 0 according to FI:
uwfi.it2 &lt;- itChoose(left_par = left_par, mod = "brm",
                     numb = 1, n.select = 1,
                     cat_theta = 0,
                     select = "UW-FI",
                     at = "theta")
uwfi.it2

## End(Not run)

</code></pre>

<hr>
<h2 id='KL'>Calculate Kullback-Leibler Divergence for IRT Models</h2><span id='topic+KL'></span><span id='topic+KL.brm'></span><span id='topic+KL.grm'></span>

<h3>Description</h3>

<p><code>KL</code> calculates the IRT implementation of Kullback-Leibler
divergence for various IRT models given a vector of ability values,
a vector/matrix of item responses, an IRT model, and a value
indicating the half-width of an indifference region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KL( params, theta, delta = .1 )
## S3 method for class 'brm'
KL( params, theta, delta = .1 )
## S3 method for class 'grm'
KL( params, theta, delta = .1 )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KL_+3A_params">params</code></td>
<td>
<p><b>numeric:</b> a vector or matrix of item parameters.  If specified
as a matrix, the rows must index the items, and the columns
must designate the item parameters.  Furthermore, if calculating
<em>expected</em> information, the number of rows must match the number
of columns of <code>resp</code>.  The class of <code>params</code> must match
the model: either <span class="option">"brm"</span> or <span class="option">"grm"</span>.  For the binary response
model, <code>params</code> must either be a 3-dimensional vector or a 3-column
matrix.  See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="KL_+3A_theta">theta</code></td>
<td>
<p><b>numeric:</b> a vector of ability values, one for each simulee.  When performing
a classification CAT, <code>theta</code> should be the boundary points for which to
choose the next item.
</p>
</td></tr>
<tr><td><code id="KL_+3A_delta">delta</code></td>
<td>
<p><b>numeric:</b> a scalar or vector indicating the half-width of the indifference
<code>KL</code> will estimate the divergence between <code class="reqn">\theta - \delta</code> and
<code class="reqn">\theta + \delta</code> using <code class="reqn">\theta + \delta</code> as the &quot;true model.&quot;
If <code>delta</code> is a vector, then <code>KL</code> will use recycling to make the length
of <code>theta</code> and <code>delta</code> match. See <b>Details</b> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>KL</code> returns item divergence and test divergence for the binary
response model (<span class="option">"brm"</span>) and the graded response model (<span class="option">"grm"</span>).  KL-divergence
is defined as the following:
</p>
<p style="text-align: center;"><code class="reqn"> KL(\theta_2 || \theta_1) = E_{\theta_2}\log\left[\frac{L(\theta_2)}{L(\theta_1)}\right]</code>
</p>

<p>where <code class="reqn">L(\theta)</code> stands for the likelihood of <code class="reqn">\theta</code>.  Essentially, KL-divergence
is the expected log-likelihood gain when using the true model in place of an alternative model.
</p>
<p>For the binary response model, KL-divergence for an item simplifies to the following:
</p>
<p style="text-align: center;"><code class="reqn"> KL_j(\theta_2 || \theta_1)_j = p_j(\theta_2)\log\left[\frac{p_j(\theta_2)}{p_j(\theta_1)}\right] + [1 - p_j(\theta_2)]\log\left[\frac{1 - p_j(\theta_2)}{1 - p_j(\theta_1)}\right]</code>
</p>

<p>where <code class="reqn">p_{ij}</code> is the probability of response, as indicated in the help page for <code><a href="#topic+simIrt">simIrt</a></code>
</p>
<p>For the graded response model, KL-divergence for an item simplifies to the following:
</p>
<p style="text-align: center;"><code class="reqn"> KL_j(\theta_2 || \theta_1) = \sum_k{P_{jk}(\theta_2)\log\left[\frac{P_{jk}(\theta_2)}{P_{jk}(\theta_1)}\right]}</code>
</p>

<p>where <code class="reqn">P_{jk}(\theta_2)</code> is the probability of <code class="reqn">\theta_2</code> responding in category k as
indicated in the help page for <code><a href="#topic+simIrt">simIrt</a></code>. See Eggen (1999) as applied to classification
CAT and van der Linden and Pashley (2010) more generally.
</p>
<p>Because of the properties of likelihood functions in item response models, test information
is simply the sum of the item informations, or:
</p>
<p style="text-align: center;"><code class="reqn"> KL(\theta_2 || \theta_1) = \sum_jKL_j(\theta_2 || \theta_1)</code>
</p>

<p><code>KL</code> is frequently used to select items in a classification CAT where the hypotheses (e.g. being
in one category versus another category are well defined).  If &quot;being in the upper category&quot; is
<code class="reqn">\theta_2</code> and &quot;being in the lower category&quot; is <code class="reqn">\theta_1</code>, then <code class="reqn">\theta_2 = B + \delta</code>
and <code class="reqn">\theta_1 = B - \delta</code> where <code class="reqn">B</code> is the boundary separating the lower category from the
upper category.  Conversely, if using <code>KL</code> to select items in a precision CAT, then
<code class="reqn">\theta_2 = \hat{\theta}_i + \delta</code> and <code class="reqn">\theta_1 = \hat{\theta}_i</code> where <code class="reqn">\hat{\theta}_i</code>
is the current, <em>best</em> estimate of <code class="reqn">\theta</code>. See <code><a href="#topic+catIrt">catIrt</a></code> for more information.
</p>


<h3>Value</h3>

<p><code>KL</code>, <code>KL.brm</code>, and <code>KL.grm</code> return a list of the following elements:
</p>
<table role = "presentation">
<tr><td><code>item</code></td>
<td>
<p>either: (1) a <code class="reqn">N \times J</code> matrix of item information for each simulee to
each item; (2) a <code class="reqn">J</code>-length vector of item information for one simulee to
each item; or (3) an <code class="reqn">N</code>-length vector of item information for all simulees
to one item, depending on the dimensions of <code>params</code>, <code>theta</code>, annd
<code>delta</code>.
</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>an <code class="reqn">N</code>-length vector of test information, one for each simulee. Test
information is the sum of item information across items.  See <b>Details</b> for
more information.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Kullback-Leibler divergence in IRT is not <em>true</em> KL divergence, as the expectation
is with respect to a model that is not necessarily true.  Furthermore, it is not reciprocal,
as <code class="reqn">KL(\theta_1 || \theta_2) \neq KL(\theta_2 || \theta_1)</code>.  There have been
other KL-based item selection measures proposed, including global information.  See
Eggen (1999) and <code><a href="#topic+itChoose">itChoose</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>


<h3>References</h3>

<p>Eggen, T. J. H. M.  (1999).  Item selection in adaptive testing with the sequential probability ratio test.  <em>Applied Psychological Measurement</em>, <em>23</em>, 249 &ndash; 261.
</p>
<p>Kullback, S., &amp; Leibler, R. A.  (1951).  On information and sufficiency.  <em>The Annals of Mathematical Statistics</em>, <em>22</em>, 79 &ndash; 86.
</p>
<p>van dr Linden, W. J. &amp; Pashley, P. J.  (2010).  Item selection and ability estimation in adaptive testing.  In W. J. van der Linden &amp; C. A. W. Glas (Eds.), <em>Elements of Adaptive Testing</em>.  New York, NY: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catIrt">catIrt</a></code>, <code><a href="#topic+FI">FI</a></code>, <code><a href="#topic+itChoose">itChoose</a></code>, <code><a href="#topic+simIrt">simIrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################
# Binary Response Model #
#########################

## 1 ##
set.seed(888)
# generating random theta:
theta &lt;- rnorm(20)
# generating an item bank under a 3-parameter binary response model:
b.params &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = .2)

# you can indicate class of params or extract it from simIrt object:
class(b.params) &lt;- "brm"

# calculating KL information with delta = .1:
k.info1 &lt;- KL(params = b.params, theta = theta, delt = .1)
# changing delta to .2
k.info2 &lt;- KL(params = b.params, theta = theta, delt = .2)

# notice how the overall information has increased when increasing delt:
k.info1$test; k.info2$test

# also compare with Fisher information:
f.info &lt;- FI(params = b.params, theta = theta, type = "expected")

k.info2$test; f.info$test

# Fisher information is much higher because of how it weighs things.

## 2 ##
# we can maximize information at a boundary - say "0":
k.info3 &lt;- KL(params = b.params, theta = 0, delta = .1)
b.params[which.max(k.info3$item), ]

# notice how the a parameter is high while the b parameter is close to
# 0, so item selection is working.

# does Fisher information choose a different item?
f.info2 &lt;- FI(params = b.params, theta = 0, type = "expected")
b.params[which.max(f.info2$item), ]

# nope - although with more items, who knows?


#########################
# Graded Response Model #
#########################

## 1 ##
set.seed(999)
# generating random theta
theta &lt;- rnorm(20)
# generating an item bank under a graded response model:
g.params &lt;- cbind(runif(100, .5, 1.5), rnorm(100), rnorm(100),
                                       rnorm(100), rnorm(100), rnorm(100))
# simulating responses (so that the parameters are ordered - see simIrt)
g.params &lt;- simIrt(theta = theta, params = g.params, mod = "grm")$params[ , -1]

# we can calculate KL information as before, noting that class(g.params) is "grm"
class(g.params)     # so we don't need to set it ourselves

# and now KL info with delt = .1
k.info4 &lt;- KL(theta = theta, params = g.params)

# KL information is higher when more boundaries
k.info4$test
k.info1$test

# Note: k.info1 would be exactly the same if calculated with the "grm"
#       rather than the "brm"

## 2 ##
# we can also maximize information at boundary "0"
k.info5 &lt;- KL(params = g.params, theta = 0, delta = .1)
g.params[which.max(k.info5$item), ]

# notice how the a parameter is high while the b parameters are pretty spread out.

# does Fisher information choose a different item?
f.info3 &lt;- FI(params = g.params, theta = 0, type = "expected")
g.params[which.max(f.info3$item), ]

# nope - although with more items, who knows?
</code></pre>

<hr>
<h2 id='mleEst'>Estimate Ability in IRT Models</h2><span id='topic+mleEst'></span><span id='topic+wleEst'></span><span id='topic+bmeEst'></span><span id='topic+eapEst'></span>

<h3>Description</h3>

<p><code>mleEst</code>, <code>wleEst</code>, <code>bmeEst</code>, and <code>eapEst</code> estimate
ability in IRT models. <code>mleEst</code> is Maximum Likelihood Information, <code>wleEst</code> is
Weighted Likelihood Information (see <b>Details</b>), <code>bmeEst</code> is
Bayesian-Modal Estimation, and <code>eapEst</code> is Expected-A-Posterior Estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mleEst( resp, params, range = c(-6, 6), mod = c("brm", "grm"), ... )
wleEst( resp, params, range = c(-6, 6), mod = c("brm", "grm"), ... )
bmeEst( resp, params, range = c(-6, 6), mod = c("brm", "grm"),
        ddist = dnorm, ... )
eapEst( resp, params, range = c(-6, 6), mod = c("brm", "grm"),
        ddist = dnorm, quad = 33, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mleEst_+3A_resp">resp</code></td>
<td>
<p><b>numeric:</b> either a <code class="reqn">N \times J</code> matrix (where <code class="reqn">N</code> indicates the
number of simulees and <code class="reqn">J</code> indicates the number of items), a
<code class="reqn">N</code> length vector (if there is only one item) or a <code class="reqn">J</code> length
vector (if there is only one simulee).  For the binary response model
(<span class="option">"brm"</span>), <code>resp</code> must solely contain 0s and 1s.  For the
graded response model (<span class="option">"grm"</span>), <code>resp</code> must solely contain
integers <code class="reqn">1, \ldots, K</code>, where <code class="reqn">K</code> is the number of categories, as
indicated by the dimension of <code>params</code>.
</p>
</td></tr>
<tr><td><code id="mleEst_+3A_params">params</code></td>
<td>
<p><b>numeric:</b> a vector or matrix of item parameters.  If specified
as a matrix, the rows must index the items, and the columns
must designate the item parameters.
</p>
</td></tr>
<tr><td><code id="mleEst_+3A_range">range</code></td>
<td>
<p><b>numeric:</b> a two-element numeric vector indicating the minimum and maximum over
which to optimize a likelihood function (<code>mleEst</code>) or posterior distribution
(<code>bmeEst</code>), find roots to a score function (<code>wleEst</code>), or integrate
over (<code>eapEst</code>).
</p>
</td></tr>
<tr><td><code id="mleEst_+3A_mod">mod</code></td>
<td>
<p><b>character:</b> a character string indicating the IRT model.  Current support
is for the 3-parameter binary response model (<span class="option">"brm"</span>),
and Samejima's graded response model (<span class="option">"grm"</span>).
See <code><a href="#topic+simIrt">simIrt</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="mleEst_+3A_ddist">ddist</code></td>
<td>
<p><b>function:</b> a function that calculates prior densities for Bayesian
estimation.  For instance, if you wish to specify a normal prior, <code>ddist = dnorm</code>,
and if you wish to specify a uniform prior, <code>ddist = dunif</code>.  Note that
it is standard in R to use <code>d</code>... to indicate a density.
</p>
</td></tr>
<tr><td><code id="mleEst_+3A_quad">quad</code></td>
<td>
<p><b>numeric:</b> a scalar indicating the number of quadrature points when
using <code>eapEst</code>.  See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="mleEst_+3A_...">...</code></td>
<td>
<p>arguments passed to <code>ddist</code>, usually distribution parameters
identified by name.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions return estimated &quot;ability&quot; for the binary response model (<span class="option">"brm"</span>)
and the graded response model (<span class="option">"grm"</span>).  The only difference between the functions
is how they estimate ability.
</p>
<p>The function <code>mleEst</code> searches for a maximum of the log-likelihood with respect to
each individual <code class="reqn">\theta_i</code> and uses <code class="reqn">[T(\theta)]^{-1/2}</code> as the corresponding standard
error of measurement (SEM), where <code class="reqn">T(\theta)</code> is the observed test information function
at <code class="reqn">\theta</code>, as described in <code><a href="#topic+FI">FI</a></code>.
</p>
<p>The function <code>bmeEst</code> searches for the maximum of the log-likelihood after a
log-prior is added, which effectively maximizes the posterior distribution for each
individual <code class="reqn">\theta_i</code>.  The SEM of the <code>bmeEst</code> estimator uses the well known
relationship (Keller, 2000, p. 10)
</p>
<p style="text-align: center;"><code class="reqn">V[\theta | \boldsymbol{u}_i]^{-1} = T(\theta) - \frac{\partial \log[p(\theta)]}{\partial \theta^2}</code>
</p>

<p>where <code class="reqn">V[\theta | \boldsymbol{u}_i]</code> is the variance of <code class="reqn">\theta</code> after
taking into consideration the prior distribution and <code class="reqn">p(\theta)</code> is the prior distribution
of <code class="reqn">\theta</code>.  The function <code>bmeEst</code> estimates the second derivative of the prior
distribution uses the <code>hessian</code> function in the <code>numDeriv</code> package.
</p>
<p>The function <code>wleEst</code> searches for the root of a modified score function (i.e.
the first derivative of the log-likelihood with something added to it).  The modification
corrects for bias in fixed length tests, and estimation using this modification results in
what is called Weighted Maximum Likelihood (or alternatively, the Warm estimator) (see Warm,
1989).  So rather than maximizing the likelihood, <code>wleEst</code> finds a root of:
</p>
<p style="text-align: center;"><code class="reqn"> \frac{\partial l(\theta)}{\partial \theta} + \frac{H(\theta)}{2I(\theta)}</code>
</p>

<p>where <code class="reqn">l(\theta)</code> is the log-likelihood of <code class="reqn">\theta</code> given a set of responses
and item parameters, <code class="reqn">I(\theta)</code> is expected test information to this point,
and <code class="reqn">H(\theta)</code> is a correction constant defined as:
</p>
<p style="text-align: center;"><code class="reqn"> H(\theta) = \sum_j\frac{p_{ij}^{\prime}p_{ij}^{\prime\prime}}{p_{ij}[1 - p_{ij}]}</code>
</p>

<p>for the binary response model, where <code class="reqn">p_{ij}^{\prime}</code> is the first derivative
of <code class="reqn">p_{ij}</code> with respect to <code class="reqn">\theta</code>, <code class="reqn">p_{ij}^{\prime\prime}</code> is
the second derivative of <code class="reqn">p_{ij}</code> with respect to <code class="reqn">\theta</code>, and <code class="reqn">p_{ij}</code> is the
probability of response, as indicated in the help page for <code><a href="#topic+simIrt">simIrt</a></code>, and
</p>
<p style="text-align: center;"><code class="reqn"> H(\theta) = \sum_j\sum_k\frac{P_{ijk}^{\prime}P_{ijk}^{\prime\prime}}{P_{ijk}}</code>
</p>

<p>for the graded response model, where <code class="reqn">P_{ijk}^{\prime}</code> is the first derivative
of <code class="reqn">P_{ijk}</code> with respect to <code class="reqn">\theta</code>, <code class="reqn">P_{ijk}^{\prime\prime}</code> is
the second derivative of <code class="reqn">P_{ijk}</code>, and <code class="reqn">P_{ijk}</code> is the probability of responding
in category k as indicated in the help page for <code><a href="#topic+simIrt">simIrt</a></code>.  The SEM of the <code>wleEst</code>
estimator uses an approximation based on Warm (1989, p. 449):
</p>
<p style="text-align: center;"><code class="reqn"> V(\theta) \approx \frac{T(\theta) + \frac{H(\theta)}{2I(\theta)}}{T^2(\theta)}</code>
</p>

<p>The function <code>eapEst</code> finds the mean and standard deviation of the posterior distribution
given the log-likelihood, a prior distribution (with specified parameters), and the number of
quadrature points using the standard Bayesian identity with summations in place of integrations
(see Bock and Mislevy, 1982). Rather than using the adaptive, quadrature based <code>integrate</code>,
<code>eapEst</code> uses the flexible <code>integrate.xy</code> function in the <code>sfsmisc</code> package. 
As long as the prior distribution is reasonable (such that the joint distribution is relatively smooth),
this method should work.
</p>


<h3>Value</h3>

<p><code>mleEst</code>, <code>wleEst</code>, <code>bmeEst</code>, and <code>eapEst</code> return a list of the
following elements:
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>an <code class="reqn">N</code>-length vector of ability values, one for each simulee.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>an <code class="reqn">N</code>-length vector of observed test information, one for each simulee.
Test information is the sum of item information across items.  See <code><a href="#topic+FI">FI</a></code>
for more information.
</p>
</td></tr>
<tr><td><code>sem</code></td>
<td>
<p>an <code class="reqn">N</code>-length vector of observed standard error of measurement (or posterior standard
deviation) for each simulee.  See <code><a href="#topic+FI">FI</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For the binary response model (<span class="option">"brm"</span>), it makes no sense to estimate
ability with a non-mixed response pattern (all 0s or all 1s).  The user might want
to include enough items in the model to allow for reasonable estimation.
</p>
<p>Weighted likelihood estimation (<code>wleEst</code>) uses <code>uniroot</code> to find the root
of the modified score function, so that the end points of <span class="option">range</span> must evaluate
to opposite signs (or zero).  Rarely, the end points of <span class="option">range</span> will evaluate
to the same sign, so that <code>uniroot</code> will error.  In these cases, uniroot will
extend the interval until the end points of the (modified) range are opposite signs.
</p>


<h3>Author(s)</h3>

<p>Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D., &amp; Mislevy, R. J.  (1982).  Adaptive EAP estimation of ability in a microcomputer environment.  <em>Applied Psychological Measurement</em>, <em>6</em>, 431 &ndash; 444.
</p>
<p>Embretson, S. E., &amp; Reise, S. P.  (2000).  <em>Item Response Theory for Psychologists</em>.  Mahway, NJ: Lawrence Erlbaum Associates.
</p>
<p>Keller (2000).  <em>Ability estimation procedures in computerized adaptive testing</em> (Technical Report).  New York, NY: American Institute of Certified Public Accountants.
</p>
<p>Warm, T. A.  (1989).  Weighted likelihood estimation of ability in item response theory.  <em>Psychometrika</em>, <em>54</em>, 427 &ndash; 450.
</p>
<p>van dr Linden, W. J. &amp; Pashley, P. J.  (2010).  Item selection and ability estimation in adaptive testing.  In W. J. van der Linden &amp; C. A. W. Glas (Eds.), <em>Elements of Adaptive Testing</em>.  New York, NY: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catIrt">catIrt</a></code>, <code><a href="#topic+simIrt">simIrt</a></code>,
<code><a href="numDeriv.html#topic+hessian">hessian</a></code>, <code><a href="stats.html#topic+uniroot">uniroot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#########################
# Binary Response Model #
#########################
set.seed(888)
# generating random theta:
theta &lt;- rnorm(201)
# generating an item bank under a 2-parameter binary response model:
b.params &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = 0)
# simulating responses using specified theta:
b.resp &lt;- simIrt(theta = theta, params = b.params, mod = "brm")$resp


# estimating theta using all four methods:
est.mle1 &lt;- mleEst(resp = b.resp, params = b.params, mod = "brm")$theta
est.wle1 &lt;- wleEst(resp = b.resp, params = b.params, mod = "brm")$theta
est.bme1 &lt;- bmeEst(resp = b.resp, params = b.params, mod = "brm",
                   ddist = dnorm, mean = 0, sd = 1)$theta
est.eap1 &lt;- eapEst(resp = b.resp, params = b.params, mod = "brm",
                   ddist = dnorm, mean = 0, sd = 1, quad = 33)$theta

# eap takes a while!

# all of the methods are highly correlated:
cor(cbind(theta = theta, mle = est.mle1, wle = est.wle1,
                         bme = est.bme1, eap = est.eap1))

# you can force eap to be positive:
est.eap2 &lt;- eapEst(resp = b.resp, params = b.params, range = c(0, 6),
                                  mod = "brm", ddist = dunif, min = 0, max = 6)$theta

est.eap2

# if you only have a single response, MLE will give junk!
mleEst(resp = 0, params = c(1, 0, .2), mod = "brm")$theta

# the others will give you answers that are not really determined by the response:
wleEst(resp = 0, params = c(1, 0, .2), mod = "brm")$theta
bmeEst(resp = 0, params = c(1, 0, .2), mod = "brm")$theta
eapEst(resp = 0, params = c(1, 0, .2), mod = "brm")$theta


#########################
# Graded Response Model #
#########################
set.seed(999)
# generating random theta
theta &lt;- rnorm(400)
# generating an item bank under a graded response model:
g.params &lt;- cbind(a = runif(100, .5, 1.5), b1 = rnorm(100), b2 = rnorm(100),
                                           b3 = rnorm(100), b4 = rnorm(100))
# simulating responses using random theta:
g.mod &lt;- simIrt(params = g.params, theta = theta, mod = "grm")

# pulling out the responses and the parameters:
g.params2 &lt;- g.mod$params[ , -1]       # now the parameters are sorted
g.resp2 &lt;- g.mod$resp

# estimating theta using all four methods:
est.mle3 &lt;- mleEst(resp = g.resp2, params = g.params2, mod = "grm")$theta
est.wle3 &lt;- wleEst(resp = g.resp2, params = g.params2, mod = "grm")$theta
est.bme3 &lt;- bmeEst(resp = g.resp2, params = g.params2, mod = "grm",
                   ddist = dnorm, mean = 0, sd = 1)$theta
est.eap3 &lt;- eapEst(resp = g.resp2, params = g.params2, mod = "grm",
                   ddist = dnorm, mean = 0, sd = 1, quad = 33)$theta

# and the correlations are still pretty high:
cor(cbind(theta = theta, mle = est.mle3, wle = est.wle3,
                         bme = est.bme3, eap = est.eap3))

# note that the graded response model is just a generalization of the brm:
cor(est.mle1, mleEst(resp = b.resp + 1, params = b.params[ , -3], mod = "grm")$theta)
cor(est.wle1, wleEst(resp = b.resp + 1, params = b.params[ , -3], mod = "grm")$theta)
cor(est.bme1, bmeEst(resp = b.resp + 1, params = b.params[ , -3], mod = "grm")$theta)
cor(est.eap1, eapEst(resp = b.resp + 1, params = b.params[ , -3], mod = "grm")$theta)


## End(Not run)

</code></pre>

<hr>
<h2 id='simIrt'>Simulate Responses to IRT Models</h2><span id='topic+simIrt'></span>

<h3>Description</h3>

<p><code>simIrt</code> simulates responses to various IRT models given a vector of ability
values and a vector/matrix of item parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simIrt( theta = seq(-3, 3, by = 0.1), params, mod = c("brm", "grm") )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simIrt_+3A_theta">theta</code></td>
<td>
<p><b>numeric:</b> a vector of ability values, one for each
simulee.
</p>
</td></tr>
<tr><td><code id="simIrt_+3A_params">params</code></td>
<td>
<p><b>numeric:</b> a vector or matrix of item parameters.  If specified as
a matrix, the rows must index the items, and the columns
must designate the item parameters.  For the binary response model,
(<span class="option">"brm"</span>), <code>params</code> must either be a 3-element vector
or a 3-column matrix.  See <b>Details</b> for more information.
</p>
</td></tr>
<tr><td><code id="simIrt_+3A_mod">mod</code></td>
<td>
<p><b>character:</b> a character string indicating the IRT model.  Current support
is for the 3-parameter binary response model (<span class="option">"brm"</span>),
and Samejima's graded response model (<span class="option">"grm"</span>).  The contents
of <code>params</code> must match the designation of <code>mod</code>.  See
<b>Details</b> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>simIrt</code> returns a response matrix of class &quot;brm&quot; or &quot;grm&quot; depending
on the model.  For the binary response model, the probability of endorsing item <code class="reqn">j</code>
for simulee <code class="reqn">i</code> is the following (Embretson &amp; Reise, 2000):
</p>
<p style="text-align: center;"><code class="reqn"> p_{ij} = Pr(u_{ij} = 1 | \theta_i, a_j, b_j, c_j) = c_j + (1 - c_j)\frac{1}{1 + \exp[-a(\theta - b)]} </code>
</p>

<p>For the graded response model, the probability of endorsing at or above boundary <code class="reqn">k</code>
of item <code class="reqn">j</code> for simulee <code class="reqn">i</code> is the following:
</p>
<p style="text-align: center;"><code class="reqn"> p_{ijk} = Pr(u_{ij} \geq k | \theta_i, a_j, b_k) = \frac{1}{1 + \exp[-a(\theta - b_k)]} </code>
</p>

<p>so that the probability of scoring <em>in</em> category <code class="reqn">k</code> is,
<code class="reqn">P_{ijk} = Pr(u_{ij} = k | \theta_i, a_j, \boldsymbol{b}) = 1 - p_{ijk}</code> if <code class="reqn">k = 1</code>;
<code class="reqn">p_{ijk}</code> if <code class="reqn">k = K</code>; and <code class="reqn">p_{ij(k - 1)} - p_{ijk}</code> otherwise, where <code class="reqn">K</code>
is the number of categories, so that <code class="reqn">K - 1</code> is the number of boundaries.
</p>
<p>Assuming perfect model fit, <code>simIrt</code> generates the probability of responding in a category,
simulates a random, uniform deviate, and compares the probability of response with the location
of the deviate.  For instance, for the binary response model, if <code class="reqn">p_{ij} = .7</code>, so that
<code class="reqn">q_{ij} = 1 - p_{ij} = .3</code>, <code>simIrt</code> will generate a uniform deviate (<code class="reqn">u_{ij}</code>) between 0 and 1.  
If <code class="reqn">u_{ij} &lt; p_{ij}</code>, the simulee will score a 1, and otherwise, the simulee will score a 0.
</p>


<h3>Value</h3>

<p>The function <code>simIrt</code> returns a list of the following elements:
</p>
<table role = "presentation">
<tr><td><code>resp</code></td>
<td>
<p>a matrix of class &quot;brm&quot; or &quot;grm&quot; depending on the model used.
The dimensions of the matrix will be <code class="reqn">N \times J</code> (persons by items),
and will contain 0s and 1s for the binary response model or <code class="reqn">1 \ldots K</code>
for the graded response model, where <em>K</em> indicates the number of categories.
</p>
</td></tr>
<tr><td><code>params</code></td>
<td>
<p>a matrix of class &quot;brm&quot; or &quot;grm&quot; containing the item parameters used 
in the simulation.  In the case of &quot;grm&quot;, the threshold parameters will be
ordered so that they will work in other functions.
</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>a vector of theta used in the simulation.  If <code>theta</code> is not specified
by the user, it will default to a 201-length vector of evenly spaced points
between -3 and 3.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven W. Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a>
</p>


<h3>References</h3>

<p>Embretson, S. E., &amp; Reise, S. P.  (2000).  <em>Item Response Theory for Psychologists</em>.  Mahway, NJ: Lawrence Erlbaum Associates.
</p>
<p>Samejima, F.  (1969).  Estimation of latent ability using a response pattern of graded scores.  <em>Psychometrika Monograph Supplement</em>, <em>34</em>, 100 &ndash; 114.
</p>
<p>van der Linden, W. J. &amp; Hambleton, R. K.  (2010).  <em>Handbook of Modern Item Response Theory</em>.  New York, NY: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+catIrt">catIrt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################
# Binary Response Model #
#########################
set.seed(888)
# generating an item bank under a binary response model:
b.params &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = .2)
# simulating responses using default theta:
b.mod &lt;- simIrt(params = b.params, mod = "brm")

# same type of model without a guessing (c) parameter:
b.params2 &lt;- cbind(a = runif(100, .5, 1.5), b = rnorm(100, 0, 2), c = 0)
b.mod2 &lt;- simIrt(params = b.params2, mod = "brm")

# now generating a different theta:
theta &lt;- rnorm(201)
b.mod3 &lt;- simIrt(theta = theta, params = b.params2, mod = "brm")

# notice all of the responses are 0 or 1:
unique(as.vector(b.mod$resp))

# and the percentages (in general) increase as theta increases:
apply(b.mod$resp, 1, mean)    # theta = seq(-3, 3, by = 0.1)


#########################
# Graded Response Model #
#########################
set.seed(999)
# generating an item bank under a graded response model:
# (as many categories as your heart desires!)
g.params &lt;- cbind(a = runif(10, .5, 1.5), b1 = rnorm(10), b2 = rnorm(10),
                                          b3 = rnorm(10))
# simulating responses using default theta (automatically sorts boundaries):
g.mod &lt;- simIrt(params = g.params, mod = "grm")

# notice how the old parameters were not sorted:
g.params
# but the new parameters are sorted from column 2 on:
g.mod$params

# don't use these parameters with the binary response model:
try(simIrt(params = g.params, mod = "brm"), silent = TRUE)[1]

# a better parameter set for the graded response model:
g.params2 &lt;- cbind(runif(100, .5, 1.5), b1 = runif(100, -2, -1), b2 = runif(100, -1, 0),
                                        b3 = runif(100, 0, 1), b4 = runif(100, 1, 2))
g.mod2 &lt;- simIrt(params = g.params2, mod = "grm")

# notice all of the responses are positive integers:
unique(as.vector(g.mod$resp))
unique(as.vector(g.mod2$resp))

# and the responses (in general) increase as theta increases:
apply(g.mod2$resp, 1, mean)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
