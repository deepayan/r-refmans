<!DOCTYPE html><html lang="en"><head><title>Help for package bnmonitor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bnmonitor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.onAttach'><p>Message for the User</p></a></li>
<li><a href='#amalgamation'><p>Amalgamation of levels</p></a></li>
<li><a href='#asy_measure'><p>Measures of asymmetric independence</p></a></li>
<li><a href='#bn2'><p>Integration with <code>bn.fit</code> objects from <code>bnlearn</code></p></a></li>
<li><a href='#bnmonitor'><p>bnmonitor: A package for sensitivity analysis and robustness in Bayesian networks</p></a></li>
<li><a href='#cachexia'><p>Bayesian networks for a cachexia study</p></a></li>
<li><a href='#CD'><p>CD-distance</p></a></li>
<li><a href='#chds'><p>Christchurch Health and Development Study</p></a></li>
<li><a href='#covariance_var'><p>Standard variation of the covariance matrix</p></a></li>
<li><a href='#covariation'><p>Co-variation schemes</p></a></li>
<li><a href='#covariation_matrix'><p>Co-variation matrices</p></a></li>
<li><a href='#diabetes'><p>Pima Indian Diabetes Data</p></a></li>
<li><a href='#diameter'><p>Diameters in a Bayesian network</p></a></li>
<li><a href='#dwi'><p>Distance-weigthed influence</p></a></li>
<li><a href='#edge_strength'><p>Strength of edges in a Bayesian network</p></a></li>
<li><a href='#ewi'><p>Edge-weigthed influence</p></a></li>
<li><a href='#final_node_monitor'><p>Final node monitors</p></a></li>
<li><a href='#fire_alarm'><p>Bayesian network on fire alarm system</p></a></li>
<li><a href='#Fro'><p>Frobenius norm</p></a></li>
<li><a href='#Fro.CI'><p>Frobenius norm for <code>CI</code></p></a></li>
<li><a href='#Fro.GBN'><p>Frobenius norm for <code>GBN</code></p></a></li>
<li><a href='#global_monitor'><p>Global monitor</p></a></li>
<li><a href='#influential_obs'><p>Influential observations</p></a></li>
<li><a href='#Jeffreys'><p>Jeffreys Divergence</p></a></li>
<li><a href='#Jeffreys.CI'><p>Jeffreys Divergence for <code>CI</code></p></a></li>
<li><a href='#Jeffreys.GBN'><p>Jeffreys Divergence for <code>GBN</code></p></a></li>
<li><a href='#KL'><p>KL Divergence</p></a></li>
<li><a href='#KL_bounds'><p>Bounds for the KL-divergence</p></a></li>
<li><a href='#KL.bn.fit'><p>KL Divergence for <code>bn.fit</code></p></a></li>
<li><a href='#KL.CI'><p>KL Divergence for <code>CI</code></p></a></li>
<li><a href='#KL.GBN'><p>KL Divergence for <code>GBN</code></p></a></li>
<li><a href='#mathmarks'><p>Math Marks Data</p></a></li>
<li><a href='#mean_var'><p>Standard variation of the mean vector</p></a></li>
<li><a href='#model_pres_cov'><p>Model-Preserving co-variation</p></a></li>
<li><a href='#mutual_info'><p>Mutual information</p></a></li>
<li><a href='#node_monitor'><p>Node monitor</p></a></li>
<li><a href='#plot'><p>Plotting methods</p></a></li>
<li><a href='#print'><p>Printing methods</p></a></li>
<li><a href='#psd_check'><p>Check for positive semi-definiteness after a perturbation</p></a></li>
<li><a href='#sensitivity'><p>Sensitivity function</p></a></li>
<li><a href='#sensquery'><p>Sensitivity of probability query</p></a></li>
<li><a href='#seq_node_monitor'><p>Sequential node monitors</p></a></li>
<li><a href='#seq_pa_ch_monitor'><p>Sequential parent-child node monitors</p></a></li>
<li><a href='#synthetic_bn'><p>A synthetic Bayesian network</p></a></li>
<li><a href='#synthetic_cbn'><p>A synthetic continuous Bayesian network</p></a></li>
<li><a href='#travel'><p>Bayesian network on travel survey</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>An Implementation of Sensitivity Analysis in Bayesian Networks</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of sensitivity and robustness methods in Bayesian networks in R. It includes methods to perform parameter variations via a variety of co-variation schemes, to compute sensitivity functions and to quantify the dissimilarity of two Bayesian networks via distances and divergences. It further includes diagnostic methods to assess the goodness of fit of a Bayesian networks to data, including global, node and parent-child monitors. Reference: M. Leonelli, R. Ramanathan, R.L. Wilkerson (2022) &lt;<a href="https://doi.org/10.1016%2Fj.knosys.2023.110882">doi:10.1016/j.knosys.2023.110882</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>bnlearn, dplyr, ggplot2, gRain, gRbase, graphics, igraph,
methods, purrr, qgraph, RColorBrewer, reshape2, rlang, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://manueleleonelli.github.io/bnmonitor/">https://manueleleonelli.github.io/bnmonitor/</a>,
<a href="https://github.com/manueleleonelli/bnmonitor">https://github.com/manueleleonelli/bnmonitor</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-23 11:59:52 UTC; manueleleonelli</td>
</tr>
<tr>
<td>Author:</td>
<td>Manuele Leonelli [aut, cre],
  Ramsiya Ramanathan [aut],
  Rachel Wilkerson [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manuele Leonelli &lt;manuele.leonelli@ie.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-23 13:01:35 UTC</td>
</tr>
</table>
<hr>
<h2 id='.onAttach'>Message for the User</h2><span id='topic+.onAttach'></span>

<h3>Description</h3>

<p>Prints out a friendly reminder message to the user.
</p>

<hr>
<h2 id='amalgamation'>Amalgamation of levels</h2><span id='topic+amalgamation'></span>

<h3>Description</h3>

<p>Computation of the diameter of children conditional probability tables when levels of a variable are merged.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amalgamation(bnfit, node)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="amalgamation_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="amalgamation_+3A_node">node</code></td>
<td>
<p>a node of <code>bnfit</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where each entry refers to a child of <code>node</code>. For each child, the function reports the diameter resulting from the amalgamation of any pair of levels.
</p>


<h3>References</h3>

<p>Leonelli, M., Smith, J. Q., &amp; Wright, S. K. (2024). The diameter of a stochastic matrix: A new measure for sensitivity analysis in Bayesian networks. arXiv preprint arXiv:2407.04667.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>amalgamation(synthetic_bn, "y1")


</code></pre>

<hr>
<h2 id='asy_measure'>Measures of asymmetric independence</h2><span id='topic+asy_measure'></span>

<h3>Description</h3>

<p>Computation of the indexes of context-specific and partial independence in a conditional probability table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asy_measure(bnfit, node)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="asy_measure_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="asy_measure_+3A_node">node</code></td>
<td>
<p>a node of <code>bnfit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The index of context-specific independence computes the upper diameter of a CPT where all parents but one are fixed, while the index of partial independence computes the lower diameter for the same CPT. If the lower diameter is close to zero it means that there are at least two rows of the CPT which are very similar to each other, thus implying a partial conditional independence.
</p>


<h3>Value</h3>

<p>A list where each entry refers to one of the parent of <code>node</code>. Each entry of the list is a dataframe with the index of context-specific independence for each outcome of the conditioning parent in one column and in additional column the index of partial independence in the case of non-binary variables.
</p>


<h3>References</h3>

<p>Leonelli, M., Smith, J. Q., &amp; Wright, S. K. (2024). The diameter of a stochastic matrix: A new measure for sensitivity analysis in Bayesian networks. arXiv preprint arXiv:2407.04667.
</p>
<p>Pensar, J., Nyman, H., Lintusaari, J., &amp; Corander, J. (2016). The role of local partial independence in learning of Bayesian networks. International Journal of Approximate Reasoning, 69, 91-105.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diameter">diameter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>asy_measure(synthetic_bn, "y3")

</code></pre>

<hr>
<h2 id='bn2'>Integration with <code>bn.fit</code> objects from <code>bnlearn</code></h2><span id='topic+bn2'></span><span id='topic+bn2gbn'></span><span id='topic+bn2ci'></span>

<h3>Description</h3>

<p>Functions that transform an object of class <code>bn.fit</code> and <code>bn.fit.gnet</code> (a Gaussian Bayesian network) to objects of class <code>GBN</code> or <code>CI</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bn2gbn(bnfit)

bn2ci(bnfit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bn2_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>bn2gbn</code> returns an object of class <code>GBN</code> consisting of a list with entries:
</p>

<ul>
<li> <p><code>order</code>: An ordering of the nodes according to the graph.
</p>
</li>
<li> <p><code>mean</code>: The mean vector of the Gaussian distribution.
</p>
</li>
<li> <p><code>covariance</code>: The covariance matrix of the Gaussian distribution.
</p>
</li></ul>

<p>The function <code>bn2ci</code> returns an object of class <code>CI</code> consisting of the same list as <code>GBN</code>, but with the additional entry <code>cond_ind</code>. <code>cond_ind</code> is a list where each entry consists of <code>A</code>, <code>B</code> and <code>C</code> corresponding to the conditional independence statements <code>A</code> independent of <code>B</code> given <code>C</code> embedded by the network.
</p>

<hr>
<h2 id='bnmonitor'>bnmonitor: A package for sensitivity analysis and robustness in Bayesian networks</h2><span id='topic+bnmonitor'></span>

<h3>Description</h3>

<p>Sensitivity and robustness analysis for Bayesian networks.
</p>


<h3>Details</h3>

<p>bnmonitor provides functions to perform sensitivity analysis for both discrete Bayesian networks (DBNs) and Gaussian Bayesian networks (GBNs). The following types of sensitivity investigations are available:
</p>

<ul>
<li> <p><strong>Parametric sensitivity analysis</strong>: Investigate the effect of changes in some of the parameter values in a Bayesian network and quantify the difference between the original and perturbed Bayesian networks using dissimilarity measures (both for DBNs and GBNs).
</p>
</li>
<li> <p><strong>Robustness to data</strong>: Verify how well a Bayesian network fits a specific dataset that was used either for learning or for testing (only for DBNs).
</p>
</li>
<li> <p><strong>Node influence</strong>: Quantify how much the nodes of a Bayesian network influence an output node of interest (only for DBNs).
</p>
</li>
<li> <p><strong>Edge strength</strong>: Assess the strength of the edges of a Bayesian network (only for DBNs).
</p>
</li>
<li> <p><strong>Other investigations</strong>: Including the diameter of the conditional probability tables, measures of asymmetric independence, and level amalgamation.
</p>
</li></ul>



<h3>DBNs - Robustness to data</h3>

<p>The available functions for robustness are:
</p>

<ul>
<li> <p><em>Node monitors</em> (<code><a href="#topic+node_monitor">node_monitor</a></code>): contribution of each vertex to the overall log-likelihood of the model.
</p>
</li>
<li> <p><em>Observation's influence</em> (<code><a href="#topic+influential_obs">influential_obs</a></code>): difference in the log-likelihood of a model learnt with the full dataset and with all but one observation.
</p>
</li>
<li> <p><em>Final node monitors</em> (<code><a href="#topic+node_monitor">node_monitor</a></code>): marginal and conditional node monitors to assess the fit of a vertex distribution to the full dataset.
</p>
</li>
<li> <p><em>Sequential node monitors</em> (<code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>): marginal and conditional node monitors for a specific vertex only using sequentially subsets of the dataset.
</p>
</li>
<li> <p><em>Sequential parent-child monitor</em> (<code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>): parent-child node monitor for a specific vertex and a specific configuration of its parents using sequentially subsets of the dataset.
</p>
</li></ul>



<h3>DBNs - Co-variation schemes</h3>

<p>The available co-variation schemes are:
</p>

<ul>
<li> <p><em>Uniform co-variation scheme</em> (<code><a href="#topic+uniform_covar">uniform_covar</a></code>): distributes the probability mass to be co-varied uniformly among the co-varying parameters.
</p>
</li>
<li> <p><em>Proportional co-variation scheme</em> (<code><a href="#topic+proportional_covar">proportional_covar</a></code>): distributes the probability mass to be co-varied in the same proportion as in the original Bayesian network.
</p>
</li>
<li> <p><em>Order-preserving co-variation scheme</em> (<code><a href="#topic+orderp_covar">orderp_covar</a></code>):distributes the to be co-varied probability mass among the co-varying parameters so that the original order of parameters is preserved.
</p>
</li></ul>



<h3>DBNs - Dissimilarity measures</h3>

<p>The dissimilarity measures quantify the difference between a Bayesian network and its update after parameter variation.<br />
The available dissimilarity measures are:
</p>

<ul>
<li> <p><em>Chan-Darwiche distance</em> (<code><a href="#topic+CD">CD</a></code>)
</p>
</li>
<li> <p><em>Kullback-Leibler divergence</em> (<code><a href="#topic+KL">KL</a></code>)
</p>
</li></ul>



<h3>DBNs - Sensitivity functions</h3>

<p>The available functions for sensitivity analysis are:
</p>

<ul>
<li> <p><em>Sensitivity function</em> (<code><a href="#topic+sensitivity">sensitivity</a></code>): returns a certain probability of interest given a parameter change. Evidence can be considered.
</p>
</li>
<li> <p><em>Sensitivity query</em> (<code><a href="#topic+sensquery">sensquery</a></code>): returns the parameter changes needed to get a certain probability of interest. Evidence can be considered.
</p>
</li></ul>



<h3>DBNs - Node influence</h3>

<p>The available functions for node influence are:
</p>

<ul>
<li> <p><em>Mutual information</em> (<code><a href="#topic+mutual_info">mutual_info</a></code>): returns the mutual information between a node and all other nodes of a DBN.
</p>
</li>
<li> <p><em>Distance-weighted influence</em> (<code><a href="#topic+dwi">dwi</a></code>): returns the distance-weighted influence between a node and all other nodes of a DBN.
</p>
</li>
<li> <p><em>Edge-weighted influence</em> (<code><a href="#topic+ewi">ewi</a></code>): returns the edge-weighted influence between a node and all other nodes of a DBN.
</p>
</li></ul>



<h3>DBNs - Edge strength</h3>

<p>The available functions for edge strength are:
</p>

<ul>
<li> <p><em>Measure of edge strength</em> (<code><a href="#topic+edge_strength">edge_strength</a></code>): returns the edge strength measure for all edges of a DBN.
</p>
</li></ul>



<h3>DBNs - Other sensitivity measures</h3>

<p>Other sensitivity measures available are:
</p>

<ul>
<li> <p><em>Diameter</em> (<code><a href="#topic+diameter">diameter</a></code>): returns the diameter of the conditional probability tables of all non-root nodes of a DBN.
</p>
</li>
<li> <p><em>Level amalgamation</em> (<code><a href="#topic+amalgamation">amalgamation</a></code>): returns the diameter of all children conditional probability tables of a node in DBN when every pair of levels are merged.
</p>
</li>
<li> <p><em>Measures of asymmetric independence</em> (<code><a href="#topic+asy_measure">asy_measure</a></code>): returns the indexes of context-specific and partial conditional independence for all variables of a DBN.
</p>
</li></ul>



<h3>GBNs - Model-Preserving matrices</h3>

<p>The available functions to construct model-preserving co-variation matrices are:
</p>

<ul>
<li> <p><em>Total co-variation matrix</em> (<code><a href="#topic+total_covar_matrix">total_covar_matrix</a></code>).
</p>
</li>
<li> <p><em>Partial co-variation matrix</em> (<code><a href="#topic+partial_covar_matrix">partial_covar_matrix</a></code>).
</p>
</li>
<li> <p><em>Row-based co-variation matrix</em> (<code><a href="#topic+row_covar_matrix">row_covar_matrix</a></code>).
</p>
</li>
<li> <p><em>Column-based co-variation matrix</em> (<code><a href="#topic+col_covar_matrix">col_covar_matrix</a></code>).
</p>
</li></ul>



<h3>GBNs - Mean and Covariance variations</h3>

<p>The available functions to perturb the distribution of a GBN are:
</p>

<ul>
<li> <p><em>Mean variations</em> (<code><a href="#topic+mean_var">mean_var</a></code>).
</p>
</li>
<li> <p><em>Standard covariance variations</em> (<code><a href="#topic+covariance_var">covariance_var</a></code>).
</p>
</li>
<li> <p><em>Model-preserving covariance variations</em> (<code><a href="#topic+model_pres_cov">model_pres_cov</a></code>).
</p>
</li></ul>



<h3>GBNs - Dissimilarity measures</h3>

<p>The available dissimilarity measures are:
</p>

<ul>
<li><p> Frobenius norm (<code><a href="#topic+Fro">Fro</a></code>).
</p>
</li>
<li><p> Jeffrey's distance (<code><a href="#topic+Jeffreys">Jeffreys</a></code>).
</p>
</li>
<li><p> Kullback-Leibler divergence (<code><a href="#topic+KL">KL</a></code>).
</p>
</li>
<li><p> Upper bound to the KL divergence (<code><a href="#topic+KL_bounds">KL_bounds</a></code>).
</p>
</li></ul>


<hr>
<h2 id='cachexia'>Bayesian networks for a cachexia study</h2><span id='topic+cachexia'></span><span id='topic+cachexia_gbn'></span><span id='topic+cachexia_ci'></span><span id='topic+control_gbn'></span><span id='topic+control_ci'></span><span id='topic+cachexia_data'></span>

<h3>Description</h3>

<p>Continuous Bayesian networks comparing the dependence of metabolomics for people who suffer and do not suffer of Cachexia
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cachexia_gbn

cachexia_ci

control_gbn

control_ci

cachexia_data
</code></pre>


<h3>Format</h3>

<p>Continuous Bayesian networks over six metabolomics: Adipate (A), Betaine (B), Fumarate (F), Glucose (GC), Glutamine (GM) and Valine (V).
The networks <code>cachexia_gbn</code> and <code>cachexia_ci</code> are for people suffering of cachexia and of class <code>GBN</code> and <code>CI</code> respectively.
The networks <code>control_gbn</code> and <code>control_ci</code> are for people not suffering of cachexia and of class <code>GBN</code> and <code>CI</code> respectively.
The original dataset is stored in <code>cachexia_data</code>.
</p>
<p>An object of class <code>GBN</code> of length 3.
</p>
<p>An object of class <code>CI</code> of length 4.
</p>
<p>An object of class <code>GBN</code> of length 3.
</p>
<p>An object of class <code>CI</code> of length 4.
</p>
<p>An object of class <code>data.table</code> (inherits from <code>data.frame</code>) with 77 rows and 7 columns.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>

<hr>
<h2 id='CD'>CD-distance</h2><span id='topic+CD'></span>

<h3>Description</h3>

<p>Chan-Darwiche (CD) distance between a Bayesian network and its update after parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CD(
  bnfit,
  node,
  value_node,
  value_parents,
  new_value,
  covariation = "proportional"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CD_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="CD_+3A_node">node</code></td>
<td>
<p>character string. Node of which the conditional probability distribution is being changed.</p>
</td></tr>
<tr><td><code id="CD_+3A_value_node">value_node</code></td>
<td>
<p>character string. Level of <code>node</code>.</p>
</td></tr>
<tr><td><code id="CD_+3A_value_parents">value_parents</code></td>
<td>
<p>character string. Levels of <code>node</code>'s parents. The levels should be defined according to the order of the parents in <code>bnfit[[node]][["parents"]]</code>. If <code>node</code> has no parents, then it should be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="CD_+3A_new_value">new_value</code></td>
<td>
<p>numeric vector with elements between 0 and 1. Values to which the parameter should be updated. It can take a specific value or more than one. In the case of more than one value, these should be defined through a vector with an increasing order of the elements. <code>new_value</code> can also be set to the character string <code>all</code>: in this case a sequence of possible parameter changes ranging from 0.05 to 0.95 is considered.</p>
</td></tr>
<tr><td><code id="CD_+3A_covariation">covariation</code></td>
<td>
<p>character string. Co-variation scheme to be used for the updated Bayesian network. Can take values <code>uniform</code>, <code>proportional</code>, <code>orderp</code>, <code>all</code>. If equal to <code>all</code>, uniform, proportional and order-preserving co-variation schemes are used. Set by default to <code>proportional</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian network on which parameter variation is being conducted should be expressed as a <code>bn.fit</code> object.
The name of the node to be varied, its level and its parent's levels should be specified.
The parameter variation specified by the function is:
</p>
<p>P ( <code>node</code> = <code>value_node</code> | parents = <code>value_parents</code> ) = <code>new_value</code>
</p>
<p>The CD distance between two probability distributions <code class="reqn">P</code> and <code class="reqn">P'</code> defined over the same sample space <code class="reqn">\mathcal{Y}</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">CD(P,P')= \log\max_{y\in\mathcal{Y}}\left(\frac{P(y)}{P'(y)}\right) - \log\min_{y\in\mathcal{Y}}\left(\frac{P(y)}{P'(y)}\right)</code>
</p>



<h3>Value</h3>

<p>The function <code>CD</code> returns a dataframe including in the first column the variations performed, and in the following columns the corresponding CD distances for the chosen co-variation schemes.
</p>


<h3>References</h3>

<p>Chan, H., &amp; Darwiche, A. (2005). A distance measure for bounding probabilistic belief change. International Journal of Approximate Reasoning, 38(2), 149-174.
</p>
<p>Renooij, S. (2014). Co-variation for sensitivity analysis in Bayesian networks: Properties, consequences and alternatives. International Journal of Approximate Reasoning, 55(4), 1022-1042.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.bn.fit">KL.bn.fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CD(synthetic_bn, "y2", "1", "2", "all", "all")
CD(synthetic_bn, "y1", "2", NULL, 0.3, "all")

</code></pre>

<hr>
<h2 id='chds'>Christchurch Health and Development Study</h2><span id='topic+chds'></span><span id='topic+chds_bn'></span><span id='topic+chds_bn.fit'></span>

<h3>Description</h3>

<p>Simulated data and Bayesian networks from the Christchurch Health and Development Study
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chds

chds_bn

chds_bn.fit
</code></pre>


<h3>Format</h3>

<p>The dataframe <code>chds</code> includes 500 observations randomly simulated from the <code>bn.fit</code> object <code>chds_bn.fit</code>. It has four variables:
</p>

<ul>
<li> <p><b>Social</b>: family's social background with levels <code>"High"</code> and <code>"Low"</code>
</p>
</li>
<li> <p><b>Economic</b>: family's economic status with levels <code>"High"</code> and <code>"Low"</code>
</p>
</li>
<li> <p><b>Events</b>: number of family life events with levels <code>"High"</code>, <code>"Average"</code> and <code>"Low"</code>
</p>
</li>
<li> <p><b>Admission</b>: hospital admission of the child with levels <code>"yes"</code> and <code>"no"</code>
</p>
</li>
<li> <p><b>statistics</b>: mark out of 100 for statistics
</p>
</li></ul>

<p><code>chds_bn</code> is an object of class <code>bn</code> including the MAP Bayesian network from Barclay et al. (2013) and <code>chds_bn.fit</code> is an object of class <code>bn.fit</code> including the probabilities from the same article.
</p>
<p>An object of class <code>data.frame</code> with 500 rows and 4 columns.
</p>
<p>An object of class <code>bn</code> of length 3.
</p>
<p>An object of class <code>bn.fit</code> (inherits from <code>bn.fit.dnet</code>) of length 4.
</p>


<h3>References</h3>

<p>Fergusson, D. M., Horwood, L. J., &amp; Shannon, F. T. (1986). Social and family factors in childhood hospital admission. Journal of Epidemiology &amp; Community Health, 40(1), 50-58.
</p>
<p>Barclay, L. M., Hutton, J. L., &amp; Smith, J. Q. (2013). Refining a Bayesian network using a chain event graph. International Journal of Approximate Reasoning, 54(9), 1300-1309.
</p>

<hr>
<h2 id='covariance_var'>Standard variation of the covariance matrix</h2><span id='topic+covariance_var'></span>

<h3>Description</h3>

<p>Computation of an updated <code>GBN</code> object after a variation of the covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covariance_var(gbn, entry, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covariance_var_+3A_gbn">gbn</code></td>
<td>
<p>object of class <code>GBN</code>.</p>
</td></tr>
<tr><td><code id="covariance_var_+3A_entry">entry</code></td>
<td>
<p>a vector of length 2 specifying the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="covariance_var_+3A_delta">delta</code></td>
<td>
<p>additive variation coefficient for the entry of the co-variation matrix given in <code>entry</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the original Bayesian network have a Normal distribution <code class="reqn">\mathcal{N}(\mu,\Sigma)</code> and let <code>entry</code> be equal to <code class="reqn">(i,j)</code>. For a variation of the covariance matrix by an amount <code class="reqn">\delta</code>, a variation matrix <code class="reqn">D</code> is constructed as
</p>
<p style="text-align: center;"><code class="reqn">D_{k,l}=\left\{
\begin{array}{ll}
\delta &amp; \mbox{if } k=i, l=j\\
\delta &amp; \mbox{if } l=i, k=j \\
0 &amp; \mbox{otherwise}
\end{array}
\right.</code>
</p>

<p>Then the resulting distribution after the variation is <code class="reqn">\mathcal{N}(\mu,\Sigma +D)</code>, assuming <code class="reqn">\Sigma+ D</code> is positive semi-definite.
</p>


<h3>Value</h3>

<p>If the resulting covariance is positive semi-definite, <code>covariance_var</code> returns an object of class <code>GBN</code> with an updated covariance matrix. Otherwise it returns an object of class <code>npsd.gbn</code>, which has the same components of <code>GBN</code> but also has a warning entry specifying that the covariance matrix is not positive semi-definite.
</p>


<h3>References</h3>

<p>Gómez-Villegas, M. A., Maín, P., &amp; Susi, R. (2007). Sensitivity analysis in Gaussian Bayesian networks using a divergence measure. Communications in Statistics—Theory and Methods, 36(3), 523-539.
</p>
<p>Gómez-Villegas, M. A., Main, P., &amp; Susi, R. (2013). The effect of block parameter perturbations in Gaussian Bayesian networks: Sensitivity and robustness. Information Sciences, 222, 439-458.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mean_var">mean_var</a></code>, <code><a href="#topic+model_pres_cov">model_pres_cov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>covariance_var(synthetic_gbn,c(1,1),3)
covariance_var(synthetic_gbn,c(1,2),-0.4)

</code></pre>

<hr>
<h2 id='covariation'>Co-variation schemes</h2><span id='topic+covariation'></span><span id='topic+proportional_covar'></span><span id='topic+orderp_covar'></span><span id='topic+uniform_covar'></span>

<h3>Description</h3>

<p>Functions that return an updated Bayesian network using the proportional, uniform and order-preserving co-variation schemes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportional_covar(bnfit, node, value_node, value_parents, new_value)

orderp_covar(bnfit, node, value_node, value_parents, new_value)

uniform_covar(bnfit, node, value_node, value_parents, new_value)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covariation_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="covariation_+3A_node">node</code></td>
<td>
<p>character string. Node of which the conditional probability distribution is being changed.</p>
</td></tr>
<tr><td><code id="covariation_+3A_value_node">value_node</code></td>
<td>
<p>character string. Level of <code>node</code>.</p>
</td></tr>
<tr><td><code id="covariation_+3A_value_parents">value_parents</code></td>
<td>
<p>character string. Levels of <code>node</code>'s parents. The levels should be defined according to the order of the parents in <code>bnfit[[node]][["parents"]]</code>. If <code>node</code> has no parents, then it should be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="covariation_+3A_new_value">new_value</code></td>
<td>
<p>numeric value between 0 and 1. Value to which the parameter should be updated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian network on which parameter variation is being conducted should be expressed as a <code>bn.fit</code> object.
The name of the node to be varied, its level and its parent's levels should be specified.
The parameter variation specified by the function is:
</p>
<p>P ( <code>node</code> = <code>value_node</code> | parents = <code>value_parents</code> ) = <code>new_value</code>
</p>
<p>For <code>orderp_covar</code>, if two or more parameters in a distribution have the same value, the order is given by the one in the respective conditional probability table. Furthermore, the parameter associated to the largest probability of the conditional probability law cannot be varied.
</p>


<h3>Value</h3>

<p>An object of class <code>bn.fit</code> with updated probabilities.
</p>


<h3>References</h3>

<p>Laskey, K. B. (1995). Sensitivity analysis for probability assessments in Bayesian networks. IEEE Transactions on Systems, Man, and Cybernetics, 25(6), 901-909.
</p>
<p>Renooij, S. (2014). Co-variation for sensitivity analysis in Bayesian networks: Properties, consequences and alternatives. International Journal of Approximate Reasoning, 55(4), 1022-1042.
</p>
<p>Leonelli, M., &amp; Riccomagno, E. (2022). A geometric characterization of sensitivity analysis in monomial models. International Journal of Approximate Reasoning, 151, 64-84.
#'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>proportional_covar(synthetic_bn, "y3", "2", c("2","1"), 0.3)
uniform_covar(synthetic_bn, "y2", "1", "2", 0.3)
orderp_covar(synthetic_bn, "y1", "1", NULL, 0.3)

</code></pre>

<hr>
<h2 id='covariation_matrix'>Co-variation matrices</h2><span id='topic+covariation_matrix'></span><span id='topic+total_covar_matrix'></span><span id='topic+col_covar_matrix'></span><span id='topic+partial_covar_matrix'></span><span id='topic+row_covar_matrix'></span>

<h3>Description</h3>

<p>Construction of model-preserving co-variation matrices for objects of class <code>CI</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>total_covar_matrix(ci, entry, delta)

col_covar_matrix(ci, entry, delta)

partial_covar_matrix(ci, entry, delta)

row_covar_matrix(ci, entry, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covariation_matrix_+3A_ci">ci</code></td>
<td>
<p>object of class <code>CI</code>.</p>
</td></tr>
<tr><td><code id="covariation_matrix_+3A_entry">entry</code></td>
<td>
<p>a vector of length two specifying the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="covariation_matrix_+3A_delta">delta</code></td>
<td>
<p>multiplicative variation coefficient for the entry of the covariance matrix given in <code>entry</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions to compute total, partial, row-based and column-based co-variation matrices to ensure the conditional independences of the original Bayesian network hold after a variation. If no co-variation is required for model-preservation the functions return a matrix filled with ones (no co-variation).
</p>


<h3>Value</h3>

<p>A co-variation matrix of the same size of the covariance matrix of <code>CI</code>.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+model_pres_cov">model_pres_cov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>total_covar_matrix(synthetic_ci,c(1,1),0.3)
total_covar_matrix(synthetic_ci,c(1,2),0.3)
partial_covar_matrix(synthetic_ci,c(1,2),0.3)
row_covar_matrix(synthetic_ci,c(1,2),0.3)
col_covar_matrix(synthetic_ci,c(1,2),0.3)

</code></pre>

<hr>
<h2 id='diabetes'>Pima Indian Diabetes Data</h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>Discretized version of the widely-used Pima Indians Diabetes Database
</p>


<h3>Format</h3>

<p>A dataframe with 392 observations on the following 9 binary variables:
</p>

<ul>
<li> <p><b>PREG</b>: number of times pregnant (low/high)
</p>
</li>
<li> <p><b>GLUC</b>: plasma glucose concentration (low/high)
</p>
</li>
<li> <p><b>PRES</b>: diastolic blood pressure (low/high)
</p>
</li>
<li> <p><b>TRIC</b>: triceps skin fold thickness (low/high)
</p>
</li>
<li> <p><b>INS</b>: 2-hour serum insulin (low/high)
</p>
</li>
<li> <p><b>MASS</b>: body mass index (low/high)
</p>
</li>
<li> <p><b>PED</b>: diabetes pedigree function (low/high)
</p>
</li>
<li> <p><b>AGE</b>: age (low/high)
</p>
</li>
<li> <p><b>DIAB</b>: test for diabetes (neg/pos)
</p>
</li></ul>



<h3>Source</h3>

<p>These data have been taken from the UCI Repository Of Machine Learning Databases. We chose this dataset because it best showcases the function of our monitors. However, we acknowledge that this data is used here without the consent of or compensation for the original Akimel O'odham participants.
</p>

<hr>
<h2 id='diameter'>Diameters in a Bayesian network</h2><span id='topic+diameter'></span>

<h3>Description</h3>

<p>Computation of the diameters of all conditional probability tables in a Bayesian network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diameter(bnfit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="diameter_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The diameter of a conditional probability table <code class="reqn">P</code> with <code class="reqn">n</code> rows <code class="reqn">p_1,\dots,p_n</code> is </p>
<p style="text-align: center;"><code class="reqn">d^+(P)=\max_{i,j\leq n} d_V(p_i,p_j),</code>
</p>
<p> where <code class="reqn">d_V</code> is the total variation distance between two probability mass functions over a sample space <code class="reqn">\mathcal{X}</code>, i.e. </p>
<p style="text-align: center;"><code class="reqn">d_V(p_i,p_j)=\frac{1}{2}\sum_{x\in\mathcal{X}}|p_i(x)-p_j(x)|.</code>
</p>



<h3>Value</h3>

<p>A dataframe with the following columns: <code>Nodes</code> - the vertices of the BN; <code>Diameter</code> - the diameters of the associated conditional probability tables.
</p>


<h3>References</h3>

<p>Leonelli, M., Smith, J. Q., &amp; Wright, S. K. (2024). The diameter of a stochastic matrix: A new measure for sensitivity analysis in Bayesian networks. arXiv preprint arXiv:2407.04667.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>diameter(travel)

</code></pre>

<hr>
<h2 id='dwi'>Distance-weigthed influence</h2><span id='topic+dwi'></span>

<h3>Description</h3>

<p>Computation of the distance-weigthed influence in a Bayesian network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dwi(bn, node, w)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dwi_+3A_bn">bn</code></td>
<td>
<p>object of class <code>bn.fit</code> or <code>bn</code>.</p>
</td></tr>
<tr><td><code id="dwi_+3A_node">node</code></td>
<td>
<p>a node of <code>bnfit</code>.</p>
</td></tr>
<tr><td><code id="dwi_+3A_w">w</code></td>
<td>
<p>a number in <code class="reqn">(0,1]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance-weigthed influence of a node <code class="reqn">X_j</code> on an output node <code class="reqn">X_i</code> in a Bayesian network is </p>
<p style="text-align: center;"><code class="reqn">DWI(X_j,X_i,w)= \sum_{s\in S_{ji}}w^{|s|},</code>
</p>
<p> where <code class="reqn">S_{ji}</code> is the set of active trails between <code class="reqn">X_j</code> and <code class="reqn">X_i</code>, <code class="reqn">w\in(0,1]</code> is an input parameter, and <code class="reqn">|s|</code> is the length of the trail <code class="reqn">s</code>.
</p>


<h3>Value</h3>

<p>A dataframe with the following columns: <code>Nodes</code> - the vertices of the BN; <code>Influence</code> - the distance-weigthed influence of the corresponding node.
</p>


<h3>References</h3>

<p>Albrecht, D., Nicholson, A. E., &amp; Whittle, C. (2014). Structural sensitivity for the knowledge engineering of Bayesian networks. In Probabilistic Graphical Models (pp. 1-16). Springer International Publishing.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ewi">ewi</a></code>, <code><a href="#topic+mutual_info">mutual_info</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dwi(travel, "T", 0.5)

</code></pre>

<hr>
<h2 id='edge_strength'>Strength of edges in a Bayesian network</h2><span id='topic+edge_strength'></span>

<h3>Description</h3>

<p>Computation of the measure of edge strength for all edges in a Bayesian networks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edge_strength(bnfit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="edge_strength_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The measure of edge strength is defined as the largest diameter out of all conditional probability tables where all other parents but the considered one are fixed to a specific combination.
</p>


<h3>Value</h3>

<p>A dataframe with first two columns the edge list of the <code>bn.fit</code> input object. The third column <code>Edge.Strength</code> reports the measure of edge strength.
</p>


<h3>References</h3>

<p>Leonelli, M., Smith, J. Q., &amp; Wright, S. K. (2024). The diameter of a stochastic matrix: A new measure for sensitivity analysis in Bayesian networks. arXiv preprint arXiv:2407.04667.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diameter">diameter</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>edge_strength(travel)

</code></pre>

<hr>
<h2 id='ewi'>Edge-weigthed influence</h2><span id='topic+ewi'></span>

<h3>Description</h3>

<p>Computation of the edge-weigthed influence in a Bayesian network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ewi(bnfit, node)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ewi_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="ewi_+3A_node">node</code></td>
<td>
<p>a node of <code>bnfit</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The edge-weigthed influence of a node <code class="reqn">X_j</code> on an output node <code class="reqn">X_i</code> in a Bayesian network is </p>
<p style="text-align: center;"><code class="reqn">EWI(X_j,X_i)= \sum_{s\in S_{ji}}\left(\prod_{(k,l)\in s}\delta_{kl}\right)^{|s|},</code>
</p>
<p> where <code class="reqn">S_{ji}</code> is the set of active trails between <code class="reqn">X_j</code> and <code class="reqn">X_i</code>, <code class="reqn">\delta_{kl}</code> is the strength of an edge between <code class="reqn">X_k</code> and <code class="reqn">X_l</code>, and <code class="reqn">|s|</code> is the length of the trail <code class="reqn">s</code>.
</p>


<h3>Value</h3>

<p>A dataframe with the following columns: <code>Nodes</code> - the vertices of the BN; <code>Influence</code> - the edge-weigthed influence of the corresponding node.
</p>


<h3>References</h3>

<p>Leonelli, M., Smith, J. Q., &amp; Wright, S. K. (2024). The diameter of a stochastic matrix: A new measure for sensitivity analysis in Bayesian networks. arXiv preprint arXiv:2407.04667.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mutual_info">mutual_info</a></code>, <code><a href="#topic+dwi">dwi</a></code>, <code><a href="#topic+edge_strength">edge_strength</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ewi(travel, "T")

</code></pre>

<hr>
<h2 id='final_node_monitor'>Final node monitors</h2><span id='topic+final_node_monitor'></span>

<h3>Description</h3>

<p>Marginal and conditional node monitors over the last observation of the data for all vertices of a Bayesian network using the full dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>final_node_monitor(dag, df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="final_node_monitor_+3A_dag">dag</code></td>
<td>
<p>an object of class <code>bn</code> from the <code>bnlearn</code> package</p>
</td></tr>
<tr><td><code id="final_node_monitor_+3A_df">df</code></td>
<td>
<p>a base R style dataframe</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider a Bayesian network over variables <code class="reqn">Y_1,\dots,Y_m</code> and suppose a dataset <code class="reqn">(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)</code> has been observed, where <code class="reqn">\boldsymbol{y}_i=(y_{i1},\dots,y_{im})</code> and <code class="reqn">y_{ij}</code> is the i-th observation of the j-th variable.
Let <code class="reqn">p_n</code> denote the marginal density of <code class="reqn">Y_j</code> after the first <code class="reqn">n-1</code> observations have been processed. Define
</p>
<p style="text-align: center;"><code class="reqn">E_n = \sum_{k=1}^Kp_n(d_k)\log(p_n(d_k)),</code>
</p>

<p style="text-align: center;"><code class="reqn">V_n = \sum_{k=1}^K p_n(d_k)\log^2(p_n(d_k))-E_n^2,</code>
</p>

<p>where <code class="reqn">(d_1,\dots,d_K)</code> are the possible values of <code class="reqn">Y_j</code>. The marginal node monitor for the vertex <code class="reqn">Y_j</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">Z_j=\frac{-\log(p_n(y_{ij}))- E_n}{\sqrt{V_n}}.</code>
</p>

<p>Higher values of <code class="reqn">Z_j</code> can give an indication of a poor model fit for the vertex <code class="reqn">Y_j</code>.
</p>
<p>The conditional node monitor for the vertex <code class="reqn">Y_j</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">Z_j=\frac{-\log(p_n(y_{nj}|y_{n1},\dots,y_{n(j-1)},y_{n(j+1)},\dots,y_{nm}))- E_n}{\sqrt{V_n}},</code>
</p>

<p>where <code class="reqn">E_n</code> and <code class="reqn">V_n</code> are computed with respect to <code class="reqn">p_n(y_{nj}|y_{n1},\dots,y_{n(j-1)},y_{n(j+1)},\dots,y_{nm})</code>. Again, higher values of <code class="reqn">Z_j</code> can give an indication of a poor model fit for the vertex <code class="reqn">Y_j</code>.
</p>


<h3>Value</h3>

<p>A dataframe including the names of the vertices, the marginal node monitors and the conditional node monitors. It also return two plots where vertices with a darker color have a higher marginal z-score or conditional z-score, respectively, in absolute value.
</p>


<h3>References</h3>

<p>Cowell, R. G., Dawid, P., Lauritzen, S. L., &amp; Spiegelhalter, D. J. (2006). Probabilistic networks and expert systems: Exact computational methods for Bayesian networks. Springer Science &amp; Business Media.
</p>
<p>Cowell, R. G., Verrall, R. J., &amp; Yoon, Y. K. (2007). Modeling operational risk with Bayesian networks. Journal of Risk and Insurance, 74(4), 795-827.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+influential_obs">influential_obs</a></code>, <code><a href="#topic+node_monitor">node_monitor</a></code>, <code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>, <code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>final_node_monitor(chds_bn, chds[1:100,])
</code></pre>

<hr>
<h2 id='fire_alarm'>Bayesian network on fire alarm system</h2><span id='topic+fire_alarm'></span>

<h3>Description</h3>

<p><code>fire_alarm</code> is a <code>bn.fit</code> object including a Bayesian network for a fire alarm system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fire_alarm
</code></pre>


<h3>Format</h3>

<p>The Bayesian network <code>fire_alarm</code> includes the following nodes:
</p>

<ul>
<li> <p><b>Fire</b>: two-level factor with levels <code>TRUE</code> and <code>FALSE</code>. It indicates presence or absence of a fire.
</p>
</li>
<li> <p><b>Smoke</b>: two level-factor with levels <code>TRUE</code> and <code>FALSE</code>. It indicates presence or absence of smoke.
</p>
</li>
<li> <p><b>Alarm</b>: three level-factor with levels <code>TRUE</code>, <code>MALFUNCTION</code> and <code>FALSE</code>. It indicates if the alarm is ringing, malfunctioning or not ringing.
</p>
</li>
<li> <p><b>Tampering</b>: two level-factor with levels <code>TRUE</code> and <code>FALSE</code>. It indicates if the alarm system has been tampered or not.
</p>
</li>
<li> <p><b>Leaving</b>: two level-factor with levels <code>TRUE</code> and <code>FALSE</code>. It indicates if the building is being evacuated or not.
</p>
</li>
<li> <p><b>Report</b>: two level-factor with levels <code>TRUE</code> and <code>FALSE</code>. It indicates if the incident has been reported or not.
</p>
</li></ul>



<h3>Source</h3>

<p>Hei Chan, Adnan Darwiche (2002). &quot;When do numbers really matter?&quot;. Journal of Artificial Intelligence Research 17 (265-287).
</p>

<hr>
<h2 id='Fro'>Frobenius norm</h2><span id='topic+Fro'></span>

<h3>Description</h3>

<p><code>Fro</code> returns the Frobenius norm between a Bayesian network and its update after parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Fro(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Fro_+3A_x">x</code></td>
<td>
<p>object of class <code>GBN</code> or <code>CI</code>.</p>
</td></tr>
<tr><td><code id="Fro_+3A_...">...</code></td>
<td>
<p>parameters specific to the class used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details depend on the class the method <code>Fro</code> is applied to.
</p>


<h3>Value</h3>

<p>A dataframe whose columns depend of the class of the object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>

<hr>
<h2 id='Fro.CI'>Frobenius norm for <code>CI</code></h2><span id='topic+Fro.CI'></span>

<h3>Description</h3>

<p><code>Fro.CI</code> returns the Frobenius norm between an object of class <code>CI</code>  and its update after a model-preserving parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CI'
Fro(x, type, entry, delta, log = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Fro.CI_+3A_x">x</code></td>
<td>
<p>object of class <code>CI</code>.</p>
</td></tr>
<tr><td><code id="Fro.CI_+3A_type">type</code></td>
<td>
<p>character string. Type of model-preserving co-variation: either <code>"total"</code>, <code>"partial"</code>, <code>row</code>, <code>column</code> or <code>all</code>. If <code>all</code> the Frobenius norm is computed for every type of co-variation matrix.</p>
</td></tr>
<tr><td><code id="Fro.CI_+3A_entry">entry</code></td>
<td>
<p>a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="Fro.CI_+3A_delta">delta</code></td>
<td>
<p>numeric vector with positive elements, including the variation parameters that act multiplicatively.</p>
</td></tr>
<tr><td><code id="Fro.CI_+3A_log">log</code></td>
<td>
<p>boolean value. If <code>TRUE</code>, the logarithm of the Frobenius norm is returned. Set by default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Fro.CI_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation of the Frobenius norm between a Bayesian network and its updated version after a model-preserving variation.
</p>


<h3>Value</h3>

<p>A dataframe including in the first column the variations performed, and in the following columns the corresponding Frobenius norms for the chosen model-preserving co-variations.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Fro(synthetic_ci,"total",c(1,1),seq(0.9,1.1,0.01))
Fro(synthetic_ci,"partial",c(1,4),seq(0.9,1.1,0.01))
Fro(synthetic_ci,"column",c(1,2),seq(0.9,1.1,0.01))
Fro(synthetic_ci,"row",c(3,2),seq(0.9,1.1,0.01))

</code></pre>

<hr>
<h2 id='Fro.GBN'>Frobenius norm for <code>GBN</code></h2><span id='topic+Fro.GBN'></span>

<h3>Description</h3>

<p><code>Fro.GBN</code> returns the Frobenius norm between between an object of class <code>GBN</code>  and its update after a standard parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GBN'
Fro(x, entry, delta, log = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Fro.GBN_+3A_x">x</code></td>
<td>
<p>object of class <code>GBN</code>.</p>
</td></tr>
<tr><td><code id="Fro.GBN_+3A_entry">entry</code></td>
<td>
<p>a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="Fro.GBN_+3A_delta">delta</code></td>
<td>
<p>numeric vector, including the variation parameters that act additively.</p>
</td></tr>
<tr><td><code id="Fro.GBN_+3A_log">log</code></td>
<td>
<p>boolean value. If <code>TRUE</code>, the logarithm of the Frobenius norm is returned. Set by default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Fro.GBN_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation of the Frobenius norm between a Bayesian network and the additively perturbed Bayesian network, where the perturbation is either to the mean vector or to the covariance matrix. The Frobenius norm is not computed for perturbations of the mean since it is always equal to zero.
</p>


<h3>Value</h3>

<p>A dataframe including in the first column the variations performed and in the second column the corresponding Frobenius norm.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Fro(synthetic_gbn,c(3,3),seq(-1,1,0.1))

</code></pre>

<hr>
<h2 id='global_monitor'>Global monitor</h2><span id='topic+global_monitor'></span>

<h3>Description</h3>

<p>Negative marginal log-likelihood of the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>global_monitor(dag, df, alpha = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="global_monitor_+3A_dag">dag</code></td>
<td>
<p>an object of class <code>bn</code> from the <code>bnlearn</code> package</p>
</td></tr>
<tr><td><code id="global_monitor_+3A_df">df</code></td>
<td>
<p>a base R style dataframe</p>
</td></tr>
<tr><td><code id="global_monitor_+3A_alpha">alpha</code></td>
<td>
<p>single integer. By default, number of max levels in <code>df</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numerical value
</p>


<h3>References</h3>

<p>Cowell, R. G., Dawid, P., Lauritzen, S. L., &amp; Spiegelhalter, D. J. (2006). Probabilistic networks and expert systems: Exact computational methods for Bayesian networks. Springer Science &amp; Business Media.
</p>
<p>Cowell, R. G., Verrall, R. J., &amp; Yoon, Y. K. (2007). Modeling operational risk with Bayesian networks. Journal of Risk and Insurance, 74(4), 795-827.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+node_monitor">node_monitor</a></code>, <code><a href="#topic+influential_obs">influential_obs</a></code>, <code><a href="#topic+final_node_monitor">final_node_monitor</a></code>, <code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>, <code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>global_monitor(chds_bn, chds, 3)

</code></pre>

<hr>
<h2 id='influential_obs'>Influential observations</h2><span id='topic+influential_obs'></span>

<h3>Description</h3>

<p>Influence of a single observation to the global monitor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>influential_obs(dag, data, alpha = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="influential_obs_+3A_dag">dag</code></td>
<td>
<p>an object of class <code>bn</code> from the <code>bnlearn</code> package</p>
</td></tr>
<tr><td><code id="influential_obs_+3A_data">data</code></td>
<td>
<p>a base R style dataframe</p>
</td></tr>
<tr><td><code id="influential_obs_+3A_alpha">alpha</code></td>
<td>
<p>single integer. By default, the number of max levels in <code>data</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider a Bayesian network over variables <code class="reqn">Y_1,\dots,Y_m</code> and suppose a dataset <code class="reqn">(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)</code> has been observed, where <code class="reqn">\boldsymbol{y}_i=(y_{i1},\dots,y_{im})</code> and <code class="reqn">y_{ij}</code> is the i-th observation of the j-th variable. Define <code class="reqn">\boldsymbol{y}_{-i}=(\boldsymbol{y}_1,\dots,\boldsymbol{y}_{i-1},\boldsymbol{y}_{i+1},\dots,\boldsymbol{y}_n)</code>.
The influence of an observation to the global monitor is defined as
</p>
<p style="text-align: center;"><code class="reqn">|\log(p(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)) - \log(p(\boldsymbol{y}_{-i}))|.</code>
</p>

<p>High values of this index denote observations that highly contribute to the likelihood of the model.
</p>


<h3>Value</h3>

<p>A vector including the influence of each observation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+influential_obs">influential_obs</a></code>, <code><a href="#topic+node_monitor">node_monitor</a></code>, <code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>, <code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>influential_obs(chds_bn, chds[1:100,], 3)

</code></pre>

<hr>
<h2 id='Jeffreys'>Jeffreys Divergence</h2><span id='topic+Jeffreys'></span>

<h3>Description</h3>

<p><code>Jeffreys</code> returns the Jeffreys divergence between a continuous Bayesian network and its update after parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Jeffreys(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Jeffreys_+3A_x">x</code></td>
<td>
<p>object of class <code>bn.fit</code>, <code>GBN</code> or <code>CI</code>.</p>
</td></tr>
<tr><td><code id="Jeffreys_+3A_...">...</code></td>
<td>
<p>parameters specific to the class used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details depend on the class the method <code>Jefrreys</code> is applied to.
</p>


<h3>Value</h3>

<p>A dataframe whose columns depend of the class of the object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>

<hr>
<h2 id='Jeffreys.CI'>Jeffreys Divergence for <code>CI</code></h2><span id='topic+Jeffreys.CI'></span>

<h3>Description</h3>

<p><code>Jeffreys.CI</code> returns the Jeffreys divergence between an object of class <code>CI</code>  and its update after a model-preserving parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CI'
Jeffreys(x, type, entry, delta, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Jeffreys.CI_+3A_x">x</code></td>
<td>
<p>object of class <code>CI</code>.</p>
</td></tr>
<tr><td><code id="Jeffreys.CI_+3A_type">type</code></td>
<td>
<p>character string. Type of model-preserving co-variation: either <code>"total"</code>, <code>"partial"</code>, <code>row</code>,<code>column</code> or <code>all</code>. If <code>all</code> the Jeffreys divergence is computed for every type of co-variation matrix.</p>
</td></tr>
<tr><td><code id="Jeffreys.CI_+3A_entry">entry</code></td>
<td>
<p>a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="Jeffreys.CI_+3A_delta">delta</code></td>
<td>
<p>numeric vector with positive elements, including the variation parameters that act multiplicatively.</p>
</td></tr>
<tr><td><code id="Jeffreys.CI_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation of the Jeffreys divergence between a Bayesian network and its updated version after a model-preserving variation.
</p>


<h3>Value</h3>

<p>A dataframe including in the first column the variations performed, and in the following columns the corresponding Jeffreys divergences for the chosen model-preserving co-variations.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Jeffreys(synthetic_ci,"total",c(1,1),seq(0.9,1.1,0.01))
Jeffreys(synthetic_ci,"partial",c(1,4),seq(0.9,1.1,0.01))
Jeffreys(synthetic_ci,"column",c(1,2),seq(0.9,1.1,0.01))
Jeffreys(synthetic_ci,"row",c(3,2),seq(0.9,1.1,0.01))
Jeffreys(synthetic_ci,"all",c(3,2),seq(0.9,1.1,0.01))

</code></pre>

<hr>
<h2 id='Jeffreys.GBN'>Jeffreys Divergence for <code>GBN</code></h2><span id='topic+Jeffreys.GBN'></span>

<h3>Description</h3>

<p><code>Jeffreys.GBN</code> returns the Jeffreys divergence between an object of class <code>GBN</code>  and its update after a standard parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GBN'
Jeffreys(x, where, entry, delta, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Jeffreys.GBN_+3A_x">x</code></td>
<td>
<p>object of class <code>GBN</code>.</p>
</td></tr>
<tr><td><code id="Jeffreys.GBN_+3A_where">where</code></td>
<td>
<p>character string: either <code>mean</code> or <code>covariance</code> for variations of the mean vector and covariance matrix respectively.</p>
</td></tr>
<tr><td><code id="Jeffreys.GBN_+3A_entry">entry</code></td>
<td>
<p>if <code>where == "mean"</code>, <code>entry</code> is the index of the entry of the mean vector to vary. If <code>where == "covariance"</code>, entry is a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="Jeffreys.GBN_+3A_delta">delta</code></td>
<td>
<p>numeric vector, including the variation parameters that act additively.</p>
</td></tr>
<tr><td><code id="Jeffreys.GBN_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation of the Jeffreys divergence between a Bayesian network and the additively perturbed Bayesian network, where the perturbation is either to the mean vector or to the covariance matrix.
</p>


<h3>Value</h3>

<p>A dataframe including in the first column the variations performed and in the second column the corresponding Jeffreys divergences.
</p>


<h3>References</h3>

<p>Goergen, C., &amp; Leonelli, M. (2018). Model-preserving sensitivity analysis for families of Gaussian distributions. arXiv preprint arXiv:1809.10794.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code><code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Jeffreys(synthetic_gbn,"mean",2,seq(-1,1,0.1))
Jeffreys(synthetic_gbn,"covariance",c(3,3),seq(-1,1,0.1))

</code></pre>

<hr>
<h2 id='KL'>KL Divergence</h2><span id='topic+KL'></span>

<h3>Description</h3>

<p><code>KL</code> returns the Kullback-Leibler (KL) divergence between a Bayesian network and its update after parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KL(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KL_+3A_x">x</code></td>
<td>
<p>object of class <code>bn.fit</code>, <code>GBN</code> or <code>CI</code>.</p>
</td></tr>
<tr><td><code id="KL_+3A_...">...</code></td>
<td>
<p>parameters specific to the class used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details depend on the class the method <code>KL</code> is applied to.
</p>


<h3>Value</h3>

<p>A dataframe whose columns depend of the class of the object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>

<hr>
<h2 id='KL_bounds'>Bounds for the KL-divergence</h2><span id='topic+KL_bounds'></span>

<h3>Description</h3>

<p>Computation of the bounds of the KL-divergence for variations of each parameter of a <code>CI</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KL_bounds(ci, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KL_bounds_+3A_ci">ci</code></td>
<td>
<p>object of class <code>CI</code>.</p>
</td></tr>
<tr><td><code id="KL_bounds_+3A_delta">delta</code></td>
<td>
<p>multiplicative variation coefficient for the entry of the covariance matrix given in <code>entry</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\Sigma</code> be the covariance matrix of a Gaussian Bayesian network with <code class="reqn">n</code> vertices.
Let <code class="reqn">D</code> and <code class="reqn">\Delta</code> be  variation matrices acting additively on <code class="reqn">\Sigma</code>. Let also <code class="reqn">\tilde\Delta</code> be a model-preserving co-variation matrix.
Denote with <code class="reqn">Y</code> and <code class="reqn">\tilde{Y}</code> the original and the perturbed random vectors. Then for a standard sensitivity analysis
</p>
<p style="text-align: center;"><code class="reqn">KL(\tilde{Y}||Y)\leq 0.5n\max\left\{f(\lambda_{\max}(D\Sigma^{-1})),f(\lambda_{\min}(D\Sigma^{-1}))\right\}</code>
</p>

<p>whilst for a model-preserving one
</p>
<p style="text-align: center;"><code class="reqn">KL(\tilde{Y}||Y)\leq 0.5n\max\left\{f(\lambda_{\max}(\tilde\Delta\circ\Delta)),f(\lambda_{\min}(\tilde\Delta\circ\Delta))\right\}</code>
</p>

<p>where <code class="reqn">\lambda_{\max}</code> and <code class="reqn">\lambda_{\min}</code> are the largest and the smallest eigenvalues, respectively, <code class="reqn">f(x)=\ln(1+x)-x/(1+x)</code> and <code class="reqn">\circ</code> denotes the Schur or element-wise product.
</p>


<h3>Value</h3>

<p>A dataframe including the KL-divergence bound for each co-variation scheme (model-preserving and standard) and every entry of the covariance matrix. For variations leading to non-positive semidefinite matrix, the dataframe includes a <code>NA</code>.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+KL.CI">KL.CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KL_bounds(synthetic_ci,1.05)


</code></pre>

<hr>
<h2 id='KL.bn.fit'>KL Divergence for <code>bn.fit</code></h2><span id='topic+KL.bn.fit'></span>

<h3>Description</h3>

<p><code>KL.bn.fit</code> returns the Kullback-Leibler (KL) divergence between a Bayesian network and its update after parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bn.fit'
KL(
  x,
  node,
  value_node,
  value_parents,
  new_value,
  covariation = "proportional",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KL.bn.fit_+3A_x">x</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="KL.bn.fit_+3A_node">node</code></td>
<td>
<p>character string. Node of which the conditional probability distribution is being changed.</p>
</td></tr>
<tr><td><code id="KL.bn.fit_+3A_value_node">value_node</code></td>
<td>
<p>character string. Level of <code>node</code>.</p>
</td></tr>
<tr><td><code id="KL.bn.fit_+3A_value_parents">value_parents</code></td>
<td>
<p>character string. Levels of <code>node</code>'s parents. The levels should be defined according to the order of the parents in <code>bnfit[[node]][["parents"]]</code>. If <code>node</code> has no parents, then it should be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="KL.bn.fit_+3A_new_value">new_value</code></td>
<td>
<p>numeric vector with elements between 0 and 1. Values to which the parameter should be updated. It can take a specific value or more than one. In the case of more than one value, these should be defined through a vector with an increasing order of the elements. <code>new_value</code> can also be set to the character string <code>all</code>: in this case a sequence of possible parameter changes ranging from 0.05 to 0.95 is considered.</p>
</td></tr>
<tr><td><code id="KL.bn.fit_+3A_covariation">covariation</code></td>
<td>
<p>character string. Co-variation scheme to be used for the updated Bayesian network. Can take values <code>uniform</code>, <code>proportional</code>, <code>orderp</code>, <code>all</code>. If equal to <code>all</code>, uniform, proportional and order-preserving co-variation schemes are used. Set by default to <code>proportional</code>.</p>
</td></tr>
<tr><td><code id="KL.bn.fit_+3A_...">...</code></td>
<td>
<p>additional parameters to be added to the plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian network on which parameter variation is being conducted should be expressed as a <code>bn.fit</code> object.
The name of the node to be varied, its level and its parent's levels should be specified.
The parameter variation specified by the function is:
</p>
<p>P ( <code>node</code> = <code>value_node</code> | parents = <code>value_parents</code> ) = <code>new_value</code>
</p>


<h3>Value</h3>

<p>A dataframe with the varied parameter and the KL divergence for different co-variation schemes. If <code>plot = TRUE</code> the function returns a plot of the KL divergences.
</p>


<h3>References</h3>

<p>Kullback, S., &amp; Leibler, R. A. (1951). On information and sufficiency. The annals of mathematical statistics, 22(1), 79-86.
</p>
<p>Leonelli, M., Goergen, C., &amp; Smith, J. Q. (2017). Sensitivity analysis in multilinear probabilistic models. Information Sciences, 411, 84-97.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CD">CD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KL(synthetic_bn, "y2", "1", "2", "all", "all")
KL(synthetic_bn, "y1", "2", NULL, 0.3, "all")

</code></pre>

<hr>
<h2 id='KL.CI'>KL Divergence for <code>CI</code></h2><span id='topic+KL.CI'></span>

<h3>Description</h3>

<p><code>KL.CI</code> returns the Kullback-Leibler (KL) divergence between an object of class <code>CI</code>  and its update after a model-preserving parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CI'
KL(x, type, entry, delta, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KL.CI_+3A_x">x</code></td>
<td>
<p>object of class <code>CI</code>.</p>
</td></tr>
<tr><td><code id="KL.CI_+3A_type">type</code></td>
<td>
<p>character string. Type of model-preserving co-variation: either <code>"total"</code>, <code>"partial"</code>, <code>row</code>,<code>column</code> or <code>all</code>. If <code>all</code> the KL divergence is computed for every type of co-variation matrix.</p>
</td></tr>
<tr><td><code id="KL.CI_+3A_entry">entry</code></td>
<td>
<p>a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="KL.CI_+3A_delta">delta</code></td>
<td>
<p>numeric vector with positive elements, including the variation parameters that act multiplicatively.</p>
</td></tr>
<tr><td><code id="KL.CI_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation of the KL divergence between a Bayesian network and its updated version after a model-preserving variation.
</p>


<h3>Value</h3>

<p>A dataframe including in the first column the variations performed, and in the following columns the corresponding KL divergences for the chosen model-preserving co-variations.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.GBN">KL.GBN</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KL(synthetic_ci, "total", c(1,1), seq(0.9,1.1,0.01))
KL(synthetic_ci, "partial", c(1,4), seq(0.9,1.1,0.01))
KL(synthetic_ci, "column", c(1,2), seq(0.9,1.1,0.01))
KL(synthetic_ci, "row", c(3,2), seq(0.9,1.1,0.01))
KL(synthetic_ci, "all", c(3,2), seq(0.9,1.1,0.01))

</code></pre>

<hr>
<h2 id='KL.GBN'>KL Divergence for <code>GBN</code></h2><span id='topic+KL.GBN'></span>

<h3>Description</h3>

<p><code>KL.GBN</code> returns the Kullback-Leibler (KL) divergence between an object of class <code>GBN</code>  and its update after a standard parameter variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GBN'
KL(x, where, entry, delta, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KL.GBN_+3A_x">x</code></td>
<td>
<p>object of class <code>GBN</code>.</p>
</td></tr>
<tr><td><code id="KL.GBN_+3A_where">where</code></td>
<td>
<p>character string: either <code>mean</code> or <code>covariance</code> for variations of the mean vector and covariance matrix respectively.</p>
</td></tr>
<tr><td><code id="KL.GBN_+3A_entry">entry</code></td>
<td>
<p>if <code>where == "mean"</code>, <code>entry</code> is the index of the entry of the mean vector to vary. If <code>where == "covariance"</code>, entry is a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="KL.GBN_+3A_delta">delta</code></td>
<td>
<p>numeric vector, including the variation parameters that act additively.</p>
</td></tr>
<tr><td><code id="KL.GBN_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computation of the KL divergence between a Bayesian network and the additively perturbed Bayesian network, where the perturbation is either to the mean vector or to the covariance matrix.
</p>


<h3>Value</h3>

<p>A dataframe including in the first column the variations performed and in the second column the corresponding KL divergences.
</p>


<h3>References</h3>

<p>Gómez-Villegas, M. A., Maín, P., &amp; Susi, R. (2007). Sensitivity analysis in Gaussian Bayesian networks using a divergence measure. Communications in Statistics—Theory and Methods, 36(3), 523-539.
</p>
<p>Gómez-Villegas, M. A., Main, P., &amp; Susi, R. (2013). The effect of block parameter perturbations in Gaussian Bayesian networks: Sensitivity and robustness. Information Sciences, 222, 439-458.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KL.CI">KL.CI</a></code>, <code><a href="#topic+Fro.CI">Fro.CI</a></code>, <code><a href="#topic+Fro.GBN">Fro.GBN</a></code>, <code><a href="#topic+Jeffreys.GBN">Jeffreys.GBN</a></code>, <code><a href="#topic+Jeffreys.CI">Jeffreys.CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>KL(synthetic_gbn,"mean",2,seq(-1,1,0.1))
KL(synthetic_gbn,"covariance",c(3,3),seq(-1,1,0.1))

</code></pre>

<hr>
<h2 id='mathmarks'>Math Marks Data</h2><span id='topic+mathmarks'></span>

<h3>Description</h3>

<p>Marks out of 100 for 88 students taking examinations in mechanics (C), vectors (C), algebra (0), analysis (O) and statistics (O), where C indicates closed and O indicates open book examination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mathmarks)
</code></pre>


<h3>Format</h3>

<p>A dataframe with 88 observations on the following 5 variables
</p>

<ul>
<li> <p><b>mechanics</b>: mark out of 100 for mechanics
</p>
</li>
<li> <p><b>vectors</b>: mark out of 100 for vectors
</p>
</li>
<li> <p><b>algebra</b>: mark out of 100 for algebra
</p>
</li>
<li> <p><b>analysis</b>: mark out of 100 for analysis
</p>
</li>
<li> <p><b>statistics</b>: mark out of 100 for statistics
</p>
</li></ul>



<h3>Source</h3>

<p>Mardia, K. V., Kent, J. T. and Bibby, J. M. (1979) Multivariate Analysis. London: Academic Press.
</p>

<hr>
<h2 id='mean_var'>Standard variation of the mean vector</h2><span id='topic+mean_var'></span>

<h3>Description</h3>

<p>Computation of an updated <code>GBN</code> object after a variation of the mean vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_var(gbn, entry, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_var_+3A_gbn">gbn</code></td>
<td>
<p>object of class <code>GBN</code>.</p>
</td></tr>
<tr><td><code id="mean_var_+3A_entry">entry</code></td>
<td>
<p>an index specifying the entry of the mean vector to vary.</p>
</td></tr>
<tr><td><code id="mean_var_+3A_delta">delta</code></td>
<td>
<p>additive variation coefficient for the entry of the mean vector given in <code>entry</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the original Bayesian network have a Normal distribution <code class="reqn">\mathcal{N}(\mu,\Sigma)</code> and let <code>entry</code> be equal to <code class="reqn">i</code>. Let <code class="reqn">\mu_i</code> be the i-th entry of <code class="reqn">\mu</code>. For a variation of the mean  by an amount <code class="reqn">\delta</code> the resulting distribution is <code class="reqn">\mathcal{N}(\mu',\Sigma)</code>, where <code class="reqn">\mu'</code> is equal to <code class="reqn">\mu</code> except for the i-th entry which is equal to <code class="reqn">\mu+\delta</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>GBN</code> with an updated mean vector.
</p>


<h3>References</h3>

<p>Gómez-Villegas, M. A., Maín, P., &amp; Susi, R. (2007). Sensitivity analysis in Gaussian Bayesian networks using a divergence measure. Communications in Statistics—Theory and Methods, 36(3), 523-539.
</p>
<p>Gómez-Villegas, M. A., Main, P., &amp; Susi, R. (2013). The effect of block parameter perturbations in Gaussian Bayesian networks: Sensitivity and robustness. Information Sciences, 222, 439-458.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covariance_var">covariance_var</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mean_var(synthetic_gbn,2,3)

</code></pre>

<hr>
<h2 id='model_pres_cov'>Model-Preserving co-variation</h2><span id='topic+model_pres_cov'></span>

<h3>Description</h3>

<p>Model-preserving co-variation for objects of class <code>CI</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_pres_cov(ci, type, entry, delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_pres_cov_+3A_ci">ci</code></td>
<td>
<p>object of class <code>CI</code>.</p>
</td></tr>
<tr><td><code id="model_pres_cov_+3A_type">type</code></td>
<td>
<p>character string. Type of model-preserving co-variation: either <code>"total"</code>, <code>"partial"</code>, <code>row</code> or <code>column</code>.</p>
</td></tr>
<tr><td><code id="model_pres_cov_+3A_entry">entry</code></td>
<td>
<p>a vector of length two specifying the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="model_pres_cov_+3A_delta">delta</code></td>
<td>
<p>multiplicative variation coefficient for the entry of the covariance matrix given in <code>entry</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the original Bayesian network have a Normal distribution <code class="reqn">\mathcal{N}(\mu,\Sigma)</code> and let <code>entry</code> be equal to <code class="reqn">(i,j)</code>. For a multiplicative variation of the covariance matrix by an amount <code class="reqn">\delta</code>, a variation matrix <code class="reqn">\Delta</code> is constructed as
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{k,l}=\left\{
\begin{array}{ll}
\delta &amp; \mbox{if } k=i, l=j\\
\delta &amp; \mbox{if } l=i, k=j \\
0 &amp; \mbox{otherwise}
\end{array}
\right.</code>
</p>

<p>A co-variation matrix <code class="reqn">\tilde\Delta</code> is then constructed and the resulting distribution after the variation is <code class="reqn">\mathcal{N}(\mu,\tilde\Delta\circ\Delta\circ\Sigma)</code>, assuming <code class="reqn">\tilde\Delta\circ\Delta\circ\Sigma</code> is positive semi-definite and where <code class="reqn">\circ</code> denotes the Schur (or element-wise) product. The matrix <code class="reqn">\tilde\Delta</code> is so constructed to ensure that all conditional independence in the original Bayesian networks are retained after the parameter variation.
</p>


<h3>Value</h3>

<p>If the resulting covariance is positive semi-definite, <code>model_pres_cov</code> returns an object of class <code>CI</code> with an updated covariance matrix. Otherwise it returns an object of class <code>npsd.ci</code>, which has the same components of <code>CI</code> but also has a warning entry specifying that the covariance matrix is not positive semi-definite.
</p>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covariance_var">covariance_var</a></code>, <code><a href="#topic+covariation_matrix">covariation_matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model_pres_cov(synthetic_ci,"partial",c(1,3),1.1)
model_pres_cov(synthetic_ci,"partial",c(1,3),0.9)
model_pres_cov(synthetic_ci,"total",c(1,2),0.5)
model_pres_cov(synthetic_ci,"row",c(1,3),0.98)
model_pres_cov(synthetic_ci,"column",c(1,3),0.98)


</code></pre>

<hr>
<h2 id='mutual_info'>Mutual information</h2><span id='topic+mutual_info'></span>

<h3>Description</h3>

<p>Computation of the mutual information in a Bayesian network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mutual_info(bnfit, node)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mutual_info_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="mutual_info_+3A_node">node</code></td>
<td>
<p>a node of <code>bnfit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mutual information between two variables <code class="reqn">X_j</code> and <code class="reqn">X_i</code> with sample spaces <code class="reqn">\mathcal{X}_i</code> and <code class="reqn">\mathcal{X}_j</code>, respectively, is equal to </p>
<p style="text-align: center;"><code class="reqn">\sum_{x_j\in\mathcal{X}_j}\sum_{x_i\in\mathcal{X}_i}p(x_i,x_j)\log\frac{p(x_i,x_j)}{p(x_i)p(x_j)}.</code>
</p>



<h3>Value</h3>

<p>A dataframe with the following columns: <code>Nodes</code> - the vertices of the BN; <code>MutualInfo</code> - the mutual information of the corresponding node.
</p>


<h3>References</h3>

<p>Albrecht, D., Nicholson, A. E., &amp; Whittle, C. (2014). Structural sensitivity for the knowledge engineering of Bayesian networks. In Probabilistic Graphical Models (pp. 1-16). Springer International Publishing.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ewi">ewi</a></code>, <code><a href="#topic+dwi">dwi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mutual_info(travel, "T")

</code></pre>

<hr>
<h2 id='node_monitor'>Node monitor</h2><span id='topic+node_monitor'></span>

<h3>Description</h3>

<p>Contribution of each vertex of a Bayesian network to the global monitor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>node_monitor(dag, df, alpha = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="node_monitor_+3A_dag">dag</code></td>
<td>
<p>an object of class <code>bn</code> from the <code>bnlearn</code> package</p>
</td></tr>
<tr><td><code id="node_monitor_+3A_df">df</code></td>
<td>
<p>a base R style dataframe</p>
</td></tr>
<tr><td><code id="node_monitor_+3A_alpha">alpha</code></td>
<td>
<p>single integer. By default, number of max levels in <code>df</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider a Bayesian network over variables <code class="reqn">Y_1,\dots,Y_m</code> and suppose a dataset <code class="reqn">(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)</code> has been observed, where <code class="reqn">\boldsymbol{y}_i=(y_{i1},\dots,y_{im})</code> and <code class="reqn">y_{ij}</code> is the i-th observation of the j-th variable. The global monitor is defined as the negative log-likelihood of the model, i.e.
</p>
<p style="text-align: center;"><code class="reqn">-\log(p(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n))= - \sum_{j=1}^m\sum_{i=1}^n \log(p(y_{ij} | \pi_{ij})),</code>
</p>

<p>where <code class="reqn">\pi_{ij}</code> is the value of the parents of <code class="reqn">Y_j</code> for the i-th observation. The contribution of the j-th vertex to the global monitor is thus
</p>
<p style="text-align: center;"><code class="reqn">-\sum_{i=1}^n\log(p(y_{ij}|\pi_{ij})).</code>
</p>



<h3>Value</h3>

<p>A dataframe including the name of the vertices and the contribution of the vertices to the global monitor. It also returns a plot where vertices with higher contributions in absolute value are darker.
</p>


<h3>References</h3>

<p>Cowell, R. G., Dawid, P., Lauritzen, S. L., &amp; Spiegelhalter, D. J. (2006). Probabilistic networks and expert systems: Exact computational methods for Bayesian networks. Springer Science &amp; Business Media.
</p>
<p>Cowell, R. G., Verrall, R. J., &amp; Yoon, Y. K. (2007). Modeling operational risk with Bayesian networks. Journal of Risk and Insurance, 74(4), 795-827.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+global_monitor">global_monitor</a></code>, <code><a href="#topic+influential_obs">influential_obs</a></code>, <code><a href="#topic+final_node_monitor">final_node_monitor</a></code>, <code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>, <code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>node_monitor(chds_bn, chds, 3)

</code></pre>

<hr>
<h2 id='plot'>Plotting methods</h2><span id='topic+plot'></span><span id='topic+plot.seq_marg_monitor'></span><span id='topic+plot.CD'></span><span id='topic+plot.seq_cond_monitor'></span><span id='topic+plot.node_monitor'></span><span id='topic+plot.influential_obs'></span><span id='topic+plot.jeffreys'></span><span id='topic+plot.kl'></span><span id='topic+plot.final_node_monitor'></span><span id='topic+plot.seq_pa_ch_monitor'></span><span id='topic+plot.sensitivity'></span><span id='topic+plot.fro'></span><span id='topic+plot.diameter'></span><span id='topic+plot.edgestrength'></span><span id='topic+plot.mutualinfo'></span><span id='topic+plot.dwi'></span><span id='topic+plot.ewi'></span>

<h3>Description</h3>

<p>Plotting methods for outputs of <code>bnmonitor</code> functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'seq_marg_monitor'
plot(x, ...)

## S3 method for class 'CD'
plot(x, ...)

## S3 method for class 'seq_cond_monitor'
plot(x, ...)

## S3 method for class 'node_monitor'
plot(x, ...)

## S3 method for class 'influential_obs'
plot(x, ...)

## S3 method for class 'jeffreys'
plot(x, ...)

## S3 method for class 'kl'
plot(x, ...)

## S3 method for class 'final_node_monitor'
plot(x, which, ...)

## S3 method for class 'seq_pa_ch_monitor'
plot(x, ...)

## S3 method for class 'sensitivity'
plot(x, ...)

## S3 method for class 'fro'
plot(x, ...)

## S3 method for class 'diameter'
plot(x, ...)

## S3 method for class 'edgestrength'
plot(x, ...)

## S3 method for class 'mutualinfo'
plot(x, ...)

## S3 method for class 'dwi'
plot(x, ...)

## S3 method for class 'ewi'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>The output of node_monitor.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>for compatibility</p>
</td></tr>
<tr><td><code id="plot_+3A_which">which</code></td>
<td>
<p>select the monitor to plot, either &quot;marginal&quot; or &quot;conditional&quot; (for output of <code>node_monitor</code> only).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot specific to the object it is applied to.
</p>

<hr>
<h2 id='print'>Printing methods</h2><span id='topic+print'></span><span id='topic+print.sensitivity'></span><span id='topic+print.diameter'></span><span id='topic+print.mutualinfo'></span><span id='topic+print.dwi'></span><span id='topic+print.ewi'></span><span id='topic+print.kl'></span><span id='topic+print.CD'></span><span id='topic+print.fro'></span><span id='topic+print.node_monitor'></span><span id='topic+print.jeffreys'></span><span id='topic+print.final_node_monitor'></span><span id='topic+print.seq_cond_monitor'></span><span id='topic+print.seq_pa_ch_monitor'></span><span id='topic+print.seq_marg_monitor'></span>

<h3>Description</h3>

<p>Printing methods for outputs of <code>bnmonitor</code> functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sensitivity'
print(x, ...)

## S3 method for class 'diameter'
print(x, ...)

## S3 method for class 'mutualinfo'
print(x, ...)

## S3 method for class 'dwi'
print(x, ...)

## S3 method for class 'ewi'
print(x, ...)

## S3 method for class 'kl'
print(x, ...)

## S3 method for class 'CD'
print(x, ...)

## S3 method for class 'fro'
print(x, ...)

## S3 method for class 'node_monitor'
print(x, ...)

## S3 method for class 'jeffreys'
print(x, ...)

## S3 method for class 'final_node_monitor'
print(x, ...)

## S3 method for class 'seq_cond_monitor'
print(x, ...)

## S3 method for class 'seq_pa_ch_monitor'
print(x, ...)

## S3 method for class 'seq_marg_monitor'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print_+3A_x">x</code></td>
<td>
<p>an appropriate object</p>
</td></tr>
<tr><td><code id="print_+3A_...">...</code></td>
<td>
<p>for compatibility</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Printing specific to the object it is applied to.
</p>

<hr>
<h2 id='psd_check'>Check for positive semi-definiteness after a perturbation</h2><span id='topic+psd_check'></span><span id='topic+psd_check.GBN'></span><span id='topic+psd_check.CI'></span>

<h3>Description</h3>

<p><code>psd_check</code> returns a boolean to determine if the covariance matrix after a perturbation is positive semi-definite.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psd_check(x, ...)

## S3 method for class 'GBN'
psd_check(x, entry, delta, ...)

## S3 method for class 'CI'
psd_check(x, type, entry, delta, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="psd_check_+3A_x">x</code></td>
<td>
<p>object of class <code>GBN</code> or <code>CI</code>.</p>
</td></tr>
<tr><td><code id="psd_check_+3A_...">...</code></td>
<td>
<p>additional arguments for compatibility.</p>
</td></tr>
<tr><td><code id="psd_check_+3A_entry">entry</code></td>
<td>
<p>a vector of length 2 indicating the entry of the covariance matrix to vary.</p>
</td></tr>
<tr><td><code id="psd_check_+3A_delta">delta</code></td>
<td>
<p>numeric vector, including the variation parameters that act additively.</p>
</td></tr>
<tr><td><code id="psd_check_+3A_type">type</code></td>
<td>
<p>character string. Type of model-preserving co-variation: either <code>total</code>, <code>partial</code>, <code>row</code>, <code>column</code> or <code>all</code>. If <code>all</code>, the Frobenius norms are computed for every type of co-variation matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details depend on the class the method <code>psd_check</code> is applied to.
</p>
<p>Let <code class="reqn">\Sigma</code> be the covariance matrix of a Gaussian Bayesian network and let <code class="reqn">D</code> be a perturbation matrix acting additively. The perturbed covariance matrix <code class="reqn">\Sigma+D</code> is positive semi-definite if
</p>
<p style="text-align: center;"><code class="reqn">\rho(D)\leq \lambda_{\min}(\Sigma)</code>
</p>

<p>where <code class="reqn">\lambda_{\min}</code> is the smallest eigenvalue end <code class="reqn">\rho</code> is the spectral radius.
</p>


<h3>Value</h3>

<p>A dataframe including the variations performed and the check for positive semi-definiteness.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>psd_check(GBN)</code>: <code>psd_check</code> for objects <code>GBN</code>
</p>
</li>
<li> <p><code>psd_check(CI)</code>: <code>psd_check</code> for objects <code>CI</code>
</p>
</li></ul>


<h3>References</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>psd_check(synthetic_gbn,c(2,4),-3)
psd_check(synthetic_gbn,c(2,3),seq(-1,1,0.1))
psd_check(synthetic_ci,"partial",c(2,4),0.95)
psd_check(synthetic_ci,"all",c(2,3),seq(0.9,1.1,0.01))

</code></pre>

<hr>
<h2 id='sensitivity'>Sensitivity function</h2><span id='topic+sensitivity'></span>

<h3>Description</h3>

<p><code>sensitivity</code> returns the sensitivity function for a probabilistic query of interest with respect to a parameter change defined by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensitivity(
  bnfit,
  interest_node,
  interest_node_value,
  evidence_nodes = NULL,
  evidence_states = NULL,
  node,
  value_node,
  value_parents,
  new_value,
  covariation = "proportional"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sensitivity_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_interest_node">interest_node</code></td>
<td>
<p>character string. Node of the probability query of interest.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_interest_node_value">interest_node_value</code></td>
<td>
<p>character string. Level of <code>interest_node</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_evidence_nodes">evidence_nodes</code></td>
<td>
<p>character string. Evidence nodes. If <code>NULL</code> no evidence is considered. Set by default to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_evidence_states">evidence_states</code></td>
<td>
<p>character string. Levels of <code>evidence_nodes</code>. If <code>NULL</code> no evidence is considered. If <code>evidence_nodes="NULL"</code>, <code>evidence_states</code> should be set to <code>NULL</code>. Set by default to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_node">node</code></td>
<td>
<p>character string. Node of which the conditional probability distribution is being changed.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_value_node">value_node</code></td>
<td>
<p>character string. Level of <code>node</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_value_parents">value_parents</code></td>
<td>
<p>character string. Levels of <code>node</code>'s parents. The levels should be defined according to the order of the parents in <code>bnfit[[node]][["parents"]]</code>. If <code>node</code> has no parents, then should be set to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_new_value">new_value</code></td>
<td>
<p>numeric vector with elements between 0 and 1. Values to which the parameter should be updated. It can take a specific value or more than one. For more than one value, these should be defined through a vector with an increasing order of the elements. <code>new_value</code> can also take as value the character string <code>all</code>: in this case a sequence of possible parameter changes ranging from 0.05 to 0.95 is considered.</p>
</td></tr>
<tr><td><code id="sensitivity_+3A_covariation">covariation</code></td>
<td>
<p>character string. Co-variation scheme to be used for the updated Bayesian network. Can take values <code>uniform</code>, <code>proportional</code>, <code>orderp</code>, <code>all</code>. If equal to <code>all</code>, uniform, proportional and order-preserving co-variation schemes are considered. Set by default to <code>proportional</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian network on which parameter variation is being conducted should be expressed as a bn.fit object.
The name of the node to be varied, its level and its parent's level should be specified.
The parameter variation specified by the function is:
</p>
<p>P ( <code>node</code> = <code>value_node</code> | parents = <code>value_parents</code> ) = <code>new_value</code>
</p>
<p>and the probabilistic query of interest is:
</p>
<p>P ( <code>interest_node</code> = <code>interest_node_value</code> | <code>evidence_nodes</code> = <code>evidence_states</code> )
</p>


<h3>Value</h3>

<p>A dataframe with the varied parameter values and the output probabilities for the co-variation schemes selected. If <code>plot = TRUE</code> the function also returns a plot of the sensitivity function.
</p>


<h3>References</h3>

<p>Coupé, V. M., &amp; Van Der Gaag, L. C. (2002). Properties of sensitivity analysis of Bayesian belief networks. Annals of Mathematics and Artificial Intelligence, 36(4), 323-356.
</p>
<p>Leonelli, M., Goergen, C., &amp; Smith, J. Q. (2017). Sensitivity analysis in multilinear probabilistic models. Information Sciences, 411, 84-97.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covariation">covariation</a></code>, <code><a href="#topic+sensquery">sensquery</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sensitivity(synthetic_bn, "y2", "3", node = "y1",value_node = "1",
 value_parents = NULL, new_value = "all", covariation = "all")
sensitivity(synthetic_bn, "y3", "1", "y2", "1", node = "y1", "1", NULL, 0.9, "all")

</code></pre>

<hr>
<h2 id='sensquery'>Sensitivity of probability query</h2><span id='topic+sensquery'></span>

<h3>Description</h3>

<p><code>sensquery</code> returns, for a given change in a probability of interest, the parameters' changes to achieve it together with the corresponding CD distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensquery(
  bnfit,
  interest_node,
  interest_node_value,
  new_value,
  evidence_nodes = NULL,
  evidence_states = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sensquery_+3A_bnfit">bnfit</code></td>
<td>
<p>object of class <code>bn.fit</code>.</p>
</td></tr>
<tr><td><code id="sensquery_+3A_interest_node">interest_node</code></td>
<td>
<p>character string. Node of the probability query of interest.</p>
</td></tr>
<tr><td><code id="sensquery_+3A_interest_node_value">interest_node_value</code></td>
<td>
<p>character string. Level of <code>interest_node</code>.</p>
</td></tr>
<tr><td><code id="sensquery_+3A_new_value">new_value</code></td>
<td>
<p>numeric value between 0 and 1. New value of the probability of interest.</p>
</td></tr>
<tr><td><code id="sensquery_+3A_evidence_nodes">evidence_nodes</code></td>
<td>
<p>character string. Evidence nodes. Set by default to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="sensquery_+3A_evidence_states">evidence_states</code></td>
<td>
<p>character string. Levels of <code>evidence_nodes</code>. If <code>NULL</code> no evidence is considered. If <code>evidence_nodes="NULL"</code>, <code>evidence_states</code> should be set to <code>NULL</code>. Set by default to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian network should be expressed as a <code>bn.fit</code> object.
The name of the node of the probability of interest, its level and the new value should be specified. Evidence could be also indicated.
The probability of interest is specified as follows:
</p>
<p>P ( <code>interest_node</code> = <code>interest_node_value</code> | <code>evidence_nodes</code> = <code>evidence_states</code>  ) = <code>new_value</code>
</p>
<p>Only the  proportional co-variation scheme is used.
</p>


<h3>Value</h3>

<p>A dataframe with the following columns: <code>node</code> - the vertex of the proposed change; <code>Value node</code> - the level of <code>node</code> to be changed; <code>Value parents</code> - the levels of the parent variables of <code>node</code>; <code>Original value</code> - the original probability defined by <code>Node</code>, <code>Value node</code> and <code>Value parents</code>; <code>Suggested change</code> - the new proposed value for the probability defined by <code>Node</code>, <code>Value node</code> and <code>Value parents</code>; <code>CD distance</code> - the CD distance between the original and new network with the <code>Suggested change</code>.
</p>


<h3>References</h3>

<p>Chan, H., &amp; Darwiche, A. (2002). When do numbers really matter?. Journal of Artificial Intelligence Research, 17, 265-287.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sensitivity">sensitivity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sensquery(synthetic_bn,"y3", "3", 0.3)

</code></pre>

<hr>
<h2 id='seq_node_monitor'>Sequential node monitors</h2><span id='topic+seq_node_monitor'></span><span id='topic+seq_marg_monitor'></span><span id='topic+seq_cond_monitor'></span>

<h3>Description</h3>

<p>Sequential marginal and conditional node monitors for a vertex of a Bayesian network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_marg_monitor(dag, df, node.name)

seq_cond_monitor(dag, df, node.name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq_node_monitor_+3A_dag">dag</code></td>
<td>
<p>an object of class <code>bn</code> from the <code>bnlearn</code> package</p>
</td></tr>
<tr><td><code id="seq_node_monitor_+3A_df">df</code></td>
<td>
<p>a base R style dataframe</p>
</td></tr>
<tr><td><code id="seq_node_monitor_+3A_node.name">node.name</code></td>
<td>
<p>node over which to compute the monitor</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider a Bayesian network over variables <code class="reqn">Y_1,\dots,Y_m</code> and suppose a dataset <code class="reqn">(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)</code> has been observed, where <code class="reqn">\boldsymbol{y}_i=(y_{i1},\dots,y_{im})</code> and <code class="reqn">y_{ij}</code> is the i-th observation of the j-th variable.
Let <code class="reqn">p_i</code> denote the marginal density of <code class="reqn">Y_j</code> after the first <code class="reqn">i-1</code> observations have been processed. Define
</p>
<p style="text-align: center;"><code class="reqn">E_i = \sum_{k=1}^Kp_i(d_k)\log(p_i(d_k)),</code>
</p>

<p style="text-align: center;"><code class="reqn">V_i = \sum_{k=1}^K p_i(d_k)\log^2(p_i(d_k))-E_i^2,</code>
</p>

<p>where <code class="reqn">(d_1,\dots,d_K)</code> are the possible values of <code class="reqn">Y_j</code>. The sequential marginal node monitor for the vertex <code class="reqn">Y_j</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">Z_{ij}=\frac{-\sum_{k=1}^i\log(p_k(y_{kj}))-\sum_{k=1}^i E_k}{\sqrt{\sum_{k=1}^iV_k}}.</code>
</p>

<p>Values of <code class="reqn">Z_{ij}</code> such that <code class="reqn">|Z_{ij}|&gt; 1.96</code> can give an indication of a poor model fit for the vertex <code class="reqn">Y_j</code> after the first i-1 observations have been processed.
</p>
<p>The sequential conditional node monitor for the vertex <code class="reqn">Y_j</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">Z_{ij}=\frac{-\sum_{k=1}^i\log(p_k(y_{kj}|y_{k1},\dots,y_{k(j-1)},y_{k(j+1)},\dots,y_{km}))-\sum_{k=1}^i E_k}{\sqrt{\sum_{k=1}^iV_k}},</code>
</p>

<p>where <code class="reqn">E_k</code> and <code class="reqn">V_k</code> are computed with respect to <code class="reqn">p_k(y_{kj}|y_{k1},\dots,y_{k(j-1)},y_{k(j+1)},\dots,y_{km})</code>. Again, values of <code class="reqn">Z_{ij}</code> such that <code class="reqn">|Z_{ij}|&gt; 1.96</code> can give an indication of a poor model fit for the vertex <code class="reqn">Y_j</code>.
</p>


<h3>Value</h3>

<p>A vector including the scores <code class="reqn">Z_{ij}</code>, either marginal or conditional.
</p>


<h3>References</h3>

<p>Cowell, R. G., Dawid, P., Lauritzen, S. L., &amp; Spiegelhalter, D. J. (2006). Probabilistic networks and expert systems: Exact computational methods for Bayesian networks. Springer Science &amp; Business Media.
</p>
<p>Cowell, R. G., Verrall, R. J., &amp; Yoon, Y. K. (2007). Modeling operational risk with Bayesian networks. Journal of Risk and Insurance, 74(4), 795-827.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+influential_obs">influential_obs</a></code>, <code><a href="#topic+node_monitor">node_monitor</a></code>, <code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>, <code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seq_marg_monitor(chds_bn, chds[1:100,], "Events")
seq_marg_monitor(chds_bn, chds[1:100,], "Admission")

</code></pre>

<hr>
<h2 id='seq_pa_ch_monitor'>Sequential parent-child node monitors</h2><span id='topic+seq_pa_ch_monitor'></span>

<h3>Description</h3>

<p>Sequential node monitor for a vertex of a Bayesian network for a specific configuration of its parents
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_pa_ch_monitor(dag, df, node.name, pa.names, pa.val, alpha = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq_pa_ch_monitor_+3A_dag">dag</code></td>
<td>
<p>an object of class <code>bn</code> from the <code>bnlearn</code> package</p>
</td></tr>
<tr><td><code id="seq_pa_ch_monitor_+3A_df">df</code></td>
<td>
<p>a base R style dataframe</p>
</td></tr>
<tr><td><code id="seq_pa_ch_monitor_+3A_node.name">node.name</code></td>
<td>
<p>node over which to compute the monitor</p>
</td></tr>
<tr><td><code id="seq_pa_ch_monitor_+3A_pa.names">pa.names</code></td>
<td>
<p>vector including the names of the parents of <code>node.name</code></p>
</td></tr>
<tr><td><code id="seq_pa_ch_monitor_+3A_pa.val">pa.val</code></td>
<td>
<p>vector including the levels of <code>pa.names</code> considered</p>
</td></tr>
<tr><td><code id="seq_pa_ch_monitor_+3A_alpha">alpha</code></td>
<td>
<p>single integer. By default, the number of max levels in <code>df</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider a Bayesian network over variables <code class="reqn">Y_1,\dots,Y_m</code> and suppose a dataset <code class="reqn">(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)</code> has been observed, where <code class="reqn">\boldsymbol{y}_i=(y_{i1},\dots,y_{im})</code> and <code class="reqn">y_{ij}</code> is the i-th observation of the j-th variable.
Consider a configuration <code class="reqn">\pi_j</code> of the parents and consider the sub-vector <code class="reqn">\boldsymbol{y}'=(\boldsymbol{y}_1',\dots,\boldsymbol{y}_{N'}')</code> of <code class="reqn">(\boldsymbol{y}_1,\dots,\boldsymbol{y}_n)</code> including observations where the parents of <code class="reqn">Y_j</code> take value <code class="reqn">\pi_j</code> only.
Let <code class="reqn">p_i(\cdot|\pi_j)</code> be the conditional distribution of <code class="reqn">Y_j</code> given that its parents take value <code class="reqn">\pi_j</code> after the first i-1 observations have been processed. Define
</p>
<p style="text-align: center;"><code class="reqn">E_i = \sum_{k=1}^Kp_i(d_k|\pi_j)\log(p_i(d_k|\pi_j)),</code>
</p>

<p style="text-align: center;"><code class="reqn">V_i = \sum_{k=1}^K p_i(d_k|\pi_j)\log^2(p_i(d_k|\pi_j))-E_i^2,</code>
</p>

<p>where <code class="reqn">(d_1,\dots,d_K)</code> are the possible values of <code class="reqn">Y_j</code>. The sequential parent-child node monitor for the vertex <code class="reqn">Y_j</code> and parent configuration <code class="reqn">\pi_j</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">Z_{ij}=\frac{-\sum_{k=1}^i\log(p_k(y_{kj}'|\pi_j))-\sum_{k=1}^i E_k}{\sqrt{\sum_{k=1}^iV_k}}.</code>
</p>

<p>Values of <code class="reqn">Z_{ij}</code> such that <code class="reqn">|Z_{ij}|&gt; 1.96</code> can give an indication of a poor model fit for the vertex <code class="reqn">Y_j</code> after the first i-1 observations have been processed.
</p>


<h3>Value</h3>

<p>A vector including the scores <code class="reqn">Z_{ij}</code>.
</p>


<h3>References</h3>

<p>Cowell, R. G., Dawid, P., Lauritzen, S. L., &amp; Spiegelhalter, D. J. (2006). Probabilistic networks and expert systems: Exact computational methods for Bayesian networks. Springer Science &amp; Business Media.
</p>
<p>Cowell, R. G., Verrall, R. J., &amp; Yoon, Y. K. (2007). Modeling operational risk with Bayesian networks. Journal of Risk and Insurance, 74(4), 795-827.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+influential_obs">influential_obs</a></code>, <code><a href="#topic+node_monitor">node_monitor</a></code>, <code><a href="#topic+seq_node_monitor">seq_node_monitor</a></code>, <code><a href="#topic+seq_pa_ch_monitor">seq_pa_ch_monitor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seq_pa_ch_monitor(chds_bn, chds, "Events", "Social", "High", 3)

</code></pre>

<hr>
<h2 id='synthetic_bn'>A synthetic Bayesian network</h2><span id='topic+synthetic_bn'></span>

<h3>Description</h3>

<p><code>synthetic_bn</code> is a <code>bn.fit</code> object for a simple Bayesian network involving three variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>synthetic_bn
</code></pre>


<h3>Format</h3>

<p>The Bayesian network <code>bnsens_example</code> comprehends the following nodes:
</p>

<ul>
<li> <p><b>y1</b>: three-level factor with levels <em>1</em>, <em>2</em>, <em>3</em>.
</p>
</li>
<li> <p><b>y2</b>: three-level factor with levels <em>1</em>, <em>2</em>, <em>3</em>.
</p>
</li>
<li> <p><b>y3</b>:  three-level factor with levels <em>1</em>, <em>2</em>, <em>3</em>.
</p>
</li></ul>



<h3>Source</h3>

<p>Leonelli, M., &amp; Riccomagno, E. (2022). A geometric characterization of sensitivity analysis in monomial models. International Journal of Approximate Reasoning, 151, 64-84.
</p>

<hr>
<h2 id='synthetic_cbn'>A synthetic continuous Bayesian network</h2><span id='topic+synthetic_cbn'></span><span id='topic+synthetic_gbn'></span><span id='topic+synthetic_ci'></span>

<h3>Description</h3>

<p>A synthetic continuous Bayesian network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>synthetic_gbn

synthetic_ci
</code></pre>


<h3>Format</h3>

<p>A continuous Bayesian networks over four variables (&quot;y1&quot;, &quot;y2&quot;, &quot;y3&quot;, &quot;y4&quot;), embedding the statement &quot;y1&quot; independent of &quot;y3&quot; given &quot;y2&quot;.
The Bayesian network is available both as an object of class <code>GBN</code> and as an object of class <code>CI</code>.
</p>
<p>An object of class <code>GBN</code> of length 3.
</p>
<p>An object of class <code>CI</code> of length 4.
</p>


<h3>Source</h3>

<p>C. Görgen &amp; M. Leonelli (2020), Model-preserving sensitivity analysis for families of Gaussian distributions.  Journal of Machine Learning Research, 21: 1-32.
</p>

<hr>
<h2 id='travel'>Bayesian network on travel survey</h2><span id='topic+travel'></span>

<h3>Description</h3>

<p><code>travel</code> is a <code>bn.fit</code> object for the Bayesian network on a traveling preferences survey.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>travel
</code></pre>


<h3>Format</h3>

<p>The Bayesian network <code>travel</code> includes the following nodes:
</p>

<ul>
<li> <p><b>A</b>: three-level factor with levels <code>young</code>, <code>adult</code>, <code>old</code>. It indicates the age of an individual.
</p>
</li>
<li> <p><b>S</b>: two level-factor with levels <code>M</code> (male) and <code>F</code> (female). It indicates the gender of an individual.
</p>
</li>
<li> <p><b>E</b>: two level-factor with levels <code>high</code> and <code>uni</code>. It indicates the education level of an individual.
</p>
</li>
<li> <p><b>O</b>: two level-factor with levels <code>emp</code> (employed) and <code>self</code> (self-employed). It indicates the occupation of an individual.
</p>
</li>
<li> <p><b>R</b>: two level-factor with levels <code>small</code> and <code>big</code>. It indicates the size of the residence of an individual.
</p>
</li>
<li> <p><b>T</b>: three level-factor with levels <code>car</code>, <code>train</code> and <code>other</code>. It indicates the preferred mean of transportation by an individual.
</p>
</li></ul>



<h3>Source</h3>

<p>Scutari, M., &amp; Denis, J. B. (2014). Bayesian networks: with examples in R. Chapman and Hall/CRC.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
