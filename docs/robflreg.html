<!DOCTYPE html><html><head><title>Help for package robflreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {robflreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#robflreg-package'>
<p>Robust function-on-function regression</p></a></li>
<li><a href='#generate.ff.data'><p>Generate functional data for the function-on-function regression model</p></a></li>
<li><a href='#generate.sf.data'><p>Generate functional data for the scalar-on-function regression model</p></a></li>
<li><a href='#get.ff.coeffs'><p>Get the estimated bivariate regression coefficient functions for function-on-function regression model</p></a></li>
<li><a href='#get.sf.coeffs'><p>Get the estimated regression coefficient functions for scalar-on-function regression model</p></a></li>
<li><a href='#getPCA'><p>Functional principal component analysis</p></a></li>
<li><a href='#getPCA.test'><p>Get the functional principal component scores for a given test sample</p></a></li>
<li><a href='#MaryRiverFlow'><p>Hourly River Flow Measurements in the Mery River</p></a></li>
<li><a href='#plot_ff_coeffs'><p>Image plot of bivariate regression coefficient functions of a function-on-function regression model</p></a></li>
<li><a href='#plot_sf_coeffs'><p>Plot of regression coefficient functions of a scalar-on-function regression model</p></a></li>
<li><a href='#predict_ff_regression'><p>Prediction for a function-on-function regression model</p></a></li>
<li><a href='#predict_sf_regression'><p>Prediction for a scalar-on-function regression model</p></a></li>
<li><a href='#rob.ff.reg'><p>Robust function-on-function regression</p></a></li>
<li><a href='#rob.out.detect'><p>Outlier detection in the functional response</p></a></li>
<li><a href='#rob.sf.reg'><p>Robust scalar-on-function regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Functional Linear Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-24</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), fda, MASS, robustbase</td>
</tr>
<tr>
<td>Imports:</td>
<td>expm, fda.usc, goffda, mvtnorm, pcaPP, fields</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ufuk Beyaztas &lt;ufukbeyaztas@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for implementing robust methods for functional linear regression. In the functional linear regression, we consider scalar-on-function linear regression and function-on-function linear regression. More details, see Beyaztas, U., and Shang, H. L. (2021) &lt;<a href="https://doi.org/10.48550/arXiv.2111.01238">doi:10.48550/arXiv.2111.01238</a>&gt; and Beyaztas, U., and Shang, H. L. (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2203.05065">doi:10.48550/arXiv.2203.05065</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-23 21:05:46 UTC; hanlinshang</td>
</tr>
<tr>
<td>Author:</td>
<td>Ufuk Beyaztas <a href="https://orcid.org/0000-0002-5208-4950"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Han Lin Shang <a href="https://orcid.org/0000-0003-1769-6430"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-23 21:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='robflreg-package'>
Robust function-on-function regression
</h2><span id='topic+robflreg-package'></span><span id='topic+robflreg'></span>

<h3>Description</h3>

<p>This package presents robust methods for analyzing functional linear regression.
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>
<p>Maintainer: Ufuk Beyaztas &lt;ufukbeyaztas@gmail.com&gt;
</p>


<h3>References</h3>

<p>B. Akturk, U. Beyaztas, H. L. Shang, A. Mandal (2024) Robust functional logistic regression, <em>Advances in Data Analysis and Classification</em>, in press.
</p>
<p>U. Beyaztas, H. L. Shang and A. Mandal (2024) Robust function-on-function interaction regression, <em>Statistical Modelling: An International Journal</em>, in press.
</p>
<p>U. Beyaztas, M. Tez and H. L. Shang (2024) Robust scalar-on-function partial quantile regression, <em>Journal of Applied Statistics</em>, in press.
</p>
<p>U. Beyaztas and H. L. Shang (2023) Robust functional linear regression models, <em>The R Journal</em>, <b>15</b>(1), 212-233.
</p>
<p>M. Mutis, U. Beyaztas, G. G. Simsek and H. L. Shang (2023) A robust scalar-on-function logistic regression for classification, <em>Communications in Statistics - Theory and Methods</em>, <b>52</b>(23), 8538-8554.
</p>
<p>S. Saricam, U. Beyaztas, B. Asikgil and H. L. Shang (2022) On partial least-squares estimation in scalar-on-function regression models, <em>Journal of Chemometrics</em>, <b>36</b>(12), e3452.
</p>
<p>U. Beyaztas and H. L. Shang (2022) A comparison of parameter estimation in function-on-function regression, Communications in Statistics - Simulation and Computation, 51(8), 4607-4637.
</p>
<p>U. Beyaztas and H. L. Shang (2022) A robust functional partial least squares for scalar-on-multiple-function regression, Journal of Chemometrics, 36(4), e3394.
</p>
<p>U. Beyaztas, H. L. Shang and A. Alin (2022) Function-on-function partial quantile regression, Journal of Agricultural, Biological, and Environmental Statistics, 27(1), 149-174.
</p>
<p>U. Beyaztas and H. L. Shang (2021) A partial least squares approach for function-on-function interaction regression, Computational Statistics, 36(2), 911-939.
</p>
<p>U. Beyaztas and H. L. Shang (2021) A robust partial least squares approach for function-on-function regression, Brazilian Journal of Probability and Statistics, 36(2), 199-219.
</p>
<p>U. Beyaztas and H. L. Shang (2021) Function-on-function linear quantile regression, Mathematical Modelling and Analysis, 27(2), 322-341.
</p>
<p>U. Beyaztas and H. L. Shang (2020) On function-on-function regression: partial least squares approach, Environmental and Ecological Statistics, 27(1), 95-114.
</p>
<p>U. Beyaztas and H. L. Shang (2019) Forecasting functional time series using weighted likelihood methodology, 89(16), 3046-3060.
</p>

<hr>
<h2 id='generate.ff.data'>Generate functional data for the function-on-function regression model</h2><span id='topic+generate.ff.data'></span>

<h3>Description</h3>

<p>This function provides a unified simulation structure for the function-on-function regression model </p>
<p style="text-align: center;"><code class="reqn">
Y(t) = \sum_{m=1}^M \int X_m(s) \beta_m(s,t) ds + \epsilon(t),</code>
</p>
<p> where <code class="reqn">Y(t)</code> denotes the functional response, <code class="reqn">X_m(s)</code> denotes the <code class="reqn">m</code>-th functional predictor, <code class="reqn">\beta_m(s,t)</code> denotes the <code class="reqn">m</code>-th bivariate regression coefficient function, and <code class="reqn">\epsilon(t)</code> is the error function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.ff.data(n.pred, n.curve, n.gp, out.p = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate.ff.data_+3A_n.pred">n.pred</code></td>
<td>
<p>An integer, denoting the number of functional predictors to be generated.</p>
</td></tr>
<tr><td><code id="generate.ff.data_+3A_n.curve">n.curve</code></td>
<td>
<p>An integer, specifying the number of observations for each functional variable to be generated.</p>
</td></tr>
<tr><td><code id="generate.ff.data_+3A_n.gp">n.gp</code></td>
<td>
<p>An integer, denoting the number of grid points, i.e., a fine grid on the interval [0, 1].</p>
</td></tr>
<tr><td><code id="generate.ff.data_+3A_out.p">out.p</code></td>
<td>
<p>An integer between 0 and 1, denoting the outlier percentage in the generated data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the data generation process, first, the functional predictors are simulated based on the following process: </p>
<p style="text-align: center;"><code class="reqn">
X_m(s) = \sum_{j=1}^5 \kappa_j v_j(s),</code>
</p>
<p> where <code class="reqn"> \kappa_j </code> is a vector generated from a Normal distribution with mean one and variance <code class="reqn">\sqrt{a} j^{-1/2}</code>, <code class="reqn">a</code> is a uniformly generated random number between 1 and 4, and </p>
<p style="text-align: center;"><code class="reqn">v_j(s) = \sin(j \pi s) - \cos(j \pi s).</code>
</p>
<p> The bivariate regression coefficient functions are generated from a coefficient space that includes ten different functions such as: </p>
<p style="text-align: center;"><code class="reqn">b \sin(2 \pi s) \sin(\pi t)</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">b e^{-3 (s - 0.5)^2} e^{-4 (t - 1)^2},</code>
</p>
<p> where <code class="reqn">b</code> is generated from a uniform distribution between 1 and 3. The error function <code class="reqn">\epsilon(t)</code>, on the other hand, is generated from the Ornstein-Uhlenbeck process: </p>
<p style="text-align: center;"><code class="reqn">\epsilon(t) = l + [\epsilon_0(t) - l] e^{-\theta t} + \sigma \int_0^t e^{-\theta (t-u)} d W_u,</code>
</p>
<p> where <code class="reqn">l, \theta &gt; 0, \sigma &gt; 0</code> are constants, <code class="reqn">\epsilon_0(t)</code> is the initial value of <code class="reqn">\epsilon(t)</code> taken from <code class="reqn">W_u</code>, and
<code class="reqn">W_u</code> is the Wiener process. If outliers are allowed in the generated data, i.e., <code class="reqn">out.p &gt; 0</code>, then, the randomly selected <code class="reqn">n.curve \times out.p</code> of the data are generated in a different way from the aforementioned process. In more detail, if <code class="reqn">out.p &gt; 0</code>, the bivariate regression coefficient functions (possibly different from the previously generated coefficient functions) generated from the coefficient space with <code class="reqn">b^*</code> (instead of <code class="reqn">b</code>), where <code class="reqn">b^*</code> is generated from a uniform distribution between 1 and 2, are used to generate the outlying observations. In addition, in this case, the following process is used to generate functional predictors: </p>
<p style="text-align: center;"><code class="reqn">
X_m^*(s) = \sum_{j=1}^5 \kappa_j^* v_j^*(s),</code>
</p>
<p> where <code class="reqn"> \kappa_j^* </code> is a vector generated from a Normal distribution with mean one and variance <code class="reqn">\sqrt{a} j^{-3/2}</code> and </p>
<p style="text-align: center;"><code class="reqn">v_j^*(s) = 2 \sin(j \pi s) - \cos(j \pi s).</code>
</p>
<p> All the functions are generated equally spaced point in the interval <code class="reqn">[0, 1]</code>.
</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>Y</code></td>
<td>
<p>An <code class="reqn">n.curve \times n.gp</code>-dimensional matrix containing the observations of simulated functional response variable.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>A list with length n.pred. The elements are the <code class="reqn">n.curve \times n.gp</code>-dimensional matrices containing the observations of simulated functional predictor variables.</p>
</td></tr>
<tr><td><code>f.coef</code></td>
<td>
<p>A list with length n.pred. Each element is a matrix and contains the generated bivariate regression coefficient function.</p>
</td></tr>
<tr><td><code>out.indx</code></td>
<td>
<p>A vector with length <code class="reqn">n.curve \times out.p</code> denoting the indices of outlying observations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>References</h3>

<p>E. Garcia-Portugues and J. Alvarez-Liebana J and G. Alvarez-Perez G and W. Gonzalez-Manteiga W (2021)  &quot;A goodness-of-fit test for the functional linear model with functional response&quot;,  <em>Scandinavian Journal of Statistics</em>, <b>48</b>(2), 502-528.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(fda)
library(fda.usc)
set.seed(2022)
sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101, out.p = 0.1)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
coeffs &lt;- sim.data$f.coef
out.indx &lt;- sim.data$out.indx
fY &lt;- fdata(Y, argvals = seq(0, 1, length.out = 101))
plot(fY[-out.indx,], lty = 1, ylab = "", xlab = "Grid point", 
     main = "Response", mgp = c(2, 0.5, 0), ylim = range(fY))
lines(fY[out.indx,], lty = 1, col = "black") # Outlying functions
</code></pre>

<hr>
<h2 id='generate.sf.data'>Generate functional data for the scalar-on-function regression model</h2><span id='topic+generate.sf.data'></span>

<h3>Description</h3>

<p>This function is used to simulate data for the scalar-on-function regression model </p>
<p style="text-align: center;"><code class="reqn">
Y = \sum_{m=1}^M \int X_m(s) \beta_m(s) ds + \epsilon,</code>
</p>
<p> where <code class="reqn">Y</code> denotes the scalar response, <code class="reqn">X_m(s)</code> denotes the <code class="reqn">m</code>-th functional predictor, <code class="reqn">\beta_m(s)</code> denotes the <code class="reqn">m</code>-th regression coefficient function, and <code class="reqn">\epsilon</code> is the error process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.sf.data(n, n.pred, n.gp, out.p = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate.sf.data_+3A_n">n</code></td>
<td>
<p>An integer, specifying the number of observations for each variable to be generated.</p>
</td></tr>
<tr><td><code id="generate.sf.data_+3A_n.pred">n.pred</code></td>
<td>
<p>An integer, denoting the number of functional predictors to be generated.</p>
</td></tr>
<tr><td><code id="generate.sf.data_+3A_n.gp">n.gp</code></td>
<td>
<p>An integer, denoting the number of grid points, i.e., a fine grid on the interval [0, 1].</p>
</td></tr>
<tr><td><code id="generate.sf.data_+3A_out.p">out.p</code></td>
<td>
<p>An integer between 0 and 1, denoting the outlier percentage in the generated data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the data generation process, first, the  functional predictors are simulated based on the following process: </p>
<p style="text-align: center;"><code class="reqn">
X_m(s) = \sum_{j=1}^5 \kappa_j v_j(s),</code>
</p>
<p> where <code class="reqn"> \kappa_j </code> is a vector generated from a Normal distribution with mean one and variance <code class="reqn">\sqrt{a} j^{-3/2}</code>, <code class="reqn">a</code> is a uniformly generated random number between 1 and 4, and </p>
<p style="text-align: center;"><code class="reqn">v_j(s) = \sin(j \pi s) - \cos(j \pi s).</code>
</p>
<p> The  regression coefficient functions are generated from a coefficient space that includes ten different functions such as: </p>
<p style="text-align: center;"><code class="reqn">b \sin(2 \pi s)</code>
</p>
<p> and </p>
<p style="text-align: center;"><code class="reqn">b \cos(2 \pi s),</code>
</p>
<p> where <code class="reqn">b</code> is generated from a uniform distribution between 1 and 3. The error process is generated from the standard normal distribution. If outliers are allowed in the generated data, i.e., <code class="reqn">out.p &gt; 0</code>, then, the randomply selected <code class="reqn">n \times out.p</code> of the data are generated in a different way from the aforementioned process. In more detail, if <code class="reqn">out.p &gt; 0</code>, the regression coefficient functions (possibly different from the previously generated coefficient functions) generated from the coefficient space with <code class="reqn">b^*</code> (instead of <code class="reqn">b</code>), where <code class="reqn">b^*</code> is generated from a uniform distribution between 3 and 5, are used to generate the outlying observations. In addition, in this case, the following process is used to generate functional predictors: </p>
<p style="text-align: center;"><code class="reqn">
X_m^*(s) = \sum_{j=1}^5 \kappa_j^* v_j^*(s),</code>
</p>
<p> where <code class="reqn"> \kappa_j^* </code> is a vector generated from a Normal distribution with mean one and variance <code class="reqn">\sqrt{a} j^{-1/2}</code> and </p>
<p style="text-align: center;"><code class="reqn">v_j^*(s) = 2 \sin(j \pi s) - \cos(j \pi s).</code>
</p>
<p> Moreover, the error process is generated from a normal distribution with mean 1 and variance 1. All the functional predictors are generated equally spaced point in the interval <code class="reqn">[0, 1]</code>.
</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>Y</code></td>
<td>
<p>An <code class="reqn">n \times 1</code>-dimensional matrix containing the observations of simulated scalar response variable.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>A list with length n.pred. The elements are the <code class="reqn">n \times n.gp</code>-dimensional matrices containing the observations of simulated functional predictor variables.</p>
</td></tr>
<tr><td><code>f.coef</code></td>
<td>
<p>A list with length n.pred. Each element is a vector and contains the generated regression coefficient function.</p>
</td></tr>
<tr><td><code>out.indx</code></td>
<td>
<p>A vector with length <code class="reqn">n \times out.p</code> denoting the indices of outlying observations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(fda.usc)
library(fda)
set.seed(2022)
sim.data &lt;- generate.sf.data(n = 400, n.pred = 5, n.gp = 101, out.p = 0.1)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
coeffs &lt;- sim.data$f.coef
out.indx &lt;- sim.data$out.indx
plot(Y[-out.indx,], type = "p", pch = 16, xlab = "Index", ylab = "",
main = "Response", ylim = range(Y))
points(out.indx, Y[out.indx,], type = "p", pch = 16, col = "blue") # Outliers
fX1 &lt;- fdata(X[[1]], argvals = seq(0, 1, length.out = 101))
plot(fX1[-out.indx,], lty = 1, ylab = "", xlab = "Grid point",
     main = expression(X[1](s)), mgp = c(2, 0.5, 0), ylim = range(fX1))
lines(fX1[out.indx,], lty = 1, col = "black") # Leverage points
</code></pre>

<hr>
<h2 id='get.ff.coeffs'>Get the estimated bivariate regression coefficient functions for function-on-function regression model</h2><span id='topic+get.ff.coeffs'></span>

<h3>Description</h3>

<p>This function is used to obtain the estimated bivariate regression coefficient functions <code class="reqn">\beta_m(s,t)</code> for function-on-function regression model (see the description in <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code> based on output object obtained from <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.ff.coeffs(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.ff.coeffs_+3A_object">object</code></td>
<td>
<p>The output object of <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the estimation of bivariate regression coefficient functions, the estimated functional principal components of 
response <code class="reqn">\hat{\Phi}(t)</code> and predictor <code class="reqn">\hat{\Psi}_m(s)</code> variables and the estimated regression parameter function obtained from the regression model between the principal component scores of response and predictor variables <code class="reqn">\hat{B}</code> 
are used, i.e., <code class="reqn">\hat{\beta}_m(s,t) = \hat{\Psi}_m^\top(s) \hat{B} \hat{\Phi}(t)</code>.</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>vars</code></td>
<td>
<p>A numeric vector specifying the indices of functional predictors used in the function-on-function regression model <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.
</p>
</td></tr>
<tr><td><code>gpY</code></td>
<td>
<p>A vector containing the grid points of the functional response <code class="reqn">Y(t)</code>.</p>
</td></tr>
<tr><td><code>gpX</code></td>
<td>
<p>A list with length <code class="reqn">M</code>. The <code class="reqn">m</code>-th element of gpX is a vector containing the grid points of 
the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>A list with length <code class="reqn">M</code>. The <code class="reqn">m</code>-th element of coefficients is a matrix of the estimated values of the coefficient function for the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gpY = seq(0, 1, length.out = 101) # grid points of Y
gpX &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs
model.fit &lt;- rob.ff.reg(Y, X, model = "full", emodel = "classical", 
                        gpY = gpY, gpX = gpX)
coefs &lt;- get.ff.coeffs(model.fit)
</code></pre>

<hr>
<h2 id='get.sf.coeffs'>Get the estimated regression coefficient functions for scalar-on-function regression model</h2><span id='topic+get.sf.coeffs'></span>

<h3>Description</h3>

<p>This function is used to obtain the estimated regression coefficient functions <code class="reqn">\beta_m(s)</code> and the estimated regression coefficients <code class="reqn">\gamma_r</code> (if <code class="reqn">X.scl \neq NULL</code>) for scalar-on-function regression model (see the description in <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code> based on output object obtained from <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.sf.coeffs(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.sf.coeffs_+3A_object">object</code></td>
<td>
<p>The output object of <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the estimation of regression coefficient functions, the estimated functional principal components of predictor <code class="reqn">\hat{\Psi}_m(s), 1\le m\le M</code> variables and the estimated regression parameter function obtained from the regression model of scalar response on the principal component scores of the functional predictor variables <code class="reqn">\hat{B}</code> are used, i.e., <code class="reqn">\hat{\beta}_m(s) = \hat{\Psi}_m^\top(s) \hat{B}</code>.</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>gp</code></td>
<td>
<p>A list with length <code class="reqn">M</code>. The <code class="reqn">m</code>-th element of gp is a vector containing the grid points of  the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>A list with length <code class="reqn">M</code>. The <code class="reqn">m</code>-th element of coefficients is a vector of the estimated values of the coefficient function for the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code>scl.coefficients</code></td>
<td>
<p>A vector consisting of the estimated coefficients of the scalar predictor <code class="reqn">X.scl</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.sf.data(n = 400, n.pred = 5, n.gp = 101)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gp &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs
model.fit &lt;- rob.sf.reg(Y, X, emodel = "classical", gp = gp)
coefs &lt;- get.sf.coeffs(model.fit)
</code></pre>

<hr>
<h2 id='getPCA'>Functional principal component analysis</h2><span id='topic+getPCA'></span>

<h3>Description</h3>

<p>This function is used to perform functional principal component analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPCA(data, nbasis, ncomp, gp, emodel = c("classical", "robust"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPCA_+3A_data">data</code></td>
<td>
<p>An <code class="reqn">n \times p</code>-dimensional data matrix for functional data <code class="reqn">X(s)</code>, where <code class="reqn">n</code> denotes the sample size
and <code class="reqn">p</code> denotes the number of grid points for <code class="reqn">X(s)</code>.</p>
</td></tr>
<tr><td><code id="getPCA_+3A_nbasis">nbasis</code></td>
<td>
<p>An integer specifying the number of B-spline basis expansion functions used to approximate the functional principal components.</p>
</td></tr>
<tr><td><code id="getPCA_+3A_ncomp">ncomp</code></td>
<td>
<p>An integer specifying the number of functional principal components to be computed.</p>
</td></tr>
<tr><td><code id="getPCA_+3A_gp">gp</code></td>
<td>
<p>A vector containing the grid points for the functional data for <code class="reqn">X(s)</code>.</p>
</td></tr>
<tr><td><code id="getPCA_+3A_emodel">emodel</code></td>
<td>
<p>Method to be used for functional principal component decomposition. Possibilities are &quot;classical&quot; and &quot;robust&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functional principal decomposition of a functional data <code class="reqn">X(s)</code> is given by </p>
<p style="text-align: center;"><code class="reqn">X(s) = \bar{X}(s) + \sum_{k=1}^K \xi_k \psi_k(s),</code>
</p>
<p> where <code class="reqn">\bar{X}(s)</code> is the mean function, <code class="reqn">\psi_k(s)</code> is the <code class="reqn">k</code>-th weight function, and <code class="reqn">\xi_k</code> is the corresponding principal component score which is given by </p>
<p style="text-align: center;"><code class="reqn">\xi_k = \int (X(s) - \bar{X}(s)) \psi_k(s) ds.</code>
</p>
<p> When computing the estimated functional principal components, first, the functional data is expressed by a set of B-spline basis expansion. Then, the functional principal components are equal to the principal components extracted from the matrix <code class="reqn">D \varphi^{1/2}</code>, where <code class="reqn">D</code> is the matrix of basis expansion coefficients and <code class="reqn">\varphi</code> is the inner product matrix of the basis functions, i.e., <code class="reqn">\varphi = \int \varphi(s) \varphi^\top(s) ds</code>. Finally, the <code class="reqn">k</code>-th weight function is given by <code class="reqn">\psi_k(s) = \varphi^{-1/2} a_k</code>, where <code class="reqn">a_k</code> is the <code class="reqn">k</code>-th eigenvector of the sample covariance matrix of <code class="reqn">D \varphi^{1/2}</code>.
</p>
<p>If <code>emodel = "classical"</code>, then, the standard functional principal component decomposition is used as given by
Ramsay and Dalzell (1991).
</p>
<p>If <code>emodel = "robust"</code>, then, the robust principal component algorithm of Hubert, Rousseeuw and Verboven (2002) is used.
</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>PCAcoef</code></td>
<td>
<p>A functional data object for the eigenfunctions.</p>
</td></tr>
<tr><td><code>PCAscore</code></td>
<td>
<p>A matrix of principal component scores.</p>
</td></tr>
<tr><td><code>meanScore</code></td>
<td>
<p>A functional data object for the mean function.</p>
</td></tr>
<tr><td><code>bs_basis</code></td>
<td>
<p>A functional data object for B-spline basis expansion.</p>
</td></tr>
<tr><td><code>evalbase</code></td>
<td>
<p>A matrix of the B-spline basis expansion functions.</p>
</td></tr>
<tr><td><code>ncomp</code></td>
<td>
<p>An integer denoting the computed number of functional principal components. If the input &ldquo;<code>ncomp</code>&rdquo; is NULL, then, the output <code>ncomp</code> equals to the number of functional principal components whose usage results in at least 95% explained variation.</p>
</td></tr>
<tr><td><code>gp</code></td>
<td>
<p>A vector containing the grid points for the functional data for <code class="reqn">X(s)</code>.</p>
</td></tr>
<tr><td><code>emodel</code></td>
<td>
<p>A character vector denoting the method used for functional principal component decomposition.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>References</h3>

<p>J. O. Ramsay and C. J. Dalzell (1991) &quot;Some tools for functional data analysis (with discussion)&quot;, <em>Journal of the Royal Statistical Society: Series B</em>, <b>53</b>(3), 539-572.
</p>
<p>M. Hubert and P. J. Rousseeuw and S. Verboven (2002) &quot;A fast robust method for principal components with applications to chemometrics&quot;, <em>Chemometrics and Intelligent Laboratory Systems</em>, <b>60</b>(1-2), 101-111.
</p>
<p>P. Filzmoser and H. Fritz and K Kalcher (2021) pcaPP: Robust PCA by Projection Pursuit, R package version 1.9-74, URL: https://cran.r-project.org/web/packages/pcaPP/index.html.
</p>
<p>J. L. Bali and G. Boente and D. E. Tyler and J.-L. Wang (2011) &quot;Robust functional principal components: A projection-pursuit approach&quot;, <em>The Annals of Statistics</em>, <b>39</b>(6), 2852-2882.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101)
Y &lt;- sim.data$Y
gpY &lt;- seq(0, 1, length.out = 101) # grid points
rob.fpca &lt;- getPCA(data = Y, nbasis = 20, ncomp = 4, gp = gpY, emodel = "robust")
</code></pre>

<hr>
<h2 id='getPCA.test'>Get the functional principal component scores for a given test sample</h2><span id='topic+getPCA.test'></span>

<h3>Description</h3>

<p>This function is used to compute the functional principal component scores of a test sample based on outputs obtained from <code><a href="#topic+getPCA">getPCA</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPCA.test(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPCA.test_+3A_object">object</code></td>
<td>
<p>An output object of <code><a href="#topic+getPCA">getPCA</a></code>.</p>
</td></tr>
<tr><td><code id="getPCA.test_+3A_data">data</code></td>
<td>
<p>An <code class="reqn">n \times p</code>-dimensional data matrix for functional data <code class="reqn">X(s)</code> (test sample), where <code class="reqn">n</code> denotes the sample size and <code class="reqn">p</code> denotes the number of grid points for <code class="reqn">X(s)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+getPCA">getPCA</a></code> for details.
</p>


<h3>Value</h3>

<p>A matrix of principal component scores for the functional data.
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101)
Y &lt;- sim.data$Y
Y.train &lt;- Y[1:100,]
Y.test &lt;- Y[101:200,]
gpY = seq(0, 1, length.out = 101) # grid points
rob.fpca &lt;- getPCA(data = Y.train, nbasis = 20, ncomp = 4,
gp = gpY, emodel = "robust")
rob.fpca.test &lt;- getPCA.test(object = rob.fpca, data = Y.test)
</code></pre>

<hr>
<h2 id='MaryRiverFlow'>Hourly River Flow Measurements in the Mery River</h2><span id='topic+MaryRiverFlow'></span>

<h3>Description</h3>

<p>Hourly river flow measurements obtained from January 2009 to December 2014 (6 years in total) in the Mery River, Australia.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MaryRiverFlow)
</code></pre>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MaryRiverFlow)
# Plot
library(fda.usc)
fflow &lt;- fdata(MaryRiverFlow, argvals = 1:24)
plot(fflow, lty = 1, ylab = "", xlab = "Hour",
main = "", mgp = c(2, 0.5, 0), ylim = range(fflow))
</code></pre>

<hr>
<h2 id='plot_ff_coeffs'>Image plot of bivariate regression coefficient functions of a function-on-function regression model</h2><span id='topic+plot_ff_coeffs'></span>

<h3>Description</h3>

<p>This function is used to obtain image plots of bivariate regression coefficient functions of a function-on-function regression model based on output object obtained from <code><a href="#topic+get.ff.coeffs">get.ff.coeffs</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_ff_coeffs(object, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_ff_coeffs_+3A_object">object</code></td>
<td>
<p>The output object of <code><a href="#topic+get.ff.coeffs">get.ff.coeffs</a></code>.</p>
</td></tr>
<tr><td><code id="plot_ff_coeffs_+3A_b">b</code></td>
<td>
<p>An integer value indicating which regression parameter function to be plotted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>References</h3>

<p>D. Nychka and R. Furrer and J. Paige and S. Sain (2021) fields: Tools for spatial data. R package version 14.1,
URL: https://github.com/dnychka/fieldsRPackage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gpY = seq(0, 1, length.out = 101) # grid points of Y
gpX &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs
model.fit &lt;- rob.ff.reg(Y, X, model = "full", emodel = "classical", 
                        gpY = gpY, gpX = gpX)
coefs &lt;- get.ff.coeffs(model.fit)
plot_ff_coeffs(object = coefs, b = 1)
</code></pre>

<hr>
<h2 id='plot_sf_coeffs'>Plot of regression coefficient functions of a scalar-on-function regression model</h2><span id='topic+plot_sf_coeffs'></span>

<h3>Description</h3>

<p>This function is used to obtain the plots of regression coefficient functions of a scalar-on-function regression model based on output object obtained from <code><a href="#topic+get.sf.coeffs">get.sf.coeffs</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_sf_coeffs(object, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_sf_coeffs_+3A_object">object</code></td>
<td>
<p>The output object of <code><a href="#topic+get.sf.coeffs">get.sf.coeffs</a></code>.</p>
</td></tr>
<tr><td><code id="plot_sf_coeffs_+3A_b">b</code></td>
<td>
<p>An integer value indicating which regression parameter function to be plotted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.sf.data(n = 400, n.pred = 5, n.gp = 101)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gp &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs
model.fit &lt;- rob.sf.reg(Y, X, emodel = "classical", gp = gp)
coefs &lt;- get.sf.coeffs(model.fit)
plot_sf_coeffs(object = coefs, b = 1)
</code></pre>

<hr>
<h2 id='predict_ff_regression'>Prediction for a function-on-function regression model</h2><span id='topic+predict_ff_regression'></span>

<h3>Description</h3>

<p>This function is used to make prediction for a new set of functional predictors based upon a fitted function-on-function regression model in the output of <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_ff_regression(object, Xnew)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_ff_regression_+3A_object">object</code></td>
<td>
<p>An output object obtained from <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.</p>
</td></tr>
<tr><td><code id="predict_ff_regression_+3A_xnew">Xnew</code></td>
<td>
<p>A list of matrices consisting of the new observations of functional predictors. The argument <code>Xnew</code> must have the same length and the same structure as the input <code>X</code> of <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code class="reqn">n_{test} \times p</code>-dimensional matrix of predicted functions of the response variable for the given set of new functional predictors <code>Xnew</code>. Here, <code class="reqn">n_{test}</code>, the number of rows of the matrix of predicted values, equals to the number of rows of <code>Xnew</code>, and <code class="reqn">p</code> equals to the number of columns of <code>Y</code>, the input in the <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101, out.p = 0.1)
out.indx &lt;- sim.data$out.indx
Y &lt;- sim.data$Y
X &lt;- sim.data$X
indx.test &lt;- sample(c(1:200)[-out.indx], 60)
indx.train &lt;- c(1:200)[-indx.test]
Y.train &lt;- Y[indx.train,]
Y.test &lt;- Y[indx.test,]
X.train &lt;- X.test &lt;- list()
for(i in 1:5){
  X.train[[i]] &lt;- X[[i]][indx.train,]
  X.test[[i]] &lt;- X[[i]][indx.test,]
}
gpY = seq(0, 1, length.out = 101) # grid points of Y
gpX &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs

model.MM &lt;- rob.ff.reg(Y = Y.train, X = X.train, model = "full", emodel = "robust",
                       fmodel = "MM", gpY = gpY, gpX = gpX)
pred.MM &lt;- predict_ff_regression(object = model.MM, Xnew = X.test)
round(mean((Y.test - pred.MM)^2), 4)        # 0.5925 (MM method)
</code></pre>

<hr>
<h2 id='predict_sf_regression'>Prediction for a scalar-on-function regression model</h2><span id='topic+predict_sf_regression'></span>

<h3>Description</h3>

<p>This function is used to make prediction for a new set of functional and scalar (if any) predictors based upon a fitted scalar-on-function regression model in the output of <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_sf_regression(object, Xnew, Xnew.scl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_sf_regression_+3A_object">object</code></td>
<td>
<p>An output object obtained from <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code>.</p>
</td></tr>
<tr><td><code id="predict_sf_regression_+3A_xnew">Xnew</code></td>
<td>
<p>A list of matrices consisting of the new observations of functional predictors. The argument <code>Xnew</code> must have the same length and the same structure as the input <code>X</code> of <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code>.</p>
</td></tr>
<tr><td><code id="predict_sf_regression_+3A_xnew.scl">Xnew.scl</code></td>
<td>
<p>A matrix consisting of the new observations of scalar predictors. The argument <code>Xnew.scl</code> must have the same length and the same structure as the input <code>X.scl</code> of <code><a href="#topic+rob.sf.reg">rob.sf.reg</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code class="reqn">n_{test} \times 1</code>-dimensional matrix of predicted values of the scalar response variable for the given set of new functional and scalar (if any) predictors <code>Xnew</code> and <code>Xnew.scl</code>, respectively. Here, <code class="reqn">n_{test}</code>, the number of rows of the matrix of predicted values, equals to the number of rows of <code>Xnew</code> and and <code>Xnew.scl</code> (if any).
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
sim.data &lt;- generate.sf.data(n = 400, n.pred = 5, n.gp = 101, out.p = 0.1)
out.indx &lt;- sim.data$out.indx
indx.test &lt;- sample(c(1:400)[-out.indx], 120)
indx.train &lt;- c(1:400)[-indx.test]
Y &lt;- sim.data$Y
X &lt;- sim.data$X
Y.train &lt;- Y[indx.train,]
Y.test &lt;- Y[indx.test,]
X.train &lt;- X.test &lt;- list()
for(i in 1:5){
  X.train[[i]] &lt;- X[[i]][indx.train,]
  X.test[[i]] &lt;- X[[i]][indx.test,]
}
gp &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs

model.tau &lt;- rob.sf.reg(Y.train, X.train, emodel = "robust", fmodel = "tau", gp = gp)
pred.tau &lt;- predict_sf_regression(object = model.tau, Xnew = X.test)
round(mean((Y.test - pred.tau)^2), 4)        # 1.868 (tau method)
</code></pre>

<hr>
<h2 id='rob.ff.reg'>Robust function-on-function regression</h2><span id='topic+rob.ff.reg'></span>

<h3>Description</h3>

<p>This function is used to perform both classical and robust function-on-function regression model </p>
<p style="text-align: center;"><code class="reqn">
Y(t) = \sum_{m=1}^M \int X_m(s) \beta_m(s,t) ds + \epsilon(t),</code>
</p>
<p> where <code class="reqn">Y(t)</code> denotes the functional response, <code class="reqn">X_m(s)</code> denotes the <code class="reqn">m</code>-th functional predictor, <code class="reqn">\beta_m(s,t)</code> denotes the <code class="reqn">m</code>-th bivariate regression coefficient function, and <code class="reqn">\epsilon(t)</code> is the error function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rob.ff.reg(Y, X, model = c("full", "selected"), emodel = c("classical", "robust"),
 fmodel = c("MCD", "MLTS", "MM", "S", "tau"), nbasisY = NULL, nbasisX = NULL,
 gpY = NULL, gpX = NULL, ncompY = NULL, ncompX = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rob.ff.reg_+3A_y">Y</code></td>
<td>
<p>An <code class="reqn">n \times p</code>-dimensional matrix containing the observations of functional response <code class="reqn">Y(t)</code>, where <code class="reqn">n</code> is the sample size and <code class="reqn">p</code> denotes the number of grid points for <code class="reqn">Y(t)</code>.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_x">X</code></td>
<td>
<p>A list consisting of <code class="reqn">M</code> functional predictors <code class="reqn">X_m(s), 1\le m\le M</code>. Each element of <code>X</code> is an <code class="reqn">n \times p_m</code>-dimensional matrix containing the observations of <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>, where <code class="reqn">n</code> is the sample size and <code class="reqn">p_m</code> denotes the number of grid points for <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_model">model</code></td>
<td>
<p>Model to be fitted. Possibilities are &quot;full&quot; and &quot;selected&quot;.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_emodel">emodel</code></td>
<td>
<p>Method to be used for functional principal component decomposition. Possibilities are &quot;classical&quot;&quot; and &quot;robust&quot;.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_fmodel">fmodel</code></td>
<td>
<p>Fitting model used to estimate the function-on-function regression model. Possibilities are &quot;MCD&quot;, &quot;MLTS&quot;, &quot;MM&quot;, &quot;S&quot;, and &quot;tau&quot;.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_nbasisy">nbasisY</code></td>
<td>
<p>An integer value specifying the number of B-spline basis expansion functions to be used to approximate the functional principal components for the response variable <code class="reqn">Y(t)</code>. If <code>NULL</code>, then, <code class="reqn">min(20, p/4)</code> number of B-spline basis expansion functions are used.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_nbasisx">nbasisX</code></td>
<td>
<p>A vector with length <code class="reqn">M</code>. Its <code class="reqn">m</code>-th value denotes the number of B-spline basis expansion functions to be used to approximate the functional principal components for the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>. If <code>NULL</code>, then, <code class="reqn">min(20, p_m/4)</code> number of B-spline basis expansion functions are used for each functional predictor, where <code class="reqn">p_m</code> denotes the number of grid points for <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_gpy">gpY</code></td>
<td>
<p>A vector containing the grid points of the functional response <code class="reqn">Y(t)</code>. If <code>NULL</code>, then <code class="reqn">p</code>
equally spaced time points in te interval [0, 1] are used.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_gpx">gpX</code></td>
<td>
<p>A list with length <code class="reqn">M</code>. The <code class="reqn">m</code>-th element of <code>gpX</code> is a vector containing the grid points of
the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>. If <code>NULL</code>, then, <code class="reqn">p_m</code> equally spaced time points in te interval
[0, 1] are used for the <code class="reqn">m</code>-th functional predictor.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_ncompy">ncompY</code></td>
<td>
<p>An integer specifying the number of functional principal components to be computed for the functional response <code class="reqn">Y(t)</code>. If <code>NULL</code>, then, the number whose usage results in at least 95% explained variation is used as the number of principal components.</p>
</td></tr>
<tr><td><code id="rob.ff.reg_+3A_ncompx">ncompX</code></td>
<td>
<p>A vector with length <code class="reqn">M</code>. Its <code class="reqn">m</code>-th value denotes the number of functional principal components to be computed for the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>. If <code>NULL</code>, then, for each functional predictor, the number whose usage results in at least 95% explained variation is used as the number of principal components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When performing a function-on-function regression model based on the functional principal component analysis, first, both the functional response <code class="reqn">Y(t)</code> and functional predictors <code class="reqn">X_m(s), 1\le m\le M</code> are decomposed by the functional principal component analysis method: </p>
<p style="text-align: center;"><code class="reqn">Y(t) = \bar{Y}(t) + \sum_{k=1}^K \nu_k \phi_k(t),</code>
</p>
 <p style="text-align: center;"><code class="reqn">X_m(s) = \bar{X}_m(s) + \sum_{l=1}^{K_m} \xi_{ml} \psi_{ml}(s),</code>
</p>
<p> where <code class="reqn">\bar{Y}(t)</code> and <code class="reqn">\bar{X}_m(s)</code> are the mean functions, <code class="reqn">\phi_k(t)</code> and <code class="reqn">\psi_{ml}(s)</code> are the weight functions, and <code class="reqn">\nu_k = \int (Y(t) - \bar{Y}(t)) \phi_k(t)</code> and <code class="reqn">\xi_{ml} = \int (X_m(s) - \bar{X}_m(s)) \psi_{ml}(s)</code> are the principal component scores for the functional response and <code class="reqn">m</code>-th functional predictor, respectively. Assume that the <code class="reqn">m</code>-th bivariate regression coefficient function admits the expansion </p>
<p style="text-align: center;"><code class="reqn">\beta_m(s,t) = \sum_{k=1}^K \sum_{l=1}^{K_m} b_{mkl} \phi_k(t) \psi_{ml}(s),</code>
</p>
<p> where <code class="reqn">b_{mkl} = \int \int \beta_m(s,t) \phi_k(t) \psi_{ml}(s) dt ds</code>. Then, the following multiple regression model is obtained for the functional response: </p>
<p style="text-align: center;"><code class="reqn">\hat{Y}(t) = \bar{Y}(s) + \sum_{k=1}^K ( \sum_{m=1}^M \sum_{l=1}^{K_m} b_{mkl} \xi_{ml} ) \phi_k(t).</code>
</p>

<p>If <code>model = "full"</code>, then, all the functional predictor variables are used in the model.
</p>
<p>If <code>model = "selected"</code>, then, only the significant functional predictor variables determined by the forward variable selection procedure of Beyaztas and Shang (2021) are used in the model.
</p>
<p>If <code>emodel = "classical"</code>, then, the least-squares method is used to estimate the function-on-function regression model.
</p>
<p>If <code>emodel = "robust"</code>, then, the robust functional principal component analysis of Bali et al. (2011) along with the method specified in <code>fmodel</code> is used to estimate the  function-on-function regression model.
</p>
<p>If <code>fmodel = "MCD"</code>, then, the minimum covariance determinant estimator of Rousseeuw et al. (2004) is used to estimate the function-on-function regression model.
</p>
<p>If <code>fmodel = "MLTS"</code>, then, the multivariate least trimmed squares estimator Agullo et al. (2008) is used to estimate the function-on-function regression model.
</p>
<p>If <code>fmodel = "MM"</code>, then, the MM estimator of Kudraszow and Maronna (2011) is used to estimate the function-on-function regression model.
</p>
<p>If <code>fmodel = "S"</code>, then, the S estimator of Bilodeau and Duchesne (2000) is used to estimate the function-on-function regression model.
</p>
<p>If <code>fmodel = "tau"</code>, then, the tau estimator of Ben et al. (2006) is used to estimate the function-on-function regression model.
</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>A list of matrices including the original functional response and functional predictors.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>An <code class="reqn">n \times p</code>-dimensional matrix containing the fitted values of the functional response.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>An <code class="reqn">n \times p</code>-dimensional matrix containing the residual functions.</p>
</td></tr>
<tr><td><code>fpca.results</code></td>
<td>
<p>A list object containing the functional principal component analysis results of the functional predictor and functional predictors variables.</p>
</td></tr>
<tr><td><code>model.details</code></td>
<td>
<p>A list object containing model details, such as number of basis functions, number of principal components, and grid points used for each functional variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>References</h3>

<p>J. Agullo and C. Croux and S. V. Aelst (2008), &quot;The multivariate least-trimmed squares estimator&quot;, <em>Journal of Multivariate Analysis</em>, <b>99</b>(3), 311-338.
</p>
<p>M. G. Ben and E. Martinez and V. J. Yohai (2006), &quot;Robust estimation for the multivariate linear model based on a <code class="reqn">\tau</code> scale&quot;, <em>Journal of Multivariate Analysis</em>, <b>97</b>(7), 1600-1622.
</p>
<p>U. Beyaztas and H. L. Shang (2021), &quot;A partial least squares approach for function-on-function interaction regression&quot;, <em>Computational Statistics</em>, <b>36</b>(2), 911-939.
</p>
<p>J. L. Bali and G. Boente and D. E. Tyler and J. -L.Wang (2011), &quot;Robust functional principal components: A projection-pursuit approach&quot;, <em>The Annals of Statistics</em>, <b>39</b>(6), 2852-2882.
</p>
<p>M. Bilodeau and P. Duchesne (2000), &quot;Robust estimation of the SUR model&quot;, <em>The Canadian Journal of Statistics</em>, <b>28</b>(2), 277-288.
</p>
<p>N. L. Kudraszow and R. A. Moronna (2011), &quot;Estimates of MM type for the multivariate linear model&quot;, <em>Journal of Multivariate Analysis</em>, <b>102</b>(9), 1280-1292.
</p>
<p>P. J. Rousseeuw and K. V. Driessen and S. V. Aelst and J. Agullo (2004), &quot;Robust multivariate regression&quot;, <em>Technometrics</em>, <b>46</b>(3), 293-305.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gpY &lt;- seq(0, 1, length.out = 101) # grid points of Y
gpX &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs
model.MM &lt;- rob.ff.reg(Y = Y, X = X, model = "full", emodel = "robust",
                       fmodel = "MM", gpY = gpY, gpX = gpX)
</code></pre>

<hr>
<h2 id='rob.out.detect'>Outlier detection in the functional response</h2><span id='topic+rob.out.detect'></span>

<h3>Description</h3>

<p>This function is used to detect outliers in the functional response based on a fitted function-on-function regression model in the output of <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rob.out.detect(object, alpha = 0.01, B = 200, fplot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rob.out.detect_+3A_object">object</code></td>
<td>
<p>An output object obtained from <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code>.</p>
</td></tr>
<tr><td><code id="rob.out.detect_+3A_alpha">alpha</code></td>
<td>
<p>Percentile of the distribution of the functional depth. The default value is 0.01.</p>
</td></tr>
<tr><td><code id="rob.out.detect_+3A_b">B</code></td>
<td>
<p>The number of bootstrap samples. The default value is 200.</p>
</td></tr>
<tr><td><code id="rob.out.detect_+3A_fplot">fplot</code></td>
<td>
<p>If <code>TRUE</code>, then the outlying points flagged by the method is plotted along with the values of functional response <code class="reqn">Y(t)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functional depth-based outlier detection method of Febrero-Bande et al. (2008) together with the h-modal depth proposed by Cuaves et al. (2007) is applied to the estimated residual functions obtained from <code><a href="#topic+rob.ff.reg">rob.ff.reg</a></code> to determine the outliers in the response variable. This method makes it possible to determine both magnitude and shape outliers in the response variable Hullait et al., (2021).
</p>


<h3>Value</h3>

<p>A vector containing the indices of outlying observations in the functional response.
</p>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang
</p>


<h3>References</h3>

<p>M. Febrero-Bande and P. Galeano and W. Gonzalez-Mantelga (2008), &quot;Outlier detection in functional data by depth measures, with application to identify abnormal NOx levels&quot;, <em>Environmetrics</em>, <b>19</b>(4), 331-345.
</p>
<p>A. Cuaves and M. Febrero and R Fraiman (2007), &quot;Robust estimation and classification for functional data via projection-based depth notions&quot;, <em>Computational Statistics</em>, <b>22</b>(3), 481-496.
</p>
<p>H. Hullait and D. S. Leslie and N. G. Pavlidis and S. King (2021), &quot;Robust function-on-function regression&quot;, <em>Technometrics</em>, <b>63</b>(3), 396-409.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- generate.ff.data(n.pred = 5, n.curve = 200, n.gp = 101, out.p = 0.1)
out.indx &lt;- sim.data$out.indx
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gpY = seq(0, 1, length.out = 101) # grid points of Y
gpX &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs

model.MM &lt;- rob.ff.reg(Y = Y, X = X, model = "full", emodel = "robust", fmodel = "MM", 
                       gpY = gpY, gpX = gpX)
rob.out.detect(object = model.MM, fplot = TRUE)
sort(out.indx)

</code></pre>

<hr>
<h2 id='rob.sf.reg'>Robust scalar-on-function regression</h2><span id='topic+rob.sf.reg'></span>

<h3>Description</h3>

<p>This function is used to perform both classical and robust scalar-on-function regression model </p>
<p style="text-align: center;"><code class="reqn">
Y = \sum_{m=1}^M \int X_m(s) \beta_m(s) ds + X.scl \gamma + \epsilon,</code>
</p>
<p> where <code class="reqn">Y</code> denotes the scalar response, <code class="reqn">X_m(s)</code> denotes the <code class="reqn">m</code>-th functional predictor, <code class="reqn">\beta_m(s)</code> denotes the <code class="reqn">m</code>-th regression coefficient function, <code class="reqn">X.scl</code> denotes the matrix of scalar predictors, <code class="reqn">\gamma</code> denotes the vector of coefficients for the scalar predictors' matrix, and <code class="reqn">\epsilon</code> is the error function, which is assumed to follow standard normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rob.sf.reg(Y, X, X.scl = NULL, emodel = c("classical", "robust"),
fmodel = c("LTS", "MM", "S", "tau"), nbasis = NULL, gp = NULL, ncomp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rob.sf.reg_+3A_y">Y</code></td>
<td>
<p>An <code class="reqn">n \times 1</code>-dimensional matrix containing the observations of scalar response <code class="reqn">Y</code>, where <code class="reqn">n</code> denotes the sample size.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_x">X</code></td>
<td>
<p>A list consisting of <code class="reqn">M</code> functional predictors <code class="reqn">X_m(s), 1\le m\le M</code>. Each element of <code>X</code> is an <code class="reqn">n \times p_m</code>-dimensional matrix containing the observations of <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>, where <code class="reqn">n</code> is the sample size and <code class="reqn">p_m</code> denotes the number of grid points for <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_x.scl">X.scl</code></td>
<td>
<p>An <code class="reqn">n \times R</code>-dimensional matrix consisting of scalar predictors <code class="reqn">X_r, 1\le r\le R</code>.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_emodel">emodel</code></td>
<td>
<p>Method to be used for functional principal component decomposition. Possibilities are &quot;classical&quot;&quot; and &quot;robust&quot;.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_fmodel">fmodel</code></td>
<td>
<p>Fitting model used to estimate the function-on-function regression model. Possibilities are &quot;LTS&quot;, &quot;MM&quot;, &quot;S&quot;, and &quot;tau&quot;.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_nbasis">nbasis</code></td>
<td>
<p>A vector with length <code class="reqn">M</code>. Its <code class="reqn">m</code>-th value denotes the number of B-spline basis expansion functions to be used to approximate the functional principal components for the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>. If <code>NULL</code>, then, <code class="reqn">min(20, p_m/4)</code> number of B-spline basis expansion functions are used for each functional predictor, where <code class="reqn">p_m</code> denotes the number of grid points for <code class="reqn">X_m(s)</code>.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_gp">gp</code></td>
<td>
<p>A list with length <code class="reqn">M</code>. The <code class="reqn">m</code>-th element of <code>gp</code> is a vector containing the grid points of the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>. If <code>NULL</code>, then, <code class="reqn">p_m</code> equally spaced time points in the interval [0, 1] are used for the <code class="reqn">m</code>-th functional predictor.</p>
</td></tr>
<tr><td><code id="rob.sf.reg_+3A_ncomp">ncomp</code></td>
<td>
<p>A vector with length <code class="reqn">M</code>. Its <code class="reqn">m</code>-th value denotes the number of functional principal components to be computed for the <code class="reqn">m</code>-th functional predictor <code class="reqn">X_m(s)</code>. If <code>NULL</code>, then, for each functional predictor, the number whose usage results in at least 95% explained variation is used as the number of principal components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When performing a scalar-on-function regression model based on the functional principal component analysis, first, the functional predictors <code class="reqn">X_m(s), 1\le m\le M</code> are decomposed by the functional principal component analysis method: </p>
<p style="text-align: center;"><code class="reqn">X_m(s) = \bar{X}_m(s) + \sum_{l=1}^{K_m} \xi_{ml} \psi_{ml}(s),</code>
</p>
<p> where <code class="reqn">\bar{X}_m(s)</code> is the mean function, <code class="reqn">\psi_{ml}(s)</code> is the weight function, and <code class="reqn">\xi_{ml} = \int (X_m(s) - \bar{X}_m(s)) \psi_{ml}(s)</code> is the principal component score for the <code class="reqn">m</code>-th functional predictor. Assume that the <code class="reqn">m</code>-th regression coefficient function admits the expansion </p>
<p style="text-align: center;"><code class="reqn">\beta_m(s) = \sum_{l=1}^{K_m} b_{ml} \psi_{ml}(s),</code>
</p>
<p> where <code class="reqn">b_{ml} = \int \beta_m(s) \psi_{m}(s)  ds</code>. Then, the following multiple regression model is obtained for the scalar response: </p>
<p style="text-align: center;"><code class="reqn">\hat{Y} = \bar{Y} + \sum_{m=1}^M \sum_{l=1}^{K_m} b_{ml} \xi_{ml} + X.scl \gamma.</code>
</p>

<p>If <code>emodel = "classical"</code>, then, the least-squares method is used to estimate the scalar-on-function regression model.
</p>
<p>If <code>emodel = "robust"</code>, then, the robust functional principal component analysis of Bali et al. (2011) along with the method specified in <code>fmodel</code> is used to estimate the  scalar-on-function regression model.
</p>
<p>If <code>fmodel = "LTS"</code>, then, the least trimmed squares robust regression of Rousseeuw (1984) is used to estimate the scalar-on-function regression model.
</p>
<p>If <code>fmodel = "MM"</code>, then, the MM-type regression estimator described in Yohai (1987) and Koller and Stahel (2011) is used to estimate the scalar-on-function regression model.
</p>
<p>If <code>fmodel = "S"</code>, then, the S estimator is used to estimate the scalar-on-function regression model.
</p>
<p>If <code>fmodel = "tau"</code>, then, the tau estimator proposed by Salibian-Barrera et al. (2008) is used to estimate the scalar-on-function regression model.
</p>


<h3>Value</h3>

<p>A list object with the following components:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>A list of matrices including the original scalar response and both the scalar and functional predictors.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>An <code class="reqn">n \times 1</code>-dimensional matrix containing the fitted values of the scalar response.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>An <code class="reqn">n \times 1</code>-dimensional matrix containing the residuals.</p>
</td></tr>
<tr><td><code>fpca.results</code></td>
<td>
<p>A list object containing the functional principal component analysis results of the functional predictors variables.</p>
</td></tr>
<tr><td><code>model.details</code></td>
<td>
<p>A list object containing model details, such as number of basis functions, number of principal components, and grid points used for each functional predictor variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ufuk Beyaztas and Han Lin Shang</p>


<h3>References</h3>

<p>J. L. Bali and G. Boente and D. E. Tyler and J. -L.Wang (2011), &quot;Robust functional principal components: A projection-pursuit approach&quot;, <em>The Annals of Statistics</em>, <b>39</b>(6), 2852-2882.
</p>
<p>P. J. Rousseeuw (1984), &quot;Least median of squares regression&quot;, <em>Journal of the American Statistical Association</em>, <b>79</b>(388), 871-881.
</p>
<p>P. J. Rousseeuw and K. van Driessen (1999) &quot;A fast algorithm for the minimum covariance determinant estimator&quot;, <em>Technometrics</em>, <b>41</b>(3), 212-223.
</p>
<p>V. J. Yohai (1987), &quot;High breakdown-point and high efficiency estimates for regression&quot;, <em>The Annals of Statistics</em>, <b>15</b>(2), 642-65.
</p>
<p>M. Koller and W. A. Stahel (2011), &quot;Sharpening Wald-type inference in robust regression for small samples&quot;, <em>Computational Statistics &amp; Data Analysis</em>, <b>55</b>(8), 2504-2515.
</p>
<p>M. Salibian-Barrera and G. Willems and R. Zamar (2008), &quot;The fast-tau estimator for regression&quot;, <em>Journal of Computational and Graphical Statistics</em>, <b>17</b>(3), 659-682
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- generate.sf.data(n = 400, n.pred = 5, n.gp = 101)
Y &lt;- sim.data$Y
X &lt;- sim.data$X
gp &lt;- rep(list(seq(0, 1, length.out = 101)), 5) # grid points of Xs
model.tau &lt;- rob.sf.reg(Y, X, emodel = "robust", fmodel = "tau", gp = gp)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
