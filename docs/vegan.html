<!DOCTYPE html><html><head><title>Help for package vegan</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {vegan}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add1.cca'><p>Add or Drop  Single Terms to a Constrained Ordination Model</p></a></li>
<li><a href='#adipart'><p>Additive Diversity Partitioning and Hierarchical Null Model Testing</p></a></li>
<li><a href='#adonis'><p>Permutational Multivariate Analysis of Variance Using Distance</p>
Matrices</a></li>
<li><a href='#anosim'><p> Analysis of Similarities</p></a></li>
<li><a href='#anova.cca'><p>Permutation Test for Constrained Correspondence Analysis,</p>
Redundancy Analysis and Constrained Analysis of Principal Coordinates</a></li>
<li><a href='#avgdist'><p>Averaged Subsampled Dissimilarity Matrices</p></a></li>
<li><a href='#BCI'><p>Barro Colorado Island Tree Counts</p></a></li>
<li><a href='#beals'><p>Beals Smoothing and Degree of Absence</p></a></li>
<li><a href='#betadisper'><p>Multivariate homogeneity of groups dispersions (variances)</p></a></li>
<li><a href='#betadiver'><p> Indices of beta Diversity</p></a></li>
<li><a href='#bgdispersal'><p> Coefficients of Biogeographical Dispersal Direction</p></a></li>
<li><a href='#bioenv'><p>Best Subset of Environmental Variables with</p>
Maximum (Rank) Correlation with Community Dissimilarities</a></li>
<li><a href='#biplot.rda'><p>PCA biplot</p></a></li>
<li><a href='#capscale'><p>[Partial] Distance-based Redundancy Analysis</p></a></li>
<li><a href='#cascadeKM'><p>K-means partitioning using a range of values of K</p></a></li>
<li><a href='#cca'><p> [Partial] [Constrained] Correspondence Analysis and Redundancy</p>
Analysis</a></li>
<li><a href='#cca.object'><p>Result Object from Constrained Ordination</p></a></li>
<li><a href='#CCorA'><p>Canonical Correlation Analysis</p></a></li>
<li><a href='#clamtest'>
<p>Multinomial Species Classification Method (CLAM)</p></a></li>
<li><a href='#commsim'>
<p>Create an Object for Null Model Algorithms</p></a></li>
<li><a href='#contribdiv'><p>Contribution Diversity Approach</p></a></li>
<li><a href='#decorana'><p>Detrended Correspondence Analysis and Basic Reciprocal Averaging</p></a></li>
<li><a href='#decostand'><p>Standardization Methods for Community Ecology</p></a></li>
<li><a href='#designdist'><p>Design your own Dissimilarities</p></a></li>
<li><a href='#deviance.cca'><p> Statistics Resembling Deviance and AIC for Constrained Ordination</p></a></li>
<li><a href='#dispindmorisita'><p>Morisita index of intraspecific aggregation</p></a></li>
<li><a href='#dispweight'><p>Dispersion-based weighting of species counts</p></a></li>
<li><a href='#distconnected'><p>Connectedness of Dissimilarities</p></a></li>
<li><a href='#diversity'><p>Ecological Diversity Indices</p></a></li>
<li><a href='#dune'><p>Vegetation and Environment in Dutch Dune Meadows.</p></a></li>
<li><a href='#dune.taxon'><p>Taxonomic Classification and Phylogeny of Dune Meadow Species</p></a></li>
<li><a href='#eigenvals'>
<p>Extract Eigenvalues from an Ordination Object</p></a></li>
<li><a href='#envfit'><p>Fits an Environmental Vector or Factor onto an Ordination</p></a></li>
<li><a href='#eventstar'>
<p>Scale Parameter at the Minimum of the Tsallis Evenness Profile</p></a></li>
<li><a href='#fisherfit'><p>Fit Fisher's Logseries and Preston's Lognormal Model to Abundance Data</p></a></li>
<li><a href='#goodness.cca'><p>Diagnostic Tools for [Constrained] Ordination (CCA,</p>
RDA, DCA, CA, PCA)</a></li>
<li><a href='#goodness.metaMDS'><p>Goodness of Fit and Shepard Plot for Nonmetric Multidimensional Scaling</p></a></li>
<li><a href='#indpower'><p>Indicator Power of Species</p></a></li>
<li><a href='#influence.cca'><p>Linear Model Diagnostics for Constrained Ordination</p></a></li>
<li><a href='#isomap'><p> Isometric Feature Mapping Ordination</p></a></li>
<li><a href='#kendall.global'><p> Kendall coefficient of concordance</p></a></li>
<li><a href='#linestack'><p>Plots One-dimensional Diagrams without Overwriting Labels</p></a></li>
<li><a href='#make.cepnames'><p>Abbreviates a Botanical or Zoological Latin Name into an Eight-character Name</p></a></li>
<li><a href='#mantel'><p>Mantel and Partial Mantel Tests for Dissimilarity Matrices</p></a></li>
<li><a href='#mantel.correlog'><p> Mantel Correlogram</p></a></li>
<li><a href='#MDSrotate'>
<p>Rotate First MDS Dimension Parallel to an External Variable</p></a></li>
<li><a href='#metaMDS'><p>Nonmetric Multidimensional Scaling with Stable Solution from</p>
Random Starts, Axis Scaling and Species Scores</a></li>
<li><a href='#mite'><p>Oribatid Mite Data with Explanatory Variables</p></a></li>
<li><a href='#monoMDS'><p> Global and Local Non-metric Multidimensional Scaling and</p>
Linear and Hybrid Scaling</a></li>
<li><a href='#MOStest'><p> Mitchell-Olds and Shaw Test for the Location of Quadratic Extreme</p></a></li>
<li><a href='#mrpp'><p>Multi Response Permutation Procedure and Mean Dissimilarity Matrix</p></a></li>
<li><a href='#mso'><p> Functions for performing and displaying a spatial partitioning</p>
of cca or rda results</a></li>
<li><a href='#multipart'><p>Multiplicative Diversity Partitioning</p></a></li>
<li><a href='#nestedtemp'><p> Nestedness Indices for Communities of Islands or Patches</p></a></li>
<li><a href='#nobs.cca'>
<p>Extract the Number of Observations from a vegan Fit.</p></a></li>
<li><a href='#nullmodel'>
<p>Null Model and Simulation</p></a></li>
<li><a href='#oecosimu'><p>Evaluate Statistics with Null Models of Biological Communities</p></a></li>
<li><a href='#ordiarrows'><p>Add Arrows and Line Segments to Ordination Diagrams</p></a></li>
<li><a href='#ordiArrowTextXY'><p>Support Functions for Drawing Vectors</p></a></li>
<li><a href='#ordihull'><p>Display Groups or Factor Levels in Ordination Diagrams</p></a></li>
<li><a href='#ordilabel'><p>Add Text on Non-transparent Label to an Ordination Plot.</p></a></li>
<li><a href='#ordiplot'><p> Alternative plot and identify Functions for Ordination</p></a></li>
<li><a href='#ordipointlabel'><p> Ordination Plots with Points and Optimized Locations for Text</p></a></li>
<li><a href='#ordiresids'><p>Plots of Residuals and Fitted Values for Constrained Ordination</p></a></li>
<li><a href='#ordistep'>
<p>Choose a Model by Permutation Tests in Constrained Ordination</p></a></li>
<li><a href='#ordisurf'><p> Fit and Plot Smooth Surfaces of Variables on Ordination.</p></a></li>
<li><a href='#orditkplot'><p> Ordination Plot with Movable Labels</p></a></li>
<li><a href='#orditorp'><p> Add Text or Points to Ordination Plots</p></a></li>
<li><a href='#ordixyplot'><p> Trellis (Lattice) Plots for Ordination</p></a></li>
<li><a href='#pcnm'><p> Principal Coordinates of Neighbourhood Matrix</p></a></li>
<li><a href='#permat'><p>Matrix Permutation Algorithms for Presence-Absence and Count Data</p></a></li>
<li><a href='#permustats'>
<p>Extract, Analyse and Display Permutation Results</p></a></li>
<li><a href='#permutations'><p>Permutation tests in Vegan</p></a></li>
<li><a href='#permutest.betadisper'><p>Permutation test of multivariate homogeneity of groups dispersions</p>
(variances)</a></li>
<li><a href='#plot.cca'><p>Plot or Extract Results of Constrained Correspondence Analysis</p>
or Redundancy Analysis</a></li>
<li><a href='#prc'><p>Principal Response Curves for Treatments with Repeated Observations</p></a></li>
<li><a href='#predict.cca'><p>Prediction Tools for [Constrained] Ordination (CCA,</p>
RDA, DCA, CA, PCA)</a></li>
<li><a href='#procrustes'><p>Procrustes Rotation of Two Configurations and PROTEST</p></a></li>
<li><a href='#pyrifos'><p>Response of Aquatic Invertebrates to Insecticide Treatment</p></a></li>
<li><a href='#radfit'><p> Rank &ndash; Abundance or Dominance / Diversity Models</p></a></li>
<li><a href='#rankindex'><p>Compares Dissimilarity Indices for Gradient Detection</p></a></li>
<li><a href='#rarefy'><p>Rarefaction Species Richness</p></a></li>
<li><a href='#raupcrick'>
<p>Raup-Crick Dissimilarity with Unequal Sampling Densities of Species</p></a></li>
<li><a href='#read.cep'><p>Reads a CEP (Canoco) data file</p></a></li>
<li><a href='#renyi'><p>Renyi and Hill Diversities and Corresponding Accumulation Curves</p></a></li>
<li><a href='#reorder.hclust'>
<p>Reorder a Hierarchical Clustering Tree</p></a></li>
<li><a href='#RsquareAdj'>
<p>Adjusted R-square</p></a></li>
<li><a href='#scores'><p> Get Species or Site Scores from an Ordination</p></a></li>
<li><a href='#screeplot.cca'><p>Screeplots for Ordination Results and Broken Stick Distributions</p></a></li>
<li><a href='#simper'><p>Similarity Percentages</p></a></li>
<li><a href='#simulate.rda'><p> Simulate Responses with Gaussian Error or Permuted Residuals for Constrained Ordination</p></a></li>
<li><a href='#sipoo'><p> Birds in the Archipelago of Sipoo (Sibbo and Borg√•)</p></a></li>
<li><a href='#spantree'><p>Minimum Spanning Tree</p></a></li>
<li><a href='#specaccum'><p>Species Accumulation Curves</p></a></li>
<li><a href='#specpool'><p> Extrapolated Species Richness in a Species Pool</p></a></li>
<li><a href='#sppscores'>
<p>Add or Replace Species Scores in Distance-Based Ordination</p></a></li>
<li><a href='#SSarrhenius'>
<p>Self-Starting nls Species-Area Models</p></a></li>
<li><a href='#stepacross'><p>Stepacross as Flexible Shortest Paths or Extended Dissimilarities</p></a></li>
<li><a href='#stressplot.wcmdscale'>
<p>Display Ordination Distances Against Observed Distances in Eigenvector Ordinations</p></a></li>
<li><a href='#taxondive'><p> Indices of Taxonomic Diversity and Distinctness</p></a></li>
<li><a href='#tolerance'><p>Species tolerances and sample heterogeneities</p></a></li>
<li><a href='#treedive'><p>Functional Diversity and Community Distances from Species Trees</p></a></li>
<li><a href='#tsallis'><p>Tsallis Diversity and Corresponding Accumulation Curves</p></a></li>
<li><a href='#varespec'><p>Vegetation and environment in lichen pastures</p></a></li>
<li><a href='#varpart'><p>Partition the Variation of Community Matrix by 2, 3, or 4 Explanatory Matrices</p></a></li>
<li><a href='#vegan-defunct'><p>Defunct Functions in Package <span class="pkg">vegan</span></p></a></li>
<li><a href='#vegan-deprecated'><p>Deprecated Functions in vegan package</p></a></li>
<li><a href='#vegan-internal'><p>Internal vegan functions</p></a></li>
<li><a href='#vegan-package'>
<p>Community Ecology Package: Ordination, Diversity and Dissimilarities</p></a></li>
<li><a href='#vegdist'><p>Dissimilarity Indices for Community Ecologists</p></a></li>
<li><a href='#vegemite'><p>Display Compact Ordered Community Tables</p></a></li>
<li><a href='#wascores'><p> Weighted Averages Scores for Species</p></a></li>
<li><a href='#wcmdscale'><p>Weighted Classical (Metric) Multidimensional Scaling</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Community Ecology Package</td>
</tr>
<tr>
<td>Version:</td>
<td>2.6-4</td>
</tr>
<tr>
<td>Depends:</td>
<td>permute (&ge; 0.9-0), lattice, R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel, tcltk, knitr, markdown</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, cluster, mgcv</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>utils, knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Ordination methods, diversity analysis and other
  functions for community and vegetation ecologists.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/vegandevs/vegan/issues">https://github.com/vegandevs/vegan/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/vegandevs/vegan">https://github.com/vegandevs/vegan</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-11 08:36:07 UTC; jarioksa</td>
</tr>
<tr>
<td>Author:</td>
<td>Jari Oksanen [aut, cre],
  Gavin L. Simpson [aut],
  F. Guillaume Blanchet [aut],
  Roeland Kindt [aut],
  Pierre Legendre [aut],
  Peter R. Minchin [aut],
  R.B. O'Hara [aut],
  Peter Solymos [aut],
  M. Henry H. Stevens [aut],
  Eduard Szoecs [aut],
  Helene Wagner [aut],
  Matt Barbour [aut],
  Michael Bedward [aut],
  Ben Bolker [aut],
  Daniel Borcard [aut],
  Gustavo Carvalho [aut],
  Michael Chirico [aut],
  Miquel De Caceres [aut],
  Sebastien Durand [aut],
  Heloisa Beatriz Antoniazi Evangelista [aut],
  Rich FitzJohn [aut],
  Michael Friendly [aut],
  Brendan Furneaux [aut],
  Geoffrey Hannigan [aut],
  Mark O. Hill [aut],
  Leo Lahti [aut],
  Dan McGlinn [aut],
  Marie-Helene Ouellette [aut],
  Eduardo Ribeiro Cunha [aut],
  Tyler Smith [aut],
  Adrian Stier [aut],
  Cajo J.F. Ter Braak [aut],
  James Weedon [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jari Oksanen &lt;jhoksane@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-11 12:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='add1.cca'>Add or Drop  Single Terms to a Constrained Ordination Model </h2><span id='topic+add1.cca'></span><span id='topic+drop1.cca'></span>

<h3>Description</h3>

<p>Compute all single terms that can be added to or dropped from a
constrained ordination model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
add1(object, scope, test = c("none", "permutation"),
    permutations = how(nperm=199), ...)
## S3 method for class 'cca'
drop1(object, scope, test = c("none", "permutation"), 
    permutations = how(nperm=199), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add1.cca_+3A_object">object</code></td>
<td>
<p> A constrained ordination object from
<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code> or <code><a href="#topic+capscale">capscale</a></code>. </p>
</td></tr>
<tr><td><code id="add1.cca_+3A_scope">scope</code></td>
<td>
<p> A formula giving the terms to be considered for adding
or dropping; see <code><a href="stats.html#topic+add1">add1</a></code> for details.</p>
</td></tr>
<tr><td><code id="add1.cca_+3A_test">test</code></td>
<td>
<p> Should a permutation test be added using <code><a href="#topic+anova.cca">anova.cca</a></code>. </p>
</td></tr>
<tr><td><code id="add1.cca_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="add1.cca_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="stats.html#topic+add1.default">add1.default</a></code>,
<code><a href="stats.html#topic+drop1.default">drop1.default</a></code>, and <code><a href="#topic+anova.cca">anova.cca</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>With argument <code>test = "none"</code> the functions will only call
<code><a href="stats.html#topic+add1.default">add1.default</a></code> or <code><a href="stats.html#topic+drop1.default">drop1.default</a></code>. With
argument <code>test = "permutation"</code> the functions will add test
results from <code><a href="#topic+anova.cca">anova.cca</a></code>. Function <code>drop1.cca</code> will
call <code><a href="#topic+anova.cca">anova.cca</a></code> with argument <code>by = "margin"</code>.
Function <code>add1.cca</code> will implement a test for single term
additions that is not directly available in <code><a href="#topic+anova.cca">anova.cca</a></code>.
</p>
<p>Functions are used implicitly in <code><a href="stats.html#topic+step">step</a></code>,
<code><a href="#topic+ordiR2step">ordiR2step</a></code> and <code><a href="#topic+ordistep">ordistep</a></code>. The
<code><a href="#topic+deviance.cca">deviance.cca</a></code> and <code><a href="#topic+deviance.rda">deviance.rda</a></code> used in
<code><a href="stats.html#topic+step">step</a></code> have no firm basis, and setting argument <code>test
  = "permutation"</code> may help in getting useful insight into validity of
model building. Function <code><a href="#topic+ordistep">ordistep</a></code> calls alternately
<code>drop1.cca</code> and <code>add1.cca</code> with argument 
<code>test = "permutation"</code> and selects variables by their permutation
<code class="reqn">P</code>-values.  Meticulous use of <code>add1.cca</code> and
<code>drop1.cca</code> will allow more judicious model building.
</p>
<p>The default number of <code>permutations</code> is set to a low value, because
permutation tests can take a long time. It should be sufficient to
give a impression on the significances of the terms, but higher
values of <code>permutations</code> should be used if <code class="reqn">P</code> values really
are important.  
</p>


<h3>Value</h3>

<p>Returns a similar object as <code><a href="stats.html#topic+add1">add1</a></code> and <code><a href="stats.html#topic+drop1">drop1</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+add1">add1</a></code>, <code><a href="stats.html#topic+drop1">drop1</a></code> and
<code><a href="#topic+anova.cca">anova.cca</a></code> for basic methods. You probably need these
functions with <code><a href="stats.html#topic+step">step</a></code> and <code><a href="#topic+ordistep">ordistep</a></code>. Functions
<code><a href="#topic+deviance.cca">deviance.cca</a></code> and <code><a href="#topic+extractAIC.cca">extractAIC.cca</a></code> are used
to produce the other arguments than test results in the
output. Functions <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code> and
<code><a href="#topic+capscale">capscale</a></code> produce result objects for these functions.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
## Automatic model building based on AIC but with permutation tests
step(cca(dune ~  1, dune.env), reformulate(names(dune.env)), test="perm")
## see ?ordistep to do the same, but based on permutation P-values
## Not run: 
ordistep(cca(dune ~  1, dune.env), reformulate(names(dune.env)))

## End(Not run)
## Manual model building
## -- define the maximal model for scope
mbig &lt;- rda(dune ~  ., dune.env)
## -- define an empty model to start with
m0 &lt;- rda(dune ~ 1, dune.env)
## -- manual selection and updating
add1(m0, scope=formula(mbig), test="perm")
m0 &lt;- update(m0, . ~ . + Management)
add1(m0, scope=formula(mbig), test="perm")
m0 &lt;- update(m0, . ~ . + Moisture)
## -- included variables still significant?
drop1(m0, test="perm")
add1(m0, scope=formula(mbig), test="perm")
</code></pre>

<hr>
<h2 id='adipart'>Additive Diversity Partitioning and Hierarchical Null Model Testing</h2><span id='topic+adipart'></span><span id='topic+adipart.default'></span><span id='topic+adipart.formula'></span><span id='topic+hiersimu'></span><span id='topic+hiersimu.default'></span><span id='topic+hiersimu.formula'></span>

<h3>Description</h3>

<p>In additive diversity partitioning, mean values of alpha diversity at lower levels of a sampling
hierarchy are compared to the total diversity in the entire data set (gamma diversity).
In hierarchical null model testing, a statistic returned by a function is evaluated
according to a nested hierarchical sampling design (<code>hiersimu</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adipart(...)
## Default S3 method:
adipart(y, x, index=c("richness", "shannon", "simpson"),
    weights=c("unif", "prop"), relative = FALSE, nsimul=99,
    method = "r2dtable", ...)
## S3 method for class 'formula'
adipart(formula, data, index=c("richness", "shannon", "simpson"),
    weights=c("unif", "prop"), relative = FALSE, nsimul=99,
    method = "r2dtable", ...)

hiersimu(...)
## Default S3 method:
hiersimu(y, x, FUN, location = c("mean", "median"),
    relative = FALSE, drop.highest = FALSE, nsimul=99,
    method = "r2dtable", ...)
## S3 method for class 'formula'
hiersimu(formula, data, FUN, location = c("mean", "median"),
    relative = FALSE, drop.highest = FALSE, nsimul=99,
    method = "r2dtable", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adipart_+3A_y">y</code></td>
<td>
<p>A community matrix.</p>
</td></tr>
<tr><td><code id="adipart_+3A_x">x</code></td>
<td>
<p>A matrix with same number of rows as in <code>y</code>, columns
coding the levels of sampling hierarchy. The number of groups within
the hierarchy must decrease from left to right. If <code>x</code> is missing,
function performs an overall decomposition into alpha, beta and
gamma diversities.</p>
</td></tr>
<tr><td><code id="adipart_+3A_formula">formula</code></td>
<td>
<p>A two sided model formula in the form <code>y ~ x</code>,
where <code>y</code> is the community data matrix with samples as rows and
species as column. Right hand side (<code>x</code>) must be grouping variables
referring to levels of sampling hierarchy, terms from right to left
will be treated as nested (first column is the lowest, last is the
highest level). The formula will add a unique indentifier to rows and
constant for the rows to always produce estimates of row-level alpha
and overall gamma diversities. You must use non-formula
interface to avoid this behaviour. Interaction terms are
not allowed.</p>
</td></tr>
<tr><td><code id="adipart_+3A_data">data</code></td>
<td>
<p>A data frame where to look for variables defined in the
right hand side of <code>formula</code>. If missing, variables are looked
in the global environment.</p>
</td></tr>
<tr><td><code id="adipart_+3A_index">index</code></td>
<td>
<p>Character, the diversity index to be calculated (see Details).</p>
</td></tr>
<tr><td><code id="adipart_+3A_weights">weights</code></td>
<td>
<p>Character, <code>"unif"</code> for uniform weights,
<code>"prop"</code> for weighting proportional to sample abundances to use
in weighted averaging of individual alpha values within strata of a
given level of the sampling hierarchy.</p>
</td></tr>
<tr><td><code id="adipart_+3A_relative">relative</code></td>
<td>
<p>Logical, if <code>TRUE</code> then alpha and beta diversity
values are given relative to the value of gamma for function
<code>adipart</code>.</p>
</td></tr>
<tr><td><code id="adipart_+3A_nsimul">nsimul</code></td>
<td>
<p>Number of permutations to use.  If <code>nsimul = 0</code>,
only the <code>FUN</code> argument is evaluated.
It is thus possible to reuse the statistic values
without a null model.</p>
</td></tr>
<tr><td><code id="adipart_+3A_method">method</code></td>
<td>
<p>Null model method: either a name (character string) of
a method defined in <code><a href="#topic+make.commsim">make.commsim</a></code> or a
<code><a href="#topic+commsim">commsim</a></code> function.
The default <code>"r2dtable"</code> keeps row sums and column sums fixed.
See <code><a href="#topic+oecosimu">oecosimu</a></code> for Details and Examples.</p>
</td></tr>
<tr><td><code id="adipart_+3A_fun">FUN</code></td>
<td>
<p>A function to be used by <code>hiersimu</code>. This must be
fully specified, because currently other arguments cannot be passed
to this function via <code>...</code>.</p>
</td></tr>
<tr><td><code id="adipart_+3A_location">location</code></td>
<td>
<p>Character, identifies which function (mean or median)
is to be used to calculate location of the samples.</p>
</td></tr>
<tr><td><code id="adipart_+3A_drop.highest">drop.highest</code></td>
<td>
<p>Logical, to drop the highest level or not. When
<code>FUN</code> evaluates only arrays with at least 2 dimensions, highest
level should be dropped, or not selected at all.</p>
</td></tr>
<tr><td><code id="adipart_+3A_...">...</code></td>
<td>
<p>Other arguments passed to functions, e.g. base of
logarithm for Shannon diversity, or <code>method</code>, <code>thin</code> or
<code>burnin</code> arguments for <code><a href="#topic+oecosimu">oecosimu</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Additive diversity partitioning means that mean alpha and beta
diversities add up to gamma diversity, thus beta diversity is measured
in the same dimensions as alpha and gamma (Lande 1996). This additive
procedure is then extended across multiple scales in a hierarchical
sampling design with <code class="reqn">i = 1, 2, 3, \ldots, m</code> levels of sampling
(Crist et al. 2003). Samples in lower hierarchical levels are nested
within higher level units, thus from <code class="reqn">i=1</code> to <code class="reqn">i=m</code> grain size
is increasing under constant survey extent. At each level <code class="reqn">i</code>,
<code class="reqn">\alpha_i</code> denotes average diversity found within samples.
</p>
<p>At the highest sampling level, the diversity components are calculated
as </p>
<p style="text-align: center;"><code class="reqn">\beta_m  = \gamma -  \alpha_m</code>
</p>
<p> For
each  lower   sampling  level   as  </p>
<p style="text-align: center;"><code class="reqn">\beta_i  =   \alpha_{i+1}  -
  \alpha_i</code>
</p>
<p> Then,  the additive partition
of diversity is </p>
<p style="text-align: center;"><code class="reqn">\gamma  = \alpha_1 + \sum_{i=1}^m \beta_i</code>
</p>

<p>Average alpha components can be weighted uniformly
(<code>weight="unif"</code>) to calculate it as simple average, or
proportionally to sample abundances (<code>weight="prop"</code>) to
calculate it as weighted average as follows </p>
<p style="text-align: center;"><code class="reqn">\alpha_i =
  \sum_{j=1}^{n_i} D_{ij} w_{ij}</code>
</p>
<p> where
<code class="reqn">D_{ij}</code> is the diversity index and <code class="reqn">w_{ij}</code> is the weight
calculated for the <code class="reqn">j</code>th sample at the <code class="reqn">i</code>th sampling level.
</p>
<p>The implementation of additive diversity partitioning in
<code>adipart</code> follows Crist et al. 2003. It is based on species
richness (<code class="reqn">S</code>, not <code class="reqn">S-1</code>), Shannon's and Simpson's diversity
indices stated as the <code>index</code> argument.
</p>
<p>The expected diversity components are calculated <code>nsimul</code> times
by individual based randomisation of the community data matrix. This
is done by the <code>"r2dtable"</code> method in <code><a href="#topic+oecosimu">oecosimu</a></code> by
default.
</p>
<p><code>hiersimu</code> works almost in the same way as <code>adipart</code>, but
without comparing the actual statistic values returned by <code>FUN</code>
to the highest possible value (cf. gamma diversity).  This is so,
because in most of the cases, it is difficult to ensure additive
properties of the mean statistic values along the hierarchy.
</p>


<h3>Value</h3>

<p>An object of class <code>"adipart"</code> or <code>"hiersimu"</code> with same
structure as <code><a href="#topic+oecosimu">oecosimu</a></code> objects.
</p>


<h3>Author(s)</h3>

<p>P√©ter S√≥lymos, <a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a></p>


<h3>References</h3>

<p>Crist,   T.O.,   Veech,    J.A.,   Gering,   J.C.   and   Summerville,
K.S.  (2003).  Partitioning species  diversity  across landscapes  and
regions:  a hierarchical  analysis of  <code class="reqn">\alpha</code>,  <code class="reqn">\beta</code>, and
<code class="reqn">\gamma</code>-diversity.  <em>Am. Nat.</em>, <b>162</b>, 734&ndash;743.
</p>
<p>Lande, R.  (1996). Statistics and partitioning of species diversity,
and similarity among multiple communities.  <em>Oikos</em>, <b>76</b>,
5&ndash;13.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+oecosimu">oecosimu</a></code> for permutation settings and
calculating <code class="reqn">p</code>-values. <code><a href="#topic+multipart">multipart</a></code> for multiplicative
diversity partitioning.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## NOTE: 'nsimul' argument usually needs to be &gt;= 99
## here much lower value is used for demonstration

data(mite)
data(mite.xy)
data(mite.env)
## Function to get equal area partitions of the mite data
cutter &lt;- function (x, cut = seq(0, 10, by = 2.5)) {
    out &lt;- rep(1, length(x))
    for (i in 2:(length(cut) - 1))
        out[which(x &gt; cut[i] &amp; x &lt;= cut[(i + 1)])] &lt;- i
    return(out)}
## The hierarchy of sample aggregation
levsm &lt;- with(mite.xy, data.frame(
    l1=1:nrow(mite),
    l2=cutter(y, cut = seq(0, 10, by = 2.5)),
    l3=cutter(y, cut = seq(0, 10, by = 5)),
    l4=rep(1, nrow(mite))))
## Let's see in a map
par(mfrow=c(1,3))
plot(mite.xy, main="l1", col=as.numeric(levsm$l1)+1, asp = 1)
plot(mite.xy, main="l2", col=as.numeric(levsm$l2)+1, asp = 1)
plot(mite.xy, main="l3", col=as.numeric(levsm$l3)+1, asp = 1)
par(mfrow=c(1,1))
## Additive diversity partitioning
adipart(mite, index="richness", nsimul=19)
## the next two define identical models
adipart(mite, levsm, index="richness", nsimul=19)
adipart(mite ~ l2 + l3, levsm, index="richness", nsimul=19)
## Hierarchical null model testing
## diversity analysis (similar to adipart)
hiersimu(mite, FUN=diversity, relative=TRUE, nsimul=19)
hiersimu(mite ~ l2 + l3, levsm, FUN=diversity, relative=TRUE, nsimul=19)
## Hierarchical testing with the Morisita index
morfun &lt;- function(x) dispindmorisita(x)$imst
hiersimu(mite ~., levsm, morfun, drop.highest=TRUE, nsimul=19)
</code></pre>

<hr>
<h2 id='adonis'>Permutational Multivariate Analysis of Variance Using Distance
Matrices</h2><span id='topic+adonis2'></span>

<h3>Description</h3>

<p>Analysis of variance using distance matrices &mdash; for
partitioning distance matrices among sources of variation and fitting
linear models (e.g., factors, polynomial regression) to distance 
matrices; uses a permutation test with pseudo-<code class="reqn">F</code> ratios.</p>


<h3>Usage</h3>

<pre><code class='language-R'>adonis2(formula, data, permutations = 999, method = "bray",
    sqrt.dist = FALSE, add = FALSE, by = "terms",
    parallel = getOption("mc.cores"), na.action = na.fail,
    strata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adonis_+3A_formula">formula</code></td>
<td>
<p>Model formula. The left-hand side (LHS) of the formula
must be either a community data matrix or a dissimilarity matrix,
e.g., from <code><a href="#topic+vegdist">vegdist</a></code> or <code><a href="stats.html#topic+dist">dist</a></code>.  If the LHS
is a data matrix, function <code><a href="#topic+vegdist">vegdist</a></code> will be used to
find the dissimilarities. The right-hand side (RHS) of the formula
defines the independent variables. These can be continuous variables
or factors, they can be transformed within the formula, and they can
have interactions as in a typical <code><a href="stats.html#topic+formula">formula</a></code>.</p>
</td></tr>
<tr><td><code id="adonis_+3A_data">data</code></td>
<td>
<p> the data frame for the independent variables.</p>
</td></tr>
<tr><td><code id="adonis_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="adonis_+3A_method">method</code></td>
<td>
<p> the name of any method used in <code><a href="#topic+vegdist">vegdist</a></code> to
calculate pairwise distances if the left hand side of the
<code>formula</code> was a data frame or a matrix. </p>
</td></tr>
<tr><td><code id="adonis_+3A_sqrt.dist">sqrt.dist</code></td>
<td>
<p>Take square root of dissimilarities. This often
euclidifies dissimilarities.</p>
</td></tr>
<tr><td><code id="adonis_+3A_add">add</code></td>
<td>
<p>Add a constant to the non-diagonal dissimilarities such
that all eigenvalues are non-negative in the underlying Principal
Co-ordinates Analysis (see <code><a href="#topic+wcmdscale">wcmdscale</a></code> for
details). Choice <code>"lingoes"</code> (or <code>TRUE</code>) use the
recommended method of Legendre &amp; Anderson (1999: &ldquo;method
1&rdquo;) and <code>"cailliez"</code> uses their &ldquo;method 2&rdquo;.</p>
</td></tr>
<tr><td><code id="adonis_+3A_by">by</code></td>
<td>
<p><code>by = "terms"</code> will assess significance for each term
(sequentially from first to last), setting <code>by = "margin"</code>
will assess the marginal effects of the terms (each marginal term
analysed in a model with all other variables), <code>by = "onedf"</code>
will analyse one-degree-of-freedom contrasts sequentially, <code>by =
    NULL</code> will assess the overall significance of all terms
together. The arguments is passed on to <code><a href="#topic+anova.cca">anova.cca</a></code>.</p>
</td></tr>
<tr><td><code id="adonis_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
<tr><td><code id="adonis_+3A_na.action">na.action</code></td>
<td>
<p>Handling of missing values on the right-hand-side
of the formula (see <code><a href="stats.html#topic+na.fail">na.fail</a></code> for explanation and
alternatives). Missing values are not allowed on the
left-hand-side. NB, argument <code>subset</code> is not implemented.</p>
</td></tr>
<tr><td><code id="adonis_+3A_strata">strata</code></td>
<td>
<p>Groups within which to constrain permutations. The
traditional non-movable strata are set as Blocks in the
<a href="https://CRAN.R-project.org/package=permute"><span class="pkg">permute</span></a> package, but some more flexible alternatives may
be more appropriate.</p>
</td></tr>
<tr><td><code id="adonis_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+vegdist">vegdist</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>adonis2</code> is a function for the analysis and partitioning sums of
squares using dissimilarities. The function is based on the principles
of McArdle &amp; Anderson (2001) and can perform sequential, marginal and
overall tests. The function also allows using additive constants or
squareroot of dissimilarities to avoid negative eigenvalues, but can
also handle semimetric indices (such as Bray-Curtis) that produce
negative eigenvalues. The <code>adonis2</code> tests are identical to
<code><a href="#topic+anova.cca">anova.cca</a></code> of <code><a href="#topic+dbrda">dbrda</a></code>. With Euclidean
distances, the tests are also identical to <code><a href="#topic+anova.cca">anova.cca</a></code> of
<code><a href="#topic+rda">rda</a></code>.
</p>
<p>The function partitions sums of squares of a multivariate data set, and
they are directly analogous to MANOVA (multivariate analysis of
variance). McArdle and Anderson (2001) and Anderson (2001) refer to the
method as &ldquo;permutational MANOVA&rdquo; (formerly &ldquo;nonparametric
MANOVA&rdquo;). Further, as the inputs are linear predictors, and a response
matrix of an arbitrary number of columns, they are a robust alternative
to both parametric MANOVA and to ordination methods for describing how
variation is attributed to different experimental treatments or
uncontrolled covariates. The method is also analogous to distance-based
redundancy analysis in functions <code><a href="#topic+dbrda">dbrda</a></code> and
<code><a href="#topic+capscale">capscale</a></code> (Legendre and Anderson 1999), and provides
an alternative to AMOVA (nested analysis of molecular variance,
Excoffier, Smouse, and Quattro, 1992; <code>amova</code> in the
<span class="pkg">ade4</span> package) for both crossed and nested factors.
</p>


<h3>Value</h3>

<p>The function returns an <code><a href="#topic+anova.cca">anova.cca</a></code> result object with a
new column for partial <code class="reqn">R^2</code>: This is the proportion
of sum of squares from the total, and in marginal models
(<code>by = "margin"</code>) the <code class="reqn">R^2</code> terms do not add up to
1.
</p>


<h3>Note</h3>

<p>Anderson (2001, Fig. 4) warns that the method may confound
location and dispersion effects: significant differences may be caused
by different within-group variation (dispersion) instead of different
mean values of the groups (see Warton et al. 2012 for a general
analysis). However, it seems that <code>adonis2</code> is less sensitive to
dispersion effects than some of its alternatives (<code><a href="#topic+anosim">anosim</a></code>,
<code><a href="#topic+mrpp">mrpp</a></code>). Function <code><a href="#topic+betadisper">betadisper</a></code> is a sister
function to <code>adonis2</code> to study the differences in dispersion
within the same geometric framework.
</p>


<h3>Author(s)</h3>

<p>Martin Henry H. Stevens and Jari Oksanen.</p>


<h3>References</h3>

<p>Anderson, M.J. 2001. A new method for non-parametric multivariate
analysis of variance. <em>Austral Ecology</em>, <strong>26</strong>: 32&ndash;46.
</p>
<p>Excoffier, L., P.E. Smouse, and J.M. Quattro. 1992. Analysis of
molecular variance inferred from metric distances among DNA haplotypes:
Application to human mitochondrial DNA restriction data. <em>Genetics</em>,
<strong>131</strong>:479&ndash;491.
</p>
<p>Legendre, P. and M.J. Anderson. 1999. Distance-based redundancy
analysis: Testing multispecies responses in multifactorial ecological
experiments. <em>Ecological Monographs</em>, <strong>69</strong>:1&ndash;24.
</p>
<p>McArdle, B.H.  and M.J. Anderson. 2001. Fitting multivariate models to
community data: A comment on distance-based redundancy
analysis. <em>Ecology</em>, <strong>82</strong>: 290&ndash;297.
</p>
<p>Warton, D.I., Wright, T.W., Wang, Y. 2012. Distance-based multivariate
analyses confound location and dispersion effects. <em>Methods in
Ecology and Evolution</em>, 3, 89&ndash;101.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+mrpp">mrpp</a></code>, <code><a href="#topic+anosim">anosim</a></code>,
<code><a href="#topic+mantel">mantel</a></code>, <code><a href="#topic+varpart">varpart</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
## default test by terms
adonis2(dune ~ Management*A1, data = dune.env)
## overall tests
adonis2(dune ~ Management*A1, data = dune.env, by = NULL)

### Example of use with strata, for nested (e.g., block) designs.
dat &lt;- expand.grid(rep=gl(2,1), NO3=factor(c(0,10)),field=gl(3,1) )
dat
Agropyron &lt;- with(dat, as.numeric(field) + as.numeric(NO3)+2) +rnorm(12)/2
Schizachyrium &lt;- with(dat, as.numeric(field) - as.numeric(NO3)+2) +rnorm(12)/2
total &lt;- Agropyron + Schizachyrium
dotplot(total ~ NO3, dat, jitter.x=TRUE, groups=field,
        type=c('p','a'), xlab="NO3", auto.key=list(columns=3, lines=TRUE) )

Y &lt;- data.frame(Agropyron, Schizachyrium)
mod &lt;- metaMDS(Y, trace = FALSE)
plot(mod)
### Ellipsoid hulls show treatment
with(dat, ordiellipse(mod, field, kind = "ehull", label = TRUE))
### Spider shows fields
with(dat, ordispider(mod, field, lty=3, col="red"))

### Incorrect (no strata)
adonis2(Y ~ NO3, data = dat, permutations = 199)
## Correct with strata
with(dat, adonis2(Y ~ NO3, data = dat, permutations = 199, strata = field))
</code></pre>

<hr>
<h2 id='anosim'> Analysis of Similarities </h2><span id='topic+anosim'></span><span id='topic+summary.anosim'></span><span id='topic+plot.anosim'></span>

<h3>Description</h3>

<p>Analysis of similarities (ANOSIM) provides a way to test statistically
whether there is a significant difference between two or more groups
of sampling units.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anosim(x, grouping, permutations = 999, distance = "bray", strata = NULL,
    parallel = getOption("mc.cores"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anosim_+3A_x">x</code></td>
<td>
<p>Data matrix or data frame in which rows are samples and
columns are response variable(s), or a dissimilarity object or a
symmetric square matrix of dissimilarities.</p>
</td></tr>
<tr><td><code id="anosim_+3A_grouping">grouping</code></td>
<td>
<p>Factor for grouping observations.</p>
</td></tr>
<tr><td><code id="anosim_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="anosim_+3A_distance">distance</code></td>
<td>
<p>Choice of distance metric that measures the
dissimilarity between two observations. See <code><a href="#topic+vegdist">vegdist</a></code> for
options.  This will be used if <code>x</code> was not a dissimilarity
structure or a symmetric square matrix.</p>
</td></tr>  
<tr><td><code id="anosim_+3A_strata">strata</code></td>
<td>
<p>An integer vector or factor specifying the strata for
permutation. If supplied, observations are permuted only within the
specified strata.</p>
</td></tr>
<tr><td><code id="anosim_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Analysis of similarities (ANOSIM) provides a way to test statistically
whether there is a significant difference between two or more groups
of sampling units.  Function <code>anosim</code> operates directly on a
dissimilarity matrix.  A suitable dissimilarity matrix is produced by
functions <code><a href="stats.html#topic+dist">dist</a></code> or <code><a href="#topic+vegdist">vegdist</a></code>.  The
method is philosophically allied with NMDS ordination
(<code><a href="#topic+monoMDS">monoMDS</a></code>), in that it uses only the rank order of
dissimilarity values.
</p>
<p>If two groups of sampling units are really different in their species
composition, then compositional dissimilarities between the groups
ought to be greater than those within the groups.  The <code>anosim</code>
statistic <code class="reqn">R</code> is based on the difference of mean ranks between
groups (<code class="reqn">r_B</code>) and within groups (<code class="reqn">r_W</code>):
</p>
<p style="text-align: center;"><code class="reqn">R = (r_B - r_W)/(N (N-1) / 4)</code>
</p>

<p>The divisor is chosen so that <code class="reqn">R</code> will be in the interval
<code class="reqn">-1 \dots +1</code>, value <code class="reqn">0</code> indicating completely random
grouping.
</p>
<p>The statistical significance of observed <code class="reqn">R</code> is assessed by
permuting the grouping vector to obtain the empirical distribution
of <code class="reqn">R</code> under null-model.  See <code><a href="#topic+permutations">permutations</a></code> for
additional details on permutation tests in Vegan. The distribution
of simulated values can be inspected with the <code><a href="#topic+permustats">permustats</a></code>
function.
</p>
<p>The function has <code>summary</code> and <code>plot</code> methods.  These both
show valuable information to assess the validity of the method:  The
function assumes that all ranked dissimilarities within groups 
have about equal median and range.  The <code>plot</code> method uses
<code><a href="graphics.html#topic+boxplot">boxplot</a></code> with options <code>notch=TRUE</code> and
<code>varwidth=TRUE</code>. 
</p>


<h3>Value</h3>

<p>The function returns a list of class <code>"anosim"</code> with following
items: 
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>Function call.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>The value of ANOSIM statistic <code class="reqn">R</code></p>
</td></tr>
<tr><td><code>signif</code></td>
<td>
<p>Significance from permutation.</p>
</td></tr>
<tr><td><code>perm</code></td>
<td>
<p>Permutation values of <code class="reqn">R</code>. The distribution of
permutation values can be inspected with function <code><a href="#topic+permustats">permustats</a></code>.</p>
</td></tr>
<tr><td><code>class.vec</code></td>
<td>
<p>Factor with value <code>Between</code> for dissimilarities
between classes and class name for corresponding dissimilarity
within class.</p>
</td></tr>
<tr><td><code>dis.rank</code></td>
<td>
<p>Rank of dissimilarity entry.</p>
</td></tr>
<tr><td><code>dissimilarity</code></td>
<td>
<p>The name of the dissimilarity index: the
<code>"method"</code> entry of the <code>dist</code> object.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>A list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>anosim</code> function can confound the differences between groups
and dispersion within groups and the results can be difficult to
interpret (cf. Warton et al. 2012).  The function returns a lot of
information to ease studying its performance. Most <code>anosim</code>
models could be analysed with <code><a href="#topic+adonis2">adonis2</a></code> which seems to be a
more robust alternative.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen, with a help from Peter R. Minchin.</p>


<h3>References</h3>

<p>Clarke, K. R. (1993). Non-parametric multivariate analysis of changes
in community structure. <em>Australian Journal of Ecology</em> 18,
117&ndash;143.
</p>
<p>Warton, D.I., Wright, T.W., Wang, Y. 2012. Distance-based multivariate
analyses confound location and dispersion effects. <em>Methods in
Ecology and Evolution</em>, 3, 89&ndash;101
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mrpp">mrpp</a></code> for a similar function using original
dissimilarities instead of their ranks. 
<code><a href="stats.html#topic+dist">dist</a></code> and <code><a href="#topic+vegdist">vegdist</a></code> for obtaining
dissimilarities, and <code><a href="base.html#topic+rank">rank</a></code> for ranking real values.  For
comparing dissimilarities against continuous variables, see
<code><a href="#topic+mantel">mantel</a></code>. Function <code><a href="#topic+adonis2">adonis2</a></code> is a more robust
alternative that should preferred. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
dune.dist &lt;- vegdist(dune)
dune.ano &lt;- with(dune.env, anosim(dune.dist, Management))
summary(dune.ano)
plot(dune.ano)
</code></pre>

<hr>
<h2 id='anova.cca'>Permutation Test for Constrained Correspondence Analysis,
Redundancy Analysis and Constrained Analysis of Principal Coordinates </h2><span id='topic+anova.cca'></span><span id='topic+permutest'></span><span id='topic+permutest.cca'></span>

<h3>Description</h3>

<p>The function performs an ANOVA like permutation test for Constrained
Correspondence Analysis (<code><a href="#topic+cca">cca</a></code>), Redundancy Analysis
(<code><a href="#topic+rda">rda</a></code>) or distance-based Redundancy Analysis (dbRDA,
<code><a href="#topic+capscale">capscale</a></code>) to assess the significance of constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
anova(object, ..., permutations = how(nperm=999),
     by = NULL, model = c("reduced", "direct", "full"),
     parallel = getOption("mc.cores"), strata = NULL,
     cutoff = 1, scope = NULL)
## S3 method for class 'cca'
permutest(x, permutations = how(nperm = 99),
     model = c("reduced", "direct", "full"), by = NULL, first = FALSE,
     strata = NULL, parallel = getOption("mc.cores"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.cca_+3A_object">object</code></td>
<td>
<p>One or several result objects from <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code> or <code><a href="#topic+capscale">capscale</a></code>. If
there are several result objects, they are compared against each
other in the order they were supplied. For a single object, a test
specified in <code>by</code> or an overall test is given.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_x">x</code></td>
<td>
<p>A single ordination result object.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_by">by</code></td>
<td>
<p>Setting <code>by = "axis"</code> will assess significance for
each constrained axis, and setting <code>by = "terms"</code> will assess
significance for each term (sequentially from first to last), and
setting <code>by = "margin"</code> will assess the marginal effects of
the terms (each marginal term analysed in a model with all other
variables), and <code>by = "onedf"</code> will assess sequentially
one-degree-of-freedom contrasts of split factors.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_model">model</code></td>
<td>
<p>Permutation model: <code>model="direct"</code> permutes
community data, <code>model="reduced"</code> permutes residuals
of the community data after Conditions (partial model),
<code>model = "full"</code> permutes residuals after Conditions and
Constraints.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_parallel">parallel</code></td>
<td>
<p>Use parallel processing with the given number of
cores.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_strata">strata</code></td>
<td>
<p>An integer vector or factor specifying the strata for
permutation. If supplied, observations are permuted only within
the specified strata. It is an error to use this when
<code>permutations</code> is a matrix, or a <code><a href="permute.html#topic+how">how</a></code>
defines <code>blocks</code>. This is a legacy argument that will be
deprecated in the future: use
<code>permutations = how(..., blocks)</code> instead. </p>
</td></tr>
<tr><td><code id="anova.cca_+3A_cutoff">cutoff</code></td>
<td>
<p>Only effective with <code>by="axis"</code> where stops
permutations after an axis exceeds the <code>cutoff</code> <code class="reqn">p</code>-value.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_scope">scope</code></td>
<td>
<p>Only effective with <code>by="margin"</code> where it can be
used to select the marginal terms for testing. The default is to
test all marginal terms in <code><a href="stats.html#topic+drop.scope">drop.scope</a></code>.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_first">first</code></td>
<td>
<p>Analyse only significance of the first axis.</p>
</td></tr>
<tr><td><code id="anova.cca_+3A_...">...</code></td>
<td>
<p>Parameters passed to other functions.  <code>anova.cca</code>
passes all arguments to <code>permutest.cca</code>. In <code>anova</code> with
<code>by = "axis"</code> you can use argument <code>cutoff</code> (defaults
<code>1</code>) which stops permutations after exceeding the given
level. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions <code>anova.cca</code> and <code>permutest.cca</code> implement ANOVA
like permutation tests for the joint effect of constraints in
<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code> or
<code><a href="#topic+capscale">capscale</a></code>. Function <code>anova</code> is intended as a more
user-friendly alternative to <code>permutest</code> (that is the real
workhorse).
</p>
<p>Function <code>anova</code> can analyse a sequence of constrained
ordination models. The analysis is based on the differences in
residual deviance in permutations of nested models.
</p>
<p>The default test is for the sum of all constrained eigenvalues.
Setting <code>first = TRUE</code> will perform a test for the first
constrained eigenvalue.  Argument <code>first</code> can be set either in
<code>anova.cca</code> or in <code>permutest.cca</code>.  It is also possible to
perform significance tests for each axis or for each term
(constraining variable) using argument <code>by</code> in <code>anova.cca</code>.
Setting <code>by = "axis"</code> will perform separate significance tests
for each constrained axis.  All previous constrained axes will be used
as conditions (&ldquo;partialled out&rdquo;) and a test for the first
constrained eigenvalues is performed (Legendre et al. 2011).  You can
stop permutation tests after exceeding a given significance level with
argument <code>cutoff</code> to speed up calculations in large
models. Setting <code>by = "terms"</code> will perform separate significance
test for each term (constraining variable). The terms are assessed
sequentially from first to last, and the order of the terms will
influence their significances. Setting <code>by = "onedf"</code> will
perform a similar sequential test for one-degree-of-freedom effects,
where multi-level factors are split in their contrasts. Setting
<code>by = "margin"</code> will perform separate significance test for each
marginal term in a model with all other terms. The marginal test also
accepts a <code>scope</code> argument for the <code><a href="stats.html#topic+drop.scope">drop.scope</a></code> which
can be a character vector of term labels that are analysed, or a
fitted model of lower scope.  The marginal effects are also known as
&ldquo;Type III&rdquo; effects, but the current function only evaluates
marginal terms. It will, for instance, ignore main effects that are
included in interaction terms. In calculating pseudo-<code class="reqn">F</code>, all
terms are compared to the same residual of the full model.
</p>
<p>Community data are permuted with choice <code>model="direct"</code>, and
residuals after partial CCA/ RDA/ dbRDA with choice
<code>model="reduced"</code> (default).  If there is no partial CCA/ RDA/
dbRDA stage, <code>model="reduced"</code> simply permutes the data and is
equivalent to <code>model="direct"</code>.  The test statistic is
&ldquo;pseudo-<code class="reqn">F</code>&rdquo;, which is the ratio of constrained and
unconstrained total Inertia (Chi-squares, variances or something
similar), each divided by their respective degrees of freedom.  If
there are no conditions (&ldquo;partial&rdquo; terms), the sum of all
eigenvalues remains constant, so that pseudo-<code class="reqn">F</code> and eigenvalues
would give equal results.  In partial CCA/ RDA/ dbRDA, the effect of
conditioning variables (&ldquo;covariables&rdquo;) is removed before
permutation, and the total Chi-square is not fixed, and test based on
pseudo-<code class="reqn">F</code> would differ from the test based on plain
eigenvalues.
</p>


<h3>Value</h3>

<p>The function <code>anova.cca</code> calls <code>permutest.cca</code> and fills an
<code><a href="stats.html#topic+anova">anova</a></code> table. Additional attributes are
<code>Random.seed</code> (the random seeds used),
<code>control</code> (the permutation design, see <a href="permute.html#topic+how">how</a>) and
<code>F.perm</code> (the permuted test statistics).
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>References</h3>

<p>Legendre, P. and Legendre, L. (2012). <em>Numerical Ecology</em>. 3rd
English ed. Elsevier.
</p>
<p>Legendre, P., Oksanen, J. and ter Braak, C.J.F. (2011). Testing the
significance of canonical axes in redundancy analysis.
<em>Methods in Ecology and Evolution</em> 2, 269&ndash;277.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anova.cca">anova.cca</a></code>, <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code> to get something to
analyse. Function <code><a href="#topic+drop1.cca">drop1.cca</a></code> calls <code>anova.cca</code>
with <code>by = "margin"</code>, and <code><a href="#topic+add1.cca">add1.cca</a></code> an analysis
for single terms additions, which can be used in automatic or
semiautomatic model building (see <code><a href="#topic+deviance.cca">deviance.cca</a></code>). </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune, dune.env)
mod &lt;- cca(dune ~ Moisture + Management, dune.env)
## overall test
anova(mod)
## tests for individual terms
anova(mod, by="term")
anova(mod, by="margin")
## sequential test for contrasts
anova(mod, by = "onedf")
## test for adding all environmental variables
anova(mod, cca(dune ~ ., dune.env))
</code></pre>

<hr>
<h2 id='avgdist'>Averaged Subsampled Dissimilarity Matrices</h2><span id='topic+avgdist'></span>

<h3>Description</h3>

<p>The function computes the dissimilarity matrix of a dataset multiple
times using <code><a href="#topic+vegdist">vegdist</a></code> while randomly subsampling the
dataset each time. All of the subsampled iterations are then averaged
(mean) to provide a distance matrix that represents the average of
multiple subsampling iterations. This emulates the behavior of the
distance matrix calculator within the Mothur microbial ecology toolkit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avgdist(x, sample, distfun = vegdist, meanfun = mean,
    transf = NULL, iterations = 100, dmethod = "bray",
    diag = TRUE, upper = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="avgdist_+3A_x">x</code></td>
<td>
<p>Community data matrix.</p>
</td></tr>
<tr><td><code id="avgdist_+3A_sample">sample</code></td>
<td>
<p>The subsampling depth to be used in each iteration. Samples that
do not meet this threshold will be removed from the analysis, and their
identity returned to the user in stdout.</p>
</td></tr>
<tr><td><code id="avgdist_+3A_distfun">distfun</code></td>
<td>
<p>The dissimilarity matrix function to be used. Default is the
vegan <code><a href="#topic+vegdist">vegdist</a></code></p>
</td></tr>
<tr><td><code id="avgdist_+3A_meanfun">meanfun</code></td>
<td>
<p>The calculation to use for the average (mean or median).</p>
</td></tr>
<tr><td><code id="avgdist_+3A_transf">transf</code></td>
<td>
<p>Option for transforming the count data before calculating the
distance matrix. Any base transformation option can be used (e.g.
<code><a href="base.html#topic+sqrt">sqrt</a></code>)</p>
</td></tr>
<tr><td><code id="avgdist_+3A_iterations">iterations</code></td>
<td>
<p>The number of random iterations to perform before averaging.
Default is 100 iterations.</p>
</td></tr>
<tr><td><code id="avgdist_+3A_dmethod">dmethod</code></td>
<td>
<p>Dissimilarity index to be used with the specified dissimilarity
matrix function. Default is Bray-Curtis</p>
</td></tr>
<tr><td><code id="avgdist_+3A_diag">diag</code>, <code id="avgdist_+3A_upper">upper</code></td>
<td>
<p>Return dissimilarities with diagonal and upper
triangle. NB. the default differs from <code><a href="#topic+vegdist">vegdist</a></code>
and returns symmetric <code>"dist"</code> structure instead of lower
diagonal. However, the object cannot be accessed with matrix
indices unless cast to matrix with <code><a href="base.html#topic+as.matrix">as.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="avgdist_+3A_...">...</code></td>
<td>
<p>Any additional arguments to add to the distance function or
mean/median function specified.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function builds on the function <code><a href="#topic+rrarefy">rrarefy</a></code> and and
additional distance matrix function (e.g. <code><a href="#topic+vegdist">vegdist</a></code>) to
add more meaningful representations of distances among randomly
subsampled datasets by presenting the average of multiple random
iterations. This function runs using the <code><a href="#topic+vegdist">vegdist</a></code>. This
functionality has been utilized in the Mothur standalone microbial
ecology toolkit <a href="https://mothur.org/wiki/Dist.shared">here</a>.
</p>


<h3>Author(s)</h3>

<p> Geoffrey Hannigan, with some minor tweaks by Gavin L. Simpson. </p>


<h3>See Also</h3>

<p>This function utilizes the <code><a href="#topic+vegdist">vegdist</a></code> and <code><a href="#topic+rrarefy">rrarefy</a></code>
functions.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import an example count dataset
data(BCI)
# Test the base functionality
mean.avg.dist &lt;- avgdist(BCI, sample = 50, iterations = 10)
# Test the transformation function
mean.avg.dist.t &lt;- avgdist(BCI, sample = 50, iterations = 10, transf = sqrt)
# Test the median functionality
median.avg.dist &lt;- avgdist(BCI, sample = 50, iterations = 10, meanfun = median)
# Print the resulting tables
head(as.matrix(mean.avg.dist))
head(as.matrix(mean.avg.dist.t))
head(as.matrix(median.avg.dist))
# Run example to illustrate low variance of mean, median, and stdev results
# Mean and median std dev are around 0.05
sdd &lt;- avgdist(BCI, sample = 50, iterations = 100, meanfun = sd)
summary(mean.avg.dist)
summary(median.avg.dist)
summary(sdd)
# Test for when subsampling depth excludes some samples
# Return samples that are removed for not meeting depth filter
depth.avg.dist &lt;- avgdist(BCI, sample = 450, iterations = 10)
# Print the result
depth.avg.dist
</code></pre>

<hr>
<h2 id='BCI'>Barro Colorado Island Tree Counts</h2><span id='topic+BCI'></span><span id='topic+BCI.env'></span>

<h3>Description</h3>

<p>Tree counts in 1-hectare plots in the Barro Colorado Island and
associated site information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BCI)
data(BCI.env)
</code></pre>


<h3>Format</h3>

<p>A data frame with 50 plots (rows) of 1 hectare with counts of trees on
each plot with total of 225 species (columns). Full Latin names are
used for tree species. The names were updated against
<a href="http://www.theplantlist.org">http://www.theplantlist.org</a> and Kress et al. (2009) which allows
matching 207 of species against <a href="https://doi.org/10.5061/dryad.63q27">doi:10.5061/dryad.63q27</a> (Zanne et
al., 2014). The original species names are available as attribute
<code>original.names</code> of <code>BCI</code>. See Examples for changed names.
</p>
<p>For <code>BCI.env</code>, a data frame with 50 plots (rows) and nine site
variables derived from Pyke et al. (2001) and Harms et al. (2001):
</p>

<dl>
<dt><code>UTM.EW</code>: </dt><dd><p>UTM coordinates (zone 17N) East-West.</p>
</dd>
<dt><code>UTM.NS</code>: </dt><dd><p>UTM coordinates (zone 17N) North-South.</p>
</dd>
<dt><code>Precipitation</code>: </dt><dd><p>Precipitation in mm per year.</p>
</dd>
<dt><code>Elevation</code>: </dt><dd><p>Elevation in m above sea level.</p>
</dd>
<dt><code>Age.cat</code>: </dt><dd><p>Forest age category.</p>
</dd>
<dt><code>Geology</code>: </dt><dd><p>The Underlying geological formation.</p>
</dd>
<dt><code>Habitat</code>: </dt><dd><p>Dominant habitat type based on the map of
habitat types in 25 grid cells in each plot (Harms et al. 2001,
excluding streamside habitat). The habitat types are <code>Young</code>
forests (<em>ca.</em> 100 years), old forests on &gt; 7 degree slopes
(<code>OldSlope</code>), old forests under 152 m elevation
(<code>OldLow</code>) and at higher elevation (<code>OldHigh</code>) and
<code>Swamp</code> forests.</p>
</dd>
<dt><code>River</code>: </dt><dd><p><code>"Yes"</code> if there is streamside habitat
in the plot.</p>
</dd>
<dt><code>EnvHet</code>: </dt><dd><p>Environmental Heterogeneity assessed as the
Simpson diversity of frequencies of <code>Habitat</code> types in 25
grid cells in the plot.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data give the numbers of trees at least 10 cm in
diameter at breast height (1.3 m above the ground) in each one hectare
square of forest. Within each one hectare square, all individuals of
all species were tallied and are recorded in this table.
</p>
<p>The data frame contains only the Barro Colorado Island subset of the
original data.
</p>
<p>The quadrats are located in a regular grid. See <code>BCI.env</code> for the
coordinates.
</p>
<p>A full description of the site information in <code>BCI.env</code> is
given in Pyke et al. (2001) and Harms et al. (2001). <em>N.B.</em>
Pyke et al. (2001) and Harms et al. (2001) give conflicting
information about forest age categories and elevation.
</p>


<h3>Source</h3>

<p><a href="https://www.science.org/doi/10.1126/science.1066854">https://www.science.org/doi/10.1126/science.1066854</a>
for community data and References for environmental data.
</p>


<h3>References</h3>

<p>Condit, R, Pitman, N, Leigh, E.G., Chave, J., Terborgh, J., Foster,
R.B., Nu√±ez, P., Aguilar, S., Valencia, R., Villa, G.,
Muller-Landau, H.C., Losos, E. &amp; Hubbell, S.P. (2002).
Beta-diversity in tropical forest trees. <em>Science</em> 295,
666&ndash;669.
</p>
<p>Harms K.E., Condit R., Hubbell S.P. &amp; Foster R.B. (2001) Habitat
associations of trees and shrubs in a 50-ha neotropical forest
plot. <em>J. Ecol.</em> 89, 947&ndash;959.
</p>
<p>Kress W.J., Erickson D.L, Jones F.A., Swenson N.G, Perez R., Sanjur
O. &amp; Bermingham E. (2009) Plant DNA barcodes and a community
phylogeny of a tropical forest dynamics plot in Panama. <em>PNAS</em>
106, 18621&ndash;18626.
</p>
<p>Zanne A.E., Tank D.C., Cornwell, W.K., Eastman J.M., Smith, S.A.,
FitzJohn, R.G., McGlinn, D.J., O‚ÄôMeara, B.C., Moles, A.T., Reich,
P.B., Royer, D.L., Soltis, D.E., Stevens, P.F., Westoby, M., Wright,
I.J., Aarssen, L., Bertin, R.I., Calaminus, A., Govaerts, R.,
Hemmings, F., Leishman, M.R., Oleksyn, J., Soltis, P.S., Swenson,
N.G., Warman, L. &amp; Beaulieu, J.M. (2014) Three keys to the radiation
of angiosperms into freezing environments. <em>Nature</em> 506,
89&ndash;92.  <a href="https://doi.org/10.1038/nature12872">doi:10.1038/nature12872</a> (published online Dec 22, 2013).
</p>
<p>Pyke, C. R., Condit, R., Aguilar, S., &amp; Lao, S. (2001). Floristic
composition across a climatic gradient in a neotropical lowland
forest. <em>Journal of Vegetation Science</em> 12, 553&ndash;566.
<a href="https://doi.org/10.2307/3237007">doi:10.2307/3237007</a> 
</p>


<h3>See Also</h3>

<p>Extra-CRAN package <span class="pkg">natto</span>
(<a href="https://github.com/jarioksa/natto">https://github.com/jarioksa/natto</a>) has data set
<code>BCI.env2</code> with original grid data of Harms et al. (2001)
habitat classification, and data set <code>BCI.taxon</code> of APG III
classification of tree species.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI, BCI.env)
head(BCI.env)
## see changed species names
oldnames &lt;- attr(BCI, "original.names")
taxa &lt;- cbind("Old Names" = oldnames, "Current Names" = names(BCI))
noquote(taxa[taxa[,1] != taxa[,2], ])
</code></pre>

<hr>
<h2 id='beals'>Beals Smoothing and Degree of Absence</h2><span id='topic+beals'></span><span id='topic+swan'></span>

<h3>Description</h3>

<p>Beals smoothing replaces each entry in the community data with a
probability of a target species occurring in that particular site, based
on the joint occurrences of the target species with the species that
actually occur in the site. Swan's (1970) degree of absence applies
Beals smoothing to zero items so long that all zeros are replaced
with smoothed values. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beals(x, species = NA, reference = x, type = 0, include = TRUE)
swan(x, maxit = Inf, type = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beals_+3A_x">x</code></td>
<td>
<p>Community data frame or matrix. </p>
</td></tr>
<tr><td><code id="beals_+3A_species">species</code></td>
<td>
<p> Column index used to compute Beals function for a single species. 
The default (<code>NA</code>) indicates that the function will be computed for all species.</p>
</td></tr> 
<tr><td><code id="beals_+3A_reference">reference</code></td>
<td>
<p> Community data frame or matrix to be used to compute
joint occurrences. By default, <code>x</code> is used as reference to
compute the joint occurrences.</p>
</td></tr> 
<tr><td><code id="beals_+3A_type">type</code></td>
<td>
<p>Numeric. Specifies if and how abundance values have to be 
used in function <code>beals</code>. See details for more explanation.</p>
</td></tr>  
<tr><td><code id="beals_+3A_include">include</code></td>
<td>
<p>This logical flag indicates whether the target species has to be
included when computing the mean of the conditioned probabilities. The
original Beals (1984) definition is equivalent to <code>include=TRUE</code>,
while the formulation of M√ºnzbergov√° and Herben is
equal to <code>include=FALSE</code>.</p>
</td></tr>
<tr><td><code id="beals_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations. The default <code>Inf</code>
means that iterations are continued until there are no zeros or
the number of zeros does not change. Probably only 
<code>maxit = 1</code> makes sense in addition to the default.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>Beals smoothing is the estimated probability <code class="reqn">p_{ij}</code> that
species <code class="reqn">j</code> occurs at site <code class="reqn">i</code>. It is defined as <code class="reqn">p_{ij}
  = \frac{1}{S_i} \sum_k \frac{N_{jk} I_{ik}}{N_k}</code>, where <code class="reqn">S_i</code> is the number of
species at site <code class="reqn">i</code>, <code class="reqn">N_{jk}</code> is the number of joint
occurrences of species <code class="reqn">j</code> and <code class="reqn">k</code>, <code class="reqn">N_k</code> is the
number of occurrences of species <code class="reqn">k</code>, and <code class="reqn">I</code> is the incidence
(0 or 1) of species (this last term is usually omitted from the
equation, but it is necessary). As <code class="reqn">N_{jk}</code> can be
interpreted as a mean of conditional probability, the <code>beals</code>
function can be interpreted as a mean of conditioned probabilities (De
C√°ceres &amp; Legendre 2008). The present function is
generalized to abundance values (De C√°ceres &amp; Legendre
2008).
</p>
<p>The <code>type</code> argument specifies if and how abundance values have to be
used. <code>type = 0</code> presence/absence mode. <code>type = 1</code>
abundances in <code>reference</code> (or <code>x</code>) are used to compute
conditioned probabilities. <code>type = 2</code> abundances in <code>x</code> are
used to compute weighted averages of conditioned
probabilities. <code>type = 3</code> abundances are used to compute both
conditioned probabilities and weighted averages.
</p>
<p>Beals smoothing was originally suggested as a method of data
transformation to remove excessive zeros (Beals 1984, McCune 1994).
However, it is not a suitable method for this purpose since it does
not maintain the information on species presences: a species may have
a higher probability of occurrence at a site where it does not occur
than at sites where it occurs. Moreover, it regularizes data too
strongly. The method may be useful in identifying species that belong
to the species pool (Ewald 2002) or to identify suitable unoccupied
patches in metapopulation analysis (M√ºnzbergov√° &amp;
Herben 2004). In this case, the function should be called with
<code>include=FALSE</code> for cross-validation smoothing for species;
argument <code>species</code> can be used if only one species is studied.
</p>
<p>Swan (1970) suggested replacing zero values with degrees of absence of
a species in a community data matrix. Swan expressed the method in
terms of a similarity matrix, but it is equivalent to applying Beals
smoothing to zero values, at each step shifting the smallest initially
non-zero item to value one, and repeating this so many times that
there are no zeros left in the data. This is actually very similar to
extended dissimilarities (implemented in function
<code><a href="#topic+stepacross">stepacross</a></code>), but very rarely used. 
</p>


<h3>Value</h3>

<p>The function returns a transformed data matrix or a vector if Beals smoothing 
is requested for a single species.
</p>


<h3>Author(s)</h3>

<p>Miquel De C√°ceres and Jari Oksanen</p>


<h3>References</h3>

<p>Beals, E.W. 1984. Bray-Curtis ordination: an effective strategy for
analysis of multivariate ecological data. Pp. 1&ndash;55 in: MacFadyen, A. &amp;
E.D. Ford [eds.] <em>Advances in Ecological Research, 14</em>. Academic
Press, London.
</p>
<p>De C√°ceres, M. &amp; Legendre, P. 2008. Beals smoothing
revisited. <em>Oecologia</em> 156: 657&ndash;669.
</p>
<p>Ewald, J. 2002. A probabilistic approach to estimating species pools
from large compositional matrices. <em>J. Veg. Sci.</em> 13: 191&ndash;198.
</p>
<p>McCune, B. 1994. Improving community ordination with the Beals smoothing
function. <em>Ecoscience</em> 1: 82&ndash;86.
</p>
<p>M√ºnzbergov√°, Z. &amp; Herben, T. 2004. Identification of
suitable unoccupied 
habitats in metapopulation studies using co-occurrence of species. <em>Oikos</em>
105: 408&ndash;414.
</p>
<p>Swan, J.M.A. 1970. An examination of some ordination problems by use of
simulated vegetational data. <em>Ecology</em> 51: 89&ndash;102. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+decostand">decostand</a></code> for proper standardization methods,
<code><a href="#topic+specpool">specpool</a></code> for an attempt to assess the size of species
pool. Function <code><a href="#topic+indpower">indpower</a></code> assesses the power of each species
to estimate the probabilities predicted by <code>beals</code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
## Default
x &lt;- beals(dune)
## Remove target species
x &lt;- beals(dune, include = FALSE)
## Smoothed values against presence or absence of species
pa &lt;- decostand(dune, "pa")
boxplot(as.vector(x) ~ unlist(pa), xlab="Presence", ylab="Beals")
## Remove the bias of tarbet species: Yields lower values.
beals(dune, type =3, include = FALSE)
## Uses abundance information.
## Vector with beals smoothing values corresponding to the first species
## in dune.
beals(dune, species=1, include=TRUE) 
</code></pre>

<hr>
<h2 id='betadisper'>Multivariate homogeneity of groups dispersions (variances)</h2><span id='topic+betadisper'></span><span id='topic+scores.betadisper'></span><span id='topic+anova.betadisper'></span><span id='topic+plot.betadisper'></span><span id='topic+boxplot.betadisper'></span><span id='topic+TukeyHSD.betadisper'></span><span id='topic+eigenvals.betadisper'></span><span id='topic+print.betadisper'></span><span id='topic+ordimedian'></span>

<h3>Description</h3>

<p>Implements Marti Anderson's PERMDISP2 procedure for the analysis of
multivariate homogeneity of group dispersions (variances).
<code>betadisper</code> is a multivariate analogue of Levene's test for
homogeneity of variances. Non-euclidean distances between objects and
group centres (centroids or medians) are handled by reducing the
original distances to principal coordinates. This procedure has
latterly been used as a means of assessing beta diversity. There are
<code>anova</code>, <code>scores</code>, <code>plot</code> and <code>boxplot</code> methods.
</p>
<p><code>TukeyHSD.betadisper</code> creates a set of confidence intervals on
the differences between the mean distance-to-centroid of the levels of
the grouping factor with the specified family-wise probability of
coverage.  The intervals are based on the Studentized range statistic,
Tukey's 'Honest Significant Difference' method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betadisper(d, group, type = c("median","centroid"), bias.adjust = FALSE,
       sqrt.dist = FALSE, add = FALSE)

## S3 method for class 'betadisper'
anova(object, ...)

## S3 method for class 'betadisper'
scores(x, display = c("sites", "centroids"),
       choices = c(1,2), ...)

## S3 method for class 'betadisper'
eigenvals(x, ...)

## S3 method for class 'betadisper'
plot(x, axes = c(1,2), cex = 0.7,
     pch = seq_len(ng), col = NULL, lty = "solid", lwd = 1, hull = TRUE,
     ellipse = FALSE, conf,
     segments = TRUE, seg.col = "grey", seg.lty = lty, seg.lwd = lwd,
     label = TRUE, label.cex = 1,
     ylab, xlab, main, sub, ...)

## S3 method for class 'betadisper'
boxplot(x, ylab = "Distance to centroid", ...)

## S3 method for class 'betadisper'
TukeyHSD(x, which = "group", ordered = FALSE,
         conf.level = 0.95, ...)

## S3 method for class 'betadisper'
print(x, digits = max(3, getOption("digits") - 3),
                           neigen = 8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betadisper_+3A_d">d</code></td>
<td>
<p>a distance structure such as that returned by 
<code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="#topic+betadiver">betadiver</a></code> or
<code><a href="#topic+vegdist">vegdist</a></code>.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_group">group</code></td>
<td>
<p>vector describing the group structure, usually a factor
or an object that can be coerced to a factor using
<code><a href="base.html#topic+as.factor">as.factor</a></code>. Can consist of a factor with a single
level (i.e., one group).</p>
</td></tr>
<tr><td><code id="betadisper_+3A_type">type</code></td>
<td>
<p>the type of analysis to perform. Use the spatial median or
the group centroid? The spatial median is now the default.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_bias.adjust">bias.adjust</code></td>
<td>
<p>logical: adjust for small sample bias in beta
diversity estimates?</p>
</td></tr>
<tr><td><code id="betadisper_+3A_sqrt.dist">sqrt.dist</code></td>
<td>
<p>Take square root of dissimilarities. This often
euclidifies dissimilarities.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_add">add</code></td>
<td>
<p>Add a constant to the non-diagonal dissimilarities such
that all eigenvalues are non-negative in the underlying Principal
Co-ordinates Analysis (see <code><a href="#topic+wcmdscale">wcmdscale</a></code> for
details). Choice <code>"lingoes"</code> (or <code>TRUE</code>) use the
recommended method of Legendre &amp; Anderson (1999: &ldquo;method
1&rdquo;) and <code>"cailliez"</code> uses their &ldquo;method 2&rdquo;.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_display">display</code></td>
<td>
<p>character; partial match to access scores for
<code>"sites"</code> or <code>"species"</code>.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_object">object</code>, <code id="betadisper_+3A_x">x</code></td>
<td>
<p>an object of class <code>"betadisper"</code>, the result of a
call to <code>betadisper</code>.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_choices">choices</code>, <code id="betadisper_+3A_axes">axes</code></td>
<td>
<p>the principal coordinate axes wanted.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_hull">hull</code></td>
<td>
<p>logical; should the convex hull for each group be plotted?</p>
</td></tr>
<tr><td><code id="betadisper_+3A_ellipse">ellipse</code></td>
<td>
<p>logical; should the standard deviation data ellipse for
each group be plotted?</p>
</td></tr>
<tr><td><code id="betadisper_+3A_conf">conf</code></td>
<td>
<p>Expected fractions of data coverage for data ellipses,
e.g. 0.95. The default is to draw a 1 standard deviation data
ellipse, but if supplied, <code>conf</code> is multiplied with the
corresponding value found from the Chi-squared distribution with 2df
to provide the requested coverage (probability contour).</p>
</td></tr>
<tr><td><code id="betadisper_+3A_pch">pch</code></td>
<td>
<p>plot symbols for the groups, a vector of length equal to
the number of groups.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_col">col</code></td>
<td>
<p>colors for the plot symbols and centroid labels for the groups,
a vector of length equal to the number of groups.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_lty">lty</code>, <code id="betadisper_+3A_lwd">lwd</code></td>
<td>
<p>linetype, linewidth for convex hulls and confidence
ellipses.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_segments">segments</code></td>
<td>
<p>logical; should segments joining points to their
centroid be drawn?</p>
</td></tr>
<tr><td><code id="betadisper_+3A_seg.col">seg.col</code></td>
<td>
<p>colour to draw segments between points and their
centroid. Can be a vector, in which case one colour per group.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_seg.lty">seg.lty</code>, <code id="betadisper_+3A_seg.lwd">seg.lwd</code></td>
<td>
<p>linetype and line width for segments.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_label">label</code></td>
<td>
<p>logical; should the centroids by labelled with their
respective factor label?</p>
</td></tr>
<tr><td><code id="betadisper_+3A_label.cex">label.cex</code></td>
<td>
<p>numeric; character expansion for centroid labels.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_cex">cex</code>, <code id="betadisper_+3A_ylab">ylab</code>, <code id="betadisper_+3A_xlab">xlab</code>, <code id="betadisper_+3A_main">main</code>, <code id="betadisper_+3A_sub">sub</code></td>
<td>
<p>graphical parameters. For details,
see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_which">which</code></td>
<td>
<p>A character vector listing terms in the fitted model for
which the intervals should be calculated. Defaults to the grouping
factor.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_ordered">ordered</code></td>
<td>
<p>logical; see <code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_conf.level">conf.level</code></td>
<td>
<p>A numeric value between zero and one giving the
family-wise confidence level to use.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_digits">digits</code>, <code id="betadisper_+3A_neigen">neigen</code></td>
<td>
<p>numeric; for the <code>print</code> method, sets the
number of digits to use (as per <code><a href="base.html#topic+print.default">print.default</a></code>) and the
maximum number of axes to display eigenvalues for, repsectively.</p>
</td></tr>
<tr><td><code id="betadisper_+3A_...">...</code></td>
<td>
<p>arguments, including graphical parameters (for
<code>plot.betadisper</code> and <code>boxplot.betadisper</code>), passed to
other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One measure of multivariate dispersion (variance) for a group of
samples is to calculate the average distance of group members to the
group centroid or spatial median (both referred to as 'centroid' from
now on unless stated otherwise) in multivariate space. To test if the
dispersions (variances) of one or more groups are different, the
distances of group members to the group centroid are subject to
ANOVA. This is a multivariate analogue of Levene's test for
homogeneity of variances if the distances between group members and
group centroids is the Euclidean distance.
</p>
<p>However, better measures of distance than the Euclidean distance are
available for ecological data. These can be accommodated by reducing
the distances produced using any dissimilarity coefficient to
principal coordinates, which embeds them within a Euclidean space. The
analysis then proceeds by calculating the Euclidean distances between
group members and the group centroid on the basis of the principal
coordinate axes rather than the original distances.
</p>
<p>Non-metric dissimilarity coefficients can produce principal coordinate
axes that have negative Eigenvalues. These correspond to the
imaginary, non-metric part of the distance between objects. If
negative Eigenvalues are produced, we must correct for these imaginary
distances.
</p>
<p>The distance to its centroid of a point is </p>
<p style="text-align: center;"><code class="reqn">z_{ij}^c =
  \sqrt{\Delta^2(u_{ij}^+, c_i^+) - \Delta^2(u_{ij}^-, c_i^-)},</code>
</p>
<p> where
<code class="reqn">\Delta^2</code> is the squared Euclidean distance between
<code class="reqn">u_{ij}</code>, the principal coordinate for the <code class="reqn">j</code>th
point in the <code class="reqn">i</code>th group, and <code class="reqn">c_i</code>, the
coordinate of the centroid for the <code class="reqn">i</code>th group. The
super-scripted &lsquo;<code class="reqn">+</code>&rsquo; and &lsquo;<code class="reqn">-</code>&rsquo; indicate the
real and imaginary parts respectively. This is equation (3) in
Anderson (2006). If the imaginary part is greater in magnitude than
the real part, then we would be taking the square root of a negative
value, resulting in NaN, and these cases are changed to zero distances
(with a warning). This is in line with the behaviour of Marti Anderson's
PERMDISP2 programme.
</p>
<p>To test if one or more groups is more variable than the others, ANOVA
of the distances to group centroids can be performed and parametric
theory used to interpret the significance of <code class="reqn">F</code>. An alternative is to
use a permutation test. <code><a href="#topic+permutest.betadisper">permutest.betadisper</a></code> permutes model
residuals to generate a permutation distribution of <code class="reqn">F</code> under the Null
hypothesis of no difference in dispersion between groups.
</p>
<p>Pairwise comparisons of group mean dispersions can also be performed
using <code><a href="#topic+permutest.betadisper">permutest.betadisper</a></code>. An alternative to the classical
comparison of group dispersions, is to calculate Tukey's Honest
Significant Differences between groups, via
<code>TukeyHSD.betadisper</code>. This is a simple wrapper to
<code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>. The user is directed to read the help file
for <code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code> before using this function. In particular,
note the statement about using the function with 
unbalanced designs.
</p>
<p>The results of the analysis can be visualised using the <code>plot</code>
and <code>boxplot</code> methods.
</p>
<p>One additional use of these functions is in assessing beta diversity
(Anderson <em>et al</em> 2006). Function <code><a href="#topic+betadiver">betadiver</a></code>
provides some popular dissimilarity measures for this purpose.
</p>
<p>As noted in passing by Anderson (2006) and in a related
context by O'Neill (2000), estimates of dispersion around a
central location (median or centroid) that is calculated from the same data
will be biased downward. This bias matters most when comparing diversity
among treatments with small, unequal numbers of samples.  Setting
<code>bias.adjust=TRUE</code> when using <code>betadisper</code> imposes a 
<code class="reqn">\sqrt{n/(n-1)}</code> correction (Stier et al. 2013).
</p>


<h3>Value</h3>

<p>The <code>anova</code> method returns an object of class <code>"anova"</code>
inheriting from class <code>"data.frame"</code>.
</p>
<p>The <code>scores</code> method returns a list with one or both of the
components <code>"sites"</code> and <code>"centroids"</code>.
</p>
<p>The <code>plot</code> function invisibly returns an object of class
<code>"ordiplot"</code>, a plotting structure which can be used by
<code><a href="#topic+identify.ordiplot">identify.ordiplot</a></code> (to identify the points) or other
functions in the <code><a href="#topic+ordiplot">ordiplot</a></code> family. 
</p>
<p>The <code>boxplot</code> function invisibly returns a list whose components
are documented in <code><a href="graphics.html#topic+boxplot">boxplot</a></code>.
</p>
<p><code>eigenvals.betadisper</code> returns a named vector of eigenvalues.
</p>
<p><code>TukeyHSD.betadisper</code> returns a list. See <code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>
for further details.
</p>
<p><code>betadisper</code> returns a list of class <code>"betadisper"</code> with the
following components:
</p>
<table>
<tr><td><code>eig</code></td>
<td>
<p>numeric; the eigenvalues of the principal coordinates
analysis.</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>
<p>matrix; the eigenvectors of the principal coordinates
analysis.</p>
</td></tr>
<tr><td><code>distances</code></td>
<td>
<p>numeric; the Euclidean distances in principal
coordinate space between the samples and their respective group
centroid or median.</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>factor; vector describing the group structure</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p>matrix; the locations of the group centroids or
medians on the principal coordinates.</p>
</td></tr>
<tr><td><code>group.distances</code></td>
<td>
<p>numeric; the mean distance to each group
centroid or median.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched function call.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>Stewart Schultz noticed that the permutation test for
<code>type="centroid"</code> had the wrong type I error and was
anti-conservative. As such, the default for <code>type</code> has been
changed to <code>"median"</code>, which uses the spatial median as the group
centroid. Tests suggests that the permutation test for this type of
analysis gives the correct error rates.
</p>


<h3>Note</h3>

<p>If <code>group</code> consists of a single level or group, then the
<code>anova</code> and <code>permutest</code> methods are not appropriate and if
used on such data will stop with an error.
</p>
<p>Missing values in either <code>d</code> or <code>group</code> will be removed
prior to performing the analysis.
</p>


<h3>Author(s)</h3>

<p>Gavin L. Simpson; bias correction by Adrian Stier and Ben Bolker.</p>


<h3>References</h3>

<p>Anderson, M.J. (2006) Distance-based tests for homogeneity of
multivariate dispersions. <em>Biometrics</em> <strong>62</strong>, 245&ndash;253.
</p>
<p>Anderson, M.J., Ellingsen, K.E. &amp; McArdle, B.H. (2006) Multivariate
dispersion as a measure of beta diversity. <em>Ecology Letters</em>
<strong>9</strong>, 683&ndash;693.
</p>
<p>O'Neill, M.E. (2000) A Weighted Least Squares Approach to Levene's 
Test of Homogeneity of Variance. <em>Australian &amp; New Zealand Journal of 
Statistics</em> <strong>42</strong>, 81-‚Äì100.
</p>
<p>Stier, A.C., Geange, S.W., Hanson, K.M., &amp; Bolker, B.M. (2013) Predator 
density and timing of arrival affect reef fish community
assembly. <em>Ecology</em> <strong>94</strong>, 1057&ndash;1068.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+permutest.betadisper">permutest.betadisper</a></code>, <code><a href="stats.html#topic+anova.lm">anova.lm</a></code>,
<code><a href="#topic+scores">scores</a></code>, <code><a href="graphics.html#topic+boxplot">boxplot</a></code>,
<code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>. Further measure of beta diversity
can be found in <code><a href="#topic+betadiver">betadiver</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)

## Bray-Curtis distances between samples
dis &lt;- vegdist(varespec)

## First 16 sites grazed, remaining 8 sites ungrazed
groups &lt;- factor(c(rep(1,16), rep(2,8)), labels = c("grazed","ungrazed"))

## Calculate multivariate dispersions
mod &lt;- betadisper(dis, groups)
mod

## Perform test
anova(mod)

## Permutation test for F
permutest(mod, pairwise = TRUE, permutations = 99)

## Tukey's Honest Significant Differences
(mod.HSD &lt;- TukeyHSD(mod))
plot(mod.HSD)

## Plot the groups and distances to centroids on the
## first two PCoA axes
plot(mod)

## with data ellipses instead of hulls
plot(mod, ellipse = TRUE, hull = FALSE) # 1 sd data ellipse
plot(mod, ellipse = TRUE, hull = FALSE, conf = 0.90) # 90% data ellipse

# plot with manual colour specification
my_cols &lt;- c("#1b9e77", "#7570b3")
plot(mod, col = my_cols, pch = c(16,17), cex = 1.1)

## can also specify which axes to plot, ordering respected
plot(mod, axes = c(3,1), seg.col = "forestgreen", seg.lty = "dashed")

## Draw a boxplot of the distances to centroid for each group
boxplot(mod)

## `scores` and `eigenvals` also work
scrs &lt;- scores(mod)
str(scrs)
head(scores(mod, 1:4, display = "sites"))
# group centroids/medians 
scores(mod, 1:4, display = "centroids")
# eigenvalues from the underlying principal coordinates analysis
eigenvals(mod) 

## try out bias correction; compare with mod3
(mod3B &lt;- betadisper(dis, groups, type = "median", bias.adjust=TRUE))
anova(mod3B)
permutest(mod3B, permutations = 99)

## should always work for a single group
group &lt;- factor(rep("grazed", NROW(varespec)))
(tmp &lt;- betadisper(dis, group, type = "median"))
(tmp &lt;- betadisper(dis, group, type = "centroid"))

## simulate missing values in 'd' and 'group'
## using spatial medians
groups[c(2,20)] &lt;- NA
dis[c(2, 20)] &lt;- NA
mod2 &lt;- betadisper(dis, groups) ## messages
mod2
permutest(mod2, permutations = 99)
anova(mod2)
plot(mod2)
boxplot(mod2)
plot(TukeyHSD(mod2))

## Using group centroids
mod3 &lt;- betadisper(dis, groups, type = "centroid")
mod3
permutest(mod3, permutations = 99)
anova(mod3)
plot(mod3)
boxplot(mod3)
plot(TukeyHSD(mod3))

</code></pre>

<hr>
<h2 id='betadiver'> Indices of beta Diversity </h2><span id='topic+betadiver'></span><span id='topic+scores.betadiver'></span><span id='topic+plot.betadiver'></span>

<h3>Description</h3>

<p>The function estimates any of the 24 indices of beta diversity
reviewed by Koleff et al. (2003). Alternatively, it finds the
co-occurrence frequencies for triangular plots (Koleff et
al. 2003). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betadiver(x, method = NA, order = FALSE, help = FALSE, ...)
## S3 method for class 'betadiver'
plot(x, ...)
## S3 method for class 'betadiver'
scores(x, triangular = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betadiver_+3A_x">x</code></td>
<td>
<p>Community data matrix, or the <code>betadiver</code> result for
<code>plot</code> and <code>scores</code> functions. </p>
</td></tr>
<tr><td><code id="betadiver_+3A_method">method</code></td>
<td>
<p>The index of beta diversity as defined in Koleff et al.
(2003), Table 1. You can use either the subscript of <code class="reqn">\beta</code> or
the number of the index. See argument <code>help</code> below. </p>
</td></tr>
<tr><td><code id="betadiver_+3A_order">order</code></td>
<td>
<p>Order sites by increasing number of species. This will
influence the configuration in the triangular plot and non-symmetric
indices. </p>
</td></tr>
<tr><td><code id="betadiver_+3A_help">help</code></td>
<td>
<p>Show the numbers, subscript names and the defining
equations of the indices and exit.</p>
</td></tr>
<tr><td><code id="betadiver_+3A_triangular">triangular</code></td>
<td>
<p>Return scores suitable for triangular plotting of
proportions. If <code>FALSE</code>, returns a 3-column matrix of raw counts.</p>
</td></tr>
<tr><td><code id="betadiver_+3A_...">...</code></td>
<td>
<p> Other arguments to functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The most commonly used index of beta diversity is
<code class="reqn">\beta_w = S/\alpha - 1</code>, where <code class="reqn">S</code> is the total number of
species, and <code class="reqn">\alpha</code> is the average number of species per site
(Whittaker 1960). A drawback of this model is that <code class="reqn">S</code> increases
with sample size, but the expectation of <code class="reqn">\alpha</code> remains
constant, and so the beta diversity increases with sample size. A
solution to this problem is to study the beta diversity of pairs of
sites (Marion et al. 2017). If we denote the number of species
shared between two sites as <code class="reqn">a</code> and the numbers of unique
species (not shared) as <code class="reqn">b</code> and <code class="reqn">c</code>, then <code class="reqn">S = a + b +
  c</code> and <code class="reqn">\alpha = (2 a + b + c)/2</code> so that <code class="reqn">\beta_w =
  (b+c)/(2 a + b + c)</code>. This is the S√∏rensen
dissimilarity as defined in <span class="pkg">vegan</span> function
<code><a href="#topic+vegdist">vegdist</a></code> with argument <code>binary = TRUE</code>. Many other
indices are dissimilarity indices as well.
</p>
<p>Function <code>betadiver</code> finds all indices reviewed by Koleff et
al. (2003). All these indices could be found with function
<code><a href="#topic+designdist">designdist</a></code>, but the current function provides a
conventional shortcut. The function only finds the indices. The proper
analysis must be done with functions such as <code><a href="#topic+betadisper">betadisper</a></code>,
<code><a href="#topic+adonis2">adonis2</a></code> or <code><a href="#topic+mantel">mantel</a></code>.
</p>
<p>The indices are directly taken from Table 1 of Koleff et al. (2003),
and they can be selected either by the index number or the subscript
name used by Koleff et al. The numbers, names and defining equations
can be seen using <code>betadiver(help = TRUE)</code>. In all cases where
there are two alternative forms, the one with the term <code class="reqn">-1</code> is
used. There are several duplicate indices, and the number of distinct
alternatives is much lower than 24 formally provided. The formulations
used in functions differ occasionally from those in Koleff et
al. (2003), but they are still mathematically equivalent. With
<code>method = NA</code>, no index is calculated, but instead an object of
class <code>betadiver</code> is returned. This is a list of elements
<code>a</code>, <code>b</code> and <code>c</code>. Function <code>plot</code> can be used to
display the proportions of these elements in triangular plot as
suggested by Koleff et al. (2003), and <code>scores</code> extracts the
triangular coordinates or the raw scores. Function <code>plot</code> returns
invisibly the triangular coordinates as an <code>"<a href="#topic+ordiplot">ordiplot</a>"</code>
object. 
</p>


<h3>Value</h3>

<p> With <code>method = NA</code>, the function returns an object of class
<code>"betadisper"</code> with elements <code>a</code>, <code>b</code>, and <code>c</code>. If
<code>method</code> is specified, the function returns a <code>"dist"</code>
object which can be used in any function analysing
dissimilarities. For beta diversity, particularly useful functions are
<code><a href="#topic+betadisper">betadisper</a></code> to study the betadiversity in groups,
<code><a href="#topic+adonis2">adonis2</a></code> for any model, and <code><a href="#topic+mantel">mantel</a></code> to
compare beta diversities to other dissimilarities or distances
(including geographical distances). Although <code>betadiver</code> returns
a <code>"dist"</code> object, some indices are similarities and cannot be
used as such in place of dissimilarities, but that is a user
error. Functions 10 (<code>"j"</code>), 11 (<code>"sor"</code>) and 21
(<code>"rlb"</code>) are similarity indices. Function sets argument
<code>"maxdist"</code> similarly as <code><a href="#topic+vegdist">vegdist</a></code>, using <code>NA</code>
when there is no fixed upper limit, and 0 for similarities.
</p>


<h3>Warning </h3>

<p>Some indices return similarities instead of dissimilarities.</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>References</h3>

<p>Baselga, A. (2010) Partitioning the turnover and nestedness
components of beta diversity. <em>Global Ecology and Biogeography</em>
19, 134&ndash;143.
</p>
<p>Koleff, P., Gaston, K.J. and Lennon, J.J. (2003) Measuring beta
diversity for presence-absence data. <em>Journal of Animal
Ecology</em> 72, 367&ndash;382.
</p>
<p>Marion, Z.H., Fordyce, J.A. and Fitzpatrick, B.M. (2017) Pairwise
beta diversity resolves an underappreciated source of confusion in
calculating species turnover. <em>Ecology</em> 98, 933&ndash;939.
</p>
<p>Whittaker, R.H. (1960) Vegetation of Siskiyou mountains, Oregon and
California. <em>Ecological Monographs</em> 30, 279&ndash;338.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+designdist">designdist</a></code> can be used to implement all these
functions, and also allows using notation with <code>alpha</code> and
<code>gamma</code> diversities.  <code><a href="#topic+vegdist">vegdist</a></code> has some canned
alternatives.  Functions <code><a href="#topic+betadisper">betadisper</a></code>,
<code><a href="#topic+adonis2">adonis2</a></code> and <code><a href="#topic+mantel">mantel</a></code> can be used for
analysing beta diversity objects. The returned dissimilarities can
be used in any distance-based methods, such as
<code><a href="#topic+metaMDS">metaMDS</a></code>, <code><a href="#topic+capscale">capscale</a></code> and
<code><a href="#topic+dbrda">dbrda</a></code>. Functions <code><a href="#topic+nestedbetasor">nestedbetasor</a></code> and
<code><a href="#topic+nestedbetajac">nestedbetajac</a></code> implement decomposition beta diversity
measures (S√∏rensen and Jaccard) into turnover and
nestedness components following Baselga (2010).  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Raw data and plotting
data(sipoo)
m &lt;- betadiver(sipoo)
plot(m)
## The indices
betadiver(help=TRUE)
## The basic Whittaker index
d &lt;- betadiver(sipoo, "w")
## This should be equal to Sorensen index (binary Bray-Curtis in
## vegan)
range(d - vegdist(sipoo, binary=TRUE))
</code></pre>

<hr>
<h2 id='bgdispersal'> Coefficients of Biogeographical Dispersal Direction </h2><span id='topic+bgdispersal'></span>

<h3>Description</h3>

<p> This function computes coefficients of dispersal direction
between geographically connected areas, as defined by Legendre and
Legendre (1984), and also described in Legendre and Legendre (2012,
section 13.3.4). </p>


<h3>Usage</h3>

<pre><code class='language-R'>bgdispersal(mat, PAonly = FALSE, abc = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bgdispersal_+3A_mat">mat</code></td>
<td>
<p> Data frame or matrix containing a community composition
data table (species presence-absence or abundance data). </p>
</td></tr>
<tr><td><code id="bgdispersal_+3A_paonly">PAonly</code></td>
<td>
 <p><code>FALSE</code> if the four types of coefficients, DD1 to
DD4, are requested; <code>TRUE</code> if <code>DD1</code> and <code>DD2</code> only are
sought (see Details). </p>
</td></tr>
<tr><td><code id="bgdispersal_+3A_abc">abc</code></td>
<td>
<p>If <code>TRUE</code>, return tables <code>a</code>, <code>b</code> and <code>c</code>
used in <code>DD1</code> and <code>DD2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The signs of the DD coefficients indicate the 
direction of dispersal, provided that the 
asymmetry is significant. A positive sign 
indicates dispersal from the first (row in DD 
tables) to the second region (column); a negative 
sign indicates the opposite. A McNemar test of 
asymmetry is computed from the presence-absence 
data to test the hypothesis of a significant 
asymmetry between the two areas under comparison.
</p>
<p>In the input data table, the rows are sites or 
areas, the columns are taxa. Most often, the taxa 
are species, but the coefficients can be computed 
from genera or families as well. DD1 and DD2 only 
are computed for presence-absence data. The four 
types of coefficients are computed for 
quantitative data, which are converted to 
presence-absence for the computation of DD1 and 
DD2. <code>PAonly = FALSE</code> indicates that the four types 
of coefficients are requested. <code>PAonly = TRUE</code> if DD1 
and DD2 only are sought. </p>


<h3>Value</h3>

<p>Function <code>bgdispersal</code> returns a list containing the following matrices:
</p>
<table>
<tr><td><code>DD1</code></td>
<td>
 <p><code class="reqn">DD1_{j,k} = (a(b - c))/((a + b + c)^2)</code> </p>
</td></tr>
<tr><td><code>DD2</code></td>
<td>
 <p><code class="reqn">DD2_{j,k} = (2 a (b - c))/((2a + b + c)  (a + b +
    c))</code>
where <code class="reqn">a</code>, <code class="reqn">b</code>, and <code class="reqn">c</code> have the 
same meaning as in the computation of binary 
similarity coefficients. </p>
</td></tr>
<tr><td><code>DD3</code></td>
<td>
 <p><code class="reqn">DD3_{j,k} = {W(A-B) / (A+B-W)^2} </code> </p>
</td></tr>
<tr><td><code>DD4</code></td>
<td>
 <p><code class="reqn">DD4_{j,k} = 2W(A-B) / ((A+B)(A+B-W))</code>
where <code>W = sum(pmin(vector1, vector2))</code>, <code>A = sum(vector1)</code>,
<code>B = sum(vector2)</code> </p>
</td></tr>
<tr><td><code>McNemar</code></td>
<td>
<p> McNemar chi-square statistic of asymmetry (Sokal and
Rohlf 1995):
<code class="reqn">2(b \log(b) + c \log(c) - (b+c) \log((b+c)/2)) / q</code>,
where <code class="reqn">q = 1 + 1/(2(b+c))</code>
(Williams correction for continuity) </p>
</td></tr>
<tr><td><code>prob.McNemar</code></td>
<td>
<p> probabilities associated 
with McNemar statistics, chi-square test. H0: no 
asymmetry in <code class="reqn">(b-c)</code>. </p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses a more powerful alternative for the McNemar test
than the classical formula. The classical formula was constructed in
the spirit of Pearson's Chi-square, but the formula in this function
was constructed in the spirit of Wilks Chi-square or the <code class="reqn">G</code>
statistic. Function <code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code> uses the classical
formula. The new formula was introduced in <span class="pkg">vegan</span> version
1.10-11, and the older implementations of <code>bgdispersal</code> used the
classical formula.  </p>


<h3>Author(s)</h3>

<p> Pierre Legendre, Departement de Sciences Biologiques,
Universite de Montreal</p>


<h3>References</h3>

 
<p>Legendre, P. and V. Legendre. 1984. Postglacial dispersal of
freshwater fishes in the Qu√©bec
peninsula. <em>Can. J. Fish. Aquat. Sci.</em> <strong>41</strong>: 1781-1802.
</p>
<p>Legendre, P. and L. Legendre. 2012. <em>Numerical ecology</em>, 3rd
English edition. Elsevier Science BV, Amsterdam.
</p>
<p>Sokal, R. R. and F. J. Rohlf. 1995. <em>Biometry. The principles and
practice of statistics in biological research.</em> 3rd
edn. W. H. Freeman, New York. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(c(32,15,14,10,70,30,100,4,10,30,25,0,18,0,40,
  0,0,20,0,0,0,0,4,0,30,20,0,0,0,0,25,74,42,1,45,89,5,16,16,20),
  4, 10, byrow=TRUE)
bgdispersal(mat)
</code></pre>

<hr>
<h2 id='bioenv'>Best Subset of Environmental Variables with
Maximum (Rank) Correlation with Community Dissimilarities </h2><span id='topic+bioenv'></span><span id='topic+bioenv.default'></span><span id='topic+bioenv.formula'></span><span id='topic+summary.bioenv'></span><span id='topic+bioenvdist'></span>

<h3>Description</h3>

<p>Function finds the best subset of environmental variables, so that
the Euclidean distances of scaled environmental variables have the
maximum (rank) correlation with community dissimilarities.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
bioenv(comm, env, method = "spearman", index = "bray",
       upto = ncol(env), trace = FALSE, partial = NULL, 
       metric = c("euclidean", "mahalanobis", "manhattan", "gower"),
       parallel = getOption("mc.cores"), ...)
## S3 method for class 'formula'
bioenv(formula, data, ...)
bioenvdist(x, which = "best")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bioenv_+3A_comm">comm</code></td>
<td>
<p>Community data frame or a dissimilarity object or a square
matrix that can be interpreted as dissimilarities. </p>
</td></tr>
<tr><td><code id="bioenv_+3A_env">env</code></td>
<td>
<p>Data frame of continuous environmental variables. </p>
</td></tr>
<tr><td><code id="bioenv_+3A_method">method</code></td>
<td>
<p>The correlation method used in <code><a href="stats.html#topic+cor">cor</a></code>.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_index">index</code></td>
<td>
<p>The dissimilarity index used for community data (<code>comm</code>) 
in <code><a href="#topic+vegdist">vegdist</a></code>. This is ignored if <code>comm</code> are dissimilarities.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_upto">upto</code></td>
<td>
<p>Maximum number of parameters in studied subsets.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_formula">formula</code>, <code id="bioenv_+3A_data">data</code></td>
<td>
<p>Model <code><a href="stats.html#topic+formula">formula</a></code> and data.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_trace">trace</code></td>
<td>
<p>Trace the calculations </p>
</td></tr>
<tr><td><code id="bioenv_+3A_partial">partial</code></td>
<td>
<p>Dissimilarities partialled out when inspecting
variables in <code>env</code>.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_metric">metric</code></td>
<td>
<p>Metric used for distances of environmental distances. See 
Details.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_x">x</code></td>
<td>
<p><code>bioenv</code> result object.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_which">which</code></td>
<td>
<p>The number of the model for which the environmental
distances are evaluated, or the <code>"best"</code> model.</p>
</td></tr>
<tr><td><code id="bioenv_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="stats.html#topic+cor">cor</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates a community dissimilarity matrix using
<code><a href="#topic+vegdist">vegdist</a></code>.  Then it selects all possible subsets of
environmental variables, <code><a href="base.html#topic+scale">scale</a></code>s the variables, and
calculates Euclidean distances for this subset using
<code><a href="stats.html#topic+dist">dist</a></code>.  The function finds the correlation between
community dissimilarities and environmental distances, and for each
size of subsets, saves the best result.  There are <code class="reqn">2^p-1</code>
subsets of <code class="reqn">p</code> variables, and an exhaustive search may take a
very, very, very long time (parameter <code>upto</code> offers a partial
relief).
</p>
<p>The argument <code>metric</code> defines distances in the given set of
environmental variables.  With <code>metric = "euclidean"</code>, the
variables are scaled to unit variance and Euclidean distances are
calculated. With <code>metric = "mahalanobis"</code>, the Mahalanobis
distances are calculated: in addition to scaling to unit variance,
the matrix of the current set of environmental variables is also
made orthogonal (uncorrelated). With <code>metric = "manhanttan"</code>,
the variables are scaled to unit range and Manhattan distances are
calculated, so that the distances are sums of differences of
environmental variables.  With <code>metric = "gower"</code>, the Gower
distances are calculated using function
<code><a href="cluster.html#topic+daisy">daisy</a></code>. This allows also using factor
variables, but with continuous variables the results are equal to
<code>metric = "manhattan"</code>.
</p>
<p>The function can be called with a model <code><a href="stats.html#topic+formula">formula</a></code> where
the LHS is the data matrix and RHS lists the environmental variables.
The formula interface is practical in selecting or transforming
environmental variables.
</p>
<p>With argument <code>partial</code> you can perform &ldquo;partial&rdquo;
analysis. The partializing item must be a dissimilarity object of
class <code><a href="stats.html#topic+dist">dist</a></code>. The
<code>partial</code> item can be used with any correlation <code>method</code>,
but it is strictly correct only for Pearson.
</p>
<p>Function <code>bioenvdist</code> recalculates the environmental distances
used within the function. The default is to calculate distances for
the best model, but the number of any model can be given.
</p>
<p>Clarke &amp; Ainsworth (1993) suggested this method to be used for
selecting the best subset of environmental variables in interpreting
results of nonmetric multidimensional scaling (NMDS). They recommended a
parallel display of NMDS of community dissimilarities and NMDS of
Euclidean distances from the best subset of scaled environmental
variables.  They warned against the use of Procrustes analysis, but
to me this looks like a good way of comparing these two ordinations.
</p>
<p>Clarke &amp; Ainsworth wrote a computer program BIO-ENV giving the name to
the current function. Presumably BIO-ENV
was later incorporated in Clarke's PRIMER software (available for
Windows).  In addition, Clarke &amp; Ainsworth suggested a novel method of
rank correlation which is not available in the current function.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>bioenv</code> with a
<code>summary</code> method.
</p>


<h3>Note</h3>

<p> If you want to study the &lsquo;significance&rsquo; of <code>bioenv</code>
results, you can use function <code><a href="#topic+mantel">mantel</a></code> or
<code><a href="#topic+mantel.partial">mantel.partial</a></code> which use the same definition of
correlation.  However, <code>bioenv</code> standardizes environmental
variables depending on the used metric, and you must do the same in
<code><a href="#topic+mantel">mantel</a></code> for comparable results (the standardized data are
returned as item <code>x</code> in the result object). It is safest to use
<code>bioenvdist</code> to extract the environmental distances that really
were used within <code>bioenv</code>. NB., <code>bioenv</code> selects variables
to maximize the Mantel correlation, and significance tests based on
<em>a priori</em> selection of variables are biased.  </p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Clarke, K. R &amp; Ainsworth, M. 1993. A method of linking multivariate
community structure to environmental variables. <em>Marine Ecology
Progress Series</em>, 92, 205&ndash;219.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vegdist">vegdist</a></code>, <code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="stats.html#topic+cor">cor</a></code>
for underlying routines, <code><a href="#topic+monoMDS">monoMDS</a></code> and
<code><a href="#topic+metaMDS">metaMDS</a></code> for ordination, <code><a href="#topic+procrustes">procrustes</a></code> for
Procrustes analysis, <code><a href="#topic+protest">protest</a></code> for an alternative, and
<code><a href="#topic+rankindex">rankindex</a></code> for studying alternatives to the default
Bray-Curtis index.</p>


<h3>Examples</h3>

<pre><code class='language-R'># The method is very slow for large number of possible subsets.
# Therefore only 6 variables in this example.
data(varespec)
data(varechem)
sol &lt;- bioenv(wisconsin(varespec) ~ log(N) + P + K + Ca + pH + Al, varechem)
sol
## IGNORE_RDIFF_BEGIN
summary(sol)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='biplot.rda'>PCA biplot</h2><span id='topic+biplot.rda'></span><span id='topic+biplot.cca'></span>

<h3>Description</h3>

<p>Draws a PCA biplot with species scores indicated by biplot arrows
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rda'
biplot(x, choices = c(1, 2), scaling = "species",
       display = c("sites", "species"), type, xlim, ylim, col = c(1,2), 
       const, correlation = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biplot.rda_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+rda">rda</a></code> result object.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_choices">choices</code></td>
<td>
<p>Axes to show.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_scaling">scaling</code></td>
<td>
<p>Scaling for species and site scores. Either species
(<code>2</code>) or site (<code>1</code>) scores are scaled by eigenvalues, and
the other set of scores is left unscaled, or with <code>3</code> both are
scaled symmetrically by square root of eigenvalues. With negative
scaling values in <code>rda</code>, species scores are divided by standard
deviation of each species and multiplied with an equalizing
constant. Unscaled raw scores stored in the result can be accessed
with <code>scaling = 0</code>.
</p>
<p>The type of scores can also be specified as one of <code>"none"</code>,
<code>"sites"</code>, <code>"species"</code>, or <code>"symmetric"</code>, which
correspond to the values <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>
respectively. Argument <code>correlation</code> can be used in combination
with these character descriptions to get the corresponding negative
value.
</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_correlation">correlation</code></td>
<td>
<p>logical; if <code>scaling</code> is a character
description of the scaling type, <code>correlation</code> can be used to
select correlation-like scores for PCA. See argument <code>scaling</code>
for details.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_display">display</code></td>
<td>
<p>Scores shown.  These must some of the alternatives
<code>"species"</code> for species scores, and/or <code>"sites"</code> for site
scores.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_type">type</code></td>
<td>
<p>Type of plot: partial match to <code>text</code>
for text labels, <code>points</code> for points, and <code>none</code> for
setting frames only. If omitted, <code>text</code> is selected for
smaller data sets, and <code>points</code> for larger. Can be of length 2
(e.g. <code>type = c("text", "points")</code>), in which case the first
element describes how species scores are handled, and the second how
site scores are drawn.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_xlim">xlim</code>, <code id="biplot.rda_+3A_ylim">ylim</code></td>
<td>
<p>the x and y limits (min, max) of the plot.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_col">col</code></td>
<td>
<p>Colours used for sites and species (in this order). If only
one colour is given, it is used for both.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_const">const</code></td>
<td>
<p>General scaling constant for <code><a href="#topic+scores.rda">scores.rda</a></code>.</p>
</td></tr>
<tr><td><code id="biplot.rda_+3A_...">...</code></td>
<td>
<p>Other parameters for plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces a plot or biplot of the results of a call to
<code><a href="#topic+rda">rda</a></code>. It is common for the &quot;species&quot; scores in a PCA to
be drawn as biplot arrows that point in the direction of increasing
values for that variable. The <code>biplot.rda</code> function provides a
wrapper to <code>plot.cca</code> to allow the easy production of such a
plot.
</p>
<p><code><a href="#topic+biplot.rda">biplot.rda</a></code> is only suitable for unconstrained models. If
used on an ordination object with constraints, an error is issued.
</p>
<p>If species scores are drawn using <code>"text"</code>, the arrows are drawn
from the origin to 0.85 * species score, whilst the labels are
drawn at the species score. If the type used is <code>"points"</code>, then
no labels are drawn and therefore the arrows are drawn from the origin
to the actual species score.
</p>


<h3>Value</h3>

<p>The <code>plot</code> function returns invisibly a plotting structure which
can be used by <code><a href="#topic+identify.ordiplot">identify.ordiplot</a></code> to identify
the points or other functions in the <code><a href="#topic+ordiplot">ordiplot</a></code> family.
</p>


<h3>Author(s)</h3>

<p>Gavin Simpson, based on <code><a href="#topic+plot.cca">plot.cca</a></code> by Jari Oksanen.</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.cca">plot.cca</a></code>, <code><a href="#topic+rda">rda</a></code> for something to
plot, <code><a href="#topic+ordiplot">ordiplot</a></code> for an alternative plotting routine
and more support functions, and <code><a href="graphics.html#topic+text">text</a></code>,
<code><a href="graphics.html#topic+points">points</a></code> and <code><a href="graphics.html#topic+arrows">arrows</a></code> for the basic routines.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
mod &lt;- rda(dune, scale = TRUE)
biplot(mod, scaling = "symmetric")

## different type for species and site scores
biplot(mod, scaling = "symmetric", type = c("text", "points"))

## We can use ordiplot pipes in R 4.1 to build similar plots with
## flexible control
## Not run: 
if (getRversion() &gt;= "4.1") {
plot(mod, scaling = "symmetric", type="n") |&gt;
   text("sites", cex=0.8) |&gt;
   text("species", arrows=TRUE, length=0.02, col="red", cex=0.6)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='capscale'>[Partial] Distance-based Redundancy Analysis </h2><span id='topic+capscale'></span><span id='topic+dbrda'></span>

<h3>Description</h3>

<p>Distance-based redundancy analysis (dbRDA) is an ordination method
similar to Redundancy Analysis (<code><a href="#topic+rda">rda</a></code>), but it allows
non-Euclidean dissimilarity indices, such as Manhattan or
Bray&ndash;Curtis distance. Despite this non-Euclidean feature, the analysis
is strictly linear and metric. If called with Euclidean distance,
the results are identical to <code><a href="#topic+rda">rda</a></code>, but dbRDA
will be less efficient. Functions <code>capscale</code> and <code>dbrda</code> are
constrained versions of metric scaling, a.k.a. principal coordinates
analysis, which are based on the Euclidean distance but can be used,
and are more useful, with other dissimilarity measures. The functions
can also perform unconstrained principal coordinates analysis,
optionally using extended dissimilarities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>capscale(formula, data, distance = "euclidean", sqrt.dist = FALSE,
    comm = NULL, add = FALSE,  dfun = vegdist, metaMDSdist = FALSE,
    na.action = na.fail, subset = NULL, ...)
dbrda(formula, data, distance = "euclidean", sqrt.dist = FALSE,
    add = FALSE, dfun = vegdist, metaMDSdist = FALSE,
    na.action = na.fail, subset = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="capscale_+3A_formula">formula</code></td>
<td>
<p>Model formula. The function can be called only with the
formula interface. Most usual features of <code><a href="stats.html#topic+formula">formula</a></code> hold,
especially as defined in <code><a href="#topic+cca">cca</a></code> and <code><a href="#topic+rda">rda</a></code>. The
LHS must be either a community data matrix or a dissimilarity matrix,
e.g., from
<code><a href="#topic+vegdist">vegdist</a></code> or <code><a href="stats.html#topic+dist">dist</a></code>.
If the LHS is a data matrix, function <code><a href="#topic+vegdist">vegdist</a></code> or
function given in <code>dfun</code>
will be used to find the dissimilarities. The RHS defines the
constraints. The constraints can be continuous variables or factors,
they can be transformed within the formula, and they can have
interactions as in a typical <code><a href="stats.html#topic+formula">formula</a></code>. The RHS can have a
special term <code>Condition</code> that defines variables to be
&ldquo;partialled out&rdquo; before constraints, just like in <code><a href="#topic+rda">rda</a></code>
or <code><a href="#topic+cca">cca</a></code>. This allows the use of partial dbRDA.</p>
</td></tr>
<tr><td><code id="capscale_+3A_data">data</code></td>
<td>
<p> Data frame containing the variables on the right hand side of
the model formula. </p>
</td></tr>
<tr><td><code id="capscale_+3A_distance">distance</code></td>
<td>
<p>The name of the dissimilarity (or distance) index if
the LHS of the <code>formula</code> is a data frame instead of
dissimilarity matrix.</p>
</td></tr>
<tr><td><code id="capscale_+3A_sqrt.dist">sqrt.dist</code></td>
<td>
<p>Take square roots of dissimilarities. See section
<code>Details</code> below.</p>
</td></tr>
<tr><td><code id="capscale_+3A_comm">comm</code></td>
<td>
<p> Community data frame which will be used for finding
species scores when the LHS of the <code>formula</code> was a
dissimilarity matrix. This is not used if the LHS is a data
frame. If this is not supplied, the &ldquo;species scores&rdquo; are
unavailable when dissimilarities were supplied. N.B., this is
only available in <code>capscale</code>: <code>dbrda</code> does not return
species scores. Function <code><a href="#topic+sppscores">sppscores</a></code> can be used to add
species scores if they are missing.</p>
</td></tr>
<tr><td><code id="capscale_+3A_add">add</code></td>
<td>
<p>Add a constant to the non-diagonal dissimilarities such
that all eigenvalues are non-negative in the underlying Principal
Co-ordinates Analysis (see <code><a href="#topic+wcmdscale">wcmdscale</a></code> for
details). <code>"lingoes"</code> (or <code>TRUE</code>) uses the
recommended method of Legendre &amp; Anderson (1999: &ldquo;method
1&rdquo;) and <code>"cailliez"</code> uses their &ldquo;method 2&rdquo;. The
latter is the only one in <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>.</p>
</td></tr>
<tr><td><code id="capscale_+3A_dfun">dfun</code></td>
<td>
<p>Distance or dissimilarity function used. Any function
returning standard <code>"dist"</code> and taking the index name as the
first argument can be used. </p>
</td></tr>
<tr><td><code id="capscale_+3A_metamdsdist">metaMDSdist</code></td>
<td>
<p>Use <code><a href="#topic+metaMDSdist">metaMDSdist</a></code> similarly as in
<code><a href="#topic+metaMDS">metaMDS</a></code>. This means automatic data transformation and
using extended flexible shortest path dissimilarities (function
<code><a href="#topic+stepacross">stepacross</a></code>) when there are many dissimilarities based on
no shared species.</p>
</td></tr>
<tr><td><code id="capscale_+3A_na.action">na.action</code></td>
<td>
<p>Handling of missing values in constraints or
conditions. The default (<code><a href="stats.html#topic+na.fail">na.fail</a></code>) is to stop
with missing values. Choices <code><a href="stats.html#topic+na.omit">na.omit</a></code> and
<code><a href="stats.html#topic+na.exclude">na.exclude</a></code> delete rows with missing values, but
differ in representation of results. With <code>na.omit</code> only
non-missing site scores are shown, but <code>na.exclude</code> gives
<code>NA</code> for scores of missing observations. Unlike in
<code><a href="#topic+rda">rda</a></code>, no WA scores are available for missing
constraints or conditions.</p>
</td></tr>
<tr><td><code id="capscale_+3A_subset">subset</code></td>
<td>
<p>Subset of data rows. This can be a logical vector
which is <code>TRUE</code> for kept observations, or a logical
expression which can contain variables in the working
environment, <code>data</code> or species names of the community data
(if given in the formula or as <code>comm</code> argument).</p>
</td></tr>
<tr><td><code id="capscale_+3A_...">...</code></td>
<td>
<p>Other parameters passed to underlying functions (e.g.,
<code><a href="#topic+metaMDSdist">metaMDSdist</a></code>).  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functions <code>capscale</code> and <code>dbrda</code> provide two alternative
implementations of dbRDA. Function <code>capscale</code> is based on
Legendre &amp; Anderson (1999): the dissimilarity data are first
ordinated using metric scaling, and the ordination results are
analysed as <code><a href="#topic+rda">rda</a></code>. Function <code>dbrda</code> is based on
McArdle &amp; Anderson (2001) and directly decomposes
dissimilarities. It does not use <code><a href="#topic+rda">rda</a></code> but a parallel
implementation adapted for analysing dissimilarities and returns a
subset of <code><a href="#topic+rda">rda</a></code> items. With Euclidean distances both
results are identical to <code><a href="#topic+rda">rda</a></code>.  Other dissimilarities
may give negative eigenvalues associated with imaginary
axes. Negative eigenvalues are handled differently: <code>capscale</code>
ignores imaginary axes and analyses only real axes with positive
eigenvalues, and <code>dbrda</code> directly analyses dissimilarities and
can give negative eigenvalues in any component.
</p>
<p>If the user supplied a community data frame instead of
dissimilarities, the functions will find dissimilarities using
<code><a href="#topic+vegdist">vegdist</a></code> or distance function given in <code>dfun</code> with
specified <code>distance</code>. The functions will accept distance
objects from <code><a href="#topic+vegdist">vegdist</a></code>, <code><a href="stats.html#topic+dist">dist</a></code>, or any other
method producing compatible objects. The constraining variables can be
continuous or factors or both, they can have interaction terms, or
they can be transformed in the call. Moreover, there can be a
special term <code>Condition</code> just like in <code><a href="#topic+rda">rda</a></code> and
<code><a href="#topic+cca">cca</a></code> so that &ldquo;partial&rdquo; analysis can be performed.
</p>
<p>Function <code>dbrda</code> does not return species scores, and they can
also be missing in <code>capscale</code>, but they can be added after the
analysis using function <code><a href="#topic+sppscores">sppscores</a></code>.
</p>
<p>Non-Euclidean dissimilarities can produce negative eigenvalues
(Legendre &amp; Anderson 1999, McArdle &amp; Anderson 2001).  If there are
negative eigenvalues, the printed output of <code>capscale</code> will add
a column with sums of positive eigenvalues and an item of sum of
negative eigenvalues, and <code>dbrda</code> will add a column giving the
number of real dimensions with positive eigenvalues.  If negative
eigenvalues are disturbing, functions let you to distort the
dissimilarities so that only non-negative eigenvalues will be
produced with argument <code>add = TRUE</code>. Alternatively, with
<code>sqrt.dist = TRUE</code>, square roots of dissimilarities will be
used which may help in avoiding negative eigenvalues (Legendre &amp;
Anderson 1999).
</p>
<p>The functions can be also used to perform ordinary metric scaling
a.k.a. principal coordinates analysis by using a formula with only a
constant on the left hand side, or <code>comm ~ 1</code>. With
<code>metaMDSdist = TRUE</code>, the function can do automatic data
standardization and use extended dissimilarities using function
<code><a href="#topic+stepacross">stepacross</a></code> similarly as in non-metric multidimensional
scaling with <code><a href="#topic+metaMDS">metaMDS</a></code>.
</p>


<h3>Value</h3>

<p>The functions return an object of class <code>capscale</code> or
<code>dbrda</code> which inherits from <code><a href="#topic+rda">rda</a></code>. See
<code><a href="#topic+cca.object">cca.object</a></code> for description of the result object.
</p>


<h3>Note</h3>

<p> The function <code>capscale</code> was originally developed as a
variant of constrained analysis of proximities (Anderson &amp; Willis
2003), but these developments made it similar to dbRDA. However, it
discards the imaginary dimensions with negative eigenvalues and
ordination and significance tests area only based on real dimensions
and positive eigenvalues.
</p>
<p>The inertia is named after the dissimilarity index as defined in the
dissimilarity data, or as <code>unknown distance</code> if such
information is missing. If the largest original dissimilarity was
larger than 4, <code>capscale</code> handles input similarly as <code>rda</code>
and bases its analysis on variance instead of sum of
squares. Keyword <code>mean</code> is added to the inertia in these cases,
e.g. with Euclidean and Manhattan distances.  Inertia is based on
squared index, and keyword <code>squared</code> is added to the name of
distance, unless data were square root transformed (argument
<code>sqrt.dist=TRUE</code>). If an additive constant was used with
argument <code>add</code>, <code>Lingoes</code> or <code>Cailliez adjusted</code> is
added to the the name of inertia, and the value of the constant is
printed.</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Anderson, M.J. &amp; Willis, T.J. (2003). Canonical analysis of principal
coordinates: a useful method of constrained ordination for
ecology. <em>Ecology</em> 84, 511&ndash;525.
</p>
<p>Gower, J.C. (1985). Properties of Euclidean and non-Euclidean
distance matrices. <em>Linear Algebra and its Applications</em> 67, 81&ndash;97.
</p>
<p>Legendre, P. &amp; Anderson, M. J. (1999). Distance-based redundancy
analysis: testing multispecies responses in multifactorial ecological
experiments. <em>Ecological Monographs</em> 69, 1&ndash;24.
</p>
<p>Legendre, P. &amp; Legendre, L. (2012).  <em>Numerical Ecology</em>. 3rd English
Edition. Elsevier.
</p>
<p>McArdle, B.H. &amp; Anderson, M.J. (2001). Fitting multivariate models
to community data: a comment on distance-based redundancy
analysis. <em>Ecology</em> 82, 290&ndash;297.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+plot.cca">plot.cca</a></code>,
<code><a href="#topic+anova.cca">anova.cca</a></code>, <code><a href="#topic+vegdist">vegdist</a></code>,
<code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, <code><a href="#topic+wcmdscale">wcmdscale</a></code>
for underlying and related functions. Function <code><a href="#topic+sppscores">sppscores</a></code>
can add species scores or replace existing species scores.
</p>
<p>The function returns similar result object as <code><a href="#topic+rda">rda</a></code> (see
<code><a href="#topic+cca.object">cca.object</a></code>). This section for <code><a href="#topic+rda">rda</a></code> gives a
more complete list of functions that can be used to access and
analyse dbRDA results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
## Basic Analysis
vare.cap &lt;- capscale(varespec ~ N + P + K + Condition(Al), varechem,
                     dist="bray")
vare.cap
plot(vare.cap)
anova(vare.cap)
## Avoid negative eigenvalues with additive constant
capscale(varespec ~ N + P + K + Condition(Al), varechem,
                     dist="bray", add =TRUE)
## Avoid negative eigenvalues by taking square roots of dissimilarities
capscale(varespec ~ N + P + K + Condition(Al), varechem,
                     dist = "bray", sqrt.dist= TRUE)
## Principal coordinates analysis with extended dissimilarities
capscale(varespec ~ 1, dist="bray", metaMDS = TRUE)
## dbrda
dbrda(varespec ~ N + P + K + Condition(Al), varechem,
                     dist="bray")
## avoid negative eigenvalues also with Jaccard distances
dbrda(varespec ~ N + P + K + Condition(Al), varechem,
                     dist="jaccard")
</code></pre>

<hr>
<h2 id='cascadeKM'>K-means partitioning using a range of values of K</h2><span id='topic+cascadeKM'></span><span id='topic+cIndexKM'></span><span id='topic+plot.cascadeKM'></span><span id='topic+orderingKM'></span><span id='topic+pregraphKM'></span>

<h3>Description</h3>

<p>This function is a wrapper for the <code>kmeans</code> function. It creates
several partitions forming a cascade from a small to a large number of
groups. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cascadeKM(data, inf.gr, sup.gr, iter = 100, criterion = "calinski",
  parallel = getOption("mc.cores"))

cIndexKM(y, x, index = "all")

## S3 method for class 'cascadeKM'
plot(x, min.g, max.g, grpmts.plot = TRUE, 
     sortg = FALSE, gridcol = NA, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cascadeKM_+3A_data">data</code></td>
<td>
<p> The data matrix. The objects (samples) are the rows.</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_inf.gr">inf.gr</code></td>
<td>
<p> The number of groups for the partition with the 
smallest number of groups of the cascade (min).</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_sup.gr">sup.gr</code></td>
<td>
<p> The number of groups for the partition with the largest 	
number of groups of the cascade (max).</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_iter">iter</code></td>
<td>
<p> The number of random starting configurations for each value
of <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_criterion">criterion</code></td>
<td>
<p> The criterion that will be used to select the best
partition. The default value is <code>"calinski"</code>, which refers to
the Calinski-Harabasz (1974) criterion. The simple structure index
(<code>"ssi"</code>) is also available. Other indices are available in
package <span class="pkg">cclust</span>. In
our experience, the two indices that work best and are most likely
to return their maximum value at or near the optimal number of
clusters are <code>"calinski"</code> and <code>"ssi"</code>. </p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_y">y</code></td>
<td>
<p>Object of class <code>"kmeans"</code> returned by a clustering algorithm
such as <code><a href="stats.html#topic+kmeans">kmeans</a></code></p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_x">x</code></td>
<td>
<p>Data matrix where columns correspond to variables and rows to
observations, or the plotting object in <code>plot</code></p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_index">index</code></td>
<td>
<p>The available indices are: <code>"calinski"</code> and <code>"ssi"</code>. 
Type <code>"all"</code> to obtain both indices. 
Abbreviations of these names are also accepted.</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_min.g">min.g</code>, <code id="cascadeKM_+3A_max.g">max.g</code></td>
<td>
<p>The minimum and maximum numbers of groups to be
displayed.</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_grpmts.plot">grpmts.plot</code></td>
<td>
<p>Show the plot (<code>TRUE</code> or <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_sortg">sortg</code></td>
<td>
<p>Sort the objects as a function of their group membership
to produce a more easily interpretable graph. See Details. The
original object names are kept; they are used as labels in the
output table <code>x</code>, although not in the graph.  If there were no
row names, sequential row numbers are used to keep track of the
original order of the objects.</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_gridcol">gridcol</code></td>
<td>
<p>The colour of the grid lines in the plots. <code>NA</code>,
which is the default value, removes the grid lines.</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_...">...</code></td>
<td>
<p>Other parameters to the functions (ignored).</p>
</td></tr>
<tr><td><code id="cascadeKM_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates several partitions forming a cascade from a small
to a large number of groups formed by <code><a href="stats.html#topic+kmeans">kmeans</a></code>.  Most
of the work is performed by function <code>cIndex</code> which is based on the
<code>clustIndex</code> in package <span class="pkg">cclust</span>). 
Some of the criteria were removed from this version because computation 
errors were generated when only one object was found in a group.
</p>
<p>The default value is <code>"calinski"</code>, which refers to the well-known
Calinski-Harabasz (1974) criterion. The other available index is the
simple structure index <code>"ssi"</code> (Dolnicar et al. 1999).
In the case of groups of equal
sizes, <code>"calinski"</code> is generally a good criterion to indicate the
correct number of groups. Users should not take its indications
literally when the groups are not equal in size. Type <code>"all"</code> to
obtain  both indices. The indices are defined as: 
</p>

<dl>
<dt>calinski:</dt><dd>
<p><code class="reqn">(SSB/(K-1))/(SSW/(n-K))</code>, where <code class="reqn">n</code> is the
number of data points and <code class="reqn">K</code> is the number of clusters.
<code class="reqn">SSW</code> is the sum of squares within the clusters while
<code class="reqn">SSB</code> is the sum of squares among the clusters. This index
is simply an <code class="reqn">F</code> (ANOVA) statistic.</p>
</dd>
<dt>ssi:</dt><dd>
<p>the &ldquo;Simple Structure Index&rdquo; multiplicatively combines
several elements which influence the interpretability of a
partitioning solution. The best partition is indicated by the
highest SSI value.</p>
</dd>
</dl>

<p>In a simulation study, Milligan and Cooper (1985) found
that the Calinski-Harabasz criterion recovered the correct number of
groups the most often. We recommend this criterion because, if the
groups are of equal sizes, the maximum value of <code>"calinski"</code>
usually indicates the correct number of groups. Another available
index is the simple structure index <code>"ssi"</code>. Users should not
take the indications of these indices literally when the groups are
not equal in size and explore the groups corresponding to other values
of <code class="reqn">K</code>.
</p>
<p>Function <code>cascadeKM</code> has a <code>plot</code> method.  Two plots are
produced. The graph on the left has the objects in 
abscissa and the number of groups in ordinate. The groups are
represented by colours. The graph on the right shows the values of the
criterion (<code>"calinski"</code> or <code>"ssi"</code>) for determining the best
partition. The highest value of the criterion is marked in red. Points
marked in orange, if any, indicate partitions producing an increase in
the criterion value as the number of groups increases; they may
represent other interesting partitions.
</p>
<p>If <code>sortg=TRUE</code>, the objects are reordered by the following
procedure: (1) a simple matching distance matrix is computed among the
objects, based on the table of K-means assignments to groups, from
<code class="reqn">K</code> = <code>min.g</code> to <code class="reqn">K</code> = <code>max.g</code>. (2) A principal
coordinate analysis (PCoA, Gower 1966) is computed on the centred
distance matrix. (3) The first principal coordinate is used as the new
order of the objects in the graph. A simplified algorithm is used to
compute the first principal coordinate only, using the iterative
algorithm described in Legendre &amp; Legendre (2012). The
full distance matrix among objects is never computed; this avoids
the problem of storing it when the number of objects is
large. Distance values are computed as they are needed by the
algorithm.
</p>


<h3>Value</h3>

<p> Function <code>cascadeKM</code> returns an object of class
<code>cascadeKM</code> with items:
</p>
<table>
<tr><td><code>partition</code></td>
<td>
<p> Table with the partitions found for different numbers 
of groups <code class="reqn">K</code>, from <code class="reqn">K</code> = <code>inf.gr</code> to <code class="reqn">K</code> =
<code>sup.gr</code>. </p>
</td></tr> 
<tr><td><code>results</code></td>
<td>
<p> Values of the criterion to select the best
partition. </p>
</td></tr> 
<tr><td><code>criterion</code></td>
<td>
<p> The name of the criterion used. </p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p> The number of objects found in each group, for all 
partitions (columns). </p>
</td></tr>
</table>
<p>Function <code>cIndex</code> returns a vector with the index values. The
maximum value of these indices is supposed to indicate the best
partition. These indices work best with groups of equal sizes. When
the groups are not of equal sizes, one should not put too much faith
in the maximum of these indices, and also explore the groups
corresponding to other values of <code class="reqn">K</code>.
</p>


<h3>Author(s)</h3>

<p> Marie-Helene Ouellette
<a href="mailto:Marie-Helene.Ouellette@UMontreal.ca">Marie-Helene.Ouellette@UMontreal.ca</a>, Sebastien Durand
<a href="mailto:Sebastien.Durand@UMontreal.ca">Sebastien.Durand@UMontreal.ca</a> and Pierre Legendre
<a href="mailto:Pierre.Legendre@UMontreal.ca">Pierre.Legendre@UMontreal.ca</a>. Parallel processing by Virgilio
G√≥mez-Rubio.  Edited for <span class="pkg">vegan</span> by Jari Oksanen.  </p>


<h3>References</h3>

<p>Calinski, T. and J. Harabasz. 1974. A dendrite method for cluster
analysis. <em>Commun. Stat.</em> <strong>3</strong>: 1&ndash;27.
</p>
<p>Dolnicar, S., K. Grabler and J. A. Mazanec. 1999.  A tale of three
cities: perceptual charting for analyzing destination images. Pp.
39-62 in: Woodside, A. et al. [eds.] <em>Consumer psychology of
tourism, hospitality and leisure</em>. CAB International, New York.
</p>
<p>Gower, J. C. 1966. Some distance properties of latent root and vector
methods used in multivariate analysis. <em>Biometrika</em> <strong>53</strong>:
325&ndash;338.
</p>
<p>Legendre, P. &amp; L. Legendre. 2012. <em>Numerical ecology</em>, 3rd
English edition. Elsevier Science BV, Amsterdam.
</p>
<p>Milligan, G. W. &amp; M. C. Cooper. 1985. An examination of procedures for
determining the number of clusters in a data set. <em>Psychometrika</em>
<strong>50</strong>: 159&ndash;179.
</p>
<p>Weingessel, A., Dimitriadou, A. and Dolnicar, S. 2002. An examination
of indexes for determining the number of clusters in binary data
sets. <em>Psychometrika</em> <strong>67</strong>: 137&ndash;160.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Partitioning a (10 x 10) data matrix of random numbers
 mat &lt;- matrix(runif(100),10,10)
 res &lt;- cascadeKM(mat, 2, 5, iter = 25, criterion = 'calinski') 
 toto &lt;- plot(res)
 
 # Partitioning an autocorrelated time series
 vec &lt;- sort(matrix(runif(30),30,1))
 res &lt;- cascadeKM(vec, 2, 5, iter = 25, criterion = 'calinski')
 toto &lt;- plot(res)
 
 # Partitioning a large autocorrelated time series
 # Note that we remove the grid lines
 vec &lt;- sort(matrix(runif(1000),1000,1))
 res &lt;- cascadeKM(vec, 2, 7, iter = 10, criterion = 'calinski')
 toto &lt;- plot(res, gridcol=NA)
 
</code></pre>

<hr>
<h2 id='cca'> [Partial] [Constrained] Correspondence Analysis and Redundancy
Analysis </h2><span id='topic+cca'></span><span id='topic+cca.default'></span><span id='topic+cca.formula'></span><span id='topic+rda'></span><span id='topic+rda.default'></span><span id='topic+rda.formula'></span>

<h3>Description</h3>

<p>Function <code>cca</code> performs correspondence analysis, or optionally
constrained correspondence analysis (a.k.a. canonical correspondence
analysis), or optionally partial constrained correspondence
analysis. Function <code>rda</code> performs redundancy analysis, or
optionally principal components analysis.
These are all very popular ordination techniques in community ecology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
cca(formula, data, na.action = na.fail, subset = NULL,
  ...)
## S3 method for class 'formula'
rda(formula, data, scale=FALSE, na.action = na.fail,
  subset = NULL, ...)
## Default S3 method:
cca(X, Y, Z, ...)
## Default S3 method:
rda(X, Y, Z, scale=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cca_+3A_formula">formula</code></td>
<td>
<p>Model formula, where the left hand side gives the
community data matrix, right hand side gives the constraining variables,
and conditioning variables can be given within a special function
<code>Condition</code>.</p>
</td></tr>
<tr><td><code id="cca_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables on the right hand side
of the model formula.</p>
</td></tr>
<tr><td><code id="cca_+3A_x">X</code></td>
<td>
<p> Community data matrix. </p>
</td></tr>
<tr><td><code id="cca_+3A_y">Y</code></td>
<td>
<p> Constraining matrix, typically of environmental variables.
Can be missing. If this is a <code>data.frame</code>, it will be
expanded to a <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> where factors are
expanded to contrasts (&ldquo;dummy variables&rdquo;). It is better to
use <code>formula</code> instead of this argument, and some further
analyses only work when <code>formula</code> was used.</p>
</td></tr>
<tr><td><code id="cca_+3A_z">Z</code></td>
<td>
<p> Conditioning matrix, the effect of which is removed
(&ldquo;partialled out&rdquo;) before next step. Can be missing. If this is a
<code>data.frame</code>, it is expanded similarly as constraining
matrix.</p>
</td></tr>
<tr><td><code id="cca_+3A_scale">scale</code></td>
<td>
<p>Scale species to unit variance (like correlations).</p>
</td></tr>
<tr><td><code id="cca_+3A_na.action">na.action</code></td>
<td>
<p>Handling of missing values in constraints or
conditions. The default (<code><a href="stats.html#topic+na.fail">na.fail</a></code>) is to stop with
missing value. Choice <code><a href="stats.html#topic+na.omit">na.omit</a></code> removes all rows with
missing values. Choice <code><a href="stats.html#topic+na.exclude">na.exclude</a></code> keeps all
observations but gives <code>NA</code> for results that cannot be
calculated. The WA scores of rows may be found also for missing
values in constraints. Missing values are never allowed in
dependent community data. </p>
</td></tr>
<tr><td><code id="cca_+3A_subset">subset</code></td>
<td>
<p>Subset of data rows. This can be a logical vector which
is <code>TRUE</code> for kept observations, or a logical expression which
can contain variables in the working environment, <code>data</code> or
species names of the community data.</p>
</td></tr>
<tr><td><code id="cca_+3A_...">...</code></td>
<td>
<p>Other arguments for <code>print</code> or <code>plot</code> functions
(ignored in other functions).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since their introduction (ter Braak 1986), constrained, or canonical,
correspondence analysis and its spin-off, redundancy analysis, have
been the most popular ordination methods in community ecology.
Functions <code>cca</code> and <code>rda</code> are  similar to popular
proprietary software <code>Canoco</code>, although the implementation is
completely different.  The functions are based on Legendre &amp;
Legendre's (2012) algorithm: in <code>cca</code>
Chi-square transformed data matrix is subjected to weighted linear
regression on constraining variables, and the fitted values are
submitted to correspondence analysis performed via singular value
decomposition (<code><a href="base.html#topic+svd">svd</a></code>). Function <code>rda</code> is similar, but uses
ordinary, unweighted linear regression and unweighted SVD. Legendre &amp;
Legendre (2012), Table 11.5 (p. 650) give a skeleton of the RDA
algorithm of <span class="pkg">vegan</span>. The algorithm of CCA is similar, but
involves standardization by row and column weights.
</p>
<p>The functions can be called either with matrix-like entries for
community data and constraints, or with formula interface.  In
general, the formula interface is preferred, because it allows a
better control of the model and allows factor constraints. Some
analyses of ordination results are only possible if model was fitted
with formula (e.g., most cases of <code><a href="#topic+anova.cca">anova.cca</a></code>, automatic
model building).
</p>
<p>In the following sections, <code>X</code>, <code>Y</code> and <code>Z</code>, although
referred to as matrices, are more commonly data frames.
</p>
<p>In the matrix interface, the
community data matrix <code>X</code> must be given, but the other data
matrices may be omitted, and the corresponding stage of analysis is
skipped.  If matrix <code>Z</code> is supplied, its effects are removed from
the community matrix, and the residual matrix is submitted to the next
stage.  This is called partial correspondence or redundancy
analysis.  If matrix
<code>Y</code> is supplied, it is used to constrain the ordination,
resulting in constrained or canonical correspondence analysis, or
redundancy analysis.
Finally, the residual is submitted to ordinary correspondence
analysis (or principal components analysis).  If both matrices
<code>Z</code> and <code>Y</code> are missing, the
data matrix is analysed by ordinary correspondence analysis (or
principal components analysis).
</p>
<p>Instead of separate matrices, the model can be defined using a model
<code><a href="stats.html#topic+formula">formula</a></code>.  The left hand side must be the
community data matrix (<code>X</code>).  The right hand side defines the
constraining model.
The constraints can contain ordered or unordered factors,
interactions among variables and functions of variables.  The defined
<code><a href="stats.html#topic+contrasts">contrasts</a></code> are honoured in <code><a href="base.html#topic+factor">factor</a></code>
variables.  The constraints can also be matrices (but not data
frames).
The formula can include a special term <code>Condition</code>
for conditioning variables (&ldquo;covariables&rdquo;) partialled out before
analysis.  So the following commands are equivalent:
<code>cca(X, Y, Z)</code>,  <code>cca(X ~ Y + Condition(Z))</code>, where <code>Y</code>
and <code>Z</code> refer to constraints and conditions matrices respectively.
</p>
<p>Constrained correspondence analysis is indeed a constrained method:
CCA does not try to display all variation in the
data, but only the part that can be explained by the used constraints.
Consequently, the results are strongly dependent on the set of
constraints and their transformations or interactions among the
constraints.  The shotgun method is to use all environmental variables
as constraints.  However, such exploratory problems are better
analysed with
unconstrained methods such as correspondence analysis
(<code><a href="#topic+decorana">decorana</a></code>, <code><a href="MASS.html#topic+corresp">corresp</a></code>) or non-metric
multidimensional scaling (<code><a href="#topic+metaMDS">metaMDS</a></code>) and
environmental interpretation after analysis
(<code><a href="#topic+envfit">envfit</a></code>, <code><a href="#topic+ordisurf">ordisurf</a></code>).
CCA is a good choice if the user has
clear and strong <em>a priori</em> hypotheses on constraints and is not
interested in the major structure in the data set.  
</p>
<p>CCA is able to correct the curve artefact commonly found in
correspondence analysis by forcing the configuration into linear
constraints.  However, the curve artefact can be avoided only with a
low number of constraints that do not have a curvilinear relation with
each other.  The curve can reappear even with two badly chosen
constraints or a single factor.  Although the formula interface makes it
easy to include polynomial or interaction terms, such terms often
produce curved artefacts (that are difficult to interpret), these
should probably be avoided.
</p>
<p>According to folklore, <code>rda</code> should be used with &ldquo;short
gradients&rdquo; rather than <code>cca</code>. However, this is not based
on research which finds methods based on Euclidean metric as uniformly
weaker than those based on Chi-squared metric.  However, standardized
Euclidean distance may be an appropriate measures (see Hellinger
standardization in <code><a href="#topic+decostand">decostand</a></code> in particular).
</p>
<p>Partial CCA (pCCA; or alternatively partial RDA) can be used to remove
the effect of some
conditioning or background or random variables or
covariables before CCA proper.  In fact, pCCA compares models
<code>cca(X ~ Z)</code> and <code>cca(X ~ Y + Z)</code> and attributes their
difference to the effect of <code>Y</code> cleansed of the effect of
<code>Z</code>.  Some people have used the method for extracting
&ldquo;components of variance&rdquo; in CCA.  However, if the effect of
variables together is stronger than sum of both separately, this can
increase total Chi-square after partialling out some
variation, and give negative &ldquo;components of variance&rdquo;.  In general,
such components of &ldquo;variance&rdquo; are not to be trusted due to
interactions between two sets of variables.
</p>
<p>The functions have <code>summary</code> and <code>plot</code> methods which are
documented separately (see <code><a href="#topic+plot.cca">plot.cca</a></code>, <code><a href="#topic+summary.cca">summary.cca</a></code>).
</p>


<h3>Value</h3>

<p>Function <code>cca</code> returns a huge object of class <code>cca</code>, which
is described separately in <code><a href="#topic+cca.object">cca.object</a></code>.
</p>
<p>Function <code>rda</code> returns an object of class <code>rda</code> which
inherits from class <code>cca</code> and is described in <code><a href="#topic+cca.object">cca.object</a></code>.
The scaling used in <code>rda</code> scores is described in a separate
vignette with this package.
</p>


<h3>Author(s)</h3>

<p>The responsible author was Jari Oksanen, but the code borrows heavily
from Dave Roberts (Montana State University, USA).
</p>


<h3>References</h3>

<p> The original method was by ter Braak, but the current
implementation follows Legendre and Legendre.
</p>
<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd English
ed. Elsevier.
</p>
<p>McCune, B. (1997) Influence of noisy environmental data on canonical
correspondence analysis. <em>Ecology</em> <strong>78</strong>, 2617-2623.
</p>
<p>Palmer, M. W. (1993) Putting things in even better order: The
advantages of canonical correspondence analysis.  <em>Ecology</em>
<strong>74</strong>,2215-2230. 
</p>
<p>Ter Braak, C. J. F. (1986) Canonical Correspondence Analysis: a new
eigenvector technique for multivariate direct gradient
analysis. <em>Ecology</em> <strong>67</strong>, 1167-1179.
</p>


<h3>See Also</h3>

<p>This help page describes two constrained ordination functions,
<code>cca</code> and <code>rda</code>.  A related method, distance-based
redundancy analysis (dbRDA) is described separately
(<code><a href="#topic+capscale">capscale</a></code>). All these functions return similar objects
(described in <code><a href="#topic+cca.object">cca.object</a></code>). There are numerous support
functions that can be used to access the result object. In the list
below, functions of type <code>cca</code> will handle all three constrained
ordination objects, and functions of <code>rda</code> only handle <code>rda</code>
and <code><a href="#topic+capscale">capscale</a></code> results.
</p>
<p>The main plotting functions are <code><a href="#topic+plot.cca">plot.cca</a></code> for all
methods, and <code><a href="#topic+biplot.rda">biplot.rda</a></code> for RDA and dbRDA.  However,
generic <span class="pkg">vegan</span> plotting functions can also handle the results.
The scores can be accessed and scaled with <code><a href="#topic+scores.cca">scores.cca</a></code>,
and summarized with <code><a href="#topic+summary.cca">summary.cca</a></code>. The eigenvalues can
be accessed with <code><a href="#topic+eigenvals.cca">eigenvals.cca</a></code> and the regression
coefficients for constraints with <code><a href="#topic+coef.cca">coef.cca</a></code>.  The
eigenvalues can be plotted with <code><a href="#topic+screeplot.cca">screeplot.cca</a></code>, and the
(adjusted) <code class="reqn">R^2</code> can be found with
<code><a href="#topic+RsquareAdj.rda">RsquareAdj.rda</a></code>. The scores can be also calculated for
new data sets with <code><a href="#topic+predict.cca">predict.cca</a></code> which allows adding
points to ordinations.  The values of constraints can be inferred
from ordination and community composition with
<code><a href="#topic+calibrate.cca">calibrate.cca</a></code>.
</p>
<p>Diagnostic statistics can be found with <code><a href="#topic+goodness.cca">goodness.cca</a></code>,
<code><a href="#topic+inertcomp">inertcomp</a></code>, <code><a href="#topic+spenvcor">spenvcor</a></code>,
<code><a href="#topic+intersetcor">intersetcor</a></code>, <code><a href="#topic+tolerance.cca">tolerance.cca</a></code>, and
<code><a href="#topic+vif.cca">vif.cca</a></code>.  Function <code><a href="#topic+as.mlm.cca">as.mlm.cca</a></code> refits the
result object as a multiple <code><a href="stats.html#topic+lm">lm</a></code> object, and this allows
finding influence statistics (<code><a href="stats.html#topic+lm.influence">lm.influence</a></code>,
<code><a href="stats.html#topic+cooks.distance">cooks.distance</a></code> etc.).
</p>
<p>Permutation based significance for the overall model, single
constraining variables or axes can be found with
<code><a href="#topic+anova.cca">anova.cca</a></code>.  Automatic model building with <span class="rlang"><b>R</b></span>
<code><a href="stats.html#topic+step">step</a></code> function is possible with
<code><a href="#topic+deviance.cca">deviance.cca</a></code>, <code><a href="#topic+add1.cca">add1.cca</a></code> and
<code><a href="#topic+drop1.cca">drop1.cca</a></code>.  Functions <code><a href="#topic+ordistep">ordistep</a></code> and
<code><a href="#topic+ordiR2step">ordiR2step</a></code> (for RDA) are special functions for
constrained ordination. Randomized data sets can be generated with
<code><a href="#topic+simulate.cca">simulate.cca</a></code>.
</p>
<p>Separate methods based on constrained ordination model are principal
response curves (<code><a href="#topic+prc">prc</a></code>) and variance partitioning between
several components (<code><a href="#topic+varpart">varpart</a></code>).
</p>
<p>Design decisions are explained in <code><a href="utils.html#topic+vignette">vignette</a></code>
on &ldquo;Design decisions&rdquo; which can be accessed with
<code>browseVignettes("vegan")</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
## Common but bad way: use all variables you happen to have in your
## environmental data matrix
vare.cca &lt;- cca(varespec, varechem)
vare.cca
plot(vare.cca)
## Formula interface and a better model
vare.cca &lt;- cca(varespec ~ Al + P*(K + Baresoil), data=varechem)
vare.cca
plot(vare.cca)
## Partialling out and negative components of variance
cca(varespec ~ Ca, varechem)
cca(varespec ~ Ca + Condition(pH), varechem)
## RDA
data(dune)
data(dune.env)
dune.Manure &lt;- rda(dune ~ Manure, dune.env)
plot(dune.Manure) 
</code></pre>

<hr>
<h2 id='cca.object'>Result Object from Constrained Ordination</h2><span id='topic+cca.object'></span><span id='topic+ordConstrained'></span><span id='topic+ordiYbar'></span><span id='topic+model.matrix.cca'></span><span id='topic+model.matrix.rda'></span><span id='topic+model.frame.cca'></span><span id='topic+weights.cca'></span><span id='topic+weights.rda'></span><span id='topic+weights.decorana'></span><span id='topic+print.cca'></span>

<h3>Description</h3>

<p>Ordination methods <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>,
<code><a href="#topic+dbrda">dbrda</a></code> and <code><a href="#topic+capscale">capscale</a></code> return similar result
objects. All these methods use the same internal function
<code>ordConstrained</code>. They differ only in (1) initial
transformation of the data and in defining inertia, (2) weighting,
and (3) the use of rectangular rows <code class="reqn">\times</code> columns data or
symmetric rows <code class="reqn">\times</code> rows dissimilarities:
<code><a href="#topic+rda">rda</a></code> initializes data to give variance or correlations
as inertia, <code><a href="#topic+cca">cca</a></code> is based on double-standardized data
to give Chi-square inertia and uses row and column weights,
<code><a href="#topic+capscale">capscale</a></code> maps the real part of dissimilarities to
rectangular data and performs RDA, and <code><a href="#topic+dbrda">dbrda</a></code> performs
an RDA-like analysis directly on symmetric dissimilarities.
</p>
<p>Function <code>ordConstrained</code> returns the same result components
for all these methods, and the calling function may add some more
components to the final result. However, you should not access these
result components directly (using <code>$</code>): the internal structure
is not regarded as stable application interface (API), but it can
change at any release. If you access the results components
directly, you take a risk of breakage at any <span class="pkg">vegan</span> release.
The <span class="pkg">vegan</span> provides a wide set of accessor functions to those
components, and these functions are updated when the result object
changes. This documentation gives an overview of accessor functions
to the <code>cca</code> result object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ordiYbar(x, model = c("CCA", "CA", "pCCA", "partial", "initial"))
## S3 method for class 'cca'
model.frame(formula, ...)
## S3 method for class 'cca'
model.matrix(object, ...)
## S3 method for class 'cca'
weights(object, display = "sites", ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cca.object_+3A_object">object</code>, <code id="cca.object_+3A_x">x</code>, <code id="cca.object_+3A_formula">formula</code></td>
<td>
<p>A result object from <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code>, or
<code><a href="#topic+capscale">capscale</a></code>. </p>
</td></tr>
<tr><td><code id="cca.object_+3A_model">model</code></td>
<td>
<p>Show constrained (<code>"CCA"</code>), unconstrained
(<code>"CA"</code>) or conditioned &ldquo;partial&rdquo; (<code>"pCCA"</code>)
results. In <code>ordiYbar</code> the value can also be <code>"initial"</code>
for the internal working input data, and <code>"partial"</code> for the
internal working input data after removing the partial effects.</p>
</td></tr>
<tr><td><code id="cca.object_+3A_display">display</code></td>
<td>
<p>Display either <code>"sites"</code> or <code>"species"</code>.</p>
</td></tr>
<tr><td><code id="cca.object_+3A_...">...</code></td>
<td>
<p>Other arguments passed to the the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The internal (&ldquo;working&rdquo;) form of the dependent (community)
data can be accessed with function <code>ordiYbar</code>. The form depends
on the ordination method: for instance, in <code><a href="#topic+cca">cca</a></code> the
data are weighted and Chi-square transformed, and in
<code><a href="#topic+dbrda">dbrda</a></code> they are Gower-centred dissimilarities. The
input data in the original (&ldquo;response&rdquo;) form can be accessed
with <code><a href="#topic+fitted.cca">fitted.cca</a></code> and <code><a href="#topic+residuals.cca">residuals.cca</a></code>.
Function <code><a href="#topic+predict.cca">predict.cca</a></code> can return either working or
response data, and also their lower-rank approximations.
</p>
<p>The model matrix of independent data (&ldquo;Constraints&rdquo; and
&ldquo;Conditions&rdquo;) can be extracted with <code>model.matrix</code>. In
partial analysis, the function returns a list of design matrices
called <code>Conditions</code> and <code>Constraints</code>. If either component
was missing, a single matrix is returned. The redundant (aliased)
terms do not appear in the model matrix. These terms can be found
with <code><a href="#topic+alias.cca">alias.cca</a></code>. Function <code>model.frame</code> tries to
reconstruct the data frame from which the model matrices were
derived. This is only possible if the original model was fitted with
<code>formula</code> and <code>data</code> arguments, and still fails if the
<code>data</code> are unavailable.
</p>
<p>The number of observations can be accessed with
<code><a href="#topic+nobs.cca">nobs.cca</a></code>, and the residual degrees of freedom with
<code><a href="#topic+df.residual.cca">df.residual.cca</a></code>. The information on observations with
missing values can be accessed with <code><a href="stats.html#topic+na.action">na.action</a></code>.  The
terms and formula of the fitted model can be accessed with
<code><a href="stats.html#topic+formula">formula</a></code> and <code><a href="stats.html#topic+terms">terms</a></code>.
</p>
<p>The weights used in <code><a href="#topic+cca">cca</a></code> can be accessed with
<code>weights</code>. In unweighted methods (<code><a href="#topic+rda">rda</a></code>) all
weights are equal.
</p>
<p>The ordination results are saved in separate components for partial
terms, constraints and residual unconstrained ordination. There is
no guarantee that these components will have the same internal names
as currently, and you should be cautious when developing scripts and
functions that directly access these components.
</p>
<p>The constrained ordination algorithm is based on QR decomposition of
constraints and conditions (environmental data), and the QR
component is saved separately for partial and constrained
components.  The QR decomposition of constraints can be accessed
with <code><a href="#topic+qr.cca">qr.cca</a></code>. This will also include the residual
effects of partial terms (Conditions), and it should be used
together with <code>ordiYbar(x, "partial")</code>. The environmental data
are first centred in <code>rda</code> or weighted and centred in
<code>cca</code>.  The QR decomposition is used in many functions that
access <code>cca</code> results, and it can be used to find many items
that are not directly stored in the object.  For examples, see
<code><a href="#topic+coef.cca">coef.cca</a></code>, <code><a href="#topic+coef.rda">coef.rda</a></code>,
<code><a href="#topic+vif.cca">vif.cca</a></code>, <code><a href="#topic+permutest.cca">permutest.cca</a></code>,
<code><a href="#topic+predict.cca">predict.cca</a></code>, <code><a href="#topic+predict.rda">predict.rda</a></code>,
<code><a href="#topic+calibrate.cca">calibrate.cca</a></code>. See <code><a href="Matrix.html#topic+qr">qr</a></code> for other possible
uses of this component. For instance, the rank of the constraints
can be found from the QR decomposition.
</p>
<p>The eigenvalues of the solution can be accessed with
<code><a href="#topic+eigenvals.cca">eigenvals.cca</a></code>. Eigenvalues are not evaluated for
partial component, and they will only be available for constrained
and residual components.
</p>
<p>The ordination scores are internally stored as (weighted)
orthonormal scores matrices. These results can be accessed with
<code><a href="#topic+scores.cca">scores.cca</a></code> and <code><a href="#topic+scores.rda">scores.rda</a></code> functions. The
ordination scores are scaled when accessed with <code><a href="#topic+scores">scores</a></code>
functions, but internal (weighted) orthonormal scores can be
accessed by setting <code>scaling = FALSE</code>. Unconstrained residual
component has species and site scores, and constrained component has
also fitted site scores or linear combination scores for sites and
biplot scores and centroids for constraint variables. The biplot
scores correspond to the <code>model.matrix</code>, and centroids
are calculated for factor variables when they were used. The scores
can be selected by defining the axes, and there is no direct way of
accessing all scores of a certain component. The number of dimensions
can be assessed from <code><a href="#topic+eigenvals">eigenvals</a></code>. In addition, some
other types can be derived from the results although not saved in
the results. For instance, regression scores and model coefficients
can be accessed with <code><a href="#topic+scores">scores</a></code> and <code><a href="stats.html#topic+coef">coef</a></code>
functions. Partial component will have no scores.
</p>
<p>Distance-based methods (<code><a href="#topic+dbrda">dbrda</a></code>, <code><a href="#topic+capscale">capscale</a></code>)
can have negative eigenvalues and associated imaginary axis
scores. There is no way of accessing these imaginary scores.  In
addition, species scores are initially missing in
<code><a href="#topic+dbrda">dbrda</a></code> and they are accessory and found after analysis
in <code><a href="#topic+capscale">capscale</a></code> (and may be misleading). Function
<code><a href="#topic+sppscores">sppscores</a></code> can be used to add species scores or replace
them with more meaningful ones.
</p>


<h3>Note</h3>

<p>Saving of &ldquo;working&rdquo; dependent (community) data changed in
<span class="pkg">vegan</span> version 2.5-0, and you should use <code>ordiYbar</code>
function instead of direct access, or your scripts and functions
will fail (<code>ordiYbar</code> has been available since <span class="pkg">vegan</span>
version 2.4-3, and it works both with the old and current result
objects).
</p>
<p>The <code>model.matrix</code> returns the unweighted model matrix also for
<code><a href="#topic+cca">cca</a></code>. Prior to <span class="pkg">vegan</span> version 2.5-0 it returned
the weighted model matrix
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd English
ed. Elsevier.
</p>


<h3>See Also</h3>

<p>The core function is <code><a href="#topic+ordConstrained">ordConstrained</a></code> which is called by
<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code> and
<code><a href="#topic+capscale">capscale</a></code>. The basic class is <code>"cca"</code> for all
methods, and the following functions are defined for this class:
<code><a href="#topic+RsquareAdj.cca">RsquareAdj.cca</a></code>, <code><a href="#topic+SSD.cca">SSD.cca</a></code>, <code><a href="#topic+add1.cca">add1.cca</a></code>, <code><a href="#topic+alias.cca">alias.cca</a></code>, <code><a href="#topic+anova.cca">anova.cca</a></code>, <code><a href="#topic+as.mlm.cca">as.mlm.cca</a></code>, <code><a href="#topic+biplot.cca">biplot.cca</a></code>, <code><a href="#topic+bstick.cca">bstick.cca</a></code>, <code><a href="#topic+calibrate.cca">calibrate.cca</a></code>, <code><a href="#topic+coef.cca">coef.cca</a></code>, <code><a href="#topic+cooks.distance.cca">cooks.distance.cca</a></code>, <code><a href="#topic+deviance.cca">deviance.cca</a></code>, <code><a href="#topic+df.residual.cca">df.residual.cca</a></code>, <code><a href="#topic+drop1.cca">drop1.cca</a></code>, <code><a href="#topic+eigenvals.cca">eigenvals.cca</a></code>, <code><a href="#topic+extractAIC.cca">extractAIC.cca</a></code>, <code><a href="#topic+fitted.cca">fitted.cca</a></code>, <code><a href="#topic+goodness.cca">goodness.cca</a></code>, <code><a href="#topic+hatvalues.cca">hatvalues.cca</a></code>, <code><a href="#topic+labels.cca">labels.cca</a></code>, <code><a href="#topic+model.frame.cca">model.frame.cca</a></code>, <code><a href="#topic+model.matrix.cca">model.matrix.cca</a></code>, <code><a href="#topic+nobs.cca">nobs.cca</a></code>, <code><a href="#topic+permutest.cca">permutest.cca</a></code>, <code><a href="#topic+plot.cca">plot.cca</a></code>, <code><a href="#topic+points.cca">points.cca</a></code>, <code><a href="#topic+predict.cca">predict.cca</a></code>, <code><a href="#topic+print.cca">print.cca</a></code>, <code><a href="#topic+qr.cca">qr.cca</a></code>, <code><a href="#topic+residuals.cca">residuals.cca</a></code>, <code><a href="#topic+rstandard.cca">rstandard.cca</a></code>, <code><a href="#topic+rstudent.cca">rstudent.cca</a></code>, <code><a href="#topic+scores.cca">scores.cca</a></code>, <code><a href="#topic+screeplot.cca">screeplot.cca</a></code>, <code><a href="#topic+sigma.cca">sigma.cca</a></code>, <code><a href="#topic+simulate.cca">simulate.cca</a></code>, <code><a href="#topic+stressplot.cca">stressplot.cca</a></code>, <code><a href="#topic+summary.cca">summary.cca</a></code>, <code><a href="#topic+text.cca">text.cca</a></code>, <code><a href="#topic+tolerance.cca">tolerance.cca</a></code>, <code><a href="#topic+vcov.cca">vcov.cca</a></code>, <code><a href="#topic+weights.cca">weights.cca</a></code>.
Other functions handling <code>"cca"</code> objects include <code><a href="#topic+inertcomp">inertcomp</a></code>,
<code><a href="#topic+intersetcor">intersetcor</a></code>, <code><a href="#topic+mso">mso</a></code>, <code><a href="#topic+ordiresids">ordiresids</a></code>,
<code><a href="#topic+ordistep">ordistep</a></code> and <code><a href="#topic+ordiR2step">ordiR2step</a></code>.
</p>

<hr>
<h2 id='CCorA'>Canonical Correlation Analysis</h2><span id='topic+CCorA'></span><span id='topic+biplot.CCorA'></span>

<h3>Description</h3>

<p>Canonical correlation analysis, following Brian McArdle's
unpublished graduate course notes, plus improvements to allow the
calculations in the case of very sparse and collinear matrices, and 
permutation test of Pillai's trace statistic. </p>


<h3>Usage</h3>

<pre><code class='language-R'>CCorA(Y, X, stand.Y=FALSE, stand.X=FALSE, permutations = 0, ...)

## S3 method for class 'CCorA'
biplot(x, plot.type="ov", xlabs, plot.axes = 1:2, int=0.5, 
   col.Y="red", col.X="blue", cex=c(0.7,0.9), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CCorA_+3A_y">Y</code></td>
<td>
<p> Left matrix (object class: <code>matrix</code> or <code>data.frame</code>). </p>
</td></tr>
<tr><td><code id="CCorA_+3A_x">X</code></td>
<td>
<p> Right matrix (object class: <code>matrix</code> or <code>data.frame</code>). </p>
</td></tr>
<tr><td><code id="CCorA_+3A_stand.y">stand.Y</code></td>
<td>
<p> Logical; should <code>Y</code> be standardized? </p>
</td></tr>
<tr><td><code id="CCorA_+3A_stand.x">stand.X</code></td>
<td>
<p> Logical; should <code>X</code> be standardized? </p>
</td></tr>
<tr><td><code id="CCorA_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="CCorA_+3A_x">x</code></td>
<td>
<p><code>CCoaR</code> result object.</p>
</td></tr>
<tr><td><code id="CCorA_+3A_plot.type">plot.type</code></td>
<td>
<p> A character string indicating which of the following 
plots should be produced: <code>"objects"</code>, <code>"variables"</code>, <code>"ov"</code> 
(separate graphs for objects and variables), or <code>"biplots"</code>. Any 
unambiguous subset containing the first letters of these names can be used 
instead of the full names. </p>
</td></tr>
<tr><td><code id="CCorA_+3A_xlabs">xlabs</code></td>
<td>
<p> Row labels. The default is to use row names, <code>NULL</code>
uses row numbers instead, and <code>NA</code> suppresses plotting row names
completely.</p>
</td></tr>
<tr><td><code id="CCorA_+3A_plot.axes">plot.axes</code></td>
<td>
<p> A vector with 2 values containing the order numbers of 
the canonical axes to be plotted. Default: first two axes. </p>
</td></tr>
<tr><td><code id="CCorA_+3A_int">int</code></td>
<td>
<p> Radius of the inner circles plotted as visual references in 
the plots of the variables. Default: <code>int=0.5</code>. With <code>int=0</code>, 
no inner circle is plotted. </p>
</td></tr>
<tr><td><code id="CCorA_+3A_col.y">col.Y</code></td>
<td>
<p> Color used for objects and variables in the first data 
table (Y) plots. In biplots, the objects are in black. </p>
</td></tr>
<tr><td><code id="CCorA_+3A_col.x">col.X</code></td>
<td>
<p> Color used for objects and variables in the second data 
table (X) plots. </p>
</td></tr>
<tr><td><code id="CCorA_+3A_cex">cex</code></td>
<td>
<p> A vector with 2 values containing the size reduction factors 
for the object and variable names, respectively, in the plots. 
Default values: <code>cex=c(0.7,0.9)</code>. </p>
</td></tr>
<tr><td><code id="CCorA_+3A_...">...</code></td>
<td>
<p> Other arguments passed to these functions. The function 
<code>biplot.CCorA</code> passes graphical arguments to <code><a href="stats.html#topic+biplot">biplot</a></code> 
and <code><a href="stats.html#topic+biplot.default">biplot.default</a></code>. <code>CCorA</code> currently ignores extra 
arguments. </p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Canonical correlation analysis (Hotelling 1936) seeks linear
combinations of the variables of <code>Y</code> that are maximally
correlated to linear combinations of the variables of <code>X</code>. The
analysis estimates the relationships and displays them in graphs.
Pillai's trace statistic is computed and tested parametrically (F-test);
a permutation test is also available.
</p>
<p>Algorithmic note &ndash; 
The blunt approach would be to read the two matrices, compute the
covariance matrices, then the matrix
<code>S12 %*% inv(S22) %*% t(S12) %*% inv(S11)</code>.
Its trace is Pillai's trace statistic. 
This approach may fail, however, when there is heavy multicollinearity
in very sparse data matrices. The safe approach is to replace all data
matrices by their PCA object scores.
</p>
<p>The function can produce different types of plots depending on the option 
chosen: 
<code>"objects"</code> produces two plots of the objects, one in the space 
of Y, the second in the space of X; 
<code>"variables"</code> produces two plots of the variables, one of the variables 
of Y in the space of Y, the second of the variables of X in the space of X; 
<code>"ov"</code> produces four plots, two of the objects and two of the variables; 
<code>"biplots"</code> produces two biplots, one for the first matrix (Y) and 
one for second matrix (X) solutions. For biplots, the function passes all arguments 
to <code><a href="stats.html#topic+biplot.default">biplot.default</a></code>; consult its help page for configuring biplots.
</p>


<h3>Value</h3>

<p>Function <code>CCorA</code> returns a list containing the following elements:
</p>
<table>
<tr><td><code>Pillai</code></td>
<td>
<p> Pillai's trace statistic = sum of the canonical
eigenvalues. </p>
</td></tr> 
<tr><td><code>Eigenvalues</code></td>
<td>
<p> Canonical eigenvalues. They are the squares of the
canonical correlations. </p>
</td></tr>
<tr><td><code>CanCorr</code></td>
<td>
<p> Canonical correlations. </p>
</td></tr>
<tr><td><code>Mat.ranks</code></td>
<td>
<p> Ranks of matrices <code>Y</code> and <code>X</code>. </p>
</td></tr>
<tr><td><code>RDA.Rsquares</code></td>
<td>
<p> Bimultivariate redundancy coefficients
(R-squares) of RDAs of Y|X and X|Y. </p>
</td></tr> 
<tr><td><code>RDA.adj.Rsq</code></td>
<td>
 <p><code>RDA.Rsquares</code> adjusted for <code>n</code> and the number 
of explanatory variables. </p>
</td></tr>
<tr><td><code>nperm</code></td>
<td>
<p> Number of permutations. </p>
</td></tr>
<tr><td><code>p.Pillai</code></td>
<td>
<p> Parametric probability value associated with Pillai's trace. </p>
</td></tr>
<tr><td><code>p.perm</code></td>
<td>
<p> Permutational probability associated with Pillai's trace. </p>
</td></tr>
<tr><td><code>Cy</code></td>
<td>
<p> Object scores in Y biplot. </p>
</td></tr>
<tr><td><code>Cx</code></td>
<td>
<p> Object scores in X biplot. </p>
</td></tr>
<tr><td><code>corr.Y.Cy</code></td>
<td>
<p> Scores of Y variables in Y biplot, computed as cor(Y,Cy). </p>
</td></tr>
<tr><td><code>corr.X.Cx</code></td>
<td>
<p> Scores of X variables in X biplot, computed as cor(X,Cx). </p>
</td></tr>
<tr><td><code>corr.Y.Cx</code></td>
<td>
<p> cor(Y,Cy) available for plotting variables Y in space of X manually. </p>
</td></tr>
<tr><td><code>corr.X.Cy</code></td>
<td>
<p> cor(X,Cx) available for plotting variables X in space of Y manually. </p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>A list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p> Call to the CCorA function. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Pierre Legendre, Departement de Sciences Biologiques,
Universite de Montreal. Implemented in <span class="pkg">vegan</span> with the help of
Jari Oksanen. </p>


<h3>References</h3>

 
<p>Hotelling, H. 1936. Relations between two sets of
variates. <em>Biometrika</em> <strong>28</strong>: 321-377.
</p>
<p>Legendre, P. 2005. Species associations: the Kendall coefficient of 
concordance revisited. <em>Journal of Agricultural, Biological, and 
Environmental Statistics</em> <strong>10</strong>: 226-245.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example using two mite groups. The mite data are available in vegan
data(mite)
# Two mite species associations (Legendre 2005, Fig. 4)
group.1 &lt;- c(1,2,4:8,10:15,17,19:22,24,26:30)
group.2 &lt;- c(3,9,16,18,23,25,31:35)
# Separate Hellinger transformations of the two groups of species 
mite.hel.1 &lt;- decostand(mite[,group.1], "hel")
mite.hel.2 &lt;- decostand(mite[,group.2], "hel")
rownames(mite.hel.1) = paste("S",1:nrow(mite),sep="")
rownames(mite.hel.2) = paste("S",1:nrow(mite),sep="")
out &lt;- CCorA(mite.hel.1, mite.hel.2)
out
biplot(out, "ob")                 # Two plots of objects
biplot(out, "v", cex=c(0.7,0.6))  # Two plots of variables
biplot(out, "ov", cex=c(0.7,0.6)) # Four plots (2 for objects, 2 for variables)
biplot(out, "b", cex=c(0.7,0.6))  # Two biplots
biplot(out, xlabs = NA, plot.axes = c(3,5))    # Plot axes 3, 5. No object names
biplot(out, plot.type="biplots", xlabs = NULL) # Replace object names by numbers

# Example using random numbers. No significant relationship is expected
mat1 &lt;- matrix(rnorm(60),20,3)
mat2 &lt;- matrix(rnorm(100),20,5)
out2 = CCorA(mat1, mat2, permutations=99)
out2
biplot(out2, "b")
</code></pre>

<hr>
<h2 id='clamtest'>
Multinomial Species Classification Method (CLAM)
</h2><span id='topic+clamtest'></span><span id='topic+summary.clamtest'></span><span id='topic+plot.clamtest'></span>

<h3>Description</h3>

<p>The CLAM statistical approach for classifying generalists and
specialists in two distinct habitats is described in Chazdon et al. (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clamtest(comm, groups, coverage.limit = 10, specialization = 2/3, 
   npoints = 20, alpha = 0.05/20)
## S3 method for class 'clamtest'
summary(object, ...)
## S3 method for class 'clamtest'
plot(x, xlab, ylab, main,  pch = 21:24, col.points = 1:4, 
   col.lines = 2:4, lty = 1:3, position = "bottomright", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clamtest_+3A_comm">comm</code></td>
<td>

<p>Community matrix, consisting of counts.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_groups">groups</code></td>
<td>

<p>A vector identifying the two habitats. Must have exactly
two unique values or levels. Habitat IDs in the grouping vector
must match corresponding rows in the community matrix <code>comm</code>.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_coverage.limit">coverage.limit</code></td>
<td>

<p>Integer, the sample coverage based correction 
is applied to rare species with counts below this limit. 
Sample coverage is calculated separately 
for the two habitats. Sample relative abundances are used for species 
with higher than or equal to <code>coverage.limit</code> total counts per habitat.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_specialization">specialization</code></td>
<td>

<p>Numeric, specialization threshold value between 0 and 1.
The value of <code class="reqn">2/3</code> represents &lsquo;supermajority&rsquo; rule,
while a value of <code class="reqn">1/2</code> represents a &lsquo;simple majority&rsquo; rule
to assign shared species as habitat specialists.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_npoints">npoints</code></td>
<td>

<p>Integer, number of points used to determine the boundary lines
in the plots.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_alpha">alpha</code></td>
<td>
<p> Numeric, nominal significance level for individual
tests.  The default value reduces the conventional limit of
<code class="reqn">0.05</code> to account for overdispersion and multiple testing for
several species simultaneously. However, the is no firm reason for
exactly this limit.  </p>
</td></tr>
<tr><td><code id="clamtest_+3A_x">x</code>, <code id="clamtest_+3A_object">object</code></td>
<td>

<p>Fitted model object of class <code>"clamtest"</code>.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_xlab">xlab</code>, <code id="clamtest_+3A_ylab">ylab</code></td>
<td>

<p>Labels for the plot axes.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_main">main</code></td>
<td>

<p>Main title of the plot.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_pch">pch</code>, <code id="clamtest_+3A_col.points">col.points</code></td>
<td>

<p>Symbols and colors used in plotting species groups.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_lty">lty</code>, <code id="clamtest_+3A_col.lines">col.lines</code></td>
<td>

<p>Line types and colors for boundary lines in plot to separate species groups.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_position">position</code></td>
<td>

<p>Position of figure legend, see <code><a href="graphics.html#topic+legend">legend</a></code> for specification details.
Legend not shown if <code>position = NULL</code>.
</p>
</td></tr>
<tr><td><code id="clamtest_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The method uses a multinomial model based on estimated
species relative abundance in two habitats (A, B). It minimizes bias
due to differences in sampling intensities between two habitat types
as well as bias due to insufficient sampling within each
habitat. The method permits a robust statistical classification of
habitat specialists and generalists, without excluding rare species
<em>a priori</em> (Chazdon et al. 2011).  Based on a user-defined
<code>specialization</code> threshold, the model classifies species into
one of four groups: (1) generalists; (2) habitat A specialists; (3)
habitat B specialists; and (4) too rare to classify with confidence.
</p>


<h3>Value</h3>

<p> A data frame (with class attribute <code>"clamtest"</code>),
with columns: 
</p>
 
<ul>
<li><p><code>Species</code>: species name (column names from <code>comm</code>), 
</p>
</li>
<li><p><code>Total_*A*</code>: total count in habitat A, 
</p>
</li>
<li><p><code>Total_*B*</code>: total count in habitat B, 
</p>
</li>
<li><p><code>Classes</code>: species classification, a factor with
levels <code>Generalist</code>, <code>Specialist_*A*</code>,
<code>Specialist_*B*</code>, and <code>Too_rare</code>.  
</p>
</li></ul>

<p><code>*A*</code> and <code>*B*</code> are placeholders for habitat names/labels found in the
data.
</p>
<p>The <code>summary</code> method returns descriptive statistics of the results.
The <code>plot</code> method returns values invisibly and produces a bivariate
scatterplot of species total abundances in the two habitats. Symbols and
boundary lines are shown for species groups.
</p>


<h3>Note</h3>

<p>The code was tested against standalone CLAM software provided
on the website of Anne Chao (which were then at http://chao.stat.nthu.edu.tw/wordpress);
minor inconsistencies were found, especially for finding the
threshold for 'too rare' species.
These inconsistencies are probably due to numerical differences between the
two implementation. The current <span class="rlang"><b>R</b></span> implementation uses 
root finding for iso-lines instead of iterative search.
</p>
<p>The original method (Chazdon et al. 2011) has two major problems:
</p>

<ol>
<li><p> It assumes that the error distribution is multinomial. This is
a justified choice if individuals are freely distributed, and
there is no over-dispersion or clustering of individuals. In most
ecological data, the variance is much higher than multinomial
assumption, and therefore test statistic are too optimistic.
</p>
</li>
<li><p> The original authors suggest that multiple testing adjustment
for multiple testing should be based on the number of points
(<code>npoints</code>) used to draw the critical lines on the plot,
whereas the adjustment should be based on the number of tests (i.e.,
tested species). The function uses the same numerical values as
the original paper, but there is no automatic connection between
<code>npoints</code> and <code>alpha</code> arguments, but you must work out
the adjustment yourself.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Peter Solymos <a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a>
</p>


<h3>References</h3>

<p>Chazdon, R. L., Chao, A., Colwell, R. K., Lin, S.-Y., Norden, N., 
Letcher, S. G., Clark, D. B., Finegan, B. and Arroyo J. P.(2011). 
A novel statistical method for classifying habitat
generalists and specialists. <em>Ecology</em> <b>92</b>, 1332&ndash;1343.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite)
data(mite.env)
sol &lt;- with(mite.env, clamtest(mite, Shrub=="None", alpha=0.005))
summary(sol)
head(sol)
plot(sol)
</code></pre>

<hr>
<h2 id='commsim'>
Create an Object for Null Model Algorithms
</h2><span id='topic+commsim'></span><span id='topic+make.commsim'></span><span id='topic+print.commsim'></span>

<h3>Description</h3>

<p>The <code>commsim</code> function can be used to feed Null Model algorithms into
<code><a href="#topic+nullmodel">nullmodel</a></code> analysis.
The <code>make.commsim</code> function returns various predefined algorithm types
(see Details).
These functions represent low level interface for community null model
infrastructure in <span class="pkg">vegan</span> with the intent of extensibility,
and less emphasis on direct use by users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>commsim(method, fun, binary, isSeq, mode)
make.commsim(method)
## S3 method for class 'commsim'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="commsim_+3A_method">method</code></td>
<td>

<p>Character, name of the algorithm.
</p>
</td></tr>
<tr><td><code id="commsim_+3A_fun">fun</code></td>
<td>

<p>A function. For possible formal arguments of this function
see Details.
</p>
</td></tr>
<tr><td><code id="commsim_+3A_binary">binary</code></td>
<td>

<p>Logical, if the algorithm applies to presence-absence or count matrices.
</p>
</td></tr>
<tr><td><code id="commsim_+3A_isseq">isSeq</code></td>
<td>

<p>Logical, if the algorithm is sequential (needs burnin and thinning) or not.
</p>
</td></tr>
<tr><td><code id="commsim_+3A_mode">mode</code></td>
<td>

<p>Character, storage mode of the community matrix, either
<code>"integer"</code> or <code>"double"</code>.
</p>
</td></tr>
<tr><td><code id="commsim_+3A_x">x</code></td>
<td>

<p>An object of class <code>commsim</code>.
</p>
</td></tr>
<tr><td><code id="commsim_+3A_...">...</code></td>
<td>

<p>Additional arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>fun</code> must return an array of <code>dim(nr, nc, n)</code>,
and must take some of the following arguments:
</p>

<ul>
<li><p><code>x</code>: input matrix,
</p>
</li>
<li><p><code>n</code>: number of permuted matrices in output,
</p>
</li>
<li><p><code>nr</code>: number of rows,
</p>
</li>
<li><p><code>nc</code>: number of columns,
</p>
</li>
<li><p><code>rs</code>: vector of row sums,
</p>
</li>
<li><p><code>cs</code>: vector of column sums,
</p>
</li>
<li><p><code>rf</code>: vector of row frequencies (non-zero cells),
</p>
</li>
<li><p><code>cf</code>: vector of column frequencies (non-zero cells),
</p>
</li>
<li><p><code>s</code>: total sum of <code>x</code>,
</p>
</li>
<li><p><code>fill</code>: matrix fill (non-zero cells),
</p>
</li>
<li><p><code>thin</code>: thinning value for sequential algorithms,
</p>
</li>
<li><p><code>...</code>: additional arguments.
</p>
</li></ul>

<p>You can define your own null model, but
several null model algorithm are pre-defined and can be called by
their name. The predefined algorithms are described in detail in the
following chapters. The binary null models produce matrices of zeros
(absences) and ones (presences) also when input matrix is
quantitative. There are two types of quantitative data: Counts are
integers with a natural unit so that individuals can be shuffled, but
abundances can have real (floating point) values and do not have a
natural subunit for shuffling. All quantitative models can handle
counts, but only some are able to handle real values. Some of the null
models are sequential so that the next matrix is derived from the
current one. This makes models dependent from previous models, and usually
you must thin these matrices and study the sequences for stability:
see <code>oecosimu</code> for details and instructions.
</p>
<p>See Examples for structural constraints imposed by each algorithm and
defining your own null model.
</p>


<h3>Value</h3>

<p>An object of class <code>commsim</code> with elements
corresponding to the arguments (<code>method</code>, <code>binary</code>,
<code>isSeq</code>, <code>mode</code>, <code>fun</code>).
</p>
<p>If the input of <code>make.comsimm</code> is a <code>commsim</code> object,
it is returned without further evaluation. If this is not the case,
the character <code>method</code> argument is matched against
predefined algorithm names. An error message is issued
if none such is found. If the <code>method</code> argument is missing,
the function returns names of all currently available
null model algorithms as a character vector.
</p>


<h3>Binary null models</h3>

<p>All binary null models preserve fill: number of presences or
conversely the number of absences. The classic models may also
preserve column (species) frequencies (<code>c0</code>) or row frequencies
or species richness of each site (<code>r0</code>) and take into account
commonness and rarity of species (<code>r1</code>, <code>r2</code>).  Algorithms
<code>swap</code>, <code>tswap</code>, <code>curveball</code>, <code>quasiswap</code> and
<code>backtracking</code> preserve both row and column frequencies. Three
first ones are sequential but the two latter are non-sequential
and produce independent matrices. Basic algorithms are reviewed by
Wright et al. (1998).
</p>

<ul>
<li><p><code>"r00"</code>: non-sequential algorithm for binary matrices
that only  preserves the number of presences (fill).
</p>
</li>
<li><p><code>"r0"</code>: non-sequential algorithm for binary
matrices that preserves the site (row) frequencies.
</p>
</li>
<li><p><code>"r1"</code>: non-sequential algorithm for binary matrices
that preserves the site (row) frequencies, but uses column marginal
frequencies as probabilities of selecting species.
</p>
</li>
<li><p><code>"r2"</code>: non-sequential algorithm for binary matrices
that preserves the site (row) frequencies, and uses squared column
marginal frequencies as as probabilities of selecting species.
</p>
</li>
<li><p><code>"c0"</code>: non-sequential algorithm for binary matrices
that preserves species frequencies (Jonsson 2001). 
</p>
</li>
<li><p><code>"swap"</code>: sequential algorithm for binary matrices that
changes the matrix structure, but does not influence marginal sums
(Gotelli &amp; Entsminger 2003).  This inspects <code class="reqn">2 \times 2</code> submatrices so long that a swap can be done.
</p>
</li>
<li><p><code>"tswap"</code>: sequential algorithm for binary matrices.
Same as the <code>"swap"</code> algorithm, but it tries a fixed
number of times and performs zero to many swaps at one step
(according to the thin argument in the call). This
approach was suggested by Mikl√≥s &amp; Podani (2004)
because they found that ordinary swap may lead to biased
sequences, since some columns or rows are more easily swapped.
</p>
</li>
<li><p><code>"curveball"</code>: sequential method for binary matrices that
implements the &lsquo;Curveball&rsquo; algorithm of Strona et
al. (2014). The algorithm selects two random rows and finds the set
of unique species that occur only in one of these rows. The
algorithm distributes the set of unique species to rows preserving
the original row frequencies.  Zero to several species are swapped
in one step, and usually the matrix is perturbed more strongly than
in other sequential methods.
</p>
</li>
<li><p><code>"quasiswap"</code>: non-sequential algorithm for binary
matrices that implements a method where matrix is first filled
honouring row and column totals, but with integers that may be
larger than one.  Then the method inspects random
<code class="reqn">2 \times 2</code> matrices and performs a quasiswap on
them. In addition to ordinary swaps, quasiswap can reduce numbers
above one to ones preserving marginal totals (Mikl√≥s &amp;
Podani 2004). The method is non-sequential, but it accepts
<code>thin</code> argument: the convergence is checked at every
<code>thin</code> steps. This allows performing several ordinary swaps in
addition to fill changing swaps which helps in reducing or removing
the bias.
</p>
</li>
<li><p><code>"greedyqswap"</code>: A greedy variant of quasiswap. In
greedy step, one element of the <code class="reqn">2 \times 2</code> matrix is
taken from <code class="reqn">&gt; 1</code> elements. The greedy steps are biased, but
the method can be thinned, and only the first of <code>thin</code>
steps is greedy. Even modest thinning (say <code>thin = 20</code>)
removes or reduces the bias, and <code>thin = 100</code> (1% greedy
steps) looks completely safe and still speeds up simulation. The
code is experimental and it is provided here for further scrutiny,
and should be tested for bias before use.
</p>
</li>
<li><p><code>"backtracking"</code>: non-sequential algorithm for binary
matrices that implements a filling method with constraints both for
row and column frequencies (Gotelli &amp; Entsminger 2001).  The matrix
is first filled randomly, but typically row and column sums are
reached before all incidences are filled in. After this begins
&quot;backtracking&quot;, where some of the incidences are removed, and
filling is started again, and this backtracking is done so many
times that all incidences will be filled into matrix.  The results
may be biased and should be inspected carefully before use.
</p>
</li></ul>



<h3>Quantitative Models for Counts with Fixed Marginal Sums</h3>

<p>These models shuffle individuals of counts and keep marginal sums
fixed, but marginal frequencies are not preserved. Algorithm
<code>r2dtable</code> uses standard <span class="rlang"><b>R</b></span> function <code><a href="stats.html#topic+r2dtable">r2dtable</a></code> also
used for simulated <code class="reqn">P</code>-values in <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>.
Algorithm <code>quasiswap_count</code> uses the same, but preserves the
original fill. Typically this means increasing numbers of zero cells
and the result is zero-inflated with respect to <code>r2dtable</code>.
</p>

<ul>
<li><p><code>"r2dtable"</code>: non-sequential algorithm for count
matrices.  This algorithm keeps matrix sum and row/column sums
constant. Based on <code><a href="stats.html#topic+r2dtable">r2dtable</a></code>.
</p>
</li>
<li><p><code>"quasiswap_count"</code>: non-sequential algorithm for count
matrices.  This algorithm is similar as Carsten Dormann's
<code>swap.web</code> function in the package
<span class="pkg">bipartite</span>. First, a random matrix is generated by the
<code><a href="stats.html#topic+r2dtable">r2dtable</a></code> function preserving row and column sums.  Then
the original matrix fill is reconstructed by sequential steps to
increase or decrease matrix fill in the random matrix. These steps
are based on swapping <code class="reqn">2 \times 2</code> submatrices (see
<code>"swap_count"</code> algorithm for details) to maintain row and
column totals. 
</p>
</li></ul>



<h3>Quantitative Swap Models</h3>

<p>Quantitative swap models are similar to binary <code>swap</code>, but they
swap the largest permissible value. The models in this section all
maintain the fill and perform a quantitative swap only if this can
be done without changing the fill. Single step of swap often changes
the matrix very little. In particular, if cell counts are variable,
high values change very slowly. Checking the chain stability and
independence is even more crucial than in binary swap, and very
strong <code>thin</code>ning is often needed. These models should never be
used without inspecting their properties for the current data. These
null models can also be defined using <code><a href="#topic+permatswap">permatswap</a></code>
function.
</p>

<ul>
<li><p><code>"swap_count"</code>: sequential algorithm for count matrices.
This algorithm find <code class="reqn">2 \times 2</code> submatrices that can be
swapped leaving column and row totals and fill unchanged. The
algorithm finds the largest value in the submatrix that can be
swapped (<code class="reqn">d</code>). Swap means that the values in diagonal or
antidiagonal positions are decreased by <code class="reqn">d</code>, while remaining
cells are increased by <code class="reqn">d</code>. A swap is made only if fill does not
change.  
</p>
</li>
<li><p><code>"abuswap_r"</code>: sequential algorithm for count or
nonnegative real valued matrices with fixed row frequencies (see
also <code><a href="#topic+permatswap">permatswap</a></code>).  The algorithm is similar to
<code>swap_count</code>, but uses different swap value for each row of the
<code class="reqn">2 \times 2</code> submatrix. Each step changes the the
corresponding column sums, but honours matrix fill, row sums, and
row/column frequencies (Hardy 2008; randomization scheme 2x).
</p>
</li>
<li><p><code>"abuswap_c"</code>: sequential algorithm for count or
nonnegative real valued matrices with fixed column frequencies
(see also <code><a href="#topic+permatswap">permatswap</a></code>).  The algorithm is similar as
the previous one, but operates on columns.  Each step changes the
the corresponding row sums, but honours matrix fill, column sums,
and row/column frequencies (Hardy 2008; randomization scheme 3x).
</p>
</li></ul>
 

<h3>Quantitative Swap and Shuffle Models</h3>

<p>Quantitative Swap and Shuffle methods (<code>swsh</code> methods) preserve
fill and column and row frequencies, and also either row or column
sums. The methods first perform a binary <code>quasiswap</code> and then
shuffle original quantitative data to non-zero cells. The
<code>samp</code> methods shuffle original non-zero cell values and can be
used also with non-integer data. The <code>both</code> methods
redistribute individuals randomly among non-zero cells and can only
be used with integer data. The shuffling is either free over the
whole matrix, or within rows (<code>r</code> methods) or within columns
(<code>c</code> methods). Shuffling within a row preserves row sums, and
shuffling within a column preserves column sums. These models can
also be defined with <code><a href="#topic+permatswap">permatswap</a></code>.
</p>

<ul>
<li><p><code>"swsh_samp"</code>: non-sequential algorithm for
quantitative data (either integer counts or non-integer values).
Original non-zero values values are shuffled.
</p>
</li>
<li><p><code>"swsh_both"</code>: non-sequential algorithm for count data.
Individuals are shuffled freely over non-zero cells.
</p>
</li>
<li><p><code>"swsh_samp_r"</code>: non-sequential algorithm for
quantitative data.  Non-zero values (samples) are shuffled
separately for each row.
</p>
</li>
<li><p><code>"swsh_samp_c"</code>: non-sequential algorithm for
quantitative data.  Non-zero values (samples) are shuffled
separately for each column.
</p>
</li>
<li><p><code>"swsh_both_r"</code>: non-sequential algorithm for count matrices.
Individuals are shuffled freely for non-zero values within each row.
</p>
</li>
<li><p><code>"swsh_both_c"</code>: non-sequential algorithm for count matrices.
Individuals are shuffled freely for non-zero values with each column.
</p>
</li></ul>



<h3>Quantitative Shuffle Methods</h3>

<p>Quantitative shuffle methods are generalizations of binary models
<code>r00</code>, <code>r0</code> and <code>c0</code>.  The <code>_ind</code> methods
shuffle individuals so that the grand sum, row sum or column sums
are preserved.  These methods are similar as <code>r2dtable</code> but
with still slacker constraints on marginal sums. The <code>_samp</code>
and <code>_both</code> methods first apply the corresponding binary model
with similar restriction on marginal frequencies and then distribute
quantitative values over non-zero cells. The <code>_samp</code> models
shuffle original cell values and can therefore handle also non-count
real values. The <code>_both</code> models shuffle individuals among
non-zero values. The shuffling is over the whole matrix in
<code>r00_</code>, and within row in <code>r0_</code> and within column in
<code>c0_</code> in all cases.
</p>

<ul>
<li><p><code>"r00_ind"</code>: non-sequential algorithm for count matrices.
This algorithm preserves grand sum and
individuals are shuffled among cells of the matrix.
</p>
</li>
<li><p><code>"r0_ind"</code>: non-sequential algorithm for count matrices.
This algorithm preserves row sums and
individuals are shuffled among cells of each row of the matrix.
</p>
</li>
<li><p><code>"c0_ind"</code>: non-sequential algorithm for count matrices.
This algorithm preserves column sums and
individuals are shuffled among cells of each column of the matrix.
</p>
</li>
<li><p><code>"r00_samp"</code>: non-sequential algorithm for count
or nonnegative real valued (<code>mode = "double"</code>) matrices.
This algorithm preserves grand sum and
cells of the matrix are shuffled.
</p>
</li>
<li><p><code>"r0_samp"</code>: non-sequential algorithm for count
or nonnegative real valued (<code>mode = "double"</code>) matrices.
This algorithm preserves row sums and
cells within each row are shuffled.
</p>
</li>
<li><p><code>"c0_samp"</code>: non-sequential algorithm for count
or nonnegative real valued (<code>mode = "double"</code>) matrices.
This algorithm preserves column sums constant and
cells within each column are shuffled.
</p>
</li>
<li><p><code>"r00_both"</code>: non-sequential algorithm for count matrices.
This algorithm preserves grand sum and
cells and individuals among cells of the matrix are shuffled.
</p>
</li>
<li><p><code>"r0_both"</code>: non-sequential algorithm for count matrices.
This algorithm preserves grand sum and
cells and individuals among cells of each row are shuffled.
</p>
</li>
<li><p><code>"c0_both"</code>: non-sequential algorithm for count matrices.
This algorithm preserves grand sum and
cells and individuals among cells of each column are shuffled.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Jari Oksanen and Peter Solymos
</p>


<h3>References</h3>

<p>Gotelli, N.J. &amp; Entsminger, N.J. (2001). Swap and fill algorithms in
null model analysis: rethinking the knight's tour. <em>Oecologia</em>
129, 281&ndash;291.
</p>
<p>Gotelli, N.J. &amp; Entsminger, N.J. (2003). Swap algorithms in null model
analysis. <em>Ecology</em> 84, 532&ndash;535.
</p>
<p>Hardy, O. J. (2008) Testing the spatial phylogenetic structure of
local communities: statistical performances of different null models
and test statistics on a locally neutral community.  <em>Journal of
Ecology</em> 96, 914&ndash;926.
</p>
<p>Jonsson, B.G. (2001) A null model for randomization tests of
nestedness in species assemblages. <em>Oecologia</em> 127, 309&ndash;313.
</p>
<p>Mikl√≥s, I. &amp; Podani, J. (2004). Randomization of
presence-absence matrices: comments and new algorithms. <em>Ecology</em>
85, 86&ndash;92.
</p>
<p>Patefield, W. M. (1981) Algorithm AS159.  An efficient method of
generating r x c tables with given row and column totals.
<em>Applied Statistics</em> 30, 91&ndash;97.
</p>
<p>Strona, G., Nappo, D., Boccacci, F., Fattorini, S. &amp;
San-Miguel-Ayanz, J. (2014). A fast and unbiased procedure to
randomize ecological binary matrices with fixed row and column
totals. <em>Nature Communications</em> 5:4114
<a href="https://doi.org/10.1038/ncomms5114">doi:10.1038/ncomms5114</a>.
</p>
<p>Wright, D.H., Patterson, B.D., Mikkelson, G.M., Cutler, A. &amp; Atmar,
W. (1998). A comparative analysis of nested subset patterns of species
composition. <em>Oecologia</em> 113, 1&ndash;20.
</p>


<h3>See Also</h3>

<p> See <code><a href="#topic+permatfull">permatfull</a></code>, <code><a href="#topic+permatswap">permatswap</a></code> for
alternative specification of quantitative null models. Function
<code><a href="#topic+oecosimu">oecosimu</a></code> gives a higher-level interface for applying null
models in hypothesis testing and analysis of models. Function
<code><a href="#topic+nullmodel">nullmodel</a></code> and <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code> are used to
generate arrays of simulated null model matrices.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## write the r00 algorithm
f &lt;- function(x, n, ...)
    array(replicate(n, sample(x)), c(dim(x), n))
(cs &lt;- commsim("r00", fun=f, binary=TRUE,
    isSeq=FALSE, mode="integer"))

## retrieving the sequential swap algorithm
(cs &lt;- make.commsim("swap"))

## feeding a commsim object as argument
make.commsim(cs)

## making the missing c1 model using r1 as a template
##   non-sequential algorithm for binary matrices
##   that preserves the species (column) frequencies,
##   but uses row marginal frequencies
##   as probabilities of selecting sites
f &lt;- function (x, n, nr, nc, rs, cs, ...) {
    out &lt;- array(0L, c(nr, nc, n))
    J &lt;- seq_len(nc)
    storage.mode(rs) &lt;- "double"
    for (k in seq_len(n))
        for (j in J)
            out[sample.int(nr, cs[j], prob = rs), j, k] &lt;- 1L
    out
}
cs &lt;- make.commsim("r1")
cs$method &lt;- "c1"
cs$fun &lt;- f

## structural constraints
diagfun &lt;- function(x, y) {
    c(sum = sum(y) == sum(x),
        fill = sum(y &gt; 0) == sum(x &gt; 0),
        rowSums = all(rowSums(y) == rowSums(x)),
        colSums = all(colSums(y) == colSums(x)),
        rowFreq = all(rowSums(y &gt; 0) == rowSums(x &gt; 0)),
        colFreq = all(colSums(y &gt; 0) == colSums(x &gt; 0)))
}
evalfun &lt;- function(meth, x, n) {
    m &lt;- nullmodel(x, meth)
    y &lt;- simulate(m, nsim=n)
    out &lt;- rowMeans(sapply(1:dim(y)[3],
        function(i) diagfun(attr(y, "data"), y[,,i])))
    z &lt;- as.numeric(c(attr(y, "binary"), attr(y, "isSeq"),
        attr(y, "mode") == "double"))
    names(z) &lt;- c("binary", "isSeq", "double")
    c(z, out)
}
x &lt;- matrix(rbinom(10*12, 1, 0.5)*rpois(10*12, 3), 12, 10)
algos &lt;- make.commsim()
a &lt;- t(sapply(algos, evalfun, x=x, n=10))
print(as.table(ifelse(a==1,1,0)), zero.print = ".")
</code></pre>

<hr>
<h2 id='contribdiv'>Contribution Diversity Approach</h2><span id='topic+contribdiv'></span><span id='topic+plot.contribdiv'></span>

<h3>Description</h3>

<p>The contribution diversity approach is based in the differentiation of
within-unit and among-unit diversity by using additive diversity
partitioning and unit distinctiveness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contribdiv(comm, index = c("richness", "simpson"),
     relative = FALSE, scaled = TRUE, drop.zero = FALSE)
## S3 method for class 'contribdiv'
plot(x, sub, xlab, ylab, ylim, col, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contribdiv_+3A_comm">comm</code></td>
<td>
<p>The community data matrix with samples as rows and species as column.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_index">index</code></td>
<td>
<p>Character, the diversity index to be calculated.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_relative">relative</code></td>
<td>
<p>Logical, if <code>TRUE</code> then contribution diversity
values are expressed as their signed deviation from their mean. See details.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_scaled">scaled</code></td>
<td>
<p>Logical, if <code>TRUE</code> then relative contribution diversity
values are scaled by the sum of gamma values (if <code>index = "richness"</code>)
or by sum of gamma values times the number of rows in <code>comm</code>
(if <code>index = "simpson"</code>). See details.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_drop.zero">drop.zero</code></td>
<td>
<p>Logical, should empty rows dropped from the result?
If empty rows are not dropped, their corresponding results will be <code>NA</code>s.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_x">x</code></td>
<td>
<p>An object of class <code>"contribdiv"</code>.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_sub">sub</code>, <code id="contribdiv_+3A_xlab">xlab</code>, <code id="contribdiv_+3A_ylab">ylab</code>, <code id="contribdiv_+3A_ylim">ylim</code>, <code id="contribdiv_+3A_col">col</code></td>
<td>
<p>Graphical arguments passed to plot.</p>
</td></tr>
<tr><td><code id="contribdiv_+3A_...">...</code></td>
<td>
<p>Other arguments passed to plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This approach was proposed by Lu et al. (2007).
Additive diversity partitioning (see <code><a href="#topic+adipart">adipart</a></code> for more references)
deals with the relation of mean alpha and the total (gamma) diversity. Although
alpha diversity values often vary considerably. Thus, contributions of the sites
to the total diversity are uneven. This site specific contribution is measured by
contribution diversity components. A unit that has e.g. many unique species will
contribute more to the higher level (gamma) diversity than another unit with the
same number of species, but all of which common.
</p>
<p>Distinctiveness of species <code class="reqn">j</code> can be defined as the number of sites where it
occurs (<code class="reqn">n_j</code>), or the sum of its relative frequencies (<code class="reqn">p_j</code>). Relative
frequencies are computed sitewise and <code class="reqn">sum_j{p_ij}</code>s at site <code class="reqn">i</code> sum up
to <code class="reqn">1</code>.
</p>
<p>The contribution of site <code class="reqn">i</code> to the total diversity is given by
<code class="reqn">alpha_i = sum_j(1 / n_ij)</code> when dealing with richness and
<code class="reqn">alpha_i = sum(p_{ij} * (1 - p_{ij}))</code> for the Simpson index.
</p>
<p>The unit distinctiveness of site <code class="reqn">i</code> is the average of the species
distinctiveness, averaging only those species which occur at site <code class="reqn">i</code>.
For species richness: <code class="reqn">alpha_i = mean(n_i)</code> (in the paper, the second
equation contains a typo, <code class="reqn">n</code> is without index). For the Simpson index:
<code class="reqn">alpha_i = mean(n_i)</code>.
</p>
<p>The Lu et al. (2007) gives an in-depth description of the different indices.
</p>


<h3>Value</h3>

<p>An object of class <code>"contribdiv"</code> inheriting from data frame.
</p>
<p>Returned values are alpha, beta and gamma components for each sites (rows)
of the community matrix. The <code>"diff.coef"</code> attribute gives the
differentiation coefficient (see Examples).
</p>


<h3>Author(s)</h3>

<p>P√©ter S√≥lymos, <a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a></p>


<h3>References</h3>

<p>Lu, H. P., Wagner, H. H. and Chen, X. Y. 2007. A contribution diversity
approach to evaluate species diversity.
<em>Basic and Applied Ecology</em>, 8, 1&ndash;12.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adipart">adipart</a></code>, <code><a href="#topic+diversity">diversity</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Artificial example given in
## Table 2 in Lu et al. 2007
x &lt;- matrix(c(
1/3,1/3,1/3,0,0,0,
0,0,1/3,1/3,1/3,0,
0,0,0,1/3,1/3,1/3),
3, 6, byrow = TRUE,
dimnames = list(LETTERS[1:3],letters[1:6]))
x
## Compare results with Table 2
contribdiv(x, "richness")
contribdiv(x, "simpson")
## Relative contribution (C values), compare with Table 2
(cd1 &lt;- contribdiv(x, "richness", relative = TRUE, scaled = FALSE))
(cd2 &lt;- contribdiv(x, "simpson", relative = TRUE, scaled = FALSE))
## Differentiation coefficients
attr(cd1, "diff.coef") # D_ST
attr(cd2, "diff.coef") # D_DT
## BCI data set
data(BCI)
opar &lt;- par(mfrow=c(2,2))
plot(contribdiv(BCI, "richness"), main = "Absolute")
plot(contribdiv(BCI, "richness", relative = TRUE), main = "Relative")
plot(contribdiv(BCI, "simpson"))
plot(contribdiv(BCI, "simpson", relative = TRUE))
par(opar)
</code></pre>

<hr>
<h2 id='decorana'>Detrended Correspondence Analysis and Basic Reciprocal Averaging </h2><span id='topic+decorana'></span><span id='topic+summary.decorana'></span><span id='topic+print.summary.decorana'></span><span id='topic+plot.decorana'></span><span id='topic+downweight'></span><span id='topic+scores.decorana'></span><span id='topic+points.decorana'></span><span id='topic+text.decorana'></span>

<h3>Description</h3>

<p>Performs detrended correspondence analysis and basic reciprocal
averaging or orthogonal correspondence analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decorana(veg, iweigh=0, iresc=4, ira=0, mk=26, short=0,
         before=NULL, after=NULL)

## S3 method for class 'decorana'
plot(x, choices=c(1,2), origin=TRUE,
     display=c("both","sites","species","none"),
     cex = 0.8, cols = c(1,2), type, xlim, ylim, ...)

## S3 method for class 'decorana'
text(x, display = c("sites", "species"), labels,
     choices = 1:2, origin = TRUE, select,  ...)

## S3 method for class 'decorana'
points(x, display = c("sites", "species"),
       choices=1:2, origin = TRUE, select, ...)

## S3 method for class 'decorana'
summary(object, digits=3, origin=TRUE,
        display=c("both", "species","sites","none"), ...)

## S3 method for class 'summary.decorana'
print(x, head = NA, tail = head, ...)

downweight(veg, fraction = 5)

## S3 method for class 'decorana'
scores(x, display="sites", choices=1:4,
       origin=TRUE, tidy=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decorana_+3A_veg">veg</code></td>
<td>
<p>Community data, a matrix-like object. </p>
</td></tr>
<tr><td><code id="decorana_+3A_iweigh">iweigh</code></td>
<td>
<p>Downweighting of rare species (0: no). </p>
</td></tr>
<tr><td><code id="decorana_+3A_iresc">iresc</code></td>
<td>
<p>Number of rescaling cycles (0: no rescaling). </p>
</td></tr>
<tr><td><code id="decorana_+3A_ira">ira</code></td>
<td>
<p>Type of analysis (0: detrended, 1: basic reciprocal averaging). </p>
</td></tr>
<tr><td><code id="decorana_+3A_mk">mk</code></td>
<td>
<p>Number of segments in rescaling. </p>
</td></tr>
<tr><td><code id="decorana_+3A_short">short</code></td>
<td>
<p>Shortest gradient to be rescaled. </p>
</td></tr>
<tr><td><code id="decorana_+3A_before">before</code></td>
<td>
<p>Hill's piecewise transformation: values before transformation. </p>
</td></tr>
<tr><td><code id="decorana_+3A_after">after</code></td>
<td>
<p>Hill's piecewise transformation: values after
transformation &ndash; these must correspond to values in <code>before</code>.</p>
</td></tr>
<tr><td><code id="decorana_+3A_x">x</code>, <code id="decorana_+3A_object">object</code></td>
<td>
<p>A <code>decorana</code> result object.</p>
</td></tr>
<tr><td><code id="decorana_+3A_choices">choices</code></td>
<td>
<p>Axes shown.</p>
</td></tr>
<tr><td><code id="decorana_+3A_origin">origin</code></td>
<td>
<p>Use true origin even in detrended correspondence analysis.</p>
</td></tr>
<tr><td><code id="decorana_+3A_display">display</code></td>
<td>
<p>Display only sites, only species, both or neither.</p>
</td></tr>
<tr><td><code id="decorana_+3A_cex">cex</code></td>
<td>
<p>Plot character size.</p>
</td></tr>
<tr><td><code id="decorana_+3A_cols">cols</code></td>
<td>
<p>Colours used for sites and species.</p>
</td></tr>
<tr><td><code id="decorana_+3A_type">type</code></td>
<td>
<p>Type of plots, partial match to <code>"text"</code>,
<code>"points"</code> or <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="decorana_+3A_labels">labels</code></td>
<td>
<p>Optional text to be used instead of row names.</p>
</td></tr>
<tr><td><code id="decorana_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of indices
of displayed items.</p>
</td></tr>
<tr><td><code id="decorana_+3A_xlim">xlim</code>, <code id="decorana_+3A_ylim">ylim</code></td>
<td>
<p>the x and y limits (min,max) of the plot.</p>
</td></tr>
<tr><td><code id="decorana_+3A_digits">digits</code></td>
<td>
<p>Number of digits in summary output.</p>
</td></tr>
<tr><td><code id="decorana_+3A_head">head</code>, <code id="decorana_+3A_tail">tail</code></td>
<td>
<p>Number of rows printed from the head and tail of
species and site scores. Default <code>NA</code> prints all.</p>
</td></tr>
<tr><td><code id="decorana_+3A_fraction">fraction</code></td>
<td>
<p>Abundance fraction where downweighting begins.</p>
</td></tr>
<tr><td><code id="decorana_+3A_tidy">tidy</code></td>
<td>
<p>Return scores that are compatible with <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>:
all scores are in a single <code>data.frame</code>, score type is
identified by factor variable <code>score</code> (<code>"sites"</code>,
<code>"species"</code>), the names by variable <code>label</code>. These scores
are incompatible with conventional <code>plot</code> functions, but they can
be used in <span class="pkg">ggplot2</span>.</p>
</td></tr>
<tr><td><code id="decorana_+3A_...">...</code></td>
<td>
<p>Other arguments for <code>plot</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In late 1970s, correspondence analysis became the method of choice for
ordination in vegetation science, since it seemed better able to cope 
with non-linear species responses than principal components
analysis. However, even correspondence analysis can produce an arc-shaped
configuration of a single gradient. Mark Hill developed detrended
correspondence analysis to correct two assumed &lsquo;faults&rsquo; in 
correspondence analysis: curvature of straight gradients and packing
of sites at the ends of the gradient.  
</p>
<p>The curvature is removed by replacing the orthogonalization of axes
with detrending.  In orthogonalization successive axes are made
non-correlated, but detrending should remove all systematic dependence
between axes.  Detrending is performed using a smoothing window on
<code>mk</code> segments.  The packing of sites at the ends of the gradient
is undone by rescaling the axes after extraction.  After rescaling,
the axis is supposed to be scaled by &lsquo;SD&rsquo; units, so that the
average width of Gaussian species responses is supposed to be one over
whole axis. Other innovations were the piecewise linear transformation
of species abundances and downweighting of rare species which were
regarded to have an unduly high influence on ordination axes.
</p>
<p>It seems that detrending actually works by twisting the ordination
space, so that the results look non-curved in two-dimensional
projections (&lsquo;lolly paper effect&rsquo;).  As a result, the points
usually have an easily recognized triangular or diamond shaped
pattern, obviously an artefact of detrending.  Rescaling works
differently than commonly presented, too. <code>decorana</code> does not
use, or even evaluate, the widths of species responses.  Instead, it
tries to equalize the weighted standard deviation of species scores on
axis segments (parameter <code>mk</code> has no effect, since
<code>decorana</code> finds the segments internally). Function
<code><a href="#topic+tolerance">tolerance</a></code> returns this internal criterion and can be
used to assess the success of rescaling.
</p>
<p>The <code>summary</code> method prints the ordination scores,
possible prior weights used in downweighting, and the marginal totals
after applying these weights. The <code>plot</code> method plots
species and site scores.  Classical <code>decorana</code> scaled the axes
so that smallest site score was 0 (and smallest species score was
negative), but <code>summary</code>, <code>plot</code> and
<code>scores</code> use the true origin, unless <code>origin = FALSE</code>.
</p>
<p>In addition to proper eigenvalues, the function reports
&lsquo;decorana values&rsquo; in detrended analysis. These &lsquo;decorana
values&rsquo; are the values that the legacy code of <code>decorana</code> returns
as eigenvalues. They are estimated during iteration, and describe the
joint effects of axes and detrending. The &lsquo;decorana values&rsquo; are
estimated before rescaling and do not show its effect on
eigenvalues. The proper eigenvalues are estimated after extraction of
the axes and they are the ratio of weighted sum of squares of site and
species scores even in detrended and rescaled solutions. These
eigenvalues are estimated for each axis separately, but they are not
additive, because higher <code>decorana</code> axes can show effects already
explained by prior axes. &lsquo;Additive eigenvalues&rsquo; are cleansed
from the effects of prior axes, and they can be assumed to add up to
total inertia (scaled Chi-square). For proportions and cumulative
proportions explained you can use <code><a href="#topic+eigenvals.decorana">eigenvals.decorana</a></code>.
</p>


<h3>Value</h3>

<p><code>decorana</code> returns an object of class <code>"decorana"</code>, which
has <code>print</code>, <code>summary</code>, <code>scores</code>, <code>plot</code>,
<code>points</code> and <code>text</code> methods, and support functions
<code><a href="#topic+eigenvals">eigenvals</a></code>, <code><a href="#topic+bstick">bstick</a></code>, <code>screeplot</code>,
<code>predict</code> and <code><a href="#topic+tolerance">tolerance</a></code>. <code>downweight</code> is an
independent function that can also be used with other methods than
<code>decorana</code>.
</p>


<h3>Note</h3>

<p><code>decorana</code> uses the central numerical engine of the
original Fortran code (which is in the public domain), or about 1/3 of
the original program.  I have tried to implement the original
behaviour, although a great part of preparatory steps were written in
<span class="rlang"><b>R</b></span> language, and may differ somewhat from the original code. However,
well-known bugs are corrected and strict criteria used (Oksanen &amp;
Minchin 1997). 
</p>
<p>Please note that there really is no need for piecewise transformation
or even downweighting within <code>decorana</code>, since there are more
powerful and extensive alternatives in <span class="rlang"><b>R</b></span>, but these options are
included for compliance with the original software.  If a different
fraction of abundance is needed in downweighting, function
<code>downweight</code> must be applied before <code>decorana</code>.  Function
<code>downweight</code> indeed can be applied prior to correspondence
analysis, and so it can be used together with <code><a href="#topic+cca">cca</a></code>, too.
</p>
<p>Github package <span class="pkg">natto</span> has an <span class="rlang"><b>R</b></span> implementation of
<code>decorana</code> which allows easier inspection of the
algorithm and also easier development of the function.
</p>


<h3>Author(s)</h3>

<p>Mark O. Hill wrote the original Fortran code, the <span class="rlang"><b>R</b></span> port was by
Jari Oksanen. </p>


<h3>References</h3>

<p>Hill, M.O. and Gauch, H.G. (1980). Detrended correspondence analysis:
an improved ordination technique. <em>Vegetatio</em> <strong>42</strong>,
47&ndash;58.
</p>
<p>Oksanen, J. and Minchin, P.R. (1997). Instability of ordination
results under changes in input data order: explanations and
remedies. <em>Journal of Vegetation Science</em> <strong>8</strong>, 447&ndash;454.
</p>


<h3>See Also</h3>

<p>For unconstrained ordination, non-metric multidimensional scaling in
<code><a href="#topic+monoMDS">monoMDS</a></code> may be more robust (see also
<code><a href="#topic+metaMDS">metaMDS</a></code>).  Constrained (or &lsquo;canonical&rsquo;)
correspondence analysis can be made with <code><a href="#topic+cca">cca</a></code>.
Orthogonal correspondence analysis can be made with <code>decorana</code> or
<code><a href="#topic+cca">cca</a></code>, but the scaling of results vary (and the one in
<code>decorana</code> corresponds to <code>scaling = "sites"</code> and <code>hill
  = TRUE</code> in <code><a href="#topic+cca">cca</a></code>.).  See <code><a href="#topic+predict.decorana">predict.decorana</a></code>
for adding new points to an ordination.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
vare.dca &lt;- decorana(varespec)
vare.dca
summary(vare.dca)
plot(vare.dca)

### the detrending rationale:
gaussresp &lt;- function(x,u) exp(-(x-u)^2/2)
x &lt;- seq(0,6,length=15) ## The gradient
u &lt;- seq(-2,8,len=23)   ## The optima
pack &lt;- outer(x,u,gaussresp)
matplot(x, pack, type="l", main="Species packing")
opar &lt;- par(mfrow=c(2,2))
plot(scores(prcomp(pack)), asp=1, type="b", main="PCA")
plot(scores(decorana(pack, ira=1)), asp=1, type="b", main="CA")
plot(scores(decorana(pack)), asp=1, type="b", main="DCA")
plot(scores(cca(pack ~ x), dis="sites"), asp=1, type="b", main="CCA")

### Let's add some noise:
noisy &lt;- (0.5 + runif(length(pack)))*pack
par(mfrow=c(2,1))
matplot(x, pack, type="l", main="Ideal model")
matplot(x, noisy, type="l", main="Noisy model")
par(mfrow=c(2,2))
plot(scores(prcomp(noisy)), type="b", main="PCA", asp=1)
plot(scores(decorana(noisy, ira=1)), type="b", main="CA", asp=1)
plot(scores(decorana(noisy)), type="b", main="DCA", asp=1)
plot(scores(cca(noisy ~ x), dis="sites"), asp=1, type="b", main="CCA")
par(opar)
</code></pre>

<hr>
<h2 id='decostand'>Standardization Methods for Community Ecology</h2><span id='topic+decostand'></span><span id='topic+wisconsin'></span><span id='topic+decobackstand'></span>

<h3>Description</h3>

<p>The function provides some popular (and effective) standardization
methods for community ecologists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decostand(x, method, MARGIN, range.global, logbase = 2, na.rm=FALSE, ...)
wisconsin(x)
decobackstand(x, zap = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decostand_+3A_x">x</code></td>
<td>
<p>Community data, a matrix-like object. For
<code>decobackstand</code> standardized data. </p>
</td></tr>
<tr><td><code id="decostand_+3A_method">method</code></td>
<td>
<p>Standardization method. See Details for available options.</p>
</td></tr>
<tr><td><code id="decostand_+3A_margin">MARGIN</code></td>
<td>
<p>Margin, if default is not acceptable. <code>1</code> = rows,
and <code>2</code> = columns of <code>x</code>.</p>
</td></tr>
<tr><td><code id="decostand_+3A_range.global">range.global</code></td>
<td>
<p>Matrix from which the range is found in
<code>method = "range"</code>.  This allows using same ranges across
subsets of data.  The dimensions of <code>MARGIN</code> must match with
<code>x</code>. </p>
</td></tr>
<tr><td><code id="decostand_+3A_logbase">logbase</code></td>
<td>
<p>The logarithm base used in <code>method = "log"</code>.</p>
</td></tr>
<tr><td><code id="decostand_+3A_na.rm">na.rm</code></td>
<td>
<p>Ignore missing values in row or column standardizations.</p>
</td></tr>
<tr><td><code id="decostand_+3A_zap">zap</code></td>
<td>
<p>Make near-zero values exact zeros to avoid negative
values and exaggerated estimates of species richness.</p>
</td></tr>
<tr><td><code id="decostand_+3A_...">...</code></td>
<td>
<p>Other arguments to the function (ignored).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function offers following standardization methods for community
data:
</p>

<ul>
<li> <p><code>total</code>: divide by margin total (default <code>MARGIN = 1</code>).
</p>
</li>
<li> <p><code>max</code>: divide by margin maximum (default <code>MARGIN = 2</code>).
</p>
</li>
<li> <p><code>frequency</code>: divide by margin total and multiply by the
number of non-zero items, so that the average of non-zero entries is
one (Oksanen 1983; default <code>MARGIN = 2</code>).
</p>
</li>
<li> <p><code>normalize</code>: make margin sum of squares equal to one (default
<code>MARGIN = 1</code>).
</p>
</li>
<li> <p><code>range</code>: standardize values into range 0 ... 1 (default
<code>MARGIN = 2</code>).  If all values are constant, they will be
transformed to 0.
</p>
</li>
<li> <p><code>rank, rrank</code>: <code>rank</code> replaces abundance values by
their increasing ranks leaving zeros unchanged, and <code>rrank</code> is
similar but uses relative ranks with maximum 1 (default
<code>MARGIN = 1</code>). Average ranks are used for tied values.
</p>
</li>
<li> <p><code>standardize</code>: scale <code>x</code> to zero mean and unit variance
(default <code>MARGIN = 2</code>).
</p>
</li>
<li> <p><code>pa</code>: scale <code>x</code> to presence/absence scale (0/1).
</p>
</li>
<li> <p><code>chi.square</code>: divide by row sums and square root of
column sums, and adjust for square root of matrix total
(Legendre &amp; Gallagher 2001). When used with the Euclidean
distance, the distances should be similar to the
Chi-square distance used in correspondence analysis. However, the
results from <code><a href="stats.html#topic+cmdscale">cmdscale</a></code> would still differ, since
CA is a weighted ordination method (default <code>MARGIN = 1</code>).
</p>
</li>
<li> <p><code>hellinger</code>: square root of <code>method = "total"</code>
(Legendre &amp; Gallagher 2001).
</p>
</li>
<li> <p><code>log</code>: logarithmic transformation as suggested by
Anderson et al. (2006): <code class="reqn">\log_b (x) + 1</code> for
<code class="reqn">x &gt; 0</code>, where <code class="reqn">b</code> is the base of the logarithm; zeros are
left as zeros. Higher bases give less weight to quantities and more
to presences, and <code>logbase = Inf</code> gives the presence/absence
scaling. Please note this is <em>not</em> <code class="reqn">\log(x+1)</code>.
Anderson et al. (2006) suggested this for their (strongly) modified
Gower distance (implemented as <code>method = "altGower"</code> in 
<code><a href="#topic+vegdist">vegdist</a></code>), but the standardization can be used 
independently of distance indices.
</p>
</li>
<li> <p><code>alr</code>: Additive log ratio (&quot;alr&quot;) transformation
(Aitchison 1986) reduces data skewness and compositionality
bias. The transformation assumes positive values, pseudocounts can
be added with the argument <code>pseudocount</code>. One of the
rows/columns is a reference that can be given by <code>reference</code>
(name of index). The first row/column is used by default
(<code>reference = 1</code>).  Note that this transformation drops one
row or column from the transformed output data. The <code>alr</code>
transformation is defined formally as follows:
</p>
<p style="text-align: center;"><code class="reqn">alr = [log\frac{x_1}{x_D}, ..., log\frac{x_{D-1}}{x_D}]</code>
</p>

<p>where the denominator sample <code class="reqn">x_D</code> can be chosen
arbitrarily. This transformation is often used with pH and other
chemistry measurenments. It is also commonly used as multinomial
logistic regression. Default <code>MARGIN = 1</code> uses row as the
<code>reference</code>.
</p>
</li>
<li> <p><code>clr</code>: centered log ratio (&quot;clr&quot;) transformation proposed by
Aitchison (1986) reduces data skewness and compositionality bias.
This transformation has frequent applications in microbial ecology
(see e.g. Gloor et al., 2017).
</p>
<p style="text-align: center;"><code class="reqn">clr = log\frac{x_{r}}{g(x_{r})} = log x_{r} - log ¬µ_{r}</code>
</p>

<p>where <code class="reqn">x_{r}</code> is a single relative value, <code class="reqn">g(x_{r})</code> is
the geometric mean
of relative values per sample, and <code class="reqn">\mu_{r}</code> is the arithmetic mean of 
relative values per sample. The method can operate only with positive data;
a common way to deal with zeroes is to add pseudocount, either by
adding it manually to the input data, or by using the argument
<code>pseudocount</code> as in
<code>decostand(x, method = "clr", pseudocount = 1)</code>. Adding
pseudocount will inevitably introduce some bias; see
the <code>rclr</code> method for one available solution.
</p>
</li>
<li> <p><code>rclr</code>: robust clr (&quot;rclr&quot;) is similar to regular clr
(see above) but allows data that contains zeroes. This method
does not use pseudocounts, unlike the standard clr.
Robust clr divides the values by geometric mean
of the observed features; zero values are kept as zeroes, and not
taken into account. In high dimensional data,
the geometric mean of rclr is a good approximation of the true
geometric mean; see e.g. Martino et al. (2019)
The <code>rclr</code> transformation is defined formally as follows:
</p>
<p style="text-align: center;"><code class="reqn">rclr = log\frac{x_{r}}{g(x_{r} &gt; 0)}</code>
</p>

<p>where <code class="reqn">x_{r}</code> is a single relative value, and <code class="reqn">g(x_{r} &gt; 0)</code>
is geometric  mean of sample-wide relative values that are positive
(over 0).
</p>
</li></ul>

<p>Standardization, as contrasted to transformation, means that the
entries are transformed relative to other entries.
</p>
<p>All methods have a default margin. <code>MARGIN=1</code> means rows (sites
in a normal data set) and <code>MARGIN=2</code> means columns (species in a
normal data set).
</p>
<p>Command <code>wisconsin</code> is a shortcut to common Wisconsin double
standardization where species (<code>MARGIN=2</code>) are first standardized
by maxima (<code>max</code>) and then sites (<code>MARGIN=1</code>) by
site totals (<code>tot</code>).
</p>
<p>Most standardization methods will give nonsense results with
negative data entries that normally should not occur in the community
data. If there are empty sites or species (or constant with
<code>method =  "range"</code>), many standardization will change these into
<code>NaN</code>.
</p>
<p>Function <code>decobackstand</code> can be used to transform standardized
data back to original. This is not possible for all standardization
and may not be implemented to all cases where it would be
possible. There are round-off errors and back-transformation is not
exact, and it is wise not to overwrite the original data. With
<code>zap=TRUE</code> original zeros should be exact.
</p>


<h3>Value</h3>

<p>Returns the standardized data frame, and adds an attribute
<code>"decostand"</code> giving the name of applied standardization
<code>"method"</code> and attribute <code>"parameters"</code> with appropriate
transformation parameters.  </p>


<h3>Note</h3>

<p>Common transformations can be made with standard <span class="rlang"><b>R</b></span> functions.</p>


<h3>Author(s)</h3>

<p>Jari Oksanen, Etienne Lalibert√©
(<code>method = "log"</code>), Leo Lahti (<code>alr</code>, 
<code>"clr"</code> and <code>"rclr"</code>).</p>


<h3>References</h3>

 
<p>Aitchison, J. The Statistical Analysis of Compositional Data (1986).
London, UK: Chapman &amp; Hall.
</p>
<p>Anderson, M.J., Ellingsen, K.E. &amp; McArdle, B.H. (2006) Multivariate
dispersion as a measure of beta diversity. <em>Ecology Letters</em> 
<strong>9</strong>, 683&ndash;693.
</p>
<p>Egozcue, J.J., Pawlowsky-Glahn, V., Mateu-Figueras, G.,
Barcel'o-Vidal, C. (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>
<strong>35</strong>, 279&ndash;300.
</p>
<p>Gloor, G.B., Macklaim, J.M., Pawlowsky-Glahn, V. &amp; Egozcue, J.J. (2017)
Microbiome Datasets Are Compositional: And This Is Not Optional.
<em>Frontiers in Microbiology</em> <strong>8</strong>, 2224. 
</p>
<p>Legendre, P. &amp; Gallagher, E.D. (2001) Ecologically meaningful
transformations for ordination of species data. <em>Oecologia</em>
<strong>129</strong>, 271&ndash;280.
</p>
<p>Martino, C., Morton, J.T., Marotz, C.A., Thompson, L.R., Tripathi, A.,
Knight, R. &amp; Zengler, K. (2019) A novel sparse compositional technique
reveals microbial perturbations.
<em>mSystems</em> <strong>4</strong>, 1.
</p>
<p>Oksanen, J. (1983) Ordination of boreal heath-like vegetation with
principal component analysis, correspondence analysis and
multidimensional scaling. <em>Vegetatio</em> <strong>52</strong>, 181&ndash;189.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
sptrans &lt;- decostand(varespec, "max")
apply(sptrans, 2, max)
sptrans &lt;- wisconsin(varespec)

# CLR transformation for rows, with pseudocount
varespec.clr &lt;- decostand(varespec, "clr", pseudocount=1)

# ALR transformation for rows, with pseudocount and reference sample
varespec.alr &lt;- decostand(varespec, "alr", pseudocount=1, reference=1)

## Chi-square: PCA similar but not identical to CA.
## Use wcmdscale for weighted analysis and identical results.
sptrans &lt;- decostand(varespec, "chi.square")
plot(procrustes(rda(sptrans), cca(varespec)))
</code></pre>

<hr>
<h2 id='designdist'>Design your own Dissimilarities </h2><span id='topic+designdist'></span><span id='topic+chaodist'></span>

<h3>Description</h3>

<p>Function <code>designdist</code> lets you define your own dissimilarities
using terms for shared and total quantities, number of rows and number
of columns. The shared and total quantities can be binary, quadratic
or minimum terms. In binary terms, the shared component is number of
shared species, and totals are numbers of species on sites. The
quadratic terms are cross-products and sums of squares, and minimum
terms are sums of parallel minima and row totals. Function
<code>chaodist</code> lets you define your own dissimilarities using terms
that are supposed to take into account the &ldquo;unseen species&rdquo;
(see Chao et al., 2005 and Details in <code><a href="#topic+vegdist">vegdist</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>designdist(x, method = "(A+B-2*J)/(A+B)",
           terms = c("binary", "quadratic", "minimum"), 
           abcd = FALSE, alphagamma = FALSE, name, maxdist)
chaodist(x, method = "1 - 2*U*V/(U+V)", name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="designdist_+3A_x">x</code></td>
<td>
<p>Input data. </p>
</td></tr>
<tr><td><code id="designdist_+3A_method">method</code></td>
<td>
<p>Equation for your dissimilarities. This can use terms
<code>J</code> for shared quantity, <code>A</code> and <code>B</code> for totals,
<code>N</code> for the number of rows (sites) and <code>P</code> for the
number of columns (species) or in <code>chaodist</code> it can use terms
<code>U</code> and <code>V</code>. The equation can also contain any <span class="rlang"><b>R</b></span>
functions that accepts vector arguments and returns vectors of the
same length. </p>
</td></tr>
<tr><td><code id="designdist_+3A_terms">terms</code></td>
<td>
<p>How shared and total components are found. For vectors
<code>x</code> and <code>y</code> the  <code>"quadratic"</code> terms are <code>J = sum(x*y)</code>,
<code>A = sum(x^2)</code>, <code>B = sum(y^2)</code>, and <code>"minimum"</code> terms
are <code>J = sum(pmin(x,y))</code>, <code>A = sum(x)</code> and <code>B = sum(y)</code>, 
and <code>"binary"</code> terms are either of these after transforming
data into binary form (shared number of species, and number of
species for each row). </p>
</td></tr>
<tr><td><code id="designdist_+3A_abcd">abcd</code></td>
<td>
<p>Use 2x2 contingency table notation for binary data:
<code class="reqn">a</code> is the number of shared species, <code class="reqn">b</code> and <code class="reqn">c</code> are the
numbers of species occurring only one of the sites but not in both,
and <code class="reqn">d</code> is the number of species that occur on neither of the sites.</p>
</td></tr>
<tr><td><code id="designdist_+3A_alphagamma">alphagamma</code></td>
<td>
<p>Use beta diversity notation with terms
<code>alpha</code> for average alpha diversity for compared sites,
<code>gamma</code> for diversity in pooled sites, and <code>delta</code> for the
absolute value of difference of average <code>alpha</code> and alpha
diversities of compared sites. Terms <code>A</code> and
<code>B</code> refer to alpha diversities of compared sites.</p>
</td></tr>
<tr><td><code id="designdist_+3A_name">name</code></td>
<td>
<p>The name you want to use for your index. The default is to
combine the <code>method</code> equation and <code>terms</code> argument.</p>
</td></tr>
<tr><td><code id="designdist_+3A_maxdist">maxdist</code></td>
<td>
<p>Theoretical maximum of the dissimilarity, or <code>NA</code>
if index is open and has no absolute maximum. This is not a necessary
argument, but only used in some <span class="pkg">vegan</span> functions, and if you are
not certain about the maximum, it is better not supply any value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most popular dissimilarity measures in ecology can be expressed with
the help of terms <code>J</code>, <code>A</code> and <code>B</code>, and some also involve
matrix dimensions <code>N</code> and <code>P</code>. Some examples you can define in
<code>designdist</code> are:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>A+B-2*J</code> </td><td style="text-align: left;"> <code>"quadratic"</code> </td><td style="text-align: left;"> squared Euclidean </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>A+B-2*J</code> </td><td style="text-align: left;"> <code>"minimum"</code> </td><td style="text-align: left;"> Manhattan </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>(A+B-2*J)/(A+B)</code> </td><td style="text-align: left;"> <code>"minimum"</code> </td><td style="text-align: left;"> Bray-Curtis </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>(A+B-2*J)/(A+B)</code> </td><td style="text-align: left;"> <code>"binary"</code> </td><td style="text-align: left;">
    S√∏rensen </td>
</tr>
<tr>
 <td style="text-align: left;"> 
    <code>(A+B-2*J)/(A+B-J)</code> </td><td style="text-align: left;"> <code>"binary"</code> </td><td style="text-align: left;"> Jaccard </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>(A+B-2*J)/(A+B-J)</code> </td><td style="text-align: left;"> <code>"minimum"</code> </td><td style="text-align: left;">
    Ru≈æiƒçka </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>(A+B-2*J)/(A+B-J)</code> </td><td style="text-align: left;"> <code>"quadratic"</code> </td><td style="text-align: left;">
    (dis)similarity ratio </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>1-J/sqrt(A*B)</code> </td><td style="text-align: left;"> <code>"binary"</code> </td><td style="text-align: left;"> Ochiai </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>1-J/sqrt(A*B)</code> </td><td style="text-align: left;"> <code>"quadratic"</code> </td><td style="text-align: left;"> cosine
    complement </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>1-phyper(J-1, A, P-A, B)</code> </td><td style="text-align: left;"> <code>"binary"</code> </td><td style="text-align: left;"> Raup-Crick (but see <code><a href="#topic+raupcrick">raupcrick</a></code>)
  </td>
</tr>

</table>

<p>The function <code>designdist</code> can implement most dissimilarity
indices in <code><a href="#topic+vegdist">vegdist</a></code> or elsewhere, and it can also be
used to implement many other indices, amongst them, most of those
described in Legendre &amp; Legendre (2012). It can also be used to
implement all indices of beta diversity described in Koleff et
al. (2003), but there also is a specific function
<code><a href="#topic+betadiver">betadiver</a></code> for the purpose.
</p>
<p>If you want to implement binary dissimilarities based on the 2x2
contingency table notation, you can set <code>abcd = TRUE</code>. In this
notation <code>a = J</code>, <code>b = A-J</code>, <code>c = B-J</code>, <code>d = P-A-B+J</code>. 
This notation is often used instead of the more more
tangible default notation for reasons that are opaque to me.
</p>
<p>With <code>alphagamma = TRUE</code> it is possible to use beta diversity
notation with terms <code>alpha</code> for average alpha diversity and
<code>gamma</code> for gamma diversity in two compared sites. The terms
are calculated as <code>alpha = (A+B)/2</code>, <code>gamma = A+B-J</code> and
<code>delta = abs(A-B)/2</code>.  Terms <code>A</code> and <code>B</code> are also
available and give the alpha diversities of the individual compared
sites.  The beta diversity terms may make sense only for binary
terms (so that diversities are expressed in numbers of species), but
they are calculated for quadratic and minimum terms as well (with a
warning).
</p>
<p>Function <code>chaodist</code> is similar to <code>designgist</code>, but uses
terms <code>U</code> and <code>V</code> of Chao et al. (2005). These terms are
supposed to take into account the effects of unseen species. Both
<code>U</code> and <code>V</code> are scaled to range <code class="reqn">0 \dots 1</code>. They take
the place of <code>A</code> and <code>B</code> and the product <code>U*V</code> is used
in the place of <code>J</code> of <code>designdist</code>.  Function
<code>chaodist</code> can implement any commonly used Chao et al. (2005)
style dissimilarity:
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>1 - 2*U*V/(U+V)</code> </td><td style="text-align: left;"> S√∏rensen type </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>1 - U*V/(U+V-U*V)</code> </td><td style="text-align: left;"> Jaccard type </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>1 - sqrt(U*V)</code> </td><td style="text-align: left;"> Ochiai type </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>(pmin(U,V) - U*V)/pmin(U,V)</code> </td><td style="text-align: left;"> Simpson type
  </td>
</tr>

</table>

<p>Function <code><a href="#topic+vegdist">vegdist</a></code> implements Jaccard-type Chao distance,
and its documentation contains more complete discussion on the
calculation of the terms.
</p>


<h3>Value</h3>

<p><code>designdist</code> returns an object of class <code><a href="stats.html#topic+dist">dist</a></code>.
</p>


<h3>Note</h3>

<p><code>designdist</code> does not use compiled code, but it is based on
vectorized <span class="rlang"><b>R</b></span> code. The <code>designdist</code> function can be much
faster than <code><a href="#topic+vegdist">vegdist</a></code>, although the latter uses compiled
code. However, <code>designdist</code> cannot skip missing values and uses
much more memory during calculations.
</p>
<p>The use of sum terms can be numerically unstable. In particularly,
when these terms are large, the precision may be lost. The risk is
large when the number of columns is high, and particularly large with
quadratic terms. For precise calculations it is better to use
functions like <code><a href="stats.html#topic+dist">dist</a></code> and <code><a href="#topic+vegdist">vegdist</a></code> which are
more robust against numerical problems.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Chao, A., Chazdon, R. L., Colwell, R. K. and Shen, T. (2005) A new
statistical approach for assessing similarity of species composition
with incidence and abundance data. <em>Ecology Letters</em> <strong>8</strong>,
148&ndash;159.
</p>
<p>Koleff, P., Gaston, K.J. and Lennon, J.J. (2003) Measuring beta
diversity for presence&ndash;absence data. <em>J. Animal Ecol.</em>
<strong>72</strong>, 367&ndash;382. 
</p>
<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd
English ed. Elsevier
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+vegdist">vegdist</a></code>, <code><a href="#topic+betadiver">betadiver</a></code>, <code><a href="stats.html#topic+dist">dist</a></code>,
<code><a href="#topic+raupcrick">raupcrick</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
## Four ways of calculating the same S√∏rensen dissimilarity
d0 &lt;- vegdist(BCI, "bray", binary = TRUE)
d1 &lt;- designdist(BCI, "(A+B-2*J)/(A+B)")
d2 &lt;- designdist(BCI, "(b+c)/(2*a+b+c)", abcd = TRUE)
d3 &lt;- designdist(BCI, "gamma/alpha - 1", alphagamma = TRUE)
## Arrhenius dissimilarity: the value of z in the species-area model
## S = c*A^z when combining two sites of equal areas, where S is the
## number of species, A is the area, and c and z are model parameters.
## The A below is not the area (which cancels out), but number of
## species in one of the sites, as defined in designdist().
dis &lt;- designdist(BCI, "(log(A+B-J)-log(A+B)+log(2))/log(2)")
## This can be used in clustering or ordination...
ordiplot(cmdscale(dis))
## ... or in analysing beta diversity (without gradients)
summary(dis)
  </code></pre>

<hr>
<h2 id='deviance.cca'> Statistics Resembling Deviance and AIC for Constrained Ordination</h2><span id='topic+deviance.cca'></span><span id='topic+deviance.rda'></span><span id='topic+extractAIC.cca'></span>

<h3>Description</h3>

<p>The functions extract statistics that resemble deviance and AIC from the
result of constrained correspondence analysis <code><a href="#topic+cca">cca</a></code> or
redundancy analysis <code><a href="#topic+rda">rda</a></code>.  These functions are rarely
needed directly, but they are called by <code><a href="stats.html#topic+step">step</a></code> in
automatic model building.  Actually, <code><a href="#topic+cca">cca</a></code> and
<code><a href="#topic+rda">rda</a></code> do not have <code><a href="stats.html#topic+AIC">AIC</a></code> and these functions
are certainly wrong.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
deviance(object, ...)

## S3 method for class 'cca'
extractAIC(fit, scale = 0, k = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deviance.cca_+3A_object">object</code></td>
<td>
<p>the result of a constrained ordination
(<code><a href="#topic+cca">cca</a></code> or <code><a href="#topic+rda">rda</a></code>). </p>
</td></tr>
<tr><td><code id="deviance.cca_+3A_fit">fit</code></td>
<td>
<p>fitted model from constrained ordination.</p>
</td></tr>
<tr><td><code id="deviance.cca_+3A_scale">scale</code></td>
<td>
<p>optional numeric specifying the scale parameter of the model,
see <code>scale</code> in <code><a href="stats.html#topic+step">step</a></code>.</p>
</td></tr>
<tr><td><code id="deviance.cca_+3A_k">k</code></td>
<td>
<p>numeric specifying the &quot;weight&quot; of the <em>equivalent degrees of
freedom</em> (=:<code>edf</code>) part in the AIC formula.</p>
</td></tr>
<tr><td><code id="deviance.cca_+3A_...">...</code></td>
<td>
<p>further arguments. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions find statistics that
resemble <code><a href="stats.html#topic+deviance">deviance</a></code> and <code><a href="stats.html#topic+AIC">AIC</a></code> in constrained
ordination.  Actually, constrained ordination methods do not have a
log-Likelihood, which means that they cannot have AIC and deviance.
Therefore you should not use these functions, and if you use them, you
should not trust them.  If you use these functions, it remains as your
responsibility to check the adequacy of the result.
</p>
<p>The deviance of <code><a href="#topic+cca">cca</a></code> is equal to the Chi-square of
the residual data matrix after fitting the constraints.  The deviance
of  <code><a href="#topic+rda">rda</a></code> is defined as the residual sum of squares. The
deviance function of <code>rda</code> is also used for
<code><a href="#topic+capscale">capscale</a></code>. Function <code>extractAIC</code> mimics
<code>extractAIC.lm</code> in translating deviance to AIC.
</p>
<p>There is little need to call these functions directly.  However, they
are called implicitly in <code><a href="stats.html#topic+step">step</a></code> function used in automatic
selection of constraining variables.  You should check the resulting
model with some other criteria, because the statistics used here are
unfounded. In particular, the penalty <code>k</code> is not properly
defined, and the default <code>k = 2</code> is not justified
theoretically. If you have only continuous covariates, the <code>step</code>
function will base the model building on magnitude of eigenvalues, and
the value of <code>k</code> only influences the stopping point (but the
variables with the highest eigenvalues are not necessarily the most
significant in permutation tests in <code><a href="#topic+anova.cca">anova.cca</a></code>). If you
also have multi-class factors, the value of <code>k</code> will have a
capricious effect in model building. The <code><a href="stats.html#topic+step">step</a></code> function
will pass arguments to <code><a href="#topic+add1.cca">add1.cca</a></code> and
<code><a href="#topic+drop1.cca">drop1.cca</a></code>, and setting <code>test = "permutation"</code>
will provide permutation tests of each deletion and addition which
can help in judging the validity of the model building.
</p>


<h3>Value</h3>

<p>The <code>deviance</code> functions return &ldquo;deviance&rdquo;, and
<code>extractAIC</code> returns effective degrees of freedom and &ldquo;AIC&rdquo;. 
</p>


<h3>Note</h3>

<p>These functions are unfounded and untested and they should not be used
directly or implicitly.  Moreover, usual caveats in using 
<code><a href="stats.html#topic+step">step</a></code> are very valid.
</p>


<h3>Author(s)</h3>

<p> Jari  Oksanen </p>


<h3>References</h3>

<p>God√≠nez-Dom√≠nguez, E. &amp; Freire, J. (2003)
Information-theoretic approach for selection of spatial and temporal
models of community organization. <em>Marine Ecology Progress
Series</em> <strong>253</strong>, 17&ndash;24. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+anova.cca">anova.cca</a></code>,
<code><a href="stats.html#topic+step">step</a></code>, <code><a href="stats.html#topic+extractAIC">extractAIC</a></code>,
<code><a href="#topic+add1.cca">add1.cca</a></code>, <code><a href="#topic+drop1.cca">drop1.cca</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'># The deviance of correspondence analysis equals Chi-square
data(dune)
data(dune.env)
chisq.test(dune)
deviance(cca(dune))
# Stepwise selection (forward from an empty model "dune ~ 1")
ord &lt;- cca(dune ~ ., dune.env)
step(cca(dune ~ 1, dune.env), scope = formula(ord))
</code></pre>

<hr>
<h2 id='dispindmorisita'>Morisita index of intraspecific aggregation</h2><span id='topic+dispindmorisita'></span>

<h3>Description</h3>

<p>Calculates the Morisita index of dispersion, standardized index values, and the so called clumpedness and uniform indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dispindmorisita(x, unique.rm = FALSE, crit = 0.05, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dispindmorisita_+3A_x">x</code></td>
<td>
<p>community data matrix, with sites (samples) as rows and
species as columns.</p>
</td></tr>
<tr><td><code id="dispindmorisita_+3A_unique.rm">unique.rm</code></td>
<td>
<p>logical, if <code>TRUE</code>, unique species (occurring
in only one sample) are removed from the result.</p>
</td></tr>
<tr><td><code id="dispindmorisita_+3A_crit">crit</code></td>
<td>
<p>two-sided p-value used to calculate critical
Chi-squared values.</p>
</td></tr>
<tr><td><code id="dispindmorisita_+3A_na.rm">na.rm</code></td>
<td>
<p>logical.
Should missing values (including <code>NaN</code>) be omitted from the
calculations?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Morisita index of dispersion is defined as (Morisita 1959, 1962):
</p>
<p><code>Imor = n * (sum(xi^2) - sum(xi)) / (sum(xi)^2 - sum(xi))</code>
</p>
<p>where <code class="reqn">xi</code> is the count of individuals in sample <code class="reqn">i</code>, and
<code class="reqn">n</code> is the number of samples (<code class="reqn">i = 1, 2, \ldots, n</code>).
<code class="reqn">Imor</code> has values from 0 to <code class="reqn">n</code>. In uniform (hyperdispersed)
patterns its value falls between 0 and 1, in clumped patterns it falls
between 1 and <code class="reqn">n</code>. For increasing sample sizes (i.e. joining
neighbouring quadrats), <code class="reqn">Imor</code> goes to <code class="reqn">n</code> as the
quadrat size approaches clump size. For random patterns,
<code class="reqn">Imor = 1</code> and counts in the samples follow Poisson
frequency distribution.
</p>
<p>The deviation from random expectation (null hypothesis)
can be tested using critical values of the Chi-squared
distribution with <code class="reqn">n-1</code> degrees of freedom.
Confidence intervals around 1 can be calculated by the clumped
<code class="reqn">Mclu</code> and uniform <code class="reqn">Muni</code> indices (Hairston et al. 1971, Krebs
1999) (Chi2Lower and Chi2Upper refers to e.g. 0.025 and 0.975 quantile
values of the Chi-squared distribution with <code class="reqn">n-1</code> degrees of
freedom, respectively, for <code>crit = 0.05</code>):
</p>
<p><code>Mclu = (Chi2Lower - n + sum(xi)) / (sum(xi) - 1)</code>
</p>
<p><code>Muni = (Chi2Upper - n + sum(xi)) / (sum(xi) - 1)</code>
</p>
<p>Smith-Gill (1975) proposed scaling of Morisita index from [0, n]
interval into [-1, 1], and setting up -0.5 and 0.5 values as
confidence limits around random distribution with rescaled value 0. To
rescale the Morisita index, one of the following four equations apply
to calculate the standardized index <code class="reqn">Imst</code>:
</p>
<p>(a) <code>Imor &gt;= Mclu &gt; 1</code>: <code>Imst = 0.5 + 0.5 (Imor - Mclu) / (n - Mclu)</code>,
</p>
<p>(b) <code>Mclu &gt; Imor &gt;= 1</code>: <code>Imst = 0.5 (Imor - 1) / (Mclu - 1)</code>,
</p>
<p>(c) <code>1 &gt; Imor &gt; Muni</code>: <code>Imst = -0.5 (Imor - 1) / (Muni - 1)</code>,
</p>
<p>(d) <code>1 &gt; Muni &gt; Imor</code>: <code>Imst = -0.5 + 0.5 (Imor - Muni) / Muni</code>.
</p>


<h3>Value</h3>

<p> Returns a data frame with as many rows as the number of columns
in the input data, and with four columns. Columns are: <code>imor</code> the
unstandardized Morisita index, <code>mclu</code> the clumpedness index,
<code>muni</code> the uniform index, <code>imst</code> the standardized Morisita
index, <code>pchisq</code> the Chi-squared based probability for the null
hypothesis of random expectation.
</p>


<h3>Note</h3>

<p> A common error found in several papers is that when standardizing
as in the case (b), the denominator is given as <code>Muni - 1</code>. This
results in a hiatus in the [0, 0.5] interval of the standardized
index. The root of this typo is the book of Krebs (1999), see the Errata
for the book (Page 217,
<a href="https://www.zoology.ubc.ca/~krebs/downloads/errors_2nd_printing.pdf">https://www.zoology.ubc.ca/~krebs/downloads/errors_2nd_printing.pdf</a>).
</p>


<h3>Author(s)</h3>

<p>P√©ter S√≥lymos, <a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a></p>


<h3>References</h3>

<p>Morisita, M. 1959. Measuring of the dispersion of individuals and
analysis of the distributional patterns.  <em>Mem. Fac. Sci. Kyushu
Univ. Ser. E</em> 2, 215&ndash;235.
</p>
<p>Morisita, M. 1962. Id-index, a measure of dispersion of individuals.
<em>Res. Popul. Ecol.</em> 4, 1&ndash;7.
</p>
<p>Smith-Gill, S. J. 1975. Cytophysiological basis of disruptive pigmentary
patterns in the leopard frog, <em>Rana pipiens</em>. II.  Wild type and
mutant cell specific patterns. <em>J. Morphol.</em> 146, 35&ndash;54.
</p>
<p>Hairston, N. G., Hill, R. and Ritte, U. 1971. The interpretation of
aggregation patterns. In: Patil, G. P., Pileou, E. C. and Waters,
W. E. eds. <em>Statistical Ecology 1: Spatial Patterns and Statistical
Distributions</em>. Penn. State Univ. Press, University Park.
</p>
<p>Krebs, C. J. 1999. <em>Ecological Methodology</em>. 2nd ed. Benjamin
Cummings Publishers.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
x &lt;- dispindmorisita(dune)
x
y &lt;- dispindmorisita(dune, unique.rm = TRUE)
y
dim(x) ## with unique species
dim(y) ## unique species removed
</code></pre>

<hr>
<h2 id='dispweight'>Dispersion-based weighting of species counts</h2><span id='topic+dispweight'></span><span id='topic+gdispweight'></span><span id='topic+summary.dispweight'></span>

<h3>Description</h3>

<p>Transform abundance data downweighting species that are 
overdispersed to the Poisson error.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dispweight(comm, groups, nsimul = 999, nullmodel = "c0_ind",
    plimit = 0.05)
gdispweight(formula, data, plimit = 0.05)
## S3 method for class 'dispweight'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dispweight_+3A_comm">comm</code></td>
<td>
<p>Community data matrix.</p>
</td></tr>
<tr><td><code id="dispweight_+3A_groups">groups</code></td>
<td>
<p>Factor describing the group structure. If missing, all 
sites are regarded as belonging to one group. <code>NA</code> values are 
not allowed.</p>
</td></tr>
<tr><td><code id="dispweight_+3A_nsimul">nsimul</code></td>
<td>
<p>Number of simulations.</p>
</td></tr>
<tr><td><code id="dispweight_+3A_nullmodel">nullmodel</code></td>
<td>
<p>The <code><a href="#topic+nullmodel">nullmodel</a></code> used in
<code><a href="#topic+commsim">commsim</a></code> within <code>groups</code>. The default
follows Clarke et al. (2006).</p>
</td></tr>
<tr><td><code id="dispweight_+3A_plimit">plimit</code></td>
<td>
<p>Downweight species if their <code class="reqn">p</code>-value is at or
below this limit.</p>
</td></tr>
<tr><td><code id="dispweight_+3A_formula">formula</code>, <code id="dispweight_+3A_data">data</code></td>
<td>
<p>Formula where the left-hand side is the
community data frame and right-hand side gives the explanatory
variables. The explanatory variables are found in the data frame
given in <code>data</code> or in the parent frame.</p>
</td></tr>
<tr><td><code id="dispweight_+3A_object">object</code></td>
<td>
<p>Result object from <code>dispweight</code> or
<code>gdispweight</code>.</p>
</td></tr>
<tr><td><code id="dispweight_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dispersion index (<code class="reqn">D</code>) is calculated as ratio between variance
and expected value for each species.  If the species abundances follow
Poisson distribution, expected dispersion is <code class="reqn">E(D) = 1</code>, and if
<code class="reqn">D &gt; 1</code>, the species is overdispersed. The inverse <code class="reqn">1/D</code> can
be used to downweight species abundances.  Species are only
downweighted when overdispersion is judged to be statistically
significant (Clarke et al. 2006).
</p>
<p>Function <code>dispweight</code> implements the original procedure of Clarke
et al. (2006). Only one factor can be used to group the sites and to
find the species means. The significance of overdispersion is assessed
freely distributing individuals of each species within factor
levels. This is achieved by using <code><a href="#topic+nullmodel">nullmodel</a></code>
<code>"c0_ind"</code> (which accords to Clarke et al. 2006), but other
nullmodels can be used, though they may not be meaningful (see
<code><a href="#topic+commsim">commsim</a></code> for alternatives). If a species is absent in
some factor level, the whole level is ignored in calculation of
overdispersion, and the number of degrees of freedom can vary among
species. The reduced number of degrees of freedom is used as a divisor
for overdispersion <code class="reqn">D</code>, and such species have higher dispersion
and hence lower weights in transformation.
</p>
<p>Function <code>gdispweight</code> is a generalized parametric version of
<code>dispweight</code>. The function is based on <code><a href="stats.html#topic+glm">glm</a></code> with
<code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code> error <code><a href="stats.html#topic+family">family</a></code>. Any
<code><a href="stats.html#topic+glm">glm</a></code> model can be used, including several factors or
continuous covariates. Function <code>gdispweight</code> uses the same test
statistic as <code>dispweight</code> (Pearson Chi-square), but it does not
ignore factor levels where species is absent, and the number of
degrees of freedom is equal for all species. Therefore transformation
weights can be higher than in <code>dispweight</code>. The
<code>gdispweight</code> function evaluates the significance of
overdispersion parametrically from Chi-square distribution
(<code><a href="stats.html#topic+pchisq">pchisq</a></code>).
</p>
<p>Functions <code>dispweight</code> and <code>gdispweight</code> transform data, but
they add information on overdispersion and weights as attributes of
the result. The <code>summary</code> can be used to extract and print that
information.  
</p>


<h3>Value</h3>

<p>Function returns transformed data with the following new attributes:
</p>
<table>
<tr><td><code>D</code></td>
<td>
<p>Dispersion statistic.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degrees of freedom for each species.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p><code class="reqn">p</code>-value of the Dispersion statistic <code class="reqn">D</code>.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>weights applied to community data.</p>
</td></tr>
<tr><td><code>nsimul</code></td>
<td>
<p>Number of simulations used to assess the <code class="reqn">p</code>-value,
or <code>NA</code> when simulations were not performed.</p>
</td></tr>
<tr><td><code>nullmodel</code></td>
<td>
<p>The name of <code><a href="#topic+commsim">commsim</a></code> null model, or
<code>NA</code> when simulations were not performed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eduard Sz√∂cs <a href="mailto:eduardszoesc@gmail.com">eduardszoesc@gmail.com</a> wrote the original
<code>dispweight</code>, Jari Oksanen significantly modified the code,
provided support functions and developed <code>gdispweight</code>.
</p>


<h3>References</h3>

<p>Clarke, K. R., M. G. Chapman, P. J. Somerfield, and
H. R. Needham. 2006. Dispersion-based weighting of species counts in
assemblage analyses. <em>Marine Ecology Progress Series</em>, 320,
11‚Äì27.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite, mite.env)
## dispweight and its summary
mite.dw &lt;- with(mite.env, dispweight(mite, Shrub, nsimul = 99))
## IGNORE_RDIFF_BEGIN
summary(mite.dw)
## IGNORE_RDIFF_END
## generalized dispersion weighting
mite.dw &lt;- gdispweight(mite ~ Shrub + WatrCont, data = mite.env)
rda(mite.dw ~ Shrub + WatrCont, data = mite.env)
</code></pre>

<hr>
<h2 id='distconnected'>Connectedness of Dissimilarities</h2><span id='topic+distconnected'></span><span id='topic+no.shared'></span>

<h3>Description</h3>

<p>Function <code>distconnected</code> finds groups that are connected
disregarding dissimilarities that are at or above a threshold or
<code>NA</code>. The function can be used to find groups that can be
ordinated together or transformed by
<code><a href="#topic+stepacross">stepacross</a></code>. Function <code>no.shared</code> returns a logical
dissimilarity object, where <code>TRUE</code> means that sites have no
species in common. This is a minimal structure for
<code>distconnected</code> or can be used to set missing values to
dissimilarities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distconnected(dis, toolong = 1, trace = TRUE)

no.shared(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distconnected_+3A_dis">dis</code></td>
<td>
<p>Dissimilarity data inheriting from class <code>dist</code> or
a an object, such as a matrix, that can be converted to a
dissimilarity matrix. Functions <code><a href="#topic+vegdist">vegdist</a></code> and
<code><a href="stats.html#topic+dist">dist</a></code> are some functions producing suitable
dissimilarity data.</p>
</td></tr>
<tr><td><code id="distconnected_+3A_toolong">toolong</code></td>
<td>
<p> Shortest dissimilarity regarded as <code>NA</code>.
The function uses a fuzz factor, so
that dissimilarities close to the limit will be made <code>NA</code>, too.
If <code>toolong = 0</code> (or negative), no dissimilarity is regarded
as too long.
</p>
</td></tr>
<tr><td><code id="distconnected_+3A_trace">trace</code></td>
<td>
<p>Summarize results of <code>distconnected</code></p>
</td></tr>
<tr><td><code id="distconnected_+3A_x">x</code></td>
<td>
<p>Community data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data sets are disconnected if they have sample plots or groups of
sample plots which share no species with other sites or groups of
sites. Such data sets cannot be sensibly ordinated by any
unconstrained method because these subsets cannot be related to each
other. For instance, correspondence analysis will polarize these
subsets with eigenvalue 1. Neither can such dissimilarities be
transformed with <code><a href="#topic+stepacross">stepacross</a></code>, because there is no path
between all points, and result will contain <code>NA</code>s. Function
<code>distconnected</code> will find such subsets in dissimilarity
matrices. The function will return a grouping vector that can be used
for sub-setting the data. If data are connected, the result vector will
be all <code class="reqn">1</code>s. The connectedness between two points can be defined
either by a threshold <code>toolong</code> or using input dissimilarities
with <code>NA</code>s.
</p>
<p>Function <code>no.shared</code> returns a <code>dist</code> structure having value
<code>TRUE</code> when two sites have nothing in common, and value
<code>FALSE</code> when they have at least one shared species. This is a
minimal structure that can be analysed with <code>distconnected</code>. The
function can be used to select dissimilarities with no shared species
in indices which do not have a fixed upper limit.
</p>
<p>Function <code>distconnected</code> uses depth-first search
(Sedgewick 1990). 
</p>


<h3>Value</h3>

<p>Function <code>distconnected</code> returns a vector for
observations using integers to identify connected groups. If the data
are connected, values will be all <code>1</code>. Function <code>no.shared</code>
returns an object of class <code><a href="stats.html#topic+dist">dist</a></code>.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Sedgewick, R. (1990). <em>Algorithms in C</em>. Addison Wesley. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vegdist">vegdist</a></code> or <code><a href="stats.html#topic+dist">dist</a></code> for getting
dissimilarities, <code><a href="#topic+stepacross">stepacross</a></code> for a case where you may need
<code>distconnected</code>, and for connecting points <code><a href="#topic+spantree">spantree</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## There are no disconnected data in vegan, and the following uses an
## extremely low threshold limit for connectedness. This is for
## illustration only, and not a recommended practice.
data(dune)
dis &lt;- vegdist(dune)
gr &lt;- distconnected(dis, toolong=0.4)
# Make sites with no shared species as NA in Manhattan dissimilarities
dis &lt;- vegdist(dune, "manhattan")
is.na(dis) &lt;- no.shared(dune)
</code></pre>

<hr>
<h2 id='diversity'>Ecological Diversity Indices</h2><span id='topic+diversity'></span><span id='topic+simpson.unb'></span><span id='topic+fisher.alpha'></span><span id='topic+specnumber'></span>

<h3>Description</h3>

<p> Shannon, Simpson, and Fisher diversity indices and species
richness.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>diversity(x, index = "shannon", groups, equalize.groups = FALSE,
   MARGIN = 1, base = exp(1))
simpson.unb(x, inverse = FALSE)
fisher.alpha(x, MARGIN = 1, ...)
specnumber(x, groups, MARGIN = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diversity_+3A_x">x</code></td>
<td>
<p>Community data, a matrix-like object or a vector.</p>
</td></tr>
<tr><td><code id="diversity_+3A_index">index</code></td>
<td>
<p>Diversity index, one of <code>"shannon"</code>,
<code>"simpson"</code> or <code>"invsimpson"</code>.</p>
</td></tr>
<tr><td><code id="diversity_+3A_margin">MARGIN</code></td>
<td>
<p>Margin for which the index is computed. </p>
</td></tr>
<tr><td><code id="diversity_+3A_base">base</code></td>
<td>
<p> The logarithm <code>base</code> used in <code>shannon</code>.</p>
</td></tr>
<tr><td><code id="diversity_+3A_inverse">inverse</code></td>
<td>
<p>Use inverse Simpson similarly as in
<code>diversity(x, "invsimpson")</code>.</p>
</td></tr>
<tr><td><code id="diversity_+3A_groups">groups</code></td>
<td>
<p>A grouping factor: if given, finds the diversity of
communities pooled by the groups.</p>
</td></tr>
<tr><td><code id="diversity_+3A_equalize.groups">equalize.groups</code></td>
<td>
<p>Instead of observed abundances, standardize all
communities to unit total.</p>
</td></tr>
<tr><td><code id="diversity_+3A_...">...</code></td>
<td>
<p>Parameters passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shannon or Shannon&ndash;Weaver (or Shannon&ndash;Wiener) index is defined as
<code class="reqn">H' = -\sum_i p_i \log_{b} p_i</code>, where
<code class="reqn">p_i</code> is the proportional abundance of species <code class="reqn">i</code> and <code class="reqn">b</code>
is the base of the logarithm.  It is most popular to use natural
logarithms, but some argue for base <code class="reqn">b = 2</code> (which makes sense,
but no real difference).
</p>
<p>Both variants of Simpson's index are based on <code class="reqn">D = \sum p_i^2</code>. Choice <code>simpson</code> returns <code class="reqn">1-D</code> and
<code>invsimpson</code> returns <code class="reqn">1/D</code>.
</p>
<p><code>simpson.unb</code> finds unbiased Simpson indices for discrete
samples (Hurlbert 1971, eq. 5). These are less sensitive to sample
size than the basic Simpson indices. The unbiased indices can be only
calculated for data of integer counts.
</p>
<p>The <code>diversity</code> function can find the total (or gamma) diversity
of pooled communities with argument <code>groups</code>. The average alpha
diversity can be found as the mean of diversities by the same groups,
and their difference or ratio is an estimate of beta diversity (see
Examples). The pooling can be based either on the observed
abundancies, or all communities can be equalized to unit total before
pooling; see Jost (2007) for discussion. Functions
<code><a href="#topic+adipart">adipart</a></code> and <code><a href="#topic+multipart">multipart</a></code> provide canned
alternatives for estimating alpha, beta and gamma diversities in
hierarchical settings.
</p>
<p><code>fisher.alpha</code> estimates the <code class="reqn">\alpha</code> parameter of
Fisher's logarithmic series (see <code><a href="#topic+fisherfit">fisherfit</a></code>). 
The estimation is possible only for genuine
counts of individuals.
</p>
<p>None of these diversity indices is usable for empty sampling units
without any species, but some of the indices can give a numeric
value. Filtering out these cases is left for the user.
</p>
<p>Function <code>specnumber</code> finds the number of species. With
<code>MARGIN = 2</code>, it finds frequencies of species. If <code>groups</code>
is given, finds the total number of species in each group (see 
example on finding one kind of beta diversity with this option).
</p>
<p>Better stories can be told about Simpson's index than about
Shannon's index, and still grander narratives about
rarefaction (Hurlbert 1971).  However, these indices are all very
closely related (Hill 1973), and there is no reason to despise one
more than others (but if you are a graduate student, don't drag me in,
but obey your Professor's orders). In particular, the exponent of the
Shannon index is linearly related to inverse Simpson (Hill 1973)
although the former may be more sensitive to rare species. Moreover,
inverse Simpson is asymptotically equal to rarefied species richness
in sample of two individuals, and Fisher's <code class="reqn">\alpha</code> is very
similar to inverse Simpson.
</p>


<h3>Value</h3>

<p>A vector of diversity indices or numbers of species. 
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen  and  Bob O'Hara (<code>fisher.alpha</code>).</p>


<h3>References</h3>

<p>Fisher, R.A., Corbet, A.S. &amp; Williams, C.B. (1943). The relation
between the number of species and the number of individuals in a
random sample of animal population. <em>Journal of Animal Ecology</em>
<strong>12</strong>, 42&ndash;58.
</p>
<p>Hurlbert, S.H. (1971). The nonconcept of species diversity: a critique
and alternative parameters. <em>Ecology</em> <strong>52</strong>, 577&ndash;586.
</p>
<p>Jost, L. (2007) Partitioning diversity into independent alpha and beta
components. <em>Ecology</em> <strong>88</strong>, 2427&ndash;2439.
</p>


<h3>See Also</h3>

<p>These functions calculate only some basic indices, but many
others can be derived with them (see Examples). Facilities related to
diversity are discussed in a <span class="pkg">vegan</span> vignette that can be read
with <code>browseVignettes("vegan")</code>.  Functions <code><a href="#topic+renyi">renyi</a></code>
and <code><a href="#topic+tsallis">tsallis</a></code> estimate a series of generalized diversity
indices. Function <code><a href="#topic+rarefy">rarefy</a></code> finds estimated number of
species for given sample size. Beta diversity can be estimated with
<code><a href="#topic+betadiver">betadiver</a></code>. Diversities can be partitioned with
<code><a href="#topic+adipart">adipart</a></code> and <code><a href="#topic+multipart">multipart</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI, BCI.env)
H &lt;- diversity(BCI)
simp &lt;- diversity(BCI, "simpson")
invsimp &lt;- diversity(BCI, "inv")
## Unbiased Simpson
unbias.simp &lt;- simpson.unb(BCI)
## Fisher alpha
alpha &lt;- fisher.alpha(BCI)
## Plot all
pairs(cbind(H, simp, invsimp, unbias.simp, alpha), pch="+", col="blue")
## Species richness (S) and Pielou's evenness (J):
S &lt;- specnumber(BCI) ## rowSums(BCI &gt; 0) does the same...
J &lt;- H/log(S)
## beta diversity defined as gamma/alpha - 1:
## alpha is the average no. of species in a group, and gamma is the
## total number of species in the group
(alpha &lt;- with(BCI.env, tapply(specnumber(BCI), Habitat, mean)))
(gamma &lt;- with(BCI.env, specnumber(BCI, Habitat)))
gamma/alpha - 1
## similar calculations with Shannon diversity
(alpha &lt;- with(BCI.env, tapply(diversity(BCI), Habitat, mean))) # average
(gamma &lt;- with(BCI.env, diversity(BCI, groups=Habitat))) # pooled
## additive beta diversity based on Shannon index
gamma-alpha
</code></pre>

<hr>
<h2 id='dune'>Vegetation and Environment in Dutch Dune Meadows. </h2><span id='topic+dune'></span><span id='topic+dune.env'></span>

<h3>Description</h3>

<p>The dune meadow vegetation data, <code>dune</code>, has cover class values
of 30 species on 20 sites. The corresponding environmental data frame
<code>dune.env</code> has following entries: </p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(dune)
  data(dune.env)
</code></pre>


<h3>Format</h3>

<p><code>dune</code> is a data frame of observations of 30 species at 20
sites. The species names are abbreviated to 4+4 letters (see
<code><a href="#topic+make.cepnames">make.cepnames</a></code>). The following names are changed from
the original source (Jongman et al. 1987): <em>Leontodon
autumnalis</em> to <em>Scorzoneroides</em>, and <em>Potentilla
palustris</em> to <em>Comarum</em>.
</p>
<p><code>dune.env</code> is a data frame of 20 observations on the following
5 variables:
</p>

<dl>
<dt>A1:</dt><dd><p>a numeric vector of thickness of soil A1 horizon.</p>
</dd>
<dt>Moisture:</dt><dd><p>an ordered factor with levels: <code>1</code> &lt; <code>2</code> &lt;
<code>4</code> &lt; <code>5</code>.</p>
</dd>

<dt>Management:</dt><dd><p>a factor with levels: <code>BF</code> (Biological
farming), <code>HF</code> (Hobby farming), <code>NM</code> (Nature
Conservation Management), and <code>SF</code> (Standard Farming).</p>
</dd>




<dt>Use:</dt><dd><p>an ordered factor of land-use with levels: <code>Hayfield</code>
&lt; <code>Haypastu</code> &lt; <code>Pasture</code>.</p>
</dd>

<dt>Manure:</dt><dd><p>an ordered factor with levels: <code>0</code> &lt; <code>1</code> &lt;
<code>2</code> &lt; <code>3</code> &lt; <code>4</code>.</p>
</dd> 

</dl>



<h3>Source</h3>

<p>Jongman, R.H.G, ter Braak, C.J.F &amp; van Tongeren,
O.F.R. (1987). <em>Data Analysis in Community and Landscape
Ecology</em>. Pudoc, Wageningen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
</code></pre>

<hr>
<h2 id='dune.taxon'>Taxonomic Classification and Phylogeny of Dune Meadow Species</h2><span id='topic+dune.taxon'></span><span id='topic+dune.phylodis'></span>

<h3>Description</h3>

<p>Classification table of the species in the <code><a href="#topic+dune">dune</a></code> data
set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(dune.taxon)
  data(dune.phylodis)
</code></pre>


<h3>Format</h3>

<p><code>dune.taxon</code> is data frame with 30 species (rows) classified into
five taxonomic levels (columns). <code>dune.phylodis</code> is a
<code><a href="stats.html#topic+dist">dist</a></code> object of estimated coalescence ages extracted from
<a href="https://doi.org/10.5061/dryad.63q27">doi:10.5061/dryad.63q27</a> (Zanne et al. 2014) using tools in packages
<span class="pkg">ape</span> and <span class="pkg">phylobase</span>.
</p>


<h3>Details</h3>

<p>The families and orders are based on APG IV (2016) in vascular
plants and on Hill et al. (2006) in mosses. The higher levels
(superorder and subclass) are based on Chase &amp; Reveal (2009). Chase
&amp; Reveal (2009) treat Angiosperms and mosses as subclasses of class
Equisetopsida (land plants), but brylogists have traditionally used
much more inflated levels which are adjusted here to match
Angiosperm classification.
</p>


<h3>References</h3>

<p>APG IV [Angiosperm Phylogeny Group] (2016) An update of the
Angiosperm Phylogeny Group classification for the orders and
families of flowering plants: APG IV. <em>Bot. J. Linnean Soc.</em>
<strong>181</strong>: 1&ndash;20.
</p>
<p>Chase, M.W. &amp; Reveal, J. L. (2009) A phylogenetic classification of
the land plants to accompany APG III. <em>Bot. J. Linnean Soc.</em>
<strong>161</strong>: 122&ndash;127.
</p>
<p>Hill, M.O et al. (2006) An annotated checklist of the mosses of Europe
and Macaronesia. <em>J. Bryology</em> <strong>28</strong>: 198&ndash;267.
</p>
<p>Zanne A.E., Tank D.C., Cornwell, W.K., Eastman J.M., Smith, S.A.,
FitzJohn, R.G., McGlinn, D.J., O‚ÄôMeara, B.C., Moles, A.T., Reich,
P.B., Royer, D.L., Soltis, D.E., Stevens, P.F., Westoby, M., Wright,
I.J., Aarssen, L., Bertin, R.I., Calaminus, A., Govaerts, R.,
Hemmings, F., Leishman, M.R., Oleksyn, J., Soltis, P.S., Swenson,
N.G., Warman, L. &amp; Beaulieu, J.M. (2014) Three keys to the radiation
of angiosperms into freezing environments. <em>Nature</em>
<strong>506</strong>: 89&ndash;92.
</p>


<h3>See Also</h3>

<p>Functions <code><a href="#topic+taxondive">taxondive</a></code>, <code><a href="#topic+treedive">treedive</a></code>,
and <code><a href="#topic+treedist">treedist</a></code> use these data sets. </p>


<h3>Examples</h3>

<pre><code class='language-R'> 
  data(dune.taxon) 
  data(dune.phylodis)
</code></pre>

<hr>
<h2 id='eigenvals'>
Extract Eigenvalues from an Ordination Object
</h2><span id='topic+eigenvals'></span><span id='topic+eigenvals.default'></span><span id='topic+eigenvals.prcomp'></span><span id='topic+eigenvals.princomp'></span><span id='topic+eigenvals.cca'></span><span id='topic+eigenvals.wcmdscale'></span><span id='topic+eigenvals.pcnm'></span><span id='topic+eigenvals.dudi'></span><span id='topic+eigenvals.pca'></span><span id='topic+eigenvals.pco'></span><span id='topic+eigenvals.decorana'></span><span id='topic+summary.eigenvals'></span>

<h3>Description</h3>

<p>Function extracts eigenvalues from an object that has them. Many
multivariate methods return such objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigenvals(x, ...)
## S3 method for class 'cca'
eigenvals(x, model = c("all", "unconstrained", "constrained"),
          constrained = NULL, ...)
## S3 method for class 'decorana'
eigenvals(x, kind = c("additive", "axiswise", "decorana"),
           ...)
## S3 method for class 'eigenvals'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eigenvals_+3A_x">x</code></td>
<td>

<p>An object from which to extract eigenvalues.
</p>
</td></tr>
<tr><td><code id="eigenvals_+3A_object">object</code></td>
<td>

<p>An <code>eigenvals</code> result object.
</p>
</td></tr>
<tr><td><code id="eigenvals_+3A_model">model</code></td>
<td>

<p>Which eigenvalues to return for objects that inherit from class
<code>"cca"</code> only.
</p>
</td></tr>
<tr><td><code id="eigenvals_+3A_constrained">constrained</code></td>
<td>

<p>Return only constrained eigenvalues. Deprecated as of vegan
2.5-0. Use <code>model</code> instead.
</p>
</td></tr>
<tr><td><code id="eigenvals_+3A_kind">kind</code></td>
<td>

<p>Kind of eigenvalues returned for <code><a href="#topic+decorana">decorana</a></code>. Only
<code>"additive"</code> eigenvalues can be used for reporting importances
of components in <code>summary</code>. <code>"axiswise"</code> gives the
non-additive eigenvalues, and <code>"decorana"</code> the decorana values
(see <code><a href="#topic+decorana">decorana</a></code> for details).
</p>
</td></tr>
<tr><td><code id="eigenvals_+3A_...">...</code></td>
<td>

<p>Other arguments to the functions (usually ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a generic function that has methods for <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+wcmdscale">wcmdscale</a></code>, <code><a href="#topic+pcnm">pcnm</a></code>, <code><a href="stats.html#topic+prcomp">prcomp</a></code>,
<code><a href="stats.html#topic+princomp">princomp</a></code>, <code>dudi</code> (of <span class="pkg">ade4</span>), and 
<code>pca</code> and <code>pco</code> (of 
<span class="pkg">labdsv</span>) result objects. The default method also
extracts eigenvalues if the result looks like being from
<code><a href="base.html#topic+eigen">eigen</a></code> or <code><a href="base.html#topic+svd">svd</a></code>.  Functions
<code><a href="stats.html#topic+prcomp">prcomp</a></code> and <code><a href="stats.html#topic+princomp">princomp</a></code> contain square roots
of eigenvalues that all called standard deviations, but
<code>eigenvals</code> function returns their squares.  Function
<code><a href="base.html#topic+svd">svd</a></code> contains singular values, but function
<code>eigenvals</code> returns their squares. For constrained ordination
methods <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code> and
<code><a href="#topic+capscale">capscale</a></code> the function returns the both constrained and
unconstrained eigenvalues concatenated in one vector, but the partial
component will be ignored. However, with argument 
<code>constrained = TRUE</code> only constrained eigenvalues are returned. 
</p>
<p>The <code>summary</code> of <code>eigenvals</code> result returns eigenvalues,
proportion explained and cumulative proportion explained. The result
object can have some negative eigenvalues (<code><a href="#topic+wcmdscale">wcmdscale</a></code>,
<code><a href="#topic+capscale">capscale</a></code>, <code><a href="#topic+pcnm">pcnm</a></code>) which correspond to
imaginary axes of Euclidean mapping of non-Euclidean distances
(Gower 1985). In these cases, the sum of absolute values of
eigenvalues is used in calculating the proportions explained, and
real axes (corresponding to positive eigenvalues) will only explain
a part of total variation (Mardia et al. 1979, Gower 1985). For
<code><a href="#topic+decorana">decorana</a></code> the importances and cumulative proportions are
only reported for <code>kind = "additive"</code>, because other alternatives
do not add up to total inertia of the input data.
</p>


<h3>Value</h3>

<p>An object of class <code>"eigenvals"</code>, which is a vector of
eigenvalues.
</p>
<p>The <code>summary</code> method returns an object of class
<code>"summary.eigenvals"</code>, which is a matrix.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen.
</p>


<h3>References</h3>

<p>Gower, J. C. (1985). Properties of Euclidean and non-Euclidean
distance matrices. <em>Linear Algebra and its Applications</em> 67,
81&ndash;97.
</p>
<p>Mardia, K. V., Kent, J. T. and Bibby, J. M. (1979).  Chapter 14 of
<em>Multivariate Analysis</em>, London: Academic Press.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+eigen">eigen</a></code>, <code><a href="base.html#topic+svd">svd</a></code>, <code><a href="stats.html#topic+prcomp">prcomp</a></code>,
<code><a href="stats.html#topic+princomp">princomp</a></code>, <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>,
<code><a href="#topic+capscale">capscale</a></code>, <code><a href="#topic+wcmdscale">wcmdscale</a></code>,
<code><a href="#topic+cca.object">cca.object</a></code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
mod &lt;- cca(varespec ~ Al + P + K, varechem)
ev &lt;- eigenvals(mod)
ev
summary(ev)

## choose which eignevalues to return
eigenvals(mod, model = "unconstrained")
</code></pre>

<hr>
<h2 id='envfit'>Fits an Environmental Vector or Factor onto an Ordination </h2><span id='topic+envfit'></span><span id='topic+envfit.default'></span><span id='topic+envfit.formula'></span><span id='topic+vectorfit'></span><span id='topic+factorfit'></span><span id='topic+plot.envfit'></span><span id='topic+scores.envfit'></span><span id='topic+labels.envfit'></span>

<h3>Description</h3>

<p>The function fits environmental vectors or factors onto an
ordination. The projections of points onto vectors have maximum
correlation with corresponding environmental variables, and the
factors show the averages of factor levels. For continuous varaibles
this is equal to fitting a linear trend surface (plane in 2D) for a
variable (see <code><a href="#topic+ordisurf">ordisurf</a></code>); this trend surface can be
presented by showing its gradient (direction of steepest increase)
using an arrow. The environmental variables are the dependent
variables that are explained by the ordination scores, and each
dependent variable is analysed separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
envfit(ord, env, permutations = 999, strata = NULL, 
   choices=c(1,2),  display = "sites", w  = weights(ord, display),
   na.rm = FALSE, ...)
## S3 method for class 'formula'
envfit(formula, data, ...)
## S3 method for class 'envfit'
plot(x, choices = c(1,2), labels, arrow.mul, at = c(0,0), 
   axis = FALSE, p.max = NULL, col = "blue", bg, add = TRUE, ...)
## S3 method for class 'envfit'
scores(x, display, choices, arrow.mul=1, tidy = FALSE, ...)
vectorfit(X, P, permutations = 0, strata = NULL, w, ...)
factorfit(X, P, permutations = 0, strata = NULL, w, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="envfit_+3A_ord">ord</code></td>
<td>
<p>An ordination object or other structure from which the
ordination <code><a href="#topic+scores">scores</a></code> can be extracted (including a data
frame or matrix of scores).</p>
</td></tr>
<tr><td><code id="envfit_+3A_env">env</code></td>
<td>
<p>Data frame, matrix or vector of environmental
variables. The variables can be of mixed type (factors, continuous
variables) in data frames.</p>
</td></tr>
<tr><td><code id="envfit_+3A_x">X</code></td>
<td>
<p>Matrix or data frame of ordination scores.</p>
</td></tr>
<tr><td><code id="envfit_+3A_p">P</code></td>
<td>
<p>Data frame, matrix or vector of environmental
variable(s). These must be continuous for <code>vectorfit</code> and
factors or characters for <code>factorfit</code>. </p>
</td></tr>
<tr><td><code id="envfit_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices. Set <code>permutations = 0</code> to skip
permutations.</p>
</td></tr>
<tr><td><code id="envfit_+3A_formula">formula</code>, <code id="envfit_+3A_data">data</code></td>
<td>
<p>Model  <code><a href="stats.html#topic+formula">formula</a></code> and data.  </p>
</td></tr>
<tr><td><code id="envfit_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove points with missing values in ordination scores
or environmental variables. The operation is casewise: the whole
row of data is removed if there is a missing value and 
<code>na.rm = TRUE</code>.</p>
</td></tr>
<tr><td><code id="envfit_+3A_x">x</code></td>
<td>
<p>A result object from <code>envfit</code>. For <code>ordiArrowMul</code>
and <code>ordiArrowTextXY</code> this must be a two-column matrix (or
matrix-like object) containing the coordinates of arrow heads on
the two plot axes, and other methods extract such a structure from
the <code>envfit</code> results.</p>
</td></tr>
<tr><td><code id="envfit_+3A_choices">choices</code></td>
<td>
<p>Axes to plotted.</p>
</td></tr>
<tr><td><code id="envfit_+3A_tidy">tidy</code></td>
<td>
<p>Return scores that are compatible with <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>:
all scores are in a single <code>data.frame</code>, score type is
identified by factor variable <code>scores</code> (<code>"vectors"</code> or
<code>"factors"</code>), the names by variable <code>label</code>. These scores
are incompatible with conventional <code>plot</code> functions, but they can
be used in <span class="pkg">ggplot2</span>.</p>
</td></tr>
<tr><td><code id="envfit_+3A_labels">labels</code></td>
<td>
<p>Change plotting labels. The argument should be a list
with elements <code>vectors</code> and <code>factors</code> which give the new
plotting labels. If either of these elements is omitted, the
default labels will be used. If there is only one type of elements
(only <code>vectors</code> or only <code>factors</code>), the labels can be
given as vector. The default labels can be displayed with
<code>labels</code> command.</p>
</td></tr>
<tr><td><code id="envfit_+3A_arrow.mul">arrow.mul</code></td>
<td>
<p>Multiplier for vector lengths. The arrows are
automatically scaled similarly as in <code><a href="#topic+plot.cca">plot.cca</a></code> if this
is not given in <code>plot</code> and <code>add = TRUE</code>. However, in
<code>scores</code> it can be used to adjust arrow lengths when the
<code>plot</code> function is not used.</p>
</td></tr>
<tr><td><code id="envfit_+3A_at">at</code></td>
<td>
<p>The origin of fitted arrows in the plot.  If you plot arrows
in other places then origin, you probably have to specify
<code>arrrow.mul</code>.</p>
</td></tr>
<tr><td><code id="envfit_+3A_axis">axis</code></td>
<td>
<p>Plot axis showing the scaling of fitted arrows.</p>
</td></tr>
<tr><td><code id="envfit_+3A_p.max">p.max</code></td>
<td>
<p>Maximum estimated <code class="reqn">P</code> value for displayed
variables.  You must calculate <code class="reqn">P</code> values with setting
<code>permutations</code> to use this option. </p>
</td></tr>
<tr><td><code id="envfit_+3A_col">col</code></td>
<td>
<p>Colour in plotting.</p>
</td></tr>
<tr><td><code id="envfit_+3A_bg">bg</code></td>
<td>
<p>Background colour for labels. If <code>bg</code> is set, the
labels are displayed with <code><a href="#topic+ordilabel">ordilabel</a></code> instead of
<code>text</code>. See Examples for using semitransparent background.</p>
</td></tr>
<tr><td><code id="envfit_+3A_add">add</code></td>
<td>
<p>Results added to an existing ordination plot.</p>
</td></tr>
<tr><td><code id="envfit_+3A_strata">strata</code></td>
<td>
<p>An integer vector or factor specifying the strata for
permutation. If supplied, observations are permuted only within the
specified strata.</p>
</td></tr>
<tr><td><code id="envfit_+3A_display">display</code></td>
<td>
<p>In fitting functions these are ordinary site scores or
linear combination scores 
(<code>"lc"</code>) in constrained ordination (<code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+capscale">capscale</a></code>). In <code>scores</code>
function they are either <code>"vectors"</code> or <code>"factors"</code>
(with synonyms <code>"bp"</code> or <code>"cn"</code>, resp.).</p>
</td></tr>
<tr><td><code id="envfit_+3A_w">w</code></td>
<td>
<p>Weights used in fitting (concerns mainly <code><a href="#topic+cca">cca</a></code>
and <code><a href="#topic+decorana">decorana</a></code> results which have nonconstant weights).</p>
</td></tr>
<tr><td><code id="envfit_+3A_...">...</code></td>
<td>
<p>Parameters passed to <code><a href="#topic+scores">scores</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>envfit</code> finds vectors or factor averages of
environmental variables.  Function <code>plot.envfit</code> adds these in an
ordination diagram.  If <code>X</code> is a <code><a href="base.html#topic+data.frame">data.frame</a></code>,
<code>envfit</code>
uses <code>factorfit</code> for <code><a href="base.html#topic+factor">factor</a></code> variables and
<code>vectorfit</code> for other variables.  If <code>X</code> is a matrix or a
vector, <code>envfit</code> uses only <code>vectorfit</code>. Alternatively, the
model can be defined a simplified model <code><a href="stats.html#topic+formula">formula</a></code>, where
the left hand side must be an ordination result object or a matrix of
ordination scores, and right hand
side lists the environmental variables. The formula interface can be
used for easier selection and/or transformation of environmental
variables. Only the main effects will be analysed even if interaction
terms were defined in the formula.
</p>
<p>The ordination results are extracted with <code><a href="#topic+scores">scores</a></code> and
all extra arguments are passed to the <code>scores</code>. The fitted
models only apply to the results defined when extracting the scores
when using <code>envfit</code>. For instance, <code>scaling</code> in
constrained ordination (see <code><a href="#topic+scores.rda">scores.rda</a></code>,
<code><a href="#topic+scores.cca">scores.cca</a></code>) must be set in the same way in
<code>envfit</code> and in the <code>plot</code> or the ordination results (see
Examples).
</p>
<p>The printed output of continuous variables (vectors) gives the
direction cosines which are the coordinates of the heads of unit
length vectors.  In <code>plot</code> these are scaled by their
correlation (square root of the column <code>r2</code>) so that
&ldquo;weak&rdquo; predictors have shorter arrows than &ldquo;strong&rdquo;
predictors.  You can see the scaled relative lengths using command
<code>scores</code>.  The <code>plot</code>ted (and scaled) arrows are further
adjusted to the current graph using a constant multiplier: this will
keep the relative <code>r2</code>-scaled lengths of the arrows but tries
to fill the current plot.  You can see the multiplier using
<code>ordiArrowMul(result_of_envfit)</code>, and set it with the
argument <code>arrow.mul</code>.
</p>
<p>Functions <code>vectorfit</code> and <code>factorfit</code> can be called directly.
Function <code>vectorfit</code> finds directions in the ordination space
towards which the environmental vectors change most rapidly and to
which they have maximal correlations with the ordination
configuration.  Function <code>factorfit</code> finds averages of ordination
scores for factor levels. Function <code>factorfit</code> treats ordered
and unordered factors similarly.
</p>
<p>If <code>permutations</code> <code class="reqn">&gt; 0</code>, the significance of fitted vectors
or factors is assessed using permutation of environmental variables.
The goodness of fit statistic is squared correlation coefficient
(<code class="reqn">r^2</code>).
For factors this is defined as <code class="reqn">r^2 = 1 - ss_w/ss_t</code>, where
<code class="reqn">ss_w</code> and <code class="reqn">ss_t</code> are within-group and total sums of
squares. See <code><a href="#topic+permutations">permutations</a></code> for additional details on
permutation tests in Vegan.
</p>
<p>User can supply a vector of prior weights <code>w</code>. If the ordination
object has weights, these will be used. In practise this means that
the row totals are used as weights with <code><a href="#topic+cca">cca</a></code> or
<code><a href="#topic+decorana">decorana</a></code> results. If you do not like this, but want to
give equal weights to all sites, you should set <code>w = NULL</code>.  The
fitted vectors are similar to biplot arrows in constrained ordination
only when fitted to LC scores (<code>display = "lc"</code>) and you set
<code>scaling = "species"</code> (see <code><a href="#topic+scores.cca">scores.cca</a></code>).  The
weighted fitting gives similar results to biplot arrows and class
centroids in <code><a href="#topic+cca">cca</a></code>.
</p>
<p>The lengths of arrows for fitted vectors are automatically adjusted
for the physical size of the plot, and the arrow lengths cannot be
compared across plots. For similar scaling of arrows, you must
explicitly set the <code>arrow.mul</code> argument in the <code>plot</code>
command; see <code><a href="#topic+ordiArrowMul">ordiArrowMul</a></code> and
<code><a href="#topic+ordiArrowTextXY">ordiArrowTextXY</a></code>.
</p>
<p>The results can be accessed with <code>scores.envfit</code> function which
returns either the fitted vectors scaled by correlation coefficient or
the centroids of the fitted environmental variables, or a named list
of both.
</p>


<h3>Value</h3>

<p>Functions <code>vectorfit</code> and <code>factorfit</code> return lists of
classes <code>vectorfit</code> and <code>factorfit</code> which have a
<code>print</code> method.  The result object have the following items:
</p>
<table>
<tr><td><code>arrows</code></td>
<td>
<p>Arrow endpoints from <code>vectorfit</code>. The arrows are
scaled to unit length.</p>
</td></tr>
<tr><td><code>centroids</code></td>
<td>
<p>Class centroids from <code>factorfit</code>.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Goodness of fit statistic: Squared correlation coefficient</p>
</td></tr>
<tr><td><code>permutations</code></td>
<td>
<p>Number of permutations.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>A list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
<tr><td><code>pvals</code></td>
<td>
<p>Empirical P-values for each variable.</p>
</td></tr>
</table>
<p>Function <code>envfit</code> returns a list of class <code>envfit</code> with
results of <code>vectorfit</code> and <code>envfit</code> as items.
</p>
<p>Function <code>plot.envfit</code> scales the vectors by correlation.
</p>


<h3>Note</h3>

<p>Fitted vectors have become the method of choice in displaying
environmental variables in ordination.  Indeed, they are the optimal
way of presenting environmental variables in Constrained
Correspondence Analysis <code><a href="#topic+cca">cca</a></code>, since there they are the
linear constraints.
In unconstrained ordination the relation between external variables
and ordination configuration may be less linear, and therefore other
methods than arrows may be more useful.  The simplest is to adjust the
plotting symbol sizes (<code>cex</code>, <code><a href="graphics.html#topic+symbols">symbols</a></code>) by
environmental variables.
Fancier methods involve smoothing and regression methods that
abound in <span class="rlang"><b>R</b></span>, and <code><a href="#topic+ordisurf">ordisurf</a></code> provides a wrapper for some.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen.  The permutation test derives from the code
suggested by Michael Scroggie. </p>


<h3>See Also</h3>

<p>A better alternative to vectors may be <code><a href="#topic+ordisurf">ordisurf</a></code>.    
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec, varechem)
library(MASS)
ord &lt;- metaMDS(varespec)
(fit &lt;- envfit(ord, varechem, perm = 999))
scores(fit, "vectors")
plot(ord)
plot(fit)
plot(fit, p.max = 0.05, col = "red")
## Adding fitted arrows to CCA. We use "lc" scores, and hope
## that arrows are scaled similarly in cca and envfit plots
ord &lt;- cca(varespec ~ Al + P + K, varechem)
plot(ord, type="p")
fit &lt;- envfit(ord, varechem, perm = 999, display = "lc")
plot(fit, p.max = 0.05, col = "red")
## 'scaling' must be set similarly in envfit and in ordination plot
plot(ord, type = "p", scaling = "sites")
fit &lt;- envfit(ord, varechem, perm = 0, display = "lc", scaling = "sites")
plot(fit, col = "red")

## Class variables, formula interface, and displaying the
## inter-class variability with ordispider, and semitransparent
## white background for labels (semitransparent colours are not
## supported by all graphics devices)
data(dune)
data(dune.env)
ord &lt;- cca(dune)
fit &lt;- envfit(ord ~ Moisture + A1, dune.env, perm = 0)
plot(ord, type = "n")
with(dune.env, ordispider(ord, Moisture, col="skyblue"))
with(dune.env, points(ord, display = "sites", col = as.numeric(Moisture),
                      pch=16))
plot(fit, cex=1.2, axis=TRUE, bg = rgb(1, 1, 1, 0.5))
## Use shorter labels for factor centroids
labels(fit)
plot(ord)
plot(fit, labels=list(factors = paste("M", c(1,2,4,5), sep = "")),
   bg = rgb(1,1,0,0.5))
</code></pre>

<hr>
<h2 id='eventstar'>
Scale Parameter at the Minimum of the Tsallis Evenness Profile
</h2><span id='topic+eventstar'></span>

<h3>Description</h3>

<p>The function <code>eventstar</code> finds the minimum (<code class="reqn">q^*</code>) of the 
evenness profile based on the Tsallis entropy. This scale factor
of the entropy represents a specific weighting of species
relative frequencies that leads to minimum evenness of the
community (Mendes et al. 2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eventstar(x, qmax = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eventstar_+3A_x">x</code></td>
<td>

<p>A community matrix or a numeric vector.
</p>
</td></tr>
<tr><td><code id="eventstar_+3A_qmax">qmax</code></td>
<td>

<p>Maximum scale parameter of the Tsallis entropy to be used in 
finding the minimum of Tsallis based evenness
in the range <code>c(0, qmax)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>eventstar</code> finds a characteristic value of the scale 
parameter <code class="reqn">q</code> of the Tsallis entropy corresponding to
minimum of the evenness (equitability) profile based on Tsallis entropy.
This value was proposed by Mendes et al. (2008) as <code class="reqn">q^*</code>.
</p>
<p>The <code class="reqn">q^\ast</code> index represents the scale parameter of
the one parameter Tsallis diversity family that leads to
the greatest deviation from the maximum equitability given the relative 
abundance vector of a community.
</p>
<p>The value of <code class="reqn">q^\ast</code> is found by identifying the minimum
of the evenness profile over scaling factor <code class="reqn">q</code> by
one-dimensional minimization. Because evenness profile is
known to be a convex function, it is guaranteed that underlying
<code><a href="stats.html#topic+optimize">optimize</a></code> function will find a unique solution
if it is in the range <code>c(0, qmax)</code>.
</p>
<p>The scale parameter value <code class="reqn">q^\ast</code> is used to 
find corresponding values of diversity (<code class="reqn">H_{q^\ast}</code>), 
evenness (<code class="reqn">H_{q^\ast}(\max)</code>),
and numbers equivalent (<code class="reqn">D_{q^\ast}</code>). For calculation
details, see <code><a href="#topic+tsallis">tsallis</a></code> and Examples below.
</p>
<p>Mendes et al. (2008) advocated the use of <code class="reqn">q^\ast</code>
and corresponding diversity, evenness, and Hill numbers, because
it is a unique value representing the diversity profile, and is
is positively associated with rare species in the community,
thus it is a potentially useful indicator of certain
relative abundance distributions of the communities.
</p>


<h3>Value</h3>

<p>A data frame with columns:
</p>

<ul>
<li><p><code>qstar</code> scale parameter value <code class="reqn">q\ast</code>
corresponding to minimum value of Tsallis based evenness profile.
</p>
</li>
<li><p><code>Estar</code> Value of evenness based on normalized Tsallis 
entropy at <code class="reqn">q^\ast</code>.
</p>
</li>
<li><p><code>Hstar</code> Value of Tsallis entropy at <code class="reqn">q^\ast</code>.
</p>
</li>
<li><p><code>Dstar</code> Value of Tsallis entropy at <code class="reqn">q^\ast</code> 
converted to numbers equivalents
(also called as Hill numbers, effective number of species, 
&lsquo;true&rsquo; diversity; cf. Jost 2007).
</p>
</li></ul>

<p>See <code><a href="#topic+tsallis">tsallis</a></code> for calculation details.
</p>


<h3>Note</h3>

<p>Values for <code class="reqn">q^\ast</code> found by Mendes et al. (2008) ranged
from 0.56 and 1.12 presenting low variability, so an
interval between 0 and 5 should safely encompass
the possibly expected <code class="reqn">q^\ast</code> values in practice,
but profiling the evenness and changing the value of
the <code>qmax</code> argument is advised if output values
near the range limits are found.
</p>


<h3>Author(s)</h3>

<p>Eduardo Ribeiro Cunha <a href="mailto:edurcunha@gmail.com">edurcunha@gmail.com</a> and 
Heloisa Beatriz Antoniazi Evangelista <a href="mailto:helobeatriz@gmail.com">helobeatriz@gmail.com</a>, 
with technical input of P√©ter S√≥lymos.
</p>


<h3>References</h3>

<p>Mendes, R.S., Evangelista, L.R., Thomaz, S.M.,
Agostinho, A.A. and Gomes, L.C. (2008) A unified
index to measure ecological diversity and species
rarity. <em>Ecography</em> <b>31</b>, 450&ndash;456.
</p>
<p>Jost, L. (2007) Partitioning diversity into independent alpha and beta components.
<em>Ecology</em> <b>88</b>, 2427&ndash;2439.
</p>
<p>Tsallis, C. (1988) Possible generalization of Boltzmann-Gibbs statistics. 
<em>J. Stat. Phis.</em> <b>52</b>, 479&ndash;487.
</p>


<h3>See Also</h3>

<p>Tsallis entropy: <code><a href="#topic+tsallis">tsallis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
(x &lt;- eventstar(BCI[1:5,]))
## profiling
y &lt;- as.numeric(BCI[10,])
(z &lt;- eventstar(y))
q &lt;- seq(0, 2, 0.05)
Eprof &lt;- tsallis(y, scales=q, norm=TRUE)
Hprof &lt;- tsallis(y, scales=q)
Dprof &lt;- tsallis(y, scales=q, hill=TRUE)
opar &lt;- par(mfrow=c(3,1))
plot(q, Eprof, type="l", main="Evenness")
abline(v=z$qstar, h=tsallis(y, scales=z$qstar, norm=TRUE), col=2)
plot(q, Hprof, type="l", main="Diversity")
abline(v=z$qstar, h=tsallis(y, scales=z$qstar), col=2)
plot(q, Dprof, type="l", main="Effective number of species")
abline(v=z$qstar, h=tsallis(y, scales=z$qstar, hill=TRUE), col=2)
par(opar)
</code></pre>

<hr>
<h2 id='fisherfit'>Fit Fisher's Logseries and Preston's Lognormal Model to Abundance Data</h2><span id='topic+fisherfit'></span><span id='topic+as.fisher'></span><span id='topic+plot.fisherfit'></span><span id='topic+prestonfit'></span><span id='topic+prestondistr'></span><span id='topic+as.preston'></span><span id='topic+plot.prestonfit'></span><span id='topic+lines.prestonfit'></span><span id='topic+plot.preston'></span><span id='topic+lines.preston'></span><span id='topic+plot.fisher'></span><span id='topic+veiledspec'></span>

<h3>Description</h3>

<p>Function <code>fisherfit</code> fits Fisher's logseries to abundance
data. Function <code>prestonfit</code> groups species frequencies into
doubling octave classes and fits Preston's lognormal model, and
function <code>prestondistr</code> fits the truncated lognormal model
without pooling the data into octaves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisherfit(x, ...)
prestonfit(x, tiesplit = TRUE, ...)
prestondistr(x, truncate = -1, ...)
## S3 method for class 'prestonfit'
plot(x, xlab = "Frequency", ylab = "Species", bar.col = "skyblue", 
    line.col = "red", lwd = 2, ...)
## S3 method for class 'prestonfit'
lines(x, line.col = "red", lwd = 2, ...)
veiledspec(x, ...)
as.fisher(x, ...)
## S3 method for class 'fisher'
plot(x, xlab = "Frequency", ylab = "Species", bar.col = "skyblue",
             kind = c("bar", "hiplot", "points", "lines"), add = FALSE, ...)
as.preston(x, tiesplit = TRUE, ...)
## S3 method for class 'preston'
plot(x, xlab = "Frequency", ylab = "Species", bar.col = "skyblue", ...)
## S3 method for class 'preston'
lines(x, xadjust = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fisherfit_+3A_x">x</code></td>
<td>
<p>Community data vector for fitting functions or their result
object for <code>plot</code> functions.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_tiesplit">tiesplit</code></td>
<td>
<p>Split frequencies <code class="reqn">1, 2, 4, 8</code> etc between adjacent 
octaves.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_truncate">truncate</code></td>
<td>
<p>Truncation point for log-Normal model, in log2
units. Default value <code class="reqn">-1</code> corresponds to the left border of zero
Octave. The choice strongly influences the fitting results.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_xlab">xlab</code>, <code id="fisherfit_+3A_ylab">ylab</code></td>
<td>
<p>Labels for <code>x</code> and <code>y</code> axes.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_bar.col">bar.col</code></td>
<td>
<p>Colour of data bars.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_line.col">line.col</code></td>
<td>
<p>Colour of fitted line.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_lwd">lwd</code></td>
<td>
<p>Width of fitted line.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_kind">kind</code></td>
<td>
<p>Kind of plot to drawn: <code>"bar"</code> is similar bar plot
as in <code>plot.fisherfit</code>, <code>"hiplot"</code> draws vertical lines
as with <code>plot(..., type="h")</code>, and <code>"points"</code> and
<code>"lines"</code> are obvious.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_add">add</code></td>
<td>
<p>Add to an existing plot.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_xadjust">xadjust</code></td>
<td>
<p>Adjustment of horizontal positions in octaves.</p>
</td></tr>
<tr><td><code id="fisherfit_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions. Ignored in 
<code>prestonfit</code> and <code>tiesplit</code> passed to <code>as.preston</code> in
<code>prestondistr</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Fisher's logarithmic series the expected number of species
<code class="reqn">f</code> with <code class="reqn">n</code> observed individuals is <code class="reqn">f_n = \alpha x^n /
  n</code> (Fisher et al. 1943).  The estimation is possible only for
genuine counts of individuals. The parameter <code class="reqn">\alpha</code> is used as
a diversity index which can be estimated with a separate function
<code><a href="#topic+fisher.alpha">fisher.alpha</a></code>. The parameter <code class="reqn">x</code> is taken as a
nuisance parameter which is not estimated separately but taken to be
<code class="reqn">n/(n+\alpha)</code>. Helper function <code>as.fisher</code> transforms
abundance data into Fisher frequency table. Diversity will be given
as <code>NA</code> for communities with one (or zero) species: there is no
reliable way of estimating their diversity, even if the equations
will return a bogus numeric value in some cases.
</p>
<p>Preston (1948) was not satisfied with Fisher's model which seemed to
imply infinite species richness, and postulated that rare species is
a diminishing class and most species are in the middle of frequency
scale. This was achieved by collapsing higher frequency classes into
wider and wider &ldquo;octaves&rdquo; of doubling class limits: 1, 2, 3&ndash;4,
5&ndash;8, 9&ndash;16 etc. occurrences. It seems that Preston regarded
frequencies 1, 2, 4, <em>etc.</em>. as &ldquo;tied&rdquo; between octaves
(Williamson &amp; Gaston 2005). This means that only half of the species
with frequency 1 are shown in the lowest octave, and the rest are
transferred to the second octave. Half of the species from the
second octave are transferred to the higher one as well, but this is
usually not as large a number of species. This practise makes data
look more lognormal by reducing the usually high lowest
octaves. This can be achieved by setting argument <code>tiesplit = TRUE</code>. 
With <code>tiesplit = FALSE</code> the frequencies are not split,
but all ones are in the lowest octave, all twos in the second, etc.
Williamson &amp; Gaston (2005) discuss alternative definitions in
detail, and they should be consulted for a critical review of
log-Normal model.
</p>
<p>Any logseries data will look like lognormal when plotted in
Preston's way. The expected frequency <code class="reqn">f</code> at abundance octave
<code class="reqn">o</code> is defined by <code class="reqn">f_o = S_0 \exp(-(\log_2(o) -
  \mu)^2/2/\sigma^2)</code>, where
<code class="reqn">\mu</code> is the location of the mode and <code class="reqn">\sigma</code> the width,
both in <code class="reqn">\log_2</code> scale, and <code class="reqn">S_0</code> is the expected
number of species at mode. The lognormal model is usually truncated
on the left so that some rare species are not observed. Function
<code>prestonfit</code> fits the truncated lognormal model as a second
degree log-polynomial to the octave pooled data using Poisson (when
<code>tiesplit = FALSE</code>) or quasi-Poisson (when <code>tiesplit = TRUE</code>)
error.  Function <code>prestondistr</code> fits left-truncated
Normal distribution to <code class="reqn">\log_2</code> transformed non-pooled
observations with direct maximization of log-likelihood. Function
<code>prestondistr</code> is modelled after function
<code><a href="MASS.html#topic+fitdistr">fitdistr</a></code> which can be used for alternative
distribution models. 
</p>
<p>The functions have common <code>print</code>, <code>plot</code> and <code>lines</code>
methods. The <code>lines</code> function adds the fitted curve to the
octave range with line segments showing the location of the mode and
the width (sd) of the response. Function <code>as.preston</code>
transforms abundance data to octaves.  Argument <code>tiesplit</code> will
not influence the fit in <code>prestondistr</code>, but it will influence
the barplot of the octaves. 
</p>
<p>The total extrapolated richness from a fitted Preston model can be
found with function <code>veiledspec</code>. The function accepts results
both from <code>prestonfit</code> and from <code>prestondistr</code>. If
<code>veiledspec</code> is called with a species count vector, it will
internally use <code>prestonfit</code>. Function <code><a href="#topic+specpool">specpool</a></code>
provides alternative ways of estimating the number of unseen
species. In fact, Preston's lognormal model seems to be truncated at
both ends, and this may be the main reason why its result differ
from lognormal models fitted in Rank&ndash;Abundance diagrams with
functions <code><a href="#topic+rad.lognormal">rad.lognormal</a></code>.  
</p>


<h3>Value</h3>

<p> The function <code>prestonfit</code> returns an object with fitted
<code>coefficients</code>, and with observed (<code>freq</code>) and fitted
(<code>fitted</code>) frequencies, and a string describing the fitting
<code>method</code>. Function <code>prestondistr</code> omits the entry
<code>fitted</code>.  The function <code>fisherfit</code> returns the result of
<code><a href="stats.html#topic+nlm">nlm</a></code>, where item <code>estimate</code> is <code class="reqn">\alpha</code>. The
result object is amended with the <code>nuisance</code> parameter and item
<code>fisher</code> for the observed data from <code>as.fisher</code>
</p>


<h3>Author(s)</h3>

<p>Bob O'Hara and Jari Oksanen. </p>


<h3>References</h3>

<p>Fisher, R.A., Corbet, A.S. &amp; Williams, C.B. (1943). The relation
between the number of species and the number of individuals in a
random sample of animal population. <em>Journal of Animal Ecology</em>
12: 42&ndash;58.
</p>
<p>Preston, F.W. (1948) The commonness and rarity of
species. <em>Ecology</em> 29, 254&ndash;283.
</p>
<p>Williamson, M. &amp; Gaston, K.J. (2005). The lognormal distribution is
not an appropriate null hypothesis for the species&ndash;abundance
distribution. <em>Journal of Animal Ecology</em> 74, 409&ndash;422.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diversity">diversity</a></code>, <code><a href="#topic+fisher.alpha">fisher.alpha</a></code>,
<code><a href="#topic+radfit">radfit</a></code>, <code><a href="#topic+specpool">specpool</a></code>. Function
<code><a href="MASS.html#topic+fitdistr">fitdistr</a></code> of <span class="pkg">MASS</span> package was used as the
model for <code>prestondistr</code>. Function <code><a href="stats.html#topic+density">density</a></code> can be used for
smoothed non-parametric estimation of responses, and
<code><a href="stats.html#topic+qqplot">qqplot</a></code> is an alternative, traditional and more effective
way of studying concordance of observed abundances to any distribution model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
mod &lt;- fisherfit(BCI[5,])
mod
# prestonfit seems to need large samples
mod.oct &lt;- prestonfit(colSums(BCI))
mod.ll &lt;- prestondistr(colSums(BCI))
mod.oct
mod.ll
plot(mod.oct)  
lines(mod.ll, line.col="blue3") # Different
## Smoothed density
den &lt;- density(log2(colSums(BCI)))
lines(den$x, ncol(BCI)*den$y, lwd=2) # Fairly similar to mod.oct
## Extrapolated richness
veiledspec(mod.oct)
veiledspec(mod.ll)
</code></pre>

<hr>
<h2 id='goodness.cca'>Diagnostic Tools for [Constrained] Ordination (CCA,
RDA, DCA, CA, PCA) </h2><span id='topic+goodness'></span><span id='topic+goodness.cca'></span><span id='topic+inertcomp'></span><span id='topic+spenvcor'></span><span id='topic+intersetcor'></span><span id='topic+vif.cca'></span><span id='topic+alias.cca'></span>

<h3>Description</h3>

<p>Functions <code>goodness</code> and <code>inertcomp</code> can
be used to assess the goodness of fit for individual sites or
species. Function <code>vif.cca</code> and <code>alias.cca</code> can be used to
analyse linear dependencies among constraints and conditions. In
addition, there are some other diagnostic tools (see 'Details').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
goodness(object, choices, display = c("species", "sites"),
    model = c("CCA", "CA"), summarize = FALSE, addprevious = FALSE, ...)
inertcomp(object, display = c("species", "sites"),
    unity = FALSE, proportional = FALSE)
spenvcor(object)
intersetcor(object)
vif.cca(object)
## S3 method for class 'cca'
alias(object, names.only = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goodness.cca_+3A_object">object</code></td>
<td>
<p>A result object from <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code> or <code><a href="#topic+capscale">capscale</a></code>. </p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_display">display</code></td>
<td>
<p>Display <code>"species"</code> or <code>"sites"</code>. Species
are not available in <code><a href="#topic+dbrda">dbrda</a></code> and <code><a href="#topic+capscale">capscale</a></code>. </p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_choices">choices</code></td>
<td>
<p>Axes shown. Default is to show all axes of the
<code>"model"</code>. </p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_model">model</code></td>
<td>
<p>Show constrained (<code>"CCA"</code>) or unconstrained
(<code>"CA"</code>) results. </p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_summarize">summarize</code></td>
<td>
<p>Show only the accumulated total.</p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_addprevious">addprevious</code></td>
<td>
<p>Add the variation explained by previous components
when <code>statistic="explained"</code>. For <code>model = "CCA"</code> add
conditioned (partialled out) variation, and for <code>model = "CA"</code>
add both conditioned and constrained variation. This will give
cumulative explanation with previous components.
</p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_unity">unity</code></td>
<td>
<p>Scale inertia components to unit sum (sum of all items is
1).</p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_proportional">proportional</code></td>
<td>
<p>Give the inertia components as proportional for
the corresponding total of the item (sum of each row is 1). This
option takes precedence over <code>unity</code>.</p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_names.only">names.only</code></td>
<td>
<p>Return only names of aliased variable(s) instead of
defining equations.</p>
</td></tr>
<tr><td><code id="goodness.cca_+3A_...">...</code></td>
<td>
<p>Other parameters to the functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>goodness</code> gives cumulative proportion of inertia
accounted by species up to chosen axes. The proportions can be
assessed either by species or by sites depending on the argument
<code>display</code>, but species are not available in distance-based
<code><a href="#topic+dbrda">dbrda</a></code>. The function is not implemented for
<code><a href="#topic+capscale">capscale</a></code>.
</p>
<p>Function <code>inertcomp</code> decomposes the inertia into partial,
constrained and unconstrained components for each site or species.
Legendre &amp; De C√°ceres (2012) called these inertia
components as local contributions to beta-diversity (LCBD) and
species contributions to beta-diversity (SCBD), and they give these
as relative contributions summing up to unity (argument
<code>unity = TRUE</code>). For this interpretation, appropriate dissimilarity
measures should be used in <code><a href="#topic+dbrda">dbrda</a></code> or appropriate
standardization in <code><a href="#topic+rda">rda</a></code> (Legendre &amp; De
C√°ceres 2012). The function is not implemented for
<code><a href="#topic+capscale">capscale</a></code>.
</p>
<p>Function <code>spenvcor</code> finds the so-called &ldquo;species &ndash;
environment correlation&rdquo; or (weighted) correlation of
weighted average scores and linear combination scores.  This is a bad
measure of goodness of ordination, because it is sensitive to extreme
scores (like correlations are), and very sensitive to overfitting or
using too many constraints. Better models often have poorer
correlations. Function <code><a href="#topic+ordispider">ordispider</a></code> can show the same
graphically.
</p>
<p>Function <code>intersetcor</code> finds the so-called &ldquo;interset
correlation&rdquo; or (weighted) correlation of weighted averages scores
and constraints.  The defined contrasts are used for factor
variables.  This is a bad measure since it is a correlation.  Further,
it focuses on correlations between single contrasts and single axes
instead of looking at the multivariate relationship.  Fitted vectors
(<code><a href="#topic+envfit">envfit</a></code>) provide a better alternative.  Biplot scores
(see <code><a href="#topic+scores.cca">scores.cca</a></code>) are a multivariate alternative for
(weighted) correlation between linear combination scores and
constraints.
</p>
<p>Function <code>vif.cca</code> gives the variance inflation factors for each
constraint or contrast in factor constraints. In partial ordination,
conditioning variables are analysed together with constraints. Variance
inflation is a diagnostic tool to identify useless constraints. A
common rule is that values over 10 indicate redundant
constraints. If later constraints are complete linear combinations of
conditions or previous constraints, they will be completely removed
from the estimation, and no biplot scores or centroids are calculated
for these aliased constraints. A note will be printed with default
output if there are aliased constraints. Function <code>alias</code> will
give the linear coefficients defining the aliased constraints, or
only their names with argument <code>names.only = TRUE</code>.
</p>


<h3>Value</h3>

<p>The functions return matrices or vectors as is appropriate.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen. The <code>vif.cca</code> relies heavily on the code by
W. N. Venables. <code>alias.cca</code> is a simplified version of
<code><a href="stats.html#topic+alias.lm">alias.lm</a></code>.</p>


<h3>References</h3>

<p>Greenacre, M. J. (1984). Theory and applications of correspondence
analysis. Academic Press, London.
</p>
<p>Gross, J. (2003). Variance inflation factors. <em>R News</em> 3(1),
13&ndash;15.
</p>
<p>Legendre, P. &amp; De C√°ceres, M. (2012). Beta diversity as
the variance of community data: dissimilarity coefficients and
partitioning. <em>Ecology Letters</em> 16, 951&ndash;963.
<a href="https://doi.org/10.1111/ele.12141">doi:10.1111/ele.12141</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code>,
<code><a href="#topic+capscale">capscale</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
mod &lt;- cca(dune ~ A1 + Management + Condition(Moisture), data=dune.env)
goodness(mod, addprevious = TRUE)
goodness(mod, addprevious = TRUE, summ = TRUE)
# Inertia components
inertcomp(mod, prop = TRUE)
inertcomp(mod)
# vif.cca
vif.cca(mod)
# Aliased constraints
mod &lt;- cca(dune ~ ., dune.env)
mod
vif.cca(mod)
alias(mod)
with(dune.env, table(Management, Manure))
# The standard correlations (not recommended)
## IGNORE_RDIFF_BEGIN
spenvcor(mod)
intersetcor(mod)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='goodness.metaMDS'>Goodness of Fit and Shepard Plot for Nonmetric Multidimensional Scaling </h2><span id='topic+goodness.metaMDS'></span><span id='topic+goodness.monoMDS'></span><span id='topic+stressplot'></span><span id='topic+stressplot.default'></span><span id='topic+stressplot.monoMDS'></span>

<h3>Description</h3>

<p>Function <code>goodness.metaMDS</code> find goodness of fit measure for
points in nonmetric multidimensional scaling, and function
<code>stressplot</code> makes a <code><a href="MASS.html#topic+Shepard">Shepard</a></code> diagram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'metaMDS'
goodness(object, dis, ...)
## Default S3 method:
stressplot(object, dis, pch, p.col = "blue", l.col = "red", 
    lwd = 2, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goodness.metaMDS_+3A_object">object</code></td>
<td>
<p>A result object from <code><a href="#topic+metaMDS">metaMDS</a></code>, 
<code><a href="#topic+monoMDS">monoMDS</a></code> or <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>. </p>
</td></tr>
<tr><td><code id="goodness.metaMDS_+3A_dis">dis</code></td>
<td>
<p>Dissimilarities.  This should not be used with
<code><a href="#topic+metaMDS">metaMDS</a></code> or <code><a href="#topic+monoMDS">monoMDS</a></code>, but must be used with
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>.</p>
</td></tr>
<tr><td><code id="goodness.metaMDS_+3A_pch">pch</code></td>
<td>
<p>Plotting character for points.  Default is dependent on the
number of points. </p>
</td></tr>
<tr><td><code id="goodness.metaMDS_+3A_p.col">p.col</code>, <code id="goodness.metaMDS_+3A_l.col">l.col</code></td>
<td>
<p>Point and line colours.</p>
</td></tr>
<tr><td><code id="goodness.metaMDS_+3A_lwd">lwd</code></td>
<td>
<p>Line width. For <code><a href="#topic+monoMDS">monoMDS</a></code> the default is
<code>lwd = 1</code> if more than two lines are drawn, and <code>lwd = 2</code> 
otherwise.</p>
</td></tr>
<tr><td><code id="goodness.metaMDS_+3A_...">...</code></td>
<td>
<p>Other parameters to functions, e.g. graphical parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>goodness.metaMDS</code> finds a goodness of fit statistic
for observations (points).  This is defined so that sum of squared
values is equal to squared stress.  Large values indicate poor fit.
The absolute values of the goodness statistic depend on the
definition of the stress: <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> expresses
stress in percents, and therefore its goodness values are 100 times
higher than those of <code><a href="#topic+monoMDS">monoMDS</a></code> which expresses the
stress as a proportion.
</p>
<p>Function <code>stressplot</code> draws a Shepard diagram which is a plot
of ordination distances and monotone or linear fit line against
original dissimilarities.  In addition, it displays two
correlation-like statistics on the goodness of fit in the graph.
The nonmetric fit is based on stress <code class="reqn">S</code> and defined as <code class="reqn">R^2
  = 1-S^2</code>.  The &ldquo;linear fit&rdquo; is the squared
correlation between fitted values and ordination distances. For
<code><a href="#topic+monoMDS">monoMDS</a></code>, the &ldquo;linear fit&rdquo; and <code class="reqn">R^2</code>
from &ldquo;stress type 2&rdquo; are equal.
</p>
<p>Both functions can be used with <code><a href="#topic+metaMDS">metaMDS</a></code>,
<code><a href="#topic+monoMDS">monoMDS</a></code> and <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>.  The original
dissimilarities should not be given for <code><a href="#topic+monoMDS">monoMDS</a></code> or
<code><a href="#topic+metaMDS">metaMDS</a></code> results (the latter tries to reconstruct the
dissimilarities using <code><a href="#topic+metaMDSredist">metaMDSredist</a></code> if
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> was used as its engine).  With
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> the dissimilarities must be given.  In
either case, the functions inspect that dissimilarities are
consistent with current ordination, and refuse to analyse
inconsistent dissimilarities.  Function <code>goodness.metaMDS</code> is
generic in <span class="pkg">vegan</span>, but you must spell its name completely with
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> which has no class.
</p>


<h3>Value</h3>

<p> Function <code>goodness</code> returns a vector of values. Function
<code>stressplot</code> returns invisibly an object with items for
original dissimilarities, ordination distances and fitted values.  </p>


<h3>Author(s)</h3>

<p>Jari Oksanen. </p>


<h3>See Also</h3>

<p><code><a href="#topic+metaMDS">metaMDS</a></code>,  <code><a href="#topic+monoMDS">monoMDS</a></code>, 
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>, <code><a href="MASS.html#topic+Shepard">Shepard</a></code>. Similar
diagrams for eigenvector ordinations can be drawn with
<code><a href="#topic+stressplot.wcmdscale">stressplot.wcmdscale</a></code>, <code><a href="#topic+stressplot.cca">stressplot.cca</a></code>,
<code><a href="#topic+stressplot.rda">stressplot.rda</a></code> and <code><a href="#topic+stressplot.capscale">stressplot.capscale</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
mod &lt;- metaMDS(varespec)
stressplot(mod)
gof &lt;- goodness(mod)
gof
plot(mod, display = "sites", type = "n")
points(mod, display = "sites", cex = 2*gof/mean(gof))
</code></pre>

<hr>
<h2 id='indpower'>Indicator Power of Species</h2><span id='topic+indpower'></span>

<h3>Description</h3>

<p> Indicator power calculation of Halme et al.  (2009)
or the congruence between indicator and target species.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indpower(x, type = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indpower_+3A_x">x</code></td>
<td>
<p>Community data frame or matrix. </p>
</td></tr>
<tr><td><code id="indpower_+3A_type">type</code></td>
<td>
<p>The type of
statistic to be returned. See Details for explanation.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>Halme et al. (2009) described an index of indicator power defined as
<code class="reqn">IP_I = \sqrt{a \times  b}</code>, where <code class="reqn">a = S / O_I</code> and
<code class="reqn">b = 1 - (O_T - S) / (N - O_I)</code>. 
<code class="reqn">N</code> is the number of sites,
<code class="reqn">S</code> is the number of shared occurrences of the indicator (<code class="reqn">I</code>)
and the target (<code class="reqn">T</code>) species. <code class="reqn">O_I</code> and <code class="reqn">O_T</code> are number
of occurrences of the indicator and target species. The <code>type</code>
argument in the function call enables to choose which statistic to
return. <code>type = 0</code> returns <code class="reqn">IP_I</code>, <code>type = 1</code> returns 
<code class="reqn">a</code>, <code>type = 2</code> returns <code class="reqn">b</code>.
Total indicator power (TIP) of an indicator species is the column mean
(without its own value, see examples).  
Halme et al. (2009) explain how to calculate confidence
intervals for these statistics, see Examples.
</p>


<h3>Value</h3>

<p>A matrix with indicator species as rows and
target species as columns (this is indicated by the first letters of the
row/column names).
</p>


<h3>Author(s)</h3>

<p>Peter Solymos</p>


<h3>References</h3>

<p>Halme, P., M√∂nkk√∂nen, M., Kotiaho, J. S, 
Ylisirni√∂, A-L. 2009. Quantifying the indicator power
of an indicator species. <em>Conservation Biology</em> 23: 1008&ndash;1016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
## IP values
ip &lt;- indpower(dune)
## and TIP values
diag(ip) &lt;- NA
(TIP &lt;- rowMeans(ip, na.rm=TRUE))

## p value calculation for a species
## from Halme et al. 2009
## i is ID for the species
i &lt;- 1
fun &lt;- function(x, i) indpower(x)[i,-i]
## 'c0' randomizes species occurrences
os &lt;- oecosimu(dune, fun, "c0", i=i, nsimul=99)
## get z values from oecosimu output
z &lt;- os$oecosimu$z
## p-value
(p &lt;- sum(z) / sqrt(length(z)))
## 'heterogeneity' measure
(chi2 &lt;- sum((z - mean(z))^2))
pchisq(chi2, df=length(z)-1)
## Halme et al.'s suggested output
out &lt;- c(TIP=TIP[i], 
    significance=p,
    heterogeneity=chi2,
    minIP=min(fun(dune, i=i)),
    varIP=sd(fun(dune, i=i)^2))
out
</code></pre>

<hr>
<h2 id='influence.cca'>Linear Model Diagnostics for Constrained Ordination</h2><span id='topic+hatvalues.cca'></span><span id='topic+hatvalues.rda'></span><span id='topic+sigma.cca'></span><span id='topic+rstandard.cca'></span><span id='topic+rstudent.cca'></span><span id='topic+cooks.distance.cca'></span><span id='topic+SSD.cca'></span><span id='topic+vcov.cca'></span><span id='topic+qr.cca'></span><span id='topic+df.residual.cca'></span>

<h3>Description</h3>

<p>This set of function extracts influence statistics and some other
linear model statistics directly from a constrained ordination result
object from <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>,
<code><a href="#topic+capscale">capscale</a></code> or <code><a href="#topic+dbrda">dbrda</a></code>. The constraints are
linear model functions and these support functions return identical
results as the corresponding linear models (<code><a href="stats.html#topic+lm">lm</a></code>), and you
can use their documentation. The main functions for normal usage are
leverage values (<code><a href="stats.html#topic+hatvalues">hatvalues</a></code>), standardized residuals
(<code><a href="stats.html#topic+rstandard">rstandard</a></code>), studentized or leave-one-out residuals
(<code><a href="stats.html#topic+rstudent">rstudent</a></code>), and Cook's distance
(<code><a href="stats.html#topic+cooks.distance">cooks.distance</a></code>).  In addition, <code><a href="stats.html#topic+vcov">vcov</a></code>
returns the variance-covariance matrix of coefficients, and its
diagonal values the variances of coefficients. Other functions are
mainly support functions for these, but they can be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'cca'
hatvalues(model, ...)
## S3 method for class 'cca'
rstandard(model, type = c("response", "canoco"), ...)
## S3 method for class 'cca'
rstudent(model, type = c("response", "canoco"), ...)
## S3 method for class 'cca'
cooks.distance(model, type = c("response", "canoco"), ...)

## S3 method for class 'cca'
sigma(object, type = c("response", "canoco"), ...)
## S3 method for class 'cca'
vcov(object, type = "canoco", ...)
## S3 method for class 'cca'
SSD(object, type = "canoco", ...)

## S3 method for class 'cca'
qr(x, ...)
## S3 method for class 'cca'
df.residual(object, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="influence.cca_+3A_model">model</code>, <code id="influence.cca_+3A_object">object</code>, <code id="influence.cca_+3A_x">x</code></td>
<td>
<p>A constrained ordination result object.</p>
</td></tr>
<tr><td><code id="influence.cca_+3A_type">type</code></td>
<td>
<p>Type of statistics used for extracting raw residuals and
residual standard deviation (<code>sigma</code>). Either
<code>"response"</code> for species data or difference of WA and LC
scores for <code>"canoco"</code>.</p>
</td></tr>
<tr><td><code id="influence.cca_+3A_...">...</code></td>
<td>
<p>Other arguments to functions (ignored).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <span class="pkg">vegan</span> algorithm for constrained ordination uses linear model
(or weighted linear model in <code><a href="#topic+cca">cca</a></code>) to find the fitted
values of dependent community data, and constrained ordination is
based on this fitted response (Legendre &amp; Legendre 2012). The
<code><a href="stats.html#topic+hatvalues">hatvalues</a></code> give the leverage values of these constraints,
and the leverage is independent on the response data. Other influence
statistics (<code><a href="stats.html#topic+rstandard">rstandard</a></code>, <code><a href="stats.html#topic+rstudent">rstudent</a></code>,
<code><a href="stats.html#topic+cooks.distance">cooks.distance</a></code>) are based on leverage, and on the raw
residuals and residual standard deviation (<code><a href="stats.html#topic+sigma">sigma</a></code>). With
<code>type = "response"</code> the raw residuals are given by the
unconstrained component of the constrained ordination, and influence
statistics are a matrix with dimensions no. of observations times
no. of species. For <code><a href="#topic+cca">cca</a></code> the statistics are the same as
obtained from the <code><a href="stats.html#topic+lm">lm</a></code> model using Chi-square standardized
species data (see <code><a href="#topic+decostand">decostand</a></code>) as dependent variable, and
row sums of community data as weights, and for <code><a href="#topic+rda">rda</a></code> the
<code><a href="stats.html#topic+lm">lm</a></code> model uses non-modified community data and no
weights.
</p>
<p>The algorithm in the CANOCO software constraints the results during
iteration by performing a linear regression of weighted averages (WA)
scores on constraints and taking the fitted values of this regression
as linear combination (LC) scores (ter Braak 1984). The WA scores are
directly found from species scores, but LC scores are linear
combinations of constraints in the regression. With <code>type =
  "canoco"</code> the raw residuals are the differences of WA and LC scores,
and the residual standard deviation (<code><a href="stats.html#topic+sigma">sigma</a></code>) is taken to
be the axis sum of squared WA scores minus one. These quantities have
no relationship to residual component of ordination, but they rather
are methodological artefacts of an algorithm that is not used in
<span class="pkg">vegan</span>. The result is a matrix with dimensions no. of
observations times no. of constrained axes.
</p>
<p>Function <code><a href="stats.html#topic+vcov">vcov</a></code> returns the matrix of variances and
covariances of regression coefficients. The diagonal values of this
matrix are the variances, and their square roots give the standard
errors of regression coefficients. The function is based on
<code><a href="stats.html#topic+SSD">SSD</a></code> that extracts the sum of squares and crossproducts
of residuals. The residuals are defined similarly as in influence
measures and with each <code>type</code> they have similar properties and
limitations, and define the dimensions of the result matrix. 
</p>


<h3>Note</h3>

<p>Function <code><a href="#topic+as.mlm">as.mlm</a></code> casts an ordination object to a multiple
linear model of class <code>"mlm"</code> (see <code><a href="stats.html#topic+lm">lm</a></code>), and similar
statistics can be derived from that modified object as with this set
of functions. However, there are some problems in the <span class="rlang"><b>R</b></span>
implementation of the further analysis of multiple linear model
objects. When the results differ, the current set of functions is more
probable to be correct. The use of <code>as.mlm</code> objects should be
avoided.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>References</h3>

<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd
English ed. Elsevier.
</p>
<p>ter Braak, C.J.F. (1984&ndash;): CANOCO &ndash; a FORTRAN program for
<em>cano</em>nical <em>c</em>ommunity <em>o</em>rdination by [partial]
[detrended] [canonical] correspondence analysis, principal components
analysis and redundancy analysis. <em>TNO Inst. of Applied Computer
Sci., Stat. Dept. Wageningen, The Netherlands</em>.
</p>


<h3>See Also</h3>

<p>Corresponding <code><a href="stats.html#topic+lm">lm</a></code> methods and
<code><a href="#topic+as.mlm.cca">as.mlm.cca</a></code>. Function <code><a href="#topic+ordiresids">ordiresids</a></code> provides
lattice graphics for residuals.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(varespec, varechem)
mod &lt;- cca(varespec ~ Al + P + K, varechem)
## leverage
hatvalues(mod)
plot(hatvalues(mod), type = "h")
## ordination plot with leverages: points with high leverage have
## similar LC and WA scores
plot(mod, type = "n")
ordispider(mod)       # segment from LC to WA scores
points(mod, dis="si", cex=5*hatvalues(mod), pch=21, bg=2) # WA scores
text(mod, dis="bp", col=4)

## deviation and influence
head(rstandard(mod))
head(cooks.distance(mod))

## Influence measures from lm
y &lt;- decostand(varespec, "chi.square") # needed in cca
y1 &lt;- with(y, Cladstel)         # take one species for lm
lmod1 &lt;- lm(y1 ~ Al + P + K, varechem, weights = rowSums(varespec))
## numerically identical within 2e-15
all(abs(cooks.distance(lmod1) - cooks.distance(mod)[, "Cladstel"]) &lt; 1e-8)

## t-values of regression coefficients based on type = "canoco"
## residuals
coef(mod)
coef(mod)/sqrt(diag(vcov(mod, type = "canoco")))
</code></pre>

<hr>
<h2 id='isomap'> Isometric Feature Mapping Ordination </h2><span id='topic+isomap'></span><span id='topic+isomapdist'></span><span id='topic+plot.isomap'></span><span id='topic+summary.isomap'></span>

<h3>Description</h3>

<p>The function performs isometric feature mapping which consists of
three simple steps: (1) retain only some of the shortest
dissimilarities among objects, (2) estimate all dissimilarities as
shortest path distances, and (3) perform metric scaling (Tenenbaum et
al. 2000).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isomap(dist, ndim=10, ...)
isomapdist(dist, epsilon, k, path = "shortest", fragmentedOK =FALSE, ...)
## S3 method for class 'isomap'
summary(object, axes = 4, ...)
## S3 method for class 'isomap'
plot(x, net = TRUE, n.col = "gray", type = "points", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isomap_+3A_dist">dist</code></td>
<td>
<p>Dissimilarities. </p>
</td></tr>
<tr><td><code id="isomap_+3A_ndim">ndim</code></td>
<td>
<p>Number of axes in metric scaling (argument <code>k</code> in 
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>).</p>
</td></tr>
<tr><td><code id="isomap_+3A_epsilon">epsilon</code></td>
<td>
<p>Shortest dissimilarity retained. </p>
</td></tr>
<tr><td><code id="isomap_+3A_k">k</code></td>
<td>
<p>Number of shortest dissimilarities retained for a point. If
both <code>epsilon</code> and <code>k</code> are given, <code>epsilon</code> will be used.  </p>
</td></tr>
<tr><td><code id="isomap_+3A_path">path</code></td>
<td>
<p>Method used in <code><a href="#topic+stepacross">stepacross</a></code> to estimate the
shortest path, with alternatives <code>"shortest"</code> and <code>"extended"</code>. </p>
</td></tr>
<tr><td><code id="isomap_+3A_fragmentedok">fragmentedOK</code></td>
<td>
<p>What to do if dissimilarity matrix is
fragmented. If <code>TRUE</code>, analyse the largest connected group,
otherwise stop with error. </p>
</td></tr>
<tr><td><code id="isomap_+3A_x">x</code>, <code id="isomap_+3A_object">object</code></td>
<td>
<p>An <code>isomap</code> result object.</p>
</td></tr>
<tr><td><code id="isomap_+3A_axes">axes</code></td>
<td>
<p>Number of axes displayed.</p>
</td></tr>
<tr><td><code id="isomap_+3A_net">net</code></td>
<td>
<p>Draw the net of retained dissimilarities.</p>
</td></tr>
<tr><td><code id="isomap_+3A_n.col">n.col</code></td>
<td>
<p>Colour of drawn net segments. This can also be a vector
that is recycled for points, and the colour of the net segment is
a mixture of joined points.</p>
</td></tr>
<tr><td><code id="isomap_+3A_type">type</code></td>
<td>
<p>Plot observations either as <code>"points"</code>,
<code>"text"</code> or use <code>"none"</code> to plot no observations. The
<code>"text"</code> will use <code><a href="#topic+ordilabel">ordilabel</a></code> if <code>net = TRUE</code> 
and <code><a href="#topic+ordiplot">ordiplot</a></code> if <code>net = FALSE</code>, and pass
extra arguments to these functions.</p>
</td></tr>
<tr><td><code id="isomap_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>isomap</code> first calls function <code>isomapdist</code> for
dissimilarity transformation, and then performs metric scaling for the
result. All arguments to <code>isomap</code> are passed to
<code>isomapdist</code>. The functions are separate so that the
<code>isompadist</code> transformation could be easily used with other
functions than simple linear mapping of <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>.
</p>
<p>Function <code>isomapdist</code> retains either dissimilarities equal or shorter to
<code>epsilon</code>, or if <code>epsilon</code> is not given, at least <code>k</code>
shortest dissimilarities for a point.  Then a complete dissimilarity
matrix is reconstructed using <code><a href="#topic+stepacross">stepacross</a></code> using either
flexible shortest paths or extended dissimilarities (for details, see
<code><a href="#topic+stepacross">stepacross</a></code>).
</p>
<p>De'ath (1999) actually published essentially the same method before
Tenenbaum et al. (2000), and De'ath's function is available in function
<code>xdiss</code> in non-CRAN package <span class="pkg">mvpart</span>. The differences are that
<code>isomap</code> introduced the <code>k</code> criterion, whereas De'ath only
used <code>epsilon</code> criterion.  In practice, De'ath also retains
higher proportion of dissimilarities than typical <code>isomap</code>.
</p>
<p>The <code>plot</code> function uses internally <code><a href="#topic+ordiplot">ordiplot</a></code>,
except that it adds text over net using <code><a href="#topic+ordilabel">ordilabel</a></code>. The
<code>plot</code> function passes extra arguments to these functions.  In
addition, <span class="pkg">vegan3d</span> package has function
<code>rgl.isomap</code> to make dynamic 3D plots that can
be rotated on the screen.
</p>


<h3>Value</h3>

<p>Function <code>isomapdist</code> returns a dissimilarity object similar to
<code>dist</code>. Function <code>isomap</code> returns an object of class
<code>isomap</code> with <code>plot</code> and <code>summary</code> methods. The
<code>plot</code> function returns invisibly an object of class
<code><a href="#topic+ordiplot">ordiplot</a></code>. Function <code><a href="#topic+scores">scores</a></code> can extract
the ordination scores.
</p>


<h3>Note</h3>

 
<p>Tenenbaum et al. (2000) justify <code>isomap</code> as a tool of unfolding a
manifold (e.g. a 'Swiss Roll'). Even with a manifold structure, the
sampling must be even and dense so
that dissimilarities along a manifold are shorter than across the
folds. If data do not have such a manifold structure, the results are
very sensitive to parameter values. 
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>De'ath, G. (1999)  Extended dissimilarity: a method of robust
estimation of ecological distances from high beta diversity data.
<em>Plant Ecology</em> 144, 191&ndash;199
</p>
<p>Tenenbaum, J.B., de Silva, V. &amp; Langford, J.C. (2000) A global
network framework for nonlinear dimensionality
reduction. <em>Science</em> 290, 2319&ndash;2323.
</p>


<h3>See Also</h3>

<p>The underlying functions that do the proper work are
<code><a href="#topic+stepacross">stepacross</a></code>, <code><a href="#topic+distconnected">distconnected</a></code> and
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>.  Function <code><a href="#topic+metaMDS">metaMDS</a></code> may trigger
<code><a href="#topic+stepacross">stepacross</a></code> transformation, but usually only for
longest dissimilarities.  The <code>plot</code> method of <span class="pkg">vegan</span>
minimum spanning tree function (<code><a href="#topic+spantree">spantree</a></code>) has even
more extreme way of isomapping things. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## The following examples also overlay minimum spanning tree to
## the graphics in red.
op &lt;- par(mar=c(4,4,1,1)+0.2, mfrow=c(2,2))
data(BCI)
dis &lt;- vegdist(BCI)
tr &lt;- spantree(dis)
pl &lt;- ordiplot(cmdscale(dis), main="cmdscale")
lines(tr, pl, col="red")
ord &lt;- isomap(dis, k=3)
ord
pl &lt;- plot(ord, main="isomap k=3")
lines(tr, pl, col="red")
pl &lt;- plot(isomap(dis, k=5), main="isomap k=5")
lines(tr, pl, col="red")
pl &lt;- plot(isomap(dis, epsilon=0.45), main="isomap epsilon=0.45")
lines(tr, pl, col="red")
par(op)
## colour points and web by the dominant species
dom &lt;- apply(BCI, 1, which.max)
## need nine colours, but default palette  has only eight
op &lt;- palette(c(palette("default"), "sienna"))
plot(ord, pch = 16, col = dom, n.col = dom) 
palette(op)
</code></pre>

<hr>
<h2 id='kendall.global'> Kendall coefficient of concordance </h2><span id='topic+kendall.global'></span><span id='topic+kendall.post'></span>

<h3>Description</h3>

 
<p>Function <code>kendall.global</code> computes and tests the coefficient of
concordance among several judges (variables, species) through a
permutation test.
</p>
<p>Function <code>kendall.post</code> carries out <em>a posteriori</em> tests
of the contributions of individual judges (variables, species) to
the overall concordance of their group through permutation tests.
</p>
<p>If several groups of judges are identified in the data table,
coefficients of concordance (<code>kendall.global</code>) or a posteriori
tests (<code>kendall.post</code>) will be computed for each group
separately. Use in ecology: to identify significant species
associations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kendall.global(Y, group, nperm = 999, mult = "holm")
kendall.post(Y, group, nperm = 999, mult = "holm")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kendall.global_+3A_y">Y</code></td>
<td>
<p> Data file (data frame or matrix) containing quantitative or
semiquantitative data. Rows are objects and columns are judges
(variables). In community ecology, that table is often a
site-by-species table. </p>
</td></tr>
<tr><td><code id="kendall.global_+3A_group">group</code></td>
<td>
<p> A vector defining how judges should be divided into
groups. See example below. If groups are not explicitly defined,
all judges in the data file will be considered as forming a single
group. </p>
</td></tr>
<tr><td><code id="kendall.global_+3A_nperm">nperm</code></td>
<td>
<p> Number of permutations to be performed. Default is
999. </p>
</td></tr>
<tr><td><code id="kendall.global_+3A_mult">mult</code></td>
<td>
<p>Correct P-values for multiple testing using the
alternatives described in <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> and in addition
<code>"sidak"</code> (see Details). The Bonferroni correction is overly
conservative; it is not recommended. It is included to allow
comparisons with the other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Y</code> must contain quantitative data. They will be transformed to
ranks within each column before computation of the coefficient of
concordance.
</p>
<p>The search for species associations described in Legendre (2005)
proceeds in 3 steps:
</p>
<p>(1) Correlation analysis of the species. A possible method is to
compute Ward's agglomerative clustering of a matrix of correlations
among the species. In detail: (1.1) compute a Pearson or Spearman
correlation matrix (<code>correl.matrix</code>) among the species; (1.2)
turn it into a distance matrix: <code>mat.D = as.dist(1-correl.matrix)</code>; 
(1.3) carry out Ward's hierarchical
clustering of that matrix using <code>hclust</code>: 
<code>clust.ward = hclust(mat.D, "ward")</code>; (1.4) plot the dendrogram:
<code>plot(clust.ward, hang=-1)</code>; (1.5) cut the dendrogram in two
groups, retrieve the vector of species membership: 
<code>group.2 = cutree(clust.ward, k=2)</code>. (1.6) After steps 2 and 3 below, 
you may
have to come back and try divisions of the species into k = <code class="reqn">3, 4, 5, \dots</code> 
groups.
</p>
<p>(2) Compute global tests of significance of the 2 (or more) groups
using the function <code>kendall.global</code> and the vector defining the
groups. Groups that are not globally significant must be refined or
abandoned.
</p>
<p>(3) Compute a posteriori tests of the contribution of individual
species to the concordance of their group using the function
<code>kendall.post</code> and the vector defining the groups. If some
species have negative values for &quot;Spearman.mean&quot;, this means that
these species clearly do not belong to the group, hence that group
is too inclusive. Go back to (1.5) and cut the dendrogram more
finely. The left and right groups can be cut separately,
independently of the levels along the dendrogram; write your own
vector of group membership if <code>cutree</code> does not produce the
desired groups.
</p>
<p>The corrections used for multiple testing are applied to the list of
P-values (P); they take into account the number of tests (k) carried
out simultaneously (number of groups in <code>kendall.global</code>, or
number of species in <code>kendall.post</code>). The corrections are
performed using function <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>; see that function
for the description of the correction methods. In addition, there is
≈†id√°k correction which defined as 
<code class="reqn">P_{corr} = 1 -(1 - P)^k</code>.
</p>


<h3>Value</h3>

<p>A table containing the following information in rows. The columns
correspond to the groups of &quot;judges&quot; defined in vector &quot;group&quot;. When
function <code>Kendall.post</code> is used, there are as many tables as
the number of predefined groups.
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>Kendall's coefficient of concordance, W. </p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>F statistic. F = W*(m-1)/(1-W) where m is the number of
judges. </p>
</td></tr>
<tr><td><code>Prob.F</code></td>
<td>
<p>Probability associated with the F statistic, computed
from the F distribution with nu1 = n-1-(2/m) and nu2 = nu1*(m-1); n is
the number of objects. </p>
</td></tr>
<tr><td><code>Corrected prob.F</code></td>
<td>
<p>Probabilities associated with F, corrected
using the method selected in parameter <code>mult</code>. Shown only if
there are more than one group. </p>
</td></tr>
<tr><td><code>Chi2</code></td>
<td>
<p>Friedman's chi-square statistic (Friedman 1937) used in
the permutation test of W. </p>
</td></tr>
<tr><td><code>Prob.perm</code></td>
<td>
<p>Permutational probabilities, uncorrected. </p>
</td></tr>
<tr><td><code>Corrected prob.perm</code></td>
<td>
<p>Permutational probabilities corrected
using the method selected in parameter <code>mult</code>. Shown only if
there are more than one group. </p>
</td></tr>
<tr><td><code>Spearman.mean</code></td>
<td>
<p>Mean of the Spearman correlations between the
judge under test and all the other judges in the same group. </p>
</td></tr>
<tr><td><code>W.per.species</code></td>
<td>
<p>Contribution of the judge under test to the
overall concordance statistic for that group. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> F. Guillaume Blanchet, University of Alberta, and Pierre
Legendre, Universit√© de Montr√©al </p>


<h3>References</h3>

 
<p>Friedman, M. 1937. The use of ranks to avoid the assumption of normality
implicit in the analysis of variance. Journal of the American
Statistical Association 32: 675-701.
</p>
<p>Kendall, M. G. and B. Babington Smith. 1939. The problem of m
rankings. Annals of Mathematical Statistics 10: 275-287.
</p>
<p>Legendre, P. 2005. Species associations: the Kendall coefficient of
concordance revisited. Journal of Agricultural, Biological, and
Environmental Statistics 10: 226-245.
</p>
<p>Legendre, P. 2009. Coefficient of concordance. In: Encyclopedia of
Research Design. SAGE Publications (in press).
</p>
<p>Siegel, S. and N. J. Castellan, Jr. 1988. Nonparametric statistics for
the behavioral sciences. 2nd edition. McGraw-Hill, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="stats.html#topic+friedman.test">friedman.test</a></code>,
<code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="stats.html#topic+cutree">cutree</a></code>, <code><a href="stats.html#topic+kmeans">kmeans</a></code>,
<code><a href="#topic+cascadeKM">cascadeKM</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite)
mite.hel &lt;- decostand(mite, "hel")

# Reproduce the results shown in Table 2 of Legendre (2005), a single group
mite.small &lt;- mite.hel[c(4,9,14,22,31,34,45,53,61,69),c(13:15,23)]
kendall.global(mite.small, nperm=49)
kendall.post(mite.small, mult="holm", nperm=49)

# Reproduce the results shown in Tables 3 and 4 of Legendre (2005), 2 groups
group &lt;-c(1,1,2,1,1,1,1,1,2,1,1,1,1,1,1,2,1,2,1,1,1,1,2,1,2,1,1,1,1,1,2,2,2,2,2)
kendall.global(mite.hel, group=group, nperm=49)
kendall.post(mite.hel, group=group, mult="holm", nperm=49)

# NOTE: 'nperm' argument usually needs to be larger than 49.
# It was set to this low value for demonstration purposes.
</code></pre>

<hr>
<h2 id='linestack'>Plots One-dimensional Diagrams without Overwriting Labels </h2><span id='topic+linestack'></span>

<h3>Description</h3>

<p>Function <code>linestack</code> plots vertical one-dimensional plots for
numeric vectors.  The plots are always labelled, but the labels
are moved vertically to avoid overwriting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linestack(x, labels, cex = 0.8, side = "right", hoff = 2, air = 1.1,
          at = 0, add = FALSE, axis = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linestack_+3A_x">x</code></td>
<td>
<p>Numeric vector to be plotted. </p>
</td></tr>
<tr><td><code id="linestack_+3A_labels">labels</code></td>
<td>
<p>Labels used instead of default (names of <code>x</code>). May
be expressions to be drawn with <code><a href="grDevices.html#topic+plotmath">plotmath</a></code>.</p>
</td></tr>
<tr><td><code id="linestack_+3A_cex">cex</code></td>
<td>
<p>Size of the labels. </p>
</td></tr>
<tr><td><code id="linestack_+3A_side">side</code></td>
<td>
<p>Put labels to the <code>"right"</code> or <code>"left"</code> of the
axis.</p>
</td></tr>
<tr><td><code id="linestack_+3A_hoff">hoff</code></td>
<td>
<p>Distance from the vertical axis to the label in units of
the width of letter &ldquo;m&rdquo;. </p>
</td></tr>
<tr><td><code id="linestack_+3A_air">air</code></td>
<td>
<p>Multiplier to string height to leave empty space between
labels.</p>
</td></tr>
<tr><td><code id="linestack_+3A_at">at</code></td>
<td>
<p>Position of plot in horizontal axis. </p>
</td></tr>
<tr><td><code id="linestack_+3A_add">add</code></td>
<td>
<p>Add to an existing plot. </p>
</td></tr>
<tr><td><code id="linestack_+3A_axis">axis</code></td>
<td>
<p>Add axis to the plot. </p>
</td></tr>
<tr><td><code id="linestack_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns invisibly the shifted positions of labels in
user coordinates.
</p>


<h3>Note</h3>

<p> The function always draws labelled diagrams.  If you want to have
unlabelled diagrams, you can use, e.g., <code><a href="graphics.html#topic+plot">plot</a></code>,
<code><a href="graphics.html#topic+stripchart">stripchart</a></code> or <code><a href="graphics.html#topic+rug">rug</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen with modifications by Gavin L. Simpson</p>


<h3>Examples</h3>

<pre><code class='language-R'>## First DCA axis
data(dune)
ord &lt;- decorana(dune)
linestack(scores(ord, choices=1, display="sp"))
linestack(scores(ord, choices=1, display="si"), side="left", add=TRUE)
title(main="DCA axis 1")

## Expressions as labels
N &lt;- 10					# Number of sites
df &lt;- data.frame(Ca = rlnorm(N, 2), NO3 = rlnorm(N, 4),
                 SO4 = rlnorm(N, 10), K = rlnorm(N, 3))
ord &lt;- rda(df, scale = TRUE)
### vector of expressions for labels
labs &lt;- expression(Ca^{2+phantom()},
                   NO[3]^{-phantom()},
                   SO[4]^{2-phantom()},
                   K^{+phantom()})
scl &lt;- "sites"
linestack(scores(ord, choices = 1, display = "species", scaling = scl),
          labels = labs, air = 2)
linestack(scores(ord, choices = 1, display = "site", scaling = scl),
          side = "left", add = TRUE)
title(main = "PCA axis 1")
</code></pre>

<hr>
<h2 id='make.cepnames'>Abbreviates a Botanical or Zoological Latin Name into an Eight-character Name</h2><span id='topic+make.cepnames'></span>

<h3>Description</h3>

<p>A standard CEP name has four first letters of the generic name and
four first letters of the specific epithet of a Latin name. The last
epithet, that may be a subspecific name, is used in the current
function. If the name has only one component, it is abbreviated to
eight characters (see <code><a href="base.html#topic+abbreviate">abbreviate</a></code>).
The returned names are made unique with function
<code><a href="base.html#topic+make.unique">make.unique</a></code> which adds numbers to the end of CEP names if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.cepnames(names, seconditem = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.cepnames_+3A_names">names</code></td>
<td>
<p>The names to be formatted into CEP names. </p>
</td></tr>
<tr><td><code id="make.cepnames_+3A_seconditem">seconditem</code></td>
<td>
<p>Take always the second item of the original name
to the abbreviated name instead of the last original item
(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Cornell Ecology Programs (CEP) used eight-letter
abbreviations for species and site names. In species, the names were
formed by taking four first letters of the generic name and four
first letters of the specific or subspecific epithet. The current
function first makes valid <span class="rlang"><b>R</b></span> names using <code><a href="base.html#topic+make.names">make.names</a></code>,
and then splits these into elements. The CEP name is made by taking
the four first letters of the first element, and four first letters
of the last (default) or the second element (with 
<code>seconditem = TRUE</code>). If there was only one name element, it is
<code><a href="base.html#topic+abbreviate">abbreviate</a></code>d to eight letters. Finally, the names are
made unique which may add numbers to duplicated names.
</p>
<p>The CEP names were originally used, because old <code>FORTRAN IV</code>
did not have <code>CHARACTER</code> data type, but text had to be stored
in numerical variables, which in popular computers could hold four
characters. In modern times, there is no reason for this limitation,
but ecologists are used to these names, and they may be practical to
avoid congestion in ordination plots.  
</p>


<h3>Value</h3>

<p>Function returns CEP names.
</p>


<h3>Note</h3>

<p>The function is simpleminded and rigid. You must write a better one if
you need.  
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+make.names">make.names</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>,
<code><a href="base.html#topic+substring">substring</a></code>, <code><a href="base.html#topic+paste">paste</a></code>, <code><a href="base.html#topic+abbreviate">abbreviate</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>make.cepnames(c("Aa maderoi", "Poa sp.", "Cladina rangiferina",
"Cladonia cornuta", "Cladonia cornuta var. groenlandica",
"Cladonia rangiformis", "Bryoerythrophyllum"))
data(BCI)
colnames(BCI) &lt;- make.cepnames(colnames(BCI))
</code></pre>

<hr>
<h2 id='mantel'>Mantel and Partial Mantel Tests for Dissimilarity Matrices </h2><span id='topic+mantel'></span><span id='topic+mantel.partial'></span>

<h3>Description</h3>

<p>Function <code>mantel</code>  finds the Mantel statistic as a matrix
correlation between two dissimilarity matrices, and function
<code>mantel.partial</code> finds the partial Mantel statistic as the
partial matrix correlation between three dissimilarity matrices.  The
significance of the statistic is evaluated by permuting rows and
columns of the first dissimilarity matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mantel(xdis, ydis, method="pearson", permutations=999, strata = NULL,
    na.rm = FALSE, parallel = getOption("mc.cores"))
mantel.partial(xdis, ydis, zdis, method = "pearson", permutations = 999, 
    strata = NULL, na.rm = FALSE, parallel = getOption("mc.cores"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mantel_+3A_xdis">xdis</code>, <code id="mantel_+3A_ydis">ydis</code>, <code id="mantel_+3A_zdis">zdis</code></td>
<td>
<p> Dissimilarity matrices or<code>dist</code>
objects. The first object <code>xdis</code> will be permuted in
permutation tests. </p>
</td></tr>
<tr><td><code id="mantel_+3A_method">method</code></td>
<td>
<p> Correlation method, as accepted by <code><a href="stats.html#topic+cor">cor</a></code>:
<code>"pearson"</code>, <code>"spearman"</code> or <code>"kendall"</code>. </p>
</td></tr>
<tr><td><code id="mantel_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="mantel_+3A_strata">strata</code></td>
<td>
<p>An integer vector or factor specifying the strata for
permutation. If supplied, observations are permuted only within the
specified strata.</p>
</td></tr>
<tr><td><code id="mantel_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove missing values in calculation of Mantel
correlation. Use this option with care: Permutation tests can
be biased, in particular if two matrices had missing values in
matching positions.</p>
</td></tr>
<tr><td><code id="mantel_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mantel statistic is simply a correlation between entries of two
dissimilarity matrices (some use cross products, but these are
linearly related).  However, the significance cannot be directly
assessed, because there are <code class="reqn">N(N-1)/2</code> entries for just <code class="reqn">N</code>
observations.  Mantel developed asymptotic test, but here we use
permutations of <code class="reqn">N</code> rows and columns of dissimilarity
matrix. Only the first matrix (<code>xdist</code>) will be permuted, and
the second is kept constant. See <code><a href="#topic+permutations">permutations</a></code> for
additional details on permutation tests in Vegan.
</p>
<p>Partial Mantel statistic uses partial correlation
conditioned on the third matrix. Only the first matrix is permuted so
that the correlation structure between second and first matrices is
kept constant. Although <code>mantel.partial</code> silently accepts other
methods than <code>"pearson"</code>, partial correlations will probably be
wrong with other methods.
</p>
<p>The function uses <code><a href="stats.html#topic+cor">cor</a></code>, which should accept
alternatives <code>pearson</code> for product moment correlations and
<code>spearman</code> or <code>kendall</code> for rank correlations.
</p>


<h3>Value</h3>

<p>The function returns a list of class <code>mantel</code> with following
components: 
</p>
<table>
<tr><td><code>Call</code></td>
<td>
<p>Function call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Correlation method used, as returned by
<code><a href="stats.html#topic+cor.test">cor.test</a></code>.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>The Mantel statistic.</p>
</td></tr>
<tr><td><code>signif</code></td>
<td>
<p>Empirical significance level from permutations.</p>
</td></tr>
<tr><td><code>perm</code></td>
<td>
<p>A vector of permuted values. The distribution of
permuted values can be inspected with <code><a href="#topic+permustats">permustats</a></code> 
function.</p>
</td></tr>
<tr><td><code>permutations</code></td>
<td>
<p>Number of permutations.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>A list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Legendre &amp; Legendre (2012, Box 10.4) warn against using partial
Mantel correlations.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>References</h3>

<p> The test is due to Mantel, of course, but the
current implementation is based on Legendre and Legendre.
</p>
<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd English
Edition. Elsevier.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code> for correlation coefficients,
<code><a href="#topic+protest">protest</a></code> (Procrustes test) for an alternative with
ordination diagrams, <code><a href="#topic+anosim">anosim</a></code>  and <code><a href="#topic+mrpp">mrpp</a></code>
for comparing dissimilarities against 
classification.  For dissimilarity matrices, see <code><a href="#topic+vegdist">vegdist</a></code>
or <code><a href="stats.html#topic+dist">dist</a></code>.  See <code><a href="#topic+bioenv">bioenv</a></code> for selecting
environmental variables. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Is vegetation related to environment?
data(varespec)
data(varechem)
veg.dist &lt;- vegdist(varespec) # Bray-Curtis
env.dist &lt;- vegdist(scale(varechem), "euclid")
mantel(veg.dist, env.dist)
mantel(veg.dist, env.dist, method="spear")
</code></pre>

<hr>
<h2 id='mantel.correlog'> Mantel Correlogram </h2><span id='topic+mantel.correlog'></span><span id='topic+plot.mantel.correlog'></span>

<h3>Description</h3>

<p>Function <code>mantel.correlog</code> computes a multivariate
Mantel correlogram. Proposed by Sokal (1986) and Oden and Sokal
(1986), the method is also described in Legendre and Legendre (2012,
pp. 819&ndash;821).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mantel.correlog(D.eco, D.geo=NULL, XY=NULL, n.class=0, break.pts=NULL, 
cutoff=TRUE, r.type="pearson", nperm=999, mult="holm", progressive=TRUE)
## S3 method for class 'mantel.correlog'
plot(x, alpha=0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mantel.correlog_+3A_d.eco">D.eco</code></td>
<td>
<p> An ecological distance matrix, with class
either <code>dist</code> or <code>matrix</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_d.geo">D.geo</code></td>
<td>
<p> A geographic distance matrix, with class either
<code>dist</code> or <code>matrix</code>. Provide either <code>D.geo</code> or
<code>XY</code>. Default: <code>D.geo=NULL</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_xy">XY</code></td>
<td>
<p> A file of Cartesian geographic coordinates of the
points. Default: <code>XY=NULL</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_n.class">n.class</code></td>
<td>
<p> Number of classes. If <code>n.class=0</code>, the Sturges
equation will be used unless break points are provided. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_break.pts">break.pts</code></td>
<td>
<p> Vector containing the break points of the distance
distribution. Provide (n.class+1) breakpoints, that is, a list with
a beginning and an ending point. Default: <code>break.pts=NULL</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_cutoff">cutoff</code></td>
<td>
<p> For the second half of the distance classes,
<code>cutoff = TRUE</code> limits the correlogram to the distance classes
that include all points. If <code>cutoff = FALSE</code>, the correlogram
includes all distance classes. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_r.type">r.type</code></td>
<td>
<p> Type of correlation in calculation of the Mantel
statistic. Default: <code>r.type="pearson"</code>.  Other choices are
<code>r.type="spearman"</code> and <code>r.type="kendall"</code>, as in functions
<code><a href="stats.html#topic+cor">cor</a></code> and <code><a href="#topic+mantel">mantel</a></code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_nperm">nperm</code></td>
<td>
<p> Number of permutations for the tests of
significance. Default: <code>nperm=999</code>. For large data files,
permutation tests are rather slow. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_mult">mult</code></td>
<td>
<p> Correct P-values for multiple testing. The correction
methods are <code>"holm"</code> (default), <code>"hochberg"</code>,
<code>"sidak"</code>, and other methods available in the
<code><a href="stats.html#topic+p.adjust">p.adjust</a></code> function: <code>"bonferroni"</code> (best known, but
not recommended because it is overly conservative), <code>"hommel"</code>,
<code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>, and <code>"none"</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_progressive">progressive</code></td>
<td>
<p> Default: <code>progressive=TRUE</code> for progressive
correction of multiple-testing, as described in Legendre and Legendre
(1998, p. 721). Test of the first distance class: no correction;
second distance class: correct for 2 simultaneous tests; distance
class k: correct for k simultaneous tests. <code>progressive=FALSE</code>:
correct all tests for <code>n.class</code> simultaneous tests. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_x">x</code></td>
<td>
<p> Output of <code>mantel.correlog</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_alpha">alpha</code></td>
<td>
<p> Significance level for the points drawn with black
symbols in the correlogram. Default: <code>alpha=0.05</code>. </p>
</td></tr>
<tr><td><code id="mantel.correlog_+3A_...">...</code></td>
<td>
<p> Other parameters passed from other functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p> A correlogram is a graph in which spatial correlation values
are plotted, on the ordinate, as a function of the geographic distance
classes among the study sites along the abscissa. In a Mantel
correlogram, a Mantel correlation (Mantel 1967) is computed between a
multivariate (e.g. multi-species) distance matrix of the user's choice
and a design matrix representing each of the geographic distance
classes in turn. The Mantel statistic is tested through a
permutational Mantel test performed by <code>vegan</code>'s
<code><a href="#topic+mantel">mantel</a></code> function.
</p>
<p>When a correction for multiple testing is applied, more permutations
are necessary than in the no-correction case, to obtain significant
p-values in the higher correlogram classes.
</p>
<p>The <code>print.mantel.correlog</code> function prints out the
correlogram. See examples.  </p>


<h3>Value</h3>

 
<table>
<tr><td><code>mantel.res</code></td>
<td>
<p>A table with the distance classes as rows and the
class indices, number of distances per class, Mantel statistics
(computed using Pearson's r, Spearman's r, or Kendall's tau), and
p-values as columns. A positive Mantel statistic indicates positive
spatial correlation. An additional column with p-values corrected for
multiple testing is added unless <code>mult="none"</code>. </p>
</td></tr>
<tr><td><code>n.class</code></td>
<td>
<p>The n umber of distance classes. </p>
</td></tr>
<tr><td><code>break.pts</code></td>
<td>
<p>The break points provided by the user or computed by
the program. </p>
</td></tr>
<tr><td><code>mult</code></td>
<td>
<p>The name of the correction for multiple testing. No
correction: <code>mult="none"</code>. </p>
</td></tr>  
<tr><td><code>progressive</code></td>
<td>
<p>A logical (<code>TRUE</code>, <code>FALSE</code>) value
indicating whether or not a progressive correction for multiple
testing was requested. </p>
</td></tr> 
<tr><td><code>n.tests</code></td>
<td>
<p>The number of distance classes for which Mantel
tests have been computed and tested for significance. </p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call. </p>
</td></tr>  
</table>


<h3>Author(s)</h3>

<p> Pierre Legendre, Universit√© de Montr√©al </p>


<h3>References</h3>

<p>Legendre, P. and L. Legendre. 2012. Numerical ecology, 3rd English
edition. Elsevier Science BV, Amsterdam.
</p>
<p>Mantel, N. 1967. The detection of disease clustering and a generalized
regression approach. Cancer Res. 27: 209-220.
</p>
<p>Oden, N. L. and R. R. Sokal. 1986. Directional autocorrelation: an
extension of spatial correlograms to two dimensions. Syst. Zool. 35:
608-617.
</p>
<p>Sokal, R. R. 1986. Spatial data analysis and historical
processes. 29-43 in: E. Diday et al. [eds.] Data analysis and
informatics, IV. North-Holland, Amsterdam.
</p>
<p>Sturges, H. A. 1926. The choice of a class interval. Journal of the 
American Statistical Association 21: 65‚Äì66.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>   
# Mite data available in "vegan"
data(mite)        
data(mite.xy)  
mite.hel &lt;- decostand(mite, "hellinger")

# Detrend the species data by regression on the site coordinates
mite.hel.resid &lt;- resid(lm(as.matrix(mite.hel) ~ ., data=mite.xy))

# Compute the detrended species distance matrix
mite.hel.D &lt;- dist(mite.hel.resid)

# Compute Mantel correlogram with cutoff, Pearson statistic
mite.correlog &lt;- mantel.correlog(mite.hel.D, XY=mite.xy, nperm=49)
summary(mite.correlog)
mite.correlog   
# or: print(mite.correlog)
# or: print.mantel.correlog(mite.correlog)
plot(mite.correlog)

# Compute Mantel correlogram without cutoff, Spearman statistic
mite.correlog2 &lt;- mantel.correlog(mite.hel.D, XY=mite.xy, cutoff=FALSE, 
   r.type="spearman", nperm=49)
summary(mite.correlog2)
mite.correlog2
plot(mite.correlog2)

# NOTE: 'nperm' argument usually needs to be larger than 49.
# It was set to this low value for demonstration purposes.

</code></pre>

<hr>
<h2 id='MDSrotate'>
Rotate First MDS Dimension Parallel to an External Variable
</h2><span id='topic+MDSrotate'></span>

<h3>Description</h3>

<p> Function rotates a multidimensional scaling result so
that its first dimension is parallel to an external (environmental
variable). The function can handle the results from
<code><a href="#topic+metaMDS">metaMDS</a></code> or <code><a href="#topic+monoMDS">monoMDS</a></code> functions.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>MDSrotate(object, vec, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MDSrotate_+3A_object">object</code></td>
<td>
<p> A result object from <code><a href="#topic+metaMDS">metaMDS</a></code> or
<code><a href="#topic+monoMDS">monoMDS</a></code>.</p>
</td></tr>
<tr><td><code id="MDSrotate_+3A_vec">vec</code></td>
<td>
<p>An environmental variable or a matrix of such
variables. The number of variables must be lower than the number
of dimensions, and the solution is rotated to these variables in
the order they appear in the matrix. Alternatively <code>vec</code> can
be a factor, and the solution is rotated to optimal separation of
factor levels using <code><a href="MASS.html#topic+lda">lda</a></code>.</p>
</td></tr>
<tr><td><code id="MDSrotate_+3A_na.rm">na.rm</code></td>
<td>
<p> Remove missing values from the continuous variable
<code>vec</code>.</p>
</td></tr>
<tr><td><code id="MDSrotate_+3A_...">...</code></td>
<td>
<p> Other arguments (ignored). </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The orientation and rotation are undefined in multidimensional
scaling.  Functions <code><a href="#topic+metaMDS">metaMDS</a></code> and <code><a href="#topic+metaMDS">metaMDS</a></code>
can rotate their solutions to principal components so that the
dispersion of the points is highest on the first dimension. Sometimes
a different rotation is more intuitive, and <code>MDSrotate</code> allows
rotation of the result so that the first axis is parallel to a given
external variable or two first variables are completely in a
two-dimensional plane etc. If several external variables are supplied,
they are applied in the order they are in the matrix. First axis is
rotated to the first supplied variable, and the second axis to the
second variable. Because variables are usually correlated, the second
variable is not usually aligned with the second axis, but it is
uncorrelated to later dimensions. There must be at least one free
dimension: the number of external variables must be lower than the
number of dimensions, and all used environmental variables are
uncorrelated with that free dimension.
</p>
<p>Alternatively the method can rotate to discriminate the levels of a
factor using linear discriminant analysis
(<code><a href="MASS.html#topic+lda">lda</a></code>). This is hardly meaningful for
two-dimensional solutions, since all rotations in two dimensions
have the same separation of cluster levels. However, the function
can be useful in finding a two-dimensional projection of clusters
from more than two dimensions. The last dimension will always show
the residual variation, and for <code class="reqn">k</code> dimensions, only <code class="reqn">k-1</code>
discrimination vectors are used.
</p>


<h3>Value</h3>

<p> Function returns the original ordination result, but with
rotated scores (both site and species if available), and the
<code>pc</code> attribute of scores set to <code>FALSE</code>.  
</p>


<h3>Note</h3>

<p>Rotation to a factor variable is an experimental feature and may
be removed. The discriminant analysis weights dimensions by their
discriminating power, but <code>MDSrotate</code> performs a rigid
rotation. Therefore the solution may not be optimal.</p>


<h3>Author(s)</h3>

<p>Jari Oksanen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+metaMDS">metaMDS</a></code>, <code><a href="#topic+monoMDS">monoMDS</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
mod &lt;- monoMDS(vegdist(varespec))
mod &lt;- with(varechem, MDSrotate(mod, pH))
plot(mod)
ef &lt;- envfit(mod ~ pH, varechem, permutations = 0)
plot(ef)
ordisurf(mod ~ pH, varechem, knots = 1, add = TRUE)
</code></pre>

<hr>
<h2 id='metaMDS'>Nonmetric Multidimensional Scaling with Stable Solution from
Random Starts, Axis Scaling and Species Scores</h2><span id='topic+metaMDS'></span><span id='topic+metaMDSdist'></span><span id='topic+metaMDSiter'></span><span id='topic+metaMDSredist'></span><span id='topic+initMDS'></span><span id='topic+postMDS'></span><span id='topic+plot.metaMDS'></span><span id='topic+points.metaMDS'></span><span id='topic+text.metaMDS'></span><span id='topic+scores.metaMDS'></span>

<h3>Description</h3>

<p>Function <code>metaMDS</code> performs Nonmetric
Multidimensional Scaling (NMDS), and tries to find a stable solution
using several random starts. In addition, it standardizes the
scaling in the result, so that the configurations are easier to
interpret, and adds species scores to the site ordination. The
<code>metaMDS</code> function does not provide actual NMDS, but it calls
another function for the purpose. Currently <code><a href="#topic+monoMDS">monoMDS</a></code> is
the default choice, and it is also possible to call the
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> (<span class="pkg">MASS</span> package). </p>


<h3>Usage</h3>

<pre><code class='language-R'>metaMDS(comm, distance = "bray", k = 2, try = 20, trymax = 20, 
    engine = c("monoMDS", "isoMDS"), autotransform =TRUE,
    noshare = (engine == "isoMDS"), wascores = TRUE, expand = TRUE, 
    trace = 1, plot = FALSE, previous.best,  ...)
## S3 method for class 'metaMDS'
plot(x, display = c("sites", "species"), choices = c(1, 2),
    type = "p", shrink = FALSE, ...)
## S3 method for class 'metaMDS'
points(x, display = c("sites", "species"),
    choices = c(1,2), shrink = FALSE, select, ...)
## S3 method for class 'metaMDS'
text(x, display = c("sites", "species"), labels, 
    choices = c(1,2), shrink = FALSE, select, ...)
## S3 method for class 'metaMDS'
scores(x, display = c("sites", "species"), shrink = FALSE, 
    choices, tidy = FALSE, ...)
metaMDSdist(comm, distance = "bray", autotransform = TRUE, 
    noshare = TRUE, trace = 1, commname, zerodist = "ignore", 
    distfun = vegdist, ...)
metaMDSiter(dist, k = 2, try = 20, trymax = 20, trace = 1, plot = FALSE, 
    previous.best, engine = "monoMDS", maxit = 200,
    parallel = getOption("mc.cores"), ...)   
initMDS(x, k=2)
postMDS(X, dist, pc=TRUE, center=TRUE, halfchange, threshold=0.8,
    nthreshold=10, plot=FALSE, ...)
metaMDSredist(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metaMDS_+3A_comm">comm</code></td>
<td>
<p>Community data. Alternatively, dissimilarities either as
a <code><a href="stats.html#topic+dist">dist</a></code> structure or as a symmetric square matrix. 
In the latter case all other stages are skipped except random 
starts and centring and pc rotation of axes. </p>
</td></tr>
<tr><td><code id="metaMDS_+3A_distance">distance</code></td>
<td>
<p>Dissimilarity index used in <code><a href="#topic+vegdist">vegdist</a></code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_k">k</code></td>
<td>
<p>Number of dimensions.  NB., the number of points <code class="reqn">n</code>
should be <code class="reqn">n &gt; 2k + 1</code>, and preferably higher in
global non-metric MDS, and still higher in local NMDS.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_try">try</code>, <code id="metaMDS_+3A_trymax">trymax</code></td>
<td>
<p>Minimum and maximum numbers of random starts in
search of stable solution. After <code>try</code> has been reached, the
iteration will stop when similar solutions were repeated or
<code>trymax</code> was reached.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_engine">engine</code></td>
<td>
<p>The function used for MDS. The default is to use the
<code><a href="#topic+monoMDS">monoMDS</a></code> function in <span class="pkg">vegan</span>, but for backward
compatibility it is also possible to use <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> of
<span class="pkg">MASS</span>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_autotransform">autotransform</code></td>
<td>
<p>Use simple heuristics for possible data
transformation of typical community data (see below). If you do
not have community data, you should probably set
<code>autotransform = FALSE</code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_noshare">noshare</code></td>
<td>
<p>Triggering of calculation step-across or extended
dissimilarities with function <code><a href="#topic+stepacross">stepacross</a></code>. The
argument can be logical or a numerical value greater than zero
and less than one. If <code>TRUE</code>, extended dissimilarities are
used always when there are no shared species between some sites,
if <code>FALSE</code>, they are never used. If <code>noshare</code> is a
numerical value, <code><a href="#topic+stepacross">stepacross</a></code> is used when the
proportion of site pairs with no shared species exceeds
<code>noshare</code>. The number of pairs with no shared species is
found with <code><a href="#topic+no.shared">no.shared</a></code> function, and <code>noshare</code>
has no effect if input data were dissimilarities instead of
community data.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_wascores">wascores</code></td>
<td>
<p>Calculate species scores using function
<code><a href="#topic+wascores">wascores</a></code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_expand">expand</code></td>
<td>
<p>Expand weighted averages of species in
<code><a href="#topic+wascores">wascores</a></code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_trace">trace</code></td>
<td>
<p>Trace the function; <code>trace = 2</code> or higher will be
more voluminous.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_plot">plot</code></td>
<td>
<p>Graphical tracing: plot interim results. You may want to set
<code>par(ask = TRUE)</code> with this option.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_previous.best">previous.best</code></td>
<td>
<p>Start searches from a previous solution.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_x">x</code></td>
<td>
<p><code>metaMDS</code> result (or a dissimilarity structure for
<code>initMDS</code>).</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_choices">choices</code></td>
<td>
<p>Axes shown.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_type">type</code></td>
<td>
<p>Plot type: <code>"p"</code> for points, <code>"t"</code> for text, and
<code>"n"</code> for axes only.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_display">display</code></td>
<td>
<p>Display <code>"sites"</code> or <code>"species"</code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_shrink">shrink</code></td>
<td>
<p>Shrink back species scores if they were expanded
originally.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_tidy">tidy</code></td>
<td>
<p>Return scores that are compatible with <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>:
all scores are in a single <code>data.frame</code>, score type is
identified by factor variable <code>code</code> (<code>"sites"</code> or
<code>"species"</code>), the names by variable <code>label</code>. These scores
are incompatible with conventional <code>plot</code> functions, but they can
be used in <span class="pkg">ggplot2</span>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_labels">labels</code></td>
<td>
<p>Optional test to be used instead of row names.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of indices
of displayed items.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_x">X</code></td>
<td>
<p>Configuration from multidimensional scaling. </p>
</td></tr>
<tr><td><code id="metaMDS_+3A_commname">commname</code></td>
<td>
<p>The name of <code>comm</code>: should not be given if the
function is called directly.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_zerodist">zerodist</code></td>
<td>
<p>Handling of zero dissimilarities: either
<code>"fail"</code> or <code>"add"</code> a small positive value, or
<code>"ignore"</code>. <code><a href="#topic+monoMDS">monoMDS</a></code> accepts zero dissimilarities
and the default is <code>zerodist = "ignore"</code>, but with
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> you may need to set <code>zerodist = "add"</code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_distfun">distfun</code></td>
<td>
<p>Dissimilarity function. Any function returning a
<code>dist</code> object and accepting argument <code>method</code> can be used
(but some extra arguments may cause name conflicts).</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations in the single NMDS run;
passed to the <code>engine</code> function <code><a href="#topic+monoMDS">monoMDS</a></code> or
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  If you use pre-defined socket clusters (say,
<code>clus</code>), you must issue <code>clusterEvalQ(clus,
   library(vegan))</code> to make available internal <span class="pkg">vegan</span>
functions. With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_dist">dist</code></td>
<td>
<p>Dissimilarity matrix used in multidimensional scaling. </p>
</td></tr>
<tr><td><code id="metaMDS_+3A_pc">pc</code></td>
<td>
<p>Rotate to principal components. </p>
</td></tr>
<tr><td><code id="metaMDS_+3A_center">center</code></td>
<td>
<p>Centre the configuration. </p>
</td></tr>
<tr><td><code id="metaMDS_+3A_halfchange">halfchange</code></td>
<td>
<p>Scale axes to half-change units. This defaults
<code>TRUE</code> when dissimilarities are known to have a theoretical
maximum value (ceiling). Function <code>vegdist</code> will have that
information in attribute <code>maxdist</code>, and for other <code>distfun</code>
this is interpreted in a simple test (that can fail), and the
information may not available when input data are distances. If
<code>FALSE</code>, the ordination dissimilarities are scaled to the same
range as the input dissimilarities.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_threshold">threshold</code></td>
<td>
<p>Largest dissimilarity used in half-change scaling. If
dissimilarities have a known (or inferred) ceiling, <code>threshold</code>
is relative to that ceiling (see <code>halfchange</code>).</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_nthreshold">nthreshold</code></td>
<td>
<p> Minimum number of points in half-change scaling. </p>
</td></tr>
<tr><td><code id="metaMDS_+3A_object">object</code></td>
<td>
<p>A result object from <code>metaMDS</code>.</p>
</td></tr>
<tr><td><code id="metaMDS_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions. Function
<code>metaMDS</code> passes all arguments to its component functions
<code>metaMDSdist</code>, <code>metaMDSiter</code>, <code>postMDS</code>, and to
<code>distfun</code> and <code>engine</code>.</p>
</td></tr>  </table>


<h3>Details</h3>

<p> Non-metric Multidimensional Scaling (NMDS) is commonly
regarded as the most robust unconstrained ordination method in
community ecology (Minchin 1987).  Function <code>metaMDS</code> is a
wrapper function that calls several other functions to combine
Minchin's (1987) recommendations into one command. The complete
steps in <code>metaMDS</code> are:
</p>
 
<ol>
<li><p> Transformation: If the data values are larger than common
abundance class scales, the function performs a Wisconsin double
standardization (<code><a href="#topic+wisconsin">wisconsin</a></code>).  If the values look
very large, the function also performs <code><a href="base.html#topic+sqrt">sqrt</a></code>
transformation. Both of these standardizations are generally found
to improve the results. However, the limits are completely
arbitrary (at present, data maximum 50 triggers <code><a href="base.html#topic+sqrt">sqrt</a></code>
and <code class="reqn">&gt;9</code> triggers <code><a href="#topic+wisconsin">wisconsin</a></code>). If you want to
have a full control of the analysis, you should set
<code>autotransform = FALSE</code> and standardize and transform data
independently. The <code>autotransform</code> is intended for community
data, and for other data types, you should set
<code>autotransform = FALSE</code>. This step is perfomed using
<code>metaMDSdist</code>, and the step is skipped if input were
dissimilarities.
</p>
</li>
<li><p> Choice of dissimilarity: For a good result, you should use
dissimilarity indices that have a good rank order relation to
ordering sites along gradients (Faith et al. 1987).  The default
is Bray-Curtis dissimilarity, because it often is the test
winner. However, any other dissimilarity index in
<code><a href="#topic+vegdist">vegdist</a></code> can be used. Function
<code><a href="#topic+rankindex">rankindex</a></code> can be used for finding the test winner
for you data and gradients. The default choice may be bad if you
analyse other than community data, and you should probably select
an appropriate index using argument <code>distance</code>.  This step is
performed using <code>metaMDSdist</code>, and the step is skipped if
input were dissimilarities.
</p>
</li>
<li><p> Step-across dissimilarities: Ordination may be very difficult
if a large proportion of sites have no shared species. In this
case, the results may be improved with <code><a href="#topic+stepacross">stepacross</a></code>
dissimilarities, or flexible shortest paths among all sites.  The
default NMDS <code>engine</code> is <code><a href="#topic+monoMDS">monoMDS</a></code> which is able
to break tied values at the maximum dissimilarity, and this often
is sufficient to handle cases with no shared species, and
therefore the default is not to use <code><a href="#topic+stepacross">stepacross</a></code> with
<code><a href="#topic+monoMDS">monoMDS</a></code>.  Function <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> does
not handle tied values adequately, and therefore the default is to
use <code><a href="#topic+stepacross">stepacross</a></code> always when there are sites with no
shared species with <code>engine = "isoMDS"</code>. The
<code><a href="#topic+stepacross">stepacross</a></code> is triggered by option <code>noshare</code>. If
you do not like manipulation of original distances, you should set
<code>noshare = FALSE</code>.  This step is skipped if input data were
dissimilarities instead of community data. This step is performed
using <code>metaMDSdist</code>, and the step is skipped always when
input were dissimilarities.
</p>
</li>
<li><p> NMDS with random starts: NMDS easily gets trapped into local
optima, and you must start NMDS several times from random starts
to be confident that you have found the global solution. The
strategy in <code>metaMDS</code> is to first run NMDS starting with the
metric scaling (<code><a href="stats.html#topic+cmdscale">cmdscale</a></code> which usually finds a good
solution but often close to a local optimum), or use the
<code>previous.best</code> solution if supplied, and take its solution
as the standard (<code>Run 0</code>). Then <code>metaMDS</code> starts NMDS
from several random starts (minimum number is given by <code>try</code>
and maximum number by <code>trymax</code>). These random starts are
generated by <code>initMDS</code>. If a solution is better (has a lower
stress) than the previous standard, it is taken as the new
standard. If the solution is better or close to a standard,
<code>metaMDS</code> compares two solutions using Procrustes analysis
(function <code><a href="#topic+procrustes">procrustes</a></code> with option
<code>symmetric = TRUE</code>). If the solutions are very similar in their
Procrustes <code>rmse</code> and the largest residual is very small, the
solutions are regarded as repeated and the better one is taken
as the new standard.  The conditions are stringent, and you may
have found good and relatively similar solutions although the
function is not yet satisfied. Setting <code>trace = TRUE</code> will
monitor the final stresses, and <code>plot = TRUE</code> will display
Procrustes overlay plots from each comparison. This step is
performed using <code>metaMDSiter</code>. This is the first step
performed if input data (<code>comm</code>) were dissimilarities. Random
starts can be run with parallel processing (argument
<code>parallel</code>).
</p>
</li>
<li><p> Scaling of the results: <code>metaMDS</code> will run <code>postMDS</code>
for the final result. Function <code>postMDS</code> provides the
following ways of &ldquo;fixing&rdquo; the indeterminacy of scaling and
orientation of axes in NMDS: Centring moves the origin to the
average of the axes; Principal components rotate the configuration
so that the variance of points is maximized on first dimension
(with function <code><a href="#topic+MDSrotate">MDSrotate</a></code> you can alternatively
rotate the configuration so that the first axis is parallel to an
environmental variable); Half-change scaling scales the
configuration so that one unit means halving of community
similarity from replicate similarity.  Half-change scaling is
based on closer dissimilarities where the relation between
ordination distance and community dissimilarity is rather linear
(the limit is set by argument <code>threshold</code>). If there are
enough points below this threshold (controlled by the parameter
<code>nthreshold</code>), dissimilarities are regressed on distances.
The intercept of this regression is taken as the replicate
dissimilarity, and half-change is the distance where similarity
halves according to linear regression.  Obviously the method is
applicable only for dissimilarity indices scaled to <code class="reqn">0 \ldots
    1</code>, such as Kulczynski, Bray-Curtis and Canberra indices. If
half-change scaling is not used, the ordination is scaled to the
same range as the original dissimilarities. Half-change scaling is
skipped by default if input were dissimilarities, but can be
turned on with argument <code>halfchange = TRUE</code>. NB., The PC
rotation only changes the directions of reference axes, and it
does not influence the configuration or solution in general.
</p>
</li>
<li><p> Species scores: Function adds the species scores to the final
solution as weighted averages using function
<code><a href="#topic+wascores">wascores</a></code> with given value of parameter
<code>expand</code>.  The expansion of weighted averages can be undone
with <code>shrink = TRUE</code> in <code>plot</code> or <code>scores</code>
functions, and the calculation of species scores can be suppressed
with <code>wascores = FALSE</code>. This step is skipped if input were
dissimilarities and community data were unavailable. However, the
species scores can be added or replaced with
<code><a href="#topic+sppscores">sppscores</a></code>.
</p>
</li></ol>
 


<h3>Value</h3>

<p> Function <code>metaMDS</code> returns an object of class
<code>metaMDS</code>. The final site ordination is stored in the item
<code>points</code>, and species ordination in the item <code>species</code>,
and the stress in item <code>stress</code> (NB, the scaling of the stress
depends on the <code>engine</code>: <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> uses
percents, and <code><a href="#topic+monoMDS">monoMDS</a></code> proportions in the range <code class="reqn">0
  \ldots 1</code>). The other items store the information on the steps taken
and the items returned by the <code>engine</code> function. The object has
<code>print</code>, <code>plot</code>, <code>points</code> and <code>text</code> methods.
Functions <code>metaMDSdist</code> and <code>metaMDSredist</code> return
<code><a href="#topic+vegdist">vegdist</a></code> objects.  Function <code>initMDS</code> returns a
random configuration which is intended to be used within
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> only.  Functions <code>metaMDSiter</code> and
<code>postMDS</code> returns the result of NMDS with updated
configuration.  </p>


<h3>Results Could Not Be Repeated</h3>

<p>Non-linear optimization is a hard task, and the best possible solution
(&ldquo;global optimum&rdquo;) may not be found from a random starting
configuration. Most software solve this by starting from the result of
metric scaling (<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>). This will probably give a
good result, but not necessarily the &ldquo;global
optimum&rdquo;. <span class="pkg">Vegan</span> does the same, but <code>metaMDS</code> tries to
verify or improve this first solution (&ldquo;try 0&rdquo;) using several
random starts and seeing if the result can be repeated or improved and
the improved solution repeated. If this does not succeed, you get a
message that the result could not be repeated. However, the result
will be at least as good as the usual standard strategy of starting
from metric scaling or it may be improved. You may not need to do
anything after such a message, but you can be satisfied with the
result. If you want to be sure that you probably have a &ldquo;global
optimum&rdquo; you may try the following instructions.
</p>
<p>With default <code>engine = "monoMDS"</code> the function will
tabulate the stopping criteria used, so that you can see which
criterion should be made more stringent. The criteria can be given
as arguments to <code>metaMDS</code> and their current values are
described in <code><a href="#topic+monoMDS">monoMDS</a></code>. In particular, if you reach
the maximum number of iterations, you should increase the value of
<code>maxit</code>. You may ask for a larger number of random starts
without losing the old ones giving the previous solution in
argument <code>previous.best</code>.
</p>
<p>In addition to slack convergence criteria and too low number
of random starts, wrong number of dimensions (argument <code>k</code>)
is the most common reason for not being able to repeat similar
solutions. NMDS is usually run with a low number dimensions
(<code>k=2</code> or <code>k=3</code>), and for complex data increasing
<code>k</code> by one may help. If you run NMDS with much higher number
of dimensions (say, <code>k=10</code> or more), you should reconsider
what you are doing and drastically reduce <code>k</code>. For very
heterogeneous data sets with partial disjunctions, it may help to
set <code>stepacross</code>, but for most data sets the default
<code>weakties = TRUE</code> is sufficient.
</p>
<p>Please note that you can give all arguments of other
<code>metaMDS*</code> functions and NMDS engine (default
<code><a href="#topic+monoMDS">monoMDS</a></code>) in your <code>metaMDS</code> command,and you
should check documentation of these functions for details.
</p>


<h3>Common Wrong Claims</h3>

<p>NMDS is often misunderstood and wrong claims of its properties are
common on the Web and even in publications. It is often claimed
that the NMDS configuration is non-metric which means that you
cannot fit environmental variables or species onto that
space. This is a false statement. In fact, the result
configuration of NMDS is metric, and it can be used like any other
ordination result. In NMDS the rank orders of Euclidean distances
among points in ordination have a non-metric monotone relationship
to any observed dissimilarities. The transfer function from
observed dissimilarities to ordination distances is non-metric
(Kruskal 1964a, 1964b), but the ordination result configuration is
metric and observed dissimilarities can be of any kind (metric or
non-metric).
</p>
<p>The ordination configuration is usually rotated to principal
components in <code>metaMDS</code>. The rotation is performed after
finding the result, and it only changes the direction of the
reference axes. The only important feature in the NMDS solution are
the ordination distances, and these do not change in
rotation. Similarly, the rank order of distances does not change in
uniform scaling or centring of configuration of points. You can also
rotate the NMDS solution to external environmental variables with
<code><a href="#topic+MDSrotate">MDSrotate</a></code>. This rotation will also only change the
orientation of axes, but will not change the configuration of points
or distances between points in ordination space.
</p>
<p>Function <code><a href="#topic+stressplot">stressplot</a></code> displays the method graphically:
it plots the observed dissimilarities against distances in
ordination space, and also shows the non-metric monotone
regression.
</p>


<h3>Warning</h3>

<p><code>metaMDS</code> uses <code><a href="#topic+monoMDS">monoMDS</a></code> as its
NMDS <code>engine</code> from <span class="pkg">vegan</span> version 2.0-0, when it replaced
the <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> function. You can set argument
<code>engine</code> to select the old engine.</p>


<h3>Note</h3>

<p> Function <code>metaMDS</code> is a simple wrapper for an NMDS engine
(either <code><a href="#topic+monoMDS">monoMDS</a></code> or <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>) and
some support functions (<code>metaMDSdist</code>,
<code><a href="#topic+stepacross">stepacross</a></code>, <code>metaMDSiter</code>, <code>initMDS</code>,
<code>postMDS</code>, <code><a href="#topic+wascores">wascores</a></code>).  You can call these support
functions separately for better control of results.  Data
transformation, dissimilarities and possible
<code><a href="#topic+stepacross">stepacross</a></code> are made in function <code>metaMDSdist</code>
which returns a dissimilarity result. Iterative search (with
starting values from <code>initMDS</code> with <code><a href="#topic+monoMDS">monoMDS</a></code>) is
made in <code>metaMDSiter</code>.  Processing of result configuration is
done in <code>postMDS</code>, and species scores added by
<code><a href="#topic+wascores">wascores</a></code>.  If you want to be more certain of reaching
a global solution, you can compare results from several independent
runs. You can also continue analysis from previous results or from
your own configuration.  Function may not save the used
dissimilarity matrix (<code><a href="#topic+monoMDS">monoMDS</a></code> does), but
<code>metaMDSredist</code> tries to reconstruct the used dissimilarities
with original data transformation and possible
<code><a href="#topic+stepacross">stepacross</a></code>.
</p>
<p>The <code>metaMDS</code> function was designed to be used with community
data.  If you have other type of data, you should probably set some
arguments to non-default values: probably at least <code>wascores</code>,
<code>autotransform</code> and <code>noshare</code> should be <code>FALSE</code>. If
you have negative data entries, <code>metaMDS</code> will set the previous
to <code>FALSE</code> with a warning.  
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Faith, D. P, Minchin, P. R. and Belbin, L. (1987).
Compositional dissimilarity as a robust measure of ecological
distance. <em>Vegetatio</em> 69, 57&ndash;68.
</p>
<p>Kruskal, J.B. (1964a). Multidimensional scaling by optimizing
goodness-of-fit to a nonmetric hypothesis. <em>Psychometrika</em>
29, 1&ndash;28.
</p>
<p>Kruskal, J.B. (1964b). Nonmetric multidimensional scaling: a numerical
method. <em>Psychometrika</em> 29, 115&ndash;129.
</p>
<p>Minchin, P.R. (1987). An evaluation of relative robustness
of techniques for ecological ordinations. <em>Vegetatio</em> 69,
89&ndash;107.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+monoMDS">monoMDS</a></code> (and <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>), 
<code><a href="#topic+decostand">decostand</a></code>, <code><a href="#topic+wisconsin">wisconsin</a></code>, 
<code><a href="#topic+vegdist">vegdist</a></code>, <code><a href="#topic+rankindex">rankindex</a></code>, <code><a href="#topic+stepacross">stepacross</a></code>, 
<code><a href="#topic+procrustes">procrustes</a></code>, <code><a href="#topic+wascores">wascores</a></code>, <code><a href="#topic+sppscores">sppscores</a></code>,
<code><a href="#topic+MDSrotate">MDSrotate</a></code>, <code><a href="#topic+ordiplot">ordiplot</a></code>, <code><a href="#topic+stressplot">stressplot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The recommended way of running NMDS (Minchin 1987)
##
data(dune)
## IGNORE_RDIFF_BEGIN
## Global NMDS using monoMDS
sol &lt;- metaMDS(dune)
sol
plot(sol, type="t")
## Start from previous best solution
sol &lt;- metaMDS(dune, previous.best = sol)
## Local NMDS and stress 2 of monoMDS
sol2 &lt;- metaMDS(dune, model = "local", stress=2)
sol2
## Use Arrhenius exponent 'z' as a binary dissimilarity measure
sol &lt;- metaMDS(dune, distfun = betadiver, distance = "z")
sol
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='mite'>Oribatid Mite Data with Explanatory Variables
</h2><span id='topic+mite'></span><span id='topic+mite.env'></span><span id='topic+mite.pcnm'></span><span id='topic+mite.xy'></span>

<h3>Description</h3>

<p>Oribatid mite data. 70 soil cores collected by Daniel Borcard in 1989.
See Borcard et al. (1992, 1994) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mite)
data(mite.env)
data(mite.pcnm)
data(mite.xy)
</code></pre>


<h3>Format</h3>

<p>There are three linked data sets: <code>mite</code> that contains the data
on 35 species of Oribatid mites, <code>mite.env</code> that contains
environmental data in the same sampling sites, <code>mite.xy</code>
that contains geographic coordinates,  and <code>mite.pcnm</code>
that contains 22 PCNM base functions (columns) computed from the geographic
coordinates of the 70 sampling sites (Borcard &amp; Legendre 2002).
The whole sampling area was 2.5 m x 10 m in size.
</p>
<p>The fields in the environmental data are:
</p>

<dl>
<dt>SubsDens</dt><dd><p>Substrate density (g/L)</p>
</dd>
<dt>WatrCont</dt><dd><p>Water content of the substrate (g/L)</p>
</dd>
<dt>Substrate</dt><dd><p>Substrate type, factor with levels <code>Sphagn1,
	Sphagn2 Sphagn3 Sphagn Litter Barepeat Interface</code> </p>
</dd>
<dt>Shrub</dt><dd><p>Shrub density, an ordered factor with levels <code>1</code> &lt;
<code>2</code> &lt; <code>3</code></p>
</dd>
<dt>Topo</dt><dd><p>Microtopography, a factor with levels <code>Blanket</code> and <code>Hummock</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Pierre Legendre
</p>


<h3>References</h3>

<p>Borcard, D., P. Legendre and P. Drapeau. 1992. Partialling out the
spatial component of ecological variation. Ecology 73: 1045-1055.
</p>
<p>Borcard, D. and P. Legendre. 1994. Environmental control and spatial
structure in ecological communities: an example using Oribatid mites
(Acari, Oribatei). Environmental and Ecological Statistics 1: 37-61.
</p>
<p>Borcard, D. and P. Legendre. 2002. All-scale spatial analysis of
ecological data by means of principal coordinates of neighbour
matrices. Ecological Modelling 153: 51-68.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite)
</code></pre>

<hr>
<h2 id='monoMDS'> Global and Local Non-metric Multidimensional Scaling and
Linear and Hybrid Scaling </h2><span id='topic+monoMDS'></span><span id='topic+scores.monoMDS'></span><span id='topic+plot.monoMDS'></span><span id='topic+points.monoMDS'></span><span id='topic+text.monoMDS'></span>

<h3>Description</h3>

<p> Function implements Kruskal's (1964a,b) non-metric
multidimensional scaling (NMDS) using monotone regression and
primary (&ldquo;weak&rdquo;) treatment of ties. In addition to
traditional global NMDS, the function implements local NMDS, linear
and hybrid multidimensional scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>monoMDS(dist, y, k = 2, model = c("global", "local", "linear", "hybrid"),
    threshold = 0.8, maxit = 200, weakties = TRUE, stress = 1,
    scaling = TRUE, pc = TRUE, smin = 1e-4, sfgrmin = 1e-7,
    sratmax=0.999999, ...)
## S3 method for class 'monoMDS'
scores(x, choices = NA, ...)
## S3 method for class 'monoMDS'
plot(x, choices = c(1,2), type = "t", ...)
## S3 method for class 'monoMDS'
points(x, choices = c(1,2), select, ...)
## S3 method for class 'monoMDS'
text(x, labels, choices = c(1,2), select, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="monoMDS_+3A_dist">dist</code></td>
<td>
<p>Input dissimilarities.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_y">y</code></td>
<td>
<p>Starting configuration. A random configuration will be
generated if this is missing.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_k">k</code></td>
<td>
<p>Number of dimensions. NB., the number of points <code class="reqn">n</code>
should be <code class="reqn">n &gt; 2k + 1</code>, and preferably higher in
non-metric MDS.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_model">model</code></td>
<td>
<p>MDS model: <code>"global"</code> is normal non-metric MDS
with a monotone regression, <code>"local"</code> is non-metric MDS with
separate regressions for each point, <code>"linear"</code> uses linear
regression, and <code>"hybrid"</code> uses linear regression for
dissimilarities below a threshold in addition to monotone
regression. See Details.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_threshold">threshold</code></td>
<td>
<p>Dissimilarity below which linear regression is
used alternately with monotone regression. </p>
</td></tr>
<tr><td><code id="monoMDS_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_weakties">weakties</code></td>
<td>
<p>Use primary or weak tie treatment, where equal
observed dissimilarities are allowed to have different fitted
values. if <code>FALSE</code>, then secondary (strong) tie treatment is
used, and tied values are not broken.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_stress">stress</code></td>
<td>
<p>Use stress type 1 or 2 (see Details).</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_scaling">scaling</code></td>
<td>
<p>Scale final scores to unit root mean squares.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_pc">pc</code></td>
<td>
<p>Rotate final scores to principal components.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_smin">smin</code>, <code id="monoMDS_+3A_sfgrmin">sfgrmin</code>, <code id="monoMDS_+3A_sratmax">sratmax</code></td>
<td>
<p>Convergence criteria: iterations stop
when stress drops below <code>smin</code>, scale factor of the gradient
drops below <code>sfgrmin</code>, or stress ratio between two iterations
goes over <code>sratmax</code> (but is still <code class="reqn">&lt; 1</code>).</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_x">x</code></td>
<td>
<p>A <code>monoMDS</code> result.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_choices">choices</code></td>
<td>
<p>Dimensions returned or plotted. The default <code>NA</code>
returns all dimensions. </p>
</td></tr>
<tr><td><code id="monoMDS_+3A_type">type</code></td>
<td>
<p>The type of the plot: <code>"t"</code> for text, <code>"p"</code>
for points, and <code>"n"</code> for none.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of
indices of displayed items.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_labels">labels</code></td>
<td>
<p>Labels to be use used instead of row names.</p>
</td></tr>
<tr><td><code id="monoMDS_+3A_...">...</code></td>
<td>
<p>Other parameters to the functions (ignored in
<code>monoMDS</code>, passed to graphical functions in <code>plot</code>.).</p>
</td></tr>
</table>


<h3>Details</h3>

<p> There are several versions of non-metric multidimensional
scaling in <span class="rlang"><b>R</b></span>, but <code>monoMDS</code> offers the following unique
combination of features:
</p>

<ul>
<li> <p>&ldquo;Weak&rdquo; treatment of ties (Kruskal 1964a,b), where tied
dissimilarities can be broken in monotone regression. This is
especially important for cases where compared sites share no species
and dissimilarities are tied to their maximum value of one. Breaking
ties allows these points to be at different distances and can help
in recovering very long coenoclines (gradients).  Functions in the
<a href="https://CRAN.R-project.org/package=smacof"><span class="pkg">smacof</span></a> package also hav adequate tie treatment.
</p>
</li>
<li><p> Handles missing values in a meaningful way.
</p>
</li>
<li><p> Offers &ldquo;local&rdquo; and &ldquo;hybrid&rdquo; scaling in
addition to usual &ldquo;global&rdquo; NMDS (see below).
</p>
</li>
<li><p> Uses fast compiled code (<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> of the
<span class="pkg">MASS</span> package also uses compiled code).
</p>
</li></ul>

<p>Function <code>monoMDS</code> uses Kruskal's (1964b) original monotone
regression to minimize the stress. There are two alternatives of
stress: Kruskal's (1964a,b) original or &ldquo;stress 1&rdquo; and an
alternative version or &ldquo;stress 2&rdquo; (Sibson 1972). Both of
these stresses can be expressed with a general formula
</p>
<p style="text-align: center;"><code class="reqn">s^2 = \frac{\sum (d - \hat d)^2}{\sum(d - d_0)^2}</code>
</p>

<p>where <code class="reqn">d</code> are distances among points in ordination configuration,
<code class="reqn">\hat d</code> are the fitted ordination distances, and
<code class="reqn">d_0</code> are the ordination distances under null model.  For
&ldquo;stress 1&rdquo; <code class="reqn">d_0 = 0</code>, and for &ldquo;stress 2&rdquo;
<code class="reqn">d_0 = \bar{d}</code> or mean distances. &ldquo;Stress 2&rdquo;
can be expressed as <code class="reqn">s^2 = 1 - R^2</code>,
where<code class="reqn">R^2</code> is squared correlation between fitted values and
ordination distances, and so related to the &ldquo;linear fit&rdquo; of
<code><a href="#topic+stressplot">stressplot</a></code>.
</p>
<p>Function <code>monoMDS</code> can fit several alternative NMDS variants that
can be selected with argument <code>model</code>.  The default <code>model =
  "global"</code> fits global NMDS, or Kruskal's (1964a,b) original NMDS
similar to <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> (<span class="pkg">MASS</span>).  Alternative
<code>model = "local"</code> fits local NMDS where independent monotone
regression is used for each point (Sibson 1972).  Alternative
<code>model = "linear"</code> fits a linear MDS. This fits a linear
regression instead of monotone, and is not identical to metric scaling
or principal coordinates analysis (<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>) that
performs an eigenvector decomposition of dissimilarities (Gower
1966). Alternative <code>model = "hybrid"</code> implements hybrid MDS that
uses monotone regression for all points and linear regression for
dissimilarities below or at a <code>threshold</code> dissimilarity in
alternating steps (Faith et al. 1987). Function
<code><a href="#topic+stressplot">stressplot</a></code> can be used to display the kind of regression
in each <code>model</code>.
</p>
<p>Scaling, orientation and direction of the axes is arbitrary.
However, the function always centres the axes, and the default
<code>scaling</code> is to scale the configuration of unit root mean
square and to rotate the axes (argument <code>pc</code>) to principal
components so that the first dimension shows the major variation.
It is possible to rotate the solution so that the first axis is
parallel to a given environmental variable using function
<code><a href="#topic+MDSrotate">MDSrotate</a></code>.
</p>


<h3>Value</h3>

<p> Returns an object of class <code>"monoMDS"</code>. The final scores
are returned in item <code>points</code> (function <code>scores</code> extracts
these results), and the stress in item <code>stress</code>. In addition,
there is a large number of other items (but these may change without
notice in the future releases). </p>


<h3>Convergence Criteria</h3>

<p>NMDS is iterative, and the function stops when any of its
convergence criteria is met. There is actually no criterion of
assured convergence, and any solution can be a local optimum. You
should compare several random starts (or use <code>monoMDS</code> via
<code><a href="#topic+metaMDS">metaMDS</a></code>) to assess if the solutions is likely a global
optimum.
</p>
<p>The stopping criteria are:
</p>

<dl>
<dt><code>maxit</code>:</dt><dd><p> Maximum number of iterations. Reaching this
criterion means that solutions was almost certainly not found,
and <code>maxit</code> should be increased.</p>
</dd>
<dt><code>smin</code>:</dt><dd><p> Minimum stress. If stress is nearly zero,
the fit is almost perfect. Usually this means that data set is
too small for the requested analysis, and there may be several
different solutions that are almost as perfect. You should reduce
the number of dimensions (<code>k</code>), get more data (more
observations) or use some other method, such as metric scaling
(<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, <code><a href="#topic+wcmdscale">wcmdscale</a></code>).</p>
</dd>
<dt><code>sratmax</code>:</dt><dd><p> Change in stress. Values close to one
mean almost unchanged stress. This may mean a solution, but it
can also signal stranding on suboptimal solution with flat stress
surface.</p>
</dd>
<dt><code>sfgrmin</code>:</dt><dd><p> Minimum scale factor. Values close to
zero mean almost unchanged configuration. This may mean a
solution, but will also happen in local optima.</p>
</dd>
</dl>



<h3>Note</h3>

<p> This is the default NMDS function used in
<code><a href="#topic+metaMDS">metaMDS</a></code>. Function <code><a href="#topic+metaMDS">metaMDS</a></code> adds support
functions so that NMDS can be run like recommended by Minchin
(1987).
</p>


<h3>Author(s)</h3>

<p>Peter R. Michin (Fortran core) and Jari Oksanen (R interface).
</p>


<h3>References</h3>

<p>Faith, D.P., Minchin, P.R and Belbin, L. 1987. Compositional
dissimilarity as a robust measure of ecological
distance. <em>Vegetatio</em> 69, 57&ndash;68.
</p>
<p>Gower, J.C. (1966). Some distance properties of latent root and
vector methods used in multivariate analysis. <em>Biometrika</em>
53, 325&ndash;328.
</p>
<p>Kruskal, J.B. 1964a. Multidimensional scaling by optimizing
goodness-of-fit to a nonmetric hypothesis. <em>Psychometrika</em>
29, 1&ndash;28.
</p>
<p>Kruskal, J.B. 1964b. Nonmetric multidimensional scaling: a numerical
method. <em>Psychometrika</em> 29, 115&ndash;129.
</p>
<p>Minchin, P.R. 1987. An evaluation of relative robustness of
techniques for ecological ordinations. <em>Vegetatio</em> 69,
89&ndash;107.
</p>
<p>Sibson, R. 1972. Order invariant methods for data
analysis. <em>Journal of the Royal Statistical Society B</em> 34,
311&ndash;349.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+metaMDS">metaMDS</a></code> for the <span class="pkg">vegan</span> way of running NMDS,
and <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> and <a href="https://CRAN.R-project.org/package=smacof"><span class="pkg">smacof</span></a> for some
alternative implementations of NMDS. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
dis &lt;- vegdist(dune)
m &lt;- monoMDS(dis, model = "loc")
m
plot(m)
</code></pre>

<hr>
<h2 id='MOStest'> Mitchell-Olds and Shaw Test for the Location of Quadratic Extreme </h2><span id='topic+MOStest'></span><span id='topic+plot.MOStest'></span><span id='topic+fieller.MOStest'></span><span id='topic+profile.MOStest'></span><span id='topic+confint.MOStest'></span>

<h3>Description</h3>

<p>Mitchell-Olds &amp; Shaw test concerns the location of the highest (hump)
or lowest (pit) value of a quadratic curve at given points. Typically,
it is used to study whether the quadratic hump or pit is located
within a studied interval. The current test is generalized so that it
applies generalized linear models (<code><a href="stats.html#topic+glm">glm</a></code>) with link
function instead of simple quadratic curve.  The test was popularized
in ecology for the analysis of humped species richness patterns
(Mittelbach et al. 2001), but it is more general. With logarithmic
link function, the quadratic response defines the Gaussian response
model of ecological gradients (ter Braak &amp; Looman 1986), and the test
can be used for inspecting the location of Gaussian optimum within a
given range of the gradient. It can also be used to replace Tokeshi's
test of &ldquo;bimodal&rdquo; species frequency distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MOStest(x, y, interval, ...)
## S3 method for class 'MOStest'
plot(x, which = c(1,2,3,6), ...)
fieller.MOStest(object, level = 0.95)
## S3 method for class 'MOStest'
profile(fitted, alpha = 0.01, maxsteps = 10, del = zmax/5, ...)
## S3 method for class 'MOStest'
confint(object, parm = 1, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MOStest_+3A_x">x</code></td>
<td>
<p>The independent variable or plotting object in <code>plot</code>. </p>
</td></tr>
<tr><td><code id="MOStest_+3A_y">y</code></td>
<td>
<p>The dependent variable. </p>
</td></tr>
<tr><td><code id="MOStest_+3A_interval">interval</code></td>
<td>
<p>The two points at which the test statistic is
evaluated. If missing, the extremes of <code>x</code> are used. </p>
</td></tr>
<tr><td><code id="MOStest_+3A_which">which</code></td>
<td>
<p>Subset of plots produced. Values <code>which=1</code> and
<code>2</code> define plots specific to <code>MOStest</code> (see Details), and
larger values select graphs of <code><a href="stats.html#topic+plot.lm">plot.lm</a></code> (minus 2). </p>
</td></tr>
<tr><td><code id="MOStest_+3A_object">object</code>, <code id="MOStest_+3A_fitted">fitted</code></td>
<td>
<p>A result object from <code>MOStest</code>.</p>
</td></tr>
<tr><td><code id="MOStest_+3A_level">level</code></td>
<td>
<p>The confidence level required.</p>
</td></tr>
<tr><td><code id="MOStest_+3A_alpha">alpha</code></td>
<td>
<p>Maximum significance level allowed.</p>
</td></tr>
<tr><td><code id="MOStest_+3A_maxsteps">maxsteps</code></td>
<td>
<p>Maximum number of steps in the profile.</p>
</td></tr>
<tr><td><code id="MOStest_+3A_del">del</code></td>
<td>
<p>A step length parameter for the profile (see code).</p>
</td></tr>
<tr><td><code id="MOStest_+3A_parm">parm</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="MOStest_+3A_...">...</code></td>
<td>
<p> Other variables passed to functions. Function
<code>MOStest</code> passes these to <code><a href="stats.html#topic+glm">glm</a></code> so that
these can include <code><a href="stats.html#topic+family">family</a></code>. The other functions pass
these to underlying graphical functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function fits a quadratic curve <code class="reqn">\mu = b_0 + b_1 x + b_2
  x^2</code> with given <code><a href="stats.html#topic+family">family</a></code> and link function.  If <code class="reqn">b_2
  &lt; 0</code>, this defines a unimodal curve with highest point at <code class="reqn">u =
  -b_1/(2 b_2)</code> (ter Braak &amp; Looman 1986). If <code class="reqn">b_2 &gt; 0</code>, the
parabola has a minimum at <code class="reqn">u</code> and the response is sometimes
called &ldquo;bimodal&rdquo;.  The null hypothesis is that the extreme
point <code class="reqn">u</code> is located within the interval given by points
<code class="reqn">p_1</code> and <code class="reqn">p_2</code>. If the extreme point <code class="reqn">u</code> is exactly at
<code class="reqn">p_1</code>, then <code class="reqn">b_1 = 0</code> on shifted axis <code class="reqn">x - p_1</code>.  In the
test, origin of <code>x</code> is shifted to the values <code class="reqn">p_1</code> and
<code class="reqn">p_2</code>, and the test statistic is based on the differences of
deviances between the original model and model where the origin is
forced to the given location using the standard
<code><a href="stats.html#topic+anova.glm">anova.glm</a></code> function (Oksanen et al. 2001).
Mitchell-Olds &amp; Shaw (1987) used the first degree coefficient with
its significance as estimated by the <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>
function.  This give identical results with Normal error, but for
other error distributions it is preferable to use the test based on
differences in deviances in fitted models.
</p>
<p>The test is often presented as a general test for the location of the
hump, but it really is dependent on the quadratic fitted curve. If the
hump is of different form than quadratic, the test may be
insignificant.
</p>
<p>Because of strong assumptions in the test, you should use the support
functions to inspect the fit. Function <code>plot(..., which=1)</code>
displays the data points, fitted quadratic model, and its approximate
95% confidence intervals (2 times SE). Function <code>plot</code> with
<code>which = 2</code> displays the approximate confidence interval of
the polynomial coefficients, together with two lines indicating the
combinations of the coefficients that produce the evaluated points of
<code>x</code>. Moreover, the cross-hair shows the approximate confidence
intervals for the polynomial coefficients ignoring their
correlations. Higher values of <code>which</code> produce corresponding
graphs from <code><a href="stats.html#topic+plot.lm">plot.lm</a></code>. That is, you must add 2 to the
value of <code>which</code> in <code><a href="stats.html#topic+plot.lm">plot.lm</a></code>.
</p>
<p>Function <code>fieller.MOStest</code> approximates the confidence limits
of the location of the extreme point (hump or pit) using Fieller's
theorem following ter Braak &amp; Looman (1986). The test is based on
quasideviance except if the <code><a href="stats.html#topic+family">family</a></code> is <code>poisson</code>
or <code>binomial</code>. Function <code>profile</code> evaluates the profile
deviance of the fitted model, and <code>confint</code> finds the profile
based confidence limits following Oksanen et al. (2001).
</p>
<p>The test is typically used in assessing the significance of diversity
hump against productivity gradient (Mittelbach et al. 2001). It also
can be used for the location of the pit (deepest points) instead of
the Tokeshi test. Further, it can be used to test the location of the
the Gaussian optimum in ecological gradient analysis (ter Braak &amp;
Looman 1986, Oksanen et al. 2001).
</p>


<h3>Value</h3>

<p>The function is based on <code><a href="stats.html#topic+glm">glm</a></code>, and it returns the result
of object of <code>glm</code> amended with the result of the test. The new
items in the <code>MOStest</code> are: 
</p>
<table>
<tr><td><code>isHump</code></td>
<td>
<p><code>TRUE</code> if the response is a
hump.</p>
</td></tr>
<tr><td><code>isBracketed</code></td>
<td>
<p><code>TRUE</code> if the hump or the pit is bracketed by
the evaluated points.</p>
</td></tr> 
<tr><td><code>hump</code></td>
<td>
<p>Sorted vector of location of the hump or the pit and the
points where the test was evaluated.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>Table of test statistics and their significances.</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>Function <code>fieller.MOStest</code> is based on package <span class="pkg">optgrad</span> in
the Ecological Archives
(<a href="https://figshare.com/articles/dataset/Full_Archive/3521975">https://figshare.com/articles/dataset/Full_Archive/3521975</a>)
accompanying Oksanen et al. (2001). The Ecological Archive package
<span class="pkg">optgrad</span> also contains profile deviance method for the location
of the hump or pit, but the current implementation of <code>profile</code>
and <code>confint</code> rather follow the example of
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code> and <code><a href="MASS.html#topic+confint.glm">confint.glm</a></code> in
the <span class="pkg">MASS</span> package.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>References</h3>

<p>Mitchell-Olds, T. &amp; Shaw, R.G. 1987. Regression analysis of natural
selection: statistical inference and biological
interpretation. <em>Evolution</em> 41, 1149&ndash;1161.
</p>
<p>Mittelbach, G.C. Steiner, C.F., Scheiner, S.M., Gross, K.L., Reynolds,
H.L., Waide, R.B., Willig, R.M., Dodson, S.I. &amp; Gough, L. 2001. What is
the observed relationship between species richness and productivity?
<em>Ecology</em> 82, 2381&ndash;2396.
</p>
<p>Oksanen, J., L√§√§r√§, E., Tolonen, K. &amp; Warner, B.G. 2001. Confidence
intervals for the optimum in the Gaussian response
function. <em>Ecology</em> 82, 1191&ndash;1197.
</p>
<p>ter Braak, C.J.F &amp; Looman, C.W.N 1986. Weighted averaging, logistic
regression and the Gaussian response model. <em>Vegetatio</em> 65,
3&ndash;11. 
</p>


<h3>See Also</h3>

<p>The no-interaction model can be fitted with <code><a href="#topic+humpfit">humpfit</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## The Al-Mufti data analysed in humpfit():
mass &lt;- c(140,230,310,310,400,510,610,670,860,900,1050,1160,1900,2480)
spno &lt;- c(1,  4,  3,  9, 18, 30, 20, 14,  3,  2,  3,  2,  5,  2)
mod &lt;- MOStest(mass, spno)
## Insignificant
mod
## ... but inadequate shape of the curve
op &lt;- par(mfrow=c(2,2), mar=c(4,4,1,1)+.1)
plot(mod)
## Looks rather like log-link with Poisson error and logarithmic biomass
mod &lt;- MOStest(log(mass), spno, family=quasipoisson)
mod
plot(mod)
par(op)
## Confidence Limits
fieller.MOStest(mod)
confint(mod)
plot(profile(mod))
</code></pre>

<hr>
<h2 id='mrpp'>Multi Response Permutation Procedure and Mean Dissimilarity Matrix</h2><span id='topic+mrpp'></span><span id='topic+meandist'></span><span id='topic+summary.meandist'></span><span id='topic+plot.meandist'></span>

<h3>Description</h3>

<p> Multiple Response Permutation Procedure (MRPP) provides a
test of whether there is a significant difference between two or more
groups of sampling units. Function <code>meandist</code> finds the mean within
and between block dissimilarities.</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrpp(dat, grouping, permutations = 999, distance = "euclidean",
     weight.type = 1, strata = NULL, parallel = getOption("mc.cores"))
meandist(dist, grouping, ...)
## S3 method for class 'meandist'
summary(object, ...)
## S3 method for class 'meandist'
plot(x, kind = c("dendrogram", "histogram"),  cluster = "average", 
     ylim, axes = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrpp_+3A_dat">dat</code></td>
<td>
<p>data matrix or data frame in which rows are samples and
columns are response variable(s), or a dissimilarity object or a
symmetric square matrix of dissimilarities.</p>
</td></tr> 
<tr><td><code id="mrpp_+3A_grouping">grouping</code></td>
<td>
<p> Factor or numeric index for grouping observations.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices. These are used to assess
the significance of the MRPP statistic, <code class="reqn">delta</code>.</p>
</td></tr> 
<tr><td><code id="mrpp_+3A_distance">distance</code></td>
<td>
<p>Choice of distance metric that measures the
dissimilarity between two observations . See <code><a href="#topic+vegdist">vegdist</a></code> for
options.  This will be used if <code>dat</code> was not a dissimilarity
structure of a symmetric square matrix.</p>
</td></tr>  
<tr><td><code id="mrpp_+3A_weight.type">weight.type</code></td>
<td>
<p> choice of group weights. See Details below for options.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_strata">strata</code></td>
<td>
<p>An integer vector or factor specifying the strata for
permutation. If supplied, observations are permuted only within the
specified strata.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_dist">dist</code></td>
<td>
<p>A <code><a href="stats.html#topic+dist">dist</a></code> object of dissimilarities, such as
produced by functions <code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="#topic+vegdist">vegdist</a></code> or
<code><a href="#topic+designdist">designdist</a></code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="mrpp_+3A_object">object</code>, <code id="mrpp_+3A_x">x</code></td>
<td>
<p>A <code>meandist</code> result object.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_kind">kind</code></td>
<td>
<p>Draw a dendrogram or a histogram; see Details.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_cluster">cluster</code></td>
<td>
<p>A clustering method for the <code><a href="stats.html#topic+hclust">hclust</a></code>
function for <code>kind = "dendrogram"</code>. 
Any <code>hclust</code> method can be used, but perhaps only
<code>"average"</code> and <code>"single"</code> make sense.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_ylim">ylim</code></td>
<td>
<p>Limits for vertical axes (optional).</p>
</td></tr>
<tr><td><code id="mrpp_+3A_axes">axes</code></td>
<td>
<p>Draw scale for the vertical axis.</p>
</td></tr>
<tr><td><code id="mrpp_+3A_...">...</code></td>
<td>
<p>Further arguments passed to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiple Response Permutation Procedure (MRPP) provides a test of
whether there is a significant difference between two or more groups
of sampling units. This difference may be one of location (differences
in mean) or one of spread (differences in within-group distance;
cf. Warton et al. 2012). Function <code>mrpp</code> operates on a
<code>data.frame</code> matrix where rows are observations and responses
data matrix. The response(s) may be uni- or multivariate. The method
is philosophically and mathematically allied with analysis of
variance, in that it compares dissimilarities within and among
groups. If two groups of sampling units are really different (e.g. in
their species composition), then average of the within-group
compositional dissimilarities ought to be less than the average of the
dissimilarities between two random collection of sampling units drawn
from the entire population.
</p>
<p>The mrpp statistic <code class="reqn">\delta</code> is the overall weighted mean of
within-group means of the pairwise dissimilarities among sampling
units. The choice of group weights is currently not clear. The
<code>mrpp</code> function offers three choices: (1) group size (<code class="reqn">n</code>),
(2) a degrees-of-freedom analogue (<code class="reqn">n-1</code>), and (3) a weight that
is the number of unique distances calculated among <code class="reqn">n</code> sampling
units (<code class="reqn">n(n-1)/2</code>).
</p>
<p>The <code>mrpp</code> algorithm first calculates all pairwise distances in
the entire dataset, then calculates <code class="reqn">\delta</code>. It then permutes the
sampling units and their associated pairwise distances, and
recalculates <code class="reqn">\delta</code> based on the permuted data. It repeats the
permutation step <code>permutations</code> times. The significance test is
the fraction of permuted deltas that are less than the observed delta,
with a small sample correction. The function also calculates the
change-corrected within-group agreement <code class="reqn">A = 1 -\delta/E(\delta)</code>,
where <code class="reqn">E(\delta)</code> is the expected <code class="reqn">\delta</code> assessed as the
average of dissimilarities.
</p>
<p>If the first argument <code>dat</code> can be interpreted as
dissimilarities, they will be used directly. In other cases the
function treats <code>dat</code> as observations, and uses
<code><a href="#topic+vegdist">vegdist</a></code> to find the dissimilarities.  The default
<code>distance</code> is Euclidean as in the traditional use of the method,
but other dissimilarities in <code><a href="#topic+vegdist">vegdist</a></code> also are available.
</p>
<p>Function <code>meandist</code> calculates a matrix of mean within-cluster
dissimilarities (diagonal) and between-cluster dissimilarities
(off-diagonal elements), and an attribute <code>n</code> of <code>grouping</code>
counts. Function <code>summary</code> finds the within-class, between-class
and overall means of these dissimilarities, and the MRPP statistics
with all <code>weight.type</code> options and the Classification Strength,
CS (Van Sickle and Hughes, 2000). CS is defined for dissimilarities as
<code class="reqn">\bar{B} - \bar{W}</code>, where <code class="reqn">\bar{B}</code> is the
mean between cluster dissimilarity and <code class="reqn">\bar{W}</code> is the mean
within cluster dissimilarity with <code>weight.type = 1</code>. The function
does not perform significance tests for these statistics, but you must
use <code>mrpp</code> with appropriate <code>weight.type</code>. There is
currently no significance test for CS, but <code>mrpp</code> with
<code>weight.type = 1</code> gives the correct test for <code class="reqn">\bar{W}</code>
and a good approximation for CS.  Function <code>plot</code> draws a
dendrogram or a histogram of the result matrix based on the
within-group and between group dissimilarities. The dendrogram is
found with the method given in the <code>cluster</code> argument using
function <code><a href="stats.html#topic+hclust">hclust</a></code>. The terminal segments hang to
within-cluster dissimilarity. If some of the clusters are more
heterogeneous than the combined class, the leaf segment are reversed.
The histograms are based on dissimilarities, but ore otherwise similar
to those of Van Sickle and Hughes (2000): horizontal line is drawn at
the level of mean between-cluster dissimilarity and vertical lines
connect within-cluster dissimilarities to this line.  </p>


<h3>Value</h3>

<p>The function returns a list of class mrpp with following items:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>	Function call.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>The overall weighted mean of group mean distances.</p>
</td></tr>
<tr><td><code>E.delta</code></td>
<td>
<p>expected delta, under the null hypothesis of no group
structure. This is the mean of original dissimilarities.</p>
</td></tr>
<tr><td><code>CS</code></td>
<td>
<p>Classification strength (Van Sickle and Hughes,
2000). Currently not implemented and always <code>NA</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of observations in each class.</p>
</td></tr>
<tr><td><code>classdelta</code></td>
<td>
<p>Mean dissimilarities within classes. The overall
<code class="reqn">\delta</code> is the weighted average of these values with given
<code>weight.type</code></p>
</td></tr></table>
<p>. 
</p>
<table>
<tr><td><code>Pvalue</code></td>
<td>
<p>Significance of the test.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>A chance-corrected estimate of the proportion of the distances
explained by group identity; a value analogous to a coefficient of 
determination in a linear model.</p>
</td></tr> 
<tr><td><code>distance</code></td>
<td>
<p>Choice of distance metric used; the &quot;method&quot; entry of
the dist object.</p>
</td></tr>
<tr><td><code>weight.type</code></td>
<td>
<p>The choice of group weights used.</p>
</td></tr>
<tr><td><code>boot.deltas</code></td>
<td>
<p>The vector of &quot;permuted deltas,&quot; the deltas
calculated from each of the permuted datasets. The distribution of
this item can be inspected with <code><a href="#topic+permustats">permustats</a></code> function.</p>
</td></tr>
<tr><td><code>permutations</code></td>
<td>
<p>The number of permutations used.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>A list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>This difference may be one of location (differences in mean) or one of
spread (differences in within-group distance). That is, it may find a
significant difference between two groups simply because one of those
groups has a greater dissimilarities among its sampling units. Most
<code>mrpp</code> models can be analysed with <code><a href="#topic+adonis2">adonis2</a></code> which seems
not suffer from the same problems as <code>mrpp</code> and is a more robust
alternative.
</p>


<h3>Author(s)</h3>

<p>M. Henry H. Stevens <a href="mailto:HStevens@muohio.edu">HStevens@muohio.edu</a> and Jari Oksanen.
</p>


<h3>References</h3>

<p>B. McCune and J. B. Grace. 2002. <em>Analysis of Ecological
Communities.</em> MjM  Software Design, Gleneden Beach, Oregon, USA.
</p>
<p>P. W. Mielke and K. J. Berry. 2001. <em>Permutation Methods: A
Distance  Function Approach.</em> Springer Series in
Statistics. Springer.  
</p>
<p>J. Van Sickle and R. M. Hughes 2000. Classification strengths of
ecoregions, catchments, and geographic clusters of aquatic vertebrates
in Oregon. <em>J. N. Am. Benthol. Soc.</em> 19:370&ndash;384.
</p>
<p>Warton, D.I., Wright, T.W., Wang, Y. 2012. Distance-based multivariate
analyses confound location and dispersion effects. <em>Methods in
Ecology and Evolution</em>, 3, 89&ndash;101
</p>


<h3>See Also</h3>

<p><code><a href="#topic+anosim">anosim</a></code> for a similar test based on ranks, and
<code><a href="#topic+mantel">mantel</a></code> for comparing dissimilarities against continuous
variables, and
<code><a href="#topic+vegdist">vegdist</a></code> for obtaining dissimilarities,
<code><a href="#topic+adonis2">adonis2</a></code> is a more robust alternative in most cases.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
dune.mrpp &lt;- with(dune.env, mrpp(dune, Management))
dune.mrpp

# Save and change plotting parameters
def.par &lt;- par(no.readonly = TRUE)
layout(matrix(1:2,nr=1))

plot(dune.ord &lt;- metaMDS(dune, trace=0), type="text", display="sites" )
with(dune.env, ordihull(dune.ord, Management))

with(dune.mrpp, {
  fig.dist &lt;- hist(boot.deltas, xlim=range(c(delta,boot.deltas)), 
                 main="Test of Differences Among Groups")
  abline(v=delta); 
  text(delta, 2*mean(fig.dist$counts), adj = -0.5,
     expression(bold(delta)), cex=1.5 )  }
)
par(def.par)
## meandist
dune.md &lt;- with(dune.env, meandist(vegdist(dune), Management))
dune.md
summary(dune.md)
plot(dune.md)
plot(dune.md, kind="histogram")
</code></pre>

<hr>
<h2 id='mso'> Functions for performing and displaying a spatial partitioning
of cca or rda results</h2><span id='topic+mso'></span><span id='topic+msoplot'></span>

<h3>Description</h3>

<p> The function <code>mso</code> adds an attribute <code>vario</code> to
an object of class <code>"cca"</code> that describes the spatial
partitioning of the <code><a href="#topic+cca">cca</a></code> object and performs an optional
permutation test for the spatial independence of residuals. The
function <code>plot.mso</code> creates a diagnostic plot of the spatial
partitioning of the <code>"cca"</code> object.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>mso(object.cca, object.xy, grain = 1, round.up = FALSE, permutations = 0)
msoplot(x, alpha = 0.05, explained = FALSE, ylim = NULL, legend = "topleft", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mso_+3A_object.cca">object.cca</code></td>
<td>
<p> An object of class cca, created by the <code><a href="#topic+cca">cca</a></code> or
<code><a href="#topic+rda">rda</a></code> function.</p>
</td></tr>
<tr><td><code id="mso_+3A_object.xy">object.xy</code></td>
<td>
<p> A vector, matrix or data frame with the spatial
coordinates of the data represented by <code>object.cca</code>. The
number of rows must match the number of observations (as given by
<code>nobs</code>) in <code>cca.object</code>. Alternatively, interpoint
distances can be supplied as a <code><a href="stats.html#topic+dist">dist</a></code> object. </p>
</td></tr>
<tr><td><code id="mso_+3A_grain">grain</code></td>
<td>
<p> Interval size for distance classes.</p>
</td></tr>
<tr><td><code id="mso_+3A_round.up">round.up</code></td>
<td>
<p> Determines the choice of breaks. If false, distances
are rounded to the nearest multiple of grain. If true, distances are
rounded to the upper multiple of grain.</p>
</td></tr> 
<tr><td><code id="mso_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="mso_+3A_x">x</code></td>
<td>
<p>A result object of <code>mso</code>.</p>
</td></tr>
<tr><td><code id="mso_+3A_alpha">alpha</code></td>
<td>
<p> Significance level for the two-sided permutation test of
the Mantel statistic for spatial independence of residual inertia
and for the point-wise envelope of the variogram of the total
variance. A Bonferroni-type correction can be achieved by dividing
the overall significance value (e.g. 0.05) by the number of distance
classes.</p>
</td></tr> 
<tr><td><code id="mso_+3A_explained">explained</code></td>
<td>
<p> If false, suppresses the plotting of the variogram
of explained variance.</p>
</td></tr>
<tr><td><code id="mso_+3A_ylim">ylim</code></td>
<td>
<p>Limits for y-axis.</p>
</td></tr>
<tr><td><code id="mso_+3A_legend">legend</code></td>
<td>
<p>The x and y co-ordinates to be used to position the legend. 
They can be specified by keyword or in any way which is accepted 
by <code><a href="graphics.html#topic+legend">legend</a></code>.</p>
</td></tr>
<tr><td><code id="mso_+3A_...">...</code></td>
<td>
<p>Other arguments passed to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mantel test is an adaptation of the function <code><a href="#topic+mantel">mantel</a></code> of the
<span class="pkg">vegan</span> package to the parallel testing of several distance classes. It
compares the mean inertia in each distance class to the pooled mean
inertia of all other distance classes. 
</p>
<p>If there are explanatory variables (RDA, CCA, pRDA, pCCA) and a
significance test for residual autocorrelation was performed when
running the function <code>mso</code>, the function <code>plot.mso</code> will
print an estimate of how much the autocorrelation (based on
significant distance classes) causes the global error variance of the
regression analysis to be underestimated 
</p>


<h3>Value</h3>

<p>The function <code>mso</code> returns an amended <code>cca</code> or <code>rda</code>
object with the additional attributes <code>grain</code>, <code>H</code>,
<code>H.test</code> and <code>vario</code>.
</p>
<table>
<tr><td><code>grain</code></td>
<td>
<p>The grain attribute defines the interval size of the
distance classes .</p>
</td></tr> 
<tr><td><code>H</code></td>
<td>
<p> H is an object of class 'dist' and contains the geographic
distances between observations.</p>
</td></tr> 
<tr><td><code>H.test</code></td>
<td>
<p> H.test contains a set of dummy variables that describe
which pairs of observations (rows = elements of <code>object$H</code>) fall in
which distance class (columns). </p>
</td></tr> 
<tr><td><code>vario</code></td>
<td>
<p> The vario attribute is a data frame that contains some
or all of the following components for the rda case (cca case in
brackets):
</p>

<dl>
<dt><code>H</code></dt><dd><p>Distance class as multiples of grain.</p>
</dd>
<dt><code>Dist</code></dt><dd><p> Average distance of pairs of observations in distance class H.</p>
</dd>
<dt>n </dt><dd><p> Number of unique pairs of observations in distance class
H.</p>
</dd> 
<dt><code>All</code></dt><dd><p> Empirical (chi-square) variogram of total variance
(inertia).</p>
</dd> 
<dt><code>Sum</code></dt><dd><p> Sum of empirical (chi-square) variograms of explained
and residual variance (inertia).</p>
</dd> 
<dt><code>CA</code></dt><dd><p> Empirical (chi-square) variogram of residual variance
(inertia).</p>
</dd> 
<dt><code>CCA</code></dt><dd><p> Empirical (chi-square) variogram of explained variance
(inertia).</p>
</dd> 
<dt><code>pCCA</code></dt><dd><p> Empirical (chi-square) variogram of conditioned
variance (inertia).</p>
</dd> 
<dt><code>se</code></dt><dd><p> Standard error of the empirical (chi-square) variogram
of total variance (inertia).</p>
</dd> 
<dt><code>CA.signif</code></dt><dd><p>P-value of permutation test for spatial
independence of residual variance (inertia).</p>
</dd> 
</dl>

</td></tr>
</table>


<h3>Note</h3>

<p> The function is based on the code published in the Ecological
Archives E085-006 (<a href="https://doi.org/10.1890/02-0738">doi:10.1890/02-0738</a>).  </p>


<h3>Author(s)</h3>

<p> The responsible author was Helene Wagner.</p>


<h3>References</h3>

<p> Wagner, H.H. 2004. Direct multi-scale ordination with
canonical correspondence analysis. <em>Ecology</em> 85: 342&ndash;351. </p>


<h3>See Also</h3>

<p> Function <code><a href="#topic+cca">cca</a></code> and <code><a href="#topic+rda">rda</a></code>,
<code><a href="#topic+cca.object">cca.object</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Reconstruct worked example of Wagner (submitted):
X &lt;- matrix(c(1, 2, 3, 2, 1, 0), 3, 2)
Y &lt;- c(3, -1, -2)
tmat &lt;- c(1:3)
## Canonical correspondence analysis (cca):
Example.cca &lt;- cca(X, Y)
Example.cca &lt;- mso(Example.cca, tmat)
msoplot(Example.cca)
Example.cca$vario

## Correspondence analysis (ca):
Example.ca &lt;- mso(cca(X), tmat)
msoplot(Example.ca)

## Unconstrained ordination with test for autocorrelation
## using oribatid mite data set as in Wagner (2004)
data(mite)
data(mite.env)
data(mite.xy)

mite.cca &lt;- cca(log(mite + 1))
mite.cca &lt;- mso(mite.cca, mite.xy, grain =  1, permutations = 99)
msoplot(mite.cca)
mite.cca

## Constrained ordination with test for residual autocorrelation
## and scale-invariance of species-environment relationships
mite.cca &lt;- cca(log(mite + 1) ~ SubsDens + WatrCont + Substrate + Shrub + Topo, mite.env)
mite.cca &lt;- mso(mite.cca, mite.xy, permutations = 99)
msoplot(mite.cca)
mite.cca
</code></pre>

<hr>
<h2 id='multipart'>Multiplicative Diversity Partitioning</h2><span id='topic+multipart'></span><span id='topic+multipart.default'></span><span id='topic+multipart.formula'></span>

<h3>Description</h3>

<p>In multiplicative diversity partitioning, mean values of alpha diversity at lower levels of a sampling
hierarchy are compared to the total diversity in the entire data set or the pooled samples (gamma diversity).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multipart(...)
## Default S3 method:
multipart(y, x, index=c("renyi", "tsallis"), scales = 1,
    global = FALSE, relative = FALSE, nsimul=99, method = "r2dtable", ...)
## S3 method for class 'formula'
multipart(formula, data, index=c("renyi", "tsallis"), scales = 1,
    global = FALSE, relative = FALSE, nsimul=99, method = "r2dtable", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multipart_+3A_y">y</code></td>
<td>
<p>A community matrix.</p>
</td></tr>
<tr><td><code id="multipart_+3A_x">x</code></td>
<td>
<p>A matrix with same number of rows as in <code>y</code>, columns
coding the levels of sampling hierarchy. The number of groups within
the hierarchy must decrease from left to right. If <code>x</code> is missing,
two levels are assumed: each row is a group in the first level, and
all rows are in the same group in the second level.</p>
</td></tr>
<tr><td><code id="multipart_+3A_formula">formula</code></td>
<td>
<p>A two sided model formula in the form <code>y ~ x</code>,
where <code>y</code> is the community data matrix with samples as rows and
species as column. Right hand side (<code>x</code>) must be grouping
variable(s) referring to levels of sampling hierarchy, terms from
right to left will be treated as nested (first column is the lowest,
last is the highest level). The formula will add a unique
indentifier to rows and constant for the rows to always produce
estimates of row-level alpha and overall gamma diversities. You must
use non-formula interface to avoid this behaviour. Interaction terms
are not allowed.</p>
</td></tr>
<tr><td><code id="multipart_+3A_data">data</code></td>
<td>
<p>A data frame where to look for variables defined in the
right hand side of <code>formula</code>. If missing, variables are looked
in the global environment.</p>
</td></tr>
<tr><td><code id="multipart_+3A_index">index</code></td>
<td>
<p>Character, the entropy index to be calculated (see Details).</p>
</td></tr>
<tr><td><code id="multipart_+3A_relative">relative</code></td>
<td>
<p>Logical, if <code>TRUE</code> then beta diversity is
standardized by its maximum (see Details).</p>
</td></tr>
<tr><td><code id="multipart_+3A_scales">scales</code></td>
<td>
<p>Numeric, of length 1, the order of the generalized
diversity index to be used.</p>
</td></tr>
<tr><td><code id="multipart_+3A_global">global</code></td>
<td>
<p>Logical, indicates the calculation of beta diversity values,
see Details.</p>
</td></tr>
<tr><td><code id="multipart_+3A_nsimul">nsimul</code></td>
<td>
<p>Number of permutations to use.  If <code>nsimul = 0</code>,
only the <code>FUN</code> argument is evaluated.
It is thus possible to reuse the statistic values
without a null model.</p>
</td></tr>
<tr><td><code id="multipart_+3A_method">method</code></td>
<td>
<p>Null model method: either a name (character string) of
a method defined in <code><a href="#topic+make.commsim">make.commsim</a></code> or a
<code><a href="#topic+commsim">commsim</a></code> function.
The default <code>"r2dtable"</code> keeps row sums and column sums fixed.
See <code><a href="#topic+oecosimu">oecosimu</a></code> for Details and Examples.</p>
</td></tr>
<tr><td><code id="multipart_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+oecosimu">oecosimu</a></code>, i.e.
<code>method</code>, <code>thin</code> or <code>burnin</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiplicative diversity partitioning is based on Whittaker's (1972) ideas,
that has recently been generalised to one parametric diversity families
(i.e. R√©nyi and Tsallis) by Jost (2006, 2007).
Jost recommends to use the numbers equivalents (Hill numbers),
instead of pure diversities, and proofs, that this satisfies the
multiplicative partitioning requirements.
</p>
<p>The current implementation of <code>multipart</code> calculates Hill numbers
based on the functions <code><a href="#topic+renyi">renyi</a></code> and <code><a href="#topic+tsallis">tsallis</a></code>
(provided as <code>index</code> argument).
If values for more than one <code>scales</code> are desired,
it should be done in separate runs, because it adds extra dimensionality
to the implementation, which has not been resolved efficiently.
</p>
<p>Alpha diversities are then the averages of these Hill numbers for
each hierarchy levels, the global gamma diversity is the alpha value
calculated for the highest hierarchy level.
When <code>global = TRUE</code>, beta is calculated relative to the global gamma value:
</p>
<p style="text-align: center;"><code class="reqn">\beta_i = \gamma / \alpha_{i}</code>
</p>

<p>when <code>global = FALSE</code>, beta is calculated relative to local
gamma values (local gamma means the diversity calculated for a particular
cluster based on the pooled abundance vector):
</p>
<p style="text-align: center;"><code class="reqn">\beta_ij = \alpha_{(i+1)j} / mean(\alpha_{ij})</code>
</p>

<p>where <code class="reqn">j</code> is a particular cluster at hierarchy level <code class="reqn">i</code>.
Then beta diversity value for level <code class="reqn">i</code> is the mean of the beta
values of the clusters at that level, <code class="reqn">\beta_{i} = mean(\beta_{ij})</code>.
</p>
<p>If <code>relative = TRUE</code>, the respective beta diversity values are
standardized by their maximum possible values (<code class="reqn">mean(\beta_{ij}) / \beta_{max,ij}</code>)
given as <code class="reqn">\beta_{max,ij} = n_{j}</code> (the number of lower level units
in a given cluster <code class="reqn">j</code>).
</p>
<p>The expected diversity components are calculated <code>nsimul</code>
times by individual based randomization of the community data matrix.
This is done by the <code>"r2dtable"</code> method in <code><a href="#topic+oecosimu">oecosimu</a></code> by default.
</p>


<h3>Value</h3>

<p>An object of class <code>"multipart"</code> with same structure as
<code>"oecosimu"</code> objects.
</p>


<h3>Author(s)</h3>

<p>P√©ter S√≥lymos, <a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a></p>


<h3>References</h3>

<p>Jost, L. (2006). Entropy and diversity.
<em>Oikos</em>, <b>113</b>, 363&ndash;375.
</p>
<p>Jost, L. (2007). Partitioning diversity into independent alpha and beta components.
<em>Ecology</em>, <b>88</b>, 2427&ndash;2439.
</p>
<p>Whittaker, R. (1972). Evolution and measurement of species diversity.
<em>Taxon</em>, <b>21</b>, 213&ndash;251.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+adipart">adipart</a></code> for additive diversity partitioning,
<code><a href="#topic+hiersimu">hiersimu</a></code> for hierarchical null model testing
and <code><a href="#topic+oecosimu">oecosimu</a></code> for permutation settings and calculating <code class="reqn">p</code>-values.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## NOTE: 'nsimul' argument usually needs to be &gt;= 99
## here much lower value is used for demonstration

data(mite)
data(mite.xy)
data(mite.env)
## Function to get equal area partitions of the mite data
cutter &lt;- function (x, cut = seq(0, 10, by = 2.5)) {
    out &lt;- rep(1, length(x))
    for (i in 2:(length(cut) - 1))
        out[which(x &gt; cut[i] &amp; x &lt;= cut[(i + 1)])] &lt;- i
    return(out)}
## The hierarchy of sample aggregation
levsm &lt;- with(mite.xy, data.frame(
    l2=cutter(y, cut = seq(0, 10, by = 2.5)),
    l3=cutter(y, cut = seq(0, 10, by = 5))))
## Multiplicative diversity partitioning
multipart(mite, levsm, index="renyi", scales=1, nsimul=19)
multipart(mite ~ l2 + l3, levsm, index="renyi", scales=1, nsimul=19)
multipart(mite ~ ., levsm, index="renyi", scales=1, nsimul=19, relative=TRUE)
multipart(mite ~ ., levsm, index="renyi", scales=1, nsimul=19, global=TRUE)
</code></pre>

<hr>
<h2 id='nestedtemp'> Nestedness Indices for Communities of Islands or Patches </h2><span id='topic+nestedtemp'></span><span id='topic+nestedchecker'></span><span id='topic+nestedn0'></span><span id='topic+nesteddisc'></span><span id='topic+nestednodf'></span><span id='topic+nestedbetasor'></span><span id='topic+nestedbetajac'></span><span id='topic+plot.nestedtemp'></span><span id='topic+plot.nestednodf'></span>

<h3>Description</h3>

<p>Patches or local communities are regarded as nested if they all could
be subsets of the same community. In general, species poor communities
should be subsets of species rich communities, and rare species should
only occur in species rich communities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nestedchecker(comm)
nestedn0(comm)
nesteddisc(comm, niter = 200)
nestedtemp(comm, ...)
nestednodf(comm, order = TRUE, weighted = FALSE, wbinary = FALSE)
nestedbetasor(comm)
nestedbetajac(comm)
## S3 method for class 'nestedtemp'
plot(x, kind = c("temperature", "incidence"),
    col=rev(heat.colors(100)),  names = FALSE, ...)
## S3 method for class 'nestednodf'
plot(x, col = "red", names = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nestedtemp_+3A_comm">comm</code></td>
<td>
<p>Community data.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_niter">niter</code></td>
<td>
<p>Number of iterations to reorder tied columns.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_x">x</code></td>
<td>
<p>Result object for a <code>plot</code>.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_col">col</code></td>
<td>
<p>Colour scheme for matrix temperatures.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_kind">kind</code></td>
<td>
<p>The kind of plot produced.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_names">names</code></td>
<td>
<p>Label columns and rows in the plot using names in <code>comm</code>.
If it is a logical vector of length 2, row and column labels are
returned accordingly.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_order">order</code></td>
<td>
<p>Order rows and columns by frequencies.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_weighted">weighted</code></td>
<td>
<p>Use species abundances as weights of interactions.</p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_wbinary">wbinary</code></td>
<td>
<p>Modify original method so that binary data give the same
result in weighted and and unweighted analysis. </p>
</td></tr>
<tr><td><code id="nestedtemp_+3A_...">...</code></td>
<td>
<p>Other arguments to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The nestedness functions evaluate alternative indices of nestedness.
The functions are intended to be used together with Null model
communities and used as an argument in <code><a href="#topic+oecosimu">oecosimu</a></code> to analyse
the non-randomness of results.
</p>
<p>Function <code>nestedchecker</code> gives the number of checkerboard units,
or 2x2 submatrices where both species occur once but on different
sites (Stone &amp; Roberts 1990).
</p>
<p>Function <code>nestedn0</code> implements
nestedness measure N0 which is the number of absences from the sites
which are richer than the most pauperate site species occurs
(Patterson &amp; Atmar 1986).
</p>
<p>Function <code>nesteddisc</code> implements discrepancy index which is the
number of ones that should be shifted to fill a row with ones in a
table arranged by species frequencies (Brualdi &amp; Sanderson
1999). The original definition arranges species (columns) by their
frequencies, but did not have any method of handling tied
frequencies.  The <code>nesteddisc</code> function tries to order tied
columns to minimize the discrepancy statistic but this is rather
slow, and with a large number of tied columns there is no guarantee
that the best ordering was found (argument <code>niter</code> gives the
maximum number of tried orders). In that case a warning of tied
columns will be issued.
</p>
<p>Function <code>nestedtemp</code> finds the matrix temperature which is
defined as the sum of &ldquo;surprises&rdquo; in arranged matrix.  In
arranged unsurprising matrix all species within proportion given by
matrix fill are in the upper left corner of the matrix, and the
surprise of the absence or presences is the diagonal distance from the
fill line (Atmar &amp; Patterson 1993). Function tries to pack species and
sites to a low temperature (Rodr√≠guez-Giron√©s
&amp; Santamaria 2006), but this is an iterative procedure, and the
temperatures usually vary among runs.  Function <code>nestedtemp</code> also
has a <code>plot</code> method which can display either incidences or
temperatures of the surprises. Matrix temperature was rather vaguely
described (Atmar &amp; Patterson 1993), but
Rodr√≠guez-Giron√©s &amp; Santamaria (2006) are
more explicit and their description is used here. However, the results
probably differ from other implementations, and users should be
cautious in interpreting the results. The details of calculations are
explained in the <code><a href="utils.html#topic+vignette">vignette</a></code> <em>Design decisions and
implementation</em> that you can read using functions
<code><a href="utils.html#topic+browseVignettes">browseVignettes</a></code>. Function
<code>nestedness</code> in the <span class="pkg">bipartite</span> package is
a direct port of the BINMATNEST programme of
Rodr√≠guez-Giron√©s &amp; Santamaria (2006).
</p>
<p>Function <code>nestednodf</code> implements a nestedness metric based on
overlap and decreasing fill (Almeida-Neto et al., 2008). Two basic
properties are required for a matrix to have the maximum degree of
nestedness according to this metric: (1) complete overlap of 1's
from right to left columns and from down to up rows, and (2)
decreasing marginal totals between all pairs of columns and all
pairs of rows. The nestedness statistic is evaluated separately for
columns (<code>N columns</code>) for rows (<code>N rows</code>) and combined for
the whole matrix (<code>NODF</code>).  If you set <code>order = FALSE</code>,
the statistic is evaluated with the current matrix ordering allowing
tests of other meaningful hypothesis of matrix structure than
default ordering by row and column totals (breaking ties by total
abundances when <code>weighted = TRUE</code>) (see Almeida-Neto et
al. 2008). With <code>weighted = TRUE</code>, the function finds the
weighted version of the index (Almeida-Neto &amp; Ulrich,
2011). However, this requires quantitative null models for adequate
testing. Almeida-Neto &amp; Ulrich (2011) say that you have positive
nestedness if values in the first row/column are higher than in the
second.  With this condition, weighted analysis of binary data will
always give zero nestedness. With argument <code>wbinary = TRUE</code>,
equality of rows/columns also indicates nestedness, and binary data
will give identical results in weighted and unweighted analysis.
However, this can also influence the results of weighted analysis so
that the results may differ from Almeida-Neto &amp; Ulrich (2011).
</p>
<p>Functions <code>nestedbetasor</code> and <code>nestedbetajac</code> find
multiple-site dissimilarities and decompose these into components of
turnover and nestedness following Baselga (2012); the pairwise
dissimilarities can be found with <code><a href="#topic+designdist">designdist</a></code>. This can
be seen as a decomposition of beta diversity (see
<code><a href="#topic+betadiver">betadiver</a></code>).  Function <code>nestedbetasor</code> uses
S√∏rensen dissimilarity and the turnover component is
Simpson dissimilarity (Baselga 2012), and <code>nestedbetajac</code> uses
analogous methods with the Jaccard index. The functions return a
vector of three items: turnover, nestedness and their sum which is
the multiple S√∏rensen or Jaccard dissimilarity. The
last one is the total beta diversity (Baselga 2012). The functions
will treat data as presence/absence (binary) and they can be used
with binary <code><a href="#topic+nullmodel">nullmodel</a></code>. The overall dissimilarity is
constant in all <code><a href="#topic+nullmodel">nullmodel</a></code>s that fix species (column)
frequencies (<code>"c0"</code>), and all components are constant if row
columns are also fixed (e.g., model <code>"quasiswap"</code>), and the
functions are not meaningful with these null models.
</p>


<h3>Value</h3>

<p>The result returned by a nestedness function contains an item called
<code>statistic</code>, but the other components differ among functions. The
functions are constructed so that they can be handled by
<code><a href="#topic+oecosimu">oecosimu</a></code>.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen and Gustavo Carvalho (<code>nestednodf</code>). </p>


<h3>References</h3>

<p>Almeida-Neto, M., Guimar√£es, P.,
Guimar√£es, P.R., Loyola, R.D. &amp; Ulrich, W. (2008). A
consistent metric for nestedness analysis in ecological systems:
reconciling concept and measurement. <em>Oikos</em> 117, 1227&ndash;1239.
</p>
<p>Almeida-Neto, M. &amp; Ulrich, W. (2011). A straightforward
computational approach for measuring nestedness using quantitative
matrices. <em>Env. Mod. Software</em> 26, 173&ndash;178.
</p>
<p>Atmar, W. &amp; Patterson, B.D. (1993). The measurement of order and
disorder in the distribution of species in fragmented
habitat. <em>Oecologia</em> 96, 373&ndash;382.
</p>
<p>Baselga, A. (2012). The relationship between species replacement,
dissimilarity derived from nestedness, and nestedness. <em>Global
Ecol. Biogeogr.</em> 21, 1223&ndash;1232.
</p>
<p>Brualdi, R.A. &amp; Sanderson, J.G. (1999). Nested species subsets, gaps,
and discrepancy. <em>Oecologia</em> 119, 256&ndash;264.
</p>
<p>Patterson, B.D. &amp; Atmar, W. (1986). Nested subsets and the structure
of insular mammalian faunas and archipelagos. <em>Biol. J. Linnean
Soc.</em> 28, 65&ndash;82.
</p>
<p>Rodr√≠guez-Giron√©s, M.A.  &amp; Santamaria, L.
(2006). A new algorithm to calculate the nestedness temperature of
presence-absence matrices. <em>J. Biogeogr.</em> 33, 924&ndash;935.
</p>
<p>Stone, L. &amp; Roberts, A. (1990). The checkerboard score and species
distributions. <em>Oecologia</em> 85, 74&ndash;79.
</p>
<p>Wright, D.H., Patterson, B.D., Mikkelson, G.M., Cutler, A. &amp; Atmar,
W. (1998). A comparative analysis of nested subset patterns of species
composition. <em>Oecologia</em> 113, 1&ndash;20.
</p>


<h3>See Also</h3>

<p>In general, the functions should be used with <code><a href="#topic+oecosimu">oecosimu</a></code>
which generates Null model communities to assess the non-randomness of
nestedness patterns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sipoo)
## Matrix temperature
out &lt;- nestedtemp(sipoo)
out
plot(out)
plot(out, kind="incid")
## Use oecosimu to assess the non-randomness of checker board units
nestedchecker(sipoo)
oecosimu(sipoo, nestedchecker, "quasiswap")
## Another Null model and standardized checkerboard score
oecosimu(sipoo, nestedchecker, "r00", statistic = "C.score")
</code></pre>

<hr>
<h2 id='nobs.cca'>
Extract the Number of Observations from a vegan Fit.
</h2><span id='topic+nobs.betadisper'></span><span id='topic+nobs.cca'></span><span id='topic+nobs.CCorA'></span><span id='topic+nobs.decorana'></span><span id='topic+nobs.isomap'></span><span id='topic+nobs.metaMDS'></span><span id='topic+nobs.pcnm'></span><span id='topic+nobs.procrustes'></span><span id='topic+nobs.rad'></span><span id='topic+nobs.varpart'></span><span id='topic+nobs.wcmdscale'></span>

<h3>Description</h3>

<p>Extract the number of &lsquo;observations&rsquo; from a <span class="pkg">vegan</span> model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nobs.cca_+3A_object">object</code></td>
<td>

<p>A fitted model object.
</p>
</td></tr>
<tr><td><code id="nobs.cca_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed to methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Function <code>nobs</code> is generic in <span class="rlang"><b>R</b></span>, and
<span class="pkg">vegan</span> provides methods for objects from
<code><a href="#topic+betadisper">betadisper</a></code>, <code><a href="#topic+cca">cca</a></code> and other related
methods, <code><a href="#topic+CCorA">CCorA</a></code>, <code><a href="#topic+decorana">decorana</a></code>,
<code><a href="#topic+isomap">isomap</a></code>, <code><a href="#topic+metaMDS">metaMDS</a></code>, <code><a href="#topic+pcnm">pcnm</a></code>,
<code><a href="#topic+procrustes">procrustes</a></code>, <code><a href="#topic+radfit">radfit</a></code>,
<code><a href="#topic+varpart">varpart</a></code> and <code><a href="#topic+wcmdscale">wcmdscale</a></code>.  </p>


<h3>Value</h3>

<p> A single number, normally an integer, giving the number of
observations.  </p>


<h3>Author(s)</h3>

<p>Jari Oksanen
</p>

<hr>
<h2 id='nullmodel'>
Null Model and Simulation
</h2><span id='topic+nullmodel'></span><span id='topic+simmat'></span><span id='topic+print.nullmodel'></span><span id='topic+simulate.nullmodel'></span><span id='topic+update.nullmodel'></span><span id='topic+str.nullmodel'></span><span id='topic+print.simmat'></span><span id='topic+smbind'></span>

<h3>Description</h3>

<p>The <code>nullmodel</code> function creates an object,
which can serve as a basis for Null Model simulation
via the <code><a href="stats.html#topic+simulate">simulate</a></code> method.
The <code><a href="stats.html#topic+update">update</a></code> method updates the nullmodel
object without sampling (effective for sequential algorithms).
<code>smbind</code> binds together multiple <code>simmat</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nullmodel(x, method)
## S3 method for class 'nullmodel'
print(x, ...)
## S3 method for class 'nullmodel'
simulate(object, nsim = 1, seed = NULL,
    burnin = 0, thin = 1, ...)
## S3 method for class 'nullmodel'
update(object, nsim = 1, seed = NULL, ...)
## S3 method for class 'simmat'
print(x, ...)
smbind(object, ..., MARGIN, strict = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nullmodel_+3A_x">x</code></td>
<td>

<p>A community matrix.
For the <code>print</code> method, it is an object to be printed.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_method">method</code></td>
<td>

<p>Character, specifying one of the null model algorithms
listed on the help page of <code><a href="#topic+commsim">commsim</a></code>.
It can be a user supplied object of class <code>commsim</code>.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_object">object</code></td>
<td>

<p>An object of class <code>nullmodel</code> returned by
the function <code>nullmodel</code>.
In case of <code>smbind</code> it is a <code>simmat</code> object
as returned by the <code>update</code> or <code>simulate</code> methods.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_nsim">nsim</code></td>
<td>

<p>Positive integer, the number of simulated matrices to return.
For the <code>update</code> method, it is the number of
burnin steps made for sequential algorithms
to update the status of the input model <code>object</code>.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_seed">seed</code></td>
<td>

<p>An object specifying if and how the random number
generator should be initialized (&quot;seeded&quot;).
Either <code>NULL</code> or an integer that will be
used in a call to <code><a href="base.html#topic+set.seed">set.seed</a></code> before
simulating the matrices.
If set, the value is saved as the
<code>"seed"</code> attribute of the returned value.
The default, <code>NULL</code> will not change the
random generator state, and return
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> as the <code>"seed"</code>
attribute, see Value.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_burnin">burnin</code></td>
<td>

<p>Nonnegative integer, specifying the number of steps
discarded before starting simulation.
Active only for sequential null model algorithms.
Ignored for non-sequential null model algorithms.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_thin">thin</code></td>
<td>

<p>Positive integer, number of simulation steps
made between each returned matrix.
Active only for sequential null model algorithms.
Ignored for non-sequential null model algorithms.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_margin">MARGIN</code></td>
<td>

<p>Integer, indicating the dimension over which multiple
<code>simmat</code> objects are to be bound together by <code>smbind</code>.
1: matrices are stacked (row bound), 2: matrices are column bound,
3: iterations are combined. Needs to be of length 1.
The other dimensions are expected to match across the objects.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_strict">strict</code></td>
<td>

<p>Logical, if consistency of the time series attributes
(<code>"start"</code>, <code>"end"</code>, <code>"thin"</code>, and number of simulated matrices)
of <code>simmat</code> objects are strictly enforced when
binding multiple objects together using <code>smbind</code>.
Applies only to input objects based on sequential
null model algorithms.
</p>
</td></tr>
<tr><td><code id="nullmodel_+3A_...">...</code></td>
<td>

<p>Additional arguments supplied to algorithms.
In case of <code>smbind</code> it can contain multiple <code>simmat</code> objects.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The purpose of the <code>nullmodel</code> function is to
create an object, where all necessary statistics of the
input matrix are calculated only once.
This information is reused, but not recalculated
in each step of the simulation process done by
the <code>simulate</code> method.
</p>
<p>The <code>simulate</code> method carries out the simulation,
the simulated matrices are stored in an array.
For sequential algorithms, the method updates the state
of the input <code>nullmodel</code> object.
Therefore, it is possible to do diagnostic
tests on the returned <code>simmat</code> object,
and make further simulations, or use
increased thinning value if desired.
</p>
<p>The <code>update</code> method makes burnin steps in case
of sequential algorithms to update the status of the
input model without any attempt to return matrices.
For non-sequential algorithms the method does nothing.
</p>
<p><code>update</code> is the preferred way of making burnin iterations
without sampling. Alternatively, burnin can be done
via the <code>simulate</code> method. For convergence
diagnostics, it is recommended to use the
<code>simulate</code> method without burnin.
The input nullmodel object is updated, so further
samples can be simulated if desired without having
to start the process all over again. See Examples.
</p>
<p>The <code>smbind</code> function can be used to combine multiple
<code>simmat</code> objects. This comes handy when null model
simulations are stratified by sites (<code>MARGIN = 1</code>)
or by species (<code>MARGIN = 2</code>), or in the case when
multiple objects are returned by identical/consistent settings
e.g. during parallel computations (<code>MARGIN = 3</code>).
Sanity checks are made to ensure that combining multiple
objects is sensible, but it is the user's responsibility
to check independence of the simulated matrices
and the null distribution has converged
in case of sequential null model algorithms.
The <code>strict = FALSE</code> setting can relax
checks regarding start, end, and thinning values
for sequential null models.
</p>


<h3>Value</h3>

<p>The function <code>nullmodel</code> returns an object of class <code>nullmodel</code>.
It is a set of objects sharing the same environment:
</p>

<ul>
<li><p><code>data</code>: original matrix in integer mode.
</p>
</li>
<li><p><code>nrow</code>: number of rows.
</p>
</li>
<li><p><code>ncol</code>: number of columns.
</p>
</li>
<li><p><code>rowSums</code>: row sums.
</p>
</li>
<li><p><code>colSums</code>: column sums.
</p>
</li>
<li><p><code>rowFreq</code>: row frequencies (number of nonzero cells).
</p>
</li>
<li><p><code>colFreq</code>: column frequencies (number of nonzero cells).
</p>
</li>
<li><p><code>totalSum</code>: total sum.
</p>
</li>
<li><p><code>fill</code>: number of nonzero cells in the matrix.
</p>
</li>
<li><p><code>commsim</code>: the <code>commsim</code> object as a result
of the <code>method</code> argument.
</p>
</li>
<li><p><code>state</code>: current state of the permutations,
a matrix similar to the original.
It is <code>NULL</code> for non-sequential algorithms.
</p>
</li>
<li><p><code>iter</code>: current number of iterations
for sequential algorithms.
It is <code>NULL</code> for non-sequential algorithms.
</p>
</li></ul>

<p>The <code>simulate</code> method returns an object of class <code>simmat</code>.
It is an array of simulated matrices (third dimension
corresponding to <code>nsim</code> argument).
</p>
<p>The <code>update</code> method returns the current state (last updated matrix)
invisibly, and update the input object for sequential algorithms.
For non sequential algorithms, it returns <code>NULL</code>.
</p>
<p>The <code>smbind</code> function returns an object of class <code>simmat</code>.
</p>


<h3>Note</h3>

<p>Care must be taken when the input matrix only contains a single
row or column. Such input is invalid for swapping and hypergeometric
distribution (calling <code><a href="stats.html#topic+r2dtable">r2dtable</a></code>) based algorithms.
This also applies to cases when the input is stratified into subsets.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen and Peter Solymos
</p>


<h3>See Also</h3>

<p><code><a href="#topic+commsim">commsim</a></code>, <code><a href="#topic+make.commsim">make.commsim</a></code>,
<code><a href="#topic+permatfull">permatfull</a></code>, <code><a href="#topic+permatswap">permatswap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite)
x &lt;- as.matrix(mite)[1:12, 21:30]

## non-sequential nullmodel
(nm &lt;- nullmodel(x, "r00"))
(sm &lt;- simulate(nm, nsim=10))

## sequential nullmodel
(nm &lt;- nullmodel(x, "swap"))
(sm1 &lt;- simulate(nm, nsim=10, thin=5))
(sm2 &lt;- simulate(nm, nsim=10, thin=5))

## sequential nullmodel with burnin and extra updating
(nm &lt;- nullmodel(x, "swap"))
(sm1 &lt;- simulate(nm, burnin=10, nsim=10, thin=5))
(sm2 &lt;- simulate(nm, nsim=10, thin=5))

## sequential nullmodel with separate initial burnin
(nm &lt;- nullmodel(x, "swap"))
nm &lt;- update(nm, nsim=10)
(sm2 &lt;- simulate(nm, nsim=10, thin=5))

## combining multiple simmat objects

## stratification
nm1 &lt;- nullmodel(x[1:6,], "r00")
sm1 &lt;- simulate(nm1, nsim=10)
nm2 &lt;- nullmodel(x[7:12,], "r00")
sm2 &lt;- simulate(nm2, nsim=10)
smbind(sm1, sm2, MARGIN=1)

## binding subsequent samples from sequential algorithms
## start, end, thin retained
nm &lt;- nullmodel(x, "swap")
nm &lt;- update(nm, nsim=10)
sm1 &lt;- simulate(nm, nsim=10, thin=5)
sm2 &lt;- simulate(nm, nsim=20, thin=5)
sm3 &lt;- simulate(nm, nsim=10, thin=5)
smbind(sm3, sm2, sm1, MARGIN=3)

## 'replicate' based usage which is similar to the output
## of 'parLapply' or 'mclapply' in the 'parallel' package
## start, end, thin are set, also noting number of chains
smfun &lt;- function(x, burnin, nsim, thin) {
    nm &lt;- nullmodel(x, "swap")
    nm &lt;- update(nm, nsim=burnin)
    simulate(nm, nsim=nsim, thin=thin)
}
smlist &lt;- replicate(3, smfun(x, burnin=50, nsim=10, thin=5), simplify=FALSE)
smbind(smlist, MARGIN=3) # Number of permuted matrices = 30

## Not run: 
## parallel null model calculations
library(parallel)

if (.Platform$OS.type == "unix") {
## forking on Unix systems
smlist &lt;- mclapply(1:3, function(i) smfun(x, burnin=50, nsim=10, thin=5))
smbind(smlist, MARGIN=3)
}

## socket type cluster, works on all platforms
cl &lt;- makeCluster(3)
clusterEvalQ(cl, library(vegan))
clusterExport(cl, c("smfun", "x"))
smlist &lt;- parLapply(cl, 1:3, function(i) smfun(x, burnin=50, nsim=10, thin=5))
stopCluster(cl)
smbind(smlist, MARGIN=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='oecosimu'>Evaluate Statistics with Null Models of Biological Communities </h2><span id='topic+oecosimu'></span><span id='topic+as.ts.oecosimu'></span><span id='topic+toCoda'></span><span id='topic+toCoda.oecosimu'></span>

<h3>Description</h3>

<p>Function evaluates a statistic or a vector of statistics in
community and evaluates its significance in a series of simulated
random communities.  The approach has been used traditionally for
the analysis of nestedness, but the function is more general and can
be used with any statistics evaluated with simulated
communities. Function <code>oecosimu</code> collects and evaluates the
statistics. The Null model communities are described in
<code><a href="#topic+make.commsim">make.commsim</a></code> and <code><a href="#topic+permatfull">permatfull</a></code>/
<code><a href="#topic+permatswap">permatswap</a></code>, the definition of Null models in
<code><a href="#topic+nullmodel">nullmodel</a></code>, and nestedness statistics in
<code><a href="#topic+nestednodf">nestednodf</a></code> (which describes several alternative
statistics, including nestedness temperature, <code class="reqn">N0</code>, checker
board units, nestedness discrepancy and NODF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oecosimu(comm, nestfun, method, nsimul = 99, burnin = 0, thin = 1,
   statistic = "statistic", alternative = c("two.sided", "less", "greater"), 
   batchsize = NA, parallel = getOption("mc.cores"), ...)
## S3 method for class 'oecosimu'
as.ts(x, ...)
## S3 method for class 'oecosimu'
toCoda(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oecosimu_+3A_comm">comm</code></td>
<td>
<p>Community data, or a Null model object generated by
<code><a href="#topic+nullmodel">nullmodel</a></code> or an object of class <code>simmat</code> (array
of permuted matrices from <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code>). If
<code>comm</code> is a community data, null model simulation
<code>method</code> must be specified.  If <code>comm</code> is a
<code><a href="#topic+nullmodel">nullmodel</a></code>, the simulation <code>method</code> is ignored,
and if <code>comm</code> is a <code>simmat</code> object, all other arguments
are ignored except <code>nestfun</code>, <code>statistic</code> and
<code>alternative</code>.</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_nestfun">nestfun</code></td>
<td>
<p>Function analysed. Some nestedness functions are
provided in <span class="pkg">vegan</span> (see <code><a href="#topic+nestedtemp">nestedtemp</a></code>), but any
function can be used if it accepts the community as the first
argument, and returns either a plain number or a vector or the
result in list item with the name defined in argument
<code>statistic</code>. See Examples for defining your own functions.</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_method">method</code></td>
<td>
<p>Null model method: either a name (character string) of
a method defined in <code><a href="#topic+make.commsim">make.commsim</a></code> or a
<code><a href="#topic+commsim">commsim</a></code> function. This argument is ignored if
<code>comm</code> is a <code><a href="#topic+nullmodel">nullmodel</a></code> or a <code>simmat</code>
object. See Details and Examples.</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_nsimul">nsimul</code></td>
<td>
<p>Number of simulated null communities (ignored if
<code>comm</code> is a <code>simmat</code> object).</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_burnin">burnin</code></td>
<td>
<p>Number of null communities discarded before proper
analysis in sequential methods (such as <code>"tswap"</code>)
(ignored with non-sequential methods or when <code>comm</code> is a
<code>simmat</code> object).</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_thin">thin</code></td>
<td>
<p>Number of discarded null communities between two
evaluations of nestedness statistic in sequential methods (ignored
with non-sequential methods or when <code>comm</code> is a <code>simmat</code>
object).</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_statistic">statistic</code></td>
<td>
<p>The name of the statistic returned by
<code>nestfun</code>.</p>
</td></tr> 
<tr><td><code id="oecosimu_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default), <code>"greater"</code>
or <code>"less"</code>. Please note that the <code class="reqn">p</code>-value of two-sided
test is approximately two times higher than in the corresponding
one-sided test (<code>"greater"</code> or <code>"less"</code> depending on the
sign of the difference).</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_batchsize">batchsize</code></td>
<td>
<p>Size in Megabytes of largest simulation object. If
a larger structure would be produced, the analysis is broken
internally into batches. With default <code>NA</code> the analysis is
not broken into batches.  See Details.</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.  If you define a <code>nestfun</code> in Windows that needs other
<span class="rlang"><b>R</b></span> packages than <span class="pkg">vegan</span> or <span class="pkg">permute</span>, you must set up a
socket cluster before the call. </p>
</td></tr>
<tr><td><code id="oecosimu_+3A_x">x</code></td>
<td>
<p>An <code>oecosimu</code> result object.</p>
</td></tr>
<tr><td><code id="oecosimu_+3A_...">...</code></td>
<td>
<p>Other arguments to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>oecosimu</code> is a wrapper that evaluates a statistic
using function given by <code>nestfun</code>, and then simulates a series
of null models based on <code>nullmodel</code>, and evaluates the
statistic on these null models. The <span class="pkg">vegan</span> packages contains
some nestedness functions that are described separately
(<code><a href="#topic+nestedchecker">nestedchecker</a></code>, <code><a href="#topic+nesteddisc">nesteddisc</a></code>,
<code><a href="#topic+nestedn0">nestedn0</a></code>, <code><a href="#topic+nestedtemp">nestedtemp</a></code>,
<code><a href="#topic+nestednodf">nestednodf</a></code>), but many other functions can be used as
long as they are meaningful with simulated communities.  An
applicable function must return either the statistic as a plain
number or a vector, or as a list element <code>"statistic"</code> (like
<code><a href="stats.html#topic+chisq.test">chisq.test</a></code>), or in an item whose name is given in the
argument <code>statistic</code>.  The statistic can be a single number
(like typical for a nestedness index), or it can be a vector. The
vector indices can be used to analyse site (row) or species (column)
properties, see <code><a href="#topic+treedive">treedive</a></code> for an example. Raup-Crick
index (<code><a href="#topic+raupcrick">raupcrick</a></code>) gives an example of using a
dissimilarities.
</p>
<p>The Null model type can be given as a name (quoted character string)
that is used to define a Null model in <code><a href="#topic+make.commsim">make.commsim</a></code>.
These include all binary models described by Wright et al. (1998),
Jonsson (2001), Gotelli &amp; Entsminger (2003), Mikl√≥s &amp;
Podani (2004), and some others. There are several quantitative Null
models, such those discussed by Hardy (2008), and several that are
unpublished (see <code><a href="#topic+make.commsim">make.commsim</a></code>,
<code><a href="#topic+permatfull">permatfull</a></code>, <code><a href="#topic+permatswap">permatswap</a></code> for
discussion). The user can also define her own <code><a href="#topic+commsim">commsim</a></code>
function (see Examples).
</p>
<p>Function works by first defining a <code><a href="#topic+nullmodel">nullmodel</a></code> with
given <code><a href="#topic+commsim">commsim</a></code>, and then generating a series of
simulated communities with <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code>. A
shortcut can be used for any of these stages and the input can be
</p>

<ol>
<li><p> Community data (<code>comm</code>), Null model function
(<code>nestfun</code>) and the number of simulations (<code>nsimul</code>).
</p>
</li>
<li><p> A <code><a href="#topic+nullmodel">nullmodel</a></code> object and the number of
simulations, and argument <code>method</code> is ignored.
</p>
</li>
<li><p> A three-dimensional array of simulated communities generated
with <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code>, and arguments
<code>method</code> and <code>nsimul</code> are ignored.  
</p>
</li></ol>

<p>The last case allows analysing several statistics with the same
simulations.
</p>
<p>The function first generates simulations with given
<code><a href="#topic+nullmodel">nullmodel</a></code> and then analyses these using the
<code>nestfun</code>.  With large data sets and/or large number of
simulations, the generated objects can be very large, and if the
memory is exhausted, the analysis can become very slow and the
system can become unresponsive. The simulation will be broken into
several smaller batches if the simulated <code><a href="#topic+nullmodel">nullmodel</a></code>
objective will be above the set <code>batchsize</code> to avoid memory
problems (see <code><a href="utils.html#topic+object.size">object.size</a></code> for estimating the size of
the current data set). The parallel processing still increases the
memory needs.  The parallel processing is only used for evaluating
<code>nestfun</code>.  The main load may be in simulation of the
<code><a href="#topic+nullmodel">nullmodel</a></code>, and <code>parallel</code> argument does not help
there.
</p>
<p>Function <code>as.ts</code> transforms the simulated results of sequential
methods into a time series or a <code><a href="stats.html#topic+ts">ts</a></code> object. This allows
using analytic tools for time series in studying the sequences (see
examples). Function <code>toCoda</code> transforms the simulated results
of sequential methods into an <code><a href="coda.html#topic+mcmc">mcmc</a></code> object of the
<a href="https://CRAN.R-project.org/package=coda"><span class="pkg">coda</span></a> package. The <span class="pkg">coda</span> package provides functions for
the analysis of stationarity, adequacy of sample size,
autocorrelation, need of burn-in and much more for sequential
methods, and summary of the results. Please consult the
documentation of the <span class="pkg">coda</span> package.
</p>
<p>Function <code><a href="#topic+permustats">permustats</a></code> provides support to the standard
<code><a href="stats.html#topic+density">density</a></code>, <code><a href="lattice.html#topic+densityplot">densityplot</a></code>,
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> and <code><a href="lattice.html#topic+qqmath">qqmath</a></code> functions for
the simulated values.
</p>


<h3>Value</h3>

 
<p>Function <code>oecosimu</code> returns an object of class
<code>"oecosimu"</code>.  The result object has items <code>statistic</code> and
<code>oecosimu</code>.  The <code>statistic</code> contains the complete object
returned by <code>nestfun</code> for the original data.  The
<code>oecosimu</code> component contains the following items:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>Observed values of the statistic.</p>
</td></tr>
<tr><td><code>simulated</code></td>
<td>
<p>Simulated values of the statistic.</p>
</td></tr>
<tr><td><code>means</code></td>
<td>
<p>Mean values of the statistic from simulations.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>Standardized effect sizes (SES, a.k.a. the <code class="reqn">z</code>-values)
of the observed statistic based on simulations.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>The <code class="reqn">P</code>-values of the statistic based on simulations.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>The type of testing as given in argument <code>alternative</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The <code>method</code> used in <code><a href="#topic+nullmodel">nullmodel</a></code>.</p>
</td></tr>
<tr><td><code>isSeq</code></td>
<td>
<p><code>TRUE</code> if <code>method</code> was sequential.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If you wonder about the name of <code>oecosimu</code>, look at journal
names in the References (and more in <code><a href="#topic+nestedtemp">nestedtemp</a></code>).  
</p>
<p>The internal structure of the function was radically changed in
<span class="pkg">vegan 2.2-0</span> with introduction of <code><a href="#topic+commsim">commsim</a></code> and
<code><a href="#topic+nullmodel">nullmodel</a></code> and deprecation of
<code><a href="#topic+commsimulator">commsimulator</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen and Peter Solymos</p>


<h3>References</h3>

<p>Hardy, O. J. (2008) 
Testing the spatial phylogenetic structure of local communities: 
statistical performances of different null models 
and test statistics on a locally neutral community. 
<em>Journal of Ecology</em> 96, 914&ndash;926.
</p>
<p>Gotelli, N.J. &amp; Entsminger, N.J. (2003). Swap algorithms in null model
analysis. <em>Ecology</em> 84, 532&ndash;535.
</p>
<p>Jonsson, B.G. (2001) A null model for randomization tests of
nestedness in species assemblages. <em>Oecologia</em> 127, 309&ndash;313.
</p>
<p>Mikl√≥s, I. &amp; Podani, J. (2004). Randomization of presence-absence
matrices: comments and new algorithms. <em>Ecology</em> 85, 86&ndash;92.
</p>
<p>Wright, D.H., Patterson, B.D., Mikkelson, G.M., Cutler, A. &amp; Atmar,
W. (1998). A comparative analysis of nested subset patterns of species
composition. <em>Oecologia</em> 113, 1&ndash;20.
</p>


<h3>See Also</h3>

<p>Function <code>oecosimu</code> currently defines null models with
<code><a href="#topic+commsim">commsim</a></code> and generates the simulated null model
communities with <code><a href="#topic+nullmodel">nullmodel</a></code> and
<code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code>. For other applications of
<code>oecosimu</code>, see <code><a href="#topic+treedive">treedive</a></code> and
<code><a href="#topic+raupcrick">raupcrick</a></code>.
</p>
<p>See also <code><a href="#topic+nestedtemp">nestedtemp</a></code> (that also discusses other
nestedness functions) and <code><a href="#topic+treedive">treedive</a></code> for another
application.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use the first eigenvalue of correspondence analysis as an index
## of structure: a model for making your own functions.
data(sipoo)
## Traditional nestedness statistics (number of checkerboard units)
oecosimu(sipoo, nestedchecker, "r0")
## sequential model, one-sided test, a vector statistic
out &lt;- oecosimu(sipoo, decorana, "swap", burnin=100, thin=10, 
   statistic="evals", alt = "greater")
out
## Inspect the swap sequence as a time series object
plot(as.ts(out))
lag.plot(as.ts(out))
acf(as.ts(out))
## Density plot
densityplot(permustats(out), as.table = TRUE, layout = c(1,4))
## Use quantitative null models to compare
## mean Bray-Curtis dissimilarities
data(dune)
meandist &lt;- function(x) mean(vegdist(x, "bray"))
mbc1 &lt;- oecosimu(dune, meandist, "r2dtable")
mbc1

## Define your own null model as a 'commsim' function: shuffle cells
## in each row
foo &lt;- function(x, n, nr, nc, ...) {
   out &lt;- array(0, c(nr, nc, n))
   for (k in seq_len(n))
      out[,,k] &lt;- apply(x, 2, function(z) sample(z, length(z)))
   out
}
cf &lt;- commsim("myshuffle", foo, isSeq = FALSE, binary = FALSE, 
   mode = "double")
oecosimu(dune, meandist, cf)

## Use pre-built null model
nm &lt;- simulate(nullmodel(sipoo, "curveball"), 99)
oecosimu(nm, nestedchecker)
## Several chains of a sequential model -- this can be generalized
## for parallel processing (see ?smbind)
nm &lt;- replicate(5, simulate(nullmodel(sipoo, "swap"), 99,
   thin=10, burnin=100), simplify = FALSE)
## nm is now a list of nullmodels: use smbind to combine these into one
## nullmodel with several chains
## IGNORE_RDIFF_BEGIN
nm &lt;- smbind(nm, MARGIN = 3)
nm
oecosimu(nm, nestedchecker)
## IGNORE_RDIFF_END
## After this you can use toCoda() and tools in the coda package to
## analyse the chains (these will show that thin, burnin and nsimul are
## all too low for real analysis).
</code></pre>

<hr>
<h2 id='ordiarrows'>Add Arrows and Line Segments to Ordination Diagrams</h2><span id='topic+ordiarrows'></span><span id='topic+ordisegments'></span><span id='topic+ordigrid'></span>

<h3>Description</h3>

<p> Functions to add arrows, line segments, regular grids of
points. The ordination diagrams can be produced by <code>vegan</code>
<code><a href="#topic+plot.cca">plot.cca</a></code>, <code><a href="#topic+plot.decorana">plot.decorana</a></code> or
<code><a href="#topic+ordiplot">ordiplot</a></code>.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>ordiarrows(ord, groups, levels, replicates, order.by, display = "sites",
         col = 1, show.groups, startmark, label = FALSE, length = 0.1, ...)
ordisegments(ord, groups, levels, replicates, order.by, display = "sites",
         col = 1, show.groups, label = FALSE, ...)
ordigrid(ord, levels, replicates, display = "sites",  lty = c(1,1), 
         col = c(1,1), lwd = c(1,1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordiarrows_+3A_ord">ord</code></td>
<td>
<p>An ordination object or an <code><a href="#topic+ordiplot">ordiplot</a></code> object. </p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_groups">groups</code></td>
<td>
<p>Factor giving the groups for which the graphical item is
drawn. </p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_levels">levels</code>, <code id="ordiarrows_+3A_replicates">replicates</code></td>
<td>
<p>Alternatively, regular
groups can be defined with arguments <code>levels</code> and
<code>replicates</code>, where <code>levels</code> gives the number of groups,
and <code>replicates</code> the number of successive items at the same
group.</p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_order.by">order.by</code></td>
<td>
<p>Order points by increasing order of this variable
within <code>groups</code>. Reverse sign of the variable for decreasing
ordering.</p>
</td></tr> 
<tr><td><code id="ordiarrows_+3A_display">display</code></td>
<td>
<p>Item to displayed. </p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_show.groups">show.groups</code></td>
<td>
<p>Show only given groups. This can be a vector, or
<code>TRUE</code> if you want to show items for which condition is
<code>TRUE</code>. This argument makes it possible to use different
colours and line types for groups. The default is to show all groups. </p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_label">label</code></td>
<td>
<p>Label the <code>groups</code> by their names. In
<code>ordiellipse</code>, <code>ordihull</code> and <code>ordispider</code> the the
group name is in the centroid of the object, in <code>ordiarrows</code>
in the start of the arrow, and in <code>ordisegments</code> at both
ends. <code>ordiellipse</code> and <code>ordihull</code> use standard
<code><a href="graphics.html#topic+text">text</a></code>, and others use <code><a href="#topic+ordilabel">ordilabel</a></code>.</p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_startmark">startmark</code></td>
<td>
<p>plotting character used to mark the first item. The
default is to use no mark, and for instance, <code>startmark = 1</code>
will draw a circle.  For other plotting characters, see <code>pch</code>
in <code><a href="graphics.html#topic+points">points</a></code>. </p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_col">col</code></td>
<td>
<p>Colour of lines, <code>label</code> borders and
<code>startmark</code> in <code>ordiarrows</code> and
<code>ordisegments</code>. This can be a vector recycled for
<code>groups</code>. In <code>ordigrid</code> it can be a vector of length 2
used for <code>levels</code> and <code>replicates</code>.</p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_length">length</code></td>
<td>
<p>Length of edges of the arrow head (in inches).</p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_lty">lty</code>, <code id="ordiarrows_+3A_lwd">lwd</code></td>
<td>
<p>Line type, line width used for 
<code>level</code>s and <code>replicate</code>s in <code>ordigrid</code>.</p>
</td></tr>
<tr><td><code id="ordiarrows_+3A_...">...</code></td>
<td>
<p>Parameters passed to graphical functions such as
<code><a href="graphics.html#topic+lines">lines</a></code>, <code><a href="graphics.html#topic+segments">segments</a></code>, <code><a href="graphics.html#topic+arrows">arrows</a></code>,
or to <code><a href="#topic+scores">scores</a></code> to select axes and scaling etc. </p>
</td></tr>
</table>


<h3>Details</h3>

<p> Function <code>ordiarrows</code> draws <code><a href="graphics.html#topic+arrows">arrows</a></code> and
<code>ordisegments</code> draws line <code><a href="graphics.html#topic+segments">segments</a></code> between
successive items in the groups. Function <code>ordigrid</code> draws line
<code><a href="graphics.html#topic+segments">segments</a></code> both within the groups and for the
corresponding items among the groups.
</p>


<h3>Note</h3>

<p>These functions add graphical items to ordination graph: You must
draw a graph first.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>See Also</h3>

<p>The functions pass parameters to basic graphical functions, and
you may wish to change the default values in <code><a href="graphics.html#topic+arrows">arrows</a></code>,
<code><a href="graphics.html#topic+lines">lines</a></code> and <code><a href="graphics.html#topic+segments">segments</a></code>. You can pass
parameters to <code><a href="#topic+scores">scores</a></code> as well. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example(pyrifos)
mod &lt;- rda(pyrifos)
plot(mod, type = "n")
## Annual succession by ditches, colour by dose
ordiarrows(mod, ditch, label = TRUE, col = as.numeric(dose))
legend("topright", levels(dose), lty=1, col=1:5, title="Dose")
## Show only control and highest Pyrifos treatment
plot(mod, type = "n")
ordiarrows(mod, ditch, label = TRUE, 
   show.groups = c("2", "3", "5", "11"))
ordiarrows(mod, ditch, label = TRUE, show = c("6", "9"),
   col = 2)
legend("topright", c("Control", "Pyrifos 44"), lty = 1, col = c(1,2))
</code></pre>

<hr>
<h2 id='ordiArrowTextXY'>Support Functions for Drawing Vectors</h2><span id='topic+ordiArrowMul'></span><span id='topic+ordiArrowTextXY'></span>

<h3>Description</h3>

<p>Support functions to assist with drawing of vectors (arrows) on
ordination plots. <code>ordiArrowMul</code> finds the multiplier for the
coordinates of the head of the vector such that they occupy
<code>fill</code> proportion of the plot region. <code>ordiArrowTextXY</code>
finds coordinates for the locations of <code>labels</code> to be drawn just
beyond the head of the vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordiArrowTextXY(x, labels, display, choices = c(1,2),
                rescale = TRUE, fill = 0.75, at = c(0,0), ...)
ordiArrowMul(x, at = c(0,0), fill = 0.75,
             display, choices = c(1,2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordiArrowTextXY_+3A_x">x</code></td>
<td>
<p>An R object, from which <code><a href="#topic+scores">scores</a></code> can determine
suitable ordination scores or an object created by
<code><a href="#topic+envfit">envfit</a></code>, or a two-column matrix of coordinates of arrow
heads on the two plot axes.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_labels">labels</code></td>
<td>
<p>Change plotting labels. A character vector of labels for
which label coordinates are sought. If not supplied, these will be
determined from the row names of <code>x</code>, or <code>scores(x, ...)</code>
if required. If either of these are not defined, suitable labels
will be generated.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_display">display</code></td>
<td>
<p>a character string known to <code><a href="#topic+scores">scores</a></code> or one
of its methods which indicates the type of scores to extract. In
fitting functions these are ordinary site scores or linear
combination scores (<code>"lc"</code>) in constrained ordination
(<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+capscale">capscale</a></code>). If
<code>x</code> was created by <code>envfit</code> then <code>display</code> can not be
set by the user and takes the value <code>"vectors"</code>. Ignored if
<code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_choices">choices</code></td>
<td>
<p>Axes to be plotted.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_rescale">rescale</code></td>
<td>
<p>logical; should the coordinates in or extracted from
<code>x</code> be rescaled to fill <code>fill</code> proportion of the plot
region? The default is to always rescale the coordinates as this is
usually desired for objects <code>x</code> from which coordinates are
retrieved. If supplying <code>x</code> a 2-column matrix that has already
been rescaled, then set this to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_fill">fill</code></td>
<td>
<p>numeric; the proportion of the plot to fill by the span of
the arrows.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_at">at</code></td>
<td>
<p>The origin of fitted arrows in the plot.  If you plot arrows
in other places than origin, you probably have to specify
<code>arrrow.mul</code>.</p>
</td></tr>
<tr><td><code id="ordiArrowTextXY_+3A_...">...</code></td>
<td>
<p>Parameters passed to <code><a href="#topic+scores">scores</a></code>, and
<code><a href="graphics.html#topic+strwidth">strwidth</a></code> and <code><a href="graphics.html#topic+strheight">strheight</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ordiArrowMul</code> finds a multiplier to scale a bunch of
arrows to fill an ordination plot, and <code>ordiArrowTextXY</code> finds
the coordinates for labels of these arrows. NB.,
<code>ordiArrowTextXY</code> does not draw labels; it simply returns
coordinates at which the labels should be drawn for use with another
function, such as <code><a href="graphics.html#topic+text">text</a></code>.
</p>


<h3>Value</h3>

<p>For <code>ordiArrowTextXY</code>, a 2-column matrix of coordinates for the
label centres in the coordinate system of the currently active
plotting device.
</p>
<p>For <code>ordiArrowMul</code>, a length-1 vector containing the scaling
factor.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen, with modifications by Gavin L. Simpson</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Scale arrows by hand to fill 80% of the plot
    ## Biplot arrows by hand
    data(varespec, varechem)
    ord &lt;- cca(varespec ~ Al + P + K, varechem)
    plot(ord, display = c("species","sites"))

    ## biplot scores
    bip &lt;- scores(ord, choices = 1:2, display = "bp")

    ## scaling factor for arrows to fill 80% of plot
    (mul &lt;- ordiArrowMul(bip, fill = 0.8))
    bip.scl &lt;- bip * mul                    # Scale the biplot scores
    labs &lt;- rownames(bip)                   # Arrow labels

    ## calculate coordinate of labels for arrows
    (bip.lab &lt;- ordiArrowTextXY(bip.scl, rescale = FALSE, labels = labs))

    ## draw arrows and text labels
    arrows(0, 0, bip.scl[,1], bip.scl[,2], length = 0.1)
    text(bip.lab, labels = labs)

    ## Handling of ordination objects directly
    mul2 &lt;- ordiArrowMul(ord, display = "bp", fill = 0.8)
    stopifnot(all.equal(mul, mul2))
</code></pre>

<hr>
<h2 id='ordihull'>Display Groups or Factor Levels in Ordination Diagrams</h2><span id='topic+ordihull'></span><span id='topic+ordispider'></span><span id='topic+ordiellipse'></span><span id='topic+ordibar'></span><span id='topic+ordicluster'></span><span id='topic+summary.ordihull'></span><span id='topic+scores.ordihull'></span><span id='topic+summary.ordiellipse'></span><span id='topic+ordiareatest'></span>

<h3>Description</h3>

<p> Functions to add convex hulls, &ldquo;spider&rdquo; graphs, ellipses
or cluster dendrogram to ordination diagrams. The ordination
diagrams can be produced by <code>vegan</code> <code><a href="#topic+plot.cca">plot.cca</a></code>,
<code><a href="#topic+plot.decorana">plot.decorana</a></code> or <code><a href="#topic+ordiplot">ordiplot</a></code>.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>ordihull(ord, groups, display = "sites", draw = c("lines","polygon", "none"),
         col = NULL, alpha = 127, show.groups, label = FALSE,
         border = NULL, lty = NULL, lwd = NULL, ...)
ordiellipse(ord, groups, display="sites", kind = c("sd","se", "ehull"),
         conf, draw = c("lines","polygon", "none"),
	 w = weights(ord, display), col = NULL, alpha = 127, show.groups,
	 label = FALSE, border = NULL, lty = NULL, lwd=NULL, ...)
ordibar(ord, groups, display = "sites", kind = c("sd", "se"), conf,
         w = weights(ord, display), col = 1, show.groups, label = FALSE,
	 lwd = NULL, length = 0,  ...)
ordispider(ord, groups, display="sites", w = weights(ord, display),
	 spiders = c("centroid", "median"),  show.groups,
         label = FALSE, col = NULL, lty = NULL, lwd = NULL, ...)
ordicluster(ord, cluster, prune = 0, display = "sites",
            w = weights(ord, display), col = 1, draw = c("segments", "none"),
            ...)
## S3 method for class 'ordihull'
summary(object, ...)
## S3 method for class 'ordiellipse'
summary(object, ...)
ordiareatest(ord, groups, area = c("hull", "ellipse"), kind = "sd",
         permutations = 999, parallel = getOption("mc.cores"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordihull_+3A_ord">ord</code></td>
<td>
<p>An ordination object or an <code><a href="#topic+ordiplot">ordiplot</a></code> object. </p>
</td></tr>
<tr><td><code id="ordihull_+3A_groups">groups</code></td>
<td>
<p>Factor giving the groups for which the graphical item is
drawn. </p>
</td></tr>
<tr><td><code id="ordihull_+3A_display">display</code></td>
<td>
<p>Item to displayed. </p>
</td></tr>
<tr><td><code id="ordihull_+3A_draw">draw</code></td>
<td>
<p>character; how should objects be represented on the plot?
For <code>ordihull</code> and <code>ordiellipse</code> use either
<code><a href="graphics.html#topic+lines">lines</a></code> or <code><a href="graphics.html#topic+polygon">polygon</a></code> to draw the
lines. For <code>ordicluster</code>, line segments are drawn using
<code><a href="graphics.html#topic+segments">segments</a></code>. To suppress plotting, use
<code>"none"</code>. Graphical parameters are passed to both. The main
difference is that <code>polygon</code>s may be filled and
non-transparent. With <code>none</code> nothing is drawn, but the function
returns the <code><a href="base.html#topic+invisible">invisible</a></code> plotting.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_col">col</code></td>
<td>
<p>Colour of hull or ellipse lines (if <code>draw = "lines"</code>)
or their fills (if <code>draw = "polygon"</code>) in <code>ordihull</code> and
<code>ordiellipse</code>.  When <code>draw = "polygon"</code>, the colour of
bordering lines can be set with argument <code>border</code> of the
<code><a href="graphics.html#topic+polygon">polygon</a></code> function. For other functions the effect
depends on the underlining functions this argument is passed to.
When multiple values of <code>col</code> are specified these are used
for each element of <code>names(table(groups))</code> (in that order),
shorter vectors are recycled. Function <code>ordicluster</code> has
no <code>groups</code>, and there the argument will be recycled for
points, and the colour of connecting lines is a mixture of point
s in the cluster.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_alpha">alpha</code></td>
<td>
<p>Transparency of the fill <code>col</code>our with <code>draw
    = "polygon"</code> in <code>ordihull</code> and <code>ordiellipse</code>.  The
argument takes precedence over possible transparency definitions
of the colour. The value must be in range <code class="reqn">0...255</code>, and low
values are more transparent.  Transparency is not available in all
graphics devices or file formats.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_show.groups">show.groups</code></td>
<td>
<p>Show only given groups. This can be a vector, or
<code>TRUE</code> if you want to show items for which condition is
<code>TRUE</code>. This argument makes it possible to use different
colours and line types for groups. The default is to show all groups. </p>
</td></tr>
<tr><td><code id="ordihull_+3A_label">label</code></td>
<td>
<p>Label the <code>groups</code> by their names in the centroid
of the object. <code>ordiellipse</code> and <code>ordihull</code> use standard
<code><a href="graphics.html#topic+text">text</a></code>, and others use <code><a href="#topic+ordilabel">ordilabel</a></code>.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_w">w</code></td>
<td>
<p>Weights used to find the average within group. Weights are
used automatically for <code><a href="#topic+cca">cca</a></code>
and <code><a href="#topic+decorana">decorana</a></code> results, unless undone by the
user. <code>w=NULL</code> sets equal weights to all points. </p>
</td></tr>
<tr><td><code id="ordihull_+3A_kind">kind</code></td>
<td>
<p>Draw standard deviations of points (<code>sd</code>), standard
errors (<code>se</code>) or ellipsoid hulls that enclose all points in
the group (<code>ehull</code>).</p>
</td></tr>
<tr><td><code id="ordihull_+3A_conf">conf</code></td>
<td>
<p>Confidence limit for ellipses, e.g. 0.95. If given, the
corresponding <code>sd</code> or <code>se</code> is multiplied with the
corresponding value found from the Chi-squared distribution with
2df. </p>
</td></tr>
<tr><td><code id="ordihull_+3A_spiders">spiders</code></td>
<td>
<p>Are centres or spider bodies calculated either as
centroids (averages) or spatial medians.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_cluster">cluster</code></td>
<td>
<p>Result of hierarchic cluster analysis, such as
<code><a href="stats.html#topic+hclust">hclust</a></code> or <code><a href="cluster.html#topic+agnes">agnes</a></code>.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_prune">prune</code></td>
<td>
<p>Number of upper level hierarchies removed from the
dendrogram. If <code>prune</code> <code class="reqn">&gt;0</code>, dendrogram will be
disconnected.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_object">object</code></td>
<td>
<p>A result object from <code>ordihull</code> or
<code>ordiellipse</code>. The result is <code><a href="base.html#topic+invisible">invisible</a></code>, but it
can be saved, and used for summaries (areas etc. of hulls and
ellipses). </p>
</td></tr>
<tr><td><code id="ordihull_+3A_area">area</code></td>
<td>
<p>Evaluate the area of convex hulls of <code>ordihull</code>, or of
ellipses of <code>ordiellipse</code>.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_lty">lty</code>, <code id="ordihull_+3A_lwd">lwd</code>, <code id="ordihull_+3A_border">border</code></td>
<td>
<p>Vectors of these parameters can be supplied
and will be applied (if appropriate) for each element of
<code>names(table(groups))</code> (in that order). Shorter vectors will be
recycled.</p>
</td></tr>
<tr><td><code id="ordihull_+3A_length">length</code></td>
<td>
<p>Width (in inches) of the small (&ldquo;caps&rdquo;) at the
ends of the bar segment (passed to <code><a href="graphics.html#topic+arrows">arrows</a></code>).</p>
</td></tr>
<tr><td><code id="ordihull_+3A_...">...</code></td>
<td>
<p>Parameters passed to graphical functions or to
<code><a href="#topic+scores">scores</a></code> to select axes and scaling etc. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>ordihull</code> draws <code><a href="graphics.html#topic+lines">lines</a></code> or
<code><a href="graphics.html#topic+polygon">polygon</a></code>s for the convex
hulls found by function <code><a href="grDevices.html#topic+chull">chull</a></code> encircling
the items in the groups.
</p>
<p>Function <code>ordiellipse</code> draws <code><a href="graphics.html#topic+lines">lines</a></code> or
<code><a href="graphics.html#topic+polygon">polygon</a></code>s for ellipses by <code>groups</code>. The function
can either draw standard deviation of points (<code>kind="sd"</code>) or
standard error of the (weighted) centroids (<code>kind="se"</code>), and
the (weighted) correlation defines the direction of the principal
axis of the ellipse. When <code>kind = "se"</code> is used together with
argument <code>conf</code>, the ellipses will show the confidence regions
for the locations of group centroids. With <code>kind="ehull"</code> the
function draws an ellipse that encloses all points of a group using
<code><a href="cluster.html#topic+ellipsoidhull">ellipsoidhull</a></code> (<span class="pkg">cluster</span> package).
</p>
<p>Function <code>ordibar</code> draws crossed &ldquo;error bars&rdquo; using
either either standard deviation of point scores or standard error
of the (weighted) average of scores. These are the principal axes of
the corresponding <code>ordiellipse</code>, and are found by principal
component analysis of the (weighted) covariance matrix.
</p>
<p>Functions <code>ordihull</code> and <code>ordiellipse</code> return invisibly an
object that has a <code>summary</code> method that returns the coordinates
of centroids and areas of the hulls or ellipses. Function
<code>ordiareatest</code> studies the one-sided hypothesis that these
areas are smaller than with randomized <code>groups</code>. Argument
<code>kind</code> can be used to select the kind of ellipse, and has no
effect with convex hulls.
</p>
<p>Function <code>ordispider</code> draws a &lsquo;spider&rsquo; diagram where
each point is connected to the group centroid with
<code><a href="graphics.html#topic+segments">segments</a></code>.  Weighted centroids are used in the
correspondence analysis methods <code><a href="#topic+cca">cca</a></code> and
<code><a href="#topic+decorana">decorana</a></code> or if the user gives the weights in the
call. If <code>ordispider</code> is called with <code><a href="#topic+cca">cca</a></code> or
<code><a href="#topic+rda">rda</a></code> result without <code>groups</code> argument, the
function connects each &lsquo;WA&rsquo; scores to the corresponding
&lsquo;LC&rsquo; score. If the argument is a (<code>invisible</code>)
<code>ordihull</code> object, the function will connect the points of the
hull to their centroid.
</p>
<p>Function <code>ordicluster</code> overlays a cluster dendrogram onto
ordination. It needs the result from a hierarchic clustering such as
<code><a href="stats.html#topic+hclust">hclust</a></code> or <code><a href="cluster.html#topic+agnes">agnes</a></code>, or other with
a similar structure. Function <code>ordicluster</code> connects cluster
centroids to each other with line <code><a href="graphics.html#topic+segments">segments</a></code>. Function
uses centroids of all points in the clusters, and is therefore
similar to average linkage methods.
</p>


<h3>Value</h3>

<p>Functions <code>ordihull</code>, <code>ordiellipse</code> and <code>ordispider</code>
return the <code><a href="base.html#topic+invisible">invisible</a></code> plotting structure.
</p>
<p>Function <code>ordispider</code> return the coordinates to which each
point is connected (centroids or &lsquo;LC&rsquo; scores).
</p>
<p>Function <code>ordihull</code> and <code>ordiellipse</code> return invisibly an
object that has a <code>summary</code> method that returns the coordinates
of centroids and areas of the hulls or ellipses. Function
<code>ordiareatest</code> studies the one-sided hypothesis that these
areas are smaller than with randomized <code>groups</code>.
</p>


<h3>Note</h3>

<p>These functions add graphical items to ordination graph: You
must draw a graph first. To draw line segments, grids or arrows, see
<code><a href="#topic+ordisegments">ordisegments</a></code>, <code><a href="#topic+ordigrid">ordigrid</a></code>
and<code><a href="#topic+ordiarrows">ordiarrows</a></code>.  </p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>See Also</h3>

<p>The functions pass parameters to basic graphical functions,
and you may wish to change the default values in
<code><a href="graphics.html#topic+lines">lines</a></code>, <code><a href="graphics.html#topic+segments">segments</a></code> and
<code><a href="graphics.html#topic+polygon">polygon</a></code>. You can pass parameters to
<code><a href="#topic+scores">scores</a></code> as well. Underlying functions for
<code>ordihull</code> is <code><a href="grDevices.html#topic+chull">chull</a></code>. The underlying function for
ellipsoid hulls in <code>ordiellipse</code> is
<code><a href="cluster.html#topic+ellipsoidhull">ellipsoidhull</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
mod &lt;- cca(dune ~ Management, dune.env)
plot(mod, type="n", scaling = "symmetric")
## Catch the invisible result of ordihull...
pl &lt;- with(dune.env, ordihull(mod, Management,
                              scaling = "symmetric", label = TRUE))
## ... and find centres and areas of the hulls
summary(pl)
## use more colours and add ellipsoid hulls
plot(mod, type = "n")
pl &lt;- with(dune.env, ordihull(mod, Management,
                              scaling = "symmetric", col = 1:4,
                              draw="polygon", label =TRUE))
with(dune.env, ordiellipse(mod, Management, scaling = "symmetric",
                           kind = "ehull", col = 1:4, lwd=3))
## ordispider to connect WA and LC scores
plot(mod, dis=c("wa","lc"), type="p")
ordispider(mod)
## Other types of plots
plot(mod, type = "p", display="sites")
cl &lt;- hclust(vegdist(dune))
ordicluster(mod, cl, prune=3, col = cutree(cl, 4))
## confidence ellipse: location of the class centroids
plot(mod, type="n", display = "sites")
with(dune.env, text(mod, display="sites", labels = as.character(Management),
                    col=as.numeric(Management)))
pl &lt;- with(dune.env, ordiellipse(mod, Management, kind="se", conf=0.95, lwd=2,
                                 draw = "polygon", col=1:4, border=1:4,
                                 alpha=63))
summary(pl)
## add confidence bars
with(dune.env, ordibar(mod, Management, kind="se", conf=0.95, lwd=2, col=1:4,
                       label=TRUE))
</code></pre>

<hr>
<h2 id='ordilabel'>Add Text on Non-transparent Label to an Ordination Plot. </h2><span id='topic+ordilabel'></span>

<h3>Description</h3>

<p> Function <code>ordilabel</code> is similar to
<code><a href="graphics.html#topic+text">text</a></code>, but the text is on an opaque label. This can help
in crowded ordination plots: you still cannot see all text labels, but
at least the uppermost are readable. Argument <code>priority</code> helps to
make the most important labels visible.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>ordilabel(x, display, labels, choices = c(1, 2), priority, select, 
    cex = 0.8, fill = "white", border = NULL, col = NULL, xpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordilabel_+3A_x">x</code></td>
<td>
<p>An ordination object an any object known to
<code><a href="#topic+scores">scores</a></code>. </p>
</td></tr> 
<tr><td><code id="ordilabel_+3A_display">display</code></td>
<td>
<p>Kind of scores displayed (passed to
<code><a href="#topic+scores">scores</a></code>). </p>
</td></tr> 
<tr><td><code id="ordilabel_+3A_labels">labels</code></td>
<td>
<p>Optional text used in plots. If this is not given, the
text is found from the ordination object.</p>
</td></tr>
<tr><td><code id="ordilabel_+3A_choices">choices</code></td>
<td>
<p>Axes shown (passed to <code><a href="#topic+scores">scores</a></code>). </p>
</td></tr>
<tr><td><code id="ordilabel_+3A_priority">priority</code></td>
<td>
<p>Vector of the same length as the number of
labels. The items with high priority will be plotted uppermost.</p>
</td></tr>
<tr><td><code id="ordilabel_+3A_select">select</code></td>
<td>
<p>Items to be displayed. This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of
indices of displayed items.</p>
</td></tr>
<tr><td><code id="ordilabel_+3A_cex">cex</code></td>
<td>
<p> Character expansion for the text (passed to
<code><a href="graphics.html#topic+text">text</a></code>). </p>
</td></tr> 
<tr><td><code id="ordilabel_+3A_fill">fill</code></td>
<td>
<p> Background colour of the labels (the <code>col</code> argument
of <code><a href="graphics.html#topic+polygon">polygon</a></code>).</p>
</td></tr>
<tr><td><code id="ordilabel_+3A_border">border</code></td>
<td>
<p>The colour and visibility of the border of the label as
defined in <code><a href="graphics.html#topic+polygon">polygon</a></code>.</p>
</td></tr>
<tr><td><code id="ordilabel_+3A_col">col</code></td>
<td>
<p>Text colour. Default <code>NULL</code> will give the value of
<code>border</code> or <code>par("fg")</code> if <code>border</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="ordilabel_+3A_xpd">xpd</code></td>
<td>
<p>Draw labels also outside the plot region (see 
<code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr> 
<tr><td><code id="ordilabel_+3A_...">...</code></td>
<td>
<p>Other arguments (passed to <code><a href="graphics.html#topic+text">text</a></code>). </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The function may be useful with crowded ordination plots, in
particular together with argument <code>priority</code>. You will not see
all text labels, but at least some are readable. Other alternatives to
crowded plots are <code><a href="#topic+identify.ordiplot">identify.ordiplot</a></code>,
<code><a href="#topic+orditorp">orditorp</a></code> and <code><a href="#topic+orditkplot">orditkplot</a></code>.  </p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>See Also</h3>

 <p><code><a href="#topic+scores">scores</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code>,
<code><a href="graphics.html#topic+text">text</a></code>. The function is modelled after
<code>s.label</code> in <span class="pkg">ade4</span> package.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
ord &lt;- cca(dune)
plot(ord, type = "n")
ordilabel(ord, dis="sites", cex=1.2, font=3, fill="hotpink", col="blue")
## You may prefer separate plots, but here species as well
ordilabel(ord, dis="sp", font=2, priority=colSums(dune))
</code></pre>

<hr>
<h2 id='ordiplot'> Alternative plot and identify Functions for Ordination </h2><span id='topic+ordiplot'></span><span id='topic+identify.ordiplot'></span><span id='topic+scores.ordiplot'></span><span id='topic+points.ordiplot'></span><span id='topic+text.ordiplot'></span>

<h3>Description</h3>

<p>Function <code>ordiplot</code> is an alternative plotting function which
can be worked with any <span class="pkg">vegan</span> ordination result and many
non-<span class="pkg">vegan</span> results. In addition, <code>plot</code> functions for
<span class="pkg">vegan</span> ordinations return invisibly an <code>"ordiplot"</code> result
object, and this allows using <code>ordiplot</code> support functions with
this result: <code>identify</code> can be used to add labels to selected
site, species or constraint points, and <code>points</code> and
<code>text</code> can add elements to the plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordiplot(ord, choices = c(1, 2), type="points", display, xlim, ylim,
     cex = 0.7, ...)
## S3 method for class 'ordiplot'
identify(x, what, labels,  ...)
## S3 method for class 'ordiplot'
points(x, what, select, arrows = FALSE, ...)
## S3 method for class 'ordiplot'
text(x, what, labels, select, arrows = FALSE,
    length = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordiplot_+3A_ord">ord</code></td>
<td>
<p>A result from an ordination.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_choices">choices</code></td>
<td>
<p>Axes shown. </p>
</td></tr>
<tr><td><code id="ordiplot_+3A_type">type</code></td>
<td>
<p>The type of graph which may be <code>"points"</code>,
<code>"text"</code> or <code>"none"</code> for any ordination method.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_display">display</code></td>
<td>
<p>Display only &quot;sites&quot; or &quot;species&quot;. The default for most
methods is to display both, but for <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code> and <code><a href="#topic+capscale">capscale</a></code> it is the same as in
<code><a href="#topic+plot.cca">plot.cca</a></code>.  </p>
</td></tr>
<tr><td><code id="ordiplot_+3A_xlim">xlim</code>, <code id="ordiplot_+3A_ylim">ylim</code></td>
<td>
<p>the x and y limits (min,max) of the plot.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_cex">cex</code></td>
<td>
<p>Character expansion factor for points and text.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters. </p>
</td></tr>
<tr><td><code id="ordiplot_+3A_x">x</code></td>
<td>
<p>A result object from <code>ordiplot</code>.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_what">what</code></td>
<td>
<p>Items identified in the ordination plot. The types depend
on the kind of plot used. Most methods know <code>sites</code> and
<code>species</code>, functions <code><a href="#topic+cca">cca</a></code> and <code><a href="#topic+rda">rda</a></code>
know in addition 
<code>constraints</code> (for LC scores), <code>centroids</code> and
<code>biplot</code>, and <code><a href="#topic+plot.procrustes">plot.procrustes</a></code> ordination plot has
<code>heads</code> and <code>points</code>.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_labels">labels</code></td>
<td>
<p>Optional text used for labels. Row names will be used if
this is missing.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_arrows">arrows</code></td>
<td>
<p>Draw arrows from the origin. This will always be
<code>TRUE</code> for biplot scores and its value will be ignored. Setting
this <code>TRUE</code> will draw arrows for any type of scores. This
allows, e.g, using biplot arrows for species. The arrow head will be
at the value of scores, and possible text is moved outwards.</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_length">length</code></td>
<td>
<p>Length of arrow heads (see <code><a href="graphics.html#topic+arrows">arrows</a></code>).</p>
</td></tr>
<tr><td><code id="ordiplot_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of indices
of displayed items.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>ordiplot</code> draws an ordination diagram using black circles for
sites and red crosses for species.  It returns invisibly an object of
class <code>ordiplot</code> which can be used by <code>identify.ordiplot</code>
to label selected sites or species, or constraints in
<code><a href="#topic+cca">cca</a></code> and <code><a href="#topic+rda">rda</a></code>.
</p>
<p>The function can handle output from several alternative ordination
methods. For <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code> and
<code><a href="#topic+decorana">decorana</a></code> it uses their <code>plot</code> method with option
<code>type = "points"</code>. In addition, the <code>plot</code> functions of
these methods return invisibly an <code>ordiplot</code> object which can
be used by <code>identify.ordiplot</code> to label points. For other
ordinations it relies on <code><a href="#topic+scores">scores</a></code> to extract the scores.
</p>
<p>For full user control of plots, it is best to call <code>ordiplot</code>
with <code>type = "none"</code> and save the result, and then add sites and
species using <code>points.ordiplot</code> or <code>text.ordiplot</code> which
both pass all their arguments to the corresponding default graphical
functions. The functions can be chained with pipes which allows an
alternative intuitive way of building up plots. 
</p>


<h3>Value</h3>

<p>Function <code>ordiplot</code> returns invisibly an object of class
<code>ordiplot</code> with used scores. In general, <span class="pkg">vegan</span> <code>plot</code>
functions for ordination results will also return an invisible
<code>ordiplot</code> object. If the <code>plot(..., type = "n")</code> was used
originally, the plot is empty, and items can be added with the
invisible object. Functions <code>points</code> and <code>text</code> will return
their input object without modification, which allows chaining these
commands with pipes. Function <code>identify.ordiplot</code> uses this
object to label the point.
</p>


<h3>Note</h3>

<p>The purpose of these functions is to provide similar functionality as
the <code>plot</code>, <code>plotid</code> and <code>specid</code> methods in library
<code>labdsv</code>. The functions are somewhat limited in parametrization,
but you can call directly the standard <code><a href="graphics.html#topic+identify">identify</a></code> and
<code><a href="graphics.html#topic+plot">plot</a></code> functions for a better user control.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen
</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+identify">identify</a></code> for basic operations, <code><a href="#topic+plot.cca">plot.cca</a></code>,
<code><a href="#topic+plot.decorana">plot.decorana</a></code>, <code><a href="#topic+plot.procrustes">plot.procrustes</a></code> which also
produce objects for
<code>identify.ordiplot</code> and <code><a href="#topic+scores">scores</a></code> for extracting
scores from non-<code>vegan</code> ordinations. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Draw a plot for a non-vegan ordination (cmdscale).
data(dune)
dune.dis &lt;- vegdist(wisconsin(dune))
dune.mds &lt;- cmdscale(dune.dis, eig = TRUE)
dune.mds$species &lt;- wascores(dune.mds$points, dune, expand = TRUE)
pl &lt;- ordiplot(dune.mds, type = "none")
points(pl, "sites", pch=21, col="red", bg="yellow")
text(pl, "species", col="blue", cex=0.9)
## Not run: 
## same plot using pipes (pipes |&gt; are available from R version 4.1.0)
if (getRversion() &gt;= "4.1") {
ordiplot(dune.mds, type="n") |&gt;
  points("sites", pch=21, col="red", bg="yellow") |&gt;
  text("species", col="blue", cex=0.9)
## Some people think that species should be shown with arrows in PCA.
## Other ordination methods also return an invisible ordiplot object and
## we can use pipes to draw those arrows.
mod &lt;- rda(dune)
plot(mod, type="n") |&gt;
  points("sites", pch=16, col="red") |&gt;
  text("species", arrows = TRUE, length=0.05, col="blue")
}

## End(Not run)
## Default plot of the previous using identify to label selected points
## Not run: 
pl &lt;- ordiplot(dune.mds)
identify(pl, "spec")
## End(Not run)
</code></pre>

<hr>
<h2 id='ordipointlabel'> Ordination Plots with Points and Optimized Locations for Text </h2><span id='topic+ordipointlabel'></span><span id='topic+plot.ordipointlabel'></span>

<h3>Description</h3>

<p>The function <code>ordipointlabel</code> produces ordination plots with
points and text label to the points. The points are in the exact
location given by the ordination, but the function tries to optimize
the location of the text labels to minimize overplotting text. The
function may be useful with moderately crowded ordination plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordipointlabel(x, display = c("sites", "species"), choices = c(1, 2),
   col = c(1, 2),  pch = c("o", "+"), font = c(1, 1), 
   cex = c(0.8, 0.8), add = FALSE, select, ...)

## S3 method for class 'ordipointlabel'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordipointlabel_+3A_x">x</code></td>
<td>
<p>For <code>ordipointlabel()</code> a result object from an
ordination function. For <code>plot.ordipointlabel</code> an object
resulting from a call to <code>ordipointlabel()</code>.</p>
</td></tr>
<tr><td><code id="ordipointlabel_+3A_display">display</code></td>
<td>
<p>Scores displayed in the plot. </p>
</td></tr>
<tr><td><code id="ordipointlabel_+3A_choices">choices</code></td>
<td>
<p>Axes shown. </p>
</td></tr>
<tr><td><code id="ordipointlabel_+3A_col">col</code>, <code id="ordipointlabel_+3A_pch">pch</code>, <code id="ordipointlabel_+3A_font">font</code>, <code id="ordipointlabel_+3A_cex">cex</code></td>
<td>
<p>Colours, point types, font style and
character expansion for each kind of scores displayed in the
plot. These should be vectors of the same length as the number of
items in <code>display</code>.</p>
</td></tr>
<tr><td><code id="ordipointlabel_+3A_add">add</code></td>
<td>
<p> Add to an existing plot. </p>
</td></tr>
<tr><td><code id="ordipointlabel_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of indices
of displayed items. <code>select</code> is only used if a single set of
scores is being plotted (i.e. <code>length(display) == 1</code>),
otherwise it is ignored and a warning issued. If a logical vector is
used, it must have the same length as the scores plotted.</p>
</td></tr>
<tr><td><code id="ordipointlabel_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="graphics.html#topic+points">points</a></code> and
<code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses simulated annealing (<code><a href="stats.html#topic+optim">optim</a></code>,
<code>method = "SANN"</code>) to optimize the location of the text labels
to the points. There are eight possible locations: up, down, sides
and corners. There is a weak preference to text right above the
point, and a weak avoidance of corner positions. The exact locations
and the goodness of solution varies between runs, and there is no
guarantee of finding the global optimum. The optimization can take a
long time in difficult cases with a high number of potential
overlaps. Several sets of scores can be displayed in one plot. 
</p>
<p>The function is modelled after <code>pointLabel</code> in the
<span class="pkg">maptools</span> package.
</p>


<h3>Value</h3>

<p>The function returns invisibly an object of class
<code>ordipointlabel</code> with items <code>xy</code> for coordinates of
points, <code>labels</code> for coordinates of labels, items <code>pch</code>,
<code>cex</code> and <code>font</code> for graphical parameters of each point or
label. In addition, it returns the result of <code><a href="stats.html#topic+optim">optim</a></code> as
an attribute <code>"optim"</code>. The unit of overlap is the area
of character <code>"m"</code>, and with variable <code>cex</code> it is the
smallest alternative.
</p>
<p>There is a <code>plot</code> method based on <code>orditkplot</code> but which
does not alter nor reset the graphical parameters via <code>par</code>.
</p>
<p>The result object from <code>ordipointlabel</code> inherits from
<code><a href="#topic+orditkplot">orditkplot</a></code>, and can also be replotted with its
<code>plot</code> method. It may be possible to further edit the result
object with <code><a href="#topic+orditkplot">orditkplot</a></code>, but for good results it is
necessary that the points span the whole horizontal axis without empty
margins. 
</p>


<h3>Note</h3>

 
<p>The function is designed for ordination graphics, and the
optimization works properly with plots of isometric aspect ratio.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
ord &lt;- cca(dune)
plt &lt;- ordipointlabel(ord)

## set scaling - should be no warnings!
ordipointlabel(ord, scaling = "sites")

## plot then add
plot(ord, scaling = "symmetric", type = "n")
ordipointlabel(ord, display = "species", scaling = "symm", add = TRUE)
ordipointlabel(ord, display = "sites", scaling = "symm", add = TRUE)

## redraw plot without rerunning SANN optimisation
plot(plt)
</code></pre>

<hr>
<h2 id='ordiresids'>Plots of Residuals and Fitted Values for Constrained Ordination</h2><span id='topic+ordiresids'></span>

<h3>Description</h3>

<p>The function provides <code><a href="stats.html#topic+plot.lm">plot.lm</a></code> style diagnostic plots for
the results of constrained ordination from <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code> and <code><a href="#topic+capscale">capscale</a></code>. Normally you do not need
these plots, because ordination is descriptive and does not
make assumptions on the distribution of the residuals. However, if
you permute residuals in significance tests (<code><a href="#topic+anova.cca">anova.cca</a></code>),
you may be interested in inspecting that the residuals really are
exchangeable and independent of fitted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordiresids(x, kind = c("residuals", "scale", "qqmath"),
   residuals = "working", type = c("p", "smooth", "g"),
   formula, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordiresids_+3A_x">x</code></td>
<td>
<p>Ordination result from <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>
or <code><a href="#topic+capscale">capscale</a></code>. </p>
</td></tr>
<tr><td><code id="ordiresids_+3A_kind">kind</code></td>
<td>
<p>The type of plot: <code>"residuals"</code> plot residuals
against fitted values, <code>"scale"</code> the square root of absolute
residuals against fitted values, and <code>"qqmath"</code> the residuals
against expected distribution (defaults <code><a href="stats.html#topic+qnorm">qnorm</a></code>),
unless defined differently in the <code>formula</code>  argument. </p>
</td></tr>
<tr><td><code id="ordiresids_+3A_residuals">residuals</code></td>
<td>
<p>The kind of residuals and fitted values, with alternatives
<code>"working"</code>, <code>"response"</code>, <code>"standardized"</code> and
<code>"studentized"</code> (see Details).</p>
</td></tr>
<tr><td><code id="ordiresids_+3A_type">type</code></td>
<td>
<p>The type of plot. The argument is passed on to
<span class="pkg">lattice</span> functions. </p>
</td></tr>
<tr><td><code id="ordiresids_+3A_formula">formula</code></td>
<td>
<p>Formula to override the default plot. The formula can
contain items <code>Fitted</code>, <code>Residuals</code>, <code>Species</code> and
<code>Sites</code> (provided that names of species and sites are available
in the ordination result).  </p>
</td></tr>
<tr><td><code id="ordiresids_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <span class="pkg">lattice</span> functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default plots are similar as in <code><a href="stats.html#topic+plot.lm">plot.lm</a></code>, but they
use <code><a href="lattice.html#topic+Lattice">Lattice</a></code> functions
<code><a href="lattice.html#topic+xyplot">xyplot</a></code> and <code><a href="lattice.html#topic+qqmath">qqmath</a></code>. The
alternatives have default formulae but these can be replaced by the
user. The elements available in formula or in the <code>groups</code> argument
are <code>Fitted</code>, <code>Residuals</code>, <code>Species</code> and <code>Sites</code>.
</p>
<p>With <code>residuals = "response"</code> and <code>residuals = "working"</code>
the fitted values and residuals are found with functions
<code><a href="#topic+fitted.cca">fitted.cca</a></code> and <code><a href="#topic+residuals.cca">residuals.cca</a></code>. With
<code>residuals = "standardized"</code> the residuals are found with
<code><a href="#topic+rstandard.cca">rstandard.cca</a></code>, and with <code>residuals = "studentized"</code>
they are found with <code><a href="#topic+rstudent.cca">rstudent.cca</a></code>, and in both cases the
fitted values are standardized with <code><a href="#topic+sigma.cca">sigma.cca</a></code>.
</p>


<h3>Value</h3>

<p>The function returns a <code><a href="lattice.html#topic+Lattice">Lattice</a></code> object that can
displayed as plot.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+plot.lm">plot.lm</a></code>, <code><a href="#topic+fitted.cca">fitted.cca</a></code>,
<code><a href="#topic+residuals.cca">residuals.cca</a></code>, <code><a href="#topic+rstandard.cca">rstandard.cca</a></code>,
<code><a href="#topic+rstudent.cca">rstudent.cca</a></code>, <code><a href="#topic+sigma.cca">sigma.cca</a></code>,
<code><a href="lattice.html#topic+Lattice">Lattice</a></code>, <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+qqmath">qqmath</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
mod &lt;- cca(varespec ~ Al + P + K, varechem)
ordiresids(mod)
ordiresids(mod, formula = Residuals ~ Fitted | Species, residuals="standard",
   cex = 0.5)
</code></pre>

<hr>
<h2 id='ordistep'>
Choose a Model by Permutation Tests in Constrained Ordination
</h2><span id='topic+ordistep'></span><span id='topic+ordiR2step'></span>

<h3>Description</h3>

<p>Automatic stepwise model building for constrained ordination methods
(<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+capscale">capscale</a></code>).
The function <code>ordistep</code> is modelled after <code><a href="stats.html#topic+step">step</a></code> and
can do forward, backward and stepwise model selection using permutation tests.
Function <code>ordiR2step</code> performs forward model choice solely on adjusted
<code class="reqn">R^2</code> and P-value, for ordination objects created by <code><a href="#topic+rda">rda</a></code> or <code><a href="#topic+capscale">capscale</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordistep(object, scope, direction = c("both", "backward", "forward"),
   Pin = 0.05, Pout = 0.1, permutations = how(nperm = 199), steps = 50,
   trace = TRUE, ...)
ordiR2step(object, scope, Pin = 0.05, R2scope = TRUE,
   permutations = how(nperm = 499), trace = TRUE, R2permutations = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordistep_+3A_object">object</code></td>
<td>

<p>In <code>ordistep</code>, an ordination object inheriting from
<code><a href="#topic+cca">cca</a></code> or <code><a href="#topic+rda">rda</a></code>.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_scope">scope</code></td>
<td>
<p> Defines the range of models examined in the stepwise
search.  This can be a list containing components <code>upper</code> and
<code>lower</code>, both formulae. If it is a single item, it is interpreted
the target scope, depending on the <code>direction</code>. If
<code>direction</code> is <code>"forward"</code>, a single item is interpreted as
the <code>upper</code> scope and the formula of the input <code>object</code> as
the <code>lower</code> scope.  See <code><a href="stats.html#topic+step">step</a></code> for details. In
<code>ordiR2step</code>, this defines the upper scope; it can also be an
ordination object from with the model is extracted.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_direction">direction</code></td>
<td>

<p>The mode of stepwise search, can be one of <code>"both"</code>,
<code>"backward"</code>, or <code>"forward"</code>, with a default of
<code>"both"</code>.  If the <code>scope</code> argument is missing, the default
for <code>direction</code> is <code>"backward"</code> in <code>ordistep</code> (and
<code>ordiR2step</code> does not have this argument, but only works
forward).
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_pin">Pin</code>, <code id="ordistep_+3A_pout">Pout</code></td>
<td>

<p>Limits of permutation <code class="reqn">P</code>-values for adding (<code>Pin</code>) a term to
the model, or dropping (<code>Pout</code>) from the model. Term is added if
<code class="reqn">P \le</code> <code>Pin</code>, and removed if <code class="reqn">P &gt;</code> <code>Pout</code>.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_r2scope">R2scope</code></td>
<td>

<p>Use adjusted <code class="reqn">R^2</code> as the stopping criterion: only models with
lower adjusted <code class="reqn">R^2</code> than scope are accepted.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations as
returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the number
of permutations required, or a permutation matrix where each row
gives the permuted indices. This is passed to
<code><a href="#topic+anova.cca">anova.cca</a></code>: see there for details.  </p>
</td></tr>
<tr><td><code id="ordistep_+3A_steps">steps</code></td>
<td>

<p>Maximum number of iteration steps of dropping and adding terms.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_trace">trace</code></td>
<td>

<p>If positive, information is printed during the model building. Larger
values may give more information.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_r2permutations">R2permutations</code></td>
<td>
<p>Number of permutations used in the estimation of
adjusted <code class="reqn">R^2</code> for <code><a href="#topic+cca">cca</a></code> using
<code><a href="#topic+RsquareAdj">RsquareAdj</a></code>.
</p>
</td></tr>
<tr><td><code id="ordistep_+3A_...">...</code></td>
<td>

<p>Any additional arguments to <code><a href="#topic+add1.cca">add1.cca</a></code> and
<code><a href="#topic+drop1.cca">drop1.cca</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic functions for model choice in constrained ordination are
<code><a href="#topic+add1.cca">add1.cca</a></code> and <code><a href="#topic+drop1.cca">drop1.cca</a></code>. With these functions,
ordination models can be chosen with standard <span class="rlang"><b>R</b></span> function
<code><a href="stats.html#topic+step">step</a></code> which bases the term choice on AIC. AIC-like
statistics for ordination are provided by functions
<code><a href="#topic+deviance.cca">deviance.cca</a></code> and <code><a href="#topic+extractAIC.cca">extractAIC.cca</a></code> (with
similar functions for <code><a href="#topic+rda">rda</a></code>). Actually, constrained
ordination methods do not have AIC, and therefore the <code><a href="stats.html#topic+step">step</a></code>
may not be trusted. This function provides an alternative using
permutation <code class="reqn">P</code>-values.
</p>
<p>Function <code>ordistep</code> defines the model, <code>scope</code> of models
considered, and <code>direction</code> of the procedure similarly as
<code><a href="stats.html#topic+step">step</a></code>. The function alternates with <code>drop</code> and
<code>add</code> steps and stops when the model was not changed during one
step. The <code>-</code> and <code>+</code> signs in the summary table indicate
which stage is performed.  It is often sensible to have <code>Pout</code>
<code class="reqn">&gt;</code> <code>Pin</code> in stepwise models to avoid cyclic adds and drops
of single terms.
</p>
<p>Function <code>ordiR2step</code> builds model forward so that it maximizes
adjusted <code class="reqn">R^2</code> (function <code><a href="#topic+RsquareAdj">RsquareAdj</a></code>) at every
step, and stopping when the adjusted <code class="reqn">R^2</code> starts to decrease,
or the adjusted <code class="reqn">R^2</code> of the <code>scope</code> is exceeded, or the
selected permutation <code class="reqn">P</code>-value is exceeded (Blanchet et
al. 2008). The second criterion is ignored with option
<code>R2scope = FALSE</code>, and the third criterion can be ignored setting
<code>Pin = 1</code> (or higher).
The function cannot be used if adjusted <code class="reqn">R^2</code>
cannot be calculated, including partial models.  If the number of
predictors is higher than the number of observations, adjusted
<code class="reqn">R^2</code> is also unavailable, but such models can be analysed
with <code>R2scope = FALSE</code>.  The <code class="reqn">R^2</code> of <code><a href="#topic+cca">cca</a></code>
is based on simulations (see <code><a href="#topic+RsquareAdj">RsquareAdj</a></code>) and different
runs of <code>ordiR2step</code> can give different results.
</p>
<p>Functions <code>ordistep</code> (based on <code class="reqn">P</code> values) and <code>ordiR2step</code>
(based on adjusted <code class="reqn">R^2</code> and hence on eigenvalues) can select
variables in different order.
</p>


<h3>Value</h3>

<p>Functions return the selected model with one additional
component, <code>anova</code>, which contains brief information of steps
taken. You can suppress voluminous output during model building by
setting <code>trace = FALSE</code>, and find the summary of model history
in the <code>anova</code> item.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen
</p>


<h3>References</h3>

<p>Blanchet, F. G., Legendre, P. &amp; Borcard, D. (2008) Forward selection
of explanatory variables. <em>Ecology</em> 89, 2623&ndash;2632.
</p>


<h3>See Also</h3>

<p>The function handles constrained ordination methods
<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code> and
<code><a href="#topic+capscale">capscale</a></code>. The underlying functions are
<code><a href="#topic+add1.cca">add1.cca</a></code> and <code><a href="#topic+drop1.cca">drop1.cca</a></code>, and the function
is modelled after standard <code><a href="stats.html#topic+step">step</a></code> (which also can be
used directly but uses AIC for model choice, see
<code><a href="#topic+extractAIC.cca">extractAIC.cca</a></code>). Function <code>ordiR2step</code> builds
upon <code><a href="#topic+RsquareAdj">RsquareAdj</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See add1.cca for another example

### Dune data
data(dune)
data(dune.env)
mod0 &lt;- rda(dune ~ 1, dune.env)  # Model with intercept only
mod1 &lt;- rda(dune ~ ., dune.env)  # Model with all explanatory variables

## With scope present, the default direction is "both"
mod &lt;- ordistep(mod0, scope = formula(mod1))
mod
## summary table of steps
mod$anova

## Example of ordistep, forward
ordistep(mod0, scope = formula(mod1), direction="forward")

## Example of ordiR2step (always forward)
## stops because R2 of 'mod1' exceeded
ordiR2step(mod0, mod1)
</code></pre>

<hr>
<h2 id='ordisurf'> Fit and Plot Smooth Surfaces of Variables on Ordination. </h2><span id='topic+ordisurf'></span><span id='topic+ordisurf.default'></span><span id='topic+ordisurf.formula'></span><span id='topic+calibrate.ordisurf'></span><span id='topic+plot.ordisurf'></span>

<h3>Description</h3>

<p>Function <code>ordisurf</code> fits a smooth surface for given variable and
plots the result on ordination diagram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
ordisurf(x, y, choices = c(1, 2), knots = 10,
         family = "gaussian", col = "red", isotropic = TRUE,
         thinplate = TRUE, bs = "tp", fx = FALSE, add = FALSE,
         display = "sites", w = weights(x, display), main, nlevels = 10,
         levels, npoints = 31, labcex = 0.6, bubble = FALSE,
         cex = 1, select = TRUE, method = "REML", gamma = 1,
         plot = TRUE, lwd.cl = par("lwd"), ...)

## S3 method for class 'formula'
ordisurf(formula, data, ...)

## S3 method for class 'ordisurf'
calibrate(object, newdata, ...)

## S3 method for class 'ordisurf'
plot(x, what = c("contour","persp","gam"),
     add = FALSE, bubble = FALSE, col = "red", cex = 1,
     nlevels = 10, levels, labcex = 0.6, lwd.cl = par("lwd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordisurf_+3A_x">x</code></td>
<td>
<p>For <code>ordisurf</code> an ordination configuration, either a
matrix or a result known by <code><a href="#topic+scores">scores</a></code>. For
<code>plot.ordisurf</code> an object of class <code>"ordisurf"</code> as
returned by <code>ordisurf</code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_y">y</code></td>
<td>
<p>Variable to be plotted / modelled as a function of the
ordination scores.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_choices">choices</code></td>
<td>
<p>Ordination axes. </p>
</td></tr>
<tr><td><code id="ordisurf_+3A_knots">knots</code></td>
<td>
<p>Number of initial knots in <code><a href="mgcv.html#topic+gam">gam</a></code> (one
more than degrees of freedom). If <code>knots = 0</code> or
<code>knots = 1</code>  the function will fit a linear trend surface, and
if <code>knots = 2</code> the function  will fit a quadratic trend surface
instead of a smooth surface. A vector of length 2 is allowed when
<code>isotropic = FALSE</code>, with the first and second elements of
<code>knots</code> referring to the first and second of ordination
dimensions (as indicated by <code>choices</code>) respectively.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_family">family</code></td>
<td>
<p>Error distribution in <code><a href="mgcv.html#topic+gam">gam</a></code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_col">col</code></td>
<td>
<p> Colour of contours. </p>
</td></tr>
<tr><td><code id="ordisurf_+3A_isotropic">isotropic</code>, <code id="ordisurf_+3A_thinplate">thinplate</code></td>
<td>
<p>Fit an isotropic smooth surface (i.e. same
smoothness in both ordination dimensions) via
<code><a href="mgcv.html#topic+gam">gam</a></code>. Use of <code>thinplate</code> is deprecated and
will be removed in a future version of the package.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_bs">bs</code></td>
<td>
<p>a two letter character string indicating the smoothing basis
to use. (e.g. <code>"tp"</code> for thin plate regression spline,
<code>"cr"</code> for cubic regression spline). One of <code>c("tp", "ts",
      "cr", "cs", "ds", "ps", "ad")</code>. See
<code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code> for an over view of what these
refer to. The default is to use thin plate splines: <code>bs = "tp"</code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_fx">fx</code></td>
<td>
<p>indicates whether the smoothers are fixed degree of freedom
regression splines (<code>fx = FALSE</code>) or penalised regression
splines (<code>fx = TRUE</code>). Can be a vector of length 2 for
anisotropic surfaces (<code>isotropic = FALSE</code>). It doesn't make
sense to use <code>fx = TRUE</code> <strong>and</strong> <code>select = TRUE</code> and
it is an <strong>error</strong> to do so. A warning is issued if you specify
<code>fx = TRUE</code> and forget to use <code>select = FALSE</code> though
fitting continues using <code>select = FALSE</code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_add">add</code></td>
<td>
<p>Add contours to an existing diagram or draw a new plot?</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_display">display</code></td>
<td>
<p>Type of scores known by <code><a href="#topic+scores">scores</a></code>: typically
&quot;sites&quot; for ordinary site scores or &quot;lc&quot; for linear combination scores.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_w">w</code></td>
<td>
<p>Prior weights on the data. Concerns mainly <code><a href="#topic+cca">cca</a></code>
and <code><a href="#topic+decorana">decorana</a></code> results which have nonconstant weights.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_main">main</code></td>
<td>
<p>The main title for the plot, or as default the name of
plotted variable in a new plot.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_nlevels">nlevels</code>, <code id="ordisurf_+3A_levels">levels</code></td>
<td>
<p>Either a vector of <code>levels</code> for which contours
are drawn, or suggested number of contours in <code>nlevels</code> if
<code>levels</code> are not supplied.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_npoints">npoints</code></td>
<td>
<p>numeric; the number of locations at which to evaluate
the fitted surface. This represents the number of locations in each
dimension.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_labcex">labcex</code></td>
<td>
<p>Label size in contours.  Setting this zero will suppress
labels.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_bubble">bubble</code></td>
<td>
<p>Use a &ldquo;bubble plot&rdquo; for points, or vary the point
diameter by the value of the plotted variable. If <code>bubble</code> is
numeric, its value is used for the maximum symbol size (as in
<code>cex</code>), or if <code>bubble = TRUE</code>, the value of <code>cex</code> gives
the maximum. The minimum size will always be <code>cex = 0.4</code>.  The
option only has an effect if <code>add = FALSE</code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_cex">cex</code></td>
<td>
<p>Character expansion of plotting symbols.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_select">select</code></td>
<td>
<p>Logical; specify <code><a href="mgcv.html#topic+gam">gam</a></code> argument
<code>"select"</code>. If this is <code>TRUE</code> then <code><a href="mgcv.html#topic+gam">gam</a></code> can
add an extra  penalty to each term so that it can be penalized to
zero. This means that the smoothing parameter estimation that is part
of fitting can completely remove terms from the model. If the
corresponding smoothing parameter is estimated as zero then the extra
penalty has no effect.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_method">method</code></td>
<td>
<p>character; the smoothing parameter estimation
method. Options allowed are: <code>"GCV.Cp"</code> uses GCV for models with
unknown scale parameter and Mallows' Cp/UBRE/AIC for models with
known scale; <code>"GACV.Cp"</code> as for <code>"GCV.Cp"</code> but uses GACV
(Generalised Approximate CV) instead of GCV; <code>"REML"</code> and
<code>"ML"</code> use restricted maximum likelihood or maximum likelihood
estimation for both known and unknown scale; and <code>"P-REML"</code> and
<code>"P-ML"</code> use REML or ML estimation but use a Pearson estimate
of the scale.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_gamma">gamma</code></td>
<td>
<p>Multiplier to inflate model degrees of freedom in GCV or
UBRE/AIC score by. This effectively places an extra penalty on
complex models. An oft-used value is <code>gamma = 1.4</code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_plot">plot</code></td>
<td>
<p>logical; should any plotting be done by
<code>ordisurf</code>? Useful if all you want is the fitted response
surface model.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_lwd.cl">lwd.cl</code></td>
<td>
<p>numeric; the <code>lwd</code> (line width) parameter to use
when drawing the contour lines.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_formula">formula</code>, <code id="ordisurf_+3A_data">data</code></td>
<td>
<p>Alternative definition of the fitted model as
<code>x ~ y</code>, where left-hand side is the ordination <code>x</code> and
right-hand side the single fitted continuous variable
<code>y</code>. The variable <code>y</code> must be in the working environment
or in the data frame or environment given by <code>data</code>. All
other arguments of are passed to the default method.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_object">object</code></td>
<td>
<p>An <code>ordisurf</code> result object.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_newdata">newdata</code></td>
<td>
<p>Coordinates in two-dimensional ordination for new
points.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_what">what</code></td>
<td>
<p>character; what type of plot to produce. <code>"contour"</code>
produces a contour plot of the response surface, see
<code><a href="graphics.html#topic+contour">contour</a></code> for details. <code>"persp"</code> produces a
perspective plot of the same, see <code><a href="graphics.html#topic+persp">persp</a></code> for
details. <code>"gam"</code> plots the fitted GAM model, an object that
inherits from class <code>"gam"</code> returned by <code>ordisurf</code>, see
<code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>.</p>
</td></tr>
<tr><td><code id="ordisurf_+3A_...">...</code></td>
<td>
<p>Other parameters passed to <code><a href="#topic+scores">scores</a></code>, or
to the graphical functions. See Note below for exceptions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>ordisurf</code> fits a smooth surface using penalised
splines (Wood 2003) in <code><a href="mgcv.html#topic+gam">gam</a></code>, and uses
<code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> to find fitted values in a regular
grid. The smooth surface can be fitted with an extra penalty that
allows the entire smoother to be penalized back to 0 degrees of
freedom, effectively removing the term from the model (see Marra &amp;
Wood, 2011). The addition of this extra penalty is invoked by
setting argument <code>select</code> to <code>TRUE</code>. An alternative is to
use a spline basis that includes shrinkage (<code>bs = "ts"</code> or
<code>bs = "cs"</code>).
</p>
<p><code>ordisurf()</code> exposes a large number of options from
<code><a href="mgcv.html#topic+gam">gam</a></code> for specifying the basis functions used for
the surface. If you stray from the defaults, do read the
<strong>Notes</strong> section below and relevant documentation in
<code><a href="mgcv.html#topic+s">s</a></code> and <code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code>.
</p>
<p>The function plots the fitted contours with convex hull of data points
either over an existing ordination diagram or draws a new plot. If
<code>select = TRUE</code> and the smooth is effectively penalised out of
the model, no contours will be plotted.
</p>
<p><code><a href="mgcv.html#topic+gam">gam</a></code> determines the degree of smoothness for the
fitted response surface during model fitting, unless <code>fx =
  TRUE</code>. Argument <code>method</code> controls how <code><a href="mgcv.html#topic+gam">gam</a></code>
performs this smoothness selection. See <code><a href="mgcv.html#topic+gam">gam</a></code> for
details of the available options. Using <code>"REML"</code> or <code>"ML"</code>
yields p-values for smooths with the best coverage properties if such
things matter to you.
</p>
<p>The function uses <code><a href="#topic+scores">scores</a></code> to extract ordination scores,
and <code>x</code> can be any result object known by that function.
</p>
<p>The user can supply a vector of prior weights <code>w</code>. If the
ordination object has weights, these will be used. In practise this
means that the row totals are used as weights with <code><a href="#topic+cca">cca</a></code>
or <code><a href="#topic+decorana">decorana</a></code> results. If you do not like this, but want
to give equal weights to all sites, you should set <code>w =
  NULL</code>. The behaviour is consistent with <code><a href="#topic+envfit">envfit</a></code>. For
complete accordance with constrained <code><a href="#topic+cca">cca</a></code>, you should set
<code>display = "lc"</code>.
</p>
<p>Function <code>calibrate</code> returns the fitted values of the response
variable. The <code>newdata</code> must be coordinates of points for which
the fitted values are desired. The function is based on
<code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> and will pass extra arguments to
that function.
</p>


<h3>Value</h3>

<p><code>ordisurf</code> is usually called for its side effect of drawing the
contour plot. The function returns a result object of class
<code>"ordisurf"</code> that inherits from <code><a href="mgcv.html#topic+gam">gam</a></code> used
internally to fit the surface, but adds an item <code>grid</code> that
contains the data for the grid surface. The item <code>grid</code> has
elements <code>x</code> and <code>y</code> which are vectors of axis coordinates,
and element <code>z</code> that is a matrix of fitted values for
<code><a href="graphics.html#topic+contour">contour</a></code>. The values outside the convex hull of observed
points are indicated as <code>NA</code> in <code>z</code>. The
<code><a href="mgcv.html#topic+gam">gam</a></code> component of the result can be used for
further analysis like predicting new values (see
<code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>).
</p>


<h3>Warning</h3>

<p>The fitted GAM is a regression model and has the usual assumptions of
such models. Of particular note is the assumption of independence of
residuals. If the observations are not independent (e.g. they are
repeat measures on a set of objects, or from an experimental design,
<em>inter alia</em>) do not trust the <em>p</em>-values from the GAM
output.
</p>
<p>If you need further control (i.e. to add additional fixed effects to
the model, or use more complex smoothers), extract the ordination
scores using the <code>scores</code> function and then generate your own
<code><a href="mgcv.html#topic+gam">gam</a></code> call.
</p>


<h3>Note</h3>

<p>The default is to use an isotropic smoother via
<code><a href="mgcv.html#topic+s">s</a></code> employing thin plate regression splines
(<code>bs = "tp"</code>). These make sense in ordination as they have
equal smoothing in all directions and are rotation invariant. However,
if different degrees of smoothness along dimensions are required, an
anisotropic smooth surface may be more applicable. This can be
achieved through the use of <code>isotropic = FALSE</code>, wherein the
surface is fitted via a tensor product smoother via
<code><a href="mgcv.html#topic+te">te</a></code> (unless <code>bs = "ad"</code>, in which case
separate splines for each dimension are fitted using
<code><a href="mgcv.html#topic+s">s</a></code>).
</p>
<p>Cubic regression splines and P splines can <strong>only</strong> be used with
<code>isotropic = FALSE</code>.
</p>
<p>Adaptive smooths (<code>bs = "ad"</code>), especially in two dimensions,
require a large number of observations; without many hundreds of
observations, the default complexities for the smoother will exceed
the number of observations and fitting will fail.
</p>
<p>To get the old behaviour of <code>ordisurf</code> use <code>select = FALSE</code>,
<code>method = "GCV.Cp"</code>, <code>fx = FALSE</code>, and <code>bs = "tp"</code>. The
latter two options are the current defaults.
</p>
<p>Graphical arguments supplied to <code>plot.ordisurf</code> are passed on to
the underlying plotting functions, <code>contour</code>, <code>persp</code>, and
<code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>. The exception to this is that arguments
<code>col</code> and <code>cex</code> can not currently be passed to
<code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code> because of a bug in the way that function
evaluates arguments when arranging the plot.
</p>
<p>A work-around is to call <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code> directly on the
result of a call to <code>ordisurf</code>. See the Examples for an
illustration of this.
</p>


<h3>Author(s)</h3>

<p> Dave Roberts, Jari Oksanen and Gavin L. Simpson </p>


<h3>References</h3>

<p>Marra, G.P &amp; Wood, S.N. (2011) Practical variable selection for
generalized additive models. <em>Comput. Stat. Data Analysis</em> 55,
2372&ndash;2387.
</p>
<p>Wood, S.N. (2003) Thin plate regression splines.
<em>J. R. Statist. Soc. B</em> 65, 95&ndash;114.
</p>


<h3>See Also</h3>

<p> For basic routines <code><a href="mgcv.html#topic+gam">gam</a></code>,
and <code><a href="#topic+scores">scores</a></code>. Function
<code><a href="#topic+envfit">envfit</a></code> provides a more traditional and compact
alternative. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
vare.dist &lt;- vegdist(varespec)
vare.mds &lt;- monoMDS(vare.dist)
## IGNORE_RDIFF_BEGIN
ordisurf(vare.mds ~ Baresoil, varechem, bubble = 5)

## as above but without the extra penalties on smooth terms,
## and using GCV smoothness selection (old behaviour of `ordisurf()`):
ordisurf(vare.mds ~ Baresoil, varechem, col = "blue", add = TRUE,
                        select = FALSE, method = "GCV.Cp")

## Cover of Cladina arbuscula
fit &lt;- ordisurf(vare.mds ~ Cladarbu, varespec, family=quasipoisson)
## Get fitted values
calibrate(fit)
## Variable selection via additional shrinkage penalties
## This allows non-significant smooths to be selected out
## of the model not just to a linear surface. There are 2
## options available:
##  - option 1: `select = TRUE` --- the *default*
ordisurf(vare.mds ~ Baresoil, varechem, method = "REML", select = TRUE)
##  - option 2: use a basis with shrinkage
ordisurf(vare.mds ~ Baresoil, varechem, method = "REML", bs = "ts")
## or bs = "cs" with `isotropic = FALSE`
## IGNORE_RDIFF_END
## Plot method
plot(fit, what = "contour")

## Plotting the "gam" object
plot(fit, what = "gam") ## 'col' and 'cex' not passed on
## or via plot.gam directly
library(mgcv)
plot.gam(fit, cex = 2, pch = 1, col = "blue")
## 'col' effects all objects drawn...

### controlling the basis functions used
## Use Duchon splines
ordisurf(vare.mds ~ Baresoil, varechem, bs = "ds")

## A fixed degrees of freedom smooth, must use 'select = FALSE'
ordisurf(vare.mds ~ Baresoil, varechem, knots = 4,
                        fx = TRUE, select = FALSE)

## An anisotropic smoother with cubic regression spline bases
ordisurf(vare.mds ~ Baresoil, varechem, isotropic = FALSE,
                        bs = "cr", knots = 4)

## An anisotropic smoother with cubic regression spline with
## shrinkage bases &amp; different degrees of freedom in each dimension
ordisurf(vare.mds ~ Baresoil, varechem, isotropic = FALSE,
                        bs = "cs", knots = c(3,4), fx = TRUE,
                        select = FALSE)
</code></pre>

<hr>
<h2 id='orditkplot'> Ordination Plot with Movable Labels </h2><span id='topic+orditkplot'></span><span id='topic+plot.orditkplot'></span><span id='topic+scores.orditkplot'></span><span id='topic+points.orditkplot'></span><span id='topic+text.orditkplot'></span>

<h3>Description</h3>

<p>Function <code>orditkplot</code> produces an editable ordination plot with
points and labels. The labels can be moved with mouse, and the edited
plot can be saved as an encapsulated postscript file or exported via <span class="rlang"><b>R</b></span> 
<code>plot</code> function to other graphical formats, or saved in the <span class="rlang"><b>R</b></span> session 
for further processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orditkplot(x, display = "species", choices = 1:2, width, xlim, ylim, 
   tcex = 0.8, tcol, pch = 1,  pcol, pbg, pcex = 0.7, labels,  ...)
## S3 method for class 'orditkplot'
plot(x, ...)
## S3 method for class 'orditkplot'
points(x, pch = x$args$pch, cex = x$args$pcex,
       col = x$args$pcol, bg = x$args$pbg, ...)
## S3 method for class 'orditkplot'
text(x, cex = x$args$tcex, col = x$args$tcol,
     font = attr(x$labels, "font"), ...)
## S3 method for class 'orditkplot'
scores(x, display, ...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="orditkplot_+3A_x">x</code></td>
<td>
<p>An ordination result or any other object that
<code><a href="#topic+scores">scores</a></code> can handle, or for the <code>plot</code> function the
object dumped from the interactive <code>orditkplot</code> session.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_display">display</code></td>
<td>
<p>Type of <code><a href="#topic+scores">scores</a></code> displayed. For ordination
scores this typically is either <code>"species"</code> or <code>"sites"</code>,
and for <code>orditkplot</code> result it is either <code>"points"</code> or
<code>"labels"</code>.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_choices">choices</code></td>
<td>
<p>Axes displayed.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_width">width</code></td>
<td>
<p>Width of the plot in inches; defaults to the current
width of the graphical device. </p>
</td></tr>
<tr><td><code id="orditkplot_+3A_xlim">xlim</code>, <code id="orditkplot_+3A_ylim">ylim</code></td>
<td>
<p>x and y limits for plots: points outside these
limits will be completely removed.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_tcex">tcex</code></td>
<td>
<p>Character expansion for text labels.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_tcol">tcol</code></td>
<td>
<p>Colour of text labels.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_pch">pch</code>, <code id="orditkplot_+3A_pcol">pcol</code>, <code id="orditkplot_+3A_pbg">pbg</code></td>
<td>
<p>Point type and outline and fill colours. 
Defaults <code>pcol="black"</code>  and <code>pbg="transparent"</code>. 
Argument <code>pbg</code> has an effect only in filled plotting characters
<code>pch = 21</code> to <code>25</code>.</p>
</td></tr> 
<tr><td><code id="orditkplot_+3A_pcex">pcex</code></td>
<td>
<p>Expansion factor for point size.</p>
</td></tr>  
<tr><td><code id="orditkplot_+3A_labels">labels</code></td>
<td>
<p>Labels used instead of row names.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_cex">cex</code>, <code id="orditkplot_+3A_col">col</code>, <code id="orditkplot_+3A_bg">bg</code>, <code id="orditkplot_+3A_font">font</code></td>
<td>
<p>graphical parameters used in the
<code>points</code> and <code>text</code> methods. See <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="orditkplot_+3A_...">...</code></td>
<td>
<p>Other arguments passed to the function. These can be
graphical parameters (see <code><a href="graphics.html#topic+par">par</a></code>) used in the plot, or
extra arguments to <code><a href="#topic+scores">scores</a></code>. These arguments are
ignored in <code>plot</code>, but honoured in <code>text</code> and <code>points</code>. </p>
</td></tr>  
</table>


<h3>Details</h3>

<p> Function <code>orditkplot</code> uses <span class="pkg">tcltk</span> package to draw
Tcl/Tk based ordination graphics with points and labels. The function
opens an editable canvas with fixed points, but the labels can be
dragged with mouse to better positions or edited. In addition, it is
possible to zoom to a part of the graph.
</p>
<p>The function knows the following mouse operations:
</p>

<ul>
<li> <p><strong>Left mouse button</strong> can be used to move labels to better
positions. A line will connect a label to the corresponding point.
</p>
</li>
<li> <p><strong>Double clicking left mouse button</strong> opens a window where the
label can be edited. After editing the label, hit the Return key.
</p>
</li>
<li> <p><strong>Right mouse button</strong> (or alternatively, Shift-Mouse button with
one-button mouse) can be used for zooming to a part of the
graph. Keeping the mouse button down and dragging will draw a box
of the zoomed area, and after releasing the button, a new plot window
will be created (this is still preliminary: all arguments are not
passed to the new plot).
</p>
</li></ul>

<p>In addition there are buttons for the following tasks: <strong>Copy
to EPS</strong> copies the current plot to an encapsulated postscript (eps)
file using standard Tcl/Tk utilities. The faithfulness of this copy
is system dependent. Button <strong>Export plot</strong> uses
<code>plot.orditkplot</code> function to redraw the plot into graphical
file formats. Depending on the system, the following graphical
formats may be available: eps, pdf, svg, png, jpeg, tiff, bmp or
xfig. Some of the output formats may be edited with external
software: svg files with Illustrator or Inkscape, and xfig with the
legacy program XFig. Button <strong>Save to R</strong> writes the edited
coordinates of labels and points to the <span class="rlang"><b>R</b></span> session for further
processing, and the <code>plot.orditkplot</code> function can be used to
display the results. For faithful replication of the plot, the graph
must have similar dimensions as the <code>orditkplot</code> canvas had
originally. The <code>plot</code> function cannot be configured, but it
uses the same settings as the original Tcl/Tk plot. However,
<code>points</code> and <code>text</code> functions are fully configurable, but
use the stored defaults for consistency with <code>plot.orditkplot</code>
if none are supplied. Finally, button <strong>Close</strong> closes the
window.
</p>
<p>The produced plot will have equal aspect ratio. The width of the
horizontal axis is fixed, but vertical axes will be scaled to needed
height, and you can use scrollbar to move vertically if the whole
canvas does not fit the window. If you use dumped labels in ordinary
<span class="rlang"><b>R</b></span> plots, your plot must have the same dimensions as the
<code>orditkplot</code> canvas to have identical location of the labels.
</p>
<p>The function only displays one set of scores. However, you can use
<code><a href="#topic+ordipointlabel">ordipointlabel</a></code> to produce a result object that has
different points and text types for several sets of scores and this
can be further edited with <code>orditkplot</code>. For a good starting
solution you need to scale the <code><a href="#topic+ordipointlabel">ordipointlabel</a></code> result
so that the points span over the whole horizontal axis. The function
cannot show environmental variables or constraints, but it is
limited to unconstrained ordination.
</p>
<p>The plot is a Tcl/Tk canvas, but the function tries to replicate
standard graphical device of the platform, and it honours several
graphical parameters (see <code><a href="graphics.html#topic+par">par</a></code>).  Many of the graphical
parameters can be given on the command line, and they will be passed
to the function without influencing other graphical devices in <span class="rlang"><b>R</b></span>.
At the moment, the
following graphical parameters are honoured: 
<code>pch</code> <code>bg</code>,  <code>cex</code>,
<code>cex.axis</code>, <code>cex.lab</code>, <code>col</code> (for labels),
<code>col.axis</code>, <code>col.lab</code>, <code>family</code> (for font faces),
<code>fg</code>, <code>font</code>, <code>font.axis</code>, <code>font.lab</code>,
<code>lheight</code>, <code>lwd</code> (for the box), <code>mar</code>, <code>mex</code>,
<code>mgp</code>, <code>ps</code>, <code>tcl</code>. These can be set with
<code><a href="graphics.html#topic+par">par</a></code>, and they also will influence other plots similarly.
</p>
<p>The <code><a href="tcltk.html#topic+tkcanvas">tkcanvas</a></code> text cannot be rotated, and
therefore vertical axis is not labelled, and <code>las</code>
<code><a href="graphics.html#topic+par">par</a></code>ameter will not be honoured in the Tcl/Tk plot, but
it will be honoured in the exported <span class="rlang"><b>R</b></span> plots and in
<code>plot.orditkplot</code>.  </p>


<h3>Value</h3>

<p> Function returns nothing useful directly, but you can save the
edited graph to a file or save the edited positions to an <span class="rlang"><b>R</b></span> session
for further processing and plotting.  
</p>


<h3>Note</h3>

<p>You need <span class="pkg">tcltk</span> package and <span class="rlang"><b>R</b></span> must have been configured with
<code><a href="base.html#topic+capabilities">capabilities</a></code> for <code>tcltk</code>.
Depending on your OS, you may need to start X11 and set the display
before loading <span class="pkg">tcltk</span> and starting the function (for instance,
with <code>Sys.setenv("DISPLAY"=":0")</code>). See
<code><a href="tcltk.html#topic+tcltk-package">tcltk-package</a></code>. 
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>See Also</h3>

<p> Function <code><a href="#topic+ordipointlabel">ordipointlabel</a></code> is an automatic
procedure with similar goals of avoiding overplotting, and its
output can be edited with <code>orditkplot</code>.  See
<code><a href="#topic+ordiplot">ordiplot</a></code>, <code><a href="#topic+plot.cca">plot.cca</a></code>,
and <code><a href="#topic+orditorp">orditorp</a></code> for
alternative ordination plots, and <code><a href="#topic+scores">scores</a></code> for
extracting ordination scores.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## The example needs user interaction and is not executed directly.
## It should work when pasted to the window.
## Not run: 
data(varespec)
ord &lt;- cca(varespec)
## Do something with the graph and end by clicking "Dismiss"
orditkplot(ord, mar = c(4,4,1,1)+.1, font=3)
## Use ordipointlabel to produce a plot that has both species and site
## scores in different colors and plotting symbols
pl &lt;- ordipointlabel(ord)
orditkplot(pl)

## End(Not run)
</code></pre>

<hr>
<h2 id='orditorp'> Add Text or Points to Ordination Plots </h2><span id='topic+orditorp'></span>

<h3>Description</h3>

<p>The function adds <code><a href="graphics.html#topic+text">text</a></code> or <code><a href="graphics.html#topic+points">points</a></code> to
ordination plots.  Text will be used if this can be done without
overwriting other text labels, and points will be used otherwise. The
function can help in reducing clutter in ordination graphics, but
manual editing may still be necessary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orditorp(x, display, labels, choices = c(1, 2), priority,
    select, cex = 0.7, pcex, col = par("col"), pcol,
    pch = par("pch"), air = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orditorp_+3A_x">x</code></td>
<td>
<p>A result object from ordination or an <code><a href="#topic+ordiplot">ordiplot</a></code>
result. </p>
</td></tr>
<tr><td><code id="orditorp_+3A_display">display</code></td>
<td>
<p>Items to be displayed in the plot.  Only one
alternative is allowed. Typically this is <code>"sites"</code> or
<code>"species"</code>.  </p>
</td></tr>
<tr><td><code id="orditorp_+3A_labels">labels</code></td>
<td>
<p> Optional text used for labels. Row names will be used if
this is missing. </p>
</td></tr>
<tr><td><code id="orditorp_+3A_choices">choices</code></td>
<td>
<p> Axes shown.</p>
</td></tr>
<tr><td><code id="orditorp_+3A_priority">priority</code></td>
<td>
<p> Text will be used for items with higher priority
if labels overlap.  This should be vector of the same
length as the number of items plotted.</p>
</td></tr>
<tr><td><code id="orditorp_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of indices
of displayed items. If a logical vector is used, it must have the
same length as the scores plotted.</p>
</td></tr>
<tr><td><code id="orditorp_+3A_cex">cex</code>, <code id="orditorp_+3A_pcex">pcex</code></td>
<td>
<p>Text and point sizes, see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>..</p>
</td></tr>
<tr><td><code id="orditorp_+3A_col">col</code>, <code id="orditorp_+3A_pcol">pcol</code></td>
<td>
<p>Text and point colours, see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
<tr><td><code id="orditorp_+3A_pch">pch</code></td>
<td>
<p>Plotting character, see <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>
<tr><td><code id="orditorp_+3A_air">air</code></td>
<td>
<p>Amount of empty space between text labels. Values &lt;1 allow
overlapping text.</p>
</td></tr>
<tr><td><code id="orditorp_+3A_...">...</code></td>
<td>
<p> Other arguments to <code><a href="#topic+scores">scores</a></code> (and its various
methods), <code><a href="graphics.html#topic+text">text</a></code> and <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>orditorp</code> will add either text or points to an existing
plot. The items with high <code>priority</code> will be added first
and <code><a href="graphics.html#topic+text">text</a></code> will be used if this can be done without
overwriting previous labels,and <code><a href="graphics.html#topic+points">points</a></code> will be used
otherwise. If <code>priority</code> is missing, labels will be added from the
outskirts to the centre. Function <code>orditorp</code> can be used
with most ordination results, or plotting results from
<code><a href="#topic+ordiplot">ordiplot</a></code> or ordination plot functions
(<code><a href="#topic+plot.cca">plot.cca</a></code>, <code><a href="#topic+plot.decorana">plot.decorana</a></code>,
<code><a href="#topic+plot.metaMDS">plot.metaMDS</a></code>).
</p>
<p>Arguments can be passed to the relevant <code><a href="#topic+scores">scores</a></code> method
for the ordination object (<code>x</code>) being drawn. See the relevant
<code><a href="#topic+scores">scores</a></code> help page for arguments that can be used.
</p>


<h3>Value</h3>

<p>The function returns invisibly a logical vector where <code>TRUE</code>
means that item was labelled with text and <code>FALSE</code> means that it
was marked with a point. The returned vector can be used as the
<code>select</code> argument in ordination <code>text</code> and <code>points</code>
functions.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>Examples</h3>

<pre><code class='language-R'>## A cluttered ordination plot :
data(BCI)
mod &lt;- cca(BCI)
plot(mod, dis="sp", type="t")
# Now with orditorp and abbreviated species names
cnam &lt;- make.cepnames(names(BCI))
plot(mod, dis="sp", type="n")
stems &lt;- colSums(BCI)
orditorp(mod, "sp", label = cnam, priority=stems, pch="+", pcol="grey")

## show select in action
set.seed(1)
take &lt;- sample(ncol(BCI), 50)
plot(mod, dis="sp", type="n")
stems &lt;- colSums(BCI)
orditorp(mod, "sp", label = cnam, priority=stems, select = take,
         pch="+", pcol="grey")

</code></pre>

<hr>
<h2 id='ordixyplot'> Trellis (Lattice) Plots for Ordination </h2><span id='topic+ordixyplot'></span><span id='topic+ordisplom'></span><span id='topic+ordicloud'></span><span id='topic+panel.ordi'></span><span id='topic+panel.ordiarrows'></span><span id='topic+panel.ordi3d'></span><span id='topic+prepanel.ordi3d'></span><span id='topic+ordilattice.getEnvfit'></span>

<h3>Description</h3>

<p>Functions <code>ordicloud</code>, <code>ordisplom</code> and <code>ordixyplot</code>
provide an interface to plot ordination results using Trellis
functions <code><a href="lattice.html#topic+cloud">cloud</a></code>, <code><a href="lattice.html#topic+splom">splom</a></code>
and <code><a href="lattice.html#topic+xyplot">xyplot</a></code> in package <span class="pkg">lattice</span>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordixyplot(x, data = NULL, formula, display = "sites", choices = 1:3,
    panel = "panel.ordi", aspect = "iso", envfit,
    type = c("p", "biplot"), ...)
ordisplom(x, data=NULL, formula = NULL,  display = "sites", choices = 1:3,
    panel = "panel.ordi", type = "p",  ...)
ordicloud(x, data = NULL, formula, display = "sites", choices = 1:3, 
    panel = "panel.ordi3d", prepanel = "prepanel.ordi3d",  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordixyplot_+3A_x">x</code></td>
<td>
<p> An ordination result that <code><a href="#topic+scores">scores</a></code> knows: any
ordination result in <span class="pkg">vegan</span> and many others. </p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_data">data</code></td>
<td>
<p> Optional data to amend ordination results. The ordination
results are found from <code>x</code>, but you may give here data for other
variables needed in plots. Typically these are environmental data.</p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_formula">formula</code></td>
<td>
<p> Formula to define the plots. A default formula will be
used if this is omitted. The
ordination axes must be called by the same names as in the
ordination results (and these names vary among methods). In
<code>ordisplom</code>, special character <code>.</code> refers to the
ordination result. </p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_display">display</code></td>
<td>
<p> The kind of scores: an argument passed to
<code><a href="#topic+scores">scores</a></code>. </p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_choices">choices</code></td>
<td>
<p> The axes selected: an argument passed to
<code><a href="#topic+scores">scores</a></code>. </p>
</td></tr> 
<tr><td><code id="ordixyplot_+3A_panel">panel</code>, <code id="ordixyplot_+3A_prepanel">prepanel</code></td>
<td>
<p> The names of the panel and prepanel
functions. </p>
</td></tr> 
<tr><td><code id="ordixyplot_+3A_aspect">aspect</code></td>
<td>
<p>The aspect of the plot (passed to the <span class="pkg">lattice</span>
function).</p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_envfit">envfit</code></td>
<td>
<p>Result of <code><a href="#topic+envfit">envfit</a></code> function displayed in
<code>ordixyplot</code>. Please note that this needs same <code>choices</code>
as <code>ordixyplot</code>.</p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_type">type</code></td>
<td>
<p>The type of plot. This knows the same alternatives as
<code><a href="lattice.html#topic+panel.xyplot">panel.xyplot</a></code>. In addition <code>ordixyplot</code>
has alternatives <code>"biplot"</code>, <code>"arrows"</code> and
<code>"polygon"</code>. The first displays fitted vectors and factor
centroids of <code>envfit</code>, or in constrained ordination, the
biplot arrows and factor centroids if <code>envfit</code> is not
given. The second (<code>type = "arrows"</code>) is a trellis variant of
<code><a href="#topic+ordiarrows">ordiarrows</a></code> and draws arrows by <code>groups</code>. The
line parameters are controlled by
<code><a href="lattice.html#topic+trellis.par.set">trellis.par.set</a></code> for <code>superpose.line</code>,
and the user can set <code>length</code>, <code>angle</code> and <code>ends</code>
parameters of <code><a href="lattice.html#topic+panel.arrows">panel.arrows</a></code>.  The last one
(<code>type = "polygon"</code>) draws a polygon enclosing all points in
a panel over a polygon enclosing all points in the data. The
overall polygon is controlled by
<code><a href="lattice.html#topic+trellis.par.set">trellis.par.set</a></code> for <code>plot.polygon</code>,
and each panel polygon is controlled by <code>superpose.polygon</code>.</p>
</td></tr>
<tr><td><code id="ordixyplot_+3A_...">...</code></td>
<td>
<p> Arguments passed to <code><a href="#topic+scores">scores</a></code> methods or
<span class="pkg">lattice</span> functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions provide an interface to the corresponding <span class="pkg">lattice</span>
functions.  All graphical parameters are passed to the <span class="pkg">lattice</span>
function so that these graphs are extremely configurable. See
<code><a href="lattice.html#topic+Lattice">Lattice</a></code> and <code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+splom">splom</a></code> and <code><a href="lattice.html#topic+cloud">cloud</a></code> for
details, usage and possibilities.
</p>
<p>The argument <code>x</code> must always be an ordination result. The scores
are extracted with <span class="pkg">vegan</span> function <code><a href="#topic+scores">scores</a></code> so that
these functions work with all <span class="pkg">vegan</span> ordinations and many others.
</p>
<p>The <code>formula</code> is used to define the models. All functions have
simple default formulae which are used if <code>formula</code> is missing. 
If formula is omitted in <code>ordisplom</code> it
produces a pairs plot of ordination axes and variables in
<code>data</code>. If <code>formula</code> is given, ordination results must be
referred to as <code>.</code> and other variables by their names. In other
functions, the formula must use the names of ordination scores and names
of <code>data</code>.
</p>
<p>The ordination scores are found from <code>x</code>, and <code>data</code> is
optional. The <code>data</code> should contain other variables than
ordination scores to be used in plots. Typically, they are
environmental variables (typically factors) to define panels or plot
symbols.
</p>
<p>The proper work is done by the panel function. The layout can be
changed by defining own panel functions. See
<code><a href="lattice.html#topic+panel.xyplot">panel.xyplot</a></code>,
<code><a href="lattice.html#topic+panel.splom">panel.splom</a></code> and
<code><a href="lattice.html#topic+panel.cloud">panel.cloud</a></code> for details and survey of
possibilities.
</p>
<p>Ordination graphics should always be isometric: same scale should be
used in all axes. This is controlled (and can be changed) with
argument <code>aspect</code> in <code>ordixyplot</code>. In <code>ordicloud</code> the
isometric scaling is defined in <code>panel</code> and <code>prepanel</code>
functions. You must replace these functions if you want to have
non-isometric scaling of graphs. You cannot select isometric scaling
in <code>ordisplom</code>.
</p>


<h3>Value</h3>

<p>The function return <code><a href="lattice.html#topic+Lattice">Lattice</a></code> objects of class
<code>"trellis"</code>.   
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>See Also</h3>

<p><code><a href="lattice.html#topic+Lattice">Lattice</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>,
<code><a href="lattice.html#topic+splom">splom</a></code>,
<code><a href="lattice.html#topic+cloud">cloud</a></code>,
<code><a href="lattice.html#topic+panel.splom">panel.splom</a></code>,
<code><a href="lattice.html#topic+panel.cloud">panel.cloud</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune, dune.env)
ord &lt;- cca(dune)
## Pairs plots
ordisplom(ord)
ordisplom(ord, data=dune.env, choices=1:2)
ordisplom(ord, data=dune.env, form = ~ . | Management, groups=Manure)
## Scatter plot with polygons
ordixyplot(ord, data=dune.env, form = CA1 ~ CA2 | Management,
  groups=Manure, type = c("p","polygon"))
## Choose a different scaling
ordixyplot(ord, scaling = "symmetric")
## ... Slices of third axis
ordixyplot(ord, form = CA1 ~ CA2 | equal.count(CA3, 4),
   type = c("g","p", "polygon"))
## Display environmental variables
ordixyplot(ord, envfit = envfit(ord ~ Management + A1, dune.env, choices=1:3))
## 3D Scatter plots
ordicloud(ord, form = CA2 ~ CA3*CA1, groups = Manure, data = dune.env)
ordicloud(ord, form = CA2 ~ CA3*CA1 | Management, groups = Manure,
   data = dune.env, auto.key = TRUE, type = c("p","h"))
</code></pre>

<hr>
<h2 id='pcnm'> Principal Coordinates of Neighbourhood Matrix </h2><span id='topic+pcnm'></span><span id='topic+scores.pcnm'></span>

<h3>Description</h3>

<p>This function computed classical PCNM by the principal coordinate
analysis of a truncated distance matrix. These are commonly used to
transform (spatial) distances to rectangular data that suitable for
constrained ordination or regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcnm(dis, threshold, w, dist.ret = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcnm_+3A_dis">dis</code></td>
<td>
<p> A distance matrix. </p>
</td></tr>
<tr><td><code id="pcnm_+3A_threshold">threshold</code></td>
<td>
<p> A threshold value or truncation distance. If
missing, minimum distance giving connected network will be
used. This is found as the longest distance in the minimum spanning
tree of <code>dis</code>. </p>
</td></tr>
<tr><td><code id="pcnm_+3A_w">w</code></td>
<td>
<p>Prior weights for rows.</p>
</td></tr>
<tr><td><code id="pcnm_+3A_dist.ret">dist.ret</code></td>
<td>
<p>Return the distances used to calculate the PCNMs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Principal Coordinates of Neighbourhood Matrix (PCNM) map distances
between rows onto rectangular matrix on rows using a truncation
threshold for long distances (Borcard &amp; Legendre 2002). If original
distances were Euclidean distances in two dimensions (like normal
spatial distances), they could be mapped onto two dimensions if there
is no truncation of distances. Because of truncation, there will be a
higher number of principal coordinates. The selection of truncation
distance has a huge influence on the PCNM vectors. The default is to
use the longest distance to keep data connected. The distances above
truncation threshold are given an arbitrary value of 4 times
threshold.  For regular data, the first PCNM vectors show a wide scale
variation and later PCNM vectors show smaller scale variation (Borcard
&amp; Legendre 2002), but for irregular data the interpretation is not as
clear.
</p>
<p>The PCNM functions are used to express distances in rectangular form
that is similar to normal explanatory variables used in, e.g.,
constrained ordination (<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+cca">cca</a></code> and
<code><a href="#topic+capscale">capscale</a></code>) or univariate regression (<code><a href="stats.html#topic+lm">lm</a></code>)
together with environmental variables (row weights should be supplied
with <code><a href="#topic+cca">cca</a></code>; see Examples). This is regarded as a more
powerful method than forcing rectangular environmental data into
distances and using them in partial mantel analysis
(<code><a href="#topic+mantel.partial">mantel.partial</a></code>) together with geographic distances
(Legendre et al. 2008, but see Tuomisto &amp; Ruokolainen 2008).
</p>
<p>The function is based on <code>pcnm</code> function in Dray's unreleased
<span class="pkg">spacemakeR</span> package. The differences are that the current
function uses <code><a href="#topic+spantree">spantree</a></code> as an internal support
function. The current function also can use prior weights for rows by
using weighted metric scaling of <code><a href="#topic+wcmdscale">wcmdscale</a></code>. The use of
row weights allows finding orthonormal PCNMs also for correspondence
analysis (e.g., <code><a href="#topic+cca">cca</a></code>).
</p>


<h3>Value</h3>

<p>A list of the following elements:
</p>
<table>
<tr><td><code>values</code></td>
<td>
<p>Eigenvalues obtained by the principal coordinates
analysis.</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>
<p>Eigenvectors obtained by the principal coordinates
analysis. They are scaled to unit norm. The vectors can be extracted
with <code>scores</code> function. The default is to return all PCNM vectors,
but argument <code>choices</code> selects the given vectors.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>Truncation distance.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>The distance matrix where values above <code>threshold</code>
are replaced with arbitrary value of four times the
threshold. String <code>"pcnm"</code> is added to the <code>method</code>
attribute, and new attribute <code>threshold</code> is added to the
distances. This is returned only when <code>dist.ret = TRUE</code>.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jari Oksanen, based on the code of Stephane Dray.</p>


<h3>References</h3>

<p>Borcard D. and Legendre P. (2002) All-scale spatial analysis of
ecological data by means of principal coordinates of neighbour
matrices. <em>Ecological Modelling</em> <b>153</b>, 51&ndash;68.
</p>
<p>Legendre, P., Borcard, D and Peres-Neto, P. (2008) Analyzing or
explaining beta diversity? Comment. <em>Ecology</em> <b>89</b>,
3238&ndash;3244.
</p>
<p>Tuomisto, H. &amp; Ruokolainen, K. (2008) Analyzing or explaining beta
diversity? A reply. <em>Ecology</em> <b>89</b>, 3244&ndash;3256.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+spantree">spantree</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from Borcard &amp; Legendre (2002)
data(mite.xy)
pcnm1 &lt;- pcnm(dist(mite.xy))
op &lt;- par(mfrow=c(1,3))
## Map of PCNMs in the sample plot
ordisurf(mite.xy, scores(pcnm1, choi=1), bubble = 4, main = "PCNM 1")
ordisurf(mite.xy, scores(pcnm1, choi=2), bubble = 4, main = "PCNM 2")
ordisurf(mite.xy, scores(pcnm1, choi=3), bubble = 4, main = "PCNM 3")
par(op)
## Plot first PCNMs against each other
ordisplom(pcnm1, choices=1:4)
## Weighted PCNM for CCA
data(mite)
rs &lt;- rowSums(mite)/sum(mite)
pcnmw &lt;- pcnm(dist(mite.xy), w = rs)
ord &lt;- cca(mite ~ scores(pcnmw))
## Multiscale ordination: residual variance should have no distance
## trend
msoplot(mso(ord, mite.xy))
</code></pre>

<hr>
<h2 id='permat'>Matrix Permutation Algorithms for Presence-Absence and Count Data</h2><span id='topic+permatfull'></span><span id='topic+permatswap'></span><span id='topic+summary.permat'></span><span id='topic+print.summary.permat'></span><span id='topic+print.permat'></span><span id='topic+plot.permat'></span><span id='topic+lines.permat'></span><span id='topic+as.ts.permat'></span><span id='topic+toCoda.permat'></span>

<h3>Description</h3>

<p> Individual (for count data) or incidence (for
presence-absence data) based null models can be generated for
community level simulations. Options for preserving characteristics of
the original matrix (rows/columns sums, matrix fill) and
restricted permutations (based on strata) are discussed in the
Details section.</p>


<h3>Usage</h3>

<pre><code class='language-R'>permatfull(m, fixedmar = "both", shuffle = "both", strata = NULL, 
    mtype = "count", times = 99, ...)
permatswap(m, method = "quasiswap", fixedmar="both", shuffle = "both",
    strata = NULL, mtype = "count", times = 99, 
    burnin = 0, thin = 1, ...)
## S3 method for class 'permat'
print(x, digits = 3, ...)
## S3 method for class 'permat'
summary(object, ...)
## S3 method for class 'summary.permat'
print(x, digits = 2, ...)
## S3 method for class 'permat'
plot(x, type = "bray", ylab, xlab, col, lty,
    lowess = TRUE, plot = TRUE, text = TRUE, ...)
## S3 method for class 'permat'
lines(x, type = "bray", ...)
## S3 method for class 'permat'
as.ts(x, type = "bray", ...)
## S3 method for class 'permat'
toCoda(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permat_+3A_m">m</code></td>
<td>
<p>A community data matrix with plots (samples) as rows and
species (taxa) as columns.</p>
</td></tr> 
<tr><td><code id="permat_+3A_fixedmar">fixedmar</code></td>
<td>
<p>character, stating which of the row/column sums should
be preserved (<code>"none", "rows", "columns", "both"</code>).</p>
</td></tr> 
<tr><td><code id="permat_+3A_strata">strata</code></td>
<td>
<p>Numeric vector or factor with length same as
<code>nrow(m)</code> for grouping rows within strata for restricted
permutations. Unique values or levels are used.</p>
</td></tr> 
<tr><td><code id="permat_+3A_mtype">mtype</code></td>
<td>
<p>Matrix data type, either <code>"count"</code> for count data,
or <code>"prab"</code> for presence-absence type incidence data.</p>
</td></tr> 
<tr><td><code id="permat_+3A_times">times</code></td>
<td>
<p>Number of permuted matrices.</p>
</td></tr> 
<tr><td><code id="permat_+3A_method">method</code></td>
<td>
<p>Character for method used for the swap algorithm
(<code>"swap"</code>, <code>"tswap"</code>, <code>"quasiswap"</code>,
<code>"backtrack"</code>) as described for function
<code><a href="#topic+make.commsim">make.commsim</a></code>. If <code>mtype="count"</code> the
<code>"quasiswap"</code>, <code>"swap"</code>, <code>"swsh"</code> and
<code>"abuswap"</code> methods are available (see details).</p>
</td></tr> 
<tr><td><code id="permat_+3A_shuffle">shuffle</code></td>
<td>
<p>Character, indicating whether individuals
(<code>"ind"</code>), samples (<code>"samp"</code>) or both (<code>"both"</code>)
should be shuffled, see details.</p>
</td></tr> 
<tr><td><code id="permat_+3A_burnin">burnin</code></td>
<td>
<p>Number of null communities discarded before proper
analysis in sequential (<code>"swap", "tswap"</code>) methods.</p>
</td></tr> 
<tr><td><code id="permat_+3A_thin">thin</code></td>
<td>
<p>Number of discarded permuted matrices between two
evaluations in sequential (<code>"swap", "tswap"</code>) methods.</p>
</td></tr> 
<tr><td><code id="permat_+3A_x">x</code>, <code id="permat_+3A_object">object</code></td>
<td>
<p>Object of class <code>"permat"</code></p>
</td></tr> 
<tr><td><code id="permat_+3A_digits">digits</code></td>
<td>
<p>Number of digits used for rounding.</p>
</td></tr>
<tr><td><code id="permat_+3A_ylab">ylab</code>, <code id="permat_+3A_xlab">xlab</code>, <code id="permat_+3A_col">col</code>, <code id="permat_+3A_lty">lty</code></td>
<td>
<p>graphical parameters for the <code>plot</code>
method.</p>
</td></tr> 
<tr><td><code id="permat_+3A_type">type</code></td>
<td>
<p>Character, type of plot to be displayed: <code>"bray"</code> for
Bray-Curtis dissimilarities, <code>"chisq"</code> for Chi-squared values.</p>
</td></tr> 
<tr><td><code id="permat_+3A_lowess">lowess</code>, <code id="permat_+3A_plot">plot</code>, <code id="permat_+3A_text">text</code></td>
<td>
<p>Logical arguments for the <code>plot</code>
method, whether a locally weighted regression curve should be drawn,
the plot should be drawn, and statistic values should be printed on
the plot.</p>
</td></tr> 
<tr><td><code id="permat_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code> 
or methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>permatfull</code> is useful when matrix fill is
allowed to vary, and matrix type is <code>count</code>.  The <code>fixedmar</code>
argument is used to set constraints for permutation.  If <code>none</code>
of the margins are fixed, cells are randomised within the matrix.  If
<code>rows</code> or <code>columns</code> are fixed, cells within rows or columns
are randomised, respectively.  If <code>both</code> margins are fixed, the
<code><a href="stats.html#topic+r2dtable">r2dtable</a></code> function is used that is based on Patefield's
(1981) algorithm. For presence absence data, matrix fill should be
necessarily fixed, and <code>permatfull</code> is a wrapper for the function
<code><a href="#topic+make.commsim">make.commsim</a></code>. The <code>r00, r0, c0, quasiswap</code>
algorithms of <code><a href="#topic+make.commsim">make.commsim</a></code> are used for <code>"none",
  "rows", "columns", "both"</code> values of the <code>fixedmar</code> argument,
respectively
</p>
<p>The <code>shuffle</code> argument only have effect if the <code>mtype =
  "count"</code> and <code>permatfull</code> function is used with <code>"none",
  "rows", "columns"</code> values of <code>fixedmar</code>. All other cases for
count data are individual based randomisations. The <code>"samp"</code> and
<code>"both"</code> options result fixed matrix fill. The <code>"both"</code>
option means that individuals are shuffled among non zero cells
ensuring that there are no cell with zeros as a result, then cell
(zero and new valued cells) are shuffled.
</p>
<p>The function <code>permatswap</code> is useful when with matrix fill
(i.e. the proportion of empty cells) and row/columns sums should be
kept constant. <code>permatswap</code> uses different kinds of swap
algorithms, and row and columns sums are fixed in all cases.  For
presence-absence data, the <code>swap</code> and <code>tswap</code> methods of
<code><a href="#topic+make.commsim">make.commsim</a></code> can be used.  For count data, a special
swap algorithm ('swapcount') is implemented that results in permuted
matrices with fixed marginals and matrix fill at the same time.
</p>
<p>The 'quasiswapcount' algorithm (<code>method="quasiswap"</code> and
<code>mtype="count"</code>) uses the same trick as Carsten Dormann's
<code>swap.web</code> function in the package
<span class="pkg">bipartite</span>. First, a random matrix is generated by the
<code><a href="stats.html#topic+r2dtable">r2dtable</a></code> function retaining row and column sums. Then
the original matrix fill is reconstructed by sequential steps to
increase or decrease matrix fill in the random matrix. These steps are
based on swapping 2x2 submatrices (see 'swapcount' algorithm for
details) to maintain row and column totals. This algorithm generates
independent matrices in each step, so <code>burnin</code> and <code>thin</code>
arguments are not considered. This is the default method, because this
is not sequential (as <code>swapcount</code> is) so independence of subsequent
matrices does not have to be checked.
</p>
<p>The <code>swapcount</code> algorithm (<code>method="swap"</code> and
<code>mtype="count"</code>) tries to find 2x2 submatrices (identified by 2
random row and 2 random column indices), that can be swapped in order
to leave column and row totals and fill unchanged. First, the
algorithm finds the largest value in the submatrix that can be swapped
(<code class="reqn">d</code>) and whether in diagonal or antidiagonal way. Submatrices
that contain values larger than zero in either diagonal or
antidiagonal position can be swapped. Swap means that the values in
diagonal or antidiagonal positions are decreased by <code class="reqn">d</code>, while
remaining cells are increased by <code class="reqn">d</code>. A swap is made only if fill
doesn't change. This algorithm is sequential, subsequent matrices are
not independent, because swaps modify little if the matrix is
large. In these cases many burnin steps and thinning is needed to get
independent random matrices. Although this algorithm is implemented in
C, large burnin and thin values can slow it down
considerably. WARNING: according to simulations, this algorithm seems
to be biased and non random, thus its use should be avoided!
</p>
<p>The algorithm <code>"swsh"</code> in the function <code>permatswap</code> is a
hybrid algorithm. First, it makes binary quasiswaps to keep row and
column incidences constant, then non-zero values are modified
according to the <code>shuffle</code> argument (only <code>"samp"</code> and
<code>"both"</code> are available in this case, because it is applied only
on non-zero values). It also recognizes the <code>fixedmar</code>
argument which cannot be <code>"both"</code> (<span class="pkg">vegan</span> versions &lt;= 2.0
had this algorithm with <code>fixedmar = "none"</code>).
</p>
<p>The algorithm <code>"abuswap"</code> produces two kinds of null models
(based on <code>fixedmar="columns"</code> or <code>fixedmar="rows"</code>) as
described in Hardy (2008; randomization scheme 2x and 3x,
respectively).  These preserve column and row occurrences, and column
or row sums at the same time. (Note that similar constraints
can be achieved by the non sequential <code>"swsh"</code> algorithm
with <code>fixedmar</code> argument set to <code>"columns"</code> or
<code>"rows"</code>, respectively.)
</p>
<p>Constraints on row/column sums, matrix fill, total sum and sums within
strata can be checked by the <code>summary</code> method. <code>plot</code> method
is for visually testing the randomness of the permuted matrices,
especially for the sequential swap algorithms. If there are any
tendency in the graph, higher <code>burnin</code> and <code>thin</code> values can
help for sequential methods.  New lines can be added to existing plot
with the <code>lines</code> method.
</p>
<p>Unrestricted and restricted permutations: if <code>strata</code> is
<code>NULL</code>, functions perform unrestricted permutations. Otherwise,
it is used for restricted permutations. Each strata should contain at
least 2 rows in order to perform randomization (in case of low row
numbers, swap algorithms can be rather slow). If the design is not
well balanced (i.e. same number of observations within each stratum),
permuted matrices may be biased because same constraints are forced on
submatrices of different dimensions. This often means, that the number
of potential permutations will decrease with their dimensions.  So the
more constraints we put, the less randomness can be expected.
</p>
<p>The <code>plot</code> method is useful for graphically testing for trend and
independence of permuted matrices. This is especially important when
using sequential algorithms (<code>"swap", "tswap", "abuswap"</code>).
</p>
<p>The <code>as.ts</code> method can be used to extract Bray-Curtis
dissimilarities or Chi-squared values as time series. This can further
used in testing independence (see Examples). The method <code>toCoda</code>
is useful for accessing diagnostic tools available in the <a href="https://CRAN.R-project.org/package=coda"><span class="pkg">coda</span></a>
package.  </p>


<h3>Value</h3>

<p>Functions <code>permatfull</code> and <code>permatswap</code> return an
object of class <code>"permat"</code> containing the the function call
(<code>call</code>), the original data matrix used for permutations
(<code>orig</code>) and a list of permuted matrices with length <code>times</code>
(<code>perm</code>).
</p>
<p>The <code>summary</code> method returns various statistics as a list
(including mean Bray-Curtis dissimilarities calculated pairwise among
original and permuted matrices, Chi-square statistics, and check
results of the constraints; see Examples). Note that when
<code>strata</code> is used in the original call, summary calculation may
take longer.
</p>
<p>The <code>plot</code> creates a plot as a side effect.
</p>
<p>The <code>as.ts</code> method returns an object of class <code>"ts"</code>.  </p>


<h3>Author(s)</h3>

<p>P√©ter S√≥lymos,
<a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a> and Jari Oksanen</p>


<h3>References</h3>

<p> Original references for presence-absence algorithms are
given on help page of <code><a href="#topic+make.commsim">make.commsim</a></code>.
</p>
<p>Hardy, O. J. (2008) Testing the spatial phylogenetic structure of
local communities: statistical performances of different null models
and test statistics on a locally neutral community. Journal of Ecology
96, 914&ndash;926. 
</p>
<p>Patefield, W. M. (1981) Algorithm AS159. An efficient method of
generating r x c tables with given row and column totals.  
Applied Statistics 30, 91&ndash;97.
</p>


<h3>See Also</h3>

<p> For other functions to permute matrices:
<code><a href="#topic+make.commsim">make.commsim</a></code>, <code><a href="stats.html#topic+r2dtable">r2dtable</a></code>,
<code><a href="base.html#topic+sample">sample</a></code>.
</p>
<p>For the use of these permutation algorithms: <code><a href="#topic+oecosimu">oecosimu</a></code>,
<code><a href="#topic+adipart">adipart</a></code>, <code><a href="#topic+hiersimu">hiersimu</a></code>.
</p>
<p>For time-series diagnostics: <code><a href="stats.html#topic+Box.test">Box.test</a></code>,
<code><a href="stats.html#topic+lag.plot">lag.plot</a></code>, <code><a href="stats.html#topic+tsdiag">tsdiag</a></code>, <code><a href="stats.html#topic+ar">ar</a></code>,
<code><a href="stats.html#topic+arima">arima</a></code> 
</p>
<p>For underlying low level implementation:
<code><a href="#topic+commsim">commsim</a></code> and <code><a href="#topic+nullmodel">nullmodel</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## A simple artificial community data matrix.
m &lt;- matrix(c(
    1,3,2,0,3,1,
    0,2,1,0,2,1,
    0,0,1,2,0,3,
    0,0,0,1,4,3
    ), 4, 6, byrow=TRUE)
## Using the quasiswap algorithm to create a 
## list of permuted matrices, where
## row/columns sums and matrix fill are preserved:
x1 &lt;- permatswap(m, "quasiswap")
summary(x1)
## Unrestricted permutation retaining
## row/columns sums but not matrix fill:
x2 &lt;- permatfull(m)
summary(x2)
## Unrestricted permutation of presence-absence type
## not retaining row/columns sums:
x3 &lt;- permatfull(m, "none", mtype="prab")
x3$orig  ## note: original matrix is binarized!
summary(x3)
## Restricted permutation,
## check sums within strata:
x4 &lt;- permatfull(m, strata=c(1,1,2,2))
summary(x4)

## NOTE: 'times' argument usually needs to be &gt;= 99
## here much lower value is used for demonstration

## Not sequential algorithm
data(BCI)
a &lt;- permatswap(BCI, "quasiswap", times=19)
## Sequential algorithm
b &lt;- permatswap(BCI, "abuswap", fixedmar="col",
    burnin=0, thin=100, times=19)
opar &lt;- par(mfrow=c(2,2))
plot(a, main="Not sequential")
plot(b, main="Sequential")
plot(a, "chisq")
plot(b, "chisq")
par(opar)
## Extract Bray-Curtis dissimilarities
## as time series
bc &lt;- as.ts(b)
## Lag plot
lag.plot(bc)
## First order autoregressive model
mar &lt;- arima(bc, c(1,0,0))
mar
## Ljung-Box test of residuals
Box.test(residuals(mar))
## Graphical diagnostics
tsdiag(mar)
</code></pre>

<hr>
<h2 id='permustats'>
Extract, Analyse and Display Permutation Results
</h2><span id='topic+permustats'></span><span id='topic+permustats.anosim'></span><span id='topic+permustats.anova.cca'></span><span id='topic+permustats.CCorA'></span><span id='topic+permustats.envfit'></span><span id='topic+permustats.factorfit'></span><span id='topic+permustats.mantel'></span><span id='topic+permustats.mrpp'></span><span id='topic+permustats.mso'></span><span id='topic+permustats.oecosimu'></span><span id='topic+permustats.ordiareatest'></span><span id='topic+permustats.permutest.betadisper'></span><span id='topic+permustats.permutest.cca'></span><span id='topic+permustats.protest'></span><span id='topic+permustats.vectorfit'></span><span id='topic+summary.permustats'></span><span id='topic+c.permustats'></span><span id='topic+densityplot.permustats'></span><span id='topic+density.permustats'></span><span id='topic+qqnorm.permustats'></span><span id='topic+qqmath.permustats'></span><span id='topic+boxplot.permustats'></span><span id='topic+pairs.permustats'></span>

<h3>Description</h3>

<p>The <code>permustats</code> function extracts permutation results of
<span class="pkg">vegan</span> functions. Its support functions can find quantiles and
standardized effect sizes, plot densities and Q-Q plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permustats(x, ...)
## S3 method for class 'permustats'
summary(object, interval = 0.95, alternative, ...)
## S3 method for class 'permustats'
densityplot(x, data, xlab = "Permutations", ...)
## S3 method for class 'permustats'
density(x, observed = TRUE, ...)
## S3 method for class 'permustats'
qqnorm(y, observed = TRUE, ...)
## S3 method for class 'permustats'
qqmath(x, data, observed = TRUE, sd.scale = FALSE,
    ylab = "Permutations", ...)
## S3 method for class 'permustats'
boxplot(x, scale = FALSE, names, ...)
## S3 method for class 'permustats'
pairs(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permustats_+3A_object">object</code>, <code id="permustats_+3A_x">x</code>, <code id="permustats_+3A_y">y</code></td>
<td>
<p>The object to be handled.</p>
</td></tr>
<tr><td><code id="permustats_+3A_interval">interval</code></td>
<td>
<p>numeric; the coverage interval reported.</p>
</td></tr>
<tr><td><code id="permustats_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the limits used for
the <code>interval</code> and the direction of the test when evaluating
the <code class="reqn">p</code>-values. Must be one of <code>"two.sided"</code> (both upper
and lower limit), <code>"greater"</code> (upper limit), <code>"less"</code>
(lower limit). Usually <code>alternative</code> is given in the result
object, but it can be specified with this argument.</p>
</td></tr>
<tr><td><code id="permustats_+3A_xlab">xlab</code>, <code id="permustats_+3A_ylab">ylab</code></td>
<td>
<p>Arguments of
<code><a href="lattice.html#topic+densityplot">densityplot</a></code> and
<code><a href="lattice.html#topic+qqmath">qqmath</a></code> functions.</p>
</td></tr>
<tr><td><code id="permustats_+3A_observed">observed</code></td>
<td>
<p>Add observed statistic among permutations.</p>
</td></tr>
<tr><td><code id="permustats_+3A_sd.scale">sd.scale</code></td>
<td>
<p>Scale permutations to unit standard deviation and observed
statistic to standardized effect size.</p>
</td></tr>
<tr><td><code id="permustats_+3A_data">data</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="permustats_+3A_scale">scale</code></td>
<td>
<p>Use standardized effect size (SES).</p>
</td></tr>
<tr><td><code id="permustats_+3A_names">names</code></td>
<td>
<p>Names of boxes (default: names of statistics).</p>
</td></tr>
<tr><td><code id="permustats_+3A_...">...</code></td>
<td>
<p> Other arguments passed to the function. In
<code>density</code> these are passed to <code><a href="stats.html#topic+density.default">density.default</a></code>,
and in <code>boxplot</code> to <code><a href="graphics.html#topic+boxplot.default">boxplot.default</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>permustats</code> function extracts permutation results and
observed statistics from several <span class="pkg">vegan</span> functions that perform
permutations or simulations.
</p>
<p>The <code>summary</code> method of <code>permustats</code> estimates the
standardized effect sizes (SES) as the difference of observed
statistic and mean of permutations divided by the standard deviation
of permutations (also known as <code class="reqn">z</code>-values). It also prints the
the mean, median, and limits which contain <code>interval</code> percent
of permuted values. With the default (<code>interval = 0.95</code>), for
two-sided test these are (2.5%, 97.5%) and for one-sided tests
either 5% or 95% quantile and the <code class="reqn">p</code>-value depending on the
test direction. The mean, quantiles and <code class="reqn">z</code> values are evaluated
from permuted values without observed statistic, but the
<code class="reqn">p</code>-value is evaluated with the observed statistic. The
intervals and the <code class="reqn">p</code>-value are evaluated with the same test
direction as in the original test, but this can be changed with
argument <code>alternative</code>. Several <code>permustats</code> objects can
be combined with <code>c</code> function. The <code>c</code> function checks
that statistics are equal, but performs no other sanity tests.
</p>
<p>The <code>density</code> and <code>densityplot</code> methods display the
kernel density estimates of permuted values. When observed value of
the statistic is included in the permuted values, the
<code>densityplot</code> method marks the observed statistic as a vertical
line. However the <code>density</code> method uses its standard <code>plot</code>
method and cannot mark the observed value.
</p>
<p>The <code>qqnorm</code> and <code>qqmath</code> display Q-Q plots of
permutations, optionally together with the observed value (default)
which is shown as horizontal line in plots. <code>qqnorm</code> plots
permutation values against standard Normal variate. <code>qqmath</code>
defaults to the standard Normal as well, but can accept other
alternatives (see standard <code><a href="lattice.html#topic+qqmath">qqmath</a></code>). The
<code>qqmath</code> function can also plot observed statistic as
standardized effect size (SES) with standandized permutations
(argument <code>sd.scale</code>). The permutations are standardized
without the observed statistic, similarly as in <code>summary</code>.
</p>
<p>Functions <code><a href="stats.html#topic+density">density</a></code> and <code><a href="stats.html#topic+qqnorm">qqnorm</a></code> are based
on standard <span class="rlang"><b>R</b></span> methods and accept their arguments. They only handle
one statistic, and cannot be used when several test statistic were
evaluated. The <code><a href="lattice.html#topic+densityplot">densityplot</a></code> and
<code><a href="lattice.html#topic+qqmath">qqmath</a></code> are <span class="pkg">lattice</span> graphics, and can be
used either for one or for several statistics.  All these functions
pass arguments to their underlying functions; see their
documentation. Functions <code><a href="lattice.html#topic+qqmath">qqmath</a></code> and
<code><a href="lattice.html#topic+densityplot">densityplot</a></code> default to use same axis scaling
in all subplots of the lattice. You can use argument <code>scales</code> to
set independent scaling for subplots when this is appropriate (see
<code><a href="lattice.html#topic+xyplot">xyplot</a></code> for an exhaustive list of arguments).
</p>
<p>Function <code>boxplot</code> draws the box-and-whiskers plots of effect
size, or the difference of permutations and observed statistic. If
<code>scale = TRUE</code>, permutations are standardized to unit standard
deviation, and the plot will show the standardized effect sizes.
</p>
<p>Function <code>pairs</code> plots permutation values of statistics against
each other. The function passes extra arguments to
<code><a href="graphics.html#topic+pairs">pairs</a></code>.
</p>
<p>The <code>permustats</code> can extract permutation statistics from the
results of <code><a href="#topic+adonis2">adonis2</a></code>,
<code><a href="#topic+anosim">anosim</a></code>, <code><a href="#topic+anova.cca">anova.cca</a></code>, <code><a href="#topic+mantel">mantel</a></code>,
<code><a href="#topic+mantel.partial">mantel.partial</a></code>, <code><a href="#topic+mrpp">mrpp</a></code>,
<code><a href="#topic+oecosimu">oecosimu</a></code>, <code><a href="#topic+ordiareatest">ordiareatest</a></code>,
<code><a href="#topic+permutest.cca">permutest.cca</a></code>, <code><a href="#topic+protest">protest</a></code>, and
<code><a href="#topic+permutest.betadisper">permutest.betadisper</a></code>.
</p>


<h3>Value</h3>

<p>The <code>permustats</code> function returns an object of class
<code>"permustats"</code>. This is a list of items <code>"statistic"</code> for
observed statistics, <code>permutations</code> which contains permuted
values, and <code>alternative</code> which contains text defining the
character of the test (<code>"two.sided"</code>, <code>"less"</code> or
<code>"greater"</code>). The <code><a href="stats.html#topic+qqnorm">qqnorm</a></code> and
<code><a href="stats.html#topic+density">density</a></code> methods return their standard result objects.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen with contributions from Gavin L. Simpson
(<code>permustats.permutest.betadisper</code> method and related
modifications to <code>summary.permustats</code> and the <code>print</code>
method) and Eduard Sz√∂cs (<code>permustats.anova.cca).</code>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+density">density</a></code>, <code><a href="lattice.html#topic+densityplot">densityplot</a></code>,
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code>, <code><a href="lattice.html#topic+qqmath">qqmath</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune, dune.env)
mod &lt;- adonis2(dune ~ Management + A1, data = dune.env)
## use permustats
perm &lt;- permustats(mod)
summary(perm)
densityplot(perm)
qqmath(perm)
boxplot(perm, scale=TRUE, lty=1, pch=16, cex=0.6, col="hotpink", ylab="SES")
abline(h=0, col="skyblue")
## example of multiple types of statistic
mod &lt;- with(dune.env, betadisper(vegdist(dune), Management))
pmod &lt;- permutest(mod, nperm = 99, pairwise = TRUE)
perm &lt;- permustats(pmod)
summary(perm, interval = 0.90)
</code></pre>

<hr>
<h2 id='permutations'>Permutation tests in Vegan</h2><span id='topic+permutations'></span>

<h3>Description</h3>

<p>From version 2.2-0, <span class="pkg">vegan</span> has significantly improved access to
restricted permutations which brings it into line with those offered
by Canoco. The permutation designs are modelled after the permutation
schemes of Canoco 3.1 (ter Braak, 1990).
</p>
<p><span class="pkg">vegan</span> currently provides for the following features within
permutation tests:
</p>

<ol>
<li><p>Free permutation of <em>DATA</em>, also known as randomisation,
</p>
</li>
<li><p>Free permutation of <em>DATA</em> within the levels of a
grouping variable,
</p>
</li>
<li><p>Restricted permutations for line transects or time series,
</p>
</li>
<li><p>Permutation of groups of samples whilst retaining the
within-group ordering,
</p>
</li>
<li><p>Restricted permutations for spatial grids,
</p>
</li>
<li><p>Blocking, samples are never permuted <em>between</em> blocks,
and
</p>
</li>
<li><p>Split-plot designs, with permutation of whole plots, split
plots, or both.
</p>
</li></ol>

<p>Above, we use <em>DATA</em> to mean either the observed data themselves
or some function of the data, for example the residuals of an
ordination model in the presence of covariables.
</p>
<p>These capabilities are provided by functions from the <span class="pkg">permute</span>
package. The user can request a particular type of permutation by
supplying the <code>permutations</code> argument of a function with an
object returned by <code><a href="permute.html#topic+how">how</a></code>, which defines how samples should
be permuted. Alternatively, the user can simply specify the required
number of permutations and a simple randomisation procedure will be
performed. Finally, the user can supply a matrix of permutations (with
number of rows equal to the number of permutations and number of
columns equal to the number of observations in the data) and
<span class="pkg">vegan</span> will use these permutations instead of generating new
permutations.
</p>
<p>The majority of functions in <span class="pkg">vegan</span> allow for the full range of
possibilities outlined above. Exceptions include
<code><a href="#topic+kendall.post">kendall.post</a></code> and <code><a href="#topic+kendall.global">kendall.global</a></code>.
</p>
<p>The Null hypothesis for the first two types of permutation test listed
above assumes free exchangeability of <em>DATA</em> (within the levels
of the grouping variable, if specified). Dependence between
observations, such as that which arises due to spatial or temporal
autocorrelation, or more-complicated experimental designs, such as
split-plot designs, violates this fundamental assumption of the test
and requires more complex restricted permutation test designs. It is
these designs that are available via the <span class="pkg">permute</span> package and to
which <span class="pkg">vegan</span> provides access from version 2.2-0 onwards.
</p>
<p>Unless otherwise stated in the help pages for specific functions,
permutation tests in <span class="pkg">vegan</span> all follow the same format/structure:
</p>

<ol>
<li><p>An appropriate test statistic is chosen. Which statistic is
chosen should be described on the help pages for individual
functions.
</p>
</li>
<li><p>The value of the test statistic is evaluate for the observed
data and analysis/model and recorded. Denote this value
<code class="reqn">x_0</code>.
</p>
</li>
<li><p>The <em>DATA</em> are randomly permuted according to one of the
above schemes, and the value of the test statistic for this
permutation is evaluated and recorded.
</p>
</li>
<li><p>Step 3 is repeated a total of <code class="reqn">n</code> times, where <code class="reqn">n</code> is
the number of permutations requested. Denote these values as
<code class="reqn">x_i</code>, where <code class="reqn">i = 1, ..., n</code>
</p>
</li>
<li><p>Count the number of values of the test statistic,
<code class="reqn">x_i</code>, in the Null distribution that are as extreme as
test statistic for the observed data <code class="reqn">x_0</code>. Denote this
count as <code class="reqn">N</code>.
</p>
<p>We use the phrase <em>as extreme</em> to include cases where a
two-sided test is performed and large negative values of the test
statistic should be considered.
</p>
</li>
<li><p>The permutation p-value is computed as
</p>
<p style="text-align: center;"><code class="reqn">p = \frac{N + 1}{n + 1}</code>
</p>

</li></ol>

<p>The above description illustrates why the default number of
permutations specified in <span class="pkg">vegan</span> functions takes values of 199 or
999 for example. Pretty <em>p</em> values are achieved because the
<code class="reqn">+ 1</code> in the denominator results in division by 200 or 1000, for
the 199 or 999 random permutations used in the test.
</p>
<p>The simple intuition behind the presence of <code class="reqn">+ 1</code> in the numerator
and denominator is that these represent the inclusion of the observed
value of the statistic in the Null distribution (e.g. Manly 2006).
Phipson &amp; Smyth (2010) present a more compelling explanation for the
inclusion of <code class="reqn">+ 1</code> in the numerator and denominator of the
<em>p</em> value calculation.
</p>
<p>Fisher (1935) had in mind that a permutation test would involve
enumeration of all possible permutations of the data yielding an exact
test. However, doing this complete enumeration may not be feasible in
practice owing to the potentially vast number of arrangements of the
data, even in modestly-sized data sets with free permutation of
samples. As a result we evaluate the <em>p</em> value as the tail
probability of the Null distribution of the test statistic directly
from the random sample of possible permutations. Phipson &amp; Smyth
(2010) show that the naive calculation of the permutation <em>p</em>
value is
</p>
<p style="text-align: center;"><code class="reqn">p = \frac{N}{n}</code>
</p>

<p>which leads to an invalid test with incorrect type I error rate. They
go on to show that by replacing the unknown tail probability (the
<em>p</em> value) of the Null distribution with the biased estimator
</p>
<p style="text-align: center;"><code class="reqn">p = \frac{N + 1}{n + 1}</code>
</p>

<p>that the positive bias induced is of just the right size to
account for the  uncertainty in the estimation of the tail probability
from the set of randomly sampled permutations to yield a test with the
correct type I error rate.
</p>
<p>The estimator described above is correct for the situation where
permutations of the data are samples randomly <em>without</em>
replacement. This is not strictly what happens in <span class="pkg">vegan</span> because
permutations are drawn pseudo-randomly independent of one
another. Note that the actual chance of this happening is practice is
small but the functions in <span class="pkg">permute</span> do not guarantee to generate
a unique set of permutations unless complete enumeration of
permutations is requested. This is not feasible for all but the
smallest of data sets or restrictive of permutation designs, but in
such cases the chance of drawing a set of permutations with repeats is
lessened as the sample size, and thence the size of set of all
possible permutations, increases.
</p>
<p>Under the situation of sampling permutations with replacement then,
the tail probability <code class="reqn">p</code> calculated from the biased estimator
described above is somewhat <strong>conservative</strong>, being too large by
an amount that depends on the number of possible values that the test
statistic can take under permutation of the data (Phipson &amp; Smyth,
2010). This represents a slight loss of statistical power for the
conservative <em>p</em> value calculation used here. However, unless
sample sizes are small and the the permutation design such that the
set of values that the test statistic can take is also small, this
loss of power is unlikely to be critical.
</p>
<p>The minimum achievable p-value is
</p>
<p style="text-align: center;"><code class="reqn">p_{\mathrm{min}} = \frac{1}{n + 1}</code>
</p>

<p>and hence depends on the number of permutations evaluated. However,
one cannot simply increase the number of permutations (<code class="reqn">n</code>) to
achieve a potentially lower p-value unless the number of observations
available permits such a number of permutations. This is unlikely to
be a problem for all but the smallest data sets when free permutation
(randomisation) is valid, but in restricted permutation designs with a
low number of observations, there may not be as many unique
permutations of the data as you might desire to reach the required
level of significance.
</p>
<p>It is currently the responsibility of the user to determine the total
number of possible permutations for their <em>DATA</em>. The number of
possible permutations allowed under the specified design can be
calculated using <code><a href="permute.html#topic+numPerms">numPerms</a></code> from the
<span class="pkg">permute</span> package. Heuristics employed within the
<code><a href="permute.html#topic+shuffleSet">shuffleSet</a></code> function used by <span class="pkg">vegan</span> can be
triggered to generate the entire set of permutations instead of a
random set. The settings controlling the triggering of the complete
enumeration step are contained within a permutation design created
using <code>link[permute]{how}</code> and can be set by the user. See
<code><a href="permute.html#topic+how">how</a></code> for details.
</p>
<p>Limits on the total number of permutations of <em>DATA</em> are more
severe in temporally or spatially ordered data or experimental designs
with low replication. For example, a time series of <code class="reqn">n = 100</code>
observations has just 100 possible permutations <strong>including</strong> the
observed ordering.
</p>
<p>In situations where only a low number of permutations is possible due
to the nature of <em>DATA</em> or the experimental design, enumeration
of all permutations becomes important and achievable computationally.
</p>
<p>Above, we have provided only a brief overview of the capabilities of
<span class="pkg">vegan</span> and <span class="pkg">permute</span>. To get the best out of the new
functionality and for details on how to set up permutation designs
using <code><a href="permute.html#topic+how">how</a></code>, consult the vignette
<em>Restricted permutations; using the permute package</em> supplied
with <span class="pkg">permute</span> and accessible via <code>vignette("permutations",
  package = "permute").</code>
</p>


<h3>Random Number Generation</h3>

<p>The permutations are based on the random number generator provided
by <span class="rlang"><b>R</b></span>. This may change in <span class="rlang"><b>R</b></span> releases and change the permutations
and <span class="pkg">vegan</span> test results. One such change was in <span class="rlang"><b>R</b></span> release
3.6.0. The new version is clearly better for permutation tests and
you should use it. However, if you need to reproduce old results,
you can set the <span class="rlang"><b>R</b></span> random number generator to a previous version
with <code><a href="base.html#topic+RNGversion">RNGversion</a></code>.
</p>


<h3>Author(s)</h3>

<p> Gavin L. Simpson </p>


<h3>References</h3>

<p>Manly, B. F. J. (2006). <em>Randomization, Bootstrap and Monte Carlo
Methods in Biology</em>, Third Edition. Chapman and Hall/CRC.
</p>
<p>Phipson, B., &amp; Smyth, G. K. (2010). Permutation P-values should never
be zero: calculating exact P-values when permutations are randomly
drawn. <em>Statistical Applications in Genetics and Molecular
Biology</em>, <strong>9</strong>, Article 39. DOI: 10.2202/1544-6115.1585
</p>
<p>ter Braak, C. J. F. (1990). <em>Update notes: CANOCO version
3.1</em>. Wageningen: Agricultural Mathematics Group. (UR).
</p>
<p>See also:
</p>
<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap Methods and
their Application</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+permutest">permutest</a></code> for the main interface in <span class="pkg">vegan</span>. See
also <code><a href="permute.html#topic+how">how</a></code> for details on permutation design
specification, <code><a href="permute.html#topic+shuffleSet">shuffleSet</a></code> for the code used to
generate a set of permutations, <code><a href="permute.html#topic+numPerms">numPerms</a></code> for
a function to return the size of the set of possible permutations
under the current design.
</p>

<hr>
<h2 id='permutest.betadisper'>Permutation test of multivariate homogeneity of groups dispersions
(variances)</h2><span id='topic+permutest.betadisper'></span>

<h3>Description</h3>

<p>Implements a permutation-based test of multivariate homogeneity of
group dispersions (variances) for the results of a call to
<code><a href="#topic+betadisper">betadisper</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'betadisper'
permutest(x, pairwise = FALSE,
          permutations = 999,
          parallel = getOption("mc.cores"),
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permutest.betadisper_+3A_x">x</code></td>
<td>
<p>an object of class <code>"betadisper"</code>, the result of a
call to <code>betadisper</code>.</p>
</td></tr>
<tr><td><code id="permutest.betadisper_+3A_pairwise">pairwise</code></td>
<td>
<p>logical; perform pairwise comparisons of group means?</p>
</td></tr>
<tr><td><code id="permutest.betadisper_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="permutest.betadisper_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing.</p>
</td></tr>
<tr><td><code id="permutest.betadisper_+3A_...">...</code></td>
<td>
<p>Arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To test if one or more groups is more variable than the others, ANOVA
of the distances to group centroids can be performed and parametric
theory used to interpret the significance of F. An alternative is to
use a permutation test. <code>permutest.betadisper</code> permutes model
residuals to generate a permutation distribution of F under the Null
hypothesis of no difference in dispersion between groups.
</p>
<p>Pairwise comparisons of group mean dispersions can be performed by
setting argument <code>pairwise</code> to <code>TRUE</code>. A classical t test
is performed on the pairwise group dispersions. This is combined with a
permutation test based on the t statistic calculated on pairwise group
dispersions. An alternative to the classical comparison of group
dispersions, is to calculate Tukey's Honest Significant Differences
between groups, via <code><a href="#topic+TukeyHSD.betadisper">TukeyHSD.betadisper</a></code>.
</p>


<h3>Value</h3>

<p><code>permutest.betadisper</code> returns a list of class
<code>"permutest.betadisper"</code> with the following components:
</p>
<table>
<tr><td><code>tab</code></td>
<td>
<p>the ANOVA table which is an object inheriting from class
<code>"data.frame"</code>.</p>
</td></tr>
<tr><td><code>pairwise</code></td>
<td>
<p>a list with components <code>observed</code> and
<code>permuted</code> containing the observed and permuted p-values for
pairwise comparisons of group mean distances (dispersions or variances).</p>
</td></tr>
<tr><td><code>groups</code></td>
<td>
<p>character; the levels of the grouping factor.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>a list, the result of a call to
<code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gavin L. Simpson</p>


<h3>References</h3>

<p>Anderson, M.J. (2006) Distance-based tests for homogeneity of
multivariate dispersions. <em>Biometrics</em> <strong>62(1)</strong>, 245&ndash;253.
</p>
<p>Anderson, M.J., Ellingsen, K.E. &amp; McArdle, B.H. (2006) Multivariate
dispersion as a measure of beta diversity. <em>Ecology Letters</em>
<strong>9(6)</strong>, 683&ndash;693.
</p>


<h3>See Also</h3>

<p>For the main fitting function see <code><a href="#topic+betadisper">betadisper</a></code>. For
an alternative approach to determining which groups are more variable,
see <code><a href="#topic+TukeyHSD.betadisper">TukeyHSD.betadisper</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)

## Bray-Curtis distances between samples
dis &lt;- vegdist(varespec)

## First 16 sites grazed, remaining 8 sites ungrazed
groups &lt;- factor(c(rep(1,16), rep(2,8)), labels = c("grazed","ungrazed"))

## Calculate multivariate dispersions
mod &lt;- betadisper(dis, groups)
mod

## Perform test
anova(mod)

## Permutation test for F
pmod &lt;- permutest(mod, permutations = 99, pairwise = TRUE)

## Tukey's Honest Significant Differences
(mod.HSD &lt;- TukeyHSD(mod))
plot(mod.HSD)

## Has permustats() method
pstat &lt;- permustats(pmod)
densityplot(pstat, scales = list(x = list(relation = "free")))
qqmath(pstat, scales = list(relation = "free"))
</code></pre>

<hr>
<h2 id='plot.cca'>Plot or Extract Results of Constrained Correspondence Analysis
or Redundancy Analysis</h2><span id='topic+plot.cca'></span><span id='topic+text.cca'></span><span id='topic+points.cca'></span><span id='topic+scores.cca'></span><span id='topic+scores.rda'></span><span id='topic+summary.cca'></span><span id='topic+print.summary.cca'></span><span id='topic+head.summary.cca'></span><span id='topic+tail.summary.cca'></span><span id='topic+labels.cca'></span>

<h3>Description</h3>

<p>Functions to plot or extract results of constrained correspondence analysis
(<code><a href="#topic+cca">cca</a></code>), redundancy analysis (<code><a href="#topic+rda">rda</a></code>) or
constrained analysis of principal coordinates (<code><a href="#topic+capscale">capscale</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
plot(x, choices = c(1, 2), display = c("sp", "wa", "cn"),
     scaling = "species", type, xlim, ylim, const,
     correlation = FALSE, hill = FALSE, ...)
## S3 method for class 'cca'
text(x, display = "sites", labels, choices = c(1, 2),
     scaling = "species", arrow.mul, head.arrow = 0.05, select, const,
     axis.bp = FALSE, correlation = FALSE, hill = FALSE, ...)
## S3 method for class 'cca'
points(x, display = "sites", choices = c(1, 2),
       scaling = "species", arrow.mul, head.arrow = 0.05, select, const,
       axis.bp = FALSE, correlation = FALSE, hill = FALSE, ...)
## S3 method for class 'cca'
scores(x, choices = c(1,2), display = c("sp","wa","bp","cn"),
       scaling = "species", hill = FALSE, tidy = FALSE, ...)
## S3 method for class 'rda'
scores(x, choices = c(1,2), display = c("sp","wa","bp","cn"),
       scaling = "species", const, correlation = FALSE, tidy = FALSE, ...)
## S3 method for class 'cca'
summary(object, scaling = "species", axes = 6,
        display = c("sp", "wa", "lc", "bp", "cn"),
        digits = max(3, getOption("digits") - 3),
        correlation = FALSE, hill = FALSE, ...)
## S3 method for class 'summary.cca'
print(x, digits = x$digits, head = NA, tail = head, ...)
## S3 method for class 'summary.cca'
head(x, n = 6, tail = 0, ...)
## S3 method for class 'summary.cca'
tail(x, n = 6, head = 0, ...)
## S3 method for class 'cca'
labels(object, display, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cca_+3A_x">x</code>, <code id="plot.cca_+3A_object">object</code></td>
<td>
<p>A <code>cca</code> result object.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_choices">choices</code></td>
<td>
<p>Axes shown.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_display">display</code></td>
<td>
<p>Scores shown.  These must include some of the
alternatives <code>"species"</code> or <code>"sp"</code> for species scores,
<code>sites</code> or <code>"wa"</code> for site scores, <code>"lc"</code> for linear
constraints or LC scores, or <code>"bp"</code> for biplot arrows or
<code>"cn"</code> for centroids of factor constraints instead of an arrow,
and <code>"reg"</code> for regression coefficients (a.k.a. canonical
coefficients). The alternative <code>"all"</code> selects all available
scores.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_scaling">scaling</code></td>
<td>
<p>Scaling for species and site scores. Either species
(<code>2</code>) or site (<code>1</code>) scores are scaled by eigenvalues, and
the other set of scores is left unscaled, or with <code>3</code> both are
scaled symmetrically by square root of eigenvalues.  Corresponding
negative values can be used in <code>cca</code> to additionally multiply
results with <code class="reqn">\sqrt(1/(1-\lambda))</code>.  This scaling is know as Hill
scaling (although it has nothing to do with Hill's rescaling of
<code><a href="#topic+decorana">decorana</a></code>). With corresponding negative values
in <code>rda</code>, species scores are divided by standard deviation of each
species and multiplied with an equalizing constant. Unscaled raw
scores stored in the result can be accessed with <code>scaling = 0</code>.
</p>
<p>The type of scores can also be specified as one of <code>"none"</code>,
<code>"sites"</code>, <code>"species"</code>, or <code>"symmetric"</code>, which
correspond to the values <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>
respectively. Arguments <code>correlation</code> and <code>hill</code> in
<code>scores.rda</code> and <code>scores.cca</code> respectively can be used in
combination with these character descriptions to get the
corresponding negative value.
</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_correlation">correlation</code>, <code id="plot.cca_+3A_hill">hill</code></td>
<td>
<p>logical; if <code>scaling</code> is a character
description of the scaling type, <code>correlation</code> or <code>hill</code>
are used to select the corresponding negative scaling type; either
correlation-like scores or Hill's scaling for PCA/RDA and CA/CCA
respectively. See argument <code>scaling</code> for details.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_tidy">tidy</code></td>
<td>
<p>Return scores that are compatible with
<a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>: all scores are in a single <code>data.frame</code>,
score type is identified by factor variable <code>score</code>, the
names by variable <code>label</code>, and weights (in CCA) are in
variable <code>weight</code>. The possible values of <code>score</code> are
<code>species</code>, <code>sites</code> (for WA scores), <code>constraints</code>
(LC scores for sites calculated directly from the constraining
variables), <code>biplot</code> (for biplot arrows), <code>centroids</code>
(for levels of factor variables), <code>factorbiplot</code> (biplot
arrows that model centroids), <code>regression</code> (for regression
coefficients to find LC scores from constraints). These scores
cannot be used with conventional <code>plot</code>, but they are
directly suitable to be used with the <span class="pkg">ggplot2</span> package.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_type">type</code></td>
<td>
<p>Type of plot: partial match to <code>text</code>
for text labels, <code>points</code> for points, and <code>none</code> for
setting frames only.  If omitted, <code>text</code> is selected for
smaller data sets, and <code>points</code> for larger.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_xlim">xlim</code>, <code id="plot.cca_+3A_ylim">ylim</code></td>
<td>
<p>the x and y limits (min,max) of the plot.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_labels">labels</code></td>
<td>
<p>Optional text to be used instead of row names. If you
use this, it is good to check the default labels and their order
using <code>labels</code> command.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_arrow.mul">arrow.mul</code></td>
<td>
<p>Factor to expand arrows in the graph.  Arrows will be
scaled automatically to fit the graph if this is missing.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_head.arrow">head.arrow</code></td>
<td>
<p>Default length of arrow heads.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_select">select</code></td>
<td>
<p>Items to be displayed.  This can either be a logical
vector which is <code>TRUE</code> for displayed items or a vector of indices
of displayed items.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_const">const</code></td>
<td>
<p>General scaling constant to <code>rda</code> scores. The
default is to use a constant that gives biplot scores, that is,
scores that approximate original data (see <code><a href="utils.html#topic+vignette">vignette</a></code>
on &lsquo;Design Decisions&rsquo; with <code>browseVignettes("vegan")</code>
for details and discussion). If <code>const</code> is a vector of two
items, the first is used for species, and the second item for site
scores.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_axis.bp">axis.bp</code></td>
<td>
<p>Draw <code><a href="graphics.html#topic+axis">axis</a></code> for biplot arrows.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_axes">axes</code></td>
<td>
<p>Number of axes in summaries.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_digits">digits</code></td>
<td>
<p>Number of digits in output.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_n">n</code>, <code id="plot.cca_+3A_head">head</code>, <code id="plot.cca_+3A_tail">tail</code></td>
<td>
<p>Number of rows printed from the head and tail of
species and site scores.  Default <code>NA</code> prints all.</p>
</td></tr>
<tr><td><code id="plot.cca_+3A_...">...</code></td>
<td>
<p>Parameters passed to other functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Same <code>plot</code> function will be used for <code><a href="#topic+cca">cca</a></code> and
<code><a href="#topic+rda">rda</a></code>. This produces a quick, standard plot with current
<code>scaling</code>.
</p>
<p>The <code>plot</code> function sets colours (<code>col</code>), plotting
characters (<code>pch</code>) and character sizes (<code>cex</code>) to
certain standard values. For a fuller control of produced plot, it is
best to call <code>plot</code> with <code>type="none"</code> first, and then add
each plotting item separately using <code>text.cca</code> or
<code>points.cca</code> functions. These use the default settings of standard
<code><a href="graphics.html#topic+text">text</a></code> and <code><a href="graphics.html#topic+points">points</a></code> functions and accept all
their parameters, allowing  a full user control of produced plots.
</p>
<p>Environmental variables receive a special treatment. With
<code>display="bp"</code>, arrows will be drawn. These are labelled with
<code>text</code> and unlabelled with <code>points</code>. The arrows have
basically unit scaling, but if sites were scaled (<code>scaling</code>
<code>"sites"</code> or <code>"symmetric"</code>), the scores of requested axes
are adjusted relative to the axis with highest eigenvalue.  With
<code>scaling = "species"</code> or <code>scaling = "none"</code>, the arrows will
be consistent with vectors fitted to linear combination scores
(<code>display = "lc"</code> in function <code><a href="#topic+envfit">envfit</a></code>), but with
other scaling alternatives they will differ. The basic <code>plot</code>
function uses a simple heuristics for adjusting the unit-length arrows
to the current plot area, but the user can give the expansion factor
in <code>mul.arrow</code>.  With <code>display="cn"</code> the centroids of levels
of <code><a href="base.html#topic+factor">factor</a></code> variables are displayed (these are available
only if there were factors and a formula interface was used in
<code><a href="#topic+cca">cca</a></code> or <code><a href="#topic+rda">rda</a></code>). With this option continuous
variables still are presented as arrows and ordered factors as arrows
and centroids. With <code>display = "reg"</code> arrows will be drawn for
regression coefficients (a.k.a. canonical coefficients) of constraints
and conditions. Biplot arrows can be interpreted individually, but
regression coefficients must be interpreted all together: the LC score
for each site is the sum of regressions displayed by arrows. The
partialled out conditions are zero and not shown in biplot arrows, but
they are shown for regressions, and show the effect that must be
partialled out to get the LC scores. The biplot arrows are more
standard and more easily interpreted, and regression arrows should be
used only if you know that you need them.
</p>
<p>If you want to have a better control of plots, it is best to
construct the plot <code>text</code> and <code>points</code> commands which
accept graphical parameters. It is important to remember to use the
same <code>scaling</code>, <code>correlation</code> and <code>hill</code> arguments
in all calls. The <code>plot.cca</code> command returns invisibly an
<code><a href="#topic+ordiplot">ordiplot</a></code> result object, and this will have consistent
scaling for all its elements. The easiest way for full control of
graphics is to first set up the plot frame using <code>plot</code> with
<code>type = "n"</code> and all needed scores in <code>display</code> and save
this result. The <code>points</code> and <code>text</code> commands for
<code><a href="#topic+ordiplot">ordiplot</a></code> will allow full graphical control (see
section Examples). Utility function <code>labels</code> returns the default
labels in the order they are applied in <code>text</code>.
</p>
<p>Function <code>summary</code> lists all scores and the output can be very
long.  You can suppress scores by setting <code>axes = 0</code> or
<code>display = NA</code> or <code>display = NULL</code>. You can display some
first or last (or both) rows of scores by using <code>head</code> or
<code>tail</code> or explicit <code>print</code> command for the <code>summary</code>.
</p>
<p>Palmer (1993) suggested using linear constraints (&ldquo;LC scores&rdquo;)
in ordination diagrams, because these gave better results in
simulations and site scores (&ldquo;WA scores&rdquo;) are a step from
constrained to unconstrained analysis.  However, McCune (1997) showed
that noisy environmental variables (and all environmental measurements
are noisy) destroy &ldquo;LC scores&rdquo; whereas &ldquo;WA scores&rdquo; were
little affected.  Therefore the <code>plot</code> function uses site scores
(&ldquo;WA scores&rdquo;) as the default. This is consistent with the usage
in statistics and other functions in <span class="rlang"><b>R</b></span> (<code><a href="MASS.html#topic+lda">lda</a></code>,
<code><a href="stats.html#topic+cancor">cancor</a></code>).  </p>


<h3>Value</h3>

<p> The <code>plot</code> function returns
invisibly a plotting structure which can be used by function
<code><a href="#topic+identify.ordiplot">identify.ordiplot</a></code> to identify the points or other
functions in the <code><a href="#topic+ordiplot">ordiplot</a></code> family.  </p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>See Also</h3>

<p><code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code> and <code><a href="#topic+capscale">capscale</a></code>
for getting something
to plot, <code><a href="#topic+ordiplot">ordiplot</a></code> for an alternative plotting routine
and more support functions, and <code><a href="graphics.html#topic+text">text</a></code>,
<code><a href="graphics.html#topic+points">points</a></code> and <code><a href="graphics.html#topic+arrows">arrows</a></code> for the basic routines.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
mod &lt;- cca(dune ~ A1 + Moisture + Management, dune.env)
## better control -- remember to set scaling etc identically
plot(mod, type="n", scaling="sites")
text(mod, dis="cn", scaling="sites")
points(mod, pch=21, col="red", bg="yellow", cex=1.2, scaling="sites")
text(mod, "species", col="blue", cex=0.8, scaling="sites")
## catch the invisible result and use ordiplot support - the example
## will make a biplot with arrows for species and correlation scaling
pca &lt;- rda(dune)
pl &lt;- plot(pca, type="n", scaling="sites", correlation=TRUE)
with(dune.env, points(pl, "site", pch=21, col=1, bg=Management))
text(pl, "sp", arrow=TRUE, length=0.05, col=4, cex=0.6, xpd=TRUE)
with(dune.env, legend("bottomleft", levels(Management), pch=21, pt.bg=1:4, bty="n"))
## Limited output of 'summary' (NB. Signs of axes are arbitrary and can change
## when the command is run repeatedly).
## IGNORE_RDIFF_BEGIN
head(summary(mod), tail=2)
## IGNORE_RDIFF_END
## Scaling can be numeric or more user-friendly names
## e.g. Hill's scaling for (C)CA
scrs &lt;- scores(mod, scaling = "sites", hill = TRUE)
## or correlation-based scores in PCA/RDA
scrs &lt;- scores(rda(dune ~ A1 + Moisture + Management, dune.env),
               scaling = "sites", correlation = TRUE)
</code></pre>

<hr>
<h2 id='prc'>Principal Response Curves for Treatments with Repeated Observations </h2><span id='topic+prc'></span><span id='topic+summary.prc'></span><span id='topic+plot.prc'></span>

<h3>Description</h3>

<p> Principal Response Curves (PRC) are a special case of
Redundancy Analysis (<code><a href="#topic+rda">rda</a></code>) for multivariate responses in
repeated observation design. They were originally suggested for
ecological communities. They should be easier to interpret than
traditional constrained ordination. They can also be used to study how
the effects of a factor <code>A</code> depend on the levels of a factor
<code>B</code>, that is <code>A + A:B</code>, in a multivariate response
experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prc(response, treatment, time, ...)
## S3 method for class 'prc'
summary(object, axis = 1, scaling = "symmetric", const,
        digits = 4, correlation = FALSE, ...)
## S3 method for class 'prc'
plot(x, species = TRUE, select, scaling = "symmetric",
     axis = 1, correlation = FALSE, const, type = "l", xlab, ylab, ylim,
     lty = 1:5, col = 1:6, pch, legpos, cex = 0.8, ...)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prc_+3A_response">response</code></td>
<td>
<p>Multivariate response data. Typically these are
community (species) data. If the data are counts, they probably
should be log transformed prior to the analysis. </p>
</td></tr>
<tr><td><code id="prc_+3A_treatment">treatment</code></td>
<td>
<p>A factor for treatments. </p>
</td></tr>
<tr><td><code id="prc_+3A_time">time</code></td>
<td>
<p> An unordered factor defining the observations times in
the repeated design.</p>
</td></tr>
<tr><td><code id="prc_+3A_object">object</code>, <code id="prc_+3A_x">x</code></td>
<td>
<p>An <code>prc</code> result object.</p>
</td></tr>
<tr><td><code id="prc_+3A_axis">axis</code></td>
<td>
<p>Axis shown (only one axis can be selected).</p>
</td></tr>
<tr><td><code id="prc_+3A_scaling">scaling</code></td>
<td>
<p>Scaling of species scores, identical to the
<code>scaling</code> in <code><a href="#topic+scores.rda">scores.rda</a></code>.
</p>
<p>The type of scores can also be specified as one of <code>"none"</code>,
<code>"sites"</code>, <code>"species"</code>, or <code>"symmetric"</code>, which
correspond to the values <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>
respectively. Argument <code>correlation</code> can be used in combination
with these character descriptions to get the corresponding negative
value.
</p>
</td></tr>
<tr><td><code id="prc_+3A_const">const</code></td>
<td>
<p>General scaling constant for species scores (see
<code><a href="#topic+scores.rda">scores.rda</a></code> for details). Lower values will reduce the
range of species scores, but will not influence the regression
coefficients.</p>
</td></tr>
<tr><td><code id="prc_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits displayed.</p>
</td></tr>
<tr><td><code id="prc_+3A_correlation">correlation</code></td>
<td>
<p>logical; if <code>scaling</code> is a character
description of the scaling type, <code>correlation</code> can be used to
select correlation-like scores for PCA. See argument <code>scaling</code>
for details.</p>
</td></tr>
<tr><td><code id="prc_+3A_species">species</code></td>
<td>
<p>Display species scores.</p>
</td></tr>
<tr><td><code id="prc_+3A_select">select</code></td>
<td>
<p>Vector to select displayed species. This can be a vector
of indices or a logical vector which is <code>TRUE</code> for the selected
species</p>
</td></tr>
<tr><td><code id="prc_+3A_type">type</code></td>
<td>
<p>Type of plot: <code>"l"</code> for lines, <code>"p"</code> for points
or <code>"b"</code> for both.</p>
</td></tr>
<tr><td><code id="prc_+3A_xlab">xlab</code>, <code id="prc_+3A_ylab">ylab</code></td>
<td>
<p>Text to replace default axis labels.</p>
</td></tr>
<tr><td><code id="prc_+3A_ylim">ylim</code></td>
<td>
<p>Limits for the vertical axis.</p>
</td></tr>
<tr><td><code id="prc_+3A_lty">lty</code>, <code id="prc_+3A_col">col</code>, <code id="prc_+3A_pch">pch</code></td>
<td>
<p>Line type, colour and plotting characters
(defaults supplied).</p>
</td></tr>
<tr><td><code id="prc_+3A_legpos">legpos</code></td>
<td>
<p>The position of the <code><a href="graphics.html#topic+legend">legend</a></code>. A guess is
made if this is not supplied, and <code>NA</code> will suppress legend. </p>
</td></tr>
<tr><td><code id="prc_+3A_cex">cex</code></td>
<td>
<p>Character expansion for symbols and species labels.</p>
</td></tr>
<tr><td><code id="prc_+3A_...">...</code></td>
<td>
<p> Other parameters passed to functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p> PRC is a special case of <code><a href="#topic+rda">rda</a></code> with a single
factor for <code>treatment</code> and a single factor for <code>time</code> points
in repeated observations. In <span class="pkg">vegan</span>, the corresponding
<code><a href="#topic+rda">rda</a></code> model is defined as <code>rda(response ~ treatment *
  time + Condition(time))</code>. Since the <code>time</code> appears twice in the
model formula, its main effects will be aliased, and only the main
effect of treatment and interaction terms are available, and will be
used in PRC. Instead of usual multivariate ordination diagrams, PRC
uses canonical (regression) coefficients and species scores for a
single axis. All that the current functions do is to provide a special
<code>summary</code> and <code>plot</code> methods that display the
<code><a href="#topic+rda">rda</a></code> results in the PRC fashion. The current version only
works with default contrasts (<code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code>) in which
the coefficients are contrasts against the first level, and the levels
must be arranged so that the first level is the control (or a
baseline). If necessary, you must change the baseline level with
function <code><a href="stats.html#topic+relevel">relevel</a></code>.  
</p>
<p>Function <code>summary</code> prints the species scores and the
coefficients. Function <code>plot</code> plots coefficients against
<code>time</code> using <code><a href="graphics.html#topic+matplot">matplot</a></code>, and has similar defaults.
The graph (and PRC) is meaningful only if the first <code>treatment</code>
level is the control, as the results are contrasts to the first level
when unordered factors are used. The plot also displays species scores
on the right vertical axis using function
<code><a href="#topic+linestack">linestack</a></code>. Typically the number of species is so high
that not all can be displayed with the default settings, but users can
reduce character size or padding (<code>air</code>) in
<code><a href="#topic+linestack">linestack</a></code>, or <code>select</code> only a subset of the
species. A legend will be displayed unless suppressed with
<code>legpos = NA</code>, and the functions tries to guess where to put the
legend if <code>legpos</code> is not supplied.
</p>


<h3>Value</h3>

<p>The function is a special case of <code><a href="#topic+rda">rda</a></code> and returns its
result object (see <code><a href="#topic+cca.object">cca.object</a></code>). However, a special
<code>summary</code> and <code>plot</code> methods display returns differently
than in <code><a href="#topic+rda">rda</a></code>.
</p>


<h3>Warning </h3>

<p>The first level of <code>treatment</code> must be the
control: use function <code><a href="stats.html#topic+relevel">relevel</a></code> to guarantee the correct
reference level. The current version will ignore user setting of
<code><a href="stats.html#topic+contrasts">contrasts</a></code> and always use treatment contrasts
(<code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code>). The <code>time</code> must be an unordered
factor.  </p>


<h3>Author(s)</h3>

<p> Jari Oksanen and Cajo ter Braak</p>


<h3>References</h3>

<p>van den Brink, P.J. &amp; ter Braak, C.J.F. (1999). Principal response
curves: Analysis of time-dependent multivariate responses of
biological community to stress. Environmental Toxicology and
Chemistry, 18, 138&ndash;148.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+anova.cca">anova.cca</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Chlorpyrifos experiment and experimental design: Pesticide
## treatment in ditches (replicated) and followed over from 4 weeks
## before to 24 weeks after exposure 
data(pyrifos)
week &lt;- gl(11, 12, labels=c(-4, -1, 0.1, 1, 2, 4, 8, 12, 15, 19, 24))
dose &lt;- factor(rep(c(0.1, 0, 0, 0.9, 0, 44, 6, 0.1, 44, 0.9, 0, 6), 11))
ditch &lt;- gl(12, 1, length=132)

## IGNORE_RDIFF_BEGIN
## PRC
mod &lt;- prc(pyrifos, dose, week)
mod            # RDA
summary(mod)   # PRC
logabu &lt;- colSums(pyrifos)
plot(mod, select = logabu &gt; 100)
## IGNORE_RDIFF_END
## Ditches are randomized, we have a time series, and are only
## interested in the first axis
ctrl &lt;- how(plots = Plots(strata = ditch,type = "free"),
    within = Within(type = "series"), nperm = 99)
anova(mod, permutations = ctrl, first=TRUE)
</code></pre>

<hr>
<h2 id='predict.cca'>Prediction Tools for [Constrained] Ordination (CCA,
RDA, DCA, CA, PCA) </h2><span id='topic+fitted.cca'></span><span id='topic+fitted.rda'></span><span id='topic+fitted.capscale'></span><span id='topic+fitted.dbrda'></span><span id='topic+residuals.cca'></span><span id='topic+predict.cca'></span><span id='topic+predict.rda'></span><span id='topic+predict.decorana'></span><span id='topic+coef.cca'></span><span id='topic+coef.rda'></span><span id='topic+calibrate.cca'></span><span id='topic+calibrate'></span>

<h3>Description</h3>

<p>Function <code>predict</code> can be used to find site and species scores or
estimates of the response data with new data sets, Function
<code>calibrate</code> estimates values of constraints with new data set.
Functions <code>fitted</code> and <code>residuals</code> return estimates of
response data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
fitted(object, model = c("CCA", "CA", "pCCA"),
    type =  c("response", "working"), ...)
## S3 method for class 'capscale'
fitted(object, model = c("CCA", "CA", "pCCA", "Imaginary"),
    type = c("response", "working"), ...)
## S3 method for class 'cca'
residuals(object, ...)
## S3 method for class 'cca'
predict(object, newdata, type = c("response", "wa", "sp", "lc", "working"),
        rank = "full", model = c("CCA", "CA"), scaling = "none",
        hill = FALSE, ...)
## S3 method for class 'rda'
predict(object, newdata, type = c("response", "wa", "sp", "lc", "working"),
        rank = "full", model = c("CCA", "CA"), scaling = "none",
        correlation = FALSE, const, ...)
## S3 method for class 'cca'
calibrate(object, newdata, rank = "full", ...)
## S3 method for class 'cca'
coef(object, norm = FALSE, ...)
## S3 method for class 'decorana'
predict(object, newdata, type = c("response", "sites", "species"),
    rank = 4, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cca_+3A_object">object</code></td>
<td>
<p>A result object from <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code>, <code><a href="#topic+capscale">capscale</a></code> or
<code><a href="#topic+decorana">decorana</a></code>. </p>
</td></tr>
<tr><td><code id="predict.cca_+3A_model">model</code></td>
<td>
<p>Show constrained (<code>"CCA"</code>), unconstrained
(<code>"CA"</code>) or conditioned &ldquo;partial&rdquo; (<code>"pCCA"</code>)
results. For <code>fitted</code> method of <code><a href="#topic+capscale">capscale</a></code> this can
also be <code>"Imaginary"</code> for imaginary components with negative
eigenvalues </p>
</td></tr>
<tr><td><code id="predict.cca_+3A_newdata">newdata</code></td>
<td>
<p>New data frame to be used in prediction or in
calibration.  Usually this a new community data frame, but with
<code>type = "lc"</code> and for constrained component with <code>type =
    "response"</code> and <code>type = "working"</code> it must be a data frame of
constraints.  The <code>newdata</code> must have the same number of rows
as the original community data for a <code><a href="#topic+cca">cca</a></code> result with
<code>type = "response"</code> or <code>type = "working"</code>.  If the
original model had row or column names, then new data must contain
rows or columns with the same names (row names for species scores,
column names for <code>"wa"</code> scores and constraint names of
<code>"lc"</code> scores). In other cases the rows or columns must match
directly. </p>
</td></tr>
<tr><td><code id="predict.cca_+3A_type">type</code></td>
<td>
<p>The type of prediction, fitted values or residuals:
<code>"response"</code> scales results so that the same ordination gives
the same results, and <code>"working"</code> gives the values used
internally, that is after Chi-square standardization in
<code><a href="#topic+cca">cca</a></code> and scaling and centring in
<code><a href="#topic+rda">rda</a></code>. In <code><a href="#topic+capscale">capscale</a></code> and
<code><a href="#topic+dbrda">dbrda</a></code> the <code>"response"</code> gives the
dissimilarities, and <code>"working"</code> the internal data structure
analysed in the ordination. Alternative <code>"wa"</code> gives the site
scores as weighted averages of the community data, <code>"lc"</code> the
site scores as linear combinations of environmental data, and
<code>"sp"</code> the species scores. In <code>predict.decorana</code> the
alternatives are scores for <code>"sites"</code> or <code>"species"</code>.</p>
</td></tr>
<tr><td><code id="predict.cca_+3A_rank">rank</code></td>
<td>
<p>The rank or the number of axes used in the approximation.
The default is to use all axes (full rank) of the <code>"model"</code> or
all available four axes in <code>predict.decorana</code>.</p>
</td></tr>
<tr><td><code id="predict.cca_+3A_scaling">scaling</code></td>
<td>
<p>logical, character, or numeric; Scaling or predicted
scores with the same meaning as in <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code>, and
<code><a href="#topic+capscale">capscale</a></code>. See <code>scores.cca</code> for further details
on acceptable values.</p>
</td></tr>
<tr><td><code id="predict.cca_+3A_correlation">correlation</code>, <code id="predict.cca_+3A_hill">hill</code></td>
<td>
<p>logical; correlation-like scores or Hill's
scaling as appropriate for RDA and CCA respectively. See
<code><a href="#topic+scores.cca">scores.cca</a></code> for additional details.</p>
</td></tr>
<tr><td><code id="predict.cca_+3A_const">const</code></td>
<td>
<p>Constant multiplier for  RDA scores. This will be used
only when <code>scaling</code> is not <code>FALSE</code>, and the default value
will give similar scaling as in <code><a href="#topic+scores.rda">scores.rda</a></code>.</p>
</td></tr>
<tr><td><code id="predict.cca_+3A_norm">norm</code></td>
<td>
<p>Coefficients for variables that are centred and scaled
to unit norm.</p>
</td></tr>
<tr><td><code id="predict.cca_+3A_...">...</code></td>
<td>
<p>Other parameters to the functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>fitted</code> gives the approximation of the original data
matrix or dissimilarities from the ordination result either in the
scale of the response or as scaled internally by the function.
Function <code>residuals</code> gives the approximation of the original data
from the unconstrained ordination.  With argument <code>type =
  "response"</code> the <code>fitted.cca</code> and <code>residuals.cca</code> function
both give the same marginal totals as the original data matrix, and
fitted and residuals do not add up to the original data.  Functions
<code>fitted</code> and <code>residuals</code> for <code><a href="#topic+dbrda">dbrda</a></code> and
<code><a href="#topic+capscale">capscale</a></code> give the dissimilarities with <code>type =
  "response"</code>, but these are not additive.  However, the
<code>"working"</code> scores are additive for <code><a href="#topic+capscale">capscale</a></code> (but
not for <code><a href="#topic+dbrda">dbrda</a></code>). The <code>fitted</code> and <code>residuals</code>
for <code><a href="#topic+capscale">capscale</a></code> and <code><a href="#topic+dbrda">dbrda</a></code> will include the
additive constant if that was requested in the function call.  All
variants of <code>fitted</code> and <code>residuals</code> are defined so that for
model <code>mod &lt;- cca(y ~ x)</code>, <code>cca(fitted(mod))</code> is equal to
constrained ordination, and <code>cca(residuals(mod))</code> is equal to
unconstrained part of the ordination.
</p>
<p>Function <code>predict</code> can find the estimate of the original data
matrix or dissimilarities (<code>type = "response"</code>) with any rank.
With <code>rank = "full"</code> it is identical to <code>fitted</code>.  In
addition, the function can find the species scores or site scores from
the community data matrix for <code><a href="#topic+cca">cca</a></code> or <code><a href="#topic+rda">rda</a></code>.
The function can be used with new data, and it can be used to add new
species or site scores to existing ordinations.  The function returns
(weighted) orthonormal scores by default, and you must specify
explicit <code>scaling</code> to add those scores to ordination
diagrams. With <code>type = "wa"</code> the function finds the site scores
from species scores. In that case, the new data can contain new sites,
but species must match in the original and new data.  With <code>type="sp"</code> 
the function finds species scores from site constraints
(linear combination scores). In that case the new data can contain new
species, but sites must match in the original and new data. With
<code>type = "lc"</code> the function finds the linear combination scores
for sites from environmental data. In that case the new data frame
must contain all constraining and conditioning environmental variables
of the model formula. With <code>type = "response"</code> or 
<code>type = "working"</code> the new data must contain environmental variables 
if constrained component is desired, and community data matrix if
residual or unconstrained component is desired.  With these types, the
function uses <code>newdata</code> to find new <code>"lc"</code> (constrained) or
<code>"wa"</code> scores (unconstrained) and then finds the response or
working data from these new row scores and species scores.  The
original site (row) and species (column) weights are used for
<code>type = "response"</code> and <code>type = "working"</code> in correspondence
analysis (<code><a href="#topic+cca">cca</a></code>) and therefore the number of rows must
match in the original data and <code>newdata</code>.
</p>
<p>If a completely new data frame is created, extreme care is needed
defining variables similarly as in the original model, in particular
with (ordered) factors. If ordination was performed with the formula
interface, the <code>newdata</code> can be a data frame or matrix, but
extreme care is needed that the columns match in the original and
<code>newdata</code>.
</p>
<p>Function <code>calibrate.cca</code> finds estimates of constraints from
community ordination or <code>"wa"</code> scores from <code><a href="#topic+cca">cca</a></code>,
<code><a href="#topic+rda">rda</a></code> and <code><a href="#topic+capscale">capscale</a></code>. This is often known as
calibration, bioindication or environmental reconstruction.
Basically, the method is similar to projecting site scores onto
biplot arrows, but it uses regression coefficients.  The function
can be called with <code>newdata</code> so that cross-validation is
possible.  The <code>newdata</code> may contain new sites, but species
must match in the original and new data.  The function does not work
with &lsquo;partial&rsquo; models with <code>Condition</code> term, and it
cannot be used with <code>newdata</code> for <code><a href="#topic+capscale">capscale</a></code> or
<code><a href="#topic+dbrda">dbrda</a></code> results.  The results may only be interpretable
for continuous variables.
</p>
<p>Function <code>coef</code> will give the regression coefficients from centred
environmental variables (constraints and conditions) to linear
combination scores. The coefficients are for unstandardized environmental
variables. The coefficients will be <code>NA</code> for aliased effects.
</p>
<p>Function <code>predict.decorana</code> is similar to <code>predict.cca</code>.
However, <code>type = "species"</code> is not available in detrended
correspondence analysis  (DCA), because detrending destroys the mutual
reciprocal averaging (except for the first axis when rescaling is not
used). Detrended CA does not attempt to approximate the original data
matrix, so <code>type = "response"</code> has no meaning in detrended
analysis (except with <code>rank = 1</code>).
</p>


<h3>Value</h3>

<p>The functions return matrices, vectors or dissimilarities as is appropriate.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen.</p>


<h3>References</h3>

<p>Greenacre, M. J. (1984). Theory and applications of correspondence
analysis. Academic Press, London.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+dbrda">dbrda</a></code>,
<code><a href="#topic+capscale">capscale</a></code>, <code><a href="#topic+decorana">decorana</a></code>,
<code><a href="#topic+goodness.cca">goodness.cca</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
mod &lt;- cca(dune ~ A1 + Management + Condition(Moisture), data=dune.env)
# Definition of the concepts 'fitted' and 'residuals'
mod
cca(fitted(mod))
cca(residuals(mod))
# Remove rare species (freq==1) from 'cca' and find their scores
# 'passively'.
freq &lt;- specnumber(dune, MARGIN=2)
freq
mod &lt;- cca(dune[, freq&gt;1] ~ A1 + Management + Condition(Moisture), dune.env)
## IGNORE_RDIFF_BEGIN
predict(mod, type="sp", newdata=dune[, freq==1], scaling="species")
# New sites
predict(mod, type="lc", new=data.frame(A1 = 3, Management="NM", Moisture="2"), scal=2)
# Calibration and residual plot
mod &lt;- cca(dune ~ A1 + Moisture, dune.env)
pred &lt;- calibrate(mod)
pred
## IGNORE_RDIFF_END
with(dune.env, plot(A1, pred[,"A1"] - A1, ylab="Prediction Error"))
abline(h=0)
</code></pre>

<hr>
<h2 id='procrustes'>Procrustes Rotation of Two Configurations and PROTEST </h2><span id='topic+procrustes'></span><span id='topic+summary.procrustes'></span><span id='topic+plot.procrustes'></span><span id='topic+points.procrustes'></span><span id='topic+text.procrustes'></span><span id='topic+lines.procrustes'></span><span id='topic+residuals.procrustes'></span><span id='topic+fitted.procrustes'></span><span id='topic+predict.procrustes'></span><span id='topic+protest'></span>

<h3>Description</h3>

<p>Function <code>procrustes</code> rotates a configuration to maximum similarity
with another configuration. Function <code>protest</code> tests the
non-randomness (significance) between two configurations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>procrustes(X, Y, scale = TRUE, symmetric = FALSE, scores = "sites", ...)
## S3 method for class 'procrustes'
summary(object, digits = getOption("digits"), ...)
## S3 method for class 'procrustes'
plot(x, kind=1, choices=c(1,2), to.target = TRUE, 
    type = "p", xlab, ylab, main, ar.col = "blue", length=0.05, 
    cex = 0.7, ...)
## S3 method for class 'procrustes'
points(x, display = c("target", "rotated"),
    choices = c(1,2), truemean = FALSE, ...)
## S3 method for class 'procrustes'
text(x, display = c("target", "rotated"),
    choices = c(1,2), labels, truemean = FALSE, ...)
## S3 method for class 'procrustes'
lines(x, type = c("segments", "arrows"),
    choices = c(1, 2), truemean = FALSE, ...)
## S3 method for class 'procrustes'
residuals(object, ...)
## S3 method for class 'procrustes'
fitted(object, truemean = TRUE, ...)
## S3 method for class 'procrustes'
predict(object, newdata, truemean = TRUE, ...)
protest(X, Y, scores = "sites", permutations = how(nperm = 999), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="procrustes_+3A_x">X</code></td>
<td>
<p>Target matrix</p>
</td></tr>
<tr><td><code id="procrustes_+3A_y">Y</code></td>
<td>
<p>Matrix to be rotated.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_scale">scale</code></td>
<td>
<p>Allow scaling of axes of <code>Y</code>.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_symmetric">symmetric</code></td>
<td>
<p>Use symmetric Procrustes statistic (the rotation will
still be non-symmetric).</p>
</td></tr>
<tr><td><code id="procrustes_+3A_scores">scores</code></td>
<td>
<p>Kind of scores used. This is the <code>display</code> argument
used with the corresponding <code>scores</code> function: see
<code><a href="#topic+scores">scores</a></code>, <code><a href="#topic+scores.cca">scores.cca</a></code> and
<code><a href="#topic+scores.cca">scores.cca</a></code> for alternatives.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_x">x</code>, <code id="procrustes_+3A_object">object</code></td>
<td>
<p>An object of class <code>procrustes</code>.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_digits">digits</code></td>
<td>
<p>Number of digits in the output.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_kind">kind</code></td>
<td>
<p>For <code>plot</code> function, the kind of plot produced:
<code>kind = 1</code> plots shifts in two configurations, <code>kind = 0</code>
draws a corresponding empty plot, and <code>kind = 2</code>
plots an impulse diagram of residuals.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_choices">choices</code></td>
<td>
<p>Axes (dimensions) plotted.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_xlab">xlab</code>, <code id="procrustes_+3A_ylab">ylab</code></td>
<td>
<p>Axis labels, if defaults unacceptable.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_main">main</code></td>
<td>
<p>Plot title, if default unacceptable.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_display">display</code></td>
<td>
<p>Show only the <code>"target"</code> or <code>"rotated"</code>
matrix as points.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_to.target">to.target</code></td>
<td>
<p>Draw arrows to point to target.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_type">type</code></td>
<td>
<p>The type of plot drawn. In <code>plot</code>, the <code>type</code>
can be <code>"points"</code> or <code>"text"</code> to select the marker for
the tail of the arrow, or <code>"none"</code> for drawing an empty
plot. In <code>lines</code> the <code>type</code> selects either
<code><a href="graphics.html#topic+arrows">arrows</a></code> or line <code><a href="graphics.html#topic+segments">segments</a></code> to connect
target and rotated configuration.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_truemean">truemean</code></td>
<td>
<p>Use the original range of target matrix instead of
centring the fitted values. Function <code>plot.procrustes</code> needs
<code>truemean = FALSE</code>, and adding graphical items to the plots
from the original results may need <code>truemean = TRUE</code>.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_newdata">newdata</code></td>
<td>
<p>Matrix of coordinates to be rotated and translated to
the target.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_ar.col">ar.col</code></td>
<td>
<p>Arrow colour.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_length">length</code></td>
<td>
<p>Width of the arrow head.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_labels">labels</code></td>
<td>
<p>Character vector of text labels. Rownames of the result 
object are used as default.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_cex">cex</code></td>
<td>
<p>Character expansion for points or text.</p>
</td></tr>
<tr><td><code id="procrustes_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions. In <code>procrustes</code>
and <code>protest</code> parameters are passed to <code><a href="#topic+scores">scores</a></code>, in
graphical functions to underlying graphical functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Procrustes rotation rotates a matrix to maximum similarity with a
target matrix minimizing sum of squared differences.  Procrustes
rotation is typically used in comparison of ordination results.  It is
particularly useful in comparing alternative solutions in
multidimensional scaling.  If <code>scale=FALSE</code>, the function only
rotates matrix <code>Y</code>. If <code>scale=TRUE</code>, it scales linearly
configuration <code>Y</code> for maximum similarity.  Since <code>Y</code> is scaled
to fit <code>X</code>, the scaling is non-symmetric. However, with
<code>symmetric=TRUE</code>, the configurations are scaled to equal
dispersions and  a symmetric version of the Procrustes statistic
is computed.
</p>
<p>Instead of matrix, <code>X</code> and <code>Y</code> can be results from an
ordination from which <code><a href="#topic+scores">scores</a></code> can extract results.
Function <code>procrustes</code> passes extra arguments to
<code><a href="#topic+scores">scores</a></code>, <code><a href="#topic+scores.cca">scores.cca</a></code> etc. so that you can
specify arguments such as <code>scaling</code>. 
</p>
<p>Function <code>plot</code> plots a <code>procrustes</code> object and returns
invisibly an <code>ordiplot</code> object so that function
<code><a href="#topic+identify.ordiplot">identify.ordiplot</a></code> can be used for identifying
points. The items in the <code>ordiplot</code> object are called
<code>heads</code> and <code>points</code> with <code>kind=1</code> (ordination
diagram) and <code>sites</code> with <code>kind=2</code> (residuals).  In
ordination diagrams, the arrow heads point to the target
configuration if <code>to.target = TRUE</code>, and to rotated
configuration if <code>to.target = FALSE</code>.  Target and original
rotated axes are shown as cross hairs in two-dimensional Procrustes
analysis, and with a higher number of dimensions, the rotated axes
are projected onto plot with their scaled and centred
range. Function <code>plot</code> passes parameters to underlying plotting
functions.  For full control of plots, you can draw the axes using
<code>plot</code> with <code>kind = 0</code>, and then add items with
<code>points</code> or <code>lines</code>.  These functions pass all parameters
to the underlying functions so that you can select the plotting
characters, their size, colours etc., or you can select the width,
colour and type of line <code><a href="graphics.html#topic+segments">segments</a></code> or arrows, or you can
select the orientation and head width of <code><a href="graphics.html#topic+arrows">arrows</a></code>.
</p>
<p>Function <code>residuals</code> returns the pointwise
residuals, and <code>fitted</code> the fitted values, either centred to zero
mean (if <code>truemean=FALSE</code>) or with the original scale (these
hardly make sense if <code>symmetric = TRUE</code>). In
addition, there are <code>summary</code> and <code>print</code> methods.
</p>
<p>If matrix <code>X</code> has a lower number of columns than matrix
<code>Y</code>, then matrix <code>X</code> will be filled with zero columns to
match dimensions. This means that the function can be used to rotate
an ordination configuration to an environmental variable (most
practically extracting the result with the <code>fitted</code>
function). Function <code>predict</code> can be used to add new rotated
coordinates to the target. The <code>predict</code> function will always
translate coordinates to the original non-centred matrix. The
function cannot be used with <code>newdata</code> for <code>symmetric</code>
analysis.
</p>
<p>Function <code>protest</code> performs symmetric Procrustes analysis
repeatedly to estimate the significance of the Procrustes
statistic. Function <code>protest</code> uses a correlation-like statistic
derived from the symmetric Procrustes sum of squares <code class="reqn">ss</code> as
<code class="reqn">r =\sqrt{1-ss}</code>, and also prints the sum of
squares of the symmetric analysis, sometimes called
<code class="reqn">m_{12}^2</code>. Function <code>protest</code> has own
<code>print</code> method, but otherwise uses <code>procrustes</code>
methods. Thus <code>plot</code> with a <code>protest</code> object yields a
Procrustean superimposition plot.  </p>


<h3>Value</h3>

<p>Function <code>procrustes</code> returns an object of class
<code>procrustes</code> with items. Function <code>protest</code> inherits from
<code>procrustes</code>, but amends that with some new items:
</p>
<table>
<tr><td><code>Yrot</code></td>
<td>
<p>Rotated matrix <code>Y</code>.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Target matrix.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>Sum of squared differences between <code>X</code> and <code>Yrot</code>.</p>
</td></tr>
<tr><td><code>rotation</code></td>
<td>
<p>Orthogonal rotation matrix.</p>
</td></tr>
<tr><td><code>translation</code></td>
<td>
<p>Translation of the origin.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>Scaling factor.</p>
</td></tr>
<tr><td><code>xmean</code></td>
<td>
<p>The centroid of the target.</p>
</td></tr>
<tr><td><code>symmetric</code></td>
<td>
<p>Type of <code>ss</code> statistic.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Function call.</p>
</td></tr>
<tr><td><code>t0</code></td>
<td>
<p>This and the following items are only in class
<code>protest</code>:  Procrustes correlation from non-permuted solution.</p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>Procrustes correlations from permutations. The distribution
of these correlations can be inspected with <code><a href="#topic+permustats">permustats</a></code>
function.</p>
</td></tr>
<tr><td><code>signif</code></td>
<td>
<p>Significance of <code>t</code></p>
</td></tr>
<tr><td><code>permutations</code></td>
<td>
<p>Number of permutations.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>A list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the list passed to argument <code>control</code> describing
the permutation design.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function <code>protest</code> follows Peres-Neto &amp; Jackson (2001),
but the implementation is still after Mardia <em>et al.</em>
(1979).</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>References</h3>

<p>Mardia, K.V., Kent, J.T. and Bibby,
J.M. (1979). <em>Multivariate Analysis</em>. Academic Press.
</p>
<p>Peres-Neto, P.R. and Jackson, D.A. (2001). How well do multivariate
data sets match? The advantages of a Procrustean superimposition
approach over the Mantel test. <em>Oecologia</em> 129: 169-178.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+monoMDS">monoMDS</a></code>,  for obtaining
objects for <code>procrustes</code>, and <code><a href="#topic+mantel">mantel</a></code> for an
alternative to <code>protest</code> without need of dimension reduction. See
<code><a href="permute.html#topic+how">how</a></code> for details on specifying the type of
permutation required.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
data(varespec)
vare.dist &lt;- vegdist(wisconsin(varespec))
mds.null &lt;- monoMDS(vare.dist, y = cmdscale(vare.dist))
mds.alt &lt;- monoMDS(vare.dist)
vare.proc &lt;- procrustes(mds.alt, mds.null)
vare.proc
summary(vare.proc)
plot(vare.proc)
plot(vare.proc, kind=2)
residuals(vare.proc)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='pyrifos'>Response of Aquatic Invertebrates to Insecticide Treatment</h2><span id='topic+pyrifos'></span>

<h3>Description</h3>

<p>The data are log transformed abundances of aquatic invertebrate in
twelve ditches studied in eleven times before and after an insecticide
treatment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pyrifos)</code></pre>


<h3>Format</h3>

<p>A data frame with 132 observations on the log-transformed (<code>log(10*x + 1)</code>) abundances
of 178 species. There are only twelve sites (ditches, mesocosms), but
these were studied repeatedly in eleven occasions. The treatment
levels, treatment times, or ditch ID's are not in the data frame, but
the data are very regular, and the example below shows how to obtain
these external variables.
</p>


<h3>Details</h3>

<p>  This data set was obtained from an experiment in outdoor
experimental ditches. Twelve mesocosms were allocated at random to
treatments; four served as controls, and the remaining eight were 
treated once with the insecticide chlorpyrifos, with nominal dose
levels of 0.1, 0.9, 6, and 44  <code class="reqn">\mu</code>g/ L in two mesocosms
each. The example data set invertebrates.
Sampling was done 11 times, from week -4 pre-treatment through
week 24 post-treatment, giving a total of 132 samples (12 mesocosms
times 11 sampling dates), see van den Brink &amp; ter Braak (1999) for
details. The data set contains only the species data,
but the example below shows how to obtain the treatment, time and
ditch ID variables. 
</p>


<h3>Source</h3>

<p>CANOCO 4 example data, with the permission of Cajo J. F. ter Braak.
</p>


<h3>References</h3>

<p>van den Brink, P.J. &amp; ter Braak, C.J.F. (1999). Principal response
curves: Analysis of time-dependent multivariate responses of
biological community to stress. Environmental Toxicology and
Chemistry, 18, 138&ndash;148.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pyrifos)
ditch &lt;- gl(12, 1, length=132)
week &lt;- gl(11, 12, labels=c(-4, -1, 0.1, 1, 2, 4, 8, 12, 15, 19, 24))
dose &lt;- factor(rep(c(0.1, 0, 0, 0.9, 0, 44, 6, 0.1, 44, 0.9, 0, 6), 11))
</code></pre>

<hr>
<h2 id='radfit'> Rank &ndash; Abundance or Dominance / Diversity Models</h2><span id='topic+radfit'></span><span id='topic+radfit.default'></span><span id='topic+radfit.data.frame'></span><span id='topic+AIC.radfit'></span><span id='topic+AIC.radfit.frame'></span><span id='topic+as.rad'></span><span id='topic+coef.radfit'></span><span id='topic+coef.radfit.frame'></span><span id='topic+deviance.radfit'></span><span id='topic+deviance.radfit.frame'></span><span id='topic+logLik+2C+20radfit'></span><span id='topic+logLik+2C+20radfit.frame'></span><span id='topic+fitted.radfit'></span><span id='topic+fitted.radfit.frame'></span><span id='topic+lines.radline'></span><span id='topic+lines.radfit'></span><span id='topic+plot.radfit.frame'></span><span id='topic+plot.radfit'></span><span id='topic+plot.radline'></span><span id='topic+plot.rad'></span><span id='topic+radlattice'></span><span id='topic+points.radline'></span><span id='topic+points.radfit'></span><span id='topic+summary.radfit.frame'></span><span id='topic+rad.preempt'></span><span id='topic+rad.lognormal'></span><span id='topic+rad.zipf'></span><span id='topic+rad.zipfbrot'></span><span id='topic+rad.null'></span><span id='topic+predict.radline'></span><span id='topic+predict.radfit'></span><span id='topic+predict.radfit.frame'></span>

<h3>Description</h3>

<p>Functions construct rank &ndash; abundance or dominance / diversity or
Whittaker plots and fit brokenstick, preemption, log-Normal,
Zipf and Zipf-Mandelbrot models of species abundance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
radfit(x, ...)
rad.null(x, family=poisson, ...)
rad.preempt(x, family = poisson, ...)
rad.lognormal(x, family = poisson, ...)
rad.zipf(x, family = poisson, ...)
rad.zipfbrot(x, family = poisson, ...)
## S3 method for class 'radline'
predict(object, newdata, total, ...)
## S3 method for class 'radfit'
plot(x, BIC = FALSE, legend = TRUE, ...)
## S3 method for class 'radfit.frame'
plot(x, order.by, BIC = FALSE, model, legend = TRUE,
     as.table = TRUE, ...)
## S3 method for class 'radline'
plot(x, xlab = "Rank", ylab = "Abundance", type = "b", ...)
radlattice(x, BIC = FALSE, ...)
## S3 method for class 'radfit'
lines(x, ...)
## S3 method for class 'radfit'
points(x, ...)
as.rad(x)
## S3 method for class 'rad'
plot(x, xlab = "Rank", ylab = "Abundance", log = "y", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="radfit_+3A_x">x</code></td>
<td>
<p>Data frame, matrix or a vector giving species abundances, or an object to
be plotted.</p>
</td></tr>
<tr><td><code id="radfit_+3A_family">family</code></td>
<td>
<p>Error distribution (passed to <code><a href="stats.html#topic+glm">glm</a></code>). All
alternatives accepting <code>link = "log"</code> in <code><a href="stats.html#topic+family">family</a></code>
can be used, although not all make sense.</p>
</td></tr>
<tr><td><code id="radfit_+3A_object">object</code></td>
<td>
<p>A fitted result object.</p>
</td></tr>
<tr><td><code id="radfit_+3A_newdata">newdata</code></td>
<td>
<p>Ranks used for ordinations. All models can
interpolate to non-integer &ldquo;ranks&rdquo; (although this may be
approximate), but extrapolation may fail</p>
</td></tr>
<tr><td><code id="radfit_+3A_total">total</code></td>
<td>
<p>The new total used for predicting abundance. Observed
total count is used if this is omitted.</p>
</td></tr>
<tr><td><code id="radfit_+3A_order.by">order.by</code></td>
<td>
<p>A vector used for ordering sites in plots.</p>
</td></tr>
<tr><td><code id="radfit_+3A_bic">BIC</code></td>
<td>
<p>Use Bayesian Information Criterion, BIC, instead of
Akaike's AIC. The penalty in BIC is <code class="reqn">k = \log(S)</code>  where <code class="reqn">S</code> is the number of species, whereas AIC uses
<code class="reqn">k = 2</code>.</p>
</td></tr>
<tr><td><code id="radfit_+3A_model">model</code></td>
<td>
<p>Show only the specified model. If missing, AIC is used
to select the model. The model names (which can be abbreviated)
are <code>Null</code>, <code>Preemption</code>, <code>Lognormal</code>, <code>Zipf</code>,
<code>Mandelbrot</code>. </p>
</td></tr>
<tr><td><code id="radfit_+3A_legend">legend</code></td>
<td>
<p>Add legend of line colours.</p>
</td></tr>
<tr><td><code id="radfit_+3A_as.table">as.table</code></td>
<td>
<p>Arrange panels starting from upper left corner (passed
to <code><a href="lattice.html#topic+xyplot">xyplot</a></code>).</p>
</td></tr>
<tr><td><code id="radfit_+3A_xlab">xlab</code>, <code id="radfit_+3A_ylab">ylab</code></td>
<td>
<p>Labels for <code>x</code> and <code>y</code> axes.</p>
</td></tr>
<tr><td><code id="radfit_+3A_type">type</code></td>
<td>
<p>Type of the plot, <code>"b"</code> for plotting both observed points
and fitted lines, <code>"p"</code> for only points, <code>"l"</code> for only
fitted lines, and <code>"n"</code> for only setting the frame. </p>
</td></tr>
<tr><td><code id="radfit_+3A_log">log</code></td>
<td>
<p>Use logarithmic scale for given axis. The default
<code>log = "y"</code> gives the traditional plot of community ecology
where the preemption model is a straight line, and with
<code>log = "xy"</code> Zipf model is a straight line. With
<code>log = ""</code> both axes are in the original arithmetic scale.</p>
</td></tr>
<tr><td><code id="radfit_+3A_...">...</code></td>
<td>
<p>Other parameters to functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rank&ndash;Abundance Dominance (RAD) or Dominance/Diversity plots
(Whittaker 1965) display logarithmic species abundances against
species rank order. These plots are supposed to be effective in
analysing types of abundance distributions in communities. These
functions fit some of the most popular models mainly following
Wilson (1991).
</p>
<p>Functions <code>rad.null</code>, <code>rad.preempt</code>, <code>rad.lognormal</code>,
<code>rad.zipf</code> and <code>zipfbrot</code> fit the individual models
(described below) for a single vector (row of data frame), and
function <code>radfit</code> fits all models. The argument of the function
<code>radfit</code> can be either a vector for a single community or a data
frame where each row represents a distinct community.
</p>
<p>Function <code>rad.null</code> fits a brokenstick model where the expected
abundance of species at rank <code class="reqn">r</code> is <code class="reqn">a_r = (J/S)
  \sum_{x=r}^S (1/x)</code> (Pielou
1975), where <code class="reqn">J</code> is the total number of individuals (site total)
and <code class="reqn">S</code> is the total number of species in the community.  This
gives a Null model where the individuals are randomly distributed
among observed species, and there are no fitted parameters.
Function <code>rad.preempt</code> fits the niche preemption model,
a.k.a. geometric series or Motomura model, where the expected
abundance <code class="reqn">a</code> of species at rank <code class="reqn">r</code> is <code class="reqn">a_r = J \alpha
  (1 - \alpha)^{r-1}</code>. The only
estimated parameter is the preemption coefficient <code class="reqn">\alpha</code> which
gives the decay rate of abundance per rank.  The niche preemption
model is a straight line in a RAD plot.  Function
<code>rad.lognormal</code> fits a log-Normal model which assumes that the
logarithmic abundances are distributed Normally, or <code class="reqn">a_r = \exp(
  \log \mu + \log \sigma N)</code>,
where <code class="reqn">N</code> is a Normal deviate.  Function <code>rad.zipf</code> fits
the Zipf model <code class="reqn">a_r = J p_1 r^\gamma</code> where
<code class="reqn">p_1</code> is the fitted proportion of the most abundant species,
and <code class="reqn">\gamma</code> is a decay coefficient. The Zipf&ndash;Mandelbrot model
(<code>rad.zipfbrot</code>) adds one parameter: <code class="reqn">a_r = J c (r +
  \beta)^\gamma</code> after which <code class="reqn">p_1</code>
of the Zipf model changes into a meaningless scaling constant
<code class="reqn">c</code>.
</p>
<p>Log-Normal and Zipf models are generalized linear models
(<code><a href="stats.html#topic+glm">glm</a></code>) with logarithmic link function.  Zipf&ndash;Mandelbrot
adds one nonlinear parameter to the Zipf model, and is fitted using
<code><a href="stats.html#topic+nlm">nlm</a></code> for the nonlinear parameter and estimating other
parameters and log-Likelihood with <code><a href="stats.html#topic+glm">glm</a></code>. Preemption
model is fitted as a purely nonlinear model. There are no estimated
parameters in the Null model.
</p>
<p>The default <code><a href="stats.html#topic+family">family</a></code> is <code>poisson</code> which is
appropriate only for genuine counts (integers), but other families
that accept <code>link = "log"</code> can be used. Families
<code><a href="stats.html#topic+Gamma">Gamma</a></code> or <code><a href="stats.html#topic+gaussian">gaussian</a></code> may be appropriate for
abundance data, such as cover. The best model is selected by
<code><a href="stats.html#topic+AIC">AIC</a></code>. Therefore &lsquo;quasi&rsquo; families such as
<code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code> cannot be used: they do not have
<code><a href="stats.html#topic+AIC">AIC</a></code> nor log-Likelihood needed in non-linear models.
</p>
<p>All these functions have their own <code>plot</code> functions. When
<code>radfit</code> was applied for a data frame, <code>plot</code> uses
<code><a href="lattice.html#topic+Lattice">Lattice</a></code> graphics, and other <code>plot</code>
functions use ordinary graphics. The ordinary graphics functions
return invisibly an <code><a href="#topic+ordiplot">ordiplot</a></code> object for observed points,
and function <code><a href="#topic+identify.ordiplot">identify.ordiplot</a></code> can be used to label
selected species.  Alternatively, <code>radlattice</code> uses
<code><a href="lattice.html#topic+Lattice">Lattice</a></code> graphics to display each <code>radfit</code>
model of a single site in a separate panel together with their AIC or
BIC values.
</p>
<p>Function <code>as.rad</code> is a base function to construct ordered RAD
data. Its <code>plot</code> is used by other RAD <code>plot</code> functions
which pass extra arguments (such as <code>xlab</code> and <code>log</code>) to
this function. The function returns an ordered vector of taxa
occurring in a site, and a corresponding attribute <code>"index"</code> of
included taxa.
</p>


<h3>Value</h3>

<p>Functions <code>rad.null</code>, <code>rad.preempt</code>, <code>rad.lognormal</code>,
<code>zipf</code> and <code>zipfbrot</code> fit each a single RAD model to a
single site. The result object has class <code>"radline"</code> and
inherits from <code><a href="stats.html#topic+glm">glm</a></code>, and can be handled by some (but not
all) <code><a href="stats.html#topic+glm">glm</a></code> methods.
</p>
<p>Function <code>radfit</code> fits all models either to a single site or to
all rows of a data frame or a matrix. When fitted to a single site,
the function returns an object of class <code>"radfit"</code> with items
<code>y</code> (observed values), <code><a href="stats.html#topic+family">family</a></code>, and <code>models</code>
which is a list of fitted <code>"radline"</code> models.  When applied for a
data frame or matrix, <code>radfit</code> function returns an object of
class <code>"radfit.frame"</code> which is a list of <code>"radfit"</code>
objects, each item names by the corresponding row name.
</p>
<p>All result objects (<code>"radline"</code>, <code>"radfit"</code>,
<code>"radfit.frame"</code>) can be accessed with same method functions.
The following methods are available: <code><a href="stats.html#topic+AIC">AIC</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="stats.html#topic+deviance">deviance</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>. In
addition the fit results can be accessed with <code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="stats.html#topic+predict">predict</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code> (inheriting from
<code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code>). The graphical functions were discussed
above in Details.
</p>


<h3>Note</h3>

<p>The RAD models are usually fitted for proportions instead of original
abundances. However, nothing in these models seems to require division
of abundances by site totals, and original observations are used in
these functions. If you wish to use proportions, you must standardize
your data by site totals, e.g. with <code><a href="#topic+decostand">decostand</a></code> and use
appropriate <code><a href="stats.html#topic+family">family</a></code> such as <code><a href="stats.html#topic+Gamma">Gamma</a></code>.
</p>
<p>The lognormal model is fitted in a standard way, but I do think this is
not quite correct &ndash; at least it is not equivalent to fitting Normal
density to log abundances like originally suggested (Preston 1948).
</p>
<p>Some models may fail. In particular, estimation of the Zipf-Mandelbrot
model is difficult.  If the fitting fails, <code>NA</code> is returned.
</p>
<p>Wilson (1991) defined preemption model as <code class="reqn">a_r = J p_1 (1
    - \alpha)^{r-1}</code>, where <code class="reqn">p_1</code>
is the fitted proportion of the first species. However, parameter
<code class="reqn">p_1</code> is completely defined by <code class="reqn">\alpha</code> since the fitted
proportions must add to one, and therefore I handle preemption as a
one-parameter model.
</p>
<p>Veiled log-Normal model was included in earlier releases of this
function, but it was removed because it was flawed: an implicit veil
line also appears in the ordinary log-Normal. The latest release version
with <code>rad.veil</code> was <code>1.6-10</code>.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Pielou, E.C. (1975) <em>Ecological Diversity</em>. Wiley &amp; Sons.
</p>
<p>Preston, F.W. (1948) The commonness and rarity of
species. <em>Ecology</em> 29, 254&ndash;283.
</p>
<p>Whittaker, R. H. (1965) Dominance and diversity in plant
communities. <em>Science</em> 147, 250&ndash;260.
</p>
<p>Wilson, J. B. (1991) Methods for fitting dominance/diversity
curves. <em>Journal of Vegetation Science</em> 2, 35&ndash;46.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fisherfit">fisherfit</a></code> and <code><a href="#topic+prestonfit">prestonfit</a></code>.
An alternative approach is to use
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> or  <code><a href="stats.html#topic+qqplot">qqplot</a></code> with any distribution.
For controlling graphics: <code><a href="lattice.html#topic+Lattice">Lattice</a></code>,
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="lattice.html#topic+lset">lset</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
mod &lt;- rad.lognormal(BCI[5,])
mod
plot(mod)
mod &lt;- radfit(BCI[1,])
## Standard plot overlaid for all models
## Preemption model is a line
plot(mod)
## log for both axes: Zipf model is a line
plot(mod, log = "xy")
## Lattice graphics separately for each model
radlattice(mod)
# Take a subset of BCI to save time and nerves
mod &lt;- radfit(BCI[3:5,])
mod
plot(mod, pch=".")
</code></pre>

<hr>
<h2 id='rankindex'>Compares Dissimilarity Indices for Gradient Detection </h2><span id='topic+rankindex'></span>

<h3>Description</h3>

<p>Rank correlations between dissimilarity indices
and gradient separation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankindex(grad, veg, indices = c("euc", "man", "gow", "bra", "kul"),
          stepacross = FALSE, method = "spearman", 
	  metric = c("euclidean", "mahalanobis", "manhattan", "gower"),
	  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankindex_+3A_grad">grad</code></td>
<td>
<p>The gradient variable or matrix. </p>
</td></tr>
<tr><td><code id="rankindex_+3A_veg">veg</code></td>
<td>
<p>The community data matrix. </p>
</td></tr>
<tr><td><code id="rankindex_+3A_indices">indices</code></td>
<td>
<p>Dissimilarity indices compared, partial matches to
alternatives in <code><a href="#topic+vegdist">vegdist</a></code>.
Alternatively, it can be a (named) list of functions returning
objects of class 'dist'.</p>
</td></tr>
<tr><td><code id="rankindex_+3A_stepacross">stepacross</code></td>
<td>
<p>Use <code><a href="#topic+stepacross">stepacross</a></code> to find
a shorter path dissimilarity. The dissimilarities for site pairs
with no shared species are set <code>NA</code> using
<code><a href="#topic+no.shared">no.shared</a></code> so that indices with no fixed
upper limit can also be analysed.</p>
</td></tr>
<tr><td><code id="rankindex_+3A_method">method</code></td>
<td>
<p>Correlation method used.</p>
</td></tr>
<tr><td><code id="rankindex_+3A_metric">metric</code></td>
<td>
<p>Metric to evaluate the gradient separation. See Details.</p>
</td></tr>
<tr><td><code id="rankindex_+3A_...">...</code></td>
<td>
<p>Other parameters to <code><a href="#topic+stepacross">stepacross</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A good dissimilarity index for multidimensional scaling should have
a high rank-order similarity with gradient separation.  The function
compares most indices in <code><a href="#topic+vegdist">vegdist</a></code> against gradient
separation using rank correlation coefficients in
<code><a href="stats.html#topic+cor">cor</a></code>. The gradient separation between each point is
assessed using given <code>metric</code>. The default is to use Euclidean
distance of continuous variables scaled to unit variance, or to use
Gower metric for mixed data using function
<code><a href="cluster.html#topic+daisy">daisy</a></code> when <code>grad</code> has factors. The other
alternatives are Mahalanabis distances which are based on
<code>grad</code> matrix scaled so that columns are orthogonal
(uncorrelated) and have unit variance, or Manhattan distances of
<code>grad</code> variables scaled to unit range.
</p>
<p>The <code>indices</code> argument can accept any dissimilarity 
indices besides the ones calculated by the 
<code><a href="#topic+vegdist">vegdist</a></code> function. For this, the argument value
should be a (possibly named) list of functions.
Each function must return a valid 'dist' object with dissimilarities,
similarities are not accepted and should be converted into dissimilarities
beforehand.
</p>


<h3>Value</h3>

<p>Returns a named vector of rank correlations.
</p>


<h3>Note</h3>

<p>There are several problems in using rank correlation coefficients.
Typically there are very many ties when <code class="reqn">n(n-1)/2</code> gradient
separation values are derived from just <code class="reqn">n</code> observations.
Due to floating point arithmetics, many tied values differ by
machine epsilon and are arbitrarily ranked differently by
<code><a href="base.html#topic+rank">rank</a></code> used in <code><a href="stats.html#topic+cor.test">cor.test</a></code>.  Two indices
which are identical with certain
transformation or standardization may differ slightly
(magnitude <code class="reqn">10^{-15}</code>) and this may lead into third or fourth decimal
instability in rank correlations.  Small differences in rank
correlations should not be taken too seriously.  Probably this method
should be replaced with a sounder method, but I do not yet know
which...  You may experiment with <code><a href="#topic+mantel">mantel</a></code>,
<code><a href="#topic+anosim">anosim</a></code> or even <code><a href="#topic+protest">protest</a></code>.
</p>
<p>Earlier version of this function used <code>method = "kendall"</code>, but
that is far too slow in large data sets.
</p>
<p>The functions returning dissimilarity objects should be self contained,
because the <code>...</code> argument passes additional parameters
to <code><a href="#topic+stepacross">stepacross</a></code> and not to the functions supplied
via the <code>indices</code> argument.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen, with additions from Peter Solymos</p>


<h3>References</h3>

<p> Faith, F.P., Minchin, P.R. and Belbin,
L. (1987).  Compositional dissimilarity as a robust measure of
ecological distance. <em>Vegetatio</em> 69, 57-68. </p>


<h3>See Also</h3>

<p><code><a href="#topic+vegdist">vegdist</a></code>, <code><a href="#topic+stepacross">stepacross</a></code>,
<code><a href="#topic+no.shared">no.shared</a></code>, <code><a href="#topic+monoMDS">monoMDS</a></code>,
<code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="base.html#topic+Machine">Machine</a></code>, and for
alternatives <code><a href="#topic+anosim">anosim</a></code>, <code><a href="#topic+mantel">mantel</a></code> and
<code><a href="#topic+protest">protest</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
## The variables are automatically scaled
rankindex(varechem, varespec)
rankindex(varechem, wisconsin(varespec))
## Using non vegdist indices as functions
funs &lt;- list(Manhattan=function(x) dist(x, "manhattan"),
    Gower=function(x) cluster:::daisy(x, "gower"),
    Ochiai=function(x) designdist(x, "1-J/sqrt(A*B)"))
rankindex(scale(varechem), varespec, funs)
</code></pre>

<hr>
<h2 id='rarefy'>Rarefaction Species Richness</h2><span id='topic+rarefy'></span><span id='topic+rrarefy'></span><span id='topic+drarefy'></span><span id='topic+rarecurve'></span><span id='topic+rareslope'></span>

<h3>Description</h3>

<p> Rarefied species richness for community ecologists.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>rarefy(x, sample, se = FALSE, MARGIN = 1)
rrarefy(x, sample)
drarefy(x, sample)
rarecurve(x, step = 1, sample, xlab = "Sample Size", ylab = "Species",
          label = TRUE, col, lty, tidy = FALSE, ...)
rareslope(x, sample)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rarefy_+3A_x">x</code></td>
<td>
<p>Community data, a matrix-like object or a vector.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_margin">MARGIN</code></td>
<td>
<p>Margin for which the index is computed. </p>
</td></tr>
<tr><td><code id="rarefy_+3A_sample">sample</code></td>
<td>
<p>Subsample size for rarefying community, either a single
value or a vector.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_se">se</code></td>
<td>
<p>Estimate standard errors.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_step">step</code></td>
<td>
<p>Step size for sample sizes in rarefaction curves.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_xlab">xlab</code>, <code id="rarefy_+3A_ylab">ylab</code></td>
<td>
<p>Axis labels in plots of rarefaction curves.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_label">label</code></td>
<td>
<p>Label rarefaction curves by rownames of <code>x</code>
(logical).</p>
</td></tr>
<tr><td><code id="rarefy_+3A_col">col</code>, <code id="rarefy_+3A_lty">lty</code></td>
<td>
<p>plotting colour and line type, see
<code><a href="graphics.html#topic+par">par</a></code>. Can be a vector of length <code>nrow(x)</code>, one per
sample, and will be extended to such a length internally.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_tidy">tidy</code></td>
<td>
<p>Instead of drawing a <code>plot</code>, return a &ldquo;tidy&rdquo;
data frame than can be used in <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a> graphics. The data
frame has variables <code>Site</code> (factor), <code>Sample</code> and
<code>Species</code>.</p>
</td></tr>
<tr><td><code id="rarefy_+3A_...">...</code></td>
<td>
<p>Parameters passed to <code><a href="stats.html#topic+nlm">nlm</a></code>, or to <code><a href="graphics.html#topic+plot">plot</a></code>,
<code><a href="graphics.html#topic+lines">lines</a></code> and <code><a href="#topic+ordilabel">ordilabel</a></code> in <code>rarecurve</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>rarefy</code> gives the expected species richness in random
subsamples of size <code>sample</code> from the community. The size of
<code>sample</code> should be smaller than total community size, but the
function will work for larger <code>sample</code> as well (with a warning)
and return non-rarefied species richness (and standard error =
0). If <code>sample</code> is a vector, rarefaction of all observations is
performed for each sample size separately.  Rarefaction can be
performed only with genuine counts of individuals.  The function
<code>rarefy</code> is based on Hurlbert's (1971) formulation, and the
standard errors on Heck et al. (1975).
</p>
<p>Function <code>rrarefy</code> generates one randomly rarefied community
data frame or vector of given <code>sample</code> size. The <code>sample</code>
can be a vector giving the sample sizes for each row.  If the
<code>sample</code> size is equal to or larger than the observed number
of individuals, the non-rarefied community will be returned.  The
random rarefaction is made without replacement so that the variance
of rarefied communities is rather related to rarefaction proportion
than to the size of the <code>sample</code>. Random rarefaction is
sometimes used to remove the effects of different sample
sizes. This is usually a bad idea: random rarefaction discards valid
data, introduces random error and reduces the quality of the data
(McMurdie &amp; Holmes 2014). It is better to use normalizing
transformations (<code><a href="#topic+decostand">decostand</a></code> in <span class="pkg">vegan</span>) possible
with variance stabilization (<code><a href="#topic+decostand">decostand</a></code> and
<code><a href="#topic+dispweight">dispweight</a></code> in <span class="pkg">vegan</span>) and methods that are not
sensitive to sample sizes.
</p>
<p>Function <code>drarefy</code> returns probabilities that species occur in
a rarefied community of size <code>sample</code>. The <code>sample</code> can be
a vector giving the sample sizes for each row. If the <code>sample</code>
is equal to or larger than the observed number of individuals, all
observed species will have sampling probability 1.
</p>
<p>Function <code>rarecurve</code> draws a rarefaction curve for each row of
the input data. The rarefaction curves are evaluated using the
interval of <code>step</code> sample sizes, always including 1 and total
sample size.  If <code>sample</code> is specified, a vertical line is
drawn at <code>sample</code> with horizontal lines for the rarefied
species richnesses.
</p>
<p>Function <code>rareslope</code> calculates the slope of <code>rarecurve</code>
(derivative of <code>rarefy</code>) at given <code>sample</code> size; the
<code>sample</code> need not be an integer.
</p>
<p>Rarefaction functions should be used for observed counts. If you
think it is necessary to use a multiplier to data, rarefy first and
then multiply. Removing rare species before rarefaction can also
give biased results. Observed count data normally include singletons
(species with count 1), and if these are missing, functions issue
warnings. These may be false positives, but it is recommended to
check that the observed counts are not multiplied or rare taxa are
not removed.
</p>


<h3>Value</h3>

<p>A vector of rarefied species richness values. With a single
<code>sample</code> and <code>se = TRUE</code>, function <code>rarefy</code> returns a
2-row matrix with rarefied richness (<code>S</code>) and its standard error
(<code>se</code>). If <code>sample</code> is a vector in <code>rarefy</code>, the
function returns a matrix with a column for each <code>sample</code> size,
and if <code>se = TRUE</code>, rarefied richness and its standard error are
on consecutive lines.
</p>
<p>Function <code>rarecurve</code> returns <code><a href="base.html#topic+invisible">invisible</a></code> list of
<code>rarefy</code> results corresponding each drawn curve. Alternatively,
with <code>tidy = TRUE</code> it returns a data frame that can be used in
<a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a> graphics.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>References</h3>

<p>Heck, K.L., van Belle, G. &amp; Simberloff, D. (1975). Explicit
calculation of the rarefaction diversity measurement and the
determination of sufficient sample size. <em>Ecology</em> <strong>56</strong>,
1459&ndash;1461.
</p>
<p>Hurlbert, S.H. (1971). The nonconcept of species diversity: a critique
and alternative parameters. <em>Ecology</em> <strong>52</strong>, 577&ndash;586.
</p>
<p>McMurdie, P.J. &amp; Holmes, S. (2014). Waste not, want not: Why
rarefying microbiome data is inadmissible. <em>PLoS Comput Biol</em>
<strong>10(4):</strong> e1003531. <a href="https://doi.org/10.1371/journal.pcbi.1003531">doi:10.1371/journal.pcbi.1003531</a>
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+specaccum">specaccum</a></code> for species accumulation curves
where sites are sampled instead of individuals. <code><a href="#topic+specpool">specpool</a></code>
extrapolates richness to an unknown sample size.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
S &lt;- specnumber(BCI) # observed number of species
(raremax &lt;- min(rowSums(BCI)))
Srare &lt;- rarefy(BCI, raremax)
plot(S, Srare, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
abline(0, 1)
rarecurve(BCI, step = 20, sample = raremax, col = "blue", cex = 0.6)
</code></pre>

<hr>
<h2 id='raupcrick'>
Raup-Crick Dissimilarity with Unequal Sampling Densities of Species
</h2><span id='topic+raupcrick'></span>

<h3>Description</h3>

<p> Function finds the Raup-Crick dissimilarity which is a
probability of number of co-occurring species with species
occurrence probabilities proportional to species frequencies.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>raupcrick(comm, null = "r1", nsimul = 999, chase = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="raupcrick_+3A_comm">comm</code></td>
<td>
<p>Community data which will be treated as presence/absence data.</p>
</td></tr>
<tr><td><code id="raupcrick_+3A_null">null</code></td>
<td>
<p>Null model used as the <code>method</code> in
<code><a href="#topic+oecosimu">oecosimu</a></code>.</p>
</td></tr>
<tr><td><code id="raupcrick_+3A_nsimul">nsimul</code></td>
<td>
<p>Number of null communities for assessing the
dissimilarity index.</p>
</td></tr>
<tr><td><code id="raupcrick_+3A_chase">chase</code></td>
<td>
<p>Use the Chase et al. (2011) method of tie handling (not
recommended except for comparing the results against the Chase
script).</p>
</td></tr>
<tr><td><code id="raupcrick_+3A_...">...</code></td>
<td>
<p>Other parameters passed to <code><a href="#topic+oecosimu">oecosimu</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Raup-Crick index is the probability that compared sampling
units have non-identical species composition.  This probability can
be regarded as a dissimilarity, although it is not metric: identical
sampling units can have dissimilarity slightly above <code class="reqn">0</code>, the
dissimilarity can be nearly zero over a range of shared species, and
sampling units with no shared species can have dissimilarity
slightly below <code class="reqn">1</code>. Moreover, communities sharing rare species
appear as more similar (lower probability of finding rare species
together), than communities sharing the same number of common
species.
</p>
<p>The function will always treat the data as binary (presence/
absence).
</p>
<p>The probability is assessed using simulation with
<code><a href="#topic+oecosimu">oecosimu</a></code> where the test statistic is the observed
number of shared species between sampling units evaluated against a
community null model (see Examples).  The default null model is
<code>"r1"</code> where the probability of selecting species is
proportional to the species frequencies.
</p>
<p>The <code><a href="#topic+vegdist">vegdist</a></code> function implements a variant of the
Raup-Crick index with equal sampling probabilities for species using
exact analytic equations without simulation. This corresponds to
<code>null</code> model <code>"r0"</code> which also can be used with the
current function.  All other null model methods of
<code><a href="#topic+oecosimu">oecosimu</a></code> can be used with the current function, but
they are new unpublished methods.  </p>


<h3>Value</h3>

<p>The function returns an object inheriting from
<code><a href="stats.html#topic+dist">dist</a></code> which can be interpreted as a dissimilarity
matrix.</p>


<h3>Note</h3>

<p> The test statistic is the number of shared species, and this is
typically tied with a large number of simulation results. The tied
values are handled differently in the current function and in the
function published with Chase et al. (2011). In <span class="pkg">vegan</span>, the
index is the number of simulated values that are smaller <em>or
equal</em> than the observed value, but smaller than observed value is
used by Chase et al. (2011) with option <code>split = FALSE</code> in
their script; this can be achieved with <code>chase = TRUE</code> in
<span class="pkg">vegan</span>.  Chase et al. (2011) script with <code>split = TRUE</code>
uses half of tied simulation values to calculate a distance measure,
and that choice cannot be directly reproduced in vegan (it is the
average of <span class="pkg">vegan</span> <code>raupcrick</code> results with 
<code>chase = TRUE</code> and <code>chase = FALSE</code>).</p>


<h3>Author(s)</h3>

<p>The function was developed after Brian Inouye contacted us and
informed us about the method in Chase et al. (2011), and the
function takes its idea from the code that was published with their
paper. The current function was written by Jari Oksanen.  </p>


<h3>References</h3>

<p>Chase, J.M., Kraft, N.J.B., Smith, K.G., Vellend, M. and Inouye,
B.D. (2011). Using null models to disentangle variation in community
dissimilarity from variation in <code class="reqn">\alpha</code>-diversity.
<em>Ecosphere</em> 2:art24 <a href="https://doi.org/10.1890/ES10-00117.1">doi:10.1890/ES10-00117.1</a>
</p>


<h3>See Also</h3>

<p>The function is based on <code><a href="#topic+oecosimu">oecosimu</a></code>. Function
<code><a href="#topic+vegdist">vegdist</a></code> with method = &quot;raup&quot; implements a related
index but with equal sampling densities of species, and
<code><a href="#topic+designdist">designdist</a></code> demonstrates its calculation.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## data set with variable species richness
data(sipoo)
## default raupcrick
dr1 &lt;- raupcrick(sipoo)
## use null model "r0" of oecosimu
dr0 &lt;- raupcrick(sipoo, null = "r0")
## vegdist(..., method = "raup") corresponds to 'null = "r0"'
d &lt;- vegdist(sipoo, "raup")
op &lt;- par(mfrow=c(2,1), mar=c(4,4,1,1)+.1)
plot(dr1 ~ d, xlab = "Raup-Crick with Null R1", ylab="vegdist")
plot(dr0 ~ d, xlab = "Raup-Crick with Null R0", ylab="vegdist")
par(op)

## The calculation is essentially as in the following oecosimu() call,
## except that designdist() is replaced with faster code
## Not run: 
oecosimu(sipoo, function(x) designdist(x, "J", "binary"), method = "r1")

## End(Not run)
</code></pre>

<hr>
<h2 id='read.cep'>Reads a CEP (Canoco) data file </h2><span id='topic+read.cep'></span>

<h3>Description</h3>

<p><code>read.cep</code> reads a file formatted with relaxed strict CEP format
used in Canoco software, among others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.cep(file, positive=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.cep_+3A_file">file</code></td>
<td>
<p>File name (character variable). </p>
</td></tr>
<tr><td><code id="read.cep_+3A_positive">positive</code></td>
<td>
<p>Only positive entries, like in community data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cornell Ecology Programs (CEP) introduced several data formats
designed for punched cards.  One of these was the &lsquo;condensed
strict&rsquo; format which was adopted by popular software DECORANA and
TWINSPAN. A relaxed variant of this format was later adopted in
Canoco software (ter Braak 1984). Function <code>read.cep</code> reads
legacy files written in this format.
</p>
<p>The condensed CEP and CANOCO formats have:
</p>

<ul>
<li><p> Two or three title cards, most importantly specifying the format
and the number of items per record.
</p>
</li>
<li><p> Data in condensed format: First number on the line is the
site identifier (an integer), and it is followed by pairs
(&lsquo;couplets&rsquo;) of numbers identifying the species and its
abundance (an integer and a floating point number).
</p>
</li>
<li><p> Species and site names, given in Fortran format <code>(10A8)</code>:
Ten names per line, eight columns for each.
</p>
</li></ul>

<p>With option <code>positive = TRUE</code> the function removes all rows and
columns with zero or negative marginal sums.  In community data
with only positive entries, this removes empty sites and species.
If data entries can be negative, this ruins data, and such data sets
should be read in with option <code>positive = FALSE</code>.
</p>


<h3>Value</h3>

<p>Returns a data frame, where columns are species and rows are
sites. Column and row names are taken from the CEP file, and changed
into unique <span class="rlang"><b>R</b></span> names by <code><a href="base.html#topic+make.names">make.names</a></code> after stripping the blanks.
</p>


<h3>Note</h3>

<p>Function <code>read.cep</code> used Fortran to read data in <span class="pkg">vegan</span>
2.4-5 and earlier, but Fortran I/O is no longer allowed in CRAN
packages, and the function was re-written in <span class="rlang"><b>R</b></span>. The original
Fortran code was more robust, and there are several legacy data sets
that may fail with the current version, but could be read with the
previous Fortran version. CRAN package <span class="pkg">cepreader</span> makes
available the original Fortran-based code run in a separate
subprocess. The <span class="pkg">cepreader</span> package can also read &lsquo;free&rsquo;
and &lsquo;open&rsquo; Canoco formats that are not handled in this
function.
</p>
<p>The function is based on <code><a href="utils.html#topic+read.fortran">read.fortran</a></code>. If the
<code>REAL</code> format defines a decimal part for species abundances
(such as <code>F5.1</code>), <code><a href="utils.html#topic+read.fortran">read.fortran</a></code> divides the
input with the corresponding power of 10 even when the input data
had explicit decimal separator. With <code>F5.1</code>, 100 would become
10, and 0.1 become 0.01. Function <code>read.cep</code> tries to undo this
division, but you should check the scaling of results after reading
the data, and if necessary, multiply results to the original scale.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

 
<p>ter Braak, C.J.F. (1984&ndash;): CANOCO &ndash; a FORTRAN program for <em>cano</em>nical
<em>c</em>ommunity <em>o</em>rdination by [partial] [detrended] [canonical]
correspondence analysis, principal components analysis and redundancy
analysis. <em>TNO Inst. of Applied Computer Sci., Stat. Dept. Wageningen,
The Netherlands</em>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Provided that you have the file "dune.spe"
## Not run: 
theclassic &lt;- read.cep("dune.spe")
## End(Not run)
</code></pre>

<hr>
<h2 id='renyi'>Renyi and Hill Diversities and Corresponding Accumulation Curves </h2><span id='topic+renyi'></span><span id='topic+plot.renyi'></span><span id='topic+renyiaccum'></span><span id='topic+plot.renyiaccum'></span><span id='topic+persp.renyiaccum'></span>

<h3>Description</h3>

<p>Function <code>renyi</code>  find R√©nyi diversities with any
scale or the corresponding Hill number (Hill 1973).  Function
<code>renyiaccum</code> finds these statistics with accumulating sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>renyi(x, scales = c(0, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, Inf),
   hill = FALSE)
## S3 method for class 'renyi'
plot(x, ...)
renyiaccum(x, scales = c(0, 0.5, 1, 2, 4, Inf), permutations = 100,
    raw = FALSE, collector = FALSE, subset, ...)
## S3 method for class 'renyiaccum'
plot(x, what = c("Collector", "mean", "Qnt 0.025", "Qnt 0.975"),
    type = "l",
    ...)
## S3 method for class 'renyiaccum'
persp(x, theta = 220, col = heat.colors(100), zlim, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="renyi_+3A_x">x</code></td>
<td>
<p>Community data matrix or plotting object. </p>
</td></tr>
<tr><td><code id="renyi_+3A_scales">scales</code></td>
<td>
<p>Scales of R√©nyi diversity.</p>
</td></tr>
<tr><td><code id="renyi_+3A_hill">hill</code></td>
<td>
<p>Calculate Hill numbers.</p>
</td></tr>
<tr><td><code id="renyi_+3A_permutations">permutations</code></td>
<td>
<p>Usually an integer giving the number
permutations, but can also be a list of control values for the
permutations as returned by the function <code><a href="permute.html#topic+how">how</a></code>,
or a permutation matrix where each row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="renyi_+3A_raw">raw</code></td>
<td>
<p>if <code>FALSE</code> then return summary statistics of
permutations, and if <code>TRUE</code> then returns the individual
permutations.</p>
</td></tr>
<tr><td><code id="renyi_+3A_collector">collector</code></td>
<td>
<p>Accumulate the diversities in the order the sites are
in the data set, and the collector curve can be plotted against
summary of permutations. The argument is ignored if <code>raw = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="renyi_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating sites (rows) to keep: missing
values are taken as <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="renyi_+3A_what">what</code></td>
<td>
<p>Items to be plotted.</p>
</td></tr>
<tr><td><code id="renyi_+3A_type">type</code></td>
<td>
<p>Type of plot, where <code>type = "l"</code> means lines.</p>
</td></tr>
<tr><td><code id="renyi_+3A_theta">theta</code></td>
<td>
<p>Angle defining the viewing direction (azimuthal) in
<code><a href="graphics.html#topic+persp">persp</a></code>.</p>
</td></tr>
<tr><td><code id="renyi_+3A_col">col</code></td>
<td>
<p>Colours used for surface. Single colour will be passed on,
and vector colours will be
selected by the midpoint of a rectangle in <code><a href="graphics.html#topic+persp">persp</a></code>. </p>
</td></tr>
<tr><td><code id="renyi_+3A_zlim">zlim</code></td>
<td>
<p>Limits of vertical axis.</p>
</td></tr>
<tr><td><code id="renyi_+3A_...">...</code></td>
<td>
<p>Other arguments which are passed to <code>renyi</code> and
to graphical functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Common <code><a href="#topic+diversity">diversity</a></code> indices are special cases of
R√©nyi diversity
</p>
<p style="text-align: center;"><code class="reqn">H_a = \frac{1}{1-a} \log \sum p_i^a</code>
</p>

<p>where <code class="reqn">a</code> is a scale parameter, and Hill (1975) suggested to
use so-called &lsquo;Hill numbers&rsquo; defined as <code class="reqn">N_a = \exp(H_a)</code>.  Some Hill numbers are the number of species with
<code class="reqn">a = 0</code>, <code class="reqn">\exp(H')</code> or the exponent of Shannon
diversity with <code class="reqn">a = 1</code>, inverse Simpson with <code class="reqn">a = 2</code> and
<code class="reqn">1/ \max(p_i)</code> with <code class="reqn">a = \infty</code>. According
to the theory of diversity ordering, one community can be regarded as
more diverse than another only if its R√©nyi diversities are all higher
(T√≥thm√©r√©sz  1995).
</p>
<p>The <code>plot</code> method for <code>renyi</code> uses <span class="pkg">lattice</span> graphics,
and displays the diversity values against each scale in separate panel
for each site together with minimum, maximum and median values in the
complete data.
</p>
<p>Function <code>renyiaccum</code> is similar to <code><a href="#topic+specaccum">specaccum</a></code> but
finds R√©nyi or Hill diversities at given <code>scales</code>
for random permutations of accumulated sites.  Its <code>plot</code>
function uses <span class="pkg">lattice</span> function <code><a href="lattice.html#topic+xyplot">xyplot</a></code>
to display the accumulation curves for each value of <code>scales</code>
in a separate panel.  In addition, it has a <code>persp</code> method to
plot the diversity surface against scale and number and
sites. Similar dynamic graphics can be made with
<code>rgl.renyiaccum</code> in <span class="pkg">vegan3d</span> package.
</p>


<h3>Value</h3>

<p>Function <code>renyi</code> returns a data frame of selected
indices.  Function <code>renyiaccum</code> with argument <code>raw = FALSE</code>
returns a three-dimensional array, where the first dimension are the
accumulated sites, second dimension are the diversity scales, and
third dimension are the summary statistics <code>mean</code>, <code>stdev</code>,
<code>min</code>, <code>max</code>, <code>Qnt 0.025</code> and <code>Qnt 0.975</code>.  With
argument <code>raw = TRUE</code> the statistics on the third dimension are
replaced with individual permutation results.
</p>


<h3>Author(s)</h3>

<p> Roeland Kindt and Jari Oksanen </p>


<h3>References</h3>

<p>Hill, M.O. (1973). Diversity and evenness: a unifying notation and its
consequences. <em>Ecology</em> 54, 427&ndash;473.
</p>
<p>Kindt, R., Van Damme, P., Simons, A.J. (2006). Tree diversity in western
Kenya: using profiles to characterise richness and
evenness. <em>Biodiversity and Conservation</em> 15, 1253&ndash;1270.
</p>
<p>T√≥thm√©r√©sz, B. (1995). Comparison of different methods for diversity
ordering. <em>Journal of Vegetation Science</em> 6, 283&ndash;290.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diversity">diversity</a></code> for diversity indices, and
<code><a href="#topic+specaccum">specaccum</a></code> for ordinary species accumulation curves, and
<code><a href="lattice.html#topic+xyplot">xyplot</a></code>, <code><a href="graphics.html#topic+persp">persp</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
i &lt;- sample(nrow(BCI), 12)
mod &lt;- renyi(BCI[i,])
plot(mod)
mod &lt;- renyiaccum(BCI[i,])
plot(mod, as.table=TRUE, col = c(1, 2, 2))
persp(mod)
</code></pre>

<hr>
<h2 id='reorder.hclust'>
Reorder a Hierarchical Clustering Tree
</h2><span id='topic+reorder.hclust'></span><span id='topic+rev.hclust'></span><span id='topic+cutreeord'></span><span id='topic+scores.hclust'></span>

<h3>Description</h3>

<p>Function takes a hierarchical clustering tree from
<code><a href="stats.html#topic+hclust">hclust</a></code> and a vector of values and reorders the
clustering tree in the order of the supplied vector, maintaining the
constraints on the tree. This is a method of generic function
<code><a href="stats.html#topic+reorder">reorder</a></code> and an alternative to reordering a
<code>"dendrogram"</code> object with <code><a href="stats.html#topic+reorder.dendrogram">reorder.dendrogram</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hclust'
reorder(x, wts, 
   agglo.FUN = c("mean", "min", "max", "sum", "uwmean"), ...)
## S3 method for class 'hclust'
rev(x)
## S3 method for class 'hclust'
scores(x, display = "internal", ...)
cutreeord(tree, k = NULL, h = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reorder.hclust_+3A_x">x</code>, <code id="reorder.hclust_+3A_tree">tree</code></td>
<td>

<p>hierarchical clustering from <code><a href="stats.html#topic+hclust">hclust</a></code>.
</p>
</td></tr>
<tr><td><code id="reorder.hclust_+3A_wts">wts</code></td>
<td>

<p>numeric vector for reordering.
</p>
</td></tr>
<tr><td><code id="reorder.hclust_+3A_agglo.fun">agglo.FUN</code></td>
<td>

<p>a function for weights agglomeration, see below.
</p>
</td></tr>
<tr><td><code id="reorder.hclust_+3A_display">display</code></td>
<td>

<p>return <code>"internal"</code> nodes or <code>"terminal"</code> nodes (also
called <code>"leaves"</code>).
</p>
</td></tr>
<tr><td><code id="reorder.hclust_+3A_k">k</code>, <code id="reorder.hclust_+3A_h">h</code></td>
<td>

<p>scalars or vectors giving the numbers of desired groups or the heights
where the tree should be cut (passed to function
<code><a href="stats.html#topic+cutree">cutree</a></code>).
</p>
</td></tr>
<tr><td><code id="reorder.hclust_+3A_...">...</code></td>
<td>

<p>additional arguments (ignored).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dendrograms can be ordered in many ways. The <code>reorder</code> function
reorders an <code><a href="stats.html#topic+hclust">hclust</a></code> tree and provides an alternative to
<code><a href="stats.html#topic+reorder.dendrogram">reorder.dendrogram</a></code> which can reorder a
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code>. The current function will also work
differently when the <code>agglo.FUN</code> is <code>"mean"</code>: the
<code><a href="stats.html#topic+reorder.dendrogram">reorder.dendrogram</a></code> will always take the direct mean of
member groups ignoring their sizes, but this function will used
<code><a href="stats.html#topic+weighted.mean">weighted.mean</a></code> weighted by group sizes, so that the
group mean is always the mean of member leaves (terminal nodes). If
you want to ignore group sizes, you can use unweighted mean with
<code>"uwmean"</code>. 
</p>
<p>The function accepts only a limited list of <code>agglo.FUN</code>
functions for assessing the value of <code>wts</code> for groups. The
ordering is always ascending, but the order of leaves can be
reversed with <code>rev</code>.
</p>
<p>Function <code>scores</code> finds the coordinates of nodes as a two-column
matrix. For terminal nodes (leaves) this the value at which the item
is merged to the tree, and the labels can still <code>hang</code> below this
level (see <code><a href="stats.html#topic+plot.hclust">plot.hclust</a></code>).
</p>
<p>Function <code>cutreeord</code> cuts a tree to groups numbered from left to
right in the tree. It is based on the standard function
<code><a href="stats.html#topic+cutree">cutree</a></code> which numbers the groups in the order they appear
in the input data instead of the order in the tree.
</p>


<h3>Value</h3>

<p>Reordered <code><a href="stats.html#topic+hclust">hclust</a></code> result object with added item
<code>value</code> that gives the value of the statistic at each merge
level. 
</p>


<h3>Note</h3>

<p>These functions should really be in base <span class="rlang"><b>R</b></span>.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+hclust">hclust</a></code> for getting clustering trees,
<code><a href="#topic+as.hclust.spantree">as.hclust.spantree</a></code> to change a <span class="pkg">vegan</span> minimum
spanning tree to an <code><a href="stats.html#topic+hclust">hclust</a></code> object, and
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code> and <code><a href="stats.html#topic+reorder.dendrogram">reorder.dendrogram</a></code> for an
alternative implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## reorder by water content of soil
data(mite, mite.env)
hc &lt;- hclust(vegdist(wisconsin(sqrt(mite))))
ohc &lt;- with(mite.env, reorder(hc, WatrCont))
plot(hc)
plot(ohc)

## label leaves by the observed value, and each branching point
## (internal node) by the cluster mean
with(mite.env, plot(ohc, labels=round(WatrCont), cex=0.7))
ordilabel(scores(ohc), label=round(ohc$value), cex=0.7)

## Slightly different from reordered 'dendrogram' which ignores group
## sizes in assessing means.
den &lt;- as.dendrogram(hc)
den &lt;- with(mite.env, reorder(den, WatrCont, agglo.FUN = mean))
plot(den)
</code></pre>

<hr>
<h2 id='RsquareAdj'>
Adjusted R-square
</h2><span id='topic+RsquareAdj'></span><span id='topic+RsquareAdj.default'></span><span id='topic+RsquareAdj.rda'></span><span id='topic+RsquareAdj.cca'></span><span id='topic+RsquareAdj.lm'></span><span id='topic+RsquareAdj.glm'></span>

<h3>Description</h3>

<p>The functions finds the adjusted R-square.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
RsquareAdj(x, n, m, ...)
## S3 method for class 'rda'
RsquareAdj(x, ...)
## S3 method for class 'cca'
RsquareAdj(x, permutations = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RsquareAdj_+3A_x">x</code></td>
<td>
<p> Unadjusted R-squared or an object from which the terms for
evaluation or adjusted R-squared can be found.</p>
</td></tr>
<tr><td><code id="RsquareAdj_+3A_n">n</code>, <code id="RsquareAdj_+3A_m">m</code></td>
<td>
<p>Number of observations and number of degrees of freedom
in the fitted model.</p>
</td></tr>
<tr><td><code id="RsquareAdj_+3A_permutations">permutations</code></td>
<td>
<p>Number of permutations to use when computing the adjusted 
R-squared for a cca. The permutations can be calculated in parallel by
specifying the number of cores which is passed to <code><a href="#topic+permutest">permutest</a></code></p>
</td></tr>
<tr><td><code id="RsquareAdj_+3A_...">...</code></td>
<td>
<p> Other arguments (ignored) except in the case of cca in 
which these arguments are passed to <code><a href="#topic+permutest">permutest</a></code>.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p> The default method finds the adjusted <code class="reqn">R^2</code>
from the unadjusted <code class="reqn">R^2</code>, number of observations, and
number of degrees of freedom in the fitted model. The specific methods
find this information from the fitted result object. There are
specific methods for <code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+cca">cca</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>. Adjusted, or even unadjusted,
<code class="reqn">R^2</code> may not be available in some cases, and then the
functions will return <code>NA</code>. There is no adjusted
<code class="reqn">R^2</code> in partial ordination, and <code class="reqn">R^2</code>
values are available only for <code><a href="stats.html#topic+gaussian">gaussian</a></code> models in
<code><a href="stats.html#topic+glm">glm</a></code>.
</p>
<p>The adjusted, <code class="reqn">R^2</code> of <code>cca</code> is computed using a
permutation approach developed by Peres-Neto et al. (2006). By
default 1000 permutations are used.
</p>


<h3>Value</h3>

<p> The functions return a list of items <code>r.squared</code> and
<code>adj.r.squared</code>.  
</p>


<h3>References</h3>

<p>Legendre, P., Oksanen, J. and ter Braak, C.J.F. (2011). Testing the
significance of canonical axes in redundancy analysis. 
<em>Methods in Ecology and Evolution</em> 2, 269&ndash;277.
</p>
<p>Peres-Neto, P., P. Legendre, S. Dray and D. Borcard. 2006. Variation
partitioning of species data matrices: estimation and comparison of
fractions. <em>Ecology</em> 87, 2614&ndash;2625.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+varpart">varpart</a></code> uses <code>RsquareAdj</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite)
data(mite.env)
## rda
m &lt;- rda(decostand(mite, "hell") ~  ., mite.env)
RsquareAdj(m)
## cca
m &lt;- cca(decostand(mite, "hell") ~  ., mite.env)
RsquareAdj(m)
## default method
RsquareAdj(0.8, 20, 5)
</code></pre>

<hr>
<h2 id='scores'> Get Species or Site Scores from an Ordination </h2><span id='topic+scores'></span><span id='topic+scores.default'></span><span id='topic+scores.lda'></span>

<h3>Description</h3>

<p>Function to access either species or site scores for specified axes
in some ordination methods. The <code>scores</code> function is generic in
<span class="pkg">vegan</span>, and <span class="pkg">vegan</span> ordination functions have their own
<code>scores</code> functions that are documented separately with the
method (see e.g. <code><a href="#topic+scores.cca">scores.cca</a></code>,
<code><a href="#topic+scores.metaMDS">scores.metaMDS</a></code>, <code><a href="#topic+scores.decorana">scores.decorana</a></code>). This
help file documents the default <code>scores</code> method that is only
used for non-<span class="pkg">vegan</span> ordination objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
scores(x, choices,
    display=c("sites", "species", "both"), tidy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_+3A_x">x</code></td>
<td>
<p> An ordination result. </p>
</td></tr>
<tr><td><code id="scores_+3A_choices">choices</code></td>
<td>
<p> Ordination axes.  If missing, default method returns all axes.</p>
</td></tr>
<tr><td><code id="scores_+3A_display">display</code></td>
<td>
<p> Partial match to access scores for <code>"sites"</code> or
<code>"species"</code> of for <code>"both"</code>.</p>
</td></tr>
<tr><td><code id="scores_+3A_tidy">tidy</code></td>
<td>
<p>Return <code>"both"</code> scores in data frame that is
compatible with <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>, with variable <code>score</code>
labelling the scores as <code>"sites"</code> or <code>"species"</code>.</p>
</td></tr> 
<tr><td><code id="scores_+3A_...">...</code></td>
<td>
<p> Other parameters (unused). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>scores</code> is a generic method in <span class="pkg">vegan</span>. Several
<span class="pkg">vegan</span> functions have their own <code>scores</code> methods with their
own defaults and with some new arguments. This help page describes
only the default method. For other methods, see, e.g.,
<code><a href="#topic+scores.cca">scores.cca</a></code>, <code><a href="#topic+scores.rda">scores.rda</a></code>,
<code><a href="#topic+scores.decorana">scores.decorana</a></code>.
</p>
<p>All <span class="pkg">vegan</span> ordination functions should have a <code>scores</code>
method which should be used to extract the scores instead of
directly accessing them. Scaling and transformation of scores should
also happen in the <code>scores</code> function. If the <code>scores</code>
function is available, the results can be plotted using
<code><a href="#topic+ordiplot">ordiplot</a></code>, <code><a href="#topic+ordixyplot">ordixyplot</a></code> etc., and the
ordination results can be compared in <code><a href="#topic+procrustes">procrustes</a></code>
analysis.
</p>
<p>The <code>scores.default</code> function is used to extract scores from
non-<span class="pkg">vegan</span> ordination results.  Many standard ordination
methods of libraries do not have a specific <code>class</code>, and no
specific method can be written for them.  However,
<code>scores.default</code> guesses where some commonly used functions
keep their site scores and possible species scores.
</p>
<p>If <code>x</code> is a matrix, <code>scores.default</code> returns the chosen
columns of that matrix, ignoring whether species or sites were
requested (do not regard this as a bug but as a feature, please).
Currently the function seems to work at least for <code><a href="MASS.html#topic+isoMDS">isoMDS</a></code>,
<code><a href="stats.html#topic+prcomp">prcomp</a></code>, <code><a href="stats.html#topic+princomp">princomp</a></code> and some <span class="pkg">ade4</span> objects. 
It may work in other cases or fail mysteriously.
</p>


<h3>Value</h3>

<p>The function returns a matrix of scores if one type is requested, or a
named list of matrices if <code>display = "both"</code>, or a
<a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a> compatible data frame if <code>tidy = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen </p>


<h3>See Also</h3>

<p>Specific <code>scores</code> functions include (but are not limited to)
<code><a href="#topic+scores.cca">scores.cca</a></code>, <code><a href="#topic+scores.rda">scores.rda</a></code>,
<code><a href="#topic+scores.decorana">scores.decorana</a></code>, <code><a href="#topic+scores.envfit">scores.envfit</a></code>,
<code><a href="#topic+scores.metaMDS">scores.metaMDS</a></code>, <code><a href="#topic+scores.monoMDS">scores.monoMDS</a></code> and
<code><a href="#topic+scores.pcnm">scores.pcnm</a></code>.  These have somewhat different interface
&ndash; <code><a href="#topic+scores.cca">scores.cca</a></code> in particular &ndash; but all work with
keywords <code>display="sites"</code> and return a matrix. However, they
may also return a list of matrices, and some other <code>scores</code>
methods will have quite different arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
vare.pca &lt;- prcomp(varespec)
scores(vare.pca, choices=c(1,2))
</code></pre>

<hr>
<h2 id='screeplot.cca'>Screeplots for Ordination Results and Broken Stick Distributions</h2><span id='topic+screeplot.cca'></span><span id='topic+screeplot.princomp'></span><span id='topic+screeplot.prcomp'></span><span id='topic+screeplot.decorana'></span><span id='topic+bstick'></span><span id='topic+bstick.default'></span><span id='topic+bstick.cca'></span><span id='topic+bstick.prcomp'></span><span id='topic+bstick.princomp'></span><span id='topic+bstick.decorana'></span>

<h3>Description</h3>

<p>Screeplot methods for plotting variances of ordination axes/components
and overlaying broken stick distributions. Also, provides alternative
screeplot methods for <code><a href="stats.html#topic+princomp">princomp</a></code> and <code><a href="stats.html#topic+prcomp">prcomp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cca'
screeplot(x, bstick = FALSE, type = c("barplot", "lines"),
         npcs = min(10, if (is.null(x$CCA) || x$CCA$rank == 0) x$CA$rank else x$CCA$rank),
         ptype = "o", bst.col = "red", bst.lty = "solid",
         xlab = "Component", ylab = "Inertia",
         main = deparse(substitute(x)), legend = bstick,
         ...)

## S3 method for class 'decorana'
screeplot(x, bstick = FALSE, type = c("barplot", "lines"),
         npcs = 4,
         ptype = "o", bst.col = "red", bst.lty = "solid",
         xlab = "Component", ylab = "Inertia",
         main = deparse(substitute(x)), legend = bstick,
         ...)

## S3 method for class 'prcomp'
screeplot(x, bstick = FALSE, type = c("barplot", "lines"),
         npcs = min(10, length(x$sdev)),
         ptype = "o", bst.col = "red", bst.lty = "solid",
         xlab = "Component", ylab = "Inertia",
         main = deparse(substitute(x)), legend = bstick,
         ...)

## S3 method for class 'princomp'
screeplot(x, bstick = FALSE, type = c("barplot", "lines"),
         npcs = min(10, length(x$sdev)),
         ptype = "o", bst.col = "red", bst.lty = "solid",
         xlab = "Component", ylab = "Inertia",
         main = deparse(substitute(x)), legend = bstick,
         ...)

bstick(n, ...)

## Default S3 method:
bstick(n, tot.var = 1, ...)

## S3 method for class 'cca'
bstick(n, ...)

## S3 method for class 'prcomp'
bstick(n, ...)

## S3 method for class 'princomp'
bstick(n, ...)

## S3 method for class 'decorana'
bstick(n, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="screeplot.cca_+3A_x">x</code></td>
<td>
<p>an object from which the component variances can be determined.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_bstick">bstick</code></td>
<td>
<p>logical; should the broken stick distribution be drawn?</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_npcs">npcs</code></td>
<td>
<p>the number of components to be plotted.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_type">type</code></td>
<td>
<p>the type of plot.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_ptype">ptype</code></td>
<td>
<p>if <code>type == "lines"</code> or <code>bstick = TRUE</code>, a
character indicating the type of plotting used for the lines;
actually any of the <code>type</code>s as in <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr> 
<tr><td><code id="screeplot.cca_+3A_bst.col">bst.col</code>, <code id="screeplot.cca_+3A_bst.lty">bst.lty</code></td>
<td>
<p>the colour and line type used to draw the
broken stick distribution.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_xlab">xlab</code>, <code id="screeplot.cca_+3A_ylab">ylab</code>, <code id="screeplot.cca_+3A_main">main</code></td>
<td>
<p>graphics parameters.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_legend">legend</code></td>
<td>
<p>logical; draw a legend?</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_n">n</code></td>
<td>
<p>an object from which the variances can be extracted or the
number of variances (components) in the case of
<code>bstick.default</code>.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_tot.var">tot.var</code></td>
<td>
<p>the total variance to be split.</p>
</td></tr>
<tr><td><code id="screeplot.cca_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions provide screeplots for most ordination methods in
<span class="pkg">vegan</span> and enhanced versions with broken stick for
<code><a href="stats.html#topic+prcomp">prcomp</a></code> and <code><a href="stats.html#topic+princomp">princomp</a></code>. 
</p>
<p>Function <code>bstick</code> gives the brokenstick values which are ordered
random proportions, defined as  <code class="reqn">p_i = (tot/n) \sum_{x=i}^n 
    (1/x)</code> (Legendre &amp; Legendre 2012), where
<code class="reqn">tot</code> is the total  and <code class="reqn">n</code> is the number of brokenstick
components (cf. <code><a href="#topic+radfit">radfit</a></code>).  Broken stick has
been recommended as a stopping rule in principal component analysis
(Jackson 1993): principal components should be retained as long as
observed eigenvalues are higher than corresponding random broken stick
components.
</p>
<p>The <code>bstick</code> function is generic. The default needs the number of
components and the total, and specific methods extract this
information from ordination results.  There also is a <code>bstick</code>
method for <code><a href="#topic+cca">cca</a></code>.  However, the broken stick model is not
strictly valid for correspondence analysis (CA), because eigenvalues
of CA are defined to be <code class="reqn">\leq 1</code>, whereas brokenstick
components have no such restrictions. The brokenstick components in
detrended correspondence analysis (DCA) assume that input data are of
full rank, and additive eigenvalues are used in <code>screeplot</code> (see
<code><a href="#topic+decorana">decorana</a></code>).
</p>


<h3>Value</h3>

<p>Function <code>screeplot</code> draws a plot on the currently active device, 
and returns invisibly the <code><a href="grDevices.html#topic+xy.coords">xy.coords</a></code> of the points or
bars for the eigenvalues.
</p>
<p>Function <code>bstick</code> returns a numeric vector of broken stick
components. 
</p>


<h3>Author(s)</h3>

<p>Gavin L. Simpson</p>


<h3>References</h3>

<p>Jackson, D. A. (1993). Stopping rules in principal components
analysis: a comparison of heuristical and statistical
approaches. <em>Ecology</em> 74, 2204&ndash;2214.
</p>
<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd English
ed. Elsevier.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+decorana">decorana</a></code>, <code><a href="stats.html#topic+princomp">princomp</a></code> and
<code><a href="stats.html#topic+prcomp">prcomp</a></code> for the ordination functions, and
<code><a href="stats.html#topic+screeplot">screeplot</a></code> for the stock version.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
vare.pca &lt;- rda(varespec, scale = TRUE)
bstick(vare.pca)
screeplot(vare.pca, bstick = TRUE, type = "lines")
</code></pre>

<hr>
<h2 id='simper'>Similarity Percentages</h2><span id='topic+simper'></span><span id='topic+summary.simper'></span>

<h3>Description</h3>

<p>Discriminating species between two groups using
Bray-Curtis dissimilarities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simper(comm, group, permutations = 999, parallel = 1, ...)
## S3 method for class 'simper'
summary(object, ordered = TRUE,
    digits = max(3,getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simper_+3A_comm">comm</code></td>
<td>
<p>Community data.</p>
</td></tr>
<tr><td><code id="simper_+3A_group">group</code></td>
<td>
<p>Factor describing the group structure. If this is
missing or has only one level, contributions are estimated for
non-grouped data and dissimilarities only show the overall
heterogeneity in species abundances.</p>
</td></tr>
<tr><td><code id="simper_+3A_permutations">permutations</code></td>
<td>
<p>a list of control values for the permutations
as returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the
number of permutations required, or a permutation matrix where each
row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="simper_+3A_object">object</code></td>
<td>
<p>an object returned by <code>simper</code>.</p>
</td></tr>
<tr><td><code id="simper_+3A_ordered">ordered</code></td>
<td>
<p>Logical; Should the species be ordered by their
average contribution?</p>
</td></tr>
<tr><td><code id="simper_+3A_digits">digits</code></td>
<td>
<p>Number of digits in output.</p>
</td></tr>
<tr><td><code id="simper_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. (Not yet implemented).</p>
</td></tr>
<tr><td><code id="simper_+3A_...">...</code></td>
<td>
<p>Parameters passed to other functions. In <code>simper</code> the
extra parameters are passed to <code><a href="permute.html#topic+shuffleSet">shuffleSet</a></code> if
permutations are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Similarity percentage, <code>simper</code> (Clarke 1993) is based
on the decomposition of Bray-Curtis dissimilarity index (see
<code><a href="#topic+vegdist">vegdist</a></code>, <code><a href="#topic+designdist">designdist</a></code>). The contribution
of individual species <code class="reqn">i</code> to the overall Bray-Curtis dissimilarity
<code class="reqn">d_{jk}</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">d_{ijk} = \frac{|x_{ij}-x_{ik}|}{\sum_{i=1}^S (x_{ij}+x_{ik})}</code>
</p>

<p>where <code class="reqn">x</code> is the abundance of species <code class="reqn">i</code> in sampling units
<code class="reqn">j</code> and <code class="reqn">k</code>. The overall index is the sum of the individual
contributions over all <code class="reqn">S</code> species 
<code class="reqn">d_{jk}=\sum_{i=1}^S d_{ijk}</code>. 
</p>
<p>The <code>simper</code> functions performs pairwise comparisons of groups
of sampling units and finds the contribution of each species to the
average between-group Bray-Curtis dissimilarity. Although the method
is called &ldquo;Similarity Percentages&rdquo;, it really studied
dissimilarities instead of similarities (Clarke 1993).
</p>
<p>The function displays most important species for each pair of
<code>groups</code>.  These species contribute at least to 70 % of the
differences between groups.  The function returns much more
extensive results (including all species) which can be accessed
directly from the result object (see section Value). Function
<code>summary</code> transforms the result to a list of data frames. With
argument <code>ordered = TRUE</code> the data frames also include the
cumulative contributions and are ordered by species contribution.
</p>
<p>The results of <code>simper</code> can be very difficult to interpret and
they are often misunderstood even in publications. The method gives
the contribution of each species to overall dissimilarities, but
these are caused by variation in species abundances, and only partly
by differences among groups.  Even if you make groups that are
copies of each other, the method will single out species with high
contribution, but these are not contributions to non-existing
between-group differences but to random noise variation in species
abundances. The most abundant species usually have highest
variances, and they have high contributions even when they do not
differ among groups. Permutation tests study the differences among
groups, and they can be used to find out the species for which the
differences among groups is an important component of their
contribution to dissimilarities. Analysis without <code>group</code>
argument will find species contributions to the average overall
dissimilarity among sampling units. These non-grouped contributions
can be compared to grouped contributions to see how much added value
the grouping has for each species.
</p>


<h3>Value</h3>

<p>A list of class <code>"simper"</code> with following items:
</p>
<table>
<tr><td><code>species</code></td>
<td>
<p>The species names.</p>
</td></tr>
<tr><td><code>average</code></td>
<td>
<p>Species contribution to average between-group dissimilarity.</p>
</td></tr>
<tr><td><code>overall</code></td>
<td>
<p>The average between-group dissimilarity. This is the sum of
the item <code>average</code>.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>Standard deviation of contribution.</p>
</td></tr> 
<tr><td><code>ratio</code></td>
<td>
<p>Average to sd ratio.</p>
</td></tr>
<tr><td><code>ava</code>, <code>avb</code></td>
<td>
<p>Average abundances per group.</p>
</td></tr>
<tr><td><code>ord</code></td>
<td>
<p>An index vector to order vectors by their contribution or
order <code>cusum</code> back to the original data order.</p>
</td></tr>
<tr><td><code>cusum</code></td>
<td>
<p>Ordered cumulative contribution. These are based on item
<code>average</code>, but they sum up to total 1.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>Permutation <code class="reqn">p</code>-value. Probability of getting a larger
or equal average contribution in random permutation of the group
factor. These area only available if <code>permutations</code> were used
(default: not calculated).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Eduard Sz√∂cs and Jari Oksanen.
</p>


<h3>References</h3>

<p>Clarke, K.R. 1993. Non-parametric multivariate analyses of changes
in community structure. <em>Australian Journal of Ecology</em>, 18,
117‚Äì143.
</p>


<h3>See Also</h3>

<p>Function <code><a href="#topic+meandist">meandist</a></code> shows the average between-group
dissimilarities (as well as the within-group dissimilarities).</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
(sim &lt;- with(dune.env, simper(dune, Management, permutations = 99)))
## IGNORE_RDIFF_BEGIN
summary(sim)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='simulate.rda'> Simulate Responses with Gaussian Error or Permuted Residuals for Constrained Ordination </h2><span id='topic+simulate.rda'></span><span id='topic+simulate.cca'></span><span id='topic+simulate.capscale'></span>

<h3>Description</h3>

<p> Function simulates a response data frame so that it adds
Gaussian error to the fitted responses of Redundancy Analysis
(<code><a href="#topic+rda">rda</a></code>), Constrained Correspondence Analysis
(<code><a href="#topic+cca">cca</a></code>) or distance-based RDA (<code><a href="#topic+capscale">capscale</a></code>).
The function is a special case of generic <code><a href="stats.html#topic+simulate">simulate</a></code>, and
works similarly as <code>simulate.lm</code>.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rda'
simulate(object, nsim = 1, seed = NULL, indx = NULL,
    rank = "full", correlated = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.rda_+3A_object">object</code></td>
<td>
<p>an object representing a fitted <code><a href="#topic+rda">rda</a></code>,
<code><a href="#topic+cca">cca</a></code> or <code><a href="#topic+capscale">capscale</a></code> model.</p>
</td></tr>
<tr><td><code id="simulate.rda_+3A_nsim">nsim</code></td>
<td>
<p>number of response matrices to be simulated. Only one
dissimilarity matrix is returned for <code><a href="#topic+capscale">capscale</a></code>, and
larger <code>nsim</code> is an error.</p>
</td></tr>
<tr><td><code id="simulate.rda_+3A_seed">seed</code></td>
<td>
<p>an object specifying if and how the random number
generator should be initialized (&lsquo;seeded&rsquo;). See 
<code><a href="stats.html#topic+simulate">simulate</a></code> for details. </p>
</td></tr>
<tr><td><code id="simulate.rda_+3A_indx">indx</code></td>
<td>
<p>Index of residuals added to the fitted values, such as
produced by <code><a href="permute.html#topic+shuffleSet">shuffleSet</a></code> or
<code><a href="base.html#topic+sample">sample</a></code>.  The index can have duplicate entries so
that bootstrapping is allowed. If <code>nsim</code> <code class="reqn">&gt;1</code>, the output
should be compliant with <code><a href="permute.html#topic+shuffleSet">shuffleSet</a></code> with
one line for each simulation.  If <code>nsim</code> is missing, the
number of rows of <code>indx</code> is used to define the number of
simulations, but if <code>nsim</code> is given, it should match number
of rows in <code>indx</code>. If null, parametric simulation is used and
Gaussian error is added to the fitted values.</p>
</td></tr>
<tr><td><code id="simulate.rda_+3A_rank">rank</code></td>
<td>
<p>The rank of the constrained component: passed to
<code><a href="#topic+predict.rda">predict.rda</a></code> or <code><a href="#topic+predict.cca">predict.cca</a></code>. </p>
</td></tr>
<tr><td><code id="simulate.rda_+3A_correlated">correlated</code></td>
<td>
<p>Are species regarded as correlated in parametric
simulation or when <code>indx</code> is not given? If
<code>correlated = TRUE</code>, multivariate Gaussian random error is
generated, and if <code>FALSE</code>, Gaussian random error is generated
separately for each species. The argument has no effect in
<code><a href="#topic+capscale">capscale</a></code> which has no information on species.</p>
</td></tr>
<tr><td><code id="simulate.rda_+3A_...">...</code></td>
<td>
<p>additional optional arguments (ignored). </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The implementation follows <code>"lm"</code> method of
<code><a href="stats.html#topic+simulate">simulate</a></code>, and adds Gaussian (Normal) error to the fitted
values (<code><a href="#topic+fitted.rda">fitted.rda</a></code>) using function <code><a href="stats.html#topic+rnorm">rnorm</a></code>
if <code>correlated = FALSE</code> or <code><a href="MASS.html#topic+mvrnorm">mvrnorm</a></code> if
<code>correlated = TRUE</code>. The standard deviations (<code><a href="stats.html#topic+rnorm">rnorm</a></code>)
or covariance matrices for species (<code><a href="MASS.html#topic+mvrnorm">mvrnorm</a></code>) are
estimated from the residuals after fitting the constraints.
Alternatively, the function can take a permutation index that is used
to add permuted residuals (unconstrained component) to the fitted
values. Raw data are used in <code><a href="#topic+rda">rda</a></code>. Internal Chi-square
transformed data are used in <code><a href="#topic+cca">cca</a></code> within the function,
but the returned matrix is similar to the original input data. The
simulation is performed on internal metric scaling data in
<code><a href="#topic+capscale">capscale</a></code>, but the function returns the Euclidean
distances calculated from the simulated data.  The simulation uses
only the real components, and the imaginary dimensions are ignored.  </p>


<h3>Value</h3>

<p> If <code>nsim = 1</code>, returns a matrix or dissimilarities (in
<code><a href="#topic+capscale">capscale</a></code>) with similar additional arguments on random
number seed as <code><a href="stats.html#topic+simulate">simulate</a></code>. If <code>nsim &gt; 1</code>, returns a
similar array as returned by <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code> with
similar attributes.  </p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+simulate">simulate</a></code> for the generic case and for
<code><a href="stats.html#topic+lm">lm</a></code> objects, and <code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code> for
community null model simulation. Functions <code><a href="#topic+fitted.rda">fitted.rda</a></code>
and <code><a href="#topic+fitted.cca">fitted.cca</a></code> return fitted values without the error
component. See <code><a href="stats.html#topic+rnorm">rnorm</a></code> and <code><a href="MASS.html#topic+mvrnorm">mvrnorm</a></code>
(<span class="pkg">MASS</span> package) for simulating Gaussian random error. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
mod &lt;- rda(dune ~  Moisture + Management, dune.env)
## One simulation
update(mod, simulate(mod) ~  .)
## An impression of confidence regions of site scores
plot(mod, display="sites")
for (i in 1:5) lines(procrustes(mod, update(mod, simulate(mod) ~ .)), col="blue")
## Simulate a set of null communities with permutation of residuals
simulate(mod, indx = shuffleSet(nrow(dune), 99))
</code></pre>

<hr>
<h2 id='sipoo'> Birds in the Archipelago of Sipoo (Sibbo and Borg√•)</h2><span id='topic+sipoo'></span><span id='topic+sipoo.map'></span>

<h3>Description</h3>

<p>Land birds on islands covered by 
coniferous forest in the Sipoo Archipelago, southern Finland.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(sipoo)
  data(sipoo.map)
</code></pre>


<h3>Format</h3>

<p>The <code>sipoo</code> data frame contains data of occurrences of 50 land
bird species on 18 islands in the Sipoo Archipelago (Simberloff &amp;
Martin, 1991, Appendix 3). The species are referred by 4+4 letter
abbreviation of their Latin names (but using five letters in two
species names to make these unique).
</p>
<p>The <code>sipoo.map</code> data contains the geographic coordinates of the
islands in the ETRS89-TM35FIN coordinate system (EPSG:3067) and the
areas of islands in hectares.
</p>


<h3>Source</h3>

<p>Simberloff, D. &amp; Martin, J.-L.  (1991).  Nestedness of insular
avifaunas: simple summary statistics masking complex species patterns.
<em>Ornis Fennica</em> 68:178&ndash;192.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sipoo)
data(sipoo.map)
plot(N ~ E, data=sipoo.map, asp = 1)
</code></pre>

<hr>
<h2 id='spantree'>Minimum Spanning Tree</h2><span id='topic+spantree'></span><span id='topic+cophenetic.spantree'></span><span id='topic+as.hclust.spantree'></span><span id='topic+plot.spantree'></span><span id='topic+lines.spantree'></span><span id='topic+spandepth'></span>

<h3>Description</h3>

<p>Function <code>spantree</code> finds a minimum spanning tree
connecting all points, but disregarding dissimilarities that are at or
above the threshold or <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spantree(d, toolong = 0)
## S3 method for class 'spantree'
as.hclust(x, ...)
## S3 method for class 'spantree'
cophenetic(x)
spandepth(x)
## S3 method for class 'spantree'
plot(x, ord, cex = 0.7, type = "p", labels, dlim,
     FUN = sammon,  ...)
## S3 method for class 'spantree'
lines(x, ord, display="sites", col = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spantree_+3A_d">d</code></td>
<td>
<p>Dissimilarity data inheriting from class <code>dist</code> or
a an object, such as a matrix, that can be converted to a
dissimilarity matrix. Functions <code><a href="#topic+vegdist">vegdist</a></code> and
<code><a href="stats.html#topic+dist">dist</a></code> are some functions producing suitable
dissimilarity data.</p>
</td></tr>
<tr><td><code id="spantree_+3A_toolong">toolong</code></td>
<td>
<p> Shortest dissimilarity regarded as <code>NA</code>.
The function uses a fuzz factor, so
that dissimilarities close to the limit will be made <code>NA</code>, too.
If <code>toolong = 0</code> (or negative), no dissimilarity is regarded
as too long.
</p>
</td></tr>
<tr><td><code id="spantree_+3A_x">x</code></td>
<td>
<p>A <code>spantree</code> result object.</p>
</td></tr>
<tr><td><code id="spantree_+3A_ord">ord</code></td>
<td>
<p>An ordination configuration, or an ordination result known
by <code><a href="#topic+scores">scores</a></code>.</p>
</td></tr>
<tr><td><code id="spantree_+3A_cex">cex</code></td>
<td>
<p>Character expansion factor.</p>
</td></tr>
<tr><td><code id="spantree_+3A_type">type</code></td>
<td>
<p>Observations are plotted as points with
<code>type="p"</code> or <code>type="b"</code>, or as text label with
<code>type="t"</code>. The tree (lines) will always be plotted.</p>
</td></tr>
<tr><td><code id="spantree_+3A_labels">labels</code></td>
<td>
<p>Text used with <code>type="t"</code> or node names if this is
missing.</p>
</td></tr>
<tr><td><code id="spantree_+3A_dlim">dlim</code></td>
<td>
<p>A ceiling value used to highest <code>cophenetic</code> dissimilarity.</p>
</td></tr>
<tr><td><code id="spantree_+3A_fun">FUN</code></td>
<td>
<p>Ordination function to find the configuration from
cophenetic dissimilarities. If the supplied <code>FUN</code> does not work,
supply ordination result as argument <code>ord</code>. </p>
</td></tr>
<tr><td><code id="spantree_+3A_display">display</code></td>
<td>
<p>Type of <code><a href="#topic+scores">scores</a></code> used for <code>ord</code>.</p>
</td></tr>
<tr><td><code id="spantree_+3A_col">col</code></td>
<td>
<p>Colour of line segments. This can be a vector which is
recycled for points, and the line colour will be a mixture of two
joined points.</p>
</td></tr>
<tr><td><code id="spantree_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>spantree</code> finds a minimum spanning tree for
dissimilarities (there may be several minimum spanning trees, but the
function finds only one). Dissimilarities at or above the threshold
<code>toolong</code> and <code>NA</code>s are disregarded, and the spanning tree
is found through other dissimilarities. If the data are disconnected,
the function will return a disconnected tree (or a forest), and the
corresponding link is <code>NA</code>. Connected subtrees can be identified
using <code><a href="#topic+distconnected">distconnected</a></code>.
</p>
<p>Minimum spanning tree is closely related to single linkage
clustering, a.k.a. nearest neighbour clustering, and in genetics as
neighbour joining tree available in <code><a href="stats.html#topic+hclust">hclust</a></code> and
<code><a href="cluster.html#topic+agnes">agnes</a></code> functions. The most important practical
difference is that minimum spanning tree has no concept of cluster
membership, but always joins individual points to each other. Function
<code>as.hclust</code> can change the <code>spantree</code> result into a
corresponding <code><a href="stats.html#topic+hclust">hclust</a></code> object.
</p>
<p>Function <code>cophenetic</code> finds distances between all points along
the tree segments. Function <code>spandepth</code> returns the depth of
each node. The nodes of a tree are either leaves (with one link) or
internal nodes (more than one link). The leaves are recursively
removed from the tree, and the depth is the layer at with the leaf
was removed. In disconnected <code>spantree</code> object (in a forest)
each tree is analysed separately and disconnected nodes not in any
tree have depth zero.
</p>
<p>Function <code>plot</code> displays the tree over a
supplied ordination configuration, and <code>lines</code> adds a spanning
tree to an ordination graph. If configuration is not supplied for <code>plot</code>,
the function ordinates the cophenetic dissimilarities of the
spanning tree and overlays the tree on this result. The default
ordination function is <code><a href="MASS.html#topic+sammon">sammon</a></code> (package <span class="pkg">MASS</span>),
because Sammon scaling emphasizes structure in the neighbourhood of
nodes and may be able to beautifully represent the tree (you may need
to set <code>dlim</code>, and sometimes the results will remain
twisted). These ordination methods do not work with disconnected
trees, but you must supply the ordination configuration. Function
<code>lines</code> will overlay the tree in an existing plot.
</p>
<p>Function <code>spantree</code> uses Prim's method
implemented as priority-first search for dense graphs (Sedgewick
1990). Function <code>cophenetic</code> uses function
<code><a href="#topic+stepacross">stepacross</a></code> with option <code>path = "extended"</code>. The
<code>spantree</code> is very fast, but <code>cophenetic</code> is slow in very
large data sets.
</p>


<h3>Value</h3>

<p>Function <code>spantree</code>
returns an object of class <code>spantree</code> which is a
list with two vectors, each of length <code class="reqn">n-1</code>. The
number of links in a tree is one less the number of observations, and
the first item is omitted. The items are
</p>
<table>
<tr><td><code>kid</code></td>
<td>
<p>The child node of the parent, starting from parent number
two. If there is no link from the parent, value will be <code>NA</code>
and tree is disconnected at the node.</p>
</td></tr>
<tr><td><code>dist</code></td>
<td>
<p>Corresponding distance. If <code>kid = NA</code>, then
<code>dist = 0</code>.</p>
</td></tr>
<tr><td><code>labels</code></td>
<td>
<p>Names of nodes as found from the input dissimilarities.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In principle, minimum spanning tree is equivalent to single linkage
clustering that can be performed using <code><a href="stats.html#topic+hclust">hclust</a></code> or
<code><a href="cluster.html#topic+agnes">agnes</a></code>. However, these functions combine
clusters to each other and the information of the actually connected points
(the &ldquo;single link&rdquo;) cannot be recovered from the result. The
graphical output of a single linkage clustering plotted with
<code><a href="#topic+ordicluster">ordicluster</a></code> will look very different from an equivalent
spanning tree plotted with <code>lines.spantree</code>.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Sedgewick, R. (1990). <em>Algorithms in C</em>. Addison Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vegdist">vegdist</a></code> or <code><a href="stats.html#topic+dist">dist</a></code> for getting
dissimilarities,  and <code><a href="stats.html#topic+hclust">hclust</a></code> or
<code><a href="cluster.html#topic+agnes">agnes</a></code> for single linkage clustering.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
dis &lt;- vegdist(dune)
tr &lt;- spantree(dis)
## Add tree to a metric scaling
plot(tr, cmdscale(dis), type = "t")
## Find a configuration to display the tree neatly
plot(tr, type = "t")
## Depths of nodes
depths &lt;- spandepth(tr)
plot(tr, type = "t", label = depths)
## Plot as a dendrogram
cl &lt;- as.hclust(tr)
plot(cl)
## cut hclust tree to classes and show in colours in spantree
plot(tr, col = cutree(cl, 5), pch=16)
</code></pre>

<hr>
<h2 id='specaccum'>Species Accumulation Curves</h2><span id='topic+specaccum'></span><span id='topic+print.specaccum'></span><span id='topic+summary.specaccum'></span><span id='topic+plot.specaccum'></span><span id='topic+lines.specaccum'></span><span id='topic+boxplot.specaccum'></span><span id='topic+fitspecaccum'></span><span id='topic+plot.fitspecaccum'></span><span id='topic+lines.fitspecaccum'></span><span id='topic+predict.specaccum'></span><span id='topic+predict.fitspecaccum'></span><span id='topic+AIC.fitspecaccum'></span><span id='topic+deviance.fitspecaccum'></span><span id='topic+logLik.fitspecaccum'></span><span id='topic+nobs.fitspecaccum'></span><span id='topic+specslope'></span>

<h3>Description</h3>

<p>Function <code>specaccum</code> finds species accumulation curves or the
number of species for a certain number of sampled sites or
individuals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specaccum(comm, method = "exact", permutations = 100,
          conditioned =TRUE, gamma = "jack1",  w = NULL, subset, ...)
## S3 method for class 'specaccum'
plot(x, add = FALSE, random = FALSE, ci = 2, 
    ci.type = c("bar", "line", "polygon"), col = par("fg"), lty = 1,
    ci.col = col, ci.lty = 1, ci.length = 0, xlab, ylab = x$method, ylim,
    xvar = c("sites", "individuals", "effort"), ...)
## S3 method for class 'specaccum'
boxplot(x, add = FALSE, ...)
fitspecaccum(object, model, method = "random", ...)
## S3 method for class 'fitspecaccum'
plot(x, col = par("fg"), lty = 1, xlab = "Sites", 
    ylab = x$method, ...) 
## S3 method for class 'specaccum'
predict(object, newdata, interpolation = c("linear", "spline"), ...)
## S3 method for class 'fitspecaccum'
predict(object, newdata, ...)
specslope(object, at)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="specaccum_+3A_comm">comm</code></td>
<td>
<p>Community data set.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_method">method</code></td>
<td>
<p>Species accumulation method (partial match). Method
<code>"collector"</code>
adds sites in the order they happen to be in the data,
<code>"random"</code> adds sites in random order, <code>"exact"</code> finds the
expected (mean) species richness, <code>"coleman"</code> finds the
expected richness following
Coleman et al. 1982, and <code>"rarefaction"</code> finds the mean when
accumulating individuals instead of sites.  </p>
</td></tr>
<tr><td><code id="specaccum_+3A_permutations">permutations</code></td>
<td>
<p>Number of permutations with <code>method = "random"</code>.
Usually an integer giving the number permutations, but can also be a
list of control values for the permutations as returned by the
function <code><a href="permute.html#topic+how">how</a></code>, or a permutation matrix where
each row gives the permuted indices.
</p>
</td></tr>
<tr><td><code id="specaccum_+3A_conditioned">conditioned</code></td>
<td>
<p> Estimation of standard deviation is conditional on
the empirical dataset for the exact SAC</p>
</td></tr>
<tr><td><code id="specaccum_+3A_gamma">gamma</code></td>
<td>
<p>Method for estimating the total extrapolated number of species in the
survey area by function <code><a href="#topic+specpool">specpool</a></code></p>
</td></tr>
<tr><td><code id="specaccum_+3A_w">w</code></td>
<td>
<p>Weights giving the sampling effort.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating sites (rows) to keep: missing
values are taken as <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_x">x</code></td>
<td>
<p>A <code>specaccum</code> result object</p>
</td></tr>
<tr><td><code id="specaccum_+3A_add">add</code></td>
<td>
<p>Add to an existing graph.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_random">random</code></td>
<td>
<p>Draw each random simulation separately instead of
drawing their average and confidence intervals.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_ci">ci</code></td>
<td>
<p>Multiplier used to get confidence intervals from standard
deviation (standard error of the estimate). Value <code>ci = 0</code>
suppresses drawing confidence intervals.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_ci.type">ci.type</code></td>
<td>
<p>Type of confidence intervals in the graph: <code>"bar"</code>
draws vertical bars, <code>"line"</code> draws lines, and
<code>"polygon"</code> draws a shaded area.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_col">col</code></td>
<td>
<p>Colour for drawing lines.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_lty">lty</code></td>
<td>
<p>line type (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="specaccum_+3A_ci.col">ci.col</code></td>
<td>
<p>Colour for drawing lines or filling the
<code>"polygon"</code>.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_ci.lty">ci.lty</code></td>
<td>
<p>Line type for confidence intervals or border of the
<code>"polygon"</code>.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_ci.length">ci.length</code></td>
<td>
<p>Length of horizontal bars (in inches) at the end of
vertical bars with <code>ci.type = "bar"</code>.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_xlab">xlab</code>, <code id="specaccum_+3A_ylab">ylab</code></td>
<td>
<p>Labels for <code>x</code> (defaults <code>xvar</code>) and
<code>y</code> axis.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_ylim">ylim</code></td>
<td>
<p>the y limits of the plot.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_xvar">xvar</code></td>
<td>
<p>Variable used for the horizontal axis:
<code>"individuals"</code> can be used only with
<code>method = "rarefaction"</code>. </p>
</td></tr>
<tr><td><code id="specaccum_+3A_object">object</code></td>
<td>
<p>Either a community data set or fitted <code>specaccum</code> model.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_model">model</code></td>
<td>
<p>Nonlinear regression model (<code><a href="stats.html#topic+nls">nls</a></code>). See Details.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_newdata">newdata</code></td>
<td>
<p>Optional data used in prediction interpreted as
number of sampling units (sites). If missing, fitted values are
returned. </p>
</td></tr>
<tr><td><code id="specaccum_+3A_interpolation">interpolation</code></td>
<td>
<p>Interpolation method used with <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_at">at</code></td>
<td>
<p>Number of plots where the slope is evaluated. Can be a
real number.</p>
</td></tr>
<tr><td><code id="specaccum_+3A_...">...</code></td>
<td>
<p>Other parameters to functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Species accumulation curves (SAC) are used to compare diversity
properties of community data sets using different accumulator
functions. The classic method is <code>"random"</code> which finds the mean
SAC and its standard deviation from random permutations of the data,
or subsampling without replacement (Gotelli &amp; Colwell 2001).  The
<code>"exact"</code> method finds the expected SAC using sample-based
rarefaction method that has been independently developed numerous
times (Chiarucci et al. 2008) and it is often known as Mao Tau
estimate (Colwell et al. 2012).  The unconditional standard deviation
for the exact SAC represents a moment-based estimation that is not
conditioned on the empirical data set (sd for all samples &gt; 0). The
unconditional standard deviation is based on an estimation of the
extrapolated number of species in the survey area (a.k.a. gamma
diversity), as estimated by function <code><a href="#topic+specpool">specpool</a></code>. The
conditional standard deviation that was developed by Jari Oksanen (not
published, sd=0 for all samples). Method <code>"coleman"</code> finds the
expected SAC and its standard deviation following Coleman et
al. (1982).  All these methods are based on sampling sites without
replacement. In contrast, the <code>method = "rarefaction"</code> finds the
expected species richness and its standard deviation by sampling
individuals instead of sites.  It achieves this by applying function
<code><a href="#topic+rarefy">rarefy</a></code> with number of individuals corresponding to
average number of individuals per site.
</p>
<p>Methods <code>"random"</code> and <code>"collector"</code> can take weights
(<code>w</code>) that give the sampling effort for each site.  The weights
<code>w</code> do not influence the order the sites are accumulated, but
only the value of the sampling effort so that not all sites are
equal. The summary results are expressed against sites even when the
accumulation uses weights (methods <code>"random"</code>,
<code>"collector"</code>), or is based on individuals
(<code>"rarefaction"</code>).  The actual sampling effort is given as item
<code>Effort</code> or <code>Individuals</code> in the printed result. For
weighted <code>"random"</code> method the effort refers to the average
effort per site, or sum of weights per number of sites. With
weighted <code>method = "random"</code>, the averaged species richness is
found from linear interpolation of single random permutations.
Therefore at least the first value (and often several first) have
<code>NA</code> richness, because these values cannot be interpolated in
all cases but should be extrapolated.  The <code>plot</code> function
defaults to display the results as scaled to sites, but this can be
changed selecting <code>xvar = "effort"</code> (weighted methods) or
<code>xvar = "individuals"</code> (with <code>method = "rarefaction"</code>).
</p>
<p>The <code>summary</code> and <code>boxplot</code> methods are available for
<code>method = "random"</code>.
</p>
<p>Function <code>predict</code> for <code>specaccum</code> can return the values
corresponding to <code>newdata</code>. With <code>method</code> <code>"exact"</code>,
<code>"rarefaction"</code> and <code>"coleman"</code> the function uses analytic
equations for interpolated non-integer values, and for other methods
linear (<code><a href="stats.html#topic+approx">approx</a></code>) or spline (<code><a href="stats.html#topic+spline">spline</a></code>)
interpolation. If <code>newdata</code> is not given, the function returns
the values corresponding to the data. NB., the fitted values with
<code>method="rarefaction"</code> are based on rounded integer counts, but
<code>predict</code> can use fractional non-integer counts with
<code>newdata</code> and give slightly different results.
</p>
<p>Function <code>fitspecaccum</code> fits a nonlinear (<code><a href="stats.html#topic+nls">nls</a></code>)
self-starting species accumulation model. The input <code>object</code>
can be a result of <code>specaccum</code> or a community in data frame. In
the latter case the function first fits a <code>specaccum</code> model and
then proceeds with fitting the nonlinear model. The function can
apply a limited set of nonlinear regression models suggested for
species-area relationship (Dengler 2009). All these are
<code><a href="stats.html#topic+selfStart">selfStart</a></code> models. The permissible alternatives are
<code>"arrhenius"</code> (<code><a href="#topic+SSarrhenius">SSarrhenius</a></code>), <code>"gleason"</code>
(<code><a href="#topic+SSgleason">SSgleason</a></code>), <code>"gitay"</code> (<code><a href="#topic+SSgitay">SSgitay</a></code>),
<code>"lomolino"</code> (<code><a href="#topic+SSlomolino">SSlomolino</a></code>) of <span class="pkg">vegan</span>
package. In addition the following standard <span class="rlang"><b>R</b></span> models are available:
<code>"asymp"</code> (<code><a href="stats.html#topic+SSasymp">SSasymp</a></code>), <code>"gompertz"</code>
(<code><a href="stats.html#topic+SSgompertz">SSgompertz</a></code>), <code>"michaelis-menten"</code>
(<code><a href="stats.html#topic+SSmicmen">SSmicmen</a></code>), <code>"logis"</code> (<code><a href="stats.html#topic+SSlogis">SSlogis</a></code>),
<code>"weibull"</code> (<code><a href="stats.html#topic+SSweibull">SSweibull</a></code>). See these functions for
model specification and details. 
</p>
<p>When weights <code>w</code> were used the fit is based on accumulated
effort and in <code>model = "rarefaction"</code> on accumulated number of
individuals.  The <code>plot</code> is still based on sites, unless other
alternative is selected with <code>xvar</code>.
</p>
<p>Function <code>predict</code> for <code>fitspecaccum</code> uses
<code><a href="stats.html#topic+predict.nls">predict.nls</a></code>, and you can pass all arguments to that
function. In addition, <code>fitted</code>, <code>residuals</code>, <code>nobs</code>,
<code>coef</code>, <code>AIC</code>, <code>logLik</code> and <code>deviance</code> work on
the result object.
</p>
<p>Function <code>specslope</code> evaluates the derivative of the species
accumulation curve at given number of sample plots, and gives the
rate of increase in the number of species. The function works with
<code>specaccum</code> result object when this is based on analytic models
<code>"exact"</code>, <code>"rarefaction"</code> or <code>"coleman"</code>, and with
non-linear regression results of <code>fitspecaccum</code>.
</p>
<p>Nonlinear regression may fail for any reason, and some of the
<code>fitspecaccum</code> models are fragile and may not succeed.  
</p>


<h3>Value</h3>

<p> Function <code>specaccum</code> returns an object of class
<code>"specaccum"</code>, and <code>fitspecaccum</code> a model of class
<code>"fitspecaccum"</code> that adds a few items to the
<code>"specaccum"</code> (see the end of the list below):
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>Function call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Accumulator method.</p>
</td></tr>
<tr><td><code>sites</code></td>
<td>
<p>Number of sites.  For <code>method = "rarefaction"</code> this
is the number of sites corresponding to a certain number of
individuals and generally not an integer, and the average
number of individuals is also returned in item <code>individuals</code>.</p>
</td></tr> 
<tr><td><code>effort</code></td>
<td>
<p>Average sum of weights corresponding to the number of
sites when model was fitted with argument <code>w</code></p>
</td></tr>
<tr><td><code>richness</code></td>
<td>
<p>The number of species corresponding to number of
sites.  With <code>method = "collector"</code> this is the observed
richness, for other methods the average or expected richness.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>The standard deviation of SAC (or its standard error). This
is <code>NULL</code> in <code>method = "collector"</code>, and it
is estimated from permutations in <code>method = "random"</code>, and from
analytic equations in other methods.</p>
</td></tr>
<tr><td><code>perm</code></td>
<td>
<p>Permutation results with <code>method = "random"</code> and
<code>NULL</code> in other cases. Each column in <code>perm</code> holds one
permutation.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Matrix of accumulated weights corresponding to the
columns of the <code>perm</code> matrix when model was fitted with
argument <code>w</code>.</p>
</td></tr>
<tr><td><code>fitted</code>, <code>residuals</code>, <code>coefficients</code></td>
<td>
<p>Only in <code>fitspecacum</code>:
fitted values, residuals and nonlinear model coefficients. For
<code>method = "random"</code> these are matrices with a column for
each random accumulation.</p>
</td></tr>
<tr><td><code>models</code></td>
<td>
<p>Only in <code>fitspecaccum</code>: list of fitted
<code><a href="stats.html#topic+nls">nls</a></code> models (see Examples on accessing these models).</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>The SAC with <code>method = "exact"</code> was
developed by Roeland Kindt, and its standard deviation by Jari
Oksanen (both are unpublished). The <code>method = "coleman"</code>
underestimates the SAC because it does not handle properly sampling
without replacement.  Further, its standard deviation does not take
into account species correlations, and is generally too low. </p>


<h3>Author(s)</h3>

<p>Roeland Kindt <a href="mailto:r.kindt@cgiar.org">r.kindt@cgiar.org</a> and Jari Oksanen.</p>


<h3>References</h3>

<p>Chiarucci, A., Bacaro, G., Rocchini, D. &amp; Fattorini,
L. (2008). Discovering and rediscovering the sample-based rarefaction
formula in the ecological literature. <em>Commun. Ecol.</em> 9:
121&ndash;123.
</p>
<p>Coleman, B.D, Mares, M.A., Willis, M.R. &amp; Hsieh,
Y. (1982). Randomness, area and species richness. <em>Ecology</em> 63:
1121&ndash;1133. 
</p>
<p>Colwell, R.K., Chao, A., Gotelli, N.J., Lin, S.Y., Mao, C.X., Chazdon,
R.L. &amp; Longino, J.T. (2012). Models and estimators linking
individual-based and sample-based rarefaction, extrapolation and
comparison of assemblages. <em>J. Plant Ecol.</em> 5: 3&ndash;21.
</p>
<p>Dengler, J. (2009). Which function describes the species-area
relationship best? A review and empirical evaluation. 
<em>Journal of Biogeography</em> 36, 728&ndash;744.
</p>
<p>Gotelli, N.J. &amp; Colwell, R.K. (2001). Quantifying biodiversity:
procedures and pitfalls in measurement and comparison of species
richness. <em>Ecol. Lett.</em> 4, 379&ndash;391.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rarefy">rarefy</a></code> and <code><a href="#topic+rrarefy">rrarefy</a></code> are related
individual based models. Other accumulation models are
<code><a href="#topic+poolaccum">poolaccum</a></code> for extrapolated richness, and
<code><a href="#topic+renyiaccum">renyiaccum</a></code> and <code><a href="#topic+tsallisaccum">tsallisaccum</a></code> for
diversity indices.  Underlying graphical functions are
<code><a href="graphics.html#topic+boxplot">boxplot</a></code>, <code><a href="graphics.html#topic+matlines">matlines</a></code>,
<code><a href="graphics.html#topic+segments">segments</a></code> and <code><a href="graphics.html#topic+polygon">polygon</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
sp1 &lt;- specaccum(BCI)
sp2 &lt;- specaccum(BCI, "random")
sp2
summary(sp2)
plot(sp1, ci.type="poly", col="blue", lwd=2, ci.lty=0, ci.col="lightblue")
boxplot(sp2, col="yellow", add=TRUE, pch="+")
## Fit Lomolino model to the exact accumulation
mod1 &lt;- fitspecaccum(sp1, "lomolino")
coef(mod1)
fitted(mod1)
plot(sp1)
## Add Lomolino model using argument 'add'
plot(mod1, add = TRUE, col=2, lwd=2)
## Fit Arrhenius models to all random accumulations
mods &lt;- fitspecaccum(sp2, "arrh")
plot(mods, col="hotpink")
boxplot(sp2, col = "yellow", border = "blue", lty=1, cex=0.3, add= TRUE)
## Use nls() methods to the list of models
sapply(mods$models, AIC)
</code></pre>

<hr>
<h2 id='specpool'> Extrapolated Species Richness in a Species Pool</h2><span id='topic+specpool'></span><span id='topic+specpool2vect'></span><span id='topic+poolaccum'></span><span id='topic+summary.poolaccum'></span><span id='topic+plot.poolaccum'></span><span id='topic+estimateR'></span><span id='topic+estimateR.default'></span><span id='topic+estimateR.matrix'></span><span id='topic+estimateR.data.frame'></span><span id='topic+estaccumR'></span>

<h3>Description</h3>

<p>The functions estimate the extrapolated species richness in a species
pool, or the number of unobserved species. Function <code>specpool</code>
is based on incidences in sample sites, and gives a single estimate
for a collection of sample sites (matrix).  Function <code>estimateR</code>
is based on abundances (counts) on single sample site. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specpool(x, pool, smallsample = TRUE)
estimateR(x, ...)
specpool2vect(X, index = c("jack1","jack2", "chao", "boot","Species"))
poolaccum(x, permutations = 100, minsize = 3)
estaccumR(x, permutations = 100, parallel = getOption("mc.cores"))
## S3 method for class 'poolaccum'
summary(object, display, alpha = 0.05, ...)
## S3 method for class 'poolaccum'
plot(x, alpha = 0.05, type = c("l","g"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="specpool_+3A_x">x</code></td>
<td>
<p>Data frame or matrix with species data or the analysis result 
for <code>plot</code> function.</p>
</td></tr>
<tr><td><code id="specpool_+3A_pool">pool</code></td>
<td>
<p>A vector giving a classification for pooling the sites in
the species data. If missing, all sites are pooled together.</p>
</td></tr>
<tr><td><code id="specpool_+3A_smallsample">smallsample</code></td>
<td>
<p>Use small sample correction <code class="reqn">(N-1)/N</code>, where
<code class="reqn">N</code> is the number of sites within the <code>pool</code>.</p>
</td></tr>
<tr><td><code id="specpool_+3A_x">X</code>, <code id="specpool_+3A_object">object</code></td>
<td>
<p>A <code>specpool</code> result object.</p>
</td></tr>
<tr><td><code id="specpool_+3A_index">index</code></td>
<td>
<p>The selected index of extrapolated richness.</p>
</td></tr>
<tr><td><code id="specpool_+3A_permutations">permutations</code></td>
<td>
<p>Usually an integer giving the number
permutations, but can also be a list of control values for the
permutations as returned by the function <code><a href="permute.html#topic+how">how</a></code>, 
or a permutation matrix where each row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="specpool_+3A_minsize">minsize</code></td>
<td>
<p>Smallest number of sampling units reported.</p>
</td></tr>
<tr><td><code id="specpool_+3A_parallel">parallel</code></td>
<td>
<p>Number of parallel processes or a predefined socket
cluster.  With <code>parallel = 1</code> uses ordinary, non-parallel
processing. The parallel processing is done with <span class="pkg">parallel</span>
package.</p>
</td></tr>
<tr><td><code id="specpool_+3A_display">display</code></td>
<td>
<p>Indices to be displayed.</p>
</td></tr>
<tr><td><code id="specpool_+3A_alpha">alpha</code></td>
<td>
<p>Level of quantiles shown. This proportion will be left outside
symmetric limits.</p>
</td></tr>
<tr><td><code id="specpool_+3A_type">type</code></td>
<td>
<p>Type of graph produced in <code><a href="lattice.html#topic+xyplot">xyplot</a></code>.</p>
</td></tr>
<tr><td><code id="specpool_+3A_...">...</code></td>
<td>
<p>Other parameters (not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many species will always remain unseen or undetected in a collection
of sample plots.  The function uses some popular ways of estimating
the number of these unseen species and adding them to the observed
species richness (Palmer 1990, Colwell &amp; Coddington 1994).
</p>
<p>The incidence-based estimates in <code>specpool</code> use the frequencies
of species in a collection of sites.
In the following, <code class="reqn">S_P</code> is the extrapolated richness in a pool,
<code class="reqn">S_0</code> is the observed number of species in the
collection, <code class="reqn">a_1</code> and <code class="reqn">a_2</code> are the number of species
occurring only in one or only in two sites in the collection, <code class="reqn">p_i</code>
is the frequency of species <code class="reqn">i</code>, and <code class="reqn">N</code> is the number of
sites in the collection.  The variants of extrapolated richness in
<code>specpool</code> are:
</p>

<table>
<tr>
 <td style="text-align: left;">
     Chao
    </td><td style="text-align: left;"> <code class="reqn">S_P = S_0 + \frac{a_1^2}{2 a_2}\frac{N-1}{N}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    Chao bias-corrected
    </td><td style="text-align: left;"> <code class="reqn">S_P = S_0 + \frac{a_1(a_1-1)}{2(a_2+1)} \frac{N-1}{N}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    First order jackknife
    </td><td style="text-align: left;"> <code class="reqn">S_P = S_0 + a_1 \frac{N-1}{N}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    Second order jackknife
    </td><td style="text-align: left;"> <code class="reqn">S_P = S_0 + a_1 \frac{2N - 3}{N} - a_2 \frac{(N-2)^2}{N
	(N-1)}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    Bootstrap
    </td><td style="text-align: left;"> <code class="reqn">S_P = S_0 + \sum_{i=1}^{S_0} (1 - p_i)^N</code>
    </td>
</tr>

</table>

<p><code>specpool</code> normally uses basic Chao equation, but when there
are no doubletons (<code class="reqn">a2=0</code>) it switches to bias-corrected
version. In that case the Chao equation simplifies to
<code class="reqn">S_0 + \frac{1}{2} a_1 (a_1-1) \frac{N-1}{N}</code>.
</p>
<p>The abundance-based estimates in <code>estimateR</code> use counts
(numbers of individuals) of species in a single site. If called for
a matrix or data frame, the function will give separate estimates
for each site.  The two variants of extrapolated richness in
<code>estimateR</code> are bias-corrected Chao and ACE (O'Hara 2005, Chiu
et al. 2014).  The Chao estimate is similar as the bias corrected
one above, but <code class="reqn">a_i</code> refers to the number of species with
abundance <code class="reqn">i</code> instead of number of sites, and the small-sample
correction is not used. The ACE estimate is defined as:
</p>

<table>
<tr>
 <td style="text-align: left;">
    ACE
    </td><td style="text-align: left;"> <code class="reqn">S_P = S_{abund} + \frac{S_{rare}}{C_{ace}}+ \frac{a_1}{C_{ace}}
      \gamma^2_{ace}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    where </td><td style="text-align: left;">
    <code class="reqn">C_{ace} = 1 - \frac{a_1}{N_{rare}}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code class="reqn">\gamma^2_{ace} = \max \left[ \frac{S_{rare} \sum_{i=1}^{10}
      i(i-1)a_i}{C_{ace} N_{rare} (N_{rare} - 1)}-1, 0 \right]</code>
    </td>
</tr>

</table>

<p>Here <code class="reqn">a_i</code> refers to number of species with abundance <code class="reqn">i</code>
and  <code class="reqn">S_{rare}</code> is the number of rare
species, 
<code class="reqn">S_{abund}</code> is the number of abundant species, with an
arbitrary 
threshold of abundance 10 for rare species, and <code class="reqn">N_{rare}</code> is
the number 
of individuals in rare species.
</p>
<p>Functions estimate the standard errors of the estimates. These only
concern the number of added species, and assume that there is no
variance in the observed richness.  The equations of standard errors
are too complicated to be reproduced in this help page, but they can
be studied in the <span class="rlang"><b>R</b></span> source code of the function and are discussed
in the <code><a href="utils.html#topic+vignette">vignette</a></code> that can be read with the
<code>browseVignettes("vegan")</code>. The standard error are based on the
following sources: Chiu et al. (2014) for the Chao estimates and
Smith and van Belle (1984) for the first-order Jackknife and the
bootstrap (second-order jackknife is still missing).  For the
variance estimator of <code class="reqn">S_{ace}</code> see O'Hara (2005).
</p>
<p>Functions <code>poolaccum</code> and <code>estaccumR</code> are similar to
<code><a href="#topic+specaccum">specaccum</a></code>, but estimate extrapolated richness indices
of <code>specpool</code> or <code>estimateR</code> in addition to number of
species for random ordering of sampling units. Function
<code>specpool</code> uses presence data and <code>estaccumR</code> count
data. The functions share <code>summary</code> and <code>plot</code>
methods. The <code>summary</code> returns quantile envelopes of
permutations corresponding the given level of <code>alpha</code> and
standard deviation of permutations for each sample size. NB., these
are not based on standard deviations estimated within <code>specpool</code>
or <code>estimateR</code>, but they are based on permutations. The
<code>plot</code> function shows the mean and envelope of permutations
with given <code>alpha</code> for models. The selection of models can be
restricted and order changes using the <code>display</code> argument in
<code>summary</code> or <code>plot</code>. For configuration of <code>plot</code>
command, see <code><a href="lattice.html#topic+xyplot">xyplot</a></code>.
</p>


<h3>Value</h3>

<p>Function <code>specpool</code> returns a data frame with entries for
observed richness and each of the indices for each class in
<code>pool</code> vector.  The utility function <code>specpool2vect</code> maps
the pooled values into a vector giving the value of selected
<code>index</code> for each original site. Function <code>estimateR</code>
returns the estimates and their standard errors for each
site. Functions <code>poolaccum</code> and <code>estimateR</code> return
matrices of permutation results for each richness estimator, the
vector of sample sizes and a table of <code>means</code> of permutations
for each estimator.
</p>


<h3>Note</h3>

<p> The functions are based on assumption that there is a species
pool: The community is closed so that there is a fixed pool size
<code class="reqn">S_P</code>.  In general, the functions give only the lower limit of
species richness: the real richness is <code class="reqn">S &gt;= S_P</code>, and there is
a consistent bias in the estimates. Even the bias-correction in Chao
only reduces the bias, but does not remove it completely (Chiu et
al. 2014).
</p>
<p>Optional small sample correction was added to <code>specpool</code> in
<span class="pkg">vegan</span> 2.2-0. It was not used in the older literature (Chao
1987), but it is recommended recently (Chiu et al. 2014).
</p>


<h3>Author(s)</h3>

<p>Bob O'Hara (<code>estimateR</code>) and Jari Oksanen.</p>


<h3>References</h3>

<p>Chao, A. (1987). Estimating the population size for capture-recapture
data with unequal catchability. <em>Biometrics</em> 43, 783&ndash;791.
</p>
<p>Chiu, C.H., Wang, Y.T., Walther, B.A. &amp; Chao, A. (2014). Improved
nonparametric lower bound of species richness via a modified
Good-Turing frequency formula. <em>Biometrics</em> 70, 671&ndash;682.
</p>
<p>Colwell, R.K. &amp; Coddington, J.A. (1994). Estimating terrestrial
biodiversity through
extrapolation. <em>Phil. Trans. Roy. Soc. London</em> B 345, 101&ndash;118.
</p>
<p>O'Hara, R.B. (2005). Species richness estimators: how many species
can dance on the head of a pin? <em>J. Anim. Ecol.</em> 74, 375&ndash;386.
</p>
<p>Palmer, M.W. (1990). The estimation of species richness by
extrapolation. <em>Ecology</em> 71, 1195&ndash;1198.
</p>
<p>Smith, E.P &amp; van Belle, G. (1984). Nonparametric estimation of
species richness. <em>Biometrics</em> 40, 119&ndash;129.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+veiledspec">veiledspec</a></code>, <code><a href="#topic+diversity">diversity</a></code>, <code><a href="#topic+beals">beals</a></code>,
<code><a href="#topic+specaccum">specaccum</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
pool &lt;- with(dune.env, specpool(dune, Management))
pool
op &lt;- par(mfrow=c(1,2))
boxplot(specnumber(dune) ~ Management, data = dune.env,
        col = "hotpink", border = "cyan3")
boxplot(specnumber(dune)/specpool2vect(pool) ~ Management,
        data = dune.env, col = "hotpink", border = "cyan3")
par(op)
data(BCI)
## Accumulation model
pool &lt;- poolaccum(BCI)
summary(pool, display = "chao")
plot(pool)
## Quantitative model
estimateR(BCI[1:5,])
</code></pre>

<hr>
<h2 id='sppscores'>
Add or Replace Species Scores in Distance-Based Ordination
</h2><span id='topic+sppscores'></span><span id='topic+sppscores+3C-'></span><span id='topic+sppscores+3C-.dbrda'></span><span id='topic+sppscores+3C-.capscale'></span><span id='topic+sppscores+3C-.metaMDS'></span>

<h3>Description</h3>

<p>Distance-based ordination (<code><a href="#topic+dbrda">dbrda</a></code>,
<code><a href="#topic+capscale">capscale</a></code>, <code><a href="#topic+metaMDS">metaMDS</a></code>) have no information
on species, but some methods may add species scores if community
data were available. However, the species scores may be missing (and
they always are in <code><a href="#topic+dbrda">dbrda</a></code>), or they may not have a
close relation to used dissimilarity index. This function will add
the species scores or replace the existing species scores in
distance-based methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sppscores(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sppscores_+3A_object">object</code></td>
<td>
<p>Ordination result.</p>
</td></tr>
<tr><td><code id="sppscores_+3A_value">value</code></td>
<td>
<p>Community data to find the species scores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Distances have no information on species (columns, variables), and
hence distance-based ordination has no information on species
scores. However, the species scores can be added as supplementary
information after the analysis to help the interpretation of
results. Some ordination methods (<code><a href="#topic+capscale">capscale</a></code>,
<code><a href="#topic+metaMDS">metaMDS</a></code>) can supplement the species scores during the
analysis if community data was available in the analysis.
</p>
<p>In <code><a href="#topic+capscale">capscale</a></code> the species scores are found by projecting
the community data to site ordination (linear combination scores),
and the scores are accurate if the analysis used Euclidean
distances. If the dissimilarity index can be expressed as Euclidean
distances of transformed data (for instance, Chord and Hellinger
Distances), the species scores based on transformed data will be
accurate, but the function still finds the dissimilarities with
untransformed data. Usually community dissimilarities differ in two
significant ways from Euclidean distances: They are bound to maximum
1, and they use absolute differences instead of squared
differences. In such cases, it may be better to use species scores
that are transformed so that their Euclidean distances have a good
linear relation to used dissimilarities. It is often useful to
standardize data so that each row has unit total, and perform
squareroot transformation to damp down the effect of squared
differences (see Examples).
</p>
<p>Function <code><a href="#topic+dbrda">dbrda</a></code> never finds the species scores, but it
is mathematically similar to <code><a href="#topic+capscale">capscale</a></code>, and similar
rules should be followed when supplementing the species scores.
</p>
<p>Function <code><a href="#topic+metaMDS">metaMDS</a></code> uses weighted averages
(<code><a href="#topic+wascores">wascores</a></code>) to find the species scores. These have a
better relationship with most dissimilarities than the projection
scores used in metric ordination, but similar transformation of the
community data should be used both in dissimilarities and in species
scores.
</p>


<h3>Value</h3>

<p>Replacement function adds the species scores or replaces the old
scores in the ordination object.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen
</p>


<h3>See Also</h3>

<p>Function <code><a href="#topic+envfit">envfit</a></code> finds similar scores, but based on
correlations. The species scores for non-metric ordination use
<code><a href="#topic+wascores">wascores</a></code> which can also used directly on any
ordination result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI, BCI.env)
mod &lt;- dbrda(vegdist(BCI) ~ Habitat, BCI.env)
## add species scores
sppscores(mod) &lt;- BCI
## Euclidean distances of BCI differ from used dissimilarity
plot(vegdist(BCI), dist(BCI))
## more linear relationship
plot(vegdist(BCI), dist(sqrt(decostand(BCI, "total"))))
## better species scores
sppscores(mod) &lt;- sqrt(decostand(BCI, "total"))
</code></pre>

<hr>
<h2 id='SSarrhenius'>
Self-Starting nls Species-Area Models
</h2><span id='topic+SSarrhenius'></span><span id='topic+SSlomolino'></span><span id='topic+SSgitay'></span><span id='topic+SSgleason'></span>

<h3>Description</h3>

<p>These functions provide self-starting species-area models for
non-linear regression (<code><a href="stats.html#topic+nls">nls</a></code>). They can also be used for
fitting species accumulation models in
<code><a href="#topic+fitspecaccum">fitspecaccum</a></code>. These models (and many more) are reviewed
by Dengler (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SSarrhenius(area, k, z)
SSgleason(area, k, slope)
SSgitay(area, k, slope)
SSlomolino(area, Asym, xmid, slope)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSarrhenius_+3A_area">area</code></td>
<td>

<p>Area or size of the sample: the independent variable.
</p>
</td></tr>
<tr><td><code id="SSarrhenius_+3A_k">k</code>, <code id="SSarrhenius_+3A_z">z</code>, <code id="SSarrhenius_+3A_slope">slope</code>, <code id="SSarrhenius_+3A_asym">Asym</code>, <code id="SSarrhenius_+3A_xmid">xmid</code></td>
<td>

<p>Estimated model parameters: see Details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All these functions are assumed to be used for species richness
(number of species) as the independent variable, and area or sample
size as the independent variable. Basically, these define least
squares models of untransformed data, and will differ from models
for transformed species richness or models with non-Gaussian error.
</p>
<p>The Arrhenius model (<code>SSarrhenius</code>) is the expression
<code>k*area^z</code>. This is the most classical model that can be found in
any textbook of ecology (and also in Dengler 2009). Parameter <code>z</code>
is the steepness of the species-area curve, and <code>k</code> is the
expected number of species in a unit area.
</p>
<p>The Gleason model (<code>SSgleason</code>) is a linear expression 
<code>k + slope*log(area)</code> (Dengler 200). This is a linear model,  
and starting values give the final estimates; it is provided to 
ease comparison with other models.
</p>
<p>The Gitay model (<code>SSgitay</code>) is a quadratic logarithmic expression
<code>(k + slope*log(area))^2</code> (Gitay et al. 1991, Dengler
2009). Parameter <code>slope</code> is the steepness of the species-area
curve, and <code>k</code> is the square root of expected richness in a unit
area. 
</p>
<p>The Lomolino model (<code>SSlomolino</code>) is
<code>Asym/(1 + slope^log(xmid/area))</code> (Lomolino 2000, Dengler 2009).
Parameter <code>Asym</code> is the asymptotic maximum number of species,
<code>slope</code> is the maximum slope of increase of richness, and
<code>xmid</code> is the  area where half of the maximum richness is
achieved. 
</p>
<p>In addition to these models, several other models studied by Dengler
(2009) are available in standard <span class="rlang"><b>R</b></span> self-starting models:
Michaelis-Menten (<code><a href="stats.html#topic+SSmicmen">SSmicmen</a></code>), Gompertz
(<code><a href="stats.html#topic+SSgompertz">SSgompertz</a></code>), logistic (<code><a href="stats.html#topic+SSlogis">SSlogis</a></code>), Weibull
(<code><a href="stats.html#topic+SSweibull">SSweibull</a></code>), and some others that may be useful.
</p>


<h3>Value</h3>

<p>Numeric vector of the same length as <code>area</code>. It is the value of
the expression of each model. If all arguments are names of objects
the gradient matrix with respect to these names is attached as an
attribute named <code>gradient</code>. 
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen.
</p>


<h3>References</h3>

<p>Dengler, J. (2009) Which function describes the species-area
relationship best? A review and empirical evaluation. <em>Journal of
Biogeography</em> 36, 728&ndash;744.
</p>
<p>Gitay, H., Roxburgh, S.H. &amp; Wilson, J.B. (1991) Species-area
relationship in a New Zealand tussock grassland, with implications for
nature reserve design and for community structure. <em>Journal of
Vegetation Science</em> 2, 113&ndash;118.
</p>
<p>Lomolino, M. V. (2000) Ecology's most general, yet protean pattern:
the species-area relationship. <em>Journal of Biogeography</em> 27,
17&ndash;26. 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nls">nls</a></code>, <code><a href="#topic+fitspecaccum">fitspecaccum</a></code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Get species area data: sipoo.map gives the areas of islands
data(sipoo, sipoo.map)
S &lt;- specnumber(sipoo)
plot(S ~ area, sipoo.map,  xlab = "Island Area (ha)",
  ylab = "Number of Species", ylim = c(1, max(S)))
## The Arrhenius model
marr &lt;- nls(S ~ SSarrhenius(area, k, z), data=sipoo.map)
marr
## confidence limits from profile likelihood
confint(marr)
## draw a line
xtmp &lt;- with(sipoo.map, seq(min(area), max(area), len=51))
lines(xtmp, predict(marr, newdata=data.frame(area = xtmp)), lwd=2)
## The normal way is to use linear regression on log-log data,
## but this will be different from the previous:
mloglog &lt;- lm(log(S) ~ log(area), data=sipoo.map)
mloglog
lines(xtmp, exp(predict(mloglog, newdata=data.frame(area=xtmp))),
   lty=2)
## Gleason: log-linear
mgle &lt;- nls(S ~ SSgleason(area, k, slope), sipoo.map)
lines(xtmp, predict(mgle, newdata=data.frame(area=xtmp)),
  lwd=2, col=2)
## Gitay: quadratic of log-linear
mgit &lt;- nls(S ~ SSgitay(area, k, slope), sipoo.map)
lines(xtmp, predict(mgit, newdata=data.frame(area=xtmp)),
  lwd=2, col = 3)
## Lomolino: using original names of the parameters (Lomolino 2000):
mlom &lt;- nls(S ~ SSlomolino(area, Smax, A50, Hill), sipoo.map)
mlom
lines(xtmp, predict(mlom, newdata=data.frame(area=xtmp)),
  lwd=2, col = 4)
## One canned model of standard R:
mmic &lt;- nls(S ~ SSmicmen(area, slope, Asym), sipoo.map)
lines(xtmp, predict(mmic, newdata = data.frame(area=xtmp)),
  lwd =2, col = 5)
legend("bottomright", c("Arrhenius", "log-log linear", "Gleason", "Gitay", 
  "Lomolino", "Michaelis-Menten"), col=c(1,1,2,3,4,5), lwd=c(2,1,2,2,2,2), 
   lty=c(1,2,1,1,1,1))
## compare models (AIC)
allmods &lt;- list(Arrhenius = marr, Gleason = mgle, Gitay = mgit, 
   Lomolino = mlom, MicMen= mmic)
sapply(allmods, AIC)
</code></pre>

<hr>
<h2 id='stepacross'>Stepacross as Flexible Shortest Paths or Extended Dissimilarities </h2><span id='topic+stepacross'></span>

<h3>Description</h3>

<p>Function <code>stepacross</code> tries to replace dissimilarities with
shortest paths stepping across intermediate 
sites while regarding dissimilarities above a threshold as missing
data (<code>NA</code>). With <code>path = "shortest"</code> this is the flexible shortest
path (Williamson 1978, Bradfield &amp; Kenkel 1987),
and with <code>path = "extended"</code> an
approximation known as extended dissimilarities (De'ath 1999).
The use of <code>stepacross</code> should improve the ordination with high
beta diversity, when there are many sites with no species in common.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepacross(dis, path = "shortest", toolong = 1, trace = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepacross_+3A_dis">dis</code></td>
<td>
<p>Dissimilarity data inheriting from class <code>dist</code> or
a an object, such as a matrix, that can be converted to a
dissimilarity matrix. Functions <code><a href="#topic+vegdist">vegdist</a></code> and
<code><a href="stats.html#topic+dist">dist</a></code> are some functions producing suitable
dissimilarity data. </p>
</td></tr>
<tr><td><code id="stepacross_+3A_path">path</code></td>
<td>
<p>The method of stepping across (partial match)
Alternative <code>"shortest"</code> finds the shortest paths, and
<code>"extended"</code>  their approximation known as extended
dissimilarities.</p>
</td></tr> 
<tr><td><code id="stepacross_+3A_toolong">toolong</code></td>
<td>
<p>Shortest dissimilarity regarded as <code>NA</code>.
The function uses a fuzz factor, so
that dissimilarities close to the limit will be made <code>NA</code>, too. </p>
</td></tr>
<tr><td><code id="stepacross_+3A_trace">trace</code></td>
<td>
<p> Trace the calculations.</p>
</td></tr>
<tr><td><code id="stepacross_+3A_...">...</code></td>
<td>
<p>Other parameters (ignored).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Williamson (1978) suggested using flexible shortest paths to estimate
dissimilarities between sites which have nothing in common, or no shared
species. With <code>path = "shortest"</code> function <code>stepacross</code>
replaces dissimilarities that are
<code>toolong</code> or longer with <code>NA</code>, and tries to find shortest
paths between all sites using remaining dissimilarities. Several
dissimilarity indices are semi-metric which means that they do not
obey the triangle inequality <code class="reqn">d_{ij} \leq d_{ik} + d_{kj}</code>, and shortest path algorithm can replace these
dissimilarities as well, even when they are shorter than
<code>toolong</code>. 
</p>
<p>De'ath (1999) suggested a simplified method known as extended
dissimilarities, which are calculated with <code>path = "extended"</code>. 
In this method, dissimilarities that are
<code>toolong</code> or longer are first made <code>NA</code>, and then the function
tries to replace these <code>NA</code> dissimilarities with a path through
single stepping stone points. If not all <code>NA</code> could be 
replaced with one pass, the function will make new passes with updated
dissimilarities as long as
all <code>NA</code> are replaced with extended dissimilarities. This mean
that in the second and further passes, the remaining <code>NA</code>
dissimilarities are allowed to have more than one stepping stone site,
but previously replaced dissimilarities are not updated. Further, the
function does not consider dissimilarities shorter than <code>toolong</code>,
although some of these could be replaced with a shorter path in
semi-metric indices, and used as a part of other paths. In optimal
cases, the extended dissimilarities are equal to shortest paths, but
they may be longer.  
</p>
<p>As an alternative to defining too long dissimilarities with parameter
<code>toolong</code>, the input dissimilarities can contain <code>NA</code>s. If
<code>toolong</code> is zero or negative, the function does not make any
dissimilarities into <code>NA</code>. If there are no <code>NA</code>s in the
input  and <code>toolong = 0</code>, <code>path = "shortest"</code>
will find shorter paths for semi-metric indices, and <code>path = "extended"</code> 
will do nothing. Function <code><a href="#topic+no.shared">no.shared</a></code> can be
used to set dissimilarities to <code>NA</code>.
</p>
<p>If the data are disconnected or there is no path between all points,
the result will
contain <code>NA</code>s and a warning is issued. Several methods cannot
handle <code>NA</code> dissimilarities, and this warning should be taken
seriously. Function <code><a href="#topic+distconnected">distconnected</a></code> can be used to find
connected groups and remove rare outlier observations or groups of
observations.
</p>
<p>Alternative <code>path = "shortest"</code> uses Dijkstra's method for
finding flexible shortest paths, implemented as priority-first search
for dense graphs (Sedgewick 1990). Alternative <code>path = "extended"</code> 
follows De'ath (1999), but implementation is simpler
than in his code.
</p>


<h3>Value</h3>

<p>Function returns an object of class <code>dist</code> with extended
dissimilarities (see functions <code><a href="#topic+vegdist">vegdist</a></code> and
<code><a href="stats.html#topic+dist">dist</a></code>). 
The value of <code>path</code> is appended to the <code>method</code> attribute.
</p>


<h3>Note</h3>

<p>The function changes the original dissimilarities, and not all
like this. It may be best to  use  the
function only when you really <em>must</em>:  extremely high
beta diversity where a large proportion of dissimilarities are at their
upper limit (no species in common). 
</p>
<p>Semi-metric indices vary in their degree of violating the triangle
inequality. Morisita and Horn&ndash;Morisita indices of
<code><a href="#topic+vegdist">vegdist</a></code> may be very strongly semi-metric, and shortest
paths can change these indices very much. Mountford index violates
basic rules of dissimilarities: non-identical sites have zero
dissimilarity if species composition of the poorer site is a subset of
the richer. With Mountford index, you can find three sites <code class="reqn">i, j,
    k</code> so that <code class="reqn">d_{ik} = 0</code> and <code class="reqn">d_{jk} = 0</code>, but <code class="reqn">d_{ij} &gt; 0</code>. The results of <code>stepacross</code>
on Mountford index can be very weird. If <code>stepacross</code> is needed,
it is best to try to use it with more metric indices only.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen</p>


<h3>References</h3>

<p>Bradfield, G.E. &amp; Kenkel, N.C. (1987). Nonlinear ordination using
flexible shortest path adjustment of ecological
distances. <em>Ecology</em> 68, 750&ndash;753.
</p>
<p>De'ath, G. (1999). Extended dissimilarity: a method of robust
estimation of ecological distances from high beta diversity
data. <em>Plant Ecol.</em> 144, 191&ndash;199.
</p>
<p>Sedgewick, R. (1990). <em>Algorithms in C</em>. Addison Wesley. 
</p>
<p>Williamson, M.H. (1978). The ordination of incidence
data. <em>J. Ecol.</em> 66, 911-920.
</p>


<h3>See Also</h3>

<p>Function <code><a href="#topic+distconnected">distconnected</a></code> can find connected groups in
disconnected data, and function <code><a href="#topic+no.shared">no.shared</a></code> can be used to
set dissimilarities as <code>NA</code>.  See <code><a href="#topic+swan">swan</a></code> for an
alternative approach. Function <code>stepacross</code> is an essential
component in <code><a href="#topic+isomap">isomap</a></code> and <code><a href="#topic+cophenetic.spantree">cophenetic.spantree</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># There are no data sets with high beta diversity in vegan, but this
# should give an idea.
data(dune)
dis &lt;- vegdist(dune)
edis &lt;- stepacross(dis)
plot(edis, dis, xlab = "Shortest path", ylab = "Original")
## Manhattan distance have no fixed upper limit.
dis &lt;- vegdist(dune, "manhattan")
is.na(dis) &lt;- no.shared(dune)
dis &lt;- stepacross(dis, toolong=0)
</code></pre>

<hr>
<h2 id='stressplot.wcmdscale'>
Display Ordination Distances Against Observed Distances in Eigenvector Ordinations
</h2><span id='topic+stressplot.wcmdscale'></span><span id='topic+stressplot.cca'></span><span id='topic+stressplot.rda'></span><span id='topic+stressplot.capscale'></span><span id='topic+stressplot.dbrda'></span><span id='topic+stressplot.prcomp'></span><span id='topic+stressplot.princomp'></span>

<h3>Description</h3>

<p>Functions plot ordination distances in given number of dimensions
against observed distances or distances in full space in eigenvector
methods. The display is similar as the Shepard diagram
(<code><a href="#topic+stressplot">stressplot</a></code> for non-metric multidimensional scaling
with <code><a href="#topic+metaMDS">metaMDS</a></code> or <code><a href="#topic+monoMDS">monoMDS</a></code>), but shows the
linear relationship of the eigenvector ordinations. The
<code>stressplot</code> methods are available for <code><a href="#topic+wcmdscale">wcmdscale</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+capscale">capscale</a></code>,
<code><a href="#topic+dbrda">dbrda</a></code>, <code><a href="stats.html#topic+prcomp">prcomp</a></code> and <code><a href="stats.html#topic+princomp">princomp</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'wcmdscale'
stressplot(object, k = 2, pch, p.col = "blue", l.col = "red",
    lwd = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stressplot.wcmdscale_+3A_object">object</code></td>
<td>

<p>Result object from eigenvector ordination (<code><a href="#topic+wcmdscale">wcmdscale</a></code>,
<code><a href="#topic+rda">rda</a></code>, <code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+capscale">capscale</a></code>)
</p>
</td></tr>
<tr><td><code id="stressplot.wcmdscale_+3A_k">k</code></td>
<td>

<p>Number of dimensions for which the ordination distances are displayed.
</p>
</td></tr>
<tr><td><code id="stressplot.wcmdscale_+3A_pch">pch</code>, <code id="stressplot.wcmdscale_+3A_p.col">p.col</code>, <code id="stressplot.wcmdscale_+3A_l.col">l.col</code>, <code id="stressplot.wcmdscale_+3A_lwd">lwd</code></td>
<td>

<p>Plotting character, point colour and line colour like in
default <code><a href="#topic+stressplot">stressplot</a></code>
</p>
</td></tr>
<tr><td><code id="stressplot.wcmdscale_+3A_...">...</code></td>
<td>

<p>Other parameters to functions, e.g. graphical parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The functions offer a similar display for eigenvector
ordinations as the standard Shepard diagram (<code><a href="#topic+stressplot">stressplot</a></code>)
in non-metric multidimensional scaling. The ordination distances in
given number of dimensions are plotted against observed
distances. With metric distances, the ordination distances in full
space (with all ordination axes) are equal to observed distances, and
the fit line shows this equality. In general, the fit line does not go
through the points, but the points for observed distances approach the
fit line from below. However, with non-Euclidean distances (in
<code><a href="#topic+wcmdscale">wcmdscale</a></code> or <code><a href="#topic+capscale">capscale</a></code>) with negative
eigenvalues the ordination distances can exceed the observed distances
in real dimensions; the imaginary dimensions with negative eigenvalues
will correct these excess distances. If you have used
<code><a href="#topic+capscale">capscale</a></code> or <code><a href="#topic+wcmdscale">wcmdscale</a></code> with argument
<code>add</code> to avoid negative eigenvalues, the ordination distances
will exceed the observed dissimilarities.
</p>
<p>In partial ordination (<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+rda">rda</a></code> and
<code><a href="#topic+capscale">capscale</a></code> with <code>Condition</code> in the formula), the
distances in the partial component are included both in the observed
distances and in ordination distances.  With <code>k=0</code>, the
ordination distances refer to the partial ordination.
</p>


<h3>Value</h3>

<p>Functions draw a graph and return invisibly the ordination distances
or the ordination distances.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stressplot">stressplot</a></code> and <code><a href="#topic+stressplot.monoMDS">stressplot.monoMDS</a></code> for
standard Shepard diagrams.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune, dune.env)
mod &lt;- rda(dune)
stressplot(mod)
mod &lt;- rda(dune ~ Management, dune.env)
stressplot(mod, k=3)
</code></pre>

<hr>
<h2 id='taxondive'> Indices of Taxonomic Diversity and Distinctness </h2><span id='topic+taxondive'></span><span id='topic+summary.taxondive'></span><span id='topic+plot.taxondive'></span><span id='topic+taxa2dist'></span>

<h3>Description</h3>

<p>Function finds indices of taxonomic diversity and distinctness,
which are averaged taxonomic distances among species or individuals in
the community (Clarke &amp; Warwick 1998, 2001)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taxondive(comm, dis, match.force = FALSE)
taxa2dist(x, varstep = FALSE, check = TRUE, labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="taxondive_+3A_comm">comm</code></td>
<td>
<p>Community data. </p>
</td></tr>
<tr><td><code id="taxondive_+3A_dis">dis</code></td>
<td>
<p>Taxonomic distances among taxa in <code>comm</code>. This should
be a <code><a href="stats.html#topic+dist">dist</a></code> object or a symmetric square matrix. </p>
</td></tr>
<tr><td><code id="taxondive_+3A_match.force">match.force</code></td>
<td>
<p>Force matching of column names in <code>comm</code> and
labels in <code>dis</code>. If <code>FALSE</code>, matching only happens when
dimensions differ, and in that case the species must be in identical
order in both.</p>
</td></tr>
<tr><td><code id="taxondive_+3A_x">x</code></td>
<td>
<p>Classification table with a row for each species or other
basic taxon, and columns
for identifiers of its classification at higher levels.</p>
</td></tr>
<tr><td><code id="taxondive_+3A_varstep">varstep</code></td>
<td>
<p>Vary step lengths between successive levels
relative to proportional loss of the number of distinct classes.</p>
</td></tr>
<tr><td><code id="taxondive_+3A_check">check</code></td>
<td>
<p>If <code>TRUE</code>, remove all redundant levels which are
different for all rows or constant for all rows and regard each row
as a different basal taxon (species). If <code>FALSE</code> all
levels are retained and basal taxa (species) also must be coded as
variables (columns). You will get a warning if species are not
coded, but you can ignore this if that was your intention.</p>
</td></tr>
<tr><td><code id="taxondive_+3A_labels">labels</code></td>
<td>
<p>The <code>labels</code> attribute of taxonomic distances. Row
names will be used if this is not given. Species will be matched by
these labels in <code>comm</code> and <code>dis</code> in <code>taxondive</code> if
these have different dimensions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Clarke &amp; Warwick (1998, 2001) suggested several alternative indices of
taxonomic diversity or distinctness. Two basic indices are called
taxonomic diversity (<code class="reqn">\Delta</code>) and distinctness (<code class="reqn">\Delta^*</code>):
</p>

<table>
<tr>
 <td style="text-align: center;">
    <code class="reqn">\Delta = (\sum \sum_{i&lt;j} \omega_{ij} x_i x_j)/(n (n-1) / 2)</code> </td>
</tr>
<tr>
 <td style="text-align: center;">
    <code class="reqn">\Delta^* = (\sum \sum_{i&lt;j} \omega_{ij} x_i x_j)/(\sum \sum_{i&lt;j} x_i x_j) </code>
  </td>
</tr>

</table>

<p>The equations give the index value for a single site, and summation
goes over species <code class="reqn">i</code> and <code class="reqn">j</code>. Here <code class="reqn">\omega</code> are taxonomic
distances among taxa, and <code class="reqn">x</code> are species abundances, and <code class="reqn">n</code>
is the total abundance for a site. 
With presence/absence  data both indices reduce to the same index
<code class="reqn">\Delta^+</code>, and for this index Clarke &amp; Warwick (1998) also have
an estimate of its standard deviation. Clarke &amp; Warwick (2001) 
presented two new indices: <code class="reqn">s\Delta^+</code> is the product of species
richness and <code class="reqn">\Delta^+</code>, and index of variation in
taxonomic distinctness (<code class="reqn">\Lambda^+</code>) defined as
</p>

<table>
<tr>
 <td style="text-align: center;">
    <code class="reqn">\Lambda^+ = (\sum \sum_{i&lt;j} \omega_{ij}^2)/(n (n-1) / 2) - (\Delta^+)^2</code>
  </td>
</tr>

</table>

<p>The <code>dis</code> argument must be species dissimilarities. These must be
similar to dissimilarities produced by <code><a href="stats.html#topic+dist">dist</a></code>. It is
customary to have integer steps of taxonomic hierarchies, but other
kind of dissimilarities can be used, such as those from phylogenetic
trees or genetic differences.  Further, the <code>dis</code> need not be
taxonomic, but other species classifications can be used. 
</p>
<p>Function <code>taxa2dist</code> can produce a suitable <code>dist</code> object
from a classification table. Each species (or basic taxon) corresponds
to a row of the classification table, and columns give the
classification at different levels. With <code>varstep = FALSE</code> the
successive levels will be separated by equal steps, and with
<code>varstep = TRUE</code> the step length is relative to the proportional
decrease in the number of classes (Clarke &amp; Warwick 1999).
With <code>check = TRUE</code>, the function removes classes which are distinct for all
species or which combine all species into one class, and assumes that
each row presents a distinct basic taxon. The function scales
the distances so that longest path length between
taxa is 100 (not necessarily when <code>check = FALSE</code>). 
</p>
<p>Function <code>plot.taxondive</code> plots <code class="reqn">\Delta^+</code> against Number of
species, together with expectation and its approximate 2*sd
limits. Function <code>summary.taxondive</code> finds the <code class="reqn">z</code> values and
their significances from Normal distribution for <code class="reqn">\Delta^+</code>.
</p>


<h3>Value</h3>

<p>Function returns an object of class <code>taxondive</code> with following items:
</p>
<table>
<tr><td><code>Species</code></td>
<td>
<p>Number of species for each site.</p>
</td></tr>
<tr><td><code>D</code>, <code>Dstar</code>, <code>Dplus</code>, <code>SDplus</code>, <code>Lambda</code></td>
<td>
<p><code class="reqn">\Delta</code>, <code class="reqn">\Delta^*</code>,
<code class="reqn">\Delta^+</code>,  <code class="reqn">s\Delta^+</code> and <code class="reqn">\Lambda^+</code> 
for each site.</p>
</td></tr>
<tr><td><code>sd.Dplus</code></td>
<td>
<p>Standard deviation of <code class="reqn">\Delta^+</code>.</p>
</td></tr>
<tr><td><code>ED</code>, <code>EDstar</code>, <code>EDplus</code></td>
<td>
<p>Expected values of corresponding
statistics.</p>
</td></tr>
</table>
<p>Function <code>taxa2dist</code> returns an object of class <code>"dist"</code>, with
an attribute <code>"steps"</code> for the step lengths between successive levels.
</p>


<h3>Note</h3>

<p>The function is still preliminary and may change. The scaling of
taxonomic dissimilarities influences the results. If you multiply
taxonomic distances (or step lengths) by a constant, the values of all
Deltas will be multiplied with the same constant, and the value of
<code class="reqn">\Lambda^+</code> by the square of the constant.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>References</h3>

<p>Clarke, K.R &amp; Warwick, R.M. (1998) A taxonomic distinctness index and
its statistical properties. <em>Journal of Applied Ecology</em> 35,
523&ndash;531.
</p>
<p>Clarke, K.R. &amp; Warwick, R.M. (1999) The taxonomic distinctness measure
of biodiversity: weighting of step lengths between hierarchical
levels. <em>Marine Ecology Progress Series</em> 184: 21&ndash;29.
</p>
<p>Clarke, K.R. &amp; Warwick, R.M. (2001) A further biodiversity index
applicable to species lists: variation in taxonomic
distinctness. <em>Marine Ecology Progress Series</em> 216, 265&ndash;278.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diversity">diversity</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Preliminary: needs better data and some support functions
data(dune)
data(dune.taxon)
# Taxonomic distances from a classification table with variable step lengths.
taxdis &lt;- taxa2dist(dune.taxon, varstep=TRUE)
plot(hclust(taxdis), hang = -1)
# Indices
mod &lt;- taxondive(dune, taxdis)
mod
summary(mod)
plot(mod)
</code></pre>

<hr>
<h2 id='tolerance'>Species tolerances and sample heterogeneities</h2><span id='topic+tolerance'></span><span id='topic+tolerance.cca'></span><span id='topic+tolerance.decorana'></span>

<h3>Description</h3>

<p>Species tolerances and sample heterogeneities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tolerance(x, ...)

## S3 method for class 'cca'
tolerance(x, choices = 1:2, which = c("species","sites"),
          scaling = "species", useN2 = TRUE, hill = FALSE, ...)

## S3 method for class 'decorana'
tolerance(x, data, choices = 1:4,
          which = c("sites", "species"), useN2 = TRUE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tolerance_+3A_x">x</code></td>
<td>
<p>object of class <code>"cca"</code>.</p>
</td></tr>
<tr><td><code id="tolerance_+3A_choices">choices</code></td>
<td>
<p>numeric; which ordination axes to compute
tolerances and heterogeneities for. Defaults to axes 1 and 2.</p>
</td></tr>
<tr><td><code id="tolerance_+3A_which">which</code></td>
<td>
<p>character; one of <code>"species"</code> or <code>"sites"</code>,
indicating whether species tolerances or sample heterogeneities
respectively are computed.</p>
</td></tr>
<tr><td><code id="tolerance_+3A_scaling">scaling</code></td>
<td>
<p>character or numeric; the ordination scaling to
use. See <code><a href="#topic+scores.cca">scores.cca</a></code> for details.</p>
</td></tr>
<tr><td><code id="tolerance_+3A_hill">hill</code></td>
<td>
<p>logical; if <code>scaling</code> is a character,
these control whether Hill's scaling is used for (C)CA
respectively. See <code><a href="#topic+scores.cca">scores.cca</a></code> for details.</p>
</td></tr>
<tr><td><code id="tolerance_+3A_usen2">useN2</code></td>
<td>
<p>logical; should the bias in the tolerances /
heterogeneities be reduced via scaling by Hill's N2?</p>
</td></tr>
<tr><td><code id="tolerance_+3A_data">data</code></td>
<td>
<p>Original input data used in <code><a href="#topic+decorana">decorana</a></code>.  If
missing, the function tries to get the same data as used in
<code>decorana</code> call.</p>
</td></tr>
<tr><td><code id="tolerance_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function to compute species tolerances and site heterogeneity measures
from unimodal ordinations (CCA &amp; CA). Implements Eq 6.47 and 6.48 from
the Canoco 4.5 Reference Manual (pages 178&ndash;179).
</p>


<h3>Value</h3>

<p>Matrix of tolerances/heterogeneities with some additional
attributes: <code>which</code>, <code>scaling</code>, and <code>N2</code>, the latter of
which will be <code>NA</code> if <code>useN2 = FALSE</code> or <code>N2</code> could not
be estimated.
</p>


<h3>Author(s)</h3>

<p>Gavin L. Simpson and Jari Oksanen (<code>decorana</code> method).</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dune)
data(dune.env)
mod &lt;- cca(dune ~ ., data = dune.env)

## defaults to species tolerances
tolerance(mod)

## sample heterogeneities for CCA axes 1:6
tolerance(mod, which = "sites", choices = 1:6)
## average should be 1 with scaling = "sites", hill = TRUE
tol &lt;- tolerance(mod, which = "sites", scaling = "sites", hill = TRUE,
   choices = 1:4)
colMeans(tol)
apply(tol, 2, sd)
## Rescaling tries to set all tolerances to 1
tol &lt;- tolerance(decorana(dune))
colMeans(tol)
apply(tol, 2, sd)
</code></pre>

<hr>
<h2 id='treedive'>Functional Diversity and Community Distances from Species Trees</h2><span id='topic+treedive'></span><span id='topic+treeheight'></span><span id='topic+treedist'></span>

<h3>Description</h3>

<p> Functional diversity is defined as the total branch
length in a trait dendrogram connecting all species, but excluding
the unnecessary root segments of the tree (Petchey and Gaston
2006). Tree distance is the increase in total branch length when
combining two sites.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>treedive(comm, tree, match.force = TRUE, verbose = TRUE)
treeheight(tree)
treedist(x, tree, relative = TRUE, match.force = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="treedive_+3A_comm">comm</code>, <code id="treedive_+3A_x">x</code></td>
<td>
<p>Community data frame or matrix.</p>
</td></tr>
<tr><td><code id="treedive_+3A_tree">tree</code></td>
<td>
<p>A dendrogram which for <code>treedive</code> must be for species
(columns).</p>
</td></tr>
<tr><td><code id="treedive_+3A_match.force">match.force</code></td>
<td>
<p>Force matching of column names in data
(<code>comm</code>, <code>x</code>) and labels in <code>tree</code>. If <code>FALSE</code>,
matching only happens when dimensions differ (with a warning or
message). The order of data must match to the order in <code>tree</code>
if matching by names is not done.</p>
</td></tr>
<tr><td><code id="treedive_+3A_verbose">verbose</code></td>
<td>
<p>Print diagnostic messages and warnings.</p>
</td></tr>
<tr><td><code id="treedive_+3A_relative">relative</code></td>
<td>
<p>Use distances relative to the height of combined tree.</p>
</td></tr>
<tr><td><code id="treedive_+3A_...">...</code></td>
<td>
<p>Other arguments passed to functions (ignored).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>treeheight</code> finds the sum of lengths of connecting
segments in a dendrogram produced by <code><a href="stats.html#topic+hclust">hclust</a></code>, or other
dendrogram that can be coerced to a correct type using
<code><a href="stats.html#topic+as.hclust">as.hclust</a></code>. When applied to a clustering of species
traits, this is a measure of functional diversity (Petchey and Gaston
2002, 2006), and when applied to phylogenetic trees this is
phylogenetic diversity.
</p>
<p>Function <code>treedive</code> finds the <code>treeheight</code> for each site
(row) of a community matrix. The function uses a subset of
dendrogram for those species that occur in each site, and excludes
the tree root if that is not needed to connect the species (Petchey
and Gaston 2006). The subset of the dendrogram is found by first
calculating <code><a href="stats.html#topic+cophenetic">cophenetic</a></code> distances from the input
dendrogram, then reconstructing the dendrogram for the subset of the
cophenetic distance matrix for species occurring in each
site. Diversity is 0 for one species, and <code>NA</code> for empty
communities.
</p>
<p>Function <code>treedist</code> finds the dissimilarities among
trees. Pairwise dissimilarity of two trees is found by combining
species in a common tree and seeing how much of the tree height is
shared and how much is unique. With <code>relative = FALSE</code> the
dissimilarity is defined as <code class="reqn">2 (A \cup B) - A - B</code>, where
<code class="reqn">A</code> and <code class="reqn">B</code> are heights of component trees and
<code class="reqn">A \cup B</code> is the height of the combined tree. With <code>relative = TRUE</code>
the dissimilarity is <code class="reqn">(2(A \cup B)-A-B)/(A \cup B)</code>. 
Although the latter formula is similar to
Jaccard dissimilarity (see <code><a href="#topic+vegdist">vegdist</a></code>,
<code><a href="#topic+designdist">designdist</a></code>), it is not in the range <code class="reqn">0 \ldots 1</code>, since combined tree can add a new root. When two zero-height
trees are combined into a tree of above zero height, the relative
index attains its maximum value <code class="reqn">2</code>. The dissimilarity is zero
from a combined zero-height tree.
</p>
<p>The functions need a dendrogram of species traits or phylogenies as an
input. If species traits contain <code><a href="base.html#topic+factor">factor</a></code> or
<code><a href="base.html#topic+ordered">ordered</a></code> factor variables, it is recommended to use Gower
distances for mixed data (function <code><a href="cluster.html#topic+daisy">daisy</a></code> in
package <span class="pkg">cluster</span>), and usually the recommended clustering method
is UPGMA (<code>method = "average"</code> in function <code><a href="stats.html#topic+hclust">hclust</a></code>)
(Podani and Schmera 2006). Phylogenetic trees can be changed into
dendrograms using function <code>as.hclust.phylo</code> in the
<span class="pkg">ape</span> package.
</p>
<p>It is possible to analyse the non-randomness of tree diversity
using <code><a href="#topic+oecosimu">oecosimu</a></code>. This needs specifying an adequate Null
model, and the results will change with this choice.
</p>


<h3>Value</h3>

 
<p>A vector of diversity values or a single tree height, or a
dissimilarity structure that inherits from <code><a href="stats.html#topic+dist">dist</a></code> and
can be used similarly.  
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>References</h3>

<p>Lozupone, C. and Knight, R. 2005. UniFrac: a new phylogenetic method
for comparing microbial communities. <em>Applied and Environmental
Microbiology</em> 71, 8228&ndash;8235.
</p>
<p>Petchey, O.L. and Gaston, K.J. 2002. Functional diversity (FD), species
richness and community composition. <em>Ecology Letters</em> 5,
402&ndash;411.
</p>
<p>Petchey, O.L. and Gaston, K.J. 2006. Functional diversity: back to
basics and looking forward. <em>Ecology Letters</em> 9, 741&ndash;758.
</p>
<p>Podani J. and Schmera, D. 2006. On dendrogram-based methods of
functional diversity. <em>Oikos</em> 115, 179&ndash;185.
</p>


<h3>See Also</h3>

<p>Function <code>treedive</code> is similar to the phylogenetic
diversity function <code>pd</code> in the package <span class="pkg">picante</span>, but
excludes tree root if that is not needed to connect species. Function
<code>treedist</code> is similar to the phylogenetic similarity
<code>phylosor</code> in the package <span class="pkg">picante</span>, but excludes
unneeded tree root and returns distances instead of similarities.
</p>
<p><code><a href="#topic+taxondive">taxondive</a></code> is something very similar from another bubble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## There is no data set on species properties yet, and we demonstrate
## the methods using phylogenetic trees
data(dune)
data(dune.phylodis)
cl &lt;- hclust(dune.phylodis)
treedive(dune, cl)
## Significance test using Null model communities.
## The current choice fixes numbers of species and picks species
## proportionally to their overall frequency
oecosimu(dune, treedive, "r1", tree = cl, verbose = FALSE)
## Phylogenetically ordered community table
dtree &lt;- treedist(dune, cl)
tabasco(dune, hclust(dtree), cl)
## Use tree distances  in capscale
capscale(dtree ~ 1, comm=dune)
</code></pre>

<hr>
<h2 id='tsallis'>Tsallis Diversity and Corresponding Accumulation Curves</h2><span id='topic+tsallis'></span><span id='topic+tsallisaccum'></span><span id='topic+persp.tsallisaccum'></span>

<h3>Description</h3>

<p>Function <code>tsallis</code> find Tsallis diversities with any scale or the corresponding evenness measures. Function <code>tsallisaccum</code> finds these statistics with accumulating sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tsallis(x, scales = seq(0, 2, 0.2), norm = FALSE, hill = FALSE)
tsallisaccum(x, scales = seq(0, 2, 0.2), permutations = 100, 
   raw = FALSE, subset, ...)
## S3 method for class 'tsallisaccum'
persp(x, theta = 220, phi = 15, col = heat.colors(100), zlim, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tsallis_+3A_x">x</code></td>
<td>
<p>Community data matrix or plotting object. </p>
</td></tr>
<tr><td><code id="tsallis_+3A_scales">scales</code></td>
<td>
<p>Scales of Tsallis diversity.</p>
</td></tr>
<tr><td><code id="tsallis_+3A_norm">norm</code></td>
<td>
<p>Logical, if <code>TRUE</code> diversity values are normalized
by their maximum (diversity value at equiprobability conditions).</p>
</td></tr>
<tr><td><code id="tsallis_+3A_hill">hill</code></td>
<td>
<p>Calculate Hill numbers.</p>
</td></tr>
<tr><td><code id="tsallis_+3A_permutations">permutations</code></td>
<td>
<p>Usually an integer giving the number
permutations, but can also be a list of control values for the
permutations as returned by the function <code><a href="permute.html#topic+how">how</a></code>, 
or a permutation matrix where each row gives the permuted indices.</p>
</td></tr>
<tr><td><code id="tsallis_+3A_raw">raw</code></td>
<td>
<p>If <code>FALSE</code> then return summary statistics of
permutations, and if TRUE then returns the individual
permutations.</p>
</td></tr>
<tr><td><code id="tsallis_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating sites (rows) to keep:
missing values are taken as <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="tsallis_+3A_theta">theta</code>, <code id="tsallis_+3A_phi">phi</code></td>
<td>
<p>angles defining the viewing
direction. <code>theta</code> gives the azimuthal direction and
<code>phi</code> the colatitude.</p>
</td></tr>
<tr><td><code id="tsallis_+3A_col">col</code></td>
<td>
<p>Colours used for surface.</p>
</td></tr>  <tr><td><code id="tsallis_+3A_zlim">zlim</code></td>
<td>
<p>Limits of
vertical axis.</p>
</td></tr>  
<tr><td><code id="tsallis_+3A_...">...</code></td>
<td>
<p>Other arguments which are passed to <code>tsallis</code> and
to graphical functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The Tsallis diversity (also equivalent to Patil and Taillie
diversity) is a one-parametric generalised entropy function, defined
as:
</p>
<p style="text-align: center;"><code class="reqn">H_q = \frac{1}{q-1} (1-\sum_{i=1}^S p_i^q)</code>
</p>

<p>where <code class="reqn">q</code> is a scale parameter, <code class="reqn">S</code> the number of species in
the sample (Tsallis 1988, Tothmeresz 1995). This diversity is concave
for all <code class="reqn">q&gt;0</code>, but non-additive (Keylock 2005). For <code class="reqn">q=0</code> it
gives the number of species minus one, as <code class="reqn">q</code> tends to 1 this
gives Shannon diversity, for <code class="reqn">q=2</code> this gives the Simpson index
(see function <code><a href="#topic+diversity">diversity</a></code>).
</p>
<p>If <code>norm = TRUE</code>, <code>tsallis</code> gives values normalized by the
maximum:
</p>
<p style="text-align: center;"><code class="reqn">H_q(max) = \frac{S^{1-q}-1}{1-q}</code>
</p>

<p>where <code class="reqn">S</code> is the number of species. As <code class="reqn">q</code> tends to 1, maximum
is defined as <code class="reqn">ln(S)</code>.
</p>
<p>If <code>hill = TRUE</code>, <code>tsallis</code> gives Hill numbers (numbers
equivalents, see Jost 2007):
</p>
<p style="text-align: center;"><code class="reqn">D_q = (1-(q-1) H)^{1/(1-q)}</code>
</p>

<p>Details on plotting methods and accumulating values can be found on
the help pages of the functions <code><a href="#topic+renyi">renyi</a></code> and
<code><a href="#topic+renyiaccum">renyiaccum</a></code>.  
</p>


<h3>Value</h3>

 
<p>Function <code>tsallis</code> returns a data frame of selected
indices. Function <code>tsallisaccum</code> with argument <code>raw = FALSE</code>
returns a three-dimensional array, where the first dimension are the
accumulated sites, second dimension are the diversity scales, and
third dimension are the summary statistics <code>mean</code>, <code>stdev</code>,
<code>min</code>, <code>max</code>, <code>Qnt 0.025</code> and <code>Qnt 0.975</code>. With
argument <code>raw = TRUE</code> the statistics on the third dimension are
replaced with individual permutation results.  </p>


<h3>Author(s)</h3>

<p>P√©ter S√≥lymos,
<a href="mailto:solymos@ualberta.ca">solymos@ualberta.ca</a>, based on the code of Roeland Kindt and
Jari Oksanen written for <code>renyi</code></p>


<h3>References</h3>

<p>Tsallis, C. (1988) Possible generalization of Boltzmann-Gibbs
statistics.  <em>J. Stat. Phis.</em> 52, 479&ndash;487.
</p>
<p>Tothmeresz, B. (1995) Comparison of different methods for diversity
ordering. <em>Journal of Vegetation Science</em> <b>6</b>, 283&ndash;290.
</p>
<p>Patil, G. P. and Taillie, C. (1982) Diversity as a concept and its
measurement.  <em>J. Am. Stat. Ass.</em> <b>77</b>, 548&ndash;567.
</p>
<p>Keylock, C. J. (2005) Simpson diversity and the Shannon-Wiener index
as special cases of a generalized entropy.  <em>Oikos</em> <b>109</b>,
203&ndash;207.
</p>
<p>Jost, L (2007) Partitioning diversity into independent alpha and beta
components.  <em>Ecology</em> <b>88</b>, 2427&ndash;2439.
</p>


<h3>See Also</h3>

<p> Plotting methods and accumulation routines are based on
functions <code><a href="#topic+renyi">renyi</a></code> and <code><a href="#topic+renyiaccum">renyiaccum</a></code>. An object
of class <code>tsallisaccum</code> can be displayed with dynamic 3D function
<code>rgl.renyiaccum</code> in the <span class="pkg">vegan3d</span> package. See also settings for
<code><a href="graphics.html#topic+persp">persp</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BCI)
i &lt;- sample(nrow(BCI), 12)
x1 &lt;- tsallis(BCI[i,])
x1
diversity(BCI[i,],"simpson") == x1[["2"]]
plot(x1)
x2 &lt;- tsallis(BCI[i,],norm=TRUE)
x2
plot(x2)
mod1 &lt;- tsallisaccum(BCI[i,])
plot(mod1, as.table=TRUE, col = c(1, 2, 2))
persp(mod1)
mod2 &lt;- tsallisaccum(BCI[i,], norm=TRUE)
persp(mod2,theta=100,phi=30)
</code></pre>

<hr>
<h2 id='varespec'>Vegetation and environment in lichen pastures</h2><span id='topic+varechem'></span><span id='topic+varespec'></span>

<h3>Description</h3>

<p>The <code>varespec</code> data frame has 24 rows and 44 columns.  Columns
are estimated cover values of 44 species.  The variable names are
formed from the scientific names, and are self explanatory for anybody
familiar with the vegetation type.
The <code>varechem</code> data frame has 24 rows and 14 columns, giving the
soil characteristics of the very same sites as in the <code>varespec</code>
data frame. The chemical measurements have obvious names.
<code>Baresoil</code> gives the estimated cover of bare soil, <code>Humdepth</code>
the thickness of the humus layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>       data(varechem)
       data(varespec)
</code></pre>


<h3>References</h3>

<p>V√§re, H., Ohtonen, R. and Oksanen, J. (1995) Effects of reindeer
grazing on understorey vegetation in dry Pinus sylvestris
forests. <em>Journal of Vegetation Science</em> 6, 523&ndash;530.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
</code></pre>

<hr>
<h2 id='varpart'>Partition the Variation of Community Matrix by 2, 3, or 4 Explanatory Matrices </h2><span id='topic+varpart'></span><span id='topic+varpart2'></span><span id='topic+varpart3'></span><span id='topic+varpart4'></span><span id='topic+showvarparts'></span><span id='topic+summary.varpart'></span><span id='topic+plot.varpart'></span><span id='topic+plot.varpart234'></span><span id='topic+simpleRDA2'></span><span id='topic+simpleDBRDA'></span>

<h3>Description</h3>

 
<p>The function partitions the variation in community data or community
dissimilarities with respect to two, three, or four explanatory
tables, using adjusted <code class="reqn">R^2</code> in redundancy analysis
ordination (RDA) or distance-based redundancy analysis. If response
is a single vector, partitioning is by partial regression. Collinear
variables in the explanatory tables do NOT have to be removed prior
to partitioning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varpart(Y, X, ..., data, chisquare = FALSE, transfo, scale = FALSE,
    add = FALSE, sqrt.dist = FALSE, permutations)
## S3 method for class 'varpart'
summary(object, ...)
showvarparts(parts, labels, bg = NULL, alpha = 63, Xnames,
    id.size = 1.2,  ...)
## S3 method for class 'varpart234'
plot(x, cutoff = 0, digits = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varpart_+3A_y">Y</code></td>
<td>
<p> Data frame or matrix containing the response data table or
dissimilarity structure inheriting from <code><a href="stats.html#topic+dist">dist</a></code>. In
community ecology, that table is often a site-by-species table or a
dissimilarity object. </p>
</td></tr>
<tr><td><code id="varpart_+3A_x">X</code></td>
<td>
<p>Two to four explanatory models, variables or tables.  These can
be defined in three alternative ways: (1) one-sided model formulae
beginning with <code>~</code> and then defining the model, (2) name of a
single numeric or factor variable, or (3) name of matrix with numeric
or data frame with numeric and factor variables.  The model formulae
can have factors, interaction terms and transformations of
variables. The names of the variables in the model formula are found
in data frame given in <code>data</code> argument, and if not found there,
in the user environment.  Single variables, data frames or matrices
are found in the user environment.  All entries till the next argument
(<code>data</code> or <code>transfo</code>) are interpreted as explanatory models,
and the names of these extra arguments cannot be abbreviated nor
omitted.  </p>
</td></tr>
<tr><td><code id="varpart_+3A_...">...</code></td>
<td>
<p>Other parameters passed to functions. NB, arguments after
dots cannot be abbreviated but they must be spelt out completely.</p>
</td></tr>
<tr><td><code id="varpart_+3A_data">data</code></td>
<td>
<p>The data frame with the variables used in the formulae in
<code>X</code>.</p>
</td></tr>
<tr><td><code id="varpart_+3A_chisquare">chisquare</code></td>
<td>
<p>Partition Chi-square or the inertia of Correspondence
Analysis (<code><a href="#topic+cca">cca</a></code>).</p>
</td></tr>
<tr><td><code id="varpart_+3A_transfo">transfo</code></td>
<td>
<p> Transformation for <code>Y</code> (community data) using
<code><a href="#topic+decostand">decostand</a></code>.  All alternatives in <code>decostand</code> can
be used, and those preserving Euclidean metric include
<code>"hellinger"</code>, <code>"chi.square"</code>, <code>"total"</code>,
<code>"norm"</code>. Ignored if <code>Y</code> are dissimilarities.</p>
</td></tr>
<tr><td><code id="varpart_+3A_scale">scale</code></td>
<td>
<p>Should the columns of <code>Y</code> be standardized to unit
variance. Ignored if <code>Y</code> are dissimilarities.</p>
</td></tr>
<tr><td><code id="varpart_+3A_add">add</code></td>
<td>
<p>Add a constant to the non-diagonal values to euclidify
dissimilarities (see <code><a href="#topic+wcmdscale">wcmdscale</a></code> for details). Choice
<code>"lingoes"</code> (or <code>TRUE</code>) use the recommended method of
Legendre &amp; Anderson (1999: &ldquo;method 1&rdquo;) and <code>"cailliez"</code>
uses their &ldquo;method 2&rdquo;. The argument has an effect only when
<code>Y</code> are dissimilarities.</p>
</td></tr>
<tr><td><code id="varpart_+3A_sqrt.dist">sqrt.dist</code></td>
<td>
<p>Take square root of dissimilarities. This often
euclidifies dissimilarities. NB., the argument name cannot be
abbreviated. The argument has an effect only when <code>Y</code> are
dissimilarities.</p>
</td></tr>
<tr><td><code id="varpart_+3A_permutations">permutations</code></td>
<td>
<p>If <code>chisquare = TRUE</code>, the adjusted
<code class="reqn">R^2</code> is estimated by permutations, and this
paramater can be a list of control values for the permutations as
returned by the function <code><a href="permute.html#topic+how">how</a></code>, or the number
of permutations required, or a permutation matrix where each row
gives the permuted indices.</p>
</td></tr>
<tr><td><code id="varpart_+3A_parts">parts</code></td>
<td>
<p>Number of explanatory tables (circles) displayed.</p>
</td></tr>
<tr><td><code id="varpart_+3A_labels">labels</code></td>
<td>
<p>Labels used for displayed fractions. Default is to use
the same letters as in the printed output.</p>
</td></tr>
<tr><td><code id="varpart_+3A_bg">bg</code></td>
<td>
<p>Fill colours of circles or ellipses.</p>
</td></tr>
<tr><td><code id="varpart_+3A_alpha">alpha</code></td>
<td>
<p>Transparency of the fill colour.  The argument takes
precedence over possible transparency definitions of the
colour. The value must be in range <code class="reqn">0...255</code>, and low values
are more transparent.  Transparency is not available in all
graphics devices or file formats.</p>
</td></tr>
<tr><td><code id="varpart_+3A_xnames">Xnames</code></td>
<td>
<p>Names for sources of variation. Default names are <code>X1</code>,
<code>X2</code>, <code>X3</code> and <code>X4</code>. <code>Xnames=NA</code>,
<code>Xnames=NULL</code> and <code>Xnames=""</code> produce no names. The names
can be changed to other names. It is often best to use short names. </p>
</td></tr>
<tr><td><code id="varpart_+3A_id.size">id.size</code></td>
<td>
<p>A numerical value giving the character expansion factor
for the names of circles or ellipses. </p>
</td></tr>
<tr><td><code id="varpart_+3A_x">x</code>, <code id="varpart_+3A_object">object</code></td>
<td>
<p>The <code>varpart</code> result.</p>
</td></tr>
<tr><td><code id="varpart_+3A_cutoff">cutoff</code></td>
<td>
<p>The values below <code>cutoff</code> will not be displayed.</p>
</td></tr>
<tr><td><code id="varpart_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits; the number of decimal
places is at least one higher.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions partition the variation in <code>Y</code> into components
accounted for by two to four explanatory tables and their combined
effects. If <code>Y</code> is a multicolumn data frame or matrix, the
partitioning is based on redundancy analysis (RDA, see
<code><a href="#topic+rda">rda</a></code>) or on constrained correspondence analysis if
<code>chisquare = TRUE</code> (CCA, see <code><a href="#topic+cca">cca</a></code>).  If <code>Y</code>
is a single variable, the partitioning is based on linear
regression.  If <code>Y</code> are dissimilarities, the decomposition is
based on distance-based redundancy analysis (db-RDA, see
<code><a href="#topic+capscale">capscale</a></code>) following McArdle &amp; Anderson (2001). The
input dissimilarities must be compatible to the results of
<code><a href="stats.html#topic+dist">dist</a></code>. <span class="pkg">Vegan</span> functions <code><a href="#topic+vegdist">vegdist</a></code>,
<code><a href="#topic+designdist">designdist</a></code>, <code><a href="#topic+raupcrick">raupcrick</a></code> and
<code><a href="#topic+betadiver">betadiver</a></code> produce such objects, as do many other
dissimilarity functions in <span class="rlang"><b>R</b></span> packages. Partitioning will be made
to squared dissimilarities analogously to using variance with
rectangular data &ndash; unless <code>sqrt.dist = TRUE</code> was specified.
</p>
<p>The function primarily uses adjusted <code class="reqn">R^2</code> to assess
the partitions explained by the explanatory tables and their
combinations (see <code><a href="#topic+RsquareAdj">RsquareAdj</a></code>), because this is the
only unbiased method (Peres-Neto et al., 2006). The raw
<code class="reqn">R^2</code> for basic fractions are also displayed, but
these are biased estimates of variation explained by the explanatory
table. In correspondence analysis (<code>chisquare = TRUE</code>), the
adjusted <code class="reqn">R^2</code> are found by permutation and they vary
in repeated analyses.
</p>
<p>The identifiable fractions are designated by lower case alphabets. The
meaning of the symbols can be found in the separate document (use
<code>browseVignettes("vegan")</code>), or can be displayed graphically
using function <code>showvarparts</code>.
</p>
<p>A fraction is testable if it can be directly expressed as an RDA or
db-RDA model.  In these cases the printed output also displays the
corresponding RDA model using notation where explanatory tables
after <code>|</code> are conditions (partialled out; see <code><a href="#topic+rda">rda</a></code>
for details). Although single fractions can be testable, this does
not mean that all fractions simultaneously can be tested, since the
number of testable fractions is higher than the number of estimated
models. The non-testable components are found as differences of
testable components. The testable components have permutation
variance in correspondence analysis (<code>chisquare = TRUE</code>), and
the non-testable components have even higher variance.
</p>
<p>An abridged explanation of the alphabetic symbols for the individual
fractions follows, but computational details should be checked in the
vignette (readable with <code>browseVignettes("vegan")</code>) or in the
source code.
</p>
<p>With two explanatory tables, the fractions explained 
uniquely by each of the two tables are <code>[a]</code> and
<code>[b]</code>, and their joint effect
is  <code>[c]</code>.
</p>
<p>With three explanatory tables, the fractions explained uniquely
by each of the three tables are  
<code>[a]</code> to <code>[c]</code>, joint fractions between two tables are
<code>[d]</code> to <code>[f]</code>, and the joint fraction between all three
tables is <code>[g]</code>.
</p>
<p>With four explanatory tables, the fractions explained uniquely by each
of the four tables are <code>[a]</code>
to <code>[d]</code>, joint fractions between two tables are <code>[e]</code> to
<code>[j]</code>, joint fractions between three variables are <code>[k]</code> to
<code>[n]</code>, and the joint fraction between all four tables is
<code>[o]</code>.
</p>
<p><code>summary</code> will give an overview of unique and and overall
contribution of each group of variables. The overall contribution
(labelled as &ldquo;Contributed&rdquo;) consists of the unique contribution
of the variable and equal shares of each fraction where the variable
contributes. The summary tabulates how each fraction is divided
between the variables, and the contributed component is the sum of all
these divided fractions. The summary is based on the idea of Lai et
al. (2022), and is similar to the output of their <a href="https://CRAN.R-project.org/package=rdacca.hp"><span class="pkg">rdacca.hp</span></a>
package.
</p>
<p>There is a <code>plot</code> function that displays the Venn diagram and
labels each intersection (individual fraction) with the adjusted R
squared if this is higher than <code>cutoff</code>.  A helper function
<code>showvarpart</code> displays the fraction labels. The circles and
ellipses are labelled by short default names or by names defined by
the user in argument <code>Xnames</code>. Longer explanatory file names can
be written on the varpart output plot as follows: use option
<code>Xnames=NA</code>, then add new names using the <code>text</code> function. A
bit of fiddling with coordinates (see <code><a href="graphics.html#topic+locator">locator</a></code>) and
character size should allow users to place names of reasonably short
lengths on the <code>varpart</code> plot.
</p>


<h3>Value</h3>

<p>Function <code>varpart</code> returns an
object of class <code>"varpart"</code> with items <code>scale</code> and
<code>transfo</code> (can be missing) which hold information on
standardizations, <code>tables</code> which contains names of explanatory
tables, and <code>call</code> with the function <code><a href="base.html#topic+call">call</a></code>. The
function <code>varpart</code> calls function <code>varpart2</code>,
<code>varpart3</code> or <code>varpart4</code> which return an object of class
<code>"varpart234"</code> and saves its result in the item <code>part</code>.
The items in this object are:
</p>
<table>
<tr><td><code>SS.Y</code></td>
<td>
<p>Sum of squares of matrix <code>Y</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of observations (rows).</p>
</td></tr>
<tr><td><code>nsets</code></td>
<td>
<p>Number of explanatory tables</p>
</td></tr>
<tr><td><code>bigwarning</code></td>
<td>
<p>Warnings on collinearity.</p>
</td></tr>
<tr><td><code>fract</code></td>
<td>
<p>Basic fractions from all estimated constrained models.</p>
</td></tr>
<tr><td><code>indfract</code></td>
<td>
<p>Individual fractions or all possible subsections in
the Venn diagram (see <code>showvarparts</code>).</p>
</td></tr>
<tr><td><code>contr1</code></td>
<td>
<p>Fractions that can be found after conditioning on single
explanatory table in models with three or four explanatory tables.</p>
</td></tr>
<tr><td><code>contr2</code></td>
<td>
<p>Fractions that can be found after conditioning on two
explanatory tables in models with four explanatory tables.</p>
</td></tr>
</table>


<h3>Fraction Data Frames</h3>

<p>Items <code>fract</code>,
<code>indfract</code>, <code>contr1</code> and <code>contr2</code> are all data frames with
items:
</p>

<ul>
<li><p><code>Df</code>: Degrees of freedom of numerator of the <code class="reqn">F</code>-statistic
for the fraction.
</p>
</li>
<li><p><code>R.square</code>: Raw <code class="reqn">R^2</code>. This is calculated only for
<code>fract</code> and this is <code>NA</code> in other items.
</p>
</li>
<li><p><code>Adj.R.square</code>: Adjusted <code class="reqn">R^2</code>.
</p>
</li>
<li><p><code>Testable</code>: If the fraction can be expressed as a (partial) RDA
model, it is directly <code>Testable</code>, and this field is
<code>TRUE</code>.  In that case the fraction label also gives the
specification of the testable RDA model.
</p>
</li></ul>



<h3>Note</h3>

<p>You can use command <code>browseVignettes("vegan")</code> to display
document which presents Venn diagrams showing the fraction names in
partitioning the variation of Y with respect to 2, 3, and 4 tables of
explanatory variables, as well as the equations used in variation
partitioning.
</p>
<p>The functions frequently give negative estimates of variation.
Adjusted <code class="reqn">R^2</code> can be negative for any fraction;
unadjusted <code class="reqn">R^2</code> of testable fractions of variances
will be non-negative.  Non-testable fractions cannot be found
directly, but by subtracting different models, and these subtraction
results can be negative.  The fractions are orthogonal, or linearly
independent, but more complicated or nonlinear dependencies can
cause negative non-testable fractions. Any fraction can be negative
for non-Euclidean dissimilarities because the underlying db-RDA model
can yield negative eigenvalues (see <code><a href="#topic+capscale">capscale</a></code>,
<code><a href="#topic+dbrda">dbrda</a></code>). These negative eigenvalues in the underlying
analysis can be avoided with arguments <code>sqrt.dist</code> and <code>add</code>
which have a similar effect as in <code><a href="#topic+capscale">capscale</a></code>: the square
roots of several dissimilarities do not have negative eigenvalues, and
no negative eigenvalues are produced after Lingoes or Cailliez
adjustment, which in effect add random variation to the
dissimilarities.
</p>
<p>A simplified, fast version of RDA, CCA adn dbRDA are used (functions
<code>simpleRDA2</code>, <code>simpleCCA</code> and <code>simpleDBRDA</code>).  The
actual calculations are done in functions <code>varpart2</code> to
<code>varpart4</code>, but these are not intended to be called directly by
the user.
</p>


<h3>Author(s)</h3>

<p> Pierre Legendre, Departement de Sciences Biologiques, Universite de
Montreal, Canada.  Further developed by Jari Oksanen. </p>


<h3>References</h3>

 
<p>(a) References on variation partitioning
</p>
<p>Borcard, D., P. Legendre &amp; P. Drapeau. 1992. Partialling out the spatial
component of ecological variation. Ecology 73: 1045&ndash;1055.
</p>
<p>Lai J., Y. Zou, J. Zhang &amp; P. Peres-Neto. 2022. Generalizing
hierarchical and variation partitioning in multiple regression and
canonical analysis using the rdacca.hp R package. Methods in Ecology and
Evolution, 13: 782&ndash;788.
</p>
<p>Legendre, P. &amp; L. Legendre. 2012. Numerical ecology, 3rd English edition.
Elsevier Science BV, Amsterdam.
</p>
<p>(b) Reference on transformations for species data
</p>
<p>Legendre, P. and E. D. Gallagher. 2001. Ecologically meaningful
transformations for ordination of species data. Oecologia 129: 271&ndash;280.
</p>
<p>(c) Reference on adjustment of the bimultivariate redundancy statistic
</p>
<p>Peres-Neto, P., P. Legendre, S. Dray and D. Borcard. 2006. Variation partitioning
of species data matrices: estimation and comparison of fractions.
Ecology 87: 2614&ndash;2625.
</p>
<p>(d) References on partitioning of dissimilarities
</p>
<p>Legendre, P. &amp; Anderson, M. J. (1999). Distance-based redundancy
analysis: testing multispecies responses in multifactorial ecological
experiments. <em>Ecological Monographs</em> 69, 1&ndash;24.
</p>
<p>McArdle, B.H. &amp; Anderson, M.J. (2001). Fitting multivariate models
to community data: a comment on distance-based redundancy
analysis. Ecology 82, 290-297.
</p>


<h3>See Also</h3>

 
<p>For analysing testable fractions, see <code><a href="#topic+rda">rda</a></code> and
<code><a href="#topic+anova.cca">anova.cca</a></code>. For data transformation, see
<code><a href="#topic+decostand">decostand</a></code>. Function <code><a href="#topic+inertcomp">inertcomp</a></code> gives
(unadjusted) components of variation for each species or site
separately.  Function <code><a href="#topic+rda">rda</a></code> displays unadjusted
components in its output, but <code><a href="#topic+RsquareAdj">RsquareAdj</a></code> will give
adjusted <code class="reqn">R^2</code> that are similar to the current
function also for partial models.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mite)
data(mite.env)
data(mite.pcnm)

# Two explanatory data frames -- Hellinger-transform Y
mod &lt;- varpart(mite, mite.env, mite.pcnm, transfo="hel")
mod
summary(mod)

## Use fill colours
showvarparts(2, bg = c("hotpink","skyblue"))
plot(mod, bg = c("hotpink","skyblue"))
## Test fraction [a] using partial RDA, '~ .' in formula tells to use
## all variables of data mite.env.
aFrac &lt;- rda(decostand(mite, "hel"), mite.env, mite.pcnm)
anova(aFrac)
## RsquareAdj gives the same result as component [a] of varpart
RsquareAdj(aFrac)

## Partition Bray-Curtis dissimilarities
varpart(vegdist(mite), mite.env, mite.pcnm)
## Three explanatory tables with formula interface
mod &lt;- varpart(mite, ~ SubsDens + WatrCont, ~ Substrate + Shrub + Topo,
   mite.pcnm, data=mite.env, transfo="hel")
mod
summary(mod)
showvarparts(3, bg=2:4)
plot(mod, bg=2:4)

## Use RDA to test fraction [a]
## Matrix can be an argument in formula
rda.result &lt;- rda(decostand(mite, "hell") ~ SubsDens + WatrCont +
   Condition(Substrate + Shrub + Topo) +
   Condition(as.matrix(mite.pcnm)), data = mite.env)
anova(rda.result)

## Four explanatory tables
mod &lt;- varpart(mite, ~ SubsDens + WatrCont, ~Substrate + Shrub + Topo,
  mite.pcnm[,1:11], mite.pcnm[,12:22], data=mite.env, transfo="hel")
mod
summary(mod)
plot(mod, bg=2:5)
## Show values for all partitions by putting 'cutoff' low enough:
plot(mod, cutoff = -Inf, cex = 0.7, bg=2:5)
</code></pre>

<hr>
<h2 id='vegan-defunct'>Defunct Functions in Package <span class="pkg">vegan</span></h2><span id='topic+vegan-defunct'></span><span id='topic+getNumObs'></span><span id='topic+permuted.index2'></span><span id='topic+permuted.index'></span><span id='topic+metaMDSrotate'></span><span id='topic+density.adonis'></span><span id='topic+density.anosim'></span><span id='topic+density.mantel'></span><span id='topic+density.mrpp'></span><span id='topic+density.permutest.cca'></span><span id='topic+density.protest'></span><span id='topic+plot.vegandensity'></span><span id='topic+densityplot.adonis'></span><span id='topic+density.oecosimu'></span><span id='topic+densityplot.oecosimu'></span><span id='topic+commsimulator'></span><span id='topic+vegandocs'></span><span id='topic+as.mlm'></span><span id='topic+as.mlm.cca'></span><span id='topic+as.mlm.rda'></span><span id='topic+humpfit'></span>

<h3>Description</h3>

<p>The functions or variables listed here are no longer part of
<span class="pkg">vegan</span> as they are no longer needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## defunct in vegan 2.6-0
as.mlm(x)
humpfit(mass, spno, family = poisson, start)
vegandocs(doc = c("NEWS", "ONEWS", "FAQ-vegan", "intro-vegan",
    "diversity-vegan", "decision-vegan", "partitioning", "permutations"))

## defunct in vegan 2.5-0
commsimulator(x, method, thin=1)

## defunct in vegan 2.4-0
## S3 method for class 'adonis'
density(x, ...)
## S3 method for class 'vegandensity'
plot(x, main = NULL, xlab = NULL, ylab = "Density", 
   type = "l", zero.line = TRUE, obs.line = TRUE, ...)
## S3 method for class 'adonis'
densityplot(x, data, xlab = "Null", ...)

## defunct in vegan 2.2-0
metaMDSrotate(object, vec, na.rm = FALSE, ...)

## defunct in vegan 2.0-0
getNumObs(object, ...)
permuted.index2(n, control = permControl())

</code></pre>


<h3>Details</h3>

<p><code>as.mlm</code> function is replaced with a set functions that can
find the same statistics directly from the ordination result object:
see <code><a href="#topic+hatvalues.cca">hatvalues.cca</a></code>, <code><a href="#topic+rstandard.cca">rstandard.cca</a></code>,
<code><a href="#topic+rstudent.cca">rstudent.cca</a></code>, <code><a href="#topic+cooks.distance.cca">cooks.distance.cca</a></code>,
<code><a href="#topic+vcov.cca">vcov.cca</a></code>.
</p>
<p>Function <code>humpfit</code> was transferred to the <span class="pkg">natto</span> package and
is still available from <a href="https://github.com/jarioksa/natto/">https://github.com/jarioksa/natto/</a>.
</p>
<p><span class="rlang"><b>R</b></span> functions <code><a href="utils.html#topic+news">news</a></code> should be used to read <span class="pkg">vegan</span>
NEWS (<code>news(package = "vegan")</code>), and
<code><a href="utils.html#topic+browseVignettes">browseVignettes</a></code> is a better tool for reading vignettes
than <code>vegandocs</code>.
</p>
<p>Function <code>commsimulator</code> is replaced with
<code><a href="#topic+make.commsim">make.commsim</a></code> which defines the Null models, and
functions <code><a href="#topic+nullmodel">nullmodel</a></code> and
<code><a href="#topic+simulate.nullmodel">simulate.nullmodel</a></code> that check the input data and
generate the Null model communities.
</p>
<p>The deprecated <code>density</code> and <code>densityplot</code> methods are
replaced with similar methods for <code><a href="#topic+permustats">permustats</a></code>. The
<code><a href="#topic+permustats">permustats</a></code> offers more powerful analysis tools for
permutations, including <code><a href="#topic+summary.permustats">summary.permustats</a></code> giving
<code class="reqn">z</code> values (a.k.a. standardized effect sizes, SES), and Q-Q
plots (<code><a href="#topic+qqnorm.permustats">qqnorm.permustats</a></code>,
<code><a href="#topic+qqmath.permustats">qqmath.permustats</a></code>).
</p>
<p>Function <code>metaMDSrotate</code> is replaced with
<code><a href="#topic+MDSrotate">MDSrotate</a></code> which can handle <code><a href="#topic+monoMDS">monoMDS</a></code>
results in addition to <code><a href="#topic+metaMDS">metaMDS</a></code>.
</p>
<p>The permutation functions were moved to the <span class="pkg">permute</span> package,
and they are documented there.  The <span class="pkg">permute</span> package replaces
<code>permuted.index</code> and <code>permuted.index2</code> with
<code><a href="permute.html#topic+shuffle">shuffle</a></code> and <code>getNumObs</code> with its
specific <code><a href="permute.html#topic+nobs-methods">nobs-methods</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Defunct">Defunct</a></code>, <code><a href="#topic+vegan-deprecated">vegan-deprecated</a></code>
</p>

<hr>
<h2 id='vegan-deprecated'>Deprecated Functions in vegan package</h2><span id='topic+adonis'></span><span id='topic+as.mcmc.oecosimu'></span><span id='topic+as.mcmc.permat'></span><span id='topic+vegan-deprecated'></span>

<h3>Description</h3>

<p>These functions are provided for compatibility with older versions of
<span class="pkg">vegan</span> only, and may be defunct as soon as the next release.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## use adonis2 instead
adonis(formula, data, permutations = 999, method = "bray",
    strata = NULL, contr.unordered = "contr.sum",
    contr.ordered = "contr.poly", parallel = getOption("mc.cores"), ...)
## use toCoda instead
as.mcmc.oecosimu(x)
as.mcmc.permat(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vegan-deprecated_+3A_formula">formula</code>, <code id="vegan-deprecated_+3A_data">data</code>, <code id="vegan-deprecated_+3A_permutations">permutations</code>, <code id="vegan-deprecated_+3A_method">method</code>, <code id="vegan-deprecated_+3A_parallel">parallel</code>, <code id="vegan-deprecated_+3A_...">...</code></td>
<td>
<p>See
<code><a href="#topic+adonis2">adonis2</a></code>.</p>
</td></tr>
<tr><td><code id="vegan-deprecated_+3A_strata">strata</code></td>
<td>
<p>groups (strata) within which to constrain permutations.</p>
</td></tr>
<tr><td><code id="vegan-deprecated_+3A_contr.unordered">contr.unordered</code>, <code id="vegan-deprecated_+3A_contr.ordered">contr.ordered</code></td>
<td>
<p>contrasts used for design matrix.</p>
</td></tr>
<tr><td><code id="vegan-deprecated_+3A_x">x</code></td>
<td>
<p>object to be tranformed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+adonis2">adonis2</a></code> replaces <code>adonis</code> with extended
functionality and completely new internal design. The shared arguments
of <code>adonis</code> are similar as in <code><a href="#topic+adonis2">adonis2</a></code>, but
arguments <code>contr.unordered</code> and <code>contr.ordered</code> can set the
contrasts within <code>adonis</code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Deprecated">Deprecated</a></code>
</p>

<hr>
<h2 id='vegan-internal'>Internal vegan functions</h2><span id='topic+vegan-internal'></span><span id='topic+ordiParseFormula'></span><span id='topic+ordiNAexclude'></span><span id='topic+ordiNApredict'></span><span id='topic+getPermuteMatrix'></span><span id='topic+howHead'></span><span id='topic+centroids.cca'></span><span id='topic+ordiTerminfo'></span><span id='topic+pasteCall'></span><span id='topic+ordiArgAbsorber'></span><span id='topic+veganCovEllipse'></span><span id='topic+hierParseFormula'></span><span id='topic+veganMahatrans'></span><span id='topic+GowerDblcen'></span><span id='topic+addLingoes'></span><span id='topic+addCailliez'></span>

<h3>Description</h3>

<p>Internal vegan functions that are not intended to be called directly,
but only within other functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordiParseFormula(formula, data, xlev = NULL,  na.action = na.fail,
    subset = NULL, X)
ordiTerminfo(d, data)
ordiNAexclude(x, excluded)
ordiNApredict(omit, x)
ordiArgAbsorber(..., shrink, origin, scaling, triangular,
                display, choices, const, truemean, FUN)
centroids.cca(x, mf, wt)
getPermuteMatrix(perm, N, strata = NULL)
howHead(x, ...)
pasteCall(call, prefix = "Call:")
veganCovEllipse(cov, center = c(0, 0), scale = 1, npoints = 100)
veganMahatrans(x, s2, tol = sqrt(.Machine$double.eps))
hierParseFormula(formula, data)
GowerDblcen(x, na.rm = TRUE)
addLingoes(d)
addCailliez(d)
</code></pre>


<h3>Details</h3>

<p> The description here is only intended for <span class="pkg">vegan</span>
developers: these functions are not intended for users, but they
only should be used within functions.  In general, these functions
are not exported to the namespace, but you must use
<code><a href="base.html#topic+get">get</a></code> or <code><a href="base.html#topic++3A+3A+3A">:::</a></code> to directly call these
functions.
</p>
<p><code>ordiParseFormula</code> returns a list of three matrices (dependent
variables, and <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> of constraints and
conditions, possibly <code>NULL</code>) needed in constrained
ordination. Argument <code>xlev</code> is passed to
<code><a href="stats.html#topic+model.frame">model.frame</a></code>. If the left-hand-side was already
evaluated in calling code, it can be given as argument <code>X</code> and
will not be re-evaluated. <code>ordiTermInfo</code> finds the term
information for constrained ordination as described in
<code><a href="#topic+cca.object">cca.object</a></code>. <code>ordiNAexclude</code> implements
<code>na.action = na.exclude</code> for constrained ordination finding WA
scores of CCA components and site scores of unconstrained component
from <code>excluded</code> rows of observations. Function
<code>ordiNApredict</code> pads the result object with these or with WA
scores similarly as <code><a href="stats.html#topic+napredict">napredict</a></code>.
</p>
<p><code>ordiArgAbsorber</code> absorbs arguments of <code><a href="#topic+scores">scores</a></code>
function of <span class="pkg">vegan</span> so that these do not cause superfluous
warnings in graphical function <code>FUN</code>. If you implement
<code>scores</code> functions with new arguments, you should update
<code>ordiArgAbsorber</code>. 
</p>
<p><code>centroids.cca</code> finds the weighted centroids of variables.
</p>
<p><code>getPermuteMatrix</code> interprets user input and returns a
permutation matrix where each row gives indices of observations for
a permutation. The input <code>perm</code> can be a single number for the
number of simple permutations, a result of
<code><a href="permute.html#topic+how">how</a></code> defining a permutation scheme or a
permutation matrix.
</p>
<p><code>howHead</code> formats the permutation scheme of
<code><a href="permute.html#topic+how">how</a></code> for display. The formatting is more
compact than the one used in <code>print</code> in the <span class="pkg">permute</span>
package, and shows only non-default choices. This output is normally
used when printing the results of <span class="pkg">vegan</span> permutations.
</p>
<p><code>pasteCall</code> prints the function call so that it is nicely wrapped
in <code><a href="utils.html#topic+Sweave">Sweave</a></code> output.
</p>
<p><code>veganCovEllipse</code> finds the coordinates for drawing a
covariance ellipse.
</p>
<p><code>veganMahatrans</code> transforms data matrix so that its Euclidean
distances are Mahalanobis distances. The input data <code>x</code> must be
a matrix centred by columns, and <code>s2</code> its covariance matrix. If
<code>s2</code> is not given, covariance matrix is found from <code>x</code>
within the function.
</p>
<p><code>hierParseFormula</code> returns a list of one matrix (left hand side)
and a model frame with factors representing hierarchy levels 
(right hand side) to be used in <code><a href="#topic+adipart">adipart</a></code>, 
<code><a href="#topic+multipart">multipart</a></code> and <code><a href="#topic+hiersimu">hiersimu</a></code>.
</p>
<p><code>GowerDblcen</code> performs the Gower double centring of a matrix of
dissimilarities. Similar function was earlier available as a compiled
code in <span class="pkg">stats</span>, but it is not a part of official API, and
therefore we have this poorer replacement.
</p>
<p><code>addLingoes</code> and <code>addCailliez</code> find the constant added to
non-diagonal (squared) dissimilarities to make all eigenvalues
non-negative in Principal Co-ordinates Analysis
(<code><a href="#topic+wcmdscale">wcmdscale</a></code>, <code><a href="#topic+capscale">capscale</a></code>). Function
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code> implements the Cailliez method. The argument
is a matrix of dissimilarities.
</p>

<hr>
<h2 id='vegan-package'>
Community Ecology Package: Ordination, Diversity and Dissimilarities
</h2><span id='topic+vegan-package'></span><span id='topic+vegan'></span>

<h3>Description</h3>

<p> The <span class="pkg">vegan</span> package provides tools for descriptive
community ecology. It has most basic functions of diversity analysis,
community ordination and dissimilarity analysis. Most of its
multivariate tools can be used for other data types as well.  </p>


<h3>Details</h3>

<p>The functions in the <span class="pkg">vegan</span> package contain tools for
diversity analysis, ordination methods and tools for the analysis of
dissimilarities. Together with the <span class="pkg">labdsv</span> package, the <span class="pkg">vegan</span>
package provides most standard tools of descriptive community
analysis. Package <span class="pkg">ade4</span> provides an alternative comprehensive
package, and several other packages complement <span class="pkg">vegan</span> and provide
tools for deeper analysis in specific fields. Package
<span class="pkg">BiodiversityR</span> provides a GUI for a large subset of <span class="pkg">vegan</span>
functionality.
</p>
<p>The <span class="pkg">vegan</span> package is developed at GitHub
(<a href="https://github.com/vegandevs/vegan/">https://github.com/vegandevs/vegan/</a>).  GitHub provides up-to-date
information and forums for bug reports.
</p>
<p>Most important changes in <span class="pkg">vegan</span> documents can be read with
<code>news(package="vegan")</code> and vignettes can be browsed with
<code>browseVignettes("vegan")</code>. The vignettes include a <span class="pkg">vegan</span>
FAQ, discussion on design decisions, short introduction to ordination
and discussion on diversity methods.



</p>
<p>To see the preferable citation of the package, type
<code>citation("vegan")</code>.  
</p>


<h3>Author(s)</h3>

<p> The <span class="pkg">vegan</span> development team is Jari Oksanen,
F. Guillaume Blanchet, Roeland Kindt, Pierre Legendre, Peter
R. Minchin, R. B. O'Hara, Gavin L. Simpson, Peter Solymos, M. Henry
H. Stevens, Helene Wagner.  Many other people have contributed to
individual functions: see credits in function help pages.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: Unconstrained ordination
## NMDS
data(varespec)
data(varechem)
ord &lt;- metaMDS(varespec)
plot(ord, type = "t")
## Fit environmental variables
ef &lt;- envfit(ord, varechem)
ef
plot(ef, p.max = 0.05)
### Example 2: Constrained ordination (RDA)
## The example uses formula interface to define the model
data(dune)
data(dune.env)
## No constraints: PCA
mod0 &lt;- rda(dune ~ 1, dune.env)
mod0
plot(mod0)
## All environmental variables: Full model
mod1 &lt;- rda(dune ~ ., dune.env)
mod1
plot(mod1)
## Automatic selection of variables by permutation P-values
mod &lt;- ordistep(mod0, scope=formula(mod1))
mod
plot(mod)
## Permutation test for all variables
anova(mod)
## Permutation test of "type III" effects, or significance when a term
## is added to the model after all other terms
anova(mod, by = "margin")
## Plot only sample plots, use different symbols and draw SD ellipses 
## for Managemenet classes
plot(mod, display = "sites", type = "n")
with(dune.env, points(mod, disp = "si", pch = as.numeric(Management)))
with(dune.env, legend("topleft", levels(Management), pch = 1:4,
  title = "Management"))
with(dune.env, ordiellipse(mod, Management, label = TRUE))
## add fitted surface of diversity to the model
ordisurf(mod, diversity(dune), add = TRUE)
### Example 3: analysis of dissimilarites a.k.a. non-parametric
### permutational anova
adonis2(dune ~ ., dune.env)
adonis2(dune ~ Management + Moisture, dune.env)
</code></pre>

<hr>
<h2 id='vegdist'>Dissimilarity Indices for Community Ecologists </h2><span id='topic+vegdist'></span>

<h3>Description</h3>

<p>The function computes dissimilarity indices that are useful for or
popular with community ecologists. All indices use quantitative data,
although they would be named by the corresponding binary index, but
you can calculate the binary index using an appropriate argument.  If
you do not find your favourite index here, you can see if it can be
implemented using <code><a href="#topic+designdist">designdist</a></code>.  Gower, Bray&ndash;Curtis,
Jaccard and Kulczynski indices are good in detecting underlying
ecological gradients (Faith et al. 1987). Morisita, Horn&ndash;Morisita,
Binomial, Cao and Chao indices should be able to handle different
sample sizes (Wolda 1981, Krebs 1999, Anderson &amp; Millar 2004), and
Mountford (1962) and Raup-Crick indices for presence&ndash;absence data
should be able to handle unknown (and variable) sample sizes. Most of
these indices are discussed by Krebs (1999) and Legendre &amp; Legendre
(2012), and their properties further compared by Wolda (1981) and
Legendre &amp; De C√°ceres (2012). Aitchison (1986) distance 
is equivalent to Euclidean distance between CLR-transformed samples
(<code>"clr"</code>) and deals with positive compositional data.
Robust Aitchison distance by Martino et al. (2019) uses robust
CLR (<code>"rlcr"</code>), making it applicable to non-negative data
including zeroes (unlike the standard Aitchison).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vegdist(x, method="bray", binary=FALSE, diag=FALSE, upper=FALSE,
        na.rm = FALSE, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vegdist_+3A_x">x</code></td>
<td>
<p>Community data matrix.</p>
</td></tr>
<tr><td><code id="vegdist_+3A_method">method</code></td>
<td>
<p>Dissimilarity index, partial match to
<code>"manhattan"</code>, <code>"euclidean"</code>, <code>"canberra"</code>,
<code>"clark"</code>, <code>"bray"</code>, <code>"kulczynski"</code>,
<code>"jaccard"</code>, <code>"gower"</code>, <code>"altGower"</code>,
<code>"morisita"</code>, <code>"horn"</code>, <code>"mountford"</code>, <code>"raup"</code>,
<code>"binomial"</code>, <code>"chao"</code>, <code>"cao"</code>, <code>"mahalanobis"</code>,
<code>"chisq"</code>, <code>"chord"</code>, <code>"hellinger"</code>,
<code>"aitchison"</code>, or <code>"robust.aitchison"</code>.</p>
</td></tr>
<tr><td><code id="vegdist_+3A_binary">binary</code></td>
<td>
<p>Perform presence/absence standardization before analysis
using <code><a href="#topic+decostand">decostand</a></code>.</p>
</td></tr>
<tr><td><code id="vegdist_+3A_diag">diag</code></td>
<td>
<p>Compute diagonals. </p>
</td></tr>
<tr><td><code id="vegdist_+3A_upper">upper</code></td>
<td>
<p>Return only the upper diagonal. </p>
</td></tr>
<tr><td><code id="vegdist_+3A_na.rm">na.rm</code></td>
<td>
<p>Pairwise deletion of missing observations when
computing dissimilarities.</p>
</td></tr>
<tr><td><code id="vegdist_+3A_...">...</code></td>
<td>
<p>Other parameters.  These are ignored, except in
<code>method ="gower"</code> which accepts <code>range.global</code> parameter of
<code><a href="#topic+decostand">decostand</a></code>, and in <code>method="aitchison"</code>, which
accepts <code>pseudocount</code> parameter of <code><a href="#topic+decostand">decostand</a></code> used
in the <code>clr</code> transformation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Jaccard (<code>"jaccard"</code>), Mountford (<code>"mountford"</code>),
Raup&ndash;Crick (<code>"raup"</code>), Binomial and Chao indices are discussed
later in this section.  The function also finds indices for presence/
absence data by setting <code>binary = TRUE</code>. The following overview
gives first the quantitative version, where <code class="reqn">x_{ij}</code>
<code class="reqn">x_{ik}</code> refer to the quantity on species (column) <code class="reqn">i</code>
and sites (rows) <code class="reqn">j</code> and <code class="reqn">k</code>. In binary versions <code class="reqn">A</code> and
<code class="reqn">B</code> are the numbers of species on compared sites, and <code class="reqn">J</code> is
the number of species that occur on both compared sites similarly as
in <code><a href="#topic+designdist">designdist</a></code> (many indices produce identical binary
versions):
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>euclidean</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = \sqrt{\sum_i (x_{ij}-x_{ik})^2}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\sqrt{A+B-2J}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>manhattan</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk}=\sum_i |x_{ij}-x_{ik}|</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">A+B-2J</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>gower</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = (1/M) \sum_i \frac{|x_{ij}-x_{ik}|}{\max x_i-\min
	x_i}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">(A+B-2J)/M</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> where <code class="reqn">M</code> is the number of columns (excluding missing
    values)
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>altGower</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = (1/NZ) \sum_i |x_{ij} - x_{ik}|</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> where <code class="reqn">NZ</code> is the number of non-zero columns excluding
    double-zeros (Anderson et al. 2006).
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\frac{A+B-2J}{A+B-J}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>canberra</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk}=\frac{1}{NZ} \sum_i
      \frac{|x_{ij}-x_{ik}|}{|x_{ij}|+|x_{ik}|}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> where <code class="reqn">NZ</code> is the number of non-zero entries.
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\frac{A+B-2J}{A+B-J}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>clark</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk}=\sqrt{\frac{1}{NZ} \sum_i
      (\frac{x_{ij}-x_{ik}}{x_{ij}+x_{ik}})^2}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> where <code class="reqn">NZ</code> is the number of non-zero entries.
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\frac{A+B-2J}{A+B-J}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>bray</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = \frac{\sum_i |x_{ij}-x_{ik}|}{\sum_i (x_{ij}+x_{ik})}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\frac{A+B-2J}{A+B}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>kulczynski</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = 1-0.5(\frac{\sum_i \min(x_{ij},x_{ik})}{\sum_i x_{ij}} +
      \frac{\sum_i \min(x_{ij},x_{ik})}{\sum_i x_{ik}} )</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">1-(J/A + J/B)/2</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>morisita</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} =  1 - \frac{2 \sum_i x_{ij} x_{ik}}{(\lambda_j +
	  \lambda_k) \sum_i x_{ij} \sum_i
	  x_{ik}}</code>, where  
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> <code class="reqn">\lambda_j = \frac{\sum_i x_{ij} (x_{ij} - 1)}{\sum_i
	x_{ij} \sum_i (x_{ij} - 1)}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: cannot be calculated
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>horn</code>
    </td><td style="text-align: left;"> Like <code>morisita</code>, but <code class="reqn">\lambda_j = \sum_i
      x_{ij}^2/(\sum_i x_{ij})^2</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\frac{A+B-2J}{A+B}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>binomial</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = \sum_i [x_{ij} \log (\frac{x_{ij}}{n_i}) + x_{ik} \log
      (\frac{x_{ik}}{n_i}) - n_i \log(\frac{1}{2})]/n_i</code>,
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: left;"> where <code class="reqn">n_i = x_{ij} + x_{ik}</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> binary: <code class="reqn">\log(2) \times (A+B-2J)</code>
    </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>cao</code>
    </td><td style="text-align: left;"> <code class="reqn">d_{jk} = \frac{1}{S} \sum_i \log
    \left(\frac{n_i}{2}\right) - (x_{ij} \log(x_{ik}) + x_{ik}
    \log(x_{ij}))/n_i</code>,
  </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;"> where <code class="reqn">S</code> is the number of species in compared sites and
    <code class="reqn">n_i = x_{ij}+x_{ik}</code>
  </td>
</tr>

</table>

<p>Jaccard index is computed as <code class="reqn">2B/(1+B)</code>, where <code class="reqn">B</code> is
Bray&ndash;Curtis dissimilarity.
</p>
<p>Binomial index is derived from Binomial deviance under null hypothesis
that the two compared communities are equal. It should be able to
handle variable sample sizes. The index does not have a fixed upper
limit, but can vary among sites with no shared species. For further
discussion, see Anderson &amp; Millar (2004).
</p>
<p>Cao index or CYd index (Cao et al. 1997) was suggested as a minimally
biased index for high beta diversity and variable sampling intensity.
Cao index does not have a fixed upper limit, but can vary among sites
with no shared species.  The index is intended for count (integer)
data, and it is undefined for zero abundances; these are replaced with
arbitrary value <code class="reqn">0.1</code> following Cao et al. (1997).  Cao et
al. (1997) used <code class="reqn">\log_{10}</code>, but the current function uses
natural logarithms so that the values are approximately <code class="reqn">2.30</code>
times higher than with 10-based logarithms. Anderson &amp; Thompson (2004)
give an alternative formulation of Cao index to highlight its
relationship with Binomial index (above).
</p>
<p>Mountford index is defined as <code class="reqn">M = 1/\alpha</code> where <code class="reqn">\alpha</code>
is the parameter of Fisher's logseries assuming that the compared
communities are samples from the same community
(cf. <code><a href="#topic+fisherfit">fisherfit</a></code>, <code><a href="#topic+fisher.alpha">fisher.alpha</a></code>). The index
<code class="reqn">M</code> is found as the positive root of equation <code class="reqn">\exp(aM) +
  \exp(bM) = 1 + \exp[(a+b-j)M]</code>, where <code class="reqn">j</code> is the number of species occurring in
both communities, and <code class="reqn">a</code> and <code class="reqn">b</code> are the number of species
in each separate community (so the index uses presence&ndash;absence
information). Mountford index is usually misrepresented in the
literature: indeed Mountford (1962) suggested an approximation to be
used as starting value in iterations, but the proper index is
defined as the root of the equation above. The function
<code>vegdist</code> solves <code class="reqn">M</code> with the Newton method. Please note
that if either <code class="reqn">a</code> or <code class="reqn">b</code> are equal to <code class="reqn">j</code>, one of the
communities could be a subset of other, and the dissimilarity is
<code class="reqn">0</code> meaning that non-identical objects may be regarded as
similar and the index is non-metric. The Mountford index is in the
range <code class="reqn">0 \dots \log(2)</code>.
</p>
<p>Raup&ndash;Crick dissimilarity (<code>method = "raup"</code>) is a probabilistic
index based on presence/absence data.  It is defined as <code class="reqn">1 -
  prob(j)</code>, or based on the probability of observing at least <code class="reqn">j</code>
species in shared in compared communities.  The current function uses
analytic result from hypergeometric distribution
(<code><a href="stats.html#topic+phyper">phyper</a></code>) to find the probabilities.  This probability
(and the index) is dependent on the number of species missing in both
sites, and adding all-zero species to the data or removing missing
species from the data will influence the index.  The probability (and
the index) may be almost zero or almost one for a wide range of
parameter values.  The index is nonmetric: two communities with no
shared species may have a dissimilarity slightly below one, and two
identical communities may have dissimilarity slightly above zero. The
index uses equal occurrence probabilities for all species, but Raup
and Crick originally suggested that sampling probabilities should be
proportional to species frequencies (Chase et al. 2011). A simulation
approach with unequal species sampling probabilities is implemented in
<code><a href="#topic+raupcrick">raupcrick</a></code> function following Chase et al. (2011).  The
index can be also used for transposed data to give a probabilistic
dissimilarity index of species co-occurrence (identical to Veech
2013).
</p>
<p>Chao index tries to take into account the number of unseen species
pairs, similarly as in <code>method = "chao"</code> in
<code><a href="#topic+specpool">specpool</a></code>. Function <code>vegdist</code> implements a
Jaccard, index defined as
<code class="reqn">1-\frac{U \times V}{U + V - U \times V}</code>;
other types can be defined with function <code><a href="#topic+chaodist">chaodist</a></code>. In Chao
equation, <code class="reqn">U = C_j/N_j + (N_k - 1)/N_k \times a_1/(2 a_2) \times
  S_j/N_j</code>,
and <code class="reqn">V</code> is similar except for site index
<code class="reqn">k</code>. <code class="reqn">C_j</code> is the total number of individuals in the
species of site <code class="reqn">j</code> that are shared with site <code class="reqn">k</code>,
<code class="reqn">N_j</code> is the total number of individuals at site <code class="reqn">j</code>,
<code class="reqn">a_1</code> (and <code class="reqn">a_2</code>) are the number of species
occurring in site <code class="reqn">j</code> that have only one (or two) individuals in
site <code class="reqn">k</code>, and <code class="reqn">S_j</code> is the total number of individuals
in the species present at site <code class="reqn">j</code> that occur with only one
individual in site <code class="reqn">k</code> (Chao et al. 2005).
</p>
<p>Morisita index can be used with genuine count data (integers) only. Its
Horn&ndash;Morisita variant is able to handle any abundance data.
</p>
<p>Mahalanobis distances are Euclidean distances of a matrix where
columns are centred, have unit variance, and are uncorrelated.  The
index is not commonly used for community data, but it is sometimes
used for environmental variables. The calculation is based on
transforming data matrix and then using Euclidean distances
following Mardia et al. (1979). The Mahalanobis transformation
usually fails when the number of columns is larger than the number
of rows (sampling units). When the transformation fails, the
distances are nearly constant except for small numeric noise. Users
must check that the returned Mahalanobis distances are meaningful.
</p>
<p>Euclidean and Manhattan dissimilarities are not good in gradient
separation without proper standardization but are still included for
comparison and special needs.
</p>
<p>Chi-square distances (<code>"chisq"</code>) are Euclidean distances of
Chi-square transformed data (see <code><a href="#topic+decostand">decostand</a></code>). This is
the internal standardization used in correspondence analysis
(<code><a href="#topic+cca">cca</a></code>, <code><a href="#topic+decorana">decorana</a></code>). Weighted principal
coordinates analysis of these distances with row sums as weights is
equal to correspondence analysis (see the Example in
<code><a href="#topic+wcmdscale">wcmdscale</a></code>). Chi-square distance is intended for
non-negative data, such as typical community data. However, it can
be calculated as long as all margin sums are positive, but warning
is issued on negative data entries.
</p>
<p>Chord distances (<code>"chord"</code>) are Euclidean distance of a matrix
where rows are standardized to unit norm (their sums of squares are 1)
using <code><a href="#topic+decostand">decostand</a></code>. Geometrically this standardization
moves row points to a surface of multidimensional unit sphere, and
distances are the chords across the hypersphere. Hellinger distances
(<code>"hellinger"</code>) are related to Chord distances, but data are
standardized to unit total (row sums are 1) using
<code><a href="#topic+decostand">decostand</a></code>, and then square root transformed. These
distances have upper limit of <code class="reqn">\sqrt{2}</code>.
</p>
<p>Bray&ndash;Curtis and Jaccard indices are rank-order similar, and some
other indices become identical or rank-order similar after some 
standardizations, especially with presence/absence transformation of
equalizing site totals with <code><a href="#topic+decostand">decostand</a></code>. Jaccard index is
metric, and probably should be preferred instead of the default
Bray-Curtis which is semimetric. 
</p>
<p>Aitchison distance (1986) and robust Aitchison distance
(Martino et al. 2019) are metrics that deal with
compositional data. Aitchison distance has been said to
outperform Jensen-Shannon divergence and Bray-Curtis dissimilarity,
due to a better stability to subsetting and aggregation, and it being a
proper distance (Aitchison et al., 2000).
</p>
<p>The naming conventions vary. The one adopted here is traditional
rather than truthful to priority. The function finds either
quantitative or binary variants of the indices under the same name,
which correctly may refer only to one of these alternatives For
instance, the Bray
index is known also as Steinhaus, Czekanowski and
S√∏rensen index.
The quantitative version of Jaccard should probably called
Ru≈æiƒçka index.
The abbreviation <code>"horn"</code> for the Horn&ndash;Morisita index is
misleading, since there is a separate Horn index. The abbreviation
will be changed if that index is implemented in <code>vegan</code>. 
</p>


<h3>Value</h3>

<p>Function is a drop-in replacement for <code><a href="stats.html#topic+dist">dist</a></code> function and
returns a distance object of the same type. The result object adds
attribute <code>maxdist</code> that gives the theoretical maximum of the
index for sampling units that share no species, or <code>NA</code> when
there is no such maximum.
</p>


<h3>Note</h3>

<p>The function is an alternative to <code><a href="stats.html#topic+dist">dist</a></code> adding some
ecologically meaningful indices.  Both methods should produce similar
types of objects which can be interchanged in any method accepting
either.  Manhattan and Euclidean dissimilarities should be identical
in both methods. Canberra index is divided by the number of variables
in <code>vegdist</code>, but not in <code><a href="stats.html#topic+dist">dist</a></code>.  So these differ by
a constant multiplier, and the alternative in <code>vegdist</code> is in
range (0,1).  Function <code><a href="cluster.html#topic+daisy">daisy</a></code> (package
<span class="pkg">cluster</span>) provides alternative implementation of Gower index that
also can handle mixed data of numeric and class variables.  There are
two versions of Gower distance (<code>"gower"</code>, <code>"altGower"</code>)
which differ in scaling: <code>"gower"</code> divides all distances by the
number of observations (rows) and scales each column to unit range,
but <code>"altGower"</code> omits double-zeros and divides by the number of
pairs with at least one above-zero value, and does not scale columns
(Anderson et al. 2006).  You can use <code><a href="#topic+decostand">decostand</a></code> to add
range standardization to <code>"altGower"</code> (see Examples). Gower
(1971) suggested omitting double zeros for presences, but it is often
taken as the general feature of the Gower distances. See Examples for
implementing the Anderson et al. (2006) variant of the Gower index.
</p>
<p>Most dissimilarity indices in <code>vegdist</code> are designed for
community data, and they will give misleading values if there are
negative data entries.  The results may also be misleading or
<code>NA</code> or <code>NaN</code> if there are empty sites.  In principle, you
cannot study species composition without species and you should remove
empty sites from community data.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen, with contributions from Tyler Smith (Gower index),
Michael Bedward (Raup&ndash;Crick index), and
Leo Lahti (Aitchison and robust Aitchison distance). </p>


<h3>References</h3>

<p>Aitchison, J. The Statistical Analysis of Compositional Data (1986).
London, UK: Chapman &amp; Hall.
</p>
<p>Aitchison, J., Barcel√≥-Vidal, C.,
Mart√≠n-Fern√°ndez, J.A., Pawlowsky-Glahn, V. (2000).
Logratio analysis and compositional distance.
<em>Math. Geol.</em> <strong>32</strong>, 271‚Äì275.
</p>
<p>Anderson, M.J. and Millar, R.B. (2004). Spatial variation and effects
of habitat on temperate reef fish assemblages in northeastern New
Zealand.  <em>Journal of Experimental Marine Biology and Ecology</em>
305, 191&ndash;221.
</p>
<p>Anderson, M.J., Ellingsen, K.E. &amp; McArdle, B.H. (2006). Multivariate
dispersion as a measure of beta diversity. <em>Ecology Letters</em> 
9, 683&ndash;693.
</p>
<p>Anderson, M.J &amp; Thompson, A.A. (2004). Multivariate control charts for
ecological and environmental monitoring. <em>Ecological
Applications</em> 14, 1921&ndash;1935.
</p>
<p>Cao, Y., Williams, W.P. &amp; Bark, A.W. (1997). Similarity measure bias
in river benthic Auswuchs community analysis. <em>Water
Environment Research</em> 69, 95&ndash;106.
</p>
<p>Chao, A., Chazdon, R. L., Colwell, R. K. and Shen, T. (2005). A new
statistical approach for assessing similarity of species composition
with incidence and abundance data. <em>Ecology Letters</em> 8, 148&ndash;159.
</p>
<p>Chase, J.M., Kraft, N.J.B., Smith, K.G., Vellend, M. and Inouye,
B.D. (2011). Using null models to disentangle variation in community
dissimilarity from variation in <code class="reqn">\alpha</code>-diversity.
<em>Ecosphere</em> 2:art24 <a href="https://doi.org/10.1890/ES10-00117.1">doi:10.1890/ES10-00117.1</a>
</p>
<p>Faith, D. P, Minchin, P. R. and Belbin, L. (1987).
Compositional dissimilarity as a robust measure of ecological
distance. <em>Vegetatio</em> 69, 57&ndash;68.
</p>
<p>Gower, J. C. (1971). A general coefficient of similarity and some
of its properties. <em>Biometrics</em> 27, 623&ndash;637.
</p>
<p>Krebs, C. J. (1999). <em>Ecological Methodology.</em> Addison Wesley
Longman.
</p>
<p>Legendre, P. &amp; De C√°ceres, M. (2012). Beta diversity as
the variance of community data: dissimilarity coefficients and
partitioning. <em>Ecology Letters</em> 16, 951&ndash;963.
<a href="https://doi.org/10.1111/ele.12141">doi:10.1111/ele.12141</a>
</p>
<p>Legendre, P. and Legendre, L. (2012) <em>Numerical Ecology</em>. 3rd English
ed. Elsevier.
</p>
<p>Mardia, K.V., Kent, J.T. and Bibby, J.M. (1979). <em>Multivariate analysis</em>.
Academic Press.
</p>
<p>Martino, C., Morton, J.T., Marotz, C.A., Thompson, L.R., Tripathi, A.,
Knight, R. &amp; Zengler, K. (2019) A novel sparse compositional technique
reveals microbial perturbations. <em>mSystems</em> <strong>4</strong>, 1.
</p>
<p>Mountford, M. D. (1962). An index of similarity and its application to
classification problems. In: P.W.Murphy (ed.),
<em>Progress in Soil Zoology</em>, 43&ndash;50. Butterworths.
</p>
<p>Veech, J. A. (2013). A probabilistic model for analysing species
co-occurrence. <em>Global Ecology and Biogeography</em> 22, 252&ndash;260. 
</p>
<p>Wolda, H. (1981). Similarity indices, sample size and
diversity. <em>Oecologia</em> 50, 296&ndash;302.
</p>


<h3>See Also</h3>

<p> Function <code><a href="#topic+designdist">designdist</a></code> can be used for defining
your own dissimilarity index.  Function <code><a href="#topic+betadiver">betadiver</a></code>
provides indices intended for the analysis of beta diversity.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
vare.dist &lt;- vegdist(varespec)
# Orl√≥ci's Chord distance: range 0 .. sqrt(2)
vare.dist &lt;- vegdist(decostand(varespec, "norm"), "euclidean")
# Anderson et al.  (2006) version of Gower
vare.dist &lt;- vegdist(decostand(varespec, "log"), "altGower")
# Range standardization with "altGower" (that excludes double-zeros)
vare.dist &lt;- vegdist(decostand(varespec, "range"), "altGower")
</code></pre>

<hr>
<h2 id='vegemite'>Display Compact Ordered Community Tables </h2><span id='topic+vegemite'></span><span id='topic+tabasco'></span><span id='topic+coverscale'></span>

<h3>Description</h3>

<p>Functions <code>vegemite</code> and <code>tabasco</code> display compact
community tables.  Function <code>vegemite</code> prints text tables where
species are rows, and each site takes only one column without
spaces.  Function <code>tabasco</code> provides interface for
<code><a href="stats.html#topic+heatmap">heatmap</a></code> for a colour <code><a href="Matrix.html#topic+image">image</a></code> of the
data. The community table can be ordered by explicit indexing, by
environmental variables or results from an ordination or cluster
analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vegemite(x, use, scale, sp.ind, site.ind, zero=".", select ,...)
tabasco(x, use, sp.ind = NULL, site.ind = NULL, select,
    Rowv = TRUE, Colv = TRUE, labRow = NULL, labCol = NULL,
    scale, col = heat.colors(12), ...)
coverscale(x, scale=c("Braun.Blanquet", "Domin", "Hult", "Hill", "fix","log"),
           maxabund, character = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vegemite_+3A_x">x</code></td>
<td>
<p>Community data. </p>
</td></tr>
<tr><td><code id="vegemite_+3A_use">use</code></td>
<td>
<p>Either a vector, or an object from <code>cca</code>,
<code>decorana</code> <em>etc.</em> or <code>hclust</code> or a
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code> for ordering sites and species.</p>
</td></tr>
<tr><td><code id="vegemite_+3A_sp.ind">sp.ind</code>, <code id="vegemite_+3A_site.ind">site.ind</code></td>
<td>
<p>Species and site indices. In <code>tabasco</code>,
these can also be <code><a href="stats.html#topic+hclust">hclust</a></code> tree,
<code><a href="cluster.html#topic+agnes">agnes</a></code> clusterings or
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code>s. </p>
</td></tr>
<tr><td><code id="vegemite_+3A_zero">zero</code></td>
<td>
<p>Character used for zeros. </p>
</td></tr>
<tr><td><code id="vegemite_+3A_select">select</code></td>
<td>
<p>Select a subset of sites.  This can be a logical vector
(<code>TRUE</code> for selected sites), or a vector of indices of selected
sites.  The order of indices does not influence results, but you
must specify <code>use</code> or <code>site.ind</code> to reorder sites.
</p>
</td></tr>
<tr><td><code id="vegemite_+3A_rowv">Rowv</code>, <code id="vegemite_+3A_colv">Colv</code></td>
<td>
<p>Re-order dendrograms for the rows (sites) or
columns (species) of <code>x</code>.  If the <code>Rowv = TRUE</code>, row
dendrograms are ordered by the first axis of correspondence
analysis, and when <code>Colv = TRUE</code> column dendrograms by the
weighted average (<code><a href="#topic+wascores">wascores</a></code>) of the row order.
Alternatively, the arguments can be vectors that are used to
reorder the dendrogram. </p>
</td></tr>
<tr><td><code id="vegemite_+3A_labrow">labRow</code>, <code id="vegemite_+3A_labcol">labCol</code></td>
<td>
<p>character vectors with row and column labels
used in the <code><a href="stats.html#topic+heatmap">heatmap</a></code> instead of the default. NB., the
input matrix is transposed so that row labels will be used for data
columns.</p>
</td></tr>
<tr><td><code id="vegemite_+3A_scale">scale</code></td>
<td>
<p>In <code>vegemite</code> and <code>coverscale</code>: cover scale
used (can be abbreviated). In <code>tabasco</code>: scaling of colours
in <code><a href="stats.html#topic+heatmap">heatmap</a></code>. The alternatives of <code>coverscale</code>
can be used in <code>tabasco</code>, and in addition <code>"column"</code> or
<code>"row"</code> scale columns or rows to equal maxima (NB., these
refer to the transposed data of the <code><a href="stats.html#topic+heatmap">heatmap</a></code>), while
<code>"none"</code> uses original values. </p>
</td></tr>
<tr><td><code id="vegemite_+3A_col">col</code></td>
<td>
<p>A vector of colours used for above-zero abundance values.</p>
</td></tr>
<tr><td><code id="vegemite_+3A_maxabund">maxabund</code></td>
<td>
<p>Maximum abundance used with <code>scale = "log"</code>.
Data maximum in the <code>select</code>ed subset will be used if this is
missing.</p>
</td></tr>
<tr><td><code id="vegemite_+3A_character">character</code></td>
<td>
<p>Return character codes suitable for
<code>vegemite</code>. If <code>FALSE</code>, returns corresponding
integers.</p>
</td></tr>
<tr><td><code id="vegemite_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>coverscale</code> (i.e., <code>maxabund</code>) in
<code>vegemite</code> and to <code><a href="stats.html#topic+heatmap">heatmap</a></code> in <code>tabasco</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>vegemite</code> prints a traditional community table.
The display is transposed, so that species are in rows and sites in
columns.  The table is printed in compact form: only one character
can be used for abundance, and there are no spaces between
columns. Species with no occurrences are dropped from the table.
</p>
<p>Function <code>tabasco</code> produces a similar table as <code>vegemite</code>
using <code><a href="stats.html#topic+heatmap">heatmap</a></code>, where abundances are coded by
colours. The function scales the abundances to equal intervals for
colour palette, but either rows or columns can be scaled to equal
maxima, or the <code>coverscale</code> class systems can be used. The
function can also display dendrograms for sites (columns) or species
if these are given as an argument (<code>use</code> for sites,
<code>sp.ind</code> for species).
</p>
<p>The parameter <code>use</code> will be used to re-order output. The
<code>use</code> can be a vector or an object from <code><a href="stats.html#topic+hclust">hclust</a></code> or
<code><a href="cluster.html#topic+agnes">agnes</a></code>, a <code><a href="stats.html#topic+dendrogram">dendrogram</a></code> or any
ordination result recognized by <code><a href="#topic+scores">scores</a></code> (all ordination
methods in <span class="pkg">vegan</span> and some of those not in <span class="pkg">vegan</span>). The
<code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="cluster.html#topic+agnes">agnes</a></code> and
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code> must be for sites. The dendrogram is
displayed above the sites in <code>tabasco</code>, but is not shown in
<code>vegemite</code>.  No dendrogram for species is displayed, except
when given in <code>sp.ind</code>.
</p>
<p>If <code>use</code> is a vector, it is used for ordering sites.  If
<code>use</code> is an object from ordination, both sites and species are
arranged by the first axis (provided that results are available both
also for species).  When <code>use</code> is an object from
<code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="cluster.html#topic+agnes">agnes</a></code> or a
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code>, the sites are ordered similarly as in the
cluster dendrogram.  Function <code>tabasco</code> re-orders the dendrogram
if <code>Rowv = TRUE</code> or <code>Rowv</code> is a vector. Such re-ordering is
not available for <code>vegemite</code>, but it can be done by hand using
<code><a href="stats.html#topic+reorder.dendrogram">reorder.dendrogram</a></code> or <code><a href="#topic+reorder.hclust">reorder.hclust</a></code>.
Please note that <code><a href="stats.html#topic+dendrogram">dendrogram</a></code> and <code><a href="stats.html#topic+hclust">hclust</a></code>
reordering can differ: unweighted means of merged branches are used in
<code><a href="stats.html#topic+dendrogram">dendrogram</a></code>, but weighted means (= means of leaves of the
cluster) are used in <code><a href="#topic+reorder.hclust">reorder.hclust</a></code>.  In all cases where
species scores are missing, species are ordered by their weighted
averages (<code><a href="#topic+wascores">wascores</a></code>) on site order.
</p>
<p>Species and sites can be ordered explicitly giving their indices or
names in parameters <code>sp.ind</code> and <code>site.ind</code>.  If these are
given, they take precedence over <code>use</code>. A subset of sites can
be displayed using argument <code>select</code>, but this cannot be used
to order sites, but you still must give <code>use</code> or
<code>site.ind</code>.  However, <code>tabasco</code> makes two exceptions:
<code>site.ind</code> and <code>select</code> cannot be used when <code>use</code> is
a dendrogram (clustering result). In addition, the <code>sp.ind</code> can
be an <code><a href="stats.html#topic+hclust">hclust</a></code> tree, <code><a href="cluster.html#topic+agnes">agnes</a></code>
clustering or a <code><a href="stats.html#topic+dendrogram">dendrogram</a></code>, and in that case the
dendrogram is plotted on the left side of the
<code><a href="stats.html#topic+heatmap">heatmap</a></code>. Phylogenetic trees cannot be directly used,
but package <span class="pkg">ape</span> has tools to transform these to
<code><a href="stats.html#topic+hclust">hclust</a></code> trees.
</p>
<p>If <code>scale</code> is given, <code>vegemite</code> calls <code>coverscale</code> to
transform percent cover scale or some other scales into traditional
class scales used in vegetation science (<code>coverscale</code> can be
called directly, too). Function <code>tabasco</code> can also use these
traditional class scales, but it treats the transformed values as
corresponding integers.  Braun-Blanquet and Domin scales are
actually not strict cover scales, and the limits used for codes
<code>r</code> and <code>+</code> are arbitrary.  Scale <code>Hill</code> may be
inappropriately named, since Mark O. Hill probably never intended
this as a cover scale.  However, it is used as default &ldquo;cut levels&rdquo;
in his <code>TWINSPAN</code>, and surprisingly many users stick to this
default, and this is a <em>de facto</em> standard in publications.
All traditional scales assume that values are cover percentages with
maximum 100.  However, non-traditional alternative <code>log</code> can be
used with any scale range.  Its class limits are integer powers of
1/2 of the maximum (argument <code>maxabund</code>), with <code>+</code> used
for non-zero entries less than 1/512 of the maximum (<code>log</code>
stands alternatively for logarithmic or logical).  Scale <code>fix</code>
is intended for &ldquo;fixing&rdquo; 10-point scales: it truncates scale values
to integers, and replaces 10 with <code>X</code> and positive values below
1 with <code>+</code>.  </p>


<h3>Value</h3>

<p>The functions are used mainly to display a table, but they return
(invisibly) a list with items <code>species</code> for ordered species
index, <code>sites</code> for ordered site index, and <code>table</code> for the
final ordered community table.
</p>
<p>These items can be used as arguments <code>sp.ind</code> and <code>site.ind</code>
to reproduce the table, or the <code>table</code> can be further edited. In
addition to the table, <code>vegemite</code> prints the numbers of species
and sites and the name of the used cover scale.
</p>


<h3>Note</h3>

<p>The name <code>vegemite</code> was chosen because the output is so
compact, and the <code>tabasco</code> because it is just as compact, but
uses heat colours.
</p>


<h3>Author(s)</h3>

<p>Jari Oksanen</p>


<h3>References</h3>

<p> The cover scales are presented in many textbooks of vegetation
science; I used:
</p>
<p>Shimwell, D.W. (1971) <em>The Description and Classification of
Vegetation</em>. Sidgwick &amp; Jackson.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code> and <code><a href="stats.html#topic+approx">approx</a></code> for making your
own &lsquo;cover scales&rsquo; for <code>vegemite</code>.  Function
<code>tabasco</code> is based on <code><a href="stats.html#topic+heatmap">heatmap</a></code> which in turn is
based on <code><a href="Matrix.html#topic+image">image</a></code>. Both functions order species with
weighted averages using <code><a href="#topic+wascores">wascores</a></code>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
## Print only more common species
freq &lt;- apply(varespec &gt; 0, 2, sum)
vegemite(varespec, scale="Hult", sp.ind = freq &gt; 10)
## Order by correspondence analysis, use Hill scaling and layout:
dca &lt;- decorana(varespec)
vegemite(varespec, dca, "Hill", zero="-")
## Show one class from cluster analysis, but retain the ordering above
clus &lt;- hclust(vegdist(varespec))
cl &lt;- cutree(clus, 3)
sel &lt;- vegemite(varespec, use=dca, select = cl == 3, scale="Br")
## Re-create previous
vegemite(varespec, sp=sel$sp, site=sel$site, scale="Hult")
## Re-order clusters by ordination
clus &lt;- as.dendrogram(clus)
clus &lt;- reorder(clus, scores(dca, choices=1, display="sites"), agglo.FUN = mean)
vegemite(varespec, clus, scale = "Hult")

## Abundance values have such a wide range that they must be rescaled
tabasco(varespec, dca, scale="Braun")

## Classification trees for species
data(dune, dune.taxon)
taxontree &lt;- hclust(taxa2dist(dune.taxon))
plotree &lt;- hclust(vegdist(dune), "average")
## Automatic reordering of clusters
tabasco(dune, plotree, sp.ind = taxontree)
## No reordering of taxonomy
tabasco(dune, plotree, sp.ind = taxontree, Colv = FALSE)
## Species cluster: most dissimilarity indices do a bad job when
## comparing rare and common species, but Raup-Crick makes sense
sptree &lt;- hclust(vegdist(t(dune), "raup"), "average")
tabasco(dune, plotree, sptree)
</code></pre>

<hr>
<h2 id='wascores'> Weighted Averages Scores for Species </h2><span id='topic+wascores'></span><span id='topic+eigengrad'></span>

<h3>Description</h3>

<p>Computes Weighted Averages scores of species for ordination
configuration or for environmental variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wascores(x, w, expand=FALSE)
eigengrad(x, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wascores_+3A_x">x</code></td>
<td>
<p>Environmental variables or ordination scores.</p>
</td></tr>
<tr><td><code id="wascores_+3A_w">w</code></td>
<td>
<p>Weights: species abundances.</p>
</td></tr>
<tr><td><code id="wascores_+3A_expand">expand</code></td>
<td>
<p>Expand weighted averages so that they have the same
weighted variance as the corresponding environmental variables.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>wascores</code> computes weighted averages. Weighted averages
&ldquo;shrink&rdquo;: they cannot be more extreme than values used for
calculating the averages. With <code>expand = TRUE</code>, the function
&ldquo;deshrinks&rdquo; the weighted averages by making their biased
weighted variance equal to the biased weighted variance of the
corresponding environmental variable.  Function <code>eigengrad</code>
returns the inverses of squared expansion factors or the attribute
<code>shrinkage</code> of the <code>wascores</code> result for each environmental
gradient.  This is equal to the constrained eigenvalue of
<code><a href="#topic+cca">cca</a></code> when only this one gradient was used as a
constraint, and describes the strength of the gradient.
</p>


<h3>Value</h3>

<p>Function <code>wascores</code> returns a matrix where species define rows
and ordination axes or environmental variables define columns. If
<code>expand = TRUE</code>, attribute <code>shrinkage</code> has the inverses of
squared expansion factors or <code><a href="#topic+cca">cca</a></code> eigenvalues for the
variable.  Function <code>eigengrad</code> returns only the <code>shrinkage</code>
attribute.
</p>


<h3>Author(s)</h3>

<p> Jari Oksanen </p>


<h3>See Also</h3>

 <p><code><a href="#topic+monoMDS">monoMDS</a></code>, <code><a href="#topic+cca">cca</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(varespec)
data(varechem)
vare.dist &lt;- vegdist(wisconsin(varespec))
vare.mds &lt;- monoMDS(vare.dist)
vare.points &lt;- postMDS(vare.mds$points, vare.dist)
vare.wa &lt;- wascores(vare.points, varespec)
plot(scores(vare.points), pch="+", asp=1)
text(vare.wa, rownames(vare.wa), cex=0.8, col="blue")
## Omit rare species (frequency &lt;= 4)
freq &lt;- apply(varespec&gt;0, 2, sum)
plot(scores(vare.points), pch="+", asp=1)
text(vare.wa[freq &gt; 4,], rownames(vare.wa)[freq &gt; 4],cex=0.8,col="blue")
## Works for environmental variables, too.
wascores(varechem, varespec)
## And the strengths of these variables are:
eigengrad(varechem, varespec)
</code></pre>

<hr>
<h2 id='wcmdscale'>Weighted Classical (Metric) Multidimensional Scaling</h2><span id='topic+wcmdscale'></span><span id='topic+scores.wcmdscale'></span><span id='topic+plot.wcmdscale'></span>

<h3>Description</h3>

<p>Weighted classical multidimensional scaling,
also known as weighted <em>principal coordinates analysis</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wcmdscale(d, k, eig = FALSE, add = FALSE, x.ret = FALSE, w)
## S3 method for class 'wcmdscale'
plot(x, choices = c(1, 2), type = "t", ...)
## S3 method for class 'wcmdscale'
scores(x, choices = NA, tidy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wcmdscale_+3A_d">d</code></td>
<td>
<p>a distance structure such as that returned by <code>dist</code>
or a full symmetric matrix containing the dissimilarities.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_k">k</code></td>
<td>
<p>the dimension of the space which the data are to be
represented in; must be in <code class="reqn">\{1,2,\ldots,n-1\}</code>.
If missing, all dimensions with above zero eigenvalue.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_eig">eig</code></td>
<td>
<p>indicates whether eigenvalues should be returned.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_add">add</code></td>
<td>
<p>an additive constant <code class="reqn">c</code> is added to the non-diagonal
dissimilarities such that all <code class="reqn">n-1</code> eigenvalues are
non-negative. Alternatives are <code>"lingoes"</code> (default, also
used with <code>TRUE</code>) and <code>"cailliez"</code> (which is the only
alternative in <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>). See Legendre &amp; Anderson
(1999).</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_x.ret">x.ret</code></td>
<td>
<p>indicates whether the doubly centred symmetric distance
matrix should be returned.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_w">w</code></td>
<td>
<p>Weights of points.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_x">x</code></td>
<td>
<p>The <code>wcmdscale</code> result object when the function was
called with options <code>eig = TRUE</code> or <code>x.ret = TRUE</code> (See
Details).</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_choices">choices</code></td>
<td>
<p>Axes to be returned; <code>NA</code> returns all real axes.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_type">type</code></td>
<td>
<p>Type of graph which may be <code>"t"</code>ext, <code>"p"</code>oints
or <code>"n"</code>one.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_tidy">tidy</code></td>
<td>
<p>Return scores that are compatible with <a href="https://CRAN.R-project.org/package=ggplot2"><span class="pkg">ggplot2</span></a>:
scores are in a <code><a href="base.html#topic+data.frame">data.frame</a></code>, score type is in the
variable <code>score</code> labelled as <code>"sites"</code>, weights in
variable <code>weigth</code>, and names in variable <code>label</code>.</p>
</td></tr>
<tr><td><code id="wcmdscale_+3A_...">...</code></td>
<td>
<p>Other arguments passed to graphical functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>wcmdscale</code> is based on function
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code> (package <span class="pkg">stats</span> of base <span class="rlang"><b>R</b></span>), but it uses
point weights. Points with high weights will have a stronger
influence on the result than those with low weights. Setting equal
weights <code>w = 1</code> will give ordinary multidimensional scaling.
</p>
<p>With default options, the function returns only a matrix of scores
scaled by eigenvalues for all real axes. If the function is called
with <code>eig = TRUE</code> or <code>x.ret = TRUE</code>, the function returns
an object of class <code>"wcmdscale"</code> with <code>print</code>,
<code>plot</code>, <code>scores</code>, <code><a href="#topic+eigenvals">eigenvals</a></code> and
<code><a href="#topic+stressplot">stressplot</a></code> methods, and described in section Value.
</p>
<p>The method is Euclidean, and with non-Euclidean dissimilarities some
eigenvalues can be negative. If this disturbs you, this can be
avoided by adding a constant to non-diagonal dissimilarities making
all eigenvalues non-negative. The function implements methods
discussed by Legendre &amp; Anderson (1999): The method of Lingoes
(<code>add="lingoes"</code>) adds the constant <code class="reqn">c</code> to squared
dissimilarities <code class="reqn">d</code> using <code class="reqn">\sqrt{d^2 + 2 c}</code>
and the method of Cailliez (<code>add="cailliez"</code>) to
dissimilarities using <code class="reqn">d + c</code>. Legendre &amp; Anderson (1999)
recommend the method of Lingoes, and base <span class="rlang"><b>R</b></span> function
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code> implements the method of Cailliez.
</p>


<h3>Value</h3>

<p> If <code>eig = FALSE</code> and <code>x.ret = FALSE</code> (default), a
matrix with <code>k</code> columns whose rows give the coordinates of
points corresponding to positive eigenvalues.  Otherwise, an object
of class <code>wcmdscale</code> containing the components that are mostly
similar as in <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>:
</p>
<table>
<tr><td><code>points</code></td>
<td>
<p>a matrix with <code>k</code> columns whose rows give the
coordinates of the points chosen to represent the
dissimilarities.</p>
</td></tr>
<tr><td><code>eig</code></td>
<td>
<p>the <code class="reqn">n-1</code> eigenvalues computed during the scaling
process if <code>eig</code> is true.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>the doubly centred and weighted distance matrix if
<code>x.ret</code> is true.</p>
</td></tr>
<tr><td><code>ac</code>, <code>add</code></td>
<td>
<p>additive constant and adjustment method used to avoid
negative eigenvalues. These are <code>NA</code> and <code>FALSE</code> if no
adjustment was done.</p>
</td></tr>
<tr><td><code>GOF</code></td>
<td>
<p>Goodness of fit statistics for <code>k</code> axes. The first
value is based on the sum of absolute values of all eigenvalues,
and the second value is based on the sum of positive eigenvalues</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Weights.</p>
</td></tr>
<tr><td><code>negaxes</code></td>
<td>
<p>A matrix of scores for axes with negative eigenvalues
scaled by the absolute eigenvalues similarly as
<code>points</code>. This is <code>NULL</code> if there are no negative
eigenvalues or <code>k</code> was specified, and would not include
negative eigenvalues.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Function call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gower, J. C. (1966)
Some distance properties of latent root and vector
methods used in multivariate analysis.
<em>Biometrika</em> <b>53</b>, 325&ndash;328.
</p>
<p>Legendre, P. &amp; Anderson, M. J. (1999). Distance-based redundancy
analysis: testing multispecies responses in multifactorial
ecological experiments. <em>Ecology</em> <b>69</b>, 1&ndash;24.
</p>
<p>Mardia, K. V., Kent, J. T. and Bibby, J. M. (1979).  Chapter 14 of
<em>Multivariate Analysis</em>, London: Academic Press.
</p>


<h3>See Also</h3>

<p>The function is modelled after <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, but adds
weights (hence name) and handles negative eigenvalues differently.
<code><a href="#topic+eigenvals.wcmdscale">eigenvals.wcmdscale</a></code> and
<code><a href="#topic+stressplot.wcmdscale">stressplot.wcmdscale</a></code> are some specific methods. Other
multidimensional scaling methods are <code><a href="#topic+monoMDS">monoMDS</a></code>, and
<code><a href="MASS.html#topic+isoMDS">isoMDS</a></code> and <code><a href="MASS.html#topic+sammon">sammon</a></code> in package
<span class="pkg">MASS</span>.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Correspondence analysis as a weighted principal coordinates
## analysis of Euclidean distances of Chi-square transformed data
data(dune)
rs &lt;- rowSums(dune)/sum(dune)
d &lt;- dist(decostand(dune, "chi"))
ord &lt;- wcmdscale(d, w = rs, eig = TRUE)
## Ordinary CA
ca &lt;- cca(dune)

## IGNORE_RDIFF_BEGIN
## Eigevalues are numerically similar
ca$CA$eig - ord$eig
## Configurations are similar when site scores are scaled by
## eigenvalues in CA
procrustes(ord, ca, choices=1:19, scaling = "sites")
## IGNORE_RDIFF_END

plot(procrustes(ord, ca, choices=1:2, scaling="sites"))
## Reconstruction of non-Euclidean distances with negative eigenvalues
d &lt;- vegdist(dune)
ord &lt;- wcmdscale(d, eig = TRUE)
## Only positive eigenvalues:
cor(d, dist(ord$points))
## Correction with negative eigenvalues:
cor(d, sqrt(dist(ord$points)^2 - dist(ord$negaxes)^2))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
