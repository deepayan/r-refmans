<!DOCTYPE html><html lang="en"><head><title>Help for package NPCDTools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NPCDTools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AAR'><p>Attribute-wise agreement rate</p></a></li>
<li><a href='#bestQperm'><p>Column permutation of the estimated Q-matrix</p></a></li>
<li><a href='#correction.rate'><p>Correction rate of a Q-matrix refinement method</p></a></li>
<li><a href='#GNPC'><p>Estimation of examinees' attribute profiles using the GNPC method</p></a></li>
<li><a href='#NPC'><p>Estimation of  examinees' attribute profiles using the NPC method</p></a></li>
<li><a href='#PAR'><p>Pattern-wise agreement rate</p></a></li>
<li><a href='#Q.generate'><p>Generation of Dichotomous Q-Matrix</p></a></li>
<li><a href='#QR'><p>Refine the Q-matrix by Minimizing the RSS</p></a></li>
<li><a href='#retention.rate'><p>Retention rate of a Q-matrix refinement method</p></a></li>
<li><a href='#RR'><p>Entry-wise and vector-wise recovery rates</p></a></li>
<li><a href='#TSQE'><p>Two-step Q-matrix Estimation Method</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>The Nonparametric Classification Methods for Cognitive Diagnosis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical tools for analyzing cognitive diagnosis (CD) data collected from small settings using the nonparametric classification (NPCD) framework. The core methods of the NPCD framework includes the nonparametric classification (NPC) method developed by Chiu and Douglas (2013) &lt;<a href="https://doi.org/10.1007%2Fs00357-013-9132-9">doi:10.1007/s00357-013-9132-9</a>&gt; and the general NPC (GNPC) method developed by Chiu, Sun, and Bian (2018) &lt;<a href="https://doi.org/10.1007%2Fs11336-017-9595-4">doi:10.1007/s11336-017-9595-4</a>&gt; and Chiu and Köhn (2019) &lt;<a href="https://doi.org/10.1007%2Fs11336-019-09660-x">doi:10.1007/s11336-019-09660-x</a>&gt;. An extension of the NPCD framework included in the package is the nonparametric method for multiple-choice items (MC-NPC) developed by Wang, Chiu, and Koehn (2023) &lt;<a href="https://doi.org/10.3102%2F10769986221133088">doi:10.3102/10769986221133088</a>&gt;.  Functions associated with various extensions concerning the evaluation, validation, and feasibility of the CD analysis are also provided. These topics include the completeness of Q-matrix, Q-matrix refinement method, as well as Q-matrix estimation. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>GDINA, NPCD, psych, SimDesign, stats, utils, gtools</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-20 14:28:22 UTC; weixuan</td>
</tr>
<tr>
<td>Author:</td>
<td>Chia-Yi Chiu [aut, cph],
  Weixuan Xiao [aut, cre],
  Xiran Wen [aut],
  Yu Wang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Weixuan Xiao &lt;wx2299@tc.columbia.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-23 13:01:53 UTC</td>
</tr>
</table>
<hr>
<h2 id='AAR'>Attribute-wise agreement rate</h2><span id='topic+AAR'></span>

<h3>Description</h3>

<p>The function is used to compute the attribute-wise agreement rate between
two sets of attribute profiles. They need to have the same dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AAR(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AAR_+3A_x">x</code></td>
<td>
<p>One set of attribute profiles</p>
</td></tr>
<tr><td><code id="AAR_+3A_y">y</code></td>
<td>
<p>The other set of attribute profiles</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the attribute-wise agreement rate between two sets of attribute profiles.
</p>

<hr>
<h2 id='bestQperm'>Column permutation of the estimated Q-matrix</h2><span id='topic+bestQperm'></span>

<h3>Description</h3>

<p>Function <code>bestQperm</code> is used to rearrange the columns of the estimated Q so that
the order of the columns best matches that of the true Q-matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bestQperm(estQ, trueQ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bestQperm_+3A_estq">estQ</code></td>
<td>
<p>The estimated Q-matrix.</p>
</td></tr>
<tr><td><code id="bestQperm_+3A_trueq">trueQ</code></td>
<td>
<p>The true Q-matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a Q-matrix in which the order of the columns best matches
that of the true Q-matrix.
</p>

<hr>
<h2 id='correction.rate'>Correction rate of a Q-matrix refinement method</h2><span id='topic+correction.rate'></span>

<h3>Description</h3>

<p>This function computes the proportion of corrected q-entries that
were originally misspecified in the provisional Q-matrix. This function is used
only when the true Q-matrix is known.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correction.rate(ref.Q = ref.Q, mis.Q = mis.Q, true.Q = true.Q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="correction.rate_+3A_ref.q">ref.Q</code></td>
<td>
<p>the <code class="reqn">J \times K</code> binary Q-matrix obtained from applying the refinement procedure.</p>
</td></tr>
<tr><td><code id="correction.rate_+3A_mis.q">mis.Q</code></td>
<td>
<p>A <code class="reqn">J \times K</code> binary provisional Q-matrix.</p>
</td></tr>
<tr><td><code id="correction.rate_+3A_true.q">true.Q</code></td>
<td>
<p>The <code class="reqn">J \times K</code> binary true Q-matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a value between 0 and 1 indicating the proportion of corrected q-entries in <code>ref.Q</code>
that were originally missepcified in <code>mis.Q</code>.
</p>

<hr>
<h2 id='GNPC'>Estimation of examinees' attribute profiles using the GNPC method</h2><span id='topic+GNPC'></span>

<h3>Description</h3>

<p>Function <code>GNPC</code> is used to estimate examinees' attribute profiles using
the general nonparametric classification (GNPC) method
(Chiu, Sun, &amp; Bian, 2018; Chiu &amp; Koehn, 2019). It can be
used with data conforming to any CDMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GNPC(
  Y,
  Q,
  initial.dis = c("hamming", "whamming"),
  initial.gate = c("AND", "OR", "Mix")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GNPC_+3A_y">Y</code></td>
<td>
<p>A <code class="reqn">N \times J</code> binary data matrix consisting of the responses
from <code class="reqn">N</code> examinees to <code class="reqn">J</code> items.</p>
</td></tr>
<tr><td><code id="GNPC_+3A_q">Q</code></td>
<td>
<p>A <code class="reqn">J \times K</code> binary Q-matrix where the entry <code class="reqn">q_{jk}</code>
describing whether the <code class="reqn">k</code>th attribute is required by the <code class="reqn">j</code>th item.</p>
</td></tr>
<tr><td><code id="GNPC_+3A_initial.dis">initial.dis</code></td>
<td>
<p>The type of distance used in the <code>AlphaNP</code> to carry
out the initial attribute profiles for the GNPC method.
Allowable options are <code>"hamming"</code> and <code>"whamming"</code> representing
the Hamming and the weighted Hamming distances, respectively.</p>
</td></tr>
<tr><td><code id="GNPC_+3A_initial.gate">initial.gate</code></td>
<td>
<p>The type of relation between examinees' attribute profiles
and the items.
Allowable relations are <code>"AND"</code>, <code>"OR"</code>, and <code>"Mix"</code>,
representing the conjunctive, disjunctive, and mixed relations, respectively</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a series of outputs, including
</p>

<dl>
<dt>att.est</dt><dd><p>The estimates of examinees' attribute profiles</p>
</dd>
<dt>class</dt><dd><p>The estimates of examinees' class memberships</p>
</dd>
<dt>weighted.ideal</dt><dd><p>The weighted ideal responses</p>
</dd>
<dt>weight</dt><dd><p>The weights used to compute the weighted ideal responses</p>
</dd>
</dl>



<h3>GNPC algorithm</h3>

<p>A weighted ideal response <code class="reqn">\eta^{(w)}</code>, defined as the convex combination
of <code class="reqn">\eta^(c)</code> and <code class="reqn">\eta^(d)</code>, is proposed.
Suppose item j requires <code class="reqn">K_{j}^* \leq {K}</code> attributes that, without loss of
generality, have been permuted to the first <code class="reqn">K_{j}^*</code> positions of the item
attribute vector <code class="reqn">\boldsymbol{q_j}</code>. For each item j and <code class="reqn">\mathcal{C}_{l}</code>,
the weighted ideal response <code class="reqn">\eta_{ij}^{(w)}</code> is defined as the convex combination
<code class="reqn">\eta_{ij}^{(w)} = w _{lj} \eta_{lj}^{(c)}+(1-w_{lj})\eta_{lj}^{(d)}</code>
where <code class="reqn">0\leq w_{lj}\leq 1</code>. The distance between the observed responses
to item j and the weighted ideal responses <code class="reqn">w_{lj}^{(w)}</code> of examinees
in <code class="reqn">\mathcal{C}_{l}</code> is defined as the sum of squared deviations:
<code class="reqn">d_{lj} = \sum_{i \in \mathcal {C}_{l}} (y_{ij} - \eta_{lj}^{(w)})^2=\sum_{i \in \mathcal {C}_{l}}(y_{ij}-w_{lj}\eta_{lj}^{(c)}-(1-w_{lj})\eta_{lj}^{(d)})</code>
Thus, <code class="reqn">\widehat{w_{lj}}</code> can be minimizing <code class="reqn">d_{lj}</code>:
<code class="reqn">\widehat{w_{lj}}=\frac{\sum_{i \in \mathcal {C}_{l}}(y_{ij}-\eta_{lj}^{(d)})}{\left \| \mathcal{C}_{l} \right \|(\eta_{lj}^{(c)}-\eta_{lj}^{(d)})}</code>
</p>
<p>As a viable alternative to <code class="reqn">\boldsymbol{\eta^{(c)}}</code> for obtaining initial
estimates of the proficiency classes, Chiu et al. (2018) suggested to
use an ideal response with fixed weights defined as
<code class="reqn">\eta_{lj}^{(fw)}=\frac{\sum_{k=1}^{K}\alpha_{k}q_{jk}}{K}\eta_{lj}^{(c)}+(1-\frac{\sum_{k=1}^{K}\alpha_{k}q_{jk}}{K})\eta_{lj}^{(d)}</code>
</p>

<hr>
<h2 id='NPC'>Estimation of  examinees' attribute profiles using the NPC method</h2><span id='topic+NPC'></span>

<h3>Description</h3>

<p>The function is used to estimate examinees' attribute profiles
using the nonparametric classification (NPC) method (Chiu, &amp; Douglas, 2013).
It uses a distance-based algorithm on the observed item responses for
classifying examiness. This function estimates attribute profiles using
nonparametric approaches for both the &quot;AND gate&quot; (conjunctive) and the
&quot;OR gate&quot; (disjunctive) cognitive diagnostic models. These algorithms select
the attribute profile with the smallest loss function value (plain,
weighted, or penalized Hamming distance, see below for details) as the
estimate. If more than one attribute profiles have the smallest loss
function value, one of them is randomly chosen.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NPC(
  Y,
  Q,
  gate = c("AND", "OR"),
  method = c("Hamming", "Weighted", "Penalized"),
  wg = 1,
  ws = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NPC_+3A_y">Y</code></td>
<td>
<p>A matrix of binary responses. Rows represent persons and columns
represent items. 1=correct, 0=incorrect.</p>
</td></tr>
<tr><td><code id="NPC_+3A_q">Q</code></td>
<td>
<p>The Q-matrix of the test. Rows represent items and columns represent
attributes. 1=attribute required by the item, 0=attribute not required
by the item.</p>
</td></tr>
<tr><td><code id="NPC_+3A_gate">gate</code></td>
<td>
<p>A character string specifying the type of gate. It can be one of
the following:
</p>

<dl>
<dt>&quot;AND&quot;</dt><dd><p>The examinee needs to possess all required attributes of an
item in order to answer it correctly.</p>
</dd>
<dt>&quot;OR&quot;</dt><dd><p>The examinee needs to possess only one of the required
attributes of an item in order to answer it correctly.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="NPC_+3A_method">method</code></td>
<td>
<p>The method of nonparametric estimation.
</p>

<dl>
<dt>&quot;Hamming&quot;</dt><dd><p>The plain Hamming distance method</p>
</dd>
<dt>&quot;Weighted&quot;</dt><dd><p>The Hamming distance weighted by inversed item variance</p>
</dd>
<dt>&quot;Penalized&quot;</dt><dd><p>The Hamming distance weighted by inversed item variance
and specified penalizing weights for guess and slip.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="NPC_+3A_wg">wg</code></td>
<td>
<p>Additional argument for the &quot;penalized&quot; method.
It is the weight assigned to guessing in the DINA or DINO models. A large
value of weight results in a stronger impact on
Hamming distance (larger loss function values) caused by guessing.</p>
</td></tr>
<tr><td><code id="NPC_+3A_ws">ws</code></td>
<td>
<p>Additional input for the &quot;penalized&quot; method.
It is the weight assigned to slipping in the DINA or DINO models.
A large value of weight results in la stronger impact on Hamming
distance (larger loss function values) caused by slipping.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a series of outputs, including:
</p>

<dl>
<dt>alpha.est</dt><dd><p>Estimated attribute profiles. Rows represent persons
and columns represent attributes.
1=examinee masters the attribute, 0=examinee does not master the attribute.</p>
</dd>
<dt>est.ideal</dt><dd><p>Estimated ideal response to all items by all examinees.
Rows represent persons and columns represent items.
1=correct, 0=incorrect.</p>
</dd>
<dt>est.class</dt><dd><p>The class number (row index in pattern) for each person's
attribute profile.
It can also be used for locating the loss function value in loss.matrix
for the estimated attribute profile for each person.</p>
</dd>
<dt>n.tie</dt><dd><p>Number of ties in the Hamming distance among the candidate
attribute profiles for each person. When we encounter ties, one of
the tied attribute profiles is randomly chosen.</p>
</dd>
<dt>pattern</dt><dd><p>All possible attribute profiles in the search space.</p>
</dd>
<dt>loss.matrix</dt><dd><p>The matrix of the values for the loss function (the
plain, weighted, or penalized Hamming distance).
Rows represent candidate attribute profiles in the same order with
the pattern matrix; columns represent different examinees.</p>
</dd>
</dl>



<h3>NPC algorithm with three distacne methods</h3>

<p>Proficiency class membership is determined by comparing an examinee's
observed item response vector <code class="reqn">\boldsymbol{Y}</code> with each of the ideal
item response vectors of the realizable <code class="reqn">2^K=M</code> proficiency classes.
The ideal item responses are a function of the Q-matrix and the attribute
vectors characteristic of the different proficiency classes. Hence, an
examinee’s proficiency class is identified by the attribute vector
<code class="reqn">\boldsymbol{\alpha}_{m}</code> underlying that ideal item response vector
which is closest—or most similar—to an examinee’s observed item response
vector. The ideal response to item j is the score that would be obtained
by an examinee if no perturbation occurred.
</p>
<p>Let <code class="reqn">\boldsymbol{\eta}_{i}</code> denote the J-dimensional ideal item response
vector of examinee i, and the <code class="reqn">\hat{\boldsymbol{\alpha}}</code> of an
examinee’s attribute vector is defined as the attribute vector
underlying the ideal item response vector that among all ideal item response
vectors minimizes the distance to an examinee’s observed item response vector:
<code class="reqn">\hat{\boldsymbol{\alpha}} = \arg\min_{m \in \{1,2,\ldots,M\}} d(\boldsymbol{y_i}, \boldsymbol{\eta}_{m})</code>
</p>
<p>A distance measure often used for clustering binary data is the Hamming
distance that simply counts the number of disagreements between two vectors:
<code class="reqn">d_H(\boldsymbol{y,\eta}) =  \sum_{j=1}^{J} | y_j - \eta_j |</code>
</p>
<p>If the different levels of variability in the item responses are to be
incorporated, then the Hamming distances can be weighted, for example, by the
inverse of the item sample variance, which allows for larger impact on the
distance functions of items with smaller variance:
<code class="reqn">d_{wH} (\boldsymbol{y,\eta}) = \sum_{j=1}^{J} \frac{1}{\overline{p_j}(1-\overline{p_j})} |y_j-\eta_j|</code>
</p>
<p>Weighting weighting differently for departures from the ideal response model
that would result from slips versus guesses is also considered:
<code class="reqn">d_{gs}(\boldsymbol{y,\eta})=\sum_{j=1}^{J} w_gI[y_j=1]|y_j-\eta_j|+\sum_{j=1}^{J}w_sI[y_j=0]|y_j-\eta_j|</code>
</p>


<h3>References</h3>

<p>Chiu, C. (2011). Flexible approaches to cognitive diagnosis: nonparametric methods and small sample techniques.
Invited session of cognitive diagnosis and item response theory at 2011 Joint Statistical Meeting.
</p>
<p>Chiu, C. Y., &amp; Douglas, J. A. (2013). A nonparametric approach to cognitive diagnosis by proximity to ideal response patterns.
Journal of Classification 30(2), 225-250.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate item and examinee profiles

natt &lt;- 3
nitem &lt;- 4
nperson &lt;- 5
Q &lt;- rbind(c(1, 0, 0), c(0, 1, 0), c(0, 0, 1), c(1, 1, 1))
alpha &lt;- rbind(c(0, 0, 0), c(1, 0, 0), c(0, 1, 0), c(0, 0, 1), c(1, 1, 1))

# Generate DINA model-based response data
slip &lt;- c(0.1, 0.15, 0.2, 0.25)
guess &lt;- c(0.1, 0.15, 0.2, 0.25)
my.par &lt;- list(slip=slip, guess=guess)
data &lt;- matrix(NA, nperson, nitem)
eta &lt;- matrix(NA, nperson, nitem)
for (i in 1:nperson) {
  for (j in 1:nitem) {
    eta[i, j] &lt;- prod(alpha[i,] ^ Q[j, ])
    P &lt;- (1 - slip[j]) ^ eta[i, j] * guess[j] ^ (1 - eta[i, j])
    u &lt;- runif(1)
    data[i, j] &lt;- as.numeric(u &lt; P)
    }
}

# Using the function to estimate examinee attribute profile
alpha.est.NP.H &lt;- NPC(data, Q, gate="AND", method="Hamming")
alpha.est.NP.W &lt;- NPC(data, Q, gate="AND", method="Weighted")
alpha.est.NP.P &lt;- NPC(data, Q, gate="AND", method="Penalized", wg=2, ws=1)

nperson &lt;- 1   # Choose an examinee to investigate
print(alpha.est.NP.H) # Print the estimated examinee attribute profiles
</code></pre>

<hr>
<h2 id='PAR'>Pattern-wise agreement rate</h2><span id='topic+PAR'></span>

<h3>Description</h3>

<p>The function is used to compute the pattern-wise agreement rate between two sets of
attribute profiles. They need to have the same dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PAR(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PAR_+3A_x">x</code></td>
<td>
<p>One set of attribute profiles</p>
</td></tr>
<tr><td><code id="PAR_+3A_y">y</code></td>
<td>
<p>The other set of attribute profiles</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the pattern-wise agreement rate between two sets of attribute profiles.
</p>

<hr>
<h2 id='Q.generate'>Generation of Dichotomous Q-Matrix</h2><span id='topic+Q.generate'></span>

<h3>Description</h3>

<p>The function generates a complete Q-matrix based on a
pre-specified probability of getting a one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Q.generate(K, J, p, single.att = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Q.generate_+3A_k">K</code></td>
<td>
<p>The number of attributes</p>
</td></tr>
<tr><td><code id="Q.generate_+3A_j">J</code></td>
<td>
<p>The number of items</p>
</td></tr>
<tr><td><code id="Q.generate_+3A_p">p</code></td>
<td>
<p>The probability of getting a one in the Q-matrix</p>
</td></tr>
<tr><td><code id="Q.generate_+3A_single.att">single.att</code></td>
<td>
<p>Whether all the single attribute patterns are included.
If <code>T</code>, the completeness of the Q-matrix is guaranteed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a complete dichotomous Q-matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>q = Q.generate(3,20,0.5,single.att = TRUE)
q1 = Q.generate(5,30,0.6,single.att = FALSE)

</code></pre>

<hr>
<h2 id='QR'>Refine the Q-matrix by Minimizing the RSS</h2><span id='topic+QR'></span>

<h3>Description</h3>

<p>We estimate memberships using the non-parametric classification
method (weighted hamming), and comparisons of the residual sum of squares
computed from the observed and the ideal item responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QR(Y, Q, gate = c("AND", "OR"), max.ite = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QR_+3A_y">Y</code></td>
<td>
<p>A matrix of binary responses (1=correct, 0=incorrect). Rows
represent persons and columns represent items.</p>
</td></tr>
<tr><td><code id="QR_+3A_q">Q</code></td>
<td>
<p>The Q-matrix of the test. Rows represent items and columns
represent attributes.</p>
</td></tr>
<tr><td><code id="QR_+3A_gate">gate</code></td>
<td>
<p>A string, &quot;AND&quot; or &quot;OR&quot;. &quot;AND&quot;: the examinee needs to possess
all related attributes to answer an item correctly.
&quot;OR&quot;: the examinee needs to possess only one of the related attributes
to answer an item correctly.</p>
</td></tr>
<tr><td><code id="QR_+3A_max.ite">max.ite</code></td>
<td>
<p>The number of iterations to run until all RSS of all items
are stationary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>initial.class</code></td>
<td>
<p>Initial classification</p>
</td></tr>
<tr><td><code>terminal.class</code></td>
<td>
<p>Terminal classification</p>
</td></tr>
<tr><td><code>modified.Q</code></td>
<td>
<p>The modified Q-matrix</p>
</td></tr>
<tr><td><code>modified.entries</code></td>
<td>
<p>The modified q-entries</p>
</td></tr>
</table>


<h3>The Q-Matrix Refinment (QR) Method</h3>

<p>This function implements the Q-matrix refinement method developed by Chiu
(2013), which is also based on the aforementioned nonparametric classification
methods (Chiu &amp; Douglas, 2013). This Q-matrix refinement method corrects
potential misspecified entries of the Q-matrix through comparisons of the
residual sum of squares computed from the observed and the ideal item responses.
</p>
<p>The algorithm operates by minimizing the RSS. Recall that <code class="reqn">Y_{ij}</code> is the
observed response and <code class="reqn">\eta_{ij}</code> is the ideal response.
Then the RSS of item <code class="reqn">j</code> for examinee <code class="reqn">i</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">RSS_{ij} = (Y_{ij} - \eta_{ij})^2</code>
</p>
<p>.
The RSS of item <code class="reqn">j</code> across all examinees is therefor
</p>
<p style="text-align: center;"><code class="reqn">RSS_{j} = \sum_{i=1}^{N} (Y_{ij} - \eta_{ij})^2 = \sum_{m=1}^{2^k} \sum_{i \in C_{m}} (Y_{ij} - \eta_{jm})^2</code>
</p>

<p>where <code class="reqn">C_m</code> is the latent proficiency-class <code class="reqn">m</code>, and <code class="reqn">N</code>
is the number of examinees. Chiu(2013) proved that the expectation of
<code class="reqn">RSS_j</code> is minimized for the correct q-vector among the
<code class="reqn">2^K - 1</code> candidates. Please see the paper for the justification.
</p>


<h3>References</h3>

<p>Chiu, C. Y. (2013). Statistical Refinement of the Q-matrix in Cognitive Diagnosis. <em>Applied Psychological Measurement, 37(8)</em>, 598-618.
</p>

<hr>
<h2 id='retention.rate'>Retention rate of a Q-matrix refinement method</h2><span id='topic+retention.rate'></span>

<h3>Description</h3>

<p>This function computes the proportion of correctly specified q-entries
in a provisional Q-matrix that remain correctly specified after a Q-matrix refinement
procedure is applied. This function is used only when the true Q-matrix is known.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>retention.rate(ref.Q = ref.Q, mis.Q = mis.Q, true.Q = true.Q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="retention.rate_+3A_ref.q">ref.Q</code></td>
<td>
<p>the <code class="reqn">J \times K</code> binary Q-matrix obtained from applying a refinement procedure.</p>
</td></tr>
<tr><td><code id="retention.rate_+3A_mis.q">mis.Q</code></td>
<td>
<p>A <code class="reqn">J \times K</code> binary provisional Q-matrix.</p>
</td></tr>
<tr><td><code id="retention.rate_+3A_true.q">true.Q</code></td>
<td>
<p>The <code class="reqn">J \times K</code> binary true Q-matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a value between 0 and 1 indicating the proportion of
correctly specified q-entries in <code>mis.Q</code> that remain correctly specified in <code>ref.Q</code>
after a Q-matrix refinement procedure is applied to <code>mis.Q</code>.
</p>

<hr>
<h2 id='RR'>Entry-wise and vector-wise recovery rates</h2><span id='topic+RR'></span>

<h3>Description</h3>

<p>Function <code>RR</code> is used to compute the recovery rates for an estimate Q-matrix.
In general, it can be used to compute the agreement rate between two matrices with identical dimensionalities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RR(Q1, Q2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RR_+3A_q1">Q1</code></td>
<td>
<p>The first Q-matrix.</p>
</td></tr>
<tr><td><code id="RR_+3A_q2">Q2</code></td>
<td>
<p>The second Q-matrix that has the same dimensionality as Q1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns
</p>

<dl>
<dt>entry.wise</dt><dd><p>The entry-wise recovery rate</p>
</dd>
<dt>item.wise</dt><dd><p>The item-wise recovery rate</p>
</dd>
</dl>


<hr>
<h2 id='TSQE'>Two-step Q-matrix Estimation Method</h2><span id='topic+TSQE'></span>

<h3>Description</h3>

<p>The function is used to estimate the Q-matrix based on the
data (responses) using the two-step Q-matrix estimation method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSQE(
  Y,
  K,
  input.cor = c("tetrachoric", "Pearson"),
  ref.method = c("QR", "GDI"),
  GDI.model = c("DINA", "ACDM", "RRUM", "GDINA"),
  cutoff = 0.8
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TSQE_+3A_y">Y</code></td>
<td>
<p>A <code class="reqn">N \times J</code> binary data matrix consisting of responses
from <code class="reqn">N</code> examinees to <code class="reqn">J</code> items</p>
</td></tr>
<tr><td><code id="TSQE_+3A_k">K</code></td>
<td>
<p>The number of attributes in the Q-matrix</p>
</td></tr>
<tr><td><code id="TSQE_+3A_input.cor">input.cor</code></td>
<td>
<p>The type of correlation used to compute the input for the
exploratory factor analysis. It could be the tetrachoric or Pearson correlation.</p>
</td></tr>
<tr><td><code id="TSQE_+3A_ref.method">ref.method</code></td>
<td>
<p>The refinement method use to polish the provisional
Q-matrix obtained from the EFA. Currently available methods include
the Q-matrix refinement (QR) method and the G-DINA discrimination index (GDI).</p>
</td></tr>
<tr><td><code id="TSQE_+3A_gdi.model">GDI.model</code></td>
<td>
<p>The CDM used in the GDI algorithm to fit the data. Currently
available models include the DINA model, the ACDM, the RRUM, and the
G-DINA model</p>
</td></tr>
<tr><td><code id="TSQE_+3A_cutoff">cutoff</code></td>
<td>
<p>The cutoff used to dichotomize the entries in the provisional
Q-matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the estimated Q-matrix
</p>


<h3>Estimation Method</h3>

<p>The TSQE method merges the Provisional Attribute Extraction (PAE) algorithm
with a Q-matrix refinement-and-validation method
including the Q-Matrix Refinement (QR) Method and the G-DINA Model
Discrimination Index (GDI). Specifically, the PAE algorithm relies on
classic exploratory factor analysis (EFA) combined with a unique stopping
rule for identifying a provisional Q-matrix, and the resulting provisional
Q-Matrix will be &quot;polished&quot; with a refinement method to derive the final
estimation of Q-matrix.
</p>


<h3>The Provisional Attribute Extraction (PAE) Algorithm</h3>

<p>The initial step of the algorithm is to aggregating the collected Q-Matrix
into an inter-item tetrachoric correlation matrix. The reason for using
tetrachoric correlation is that the examinee responses are binary, so it
is more appropriate than the Pearson product moment correlation coefficient.
See Chiu et al. (2022) for details. The next step is to use factor analysis
on the item-correlation matrix, and treat the extracted factors as proxies
for the latent attributes. The third step concerns identifying which specific
attributes are required for which item:
</p>

<dl>
<dt>(1)</dt><dd><p>Initialize the item index as <code class="reqn">j = 1</code>.</p>
</dd>
<dt>(2)</dt><dd><p>Let <code class="reqn">l_{jk}</code> denote the loading of item <code class="reqn">j</code> on factor <code class="reqn">k</code>, where <code class="reqn">k = 1,2,...,K</code>.</p>
</dd>
<dt>(3)</dt><dd><p>Arrange the loadings in descending order. Define a mapping
function <code class="reqn">f(k) = t</code>, where <code class="reqn">t</code> is the order index.
Hence, <code class="reqn">l_{j(1)}</code> will indicate the maximum loading,
while <code class="reqn">l_{j(K)}</code> will indicate the minimum loading.</p>
</dd>
<dt>(4)</dt><dd><p>Define </p>
<p style="text-align: center;"><code class="reqn">p_j(t) = \frac{\sum_{h=1}^t l_{j(h)}^2}{\sum_{k=1}^K l_{jk}^2}</code>
</p>

<p>as the proportion of the communality of item <code class="reqn">j</code> accounted for
by the first <code class="reqn">t</code> factors.</p>
</dd>
<dt>(5)</dt><dd><p>Define </p>
<p style="text-align: center;"><code class="reqn">K_j = \min \{ t \mid p_j(t) \geq \lambda \}</code>
</p>
<p>,
where <code class="reqn">\lambda</code> is the cut-off value for the desired proportion
of item variance-accounted-for. Then, the ordered entries of the
provisional q-vector of item <code class="reqn">j</code> are obtained as
</p>
<p style="text-align: center;"><code class="reqn">q_{j(t)}^* = \begin{cases}
      1 &amp; \text{if } t \leq K_j \\
      0 &amp; \text{if } t &gt; K_j
      \end{cases}</code>
</p>
<p>.</p>
</dd>
<dt>(6)</dt><dd><p>Identify <code class="reqn">q_j^* = (q_{j1}^*,q_{j2}^*,...,q_{jK}^*)</code>
by rearranging the ordered entries of the q-vector using the inverse function <code class="reqn">k = f^{-1}(t)</code>.</p>
</dd>
<dt>(7)</dt><dd><p>Set <code class="reqn">j = j + 1</code> and repeat (2) to (6) until <code class="reqn">j = J</code>.
Then denote the provisional Q-matrix as <code class="reqn">\mathbf{Q}^*</code>.</p>
</dd>
</dl>



<h3>The Q-Matrix Refinment (QR) Method</h3>

<p>This function implements the Q-matrix refinement method developed by
Chiu (2013), which is also based on the aforementioned nonparametric
classification methods (Chiu &amp; Douglas, 2013). This Q-matrix refinement
method corrects potential misspecified entries of the Q-matrix through
comparisons of the residual sum of squares computed from the observed
and the ideal item responses.
</p>
<p>The algorithm operates by minimizing the RSS. Recall that <code class="reqn">Y_{ij}</code>
is the observed response and <code class="reqn">\eta_{ij}</code> is the ideal response.
Then the RSS of item <code class="reqn">j</code> for examinee <code class="reqn">i</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">RSS_{ij} = (Y_{ij} - \eta_{ij})^2</code>
</p>
<p>.
The RSS of item <code class="reqn">j</code> across all examinees is therefor
</p>
<p style="text-align: center;"><code class="reqn">RSS_{j} = \sum_{i=1}^{N} (Y_{ij} - \eta_{ij})^2 = \sum_{m=1}^{2^k} \sum_{i \in C_{m}} (Y_{ij} - \eta_{jm})^2</code>
</p>

<p>where <code class="reqn">C_m</code> is the latent proficiency-class <code class="reqn">m</code>,
and <code class="reqn">N</code> is the number of examinees.
Chiu(2013) proved that the expectation of <code class="reqn">RSS_j</code> is minimized for
the correct q-vector among the <code class="reqn">2^K - 1</code> candidates. Please see  the
paper for the justification.
</p>


<h3>The G-DINA Model Discrimination Index (GDI)</h3>

<p>The GDI is an extension of de la Torre's (2008) <code class="reqn">\delta</code>-method,
which has a limitation that it cannot be used with CDMs that
devide examinees into more than two groups. In response to the limitation,
de la Torre and Chiu (2016) porposed to select that item attribute vector
which maximizes the weighted variance of the probabilities of a correct
response for the different groups defined as
</p>
<p style="text-align: center;"><code class="reqn">\zeta_j^2 = \sum_{l=1}^{2^{K_j}} P(\alpha_{lj}) \left[ P(Y_{ij} = 1 \mid \alpha_{lj}) - \bar{P}_{j} \right]^2</code>
</p>

<p>where <code class="reqn">P(\alpha_{lj})</code> is the posterior probability for the proficiency class
<code class="reqn">\alpha_{lj}</code>, and <code class="reqn">\bar{P}_{j} =  \sum_{l=1}^{2^{K_j}} P(\alpha_{lj})P(Y_{ij} = 1 \mid \alpha_{lj})</code>,
where <code class="reqn">l = 1,2,...,2^{K_j}</code>. De la Torre and Chiu (2016) called <code class="reqn">\zeta^2</code>
the GDI, which can be applied to any CDM that can be reparameterized in
terms of the G-DINA model.
</p>


<h3>References</h3>

<p>Chiu, C. Y. (2013). Statistical Refinement of the Q-matrix in Cognitive Diagnosis. <em>Applied Psychological Measurement, 37(8)</em>, 598-618.
</p>
<p>Chiu, C. Y., &amp; Douglas, J. A. (2013). A nonparametric approach to cognitive diagnosis by proximity to ideal response patterns. <em>Journal of Classification 30(2)</em>, 225-250.
</p>
<p>de la Torre, J., &amp; Chiu, C.-Y. (2016) A general method of empirical Q-matrix validation. <em>Psychometrika, 81</em>, 253-73.
</p>
<p>de la Torre, J. (2008). An empirically based method of Q-matrix validation for the DINA model: Development and applications. <em>Journal of Educational Measurement, 45</em>, 343-362.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
