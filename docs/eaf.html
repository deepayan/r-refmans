<!DOCTYPE html><html><head><title>Help for package eaf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {eaf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#eaf-package'><p>Computation and visualization of the empirical attainment function (EAF) for</p>
the analysis of random sets in multi-criterion optimization.</a></li>
<li><a href='#attsurf2df'><p>Convert a list of attainment surfaces to a data.frame</p></a></li>
<li><a href='#choose_eafdiffplot'><p>Interactively choose according to empirical attainment function differences</p></a></li>
<li><a href='#CPFs'><p>Conditional Pareto fronts obtained from Gaussian processes simulations.</p></a></li>
<li><a href='#eafdiff'><p>Compute empirical attainment function differences</p></a></li>
<li><a href='#eafdiffplot'><p>Plot empirical attainment function differences</p></a></li>
<li><a href='#eafplot'><p>Plot the Empirical Attainment Function for two objectives</p></a></li>
<li><a href='#eafs'><p>Exact computation of the EAF in 2D or 3D</p></a></li>
<li><a href='#epsilon'><p>Epsilon metric</p></a></li>
<li><a href='#gcp2x2'><p>Metaheuristics for solving the Graph Vertex Coloring Problem</p></a></li>
<li><a href='#hv_contributions'><p>Hypervolume contribution of a set of points</p></a></li>
<li><a href='#HybridGA'><p>Results of Hybrid GA on vanzyl and Richmond water networks</p></a></li>
<li><a href='#hypervolume'><p>Hypervolume metric</p></a></li>
<li><a href='#igd'><p>Inverted Generational Distance (IGD and IGD+) and Averaged Hausdorff Distance</p></a></li>
<li><a href='#is_nondominated'><p>Identify, remove and rank dominated points according to Pareto optimality</p></a></li>
<li><a href='#largest_eafdiff'><p>Identify largest EAF differences</p></a></li>
<li><a href='#normalise'><p>Normalise points</p></a></li>
<li><a href='#pdf_crop'><p>Remove whitespace margins from a PDF file (and maybe embed fonts)</p></a></li>
<li><a href='#read_datasets'><p>Read several data sets</p></a></li>
<li><a href='#SPEA2minstoptimeRichmond'><p>Results of SPEA2 when minimising electrical cost and maximising the</p>
minimum idle time of pumps on Richmond water network.</a></li>
<li><a href='#SPEA2relativeRichmond'><p>Results of SPEA2 with relative time-controlled triggers on Richmond water</p>
network.</a></li>
<li><a href='#SPEA2relativeVanzyl'><p>Results of SPEA2 with relative time-controlled triggers on Vanzyl's</p>
water network.</a></li>
<li><a href='#vorobT'><p>Vorob'ev computations</p></a></li>
<li><a href='#whv_hype'><p>Approximation of the (weighted) hypervolume by Monte-Carlo sampling (2D only)</p></a></li>
<li><a href='#whv_rect'><p>Compute (total) weighted hypervolume given a set of rectangles</p></a></li>
<li><a href='#write_datasets'><p>Write data sets</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Plots of the Empirical Attainment Function</td>
</tr>
<tr>
<td>Version:</td>
<td>2.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Computation and visualization of the empirical attainment function (EAF) for the analysis of random sets in multi-criterion optimization. M. López-Ibáñez, L. Paquete, and T. Stützle (2010) &lt;<a href="https://doi.org/10.1007%2F978-3-642-02538-9_9">doi:10.1007/978-3-642-02538-9_9</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>modeltools, graphics, grDevices, matrixStats, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>extrafont, testthat (&ge; 3.0.0), withr, viridisLite, spelling</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/MLopez-Ibanez/eaf/issues">https://github.com/MLopez-Ibanez/eaf/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://mlopez-ibanez.github.io/eaf/">https://mlopez-ibanez.github.io/eaf/</a>,
<a href="https://github.com/MLopez-Ibanez/eaf">https://github.com/MLopez-Ibanez/eaf</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make, Gnu Scientific Library</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-28 18:43:03 UTC; manu</td>
</tr>
<tr>
<td>Author:</td>
<td>Manuel López-Ibáñez
    <a href="https://orcid.org/0000-0001-9974-1295"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Marco Chiarandini [aut],
  Carlos Fonseca [aut],
  Luís Paquete [aut],
  Thomas Stützle [aut],
  Mickaël Binois [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manuel López-Ibáñez &lt;manuel.lopez-ibanez@manchester.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-28 19:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='eaf-package'>Computation and visualization of the empirical attainment function (EAF) for
the analysis of random sets in multi-criterion optimization.</h2><span id='topic+eaf'></span><span id='topic+eaf-package'></span>

<h3>Description</h3>

<p>The empirical attainment function (EAF) describes the probabilistic
distribution of the outcomes obtained by a stochastic algorithm in the
objective space. This package implements plots of summary
attainment surfaces and differences between the first-order
EAFs. These plots may be used for exploring the performance of
stochastic local search algorithms for biobjective optimization
problems and help in identifying certain algorithmic behaviors in a
graphical way.
</p>


<h3>Functions</h3>


<table>
<tr>
 <td style="text-align: right;">
<code><a href="#topic+eafdiffplot">eafdiffplot()</a></code> </td><td style="text-align: left;">  Empirical attainment function differences</td>
</tr>
<tr>
 <td style="text-align: right;">
<code><a href="#topic+eafplot">eafplot()</a></code> </td><td style="text-align: left;">  Plot the Empirical Attainment Function for two objectives</td>
</tr>
<tr>
 <td style="text-align: right;">
<code><a href="#topic+read_datasets">read_datasets()</a></code> </td><td style="text-align: left;">  Read several data.frame sets
</td>
</tr>

</table>



<h3>Data</h3>


<dl>
<dt><code><a href="#topic+gcp2x2">gcp2x2</a></code></dt><dd><p>  Metaheuristics for solving the Graph Vertex Coloring Problem</p>
</dd>
<dt><code><a href="#topic+HybridGA">HybridGA</a></code></dt><dd><p>  Results of Hybrid GA on vanzyl and Richmond
water networks</p>
</dd>
<dt><code><a href="#topic+SPEA2minstoptimeRichmond">SPEA2minstoptimeRichmond</a></code></dt><dd><p> Results of SPEA2 when minimising electrical cost and maximising the
minimum idle time of pumps on Richmond water network</p>
</dd>
</dl>

<p>Extras are available at <code>system.file(package="eaf")</code>:
</p>

<table>
<tr>
 <td style="text-align: right;">
<code>extdata</code>        </td><td style="text-align: left;">  External data sets (see <code><a href="#topic+read_datasets">read_datasets</a></code>) </td>
</tr>
<tr>
 <td style="text-align: right;">
<code>scripts/eaf</code>    </td><td style="text-align: left;">  EAF command-line program </td>
</tr>
<tr>
 <td style="text-align: right;">
<code>scripts/eafplot</code></td><td style="text-align: left;">  Perl script to generate plots of attainment surfaces</td>
</tr>
<tr>
 <td style="text-align: right;">
<code>scripts/eafdiff</code></td><td style="text-align: left;">  Perl script to generate plots of EAF differences
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Manuel López-Ibáñez <a href="mailto:manuel.lopez-ibanez@manchester.ac.uk">manuel.lopez-ibanez@manchester.ac.uk</a> (<a href="https://orcid.org/0000-0001-9974-1295">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Marco Chiarandini
</p>
</li>
<li><p> Carlos Fonseca
</p>
</li>
<li><p> Luís Paquete
</p>
</li>
<li><p> Thomas Stützle
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Mickaël Binois [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Viviane Grunert da Fonseca, Carlos
M. Fonseca, Andreia
O. Hall (2001).
&ldquo;Inferential Performance Assessment of Stochastic Optimisers and the Attainment Function.&rdquo;
In Eckart Zitzler, Kalyanmoy Deb, Lothar Thiele, Carlos
A. Coello Coello, David Corne (eds.), <em>Evolutionary Multi-criterion Optimization, EMO 2001</em>, volume 1993 of <em>Lecture Notes in Computer Science</em>, 213&ndash;225.
Springer, Heidelberg, Germany.
doi: <a href="https://doi.org/10.1007/3-540-44719-9_15">10.1007/3-540-44719-9_15</a>.
</p>
<p>Viviane Grunert da Fonseca, Carlos
M. Fonseca (2010).
&ldquo;The Attainment-Function Approach to Stochastic Multiobjective Optimizer Assessment and Comparison.&rdquo;
In Thomas Bartz-Beielstein, Marco Chiarandini, Luís Paquete, Mike Preuss (eds.), <em>Experimental Methods for the Analysis of Optimization Algorithms</em>, 103&ndash;130.
Springer, Berlin, Germany.
</p>
<p>Manuel López-Ibáñez, Luís Paquete, Thomas Stützle (2010).
&ldquo;Exploratory Analysis of Stochastic Local Search Algorithms in Biobjective Optimization.&rdquo;
In Thomas Bartz-Beielstein, Marco Chiarandini, Luís Paquete, Mike Preuss (eds.), <em>Experimental Methods for the Analysis of Optimization Algorithms</em>, 209&ndash;222.
Springer, Berlin, Germany.
doi: <a href="https://doi.org/10.1007/978-3-642-02538-9_9">10.1007/978-3-642-02538-9_9</a>.
</p>
<p>Carlos
M. Fonseca, Andreia
P. Guerreiro, Manuel López-Ibáñez, Luís Paquete (2011).
&ldquo;On the Computation of the Empirical Attainment Function.&rdquo;
In R
H
C Takahashi,  others (eds.), <em> Evolutionary Multi-criterion Optimization, EMO 2011</em>, volume 6576 of <em>Lecture Notes in Computer Science</em>, 106&ndash;120.
Springer,  Heidelberg .
doi: <a href="https://doi.org/10.1007/978-3-642-19893-9_8">10.1007/978-3-642-19893-9_8</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://mlopez-ibanez.github.io/eaf/">https://mlopez-ibanez.github.io/eaf/</a>
</p>
</li>
<li> <p><a href="https://github.com/MLopez-Ibanez/eaf">https://github.com/MLopez-Ibanez/eaf</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/MLopez-Ibanez/eaf/issues">https://github.com/MLopez-Ibanez/eaf/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(gcp2x2)
tabucol&lt;-subset(gcp2x2, alg!="TSinN1")
tabucol$alg&lt;-tabucol$alg[drop=TRUE]
eafplot(time+best~run,data=tabucol,subset=tabucol$inst=="DSJC500.5")

eafplot(time+best~run|inst,groups=alg,data=gcp2x2)
eafplot(time+best~run|inst,groups=alg,data=gcp2x2,
	percentiles = c(0,50,100), cex = 1.4, lty = c(2,1,2),lwd = c(2,2,2),
        col = c("black","blue","grey50"))
 
extdata_path &lt;- system.file(package="eaf","extdata")
A1 &lt;- read_datasets(file.path(extdata_path, "wrots_l100w10_dat"))
A2 &lt;- read_datasets(file.path(extdata_path, "wrots_l10w100_dat"))
eafplot(A1, percentiles=c(50))
eafplot(list(A1=A1, A2=A2), percentiles=c(50))
eafdiffplot(A1, A2)
## Save to a PDF file
# dev.copy2pdf(file="eaf.pdf", onefile=TRUE, width=5, height=4)
</code></pre>

<hr>
<h2 id='attsurf2df'>Convert a list of attainment surfaces to a data.frame</h2><span id='topic+attsurf2df'></span>

<h3>Description</h3>

<p>Convert a list of attainment surfaces to a single data.frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attsurf2df(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attsurf2df_+3A_x">x</code></td>
<td>
<p>(<code>list()</code>) List of data.frames or matrices. The names of the list
give the percentiles of the attainment surfaces.  This is the format
returned by <code><a href="#topic+eafplot">eafplot()</a></code> (and the internal function <code>compute_eaf_as_list</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with as many columns as objectives and an additional column <code>percentiles</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(SPEA2relativeRichmond)
attsurfs &lt;- eafplot (SPEA2relativeRichmond, percentiles = c(0,50,100),
                     xlab = expression(C[E]), ylab = "Total switches",
                     lty=0, pch=21, xlim = c(90, 140), ylim = c(0, 25))
attsurfs &lt;- attsurf2df(attsurfs)
text(attsurfs[,1:2], labels = attsurfs[,3], adj = c(1.5,1.5))

</code></pre>

<hr>
<h2 id='choose_eafdiffplot'>Interactively choose according to empirical attainment function differences</h2><span id='topic+choose_eafdiffplot'></span><span id='topic+choose_eafdiff'></span>

<h3>Description</h3>

<p>Creates the same plot as <code><a href="#topic+eafdiffplot">eafdiffplot()</a></code> but waits for the user to click in
one of the sides. Then it returns the rectangles the give the differences in
favour of the chosen side. These rectangles may be used for interactive
decision-making as shown in Diaz and López-Ibáñez (2021). The function
<code><a href="#topic+choose_eafdiff">choose_eafdiff()</a></code> may be used in a non-interactive context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose_eafdiffplot(
  data.left,
  data.right,
  intervals = 5,
  maximise = c(FALSE, FALSE),
  title.left = deparse(substitute(data.left)),
  title.right = deparse(substitute(data.right)),
  ...
)

choose_eafdiff(x, left = stop("'left' must be either TRUE or FALSE"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose_eafdiffplot_+3A_data.left">data.left</code>, <code id="choose_eafdiffplot_+3A_data.right">data.right</code></td>
<td>
<p>Data frames corresponding to the input data of
left and right sides, respectively. Each data frame has at least three
columns, the third one being the set of each point. See also
<code><a href="#topic+read_datasets">read_datasets()</a></code>.</p>
</td></tr>
<tr><td><code id="choose_eafdiffplot_+3A_intervals">intervals</code></td>
<td>
<p>(<code>integer(1)</code>|<code>character()</code>) <br /> The absolute range of the
differences <code class="reqn">[0, 1]</code> is partitioned into the number of intervals
provided. If an integer is provided, then labels for each interval are
computed automatically. If a character vector is provided, its length is
taken as the number of intervals.</p>
</td></tr>
<tr><td><code id="choose_eafdiffplot_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="choose_eafdiffplot_+3A_title.left">title.left</code>, <code id="choose_eafdiffplot_+3A_title.right">title.right</code></td>
<td>
<p>Title for left and right panels, respectively.</p>
</td></tr>
<tr><td><code id="choose_eafdiffplot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed down to
<code><a href="#topic+eafdiffplot">eafdiffplot()</a></code>.</p>
</td></tr>
<tr><td><code id="choose_eafdiffplot_+3A_x">x</code></td>
<td>
<p>(<code>matrix()</code>) Matrix of rectangles representing EAF differences
(returned by <code><a href="#topic+eafdiff">eafdiff()</a></code> with <code>rectangles=TRUE</code>).</p>
</td></tr>
<tr><td><code id="choose_eafdiffplot_+3A_left">left</code></td>
<td>
<p>(<code>logical(1)</code>) With <code>left=TRUE</code> return the rectangles with
positive differences, otherwise return those with negative differences but
differences are converted to positive.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>matrix</code> where the first 4 columns give the coordinates of two
corners of each rectangle and the last column. In both cases, the last
column gives the positive differences in favor of the chosen side.
</p>


<h3>References</h3>

<p>Juan
Esteban Diaz, Manuel López-Ibáñez (2021).
&ldquo;Incorporating Decision-Maker's Preferences into the Automatic Configuration of Bi-Objective Optimisation Algorithms.&rdquo;
<em>European Journal of Operational Research</em>, <b>289</b>(3), 1209&ndash;1222.
doi: <a href="https://doi.org/10.1016/j.ejor.2020.07.059">10.1016/j.ejor.2020.07.059</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code>, <code><a href="#topic+eafdiffplot">eafdiffplot()</a></code>, <code><a href="#topic+whv_rect">whv_rect()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

extdata_dir &lt;- system.file(package="eaf", "extdata") 
A1 &lt;- read_datasets(file.path(extdata_dir, "wrots_l100w10_dat"))
A2 &lt;- read_datasets(file.path(extdata_dir, "wrots_l10w100_dat"))
if (interactive()) {
  rectangles &lt;- choose_eafdiffplot(A1, A2, intervals = 5)
} else { # Choose A1
  rectangles &lt;- eafdiff(A1, A2, intervals = 5, rectangles = TRUE)
  rectangles &lt;- choose_eafdiff(rectangles, left = TRUE)
}
reference &lt;- c(max(A1[, 1], A2[, 1]), max(A1[, 2], A2[, 2]))
x &lt;- split.data.frame(A1[,1:2], A1[,3])
hv_A1 &lt;- sapply(split.data.frame(A1[, 1:2], A1[, 3]),
                 hypervolume, reference=reference)
hv_A2 &lt;- sapply(split.data.frame(A2[, 1:2], A2[, 3]),
                 hypervolume, reference=reference)
boxplot(list(A1=hv_A1, A2=hv_A2), main = "Hypervolume")

whv_A1 &lt;- sapply(split.data.frame(A1[, 1:2], A1[, 3]),
                 whv_rect, rectangles=rectangles, reference=reference)
whv_A2 &lt;- sapply(split.data.frame(A2[, 1:2], A2[, 3]),
                 whv_rect, rectangles=rectangles, reference=reference)
boxplot(list(A1=whv_A1, A2=whv_A2), main = "Weighted hypervolume")


</code></pre>

<hr>
<h2 id='CPFs'>Conditional Pareto fronts obtained from Gaussian processes simulations.</h2><span id='topic+CPFs'></span>

<h3>Description</h3>

<p>The data has the only goal of providing an example of use of <code><a href="#topic+vorobT">vorobT()</a></code> and
<code><a href="#topic+vorobDev">vorobDev()</a></code>. It has been obtained by fitting two Gaussian processes on 20
observations of a bi-objective problem, before generating conditional
simulation of both GPs at different locations and extracting non-dominated
values of coupled simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CPFs
</code></pre>


<h3>Format</h3>

<p>A data frame with 2967 observations on the following 3 variables.
</p>

<dl>
<dt><code>f1</code></dt><dd><p>first objective values.</p>
</dd>
<dt><code>f2</code></dt><dd><p>second objective values.</p>
</dd>
<dt><code>set</code></dt><dd><p>indices of corresponding conditional Pareto fronts.</p>
</dd>
</dl>



<h3>Source</h3>

<p>M Binois, D Ginsbourger, O Roustant (2015).
&ldquo;Quantifying uncertainty on Pareto fronts with Gaussian process conditional simulations.&rdquo;
<em>European Journal of Operational Research</em>, <b>243</b>(2), 386&ndash;394.
doi: <a href="https://doi.org/10.1016/j.ejor.2014.07.032">10.1016/j.ejor.2014.07.032</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(CPFs)

res &lt;- vorobT(CPFs, reference = c(2, 200))
eafplot(CPFs[,1:2], sets = CPFs[,3], percentiles = c(0, 20, 40, 60, 80, 100),
       col = gray(seq(0.8, 0.1, length.out = 6)^2), type = "area",
       legend.pos = "bottomleft", extra.points = res$VE, extra.col = "cyan")
</code></pre>

<hr>
<h2 id='eafdiff'>Compute empirical attainment function differences</h2><span id='topic+eafdiff'></span>

<h3>Description</h3>

<p>Calculate the differences between the empirical attainment functions of two
data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eafdiff(x, y, intervals = NULL, maximise = c(FALSE, FALSE), rectangles = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eafdiff_+3A_x">x</code>, <code id="eafdiff_+3A_y">y</code></td>
<td>
<p>Data frames corresponding to the input data of
left and right sides, respectively. Each data frame has at least three
columns, the third one being the set of each point. See also
<code><a href="#topic+read_datasets">read_datasets()</a></code>.</p>
</td></tr>
<tr><td><code id="eafdiff_+3A_intervals">intervals</code></td>
<td>
<p>(<code>integer(1)</code>) <br /> The absolute range of the differences
<code class="reqn">[0, 1]</code> is partitioned into the number of intervals provided.</p>
</td></tr>
<tr><td><code id="eafdiff_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="eafdiff_+3A_rectangles">rectangles</code></td>
<td>
<p>If TRUE, the output is in the form of rectangles of the same color.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the differences between the EAFs of two
data sets.
</p>


<h3>Value</h3>

<p>With <code>rectangle=FALSE</code>, a <code>data.frame</code> containing points where there
is a transition in the value of the EAF differences.  With
<code>rectangle=TRUE</code>, a <code>matrix</code> where the first 4 columns give the
coordinates of two corners of each rectangle and the last column. In both
cases, the last column gives the difference in terms of sets in <code>x</code> minus
sets in <code>y</code> that attain each point (i.e., negative values are differences
in favour <code>y</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code>, <code><a href="#topic+eafdiffplot">eafdiffplot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
A1 &lt;- read_datasets(text='
 3 2
 2 3
 
 2.5 1
 1 2
 
 1 2
')
A2 &lt;- read_datasets(text='
 4 2.5
 3 3
 2.5 3.5
 
 3 3
 2.5 3.5
 
 2 1
')
d &lt;- eafdiff(A1, A2)
str(d)
print(d)

d &lt;- eafdiff(A1, A2, rectangles = TRUE)
str(d)
print(d)

</code></pre>

<hr>
<h2 id='eafdiffplot'>Plot empirical attainment function differences</h2><span id='topic+eafdiffplot'></span>

<h3>Description</h3>

<p>Plot the differences between the empirical attainment functions (EAFs) of two
data sets as a two-panel plot, where the left side shows the values of
the left EAF minus the right EAF and the right side shows the
differences in the other direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eafdiffplot(
  data.left,
  data.right,
  col = c("#FFFFFF", "#808080", "#000000"),
  intervals = 5,
  percentiles = c(50),
  full.eaf = FALSE,
  type = "area",
  legend.pos = if (full.eaf) "bottomleft" else "topright",
  title.left = deparse(substitute(data.left)),
  title.right = deparse(substitute(data.right)),
  xlim = NULL,
  ylim = NULL,
  cex = par("cex"),
  cex.lab = par("cex.lab"),
  cex.axis = par("cex.axis"),
  maximise = c(FALSE, FALSE),
  grand.lines = TRUE,
  sci.notation = FALSE,
  left.panel.last = NULL,
  right.panel.last = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eafdiffplot_+3A_data.left">data.left</code>, <code id="eafdiffplot_+3A_data.right">data.right</code></td>
<td>
<p>Data frames corresponding to the input data of
left and right sides, respectively. Each data frame has at least three
columns, the third one being the set of each point. See also
<code><a href="#topic+read_datasets">read_datasets()</a></code>.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_col">col</code></td>
<td>
<p>A character vector of three colors for the magnitude of the
differences of 0, 0.5, and 1. Intermediate colors are computed
automatically given the value of <code>intervals</code>. Alternatively, a function
such as <code><a href="viridisLite.html#topic+viridis">viridisLite::viridis()</a></code> that generates a colormap given an integer
argument.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_intervals">intervals</code></td>
<td>
<p>(<code>integer(1)</code>|<code>character()</code>) <br /> The
absolute range of the differences <code class="reqn">[0, 1]</code> is partitioned into the number
of intervals provided. If an integer is provided, then labels for each
interval are  computed automatically. If a character vector is
provided, its length is taken as the number of intervals.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_percentiles">percentiles</code></td>
<td>
<p>The percentiles of the EAF of each side that will be
plotted as attainment surfaces. <code>NA</code> does not plot any. See
<code><a href="#topic+eafplot">eafplot()</a></code>.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_full.eaf">full.eaf</code></td>
<td>
<p>Whether to plot the EAF of each side instead of the
differences between the EAFs.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_type">type</code></td>
<td>
<p>Whether the EAF differences are plotted as points
(&lsquo;<span class="samp">&#8288;points&#8288;</span>&rsquo;) or whether to color the areas that have at least a
certain value (&lsquo;<span class="samp">&#8288;area&#8288;</span>&rsquo;).</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_legend.pos">legend.pos</code></td>
<td>
<p>The position of the legend. See <code><a href="graphics.html#topic+legend">legend()</a></code>.  A value of
<code>"none"</code> hides the legend.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_title.left">title.left</code>, <code id="eafdiffplot_+3A_title.right">title.right</code></td>
<td>
<p>Title for left and right panels, respectively.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_xlim">xlim</code>, <code id="eafdiffplot_+3A_ylim">ylim</code>, <code id="eafdiffplot_+3A_cex">cex</code>, <code id="eafdiffplot_+3A_cex.lab">cex.lab</code>, <code id="eafdiffplot_+3A_cex.axis">cex.axis</code></td>
<td>
<p>Graphical parameters, see
<code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_grand.lines">grand.lines</code></td>
<td>
<p>Whether to plot the grand-best and grand-worst
attainment surfaces.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_sci.notation">sci.notation</code></td>
<td>
<p>Generate prettier labels</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_left.panel.last">left.panel.last</code>, <code id="eafdiffplot_+3A_right.panel.last">right.panel.last</code></td>
<td>
<p>An expression to be evaluated after
plotting has taken place on each panel (left or right). This can be useful
for adding points or text to either panel.  Note that this works by lazy
evaluation: passing this argument from other <code>plot</code> methods may well
not work since it may be evaluated too early.</p>
</td></tr>
<tr><td><code id="eafdiffplot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters are passed down to
<code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the differences between the EAFs of two
data sets, and plots on the left the differences in favour
of the left data set, and on the right the differences in favour of
the right data set. By default, it also plots the grand best and worst
attainment surfaces, that is, the 0%- and 100%-attainment surfaces
over all data. These two surfaces delimit the area where differences
may exist. In addition, it also plots the 50%-attainment surface of
each data set.
</p>
<p>With <code>type = "point"</code>, only the points where there is a change in
the value of the EAF difference are plotted. This means that for areas
where the EAF differences stays constant, the region will appear in
white even if the value of the differences in that region is
large. This explains &quot;white holes&quot; surrounded by black
points.
</p>
<p>With <code>type = "area"</code>, the area where the EAF differences has a
certain value is plotted.  The idea for the algorithm to compute the
areas was provided by Carlos M. Fonseca.  The implementation uses R
polygons, which some PDF viewers may have trouble rendering correctly
(See
<a href="https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-there-unwanted-borders">https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-there-unwanted-borders</a>). Plots (should) look correct when printed.
</p>
<p>Large differences that appear when using <code>type = "point"</code> may
seem to disappear when using <code>type = "area"</code>. The explanation is
the points size is independent of the axes range, therefore, the
plotted points may seem to cover a much larger area than the actual
number of points. On the other hand, the areas size is plotted with
respect to the objective space, without any extra borders. If the
range of an area becomes smaller than one-pixel, it won't be
visible. As a consequence, zooming in or out certain regions of the plots
does not change the apparent size of the points, whereas it affects
considerably the apparent size of the areas.
</p>


<h3>Value</h3>

<p>Returns a representation of the EAF differences (invisibly).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code> <code><a href="#topic+eafplot">eafplot()</a></code> <code><a href="#topic+pdf_crop">pdf_crop()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## NOTE: The plots in the website look squashed because of how pkgdown
## generates them. They should look fine when you generate them yourself.
extdata_dir &lt;- system.file(package="eaf", "extdata") 
A1 &lt;- read_datasets(file.path(extdata_dir, "ALG_1_dat.xz"))
A2 &lt;- read_datasets(file.path(extdata_dir, "ALG_2_dat.xz"))
# These take time
eafdiffplot(A1, A2, full.eaf = TRUE)
if (requireNamespace("viridisLite", quietly=TRUE)) {
  viridis_r &lt;- function(n) viridisLite::viridis(n, direction=-1)
  eafdiffplot(A1, A2, type = "area", col = viridis_r)
} else {
  eafdiffplot(A1, A2, type = "area")
}
A1 &lt;- read_datasets(file.path(extdata_dir, "wrots_l100w10_dat"))
A2 &lt;- read_datasets(file.path(extdata_dir, "wrots_l10w100_dat"))
eafdiffplot(A1, A2, type = "point", sci.notation = TRUE, cex.axis=0.6)

# A more complex example
DIFF &lt;- eafdiffplot(A1, A2, col = c("white", "blue", "red"), intervals = 5,
                    type = "point",
                    title.left=expression("W-RoTS," ~ lambda==100 * "," ~ omega==10),
                    title.right=expression("W-RoTS," ~ lambda==10 * "," ~ omega==100),
                    right.panel.last={
                      abline(a = 0, b = 1, col = "red", lty = "dashed")})
DIFF$right[,3] &lt;- -DIFF$right[,3]

## Save the values to a file.
# write.table(rbind(DIFF$left,DIFF$right),
#             file = "wrots_l100w10_dat-wrots_l10w100_dat-diff.txt",
#             quote = FALSE, row.names = FALSE, col.names = FALSE)

</code></pre>

<hr>
<h2 id='eafplot'>Plot the Empirical Attainment Function for two objectives</h2><span id='topic+eafplot'></span><span id='topic+eafplot.default'></span><span id='topic+eafplot.formula'></span><span id='topic+eafplot.list'></span>

<h3>Description</h3>

<p>Computes and plots the Empirical Attainment Function, either as
attainment surfaces for certain percentiles or as points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eafplot(x, ...)

## Default S3 method:
eafplot(
  x,
  sets = NULL,
  groups = NULL,
  percentiles = c(0, 50, 100),
  attsurfs = NULL,
  xlab = NULL,
  ylab = NULL,
  xlim = NULL,
  ylim = NULL,
  log = "",
  type = "point",
  col = NULL,
  lty = c("dashed", "solid", "solid", "solid", "dashed"),
  lwd = 1.75,
  pch = NA,
  cex.pch = par("cex"),
  las = par("las"),
  legend.pos = "topright",
  legend.txt = NULL,
  extra.points = NULL,
  extra.legend = NULL,
  extra.pch = 4:25,
  extra.lwd = 0.5,
  extra.lty = NA,
  extra.col = "black",
  maximise = c(FALSE, FALSE),
  xaxis.side = "below",
  yaxis.side = "left",
  axes = TRUE,
  sci.notation = FALSE,
  ...
)

## S3 method for class 'formula'
eafplot(formula, data, groups = NULL, subset = NULL, ...)

## S3 method for class 'list'
eafplot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eafplot_+3A_x">x</code></td>
<td>
<p>Either a matrix of data values, or a data frame, or a list of
data frames of exactly three columns.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_sets">sets</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br /> Vector indicating which set each point belongs to.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_groups">groups</code></td>
<td>
<p>This may be used to plot profiles of different algorithms on the same plot.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_percentiles">percentiles</code></td>
<td>
<p>(<code>numeric()</code>) Vector indicating which percentile should be plot. The
default is to plot only the median attainment curve.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_attsurfs">attsurfs</code></td>
<td>
<p>TODO</p>
</td></tr>
<tr><td><code id="eafplot_+3A_xlab">xlab</code>, <code id="eafplot_+3A_ylab">ylab</code>, <code id="eafplot_+3A_xlim">xlim</code>, <code id="eafplot_+3A_ylim">ylim</code>, <code id="eafplot_+3A_log">log</code>, <code id="eafplot_+3A_col">col</code>, <code id="eafplot_+3A_lty">lty</code>, <code id="eafplot_+3A_lwd">lwd</code>, <code id="eafplot_+3A_pch">pch</code>, <code id="eafplot_+3A_cex.pch">cex.pch</code>, <code id="eafplot_+3A_las">las</code></td>
<td>
<p>Graphical
parameters, see <code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_type">type</code></td>
<td>
<p>(<code>character(1)</code>)<br /> string giving the type of plot desired.  The following values
are possible, &lsquo;<span class="samp">&#8288;points&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;area&#8288;</span>&rsquo;.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_legend.pos">legend.pos</code></td>
<td>
<p>the position of the legend, see <code><a href="graphics.html#topic+legend">legend()</a></code>.  A value of <code>"none"</code> hides the legend.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_legend.txt">legend.txt</code></td>
<td>
<p>a character or expression vector to appear in the
legend. If <code>NULL</code>, appropriate labels will be generated.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_extra.points">extra.points</code></td>
<td>
<p>A list of matrices or data.frames with
two-columns. Each element of the list defines a set of points, or
lines if one of the columns is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_extra.legend">extra.legend</code></td>
<td>
<p>A character vector providing labels for the
groups of points.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_extra.pch">extra.pch</code>, <code id="eafplot_+3A_extra.lwd">extra.lwd</code>, <code id="eafplot_+3A_extra.lty">extra.lty</code>, <code id="eafplot_+3A_extra.col">extra.col</code></td>
<td>
<p>Control the graphical aspect
of the points. See <code><a href="graphics.html#topic+points">points()</a></code> and <code><a href="graphics.html#topic+lines">lines()</a></code>.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_xaxis.side">xaxis.side</code></td>
<td>
<p>On which side that xaxis is drawn. Valid values are
&quot;below&quot; and &quot;above&quot;. See <code><a href="graphics.html#topic+axis">axis()</a></code>.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_yaxis.side">yaxis.side</code></td>
<td>
<p>On which side that yaxis is drawn. Valid values are &quot;left&quot;
and &quot;right&quot;. See <code><a href="graphics.html#topic+axis">axis()</a></code>.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_axes">axes</code></td>
<td>
<p>A logical value indicating whether both axes should be drawn
on the plot.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_sci.notation">sci.notation</code></td>
<td>
<p>Generate prettier labels</p>
</td></tr>
<tr><td><code id="eafplot_+3A_formula">formula</code></td>
<td>
<p>A formula of the type: <code>time + cost ~ run | instance</code>
will draw <code>time</code> on the x-axis and <code>cost</code> on the y-axis. If <code>instance</code> is
present the plot is conditional to the instances.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_data">data</code></td>
<td>
<p>Dataframe containing the fields mentioned in the formula and in groups.</p>
</td></tr>
<tr><td><code id="eafplot_+3A_subset">subset</code></td>
<td>
<p>(<code>integer()</code> | <code>NULL</code>)<br /> A vector indicating which rows of the data should be used. If left to default <code>NULL</code> all data in the data frame are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used to plot random sets of points like those obtained
by different runs of biobjective stochastic optimisation algorithms.  An EAF
curve represents the boundary separating points that are known to be
attainable (that is, dominated in Pareto sense) in at least a fraction
(quantile) of the runs from those that are not. The median EAF represents
the curve where the fraction of attainable points is 50%.  In single
objective optimisation the function can be used to plot the profile of
solution quality over time of a collection of runs of a stochastic optimizer.
</p>


<h3>Value</h3>

<p>Return (invisibly) the attainment surfaces computed.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>eafplot(default)</code>: Main function
</p>
</li>
<li> <p><code>eafplot(formula)</code>: Formula interface
</p>
</li>
<li> <p><code>eafplot(list)</code>: List interface for lists of data.frames or matrices
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code> <code><a href="#topic+eafdiffplot">eafdiffplot()</a></code> <code><a href="#topic+pdf_crop">pdf_crop()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gcp2x2)
tabucol &lt;- subset(gcp2x2, alg != "TSinN1")
tabucol$alg &lt;- tabucol$alg[drop=TRUE]
eafplot(time + best ~ run, data = tabucol, subset = tabucol$inst=="DSJC500.5")

# These take time
eafplot(time + best ~ run | inst, groups=alg, data=gcp2x2)
eafplot(time + best ~ run | inst, groups=alg, data=gcp2x2,
	percentiles=c(0,50,100), cex.axis = 0.8, lty = c(2,1,2), lwd = c(2,2,2),
     col = c("black","blue","grey50"))

extdata_path &lt;- system.file(package = "eaf", "extdata")
A1 &lt;- read_datasets(file.path(extdata_path, "ALG_1_dat.xz"))
A2 &lt;- read_datasets(file.path(extdata_path, "ALG_2_dat.xz"))
eafplot(A1, percentiles = 50, sci.notation = TRUE, cex.axis=0.6)
# The attainment surfaces are returned invisibly.
attsurfs &lt;- eafplot(list(A1 = A1, A2 = A2), percentiles = 50)
str(attsurfs)

## Save as a PDF file.
# dev.copy2pdf(file = "eaf.pdf", onefile = TRUE, width = 5, height = 4)


## Using extra.points

data(HybridGA)
data(SPEA2relativeVanzyl)
eafplot(SPEA2relativeVanzyl, percentiles = c(25, 50, 75), 
        xlab = expression(C[E]), ylab = "Total switches", xlim = c(320, 400),
        extra.points = HybridGA$vanzyl, extra.legend = "Hybrid GA")

data(SPEA2relativeRichmond)
eafplot (SPEA2relativeRichmond, percentiles = c(25, 50, 75),
         xlab = expression(C[E]), ylab = "Total switches",
         xlim = c(90, 140), ylim = c(0, 25),
         extra.points = HybridGA$richmond, extra.lty = "dashed",
         extra.legend = "Hybrid GA")

eafplot (SPEA2relativeRichmond, percentiles = c(25, 50, 75),
         xlab = expression(C[E]), ylab = "Total switches",
         xlim = c(90, 140), ylim = c(0, 25), type = "area",
         extra.points = HybridGA$richmond, extra.lty = "dashed",
         extra.legend = "Hybrid GA", legend.pos = "bottomright")

data(SPEA2minstoptimeRichmond)
SPEA2minstoptimeRichmond[,2] &lt;- SPEA2minstoptimeRichmond[,2] / 60
eafplot (SPEA2minstoptimeRichmond, xlab = expression(C[E]),
         ylab = "Minimum idle time (minutes)", maximise = c(FALSE, TRUE),
         las = 1, log = "y", main = "SPEA2 (Richmond)",
         legend.pos = "bottomright")

</code></pre>

<hr>
<h2 id='eafs'>Exact computation of the EAF in 2D or 3D</h2><span id='topic+eafs'></span>

<h3>Description</h3>

<p>This function computes the EAF given a set of 2D or 3D points and a vector <code>set</code>
that indicates to which set each point belongs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eafs(points, sets, groups = NULL, percentiles = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eafs_+3A_points">points</code></td>
<td>
<p>Either a matrix or a data frame of numerical values, where
each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="eafs_+3A_sets">sets</code></td>
<td>
<p>A vector indicating which set each point belongs to.</p>
</td></tr>
<tr><td><code id="eafs_+3A_groups">groups</code></td>
<td>
<p>Indicates that the EAF must be computed separately for data
belonging to different groups.</p>
</td></tr>
<tr><td><code id="eafs_+3A_percentiles">percentiles</code></td>
<td>
<p>(<code>numeric()</code>) Vector indicating which percentiles are computed.
<code>NULL</code> computes all.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame (<code>data.frame</code>) containing the exact representation
of EAF. The last column gives the percentile that corresponds to each
point. If groups is not <code>NULL</code>, then an additional column
indicates to which group the point belongs.
</p>


<h3>Note</h3>

<p>There are several examples of data sets in <code>system.file(package="eaf","extdata")</code>. The current implementation only supports two and three dimensional points.
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>References</h3>

<p>Viviane Grunert da Fonseca, Carlos
M. Fonseca, Andreia
O. Hall (2001).
&ldquo;Inferential Performance Assessment of Stochastic Optimisers and the Attainment Function.&rdquo;
In Eckart Zitzler, Kalyanmoy Deb, Lothar Thiele, Carlos
A. Coello Coello, David Corne (eds.), <em>Evolutionary Multi-criterion Optimization, EMO 2001</em>, volume 1993 of <em>Lecture Notes in Computer Science</em>, 213&ndash;225.
Springer, Heidelberg, Germany.
doi: <a href="https://doi.org/10.1007/3-540-44719-9_15">10.1007/3-540-44719-9_15</a>.
</p>
<p>Carlos
M. Fonseca, Andreia
P. Guerreiro, Manuel López-Ibáñez, Luís Paquete (2011).
&ldquo;On the Computation of the Empirical Attainment Function.&rdquo;
In R
H
C Takahashi,  others (eds.), <em> Evolutionary Multi-criterion Optimization, EMO 2011</em>, volume 6576 of <em>Lecture Notes in Computer Science</em>, 106&ndash;120.
Springer,  Heidelberg .
doi: <a href="https://doi.org/10.1007/978-3-642-19893-9_8">10.1007/978-3-642-19893-9_8</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>extdata_path &lt;- system.file(package="eaf", "extdata")

x &lt;- read_datasets(file.path(extdata_path, "example1_dat"))
# Compute full EAF
str(eafs(x[,1:2], x[,3]))

# Compute only best, median and worst
str(eafs(x[,1:2], x[,3], percentiles = c(0, 50, 100)))

x &lt;- read_datasets(file.path(extdata_path, "spherical-250-10-3d.txt"))
y &lt;- read_datasets(file.path(extdata_path, "uniform-250-10-3d.txt"))
x &lt;- rbind(data.frame(x, groups = "spherical"),
           data.frame(y, groups = "uniform"))
# Compute only median separately for each group
z &lt;- eafs(x[,1:3], sets = x[,4], groups = x[,5], percentiles = 50)
str(z)
# library(plotly)
# plot_ly(z, x = ~X1, y = ~X2, z = ~X3, color = ~groups,
#         colors = c('#BF382A', '#0C4B8E')) %&gt;% add_markers()
</code></pre>

<hr>
<h2 id='epsilon'>Epsilon metric</h2><span id='topic+epsilon'></span><span id='topic+epsilon_additive'></span><span id='topic+epsilon_mult'></span>

<h3>Description</h3>

<p>Computes the epsilon metric, either additive or multiplicative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epsilon_additive(data, reference, maximise = FALSE)

epsilon_mult(data, reference, maximise = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epsilon_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="epsilon_+3A_reference">reference</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Reference set as a matrix or
data.frame of numerical values.</p>
</td></tr>
<tr><td><code id="epsilon_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The epsilon metric of a set <code class="reqn">A</code> with respect to a reference set <code class="reqn">R</code>
is defined as
</p>
<p style="text-align: center;"><code class="reqn">epsilon(A,R) = \max_{r \in R} \min_{a \in A} \max_{1 \leq i \leq n} epsilon(a_i, r_i)</code>
</p>

<p>where <code class="reqn">a</code> and <code class="reqn">b</code> are objective vectors and, in the case of
minimization of objective <code class="reqn">i</code>, <code class="reqn">epsilon(a_i,b_i)</code> is computed as
<code class="reqn">a_i/b_i</code> for the multiplicative variant (respectively, <code class="reqn">a_i - b_i</code>
for the additive variant), whereas in the case of maximization of objective
<code class="reqn">i</code>, <code class="reqn">epsilon(a_i,b_i) = b_i/a_i</code> for the multiplicative variant
(respectively, <code class="reqn">b_i - a_i</code> for the additive variant). This allows
computing a single value for problems where some objectives are to be
maximized while others are to be minimized. Moreover, a lower value
corresponds to a better approximation set, independently of the type of
problem (minimization, maximization or mixed). However, the meaning of the
value is different for each objective type. For example, imagine that
objective 1 is to be minimized and objective 2 is to be maximized, and the
multiplicative epsilon computed here for <code class="reqn">epsilon(A,R) = 3</code>. This means
that <code class="reqn">A</code> needs to be multiplied by 1/3 for all <code class="reqn">a_1</code> values and by 3
for all <code class="reqn">a_2</code> values in order to weakly dominate <code class="reqn">R</code>. The
computation of the multiplicative version for negative values doesn't make
sense.
</p>
<p>Computation of the epsilon indicator requires <code class="reqn">O(n \cdot |A| \cdot
|R|)</code>, where <code class="reqn">n</code> is the number of objectives (dimension of vectors).
</p>


<h3>Value</h3>

<p>A single numerical value.
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>References</h3>

<p>Eckart Zitzler, Lothar Thiele, Marco Laumanns, Carlos
M. Fonseca, Viviane Grunert da Fonseca (2003).
&ldquo;Performance Assessment of Multiobjective Optimizers: an Analysis and Review.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>7</b>(2), 117&ndash;132.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fig 6 from Zitzler et al. (2003).
A1 &lt;- matrix(c(9,2,8,4,7,5,5,6,4,7), ncol=2, byrow=TRUE)
A2 &lt;- matrix(c(8,4,7,5,5,6,4,7), ncol=2, byrow=TRUE)
A3 &lt;- matrix(c(10,4,9,5,8,6,7,7,6,8), ncol=2, byrow=TRUE)

plot(A1, xlab=expression(f[1]), ylab=expression(f[2]),
     panel.first=grid(nx=NULL), pch=4, cex=1.5, xlim = c(0,10), ylim=c(0,8))
points(A2, pch=0, cex=1.5)
points(A3, pch=1, cex=1.5)
legend("bottomleft", legend=c("A1", "A2", "A3"), pch=c(4,0,1),
       pt.bg="gray", bg="white", bty = "n", pt.cex=1.5, cex=1.2)
epsilon_mult(A1, A3) # A1 epsilon-dominates A3 =&gt; e = 9/10 &lt; 1 
epsilon_mult(A1, A2) # A1 weakly dominates A2 =&gt; e = 1
epsilon_mult(A2, A1) # A2 is epsilon-dominated by A1 =&gt; e = 2 &gt; 1

# A more realistic example
extdata_path &lt;- system.file(package="eaf","extdata")
path.A1 &lt;- file.path(extdata_path, "ALG_1_dat.xz")
path.A2 &lt;- file.path(extdata_path, "ALG_2_dat.xz")
A1 &lt;- read_datasets(path.A1)[,1:2]
A2 &lt;- read_datasets(path.A2)[,1:2]
ref &lt;- filter_dominated(rbind(A1, A2))
epsilon_additive(A1, ref)
epsilon_additive(A2, ref)
# Multiplicative version of epsilon metric
ref &lt;- filter_dominated(rbind(A1, A2))
epsilon_mult(A1, ref)
epsilon_mult(A2, ref)

</code></pre>

<hr>
<h2 id='gcp2x2'>Metaheuristics for solving the Graph Vertex Coloring Problem</h2><span id='topic+gcp2x2'></span>

<h3>Description</h3>

<p>Two metaheuristic algorithms, TabuCol (Hertz et al., 1987) and
simulated annealing (Johnson et al. 1991), to find a good
approximation of the chromatic number of two random graphs. The data
here has the only goal of providing an example of use of eafplot for
comparing algorithm performance with respect to both time and quality
when modelled as two objectives in trade off.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcp2x2
</code></pre>


<h3>Format</h3>

<p>A data frame with 3133 observations on the following 6 variables.
</p>

<dl>
<dt><code>alg</code></dt><dd><p>a factor with levels <code>SAKempeFI</code> and <code>TSinN1</code></p>
</dd>
<dt><code>inst</code></dt><dd><p>a factor with levels <code>DSJC500.5</code> and
<code>DSJC500.9</code>. Instances are taken from the DIMACS repository.</p>
</dd>
<dt><code>run</code></dt><dd><p>a numeric vector indicating the run to
which the observation belong. </p>
</dd>
<dt><code>best</code></dt><dd><p>a numeric vector indicating the best solution in
number of colors found in the corresponding run up to that time.</p>
</dd>
<dt><code>time</code></dt><dd><p>a numeric vector indicating the time since the
beginning of the run for each observation. A rescaling is applied.</p>
</dd>
<dt><code>titer</code></dt><dd><p>a numeric vector indicating iteration number
corresponding to the observations.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each algorithm was run 10 times per graph registering the time and
iteration number at which a new best solution was found. A time limit
corresponding to 500*10^5 total iterations of TabuCol was imposed. The
time was then normalized on a scale from 0 to 1 to make it instance
independent.
</p>


<h3>Source</h3>

<p>Marco Chiarandini (2005).
<em>Stochastic Local Search Methods for Highly Constrained Combinatorial Optimisation Problems</em>.
Ph.D. thesis, FB Informatik, TU Darmstadt, Germany. (page 138)
</p>


<h3>References</h3>

<p>A. Hertz and D. de Werra. Using Tabu Search Techniques for Graph
Coloring. Computing, 1987, 39(4), 345-351.
</p>
<p>David
S. Johnson, Cecilia
R. Aragon, Lyle
A. McGeoch, Catherine Schevon (1991).
&ldquo;Optimization by Simulated Annealing: An Experimental Evaluation: Part II, Graph Coloring and Number Partitioning.&rdquo;
<em>Operations Research</em>, <b>39</b>(3), 378&ndash;406.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gcp2x2)
</code></pre>

<hr>
<h2 id='hv_contributions'>Hypervolume contribution of a set of points</h2><span id='topic+hv_contributions'></span>

<h3>Description</h3>

<p>Computes the hypervolume contribution of each point given a set of points
with respect to a given reference point assuming minimization of all
objectives.  Dominated points have zero contribution. Duplicated points have
zero contribution even if not dominated, because removing one of them does
not change the hypervolume dominated by the remaining set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hv_contributions(data, reference, maximise = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hv_contributions_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="hv_contributions_+3A_reference">reference</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Reference point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="hv_contributions_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+numeric">numeric</a>) A numerical vector
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>References</h3>

<p>Carlos
M. Fonseca, Luís Paquete, Manuel López-Ibáñez (2006).
&ldquo;An improved dimension-sweep algorithm for the hypervolume indicator.&rdquo;
In <em>Proceedings of the 2006 Congress on Evolutionary Computation (CEC 2006)</em>, 1157&ndash;1163.
IEEE Press, Piscataway, NJ.
doi: <a href="https://doi.org/10.1109/CEC.2006.1688440">10.1109/CEC.2006.1688440</a>.
</p>
<p>Nicola Beume, Carlos
M. Fonseca, Manuel López-Ibáñez, Luís Paquete, Jan Vahrenhold (2009).
&ldquo;On the complexity of computing the hypervolume indicator.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>13</b>(5), 1075&ndash;1082.
doi: <a href="https://doi.org/10.1109/TEVC.2009.2015575">10.1109/TEVC.2009.2015575</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypervolume">hypervolume</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(SPEA2minstoptimeRichmond)
# The second objective must be maximized
# We calculate the hypervolume contribution of each point of the union of all sets.
hv_contributions(SPEA2minstoptimeRichmond[, 1:2], reference = c(250, 0),
            maximise = c(FALSE, TRUE))

# Duplicated points show zero contribution above, even if not
# dominated. However, filter_dominated removes all duplicates except
# one. Hence, there are more points below with nonzero contribution.
hv_contributions(filter_dominated(SPEA2minstoptimeRichmond[, 1:2], maximise = c(FALSE, TRUE)),
                 reference = c(250, 0), maximise = c(FALSE, TRUE))

</code></pre>

<hr>
<h2 id='HybridGA'>Results of Hybrid GA on vanzyl and Richmond water networks</h2><span id='topic+HybridGA'></span>

<h3>Description</h3>

<p>The data has the only goal of providing an example of use of eafplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HybridGA
</code></pre>


<h3>Format</h3>

<p>A list with two data frames, each of them with three columns, as
produced by <code><a href="#topic+read_datasets">read_datasets()</a></code>.
</p>

<dl>
<dt><code style="white-space: pre;">&#8288;$vanzyl&#8288;</code></dt><dd><p>data frame of results on vanzyl network</p>
</dd>
<dt><code style="white-space: pre;">&#8288;$richmond&#8288;</code></dt><dd><p>data frame of results on Richmond
network. The second column is filled with <code>NA</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Manuel López-Ibáñez (2009).
<em>Operational Optimisation of Water Distribution Networks</em>.
Ph.D. thesis, School of Engineering and the Built Environment, Edinburgh Napier University, UK.
<a href="https://researchrepository.napier.ac.uk/id/eprint/3044">https://researchrepository.napier.ac.uk/id/eprint/3044</a>..
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HybridGA)
print(HybridGA$vanzyl)
print(HybridGA$richmond)
</code></pre>

<hr>
<h2 id='hypervolume'>Hypervolume metric</h2><span id='topic+hypervolume'></span>

<h3>Description</h3>

<p>Computes the hypervolume metric with respect to a given reference point
assuming minimization of all objectives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypervolume(data, reference, maximise = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hypervolume_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="hypervolume_+3A_reference">reference</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Reference point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="hypervolume_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm has <code class="reqn">O(n^{d-2} \log n)</code> time and linear space
complexity in the worst-case, but experimental results show that the
pruning techniques used may reduce the time complexity even further.
</p>


<h3>Value</h3>

<p>A single numerical value.
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>References</h3>

<p>Carlos
M. Fonseca, Luís Paquete, Manuel López-Ibáñez (2006).
&ldquo;An improved dimension-sweep algorithm for the hypervolume indicator.&rdquo;
In <em>Proceedings of the 2006 Congress on Evolutionary Computation (CEC 2006)</em>, 1157&ndash;1163.
IEEE Press, Piscataway, NJ.
doi: <a href="https://doi.org/10.1109/CEC.2006.1688440">10.1109/CEC.2006.1688440</a>.
</p>
<p>Nicola Beume, Carlos
M. Fonseca, Manuel López-Ibáñez, Luís Paquete, Jan Vahrenhold (2009).
&ldquo;On the complexity of computing the hypervolume indicator.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>13</b>(5), 1075&ndash;1082.
doi: <a href="https://doi.org/10.1109/TEVC.2009.2015575">10.1109/TEVC.2009.2015575</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(SPEA2minstoptimeRichmond)
# The second objective must be maximized
# We calculate the hypervolume of the union of all sets.
hypervolume(SPEA2minstoptimeRichmond[, 1:2], reference = c(250, 0),
            maximise = c(FALSE, TRUE))

</code></pre>

<hr>
<h2 id='igd'>Inverted Generational Distance (IGD and IGD+) and Averaged Hausdorff Distance</h2><span id='topic+igd'></span><span id='topic+IGDX'></span><span id='topic+igd_plus'></span><span id='topic+avg_hausdorff_dist'></span>

<h3>Description</h3>

<p>Functions to compute the inverted generational distance (IGD and IGD+) and
the averaged Hausdorff distance between nondominated sets of points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>igd(data, reference, maximise = FALSE)

igd_plus(data, reference, maximise = FALSE)

avg_hausdorff_dist(data, reference, maximise = FALSE, p = 1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="igd_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="igd_+3A_reference">reference</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Reference set as a matrix or
data.frame of numerical values.</p>
</td></tr>
<tr><td><code id="igd_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="igd_+3A_p">p</code></td>
<td>
<p>(<code>integer(1)</code>) Hausdorff distance parameter (default: <code>1L</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generational distance (GD) of a set <code class="reqn">A</code> is defined as the distance
between each point <code class="reqn">a \in A</code> and the closest point <code class="reqn">r</code> in a
reference set <code class="reqn">R</code>, averaged over the size of <code class="reqn">A</code>. Formally,
</p>
<p style="text-align: center;"><code class="reqn">GD_p(A,R) = \left(\frac{1}{|A|}\sum_{a\in A}\min_{r\in R} d(a,r)^p\right)^{\frac{1}{p}} </code>
</p>

<p>where the distance in our implementation is the Euclidean distance:
</p>
<p style="text-align: center;"><code class="reqn">d(a,r) = \sqrt{\sum_{k=1}^M (a_k - r_k)^2} </code>
</p>

<p>The inverted generational distance (IGD) is calculated as <code class="reqn">IGD_p(A,R) = GD_p(R,A)</code>.
</p>
<p>The modified inverted generational distanced (IGD+) was proposed by
Ishibuchi et al. (2015) to ensure that IGD+ is weakly Pareto compliant,
similarly to <code><a href="#topic+epsilon_additive">epsilon_additive()</a></code> or <code><a href="#topic+epsilon_mult">epsilon_mult()</a></code>. It modifies the
distance measure as:
</p>
<p style="text-align: center;"><code class="reqn">d^+(r,a) = \sqrt{\sum_{k=1}^M (\max\{r_k - a_k, 0\})^2}</code>
</p>

<p>The average Hausdorff distance (<code class="reqn">\Delta_p</code>) was proposed by
Schütze et al. (2012) and it is calculated as:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_p(A,R) = \max\{ IGD_p(A,R), IGD_p(R,A) \}</code>
</p>

<p>IGDX (Zhou et al. 2009) is the application of IGD to decision vectors
instead of objective vectors to measure closeness and diversity in decision
space. One can use the functions <code>igd()</code> or <code>igd_plus()</code> (recommended)
directly, just passing the decision vectors as <code>data</code>.
</p>
<p>There are different formulations of the GD and IGD metrics in the literature
that differ on the value of <code class="reqn">p</code>, on the distance metric used and on
whether the term <code class="reqn">|A|^{-1}</code> is inside (as above) or outside the exponent
<code class="reqn">1/p</code>.  GD was first proposed by Van Veldhuizen and Lamont (1998) with <code class="reqn">p=2</code> and
the term <code class="reqn">|A|^{-1}</code> outside the exponent. IGD seems to have been
mentioned first by Coello Coello and Reyes-Sierra (2004), however, some people also used the
name D-metric for the same concept with <code class="reqn">p=1</code> and later papers have
often used IGD/GD with <code class="reqn">p=1</code>. Schütze et al. (2012) proposed to
place the term <code class="reqn">|A|^{-1}</code> inside the exponent, as in the formulation
shown above.  This has a significant effect for GD and less so for IGD given
a constant reference set. IGD+ also follows this formulation.  We refer to
Ishibuchi et al. (2015) and Bezerra et al. (2017) for a more detailed
historical perspective and a comparison of the various variants.
</p>
<p>Following Ishibuchi et al. (2015), we always use <code class="reqn">p=1</code> in our
implementation of IGD and IGD+ because (1) it is the setting most used in
recent works; (2) it makes irrelevant whether the term <code class="reqn">|A|^{-1}</code> is
inside or outside the exponent <code class="reqn">1/p</code>; and (3) the meaning of IGD becomes
the average Euclidean distance from each reference point to its nearest
objective vector). It is also slightly faster to compute.
</p>
<p>GD should never be used directly to compare the quality of approximations to
a Pareto front, as it often contradicts Pareto optimality (it is not weakly
Pareto-compliant). We recommend IGD+ instead of IGD, since the latter
contradicts Pareto optimality in some cases (see examples below) whereas
IGD+ is weakly Pareto-compliant, but we implement IGD here because it is
still popular due to historical reasons.
</p>
<p>The average Hausdorff distance (<code class="reqn">\Delta_p(A,R)</code>) is also not weakly
Pareto-compliant, as shown in the examples below.
</p>


<h3>Value</h3>

<p>(<code>numeric(1)</code>) A single numerical value.
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>References</h3>

<p>Leonardo
C.
T. Bezerra, Manuel López-Ibáñez, Thomas Stützle (2017).
&ldquo;An Empirical Assessment of the Properties of Inverted Generational Distance Indicators on Multi- and Many-objective Optimization.&rdquo;
In Heike Trautmann, Günter Rudolph, Kathrin Klamroth, Oliver Schütze, Margaret
M. Wiecek, Yaochu Jin, Christian Grimme (eds.), <em>Evolutionary Multi-criterion Optimization, EMO 2017</em>,  Lecture Notes in Computer Science, 31&ndash;45.
Springer International Publishing, Cham, Switzerland.
doi: <a href="https://doi.org/10.1007/978-3-319-54157-0_3">10.1007/978-3-319-54157-0_3</a>.<br /><br /> Carlos
A. Coello Coello, Margarita Reyes-Sierra (2004).
&ldquo;A Study of the Parallelization of a Coevolutionary Multi-objective Evolutionary Algorithm.&rdquo;
In Raúl Monroy, Gustavo Arroyo-Figueroa, Luis
Enrique Sucar, Humberto Sossa (eds.), <em>Proceedings of MICAI</em>, volume 2972 of <em>Lecture Notes in Artificial Intelligence</em>, 688&ndash;697.
Springer, Heidelberg, Germany.<br /><br /> Hisao Ishibuchi, Hiroyuki Masuda, Yuki Tanigaki, Yusuke Nojima (2015).
&ldquo;Modified Distance Calculation in Generational Distance and Inverted Generational Distance.&rdquo;
In António Gaspar-Cunha, Carlos
Henggeler Antunes, Carlos
A. Coello Coello (eds.), <em>Evolutionary Multi-criterion Optimization, EMO 2015 Part I</em>, volume 9018 of <em>Lecture Notes in Computer Science</em>, 110&ndash;125.
Springer, Heidelberg, Germany.<br /><br /> Oliver Schütze, X Esquivel, A Lara, Carlos
A. Coello Coello (2012).
&ldquo;Using the Averaged Hausdorff Distance as a Performance Measure in Evolutionary Multiobjective Optimization.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>16</b>(4), 504&ndash;522.<br /><br /> David
A. Van Veldhuizen, Gary
B. Lamont (1998).
&ldquo;Evolutionary Computation and Convergence to a Pareto Front.&rdquo;
In John
R. Koza (ed.), <em>Late Breaking Papers at the Genetic Programming 1998 Conference</em>, 221&ndash;228.<br /><br /> A Zhou, Qingfu Zhang, Yaochu Jin (2009).
&ldquo;Approximating the set of Pareto-optimal solutions in both the decision and objective spaces by an estimation of distribution algorithm.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>13</b>(5), 1167&ndash;1189.
doi: <a href="https://doi.org/10.1109/TEVC.2009.2021467">10.1109/TEVC.2009.2021467</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 4 from Ishibuchi et al. (2015)
ref &lt;- matrix(c(10,0,6,1,2,2,1,6,0,10), ncol=2, byrow=TRUE)
A &lt;- matrix(c(4,2,3,3,2,4), ncol=2, byrow=TRUE)
B &lt;- matrix(c(8,2,4,4,2,8), ncol=2, byrow=TRUE)
plot(ref, xlab=expression(f[1]), ylab=expression(f[2]),
     panel.first=grid(nx=NULL), pch=23, bg="gray", cex=1.5)
points(A, pch=1, cex=1.5)
points(B, pch=19, cex=1.5)
legend("topright", legend=c("Reference", "A", "B"), pch=c(23,1,19),
       pt.bg="gray", bg="white", bty = "n", pt.cex=1.5, cex=1.2)
cat("A is better than B in terms of Pareto optimality,\n however, IGD(A)=",
    igd(A, ref), "&gt; IGD(B)=", igd(B, ref),
    "and AvgHausdorff(A)=", avg_hausdorff_dist(A, ref),
    "&gt; AvgHausdorff(A)=", avg_hausdorff_dist(B, ref),
    ", which both contradict Pareto optimality.\nBy contrast, IGD+(A)=",
    igd_plus(A, ref), "&lt; IGD+(B)=", igd_plus(B, ref), ", which is correct.\n")

# A less trivial example.
extdata_path &lt;- system.file(package="eaf","extdata")
path.A1 &lt;- file.path(extdata_path, "ALG_1_dat.xz")
path.A2 &lt;- file.path(extdata_path, "ALG_2_dat.xz")
A1 &lt;- read_datasets(path.A1)[,1:2]
A2 &lt;- read_datasets(path.A2)[,1:2]
ref &lt;- filter_dominated(rbind(A1, A2))
igd(A1, ref)
igd(A2, ref)

# IGD+ (Pareto compliant)
igd_plus(A1, ref)
igd_plus(A2, ref)

# Average Haussdorff distance
avg_hausdorff_dist(A1, ref)
avg_hausdorff_dist(A2, ref)
</code></pre>

<hr>
<h2 id='is_nondominated'>Identify, remove and rank dominated points according to Pareto optimality</h2><span id='topic+is_nondominated'></span><span id='topic+filter_dominated'></span><span id='topic+pareto_rank'></span>

<h3>Description</h3>

<p>Identify nondominated points with <code>is_nondominated</code> and remove dominated
ones with <code>filter_dominated</code>.
</p>
<p><code>pareto_rank()</code> ranks points according to Pareto-optimality,
which is also called nondominated sorting (Deb et al. 2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_nondominated(data, maximise = FALSE, keep_weakly = FALSE)

filter_dominated(data, maximise = FALSE, keep_weakly = FALSE)

pareto_rank(data, maximise = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_nondominated_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="is_nondominated_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="is_nondominated_+3A_keep_weakly">keep_weakly</code></td>
<td>
<p>If <code>FALSE</code>, return <code>FALSE</code> for any duplicates
of nondominated points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pareto_rank()</code> is meant to be used like <code>rank()</code>, but it
assigns ranks according to Pareto dominance. Duplicated points are kept on
the same front. When <code>ncol(data) == 2</code>, the code uses the <code class="reqn">O(n
  \log n)</code> algorithm by Jensen (2003).
</p>


<h3>Value</h3>

<p><code>is_nondominated</code> returns a logical vector of the same length
as the number of rows of <code>data</code>, where <code>TRUE</code> means that the
point is not dominated by any other point.
</p>
<p><code>filter_dominated</code> returns a matrix or data.frame with only mutually nondominated points.
</p>
<p><code>pareto_rank()</code> returns an integer vector of the same length as
the number of rows of <code>data</code>, where each value gives the rank of each
point.
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>References</h3>

<p>Kalyanmoy Deb, A Pratap, S Agarwal, T Meyarivan (2002).
&ldquo;A fast and elitist multi-objective genetic algorithm: NSGA-II.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>6</b>(2), 182&ndash;197.
doi: <a href="https://doi.org/10.1109/4235.996017">10.1109/4235.996017</a>.<br /><br /> M
T Jensen (2003).
&ldquo;Reducing the run-time complexity of multiobjective EAs: The NSGA-II and other algorithms.&rdquo;
<em>IEEE Transactions on Evolutionary Computation</em>, <b>7</b>(5), 503&ndash;515.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path_A1 &lt;- file.path(system.file(package="eaf"),"extdata","ALG_1_dat.xz")
set &lt;- read_datasets(path_A1)[,1:2]

is_nondom &lt;- is_nondominated(set)
cat("There are ", sum(is_nondom), " nondominated points\n")

plot(set, col = "blue", type = "p", pch = 20)
ndset &lt;- filter_dominated(set)
points(ndset[order(ndset[,1]),], col = "red", pch = 21)

ranks &lt;- pareto_rank(set)
colors &lt;- colorRampPalette(c("red","yellow","springgreen","royalblue"))(max(ranks))
plot(set, col = colors[ranks], type = "p", pch = 20)
</code></pre>

<hr>
<h2 id='largest_eafdiff'>Identify largest EAF differences</h2><span id='topic+largest_eafdiff'></span>

<h3>Description</h3>

<p>Given a list of datasets, return the indexes of the pair with the largest
EAF differences according to the method proposed by Diaz and López-Ibáñez (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>largest_eafdiff(data, maximise = FALSE, intervals = 5, reference, ideal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="largest_eafdiff_+3A_data">data</code></td>
<td>
<p>(<code>list(1)</code>) A list of matrices with at least 3 columns</p>
</td></tr>
<tr><td><code id="largest_eafdiff_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="largest_eafdiff_+3A_intervals">intervals</code></td>
<td>
<p>(<code>integer(1)</code>) <br /> The absolute range of the differences
<code class="reqn">[0, 1]</code> is partitioned into the number of intervals provided.</p>
</td></tr>
<tr><td><code id="largest_eafdiff_+3A_reference">reference</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Reference point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="largest_eafdiff_+3A_ideal">ideal</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Ideal point as a vector of numerical values. If <code>NULL</code>, it is calculated as minimum (resp. maximum if maximising that objective) of each objective in <code>data</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>list()</code>) A list with two components <code>pair</code> and <code>value</code>.
</p>


<h3>References</h3>

<p>Juan
Esteban Diaz, Manuel López-Ibáñez (2021).
&ldquo;Incorporating Decision-Maker's Preferences into the Automatic Configuration of Bi-Objective Optimisation Algorithms.&rdquo;
<em>European Journal of Operational Research</em>, <b>289</b>(3), 1209&ndash;1222.
doi: <a href="https://doi.org/10.1016/j.ejor.2020.07.059">10.1016/j.ejor.2020.07.059</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># FIXME: This example is too large, we need a smaller one.
files &lt;- c("wrots_l100w10_dat","wrots_l10w100_dat")
data &lt;- lapply(files, function(x)
               read_datasets(file.path(system.file(package="eaf"),
                             "extdata", x)))
nadir &lt;- apply(do.call(rbind, data)[,1:2], 2, max)
x &lt;- largest_eafdiff(data, reference = nadir)
str(x)

</code></pre>

<hr>
<h2 id='normalise'>Normalise points</h2><span id='topic+normalise'></span>

<h3>Description</h3>

<p>Normalise points per coordinate to a range, e.g., <code>c(1,2)</code>, where the
minimum value will correspond to 1 and the maximum to 2. If bounds are
given, they are used for the normalisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalise(data, to_range = c(1, 2), lower = NA, upper = NA, maximise = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalise_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="normalise_+3A_to_range">to_range</code></td>
<td>
<p>Normalise values to this range. If the objective is
maximised, it is normalised to <code>c(to_range[1], to_range[0])</code>
instead.</p>
</td></tr>
<tr><td><code id="normalise_+3A_lower">lower</code>, <code id="normalise_+3A_upper">upper</code></td>
<td>
<p>Bounds on the values. If NA, the maximum and minimum
values of each coordinate are used.</p>
</td></tr>
<tr><td><code id="normalise_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numerical matrix
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(SPEA2minstoptimeRichmond)
# The second objective must be maximized
head(SPEA2minstoptimeRichmond[, 1:2])

head(normalise(SPEA2minstoptimeRichmond[, 1:2], maximise = c(FALSE, TRUE)))

head(normalise(SPEA2minstoptimeRichmond[, 1:2], to_range = c(0,1), maximise = c(FALSE, TRUE)))

</code></pre>

<hr>
<h2 id='pdf_crop'>Remove whitespace margins from a PDF file (and maybe embed fonts)</h2><span id='topic+pdf_crop'></span>

<h3>Description</h3>

<p>Remove whitespace margins using <a href="https://ctan.org/pkg/pdfcrop">https://ctan.org/pkg/pdfcrop</a> and
optionally embed fonts using <code><a href="grDevices.html#topic+embedFonts">grDevices::embedFonts()</a></code>. You may install
<code>pdfcrop</code> using TinyTeX (<a href="https://cran.r-project.org/package=tinytex">https://cran.r-project.org/package=tinytex</a>) with
<code>tinytex::tlmgr_install('pdfcrop')</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdf_crop(
  filename,
  mustWork = FALSE,
  pdfcrop = Sys.which("pdfcrop"),
  embed_fonts = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdf_crop_+3A_filename">filename</code></td>
<td>
<p>Filename of a PDF file to crop. The file will be overwritten.</p>
</td></tr>
<tr><td><code id="pdf_crop_+3A_mustwork">mustWork</code></td>
<td>
<p>If <code>TRUE</code>, then give an error if the file cannot be cropped.</p>
</td></tr>
<tr><td><code id="pdf_crop_+3A_pdfcrop">pdfcrop</code></td>
<td>
<p>Path to the <code>pdfcrop</code> utility.</p>
</td></tr>
<tr><td><code id="pdf_crop_+3A_embed_fonts">embed_fonts</code></td>
<td>
<p>(<code>logical(1)</code>) If <code>TRUE</code>, use <code><a href="grDevices.html#topic+embedFonts">grDevices::embedFonts()</a></code> to embed fonts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You may also wish to consider <code><a href="extrafont.html#topic+embed_fonts">extrafont::embed_fonts()</a></code>
(<a href="https://cran.r-project.org/package=extrafont">https://cran.r-project.org/package=extrafont</a>).
</p>
<div class="sourceCode"><pre>library(extrafont)
# If you need to specify the path to Ghostscript (probably not needed in Linux)
Sys.setenv(R_GSCMD = "C:/Program Files/gs/gs9.56.1/bin/gswin64c.exe")
embed_fonts("original.pdf", outfile = "new.pdf")
</pre></div>
<p>As an alternative, saving the PDF with <code><a href="grDevices.html#topic+cairo">grDevices::cairo_pdf()</a></code> should
already embed the fonts.
</p>


<h3>Value</h3>

<p>Nothing
</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+embedFonts">grDevices::embedFonts()</a></code> <code><a href="extrafont.html#topic+embed_fonts">extrafont::embed_fonts()</a></code> <code><a href="grDevices.html#topic+cairo">grDevices::cairo_pdf()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
extdata_path &lt;- system.file(package = "eaf", "extdata")
A1 &lt;- read_datasets(file.path(extdata_path, "wrots_l100w10_dat"))
A2 &lt;- read_datasets(file.path(extdata_path, "wrots_l10w100_dat"))
pdf(file = "eaf.pdf", onefile = TRUE, width = 5, height = 4)
eafplot(list(A1 = A1, A2 = A2), percentiles = 50, sci.notation=TRUE)
dev.off()
pdf_crop("eaf.pdf")

## End(Not run)
</code></pre>

<hr>
<h2 id='read_datasets'>Read several data sets</h2><span id='topic+read_datasets'></span><span id='topic+read.data.sets'></span>

<h3>Description</h3>

<p>Reads a text file in table format and creates a matrix from it. The file
may contain several sets, separated by empty lines. Lines starting by
<code>'#'</code> are considered comments and treated as empty lines. The function
adds an additional column <code>set</code> to indicate to which set each row
belongs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_datasets(file, col_names, text)

read.data.sets(file, col.names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_datasets_+3A_file">file</code></td>
<td>
<p>(<code>character()</code>) <br /> Filename that contains the data.  Each row
of the table appears as one line of the file.  If it does not contain an
<em>absolute</em> path, the file name is <em>relative</em> to the current
working directory, <code><a href="base.html#topic+getwd">getwd</a>()</code>.  Tilde-expansion is
performed where supported.  Files compressed with <code>xz</code> are supported.</p>
</td></tr>
<tr><td><code id="read_datasets_+3A_col_names">col_names</code>, <code id="read_datasets_+3A_col.names">col.names</code></td>
<td>
<p>Vector of optional names for the variables.  The
default is to use &lsquo;<span class="samp">&#8288;"V"&#8288;</span>&rsquo; followed by the column number.</p>
</td></tr>
<tr><td><code id="read_datasets_+3A_text">text</code></td>
<td>
<p>(<code>character()</code>) <br /> If <code>file</code> is not supplied and this is,
then data are read from the value of <code>text</code> via a text connection.
Notice that a literal string can be used to include (small) data sets
within R code.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>matrix()</code>) containing a representation of the
data in the file. An extra column <code>set</code> is added to indicate to
which set each row belongs.
</p>


<h3>Warning</h3>

<p>A known limitation is that the input file must use newline characters
native to the host system, otherwise they will be, possibly silently,
misinterpreted. In GNU/Linux the program <code>dos2unix</code> may be used
to fix newline characters.
</p>


<h3>Note</h3>

<p>There are several examples of data sets in
<code>system.file(package="eaf","extdata")</code>.
</p>
<p><code>read.data.sets()</code> is a deprecated alias. It will be removed in the next
major release.
</p>


<h3>Author(s)</h3>

<p>Manuel López-Ibáñez
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+read.table">read.table</a></code>, <code><a href="#topic+eafplot">eafplot()</a></code>, <code><a href="#topic+eafdiffplot">eafdiffplot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>extdata_path &lt;- system.file(package="eaf","extdata")
A1 &lt;- read_datasets(file.path(extdata_path,"ALG_1_dat.xz"))
str(A1)

read_datasets(text="1 2\n3 4\n\n5 6\n7 8\n", col_names=c("obj1", "obj2"))

</code></pre>

<hr>
<h2 id='SPEA2minstoptimeRichmond'>Results of SPEA2 when minimising electrical cost and maximising the
minimum idle time of pumps on Richmond water network.</h2><span id='topic+SPEA2minstoptimeRichmond'></span>

<h3>Description</h3>

<p>The data has the only goal of providing an example of use of eafplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPEA2minstoptimeRichmond
</code></pre>


<h3>Format</h3>

<p>A data frame as produced by <code><a href="#topic+read_datasets">read_datasets()</a></code>. The second
column measures time in seconds and corresponds to a maximisation problem.
</p>


<h3>Source</h3>

<p>Manuel López-Ibáñez (2009).
<em>Operational Optimisation of Water Distribution Networks</em>.
Ph.D. thesis, School of Engineering and the Built Environment, Edinburgh Napier University, UK.
<a href="https://researchrepository.napier.ac.uk/id/eprint/3044">https://researchrepository.napier.ac.uk/id/eprint/3044</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HybridGA)
data(SPEA2minstoptimeRichmond)
SPEA2minstoptimeRichmond[,2] &lt;- SPEA2minstoptimeRichmond[,2] / 60
eafplot (SPEA2minstoptimeRichmond, xlab = expression(C[E]),
         ylab = "Minimum idle time (minutes)", maximise = c(FALSE, TRUE),
         las = 1, log = "y", legend.pos = "bottomright")
</code></pre>

<hr>
<h2 id='SPEA2relativeRichmond'>Results of SPEA2 with relative time-controlled triggers on Richmond water
network.</h2><span id='topic+SPEA2relativeRichmond'></span>

<h3>Description</h3>

<p>The data has the only goal of providing an example of use of eafplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPEA2relativeRichmond
</code></pre>


<h3>Format</h3>

<p>A data frame as produced by <code><a href="#topic+read_datasets">read_datasets()</a></code>.
</p>


<h3>Source</h3>

<p>Manuel López-Ibáñez (2009).
<em>Operational Optimisation of Water Distribution Networks</em>.
Ph.D. thesis, School of Engineering and the Built Environment, Edinburgh Napier University, UK.
<a href="https://researchrepository.napier.ac.uk/id/eprint/3044">https://researchrepository.napier.ac.uk/id/eprint/3044</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HybridGA)
data(SPEA2relativeRichmond)
eafplot (SPEA2relativeRichmond, percentiles = c(25, 50, 75),
        xlab = expression(C[E]), ylab = "Total switches",
        xlim = c(90, 140), ylim = c(0, 25),
        extra.points = HybridGA$richmond, extra.lty = "dashed",
        extra.legend = "Hybrid GA")
</code></pre>

<hr>
<h2 id='SPEA2relativeVanzyl'>Results of SPEA2 with relative time-controlled triggers on Vanzyl's
water network.</h2><span id='topic+SPEA2relativeVanzyl'></span>

<h3>Description</h3>

<p>The data has the only goal of providing an example of use of eafplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPEA2relativeVanzyl
</code></pre>


<h3>Format</h3>

<p>A data frame as produced by <code><a href="#topic+read_datasets">read_datasets()</a></code>.
</p>


<h3>Source</h3>

<p>Manuel López-Ibáñez (2009).
<em>Operational Optimisation of Water Distribution Networks</em>.
Ph.D. thesis, School of Engineering and the Built Environment, Edinburgh Napier University, UK.
<a href="https://researchrepository.napier.ac.uk/id/eprint/3044">https://researchrepository.napier.ac.uk/id/eprint/3044</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HybridGA)
data(SPEA2relativeVanzyl)
eafplot(SPEA2relativeVanzyl, percentiles = c(25, 50, 75), 
       xlab = expression(C[E]), ylab = "Total switches", xlim = c(320, 400),
       extra.points = HybridGA$vanzyl, extra.legend = "Hybrid GA")
</code></pre>

<hr>
<h2 id='vorobT'>Vorob'ev computations</h2><span id='topic+vorobT'></span><span id='topic+vorobDev'></span><span id='topic+symDifPlot'></span>

<h3>Description</h3>

<p>Compute Vorob'ev threshold, expectation and deviation. Also, displaying the
symmetric deviation function is possible.  The symmetric deviation
function is the probability for a given target in the objective space to
belong to the symmetric difference between the Vorob'ev expectation and a
realization of the (random) attained set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vorobT(x, reference)

vorobDev(x, VE, reference)

symDifPlot(
  x,
  VE,
  threshold,
  nlevels = 11,
  ve.col = "blue",
  xlim = NULL,
  ylim = NULL,
  legend.pos = "topright",
  main = "Symmetric deviation function",
  col.fun = function(n) gray(seq(0, 0.9, length.out = n)^2)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vorobT_+3A_x">x</code></td>
<td>
<p>Either a matrix of data values, or a data frame, or a list of data
frames of exactly three columns.  The third column gives the set (run,
sample, ...) identifier.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_reference">reference</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Reference point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_ve">VE</code>, <code id="vorobT_+3A_threshold">threshold</code></td>
<td>
<p>Vorob'ev expectation and threshold, e.g., as returned
by <code><a href="#topic+vorobT">vorobT()</a></code>.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_nlevels">nlevels</code></td>
<td>
<p>number of levels in which is divided the range of the
symmetric deviation.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_ve.col">ve.col</code></td>
<td>
<p>plotting parameters for the Vorob'ev expectation.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_xlim">xlim</code>, <code id="vorobT_+3A_ylim">ylim</code>, <code id="vorobT_+3A_main">main</code></td>
<td>
<p>Graphical parameters, see
<code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_legend.pos">legend.pos</code></td>
<td>
<p>the position of the legend, see
<code><a href="graphics.html#topic+legend">legend()</a></code>. A value of <code>"none"</code> hides the legend.</p>
</td></tr>
<tr><td><code id="vorobT_+3A_col.fun">col.fun</code></td>
<td>
<p>function that creates a vector of <code>n</code> colors, see
<code><a href="grDevices.html#topic+palettes">heat.colors()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>vorobT</code> returns a list with elements <code>threshold</code>,
<code>VE</code>, and <code>avg_hyp</code> (average hypervolume)
</p>
<p><code>vorobDev</code> returns the Vorob'ev deviation.
</p>


<h3>Author(s)</h3>

<p>Mickael Binois
</p>


<h3>References</h3>

<p>M Binois, D Ginsbourger, O Roustant (2015).
&ldquo;Quantifying uncertainty on Pareto fronts with Gaussian process conditional simulations.&rdquo;
<em>European Journal of Operational Research</em>, <b>243</b>(2), 386&ndash;394.
doi: <a href="https://doi.org/10.1016/j.ejor.2014.07.032">10.1016/j.ejor.2014.07.032</a>.
</p>
<p>C. Chevalier (2013), Fast uncertainty reduction strategies relying on
Gaussian process models, University of Bern, PhD thesis.
</p>
<p>I. Molchanov (2005), Theory of random sets, Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(CPFs)
res &lt;- vorobT(CPFs, reference = c(2, 200))
print(res$threshold)

## Display Vorob'ev expectation and attainment function
# First style
eafplot(CPFs[,1:2], sets = CPFs[,3], percentiles = c(0, 25, 50, 75, 100, res$threshold),
        main = substitute(paste("Empirical attainment function, ",beta,"* = ", a, "%"),
                          list(a = formatC(res$threshold, digits = 2, format = "f"))))

# Second style
eafplot(CPFs[,1:2], sets = CPFs[,3], percentiles = c(0, 20, 40, 60, 80, 100),
        col = gray(seq(0.8, 0.1, length.out = 6)^0.5), type = "area", 
        legend.pos = "bottomleft", extra.points = res$VE, extra.col = "cyan",
        extra.legend = "VE", extra.lty = "solid", extra.pch = NA, extra.lwd = 2,
        main = substitute(paste("Empirical attainment function, ",beta,"* = ", a, "%"),
                          list(a = formatC(res$threshold, digits = 2, format = "f"))))

# Now print Vorob'ev deviation
VD &lt;- vorobDev(CPFs, res$VE, reference = c(2, 200))
print(VD)
# Now display the symmetric deviation function.
symDifPlot(CPFs, res$VE, res$threshold, nlevels = 11)
# Levels are adjusted automatically if too large.
symDifPlot(CPFs, res$VE, res$threshold, nlevels = 200, legend.pos = "none")

# Use a different palette.
symDifPlot(CPFs, res$VE, res$threshold, nlevels = 11, col.fun = heat.colors)
</code></pre>

<hr>
<h2 id='whv_hype'>Approximation of the (weighted) hypervolume by Monte-Carlo sampling (2D only)</h2><span id='topic+whv_hype'></span>

<h3>Description</h3>

<p>Return an estimation of the hypervolume of the space dominated by the input
data following the procedure described by Auger et al. (2009). A
weight distribution describing user preferences may be specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whv_hype(
  data,
  reference,
  ideal,
  maximise = FALSE,
  dist = list(type = "uniform"),
  nsamples = 100000L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="whv_hype_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="whv_hype_+3A_reference">reference</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Reference point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="whv_hype_+3A_ideal">ideal</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Ideal point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="whv_hype_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="whv_hype_+3A_dist">dist</code></td>
<td>
<p>(<code>list()</code>) weight distribution. See Details.</p>
</td></tr>
<tr><td><code id="whv_hype_+3A_nsamples">nsamples</code></td>
<td>
<p>(<code>integer(1)</code>) number of samples for Monte-Carlo sampling.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The current implementation only supports 2 objectives.
</p>
<p>A weight distribution  (Auger et al. 2009) can be provided via the <code>dist</code> argument. The ones currently supported are:
</p>

<ul>
<li> <p><code>type="uniform"</code> corresponds to the default hypervolume (unweighted).
</p>
</li>
<li> <p><code>type="point"</code> describes a goal in the objective space, where <code>mu</code> gives the coordinates of the goal. The resulting weight distribution is a multivariate normal distribution centred at the goal.
</p>
</li>
<li> <p><code>type="exponential"</code> describes an exponential distribution with rate parameter <code>1/mu</code>, i.e., <code class="reqn">\lambda = \frac{1}{\mu}</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A single numerical value.
</p>


<h3>References</h3>

<p>Anne Auger, Johannes Bader, Dimo Brockhoff, Eckart Zitzler (2009).
&ldquo;Articulating User Preferences in Many-Objective Problems by Sampling the Weighted Hypervolume.&rdquo;
In Franz Rothlauf (ed.), <em>Proceedings of the Genetic and Evolutionary Computation Conference, GECCO 2009</em>, 555&ndash;562.
ACM Press, New York, NY.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code>, <code><a href="#topic+eafdiff">eafdiff()</a></code>, <code><a href="#topic+whv_rect">whv_rect()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
whv_hype (matrix(2, ncol=2), reference = 4, ideal = 1)

whv_hype (matrix(c(3,1), ncol=2), reference = 4, ideal = 1)

whv_hype (matrix(2, ncol=2), reference = 4, ideal = 1,
          dist = list(type="exponential", mu=0.2))

whv_hype (matrix(c(3,1), ncol=2), reference = 4, ideal = 1,
          dist = list(type="exponential", mu=0.2))

whv_hype (matrix(2, ncol=2), reference = 4, ideal = 1,
          dist = list(type="point", mu=c(1,1)))

whv_hype (matrix(c(3,1), ncol=2), reference = 4, ideal = 1,
          dist = list(type="point", mu=c(1,1)))

</code></pre>

<hr>
<h2 id='whv_rect'>Compute (total) weighted hypervolume given a set of rectangles</h2><span id='topic+whv_rect'></span><span id='topic+total_whv_rect'></span>

<h3>Description</h3>

<p>Calculates the hypervolume weighted by a set of rectangles (with zero weight outside the rectangles). The function <code><a href="#topic+total_whv_rect">total_whv_rect()</a></code> calculates the total weighted hypervolume as <code><a href="#topic+hypervolume">hypervolume()</a></code><code> + scalefactor * abs(prod(reference - ideal)) * whv_rect()</code>. The details of the computation are given by Diaz and López-Ibáñez (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whv_rect(data, rectangles, reference, maximise = FALSE)

total_whv_rect(
  data,
  rectangles,
  reference,
  maximise = FALSE,
  ideal = NULL,
  scalefactor = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="whv_rect_+3A_data">data</code></td>
<td>
<p>(<code>matrix</code> | <code>data.frame</code>) <br /> Matrix or data frame of numerical
values, where each row gives the coordinates of a point.</p>
</td></tr>
<tr><td><code id="whv_rect_+3A_rectangles">rectangles</code></td>
<td>
<p>(<code>matrix()</code>) Weighted rectangles that will bias the
computation of the hypervolume. Maybe generated by <code><a href="#topic+eafdiff">eafdiff()</a></code> with
<code>rectangles=TRUE</code> or by <code><a href="#topic+choose_eafdiff">choose_eafdiff()</a></code>.</p>
</td></tr>
<tr><td><code id="whv_rect_+3A_reference">reference</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Reference point as a vector of numerical values.</p>
</td></tr>
<tr><td><code id="whv_rect_+3A_maximise">maximise</code></td>
<td>
<p>(<code>logical()</code> | <code>logical(1)</code>) <br /> Whether the objectives must be
maximised instead of minimised. Either a single logical value that applies
to all objectives or a vector of logical values, with one value per
objective.</p>
</td></tr>
<tr><td><code id="whv_rect_+3A_ideal">ideal</code></td>
<td>
<p>(<code>numeric()</code>) <br /> Ideal point as a vector of numerical values. If <code>NULL</code>, it is calculated as minimum (resp. maximum if maximising that objective) of each objective in <code>data</code>.</p>
</td></tr>
<tr><td><code id="whv_rect_+3A_scalefactor">scalefactor</code></td>
<td>
<p>(<code>numeric(1)</code>) real value within <code class="reqn">(0,1]</code> that scales
the overall weight of the differences. This is parameter psi (<code class="reqn">\psi</code>) in Diaz and López-Ibáñez (2021).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TODO
</p>


<h3>Value</h3>

<p>A single numerical value.
</p>


<h3>References</h3>

<p>Juan
Esteban Diaz, Manuel López-Ibáñez (2021).
&ldquo;Incorporating Decision-Maker's Preferences into the Automatic Configuration of Bi-Objective Optimisation Algorithms.&rdquo;
<em>European Journal of Operational Research</em>, <b>289</b>(3), 1209&ndash;1222.
doi: <a href="https://doi.org/10.1016/j.ejor.2020.07.059">10.1016/j.ejor.2020.07.059</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_datasets">read_datasets()</a></code>, <code><a href="#topic+eafdiff">eafdiff()</a></code>, <code><a href="#topic+choose_eafdiff">choose_eafdiff()</a></code>, <code><a href="#topic+whv_hype">whv_hype()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

rectangles &lt;- as.matrix(read.table(header=FALSE, text='
 1.0  3.0  2.0  Inf    1
 2.0  3.5  2.5  Inf    2
 2.0  3.0  3.0  3.5    3
'))
whv_rect (matrix(2, ncol=2), rectangles, reference = 6)
whv_rect (matrix(c(2, 1), ncol=2), rectangles, reference = 6)
whv_rect (matrix(c(1, 2), ncol=2), rectangles, reference = 6)

total_whv_rect (matrix(2, ncol=2), rectangles, reference = 6, ideal = c(1,1))
total_whv_rect (matrix(c(2, 1), ncol=2), rectangles, reference = 6, ideal = c(1,1))
total_whv_rect (matrix(c(1, 2), ncol=2), rectangles, reference = 6, ideal = c(1,1))

</code></pre>

<hr>
<h2 id='write_datasets'>Write data sets</h2><span id='topic+write_datasets'></span>

<h3>Description</h3>

<p>Write data sets to a file in the same format as <code><a href="#topic+read_datasets">read_datasets()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_datasets(x, file = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_datasets_+3A_x">x</code></td>
<td>
<p>The data set to write. The last column must be the set number.</p>
</td></tr>
<tr><td><code id="write_datasets_+3A_file">file</code></td>
<td>
<p>either a character string naming a file or a connection open for
writing. <code>""</code> indicates output to the console.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+write.table">write.table</a></code>, <code><a href="#topic+read_datasets">read_datasets()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- read_datasets(text="1 2\n3 4\n\n5 6\n7 8\n", col_names=c("obj1", "obj2"))
write_datasets(x)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
