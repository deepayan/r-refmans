<!DOCTYPE html><html><head><title>Help for package BeeBDC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BeeBDC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#atlasDownloader'><p>Download occurrence data from the Atlas of Living Australia (ALA)</p></a></li>
<li><a href='#BeeBDCQuery'><p>Query the bee taxonomy and country checklist</p></a></li>
<li><a href='#bees3sp'><p>A flagged dataset of 105 random bee occurrence records from the three species</p></a></li>
<li><a href='#beesChecklist'><p>Download a country-level checklist of bees from Discover Life</p></a></li>
<li><a href='#beesFlagged'><p>A flagged dataset of 100 random bee occurrence records</p></a></li>
<li><a href='#beesRaw'><p>A dataset of 100 random bee occurrence records without flags or filters applied</p></a></li>
<li><a href='#beesTaxonomy'><p>Download a nearly complete taxonomy of bees globally</p></a></li>
<li><a href='#chordDiagramR'><p>Build a chord diagram of duplicate occurrence links</p></a></li>
<li><a href='#ColTypeR'><p>Sets up column names and types</p></a></li>
<li><a href='#coordUncerFlagR'><p>Flag occurrences with an uncertainty threshold</p></a></li>
<li><a href='#countryNameCleanR'><p>Fix country name issues using a user-input list</p></a></li>
<li><a href='#countryOutlieRs'><p>Flag country-level outliers with a provided checklist.</p></a></li>
<li><a href='#dataProvTables'><p>Build a table of data providers for bee occurrence records</p></a></li>
<li><a href='#dataSaver'><p>Simple function to save occurrence AND EML data as a list</p></a></li>
<li><a href='#dateFindR'><p>Find dates in other columns</p></a></li>
<li><a href='#diagonAlley'><p>Find fill-down errors</p></a></li>
<li><a href='#dirMaker'><p>Set up global directory paths and create folders</p></a></li>
<li><a href='#dupePlotR'><p>Create a compound bar graph of duplicate data sources</p></a></li>
<li><a href='#dupeSummary'><p>Identifies duplicate occurrence records</p></a></li>
<li><a href='#fileFinder'><p>Finds files within a directory</p></a></li>
<li><a href='#flagAbsent'><p>Flags occurrences that are marked as absent</p></a></li>
<li><a href='#flagLicense'><p>Flag license protected records</p></a></li>
<li><a href='#flagRecorder'><p>Loads, appends, and saves occurrence flag data</p></a></li>
<li><a href='#flagSummaryTable'><p>Build a per-species summary for each and all flags</p></a></li>
<li><a href='#formattedCombiner'><p>Combine the formatted USGS data with the main dataset</p></a></li>
<li><a href='#GBIFissues'><p>Flags records with GBIF issues</p></a></li>
<li><a href='#harmoniseR'><p>Harmonise taxonomy of bee occurrence data</p></a></li>
<li><a href='#idMatchR'><p>Attempt to match database_ids from a prior run</p></a></li>
<li><a href='#importOccurrences'><p>Imports the most-recent repoMerge data</p></a></li>
<li><a href='#interactiveMapR'><p>Creates interactive html maps for species</p></a></li>
<li><a href='#jbd_CfC_chunker'><p>Get country names from coordinates</p></a></li>
<li><a href='#jbd_coordCountryInconsistent'><p>Flags coordinates that are inconsistent with the stated country name</p></a></li>
<li><a href='#jbd_coordinates_precision'><p>Flags coordinates for imprecision</p></a></li>
<li><a href='#jbd_coordinates_transposed'><p>Identify transposed geographic coordinates</p></a></li>
<li><a href='#jbd_create_figures'><p>Create figures reporting the results of the bdc/BeeBDC packages</p></a></li>
<li><a href='#jbd_Ctrans_chunker'><p>Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences</p></a></li>
<li><a href='#manualOutlierFindeR'><p>Finds outliers, and their duplicates, as determined by experts</p></a></li>
<li><a href='#PaigeIntegrater'><p>Integrate manually-cleaned data from Paige Chesshire</p></a></li>
<li><a href='#plotFlagSummary'><p>Generate a plot summarising flagged data</p></a></li>
<li><a href='#readr_BeeBDC'><p>A wrapper for all of the data readr_functions</p></a></li>
<li><a href='#repoFinder'><p>Find GBIF, ALA, iDigBio, and SCAN files in a directory</p></a></li>
<li><a href='#repoMerge'><p>Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads</p></a></li>
<li><a href='#summaryFun'><p>Create or update the .summary flag column</p></a></li>
<li><a href='#summaryMaps'><p>Create country-level summary maps of species and occurrence numbers</p></a></li>
<li><a href='#taxadbToBeeBDC'><p>Import and convert taxadb taxonomies to BeeBDC format</p></a></li>
<li><a href='#USGS_formatter'><p>Find, import, and format USGS data to Darwin Core</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Occurrence Data Cleaning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Flags and checks occurrence data that are in Darwin Core
    format.  The package includes generic functions and data as well as
    some that are specific to bees. This package is meant to build upon
    and be complimentary to other excellent occurrence cleaning packages,
    including 'bdc' and 'CoordinateCleaner'.  This package uses datasets
    from several sources and particularly from the Discover Life Website,
    created by Ascher and Pickering (2020).  For further information,
    please see the original publication and package website.  Publication
    - Dorey et al. (2023) &lt;<a href="https://doi.org/10.1101%2F2023.06.30.547152">doi:10.1101/2023.06.30.547152</a>&gt; and package
    website - Dorey et al. (2023) <a href="https://github.com/jbdorey/BeeBDC">https://github.com/jbdorey/BeeBDC</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jbdorey/BeeBDC/issues">https://github.com/jbdorey/BeeBDC/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>circlize, CoordinateCleaner, cowplot, dplyr, forcats, ggplot2,
ggspatial, here, igraph, lubridate, mgsub, openxlsx, paletteer,
readr, rnaturalearth, sf, stringr, tidyselect</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bdc, BiocManager, classInt, ComplexHeatmap, countrycode,
devtools, emld, formatR, galah, hexbin, htmltools, htmlwidgets,
httr, janitor, knitr, leaflet, magrittr, pkgdown, plotly,
prettydoc, purrr, R.utils, renv, rgnparser, rlang, rmarkdown,
rmdformats, rnaturalearthdata, rvest, taxadb, terra, testthat,
tidyr, utils, xml2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-gb</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-03 04:16:04 UTC; jamesdorey</td>
</tr>
<tr>
<td>Author:</td>
<td>James B. Dorey <a href="https://orcid.org/0000-0003-2721-3842"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Robert L. O'Reilly
    <a href="https://orcid.org/0000-0001-5291-7396"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Silas Bossert <a href="https://orcid.org/0000-0002-3620-5468"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Erica E. Fischer <a href="https://orcid.org/0000-0002-8202-158X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>James B. Dorey &lt;jbdorey@me.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-03 23:53:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='atlasDownloader'>Download occurrence data from the Atlas of Living Australia (ALA)</h2><span id='topic+atlasDownloader'></span>

<h3>Description</h3>

<p>Downloads ALA data and creates a new file in the path to put those data. This function can also
request downloads from other atlases (see: http://galah.ala.org.au/articles/choosing_an_atlas.html).
However, it will only send the download to your email and you must do the rest yourself at this point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>atlasDownloader(
  path,
  userEmail = NULL,
  ALA_taxon,
  DL_reason = 4,
  atlas = "ALA"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="atlasDownloader_+3A_path">path</code></td>
<td>
<p>A character directory. The path to a folder where the download will be stored.</p>
</td></tr>
<tr><td><code id="atlasDownloader_+3A_useremail">userEmail</code></td>
<td>
<p>A character string. The email used associated with the user's ALA account;
user must make an ALA account to download data.</p>
</td></tr>
<tr><td><code id="atlasDownloader_+3A_ala_taxon">ALA_taxon</code></td>
<td>
<p>A character string. The taxon to download from ALA. Uses <code><a href="galah.html#topic+galah_identify">galah::galah_identify()</a></code></p>
</td></tr>
<tr><td><code id="atlasDownloader_+3A_dl_reason">DL_reason</code></td>
<td>
<p>Numeric. The reason for data download according to <code><a href="galah.html#topic+galah_config">galah::galah_config()</a></code></p>
</td></tr>
<tr><td><code id="atlasDownloader_+3A_atlas">atlas</code></td>
<td>
<p>Character. The atlas to download occurrence data from - see here https://galah.ala.org.au/R/articles/choosing_an_atlas.html for details.
Note: the default is &quot;ALA&quot; and is probably the only atlas which will work seamlessly with the rest
of the workflow. However, different atlases can still be downloaded and a doi will be sent to
your email.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Completes an ALA data download and saves those data to the path provided.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
atlasDownloader(path = DataPath,
               userEmail = "InsertYourEmail",
               ALA_taxon = "Apiformes",
               DL_reason = 4)
               
## End(Not run)
</code></pre>

<hr>
<h2 id='BeeBDCQuery'>Query the bee taxonomy and country checklist</h2><span id='topic+BeeBDCQuery'></span>

<h3>Description</h3>

<p>A simple function to return information about a particular species, including name validity and
country occurrences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BeeBDCQuery(
  beeName = NULL,
  searchChecklist = TRUE,
  printAllSynonyms = FALSE,
  beesChecklist = NULL,
  beesTaxonomy = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BeeBDCQuery_+3A_beename">beeName</code></td>
<td>
<p>Character or character vector. A single or several bee species names to search for
in the beesTaxonomy and beesChecklist tables.</p>
</td></tr>
<tr><td><code id="BeeBDCQuery_+3A_searchchecklist">searchChecklist</code></td>
<td>
<p>Logical. If TRUE (default), search the country checklist for each species.</p>
</td></tr>
<tr><td><code id="BeeBDCQuery_+3A_printallsynonyms">printAllSynonyms</code></td>
<td>
<p>Logical. If TRUE, all synonyms will be printed out for each entered name.
default = FALSE.</p>
</td></tr>
<tr><td><code id="BeeBDCQuery_+3A_beeschecklist">beesChecklist</code></td>
<td>
<p>A tibble. The bee checklist file for BeeBDC. If is NULL then
<code><a href="#topic+beesChecklist">beesChecklist()</a></code> will be called internally to download the file. Default = NULL.</p>
</td></tr>
<tr><td><code id="BeeBDCQuery_+3A_beestaxonomy">beesTaxonomy</code></td>
<td>
<p>A tibble. The bee taxonomy file for BeeBDC. If is NULL then
<code><a href="#topic+beesTaxonomy">beesTaxonomy()</a></code> will be called internally to download the file. Default = NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the elements 'taxonomyReport' and 'SynonymReport'. IF searchChecklist
is TRUE, then 'checklistReport' will also be returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # For the sake of these examples, we will use the example taxonomy and checklist
  system.file("extdata", "testTaxonomy.rda", package="BeeBDC") |&gt; load()
  system.file("extdata", "testChecklist.rda", package="BeeBDC") |&gt; load()

  # Single entry example
testQuery &lt;- BeeBDCQuery(
  beeName = "Lasioglossum bicingulatum",
  searchChecklist = TRUE,
  printAllSynonyms = TRUE,
  beesTaxonomy = testTaxonomy,
  beesChecklist = testChecklist)

  # Multiple entry example
testQuery &lt;- BeeBDCQuery(
  beeName = c("Lasioglossum bicingulatum", "Nomada flavopicta",
  "Lasioglossum fijiense (Perkins and Cheesman, 1928)"),
  searchChecklist = TRUE,
  printAllSynonyms = TRUE,
  beesTaxonomy = testTaxonomy,
  beesChecklist = testChecklist)
  
    # Example way to examine a report from the output list
  testQuery$checklistReport



</code></pre>

<hr>
<h2 id='bees3sp'>A flagged dataset of 105 random bee occurrence records from the three species</h2><span id='topic+bees3sp'></span>

<h3>Description</h3>

<p>This test dataset includes 105 random occurrence records from three bee species.
The included species are: &quot;Agapostemon tyleri Cockerell, 1917&quot;, &quot;Centris rhodopus Cockerell,
1897&quot;, and &quot;Perdita octomaculata (Say, 1824)&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("bees3sp", package = "BeeBDC")
</code></pre>


<h3>Format</h3>

<p>An object of class <code>"tibble"</code>
</p>

<dl>
<dt>database_id</dt><dd><p>Occurrence code generated in bdc or BeeBDC</p>
</dd>
<dt>scientificName</dt><dd><p>Full scientificName as shown on DiscoverLife</p>
</dd>
<dt>family</dt><dd><p>Family name</p>
</dd>
<dt>subfamily</dt><dd><p>Subfamily name</p>
</dd>
<dt>genus</dt><dd><p>Genus name</p>
</dd>
<dt>subgenus</dt><dd><p>Subgenus name</p>
</dd>
<dt>subspecies</dt><dd><p>Full scientific name with subspecies name - ALA column</p>
</dd>
<dt>specificEpithet</dt><dd><p>The species name (specific epithet) only</p>
</dd>
<dt>infraspecificEpithet</dt><dd><p>The subspecies name (intraspecific epithet) only</p>
</dd>
<dt>acceptedNameUsage</dt><dd><p>The full scientific name, with authorship and date information if known, of the currently valid (zoological) or accepted (botanical) taxon.</p>
</dd>
<dt>taxonRank</dt><dd><p>The taxonomic rank of the most specific name in the scientificName column.</p>
</dd>
<dt>scientificNameAuthorship</dt><dd><p>The authorship information for the scientificName column formatted according to the conventions of the applicable nomenclaturalCode.</p>
</dd>
<dt>identificationQualifier</dt><dd><p>A brief phrase or a standard term (&quot;cf.&quot;, &quot;aff.&quot;) to express the determiner's doubts about the identification.</p>
</dd>
<dt>higherClassification</dt><dd><p>A list (concatenated and separated) of taxon names terminating at the rank immediately superior to the taxon referenced in the taxon record.</p>
</dd>
<dt>identificationReferences</dt><dd><p>A list (concatenated and separated) of references (e.g. publications, global unique identifier, URI, etc.) used in the identification of the occurrence.</p>
</dd>
<dt>typeStatus</dt><dd><p>A list (concatenated and separated) of nomenclatural types (e.g. type status, typified scientific name, publication) applied to the occurrence.</p>
</dd>
<dt>previousIdentifications</dt><dd><p>A list (concatenated and separated) of previous assignments of names to the occurrence.</p>
</dd>
<dt>verbatimIdentification</dt><dd><p>This term is meant to allow the capture of an unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. This term is meant to be used in addition to scientificName (and identificationQualifier etc.), not instead of it.</p>
</dd>
<dt>identifiedBy</dt><dd><p>A list (concatenated and separated) of names of people, groups, or organizations who assigned the Taxon to the subject.</p>
</dd>
<dt>dateIdentified</dt><dd><p>The date on which the occurrence was identified as belonging to a taxon.</p>
</dd>
<dt>decimalLatitude</dt><dd><p>The geographic latitude (in decimal degrees, using the spatial reference system given in geodeticDatum) of the geographic center of a location. Positive values are north of the Equator, negative values are south of it, and valid values lie between -90 and 90, inclusive.</p>
</dd>
<dt>decimalLongitude</dt><dd><p>The geographic longitude (in decimal degrees, using the spatial reference system given in geodeticDatum) of the geographic center of a location. Positive values are east of the Greenwich Meridian, and negative values are west of it. Valid values lie between -180 and 180, inclusive.</p>
</dd>
<dt>stateProvince</dt><dd><p>The name of the next smaller administrative region than country (e.g. state, province, canton, department, region, etc.) in which the location for the occurrence is found.</p>
</dd>
<dt>continent</dt><dd><p>The name of the continent in which the location for the occurrence is found.</p>
</dd>
<dt>locality</dt><dd><p>A specific description of the place the occurrence was found.</p>
</dd>
<dt>island</dt><dd><p>The name of the island on or near which the location for the occurrence is found, if applicable.</p>
</dd>
<dt>county</dt><dd><p>The full, unabbreviated name of the next smaller administrative region than stateProvince (e.g. county, shire, department, etc.) in which the location for the occurrence is found.</p>
</dd>
<dt>municipality</dt><dd><p>The full, unabbreviated name of the next smaller administrative region than county (e.g. city, municipality, etc.) in which the location for the occurrence is found. Do not use this term for a nearby named place that does not contain the actual location for the occurrence.</p>
</dd>
<dt>license</dt><dd><p>A legal document giving official permission to do something with the resource.</p>
</dd>
<dt>issue</dt><dd><p>A GBIF-defined issue.</p>
</dd>
<dt>eventDate</dt><dd><p>The time or interval during which the Event occurred. For occurrences, this is the time or interval when the event was recorded.</p>
</dd>
<dt>eventTime</dt><dd><p>The time or interval during which an Event occurred.</p>
</dd>
<dt>day</dt><dd><p>The integer day of the month on which the Event occurred. For occurrences, this is the day when the event was recorded.</p>
</dd>
<dt>month</dt><dd><p>The integer month in which the Event occurred. For occurrences, this is the month of when the event was recorded.</p>
</dd>
<dt>year</dt><dd><p>The four-digit year in which the Event occurred, according to the Common Era Calendar. For occurrences, this is the year when the event was recorded.</p>
</dd>
<dt>basisOfRecord</dt><dd><p>The specific nature of the data record. Recommended best practice is to use the standard label of one of the Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation</p>
</dd>
<dt>country</dt><dd><p>The name of the country or major administrative unit in which the location for the occurrence is found.</p>
</dd>
<dt>type</dt><dd><p>The nature or genre of the resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text.</p>
</dd>
<dt>occurrenceStatus</dt><dd><p>A statement about the presence or absence of a Taxon at a Location. present, absent.</p>
</dd>
<dt>recordNumber</dt><dd><p>An identifier given to the Occurrence at the time it was recorded. Often serves as a link between field notes and an Occurrence record, such as a specimen collector's number.</p>
</dd>
<dt>recordedBy</dt><dd><p>A list (concatenated and separated) of names of people, groups, or organizations responsible for recording the original Occurrence. The primary collector or observer, especially one who applies a personal identifier (recordNumber), should be listed first.</p>
</dd>
<dt>eventID</dt><dd><p>An identifier for the set of information associated with an Event (something that occurs at a place and time). May be a global unique identifier or an identifier specific to the data set.</p>
</dd>
<dt>Location</dt><dd><p>A spatial region or named place.</p>
</dd>
<dt>samplingProtocol</dt><dd><p>The names of, references to, or descriptions of the methods or protocols used during an Event. Examples	UV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins from space: faecal stains reveal the location of emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001.</p>
</dd>
<dt>samplingEffort</dt><dd><p>The amount of effort expended during an Event. Examples	40 trap-nights, 10 observer-hours, 10 km by foot, 30 km by car.</p>
</dd>
<dt>individualCount</dt><dd><p>The number of individuals present at the time of the Occurrence. Integer.</p>
</dd>
<dt>organismQuantity</dt><dd><p>A number or enumeration value for the quantity of organisms. Examples	27 (organismQuantity) with individuals (organismQuantityType). 12.5 (organismQuantity) with percentage biomass (organismQuantityType). r (organismQuantity) with Braun Blanquet Scale (organismQuantityType). many (organismQuantity) with individuals (organismQuantityType).</p>
</dd>
<dt>coordinatePrecision</dt><dd><p>A decimal representation of the precision of the coordinates given in the decimalLatitude and decimalLongitude.</p>
</dd>
<dt>coordinateUncertaintyInMeters</dt><dd><p>The horizontal distance (in meters) from the given decimalLatitude and decimalLongitude describing the smallest circle containing the whole of the Location. Leave the value empty if the uncertainty is unknown, cannot be estimated, or is not applicable (because there are no coordinates). Zero is not a valid value for this term.</p>
</dd>
<dt>spatiallyValid</dt><dd><p>Occurrence records in the ALA can be filtered by using the spatially valid flag. This flag combines a set of tests applied to the record to see how reliable are its spatial data components.</p>
</dd>
<dt>catalogNumber</dt><dd><p>An identifier (preferably unique) for the record within the data set or collection.</p>
</dd>
<dt>gbifID</dt><dd><p>The identifier assigned by GBIF for each record.</p>
</dd>
<dt>datasetID</dt><dd><p>An identifier for the set of data. May be a global unique identifier or an identifier specific to a collection or institution.</p>
</dd>
<dt>institutionCode</dt><dd><p>The name (or acronym) in use by the institution having custody of the object(s) or information referred to in the record. Examples	MVZ, FMNH, CLO, UCMP.</p>
</dd>
<dt>datasetName</dt><dd><p>The name identifying the data set from which the record was derived.</p>
</dd>
<dt>otherCatalogNumbers</dt><dd><p>A list (concatenated and separated) of previous or alternate fully qualified catalog numbers or other human-used identifiers for the same Occurrence, whether in the current or any other data set or collection.</p>
</dd>
<dt>occurrenceID</dt><dd><p>An identifier for the Occurrence (as opposed to a particular digital record of the occurrence). In the absence of a persistent global unique identifier, construct one from a combination of identifiers in the record that will most closely make the occurrenceID globally unique.</p>
</dd>
<dt>taxonKey</dt><dd><p>The GBIF-assigned taxon identifier number.</p>
</dd>
<dt>collectionID</dt><dd><p>An identifier for the collection or dataset from which the record was derived.</p>
</dd>
<dt>verbatimScientificName</dt><dd><p>Scientific name as recorded on specimen label, not necessarily valid.</p>
</dd>
<dt>verbatimEventDate</dt><dd><p>The verbatim original representation of the date and time information for an event. For occurrences, this is the date-time when the event was recorded as noted by the collector.</p>
</dd>
<dt>associatedTaxa</dt><dd><p>A list (concatenated and separated) of identifiers or names of taxa and the associations of this occurrence to each of them.</p>
</dd>
<dt>associatedOrganisms</dt><dd><p>A list (concatenated and separated) of identifiers of other Organisms and the associations of this occurrence to each of them.</p>
</dd>
<dt>fieldNotes</dt><dd><p>One of (a) an indicator of the existence of, (b) a reference to (publication, URI), or (c) the text of notes taken in the field about the Event.</p>
</dd>
<dt>sex</dt><dd><p>The sex of the biological individual(s) represented in the Occurrence.</p>
</dd>
<dt>rights</dt><dd><p>A description of the usage rights applicable to the record.</p>
</dd>
<dt>rightsHolder</dt><dd><p>A person or organization owning or managing rights over the resource.</p>
</dd>
<dt>accessRights</dt><dd><p>Information about who can access the resource or an indication of its security status.</p>
</dd>
<dt>associatedReferences</dt><dd><p>A list (concatenated and separated) of identifiers (publication, bibliographic reference, global unique identifier, URI) of literature associated with the Occurrence.</p>
</dd>
<dt>bibliographicCitation</dt><dd><p>A bibliographic reference for the resource as a statement indicating how this record should be cited (attributed) when used.</p>
</dd>
<dt>references</dt><dd><p>A related resource that is referenced, cited, or otherwise pointed to by the described resource.</p>
</dd>
<dt>informationWithheld</dt><dd><p>Additional information that exists, but that has not been shared in the given record.</p>
</dd>
<dt>isDuplicateOf</dt><dd><p>The code for another occerrence but for the same specimen.</p>
</dd>
<dt>hasCoordinate</dt><dd><p>Variable indicating presence/absence of location coordinates.</p>
</dd>
<dt>hasGeospatialIssues</dt><dd><p>Variable indicating validity of geospatial data associated with record.</p>
</dd>
<dt>occurrenceYear</dt><dd><p>Year associated with Occurrence.</p>
</dd>
<dt>id</dt><dd><p>Variable with identifying value for the Occurrenc.</p>
</dd>
<dt>duplicateStatus</dt><dd><p>Variable indicating is Occurrence is duplicate or not.</p>
</dd>
<dt>associatedOccurrences</dt><dd><p>A list (concatenated and separated) of identifiers of other occurrence records and their associations to this occurrence.</p>
</dd>
<dt>locationRemarks</dt><dd><p>Comments or notes about the Location.</p>
</dd>
<dt>dataSource</dt><dd><p>BeeBDC assigned source of the data. Often written when the data is formatted by a BeeBDC::xxx_readr function or similar.</p>
</dd>
<dt>verbatim_scientificName</dt><dd><p>The verbatim (originally-provided) scientific name</p>
</dd>
<dt>.scientificName_empty</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_scientificName_empty">bdc::bdc_scientificName_empty()</a></code> where FALSE == no scientific name provided and TRUE means that there is text in that column.</p>
</dd>
<dt>.coordinates_empty</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_coordinates_empty">bdc::bdc_coordinates_empty()</a></code> where FALSE == no coordinates provided.</p>
</dd>
<dt>.coordinates_outOfRange</dt><dd><p>Flag column produced by bdc::bdc_coordinates_outOfRange() where FALSE == coordinates represent a point off of the Earth. This is to say, the function identifies records with out-of-range coordinates (not between -90 and 90 for latitude; not between -180 and 180 for longitude).</p>
</dd>
<dt>.basisOfRecords_notStandard</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_basisOfRecords_notStandard">bdc::bdc_basisOfRecords_notStandard()</a></code> where FALSE == an occurrence with a basisOfRecord not defined as acceptable by the user.</p>
</dd>
<dt>country_suggested</dt><dd><p>A country name suggested by the <code><a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized()</a></code> function.</p>
</dd>
<dt>countryCode</dt><dd><p>A country code suggested by the <code><a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized()</a></code> function.</p>
</dd>
<dt>coordinates_transposed</dt><dd><p>A column indicating if coordinates were identified as being transposed by the function <code><a href="#topic+jbd_Ctrans_chunker">jbd_Ctrans_chunker()</a></code> where FALSE == transposed.</p>
</dd>
<dt>.coordinates_country_inconsistent</dt><dd><p>A flag generated by <code><a href="#topic+jbd_coordCountryInconsistent">jbd_coordCountryInconsistent()</a></code> where FALSE == an occurrence where the country name and coordinates did not match.</p>
</dd>
<dt>.occurrenceAbsent</dt><dd><p>A flag generated by <code><a href="#topic+flagAbsent">flagAbsent()</a></code> where FALSE == occurrences marked as &quot;ABSENT&quot; in the &quot;occurrenceStatus&quot; column</p>
</dd>
<dt>.unLicensed</dt><dd><p>A flag generated by <code><a href="#topic+flagLicense">flagLicense()</a></code> where FALSE == those occurrences protected by a restrictive license.</p>
</dd>
<dt>.GBIFflags</dt><dd><p>A flag generated by <code><a href="#topic+GBIFissues">GBIFissues()</a></code> where FALSE == an occurrence with user-specified GBIF issues to flag.</p>
</dd>
<dt>.uncer_terms</dt><dd><p>A flag generated by <code><a href="bdc.html#topic+bdc_clean_names">bdc::bdc_clean_names()</a></code> where FALSE == the presence of taxonomic uncertainty terms.</p>
</dd>
<dt>names_clean</dt><dd><p>A column made by <code><a href="bdc.html#topic+bdc_clean_names">bdc::bdc_clean_names()</a></code> indicating the cleaned scientificName</p>
</dd>
<dt>.invalidName</dt><dd><p>A flag generated by <code><a href="#topic+harmoniseR">harmoniseR()</a></code> where FALSE == occurrences whose scientificName did not match the Discover Life taxonomy.</p>
</dd>
<dt>.rou</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == rounded (probably imprecise) coordinates.</p>
</dd>
<dt>.val</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == invalid coordinates.</p>
</dd>
<dt>.equ</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == equal coordinates (e.g., 0.1, 0.1).</p>
</dd>
<dt>.zer</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == zeros as coordinates</p>
</dd>
<dt>.cap</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around country capital centroid.</p>
</dd>
<dt>.cen</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around country or province centroids.</p>
</dd>
<dt>.gbf</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around the GBIF headquarters.</p>
</dd>
<dt>.inst</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around biodiversity institutions.</p>
</dd>
<dt>.sequential</dt><dd><p>A flag generated by <code><a href="#topic+diagonAlley">diagonAlley()</a></code> where FALSE == records that are possibly the result of fill-down errors in sequence.</p>
</dd>
<dt>.lonFlag</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+cd_round">CoordinateCleaner::cd_round()</a></code> where FALSE == potential gridding in the longitude column within dataset.</p>
</dd>
<dt>.latFlag</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+cd_round">CoordinateCleaner::cd_round()</a></code> where FALSE == potential gridding in the latitude column within dataset.</p>
</dd>
<dt>.gridSummary</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+cd_round">CoordinateCleaner::cd_round()</a></code> where FALSE == potential gridding in either the longitude or latitude columns within dataset.</p>
</dd>
<dt>.uncertaintyThreshold</dt><dd><p>A flag generated by <code><a href="#topic+coordUncerFlagR">coordUncerFlagR()</a></code> where FALSE == occurrences that did not pass a user-specified threshold in the &quot;coordinateUncertaintyInMeters&quot; column.</p>
</dd>
<dt>countryMatch</dt><dd><p>A column made by <code><a href="#topic+countryOutlieRs">countryOutlieRs()</a></code>. Summarises the occurrence-level result: where the species is not known to occur in that country (noMatch), it is known from a bordering country (neighbour), or it is known to occur in that country (exact).</p>
</dd>
<dt>.countryOutlier</dt><dd><p>A flag generated by <code><a href="#topic+countryOutlieRs">countryOutlieRs()</a></code> where FALSE == occurrences the do not occur in a country that concurs with the Discover Life country checklist OR an adjacent country.</p>
</dd>
<dt>.sea</dt><dd><p>A flag generated by <code><a href="#topic+countryOutlieRs">countryOutlieRs()</a></code> where FALSE == occurrences that are in the ocean.</p>
</dd>
<dt>.summary</dt><dd><p>A flag generated by <code><a href="#topic+summaryFun">summaryFun()</a></code> where FALSE == occurrences flagged as FALSE in any of the .flag columns. In this example it excludes flags in the &quot;.gridSummary&quot;, &quot;.lonFlag&quot;, &quot;.latFlag&quot;, and &quot;.uncer_terms&quot; columns.</p>
</dd>
<dt>.eventDate_empty</dt><dd><p>A flag generated by <code><a href="bdc.html#topic+bdc_eventDate_empty">bdc::bdc_eventDate_empty()</a></code> where FALSE == occurrences with no eventDate provided.</p>
</dd>
<dt>.year_outOfRange</dt><dd><p>A flag column generated by <code><a href="bdc.html#topic+bdc_year_outOfRange">bdc::bdc_year_outOfRange()</a></code> where FALSE == occurrences older than a threshold date. In the case of the bee dataset used in this package, the lower threshold is 1950</p>
</dd>
<dt>.duplicates</dt><dd><p>A flag generated by <code><a href="#topic+dupeSummary">dupeSummary()</a></code> where FALSE == occurrences identified as duplicates. There will be an associated kept duplicate (.duplictes == TRUE) for all duplicate clusters.</p>
</dd>
</dl>



<h3>Details</h3>

<p>A small bee occurrence dataset with flags generated by BeeBDC which can be used to run the
example script and to test functions. For data types, see <code><a href="#topic+ColTypeR">ColTypeR()</a></code>.
</p>


<h3>References</h3>

<p>This data set was created by generating a random subset of 105 rows from the full BeeBDC dataset from the publication:
Dorey, J.B., Fischer, E.E., Chesshire, P.R., Nava-Bolaños, A., O’Reilly, R.L., Bossert, S., Collins, S.M., Lichtenberg, E.M., Tucker, E., Smith-Pardo, A., Falcon-Brindis, A., Guevara, D.A., Ribeiro, B.R., de Pedro, D., Hung, J.K.-L., Parys, K.A., McCabe, L.M., Rogan, M.S., Minckley, R.L., Velzco, S.J.E., Griswold, T., Zarrillo, T.A., Jetz, W., Sica, Y.V., Orr, M.C., Guzman, L.M., Ascher, J., Hughes, A.C. &amp; Cobb, N.S. (2023) A globally synthesised and flagged bee occurrence dataset and cleaning workflow. Scientific Data, 10, 1–17. https://www.doi.org/10.1038/S41597-023-02626-W
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
bees3sp &lt;- BeeBDC::bees3sp
head(bees3sp)

</code></pre>

<hr>
<h2 id='beesChecklist'>Download a country-level checklist of bees from Discover Life</h2><span id='topic+beesChecklist'></span>

<h3>Description</h3>

<p>Download the table contains taxonomic and country information for the bees of the world based
on data collated on Discover Life. The data will be sourced from the BeeBDC article's
Figshare.
</p>
<p>Note that sometimes the download might not work without restarting R. In this case, you could
alternatively download the dataset from the URL below and then read it in using
<code>base::readRDS("filePath.Rda")</code>.
</p>
<p>See <code><a href="#topic+beesTaxonomy">beesTaxonomy()</a></code> for further context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beesChecklist(
  URL =
    "https://figshare.com/ndownloader/files/42320598?private_link=bce1f92848c2ced313ee",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beesChecklist_+3A_url">URL</code></td>
<td>
<p>A character vector to the FigShare location of the dataset. The default will be to
the most-recent version.</p>
</td></tr>
<tr><td><code id="beesChecklist_+3A_...">...</code></td>
<td>
<p>Extra variables that can be passed to <code><a href="utils.html#topic+download.file">utils::download.file()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A downloaded beesChecklist.Rda file in the outPath and the same tibble returned to
the environment.
</p>
<p>**Column details **
</p>
<p><strong>validName</strong> The valid scientificName as it should occur in the scientificName column.
</p>
<p><strong>DiscoverLife_name</strong> The full country name as it occurs on Discover Life.
</p>
<p><strong>rNaturalEarth_name</strong> Country name from rnaturalearth's name_long.
</p>
<p><strong>shortName</strong> A short version of the country name.
</p>
<p><strong>DiscoverLife_ISO</strong> The ISO country name as it occurs on Discover Life.
</p>
<p><strong>Alpha-2</strong> Alpha-2 from rnaturalearth.
</p>
<p><strong>Alpha-3</strong> Alpha-3 from rnaturalearth.
</p>
<p><strong>official</strong> Official country name = &quot;yes&quot; or only a Discover Life name = &quot;no&quot;.
</p>
<p><strong>Source</strong> A text strign denoting the source or author of the name-country pair.
</p>
<p><strong>matchCertainty</strong> Quality of the name's match to the Discover Life checklist.
</p>
<p><strong>canonical</strong> The valid species name without scientificNameAuthority.
</p>
<p><strong>canonical_withFlags</strong> The validName without the scientificNameAuthority but with Discover Life flags.
</p>
<p><strong>family</strong> Bee family.
</p>
<p><strong>subfamily</strong> Bee subfamily.
</p>
<p><strong>genus</strong> Bee genus.
</p>
<p><strong>subgenus</strong> Bee subgenus.
</p>
<p><strong>infraspecies</strong> Bee infraSpecificEpithet.
</p>
<p><strong>species</strong> Bee specificEpithet.
</p>
<p><strong>scientificNameAuthorship</strong> Bee scientificNameAuthorship.
</p>
<p><strong>taxon_rank</strong> Rank of the taxon name.
</p>
<p><strong>Notes</strong> Discover Life country name notes.
</p>


<h3>References</h3>

<p>This dataset was created using the Discover Life checklist and taxonomy.
Dataset is from the publication:
Dorey, J.B., Fischer, E.E., Chesshire, P.R., Nava-Bolaños, A., O’Reilly, R.L., Bossert, S., Collins, S.M., Lichtenberg, E.M., Tucker, E., Smith-Pardo, A., Falcon-Brindis, A., Guevara, D.A., Ribeiro, B.R., de Pedro, D., Hung, J.K.-L., Parys, K.A., McCabe, L.M., Rogan, M.S., Minckley, R.L., Velzco, S.J.E., Griswold, T., Zarrillo, T.A., Jetz, W., Sica, Y.V., Orr, M.C., Guzman, L.M., Ascher, J., Hughes, A.C. &amp; Cobb, N.S. (2023) A globally synthesised and flagged bee occurrence dataset and cleaning workflow. Scientific Data, 10, 1–17. https://www.doi.org/10.1038/S41597-023-02626-W
The checklist data are mostly compiled from Discover Life data, www.discoverlife.org:
Ascher, J.S. &amp; Pickering, J. (2020) Discover Life bee species guide and world checklist (Hymenoptera: Apoidea: Anthophila). http://www.discoverlife.org/mp/20q?guide=Apoidea_species
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
beesChecklist &lt;- BeeBDC::beesChecklist()

## End(Not run)
</code></pre>

<hr>
<h2 id='beesFlagged'>A flagged dataset of 100 random bee occurrence records</h2><span id='topic+beesFlagged'></span>

<h3>Description</h3>

<p>A small bee occurrence dataset with flags generated by BeeBDC used to run example script and test
functions. For data types, see <code><a href="#topic+ColTypeR">ColTypeR()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("beesFlagged", package = "BeeBDC")
</code></pre>


<h3>Format</h3>

<p>An object of class <code>"tibble"</code>
</p>

<dl>
<dt>database_id</dt><dd><p>Occurrence code generated in bdc or BeeBDC</p>
</dd>
<dt>scientificName</dt><dd><p>Full scientificName as shown on DiscoverLife</p>
</dd>
<dt>family</dt><dd><p>Family name</p>
</dd>
<dt>subfamily</dt><dd><p>Subfamily name</p>
</dd>
<dt>genus</dt><dd><p>Genus name</p>
</dd>
<dt>subgenus</dt><dd><p>Subgenus name</p>
</dd>
<dt>subspecies</dt><dd><p>Full name with subspecies name - ALA column</p>
</dd>
<dt>specificEpithet</dt><dd><p>The species name only</p>
</dd>
<dt>infraspecificEpithet</dt><dd><p>The subspecies name only</p>
</dd>
<dt>acceptedNameUsage</dt><dd><p>The full name, with authorship and date information if known, of the currently valid (zoological) or accepted (botanical) taxon.</p>
</dd>
<dt>taxonRank</dt><dd><p>The taxonomic rank of the most specific name in the scientificName.</p>
</dd>
<dt>scientificNameAuthorship</dt><dd><p>The authorship information for the scientificName formatted according to the conventions of the applicable nomenclaturalCode.</p>
</dd>
<dt>identificationQualifier</dt><dd><p>A brief phrase or a standard term (&quot;cf.&quot;, &quot;aff.&quot;) to express the determiner's doubts about the Identification.</p>
</dd>
<dt>higherClassification</dt><dd><p>A list (concatenated and separated) of taxa names terminating at the rank immediately superior to the taxon referenced in the taxon record.)</p>
</dd>
<dt>identificationReferences</dt><dd><p>A list (concatenated and separated) of references (publication, global unique identifier, URI) used in the Identification.</p>
</dd>
<dt>typeStatus</dt><dd><p>A list (concatenated and separated) of nomenclatural types (type status, typified scientific name, publication) applied to the subject.</p>
</dd>
<dt>previousIdentifications</dt><dd><p>A list (concatenated and separated) of previous assignments of names to the Organism.</p>
</dd>
<dt>verbatimIdentification</dt><dd><p>This term is meant to allow the capture of an unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. This term is meant to be used in addition to scientificName (and identificationQualifier etc.), not instead of it.</p>
</dd>
<dt>identifiedBy</dt><dd><p>A list (concatenated and separated) of names of people, groups, or organizations who assigned the Taxon to the subject.</p>
</dd>
<dt>dateIdentified</dt><dd><p>The date on which the subject was determined as representing the Taxon.</p>
</dd>
<dt>decimalLatitude</dt><dd><p>The geographic latitude (in decimal degrees, using the spatial reference system given in geodeticDatum) of the geographic center of a Location. Positive values are north of the Equator, negative values are south of it. Legal values lie between -90 and 90, inclusive.</p>
</dd>
<dt>decimalLongitude</dt><dd><p>The geographic longitude (in decimal degrees, using the spatial reference system given in geodeticDatum) of the geographic center of a Location. Positive values are east of the Greenwich Meridian, negative values are west of it. Legal values lie between -180 and 180, inclusive.</p>
</dd>
<dt>stateProvince</dt><dd><p>The name of the next smaller administrative region than country (state, province, canton, department, region, etc.) in which the Location occurs.</p>
</dd>
<dt>continent</dt><dd><p>The name of the continent in which the Location occurs.</p>
</dd>
<dt>locality</dt><dd><p>The specific description of the place.</p>
</dd>
<dt>island</dt><dd><p>The name of the island on or near which the Location occurs.</p>
</dd>
<dt>county</dt><dd><p>The full, unabbreviated name of the next smaller administrative region than stateProvince (county, shire, department, etc.) in which the Location occurs.</p>
</dd>
<dt>municipality</dt><dd><p>The full, unabbreviated name of the next smaller administrative region than county (city, municipality, etc.) in which the Location occurs. Do not use this term for a nearby named place that does not contain the actual location.</p>
</dd>
<dt>license</dt><dd><p>A legal document giving official permission to do something with the resource.</p>
</dd>
<dt>issue</dt><dd><p>A GBIF-defined issue.</p>
</dd>
<dt>eventDate</dt><dd><p>The date-time or interval during which an Event occurred. For occurrences, this is the date-time when the event was recorded. Not suitable for a time in a geological context.</p>
</dd>
<dt>eventTime</dt><dd><p>The time or interval during which an Event occurred.</p>
</dd>
<dt>day</dt><dd><p>The integer day of the month on which the Event occurred.</p>
</dd>
<dt>month</dt><dd><p>The integer month in which the Event occurred.</p>
</dd>
<dt>year</dt><dd><p>The four-digit year in which the Event occurred, according to the Common Era Calendar.</p>
</dd>
<dt>basisOfRecord</dt><dd><p>The specific nature of the data record. Recommended best practice is to use the standard label of one of the Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation</p>
</dd>
<dt>country</dt><dd><p>The name of the country or major administrative unit in which the Location occurs.</p>
</dd>
<dt>type</dt><dd><p>The nature or genre of the resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text.</p>
</dd>
<dt>occurrenceStatus</dt><dd><p>A statement about the presence or absence of a Taxon at a Location. present, absent.</p>
</dd>
<dt>recordNumber</dt><dd><p>An identifier given to the Occurrence at the time it was recorded. Often serves as a link between field notes and an Occurrence record, such as a specimen collector's number.</p>
</dd>
<dt>recordedBy</dt><dd><p>A list (concatenated and separated) of names of people, groups, or organizations responsible for recording the original Occurrence. The primary collector or observer, especially one who applies a personal identifier (recordNumber), should be listed first.</p>
</dd>
<dt>eventID</dt><dd><p>An identifier for the set of information associated with an Event (something that occurs at a place and time). May be a global unique identifier or an identifier specific to the data set.</p>
</dd>
<dt>Location</dt><dd><p>A spatial region or named place.</p>
</dd>
<dt>samplingProtocol</dt><dd><p>The names of, references to, or descriptions of the methods or protocols used during an Event. Examples	UV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins from space: faecal stains reveal the location of emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001.</p>
</dd>
<dt>samplingEffort</dt><dd><p>The amount of effort expended during an Event. Examples	40 trap-nights, 10 observer-hours, 10 km by foot, 30 km by car.</p>
</dd>
<dt>individualCount</dt><dd><p>The number of individuals present at the time of the Occurrence. Integer.</p>
</dd>
<dt>organismQuantity</dt><dd><p>A number or enumeration value for the quantity of organisms. Examples	27 (organismQuantity) with individuals (organismQuantityType). 12.5 (organismQuantity) with percentage biomass (organismQuantityType). r (organismQuantity) with Braun Blanquet Scale (organismQuantityType). many (organismQuantity) with individuals (organismQuantityType).</p>
</dd>
<dt>coordinatePrecision</dt><dd><p>A decimal representation of the precision of the coordinates given in the decimalLatitude and decimalLongitude.</p>
</dd>
<dt>coordinateUncertaintyInMeters</dt><dd><p>The horizontal distance (in meters) from the given decimalLatitude and decimalLongitude describing the smallest circle containing the whole of the Location. Leave the value empty if the uncertainty is unknown, cannot be estimated, or is not applicable (because there are no coordinates). Zero is not a valid value for this term.</p>
</dd>
<dt>spatiallyValid</dt><dd><p>Occurrence records in the ALA can be filtered by using the spatially valid flag. This flag combines a set of tests applied to the record to see how reliable are its spatial data components.</p>
</dd>
<dt>catalogNumber</dt><dd><p>An identifier (preferably unique) for the record within the data set or collection.</p>
</dd>
<dt>gbifID</dt><dd><p>The identifier assigned by GBIF for each record.</p>
</dd>
<dt>datasetID</dt><dd><p>An identifier for the set of data. May be a global unique identifier or an identifier specific to a collection or institution.</p>
</dd>
<dt>institutionCode</dt><dd><p>The name (or acronym) in use by the institution having custody of the object(s) or information referred to in the record. Examples	MVZ, FMNH, CLO, UCMP.</p>
</dd>
<dt>datasetName</dt><dd><p>The name identifying the data set from which the record was derived.</p>
</dd>
<dt>otherCatalogNumbers</dt><dd><p>A list (concatenated and separated) of previous or alternate fully qualified catalog numbers or other human-used identifiers for the same Occurrence, whether in the current or any other data set or collection.</p>
</dd>
<dt>occurrenceID</dt><dd><p>An identifier for the Occurrence (as opposed to a particular digital record of the occurrence). In the absence of a persistent global unique identifier, construct one from a combination of identifiers in the record that will most closely make the occurrenceID globally unique.</p>
</dd>
<dt>taxonKey</dt><dd><p>The GBIF-assigned taxon identifier number.</p>
</dd>
<dt>collectionID</dt><dd><p>An identifier for the collection or dataset from which the record was derived.</p>
</dd>
<dt>verbatim_scientificName</dt><dd><p>The verbatim (originally-provided) scientific name</p>
</dd>
<dt>verbatimEventDate</dt><dd><p>The verbatim original representation of the date and time information for an Event.</p>
</dd>
<dt>associatedTaxa</dt><dd><p>A list (concatenated and separated) of identifiers or names of taxa and the associations of this Occurrence to each of them.</p>
</dd>
<dt>associatedOrganisms</dt><dd><p>A list (concatenated and separated) of identifiers of other Organisms and the associations of this Organism to each of them.</p>
</dd>
<dt>fieldNotes</dt><dd><p>One of a) an indicator of the existence of, b) a reference to (publication, URI), or c) the text of notes taken in the field about the Event.</p>
</dd>
<dt>sex</dt><dd><p>The sex of the biological individual(s) represented in the Occurrence.</p>
</dd>
<dt>rights</dt><dd><p>A description of the usage rights applicable to the record.</p>
</dd>
<dt>rightsHolder</dt><dd><p>A person or organization owning or managing rights over the resource.</p>
</dd>
<dt>accessRights</dt><dd><p>Information about who can access the resource or an indication of its security status.</p>
</dd>
<dt>associatedReferences</dt><dd><p>A list (concatenated and separated) of identifiers (publication, bibliographic reference, global unique identifier, URI) of literature associated with the Occurrence.</p>
</dd>
<dt>bibliographicCitation</dt><dd><p>A bibliographic reference for the resource as a statement indicating how this record should be cited (attributed) when used.</p>
</dd>
<dt>references</dt><dd><p>A related resource that is referenced, cited, or otherwise pointed to by the described resource.</p>
</dd>
<dt>informationWithheld</dt><dd><p>Additional information that exists, but that has not been shared in the given record.</p>
</dd>
<dt>isDuplicateOf</dt><dd><p>Additional information that exists, but that has not been shared in the given record.</p>
</dd>
<dt>hasCoordinate</dt><dd><p>Variable indicating presence/absence of location coordinates.</p>
</dd>
<dt>hasGeospatialIssues</dt><dd><p>Variable indicating validity of geospatial data associated with record.</p>
</dd>
<dt>occurrenceYear</dt><dd><p>Year associated with Occurrence.</p>
</dd>
<dt>id</dt><dd><p>Variable with identifying value for the Occurrenc.</p>
</dd>
<dt>duplicateStatus</dt><dd><p>Variable indicating is Occurrence is duplicate or not.</p>
</dd>
<dt>associatedOccurrences</dt><dd><p>A list (concatenated and separated) of identifiers of other Occurrence records and their associations to this Occurrence.</p>
</dd>
<dt>locationRemarks</dt><dd><p>Comments or notes about the Location.</p>
</dd>
<dt>dataSource</dt><dd><p>BeeBDC assigned source of the data. Often written when the data is formatted by a BeeBDC::xxx_readr function or similar.</p>
</dd>
<dt>verbatim_scientificName</dt><dd><p>The verbatim (originally-provided) scientific name</p>
</dd>
<dt>.scientificName_empty</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_scientificName_empty">bdc::bdc_scientificName_empty()</a></code> where FALSE == no scientific name provided and TRUE means that there is text in that column.</p>
</dd>
<dt>.coordinates_empty</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_coordinates_empty">bdc::bdc_coordinates_empty()</a></code> where FALSE == no coordinates provided.</p>
</dd>
<dt>.coordinates_outOfRange</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_coordinates_outOfRange">bdc::bdc_coordinates_outOfRange()</a></code> where FALSE == point off the earth. This function identifies records with out-of-range coordinates (not between -90 and 90 for latitude; between -180 and 180 for longitude).</p>
</dd>
<dt>.basisOfRecords_notStandard</dt><dd><p>Flag produced by <code><a href="bdc.html#topic+bdc_basisOfRecords_notStandard">bdc::bdc_basisOfRecords_notStandard()</a></code> where FALSE == an occurrence with a basisOfRecord not defined as acceptable by the user.</p>
</dd>
<dt>country_suggested</dt><dd><p>A country name suggested by the <code><a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized()</a></code> function.</p>
</dd>
<dt>countryCode</dt><dd><p>A country code suggested by the <code><a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized()</a></code> function.</p>
</dd>
<dt>coordinates_transposed</dt><dd><p>A column indicating if coordinates were tansposed by <code><a href="#topic+jbd_Ctrans_chunker">jbd_Ctrans_chunker()</a></code> where FALSE == transposed.</p>
</dd>
<dt>.coordinates_country_inconsistent</dt><dd><p>A flag generated by <code><a href="#topic+jbd_coordCountryInconsistent">jbd_coordCountryInconsistent()</a></code> where FALSE == an occurrence where the country name and coordinates did not match.</p>
</dd>
<dt>.occurrenceAbsent</dt><dd><p>A flag generated by <code><a href="#topic+flagAbsent">flagAbsent()</a></code> where FALSE == occurrences marked as &quot;ABSENT&quot; in the &quot;occurrenceStatus&quot; column</p>
</dd>
<dt>.unLicensed</dt><dd><p>A flag generated by <code><a href="#topic+flagLicense">flagLicense()</a></code> where FALSE == those occurrences protected by a restrictive license.</p>
</dd>
<dt>.GBIFflags</dt><dd><p>A flag generated by <code><a href="#topic+GBIFissues">GBIFissues()</a></code> where FALSE == an occurrence with user-specified GBIF issues to flag.</p>
</dd>
<dt>.uncer_terms</dt><dd><p>A flag generated by <code><a href="bdc.html#topic+bdc_clean_names">bdc::bdc_clean_names()</a></code> where FALSE == the presence of taxonomic uncertainty terms.</p>
</dd>
<dt>names_clean</dt><dd><p>A column made by <code><a href="bdc.html#topic+bdc_clean_names">bdc::bdc_clean_names()</a></code> indicating the cleaned scientificName</p>
</dd>
<dt>.invalidName</dt><dd><p>A flag generated by <code><a href="#topic+harmoniseR">harmoniseR()</a></code> where FALSE == occurrences whose scientificName did not match the Discover Life taxonomy.</p>
</dd>
<dt>.rou</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == rounded (probably imprecise) coordinates.</p>
</dd>
<dt>.val</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == invalid coordinates.</p>
</dd>
<dt>.equ</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == equal coordinates (e.g., 0.1, 0.1).</p>
</dd>
<dt>.zer</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == zeros as coordinates</p>
</dd>
<dt>.cap</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around country capital centroid.</p>
</dd>
<dt>.cen</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around country or province centroids.</p>
</dd>
<dt>.gbf</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around the GBIF headquarters.</p>
</dd>
<dt>.inst</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+clean_coordinates">CoordinateCleaner::clean_coordinates()</a></code> where FALSE == records around biodiversity institutions.</p>
</dd>
<dt>.sequential</dt><dd><p>A flag generated by <code><a href="#topic+diagonAlley">diagonAlley()</a></code> where FALSE == records that are possibly the result of fill-down errors in sequence.</p>
</dd>
<dt>.lonFlag</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+cd_round">CoordinateCleaner::cd_round()</a></code> where FALSE == potential gridding in the longitude column within dataset.</p>
</dd>
<dt>.latFlag</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+cd_round">CoordinateCleaner::cd_round()</a></code> where FALSE == potential gridding in the latitude column within dataset.</p>
</dd>
<dt>.gridSummary</dt><dd><p>A flag generated by <code><a href="CoordinateCleaner.html#topic+cd_round">CoordinateCleaner::cd_round()</a></code> where FALSE == potential gridding in either the longitude or latitude columns within dataset.</p>
</dd>
<dt>.uncertaintyThreshold</dt><dd><p>A flag generated by <code><a href="#topic+coordUncerFlagR">coordUncerFlagR()</a></code> where FALSE == occurrences that did not pass a user-specified threshold in the &quot;coordinateUncertaintyInMeters&quot; column.</p>
</dd>
<dt>countryMatch</dt><dd><p>A column made by <code><a href="#topic+countryOutlieRs">countryOutlieRs()</a></code>. Summarises the occurrence-level result: where the species is not known to occur in that country (noMatch), it is known from a bordering country (neighbour), or it is known to occur in that country (exact).</p>
</dd>
<dt>.countryOutlier</dt><dd><p>A flag generated by <code><a href="#topic+countryOutlieRs">countryOutlieRs()</a></code> where FALSE == occurrences the do not occur in a country that concurs with the Discover Life country checklist OR an adjacent country.</p>
</dd>
<dt>.sea</dt><dd><p>A flag generated by <code><a href="#topic+countryOutlieRs">countryOutlieRs()</a></code> where FALSE == occurrences that are in the ocean.</p>
</dd>
<dt>.summary</dt><dd><p>A flag generated by <code><a href="#topic+summaryFun">summaryFun()</a></code> where FALSE == occurrences flagged as FALSE in any of the .flag columns. In this example it excludes flags in the &quot;.gridSummary&quot;, &quot;.lonFlag&quot;, &quot;.latFlag&quot;, and &quot;.uncer_terms&quot; columns.</p>
</dd>
<dt>.eventDate_empty</dt><dd><p>A flag generated by <code><a href="bdc.html#topic+bdc_eventDate_empty">bdc::bdc_eventDate_empty()</a></code> where FALSE == occurrences with no eventDate provided.</p>
</dd>
<dt>.year_outOfRange</dt><dd><p>A flag generated by <code><a href="bdc.html#topic+bdc_year_outOfRange">bdc::bdc_year_outOfRange()</a></code> where FALSE == occurrences older than a threshold date. In this case 1950.</p>
</dd>
<dt>.duplicates</dt><dd><p>A flag generated by <code><a href="#topic+dupeSummary">dupeSummary()</a></code> where FALSE == occurrences identified as duplicates. There will be an associated kept duplicate (.duplictes == TRUE) for all duplicate clusters.</p>
</dd>
</dl>



<h3>References</h3>

<p>This data set was created by generating a random subset of 100 rows from the full BeeBDC dataset from the publication:
Dorey, J.B., Fischer, E.E., Chesshire, P.R., Nava-Bolaños, A., O’Reilly, R.L., Bossert, S., Collins, S.M., Lichtenberg, E.M., Tucker, E., Smith-Pardo, A., Falcon-Brindis, A., Guevara, D.A., Ribeiro, B.R., de Pedro, D., Hung, J.K.-L., Parys, K.A., McCabe, L.M., Rogan, M.S., Minckley, R.L., Velzco, S.J.E., Griswold, T., Zarrillo, T.A., Jetz, W., Sica, Y.V., Orr, M.C., Guzman, L.M., Ascher, J., Hughes, A.C. &amp; Cobb, N.S. (2023) A globally synthesised and flagged bee occurrence dataset and cleaning workflow. Scientific Data, 10, 1–17. https://www.doi.org/10.1038/S41597-023-02626-W
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
beesFlagged &lt;- BeeBDC::beesFlagged
head(beesFlagged)

</code></pre>

<hr>
<h2 id='beesRaw'>A dataset of 100 random bee occurrence records without flags or filters applied</h2><span id='topic+beesRaw'></span>

<h3>Description</h3>

<p>A small bee occurrence dataset with flags generated by BeeBDC used to run example script and test
functions. For data types, see <code><a href="#topic+ColTypeR">ColTypeR()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("beesRaw", package = "BeeBDC")
</code></pre>


<h3>Format</h3>

<p>An object of class <code>"tibble"</code>
</p>

<dl>
<dt>database_id</dt><dd><p>Occurrence code generated in bdc or BeeBDC</p>
</dd>
<dt>scientificName</dt><dd><p>Full scientificName as shown on DiscoverLife</p>
</dd>
<dt>family</dt><dd><p>Family name</p>
</dd>
<dt>subfamily</dt><dd><p>Subfamily name</p>
</dd>
<dt>genus</dt><dd><p>Genus name</p>
</dd>
<dt>subgenus</dt><dd><p>Subgenus name</p>
</dd>
<dt>subspecies</dt><dd><p>Full name with subspecies name - ALA column</p>
</dd>
<dt>specificEpithet</dt><dd><p>The species name only</p>
</dd>
<dt>infraspecificEpithet</dt><dd><p>The subspecies name only</p>
</dd>
<dt>acceptedNameUsage</dt><dd><p>The full name, with authorship and date information if known, of the currently valid (zoological) or accepted (botanical) taxon.</p>
</dd>
<dt>taxonRank</dt><dd><p>The taxonomic rank of the most specific name in the scientificName.</p>
</dd>
<dt>scientificNameAuthorship</dt><dd><p>The authorship information for the scientificName formatted according to the conventions of the applicable nomenclaturalCode.</p>
</dd>
<dt>identificationQualifier</dt><dd><p>A brief phrase or a standard term (&quot;cf.&quot;, &quot;aff.&quot;) to express the determiner's doubts about the Identification.</p>
</dd>
<dt>higherClassification</dt><dd><p>A list (concatenated and separated) of taxa names terminating at the rank immediately superior to the taxon referenced in the taxon record.)</p>
</dd>
<dt>identificationReferences</dt><dd><p>A list (concatenated and separated) of references (publication, global unique identifier, URI) used in the Identification.</p>
</dd>
<dt>typeStatus</dt><dd><p>A list (concatenated and separated) of nomenclatural types (type status, typified scientific name, publication) applied to the subject.</p>
</dd>
<dt>previousIdentifications</dt><dd><p>A list (concatenated and separated) of previous assignments of names to the Organism.</p>
</dd>
<dt>verbatimIdentification</dt><dd><p>This term is meant to allow the capture of an unaltered original identification/determination, including identification qualifiers, hybrid formulas, uncertainties, etc. This term is meant to be used in addition to scientificName (and identificationQualifier etc.), not instead of it.</p>
</dd>
<dt>identifiedBy</dt><dd><p>A list (concatenated and separated) of names of people, groups, or organizations who assigned the Taxon to the subject.</p>
</dd>
<dt>dateIdentified</dt><dd><p>The date on which the subject was determined as representing the Taxon.</p>
</dd>
<dt>decimalLatitude</dt><dd><p>The geographic latitude (in decimal degrees, using the spatial reference system given in geodeticDatum) of the geographic center of a Location. Positive values are north of the Equator, negative values are south of it. Legal values lie between -90 and 90, inclusive.</p>
</dd>
<dt>decimalLongitude</dt><dd><p>The geographic longitude (in decimal degrees, using the spatial reference system given in geodeticDatum) of the geographic center of a Location. Positive values are east of the Greenwich Meridian, negative values are west of it. Legal values lie between -180 and 180, inclusive.</p>
</dd>
<dt>stateProvince</dt><dd><p>The name of the next smaller administrative region than country (state, province, canton, department, region, etc.) in which the Location occurs.</p>
</dd>
<dt>continent</dt><dd><p>The name of the continent in which the Location occurs.</p>
</dd>
<dt>locality</dt><dd><p>The specific description of the place.</p>
</dd>
<dt>island</dt><dd><p>The name of the island on or near which the Location occurs.</p>
</dd>
<dt>county</dt><dd><p>The full, unabbreviated name of the next smaller administrative region than stateProvince (county, shire, department, etc.) in which the Location occurs.</p>
</dd>
<dt>municipality</dt><dd><p>The full, unabbreviated name of the next smaller administrative region than county (city, municipality, etc.) in which the Location occurs. Do not use this term for a nearby named place that does not contain the actual location.</p>
</dd>
<dt>license</dt><dd><p>A legal document giving official permission to do something with the resource.</p>
</dd>
<dt>issue</dt><dd><p>A GBIF-defined issue.</p>
</dd>
<dt>eventDate</dt><dd><p>The date-time or interval during which an Event occurred. For occurrences, this is the date-time when the event was recorded. Not suitable for a time in a geological context.</p>
</dd>
<dt>eventTime</dt><dd><p>The time or interval during which an Event occurred.</p>
</dd>
<dt>day</dt><dd><p>The integer day of the month on which the Event occurred.</p>
</dd>
<dt>month</dt><dd><p>The integer month in which the Event occurred.</p>
</dd>
<dt>year</dt><dd><p>The four-digit year in which the Event occurred, according to the Common Era Calendar.</p>
</dd>
<dt>basisOfRecord</dt><dd><p>The specific nature of the data record. Recommended best practice is to use the standard label of one of the Darwin Core classes.PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence, MaterialCitation</p>
</dd>
<dt>country</dt><dd><p>The name of the country or major administrative unit in which the Location occurs.</p>
</dd>
<dt>type</dt><dd><p>The nature or genre of the resource. StillImage, MovingImage, Sound, PhysicalObject, Event, Text.</p>
</dd>
<dt>occurrenceStatus</dt><dd><p>A statement about the presence or absence of a Taxon at a Location. present, absent.</p>
</dd>
<dt>recordNumber</dt><dd><p>An identifier given to the Occurrence at the time it was recorded. Often serves as a link between field notes and an Occurrence record, such as a specimen collector's number.</p>
</dd>
<dt>recordedBy</dt><dd><p>A list (concatenated and separated) of names of people, groups, or organizations responsible for recording the original Occurrence. The primary collector or observer, especially one who applies a personal identifier (recordNumber), should be listed first.</p>
</dd>
<dt>eventID</dt><dd><p>An identifier for the set of information associated with an Event (something that occurs at a place and time). May be a global unique identifier or an identifier specific to the data set.</p>
</dd>
<dt>Location</dt><dd><p>A spatial region or named place.</p>
</dd>
<dt>samplingProtocol</dt><dd><p>The names of, references to, or descriptions of the methods or protocols used during an Event. Examples	UV light trap, mist net, bottom trawl, ad hoc observation | point count, Penguins from space: faecal stains reveal the location of emperor penguin colonies, https://doi.org/10.1111/j.1466-8238.2009.00467.x, Takats et al. 2001.</p>
</dd>
<dt>samplingEffort</dt><dd><p>The amount of effort expended during an Event. Examples	40 trap-nights, 10 observer-hours, 10 km by foot, 30 km by car.</p>
</dd>
<dt>individualCount</dt><dd><p>The number of individuals present at the time of the Occurrence. Integer.</p>
</dd>
<dt>organismQuantity</dt><dd><p>A number or enumeration value for the quantity of organisms. Examples	27 (organismQuantity) with individuals (organismQuantityType). 12.5 (organismQuantity) with percentage biomass (organismQuantityType). r (organismQuantity) with Braun Blanquet Scale (organismQuantityType). many (organismQuantity) with individuals (organismQuantityType).</p>
</dd>
<dt>coordinatePrecision</dt><dd><p>A decimal representation of the precision of the coordinates given in the decimalLatitude and decimalLongitude.</p>
</dd>
<dt>coordinateUncertaintyInMeters</dt><dd><p>The horizontal distance (in meters) from the given decimalLatitude and decimalLongitude describing the smallest circle containing the whole of the Location. Leave the value empty if the uncertainty is unknown, cannot be estimated, or is not applicable (because there are no coordinates). Zero is not a valid value for this term.</p>
</dd>
<dt>spatiallyValid</dt><dd><p>Occurrence records in the ALA can be filtered by using the spatially valid flag. This flag combines a set of tests applied to the record to see how reliable are its spatial data components.</p>
</dd>
<dt>catalogNumber</dt><dd><p>An identifier (preferably unique) for the record within the data set or collection.</p>
</dd>
<dt>gbifID</dt><dd><p>The identifier assigned by GBIF for each record.</p>
</dd>
<dt>datasetID</dt><dd><p>An identifier for the set of data. May be a global unique identifier or an identifier specific to a collection or institution.</p>
</dd>
<dt>institutionCode</dt><dd><p>The name (or acronym) in use by the institution having custody of the object(s) or information referred to in the record. Examples	MVZ, FMNH, CLO, UCMP.</p>
</dd>
<dt>datasetName</dt><dd><p>The name identifying the data set from which the record was derived.</p>
</dd>
<dt>otherCatalogNumbers</dt><dd><p>A list (concatenated and separated) of previous or alternate fully qualified catalog numbers or other human-used identifiers for the same Occurrence, whether in the current or any other data set or collection.</p>
</dd>
<dt>occurrenceID</dt><dd><p>An identifier for the Occurrence (as opposed to a particular digital record of the occurrence). In the absence of a persistent global unique identifier, construct one from a combination of identifiers in the record that will most closely make the occurrenceID globally unique.</p>
</dd>
<dt>taxonKey</dt><dd><p>The GBIF-assigned taxon identifier number.</p>
</dd>
<dt>collectionID</dt><dd><p>An identifier for the collection or dataset from which the record was derived.</p>
</dd>
<dt>verbatim_scientificName</dt><dd><p>The verbatim (originally-provided) scientific name</p>
</dd>
<dt>verbatimEventDate</dt><dd><p>The verbatim original representation of the date and time information for an Event.</p>
</dd>
<dt>associatedTaxa</dt><dd><p>A list (concatenated and separated) of identifiers or names of taxa and the associations of this Occurrence to each of them.</p>
</dd>
<dt>associatedOrganisms</dt><dd><p>A list (concatenated and separated) of identifiers of other Organisms and the associations of this Organism to each of them.</p>
</dd>
<dt>fieldNotes</dt><dd><p>One of a) an indicator of the existence of, b) a reference to (publication, URI), or c) the text of notes taken in the field about the Event.</p>
</dd>
<dt>sex</dt><dd><p>The sex of the biological individual(s) represented in the Occurrence.</p>
</dd>
<dt>rights</dt><dd><p>A description of the usage rights applicable to the record.</p>
</dd>
<dt>rightsHolder</dt><dd><p>A person or organization owning or managing rights over the resource.</p>
</dd>
<dt>accessRights</dt><dd><p>Information about who can access the resource or an indication of its security status.</p>
</dd>
<dt>associatedReferences</dt><dd><p>A list (concatenated and separated) of identifiers (publication, bibliographic reference, global unique identifier, URI) of literature associated with the Occurrence.</p>
</dd>
<dt>bibliographicCitation</dt><dd><p>A bibliographic reference for the resource as a statement indicating how this record should be cited (attributed) when used.</p>
</dd>
<dt>references</dt><dd><p>A related resource that is referenced, cited, or otherwise pointed to by the described resource.</p>
</dd>
<dt>informationWithheld</dt><dd><p>Additional information that exists, but that has not been shared in the given record.</p>
</dd>
<dt>isDuplicateOf</dt><dd><p>Additional information that exists, but that has not been shared in the given record.</p>
</dd>
<dt>hasCoordinate</dt><dd><p>Variable indicating presence/absence of location coordinates.</p>
</dd>
<dt>hasGeospatialIssues</dt><dd><p>Variable indicating validity of geospatial data associated with record.</p>
</dd>
<dt>occurrenceYear</dt><dd><p>Year associated with Occurrence.</p>
</dd>
<dt>id</dt><dd><p>Variable with identifying value for the Occurrenc.</p>
</dd>
<dt>duplicateStatus</dt><dd><p>Variable indicating is Occurrence is duplicate or not.</p>
</dd>
<dt>associatedOccurrences</dt><dd><p>A list (concatenated and separated) of identifiers of other Occurrence records and their associations to this Occurrence.</p>
</dd>
<dt>locationRemarks</dt><dd><p>Comments or notes about the Location.</p>
</dd>
<dt>dataSource</dt><dd><p>BeeBDC assigned source of the data. Often written when the data is formatted by a BeeBDC::xxx_readr function or similar.</p>
</dd>
<dt>verbatim_scientificName</dt><dd><p>The verbatim (originally-provided) scientific name</p>
</dd>
</dl>



<h3>References</h3>

<p>This data set was created by generating a random subset of 100 rows from the full, unfiltered and unflagged, BeeBDC dataset from the publication:
Dorey, J.B., Fischer, E.E., Chesshire, P.R., Nava-Bolaños, A., O’Reilly, R.L., Bossert, S., Collins, S.M., Lichtenberg, E.M., Tucker, E., Smith-Pardo, A., Falcon-Brindis, A., Guevara, D.A., Ribeiro, B.R., de Pedro, D., Hung, J.K.-L., Parys, K.A., McCabe, L.M., Rogan, M.S., Minckley, R.L., Velzco, S.J.E., Griswold, T., Zarrillo, T.A., Jetz, W., Sica, Y.V., Orr, M.C., Guzman, L.M., Ascher, J., Hughes, A.C. &amp; Cobb, N.S. (2023) A globally synthesised and flagged bee occurrence dataset and cleaning workflow. Scientific Data, 10, 1–17. https://www.doi.org/10.1038/S41597-023-02626-W
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
beesRaw &lt;- BeeBDC::beesRaw
head(beesRaw)

</code></pre>

<hr>
<h2 id='beesTaxonomy'>Download a nearly complete taxonomy of bees globally</h2><span id='topic+beesTaxonomy'></span>

<h3>Description</h3>

<p>Downloads the taxonomic information for the bees of the world.
Source of taxonomy is listed under &quot;source&quot; but are mostly derived from the Discover Life
website. The data will be sourced from the BeeBDC article's Figshare.
</p>
<p>Note that sometimes the download might not work without restarting R. In this case, you could
alternatively download the dataset from the URL below and then read it in using
<code>base::readRDS("filePath.Rda")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beesTaxonomy(
  URL = "https://open.flinders.edu.au/ndownloader/files/43331472",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beesTaxonomy_+3A_url">URL</code></td>
<td>
<p>A character vector to the FigShare location of the dataset. The default will be to
the most-recent version.</p>
</td></tr>
<tr><td><code id="beesTaxonomy_+3A_...">...</code></td>
<td>
<p>Extra variables that can be passed to <code><a href="utils.html#topic+download.file">utils::download.file()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Column details</strong>
</p>
<p><strong>flags</strong> Flags or comments about the taxon name.
</p>
<p><strong>taxonomic_status</strong> Taxonomic status. Values are &quot;accepted&quot; or &quot;synonym&quot;
</p>
<p><strong>source</strong> Source of the name.
</p>
<p><strong>accid</strong> The id of the accepted taxon name or &quot;0&quot; if taxonomic_status == accepted.
</p>
<p><strong>id</strong> The id number for the taxon name.
</p>
<p><strong>kingdom</strong> The biological kingdom the taxon belongs to. For bees, kingdom == Animalia.
</p>
<p><strong>phylum</strong> The biological phylum the taxon belongs to. For bees, phylum == Arthropoda.
</p>
<p><strong>class</strong> The biological class the taxon belongs to. For bees, class == Insecta.
</p>
<p><strong>order</strong> The biological order the taxon belongs to. For bees, order == Hymenoptera.
</p>
<p><strong>family</strong> The family of bee which the species belongs to.
</p>
<p><strong>subfamily</strong> The subfamily of bee which the species belongs to.
</p>
<p><strong>tribe</strong> The tribe of bee which the species belongs to.
</p>
<p><strong>subtribe</strong> The subtribe of bee which the species belongs to.
</p>
<p><strong>validName</strong> The valid scientific name as it should occur in the 'scientificName&quot; column in a Darwin Core file.
</p>
<p><strong>canonical</strong> The scientificName without the scientificNameAuthority.
</p>
<p><strong>canonical_withFlags</strong> The scientificName without the scientificNameAuthority and with Discover Life taxonomy flags.
</p>
<p><strong>genus</strong> The genus the bee species belongs to.
</p>
<p><strong>subgenus</strong> The subgenus the bee species belongs to.
</p>
<p><strong>species</strong> The specific epithet for the bee species.
</p>
<p><strong>infraspecies</strong> The infraspecific epithet for the bee addressed.
</p>
<p><strong>authorship</strong> The author who described the bee species.
</p>
<p><strong>taxon_rank</strong> Rank for the bee taxon addressed in the entry.
</p>
<p><strong>notes</strong> Additional notes about the name/taxon.
</p>


<h3>Value</h3>

<p>A downloaded beesTaxonomy.Rda file in the <code><a href="base.html#topic+tempdir">tempdir()</a></code> and the same tibble returned to
the environment.
</p>


<h3>References</h3>

<p>This dataset was created using the Discover Life taxonomy.
Dataset is from the publication:
Dorey, J.B., Fischer, E.E., Chesshire, P.R., Nava-Bolaños, A., O’Reilly, R.L., Bossert, S., Collins, S.M., Lichtenberg, E.M., Tucker, E., Smith-Pardo, A., Falcon-Brindis, A., Guevara, D.A., Ribeiro, B.R., de Pedro, D., Hung, J.K.-L., Parys, K.A., McCabe, L.M., Rogan, M.S., Minckley, R.L., Velzco, S.J.E., Griswold, T., Zarrillo, T.A., Jetz, W., Sica, Y.V., Orr, M.C., Guzman, L.M., Ascher, J., Hughes, A.C. &amp; Cobb, N.S. (2023) A globally synthesised and flagged bee occurrence dataset and cleaning workflow. Scientific Data, 10, 1–17. https://www.doi.org/10.1038/S41597-023-02626-W
The taxonomy data are mostly compiled from Discover Life data, www.discoverlife.org:
Ascher, J.S. &amp; Pickering, J. (2020) Discover Life bee species guide and world checklist (Hymenoptera: Apoidea: Anthophila). http://www.discoverlife.org/mp/20q?guide=Apoidea_species
</p>


<h3>See Also</h3>

<p><code><a href="#topic+taxadbToBeeBDC">taxadbToBeeBDC()</a></code> to download any other taxonomy (of any taxa or of bees)
and <code><a href="#topic+harmoniseR">harmoniseR()</a></code> for the
taxon-cleaning function where these taxonomies are implemented.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
beesTaxonomy &lt;- BeeBDC::beesTaxonomy()

## End(Not run)


</code></pre>

<hr>
<h2 id='chordDiagramR'>Build a chord diagram of duplicate occurrence links</h2><span id='topic+chordDiagramR'></span>

<h3>Description</h3>

<p>This function outputs a figure which shows the relative size and direction of occurrence points
duplicated between data providers, such as, SCAN, GBIF, ALA, etc. This function requires the
outputs generated by <code><a href="#topic+dupeSummary">dupeSummary()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chordDiagramR(
  dupeData = NULL,
  outPath = NULL,
  fileName = NULL,
  width = 7,
  height = 6,
  bg = "white",
  smallGrpThreshold = 3,
  title = "Duplicated record sources",
  palettes = c("cartography::blue.pal", "cartography::green.pal",
    "cartography::sand.pal", "cartography::orange.pal", "cartography::red.pal",
    "cartography::purple.pal", "cartography::brown.pal"),
  canvas.ylim = c(-1, 1),
  canvas.xlim = c(-0.6, 0.25),
  text.col = "black",
  legendX = grid::unit(6, "mm"),
  legendY = grid::unit(18, "mm"),
  legendJustify = c("left", "bottom"),
  niceFacing = TRUE,
  self.link = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chordDiagramR_+3A_dupedata">dupeData</code></td>
<td>
<p>A tibble or data frame. The duplicate file produced by <code><a href="#topic+dupeSummary">dupeSummary()</a></code>.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_outpath">outPath</code></td>
<td>
<p>Character. The path to a directory (folder) in which the output should be saved.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the output file, ending in '.pdf'.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_width">width</code></td>
<td>
<p>Numeric. The width of the figure to save (in inches). Default = 7.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_height">height</code></td>
<td>
<p>Numeric. The height of the figure to save (in inches). Default = 6.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_bg">bg</code></td>
<td>
<p>The plot's background colour. Default = &quot;white&quot;.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_smallgrpthreshold">smallGrpThreshold</code></td>
<td>
<p>Numeric. The upper threshold of sub-dataSources to be listed as &quot;other&quot;.
Default = 3.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_title">title</code></td>
<td>
<p>A character string. The figure title. Default = &quot;Duplicated record sources&quot;.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_palettes">palettes</code></td>
<td>
<p>A vector of the palettes to be used. One palette for each major dataSource and &quot;other&quot;
using the <code>paletteer</code> package. Default = c(&quot;cartography::blue.pal&quot;, &quot;cartography::green.pal&quot;,
&quot;cartography::sand.pal&quot;, &quot;cartography::orange.pal&quot;, &quot;cartography::red.pal&quot;,
&quot;cartography::purple.pal&quot;, &quot;cartography::brown.pal&quot;)</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_canvas.ylim">canvas.ylim</code></td>
<td>
<p>Canvas limits from <code><a href="circlize.html#topic+circos.par">circlize::circos.par()</a></code>. Default = c(-1.0,1.0).</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_canvas.xlim">canvas.xlim</code></td>
<td>
<p>Canvas limits from <code><a href="circlize.html#topic+circos.par">circlize::circos.par()</a></code>. Default = c(-0.6, 0.25).</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_text.col">text.col</code></td>
<td>
<p>A character string. Text colour</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_legendx">legendX</code></td>
<td>
<p>The x position of the legends, as measured in current viewport.
Passed to ComplexHeatmap::draw(). Default = grid::unit(6, &quot;mm&quot;).</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_legendy">legendY</code></td>
<td>
<p>The y position of the legends, as measured in current viewport.
Passed to ComplexHeatmap::draw(). Default = grid::unit(18, &quot;mm&quot;).</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_legendjustify">legendJustify</code></td>
<td>
<p>A character vector declaring the justification of the legends.
Passed to ComplexHeatmap::draw(). Default = c(&quot;left&quot;, &quot;bottom&quot;).</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_nicefacing">niceFacing</code></td>
<td>
<p>TRUE/FALSE. The niceFacing option automatically adjusts the text facing
according to their positions in the circle. Passed to <code><a href="circlize.html#topic+highlight.sector">circlize::highlight.sector()</a></code>.</p>
</td></tr>
<tr><td><code id="chordDiagramR_+3A_self.link">self.link</code></td>
<td>
<p>1 or 2 (numeric). Passed to <code><a href="circlize.html#topic+chordDiagram">circlize::chordDiagram()</a></code>:
if there is a self link in one sector, 1 means the link will be degenerated as a 'mountain' and the width corresponds to the value for this connection. 2 means the width of the starting root and the ending root all have the width that corresponds to the value for the connection.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Saves a figure to the provided file path.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Create a basic example dataset of duplicates to visualise
basicData &lt;- dplyr::tribble(
                            ~dataSource,    ~dataSource_keep,
                      "GBIF_Halictidae",         "USGS_data",
                      "GBIF_Halictidae",         "USGS_data",
                      "GBIF_Halictidae",         "USGS_data",
                      "GBIF_Halictidae",         "USGS_data",
                      "GBIF_Halictidae",         "USGS_data",
                      "GBIF_Halictidae",         "USGS_data",
                      "SCAN_Halictidae",   "GBIF_Halictidae",
                   "iDigBio_halictidae",   "GBIF_Halictidae",
                   "iDigBio_halictidae",   "SCAN_Halictidae",
                   "iDigBio_halictidae",   "SCAN_Halictidae",
                      "SCAN_Halictidae",   "GBIF_Halictidae",
                       "iDigBio_apidae",       "SCAN_Apidae",
                          "SCAN_Apidae",    "Ecd_Anthophila",
                       "iDigBio_apidae",    "Ecd_Anthophila",
                          "SCAN_Apidae",    "Ecd_Anthophila",
                       "iDigBio_apidae",    "Ecd_Anthophila",
                    "SCAN_Megachilidae", "SCAN_Megachilidae",
                      "CAES_Anthophila",   "CAES_Anthophila",
                      "CAES_Anthophila",   "CAES_Anthophila"
 )


 chordDiagramR(
dupeData = basicData,
outPath = tempdir(),
fileName = "ChordDiagram.pdf",
# These can be modified to help fit the final pdf that's exported.
width = 9,
height = 7.5,
bg = "white",
# How few distinct dataSources should a group have to be listed as "other"
smallGrpThreshold = 3,
title = "Duplicated record sources",
# The default list of colour palettes to choose from using the paleteer package
palettes = c("cartography::blue.pal", "cartography::green.pal", 
             "cartography::sand.pal", "cartography::orange.pal", "cartography::red.pal",
             "cartography::purple.pal", "cartography::brown.pal"),
canvas.ylim = c(-1.0,1.0), 
canvas.xlim = c(-0.6, 0.25),
text.col = "black",
legendX = grid::unit(6, "mm"),
legendY = grid::unit(18, "mm"),
legendJustify = c("left", "bottom"),
niceFacing = TRUE)
## End(Not run)
</code></pre>

<hr>
<h2 id='ColTypeR'>Sets up column names and types</h2><span id='topic+ColTypeR'></span>

<h3>Description</h3>

<p>This function uses <code><a href="readr.html#topic+cols">readr::cols_only()</a></code> to assign a column name and the type of data
(e.g., <code><a href="readr.html#topic+parse_atomic">readr::col_character()</a></code>,
and <code><a href="readr.html#topic+parse_atomic">readr::col_integer()</a></code>). To see the default columns simply run <code><a href="#topic+ColTypeR">ColTypeR()</a></code>.
This is intended for use with <code><a href="readr.html#topic+read_delim">readr::read_csv()</a></code>. Columns that are not present will NOT be included
in the resulting tibble unless they are specified using <a href="base.html#topic+...">...</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColTypeR(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColTypeR_+3A_...">...</code></td>
<td>
<p>Additional arguments. These can be specified in addition to the ones default to the
function.  For example:
</p>

<ul>
<li><p> newCharacterColumn = <code><a href="readr.html#topic+parse_atomic">readr::col_character()</a></code>,
</p>
</li>
<li><p> newNumericColumn = <code><a href="readr.html#topic+parse_atomic">readr::col_integer()</a></code>,
</p>
</li>
<li><p> newLogicalColumn = <code><a href="readr.html#topic+parse_atomic">readr::col_logical()</a></code>
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class col_spec.
See <code><a href="readr.html#topic+as.col_spec">readr::as.col_spec()</a></code> for additional context and explication.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # You can simply return the below for default values
  library(dplyr)
BeeBDC::ColTypeR() 

  # To add new columns you can write
ColTypeR(newCharacterColumn = readr::col_character(), 
         newNumericColumn = readr::col_integer(), 
         newLogicalColumn = readr::col_logical()) 

# Try reading in one of the test datasets as an example:
beesFlagged %&gt;% dplyr::as_tibble(col_types = BeeBDC::ColTypeR())
  # OR
beesRaw %&gt;% dplyr::as_tibble(col_types = BeeBDC::ColTypeR())


</code></pre>

<hr>
<h2 id='coordUncerFlagR'>Flag occurrences with an uncertainty threshold</h2><span id='topic+coordUncerFlagR'></span>

<h3>Description</h3>

<p>To use this function, the user must choose a column, probably &quot;coordinateUncertaintyInMeters&quot;
and a threshold above which occurrences will be flagged for geographic uncertainty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coordUncerFlagR(
  data = NULL,
  uncerColumn = "coordinateUncertaintyInMeters",
  threshold = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coordUncerFlagR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="coordUncerFlagR_+3A_uncercolumn">uncerColumn</code></td>
<td>
<p>Character. The column to flag uncertainty in.</p>
</td></tr>
<tr><td><code id="coordUncerFlagR_+3A_threshold">threshold</code></td>
<td>
<p>Numeric. The uncertainty threshold. Values equal to, or greater than, this
threshold will be flagged.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input data with a new column, .uncertaintyThreshold.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run the function
beesRaw_out &lt;- coordUncerFlagR(data = beesRaw,
                               uncerColumn = "coordinateUncertaintyInMeters",
                               threshold = 1000)
# View the output
table(beesRaw_out$.uncertaintyThreshold, useNA = "always")
</code></pre>

<hr>
<h2 id='countryNameCleanR'>Fix country name issues using a user-input list</h2><span id='topic+countryNameCleanR'></span>

<h3>Description</h3>

<p>This function is basic for a user to manually fix some country name inconsistencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>countryNameCleanR(data = NULL, ISO2_table = NULL, commonProblems = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="countryNameCleanR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="countryNameCleanR_+3A_iso2_table">ISO2_table</code></td>
<td>
<p>A data frame or tibble with the columns ISO2 and long names for country names. Default
is a static version from Wikipedia.</p>
</td></tr>
<tr><td><code id="countryNameCleanR_+3A_commonproblems">commonProblems</code></td>
<td>
<p>A data frame or tibble. It must have two columns:
one containing the user-identified problem and one with a user-defined fix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the input data, but with countries occurring in the user-supplied problem
column (&quot;commonProblems&quot;) replaced with those in the user-supplied fix column
</p>


<h3>Examples</h3>

<pre><code class='language-R'>beesFlagged_out &lt;- countryNameCleanR(
data = BeeBDC::beesFlagged,
commonProblems = dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES',
                        'United States','U.S.A','MX','CA','Bras.','Braz.',
                        'Brasil','CNMI','USA TERRITORY: PUERTO RICO'),
                        fix = c('United States of America','United States of America',
                                'United States of America','United States of America',
                                'United States of America','United States of America',
                                'United States of America','Mexico','Canada','Brazil',
                                'Brazil','Brazil','Northern Mariana Islands','PUERTO.RICO')))
</code></pre>

<hr>
<h2 id='countryOutlieRs'>Flag country-level outliers with a provided checklist.</h2><span id='topic+countryOutlieRs'></span>

<h3>Description</h3>

<p>This function flags country-level outliers using the checklist provided with this package.
For additional context and column names, see <code><a href="#topic+beesChecklist">beesChecklist()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>countryOutlieRs(
  checklist = NULL,
  data = NULL,
  keepAdjacentCountry = TRUE,
  pointBuffer = NULL,
  scale = 50,
  stepSize = 1e+06,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="countryOutlieRs_+3A_checklist">checklist</code></td>
<td>
<p>A data frame or tibble. The formatted checklist which was built based on the Discover Life website.</p>
</td></tr>
<tr><td><code id="countryOutlieRs_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. The a Darwin Core occurrence dataset.</p>
</td></tr>
<tr><td><code id="countryOutlieRs_+3A_keepadjacentcountry">keepAdjacentCountry</code></td>
<td>
<p>Logical. If TRUE, occurrences in countries that are adjacent to checklist countries will be
kept. If FALSE, they will be flagged.</p>
</td></tr>
<tr><td><code id="countryOutlieRs_+3A_pointbuffer">pointBuffer</code></td>
<td>
<p>Numeric. A buffer around points to help them align with a country or coastline.
This provides a good way to retain points that occur right along the coast or borders of the
maps in rnaturalearth</p>
</td></tr>
<tr><td><code id="countryOutlieRs_+3A_scale">scale</code></td>
<td>
<p>Numeric. The value fed into the map scale parameter for
<code><a href="rnaturalearth.html#topic+ne_countries">rnaturalearth::ne_countries()</a></code>'s scale parameter:
Scale of map to return, one of 110, 50, 10 or 'small', 'medium', 'large', where smaller numbers
are higher resolution. WARNING: This function is tested on 110 and 50.</p>
</td></tr>
<tr><td><code id="countryOutlieRs_+3A_stepsize">stepSize</code></td>
<td>
<p>Numeric. The number of occurrences to process in each chunk. Default = 1000000.</p>
</td></tr>
<tr><td><code id="countryOutlieRs_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory. If the cores throw issues, consider
setting mc.cores to 1.
Default = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input data with two new columns, .countryOutlier or .sea. There are three possible
values for
the new column: TRUE == passed, FALSE == failed (not in country or in the ocean),
NA == did not overlap with rnaturalearth map.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(magrittr)
  # Load in the test dataset
beesRaw &lt;- BeeBDC::beesRaw
  # For the sake of this example, use the testChecklist
system.file("extdata", "testChecklist.rda", package="BeeBDC") |&gt; load()
  # For real examples, you might download the beesChecklist from FigShare using 
  #  [BeeBDC::beesChecklist()]

beesRaw_out &lt;- countryOutlieRs(checklist = testChecklist,
                               data = beesRaw %&gt;%
                               dplyr::filter(dplyr::row_number() %in% 1:50),
                               keepAdjacentCountry = TRUE,
                               pointBuffer = 1,
                               scale = 50,
                               stepSize = 1000000,
                               mc.cores = 1)
table(beesRaw_out$.countryOutlier, useNA = "always")
</code></pre>

<hr>
<h2 id='dataProvTables'>Build a table of data providers for bee occurrence records</h2><span id='topic+dataProvTables'></span>

<h3>Description</h3>

<p>This function will attempt to find and build a table of data providers that have contributed
to the input data, especially using the 'institutionCode' column. It will also look for a
variety of other columns to find data providers using an internally set sequence of if-else
statements. Hence, this function is quite specific for bee data, but should work for other
taxa in similar institutions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataProvTables(
  data = NULL,
  runBeeDataChecks = FALSE,
  outPath = OutPath_Report,
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataProvTables_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="dataProvTables_+3A_runbeedatachecks">runBeeDataChecks</code></td>
<td>
<p>Logical. If TRUE, will search in other columns for specific clues to
determine the institution.</p>
</td></tr>
<tr><td><code id="dataProvTables_+3A_outpath">outPath</code></td>
<td>
<p>A character path. The path to the directory in which the figure will be saved.
Default = OutPath_Report.</p>
</td></tr>
<tr><td><code id="dataProvTables_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the file to be saved, ending in &quot;.csv&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a table with the data providers, an specimen count, and a species count.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(beesFlagged)

testOut &lt;- dataProvTables(
data = beesFlagged,
runBeeDataChecks = TRUE,
outPath = tempdir(),
fileName = "testFile.csv")

</code></pre>

<hr>
<h2 id='dataSaver'>Simple function to save occurrence AND EML data as a list</h2><span id='topic+dataSaver'></span>

<h3>Description</h3>

<p>Used at the end of 1.x in the example workflow in order to save the occurrence dataset and its associated eml metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataSaver(
  path = NULL,
  save_type = NULL,
  occurrences = NULL,
  eml_files = NULL,
  file_prefix = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataSaver_+3A_path">path</code></td>
<td>
<p>Character. The main file path to look for data in.</p>
</td></tr>
<tr><td><code id="dataSaver_+3A_save_type">save_type</code></td>
<td>
<p>Character. The file format in which to save occurrence and EML data.
Either &quot;R_file&quot; or &quot;CSV_file&quot;</p>
</td></tr>
<tr><td><code id="dataSaver_+3A_occurrences">occurrences</code></td>
<td>
<p>The occurrences to save as a data frame or tibble.</p>
</td></tr>
<tr><td><code id="dataSaver_+3A_eml_files">eml_files</code></td>
<td>
<p>A list of the EML files.</p>
</td></tr>
<tr><td><code id="dataSaver_+3A_file_prefix">file_prefix</code></td>
<td>
<p>Character. A prefix for the resulting output file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function saves both occurrence and EML data as a list when save_type = &quot;R_File&quot; or
as individual csv files when save_type = &quot;CSV_file&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataSaver(path = tempdir(),# The main path to look for data in
save_type = "CSV_file", # "R_file" OR "CSV_file"
occurrences = Complete_data$Data_WebDL, # The existing datasheet
eml_files = Complete_data$eml_files, # The existing EML files
file_prefix = "Fin_") # The prefix for the file name

## End(Not run)

</code></pre>

<hr>
<h2 id='dateFindR'>Find dates in other columns</h2><span id='topic+dateFindR'></span>

<h3>Description</h3>

<p>A function made to search other columns for dates and add them to the eventDate column.
The function searches the columns locality, fieldNotes, locationRemarks, and verbatimEventDate
for the relevant information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dateFindR(data = NULL, maxYear = lubridate::year(Sys.Date()), minYear = 1700)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dateFindR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="dateFindR_+3A_maxyear">maxYear</code></td>
<td>
<p>Numeric. The maximum year considered reasonable to find.
Default = lubridate::year(Sys.Date()).</p>
</td></tr>
<tr><td><code id="dateFindR_+3A_minyear">minYear</code></td>
<td>
<p>Numeric. The minimum year considered reasonable to find. Default = 1700.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function results in the input occurrence data with but with updated eventDate, year,
month, and day columns for occurrences where these data were a) missing and b) located in one of the
searched columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using the example dataset, you may not find any missing eventDates are rescued (dependent on 
# which version of the example dataset the user inputs.
beesRaw_out &lt;- dateFindR(data = beesRaw,
                         # Years above this are removed (from the recovered dates only)
                         maxYear = lubridate::year(Sys.Date()),
                         # Years below this are removed (from the recovered dates only)
                         minYear = 1700)
</code></pre>

<hr>
<h2 id='diagonAlley'>Find fill-down errors</h2><span id='topic+diagonAlley'></span>

<h3>Description</h3>

<p>A simple function that looks for potential latitude and longitude fill-down errors by
identifying consecutive occurrences with coordinates at regular intervals. This is accomplished
by using a sliding window with the length determined by minRepeats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagonAlley(
  data = NULL,
  minRepeats = NULL,
  groupingColumns = c("eventDate", "recordedBy", "datasetName"),
  ndec = 3,
  stepSize = 1e+06,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagonAlley_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="diagonAlley_+3A_minrepeats">minRepeats</code></td>
<td>
<p>Numeric. The minimum number of lat or lon repeats needed to flag a record</p>
</td></tr>
<tr><td><code id="diagonAlley_+3A_groupingcolumns">groupingColumns</code></td>
<td>
<p>Character. The column(s) to group the analysis by and search for fill-down
errors within. Default = c(&quot;eventDate&quot;, &quot;recordedBy&quot;, &quot;datasetName&quot;).</p>
</td></tr>
<tr><td><code id="diagonAlley_+3A_ndec">ndec</code></td>
<td>
<p>Numeric. The number of decimal places below which records will not be considered
in the diagonAlley function. This is fed into <code><a href="#topic+jbd_coordinates_precision">jbd_coordinates_precision()</a></code>. Default = 3.</p>
</td></tr>
<tr><td><code id="diagonAlley_+3A_stepsize">stepSize</code></td>
<td>
<p>Numeric. The number of occurrences to process in each chunk. Default = 1000000.</p>
</td></tr>
<tr><td><code id="diagonAlley_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory.
Default = 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sliding window (and hence fill-down errors) will only be examined
within the user-defined groupingColumns; if any of those
columns are empty, that record will be excluded.
</p>


<h3>Value</h3>

<p>The function returns the input data with a new column, .sequential, where FALSE =
records that have consecutive latitudes or longitudes greater than or equal to the user-defined
threshold.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read in the example data
  data(beesRaw)
 # Run the function
  beesRaw_out &lt;- diagonAlley(
    data = beesRaw,
    # The minimum number of repeats needed to find a sequence in for flagging
    minRepeats = 4,
    groupingColumns = c("eventDate", "recordedBy", "datasetName"),
    ndec = 3,
    stepSize = 1000000,
    mc.cores = 1)
  

</code></pre>

<hr>
<h2 id='dirMaker'>Set up global directory paths and create folders</h2><span id='topic+dirMaker'></span>

<h3>Description</h3>

<p>This function sets up a directory for saving outputs (i.e. data, figures) generated through the
use of the BeeBDC package, if the required folders do not already exist.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirMaker(
  RootPath = RootPath,
  ScriptPath = NULL,
  DataPath = NULL,
  DataSubPath = "/Data_acquisition_workflow",
  DiscLifePath = NULL,
  OutPath = NULL,
  OutPathName = "Output",
  Report = TRUE,
  Check = TRUE,
  Figures = TRUE,
  Intermediate = TRUE,
  RDoc = NULL,
  useHere = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dirMaker_+3A_rootpath">RootPath</code></td>
<td>
<p>A character String. The <code>RootPath</code> is the base path for your project, and all
other paths should ideally be located within the <code>RootPath</code>. However, users may specify paths not
contained in the RootPath</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_scriptpath">ScriptPath</code></td>
<td>
<p>A character String. The <code>ScriptPath</code> is the path to any additional functions
that you would like to read in for use with BeeBDC.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_datapath">DataPath</code></td>
<td>
<p>A character string. The path to the folder containing bee occurrence data
to be flagged and/or cleaned</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_datasubpath">DataSubPath</code></td>
<td>
<p>A character String. If a <code>DataPath</code> is not provided, this will be used as the <code>DataPath</code>
folder name within the <code>RootPath.</code> Default is &quot;/Data_acquisition_workflow&quot;</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_disclifepath">DiscLifePath</code></td>
<td>
<p>A character String. The path to the folder which contains data from Ascher
and Pcikering's Discover Life website.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_outpath">OutPath</code></td>
<td>
<p>A character String. The path to the folder where output data will be saved.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_outpathname">OutPathName</code></td>
<td>
<p>A character String. The name of the <code>OutPath</code> subfolder located within the
<code>RootPath.</code> Default is &quot;Output&quot;.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_report">Report</code></td>
<td>
<p>Logical. If TRUE, function creates a &quot;Report&quot; folder within the OutPath-defined
folder. Default = TRUE.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_check">Check</code></td>
<td>
<p>Logical. If TRUE, function creates a &quot;Check&quot; folder within the OutPath-defined
folder. Default = TRUE.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_figures">Figures</code></td>
<td>
<p>Logical. If TRUE, function creates a &quot;Figures&quot; folder within the OutPath-defined
folder. Default = TRUE.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_intermediate">Intermediate</code></td>
<td>
<p>Logical. If TRUE, function creates a &quot;Intermediate&quot; folder within the
OutPath-defined folder in which to save intermediate datasets. Default = TRUE.</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_rdoc">RDoc</code></td>
<td>
<p>A character String. The path to the current script or report, relative to the project
root. Passing an absolute path raises an error. This argument is used by <code><a href="here.html#topic+i_am">here::i_am()</a></code> and incorrectly
setting this may result in <code>bdc</code> figures being saved to your computer's root directory</p>
</td></tr>
<tr><td><code id="dirMaker_+3A_usehere">useHere</code></td>
<td>
<p>Logical. If TRUE, dirMaker will use <code><a href="here.html#topic+i_am">here::i_am()</a></code> to declare the relative path
to 'RDoc'. This is aimed at preserving some functionality with where bdc saves summary figures
and tables. Default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Results in the generation of a list containing the BeeBDC-required directories in your global
environment. This function should be run at the start of each session. Additionally, this
function will create the BeeBDC-required folders if they do not already exist in the supplied
directory
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # load dplyr
  library(dplyr)
# Standard/basic usage:
RootPath &lt;- tempdir()
dirMaker(
RootPath = RootPath,
# Input the location of the workflow script RELATIVE to the RootPath
RDoc = NULL,
useHere = FALSE) %&gt;%
  # Add paths created by this function to the environment()
  list2env(envir = environment())  

# Custom OutPathName provided
  dirMaker(
 RootPath = RootPath,
 # Set some custom OutPath info
 OutPath = NULL,
 OutPathName = "T2T_Output",
 # Input the location of the workflow script RELATIVE to the RootPath
 RDoc = NULL,
 useHere = FALSE) %&gt;%
   # Add paths created by this function to the environment()
   list2env(envir = environment())  
 # Set the working directory

# Further customisations are also possible
dirMaker(
  RootPath = RootPath,
  ScriptPath = "...path/Bee_SDM_paper/BDC_repo/BeeBDC/R",
  DiscLifePath = "...path/BDC_repo/DiscoverLife_Data",
  OutPathName = "AsianPerspective_Output",
  # Input the location of the workflow script RELATIVE to the RootPath
  RDoc = NULL,
  useHere = FALSE) %&gt;%
  # Add paths created by this function to the environment()
  list2env(envir = environment())  



</code></pre>

<hr>
<h2 id='dupePlotR'>Create a compound bar graph of duplicate data sources</h2><span id='topic+dupePlotR'></span>

<h3>Description</h3>

<p>Creates a plot with two bar graphs. One shows the absolute number of duplicate records for each
data source
while the other shows the proportion of records that are duplicated within each data source.
This function requires a dataset that has been run through <code><a href="#topic+dupeSummary">dupeSummary()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dupePlotR(
  data = NULL,
  outPath = NULL,
  fileName = NULL,
  legend.position = c(0.85, 0.8),
  base_height = 7,
  base_width = 7,
  ...,
  dupeColours = c("#F2D2A2", "#B9D6BC", "#349B90"),
  returnPlot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dupePlotR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_outpath">outPath</code></td>
<td>
<p>Character. The path to a directory (folder) in which the output should be saved.</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the output file, ending in '.pdf'.</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_legend.position">legend.position</code></td>
<td>
<p>The position of the legend as coordinates. Default = c(0.85, 0.8).</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_base_height">base_height</code></td>
<td>
<p>Numeric. The height of the plot in inches. Default = 7.</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_base_width">base_width</code></td>
<td>
<p>Numeric. The width of the plot in inches. Default = 7.</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_...">...</code></td>
<td>
<p>Other arguments to be used to change factor levels of data sources.</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_dupecolours">dupeColours</code></td>
<td>
<p>A vector of colours for the levels duplicate, kept duplicate, and unique.
Default = c(&quot;#F2D2A2&quot;,&quot;#B9D6BC&quot;, &quot;#349B90&quot;).</p>
</td></tr>
<tr><td><code id="dupePlotR_+3A_returnplot">returnPlot</code></td>
<td>
<p>Logical. If TRUE, return the plot to the environment. Default = FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Outputs a .pdf figure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# This example will show a warning for the factor levels taht are not present in the specific 
# test dataset
dupePlotR(
  data = beesFlagged,
  # The outPath to save the plot as
    # Should be something like: #paste0(OutPath_Figures, "/duplicatePlot_TEST.pdf"),
  outPath = tempdir(), 
  fileName = "duplicatePlot_TEST.pdf",
  # Colours in order: duplicate, kept duplicate, unique
  dupeColours = c("#F2D2A2","#B9D6BC", "#349B90"),
  # Plot size and height
  base_height = 7, base_width = 7,
  legend.position = c(0.85, 0.8),
  # Extra variables can be fed into forcats::fct_recode() to change names on plot
  GBIF = "GBIF", SCAN = "SCAN", iDigBio = "iDigBio", USGS = "USGS", ALA = "ALA", 
  ASP = "ASP", CAES = "CAES", 'B. Mont.' = "BMont", 'B. Minckley' = "BMin", Ecd = "Ecd",
  Gaiarsa = "Gai", EPEL = "EPEL", Lic = "Lic", Bal = "Bal", Arm = "Arm"
  )
</code></pre>

<hr>
<h2 id='dupeSummary'>Identifies duplicate occurrence records</h2><span id='topic+dupeSummary'></span>

<h3>Description</h3>

<p>This function uses user-specified inputs and columns to identify duplicate occurrence records.
Duplicates are identified iteratively and will be tallied up, duplicate pairs clustered, and
sorted at the end of the function.
The function is designed to work with Darwin Core data with a database_id column,
but it is also modifiable to work with other columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dupeSummary(
  data = NULL,
  path = NULL,
  duplicatedBy = NULL,
  completeness_cols = NULL,
  idColumns = NULL,
  collectionCols = NULL,
  collectInfoColumns = NULL,
  CustomComparisonsRAW = NULL,
  CustomComparisons = NULL,
  sourceOrder = NULL,
  prefixOrder = NULL,
  dontFilterThese = c(".gridSummary", ".lonFlag", ".latFlag", ".uncer_terms",
    ".uncertaintyThreshold", ".unLicensed"),
  characterThreshold = 2,
  numberThreshold = 3,
  numberOnlyThreshold = 5,
  catalogSwitch = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dupeSummary_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_path">path</code></td>
<td>
<p>A character path to the location where the duplicateRun_ file will be saved.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_duplicatedby">duplicatedBy</code></td>
<td>
<p>A character vector. Options are c(&quot;ID&quot;, &quot;collectionInfo&quot;, &quot;both&quot;). &quot;ID&quot;
columns runs through a series of ID-only columns defined by idColumns. &quot;collectionInfo&quot; runs
through a series of columns defined by collectInfoColumns, which are checked in combination
with collectionCols. &quot;both&quot; runs both of the above.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_completeness_cols">completeness_cols</code></td>
<td>
<p>A character vector. A set of columns that are used to order and select
duplicates by. For each occurrence, this function will calculate the sum of <code><a href="stats.html#topic+complete.cases">complete.cases()</a></code>.
Within duplicate clusters occurrences with a greater number of the completeness_cols filled
in will be kept over those with fewer.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_idcolumns">idColumns</code></td>
<td>
<p>A character vector. The columns to be checked individually for internal
duplicates. Intended for use with ID columns only.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_collectioncols">collectionCols</code></td>
<td>
<p>A character vector. The columns to be checked in combination with each
of the completeness_cols.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_collectinfocolumns">collectInfoColumns</code></td>
<td>
<p>A character vector. The columns to be checked in combinatino with
all of the collectionCols columns.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_customcomparisonsraw">CustomComparisonsRAW</code></td>
<td>
<p>A list of character vectors. Custom comparisons - as a list of
columns to iteratively compare for duplicates. These differ from the CustomComparisons in
that they ignore the minimum number and character thresholds for IDs.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_customcomparisons">CustomComparisons</code></td>
<td>
<p>A list of character vectors. Custom comparisons - as a list of
columns to iteratively compare for duplicates. These comparisons are made after character
and number thresholds are accounted for in ID columns.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_sourceorder">sourceOrder</code></td>
<td>
<p>A character vector. The order in which you want to KEEP duplicated
based on the dataSource column (i.e. what order to prioritize data sources).
NOTE: These dataSources are simplified to the string prior
to the first &quot;_&quot;. Hence, &quot;GBIF_Anthophyla&quot; becomes &quot;GBIF.&quot;</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_prefixorder">prefixOrder</code></td>
<td>
<p>A character vector. Like sourceOrder, except based on the database_id prefix,
rather than the dataSource. Additionally, this is only examined if prefixOrder != NULL.
Default = NULL.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_dontfilterthese">dontFilterThese</code></td>
<td>
<p>A character vector. This should contain the flag columns to be ignored
in the creation or updating of the .summary column. Passed to  <code><a href="#topic+summaryFun">summaryFun()</a></code>.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_characterthreshold">characterThreshold</code></td>
<td>
<p>Numeric. The complexity threshold for ID letter length. This is the
minimum number of characters that need to be present in ADDITION TO the numberThreshold for an
ID number to be tested for duplicates. Ignored by CustomComparisonsRAW. The columns that are
checked are occurrenceID, recordId, id, catalogNumber, and otherCatalogNumbers. Default = 2.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_numberthreshold">numberThreshold</code></td>
<td>
<p>Numeric. The complexity threshold for ID number length. This is the
minimum number of numeric characters that need to be present in ADDITION TO the
characterThreshold for an ID number to be tested for duplicates. Ignored by
CustomComparisonsRAW. The columns that are checked are occurrenceID, recordId, id,
catalogNumber, and otherCatalogNumbers. Default = 3.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_numberonlythreshold">numberOnlyThreshold</code></td>
<td>
<p>Numeric. As numberThreshold except the characterThreshold is ignored.
Default = 5.</p>
</td></tr>
<tr><td><code id="dupeSummary_+3A_catalogswitch">catalogSwitch</code></td>
<td>
<p>Logical. If TRUE, and the catalogNumber is empty the function will copy over
the otherCatalogNumbers into catalogNumber and visa versa. Hence, the function will attempt
to matchmore catalog numbers as both of these functions can be problematic. Default = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data with an additional column called .duplicates where FALSE occurrences are
duplicates and TRUE occurrences are either kept duplicates or unique. Also exports a .csv to
the user-specified location with information about duplicate matching. This file is used by
other functions including
<code><a href="#topic+manualOutlierFindeR">manualOutlierFindeR()</a></code> and <code><a href="#topic+chordDiagramR">chordDiagramR()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chordDiagramR">chordDiagramR()</a></code> for creating a chord diagram to visualise linkages between
dataSources and <code><a href="#topic+dupePlotR">dupePlotR()</a></code> to visualise the numbers and proportions of duplicates in
each dataSource.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>beesFlagged_out &lt;- dupeSummary(
data = BeeBDC::beesFlagged,
  # Should start with paste0(DataPath, "/Output/Report/"), instead of tempdir():
path = paste0(tempdir(), "/"),
# options are "ID","collectionInfo", or "both"
duplicatedBy = "collectionInfo", # I'm only running ID for the first lot because we might 
# recover other info later
# The columns to generate completeness info from
completeness_cols = c("decimalLatitude",  "decimalLongitude",
                      "scientificName", "eventDate"),
# idColumns = c("gbifID", "occurrenceID", "recordId","id"),
# The columns to ADDITIONALLY consider when finding duplicates in collectionInfo
collectionCols = c("decimalLatitude", "decimalLongitude", "scientificName", "eventDate", 
                   "recordedBy"),
# The columns to combine, one-by-one with the collectionCols
collectInfoColumns = c("catalogNumber", "otherCatalogNumbers"),
# Custom comparisons - as a list of columns to compare
# RAW custom comparisons do not use the character and number thresholds
CustomComparisonsRAW = dplyr::lst(c("catalogNumber", "institutionCode", "scientificName")),
# Other custom comparisons use the character and number thresholds
CustomComparisons = dplyr::lst(c("gbifID", "scientificName"),
                                c("occurrenceID", "scientificName"),
                                c("recordId", "scientificName"),
                                c("id", "scientificName")),
# The order in which you want to KEEP duplicated based on data source
# try unique(check_time$dataSource)
sourceOrder = c("CAES", "Gai", "Ecd","BMont", "BMin", "EPEL", "ASP", "KP", "EcoS", "EaCO",
                "FSCA", "Bal", "SMC", "Lic", "Arm",
                "USGS", "ALA", "GBIF","SCAN","iDigBio"),
# !!!!!! BELS &gt; GeoLocate
# Set the complexity threshold for id letter and number length
# minimum number of characters when WITH the numberThreshold
characterThreshold = 2,
# minimum number of numbers when WITH the characterThreshold
numberThreshold = 3,
# Minimum number of numbers WITHOUT any characters
numberOnlyThreshold = 5)


</code></pre>

<hr>
<h2 id='fileFinder'>Finds files within a directory</h2><span id='topic+fileFinder'></span>

<h3>Description</h3>

<p>A function which can be used to find files within a user-defined directory based on a
user-provided character string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fileFinder(path, fileName)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fileFinder_+3A_path">path</code></td>
<td>
<p>A directory as character. The directory to recursively search.</p>
</td></tr>
<tr><td><code id="fileFinder_+3A_filename">fileName</code></td>
<td>
<p>A character/regex string. The file name to find.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a directory to the most-recent file that matches the provied file Using regex
can greatly improve specificity. Using regex can greatly improve specificity.
The function will also write into the console the file that it has found - it is worthwhile to
check that this is the correct file to avoid complications down the line
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load dplyr
library(dplyr)

 # Make the RootPath to the tempdir for this example
  RootPath &lt;- tempdir()
  
 # Load the example data
 data("beesRaw", package = "BeeBDC")

# Save and example dataset to the temp dir
  readr::write_csv(beesRaw, file = paste0(RootPath, "/beesRaw.csv"))

 # Now go find it!
fileFinder(path = RootPath, fileName = "beesRaw")
# more specifically the .csv version
fileFinder(path = RootPath, fileName = "beesRaw.csv")

</code></pre>

<hr>
<h2 id='flagAbsent'>Flags occurrences that are marked as absent</h2><span id='topic+flagAbsent'></span>

<h3>Description</h3>

<p>Flags occurrences that are &quot;ABSENT&quot; for the occurrenceStatus (or some other user-specified) column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flagAbsent(data = NULL, PresAbs = "occurrenceStatus")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flagAbsent_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="flagAbsent_+3A_presabs">PresAbs</code></td>
<td>
<p>Character. The column in which the function will find &quot;ABSENT&quot; or &quot;PRESENT&quot; records.
Default = &quot;occurrenceStatus&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input data with a new column called &quot;.occurrenceAbsent&quot; where FALSE == &quot;ABSENT&quot; records.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Bring in the data
data(beesRaw)
  # Run the function
beesRaw_out &lt;- flagAbsent(data = beesRaw,
PresAbs = "occurrenceStatus")
  # See the result
table(beesRaw_out$.occurrenceAbsent, useNA = "always")
</code></pre>

<hr>
<h2 id='flagLicense'>Flag license protected records</h2><span id='topic+flagLicense'></span>

<h3>Description</h3>

<p>This function will search for strings that indicate a record is restricted in its use and will
flag the restricted records.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flagLicense(data = NULL, strings_to_restrict = "all", excludeDataSource = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flagLicense_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="flagLicense_+3A_strings_to_restrict">strings_to_restrict</code></td>
<td>
<p>A character vector. Should contain the strings used to detect protected records.
Default =  c(&quot;All Rights Reserved&quot;, &quot;All rights reserved&quot;, &quot;All rights reserved.&quot;, &quot;ND&quot;, &quot;Not for public&quot;)</p>
</td></tr>
<tr><td><code id="flagLicense_+3A_excludedatasource">excludeDataSource</code></td>
<td>
<p>Optional. A character vector. A vector of the data sources (dataSource)
that will not be flagged as protected, even if they are. This is useful if you have a private
dataset that should be listed  as &quot;All rights reserved&quot; which you want to be ignored by this flag.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the data with a new column, .unLicensed, where FALSE = records that are protected by
a license.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Read in the example data
data("beesRaw")
  # Run the function
beesRaw_out &lt;- flagLicense(data = beesRaw,
                        strings_to_restrict = "all",
                        # DON'T flag if in the following data# source(s)
                        excludeDataSource = NULL)
</code></pre>

<hr>
<h2 id='flagRecorder'>Loads, appends, and saves occurrence flag data</h2><span id='topic+flagRecorder'></span>

<h3>Description</h3>

<p>This function is used to save the flag data for your occurrence data as you run the BeeBDC script.
It will read and append existing files, if asked to. Your flags should also be saved in the occurrence
file itself automatically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flagRecorder(
  data = NULL,
  outPath = NULL,
  fileName = NULL,
  idColumns = c("database_id", "id", "catalogNumber", "occurrenceID", "dataSource"),
  append = NULL,
  printSummary = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flagRecorder_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="flagRecorder_+3A_outpath">outPath</code></td>
<td>
<p>A character path. Where the file should be saved.</p>
</td></tr>
<tr><td><code id="flagRecorder_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the file to be saved</p>
</td></tr>
<tr><td><code id="flagRecorder_+3A_idcolumns">idColumns</code></td>
<td>
<p>A character vector. The names of the columns that are to be kept along with the
flag columns. These columns should be useful for identifying unique records with flags.
Default = c(&quot;database_id&quot;, &quot;id&quot;, &quot;catalogNumber&quot;, &quot;occurrenceID&quot;, &quot;dataSource&quot;).</p>
</td></tr>
<tr><td><code id="flagRecorder_+3A_append">append</code></td>
<td>
<p>Logical. If TRUE, this will find and append an existing file generated by this function.</p>
</td></tr>
<tr><td><code id="flagRecorder_+3A_printsummary">printSummary</code></td>
<td>
<p>Logical. If TRUE, print a <code><a href="base.html#topic+summary">summary()</a></code> of all filter columns - i.e. those which
tidyselect::starts_with(&quot;.&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Saves a file with id and flag columns and returns this as an object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the example data
data("beesFlagged")

  # Run the function
  OutPath_Report &lt;- tempdir()
flagFile &lt;- flagRecorder(
  data = beesFlagged,
  outPath = paste(OutPath_Report, sep =""),
  fileName = paste0("flagsRecorded_", Sys.Date(), ".csv"),
  # These are the columns that will be kept along with the flags
  idColumns = c("database_id", "id", "catalogNumber", "occurrenceID", "dataSource"),
  # TRUE if you want to find a file from a previous part of the script to append to
  append = FALSE)
</code></pre>

<hr>
<h2 id='flagSummaryTable'>Build a per-species summary for each and all flags</h2><span id='topic+flagSummaryTable'></span>

<h3>Description</h3>

<p>Takes a flagged dataset and returns the total number of fails (FALSE) per flag (columns starting
with &quot;.&quot;) and per species. It will ignore the .scientificName_empty and .invalidName columns as
species are not assigned.
Users may define the column to group the summary by. While it is intended to work with
the scientificName column, users may select any grouping column (e.g., country).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flagSummaryTable(
  data = NULL,
  column = "scientificName",
  outPath = OutPath_Report,
  fileName = "flagTable.csv",
  percentImpacted = TRUE,
  percentThreshold = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flagSummaryTable_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. The flagged dataset.</p>
</td></tr>
<tr><td><code id="flagSummaryTable_+3A_column">column</code></td>
<td>
<p>Character. The name of the column to group by and summarise the failed occurrences.
Default = &quot;scientificName&quot;.</p>
</td></tr>
<tr><td><code id="flagSummaryTable_+3A_outpath">outPath</code></td>
<td>
<p>A character path. The path to the directory in which the figure will be saved.
Default = OutPath_Report. If is NULL then no file will be saved to the disk.</p>
</td></tr>
<tr><td><code id="flagSummaryTable_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the file to be saved, ending in &quot;.csv&quot;.
Default = &quot;flagTable.csv&quot;.</p>
</td></tr>
<tr><td><code id="flagSummaryTable_+3A_percentimpacted">percentImpacted</code></td>
<td>
<p>Logical. If TRUE (the default), the program will write the percentage of
species impacted and over the percentThreshold for each flagging column.</p>
</td></tr>
<tr><td><code id="flagSummaryTable_+3A_percentthreshold">percentThreshold</code></td>
<td>
<p>Numeric. A number between 0 and 100 to indicate the percent of
individuals (&gt;; within each species) that is impacted by a flag, and to be included in the
percentImpacted. Default = 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with a column for each flag column (starting with &quot;.&quot;) showing the number of
failed (FALSE) occurrences per group. Also shows the (i) total number of records, (ii) total
number of failed records, and (iii) the percentage of failed records.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the toy flagged bee data
data("beesFlagged")

  # Run the function and build the flag table
flagTibble &lt;- flagSummaryTable(data = beesFlagged,
                              column = "scientificName",
                              outPath = paste0(tempdir()),
                              fileName = "flagTable.csv")
                              

</code></pre>

<hr>
<h2 id='formattedCombiner'>Combine the formatted USGS data with the main dataset</h2><span id='topic+formattedCombiner'></span>

<h3>Description</h3>

<p>Merges the Darwin Core version of the USGS dataset that was created using <code><a href="#topic+USGS_formatter">USGS_formatter()</a></code>
with the main dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formattedCombiner(path, strings, existingOccurrences, existingEMLs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formattedCombiner_+3A_path">path</code></td>
<td>
<p>A directory as character. The directory to look in for the formatted USGS data.</p>
</td></tr>
<tr><td><code id="formattedCombiner_+3A_strings">strings</code></td>
<td>
<p>A regex string. The string to find the most-recent formatted USGS dataset.</p>
</td></tr>
<tr><td><code id="formattedCombiner_+3A_existingoccurrences">existingOccurrences</code></td>
<td>
<p>A data frame. The existing occurrence dataset.</p>
</td></tr>
<tr><td><code id="formattedCombiner_+3A_existingemls">existingEMLs</code></td>
<td>
<p>An EML file. The existing EML data file to be appended.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the combined occurrence dataset and the updated EML file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DataPath &lt;- tempdir()
strings = c("USGS_DRO_flat_27-Apr-2022")
    # Combine the USGS data and the existing big dataset
Complete_data &lt;- formattedCombiner(path = DataPath, 
                                    strings = strings, 
                                    # This should be the list-format with eml attached
                                    existingOccurrences = DataImp$Data_WebDL,
                                    existingEMLs = DataImp$eml_files) 
                                    
## End(Not run)
</code></pre>

<hr>
<h2 id='GBIFissues'>Flags records with GBIF issues</h2><span id='topic+GBIFissues'></span>

<h3>Description</h3>

<p>This function will flag records which are subject to a user-specified vector of GBIF issues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GBIFissues(data = NULL, issueColumn = "issue", GBIFflags = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GBIFissues_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="GBIFissues_+3A_issuecolumn">issueColumn</code></td>
<td>
<p>Character. The column in which to look for GBIF issues. Default = &quot;issue&quot;.</p>
</td></tr>
<tr><td><code id="GBIFissues_+3A_gbifflags">GBIFflags</code></td>
<td>
<p>Character vector. The GBIF issues to flag. Users may choose their own vector of issues to flag or
use a pre-set vector or vectors, including c(&quot;allDates&quot;, &quot;allMetadata&quot;, &quot;allObservations&quot;,
&quot;allSpatial&quot;, &quot;allTaxo&quot;, or &quot;all&quot;).
</p>
<p>Default = c(&quot;COORDINATE_INVALID&quot;, &quot;PRESUMED_NEGATED_LONGITUDE&quot;, &quot;PRESUMED_NEGATED_LATITUDE&quot;, &quot;COUNTRY_COORDINATE_MISMATCH&quot;, &quot;ZERO_COORDINATE&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the data with a new column, &quot;.GBIFflags&quot;, where FALSE = records with any of the provided
GBIFflags.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import the example data
data(beesRaw)
# Run the function
beesRaw_Out &lt;- GBIFissues(data = beesRaw, 
   issueColumn = "issue", 
   GBIFflags = c("COORDINATE_INVALID", "ZERO_COORDINATE")) 


</code></pre>

<hr>
<h2 id='harmoniseR'>Harmonise taxonomy of bee occurrence data</h2><span id='topic+harmoniseR'></span>

<h3>Description</h3>

<p>Uses the Discover Life taxonomy to harmonise bee occurrences and flag those that do not match
the checklist. <code><a href="#topic+harmoniseR">harmoniseR()</a></code> prefers to use the names_clean columns that is generated
by <code><a href="bdc.html#topic+bdc_clean_names">bdc::bdc_clean_names()</a></code>. While this is not required, you may find better results by running
that function on your dataset first.
This function could be hijacked to service other taxa if a user matched the format of the
<code><a href="#topic+beesTaxonomy">beesTaxonomy()</a></code> file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmoniseR(
  data = NULL,
  path = NULL,
  taxonomy = BeeBDC::beesTaxonomy(),
  speciesColumn = "scientificName",
  rm_names_clean = TRUE,
  checkVerbatim = FALSE,
  stepSize = 1e+06,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="harmoniseR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_path">path</code></td>
<td>
<p>A directory as character. The path to a folder that the output can be saved.</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_taxonomy">taxonomy</code></td>
<td>
<p>A data frame or tibble. The bee taxonomy to use.
Default = <code><a href="#topic+beesTaxonomy">beesTaxonomy()</a></code>.</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_speciescolumn">speciesColumn</code></td>
<td>
<p>Character. The name of the column containing species names. Default = &quot;scientificName&quot;.</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_rm_names_clean">rm_names_clean</code></td>
<td>
<p>Logical. If TRUE then the names_clean column will be removed at the end of
this function to help reduce confusion about this column later. Default = TRUE</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_checkverbatim">checkVerbatim</code></td>
<td>
<p>Logical. If TRUE then the verbatimScientificName will be checked as well
for species matches. This matching will ONLY be done after harmoniseR has failed for the other
name columns. NOTE: this column is <em>not</em> first run through <code>bdc::bdc_clean_names</code>. Default = FALSE</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_stepsize">stepSize</code></td>
<td>
<p>Numeric. The number of occurrences to process in each chunk. Default = 1000000.</p>
</td></tr>
<tr><td><code id="harmoniseR_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory.
Default = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The occurrences are returned with update taxonomy columns, including: scientificName,
species, family, subfamily, genus, subgenus, specificEpithet, infraspecificEpithet, and
scientificNameAuthorship. A new column, .invalidName, is also added and is FALSE when the occurrence's
name did not match the supplied taxonomy.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+taxadbToBeeBDC">taxadbToBeeBDC()</a></code> to download any taxonomy (of any taxa or of bees) and
<code><a href="#topic+beesTaxonomy">beesTaxonomy()</a></code> for the bee taxonomy download.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in the test dataset
system.file("extdata", "testTaxonomy.rda", package="BeeBDC") |&gt; load()

beesRaw_out &lt;- BeeBDC::harmoniseR(
  #The path to a folder that the output can be saved
path = tempdir(),
# The formatted taxonomy file
taxonomy = testTaxonomy, 
data = BeeBDC::beesFlagged,
speciesColumn = "scientificName")
table(beesRaw_out$.invalidName, useNA = "always")
</code></pre>

<hr>
<h2 id='idMatchR'>Attempt to match database_ids from a prior run</h2><span id='topic+idMatchR'></span>

<h3>Description</h3>

<p>This function attempts to match database_ids from a prior bdc or BeeBDC run in order to keep
this column somewhat consistent between iterations. However, not all records contain sufficient
information for this to work flawlessly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>idMatchR(
  currentData = NULL,
  priorData = NULL,
  matchBy = NULL,
  completeness_cols = NULL,
  excludeDataset = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="idMatchR_+3A_currentdata">currentData</code></td>
<td>
<p>A data frame or tibble. The NEW occurrence records as input.</p>
</td></tr>
<tr><td><code id="idMatchR_+3A_priordata">priorData</code></td>
<td>
<p>A data frame or tibble. The PRIOR occurrence records as input.</p>
</td></tr>
<tr><td><code id="idMatchR_+3A_matchby">matchBy</code></td>
<td>
<p>A list of character vectors Should contain the columns to iteratively compare.</p>
</td></tr>
<tr><td><code id="idMatchR_+3A_completeness_cols">completeness_cols</code></td>
<td>
<p>A character vector. The columns to check for completeness, arrange,
and assign the relevant prior database_id.</p>
</td></tr>
<tr><td><code id="idMatchR_+3A_excludedataset">excludeDataset</code></td>
<td>
<p>A character vector. The dataSources that are to be excluded from data
matching. These should be static dataSources from minor providers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input data frame returned with an updated database_id column that shows the
database_ids as in priorData where they could be matched. Additionally, a columnd called
idContinuity is returned where TRUE indicates a match to a prior database_id and FALSE
indicates that a new database_id was assigned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get the example data
data("beesRaw", package = "BeeBDC")
# Which datasets are static and should be excluded from matching?
excludeDataset &lt;- c("BMin", "BMont", "CAES", "EaCO", "Ecd", "EcoS",
                    "Gai", "KP", "EPEL", "USGS", "FSCA", "SMC", "Bal", "Lic", "Arm", "BBD", 
                    "MEPB")
  # Match the data to itself just as an example of running the code.
beesRaw_out &lt;- idMatchR(
  currentData = beesRaw,
  priorData = beesRaw,
  # First matches will be given preference over later ones
  matchBy = dplyr::lst(c("gbifID"),
                        c("catalogNumber", "institutionCode", "dataSource"),
                        c("occurrenceID", "dataSource"),
                        c("recordId", "dataSource"),
                        c("id"),
                        c("catalogNumber", "institutionCode")),
  # You can exclude datasets from prior by matching their prefixs - before first underscore:
  excludeDataset = excludeDataset)
</code></pre>

<hr>
<h2 id='importOccurrences'>Imports the most-recent repoMerge data</h2><span id='topic+importOccurrences'></span>

<h3>Description</h3>

<p>Looks for and imports the most-recent version of the occurrence data created by the <code><a href="#topic+repoMerge">repoMerge()</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importOccurrences(path = path, fileName = "^BeeData_")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importOccurrences_+3A_path">path</code></td>
<td>
<p>A directory as a character. The directory to recursively look in for the above data.</p>
</td></tr>
<tr><td><code id="importOccurrences_+3A_filename">fileName</code></td>
<td>
<p>Character. A String of text to look for the most-recent dataset.
Default = &quot;^BeeData_&quot;. Find faults by modifying <code><a href="#topic+fileFinder">fileFinder()</a></code>
and logic-checking the file that's found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with a data frame of merged occurrence records, &quot;Data_WebDL&quot;, and a list of EML
files contained in &quot;eml_files&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DataImp &lt;- importOccurrences(path = DataPath)

## End(Not run)
</code></pre>

<hr>
<h2 id='interactiveMapR'>Creates interactive html maps for species</h2><span id='topic+interactiveMapR'></span>

<h3>Description</h3>

<p>Uses the occurrence data (preferably uncleaned) and outputs interactive .html maps that can be opened
in your browser to a specific directory. The maps can highlight if an occurrence has passed all filtering
(.summary == TRUE) or failed at least one filter (.summary == FALSE). This can be modified by first running
<code><a href="#topic+summaryFun">summaryFun()</a></code> to set the columns that you want to be highlighted. It can also highlight occurrences
flagged as expert-identified or country outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interactiveMapR(
  data = NULL,
  outPath = NULL,
  lon = "decimalLongitude",
  lat = "decimalLatitude",
  speciesColumn = "scientificName",
  speciesList = NULL,
  countryList = NULL,
  jitterValue = NULL,
  onlySummary = TRUE,
  overWrite = TRUE,
  TrueAlwaysTop = FALSE,
  excludeApis_mellifera = TRUE,
  pointColours = c("blue", "darkred", "#ff7f00", "black")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interactiveMapR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records to use as input.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_outpath">outPath</code></td>
<td>
<p>A directory as character. Directory where to save output maps.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_lon">lon</code></td>
<td>
<p>Character. The name of the longitude column. Default = &quot;decimalLongitude&quot;.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_lat">lat</code></td>
<td>
<p>Character. The name of the latitude column. Default = &quot;decimalLatitude&quot;.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_speciescolumn">speciesColumn</code></td>
<td>
<p>Character. The name of the column containing species names (or another factor)
to build individual maps from. Default = &quot;scientificName&quot;.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_specieslist">speciesList</code></td>
<td>
<p>A character vector. Should contain species names as they appear in the
speciesColumn to make maps of. User can also specify &quot;ALL&quot; in order to make maps of all
species present in the data. Hence, a user may first filter their data and then use &quot;ALL&quot;.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_countrylist">countryList</code></td>
<td>
<p>A character vector. Country names to map, or NULL for to map ALL countries.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_jittervalue">jitterValue</code></td>
<td>
<p>Numeric. The amount, in decimal degrees, to jitter the map points by - this
is important for separating stacked points with the same coordinates.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_onlysummary">onlySummary</code></td>
<td>
<p>Logical. If TRUE, the function will not look to plot country or
expert-identified outliers in different colours.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_overwrite">overWrite</code></td>
<td>
<p>Logical. If TRUE, the function will overwrite existing files in the provided
directory that have the same name.
Default = TRUE.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_truealwaystop">TrueAlwaysTop</code></td>
<td>
<p>If TRUE, the quality (TRUE) points will always be displayed on top of other points.
If FALSE, then whichever layer was turned on most-recently will be displayed on top.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_excludeapis_mellifera">excludeApis_mellifera</code></td>
<td>
<p>Logical. If TRUE, will not map records for Apis mellifera. Note: in most cases
A. mellifera has too many points, and the resulting map will take a long time to make and be difficult to open.
Default = TRUE.</p>
</td></tr>
<tr><td><code id="interactiveMapR_+3A_pointcolours">pointColours</code></td>
<td>
<p>A character vector of colours. In order provide colour for TRUE, FALSE, countryOutlier, and customOutlier.
Default = c(&quot;blue&quot;, &quot;darkred&quot;,&quot;#ff7f00&quot;, &quot;black&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Exports .html interactive maps of bee occurrences to the specified directory.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>OutPath_Figures &lt;- tempdir()

interactiveMapR(
# occurrence data - start with entire dataset, filter down to these species
data = BeeBDC::bees3sp, # %&gt;%
  # Select only those species in the 100 randomly chosen
  # dplyr::filter(scientificName %in% beeData_interactive$scientificName),
  # Select only one species to map
  # dplyr::filter(scientificName %in% "Agapostemon sericeus (Forster, 1771)"),
# Directory where to save files
outPath = paste0(OutPath_Figures, "/interactiveMaps_TEST"),
# lat long columns
lon = "decimalLongitude",
lat = "decimalLatitude",
# Occurrence dataset column with species names
speciesColumn = "scientificName",
# Which species to map - a character vector of names or "ALL"
# Note: "ALL" is defined AFTER filtering for country
speciesList = "ALL",
# studyArea
countryList = NULL, 
# Point jitter to see stacked points - jitters an amount in decimal degrees
jitterValue = 0.01,
# If TRUE, it will only map the .summary column. Otherwise, it will map .summary
# which will be over-written by countryOutliers and manualOutliers
onlySummary = TRUE,
excludeApis_mellifera = TRUE,
overWrite = TRUE,
  # Colours for points which are flagged as TRUE, FALSE, countryOutlier, and customOutlier
pointColours = c("blue", "darkred","#ff7f00", "black")
)
</code></pre>

<hr>
<h2 id='jbd_CfC_chunker'>Get country names from coordinates</h2><span id='topic+jbd_CfC_chunker'></span>

<h3>Description</h3>

<p>Because the <code><a href="bdc.html#topic+bdc_country_from_coordinates">bdc::bdc_country_from_coordinates()</a></code> function is very RAM-intensive, this wrapper
allows a user to specify chunk-sizes and only analyse a small portion of the occurrence data at a
time. The prefix jbd_ is used to highlight the difference between this function and the original
<code><a href="bdc.html#topic+bdc_country_from_coordinates">bdc::bdc_country_from_coordinates()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbd_CfC_chunker(
  data = NULL,
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  country = "country",
  stepSize = 1e+06,
  chunkStart = 1,
  scale = "medium",
  path = tempdir(),
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbd_CfC_chunker_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records to use as input.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_lat">lat</code></td>
<td>
<p>Character. The name of the column to use as latitude. Default = &quot;decimalLatitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_lon">lon</code></td>
<td>
<p>Character. The name of the column to use as longitude. Default = &quot;decimalLongitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_country">country</code></td>
<td>
<p>Character. The name of the column containing country names. Default = &quot;country.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_stepsize">stepSize</code></td>
<td>
<p>Numeric. The number of occurrences to process in each chunk. Default = 1000000.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_chunkstart">chunkStart</code></td>
<td>
<p>Numeric. The chunk number to start from. This can be &gt; 1 when you need to
restart the function from a certain chunk. For example, can be used if R failed unexpectedly.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_scale">scale</code></td>
<td>
<p>Passed to rnaturalearth's ne_countries().
Scale of map to return, one of 110, 50, 10 or 'small', 'medium', 'large'. Default = &quot;large&quot;.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_path">path</code></td>
<td>
<p>Character. The directory path to a folder in which to save the running countrylist
csv file.</p>
</td></tr>
<tr><td><code id="jbd_CfC_chunker_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory.
Default = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing database_ids and a country column
that needs to be re-merged with the data input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("dplyr")
data(beesFlagged)
HomePath = tempdir()
# Tibble of common issues in country names and their replacements
commonProblems &lt;- dplyr::tibble(problem = c('U.S.A.', 'US','USA','usa','UNITED STATES',
'United States','U.S.A','MX','CA','Bras.','Braz.','Brasil','CNMI','USA TERRITORY: PUERTO RICO'),
                                 fix = c('United States of America','United States of America',
                                 'United States of America','United States of America',
                                 'United States of America','United States of America',
                                 'United States of America','Mexico','Canada','Brazil','Brazil',
                                 'Brazil','Northern Mariana Islands','Puerto Rico'))
                                 
beesFlagged &lt;- beesFlagged %&gt;%
      # Replace a name to test
   dplyr::mutate(country = stringr::str_replace_all(country, "Brazil", "Brasil"))

beesFlagged_out &lt;- countryNameCleanR(
  data = beesFlagged,
  commonProblems = commonProblems)

suppressWarnings(
  countryOutput &lt;- jbd_CfC_chunker(data = beesFlagged_out,
                                   lat = "decimalLatitude",
                                   lon = "decimalLongitude",
                                   country = "country",
                                   # How many rows to process at a time
                                   stepSize = 1000000,
                                   # Start row
                                   chunkStart = 1,
                                   path = HomePath,
                                   scale = "medium"),
  classes = "warning")


# Left join these datasets
beesFlagged_out &lt;- left_join(beesFlagged_out, countryOutput, by = "database_id")  %&gt;% 
  # merge the two country name columns into the "country" column
  dplyr::mutate(country = dplyr::coalesce(country.x, country.y)) %&gt;%
  # remove the now redundant country columns 
  dplyr::select(!c(country.x, country.y)) %&gt;%
  # put the column back 
  dplyr::relocate(country) %&gt;% 
  # Remove duplicates if they arose!
  dplyr::distinct()

# Remove illegal characters
beesFlagged_out$country &lt;- beesFlagged_out$country %&gt;%
  stringr::str_replace(., pattern = paste("\\[", "\\]", "\\?",
                                          sep=  "|"), replacement = "")
</code></pre>

<hr>
<h2 id='jbd_coordCountryInconsistent'>Flags coordinates that are inconsistent with the stated country name</h2><span id='topic+jbd_coordCountryInconsistent'></span>

<h3>Description</h3>

<p>Compares stated country name in an occurrence record with record's coordinates using
rnaturalearth data. The prefix, jbd_ is meant
to distinguish this function from the original <code><a href="bdc.html#topic+bdc_coordinates_country_inconsistent">bdc::bdc_coordinates_country_inconsistent()</a></code>.
This functions will preferably use the countryCode and country_suggested columns
generated by <code>bdc::bdc_country_standardized()</code>; please run it on your dataset prior to running
this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbd_coordCountryInconsistent(
  data = NULL,
  lon = "decimalLongitude",
  lat = "decimalLatitude",
  scale = 50,
  pointBuffer = 0.01,
  stepSize = 1e+06,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_lon">lon</code></td>
<td>
<p>Character. The name of the column to use as longitude. Default = &quot;decimalLongitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_lat">lat</code></td>
<td>
<p>Character. The name of the column to use as latitude. Default = &quot;decimalLatitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_scale">scale</code></td>
<td>
<p>Numeric or character. To be passed to <code><a href="rnaturalearth.html#topic+ne_countries">rnaturalearth::ne_countries()</a></code>'s scale.
Scale of map to return, one of 110, 50, 10 or &quot;small&quot;, &quot;medium&quot;, &quot;large&quot;.
Smaller values return higher-resolution maps.</p>
</td></tr>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_pointbuffer">pointBuffer</code></td>
<td>
<p>Numeric. Amount to buffer points, in decimal degrees. If the point is outside
of a country, but within this point buffer, it will not be flagged. Default = 0.01.</p>
</td></tr>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_stepsize">stepSize</code></td>
<td>
<p>Numeric. The number of occurrences to process in each chunk. Default = 1000000.</p>
</td></tr>
<tr><td><code id="jbd_coordCountryInconsistent_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the st_intersects function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory.
Default = 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input occurrence data with a new column, .coordinates_country_inconsistent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
beesRaw_out &lt;- jbd_coordCountryInconsistent(
  data = BeeBDC::beesRaw,
  lon = "decimalLongitude",
  lat = "decimalLatitude",
  scale = 50,
  pointBuffer = 0.01)
</code></pre>

<hr>
<h2 id='jbd_coordinates_precision'>Flags coordinates for imprecision</h2><span id='topic+jbd_coordinates_precision'></span>

<h3>Description</h3>

<p>This function flags occurrences where BOTH latitude and longitude values are rounded. This
contrasts with the original function, bdc::bdc_coordinates_precision() that will flag
occurrences where only one of latitude OR longitude are rounded. The BeeBDC approach saves
occurrences that may have had terminal zeros rounded in one coordinate column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbd_coordinates_precision(
  data,
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  ndec = NULL,
  quieter = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbd_coordinates_precision_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_precision_+3A_lat">lat</code></td>
<td>
<p>Character. The name of the column to use as latitude. Default = &quot;decimalLatitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_precision_+3A_lon">lon</code></td>
<td>
<p>Character. The name of the column to use as longitude. Default = &quot;decimalLongitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_precision_+3A_ndec">ndec</code></td>
<td>
<p>Numeric. The number of decimal places to flag in decimal degrees. For example,
argument value of 2 would flag occurrences with nothing in the hundredths place (0.0x).</p>
</td></tr>
<tr><td><code id="jbd_coordinates_precision_+3A_quieter">quieter</code></td>
<td>
<p>Logical. If TRUE, the functino will run a little quieter. Default = FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the input data frame with a new column, .rou, where FALSE indicates occurrences
that failed the test.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>beesRaw_out &lt;- jbd_coordinates_precision(
  data = BeeBDC::beesRaw,
  lon = "decimalLongitude",
  lat = "decimalLatitude",
    # number of decimals to be tested
  ndec = 2
)
table(beesRaw_out$.rou, useNA = "always")
</code></pre>

<hr>
<h2 id='jbd_coordinates_transposed'>Identify transposed geographic coordinates</h2><span id='topic+jbd_coordinates_transposed'></span>

<h3>Description</h3>

<p>This function flags and corrects records when latitude and longitude appear
to be transposed.
This function will preferably use the countryCode column generated by
<code><a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbd_coordinates_transposed(
  data,
  idcol = "database_id",
  sci_names = "scientificName",
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  country = "country",
  countryCode = "countryCode",
  border_buffer = 0.2,
  save_outputs = FALSE,
  fileName = NULL,
  scale = "large",
  path = NULL,
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbd_coordinates_transposed_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Containing a unique identifier for each record,
geographical coordinates, and country names. Coordinates must be expressed
in decimal degrees and WGS84.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_idcol">idcol</code></td>
<td>
<p>A character string. The column name with a unique record identifier.
Default = &quot;database_id&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_sci_names">sci_names</code></td>
<td>
<p>A character string. The column name with species' scientific
names. Default = &quot;scientificName&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_lat">lat</code></td>
<td>
<p>A character string. The column name with latitudes. Coordinates must
be expressed in decimal degrees and WGS84. Default = &quot;decimalLatitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_lon">lon</code></td>
<td>
<p>A character string. The column name with longitudes. Coordinates must be
expressed in decimal degrees and WGS84. Default = &quot;decimalLongitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_country">country</code></td>
<td>
<p>A character string. The column name with the country
assignment of each occurrence record. Default = &quot;country&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_countrycode">countryCode</code></td>
<td>
<p>A character string. The column name containing an ISO-2 country code for
each record.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_border_buffer">border_buffer</code></td>
<td>
<p>Numeric. Must have value greater than or equal to 0.
A distance in decimal degrees used to
created a buffer around each country. Records within a given country and at
a specified distance from the border will be not be corrected.
Default = 0.2 (~22 km at the equator).</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_save_outputs">save_outputs</code></td>
<td>
<p>Logical. Indicates if a table containing transposed coordinates should be
saved for further inspection. Default = FALSE.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_filename">fileName</code></td>
<td>
<p>A character string. The out file's name.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_scale">scale</code></td>
<td>
<p>Passed to rnaturalearth's ne_countries().
Scale of map to return, one of 110, 50, 10 or 'small', 'medium', 'large'. Default = &quot;large&quot;.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_path">path</code></td>
<td>
<p>A character string. A path as a character vector for where to create the directories
and save the figures. If
no path is provided (the default), the directories will be created using <code><a href="here.html#topic+here">here::here()</a></code>.</p>
</td></tr>
<tr><td><code id="jbd_coordinates_transposed_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the jbd_correct_coordinates function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory.
Default = 1.#'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This test identifies transposed coordinates based on mismatches between the
country provided for a record and the record's latitude and longitude coordinates. Transposed
coordinates often fall outside of the indicated country (i.e., in other
countries or in the sea). Different coordinate transformations are
performed to correct country/coordinates mismatches. Importantly, verbatim
coordinates are replaced by the corrected ones in the returned database. A
database containing verbatim and corrected coordinates is created in
&quot;Output/Check/01_coordinates_transposed.csv&quot; if save_outputs == TRUE. The
columns &quot;country&quot; and &quot;countryCode&quot; can be retrieved by using the function
<a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized</a>.
</p>


<h3>Value</h3>

<p>A tibble containing the column &quot;coordinates_transposed&quot; which indicates if
verbatim coordinates were not transposed (TRUE). Otherwise
records are flagged as (FALSE) and, in this case, verbatim coordinates are
replaced by corrected coordinates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
database_id &lt;- c(1, 2, 3, 4)
scientificName &lt;- c(
  "Rhinella major", "Scinax ruber",
  "Siparuna guianensis", "Psychotria vellosiana"
)
decimalLatitude &lt;- c(63.43333, -14.43333, -41.90000, -46.69778)
decimalLongitude &lt;- c(-17.90000, -67.91667, -13.25000, -13.82444)
country &lt;- c("BOLIVIA", "bolivia", "Brasil", "Brazil")

x &lt;- data.frame(
  database_id, scientificName, decimalLatitude,
  decimalLongitude, country
)

# Get country codes
x &lt;- bdc::bdc_country_standardized(data = x, country = "country")

jbd_coordinates_transposed(
  data = x,
  idcol = "database_id",
  sci_names = "scientificName",
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  country = "country_suggested",
  countryCode = "countryCode",
  border_buffer = 0.2,
  save_outputs = FALSE,
  scale = "medium"
) 


</code></pre>

<hr>
<h2 id='jbd_create_figures'>Create figures reporting the results of the bdc/BeeBDC packages</h2><span id='topic+jbd_create_figures'></span>

<h3>Description</h3>

<p>Creates figures (i.e., bar plots, maps, and histograms) reporting the results
of data quality tests implemented the bdc and BeeBDC packages. Works like <code><a href="bdc.html#topic+bdc_create_figures">bdc::bdc_create_figures()</a></code>,
but it allows the user to specify a save path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbd_create_figures(
  data,
  path = OutPath_Figures,
  database_id = "database_id",
  workflow_step = NULL,
  save_figures = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbd_create_figures_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Needs to contain the results of data quality tests; that
is, columns starting with &quot;.&quot;.</p>
</td></tr>
<tr><td><code id="jbd_create_figures_+3A_path">path</code></td>
<td>
<p>A character directory. The path to a directory in which to save the figures.
Default = OutPath_Figures.</p>
</td></tr>
<tr><td><code id="jbd_create_figures_+3A_database_id">database_id</code></td>
<td>
<p>A character string. The column name with a unique record
identifier. Default = &quot;database_id&quot;.</p>
</td></tr>
<tr><td><code id="jbd_create_figures_+3A_workflow_step">workflow_step</code></td>
<td>
<p>A character string. Name of the workflow step. Options
available are &quot;prefilter&quot;, &quot;space&quot;, and &quot;time&quot;.</p>
</td></tr>
<tr><td><code id="jbd_create_figures_+3A_save_figures">save_figures</code></td>
<td>
<p>Logical. Indicates if the figures should be saved for further inspection or
use. Default = FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates figures based on the results of data quality
tests. A pre-defined list of test names is used for creating
figures depending on the name of the workflow step informed. Figures are
saved in &quot;Output/Figures&quot; if save_figures = TRUE.
</p>


<h3>Value</h3>

<p>List containing figures showing the results of data quality tests
implemented in one module of bdc/BeeBDC. When save_figures = TRUE, figures are
also saved locally in a .png format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
database_id &lt;- c("GBIF_01", "GBIF_02", "GBIF_03", "FISH_04", "FISH_05")
lat &lt;- c(-19.93580, -13.01667, -22.34161, -6.75000, -15.15806)
lon &lt;- c(-40.60030, -39.60000, -49.61017, -35.63330, -39.52861)
.scientificName_emptys &lt;- c(TRUE, TRUE, TRUE, FALSE, FALSE)
.coordinates_empty &lt;- c(TRUE, TRUE, TRUE, TRUE, TRUE)
.invalid_basis_of_records &lt;- c(TRUE, FALSE, TRUE, FALSE, TRUE)
.summary &lt;- c(TRUE, FALSE, TRUE, FALSE, FALSE)

x &lt;- data.frame(
  database_id,
  lat,
  lon,
  .scientificName_emptys,
  .coordinates_empty,
  .invalid_basis_of_records,
  .summary
)

figures &lt;- 
jbd_create_figures(
  data = x, 
  database_id = "database_id",
  workflow_step = "prefilter",
  save_figures = FALSE
)

</code></pre>

<hr>
<h2 id='jbd_Ctrans_chunker'>Wraps jbd_coordinates_transposed to identify  and fix transposed occurrences</h2><span id='topic+jbd_Ctrans_chunker'></span>

<h3>Description</h3>

<p>Because the <code><a href="#topic+jbd_coordinates_transposed">jbd_coordinates_transposed()</a></code> function is very RAM-intensive, this wrapper
allows a user to specify chunk-sizes and only analyse a small portion of the occurrence data at a
time. The prefix jbd_ is used to highlight the difference between this function and the original
<code><a href="bdc.html#topic+bdc_coordinates_transposed">bdc::bdc_coordinates_transposed()</a></code>.
This function will preferably use the countryCode column generated by
<code><a href="bdc.html#topic+bdc_country_standardized">bdc::bdc_country_standardized()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jbd_Ctrans_chunker(
  data = NULL,
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  idcol = "databse_id",
  country = "country_suggested",
  countryCode = "countryCode",
  sci_names = "scientificName",
  border_buffer = 0.2,
  save_outputs = TRUE,
  stepSize = 1e+06,
  chunkStart = 1,
  progressiveSave = TRUE,
  path = tempdir(),
  append = TRUE,
  scale = "large",
  mc.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jbd_Ctrans_chunker_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_lat">lat</code></td>
<td>
<p>Character. The column with latitude in decimal degrees. Default = &quot;decimalLatitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_lon">lon</code></td>
<td>
<p>Character. The column with longitude in decimal degrees. Default = &quot;decimalLongitude&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_idcol">idcol</code></td>
<td>
<p>Character. The column name with a unique record identifier. Default = &quot;database_id&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_country">country</code></td>
<td>
<p>Character. The name of the column containing country names. Default = &quot;country&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_countrycode">countryCode</code></td>
<td>
<p>Character. Identifies the column containing ISO-2 country codes
Default = &quot;countryCode&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_sci_names">sci_names</code></td>
<td>
<p>Character. The column containing scientific names. Default = &quot;scientificName&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_border_buffer">border_buffer</code></td>
<td>
<p>Numeric. The buffer, in decimal degrees, around points to help match them
to countries. Default = 0.2 (~22 km at equator).</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_save_outputs">save_outputs</code></td>
<td>
<p>Logical. If TRUE, transposed occurrences will be saved to their own file.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_stepsize">stepSize</code></td>
<td>
<p>Numeric. The number of occurrences to process in each chunk. Default = 1000000.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_chunkstart">chunkStart</code></td>
<td>
<p>Numeric. The chunk number to start from. This can be &gt; 1 when you need to restart
the function from a certain chunk; for example if R failed unexpectedly.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_progressivesave">progressiveSave</code></td>
<td>
<p>Logical. If TRUE then the country output list will be saved between
each iteration so that <code>append</code> can be used if the function is stopped part way through.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_path">path</code></td>
<td>
<p>Character. The path to a file in which to save the 01_coordinates_transposed_
output.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_append">append</code></td>
<td>
<p>Logical. If TRUE, the function will look to append an existing file.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_scale">scale</code></td>
<td>
<p>Passed to rnaturalearth's ne_countries().
Scale of map to return, one of 110, 50, 10 or 'small', 'medium', 'large'. Default = &quot;large&quot;.</p>
</td></tr>
<tr><td><code id="jbd_Ctrans_chunker_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Numeric. If &gt; 1, the jbd_correct_coordinates function will run in parallel
using mclapply using the number of cores specified. If = 1 then it will be run using a serial
loop. NOTE: Windows machines must use a value of 1 (see ?parallel::mclapply). Additionally,
be aware that each thread can use large chunks of memory.
Default = 1.#'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the input data frame with a new column, coordinates_transposed, where FALSE = columns
that had coordinates transposed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
  # Import and prepare the data
data(beesFlagged)
beesFlagged &lt;- beesFlagged %&gt;% dplyr::select(!c(.val, .sea)) %&gt;%
  # Cut down the dataset to un example quicker
dplyr::filter(dplyr::row_number() %in% 1:20)
  # Run the function
beesFlagged_out &lt;- jbd_Ctrans_chunker(
# bdc_coordinates_transposed inputs
data = beesFlagged,
idcol = "database_id",
lat = "decimalLatitude",
lon = "decimalLongitude",
country = "country_suggested",
countryCode = "countryCode",
# in decimal degrees (~22 km at the equator)
border_buffer = 1, 
save_outputs = FALSE,
sci_names = "scientificName",
# chunker inputs
# How many rows to process at a time
stepSize = 1000000,  
# Start row
chunkStart = 1,  
# Progressively save the output between each iteration?
progressiveSave = FALSE,
path = tempdir(),
# If FALSE it may overwrite existing dataset
append = FALSE,
  # Users should select scale = "large" as it is more thoroughly tested
scale = "medium",
mc.cores = 1
) 
table(beesFlagged_out$coordinates_transposed, useNA = "always")

</code></pre>

<hr>
<h2 id='manualOutlierFindeR'>Finds outliers, and their duplicates, as determined by experts</h2><span id='topic+manualOutlierFindeR'></span>

<h3>Description</h3>

<p>Uses expert-identified outliers with source spreadsheets that may be edited by users. The function
will also use the duplicates file made using <code><a href="#topic+dupeSummary">dupeSummary()</a></code> to identify duplicates of the
expert-identified outliers and flag those as well.
The function will add a flagging column called <code>.expertOutlier</code> where records that are FALSE are
the expert outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manualOutlierFindeR(
  data = NULL,
  DataPath = NULL,
  PaigeOutliersName = "removedBecauseDeterminedOutlier.csv",
  newOutliersName = "All_outliers_ANB.xlsx",
  ColombiaOutliers_all = "All_Colombian_OutlierIDs.csv",
  duplicates = NULL,
  NearTRUE = NULL,
  NearTRUE_threshold = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="manualOutlierFindeR_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_datapath">DataPath</code></td>
<td>
<p>A character path to the directory that contains the outlier spreadsheets.</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_paigeoutliersname">PaigeOutliersName</code></td>
<td>
<p>A character patch. Should lead to outlier spreadsheet from Paige Chesshire (csv file).</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_newoutliersname">newOutliersName</code></td>
<td>
<p>A character path. Should lead to appropriate outlier spreadsheet (xlsx file).</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_colombiaoutliers_all">ColombiaOutliers_all</code></td>
<td>
<p>A character path. Should lead to spreadsheet of bee outliers from Colombia (csv file).</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_duplicates">duplicates</code></td>
<td>
<p>A data frame or tibble. The duplicate file produced by <code><a href="#topic+dupeSummary">dupeSummary()</a></code>.</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_neartrue">NearTRUE</code></td>
<td>
<p>Optional. A character file name to the csv file. If you want to remove expert
outliers that are too close to TRUE points, use the name of the NearTRUE.csv.
Note: This implementation is only basic for now unless there is a greater need in the future.</p>
</td></tr>
<tr><td><code id="manualOutlierFindeR_+3A_neartrue_threshold">NearTRUE_threshold</code></td>
<td>
<p>Numeric. The threshold (in km) for the distance to TRUE points to
keep expert outliers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the data with a new column, <code>.expertOutlier</code> where records that are FALSE are
the expert outliers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Read example data
  data(beesFlagged)
# Read in the most-recent duplicates file as well
if(!exists("duplicates")){
  duplicates &lt;- fileFinder(path = DataPath,
                            fileName = "duplicateRun_") %&gt;%
    readr::read_csv()}
# identify the outliers and get a list of their database_ids
beesFlagged_out &lt;- manualOutlierFindeR(
  data = beesFlagged,
  DataPath = DataPath,
  PaigeOutliersName = "removedBecauseDeterminedOutlier.csv",
  newOutliersName = "^All_outliers_ANB_14March.xlsx",
  ColombiaOutliers_all = "All_Colombian_OutlierIDs.csv",
  duplicates = duplicates)

## End(Not run)

</code></pre>

<hr>
<h2 id='PaigeIntegrater'>Integrate manually-cleaned data from Paige Chesshire</h2><span id='topic+PaigeIntegrater'></span>

<h3>Description</h3>

<p>Replaces publicly available data with data that has been manually cleaned and error-corrected for use in
the paper Chesshire, P. R., Fischer, E. E., Dowdy, N. J., Griswold, T., Hughes, A. C., Orr, M. J., . . . McCabe, L. M. (In Press). Completeness analysis for over 3000 United States bee species identifies persistent data gaps. Ecography.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PaigeIntegrater(db_standardized = NULL, PaigeNAm = NULL, columnStrings = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PaigeIntegrater_+3A_db_standardized">db_standardized</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="PaigeIntegrater_+3A_paigenam">PaigeNAm</code></td>
<td>
<p>A data frame or tibble. The Paige Chesshire dataset.</p>
</td></tr>
<tr><td><code id="PaigeIntegrater_+3A_columnstrings">columnStrings</code></td>
<td>
<p>A list of character vectors. Each vector is a set of columns that will be
used to iteratively match the public dataset against the Paige dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns db_standardized (input occurrence records) with the Paige Chesshire data integrated.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
# set the DataPath to tempdir for this example
DataPath &lt;- tempdir()
# Integrate Paige Chesshire's cleaned dataset.
PaigeNAm &lt;- readr::read_csv(paste(DataPath, "Paige_data", "NorAmer_highQual_only_ALLfamilies.csv",
                                 sep = "/"), col_types = ColTypeR()) %&gt;%
 # Change the column name from Source to dataSource to match the rest of the data.
 dplyr::rename(dataSource = Source) %&gt;%
 # add a NEW database_id column
 dplyr::mutate(
   database_id = paste0("Paige_data_", 1:nrow(.)),
   .before = scientificName)

 # Set up the list of character vectors to iteratively check for matches with public data.
columnList &lt;- list(
 c("decimalLatitude", "decimalLongitude", 
   "recordNumber", "recordedBy", "individualCount", "samplingProtocol",
   "associatedTaxa", "sex", "catalogNumber", "institutionCode", "otherCatalogNumbers",
   "recordId", "occurrenceID", "collectionID"), # Iteration 1
 c("catalogNumber", "institutionCode", "otherCatalogNumbers",
   "recordId", "occurrenceID", "collectionID"), # Iteration 2
 c("decimalLatitude", "decimalLongitude", 
   "recordedBy", "genus", "specificEpithet"), # Iteration 3
 c("id", "decimalLatitude", "decimalLongitude"), # Iteration 4
 c("recordedBy", "genus", "specificEpithet", "locality"), # Iteration 5
 c("recordedBy", "institutionCode", "genus", 
   "specificEpithet","locality"),# Iteration 6
 c("occurrenceID","decimalLatitude", "decimalLongitude"), # Iteration 7
 c("catalogNumber","decimalLatitude", "decimalLongitude"), # Iteration 8
 c("catalogNumber", "locality") # Iteration 9
) 

# Merge Paige's data with downloaded data
db_standardized &lt;- BeeBDC::PaigeIntegrater(
 db_standardized = db_standardized,
 PaigeNAm = PaigeNAm,
 columnStrings = columnList)

## End(Not run)


</code></pre>

<hr>
<h2 id='plotFlagSummary'>Generate a plot summarising flagged data</h2><span id='topic+plotFlagSummary'></span>

<h3>Description</h3>

<p>Creates a compound bar plot that shows the proportion of records that pass or fail each flag (rows)
and for each data source (columns). The function can also optionally return a point map for
a user-specified species when plotMap = TRUE. This function requires that your dataset has been
run through some filtering functions - so that is can display logical columns starting with
&quot;.&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFlagSummary(
  data = NULL,
  flagColours = c("#127852", "#A7002D", "#BDBABB"),
  fileName = NULL,
  outPath = OutPath_Figures,
  width = 15,
  height = 9,
  units = "in",
  dpi = 300,
  bg = "white",
  device = "pdf",
  speciesName = NULL,
  saveFiltered = FALSE,
  filterColumn = ".summary",
  nameColumn = NULL,
  plotMap = FALSE,
  mapAlpha = 0.5,
  xbuffer = c(0, 0),
  ybuffer = c(0, 0),
  ptSize = 1,
  saveTable = FALSE,
  jitterValue = NULL,
  returnPlot = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotFlagSummary_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_flagcolours">flagColours</code></td>
<td>
<p>A character vector. Colours in order of pass (TRUE), fail (FALSE), and NA.
Default = c(&quot;#127852&quot;, &quot;#A7002D&quot;, &quot;#BDBABB&quot;).</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the file to be saved, ending in &quot;.pdf&quot;.
If saving as a different file type, change file type suffix - See <code>device</code>.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_outpath">outPath</code></td>
<td>
<p>A character path. The path to the directory in which the figure will be saved.
Default = OutPath_Figures.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_width">width</code></td>
<td>
<p>Numeric. The width of the output figure in user-defined units Default = 15.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_height">height</code></td>
<td>
<p>Numeric. The height of the output figure in user-defined units Default = 9.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_units">units</code></td>
<td>
<p>Character. The units for the figure width and height passed to <code><a href="ggplot2.html#topic+ggsave">ggplot2::ggsave()</a></code>
(&quot;in&quot;, &quot;cm&quot;, &quot;mm&quot;, or &quot;px&quot;). Default = &quot;in&quot;.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_dpi">dpi</code></td>
<td>
<p>Numeric. Passed to <code><a href="ggplot2.html#topic+ggsave">ggplot2::ggsave()</a></code>. Plot resolution. Also accepts a string input: &quot;retina&quot; (320), &quot;print&quot; (300), or
&quot;screen&quot; (72). Applies only to raster output types. Default = 300.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_bg">bg</code></td>
<td>
<p>Character. Passed to <code><a href="ggplot2.html#topic+ggsave">ggplot2::ggsave()</a></code>. Background colour. If NULL, uses the plot.background fill value from the plot theme.
Default = &quot;white.&quot;</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_device">device</code></td>
<td>
<p>Character. Passed to <code><a href="ggplot2.html#topic+ggsave">ggplot2::ggsave()</a></code>. Device to use. Can either be a device function (e.g. png), or one of &quot;eps&quot;, &quot;ps&quot;, &quot;tex&quot; (pictex), &quot;pdf&quot;, &quot;jpeg&quot;, &quot;tiff&quot;, &quot;png&quot;, &quot;bmp&quot;, &quot;svg&quot; or &quot;wmf&quot; (windows only).
Default = &quot;pdf&quot;. If not using default, change file name suffix in fileName argument.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_speciesname">speciesName</code></td>
<td>
<p>Optional. Character. A species name, as it occurs in the user-input nameColumn.
If provided, the data will be filtered to this species for the plot.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_savefiltered">saveFiltered</code></td>
<td>
<p>Optional. Logical. If TRUE, the filtered data will be saved to the computer
as a .csv file.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_filtercolumn">filterColumn</code></td>
<td>
<p>Optional. The flag column to display on the map. Default = .summary.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_namecolumn">nameColumn</code></td>
<td>
<p>Optional. Character. If speciesName is not NULL, enter the column to look
for the species in. A User might realise that, combined with speciesName, figures can be made for
a variety of factors.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_plotmap">plotMap</code></td>
<td>
<p>Logical. If TRUE, the function will produce a point map. Tested for use with one
species at a time; i.e., with speciesName is not NULL.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_mapalpha">mapAlpha</code></td>
<td>
<p>Optional. Numeric. The opacity for the points on the map.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_xbuffer">xbuffer</code></td>
<td>
<p>Optional. Numeric vector. A buffer in degrees of the amount to increase the
min and max bounds along the
x-axis. This may require some experimentation, keeping in mind
the negative and positive directionality of hemispheres. Default = c(0,0).</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_ybuffer">ybuffer</code></td>
<td>
<p>Optional. Numeric vector. A buffer in degrees of the amount to increase the
min and max bounds along the y-axis. This may require some experimentation, keeping in mind
the negative and positive directionality of hemispheres. Default = c(0,0).</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_ptsize">ptSize</code></td>
<td>
<p>Optional. Numeric. The size of the points as passed to ggplot2. Default = 1.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_savetable">saveTable</code></td>
<td>
<p>Optional. Logical. If TRUE, the function will save the data used to produce the
compound bar plot.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_jittervalue">jitterValue</code></td>
<td>
<p>Optional. Numeric. The value to jitter points by in the map in decimal degrees.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_returnplot">returnPlot</code></td>
<td>
<p>Logical. If TRUE, return the plot to the environment. Default = FALSE.</p>
</td></tr>
<tr><td><code id="plotFlagSummary_+3A_...">...</code></td>
<td>
<p>Optional. Extra variables to be fed into <code><a href="forcats.html#topic+fct_recode">forcats::fct_recode()</a></code> to change names on plot.
For example... 'B. Mont.' = &quot;BMont&quot;, 'B. Minkley' = &quot;BMin&quot;, Ecd = &quot;Ecd&quot;, Gaiarsa = &quot;Gai&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Exports a compound bar plot that summarises all flag columns. Optionally can also return
a point map for a particular species in tandem with the summary plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># import data
data(beesFlagged)
OutPath_Figures &lt;- tempdir()
 # Visualise all flags for each dataSource (simplified to the text before the first underscore)
plotFlagSummary(
  data = beesFlagged,
  # Colours in order of pass (TRUE), fail (FALSE), and NA
  flagColours = c("#127852", "#A7002D", "#BDBABB"),
  fileName = paste0("FlagsPlot_TEST_", Sys.Date(),".pdf"),
  outPath = OutPath_Figures,
  width = 15, height = 9,
  # OPTIONAL:
  #\   #  # Filter to species
  #\   speciesName = "Holcopasites heliopsis",
  #\   # column to look in
  #\   nameColumn = "species",
  #\   # Save the filtered data
  #\   saveFiltered = TRUE,
  #\   # Filter column to display on map
  #\   filterColumn = ".summary",
  #\   plotMap = TRUE,
  #\   # amount to jitter points if desired, e.g. 0.25 or NULL
  #\   jitterValue = NULL,
  #\   # Map opacity value for points between 0 and 1
  #\   mapAlpha = 1,
  # Extra variables can be fed into forcats::fct_recode() to change names on plot
  GBIF = "GBIF", SCAN = "SCAN", iDigBio = "iDigBio", USGS = "USGS", ALA = "ALA", 
  ASP = "ASP", CAES = "CAES", 'B. Mont.' = "BMont", 'B. Minkley' = "BMin", Ecd = "Ecd",
  Gaiarsa = "Gai", EPEL = "EPEL"
)



</code></pre>

<hr>
<h2 id='readr_BeeBDC'>A wrapper for all of the data readr_functions</h2><span id='topic+readr_BeeBDC'></span><span id='topic+readr_EPEL'></span><span id='topic+readr_ASP'></span><span id='topic+readr_BMin'></span><span id='topic+readr_BMont'></span><span id='topic+readr_Ecd'></span><span id='topic+readr_Gai'></span><span id='topic+readr_CAES'></span><span id='topic+readr_KP'></span><span id='topic+readr_EcoS'></span><span id='topic+readr_GeoL'></span><span id='topic+readr_EaCO'></span><span id='topic+readr_MABC'></span><span id='topic+readr_Col'></span><span id='topic+readr_FSCA'></span><span id='topic+readr_SMC'></span><span id='topic+readr_Bal'></span><span id='topic+readr_Lic'></span><span id='topic+readr_Arm'></span><span id='topic+readr_Dor'></span><span id='topic+readr_MEPB'></span><span id='topic+readr_BBD'></span><span id='topic+readr_MPUJ'></span><span id='topic+readr_STRI'></span><span id='topic+readr_PALA'></span><span id='topic+readr_JoLa'></span><span id='topic+readr_VicWam'></span>

<h3>Description</h3>

<p>Read in a variety of data files that are specific to certain smaller data providers.
There is an internal readr function for each dataset and each one of these functions is called
by readr_BeeBDC. While these functions are internal, they are displayed in the documentation of
readr_BeeBDC for clarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readr_BeeBDC(
  dataset = NULL,
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = NULL
)

readr_EPEL(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_ASP(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_BMin(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_BMont(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_Ecd(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_Gai(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_CAES(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = "Sheet1"
)

readr_KP(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_EcoS(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_GeoL(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_EaCO(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_MABC(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = "Hoja1"
)

readr_Col(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = sheet
)

readr_FSCA(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_SMC(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_Bal(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = "animal_data"
)

readr_Lic(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_Arm(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = "Sheet1"
)

readr_Dor(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_MEPB(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = NULL
)

readr_BBD(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_MPUJ(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = sheet
)

readr_STRI(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_PALA(path = NULL, inFile = NULL, outFile = NULL, dataLicense = NULL)

readr_JoLa(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = c("pre-1950", "post-1950")
)

readr_VicWam(
  path = NULL,
  inFile = NULL,
  outFile = NULL,
  dataLicense = NULL,
  sheet = "Combined"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readr_BeeBDC_+3A_dataset">dataset</code></td>
<td>
<p>Character. The name of the dataset to be read in. For example readr_CAES can
be called using &quot;readr_CAES&quot; or &quot;CAES&quot;. This is not caps sensitive.</p>
</td></tr>
<tr><td><code id="readr_BeeBDC_+3A_path">path</code></td>
<td>
<p>A character path. The path to the directory containing the data.</p>
</td></tr>
<tr><td><code id="readr_BeeBDC_+3A_infile">inFile</code></td>
<td>
<p>Character or character path. The name of the file itself (can also be the
remainder of a path including the file name).</p>
</td></tr>
<tr><td><code id="readr_BeeBDC_+3A_outfile">outFile</code></td>
<td>
<p>Character or character path. The name of the Darwin Core format file to be saved.</p>
</td></tr>
<tr><td><code id="readr_BeeBDC_+3A_datalicense">dataLicense</code></td>
<td>
<p>Character. The license to accompany each record in the Darwin Core 'license'
column.</p>
</td></tr>
<tr><td><code id="readr_BeeBDC_+3A_sheet">sheet</code></td>
<td>
<p>A character String. For those datasets read from an .xlsx format, provide the
sheet name.
NOTE: This will be ignored for .csv readr_ functions and required for .xlsx readr_ functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function wraps several internal readr functions. Users may call
readr_BeeBDC and select the dataset name to import a certain dataset. These datasets include:
</p>
<p>Excel (.xlsx) formatted datasets: CAES, MABC, Col, Bal, MEPB, MUPJ, Arm, JoLa, and VicWam.
</p>
<p>CSV (.csv) formatted datasets: EPEL, ASP, BMin, BMont, Ecd, Gai, KP, EcoS, GeoL, EaCo, FSCA, SMC,
Lic, Dor, BBD, STRI, and PALA
</p>
<p>See Dorey et al. 2023 BeeBDC... for further details.
</p>


<h3>Value</h3>

<p>A data frame that is in Darwin Core format.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>readr_EPEL()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_ASP()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_BMin()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_BMont()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Ecd()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Gai()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_CAES()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_KP()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_EcoS()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_GeoL()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_EaCO()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_MABC()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Col()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_FSCA()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_SMC()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Bal()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Lic()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Arm()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_Dor()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_MEPB()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_BBD()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_MPUJ()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_STRI()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_PALA()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_JoLa()</code>: Reads specific data files into Darwin Core format
</p>
</li>
<li> <p><code>readr_VicWam()</code>: Reads specific data files into Darwin Core format
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# An example using a .xlsx file
Arm_Data &lt;- readr_BeeBDC(
    dataset = "Arm",
    path = paste0(tempdir(), "/Additional_Datasets"),
    inFile = "/InputDatasets/Bee database Armando_Final.xlsx",
    outFile = "jbd_Arm_Data.csv",
    sheet = "Sheet1",
    dataLicense = "https://creativecommons.org/licenses/by-nc-sa/4.0/")
    
    
    # An example using a .csv file
EPEL_Data &lt;- readr_BeeBDC(
  dataset = "readr_EPEL",
  path = paste0(tempdir(), "/Additional_Datasets"),
  inFile = "/InputDatasets/bee_data_canada.csv",
  outFile = "jbd_EPEL_data.csv",
  dataLicense = "https://creativecommons.org/licenses/by-nc-sa/4.0/")

## End(Not run)
</code></pre>

<hr>
<h2 id='repoFinder'>Find GBIF, ALA, iDigBio, and SCAN files in a directory</h2><span id='topic+repoFinder'></span>

<h3>Description</h3>

<p>Find GBIF, ALA, iDigBio, and SCAN files in a directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repoFinder(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repoFinder_+3A_path">path</code></td>
<td>
<p>A directory as character. The path within which to recursively look for GBIF, ALA,
iDigBio, and SCAN files.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of directories to each of the above data downloads
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Where DataPath is made by [BeeBDC::dirMaker()]
BeeBDC::repoFinder(path = DataPath)

## End(Not run)
</code></pre>

<hr>
<h2 id='repoMerge'>Import occurrences from GBIF, ALA, iDigBio, and SCAN downloads</h2><span id='topic+repoMerge'></span>

<h3>Description</h3>

<p>Locates data from GBIF, ALA, iDigBio, and SCAN within a directory and reads it in along with its eml
metadata. Please keep the original download folder names and architecture unchanged.
NOTE: This function uses family-level data to identify taxon downloads. If this, or something new,
becomes an issue, please contact James Dorey (the developer) as there are likely to be exceptions
to how files are downloaded. current as of versions 1.0.4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repoMerge(path, save_type, occ_paths)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repoMerge_+3A_path">path</code></td>
<td>
<p>A directory as a character. The directory to recursively look in for the above data.</p>
</td></tr>
<tr><td><code id="repoMerge_+3A_save_type">save_type</code></td>
<td>
<p>Character. The data type to save the resulting file as. Options are:
csv_files&quot; or &quot;R_file&quot;.</p>
</td></tr>
<tr><td><code id="repoMerge_+3A_occ_paths">occ_paths</code></td>
<td>
<p>A list of directories. Preferably produced using <code><a href="#topic+repoFinder">repoFinder()</a></code> the
function asks for a list of paths to the relevant input datasets. You can fault-find errors
in this function by checking the output of <code><a href="#topic+repoFinder">repoFinder()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with a data frame of merged occurrence records, &quot;Data_WebDL&quot;, and a list of eml
files contained in &quot;eml_files&quot;. Also saves these files in the requested format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
DataImp &lt;- repoMerge(path = DataPath, 
# Find data - Many problems can be solved by running [BeeBDC::repoFinder(path = DataPath)]
# And looking for problems
occ_paths = BeeBDC::repoFinder(path = DataPath),
save_type = "R_file")

## End(Not run)
</code></pre>

<hr>
<h2 id='summaryFun'>Create or update the .summary flag column</h2><span id='topic+summaryFun'></span>

<h3>Description</h3>

<p>Using all flag columns (column names starting with &quot;.&quot;), this function either creates or updates
the .summary flag column which is FALSE when ANY of the flag columns are FALSE. Columns can be excluded
and removed after creating the .summary column. Additionally, the occurrence dataset
can be filtered to only those where .summary = TRUE at the end of the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryFun(
  data = NULL,
  dontFilterThese = NULL,
  removeFilterColumns = FALSE,
  filterClean = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryFun_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records to use as input.</p>
</td></tr>
<tr><td><code id="summaryFun_+3A_dontfilterthese">dontFilterThese</code></td>
<td>
<p>A character vector of flag columns to be ignored in the creation or updating
of the .summary column.</p>
</td></tr>
<tr><td><code id="summaryFun_+3A_removefiltercolumns">removeFilterColumns</code></td>
<td>
<p>Logical. If TRUE all columns starting with &quot;.&quot; will be removed in the
output data. This only makes sense to use when filterClean = TRUE. Default = FALSE.</p>
</td></tr>
<tr><td><code id="summaryFun_+3A_filterclean">filterClean</code></td>
<td>
<p>Logical. If TRUE, the data will be filtered to only those occurrence where .summary
= TRUE (i.e., completely clean according to the used flag columns). Default = FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame or tibble of the input data but modified based on the above parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read in example data
data(beesFlagged)

# To only update the .summary column
beesFlagged_out &lt;- summaryFun(
    data = beesFlagged,
    dontFilterThese = c(".gridSummary", ".lonFlag", ".latFlag", ".uncer_terms", ".unLicensed"),
    removeFilterColumns = FALSE,
    filterClean = FALSE)
  # View output
table(beesFlagged_out$.summary, useNA = "always")

# Now filter to only the clean data and remove the flag columns
beesFlagged_out &lt;- summaryFun(
  data = BeeBDC::beesFlagged,
  dontFilterThese = c(".gridSummary", ".lonFlag", ".latFlag", ".uncer_terms", ".unLicensed"),
  removeFilterColumns = TRUE,
  filterClean = TRUE)
# View output
table(beesFlagged_out$.summary, useNA = "always")



</code></pre>

<hr>
<h2 id='summaryMaps'>Create country-level summary maps of species and occurrence numbers</h2><span id='topic+summaryMaps'></span>

<h3>Description</h3>

<p>Builds an output figure that shows the number of species and the number of occurrences per
country. Breaks the data into classes for visualisation. Users may filter data to their taxa
of interest to produce figures of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryMaps(
  data = NULL,
  class_n = 15,
  class_Style = "fisher",
  outPath = NULL,
  fileName = NULL,
  width = 10,
  height = 5,
  dpi = 300,
  returnPlot = FALSE,
  scale = 110,
  pointBuffer = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryMaps_+3A_data">data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_class_n">class_n</code></td>
<td>
<p>Numeric. The number of categories to break the data into.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_class_style">class_Style</code></td>
<td>
<p>Character. The class style passed to <code><a href="classInt.html#topic+classIntervals">classInt::classIntervals()</a></code>. Options are chosen
style: one of &quot;fixed&quot;, &quot;sd&quot;, &quot;equal&quot;, &quot;pretty&quot;, &quot;quantile&quot;, &quot;kmeans&quot;, &quot;hclust&quot;, &quot;bclust&quot;,
&quot;fisher&quot;, &quot;jenks&quot;, &quot;dpih&quot;, &quot;headtails&quot;, or &quot;maximum&quot;. Default = &quot;fisher&quot;</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_outpath">outPath</code></td>
<td>
<p>A character vector the path to the save location for the output figure.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_filename">fileName</code></td>
<td>
<p>A character vector with file name
for the output figure, ending with '.pdf'.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_width">width</code></td>
<td>
<p>Numeric. The width, in inches, of the resulting figure. Default = 10.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_height">height</code></td>
<td>
<p>Numeric. The height, in inches, of the resulting figure. Default = 5.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_dpi">dpi</code></td>
<td>
<p>Numeric. The resolution of the resulting plot. Default = 300.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_returnplot">returnPlot</code></td>
<td>
<p>Logical. If TRUE, return the plot to the environment. Default = FALSE.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_scale">scale</code></td>
<td>
<p>Numeric or character. Passed to rnaturalearth's ne_countries().
Scale of map to return, one of 110, 50, 10 or 'small', 'medium', 'large'. Default = 110.</p>
</td></tr>
<tr><td><code id="summaryMaps_+3A_pointbuffer">pointBuffer</code></td>
<td>
<p>Numeric. Amount to buffer points, in decimal degrees. If the point is outside
of a country, but within this point buffer, it will count towards that country. It's a good idea
to keep this value consistent with the prior flags applied. Default = 0.01.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Saves a figure to the user-specified outpath and name with a global map of bee
occurrence species and count data from the input dataset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read in data
data(beesFlagged)
OutPath_Figures &lt;- tempdir()
# This simple example using the test data has very few classes due to the small amount of input 
# data.
summaryMaps(
data = beesFlagged,
width = 10, height = 10,
class_n = 4,
class_Style = "fisher",
outPath = OutPath_Figures,
fileName = paste0("CountryMaps_fisher_TEST.pdf"),
)


</code></pre>

<hr>
<h2 id='taxadbToBeeBDC'>Import and convert taxadb taxonomies to BeeBDC format</h2><span id='topic+taxadbToBeeBDC'></span>

<h3>Description</h3>

<p>Uses the taxadb R package to download a requested taxonomy and then transforms it into the input
BeeBDC format. This means that any taxonomy in their databases can be used with BeeBDC. You can
also save the output to your computer and to the R environment for immediate use. See
details below for a list of providers or see <code>taxadb::td_create()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taxadbToBeeBDC(
  name = NULL,
  rank = NULL,
  provider = "gbif",
  version = "22.12",
  collect = TRUE,
  ignore_case = TRUE,
  db = NULL,
  removeEmptyNames = TRUE,
  outPath = getwd(),
  fileName = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="taxadbToBeeBDC_+3A_name">name</code></td>
<td>
<p>Character. Taxonomic scientific name (e.g. &quot;Aves&quot;).
As defined by  <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_rank">rank</code></td>
<td>
<p>Character. Taxonomic rank name. (e.g. &quot;class&quot;).
As defined by <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_provider">provider</code></td>
<td>
<p>Character. From which provider should the hierarchy be returned?
Default is 'gbif', which can also be configured using options(default_taxadb_provide = ...&quot;).
See <code>taxadb::td_create()</code> for a list of recognized providers. NOTE: gbif seems to have the most-complete
columns, especially in terms of scientificNameAuthorship, which is important for matching
ambiguous names.
As defined by <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_version">version</code></td>
<td>
<p>Character. Which version of the taxadb provider database should we use? defaults
to latest. See tl_import for details. Default = 22.12.
As defined by <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_collect">collect</code></td>
<td>
<p>Logical. Should we return an in-memory data.frame
(default, usually the most convenient), or a reference to lazy-eval table on disk
(useful for very large tables on which we may first perform subsequent filtering operations.).
Default = TRUE.
As defined by <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_ignore_case">ignore_case</code></td>
<td>
<p>Logical. should we ignore case (capitalization) in matching names?
Can be significantly slower to run. Default = TRUE.
As defined by <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_db">db</code></td>
<td>
<p>a connection to the taxadb database. See details of <code>taxadb::filter_rank()</code>. Default
= Null which should work.
As defined by <code>taxadb::filter_rank()</code>.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_removeemptynames">removeEmptyNames</code></td>
<td>
<p>Logical. If True (default), it will remove entries without an entry
for specificEpithet.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_outpath">outPath</code></td>
<td>
<p>Character. The path to a directory (folder) in which the output should be saved.</p>
</td></tr>
<tr><td><code id="taxadbToBeeBDC_+3A_filename">fileName</code></td>
<td>
<p>Character. The name of the output file, ending in '.csv'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a taxonomy file (to the R environment and to the disk, if a fileName is
provided) as a tibble that can be used with <code>BeeBDC::harmoniseR()</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beesTaxonomy">beesTaxonomy()</a></code> for the bee taxonomy and <code><a href="#topic+harmoniseR">harmoniseR()</a></code> for the
taxon-cleaning function where these taxonomies are implemented.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Run the function using the bee genus Apis as an example...
ApisTaxonomy &lt;- BeeBDC::taxadbToBeeBDC(
  name = "Apis",
  rank = "Genus",
  provider = "gbif",
  version = "22.12",
  removeEmptyNames = TRUE,
  outPath = getwd(),
  fileName = NULL
  )
  
## End(Not run)

</code></pre>

<hr>
<h2 id='USGS_formatter'>Find, import, and format USGS data to Darwin Core</h2><span id='topic+USGS_formatter'></span>

<h3>Description</h3>

<p>The function finds, imports, formats, and creates metadata for the USGS dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>USGS_formatter(path, pubDate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="USGS_formatter_+3A_path">path</code></td>
<td>
<p>A character path to a directory that contains the USGS data, which will be found using
<code><a href="#topic+fileFinder">fileFinder()</a></code>. The function will look for &quot;USGS_DRO_flat&quot;.</p>
</td></tr>
<tr><td><code id="USGS_formatter_+3A_pubdate">pubDate</code></td>
<td>
<p>Character. The publication date of the dataset to update the metadata and citation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the occurrence data, &quot;USGS_data&quot;, and the EML data, &quot;EML_attributes&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
USGS_data &lt;- USGS_formatter(path = DataPath, pubDate = "19-11-2022")

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
