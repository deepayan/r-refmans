<!DOCTYPE html><html><head><title>Help for package diffcor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {diffcor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#diffcor.dep'><p>Fisher's z-Tests of dependent correlations</p></a></li>
<li><a href='#diffcor.one'><p>Fisher's z-test of difference between an empirical and a hypothesized</p>
correlation</a></li>
<li><a href='#diffcor.two'><p>Fisher's z-Tests for differences of correlations in two independent</p>
samples</a></li>
<li><a href='#diffpwr.dep'><p>Monte Carlo Simulation for the correlation difference between dependent</p>
correlations</a></li>
<li><a href='#diffpwr.one'><p>Monte Carlo Simulation for the correlation difference between an expected</p>
and an observed correlation</a></li>
<li><a href='#diffpwr.two'><p>Monte Carlo Simulation for the correlation difference between two</p>
correlations that were observed in two independent samples</a></li>
<li><a href='#visual_mc'><p>Visualization of the simulated parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fisher's z-Tests Concerning Difference of Correlations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3.0), MASS</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-20</td>
</tr>
<tr>
<td>Author:</td>
<td>Christian Blötner</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Christian Blötner &lt;c.bloetner@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Computations of Fisher's z-tests concerning different kinds of correlation differences. Additionally, approaches to estimating statistical power via Monte Carlo simulations are implemented. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-20 17:14:23 UTC; christianblotner</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-21 11:22:54 UTC</td>
</tr>
</table>
<hr>
<h2 id='diffcor.dep'>Fisher's z-Tests of dependent correlations</h2><span id='topic+diffcor.dep'></span>

<h3>Description</h3>

<p>Tests if the correlation between two variables (r12) differs from the
correlation between the first and a third one (r13), given the intercorrelation
of the compared constructs (r23). All correlations are automatically transformed
with the Fisher z-transformation prior to computations. The output provides the
compared correlations, test statistic as z-score, and p-values.</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffcor.dep(r12, r13, r23, n, cor.names = NULL,
alternative = c("one.sided", "two.sided"), digit = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffcor.dep_+3A_r12">r12</code></td>
<td>
<p>Correlation between the criterion with which both competing
variables are correlated and the first of the two competing variables.</p>
</td></tr>
<tr><td><code id="diffcor.dep_+3A_r13">r13</code></td>
<td>
<p>Correlation between the criterion with which both competing
variables are correlated and the second of the two competing variables.</p>
</td></tr>
<tr><td><code id="diffcor.dep_+3A_r23">r23</code></td>
<td>
<p>Intercorrelation between the two competing variables.</p>
</td></tr>
<tr><td><code id="diffcor.dep_+3A_n">n</code></td>
<td>
<p>Sample size in which the observed effect was found</p>
</td></tr>
<tr><td><code id="diffcor.dep_+3A_cor.names">cor.names</code></td>
<td>
<p>OPTIONAL, label for the correlation. DEFAULT is NULL</p>
</td></tr>
<tr><td><code id="diffcor.dep_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying if you wish to test one-sided
or two-sided differences</p>
</td></tr>
<tr><td><code id="diffcor.dep_+3A_digit">digit</code></td>
<td>
<p>Number of digits in the output for all parameters, DEFAULT = 3</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>r12</code></td>
<td>
<p>Correlation between the criterion with which both competing
variables are correlated and the first of the two competing variables.</p>
</td></tr>
<tr><td><code>r13</code></td>
<td>
<p>Correlation between the criterion with which both competing
variables are correlated and the second of the two competing variables.</p>
</td></tr>
<tr><td><code>r23</code></td>
<td>
<p>Intercorrelation between the two competing variables.</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>Test statistic for correlation difference in units of z distribution</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>p value for one- or two-sided testing, depending on alternative =
c(&quot;one.sided&quot;, &quot;two.sided)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral
sciences (2nd ed.). Lawrence Erlbaum.
</p>
<p>Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2015). Statistik und Forschungsmethoden
(4.Auflage) [Statistics and research methods (4th ed.)]. Beltz.
</p>
<p>Steiger, J. H. (1980). Tests for comparing elements of a correlation matrix.
Psychological Bulletin, 87, 245-251.</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffcor.dep(r12 = .76, r13 = .70, r23 = .50, n = 271, digit = 4,
cor.names = NULL, alternative = "two.sided")
</code></pre>

<hr>
<h2 id='diffcor.one'>Fisher's z-test of difference between an empirical and a hypothesized
correlation</h2><span id='topic+diffcor.one'></span>

<h3>Description</h3>

<p>The function tests whether an observed correlation differs from an expected one,
for example, in construct validation. All correlations are automatically
transformed with the Fisher z-transformation prior to computations. The output
provides the compared correlations, a z-score, a p-value, a confidence interval,
and the effect size Cohens q. According to Cohen (1988), q = |.10|, |.30| and
|.50| are considered small, moderate, and large differences, respectively.</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffcor.one(emp.r, hypo.r, n, alpha = .05, cor.names = NULL,
alternative = c("one.sided", "two.sided"), digit = 3)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffcor.one_+3A_emp.r">emp.r</code></td>
<td>
<p>Empirically observed correlation</p>
</td></tr>
<tr><td><code id="diffcor.one_+3A_hypo.r">hypo.r</code></td>
<td>
<p>Hypothesized correlation which shall be tested</p>
</td></tr>
<tr><td><code id="diffcor.one_+3A_n">n</code></td>
<td>
<p>Sample size in which the observed effect was found</p>
</td></tr>
<tr><td><code id="diffcor.one_+3A_alpha">alpha</code></td>
<td>
<p>Likelihood of Type I error, DEFAULT = .05</p>
</td></tr>
<tr><td><code id="diffcor.one_+3A_cor.names">cor.names</code></td>
<td>
<p>OPTIONAL, label for the correlation (e.g., &quot;IQ-performance&quot;).
DEFAULT is NULL</p>
</td></tr>
<tr><td><code id="diffcor.one_+3A_digit">digit</code></td>
<td>
<p>Number of digits in the output for all parameters, DEFAULT = 3</p>
</td></tr>
<tr><td><code id="diffcor.one_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying if you wish to test one-sided
or two-sided differences</p>
</td></tr></table>


<h3>Value</h3>

<table>
<tr><td><code>r_exp</code></td>
<td>
<p>Vector of the expected correlations</p>
</td></tr>
<tr><td><code>r_obs</code></td>
<td>
<p>Vector of the empirically observed correlations</p>
</td></tr>
<tr><td><code>LL</code></td>
<td>
<p>Lower limit of the confidence interval of the empirical correlation,
given the specified alpha level, DEFAULT = 95 percent</p>
</td></tr>
<tr><td><code>UL</code></td>
<td>
<p>Upper limit of the confidence interval of the empirical correlation,
given the specified alpha level, DEFAULT = 95 percent</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>Test statistic for correlation difference in units of z distribution</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>p value for one- or two-sided testing, depending on alternative =
c(&quot;one.sided&quot;, &quot;two.sided)</p>
</td></tr>
<tr><td><code>Cohen_q</code></td>
<td>
<p>Effect size measure for differences of independent correlations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral
sciences (2nd ed.). Lawrence Erlbaum.
</p>
<p>Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2015). Statistik und Forschungsmethoden
(4.Auflage) [Statistics and research methods (4th ed.)]. Beltz.
</p>
<p>Steiger, J. H. (1980). Tests for comparing elements of a correlation matrix.
Psychological Bulletin, 87, 245-251.</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffcor.one(c(.76, .53, -.32), c(.70, .35, -.40),
  c(225, 250, 210),
  cor.names = c("a-b", "c-d", "e-f"), digit = 2, alternative = "one.sided")
</code></pre>

<hr>
<h2 id='diffcor.two'>Fisher's z-Tests for differences of correlations in two independent
samples</h2><span id='topic+diffcor.two'></span>

<h3>Description</h3>

<p>Tests whether the correlation between two variables differs across two
independent studies/samples. The correlations are automatically transformed with
the Fisher z-transformation prior to computations. The output provides the
compared correlations, test statistic as z-score, p-values, confidence intervals
of the empirical correlations, and the effect size Cohens q. According to Cohen
(1988), q = |.10|, |.30| and |.50| are considered small, moderate, and large
differences, respectively.</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffcor.two(r1, r2, n1, n2, alpha = .05, cor.names = NULL,
alternative = c("one.sided", "two.sided"), digit = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffcor.two_+3A_r1">r1</code></td>
<td>
<p>Correlation coefficient in first sample</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_r2">r2</code></td>
<td>
<p>Correlation coefficient in second sample</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_n1">n1</code></td>
<td>
<p>First sample size</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_n2">n2</code></td>
<td>
<p>Second sample size</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_alpha">alpha</code></td>
<td>
<p>Likelihood of Type I error, DEFAULT = .05</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_cor.names">cor.names</code></td>
<td>
<p>OPTIONAL, label for the correlation (e.g., &quot;IQ-performance&quot;).
DEFAULT is NULL</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_digit">digit</code></td>
<td>
<p>Number of digits in the output for all parameters, DEFAULT = 3</p>
</td></tr>
<tr><td><code id="diffcor.two_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying if you wish to test one-sided
or two-sided differences</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>r1</code></td>
<td>
<p>Vector of the empirically observed correlations in the first sample</p>
</td></tr>
<tr><td><code>r2</code></td>
<td>
<p>Vector of the empirically observed correlations in the second sample</p>
</td></tr>
<tr><td><code>LL1</code></td>
<td>
<p>Lower limit of the confidence interval of the first empirical
correlation, given the specified alpha level, DEFAULT = 95 percent</p>
</td></tr>
<tr><td><code>UL1</code></td>
<td>
<p>Upper limit of the confidence interval of the first empirical
correlation, given the specified alpha level, DEFAULT = 95 percent</p>
</td></tr>
<tr><td><code>LL2</code></td>
<td>
<p>Lower limit of the confidence interval of the second empirical
correlation, given the specified alpha level, DEFAULT = 95 percent</p>
</td></tr>
<tr><td><code>UL2</code></td>
<td>
<p>Upper limit of the confidence interval of the second empirical
correlation, given the specified alpha level, DEFAULT = 95 percent</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>Test statistic for correlation difference in units of z distribution</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>p value for one- or two-sided testing, depending on alternative =
c(&quot;one.sided&quot;, &quot;two.sided)</p>
</td></tr>
<tr><td><code>Cohen_q</code></td>
<td>
<p>Effect size measure for differences of independent correlations</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral
sciences (2nd ed.). Lawrence Erlbaum.
</p>
<p>Eid, M., Gollwitzer, M., &amp; Schmitt, M. (2015). Statistik und Forschungsmethoden
(4.Auflage) [Statistics and research methods (4th ed.)]. Beltz.
</p>
<p>Steiger, J. H. (1980). Tests for comparing elements of a correlation matrix.
Psychological Bulletin, 87, 245-251.</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffcor.two(r1 = c(.39, .52, .22),
  r2 = c(.29, .44, .12),
  n1 = c(66, 66, 66), n2 = c(96, 96, 96), alpha = .01,
  cor.names = c("a-b", "c-d", "e-f"), alternative = "one.sided")
</code></pre>

<hr>
<h2 id='diffpwr.dep'>Monte Carlo Simulation for the correlation difference between dependent
correlations</h2><span id='topic+diffpwr.dep'></span>

<h3>Description</h3>

<p>Computation of a Monte Carlo simulation to estimate the statistical power of the
comparison between the correlations of a variable with two competing variables
that are also correlated with each other.</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffpwr.dep(n, r12, r13, r23, alpha = 0.05, n.samples = 1000, seed = 1234)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffpwr.dep_+3A_n">n</code></td>
<td>
<p>Sample size to be tested in the Monte Carlo simulation.</p>
</td></tr>
<tr><td><code id="diffpwr.dep_+3A_r12">r12</code></td>
<td>
<p>Correlation between the criterion with which both competing variables
are correlated and the first of the two competing variables.</p>
</td></tr>
<tr><td><code id="diffpwr.dep_+3A_r13">r13</code></td>
<td>
<p>Correlation between the criterion with which both competing variables
are correlated and the second of the two competing variables.</p>
</td></tr>
<tr><td><code id="diffpwr.dep_+3A_r23">r23</code></td>
<td>
<p>Intercorrelation between the two competing variables.</p>
</td></tr>
<tr><td><code id="diffpwr.dep_+3A_alpha">alpha</code></td>
<td>
<p>Type I error. Default is .05.</p>
</td></tr>
<tr><td><code id="diffpwr.dep_+3A_n.samples">n.samples</code></td>
<td>
<p>Number of samples generated in the Monte Carlo simulation. The
recommended minimum is 1000 iterations, which is also the default.</p>
</td></tr>
<tr><td><code id="diffpwr.dep_+3A_seed">seed</code></td>
<td>
<p>To make the results reproducible, it is recommended to set a random
seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depending on the number of generated samples ('n.samples'), correlation
coefficients of the sizes 'r12', 'r13', and 'r23' are simulated. For each
simulated sample, it is checked whether the correlations r12 and r13 differ,
given the correlation 'r23'. The ratio of simulated z-tests of the correlation
difference tests exceeding the critical z-value, given the intended alpha-level,
equals the achieved statistical power ('n'; see Muthén &amp; Muthén, 2002
&lt;doi:10.1207/S15328007SEM0904_8&gt;; Robert &amp; Casella, 2010
&lt;doi:10.1007/978-1-4419-1576-4&gt;, for overviews of the Monte Carlo method).</p>


<h3>Value</h3>

<table>
<tr><td><code>r12</code></td>
<td>
<p>Correlation between the criterion with which both competing variables
are correlated and the first of the two competing variables.</p>
</td></tr>
<tr><td><code>cov12</code></td>
<td>
<p>Coverage. Indicates the ratio of simulated confidence intervals
including the assumed effect size r12.</p>
</td></tr>
<tr><td><code>bias12</code></td>
<td>
<p>Average relative deviation of the simulated correlations r12 from
the intended one.</p>
</td></tr>
<tr><td><code>r13</code></td>
<td>
<p>Correlation between the criterion with which both competing variables
are correlated and the second of the two competing variables.</p>
</td></tr>
<tr><td><code>cov13</code></td>
<td>
<p>Coverage. Indicates the ratio of simulated confidence intervals
including the assumed effect size r13.</p>
</td></tr>
<tr><td><code>bias13</code></td>
<td>
<p>Average relative deviation of the simulated correlations r13 from
the intended one.</p>
</td></tr>
<tr><td><code>r23</code></td>
<td>
<p>Intercorrelation between the two competing variables.</p>
</td></tr>
<tr><td><code>cov23</code></td>
<td>
<p>Coverage. Indicates the ratio of simulated confidence intervals
including the assumed effect size r23.</p>
</td></tr>
<tr><td><code>bias23</code></td>
<td>
<p>Average relative deviation of the simulated correlations r23 from
the intended one.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size to be tested in the Monte Carlo simulation.</p>
</td></tr>
<tr><td><code>pwr</code></td>
<td>
<p>Statistical power as the ratio of simulated difference tests that
yielded significance.</p>
</td></tr>
</table>
<p>Biases should be as close to zero as possible and coverage should be ideally
between .91 and .98 (Muthén &amp; Muthén, 2002 &lt;doi:10.1207/S15328007SEM0904_8&gt;).</p>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Muthén, L. K., &amp; Muthén, B. O. (2002). How to use a Monte Carlo study to decide
on sample size and determine power. Structural Equation Modeling: A
Multidisciplinary Journal, 9(4), 599–620.
https://doi.org/10.1207/S15328007SEM0904_8
</p>
<p>Robert, C., &amp; Casella, G. (2010). Introducing Monte Carlo methods with R.
Springer. https://doi.org/10.1007/978-1-4419-1576-4
</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffpwr.dep(n.samples = 1000, n = 250, r12 = .30, r13 = .45,
                      r23 = .50, alpha = .05, seed = 1234)</code></pre>

<hr>
<h2 id='diffpwr.one'>Monte Carlo Simulation for the correlation difference between an expected
and an observed correlation</h2><span id='topic+diffpwr.one'></span>

<h3>Description</h3>

<p>Computation of a Monte Carlo simulation to estimate the statistical
power the correlation difference between an observed correlation coefficient and
an a fixed value against which the correlation should be tested.</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffpwr.one(n, emp.r, hypo.r, alpha = .05, n.samples = 1000, seed = 1234)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffpwr.one_+3A_n">n</code></td>
<td>
<p>Sample size to be tested in the Monte Carlo simulation.</p>
</td></tr>
<tr><td><code id="diffpwr.one_+3A_emp.r">emp.r</code></td>
<td>
<p>Assumed observed correlation.</p>
</td></tr>
<tr><td><code id="diffpwr.one_+3A_hypo.r">hypo.r</code></td>
<td>
<p>Correlation coefficient against which to test.</p>
</td></tr>
<tr><td><code id="diffpwr.one_+3A_alpha">alpha</code></td>
<td>
<p>Type I error. Default is .05.</p>
</td></tr>
<tr><td><code id="diffpwr.one_+3A_n.samples">n.samples</code></td>
<td>
<p>Number of samples generated in the Monte Carlo simulation. The
recommended minimum is 1000 iterations, which is also the default.</p>
</td></tr>
<tr><td><code id="diffpwr.one_+3A_seed">seed</code></td>
<td>
<p>To make the results reproducible, it is recommended to set a random
seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depending on the number of generated samples ('n.samples'), correlation
coefficients of the size 'emp.r' are simulated. Confidence intervals are built
around the simulated correlation coefficients. For each simulated coefficient,
it is then checked whether the hypothesized correlation cofficient ('hypo.r')
falls within this interval. All correlations are automatically transformed with
the Fisher z-transformation prior to computations. The ratio of simulated
confidence intervals excluding the hypothesized coefficient equals the
statistical power, given the actual sample size ('n'; see Robert &amp; Casella, 2010
&lt;doi:10.1007/978-1-4419-1576-4&gt;, for an overview of the Monte Carlo method).</p>


<h3>Value</h3>

<table>
<tr><td><code>emp.r</code></td>
<td>
<p>Empirically observed correlation.</p>
</td></tr>
<tr><td><code>hypo.r</code></td>
<td>
<p>Correlation against which 'emp.r' should be tested.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The sample size entered in the function.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>Coverage. Indicates the ratio of simulated confidence intervals
including the assumed correlation 'emp.r'. Should be between .91 and .98 (Muthén
&amp; Muthén, 2002 &lt;doi:10.1207/S15328007SEM0904_8&gt;).</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>Average relative difference between the assumed 'emp.r' and the
simulated correlations.</p>
</td></tr>
<tr><td><code>pwr</code></td>
<td>
<p>Statistical power as the ratio of simulated confidence intervals
excluding the hypothesized correlation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Muthén, L. K., &amp; Muthén, B. O. (2002). How to use a Monte Carlo study to decide
on sample size and determine power. Structural Equation Modeling: A
Multidisciplinary Journal, 9(4), 599–620.
https://doi.org/10.1207/S15328007SEM0904_8
</p>
<p>Robert, C., &amp; Casella, G. (2010). Introducing Monte Carlo methods with R.
Springer. https://doi.org/10.1007/978-1-4419-1576-4
</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffpwr.one(n.samples = 1000, n = 500, emp.r = .30, hypo.r = .40, alpha = .05,
            seed = 1234)
</code></pre>

<hr>
<h2 id='diffpwr.two'>Monte Carlo Simulation for the correlation difference between two
correlations that were observed in two independent samples</h2><span id='topic+diffpwr.two'></span>

<h3>Description</h3>

<p>Computation of a Monte Carlo simulation to estimate the statistical
power the correlation difference between the correlation coefficients detected
in two indepdenent samples (e.g., original study and replication study).</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffpwr.two(n1, n2, r1, r2, alpha = .05, n.samples = 1000, seed = 1234)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffpwr.two_+3A_n1">n1</code></td>
<td>
<p>Sample size to be tested in the Monte Carlo simulation for the first
sample.</p>
</td></tr>
<tr><td><code id="diffpwr.two_+3A_n2">n2</code></td>
<td>
<p>Sample size to be tested in the Monte Carlo simulation for the
second sample.</p>
</td></tr>
<tr><td><code id="diffpwr.two_+3A_r1">r1</code></td>
<td>
<p>Correlarion observed in the first sample.</p>
</td></tr>
<tr><td><code id="diffpwr.two_+3A_r2">r2</code></td>
<td>
<p>Correlarion observed in the second sample.</p>
</td></tr>
<tr><td><code id="diffpwr.two_+3A_alpha">alpha</code></td>
<td>
<p>Type I error. Default is .05.</p>
</td></tr>
<tr><td><code id="diffpwr.two_+3A_n.samples">n.samples</code></td>
<td>
<p>Number of samples generated in the Monte Carlo simulation. The
recommended minimum is 1000 iterations, which is also the default.</p>
</td></tr>
<tr><td><code id="diffpwr.two_+3A_seed">seed</code></td>
<td>
<p>To make the results reproducible, a random seed is specified.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depending on the number of generated samples ('n.samples'), correlation
coefficients of the sizes 'r1' and 'r2' are simulated. For each simulated pair
of coefficients, it is then checked whether the confidence intervals (with
given alpha level) of the correlations overlap. All correlations are
automatically transformed with the Fisher z-transformation prior to
computations. The ratio of simulated non-overlapping confidence intervals equals
the statistical power, given the actual sample sizes ('n1' and 'n2'; see Robert
&amp; Casella, 2010 &lt;doi:10.1007/978-1-4419-1576-4&gt;, for an overview of the Monte
Carlo method).</p>


<h3>Value</h3>

<table>
<tr><td><code>r1</code></td>
<td>
<p>Correlation observed in sample 1.</p>
</td></tr>
<tr><td><code>n1</code></td>
<td>
<p>The sample size of the first sample.</p>
</td></tr>
<tr><td><code>cov1</code></td>
<td>
<p>Coverage. Ratio of simulated confidence intervals including r1.</p>
</td></tr>
<tr><td><code>bias1</code></td>
<td>
<p>Average relative difference between r1 and simulated correlations.</p>
</td></tr>
<tr><td><code>r2</code></td>
<td>
<p>Correlation observed in sample 2.</p>
</td></tr>
<tr><td><code>n2</code></td>
<td>
<p>The sample size of the second sample.</p>
</td></tr>
<tr><td><code>cov2</code></td>
<td>
<p>Coverage. Ratio of simulated confidence intervals including r2.</p>
</td></tr>
<tr><td><code>bias2</code></td>
<td>
<p>Average relative difference between r2 and simulated correlations.</p>
</td></tr>
<tr><td><code>pwr</code></td>
<td>
<p>Statistical power as the ratio of simulated non-verlapping confidence
intervals.</p>
</td></tr>
</table>
<p>Biases should be as close to zero as possible and coverage should be ideally
between .91 and .98 (Muthén &amp; Muthén, 2002 &lt;doi:10.1207/S15328007SEM0904_8&gt;).</p>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Muthén, L. K., &amp; Muthén, B. O. (2002). How to use a Monte Carlo study to decide
on sample size and determine power. Structural Equation Modeling: A
Multidisciplinary Journal, 9(4), 599–620.
https://doi.org/10.1207/S15328007SEM0904_8
</p>
<p>Robert, C., &amp; Casella, G. (2010). Introducing Monte Carlo methods with R.
Springer. https://doi.org/10.1007/978-1-4419-1576-4</p>


<h3>Examples</h3>

<pre><code class='language-R'>diffpwr.two(n.samples = 1000, n1 = 1000, n2 = 594, r1 = .45, r2 = .39,
            alpha = .05, seed = 1234)</code></pre>

<hr>
<h2 id='visual_mc'>Visualization of the simulated parameters</h2><span id='topic+visual_mc'></span>

<h3>Description</h3>

<p>To evaluate the quality of the Monte Carlo simulation beyond bias
and coverage parameters (Muthén &amp; Muthén, 2002), it can be helpful to also
inspect the simulated parameters visually. To this end, visual_mc() can be used
to visualize the simulated parameters (including corresponding confidence
intervals) in relation to the targeted parameter.</p>


<h3>Usage</h3>

<pre><code class='language-R'>visual_mc(emp.r, n, alpha = .05, n.intervals = 100, seed = 1234)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visual_mc_+3A_emp.r">emp.r</code></td>
<td>
<p>Targeted correlation coefficient of the simulation.</p>
</td></tr>
<tr><td><code id="visual_mc_+3A_n">n</code></td>
<td>
<p>An integer reflecting the sample size.</p>
</td></tr>
<tr><td><code id="visual_mc_+3A_alpha">alpha</code></td>
<td>
<p>Type I error. Default is .05.</p>
</td></tr>
<tr><td><code id="visual_mc_+3A_n.intervals">n.intervals</code></td>
<td>
<p>An integer reflecting the number of simulated parameters
that should be visualized in the graphic. Default is 100.</p>
</td></tr>
<tr><td><code id="visual_mc_+3A_seed">seed</code></td>
<td>
<p>To make the results reproducible, a random seed is specified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot in which the targeted correlation coefficient is visualized with a dashed
red line and the simulated correlation coefficients are visualized by black
squares and confidence intervals (level depending on the specification made in
the argument 'alpha').</p>


<h3>Author(s)</h3>

<p>Christian Blötner
<a href="mailto:c.bloetner@gmail.com">c.bloetner@gmail.com</a></p>


<h3>References</h3>

<p>Muthén, L. K., &amp; Muthén, B. O. (2002). How to use a Monte Carlo study to decide
on sample size and determine power. Structural Equation Modeling: A
Multidisciplinary Journal, 9(4), 599–620.
https://doi.org/10.1207/S15328007SEM0904_8</p>


<h3>Examples</h3>

<pre><code class='language-R'>visual_mc(emp.r = .25,
                    n = 300,
                    alpha = .05,
                    n.intervals = 100,
                    seed = 1234)</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
