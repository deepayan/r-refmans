<!DOCTYPE html><html><head><title>Help for package mlexperiments</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlexperiments}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#handle_cat_vars'><p>handle_cat_vars</p></a></li>
<li><a href='#LearnerGlm'><p>LearnerGlm R6 class</p></a></li>
<li><a href='#LearnerKnn'><p>LearnerKnn R6 class</p></a></li>
<li><a href='#LearnerLm'><p>LearnerLm R6 class</p></a></li>
<li><a href='#LearnerRpart'><p>LearnerRpart R6 class</p></a></li>
<li><a href='#metric'><p>metric</p></a></li>
<li><a href='#metric_types_helper'><p>metric_types_helper</p></a></li>
<li><a href='#MLBase'><p>Basic R6 Class for the mlexperiments package</p></a></li>
<li><a href='#MLCrossValidation'><p>R6 Class to perform cross-validation experiments</p></a></li>
<li><a href='#MLExperimentsBase'><p>R6 Class on which the experiment classes are built on</p></a></li>
<li><a href='#MLLearnerBase'><p>R6 Class to construct learners</p></a></li>
<li><a href='#MLNestedCV'><p>R6 Class to perform nested cross-validation experiments</p></a></li>
<li><a href='#MLTuneParameters'><p>R6 Class to perform hyperparameter tuning experiments</p></a></li>
<li><a href='#performance'><p>performance</p></a></li>
<li><a href='#predictions'><p>predictions</p></a></li>
<li><a href='#validate_fold_equality'><p>validate_fold_equality</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Machine Learning Experiments</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides 'R6' objects to perform parallelized hyperparameter
    optimization and cross-validation. Hyperparameter optimization can be
    performed with Bayesian optimization (via 'ParBayesianOptimization'
    <a href="https://cran.r-project.org/package=ParBayesianOptimization">https://cran.r-project.org/package=ParBayesianOptimization</a>) and grid
    search. The optimized hyperparameters can be validated using k-fold
    cross-validation. Alternatively, hyperparameter optimization and
    validation can be performed with nested cross-validation. While
    'mlexperiments' focuses on core wrappers for machine learning
    experiments, additional learner algorithms can be supplemented by
    inheriting from the provided learner base class.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kapsner/mlexperiments">https://github.com/kapsner/mlexperiments</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kapsner/mlexperiments/issues">https://github.com/kapsner/mlexperiments/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, kdry, parallel, progress, R6, splitTools, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>class, datasets, lintr, mlbench, mlr3measures,
ParBayesianOptimization, quarto, rpart, testthat (&ge; 3.0.1)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>quarto</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>false</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-05 08:30:02 UTC</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Quarto command line tools
(https://github.com/quarto-dev/quarto-cli).</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-05 08:03:56 UTC; user</td>
</tr>
<tr>
<td>Author:</td>
<td>Lorenz A. Kapsner <a href="https://orcid.org/0000-0003-1866-860X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lorenz A. Kapsner &lt;lorenz.kapsner@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
</table>
<hr>
<h2 id='handle_cat_vars'>handle_cat_vars</h2><span id='topic+handle_cat_vars'></span>

<h3>Description</h3>

<p>Helper function to handle categorical variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>handle_cat_vars(kwargs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="handle_cat_vars_+3A_kwargs">kwargs</code></td>
<td>
<p>A list containing keyword arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a utility function to separate the list element with the
names of the categorical variables from the key word arguments list to
be passed further on to <code><a href="kdry.html#topic+dtr_matrix2df">kdry::dtr_matrix2df()</a></code>.
</p>


<h3>Value</h3>

<p>Returns a list with two elements:
</p>

<ul>
<li> <p><code>params</code> The keyword arguments without <code>cat_vars</code>.
</p>
</li>
<li> <p><code>cat_vars</code> The vector <code>cat_vars</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="kdry.html#topic+dtr_matrix2df">kdry::dtr_matrix2df()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>handle_cat_vars(list(cat_vars = c("a", "b", "c"), arg1 = 1, arg2 = 2))

</code></pre>

<hr>
<h2 id='LearnerGlm'>LearnerGlm R6 class</h2><span id='topic+LearnerGlm'></span>

<h3>Description</h3>

<p>This learner is a wrapper around <code><a href="stats.html#topic+glm">stats::glm()</a></code> in order to perform a
generalized linear regression. There is no implementation for tuning
parameters.
</p>


<h3>Details</h3>

<p>Can be used with
</p>

<ul>
<li> <p><a href="#topic+MLCrossValidation">MLCrossValidation</a>
</p>
</li></ul>

<p>Implemented methods:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$fit&#8288;</code> To fit the model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$predict&#8288;</code> To predict new data with the model.
</p>
</li></ul>



<h3>Super class</h3>

<p><code><a href="#topic+MLLearnerBase">mlexperiments::MLLearnerBase</a></code> -&gt; <code>LearnerGlm</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerGlm-new"><code>LearnerGlm$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerGlm-clone"><code>LearnerGlm$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="bayesian_scoring_function"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-bayesian_scoring_function'><code>mlexperiments::MLLearnerBase$bayesian_scoring_function()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="cross_validation"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-cross_validation'><code>mlexperiments::MLLearnerBase$cross_validation()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="fit"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-fit'><code>mlexperiments::MLLearnerBase$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="predict"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-predict'><code>mlexperiments::MLLearnerBase$predict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerGlm-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>LearnerGlm</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerGlm$new()</pre></div>



<h5>Details</h5>

<p>This learner is a wrapper around <code><a href="stats.html#topic+glm">stats::glm()</a></code> in order to perform a
generalized linear regression. There is no implementation for tuning
parameters, thus the only experiment to use <code>LearnerGlm</code> for is
<a href="#topic+MLCrossValidation">MLCrossValidation</a>.
</p>



<h5>Returns</h5>

<p>A new <code>LearnerGlm</code> R6 object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>LearnerGlm$new()

</pre>
</div>


<hr>
<a id="method-LearnerGlm-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerGlm$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">stats::glm()</a></code>
</p>
<p><code><a href="stats.html#topic+glm">stats::glm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LearnerGlm$new()


## ------------------------------------------------
## Method `LearnerGlm$new`
## ------------------------------------------------

LearnerGlm$new()

</code></pre>

<hr>
<h2 id='LearnerKnn'>LearnerKnn R6 class</h2><span id='topic+LearnerKnn'></span>

<h3>Description</h3>

<p>This learner is a wrapper around <code><a href="class.html#topic+knn">class::knn()</a></code> in order to perform a
k-nearest neighbor classification.
</p>


<h3>Details</h3>

<p>Optimization metric: classification error rate
Can be used with
</p>

<ul>
<li> <p><a href="#topic+MLTuneParameters">MLTuneParameters</a>
</p>
</li>
<li> <p><a href="#topic+MLCrossValidation">MLCrossValidation</a>
</p>
</li>
<li> <p><a href="#topic+MLNestedCV">MLNestedCV</a>
</p>
</li></ul>

<p>Implemented methods:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$fit&#8288;</code> To fit the model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$predict&#8288;</code> To predict new data with the model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$cross_validation&#8288;</code> To perform a grid search (hyperparameter
optimization).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bayesian_scoring_function&#8288;</code> To perform a Bayesian hyperparameter
optimization.
</p>
</li></ul>

<p>For the two hyperparameter optimization strategies (&quot;grid&quot; and &quot;bayesian&quot;),
the parameter <code>metric_optimization_higher_better</code> of the learner is
set to <code>FALSE</code> by default as the classification error rate
(<code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>) is used as the optimization metric.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+MLLearnerBase">mlexperiments::MLLearnerBase</a></code> -&gt; <code>LearnerKnn</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerKnn-new"><code>LearnerKnn$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerKnn-clone"><code>LearnerKnn$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="bayesian_scoring_function"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-bayesian_scoring_function'><code>mlexperiments::MLLearnerBase$bayesian_scoring_function()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="cross_validation"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-cross_validation'><code>mlexperiments::MLLearnerBase$cross_validation()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="fit"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-fit'><code>mlexperiments::MLLearnerBase$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="predict"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-predict'><code>mlexperiments::MLLearnerBase$predict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerKnn-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>LearnerKnn</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerKnn$new()</pre></div>



<h5>Details</h5>

<p>This learner is a wrapper around <code><a href="class.html#topic+knn">class::knn()</a></code> in order to perform a
k-nearest neighbor classification. The following experiments are
implemented:
</p>

<ul>
<li> <p><a href="#topic+MLTuneParameters">MLTuneParameters</a>
</p>
</li>
<li> <p><a href="#topic+MLCrossValidation">MLCrossValidation</a>
</p>
</li>
<li> <p><a href="#topic+MLNestedCV">MLNestedCV</a>
For the two hyperparameter optimization strategies (&quot;grid&quot; and
&quot;bayesian&quot;), the parameter <code>metric_optimization_higher_better</code> of the
learner is set to <code>FALSE</code> by default as the classification error rate
(<code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>) is used as the optimization metric.
</p>
</li></ul>




<h5>Examples</h5>

<div class="r example copy">
<pre>LearnerKnn$new()

</pre>
</div>


<hr>
<a id="method-LearnerKnn-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerKnn$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="class.html#topic+knn">class::knn()</a></code>, <code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>
</p>
<p><code><a href="class.html#topic+knn">class::knn()</a></code>, <code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LearnerKnn$new()


## ------------------------------------------------
## Method `LearnerKnn$new`
## ------------------------------------------------

LearnerKnn$new()

</code></pre>

<hr>
<h2 id='LearnerLm'>LearnerLm R6 class</h2><span id='topic+LearnerLm'></span>

<h3>Description</h3>

<p>This learner is a wrapper around <code><a href="stats.html#topic+lm">stats::lm()</a></code> in order to perform a
linear regression. There is no implementation for tuning
parameters.
</p>


<h3>Details</h3>

<p>Can be used with
</p>

<ul>
<li><p> mlexperiments::MLCrossValidation
</p>
</li></ul>

<p>Implemented methods:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$fit&#8288;</code> To fit the model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$predict&#8288;</code> To predict new data with the model.
</p>
</li></ul>



<h3>Super class</h3>

<p><code><a href="#topic+MLLearnerBase">mlexperiments::MLLearnerBase</a></code> -&gt; <code>LearnerLm</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerLm-new"><code>LearnerLm$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerLm-clone"><code>LearnerLm$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="bayesian_scoring_function"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-bayesian_scoring_function'><code>mlexperiments::MLLearnerBase$bayesian_scoring_function()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="cross_validation"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-cross_validation'><code>mlexperiments::MLLearnerBase$cross_validation()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="fit"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-fit'><code>mlexperiments::MLLearnerBase$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="predict"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-predict'><code>mlexperiments::MLLearnerBase$predict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerLm-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>LearnerLm</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerLm$new()</pre></div>



<h5>Details</h5>

<p>This learner is a wrapper around <code><a href="stats.html#topic+lm">stats::lm()</a></code> in order to perform a
linear regression. There is no implementation for tuning
parameters, thus the only experiment to use <code>LearnerLm</code> for is
<a href="#topic+MLCrossValidation">MLCrossValidation</a>
</p>



<h5>Returns</h5>

<p>A new <code>LearnerLm</code> R6 object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>LearnerLm$new()

</pre>
</div>


<hr>
<a id="method-LearnerLm-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerLm$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">stats::lm()</a></code>
</p>
<p><code><a href="stats.html#topic+lm">stats::lm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LearnerLm$new()


## ------------------------------------------------
## Method `LearnerLm$new`
## ------------------------------------------------

LearnerLm$new()

</code></pre>

<hr>
<h2 id='LearnerRpart'>LearnerRpart R6 class</h2><span id='topic+LearnerRpart'></span>

<h3>Description</h3>

<p>This learner is a wrapper around <code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code> in order to fit recursive
partitioning and regression trees.
</p>


<h3>Details</h3>

<p>Optimization metric:
</p>

<ul>
<li><p> classification (<code>method = "class"</code>): classification error rate
</p>
</li>
<li><p> regression (<code>method = "anova"</code>): mean squared error
</p>
</li></ul>

<p>Can be used with
</p>

<ul>
<li> <p><a href="#topic+MLTuneParameters">MLTuneParameters</a>
</p>
</li>
<li> <p><a href="#topic+MLCrossValidation">MLCrossValidation</a>
</p>
</li>
<li> <p><a href="#topic+MLNestedCV">MLNestedCV</a>
</p>
</li></ul>

<p>Implemented methods:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$fit&#8288;</code> To fit the model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$predict&#8288;</code> To predict new data with the model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$cross_validation&#8288;</code> To perform a grid search (hyperparameter
optimization).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bayesian_scoring_function&#8288;</code> To perform a Bayesian hyperparameter
optimization.
</p>
</li></ul>

<p>Parameters that are specified with <code>parameter_grid</code> and / or <code>learner_args</code>
are forwarded to <code>rpart</code>'s argument <code>control</code> (see
<code><a href="rpart.html#topic+rpart.control">rpart::rpart.control()</a></code> for further details).
</p>
<p>For the two hyperparameter optimization strategies (&quot;grid&quot; and &quot;bayesian&quot;),
the parameter <code>metric_optimization_higher_better</code> of the learner is
set to <code>FALSE</code> by default as the classification error rate
(<code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>) is used as the optimization metric for
classification tasks and the mean squared error (<code><a href="mlr3measures.html#topic+mse">mlr3measures::mse()</a></code>) is
used for regression tasks.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+MLLearnerBase">mlexperiments::MLLearnerBase</a></code> -&gt; <code>LearnerRpart</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerRpart-new"><code>LearnerRpart$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerRpart-clone"><code>LearnerRpart$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="bayesian_scoring_function"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-bayesian_scoring_function'><code>mlexperiments::MLLearnerBase$bayesian_scoring_function()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="cross_validation"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-cross_validation'><code>mlexperiments::MLLearnerBase$cross_validation()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="fit"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-fit'><code>mlexperiments::MLLearnerBase$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLLearnerBase" data-id="predict"><a href='../../mlexperiments/html/MLLearnerBase.html#method-MLLearnerBase-predict'><code>mlexperiments::MLLearnerBase$predict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerRpart-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>LearnerRpart</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerRpart$new()</pre></div>



<h5>Details</h5>

<p>This learner is a wrapper around <code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code> in order to fit
recursive partitioning and regression trees. The following experiments
are implemented:
</p>

<ul>
<li> <p><a href="#topic+MLTuneParameters">MLTuneParameters</a>
</p>
</li>
<li> <p><a href="#topic+MLCrossValidation">MLCrossValidation</a>
</p>
</li>
<li> <p><a href="#topic+MLNestedCV">MLNestedCV</a>
</p>
</li></ul>

<p>For the two hyperparameter optimization strategies (&quot;grid&quot; and
&quot;bayesian&quot;), the parameter <code>metric_optimization_higher_better</code> of the
learner is set to <code>FALSE</code> by default as the classification error rate
(<code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>) is used as the optimization metric for
classification tasks and the mean squared error (<code><a href="mlr3measures.html#topic+mse">mlr3measures::mse()</a></code>)
is used for regression tasks.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>LearnerRpart$new()

</pre>
</div>


<hr>
<a id="method-LearnerRpart-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerRpart$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code>, <code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>, <code><a href="mlr3measures.html#topic+mse">mlr3measures::mse()</a></code>,
<code><a href="rpart.html#topic+rpart.control">rpart::rpart.control()</a></code>
</p>
<p><code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code>, <code><a href="mlr3measures.html#topic+ce">mlr3measures::ce()</a></code>, <code><a href="mlr3measures.html#topic+mse">mlr3measures::mse()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LearnerRpart$new()


## ------------------------------------------------
## Method `LearnerRpart$new`
## ------------------------------------------------

LearnerRpart$new()

</code></pre>

<hr>
<h2 id='metric'>metric</h2><span id='topic+metric'></span>

<h3>Description</h3>

<p>Returns a metric function which can be used for the experiments
(especially the cross-validation experiments) to compute the performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric(name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_+3A_name">name</code></td>
<td>
<p>A metric name. Accepted names are the names of the metric
function exported from the <code>mlr3measures</code> R package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a utility function to select performance metrics from the
<code>mlr3measures</code> R package and to reformat them into a form that is required
by the <code>mlexperiments</code> R package. For <code>mlexperiments</code> it is required that
a metric function takes the two arguments <code>ground_truth</code>, and <code>predictions</code>,
as well as additional names arguments that are necessary to compute the
performance, which are provided via the ellipsis argument (...).
When using the performance metric with an experiment of class
<code>"MLCrossValidation"</code>, such arguments can be defined as a list provided to
the field <code>performance_metric_args</code> of the R6 class.
The main purpose of <code>mlexperiments::metric()</code> is convenience and to
re-use already existing implementations of the metrics. However, custom
functions can be provided easily to compute the performance of the
experiments, simply by providing a function that takes the above mentioned
arguments and returns one performance metric value.
</p>


<h3>Value</h3>

<p>Returns a function that can be used as function to calculate the
performance metric throughout the experiments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>metric("auc")

</code></pre>

<hr>
<h2 id='metric_types_helper'>metric_types_helper</h2><span id='topic+metric_types_helper'></span>

<h3>Description</h3>

<p>Prepares the data to be conform with the requirements of
the metrics from <code>mlr3measures</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_types_helper(FUN, y, perf_args)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metric_types_helper_+3A_fun">FUN</code></td>
<td>
<p>A metric function, created with <code><a href="#topic+metric">metric()</a></code>.</p>
</td></tr>
<tr><td><code id="metric_types_helper_+3A_y">y</code></td>
<td>
<p>The outcome vector.</p>
</td></tr>
<tr><td><code id="metric_types_helper_+3A_perf_args">perf_args</code></td>
<td>
<p>A list. The arguments to call the metric function with.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>mlr3measures</code> R package makes some restrictions on the data type of
the ground truth and the predictions, depending on the metric, i.e. the
type of the task (regression or classification).
Thus, it is necessary to convert the inputs to the metric function
accordingly, which is done with this helper function.
</p>


<h3>Value</h3>

<p>Returns the calculated performance measure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
ground_truth &lt;- sample(0:1, 100, replace = TRUE)
predictions &lt;- sample(0:1, 100, replace = TRUE)
FUN &lt;- metric("acc")

perf_args &lt;- list(
  ground_truth = ground_truth,
  predictions = predictions
)

metric_types_helper(
  FUN = FUN,
  y = ground_truth,
  perf_args = perf_args
)

</code></pre>

<hr>
<h2 id='MLBase'>Basic R6 Class for the mlexperiments package</h2><span id='topic+MLBase'></span>

<h3>Description</h3>

<p>Basic R6 Class for the mlexperiments package
</p>
<p>Basic R6 Class for the mlexperiments package
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>results</code></dt><dd><p>A list. This field is used to store the final results of
the respective methods.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MLBase-new"><code>MLBase$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MLBase-clone"><code>MLBase$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-MLBase-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>MLBase</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLBase$new(seed, ncores = -1L)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>seed</code></dt><dd><p>An integer. Needs to be set for reproducibility purposes.</p>
</dd>
<dt><code>ncores</code></dt><dd><p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>MLBase</code> R6 object.
</p>


<hr>
<a id="method-MLBase-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLBase$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='MLCrossValidation'>R6 Class to perform cross-validation experiments</h2><span id='topic+MLCrossValidation'></span>

<h3>Description</h3>

<p>The <code>MLCrossValidation</code> class is used to construct a cross validation object
and to perform a k-fold cross validation for a specified machine learning
algorithm using one distinct hyperparameter setting.
</p>


<h3>Details</h3>

<p>The <code>MLCrossValidation</code> class requires to provide a named list of predefined
row indices for the cross validation folds, e.g., created with the function
<code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>. This list also defines the <code>k</code> of the k-fold
cross-validation. When wanting to perform a repeated k-fold cross
validations, just provide a list with all repeated fold definitions, e.g.,
when specifying the argument <code>m_rep</code> of <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>.
</p>


<h3>Super classes</h3>

<p><code><a href="#topic+MLBase">mlexperiments::MLBase</a></code> -&gt; <code><a href="#topic+MLExperimentsBase">mlexperiments::MLExperimentsBase</a></code> -&gt; <code>MLCrossValidation</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>fold_list</code></dt><dd><p>A named list of predefined row indices for the cross
validation folds, e.g., created with the function
<code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>.</p>
</dd>
<dt><code>return_models</code></dt><dd><p>A logical. If the fitted models should be returned
with the results (default: <code>FALSE</code>).</p>
</dd>
<dt><code>performance_metric</code></dt><dd><p>Either a named list with metric functions, a
single metric function, or a character vector with metric names from
the <code>mlr3measures</code> package. The provided functions must take two named
arguments: <code>ground_truth</code> and <code>predictions</code>. For metrics from the
<code>mlr3measures</code> package, the wrapper function <code><a href="#topic+metric">metric()</a></code>
exists in order to prepare them for use with the <code>mlexperiments</code>
package.</p>
</dd>
<dt><code>performance_metric_args</code></dt><dd><p>A list. Further arguments required to
compute the performance metric.</p>
</dd>
<dt><code>predict_args</code></dt><dd><p>A list. Further arguments required to compute the
predictions.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MLCrossValidation-new"><code>MLCrossValidation$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MLCrossValidation-execute"><code>MLCrossValidation$execute()</code></a>
</p>
</li>
<li> <p><a href="#method-MLCrossValidation-clone"><code>MLCrossValidation$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLExperimentsBase" data-id="set_data"><a href='../../mlexperiments/html/MLExperimentsBase.html#method-MLExperimentsBase-set_data'><code>mlexperiments::MLExperimentsBase$set_data()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-MLCrossValidation-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>MLCrossValidation</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLCrossValidation$new(
  learner,
  fold_list,
  seed,
  ncores = -1L,
  return_models = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>An initialized learner object that inherits from class
<code>"MLLearnerBase"</code>.</p>
</dd>
<dt><code>fold_list</code></dt><dd><p>A named list of predefined row indices for the cross
validation folds, e.g., created with the function
<code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>.</p>
</dd>
<dt><code>seed</code></dt><dd><p>An integer. Needs to be set for reproducibility purposes.</p>
</dd>
<dt><code>ncores</code></dt><dd><p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</dd>
<dt><code>return_models</code></dt><dd><p>A logical. If the fitted models should be returned
with the results (default: <code>FALSE</code>).</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>The <code>MLCrossValidation</code> class requires to provide a named list of
predefined row indices for the cross validation folds, e.g., created
with the function <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>. This list also defines
the <code>k</code> of the k-fold cross-validation. When wanting to perform a
repeated k-fold cross validations, just provide a list with all
repeated fold definitions, e.g., when specifing the argument <code>m_rep</code> of
<code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv &lt;- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)

</pre>
</div>


<hr>
<a id="method-MLCrossValidation-execute"></a>



<h4>Method <code>execute()</code></h4>

<p>Execute the cross validation.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLCrossValidation$execute()</pre></div>



<h5>Details</h5>

<p>All results of the cross validation are saved in the field
<code style="white-space: pre;">&#8288;$results&#8288;</code> of the <code>MLCrossValidation</code> class. After successful execution
of the cross validation, <code style="white-space: pre;">&#8288;$results&#8288;</code> contains a list with the items:
</p>

<ul>
<li><p> &quot;fold&quot; A list of folds containing the following items for each
cross validation fold:
</p>

<ul>
<li><p> &quot;fold_ids&quot; A vector with the utilized in-sample row indices.
</p>
</li>
<li><p> &quot;ground_truth&quot; A vector with the ground truth.
</p>
</li>
<li><p> &quot;predictions&quot; A vector with the predictions.
</p>
</li>
<li><p> &quot;learner.args&quot; A list with the arguments provided to the learner.
</p>
</li>
<li><p> &quot;model&quot; If <code>return_models = TRUE</code>, the fitted model.
</p>
</li></ul>

</li>
<li><p> &quot;summary&quot; A data.table with the summarized results (same as
the returned value of the <code>execute</code> method).
</p>
</li>
<li><p> &quot;performance&quot; A list with the value of the performance metric
calculated for each of the cross validation folds.
</p>
</li></ul>




<h5>Returns</h5>

<p>The function returns a data.table with the results of the cross
validation. More results are accessible from the field <code style="white-space: pre;">&#8288;$results&#8288;</code> of
the <code>MLCrossValidation</code> class.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv &lt;- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)
cv$learner_args &lt;- list(
  k = 20,
  l = 0,
  test = parse(text = "fold_test$x")
)
cv$predict_args &lt;- list(type = "response")
cv$performance_metric &lt;- metric("bacc")

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()
</pre>
</div>


<hr>
<a id="method-MLCrossValidation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLCrossValidation$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>
</p>
<p><code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>, <a href="mlr3measures.html#topic+measures">mlr3measures::measures</a>,
<code><a href="#topic+metric">metric()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

cv &lt;- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)

# learner parameters
cv$learner_args &lt;- list(
  k = 20,
  l = 0,
  test = parse(text = "fold_test$x")
)

# performance parameters
cv$predict_args &lt;- list(type = "response")
cv$performance_metric &lt;- metric("bacc")

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()


## ------------------------------------------------
## Method `MLCrossValidation$new`
## ------------------------------------------------

dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv &lt;- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)


## ------------------------------------------------
## Method `MLCrossValidation$execute`
## ------------------------------------------------

dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)
cv &lt;- MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123,
  ncores = 2
)
cv$learner_args &lt;- list(
  k = 20,
  l = 0,
  test = parse(text = "fold_test$x")
)
cv$predict_args &lt;- list(type = "response")
cv$performance_metric &lt;- metric("bacc")

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()
</code></pre>

<hr>
<h2 id='MLExperimentsBase'>R6 Class on which the experiment classes are built on</h2><span id='topic+MLExperimentsBase'></span>

<h3>Description</h3>

<p>R6 Class on which the experiment classes are built on
</p>
<p>R6 Class on which the experiment classes are built on
</p>


<h3>Super class</h3>

<p><code><a href="#topic+MLBase">mlexperiments::MLBase</a></code> -&gt; <code>MLExperimentsBase</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>learner_args</code></dt><dd><p>A list containing the parameter settings of the
learner algorithm.</p>
</dd>
<dt><code>learner</code></dt><dd><p>An initialized learner object that inherits from class
<code>"MLLearnerBase"</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MLExperimentsBase-new"><code>MLExperimentsBase$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MLExperimentsBase-set_data"><code>MLExperimentsBase$set_data()</code></a>
</p>
</li>
<li> <p><a href="#method-MLExperimentsBase-clone"><code>MLExperimentsBase$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-MLExperimentsBase-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>MLExperimentsBase</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLExperimentsBase$new(learner, seed, ncores = -1L)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>An initialized learner object that inherits from class
<code>"MLLearnerBase"</code>.</p>
</dd>
<dt><code>seed</code></dt><dd><p>An integer. Needs to be set for reproducibility purposes.</p>
</dd>
<dt><code>ncores</code></dt><dd><p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>MLExperimentsBase</code> R6 object.
</p>


<hr>
<a id="method-MLExperimentsBase-set_data"></a>



<h4>Method <code>set_data()</code></h4>

<p>Set the data for the experiment.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLExperimentsBase$set_data(x, y, cat_vars = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>x</code></dt><dd><p>A matrix with the training data.</p>
</dd>
<dt><code>y</code></dt><dd><p>A vector with the target.</p>
</dd>
<dt><code>cat_vars</code></dt><dd><p>A character vector with the column names of variables
that should be treated as categorical features (if applicable /
supported by the respective algorithm).</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>The function has no return value. It internally performs quality
checks on the provided data and, if passed, defines private fields of
the R6 class.
</p>


<hr>
<a id="method-MLExperimentsBase-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLExperimentsBase$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='MLLearnerBase'>R6 Class to construct learners</h2><span id='topic+MLLearnerBase'></span>

<h3>Description</h3>

<p>The <code>MLLearnerBase</code> class is used to construct a learner object that can be
used with the experiment classes from the <code>mlexperiments</code> package. It is
thought to serve as a class to inherit from when creating new learners.
</p>


<h3>Details</h3>

<p>The learner class exposes 4 methods that can be defined:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$fit&#8288;</code> A wrapper around the private function <code>fun_fit</code>, which needs to
be defined for every learner. The return value of this function is the
fitted model.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$predict&#8288;</code> A wrapper around the private function <code>fun_predict</code>,
which needs to be defined for every learner. The function must accept the
three arguments <code>model</code>, <code>newdata</code>, and <code>ncores</code> and is a wrapper around
the respective learner's predict-function. In order to allow the passing of
further arguments, the ellipsis (<code>...</code>) can be used. The function should
return the prediction results.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$cross_validation&#8288;</code> A wrapper around the private function
<code>fun_optim_cv</code>, which needs to be defined when hyperparameters should be
optimized with a grid search (required for use with
<a href="#topic+MLTuneParameters">MLTuneParameters</a>, and <a href="#topic+MLNestedCV">MLNestedCV</a>).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bayesian_scoring_function&#8288;</code> A wrapper around the private function
<code>fun_bayesian_scoring_function</code>, which needs to be defined when
hyperparameters should be optimized with a Bayesian process (required for
use with <a href="#topic+MLTuneParameters">MLTuneParameters</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>).
</p>
</li></ul>

<p>For further details please refer to the package's vignette.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>cluster_export</code></dt><dd><p>A character vector defining the (internal)
functions that need to be exported to the parallelization cluster.
This is only required when performing a Bayesian hyperparameter
optimization. See also <code><a href="parallel.html#topic+clusterApply">parallel::clusterExport()</a></code>.</p>
</dd>
<dt><code>metric_optimization_higher_better</code></dt><dd><p>A logical. Defines the direction
of the optimization metric used throughout the hyperparameter
optimization. This field is set automatically during the initialization
of the <code>MLLearnerBase</code> object. Its purpose is to make it accessible by
the evaluation functions from <a href="#topic+MLTuneParameters">MLTuneParameters</a>.</p>
</dd>
<dt><code>environment</code></dt><dd><p>The environment in which to search for the functions
of the learner (default: <code>-1L</code>).</p>
</dd>
<dt><code>seed</code></dt><dd><p>Seed for reproducible results.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MLLearnerBase-new"><code>MLLearnerBase$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MLLearnerBase-cross_validation"><code>MLLearnerBase$cross_validation()</code></a>
</p>
</li>
<li> <p><a href="#method-MLLearnerBase-fit"><code>MLLearnerBase$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-MLLearnerBase-predict"><code>MLLearnerBase$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-MLLearnerBase-bayesian_scoring_function"><code>MLLearnerBase$bayesian_scoring_function()</code></a>
</p>
</li>
<li> <p><a href="#method-MLLearnerBase-clone"><code>MLLearnerBase$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-MLLearnerBase-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>MLLearnerBase</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLLearnerBase$new(metric_optimization_higher_better)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>metric_optimization_higher_better</code></dt><dd><p>A logical. Defines the direction
of the optimization metric used throughout the hyperparameter
optimization.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new <code>MLLearnerBase</code> R6 object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>MLLearnerBase$new(metric_optimization_higher_better = FALSE)

</pre>
</div>


<hr>
<a id="method-MLLearnerBase-cross_validation"></a>



<h4>Method <code>cross_validation()</code></h4>

<p>Perform a cross-validation with an <code>MLLearnerBase</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLLearnerBase$cross_validation(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>Arguments to be passed to the learner's cross-validation
function.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>A wrapper around the private function <code>fun_optim_cv</code>, which needs to be
defined when hyperparameters should be optimized with a grid search
(required for use with <a href="#topic+MLTuneParameters">MLTuneParameters</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>.
However, the function should be never executed directly but by the
respective experiment wrappers <a href="#topic+MLTuneParameters">MLTuneParameters</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>.
For further details please refer to the package's vignette.
</p>



<h5>Returns</h5>

<p>The fitted model.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
\dontrun{
# This example cannot be run without further adaptions.
# The method `$cross_validation()` needs to be overwritten when
# inheriting from this class.
learner$cross_validation()
}

</pre>
</div>


<hr>
<a id="method-MLLearnerBase-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Fit a <code>MLLearnerBase</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLLearnerBase$fit(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>Arguments to be passed to the learner's fitting function.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>A wrapper around the private function <code>fun_fit</code>, which needs to be
defined for every learner. The return value of this function is the
fitted model.
However, the function should be never executed directly but by the
respective experiment wrappers <a href="#topic+MLTuneParameters">MLTuneParameters</a>,
<a href="#topic+MLCrossValidation">MLCrossValidation</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>.
For further details please refer to the package's vignette.
</p>



<h5>Returns</h5>

<p>The fitted model.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
\dontrun{
# This example cannot be run without further adaptions.
# The method `$fit()` needs to be overwritten when
# inheriting from this class.
learner$fit()
}

</pre>
</div>


<hr>
<a id="method-MLLearnerBase-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Make predictions from a fitted <code>MLLearnerBase</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLLearnerBase$predict(model, newdata, ncores = -1L, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model</code></dt><dd><p>A fitted model of the learner (as returned by
<code>MLLearnerBase$fit()</code>).</p>
</dd>
<dt><code>newdata</code></dt><dd><p>The new data for which predictions should be made using
the <code>model</code>.</p>
</dd>
<dt><code>ncores</code></dt><dd><p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</dd>
<dt><code>...</code></dt><dd><p>Further arguments to be passed to the learner's predict
function.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>A wrapper around the private function <code>fun_predict</code>, which needs to be
defined for every learner. The function must accept the three arguments
<code>model</code>, <code>newdata</code>, and <code>ncores</code> and is a wrapper around the respective
learner's predict-function. In order to allow the passing of further
arguments, the ellipsis (<code>...</code>) can be used. The function should
return the prediction results.
However, the function should be never executed directly but by the
respective experiment wrappers <a href="#topic+MLTuneParameters">MLTuneParameters</a>,
<a href="#topic+MLCrossValidation">MLCrossValidation</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>.
For further details please refer to the package's vignette.
</p>



<h5>Returns</h5>

<p>The predictions for <code>newdata</code>.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
\dontrun{
# This example cannot be run without further adaptions.
# The method `$predict()` needs to be overwritten when
# inheriting from this class.
learner$fit()
learner$predict()
}

</pre>
</div>


<hr>
<a id="method-MLLearnerBase-bayesian_scoring_function"></a>



<h4>Method <code>bayesian_scoring_function()</code></h4>

<p>Perform a Bayesian hyperparameter optimization with an <code>MLLearnerBase</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLLearnerBase$bayesian_scoring_function(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>Arguments to be passed to the learner's Bayesian scoring
function.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>A wrapper around the private function <code>fun_bayesian_scoring_function</code>,
which needs to be defined when hyperparameters should be optimized with
a Bayesian process (required for use with
<a href="#topic+MLTuneParameters">MLTuneParameters</a>, and <a href="#topic+MLNestedCV">MLNestedCV</a>.
However, the function should be never executed directly but by the
respective experiment wrappers <a href="#topic+MLTuneParameters">MLTuneParameters</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>.
For further details please refer to the package's vignette.
</p>



<h5>Returns</h5>

<p>The results of the Bayesian scoring.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
\dontrun{
# This example cannot be run without further adaptions.
# The method `$bayesian_scoring_function()` needs to be overwritten when
# inheriting from this class.
learner$bayesian_scoring_function()
}

</pre>
</div>


<hr>
<a id="method-MLLearnerBase-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLLearnerBase$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><a href="#topic+MLTuneParameters">MLTuneParameters</a>,
<a href="#topic+MLCrossValidation">MLCrossValidation</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>
</p>
<p><a href="#topic+MLTuneParameters">MLTuneParameters</a>,
<a href="#topic+MLCrossValidation">MLCrossValidation</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>
</p>
<p><a href="#topic+MLTuneParameters">MLTuneParameters</a>,
<a href="#topic+MLCrossValidation">MLCrossValidation</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>
</p>
<p><code><a href="ParBayesianOptimization.html#topic+bayesOpt">ParBayesianOptimization::bayesOpt()</a></code>,
<a href="#topic+MLTuneParameters">MLTuneParameters</a>, and <a href="#topic+MLNestedCV">MLNestedCV</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MLLearnerBase$new(metric_optimization_higher_better = FALSE)


## ------------------------------------------------
## Method `MLLearnerBase$new`
## ------------------------------------------------

MLLearnerBase$new(metric_optimization_higher_better = FALSE)


## ------------------------------------------------
## Method `MLLearnerBase$cross_validation`
## ------------------------------------------------

learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
## Not run: 
# This example cannot be run without further adaptions.
# The method `$cross_validation()` needs to be overwritten when
# inheriting from this class.
learner$cross_validation()

## End(Not run)


## ------------------------------------------------
## Method `MLLearnerBase$fit`
## ------------------------------------------------

learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
## Not run: 
# This example cannot be run without further adaptions.
# The method `$fit()` needs to be overwritten when
# inheriting from this class.
learner$fit()

## End(Not run)


## ------------------------------------------------
## Method `MLLearnerBase$predict`
## ------------------------------------------------

learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
## Not run: 
# This example cannot be run without further adaptions.
# The method `$predict()` needs to be overwritten when
# inheriting from this class.
learner$fit()
learner$predict()

## End(Not run)


## ------------------------------------------------
## Method `MLLearnerBase$bayesian_scoring_function`
## ------------------------------------------------

learner &lt;- MLLearnerBase$new(metric_optimization_higher_better = FALSE)
## Not run: 
# This example cannot be run without further adaptions.
# The method `$bayesian_scoring_function()` needs to be overwritten when
# inheriting from this class.
learner$bayesian_scoring_function()

## End(Not run)

</code></pre>

<hr>
<h2 id='MLNestedCV'>R6 Class to perform nested cross-validation experiments</h2><span id='topic+MLNestedCV'></span>

<h3>Description</h3>

<p>The <code>MLNestedCV</code> class is used to construct a nested cross validation object
and to perform a nested cross validation for a specified machine learning
algorithm by performing a hyperparameter optimization with the in-sample
observations of each of the k outer folds and validate them directly on the
out-of-sample observations of the respective fold.
</p>


<h3>Details</h3>

<p>The <code>MLNestedCV</code> class requires to provide a named list of predefined
row indices for the outer cross validation folds, e.g., created with the
function <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>. This list also defines the <code>k</code> of
the k-fold cross-validation. Furthermore, a strategy needs to be chosen
(&quot;grid&quot; or &quot;bayesian&quot;) for the hyperparameter optimization as well as the
parameter <code>k_tuning</code> to define the number of inner cross validation folds.
</p>


<h3>Super classes</h3>

<p><code><a href="#topic+MLBase">mlexperiments::MLBase</a></code> -&gt; <code><a href="#topic+MLExperimentsBase">mlexperiments::MLExperimentsBase</a></code> -&gt; <code><a href="#topic+MLCrossValidation">mlexperiments::MLCrossValidation</a></code> -&gt; <code>MLNestedCV</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>strategy</code></dt><dd><p>A character. The strategy to optimize the hyperparameters
(either <code>"grid"</code> or <code>"bayesian"</code>).</p>
</dd>
<dt><code>parameter_bounds</code></dt><dd><p>A named list of tuples to define the parameter
bounds of the Bayesian hyperparameter optimization. For further details
please see the documentation of the <code>ParBayesianOptimization</code> package.</p>
</dd>
<dt><code>parameter_grid</code></dt><dd><p>A matrix with named columns in which each column
represents a parameter that should be optimized and each row represents
a specific hyperparameter setting that should be tested throughout the
procedure. For <code>strategy = "grid"</code>, each row of the <code>parameter_grid</code> is
considered as a setting that is evaluated. For <code>strategy = "bayesian"</code>,
the <code>parameter_grid</code> is passed further on to the <code>initGrid</code> argument of
the function <code><a href="ParBayesianOptimization.html#topic+bayesOpt">ParBayesianOptimization::bayesOpt()</a></code> in order to
initialize the Bayesian process. The maximum rows considered for
initializing the Bayesian process can be specified with the R option
<code>option("mlexperiments.bayesian.max_init")</code>, which is set to <code>50L</code> by
default.</p>
</dd>
<dt><code>optim_args</code></dt><dd><p>A named list of tuples to define the parameter
bounds of the Bayesian hyperparameter optimization. For further details
please see the documentation of the <code>ParBayesianOptimization</code> package.</p>
</dd>
<dt><code>split_type</code></dt><dd><p>A character. The splitting strategy to construct the
k cross-validation folds. This parameter is passed further on to the
function <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code> and defaults to <code>"stratified"</code>.</p>
</dd>
<dt><code>split_vector</code></dt><dd><p>A vector If another criteria than the provided <code>y</code>
should be considered for generating the cross-validation folds, it can
be defined here. It is important, that a vector of the same length as
<code>x</code> is provided here.</p>
</dd>
<dt><code>k_tuning</code></dt><dd><p>An integer to define the number of cross-validation folds
used to tune the hyperparameters.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MLNestedCV-new"><code>MLNestedCV$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MLNestedCV-execute"><code>MLNestedCV$execute()</code></a>
</p>
</li>
<li> <p><a href="#method-MLNestedCV-clone"><code>MLNestedCV$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLExperimentsBase" data-id="set_data"><a href='../../mlexperiments/html/MLExperimentsBase.html#method-MLExperimentsBase-set_data'><code>mlexperiments::MLExperimentsBase$set_data()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-MLNestedCV-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>MLNestedCV</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLNestedCV$new(
  learner,
  strategy = c("grid", "bayesian"),
  k_tuning,
  fold_list,
  seed,
  ncores = -1L,
  return_models = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>An initialized learner object that inherits from class
<code>"MLLearnerBase"</code>.</p>
</dd>
<dt><code>strategy</code></dt><dd><p>A character. The strategy to optimize the hyperparameters
(either <code>"grid"</code> or <code>"bayesian"</code>).</p>
</dd>
<dt><code>k_tuning</code></dt><dd><p>An integer to define the number of cross-validation folds
used to tune the hyperparameters.</p>
</dd>
<dt><code>fold_list</code></dt><dd><p>A named list of predefined row indices for the cross
validation folds, e.g., created with the function
<code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>.</p>
</dd>
<dt><code>seed</code></dt><dd><p>An integer. Needs to be set for reproducibility purposes.</p>
</dd>
<dt><code>ncores</code></dt><dd><p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</dd>
<dt><code>return_models</code></dt><dd><p>A logical. If the fitted models should be returned
with the results (default: <code>FALSE</code>).</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>The <code>MLNestedCV</code> class requires to provide a named list of predefined
row indices for the outer cross validation folds, e.g., created with
the function <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>. This list also defines the
<code>k</code> of the k-fold cross-validation. Furthermore, a strategy needs to
be chosen (&quot;grid&quot; or &quot;bayesian&quot;) for the hyperparameter optimization
as well as the parameter <code>k_tuning</code> to define the number of inner
cross validation folds.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

cv &lt;- MLNestedCV$new(
  learner = LearnerKnn$new(),
  strategy = "grid",
  fold_list = fold_list,
  k_tuning = 3L,
  seed = 123,
  ncores = 2
)

</pre>
</div>


<hr>
<a id="method-MLNestedCV-execute"></a>



<h4>Method <code>execute()</code></h4>

<p>Execute the nested cross validation.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLNestedCV$execute()</pre></div>



<h5>Details</h5>

<p>All results of the cross validation are saved in the field <code style="white-space: pre;">&#8288;$results&#8288;</code> of
the <code>MLNestedCV</code> class. After successful execution of the nested cross
validation, <code style="white-space: pre;">&#8288;$results&#8288;</code> contains a list with the items:
</p>

<ul>
<li><p> &quot;results.optimization&quot; A list with the results of the hyperparameter
optimization.
</p>
</li>
<li><p> &quot;fold&quot; A list of folds containing the following items for each
cross validation fold:
</p>

<ul>
<li><p> &quot;fold_ids&quot; A vector with the utilized in-sample row indices.
</p>
</li>
<li><p> &quot;ground_truth&quot; A vector with the ground truth.
</p>
</li>
<li><p> &quot;predictions&quot; A vector with the predictions.
</p>
</li>
<li><p> &quot;learner.args&quot; A list with the arguments provided to the learner.
</p>
</li>
<li><p> &quot;model&quot; If <code>return_models = TRUE</code>, the fitted model.
</p>
</li></ul>

</li>
<li><p> &quot;summary&quot; A data.table with the summarized results (same as
the returned value of the <code>execute</code> method).
</p>
</li>
<li><p> &quot;performance&quot; A list with the value of the performance metric
calculated for each of the cross validation folds.
</p>
</li></ul>




<h5>Returns</h5>

<p>The function returns a data.table with the results of the nested
cross validation. More results are accessible from the field <code style="white-space: pre;">&#8288;$results&#8288;</code>
of the <code>MLNestedCV</code> class.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

cv &lt;- MLNestedCV$new(
  learner = LearnerKnn$new(),
  strategy = "grid",
  fold_list = fold_list,
  k_tuning = 3L,
  seed = 123,
  ncores = 2
)

# learner args (not optimized)
cv$learner_args &lt;- list(
  l = 0,
  test = parse(text = "fold_test$x")
)

# parameters for hyperparameter tuning
cv$parameter_grid &lt;- expand.grid(
  k = seq(4, 68, 8)
)
cv$split_type &lt;- "stratified"

# performance parameters
cv$predict_args &lt;- list(type = "response")
cv$performance_metric &lt;- metric("bacc")

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()

</pre>
</div>


<hr>
<a id="method-MLNestedCV-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLNestedCV$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>
</p>
<p><code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

cv &lt;- MLNestedCV$new(
  learner = LearnerKnn$new(),
  strategy = "grid",
  fold_list = fold_list,
  k_tuning = 3L,
  seed = 123,
  ncores = 2
)

# learner args (not optimized)
cv$learner_args &lt;- list(
  l = 0,
  test = parse(text = "fold_test$x")
)

# parameters for hyperparameter tuning
cv$parameter_grid &lt;- expand.grid(
  k = seq(4, 16, 8)
)
cv$split_type &lt;- "stratified"

# performance parameters
cv$predict_args &lt;- list(type = "response")
cv$performance_metric &lt;- metric("bacc")

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()


## ------------------------------------------------
## Method `MLNestedCV$new`
## ------------------------------------------------

dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

cv &lt;- MLNestedCV$new(
  learner = LearnerKnn$new(),
  strategy = "grid",
  fold_list = fold_list,
  k_tuning = 3L,
  seed = 123,
  ncores = 2
)


## ------------------------------------------------
## Method `MLNestedCV$execute`
## ------------------------------------------------

dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

cv &lt;- MLNestedCV$new(
  learner = LearnerKnn$new(),
  strategy = "grid",
  fold_list = fold_list,
  k_tuning = 3L,
  seed = 123,
  ncores = 2
)

# learner args (not optimized)
cv$learner_args &lt;- list(
  l = 0,
  test = parse(text = "fold_test$x")
)

# parameters for hyperparameter tuning
cv$parameter_grid &lt;- expand.grid(
  k = seq(4, 68, 8)
)
cv$split_type &lt;- "stratified"

# performance parameters
cv$predict_args &lt;- list(type = "response")
cv$performance_metric &lt;- metric("bacc")

# set data
cv$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv$execute()

</code></pre>

<hr>
<h2 id='MLTuneParameters'>R6 Class to perform hyperparameter tuning experiments</h2><span id='topic+MLTuneParameters'></span>

<h3>Description</h3>

<p>The <code>MLTuneParameters</code> class is used to construct a parameter tuner object
and to perform the tuning of a set of hyperparameters for a specified
machine learning algorithm using either a grid search or a Bayesian
optimization.
</p>


<h3>Details</h3>

<p>The hyperparameter tuning can be performed with a grid search or a Bayesian
optimization. In both cases, each hyperparameter setting is evaluated in a
k-fold cross-validation on the dataset specified.
</p>


<h3>Super classes</h3>

<p><code><a href="#topic+MLBase">mlexperiments::MLBase</a></code> -&gt; <code><a href="#topic+MLExperimentsBase">mlexperiments::MLExperimentsBase</a></code> -&gt; <code>MLTuneParameters</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>parameter_bounds</code></dt><dd><p>A named list of tuples to define the parameter
bounds of the Bayesian hyperparameter optimization. For further details
please see the documentation of the <code>ParBayesianOptimization</code> package.</p>
</dd>
<dt><code>parameter_grid</code></dt><dd><p>A matrix with named columns in which each column
represents a parameter that should be optimized and each row represents
a specific hyperparameter setting that should be tested throughout the
procedure. For <code>strategy = "grid"</code>, each row of the <code>parameter_grid</code> is
considered as a setting that is evaluated. For <code>strategy = "bayesian"</code>,
the <code>parameter_grid</code> is passed further on to the <code>initGrid</code> argument of
the function <code><a href="ParBayesianOptimization.html#topic+bayesOpt">ParBayesianOptimization::bayesOpt()</a></code> in order to
initialize the Bayesian process. The maximum rows considered for
initializing the Bayesian process can be specified with the R option
<code>option("mlexperiments.bayesian.max_init")</code>, which is set to <code>50L</code> by
default.</p>
</dd>
<dt><code>optim_args</code></dt><dd><p>A named list of tuples to define the parameter
bounds of the Bayesian hyperparameter optimization. For further details
please see the documentation of the <code>ParBayesianOptimization</code> package.</p>
</dd>
<dt><code>split_type</code></dt><dd><p>A character. The splitting strategy to construct the
k cross-validation folds. This parameter is passed further on to the
function <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code> and defaults to <code>"stratified"</code>.</p>
</dd>
<dt><code>split_vector</code></dt><dd><p>A vector If another criteria than the provided <code>y</code>
should be considered for generating the cross-validation folds, it can
be defined here. It is important, that a vector of the same length as
<code>x</code> is provided here.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-MLTuneParameters-new"><code>MLTuneParameters$new()</code></a>
</p>
</li>
<li> <p><a href="#method-MLTuneParameters-execute"><code>MLTuneParameters$execute()</code></a>
</p>
</li>
<li> <p><a href="#method-MLTuneParameters-clone"><code>MLTuneParameters$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlexperiments" data-topic="MLExperimentsBase" data-id="set_data"><a href='../../mlexperiments/html/MLExperimentsBase.html#method-MLExperimentsBase-set_data'><code>mlexperiments::MLExperimentsBase$set_data()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-MLTuneParameters-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new <code>MLTuneParameters</code> object.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLTuneParameters$new(
  learner,
  seed,
  strategy = c("grid", "bayesian"),
  ncores = -1L
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>An initialized learner object that inherits from class
<code>"MLLearnerBase"</code>.</p>
</dd>
<dt><code>seed</code></dt><dd><p>An integer. Needs to be set for reproducibility purposes.</p>
</dd>
<dt><code>strategy</code></dt><dd><p>A character. The strategy to optimize the hyperparameters
(either <code>"grid"</code> or <code>"bayesian"</code>).</p>
</dd>
<dt><code>ncores</code></dt><dd><p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>For <code>strategy = "bayesian"</code>, the number of starting iterations can be
set using the R option <code>"mlexperiments.bayesian.max_init"</code>, which
defaults to <code>50L</code>. This option reduces the provided initialization
grid to contain at most the specified number of rows. This
initialization grid is then further passed on to the <code>initGrid</code>
argument of <a href="ParBayesianOptimization.html#topic+bayesOpt">ParBayesianOptimization::bayesOpt</a>.
</p>



<h5>Returns</h5>

<p>A new <code>MLTuneParameters</code> R6 object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>MLTuneParameters$new(
  learner = LearnerKnn$new(),
  seed = 123,
  strategy = "grid",
  ncores = 2
)

</pre>
</div>


<hr>
<a id="method-MLTuneParameters-execute"></a>



<h4>Method <code>execute()</code></h4>

<p>Execute the hyperparameter tuning.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLTuneParameters$execute(k)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>k</code></dt><dd><p>An integer to define the number of cross-validation folds used
to tune the hyperparameters.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>All results of the hyperparameter tuning are saved in the field
<code style="white-space: pre;">&#8288;$results&#8288;</code> of the <code>MLTuneParameters</code> class. After successful execution
of the parameter tuning, <code style="white-space: pre;">&#8288;$results&#8288;</code> contains a list with the items
</p>

<dl>
<dt>&quot;summary&quot;</dt><dd><p>A data.table with the summarized results (same as
the returned value of the <code>execute</code> method).</p>
</dd>
<dt>&quot;best.setting&quot;</dt><dd><p>The best setting (according to the learner's
parameter <code>metric_optimization_higher_better</code>) identified during the
hyperparameter tuning.</p>
</dd>
<dt>&quot;bayesOpt&quot;</dt><dd><p>The returned value of
<code><a href="ParBayesianOptimization.html#topic+bayesOpt">ParBayesianOptimization::bayesOpt()</a></code> (only for <code>strategy = "bayesian"</code>).</p>
</dd>
</dl>




<h5>Returns</h5>

<p>A <code>data.table</code> with the results of the hyperparameter
optimization. The optimized metric, i.e. the cross-validated evaluation
metric is given in the column <code>metric_optim_mean</code>. More results are
accessible from the field <code style="white-space: pre;">&#8288;$results&#8288;</code> of the <code>MLTuneParameters</code> class.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
tuner &lt;- MLTuneParameters$new(
  learner = LearnerKnn$new(),
  seed = 123,
  strategy = "grid",
  ncores = 2
)
tuner$parameter_bounds &lt;- list(k = c(2L, 80L))
tuner$parameter_grid &lt;- expand.grid(
  k = seq(4, 68, 8),
  l = 0,
  test = parse(text = "fold_test$x")
)
tuner$split_type &lt;- "stratified"
tuner$optim_args &lt;- list(
  iters.n = 4,
  kappa = 3.5,
  acq = "ucb"
)

# set data
tuner$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

tuner$execute(k = 3)

</pre>
</div>


<hr>
<a id="method-MLTuneParameters-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>MLTuneParameters$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><code><a href="ParBayesianOptimization.html#topic+bayesOpt">ParBayesianOptimization::bayesOpt()</a></code>, <code><a href="splitTools.html#topic+create_folds">splitTools::create_folds()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>knn_tuner &lt;- MLTuneParameters$new(
  learner = LearnerKnn$new(),
  seed = 123,
  strategy = "grid",
  ncores = 2
)


## ------------------------------------------------
## Method `MLTuneParameters$new`
## ------------------------------------------------

MLTuneParameters$new(
  learner = LearnerKnn$new(),
  seed = 123,
  strategy = "grid",
  ncores = 2
)


## ------------------------------------------------
## Method `MLTuneParameters$execute`
## ------------------------------------------------

dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))
tuner &lt;- MLTuneParameters$new(
  learner = LearnerKnn$new(),
  seed = 123,
  strategy = "grid",
  ncores = 2
)
tuner$parameter_bounds &lt;- list(k = c(2L, 80L))
tuner$parameter_grid &lt;- expand.grid(
  k = seq(4, 68, 8),
  l = 0,
  test = parse(text = "fold_test$x")
)
tuner$split_type &lt;- "stratified"
tuner$optim_args &lt;- list(
  iters.n = 4,
  kappa = 3.5,
  acq = "ucb"
)

# set data
tuner$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

tuner$execute(k = 3)

</code></pre>

<hr>
<h2 id='performance'>performance</h2><span id='topic+performance'></span>

<h3>Description</h3>

<p>Calculate performance measures from the predictions results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance(object, prediction_results, y_ground_truth, type = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performance_+3A_object">object</code></td>
<td>
<p>An R6 object of class <code>"MLCrossValidation"</code> for which the
performance should be computed.</p>
</td></tr>
<tr><td><code id="performance_+3A_prediction_results">prediction_results</code></td>
<td>
<p>An object of class <code>"mlexPredictions"</code> (the output
of the function <code><a href="#topic+predictions">predictions()</a></code>).</p>
</td></tr>
<tr><td><code id="performance_+3A_y_ground_truth">y_ground_truth</code></td>
<td>
<p>A vector with the ground truth of the predicted data.</p>
</td></tr>
<tr><td><code id="performance_+3A_type">type</code></td>
<td>
<p>A character to select a pre-defined set of metrics for &quot;binary&quot;
and &quot;regression&quot; tasks. If not specified (default: <code>NULL</code>), the metrics
that were specified during fitting the <code>object</code> are used.</p>
</td></tr>
<tr><td><code id="performance_+3A_...">...</code></td>
<td>
<p>A list. Further arguments required to compute the performance
metrics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The performance metric has to be specified in the <code>object</code> that is used to
carry out the experiment, i.e., <a href="#topic+MLCrossValidation">MLCrossValidation</a> or
<a href="#topic+MLNestedCV">MLNestedCV</a>.
Please note that the option <code>return_models = TRUE</code> must be set in the
experiment class in order to be able to compute the predictions, which are
required to conduct the calculation of the performance.
</p>


<h3>Value</h3>

<p>The function returns a data.table with the computed performance
metric of each fold.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

glm_optimization &lt;- mlexperiments::MLCrossValidation$new(
  learner = LearnerGlm$new(),
  fold_list = fold_list,
  seed = 123
)

glm_optimization$learner_args &lt;- list(family = binomial(link = "logit"))
glm_optimization$predict_args &lt;- list(type = "response")
glm_optimization$performance_metric_args &lt;- list(positive = "1")
glm_optimization$performance_metric &lt;- list(
  auc = metric("auc"), sensitivity = metric("sensitivity"),
  specificity = metric("specificity")
)
glm_optimization$return_models &lt;- TRUE

# set data
glm_optimization$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv_results &lt;- glm_optimization$execute()

# predictions
preds &lt;- mlexperiments::predictions(
  object = glm_optimization,
  newdata = data.matrix(dataset[, -7]),
  na.rm = FALSE,
  ncores = 2L,
  type = "response"
)

# performance
mlexperiments::performance(
  object = glm_optimization,
  prediction_results = preds,
  y_ground_truth = dataset[, 7],
  positive = "1"
)

# performance - binary
mlexperiments::performance(
  object = glm_optimization,
  prediction_results = preds,
  y_ground_truth = dataset[, 7],
  type = "binary",
  positive = "1"
)

</code></pre>

<hr>
<h2 id='predictions'>predictions</h2><span id='topic+predictions'></span>

<h3>Description</h3>

<p>Apply an R6 object of class <code>"MLCrossValidation"</code> to new data
to compute predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictions(object, newdata, na.rm = FALSE, ncores = -1L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictions_+3A_object">object</code></td>
<td>
<p>An R6 object of class <code>"MLCrossValidation"</code> for which the
predictions should be computed.</p>
</td></tr>
<tr><td><code id="predictions_+3A_newdata">newdata</code></td>
<td>
<p>The new data for which predictions should be made using
the <code>model</code>.</p>
</td></tr>
<tr><td><code id="predictions_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical. If missings should be removed before computing the
mean and standard deviation of the performance across different folds for
each observation in <code>newdata</code>.</p>
</td></tr>
<tr><td><code id="predictions_+3A_ncores">ncores</code></td>
<td>
<p>An integer to specify the number of cores used for
parallelization (default: <code>-1L</code>).</p>
</td></tr>
<tr><td><code id="predictions_+3A_...">...</code></td>
<td>
<p>A list. Further arguments required to compute the predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a data.table of class <code>"mlexPredictions"</code>with
one row for each observation in <code>newdata</code> and the columns containing
the predictions for each fold, along with the mean and standard deviation
across all folds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

glm_optimization &lt;- mlexperiments::MLCrossValidation$new(
  learner = LearnerGlm$new(),
  fold_list = fold_list,
  seed = 123
)

glm_optimization$learner_args &lt;- list(family = binomial(link = "logit"))
glm_optimization$predict_args &lt;- list(type = "response")
glm_optimization$performance_metric_args &lt;- list(positive = "1")
glm_optimization$performance_metric &lt;- metric("auc")
glm_optimization$return_models &lt;- TRUE

# set data
glm_optimization$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv_results &lt;- glm_optimization$execute()

# predictions
preds &lt;- mlexperiments::predictions(
  object = glm_optimization,
  newdata = data.matrix(dataset[, -7]),
  na.rm = FALSE,
  ncores = 2L,
  type = "response"
)
head(preds)

</code></pre>

<hr>
<h2 id='validate_fold_equality'>validate_fold_equality</h2><span id='topic+validate_fold_equality'></span>

<h3>Description</h3>

<p>Validate that the same folds were used in two or more
independent experiments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_fold_equality(experiments)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_fold_equality_+3A_experiments">experiments</code></td>
<td>
<p>A list of experiments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be applied to all implemented experiments, i.e.,
<a href="#topic+MLTuneParameters">MLTuneParameters</a>, <a href="#topic+MLCrossValidation">MLCrossValidation</a>, and
<a href="#topic+MLNestedCV">MLNestedCV</a>. However, it is required that the list
<code>experiments</code> contains only experiments of the same class.
</p>


<h3>Value</h3>

<p>Writes messages to the console on the result of the comparison.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- do.call(
  cbind,
  c(sapply(paste0("col", 1:6), function(x) {
    rnorm(n = 500)
    },
    USE.NAMES = TRUE,
    simplify = FALSE
   ),
   list(target = sample(0:1, 500, TRUE))
))

fold_list &lt;- splitTools::create_folds(
  y = dataset[, 7],
  k = 3,
  type = "stratified",
  seed = 123
)

# GLM
glm_optimization &lt;- mlexperiments::MLCrossValidation$new(
  learner = LearnerGlm$new(),
  fold_list = fold_list,
  seed = 123
)

glm_optimization$learner_args &lt;- list(family = binomial(link = "logit"))
glm_optimization$predict_args &lt;- list(type = "response")
glm_optimization$performance_metric_args &lt;- list(positive = "1")
glm_optimization$performance_metric &lt;- metric("auc")
glm_optimization$return_models &lt;- TRUE

# set data
glm_optimization$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

glm_cv_results &lt;- glm_optimization$execute()

# KNN
knn_optimization &lt;- mlexperiments::MLCrossValidation$new(
  learner = LearnerKnn$new(),
  fold_list = fold_list,
  seed = 123
)
knn_optimization$learner_args &lt;- list(
  k = 3,
  l = 0,
  test = parse(text = "fold_test$x")
)
knn_optimization$predict_args &lt;- list(type = "prob")
knn_optimization$performance_metric_args &lt;- list(positive = "1")
knn_optimization$performance_metric &lt;- metric("auc")

# set data
knn_optimization$set_data(
  x = data.matrix(dataset[, -7]),
  y = dataset[, 7]
)

cv_results_knn &lt;- knn_optimization$execute()

# validate folds
validate_fold_equality(
  list(glm_optimization, knn_optimization)
)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
