<!DOCTYPE html><html lang="en"><head><title>Help for package QRM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {QRM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#QRM-package'><p>Quantitative Risk Modelling</p></a></li>
<li><a href='#BiDensPlot'>
<p>Bivariate Density Plot</p></a></li>
<li><a href='#cac40'>
<p>CAC 40 Stock Market Index (France)</p></a></li>
<li><a href='#CopulaAC'><p>Archimedean Copulae</p></a></li>
<li><a href='#CopulaGauss'>
<p>Gauss Copula</p></a></li>
<li><a href='#CopulaStudent'>
<p>Student's t Copula</p></a></li>
<li><a href='#Credit'>
<p>Credit Risk Modelling</p></a></li>
<li><a href='#danish'>
<p>Danish Fire Losses</p></a></li>
<li><a href='#DJ'>
<p>Dow Jones 30 Stock Prices</p></a></li>
<li><a href='#dji'>
<p>Dow Jones Index</p></a></li>
<li><a href='#edf'>
<p>Empirical Distribution Function</p></a></li>
<li><a href='#eigenmeth'>
<p>Make Matrix Positive Definite</p></a></li>
<li><a href='#equicorr'>
<p>Equal Correlation Matrix</p></a></li>
<li><a href='#ES'>
<p>Expected Shortfall</p></a></li>
<li><a href='#ftse100'>
<p>FTSE 100 Stock Market Index</p></a></li>
<li><a href='#FXGBP.RAW'>
<p>Sterling Exchange Rates</p></a></li>
<li><a href='#game'><p>Smooth Parameter Estimation and Bootstrapping of Generalized Pareto Distributions</p>
with Penalized Maximum Likelihood Estimation</a></li>
<li><a href='#game-aux'><p>Auxiliary Functions for Extracting/Computing Results Related to gamGPDfit()/gamGPDboot()</p></a></li>
<li><a href='#Gauss'>
<p>Multivariate Gauss Distribution</p></a></li>
<li><a href='#GEV'>
<p>Generalized Extreme Value Distribution</p></a></li>
<li><a href='#GHYP'>
<p>Uni- and Multivariate Generalized Hyperbolic Distribution</p></a></li>
<li><a href='#GIG'><p>Generalized Inverse Gaussian Distribution</p></a></li>
<li><a href='#GPD'>
<p>Generalized Pareto Distribution</p></a></li>
<li><a href='#Gumbel'>
<p>Gumbel Distribution</p></a></li>
<li><a href='#hsi'>
<p>Hang Seng Stock Market Index</p></a></li>
<li><a href='#Kendall'>
<p>Kendall's Rank Correlation</p></a></li>
<li><a href='#nasdaq'>
<p>NASDAQ Stock Market Index</p></a></li>
<li><a href='#NH'>
<p>Normal Inverse Gaussian and Hyperbolic Distribution</p></a></li>
<li><a href='#nikkei'>
<p>Nikkei Stock Market Index</p></a></li>
<li><a href='#Pconstruct'>
<p>Assemble a Correlation Matrix for ML Copula Fitting</p></a></li>
<li><a href='#Pdeconstruct'>
<p>Disassemble a Correlation Matrix for ML Copula Fitting</p></a></li>
<li><a href='#POT'>
<p>Peaks-over-Threshold Method</p></a></li>
<li><a href='#QQplot'>
<p>Generic Quantile-Quantile Plot</p></a></li>
<li><a href='#QRM-defunct'><p>Defunct Functions in Package QRM</p></a></li>
<li><a href='#smi'>
<p>Swiss Market Index</p></a></li>
<li><a href='#sp500'>
<p>Standard and Poors 500 Index</p></a></li>
<li><a href='#spdata'>
<p>Standard and Poors Default Data</p></a></li>
<li><a href='#spdata.raw'>
<p>Standard and Poors Default Data</p></a></li>
<li><a href='#Spearman'>
<p>Spearman's Rank Correlation</p></a></li>
<li><a href='#Student'>
<p>Student's t Distribution</p></a></li>
<li><a href='#VaRbound'><p>Computing lower and upper bounds for the (smallest or largest) VaR</p></a></li>
<li><a href='#xdax'>
<p>Xetra DAX German Index</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.4-31</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-02-15</td>
</tr>
<tr>
<td>Title:</td>
<td>Provides R-Language Code to Examine Quantitative Risk Management
Concepts</td>
</tr>
<tr>
<td>Author:</td>
<td>Bernhard Pfaff [aut, cre],
  Marius Hofert [ctb],
  Alexander McNeil [aut] (S-Plus original (QRMlib)),
  Scott Ulmann [trl] (First R port as package QRMlib)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Bernhard Pfaff &lt;bernhard@pfaffikus.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions/methods to accompany the book
 Quantitative Risk Management: Concepts, Techniques and Tools by
 Alexander J. McNeil, Ruediger Frey, and Paul Embrechts.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0), gsl, Matrix, mvtnorm, numDeriv, timeSeries</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.1), mgcv, methods, timeDate</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>LazyData:</td>
<td>Yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Repository/R-Forge/Project:</td>
<td>qrm</td>
</tr>
<tr>
<td>Repository/R-Forge/Revision:</td>
<td>105</td>
</tr>
<tr>
<td>Repository/R-Forge/DateTimeStamp:</td>
<td>2020-01-27 21:36:47</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-15 23:00:02 UTC</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-15 21:25:47 UTC; bp</td>
</tr>
</table>
<hr>
<h2 id='QRM-package'>Quantitative Risk Modelling</h2><span id='topic+QRM-package'></span>

<h3>Description</h3>

<p>This package is designed to accompany the book Quantitative
Risk Management: Concepts, Techniques and Tools by Alexander
J. McNeil, Rudiger Frey and Paul Embrechts.
</p>


<h3>Overview</h3>

<p>This package provides functions for quantitative risk management as
introduced in the book &ldquo;Quantitative Risk Management: Concepts,
Techniques and Tools&rdquo; (henceforth: QRM). The S-Plus package
&ldquo;QRMlib&rdquo; has been made available the first author of the book
and can be obtained by following the instructions on
<a href="https://www.qrmtutorial.org/books">https://www.qrmtutorial.org/books</a>. A R port of
this package has been made available on CRAN by Scott Ulmann. However,
the package failed the checks and hence has been moved to the
CRAN archive (<span class="pkg">QRMlib</span>, version 1.4.5.1 as of 04/25/2011). This
package is based on <span class="pkg">QRMlib</span>, but (i), not all functions have been
ported from <span class="pkg">QRMlib</span> to <span class="pkg">QRM</span>, (ii) the arguments of some
functions have been modified, and (iii) the manual pages have been
re-ordered by topic.<br />
A list of the not ported functions is provided in
<code><a href="#topic+QRM-defunct">QRM-defunct</a></code> with pointers to their replacements. This 
was achieved by the inclusion of dependencies to the packages
<span class="pkg">gsl</span>, <span class="pkg">numDeriv</span> and <span class="pkg">timeSeries</span> and/or resorting to
functions contained in the base installation of R. Second, in
particular with respect to passing down arguments to the routines used
in optimizations and/or argument matching, modifications to the
functions' closures were necessary. In addition, the names of
arguments in similar functions have been unified. Third, to provide
the user a faster access to the manual pages of certain risk concepts,
the functions' documentation are now ordered by concept rather than by
the name of the functions.<br /> 
Without modifying the existing functions of <span class="pkg">QRMlib</span> too much,
neither S3- nor S4-classes and methods have been included completely
by now in <span class="pkg">QRM</span>, but the characteristic of the former package as a
collection of functions pertinent to quantitative risk modelling have
been kept intact. However, this might change in future releases of
<span class="pkg">QRM</span>. By now, the current package can be used almost alike
<span class="pkg">QRMlib</span>, but with the stated modifications. 
</p>


<h3>References</h3>

<p>McNeil, A., Frey, R. and Embrechts, P., <em>Quantitative Risk
Management: Concepts, Techniques and Tools</em>, 2005, Princeton:
Princeton University Press.
</p>

<hr>
<h2 id='BiDensPlot'>
Bivariate Density Plot 
</h2><span id='topic+BiDensPlot'></span>

<h3>Description</h3>

<p>Generates eiether a perspective or a contour plot of a bivariate
density.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BiDensPlot(func, xpts = c(-2, 2), ypts = c(-2, 2), npts = 50,
           type = c("persp", "contour"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BiDensPlot_+3A_func">func</code></td>
<td>
<p><code>function</code>, the name of a bivariate density
function.</p>
</td></tr>
<tr><td><code id="BiDensPlot_+3A_xpts">xpts</code></td>
<td>
<p><code>vector</code>, interval of x.</p>
</td></tr>
<tr><td><code id="BiDensPlot_+3A_ypts">ypts</code></td>
<td>
<p><code>vector</code>, interval of y.</p>
</td></tr>
<tr><td><code id="BiDensPlot_+3A_npts">npts</code></td>
<td>
<p><code>integer</code>, number of subdivision points between x and
y over the specified range xpts to ypts.</p>
</td></tr>
<tr><td><code id="BiDensPlot_+3A_type">type</code></td>
<td>
<p><code>character</code>, the plot type, either a perspective
or a contour plot.</p>
</td></tr>
<tr><td><code id="BiDensPlot_+3A_...">...</code></td>
<td>
<p><code>ellipsis</code>, arguments are passed to the call of
<code>func</code>.</p>
</td></tr>  
</table>


<h3>Value</h3>

<p>Returns invisibly a list of <code>(x, y, z)</code> triplet.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BiDensPlot(func = dmnorm, mu = c(0, 0), Sigma = equicorr(2, -0.7)) 
</code></pre>

<hr>
<h2 id='cac40'>
CAC 40 Stock Market Index (France)
</h2><span id='topic+cac40'></span><span id='topic+cac40.df'></span>

<h3>Description</h3>

<p>This <code>timeSeries</code> data set provides the daily closing values of the
French CAC 40 stock index for the period 1994 to March 2004. In
addition, the data set is also made available as a <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cac40)
data(cac40.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(cac40)
head(cac40)  
</code></pre>

<hr>
<h2 id='CopulaAC'>Archimedean Copulae</h2><span id='topic+dcopula.AC'></span><span id='topic+dcopula.clayton'></span><span id='topic+dcopula.gumbel'></span><span id='topic+rAC'></span><span id='topic+rACp'></span><span id='topic+rcopula.gumbel'></span><span id='topic+rcopula.clayton'></span><span id='topic+rcopula.frank'></span><span id='topic+rstable'></span><span id='topic+rFrankMix'></span><span id='topic+rBB9Mix'></span><span id='topic+rcopula.Gumbel2Gp'></span><span id='topic+rcopula.GumbelNested'></span><span id='topic+fit.AC'></span><span id='topic+rfrank'></span>

<h3>Description</h3>

<p>Functions for ealuating densities of Archimedean copulae, generating
random variates and fitting data to AC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcopula.AC(u, theta, name = c("clayton", "gumbel"), log = TRUE)
dcopula.clayton(u, theta, log = FALSE)
dcopula.gumbel(u, theta, log = FALSE)
rAC(name = c("clayton", "gumbel", "frank", "BB9", "GIG"), n, d, theta)
rACp(name = c("clayton", "gumbel", "frank", "BB9", "GIG"), n, d, theta, A)
rcopula.gumbel(n, theta, d)
rcopula.clayton(n, theta, d)
rcopula.frank(n, theta, d)
rstable(n, alpha, beta = 1)
rFrankMix(n, theta)
rBB9Mix(n, theta)
rcopula.Gumbel2Gp(n = 1000, gpsizes = c(2, 2), theta = c(2, 3, 5))
rcopula.GumbelNested(n, theta)
fit.AC(Udata, name = c("clayton", "gumbel"), initial = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CopulaAC_+3A_a">A</code></td>
<td>
<p><code>matrix</code>, dimension <code class="reqn">d \times p</code> containing asymmetry
parameters. Rowsums must be equal to one.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_alpha">alpha</code></td>
<td>
<p><code>numeric</code>, parameter <code class="reqn">0 &lt; \alpha \le 2</code>, but <code class="reqn">\alpha
      \ne 1</code>.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_beta">beta</code></td>
<td>
<p><code>numeric</code>, parameter <code class="reqn">-1 \le \beta \le 1</code>.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_d">d</code></td>
<td>
<p><code>integer</code>, dimension of copula.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_gpsizes">gpsizes</code></td>
<td>
<p><code>vector</code>, length of two, containing the group
sizes.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_initial">initial</code></td>
<td>
<p><code>numeric</code>, initial value used by <code>fit.AC()</code> in
the call to <code>nlminb()</code>.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log density values should be returned</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_name">name</code></td>
<td>
<p><code>character</code>, name of copula.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_theta">theta</code></td>
<td>
<p><code>vector</code>, copula parameter(s).</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_u">u</code></td>
<td>
<p><code>matrix</code>, dimension <code class="reqn">n \times d</code>, where d is the
dimension of the copula and n is the number of vector values at which
to evaluate density.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_udata">Udata</code></td>
<td>
<p><code>matrix</code>, pseudo-uniform observations.</p>
</td></tr>
<tr><td><code id="CopulaAC_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>nlminb()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>dcopula.AC()</code> is a generic function, designed such
that additional copulae, or expressions for densities of
higher-dimensional copulae may be added. Clayton copula works in any
dimension at present but Gumbel is only implemented for <code class="reqn">d = 2</code>. To extend, one must calculate the d-th derivative of the generator
inverse and take the logarithm of absolute value; this is the term
called <code>loggfunc</code>. In addition, for other copulae, one needs the
generator <code class="reqn">\phi</code> and the log of the negative value of its
first derivative <code>lnegphidash</code>.<br /> 
The random variates from <code>rAC()</code> with arbitrary dimension are
generated by using the mixture construction of Marshall and Olkin. It
may be used in place of the other functions <code>rcopula.clayton()</code>,
<code>rcopula.gumbel()</code>, and <code>rcopula.frank()</code>. In addition, it
allows simulation of BB9 and GIG copulas which don't have individual
simulation routines.<br />
For the Clayton and Gumbel copulae, see page 192 and 222&ndash;224 in
QRM. The random variates for the BB9 and Frank copula are obtained from
a mixing distribution using a Laplace transform method (see page 224 of
QRM). The function <code>rcopula.Gumbel2Gp()</code> generates sample from a
Gumbel copula with two-group structure constructed using three Gumbel
generators (see pages 222-224 and 227 of QRM). The function
<code>rcopula.gumbelNested()</code> generates sample from a d-dimensional
Gumbel copula with nested structure constructed using
<code class="reqn">(d-1)</code> Gumbel generators.<br /> 
For the random variates of the Stable distribution, a default value
<code class="reqn">\beta = 1</code> is used; combined with a value for
<code class="reqn">\alpha &lt; 1</code> yields a positive stable distribution,
which is required for Gumbel copula generation; the case <code class="reqn">\alpha =
 1</code> has not been implemented.   
</p>


<h3>Value</h3>

<p>vector or matrix in case of the density and random-generator related
functions and a list object for the fitting function.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nlminb">nlminb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Gumbel
r1 &lt;- rAC("gumbel", n = 50, d = 7, theta = 3)
head(r1)
## Weighted Gumbel
alpha &lt;- c(0.95,0.7)
wtmatrix &lt;- cbind(alpha, 1 - alpha)
r2 &lt;- rACp(name = "gumbel", n = 1000, d = 2, theta = c(4, 1),
           A = wtmatrix)
head(r2)
## Gumbel with two-group structure
r3 &lt;- rcopula.Gumbel2Gp(n = 3000, gpsizes = c(3, 4),
                        theta = c(2, 3, 5)) 
pairs(r3)
## Nested Gumbel
r4 &lt;- rcopula.GumbelNested(n=3000,theta=1:6) 
pairs(r4) 
## Frank
r5 &lt;- rcopula.frank(1000, 2, 4) 
pairs(r5)
## Fitting of Gumbel and Clayton
data(smi)
data(ftse100)
s1 &lt;- window(ftse100, "1990-11-09", "2004-03-25")
s1a &lt;- alignDailySeries(s1)
s2a &lt;- alignDailySeries(smi)
idx &lt;- merge(s1a, s2a)
r &lt;-returns(idx)
rp &lt;- series(window(r, "1994-01-01", "2003-12-31"))
rp &lt;- rp[(rp[, 1] != 0) &amp; (rp[, 2] !=0), ]
Udata &lt;- apply(rp, 2, edf, adjust = 1)
mod.gumbel &lt;- fit.AC(Udata, "gumbel")
mod.clayton &lt;- fit.AC(Udata, "clayton")
mod.clayton
</code></pre>

<hr>
<h2 id='CopulaGauss'>
Gauss Copula 
</h2><span id='topic+dcopula.gauss'></span><span id='topic+rcopula.gauss'></span><span id='topic+fit.gausscopula'></span>

<h3>Description</h3>

<p>Functions for evaluating the Gauss copula, generating random variates
and fitting. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcopula.gauss(Udata, Sigma, log = FALSE)
rcopula.gauss(n, Sigma)
fit.gausscopula(Udata, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CopulaGauss_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log density values should be
returned.</p>
</td></tr>
<tr><td><code id="CopulaGauss_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates</p>
</td></tr>
<tr><td><code id="CopulaGauss_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code>, correlation matrix.</p>
</td></tr>
<tr><td><code id="CopulaGauss_+3A_udata">Udata</code></td>
<td>
<p><code>matrix</code>, pseudo-uniform data where rows are vector
observations with all values in unit interval.</p>
</td></tr>
<tr><td><code id="CopulaGauss_+3A_...">...</code></td>
<td>
<p>ellipsis argument, passed down to <code>nlminb()</code> used in
optimization.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>For <code>dcopula.gauss()</code> a vector of density values of length n. For
<code>rcopula.gauss()</code> a <code class="reqn">n \times d</code> matrix of random variates
and for <code>fit.gausscopula()</code> a list with the optimization results.    
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nlminb">nlminb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ll &lt;- c(0.01,0.99)
BiDensPlot(func = dcopula.gauss, xpts = ll, ypts = ll,
           Sigma = equicorr(2, 0.5))
data &lt;- rcopula.gauss(2000, Sigma = equicorr(d = 6, rho = 0.7)) 
pairs(data)
## Fitting Gauss Copula
data(smi)
data(ftse100)
s1 &lt;- window(ftse100, "1990-11-09", "2004-03-25")
s1a &lt;- alignDailySeries(s1)
s2a &lt;- alignDailySeries(smi)
idx &lt;- merge(s1a, s2a)
r &lt;-returns(idx)
rp &lt;- series(window(r, "1994-01-01", "2003-12-31"))
rp &lt;- rp[(rp[, 1] != 0) &amp; (rp[, 2] !=0), ]
Udata &lt;- apply(rp, 2, edf, adjust = 1)
copgauss &lt;- fit.gausscopula(Udata) 
</code></pre>

<hr>
<h2 id='CopulaStudent'>
Student's t Copula 
</h2><span id='topic+CopulaStudent'></span><span id='topic+dcopula.t'></span><span id='topic+rcopula.t'></span><span id='topic+fit.tcopula'></span>

<h3>Description</h3>

<p>Functions for copula density, generating random variates and fitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcopula.t(Udata, df, Sigma, log = FALSE)
rcopula.t(n, df, Sigma)
fit.tcopula(Udata, method = c("all", "Kendall", "Spearman"),
            startdf = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CopulaStudent_+3A_df">df</code></td>
<td>
<p><code>numeric</code>, degrees of freedom.</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log density values should be
returned.</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_method">method</code></td>
<td>
<p><code>character</code>, method for fitting.</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code>, correlation matrix</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_startdf">startdf</code></td>
<td>
<p><code>numeric</code>, initial DF value.</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_udata">Udata</code></td>
<td>
<p><code>matrix</code>, dimension <code class="reqn">n \times d</code>, where d is the
dimension of the copula and n is the number of pseudo-uniform
values.</p>
</td></tr>
<tr><td><code id="CopulaStudent_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>nlminb()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If in the call to <code>fit.tcopula()</code>, <code>method = "all"</code>, then
all parameters are estimated, <em>i.e.</em>, the degrees of freedom and
the dispersion parameters (initial values from Spearman
correlations). In case of either <code>method = "Kendall"</code> or
<code>method = "Spearman"</code>, the corresponding rank correlations are
used and the optimization is only carried out with respect to the
degrees of freedom parameter. The initial value for the DF is given by
<code>startdf</code>. See pages 197 and 229&ndash;236 of QRM.   
</p>


<h3>Value</h3>

<p>A vector of density values of length n for <code>dcopula.t()</code>. A
matrix of random variates for <code>rcopula.t()</code>. A list object
containing parameter estimates and details of fit for function
<code>fit.tcopula()</code>.    
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nlminb">nlminb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ll &lt;- c(0.01,0.99)
#create perspective plot for bivariate density:
BiDensPlot(func = dcopula.t, xpts = ll, ypts = ll, df = 4,
           Sigma = equicorr(2, 0.5))
S &lt;- equicorr(d = 6, rho = 0.7)
data &lt;- rcopula.t(2000, df = 4, Sigma = S) 
pairs(data)
## Fitting Student's Copula
data(smi)
data(ftse100)
s1 &lt;- window(ftse100, "1990-11-09", "2004-03-25")
s1a &lt;- alignDailySeries(s1)
s2a &lt;- alignDailySeries(smi)
idx &lt;- merge(s1a, s2a)
r &lt;-returns(idx)
rp &lt;- series(window(r, "1994-01-01", "2003-12-31"))
rp &lt;- rp[(rp[, 1] != 0) &amp; (rp[, 2] !=0), ]
Udata &lt;- apply(rp, 2, edf, adjust = 1)
copt2 &lt;- fit.tcopula(Udata, method = "Kendall")
</code></pre>

<hr>
<h2 id='Credit'>
Credit Risk Modelling 
</h2><span id='topic+Credit'></span><span id='topic+cal.beta'></span><span id='topic+cal.claytonmix'></span><span id='topic+cal.probitnorm'></span><span id='topic+dclaytonmix'></span><span id='topic+pclaytonmix'></span><span id='topic+rclaytonmix'></span><span id='topic+dprobitnorm'></span><span id='topic+pprobitnorm'></span><span id='topic+rprobitnorm'></span><span id='topic+rlogitnorm'></span><span id='topic+rtcopulamix'></span><span id='topic+fit.binomial'></span><span id='topic+fit.binomialBeta'></span><span id='topic+fit.binomialLogitnorm'></span><span id='topic+fit.binomialProbitnorm'></span><span id='topic+momest'></span><span id='topic+rbinomial.mixture'></span>

<h3>Description</h3>

<p>Functions for modelling credit risk:
</p>

<ul>
<li><p> Bernoulli mixture model with prescribed default and joint
default probabilities
</p>
</li>
<li><p> Bernoulli mixture model with Clayton copula dependencies of
default.
</p>
</li>
<li><p> Probitnormal Mixture of Bernoullis
</p>
</li>
<li><p> Beta-Binomial Distribution
</p>
</li>
<li><p> Logitnormal-Binomial Distribution
</p>
</li>
<li><p> Probitnormal-Binomial Distribution
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>cal.beta(pi1, pi2)
cal.claytonmix(pi1, pi2)
cal.probitnorm(pi1, pi2)
dclaytonmix(x, pi, theta) 
pclaytonmix(q, pi, theta) 
rclaytonmix(n, pi, theta)
rtcopulamix(n, pi, rho.asset, df)
dprobitnorm(x, mu, sigma) 
pprobitnorm(q, mu, sigma) 
rprobitnorm(n, mu, sigma)
rbinomial.mixture(n = 1000, m = 100,
                  model = c("probitnorm", "logitnorm", "beta"), ...)
rlogitnorm(n, mu, sigma)
fit.binomial(M, m)
fit.binomialBeta(M, m, startvals = c(2, 2), ses = FALSE, ...)
fit.binomialLogitnorm(M, m, startvals = c(-1, 0.5), ...)
fit.binomialProbitnorm(M, m, startvals = c(-1, 0.5), ...)
momest(data, trials, limit = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Credit_+3A_data">data</code></td>
<td>
<p><code>vector</code>, numbers of defaults in each time period.</p>
</td></tr>
<tr><td><code id="Credit_+3A_df">df</code></td>
<td>
<p><code>numeric</code>, degree of freedom.</p>
</td></tr>
<tr><td><code id="Credit_+3A_limit">limit</code></td>
<td>
<p><code>intgeger</code>, maximum order of joint default probability
to estimate.</p>
</td></tr> 
<tr><td><code id="Credit_+3A_m">M</code></td>
<td>
<p><code>vector</code>, count of successes.</p>
</td></tr>
<tr><td><code id="Credit_+3A_m">m</code></td>
<td>
<p><code>vector</code>, count of trials.</p>
</td></tr>
<tr><td><code id="Credit_+3A_model">model</code></td>
<td>
<p><code>character</code>, name of mixing distribution.</p>
</td></tr> 
<tr><td><code id="Credit_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameter.</p>
</td></tr>
<tr><td><code id="Credit_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="Credit_+3A_pi">pi</code></td>
<td>
<p><code>numeric</code>, default probability.</p>
</td></tr>
<tr><td><code id="Credit_+3A_pi1">pi1</code></td>
<td>
<p><code>numeric</code>, default probability.</p>
</td></tr>
<tr><td><code id="Credit_+3A_pi2">pi2</code></td>
<td>
<p><code>numeric</code>, joint default probability.</p>
</td></tr>
<tr><td><code id="Credit_+3A_q">q</code></td>
<td>
<p><code>numeric</code>, values at which CDF should be evaluated.</p>
</td></tr> 
<tr><td><code id="Credit_+3A_sigma">sigma</code></td>
<td>
<p><code>numeric</code>, scale parameter.</p>
</td></tr>
<tr><td><code id="Credit_+3A_ses">ses</code></td>
<td>
<p><code>logical</code>, whether standard errors should be returned.</p>
</td></tr>
<tr><td><code id="Credit_+3A_startvals">startvals</code></td>
<td>
<p><code>numeric</code>, starting values.</p>
</td></tr>
<tr><td><code id="Credit_+3A_theta">theta</code></td>
<td>
<p><code>numeric</code>, parameter of distribution.</p>
</td></tr>
<tr><td><code id="Credit_+3A_trials">trials</code></td>
<td>
<p><code>vector</code>, group sizes in each time period.</p>
</td></tr>
<tr><td><code id="Credit_+3A_x">x</code></td>
<td>
<p><code>numeric</code>, values at which density should be evaluated.</p>
</td></tr>
<tr><td><code id="Credit_+3A_rho.asset">rho.asset</code></td>
<td>
<p><code>numeric</code>, asset correlation parameter.</p>
</td></tr>
<tr><td><code id="Credit_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to either mixing
distribution or <code>nlminb()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cal.beta()</code>: calibrates a beta mixture distribution on unit
interval to give an exchangeable Bernoulli mixture model with
prescribed default and joint default probabilities (see pages 354-355
in QRM).<br /> 
<code>cal.claytonmix()</code>: calibrates a mixture distribution on unit
interval to give an exchangeable Bernoulli mixture model with
prescribed default and joint default probabilities. The mixture
distribution is the one implied by a Clayton copula model of default
(see page 362 in QRM).<br /> 
<code>cal.probitnorm()</code>: calibrates a probitnormal mixture
distribution on unit interval to give an exchangeable Bernoulli
mixture model with prescribed default and joint default probabilities
(see page 354 in QRM).<br />
<code>dclaytonmix()</code>, <code>pclaytonmix()</code>, <code>rclaytonmix()</code>:
density, cumulative probability, and random generation for a mixture
distribution on the unit interval which gives an exchangeable
Bernoulli mixture model equivalent to a Clayton copula model (see page
362 in QRM).<br /> 
<code>fit.binomial()</code>: fits binomial distribution by maximum
likelihood.<br /> 
<code>dprobitnorm()</code>, <code>pprobitnorm()</code>, <code>rprobitnorm()</code>:
density, cumulative probability and random number generation for
distribution of random variable Q on unit interval such that the
probit transform of Q has a normal distribution with parameters
<code class="reqn">\mu</code> and <code class="reqn">\sigma</code> (see pages 353-354 in QRM).<br />   
<code>fit.binomialBeta()</code>: fit a beta-binomial distribution by maximum
likelihood.<br /> 
<code>fit.binomialLogitnorm()</code>: fits a mixed binomial distribution
where success probability has a logitnormal distribution. Lower and
upper bounds for the input parameters M and m can be specified by
means of the arguments <code>lower</code> and <code>upper</code>, which are passed to
<code>nlminb()</code>. If convergence occurs at an endpoint of either limit,
one need to reset lower and upper parameter estimators and run the
function again.<br /> 
<code>fit.binomialProbitnorm()</code>: Fits a mixed binomial distribution
where success probability has a probitnormal distribution. Lower and
upper bounds for the input parameters M and m can be specified by
means of the arguments <code>lower</code> and <code>upper</code>, which are passed to
<code>nlminb()</code>. If convergence occurs at an endpoint of either limit,
one need to reset lower and upper parameter estimators and run the
function again.<br />
<code>momest()</code>: calculates moment estimator of default probabilities
and joint default probabilities for a homogeneous group. First
returned value is default probability estimate; second value is
estimate of joint default probability for two firms; and so on (see
pages 375-376 in QRM).<br />
<code>rbinomial.mixture()</code>: random variates from mixed binomial
distribution (see pages 354-355 and pages 375-377 of QRM).<br />
<code>rlogitnorm()</code>: Random number generation for distribution of
random variable Q on unit interval such that the probit transform of Q
has a normal distribution with parameters <code class="reqn">\mu</code> and
<code class="reqn">\sigma</code> (see pages 353-354 in QRM).<br />
<code>rtcopulamix()</code>: random generation for mixing distribution on
unit interval yielding Student's t copula model (see page 361 in QRM,
exchangeable case of this model is considered). 
</p>


<h3>See Also</h3>

<p><code>link[stats]{nlminb}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## calibrating models
pi.B &lt;- 0.2
pi2.B &lt;- 0.05 
probitnorm.pars &lt;- cal.probitnorm(pi.B, pi2.B) 
probitnorm.pars 
beta.pars &lt;- cal.beta(pi.B, pi2.B) 
beta.pars 
claytonmix.pars &lt;- cal.claytonmix(pi.B, pi2.B) 
claytonmix.pars 
q &lt;- (1:1000) / 1001 
q &lt;- q[q &lt; 0.25] 
p.probitnorm &lt;- pprobitnorm(q, probitnorm.pars[1],
                            probitnorm.pars[2]) 
p.beta &lt;- pbeta(q, beta.pars[1], beta.pars[2]) 
p.claytonmix &lt;- pclaytonmix(q, claytonmix.pars[1],
                            claytonmix.pars[2]) 
scale &lt;- range((1 - p.probitnorm), (1 - p.beta), (1 - p.claytonmix)) 
plot(q, (1 - p.probitnorm), type = "l", log = "y", xlab = "q", 
           ylab = "P(Q &gt; q)",ylim=scale) 
lines(q, (1 - p.beta), col = 2) 
lines(q, (1 - p.claytonmix), col = 3) 
legend("topright", c("Probit-normal", "Beta", "Clayton-Mixture"), 
          lty=rep(1,3),col = (1:3))
## Clayton Mix
pi.B &lt;- 0.0489603 
pi2.B &lt;- 0.003126529 
claytonmix.pars &lt;- cal.claytonmix(pi.B, pi2.B)
claytonmix.pars
q &lt;- (1:1000) / 1001
q &lt;- q[q &lt; 0.25]
d.claytonmix &lt;- dclaytonmix(q, claytonmix.pars[1], claytonmix.pars[2])
head(d.claytonmix)
## SP Data
data(spdata.raw) 
attach(spdata.raw) 
BdefaultRate &lt;- Bdefaults / Bobligors 
## Binomial Model
mod1a &lt;- fit.binomial(Bdefaults, Bobligors)
## Binomial Logitnorm Model
mod1b &lt;- fit.binomialLogitnorm(Bdefaults, Bobligors) 
## Binomial Probitnorm Model
mod1c &lt;- fit.binomialProbitnorm(Bdefaults, Bobligors)
## Binomial Beta Model
mod1d &lt;- fit.binomialBeta(Bdefaults, Bobligors); 
## Moment estimates for default probabilities
momest(Bdefaults, Bobligors)
pi.B &lt;- momest(Bdefaults, Bobligors)[1]
pi2.B &lt;- momest(Bdefaults, Bobligors)[2]
## Probitnorm
probitnorm.pars &lt;- cal.probitnorm(pi.B, pi2.B) 
q &lt;- (1:1000)/1001
q &lt;- q[ q &lt; 0.25]
d.probitnorm &lt;- dprobitnorm(q, probitnorm.pars[1], probitnorm.pars[2])
p &lt;- c(0.90,0.95,0.975,0.99,0.995,0.999,0.9999,0.99999,0.999999)
sigma &lt;- 0.2 * 10000 / sqrt(250)
VaR.t4 &lt;- qst(p, df = 4, sd = sigma, scale = TRUE)
VaR.t4
detach(spdata.raw)
## Binomial Mixture Models
pi &lt;- 0.04896 
pi2 &lt;- 0.00321 
beta.pars &lt;- cal.beta(pi, pi2)
probitnorm.pars &lt;- cal.probitnorm(pi, pi2) 
n &lt;- 1000 
m &lt;- rep(500, n) 
mod2a &lt;- rbinomial.mixture(n, m, "beta", shape1 = beta.pars[1],
                          shape2 = beta.pars[2]) 
mod2b &lt;- rbinomial.mixture(n, m, "probitnorm",
                          mu = probitnorm.pars[1],
                          sigma = probitnorm.pars[2])
</code></pre>

<hr>
<h2 id='danish'>
Danish Fire Losses
</h2><span id='topic+danish'></span><span id='topic+danish.df'></span>

<h3>Description</h3>

<p>The <code>danish</code> timeSeries dataset provides the daily closing value
for the Danish fire losses measured from January 1980 through December
1990. In addition, the data set is also made available as a
<code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(danish)
data(danish.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
head(danish)  
</code></pre>

<hr>
<h2 id='DJ'>
Dow Jones 30 Stock Prices
</h2><span id='topic+DJ'></span><span id='topic+DJ.df'></span>

<h3>Description</h3>

<p>The <code>DJ</code> timeSeries data set provides the closing values of the
Dow Jones 30 Stocks from 1991-2000. In addition, the data set is also
made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DJ)
data(DJ.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(DJ)
head(DJ)  
</code></pre>

<hr>
<h2 id='dji'>
Dow Jones Index
</h2><span id='topic+dji'></span><span id='topic+dji.df'></span>

<h3>Description</h3>

<p>The <code>dji</code> timeSeries dataset provides the daily closing value for
the Dow Jones index from January 1980 to March 2004. In addition, the
data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dji)
data(dji.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(dji)
head(dji)  
</code></pre>

<hr>
<h2 id='edf'>
Empirical Distribution Function 
</h2><span id='topic+edf'></span>

<h3>Description</h3>

<p>This function calculates the empirical distribution function at each
element of a vector of observations.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edf(v, adjust = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="edf_+3A_v">v</code></td>
<td>
<p><code>vector</code>, observations of length n.</p>
</td></tr>
<tr><td><code id="edf_+3A_adjust">adjust</code></td>
<td>
<p><code>logical</code>, adjustment of denominator to be (n + 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(smi)
data(ftse100)
s1 &lt;- window(ftse100, "1990-11-09", "2004-03-25")
s1a &lt;- alignDailySeries(s1)
s2a &lt;- alignDailySeries(smi)
idx &lt;- merge(s1a, s2a)
r &lt;-returns(idx)
rp &lt;- series(window(r, "1994-01-01", "2003-12-31"))
rp &lt;- rp[(rp[, 1] != 0) &amp; (rp[, 2] !=0), ]
Udata &lt;- apply(rp, 2, edf, adjust = 1)
plot(Udata)
</code></pre>

<hr>
<h2 id='eigenmeth'>
Make Matrix Positive Definite 
</h2><span id='topic+eigenmeth'></span>

<h3>Description</h3>

<p>The function adjusts a negative definite symmetric matrix to make it
positive definite.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigenmeth(mat, delta = 0.001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eigenmeth_+3A_mat">mat</code></td>
<td>
<p><code>matrix</code>, a symmetric matrix</p>
</td></tr>
<tr><td><code id="eigenmeth_+3A_delta">delta</code></td>
<td>
<p><code>numeric</code>, new size of smallest eigenvalues</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See page 231 of QRM. 
</p>


<h3>Value</h3>

<p>a positive-definite matrix 
</p>

<hr>
<h2 id='equicorr'>
Equal Correlation Matrix 
</h2><span id='topic+equicorr'></span>

<h3>Description</h3>

<p>Construction of an equal correlation matrix 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equicorr(d, rho)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="equicorr_+3A_d">d</code></td>
<td>
<p>integer, dimension of matrix</p>
</td></tr> 
<tr><td><code id="equicorr_+3A_rho">rho</code></td>
<td>
<p>numeric, value of correlation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>equicorr(7, 0.5)
ll &lt;- c(0.01, 0.99)
BiDensPlot(func = dcopula.gauss, xpts = ll, ypts = ll,
           Sigma = equicorr(2,0.5))
BiDensPlot(func = dcopula.t, xpts = ll, ypts = ll , df = 4,
           Sigma = equicorr(2, 0.5)) 
</code></pre>

<hr>
<h2 id='ES'>
Expected Shortfall 
</h2><span id='topic+ES'></span><span id='topic+ESnorm'></span><span id='topic+ESst'></span>

<h3>Description</h3>

<p>Functions for computing the expected shortfall derived from the Normal
or Student's t distribution (see page 45 of QRM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESnorm(p, mu = 0, sd = 1)
ESst(p, mu = 0, sd = 1, df, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ES_+3A_p">p</code></td>
<td>
<p><code>numeric</code>, probability</p>
</td></tr>
<tr><td><code id="ES_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameter</p>
</td></tr>
<tr><td><code id="ES_+3A_sd">sd</code></td>
<td>
<p><code>numeric</code>, scale parameter</p>
</td></tr>
<tr><td><code id="ES_+3A_df">df</code></td>
<td>
<p><code>numeric</code>, degrees of freedom</p>
</td></tr>
<tr><td><code id="ES_+3A_scale">scale</code></td>
<td>
<p>logical, scaling Student's t distribution to have variance one</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(0.95, 0.99)
s &lt;- 0.2 * 10000 / sqrt(250)
ESnorm(p)
ESst(p, sd = s, df = 4, scale = TRUE)
ESst(p, df = 4)
</code></pre>

<hr>
<h2 id='ftse100'>
FTSE 100 Stock Market Index
</h2><span id='topic+ftse100'></span><span id='topic+ftse100.df'></span>

<h3>Description</h3>

<p>The <code>ftse100</code> timeSeries dataset provides the daily closing value
for the FTSE index from January 1980 to March 2004. In addition, the
data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ftse100)
data(ftse100.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(ftse100)
head(ftse100)  
</code></pre>

<hr>
<h2 id='FXGBP.RAW'>
Sterling Exchange Rates 
</h2><span id='topic+FXGBP'></span><span id='topic+FXGBP.df'></span>

<h3>Description</h3>

<p>The <code>FXGBP</code> timeSeries dataset provides daily exchange rates for
major currencies (US Dollar, Japanese Yen, Euro, Swiss franc) against
the British Pound for the period January 1987 through March 2004. In
addition, the data set is also made available as a <code>data.frame</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(FXGBP)
data(FXGBP.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(FXGBP)
</code></pre>

<hr>
<h2 id='game'>Smooth Parameter Estimation and Bootstrapping of Generalized Pareto Distributions
with Penalized Maximum Likelihood Estimation</h2><span id='topic+gamGPDfit'></span><span id='topic+gamGPDboot'></span>

<h3>Description</h3>

<p><code>gamGPDfit()</code> fits the parameters of a generalized Pareto
distribution (GPD) depending on covariates in a non- or semiparametric
way.
</p>
<p><code>gamGPDboot()</code> fits and bootstraps the parameters of a GPD
distribution depending on covariates in a non- or semiparametric
way. Applies the post-blackend bootstrap of Chavez-Demoulin and
Davison (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamGPDfit(x, threshold, nextremes = NULL, datvar, xiFrhs, nuFrhs,
          init = fit.GPD(x[,datvar], threshold = threshold,
                         type = "pwm", verbose = FALSE)$par.ests,
          niter = 32, include.updates = FALSE, eps.xi = 1e-05, eps.nu = 1e-05,
          progress = TRUE, adjust = TRUE, verbose = FALSE, ...)
gamGPDboot(x, B, threshold, nextremes = NULL, datvar, xiFrhs, nuFrhs,
           init = fit.GPD(x[,datvar], threshold = threshold,
                          type = "pwm", verbose = FALSE)$par.ests,
           niter = 32, include.updates = FALSE, eps.xi = 1e-5, eps.nu = 1e-5,
           boot.progress = TRUE, progress = FALSE, adjust = TRUE, verbose = FALSE,
           debug = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="game_+3A_x">x</code></td>
<td>
<p>data.frame containing the losses (in some component; can be
specified with the argument <code>datvar</code>; the other components
contain the covariates).</p>
</td></tr>
<tr><td><code id="game_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications.</p>
</td></tr>
<tr><td><code id="game_+3A_threshold">threshold</code></td>
<td>
<p>threshold of the peaks-over-threshold (POT)
method.</p>
</td></tr>
<tr><td><code id="game_+3A_nextremes">nextremes</code></td>
<td>
<p>number of excesses. This can be used to determine</p>
</td></tr>
<tr><td><code id="game_+3A_datvar">datvar</code></td>
<td>
<p>name of the data column in <code>x</code> which contains the
the data to be modeled.</p>
</td></tr>
<tr><td><code id="game_+3A_xifrhs">xiFrhs</code></td>
<td>
<p>right-hand side of the formula for <code class="reqn">\xi</code> in
the <code>gam()</code> call for fitting <code class="reqn">\xi</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_nufrhs">nuFrhs</code></td>
<td>
<p>right-hand side of the formula for <code class="reqn">\nu</code> in
the <code>gam()</code> call for fitting <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_init">init</code></td>
<td>
<p>bivariate vector containing initial values
for <code class="reqn">(\xi, \beta)</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_niter">niter</code></td>
<td>
<p>maximal number of iterations in the backfitting
algorithm.</p>
</td></tr>
<tr><td><code id="game_+3A_include.updates">include.updates</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating whether
updates for xi and nu are returned as well (note: this might lead to
objects of large size).</p>
</td></tr>
<tr><td><code id="game_+3A_eps.xi">eps.xi</code></td>
<td>
<p>epsilon for stop criterion for <code class="reqn">\xi</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_eps.nu">eps.nu</code></td>
<td>
<p>epsilon for stop criterion for <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_boot.progress">boot.progress</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating
whether progress information about <code>gamGPDboot()</code> is displayed.</p>
</td></tr>
<tr><td><code id="game_+3A_progress">progress</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating whether progress information about
<code>gamGPDfit()</code> is displayed. For <code>gamGPDboot()</code>,
<code>progress</code> is only passed to <code>gamGPDfit()</code> in the case that
<code>boot.progress==TRUE</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_adjust">adjust</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating whether non-real values
of the derivatives are adjusted.</p>
</td></tr>
<tr><td><code id="game_+3A_verbose">verbose</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating whether additional
information (in case of undesired behavior) is printed. For <code>gamGPDboot()</code>,
<code>progress</code> is only passed to <code>gamGPDfit()</code> if
<code>boot.progress==TRUE</code>.</p>
</td></tr>
<tr><td><code id="game_+3A_debug">debug</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating whether initial fit
(before the bootstrap is initiated) is saved.</p>
</td></tr>
<tr><td><code id="game_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>gam()</code> (which is
called internally; see the source code of <code>gamGPDfitUp()</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gamGPDfit()</code> fits the parameters <code class="reqn">\xi</code> and
<code class="reqn">\beta</code> of the generalized Pareto distribution
<code class="reqn">\mathrm{GPD}(\xi,\beta)</code> depending on covariates in
a non- or semiparametric way. The distribution function is given by
</p>
<p style="text-align: center;"><code class="reqn">G_{\xi,\beta}(x)=1-(1+\xi x/\beta)^{-1/\xi},\quad
    x\ge0,</code>
</p>

<p>for <code class="reqn">\xi&gt;0</code> (which is what we assume) and
<code class="reqn">\beta&gt;0</code>. Note that <code class="reqn">\beta</code> is also denoted by
<code class="reqn">\sigma</code> in this package. Estimation of <code class="reqn">\xi</code>
and <code class="reqn">\beta</code> by <code>gamGPDfit()</code> is done via penalized maximum
likelihood estimation, where the estimators are computed with a
backfitting algorithm. In order to guarantee convergence of this
algorithm, a reparameterization of <code class="reqn">\beta</code> in terms of the parameter
<code class="reqn">\nu</code> is done via
</p>
<p style="text-align: center;"><code class="reqn">\beta=\exp(\nu)/(1+\xi).</code>
</p>

<p>The parameters <code class="reqn">\xi</code> and <code class="reqn">\nu</code> (and thus
<code class="reqn">\beta</code>) are allowed to depend on covariates (including
time) in a non- or semiparametric way, for example:
</p>
<p style="text-align: center;"><code class="reqn">\xi=\xi(\bm{x},t)=\bm{x}^{\top}\bm{\alpha}_{\xi}+h_{\xi}(t),</code>
</p>

<p style="text-align: center;"><code class="reqn">\nu=\nu(\bm{x},t)=\bm{x}^{\top}\bm{\alpha}_{\nu}+h_{\nu}(t),</code>
</p>

<p>where <code class="reqn">\bm{x}</code> denotes the vector of covariates,
<code class="reqn">\bm{\alpha}_{\xi}</code>, <code class="reqn">\bm{\alpha}_{\nu}</code>
are parameter vectors and <code class="reqn">h_{\xi}</code>, <code class="reqn">h_{\nu}</code> are
regression splines. For more details, see the references and the source
code.
</p>
<p><code>gamGPDboot()</code> first fits the GPD parameters via
<code>gamGPDfit()</code>. It then conducts the post-blackend bootstrap of
Chavez-Demoulin and Davison (2005). To this end, it computes the
residuals, resamples them (<code>B</code> times), reconstructs the
corresponding excesses, and refits the GPD parameters via
<code>gamGPDfit()</code> again.
</p>
<p>Note that if <code><a href="mgcv.html#topic+gam">gam</a>()</code> fails in <code>gamGPDfit()</code> or the
fitting or one of the bootstrap replications in <code>gamGPDboot()</code>,
then the output object contains (an) empty (sub)list(s). These
failures typically happen for too small sample sizes.
</p>


<h3>Value</h3>

<p><code>gamGPDfit()</code> returns either an empty list (<code>list()</code>; in
case at least one of the two <code><a href="mgcv.html#topic+gam">gam</a>()</code> calls in the internal
function <code>gamGPDfitUp()</code> fails) or a list with the components
</p>

<dl>
<dt><code>xi</code>:</dt><dd><p>estimated parameters <code class="reqn">\xi</code>;</p>
</dd>
<dt><code>beta</code>:</dt><dd><p>estimated parameters <code class="reqn">\beta</code>;</p>
</dd>
<dt><code>nu</code>:</dt><dd><p>estimated parameters <code class="reqn">\nu</code>;</p>
</dd>
<dt><code>se.xi</code>:</dt><dd><p>standard error for <code class="reqn">\xi</code> ((possibly
adjusted) second-order derivative of the reparameterized
log-likelihood with respect to <code class="reqn">\xi</code>) multiplied by -1;</p>
</dd>
<dt><code>se.nu</code>:</dt><dd><p>standard error for <code class="reqn">\nu</code> ((possibly
adjusted) second-order derivative of the reparameterized
log-likelihood with respect to <code class="reqn">\nu</code>) multiplied by -1;</p>
</dd>
<dt><code>xi.covar</code>:</dt><dd><p>(unique) covariates for <code class="reqn">\xi</code>;</p>
</dd>
<dt><code>nu.covar</code>:</dt><dd><p>(unique) covariates for <code class="reqn">\nu</code>;</p>
</dd>
<dt><code>covar</code>:</dt><dd><p>available covariate combinations used for
fitting <code class="reqn">\beta</code> (<code class="reqn">\xi</code>, <code class="reqn">\nu</code>);</p>
</dd>
<dt><code>y</code>:</dt><dd><p>vector of excesses (exceedances minus threshold);</p>
</dd>
<dt><code>res</code>:</dt><dd><p>residuals;</p>
</dd>
<dt><code>MRD</code>:</dt><dd><p>mean relative distances between for all
iterations, calculated between old parameters <code class="reqn">(\xi, \nu)</code> (from the last iteration) and new parameters (currently
estimated ones);</p>
</dd>
<dt><code>logL</code>:</dt><dd><p>log-likelihood at the estimated parameters;</p>
</dd>
<dt><code>xiObj</code>:</dt><dd><p><span class="rlang"><b>R</b></span> object of type <code>gamObject</code> for estimated
<code class="reqn">\xi</code> (returned by <code>mgcv::gam()</code>);</p>
</dd>
<dt><code>nuObj</code>:</dt><dd><p><span class="rlang"><b>R</b></span> object of type <code>gamObject</code> for estimated
<code class="reqn">\nu</code> (returned by <code>mgcv::gam()</code>);</p>
</dd>
<dt><code>xiUpdates</code>:</dt><dd><p>if <code>include.updates</code> is
<code><a href="base.html#topic+TRUE">TRUE</a></code>, updates for <code class="reqn">\xi</code> for each
iteration. This is a list of <span class="rlang"><b>R</b></span> objects of type <code>gamObject</code>
which contains <code>xiObj</code> as last element;</p>
</dd>
<dt><code>nuUpdates</code>:</dt><dd><p>if <code>include.updates</code> is
<code><a href="base.html#topic+TRUE">TRUE</a></code>, updates for <code class="reqn">\nu</code> for each
iteration. This is a list of <span class="rlang"><b>R</b></span> objects of type <code>gamObject</code>
which contains <code>nuObj</code> as last element;</p>
</dd>
</dl>

<p><code>gamGPDboot()</code> returns a list of length <code>B+1</code> where
the first component contains the results of
the initial fit via <code>gamGPDfit()</code> and the other <code>B</code>
components contain the results for each replication of the
post-blackend bootstrap. Components for which <code><a href="mgcv.html#topic+gam">gam</a>()</code>
fails (e.g., due to too few data) are given as empty lists (<code>list()</code>).
</p>


<h3>Author(s)</h3>

<p>Marius Hofert, Valerie Chavez-Demoulin.</p>


<h3>References</h3>

<p>Chavez-Demoulin, V., and Davison, A. C. (2005).
Generalized additive models for sample extremes.
<em>Applied Statistics</em> <b>54</b>(1), 207&ndash;222.
</p>
<p>Chavez-Demoulin, V., Embrechts, P., and Hofert, M. (2014).
An extreme value approach for modeling Operational
Risk losses depending on covariates.
<em>Journal of Risk and Insurance</em>; accepted.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(QRM)
## generate an example data set
years &lt;- 2003:2012 # years
nyears &lt;- length(years)
n &lt;- 250 # sample size for each (different) xi
u &lt;- 200 # threshold
rGPD &lt;- function(n, xi, beta) ((1-runif(n))^(-xi)-1)*beta/xi # sampling GPD

set.seed(17) # setting seed
xi.true.A &lt;- seq(0.4, 0.8, length=nyears) # true xi for group "A"
## generate losses for group "A"
lossA &lt;- unlist(lapply(1:nyears,
                       function(y) u + rGPD(n, xi=xi.true.A[y], beta=1)))
xi.true.B &lt;- xi.true.A^2 # true xi for group "B"
## generate losses for group "B"
lossB &lt;- unlist(lapply(1:nyears,
                       function(y) u + rGPD(n, xi=xi.true.B[y], beta=1)))
## build data frame
time &lt;- rep(rep(years, each=n), 2) # "2" stands for the two groups
covar &lt;- rep(c("A","B"), each=n*nyears)
value &lt;- c(lossA, lossB)
x &lt;- data.frame(covar=covar, time=time, value=value)

## fit
eps &lt;- 1e-3 # to decrease the run time for this example
require(mgcv) # due to s()
fit &lt;- gamGPDfit(x, threshold=u, datvar="value", xiFrhs=~covar+s(time)-1,
                 nuFrhs=~covar+s(time)-1, eps.xi=eps, eps.nu=eps)
## note: choosing s(..., bs="cr") will fit cubic splines

## grab the fitted values per group and year
xi.fit &lt;- fitted(fit$xiObj)
xi.fit. &lt;- xi.fit[1+(0:(2*nyears-1))*n] # pick fit for each group and year
xi.fit.A &lt;- xi.fit.[1:nyears] # fit for "A" and each year
xi.fit.B &lt;- xi.fit.[(nyears+1):(2*nyears)] # fit for "B" and each year

## plot the fitted values of xi and the true ones we simulated from
par(mfrow=c(1,2))
plot(years, xi.true.A, type="l", ylim=range(xi.true.A, xi.fit.A),
     main="Group A", xlab="Year", ylab=expression(xi))
points(years, xi.fit.A, type="l", col="red")
legend("topleft", inset=0.04, lty=1, col=c("black", "red"),
       legend=c("true", "fitted"), bty="n")
plot(years, xi.true.B, type="l", ylim=range(xi.true.B, xi.fit.B),
     main="Group B", xlab="Year", ylab=expression(xi))
points(years, xi.fit.B, type="l", col="blue")
legend("topleft", inset=0.04, lty=1, col=c("black", "blue"),
       legend=c("true", "fitted"), bty="n")
</code></pre>

<hr>
<h2 id='game-aux'>Auxiliary Functions for Extracting/Computing Results Related to gamGPDfit()/gamGPDboot()</h2><span id='topic+get.gam.fit'></span><span id='topic+gam.predict'></span><span id='topic+get.GPD.fit'></span><span id='topic+GPD.predict'></span><span id='topic+risk.measure'></span>

<h3>Description</h3>

<p><code>get.gam.fit()</code> extracts a convenient list containing unique
covariate combinations and corresponding fitted values from an
object returned by <code><a href="mgcv.html#topic+gam">gam</a>()</code>.
</p>
<p><code>gam.predict()</code> computes a convenient list containing unique
covariate combinations and corresponding predicted values and
pointwise asymptotic confidence intervals (obtained from the estimated
standard errors obtained by <code>predict(..., se.fit=TRUE)</code>).
</p>
<p><code>get.GPD.fit()</code> extracts a convenient list containing (for each
of the GPD parameters) unique
covariate combinations, the fitted GPD parameter (vector),
bootstrapped pointwise two-sided 1-<code class="reqn">\alpha</code> confidence
intervals, and a matrix of bootstrapped parameter values.
</p>
<p><code>GPD.predict()</code> computes a convenient list containing (for each
of the GPD parameters) unique
covariate combinations and  corresponding predicted values.
</p>
<p><code>risk.measure()</code> computes the selected risk measure at a matrix
of values for <code class="reqn">\rho</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.gam.fit(x)
gam.predict(x, newdata=NULL, alpha=0.05, value=c("lambda", "rho"))
get.GPD.fit(x, alpha=0.05)
GPD.predict(x, xi.newdata=NULL, beta.newdata=NULL)

risk.measure(x, alpha, u, method = c("VaR", "ES"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="game-aux_+3A_x">x</code></td>
<td>
<p>For <code>get.gam.fit()</code> and <code>gam.predict()</code>
an object as returned by <code><a href="mgcv.html#topic+gam">gam</a>()</code>; for
<code>get.GPD.fit()</code> and <code>GPD.predict()</code> an object as returned by
<code><a href="#topic+gamGPDboot">gamGPDboot</a>()</code>; for <code>risk.measure()</code> a matrix with
three columns containing an estimate <code class="reqn">\rho</code> of the tail of
the loss distribution at the threshold <code>u</code> for a covariate
combination, the corresponding <code class="reqn">\xi</code> and the
corresponding <code class="reqn">\beta</code> (in this order).</p>
</td></tr>
<tr><td><code id="game-aux_+3A_newdata">newdata</code></td>
<td>
<p>object as required by
<code><a href="stats.html#topic+predict">predict</a>()</code>. Typically a named <code><a href="base.html#topic+data.frame">data.frame</a></code>
of type <code>expand.grid(covar1=, covar2=)</code> with at least the covariates
used for fitting with <code><a href="mgcv.html#topic+gam">gam</a>()</code>; if more are provided,
<code><a href="stats.html#topic+predict">predict</a>()</code> returns values which are equal uniformly
over all of these additional covariates. Each covariate which
appears when fitting with <code><a href="mgcv.html#topic+gam">gam</a>()</code> can
have more values than were actually used in <code><a href="mgcv.html#topic+gam">gam</a>()</code>.
In this case <code><a href="stats.html#topic+predict">predict</a>()</code> &ldquo;interpolates&rdquo; correctly with the
fitted model.</p>
</td></tr>
<tr><td><code id="game-aux_+3A_xi.newdata">xi.newdata</code>, <code id="game-aux_+3A_beta.newdata">beta.newdata</code></td>
<td>
<p>as <code>newdata</code>, just for the GPD
parameters <code class="reqn">\xi</code> and <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="game-aux_+3A_alpha">alpha</code></td>
<td>
<p>for <code>gam.predict()</code>,
<code>get.GPD.fit()</code> the significance level
(typcially 0.05); for <code>risk.measure()</code> the confidence level
(typically close to 1).</p>
</td></tr>
<tr><td><code id="game-aux_+3A_u">u</code></td>
<td>
<p>threshold.</p>
</td></tr>
<tr><td><code id="game-aux_+3A_value">value</code></td>
<td>
<p>either <code>"lambda"</code> or <code>"rho"</code> depending on
whether <code class="reqn">\lambda</code> or <code class="reqn">\rho</code> is predicted.</p>
</td></tr>
<tr><td><code id="game-aux_+3A_method">method</code></td>
<td>
<p><code><a href="base.html#topic+character">character</a></code> string indicating the kind of
risk measure (Value-at-Risk (<code>VaR</code>) or expected shortfall
(<code>ES</code>)).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if <code><a href="mgcv.html#topic+gam">gam</a>()</code> fails in <code>gamGPDfit()</code> or the
fitting or one of the bootstrap replications in <code>gamGPDboot()</code>,
then <code>x</code> contains (an) empty (sub)list(s). These empty lists will
be removed from the output of <code>get.GPD.fit()</code>. Hence, the
subcomponent <code>xi$fit</code> of the output of <code>get.GPD.fit()</code> can
contain less columns than the chosen number of bootstrap replications
for creating <code>x</code> (each bootstrap replication with failed
<code><a href="mgcv.html#topic+gam">gam</a>()</code> calls is omitted). If there is any such failure,
<code>get.GPD.fit()</code> outputs a warning. These
failures typically happen for too small sample sizes.
</p>


<h3>Value</h3>

<p><code>get.gam.fit()</code> returns a list with components
</p>

<dl>
<dt><code>covar</code>:</dt><dd><p>(unique/minimalized) covariate combinations;</p>
</dd>
<dt><code>fit</code>:</dt><dd><p>corresponding fitted values of lambda or rho.</p>
</dd>
</dl>

<p><code>gam.predict()</code> returns a list with components
</p>

<dl>
<dt><code>covar</code>:</dt><dd><p>covariate combinations as provided by <code>newdata</code>;</p>
</dd>
<dt><code>predict</code>:</dt><dd><p>predicted lambda or rho;</p>
</dd>
<dt><code>CI.low</code>:</dt><dd><p>lower confidence interval (based on predicted values);</p>
</dd>
<dt><code>CI.up</code>:</dt><dd><p>upper confidence interval (based on predicted values).</p>
</dd>
</dl>

<p><code>get.GPD.fit()</code> returns a list with components
</p>

<dl>
<dt><code>xi</code>:</dt><dd><p>list with components
</p>

<dl>
<dt><code>covar</code>:</dt><dd><p>(possibly empty) <code><a href="base.html#topic+data.frame">data.frame</a></code> containing
the unique/minimal covariate combinations for the covariates used
for fitting <code class="reqn">\xi</code>;</p>
</dd>
<dt><code>fit</code>:</dt><dd><p>corresponding fitted <code class="reqn">\xi</code>;</p>
</dd>
<dt><code>CI.low</code>:</dt><dd><p>lower confidence interval (bootstrapped
pointwise two-sides 1-<code class="reqn">\alpha</code>);</p>
</dd>
<dt><code>CI.up</code>:</dt><dd><p>upper confidence interval (bootstrapped
pointwise two-sides 1-<code class="reqn">\alpha</code>);</p>
</dd>
<dt><code>boot</code>:</dt><dd><p><code><a href="base.html#topic+matrix">matrix</a></code> containing the
corresponding bootstrapped <code class="reqn">\xi</code>'s (or <code>NULL</code> if
none of the bootstrap repetitions worked).</p>
</dd>
</dl>
</dd>
<dt><code>beta</code>:</dt><dd><p>similar as for <code>xi</code>.</p>
</dd>
</dl>

<p><code>GPD.predict()</code> returns a list with components
</p>

<dl>
<dt><code>xi</code>:</dt><dd><p>list with components
</p>

<dl>
<dt><code>covar</code>:</dt><dd><p><code><a href="base.html#topic+data.frame">data.frame</a></code> containing the
covariate combinations as provided by <code>xi.newdata</code>;</p>
</dd>
<dt><code>predict</code>:</dt><dd><p>predicted <code class="reqn">\xi</code>'s;</p>
</dd>
</dl>
</dd>
<dt><code>beta</code>:</dt><dd><p>similar as for <code>xi</code>.</p>
</dd>
</dl>

<p><code>risk.measure()</code> returns a vector of values of the selected risk measure.
</p>


<h3>Author(s)</h3>

<p>Marius Hofert</p>


<h3>References</h3>

<p>Chavez-Demoulin, V., Embrechts, P., and Hofert, M.,
An extreme value approach for modeling Operational
Risk losses depending on covariates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see demo(game) for how to use these functions
</code></pre>

<hr>
<h2 id='Gauss'>
Multivariate Gauss Distribution  
</h2><span id='topic+Gauss'></span><span id='topic+dmnorm'></span><span id='topic+rmnorm'></span><span id='topic+fit.norm'></span><span id='topic+MardiaTest'></span><span id='topic+jointnormalTest'></span>

<h3>Description</h3>

<p>Functions for evaluating multivariate normal density, generating
random variates, fitting and testing. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmnorm(x, mu, Sigma, log = FALSE)
fit.norm(data)
rmnorm(n, mu = 0, Sigma)
MardiaTest(data)
jointnormalTest(data, dist = c("chisquare", "beta"), plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Gauss_+3A_data">data</code></td>
<td>
<p><code>matrix</code>, data set.</p>
</td></tr>
<tr><td><code id="Gauss_+3A_dist">dist</code></td>
<td>
<p><code>character</code>, &ldquo;chisquare&rdquo; performs test against
<code class="reqn">\chi^2</code> distribution, which is an approximation;
&ldquo;beta&rdquo; performs a test against a scaled beta distribution.</p>
</td></tr>
<tr><td><code id="Gauss_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log density values shall be
returned.</p>
</td></tr>
<tr><td><code id="Gauss_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="Gauss_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameters.</p>
</td></tr>
<tr><td><code id="Gauss_+3A_plot">plot</code></td>
<td>
<p><code>logical</code>, whether test result shall be plotted.</p>
</td></tr> 
<tr><td><code id="Gauss_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code>, covariance matrix.</p>
</td></tr>
<tr><td><code id="Gauss_+3A_x">x</code></td>
<td>
<p><code>matrix</code>, density is evaluated per row.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(QRM)
BiDensPlot(func = dmnorm, mu = c(0, 0), Sigma = equicorr(2, -0.7))
S &lt;- equicorr(d = 3, rho = 0.7)
data &lt;- rmnorm(1000, Sigma = S)
fit.norm(data)
S &lt;- equicorr(d = 10, rho = 0.6)
data &lt;- rmnorm(1000, Sigma = S) 
MardiaTest(data)
## Dow Jones Data
data(DJ)
r &lt;- returns(DJ) 
stocks &lt;- c("AXP","EK","BA","C","KO","MSFT",
            "HWP","INTC","JPM","DIS")
ss &lt;- window(r[, stocks], "1993-01-01", "2000-12-31")
jointnormalTest(ss) 
</code></pre>

<hr>
<h2 id='GEV'>
Generalized Extreme Value Distribution 
</h2><span id='topic+GEV'></span><span id='topic+pGEV'></span><span id='topic+qGEV'></span><span id='topic+dGEV'></span><span id='topic+rGEV'></span><span id='topic+fit.GEV'></span>

<h3>Description</h3>

<p>Density, quantiles, cumulative probability, and fitting of the Generalized
Extreme Value distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pGEV(q, xi, mu = 0, sigma = 1) 
qGEV(p, xi, mu = 0, sigma = 1) 
dGEV(x, xi, mu = 0, sigma = 1, log = FALSE) 
rGEV(n, xi, mu = 0, sigma = 1)
fit.GEV(maxima, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GEV_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log values of density should be returned,
default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GEV_+3A_maxima">maxima</code></td>
<td>
<p><code>vector</code>, block maxima data</p>
</td></tr>
<tr><td><code id="GEV_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameter.</p>
</td></tr>
<tr><td><code id="GEV_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="GEV_+3A_p">p</code></td>
<td>
<p><code>vector</code>, probabilities.</p>
</td></tr>
<tr><td><code id="GEV_+3A_q">q</code></td>
<td>
<p><code>vector</code>, quantiles.</p>
</td></tr>
<tr><td><code id="GEV_+3A_sigma">sigma</code></td>
<td>
<p><code>numeric</code>, scale parameter.</p>
</td></tr>
<tr><td><code id="GEV_+3A_x">x</code></td>
<td>
<p><code>vector</code>, values to evaluate density.</p>
</td></tr>
<tr><td><code id="GEV_+3A_xi">xi</code></td>
<td>
<p><code>numeric</code>, shape parameter.</p>
</td></tr>
<tr><td><code id="GEV_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>optim()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric, probability (pGEV), quantile (qGEV), density (dGEV) or random
variates (rGEV) for the GEV distribution with shape parameter
<code class="reqn">\xi</code>, location parameter <code class="reqn">\mu</code> and scale parameter
<code class="reqn">\sigma</code>. A list object in case of <code>fit.GEV()</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GPD">GPD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quantValue &lt;- 4.5
pGEV(q = quantValue, xi = 0, mu = 1.0, sigma = 2.5) 
pGumbel(q = quantValue, mu = 1.0, sigma = 2.5)
## Fitting to monthly block-maxima
data(nasdaq)
l &lt;- -returns(nasdaq)
em &lt;- timeLastDayInMonth(time(l))
monmax &lt;- aggregate(l, by = em, FUN = max) 
mod1 &lt;- fit.GEV(monmax) 
</code></pre>

<hr>
<h2 id='GHYP'>
Uni- and Multivariate Generalized Hyperbolic Distribution 
</h2><span id='topic+dghyp'></span><span id='topic+dmghyp'></span><span id='topic+dsmghyp'></span><span id='topic+dghypB'></span><span id='topic+rghyp'></span><span id='topic+rmghyp'></span><span id='topic+rghypB'></span>

<h3>Description</h3>

<p>Values of density and random number generation for uni- and
multivariate Generalized Hyperbolic distribution in new QRM
parameterization <code class="reqn">(\chi, \psi, \gamma)</code> and in
standard parametrization <code class="reqn">(\alpha, \beta, \delta)</code>; univariate only. See pp. 77&ndash;81 in QRM. The special case of a
multivariate symmetric GHYP is implemented seperately as function
<code>dsmghyp()</code>.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dghyp(x, lambda, chi, psi, mu = 0, gamma = 0, log = FALSE) 
dmghyp(x, lambda, chi, psi, mu, Sigma, gamma, log = FALSE)
dsmghyp(x, lambda, chi, psi, mu, Sigma, log = FALSE)
dghypB(x, lambda, delta, alpha, beta = 0, mu = 0, log = FALSE) 
rghyp(n, lambda, chi, psi, mu = 0, gamma = 0)
rmghyp(n, lambda, chi, psi, Sigma, mu, gamma)
rghypB(n, lambda, delta, alpha, beta = 0, mu = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GHYP_+3A_alpha">alpha</code></td>
<td>
<p><code>numeric</code>, parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_beta">beta</code></td>
<td>
<p><code>numeric</code>, skewness parameter.</p>
</td></tr>
<tr><td><code id="GHYP_+3A_chi">chi</code></td>
<td>
<p><code>numeric</code>,  mixing parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_delta">delta</code></td>
<td>
<p><code>numeric</code>, parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_gamma">gamma</code></td>
<td>
<p><code>numeric</code>, skewness parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_lambda">lambda</code></td>
<td>
<p><code>numeric</code>, mixing parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_log">log</code></td>
<td>
<p><code>logical</code>, should log density be returned; default is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GHYP_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="GHYP_+3A_psi">psi</code></td>
<td>
<p><code>numeric</code>, mixing parameter(s).</p>
</td></tr>
<tr><td><code id="GHYP_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code>, dispersion matrix for multivaraiate GHYP.</p>
</td></tr>
<tr><td><code id="GHYP_+3A_x">x</code></td>
<td>
<p><code>vector</code>, values to evaluate density.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The univariate QRM parameterization is defined in terms of parameters
<code class="reqn">\chi, \psi, \gamma</code> instead of the
<code class="reqn">\alpha, \beta, \delta</code> model used by Blaesild
(1981). If <code class="reqn">\gamma = 0</code>, a normal variance mixture where
the mixing variable <code class="reqn">W</code> has a Generalized Inverse Gaussian
distribution (GIG) with parameters <code class="reqn">\lambda, \chi, \psi</code> is given, with heavier tails. If <code class="reqn">\gamma &gt; 0</code>, a normal mean-variance mixture where the mean is also perturbed to
equal <code class="reqn">\mu + (W * \gamma)</code> which introduces
asymmetry as well, is obtained. Values for <code class="reqn">\lambda</code> and
<code class="reqn">\mu</code> are identical in both QRM and B parameterizations. The
dispersion matrix <code class="reqn">\Sigma</code> does not appear as argument in
the univariate case since its value is identically one.  
</p>


<h3>Value</h3>

<p>numeric, value(s) of density or log-density (dghyp, dmghyp, dsmghyp
and dghypB) or random sample (rghyp, rmghyp, rghypB) 
</p>


<h3>Note</h3>

<p>Density values from dgyhp() should be identical to those from dghypB()
if the <code class="reqn">\alpha, \beta, \delta</code> parameters of
the B type are translated to the corresponding <code class="reqn">\gamma, \chi,
  \psi</code> parameters of the QRM type by formulas on pp
79&ndash;80 in QRM.<br />
If <code class="reqn">\gamma</code> is a vector of zeros, the distribution is
elliptical and <code>dsmghyp()</code> is utilised in <code>dmghyp()</code>. If
<code class="reqn">\lambda = (d + 1) / 2</code>, a d-dimensional
hyperbolic density results. If <code class="reqn">\lambda = 1</code>, the
univariate marginals are one-dimensional hyperbolics. If <code class="reqn">\lambda
  = -1/2</code>, the distribution is Normal Inverse Gaussian
(NIG). If <code class="reqn">\lambda &gt; 0</code> and <code class="reqn">\chi = 0</code>,
one obtains a Variance Gamma distribution (VG). If one can define a
constant <code class="reqn">\nu</code> such that <code class="reqn">\lambda = (-1/2) * \nu</code> and <code class="reqn">\chi = \nu</code> then one obtains a
multivariate skewed-t distribution. See p. 80 of QRM for details.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>old.par &lt;- par(no.readonly = TRUE)
par(mfrow = c(2, 2))
ll &lt;- c(-4, 4)
BiDensPlot(func = dmghyp, xpts = ll, ypts = ll, mu = c(0, 0),
           Sigma = equicorr(2, -0.7), lambda = 1, chi = 1, psi = 1,
           gamma = c(0, 0))
BiDensPlot(func = dmghyp, type = "contour", xpts = ll, ypts = ll,
           mu = c(0, 0), Sigma = equicorr(2, -0.7), lambda = 1,
           chi = 1, psi = 1, gamma = c(0, 0))
BiDensPlot(func = dmghyp, xpts = ll, ypts = ll, mu = c(0, 0),
           Sigma = equicorr(2, -0.7), lambda = 1, chi = 1, psi = 1,
           gamma = c(0.5, -0.5))
BiDensPlot(func = dmghyp, type = "contour", xpts = ll, ypts = ll,
           mu = c(0, 0), Sigma = equicorr(2, -0.7), lambda = 1,
           chi = 1, psi = 1, gamma = c(0.5, -0.5))
par(old.par)
</code></pre>

<hr>
<h2 id='GIG'>Generalized Inverse Gaussian Distribution</h2><span id='topic+GIG'></span><span id='topic+EGIG'></span><span id='topic+ElogGIG'></span><span id='topic+rGIG'></span><span id='topic+rgig'></span>

<h3>Description</h3>

<p>Calculates (log) moments of univariate generalized inverse Gaussian
(GIG) distribution and generating random variates. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EGIG(lambda, chi, psi, k = 1)
ElogGIG(lambda, chi, psi)
rGIG(n, lambda, chi, psi, envplot = FALSE, messages = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GIG_+3A_chi">chi</code></td>
<td>
<p><code>numeric</code>, chi parameter.</p>
</td></tr>
<tr><td><code id="GIG_+3A_envplot">envplot</code></td>
<td>
<p><code>logical</code>, whether plot of rejection envelope
should be created.</p>
</td></tr>
<tr><td><code id="GIG_+3A_k">k</code></td>
<td>
<p><code>integer</code>, order of moments.</p>
</td></tr>
<tr><td><code id="GIG_+3A_lambda">lambda</code></td>
<td>
<p><code>numeric</code>, lambda parameter.</p>
</td></tr>
<tr><td><code id="GIG_+3A_messages">messages</code></td>
<td>
<p><code>logical</code>, whether a message about rejection rate
should be returned.</p>
</td></tr>
<tr><td><code id="GIG_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="GIG_+3A_psi">psi</code></td>
<td>
<p><code>numeric</code>, psi parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Normal variance mixtures are frequently obtained by perturbing the
variance component of a normal distribution; here this is done by
multiplying the square root of a mixing variable assumed to have a GIG
distribution depending upon three parameters <code class="reqn">(\lambda, \chi,
    \psi)</code>. See p.77 in QRM.<br />
Normal mean-variance mixtures are created from normal variance
mixtures by applying another perturbation of the same mixing variable
to the mean component of a normal distribution. These perturbations
create Generalized Hyperbolic Distributions. See pp. 78&ndash;81 in QRM. A
description of the GIG is given on page 497 in QRM Book.
</p>


<h3>Value</h3>

<p>(log) mean of distribution or vector random variates in case of
<code>rgig()</code>.</p>

<hr>
<h2 id='GPD'>
Generalized Pareto Distribution 
</h2><span id='topic+GPD'></span><span id='topic+pGPD'></span><span id='topic+qGPD'></span><span id='topic+dGPD'></span><span id='topic+rGPD'></span>

<h3>Description</h3>

<p>Density, quantiles, and cumulative probability of the Generalized
Pareto distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pGPD(q, xi, beta = 1) 
qGPD(p, xi, beta = 1) 
dGPD(x, xi, beta = 1, log = FALSE) 
rGPD(n, xi, beta = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GPD_+3A_beta">beta</code></td>
<td>
<p><code>numeric</code>, scale parameter.</p>
</td></tr>
<tr><td><code id="GPD_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log values of density should be
returned.</p>
</td></tr>
<tr><td><code id="GPD_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="GPD_+3A_p">p</code></td>
<td>
<p><code>vector</code>, probabilities.</p>
</td></tr>
<tr><td><code id="GPD_+3A_q">q</code></td>
<td>
<p><code>vector</code>, quantiles.</p>
</td></tr>
<tr><td><code id="GPD_+3A_x">x</code></td>
<td>
<p><code>vector</code>, values to evaluate density.</p>
</td></tr>
<tr><td><code id="GPD_+3A_xi">xi</code></td>
<td>
<p><code>numeric</code>, shape parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric, probability (pGPD), quantile (qGPD), density (dGPD) or random
variates (rGPD) for the GPD with scale parameter <code class="reqn">\beta</code> and
shape parameter <code class="reqn">\xi</code>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GEV">GEV</a></code>, <code><a href="#topic+POT">POT</a></code>
</p>

<hr>
<h2 id='Gumbel'>
Gumbel Distribution 
</h2><span id='topic+dGumbel'></span><span id='topic+qGumbel'></span><span id='topic+pGumbel'></span><span id='topic+rGumbel'></span>

<h3>Description</h3>

<p>Density, quantiles, and cumulative probability of the Gumbel
distribution. The standard Gumbel has <code class="reqn">\mu</code> value of 0 and
<code class="reqn">\sigma</code> value of one. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dGumbel(x, mu = 0, sigma = 1, log = FALSE) 
qGumbel(p, mu = 0, sigma = 1) 
pGumbel(q, mu = 0, sigma = 1)
rGumbel(n, mu = 0, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Gumbel_+3A_log">log</code></td>
<td>
<p><code>logical</code>, whether log values of density should be
returned.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameter.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_p">p</code></td>
<td>
<p><code>vector</code>, probabilities.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_q">q</code></td>
<td>
<p><code>vector</code>, quantiles.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_sigma">sigma</code></td>
<td>
<p><code>numeric</code>, scale parameter.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_x">x</code></td>
<td>
<p><code>vector</code>, values to evaluate density.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric, probability (<code>pGumbel()</code>), quantile (<code>qGumbel()</code>),
density (<code>dGumbel()</code>) or random variates (<code>rGumbel()</code>) for
the Gumbel distribution with location parameter <code class="reqn">\mu</code> and
scale parameter <code class="reqn">\sigma</code>.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rGumbelSim &lt;- rGumbel(1000, 1.0, 2.5)
quantValue &lt;- 4.5
pGEV(q = quantValue, xi = 0, mu = 1.0, sigma = 2.5) 
pGumbel(q = quantValue, mu = 1.0, sigma = 2.5)
</code></pre>

<hr>
<h2 id='hsi'>
Hang Seng Stock Market Index 
</h2><span id='topic+hsi'></span><span id='topic+hsi.df'></span>

<h3>Description</h3>

<p>The <code>hsi</code> timeSeries dataset provides the daily closing value for
the Hanh Seng Index from January 1994 to March 2004. In addition, the
data set is also made available as a <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hsi)
data(hsi.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(hsi)
head(hsi)  
</code></pre>

<hr>
<h2 id='Kendall'>
Kendall's Rank Correlation 
</h2><span id='topic+Kendall'></span>

<h3>Description</h3>

<p>Calculates Kendall's rank correlations. The function is a wrapper to
<code>cor()</code>.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kendall(data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kendall_+3A_data">data</code></td>
<td>
<p><code>matrix</code> or <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="Kendall_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>cor()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+Spearman">Spearman</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- equicorr(d = 3, rho = 0.5)
data &lt;- rmnorm(1000, Sigma = S) 
Kendall(data) 
</code></pre>

<hr>
<h2 id='nasdaq'>
NASDAQ Stock Market Index
</h2><span id='topic+nasdaq'></span><span id='topic+nasdaq.df'></span>

<h3>Description</h3>

<p>The <code>nasdaq</code> timeSeries dataset provides the daily closing value
for the NASDAQ index from January 1994 to March 2004. In addition, the
data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nasdaq)
data(nasdaq.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(nasdaq)
head(nasdaq)  
</code></pre>

<hr>
<h2 id='NH'>
Normal Inverse Gaussian and Hyperbolic Distribution 
</h2><span id='topic+NH'></span><span id='topic+fit.NH'></span><span id='topic+fit.mNH'></span><span id='topic+MCECMupdate'></span><span id='topic+MCECM.Qfunc'></span><span id='topic+EMupdate'></span>

<h3>Description</h3>

<p>Functions for fitting uni- and multivariate NIG and HYP distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.NH(data, case = c("NIG", "HYP"), symmetric = FALSE,
       se = FALSE, ...)
fit.mNH(data, symmetric = FALSE, case = c("NIG", "HYP"),
        kvalue = NA, nit = 2000, tol = 1e-10, ...)
MCECMupdate(data, mix.pars, mu, Sigma, gamma, optpars, optfunc,
xieval=FALSE, ...)
MCECM.Qfunc(lambda, chi, psi, delta, eta, xi)
EMupdate(data, mix.pars, mu, Sigma, gamma, symmetric, 
         scaling = TRUE, kvalue = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NH_+3A_case">case</code></td>
<td>
<p><code>character</code>, whether NIG or HYP shall be used.</p>
</td></tr>
<tr><td><code id="NH_+3A_chi">chi</code></td>
<td>
<p><code>numeric</code>, chi parameter.</p>
</td></tr>
<tr><td><code id="NH_+3A_data">data</code></td>
<td>
<p><code>numeric</code>, data.</p>
</td></tr>
<tr><td><code id="NH_+3A_delta">delta</code></td>
<td>
<p><code>numeric</code>, delta parameter.</p>
</td></tr>
<tr><td><code id="NH_+3A_eta">eta</code></td>
<td>
<p><code>numeric</code>, eta parameter.</p>
</td></tr>
<tr><td><code id="NH_+3A_kvalue">kvalue</code></td>
<td>
<p><code>numeric</code>, value to which the determinant of the
dispersion matrix is constrained.</p>
</td></tr>
<tr><td><code id="NH_+3A_lambda">lambda</code></td>
<td>
<p><code>numeric</code>, lambda parameter.</p>
</td></tr>
<tr><td><code id="NH_+3A_mix.pars">mix.pars</code></td>
<td>
<p><code>vector</code>, values of lambda, chi and psi.</p>
</td></tr>
<tr><td><code id="NH_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, value of location parameters.</p>
</td></tr>
<tr><td><code id="NH_+3A_nit">nit</code></td>
<td>
<p><code>integer</code>, maximum number of iterations.</p>
</td></tr>
<tr><td><code id="NH_+3A_optpars">optpars</code></td>
<td>
<p><code>vector</code>, parameters to optimize over.</p>
</td></tr>
<tr><td><code id="NH_+3A_optfunc">optfunc</code></td>
<td>
<p><code>function</code>, the function to be optimized.</p>
</td></tr>
<tr><td><code id="NH_+3A_psi">psi</code></td>
<td>
<p><code>numeric</code>, pi parameter.</p>
</td></tr>
<tr><td><code id="NH_+3A_scaling">scaling</code></td>
<td>
<p><code>logical</code>, whether determinant scaling of Sigma
shall be fixed.</p>
</td></tr>
<tr><td><code id="NH_+3A_se">se</code></td>
<td>
<p><code>logical</code>, whether standard errors should be
calculated.</p>
</td></tr>
<tr><td><code id="NH_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code>, value of Sigma.</p>
</td></tr>
<tr><td><code id="NH_+3A_symmetric">symmetric</code></td>
<td>
<p><code>logical</code>, whether symmetric case should be
fitted.</p>
</td></tr>
<tr><td><code id="NH_+3A_tol">tol</code></td>
<td>
<p><code>numeric</code>, tolerance for convergence.</p>
</td></tr>
<tr><td><code id="NH_+3A_gamma">gamma</code></td>
<td>
<p><code>numeric</code>, value of gamma</p>
</td></tr>
<tr><td><code id="NH_+3A_xi">xi</code></td>
<td>
<p><code>numeric</code>, xi parameter.</p>
</td></tr>
<tr><td><code id="NH_+3A_xieval">xieval</code></td>
<td>
<p><code>logical</code>, whether log moment xi shall be
evaluated.</p>
</td></tr>
<tr><td><code id="NH_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>optim()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit.NH()</code>: See pages 78&ndash;80 of QRM. Case &lsquo;NIG&rsquo; sets
<code class="reqn">\lambda = -1/2</code>; case &lsquo;HYP&rsquo; sets
<code class="reqn">\lambda = 1</code>.<br />
<code>fit.mNH()</code>: Fitting is accomplished by using a variant of the EM
algorithm (see pages 81&ndash;83 in QRM).<br /> 
<code>MCECMupdate()</code>: updates estimates of mixing parameters in EM
estimation of generalized hyperbolic (see Algorithm 3.14, steps (5)
and (6) on page 83 in QRM).<br />
<code>MCECM.Qfunc()</code>: a functional form that must be optimized when
fitting members of generalized hyperbolic family with an MCECM
algorithm (see function Q2 on page 82 of QRM).<br />
<code>EMupdate()</code>: updates estimates of location (<code class="reqn">\mu</code>),
dispersion (<code class="reqn">\Sigma</code>) and skewness (<code class="reqn">\gamma</code>)
parameters in EM estimation of multivariate generalized hyperbolic
distributions (see pages 81&ndash;83 in QRM; in that case k is the
determinant of the sample covariance matrix. &ldquo;EM&rdquo; is an acronym
for for &ldquo;Expectation-Maximization&rdquo; type of algorithm
used to fit proposed multivariate hyperbolic models to actual data). 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(QRM)
data(DJ)
r &lt;- returns(DJ) 
s &lt;- window(r[, "MSFT"], "1993-01-01", "2000-12-31")
mod.NIG &lt;- fit.NH(100 * s, method = "BFGS")
## multivariate
stocks &lt;- c("AXP","EK","BA","C","KO","MSFT",
            "HWP","INTC","JPM","DIS")
ss &lt;- window(r[, stocks], "1993-01-01", "2000-12-31")
fridays &lt;- time(ss)[isWeekday(time(ss), wday = 5)]
ssw &lt;- aggregate(ss, by = fridays, FUN = sum)
mod.mNIG &lt;- fit.mNH(ssw, symmetric = FALSE, case = "NIG") 
</code></pre>

<hr>
<h2 id='nikkei'>
Nikkei Stock Market Index
</h2><span id='topic+nikkei'></span><span id='topic+nikkei.df'></span>

<h3>Description</h3>

<p>The <code>nikkei</code> timeSeries dataset provides the daily closing value
for the Nikkei index from January 1994 to March 2004. In addition, the
data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nikkei)
data(nikkei.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(nikkei)
head(nikkei)  
</code></pre>

<hr>
<h2 id='Pconstruct'>
Assemble a Correlation Matrix for ML Copula Fitting 
</h2><span id='topic+Pconstruct'></span>

<h3>Description</h3>

<p>This function converts a vector of values representing the terms of a
lower triangular matrix <code class="reqn">A</code> with ones on the diagonal and
returns the correlation matrix corresponding to the covariance matrix
<code class="reqn">AA'</code> (see page 235 in QRM).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pconstruct(theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Pconstruct_+3A_theta">theta</code></td>
<td>
<p><code>vector</code>, elements of a lower triangular matrix
<code class="reqn">A</code> with ones on the diagonal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>


<h3>See Also</h3>

<p><code>link{Pdeconstruct}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- Pconstruct(1:6) 
eigen(P) 
Pdeconstruct(P) 
</code></pre>

<hr>
<h2 id='Pdeconstruct'>
Disassemble a Correlation Matrix for ML Copula Fitting 
</h2><span id='topic+Pdeconstruct'></span>

<h3>Description</h3>

<p>This function takes a correlation matrix <code class="reqn">P</code> and returns the
elements of a lower-triangular matrix <code class="reqn">A</code> with ones on the
diagonal such that <code class="reqn">P</code> is the corelation matrix corresponding to
the covariance matrix <code class="reqn">AA'</code> (see page 235 in QRM).   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pdeconstruct(P)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Pdeconstruct_+3A_p">P</code></td>
<td>
<p><code>matrix</code>, a correlation matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Pconstruct">Pconstruct</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- Pconstruct(1:6) 
Pdeconstruct(P) 
</code></pre>

<hr>
<h2 id='POT'>
Peaks-over-Threshold Method
</h2><span id='topic+POT'></span><span id='topic+fit.GPD'></span><span id='topic+findthreshold'></span><span id='topic+plotTail'></span><span id='topic+MEplot'></span><span id='topic+showRM'></span><span id='topic+xiplot'></span><span id='topic+RiskMeasures'></span><span id='topic+hill'></span><span id='topic+hillPlot'></span><span id='topic+plotFittedGPDvsEmpiricalExcesses'></span>

<h3>Description</h3>

<p>Functions for fitting, analysing and risk measures according to POT/GPD
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.GPD(data, threshold = NA, nextremes = NA, type = c("ml", "pwm"),
        information = c("observed", "expected"),
        optfunc = c("optim", "nlminb"), verbose = TRUE, ...)
plotTail(object, ppoints.gpd = ppoints(256), main = "Estimated tail probabilities",
         xlab = "Exceedances x", ylab = expression(1-hat(F)[n](x)), ...)
showRM(object, alpha, RM = c("VaR", "ES"),
       like.num = 64, ppoints.gpd = ppoints(256),
       xlab = "Exceedances x", ylab = expression(1-hat(F)[n](x)),
       legend.pos = "topright", pre.0.4.9=FALSE, ...)
findthreshold(data, ne)
MEplot(data, omit = 3., main = "Mean-Excess Plot", xlab = "Threshold",
       ylab = "Mean Excess", ...)
xiplot(data, models = 30., start = 15., end = 500., reverse = TRUE,
       ci = 0.95, auto.scale = TRUE, labels = TRUE, table = FALSE, ...)
hill(data, k, tail.index = TRUE)
hillPlot(data, option = c("alpha", "xi", "quantile"), start = 15,
         end = NA, reverse = FALSE, p = NA, ci = 0.95,
         auto.scale = TRUE, labels = TRUE, ...)
plotFittedGPDvsEmpiricalExcesses(data, threshold = NA, nextremes = NA)
RiskMeasures(out, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="POT_+3A_alpha">alpha</code></td>
<td>
<p><code>numeric</code>, probability level(s).</p>
</td></tr>
<tr><td><code id="POT_+3A_auto.scale">auto.scale</code></td>
<td>
<p><code>logical</code>, whether plot should be automatically
scaled.</p>
</td></tr>
<tr><td><code id="POT_+3A_ci">ci</code></td>
<td>
<p><code>numeric</code>, probability for asymptotic confidence
bands.</p>
</td></tr>
<tr><td><code id="POT_+3A_data">data</code></td>
<td>
<p><code>numeric</code>, data vector or timesSeries.</p>
</td></tr>
<tr><td><code id="POT_+3A_end">end</code></td>
<td>
<p><code>integer</code>, maximum number of exceedances to be
considered.</p>
</td></tr>
<tr><td><code id="POT_+3A_information">information</code></td>
<td>
<p><code>character</code>, whether standard errors should be
calculated with &ldquo;observed&rdquo; or &ldquo;expected&rdquo;
information. This only applies to maximum likelihood type; for
&ldquo;pwm&rdquo; type &ldquo;expected&rdquo; information is used if possible.</p>
</td></tr>
<tr><td><code id="POT_+3A_k">k</code></td>
<td>
<p>number (greater than or equal to 2) of order statistics used
to compute the Hill plot.</p>
</td></tr>
<tr><td><code id="POT_+3A_labels">labels</code></td>
<td>
<p><code>logical</code>, whether axes shall be labelled.</p>
</td></tr>
<tr><td><code id="POT_+3A_legend.pos">legend.pos</code></td>
<td>
<p>if not <code><a href="base.html#topic+NULL">NULL</a></code>, position of
<code><a href="graphics.html#topic+legend">legend</a>()</code>.</p>
</td></tr>
<tr><td><code id="POT_+3A_pre.0.4.9">pre.0.4.9</code></td>
<td>
<p><code>logical</code>, whether behavior previous to version
0.4-9 applies (returning the risk measure estimate and confidence
intervals instead of just <code>invisible()</code>).</p>
</td></tr>
<tr><td><code id="POT_+3A_like.num">like.num</code></td>
<td>
<p><code>integer</code>, count of evaluations of profile likelihood.</p>
</td></tr>
<tr><td><code id="POT_+3A_main">main</code>, <code id="POT_+3A_xlab">xlab</code>, <code id="POT_+3A_ylab">ylab</code></td>
<td>
<p>title, x axis and y axis labels.</p>
</td></tr>
<tr><td><code id="POT_+3A_models">models</code></td>
<td>
<p><code>integer</code>, count of consecutive gpd models to be
fitted; <em>i.e.</em>, the count of different thresholds at which to
re-estimate <code class="reqn">\xi</code>; this many <code class="reqn">\xi</code> estimates will be
plotted.</p>
</td></tr>
<tr><td><code id="POT_+3A_ne">ne</code></td>
<td>
<p><code>integer</code>, count of excesses above the threshold.</p>
</td></tr>
<tr><td><code id="POT_+3A_nextremes">nextremes</code></td>
<td>
<p><code>integer</code>, count of upper extremes to be used.</p>
</td></tr>
<tr><td><code id="POT_+3A_object">object</code></td>
<td>
<p><code>list</code>, returned value from fitting GPD</p>
</td></tr>
<tr><td><code id="POT_+3A_omit">omit</code></td>
<td>
<p><code>integer</code>, count of upper plotting points to be
omitted.</p>
</td></tr>
<tr><td><code id="POT_+3A_optfunc">optfunc</code></td>
<td>
<p><code>character</code>, function used for ML-optimization.</p>
</td></tr>
<tr><td><code id="POT_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code> indicating whether warnings are given;
currently only applies in the case where <code>type="pwm"</code> and
<code>xi &gt; 0.5</code>.</p>
</td></tr>
<tr><td><code id="POT_+3A_option">option</code></td>
<td>
<p><code>logical</code>, whether &quot;alpha&quot;, &quot;xi&quot; (1 / alpha) or
&quot;quantile&quot; (a quantile estimate) should be plotted.</p>
</td></tr>
<tr><td><code id="POT_+3A_out">out</code></td>
<td>
<p><code>list</code>, returned value from fitting GPD.</p>
</td></tr>
<tr><td><code id="POT_+3A_p">p</code></td>
<td>
<p><code>vector</code>, probability levels for risk measures.</p>
</td></tr>
<tr><td><code id="POT_+3A_ppoints.gpd">ppoints.gpd</code></td>
<td>
<p>points in (0,1) for evaluating the GPD tail estimate.</p>
</td></tr>
<tr><td><code id="POT_+3A_reverse">reverse</code></td>
<td>
<p><code>logical</code>, plot ordered by increasing threshold
or number of extremes.</p>
</td></tr>
<tr><td><code id="POT_+3A_rm">RM</code></td>
<td>
<p><code>character</code>, risk measure, either &quot;VaR&quot; or &quot;ES&quot;</p>
</td></tr>
<tr><td><code id="POT_+3A_start">start</code></td>
<td>
<p><code>integer</code>, lowest number of exceedances to be
considered.</p>
</td></tr>
<tr><td><code id="POT_+3A_table">table</code></td>
<td>
<p><code>logical</code>, printing of a result table.</p>
</td></tr>
<tr><td><code id="POT_+3A_tail.index">tail.index</code></td>
<td>
<p><code>logical</code> indicating whether the Hill estimator
of <code class="reqn">alpha</code> (the default) or <code class="reqn">1/alpha</code> is computed.</p>
</td></tr>
<tr><td><code id="POT_+3A_threshold">threshold</code></td>
<td>
<p><code>numeric</code>, threshold value.</p>
</td></tr>
<tr><td><code id="POT_+3A_type">type</code></td>
<td>
<p><code>character</code>, estimation by either ML- or PWM type.</p>
</td></tr>
<tr><td><code id="POT_+3A_...">...</code></td>
<td>
<p>ellpsis, arguments are passed down to either <code>plot()</code>
or <code>optim()</code> or <code>nlminb()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hillplot()</code>: This plot is usually calculated from the alpha
perspective. For a generalized Pareto analysis of heavy-tailed data
using the gpd function, it helps to plot the Hill estimates for
xi. See pages 286&ndash;289 in QRM. Especially note that Example 7.28
suggests the best estimates occur when the threshold is very small,
perhaps 0.1 of the sample size (10&ndash;50 order statistics in a sample of
size 1000).  Hence one should NOT be using a 95 percent threshold for
Hill estimates.<br />
<code>MEplot()</code>: An upward trend in plot shows heavy-tailed
behaviour. In particular, a straight line with positive gradient above
some threshold is a sign of Pareto behaviour in tail. A downward trend
shows thin-tailed behaviour whereas a line with zero gradient shows an
exponential tail. Because upper plotting points are the average of a
handful of extreme excesses, these may be omitted for a prettier
plot.<br />
<code>plotFittedGPDvsEmpiricalExcesses()</code>: Build a graph which plots
the GPD fit of excesses over a threshold u and the corresponding
empirical distribution function for observed excesses.<br />
<code>RiskMeasures()</code>: Calculates risk measures (VaR or ES) based on a
generalized Pareto model fitted to losses over a high threshold.<br />
<code>xiplot()</code>: Creates a plot showing how the estimate of shape
varies with threshold or number of extremes.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GEV">GEV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
plot(danish)

MEplot(danish)

xiplot(danish)

hillPlot(danish, option = "alpha", start = 5, end = 250, p = 0.99)
hillPlot(danish, option = "alpha", start = 5, end = 60, p = 0.99)

plotFittedGPDvsEmpiricalExcesses(danish, nextremes = 109)
u &lt;- quantile(danish, probs=0.9, names=FALSE)
plotFittedGPDvsEmpiricalExcesses(danish, threshold = u)

findthreshold(danish, 50)
mod1 &lt;- fit.GPD(danish, threshold = u)

RiskMeasures(mod1, c(0.95, 0.99))
plotTail(mod1)

showRM(mod1, alpha = 0.99, RM = "VaR", method = "BFGS")
showRM(mod1, alpha = 0.99, RM = "ES", method = "BFGS")

mod2 &lt;- fit.GPD(danish, threshold = u, type = "pwm")
mod3 &lt;- fit.GPD(danish, threshold = u, optfunc = "nlminb")

## Hill plot manually constructed based on hill()

## generate data
set.seed(1)
n &lt;- 1000 # sample size
U &lt;- runif(n)
X1 &lt;- 1/(1-U) # ~ F_1(x) = 1-x^{-1}, x &gt;= 1 =&gt; Par(1)
F2 &lt;- function(x) 1-(x*log(x))^(-1) # Par(1) with distorted SV function
X2 &lt;- vapply(U, function(u) uniroot(function(x) 1-(x*log(x))^(-1)-u,
                                    lower=1.75, upper=1e10)$root, NA_real_)

## compute Hill estimators for various k
k &lt;- 10:800
y1 &lt;- hill(X1, k=k)
y2 &lt;- hill(X2, k=k)

## Hill plot
plot(k, y1, type="l", ylim=range(y1, y2, 1),
     xlab=expression("Number"~~italic(k)~~"of upper order statistics"),
     ylab=expression("Hill estimator for"~~alpha),
     main="Hill plot") # Hill plot, good natured case (based on X1)
lines(k, y2, col="firebrick") # Hill "horror" plot (based on X2)
lines(x=c(10, 800), y=c(1, 1), col="royalblue3") # correct value alpha=1
legend("topleft", inset=0.01, lty=c(1, 1, 1), bty="n",
       col=c("black", "firebrick", "royalblue3"),
       legend=as.expression(c("Hill estimator based on"~~
                               italic(F)(x)==1-1/x,
                              "Hill estimator based on"~~
                               italic(F)(x)==1-1/(x~log~x),
                              "Correct value"~~alpha==1)))

## via hillPlot()
hillPlot(X1, option="alpha", start=10, end=800)
hillPlot(X2, option="alpha", start=10, end=800)
</code></pre>

<hr>
<h2 id='QQplot'>
Generic Quantile-Quantile Plot 
</h2><span id='topic+QQplot'></span>

<h3>Description</h3>

<p>Constructs a quantile-quantile plot against a given reference
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QQplot(x, a = 0.5, reference = c("normal", "exp", "student"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="QQplot_+3A_x">x</code></td>
<td>
<p><code>vector</code>, data for QQ-plot.</p>
</td></tr>
<tr><td><code id="QQplot_+3A_a">a</code></td>
<td>
<p><code>numeric</code>, the offset fraction to be used in
<code>ppoints()</code>; typically in (0, 1).</p>
</td></tr>
<tr><td><code id="QQplot_+3A_reference">reference</code></td>
<td>
<p><code>character</code>, name of reference distribution.</p>
</td></tr>
<tr><td><code id="QQplot_+3A_...">...</code></td>
<td>
<p>ellipsis argument, passed down to quantile function of
reference distribution.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Special forms like ParetoQQ plots can also be created via this function. E.g.,
to create a ParetoQQ plot, merely pass log(data) in place of data as the first
parameter and use <code>reference = "exp"</code> as the reference
distribution. The ParetoQQ plot should provide a linear graph when a
log transform of the data is plotted against the exponential distribution.
</p>


<h3>Value</h3>

<p>Produces QQ-plot and returns invisibly a list of <code>(x, y)</code> pairs.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ppoints">ppoints</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>QQplot(rnorm(1000), reference = "normal") 
QQplot(rexp(1000), reference = "exp", rate = 0.3) 
</code></pre>

<hr>
<h2 id='QRM-defunct'>Defunct Functions in Package QRM</h2><span id='topic+QRM-defunct'></span><span id='topic+mk.returns'></span><span id='topic+plotMultiTS'></span><span id='topic+signalSeries'></span><span id='topic+aggregateQuarterlySeries'></span><span id='topic+aggregateMonthlySeries'></span><span id='topic+aggregateWeeklySeries'></span><span id='topic+aggregateSignalSeries'></span><span id='topic+ConvertDFToTimeSeries'></span><span id='topic+CovToCor'></span><span id='topic+symmetrize'></span><span id='topic+hessb'></span><span id='topic+fit.Archcopula2d'></span><span id='topic+besselM3'></span><span id='topic+psifunc'></span><span id='topic+kurtosisSPlus'></span><span id='topic+fit.tcopula.rank'></span><span id='topic+fit.GPDb'></span><span id='topic+lbeta'></span><span id='topic+extremalPP'></span><span id='topic+unmark'></span><span id='topic+plot.MPP'></span><span id='topic+plot.PP'></span><span id='topic+fit.POT'></span><span id='topic+sePP.negloglik'></span><span id='topic+seMPP.negloglik'></span><span id='topic+volfunction'></span><span id='topic+plot.sePP'></span><span id='topic+fit.sePP'></span><span id='topic+fit.seMPP'></span><span id='topic+stationary.sePP'></span>

<h3>Description</h3>

<p>The functions listed below which were contained in the package QRMlib
are now defunct. The user is referred to the suggested functions as an
alternative. 
</p>


<h3>Details</h3>

<p><code>aggregateMonthlySeries()</code> is defunct. use <code>aggregate()</code> in
package <span class="pkg">timeSeries</span>.<br />
<code>aggregateQuarterlySeries</code> is defunct. use <code>aggregate()</code> in
package <code>timeSeries</code>.<br /> 
<code>aggregateSignalSeries()</code> is defunct. use <code>aggregate()</code> in
package <span class="pkg">timeSeries</span>.<br />
<code>aggregateWeeklySeries()</code> is defunct. use <code>aggregate()</code> in
package <span class="pkg">timeSeries</span>.<br />
<code>besselM3()</code> is defunct. use <code>besselK()</code> in package
<span class="pkg">base</span>.<br /> 
<code>ConvertDFToTimeSeries()</code> is defunct. use <code>timeSeries()</code> in
package <span class="pkg">timeSeries</span>.<br />
<code>CovToCor()</code> is defunct. use <code>cov2cor()</code> in package
<span class="pkg">stats</span>.<br /> 
<code>fit.Archcopula2d()</code> is defunct. use <code>fit.AC()</code>.<br />
<code>fit.GPDb()</code> is defunct. use <code>fit.GPD()</code>.<br />
<code>fit.tcopula.rank()</code> is defunct. use <code>fit.tcopula()</code>.<br />
<code>hessb()</code> is defunct. use <code>hessian()</code> in package
<span class="pkg">numDeriv</span>.<br /> 
<code>kurtosisSPlus()</code> is defunct. use <code>kurtosis()</code> in package
<span class="pkg">timeDate</span>.<br /> 
<code>lbeta()</code> is defunct. use <code>lbeta()</code> in package
<span class="pkg">base</span>.<br />  
<code>mk.returns()</code> is defunct. use <code>returnSeries()</code> in package
<span class="pkg">timeSeries</span>.<br />  
<code>plotMultiTS()</code> is defunct. use <code>plot()</code> in package
<span class="pkg">timeSeries</span>.<br />
<code>psifunc()</code> is defunct. use <code>psi()</code> in package <span class="pkg">gsl</span>.<br /> 
<code>signalSeries()</code> is defunct. use <code>series()</code> in package
<span class="pkg">timeSeries</span>.<br />  
<code>symmetrize()</code> is defunct. use <code>forceSymmetric()</code> in package
<span class="pkg">Matrix</span>.<br />
<code>extremalPP()</code> is defunct.<br />
<code>unmark()</code> is defunct.<br />
<code>plot.MPP()</code> is defunct.<br />
<code>plot.PP()</code> is defunct.<br />
<code>fit.POT()</code> is defunct.<br />
<code>sePP.negloglik()</code> is defunct.<br />
<code>seMPP.negloglik()</code> is defunct.<br />
<code>volfunction()</code> is defunct.<br />
<code>plot.sePP()</code> is defunct.<br />
<code>fit.sePP()</code> is defunct.<br />
<code>fit.seMPP()</code> is defunct.<br />
<code>stationary.sePP()</code> is defunct.
</p>

<hr>
<h2 id='smi'>
Swiss Market Index
</h2><span id='topic+smi'></span><span id='topic+smi.df'></span>

<h3>Description</h3>

<p>The <code>smi</code> timeSeries dataset provides the daily closing value for
the Swiss Market index from November 1990 to March 2004. In addition,
the data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(smi)
data(smi.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(smi)
head(smi)  
</code></pre>

<hr>
<h2 id='sp500'>
Standard and Poors 500 Index
</h2><span id='topic+sp500'></span><span id='topic+sp500.df'></span>

<h3>Description</h3>

<p>The <code>sp500</code> timeSeries dataset provides the daily closing value
for the S and P 500 Index from January 1980 to March 2004. In
addition, the data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dji)
data(dji.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(sp500)
head(sp500)  
</code></pre>

<hr>
<h2 id='spdata'>
Standard and Poors Default Data 
</h2><span id='topic+spdata'></span><span id='topic+spdata.df'></span>

<h3>Description</h3>

<p>The <code>spdata</code> timeSeries dataset contains default data for A, BBB,
BB, B and C-rated companies for the years 1981 to 2000. In addition,
the data set is also made available as a <code>data.frame</code>.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spdata)
data(spdata.df)
</code></pre>


<h3>Source</h3>

<p>Standard and Poors Credit Monitor 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spdata)
head(spdata)
</code></pre>

<hr>
<h2 id='spdata.raw'>
Standard and Poors Default Data
</h2><span id='topic+spdata.raw'></span><span id='topic+spdata.raw.df'></span>

<h3>Description</h3>

<p>The <code>spdata.raw</code> timeSeries contains default data for A, BBB, BB,
B and C-rated companies for the years 1981 to 2000.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spdata.raw)
data(spdata.raw.df)
</code></pre>


<h3>Source</h3>

<p>Standard &amp; Poors Credit Monitor 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(spdata.raw)
head(spdata.raw)
</code></pre>

<hr>
<h2 id='Spearman'>
Spearman's Rank Correlation 
</h2><span id='topic+Spearman'></span>

<h3>Description</h3>

<p>Calculates Sperman's rank correlations. The function is a wrapper to
<code>cor()</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Spearman(data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Spearman_+3A_data">data</code></td>
<td>
<p><code>matrix</code> or <code>data.frame</code></p>
</td></tr>
<tr><td><code id="Spearman_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>cor()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+Kendall">Kendall</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- equicorr(d = 3, rho = 0.5)
data &lt;- rmnorm(1000, Sigma = S) 
Spearman(data) 
</code></pre>

<hr>
<h2 id='Student'>
Student's t Distribution 
</h2><span id='topic+Student'></span><span id='topic+dmt'></span><span id='topic+rmt'></span><span id='topic+qst'></span><span id='topic+fit.st'></span><span id='topic+fit.mst'></span>

<h3>Description</h3>

<p>Functions for evaluating density, fitting and random variates of
multivaraite Student's t distribution and routines for quantiles and
fitting of univariate distribution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmt(x, df, mu, Sigma, log = FALSE)
rmt(n, df = 4, mu = 0, Sigma)
qst(p, mu = 0, sd = 1, df, scale = FALSE)
fit.st(data, ...)
fit.mst(data, nit = 2000, tol = 1e-10, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Student_+3A_x">x</code></td>
<td>
<p><code>matrix</code>, dimension <code class="reqn">n \times d</code>; density is
evaluated for each row.</p>
</td></tr>
<tr><td><code id="Student_+3A_df">df</code></td>
<td>
<p><code>numeric</code>, degrees of freedom.</p>
</td></tr>
<tr><td><code id="Student_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code>, location parameters.</p>
</td></tr>
<tr><td><code id="Student_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code>, dispersion matrix.</p>
</td></tr>
<tr><td><code id="Student_+3A_log">log</code></td>
<td>
<p><code>logical</code>, returning log density values.</p>
</td></tr>
<tr><td><code id="Student_+3A_data">data</code></td>
<td>
<p><code>numeric</code>, data used for uni- and multivariate fitting.</p>
</td></tr>
<tr><td><code id="Student_+3A_nit">nit</code></td>
<td>
<p><code>integer</code>, number of iterations of EM-type algorithm.</p>
</td></tr>
<tr><td><code id="Student_+3A_tol">tol</code></td>
<td>
<p><code>numeric</code>, tolerance of improvement for stopping iteration.</p>
</td></tr>
<tr><td><code id="Student_+3A_p">p</code></td>
<td>
<p><code>numeric</code>, probability.</p>
</td></tr>
<tr><td><code id="Student_+3A_sd">sd</code></td>
<td>
<p><code>numeric</code>, scale parameters.</p>
</td></tr>
<tr><td><code id="Student_+3A_scale">scale</code></td>
<td>
<p><code>logical</code>, scaling Student's t distribution.</p>
</td></tr>
<tr><td><code id="Student_+3A_n">n</code></td>
<td>
<p><code>integer</code>, count of random variates.</p>
</td></tr>
<tr><td><code id="Student_+3A_...">...</code></td>
<td>
<p>ellipsis, arguments are passed down to <code>optim()</code> in
<code>fit.st()</code> and to <code>MCECMupdate()</code> in <code>fit.mst()</code>.</p>
</td></tr> 
</table>


<h3>See Also</h3>

<p><code>link{EMupdate}</code>, <code>link{MCECMupdate}</code>, and
<code>link{MCECM.Qfunc}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BiDensPlot(func = dmt, xpts = c(-4, 4), ypts = c(-4, 4), mu = c(0, 0),
           Sigma = equicorr(2, -0.7), df = 4)
## Quantiles of univariate Student's t
p &lt;- c(0.90,0.95)
s &lt;- 0.2 * 10000/sqrt(250)
qst(p, sd = s, df = 4, scale = TRUE)
## Fitting multivariate Student's t
Sigma &lt;- diag(c(3, 4, 5)) %*% equicorr(3, 0.6) %*% diag(c(3, 4, 5)) 
mu &lt;- c(1, 2 ,3) 
tdata &lt;- rmt(1000, 4, mu = mu, Sigma = Sigma) 
mod1 &lt;- fit.mst(tdata, method = "BFGS")
## DJ data
data(DJ)
r &lt;- returns(DJ)
s &lt;- window(r[, "MSFT"], "1993-01-01", "2000-12-31")
mod.t1 &lt;- fit.st(100 * s)
stocks &lt;- c("AXP","EK","BA","C","KO","MSFT",
            "HWP","INTC","JPM","DIS")
ss &lt;- window(r[, stocks], "1993-01-01", "2000-12-31")
fridays &lt;- time(ss)[isWeekday(time(ss), wday = 5)]
ssw &lt;- aggregate(ss, by = fridays, FUN = sum)
mod.t2 &lt;- fit.mst(ssw, method = "BFGS") 
</code></pre>

<hr>
<h2 id='VaRbound'>Computing lower and upper bounds for the (smallest or largest) VaR</h2><span id='topic+VaRbound'></span>

<h3>Description</h3>

<p><code>VaRbound()</code> computes lower and upper bounds for the lower or upper
Value-at-Risk bound.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VaRbound(alpha, N, qmargins, bound = c("upper", "lower"), verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VaRbound_+3A_alpha">alpha</code></td>
<td>
<p>confidence level in (0,1).</p>
</td></tr>
<tr><td><code id="VaRbound_+3A_n">N</code></td>
<td>
<p>tail discretization parameter; see Embrechts et al. (2013).</p>
</td></tr>
<tr><td><code id="VaRbound_+3A_qmargins">qmargins</code></td>
<td>
<p><code><a href="base.html#topic+list">list</a></code> containing the marginal quantile
functions.</p>
</td></tr>
<tr><td><code id="VaRbound_+3A_bound">bound</code></td>
<td>
<p><code><a href="base.html#topic+character">character</a></code> string indicating the VaR bound to
be approximated (largest (default) or smallest).</p>
</td></tr>
<tr><td><code id="VaRbound_+3A_verbose">verbose</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating whether progress
information is displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to the nature of the rearrangement algorithm, note that this
purely R based implementation can be slow.
</p>


<h3>Value</h3>

<p><code><a href="base.html#topic+numeric">numeric</a></code> vector of length two, containing the lower and
upper bound for the (chosen) Value-at-Risk estimate.
</p>


<h3>Author(s)</h3>

<p>Marius Hofert.</p>


<h3>References</h3>

<p>Embrechts, P., Puccetti, G., and Rüschendorf, L. (2013),
Model uncertainty and VaR aggregation,
<em>Journal of Banking and Finance</em> <b>37</b>(8), 2750&ndash;2764.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>qPar &lt;- function(p, theta) (1-p)^(-1/theta)-1
qmar &lt;- lapply(1:3, function(j) function(p) qPar(p, theta=2.5))
## bounds for the largest VaR
VaRbound(0.99, N=50, qmargins=qmar)
## bounds for the smallest VaR
VaRbound(0.99, N=50, qmargins=qmar, bound="lower")
</code></pre>

<hr>
<h2 id='xdax'>
Xetra DAX German Index
</h2><span id='topic+xdax'></span><span id='topic+xdax.df'></span>

<h3>Description</h3>

<p>The <code>xdax</code> timeSeries dataset provides the daily closing value
for the German Xextra DAX index from January 1994 to March 2004. In
addition, the data set is also made available as a <code>data.frame</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(xdax)
data(xdax.df)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(xdax)
head(xdax)  
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
