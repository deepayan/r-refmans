<!DOCTYPE html><html><head><title>Help for package DebiasInfer</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DebiasInfer}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DebiasProg'><p>The proposed debiasing (primal) program.</p></a></li>
<li><a href='#DebiasProgCV'><p>The proposed debiasing (primal) program with cross-validation.</p></a></li>
<li><a href='#DualCD'><p>Coordinate descent algorithm for solving the dual form of our debiasing program.</p></a></li>
<li><a href='#DualObj'><p>The objective function of the debiasing dual program.</p></a></li>
<li><a href='#SoftThres'><p>The soft-thresholding function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Efficient Inference on High-Dimensional Linear Model with
Missing Outcomes</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>A statistically and computationally efficient debiasing method for conducting valid inference on the high-dimensional linear regression function with missing outcomes.
    The reference paper is Zhang, Giessing, and Chen (2023) &lt;<a href="https://arxiv.org/abs/2309.06429">arXiv:2309.06429</a>&gt;. </td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/zhangyk8/Debias-Infer/">https://github.com/zhangyk8/Debias-Infer/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/zhangyk8/Debias-Infer/issues">https://github.com/zhangyk8/Debias-Infer/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>CVXR, caret, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, glmnet</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yikun Zhang &lt;yikunzhang@foxmail.com&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-09 18:15:24 UTC; yikun</td>
</tr>
<tr>
<td>Author:</td>
<td>Yikun Zhang <a href="https://orcid.org/0000-0003-3905-6346"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Alexander Giessing
    <a href="https://orcid.org/0000-0002-6917-0652"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Yen-Chi Chen <a href="https://orcid.org/0000-0002-4485-306X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-09 19:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='DebiasProg'>The proposed debiasing (primal) program.</h2><span id='topic+DebiasProg'></span>

<h3>Description</h3>

<p>This function implements our proposed debiasing (primal) program that solves for
the weights for correcting the Lasso pilot estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DebiasProg(X, x, Pi, gamma_n = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DebiasProg_+3A_x">X</code></td>
<td>
<p>The input design n*d matrix.</p>
</td></tr>
<tr><td><code id="DebiasProg_+3A_x">x</code></td>
<td>
<p>The current query point, which is a 1*d array.</p>
</td></tr>
<tr><td><code id="DebiasProg_+3A_pi">Pi</code></td>
<td>
<p>An n*n diagonal matrix with (estimated) propensity scores as its diagonal entries.</p>
</td></tr>
<tr><td><code id="DebiasProg_+3A_gamma_n">gamma_n</code></td>
<td>
<p>The regularization parameter &quot;<code class="reqn">\gamma/n</code>&quot;. (Default: gamma_n=0.1.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimated weights by our debiasing program, which is a n-dim vector.
</p>


<h3>Author(s)</h3>

<p>Yikun Zhang, <a href="mailto:yikunzhang@foxmail.com">yikunzhang@foxmail.com</a>
</p>


<h3>References</h3>

<p>Zhang, Y., Giessing, A. and Chen, Y.-C. (2023)
<em>Efficient Inference on High-Dimensional Linear Model with Missing Outcomes.</em>
<a href="https://arxiv.org/abs/2309.06429">https://arxiv.org/abs/2309.06429</a>.
</p>
<p>Fu, A., Narasimhan, B. and Boyd, S. (2017) <em>CVXR: An R Package for Disciplined Convex Optimization.
Journal of Statistical Software 94 (14): 1â€“34.</em> doi: <a href="https://doi.org/10.18637/jss.v094.i14">10.18637/jss.v094.i14</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  require(MASS)
  require(glmnet)
  d = 1000
  n = 900

  Sigma = array(0, dim = c(d,d)) + diag(d)
  rho = 0.1
  for(i in 1:(d-1)){
    for(j in (i+1):d){
      if ((j &lt; i+6) | (j &gt; i+d-6)){
        Sigma[i,j] = rho
        Sigma[j,i] = rho
      }
    }
  }
  sig = 1

  ## Current query point
  x_cur = rep(0, d)
  x_cur[c(1, 2, 3, 7, 8)] = c(1, 1/2, 1/4, 1/2, 1/8)
  x_cur = array(x_cur, dim = c(1,d))

  ## True regression coefficient
  s_beta = 5
  beta_0 = rep(0, d)
  beta_0[1:s_beta] = sqrt(5)

  ## Generate the design matrix and outcomes
  X_sim = mvrnorm(n, mu = rep(0, d), Sigma)
  eps_err_sim = sig * rnorm(n)
  Y_sim = drop(X_sim %*% beta_0) + eps_err_sim

  obs_prob = 1 / (1 + exp(-1 + X_sim[, 7] - X_sim[, 8]))
  R_sim = rep(1, n)
  R_sim[runif(n) &gt;= obs_prob] = 0

  ## Estimate the propensity scores via the Lasso-type generalized linear model
  zeta = 5*sqrt(log(d)/n)/n
  lr1 = glmnet(X_sim, R_sim, family = "binomial", alpha = 1, lambda = zeta,
               standardize = TRUE, thresh=1e-6)
  prop_score = drop(predict(lr1, newx = X_sim, type = "response"))

  ## Estimate the debiasing weights
  w_obs = DebiasProg(X_sim, x_cur, Pi=diag(prop_score), gamma_n = 0.1)


</code></pre>

<hr>
<h2 id='DebiasProgCV'>The proposed debiasing (primal) program with cross-validation.</h2><span id='topic+DebiasProgCV'></span>

<h3>Description</h3>

<p>This function implements our proposed debiasing program that selects the tuning parameter
&quot;<code class="reqn">\gamma/n</code>&quot; by cross-validation and returns the final debiasing weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DebiasProgCV(X, x, prop_score, gamma_lst = NULL, cv_fold = 5, cv_rule = "1se")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DebiasProgCV_+3A_x">X</code></td>
<td>
<p>The input design n*d matrix.</p>
</td></tr>
<tr><td><code id="DebiasProgCV_+3A_x">x</code></td>
<td>
<p>The current query point, which is a 1*d array.</p>
</td></tr>
<tr><td><code id="DebiasProgCV_+3A_prop_score">prop_score</code></td>
<td>
<p>An n-dim numeric vector with (estimated) propensity scores
as its entries.</p>
</td></tr>
<tr><td><code id="DebiasProgCV_+3A_gamma_lst">gamma_lst</code></td>
<td>
<p>A numeric vector with candidate values for the regularization
parameter &quot;<code class="reqn">\gamma/n</code>&quot;. (Default: gamma_lst=NULL. Then, gamma_lst contains
41 equally spacing value between 0.001 and max(abs(x)).)</p>
</td></tr>
<tr><td><code id="DebiasProgCV_+3A_cv_fold">cv_fold</code></td>
<td>
<p>The number of folds for cross-validation on the dual program.
(Default: cv_fold=5.)</p>
</td></tr>
<tr><td><code id="DebiasProgCV_+3A_cv_rule">cv_rule</code></td>
<td>
<p>The criteria/rules for selecting the final value of the regularization
parameter &quot;<code class="reqn">\gamma/n</code>&quot; in the dual program. (Default: cv_rule=&quot;1se&quot;. The candidate
choices include &quot;1se&quot;, &quot;minfeas&quot;, and &quot;mincv&quot;.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list that contains three elements.
</p>
<table>
<tr><td><code>w_obs</code></td>
<td>
<p>The final estimated weights by our debiasing program.</p>
</td></tr>
<tr><td><code>ll_obs</code></td>
<td>
<p>The final value of the solution to our debiasing dual program.</p>
</td></tr>
<tr><td><code>gamma_n_opt</code></td>
<td>
<p>The final value of the tuning parameter &quot;<code class="reqn">\gamma/n</code>&quot; selected by cross-validation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yikun Zhang, <a href="mailto:yikunzhang@foxmail.com">yikunzhang@foxmail.com</a>
</p>


<h3>References</h3>

<p>Zhang, Y., Giessing, A. and Chen, Y.-C. (2023)
<em>Efficient Inference on High-Dimensional Linear Model with Missing Outcomes.</em>
<a href="https://arxiv.org/abs/2309.06429">https://arxiv.org/abs/2309.06429</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  require(MASS)
  require(glmnet)
  d = 1000
  n = 900

  Sigma = array(0, dim = c(d,d)) + diag(d)
  rho = 0.1
  for(i in 1:(d-1)){
    for(j in (i+1):d){
      if ((j &lt; i+6) | (j &gt; i+d-6)){
        Sigma[i,j] = rho
        Sigma[j,i] = rho
      }
    }
  }
  sig = 1

  ## Current query point
  x_cur = rep(0, d)
  x_cur[c(1, 2, 3, 7, 8)] = c(1, 1/2, 1/4, 1/2, 1/8)
  x_cur = array(x_cur, dim = c(1,d))

  ## True regression coefficient
  s_beta = 5
  beta_0 = rep(0, d)
  beta_0[1:s_beta] = sqrt(5)

  ## Generate the design matrix and outcomes
  X_sim = mvrnorm(n, mu = rep(0, d), Sigma)
  eps_err_sim = sig * rnorm(n)
  Y_sim = drop(X_sim %*% beta_0) + eps_err_sim

  obs_prob = 1 / (1 + exp(-1 + X_sim[, 7] - X_sim[, 8]))
  R_sim = rep(1, n)
  R_sim[runif(n) &gt;= obs_prob] = 0

  ## Estimate the propensity scores via the Lasso-type generalized linear model
  zeta = 5*sqrt(log(d)/n)/n
  lr1 = glmnet(X_sim, R_sim, family = "binomial", alpha = 1, lambda = zeta,
               standardize = TRUE, thresh=1e-6)
  prop_score = drop(predict(lr1, newx = X_sim, type = "response"))

  ## Estimate the debiasing weights with the tuning parameter selected by cross-validations.
  deb_res = DebiasProgCV(X_sim, x_cur, prop_score, gamma_lst = c(0.1, 0.5, 1),
                         cv_fold = 5, cv_rule = '1se')


</code></pre>

<hr>
<h2 id='DualCD'>Coordinate descent algorithm for solving the dual form of our debiasing program.</h2><span id='topic+DualCD'></span>

<h3>Description</h3>

<p>This function implements the coordinate descent algorithm for the debiasing
dual program. More details can be found in Appendix A of our paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DualCD(
  X,
  x,
  Pi = NULL,
  gamma_n = 0.05,
  ll_init = NULL,
  eps = 1e-09,
  max_iter = 5000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DualCD_+3A_x">X</code></td>
<td>
<p>The input design n*d matrix.</p>
</td></tr>
<tr><td><code id="DualCD_+3A_x">x</code></td>
<td>
<p>The current query point, which is a 1*d array.</p>
</td></tr>
<tr><td><code id="DualCD_+3A_pi">Pi</code></td>
<td>
<p>An n*n diagonal matrix with (estimated) propensity scores as its diagonal entries.</p>
</td></tr>
<tr><td><code id="DualCD_+3A_gamma_n">gamma_n</code></td>
<td>
<p>The regularization parameter &quot;<code class="reqn">\gamma/n</code>&quot;. (Default: gamma_n=0.05.)</p>
</td></tr>
<tr><td><code id="DualCD_+3A_ll_init">ll_init</code></td>
<td>
<p>The initial value of the dual solution vector. (Default: ll_init=NULL. Then, the vector with all-one entries is used.)</p>
</td></tr>
<tr><td><code id="DualCD_+3A_eps">eps</code></td>
<td>
<p>The tolerance value for convergence. (Default: eps=1e-9.)</p>
</td></tr>
<tr><td><code id="DualCD_+3A_max_iter">max_iter</code></td>
<td>
<p>The maximum number of coordinate descent iterations. (Default: max_iter=5000.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The solution vector to our dual debiasing program.
</p>


<h3>Author(s)</h3>

<p>Yikun Zhang, <a href="mailto:yikunzhang@foxmail.com">yikunzhang@foxmail.com</a>
</p>


<h3>References</h3>

<p>Zhang, Y., Giessing, A. and Chen, Y.-C. (2023)
<em>Efficient Inference on High-Dimensional Linear Model with Missing Outcomes.</em>
<a href="https://arxiv.org/abs/2309.06429">https://arxiv.org/abs/2309.06429</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  require(MASS)
  require(glmnet)
  d = 1000
  n = 900

  Sigma = array(0, dim = c(d,d)) + diag(d)
  rho = 0.1
  for(i in 1:(d-1)){
    for(j in (i+1):d){
      if ((j &lt; i+6) | (j &gt; i+d-6)){
        Sigma[i,j] = rho
        Sigma[j,i] = rho
      }
    }
  }
  sig = 1

  ## Current query point
  x_cur = rep(0, d)
  x_cur[c(1, 2, 3, 7, 8)] = c(1, 1/2, 1/4, 1/2, 1/8)
  x_cur = array(x_cur, dim = c(1,d))

  ## True regression coefficient
  s_beta = 5
  beta_0 = rep(0, d)
  beta_0[1:s_beta] = sqrt(5)

  ## Generate the design matrix and outcomes
  X_sim = mvrnorm(n, mu = rep(0, d), Sigma)
  eps_err_sim = sig * rnorm(n)
  Y_sim = drop(X_sim %*% beta_0) + eps_err_sim

  obs_prob = 1 / (1 + exp(-1 + X_sim[, 7] - X_sim[, 8]))
  R_sim = rep(1, n)
  R_sim[runif(n) &gt;= obs_prob] = 0

  ## Estimate the propensity scores via the Lasso-type generalized linear model
  zeta = 5*sqrt(log(d)/n)/n
  lr1 = glmnet(X_sim, R_sim, family = "binomial", alpha = 1, lambda = zeta,
               standardize = TRUE, thresh=1e-6)
  prop_score = drop(predict(lr1, newx = X_sim, type = "response"))

  ## Solve the debiasing dual program
  ll_cur = DualCD(X_sim, x_cur, Pi = diag(prop_score), gamma_n = 0.1, ll_init = NULL,
                  eps=1e-9, max_iter = 5000)


</code></pre>

<hr>
<h2 id='DualObj'>The objective function of the debiasing dual program.</h2><span id='topic+DualObj'></span>

<h3>Description</h3>

<p>This function computes the objective function value of the debiasing dual program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DualObj(X, x, Pi, ll_cur, gamma_n = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DualObj_+3A_x">X</code></td>
<td>
<p>The input design n*d matrix.</p>
</td></tr>
<tr><td><code id="DualObj_+3A_x">x</code></td>
<td>
<p>The current query point, which is a 1*d array.</p>
</td></tr>
<tr><td><code id="DualObj_+3A_pi">Pi</code></td>
<td>
<p>An n*n diagonal matrix with (estimated) propensity scores as its diagonal entries.</p>
</td></tr>
<tr><td><code id="DualObj_+3A_ll_cur">ll_cur</code></td>
<td>
<p>The current value of the dual solution vector.</p>
</td></tr>
<tr><td><code id="DualObj_+3A_gamma_n">gamma_n</code></td>
<td>
<p>The regularization parameter &quot;<code class="reqn">\gamma/n</code>&quot;. (Default: gamma_n=0.1.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the objective function of our dual debiasing program.
</p>


<h3>Author(s)</h3>

<p>Yikun Zhang, <a href="mailto:yikunzhang@foxmail.com">yikunzhang@foxmail.com</a>
</p>


<h3>References</h3>

<p>Zhang, Y., Giessing, A. and Chen, Y.-C. (2023)
<em>Efficient Inference on High-Dimensional Linear Model with Missing Outcomes.</em>
<a href="https://arxiv.org/abs/2309.06429">https://arxiv.org/abs/2309.06429</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  require(MASS)
  require(glmnet)
  d = 1000
  n = 900

  Sigma = array(0, dim = c(d,d)) + diag(d)
  rho = 0.1
  for(i in 1:(d-1)){
    for(j in (i+1):d){
      if ((j &lt; i+6) | (j &gt; i+d-6)){
        Sigma[i,j] = rho
        Sigma[j,i] = rho
      }
    }
  }
  sig = 1

  ## Current query point
  x_cur = rep(0, d)
  x_cur[c(1, 2, 3, 7, 8)] = c(1, 1/2, 1/4, 1/2, 1/8)
  x_cur = array(x_cur, dim = c(1,d))

  ## True regression coefficient
  s_beta = 5
  beta_0 = rep(0, d)
  beta_0[1:s_beta] = sqrt(5)

  ## Generate the design matrix and outcomes
  X_sim = mvrnorm(n, mu = rep(0, d), Sigma)
  eps_err_sim = sig * rnorm(n)
  Y_sim = drop(X_sim %*% beta_0) + eps_err_sim

  obs_prob = 1 / (1 + exp(-1 + X_sim[, 7] - X_sim[, 8]))
  R_sim = rep(1, n)
  R_sim[runif(n) &gt;= obs_prob] = 0

  ## Estimate the propensity scores via the Lasso-type generalized linear model
  zeta = 5*sqrt(log(d)/n)/n
  lr1 = glmnet(X_sim, R_sim, family = "binomial", alpha = 1, lambda = zeta,
               standardize = TRUE, thresh=1e-6)
  prop_score = drop(predict(lr1, newx = X_sim, type = "response"))

  ## Solve the debiasing dual program and estimate the dual objective function value
  ll_cur = DualCD(X_sim, x_cur, Pi = diag(prop_score), gamma_n = 0.1, ll_init = NULL,
                  eps=1e-9, max_iter = 5000)
  dual_val = DualObj(X_sim, x_cur, Pi=diag(prop_score), ll_cur=ll_cur, gamma_n=0.1)


</code></pre>

<hr>
<h2 id='SoftThres'>The soft-thresholding function</h2><span id='topic+SoftThres'></span>

<h3>Description</h3>

<p>This function implements the soft-threshold operator
<code class="reqn">S_{\lambda}(x)=sign(x)\cdot (x-\lambda)_+</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SoftThres(theta, lamb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SoftThres_+3A_theta">theta</code></td>
<td>
<p>The input numeric vector.</p>
</td></tr>
<tr><td><code id="SoftThres_+3A_lamb">lamb</code></td>
<td>
<p>The thresholding parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The resulting vector after soft-thresholding.
</p>


<h3>Author(s)</h3>

<p>Yikun Zhang, <a href="mailto:yikunzhang@foxmail.com">yikunzhang@foxmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a = c(1,2,4,6)
SoftThres(theta=a, lamb=3)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
