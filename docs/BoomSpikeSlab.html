<!DOCTYPE html><html><head><title>Help for package BoomSpikeSlab</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BoomSpikeSlab}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#independent.spike.slab.prior'>
<p>A spike and slab prior assuming a priori independence.</p></a></li>
<li><a href='#independent.student.spike.slab.prior'>
<p>Spike and Slab Prior for Regressions with Student T Errors</p></a></li>
<li><a href='#lm.spike'>
<p>Spike and slab regression</p></a></li>
<li><a href='#logit.spike'>
<p>Spike and slab logistic regression</p></a></li>
<li><a href='#logit.zellner.prior'>
<p>Zellner Prior for Logistic Regression</p></a></li>
<li><a href='#mlm.spike'>
<p>Spike and slab multinomial logistic regression</p></a></li>
<li><a href='#mlm.spike.slab.prior'>
<p>Create a spike and slab prior for use with mlm.spike.</p></a></li>
<li><a href='#model.matrix'>
<p>GetPredictorMatrix</p></a></li>
<li><a href='#model.matrix.glm.spike'>
<p>Construct Design Matrices</p></a></li>
<li><a href='#nested.regression'>
<p>Nested Regression</p></a></li>
<li><a href='#nnet'>
<p>Bayesian Feed Forward Neural Networks</p></a></li>
<li><a href='#partial.dependence.plot'>
<p>Plot a Bayesian Neural Network</p></a></li>
<li><a href='#plot.BayesNnet'>
<p>Plot a Bayesian Neural Network</p></a></li>
<li><a href='#plot.coefficients'>
<p>Plot Coefficients.</p></a></li>
<li><a href='#plot.lm.spike'>
<p>Plot the results of a spike and slab regression.</p></a></li>
<li><a href='#plot.lm.spike.fit'>
<p>Predicted vs actual plot for lm.spike.</p></a></li>
<li><a href='#plot.lm.spike.residuals'>
<p>Residual plot for lm.spike</p></a></li>
<li><a href='#plot.logit.spike'>
<p>Plot a <code>logit.spike</code> object</p></a></li>
<li><a href='#plot.logit.spike.fit.summary'>
<p>Plot Logit or Probit Fit Summary</p></a></li>
<li><a href='#plot.logit.spike.residuals'>
<p>Residual plot for <code>logit.spike</code> objects.</p></a></li>
<li><a href='#plot.marginal.inclusion.probabilities'>
<p>Plot marginal inclusion probabilities.</p></a></li>
<li><a href='#plot.poisson.spike'>
<p>Plot a <code>poisson.spike</code> object</p></a></li>
<li><a href='#plot.qreg.spike'>
<p>Plot the results of a spike and slab regression.</p></a></li>
<li><a href='#PlotModelSize'>
<p>Plot a distribution of model size</p></a></li>
<li><a href='#poisson.spike'>
<p>Spike and slab Poisson regression</p></a></li>
<li><a href='#poisson.zellner.prior'>
<p>Zellner Prior for Poisson Regression</p></a></li>
<li><a href='#predict.lm.spike'>
<p>Predictions using spike-and-slab regression.</p></a></li>
<li><a href='#print.summary.lm.spike'>
<p>Print method for spikeslab objects.</p></a></li>
<li><a href='#probit.spike'>
<p>Spike and slab probit regression</p></a></li>
<li><a href='#qreg.spike'>
<p>Quantile Regression</p></a></li>
<li><a href='#residuals.lm.spike'>
<p>Extract lm.spike Residuals</p></a></li>
<li><a href='#shrinkage.regression'>
<p>Shrinking Regression Coefficients</p></a></li>
<li><a href='#spike.slab.glm.prior'>
<p>Zellner Prior for Glm's.</p></a></li>
<li><a href='#spike.slab.prior'>
<p>Create a spike and slab prior for use with lm.spike.</p></a></li>
<li><a href='#spike.slab.prior.base'><p>Base class for spike and slab priors</p></a></li>
<li><a href='#spliunes'>
<p>Spline Basis Expansions</p></a></li>
<li><a href='#student.spike.slab.prior'>
<p>Spike and Slab Prior for Student-T Regression</p></a></li>
<li><a href='#suggest.burn'>
<p>Suggest Burn-in</p></a></li>
<li><a href='#SummarizeSpikeSlabCoefficients'>
<p>Numerical summaries of coefficients from a spike and slab regression.</p></a></li>
<li><a href='#summary.lm.spike'>
<p>Numerical summaries of the results from a spike and slab regression.</p></a></li>
<li><a href='#summary.logit.spike'>
<p>Numerical summaries of the results from a spike and slab logistic regression.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.2.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-14</td>
</tr>
<tr>
<td>Title:</td>
<td>MCMC for Spike and Slab Regression</td>
</tr>
<tr>
<td>Author:</td>
<td>Steven L. Scott &lt;steve.the.bayesian@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Steven L. Scott &lt;steve.the.bayesian@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Spike and slab regression with a variety of residual error
  distributions corresponding to Gaussian, Student T, probit, logit, SVM, and a
  few others.  Spike and slab regression is Bayesian regression with prior
  distributions containing a point mass at zero.  The posterior updates the
  amount of mass on this point, leading to a posterior distribution that is
  actually sparse, in the sense that if you sample from it many coefficients are
  actually zeros.  Sampling from this posterior distribution is an elegant way
  to handle Bayesian variable selection and model averaging.  See
  &lt;<a href="https://doi.org/10.1504%2FIJMMNO.2014.059942">doi:10.1504/IJMMNO.2014.059942</a>&gt; for an explanation of the Gaussian case.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2.1">LGPL-2.1</a> | file LICENSE</td>
</tr>
<tr>
<td>Depends:</td>
<td>Boom (&ge; 0.9.13) , R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Boom(&ge; 0.9.13)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, testthat, mlbench, igraph</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-16 23:55:33 UTC; steve</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-17 00:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='independent.spike.slab.prior'>
A spike and slab prior assuming a priori independence.
</h2><span id='topic+IndependentSpikeSlabPrior'></span>

<h3>Description</h3>

<p>A spike and slab prior on the regression coefficients.  The prior
distribution assumes coefficients to be independent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IndependentSpikeSlabPrior(x = NULL,
                          y = NULL,
                          expected.r2 = .5,
                          prior.df = .01,
                          expected.model.size = 1,
                          prior.beta.sd = NULL,
                          optional.coefficient.estimate = NULL,
                          mean.y = mean(y, na.rm = TRUE),
                          sdy = sd(as.numeric(y), na.rm = TRUE),
                          sdx = apply(as.matrix(x), 2, sd, na.rm = TRUE),
                          prior.inclusion.probabilities = NULL,
                          number.of.observations = nrow(x),
                          number.of.variables = ncol(x),
                          scale.by.residual.variance = FALSE,
                          sigma.upper.limit = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="independent.spike.slab.prior_+3A_x">x</code></td>
<td>

<p>The design matrix for the regression problem.  Missing data is not allowed.
</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_y">y</code></td>
<td>

<p>The vector of responses for the regression.  Missing data is not allowed.
</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_expected.r2">expected.r2</code></td>
<td>

<p>The expected R-square for the regression.  The spike and slab prior
requires an inverse gamma prior on the residual variance of the
regression.  The prior can be parameterized in terms of a guess at
the residual variance, and a &quot;degrees of freedom&quot; representing the
number of observations that the guess should weigh.  The guess at
sigma^2 is set to <code> (1-expected.r2) * var(y) </code>.
</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_prior.df">prior.df</code></td>
<td>

<p>A positive scalar representing the prior 'degrees of freedom' for
estimating the residual variance.  This can be thought of as the
amount of weight (expressed as an observation count) given to the
<code>expected.r2</code> argument.
</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor p variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_prior.beta.sd">prior.beta.sd</code></td>
<td>

<p>A vector of positive numbers giving the prior standard deviation of
each model coefficient, conditionl on inclusion.  If NULL it will be
set to 10 * the ratio of sdy / sdx.
</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_mean.y">mean.y</code></td>
<td>
<p>The mean of the response vector, for use in cases when
specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_sdy">sdy</code></td>
<td>
<p>The standard deviation of the response vector, for use in
cases when specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_sdx">sdx</code></td>
<td>
<p>The standard deviations to use when scaling the prior sd of
each coefficient. </p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_number.of.observations">number.of.observations</code></td>
<td>
<p>The number of observations in the data
to be modeled.</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_number.of.variables">number.of.variables</code></td>
<td>
<p>The number of potential predictor variables
in the data to be modeled.</p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_scale.by.residual.variance">scale.by.residual.variance</code></td>
<td>
<p>If <code>TRUE</code> the prior variance is
<code>sigma_sq * V</code>, where <code>sigma_sq</code> is the residual variance of the
linear regression modeled by this prior.  Otherwise the prior
variance is <code>V</code>, unscaled. </p>
</td></tr>
<tr><td><code id="independent.spike.slab.prior_+3A_sigma.upper.limit">sigma.upper.limit</code></td>
<td>
<p>The largest acceptable value for the residual
standard deviation.  A non-positive number is interpreted as
<code>Inf</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with with the components necessary to run <code>lm.spike</code> with
method &quot;DA&quot;.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Ghosh and Clyde (2011) &quot;Rao-Blackwellization for Bayesian variable
selection and model averaging in linear and binary regression: A novel
data augmentation approach&quot;, <em>Journal of the American Statistical
Association</em>, <b>106</b> 1041-1052.
<a href="https://homepage.stat.uiowa.edu/~jghsh/ghosh_clyde_2011_jasa.pdf">https://homepage.stat.uiowa.edu/~jghsh/ghosh_clyde_2011_jasa.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  x &lt;- cbind(1, matrix(rnorm(900), ncol = 9))
  beta &lt;- rep(0, 10)
  beta[1] &lt;- 3
  beta[5] &lt;- -4
  beta[8] &lt;- 2
  y &lt;- rnorm(100, x %*% beta)
  ## x has 10 columns, including the intercept
  prior &lt;- IndependentSpikeSlabPrior(x, y,
             expected.model.size = 3,  # expect 3 nonzero predictors
             prior.df = .01,           # weaker prior than the default
             optional.coefficient.estimate = rep(0, 10) # shrink to zero
          )
  ## now 'prior' can be fed to 'lm.spike'
  x &lt;- x[, -1]
  model &lt;- lm.spike(y ~ x, niter = 1000, prior = prior, model.options = OdaOptions())
</code></pre>

<hr>
<h2 id='independent.student.spike.slab.prior'>
Spike and Slab Prior for Regressions with Student T Errors
</h2><span id='topic+StudentIndependentSpikeSlabPrior'></span>

<h3>Description</h3>

<p> A spike and slab prior on the parameters of a regression
model with Student T errors.  The prior assumes independence amon the
regression coefficients.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>StudentIndependentSpikeSlabPrior(
    predictor.matrix = NULL,
    response.vector = NULL,
    expected.r2 = .5,
    prior.df = .01,
    expected.model.size = 1,
    prior.beta.sd = NULL,
    optional.coefficient.estimate = NULL,
    mean.y = mean(response.vector, na.rm = TRUE),
    sdy = sd(as.numeric(response.vector), na.rm = TRUE),
    sdx = apply(as.matrix(predictor.matrix), 2, sd, na.rm = TRUE),
    prior.inclusion.probabilities = NULL,
    number.of.observations = nrow(predictor.matrix),
    number.of.variables = ncol(predictor.matrix),
    scale.by.residual.variance = FALSE,
    sigma.upper.limit = Inf,
    degrees.of.freedom.prior = UniformPrior(.1, 100))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="independent.student.spike.slab.prior_+3A_predictor.matrix">predictor.matrix</code></td>
<td>

<p>The design matrix for the regression problem.  Missing data is not allowed.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_response.vector">response.vector</code></td>
<td>

<p>The vector of responses for the regression.  Missing data is not allowed.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_expected.r2">expected.r2</code></td>
<td>

<p>The expected R-square for the regression.  The spike and slab prior
requires an inverse gamma prior on the residual variance of the
regression.  The prior can be parameterized in terms of a guess at
the residual variance, and a &quot;degrees of freedom&quot; representing the
number of observations that the guess should weigh.  The guess at
sigma^2 is set to <code> (1-expected.r2) * var(y) </code>.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_prior.df">prior.df</code></td>
<td>

<p>A positive scalar representing the prior 'degrees of freedom' for
estimating the residual variance.  This can be thought of as the
amount of weight (expressed as an observation count) given to the
<code>expected.r2</code> argument.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor p variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_prior.beta.sd">prior.beta.sd</code></td>
<td>

<p>A vector of positive numbers giving the prior standard deviation of
each model coefficient, conditionl on inclusion.  If NULL it will be
set to 10 * the ratio of sdy / sdx.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_mean.y">mean.y</code></td>
<td>
<p>The mean of the response vector, for use in cases when
specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_sdy">sdy</code></td>
<td>
<p>The standard deviation of the response vector, for use in
cases when specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_sdx">sdx</code></td>
<td>
<p>The standard deviations to use when scaling the prior sd of
each coefficient. </p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_number.of.observations">number.of.observations</code></td>
<td>
<p>The number of observations in the data
to be modeled.</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_number.of.variables">number.of.variables</code></td>
<td>
<p>The number of potential predictor variables
in the data to be modeled.</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_scale.by.residual.variance">scale.by.residual.variance</code></td>
<td>
<p>If <code>TRUE</code> the prior variance is
<code>sigma_sq * V</code>, where <code>sigma_sq</code> is the residual variance of the
linear regression modeled by this prior.  Otherwise the prior
variance is <code>V</code>, unscaled. </p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_sigma.upper.limit">sigma.upper.limit</code></td>
<td>
<p>The largest acceptable value for the residual
standard deviation.  A non-positive number is interpreted as
<code>Inf</code>.
</p>
</td></tr>
<tr><td><code id="independent.student.spike.slab.prior_+3A_degrees.of.freedom.prior">degrees.of.freedom.prior</code></td>
<td>
<p>An object of class
<code><a href="Boom.html#topic+DoubleModel">DoubleModel</a></code> representing the prior distribution for the
Student T tail thickness (or &quot;degrees of freedom&quot;) parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code><a href="#topic+IndependentSpikeSlabPrior">IndependentSpikeSlabPrior</a></code> with
<code>degrees.of.freedom.prior</code> appended.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Ghosh and Clyde (2011) &quot;Rao-Blackwellization for Bayesian variable
selection and model averaging in linear and binary regression: A novel
data augmentation approach&quot;, <em>Journal of the American Statistical
Association</em>, <b>106</b> 1041-1052.
<a href="https://homepage.stat.uiowa.edu/~jghsh/ghosh_clyde_2011_jasa.pdf">https://homepage.stat.uiowa.edu/~jghsh/ghosh_clyde_2011_jasa.pdf</a>
</p>

<hr>
<h2 id='lm.spike'>
Spike and slab regression
</h2><span id='topic+lm.spike'></span><span id='topic+spikeslab'></span><span id='topic+SsvsOptions'></span><span id='topic+OdaOptions'></span>

<h3>Description</h3>

<p>MCMC algorithm for linear regression models with a 'spike-and-slab'
prior that places some amount of posterior probability at zero for a
subset of the regression coefficients.
</p>
<p>The model admits either Gaussian or student T errors; the latter are
useful in the presence of outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm.spike(formula,
         niter,
         data,
         subset,
         prior = NULL,
         error.distribution = c("gaussian", "student"),
         contrasts = NULL,
         drop.unused.levels = TRUE,
         model.options = SsvsOptions(),
         ping = niter / 10,
         seed = NULL,
         ...)

SsvsOptions(adaptive.cutoff = 100,
            adaptive.step.size = .001,
            target.acceptance.rate = .345,
            correlation.swap.threshold = .8)

OdaOptions(fallback.probability = 0.0,
           eigenvalue.fudge.factor = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm.spike_+3A_formula">formula</code></td>
<td>

<p>formula for the maximal model (with all variables included), this is
parsed the same way as a call to <code>lm</code>.
</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_niter">niter</code></td>
<td>

<p>The number of MCMC iterations to run.  Be sure to include enough so
you can throw away a burn-in set.
</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_data">data</code></td>
<td>

<p>An optional data frame, list or environment (or object coercible by
'as.data.frame' to a data frame) containing the variables in the
model.  If not found in 'data', the variables are taken from
'environment(formula)', typically the environment from which
'lm.spike' is called.
</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_subset">subset</code></td>
<td>

<p>An optional vector specifying a subset of observations to be used in
the fitting process.
</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_prior">prior</code></td>
<td>
<p> An optional list returned by
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.  If <code>prior</code> is missing then a
default prior will be used.  See <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.
</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_error.distribution">error.distribution</code></td>
<td>
<p>Specify either Gaussian or Student T
errors.  If the error distribution is student then the prior
must be a <code><a href="#topic+StudentSpikeSlabPrior">StudentSpikeSlabPrior</a></code> and the SSVS method
must be used.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code>
argument of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="lm.spike_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p>Logical indicating whether unobserved factor
levels should be dropped from the model.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_model.options">model.options</code></td>
<td>
<p>A list containing the tuning parameters for the
desired MCMC method.  </p>
</td></tr>
<tr><td><code id="lm.spike_+3A_ping">ping</code></td>
<td>
<p>The frequency with which to print status update messages
to the screen.  For example, if <code>ping == 10</code> then an update
will be printed every 10 MCMC iterations.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_seed">seed</code></td>
<td>
<p>An integer to use as the random seed for the underlying
C++ code.  If <code>NULL</code> then the seed will be set using the
clock.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_...">...</code></td>
<td>

<p>Extra arguments to be passed to <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code> (if
<code>method == "SSVS"</code>) or <code><a href="#topic+IndependentSpikeSlabPrior">IndependentSpikeSlabPrior</a></code>
(if <code>method == "ODA"</code>).</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_fallback.probability">fallback.probability</code></td>
<td>
<p> When using the ODA method, each MCMC
iteration will use SSVS instead of ODA with this probability.  In
cases where the latent data have high leverage, ODA mixing can
suffer.  Mixing in a few SSVS steps can help keep an errant
algorithm on track.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_eigenvalue.fudge.factor">eigenvalue.fudge.factor</code></td>
<td>
<p>When using the ODA method, the latent
X's will be chosen so that the complete data X'X matrix (after
scaling) is a constant diagonal matrix equal to the largest
eigenvalue of the observed (scaled) X'X times (1 +
eigenvalue.fudge.factor).  This should be a small positive number.
</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_adaptive.cutoff">adaptive.cutoff</code></td>
<td>
<p>The traditional SSVS method (sample every
predictor at every iteration) will be used when there are fewer than
this many predictors.  The adaptive method of Benson and Fried will
be used if there are more.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_adaptive.step.size">adaptive.step.size</code></td>
<td>
<p>The step size scaling factor to use in the
adaptive SSVS algorithm.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_target.acceptance.rate">target.acceptance.rate</code></td>
<td>
<p>The target acceptance rate for the
adaptive SSVS algorithm.</p>
</td></tr>
<tr><td><code id="lm.spike_+3A_correlation.swap.threshold">correlation.swap.threshold</code></td>
<td>
<p> The minimal absolute correlation
required for two variables to be considered for a swap move.  Swap
moves are currently only supported for less than
<code>adaptive.cutoff</code> variables.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two MCMC methods available.  SSVS is the stochastic search
variable selection algorithm from George and McCulloch (1998).  ODA is
the orthogonal data augmentation method from Clyde and Ghosh (2011).
Both sampling methods (&quot;ODA&quot; and &quot;SSVS&quot;) draw each variable inclusion
indicator given all others, in a Gibbs sampler.  The ODA method
includes an extra data augmentation step that renders each indicator
conditionally independent of the others given the latent data.  There
is residual dependence between successive MCMC steps introduced by the
latent data, but the paper by Ghosh and Clyde suggested that on
balance mixing should be improved.
</p>
<p>SSVS offers a choice between to implementations.  Classic SSVS
attempts to flip each coefficient in or out of the model every
iteration.  The adaptive method attempts to learn which coefficients
are likely to be included or excluded.  It then biases its 'birth' and
'death' moves towards candidates that are likely to succeed.
</p>
<p>Regarding the overall compute time, the DA method decomposes the
(potentially very large) model matrix one time, at the start of the
algorithm.  But it then works with independent scalar updates.  The
SSVS algorithm does not have the upfront cost, but it works with many
small matrix decompositions each MCMC iteration.  The DA algorithm is
very likely to be faster in terms of time per iteration.
</p>
<p>Finally, note that the two algorithms require slightly different
priors.  The DA algorithm requires a priori independence, while the
SSVS algorithm can work with arbitrary conjugate priors.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>lm.spike</code>, which is a list with the
following elements
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code>niter</code> by <code>ncol(x)</code> matrix of regression
coefficients, many of which may be zero.  Each row corresponds to an
MCMC iteration. </p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p> A vector of length <code>niter</code> containing the MCMC
draws of the residual standard deviation parameter. </p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to fit the model.  If a <code>prior</code> was
supplied as an argument it will be returned.  Otherwise this will be
the automatically generated prior based on the other function
arguments. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>George and McCulloch (1997), &quot;Approaches to Bayesian Variable
Selection&quot;, <em>Statistica Sinica</em>, <b>7</b>, 339 &ndash; 373.
<a href="https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf">https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf</a>
</p>
<p>Ghosh and Clyde (2011) &quot;Rao-Blackwellization for Bayesian variable
selection and model averaging in linear and binary regression: A novel
data augmentation approach&quot;, <em>Journal of the American Statistical
Association</em>, <b>106</b> 1041-1052.
<a href="https://homepage.stat.uiowa.edu/~jghsh/ghosh_clyde_2011_jasa.pdf">https://homepage.stat.uiowa.edu/~jghsh/ghosh_clyde_2011_jasa.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>,
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>,
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3
  niter &lt;- 1000
  sigma &lt;- .8

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, x %*% beta, sigma)
  x &lt;- x[,-1]
  model &lt;- lm.spike(y ~ x, niter=niter)
  plot.ts(model$beta)
  hist(model$sigma)  ## should be near 8
  plot(model)
  summary(model)
  plot(model, "residuals")

  ## Now replace the first observation with a big outlier.
  y[1] &lt;- 50
  model &lt;- lm.spike(y ~ x, niter = niter)
  model2 &lt;- lm.spike(y ~ x, niter = niter, error.distribution = "student")
  pred &lt;- predict(model, newdata = x)
  pred2 &lt;- predict(model2, newdata = x)

  ## Maximize the plot window before making these box plots.  They show
  ## the posterior predictive distribution of all 100 data points, so
  ## make sure your screen is 100 boxes wide!
  par(mfrow = c(2,1))
  BoxplotTrue(t(pred), truth = y, ylim = range(pred), pch = ".",
     main = "Posterior predictive distribution assuming Gaussian errors.")
  BoxplotTrue(t(pred2), truth = y, ylim  = range(pred), pch = ",",
     main = "Posterior predictive distribution assuming Student errors.")

  ## The posterior predictive distributions are much tighter in the
  ## student case than in the Gaussian case, even though the student
  ## model has heavier tails, because the "sigma" parameter is smaller.
  par(mfrow = c(1,1))
  CompareDensities(list(gaussian = model$sigma, student = model2$sigma),
                        xlab = "sigma")
</code></pre>

<hr>
<h2 id='logit.spike'>
Spike and slab logistic regression
</h2><span id='topic+logit.spike'></span>

<h3>Description</h3>

<p>MCMC algorithm for logistic regression models with a 'spike-and-slab'
prior that places some amount of posterior probability at zero for a
subset of the regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit.spike(formula,
            niter,
            data,
            subset,
            prior = NULL,
            na.action = options("na.action"),
            contrasts = NULL,
            drop.unused.levels = TRUE,
            initial.value = NULL,
            ping = niter / 10,
            nthreads = 0,
            clt.threshold = 2,
            mh.chunk.size = 10,
            proposal.df = 3,
            sampler.weights = c("DA" = .333, "RWM" = .333, "TIM" = .333),
            seed = NULL,
            ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit.spike_+3A_formula">formula</code></td>
<td>
<p> formula for the maximal model (with all variables
included), this is parsed the same way as a call to
<code><a href="stats.html#topic+glm">glm</a></code>, but no <code>family</code> argument is needed.  Like
<code><a href="stats.html#topic+glm">glm</a></code>, a two-column input format (success-count,
failure-count).  Otherwise, the response variable can be a logical
or numeric vector.  If numeric, then values &gt;0 indicate a
&quot;success&quot;.  </p>
</td></tr>
<tr><td><code id="logit.spike_+3A_niter">niter</code></td>
<td>
<p> The number of MCMC iterations to run.  Be sure to
include enough so you can throw away a burn-in set.  </p>
</td></tr>
<tr><td><code id="logit.spike_+3A_data">data</code></td>
<td>
<p> An optional data frame, list or environment (or object
coercible by 'as.data.frame' to a data frame) containing the
variables in the model.  If not found in 'data', the variables are
taken from 'environment(formula)', typically the environment from
which logit.spike' is called.  </p>
</td></tr>
<tr><td><code id="logit.spike_+3A_subset">subset</code></td>
<td>
<p> An optional vector specifying a subset of observations
to be used in the fitting process.  </p>
</td></tr>
<tr><td><code id="logit.spike_+3A_prior">prior</code></td>
<td>
<p>A n object inheriting from
<code><a href="#topic+SpikeSlabGlmPrior">SpikeSlabGlmPrior</a></code>.  If <code>prior</code> is supplied it
will be used.  Otherwise a prior distribution will constructed by
calling <code><a href="#topic+LogitZellnerPrior">LogitZellnerPrior</a></code>.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when
the data contain <code>NA</code>s.  The default is set by the
<code>na.action</code> setting of <code>options</code>, and is <code>na.fail</code> if
that is unset.  The <code>factory-fresh</code> default is <code>na.omit</code>.
Another possible value is <code>NULL</code>, no action.  Value
<code>na.exclude</code> can be useful.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code> of
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="logit.spike_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p> A logical value indicating whether factor
levels that are unobserved should be dropped from the model.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_initial.value">initial.value</code></td>
<td>
<p>Initial value for the MCMC algorithm.  Can either
be a numeric vector, a <code><a href="stats.html#topic+glm">glm</a></code> object (from which the
coefficients will be used), or a <code><a href="#topic+logit.spike">logit.spike</a></code> object.
If a <code><a href="#topic+logit.spike">logit.spike</a></code> object is supplied, it is assumed to
be from a previous MCMC run for which <code>niter</code> additional draws
are desired.  If a <code><a href="stats.html#topic+glm">glm</a></code> object is supplied then its
coefficients will be used as the initial values for the simulation.
</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_ping">ping</code></td>
<td>
<p>If positive, then print a status update to the console
every <code>ping</code> MCMC iterations.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_nthreads">nthreads</code></td>
<td>
<p>The number of CPU-threads to use for data
augmentation.  There is some small overhead to stopping and starting
threads.  For small data sets, thread overhead will make it faster
to run single threaded.  For larger data sets multi-threading can
speed things up substantially.  This is all machine dependent, so
please experiment.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_clt.threshold">clt.threshold</code></td>
<td>
<p>When the model is presented with binomial data
(i.e. when the response is a two-column matrix) the data
augmentation algorithm can be made more efficient by updating a
single, asymptotically normal scalar quantity for each unique value
of the predictors.  The asymptotic result will be used whenever the
number of successes or failures exceeds <code>clt.threshold</code>.
</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_mh.chunk.size">mh.chunk.size</code></td>
<td>
<p>The maximum number of coefficients to draw in a
single &quot;chunk&quot; of a Metropolis-Hastings update.  See details. </p>
</td></tr>
<tr><td><code id="logit.spike_+3A_proposal.df">proposal.df</code></td>
<td>
<p>The degrees of freedom parameter to use in
Metropolis-Hastings proposals.  See details.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_sampler.weights">sampler.weights</code></td>
<td>
<p>The proportion of MCMC iterations spent in each
of the three algorithms described in the Details section. This must
be a vector of length 3, with names &quot;DA&quot;, &quot;RWM&quot; and &quot;TIM&quot;,
containing non-negative elements that sum to (within numerical
error .999 or 1.001 are okay).</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_seed">seed</code></td>
<td>
<p>Seed to use for the C++ random number generator.  It
should be <code>NULL</code> or an int.  If <code>NULL</code> the seed value will
be taken from the global <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> object.</p>
</td></tr>
<tr><td><code id="logit.spike_+3A_...">...</code></td>
<td>
<p> Extra arguments passed to
<code><a href="#topic+LogitZellnerPrior">LogitZellnerPrior</a></code> in the case where <code>prior</code> is
<code>NULL</code>.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model parameters are updated using a composite of three
Metropolis-Hastings updates.  An auxiliary mixture sampling algorithm
(Tuchler 2008) updates the entire parameter vector at once, but can
mix slowly.
</p>
<p>The second algorithm is a random walk Metropolis update based on a
multivariate T proposal with <code>proposal.df</code> degrees of freedom.
If <code>proposal.df</code> is nonpositive then a Gaussian proposal is used.
The variance of the proposal distribution is based on the Fisher
information matrix evaluated at the current draw of the coefficients.
</p>
<p>The third algorithm is an independence Metropolis sampler centered on
the posterior mode with variance determined by posterior information
matrix (Fisher information plus prior information).  If
<code>proposal.df &gt; 0</code> then the tails of the proposal are inflated so
that a multivariate T proposal is used instead.
</p>
<p>For either of the two MH updates, at most <code>mh.chunk.size</code>
coefficients will be updated at a time.  At each iteration, one of the
three algorithms is chosen at random.  The auxiliary mixture sampler
is the only one that can change the dimension of the coefficient
vector.  The MH algorithms only update the coefficients that are
currently nonzero.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>logit.spike</code>, which inherits from
<code>lm.spike</code>.  The returned object is a list with the following
elements
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code>niter</code> by <code>ncol(x)</code> matrix of regression
coefficients, many of which may be zero.  Each row corresponds to an
MCMC iteration.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to fit the model.  If a <code>prior</code> was
supplied as an argument it will be returned.  Otherwise this will be
the automatically generated prior based on the other function
arguments. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Tuchler (2008), &quot;Bayesian Variable Selection for Logistic Models Using
Auxiliary Mixture Sampling&quot;, <em>Journal of Computational and
Graphical Statistics</em>, <b>17</b> 76 &ndash; 94.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+plot.logit.spike">plot.logit.spike</a></code>,
<code><a href="#topic+PlotLogitSpikeFitSummary">PlotLogitSpikeFitSummary</a></code>
<code><a href="#topic+PlotLogitSpikeResiduals">PlotLogitSpikeResiduals</a></code>
<code><a href="#topic+summary.logit.spike">summary.logit.spike</a></code>,
<code><a href="#topic+predict.logit.spike">predict.logit.spike</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("MASS")) {
  data(Pima.tr, package = "MASS")
  data(Pima.te, package = "MASS")
  pima &lt;- rbind(Pima.tr, Pima.te)
  model &lt;- logit.spike(type == "Yes" ~ ., data = pima, niter = 500)
  plot(model)
  plot(model, "fit")
  plot(model, "residuals")
  plot(model, "size")
  summary(model)
}
</code></pre>

<hr>
<h2 id='logit.zellner.prior'>
Zellner Prior for Logistic Regression
</h2><span id='topic+LogitZellnerPrior'></span><span id='topic+LogitPrior'></span>

<h3>Description</h3>

<p>A Zellner-style spike and slab prior for logistic regression models.
See 'Details' for a definition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogitZellnerPrior(
    predictors,
    successes = NULL,
    trials = NULL,
    prior.success.probability = NULL,
    expected.model.size = 1,
    prior.information.weight = .01,
    diagonal.shrinkage = .5,
    optional.coefficient.estimate = NULL,
    max.flips = -1,
    prior.inclusion.probabilities = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit.zellner.prior_+3A_predictors">predictors</code></td>
<td>

<p>The design matrix for the regression problem.  No missing data is allowed.
</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_successes">successes</code></td>
<td>
<p> The vector of responses, which can be 0/1,
<code>TRUE/FALSE</code>, or 1/-1.  This is only used to obtain the empirical
overall success rate, so it can be left <code>NULL</code> if
prior.success.probability is specified.
</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_trials">trials</code></td>
<td>
<p>A vector of the same length as successes, giving the
number of trials for each success count (trials cannot be less than
successes).  If successes is binary (or <code>NULL</code>) then this can
be <code>NULL</code> as well, signifying that there was only one trial per
experiment.</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_prior.success.probability">prior.success.probability</code></td>
<td>
<p>The overal prior guess at the
proportion of successes.  This is used in two places.  It is an
input into the intercept term of the default
<code>optional.coefficient.estimate</code>, and it is used as a weight for
the prior information matrix.  See 'Details'.</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_prior.information.weight">prior.information.weight</code></td>
<td>

<p>A positive scalar.  Number of observations worth of weight that
should be given to the prior estimate of beta.
</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_diagonal.shrinkage">diagonal.shrinkage</code></td>
<td>

<p>The conditionally Gaussian prior for beta (the &quot;slab&quot;) starts with a
precision matrix equal to the information in a single observation.
However, this matrix might not be full rank.  The matrix can be made
full rank by averaging with its diagonal.  <code>diagonal.shrinkage</code>
is the weight given to the diaonal in this average.  Setting this to
zero gives Zellner's g-prior.
</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_max.flips">max.flips</code></td>
<td>
<p>The maximum number of variable inclusion indicators
the sampler will attempt to sample each iteration.  If negative then
all indicators will be sampled.</p>
</td></tr>
<tr><td><code id="logit.zellner.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.  If <code>NULL</code> then a
default set of probabilities is obtained by setting each element
equal to <code>min(1, expected.model.size / ncol(x))</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> A Zellner-style spike and slab prior for logistic regression.
Denote the vector of coefficients by <code class="reqn">\beta</code>, and the vector
of inclusion indicators by <code class="reqn">\gamma</code>.  These are linked by the
relationship <code class="reqn">\beta_i \ne 0</code> if <code class="reqn">\gamma_i =
1</code> and <code class="reqn">\beta_i = 0</code> if <code class="reqn">\gamma_i =
0</code>.  The prior is
</p>
<p style="text-align: center;"><code class="reqn">\beta | \gamma \sim N(b, V)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma \sim B(\pi)</code>
</p>

<p>where <code class="reqn">\pi</code> is the vector of
<code>prior.inclusion.probabilities</code>, and <code class="reqn">b</code> is the
<code>optional.coefficient.estimate</code>.  Conditional on
<code class="reqn">\gamma</code>, the prior information matrix is
</p>
<p style="text-align: center;"><code class="reqn">V^{-1} = \kappa ((1 - \alpha) x^Twx / n + \alpha diag(x^Twx / n))</code>
</p>

<p>The matrix <code class="reqn">x^Twx</code> is, for suitable choice of the weight vector
<code class="reqn">w</code>, the total Fisher information available in the data.
Dividing by <code class="reqn">n</code> gives the average Fisher information in a single
observation, multiplying by <code class="reqn">\kappa</code> then results in
<code class="reqn">\kappa</code> units of &quot;average&quot; information.  This matrix is
averaged with its diagonal to ensure positive definiteness.
</p>
<p>In the formula above, <code class="reqn">\kappa</code> is
<code>prior.information.weight</code>, <code class="reqn">\alpha</code> is
<code>diagonal.shrinkage</code>, and <code class="reqn">w</code> is a diagonal matrix with all
elements set to <code>prior.success.probability * (1 -
  prior.success.probability)</code>.  The vector <code class="reqn">b</code> and the matrix
<code class="reqn">V^{-1}</code> are both implicitly subscripted by <code class="reqn">\gamma</code>,
meaning that elements, rows, or columsn corresponding to gamma = 0
should be omitted.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>LogitZellnerPrior</code>, which is a list
with data elements encoding the selected prior values.  It inherits
from <code>LogitPrior</code>, which implies that it contains an element
<code>prior.success.probability</code>.
</p>
<p>This object is intended for use with <code><a href="#topic+logit.spike">logit.spike</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Hugh Chipman, Edward I. George, Robert E. McCulloch, M. Clyde, Dean
P. Foster, Robert A. Stine (2001),
&quot;The Practical Implementation of Bayesian Model Selection&quot;
<em>Lecture Notes-Monograph Series</em>, Vol. 38, pp. 65-134.
Institute of Mathematical Statistics.
</p>

<hr>
<h2 id='mlm.spike'>
Spike and slab multinomial logistic regression
</h2><span id='topic+mlm.spike'></span>

<h3>Description</h3>

<p>MCMC algorithm for multinomial logist models with a 'spike-and-slab'
prior that places some amount of posterior probability at zero for a
subset of the regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlm.spike(subject.formula,
          choice.formula = NULL,
          niter,
          data,
          choice.name.separator = ".",
          contrasts = NULL,
          subset,
          prior = NULL,
          ping = niter / 10,
          proposal.df = 3,
          rwm.scale.factor = 1,
          nthreads = 1,
          mh.chunk.size = 10,
          proposal.weights = c("DA" = .5, "RWM" = .25, "TIM" = .25),
          seed = NULL,
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlm.spike_+3A_subject.formula">subject.formula</code></td>
<td>
<p>A model <code><a href="stats.html#topic+formula">formula</a></code> describing the
relationship between the response (which must be a factor) and the
characteristics of the subjects associated with the decision
process.  If there are no subject-level predictors then <code>y ~ 1</code>
will provide a model with a different intercept for each level of
the response.  If no intercepts are desired, use <code>y ~ 0</code>.  </p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_choice.formula">choice.formula</code></td>
<td>
<p>A model <code><a href="stats.html#topic+formula">formula</a></code> describing the
relationship between the response and the characteristics of the
object being chosen.  This can be left <code>NULL</code> if no
choice-level characteristics are to be used in the model.  The
variables appearing on the right hand side must be stored in
<code>data</code> with the name of response levels appended, and a
chararacter (<code>choice.name.separator</code>) used as a separator.  For
example, if &quot;MPG&quot; is one of the variables in the formula, and the
response can assume values of &quot;Toyota&quot;, &quot;Honda&quot;, and &quot;Chevy&quot;, then
<code>data</code> must contain <code>MPG.Toyota</code>, <code>MPG.Honda</code>, and
<code>MPG.Chevy</code>.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_niter">niter</code></td>
<td>
<p> The number of MCMC iterations to run.  Be sure to
include enough so you can discard a burn-in set.  </p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_data">data</code></td>
<td>
<p>A data frame containing the data referenced in
<code>subject.formula</code> and <code>choice.formula</code> arguments.  If
<code>choice.formula</code> is <code>NULL</code> then this argument is optional,
and variables will be pulled from the parent environment if it is
omitted.  If <code>choice.formula</code> is non-<code>NULL</code>, then
<code>data</code> must be supplied.  Each row in <code>data</code> represents a
single observation containing the relevant data about both the
subject making the choice, as well as about the items being chosen
among.  A variable measuring a choice characteristic must be present
for each choice level in the response variable.  The stems for the
choice-variable names that measure the same concepts must be
identical, and choice level must be appended as a suffix, separated
by a &quot;.&quot;  character.  Thus, if 'HP' is a variable to be considered,
and the response levels are 'Toyota', 'Honda', 'Chevy', then the
data must contain variables named 'HP.Toyota', 'HP.Honda', and
'HP.Chevy'.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_choice.name.separator">choice.name.separator</code></td>
<td>
<p>The character used to separate the
predictor names from the choice values for the choice-level
predictor variables in 'data'.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code> of
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_subset">subset</code></td>
<td>
<p> An optional vector specifying a subset of observations
to be used in the fitting process.  </p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_prior">prior</code></td>
<td>
<p> An object of class
<code><a href="#topic+IndependentSpikeSlabPrior">IndependentSpikeSlabPrior</a></code>.  The portions of the prior
distribution relating to the residual variance are not used.
</p>
<p>A convenience function: <code><a href="#topic+MultinomialLogitSpikeSlabPrior">MultinomialLogitSpikeSlabPrior</a></code>
is provided to help with the accounting headaches of vectorizing the
<code>subject.beta</code> and <code>choice.beta</code> parameters.  </p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_ping">ping</code></td>
<td>
<p>The frequency with which status updates are printed to the
console.  Measured in MCMC iterations.  If <code>ping &lt; 0</code> then no
status updates will be printed.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_proposal.df">proposal.df</code></td>
<td>
<p>The &quot;degrees of freedom&quot; parameter that the
Metropolis-Hastings algorithm should use for the multivariate T
proposal distribution.  If <code>proposal.df &lt;= 0</code> then a Gaussian
proposal is used instead.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_rwm.scale.factor">rwm.scale.factor</code></td>
<td>
<p>The scale factor to use for random walk
Metropolis updates.  See details.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_nthreads">nthreads</code></td>
<td>
<p>The number of CPU-threads to use for data
augmentation.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_mh.chunk.size">mh.chunk.size</code></td>
<td>
<p>The maximum number of coefficients to draw in a
single &quot;chunk&quot; of a Metropolis-Hastings update.  See details. </p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_proposal.weights">proposal.weights</code></td>
<td>
<p>A vector of 3 probabilities (summing to 1)
indicating the probability of each type of MH proposal during each
iteration.  The weights should be given names &quot;DA&quot;, &quot;RWM&quot;, and
&quot;TIM&quot; for clarity.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_seed">seed</code></td>
<td>
<p>Seed to use for the C++ random number generator.  It
should be <code>NULL</code> or an int.  If <code>NULL</code> the seed value will
be taken from the global <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> object.</p>
</td></tr>
<tr><td><code id="mlm.spike_+3A_...">...</code></td>
<td>

<p>Extra arguments to be passed to <code><a href="#topic+MultinomialLogitSpikeSlabPrior">MultinomialLogitSpikeSlabPrior</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Model Details:</h4>

<p>A multinomial logit model has two sets of predictors: one measuring
characterisitcs of the subject making the choice, and the other
measuring characteristics of the items being chosen.  The model
can be written
</p>
<p style="text-align: center;"><code class="reqn"> Pr(y[i] = m) \propto exp(beta.subject[, m] * x.subject[i, ]
     + beta.choice * x.choice[i, , m])</code>
</p>

<p>The coefficients in this model are beta.subject and beta.choice.
beta.choice is a subject.xdim by ('nchoices' - 1) matrix.  Each row
multiplies the design matrix produced by subject.formula for a
particular choice level, where the first choice level is omitted
(logically set to zero) for identifiability.  beta.choice is a
vector multiplying the design matrix produced by choice.formula,
and thre are 'nchoices' of such matrices.
</p>
<p>The coefficient vector 'beta' is the concatenation
c(beta.subject, beta.choice), where beta.subject is vectorized
by stacking its columns (in the usual R fashion).  This means
that the first contiguous region of beta contains the
subject-level coefficients for choice level 2.
</p>



<h4>MCMC Details:</h4>

<p>The MCMC algorithm randomly moves between three tyes of
updates: data augmentation, random walk Metropolis (RWM), and
tailored independence Metropolis (TIM).
</p>

<ul>
<li><p>  DA: Each observation in the model is
associated with a set of latent variables that renders the
complete data posterior distribution conditionally Gaussian.
The augmentation scheme is described in Tuchler (2008).  The
data augmentation algorithm conditions on the latent data,
and integrates out the coefficients, to sample the inclusion
vector (i.e. the vector of indicators showing which
coefficients are nonzero) using Gibbs sampling.  Then the
coefficients are sampled given complete data conditional on
inclusion.  This is the only move that attemps a dimension
change.
</p>
</li>
<li><p> RWM: A chunk of the coefficient vector (up to mh.chunk.size)
is selected.  The proposal distribution is either
multivariate normal or multivariate T (depending on
'proposal.df') centered on current values of this chunk.
The precision parameter of the normal (or T) is the negative
Hessian of the un-normalized log posterior, evaluated at the
current value.  The precision is divided by
rwm.scale.factor.  Only coefficients currently included in
the model at the time of the proposal will be modified.
</p>
</li>
<li><p> TIM: A chunk of the coefficient vector (up to mh.chunk.size)
is selected.  The proposal distribution is constructed by
locating the posterior mode (using the current value as a
starting point).  The proposal is a Gaussian (or
multivariate T) centered on the posterior mode, with
precision equal to the negative Hessian evaluated at the
mode.  This is an expensive, but effective step.  If the
posterior mode finding fails (for numerical reasons) then a
RWM proposal will be attempted instead.
</p>
</li></ul>




<h3>Value</h3>

<p>Returns an object of class <code>mlm.spike</code>, which inherits from
<code>logit.spike</code> and <code>lm.spike</code>.  The returned object is a list
with the following elements
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code>niter</code> by <code>ncol(x)</code> matrix of regression
coefficients, many of which may be zero.  Each row corresponds to an
MCMC iteration.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to fit the model.  If a <code>prior</code> was
supplied as an argument it will be returned.  Otherwise this will be
the automatically generated prior based on the other function
arguments. </p>
</td></tr>
<tr><td><code>MH.accounting</code></td>
<td>
<p>A summary of the amount of time spent in each
type of MCMC move, and the acceptance rate for each move type. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Tuchler (2008), &quot;Bayesian Variable Selection for Logistic Models Using
Auxiliary Mixture Sampling&quot;, <em>Journal of Computational and
Graphical Statistics</em>, <b>17</b> 76 &ndash; 94.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>,
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>,
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rmulti &lt;- function (prob) {
  ## Sample from heterogeneous multinomial distributions.
    if (is.vector(prob)) {
        S &lt;- length(prob)
        return(sample(1:S, size = 1, prob = prob))
    }
    nc &lt;- apply(prob, 1, sum)
    n &lt;- nrow(prob)
    S &lt;- ncol(prob)
    u &lt;- runif(n, 0, nc)
    alive &lt;- rep(TRUE, n)
    z &lt;- numeric(n)
    p &lt;- rep(0, n)
    for (s in 1:S) {
        p &lt;- p + prob[, s]
        indx &lt;- alive &amp; (u &lt; p)
        alive[indx] &lt;- FALSE
        z[indx] &lt;- s
        if (!any(alive))
            break
    }
    return(z)
}

## Define sizes for the problem
subject.predictor.dimension &lt;- 3
choice.predictor.dimension &lt;- 4
nchoices &lt;- 5
nobs &lt;- 1000

## The response can be "a", "b", "c", ...
choice.levels &lt;- letters[1:nchoices]

## Create "subject level characteristics".
subject.x &lt;- matrix(rnorm(nobs * (subject.predictor.dimension - 1)),
                    nrow = nobs)
subject.beta &lt;- cbind(
    0, matrix(rnorm(subject.predictor.dimension * (nchoices - 1)),
              ncol = nchoices - 1))
colnames(subject.x) &lt;- state.name[1:ncol(subject.x)]

## Create "choice level characteristics".
choice.x &lt;- matrix(rnorm(nchoices * choice.predictor.dimension * nobs),
                   nrow = nobs)
choice.characteristics &lt;- c("foo", "bar", "baz", "qux")
choice.names &lt;- as.character(outer(choice.characteristics, choice.levels, FUN = paste, sep = ":"))
colnames(choice.x) &lt;- choice.names
choice.beta &lt;- rnorm(choice.predictor.dimension)

## Combine an intercept term, subject data, and choice data.
X &lt;- cbind(1, subject.x, choice.x)
p &lt;- ncol(X)
true.beta &lt;- c(subject.beta[, -1], choice.beta)
Beta &lt;- matrix(nrow = nchoices, ncol = p)
for (m in 1:nchoices) {
  Beta[m, ] &lt;- rep(0, p)
  Beta[m, 1:subject.predictor.dimension] &lt;- subject.beta[, m]
  begin &lt;- subject.predictor.dimension + 1 + (m-1) * choice.predictor.dimension
  end &lt;- begin + choice.predictor.dimension - 1
  Beta[m, begin:end] &lt;- choice.beta
}

eta &lt;- X %*% t(Beta)
prob &lt;- exp(eta)
prob &lt;- prob / rowSums(prob)
response &lt;- as.factor(choice.levels[rmulti(prob)])
simulated.data &lt;- as.data.frame(X[, -1])
simulated.data$response &lt;- response

# NOTE: The number of MCMC iterations is artificially small to reduce
# the run time.
model &lt;- mlm.spike(response ~ Alabama + Alaska,
                   response ~ foo + bar + baz + qux,
                   niter = 100,
                   choice.name.separator = ":",
                   expected.subject.model.size = -1,
                   expected.choice.model.size = -1,
                   data = simulated.data,
                   proposal.weights = c("DA" = .8, "RWM" = .1, "TIM" = .1))
</code></pre>

<hr>
<h2 id='mlm.spike.slab.prior'>
Create a spike and slab prior for use with mlm.spike.
</h2><span id='topic+MultinomialLogitSpikeSlabPrior'></span>

<h3>Description</h3>

<p>Creates a spike and slab prior for use with mlm.spike.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultinomialLogitSpikeSlabPrior(
    response,
    subject.x,
    expected.subject.model.size = 1,
    choice.x = NULL,
    expected.choice.model.size = 1,
    max.flips = -1,
    nchoices = length(levels(response)),
    subject.dim = ifelse(is.null(subject.x), 0, ncol(subject.x)),
    choice.dim = ifelse(is.null(choice.x), 0, ncol(choice.x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlm.spike.slab.prior_+3A_response">response</code></td>
<td>
<p>The response variable in the multinomial logistic
regression.  The response variable is optional if nchoices
is supplied.  If 'response' is provided then the prior
means for the subject level intercpets will be chosen to
match the empirical values of the response.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_subject.x">subject.x</code></td>
<td>
<p>The design matrix for subject-level predictors.
This can be NULL or of length 0 if no subject-level
predictors are present.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_expected.subject.model.size">expected.subject.model.size</code></td>
<td>
<p>The expected number of non-zero
coefficients &ndash; per choice level &ndash; in the subject specific
portion of the model.  All coefficients can be forced into
the model by setting this to a negative number, or by setting
it to be larger than the dimension of the subject-level
predictors.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_choice.x">choice.x</code></td>
<td>
<p>The design matrix for choice-level predictors.  Each
row of this matrix represents the characteristics of a choice
in a choice occasion, so it takes 'nchoices' rows to encode
one observation.  This can be NULL or of length 0 if no
choice-level predictors are present.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_expected.choice.model.size">expected.choice.model.size</code></td>
<td>
<p>The expected number of non-zero
coefficients in the choice-specific portion of the model.
All choice coefficients can be forced into the model by
setting this to a negative number, or by setting it to be
larger than the dimension of the choice-level predictors (for
a single response level).</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_max.flips">max.flips</code></td>
<td>
<p>The maximum number of variable inclusion indicators
the sampler will attempt to sample each iteration.  If
<code>max.flips &lt;= 0</code> then all indicators will be sampled.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_nchoices">nchoices</code></td>
<td>
<p>Tne number of potential response levels.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_subject.dim">subject.dim</code></td>
<td>
<p>The number of potential predictors in the
subject-specific portion of the model.</p>
</td></tr>
<tr><td><code id="mlm.spike.slab.prior_+3A_choice.dim">choice.dim</code></td>
<td>
<p>The number of potential predictors in the
choice-specific portion of the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> An object of class <code><a href="#topic+IndependentSpikeSlabPrior">IndependentSpikeSlabPrior</a></code>, with
elements arranged as expected by <code><a href="#topic+mlm.spike">mlm.spike</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Tuchler (2008), &quot;Bayesian Variable Selection for Logistic Models Using
Auxiliary Mixture Sampling&quot;, <em>Journal of Computational and
Graphical Statistics</em>, <b>17</b> 76 &ndash; 94.
</p>

<hr>
<h2 id='model.matrix'>
GetPredictorMatrix
</h2><span id='topic+GetPredictorMatrix'></span>

<h3>Description</h3>

<p>Extract the matrix of predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  GetPredictorMatrix(object, newdata, na.action = na.omit, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.matrix_+3A_object">object</code></td>
<td>

<p>An object of class glm.spike.  The object must be a
list with the following elements
</p>

<ul>
<li><p> beta: a matrix of MCMC draws, with rows representing draws,
and columns representing coefficients.
</p>
</li>
<li><p> xlevels: the levels of any contrasts present in the original
training data.
</p>
</li>
<li><p> contrasts: the &quot;contrasts&quot; attribute of the original design
matrix used to train the model.
</p>
</li>
<li><p> terms: the terms of the formula used to fit the original model.
</p>
</li></ul>

</td></tr>
<tr><td><code id="model.matrix_+3A_newdata">newdata</code></td>
<td>
<p>A data frame, matrix, or vector containing the
predictors needed to make a prediction.  If newdata is a
matrix it must have the same number of columns as
length(object$beta), unless it is off by one and the model
contains an intercept, in which case an intercept term will
be added.  If length(object$beta) == 1 (or 2, with one
element containing an intercept) then newdata can be a
numeric vector.
</p>
</td></tr>
<tr><td><code id="model.matrix_+3A_na.action">na.action</code></td>
<td>
<p>A function specifying what to do with <code>NA</code>'s.</p>
</td></tr>
<tr><td><code id="model.matrix_+3A_...">...</code></td>
<td>

<p>Extra arguments passed to <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>, in the event
that <code>newdata</code> is a data frame.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p> A matrix of predictor variables suitable for multiplication by
<code>object$beta</code>.  </p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>
</p>

<hr>
<h2 id='model.matrix.glm.spike'>
Construct Design Matrices
</h2><span id='topic+model.matrix.glm.spike'></span>

<h3>Description</h3>

<p>Creates a matrix of predictors appropriate for glm.spike models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'glm.spike'
model.matrix(object, data = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.matrix.glm.spike_+3A_object">object</code></td>
<td>

<p>An object of class <code>glm.spike</code>.
</p>
</td></tr>
<tr><td><code id="model.matrix.glm.spike_+3A_data">data</code></td>
<td>
<p> Either a data frame to use when building the model
matrix, or <code>NULL</code>.  If <code>NULL</code> then the training data from
<code>object</code> will be used.
</p>
</td></tr>
<tr><td><code id="model.matrix.glm.spike_+3A_...">...</code></td>
<td>

<p>Extra arguments passed to <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>glm.spike</code> objects do not store the predictors used to fit the
model.  If the training data is modified between when <code>object</code>
is fit and when this function is called, the modifications will
be reflected in the returned value.
</p>


<h3>Value</h3>

<p>The matrix of predictors used at training time, so long as the
original data used to fit the model is available in the frame
where this function is called.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
</p>

<hr>
<h2 id='nested.regression'>
Nested Regression
</h2><span id='topic+NestedRegression'></span>

<h3>Description</h3>

<p>Fits a Bayesian hierarchical regression model to data nested within groups.
The model is
</p>
<p style="text-align: center;"><code class="reqn">%
          y_{ig}  \sim N(x_i  \beta_g, \sigma^2) \\ %
     1 / \sigma^2 \sim Gamma(df/2, ss/2)        \\ %
          \beta_g \sim N(b, V)                  \\ %
        </code>
</p>

<p>Optional hyperprior distributions can be supplied to the prior parameters.
</p>
<p style="text-align: center;"><code class="reqn">%
                        b ~ N(prior.mean, prior.variance)       \\ %
                        V ~ InverseWishart(df, variance.guess). \\ %
                </code>
</p>

<p>Either hyperprior can be omitted, in which case the corresponding
prior parameter is assumed fixed at the user-supplied value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NestedRegression(response,
                 predictors,
                 group.id,
                 residual.precision.prior = NULL,
                 coefficient.prior = NULL,
                 coefficient.mean.hyperprior = NULL,
                 coefficient.variance.hyperprior = NULL,
                 suf = NULL,
                 niter,
                 ping = niter / 10,
                 sampling.method = c("ASIS", "DA"),
                 seed = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nested.regression_+3A_response">response</code></td>
<td>
<p>A numeric vector.  The response variable to be modeled.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_predictors">predictors</code></td>
<td>
<p>A numeric matrix of predictor variables, including
an intercept term if one is desired.  The number of rows must match
length(response).</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_group.id">group.id</code></td>
<td>
<p>A factor (or object that can be converted using
<code><a href="base.html#topic+as.factor">as.factor</a></code>) naming the group to which each entry in
<code>response</code> belongs.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_residual.precision.prior">residual.precision.prior</code></td>
<td>
<p>An object of type
<code><a href="Boom.html#topic+SdPrior">SdPrior</a></code> describing the prior
distribution of the residual standard deviation.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_coefficient.prior">coefficient.prior</code></td>
<td>
<p>An object of class MvnPrior, or <code>NULL</code>.
If non-<code>NULL</code> this gives the initial values of the prior
distribution of the regression coefficients in the nested regression
model.  This argument must be non-<code>NULL</code> if either
<code>coefficient.mean.hyperprior</code> or
<code>coefficient.variance.hyperprior</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_coefficient.mean.hyperprior">coefficient.mean.hyperprior</code></td>
<td>
<p>An object of class
<code><a href="Boom.html#topic+MvnPrior">MvnPrior</a></code>, specifying the hyperprior
distribution for the mean of <code>coefficient.prior</code>.  This
argument can also be <code>NULL</code>, or <code>FALSE</code>.  If <code>NULL</code>
then a default prior will be used when learning the mean of the
prior distribution.  If <code>FALSE</code> then the mean of the prior
distribution will not be learned; the mean of the
<code>coefficient.prior</code> distribution will be assumed instead.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_coefficient.variance.hyperprior">coefficient.variance.hyperprior</code></td>
<td>
<p>An object of class
<code><a href="Boom.html#topic+InverseWishartPrior">InverseWishartPrior</a></code>, specifying the
hyperprior distribution for the variance of
<code>coefficient.prior</code>.  This argument can also be <code>NULL</code>, or
<code>FALSE</code>.  If <code>NULL</code> then a default prior will be used when
learning the variance of the prior distribution.  If <code>FALSE</code>
then the variance of the prior distribution will not be learned; the
variance of the <code>coefficient.prior</code> distribution will be
assumed instead.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_suf">suf</code></td>
<td>
<p>A list, where each entry is of type
<code><a href="Boom.html#topic+RegressionSuf">RegressionSuf</a></code>, giving the sufficient
statistics for each group, or <code>NULL</code>.  If <code>NULL</code>, then
<code>suf</code> will be computed from <code>response</code>, <code>predictors</code>,
and <code>group.id</code>.  If non-<code>NULL</code> then these arguments will
not be accessed, in which case they can be left unspecified.  In
'big data' problems this can be a significant computational
savings.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_niter">niter</code></td>
<td>
<p>The desired number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_ping">ping</code></td>
<td>
<p>The frequency with which to print status updates.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_sampling.method">sampling.method</code></td>
<td>
<p>The MCMC sampling scheme that should be used.
If either hyperprior is set to <code>FALSE</code> then the &quot;DA&quot; method
will be used.</p>
</td></tr>
<tr><td><code id="nested.regression_+3A_seed">seed</code></td>
<td>
<p>The integer-valued seed (or <code>NULL</code>) to use for the
C++ random number generator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note: ASIS (Yu and Meng, 2011) has slightly better MCMC convergence,
but is slightly slower than the classic DA (data augmentation) method,
which alternates between sampling group-level regression coefficients
and prior parameters.  Both methods are pretty fast.
</p>


<h3>Value</h3>

<p>A list containing MCMC draws from the posterior distribution of model
parameters.  Each of the following is a vector, matrix, or array, with
first index corresponding to MCMC draws, and later indices to distinct
parameters.
</p>

<ul>
<li><p> coefficients: regression coefficients.
</p>
</li>
<li><p>residual.sd: the residual standard deviation from the
regression model.
</p>
</li>
<li><p>prior.mean: The posterior distribution of the coefficient
means across groups.
</p>
</li>
<li><p>prior.variance: The posterior distribution of the variance
matrix describing the distribution of regression coefficients
across groups.  
</p>
</li>
<li><p>priors: A list of the prior distributions used to fit the
model.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SimulateNestedRegressionData &lt;- function() {
  beta.hyperprior.mean &lt;- c(8, 6, 7, 5)
  xdim &lt;- length(beta.hyperprior.mean)
  beta.hyperprior.variance &lt;-
    rWishart(2 * xdim, diag(rep(1, xdim)), inverse = TRUE)

  number.of.groups &lt;- 27
  nobs.per.group = 23
  beta &lt;- rmvn(number.of.groups,
               beta.hyperprior.mean,
               beta.hyperprior.variance)

  residual.sd &lt;- 2.4
  X &lt;- cbind(1, matrix(rnorm(number.of.groups * (xdim - 1) * nobs.per.group),
                       ncol = xdim - 1))
  group.id &lt;- rep(1:number.of.groups, len = nrow(X))
  y.hat &lt;- numeric(nrow(X))
  for (i in 1:nrow(X)) {
    y.hat[i] = sum(X[i, ] * beta[group.id[i], ])
  }
  y &lt;- rnorm(length(y.hat), y.hat, residual.sd)
  suf &lt;- BoomSpikeSlab:::.RegressionSufList(X, y, group.id)

  return(list(beta.hyperprior.mean = beta.hyperprior.mean,
              beta.hyperprior.variance = beta.hyperprior.variance,
              beta = beta,
              residual.sd = residual.sd,
              X = X,
              y = y,
              group.id = group.id,
              suf = suf))
}

d &lt;- SimulateNestedRegressionData()
model &lt;- NestedRegression(suf = d$suf, niter = 500)

</code></pre>

<hr>
<h2 id='nnet'>
Bayesian Feed Forward Neural Networks
</h2><span id='topic+BayesNnet'></span><span id='topic+HiddenLayer'></span>

<h3>Description</h3>

<p>Fit a feed forward neural network using MCMC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BayesNnet(formula,
          hidden.layers,
          niter,
          data,
          subset,
          prior = NULL,
          expected.model.size = Inf,
          drop.unused.levels = TRUE,
          contrasts = NULL,
          ping = niter / 10,
          seed = NULL) 

HiddenLayer(number.of.nodes, prior = NULL, expected.model.size = Inf)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnet_+3A_formula">formula</code></td>
<td>
<p> A formula describing the model to be fit.  The formula
should be additive.  The network will figure out any interactions or
nonlinearities.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_hidden.layers">hidden.layers</code></td>
<td>

<p>A list of objects created by <code><a href="#topic+HiddenLayer">HiddenLayer</a></code> defining the
network structure.  The input layer is determined by the
<code>formula</code> argument.  The terminal layer is a linear regression
on the outputs of the final hidden layer.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_niter">niter</code></td>
<td>

<p>The number of MCMC iterations to run.  Be sure to include enough so
you can throw away a burn-in set.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_data">data</code></td>
<td>

<p>An optional data frame, list or environment (or object coercible by
'as.data.frame' to a data frame) containing the variables in the
model.  If not found in 'data', the variables are taken from
'environment(formula)', typically the environment from which
<code>BayesNnet</code> is called.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_subset">subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be used in
the fitting process.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_prior">prior</code></td>
<td>
<p>When passed to <code>BayesNnet</code> this is the prior
distribution for the terminal layer, which must be an object of
class <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+SpikeSlabPriorDirect">SpikeSlabPriorDirect</a></code>, or <code>NULL</code>.  If <code>NULL</code>
then a default prior will be used.
</p>
<p>When passed to <code>HiddenLayer</code> this is the prior distribution for
the coefficients to that layer.  The prior is specified for a single
output node, and the same prior is used for all nodes.  You can
think of each hidden layer output node as a logistic regression
model where the predictors are the outputs of the previous layer.
This must be an object of class <code><a href="Boom.html#topic+MvnPrior">MvnPrior</a></code>,
<code><a href="#topic+SpikeSlabGlmPrior">SpikeSlabGlmPrior</a></code>, or
<code><a href="#topic+SpikeSlabGlmPriorDirect">SpikeSlabGlmPriorDirect</a></code>.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>When <code>prior</code> is not specified a default spike-and-slab prior
will be used.  The <code>expected.model.size</code> argument to
<code><a href="#topic+BayesNnet">BayesNnet</a></code> is passed to
<code><a href="#topic+SpikeSlabPriorDirect">SpikeSlabPriorDirect</a></code>.  In <code>HiddenLayer</code> the
argument is passed to <code><a href="#topic+SpikeSlabGlmPriorDirect">SpikeSlabGlmPriorDirect</a></code>.
</p>
<p>The parameter is used to set the prior inclusion probabilities for
the coefficients.  If <code>p</code> coefficients are available then the
prior inclusion probabilities are each set to
<code>expected.model.size / p</code>.  If this ratio exceeds 1 then model
selection is turned off and all coefficients are included.
</p>
</td></tr>
<tr><td><code id="nnet_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p>Logical indicating whether unobserved factor
levels should be dropped when forming the model matrix. </p>
</td></tr> 
<tr><td><code id="nnet_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code>
argument of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="nnet_+3A_ping">ping</code></td>
<td>
<p>The frequency with which to print status update messages
to the screen.  For example, if <code>ping == 10</code> then an update
will be printed every 10 MCMC iterations.</p>
</td></tr>
<tr><td><code id="nnet_+3A_seed">seed</code></td>
<td>
<p>An integer to use as the random seed for the underlying
C++ code.  If <code>NULL</code> then the seed will be set using the
clock.</p>
</td></tr>
<tr><td><code id="nnet_+3A_number.of.nodes">number.of.nodes</code></td>
<td>
<p>The number of nodes in this hidden layer.  This
must be a positive scalar integer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is a feedforward neural network regression.  The model is
fit using an MCMC algorithm based on data augmentation.  Each hidden
node is randomly assigned a 0/1 value from its full conditional
distribution.  Then conditional on the imputed data an MCMC draw is
done on each latent logistic regression and on the regression model
defining the terminal node.
</p>


<h3>Value</h3>

<p>The returned object is a list with class <code>BayesNnet</code>.  It
contains the following objects
</p>

<ul>
<li> <p><code>residual.sd</code> The standard deviation of the residuals
from the model.
</p>
</li>
<li> <p><code>hidden.layer.coefficients</code> A list, with one element per
hidden layer, giving the posterior draws of the hidden layer
coefficients for that layer.  Each list element is a 3-way array
with dimensions corresponding to
</p>

<ol>
<li><p> MCMC iteration
</p>
</li>
<li><p> Input node.  For the first hidden layer each 'input node' is
a predictor variable.
</p>
</li>
<li><p> Output node.  
</p>
</li></ol>

<p>You can think of hidden.layer.coefficients[[i]][, , j] as the
posterior distribution of the logistic regression model defining
node 'j' in hidden layer 'i'.
</p>
</li>
<li> <p><code>terminal.layer.coefficients</code> A matrix containing the
MCMC draws of the model coefficients for the terminal layer.
</p>
</li>
<li><p> Other list elements needed to implement various methods
(predict, plot, etc.).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>??
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.BayesNnet">plot.BayesNnet</a></code>,
<code><a href="#topic+predict.BayesNnet">predict.BayesNnet</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require(mlbench)) {
  data(BostonHousing)
  hidden.layers &lt;- list(
    HiddenLayer(10, expected.model.size = Inf))

  ## In real life you'd want more 50 MCMC draws.
  model &lt;- BayesNnet(medv ~ .,
    hidden.layers = hidden.layers,
    niter = 50,
    data = BostonHousing)

  par(mfrow = c(1, 2))
  plot(model)  # plots predicted vs actual.
  plot(model, "residual") # plots 
  par(mfrow = c(1,1))
  plot(model, "structure")
  ## Examine all partial dependence plots.
  plot(model, "partial", pch = ".")

  ## Examine a single partial dependence plot.
  par(mfrow = c(1,1))
  plot(model, "lstat", pch = ".")

  ## Check out the mixing performance.
  PlotManyTs(model$terminal.layer.coefficients)
  PlotMacf(model$terminal.layer.coefficients)

  ## Get the posterior distribution of the function values for the
  ## training data.
  pred &lt;- predict(model)

  ## Get predictions for data at new points (though in this example I'm
  ## reusing old points.
  pred2 &lt;- predict(model, newdata = BostonHousing[1:12, ])

} else {
  cat("The Boston housing data from 'mlbench' is needed for this example.")
}

</code></pre>

<hr>
<h2 id='partial.dependence.plot'>
Plot a Bayesian Neural Network
</h2><span id='topic+PartialDependencePlot'></span>

<h3>Description</h3>

<p>Plot the relationship between Y and a single X variable, averaging
over the values of the other X's.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  PartialDependencePlot(model,
                        which.variable,
                        burn = SuggestBurn(model),
                        data.fraction = .2,
                        gridsize = 50,
                        mean.only = FALSE,
                        show.points = TRUE,
                        xlab = NULL,
                        ylab = NULL,
                        ylim = NULL,
                        report.time = FALSE,
                        ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partial.dependence.plot_+3A_model">model</code></td>
<td>
<p> An object of class <code>BayesNnet</code>. </p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_which.variable">which.variable</code></td>
<td>
<p> Either an integer denoting the position of the
X variable in the data frame used to fit the model, or a character
string naming that variable.  </p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_data.fraction">data.fraction</code></td>
<td>
<p>The fraction of observations in the predictor
matrix to use when constructing the partial dependence plot.  A
random sub-sample of this fraction will be taken (without
replacement) for the purposes of marginalizing over the remaining
predictors.  </p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_gridsize">gridsize</code></td>
<td>
<p>The number of grid points to use on the X axis.</p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_mean.only">mean.only</code></td>
<td>
<p> Logical.  If <code>TRUE</code> then only the mean is
plotted at each point.  If <code>FALSE</code> then the posterior of the
function value is plotted.
</p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_show.points">show.points</code></td>
<td>
<p>If <code>TRUE</code> then the scatterplot of x vs y is
added to the graph.  Otherwise the points are left off.  Note that
the estimated function might not match the pattern in the
scatterplot, because the points in the scatterplot are not adjusted
for the values of the other X variables.  </p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_xlab">xlab</code></td>
<td>
<p>Label for the X axis.  NULL produces a default label.
Use &quot;&quot; for no label.</p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_ylab">ylab</code></td>
<td>
<p> Label for the Y axis.  NULL produces a default label.
Use &quot;&quot; for no label.  </p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_ylim">ylim</code></td>
<td>
<p>Limits on the vertical axis.  If NULL then the plot will
default to its natural vertical limits.</p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_report.time">report.time</code></td>
<td>
<p>Print the time required to produce the plot.</p>
</td></tr>
<tr><td><code id="partial.dependence.plot_+3A_...">...</code></td>
<td>
<p>Extra arguments are passed either to 'plot' (if mean.only
is <code>TRUE</code>)' or 'PlotDynamicDistribution' (otherwise).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A partial dependence plot shows the relationship between Y and a
single X variable, averaging over the values of the other X's in a
possibly nonlinear regression model.  Partial dependence plots are a
generalization of the &quot;added variable plot&quot; idea from linear
regression models.
</p>
<p>A partial dependence plot is more expensive to produce than most other
plots, because a set of predictions must be generated at each point on
the X axis.  This is done by taking a random subset of the training
data, and evaluating the posterior predictive distribution with each
observation's target X value set to each value of X on the grid.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.BayesNnet">plot.BayesNnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Please see the code in ?BayesNnet
</code></pre>

<hr>
<h2 id='plot.BayesNnet'>
Plot a Bayesian Neural Network
</h2><span id='topic+plot.BayesNnet'></span><span id='topic+PlotNetworkStructure'></span><span id='topic+PlotBayesNnetPredictions'></span><span id='topic+PlotBayesNnetResiduals'></span>

<h3>Description</h3>

<p>The default plot is a barplot of the marginal inclusion probabilities
for each variable, as obtained by
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.  Other interesting
plots can be obtained by supplying a string as the second argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'BayesNnet'
plot(x,
     y = c("predicted", "residual", "structure", "partial", "help"),
     ...)

  PlotBayesNnetPredictions(model, burn = SuggestBurn(model), ...)

  PlotBayesNnetResiduals(model, burn = SuggestBurn(model), ...)

  PlotNetworkStructure(model, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.BayesNnet_+3A_model">model</code></td>
<td>
<p> An object of class <code>BayesNnet</code>. </p>
</td></tr>
<tr><td><code id="plot.BayesNnet_+3A_x">x</code></td>
<td>

<p>An object of class <code>BayesNnet</code>.  The name <code>x</code> is required
to conform with the <code>plot</code> generic function signature.
</p>
</td></tr>
<tr><td><code id="plot.BayesNnet_+3A_y">y</code></td>
<td>

<p>The type of plot desired, or the name of the variable to plot
against.  The name <code>y</code> is required to conform with the
<code>plot</code> generic function signature.
</p>
<p>If <code>y</code> matches (or partially matches) one of the names in the
function signature, then the corresponding plot function handles the
plot request.
</p>

<ul>
<li><p>&quot;predicted&quot; (the default) plot actual vs predicted values
using <code>PlotBayesNnetPredictions</code>.
</p>
</li>
<li><p>&quot;residual&quot; plot residuals vs predicted values using
<code>PlotBayesNnetResiduals</code>.
</p>
</li>
<li><p>&quot;structure&quot; plot network structure using
<code>PlotNetworkStructure</code>.
</p>
</li>
<li><p>&quot;partial&quot; Draw the partial dependence plot for each
predictor variable in the training data.  This is an expensive
plot.  It might take a while to draw for large data sets or
complex models.
</p>
</li>
<li><p>&quot;help&quot; show this help page in a browser
</p>
</li></ul>

<p>If <code>y</code> fails to match any of the above, but it (partially) the
name of one of the variables in the training data, then a partial
dependence plot vs that variable is produced.
</p>
</td></tr>
<tr><td><code id="plot.BayesNnet_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="plot.BayesNnet_+3A_...">...</code></td>
<td>
<p> Additional arguments passed to the specific functions
that do the plotting.  For residual and predicted plots that is the
<code><a href="graphics.html#topic+plot">plot</a></code> function.  For network structure it is
<code><a href="igraph.html#topic+plot.igraph">plot.igraph</a></code>.  For partial dependence plots it
is <code><a href="#topic+PartialDependencePlot">PartialDependencePlot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Residual and predicted plots should be self explanatory.  The
network structure plot is fairly standard for neural network models.
The width of a line linking two nodes is determined by the absolute
value of the corresponding coefficient.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BayesNnet">BayesNnet</a></code>
<code><a href="#topic+PartialDependencePlot">PartialDependencePlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## See the examples in ?BayesNnet
</code></pre>

<hr>
<h2 id='plot.coefficients'>
Plot Coefficients.
</h2><span id='topic+PlotLmSpikeCoefficients'></span>

<h3>Description</h3>

<p>Produces boxplots showing the marginal distribution of the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotLmSpikeCoefficients(
     beta,
     burn = 0,
     inclusion.threshold = 0,
     scale.factors = NULL,
     number.of.variables = NULL,
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.coefficients_+3A_beta">beta</code></td>
<td>
<p> A matrix of model coefficients.  Each row represents an
MCMC draw.  Each column represents a coefficient for a variable.
</p>
</td></tr>
<tr><td><code id="plot.coefficients_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the ojbect to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="plot.coefficients_+3A_inclusion.threshold">inclusion.threshold</code></td>
<td>
<p> Only plot coefficients with posterior
inclusion probabilities exceeding this value.  </p>
</td></tr>
<tr><td><code id="plot.coefficients_+3A_scale.factors">scale.factors</code></td>
<td>
<p>If non-null then a vector of scale factors with which to
scale the columns of beta.  A <code>NULL</code> value is ignored.</p>
</td></tr>
<tr><td><code id="plot.coefficients_+3A_number.of.variables">number.of.variables</code></td>
<td>
<p>If non-<code>NULL</code> this specifies the
maximum number of coefficients to plot.  A <code>NULL</code> value is
ignored.</p>
</td></tr>
<tr><td><code id="plot.coefficients_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to <code><a href="graphics.html#topic+boxplot">boxplot</a>.</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the value from the final call to <code>boxplot</code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.lm.spike &lt;- function(n = 100, p = 10, ngood = 3, niter=1000, sigma = 1){
  x &lt;- cbind(matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, beta[1] + x %*% beta[-1], sigma)
  draws &lt;- lm.spike(y ~ x, niter=niter)
  return(invisible(draws))
}
model &lt;- simulate.lm.spike(n = 1000, p = 50, sigma = .3)
plot(model, "coef", inclusion.threshold = .01)
</code></pre>

<hr>
<h2 id='plot.lm.spike'>
Plot the results of a spike and slab regression.
</h2><span id='topic+plot.lm.spike'></span>

<h3>Description</h3>

<p>The default plot is a barplot of the marginal inclusion probabilities
for each variable, as obtained by
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.  Other interesting
plots can be obtained by supplying a string as the second argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'lm.spike'
plot(x,
     y = c("inclusion", "coefficients", "scaled.coefficients",
              "residuals", "fit", "size", "help"),
     burn = SuggestBurnLogLikelihood(x$log.likelihood),
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lm.spike_+3A_x">x</code></td>
<td>

<p>An object of class <code>lm.spike</code>.
</p>
</td></tr>
<tr><td><code id="plot.lm.spike_+3A_y">y</code></td>
<td>

<p>The type of plot desired.
</p>
</td></tr>
<tr><td><code id="plot.lm.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="plot.lm.spike_+3A_...">...</code></td>
<td>
<p> Additional arguments passed to the specific functions
that do the plotting.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The actual plotting will be handled by
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>,
<code><a href="#topic+PlotLmSpikeCoefficients">PlotLmSpikeCoefficients</a></code>,
<code><a href="#topic+PlotLmSpikeResiduals">PlotLmSpikeResiduals</a></code>, or <code><a href="#topic+PlotModelSize">PlotModelSize</a></code>.
See the appropriate function for more options.</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>
<code><a href="#topic+PlotLmSpikeCoefficients">PlotLmSpikeCoefficients</a></code>
<code><a href="#topic+PlotLmSpikeResiduals">PlotLmSpikeResiduals</a></code>
<code><a href="#topic+PlotModelSize">PlotModelSize</a></code>
<code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.lm.spike &lt;- function(n = 100, p = 10, ngood = 3, niter=1000, sigma = 8){
  x &lt;- cbind(matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, beta[1] + x %*% beta[-1], sigma)
  draws &lt;- lm.spike(y ~ x, niter=niter)
  return(invisible(draws))
}
model &lt;- simulate.lm.spike(n = 1000, p = 50, sigma = .3)
plot(model, inclusion.threshold = .01)

plot(model, "size")
</code></pre>

<hr>
<h2 id='plot.lm.spike.fit'>
Predicted vs actual plot for lm.spike.
</h2><span id='topic+PlotLmSpikeFit'></span>

<h3>Description</h3>

<p>Plot actual values vs. predictions in an lm.spike model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotLmSpikeFit(
    object,
    burn = SuggestBurnLogLikelihood(object$log.likelihood),
    ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lm.spike.fit_+3A_object">object</code></td>
<td>
<p>A model object inheriting from <code><a href="#topic+lm.spike">lm.spike</a></code>.</p>
</td></tr>
<tr><td><code id="plot.lm.spike.fit_+3A_burn">burn</code></td>
<td>
<p> The number of MCMC iterations to be discarded as burn-in
before computing posterior means. </p>
</td></tr>
<tr><td><code id="plot.lm.spike.fit_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to <code><a href="graphics.html#topic+plot">plot</a>.</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This plot is normally called via the plot function for <code>lm.spike</code>
objects.  See the help entry for <code><a href="#topic+lm.spike">lm.spike</a></code> for example
usage.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
</p>

<hr>
<h2 id='plot.lm.spike.residuals'>
Residual plot for lm.spike
</h2><span id='topic+PlotLmSpikeResiduals'></span>

<h3>Description</h3>

<p>Plot residuals vs. fitted values in an lm.spike model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotLmSpikeResiduals(
    object,
    burn = SuggestBurnLogLikelihood(object$log.likelihood),
    ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lm.spike.residuals_+3A_object">object</code></td>
<td>
<p>A model object inheriting from <code><a href="#topic+lm.spike">lm.spike</a></code>.</p>
</td></tr>
<tr><td><code id="plot.lm.spike.residuals_+3A_burn">burn</code></td>
<td>
<p> The number of MCMC iterations to be discarded as burn-in
before computing posterior means. </p>
</td></tr>
<tr><td><code id="plot.lm.spike.residuals_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to <code><a href="graphics.html#topic+plot">plot</a>.</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This plot is normally called via the plot function for <code>lm.spike</code>
objects.  See the help entry for <code><a href="#topic+lm.spike">lm.spike</a></code> for example
usage.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
</p>

<hr>
<h2 id='plot.logit.spike'>
Plot a <code><a href="#topic+logit.spike">logit.spike</a></code> object
</h2><span id='topic+plot.logit.spike'></span><span id='topic+plot.probit.spike'></span>

<h3>Description</h3>

<p>Plot a <code><a href="#topic+logit.spike">logit.spike</a></code> object.  The default plot is a
barplot of the marginal inclusion probabilities for each variable,
as obtained by <code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.
See below for other types of plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'logit.spike'
plot(x,
     y = c("inclusion", "coefficients", "scaled.coefficients", "fit",
           "residuals", "size", "help"),
     burn = SuggestBurnLogLikelihood(x$log.likelihood),
     ...)

  ## S3 method for class 'probit.spike'
plot(x,
     y = c("inclusion", "coefficients", "scaled.coefficients", "fit",
           "residuals", "size", "help"),
     burn = SuggestBurnLogLikelihood(x$log.likelihood),
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.logit.spike_+3A_x">x</code></td>
<td>

<p>An object of class <code>logit.spike</code>.
</p>
</td></tr>
<tr><td><code id="plot.logit.spike_+3A_y">y</code></td>
<td>

<p>The type of plot desired.
</p>
</td></tr>
<tr><td><code id="plot.logit.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="plot.logit.spike_+3A_...">...</code></td>
<td>
<p> Additional arguments passed to the specific functions
that do the plotting.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default plot is a barplot showing the marginal inclusion
probabilities of the coefficients, constructed using
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.
</p>
<p>The plot of the fit summary is handled by
<code><a href="#topic+PlotLogitSpikeFitSummary">PlotLogitSpikeFitSummary</a></code>.
</p>
<p>The plot of the residuals is handled by
<code><a href="#topic+PlotLogitSpikeResiduals">PlotLogitSpikeResiduals</a></code>.
</p>
<p>The plot of model size is handled by <code><a href="#topic+PlotModelSize">PlotModelSize</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>
<code><a href="#topic+PlotModelSize">PlotModelSize</a></code>
<code><a href="#topic+PlotLogitSpikeFitSummary">PlotLogitSpikeFitSummary</a></code>
<code><a href="#topic+PlotLogitSpikeResiduals">PlotLogitSpikeResiduals</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See the examples in ?logit.spike
</code></pre>

<hr>
<h2 id='plot.logit.spike.fit.summary'>
Plot Logit or Probit Fit Summary
</h2><span id='topic+PlotLogitSpikeFitSummary'></span><span id='topic+PlotProbitSpikeFitSummary'></span>

<h3>Description</h3>

<p>Two plots can be accessed by this function.  The first is a time
series plot of the &quot;deviance R-square&quot; statistic, by MCMC iteration.
The second is a Hosmer-Lemeshow plot in which the data is divided into
10 groups based on predicted probabilities, and the empirical success
probabilities for that group are plotted against the expected
probabilities from the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotLogitSpikeFitSummary(
    model,
    burn = 0,
    which.summary = c("both", "r2", "bucket"),
    scale = c("logit", "probability"),
    cutpoint.basis = c("sample.size", "equal.range"),
    number.of.buckets = 10,
    ...)

PlotProbitSpikeFitSummary(
    model,
    burn = 0,
    which.summary = c("both", "r2", "bucket"),
    scale = c("probit", "probability"),
    cutpoint.basis = c("sample.size", "equal.range"),
    number.of.buckets = 10,
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_model">model</code></td>
<td>
<p>A model object inheriting from <code><a href="#topic+logit.spike">logit.spike</a></code>
or <code><a href="#topic+probit.spike">probit.spike</a></code>.</p>
</td></tr>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_burn">burn</code></td>
<td>
<p> The number of MCMC iterations in the object to be
discarded as burn-in.  Note that this only affects the deviance
R-square plot.  The fit summaries in the Hosmer-Lemeshow plot are
constructed by <code><a href="#topic+logit.spike">logit.spike</a></code> or
<code><a href="#topic+probit.spike">probit.spike</a></code> in order to keep permanent object sizes
small.  </p>
</td></tr>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_which.summary">which.summary</code></td>
<td>
<p>Which plot is desired?</p>
</td></tr>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_scale">scale</code></td>
<td>
<p>The scale to use for the predicted probabilities in the
Hosmer-Lemeshow plot.  </p>
</td></tr>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_cutpoint.basis">cutpoint.basis</code></td>
<td>
<p>How should cutpoints be determined for the
Hosmer-Lemeshow plot?  If <code>"sample.size"</code> then each bucket will
have equal sample size.  If <code>"equal.range"</code> then each bucket
will occupy the same size on the chosen (logit/probit or probability) scale.</p>
</td></tr>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_number.of.buckets">number.of.buckets</code></td>
<td>
<p>The number of buckets to use in the
Hosmer-Lemeshow plot.</p>
</td></tr>
<tr><td><code id="plot.logit.spike.fit.summary_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to <code><a href="graphics.html#topic+barplot">barplot</a>.</code>
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.logit.spike &lt;- function(n = 100, p = 10, ngood = 3,
                              niter=1000){
  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  prob &lt;- plogis(x %*% beta)
  y &lt;- runif(n) &lt; prob
  x &lt;- x[,-1]
  draws &lt;- logit.spike(y ~ x, niter=niter)
  plot.ts(draws$beta)
  return(invisible(draws))
}
model &lt;- simulate.logit.spike()
plot(model, "fit")
plot(model, "fit", scale = "probability", number.of.buckets = 15)
</code></pre>

<hr>
<h2 id='plot.logit.spike.residuals'>
Residual plot for <code><a href="#topic+logit.spike">logit.spike</a></code> objects.
</h2><span id='topic+PlotLogitSpikeResiduals'></span><span id='topic+PlotProbitSpikeResiduals'></span>

<h3>Description</h3>

<p>Plots the &quot;deviance residuals&quot; from a logit.spike model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  PlotLogitSpikeResiduals(model, ...)
  PlotProbitSpikeResiduals(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.logit.spike.residuals_+3A_model">model</code></td>
<td>
<p>A model object inheriting from <code><a href="#topic+logit.spike">logit.spike</a></code>
or <code><a href="#topic+probit.spike">probit.spike</a></code>.</p>
</td></tr>
<tr><td><code id="plot.logit.spike.residuals_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to <code><a href="graphics.html#topic+plot">plot</a>.</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;deviance residuals&quot; are defined as the signed square root
each observation's contribution to log likelihood.  The sign of
the residual is positive if half or more of the trials associated
with an observation are successes.  The sign is negative
otherwise.
</p>
<p>The &quot;contribution to log likelihood&quot; is taken to be the posterior mean
of an observations log likelihood contribution, averaged over the life
of the MCMC chain.
</p>
<p>The deviance residual is plotted against the fitted value, again
averaged over the life of the MCMC chain.
</p>
<p>The plot also shows the .95 and .99 bounds from the square root
of a chi-square(1) random variable.  As a rough approximation,
about 5% and 1% of the data should lie outside these bounds.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logit.spike">logit.spike</a></code>
<code><a href="#topic+plot.logit.spike">plot.logit.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.logit.spike &lt;- function(n = 100, p = 10, ngood = 3,
                              niter=1000){
  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  prob &lt;- plogis(x %*% beta)
  y &lt;- runif(n) &lt; prob
  x &lt;- x[,-1]
  draws &lt;- logit.spike(y ~ x, niter=niter)
  plot.ts(draws$beta)
  return(invisible(draws))
}
model &lt;- simulate.logit.spike()
plot(model, "fit")
plot(model, "fit", scale = "probability", number.of.buckets = 15)
</code></pre>

<hr>
<h2 id='plot.marginal.inclusion.probabilities'>
Plot marginal inclusion probabilities.
</h2><span id='topic+PlotMarginalInclusionProbabilities'></span>

<h3>Description</h3>

<p>Produces a barplot of the marginal inclusion probabilities for a
set of model coefficients sampled under a spike and slab prior.
The coefficients are sorted by the marginal inclusion
probability, and shaded by the conditional probability that a
coefficient is positive, given that it is nonzero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMarginalInclusionProbabilities(
     beta,
     burn = 0,
     inclusion.threshold = 0,
     unit.scale = TRUE,
     number.of.variables = NULL,
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.marginal.inclusion.probabilities_+3A_beta">beta</code></td>
<td>
<p> A matrix of model coefficients.  Each row represents an
MCMC draw.  Each column represents a coefficient for a variable.
</p>
</td></tr>
<tr><td><code id="plot.marginal.inclusion.probabilities_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the ojbect to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="plot.marginal.inclusion.probabilities_+3A_inclusion.threshold">inclusion.threshold</code></td>
<td>
<p> Only plot coefficients with posterior
inclusion probabilities exceeding this value.  </p>
</td></tr>
<tr><td><code id="plot.marginal.inclusion.probabilities_+3A_unit.scale">unit.scale</code></td>
<td>
<p>A logical value indicating whether the scale of the
plot should be from 0 to 1.  Otherwise the scale is determined by
the maximum inclusion probability.</p>
</td></tr>
<tr><td><code id="plot.marginal.inclusion.probabilities_+3A_number.of.variables">number.of.variables</code></td>
<td>
<p>If non-<code>NULL</code> this specifies the
number of coefficients to plot, taking precedence over
<code>inclusion.threshold</code>.</p>
</td></tr>
<tr><td><code id="plot.marginal.inclusion.probabilities_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to <code><a href="graphics.html#topic+barplot">barplot</a>.</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a list with the following elements.
</p>
<table>
<tr><td><code>barplot</code></td>
<td>
<p>The midpoints of each bar, which is useful for adding
to the plot.</p>
</td></tr>
<tr><td><code>inclusion.prob</code></td>
<td>
<p>The marginal inclusion probabilities of each
variable, ordered smallest to largest (the same order as the plot).</p>
</td></tr>
<tr><td><code>positive.prob</code></td>
<td>
<p>The probability that each variable has a
positive coefficient, in the same order as <code>inclusion.prob</code>.</p>
</td></tr>
<tr><td><code>permutation</code></td>
<td>
<p>The permutation of beta that puts the
coefficients in the same order as <code>positive.prob</code> and
<code>inclusion.prob</code>.  That is: <code>beta[, permutation]</code> will have the
most significant coefficients in the right hand columns.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.lm.spike &lt;- function(n = 100, p = 10, ngood = 3, niter=1000, sigma = 8){
  x &lt;- cbind(matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, beta[1] + x %*% beta[-1], sigma)
  draws &lt;- lm.spike(y ~ x, niter=niter)
  return(invisible(draws))
}
model &lt;- simulate.lm.spike(n = 1000, p = 50, sigma = .3)
plot(model, inclusion.threshold = .01)
</code></pre>

<hr>
<h2 id='plot.poisson.spike'>
Plot a <code><a href="#topic+poisson.spike">poisson.spike</a></code> object
</h2><span id='topic+plot.poisson.spike'></span>

<h3>Description</h3>

<p>Plot a <code><a href="#topic+poisson.spike">poisson.spike</a></code> object.  The default plot is a
barplot of the marginal inclusion probabilities for each variable,
as obtained by <code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.
See below for other types of plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'poisson.spike'
plot(x,
     y = c("inclusion", "coefficients", "scaled.coefficients", "size", "help"),
     burn = SuggestBurnLogLikelihood(x$log.likelihood),
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.poisson.spike_+3A_x">x</code></td>
<td>

<p>An object of class <code>poisson.spike</code>.
</p>
</td></tr>
<tr><td><code id="plot.poisson.spike_+3A_y">y</code></td>
<td>

<p>The type of plot desired.
</p>
</td></tr>
<tr><td><code id="plot.poisson.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="plot.poisson.spike_+3A_...">...</code></td>
<td>
<p> Additional arguments passed to the specific functions
that do the plotting.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default plot is a barplot showing the marginal inclusion
probabilities of the coefficients, constructed using
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.
</p>
<p>The plot of model size is handled by <code><a href="#topic+PlotModelSize">PlotModelSize</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>
<code><a href="#topic+PlotModelSize">PlotModelSize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See the examples in ?poisson.spike
</code></pre>

<hr>
<h2 id='plot.qreg.spike'>
Plot the results of a spike and slab regression.
</h2><span id='topic+plot.qreg.spike'></span>

<h3>Description</h3>

<p>The default plot is a barplot of the marginal inclusion probabilities
for each variable, as obtained by
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>.  Other interesting
plots can be obtained by supplying a string as the second argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'qreg.spike'
plot(x,
     y = c("inclusion", "coefficients", "scaled.coefficients",
              "size", "help"),
     burn = SuggestBurnLogLikelihood(x$log.likelihood),
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.qreg.spike_+3A_x">x</code></td>
<td>

<p>An object of class <code>qreg.spike</code>.
</p>
</td></tr>
<tr><td><code id="plot.qreg.spike_+3A_y">y</code></td>
<td>

<p>The type of plot desired.
</p>
</td></tr>
<tr><td><code id="plot.qreg.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations to discard as burn-in.
</p>
</td></tr>
<tr><td><code id="plot.qreg.spike_+3A_...">...</code></td>
<td>
<p> Additional arguments passed to the specific functions
that do the plotting.  </p>
</td></tr>
</table>


<h3>Details</h3>

<p> The actual plotting will be handled by
<code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>,
<code><a href="#topic+PlotLmSpikeCoefficients">PlotLmSpikeCoefficients</a></code>, or <code><a href="#topic+PlotModelSize">PlotModelSize</a></code>.
See the appropriate function for more options.</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotMarginalInclusionProbabilities">PlotMarginalInclusionProbabilities</a></code>
<code><a href="#topic+PlotLmSpikeCoefficients">PlotLmSpikeCoefficients</a></code>
<code><a href="#topic+PlotModelSize">PlotModelSize</a></code>
<code><a href="#topic+qreg.spike">qreg.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+predict.qreg.spike">predict.qreg.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 50
  x &lt;- rnorm(n)
  y &lt;- rnorm(n, 4 * x)
  model &lt;- qreg.spike(y ~ x,
                      quantile = .8,
                      niter = 1000,
                      expected.model.size = 100)
  plot(model)
  plot(model, "coef")
  plot(model, "coefficients")
  plot(model, "scaled.coefficients")
  plot(model, "scal")
  plot(model, "size")
  plot(model, "help")
</code></pre>

<hr>
<h2 id='PlotModelSize'>
Plot a distribution of model size
</h2><span id='topic+PlotModelSize'></span>

<h3>Description</h3>

<p>Produces a histogram of number of nonzero coefficients in a
spike-and-slab regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  PlotModelSize(beta, burn = 0, xlab= "Number of nonzero coefficients", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotModelSize_+3A_beta">beta</code></td>
<td>
<p> A matrix of model coefficients.  Each row represents an
MCMC draw.  Each column represents a coefficient for a variable.  </p>
</td></tr>
<tr><td><code id="PlotModelSize_+3A_burn">burn</code></td>
<td>
<p> The number of MCMC iterations to be discarded as
burn-in.</p>
</td></tr>
<tr><td><code id="PlotModelSize_+3A_xlab">xlab</code></td>
<td>
<p> Label for the horizontal axis.</p>
</td></tr>
<tr><td><code id="PlotModelSize_+3A_...">...</code></td>
<td>

<p>Additional arguments to be passed to <code><a href="graphics.html#topic+hist">hist</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the vector of MCMC draws of model sizes.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.lm.spike &lt;- function(n = 100, p = 10, ngood = 3, niter=1000, sigma = 8){
  x &lt;- cbind(matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, beta[1] + x %*% beta[-1], sigma)
  draws &lt;- lm.spike(y ~ x, niter=niter)
  return(invisible(draws))
}
model &lt;- simulate.lm.spike(n = 1000, p = 50, sigma = .3)

# To get the plot of model size directly.
PlotModelSize(model$beta, burn = 10)

# Another way to get the same plot.
plot(model, "size", burn = 10)
</code></pre>

<hr>
<h2 id='poisson.spike'>
Spike and slab Poisson regression
</h2><span id='topic+poisson.spike'></span>

<h3>Description</h3>

<p>MCMC algorithm for Poisson regression models with a 'spike-and-slab'
prior that places some amount of posterior probability at zero for a
subset of the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisson.spike(formula,
              exposure = 1,
              niter,
              data,
              subset,
              prior = NULL,
              na.action = options("na.action"),
              contrasts = NULL,
              drop.unused.levels = TRUE,
              initial.value = NULL,
              ping = niter / 10,
              nthreads = 4,
              seed = NULL,
              ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poisson.spike_+3A_formula">formula</code></td>
<td>
<p>A model formula, as would be passed to <code>glm</code>,
specifying the maximal model (i.e. the model with all predictors
included).  </p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_exposure">exposure</code></td>
<td>
<p>A vector of exposure durations matching the length of
the response vector.  If <code>exposure</code> is of length 1 it will be
recycled. </p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_niter">niter</code></td>
<td>
<p> The number of MCMC iterations to run. </p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_data">data</code></td>
<td>
<p> An optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>, typically the
environment from which <code>poisson.spike</code> is called.  </p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_subset">subset</code></td>
<td>
<p> An optional vector specifying a subset of observations
to be used in the fitting process.  </p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_prior">prior</code></td>
<td>
<p> A list such as that returned by
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.  If <code>prior</code> is supplied it
will be used.  Otherwise a prior distribution will be built using
the remaining arguments.  See <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.
</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when
the data contain <code>NA</code>s.  The default is set by the
<code>na.action</code> setting of <code>options</code>, and is <code>na.fail</code> if
that is unset.  The <code>factory-fresh</code> default is <code>na.omit</code>.
Another possible value is <code>NULL</code>, no action.  Value
<code>na.exclude</code> can be useful.</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code> of
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p> A logical value indicating whether factor
levels that are unobserved should be dropped from the model.</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_initial.value">initial.value</code></td>
<td>
<p>Initial value for the MCMC algorithm.  Can either
be a numeric vector, a <code><a href="stats.html#topic+glm">glm</a></code> object (from which the
coefficients will be used), or a <code><a href="#topic+poisson.spike">poisson.spike</a></code> object.
If a <code><a href="#topic+poisson.spike">poisson.spike</a></code> object is supplied, it is assumed to
be from a previous MCMC run for which <code>niter</code> additional draws
are desired.  If a <code><a href="stats.html#topic+glm">glm</a></code> object is supplied then its
coefficients will be used as the initial values for the simulation.
</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_ping">ping</code></td>
<td>
<p>If positive, then print a status update to the console
every <code>ping</code> MCMC iterations.</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_nthreads">nthreads</code></td>
<td>
<p>The number of CPU-threads to use for data
augmentation.</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_seed">seed</code></td>
<td>
<p>Seed to use for the C++ random number generator.  It
should be <code>NULL</code> or an int.  If <code>NULL</code> the seed value will
be taken from the global <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> object.</p>
</td></tr>
<tr><td><code id="poisson.spike_+3A_...">...</code></td>
<td>

<p>Extra arguments to be passed to <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MCMC algorithm used here is based on the auxiliary mixture
sampling algorithm published by Fruhwirth-Schnatter, Fruhwirth, Held,
and Rue (2009).
</p>


<h3>Value</h3>

<p>Returns an object of class <code>poisson.spike</code>.  The returned object
is a list with the following elements.
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code>niter</code> by <code>ncol(x)</code> matrix of regression
coefficients, many of which may be zero.  Each row corresponds to an
MCMC iteration.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to fit the model.  If a <code>prior</code> was
supplied as an argument it will be returned.  Otherwise this will be
the automatically generated prior based on the other function
arguments. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Sylvia Fruhwirth-Schnatter, Rudolf Fruhwirth, Leonhard Held, and Havard Rue.
Statistics and Computing, Volume 19 Issue 4, Pages 479-492.  December 2009
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>,
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>,
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulate.poisson.spike &lt;- function(n = 100, p = 10, ngood = 3, niter=1000){
  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  lambda &lt;- exp(x %*% beta)
  y &lt;- rpois(n, lambda)
  x &lt;- x[,-1]
  model &lt;- poisson.spike(y ~ x, niter=niter)
  return(invisible(model))
}
model &lt;- simulate.poisson.spike()
plot(model)
summary(model)
</code></pre>

<hr>
<h2 id='poisson.zellner.prior'>
Zellner Prior for Poisson Regression
</h2><span id='topic+PoissonZellnerPrior'></span>

<h3>Description</h3>

<p>A Zellner-style spike and slab prior for Poisson regression models.
See 'Details' for a definition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoissonZellnerPrior(
    predictors,
    counts = NULL,
    exposure = NULL,
    prior.event.rate = NULL,
    expected.model.size = 1,
    prior.information.weight = .01,
    diagonal.shrinkage = .5,
    optional.coefficient.estimate = NULL,
    max.flips = -1,
    prior.inclusion.probabilities = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poisson.zellner.prior_+3A_predictors">predictors</code></td>
<td>

<p>The design matrix for the regression problem.  No missing data is allowed.
</p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_counts">counts</code></td>
<td>
<p>The vector of responses, This is only used to obtain the
empirical overall event rate, so it can be left <code>NULL</code> if
prior.event.rate is specified.  </p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_exposure">exposure</code></td>
<td>
<p>A vector of the same length as <code>counts</code>, giving
the &quot;exposure time&quot; for each observation.  This can also be
<code>NULL</code>, signifying that <code>exposure = 1.0</code> for each
observation.  </p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_prior.event.rate">prior.event.rate</code></td>
<td>
<p>An a priori guess at the overall event rate.
Used in two places: to set the prior mean of the intercept (if
<code>optional.coefficient.estimate</code> is <code>NULL</code>) and to weight
the information matrix in the &quot;slab&quot; portion of the prior.  </p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_prior.information.weight">prior.information.weight</code></td>
<td>

<p>A positive scalar.  Number of observations worth of weight that
should be given to the prior estimate of beta.
</p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_diagonal.shrinkage">diagonal.shrinkage</code></td>
<td>

<p>The conditionally Gaussian prior for beta (the &quot;slab&quot;) starts with a
precision matrix equal to the information in a single observation.
However, this matrix might not be full rank.  The matrix can be made
full rank by averaging with its diagonal.  <code>diagonal.shrinkage</code>
is the weight given to the diaonal in this average.  Setting this to
zero gives Zellner's g-prior.
</p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_max.flips">max.flips</code></td>
<td>
<p>The maximum number of variable inclusion indicators
the sampler will attempt to sample each iteration.  If negative then
all indicators will be sampled.</p>
</td></tr>
<tr><td><code id="poisson.zellner.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.  If <code>NULL</code> then a
default set of probabilities is obtained by setting each element
equal to <code>min(1, expected.model.size / ncol(x))</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> A Zellner-style spike and slab prior for Poisson regression.
Denote the vector of coefficients by <code class="reqn">\beta</code>, and the vector
of inclusion indicators by <code class="reqn">\gamma</code>.  These are linked by the
relationship <code class="reqn">\beta_i \ne 0</code> if <code class="reqn">\gamma_i =
1</code> and <code class="reqn">\beta_i = 0</code> if <code class="reqn">\gamma_i =
0</code>.  The prior is
</p>
<p style="text-align: center;"><code class="reqn">\beta | \gamma \sim N(b, V)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma \sim B(\pi)</code>
</p>

<p>where <code class="reqn">\pi</code> is the vector of
<code>prior.inclusion.probabilities</code>, and <code class="reqn">b</code> is the
<code>optional.coefficient.estimate</code>.  Conditional on
<code class="reqn">\gamma</code>, the prior information matrix is
</p>
<p style="text-align: center;"><code class="reqn">V^{-1} = \kappa ((1 - \alpha) x^Twx / n + \alpha diag(x^Twx / n))</code>
</p>

<p>The matrix <code class="reqn">x^Twx</code> is, for suitable choice of the weight vector
<code class="reqn">w</code>, the total Fisher information available in the data.
Dividing by <code class="reqn">n</code> gives the average Fisher information in a single
observation, multiplying by <code class="reqn">\kappa</code> then results in
<code class="reqn">\kappa</code> units of &quot;average&quot; information.  This matrix is
averaged with its diagonal to ensure positive definiteness.
</p>
<p>In the formula above, <code class="reqn">\kappa</code> is
<code>prior.information.weight</code>, <code class="reqn">\alpha</code> is
<code>diagonal.shrinkage</code>, and <code class="reqn">w</code> is a diagonal matrix with all
elements set to <code>prior.success.probability * (1 -
  prior.success.probability)</code>.  The vector <code class="reqn">b</code> and the matrix
<code class="reqn">V^{-1}</code> are both implicitly subscripted by <code class="reqn">\gamma</code>,
meaning that elements, rows, or columsn corresponding to gamma = 0
should be omitted.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>PoissonZellnerPrior</code>, which is a list
with data elements encoding the selected prior values.  It inherits
from <code>PoissonPrior</code> and from <code>SpikeSlabGlmPrior</code>, which
implies that it contains an element <code>prior.success.probability</code>.
</p>
<p>This object is intended for use with <code><a href="#topic+poisson.spike">poisson.spike</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Hugh Chipman, Edward I. George, Robert E. McCulloch, M. Clyde, Dean
P. Foster, Robert A. Stine (2001),
&quot;The Practical Implementation of Bayesian Model Selection&quot;
<em>Lecture Notes-Monograph Series</em>, Vol. 38, pp. 65-134.
Institute of Mathematical Statistics.
</p>

<hr>
<h2 id='predict.lm.spike'>
Predictions using spike-and-slab regression.
</h2><span id='topic+predict.lm.spike'></span><span id='topic+predict.logit.spike'></span><span id='topic+predict.probit.spike'></span><span id='topic+predict.poisson.spike'></span><span id='topic+predict.qreg.spike'></span><span id='topic+predict.BayesNnet'></span>

<h3>Description</h3>

<p>Generate draws from the posterior predictive distribution of a spike
and slab regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm.spike'
predict(object, newdata = NULL, burn = 0,
    na.action = na.pass, mean.only = FALSE, ...)

## S3 method for class 'logit.spike'
predict(object, newdata, burn = 0,
    type = c("prob", "logit", "link", "response"),
    na.action = na.pass, ...)

## S3 method for class 'poisson.spike'
predict(object, newdata = NULL,
    exposure = NULL, burn = 0,
    type = c("mean", "log", "link", "response"),
    na.action = na.pass, ...)

## S3 method for class 'probit.spike'
predict(object, newdata, burn = 0,
    type = c("prob", "probit", "link", "response"),
    na.action = na.pass, ...)

## S3 method for class 'qreg.spike'
predict(object, newdata, burn = 0,
    na.action = na.pass, ...)

## S3 method for class 'BayesNnet'
predict(object, newdata = NULL, burn = 0,
    na.action = na.pass, mean.only = FALSE, seed = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.lm.spike_+3A_object">object</code></td>
<td>

<p>A model object of class <code>lm.spike</code>, <code>logit.spike</code>, etc.
</p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_newdata">newdata</code></td>
<td>
<p> Either <code>NULL</code>, or else a data frame, matrix, or
vector containing the predictors needed to make the prediction.
</p>
<p>If <code>newdata</code> is <code>NULL</code> then the predictors are taken from
the training data used to create the model object.  Note that
<code>object</code> does not store its training data, so the data objects
used to fit the model must be present for the training data to be
recreated.
</p>
<p>If <code>newdata</code> is a <code>data.frame</code> it must contain variables
with the same names as the data frame used to fit <code>object</code>.  If
it is a <code>matrix</code>, it must have the same number of columns as
<code>object$beta</code>.  An intercept term will be implicitly added if
the number of columns is too small by one.  If the dimension of
<code>object$beta</code> is 1 or 2, then <code>newdata</code> can be a vector. </p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_exposure">exposure</code></td>
<td>
<p> A vector of positive real numbers the same size as
newdata, or <code>NULL</code>.  If both <code>newdata</code> and <code>exposure</code>
are <code>NULL</code> then <code>exposure</code> is taken to be the exposure
from the training data.  If <code>newdata</code> is supplied and
<code>exposure</code> is <code>NULL</code> then <code>exposure</code> is taken to be 1
for all observations.  </p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the object to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>'s.  The default is set by the
<code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and is
<code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.  The &quot;factory-fresh&quot; default
is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.  Another possible value is <code>NULL</code>, no
action.  Value <code><a href="stats.html#topic+na.exclude">na.exclude</a></code> can be useful.</p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_type">type</code></td>
<td>
<p> The type of prediction desired.
</p>
<p>For <code>logit.spike</code>, <code>prob</code> means the prediction is returned
on the probability scale, while <code>logit</code> returns the scale of
the linear predictor.  Probits work similarly to logits.
</p>
<p>For <code>poisson.spike</code>, <code>mean</code> means the prediction is
returned on the scale of the data, while <code>log</code> means it is on
the scale of the linear predictor.
</p>
<p>Both cases also accept <code>link</code> and <code>response</code> for
compatibility with <code>predict.glm</code>.  </p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_mean.only">mean.only</code></td>
<td>
<p>Logical.  If <code>TRUE</code> then return the posterior
mean of the predictive distribution.  If <code>FALSE</code> then return
the entire distribution.</p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_seed">seed</code></td>
<td>
<p>Random seed for the C++ random number generator.  This is
only needed for models that require C++ to implement their predict
method.</p>
</td></tr>
<tr><td><code id="predict.lm.spike_+3A_...">...</code></td>
<td>
<p>Unused, but present for compatibility with generic
<code>predict</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of predictions, with each row corresponding to a row
in newdata, and each column to an MCMC iteration.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  niter &lt;- 1000
  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- rep(0, p)
  good &lt;- sample(1:p, ngood)
  beta[good] &lt;- rnorm(ngood)
  sigma &lt;- 1

  y &lt;- rnorm(n, x %*% beta, sigma)
  model &lt;- lm.spike(y ~ x - 1, niter=niter)
  plot(model)
  plot.ts(model$beta)
  hist(model$sigma)  ## should be near true value

  new.x &lt;- cbind(1, matrix(rnorm(100 * (p-1)), ncol = (p-1)))
  pred &lt;- predict(model, newdata = new.x, burn = 100)
</code></pre>

<hr>
<h2 id='print.summary.lm.spike'>
Print method for spikeslab objects.
</h2><span id='topic+print.summary.lm.spike'></span><span id='topic+print.summary.logit.spike'></span>

<h3>Description</h3>

<p>Print a spikeslab object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.lm.spike'
print(x, ...)
## S3 method for class 'summary.logit.spike'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.lm.spike_+3A_x">x</code></td>
<td>

<p>An object of class <code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>.
</p>
</td></tr>
<tr><td><code id="print.summary.lm.spike_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to <code><a href="base.html#topic+print.default">print.default</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function is called for its side effect, which is to print the
<code>spikeslab</code> object to the screen.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3
  niter &lt;- 1000
  sigma &lt;- 2

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, x %*% beta, sigma)
  x &lt;- x[,-1]
  model &lt;- lm.spike(y ~ x, niter=niter)
  summary(model)
</code></pre>

<hr>
<h2 id='probit.spike'>
Spike and slab probit regression
</h2><span id='topic+probit.spike'></span>

<h3>Description</h3>

<p>MCMC algorithm for logistic regression models with a 'spike-and-slab'
prior that places some amount of posterior probability at zero for a
subset of the regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probit.spike(formula,
             niter,
             data,
             subset,
             prior = NULL,
             na.action = options("na.action"),
             contrasts = NULL,
             drop.unused.levels = TRUE,
             initial.value = NULL,
             ping = niter / 10,
             clt.threshold = 5,
             proposal.df = 3,
             sampler.weights = c(.5, .5),
             seed = NULL,
             ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probit.spike_+3A_formula">formula</code></td>
<td>
<p>Formula for the maximal model (with all variables
included).  This is parsed the same way as a call to
<code><a href="stats.html#topic+glm">glm</a></code>, but no <code>family</code> argument is needed.  Like
<code><a href="stats.html#topic+glm">glm</a></code>, a two-column input format (success-count,
failure-count) can be used for the reponse.  Otherwise, the response
variable can be a logical or numeric vector.  If a single-column
response is numeric, then a positive value indicates a &quot;success&quot;.  </p>
</td></tr>
<tr><td><code id="probit.spike_+3A_niter">niter</code></td>
<td>
<p> The number of MCMC iterations to run.  Be sure to
include enough so you can throw away a burn-in set.  </p>
</td></tr>
<tr><td><code id="probit.spike_+3A_data">data</code></td>
<td>
<p> An optional data frame, list or environment (or object
coercible by 'as.data.frame' to a data frame) containing the
variables in the model.  If not found in 'data', the variables are
taken from 'environment(formula)', typically the environment from
which probit.spike' is called.  </p>
</td></tr>
<tr><td><code id="probit.spike_+3A_subset">subset</code></td>
<td>
<p> An optional vector specifying a subset of observations
to be used in the fitting process.  </p>
</td></tr>
<tr><td><code id="probit.spike_+3A_prior">prior</code></td>
<td>
<p>An object inheriting from <code><a href="#topic+LogitPrior">LogitPrior</a></code> and
<code><a href="#topic+SpikeSlabPriorBase">SpikeSlabPriorBase</a></code>.  If <code>prior</code> is supplied it
will be used.  Otherwise a prior distribution will constructed by
calling <code><a href="#topic+LogitZellnerPrior">LogitZellnerPrior</a></code> with the remaining
arguments. Despite the name, LogitPrior objects are appropriate for
Probit models.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when
the data contain <code>NA</code>s.  The default is set by the
<code>na.action</code> setting of <code>options</code>, and is <code>na.fail</code> if
that is unset.  The <code>factory-fresh</code> default is <code>na.omit</code>.
Another possible value is <code>NULL</code>, no action.  Value
<code>na.exclude</code> can be useful.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code> of
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="probit.spike_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p> A logical value indicating whether factor
levels that are unobserved should be dropped from the model.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_initial.value">initial.value</code></td>
<td>
<p>Initial value for the MCMC algorithm.  Can either
be a numeric vector, a <code><a href="stats.html#topic+glm">glm</a></code> object (from which the
coefficients will be used), or a <code><a href="#topic+probit.spike">probit.spike</a></code> object.
If a <code><a href="#topic+probit.spike">probit.spike</a></code> object is supplied, it is assumed to
be from a previous MCMC run for which <code>niter</code> additional draws
are desired.  If a <code><a href="stats.html#topic+glm">glm</a></code> object is supplied then its
coefficients will be used as the initial values for the simulation.
</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_ping">ping</code></td>
<td>
<p>If positive, then print a status update to the console
every <code>ping</code> MCMC iterations.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_clt.threshold">clt.threshold</code></td>
<td>
<p>When the model is presented with binomial data
(i.e. when the response is a two-column matrix) the data
augmentation algorithm can be made more efficient by updating a
single, asymptotically normal scalar quantity for each unique value
of the predictors.  The asymptotic result will be used whenever the
number of successes or failures exceeds <code>clt.threshold</code>.
</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_proposal.df">proposal.df</code></td>
<td>
<p>The degrees of freedom parameter to use in
Metropolis-Hastings proposals.  See details.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_sampler.weights">sampler.weights</code></td>
<td>
<p>A two-element vector giving the probabilities
of drawing from the two base sampling algorithm.  The first element
refers to the spike and slab algorithm.  The second refers to the
tailored independence Metropolis sampler.  TIM is usually faster
mixing, but cannot change model dimension.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_seed">seed</code></td>
<td>
<p>Seed to use for the C++ random number generator.  It
should be <code>NULL</code> or an int.  If <code>NULL</code> the seed value will
be taken from the global <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> object.</p>
</td></tr>
<tr><td><code id="probit.spike_+3A_...">...</code></td>
<td>

<p>Extra arguments to be passed to <code><a href="#topic+LogitZellnerPrior">LogitZellnerPrior</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model parameters are updated using a composite of two
Metropolis-Hastings updates.  A data augmentation algorithm (Albert
and Chib 1993) updates the entire parameter vector at once, but can
mix slowly.
</p>
<p>The second algorithm is an independence Metropolis sampler centered on
the posterior mode with variance determined by posterior information
matrix (Fisher information plus prior information).  If
<code>proposal.df &gt; 0</code> then the tails of the proposal are inflated so
that a multivariate T proposal is used instead.
</p>
<p>At each iteration, one of the three algorithms is chosen at random.
The auxiliary mixture sampler is the only one that can change the
dimension of the coefficient vector.  The MH algorithm only updates
the coefficients that are currently nonzero.  </p>


<h3>Value</h3>

<p>Returns an object of class <code>probit.spike</code>, which inherits from
<code>lm.spike</code>.  The returned object is a list with the following
elements
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code>niter</code> by <code>ncol(x)</code> matrix of regression
coefficients, many of which may be zero.  Each row corresponds to an
MCMC iteration.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to fit the model.  If a <code>prior</code> was
supplied as an argument it will be returned.  Otherwise this will be
the automatically generated prior based on the other function
arguments. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+plot.probit.spike">plot.probit.spike</a></code>,
<code><a href="#topic+PlotProbitSpikeFitSummary">PlotProbitSpikeFitSummary</a></code>
<code><a href="#topic+PlotProbitSpikeResiduals">PlotProbitSpikeResiduals</a></code>
<code><a href="#topic+summary.logit.spike">summary.logit.spike</a></code>,
<code><a href="#topic+predict.logit.spike">predict.logit.spike</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("MASS")) {
  data(Pima.tr, package = "MASS")
  data(Pima.te, package = "MASS")
  pima &lt;- rbind(Pima.tr, Pima.te)
  model &lt;- probit.spike(type == "Yes" ~ ., data = pima, niter = 500)
  plot(model)
  plot(model, "fit")
  plot(model, "residuals")
  plot(model, "size")
  summary(model)
}
</code></pre>

<hr>
<h2 id='qreg.spike'>
Quantile Regression
</h2><span id='topic+qreg.spike'></span>

<h3>Description</h3>

<p>MCMC algorithm for quasi-Bayesian quantile models with a 'spike-and-slab'
prior that places some amount of posterior probability at zero for a
subset of the regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qreg.spike(formula,
               quantile,
               niter,
               ping = niter / 10,
               nthreads = 0,
               data,
               subset,
               prior = NULL,
               na.action = options("na.action"),
               contrasts = NULL,
               drop.unused.levels = TRUE,
               initial.value = NULL,
               seed = NULL,
               ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qreg.spike_+3A_formula">formula</code></td>
<td>
<p>Formula for the maximal model (with all variables
included).  </p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_quantile">quantile</code></td>
<td>
<p>A scalar value between 0 and 1 indicating the
quantile of the conditional distribution being modeled.</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_niter">niter</code></td>
<td>
<p> The number of MCMC iterations to run.  Be sure to
include enough so you can throw away a burn-in set.  </p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_ping">ping</code></td>
<td>
<p>If positive, then print a status update to the console
every <code>ping</code> MCMC iterations.</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_nthreads">nthreads</code></td>
<td>
<p>The number of CPU-threads to use for data
augmentation.  There is some small overhead to stopping and starting
threads.  For small data sets, thread overhead will make it faster
to run single threaded.  For larger data sets multi-threading can
speed things up substantially.  This is all machine dependent, so
please experiment.</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_data">data</code></td>
<td>
<p> An optional data frame, list or environment (or object
coercible by <code>as.data.frame</code> to a data frame) containing the
variables in the model.  If not found in <code>data</code>, the variables
are taken from <code>environment(formula)</code>, typically the
environment from which <code>qreg.spike</code> is called.  </p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_subset">subset</code></td>
<td>
<p> An optional vector specifying a subset of observations
to be used in the fitting process.  </p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_prior">prior</code></td>
<td>
<p>An optional list such as that returned from
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.  If missing, <code>SpikeSlabPrior</code>
will be called using the extra arguments passed via ....
</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when
the data contain <code>NA</code>s.  The default is set by the
<code>na.action</code> setting of <code>options</code>, and is <code>na.fail</code> if
that is unset.  The <code>factory-fresh</code> default is <code>na.omit</code>.
Another possible value is <code>NULL</code>, no action.  Value
<code>na.exclude</code> can be useful.</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_contrasts">contrasts</code></td>
<td>
<p> An optional list. See the <code>contrasts.arg</code> of
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.  </p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p> A logical value indicating whether factor
levels that are unobserved should be dropped from the model.</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_initial.value">initial.value</code></td>
<td>
<p>Initial value for the MCMC algorithm.  Can either
be a numeric vector, a <code><a href="stats.html#topic+glm">glm</a></code> object (from which the
coefficients will be used), or a <code><a href="#topic+qreg.spike">qreg.spike</a></code> object.
If a <code><a href="#topic+qreg.spike">qreg.spike</a></code> object is supplied, it is assumed to
be from a previous MCMC run for which <code>niter</code> additional draws
are desired.  If a <code><a href="stats.html#topic+glm">glm</a></code> object is supplied then its
coefficients will be used as the initial values for the simulation.
</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_seed">seed</code></td>
<td>
<p>Seed to use for the C++ random number generator.  It
should be <code>NULL</code> or an int.  If <code>NULL</code> the seed value will
be taken from the global <code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> object.</p>
</td></tr>
<tr><td><code id="qreg.spike_+3A_...">...</code></td>
<td>

<p>Extra arguments to be passed to <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Just like ordinary regression models the mean of a distribution as a
linear function of X, quantile regression models a specific quantile
(e.g. the 90th percentile) as a function of X.
</p>
<p>Median regression is a special case of quantile regression.  Median
regression is sometimes cast in terms of minimizing |y - X * beta|,
because the median is the optimal action under L1 loss.  Similarly,
selecting quantile tau is optimal under the asymmetric loss function
</p>
<p style="text-align: center;"><code class="reqn">\rho_\tau(u) = \tau u I(u &gt; 0) + (1-\tau) u I(u &lt; 0) </code>
</p>

<p>Thus quantile regression (for a specific quantile tau) minimizes
</p>
<p style="text-align: center;"><code class="reqn"> Q(\beta) = \sum_i \rho_\tau( y_i - \beta^Tx_i) </code>
</p>

<p>Bayesian quantile regression treats </p>
<p style="text-align: center;"><code class="reqn">\exp(-2Q(\beta))</code>
</p>

<p>as a likelihood function to which a prior distribution
<code class="reqn">p(\beta)</code> is applied.  For posterior sampling, a data
augmentation scheme is used where each observation is associated with
a latent variable <code class="reqn">\lambda_i</code>, which has a marginal
distribution of </p>
<p style="text-align: center;"><code class="reqn">Exp(2 \tau(1-\tau)).</code>
</p>

<p>The conditional distribution given the residual <code class="reqn">r = y - x
    \beta</code> is
</p>
<p style="text-align: center;"><code class="reqn">
    \frac{1}{\lambda} | r \sim  InvGaus( 1 / |r|, 1.0)</code>
</p>

<p>The conditional distribution of beta given complete data (lambda and
y) is a weighted least squares regression, where observation i has
precision <code class="reqn">\lambda_i</code> and where observation i is offset
by <code class="reqn">2(\tau - 1)\lambda_i</code>.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>qreg.spike</code>, which inherits from
<code>lm.spike</code>.  The returned object is a list with the following
elements
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code>niter</code> by <code>ncol(x)</code> matrix of regression
coefficients, many of which may be zero.  Each row corresponds to an
MCMC iteration.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to fit the model.  If a <code>prior</code> was
supplied as an argument it will be returned.  Otherwise this will be
the automatically generated prior based on the other function
arguments. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Parzen and Polson (2011, unpublished)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>,
<code><a href="#topic+plot.qreg.spike">plot.qreg.spike</a></code>,
<code><a href="#topic+predict.qreg.spike">predict.qreg.spike</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 50
  x &lt;- rnorm(n)
  y &lt;- rnorm(n, 4 * x)
  model &lt;- qreg.spike(y ~ x,
                      quantile = .8,
                      niter = 1000,
                      expected.model.size = 100)

  ## Should get a slope near 4 and an intercept near qnorm(.8).
  PlotManyTs(model$beta[-(1:100),],
             same.scale = TRUE,
             truth = c(qnorm(.8), 4))

</code></pre>

<hr>
<h2 id='residuals.lm.spike'>
Extract lm.spike Residuals
</h2><span id='topic+residuals.lm.spike'></span>

<h3>Description</h3>

<p>Get residuals from an <code><a href="#topic+lm.spike">lm.spike</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm.spike'
residuals(
    object,
    burn = SuggestBurnLogLikelihood(object$log.likelihood),
    mean.only = FALSE,
    ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.lm.spike_+3A_object">object</code></td>
<td>

<p>An object of class <code>lm.spike</code>.
</p>
</td></tr>
<tr><td><code id="residuals.lm.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the object to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="residuals.lm.spike_+3A_mean.only">mean.only</code></td>
<td>
<p> Logical.  If <code>TRUE</code> then the posterior mean of
each residual is returned.  If <code>FALSE</code> then the full
posterior distribution of residuals is returned.  </p>
</td></tr>
<tr><td><code id="residuals.lm.spike_+3A_...">...</code></td>
<td>
<p>Unused, but present for compatibility with generic
<code>residuals</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> The posterior distribution (or posterior mean) of residuals from
the model object.  If <code>mean.only</code> is <code>TRUE</code> then the return
value is the vector of residuals, otherwise the return value is a
matrix, with rows corresponding to MCMC iterations, and columns to
individual observations.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  niter &lt;- 1000
  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- rep(0, p)
  good &lt;- sample(1:p, ngood)
  beta[good] &lt;- rnorm(ngood)
  sigma &lt;- 1

  y &lt;- rnorm(n, x %*% beta, sigma)
  model &lt;- lm.spike(y ~ x - 1, niter=niter)
  plot(model)
  residuals(model)
  residuals(model, mean.only = TRUE)
</code></pre>

<hr>
<h2 id='shrinkage.regression'>
Shrinking Regression Coefficients
</h2><span id='topic+ShrinkageRegression'></span><span id='topic+CoefficientGroup'></span>

<h3>Description</h3>

<p>Fits a Bayesian regression model with a shrinkage prior on the coefficient.
The model is
</p>
<p style="text-align: center;"><code class="reqn">%
            y_i  \sim N(x_i  \beta, \sigma^2) \\ %
     1 / \sigma^2 \sim Gamma(df/2, ss/2)        \\ %
  g_1(\beta) \sim N(b1, v1)                \\ %
  g_2(\beta) \sim N(b2, v2)                \\ %
  \dots </code>
</p>

<p>In this notation, <code class="reqn">g_k(\beta) \sim N(b_k, v_k)</code> indicates that the subset of coefficients in group k are a
priori independent draws from the specified normal distribution. In
addition, each subset-level prior may include a hyperprior, in which
case the subset-level prior parameters will be updated as part of the
MCMC.  The hyperprior has the form of independent priors on the mean
and precision parameters:
</p>
<p style="text-align: center;"><code class="reqn">%
                      b_i ~ N(prior.mean, prior.variance)   \\ %
                  1 / v_i ~ Chisq(df, guess.at.sd).          \\ %
                </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>ShrinkageRegression(response, predictors, coefficient.groups,
                    residual.precision.prior = NULL,
                    suf = NULL, niter, ping = niter / 10,
                    seed = NULL)

CoefficientGroup(indices, mean.hyperprior = NULL, sd.hyperprior = NULL,
                 prior = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shrinkage.regression_+3A_response">response</code></td>
<td>
<p>The numeric vector of responses.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_predictors">predictors</code></td>
<td>
<p>The matrix of predictors, including an intercept
term, if desired.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_coefficient.groups">coefficient.groups</code></td>
<td>
<p>A list of objects of type
<code><a href="#topic+CoefficientGroup">CoefficientGroup</a></code>, defining the pattern in which the
coefficients should be shrunk together.  Each coefficient must
belong to exactly one <code>CoefficientGroup</code>.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_residual.precision.prior">residual.precision.prior</code></td>
<td>
<p>An object of type
<code><a href="Boom.html#topic+SdPrior">SdPrior</a></code> describing the prior distribution of the
residual standard deviation.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_suf">suf</code></td>
<td>
<p>An object of class <code><a href="Boom.html#topic+RegressionSuf">RegressionSuf</a></code> containing
the sufficient statistics for the regression model.  If this is
<code>NULL</code> then it will be computed from <code>response</code> and
<code>predictors</code>.  If it is supplied then <code>response</code> and
<code>predictors</code> are not used and can be left missing.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_niter">niter</code></td>
<td>
<p>The desired number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_ping">ping</code></td>
<td>
<p>The frequency with which to print status updates.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_seed">seed</code></td>
<td>
<p>The integer-valued seed (or <code>NULL</code>) to use for the
C++ random number generator.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_indices">indices</code></td>
<td>
<p>A vector of integers giving the positions of the regression
coefficients that should be viewed as exchangeable.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_mean.hyperprior">mean.hyperprior</code></td>
<td>
<p>A <code><a href="Boom.html#topic+NormalPrior">NormalPrior</a></code> object describing
the hyperprior distribution for the average coefficient.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_sd.hyperprior">sd.hyperprior</code></td>
<td>
<p>An <code><a href="Boom.html#topic+SdPrior">SdPrior</a></code> object describing the
hyperprior distribution for the standard deviation of the
coefficients.</p>
</td></tr>
<tr><td><code id="shrinkage.regression_+3A_prior">prior</code></td>
<td>
<p>An object of type <code><a href="Boom.html#topic+NormalPrior">NormalPrior</a></code> giving the
initial value of the distribution describing the collection of
coefficients in this group.  If either hyperprior is <code>NULL</code>
then the corresponding prior parameter will not be updated.  If both
hyperpriors are non-<code>NULL</code> then this parameter can be left
unspecified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>ShrinkageRegression</code> returns a list containing MCMC draws from
the posterior distribution of model parameters.  Each of the following
is a matrix, with rows corresponding to MCMC draws, and columsn to
distinct parameters.
</p>

<ul>
<li><p> coefficients: regression coefficients.
</p>
</li>
<li><p> residual.sd: the residual standard deviation from the
regression model.
</p>
</li>
<li><p> group.means: The posterior distribution of the mean of each
coefficient group.  If no mean hyperprior was assigned to a
particular group, then the value here will be a constant (the
values supplied by the <code>prior</code> argument to
<code>CoefficientGroup</code> for that group).
</p>
</li>
<li><p> group.sds: The posterior distribution of the standard
deviation of each coefficient group.  If no sd.hyperprior was
assigned to a particular group, then the value here will be a
constant (the values supplied by the <code>prior</code> argument to
<code>CoefficientGroup</code> for that group).
</p>
</li></ul>

<p><code>CoefficientGroup</code> is a configuration utility used to define
which coefficients should be shrunk together.  It returns an object
(list) formatted in the manner expected by
<code>ShrinkageRegression</code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>Examples</h3>

<pre><code class='language-R'>b0 &lt;- -1
b1 &lt;- rnorm(20, 3, .2)
b2 &lt;- rnorm(30, -4, 7)
nobs &lt;- 10000
beta &lt;- c(b0, b1, b2)

X &lt;- cbind(1, matrix(rnorm(nobs * (length(beta) - 1)), nrow = nobs, ncol = length(beta) - 1))
y.hat &lt;- X %*% beta
y &lt;- rnorm(nobs, y.hat, .5)

groups &lt;- list(intercept = CoefficientGroup(1, prior = NormalPrior(0, 100)),
               first = CoefficientGroup(2:21,
                                        mean.hyperprior = NormalPrior(0, 100),
                                        sd.hyperprior = SdPrior(.2, 1)),
               second = CoefficientGroup(22:51,
                                         mean.hyperprior = NormalPrior(0, 100),
                                         sd.hyperprior = SdPrior(7, 1)))

model &lt;- ShrinkageRegression(y, X, groups,
                             residual.precision.prior = SdPrior(.5, 1),
                             niter = 1000)

</code></pre>

<hr>
<h2 id='spike.slab.glm.prior'>
Zellner Prior for Glm's.
</h2><span id='topic+SpikeSlabGlmPrior'></span><span id='topic+SpikeSlabGlmPriorDirect'></span>

<h3>Description</h3>

<p>A Zellner-style spike and slab prior for generalized linear models.
It is intended as a base class for LogitZellnerPrior,
PoissonZellnerPrior, and potential future extensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpikeSlabGlmPrior(
    predictors,
    weight,
    mean.on.natural.scale,
    expected.model.size,
    prior.information.weight,
    diagonal.shrinkage,
    optional.coefficient.estimate,
    max.flips,
    prior.inclusion.probabilities)

SpikeSlabGlmPriorDirect(
    coefficient.mean,
    coefficient.precision,
    prior.inclusion.probabilities = NULL,
    expected.model.size = NULL,
    max.flips = -1)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spike.slab.glm.prior_+3A_predictors">predictors</code></td>
<td>

<p>The design matrix for the regression problem.  No missing data is allowed.
</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_weight">weight</code></td>
<td>
<p>A vector of length <code>nrow(predictors)</code> giving the
prior weight assigned to each observation in <code>predictors</code>.
This should ideally match the weights from the Fisher information
(e.g. <code>p * (1-p)</code>) for logistic regression, or <code>lambda</code> for
Poisson regression, but that depends on the model, so a typical
thing to do is to set all the weights the same. </p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_mean.on.natural.scale">mean.on.natural.scale</code></td>
<td>
<p>Used to set the prior mean for the
intercept.  The mean of the response, expressed on the natural
scale.  This is logit(p-hat) for logits and log(ybar) for Poissons.
</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_prior.information.weight">prior.information.weight</code></td>
<td>

<p>A positive scalar.  Number of observations worth of weight that
should be given to the prior estimate of beta.
</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_diagonal.shrinkage">diagonal.shrinkage</code></td>
<td>

<p>The conditionally Gaussian prior for beta (the &quot;slab&quot;) starts with a
precision matrix equal to the information in a single observation.
However, this matrix might not be full rank.  The matrix can be made
full rank by averaging with its diagonal.  <code>diagonal.shrinkage</code>
is the weight given to the diaonal in this average.  Setting this to
zero gives Zellner's g-prior.
</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_max.flips">max.flips</code></td>
<td>
<p>The maximum number of variable inclusion indicators
the sampler will attempt to sample each iteration.  If negative then
all indicators will be sampled.</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.  If <code>NULL</code> then a
default set of probabilities is obtained by setting each element
equal to <code>min(1, expected.model.size / ncol(x))</code>.</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_coefficient.mean">coefficient.mean</code></td>
<td>
<p>The prior mean of the coefficients in the
maximal model (with all coefficients included).</p>
</td></tr>
<tr><td><code id="spike.slab.glm.prior_+3A_coefficient.precision">coefficient.precision</code></td>
<td>
<p>The prior precision (inverse variance) of
the coefficients in the maximal model (with all coefficients
included).</p>
</td></tr>
</table>


<h3>Details</h3>

<p> A Zellner-style spike and slab prior for generalized linear
models.  Denote the vector of coefficients by <code class="reqn">\beta</code>, and the
vector of inclusion indicators by <code class="reqn">\gamma</code>.  These are linked
by the relationship <code class="reqn">\beta_i \ne 0</code> if <code class="reqn">\gamma_i =
    1</code> and <code class="reqn">\beta_i = 0</code> if <code class="reqn">\gamma_i =
    0</code>.  The prior is
</p>
<p style="text-align: center;"><code class="reqn">\beta | \gamma \sim N(b, V)</code>
</p>

<p style="text-align: center;"><code class="reqn">\gamma \sim B(\pi)</code>
</p>

<p>where <code class="reqn">\pi</code> is the vector of
<code>prior.inclusion.probabilities</code>, and <code class="reqn">b</code> is the
<code>optional.coefficient.estimate</code>.  Conditional on
<code class="reqn">\gamma</code>, the prior information matrix is
</p>
<p style="text-align: center;"><code class="reqn">V^{-1} = \kappa ((1 - \alpha) x^Twx / n + \alpha diag(x^Twx / n))</code>
</p>

<p>The matrix <code class="reqn">x^Twx</code> is, for suitable choice of the weight vector
<code class="reqn">w</code>, the total Fisher information available in the data.
Dividing by <code class="reqn">n</code> gives the average Fisher information in a single
observation, multiplying by <code class="reqn">\kappa</code> then results in
<code class="reqn">\kappa</code> units of &quot;average&quot; information.  This matrix is
averaged with its diagonal to ensure positive definiteness.
</p>
<p>In the formula above, <code class="reqn">\kappa</code> is
<code>prior.information.weight</code>, <code class="reqn">\alpha</code> is
<code>diagonal.shrinkage</code>, and <code class="reqn">w</code> is a diagonal matrix with all
elements set to <code>prior.success.probability * (1 -
  prior.success.probability)</code>.  The vector <code class="reqn">b</code> and the matrix
<code class="reqn">V^{-1}</code> are both implicitly subscripted by <code class="reqn">\gamma</code>,
meaning that elements, rows, or columsn corresponding to gamma = 0
should be omitted.
</p>
<p>The &quot;Direct&quot; version is intended for situations where the predictors are
unavailable, or if the user wants more control over the prior precision
matrix.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>SpikeSlabGlmPrior</code>, which is a list
with data elements encoding the selected prior values.
</p>
<p>This object is intended for use as a base class for
<code><a href="#topic+LogitZellnerPrior">LogitZellnerPrior</a></code> and <code><a href="#topic+PoissonZellnerPrior">PoissonZellnerPrior</a></code>.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Hugh Chipman, Edward I. George, Robert E. McCulloch, M. Clyde, Dean
P. Foster, Robert A. Stine (2001),
&quot;The Practical Implementation of Bayesian Model Selection&quot;
<em>Lecture Notes-Monograph Series</em>, Vol. 38, pp. 65-134.
Institute of Mathematical Statistics.
</p>

<hr>
<h2 id='spike.slab.prior'>
Create a spike and slab prior for use with lm.spike.
</h2><span id='topic+SpikeSlabPrior'></span><span id='topic+SpikeSlabPriorDirect'></span><span id='topic+ConditionalZellnerPrior'></span>

<h3>Description</h3>

<p>Creates a spike and slab prior for use with lm.spike.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpikeSlabPrior(x,
               y = NULL,
               expected.r2 = .5,
               prior.df = .01,
               expected.model.size = 1,
               prior.information.weight = .01,
               diagonal.shrinkage = .5,
               optional.coefficient.estimate = NULL,
               max.flips = -1,
               mean.y = mean(y, na.rm = TRUE),
               sdy = sd(as.numeric(y), na.rm = TRUE),
               prior.inclusion.probabilities = NULL,
               sigma.upper.limit = Inf)

SpikeSlabPriorDirect(coefficient.mean,
                     coefficient.precision,
                     prior.inclusion.probabilities,
                     prior.df,
                     sigma.guess,
                     max.flips = -1,
                     sigma.upper.limit = Inf)


ConditionalZellnerPrior(xdim, 
                        optional.coefficient.estimate = NULL,
                        expected.model.size = 1,
                        prior.information.weight = .01,
                        diagonal.shrinkage = .5,
                        max.flips = -1,
                        prior.inclusion.probabilities = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spike.slab.prior_+3A_x">x</code></td>
<td>

<p>The design matrix for the regression problem.  Missing data is not allowed.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_y">y</code></td>
<td>
<p> The vector of responses for the regression.  Missing data is
not allowed.  If <code>y</code> is not available, you can pass <code>y =
      NULL</code>, and specify <code>mean.y</code> and <code>sdy</code> instead.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_expected.r2">expected.r2</code></td>
<td>

<p>The expected R-square for the regression.  The spike and slab prior
requires an inverse gamma prior on the residual variance of the
regression.  The prior can be parameterized in terms of a guess at
the residual variance, and a &quot;degrees of freedom&quot; representing the
number of observations that the guess should weigh.  The guess at
sigma^2 is set to <code> (1-expected.r2) * var(y) </code>.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_prior.df">prior.df</code></td>
<td>

<p>A positive scalar representing the prior 'degrees of freedom' for
estimating the residual variance.  This can be thought of as the
amount of weight (expressed as an observation count) given to the
<code>expected.r2</code> argument.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_prior.information.weight">prior.information.weight</code></td>
<td>

<p>A positive scalar.  Number of observations worth of weight that
should be given to the prior estimate of beta.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_diagonal.shrinkage">diagonal.shrinkage</code></td>
<td>

<p>The conditionally Gaussian prior for beta (the &quot;slab&quot;) starts with a
precision matrix equal to the information in a single observation.
However, this matrix might not be full rank.  The matrix can be made
full rank by averaging with its diagonal.  <code>diagonal.shrinkage</code>
is the weight given to the diaonal in this average.  Setting this to
zero gives Zellner's g-prior.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_max.flips">max.flips</code></td>
<td>
<p>The maximum number of variable inclusion indicators
the sampler will attempt to sample each iteration.  If
<code>max.flips &lt;= 0</code> then all indicators will be sampled.</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_mean.y">mean.y</code></td>
<td>
<p>The mean of the response vector, for use in cases when
specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_xdim">xdim</code></td>
<td>
<p>The dimension of the predictor matrix.</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_sdy">sdy</code></td>
<td>
<p>The standard deviation of the response vector, for use in
cases when specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_sigma.upper.limit">sigma.upper.limit</code></td>
<td>
<p>The largest acceptable value for the residual
standard deviation.  A non-positive number is interpreted as
<code>Inf</code>.</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_coefficient.mean">coefficient.mean</code></td>
<td>
<p>The prior mean of the coefficients in the
maximal model (with all variables included).</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_coefficient.precision">coefficient.precision</code></td>
<td>
<p>The prior precision (inverse variance) of
the coefficients in the maximal model (with all variables
included).</p>
</td></tr>
<tr><td><code id="spike.slab.prior_+3A_sigma.guess">sigma.guess</code></td>
<td>
<p>Prior estimate of the residual standard deviation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with with the components necessary to run <code>lm.spike</code>.
</p>
<p><code>SpikeSlabPrior</code> is intended for use in traditional regression
problems, when the matrix of predictors and the vector of responses
are available to the modeler.
</p>
<p><code>ConditionalZellnerPrior</code> is intended for cases where the
predictor variables are potentially unknown, because they depend on
model parameters or latent variables, for example.  For models that
support ConditionalZellnerPrior, the underlying C++ code must know
where to find the relevant predictors on which to condition the prior.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>George and McCulloch (1997), &quot;Approaches to Bayesian Variable
Selection&quot;, <em>Statistica Sinica</em>, <b>7</b>, 339 &ndash; 373.
</p>
<p><a href="https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf">https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- cbind(1, matrix(rnorm(900), ncol = 9))
  beta &lt;- rep(0, 10)
  beta[1] &lt;- 3
  beta[5] &lt;- -4
  beta[8] &lt;- 2
  y &lt;- rnorm(100, x %*% beta)
  ## x has 10 columns, including the intercept
  prior &lt;- SpikeSlabPrior(x, y,
             expected.model.size = 3,  # expect 3 nonzero predictors
             prior.df = .01,           # weaker prior than the default
             prior.information.weight = .01,
             diagonal.shrinkage = 0,   # use Zellner's prior
             optional.coefficient.estimate = rep(0, 10) # shrink to zero
          )
  ## now 'prior' can be fed to 'lm.spike'
  model &lt;- lm.spike(y ~ x - 1, niter = 1000, prior = prior)
</code></pre>

<hr>
<h2 id='spike.slab.prior.base'>Base class for spike and slab priors</h2><span id='topic+SpikeSlabPriorBase'></span>

<h3>Description</h3>

<p>A base class for SpikeSlabPrior and SpikeSlabPriorBase to ensure that
elements common to both classes are handled consistently.  Users
will not normally interact with this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpikeSlabPriorBase(number.of.variables,
                   expected.r2 = .5,
                   prior.df = .01,
                   expected.model.size = 1,
                   optional.coefficient.estimate = NULL,
                   mean.y,
                   sdy,
                   prior.inclusion.probabilities = NULL,
                   sigma.upper.limit = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spike.slab.prior.base_+3A_number.of.variables">number.of.variables</code></td>
<td>
<p>The number of columns in <code>x</code>.</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_expected.r2">expected.r2</code></td>
<td>

<p>The expected R-square for the regression.  The spike and slab prior
requires an inverse gamma prior on the residual variance of the
regression.  The prior can be parameterized in terms of a guess at
the residual variance, and a &quot;degrees of freedom&quot; representing the
number of observations that the guess should weigh.  The guess at
sigma^2 is set to <code> (1-expected.r2) * var(y) </code>.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_prior.df">prior.df</code></td>
<td>

<p>A positive scalar representing the prior 'degrees of freedom' for
estimating the residual variance.  This can be thought of as the
amount of weight (expressed as an observation count) given to the
<code>expected.r2</code> argument.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_expected.model.size">expected.model.size</code></td>
<td>
<p> A positive number less than
<code>ncol(x)</code>, representing a guess at the number of significant
predictor p variables.  Used to compute a default value of
<code>prior.inclusion.probabilities</code> if the latter is <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to <code>mean.y</code>.  </p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_mean.y">mean.y</code></td>
<td>
<p>The mean of the response vector.  Used to create a
default value of <code>optional.coefficient.estimate</code> when the latter
is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_sdy">sdy</code></td>
<td>
<p>The standard deviation of the response vector.  Used along
with <code>expected.r2</code> to create a prior estimate of the residual
variance.</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each coefficient.</p>
</td></tr>
<tr><td><code id="spike.slab.prior.base_+3A_sigma.upper.limit">sigma.upper.limit</code></td>
<td>
<p>The largest acceptable value for the residual
standard deviation.  A non-positive number is interpreted as
<code>Inf</code>.</p>
</td></tr>  </table>


<h3>Value</h3>

<p>Returns an object of class <code>SpikeSlabPriorBase</code>, which is a
list with the following elements.
</p>

<ul>
<li><p> prior.inclusion.probabilities: A vector giving the prior
probability of inclusion for each coefficient.
</p>
</li>
<li><p> mu: A vector giving the prior mean of each coefficient
conditional on inclusion.
</p>
</li>
<li><p> sigma.guess: A prior estimate of the residual standard
deviation.
</p>
</li>
<li><p> prior.df: The number of observations worth of weight to be
given to <code>sigma.guess</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>George and McCulloch (1997), &quot;Approaches to Bayesian Variable
Selection&quot;, <em>Statistica Sinica</em>, <b>7</b>, 339 &ndash; 373.
</p>
<p><a href="https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf">https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf</a>
</p>

<hr>
<h2 id='spliunes'>
Spline Basis Expansions
</h2><span id='topic+BsplineBasis'></span><span id='topic+MsplineBasis'></span><span id='topic+IsplineBasis'></span><span id='topic+knots.SplineBasis'></span><span id='topic+knots'></span>

<h3>Description</h3>

<p>Spline basis expansions of a continuous variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  BsplineBasis(x, knots = NULL, numknots = 3)
  MsplineBasis(x, knots = NULL, numknots = 3)
  IsplineBasis(x, knots = NULL, numknots = 3)

  ## S3 method for class 'SplineBasis'
knots(Fn, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spliunes_+3A_x">x</code></td>
<td>

<p>A numeric vector to be expanded.
</p>
</td></tr>
<tr><td><code id="spliunes_+3A_knots">knots</code></td>
<td>
<p> A numeric vector of knots defining the expansion.  The
smallest and largest elements in <code>knots</code> defines the range of
the expansion.  These knots are (notionally) replicated infinitely
many times.  </p>
</td></tr>
<tr><td><code id="spliunes_+3A_numknots">numknots</code></td>
<td>
<p>If the knot vector is <code>NULL</code> then create a vector
of length <code>numknots</code> that partitions <code>x</code> into
<code>numknots</code> + 1 eqiprobable segments.</p>
</td></tr>
<tr><td><code id="spliunes_+3A_fn">Fn</code></td>
<td>
<p>A spline basis matrix.</p>
</td></tr>
<tr><td><code id="spliunes_+3A_...">...</code></td>
<td>
<p>Unused, but required to match the signature of the
<code>knots</code> generic function in the <code>stats</code> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>B-splines are the basis most commonly used for additive
regression models.
</p>
<p>M-splines are an alternative to B-splines, but are rarely used.
</p>
<p>I-splines are integrated M-splines.  These are monotonic functions,
which is useful in monotonic regression problems.  If all regression
coefficients are positive then the resulting function is
nondecreasing.
</p>


<h3>Value</h3>

<p><code>XsplineBasis</code> returns a matrix formed by the spline basis
expansion of <code>x</code>.
</p>
<p><code>knots(Fn)</code> returns the <code>knots</code> attribute of <code>Fn</code>,
which might be useful in a second call to the basis expansion
function.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>References</h3>

<p>Bsplines are described in 
deBoor (2001), &quot;A Practical Guide to Splines&quot;.  Springer.
</p>
<p>Msplines and Isplines are reviewed by Ramsay (1988), Statistical
Science pp. 425-461.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Plot the B-spline basis for x with knots determined by 3 quantiles.
x &lt;- sort(rnorm(1000))
basis &lt;- BsplineBasis(x, numknots=3)
par(mfrow=c(2,3))
for(i in 1:5) plot(x, basis[, i], type="l")

# Plot the I-spline basis for x with the same knots.
basis &lt;- IsplineBasis(x, numknots=3)
par(mfrow=c(2,3))
for(i in 1:5) plot(x, basis[, i], type="l")

# Bring you own knots...
basis &lt;- BsplineBasis(x, knots = quantile(x, c(.2, .5, .8, .9)))
par(mfrow=c(2,3))
for(i in 1:6) plot(x, basis[, i], type="l")

knots(basis)

</code></pre>

<hr>
<h2 id='student.spike.slab.prior'>
Spike and Slab Prior for Student-T Regression
</h2><span id='topic+StudentSpikeSlabPrior'></span>

<h3>Description</h3>

<p>A Zellner-style spike and slab prior for regression models with
Student-t errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StudentSpikeSlabPrior(predictor.matrix,
    response.vector = NULL,
    expected.r2 = .5,
    prior.df = .01,
    expected.model.size = 1,
    prior.information.weight = .01,
    diagonal.shrinkage = .5,
    optional.coefficient.estimate = NULL,
    max.flips = -1,
    mean.y = mean(response.vector, na.rm = TRUE),
    sdy = sd(as.numeric(response.vector), na.rm = TRUE),
    prior.inclusion.probabilities = NULL,
    sigma.upper.limit = Inf,
    degrees.of.freedom.prior = UniformPrior(.1, 100))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="student.spike.slab.prior_+3A_predictor.matrix">predictor.matrix</code></td>
<td>

<p>The design matrix for the regression problem.  Missing data is not allowed.
</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_response.vector">response.vector</code></td>
<td>
<p> The vector of responses for the regression.
Missing data is not allowed.  If <code>response.vector</code> is not
available, you can pass <code>response.vector = NULL</code>, and specify
<code>mean.y</code> and <code>sdy</code> instead.  </p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_expected.r2">expected.r2</code></td>
<td>

<p>The expected R-square for the regression.  The spike and slab prior
requires an inverse gamma prior on the residual variance of the
regression.  The prior can be parameterized in terms of a guess at
the residual variance, and a &quot;degrees of freedom&quot; representing the
number of observations that the guess should weigh.  The guess at
sigma^2 is set to <code> (1-expected.r2) * var(y) </code>.
</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_prior.df">prior.df</code></td>
<td>

<p>A positive scalar representing the prior 'degrees of freedom' for
estimating the residual variance.  This can be thought of as the
amount of weight (expressed as an observation count) given to the
<code>expected.r2</code> argument.
</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_expected.model.size">expected.model.size</code></td>
<td>

<p>A positive number less than <code>ncol(x)</code>, representing a guess at
the number of significant predictor variables.  Used to obtain the
'spike' portion of the spike and slab prior.
</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_prior.information.weight">prior.information.weight</code></td>
<td>

<p>A positive scalar.  Number of observations worth of weight that
should be given to the prior estimate of beta.
</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_diagonal.shrinkage">diagonal.shrinkage</code></td>
<td>

<p>The conditionally Gaussian prior for beta (the &quot;slab&quot;) starts with a
precision matrix equal to the information in a single observation.
However, this matrix might not be full rank.  The matrix can be made
full rank by averaging with its diagonal.  <code>diagonal.shrinkage</code>
is the weight given to the diaonal in this average.  Setting this to
zero gives Zellner's g-prior.
</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_optional.coefficient.estimate">optional.coefficient.estimate</code></td>
<td>
<p> If desired, an estimate of the
regression coefficients can be supplied.  In most cases this will be
a difficult parameter to specify.  If omitted then a prior mean of
zero will be used for all coordinates except the intercept, which
will be set to mean(y).  </p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_max.flips">max.flips</code></td>
<td>
<p>The maximum number of variable inclusion indicators
the sampler will attempt to sample each iteration.  If
<code>max.flips &lt;= 0</code> then all indicators will be sampled.</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_mean.y">mean.y</code></td>
<td>
<p>The mean of the response vector, for use in cases when
specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_sdy">sdy</code></td>
<td>
<p>The standard deviation of the response vector, for use in
cases when specifying the response vector is undesirable.</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_prior.inclusion.probabilities">prior.inclusion.probabilities</code></td>
<td>
<p>A vector giving the prior
probability of inclusion for each variable.</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_sigma.upper.limit">sigma.upper.limit</code></td>
<td>
<p>The largest acceptable value for the residual
standard deviation.  A non-positive number is interpreted as
<code>Inf</code>.</p>
</td></tr>
<tr><td><code id="student.spike.slab.prior_+3A_degrees.of.freedom.prior">degrees.of.freedom.prior</code></td>
<td>
<p>An object of class
<code><a href="Boom.html#topic+DoubleModel">DoubleModel</a></code> representing the prior distribution for the
Student T tail thickness (or &quot;degrees of freedom&quot;) parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> A <code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code> with
<code>degrees.of.freedom.prior</code> appended.  </p>


<h3>Author(s)</h3>

<p> Steven L. Scott
</p>


<h3>References</h3>

<p>George and McCulloch (1997), &quot;Approaches to Bayesian Variable
Selection&quot;, <em>Statistica Sinica</em>, <b>7</b>, 339 &ndash; 373.
</p>
<p><a href="https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf">https://www3.stat.sinica.edu.tw/statistica/oldpdf/A7n26.pdf</a>
</p>

<hr>
<h2 id='suggest.burn'>
Suggest Burn-in
</h2><span id='topic+SuggestBurn'></span>

<h3>Description</h3>

<p>Suggest a burn-in period for a Bayesian neural network model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SuggestBurn(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suggest.burn_+3A_model">model</code></td>
<td>
<p>An object inheriting from class <code>BayesNnet</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="Boom.html#topic+SuggestBurnLogLikelihood">SuggestBurnLogLikelihood</a></code> for details of the on how
the burn-in period is suggested.  In this case the negative the
residual standard deviation is used as a proxy for log likelihood.
</p>


<h3>Value</h3>

<p>A non-negative integer less than the number of MCMC draws.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="Boom.html#topic+SuggestBurnLogLikelihood">SuggestBurnLogLikelihood</a></code>
</p>

<hr>
<h2 id='SummarizeSpikeSlabCoefficients'>
Numerical summaries of coefficients from a spike and slab regression.
</h2><span id='topic+SummarizeSpikeSlabCoefficients'></span>

<h3>Description</h3>

<p>Produces a summary of the marginal distribution of model coefficients
from a spike and slab regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> SummarizeSpikeSlabCoefficients(beta, burn = 0, order = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SummarizeSpikeSlabCoefficients_+3A_beta">beta</code></td>
<td>
<p> A matrix containing MCMC draws of regression
coefficients.  Each row is an MCMC draw.  Each column is a
coefficient.
</p>
</td></tr>
<tr><td><code id="SummarizeSpikeSlabCoefficients_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the ojbect to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="SummarizeSpikeSlabCoefficients_+3A_order">order</code></td>
<td>
<p> Logical.  If <code>TRUE</code> then the coefficients are
presented in order of their posterior inclusion probabilities.
Otherwise the order of the coefficients is the same as in
<code>object</code>.  </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A five-column matrix with rows representing model coefficients.  The
first two columns are the posterior mean and standard deviation of each
coefficient, including the point mass at zero.  The next two columns
are the posterior mean and standard deviations conditional on the
coefficient being nonzero.  The last column is the probability of a
nonzero coefficient.
</p>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+summary.lm.spike">summary.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3
  niter &lt;- 1000
  sigma &lt;- 2

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, x %*% beta, sigma)
  x &lt;- x[,-1]
  model &lt;- lm.spike(y ~ x, niter=niter)
  plot(model)
  plot.ts(model$beta)
  hist(model$sigma)  ## should be near 8
  summary(model)
  SummarizeSpikeSlabCoefficients(model$beta, burn = 100)
</code></pre>

<hr>
<h2 id='summary.lm.spike'>
Numerical summaries of the results from a spike and slab regression.
</h2><span id='topic+summary.lm.spike'></span>

<h3>Description</h3>

<p>Produces a summary of the marginal distribution of model coefficients
from a spike and slab regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm.spike'
summary(object, burn = 0, order = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.lm.spike_+3A_object">object</code></td>
<td>

<p>An object of class <code>lm.spike</code>.
</p>
</td></tr>
<tr><td><code id="summary.lm.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the ojbect to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="summary.lm.spike_+3A_order">order</code></td>
<td>
<p> Logical.  If <code>TRUE</code> then the coefficients are
presented in order of their posterior inclusion probabilities.
Otherwise the order of the coefficients is the same as in
<code>object</code>.  </p>
</td></tr>
<tr><td><code id="summary.lm.spike_+3A_...">...</code></td>
<td>

<p>Unused.  Present for compatibility with generic summary().
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the following elements:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p> A five-column matrix with rows representing model
coefficients.  The first two columns are the posterior mean and
standard deviation of each coefficient, including the point mass at
zero.  The next two columns are the posterior mean and standard
deviations conditional on the coefficient being nonzero.  The last
column is the probability of a nonzero coefficient.</p>
</td></tr>
<tr><td><code>residual.sd</code></td>
<td>
<p>A summary of the posterior distribution of the
residual standard deviation parameter.</p>
</td></tr>
<tr><td><code>rsquare</code></td>
<td>
<p>A summary of the posterior distribution of the R^2
statistic:  1 - residual.sd^2 / var(y)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lm.spike">lm.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
<code><a href="#topic+plot.lm.spike">plot.lm.spike</a></code>
<code><a href="#topic+predict.lm.spike">predict.lm.spike</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3
  niter &lt;- 1000
  sigma &lt;- 2

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  y &lt;- rnorm(n, x %*% beta, sigma)
  x &lt;- x[,-1]
  model &lt;- lm.spike(y ~ x, niter=niter)
  plot(model)
  plot.ts(model$beta)
  hist(model$sigma)  ## should be near 8
  summary(model)
</code></pre>

<hr>
<h2 id='summary.logit.spike'>
Numerical summaries of the results from a spike and slab logistic regression.
</h2><span id='topic+summary.logit.spike'></span><span id='topic+summary.probit.spike'></span>

<h3>Description</h3>

<p>Produces a summary of the marginal distribution of model coefficients
from a spike and slab logistic regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logit.spike'
summary(object,
        burn = 0,
        order = TRUE,
        cutpoint.scale = c("probability", "logit"),
        cutpoint.basis = c("sample.size", "equal.range"),
        number.of.buckets = 10,
        coefficients = TRUE,
        ...)

## S3 method for class 'probit.spike'
summary(object,
        burn = 0,
        order = TRUE,
        cutpoint.scale = c("probability", "probit"),
        cutpoint.basis = c("sample.size", "equal.range"),
        number.of.buckets = 10,
        coefficients = TRUE,
        ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.logit.spike_+3A_object">object</code></td>
<td>

<p>An object of class <code>logit.spike</code> or <code>probit.spike</code>.
</p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_burn">burn</code></td>
<td>

<p>The number of MCMC iterations in the ojbect to be discarded as
burn-in.
</p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_order">order</code></td>
<td>
<p> Logical.  If <code>TRUE</code> then the coefficients are
presented in order of their posterior inclusion probabilities.
Otherwise the order of the coefficients is the same as in
<code>object</code>.  </p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_cutpoint.scale">cutpoint.scale</code></td>
<td>
<p>The scale that should be used to determine the
buckets for the comparison of predicted and actual probabilities.</p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_cutpoint.basis">cutpoint.basis</code></td>
<td>
<p>How should the buckets be determined in the
comparison of predicted to actual probabilities?  If
&quot;sample.sample&quot;, then each bucket contains the same fraction of
data.  If &quot;equal.range&quot; then the buckets are formed by parititioning
the range of the predicted probabilities, and each bucket occupies
the same amount of space on the real line.</p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_number.of.buckets">number.of.buckets</code></td>
<td>
<p>The number of buckets to use in the
comparison of predicted to actual probabilities.</p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_coefficients">coefficients</code></td>
<td>
<p>Logical value indicating whether the coefficient
summary should be included in the output.  It can be useful to
suppress the coefficients if there are many of them.</p>
</td></tr>
<tr><td><code id="summary.logit.spike_+3A_...">...</code></td>
<td>

<p>Unused.  Present for compatibility with generic summary().
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with the following elements
</p>

<ul>
<li><p> coefficients: A five-column matrix summarizing the model
coefficients, produced by
<code><a href="#topic+SummarizeSpikeSlabCoefficients">SummarizeSpikeSlabCoefficients</a></code>.
</p>
</li>
<li><p> null.log.likelihood: The log likelihood of the null binomial
model evaluated at the MLE.
</p>
</li>
<li><p> mean.log.likelihood: The average value of log likelihood
visited by the sampler.
</p>
</li>
<li><p> max.log.likelihood: The largest log likelihood value visited
by the sampler.
</p>
</li>
<li><p> deviance.r2: The deviance R-square obtained by taking
<code>(null.likelihood - mean.log.likelihood) /
        null.log.likelihood</code>
</p>
</li>
<li><p> deviance.r2.distribution: The value of the deviance R-square
statistic at each point visited by the MCMC chain.  This is not
printed by the print method.
</p>
</li>
<li><p> predicted.vs.actual: A table obtained by paritioning the data
into buckets, and comparing the aveage predicted probability with
the empirical success rate in each bucket.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Steven L. Scott
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logit.spike">logit.spike</a></code>
<code><a href="#topic+probit.spike">probit.spike</a></code>
<code><a href="#topic+SpikeSlabPrior">SpikeSlabPrior</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  n &lt;- 100
  p &lt;- 10
  ngood &lt;- 3
  niter &lt;- 1000

  x &lt;- cbind(1, matrix(rnorm(n * (p-1)), nrow=n))
  beta &lt;- c(rnorm(ngood), rep(0, p - ngood))
  prob &lt;- plogis(x %*% beta)
  y &lt;- runif(n) &lt; prob
  x &lt;- x[,-1]
  model &lt;- logit.spike(y ~ x, niter=niter)
  summary(model)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
