<!DOCTYPE html><html><head><title>Help for package mixtools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mixtools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aug.x'><p>Augmented Predictor Function</p></a></li>
<li><a href='#boot.comp'><p>Performs Parametric Bootstrap for Sequentially Testing</p>
the Number of Components in Various Mixture Models</a></li>
<li><a href='#boot.se'><p>Performs Parametric Bootstrap for Standard Error</p>
Approximation</a></li>
<li><a href='#CO2data'><p>GNP and CO2 Data Set</p></a></li>
<li><a href='#compCDF'><p>Plot the Component CDF</p></a></li>
<li><a href='#ddirichlet'><p>Density Function for the Dirichlet Distribution</p></a></li>
<li><a href='#density.npEM'><p>Normal kernel density estimate for nonparametric EM output</p></a></li>
<li><a href='#density.spEM'><p>Normal kernel density estimate for semiparametric EM output</p></a></li>
<li><a href='#depth'><p>Elliptical and Spherical Depth</p></a></li>
<li><a href='#dmvnorm'><p>The Multivariate Normal Density</p></a></li>
<li><a href='#ellipse'><p>Draw Two-Dimensional Ellipse Based on Mean and Covariance</p></a></li>
<li><a href='#expRMM_EM'><p>EM algorithm for Reliability Mixture Models (RMM) with right Censoring</p></a></li>
<li><a href='#flaremixEM'><p>EM Algorithm for Mixtures of Regressions with Flare</p></a></li>
<li><a href='#gammamixEM'><p>EM Algorithm for Mixtures of Gamma Distributions</p></a></li>
<li><a href='#Habituationdata'><p>Infant habituation data</p></a></li>
<li><a href='#hmeEM'><p>EM Algorithm for Mixtures-of-Experts</p></a></li>
<li><a href='#ise.npEM'><p>Integrated Squared Error for a selected density from npEM output</p></a></li>
<li><a href='#lambda'><p>Local Estimation for Lambda in Mixtures of Regressions</p></a></li>
<li><a href='#lambda.pert'><p>Perturbation of Mixing Proportions</p></a></li>
<li><a href='#ldmult'><p>Log-Density for Multinomial Distribution</p></a></li>
<li><a href='#logisregmixEM'><p>EM Algorithm for Mixtures of Logistic Regressions</p></a></li>
<li><a href='#makemultdata'><p>Produce Cutpoint Multinomial Data</p></a></li>
<li><a href='#matsqrt'><p>Calculates the Square Root of a Diagonalizable Matrix</p></a></li>
<li><a href='#mixtools initializations'><p>Initializations for Various EM Algorithms in 'mixtools'</p></a></li>
<li><a href='#mixtools-internal'><p>Internal 'mixtools' Functions</p></a></li>
<li><a href='#mixturegram'><p>Mixturegrams</p></a></li>
<li><a href='#multmixEM'><p>EM Algorithm for Mixtures of Multinomials</p></a></li>
<li><a href='#multmixmodel.sel'><p>Model Selection Mixtures of Multinomials</p></a></li>
<li><a href='#mvnormalmixEM'><p>EM Algorithm for Mixtures of Multivariate Normals</p></a></li>
<li><a href='#mvnpEM'><p>EM-like Algorithm for Nonparametric Mixture Models</p>
with Conditionally Independent Multivariate Component Densities</a></li>
<li><a href='#NOdata'><p>Ethanol Fuel Data Set</p></a></li>
<li><a href='#normalmixEM'><p>EM Algorithm for Mixtures of Univariate Normals</p></a></li>
<li><a href='#normalmixEM2comp'><p>Fast EM Algorithm for 2-Component Mixtures of Univariate Normals</p></a></li>
<li><a href='#normalmixMMlc'><p>EC-MM Algorithm for Mixtures of Univariate Normals</p>
with linear constraints</a></li>
<li><a href='#npEM'><p>Nonparametric EM-like Algorithm for Mixtures of Independent Repeated Measurements</p></a></li>
<li><a href='#npMSL'><p>Nonparametric EM-like Algorithm for Mixtures of Independent Repeated Measurements - Maximum Smoothed Likelihood version</p></a></li>
<li><a href='#parse.constraints'><p>Constraint Function</p></a></li>
<li><a href='#perm'><p>Permutation Function</p></a></li>
<li><a href='#plot.mixEM'><p>Various Plots Pertaining to Mixture Models</p></a></li>
<li><a href='#plot.mixMCMC'><p>Various Plots Pertaining to Mixture Model Output Using MCMC Methods</p></a></li>
<li><a href='#plot.mvnpEM'><p>Plots of Marginal Density Estimates from the mvnpEM Algorithm Output</p></a></li>
<li><a href='#plot.npEM'><p>Plot Nonparametric or Semiparametric EM Output</p></a></li>
<li><a href='#plot.spEMN01'><p>Plot mixture pdf for the semiparametric mixture model output by spEMsymlocN01</p></a></li>
<li><a href='#plotexpRMM'><p>Plot sequences from the EM algorithm for censored mixture of exponentials</p></a></li>
<li><a href='#plotFDR'><p>Plot False Discovery Rate (FDR) estimates from output by EM-like strategies</p></a></li>
<li><a href='#plotly_compCDF'><p>Plot the Component CDF using <code>plotly</code></p></a></li>
<li><a href='#plotly_ellipse'><p>Draw Two-Dimensional Ellipse Based on Mean and Covariance using <code>plotly</code></p></a></li>
<li><a href='#plotly_expRMM'><p>Plot sequences from the EM algorithm for censored mixture of exponentials using <code>plotly</code></p></a></li>
<li><a href='#plotly_FDR'><p>Plot False Discovery Rate (FDR) estimates from output by EM-like strategies using <code>plotly</code></p></a></li>
<li><a href='#plotly_ise.npEM'><p>Visualization of Integrated Squared Error for a selected density from npEM output using <code>plotly</code></p></a></li>
<li><a href='#plotly_mixEM'><p>Visualization of output of <code>mixEM</code> function using <code>plotly</code></p></a></li>
<li><a href='#plotly_mixMCMC'><p>Various Plots Pertaining to Mixture Model Output Using MCMC Methods using <code>plotly</code></p></a></li>
<li><a href='#plotly_mixturegram'><p>Mixturegrams</p></a></li>
<li><a href='#plotly_npEM'><p>Plot Nonparametric or Semiparametric EM Output</p></a></li>
<li><a href='#plotly_post.beta'><p>Visualization of Posterior Regression Coefficients in Mixtures of Random Effects Regressions using <code>plotly</code></p></a></li>
<li><a href='#plotly_seq.npEM'><p>Plotting sequences of estimates from non- or semiparametric EM-like Algorithm using <code>plotly</code></p></a></li>
<li><a href='#plotly_spEMN01'><p>Plot mixture pdf for the semiparametric mixture model output by <code>spEMsymlocN01</code> using <code>plotly</code>.</p></a></li>
<li><a href='#plotly_spRMM'><p>Plot output from Stochastic EM algorithm for semiparametric scaled mixture of censored data using <code>plotly</code>.</p></a></li>
<li><a href='#plotly_weibullRMM'><p>Plot sequences from the Stochastic EM algorithm for mixture of Weibull using <code>plotly</code></p></a></li>
<li><a href='#plotseq.npEM'><p>Plotting sequences of estimates from non- or semiparametric EM-like Algorithm</p></a></li>
<li><a href='#plotspRMM'><p>Plot output from Stochastic EM algorithm for semiparametric scaled mixture of censored data</p></a></li>
<li><a href='#plotweibullRMM'><p>Plot sequences from the Stochastic EM algorithm for mixture of Weibull</p></a></li>
<li><a href='#poisregmixEM'><p>EM Algorithm for Mixtures of Poisson Regressions</p></a></li>
<li><a href='#post.beta'><p>Summary of Posterior Regression Coefficients in Mixtures of Random Effects Regressions</p></a></li>
<li><a href='#print.mvnpEM'><p>Printing of Results from the mvnpEM Algorithm Output</p></a></li>
<li><a href='#print.npEM'><p>Printing non- and semi-parametric multivariate mixture model fits</p></a></li>
<li><a href='#RanEffdata'><p>Simulated Data from 2-Component Mixture of Regressions with Random Effects</p></a></li>
<li><a href='#regcr'><p>Add a Confidence Region or Bayesian Credible Region for Regression Lines to a Scatterplot</p></a></li>
<li><a href='#regmixEM'><p>EM Algorithm for Mixtures of Regressions</p></a></li>
<li><a href='#regmixEM.lambda'><p>EM Algorithm for Mixtures of Regressions with Local Lambda Estimates</p></a></li>
<li><a href='#regmixEM.loc'><p>Iterative Algorithm Using EM Algorithm for Mixtures of Regressions with</p>
Local Lambda Estimates</a></li>
<li><a href='#regmixEM.mixed'><p>EM Algorithm for Mixtures of Regressions with Random Effects</p></a></li>
<li><a href='#regmixMH'><p>Metropolis-Hastings Algorithm for Mixtures of Regressions</p></a></li>
<li><a href='#regmixmodel.sel'><p>Model Selection in Mixtures of Regressions</p></a></li>
<li><a href='#repnormmixEM'><p>EM Algorithm for Mixtures of Normals with Repeated Measurements</p></a></li>
<li><a href='#repnormmixmodel.sel'><p>Model Selection in Mixtures of Normals with Repeated Measures</p></a></li>
<li><a href='#rexpmix'><p>Simulate from Mixtures of Exponentials</p></a></li>
<li><a href='#rmvnorm'><p>Simulate from a Multivariate Normal Distribution</p></a></li>
<li><a href='#rmvnormmix'><p>Simulate from Multivariate (repeated measures) Mixtures of Normals</p></a></li>
<li><a href='#rnormmix'><p>Simulate from Mixtures of Normals</p></a></li>
<li><a href='#RodFramedata'><p>Rod and Frame Task Data Set</p></a></li>
<li><a href='#RTdata'><p>Reaction Time (RT) Data Set</p></a></li>
<li><a href='#RTdata2'><p>Reaction Time (RT) Data Set (No. 2)</p></a></li>
<li><a href='#rweibullmix'><p>Simulate from Mixtures of Weibull distributions</p></a></li>
<li><a href='#segregmixEM'><p>ECM Algorithm for Mixtures of Regressions with Changepoints</p></a></li>
<li><a href='#spEM'><p>Semiparametric EM-like Algorithm for Mixtures of Independent Repeated Measurements</p></a></li>
<li><a href='#spEMsymloc'><p>Semiparametric EM-like Algorithm for univariate symmetric location mixture</p></a></li>
<li><a href='#spEMsymlocN01'><p>semiparametric EM-like algorithm for univariate mixture in False Discovery Rate (FDR) estimation</p></a></li>
<li><a href='#spregmix'><p>EM-like Algorithm for Semiparametric Mixtures of Regressions</p></a></li>
<li><a href='#spRMM_SEM'><p>Stochastic EM algorithm for semiparametric scaled mixture of censored data</p></a></li>
<li><a href='#summary.mixEM'><p>Summarizing EM mixture model fits</p></a></li>
<li><a href='#summary.mvnpEM'><p>Summarizing Fits for Nonparametric Mixture Models</p>
with Conditionally Independent Multivariate Component Densities</a></li>
<li><a href='#summary.npEM'><p>Summarizing non- and semi-parametric multivariate mixture model fits</p></a></li>
<li><a href='#summary.spRMM'><p>Summarizing fits from Stochastic EM algorithm for semiparametric scaled mixture of censored data</p></a></li>
<li><a href='#tauequivnormalmixEM'><p>Special EM Algorithm for three-component tau equivalence model</p></a></li>
<li><a href='#test.equality'><p>Performs Chi-Square Tests for Scale and Location Mixtures</p></a></li>
<li><a href='#test.equality.mixed'><p>Performs Chi-Square Test for Mixed Effects Mixtures</p></a></li>
<li><a href='#tonedata'><p>Tone perception data</p></a></li>
<li><a href='#try.flare'><p>Mixtures of Regressions with Flare MM Algorithm</p></a></li>
<li><a href='#Waterdata'><p>Water-Level Task Data Set</p></a></li>
<li><a href='#weibullRMM_SEM'><p>St-EM algorithm for Reliability Mixture Models (RMM) of Weibull with right Censoring</p></a></li>
<li><a href='#wkde'><p>Weighted Univariate (Normal) Kernel Density Estimate</p></a></li>
<li><a href='#wquantile'><p>Weighted quantiles</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.0.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-12-04</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Analyzing Finite Mixture Models</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>kernlab, MASS, plotly, scales, segmented, stats, survival</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/dsy109/mixtools">https://github.com/dsy109/mixtools</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Analyzes finite mixture models for various parametric and semiparametric settings.  This includes mixtures of parametric distributions (normal, multivariate normal, multinomial, gamma), various Reliability Mixture Models (RMMs), mixtures-of-regressions settings (linear regression, logistic regression, Poisson regression, linear regression with changepoints, predictor-dependent mixing proportions, random effects regressions, hierarchical mixtures-of-experts), and tools for selecting the number of components (bootstrapping the likelihood ratio test statistic, mixturegrams, and model selection criteria).  Bayesian estimation of mixtures-of-linear-regressions models is available as well as a novel data depth method for obtaining credible bands.  This package is based upon work supported by the National Science Foundation under Grant No. SES-0518772 and the Chan Zuckerberg Initiative: Essential Open Source Software for Science (Grant No. 2020-255193).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-05 06:17:17 UTC; derekyoung</td>
</tr>
<tr>
<td>Author:</td>
<td>Derek Young <a href="https://orcid.org/0000-0002-3048-3803"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Tatiana Benaglia [aut],
  Didier Chauveau [aut],
  David Hunter [aut],
  Kedai Cheng [aut],
  Ryan Elmore [ctb],
  Thomas Hettmansperger [ctb],
  Hoben Thomas [ctb],
  Fengjuan Xuan [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Derek Young &lt;derek.young@uky.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-12-05 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aug.x'>Augmented Predictor Function</h2><span id='topic+aug.x'></span>

<h3>Description</h3>

<p>Creates the augmented predictor matrix based on an appropriately defined changepoint structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aug.x(X, cp.locs, cp, delta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aug.x_+3A_x">X</code></td>
<td>
<p>The raw matrix of predictor values.  Note that the raw data matrix should not include a columns of 1's.</p>
</td></tr>
<tr><td><code id="aug.x_+3A_cp.locs">cp.locs</code></td>
<td>
<p>The locations of the changepoints.  The length of this vector must be equal to the sum of the entries of <code>cp</code>.</p>
</td></tr>
<tr><td><code id="aug.x_+3A_cp">cp</code></td>
<td>
<p>A vector having length equal to the number of predictors.</p>
</td></tr>
<tr><td><code id="aug.x_+3A_delta">delta</code></td>
<td>
<p>A vector to accommodate discontinuities.  If NULL, then no discontinuities are included.  Otherwise, this must be a vector of the same length as <code>cp.locs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>segregmixEM</code> and the associated internal functions.
</p>


<h3>Value</h3>

<p><code>aug.x</code> returns a matrix of the original matrix <code>X</code> with the predictor adjusted for changepoints and (optional) discontinuities.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+segregmixEM">segregmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(1:30, nrow = 10)
cp &lt;- c(1, 3, 0)
cp.locs &lt;- c(3, 12, 14, 16)
d &lt;- rep(0, 4)
x1 &lt;- aug.x(x, cp.locs, cp, delta = NULL)
x1
x2 &lt;- aug.x(x, cp.locs, cp, delta = d)
x2
</code></pre>

<hr>
<h2 id='boot.comp'>Performs Parametric Bootstrap for Sequentially Testing
the Number of Components in Various Mixture Models</h2><span id='topic+boot.comp'></span>

<h3>Description</h3>

<p>Performs a parametric bootstrap by producing B bootstrap realizations of the likelihood ratio
statistic for testing the null hypothesis of a k-component fit versus the alternative
hypothesis of a (k+1)-component fit to various mixture models. This is performed for up to a
specified number of maximum components, k. A p-value is calculated for each test and once the p-value
is above a specified significance level, the testing terminates.  An optional histogram showing
the distribution of the likelihood ratio statistic along with the observed statistic can also be
produced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.comp(y, x = NULL, N = NULL, max.comp = 2, B = 100,
          sig = 0.05, arbmean = TRUE, arbvar = TRUE,
          mix.type = c("logisregmix", "multmix", "mvnormalmix",
          "normalmix", "poisregmix", "regmix", "regmix.mixed", 
          "repnormmix"), hist = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.comp_+3A_y">y</code></td>
<td>
<p>The raw data for <code>multmix</code>, <code>mvnormalmix</code>, <code>normalmix</code>, and <code>repnormmix</code> and
the response values for <code>logisregmix</code>, <code>poisregmix</code>, and <code>regmix</code>.  See the documentation
concerning their respective EM algorithms for specific structure of the raw data.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_x">x</code></td>
<td>
<p>The predictor values required only for the regression mixtures <code>logisregmix</code>, 
<code>poisregmix</code>, and <code>regmix</code>. A column of 1s for the intercept term must not be included! See the
documentation concerning their respective EM algorithms for specific structure of the predictor values.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_n">N</code></td>
<td>
<p>An n-vector of number of trials for the logistic regression type <code>logisregmix</code>.  
If NULL, then <code>N</code> is an n-vector of 1s for binary logistic regression.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_max.comp">max.comp</code></td>
<td>
<p>The maximum number of components to test for.  The default is 2.  This function will 
perform a test of k-components versus (k+1)-components sequentially until we fail to reject the null hypothesis.
This decision rule is governed by the calculated p-value and <code>sig</code>.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_b">B</code></td>
<td>
<p>The number of bootstrap realizations of the likelihood ratio statistic to produce.  The default is 100,
but ideally, values of 1000 or more would be more acceptable.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_sig">sig</code></td>
<td>
<p>The significance level for which to compare the p-value against when performing the test of k-components
versus (k+1)-components.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_arbmean">arbmean</code></td>
<td>
<p>If FALSE, then a scale mixture analysis can be performed for <code>mvnormalmix</code>, <code>normalmix</code>, <code>regmix</code>,
or <code>repnormmix</code>. The default is TRUE.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_arbvar">arbvar</code></td>
<td>
<p>If FALSE, then a location mixture analysis can be performed for <code>mvnormalmix</code>, <code>normalmix</code>, <code>regmix</code>,
or <code>repnormmix</code>. The default is TRUE.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_mix.type">mix.type</code></td>
<td>
<p>The type of mixture analysis you wish to perform. The data inputted for <code>y</code> and <code>x</code> depend on
which type of mixture is selected.  <code>logisregmix</code> corresponds to a mixture of logistic regressions.  <code>multmix</code> corresponds
to a mixture of multinomials with data determined by the cut-point method.  <code>mvnormalmix</code> corresponds to a mixture of
multivariate normals.  <code>normalmix</code> corresponds to a mixture of univariate normals. <code>poisregmix</code> corresponds to a mixture of
Poisson regressions.  <code>regmix</code> corresponds to a mixture of regressions with normal components.  <code>regmix.mixed</code>
corresponds to a mixture of regressions with random or mixed effects.  <code>repnormmix</code> corresponds to a mixture
of normals with repeated measurements.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_hist">hist</code></td>
<td>
<p>An argument to provide a matrix plot of histograms for the boostrapped likelihood ratio statistic.</p>
</td></tr>
<tr><td><code id="boot.comp_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the various EM algorithms for the mixture of interest.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>boot.comp</code> returns a list with items:
</p>
<table>
<tr><td><code>p.values</code></td>
<td>
<p>The p-values for each test of k-components versus (k+1)-components.</p>
</td></tr>
<tr><td><code>log.lik</code></td>
<td>
<p>The B bootstrap realizations of the likelihood ratio statistic.</p>
</td></tr>
<tr><td><code>obs.log.lik</code></td>
<td>
<p>The observed likelihood ratio statistic for each test which is used in determining
the p-values.</p>
</td></tr>
</table>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logisregmixEM">logisregmixEM</a></code>, <code><a href="#topic+multmixEM">multmixEM</a></code>, <code><a href="#topic+mvnormalmixEM">mvnormalmixEM</a></code>, <code><a href="#topic+normalmixEM">normalmixEM</a></code>,
<code><a href="#topic+poisregmixEM">poisregmixEM</a></code>, <code><a href="#topic+regmixEM">regmixEM</a></code>, <code><a href="#topic+regmixEM.mixed">regmixEM.mixed</a></code>, <code><a href="#topic+repnormmixEM">repnormmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Bootstrapping to test the number of components on the RTdata.

data(RTdata)
set.seed(100)
x &lt;- as.matrix(RTdata[, 1:3])
y &lt;- makemultdata(x, cuts = quantile(x, (1:9)/10))$y
a &lt;- boot.comp(y = y, max.comp = 1, B = 5, mix.type = "multmix", 
               epsilon = 1e-3)
a$p.values

</code></pre>

<hr>
<h2 id='boot.se'>Performs Parametric Bootstrap for Standard Error 
Approximation</h2><span id='topic+boot.se'></span>

<h3>Description</h3>

<p>Performs a parametric bootstrap by producing B bootstrap samples for the parameters in the specified
mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.se(em.fit, B = 100, arbmean = TRUE, arbvar = TRUE, 
        N = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.se_+3A_em.fit">em.fit</code></td>
<td>
<p>An object of class <code>mixEM</code>.  The estimates produced in <code>em.fit</code> will be used as the 
parameters for the distribution from which we generate the bootstrap data.</p>
</td></tr>
<tr><td><code id="boot.se_+3A_b">B</code></td>
<td>
<p>The number of bootstrap samples to produce.  The default is 100,
but ideally, values of 1000 or more would be more acceptable.</p>
</td></tr>
<tr><td><code id="boot.se_+3A_arbmean">arbmean</code></td>
<td>
<p>If FALSE, then a scale mixture analysis can be performed for <code>mvnormalmix</code>, <code>normalmix</code>, <code>regmix</code>,
or <code>repnormmix</code>. The default is TRUE.</p>
</td></tr>
<tr><td><code id="boot.se_+3A_arbvar">arbvar</code></td>
<td>
<p>If FALSE, then a location mixture analysis can be performed for <code>mvnormalmix</code>, <code>normalmix</code>, <code>regmix</code>,
or <code>repnormmix</code>. The default is TRUE.</p>
</td></tr>
<tr><td><code id="boot.se_+3A_n">N</code></td>
<td>
<p>An n-vector of number of trials for the logistic regression type <code>logisregmix</code>.  
If NULL, then <code>N</code> is an n-vector of 1s for binary logistic regression.</p>
</td></tr>
<tr><td><code id="boot.se_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the various EM algorithms for the mixture of interest.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>boot.se</code> returns a list with the bootstrap samples and standard errors for the mixture of interest.
</p>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Bootstrapping standard errors for a regression mixture case.

data(NOdata)
attach(NOdata)
set.seed(100)
em.out &lt;- regmixEM(Equivalence, NO, arbvar = FALSE)
out.bs &lt;- boot.se(em.out, B = 10, arbvar = FALSE)
out.bs

</code></pre>

<hr>
<h2 id='CO2data'>GNP and CO2 Data Set</h2><span id='topic+CO2data'></span>

<h3>Description</h3>

<p>This data set gives the gross national product (GNP) per capita in 1996 for various countries as
well as their estimated carbon dioxide (CO2) emission per capita for the same year. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CO2data)
</code></pre>


<h3>Format</h3>

<p>This data frame consists of 28 countries and the following columns:
</p>

<ul>
<li><p><code>GNP</code>The gross national product per capita in 1996.
</p>
</li>
<li><p><code>CO2</code>The estimated carbon dioxide emission per capita in 1996.
</p>
</li>
<li><p><code>country</code>An abbreviation pertaining to the country measured 
(e.g., &quot;GRC&quot; = Greece and &quot;CH&quot; = Switzerland).
</p>
</li></ul>



<h3>References</h3>

<p>Hurn, M., Justel, A. and Robert, C. P. (2003) Estimating Mixtures of Regressions, <em>Journal 
of Computational and Graphical Statistics</em> <b>12(1)</b>, 55&ndash;79.
</p>

<hr>
<h2 id='compCDF'>Plot the Component CDF</h2><span id='topic+compCDF'></span>

<h3>Description</h3>

<p>Plot the components' CDF via the posterior probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compCDF(data, weights, 
        x=seq(min(data, na.rm=TRUE), max(data, na.rm=TRUE), len=250), 
        comp=1:NCOL(weights), makeplot=TRUE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compCDF_+3A_data">data</code></td>
<td>
<p>A matrix containing the raw data. Rows are subjects and columns
are repeated measurements.</p>
</td></tr>
<tr><td><code id="compCDF_+3A_weights">weights</code></td>
<td>
<p>The weights to compute the empirical CDF; however, most of
time they are the posterior probabilities.</p>
</td></tr>
<tr><td><code id="compCDF_+3A_x">x</code></td>
<td>
<p>The points at which the CDFs are to be evaluated.</p>
</td></tr>
<tr><td><code id="compCDF_+3A_comp">comp</code></td>
<td>
<p>The mixture components for which CDFs are desired.</p>
</td></tr>
<tr><td><code id="compCDF_+3A_makeplot">makeplot</code></td>
<td>
<p>Logical:  Should a plot be produced as a side effect?</p>
</td></tr>
<tr><td><code id="compCDF_+3A_...">...</code></td>
<td>
<p>Additional arguments (other than <code>lty</code> and <code>type</code>, 
which are already used)
to be passed directly to <code>plot</code> and <code>lines</code> functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>makeplot</code> is <code>TRUE</code>, a line plot is produced of the
CDFs evaluated at <code>x</code>.  The plot is not a step function plot; 
the points <code class="reqn">(x, CDF(x))</code> are simply joined by line segments.
</p>


<h3>Value</h3>

<p>A matrix with <code>length(comp)</code> rows and <code>length(x)</code> columns 
in which each row gives the CDF evaluated at each point of <code>x</code>.
</p>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>
<p>Elmore, R. T., Hettmansperger, T. P. and Xuan, F. (2004) The Sign Statistic, One-Way Layouts
and Mixture Models, <em>Statistical Science</em> <b>19(4)</b>, 579&ndash;587.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makemultdata">makemultdata</a></code>, <code><a href="#topic+multmixmodel.sel">multmixmodel.sel</a></code>, <code><a href="#topic+multmixEM">multmixEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The sulfur content of the coal seams in Texas

set.seed(100)

A &lt;- c(1.51, 1.92, 1.08, 2.04, 2.14, 1.76, 1.17)
B &lt;- c(1.69, 0.64, .9, 1.41, 1.01, .84, 1.28, 1.59) 
C &lt;- c(1.56, 1.22, 1.32, 1.39, 1.33, 1.54, 1.04, 2.25, 1.49) 
D &lt;- c(1.3, .75, 1.26, .69, .62, .9, 1.2, .32) 
E &lt;- c(.73, .8, .9, 1.24, .82, .72, .57, 1.18, .54, 1.3)

dis.coal &lt;- makemultdata(A, B, C, D, E, 
                         cuts = median(c(A, B, C, D, E)))
temp &lt;- multmixEM(dis.coal)

## Now plot the components' CDF via the posterior probabilities

compCDF(dis.coal$x, temp$posterior, xlab="Sulfur", ylab="", main="empirical CDFs")
</code></pre>

<hr>
<h2 id='ddirichlet'>Density Function for the Dirichlet Distribution</h2><span id='topic+ddirichlet'></span>

<h3>Description</h3>

<p>Density function for the Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddirichlet(x, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddirichlet_+3A_x">x</code></td>
<td>
<p>A k-dimensional vector of values that sum to 1 for which to calculate the density</p>
</td></tr>
<tr><td><code id="ddirichlet_+3A_alpha">alpha</code></td>
<td>
<p>A k-dimensional vector of the Dirichlet distribution parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is usually not to be called by the user.
</p>

<hr>
<h2 id='density.npEM'>Normal kernel density estimate for nonparametric EM output</h2><span id='topic+density.npEM'></span>

<h3>Description</h3>

<p>Takes an object of class <code>npEM</code> and returns an object of class
<code><a href="stats.html#topic+density">density</a></code> giving the kernel density estimate for the selected
component and, if applicable, the selected block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'npEM'
density(x, u=NULL, component=1, block=1, scale=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="density.npEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>npEM</code> such as the output
of the <code><a href="#topic+npEM">npEM</a></code> or <code><a href="#topic+spEMsymloc">spEMsymloc</a></code> functions.</p>
</td></tr>
<tr><td><code id="density.npEM_+3A_u">u</code></td>
<td>
<p>Vector of points at which the density is to be evaluated</p>
</td></tr>
<tr><td><code id="density.npEM_+3A_component">component</code></td>
<td>
<p>Mixture component number; should be an integer from 1 to the
number of columns of <code>x$posteriors</code>.</p>
</td></tr>
<tr><td><code id="density.npEM_+3A_block">block</code></td>
<td>
<p>Block of repeated measures.  Only applicable in repeated measures
case, for which <code>x$blockid</code> exists; should be an integer from 1 to
<code>max(x$blockid)</code>.</p>
</td></tr>
<tr><td><code id="density.npEM_+3A_scale">scale</code></td>
<td>
<p>Logical:  If TRUE, multiply the density values by the 
corresponding mixing proportions found in <code>x$lambdahat</code></p>
</td></tr>
<tr><td><code id="density.npEM_+3A_...">...</code></td>
<td>
<p>Additional arguments; not used by this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bandwidth is taken to be the same as that used to produce the <code>npEM</code>
object, which is given by <code>x$bandwidth</code>.
</p>


<h3>Value</h3>

<p><code>density.npEM</code> returns a list of type <code>"density"</code>.  See 
<code><a href="stats.html#topic+density">density</a></code> for details.  In particular, the output of 
<code>density.npEM</code> may be used directly by functions such as 
<code><a href="graphics.html#topic+plot">plot</a></code> or <code><a href="graphics.html#topic+lines">lines</a></code>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, <code><a href="#topic+plot.npEM">plot.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Look at histogram of Old Faithful waiting times
data(faithful)
Minutes &lt;- faithful$waiting
hist(Minutes, freq=FALSE)

## Superimpose equal-variance normal mixture fit:
set.seed(100)
nm &lt;- normalmixEM(Minutes, mu=c(50,80), sigma=5, arbvar=FALSE, fast=TRUE)
x &lt;- seq(min(Minutes), max(Minutes), len=200)
for (j in 1:2) 
  lines(x, nm$lambda[j]*dnorm(x, mean=nm$mu[j], sd=nm$sigma), lwd=3, lty=2)
  
## Superimpose several semiparametric fits with different bandwidths:
bw &lt;- c(1, 3, 5)
for (i in 1:3) {
  sp &lt;- spEMsymloc(Minutes, c(50,80), bw=bw[i], eps=1e-3)
  for (j in 1:2) 
    lines(density(sp, component=j, scale=TRUE), col=1+i, lwd=2)    
}
legend("topleft", legend=paste("Bandwidth =",bw), fill=2:4)
</code></pre>

<hr>
<h2 id='density.spEM'>Normal kernel density estimate for semiparametric EM output</h2><span id='topic+density.spEM'></span>

<h3>Description</h3>

<p>Takes an object of class <code>spEM</code> and returns an object of class
<code><a href="stats.html#topic+density">density</a></code> giving the kernel density estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spEM'
density(x, u=NULL, component=1, block=1, scale=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="density.spEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>npEM</code> such as the output
of the <code><a href="#topic+npEM">npEM</a></code> or <code><a href="#topic+spEMsymloc">spEMsymloc</a></code> functions.</p>
</td></tr>
<tr><td><code id="density.spEM_+3A_u">u</code></td>
<td>
<p>Vector of points at which the density is to be evaluated</p>
</td></tr>
<tr><td><code id="density.spEM_+3A_component">component</code></td>
<td>
<p>Mixture component number; should be an integer from 1 to the
number of columns of <code>x$posteriors</code>.</p>
</td></tr>
<tr><td><code id="density.spEM_+3A_block">block</code></td>
<td>
<p>Block of repeated measures.  Only applicable in repeated measures
case, for which <code>x$blockid</code> exists; should be an integer from 1 to
<code>max(x$blockid)</code>.</p>
</td></tr>  
<tr><td><code id="density.spEM_+3A_scale">scale</code></td>
<td>
<p>Logical:  If TRUE, multiply the density values by the 
corresponding mixing proportions found in <code>x$lambdahat</code></p>
</td></tr>
<tr><td><code id="density.spEM_+3A_...">...</code></td>
<td>
<p>Additional arguments; not used by this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bandwidth is taken to be the same as that used to produce the <code>npEM</code>
object, which is given by <code>x$bandwidth</code>.
</p>


<h3>Value</h3>

<p><code>density.spEM</code> returns a list of type <code>"density"</code>.  See 
<code><a href="stats.html#topic+density">density</a></code> for details.  In particular, the output of 
<code>density.spEM</code> may be used directly by functions such as 
<code><a href="graphics.html#topic+plot">plot</a></code> or <code><a href="graphics.html#topic+lines">lines</a></code>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+spEM">spEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, <code><a href="#topic+plot.spEM">plot.spEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(100)
mu &lt;- matrix(c(0, 15), 2, 3)
sigma &lt;- matrix(c(1, 5), 2, 3)
x &lt;- rmvnormmix(300, lambda = c(.4,.6), mu = mu, sigma = sigma)

d &lt;- spEM(x, mu0 = 2, blockid = rep(1,3), constbw = TRUE) 
plot(d, xlim=c(-10, 40), ylim = c(0, .16), xlab = "", breaks = 30, 
     cex.lab=1.5, cex.axis=1.5) # plot.spEM calls density.spEM here
</code></pre>

<hr>
<h2 id='depth'>Elliptical and Spherical Depth</h2><span id='topic+depth'></span>

<h3>Description</h3>

<p>Computation of spherical or elliptical depth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> depth(pts, x, Cx = var(x))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="depth_+3A_pts">pts</code></td>
<td>
<p>A kxd matrix containing the k points that one wants to compute the depth. Each row is a point. </p>
</td></tr>
<tr><td><code id="depth_+3A_x">x</code></td>
<td>
<p>A nxd matrix containing the reference data. Each row is an observation.</p>
</td></tr>
<tr><td><code id="depth_+3A_cx">Cx</code></td>
<td>
<p>A dxd scatter matrix for the data x where the default is var(x). When Cx = I(d), it returns the sphercial depth.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>depth</code> returns a k-vector where each entry is the elliptical depth of a point in <code>pts</code>.
</p>


<h3>Note</h3>

<p><code>depth</code> is used in <code>regcr</code>.</p>


<h3>References</h3>

<p>Elmore, R. T., Hettmansperger, T. P. and Xuan, F. (2000) Spherical Data Depth and a Multivariate Median,
<em>Proceedings of Data Depth: Robust Multivariate Statistical Analysis, Computational Geometry and Applications</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcr">regcr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(100)
  x &lt;- matrix(rnorm(200),nc = 2)
  depth(x[1:3, ], x)
</code></pre>

<hr>
<h2 id='dmvnorm'>The Multivariate Normal Density</h2><span id='topic+dmvnorm'></span><span id='topic+logdmvnorm'></span>

<h3>Description</h3>

<p>Density and log-density for the multivariate normal distribution 
with mean equal to <code>mu</code>
and variance matrix equal to <code>sigma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmvnorm(y, mu=NULL, sigma=NULL)
logdmvnorm(y, mu=NULL, sigma=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dmvnorm_+3A_y">y</code></td>
<td>
<p>Either a <code class="reqn">d</code> - vector or an <code class="reqn">n\times d</code> matrix, where <code class="reqn">d</code>
is the dimension of the normal distribution and <code class="reqn">n</code> is the number of
points at which the density is to be evaluated.</p>
</td></tr>
<tr><td><code id="dmvnorm_+3A_mu">mu</code></td>
<td>
<p><code class="reqn">d</code> - vector:  Mean of the normal distribution (or NULL uses
the origin as default)</p>
</td></tr>
<tr><td><code id="dmvnorm_+3A_sigma">sigma</code></td>
<td>
<p>This <code class="reqn">d\times d</code> matrix is the variance matrix of the normal
distribution (or NULL uses the identity matrix as default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This code is written to be efficient, using the qr-decomposition of the 
covariance matrix (and using it only once, rather than recalculating it
for both the determinant and the inverse of <code>sigma</code>).
</p>


<h3>Value</h3>

<p><code>dmvnorm</code> gives the densities, while
<code>logdmvnorm</code> gives the logarithm of the densities.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+qr">qr</a></code>, <code><a href="base.html#topic+qr.solve">qr.solve</a></code>, <code><a href="stats.html#topic+dnorm">dnorm</a></code>, 
<code><a href="#topic+rmvnorm">rmvnorm</a></code>
</p>

<hr>
<h2 id='ellipse'>Draw Two-Dimensional Ellipse Based on Mean and Covariance</h2><span id='topic+ellipse'></span>

<h3>Description</h3>

<p>Draw a two-dimensional ellipse that traces a bivariate normal density
contour for a given mean vector, covariance matrix, and probability content.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ellipse(mu, sigma, alpha = .05, npoints = 250, newplot = FALSE,
        draw = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ellipse_+3A_mu">mu</code></td>
<td>
<p>A 2-vector giving the mean.</p>
</td></tr>
<tr><td><code id="ellipse_+3A_sigma">sigma</code></td>
<td>
<p>A 2x2 matrix giving the covariance matrix.</p>
</td></tr>
<tr><td><code id="ellipse_+3A_alpha">alpha</code></td>
<td>
<p>Probability to be excluded from the ellipse. The
default value is alpha = .05, which results in a 95% ellipse.</p>
</td></tr>
<tr><td><code id="ellipse_+3A_npoints">npoints</code></td>
<td>
<p>Number of points comprising the border of the ellipse.</p>
</td></tr>
<tr><td><code id="ellipse_+3A_newplot">newplot</code></td>
<td>
<p>If newplot = TRUE and draw = TRUE, plot the ellipse on a new
plot.  If newplot = FALSE and draw = TRUE, add the ellipse to an
existing plot.</p>
</td></tr>
<tr><td><code id="ellipse_+3A_draw">draw</code></td>
<td>
<p>If TRUE, draw the ellipse.</p>
</td></tr>
<tr><td><code id="ellipse_+3A_...">...</code></td>
<td>
<p>Graphical parameters passed to <code>lines</code> or <code>plot</code>
command.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>ellipse</code> returns an <code>npoints</code>x2 matrix of the points forming the
border of the ellipse.
</p>


<h3>References</h3>

<p>Johnson, R. A. and Wichern, D. W. (2002) <em>Applied Multivariate Statistical Analysis, Fifth Edition</em>,
Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcr">regcr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Produce a 95% ellipse with the specified mean and covariance structure. 

mu &lt;- c(1, 3)
sigma &lt;- matrix(c(1, .3, .3, 1.5), 2, 2)

ellipse(mu, sigma, npoints = 200, newplot = TRUE)
 
</code></pre>

<hr>
<h2 id='expRMM_EM'>EM algorithm for Reliability Mixture Models (RMM) with right Censoring</h2><span id='topic+expRMM_EM'></span>

<h3>Description</h3>

<p>Parametric EM algorithm for univariate finite mixture of exponentials 
distributions with randomly right censored data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  expRMM_EM(x, d=NULL, lambda = NULL, rate = NULL, k = 2, 
		    complete = "tdz", epsilon = 1e-08, maxit = 1000, verb = FALSE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expRMM_EM_+3A_x">x</code></td>
<td>
<p>A vector of <code class="reqn">n</code> real positive lifetime (possibly censored) durations.
If <code>d</code> is not <code>NULL</code> then a vector of random censoring times
<code>c</code> occurred,  
so that <code class="reqn">x= min(x,c)</code> and <code class="reqn">d = I(x &lt;= c)</code>.</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_d">d</code></td>
<td>
<p>The vector of censoring indication, where 1 means observed lifetime data, 
and 0 means censored lifetime data.</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.
If <code>NULL</code>, then <code>lambda</code> is set to <code>rep(1/k,k)</code>.</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_rate">rate</code></td>
<td>
<p>Initial value of component exponential rates, 
all set to 1 if  <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_k">k</code></td>
<td>
<p>Number of components of the mixture.</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_complete">complete</code></td>
<td>
<p>Nature of complete data involved within the EM machinery,
can be &quot;tdz&quot; for <code>(t,d,z)</code> (the default), or &quot;xz&quot; for <code>(x,z)</code>
(see  Bordes L. and Chauveau D. (2016) reference below).</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_epsilon">epsilon</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence based on
the change between two consecutive iterations.</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations allowed, convergence
may be declared before <code>maxit</code> iterations (see <code>epsilon</code> above).</p>
</td></tr>
<tr><td><code id="expRMM_EM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>expRMM_EM</code> returns a list of class &quot;mixEM&quot; with the following items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The input data.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The input censoring indicator.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The estimates for the mixing proportions.</p>
</td></tr>
<tr><td><code>rate</code></td>
<td>
<p>The estimates for the component rates.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The log-likelihood value at convergence of the algorithm.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An <code class="reqn">n\times k</code> matrix of posterior probabilities for
observation, after convergence of the algorithm.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>The sequence of log-likelihoods over iterations.</p>
</td></tr>
<tr><td><code>all.lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>all.rate</code></td>
<td>
<p>The sequence of component rates over iterations.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions: 
<code><a href="#topic+plotexpRMM">plotexpRMM</a></code>,
<code><a href="#topic+summary.mixEM">summary.mixEM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data:
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>, 
<code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 300 # sample size
m &lt;- 2   # number of mixture components
lambda &lt;- c(1/3,1-1/3); rate &lt;- c(1,1/10) # mixture parameters
set.seed(1234)
x &lt;- rexpmix(n, lambda, rate) # iid ~ exponential mixture
cs &lt;- runif(n,0,max(x)) # Censoring (uniform) and incomplete data
t &lt;- apply(cbind(x,cs),1,min) # observed or censored data
d &lt;- 1*(x &lt;= cs)              # censoring indicator

###### EM for RMM, exponential lifetimes
l0 &lt;- rep(1/m,m); r0 &lt;- c(1, 0.5) # "arbitrary" initial values
a &lt;- expRMM_EM(t, d, lambda = l0, rate = r0, k = m)
summary(a)                 # EM estimates etc
plotexpRMM(a, lwd=2) # default plot of EM sequences
plot(a, which=2) # or equivalently, S3 method for "mixEM" object
</code></pre>

<hr>
<h2 id='flaremixEM'>EM Algorithm for Mixtures of Regressions with Flare</h2><span id='topic+flaremixEM'></span>

<h3>Description</h3>

<p>Returns output for 2-component mixture of regressions with flaring
using an EM algorithm with one step of Newton-Raphson requiring
an adaptive barrier for maximization of the objective function. A mixture of regressions
with flare occurs when there appears to be a common regression relationship for the data,
but the error terms have a mixture structure of one normal component and one exponential
component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flaremixEM(y, x, lambda = NULL, beta = NULL, sigma = NULL, 
           alpha = NULL, nu = NULL, epsilon = 1e-04, 
           maxit = 10000, verb = FALSE, restart = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flaremixEM_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_x">x</code></td>
<td>
<p>An n-vector of predictor values.  An intercept term will be added by default.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to 1.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a 2x2 matrix where the columns
correspond to the component.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_alpha">alpha</code></td>
<td>
<p>A scalar for the exponential component's rate.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_nu">nu</code></td>
<td>
<p>A vector specifying the barrier constants to use.  The first barrier constant where the algorithm
converges is used.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="flaremixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="flaremixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
<tr><td><code id="flaremixEM_+3A_restart">restart</code></td>
<td>
<p>The number of times to restart the algorithm in case convergence is not attained.
The default is 50.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>flaremixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nx2 matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The final exponential rate.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulation output.

set.seed(100)
j=1
while(j == 1){
    x1 &lt;- runif(30, 0, 10)
    x2 &lt;- runif(20, 10, 20)
    x3 &lt;- runif(30, 20, 30)
    y1 &lt;- 3+4*x1+rnorm(30, sd = 1)
    y2 &lt;- 3+4*x2+rexp(20, rate = .05)
    y3 &lt;- 3+4*x3+rnorm(30, sd = 1)
    x &lt;- c(x1, x2, x3)
    y &lt;- c(y1, y2, y3)
    nu &lt;- (1:30)/2

    out &lt;- try(flaremixEM(y, x, beta = c(3, 4), nu = nu,
               lambda = c(.75, .25), sigma = 1), silent = TRUE)
    if(any(class(out) == "try-error")){
        j &lt;- 1
    } else j &lt;- 2
}

out[4:7]
plot(x, y, pch = 19)
abline(out$beta)



</code></pre>

<hr>
<h2 id='gammamixEM'>EM Algorithm for Mixtures of Gamma Distributions</h2><span id='topic+gammamixEM'></span>

<h3>Description</h3>

<p>Return EM algorithm output for mixtures of gamma distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammamixEM(x, lambda = NULL, alpha = NULL, beta = NULL, k = 2,
           mom.start = TRUE, fix.alpha = FALSE, epsilon = 1e-08, 
           maxit = 1000, maxrestarts = 20, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammamixEM_+3A_x">x</code></td>
<td>
<p>A vector of length n consisting of the data.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  If <code>NULL</code>, 
then <code>lambda</code> is random from a uniform Dirichlet
distribution (i.e., its entries are uniform random and then it is 
normalized to sum to 1).</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_alpha">alpha</code></td>
<td>
<p>Starting value of vector of component shape parameters.  If non-NULL, <code>alpha</code> must be of length <code>k</code> if allowing different component shape parameters, or a single value if <code>fix.alpha = TRUE</code>.  If NULL, then the initial value
is estimated by partitioning the data into <code>k</code> regions (with <code>lambda</code> determining
the proportion of values in each region) and then calculating the method of moments estimates.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_beta">beta</code></td>
<td>
<p>Starting value of vector of component scale parameters.  If non-NULL and a vector,
<code>k</code> is set to <code>length(beta)</code>.  If NULL, then the initial value
is estimated the same method described for <code>alpha</code>.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Initial value ignored unless <code>alpha</code> and <code>beta</code>
are both NULL.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_mom.start">mom.start</code></td>
<td>
<p>Logical to indicate if a method of moments starting value strategy should be implemented.  If <code>TRUE</code>, then only unspecified starting values will be generated according to this strategy.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.  Convergence is declared when the change in 
the observed data log-likelihood increases by less than epsilon.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_fix.alpha">fix.alpha</code></td>
<td>
<p>Logical to indicate if the components should have a common shape parameter <code>alpha</code> estimated.  The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_maxrestarts">maxrestarts</code></td>
<td>
<p>The maximum number of restarts allowed in case of a problem
with the particular starting values chosen (each restart uses randomly chosen
starting values).</p>
</td></tr>
<tr><td><code id="gammamixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>gammamixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>gamma.pars</code></td>
<td>
<p>A 2xk matrix where each column provides the component estimates of <code>alpha</code> and <code>beta</code>.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.  This vector
includes both the initial and the final values; thus, the number of iterations 
is one less than its length.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977) Maximum Likelihood From Incomplete Data
Via the EM Algorithm, <em>Journal of the Royal Statistical Society, Series B</em>, <b>39(1)</b>, 1&ndash;38.
</p>
<p>Young, D. S., Chen, X., Hewage, D., and Nilo-Poyanco, R. (2019) Finite Mixture-of-Gamma Distributions: Estimation, Inference, and Model-Based Clustering, <em>Advances in Data Analysis and Classification</em>, <b>13(4)</b>, 1053&ndash;1082.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Analyzing a 3-component mixture of gammas.

set.seed(100)
x &lt;- c(rgamma(200, shape = 0.2, scale = 14), rgamma(200, 
     shape = 32, scale = 10), rgamma(200, shape = 5, scale = 6))
out &lt;- gammamixEM(x, lambda = c(1, 1, 1)/3, verb = TRUE)
out[2:4]
</code></pre>

<hr>
<h2 id='Habituationdata'>Infant habituation data</h2><span id='topic+Habituationdata'></span>

<h3>Description</h3>

<p>From Thomas et al (2011):
</p>
<p>&quot;Habituation is a standard method of studying infant behaviors. Indeed,
much of what is known about infant memory and perception rests on 
habituation methods. Six-month infants (n = 51) were habituated to a 
checker-board pattern on two occasions, 
one week apart. On each occasion, the
infant was presented with the checkerboard pattern and the length of time
the infant viewed the pattern before disengaging was recorded; this denoted
the end of a trial. After disengagement, another trial was presented. The
procedure was implemented for eleven trials. The conventional index of 
habituation performance is the summed observed fixation to the checkerboard
pattern over the eleven trials. Thus, an index of reliability focuses on how
these fixation times, in seconds, on the two assessment occasions correlate:
<code class="reqn">r = .29</code>.&quot;</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Habituationdata)</code></pre>


<h3>Format</h3>

<p>A data frame with two variables, <code>m1</code> and <code>m2</code>, and
51 cases.  The two variables are the summed observations times
for the two occasions described above.</p>


<h3>Author(s)</h3>

<p>Hoben Thomas</p>


<h3>Source</h3>

<p>Original source: 
Thomas et al. (2011).  See references section.
</p>


<h3>References</h3>

<p>Thomas, H., Lohaus, A., and Domsch, H. (2011), Extensions of
Reliability Theory, in
Nonparametric Statistics and Mixture Models:  A Festschrift in
Honor of Thomas Hettmansperger (Singapore:  World Scientific),
pp. 309-316.
</p>

<hr>
<h2 id='hmeEM'>EM Algorithm for Mixtures-of-Experts</h2><span id='topic+hmeEM'></span>

<h3>Description</h3>

<p>Returns EM algorithm output for a mixture-of-experts model. Currently, this code
only handles a 2-component mixture-of-experts, but will be extended to the
general k-component hierarchical mixture-of-experts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hmeEM(y, x, lambda = NULL, beta = NULL, sigma = NULL, w = NULL,
      k = 2, addintercept = TRUE, epsilon = 1e-08, 
      maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hmeEM_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions, which are modeled as an inverse
logit function of the predictors.  Entries should sum to 1.  
If NULL, then <code>lambda</code> is taken as 1/<code>k</code> for each <code>x</code>.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and k is number of components.
If NULL, then <code>beta</code> has standard normal entries according to a binning method done on the data.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.  If NULL, then <code class="reqn">1/\code{sigma}^2</code> has
random standard exponential entries according to a binning method done on the data.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_w">w</code></td>
<td>
<p>A p-vector of coefficients for the way the mixing proportions are modeled.  See <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Currently, only <code>k</code>=2 is accepted.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="hmeEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="hmeEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>hmeEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's if <code>addintercept</code> = TRUE).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>The final coefficients for the functional form of the mixing proportions.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>An nxk matrix of the final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations. If <code>arbmean</code> = FALSE, then only the smallest standard
deviation is returned. See <code>scale</code> below.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jacobs, R. A., Jordan, M. I., Nowlan, S. J. and Hinton, G. E. (1991) Adaptive Mixtures of Local
Experts, <em>Neural Computation</em> <b>3(1)</b>, 79&ndash;87.
</p>
<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EM output for NOdata.
 
data(NOdata)
attach(NOdata)
set.seed(100)
em.out &lt;- regmixEM(Equivalence, NO)
hme.out &lt;- hmeEM(Equivalence, NO, beta = em.out$beta)
hme.out[3:7]
</code></pre>

<hr>
<h2 id='ise.npEM'>Integrated Squared Error for a selected density from npEM output</h2><span id='topic+ise.npEM'></span>

<h3>Description</h3>

<p>Computes the integrated squared error for a selected estimated density 
from <code><a href="#topic+npEM">npEM</a></code> output (selected by specifying the component 
and block number), 
relative to a true pdf that must be specified by the user.
The range for the numerical integration must be specified.  This function
also returns (by default) a plot of the
true and estimated densities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ise.npEM(npEMout, component=1, block=1, truepdf, lower=-Inf, 
         upper=Inf, plots = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ise.npEM_+3A_npemout">npEMout</code></td>
<td>
<p>An object of class <code>npEM</code> such as the output
of the <code><a href="#topic+npEM">npEM</a></code> function</p>
</td></tr>
<tr><td><code id="ise.npEM_+3A_component">component</code>, <code id="ise.npEM_+3A_block">block</code></td>
<td>
<p>Component and block of particular density to analyze
from <code>npEMout</code>.</p>
</td></tr>
<tr><td><code id="ise.npEM_+3A_truepdf">truepdf</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> function taking a numeric first argument and 
returning a numeric vector of the same length. Returning a 
non-finite element will generate an error.</p>
</td></tr>
<tr><td><code id="ise.npEM_+3A_lower">lower</code>, <code id="ise.npEM_+3A_upper">upper</code></td>
<td>
<p>the limits of integration.  Can be infinite.</p>
</td></tr>
<tr><td><code id="ise.npEM_+3A_plots">plots</code></td>
<td>
<p>logical:  Should plots be produced?</p>
</td></tr>
<tr><td><code id="ise.npEM_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>truepdf</code>
(and that may be mandatory like, e.g., the <code>df = </code> argument of <code>dt</code>). 
Remember to use argument names not matching those of <code>ise.npRM</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls the <code><a href="#topic+wkde">wkde</a></code> (weighted kernel
density estimate) function.
</p>


<h3>Value</h3>

<p>Just as for the <code><a href="stats.html#topic+integrate">integrate</a></code> function,
a list of class <code>"integrate"</code> with components
</p>
<table>
<tr><td><code>value</code></td>
<td>
<p>the final estimate of the integral.</p>
</td></tr>
<tr><td><code>abs.error</code></td>
<td>
<p>estimate of the modulus of the absolute error.</p>
</td></tr>
<tr><td><code>subdivisions</code></td>
<td>
<p>the number of subintervals produced in the
subdivision process.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p><code>"OK"</code> or a character string giving the error message.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D. (2009),
mixtools: An R package for analyzing finite mixture models.
Journal of Statistical Software, 32(6):1-29.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+wkde">wkde</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mixture with mv gaussian model
set.seed(100)
m &lt;- 2 # no. of components
r &lt;- 3 # no. of repeated measures (coordinates)
lambda &lt;- c(0.4, 0.6)
# Note:  Need first 2 coordinates conditionally iid due to block structure
mu &lt;- matrix(c(0, 0, 0, 3, 3, 5), m, r, byrow=TRUE) # means 
sigma &lt;- matrix(rep(1, 6), m, r, byrow=TRUE) # stdevs
blockid = c(1,1,2) # block structure of coordinates
n &lt;- 200
x &lt;- rmvnormmix(n, lambda, mu, sigma) # simulated data

# fit the model with "arbitrary" initial centers
centers &lt;- matrix(c(0, 0, 0, 4, 4, 4), 2, 3, byrow=TRUE) 
a &lt;- npEM(x, centers, blockid, eps=1e-8, verb=FALSE)

# Calculate integrated squared error for j=2, b=1:
j &lt;- 2 # component
b &lt;- 1 # block
coords &lt;- a$blockid == b
ise.npEM(a, j, b, dnorm, lower=0, upper=10, plots=TRUE,
         mean=mu[j,coords][1], sd=sigma[j, coords][1])


# The following (lengthy) example recreates the normal multivariate 
# mixture model simulation from Benaglia et al (2009).  
mu &lt;- matrix(c(0, 0, 0, 3, 4, 5), m, r, byrow=TRUE) 
nbrep &lt;- 5  # Benaglia et al use 300 replications

# matrix for storing sums of Integrated Squared Errors 
ISE &lt;- matrix(0,m,r,dimnames=list(Components=1:m, Blocks=1:r)) 

nblabsw &lt;- 0 # no. of label switches
for (mc in 1:nbrep) {
  print(paste("REPETITION", mc))
	x &lt;- rmvnormmix(n,lambda,mu,sigma) # simulated data
  a &lt;- npEM(x, centers, verb=FALSE) #default:
	if (a$lambda[1] &gt; a$lambda[2]) nblabsw &lt;- nblabsw + 1
	for (j in 1:m) {  # for each component
		for (k in 1:r) { # for each coordinate; not assuming iid!
      # dnorm with correct mean, sd is the true density:
      ISE[j,k] &lt;- ISE[j,k] + ise.npEM(a, j, k, dnorm, lower=mu[j,k]-5, 
               upper=mu[j,k]+5, plots=FALSE, mean=mu[j,k], 
               sd=sigma[j,k])$value
    }
  }
	MISE &lt;- ISE/nbrep # Mean ISE
	sqMISE &lt;- sqrt(MISE) # root-mean-integrated-squared error
}
sqMISE
</code></pre>

<hr>
<h2 id='lambda'>Local Estimation for Lambda in Mixtures of Regressions</h2><span id='topic+lambda'></span>

<h3>Description</h3>

<p>Return local estimates of the mixing proportions from each component
of a mixture of regressions model using output from an EM algorithm.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda(z, x, xi, h = NULL, kernel = c("Gaussian", "Beta", 
       "Triangle", "Cosinus", "Optcosinus"), g = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda_+3A_z">z</code></td>
<td>
<p>An nxk matrix of posterior probabilities obtained from the EM
algorithm.</p>
</td></tr>
<tr><td><code id="lambda_+3A_x">x</code></td>
<td>
<p>A vector of values for which the local estimation is calculated.</p>
</td></tr>
<tr><td><code id="lambda_+3A_xi">xi</code></td>
<td>
<p>An nx(p-1) matrix of the predictor values.</p>
</td></tr>
<tr><td><code id="lambda_+3A_h">h</code></td>
<td>
<p>The bandwidth controlling the size of the window used for the
local estimation.</p>
</td></tr>
<tr><td><code id="lambda_+3A_kernel">kernel</code></td>
<td>
<p>The type of kernel to be used for the local estimation.</p>
</td></tr>
<tr><td><code id="lambda_+3A_g">g</code></td>
<td>
<p>A shape parameter required for the symmetric beta kernel.  The default
is <code>g</code> = 0 which yields the uniform kernel.  Some common values are <code>g</code> = 1 for the
Epanechnikov kernel, <code>g</code> = 2 for the biweight kernel, and <code>g</code> = 3 for the triweight kernel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>lambda</code> returns local estimates of the mixing proportions for the inputted
<code>x</code> vector.
</p>


<h3>Note</h3>

<p><code>lambda</code> is for use within <code>regmixEM.loc</code>.</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM.loc">regmixEM.loc</a></code>
</p>

<hr>
<h2 id='lambda.pert'>Perturbation of Mixing Proportions</h2><span id='topic+lambda.pert'></span>

<h3>Description</h3>

<p>Perturbs a set of mixing proportions by first scaling the
mixing proportions, then taking the logit of the scaled values,
perturbing them, and inverting back to produce a set of
new mixing proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda.pert(lambda, pert)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda.pert_+3A_lambda">lambda</code></td>
<td>
<p>A vector of length k giving the mixing proportions which
are to be perturbed.</p>
</td></tr>
<tr><td><code id="lambda.pert_+3A_pert">pert</code></td>
<td>
<p>A vector (possibly of length k-1) for which to perturb <code>lambda</code>.
If the length is less than k, then values of the vector are recycled.  If length
is greater than k, then only the first k values are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>regmixMH</code>.
</p>


<h3>Value</h3>

<p><code>lambda.pert</code> returns new <code>lambda</code> values perturbed by <code>pert</code>.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixMH">regmixMH</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)
x &lt;- c(0.5, 0.2, 0.3)
lambda.pert(x, rcauchy(3))

</code></pre>

<hr>
<h2 id='ldmult'>Log-Density for Multinomial Distribution</h2><span id='topic+ldmult'></span>

<h3>Description</h3>

<p>Return the logarithm of the multinomial density function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldmult(y, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldmult_+3A_y">y</code></td>
<td>
<p>A vector of multinomial counts.</p>
</td></tr>
<tr><td><code id="ldmult_+3A_theta">theta</code></td>
<td>
<p>A vector of multinomial probabilities.  May have same number of
components as or one fewer component than <code>y</code>.  In the latter case, 
an extra component is appended so that theta sums to one.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>multmixEM</code>.
</p>


<h3>Value</h3>

<p><code>ldmult</code> returns the logarithm of the multinomial density
with parameter <code>theta</code>, evaluated at <code>y</code>.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multmixEM">multmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- c(2, 2, 10)
theta &lt;- c(0.2, 0.3, 0.5)
ldmult(y, theta)

</code></pre>

<hr>
<h2 id='logisregmixEM'>EM Algorithm for Mixtures of Logistic Regressions</h2><span id='topic+logisregmixEM'></span>

<h3>Description</h3>

<p>Returns EM algorithm output for mixtures of logistic regressions with
arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisregmixEM(y, x, N = NULL, lambda = NULL, beta = NULL, k = 2,
              addintercept = TRUE, epsilon = 1e-08, 
              maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logisregmixEM_+3A_y">y</code></td>
<td>
<p>An n-vector of successes out of N trials.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_n">N</code></td>
<td>
<p>An n-vector of number of trials for the logistic regression.  
If NULL, then <code>N</code> is an n-vector of 1s for binary logistic regression.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>beta</code>.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and k is number of components.
If NULL, then <code>beta</code> is generated by binning the data into k bins and using <code>glm</code> on
the values in each of the bins.  If both <code>lambda</code> and <code>beta</code> are NULL, then 
number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless <code>lambda</code> and <code>beta</code> are both NULL.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="logisregmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>logisregmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The predictor values.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final logistic regression coefficients.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>   
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poisregmixEM">poisregmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EM output for data generated from a 2-component logistic regression model.

set.seed(100)
beta &lt;- matrix(c(1, .5, 2, -.8), 2, 2)
x &lt;- runif(50, 0, 10)
x1 &lt;- cbind(1, x)
xbeta &lt;- x1%*%beta
N &lt;- ceiling(runif(50, 50, 75))
w &lt;- rbinom(50, 1, .3)
y &lt;- w*rbinom(50, size = N, prob = (1/(1+exp(-xbeta[, 1]))))+
              (1-w)*rbinom(50, size = N, prob = 
              (1/(1+exp(-xbeta[, 2]))))
out.1 &lt;- logisregmixEM(y, x, N, verb = TRUE, epsilon = 1e-01)
out.1

## EM output for data generated from a 2-component binary logistic regression model.

beta &lt;- matrix(c(-10, .1, 20, -.1), 2, 2)
x &lt;- runif(500, 50, 250)
x1 &lt;- cbind(1, x)
xbeta &lt;- x1%*%beta
w &lt;- rbinom(500, 1, .3)
y &lt;- w*rbinom(500, size = 1, prob = (1/(1+exp(-xbeta[, 1]))))+
              (1-w)*rbinom(500, size = 1, prob = 
              (1/(1+exp(-xbeta[, 2]))))
out.2 &lt;- logisregmixEM(y, x, beta = beta, lambda = c(.3, .7), 
                       verb = TRUE, epsilon = 1e-01)
out.2
</code></pre>

<hr>
<h2 id='makemultdata'>Produce Cutpoint Multinomial Data</h2><span id='topic+makemultdata'></span>

<h3>Description</h3>

<p>Change data into a matrix of multinomial counts using the
cutpoint method and generate EM algorithm starting values for 
a k-component mixture of multinomials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makemultdata(..., cuts)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makemultdata_+3A_...">...</code></td>
<td>
<p>Either vectors (possibly of different lengths) of raw data 
or an nxm matrix (or data frame) of data. If <code>...</code> are vectors of varying length, 
then <code>makemultdata</code> will create a matrix of size nxm where n is the
sample size and m is the length of the vector with maximum length.  Those 
vectors with length less than m will have <code>NA</code>s to make the 
corresponding row in the matrix of length m.  If <code>...</code> is a matrix (or data frame), then
the rows must correspond to the sample and the columns the repeated measures.</p>
</td></tr>
<tr><td><code id="makemultdata_+3A_cuts">cuts</code></td>
<td>
<p>A vector of cutpoints.  This vector is sorted by the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (i, j)th entry of the matrix <code>y</code> (for j &lt; p)
is equal to the number of entries
in the ith column of <code>x</code> that are less than or equal to <code>cuts</code>[j].
The (i, p)th entry is equal to the number of entries greater than
<code>cuts</code>[j].
</p>


<h3>Value</h3>

<p><code>makemultdata</code> returns an object which is a list with components:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>An nxm matrix of the raw data.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>An nxp matrix of the discretized data where p is one more than the
number of cutpoints. Each row is a multinomial vector of counts.  In particular,
each row should sum to the number of repeated measures for that sample.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Elmore, R. T., Hettmansperger, T. P. and Xuan, F. (2004) The Sign Statistic, One-Way Layouts
and Mixture Models, <em>Statistical Science</em> <b>19(4)</b>, 579&ndash;587.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compCDF">compCDF</a></code>, <code><a href="#topic+multmixmodel.sel">multmixmodel.sel</a></code>, <code><a href="#topic+multmixEM">multmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Randomly generated data.

set.seed(100)
y &lt;- matrix(rpois(70, 6), 10, 7)
cuts &lt;- c(2, 5, 7)
out1 &lt;- makemultdata(y, cuts = cuts)
out1

## The sulfur content of the coal seams in Texas.

A &lt;- c(1.51, 1.92, 1.08, 2.04, 2.14, 1.76, 1.17)
B &lt;- c(1.69, 0.64, .9, 1.41, 1.01, .84, 1.28, 1.59)
C &lt;- c(1.56, 1.22, 1.32, 1.39, 1.33, 1.54, 1.04, 2.25, 1.49)
D &lt;- c(1.3, .75, 1.26, .69, .62, .9, 1.2, .32)
E &lt;- c(.73, .8, .9, 1.24, .82, .72, .57, 1.18, .54, 1.3)

out2 &lt;- makemultdata(A, B, C, D, E, 
                     cuts = median(c(A, B, C, D, E)))
out2

## The reaction time data.

data(RTdata)
out3 &lt;- makemultdata(RTdata, cuts = 
                     100*c(5, 10, 12, 14, 16, 20, 25, 30, 40, 50))
dim(out3$y)
out3$y[1:10,]
</code></pre>

<hr>
<h2 id='matsqrt'>Calculates the Square Root of a Diagonalizable Matrix</h2><span id='topic+matsqrt'></span>

<h3>Description</h3>

<p>Returns the square root of a diagonalizable matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matsqrt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matsqrt_+3A_x">x</code></td>
<td>
<p>An nxn diagonalizable matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>regcr</code>.
</p>


<h3>Value</h3>

<p><code>matsqrt</code> returns the square root of <code>x</code>.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcr">regcr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix(c(1, -0.2, -0.2, 1), 2, 2)
matsqrt(a)

</code></pre>

<hr>
<h2 id='mixtools+20initializations'>Initializations for Various EM Algorithms in 'mixtools'</h2><span id='topic+flaremix.init'></span><span id='topic+gammamix.init'></span><span id='topic+logisregmix.init'></span><span id='topic+multmix.init'></span><span id='topic+mvnormalmix.init'></span><span id='topic+normalmix.init'></span><span id='topic+poisregmix.init'></span><span id='topic+regmix.init'></span><span id='topic+regmix.lambda.init'></span><span id='topic+regmix.mixed.init'></span><span id='topic+repnormmix.init'></span><span id='topic+segregmix.init'></span>

<h3>Description</h3>

<p>Internal intialization functions for EM algorithms in the package <code>mixtools</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flaremix.init(y, x, lambda = NULL, beta = NULL, sigma = NULL,
              alpha = NULL)
gammamix.init(x, lambda = NULL, alpha = NULL, beta = NULL, 
              k = 2)
logisregmix.init(y, x, N, lambda = NULL, beta = NULL, k = 2)
multmix.init(y, lambda = NULL, theta = NULL, k = 2)
mvnormalmix.init(x, lambda = NULL, mu = NULL, sigma = NULL, 
                 k = 2, arbmean = TRUE, arbvar = TRUE)
normalmix.init(x, lambda = NULL, mu = NULL, s = NULL, k = 2, 
               arbmean = TRUE, arbvar = TRUE)
poisregmix.init(y, x, lambda = NULL, beta = NULL, k = 2)
regmix.init(y, x, lambda = NULL, beta = NULL, s = NULL, k = 2, 
            addintercept = TRUE, arbmean = TRUE, arbvar=TRUE)
regmix.lambda.init(y, x, lambda = NULL, beta = NULL, s = NULL,
                   k = 2, addintercept = TRUE, arbmean = TRUE,
                   arbvar = TRUE)
regmix.mixed.init(y, x, w = NULL, sigma = NULL, 
                  arb.sigma = TRUE, alpha = NULL, lambda = NULL, 
                  mu = NULL, R = NULL, arb.R = TRUE, k = 2, 
                  mixed = FALSE, addintercept.fixed = FALSE,
                  addintercept.random = TRUE)
repnormmix.init(x, lambda = NULL, mu = NULL, s = NULL, k = 2, 
                arbmean = TRUE, arbvar = TRUE)
segregmix.init(y, x, lambda = NULL, beta = NULL, s = NULL, k = 2,
               seg.Z, psi, psi.locs = NULL)
</code></pre>


<h3>Details</h3>

<p>These are usually not to be called by the user. Definitions of the arguments appear in the respective EM algorithms.
</p>

<hr>
<h2 id='mixtools-internal'>Internal 'mixtools' Functions</h2><span id='topic+inv.logit'></span><span id='topic+dexpmixt'></span><span id='topic+HRkde'></span><span id='topic+kern.B'></span><span id='topic+kern.C'></span><span id='topic+kern.G'></span><span id='topic+kern.O'></span><span id='topic+kern.T'></span><span id='topic+kfoldCV'></span><span id='topic+KMintegrate'></span><span id='topic+KMod'></span><span id='topic+ldc'></span><span id='topic+logit'></span><span id='topic+npMSL_old'></span><span id='topic+plotseq'></span><span id='topic+rlnormscalemix'></span><span id='topic+splitsample'></span><span id='topic+triang_wkde'></span><span id='topic+wbw.kCV'></span>

<h3>Description</h3>

<p>Internal kernel, semiparametric-related, and miscellaneous functions for the package <code>mixtools</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dexpmixt(t, lam, rate)
HRkde(cpd, u = cpd[,1], kernelft = triang_wkde, 
      bw = rep(bw.nrd0(as.vector(cpd[,1])), length(cpd[,1])))
inv.logit(eta)
kern.B(x, xi, h, g = 0)
kern.C(x, xi, h)
kern.G(x, xi, h)
kern.O(x, xi, h)
kern.T(x, xi, h)
kfoldCV(h, x, nbsets = 2, w = rep(1, length(x)), 
        lower = mean(x) - 5*sd(x), upper = mean(x) + 5*sd(x))
KMintegrate(s) 
KMod(cpd, already.ordered = TRUE)
ldc(data, class, score)
logit(mu)
npMSL_old(x, mu0, blockid = 1:ncol(x),
          bw=bw.nrd0(as.vector(as.matrix(x))), samebw = TRUE,
          h=bw, eps=1e-8, maxiter=500, bwiter = maxiter,
          ngrid = 200, post = NULL, verb = TRUE)
plotseq(x, ...)
rlnormscalemix(n, lambda=1, meanlog=1, sdlog=1, scale=0.1)
splitsample(n, nbsets = 2)
triang_wkde(t, u=t, w=rep(1/length(t),length(t)), bw=rep(bw.nrd0(t), length(t)))
wbw.kCV(x, nbfold = 5, w = rep(1, length(x)), 
        hmin = 0.1*hmax, hmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixtools-internal_+3A_x">x</code></td>
<td>
<p>A vector of values to which local modeling techniques are applied.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_xi">xi</code></td>
<td>
<p>An n-vector of data values.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_h">h</code></td>
<td>
<p>The bandwidth controlling the size of the window used for the
local estimation around <code>x</code>.  This pertains to its usage in the kernel functionns
<code>kern.B</code>, <code>kern.C</code>, <code>kern.G</code>, <code>kern.O</code>, and <code>kern.T</code>.  For its
usage in the <code>kfoldCV</code> function, see updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_g">g</code></td>
<td>
<p>A shape parameter required for the symmetric beta kernel.  The default
is <code>g</code> = 0 which yields the uniform kernel.  Some common values are <code>g</code> = 1 for the
Epanechnikov kernel, <code>g</code> = 2 for the biweight kernel, and <code>g</code> = 3 for the triweight kernel.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_mu0">mu0</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_blockid">blockid</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_bw">bw</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_samebw">samebw</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_eps">eps</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_maxiter">maxiter</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_bwiter">bwiter</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_ngrid">ngrid</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_post">post</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_verb">verb</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_n">n</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_nbsets">nbsets</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_w">w</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_lower">lower</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_upper">upper</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_nbfold">nbfold</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_hmin">hmin</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_hmax">hmax</code></td>
<td>
<p>See updated arguments in the <code>npMSL</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_data">data</code></td>
<td>
<p>Data, possibly multivariate, fed to the <code>mixturegram</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_class">class</code></td>
<td>
<p>The number of classes, inputted based on number of components in the <code>mixturegram</code> function.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_score">score</code></td>
<td>
<p>The score vector from LDA used in constructing a mixturegram.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_lam">lam</code></td>
<td>
<p>A vector of mixture proportions, should sum to one.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_rate">rate</code></td>
<td>
<p>A vector of mixture component rates.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_t">t</code></td>
<td>
<p>Argument for <code>dexpmixt</code>.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_mu">mu</code></td>
<td>
<p>A proportion for which to calculate the logit function; i.e., <code>log(mu / (1 - mu))</code>.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_eta">eta</code></td>
<td>
<p>Any real value for which to calculate the inverse logit function; 
i.e., <code>1 / (1 + exp(eta))</code>.</p>
</td></tr>  
<tr><td><code id="mixtools-internal_+3A_cpd">cpd</code></td>
<td>
<p>Argument for <code>HRkde</code>.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_kernelft">kernelft</code></td>
<td>
<p>Argument for <code>HRkde</code>.</p>
</td></tr> 
<tr><td><code id="mixtools-internal_+3A_s">s</code></td>
<td>
<p>Argument for <code>KMintegrate</code>.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_meanlog">meanlog</code></td>
<td>
<p>Argument for <code>rlnormscalemix</code>.</p>
</td></tr>
<tr><td><code id="mixtools-internal_+3A_sdlog">sdlog</code></td>
<td>
<p>Argument for <code>rlnormscalemix</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are usually not to be called by the user.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+npMSL">npMSL</a></code>
</p>

<hr>
<h2 id='mixturegram'>Mixturegrams</h2><span id='topic+mixturegram'></span>

<h3>Description</h3>

<p>Construct a mixturegram for determining an apporpriate number of components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixturegram(data, pmbs, method = c("pca", "kpca", "lda"), all.n = FALSE,
			id.con = NULL, score = 1, iter.max = 50, nstart = 25, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixturegram_+3A_data">data</code></td>
<td>
<p>The data, which must either be a vector or a matrix.  If a matrix, then the rows correspond to the observations.</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_pmbs">pmbs</code></td>
<td>
<p>A list of length (K-1) such that each element is an nxk matrix of the posterior membership probabilities.  These are obtained from each of the &quot;best&quot; estimated k-component mixture models, k = 2,...,K.
</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_method">method</code></td>
<td>
<p>The dimension reduction method used.  <code>method = "pca"</code> implements principal components analysis.  <code>method = "kpca"</code> implements kernel principal components analysis. <code>method = "lda"</code> implements reduced rank linear discriminant analysis.
</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_all.n">all.n</code></td>
<td>
<p>A logical specifying whether the mixturegram should plot the profiles of all observations (<code>TRUE</code>) or just the K-profile summaries (<code>FALSE</code>).  The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_id.con">id.con</code></td>
<td>
<p>An argument that allows one to impose some sort of (meaningful) identifiability constraint so that the mixture components are in some sort of comparable order between mixture models with different numbers of components.  If <code>NULL</code>, then the components are ordered by the component means for univariate data or ordered by the first dimension of the component means for multivariate data.</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_score">score</code></td>
<td>
<p>The value for the specified dimension reduction technique's score, which is used for constructing the mixturegram.  By default, this value is <code>1</code>, which is the value that will typically be used.  Larger values will result in more variability displayed on the mixturegram.  Note that the largest value that can be calculated at each value of k&gt;1 on the mixturegram is p+k-1, where p is the number of columns of <code>data</code>. 
</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_iter.max">iter.max</code></td>
<td>
<p>The maximum number of iterations allowed for the k-means clustering algorithm, which is passed to the <code><a href="stats.html#topic+kmeans">kmeans</a></code> function.  The default is <code>50</code>.
</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_nstart">nstart</code></td>
<td>
<p>The number of random sets chosen based on k centers, which is passed to the <code><a href="stats.html#topic+kmeans">kmeans</a></code> function.  The default is <code>25</code>.</p>
</td></tr>
<tr><td><code id="mixturegram_+3A_...">...</code></td>
<td>
<p>Additional arguments that can be passed to the underlying <code><a href="graphics.html#topic+plot">plot</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mixturegram</code> returns a mixturegram where the profiles are plotted over component values of k = 1,...,K.
</p>


<h3>References</h3>

<p>Young, D. S., Ke, C., and Zeng, X. (2018) The Mixturegram: A Visualization Tool for Assessing the
Number of Components in Finite Mixture Models, <em>Journal 
of Computational and Graphical Statistics</em>, <b>27(3)</b>, 564&ndash;575.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.comp">boot.comp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Data generated from a 2-component mixture of normals.


set.seed(100)
n &lt;- 100
w &lt;- rmultinom(n,1,c(.3,.7))
y &lt;- sapply(1:n,function(i) w[1,i]*rnorm(1,-6,1) +
            w[2,i]*rnorm(1,0,1))

selection &lt;- function(i,data,rep=30){
  out &lt;- replicate(rep,normalmixEM(data,epsilon=1e-06,
  				   k=i,maxit=5000),simplify=FALSE)
  counts &lt;- lapply(1:rep,function(j) 
                   table(apply(out[[j]]$posterior,1,
                   which.max)))
  counts.length &lt;- sapply(counts, length)
  counts.min &lt;- sapply(counts, min)
  counts.test &lt;- (counts.length != i)|(counts.min &lt; 5)
  if(sum(counts.test) &gt; 0 &amp; sum(counts.test) &lt; rep) 
  	out &lt;- out[!counts.test]
  l &lt;- unlist(lapply(out, function(x) x$loglik))
  tmp &lt;- out[[which.max(l)]]
}

all.out &lt;- lapply(2:5, selection, data = y, rep = 2)
pmbs &lt;- lapply(1:length(all.out), function(i) 
			   all.out[[i]]$post)
mixturegram(y, pmbs, method = "pca", all.n = FALSE,
		    id.con = NULL, score = 1, 
		    main = "Mixturegram (Well-Separated Data)")
</code></pre>

<hr>
<h2 id='multmixEM'>EM Algorithm for Mixtures of Multinomials</h2><span id='topic+multmixEM'></span>

<h3>Description</h3>

<p>Return EM algorithm output for mixtures of multinomial distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multmixEM(y, lambda = NULL, theta = NULL, k = 2,
          maxit = 10000, epsilon = 1e-08, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multmixEM_+3A_y">y</code></td>
<td>
<p>Either An nxp matrix of data (multinomial counts), where n is the
sample size and p is the number of multinomial bins, or the
output of the <code><a href="#topic+makemultdata">makemultdata</a></code> function.  It is not necessary
that all of the rows contain the same number of multinomial trials (i.e.,
the row sums of <code>y</code> need not be identical).</p>
</td></tr>
<tr><td><code id="multmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>theta</code>.</p>
</td></tr>
<tr><td><code id="multmixEM_+3A_theta">theta</code></td>
<td>
<p>Initial value of <code>theta</code> parameters.  Should be a kxp matrix,
where p is the number of columns of y and k is number of components.
Each row of <code>theta</code> should sum to 1.
If NULL, then each row is random from uniform Dirichlet.
If both <code>lambda</code> and <code>theta</code> are NULL, then number of components 
is determined by k.</p>
</td></tr>
<tr><td><code id="multmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless <code>lambda</code> and <code>theta</code>
are NULL.</p>
</td></tr>
<tr><td><code id="multmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="multmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="multmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>multmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>The final multinomial parameters.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr> 
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>
</li>
<li><p> Elmore, R. T., Hettmansperger, T. P. and Xuan, F. (2004) The Sign Statistic, One-Way Layouts
and Mixture Models, <em>Statistical Science</em> <b>19(4)</b>, 579&ndash;587.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+compCDF">compCDF</a></code>, <code><a href="#topic+makemultdata">makemultdata</a></code>, <code><a href="#topic+multmixmodel.sel">multmixmodel.sel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The sulfur content of the coal seams in Texas

set.seed(100)
A &lt;- c(1.51, 1.92, 1.08, 2.04, 2.14, 1.76, 1.17)
B &lt;- c(1.69, 0.64, .9, 1.41, 1.01, .84, 1.28, 1.59) 
C &lt;- c(1.56, 1.22, 1.32, 1.39, 1.33, 1.54, 1.04, 2.25, 1.49) 
D &lt;- c(1.3, .75, 1.26, .69, .62, .9, 1.2, .32) 
E &lt;- c(.73, .8, .9, 1.24, .82, .72, .57, 1.18, .54, 1.3)

dis.coal &lt;- makemultdata(A, B, C, D, E, 
                         cuts = median(c(A, B, C, D, E)))
em.out &lt;- multmixEM(dis.coal)
em.out[1:4]
</code></pre>

<hr>
<h2 id='multmixmodel.sel'>Model Selection Mixtures of Multinomials</h2><span id='topic+multmixmodel.sel'></span>

<h3>Description</h3>

<p>Assess the number of components in a mixture of multinomials model using the Akaike's information
criterion (AIC), Schwartz's Bayesian information criterion (BIC), Bozdogan's consistent AIC (CAIC),
and Integrated Completed Likelihood (ICL).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multmixmodel.sel(y, comps = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multmixmodel.sel_+3A_y">y</code></td>
<td>
<p>Either An nxp matrix of data (multinomial counts), where n is the
sample size and p is the number of multinomial bins, or the
output of the <code><a href="#topic+makemultdata">makemultdata</a></code> function.  It is not necessary
that all of the rows contain the same number of multinomial trials (i.e.,
the row sums of <code>y</code> need not be identical).</p>
</td></tr>
<tr><td><code id="multmixmodel.sel_+3A_comps">comps</code></td>
<td>
<p>Vector containing the numbers of components to consider.
If NULL, this is set to be 1:(max possible), where (max possible) is
floor((m+1)/2) and m is the minimum row sum of y.</p>
</td></tr>
<tr><td><code id="multmixmodel.sel_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>multmixEM</code> that control convergence of the underlying EM algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>multmixmodel.sel</code> returns a table summarizing the AIC, BIC, CAIC, ICL, and log-likelihood
values along with the winner (the number with the lowest aforementioned values).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compCDF">compCDF</a></code>, <code><a href="#topic+makemultdata">makemultdata</a></code>, <code><a href="#topic+multmixEM">multmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Data generated using the multinomial cutpoint method.

set.seed(100)
x &lt;- matrix(rpois(70, 6), 10, 7) 
x.new &lt;- makemultdata(x, cuts = 5)
multmixmodel.sel(x.new$y, comps = c(1,2), epsilon = 1e-03)

</code></pre>

<hr>
<h2 id='mvnormalmixEM'>EM Algorithm for Mixtures of Multivariate Normals</h2><span id='topic+mvnormalmixEM'></span>

<h3>Description</h3>

<p>Return EM algorithm output for mixtures of multivariate normal distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnormalmixEM(x, lambda = NULL, mu = NULL, sigma = NULL, k = 2,
              arbmean = TRUE, arbvar = TRUE, epsilon = 1e-08, 
              maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnormalmixEM_+3A_x">x</code></td>
<td>
<p>A matrix of size nxp consisting of the data.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>mu</code>.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_mu">mu</code></td>
<td>
<p>A list of size k consisting of initial values for the p-vector mean parameters.  
If NULL, then the vectors are generated from a normal distribution with
mean and standard deviation according to a binning method done on the data.
If both <code>lambda</code> and <code>mu</code> are NULL, then number of components is determined by <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_sigma">sigma</code></td>
<td>
<p>A list of size k consisting of initial values for the pxp variance-covariance matrices.  
If NULL, then <code>sigma</code> is generated using the data.  
If <code>lambda</code>, <code>mu</code>, and <code>sigma</code> are
NULL, then number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless <code>lambda</code>, <code>mu</code>, and <code>sigma</code>
are all NULL.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_arbmean">arbmean</code></td>
<td>
<p>If TRUE, then the component densities are allowed to have different <code>mu</code>s. If FALSE, then
a scale mixture will be fit.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_arbvar">arbvar</code></td>
<td>
<p>If TRUE, then the component densities are allowed to have different <code>sigma</code>s. If FALSE, then
a location mixture will be fit.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="mvnormalmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>normalmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A list of with the final mean vectors.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>A list with the final variance-covariance matrices.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+normalmixEM">normalmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Fitting randomly generated data with a 2-component location mixture of bivariate normals.

set.seed(100)
x.1 &lt;- rmvnorm(40, c(0, 0))
x.2 &lt;- rmvnorm(60, c(3, 4))
X.1 &lt;- rbind(x.1, x.2)
mu &lt;- list(c(0, 0), c(3, 4))

out.1 &lt;- mvnormalmixEM(X.1, arbvar = FALSE, mu = mu,
                       epsilon = 1e-02)
out.1[2:5]

##Fitting randomly generated data with a 2-component scale mixture of bivariate normals.

x.3 &lt;- rmvnorm(40, c(0, 0), sigma = 
               matrix(c(200, 1, 1, 150), 2, 2))
x.4 &lt;- rmvnorm(60, c(0, 0))
X.2 &lt;- rbind(x.3, x.4)
lambda &lt;- c(0.40, 0.60)
sigma &lt;- list(diag(1, 2), matrix(c(200, 1, 1, 150), 2, 2))
 
out.2 &lt;- mvnormalmixEM(X.2, arbmean = FALSE,
                       sigma = sigma, lambda = lambda,
                       epsilon = 1e-02)
out.2[2:5]
</code></pre>

<hr>
<h2 id='mvnpEM'>EM-like Algorithm for Nonparametric Mixture Models 
with Conditionally Independent Multivariate Component Densities</h2><span id='topic+mvnpEM'></span>

<h3>Description</h3>

<p>An extension of the original <code><a href="#topic+npEM">npEM</a></code> algorithm, for mixtures
of multivariate data where the coordinates of a row (case)
in the data matrix are assumed to be made of independent but multivariate blocks (instead of just coordinates), 
conditional on the mixture
component (subpopulation) from which they are drawn (Chauveau and Hoang 2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnpEM(x, mu0, blockid = 1:ncol(x), samebw = TRUE, 
       bwdefault = apply(x,2,bw.nrd0), init = NULL,
       eps = 1e-8, maxiter = 500, verb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnpEM_+3A_x">x</code></td>
<td>
<p>An <code class="reqn">n\times r</code> matrix of data.  Each of the <code class="reqn">n</code> rows is a case,
and each case has <code class="reqn">r</code> repeated measurements.  These measurements are assumed
to be conditionally independent, conditional on the mixture component (subpopulation) 
from which the case is drawn.</p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_mu0">mu0</code></td>
<td>
<p>Either an <code class="reqn">m\times r</code> matrix specifying the initial
centers for the <a href="stats.html#topic+kmeans">kmeans</a> function, or an integer <code class="reqn">m</code> specifying the 
number of initial centers, which are then chosen randomly in <a href="stats.html#topic+kmeans">kmeans</a></p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_blockid">blockid</code></td>
<td>
<p>A vector of length <code class="reqn">r</code> identifying coordinates 
(columns of <code>x</code>) that are in the same block.  The default has all distinct elements, 
indicating that the model has <code class="reqn">r</code> blocks of dimension 1, in which case the model is handled 
directly by the <code><a href="#topic+npEM">npEM</a></code> algorithm.
See example below for actual multivariate blocks example.</p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_samebw">samebw</code></td>
<td>
<p>Logical:  If <code>TRUE</code>, use the same bandwidth per coordinate for
all iteration and all components.  If <code>FALSE</code>, 
use a separate bandwidth for each component and coordinate, and update
this bandwidth at each iteration of the algorithm using a suitably
modified <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> method as described in 
Benaglia et al (2011) and Chauveau and Hoang (2015).</p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_bwdefault">bwdefault</code></td>
<td>
<p>Bandwidth default for density estimation,a simplistic application of the 
default <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> for each coordinate (column) of the data.</p>
</td></tr> 
<tr><td><code id="mvnpEM_+3A_init">init</code></td>
<td>
<p>Initialization method, based on an initial <code class="reqn">n\times m</code>
matrix for the posterior probabilities. If <code>NULL</code>,
a  <code><a href="stats.html#topic+kmeans">kmeans</a></code> clustering with <code>mu0</code> initial centers is applied to the data and the 
initial matrix of posteriors is built from the result.</p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_eps">eps</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence.  Convergence
is declared whenever the maximum change in any coordinate of the 
<code>lambda</code> vector (of mixing proportion estimates) does not exceed 
<code>eps</code>.</p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations allowed; convergence
may be declared before <code>maxiter</code> iterations (see <code>eps</code> above).</p>
</td></tr>
<tr><td><code id="mvnpEM_+3A_verb">verb</code></td>
<td>
<p>Verbose mode; if TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>mvnpEM</code> returns a list of class <code>mvnpEM</code> with the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The raw data (an <code class="reqn">n\times r</code> matrix).</p>
</td></tr>
<tr><td><code>posteriors</code></td>
<td>
<p>An <code class="reqn">n\times m</code> matrix of posterior probabilities for
each observation (row).</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>blockid</code></td>
<td>
<p>The <code>blockid</code> input argument. Needed by any method that produces density 
estimates from the output, like <code><a href="#topic+plot.mvnpEM">plot.mvnpEM</a></code>.</p>
</td></tr>
<tr><td><code>samebw</code></td>
<td>
<p>The <code>samebw</code> input argument. 
Needed by any method that produces density estimates from the output, like <code><a href="#topic+plot.mvnpEM">plot.mvnpEM</a></code>.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>The final bandwidth matrix 
after convergence of the algorithm.
Its shape depends on the <code>samebw</code> input argument. If <code>samebw = TRUE</code>, a 
vectors with the bandwidth value for each of the <code>r</code> coordinates (same for all components and iterations).
If <code>samebw = FALSE</code>, a <code class="reqn">m\times r</code> matrix, where each row is associated to one component 
and gives the <code class="reqn">r</code> bandwidth values, one for each coordinate.
Needed by any method that produces density estimates from the output, like <code><a href="#topic+plot.mvnpEM">plot.mvnpEM</a></code>.</p>
</td></tr>
<tr><td><code>lambdahat</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The sequence of pseudo log-likelihood values over iterations.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D. and Hunter, D.R. (2011),
Bandwidth Selection in an EM-like algorithm for nonparametric multivariate mixtures.
Nonparametric Statistics and Mixture Models: A Festschrift in
Honor of Thomas P. Hettmansperger. World Scientific Publishing Co., 
pages 15-27.
</p>
</li>
<li><p>  Chauveau, D., and Hoang, V. T. L. (2015),
Nonparametric mixture models with conditionally independent multivariate component densities, 
Preprint under revision.
<a href="https://hal.archives-ouvertes.fr/hal-01094837">https://hal.archives-ouvertes.fr/hal-01094837</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.mvnpEM">plot.mvnpEM</a></code>, <code><a href="#topic+npEM">npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example as in Chauveau and Hoang (2015) with 6 coordinates
## Not run: 
m=2; r=6; blockid &lt;-c(1,1,2,2,3,3) # 3 bivariate blocks 
# generate some data x ...
a &lt;- mvnpEM(x, mu0=2, blockid, samebw=F) # adaptive bandwidth
plot(a) # this S3 method produces 6 plots of univariate marginals
summary(a)
## End(Not run)
</code></pre>

<hr>
<h2 id='NOdata'>Ethanol Fuel Data Set</h2><span id='topic+NOdata'></span>

<h3>Description</h3>

<p>This data set gives the equivalence ratios and peak nitrogen oxide emissions in a
study using pure ethanol as a spark-ignition engine fuel.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NOdata)
</code></pre>


<h3>Format</h3>

<p>This data frame consists of:
</p>

<ul>
<li><p><code>NO</code>The peak nitrogen oxide emission levels.
</p>
</li>
<li><p><code>Equivalence</code>The equivalence ratios for the engine at compression ratios from 7.5 to 18.
</p>
</li></ul>



<h3>Source</h3>

<p>Brinkman, N. D. (1981) Ethanol Fuel &ndash; A Single-Cylinder Engine Study of Efficiency and
Exhaust Emissions, <em>S.A.E. Transactions</em>, 68.
</p>


<h3>References</h3>

<p>Hurn, M., Justel, A. and Robert, C. P. (2003) Estimating Mixtures of Regressions, <em>Journal 
of Computational and Graphical Statistics</em> <b>12(1)</b>, 55&ndash;79.
</p>

<hr>
<h2 id='normalmixEM'>EM Algorithm for Mixtures of Univariate Normals</h2><span id='topic+normalmixEM'></span>

<h3>Description</h3>

<p>Return EM algorithm output for mixtures of normal distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalmixEM(x, lambda = NULL, mu = NULL, sigma = NULL, k = 2, 
            mean.constr = NULL, sd.constr = NULL,
            epsilon = 1e-08, maxit = 1000, maxrestarts = 20, 
            verb = FALSE, fast = FALSE, ECM = FALSE,
            arbmean = TRUE, arbvar = TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalmixEM_+3A_x">x</code></td>
<td>
<p>A vector of length n consisting of the data.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Automatically 
repeated as necessary 
to produce a vector of length <code>k</code>, then normalized to sum to 1.
If <code>NULL</code>, then <code>lambda</code> is random from a uniform Dirichlet
distribution (i.e., its entries are uniform random and then it is 
normalized to sum to 1).</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_mu">mu</code></td>
<td>
<p>Starting value of vector of component means.  If non-NULL and a
scalar, <code>arbmean</code> is set to <code>FALSE</code>.  If non-NULL and a vector,
<code>k</code> is set to <code>length(mu)</code>.  If NULL, then the initial value
is randomly generated from a normal distribution with center(s) determined
by binning the data.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_sigma">sigma</code></td>
<td>
<p>Starting value of vector of component standard deviations 
for algorithm.  If non-NULL
and a scalar, <code>arbvar</code> is set to <code>FALSE</code>.  If non-NULL and a vector,
<code>arbvar</code> is set to <code>TRUE</code> and <code>k</code> is set to <code>length(sigma)</code>.
If NULL, then the initial value is the reciprocal of the square root of
a vector of random exponential-distribution values whose means are determined
according to a binning method done on the data.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Initial value ignored unless <code>mu</code> 
and <code>sigma</code> are both NULL.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_mean.constr">mean.constr</code></td>
<td>
<p>Equality constraints on the mean parameters, given as
a vector of length <code>k</code>.  Each vector entry helps specify the constraints,
if any, on the corresponding mean parameter:  If <code>NA</code>, the corresponding
parameter is unconstrained.  If numeric, the corresponding
parameter is fixed at that value.  If a character string consisting of
a single character preceded by a coefficient, such as <code>"0.5a"</code>
or <code>"-b"</code>, all parameters using the same single character in their
constraints will fix these parameters equal to the coefficient times
some the same free parameter.  For instance, if 
<code>mean.constr = c(NA, 0, "a", "-a")</code>, then the first mean parameter
is unconstrained, the second is fixed at zero, and the third and forth
are constrained to be equal and opposite in sign.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_sd.constr">sd.constr</code></td>
<td>
<p>Equality constraints on the standard deviation parameters.
See <code>mean.constr</code>.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.  Convergence is declared when the change in 
the observed data log-likelihood increases by less than epsilon.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_maxrestarts">maxrestarts</code></td>
<td>
<p>The maximum number of restarts allowed in case of a problem
with the particular starting values chosen due to one of the variance
estimates getting too small
(each restart uses randomly chosen
starting values).  It is well-known that when each component of a normal
mixture may have its own mean and variance, the likelihood has no maximizer;
in such cases, we hope to find a &quot;nice&quot; local maximum with this algorithm
instead, but occasionally the algorithm finds a &quot;not nice&quot; solution and
one of the variances goes to zero, driving the likelihood to infinity.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each 
iteration of the algorithm.</p>
</td></tr> 
<tr><td><code id="normalmixEM_+3A_fast">fast</code></td>
<td>
<p>If TRUE and k==2 and arbmean==TRUE, then use 
<code><a href="#topic+normalmixEM2comp">normalmixEM2comp</a></code>, which is a much faster version of the EM 
algorithm for this case.
This version is less protected against certain kinds of underflow
that can cause numerical problems and it does not permit any restarts.  If
k&gt;2, <code>fast</code> is ignored.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_ecm">ECM</code></td>
<td>
<p>logical:  Should this algorithm be an ECM algorithm in the sense
of Meng and Rubin (1993)?  If FALSE, the algorithm is a true EM algorithm;
if TRUE, then every half-iteration alternately updates the means conditional
on the variances or the variances conditional on the means, with an extra
E-step in between these updates.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_arbmean">arbmean</code></td>
<td>
<p>If TRUE, then the component densities are allowed to have different <code>mu</code>s. If FALSE, then
a scale mixture will be fit.  Initial value ignored unless <code>mu</code> is NULL.</p>
</td></tr>
<tr><td><code id="normalmixEM_+3A_arbvar">arbvar</code></td>
<td>
<p>If TRUE, then the component densities are allowed to have different <code>sigma</code>s. If FALSE, then
a location mixture will be fit.  Initial value ignored unless <code>sigma</code> is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the standard EM algorithm for normal mixtures that maximizes
the conditional expected complete-data
log-likelihood at each M-step of the algorithm.
If desired, the
EM algorithm may be replaced by an ECM algorithm (see <code>ECM</code> argument)
that alternates between maximizing with respect to the <code>mu</code>
and <code>lambda</code> while holding <code>sigma</code> fixed, and maximizing with
respect to <code>sigma</code> and <code>lambda</code> while holding <code>mu</code>
fixed.  In the case where <code>arbmean</code> is <code>FALSE</code>
and <code>arbvar</code> is <code>TRUE</code>, there is no closed-form EM algorithm,
so the ECM option is forced in this case.
</p>


<h3>Value</h3>

<p><code>normalmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The final mean parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations. If <code>arbmean</code> = FALSE, then only the smallest standard
deviation is returned. See <code>scale</code> below.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>If <code>arbmean</code> = FALSE, then the scale factor for the component standard deviations is returned.
Otherwise, this is omitted from the output.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.  This vector
includes both the initial and the final values; thus, the number of iterations 
is one less than its length.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, 
John Wiley and Sons, Inc.
</p>
</li>
<li><p> Meng, X.-L. and Rubin, D. B. (1993) Maximum Likelihood Estimation
Via the ECM Algorithm:  A General Framework, <em>Biometrika</em> 80(2):
267-278.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D.
mixtools: An R package for analyzing finite mixture models.
Journal of Statistical Software, 32(6):1-29, 2009.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+mvnormalmixEM">mvnormalmixEM</a></code>, <code><a href="#topic+normalmixEM2comp">normalmixEM2comp</a></code>,
<code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Analyzing the Old Faithful geyser data with a 2-component mixture of normals.

data(faithful)
attach(faithful)
set.seed(100)
system.time(out&lt;-normalmixEM(waiting, arbvar = FALSE, epsilon = 1e-03))
out
system.time(out2&lt;-normalmixEM(waiting, arbvar = FALSE, epsilon = 1e-03, fast=TRUE))
out2 # same thing but much faster
</code></pre>

<hr>
<h2 id='normalmixEM2comp'>Fast EM Algorithm for 2-Component Mixtures of Univariate Normals</h2><span id='topic+normalmixEM2comp'></span>

<h3>Description</h3>

<p>Return EM algorithm output for mixtures of univariate normal distributions 
for the special case of 2 components, exploiting the simple structure of the
problem to speed up the code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalmixEM2comp(x, lambda, mu, sigsqrd, eps= 1e-8, maxit = 1000, verb=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalmixEM2comp_+3A_x">x</code></td>
<td>
<p>A vector of length <code class="reqn">n</code> consisting of the data.</p>
</td></tr>
<tr><td><code id="normalmixEM2comp_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of first-component mixing proportion.</p>
</td></tr>
<tr><td><code id="normalmixEM2comp_+3A_mu">mu</code></td>
<td>
<p>A 2-vector of initial values for the mean parameters.</p>
</td></tr>
<tr><td><code id="normalmixEM2comp_+3A_sigsqrd">sigsqrd</code></td>
<td>
<p>Either a scalar or a 2-vector with initial value(s) for
the variance parameters.  If a scalar, the algorithm assumes that the
two components have equal variances; if a 2-vector, it assumes that the
two components do not have equal variances.</p>
</td></tr>
<tr><td><code id="normalmixEM2comp_+3A_eps">eps</code></td>
<td>
<p>The convergence criterion.  Convergence is declared when the change in 
the observed data log-likelihood increases by less than epsilon.</p>
</td></tr>
<tr><td><code id="normalmixEM2comp_+3A_maxit">maxit</code></td>
<td>
<p>The maximum possible number of iterations.</p>
</td></tr>
<tr><td><code id="normalmixEM2comp_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This code is written to be very fast, sometimes more than an order of magnitude
faster than <code><a href="#topic+normalmixEM">normalmixEM</a></code> for the same problem.  It is less numerically
stable that <code><a href="#topic+normalmixEM">normalmixEM</a></code> in the sense that it does not safeguard 
against underflow as carefully.
</p>
<p>Note that when the two components are assumed to have unequal variances,
the loglikelihood is unbounded.  However, in practice this is rarely a problem
and quite often the algorithm converges to a &quot;nice&quot; local maximum.
</p>


<h3>Value</h3>

<p><code>normalmixEM2comp</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions (lambda and 1-lambda).</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The final two mean parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final one or two standard deviations. </p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nx2 matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.  This vector
includes both the initial and the final values; thus, the number of iterations 
is one less than its length.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to 
unacceptable choice of initial values (always zero).</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvnormalmixEM">mvnormalmixEM</a></code>, <code><a href="#topic+normalmixEM">normalmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Analyzing the Old Faithful geyser data with a 2-component mixture of normals.

data(faithful)
attach(faithful)
set.seed(100)
system.time(out &lt;- normalmixEM2comp(waiting, lambda=.5, 
            mu=c(50,80), sigsqrd=100))
out$all.loglik # Note:  must be monotone increasing

# Compare elapsed time with more general version
system.time(out2 &lt;- normalmixEM(waiting, lambda=c(.5,.5), 
            mu=c(50,80), sigma=c(10,10), arbvar=FALSE))
out2$all.loglik # Values should be identical to above
</code></pre>

<hr>
<h2 id='normalmixMMlc'>EC-MM Algorithm for Mixtures of Univariate Normals 
with linear constraints</h2><span id='topic+normalmixMMlc'></span>

<h3>Description</h3>

<p>Return EC-MM (see below) algorithm output for mixtures of normal distributions
with linear constraints on the means and variances parameters,
as in Chauveau and Hunter (2013).
The linear constraint for the means is of the form
<code class="reqn">\mu = M \beta + C</code>, where <code class="reqn">M</code> and <code class="reqn">C</code> are matrix 
and vector specified as parameters.
The linear constraints for the variances are actually specified on
the inverse variances, by <code class="reqn">\pi = A \gamma</code>, where <code class="reqn">\pi</code>
is the vector of inverse variances, and <code class="reqn">A</code> is a matrix
specified as a parameter (see below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalmixMMlc(x, lambda = NULL, mu = NULL, sigma = NULL, k = 2,
              mean.constr = NULL, mean.lincstr = NULL, 
              mean.constant = NULL, var.lincstr = NULL, 
              gparam = NULL, epsilon = 1e-08, maxit = 1000, 
              maxrestarts=20, verb = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalmixMMlc_+3A_x">x</code></td>
<td>
<p>A vector of length n consisting of the data.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Automatically 
repeated as necessary 
to produce a vector of length <code>k</code>, then normalized to sum to 1.
If <code>NULL</code>, then <code>lambda</code> is random from a uniform Dirichlet
distribution (i.e., its entries are uniform random and then it is 
normalized to sum to 1).</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_mu">mu</code></td>
<td>
<p>Starting value of vector of component means.
If non-NULL and a vector,
<code>k</code> is set to <code>length(mu)</code>.  If NULL, then the initial value
is randomly generated from a normal distribution with center(s) determined
by binning the data.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_sigma">sigma</code></td>
<td>
<p>Starting value of vector of component standard deviations 
for algorithm.  
Obsolete for linear constraints on the inverse variances;
use <code>gparam</code> instead to specify a starting value.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_k">k</code></td>
<td>
<p>Number of components.  Initial value ignored unless <code>mu</code> 
and <code>sigma</code> are both NULL.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_mean.constr">mean.constr</code></td>
<td>
<p>First, simplest way to define 
equality constraints on the mean parameters, given as
a vector of length <code>k</code>, as in <code><a href="#topic+normalmixEM">normalmixEM</a></code>.  
Each vector entry specifies the constraints,
if any, on the corresponding mean parameter:  If <code>NA</code>, the corresponding
parameter is unconstrained.  If numeric, the corresponding
parameter is fixed at that value.  If a character string consisting of
a single character preceded by a coefficient, such as <code>"0.5a"</code>
or <code>"-b"</code>, all parameters using the same single character in their
constraints will fix these parameters equal to the coefficient times
some the same free parameter.  For instance, if 
<code>mean.constr = c(NA, 0, "a", "-a")</code>, then the first mean parameter
is unconstrained, the second is fixed at zero, and the third and forth
are constrained to be equal and opposite in sign.
Note: if there are no linear constraints for the means, it is
more efficient to use directly <code><a href="#topic+normalmixEM">normalmixEM</a></code>.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_mean.lincstr">mean.lincstr</code></td>
<td>
<p>Matrix <code class="reqn">M</code> <code class="reqn">(k,p)</code> in the linear constraint for the means
equation <code class="reqn">\mu = M \beta + C</code>, with <code class="reqn">p \le k</code>.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_mean.constant">mean.constant</code></td>
<td>
<p>Vector of <code class="reqn">k</code> constants <code class="reqn">C</code> 
in the linear constraint for the means
equation <code class="reqn">\mu = M \beta + C</code>.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_var.lincstr">var.lincstr</code></td>
<td>
<p>Matrix <code class="reqn">A</code> <code class="reqn">(k,q)</code> in the linear constraint for the
inverse variances equation <code class="reqn">\pi = A \gamma</code>, with <code class="reqn">q \le k</code>.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_gparam">gparam</code></td>
<td>
<p>Vector of <code class="reqn">q</code> starting values
for the <code class="reqn">\gamma</code> parameter in the
linear constraint for the inverse variances;
see <code>var.lincstr</code>.  If NULL, a vector of randomly generated
standard exponential variables is used.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.  
Convergence is declared when the change in 
the observed data log-likelihood increases by less than epsilon.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_maxit">maxit</code></td>
<td>
<p>The maximum allowed number of iterations.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_maxrestarts">maxrestarts</code></td>
<td>
<p>The maximum number of restarts allowed in case of a problem
with the particular starting values chosen due to one of the variance
estimates getting too small
(each restart uses randomly chosen
starting values).  It is well-known that when each component of a normal
mixture may have its own mean and variance, the likelihood has no maximizer;
in such cases, we hope to find a &quot;nice&quot; local maximum with this algorithm
instead, but occasionally the algorithm finds a &quot;not nice&quot; solution and
one of the variances goes to zero, driving the likelihood to infinity.</p>
</td></tr>
<tr><td><code id="normalmixMMlc_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each 
iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This is a specific &quot;EC-MM&quot; algorithm for normal mixtures 
with linear constraints on the means and variances parameters.
EC-MM here means that this algorithm is similar to 
an ECM algorithm as in Meng and Rubin (1993), 
except that it uses conditional MM 
(Minorization-Maximization)-steps
instead of simple M-steps. Conditional means that it 
alternates between maximizing with respect to the <code>mu</code>
and <code>lambda</code> while holding <code>sigma</code> fixed, and maximizing with
respect to <code>sigma</code> and <code>lambda</code> while holding <code>mu</code>
fixed.  This ECM generalization of EM is forced in the case of linear constraints because there is no closed-form EM algorithm.
</p>


<h3>Value</h3>

<p><code>normalmixMMlc</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The final mean parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviation(s)</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>Scale factor for the component standard deviations, if applicable.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.  This vector
includes both the initial and the final values; thus, the number of iterations 
is one less than its length.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final <code class="reqn">\beta</code> parameter estimate.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>The final <code class="reqn">\gamma</code> parameter estimate.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, 
John Wiley &amp; Sons, Inc.
</p>
</li>
<li><p> Meng, X.-L. and Rubin, D. B. (1993) Maximum Likelihood Estimation
Via the ECM Algorithm:  A General Framework, <em>Biometrika</em> 80(2):
267-278.
</p>
</li>
<li><p> Chauveau, D. and Hunter, D.R. (2013)
ECM and MM algorithms for mixtures with constrained parameters,
<em>preprint <a href="https://hal.archives-ouvertes.fr/hal-00625285">https://hal.archives-ouvertes.fr/hal-00625285</a></em>.
</p>
</li>
<li><p> Thomas, H., Lohaus, A., and Domsch, H. (2011) Stable Unstable Reliability
Theory, <em>British Journal of Mathematical and Statistical Psychology</em>
65(2): 201-221.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+normalmixEM">normalmixEM</a></code>, <code><a href="#topic+mvnormalmixEM">mvnormalmixEM</a></code>, 
<code><a href="#topic+normalmixEM2comp">normalmixEM2comp</a></code>, <code><a href="#topic+tauequivnormalmixEM">tauequivnormalmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Analyzing synthetic data as in the tau equivalent model  
## From Thomas et al (2011), see also Chauveau and Hunter (2013)
## a 3-component mixture of normals with linear constraints.
lbd &lt;- c(0.6,0.3,0.1); m &lt;- length(lbd)
sigma &lt;- sig0 &lt;- sqrt(c(1,9,9))
# means constaints mu = M beta
M &lt;- matrix(c(1,1,1,0,-1,1), 3, 2)
beta &lt;- c(1,5) # unknown constrained mean
mu0 &lt;- mu &lt;- as.vector(M %*% beta)
# linear constraint on the inverse variances pi = A.g
A &lt;- matrix(c(1,1,1,0,1,0), m, 2, byrow=TRUE)
iv0 &lt;- 1/(sig0^2)
g0 &lt;- c(iv0[2],iv0[1] - iv0[2]) # gamma^0 init 

# simulation and EM fits
set.seed(50); n=100; x &lt;- rnormmix(n,lbd,mu,sigma)
s &lt;- normalmixEM(x,mu=mu0,sigma=sig0,maxit=2000) # plain EM
# EM with var and mean linear constraints
sc &lt;- normalmixMMlc(x, lambda=lbd, mu=mu0, sigma=sig0,
					mean.lincstr=M, var.lincstr=A, gparam=g0)
# plot and compare both estimates
dnormmixt &lt;- function(t, lam, mu, sig){
	m &lt;- length(lam); f &lt;- 0
	for (j in 1:m) f &lt;- f + lam[j]*dnorm(t,mean=mu[j],sd=sig[j])
	f}
t &lt;- seq(min(x)-2, max(x)+2, len=200)
hist(x, freq=FALSE, col="lightgrey", 
		ylim=c(0,0.3), ylab="density",main="")
lines(t, dnormmixt(t, lbd, mu, sigma), col="darkgrey", lwd=2) # true
lines(t, dnormmixt(t, s$lambda, s$mu, s$sigma), lty=2) 
lines(t, dnormmixt(t, sc$lambda, sc$mu, sc$sigma), col=1, lty=3)
legend("topleft", c("true","plain EM","constr EM"), 
	col=c("darkgrey",1,1), lty=c(1,2,3), lwd=c(2,1,1))
</code></pre>

<hr>
<h2 id='npEM'>Nonparametric EM-like Algorithm for Mixtures of Independent Repeated Measurements</h2><span id='topic+npEM'></span><span id='topic+npEMindrep'></span><span id='topic+npEMindrepbw'></span>

<h3>Description</h3>

<p>Returns nonparametric EM algorithm output (Benaglia et al, 2009) for mixtures
of multivariate (repeated measures) data where the coordinates of a row (case)
in the data matrix are assumed to be independent, conditional on the mixture
component (subpopulation) from which they are drawn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npEM(x, mu0, blockid = 1:ncol(x), 
     bw = bw.nrd0(as.vector(as.matrix(x))), samebw = TRUE, 
     h = bw, eps = 1e-8, 
     maxiter = 500, stochastic = FALSE, verb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npEM_+3A_x">x</code></td>
<td>
<p>An <code class="reqn">n\times r</code> matrix of data.  Each of the <code class="reqn">n</code> rows is a case,
and each case has <code class="reqn">r</code> repeated measurements.  These measurements are assumed
to be conditionally independent, conditional on the mixture component (subpopulation) 
from which the case is drawn.</p>
</td></tr>
<tr><td><code id="npEM_+3A_mu0">mu0</code></td>
<td>
<p>Either an <code class="reqn">m\times r</code> matrix specifying the initial
centers for the <a href="stats.html#topic+kmeans">kmeans</a> function, or an integer <code class="reqn">m</code> specifying the 
number of initial centers, which are then choosen randomly in
<a href="stats.html#topic+kmeans">kmeans</a></p>
</td></tr>
<tr><td><code id="npEM_+3A_blockid">blockid</code></td>
<td>
<p>A vector of length <code class="reqn">r</code> identifying coordinates 
(columns of <code>x</code>) that are
assumed to be identically distributed (i.e., in the same block).  For instance,
the default has all distinct elements, indicating that no two coordinates 
are assumed identically distributed and thus a separate set of <code class="reqn">m</code> 
density estimates is produced for each column of <code class="reqn">x</code>.  On the other hand,
if <code>blockid=rep(1,ncol(x))</code>, then the coordinates in each row 
are assumed conditionally i.i.d.</p>
</td></tr>
<tr><td><code id="npEM_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for density estimation, equal to the standard deviation 
of the kernel density.  By default, a simplistic application of the 
default <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> 
bandwidth used by <code><a href="stats.html#topic+density">density</a></code> to the entire dataset.</p>
</td></tr>
<tr><td><code id="npEM_+3A_samebw">samebw</code></td>
<td>
<p>Logical:  If <code>TRUE</code>, use the same bandwidth for
each iteration and for each component and block.  If <code>FALSE</code>, 
use a separate bandwidth for each component and block, and update
this bandwidth at each iteration of the algorithm using a suitably
modified <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> method as described in 
Benaglia et al (2011).</p>
</td></tr>
<tr><td><code id="npEM_+3A_h">h</code></td>
<td>
<p>Alternative way to specify the bandwidth, to provide backward 
compatibility.</p>
</td></tr>
<tr><td><code id="npEM_+3A_eps">eps</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence.  Convergence
is declared whenever the maximum change in any coordinate of the 
<code>lambda</code> vector (of mixing proportion estimates) does not exceed 
<code>eps</code>.</p>
</td></tr>
<tr><td><code id="npEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations allowed, for both 
stochastic and non-stochastic versions; 
for non-stochastic algorithms (<code>stochastic = FALSE</code>), convergence
may be declared before <code>maxiter</code> iterations (see <code>eps</code> above).</p>
</td></tr>
<tr><td><code id="npEM_+3A_stochastic">stochastic</code></td>
<td>
<p>Flag, if FALSE (the default), runs the non-stochastic version
of the npEM algorithm, as in Benaglia et al (2009). Set to TRUE to
run a stochastic version which simulates the posteriors at each
iteration, and runs for <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code id="npEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>npEM</code> returns a list of class <code>npEM</code> with the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The raw data (an <code class="reqn">n\times r</code> matrix).</p>
</td></tr>
<tr><td><code>posteriors</code></td>
<td>
<p>An <code class="reqn">n\times m</code> matrix of posterior probabilities for
observation. If <code>stochastic = TRUE</code>, this matrix is computed 
from an average over the <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>If <code>samebw==TRUE</code>, 
same as the <code>bw</code> input argument; otherwise, value of <code>bw</code> matrix
at final iteration.  This
information is needed by any method that produces density estimates from the
output.</p>
</td></tr>
<tr><td><code>blockid</code></td>
<td>
<p>Same as the <code>blockid</code> input argument, but recoded to have
positive integer values.  Also needed by any method that produces density 
estimates from the output.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>lambdahat</code></td>
<td>
<p>The final mixing proportions if <code>stochastic = FALSE</code>, 
or the average mixing proportions if <code>stochastic = TRUE</code>.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The sequence of log-likelihoods over iterations.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D. (2009),
mixtools: An R package for analyzing finite mixture models.
Journal of Statistical Software, 32(6):1-29.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D. and Hunter, D.R. (2011),
Bandwidth Selection in an EM-like algorithm for nonparametric multivariate mixtures.
Nonparametric Statistics and Mixture Models: A Festschrift in
Honor of Thomas P. Hettmansperger. World Scientific Publishing Co., 
pages 15-27.
</p>
</li>
<li><p> Bordes, L., Chauveau, D., and Vandekerkhove, P. (2007),
An EM algorithm for a semiparametric mixture model, 
Computational Statistics and Data Analysis, 51: 5429-5443.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.npEM">plot.npEM</a></code>, <code><a href="#topic+normmixrm.sim">normmixrm.sim</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>,
<code><a href="#topic+spEM">spEM</a></code>, <code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examine and plot water-level task data set.

## First, try a 3-component solution where no two coordinates are
## assumed i.d.
data(Waterdata)
set.seed(100)
## Not run: 
a &lt;- npEM(Waterdata[,3:10], mu0=3, bw=4) # Assume indep but not iid
plot(a) # This produces 8 plots, one for each coordinate

## End(Not run)

## Next, same thing but pairing clock angles that are directly opposite one
## another (1:00 with 7:00, 2:00 with 8:00, etc.)
## Not run: 
b &lt;- npEM(Waterdata[,3:10], mu0=3, blockid=c(4,3,2,1,3,4,1,2), bw=4) # iid in pairs
plot(b) # Now only 4 plots, one for each block

## End(Not run)
</code></pre>

<hr>
<h2 id='npMSL'>Nonparametric EM-like Algorithm for Mixtures of Independent Repeated Measurements - Maximum Smoothed Likelihood version</h2><span id='topic+npMSL'></span>

<h3>Description</h3>

<p>Returns nonparametric Smoothed Likelihood algorithm output 
(Levine et al, 2011) for mixtures
of multivariate (repeated measures) data where the coordinates of a row (case)
in the data matrix are assumed to be independent, conditional on the mixture
component (subpopulation) from which they are drawn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npMSL(x, mu0, blockid = 1:ncol(x), 
      bw = bw.nrd0(as.vector(as.matrix(x))), samebw = TRUE, 
      bwmethod = "S", h = bw, eps = 1e-8, 
      maxiter=500, bwiter = maxiter, nbfold = NULL,
      ngrid=200, post=NULL, verb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npMSL_+3A_x">x</code></td>
<td>
<p>An <code class="reqn">n\times r</code> matrix of data.  Each of the <code class="reqn">n</code> rows is a case,
and each case has <code class="reqn">r</code> repeated measurements.  These measurements are assumed
to be conditionally independent, conditional on the mixture component (subpopulation) 
from which the case is drawn.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_mu0">mu0</code></td>
<td>
<p>Either an <code class="reqn">m\times r</code> matrix specifying the initial
centers for the <a href="stats.html#topic+kmeans">kmeans</a> function, or an integer <code class="reqn">m</code> specifying the 
number of initial centers, which are then choosen randomly in
<a href="stats.html#topic+kmeans">kmeans</a></p>
</td></tr>
<tr><td><code id="npMSL_+3A_blockid">blockid</code></td>
<td>
<p>A vector of length <code class="reqn">r</code> identifying coordinates 
(columns of <code>x</code>) that are
assumed to be identically distributed (i.e., in the same block).  
For instance,
the default has all distinct elements, indicating that no two coordinates 
are assumed identically distributed and thus a separate set of <code class="reqn">m</code> 
density estimates is produced for each column of <code class="reqn">x</code>.  On the other hand,
if <code>blockid=rep(1,ncol(x))</code>, then the coordinates in each row 
are assumed conditionally i.i.d.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for density estimation, equal to the standard deviation 
of the kernel density.  By default, a simplistic application of the 
default <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> 
bandwidth used by <code><a href="stats.html#topic+density">density</a></code> to the entire dataset.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_samebw">samebw</code></td>
<td>
<p>Logical:  If <code>TRUE</code>, use the same bandwidth for
each iteration and for each component and block.  If <code>FALSE</code>, 
use a separate bandwidth for each component and block, and update
this bandwidth at each iteration of the algorithm 
until <code>bwiter</code> is reached (see below). Two adaptation methods are provided, 
see <code>bwmethod</code> below.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_bwmethod">bwmethod</code></td>
<td>
<p>Define the adaptive bandwidth strategy when <code>samebw = FALSE</code>, in which case
the bandwidth depends on each component, block, and iteration of the algorithm.
If set to &quot;S&quot; (the default), adaptation is done using a suitably
modified <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> method as described in 
Benaglia et al (2011).
If set to &quot;CV&quot;, an adaptive <code class="reqn">k</code>-fold Cross Validation method is applied,
as described in Chauveau et al (2014), where <code>nbfold</code> is the number of subsamples.
This corresponds to a Leave-<code class="reqn">[n/nbfold]</code>-Out CV.
</p>
</td></tr>
<tr><td><code id="npMSL_+3A_h">h</code></td>
<td>
<p>Alternative way to specify the bandwidth, to provide backward 
compatibility.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_eps">eps</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence.  Convergence
is declared whenever the maximum change in any coordinate of the 
<code>lambda</code> vector (of mixing proportion estimates) does not exceed 
<code>eps</code>.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations allowed, convergence
may be declared before <code>maxiter</code> iterations (see <code>eps</code> above).</p>
</td></tr>
<tr><td><code id="npMSL_+3A_bwiter">bwiter</code></td>
<td>
<p>The maximum number of iterations allowed for adaptive bandwidth stage,
when <code>samebw = FALSE</code>. If set to <code>0</code>, then the initial bandwidth matrix is used without adaptation.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_nbfold">nbfold</code></td>
<td>
<p>A parameter passed to the internal function <code>wbs.kCV</code>, which controls the weighted bandwidth selection by k-fold cross-validation.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_ngrid">ngrid</code></td>
<td>
<p>Number of points in the discretization of the intervals over which are approximated the (univariate) integrals for non linear smoothing of the log-densities, as required in the E step of the npMSL algorithm,
see Levine et al (2011).</p>
</td></tr>
<tr><td><code id="npMSL_+3A_post">post</code></td>
<td>
<p>If non-NULL, an <code class="reqn">n\times m</code> matrix specifying the initial 
posterior probability vectors for each of the observations, i.e., the
initial values to start the EM-like algorithm.</p>
</td></tr>
<tr><td><code id="npMSL_+3A_verb">verb</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>npMSL</code> returns a list of class <code>npEM</code> with the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The raw data (an <code class="reqn">n\times r</code> matrix).</p>
</td></tr>
<tr><td><code>posteriors</code></td>
<td>
<p>An <code class="reqn">n\times m</code> matrix 
of posterior probabilities for
observation.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>If <code>samebw==TRUE</code>, 
same as the <code>bw</code> input argument; otherwise, value of <code>bw</code> matrix
at final iteration.  This
information is needed by any method that produces density estimates from the
output.</p>
</td></tr>
<tr><td><code>blockid</code></td>
<td>
<p>Same as the <code>blockid</code> input argument, but recoded to have
positive integer values.  Also needed by any method that produces density 
estimates from the output.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>lambdahat</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The sequence of log-likelihoods over iterations.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>An array of size <code class="reqn">ngrid \times m \times l</code>,
returning last values of density for component <code class="reqn">j</code>
and block <code class="reqn">k</code> over <code>grid</code> points.</p>
</td></tr>
<tr><td><code>meanNaN</code></td>
<td>
<p>Average number of <code>NaN</code> that occured over iterations (for internal testing and control purpose).</p>
</td></tr>
<tr><td><code>meanUdfl</code></td>
<td>
<p>Average number of &quot;underflow&quot; that occured over iterations (for internal testing and control purpose).</p>
</td></tr>
</table>


<h3>References</h3>

   	   
<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D. and Hunter, D.R. (2011),
Bandwidth Selection in an EM-like algorithm for nonparametric multivariate mixtures.
Nonparametric Statistics and Mixture Models: A Festschrift in
Honor of Thomas P. Hettmansperger. World Scientific Publishing Co., 
pages 15-27.
</p>
</li>
<li><p> Chauveau D., Hunter D. R. and Levine M. (2014),
Semi-Parametric Estimation for Conditional Independence Multivariate Finite Mixture Models.
Preprint (under revision).
</p>
</li>
<li><p> Levine, M., Hunter, D. and Chauveau, D. (2011),
Maximum Smoothed Likelihood for Multivariate Mixtures,
Biometrika 98(2): 403-416.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+plot.npEM">plot.npEM</a></code>, 
<code><a href="#topic+normmixrm.sim">normmixrm.sim</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>,
<code><a href="#topic+spEM">spEM</a></code>, <code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examine and plot water-level task data set.
## Block structure pairing clock angles that are directly opposite one
## another (1:00 with 7:00, 2:00 with 8:00, etc.)
set.seed(111) # Ensure that results are exactly reproducible
data(Waterdata)
blockid &lt;- c(4,3,2,1,3,4,1,2) # see Benaglia et al (2009a)

## Not run: 
a &lt;- npEM(Waterdata[,3:10], mu0=3, blockid=blockid, bw=4)  # npEM solution
b &lt;- npMSL(Waterdata[,3:10], mu0=3, blockid=blockid, bw=4) # smoothed version

# Comparisons on the 4 default plots, one for each block
par(mfrow=c(2,2))
for (l in 1:4){
plot(a, blocks=l, breaks=5*(0:37)-92.5,
	xlim=c(-90,90), xaxt="n",ylim=c(0,.035), xlab="")
plot(b, blocks=l, hist=FALSE, newplot=FALSE, addlegend=FALSE, lty=2,
	dens.col=1)
axis(1, at=30*(1:7)-120, cex.axis=1)
legend("topleft",c("npMSL"),lty=2, lwd=2)}

## End(Not run)

</code></pre>

<hr>
<h2 id='parse.constraints'>Constraint Function</h2><span id='topic+parse.constraints'></span>

<h3>Description</h3>

<p>Constraint function for some mixture EM algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse.constraints(constr, k = 2, allsame = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse.constraints_+3A_constr">constr</code></td>
<td>
<p>Vector indicating constrained/unconstrained means.</p>
</td></tr>
<tr><td><code id="parse.constraints_+3A_k">k</code></td>
<td>
<p>Number of components.</p>
</td></tr>
<tr><td><code id="parse.constraints_+3A_allsame">allsame</code></td>
<td>
<p>Logical indicating for processing the constraints.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is not intended to be called by the user.
</p>

<hr>
<h2 id='perm'>Permutation Function</h2><span id='topic+perm'></span>

<h3>Description</h3>

<p>Enumerates the possible permutations of a specified size from the elements of a vector having the same size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perm(n, r, v = 1:n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perm_+3A_n">n</code></td>
<td>
<p>Size of the source vector.</p>
</td></tr>
<tr><td><code id="perm_+3A_r">r</code></td>
<td>
<p>Size of the target vector.</p>
</td></tr>
<tr><td><code id="perm_+3A_v">v</code></td>
<td>
<p>Source vector.  Must be a vector of length <code>n</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code>segregmixEM</code> and the associated internal functions.  This is also a simplified version of the function <code>permutations</code> found in the package <code>gtools</code>.
</p>


<h3>Value</h3>

<p><code>perm</code> returns a matrix where each row contains one of the permutations of length <code>r</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+segregmixEM">segregmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>perm(3, 3, 2:4)
</code></pre>

<hr>
<h2 id='plot.mixEM'>Various Plots Pertaining to Mixture Models</h2><span id='topic+plot.mixEM'></span>

<h3>Description</h3>

<p>Takes an object of class <code>mixEM</code> and returns various graphical output for select mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixEM'
plot(x, whichplots = 1, 
     loglik = 1 %in% whichplots,
     density = 2 %in% whichplots,
     xlab1="Iteration", ylab1="Log-Likelihood",
     main1="Observed Data Log-Likelihood", col1=1, lwd1=2,
     xlab2=NULL, ylab2=NULL, main2=NULL, col2=NULL, 
     lwd2=2, alpha = 0.05, marginal = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mixEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>mixEM</code>.</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_whichplots">whichplots</code></td>
<td>
<p>vector telling which plots to produce:  1 = loglikelihood
plot, 2 = density plot.  Irrelevant if <code>loglik</code> and <code>density</code>
are specified.</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_loglik">loglik</code></td>
<td>
<p>If TRUE, a plot of the log-likelihood versus the EM iterations is given.</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_density">density</code></td>
<td>
<p>Graphics pertaining to certain mixture models.  The details are given below.</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_xlab1">xlab1</code>, <code id="plot.mixEM_+3A_ylab1">ylab1</code>, <code id="plot.mixEM_+3A_main1">main1</code>, <code id="plot.mixEM_+3A_col1">col1</code>, <code id="plot.mixEM_+3A_lwd1">lwd1</code></td>
<td>
<p>Graphical parameters <code>xlab</code>, ..., <code>lwd</code>
to be passed to the loglikelihood plot.  Trying to change these parameters using
<code>xlab</code>, ..., <code>lwd</code> will result in an error, but all other graphical parameters
are passed directly to the plotting functions via ...</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_xlab2">xlab2</code>, <code id="plot.mixEM_+3A_ylab2">ylab2</code>, <code id="plot.mixEM_+3A_main2">main2</code>, <code id="plot.mixEM_+3A_col2">col2</code>, <code id="plot.mixEM_+3A_lwd2">lwd2</code></td>
<td>
<p>Same as <code>xlab1</code> etc. but for the
density plot</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_alpha">alpha</code></td>
<td>
<p>A vector of significance levels when constructing confidence ellipses and confidence bands for the mixture
of multivariate normals and mixture of regressions cases, respectively.  The default is 0.05.</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_marginal">marginal</code></td>
<td>
<p>For the mixture of bivariate normals, should optional marginal histograms be included?</p>
</td></tr>
<tr><td><code id="plot.mixEM_+3A_...">...</code></td>
<td>
<p>Graphical parameters passed to <code>plot</code> command.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plot.mixEM</code> returns a plot of the log-likelihood versus the EM iterations by default for all objects of class
<code>mixEM</code>.  In addition, other plots may be produced for the following k-component mixture model functions:
</p>
<table>
<tr><td><code>normalmixEM</code></td>
<td>
<p>A histogram of the raw data is produced along with k density curves determined by <code>normalmixEM</code>.</p>
</td></tr>
<tr><td><code>repnormmixEM</code></td>
<td>
<p>A histogram of the raw data produced in a similar manner as for <code>normalmixEM</code>.</p>
</td></tr>
<tr><td><code>mvnormalmixEM</code></td>
<td>
<p>A 2-dimensional plot with each point color-coded to denote its most probable component membership. In
addition, the estimated component means are plotted along with (1 - <code>alpha</code>)% bivariate normal density contours.  These ellipses are
constructed by assigning each value to their component of most probable membership and then using normal theory. Optional marginal histograms
may also be produced.</p>
</td></tr>
<tr><td><code>regmixEM</code></td>
<td>
<p>A plot of the response versus the predictor with each point color-coded to denote its most probable component
membership.  In addition, the estimated component regression lines are plotted along with (1 - <code>alpha</code>)% Working-Hotelling 
confidence bands. These bands are constructed by assigning each value to their component of most probable membership and then
performing least squares estimation.</p>
</td></tr>
<tr><td><code>logisregmixEM</code></td>
<td>
<p>A plot of the binary response versus the predictor with each point color-coded to denote its most probable
compopnent membership.  In addition, the estimate component logistic regression lines are plotted.</p>
</td></tr>
<tr><td><code>regmixEM.mixed</code></td>
<td>
<p>Provides a 2x2 matrix of plots summarizing the posterior slope and posterior intercept terms from a
mixture of random effects regression.  See <code>post.beta</code> for a more detailed description.</p>
</td></tr>
</table>


<h3>See Also</h3>

 
<p><code><a href="#topic+post.beta">post.beta</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
##Analyzing the Old Faithful geyser data with a 2-component mixture of normals.

data(faithful)
attach(faithful)
set.seed(100)
out &lt;- normalmixEM(waiting, arbvar = FALSE, verb = TRUE,
                   epsilon = 1e-04)
plot(out, density = TRUE, w = 1.1)

##Fitting randomly generated data with a 2-component location mixture of bivariate normals.

x.1 &lt;- rmvnorm(40, c(0, 0))
x.2 &lt;- rmvnorm(60, c(3, 4))
X.1 &lt;- rbind(x.1, x.2)

out.1 &lt;- mvnormalmixEM(X.1, arbvar = FALSE, verb = TRUE,
                       epsilon = 1e-03)
plot(out.1, density = TRUE, alpha = c(0.01, 0.05, 0.10), 
     marginal = TRUE)

</code></pre>

<hr>
<h2 id='plot.mixMCMC'>Various Plots Pertaining to Mixture Model Output Using MCMC Methods</h2><span id='topic+plot.mixMCMC'></span>

<h3>Description</h3>

<p>Takes an object of class <code>mixMCMC</code> and returns various graphical output for select mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
## S3 method for class 'mixMCMC'
plot(x, trace.plots = TRUE, 
     summary.plots = FALSE, burnin = 2000, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mixMCMC_+3A_x">x</code></td>
<td>
<p>An object of class <code>mixMCMC</code>.</p>
</td></tr>
<tr><td><code id="plot.mixMCMC_+3A_trace.plots">trace.plots</code></td>
<td>
<p>If TRUE, trace plots of the various parameters estimated by the MCMC methods is given.</p>
</td></tr>
<tr><td><code id="plot.mixMCMC_+3A_summary.plots">summary.plots</code></td>
<td>
<p>Graphics pertaining to certain mixture models.  The details are given below.</p>
</td></tr>
<tr><td><code id="plot.mixMCMC_+3A_burnin">burnin</code></td>
<td>
<p>The values 1 to <code>burnin</code> are dropped when producing the plots in <code>summary.plots</code>.</p>
</td></tr>
<tr><td><code id="plot.mixMCMC_+3A_...">...</code></td>
<td>
<p>Graphical parameters passed to <code>regcr</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plot.mixMCMC</code> returns trace plots of the various parameters estimated by the MCMC methods for all objects of class
<code>mixMCMC</code>.  In addition, other plots may be produced for the following k-component mixture model functions:
</p>
<table>
<tr><td><code>regmixMH</code></td>
<td>
<p>Credible bands for the regression lines in a mixture of linear regressions.  See <code>regcr</code> for more details.</p>
</td></tr>
</table>


<h3>See Also</h3>

 
<p><code><a href="#topic+regcr">regcr</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## M-H algorithm for NOdata with acceptance rate about 40%.

data(NOdata)
attach(NOdata)
set.seed(100)
beta &lt;- matrix(c(1.3, -0.1, 0.6, 0.1), 2, 2)
sigma &lt;- c(.02, .05)
MH.out &lt;- regmixMH(Equivalence, NO, beta = beta, s = sigma, 
                   sampsize = 2500, omega = .0013)
plot(MH.out, summary.plots = TRUE, burnin = 2450, 
     alpha = 0.01)
</code></pre>

<hr>
<h2 id='plot.mvnpEM'>Plots of Marginal Density Estimates from the mvnpEM Algorithm Output</h2><span id='topic+plot.mvnpEM'></span>

<h3>Description</h3>

<p>Takes an object of class <code>mvnpEM</code>, as the one returned by the  <code><a href="#topic+mvnpEM">mvnpEM</a></code>
algorithm, and returns a set of plots of the 
density estimates for each coordinate within each multivariate block.
All the components are displayed on each plot so it is possible
to see the mixture structure for each coordinate and block. The final bandwidth values are also displayed,
in a format depending on the bandwidth strategy .     
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvnpEM'
plot(x, truenorm = FALSE, lambda = NULL, mu = NULL, v = NULL, 
            lgdcex = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mvnpEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>mvnpEM</code> such as the output
of the <code><a href="#topic+mvnpEM">mvnpEM</a></code> function</p>
</td></tr>
<tr><td><code id="plot.mvnpEM_+3A_truenorm">truenorm</code></td>
<td>
<p>Mostly for checking purpose, if the nonparametric model is to be compared
with a multivariate Gaussian mixture as the true model.</p>
</td></tr>
<tr><td><code id="plot.mvnpEM_+3A_lambda">lambda</code></td>
<td>
<p>true weight parameters, for Gaussian models only (see above)</p>
</td></tr>
<tr><td><code id="plot.mvnpEM_+3A_mu">mu</code></td>
<td>
<p>true mean parameters, for Gaussian models only (see above)</p>
</td></tr>
<tr><td><code id="plot.mvnpEM_+3A_v">v</code></td>
<td>
<p>true covariance matrices, for Gaussian models only (see above)</p>
</td></tr>
<tr><td><code id="plot.mvnpEM_+3A_lgdcex">lgdcex</code></td>
<td>
<p>Character expansion factor for <code><a href="graphics.html#topic+legend">legend</a></code>.</p>
</td></tr>
<tr><td><code id="plot.mvnpEM_+3A_...">...</code></td>
<td>
<p>Any remaining arguments are passed to <code><a href="graphics.html#topic+hist">hist</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plot.mvnpEM</code> currently just plots the figure.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+mvnpEM">mvnpEM</a></code>, <code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+density.npEM">density.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
# example as in Chauveau and Hoang (2015) with 6 coordinates
## Not run: 
m=2; r=6; blockid &lt;-c(1,1,2,2,3,3) # 3 bivariate blocks 
# generate some data x ...
a &lt;- mvnpEM(x, mu0=2, blockid, samebw=F) # adaptive bandwidth
plot(a) # this S3 method produces 6 plots of univariate marginals
summary(a)
## End(Not run)
</code></pre>

<hr>
<h2 id='plot.npEM'>Plot Nonparametric or Semiparametric EM Output</h2><span id='topic+plot.npEM'></span><span id='topic+plot.spEM'></span>

<h3>Description</h3>

<p>Takes an object of class <code>npEM</code> and returns a set of plots of the 
density estimates for each block and each component.  There is one plot
per block, with all the components displayed on each block so it is possible
to see the mixture structure for each block.      
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'npEM'
plot(x, blocks = NULL, hist=TRUE, addlegend = TRUE,
      scale=TRUE, title=NULL, breaks="Sturges", ylim=NULL, dens.col,
      newplot = TRUE, pos.legend = "topright", cex.legend = 1, ...)         
## S3 method for class 'spEM'
plot(x, blocks = NULL, hist=TRUE, addlegend = TRUE,
      scale=TRUE, title=NULL, breaks="Sturges", ylim=NULL, dens.col,
      newplot = TRUE, pos.legend = "topright", cex.legend = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.npEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>npEM</code> such as the output
of the <code><a href="#topic+npEM">npEM</a></code> function</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_blocks">blocks</code></td>
<td>
<p>Blocks (of repeated measures coordinates) to plot; not relevant
for univariate case.  Default is to plot all blocks.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_hist">hist</code></td>
<td>
<p>If TRUE, superimpose density estimate plots on a histogram
of the data</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_addlegend">addlegend</code></td>
<td>
<p>If TRUE, adds legend to the plot.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_scale">scale</code></td>
<td>
<p>If TRUE, scale each density estimate by its corresponding estimated
mixing proportion, so that the total area under all densities equals 1 and the 
densities plotted may be added to produce an estimate of the mixture density.
When FALSE, each density curve has area 1 in the plot.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_title">title</code></td>
<td>
<p>Alternative vector of main titles for plots (recycled as many times
as needed)</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_breaks">breaks</code></td>
<td>
<p>Passed directly to the <code><a href="graphics.html#topic+hist">hist</a></code> function</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_ylim">ylim</code></td>
<td>
<p><code>ylim</code> parameter to use for all plots, if desired.  If not
given, each plot uses its own ylim that ensures that no part of the plot will
go past the top of the plotting area.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_dens.col">dens.col</code></td>
<td>
<p>Color values to use for the individual component density
functions, repeated as necessary.  Default value is <code>2:(m+1)</code>.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_newplot">newplot</code></td>
<td>
<p>If TRUE, creates a new plot.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_pos.legend">pos.legend</code></td>
<td>
<p>Single argument specifying the 
position of the legend.  See &lsquo;Details&rsquo; section of
<code><a href="graphics.html#topic+legend">legend</a></code>.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_cex.legend">cex.legend</code></td>
<td>
<p>Character expansion factor for <code><a href="graphics.html#topic+legend">legend</a></code>.</p>
</td></tr>
<tr><td><code id="plot.npEM_+3A_...">...</code></td>
<td>
<p>Any remaining arguments are passed to the <code><a href="graphics.html#topic+hist">hist</a></code> and 
<code><a href="graphics.html#topic+lines">lines</a></code> functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plot.npEM</code> returns a list with two elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>List of matrices.  The <code class="reqn">j</code>th column of the <code class="reqn">i</code>th matrix is the vector of 
<code class="reqn">x</code>-values for the <code class="reqn">j</code>th density in the <code class="reqn">i</code>th plot.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p><code class="reqn">y</code>-values, given in the same form as the <code class="reqn">x</code>-values.</p>
</td></tr>
</table>


<h3>See Also</h3>

 
<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+density.npEM">density.npEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>,
<code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Examine and plot water-level task data set.

## First, try a 3-component solution where no two coordinates are
## assumed i.d.
data(Waterdata)
set.seed(100)
## Not run: 
a &lt;- npEM(Waterdata[,3:10], 3, bw=4)
par(mfrow=c(2,4))
plot(a) # This produces 8 plots, one for each coordinate

## End(Not run)

## Not run: 
## Next, same thing but pairing clock angles that are directly opposite one
## another (1:00 with 7:00, 2:00 with 8:00, etc.)
b &lt;- npEM(Waterdata[,3:10], 3, blockid=c(4,3,2,1,3,4,1,2), bw=4)
par(mfrow=c(2,2))
plot(b) # Now only 4 plots, one for each block

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.spEMN01'>Plot mixture pdf for the semiparametric mixture model output by spEMsymlocN01</h2><span id='topic+plot.spEMN01'></span>

<h3>Description</h3>

<p>Plot mixture density for the semiparametric mixture model output by spEMsymlocN01, with one component known and set to normal(0,1), and a symmetric nonparametric density with location parameter.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spEMN01'
plot(x, bw = x$bandwidth, knownpdf = dnorm, add.plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.spEMN01_+3A_x">x</code></td>
<td>
<p>An object of class &quot;spEMN01&quot; as returned by spEMsymlocN01</p>
</td></tr>
<tr><td><code id="plot.spEMN01_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for weighted kernel density estimation.</p>
</td></tr>
<tr><td><code id="plot.spEMN01_+3A_knownpdf">knownpdf</code></td>
<td>
<p>The known density of component 1, default to <code>dnorm</code>.</p>
</td></tr>
<tr><td><code id="plot.spEMN01_+3A_add.plot">add.plot</code></td>
<td>
<p>Set to TRUE to add to an existing plot.</p>
</td></tr>
<tr><td><code id="plot.spEMN01_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>plot</code> if <code>add.plot = FALSE</code>,
and to <code>lines</code> if <code>add.plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the density of the mixture</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D., Saby, N., Orton, T. G., Lemercier B., Walter, C. and Arrouys, D.
Large-scale simultaneous hypothesis testing in soil monitoring:
A semi-parametric mixture approach, preprint (2013).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code></p>

<hr>
<h2 id='plotexpRMM'>Plot sequences from the EM algorithm for censored mixture of exponentials
</h2><span id='topic+plotexpRMM'></span>

<h3>Description</h3>

<p>Function for plotting sequences of estimates along iterations, from an object returned by the <code><a href="#topic+expRMM_EM">expRMM_EM</a></code>, an EM algorithm for mixture of exponential 
distributions with randomly right censored data (see reference below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotexpRMM(a, title=NULL, rowstyle=TRUE, subtitle=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotexpRMM_+3A_a">a</code></td>
<td>
<p>An object returned by <code><a href="#topic+expRMM_EM">expRMM_EM</a></code>.</p>
</td></tr>
<tr><td><code id="plotexpRMM_+3A_title">title</code></td>
<td>
<p>The title of the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotexpRMM_+3A_rowstyle">rowstyle</code></td>
<td>
<p>Window organization, for plots in rows (the default) or columns.</p>
</td></tr>
<tr><td><code id="plotexpRMM_+3A_subtitle">subtitle</code></td>
<td>
<p>A subtitle for the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotexpRMM_+3A_...">...</code></td>
<td>
<p>Other parameters (such as <code>lwd</code>) passed to <code>plot</code>, <code>lines</code>, and  
<code>legend</code> commands.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The plot returned</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions: 
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,   <code><a href="#topic+summary.mixEM">summary.mixEM</a></code>, <code><a href="#topic+plot.mixEM">plot.mixEM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>, <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=300 # sample size
m=2   # number of mixture components
lambda &lt;- c(1/3,1-1/3); rate &lt;- c(1,1/10) # mixture parameters
set.seed(1234)
x &lt;- rexpmix(n, lambda, rate) # iid ~ exponential mixture
cs=runif(n,0,max(x)) # Censoring (uniform) and incomplete data
t &lt;- apply(cbind(x,cs),1,min) # observed or censored data
d &lt;- 1*(x &lt;= cs)              # censoring indicator

###### EM for RMM, exponential lifetimes
l0 &lt;- rep(1/m,m); r0 &lt;- c(1, 0.5) # "arbitrary" initial values
a &lt;- expRMM_EM(t, d, lambda=l0, rate=r0, k = m)
summary(a)             # EM estimates etc
plotexpRMM(a, lwd=2) # plot of EM sequences
</code></pre>

<hr>
<h2 id='plotFDR'>Plot False Discovery Rate (FDR) estimates from output by EM-like strategies</h2><span id='topic+plotFDR'></span>

<h3>Description</h3>

<p>Plot FDR<code class="reqn">(p_i)</code> estimates against index of sorted p-values
from, e.g., normalmixEM or the semiparametric mixture model posterior probabilities
output by <code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>, or any EM-algorithm like
<code><a href="#topic+normalmixEM">normalmixEM</a></code> which returns posterior probabilities. The function
can simultaneously plot FDR estimates from two strategies for comparison.
Plot of the true FDR can be added if complete data are available 
(typically in simulation studies).</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFDR(post1, post2 = NULL, lg1 = "FDR 1", lg2 = NULL, title = NULL, 
        compH0 = 1, alpha = 0.1, complete.data = NULL, pctfdr = 0.3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotFDR_+3A_post1">post1</code></td>
<td>
<p>The matrix of posterior probabilities from objects such as the output
from <code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>. The rows need to be sorted by increasing pvalues.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_post2">post2</code></td>
<td>
<p>A second object like <code>post1</code> if comparison is desired, also sorted by increasing pvalues.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_lg1">lg1</code></td>
<td>
<p>Text describing the FDR estimate in <code>post1</code>.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_lg2">lg2</code></td>
<td>
<p>Text describing the FDR estimate in <code>post2</code> if provided.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_title">title</code></td>
<td>
<p>Plot title, a default is provided if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_comph0">compH0</code></td>
<td>
<p>The component indicator associated to the null hypothesis H0,
normally 1 since it is defined in this way in <code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>, but in case of label switching in other algorithms it can be set to <code>2</code>.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_alpha">alpha</code></td>
<td>
<p>The target FDR level; the index at which the FDR estimate crosses the horizontal line for level <code>alpha</code> gives the maximum number of cases to reject.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_complete.data">complete.data</code></td>
<td>
<p>An array with <code class="reqn">n</code> lines and 2 columns, with the component indicator in column 1 and the p-values in column 2, sorted by p-values.</p>
</td></tr>
<tr><td><code id="plotFDR_+3A_pctfdr">pctfdr</code></td>
<td>
<p>The level up to which the FDR is plotted, i.e. 
the scale of the vertical axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of one or two FDR estimates, with the true FDR if available</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D., Saby, N., Orton, T. G., Lemercier B., Walter, C. and Arrouys, D.
Large-scale simultaneous hypothesis testing in monitoring carbon content 
from French soil database &ndash; A semi-parametric mixture approach, Geoderma 219-220 (2014), 117-124.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code></p>

<hr>
<h2 id='plotly_compCDF'>Plot the Component CDF using <code>plotly</code></h2><span id='topic+plotly_compCDF'></span>

<h3>Description</h3>

<p>Plot the components' CDF via the posterior probabilities using <code>plotly</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_compCDF(data, weights, x=seq(min(data, na.rm=TRUE), max(data, na.rm=TRUE), 
               len=250), comp=1:NCOL(weights), makeplot=TRUE,
               cex = 3, width = 3,
               legend.text = "Composition", legend.text.size = 15, legend.size = 15,
               title = "Empirical CDF", title.x = 0.5, title.y = 0.95, title.size = 15,
               xlab = "Data", xlab.size = 15, xtick.size = 15,
               ylab = "Probability", ylab.size = 15, ytick.size = 15,
               col.comp = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_compCDF_+3A_data">data</code></td>
<td>
<p>A matrix containing the raw data. Rows are subjects and columns
are repeated measurements.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_weights">weights</code></td>
<td>
<p>The weights to compute the empirical CDF; however, most of
time they are the posterior probabilities.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_x">x</code></td>
<td>
<p>The points at which the CDFs are to be evaluated.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_comp">comp</code></td>
<td>
<p>The mixture components for which CDFs are desired.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_makeplot">makeplot</code></td>
<td>
<p>Logical:  Should a plot be produced as a side effect?</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_cex">cex</code></td>
<td>
<p>Size of markers.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_legend.text">legend.text</code></td>
<td>
<p>Title of legend.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>Size of the legend title.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
<tr><td><code id="plotly_compCDF_+3A_col.comp">col.comp</code></td>
<td>
<p>Color of compositions. Number of color specified needs to be consistent with number of compositions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>makeplot</code> is <code>TRUE</code>, a line plot is produced of the
CDFs evaluated at <code>x</code>.  The plot is not a step function plot; 
the points <code class="reqn">(x, CDF(x))</code> are simply joined by line segments.
</p>


<h3>Value</h3>

<p>A matrix with <code>length(comp)</code> rows and <code>length(x)</code> columns 
in which each row gives the CDF evaluated at each point of <code>x</code>.
</p>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>
<p>Elmore, R. T., Hettmansperger, T. P. and Xuan, F. (2004) The Sign Statistic, One-Way Layouts
and Mixture Models, <em>Statistical Science</em> <b>19(4)</b>, 579&ndash;587.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makemultdata">makemultdata</a></code>, <code><a href="#topic+multmixmodel.sel">multmixmodel.sel</a></code>, <code><a href="#topic+multmixEM">multmixEM</a></code>, <code><a href="#topic+compCDF">compCDF</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The sulfur content of the coal seams in Texas
set.seed(100)
A &lt;- c(1.51, 1.92, 1.08, 2.04, 2.14, 1.76, 1.17)
B &lt;- c(1.69, 0.64, .9, 1.41, 1.01, .84, 1.28, 1.59)
C &lt;- c(1.56, 1.22, 1.32, 1.39, 1.33, 1.54, 1.04, 2.25, 1.49)
D &lt;- c(1.3, .75, 1.26, .69, .62, .9, 1.2, .32)
E &lt;- c(.73, .8, .9, 1.24, .82, .72, .57, 1.18, .54, 1.3)
dis.coal &lt;- makemultdata(A, B, C, D, E,
                         cuts = median(c(A, B, C, D, E)))
temp &lt;- multmixEM(dis.coal)
## Now plot the components' CDF via the posterior probabilities
plotly_compCDF(dis.coal$x, temp$posterior, xlab="Sulfur")
</code></pre>

<hr>
<h2 id='plotly_ellipse'>Draw Two-Dimensional Ellipse Based on Mean and Covariance using <code>plotly</code></h2><span id='topic+plotly_ellipse'></span>

<h3>Description</h3>

<p>This is an updated version of <code>ellipse</code>. For more technical details, please refer to <code>ellipse</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_ellipse(mu, sigma, alpha=.05, npoints=250,
               draw=TRUE, cex = 3, col = "#1f77b4", lwd = 3,
               title = "", title.x = 0.5, title.y = 0.95, title.size = 15,
               xlab = "X", xlab.size = 15, xtick.size = 15,
               ylab = "Y", ylab.size = 15, ytick.size = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_ellipse_+3A_mu">mu</code></td>
<td>
<p>A 2-vector giving the mean.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_sigma">sigma</code></td>
<td>
<p>A 2x2 matrix giving the covariance matrix.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_alpha">alpha</code></td>
<td>
<p>Probability to be excluded from the ellipse. The
default value is alpha = .05, which results in a 95% ellipse.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_npoints">npoints</code></td>
<td>
<p>Number of points comprising the border of the ellipse.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_draw">draw</code></td>
<td>
<p>If TRUE, draw the ellipse.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_cex">cex</code></td>
<td>
<p>Size of markers.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_lwd">lwd</code></td>
<td>
<p>Line width of the ellipse.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_col">col</code></td>
<td>
<p>Color of both markers and lines.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_ellipse_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plotly_ellipse</code> returns an <code>npoints</code>x2 matrix of the points forming the
border of the ellipse.
</p>


<h3>References</h3>

<p>Johnson, R. A. and Wichern, D. W. (2002) <em>Applied Multivariate Statistical Analysis, Fifth Edition</em>,
Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcr">regcr</a></code>, <code><a href="#topic+ellipse">ellipse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Produce a 95% ellipse with the specified mean and covariance structure.
mu &lt;- c(1, 3)
sigma &lt;- matrix(c(1, .3, .3, 1.5), 2, 2)
plotly_ellipse(mu, sigma, npoints = 200)
</code></pre>

<hr>
<h2 id='plotly_expRMM'>Plot sequences from the EM algorithm for censored mixture of exponentials using <code>plotly</code>
</h2><span id='topic+plotly_expRMM'></span>

<h3>Description</h3>

<p>This is an updated function of <code>plotexpRMM</code>. For more technical details, please refer to <code>plotexpRMM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotly_expRMM(a , title = NULL , rowstyle = TRUE , subtitle=NULL,
  width = 2 , cex = 2 , col.comp = NULL,
  legend.text = NULL, legend.text.size = 15, legend.size = 15,
  title.x = 0.5, title.y = 0.95, title.size = 15,
  xlab.size = 15, xtick.size = 15, 
  ylab.size = 15, ytick.size = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_expRMM_+3A_a">a</code></td>
<td>
<p>An object returned by <code><a href="#topic+expRMM_EM">expRMM_EM</a></code>.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_title">title</code></td>
<td>
<p>The title of the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_rowstyle">rowstyle</code></td>
<td>
<p>Window organization, for plots in rows (the default) or columns.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_subtitle">subtitle</code></td>
<td>
<p>A subtitle for the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_cex">cex</code></td>
<td>
<p>Size of dots.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_col.comp">col.comp</code></td>
<td>
<p>Color of different components. Number of color specified needs to be consistent with number of components.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_legend.text">legend.text</code></td>
<td>
<p>Title of legend.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>Size of the legend title.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_expRMM_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The plot returned</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions: 
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,   <code><a href="#topic+summary.mixEM">summary.mixEM</a></code>, <code><a href="#topic+plot.mixEM">plot.mixEM</a></code>, <code><a href="#topic+plotexpRMM">plotexpRMM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>, <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=300 # sample size
m=2 # number of mixture components
lambda &lt;- c(1/3,1-1/3); rate &lt;- c(1,1/10) # mixture parameters
set.seed(1234)
x &lt;- rexpmix(n, lambda, rate) # iid ~ exponential mixture
cs=runif(n,0,max(x)) # Censoring (uniform) and incomplete data
t &lt;- apply(cbind(x,cs),1,min) # observed or censored data
d &lt;- 1*(x &lt;= cs) # censoring indicator
###### EM for RMM, exponential lifetimes
l0 &lt;- rep(1/m,m); r0 &lt;- c(1, 0.5) # "arbitrary" initial values
a &lt;- expRMM_EM(t, d, lambda=l0, rate=r0, k = m)
summary(a) # EM estimates etc
plotly_expRMM(a , rowstyle = TRUE) # plot of EM sequences
</code></pre>

<hr>
<h2 id='plotly_FDR'>Plot False Discovery Rate (FDR) estimates from output by EM-like strategies using <code>plotly</code></h2><span id='topic+plotly_FDR'></span>

<h3>Description</h3>

<p>This is an updated version of <code>plotFDR</code>. For more technical details, please refer to <code>plotFDR</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_FDR(post1, post2=NULL, lg1="FDR 1", lg2=NULL, 
          compH0=1, alpha=0.1, complete.data =NULL, pctfdr=0.3,
          col = NULL, width = 3 ,
          title = NULL , title.size = 15 , title.x = 0.5 , title.y = 0.95,
          xlab = "Index" , xlab.size = 15 , xtick.size = 15,
          ylab = "Probability" , ylab.size = 15 , ytick.size = 15,
          legend.text = "" , legend.text.size = 15 , legend.size = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_FDR_+3A_post1">post1</code></td>
<td>
<p>The matrix of posterior probabilities from objects such as the output
from <code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>. The rows need to be sorted by increasing pvalues.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_post2">post2</code></td>
<td>
<p>A second object like <code>post1</code> if comparison is desired, also sorted by increasing pvalues.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_lg1">lg1</code></td>
<td>
<p>Text describing the FDR estimate in <code>post1</code>.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_lg2">lg2</code></td>
<td>
<p>Text describing the FDR estimate in <code>post2</code> if provided.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_comph0">compH0</code></td>
<td>
<p>The component indicator associated to the null hypothesis H0,
normally 1 since it is defined in this way in <code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>, but in case of label switching in other algorithms it can be set to <code>2</code>.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_alpha">alpha</code></td>
<td>
<p>The target FDR level; the index at which the FDR estimate crosses the horizontal line for level <code>alpha</code> gives the maximum number of cases to reject.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_complete.data">complete.data</code></td>
<td>
<p>An array with <code class="reqn">n</code> lines and 2 columns, with the component indicator in column 1 and the p-values in column 2, sorted by p-values.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_pctfdr">pctfdr</code></td>
<td>
<p>The level up to which the FDR is plotted, i.e. 
the scale of the vertical axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_col">col</code></td>
<td>
<p>Color of traces.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_width">width</code></td>
<td>
<p>Width of traces.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_legend.text">legend.text</code></td>
<td>
<p>Title of legend.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>Size of the legend title.</p>
</td></tr>
<tr><td><code id="plotly_FDR_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of one or two FDR estimates, with the true FDR if available</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D., Saby, N., Orton, T. G., Lemercier B., Walter, C. and Arrouys, D.
Large-scale simultaneous hypothesis testing in monitoring carbon content 
from French soil database &ndash; A semi-parametric mixture approach, Geoderma 219-220 (2014), 117-124.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>, <code><a href="#topic+plotFDR">plotFDR</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Probit transform of p-values
## from a Beta-Uniform mixture model
## comparion of parametric and semiparametric EM fit
## Note: in actual situations n=thousands
set.seed(50)
n=300 # nb of multiple tests
m=2 # 2 mixture components
a=c(1,0.1); b=c(1,1); lambda=c(0.6,0.4) # parameters
z=sample(1:m, n, rep=TRUE, prob = lambda)
p &lt;- rbeta(n, shape1 = a[z], shape2 = b[z]) # p-values
o &lt;- order(p)
cpd &lt;- cbind(z,p)[o,] # sorted complete data, z=1 if H0, 2 if H1
p &lt;- cpd[,2] # sorted p-values
y &lt;- qnorm(p) # probit transform of the pvalues
# gaussian EM fit with component 1 constrained to N(0,1)
s1 &lt;- normalmixEM(y, mu=c(0,-4),
                  mean.constr = c(0,NA), sd.constr = c(1,NA))
s2 &lt;- spEMsymlocN01(y, mu0 = c(0,-3)) # spEM with N(0,1) fit
plotly_FDR(s1$post, s2$post, lg1 = "normalmixEM", lg2 = "spEMsymlocN01",
           complete.data = cpd) # with true FDR computed from z
</code></pre>

<hr>
<h2 id='plotly_ise.npEM'>Visualization of Integrated Squared Error for a selected density from npEM output using <code>plotly</code></h2><span id='topic+plotly_ise.npEM'></span>

<h3>Description</h3>

<p>This is an updated visualization function for <code>ise.npEM</code>. For more technical details, please refer to <code>ise.npEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_ise.npEM(npEMout, component=1, block=1, truepdf=dnorm, lower=-Inf,
                upper=Inf, plots = TRUE ,
                col = NULL , width = 3,
                title = NULL , title.size = 15 , title.x = 0.5 , title.y = 0.95,
                xlab = "t" , xlab.size = 15 , xtick.size = 15,
                ylab = "" , ylab.size = 15 , ytick.size = 15,
                legend.text = "" , legend.text.size = 15 , legend.size = 15, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_ise.npEM_+3A_npemout">npEMout</code></td>
<td>
<p>An object of class <code>npEM</code> such as the output
of the <code><a href="#topic+npEM">npEM</a></code> function</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_component">component</code>, <code id="plotly_ise.npEM_+3A_block">block</code></td>
<td>
<p>Component and block of particular density to analyze
from <code>npEMout</code>.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_truepdf">truepdf</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> function taking a numeric first argument and 
returning a numeric vector of the same length. Returning a 
non-finite element will generate an error.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_lower">lower</code>, <code id="plotly_ise.npEM_+3A_upper">upper</code></td>
<td>
<p>the limits of integration.  Can be infinite.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_plots">plots</code></td>
<td>
<p>logical:  Should plots be produced?</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>truepdf</code>
(and that may be mandatory like, e.g., the <code>df = </code> argument of <code>dt</code>). 
Remember to use argument names not matching those of <code>ise.npRM</code>.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_col">col</code></td>
<td>
<p>Color of traces.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_width">width</code></td>
<td>
<p>Line width of traces.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_legend.text">legend.text</code></td>
<td>
<p>Title of legend.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>Size of the legend title.</p>
</td></tr>
<tr><td><code id="plotly_ise.npEM_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls the <code><a href="#topic+wkde">wkde</a></code> (weighted kernel
density estimate) function.
</p>


<h3>Value</h3>

<p>Just as for the <code><a href="stats.html#topic+integrate">integrate</a></code> function,
a list of class <code>"integrate"</code> with components
</p>
<table>
<tr><td><code>value</code></td>
<td>
<p>the final estimate of the integral.</p>
</td></tr>
<tr><td><code>abs.error</code></td>
<td>
<p>estimate of the modulus of the absolute error.</p>
</td></tr>
<tr><td><code>subdivisions</code></td>
<td>
<p>the number of subintervals produced in the
subdivision process.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p><code>"OK"</code> or a character string giving the error message.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D. (2009),
mixtools: An R package for analyzing finite mixture models.
Journal of Statistical Software, 32(6):1-29.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+wkde">wkde</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="#topic+ise.npEM">ise.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(Waterdata)
set.seed(100)
a &lt;- npEM(Waterdata[,3:10], mu0=3, bw=4) # Assume indep but not iid
plotly_ise.npEM(a , plots = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotly_mixEM'>Visualization of output of <code>mixEM</code> function using <code>plotly</code></h2><span id='topic+plotly_mixEM'></span>

<h3>Description</h3>

<p>This is an updated version of <code>plot.mixEM</code>. For more technical details, please refer to <code>plot.mixEM</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_mixEM(x, 
             loglik = TRUE,
             density = FALSE,
             xlab1="Iteration", xlab1.size=15 , xtick1.size=15,
             ylab1="Log-Likelihood", ylab1.size=15 , ytick1.size=15,
             title1="Observed Data Log-Likelihood", title1.size=15,
             title1.x = 0.5,title1.y=0.95,
             col1="#1f77b4", lwd1=3, cex1=6,
             xlab2=NULL, xlab2.size=15 , xtick2.size=15,
             ylab2=NULL, ylab2.size=15 , ytick2.size=15,
             title2=NULL, title2.size=15,
             title2.x = 0.5,title2.y=0.95, col.hist = "#1f77b4",
             col2=NULL, lwd2=3, cex2=6,
             alpha = 0.05, marginal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_mixEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>mixEM</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_loglik">loglik</code></td>
<td>
<p>If TRUE, a plot of the log-likelihood versus the EM iterations is given.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_density">density</code></td>
<td>
<p>Graphics pertaining to certain mixture models. The details are given below.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_xlab1">xlab1</code></td>
<td>
<p>Label of x-axis to be passed to the loglikelihood plot. Trying to change these parameters using <code>xlab</code> result in an error.</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_xlab1.size">xlab1.size</code></td>
<td>
<p>Font of <code>xlab1</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_xtick1.size">xtick1.size</code></td>
<td>
<p>Font of tick labels of x-axis to be passed to the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_ylab1">ylab1</code></td>
<td>
<p>Label of y-axis to be passed to the loglikelihood plot. Trying to change these parameters using <code>ylab</code> result in an error.</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_ylab1.size">ylab1.size</code></td>
<td>
<p>Font of <code>ylab1</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_ytick1.size">ytick1.size</code></td>
<td>
<p>Font of tick labels of y-axis to be passed to the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_title1">title1</code></td>
<td>
<p>Title to be passed to the loglikelihood plot.</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_title1.size">title1.size</code></td>
<td>
<p>Tile size of the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_title1.x">title1.x</code></td>
<td>
<p>Horizontal position of the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_title1.y">title1.y</code></td>
<td>
<p>Verticle position of the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_col1">col1</code></td>
<td>
<p>Color of the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_lwd1">lwd1</code></td>
<td>
<p>Width of the density curve of the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_cex1">cex1</code></td>
<td>
<p>Dot size of the loglikelihood plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_xlab2">xlab2</code></td>
<td>
<p>Label of x-axis to be passed to the density plot. Trying to change these parameters using <code>xlab</code> result in an error.</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_xlab2.size">xlab2.size</code></td>
<td>
<p>Font of <code>xlab2</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_xtick2.size">xtick2.size</code></td>
<td>
<p>Font of tick labels of x-axis to be passed to the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_ylab2">ylab2</code></td>
<td>
<p>Label of y-axis to be passed to the density plot. Trying to change these parameters using <code>ylab</code> result in an error.</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_ylab2.size">ylab2.size</code></td>
<td>
<p>Font of <code>ylab2</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_ytick2.size">ytick2.size</code></td>
<td>
<p>Font of tick labels of y-axis to be passed to the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_title2">title2</code></td>
<td>
<p>Title to be passed to the density plot.</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_title2.size">title2.size</code></td>
<td>
<p>Tile size of the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_title2.x">title2.x</code></td>
<td>
<p>Horizontal position of the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_title2.y">title2.y</code></td>
<td>
<p>Verticle position of the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_col2">col2</code></td>
<td>
<p>Color of the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_lwd2">lwd2</code></td>
<td>
<p>Width of the density curve of the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_cex2">cex2</code></td>
<td>
<p>Dot size of the density plot.</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_col.hist">col.hist</code></td>
<td>
<p>Color of the histogram of the density plot</p>
</td></tr>
<tr><td><code id="plotly_mixEM_+3A_alpha">alpha</code></td>
<td>
<p>A vector of significance levels when constructing confidence ellipses and confidence bands for the mixture of multivariate normals and mixture of regressions
cases, respectively. The default is 0.05</p>
</td></tr> 
<tr><td><code id="plotly_mixEM_+3A_marginal">marginal</code></td>
<td>
<p>If <code>TRUE</code>, marginal density is presented on the side of the corresponding variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the output of <code>mixEM</code> function is presented depends on output type.</p>


<h3>See Also</h3>

<p><code><a href="#topic+post.beta">post.beta</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## EM output for data generated from a 2-component binary logistic regression model.
beta &lt;- matrix(c(-10, .1, 20, -.1), 2, 2)
x &lt;- runif(500, 50, 250)
x1 &lt;- cbind(1, x)
xbeta &lt;- x1
w &lt;- rbinom(500, 1, .3)
y &lt;- w*rbinom(500, size = 1, prob = (1/(1+exp(-xbeta[, 1]))))+
  (1-w)*rbinom(500, size = 1, prob =
                 (1/(1+exp(-xbeta[, 2]))))
out.2 &lt;- logisregmixEM(y, x, beta = beta, lambda = c(.3, .7),
                       verb = TRUE, epsilon = 1e-01)
plotly_mixEM(out.2 , col2 = c("red" , "green") , density = TRUE)

## Fitting randomly generated data with a 2-component location mixture of bivariate normals.
set.seed(100)
x.1 &lt;- rmvnorm(40, c(0, 0))
x.2 &lt;- rmvnorm(60, c(3, 4))
X.1 &lt;- rbind(x.1, x.2)
mu &lt;- list(c(0, 0), c(3, 4))
out.1 &lt;- mvnormalmixEM(X.1, arbvar = FALSE, mu = mu,
                       epsilon = 1e-02)
plotly_mixEM(out.1 , col2 = c("brown" , "blue") ,
             alpha = c(0.01 , 0.05 , 0.1),
             density = TRUE , marginal = FALSE)

## Fitting randomly generated data with a 2-component scale mixture of bivariate normals.
x.3 &lt;- rmvnorm(40, c(0, 0), sigma =
                 matrix(c(200, 1, 1, 150), 2, 2))
x.4 &lt;- rmvnorm(60, c(0, 0))
X.2 &lt;- rbind(x.3, x.4)
lambda &lt;- c(0.40, 0.60)
sigma &lt;- list(diag(1, 2), matrix(c(200, 1, 1, 150), 2, 2))
out.2 &lt;- mvnormalmixEM(X.2, arbmean = FALSE,
                       sigma = sigma, lambda = lambda,
                       epsilon = 1e-02)
plotly_mixEM(out.1 , col2 = c("brown" , "blue") ,
             alpha = c(0.01 , 0.05 , 0.1),
             density = TRUE , marginal = TRUE)

## EM output for simulated data from 2-component mixture of random effects.
data(RanEffdata)
set.seed(100)
x &lt;- lapply(1:length(RanEffdata), function(i)
  matrix(RanEffdata[[i]][, 2:3], ncol = 2))
x &lt;- x[1:20]
y &lt;- lapply(1:length(RanEffdata), function(i)
  matrix(RanEffdata[[i]][, 1], ncol = 1))
y &lt;- y[1:20]
lambda &lt;- c(0.45, 0.55)
mu &lt;- matrix(c(0, 4, 100, 12), 2, 2)
sigma &lt;- 2
R &lt;- list(diag(1, 2), diag(1, 2))
em.out &lt;- regmixEM.mixed(y, x, sigma = sigma, arb.sigma = FALSE,
                         lambda = lambda, mu = mu, R = R,
                         addintercept.random = FALSE,
                         epsilon = 1e-02, verb = TRUE)
plotly_mixEM(em.out , col2 = c("gold" , "purple") , 
             density = TRUE , lwd2 = 1 , cex2 =9)

## Analyzing the Old Faithful geyser data with a 2-component mixture of normals.
data(faithful)
attach(faithful)
set.seed(100)
out &lt;- normalmixEM(waiting, arbvar = FALSE, verb = TRUE,
                   epsilon = 1e-04)
plotly_mixEM(out, density = TRUE , col2 = c("gold" , "purple"))

## EM output for the water-level task data set.
data(Waterdata)
set.seed(100)
water &lt;- t(as.matrix(Waterdata[,3:10]))
em.out &lt;- repnormmixEM(water, k = 2, verb = TRUE, epsilon = 1e-03)
plotly_mixEM(em.out, density = TRUE , col2 = c("gold" , "purple"))

## End(Not run)
</code></pre>

<hr>
<h2 id='plotly_mixMCMC'>Various Plots Pertaining to Mixture Model Output Using MCMC Methods using <code>plotly</code></h2><span id='topic+plotly_mixMCMC'></span>

<h3>Description</h3>

<p>This is an updated version of <code>plot.mixMCMC</code>. For technical details, please refer to <code>plot.mixMCMC</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
plotly_mixMCMC(x, trace.plot = TRUE, summary.plot = FALSE, burnin = 2000, 
               credit.region = 0.95, col.cr = NULL,
               cex.trace = 3, width.trace = 3, 
               cex.summary = 3, width.summary = 1,
               title.trace = "", title.trace.x = 0.5, 
               title.trace.y = 0.95, title.trace.size = 15,
               xlab.trace = "Index", xlab.trace.size = 15, xtick.trace.size = 15,
               ylab.trace = NULL, ylab.trace.size = 15, ytick.trace.size = 15,
               title.summary = "Credible Regions", title.summary.x = 0.5, 
               title.summary.y = 0.95, title.summary.size = 15,
               xlab.summary = "Predictor", xlab.summary.size = 15, 
               xtick.summary.size = 15,
               ylab.summary = "Response", ylab.summary.size = 15, 
               ytick.summary.size = 15
) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_mixMCMC_+3A_x">x</code></td>
<td>
<p>An object of class <code>mixMCMC</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_trace.plot">trace.plot</code></td>
<td>
<p>If TRUE, trace plots of the various parameters estimated by the MCMC methods is given.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_summary.plot">summary.plot</code></td>
<td>
<p>Graphics pertaining to certain mixture models.  The details are given below.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_burnin">burnin</code></td>
<td>
<p>The values 1 to <code>burnin</code> are dropped when producing the plots in <code>summary.plots</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_credit.region">credit.region</code></td>
<td>
<p>Confidence level of credit region.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_col.cr">col.cr</code></td>
<td>
<p>Color of credit region. Number of color specified needs to be consistent with number of components.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_cex.trace">cex.trace</code></td>
<td>
<p>Dot size of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_width.trace">width.trace</code></td>
<td>
<p>Line width of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_cex.summary">cex.summary</code></td>
<td>
<p>Dot size of summary plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_width.summary">width.summary</code></td>
<td>
<p>Line width of summary plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.trace">title.trace</code></td>
<td>
<p>Text of the main title of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.trace.x">title.trace.x</code></td>
<td>
<p>Horizontal position of main title of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.trace.y">title.trace.y</code></td>
<td>
<p>Vertical position of main title of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.trace.size">title.trace.size</code></td>
<td>
<p>Text sise of main title of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_xlab.trace">xlab.trace</code></td>
<td>
<p>Label of X-axis of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_xlab.trace.size">xlab.trace.size</code></td>
<td>
<p>Size of the lable of X-axis of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_xtick.trace.size">xtick.trace.size</code></td>
<td>
<p>Size of tick lables of X-axis of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_ylab.trace">ylab.trace</code></td>
<td>
<p>Label of Y-axis of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_ylab.trace.size">ylab.trace.size</code></td>
<td>
<p>Size of the lable of Y-axis of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_ytick.trace.size">ytick.trace.size</code></td>
<td>
<p>Size of tick lables of Y-axis of trace plots.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.summary">title.summary</code></td>
<td>
<p>Text of the main title of summar plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.summary.x">title.summary.x</code></td>
<td>
<p>Horizontal position of main title of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.summary.y">title.summary.y</code></td>
<td>
<p>Vertical position of main title of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_title.summary.size">title.summary.size</code></td>
<td>
<p>Text sise of main title of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_xlab.summary">xlab.summary</code></td>
<td>
<p>Label of X-axis of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_xlab.summary.size">xlab.summary.size</code></td>
<td>
<p>Size of the lable of X-axis of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_xtick.summary.size">xtick.summary.size</code></td>
<td>
<p>Size of tick lables of X-axis of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_ylab.summary">ylab.summary</code></td>
<td>
<p>Label of Y-axis of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_ylab.summary.size">ylab.summary.size</code></td>
<td>
<p>Size of the lable of Y-axis of summary plot.</p>
</td></tr>
<tr><td><code id="plotly_mixMCMC_+3A_ytick.summary.size">ytick.summary.size</code></td>
<td>
<p>Size of tick lables of Y-axis of summary plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plotly_mixMCMC</code> returns trace plots of the various parameters estimated by the MCMC methods for all objects of class
<code>mixMCMC</code>.  In addition, other plots may be produced for the following k-component mixture model functions:
</p>
<table>
<tr><td><code>regmixMH</code></td>
<td>
<p>Credible bands for the regression lines in a mixture of linear regressions.  See <code>regcr</code> for more details.</p>
</td></tr>
</table>


<h3>See Also</h3>

 
<p><code><a href="#topic+regcr">regcr</a></code>, <code>plot.mixMCMC</code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
data(NOdata)
attach(NOdata)
set.seed(100)
beta &lt;- matrix(c(1.3, -0.1, 0.6, 0.1), 2, 2)
sigma &lt;- c(.02, .05)
MH.out &lt;- regmixMH(Equivalence, NO, beta = beta, s = sigma,
                   sampsize = 2500, omega = .0013)
plotly_mixMCMC(x = MH.out, summary.plot = TRUE, col.cr = c("red", "green"))

## End(Not run)
</code></pre>

<hr>
<h2 id='plotly_mixturegram'>Mixturegrams</h2><span id='topic+plotly_mixturegram'></span>

<h3>Description</h3>

<p>Construct a mixturegram for determining an apporpriate number of components using <code>plotly</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_mixturegram(data, pmbs, method=c("pca","kpca","lda"), 
                   all.n=FALSE, id.con=NULL, score=1, iter.max=50, 
                   nstart=25, xlab = "K", xlab.size = 15, 
                   xtick.size = 15, ylab = NULL, ylab.size = 15, 
                   ytick.size = 15, cex = 12, col.dot = "red", 
                   width = 1, title = "Mixturegram", title.size = 15, 
                   title.x = 0.5, title.y = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_mixturegram_+3A_data">data</code></td>
<td>
<p>The data, which must either be a vector or a matrix.  If a matrix, then the rows correspond to the observations.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_pmbs">pmbs</code></td>
<td>
<p>A list of length (K-1) such that each element is an nxk matrix of the posterior membership probabilities.  These are obtained from each of the &quot;best&quot; estimated k-component mixture models, k = 2,...,K.
</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_method">method</code></td>
<td>
<p>The dimension reduction method used.  <code>method = "pca"</code> implements principal components analysis.  <code>method = "kpca"</code> implements kernel principal components analysis. <code>method = "lda"</code> implements reduced rank linear discriminant analysis.
</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_all.n">all.n</code></td>
<td>
<p>A logical specifying whether the mixturegram should plot the profiles of all observations (<code>TRUE</code>) or just the K-profile summaries (<code>FALSE</code>).  The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_id.con">id.con</code></td>
<td>
<p>An argument that allows one to impose some sort of (meaningful) identifiability constraint so that the mixture components are in some sort of comparable order between mixture models with different numbers of components.  If <code>NULL</code>, then the components are ordered by the component means for univariate data or ordered by the first dimension of the component means for multivariate data.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_score">score</code></td>
<td>
<p>The value for the specified dimension reduction technique's score, which is used for constructing the mixturegram.  By default, this value is <code>1</code>, which is the value that will typically be used.  Larger values will result in more variability displayed on the mixturegram.  Note that the largest value that can be calculated at each value of k&gt;1 on the mixturegram is p+k-1, where p is the number of columns of <code>data</code>. 
</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_iter.max">iter.max</code></td>
<td>
<p>The maximum number of iterations allowed for the k-means clustering algorithm, which is passed to the <code><a href="stats.html#topic+kmeans">kmeans</a></code> function.  The default is <code>50</code>.
</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_nstart">nstart</code></td>
<td>
<p>The number of random sets chosen based on k centers, which is passed to the <code><a href="stats.html#topic+kmeans">kmeans</a></code> function.  The default is <code>25</code>.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_cex">cex</code></td>
<td>
<p>Size of dots.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_col.dot">col.dot</code></td>
<td>
<p>Color of dots.</p>
</td></tr>
<tr><td><code id="plotly_mixturegram_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plotly_mixturegram</code> returns a mixturegram where the profiles are plotted over component values of k = 1,...,K.
</p>


<h3>References</h3>

<p>Young, D. S., Ke, C., and Zeng, X. (2018) The Mixturegram: A Visualization Tool for Assessing the
Number of Components in Finite Mixture Models, <em>Journal 
of Computational and Graphical Statistics</em>, <b>27(3)</b>, 564&ndash;575.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.comp">boot.comp</a></code>, <code><a href="#topic+mixturegram">mixturegram</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##Data generated from a 2-component mixture of normals.
set.seed(100)
n &lt;- 100
w &lt;- rmultinom(n,1,c(.3,.7))
y &lt;- sapply(1:n,function(i) w[1,i]*rnorm(1,-6,1) +
              w[2,i]*rnorm(1,0,1))
selection &lt;- function(i,data,rep=30){
  out &lt;- replicate(rep,normalmixEM(data,epsilon=1e-06,
                                   k=i,maxit=5000),simplify=FALSE)
  counts &lt;- lapply(1:rep,function(j)
    table(apply(out[[j]]$posterior,1,
                which.max)))
  counts.length &lt;- sapply(counts, length)
  counts.min &lt;- sapply(counts, min)
  counts.test &lt;- (counts.length != i)|(counts.min &lt; 5)
  if(sum(counts.test) &gt; 0 &amp; sum(counts.test) &lt; rep)
    out &lt;- out[!counts.test]
  l &lt;- unlist(lapply(out, function(x) x$loglik))
  tmp &lt;- out[[which.max(l)]]
}
all.out &lt;- lapply(2:5, selection, data = y, rep = 2)
pmbs &lt;- lapply(1:length(all.out), function(i)
  all.out[[i]]$post)
plotly_mixturegram(y, pmbs, method = "pca", all.n = TRUE,
                   id.con = NULL, score = 1,
                   title = "Mixturegram (Well-Separated Data)")

## End(Not run)
</code></pre>

<hr>
<h2 id='plotly_npEM'>Plot Nonparametric or Semiparametric EM Output</h2><span id='topic+plotly_npEM'></span><span id='topic+plotly_spEM'></span>

<h3>Description</h3>

<p>This is an updater version of <code>plot.npEM</code> function by using <code>plotly</code>. For technical details, please refer to <code>plot.npEM</code>.     
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_npEM(x, blocks = NULL, hist=TRUE, addlegend=TRUE,
            scale = TRUE, title=NULL, breaks="Sturges", 
            dens.col = NULL, newplot=TRUE, ylim = NULL ,
            col.hist = "#1f77b4",
            width = 3, title.x = 0.5 , title.y = 0.95, title.size = 15,
            xlab = "X" , xlab.size = 15 , xtick.size = 15,
            ylab = "Density" , ylab.size = 15 , ytick.size = 15,
            legend.text = "Posteriors",
            legend.text.size = 15,
            legend.size = 15)         
plotly_spEM(x, blocks = NULL, hist=TRUE, addlegend=TRUE,
            scale = TRUE, title=NULL, breaks="Sturges", 
            dens.col = NULL, newplot=TRUE, ylim = NULL ,
            col.hist = "#1f77b4",
            width = 3, title.x = 0.5 , title.y = 0.95, title.size = 15,
            xlab = "X" , xlab.size = 15 , xtick.size = 15,
            ylab = "Density" , ylab.size = 15 , ytick.size = 15,
            legend.text = "Posteriors",
            legend.text.size = 15,
            legend.size = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_npEM_+3A_x">x</code></td>
<td>
<p>An object of class <code>npEM</code> such as the output
of the <code><a href="#topic+npEM">npEM</a></code> function</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_blocks">blocks</code></td>
<td>
<p>Blocks (of repeated measures coordinates) to plot; not relevant
for univariate case.  Default is to plot all blocks.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_hist">hist</code></td>
<td>
<p>If TRUE, superimpose density estimate plots on a histogram
of the data</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_addlegend">addlegend</code></td>
<td>
<p>If TRUE, adds legend to the plot.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_scale">scale</code></td>
<td>
<p>If TRUE, scale each density estimate by its corresponding estimated
mixing proportion, so that the total area under all densities equals 1 and the 
densities plotted may be added to produce an estimate of the mixture density.
When FALSE, each density curve has area 1 in the plot.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_title">title</code></td>
<td>
<p>Alternative vector of main titles for plots (recycled as many times
as needed)</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_breaks">breaks</code></td>
<td>
<p>Passed directly to the <code><a href="graphics.html#topic+hist">hist</a></code> function</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_ylim">ylim</code></td>
<td>
<p><code>ylim</code> parameter to use for all plots, if desired.  If not
given, each plot uses its own ylim that ensures that no part of the plot will
go past the top of the plotting area.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_dens.col">dens.col</code></td>
<td>
<p>Color values to use for the individual component density
functions, repeated as necessary.  Default value is <code>2:(m+1)</code>.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_newplot">newplot</code></td>
<td>
<p>If TRUE, creates a new plot.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_col.hist">col.hist</code></td>
<td>
<p>Color of the histogram to plot.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_legend.text">legend.text</code></td>
<td>
<p>Title of legend.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>Size of the legend title.</p>
</td></tr>
<tr><td><code id="plotly_npEM_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plotly_npEM</code> returns a list with two elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>List of matrices.  The <code class="reqn">j</code>th column of the <code class="reqn">i</code>th matrix is the vector of 
<code class="reqn">x</code>-values for the <code class="reqn">j</code>th density in the <code class="reqn">i</code>th plot.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p><code class="reqn">y</code>-values, given in the same form as the <code class="reqn">x</code>-values.</p>
</td></tr>
</table>


<h3>See Also</h3>

 
<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+density.npEM">density.npEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>,
<code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>, <code>plot.npEM</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
## Examine and plot water-level task data set.

## First, try a 3-component solution where no two coordinates are
## assumed i.d.
data(Waterdata)
set.seed(100)
a &lt;- npEM(Waterdata[,3:10], 3, bw=4)
plotly_npEM(a , newplot = FALSE)

## Next, same thing but pairing clock angles that are directly opposite one
## another (1:00 with 7:00, 2:00 with 8:00, etc.)
b &lt;- npEM(Waterdata[,3:10], 3, blockid=c(4,3,2,1,3,4,1,2), bw=4)
plotly_npEM(b , newplot = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='plotly_post.beta'>Visualization of Posterior Regression Coefficients in Mixtures of Random Effects Regressions using <code>plotly</code></h2><span id='topic+plotly_post.beta'></span>

<h3>Description</h3>

<p>Returns a 2x2 matrix of plots summarizing the posterior intercept and slope terms in a mixture of random effects regression with arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_post.beta(y, x, p.beta, p.z,
                 cex = 6,lwd=1,
                 title.size = 15,
                 xlab.size = 15 , xtick.size = 15,
                 ylab.size = 15 , ytick.size = 15,
                 col.data = "#1f77b4",
                 col.comp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_post.beta_+3A_y">y</code></td>
<td>
<p>A list of N response trajectories with (possibly) varying dimensions of
length <code class="reqn">n_i</code>.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_x">x</code></td>
<td>
<p>A list of N predictor values of dimension <code class="reqn">n_i</code>.  Each trajectory in y has
its own design vector.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_p.beta">p.beta</code></td>
<td>
<p>A list of N 2xk matrices giving the posterior intercept and slope values from the output of an
EM algorithm.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_p.z">p.z</code></td>
<td>
<p>An Nxk matrix of posterior membership probabilities from the output of an EM algorithm.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_cex">cex</code></td>
<td>
<p>Size of dots of posterior Coefficients.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_lwd">lwd</code></td>
<td>
<p>Width of lines.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_col.data">col.data</code></td>
<td>
<p>Color of original data points.</p>
</td></tr>
<tr><td><code id="plotly_post.beta_+3A_col.comp">col.comp</code></td>
<td>
<p>Color of points and lines of components. Number of colors specified needs to be consistent with number of components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is primarily used for within <code>plot.mixEM</code>.
</p>


<h3>Value</h3>

<p>Plots returned.
</p>


<h3>References</h3>

<p>Young, D. S. and Hunter, D. R. (2015) Random Effects Regression Mixtures for Analyzing Infant Habituation,
<em>Journal of Applied Statistics</em>, <b>42(7)</b>, 1421&ndash;1441.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM.mixed">regmixEM.mixed</a></code>, <code><a href="#topic+plot.mixEM">plot.mixEM</a></code>, <code><a href="#topic+post.beta">post.beta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RanEffdata)
set.seed(100)
x &lt;- lapply(1:length(RanEffdata), function(i)
  matrix(RanEffdata[[i]][, 2:3], ncol = 2))
x &lt;- x[1:20]
y &lt;- lapply(1:length(RanEffdata), function(i)
  matrix(RanEffdata[[i]][, 1], ncol = 1))
y &lt;- y[1:20]
lambda &lt;- c(0.45, 0.55)
mu &lt;- matrix(c(0, 4, 100, 12), 2, 2)
sigma &lt;- 2
R &lt;- list(diag(1, 2), diag(1, 2))
em.out &lt;- regmixEM.mixed(y, x, sigma = sigma, arb.sigma = FALSE,
                         lambda = lambda, mu = mu, R = R,
                         addintercept.random = FALSE,
                         epsilon = 1e-02, verb = TRUE)

x.1 = em.out$x
n = sum(sapply(x.1, nrow))
x.1.sum = sum(sapply(1:length(x.1), function(i) length(x.1[[i]][,1])))
if (x.1.sum == n) {
  x = lapply(1:length(x.1), function(i) matrix(x.1[[i]][,-1], ncol = 1))
} else {
  x = x.1
}

plotly_post.beta(x = x, y = em.out$y, p.beta = em.out$posterior.beta, 
                 p.z = em.out$posterior.z)
</code></pre>

<hr>
<h2 id='plotly_seq.npEM'>Plotting sequences of estimates from non- or semiparametric EM-like Algorithm using <code>plotly</code></h2><span id='topic+plotly_seq.npEM'></span>

<h3>Description</h3>

<p>This is an updated version of <code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>. For technical details, please refer to <code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotly_seq.npEM (x, col = '#1f77b4' , width = 6,
                   xlab = "Iteration" , xlab.size = 15 , xtick.size = 15,
                   ylab.size = 15 , ytick.size = 15,
                   title.size = 15 , title.x = 0.5 , title.y = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_seq.npEM_+3A_x">x</code></td>
<td>
<p>an object of class <code>npEM</code>, as output by <code><a href="#topic+npEM">npEM</a></code> 
or <code><a href="#topic+spEMsymloc">spEMsymloc</a></code></p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_col">col</code></td>
<td>
<p>Line color.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_seq.npEM_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plotly_seq.npEM</code> returns a figure with one plot for each component 
proportion, and, in the case of <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, one plot for each 
component mean.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics (to appear).
</p>
</li>
<li><p> Bordes, L., Chauveau, D., and Vandekerkhove, P. (2007),
An EM algorithm for a semiparametric mixture model, 
Computational Statistics and Data Analysis, 51: 5429-5443.   
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.npEM">plot.npEM</a></code>, <code><a href="#topic+rnormmix">rnormmix</a></code>,
<code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, <code><a href="#topic+plotly_seq.npEM">plotly_seq.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Examine and plot water-level task data set.
## First, try a 3-component solution where no two coordinates are
## assumed i.d.
data(Waterdata)
set.seed(100)
## Not run:
a &lt;- npEM(Waterdata[,3:10], mu0=3, bw=4) # Assume indep but not iid
plotly_seq.npEM(a)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotly_spEMN01'>Plot mixture pdf for the semiparametric mixture model output by <code>spEMsymlocN01</code> using <code>plotly</code>.</h2><span id='topic+plotly_spEMN01'></span>

<h3>Description</h3>

<p>This is an updated version of <code>plotlspEMN01</code> function by using <code>plotly</code>. For technical details, please refer to <code><a href="#topic+plot.spEMN01">plot.spEMN01</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotly_spEMN01(x, bw=x$bandwidth, knownpdf=dnorm, add.plot=FALSE,
               width = 3 , col.dens = NULL, col.hist =  '#1f77b4',
               title = NULL , title.size = 15 , 
               title.x = 0.5 , title.y = 0.95,
               xlab = "t" , xlab.size = 15 , xtick.size = 15,
               ylab = "Density" , ylab.size = 15 , ytick.size = 15,
               legend.text = "Densities" , legend.text.size = 15 , 
               legend.size = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_spEMN01_+3A_x">x</code></td>
<td>
<p>An object of class &quot;spEMN01&quot; as returned by spEMsymlocN01</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for weighted kernel density estimation.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_knownpdf">knownpdf</code></td>
<td>
<p>The known density of component 1, default to <code>dnorm</code>.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_add.plot">add.plot</code></td>
<td>
<p>Set to TRUE to add to an existing plot.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_col.dens">col.dens</code></td>
<td>
<p>Color of density lines. Number of colors specified needs to be consistent with number of components.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_col.hist">col.hist</code></td>
<td>
<p>Color of histogram.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_title">title</code></td>
<td>
<p>Text of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_legend.text">legend.text</code></td>
<td>
<p>Title of legend.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_legend.text.size">legend.text.size</code></td>
<td>
<p>Size of the legend title.</p>
</td></tr>
<tr><td><code id="plotly_spEMN01_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of the density of the mixture</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D., Saby, N., Orton, T. G., Lemercier B., Walter, C. and Arrouys, D.
Large-scale simultaneous hypothesis testing in soil monitoring:
A semi-parametric mixture approach, preprint (2013).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>, <code><a href="#topic+plot.spEMN01">plot.spEMN01</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Probit transform of p-values
## from a Beta-Uniform mixture model
## comparion of parametric and semiparametric EM fit
## Note: in actual situations n=thousands
set.seed(50)
n=300 # nb of multiple tests
m=2 # 2 mixture components
a=c(1,0.1); b=c(1,1); lambda=c(0.6,0.4) # parameters
z=sample(1:m, n, rep=TRUE, prob = lambda)
p &lt;- rbeta(n, shape1 = a[z], shape2 = b[z]) # p-values
o &lt;- order(p)
cpd &lt;- cbind(z,p)[o,] # sorted complete data, z=1 if H0, 2 if H1
p &lt;- cpd[,2] # sorted p-values
y &lt;- qnorm(p) # probit transform of the pvalues
# gaussian EM fit with component 1 constrained to N(0,1)
s1 &lt;- normalmixEM(y, mu=c(0,-4),
                  mean.constr = c(0,NA), sd.constr = c(1,NA))
s2 &lt;- spEMsymlocN01(y, mu0 = c(0,-3)) # spEM with N(0,1) fit
plotly_spEMN01(s2 , add.plot = FALSE)
</code></pre>

<hr>
<h2 id='plotly_spRMM'>Plot output from Stochastic EM algorithm for semiparametric scaled mixture of censored data using <code>plotly</code>.
</h2><span id='topic+plotly_spRMM'></span>

<h3>Description</h3>

<p>This is an updated version of <code>plotspRMM</code> function. For technical details, please refer to <code><a href="#topic+plotspRMM">plotspRMM</a>.
</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotly_spRMM(sem, tmax = NULL,
               width = 3 , col = '#1f77b4', cex = 3,
               title.size = 15 , 
               title.x = 0.5 , title.y = 0.95,
               xlab.size = 15 , xtick.size=15 ,
               ylab.size = 15 , ytick.size=15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_spRMM_+3A_sem">sem</code></td>
<td>
<p>An object returned by <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_tmax">tmax</code></td>
<td>
<p>The max time for <code class="reqn">x</code> axis, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_width">width</code></td>
<td>
<p>Width of lines.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_col">col</code></td>
<td>
<p>Color of lines.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_cex">cex</code></td>
<td>
<p>Size of dots.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_title.x">title.x</code></td>
<td>
<p>Horizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_title.y">title.y</code></td>
<td>
<p>Vertical position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of the tick of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_spRMM_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of the tick of Y-axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The four plots returned.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions: <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code> , <code><a href="#topic+plotspRMM">plotspRMM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n=500 # sample size
m=2 # nb components
lambda=c(0.4, 0.6) # parameters
meanlog=3; sdlog=0.5; scale=0.1
set.seed(12)
# simulate a scaled mixture of lognormals
x &lt;- rlnormscalemix(n, lambda, meanlog, sdlog, scale)
cs=runif(n,20,max(x)+400) # Censoring (uniform) and incomplete data
t &lt;- apply(cbind(x,cs),1,min)
d &lt;- 1*(x &lt;= cs)
tauxc &lt;- 100*round( 1-mean(d),3)
cat(tauxc, "percents of data censored.\n")

c0 &lt;- c(25, 180) # data-driven initial centers (visible modes)
sc0 &lt;- 25/180    # and scaling
s &lt;- spRMM_SEM(t, d, scaling = sc0, centers = c0, bw = 15, maxit = 100)

plotly_spRMM(s) # default
summary(s)   # S3 method for class "spRMM"

## End(Not run)
</code></pre>

<hr>
<h2 id='plotly_weibullRMM'>Plot sequences from the Stochastic EM algorithm for mixture of Weibull using <code>plotly</code>
</h2><span id='topic+plotly_weibullRMM'></span>

<h3>Description</h3>

<p>This is an updated version of <code>plotweibullRMM</code> function by using <code>plotly</code> function. For technical details, please refer to <code><a href="#topic+plotweibullRMM">plotweibullRMM</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotly_weibullRMM(a, title=NULL, rowstyle=TRUE, subtitle=NULL,
                    width = 3 , col = NULL , 
                    title.size = 15 , title.x = 0.5 , title.y = 0.95,
                    xlab = "Iterations" , xlab.size = 15 , xtick.size = 15,
                    ylab = "Estimates" , ylab.size = 15 , ytick.size = 15,
                    legend.size = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotly_weibullRMM_+3A_a">a</code></td>
<td>
<p>An object returned by <code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_title">title</code></td>
<td>
<p>The title of the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_rowstyle">rowstyle</code></td>
<td>
<p>Window organization, for plots in rows (the default) or columns.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_subtitle">subtitle</code></td>
<td>
<p>A subtitle for the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_width">width</code></td>
<td>
<p>Line width.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_col">col</code></td>
<td>
<p>Color of lines. Number of colors specified needs to be consistent with number of components.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_title.size">title.size</code></td>
<td>
<p>Size of the main title.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_title.x">title.x</code></td>
<td>
<p>Horsizontal position of the main title.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_title.y">title.y</code></td>
<td>
<p>Vertical posotion of the main title.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_xlab">xlab</code></td>
<td>
<p>Label of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_xlab.size">xlab.size</code></td>
<td>
<p>Size of the lable of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_xtick.size">xtick.size</code></td>
<td>
<p>Size of tick lables of X-axis.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_ylab.size">ylab.size</code></td>
<td>
<p>Size of the lable of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_ytick.size">ytick.size</code></td>
<td>
<p>Size of tick lables of Y-axis.</p>
</td></tr>
<tr><td><code id="plotly_weibullRMM_+3A_legend.size">legend.size</code></td>
<td>
<p>Size of legend.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The plot returned.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions:
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>,   <code><a href="#topic+summary.mixEM">summary.mixEM</a></code>, <code><a href="#topic+plotweibullRMM">plotweibullRMM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>
.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 500 # sample size
m = 2 # nb components
lambda=c(0.4, 0.6)
shape &lt;- c(0.5,5); scale &lt;- c(1,20) # model parameters
set.seed(321)
x &lt;- rweibullmix(n, lambda, shape, scale) # iid ~ weibull mixture
cs=runif(n,0,max(x)+10) # iid censoring times
t &lt;- apply(cbind(x,cs),1,min) # censored observations
d &lt;- 1*(x &lt;= cs) # censoring indicator
## set arbitrary or "reasonable" (e.g., data-driven) initial values
l0 &lt;- rep(1/m,m); sh0 &lt;- c(1, 2); sc0 &lt;- c(2,10)
# Stochastic EM algorithm
a &lt;- weibullRMM_SEM(t, d, lambda = l0, shape = sh0, scale = sc0, maxit = 200)
summary(a) # Parameters estimates etc
plotly_weibullRMM(a , legend.size = 20) # plot of St-EM sequences
</code></pre>

<hr>
<h2 id='plotseq.npEM'>Plotting sequences of estimates from non- or semiparametric EM-like Algorithm</h2><span id='topic+plotseq.npEM'></span>

<h3>Description</h3>

<p>Returns plots of the sequences of scalar parameter
estimates along iterations from an object of class <code>npEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'npEM'
plotseq(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotseq.npEM_+3A_x">x</code></td>
<td>
<p>an object of class <code>npEM</code>, as output by <code><a href="#topic+npEM">npEM</a></code> 
or <code><a href="#topic+spEMsymloc">spEMsymloc</a></code></p>
</td></tr>
<tr><td><code id="plotseq.npEM_+3A_...">...</code></td>
<td>
<p>further parameters that are passed to <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plotseq.npEM</code> returns a figure with one plot for each component 
proportion, and, in the case of <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, one plot for each 
component mean.
</p>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics (to appear).
</p>
</li>
<li><p> Bordes, L., Chauveau, D., and Vandekerkhove, P. (2007),
An EM algorithm for a semiparametric mixture model, 
Computational Statistics and Data Analysis, 51: 5429-5443.   
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.npEM">plot.npEM</a></code>, <code><a href="#topic+rnormmix">rnormmix</a></code>,
<code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from a normal location mixture
n &lt;- 200
set.seed(100)
lambda &lt;- c(1/3,2/3)
mu &lt;- c(0, 4); sigma&lt;-rep(1, 2)
x &lt;- rnormmix(n, lambda, mu, sigma)
b &lt;- spEMsymloc(x, mu0=c(-1, 2), stochastic=FALSE)
plotseq(b)
bst &lt;- spEMsymloc(x, mu0=c(-1, 2), stochastic=TRUE)
plotseq(bst)
</code></pre>

<hr>
<h2 id='plotspRMM'>Plot output from Stochastic EM algorithm for semiparametric scaled mixture of censored data
</h2><span id='topic+plotspRMM'></span>

<h3>Description</h3>

<p>Function for plotting various results from an object returned by <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>, a Stochastic EM algorithm for semiparametric scaled 
mixture of randomly right censored lifetime data.
Four plots of sequences of estimates along iterations, survival and density estimates
(see reference below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotspRMM(sem, tmax = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotspRMM_+3A_sem">sem</code></td>
<td>
<p>An object returned by <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.</p>
</td></tr>
<tr><td><code id="plotspRMM_+3A_tmax">tmax</code></td>
<td>
<p>The max time for <code class="reqn">x</code> axis, set to some default value if <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The four plots returned</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions: <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See example(spRMM_SEM)
</code></pre>

<hr>
<h2 id='plotweibullRMM'>Plot sequences from the Stochastic EM algorithm for mixture of Weibull
</h2><span id='topic+plotweibullRMM'></span>

<h3>Description</h3>

<p>Function for plotting sequences of estimates along iterations, from an object returned by <code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>, a Stochastic EM algorithm for mixture of Weibull 
distributions with randomly right censored data (see reference below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotweibullRMM(a, title = NULL, rowstyle = TRUE, subtitle = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotweibullRMM_+3A_a">a</code></td>
<td>
<p>An object returned by <code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>.</p>
</td></tr>
<tr><td><code id="plotweibullRMM_+3A_title">title</code></td>
<td>
<p>The title of the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotweibullRMM_+3A_rowstyle">rowstyle</code></td>
<td>
<p>Window organization, for plots in rows (the default) or columns.</p>
</td></tr>
<tr><td><code id="plotweibullRMM_+3A_subtitle">subtitle</code></td>
<td>
<p>A subtitle for the plot, set to some default value if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotweibullRMM_+3A_...">...</code></td>
<td>
<p>Other parameters (such as <code>lwd</code>) passed to <code>plot</code>, <code>lines</code>, and  
<code>legend</code> commands.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The plot returned</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions:
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>,   <code><a href="#topic+summary.mixEM">summary.mixEM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>
.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 500 # sample size
m = 2 # nb components
lambda=c(0.4, 0.6)
shape &lt;- c(0.5,5); scale &lt;- c(1,20) # model parameters
set.seed(321)
x &lt;- rweibullmix(n, lambda, shape, scale) # iid ~ weibull mixture
cs=runif(n,0,max(x)+10) # iid censoring times
t &lt;- apply(cbind(x,cs),1,min) # censored observations
d &lt;- 1*(x &lt;= cs)              # censoring indicator

## set arbitrary or "reasonable" (e.g., data-driven) initial values
l0 &lt;- rep(1/m,m); sh0 &lt;- c(1, 2); sc0 &lt;- c(2,10)
# Stochastic EM algorithm 
a &lt;- weibullRMM_SEM(t, d, lambda = l0, shape = sh0, scale = sc0, maxit = 200)

summary(a) # Parameters estimates etc
plotweibullRMM(a) # default plot of St-EM sequences
</code></pre>

<hr>
<h2 id='poisregmixEM'>EM Algorithm for Mixtures of Poisson Regressions</h2><span id='topic+poisregmixEM'></span>

<h3>Description</h3>

<p>Returns EM algorithm output for mixtures of Poisson regressions with
arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisregmixEM(y, x, lambda = NULL, beta = NULL, k = 2,
             addintercept = TRUE, epsilon = 1e-08, 
             maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poisregmixEM_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>beta</code>.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and k is number of components.
If NULL, then <code>beta</code> is generated by binning the data into k bins and using <code>glm</code> on
the values in each of the bins.  If both <code>lambda</code> and <code>beta</code> are NULL, then 
number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless <code>lambda</code> and <code>beta</code> are both NULL.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="poisregmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>poisregmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The predictor values.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final Poisson regression coefficients.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>
<p>Wang, P., Puterman, M. L., Cockburn, I. and Le, N.  (1996)
Mixed Poisson Regression Models with Covariate Dependent Rates, <em>Biometrics</em>,
<b>52(2)</b>, 381&ndash;400.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logisregmixEM">logisregmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EM output for data generated from a 2-component model.

set.seed(100)
beta &lt;- matrix(c(1, .5, .7, -.8), 2, 2)
x &lt;- runif(50, 0, 10)
xbeta &lt;- cbind(1, x)%*%beta
w &lt;- rbinom(50, 1, .5)
y &lt;- w*rpois(50, exp(xbeta[, 1]))+(1-w)*rpois(50, exp(xbeta[, 2]))
out &lt;- poisregmixEM(y, x, verb = TRUE,  epsilon = 1e-03)
out
</code></pre>

<hr>
<h2 id='post.beta'>Summary of Posterior Regression Coefficients in Mixtures of Random Effects Regressions</h2><span id='topic+post.beta'></span>

<h3>Description</h3>

<p>Returns a 2x2 matrix of plots summarizing the posterior intercept and slope terms in a mixture of
random effects regression with arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post.beta(y, x, p.beta, p.z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="post.beta_+3A_y">y</code></td>
<td>
<p>A list of N response trajectories with (possibly) varying dimensions of
length <code class="reqn">n_i</code>.</p>
</td></tr>
<tr><td><code id="post.beta_+3A_x">x</code></td>
<td>
<p>A list of N predictor values of dimension <code class="reqn">n_i</code>.  Each trajectory in y has
its own design vector.</p>
</td></tr>
<tr><td><code id="post.beta_+3A_p.beta">p.beta</code></td>
<td>
<p>A list of N 2xk matrices giving the posterior intercept and slope values from the output of an
EM algorithm.</p>
</td></tr>
<tr><td><code id="post.beta_+3A_p.z">p.z</code></td>
<td>
<p>An Nxk matrix of posterior membership probabilities from the output of an EM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is primarily used for within <code>plot.mixEM</code>.
</p>


<h3>Value</h3>

<p><code>post.beta</code> returns a 2x2 matrix of plots giving:
</p>
<table>
<tr><td><code>(1</code>, <code>1)</code></td>
<td>
<p>The data plotted on the x-y axes with all posterior regression lines.</p>
</td></tr>
<tr><td><code>(1</code>, <code>2)</code></td>
<td>
<p>The data plotted on the x-y axes with most probable posterior regression lines.</p>
</td></tr>
<tr><td><code>(2</code>, <code>1)</code></td>
<td>
<p>A beta-space plot of all posterior regression coefficients.</p>
</td></tr>
<tr><td><code>(1</code>, <code>1)</code></td>
<td>
<p>A beta-space plot of most probable posterior regression coefficients.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Young, D. S. and Hunter, D. R. (2015) Random Effects Regression Mixtures for Analyzing Infant Habituation,
<em>Journal of Applied Statistics</em>, <b>42(7)</b>, 1421&ndash;1441.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM.mixed">regmixEM.mixed</a></code>, <code><a href="#topic+plot.mixEM">plot.mixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
## EM output for simulated data from 2-component mixture of random effects.

data(RanEffdata)
set.seed(100)
x &lt;- lapply(1:length(RanEffdata), function(i) 
            matrix(RanEffdata[[i]][, 2:3], ncol = 2))
x &lt;- x[1:20]
y &lt;- lapply(1:length(RanEffdata), function(i) 
            matrix(RanEffdata[[i]][, 1], ncol = 1))
y &lt;- y[1:20]
lambda &lt;- c(0.45, 0.55)
mu &lt;- matrix(c(0, 4, 100, 12), 2, 2)
sigma &lt;- 2
R &lt;- list(diag(1, 2), diag(1, 2))
em.out &lt;- regmixEM.mixed(y, x, sigma = sigma, arb.sigma = FALSE,
                         lambda = lambda, mu = mu, R = R,
                         addintercept.random = FALSE,
                         epsilon = 1e-02, verb = TRUE)

## Obtaining the 2x2 matrix of plots.

x.ran &lt;- lapply(1:length(x), function(i) x[[i]][, 2])
p.beta &lt;- em.out$posterior.beta
p.z &lt;- em.out$posterior.z
post.beta(y, x.ran, p.beta = p.beta, p.z = p.z)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.mvnpEM'>Printing of Results from the mvnpEM Algorithm Output</h2><span id='topic+print.mvnpEM'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+print">print</a></code> method for class <code>mvnpEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvnpEM'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mvnpEM_+3A_x">x</code></td>
<td>
<p>an object of class <code>mvnpEM</code> such as a result of a call
to <code><a href="#topic+mvnpEM">mvnpEM</a></code></p>
</td></tr>
<tr><td><code id="print.mvnpEM_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="base.html#topic+print">print</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.mvnpEM</code> prints the elements of an <code>mvnpEM</code> object
without printing the data or the posterior probabilities.
(These may still be accessed as <code>x$data</code> and <code>x$posteriors</code>.)
</p>


<h3>Value</h3>

<p><code>print.mvnpEM</code> returns (invisibly) the full value of <code>x</code> itself,
including the <code>data</code> and <code>posteriors</code> elements.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+mvnpEM">mvnpEM</a></code>,
<code><a href="#topic+plot.mvnpEM">plot.mvnpEM</a></code>
<code><a href="#topic+summary.mvnpEM">summary.mvnpEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example as in Chauveau and Hoang (2015) with 6 coordinates
## Not run: 
m=2; r=6; blockid &lt;-c(1,1,2,2,3,3) # 3 bivariate blocks 
# generate some data x ...
a &lt;- mvnpEM(x, mu0=2, blockid, samebw=F) # adaptive bandwidth
print(a)
## End(Not run)
</code></pre>

<hr>
<h2 id='print.npEM'>Printing non- and semi-parametric multivariate mixture model fits</h2><span id='topic+print.npEM'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+print">print</a></code> method for class <code>npEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'npEM'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.npEM_+3A_x">x</code></td>
<td>
<p>an object of class <code>npEM</code> such as a result of a call
to <code><a href="#topic+npEM">npEM</a></code></p>
</td></tr>
<tr><td><code id="print.npEM_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="base.html#topic+print">print</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.npEM</code> prints the elements of an <code>npEM</code> object
without printing the data or the posterior probabilities.
(These may still be accessed as <code>x$data</code> and <code>x$posteriors</code>.)
</p>


<h3>Value</h3>

<p><code>print.npEM</code> returns (invisibly) the full value of <code>x</code> itself,
including the <code>data</code> and <code>posteriors</code> elements.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+npEM">npEM</a></code>,
<code><a href="#topic+plot.npEM">plot.npEM</a></code>
<code><a href="#topic+summary.npEM">summary.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Waterdata)
set.seed(100)
## Not run: npEM(Waterdata[,3:10], 3, bw=4, verb=FALSE) # Assume indep but not iid
</code></pre>

<hr>
<h2 id='RanEffdata'>Simulated Data from 2-Component Mixture of Regressions with Random Effects</h2><span id='topic+RanEffdata'></span>

<h3>Description</h3>

<p>This data set was generated from a 2-component mixture of regressions with random effects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(RanEffdata)
</code></pre>


<h3>Format</h3>

<p>This data set consists of a list with 100 25x3 matrices. 
The first column is the response variable, the second column is a column of 1's and the last column is the
predictor variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM.mixed">regmixEM.mixed</a></code>
</p>

<hr>
<h2 id='regcr'>Add a Confidence Region or Bayesian Credible Region for Regression Lines to a Scatterplot</h2><span id='topic+regcr'></span>

<h3>Description</h3>

<p>Produce a confidence or credible region for regression lines based on
a sample of bootstrap beta values or posterior beta values.
The beta parameters are the intercept and slope
from a simple linear regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regcr(beta, x, em.beta = NULL, em.sigma = NULL, alpha = .05, 
      nonparametric = FALSE, plot = FALSE, xyaxes = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regcr_+3A_beta">beta</code></td>
<td>
<p>An nx2 matrix of regression parameters.  The first column
gives the intercepts and the second column gives the slopes.</p>
</td></tr> 
<tr><td><code id="regcr_+3A_x">x</code></td>
<td>
<p>An n-vector of the predictor variable which is necessary when
nonparametric = TRUE.</p>
</td></tr>
<tr><td><code id="regcr_+3A_em.beta">em.beta</code></td>
<td>
<p>The estimates for beta required when obtaining confidence
regions. This is required for performing the standardization necessary when
obtaining nonparametric confidence regions.</p>
</td></tr>
<tr><td><code id="regcr_+3A_em.sigma">em.sigma</code></td>
<td>
<p>The estimates for the regression standard deviation required when obtaining confidence
regions. This is required for performing the standardization necessary when
obtaining nonparametric confidence regions.</p>
</td></tr>
<tr><td><code id="regcr_+3A_alpha">alpha</code></td>
<td>
<p>The proportion of the beta sample to remove. In other
words, 1-alpha is the level of the credible region.</p>
</td></tr>
<tr><td><code id="regcr_+3A_nonparametric">nonparametric</code></td>
<td>

<p>If nonparametric = TRUE, then the region is based on the convex
hull of the remaining beta after trimming, which is accomplished
using a data depth technique.
If nonparametric = FALSE, then the region is based on the
asymptotic normal approximation.</p>
</td></tr>
<tr><td><code id="regcr_+3A_plot">plot</code></td>
<td>
<p>If plot = TRUE, lines are added to the existing plot.
The type of plot created depends on the value of xyaxes.</p>
</td></tr>
<tr><td><code id="regcr_+3A_xyaxes">xyaxes</code></td>
<td>
<p>If xyaxes = TRUE and plot = TRUE, then a confidence or credible region
for the regression lines is plotted on the x-y axes, presumably
overlaid on a scatterplot of the data.  If xyaxes = FALSE and
plot = TRUE, the (convex) credible region for the regression line is
plotted on the beta, or intercept-slope, axes, presumably overlaid
on a scatterplot of beta.</p>
</td></tr>
<tr><td><code id="regcr_+3A_...">...</code></td>
<td>
<p>Graphical parameters passed to <code>lines</code> or <code>plot</code>
command.</p>
</td></tr>   
</table>


<h3>Value</h3>

<p><code>regcr</code> returns a list containing the following items:
</p>
<table>
<tr><td><code>boundary</code></td>
<td>
<p>A matrix of points in beta, or intercept-slope, space
arrayed along the boundary of the confidence or credible region.</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>A matrix of points in x-y space arrayed along the upper
confidence or credible limit for the regression line.</p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>A matrix of points in x-y space arrayed along the lower
confidence or credible limit for the regression line.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>, <code><a href="#topic+regmixMH">regmixMH</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nonparametric credible regions fit to NOdata. 

data(NOdata)
attach(NOdata)
set.seed(100)
beta &lt;- matrix(c(1.3, -0.1, 0.6, 0.1), 2, 2)
sigma &lt;- c(.02, .05)
MH.out &lt;- regmixMH(Equivalence, NO, beta = beta, s = sigma, 
                   sampsize = 2500, omega = .0013)
attach(data.frame(MH.out$theta))
beta.c1 &lt;- cbind(beta0.1[2400:2499], beta1.1[2400:2499])
beta.c2 &lt;- cbind(beta0.2[2400:2499], beta1.2[2400:2499])
plot(NO, Equivalence)
regcr(beta.c1, x = NO, nonparametric = TRUE, plot = TRUE, 
      col = 2)
regcr(beta.c2, x = NO, nonparametric = TRUE, plot = TRUE, 
      col = 3)

</code></pre>

<hr>
<h2 id='regmixEM'>EM Algorithm for Mixtures of Regressions</h2><span id='topic+regmixEM'></span>

<h3>Description</h3>

<p>Returns EM algorithm output for mixtures of multiple regressions with
arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmixEM(y, x, lambda = NULL, beta = NULL, sigma = NULL, k = 2,
         addintercept = TRUE, arbmean = TRUE, arbvar = TRUE, 
         epsilon = 1e-08, maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regmixEM_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>beta</code>.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and k is number of components.
If NULL, then <code>beta</code> has standard normal entries according to a binning method done on the data.  If both
<code>lambda</code> and <code>beta</code> are NULL, then number of components is determined by <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.  If NULL, then 1/<code>sigma</code>^2 has
random standard exponential entries according to a binning method done on the data.
If <code>lambda</code>, <code>beta</code>, and <code>sigma</code> are
NULL, then number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless all of <code>lambda</code>, <code>beta</code>, 
and <code>sigma</code> are NULL.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_arbmean">arbmean</code></td>
<td>
<p>If TRUE, each mixture component is assumed to have a different set of regression coefficients
(i.e., the <code>beta</code>s).</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_arbvar">arbvar</code></td>
<td>
<p>If TRUE, each mixture component is assumed to have a different <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="regmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="regmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>regmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's if <code>addintercept</code> = TRUE).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations. If <code>arbmean</code> = FALSE, then only the smallest standard
deviation is returned. See <code>scale</code> below.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>If <code>arbmean</code> = FALSE, then the scale factor for the component standard deviations is returned.
Otherwise, this is omitted from the output.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>de Veaux, R. D. (1989), Mixtures of Linear Regressions,
<em>Computational Statistics and Data Analysis</em> 8, 227-245.
</p>
<p>Hurn, M., Justel, A. and Robert, C. P. (2003) Estimating Mixtures of Regressions, <em>Journal 
of Computational and Graphical Statistics</em> <b>12(1)</b>, 55&ndash;79.
</p>
<p>McLachlan, G. J. and Peel, D. (2000) <em>Finite Mixture Models</em>, John Wiley and Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcr">regcr</a></code>, <code><a href="#topic+regmixMH">regmixMH</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EM output for NOdata.
 
data(NOdata)
attach(NOdata)
set.seed(100)
em.out &lt;- regmixEM(Equivalence, NO, verb = TRUE, epsilon = 1e-04)
em.out[3:6]
</code></pre>

<hr>
<h2 id='regmixEM.lambda'>EM Algorithm for Mixtures of Regressions with Local Lambda Estimates</h2><span id='topic+regmixEM.lambda'></span>

<h3>Description</h3>

<p>Returns output for one step of an EM algorithm output for mixtures of multiple regressions 
where the mixing proportions are estimated locally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmixEM.lambda(y, x, lambda = NULL, beta = NULL, sigma = NULL, 
                k = 2, addintercept = TRUE, arbmean = TRUE,
                arbvar = TRUE, epsilon = 1e-8, maxit = 10000,
                verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regmixEM.lambda_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_lambda">lambda</code></td>
<td>
<p>An nxk matrix of initial local values of mixing proportions.  
Entries should sum to 1.  This determines number of components.  
If NULL, then <code>lambda</code> is simply one over the number of components.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and k is number of components.
If NULL, then <code>beta</code> has uniform standard normal entries.  If both
<code>lambda</code> and <code>beta</code> are NULL, then number of components is determined by <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_sigma">sigma</code></td>
<td>
<p>k-vector of initial global values of standard deviations.  
If NULL, then <code class="reqn">1/\code{sigma}^2</code> has random standard exponential entries.  
If <code>lambda</code>, <code>beta</code>, and <code>sigma</code> are NULL, then number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_k">k</code></td>
<td>
<p>The number of components.  Ignored unless all of <code>lambda</code>, <code>beta</code>,
and <code>sigma</code> are NULL.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_arbmean">arbmean</code></td>
<td>
<p>If TRUE, each mixture component is assumed to have a different set of regression coefficients
(i.e., the <code>beta</code>s).</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_arbvar">arbvar</code></td>
<td>
<p>If TRUE, each mixture component is assumed to have a different <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="regmixEM.lambda_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="regmixEM.lambda_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Primarily used within <code>regmixEM.loc</code>.
</p>


<h3>Value</h3>

<p><code>regmixEM.lambda</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's if <code>addintercept</code> = TRUE).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The inputted mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations. If <code>arbmean</code> = FALSE, then only the smallest standard
deviation is returned. See <code>scale</code> below.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>If <code>arbmean</code> = FALSE, then the scale factor for the component standard deviations is returned.
Otherwise, this is omitted from the output.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM.loc">regmixEM.loc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compare a 2-component and 3-component fit to NOdata.

data(NOdata)
attach(NOdata)
set.seed(100)
out1 &lt;- regmixEM.lambda(Equivalence, NO)
out2 &lt;- regmixEM.lambda(Equivalence, NO, k = 3)
c(out1$loglik, out2$loglik)

</code></pre>

<hr>
<h2 id='regmixEM.loc'>Iterative Algorithm Using EM Algorithm for Mixtures of Regressions with 
Local Lambda Estimates</h2><span id='topic+regmixEM.loc'></span>

<h3>Description</h3>

<p>Iterative algorithm returning EM algorithm output for mixtures of multiple regressions where the mixing proportions
are estimated locally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmixEM.loc(y, x, lambda = NULL, beta = NULL, sigma = NULL, 
             k = 2, addintercept = TRUE, kern.l = c("Gaussian",
             "Beta", "Triangle", "Cosinus", "Optcosinus"), 
             epsilon = 1e-08, maxit = 10000, kernl.g = 0, 
             kernl.h = 1, verb = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regmixEM.loc_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_lambda">lambda</code></td>
<td>
<p>An nxk matrix of initial local values of mixing proportions.  
Entries should sum to 1.  This determines number of components.  
If NULL, then <code>lambda</code> is simply one over the number of components.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_beta">beta</code></td>
<td>
<p>Initial global values of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and <code>k</code> is number of components.
If NULL, then <code>beta</code> has uniform standard normal entries.  If both
<code>lambda</code> and <code>beta</code> are NULL, then number of components is determined by <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_sigma">sigma</code></td>
<td>
<p>A k-vector of initial global values of standard deviations.
If NULL, then <code class="reqn">1/\code{sigma}^2</code> has random standard exponential entries.  
If <code>lambda</code>, <code>beta</code>, and <code>sigma</code> are NULL, then number of components determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless all of <code>lambda</code>, <code>beta</code>,
and <code>sigma</code> are NULL.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_kern.l">kern.l</code></td>
<td>
<p>The type of kernel to use in the local estimation of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="regmixEM.loc_+3A_kernl.g">kernl.g</code></td>
<td>
<p>A shape parameter required for the symmetric beta kernel for local estimation of <code>lambda</code>.  
The default is g = 0 which yields the uniform kernel.  Some common values are g = 1 for the
Epanechnikov kernel, g = 2 for the biweight kernel, and g = 3 for the triweight kernel.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_kernl.h">kernl.h</code></td>
<td>
<p>The bandwidth controlling the size of the window used in the
local estimation of lambda around x.</p>
</td></tr>
<tr><td><code id="regmixEM.loc_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>regmixEM.loc</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's if <code>addintercept</code> = TRUE).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda.x</code></td>
<td>
<p>The final local mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final global regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final global standard deviations.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM.lambda">regmixEM.lambda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compare a 2-component and 3-component fit to NOdata.

data(NOdata)
attach(NOdata)
set.seed(100)
out1 &lt;- regmixEM.loc(Equivalence, NO, kernl.h = 2, 
                     epsilon = 1e-02, verb = TRUE)
out2 &lt;- regmixEM.loc(Equivalence, NO, kernl.h = 2, k = 3,
                     epsilon = 1e-02, verb = TRUE)
c(out1$loglik, out2$loglik)

</code></pre>

<hr>
<h2 id='regmixEM.mixed'>EM Algorithm for Mixtures of Regressions with Random Effects</h2><span id='topic+regmixEM.mixed'></span>

<h3>Description</h3>

<p>Returns EM algorithm output for mixtures of multiple regressions with random effects
and an option to incorporate fixed effects and/or AR(1) errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmixEM.mixed(y, x, w = NULL, sigma = NULL, arb.sigma = TRUE,
               alpha = NULL, lambda = NULL, mu = NULL, 
               rho = NULL, R = NULL, arb.R = TRUE, k = 2, 
               ar.1 = FALSE, addintercept.fixed = FALSE, 
               addintercept.random = TRUE, epsilon = 1e-08, 
               maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regmixEM.mixed_+3A_y">y</code></td>
<td>
<p>A list of N response trajectories with (possibly) varying dimensions of
length <code class="reqn">n_i</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_x">x</code></td>
<td>
<p>A list of N design matrices of dimensions <code class="reqn">(n_i)\times p</code>.  
Each trajectory in y has
its own design matrix.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_w">w</code></td>
<td>
<p>A list of N known explanatory variables having dimensions <code class="reqn">(n_i)\times q</code>. 
If <code>mixed</code> = FALSE,
then <code>w</code> is replaced by a list of N zeros.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.  If NULL, then <code class="reqn">1/s^2</code> has
random standard exponential entries according to a binning method done on the data.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_arb.sigma">arb.sigma</code></td>
<td>
<p>If TRUE, then <code>sigma</code> is k-dimensional. Else a common standard deviation is assumed.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_alpha">alpha</code></td>
<td>
<p>A q-vector of unknown regression parameters for the fixed effects.  If NULL and <code>mixed</code> = TRUE, then <code>alpha</code> is 
random from a normal distribution with mean and variance according to a binning method done
on the data. If <code>mixed</code> = FALSE, then <code>alpha</code> = 0.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions for the assumed mixture structure on the regression coefficients.
Entries should sum to 1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and the number of components is determined by <code>mu</code>.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_mu">mu</code></td>
<td>
<p>A pxk matrix of the mean for the mixture components of the random regression coefficients. If NULL, then the columns
of <code>mu</code> are random from a multivariate normal distribution with mean and variance determined by a binning method
done on the data.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_rho">rho</code></td>
<td>
<p>An Nxk matrix giving initial values for the correlation term in an AR(1) process.  If NULL, then these values
are simulated from a uniform distribution on the interval (-1, 1).</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_r">R</code></td>
<td>
<p>A list of N pxp covariance matrices for the mixture components of the random regression coefficients. If NULL, then
each matrix is random from a standard Wishart distribution according to a binning method done on the data.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_arb.r">arb.R</code></td>
<td>
<p>If TRUE, then <code>R</code> is a list of N pxp covariance matrices.  Else, one common covariance matrix is assumed.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless <code>lambda</code> is NULL.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_ar.1">ar.1</code></td>
<td>
<p>If TRUE, then an AR(1) process on the error terms is included.  The default is FALSE.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_addintercept.fixed">addintercept.fixed</code></td>
<td>
<p>If TRUE, a column of ones is appended to the matrices in w.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_addintercept.random">addintercept.random</code></td>
<td>
<p>If TRUE, a column of ones is appended to the matrices in x before p is calculated.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="regmixEM.mixed_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="regmixEM.mixed_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>regmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The predictor values corresponding to the random effects.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>The predictor values corresponding to the (optional) fixed effects.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The final mean vectors.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>The final covariance matrices.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final component error standard deviations.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The final regression coefficients for the fixed effects.</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>The final error correlation values if an AR(1) process is included.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior.z</code></td>
<td>
<p>An Nxk matrix of posterior membership probabilities.</p>
</td></tr>
<tr><td><code>posterior.beta</code></td>
<td>
<p>A list of N pxk matrices giving the posterior regression coefficient values.</p>
</td></tr> 
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Xu, W. and Hedeker, D. (2001) A Random-Effects Mixture Model for Classifying Treatment Response in
Longitudinal Clinical Trials, <em>Journal of Biopharmaceutical Statistics</em>, <b>11(4)</b>, 253&ndash;273.
</p>
<p>Young, D. S. and Hunter, D. R. (2015) Random Effects Regression Mixtures for Analyzing Infant Habituation,
<em>Journal of Applied Statistics</em>, <b>42(7)</b>, 1421&ndash;1441.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>, <code><a href="#topic+post.beta">post.beta</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EM output for simulated data from 2-component mixture of random effects.

data(RanEffdata)
set.seed(100)
x &lt;- lapply(1:length(RanEffdata), function(i) 
            matrix(RanEffdata[[i]][, 2:3], ncol = 2))
x &lt;- x[1:20]
y &lt;- lapply(1:length(RanEffdata), function(i) 
            matrix(RanEffdata[[i]][, 1], ncol = 1))
y &lt;- y[1:20]
lambda &lt;- c(0.45, 0.55)
mu &lt;- matrix(c(0, 4, 100, 12), 2, 2)
sigma &lt;- 2
R &lt;- list(diag(1, 2), diag(1, 2))
em.out &lt;- regmixEM.mixed(y, x, sigma = sigma, arb.sigma = FALSE,
                         lambda = lambda, mu = mu, R = R,
                         addintercept.random = FALSE,
                         epsilon = 1e-02, verb = TRUE)
em.out[4:10]

</code></pre>

<hr>
<h2 id='regmixMH'>Metropolis-Hastings Algorithm for Mixtures of Regressions</h2><span id='topic+regmixMH'></span>

<h3>Description</h3>

<p>Return Metropolis-Hastings (M-H) algorithm output for mixtures of multiple regressions with
arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmixMH(y, x, lambda = NULL, beta = NULL, s = NULL, k = 2,
         addintercept = TRUE, mu = NULL, sig = NULL, lam.hyp = NULL,
         sampsize = 1000, omega = 0.01, thin = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regmixMH_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  See <code>addintercept</code> below.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>beta</code>.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a pxk matrix,
where p is the number of columns of x and k is number of components.
If NULL, then <code>beta</code> has uniform standard normal entries.  If both
<code>lambda</code> and <code>beta</code> are NULL, then number of components is determined by <code>s</code>.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_s">s</code></td>
<td>
<p>k-vector of standard deviations.  If NULL, then <code class="reqn">1/\code{s}^2</code> has
random standard exponential entries.  If <code>lambda</code>, <code>beta</code>, and <code>s</code> are
NULL, then number of components determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless all of <code>lambda</code>, <code>beta</code>,
and <code>s</code> are NULL.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_addintercept">addintercept</code></td>
<td>
<p>If TRUE, a column of ones is appended to the x
matrix before the value of p is calculated.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_mu">mu</code></td>
<td>
<p>The prior hyperparameter of same size as <code>beta</code>;
the means of <code>beta</code> components.  If NULL,
these are set to zero.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_sig">sig</code></td>
<td>
<p>The prior hyperparameter of same size as <code>beta</code>;
the standard deviations of <code>beta</code> components.  If NULL, these are 
all set to five times the overall standard deviation of y.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_lam.hyp">lam.hyp</code></td>
<td>
<p>The prior hyperparameter of length <code>k</code> for the mixing proportions (i.e.,
these are hyperparameters for the Dirichlet distribution).  If NULL, these are generated from a standard uniform
distribution and then scaled to sum to 1.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_sampsize">sampsize</code></td>
<td>
<p>Size of posterior sample returned.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_omega">omega</code></td>
<td>
<p>Multiplier of step size to control M-H acceptance rate.
Values closer to zero result in higher acceptance rates, generally.</p>
</td></tr>
<tr><td><code id="regmixMH_+3A_thin">thin</code></td>
<td>
<p>Lag between parameter vectors that will be kept.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>regmixMH</code> returns a list of class <code>mixMCMC</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>A nxp matrix of the predictors.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>A vector of the responses.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>A (<code>sampsize</code>/<code>thin</code>) x q matrix of MCMC-sampled
q-vectors, where q is the total number of parameters in <code>beta</code>, <code>s</code>, and
<code>lambda</code>.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>The number of components.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hurn, M., Justel, A. and Robert, C. P. (2003) Estimating Mixtures of Regressions, <em>Journal 
of Computational and Graphical Statistics</em> <b>12(1)</b>, 55&ndash;79.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regcr">regcr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## M-H algorithm for NOdata with acceptance rate about 40%.

data(NOdata)
attach(NOdata)
set.seed(100)
beta &lt;- matrix(c(1.3, -0.1, 0.6, 0.1), 2, 2)
sigma &lt;- c(.02, .05)
MH.out &lt;- regmixMH(Equivalence, NO, beta = beta, s = sigma, 
                   sampsize = 2500, omega = .0013)
MH.out$theta[2400:2499,]
</code></pre>

<hr>
<h2 id='regmixmodel.sel'>Model Selection in Mixtures of Regressions</h2><span id='topic+regmixmodel.sel'></span>

<h3>Description</h3>

<p>Assess the number of components in a mixture of regressions model using the Akaike's information
criterion (AIC), Schwartz's Bayesian information criterion (BIC), Bozdogan's consistent AIC (CAIC),
and Integrated Completed Likelihood (ICL).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regmixmodel.sel(x, y, w = NULL, k = 2, type = c("fixed", 
                "random", "mixed"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regmixmodel.sel_+3A_x">x</code></td>
<td>
<p>An nxp matrix (or list) of predictors. If an intercept is required, then <code>x</code> must NOT include a column of 1's!
Requiring an intercept may be controlled through arguments specified in <code>...</code>.</p>
</td></tr>
<tr><td><code id="regmixmodel.sel_+3A_y">y</code></td>
<td>
<p>An n-vector (or list) of response values.</p>
</td></tr>
<tr><td><code id="regmixmodel.sel_+3A_w">w</code></td>
<td>
<p>An optional list of fixed effects predictors for type &quot;mixed&quot; or &quot;random&quot;.</p>
</td></tr>
<tr><td><code id="regmixmodel.sel_+3A_k">k</code></td>
<td>
<p>The maximum number of components to assess.</p>
</td></tr>
<tr><td><code id="regmixmodel.sel_+3A_type">type</code></td>
<td>
<p>The type of regression mixture to use.  If &quot;fixed&quot;, then a mixture of regressions with fixed effects
will be used.  If &quot;random&quot;, then a mixture of regressions where the random effects regression coefficients are assumed
to come from a mixture will be used.  If &quot;mixed&quot;, the mixture structure used is the same as &quot;random&quot;, except a coefficient
of fixed effects is also assumed.</p>
</td></tr>
<tr><td><code id="regmixmodel.sel_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the EM algorithm used for calculating the type of regression mixture specified
in <code>type</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>regmixmodel.sel</code> returns a matrix of the AIC, BIC, CAIC, and ICL values along with the winner (i.e., the highest
value given by the model selection criterion) for various types of regression mixtures.
</p>


<h3>References</h3>

<p>Biernacki, C., Celeux, G. and Govaert, G. (2000) Assessing a Mixture Model for Clustering with the
Integrated Completed Likelihood, <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> <b>22(7)</b>, 719&ndash;725.
</p>
<p>Bozdogan, H. (1987) Model Selection and Akaike's Information Criterion (AIC): The General Theory and its
Analytical Extensions, <em>Psychometrika</em> <b>52</b>, 345&ndash;370.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>, <code><a href="#topic+regmixEM.mixed">regmixEM.mixed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Assessing the number of components for NOdata.

data(NOdata)
attach(NOdata)
set.seed(100)
regmixmodel.sel(x = NO, y = Equivalence, k = 3, type = "fixed")
</code></pre>

<hr>
<h2 id='repnormmixEM'>EM Algorithm for Mixtures of Normals with Repeated Measurements</h2><span id='topic+repnormmixEM'></span>

<h3>Description</h3>

<p>Returns EM algorithm output for mixtures of normals with repeated
measurements and arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repnormmixEM(x, lambda = NULL, mu = NULL, sigma = NULL, k = 2, 
             arbmean = TRUE, arbvar = TRUE, epsilon = 1e-08, 
             maxit = 10000, verb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repnormmixEM_+3A_x">x</code></td>
<td>
<p>An mxn matrix of data.  The columns correspond to the subjects and
the rows correspond to the repeated measurements.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and number of
components is determined by <code>mu</code>.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_mu">mu</code></td>
<td>
<p>A k-vector of component means.  If NULL, then <code>mu</code> is determined by a
normal distribution according to a binning method done on the data.  If both
<code>lambda</code> and <code>mu</code> are NULL, then number of components is determined by <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.  If NULL, then <code class="reqn">1/\code{sigma}^2</code> has
random standard exponential entries according to a binning method done on the data.
If <code>lambda</code>, <code>mu</code>, and <code>sigma</code> are NULL, then number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless all of <code>lambda</code>, <code>mu</code>, 
and <code>sigma</code> are NULL.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_arbmean">arbmean</code></td>
<td>
<p>If TRUE, then the component densities are allowed to have different <code>mu</code>s. If FALSE, then
a scale mixture will be fit.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_arbvar">arbvar</code></td>
<td>
<p>If TRUE, then the component densities are allowed to have different <code>sigma</code>s. If FALSE, then
a location mixture will be fit.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="repnormmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="repnormmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>repnormmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The final mean parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations. If <code>arbmean</code> = FALSE, then only the smallest standard
deviation is returned. See <code>scale</code> below.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>If <code>arbmean</code> = FALSE, then the scale factor for the component standard deviations is returned.
Otherwise, this is omitted from the output.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hettmansperger, T. P. and Thomas, H.  (2000)
Almost Nonparametric Inference for Repeated Measures in Mixture Models,
<em>Journal of the Royals Statistical Society, Series B</em> <b>62(4)</b> 811&ndash;825.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+normalmixEM">normalmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EM output for the water-level task data set.

data(Waterdata)
set.seed(100)
water &lt;- t(as.matrix(Waterdata[,3:10]))
em.out &lt;- repnormmixEM(water, k = 2, verb = TRUE, epsilon = 1e-03)
em.out
</code></pre>

<hr>
<h2 id='repnormmixmodel.sel'>Model Selection in Mixtures of Normals with Repeated Measures</h2><span id='topic+repnormmixmodel.sel'></span>

<h3>Description</h3>

<p>Assess the number of components in a mixture model with normal components and repeated measures 
using the Akaike's information criterion (AIC), Schwartz's Bayesian information criterion (BIC), 
Bozdogan's consistent AIC (CAIC), and Integrated Completed Likelihood (ICL).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repnormmixmodel.sel(x, k = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repnormmixmodel.sel_+3A_x">x</code></td>
<td>
<p>An mxn matrix of observations. The rows correspond to the repeated measures and the columns correspond
to the subject.</p>
</td></tr>
<tr><td><code id="repnormmixmodel.sel_+3A_k">k</code></td>
<td>
<p>The maximum number of components to assess.</p>
</td></tr>
<tr><td><code id="repnormmixmodel.sel_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>repnormmixEM</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>repnormmixmodel.sel</code> returns a matrix of the AIC, BIC, CAIC, and ICL values along with the winner (i.e., the highest
value given by the model selection criterion) for a mixture of normals with repeated measures.
</p>


<h3>References</h3>

<p>Biernacki, C., Celeux, G., and Govaert, G. (2000). Assessing a Mixture Model for Clustering with the
Integrated Completed Likelihood. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 22(7):719-725.
</p>
<p>Bozdogan, H. (1987). Model Selection and Akaike's Information Criterion (AIC): The General Theory and its
Analytical Extensions. <em>Psychometrika</em>, 52:345-370.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+repnormmixEM">repnormmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Assessing the number of components for the water-level task data set.

data(Waterdata)
water&lt;-t(as.matrix(Waterdata[,3:10]))
set.seed(100)
out &lt;- repnormmixmodel.sel(water, k = 3, epsilon = 5e-01)
out
</code></pre>

<hr>
<h2 id='rexpmix'>Simulate from Mixtures of Exponentials</h2><span id='topic+rexpmix'></span>

<h3>Description</h3>

<p>Simulate from a mixture of univariate exponential distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rexpmix(n, lambda = 1, rate = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rexpmix_+3A_n">n</code></td>
<td>
<p>Number of cases to simulate.</p>
</td></tr>
<tr><td><code id="rexpmix_+3A_lambda">lambda</code></td>
<td>
<p>Vector of mixture probabilities, with length equal to <code class="reqn">m</code>, 
the desired number of components (subpopulations).  This is assumed to sum
to 1.</p>
</td></tr>
<tr><td><code id="rexpmix_+3A_rate">rate</code></td>
<td>
<p>Vector of component rates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rexpmix</code> returns an <code class="reqn">n</code>-vector sampled from an <code class="reqn">m</code>-component 
mixture of univariate exponential distributions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnormmix">rnormmix</a></code>, <code><a href="#topic+rmvnormmix">rmvnormmix</a></code> for Gaussian mixtures,
<code><a href="#topic+rweibullmix">rweibullmix</a></code> for mixture of Weibull distributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data from a 2-component mixture of exponentials.
n=300 # sample size
m=2 # nb components
lambda=c(1/3, 2/3); rate = c(1,1/10) # parameters
set.seed(1234)
x &lt;- rexpmix(n, lambda, rate) # iid ~ exp mixture

## histogram of the simulated data.
hist(x, col=8)
</code></pre>

<hr>
<h2 id='rmvnorm'>Simulate from a Multivariate Normal Distribution</h2><span id='topic+rmvnorm'></span>

<h3>Description</h3>

<p>Simulate from a multiviate normal distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnorm(n, mu=NULL, sigma=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvnorm_+3A_n">n</code></td>
<td>
<p>Number of vectors to simulate</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_mu">mu</code></td>
<td>
<p>mean vector</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix, assumed symmetric and nonnegative definite</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses an <code><a href="base.html#topic+eigen">eigen</a></code> decomposition assuming <code>sigma</code> is symmetric.
In particular, the upper triangle of <code>sigma</code> is ignored.
</p>


<h3>Value</h3>

<p>An <code class="reqn">n \times d</code> matrix in which each row is an independently
generated realization from the desired multivariate normal distribution
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+eigen">eigen</a></code>, <code><a href="stats.html#topic+dnorm">dnorm</a></code>, <code><a href="#topic+dmvnorm">dmvnorm</a></code>
</p>

<hr>
<h2 id='rmvnormmix'>Simulate from Multivariate (repeated measures) Mixtures of Normals</h2><span id='topic+normmixrm.sim'></span><span id='topic+rmvnormmix'></span>

<h3>Description</h3>

<p>Simulate from a mixture of multivariate zero-correlation normal distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnormmix(n, lambda=1, mu=0, sigma=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvnormmix_+3A_n">n</code></td>
<td>
<p>Number of cases to simulate.</p>
</td></tr>
<tr><td><code id="rmvnormmix_+3A_lambda">lambda</code></td>
<td>
<p>Vector of mixture probabilities with length equal to <code class="reqn">m</code>, the
desired number of components.  This is assumed to sum
to 1; if not, it is normalized.</p>
</td></tr>
<tr><td><code id="rmvnormmix_+3A_mu">mu</code></td>
<td>
<p>Matrix of means of dimensions <code class="reqn">m\times r</code>, where
<code class="reqn">m</code> is the number of components (subpopulations) and <code class="reqn">r</code> is
the number of coordinates (repeated measurements) per case.  Note:  <code>mu</code>
is automatically coerced to a matrix with <code class="reqn">m</code> rows even if it is not
given in this form, which can lead to unexpected behavior in some cases.</p>
</td></tr>
<tr><td><code id="rmvnormmix_+3A_sigma">sigma</code></td>
<td>
<p>Matrix of standard deviations, same dimensions as <code>mu</code>.
The coordinates within a case are independent, conditional on the mixture
component. (There is marginal correlation among the coordinates, but
this is due to the mixture structure only.)  Note:  <code>sigma</code> is
automatically coerced to a matrix with <code class="reqn">m</code> rows even if it is not
given in this form, which can lead to unexpected behavior in some cases.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is possible to generate univariate standard normal random variables using
the default values (but why bother?).  The case of conditionally iid
coordinates is covered by the situation in which
all columns in mu and sigma are identical.
</p>


<h3>Value</h3>

<p><code>rmvnormmix</code> returns an <code class="reqn">n\times r</code> matrix in which each row is
a sample from one of the components of a mixture of zero-correlation 
multivariate normals.  The mixture structure
induces nonzero correlations among the coordinates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnormmix">rnormmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Generate data from a 2-component mixture of trivariate normals.

set.seed(100)
n &lt;- 200
lambda &lt;- rep(1, 2)/2
mu &lt;- matrix(2*(1:6), 2, 3)
sigma &lt;- matrix(1,2,3)
mydata&lt;-rmvnormmix(n, lambda, mu, sigma)

## Now check to see if we can estimate mixture densities well:
title &lt;- paste("Does this resemble N(", mu[1,], ",1) and N(", mu[2,],",1)?",
                sep="")
plot(npEM(mydata, 2), title=title)
</code></pre>

<hr>
<h2 id='rnormmix'>Simulate from Mixtures of Normals</h2><span id='topic+normmix.sim'></span><span id='topic+rnormmix'></span>

<h3>Description</h3>

<p>Simulate from a mixture of univariate normal distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnormmix(n, lambda=1, mu=0, sigma=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rnormmix_+3A_n">n</code></td>
<td>
<p>Number of cases to simulate.</p>
</td></tr>
<tr><td><code id="rnormmix_+3A_lambda">lambda</code></td>
<td>
<p>Vector of mixture probabilities, with length equal to <code class="reqn">m</code>,
the desired number of components (subpopulations).  This is assumed to sum
to 1; if not, it is normalized.</p>
</td></tr>
<tr><td><code id="rnormmix_+3A_mu">mu</code></td>
<td>
<p>Vector of means.</p>
</td></tr>
<tr><td><code id="rnormmix_+3A_sigma">sigma</code></td>
<td>
<p>Vector of standard deviations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simply calls <code><a href="#topic+rmvnormmix">rmvnormmix</a></code>.</p>


<h3>Value</h3>

<p><code>rnormmix</code> returns an <code class="reqn">n</code>-vector sampled from an <code class="reqn">m</code>-component 
mixture of univariate normal distributions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makemultdata">makemultdata</a></code>, <code><a href="#topic+rmvnormmix">rmvnormmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Generate data from a 2-component mixture of normals.

set.seed(100)
n &lt;- 500
lambda &lt;- rep(1, 2)/2
mu &lt;- c(0, 5)
sigma &lt;- rep(1, 2)
mixnorm.data &lt;- rnormmix(n, lambda, mu, sigma)

##A histogram of the simulated data.

hist(mixnorm.data)
</code></pre>

<hr>
<h2 id='RodFramedata'>Rod and Frame Task Data Set</h2><span id='topic+RodFramedata'></span>

<h3>Description</h3>

<p>This data set involves assessing children longitudinally at 6 age points from ages 4 through 18 years for the rod and
frame task.  This task sits the child in a darkened room in front of a luminous square frame tilted at 28 degrees on its
axis to the left or right.  Centered inside the frame was a luminous rod also tilted 28 degrees to the left or right.  The
child's task was to adjust the rod to the vertical position and the absolute deviation from the vertical (in degrees) was the
measured response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(RodFramedata)
</code></pre>


<h3>Format</h3>

<p>This data frame consists of 140 children (the rows).  Column 1 is the subject number and column 
2 is the sex (0=MALE and 1=FEMALE).  Columns 3 through 26 give the 8 responses at each of the ages 4, 5, and 7.  
Columns 27 through 56 give the 10 responses at each of the ages 11, 14, and 18.  A value of 99 denotes missing data.
</p>


<h3>Source</h3>

<p>Thomas, H. and Dahlin, M. P. (2005) Individual Development and Latent Groups: Analytical Tools for Interpreting Heterogeneity,
<em>Developmental Review</em> <b>25(2)</b>, 133&ndash;154.
</p>

<hr>
<h2 id='RTdata'>Reaction Time (RT) Data Set</h2><span id='topic+RTdata'></span>

<h3>Description</h3>

<p>This data set involves normally developing children 9 years of age presented with two visual simuli on a computer monitor.
The left image is the target stimuli and on the right is either an exact copy or a mirror image
of the target stimuli.  The child must press one key if it is a copy or another key if it is a mirror image.  The
data consists of the reaction times (RT) of the 197 children who provided correct responses for all 6 task trials. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(RTdata)
</code></pre>


<h3>Format</h3>

<p>This data frame consists of 197 children (the rows) and their 6 responses (the columns)
to the stimulus presented.  The response (RT) is recorded in milliseconds.
</p>


<h3>References</h3>

<p>Cruz-Medina, I. R., Hettmansperger, T. P. and Thomas, H. (2004) Semiparametric Mixture Models and Repeated
Measures: The Multinomial Cut Point Model, <em>Applied Statistics</em> <b>53(3)</b>, 463&ndash;474.
</p>
<p>Miller, C. A., Kail, R., Leonard, L. B. and Tomblin, J. B. (2001) Speed of Processing in Children with
Specific Language Impairment, <em>Journal of Speech, Language, and Hearing Research</em> <b>44(2)</b>, 416&ndash;433.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RTdata2">RTdata2</a></code>
</p>

<hr>
<h2 id='RTdata2'>Reaction Time (RT) Data Set (No. 2)</h2><span id='topic+RTdata2'></span>

<h3>Description</h3>

<p>This data set involves normally developing children 9 years of age presented 
visual simuli on a computer monitor.  There are three different experimental
conditions, according to the length of the delay after which the stimulus 
was displayed on the screen.  Each subject experienced each condition eight
times, and these 24 trials were given in random order.
These data give the 82 children for whom
there are complete measurements among over 200 total subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(RTdata2)
</code></pre>


<h3>Format</h3>

<p>This data frame consists of 82 children (the rows) and their 24 responses (the columns)
to the stimulus presented.  The response is recorded in milliseconds.  The columns are
not in the order in which the stimuli were presented to the children;  rather, they
are arranged into three blocks of eight columns each so that each eight-column
block contains only trials from one of the three conditions.
</p>


<h3>References</h3>

<p>Miller, C. A., Kail, R., Leonard, L. B. and Tomblin, J. B. (2001) Speed of Processing in Children with
Specific Language Impairment, <em>Journal of Speech, Language, and Hearing Research</em> <b>44(2)</b>, 416&ndash;433.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RTdata">RTdata</a></code>
</p>

<hr>
<h2 id='rweibullmix'>Simulate from Mixtures of Weibull distributions</h2><span id='topic+rweibullmix'></span>

<h3>Description</h3>

<p>Simulate from a mixture of univariate Weibull distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rweibullmix(n, lambda = 1, shape = 1, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rweibullmix_+3A_n">n</code></td>
<td>
<p>Number of cases to simulate.</p>
</td></tr>
<tr><td><code id="rweibullmix_+3A_lambda">lambda</code></td>
<td>
<p>Vector of mixture probabilities, with length equal to <code class="reqn">m</code>, 
the desired number of components (subpopulations).  This is assumed to sum
to 1.</p>
</td></tr>
<tr><td><code id="rweibullmix_+3A_shape">shape</code></td>
<td>
<p>Vector of component shapes.</p>
</td></tr>
<tr><td><code id="rweibullmix_+3A_scale">scale</code></td>
<td>
<p>Vector of component scales.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rexpmix</code> returns an <code class="reqn">n</code>-vector sampled from an <code class="reqn">m</code>-component 
mixture of univariate Weibull distributions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnormmix">rnormmix</a></code> and <code><a href="#topic+rmvnormmix">rmvnormmix</a></code> for Gaussian mixtures,
<code><a href="#topic+rexpmix">rexpmix</a></code> for mixture of exponentials.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 500 # sample size
m = 2 # nb components
lambda=c(0.4, 0.6)
shape &lt;- c(0.5,5); scale &lt;- c(1,20) # model parameters
set.seed(321)
x &lt;- rweibullmix(n, lambda, shape, scale) # iid ~ weibull mixture

## histogram of the simulated data.
hist(x, col=8)
</code></pre>

<hr>
<h2 id='segregmixEM'>ECM Algorithm for Mixtures of Regressions with Changepoints</h2><span id='topic+segregmixEM'></span><span id='topic+regmixEM.chgpt'></span>

<h3>Description</h3>

<p>Returns ECM algorithm output for mixtures of multiple regressions with
changepoints and arbitrarily many components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segregmixEM(y, x, lambda = NULL, beta = NULL, sigma = NULL, 
            k = 2, seg.Z, psi, psi.locs = NULL, delta = NULL, 
            epsilon = 1e-08, maxit = 10000, verb = FALSE,
            max.restarts = 15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segregmixEM_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_x">x</code></td>
<td>
<p>An nxp matrix of predictors.  Note that this model assumes the presence of an intercept.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to
1.  This determines number of components.  If NULL, then <code>lambda</code> is
random from uniform Dirichlet and the number of
components is determined by <code>beta</code>.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  This is a list of length <code>k</code> such that each element must contain a vector having length consistent with the defined changepoint structure. See <code>seg.Z</code>, <code>psi</code>, and <code>psi.loc</code> below. If NULL, then <code>beta</code> has standard normal entries according to a binning method done on the data.  If both
<code>lambda</code> and <code>beta</code> are NULL, then number of components is determined by <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.  If NULL, then 1/<code>sigma</code>^2 has
random standard exponential entries according to a binning method done on the data.
If <code>lambda</code>, <code>beta</code>, and <code>sigma</code> are
NULL, then number of components is determined by <code>k</code>.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_k">k</code></td>
<td>
<p>Number of components.  Ignored unless all of <code>lambda</code>, <code>beta</code>, 
and <code>sigma</code> are NULL.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_seg.z">seg.Z</code></td>
<td>
<p>A list of length <code>k</code> whose elements are right-hand side formulas, which are additive linear models of the predictors that have changepoints in their respective components.  See below for more details.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_psi">psi</code></td>
<td>
<p>A kxp matrix specifying the number of changepoints for each predictor in each component. See below for more details.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_psi.locs">psi.locs</code></td>
<td>
<p>A list of length <code>k</code> that has initial estimates for the changepoint locations.  Each element of the list must have length equal to the number of chanegpoints specified in the corresponding row of the <code>psi</code> matrix.  For components with no changepoints, simply set that element equal to NULL. See below for more details.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_delta">delta</code></td>
<td>
<p>An optional list of values quantifying the amount of separation at each changepoint if assuming discontinuities at the changepoints.  This has the same dimensions as <code>psi.locs</code>.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="segregmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="segregmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
<tr><td><code id="segregmixEM_+3A_max.restarts">max.restarts</code></td>
<td>
<p>The number of times to try restarting the ECM algorithm if estimation problems occur - such as choice of poor initial values or a poorly chosen changepoint structure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>seg.Z</code> is defined as a list of right-hand side linear model formulas that are used to identify which predictors have changepoints in each component.  For example, suppose you have a dataframe with three predictors: <code>V1</code>, <code>V2</code>, <code>V3</code>.  Suppose now that you wish to model a 3-component mixture of regressions with changepoints structure such that the first component has changepoints in V1 and V2, the second component has changepoints in <code>V3</code>, and the third component has no changepoints.  Then you would define <code>seg.Z = list(~V1+V2, ~V3, NULL)</code>.  Note that you MUST place the variables in order with respect to how they appear in the predictor matrix <code>x</code>.
</p>
<p><code>psi</code> is a kxp matrix specifying the number of changepoints for each predictor in each component.  For the example given above, suppose there are three changepoints for <code>V1</code>, two changepoints for <code>V2</code>, and four changepoints for <code>V3</code>.  Then you would define <code>psi = rbind(c(3, 2, 0), c(0, 0, 4), c(0, 0, 0))</code>.
</p>
<p><code>psi.locs</code> is a list of length k whose elements give the initial locations of the changepoints for each component.  Each element of the list must have length equal to the total number of changepoints for that component's regression equation.  For the example given above, in component 1, assume that the three changepoints for <code>V1</code> are at 3, 7, and 10 and the two changepoints for <code>V1</code> are at 5, 20, and 30.  In component 2, assume that the four changepoints for <code>V3</code> are at 2, 4, 6, and 8.  Then you would define <code>psi.locs = list(c(3, 7, 10, 5, 20, 30), c(2, 4, 6, 8), NULL)</code>.  Note that the order of the changepoints is determined by first sorting the predictors by how they appear in the formulas in <code>seg.Z</code> and then sorting in increasing order within each predictor.
</p>


<h3>Value</h3>

<p><code>segregmixEM</code> returns a list of class <code>segregmixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations.</p>
</td></tr>
<tr><td><code>seg.Z</code></td>
<td>
<p>The list of right-hand side formulas as defined by the user.</p>
</td></tr>
<tr><td><code>psi.locs</code></td>
<td>
<p>A list of length k with the final estimates for the changepoint locations.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>A list of the delta values that were optionally specified by the user.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>As of version 0.4.6, this more general function has replaced the now defunct <code>regmixEM.chgpt</code> and associated internal functions.
</p>


<h3>References</h3>

<p>Young, D. S. (2014) Mixtures of Regressions with Changepoints, <em>Statistics and Computing</em>, <b>24(2)</b>, 265&ndash;281.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulated example.

set.seed(100)
x &lt;- 1:20
y1 &lt;- 3 + x + rnorm(20)
y2 &lt;- 3 - x - 5*(x - 15)*(x &gt; 15) + rnorm(20)
y &lt;- c(y1, y2)
x &lt;- c(x, x)

set.seed(100)
be &lt;- list(c(3, -1, -5), c(3, 1))
s &lt;- c(1, 1)
psi.locs &lt;- list(comp.1 = list(x = 15), comp.2 = NULL)
out &lt;- segregmixEM(y, cbind(1,x), verb = TRUE, k = 2,
                   beta = be, sigma = s, lambda = c(1, 1)/2, 
                   seg.Z = list(~x, NULL), psi = rbind(1, 0),
                   psi.locs = psi.locs, epsilon = 0.9)

z &lt;- seq(0, 21, len = 40)
plot(x, y, col = apply(out$post, 1, which.max) + 1, pch = 19, 
	   cex.lab = 1.4, cex = 1.4)
b &lt;- out$beta
d &lt;- out$psi.locs
lines(z, b[[1]][1] + b[[1]][2] * z + b[[1]][3] * 
      (z - d[[1]][[1]]) * (z &gt; d[[1]][[1]]) , col = 2, lwd = 2)
lines(z, b[[2]][1] + b[[2]][2] * z, col = 3, lwd = 2)
abline(v = out$psi.locs[[1]][1], col = 2, lty = 2)

## End(Not run)

## Not run: 
## Example using the NOdata.
 
data(NOdata)
attach(NOdata)

set.seed(100)
be &lt;- list(c(1.30, -0.13, 0.08), c(0.56, 0.09))
s &lt;- c(0.02, 0.04)
psi.locs &lt;- list(comp.1 = list(NO = 1.57), comp.2 = NULL)
out &lt;- segregmixEM(Equivalence, cbind(NO), verb = TRUE, k = 2,
                   beta = be, sigma = s, lambda = c(1, 1)/2, 
                   seg.Z = list(~NO, NULL), psi = rbind(1, 0),
                   psi.locs = psi.locs, epsilon = 0.1)

z &lt;- seq(0, 5, len = 1000)
plot(NOdata, col = apply(out$post, 1, which.max) + 1, pch = 19, 
	   cex.lab = 1.4, cex = 1.4, ylab = "Equivalence Ratio")
b &lt;- out$beta
d &lt;- out$psi.locs
lines(z, b[[1]][1] + b[[1]][2] * z + b[[1]][3] * 
      (z - d[[1]][[1]]) * (z &gt; d[[1]][[1]]) , col = 2, lwd = 2)
lines(z, b[[2]][1] + b[[2]][2] * z, col = 3, lwd = 2)
abline(v = out$psi.locs[[1]][1], col = 2, lty = 2)

detach(NOdata)

## End(Not run)
</code></pre>

<hr>
<h2 id='spEM'>Semiparametric EM-like Algorithm for Mixtures of Independent Repeated Measurements</h2><span id='topic+spEM'></span>

<h3>Description</h3>

<p>Returns semiparametric EM algorithm output (Benaglia et al, 2009) for mixtures
of multivariate (repeated measures) data where the coordinates of a row (case)
in the data matrix are assumed to be independent, conditional on the mixture
component (subpopulation) from which they are drawn.
For now, this algorithm only implements model (4.7) in 
Benaglia et al, in which each component and block has exactly
the same (nonparametric) shape and they differ only by location and scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spEM(x, mu0, blockid = 1:ncol(x), 
     bw = bw.nrd0(as.vector(as.matrix(x))), constbw = TRUE, 
     h = bw, eps = 1e-8, 
     maxiter = 500, stochastic = FALSE, verb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spEM_+3A_x">x</code></td>
<td>
<p>An <code class="reqn">n\times r</code> matrix of data.  Each of the <code class="reqn">n</code> rows is a case,
and each case has <code class="reqn">r</code> repeated measurements.  These measurements are assumed
to be conditionally independent, conditional on the mixture component (subpopulation) 
from which the case is drawn.</p>
</td></tr>
<tr><td><code id="spEM_+3A_mu0">mu0</code></td>
<td>
<p>Either an <code class="reqn">m\times r</code> matrix specifying the initial
centers for the <a href="stats.html#topic+kmeans">kmeans</a> function, or an integer <code class="reqn">m</code> specifying the 
number of initial centers, which are then choosen randomly in
<a href="stats.html#topic+kmeans">kmeans</a></p>
</td></tr>
<tr><td><code id="spEM_+3A_blockid">blockid</code></td>
<td>
<p>A vector of length <code class="reqn">r</code> identifying coordinates 
(columns of <code>x</code>) that are
assumed to be identically distributed (i.e., in the same block).  For instance,
the default has all distinct elements, indicating that no two coordinates 
are assumed identically distributed and thus a separate set of <code class="reqn">m</code> 
density estimates is produced for each column of <code class="reqn">x</code>.  On the other hand,
if <code>blockid=rep(1,ncol(x))</code>, then the coordinates in each row 
are assumed conditionally i.i.d.</p>
</td></tr>
<tr><td><code id="spEM_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for density estimation, equal to the standard deviation 
of the kernel density.  By default, a simplistic application of the 
default <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> 
bandwidth used by <code><a href="stats.html#topic+density">density</a></code> to the entire dataset.</p>
</td></tr>
<tr><td><code id="spEM_+3A_constbw">constbw</code></td>
<td>
<p>Logical:  If <code>TRUE</code>, use the same bandwidth for
each iteration and for each component and block.  If <code>FALSE</code>, 
use a separate bandwidth for each component and block, and update
this bandwidth at each iteration of the algorithm using a suitably
modified <code><a href="stats.html#topic+bw.nrd0">bw.nrd0</a></code> method as described in 
Benaglia et al (2011).</p>
</td></tr>
<tr><td><code id="spEM_+3A_h">h</code></td>
<td>
<p>Alternative way to specify the bandwidth, to provide backward 
compatibility.</p>
</td></tr>
<tr><td><code id="spEM_+3A_eps">eps</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence.  Convergence
is declared whenever the maximum change in any coordinate of the 
<code>lambda</code> vector (of mixing proportion estimates) does not exceed 
<code>eps</code>.</p>
</td></tr>
<tr><td><code id="spEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations allowed, for both 
stochastic and non-stochastic versions; 
for non-stochastic algorithms (<code>stochastic = FALSE</code>), convergence
may be declared before <code>maxiter</code> iterations (see <code>eps</code> above).</p>
</td></tr>
<tr><td><code id="spEM_+3A_stochastic">stochastic</code></td>
<td>
<p>Flag, if FALSE (the default), runs the non-stochastic version
of the npEM algorithm, as in Benaglia et al (2009). Set to TRUE to
run a stochastic version which simulates the posteriors at each
iteration, and runs for <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code id="spEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>spEM</code> returns a list of class <code>spEM</code> with the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The raw data (an <code class="reqn">n\times r</code> matrix).</p>
</td></tr>
<tr><td><code>posteriors</code></td>
<td>
<p>An <code class="reqn">n\times m</code> matrix of posterior probabilities for
observation. If <code>stochastic = TRUE</code>, this matrix is computed 
from an average over the <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>If <code>constbw==TRUE</code>, 
same as the <code>bw</code> input argument; otherwise, value of <code>bw</code> matrix
at final iteration (since for now this algorithm only implements 
model (4.7) in Benaglia et al, the bandwidth matrix is reduced to a single
bandwith scalar).  
This
information is needed by any method that produces density estimates from the
output.</p>
</td></tr>
<tr><td><code>blockid</code></td>
<td>
<p>Same as the <code>blockid</code> input argument, but recoded to have
positive integer values.  Also needed by any method that produces density 
estimates from the output.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>lambdahat</code></td>
<td>
<p>The final mixing proportions if <code>stochastic = FALSE</code>, 
or the average mixing proportions if <code>stochastic = TRUE</code>.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The sequence of location parameters over iterations.</p>
</td></tr>
<tr><td><code>muhat</code></td>
<td>
<p>The final location parameters if <code>stochastic = FALSE</code>, 
or the average location parameters if <code>stochastic = TRUE</code>.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The sequence of scale parameters over iterations.</p>
</td></tr>
<tr><td><code>sigmahat</code></td>
<td>
<p>The final scale parameters if <code>stochastic = FALSE</code>, 
or the average scale parameters if <code>stochastic = TRUE</code>.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The sequence of log-likelihoods over iterations.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R., An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526, 2009.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D. and Hunter, D.R.
Bandwidth Selection in an EM-like algorithm for nonparametric multivariate mixtures.
Nonparametric Statistics and Mixture Models: A Festschrift in
Honor of Thomas P. Hettmansperger. World Scientific Publishing Co., 
pages 15-27, 2011.
</p>
</li>
<li><p> Bordes, L., Chauveau, D., and Vandekerkhove, P.,
An EM algorithm for a semiparametric mixture model, 
Computational Statistics and Data Analysis, 51: 5429-5443, 2007.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.spEM">plot.spEM</a></code>, <code><a href="#topic+normmixrm.sim">normmixrm.sim</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>,
<code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## simulate a 2-component gaussian mixture with 3 iid repeated measures
set.seed(100)
mu &lt;- matrix(c(0, 15), 2, 3)
sigma &lt;- matrix(c(1, 5), 2, 3)
x &lt;- rmvnormmix(300, lambda = c(.4,.6), mu = mu, sigma = sigma)

## apply spEM with or without an iterative bandwidth selection
d &lt;- spEM(x, mu0 = 2, blockid = rep(1,3), constbw = FALSE)
d2 &lt;- spEM(x, mu0 = 2, blockid = rep(1,3), constbw = TRUE)
plot(d, xlim=c(-10, 40), ylim = c(0, .16), xlab = "", breaks = 30,
     cex.lab=1.5, cex.axis=1.5, addlegend=FALSE)
plot(d2, newplot=FALSE, addlegend=FALSE, lty=2)
## End(Not run)
</code></pre>

<hr>
<h2 id='spEMsymloc'>Semiparametric EM-like Algorithm for univariate symmetric location mixture</h2><span id='topic+spEMsymloc'></span>

<h3>Description</h3>

<p>Returns semiparametric EM algorithm output (Bordes et al, 2007,
and Benaglia et al, 2009)  for location mixtures
of univariate data and symmetric component density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spEMsymloc(x, mu0, bw = bw.nrd0(x), h=bw, eps = 1e-8, maxiter = 100, 
           stochastic = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spEMsymloc_+3A_x">x</code></td>
<td>
<p>A vector of length <code class="reqn">n</code> consisting of the data.</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_mu0">mu0</code></td>
<td>
<p>Either a vector specifying the initial
centers for the <a href="stats.html#topic+kmeans">kmeans</a> function, and from which the number of 
component is obtained,  or an integer <code class="reqn">m</code> specifying the 
number of initial centers, which are then choosen randomly in
<a href="stats.html#topic+kmeans">kmeans</a>.</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for density estimation, equal to the standard deviation 
of the kernel density.</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_h">h</code></td>
<td>
<p>Alternative way to specify the bandwidth, to provide backward 
compatibility.</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_eps">eps</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence.  Convergence
is declared before <code>maxiter</code> iterations
whenever the maximum change in any coordinate of the 
<code>lambda</code> (mixing proportion estimates) and <code>mu</code> (means) 
vector  does not exceed <code>eps</code>.</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations allowed, for both 
stochastic and non-stochastic versions; 
for non-stochastic algorithms (<code>stochastic = FALSE</code>), convergence
may be declared before <code>maxiter</code> iterations (see <code>eps</code> above).</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_stochastic">stochastic</code></td>
<td>
<p>Flag, if FALSE (the default), runs the non-stochastic version
of the algorithm, as in Benaglia et al (2009). Set to TRUE to
run a stochastic version which simulates the posteriors at each
iteration (as in Bordes et al, 2007),
and runs for <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code id="spEMsymloc_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>spEMsymloc</code> returns a list of class <code>npEM</code> with the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The raw data (an <code class="reqn">n\times r</code> matrix).</p>
</td></tr>
<tr><td><code>posteriors</code></td>
<td>
<p>An <code class="reqn">n\times m</code> matrix of posterior probabilities for
observations. If <code>stochastic = TRUE</code>, this matrix is computed 
from an average over the <code>maxiter</code> iterations.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>Same as the <code>bw</code> input argument, returned because this
information is needed by any method that produces density estimates from the
output.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>lambdahat</code></td>
<td>
<p>The final estimate for mixing proportions if <code>stochastic = 
  FALSE</code>, the average over the sequence if <code>stochastic = TRUE</code>.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>the sequence of component means over iterations.</p>
</td></tr>
<tr><td><code>muhat</code></td>
<td>
<p>the final estimate of component means if <code>stochastic = 
   FALSE</code>, the average over the sequence if <code>stochastic = TRUE</code>.</p>
</td></tr>
<tr><td><code>symmetric</code></td>
<td>
<p>Flag indicating that the kernel density estimate is
using a symmetry assumption.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R., An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526, 2009.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D.
mixtools: An R package for analyzing finite mixture models.
Journal of Statistical Software, 32(6):1-29, 2009.
</p>
</li>
<li><p> Bordes, L., Chauveau, D., and Vandekerkhove, P. (2007),
An EM algorithm for a semiparametric mixture model, 
Computational Statistics and Data Analysis, 51: 5429-5443.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.npEM">plot.npEM</a></code>, <code><a href="#topic+rnormmix">rnormmix</a></code>,
<code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+spEMsymlocN01">spEMsymlocN01</a></code>, <code><a href="#topic+plotseq.npEM">plotseq.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example from a normal location mixture
set.seed(100)
n &lt;- 200
lambda &lt;- c(1/3,2/3)
mu &lt;- c(0, 4); sigma&lt;-rep(1, 2)
x &lt;- rnormmix(n, lambda, mu, sigma)
out.stoc &lt;- spEMsymloc(x, mu0=c(-1, 2), stochastic=TRUE)
out.nonstoc &lt;- spEMsymloc(x, mu0=c(-1, 2))
</code></pre>

<hr>
<h2 id='spEMsymlocN01'>semiparametric EM-like algorithm for univariate mixture in False Discovery Rate (FDR) estimation</h2><span id='topic+spEMsymlocN01'></span>

<h3>Description</h3>

<p>Return semiparametric EM-like algorithm output for a 2-components 
mixture model with one component set to Normal(0,1), and the other component 
being a unspecified but symmetric density with a location parameter. 
This model is tailored to
FDR estimation on probit transform (<code>qnorm</code>) of p-values arising from multiple testing.</p>


<h3>Usage</h3>

<pre><code class='language-R'>spEMsymlocN01(x, mu0 = 2, bw = bw.nrd0(x), h=bw, eps = 1e-8,
              maxiter = 100, verbose = FALSE, plotf = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spEMsymlocN01_+3A_x">x</code></td>
<td>
<p>A vector of length n consisting of the data, probit transform of pvalues, preferably sorted.</p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_mu0">mu0</code></td>
<td>
<p>Starting value of vector of component means. If not set then the initial value
is randomly generated by a <code>kmeans</code> of the data in two bins. Since component 1 is 
theoretically normal(0,1), <code>mu[1]</code> must be 0 and <code>mu[2]</code> some negative value (see details).</p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_bw">bw</code></td>
<td>
<p>Bandwidth for weighted kernel density estimation.</p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_h">h</code></td>
<td>
<p>Alternative way to specify the bandwidth, to provide backward compatibility.</p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_eps">eps</code></td>
<td>
<p>Tolerance limit for declaring algorithm convergence. 
Convergence is declared before <code>maxiter</code> iterations 
whenever the maximum change in any coordinate of the 
<code>lambda</code> (mixing proportion estimates) and <code>mu</code> (mean of the semiparametric component) 
vector  does not exceed <code>eps</code></p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations allowed; convergence
may be declared before <code>maxiter</code> iterations (see <code>eps</code> above).</p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs.</p>
</td></tr>
<tr><td><code id="spEMsymlocN01_+3A_plotf">plotf</code></td>
<td>
<p>If TRUE, plots successive updates of the nonparametric density estimate
over iterations. Mostly for testing purpose.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm is a specific version of semiparametric EM-like algorithm
similar in spirit to <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, but specialized for FDR estimation on
probit transform (<code>qnorm</code>) of p-values in multiple testing framework.
In this model, component 1 corresponds to the individuals under the null hypothesis,
i.e. theoretically normal(0,1) distributed, whereas component 2 corresponds to individuals in the
alternative hypothesis, with typically very small p-values and consequently
negative values for probit(p) data. This model only assumes
that these individuals come from an unspecified but symmetric density with a location parameter,
as in Bordes and Vandekerkhove (2010) and Chauveau et al. (2014).</p>


<h3>Value</h3>

<p><code>spEMsymlocN01</code> returns a list of class <code>spEMN01</code> with the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>The raw data (an <code class="reqn">n\times r</code> matrix).</p>
</td></tr>
<tr><td><code>posteriors</code></td>
<td>
<p>An <code class="reqn">n\times 2</code> matrix of posterior probabilities for
observations. This can be used in, e.g., <code><a href="#topic+plotFDR">plotFDR</a></code> to plot
False Discovery Rate estimates.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>Same as the <code>bw</code> input argument, returned because this
information is needed by any method that produces density estimates from the
output.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>lambdahat</code></td>
<td>
<p>The final estimate for mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>the sequence of second component mean over iterations.</p>
</td></tr>
<tr><td><code>muhat</code></td>
<td>
<p>the final estimate of second component mean.</p>
</td></tr>
<tr><td><code>symmetric</code></td>
<td>
<p>Flag indicating that the kernel density estimate is
using a symmetry assumption.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L. and Vandekerkhove, P. (2010). 
Semiparametric two-component mixture model with a known component:
an asymptotically normal estimator.
Mathematical Methods of Statistics, 19(1):22-41
</p>
</li>
<li><p> Chauveau, D., Saby, N., Orton, T. G., Lemercier B., 
Walter, C. and Arrouys, D. (2014)
Large-scale simultaneous hypothesis testing in monitoring carbon
content from french soil database: A semi-parametric mixture approach.
Geoderma 219-220 (2014): 117-124.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, <code><a href="#topic+normalmixEM">normalmixEM</a></code>,
<code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+plot.spEMN01">plot.spEMN01</a></code>,
<code><a href="#topic+plotFDR">plotFDR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Probit transform of p-values
## from a Beta-Uniform mixture model
## comparion of parametric and semiparametric EM fit
## Note: in actual situations n=thousands 
set.seed(50)
n=300 # nb of multiple tests
m=2 # 2 mixture components
a=c(1,0.1); b=c(1,1); lambda=c(0.6,0.4) # parameters
z=sample(1:m, n, rep=TRUE, prob = lambda)
p &lt;- rbeta(n, shape1 = a[z], shape2 = b[z]) # p-values
o &lt;- order(p)
cpd &lt;- cbind(z,p)[o,] # sorted complete data, z=1 if H0, 2 if H1
p &lt;- cpd[,2] # sorted p-values

y &lt;- qnorm(p) # probit transform of the pvalues
# gaussian EM fit with component 1 constrained to N(0,1)
s1 &lt;- normalmixEM(y, mu=c(0,-4), 
				mean.constr = c(0,NA), sd.constr = c(1,NA)) 
s2 &lt;- spEMsymlocN01(y, mu0 = c(0,-3)) # spEM with N(0,1) fit
hist(y, freq = FALSE, col = 8, main = "histogram of probit(pvalues)")
plot(s2, add.plot = TRUE, lwd = 2)

# Exemples of plot capabilities
# Note: posteriors must be ordered by p for plot.FDR
# plotFDR(s1$post) # when true complete data not observed
# plotFDR(s1$post, s2$post) # comparing 2 strategies
plotFDR(s1$post, s2$post, lg1 = "normalmixEM", lg2 = "spEMsymlocN01", 
		complete.data = cpd) # with true FDR computed from z
</code></pre>

<hr>
<h2 id='spregmix'>EM-like Algorithm for Semiparametric Mixtures of Regressions</h2><span id='topic+spregmix'></span>

<h3>Description</h3>

<p>Returns parameter estimates for finite mixtures of linear
regressions with unspecified error structure.  Based on 
Hunter and Young (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spregmix(lmformula, bw = NULL, constbw = FALSE,
         bwmult = 0.9, z.hat = NULL, symm = TRUE, betamethod = "LS",
         m = ifelse(is.null(z.hat), 2, ncol(z.hat)),
         epsilon = 1e-04, maxit = 1000, verbose = FALSE, 
         ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spregmix_+3A_lmformula">lmformula</code></td>
<td>
<p>Formula for a linear model, in the same format used by
<code><a href="stats.html#topic+lm">lm</a></code>.  Additional parameters may be passed to <code><a href="stats.html#topic+lm">lm</a></code>
via the <code>...</code> argument.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_bw">bw</code></td>
<td>
<p>Initial bandwidth value.  If NULL, this will be chosen automatically
by the algorithm.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_constbw">constbw</code></td>
<td>
<p>Logical:  If TRUE, the bandwidth is held constant throughout the
algorithm; if FALSE, it adapts at each iteration according to the rules
given in Hunter and Young (2012).</p>
</td></tr>
<tr><td><code id="spregmix_+3A_bwmult">bwmult</code></td>
<td>

<p>Whenever it is updated automatically,
the bandwidth is equal to <code>bwmult</code> divided by 
the fifth root of <code class="reqn">n</code> times the smaller of s and IQR/1.34, 
where s and IQR are estimates of the standard deviation and interquartile 
range of the residuals, as explained in Hunter and Young (2012).
The value of 0.9 gives the rule of Silverman (1986) and
the value of 1.06 gives the rule of Scott (1992).
Larger values lead to greater smoothing, whereas smaller values lead to less 
smoothing.  </p>
</td></tr>
<tr><td><code id="spregmix_+3A_z.hat">z.hat</code></td>
<td>
<p>Initial nxm matrix of posterior probabilities.  If NULL, this
is initialized randomly.  As long as a parametric estimation method like least
squares is used to estimate <code>beta</code> in each M-step, the <code>z.hat</code>
values are the only values necessary to begin the EM iterations.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_symm">symm</code></td>
<td>
<p>Logical:  If TRUE, the error density is assumed symmetric
about zero.  If FALSE, it is not.  WARNING:  If FALSE, the intercept parameter
is not uniquely identifiable if it is included in the linear model.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_betamethod">betamethod</code></td>
<td>
<p>Method of calculating beta coefficients in the
M-step.  Current possible values are &quot;LS&quot; for least-squares; 
&quot;L1&quot; for least absolute deviation; &quot;NP&quot; for fully nonparametric; 
and &quot;transition&quot; for a transition
from least squares to fully nonparametric. If something other than
these four possibilities is used, then &quot;NP&quot; is assumed. For details
of these methods, see Hunter and Young (2012).</p>
</td></tr>
<tr><td><code id="spregmix_+3A_m">m</code></td>
<td>
<p>Number of components in the mixture.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_epsilon">epsilon</code></td>
<td>
<p>Convergence is declared if the largest change in any lambda or
beta coordinate is smaller than <code>epsilon</code>.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations; if convergence is never declared
based on comparison with <code>epsilon</code>, then the algorithm stops after
<code>maxit</code> iterations.</p>
</td></tr>
<tr><td><code id="spregmix_+3A_verbose">verbose</code></td>
<td>
<p>Logical: If TRUE, then various updates are printed during 
each iteration of the algorithm.</p>
</td></tr> 
<tr><td><code id="spregmix_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to the 
<code><a href="stats.html#topic+model.frame">model.frame</a></code> and <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> functions,
which are used to obtain the response and predictor of the regression.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>regmixEM</code> returns a list of class <code>npEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's if <code>addintercept</code> = TRUE).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The mixing proportions for every iteration in the form of a 
matrix with m columns and (#iterations) rows</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxm matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>np.stdev</code></td>
<td>
<p>Nonparametric estimate of the standard deviation, as given
in Hunter and Young (2012)</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>Final value of the bandwidth</p>
</td></tr>
<tr><td><code>density.x</code></td>
<td>
<p>Points at which the error density is estimated</p>
</td></tr>
<tr><td><code>density.y</code></td>
<td>
<p>Values of the error density at the points <code>density.x</code></p>
</td></tr>
<tr><td><code>symmetric</code></td>
<td>
<p>Logical:  Was the error density assumed symmetric?</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>A quantity similar to a log-likelihood, computed just like 
a standard loglikelihood would be, conditional on the component density 
functions being equal to the final density estimates.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hunter, D. R. and Young, D. S. (2012) Semi-parametric Mixtures of Regressions,
Journal of Nonparametric Statistics 24(1): 19-38.
</p>
<p>Scott, D. W. (1992) <em>Multivariate Density Estimation</em>,
John Wiley &amp; Sons Inc., New York.
</p>
<p>Silverman, B. W. (1986). <em>Density Estimation for Statistics and Data 
Analysis</em>, Chapman &amp; Hall, London.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regmixEM">regmixEM</a></code>, <code><a href="#topic+spEMsymloc">spEMsymloc</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tonedata)
## By default, the bandwidth will adapt and the error density is assumed symmetric
set.seed(100)
a=spregmix(tuned~stretchratio, bw=.2, data=tonedata, verb=TRUE)

## Look at the sp mixreg solution:
plot(tonedata)
abline(a=a$beta[1,1],b=a$beta[2,1], col=2)
abline(a=a$beta[1,2],b=a$beta[2,2], col=3)

## Look at the nonparametric KD-based estimate of the error density, 
## constrained to be zero-symmetric:
plot(xx&lt;-a$density.x, yy&lt;-a$density.y, type="l")
## Compare to a normal density with mean 0 and NP-estimated stdev:
z &lt;- seq(min(xx), max(xx), len=200)
lines(z, dnorm(z, sd=sqrt((a$np.stdev)^2+a$bandwidth^2)), col=2, lty=2)
# Add bandwidth^2 to variance estimate to get estimated var of KDE

## Now add the sp mixreg estimate without assuming symmetric errors:
b=spregmix(tuned~stretchratio, bw=.2, , symm=FALSE, data=tonedata, verb=TRUE)
lines(b$density.x, b$density.y, col=3)
</code></pre>

<hr>
<h2 id='spRMM_SEM'>Stochastic EM algorithm for semiparametric scaled mixture of censored data</h2><span id='topic+spRMM_SEM'></span>

<h3>Description</h3>

<p>Stochastic EM algorithm for semiparametric scaled mixture for randomly right censored data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  spRMM_SEM(t, d = NULL, lambda = NULL, scaling = NULL, 
          centers = 2, kernelft = triang_wkde, 
          bw = rep(bw.nrd0(t),length(t)), averaged = TRUE,
          epsilon = 1e-08, maxit = 100, batchsize = 1, verb = FALSE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spRMM_SEM_+3A_t">t</code></td>
<td>
<p>A vector of <code class="reqn">n</code> real positive lifetime (possibly censored) durations.
If <code>d</code> is not <code>NULL</code> then a vector of random censoring times
<code>c</code> occurred,  
so that <code class="reqn">x= min(x,c)</code> and <code class="reqn">d = I(x &lt;= c)</code>.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_d">d</code></td>
<td>
<p>The vector of censoring indication, where 1 means observed lifetime data, 
and 0 means censored lifetime data.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.
If <code>NULL</code>, then <code>lambda</code> is set to <code>rep(1/k,k)</code>.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_scaling">scaling</code></td>
<td>
<p>Initial value of scaling between components, 
set to 1 if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_centers">centers</code></td>
<td>
<p>initial centers for initial call to kmeans for initialization.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_kernelft">kernelft</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_bw">bw</code></td>
<td>
<p>Bandwidth in the kernel hazard estimates.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_averaged">averaged</code></td>
<td>
<p>averaged.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_epsilon">epsilon</code></td>
<td>
<p>Tolerance limit.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_maxit">maxit</code></td>
<td>
<p>The number of iterations allowed.</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_batchsize">batchsize</code></td>
<td>
<p>The batchsize (see reference below).</p>
</td></tr>
<tr><td><code id="spRMM_SEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>spRMM_SEM</code> returns a list of class <code>"spRMM"</code> with the following items:
</p>
<table>
<tr><td><code>t</code></td>
<td>
<p>The input data.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The input censoring indicator.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The estimates for the mixing proportions.</p>
</td></tr>
<tr><td><code>scaling</code></td>
<td>
<p>The estimates for the components scaling.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An <code class="reqn">n\times k</code> matrix of posterior probabilities for
observation, after convergence of the algorithm.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The (pseudo) log-likelihood value at convergence of the algorithm.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>The sequence of log-likelihood values over iterations.</p>
</td></tr>
<tr><td><code>all.lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>all.scaling</code></td>
<td>
<p>The sequence of scaling parameter over iterations.</p>
</td></tr>
<tr><td><code>meanpost</code></td>
<td>
<p>Posterior probabilities averaged over iterations.</p>
</td></tr>
<tr><td><code>survival</code></td>
<td>
<p>Kaplan-Meier last iteration estimate (a <code>stepfun</code> object).</p>
</td></tr>
<tr><td><code>hazard</code></td>
<td>
<p>Hazard rate last iteration estimate evaluated at <code>final.t</code>.</p>
</td></tr>
<tr><td><code>final.t</code></td>
<td>
<p>Last iteration unscaled sample (see reference).</p>
</td></tr>
<tr><td><code>s.hat</code></td>
<td>
<p>Kaplan-Meier average estimate.</p>
</td></tr>
<tr><td><code>t.hat</code></td>
<td>
<p>Ordered unscaled sample, for testing purpose.</p>
</td></tr>
<tr><td><code>avg.od</code></td>
<td>
<p>For testing purpose only.</p>
</td></tr>
<tr><td><code>hazard.hat</code></td>
<td>
<p>Hazard rate average estimate on <code>t.hat</code>.</p>
</td></tr>
<tr><td><code>batch.t</code></td>
<td>
<p>Batch sample (not ordered), see reference.</p>
</td></tr>
<tr><td><code>batch.d</code></td>
<td>
<p>Associated event indicators just <code>rep(d,batchsize)</code>, for testing purpose.</p>
</td></tr>
<tr><td><code>sumNaNs</code></td>
<td>
<p>Internal control of numerical stability.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions: 
<code><a href="#topic+plotspRMM">plotspRMM</a></code>,
<code><a href="#topic+summary.spRMM">summary.spRMM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n=500 # sample size
m=2 # nb components
lambda=c(0.4, 0.6) # parameters
meanlog=3; sdlog=0.5; scale=0.1
set.seed(12)
# simulate a scaled mixture of lognormals
x &lt;- rlnormscalemix(n, lambda, meanlog, sdlog, scale)
cs=runif(n,20,max(x)+400) # Censoring (uniform) and incomplete data
t &lt;- apply(cbind(x,cs),1,min)
d &lt;- 1*(x &lt;= cs)
tauxc &lt;- 100*round( 1-mean(d),3)
cat(tauxc, "percents of data censored.\n")

c0 &lt;- c(25, 180) # data-driven initial centers (visible modes)
sc0 &lt;- 25/180    # and scaling
s &lt;- spRMM_SEM(t, d, scaling = sc0, centers = c0, bw = 15, maxit = 100)

plotspRMM(s) # default
summary(s)   # S3 method for class "spRMM"

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.mixEM'>Summarizing EM mixture model fits</h2><span id='topic+summary.mixEM'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+summary">summary</a></code> method for class <code>mixEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mixEM'
summary(object, digits=6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mixEM_+3A_object">object</code></td>
<td>
<p>an object of class <code>mixEM</code> such as a result of a call
to <code><a href="#topic+normalmixEM">normalmixEM</a></code></p>
</td></tr>
<tr><td><code id="summary.mixEM_+3A_digits">digits</code></td>
<td>
<p>Significant digits for printing values</p>
</td></tr>
<tr><td><code id="summary.mixEM_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>print</code> method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+summary.mixEM">summary.mixEM</a></code> prints parameter estimates for
each component of a fitted mixture model.  
The estimates printed vary with the type of model.
</p>


<h3>Value</h3>

<p>The function <code><a href="#topic+summary.mixEM">summary.mixEM</a></code> prints the final loglikelihood
value at the solution as well as a matrix of values for each component
that could include:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The estimated mixing weights</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The estimated mean parameters</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The estimated standard deviations</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>The estimated multinomial parameters</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The estimated regression parameters</p>
</td></tr>
</table>


<h3>See Also</h3>

 
<p><code><a href="#topic+normalmixEM">normalmixEM</a></code>,
<code><a href="#topic+logisregmixEM">logisregmixEM</a></code>,
<code><a href="#topic+multmixEM">multmixEM</a></code>,
<code><a href="#topic+mvnormalmixEM">mvnormalmixEM</a></code>,
<code><a href="#topic+poisregmixEM">poisregmixEM</a></code>,
<code><a href="#topic+regmixEM">regmixEM</a></code>,
<code><a href="#topic+regmixEM.lambda">regmixEM.lambda</a></code>,
<code><a href="#topic+regmixEM.loc">regmixEM.loc</a></code>,
<code><a href="#topic+regmixEM.mixed">regmixEM.mixed</a></code>,
<code><a href="#topic+regmixEM.chgpt">regmixEM.chgpt</a></code>,
<code><a href="#topic+repnormmixEM">repnormmixEM</a></code>,
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(faithful)
attach(faithful)
set.seed(100)
out &lt;- normalmixEM(waiting, mu=c(50,80), sigma=c(5,5), lambda=c(.5,.5))
summary(out)
</code></pre>

<hr>
<h2 id='summary.mvnpEM'>Summarizing Fits for Nonparametric Mixture Models 
with Conditionally Independent Multivariate Component Densities</h2><span id='topic+summary.mvnpEM'></span><span id='topic+print.summary.mvnpEM'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+summary">summary</a></code> method for class <code>mvnpEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mvnpEM'
summary(object, ...)
## S3 method for class 'summary.mvnpEM'
print(x, digits=3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mvnpEM_+3A_object">object</code>, <code id="summary.mvnpEM_+3A_x">x</code></td>
<td>
<p>an object of class <code>mvnpEM</code> such as a result of a call
to <code><a href="#topic+mvnpEM">mvnpEM</a></code></p>
</td></tr>
<tr><td><code id="summary.mvnpEM_+3A_digits">digits</code></td>
<td>
<p>Significant digits for printing values</p>
</td></tr>
<tr><td><code id="summary.mvnpEM_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+summary.mvnpEM">summary.mvnpEM</a></code> prints means and variances of each block for
each component.  These quantities might not be part of the model, but they
are estimated nonparametrically based on the posterior probabilities and the
data.
</p>


<h3>Value</h3>

<p>The function <code><a href="#topic+summary.mvnpEM">summary.mvnpEM</a></code> returns a list of type <code>summary.mvnpEM</code>
with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>The number of observations</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>The number of mixture components</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>The number of blocks</p>
</td></tr>
<tr><td><code>blockid</code></td>
<td>
<p>The block ID (from 1 through B) for each of the coordinates
of the multivariate observations.  The <code>blockid</code> component is of length
<code class="reqn">r</code>, the dimension of each observation.</p>
</td></tr>
<tr><td><code>means</code></td>
<td>
<p>A <code class="reqn">B\times m</code> matrix giving the estimated mean of each
block in each component.</p>
</td></tr>
<tr><td><code>variances</code></td>
<td>
<p>Same as <code>means</code> but giving the estimated variances instead.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
<em>Journal of Computational and Graphical Statistics</em>, <b>18(2)</b>, 505&ndash;526.
</p>
<p>Chauveau, D., and Hoang, V. T. L. (2015),
Nonparametric mixture models with conditionally independent multivariate component densities, 
Preprint under revision.
<a href="https://hal.archives-ouvertes.fr/hal-01094837">https://hal.archives-ouvertes.fr/hal-01094837</a>
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+mvnpEM">mvnpEM</a></code>,
<code><a href="#topic+plot.mvnpEM">plot.mvnpEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example as in Chauveau and Hoang (2015) with 6 coordinates
## Not run: 
m=2; r=6; blockid &lt;-c(1,1,2,2,3,3) # 3 bivariate blocks 
# generate some data x ...
a &lt;- mvnpEM(x, mu0=2, blockid, samebw=F) # adaptive bandwidth
plot(a) # this S3 method produces 6 plots of univariate marginals
summary(a)
## End(Not run)
</code></pre>

<hr>
<h2 id='summary.npEM'>Summarizing non- and semi-parametric multivariate mixture model fits</h2><span id='topic+summary.npEM'></span><span id='topic+print.summary.npEM'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+summary">summary</a></code> method for class <code>npEM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'npEM'
summary(object, ...)
## S3 method for class 'summary.npEM'
print(x, digits=3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.npEM_+3A_object">object</code>, <code id="summary.npEM_+3A_x">x</code></td>
<td>
<p>an object of class <code>npEM</code> such as a result of a call
to <code><a href="#topic+npEM">npEM</a></code></p>
</td></tr>
<tr><td><code id="summary.npEM_+3A_digits">digits</code></td>
<td>
<p>Significant digits for printing values</p>
</td></tr>
<tr><td><code id="summary.npEM_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+summary.npEM">summary.npEM</a></code> prints means and variances of each block for
each component.  These quantities might not be part of the model, but they
are estimated nonparametrically based on the posterior probabilities and the
data.
</p>


<h3>Value</h3>

<p>The function <code><a href="#topic+summary.npEM">summary.npEM</a></code> returns a list of type <code>summary.npEM</code>
with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>The number of observations</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>The number of mixture components</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>The number of blocks</p>
</td></tr>
<tr><td><code>blockid</code></td>
<td>
<p>The block ID (from 1 through B) for each of the coordinates
of the multivariate observations.  The <code>blockid</code> component is of length
<code class="reqn">r</code>, the dimension of each observation.</p>
</td></tr>
<tr><td><code>means</code></td>
<td>
<p>A <code class="reqn">B\times m</code> matrix giving the estimated mean of each
block in each component.</p>
</td></tr>
<tr><td><code>variances</code></td>
<td>
<p>Same as <code>means</code> but giving the estimated variances instead.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
<em>Journal of Computational and Graphical Statistics</em>, <b>18(2)</b>, 505&ndash;526.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+npEM">npEM</a></code>,
<code><a href="#topic+plot.npEM">plot.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Waterdata)
set.seed(100)
## Not run: 
a &lt;- npEM(Waterdata[,3:10], 3, bw=4) # Assume indep but not iid
summary(a) 

b &lt;- npEM(Waterdata[,3:10], 3, bw=4, blockid=rep(1,8)) # Now assume iid
summary(b)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.spRMM'>Summarizing fits from Stochastic EM algorithm for semiparametric scaled mixture of censored data</h2><span id='topic+summary.spRMM'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+summary">summary</a></code> method for class <code>spRMM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spRMM'
summary(object, digits = 6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.spRMM_+3A_object">object</code></td>
<td>
<p>an object of class <code>spRMM</code> such as a result of a call
to <code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code></p>
</td></tr>
<tr><td><code id="summary.spRMM_+3A_digits">digits</code></td>
<td>
<p>Significant digits for printing values</p>
</td></tr>
<tr><td><code id="summary.spRMM_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to <code>print</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+summary.spRMM">summary.spRMM</a></code> prints scalar parameter estimates for
a fitted mixture model: each component weight and the scaling factor, see reference below.
The functional (nonparametric) estimates of survival and hazard rate funcions can be obtained 
using <code><a href="#topic+plotspRMM">plotspRMM</a></code>.
</p>


<h3>Value</h3>

<p>The function <code><a href="#topic+summary.spRMM">summary.spRMM</a></code> prints the final loglikelihood
value at the solution as well as The estimated mixing weights and the scaling parameter.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Function for plotting functional (nonparametric) estimates:
<code><a href="#topic+plotspRMM">plotspRMM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+weibullRMM_SEM">weibullRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See example(spRMM_SEM)
</code></pre>

<hr>
<h2 id='tauequivnormalmixEM'>Special EM Algorithm for three-component tau equivalence model</h2><span id='topic+tauequivnormalmixEM'></span>

<h3>Description</h3>

<p>Return ECM algorithm output for a specific case of a three-component tau equivalence model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tauequivnormalmixEM (x, lambda = NULL, mu = NULL, sigma = NULL, k = 3, 
          mean.constr = NULL, sd.constr = NULL, gparam = NULL,
          epsilon = 1e-08, maxit = 10000, maxrestarts=20, 
          verb = FALSE, fast=FALSE, ECM = TRUE,
          arbmean = TRUE, arbvar = TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tauequivnormalmixEM_+3A_x">x</code></td>
<td>
<p>A vector of length n consisting of the data,
passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions, 
passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>.  Automatically 
repeated as necessary 
to produce a vector of length <code>k</code>, then normalized to sum to 1.
If <code>NULL</code>, then <code>lambda</code> is random from a uniform Dirichlet
distribution (i.e., its entries are uniform random and then it is 
normalized to sum to 1).</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_mu">mu</code></td>
<td>
<p>Starting value of vector of component means for algorithm,
passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>. 
If non-NULL and a vector,
<code>k</code> is set to <code>length(mu)</code>.  If NULL, then the initial value
is randomly generated from a normal distribution with center(s) determined
by binning the data.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_sigma">sigma</code></td>
<td>
<p>Starting value of vector of component standard deviations 
for algorithm, passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>.  
Obsolete for linear constraint on the inverse variances,
use <code>gparam</code> instead to specify a starting value.
Note: This needs more precision</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_k">k</code></td>
<td>
<p>Number of components, passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>.  
Initial value ignored unless <code>mu</code> and <code>sigma</code> are both NULL.
Also, initial value is ignored if <code>mean.constr</code> is NULL, since in that
case we presume <code>k=3</code>.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_mean.constr">mean.constr</code></td>
<td>
<p>If non-NULL, this parameter is
passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code> and both 
<code>mean.lincstr</code> and <code>var.lincstr</code> are passed as NULL to
<code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>.  If NULL, then 
it is assumed that <code>k=3</code> and the means must take the form
<code class="reqn">\alpha</code>, <code class="reqn">\alpha-\delta</code>, and <code class="reqn">\alpha+\delta</code> for unknown parameters
<code class="reqn">\alpha</code> and <code class="reqn">\delta</code>.  Furthermore, the reciprocal variances are
assumed to be <code class="reqn">\gamma_1+\gamma_2</code>, <code class="reqn">\gamma_1</code>, and <code class="reqn">\gamma_1</code>
for unknown positive parameters <code class="reqn">\gamma_1</code> and <code class="reqn">\gamma_2</code>.
These constraints are passed to the
<code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code> function using the <code>mean.lincstr</code> and
<code>var.lincstr</code> arguments
as shown in the examples for the <code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code> help file.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_sd.constr">sd.constr</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_gparam">gparam</code></td>
<td>
<p>This argument is passed directly to <code><a href="#topic+normalmixMMlc">normalmixMMlc</a>.</code>
</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.  Convergence is declared when the change in 
the observed data log-likelihood increases by less than epsilon.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_maxrestarts">maxrestarts</code></td>
<td>
<p>The maximum number of restarts allowed in case of a problem
with the particular starting values chosen due to one of the variance
estimates getting too small
(each restart uses randomly chosen
starting values).  It is well-known that when each component of a normal
mixture may have its own mean and variance, the likelihood has no maximizer;
in such cases, we hope to find a &quot;nice&quot; local maximum with this algorithm
instead, but occasionally the algorithm finds a &quot;not nice&quot; solution and
one of the variances goes to zero, driving the likelihood to infinity.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each 
iteration of the algorithm.</p>
</td></tr> 
<tr><td><code id="tauequivnormalmixEM_+3A_fast">fast</code></td>
<td>
<p>If TRUE and k==2 and arbmean==TRUE, then use 
<code><a href="#topic+normalmixEM2comp">normalmixEM2comp</a></code>, which is a much faster version of the EM 
algorithm for this case.
This version is less protected against certain kinds of underflow
that can cause numerical problems and it does not permit any restarts.  If
k&gt;2, <code>fast</code> is ignored.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_ecm">ECM</code></td>
<td>
<p>logical:  Should this algorithm be an ECM algorithm in the sense
of Meng and Rubin (1993)?  If FALSE, the algorithm is a true EM algorithm;
if TRUE, then every half-iteration alternately updates the means conditional
on the variances or the variances conditional on the means, with an extra
E-step in between these updates.  For <code>tauequivnormalmixEM</code>, it must
be TRUE.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_arbmean">arbmean</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="tauequivnormalmixEM_+3A_arbvar">arbvar</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>tauequivnormalmixEM</code> function is merely a wrapper for the
<code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code> function.
# This is the standard EM algorithm for normal mixtures that maximizes
# the conditional expected complete-data
# log-likelihood at each M-step of the algorithm.
#  If desired, the
#  EM algorithm may be replaced by an ECM algorithm (see <code>ECM</code> argument)
#  that alternates between maximizing with respect to the <code>mu</code>
#  and <code>lambda</code> while holding <code>sigma</code> fixed, and maximizing with
#  respect to <code>sigma</code> and <code>lambda</code> while holding <code>mu</code>
#  fixed.  In the case where <code>arbmean</code> is <code>FALSE</code>
#  and <code>arbvar</code> is <code>TRUE</code>, there is no closed-form EM algorithm,
#  so the ECM option is forced in this case.
</p>


<h3>Value</h3>

<p><code>normalmixEM</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The raw data.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The final mean parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviation(s)</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>Scale factor for the component standard deviations, if applicable.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nxk matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.  This vector
includes both the initial and the final values; thus, the number of iterations 
is one less than its length.</p>
</td></tr>
<tr><td><code>restarts</code></td>
<td>
<p>The number of times the algorithm restarted due to unacceptable choice of initial values.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>References</h3>


<ul>
<li><p> Thomas, H., Lohaus, A., and Domsch, H. (2011) Stable Unstable Reliability
Theory, <em>British Journal of Mathematical and Statistical Psychology</em>
65(2): 201-221.
</p>
</li>
<li><p> Meng, X.-L. and Rubin, D. B. (1993) Maximum Likelihood Estimation
Via the ECM Algorithm:  A General Framework, <em>Biometrika</em> 80(2):
267-278.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+normalmixMMlc">normalmixMMlc</a></code>, <code><a href="#topic+normalmixEM">normalmixEM</a></code>, <code><a href="#topic+mvnormalmixEM">mvnormalmixEM</a></code>, <code><a href="#topic+normalmixEM2comp">normalmixEM2comp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Analyzing synthetic data as in the tau equivalent model  
## From Thomas et al (2011), see also Chauveau and Hunter (2013)
## a 3-component mixture of normals with linear constraints.
lbd &lt;- c(0.6,0.3,0.1); m &lt;- length(lbd)
sigma &lt;- sig0 &lt;- sqrt(c(1,9,9))
# means constaints mu = M beta
M &lt;- matrix(c(1,1,1,0,1,-1), 3, 2)
beta &lt;- c(1,5) # unknown constained mean
mu0 &lt;- mu &lt;- as.vector(M %*% beta)
# linear constraint on the inverse variances pi = A.g
A &lt;- matrix(c(1,1,1,0,1,0), m, 2, byrow=TRUE)
iv0 &lt;- 1/(sig0^2)
g0 &lt;- c(iv0[2],iv0[1] - iv0[2]) # gamma^0 init 

# simulation and EM fits
set.seed(40); n=100; x &lt;- rnormmix(n,lbd,mu,sigma)
s &lt;- normalmixEM(x,mu=mu0,sigma=sig0,maxit=2000) # plain EM
# EM with var and mean linear constraints
sc &lt;- normalmixMMlc(x, lambda=lbd, mu=mu0, sigma=sig0,
					mean.lincstr=M, var.lincstr=A, gparam=g0)
# Using tauequivnormalmixEM function to call normalmixMMlc					
tau &lt;- tauequivnormalmixEM (x, lambda=lbd, mu=mu0, gparam=g0)
# plot and compare both estimates
dnormmixt &lt;- function(t, lam, mu, sig){
	m &lt;- length(lam); f &lt;- 0
	for (j in 1:m) f &lt;- f + lam[j]*dnorm(t,mean=mu[j],sd=sig[j])
	f}
t &lt;- seq(min(x)-2, max(x)+2, len=200)
hist(x, freq=FALSE, col="lightgrey", 
		ylim=c(0,0.3), ylab="density",main="")
lines(t, dnormmixt(t, lbd, mu, sigma), col="darkgrey", lwd=2) # true
lines(t, dnormmixt(t, s$lambda, s$mu, s$sigma), lty=2) 
lines(t, dnormmixt(t, sc$lambda, sc$mu, sc$sigma), col=1, lty=3)
lines(t, dnormmixt(t, tau$lambda, tau$mu, tau$sigma), col=2, lty=4)
legend("topleft", c("true","plain EM","constr EM", "Tau Equiv"), 
	col=c("darkgrey",1,1,2), lty=c(1,2,3,4), lwd=c(2,1,1,1))
</code></pre>

<hr>
<h2 id='test.equality'>Performs Chi-Square Tests for Scale and Location Mixtures</h2><span id='topic+test.equality'></span>

<h3>Description</h3>

<p>Performs a likelihood ratio test of a location (or scale) normal or regression mixture versus the more
general model.  For a normal mixture, the alternative hypothesis is that each
component has its own mean and variance, whereas the null is that all means
(in the case of a scale mixture) or all variances (in the case of a location
mixture) are equal.
This test is asymptotically chi-square with degrees of freedom equal to k-1,
where k is
the number of components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.equality(y, x = NULL, arbmean = TRUE, arbvar = FALSE, 
              mu = NULL, sigma = NULL, beta = NULL, 
              lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.equality_+3A_y">y</code></td>
<td>
<p>The responses for <code>regmixEM</code> or the data for <code>normalmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_x">x</code></td>
<td>
<p>The predictors for <code>regmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_arbmean">arbmean</code></td>
<td>
<p>If FALSE, then a scale mixture analysis is performed for <code>normalmixEM</code> or <code>regmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_arbvar">arbvar</code></td>
<td>
<p>If FALSE, then a location mixture analysis is performed for <code>normalmixEM</code> or <code>regmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_mu">mu</code></td>
<td>
<p>An optional vector for starting values (under the null hypothesis) for <code>mu</code> in <code>normalmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_sigma">sigma</code></td>
<td>
<p>An optional vector for starting values (under the null hypothesis) for <code>sigma</code> in <code>normalmixEM</code> or <code>regmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_beta">beta</code></td>
<td>
<p>An optional matrix for starting values (under the null hypothesis) for <code>beta</code> in <code>regmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_lambda">lambda</code></td>
<td>
<p>An otional vector for starting values (under the null hypothesis) for <code>lambda</code> in <code>normalmixEM</code> or <code>regmixEM</code>.</p>
</td></tr>
<tr><td><code id="test.equality_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the various EM algorithms for the mixture of interest.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>test.equality</code> returns a list with the following items:
</p>
<table>
<tr><td><code>chi.sq</code></td>
<td>
<p>The chi-squared test statistic.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The degrees of freedom for the chi-squared test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p-value corresponding to this likelihood ratio test.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+test.equality.mixed">test.equality.mixed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Should a location mixture be used for the Old Faithful data?

data(faithful)
attach(faithful)
set.seed(100)
test.equality(y = waiting, arbmean = FALSE, arbvar = TRUE)

</code></pre>

<hr>
<h2 id='test.equality.mixed'>Performs Chi-Square Test for Mixed Effects Mixtures</h2><span id='topic+test.equality.mixed'></span>

<h3>Description</h3>

<p>Performs a likelihood ratio test of either common variance terms between the response trajectories in a mixture
of random (or mixed) effects regressions or for common variance-covariance matrices for the random effects mixture distribution.</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.equality.mixed(y, x, w=NULL, arb.R = TRUE, 
                    arb.sigma = FALSE, lambda = NULL, 
                    mu = NULL, sigma = NULL, R = NULL, 
                    alpha = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.equality.mixed_+3A_y">y</code></td>
<td>
<p>The responses for <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_x">x</code></td>
<td>
<p>The predictors for the random effects in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_w">w</code></td>
<td>
<p>The predictors for the (optional) fixed effects in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_arb.r">arb.R</code></td>
<td>
<p>If FALSE, then a test for different variance-covariance matrices for the random effects mixture is performed.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_arb.sigma">arb.sigma</code></td>
<td>
<p>If FALSE, then a test for different variance terms between the response trajectories is performed.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_lambda">lambda</code></td>
<td>
<p>A vector of mixing proportions (under the null hypothesis) with same purpose as outlined in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_mu">mu</code></td>
<td>
<p>A matrix of the means (under the null hypothesis) with same purpose as outlined in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations (under the null hypothesis) with same purpose as outlined in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_r">R</code></td>
<td>
<p>A list of covariance matrices  (under the null hypothesis) with same purpose as outlined in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_alpha">alpha</code></td>
<td>
<p>An optional vector of fixed effects regression coefficients  (under the null hypothesis) with same purpose as outlined
in <code>regmixEM.mixed</code>.</p>
</td></tr>
<tr><td><code id="test.equality.mixed_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>regmixEM.mixed</code>.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p><code>test.equality.mixed</code> returns a list with the following items:
</p>
<table>
<tr><td><code>chi.sq</code></td>
<td>
<p>The chi-squared test statistic.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The degrees of freedom for the chi-squared test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p-value corresponding to this likelihood ratio test.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+test.equality">test.equality</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Test of equal variances in the simulated data set.

data(RanEffdata)
set.seed(100)
x&lt;-lapply(1:length(RanEffdata), function(i) 
          matrix(RanEffdata[[i]][, 2:3], ncol = 2))
x&lt;-x[1:15]
y&lt;-lapply(1:length(RanEffdata), function(i) 
          matrix(RanEffdata[[i]][, 1], ncol = 1))
y&lt;-y[1:15]

out&lt;-test.equality.mixed(y, x, arb.R = TRUE, arb.sigma = FALSE,
                         epsilon = 1e-1,  verb = TRUE,
                         maxit = 50,
                         addintercept.random = FALSE)
out
</code></pre>

<hr>
<h2 id='tonedata'>Tone perception data</h2><span id='topic+tonedata'></span>

<h3>Description</h3>

<p>The tone perception data stem
from an experiment of Cohen (1980) and have been analyzed in de Veaux
(1989) and Viele and Tong (2002).  The dataset and this documentation file
were copied from the fpc package by Christian Hennig.
A pure fundamental tone was played to a
trained musician. Electronically generated overtones were added, determined 
by a stretching ratio of <code>stretchratio</code>. <code>stretchratio=2.0</code>
corresponds to the harmonic pattern
usually heard in traditional definite pitched instruments. The musician was
asked to tune an adjustable tone to the octave above the fundamental tone.
<code>tuned</code> gives the ratio of the adjusted tone to the fundamental,
i.e. <code>tuned=2.0</code> would be the correct tuning for all
<code>stretchratio</code>-values.
The data analyzed here belong to 150 trials 
with the same musician. In the original study, there were four further
musicians. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tonedata)</code></pre>


<h3>Format</h3>

<p>A data frame with 2 variables, <code>stretchratio</code> and
<code>tuned</code>, and 150 cases.</p>


<h3>Author(s)</h3>

<p>Christian Hennig</p>


<h3>Source</h3>

<p>Original source: Cohen, E. A. (1980), <em>Inharmonic tone
perception</em>. Unpublished Ph.D. dissertation, Stanford University
</p>
<p>R source:  Hennig, Christian (2010), fpc: Flexible procedures 
for clustering, R package version 2.0-2.  
<a href="https://cran.r-project.org/package=fpc">https://cran.r-project.org/package=fpc</a>
</p>


<h3>References</h3>

<p>de Veaux, R. D. (1989), Mixtures of Linear Regressions,
<em>Computational Statistics and Data Analysis</em> 8, 227-245.
</p>
<p>Viele, K. and Tong, B. (2002), Modeling with Mixtures
of Linear Regressions, <em>Statistics and Computing</em> 12, 315-330.
</p>

<hr>
<h2 id='try.flare'>Mixtures of Regressions with Flare MM Algorithm</h2><span id='topic+try.flare'></span>

<h3>Description</h3>

<p>The function which <code>flaremixEM</code> actually calls.  This only allows
one barrier constant to be inputted at a time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>try.flare(y, x, lambda = NULL, beta = NULL, sigma = NULL, 
          alpha = NULL, nu = 1, epsilon = 1e-04, 
          maxit = 10000, verb = FALSE, restart = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="try.flare_+3A_y">y</code></td>
<td>
<p>An n-vector of response values.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_x">x</code></td>
<td>
<p>An n-vector of predictor values.  An intercept term will be added by default.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.  Entries should sum to 1.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_beta">beta</code></td>
<td>
<p>Initial value of <code>beta</code> parameters.  Should be a 2x2 matrix where the columns
corresond to the component.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_sigma">sigma</code></td>
<td>
<p>A vector of standard deviations.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_alpha">alpha</code></td>
<td>
<p>A scalar for the exponential component's rate.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_nu">nu</code></td>
<td>
<p>A scalar specifying the barrier constant to use.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_epsilon">epsilon</code></td>
<td>
<p>The convergence criterion.</p>
</td></tr>
<tr><td><code id="try.flare_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations.</p>
</td></tr> 
<tr><td><code id="try.flare_+3A_verb">verb</code></td>
<td>
<p>If TRUE, then various updates are printed during each iteration of the algorithm.</p>
</td></tr> 
<tr><td><code id="try.flare_+3A_restart">restart</code></td>
<td>
<p>The number of times to restart the algorithm in case convergence is not attained.
The default is 50.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This usually is not called by the user.  The user will likely want <code>flaremixEM</code>, which also
has an example to demonstrate this algorithm.
</p>


<h3>Value</h3>

<p><code>try.flare</code> returns a list of class <code>mixEM</code> with items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The set of predictors (which includes a column of 1's).</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The response values.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An nx2 matrix of posterior probabilities for
observations.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The final mixing proportions.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The final regression coefficients.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The final standard deviations.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The final exponential rate.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The final log-likelihood.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>A vector of each iteration's log-likelihood.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+flaremixEM">flaremixEM</a></code>
</p>

<hr>
<h2 id='Waterdata'>Water-Level Task Data Set</h2><span id='topic+Waterdata'></span><span id='topic+WaterdataFull'></span>

<h3>Description</h3>

<p>This data set arises from the water-level task proposed by the Swiss 
psychologist Jean Piaget to assess children's understanding of the physical 
world.  This involves presenting a child with a rectangular vessel with a cap,
affixed to a wall, that can be tilted (like the minute hand of a clock) to point
in any direction.  A separate disk with a water line indicated on it, which
can similarly be spun so that the water line may assume any desired angle with
the horizontal, is positioned so that by spinning this disk, the child subject 
may make the hypothetical surface of water inside the vessel assume any desired
orientation.  For each of eight different orientations of the vessel, corresponding
to the clock angles at 1:00, 2:00, 4:00, 5:00, 7:00, 8:00, 10:00, and 11:00,
the child subject is asked to position the water level as it would appear in reality
if water were in the vessel.  The measurement is the acute angle with 
the horizontal, in degrees,
assumed by the water line after it is positioned by the child.  A sign is attached
to the measurement to indicate whether the line slopes up 
(positive) or down (negative) from left to right.  Thus, each 
child has 8 repeated measurements, one for each vessel angle, and the range of
possible values are from -90 to 90.
</p>
<p>The setup of the experiment, along with a photograph of the testing apparatus,
is given by Thomas and Jamison (1975).  A more detailed analysis using a 
subset of 405 of the original 579 subjects is given
by Thomas and Lohaus (1993); further analyses using the functions in
<code>mixtools</code> are given by Benaglia et al (2008) and Levine et al (2011), 
among others.
</p>
<p>There are two versions of the dataset included in <code>mixtools</code>.  The full 
dataset, called <code>WaterdataFull</code>, has 579 individuals.  The dataset
called <code>Waterdata</code> is a subset of 405 individuals, comprising all children
aged 11 years or more and omitting any individuals with any observations equal
to 100, which in this context indicates a missing value (since all of the degree
measurements should be in the range from -90 to +90, 100 is not a possible value).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Waterdata)
</code></pre>


<h3>Format</h3>

<p>These data frames consist of 405 or 579 rows, one row for each child. 
There are ten columns:
The age (in years) and sex (where 1=male and 0=female) are given for each 
individual along with the 
degree of deviation from the horizontal
for 8 specified clock-hour orientations 
(11, 4, 2, 7, 10, 5, 1, and 8 o'clock, in order).
</p>


<h3>Source</h3>

<p>Benaglia, T., Chauveau, D., and Hunter, D.R. (2009), 
An EM-Like Algorithm for Semi- and Non-Parametric Estimation in 
Multivariate Mixtures, 
<em>Journal of Computational and Graphical Statistics</em>, 
18: 505-526.
</p>
<p>Levine, M., Hunter, D.R., and Chauveau, D. (2011), 
Maximum Smoothed Likelihood for Multivariate Mixtures, 
<em>Biometrika</em>, 
98(2): 403-416.
</p>
<p>Thomas, H. and Jamison, W. (1975),
On the Acquisition of Understanding that Still Water is Horizontal,
<em>Merrill-Palmer Quarterly of Behavior and Development</em>,
21(1): 31-44.
</p>
<p>Thomas, H. and Lohaus, A.  (1993),
<em>Modeling Growth and Individual Differences in Spatial Tasks</em>,
University of Chicago Press, Chicago, available on JSTOR.  
</p>

<hr>
<h2 id='weibullRMM_SEM'>St-EM algorithm for Reliability Mixture Models (RMM) of Weibull with right Censoring</h2><span id='topic+weibullRMM_SEM'></span>

<h3>Description</h3>

<p>Parametric Stochastic EM (St-EM) algorithm for univariate finite mixture of Weibull 
distributions with randomly right censored data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weibullRMM_SEM(x, d = NULL, lambda = NULL, shape = NULL, scale = NULL,
        k = 2, maxit = 200, maxit.survreg = 200, epsilon = 1e-03,
        averaged = TRUE, verb = FALSE) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weibullRMM_SEM_+3A_x">x</code></td>
<td>
<p>A vector of <code class="reqn">n</code> real positive lifetime (possibly censored) durations.
If <code>d</code> is not <code>NULL</code> then a vector of random censoring times
<code>c</code> occured,  
so that <code class="reqn">x= min(x,c)</code> and <code class="reqn">d = I(x &lt;= c)</code>.</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_d">d</code></td>
<td>
<p>The vector of censoring indication, where 1 means observed lifetime data, 
and 0 means censored lifetime data.</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_lambda">lambda</code></td>
<td>
<p>Initial value of mixing proportions.
If <code>NULL</code>, then <code>lambda</code> is set to <code>rep(1/k,k)</code>.</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_shape">shape</code></td>
<td>
<p>Initial value of Weibull component shapes, 
all set to 1 if  <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_scale">scale</code></td>
<td>
<p>Initial value of Weibull component scales, 
all set to 1 if  <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_k">k</code></td>
<td>
<p>Number of components of the mixture.</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_maxit">maxit</code></td>
<td>
<p>The number of iterations allowed, since for St-EM algorithms convergence
is not based on stabilization, exactly <code>maxit</code> iterations are performed
(see  Bordes L. and Chauveau D. (2016) reference below).</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_maxit.survreg">maxit.survreg</code></td>
<td>
<p>The number of iterations allowed in the computations of the
MLE for censored weibull data from the  <code>survival</code> package
(see  Bordes L. and Chauveau D. (2016) reference below).</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_epsilon">epsilon</code></td>
<td>
<p>Tolerance parameter used in the numerical computations of the
MLE for censored weibull data by <code>survreg</code> from the  <code>survival</code> package
(see  Bordes L. and Chauveau D. (2016) reference below).</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_averaged">averaged</code></td>
<td>
<p>The way of updating parameters at each iteration: if <code>TRUE</code>, current values of the parameters 
are obtained by averaging the sequence
(see Bordes L. and Chauveau D. (2016) reference below).</p>
</td></tr>
<tr><td><code id="weibullRMM_SEM_+3A_verb">verb</code></td>
<td>
<p>If TRUE, print updates for every iteration of the algorithm as
it runs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This St-EM algorithm calls functions from  the <code>survival</code> package to compute 
parametric MLE for censored weibull data.</p>


<h3>Value</h3>

<p><code>weibullRMM_SEM</code> returns a list of class &quot;mixEM&quot; with the following items:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The input data.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>The input censoring indicator.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The estimates for the  mixing proportions.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>The estimates for the Weibull component scales.</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>The estimates for the Weibull component shapes.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The log-likelihood value at convergence of the algorithm.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>An <code class="reqn">n\times k</code> matrix of posterior probabilities for
observation, after convergence of the algorithm.</p>
</td></tr>
<tr><td><code>all.loglik</code></td>
<td>
<p>The sequence of log-likelihoods over iterations.</p>
</td></tr>
<tr><td><code>all.lambda</code></td>
<td>
<p>The sequence of mixing proportions over iterations.</p>
</td></tr>
<tr><td><code>all.scale</code></td>
<td>
<p>The sequence of component scales over iterations.</p>
</td></tr>
<tr><td><code>all.shape</code></td>
<td>
<p>The sequence of component shapes over iterations.</p>
</td></tr>
<tr><td><code>ft</code></td>
<td>
<p>A character vector giving the name of the function called.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau</p>


<h3>References</h3>


<ul>
<li><p> Bordes, L., and Chauveau, D. (2016),
Stochastic EM algorithms for parametric and semiparametric mixture models 
for right-censored lifetime data, 
Computational Statistics, Volume 31, Issue 4, pages 1513-1538.
<a href="https://link.springer.com/article/10.1007/s00180-016-0661-7">https://link.springer.com/article/10.1007/s00180-016-0661-7</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Related functions:
<code><a href="#topic+plotweibullRMM">plotweibullRMM</a></code>,   <code><a href="#topic+summary.mixEM">summary.mixEM</a></code>.
</p>
<p>Other models and algorithms for censored lifetime data 
(name convention is model_algorithm):
<code><a href="#topic+expRMM_EM">expRMM_EM</a></code>,
<code><a href="#topic+spRMM_SEM">spRMM_SEM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 500 # sample size
m = 2 # nb components
lambda=c(0.4, 0.6)
shape &lt;- c(0.5,5); scale &lt;- c(1,20) # model parameters
set.seed(321)
x &lt;- rweibullmix(n, lambda, shape, scale) # iid ~ weibull mixture
cs=runif(n,0,max(x)+10) # iid censoring times
t &lt;- apply(cbind(x,cs),1,min) # censored observations
d &lt;- 1*(x &lt;= cs)              # censoring indicator

## set arbitrary or "reasonable" (e.g., data-driven) initial values
l0 &lt;- rep(1/m,m); sh0 &lt;- c(1, 2); sc0 &lt;- c(2,10)
# Stochastic EM algorithm 
a &lt;- weibullRMM_SEM(t, d, lambda = l0, shape = sh0, scale = sc0, maxit = 200)

summary(a) # Parameters estimates etc
plotweibullRMM(a) # plot of St-EM sequences
plot(a, which=2) # or equivalently, S3 method for "mixEM" object
</code></pre>

<hr>
<h2 id='wkde'>Weighted Univariate (Normal) Kernel Density Estimate</h2><span id='topic+wkde'></span><span id='topic+wkde.symm'></span>

<h3>Description</h3>

<p>Evaluates a weighted kernel density estimate, using a Gaussian kernel, 
at a specified vector of points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wkde(x, u=x, w=rep(1, length(x)), bw=bw.nrd0(as.vector(x)), sym=FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wkde_+3A_x">x</code></td>
<td>
<p>Data</p>
</td></tr>
<tr><td><code id="wkde_+3A_u">u</code></td>
<td>
<p>Points at which density is to be estimated</p>
</td></tr>
<tr><td><code id="wkde_+3A_w">w</code></td>
<td>
<p>Weights (same length as <code>x</code>)</p>
</td></tr>
<tr><td><code id="wkde_+3A_bw">bw</code></td>
<td>
<p>Bandwidth</p>
</td></tr>
<tr><td><code id="wkde_+3A_sym">sym</code></td>
<td>
<p>Logical:  Symmetrize about zero?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the same length as <code>u</code>
</p>


<h3>References</h3>


<ul>
<li><p> Benaglia, T., Chauveau, D., and Hunter, D. R. (2009), An EM-like algorithm
for semi- and non-parametric estimation in multivariate mixtures, 
Journal of Computational and Graphical Statistics, 18, 505-526.
</p>
</li>
<li><p> Benaglia, T., Chauveau, D., Hunter, D. R., and Young, D. (2009),
mixtools: An R package for analyzing finite mixture models.
Journal of Statistical Software, 32(6):1-29.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+npEM">npEM</a></code>, <code><a href="#topic+ise.npEM">ise.npEM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Mixture with mv gaussian model
set.seed(100)
m &lt;- 2 # no. of components
r &lt;- 3 # no. of repeated measures (coordinates)
lambda &lt;- c(0.4, 0.6)
mu &lt;- matrix(c(0, 0, 0, 4, 4, 6), m, r, byrow=TRUE) # means 
sigma &lt;- matrix(rep(1, 6), m, r, byrow=TRUE) # stdevs
centers &lt;- matrix(c(0, 0, 0, 4, 4, 4), 2, 3, byrow=TRUE) # initial centers for est

blockid = c(1,1,2) # block structure of coordinates
n = 100
x &lt;- rmvnormmix(n, lambda, mu, sigma) # simulated data
a &lt;- npEM(x, centers, blockid, eps=1e-8, verb=FALSE)

par(mfrow=c(2,2))
u &lt;- seq(min(x), max(x), len=200)
for(j in 1:2) { 
  for(b in 1:2) {
    xx &lt;- as.vector(x[,a$blockid==b])
    wts &lt;- rep(a$post[,j], length.out=length(xx))
    bw &lt;- a$bandwidth
    title &lt;- paste("j =", j, "and b =", b)
    plot(u, wkde(xx, u, wts, bw), type="l", main=title)
  }
}

</code></pre>

<hr>
<h2 id='wquantile'>Weighted quantiles</h2><span id='topic+wIQR'></span><span id='topic+wquantile'></span>

<h3>Description</h3>

<p>Functions to compute weighted quantiles and the weighted interquartile range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wquantile(wt = rep(1,length(x)), x, probs, already.sorted = FALSE, 
          already.normalized = FALSE)
wIQR(wt = rep(1,length(x)), x, already.sorted = FALSE, 
     already.normalized = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wquantile_+3A_wt">wt</code></td>
<td>
<p> Vector of weights </p>
</td></tr>
<tr><td><code id="wquantile_+3A_x">x</code></td>
<td>
<p> Vector of data, same length as <code>wt</code> </p>
</td></tr>
<tr><td><code id="wquantile_+3A_probs">probs</code></td>
<td>
<p> Numeric vector of probabilities with values in [0,1].</p>
</td></tr>
<tr><td><code id="wquantile_+3A_already.sorted">already.sorted</code></td>
<td>
<p> If FALSE, sort <code>wt</code> and <code>x</code> in increasing
order of <code>x</code>.  If TRUE, it is assumed that <code>wt</code> and <code>x</code>
are already sorted.</p>
</td></tr>
<tr><td><code id="wquantile_+3A_already.normalized">already.normalized</code></td>
<td>
<p> If FALSE, normalize <code>wt</code> by diving each
entry by the sum of all entries.  If TRUE, it is assumed that <code>sum(wt)==1</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>wquantile</code> uses the <code><a href="base.html#topic+findInterval">findInterval</a></code> function.  <code>wIQR</code>
calls the <code>wquantile</code> function.
</p>


<h3>Value</h3>

<p>Returns the sample quantiles or interquartile range of a discrete distribution with
support points <code>x</code> and corresponding probability masses <code>wt</code>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+npEM">npEM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>IQR(1:10)
wIQR(x=1:10) # Note:  Different algorithm than IQR function
wIQR(1:10,1:10) # Weighted quartiles are now 4 and 8
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
