<!DOCTYPE html><html><head><title>Help for package CMF</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CMF}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CMF-package'><p>Collective Matrix Factorization (CMF)</p></a></li>
<li><a href='#CMF'><p>Collective Matrix Factorization</p></a></li>
<li><a href='#getCMFopts'><p>Default options for CMF</p></a></li>
<li><a href='#matrix_to_triplets'><p>Conversion from matrix to coordinate/triplet format</p></a></li>
<li><a href='#p_check_sparsity'><p>Internal function for checking whether the input is in the right format</p></a></li>
<li><a href='#p_gradUsparseWrapper'><p>Internal function for computing the gradients</p></a></li>
<li><a href='#predictCMF'><p>Predict with CMF</p></a></li>
<li><a href='#triplets_to_matrix'><p>Conversion from triplet/coordinate format to matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Collective Matrix Factorization</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-09</td>
</tr>
<tr>
<td>Description:</td>
<td>Collective matrix factorization (CMF) finds joint low-rank
	representations for a collection of matrices with shared row or column
	entities. This code learns a variational Bayesian approximation for CMF,
	supporting multiple likelihood potentials and missing data, while
	identifying both factors shared by multiple matrices and factors private
	for each matrix. For further details on the method see
	Klami et al. (2014) &lt;<a href="https://doi.org/10.48550/arXiv.1312.5921">doi:10.48550/arXiv.1312.5921</a>&gt;.
	The package can also be used to learn Bayesian canonical correlation
	analysis (CCA) and group factor analysis (GFA) models, both of which are
	special cases of CMF. This is likely to be useful for people looking for
	CCA and GFA solutions supporting missing data and non-Gaussian likelihoods.
	See Klami et al. (2013) <a href="https://research.cs.aalto.fi/pml/online-papers/klami13a.pdf">https://research.cs.aalto.fi/pml/online-papers/klami13a.pdf</a>
	and	Virtanen et al. (2012) <a href="http://proceedings.mlr.press/v22/virtanen12.html">http://proceedings.mlr.press/v22/virtanen12.html</a>
	for details on Bayesian CCA and GFA, respectively.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>cpp11</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cyianor/CMF/issues">https://github.com/cyianor/CMF/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-09 19:11:09 UTC; hefelix</td>
</tr>
<tr>
<td>Author:</td>
<td>Arto Klami [aut],
  Lauri Väre [aut],
  Felix Held [ctb, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Felix Held &lt;felix.held@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-09 21:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='CMF-package'>Collective Matrix Factorization (CMF)</h2><span id='topic+CMF-package'></span>

<h3>Description</h3>

<p>Collective matrix factorization (CMF) finds joint low-rank
representations for a collection of matrices with shared
row or column entities. This package learns a variational
Bayesian approximation for CMF, supporting multiple
likelihood potentials and missing data, while identifying
both factors shared by multiple matrices and factors
private for each matrix.
</p>


<h3>Details</h3>

<p>This package implements a variational Bayesian approximation for
CMF, following the presentation in &quot;Group-sparse embeddings in
collective matrix factorization&quot; (see references below).
</p>
<p>The main functionality is provided by the function
<code><a href="#topic+CMF">CMF()</a></code> that is used for learning the model, and by the
function <code><a href="#topic+predictCMF">predictCMF()</a></code> that estimates missing entries
based on the learned model. These functions take as input
lists of matrices in a specific sparse format that stores
only the observed entries but that explicitly stores
zeroes (unlike most sparse matrix representations).
For converting between regular matrices and this sparse
format see <code><a href="#topic+matrix_to_triplets">matrix_to_triplets()</a></code> and <code><a href="#topic+triplets_to_matrix">triplets_to_matrix()</a></code>.
</p>
<p>The package can also be used to learn Bayesian canonical
correlation analysis (CCA) and group factor analysis (GFA)
models, both of which are special cases of CMF. This is likely to be
useful for people looking for CCA and GFA solutions supporting
missing data and non-Gaussian likelihoods.
</p>


<h3>Author(s)</h3>

<p>Arto Klami <a href="mailto:arto.klami@cs.helsinki.fi">arto.klami@cs.helsinki.fi</a> and Lauri Väre
</p>
<p>Maintainer: Felix Held <a href="mailto:felix.held@gmail.se">felix.held@gmail.se</a>
</p>


<h3>References</h3>

<p>Arto Klami, Guillaume Bouchard, and Abhishek Tripathi.
Group-sparse embeddings in collective matrix factorization.
arXiv:1312.5921, 2013.
</p>
<p>Arto Klami, Seppo Virtanen, and Samuel Kaski.
Bayesian canonical correlation analysis. Journal of Machine
Learning Research, 14(1):965&ndash;1003, 2013.
</p>
<p>Seppo Virtanen, Arto Klami, Suleiman A. Khan, and Samuel Kaski.
Bayesian group factor analysis. In Proceedings of the 15th
International Conference on Artificial Intelligence and Statistics,
volume 22 of JMLR:W&amp;CP, pages 1269-1277, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require("CMF")

# Create data for a circular setup with three matrices and three
# object sets of varying sizes.
X &lt;- list()
D &lt;- c(10, 20, 30)
inds &lt;- matrix(0, nrow = 3, ncol = 2)

# Matrix 1 is between sets 1 and 2 and has continuous data
inds[1, ] &lt;- c(1, 2)
X[[1]] &lt;- matrix(
  rnorm(D[inds[1, 1]] * D[inds[1, 2]], 0, 1),
  nrow = D[inds[1, 1]]
)

# Matrix 2 is between sets 1 and 3 and has binary data
inds[2, ] &lt;- c(1, 3)
X[[2]] &lt;- matrix(
  round(runif(D[inds[2, 1]] * D[inds[2, 2]], 0, 1)),
  nrow = D[inds[2, 1]]
)

# Matrix 3 is between sets 2 and 3 and has count data
inds[3, ] &lt;- c(2, 3)
X[[3]] &lt;- matrix(
  round(runif(D[inds[3, 1]] * D[inds[3, 2]], 0, 6)),
  nrow = D[inds[3, 1]]
)

# Convert the data into the right format
triplets &lt;- lapply(X, matrix_to_triplets)

# Missing entries correspond to missing rows in the triple representation
# so they can be removed from training data by simply taking a subset
# of the rows.
train &lt;- list()
test &lt;- list()
keep_for_training &lt;- c(100, 200, 300)
for (m in 1:3) {
  subset &lt;- sample(nrow(triplets[[m]]), keep_for_training[m])
  train[[m]] &lt;- triplets[[m]][subset, ]
  test[[m]] &lt;- triplets[[m]][-subset, ]
}

# Learn the model with the correct likelihoods
K &lt;- 4
likelihood &lt;- c("gaussian", "bernoulli", "poisson")
opts &lt;- getCMFopts()
opts$iter.max &lt;- 500 # Less iterations for faster computation
model &lt;- CMF(train, inds, K, likelihood, D, test = test, opts = opts)

# Check the predictions
# Note that the data created here has no low-rank structure,
# so we should not expect good accuracy.
print(test[[1]][1:3, ])
print(model$out[[1]][1:3, ])

# predictions for the test set using the previously learned model
out &lt;- predictCMF(test, model)
print(out$out[[1]][1:3, ])
print(out$error[[1]])
# ...this should be the same as the output provided by CMF()
print(model$out[[1]][1:3, ])

</code></pre>

<hr>
<h2 id='CMF'>Collective Matrix Factorization</h2><span id='topic+CMF'></span>

<h3>Description</h3>

<p>Learns the CMF model for a given collection of M matrices.
The code learns the parameters of a variational approximation for CMF,
and also computes predictions for indices specified in <code>test</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CMF(X, inds, K, likelihood, D, test = NULL, opts = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CMF_+3A_x">X</code></td>
<td>
<p>List of input matrices.</p>
</td></tr>
<tr><td><code id="CMF_+3A_inds">inds</code></td>
<td>
<p>A <code>length(X)</code> times 2 matrix that links dimensions of the
matrices in <code>X</code> to object sets. <code>inds[m, 1]</code> tells which
object set corresponds to the rows in matrix <code>X[[m]]</code>,
and <code>inds[m, 2]</code> tells the same for the columns.</p>
</td></tr>
<tr><td><code id="CMF_+3A_k">K</code></td>
<td>
<p>The number of factors.</p>
</td></tr>
<tr><td><code id="CMF_+3A_likelihood">likelihood</code></td>
<td>
<p>A list of likelihood choices, one for each matrix in X.
Each entry should be a string with possible values of:
&quot;gaussian&quot;, &quot;bernoulli&quot; or &quot;poisson&quot;.</p>
</td></tr>
<tr><td><code id="CMF_+3A_d">D</code></td>
<td>
<p>A vector containing sizes of each object set.</p>
</td></tr>
<tr><td><code id="CMF_+3A_test">test</code></td>
<td>
<p>A list of test matrices. If not NULL, the code will compute
predictions for these elements of the matrices. This duplicates
the functionality of <code><a href="#topic+predictCMF">predictCMF()</a></code>.</p>
</td></tr>
<tr><td><code id="CMF_+3A_opts">opts</code></td>
<td>
<p>A list of options as given by <code><a href="#topic+getCMFopts">getCMFopts()</a></code>.
If set to <code>NULL</code>, the default values will be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variational approximation is fully factorized over all of the model
parameters, including individual elements of the projection matrices.
The parameters for the projection matrices are updated jointly by
Newton-Raphson method, whereas the rest use closed-form updates.
</p>
<p>Note that the input data needs to be given in a specific sparse format.
See <code><a href="#topic+matrix_to_triplets">matrix_to_triplets()</a></code> for details.
</p>
<p>The behavior of the algorithm can be modified via the <code>opts</code> parameter.
See <code><a href="#topic+getCMFopts">getCMFopts()</a></code> for details. Of particular interest are the elements
<code>useBias</code> and <code>method</code>.
</p>
<p>For full description of the output parameters, see the referred publication.
The notation in the code follows roughly the notation used in the paper.
</p>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>U</code></td>
<td>
<p>A list of the mean parameters for the rank-K projection matrices,
one for each object set.</p>
</td></tr>
<tr><td><code>covU</code></td>
<td>
<p>A list of the variance parameters for the rank-K projection
matrices, one for each object set.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>A vector of the precision parameter means.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>A vector of the ARD parameter means.</p>
</td></tr>
<tr><td><code>cost</code></td>
<td>
<p>A vector of variational lower bound values.</p>
</td></tr>
<tr><td><code>inds</code></td>
<td>
<p>The input parameter <code>inds</code> stored for further use.</p>
</td></tr>
<tr><td><code>errors</code></td>
<td>
<p>A vector containing root-mean-square errors for each
iteration, computed over the elements indicated by the
<code>test</code> parameter.</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>A list (of lists) storing the parameters of the row and
column bias terms.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The sizes of the object sets as given in the parameters.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>The number of components as given in the parameters.</p>
</td></tr>
<tr><td><code>Uall</code></td>
<td>
<p>Matrices of U joined into one sum(D) by K matrix, for
easier plotting of the results.</p>
</td></tr>
<tr><td><code>items</code></td>
<td>
<p>A list containing the running number for each item among
all object sets. This corresponds to rows of the <code>Uall</code>
matrix. Each part of the list contains a vector that has the
numbers for each particular object set.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>If test matrices were provided, returns the reconstructed data
sets. Otherwise returns <code>NULL</code>.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>The number of input matrices.</p>
</td></tr>
<tr><td><code>likelihood</code></td>
<td>
<p>The likelihoods of the matrices.</p>
</td></tr>
<tr><td><code>opts</code></td>
<td>
<p>The options used for running the code.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arto Klami and Lauri Väre
</p>


<h3>References</h3>

<p>Arto Klami, Guillaume Bouchard, and Abhishek Tripathi.
Group-sparse embeddings in collective matrix factorization.
arXiv:1312.5921, 2014.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See CMF-package for an example.

</code></pre>

<hr>
<h2 id='getCMFopts'>Default options for CMF</h2><span id='topic+getCMFopts'></span>

<h3>Description</h3>

<p>A helper function that creates a list of options to be passed to <code>CMF</code>.
To run the code with other option values, first run this function and
then directly modify the entries before passing the list to <code>CMF</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCMFopts()
</code></pre>


<h3>Details</h3>

<p>Most of the parameters are for controlling the optimization, but some will
alter the model itself. In particular, <code>useBias</code> is used for turning
the bias terms on and off, and <code>method</code> will change the prior for <code>U</code>.
</p>
<p>The default choice for <code>method</code> is <code>"gCMF"</code>, providing the
group-wise sparse CMF that identifies both shared and private factors
(see Klami et al. (2013) for details). The value <code>"CMF"</code> turns off
the group-wise sparsity, providing a CMF solution that attempts to learn
only factors shared by all matrices. Finally, <code>method="GFA"</code> implements
the group factor analysis (GFA) method, by fixing the variance of
<code>U[[1]]</code> to one and forcing <code>useBias=FALSE</code>. Then <code>U[[1]]</code> can be
interpreted as latent variables with unit variance and zero mean,
as assumed by GFA and CCA (special case of GFA with <code>M = 2</code>). Note that as a
multi-view learning method <code>"GFA"</code> requires all matrices to share the
same rows, the very first entity set.
</p>


<h3>Value</h3>

<p>Returns a list of:
</p>
<table>
<tr><td><code>init.tau</code></td>
<td>
<p>Initial value for the noise precisions. Only matters for
Gaussian likelihood.</p>
</td></tr>
<tr><td><code>init.alpha</code></td>
<td>
<p>Initial value for the automatic relevance determination
(ARD) prior precisions.</p>
</td></tr>
<tr><td><code>grad.reg</code></td>
<td>
<p>The regularization parameter for the under-relaxed Newton
iterations. 0 = no regularization, larger values provide
increasing regularization. The value must be below 1.</p>
</td></tr>
<tr><td><code>gradIter</code></td>
<td>
<p>How many gradient steps for updating the projections are
performed during each iteration of the whole algorithm.
Default is 1.</p>
</td></tr>
<tr><td><code>grad.max</code></td>
<td>
<p>Maximum absolute change for the elements of the projection
matrices during one gradient step. Small values help to
prevent over-shooting, wheres inf results to no constraints.
Default is <code>inf</code>.</p>
</td></tr>
<tr><td><code>iter.max</code></td>
<td>
<p>Number of iterations for the whole algorithm.</p>
</td></tr>
<tr><td><code>computeCost</code></td>
<td>
<p>Should the cost function values be computed or not.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code>verbose</code></td>
<td>
<p>0 = supress all printing, 1 = print current iteration and
test RMSE every now and then, 2 = in addition to level 1
print also the current gradient norm.</p>
</td></tr>
<tr><td><code>useBias</code></td>
<td>
<p>Set this to <code>FALSE</code> to exclude the row and column bias terms.
The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Default value of &quot;gCMF&quot; computes the CMF with group-sparsity.
The other possible values are &quot;CMF&quot; for turning off the
group-sparsity prior, and &quot;GFA&quot; for implementing group factor
analysis (and canonical correlation analysis when <code>M = 2</code>).</p>
</td></tr>
<tr><td><code>prior.alpha_0</code></td>
<td>
<p>Hyperprior values for the gamma prior for ARD.</p>
</td></tr>
<tr><td><code>prior.alpha_0t</code></td>
<td>
<p>Hyperprior values for the gamma prior for tau.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arto Klami and Lauri Väre
</p>


<h3>References</h3>

<p>Arto Klami, Guillaume Bouchard, and Abhishek Tripathi.
Group-sparse embeddings in collective matrix factorization.
arXiv:1312.5921, 2014.
</p>
<p>Seppo Virtanen, Arto Klami, Suleiman A. Khan, and Samuel Kaski.
Bayesian group factor analysis. In Proceedings of the 15th
International Conference on Artificial Intelligence and Statistics,
volume 22 of JMLR:W&amp;CP, pages 1269-1277, 2012.
</p>


<h3>See Also</h3>

<p>'CMF'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
CMF_options &lt;- getCMFopts()
CMF_options$iter.max &lt;- 500 # Change the number of iterations from default
                            # of 200 to 500.
CMF_options$useBias &lt;- FALSE # Do not take row and column means into
                             # consideration.
# These options will be in effect when CMF_options is passed on to CMF.

</code></pre>

<hr>
<h2 id='matrix_to_triplets'>Conversion from matrix to coordinate/triplet format</h2><span id='topic+matrix_to_triplets'></span>

<h3>Description</h3>

<p>The CMF code requires inputs to be speficied in a specific
sparse format. This function converts regular R matrices
into that format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix_to_triplets(orig)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matrix_to_triplets_+3A_orig">orig</code></td>
<td>
<p>A matrix of class <code>matrix</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The element <code>X[i, j]</code> on the <code>i</code>-th row and <code>j</code>-th column is represented
as a triple <code style="white-space: pre;">&#8288;(i, j, X[i,k])&#8288;</code>. The input for CMF is then a matrix
where each row specifies one element, and hence the representation
is of size <code style="white-space: pre;">&#8288;N x 3&#8288;</code>, where <code>N</code> is the total number of observed entries.
</p>
<p>In the original input matrix the missing entries should be marked
as <code>NA</code>. In the output they will be completely omitted.
</p>
<p>Even though this format reminds the representation often used
for representing sparse matrices, it is important to notice that
observed zeroes are retained in the representation. The
elements missing from this representation are considered unknown,
not zero.
</p>


<h3>Value</h3>

<p>The input matrix in triplet/coordinate format.
</p>


<h3>Author(s)</h3>

<p>Arto Klami and Lauri Väre
</p>


<h3>See Also</h3>

<p><code><a href="#topic+triplets_to_matrix">triplets_to_matrix()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(c(1, 2, NA, NA, 5, 6), nrow = 3)
triplet &lt;- matrix_to_triplets(x)
print(triplet)

</code></pre>

<hr>
<h2 id='p_check_sparsity'>Internal function for checking whether the input is in the right format</h2><span id='topic+p_check_sparsity'></span>

<h3>Description</h3>

<p>Internal function for checking whether the input is in the right format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_check_sparsity(mat, max_row, max_col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_check_sparsity_+3A_mat">mat</code></td>
<td>
<p>An input matrix of class <code>matrix</code></p>
</td></tr>
<tr><td><code id="p_check_sparsity_+3A_max_row">max_row</code></td>
<td>
<p>Maximum row index for <code>mat</code></p>
</td></tr>
<tr><td><code id="p_check_sparsity_+3A_max_col">max_col</code></td>
<td>
<p>Maximum column index for <code>mat</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> if the input is in coordinate/triplet format.
<code>FALSE</code> otherwise.
</p>

<hr>
<h2 id='p_gradUsparseWrapper'>Internal function for computing the gradients</h2><span id='topic+p_gradUsparseWrapper'></span>

<h3>Description</h3>

<p>Internal function for computing the gradients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_gradUsparseWrapper(r, par, stochastic = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_gradUsparseWrapper_+3A_r">r</code></td>
<td>
<p>?</p>
</td></tr>
<tr><td><code id="p_gradUsparseWrapper_+3A_par">par</code></td>
<td>
<p>?</p>
</td></tr>
<tr><td><code id="p_gradUsparseWrapper_+3A_stochastic">stochastic</code></td>
<td>
<p>Whether or not to perform updates on a subsample</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gradient
</p>

<hr>
<h2 id='predictCMF'>Predict with CMF</h2><span id='topic+predictCMF'></span>

<h3>Description</h3>

<p>Code for predicting missing elements with an existing CMF model.
The predictions are made for all of the elements specified in the list of
input matrices <code>X</code>. The function also returns the root mean square error
(RMSE) between the predicted outputs and the values provided in <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictCMF(X, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictCMF_+3A_x">X</code></td>
<td>
<p>A list of sparse matrices specifying the indices for which to
make the predictions.
These matrices must correspond to the structure used for <code>X</code>
when learning the model with <code>CMF</code>.</p>
</td></tr>
<tr><td><code id="predictCMF_+3A_model">model</code></td>
<td>
<p>A list of model parameter values provided by <code>CMF</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>X</code> needs to be provided as a set of triplets instead of as
a regular matrix. See <code><a href="#topic+matrix_to_triplets">matrix_to_triplets()</a></code>.
</p>


<h3>Value</h3>

<p>A list of
</p>
<table>
<tr><td><code>out</code></td>
<td>
<p>A list of matrices corresponding to predictions for each
matrix in <code>X</code>.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>A vector containing the root-mean-square error for each
matrix separately.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arto Klami and Lauri Väre
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See CMF-package for an example.

</code></pre>

<hr>
<h2 id='triplets_to_matrix'>Conversion from triplet/coordinate format to matrix</h2><span id='topic+triplets_to_matrix'></span>

<h3>Description</h3>

<p>This function is the inverse of <code><a href="#topic+matrix_to_triplets">matrix_to_triplets()</a></code>.
It converts a matrix represented as a set of triplets into
an object of the class <code>matrix</code>. The missing entries
(the ones not present in the triplet representation) are
filled in as <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triplets_to_matrix(triplets)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="triplets_to_matrix_+3A_triplets">triplets</code></td>
<td>
<p>A matrix in triplet/coordinate format</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+matrix_to_triplets">matrix_to_triplets()</a></code> for a description of the
representation.
</p>


<h3>Value</h3>

<p>The input matrix as a normal matrix of class <code>matrix</code>
</p>


<h3>Author(s)</h3>

<p>Arto Klami and Lauri Väre
</p>


<h3>See Also</h3>

<p><code><a href="#topic+matrix_to_triplets">matrix_to_triplets()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(c(1, 2, NA, NA, 5, 6), nrow = 3)
triplet &lt;- matrix_to_triplets(x)
print(triplet)
xnew &lt;- triplets_to_matrix(triplet)
print(xnew)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
