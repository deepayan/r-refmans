<!DOCTYPE html><html><head><title>Help for package FFdownload</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FFdownload}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#converter'><p>Converter to read downloaded datasets and automatically put them into one large dataframe with xts</p></a></li>
<li><a href='#converter_tbl'><p>Converter to read downloaded datasets and automatically put them into one large dataframe with xts</p></a></li>
<li><a href='#FFdownload'><p>Downloads Datasets from Kenneth French's Website</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Download Data from Kenneth French's Website</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Downloads all the datasets (you can exclude the daily ones or specify a list of those you are targeting specifically) from Kenneth French's Website at <a href="https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html">https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html</a>, process them and convert them to list of 'xts' (time series).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), utils, stats, rvest, xts, xml2, zoo, plyr</td>
</tr>
<tr>
<td>Imports:</td>
<td>timetk</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/sstoeckl/ffdownload">https://github.com/sstoeckl/ffdownload</a>,
<a href="https://sstoeckl.github.io/ffdownload/">https://sstoeckl.github.io/ffdownload/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/sstoeckl/ffdownload/issues">https://github.com/sstoeckl/ffdownload/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, dplyr, viridis, ggplot2, tidyr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-11 11:52:39 UTC; sstoeckl</td>
</tr>
<tr>
<td>Author:</td>
<td>Sebastian Stoeckl <a href="https://orcid.org/0000-0002-4196-6093"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre] (Package commissioner and maintainer.),
  Annar Massimov [ctb] (Original developer of FFdownload.)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Stoeckl &lt;sebastian.stoeckl@uni.li&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-12 11:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='converter'>Converter to read downloaded datasets and automatically put them into one large dataframe with xts</h2><span id='topic+converter'></span>

<h3>Description</h3>

<p><code>converter</code> read/clean/write
</p>


<h3>Usage</h3>

<pre><code class='language-R'>converter(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="converter_+3A_file">file</code></td>
<td>
<p>downloaded dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of annual/monthly/daily files
</p>

<hr>
<h2 id='converter_tbl'>Converter to read downloaded datasets and automatically put them into one large dataframe with xts</h2><span id='topic+converter_tbl'></span>

<h3>Description</h3>

<p><code>converter</code> read/clean/write
</p>


<h3>Usage</h3>

<pre><code class='language-R'>converter_tbl(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="converter_tbl_+3A_file">file</code></td>
<td>
<p>downloaded dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of annual/monthly/daily files
</p>

<hr>
<h2 id='FFdownload'>Downloads Datasets from Kenneth French's Website</h2><span id='topic+FFdownload'></span>

<h3>Description</h3>

<p><code>FFdownload</code> returns an RData file with all (possibility to exclude the large daily) datasets from Kenneth French's Website.
Should help researchers to work with the datasets and update the regularly. Allows for reproducible research. Be aware that processing
(especially when including daily files) takes quite a long time!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FFdownload(
  output_file = "data.Rdata",
  tempd = NULL,
  exclude_daily = FALSE,
  download = TRUE,
  download_only = FALSE,
  listsave = NULL,
  inputlist = NULL,
  format = "xts"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FFdownload_+3A_output_file">output_file</code></td>
<td>
<p>name of the .RData file to be saved (include path if necessary)</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_tempd">tempd</code></td>
<td>
<p>specify if you want to keep downloaded files somewhere save. Seems to be necessary for
reproducible research as the files on the website do change from time to time</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_exclude_daily">exclude_daily</code></td>
<td>
<p>excludes the daily datasets (are not downloaded) ==&gt; speeds the process up considerably</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_download">download</code></td>
<td>
<p>set to TRUE if you actually want to download again. set to false and specify tempd to keep processing the already downloaded files</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_download_only">download_only</code></td>
<td>
<p>set to FALSE if you want to process all your downloaded files at once</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_listsave">listsave</code></td>
<td>
<p>if not NULL, the list of unzipped files is saved here (good for processing only a limited number of files through inputlist).
Is written before inputlist is processed.</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_inputlist">inputlist</code></td>
<td>
<p>if not NULL, FFdownload tries to match the names from the list with the list of zip-files</p>
</td></tr>
<tr><td><code id="FFdownload_+3A_format">format</code></td>
<td>
<p>(set to xts) specify &quot;xts&quot; or &quot;tbl&quot;/&quot;tibble&quot; for the output format of the nested lists</p>
</td></tr>
</table>


<h3>Value</h3>

<p>RData file
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tempf &lt;- tempfile(fileext = ".RData"); outd &lt;- paste0(tempdir(),"/",format(Sys.time(), "%F_%H-%M"))
temptxt &lt;- tempfile(fileext = ".txt")

# Example 1: Use FFdownload to get a list of all monthly zip-files. Save that list as temptxt.

FFdownload(exclude_daily=TRUE,download=FALSE,download_only=TRUE,listsave=temptxt)
read.delim(temptxt,sep = ",")
# set vector with only files to download (we try a fuzzyjoin, so "Momentum" should be enough to get
# the Momentum Factor)
inputlist &lt;- c("Research_Data_Factors","Momentum_Factor","ST_Reversal_Factor","LT_Reversal_Factor")
# Now process only these files if they can be matched (download only)
FFdownload(exclude_daily=FALSE,tempd=outd,download=TRUE,download_only=FALSE,
inputlist=inputlist,output_file = tempf)
list.files(outd)
# Then process all the downloaded files
FFdownload(output_file = tempf, exclude_daily=TRUE,tempd=outd,download=FALSE,
download_only=FALSE,inputlist=inputlist)
load(tempf); FFdata$`x_F-F_Momentum_Factor`$monthly$Temp2[1:10]

# Example 2: Download all non-daily files and process them

# Commented out to not being tested
# tempf2 &lt;- tempfile(fileext = ".RData");
# outd2&lt;- paste0(tempdir(),"/",format(Sys.time(), "%F_%H-%M"))
# FFdownload(output_file = tempf2,tempd = outd2, exclude_daily = TRUE, download = TRUE,
# download_only=FALSE, listsave=temptxt)
# load(tempf2)
# FFdownload$x_25_Portfolios_5x5$monthly$average_value_weighted_returns

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
