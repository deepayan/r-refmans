<!DOCTYPE html><html lang="en"><head><title>Help for package NUSS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NUSS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#base_dictionary'><p>Base dictionary with unigrams</p></a></li>
<li><a href='#igrepl'><p>Perform inverse regex search (C++)</p></a></li>
<li><a href='#ngrams_dictionary'><p>Create n-grams dictionary</p></a></li>
<li><a href='#ngrams_segmentation'><p>Segmenting sequences with n-grams.</p></a></li>
<li><a href='#nuss'><p>Mixed N-Grams and Unigram Sequence Segmentation (NUSS) function</p></a></li>
<li><a href='#unigram_dictionary'><p>Create unigram dictionary</p></a></li>
<li><a href='#unigram_sequence_segmentation'><p>Segmenting sequences with unigrams</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Mixed N-Grams and Unigram Sequence Segmentation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Segmentation of short text sequences - like hashtags - into the
    separated words sequence, done with the use of dictionary, which may be
    built on custom corpus of texts. Unigram dictionary is used to find most
    probable sequence, and n-grams approach is used to determine possible
    segmentation given the text corpus.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/theogrost/NUSS">https://github.com/theogrost/NUSS</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/theogrost/NUSS/issues">https://github.com/theogrost/NUSS/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, magrittr, Rcpp, stringr, text2vec, textclean, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, Rcpp</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-31 10:43:30 UTC; theog</td>
</tr>
<tr>
<td>Author:</td>
<td>Oskar Kosch <a href="https://orcid.org/0000-0003-2697-1393"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Oskar Kosch &lt;contact@oskarkosch.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-19 08:20:16 UTC</td>
</tr>
</table>
<hr>
<h2 id='base_dictionary'>Base dictionary with unigrams</h2><span id='topic+base_dictionary'></span>

<h3>Description</h3>

<p>Data contains English unigrams, with their replacements, points and ids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(base_dictionary)
</code></pre>


<h3>Format</h3>

<p>A data.frame with four columns: to_search, to_replace, points, id.
</p>


<h3>References</h3>

<p>Created based on Wikipedia unigrams.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(base_dictionary)
</code></pre>

<hr>
<h2 id='igrepl'>Perform inverse regex search (C++)</h2><span id='topic+igrepl'></span>

<h3>Description</h3>

<p>This function takes character vector <code>patterns</code> with regex patterns
(or fixed strings),
and searches for match in the <code>x</code> string. It is inverse in the meaning,
that in <a href="base.html#topic+grepl">grepl</a> single pattern is used against multiple strings;
instead, this function takes multiple patterns to fit on a single string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>igrepl(patterns, x, fixed = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="igrepl_+3A_patterns">patterns</code></td>
<td>
<p>a character vector of regex or fixed patterns.</p>
</td></tr>
<tr><td><code id="igrepl_+3A_x">x</code></td>
<td>
<p>a string to search for the match.</p>
</td></tr>
<tr><td><code id="igrepl_+3A_fixed">fixed</code></td>
<td>
<p>a logical, indicating whether patterns are fixed strings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Logical vector of length as <code>patterns</code> with true if pattern
was found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>igrepl(c("today","b.* fox", "jumps over", "vigorous"),
"The quick brown fox jumps over the lazy dog", FALSE)
igrepl(c("today","brown fox", "jumps over", "vigorous"),
"The quick brown fox jumps over the lazy dog", TRUE)
</code></pre>

<hr>
<h2 id='ngrams_dictionary'>Create n-grams dictionary</h2><span id='topic+ngrams_dictionary'></span>

<h3>Description</h3>

<p><code>ngrams_dictionary</code> returns the data.frame containing dictionary for
<a href="#topic+ngrams_segmentation">ngrams_segmentation</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ngrams_dictionary(
  texts,
  clean = TRUE,
  ngram_min = 1,
  ngram_max = 5,
  points_filter = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ngrams_dictionary_+3A_texts">texts</code></td>
<td>
<p>character vector, these are the texts used to create n-grams
dictionary. Case-sensitive.</p>
</td></tr>
<tr><td><code id="ngrams_dictionary_+3A_clean">clean</code></td>
<td>
<p>logical, indicating if the texts should be cleaned before
creating n-grams dictionary.</p>
</td></tr>
<tr><td><code id="ngrams_dictionary_+3A_ngram_min">ngram_min</code></td>
<td>
<p>numeric, sets the minimum number of words in creating
the dictionary.</p>
</td></tr>
<tr><td><code id="ngrams_dictionary_+3A_ngram_max">ngram_max</code></td>
<td>
<p>numeric, sets the maximum number of words in creating
the dictionary.</p>
</td></tr>
<tr><td><code id="ngrams_dictionary_+3A_points_filter">points_filter</code></td>
<td>
<p>numeric, sets the minimal number of points (occurrences)
of an n-gram to be included in the dictionary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output always will be data.frame with 4 columns: 1) to_search,
2) to_replace, 3) id, 4) points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>texts &lt;- c("this is science",
           "science is #fascinatingthing",
           "this is a scientific approach",
           "science is everywhere",
           "the beauty of science")
ngrams_dictionary(texts)
ngrams_dictionary(texts,
                  clean = FALSE)
ngrams_dictionary(texts,
                  clean = TRUE,
                  ngram_min = 2,
                  ngram_max = 2)

</code></pre>

<hr>
<h2 id='ngrams_segmentation'>Segmenting sequences with n-grams.</h2><span id='topic+ngrams_segmentation'></span>

<h3>Description</h3>

<p><code>ngrams_segmentation</code> segments input sequence into possible segmented
text based on n-grams segmentation approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ngrams_segmentation(
  sequences,
  ngrams_dictionary,
  retrieve = "most-scored",
  simplify = TRUE,
  omit_zero = TRUE,
  score_formula = "points / words.number ^ 2"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ngrams_segmentation_+3A_sequences">sequences</code></td>
<td>
<p>character vector, sequence to be segmented
(e.g., hashtag) or without it.</p>
</td></tr>
<tr><td><code id="ngrams_segmentation_+3A_ngrams_dictionary">ngrams_dictionary</code></td>
<td>
<p>data.frame, containing ids, n-grams to search, words
to use for segmentation, and their points. See details.</p>
</td></tr>
<tr><td><code id="ngrams_segmentation_+3A_retrieve">retrieve</code></td>
<td>
<p>character vector of length 1, with formula
to calculate score.</p>
</td></tr>
<tr><td><code id="ngrams_segmentation_+3A_simplify">simplify</code></td>
<td>
<p>logical, if adjacent numbers should be merged into one,
and underscores removed. See simplification section.</p>
</td></tr>
<tr><td><code id="ngrams_segmentation_+3A_omit_zero">omit_zero</code></td>
<td>
<p>logical, if words with 0 points should be omitted
from word count. See simplification section.</p>
</td></tr>
<tr><td><code id="ngrams_segmentation_+3A_score_formula">score_formula</code></td>
<td>
<p>character vector of length 1, with formula
to calculate score.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output always will be data.frame. If <code>retrieve='all'</code>
is used, then the return will include all possible segmentation
of the given sequence.<br />
If <code>retrieve='first-shortest'</code> is used, the first of the shortest
segmentations (with respect to the order of word's appearance
in the dictionary, 1 row).<br />
If <code>retrieve='most-pointed'</code> is used, segmentation with most total
points is returned (1 row).<br />
If <code>retrieve='most-scored'</code> is used, segmentation with the highest
score calculated as
<br /> <code class="reqn">score = points / words.number ^ 2</code> (or as specified by the user).
<br /> <strong>The output is not in the input order. If needed, use
<a href="base.html#topic+lapply">lapply</a></strong>
</p>


<h3>ngrams_dictionary</h3>

<p>Dictionary has to be data.frame with four named columns: 1) to_search,
2) to_replace, 3) id, 4) points.<br />
'to_search' should be column of type character, containing n-grams to
look for. Word case might be used.<br />
'to_replace' should be column of type character, containing n-grams that
should be used for creating segmentation vector, if 'to_search' matches
text. <br />
'id' should be column of type numeric, containing id of unigram.<br />
'points' should be column of type numeric, containing number of points
for the word - the higher, the better. Unigrams with 0 points might be
removed from the word count with omit_zero argument. ngrams_dictionary
might be created with <a href="#topic+ngrams_dictionary">ngrams_dictionary</a>.
</p>


<h3>Simplification</h3>

<p>Two arguments are possible for simplification:<br />
</p>

<ul>
<li><p> simplify - removes spaces between numbers and removes underscores,<br />
</p>
</li>
<li><p> omit_zero - removes ids of 0-pointed unigrams,
and omits them in the word count.<br />
By default segmented sequence will be simplified,
and numbers and underscores will be removed from word count
for score computing, since they are neutral as they are necessary.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>texts &lt;- c("this is science",
           "science is #fascinatingthing",
           "this is a scientific approach",
           "science is everywhere",
           "the beauty of science")
ndict &lt;- ngrams_dictionary(texts)
ngrams_segmentation("thisisscience", ndict)
ngrams_segmentation("this_is_science", ndict)
ngrams_segmentation("ThisIsScience", ndict)
ngrams_segmentation("thisisscience",
                    ndict,
                    simplify=FALSE,
                    omit_zero=FALSE)

</code></pre>

<hr>
<h2 id='nuss'>Mixed N-Grams and Unigram Sequence Segmentation (NUSS) function</h2><span id='topic+nuss'></span>

<h3>Description</h3>

<p><code>nuss</code> returns the data.frame containing
hashtag, its segmented version, ids of dictionary words,
number of words it have taken to segment the hashtag,
total number of points, and computed score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nuss(sequences, texts)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nuss_+3A_sequences">sequences</code></td>
<td>
<p>character vector, sequence to be segmented,
(e.g., hashtag) or without it. Case-insensitive.</p>
</td></tr>
<tr><td><code id="nuss_+3A_texts">texts</code></td>
<td>
<p>character vector, these are the texts used to create n-grams
and unigram dictionary. Case-insensitive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an arbitrary combination of <a href="#topic+ngrams_dictionary">ngrams_dictionary</a>,
<a href="#topic+unigram_dictionary">unigram_dictionary</a>, <a href="#topic+ngrams_segmentation">ngrams_segmentation</a>,
<a href="#topic+unigram_sequence_segmentation">unigram_sequence_segmentation</a>, created to easily segment short texts
based on text corpus.
</p>


<h3>Value</h3>

<p>The output always will be data.frame with sequences, that were
<br /> <strong>The output is not in the input order. If needed, use
<a href="base.html#topic+lapply">lapply</a></strong>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>texts &lt;- c("this is science",
           "science is #fascinatingthing",
           "this is a scientific approach",
           "science is everywhere",
           "the beauty of science")
nuss(c("thisisscience", "scienceisscience"), texts)

</code></pre>

<hr>
<h2 id='unigram_dictionary'>Create unigram dictionary</h2><span id='topic+unigram_dictionary'></span>

<h3>Description</h3>

<p><code>unigram_dictionary</code> returns the data.frame containing dictionary for
<a href="#topic+unigram_sequence_segmentation">unigram_sequence_segmentation</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unigram_dictionary(texts, points_filter = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unigram_dictionary_+3A_texts">texts</code></td>
<td>
<p>character vector, these are the texts used to create ngrams
dictionary. Case-sensitive.</p>
</td></tr>
<tr><td><code id="unigram_dictionary_+3A_points_filter">points_filter</code></td>
<td>
<p>numeric, sets the minimal number of points (occurrences)
of an unigram to be included in the dictionary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output always will be data.frame with 4 columns: 1) to_search,
2) to_replace, 3) id, 4) points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>texts &lt;- c("this is science",
           "science is #fascinatingthing",
           "this is a scientific approach",
           "science is everywhere",
           "the beauty of science")
unigram_dictionary(texts)

</code></pre>

<hr>
<h2 id='unigram_sequence_segmentation'>Segmenting sequences with unigrams</h2><span id='topic+unigram_sequence_segmentation'></span>

<h3>Description</h3>

<p><code>unigram_sequence_segmentation</code> segments input sequence into possible segmented
text based on unigram sequence segmentation approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unigram_sequence_segmentation(
  sequences,
  unigram_dictionary = NUSS::base_dictionary,
  retrieve = "most-scored",
  simplify = TRUE,
  omit_zero = TRUE,
  score_formula = "points / words.number ^ 2"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unigram_sequence_segmentation_+3A_sequences">sequences</code></td>
<td>
<p>character vector, sequence to be segmented
(e.g., hashtag). Case-sensitive.</p>
</td></tr>
<tr><td><code id="unigram_sequence_segmentation_+3A_unigram_dictionary">unigram_dictionary</code></td>
<td>
<p>data.frame, containing ids, words to search, words to use
for segmentation, and their points. See details.</p>
</td></tr>
<tr><td><code id="unigram_sequence_segmentation_+3A_retrieve">retrieve</code></td>
<td>
<p>character vector of length 1, the type of the result
data.frame to be returned: 'all', 'first-shortest', 'most-pointed' or
'most-scored'. See value section.</p>
</td></tr>
<tr><td><code id="unigram_sequence_segmentation_+3A_simplify">simplify</code></td>
<td>
<p>logical, if adjacent numbers should be merged into one,
and underscores removed. See simplification section.</p>
</td></tr>
<tr><td><code id="unigram_sequence_segmentation_+3A_omit_zero">omit_zero</code></td>
<td>
<p>logical, if words with 0 points should be omitted
from word count. See simplification section.</p>
</td></tr>
<tr><td><code id="unigram_sequence_segmentation_+3A_score_formula">score_formula</code></td>
<td>
<p>character vector of length 1, with formula
to calculate score.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is not intended for long strings segmentation -
70 characters should be considered too long
and may take hours to complete. 15 characters takes about 0.02s,
30 characters about 0.03s.
</p>


<h3>Value</h3>

<p>The output always will be data.frame. If <code>retrieve='all'</code>
is used, then the return will include all possible segmentation
of the given sequence.<br />
If <code>retrieve='first-shortest'</code> is used, the first of the shortest
segmentations (with respect to the order of word's appearance
in the dictionary, 1 row).<br />
If <code>retrieve='most-pointed'</code> is used, segmentation with most total
points is returned (1 row).<br />
If <code>retrieve='most-scored'</code> is used, segmentation with the highest
score calculated as
<br /> <code class="reqn">score = points / words.number ^ 2</code> (or as specified by the user).
<br /> <strong>The output is not in the input order. If needed, use
<a href="base.html#topic+lapply">lapply</a></strong>
</p>


<h3>unigram_dictionary</h3>

<p>Dictionary has to be data.frame with four named columns: 1) to_search,
2) to_replace, 3) id, 4) points.<br />
'to_search' should be column of type character, containing unigram to
look for. Word case might be used.<br />
'to_replace' should be column of type character, containing word that
should be used for creating segmentation vector, if 'to_search' matches
text. <br />
'id' should be column of type numeric, containing id of unigram.<br />
'points' should be column of type numeric, containing number of points
for the word - the higher, the better. Unigrams with 0 points might be
removed from the word count with omit_zero argument.
</p>


<h3>Simplification</h3>

<p>Two arguments are possible for simplification:<br />
</p>

<ul>
<li><p> simplify - removes spaces between numbers and removes underscores,<br />
</p>
</li>
<li><p> omit_zero - removes ids of 0-pointed unigrams,
and omits them in the word count.<br />
By default segmented sequence will be simplified,
and numbers and underscores will be removed from word count
for score computing, since they are neutral as they are necessary.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># With custom dictionary
texts &lt;- c("this is science",
           "science is #fascinatingthing",
           "this is a scientific approach",
           "science is everywhere",
           "the beauty of science")
udict &lt;- unigram_dictionary(texts)
unigram_sequence_segmentation('thisisscience', udict)

# With built-in dictionary (English, only lowercase)
unigram_sequence_segmentation('thisisscience')
unigram_sequence_segmentation('thisisscience2024')
unigram_sequence_segmentation('thisisscience2024', simplify=FALSE, omit_zero=FALSE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
