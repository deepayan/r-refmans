<!DOCTYPE html><html lang="en"><head><title>Help for package FuncNN</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FuncNN}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#FuncNN-package'><p>FuncNN: Functional Neural Networks</p></a></li>
<li><a href='#daily'><p>Classic Canadian weather data set.</p></a></li>
<li><a href='#fnn.cv'><p>Functional Neural Networks with Cross-validation</p></a></li>
<li><a href='#fnn.fit'><p>Fitting Functional Neural Networks</p></a></li>
<li><a href='#fnn.fnc'><p>Output of Estimated Functional Weights</p></a></li>
<li><a href='#fnn.plot'><p>Plotting Functional Response Predictions</p></a></li>
<li><a href='#fnn.predict'><p>Prediction using Functional Neural Networks</p></a></li>
<li><a href='#fnn.tune'><p>Tuning Functional Neural Networks</p></a></li>
<li><a href='#tecator'><p>Classic Tecator data set.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Functional Neural Networks</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions which fit functional neural network models. In
            other words, this package will allow users to build deep learning models 
            that have either functional or scalar responses paired with functional and 
            scalar covariates. We implement the theoretical discussion found 
            in Thind, Multani and Cao (2020) &lt;<a href="https://doi.org/10.48550/arXiv.2006.09590">doi:10.48550/arXiv.2006.09590</a>&gt; through the help of a main fitting and 
            prediction function as well as a number of helper functions to assist with 
            cross-validation, tuning, and the display of estimated functional weights.</td>
</tr>
<tr>
<td>Imports:</td>
<td>keras, tensorflow, fda.usc, fda, ggplot2, ggpubr, caret,
pbapply, reshape2, flux, doParallel, foreach, Matrix</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://arxiv.org/abs/2006.09590">https://arxiv.org/abs/2006.09590</a>, <a href="https://github.com/b-thi/FuncNN">https://github.com/b-thi/FuncNN</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-09-07 23:52:53 UTC; Richard</td>
</tr>
<tr>
<td>Author:</td>
<td>Richard Groenewald [ctb],
  Barinder Thind [aut, cre, cph],
  Jiguo Cao [aut],
  Sidi Wu [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Barinder Thind &lt;barinder.thi@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-09-15 09:40:15 UTC</td>
</tr>
</table>
<hr>
<h2 id='FuncNN-package'>FuncNN: Functional Neural Networks</h2><span id='topic+FuncNN'></span><span id='topic+FuncNN-package'></span>

<h3>Description</h3>

<p>A collection of functions which fit functional neural network models. In
other words, this package will allow users to build deep learning models 
that have either functional or scalar responses paired with functional and 
scalar covariates. We implement the theoretical discussion found 
in Thind, Multani and Cao (2020) &lt;arXiv:2006.09590&gt; through the help of a main fitting and 
prediction function as well as a number of helper functions to assist with 
cross-validation, tuning, and the display of estimated functional weights.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Barinder Thind <a href="mailto:barinder.thi@gmail.com">barinder.thi@gmail.com</a> [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Jiguo Cao
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Richard Groenewald [contributor]
</p>
</li>
<li><p> Sidi Wu [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Thind, B., Multani, K., and Cao J. (2020) “Deep Learning with Functional Inputs”, <a href="https://arxiv.org/abs/2006.09590">https://arxiv.org/abs/2006.09590</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://arxiv.org/abs/2006.09590">https://arxiv.org/abs/2006.09590</a>
</p>
</li>
<li> <p><a href="https://github.com/b-thi/FuncNN">https://github.com/b-thi/FuncNN</a>
</p>
</li></ul>


<hr>
<h2 id='daily'>Classic Canadian weather data set.</h2><span id='topic+daily'></span>

<h3>Description</h3>

<p>Classic Canadian weather data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(daily)
</code></pre>


<h3>Format</h3>

<p>An object containing temperature and precipitation data for 35 Canadian cities.
</p>


<h3>References</h3>

<p>Ramsay, J., Hooker, G. and Graves, S. (2009) &quot;Functional Data Analysis with R and MATLAB&quot;, Springer-Verlag, New York, ISBN: 9780387981857
</p>

<hr>
<h2 id='fnn.cv'>Functional Neural Networks with Cross-validation</h2><span id='topic+fnn.cv'></span>

<h3>Description</h3>

<p>This is a convenience function for the user. The inputs are largely the same as the <code><a href="#topic+fnn.fit">fnn.fit()</a></code> function with the
additional parameter of fold choice. This function only works for scalar responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnn.cv(
  nfolds,
  resp,
  func_cov,
  scalar_cov = NULL,
  basis_choice = c("fourier"),
  num_basis = c(7),
  hidden_layers = 2,
  neurons_per_layer = c(64, 64),
  activations_in_layers = c("sigmoid", "linear"),
  domain_range = list(c(0, 1)),
  epochs = 100,
  loss_choice = "mse",
  metric_choice = list("mean_squared_error"),
  val_split = 0.2,
  learn_rate = 0.001,
  patience_param = 15,
  early_stopping = TRUE,
  print_info = TRUE,
  batch_size = 32,
  decay_rate = 0,
  func_resp_method = 1,
  covariate_scaling = TRUE,
  raw_data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnn.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to be used in the cross-validation process.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_resp">resp</code></td>
<td>
<p>For scalar responses, this is a vector of the observed dependent variable. For functional responses,
this is a matrix where each row contains the basis coefficients defining the functional response (for each observation).</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_func_cov">func_cov</code></td>
<td>
<p>The form of this depends on whether the <code>raw_data</code> argument is true or not. If true, then this is
a list of k matrices. The dimensionality of the matrices should be the same (n x p) where n is the number of
observations and p is the number of longitudinal observations. If <code>raw_data</code> is false, then the input should be a tensor
with dimensionality b x n x k where b is the number of basis functions used to define the functional covariates, n is
the number of observations, and k is the number of functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_scalar_cov">scalar_cov</code></td>
<td>
<p>A matrix contained the multivariate information associated with the data set. This is all of your
non-longitudinal data.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_basis_choice">basis_choice</code></td>
<td>
<p>A vector of size k (the number of functional covariates) with either &quot;fourier&quot; or &quot;bspline&quot; as the inputs.
This is the choice for the basis functions used for the functional weight expansion. If you only specify one, with k &gt; 1,
then the argument will repeat that choice for all k functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_num_basis">num_basis</code></td>
<td>
<p>A vector of size k defining the number of basis functions to be used in the basis expansion. Must be odd
for <code>fourier</code> basis choices. If you only specify one, with k &gt; 1, then the argument will repeat that choice for all
k functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_hidden_layers">hidden_layers</code></td>
<td>
<p>The number of hidden layers to be used in the neural network.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_neurons_per_layer">neurons_per_layer</code></td>
<td>
<p>Vector of size = <code>hidden_layers</code>. The u-th element of the vector corresponds to the number of neurons
in the u-th hidden layer.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_activations_in_layers">activations_in_layers</code></td>
<td>
<p>Vector of size = <code>hidden_layers</code>. The u-th element of the vector corresponds to the
activation choice in the u-th hidden layer.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_domain_range">domain_range</code></td>
<td>
<p>List of size k. Each element of the list is a 2-dimensional vector containing the upper and lower
bounds of the k-th functional weight.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_epochs">epochs</code></td>
<td>
<p>The number of training iterations.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_loss_choice">loss_choice</code></td>
<td>
<p>This parameter defines the loss function used in the learning process.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_metric_choice">metric_choice</code></td>
<td>
<p>This parameter defines the printed out error metric.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_val_split">val_split</code></td>
<td>
<p>A parameter that decides the percentage split of the inputted data set.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_learn_rate">learn_rate</code></td>
<td>
<p>Hyperparameter that defines how quickly you move in the direction of the gradient.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_patience_param">patience_param</code></td>
<td>
<p>A keras parameter that decides how many additional <code>epochs</code> are eclipsed with minimal change in
error before the learning process is stopped. This is only active if <code>early_stopping = TRUE</code></p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_early_stopping">early_stopping</code></td>
<td>
<p>If TRUE, then learning process will be halted early if error improvement isn't seen.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_print_info">print_info</code></td>
<td>
<p>If TRUE, function will output information about the model as it is trained.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of the batch for stochastic gradient descent.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_decay_rate">decay_rate</code></td>
<td>
<p>A modification to the learning rate that decreases the learning rate as more and more learning
iterations are completed.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_func_resp_method">func_resp_method</code></td>
<td>
<p>Set to 1 by default. In the future, this will be set to 2 for an alternative functional response
approach.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_covariate_scaling">covariate_scaling</code></td>
<td>
<p>If TRUE, then data will be internally scaled before model development.</p>
</td></tr>
<tr><td><code id="fnn.cv_+3A_raw_data">raw_data</code></td>
<td>
<p>If TRUE, then user does not need to create functional observations beforehand. The function will
internally take care of that pre-processing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>No additional details for now.
</p>


<h3>Value</h3>

<p>The following are returned.
</p>
<p><code>predicted_folds</code> &ndash; The predicted scalar values in each fold.
</p>
<p><code>true_folds</code> &ndash; The true values of the response in each fold.
</p>
<p><code>MSPE</code> &ndash; A list object containing the MSPE in each fold and the overall cross-validated MSPE.
</p>
<p><code>fold_indices</code> &ndash; The generated indices for each fold; for replication purposes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Libraries
library(fda)

# Loading data
data("daily")

# Creating functional data
nbasis = 65
temp_data = array(dim = c(nbasis, 35, 1))
tempbasis65  = create.fourier.basis(c(0,365), nbasis)
tempbasis7 = create.bspline.basis(c(0,365), 7, norder = 4)
timepts = seq(1, 365, 1)
temp_fd = Data2fd(timepts, daily$tempav, tempbasis65)
prec_fd = Data2fd(timepts, daily$precav, tempbasis7)
prec_fd$coefs = scale(prec_fd$coefs)

# Data set up
temp_data[,,1] = temp_fd$coefs
resp_mat = prec_fd$coefs

# Non functional covariate
weather_scalar = data.frame(total_prec = apply(daily$precav, 2, sum))

# Setting up data to pass in to function
weather_data_full &lt;- array(dim = c(nbasis, ncol(temp_data), 1))
weather_data_full[,,1] = temp_data
scalar_full = data.frame(weather_scalar[,1])
total_prec = apply(daily$precav, 2, mean)

# cross-validating
cv_example &lt;- fnn.cv(nfolds = 5,
                     resp = total_prec,
                     func_cov = weather_data_full,
                     scalar_cov = scalar_full,
                     domain_range = list(c(1, 365)),
                     learn_rate = 0.001)


</code></pre>

<hr>
<h2 id='fnn.fit'>Fitting Functional Neural Networks</h2><span id='topic+fnn.fit'></span>

<h3>Description</h3>

<p>This is the main function in the <code>FuncNN</code> package. This function fits models of the form: f(z, b(x)) where
z are the scalar covariates and b(x) are the functional covariates. The form of f() is that of a neural network
with a generalized input space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnn.fit(
  resp,
  func_cov,
  scalar_cov = NULL,
  basis_choice = c("fourier"),
  num_basis = c(7),
  hidden_layers = 2,
  neurons_per_layer = c(64, 64),
  activations_in_layers = c("sigmoid", "linear"),
  domain_range = list(c(0, 1)),
  epochs = 100,
  loss_choice = "mse",
  metric_choice = list("mean_squared_error"),
  val_split = 0.2,
  learn_rate = 0.001,
  patience_param = 15,
  early_stopping = TRUE,
  print_info = TRUE,
  batch_size = 32,
  decay_rate = 0,
  func_resp_method = 1,
  covariate_scaling = TRUE,
  raw_data = FALSE,
  dropout = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnn.fit_+3A_resp">resp</code></td>
<td>
<p>For scalar responses, this is a vector of the observed dependent variable. For functional responses,
this is a matrix where each row contains the basis coefficients defining the functional response (for each observation).</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_func_cov">func_cov</code></td>
<td>
<p>The form of this depends on whether the <code>raw_data</code> argument is true or not. If true, then this is
a list of k matrices. The dimensionality of the matrices should be the same (n x p) where n is the number of
observations and p is the number of longitudinal observations. If <code>raw_data</code> is false, then the input should be a tensor
with dimensionality b x n x k where b is the number of basis functions used to define the functional covariates, n is
the number of observations, and k is the number of functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_scalar_cov">scalar_cov</code></td>
<td>
<p>A matrix contained the multivariate information associated with the data set. This is all of your
non-longitudinal data.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_basis_choice">basis_choice</code></td>
<td>
<p>A vector of size k (the number of functional covariates) with either &quot;fourier&quot; or &quot;bspline&quot; as the inputs.
This is the choice for the basis functions used for the functional weight expansion. If you only specify one, with k &gt; 1,
then the argument will repeat that choice for all k functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_num_basis">num_basis</code></td>
<td>
<p>A vector of size k defining the number of basis functions to be used in the basis expansion. Must be odd
for <code>fourier</code> basis choices. If you only specify one, with k &gt; 1, then the argument will repeat that choice for all
k functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_hidden_layers">hidden_layers</code></td>
<td>
<p>The number of hidden layers to be used in the neural network.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_neurons_per_layer">neurons_per_layer</code></td>
<td>
<p>Vector of size = <code>hidden_layers</code>. The u-th element of the vector corresponds to the number of neurons
in the u-th hidden layer.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_activations_in_layers">activations_in_layers</code></td>
<td>
<p>Vector of size = <code>hidden_layers</code>. The u-th element of the vector corresponds to the
activation choice in the u-th hidden layer.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_domain_range">domain_range</code></td>
<td>
<p>List of size k. Each element of the list is a 2-dimensional vector containing the upper and lower
bounds of the k-th functional weight.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_epochs">epochs</code></td>
<td>
<p>The number of training iterations.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_loss_choice">loss_choice</code></td>
<td>
<p>This parameter defines the loss function used in the learning process.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_metric_choice">metric_choice</code></td>
<td>
<p>This parameter defines the printed out error metric.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_val_split">val_split</code></td>
<td>
<p>A parameter that decides the percentage split of the inputted data set.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_learn_rate">learn_rate</code></td>
<td>
<p>Hyperparameter that defines how quickly you move in the direction of the gradient.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_patience_param">patience_param</code></td>
<td>
<p>A keras parameter that decides how many additional <code>epochs</code> are eclipsed with minimal change in
error before the learning process is stopped. This is only active if <code>early_stopping = TRUE</code></p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_early_stopping">early_stopping</code></td>
<td>
<p>If TRUE, then learning process will be halted early if error improvement isn't seen.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_print_info">print_info</code></td>
<td>
<p>If TRUE, function will output information about the model as it is trained.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of the batch for stochastic gradient descent.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_decay_rate">decay_rate</code></td>
<td>
<p>A modification to the learning rate that decreases the learning rate as more and more learning
iterations are completed.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_func_resp_method">func_resp_method</code></td>
<td>
<p>Set to 1 by default. In the future, this will be set to 2 for an alternative functional response
approach.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_covariate_scaling">covariate_scaling</code></td>
<td>
<p>If TRUE, then data will be internally scaled before model development.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_raw_data">raw_data</code></td>
<td>
<p>If TRUE, then user does not need to create functional observations beforehand. The function will
internally take care of that pre-processing.</p>
</td></tr>
<tr><td><code id="fnn.fit_+3A_dropout">dropout</code></td>
<td>
<p>Keras parameter that randomly drops some percentage of the neurons in a given layer.
If TRUE, then 0.1*layer_number will be dropped; instead, you can specify a vector equal to the number
of layers specifying what percentage to drop in each layer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Updates coming soon.
</p>


<h3>Value</h3>

<p>The following are returned:
</p>
<p><code>model</code> &ndash; Full keras model that can be used with any functions that act on keras models.
</p>
<p><code>data</code> &ndash; Adjust data set after scaling and appending of scalar covariates.
</p>
<p><code>fnc_basis_num</code> &ndash; A return of the original input; describes the number of functions used in each of the k basis expansions.
</p>
<p><code>fnc_type</code> &ndash; A return of the original input; describes the basis expansion used to make the functional weights.
</p>
<p><code>parameter_info</code> &ndash; Information associated with hyperparameter choices in the model.
</p>
<p><code>per_iter_info</code> &ndash; Change in error over training iterations
</p>
<p><code>func_obs</code> &ndash; In the case when <code>raw_data</code> is <code>TRUE</code>, the user may want to see the internally developed functional observations.
This returns those functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
# First, an easy example with raw_data = TRUE


# Loading in data
data("daily")

# Functional covariates (subsetting for time sake)
precip = t(daily$precav)
longtidunal_dat = list(precip)

# Scalar Response
total_prec = apply(daily$precav, 2, mean)

# Running model
fit1 = fnn.fit(resp = total_prec,
               func_cov = longtidunal_dat,
               scalar_cov = NULL,
               learn_rate = 0.0001,
               epochs = 10,
               raw_data = TRUE)
               
# Classification Example with raw_data = TRUE

# Loading data
tecator = FuncNN::tecator

# Making classification bins
tecator_resp = as.factor(ifelse(tecator$y$Fat &gt; 25, 1, 0))

# Non functional covariate
tecator_scalar = data.frame(water = tecator$y$Water)

# Splitting data
ind = sample(1:length(tecator_resp), round(0.75*length(tecator_resp)))
train_y = tecator_resp[ind]
test_y = tecator_resp[-ind]
train_x = tecator$absorp.fdata$data[ind,]
test_x = tecator$absorp.fdata$data[-ind,]
scalar_train = data.frame(tecator_scalar[ind,1])
scalar_test = data.frame(tecator_scalar[-ind,1])

# Making list element to pass in
func_covs_train = list(train_x)
func_covs_test = list(test_x)

# Now running model
fit_class = fnn.fit(resp = train_y,
                    func_cov = func_covs_train,
                    scalar_cov = scalar_train,
                    hidden_layers = 6,
                    neurons_per_layer = c(24, 24, 24, 24, 24, 58),
                    activations_in_layers = c("relu", "relu", "relu", "relu", "relu", "linear"),
                    domain_range = list(c(850, 1050)),
                    learn_rate = 0.001,
                    epochs = 100,
                    raw_data = TRUE,
                    early_stopping = TRUE)

# Running prediction, gets probabilities
predict_class = fnn.predict(fit_class,
                            func_cov = func_covs_test,
                            scalar_cov = scalar_test,
                            domain_range = list(c(850, 1050)),
                            raw_data = TRUE)

# Example with Pre-Processing (raw_data = FALSE)

# loading data
tecator = FuncNN::tecator

# libraries
library(fda)

# define the time points on which the functional predictor is observed.
timepts = tecator$absorp.fdata$argvals

# define the fourier basis
nbasis = 29
spline_basis = create.fourier.basis(tecator$absorp.fdata$rangeval, nbasis)

# convert the functional predictor into a fda object and getting deriv
tecator_fd =  Data2fd(timepts, t(tecator$absorp.fdata$data), spline_basis)
tecator_deriv = deriv.fd(tecator_fd)
tecator_deriv2 = deriv.fd(tecator_deriv)

# Non functional covariate
tecator_scalar = data.frame(water = tecator$y$Water)

# Response
tecator_resp = tecator$y$Fat

# Getting data into right format
tecator_data = array(dim = c(nbasis, length(tecator_resp), 3))
tecator_data[,,1] = tecator_fd$coefs
tecator_data[,,2] = tecator_deriv$coefs
tecator_data[,,3] = tecator_deriv2$coefs

# Splitting into test and train for third FNN
ind = 1:165
tec_data_train &lt;- array(dim = c(nbasis, length(ind), 3))
tec_data_test &lt;- array(dim = c(nbasis, nrow(tecator$absorp.fdata$data) - length(ind), 3))
tec_data_train = tecator_data[, ind, ]
tec_data_test = tecator_data[, -ind, ]
tecResp_train = tecator_resp[ind]
tecResp_test = tecator_resp[-ind]
scalar_train = data.frame(tecator_scalar[ind,1])
scalar_test = data.frame(tecator_scalar[-ind,1])

# Setting up network
tecator_fnn = fnn.fit(resp = tecResp_train,
                      func_cov = tec_data_train,
                      scalar_cov = scalar_train,
                      basis_choice = c("fourier", "fourier", "fourier"),
                      num_basis = c(5, 5, 7),
                      hidden_layers = 4,
                      neurons_per_layer = c(64, 64, 64, 64),
                      activations_in_layers = c("relu", "relu", "relu", "linear"),
                      domain_range = list(c(850, 1050), c(850, 1050), c(850, 1050)),
                      epochs = 300,
                      learn_rate = 0.002)

# Prediction example can be seen with ?fnn.fit()

# Functional Response Example:

# libraries
library(fda)

# Loading data
data("daily")

# Creating functional data
temp_data = array(dim = c(65, 35, 1))
tempbasis65  = create.fourier.basis(c(0,365), 65)
tempbasis7 = create.bspline.basis(c(0,365), 7, norder = 4)
timepts = seq(1, 365, 1)
temp_fd = Data2fd(timepts, daily$tempav, tempbasis65)
prec_fd = Data2fd(timepts, daily$precav, tempbasis7)
prec_fd$coefs = scale(prec_fd$coefs)

# Data set up
temp_data[,,1] = temp_fd$coefs
resp_mat = prec_fd$coefs

# Non functional covariate
weather_scalar = data.frame(total_prec = apply(daily$precav, 2, sum))

# Getting data into proper format
ind = 1:30
nbasis = 65
weather_data_train &lt;- array(dim = c(nbasis, ncol(temp_data), 1))
weather_data_train[,,1] = temp_data
scalar_train = data.frame(weather_scalar[,1])
resp_train = t(resp_mat)

# Running model
weather_func_fnn &lt;- fnn.fit(resp = resp_train,
                            func_cov = weather_data_train,
                            scalar_cov = scalar_train,
                            basis_choice = c("bspline"),
                            num_basis = c(7),
                            hidden_layers = 2,
                            neurons_per_layer = c(1024, 1024),
                            activations_in_layers = c("sigmoid", "linear"),
                            domain_range = list(c(1, 365)),
                            epochs = 300,
                            learn_rate = 0.01,
                            func_resp_method = 1)



</code></pre>

<hr>
<h2 id='fnn.fnc'>Output of Estimated Functional Weights</h2><span id='topic+fnn.fnc'></span>

<h3>Description</h3>

<p>This function outputs plots and <code>ggplot()</code> objects of the functional weights found by the <code>fnn.fit()</code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnn.fnc(model, domain_range, covariate_scaling = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnn.fnc_+3A_model">model</code></td>
<td>
<p>A keras model as outputted by <code>fnn.fit()</code>.</p>
</td></tr>
<tr><td><code id="fnn.fnc_+3A_domain_range">domain_range</code></td>
<td>
<p>List of size k. Each element of the list is a 2-dimensional vector containing the upper and lower
bounds of the k-th functional weight. Must be the same covariates as input into <code>fnn.fit()</code>.</p>
</td></tr>
<tr><td><code id="fnn.fnc_+3A_covariate_scaling">covariate_scaling</code></td>
<td>
<p>If TRUE, then data will be internally scaled before model development.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>No additional details for now.
</p>


<h3>Value</h3>

<p>The following are returned:
</p>
<p><code>FNC_Coefficients</code> &ndash; The estimated coefficients defining the basis expansion for each of the k functional weights.
</p>
<p><code>saved_plot</code> &ndash; A list of size k of <code>ggplot()</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# libraries
library(fda)

# loading data
tecator = FuncNN::tecator

# define the time points on which the functional predictor is observed.
timepts = tecator$absorp.fdata$argvals

# define the fourier basis
nbasis = 29
spline_basis = create.fourier.basis(tecator$absorp.fdata$rangeval, nbasis)

# convert the functional predictor into a fda object and getting deriv
tecator_fd =  Data2fd(timepts, t(tecator$absorp.fdata$data), spline_basis)
tecator_deriv = deriv.fd(tecator_fd)
tecator_deriv2 = deriv.fd(tecator_deriv)

# Non functional covariate
tecator_scalar = data.frame(water = tecator$y$Water)

# Response
tecator_resp = tecator$y$Fat

# Getting data into right format
tecator_data = array(dim = c(nbasis, length(tecator_resp), 3))
tecator_data[,,1] = tecator_fd$coefs
tecator_data[,,2] = tecator_deriv$coefs
tecator_data[,,3] = tecator_deriv2$coefs

# Getting data ready to pass into function
ind = 1:165
tec_data_train &lt;- array(dim = c(nbasis, length(ind), 3))
tec_data_train = tecator_data[, ind, ]
tecResp_train = tecator_resp[ind]
scalar_train = data.frame(tecator_scalar[ind,1])

# Setting up network
tecator_fnn = fnn.fit(resp = tecResp_train,
                      func_cov = tec_data_train,
                      scalar_cov = scalar_train,
                      basis_choice = c("fourier", "fourier", "fourier"),
                      num_basis = c(5, 5, 7),
                      hidden_layers = 4,
                      neurons_per_layer = c(64, 64, 64, 64),
                      activations_in_layers = c("relu", "relu", "relu", "linear"),
                      domain_range = list(c(850, 1050), c(850, 1050), c(850, 1050)),
                      epochs = 300,
                      learn_rate = 0.002)

# Functional weights for this model
est_func_weights = fnn.fnc(tecator_fnn, domain_range = list(c(850, 1050),
                                                            c(850, 1050),
                                                            c(850, 1050)))


</code></pre>

<hr>
<h2 id='fnn.plot'>Plotting Functional Response Predictions</h2><span id='topic+fnn.plot'></span>

<h3>Description</h3>

<p>This function is to be used for functional responses. It outputs a <code>ggplot()</code> object of the predicted functional responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnn.plot(
  FNN_Predict_Object,
  Basis_Type = "fourier",
  domain_range = c(0, 1),
  step_size = 0.01
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnn.plot_+3A_fnn_predict_object">FNN_Predict_Object</code></td>
<td>
<p>An object output by the <code>fnn.predict()</code> function. Must be for when the problem is that of
a functional response.</p>
</td></tr>
<tr><td><code id="fnn.plot_+3A_basis_type">Basis_Type</code></td>
<td>
<p>The type of basis to use to create the functional response.</p>
</td></tr>
<tr><td><code id="fnn.plot_+3A_domain_range">domain_range</code></td>
<td>
<p>The continuum range of the functional responses.</p>
</td></tr>
<tr><td><code id="fnn.plot_+3A_step_size">step_size</code></td>
<td>
<p>The size of the movement from the lower bound of the <code>domanin_range</code> to the upper bound.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>No additional details for now.
</p>


<h3>Value</h3>

<p>The following are returned:
</p>
<p><code>plot</code> &ndash; A <code>ggplot()</code> object of the predicted functional responses.
</p>
<p><code>evaluations</code> &ndash; The discrete evaluations across the domain of the functional response.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# libraries
library(fda)

# Loading data
data("daily")

# Creating functional data
temp_data = array(dim = c(65, 35, 1))
tempbasis65  = create.fourier.basis(c(0,365), 65)
tempbasis7 = create.bspline.basis(c(0,365), 7, norder = 4)
timepts = seq(1, 365, 1)
temp_fd = Data2fd(timepts, daily$tempav, tempbasis65)
prec_fd = Data2fd(timepts, daily$precav, tempbasis7)
prec_fd$coefs = scale(prec_fd$coefs)

# Data set up
temp_data[,,1] = temp_fd$coefs
resp_mat = prec_fd$coefs

# Non functional covariate
weather_scalar = data.frame(total_prec = apply(daily$precav, 2, sum))

# Splitting into test and train
ind = 1:30
nbasis = 65
weather_data_train &lt;- array(dim = c(nbasis, length(ind), 1))
weather_data_test &lt;- array(dim = c(nbasis, ncol(daily$tempav) - length(ind), 1))
weather_data_train[,,1] = temp_data[, ind, ]
weather_data_test[,,1] = temp_data[, -ind, ]
scalar_train = data.frame(weather_scalar[ind,1])
scalar_test = data.frame(weather_scalar[-ind,1])
resp_train = t(resp_mat[,ind])
resp_test = t(resp_mat[,-ind])

# Running model
weather_func_fnn &lt;- fnn.fit(resp = resp_train,
                            func_cov = weather_data_train,
                            scalar_cov = scalar_train,
                            basis_choice = c("bspline"),
                            num_basis = c(7),
                            hidden_layers = 2,
                            neurons_per_layer = c(1024, 1024),
                            activations_in_layers = c("sigmoid", "linear"),
                            domain_range = list(c(1, 365)),
                            epochs = 300,
                            learn_rate = 0.01,
                            func_resp_method = 1)

# Getting predictions
predictions = fnn.predict(weather_func_fnn,
                          weather_data_test,
                          scalar_cov = scalar_test,
                          basis_choice = c("bspline"),
                          num_basis = c(7),
                          domain_range = list(c(1, 365)))

# Looking at plot
fnn.plot(predictions, domain_range = c(1, 365), step_size = 1, Basis_Type = "bspline")


</code></pre>

<hr>
<h2 id='fnn.predict'>Prediction using Functional Neural Networks</h2><span id='topic+fnn.predict'></span>

<h3>Description</h3>

<p>The prediction function associated with the fnn model allowing for users to quickly get scalar or functional outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnn.predict(
  model,
  func_cov,
  scalar_cov = NULL,
  basis_choice = c("fourier"),
  num_basis = c(7),
  domain_range = list(c(0, 1)),
  covariate_scaling = TRUE,
  raw_data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnn.predict_+3A_model">model</code></td>
<td>
<p>A keras model as outputted by <code>fnn.fit()</code>.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_func_cov">func_cov</code></td>
<td>
<p>The form of this depends on whether the <code>raw_data</code> argument is true or not. If true, then this is
a list of k matrices. The dimensionality of the matrices should be the same (n x p) where n is the number of
observations and p is the number of longitudinal observations. If <code>raw_data</code> is false, then the input should be a tensor
with dimensionality b x n x k where b is the number of basis functions used to define the functional covariates, n is
the number of observations, and k is the number of functional covariates. Must be the same covariates as input into
<code>fnn.fit()</code> although here, they will likely be the 'test' observations.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_scalar_cov">scalar_cov</code></td>
<td>
<p>A matrix contained the multivariate information associated with the data set. This is all of your
non-longitudinal data. Must be the same covariates as input into
<code>fnn.fit()</code> although here, they will likely be the 'test' observations.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_basis_choice">basis_choice</code></td>
<td>
<p>A vector of size k (the number of functional covariates) with either &quot;fourier&quot; or &quot;bspline&quot; as the inputs.
This is the choice for the basis functions used for the functional weight expansion. If you only specify one, with k &gt; 1,
then the argument will repeat that choice for all k functional covariates. Should be the same choices as input into
<code>fnn.fit()</code>.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_num_basis">num_basis</code></td>
<td>
<p>A vector of size k defining the number of basis functions to be used in the basis expansion. Must be odd
for <code>fourier</code> basis choices. If you only specify one, with k &gt; 1, then the argument will repeat that choice for all
k functional covariates. Should be the same values as input into
<code>fnn.fit()</code>.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_domain_range">domain_range</code></td>
<td>
<p>List of size k. Each element of the list is a 2-dimensional vector containing the upper and lower
bounds of the k-th functional weight. Must be the same covariates as input into <code>fnn.fit()</code>.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_covariate_scaling">covariate_scaling</code></td>
<td>
<p>If TRUE, then data will be internally scaled before model development.</p>
</td></tr>
<tr><td><code id="fnn.predict_+3A_raw_data">raw_data</code></td>
<td>
<p>If TRUE, then user does not need to create functional observations beforehand. The function will
internally take care of that pre-processing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>No additional details for now.
</p>


<h3>Value</h3>

<p>The following is returned:
</p>
<p><code>Predictions</code> &ndash; A vector of scalar predictions or a matrix of basis coefficients for functional responses.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First, we do an example with a scalar response:

# loading data
tecator = FuncNN::tecator

# libraries
library(fda)

# define the time points on which the functional predictor is observed.
timepts = tecator$absorp.fdata$argvals

# define the fourier basis
nbasis = 29
spline_basis = create.fourier.basis(tecator$absorp.fdata$rangeval, nbasis)

# convert the functional predictor into a fda object and getting deriv
tecator_fd =  Data2fd(timepts, t(tecator$absorp.fdata$data), spline_basis)
tecator_deriv = deriv.fd(tecator_fd)
tecator_deriv2 = deriv.fd(tecator_deriv)

# Non functional covariate
tecator_scalar = data.frame(water = tecator$y$Water)

# Response
tecator_resp = tecator$y$Fat

# Getting data into right format
tecator_data = array(dim = c(nbasis, length(tecator_resp), 3))
tecator_data[,,1] = tecator_fd$coefs
tecator_data[,,2] = tecator_deriv$coefs
tecator_data[,,3] = tecator_deriv2$coefs

# Splitting into test and train for third FNN
ind = 1:165
tec_data_train &lt;- array(dim = c(nbasis, length(ind), 3))
tec_data_test &lt;- array(dim = c(nbasis, nrow(tecator$absorp.fdata$data) - length(ind), 3))
tec_data_train = tecator_data[, ind, ]
tec_data_test = tecator_data[, -ind, ]
tecResp_train = tecator_resp[ind]
tecResp_test = tecator_resp[-ind]
scalar_train = data.frame(tecator_scalar[ind,1])
scalar_test = data.frame(tecator_scalar[-ind,1])

# Setting up network
tecator_fnn = fnn.fit(resp = tecResp_train,
                      func_cov = tec_data_train,
                      scalar_cov = scalar_train,
                      basis_choice = c("fourier", "fourier", "fourier"),
                      num_basis = c(5, 5, 7),
                      hidden_layers = 4,
                      neurons_per_layer = c(64, 64, 64, 64),
                      activations_in_layers = c("relu", "relu", "relu", "linear"),
                      domain_range = list(c(850, 1050), c(850, 1050), c(850, 1050)),
                      epochs = 300,
                      learn_rate = 0.002)

# Predicting
pred_tec = fnn.predict(tecator_fnn,
                       tec_data_test,
                       scalar_cov = scalar_test,
                       basis_choice = c("fourier", "fourier", "fourier"),
                       num_basis = c(5, 5, 7),
                       domain_range = list(c(850, 1050), c(850, 1050), c(850, 1050)))

# Now an example with functional responses

# libraries
library(fda)

# Loading data
data("daily")

# Creating functional data
temp_data = array(dim = c(65, 35, 1))
tempbasis65  = create.fourier.basis(c(0,365), 65)
tempbasis7 = create.bspline.basis(c(0,365), 7, norder = 4)
timepts = seq(1, 365, 1)
temp_fd = Data2fd(timepts, daily$tempav, tempbasis65)
prec_fd = Data2fd(timepts, daily$precav, tempbasis7)
prec_fd$coefs = scale(prec_fd$coefs)

# Data set up
temp_data[,,1] = temp_fd$coefs
resp_mat = prec_fd$coefs

# Non functional covariate
weather_scalar = data.frame(total_prec = apply(daily$precav, 2, sum))

# Splitting into test and train
ind = 1:30
nbasis = 65
weather_data_train &lt;- array(dim = c(nbasis, length(ind), 1))
weather_data_test &lt;- array(dim = c(nbasis, ncol(daily$tempav) - length(ind), 1))
weather_data_train[,,1] = temp_data[, ind, ]
weather_data_test[,,1] = temp_data[, -ind, ]
scalar_train = data.frame(weather_scalar[ind,1])
scalar_test = data.frame(weather_scalar[-ind,1])
resp_train = t(resp_mat[,ind])
resp_test = t(resp_mat[,-ind])

# Running model
weather_func_fnn &lt;- fnn.fit(resp = resp_train,
                            func_cov = weather_data_train,
                            scalar_cov = scalar_train,
                            basis_choice = c("bspline"),
                            num_basis = c(7),
                            hidden_layers = 2,
                            neurons_per_layer = c(1024, 1024),
                            activations_in_layers = c("sigmoid", "linear"),
                            domain_range = list(c(1, 365)),
                            epochs = 300,
                            learn_rate = 0.01,
                            func_resp_method = 1)

# Getting Predictions
predictions = fnn.predict(weather_func_fnn,
                          weather_data_test,
                          scalar_cov = scalar_test,
                          basis_choice = c("bspline"),
                          num_basis = c(7),
                          domain_range = list(c(1, 365)))

# Looking at predictions
predictions


# Classification Prediction

# Loading data
tecator = FuncNN::tecator

# Making classification bins
tecator_resp = as.factor(ifelse(tecator$y$Fat &gt; 25, 1, 0))

# Non functional covariate
tecator_scalar = data.frame(water = tecator$y$Water)

# Splitting data
ind = sample(1:length(tecator_resp), round(0.75*length(tecator_resp)))
train_y = tecator_resp[ind]
test_y = tecator_resp[-ind]
train_x = tecator$absorp.fdata$data[ind,]
test_x = tecator$absorp.fdata$data[-ind,]
scalar_train = data.frame(tecator_scalar[ind,1])
scalar_test = data.frame(tecator_scalar[-ind,1])

# Making list element to pass in
func_covs_train = list(train_x)
func_covs_test = list(test_x)

# Now running model
fit_class = fnn.fit(resp = train_y,
                    func_cov = func_covs_train,
                    scalar_cov = scalar_train,
                    hidden_layers = 6,
                    neurons_per_layer = c(24, 24, 24, 24, 24, 58),
                    activations_in_layers = c("relu", "relu", "relu", "relu", "relu", "linear"),
                    domain_range = list(c(850, 1050)),
                    learn_rate = 0.001,
                    epochs = 100,
                    raw_data = TRUE,
                    early_stopping = TRUE)

# Running prediction
predict_class = fnn.predict(fit_class,
                            func_cov = func_covs_test,
                            scalar_cov = scalar_test,
                            domain_range = list(c(850, 1050)),
                            raw_data = TRUE)

# Rounding predictions (they are probabilities)
rounded_preds = ifelse(round(predict_class)[,2] == 1, 1, 0)

# Confusion matrix
# caret::confusionMatrix(as.factor(rounded_preds), as.factor(test_y))



</code></pre>

<hr>
<h2 id='fnn.tune'>Tuning Functional Neural Networks</h2><span id='topic+fnn.tune'></span>

<h3>Description</h3>

<p>A convenience function for the user that implements a simple grid search for the purpose of tuning. For each combination
in the grid, a cross-validated error is calculated. The best combination is returned along with additional information.
This function only works for scalar responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnn.tune(
  tune_list,
  resp,
  func_cov,
  scalar_cov = NULL,
  basis_choice,
  domain_range,
  batch_size = 32,
  decay_rate = 0,
  nfolds = 5,
  cores = 4,
  raw_data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fnn.tune_+3A_tune_list">tune_list</code></td>
<td>
<p>This is a list object containing the values from which to develop the grid. For each of the hyperparameters
that can be tuned for (<code>num_hidden_layers</code>, <code>neurons</code>, <code>epochs</code>, <code>val_split</code>, <code>patience</code>, <code>learn_rate</code>, <code>num_basis</code>,
<code>activation_choice</code>), the user inputs a set of values to try. Note that the combinations are found based on the number of
hidden layers. For example, if <code>num_hidden_layers</code> = 3 and <code>neurons</code> = c(8, 16), then the combinations will begin as
c(8, 8, 8), c(8, 8, 16), ..., c(16, 16, 16). Example provided below.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_resp">resp</code></td>
<td>
<p>For scalar responses, this is a vector of the observed dependent variable. For functional responses,
this is a matrix where each row contains the basis coefficients defining the functional response (for each observation).</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_func_cov">func_cov</code></td>
<td>
<p>The form of this depends on whether the <code>raw_data</code> argument is true or not. If true, then this is
a list of k matrices. The dimensionality of the matrices should be the same (n x p) where n is the number of
observations and p is the number of longitudinal observations. If <code>raw_data</code> is false, then the input should be a tensor
with dimensionality b x n x k where b is the number of basis functions used to define the functional covariates, n is
the number of observations, and k is the number of functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_scalar_cov">scalar_cov</code></td>
<td>
<p>A matrix contained the multivariate information associated with the data set. This is all of your
non-longitudinal data.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_basis_choice">basis_choice</code></td>
<td>
<p>A vector of size k (the number of functional covariates) with either &quot;fourier&quot; or &quot;bspline&quot; as the inputs.
This is the choice for the basis functions used for the functional weight expansion. If you only specify one, with k &gt; 1,
then the argument will repeat that choice for all k functional covariates.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_domain_range">domain_range</code></td>
<td>
<p>List of size k. Each element of the list is a 2-dimensional vector containing the upper and lower
bounds of the k-th functional weight.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of the batch for stochastic gradient descent.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_decay_rate">decay_rate</code></td>
<td>
<p>A modification to the learning rate that decreases the learning rate as more and more learning
iterations are completed.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to be used in the cross-validation process.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_cores">cores</code></td>
<td>
<p>For the purpose of parallelization.</p>
</td></tr>
<tr><td><code id="fnn.tune_+3A_raw_data">raw_data</code></td>
<td>
<p>If TRUE, then user does not need to create functional observations beforehand. The function will
internally take care of that pre-processing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>No additional details for now.
</p>


<h3>Value</h3>

<p>The following are returned:
</p>
<p><code>Parameters</code> &ndash; The final list of hyperparameter chosen by the tuning process.
</p>
<p><code>All_Information</code> &ndash; A list object containing the errors for every combination in the grid. Each element of the list
corresponds to a different choice of number of hidden layers.
</p>
<p><code>Best_Per_Layer</code> &ndash; An object that returns the best parameter combination for each choice of hidden layers.
</p>
<p><code>Grid_List</code> &ndash; An object containing information about all combinations tried by the tuning process.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# libraries
library(fda)

# Loading data
data("daily")

# Obtaining response
total_prec = apply(daily$precav, 2, mean)

# Creating functional data
temp_data = array(dim = c(65, 35, 1))
tempbasis65  = create.fourier.basis(c(0,365), 65)
timepts = seq(1, 365, 1)
temp_fd = Data2fd(timepts, daily$tempav, tempbasis65)

# Data set up
temp_data[,,1] = temp_fd$coefs

# Creating grid
tune_list_weather = list(num_hidden_layers = c(2),
                         neurons = c(8, 16),
                         epochs = c(250),
                         val_split = c(0.2),
                         patience = c(15),
                         learn_rate = c(0.01, 0.1),
                         num_basis = c(7),
                         activation_choice = c("relu", "sigmoid"))

# Running Tuning
weather_tuned = fnn.tune(tune_list_weather,
                         total_prec,
                         temp_data,
                         basis_choice = c("fourier"),
                         domain_range = list(c(1, 24)),
                         nfolds = 2)

# Looking at results
weather_tuned


</code></pre>

<hr>
<h2 id='tecator'>Classic Tecator data set.</h2><span id='topic+tecator'></span>

<h3>Description</h3>

<p>Classic Tecator data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tecator)
</code></pre>


<h3>Format</h3>

<p>An object containing the response and absorbance curve values.
</p>


<h3>References</h3>

<p>Thodberg, H. H. (2015) “Tecator meat sample dataset”, <a href="http://lib.stat.cmu.edu/datasets/tecator">http://lib.stat.cmu.edu/datasets/tecator</a> StatLib Datasets Archive
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
