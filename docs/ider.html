<!DOCTYPE html><html><head><title>Help for package ider</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ider}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#convU'><p>Intrinsic Dimension Estimation with Convergence Property of a U-statistics.</p></a></li>
<li><a href='#corint'><p>Intrinsic Dimension Estimation with Correlation Integral</p></a></li>
<li><a href='#gendata'><p>Data generator for intrinsic dimension estimation.</p></a></li>
<li><a href='#handD'><p>Hand ratation data</p></a></li>
<li><a href='#ider-package'><p>Algorithms for Estimating Intrinsic Dimensions.</p></a></li>
<li><a href='#lbmle'><p>Maximum Likelihood Estimation of Intrinsic Dimension.</p></a></li>
<li><a href='#mada'><p>Manifold-Adaptive Local Dimension Estimation.</p></a></li>
<li><a href='#nni'><p>Intrinsic Dimensionality Estimation from Near-Neighbor Information.</p></a></li>
<li><a href='#pack'><p>Intrinsic Dimension Estimation Using Packing Numbers.</p></a></li>
<li><a href='#side'><p>Higher-order Local Information Dimension Estimator.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Various Methods for Estimating Intrinsic Dimension</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-02-10</td>
</tr>
<tr>
<td>Author:</td>
<td>Hideitsu Hino</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hideitsu Hino &lt;hideitsu.hino@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of various methods for estimating intrinsic
    dimension of vector-valued dataset or distance matrix. Most methods implemented
    are based on different notion of fractal dimension such as the capacity
    dimension, the box-counting dimension, and the information dimension.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>FNN, stats, glm2</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.2</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-10 09:31:05 UTC; hino1</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-10 10:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='convU'>Intrinsic Dimension Estimation with Convergence Property of a U-statistics.</h2><span id='topic+convU'></span>

<h3>Description</h3>

<p><code>convU</code> estimates intrinsic dimension of given dataset based on 
the convergence property of Ustatistics(smoothed correlation dimension)
w.r.t. kernel bandwidth
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convU(x, maxDim = 5, DM = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convU_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="convU_+3A_maxdim">maxDim</code></td>
<td>
<p>maximum of the candidate dimension.</p>
</td></tr>
<tr><td><code id="convU_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variant of fractal dimension called the correlation dimension is considered.
The correlation dimension is defined by the notion of the correlation integral, which 
is calculated by counting the number of pairs closer than certain threshold epsilon.
The counting operation is replaced with the kernel smoothed version, and based on
the convergence property of the resulting U-statistics, an intrinsic dimension estimator is derived.
</p>


<h3>Value</h3>

<p>Estimated global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>M. Hein and J-Y. Audibert. Intrinsic dimensionality estimation of
submanifolds in Rd. International Conference on Machine Learning, 2005.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- gendata(DataName='SwissRoll',n=300)
estconvU &lt;- convU(x=x)
print(estconvU)
</code></pre>

<hr>
<h2 id='corint'>Intrinsic Dimension Estimation with Correlation Integral</h2><span id='topic+corint'></span>

<h3>Description</h3>

<p><code>corint</code> estimates intrinsic dimension of given dataset based on 
the correlation integral
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corint(x, k1 = NULL, k2 = NULL, DM = FALSE, p = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corint_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="corint_+3A_k1">k1</code></td>
<td>
<p>first k-NN parameter.</p>
</td></tr>
<tr><td><code id="corint_+3A_k2">k2</code></td>
<td>
<p>second k-NN parameter.</p>
</td></tr>
<tr><td><code id="corint_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
<tr><td><code id="corint_+3A_p">p</code></td>
<td>
<p>ambient dimension used for automatically define <code>'k1'</code> and <code>'k2'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variant of fractal dimension called the correlation dimension is considered.
The correlation dimension is defined by the notion of the correlation integral, 
is calculated by using the power low for the definition of the correlation dimension.
</p>


<h3>Value</h3>

<p>Estimated global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>P. Grassberger and I. Procaccia. Measuring the strangeness of strange attractors. 
Physica, 1983.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- gendata(DataName='SwissRoll',n=300)
estcorint &lt;- corint(x=x,k1=5,k2=10)
print(estcorint)
</code></pre>

<hr>
<h2 id='gendata'>Data generator for intrinsic dimension estimation.</h2><span id='topic+gendata'></span>

<h3>Description</h3>

<p><code>gendata</code> generates various artificial datasets for intrinsic dimension estimation experiments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendata(
  DataName = "SwissRoll",
  n = 300,
  p = NULL,
  noise = NULL,
  ol = NULL,
  curv = 1,
  seed = 123,
  sorted = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendata_+3A_dataname">DataName</code></td>
<td>
<p>Name of dataset, one of the following: 
</p>

<ul>
<li><p> SwissRoll: SwissRoll data, 2D manifold in 3D space.
</p>
</li>
<li><p> NDSwissRoll: Non-deformable SwissRoll data, 2D manifold in 3D space.
</p>
</li>
<li><p> Moebius: Moebius strip, 2D manifold in 3D space.
</p>
</li>
<li><p> SphericalShell: Spherical Shell, (p-1)-dimensional manifold in p-dimensional space.
</p>
</li>
<li><p> Sinusoidal: Sinusoidal data, 1D manifold in 3D space.
</p>
</li>
<li><p> Spiral: Spiral-shaped 1D manifold in 2D space.
</p>
</li>
<li><p> Cylinder: Cylinder-shaped 2D manifold in 3D space.
</p>
</li>
<li><p> SShape: S-shaped 2D manifold in 3D space.
</p>
</li>
<li><p> ldbl: LDB(line - disc - filled ball - line), embedded in 3D space (original dataset).
</p>
</li></ul>
</td></tr>
<tr><td><code id="gendata_+3A_n">n</code></td>
<td>
<p>number of data points to be generated.</p>
</td></tr>
<tr><td><code id="gendata_+3A_p">p</code></td>
<td>
<p>ambient dimension of the dataset.</p>
</td></tr>
<tr><td><code id="gendata_+3A_noise">noise</code></td>
<td>
<p>parameter to control noise level in the dataset. In many cases,
it is used for <code>sd</code> of <code>rnorm</code> used inside the function.</p>
</td></tr>
<tr><td><code id="gendata_+3A_ol">ol</code></td>
<td>
<p>percentage of outliers, i.e., n * ol outliers are added to the generated dataset.</p>
</td></tr>
<tr><td><code id="gendata_+3A_curv">curv</code></td>
<td>
<p>a parameter to control the complexity of the embedded manifold.</p>
</td></tr>
<tr><td><code id="gendata_+3A_seed">seed</code></td>
<td>
<p>random number seed.</p>
</td></tr>
<tr><td><code id="gendata_+3A_sorted">sorted</code></td>
<td>
<p>logical. If <code>TRUE</code>, the index of the generated dataset is sorted
with respect to x-axis for the ease of visualization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates various artificial datasets often used in 
manifold learning and dimension estimation researches.
For some datasets, complexity of the shape is controlled by the parameter <code>curv</code>.
The parameters <code>noise</code> and <code>outlier</code> are used for adding noise and/or 
outliers for the dataset.
</p>


<h3>Value</h3>

<p>Data matrix. For <code>ldbl</code> dataset, it outputs a list composed of
<code>x</code>: data matrix and <code>tDim</code>: true intrinsic dimension for each point.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## global intrinsic dimension estimate
x &lt;- gendata(DataName='SwissRoll')
estmle &lt;- lbmle(x=x,k1=3,k2=5)
print(estmle)

## local intrinsic dimension estimate
tmp &lt;- gendata(DataName='ldbl',n=1000)
x &lt;- tmp$x
estmada &lt;- mada(x=x,local=TRUE)
head(estmada)  ## estimated local intrinsic dimensions
head(tmp$tDim) ## true local intrinsic dimensions
</code></pre>

<hr>
<h2 id='handD'>Hand ratation data</h2><span id='topic+handD'></span>

<h3>Description</h3>

<p>Data from a QTL experiment on gravitropism in
Arabidopsis, with data on 162 recombinant inbred lines (Ler x
Cvi). The outcome is the root tip angle (in degrees) at two-minute
increments over eight hours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(handD)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>'dist'</code>.
</p>


<h3>References</h3>

<p>E. Levina and P. J. Bickel. Maximum likelihood estimation of intrinsic dimension. Advances in Neural Information Processing Systems 17, 2005.
</p>
<p>B. Kegl. Intrinsic dimension estimation using packing numbers. Advances in Neural Information Processing Systems 15, 2002.
</p>
<p>H. Hino, J. Fujiki, S. Akaho, and N. Murata, 'Local Intrinsic Dimension Estimation by Generalized Linear Modeling', Neural Computation, 2017
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(handD)
estmle &lt;- lbmle(x=handD,DM=TRUE,k1=5,k2=10)
print(estmle)
</code></pre>

<hr>
<h2 id='ider-package'>Algorithms for Estimating Intrinsic Dimensions.</h2><span id='topic+ider-package'></span><span id='topic+ider'></span>

<h3>Description</h3>

<p>This package is used for estimating intrinsic dimension of a given dataset.
</p>


<h3>Details</h3>

<p>In common data analysis situations, an observed datum is expressed by a 
p-dimensional vector. In general, the apparent data dimension p and its 
intrinsic dimension d are different. A basic assumption in many data analysis
and machine learning methods is that the intrinsic dimension is low 
even when the apparent dimension is high and the data distribution is 
constrained onto a low dimensional manifold. 
Examples of such methods include manifold learning, subspace methods, and 
visualization and dimensionality reduction methods.
The key to the success of dimensionality reduction, manifold learning and
latent variable analysis lies in the accurate estimation of the
intrinsic dimension of the dataset at hand.
This package implements a number of intrinsic dimension estimation methods.
Some functions are for estimating the global intrinsic dimension while others
are capable of estimating both local and global intrinsic dimension.
</p>
<p>The package has functions <code>corint,convU,lbmle,nni,pack</code> for estimating global
intrinsic dimensions, and <code>mada,side</code> for estimating local intrinsic dimensions. 
A data generator <code>gendata</code> is included in the packege.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>P. Grassberger and I. Procaccia. Measuring the strangeness of strange attractors. 
Physica, 1983.
</p>
<p>E. Levina and P. J. Bickel. Maximum likelihood estimation of 
intrinsic dimension. Advances in Neural Information Processing Systems 17, 2005.
</p>
<p>D. MacKay and Z. Ghahramani. <a href="http://www.inference.org.uk/mackay/dimension/">http://www.inference.org.uk/mackay/dimension/</a>
</p>
<p>K. W. Pettis et al. An intrinsic dimensionality estimator from near
neighbor information. IEEE transactions on pattern recognition and machine intelligence, 1979.
</p>
<p>M. Hein and J-Y. Audibert. Intrinsic dimensionality estimation of
submanifolds in Rd. International Conference on Machine Learning, 2005.
</p>
<p>B. Kegl. Intrinsic dimension estimation using packing numbers.
Advances in Neural Information Processing Systems 15, 2002.
</p>
<p>B. Eriksson and M. Crovella. Estimating intrinsic dimension via clustering.
IEEE Statistical Signal Processing Workshop, 2012.
</p>
<p>H. Hino, J. Fujiki, S. Akaho, and N. Murata, 'Local Intrinsic Dimension Estimation by Generalized Linear Modeling', Neural Computation, 2017
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 ## global intrinsic dimension estimate
 x &lt;- gendata(DataName='SwissRoll',n=300)
 
 x &lt;- gendata(DataName='SwissRoll',n=300,p=3,q=2)
 estcorint &lt;- corint(x=x,k1=5,k2=10)
 print(estcorint)
 
 estmle &lt;- lbmle(x=x,k1=3,k2=5)  ## estimation by mle
 print(estmle) 
 
 estnii &lt;- nni(x=x) ## estimation by nearest neighbor information
 print(estnni)
 
 estconvU &lt;- convU(x=x)  ## estimation by convergence property of U-stats
 print(estconvU)
 
estpackG &lt;- pack(x=x,greedy=TRUE)  ## estimation by the packing number method with greedy algorithm
print(estpackG)
estpackC &lt;- pack(x=x,greedy=FALSE) ## estimation by the packing number method by clutering
print(estpackC)

 ## local intrinsic dimension estimate
 tmp &lt;- gendata(DataName='ldbl',n=300)
x &lt;- tmp$x
estmada &lt;- mada(x=x,local=TRUE)
head(estmada)  ## estimated local intrinsic dimensions by mada
head(tmp$tDim) ## true local intrinsic dimensions
estside &lt;- side(x=x,local=TRUE)
head(estside) ## estimated local intrinsic dimensions by side


## End(Not run)
</code></pre>

<hr>
<h2 id='lbmle'>Maximum Likelihood Estimation of Intrinsic Dimension.</h2><span id='topic+lbmle'></span>

<h3>Description</h3>

<p><code>lbmle</code> estimate the intrinsic dimension of a given dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lbmle(x = NULL, k1 = NULL, k2 = NULL, BC = TRUE, DM = FALSE, p = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lbmle_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="lbmle_+3A_k1">k1</code></td>
<td>
<p>first k-NN parameter.</p>
</td></tr>
<tr><td><code id="lbmle_+3A_k2">k2</code></td>
<td>
<p>second k-NN parameter.</p>
</td></tr>
<tr><td><code id="lbmle_+3A_bc">BC</code></td>
<td>
<p>whether bias is corrected or not. logical.</p>
</td></tr>
<tr><td><code id="lbmle_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
<tr><td><code id="lbmle_+3A_p">p</code></td>
<td>
<p>ambient dimension used for automatically define <code>'k1'</code> and <code>'k2'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood of the rate parameter of the Poisson process, which characterize the behaviour of  
the distance from a point to another point in the given dataset, is considered, and the maximum likelihood estimator (MLE) for the intrinsic dimension is derived.
The original method proposed by Levina and Bickel contains a known bias, and it is corrected by Mackay and Ghahramani. This function implements both, with the default the bias corrected estimate.
</p>


<h3>Value</h3>

<p>Estimated global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>E. Levina and P. J. Bickel. Maximum likelihood estimation of 
intrinsic dimension. Advances in Neural Information Processing Systems 17, 2005.
</p>
<p>D. MacKay and Z. Ghahramani. <a href="http://www.inference.org.uk/mackay/dimension/">http://www.inference.org.uk/mackay/dimension/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- gendata(DataName='SwissRoll',n=300)
estmle &lt;- lbmle(x=x,k1=3,k2=5)
print(estmle)
</code></pre>

<hr>
<h2 id='mada'>Manifold-Adaptive Local Dimension Estimation.</h2><span id='topic+mada'></span>

<h3>Description</h3>

<p><code>mada</code> estimates local information dimension of given dataset based on 
the first order expansion of probability mass function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mada(x, k = NULL, comb = "average", DM = FALSE, local = FALSE, maxDim = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mada_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="mada_+3A_k">k</code></td>
<td>
<p>k-NN parameter.</p>
</td></tr>
<tr><td><code id="mada_+3A_comb">comb</code></td>
<td>
<p>'average', 'median' or 'vote' for combining local estimates when global estimate is required.</p>
</td></tr>
<tr><td><code id="mada_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
<tr><td><code id="mada_+3A_local">local</code></td>
<td>
<p>logical. If <code>TRUE</code>, a vector of local dimensions at each sample point is returned.</p>
</td></tr>
<tr><td><code id="mada_+3A_maxdim">maxDim</code></td>
<td>
<p>maximum of the candidate dimensions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variant of fractal dimension called the local information dimension is considered.
The local information dimension is estimated by using the probability mass function.
The function <code>mada</code> considers first order expansion of the probability mass around
the inspection point, and it estimates the local information dimension by using two different
radii from the inspection point.
</p>


<h3>Value</h3>

<p>Estimated local or global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>A. M. Farahmand, C. Szepesvari and J-Y. Audibert.
Manifold-adaptive dimension estimation. International Conference on Machine Learning, 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## local intrinsic dimension estimate
tmp &lt;- gendata(DataName='ldbl',n=300)
x &lt;- tmp$x
estmada &lt;- mada(x=x,local=TRUE)
head(estmada)  ## estimated local intrinsic dimensions by mada
head(tmp$tDim) ## true local intrinsic dimensions
</code></pre>

<hr>
<h2 id='nni'>Intrinsic Dimensionality Estimation from Near-Neighbor Information.</h2><span id='topic+nni'></span>

<h3>Description</h3>

<p><code>nni</code> estimates intrinsic dimension of given dataset based on the nearest-neighbor
information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nni(x, k1 = 2, k2 = 30, DM = FALSE, eps = 0.01, p = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nni_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="nni_+3A_k1">k1</code></td>
<td>
<p>first k-NN parameter.</p>
</td></tr>
<tr><td><code id="nni_+3A_k2">k2</code></td>
<td>
<p>second k-NN parameter.</p>
</td></tr>
<tr><td><code id="nni_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
<tr><td><code id="nni_+3A_eps">eps</code></td>
<td>
<p>accuracy parameter.</p>
</td></tr>
<tr><td><code id="nni_+3A_p">p</code></td>
<td>
<p>ambient dimension used for automatically define <code>'k1'</code> and <code>'k2'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First order expansion of the probability mass function is considered, then 
the distribution of the nearest-neighbor points from the inspection point is 
modeled by the Poisson distribution. The average of the nearest-distance is 
expressed by intrinsic dimension to be estimated.
</p>


<h3>Value</h3>

<p>Estimated global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>B. Kegl. Intrinsic dimension estimation using packing numbers.
Advances in Neural Information Processing Systems 15, 2002.
</p>
<p>K. W. Pettis et al. An intrinsic dimensionality estimator from near
neighbor information. IEEE transactions on pattern recognition and machine intelligence, 1979.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- gendata(DataName='SwissRoll',n=300)
estnni &lt;- nni(x=x)
print(estnni)
</code></pre>

<hr>
<h2 id='pack'>Intrinsic Dimension Estimation Using Packing Numbers.</h2><span id='topic+pack'></span>

<h3>Description</h3>

<p><code>pack</code> estimates intrinsic dimension of given dataset based on the packing number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pack(x, k1 = NULL, k2 = NULL, greedy = TRUE, eps = 0.01, DM = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pack_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="pack_+3A_k1">k1</code></td>
<td>
<p>first radius parameter. If one of <code>k1</code> or <code>k2</code> is <code>NULL</code>,
then both are automatically determined from the input data.</p>
</td></tr>
<tr><td><code id="pack_+3A_k2">k2</code></td>
<td>
<p>second radius parameter.</p>
</td></tr>
<tr><td><code id="pack_+3A_greedy">greedy</code></td>
<td>
<p>logical. If <code>TRUE</code>, then a greedy algorithm is used for 
estimating the packing number. If <code>FALSE</code>, then a hierarchical clustering
algorithm is used instead.</p>
</td></tr>
<tr><td><code id="pack_+3A_eps">eps</code></td>
<td>
<p>accuracy parameter.</p>
</td></tr>
<tr><td><code id="pack_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variant of fractal dimension called the capacity dimension is considered.
The capacity dimension is defined by using the notion of covering number, which is
hard to calculate in general. In this function, the packing number of the data
space is used as the surrogate of the covering number.
The packing number is estimated by greedy manner or by hierarchical clustering.
</p>


<h3>Value</h3>

<p>Estimated global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>B. Kegl. Intrinsic dimension estimation using packing numbers.
Advances in Neural Information Processing Systems 15, 2002.
</p>
<p>B. Eriksson and M. Crovella. Estimating intrinsic dimension via clustering.
IEEE Statistical Signal Processing Workshop, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- gendata(DataName='SwissRoll',n=300)
estpackG &lt;- pack(x=x,greedy=TRUE)  ## estimate the packing number by greedy method
print(estpackG)
estpackC &lt;- pack(x=x,greedy=FALSE) ## estimate the packing number by cluttering
print(estpackC)
</code></pre>

<hr>
<h2 id='side'>Higher-order Local Information Dimension Estimator.</h2><span id='topic+side'></span>

<h3>Description</h3>

<p><code>side</code> is a Higher-order Information Dimension Estimator, which estimates
local information dimension of given dataset based on the polynomial regression
with Poisson error structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>side(
  x,
  maxDim = 5,
  DM = FALSE,
  local = FALSE,
  method = "disc",
  comb = "average"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="side_+3A_x">x</code></td>
<td>
<p>data matrix or distance matrix given by as.matrix(dist(x)).</p>
</td></tr>
<tr><td><code id="side_+3A_maxdim">maxDim</code></td>
<td>
<p>maximum of the candidate dimensions.</p>
</td></tr>
<tr><td><code id="side_+3A_dm">DM</code></td>
<td>
<p>whether <code>'x'</code> is distance matrix or not. logical.</p>
</td></tr>
<tr><td><code id="side_+3A_local">local</code></td>
<td>
<p>logical. If <code>TRUE</code>, a vector of local dimensions at each sample point is returned.</p>
</td></tr>
<tr><td><code id="side_+3A_method">method</code></td>
<td>
<p>algorithm to estimate intrinsic dimension. 'disc' for discrite dimension estimation. 'cont' for continuous dimension estimation with MLE by Newton-method.</p>
</td></tr>
<tr><td><code id="side_+3A_comb">comb</code></td>
<td>
<p>'average', 'median' or 'vote' for combining local estimates when global estimate is required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A variant of fractal dimension called the local information dimension is considered.
The local information dimension is estimated by using the probability mass function.
The function <code>side</code> considers higher-order expansion of the probability mass around
the inspection point, and it estimates the local information dimension by fitting 
a generalized linear model with Poisson error structure and an identity link function.
There are two methods for dimension estimation: the first method tries different 
dimensions and adopt the one with maximum likelihood, while the second method directly
maximises the likelihood with respect to the intrinsic dimension. The former returns 
an integer-valued dimension estimate, and the latter returns a real-valued estimate.
The result of the former method is used as an initial value for the latter method
in numerical optimization. Slow but more accurate than <code>mada</code> in some cases.
</p>


<h3>Value</h3>

<p>Estimated local or global intrinsic dimension.
</p>


<h3>Author(s)</h3>

<p>Hideitsu Hino <a href="mailto:hideitsu.hino@gmail.com">hideitsu.hino@gmail.com</a>
</p>


<h3>References</h3>

<p>H. Hino, J. Fujiki, S. Akaho, and N. Murata, 'Local Intrinsic Dimension Estimation by Generalized Linear Modeling', Neural Computation, 2017
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## local intrinsic dimension estimate
tmp &lt;- gendata(DataName='ldbl', n=300)
x &lt;- tmp$x
set.seed(999)
idx &lt;- c(sample(which(tmp$tDim==1)[1:10],3), sample(which(tmp$tDim==2)[1:30],3))
estmada &lt;- mada(x=x[1:100,], local=TRUE)
estmada[idx]  ## estimated local intrinsic dimensions by mada
tmp$tDim[idx] ## true local intrinsic dimensions
estside &lt;- side(x=x[1:100,], local=TRUE)
estside[idx] ## estimated local intrinsic dimensions by side
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
