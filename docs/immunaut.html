<!DOCTYPE html><html lang="en"><head><title>Help for package immunaut</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {immunaut}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#auto_simon_ml'><p>Automated Machine Learning Model Building</p></a></li>
<li><a href='#calculate_tsne'><p>Perform t-Distributed Stochastic Neighbor Embedding (t-SNE)</p></a></li>
<li><a href='#castAllStringsToNA'><p>Cast All Strings to NA</p></a></li>
<li><a href='#cluster_tsne_density'><p>Perform Density-Based Clustering on t-SNE Results Using DBSCAN</p></a></li>
<li><a href='#cluster_tsne_hierarchical'><p>Perform Hierarchical Clustering on t-SNE Results</p></a></li>
<li><a href='#cluster_tsne_knn_louvain'><p>Perform KNN and Louvain Clustering on t-SNE Results</p></a></li>
<li><a href='#cluster_tsne_mclust'><p>Apply Mclust Clustering on t-SNE Results</p></a></li>
<li><a href='#find_optimal_resolution'><p>Find Optimal Resolution for Louvain Clustering</p></a></li>
<li><a href='#generate_demo_data'><p>Generate a Demo Dataset with Specified Number of Clusters and Overlap</p></a></li>
<li><a href='#generate_file_header'><p>Generate a File Header</p></a></li>
<li><a href='#immunaut'><p>Main function to carry out Immunaut Analysis</p></a></li>
<li><a href='#immunautDemo'><p>Demo data set from immunaut package.</p>
This data is used in this package examples. It consist of 4x4 feature matrix + additional dummy columns that can be used for testing.</a></li>
<li><a href='#is_var_empty'><p>Check if request variable is Empty</p></a></li>
<li><a href='#isNumeric'><p>Is Numeric</p></a></li>
<li><a href='#pick_best_cluster_modularity'><p>Pick Best Cluster by Modularity</p></a></li>
<li><a href='#pick_best_cluster_overall'><p>Pick the Best Clustering Result Based on Multiple Metrics</p></a></li>
<li><a href='#pick_best_cluster_silhouette'><p>Pick Best Cluster by Silhouette Score</p></a></li>
<li><a href='#pick_best_cluster_simon'><p>Select the Best Clustering Based on Weighted Scores: AUROC, Modularity, and Silhouette</p></a></li>
<li><a href='#plot_clustered_tsne'><p>Plot Clustered t-SNE Results</p></a></li>
<li><a href='#preProcessData'><p>Preprocess a Dataset Using Specified Methods</p></a></li>
<li><a href='#preProcessResample'><p>Pre-process and Resample Dataset</p></a></li>
<li><a href='#remove_outliers'><p>Remove Outliers Based on Cluster Information</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-24</td>
</tr>
<tr>
<td>Title:</td>
<td>Machine Learning Immunogenicity and Vaccine Response Analysis</td>
</tr>
<tr>
<td>Author:</td>
<td>Ivan Tomic <a href="https://orcid.org/0000-0003-3596-681X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  Adriana Tomic <a href="https://orcid.org/0000-0001-9885-3535"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, ctb, cph, fnd],
  Stephanie Hao <a href="https://orcid.org/0000-0002-3760-8234"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Description:</td>
<td>Used for analyzing immune responses and predicting vaccine efficacy using machine learning and advanced data processing techniques. 'Immunaut' integrates both unsupervised and supervised learning methods, managing outliers and capturing immune response variability. It performs multiple rounds of predictive model testing to identify robust immunogenicity signatures that can predict vaccine responsiveness. The platform is designed to handle high-dimensional immune data, enabling researchers to uncover immune predictors and refine personalized vaccination strategies across diverse populations.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ivan Tomic &lt;info@ivantomic.com&gt;</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-25 20:46:42 UTC; login</td>
</tr>
<tr>
<td>Imports:</td>
<td>cluster, plyr, dplyr, caret, pROC, PRROC, stats, rlang, Rtsne,
dbscan, FNN, igraph, fpc, mclust, ggplot2, grDevices,
RColorBrewer, R.utils, clusterSim, parallel, doParallel</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/atomiclaboratory/immunaut">https://github.com/atomiclaboratory/immunaut</a>,
&lt;<a href="https://atomic-lab.org&amp;gt;">https://atomic-lab.org&gt;</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/atomiclaboratory/immunaut/issues">https://github.com/atomiclaboratory/immunaut/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-25 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='auto_simon_ml'>Automated Machine Learning Model Building</h2><span id='topic+auto_simon_ml'></span>

<h3>Description</h3>

<p>This function automates the process of building machine learning models using the caret package.
It supports both binary and multi-class classification and allows users to specify a list of
machine learning algorithms to be trained on the dataset. The function splits the dataset into
training and testing sets, applies preprocessing steps, and trains models using cross-validation.
It computes relevant performance metrics such as confusion matrix, AUROC (for binary classification),
and prAUC (for binary classification).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto_simon_ml(dataset_ml, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auto_simon_ml_+3A_dataset_ml">dataset_ml</code></td>
<td>
<p>A data frame containing the dataset for training. All columns except the outcome
column should contain the features.</p>
</td></tr>
<tr><td><code id="auto_simon_ml_+3A_settings">settings</code></td>
<td>
<p>A list containing the following parameters:
</p>

<ul>
<li><p><code>outcome</code>: A string specifying the name of the outcome column in <code>dataset_ml</code>. Defaults to &quot;immunaut&quot; if not provided.
</p>
</li>
<li><p><code>excludedColumns</code>: A vector of column names to be excluded from the training data. Defaults to <code>NULL</code>.
</p>
</li>
<li><p><code>preProcessDataset</code>: A vector of preprocessing steps to be applied (e.g., <code>c("center", "scale", "medianImpute")</code>). Defaults to <code>NULL</code>.
</p>
</li>
<li><p><code>selectedPartitionSplit</code>: A numeric value specifying the proportion of data to be used for training. Must be between 0 and 1. Defaults to 0.7.
</p>
</li>
<li><p><code>selectedPackages</code>: A character vector specifying the machine learning algorithms to be used for training (e.g., <code>"nb"</code>, <code>"rpart"</code>). Defaults to <code>c("nb", "rpart")</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs preprocessing (e.g., centering, scaling, and imputation of missing values) on the dataset based on the provided settings.
It splits the data into training and testing sets using the specified partition, trains models using cross-validation, and computes performance metrics.
</p>
<p>For binary classification problems, the function calculates AUROC and prAUC. For multi-class classification, it calculates macro-averaged AUROC, though prAUC is not used.
</p>
<p>The function returns a list of trained models along with their performance metrics, including confusion matrix, variable importance, and post-resample metrics.
</p>


<h3>Value</h3>

<p>A list where each element corresponds to a trained model for one of the algorithms specified in
<code>settings$selectedPackages</code>. Each element contains:
</p>

<ul>
<li><p><code>info</code>: General information about the model, including resampling indices, problem type,
and outcome mapping.
</p>
</li>
<li><p><code>training</code>: The trained model object and variable importance.
</p>
</li>
<li><p><code>predictions</code>: Predictions on the test set, including probabilities, confusion matrix,
post-resample statistics, AUROC (for binary classification), and prAUC (for binary classification).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataset &lt;- read.csv("fc_wo_noise.csv", header = TRUE, row.names = 1)

# Generate a file header for the dataset to use in downstream analysis
file_header &lt;- generate_file_header(dataset)

settings &lt;- list(
    fileHeader = file_header,
    # Columns selected for analysis
    selectedColumns = c("ExampleColumn1", "ExampleColumn2"), 
    clusterType = "Louvain",
    removeNA = TRUE,
    preProcessDataset = c("scale", "center", "medianImpute", "corr", "zv", "nzv"),
    target_clusters_range = c(3,4),
    resolution_increments = c(0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5),
    min_modularities = c(0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9),
    pickBestClusterMethod = "Modularity",
    seed = 1337
)

result &lt;- immunaut(dataset, settings)
dataset_ml &lt;- result$dataset$original
dataset_ml$pandora_cluster &lt;- tsne_clust[[i]]$info.norm$pandora_cluster
dataset_ml &lt;- dplyr::rename(dataset_ml, immunaut = pandora_cluster)
dataset_ml &lt;- dataset_ml[, c("immunaut", setdiff(names(dataset_ml), "immunaut"))]
settings_ml &lt;- list(
    excludedColumns = c("ExampleColumn0"),
    preProcessDataset = c("scale", "center", "medianImpute", "corr", "zv", "nzv"),
    selectedPartitionSplit = split,  # Use the current partition split
    selectedPackages = c("rf", "RRF", "RRFglobal", "rpart2", "c5.0", "sparseLDA", 
    "gcvEarth", "cforest", "gaussPRPoly", "monmlp", "slda", "spls"),
    trainingTimeout = 180  # Timeout 3 minutes
)
ml_results &lt;- auto_simon_ml(dataset_ml, settings_ml)

## End(Not run)

</code></pre>

<hr>
<h2 id='calculate_tsne'>Perform t-Distributed Stochastic Neighbor Embedding (t-SNE)</h2><span id='topic+calculate_tsne'></span>

<h3>Description</h3>

<p>The <code>calculate_tsne</code> function reduces high-dimensional data into a 2-dimensional space using
t-SNE for visualization and analysis. This function dynamically adjusts t-SNE parameters
based on the characteristics of the dataset, ensuring robust handling of edge cases.
It also performs data validation, such as checking for sufficient data, removing zero variance
columns, and adjusting perplexity for optimal performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_tsne(dataset, settings, removeGroups = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate_tsne_+3A_dataset">dataset</code></td>
<td>
<p>A data frame or matrix containing the dataset to be processed. Must contain numeric columns.</p>
</td></tr>
<tr><td><code id="calculate_tsne_+3A_settings">settings</code></td>
<td>
<p>A list of settings for t-SNE, which may include <code>fileHeader</code>, <code>groupingVariables</code>, <code>perplexity</code>,
<code>max_iter</code>, <code>eta</code>, <code>theta</code>, <code>exaggeration_factor</code>, and <code>preProcessDataset</code>.</p>
</td></tr>
<tr><td><code id="calculate_tsne_+3A_removegroups">removeGroups</code></td>
<td>
<p>Logical, indicating whether to remove grouping variables before performing t-SNE. Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>info.norm</code>: The dataset with the t-SNE coordinates (<code>tsne1</code>, <code>tsne2</code>) added.
</p>
</li>
<li> <p><code>tsne.norm</code>: The output from the <code>Rtsne</code> function.
</p>
</li>
<li> <p><code>tsne_columns</code>: The names of the t-SNE columns used.
</p>
</li>
<li> <p><code>initial_dims</code>: The number of dimensions used in the initial PCA step.
</p>
</li>
<li> <p><code>perplexity</code>: The perplexity parameter used.
</p>
</li>
<li> <p><code>exaggeration_factor</code>: The exaggeration factor used.
</p>
</li>
<li> <p><code>max_iter</code>: The number of iterations used.
</p>
</li>
<li> <p><code>theta</code>: The Barnes-Hut approximation parameter used.
</p>
</li>
<li> <p><code>eta</code>: The learning rate used.
</p>
</li></ul>


<hr>
<h2 id='castAllStringsToNA'>Cast All Strings to NA</h2><span id='topic+castAllStringsToNA'></span>

<h3>Description</h3>

<p>This function processes the columns of a given dataset, converting all non-numeric string values
(including factor columns converted to character) to <code>NA</code>. It excludes specified columns from
this transformation. Columns that are numeric or of other types are left unchanged.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>castAllStringsToNA(dataset, excludeColumns = c())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="castAllStringsToNA_+3A_dataset">dataset</code></td>
<td>
<p>A data frame containing the dataset to be processed.</p>
</td></tr>
<tr><td><code id="castAllStringsToNA_+3A_excludecolumns">excludeColumns</code></td>
<td>
<p>A character vector specifying the names of columns to be excluded from processing.
These columns will not have any values converted to <code>NA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function iterates through the specified columns (excluding those listed in <code>excludeColumns</code>),
converts factors to character, and then attempts to convert character values to numeric.
Any non-numeric strings will be converted to <code>NA</code>. This is useful for cleaning datasets that may contain
mixed data types.
</p>


<h3>Value</h3>

<p>A data frame where non-numeric strings in the included columns are replaced with <code>NA</code>, and all other columns remain unchanged.
</p>

<hr>
<h2 id='cluster_tsne_density'>Perform Density-Based Clustering on t-SNE Results Using DBSCAN</h2><span id='topic+cluster_tsne_density'></span>

<h3>Description</h3>

<p>This function applies Density-Based Spatial Clustering of Applications with Noise (DBSCAN)
on t-SNE results to identify clusters and detect noise points. It dynamically calculates the
<code>MinPts</code> and <code>eps</code> parameters based on the t-SNE results and settings provided. Additionally,
the function computes silhouette scores to evaluate cluster quality and returns cluster centroids
along with cluster sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_tsne_density(info.norm, tsne.norm, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster_tsne_density_+3A_info.norm">info.norm</code></td>
<td>
<p>A data frame containing the normalized data on which the t-SNE analysis was carried out.</p>
</td></tr>
<tr><td><code id="cluster_tsne_density_+3A_tsne.norm">tsne.norm</code></td>
<td>
<p>The t-SNE results object, including the 2D t-SNE coordinates (<code>Y</code> matrix).</p>
</td></tr>
<tr><td><code id="cluster_tsne_density_+3A_settings">settings</code></td>
<td>
<p>A list of settings for the DBSCAN clustering. These settings include:
</p>

<ul>
<li> <p><code>minPtsAdjustmentFactor</code>: A factor to adjust the minimum number of points required to form a cluster (MinPts).
</p>
</li>
<li> <p><code>epsQuantile</code>: The quantile used to determine the <code>eps</code> value for DBSCAN.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first calculates <code>MinPts</code> based on the dimensionality of the t-SNE data and adjusts
it using the provided <code>minPtsAdjustmentFactor</code>. The <code>eps</code> value is determined dynamically from the
k-nearest neighbors distance using the quantile specified by <code>epsQuantile</code>. DBSCAN is then applied
to the t-SNE data, and any NA values in the cluster assignments are replaced with a predefined
outlier cluster ID (100). Finally, the function calculates cluster centroids, sizes, and silhouette
scores to evaluate cluster separation and quality.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>info.norm</code>: The input data frame with an additional <code>pandora_cluster</code> column for cluster assignments.
</p>
</li>
<li> <p><code>cluster_data</code>: A data frame with cluster centroids and labeled clusters.
</p>
</li>
<li> <p><code>avg_silhouette_score</code>: The average silhouette score, providing a measure of clustering quality.
</p>
</li></ul>


<hr>
<h2 id='cluster_tsne_hierarchical'>Perform Hierarchical Clustering on t-SNE Results</h2><span id='topic+cluster_tsne_hierarchical'></span>

<h3>Description</h3>

<p>This function applies hierarchical clustering to t-SNE results, allowing for the identification of clusters in
a reduced-dimensional space. The function also handles outliers by using DBSCAN for initial noise detection,
and provides options to include or exclude outliers from the clustering process. Silhouette scores are computed
to evaluate clustering quality, and cluster centroids are returned for visualization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_tsne_hierarchical(info.norm, tsne.norm, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster_tsne_hierarchical_+3A_info.norm">info.norm</code></td>
<td>
<p>A data frame containing the normalized data on which the t-SNE analysis was carried out.</p>
</td></tr>
<tr><td><code id="cluster_tsne_hierarchical_+3A_tsne.norm">tsne.norm</code></td>
<td>
<p>The t-SNE results object, including the 2D t-SNE coordinates (<code>Y</code> matrix).</p>
</td></tr>
<tr><td><code id="cluster_tsne_hierarchical_+3A_settings">settings</code></td>
<td>
<p>A list of settings for the clustering analysis. The settings must include:
</p>

<ul>
<li> <p><code>clustLinkage</code>: The linkage method for hierarchical clustering (e.g., &quot;ward.D2&quot;).
</p>
</li>
<li> <p><code>clustGroups</code>: The number of groups (clusters) to cut the hierarchical tree into.
</p>
</li>
<li> <p><code>distMethod</code>: The distance metric to be used (e.g., &quot;euclidean&quot;).
</p>
</li>
<li> <p><code>minPtsAdjustmentFactor</code>: A factor to adjust the minimum number of points required to form a cluster (MinPts).
</p>
</li>
<li> <p><code>epsQuantile</code>: The quantile used to determine the <code>eps</code> value for DBSCAN.
</p>
</li>
<li> <p><code>excludeOutliers</code>: A logical value indicating whether to exclude outliers detected by DBSCAN from hierarchical clustering.
</p>
</li>
<li> <p><code>pointSize</code>: A numeric value used to adjust the placement of outlier centroids.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first uses DBSCAN to detect outliers (marked as cluster &quot;100&quot;) and then applies hierarchical clustering
on the t-SNE results, either including or excluding the outliers depending on the settings. Silhouette scores are
computed to assess the quality of the clustering. Cluster centroids are calculated and returned, along with the
sizes of each cluster. Outliers, if detected, are handled separately in the final centroid calculation.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>info.norm</code>: The input data frame with an additional <code>pandora_cluster</code> column for cluster assignments.
</p>
</li>
<li> <p><code>cluster_data</code>: A data frame with cluster centroids and labeled clusters.
</p>
</li>
<li> <p><code>avg_silhouette_score</code>: The average silhouette score, providing a measure of clustering quality.
</p>
</li></ul>


<hr>
<h2 id='cluster_tsne_knn_louvain'>Perform KNN and Louvain Clustering on t-SNE Results</h2><span id='topic+cluster_tsne_knn_louvain'></span>

<h3>Description</h3>

<p>This function performs clustering on t-SNE results by first applying K-Nearest Neighbors (KNN) to construct a graph,
and then using the Louvain method for community detection. The function dynamically adjusts KNN parameters based on the
size of the dataset, ensuring scalability. Additionally, it computes the silhouette score to evaluate cluster quality
and calculates cluster centroids for visualization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_tsne_knn_louvain(
  info.norm,
  tsne.norm,
  settings,
  resolution_increment = 0.1,
  min_modularity = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster_tsne_knn_louvain_+3A_info.norm">info.norm</code></td>
<td>
<p>A data frame containing the normalized data on which the t-SNE analysis was carried out.</p>
</td></tr>
<tr><td><code id="cluster_tsne_knn_louvain_+3A_tsne.norm">tsne.norm</code></td>
<td>
<p>A list containing the t-SNE results, including a 2D t-SNE coordinate matrix in the <code>Y</code> element.</p>
</td></tr>
<tr><td><code id="cluster_tsne_knn_louvain_+3A_settings">settings</code></td>
<td>
<p>A list of settings for the analysis, including:
</p>

<ul>
<li> <p><code>knn_clusters</code>: The number of nearest neighbors to use for KNN (default: 250).
</p>
</li>
<li> <p><code>target_clusters_range</code>: A numeric vector specifying the target range for the number of clusters.
</p>
</li>
<li> <p><code>start_resolution</code>: The starting resolution for Louvain clustering.
</p>
</li>
<li> <p><code>end_resolution</code>: The maximum resolution to test.
</p>
</li>
<li> <p><code>min_modularity</code>: The minimum acceptable modularity for valid clusterings.
</p>
</li></ul>
</td></tr>
<tr><td><code id="cluster_tsne_knn_louvain_+3A_resolution_increment">resolution_increment</code></td>
<td>
<p>The step size for incrementing the Louvain clustering resolution. Defaults to 0.1.</p>
</td></tr>
<tr><td><code id="cluster_tsne_knn_louvain_+3A_min_modularity">min_modularity</code></td>
<td>
<p>The minimum modularity score allowed for a valid clustering. Defaults to 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function begins by constructing a KNN graph from the t-SNE results, then applies the Louvain algorithm for
community detection. The KNN parameter is dynamically adjusted based on the size of the dataset to ensure scalability.
The function evaluates clustering quality using silhouette scores and calculates cluster centroids for visualization.
NA cluster assignments are handled by assigning them to a separate cluster labeled as &quot;100.&quot;
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>

<ul>
<li> <p><code>info.norm</code>: The input data frame with an additional <code>pandora_cluster</code> column for cluster assignments.
</p>
</li>
<li> <p><code>cluster_data</code>: A data frame containing cluster centroids and cluster labels.
</p>
</li>
<li> <p><code>avg_silhouette_score</code>: The average silhouette score, a measure of clustering quality.
</p>
</li>
<li> <p><code>modularity</code>: The modularity score of the Louvain clustering.
</p>
</li>
<li> <p><code>num_clusters</code>: The number of clusters found.
</p>
</li></ul>


<hr>
<h2 id='cluster_tsne_mclust'>Apply Mclust Clustering on t-SNE Results</h2><span id='topic+cluster_tsne_mclust'></span>

<h3>Description</h3>

<p>This function performs Mclust clustering on the 2D t-SNE results, which are derived from high-dimensional data.
It includes an initial outlier detection step using DBSCAN, and the user can specify whether to exclude outliers
from the clustering process. Silhouette scores are computed to evaluate the quality of the clustering, and cluster
centroids are returned for visualization, with outliers handled separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_tsne_mclust(info.norm, tsne.norm, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cluster_tsne_mclust_+3A_info.norm">info.norm</code></td>
<td>
<p>A data frame containing the normalized data on which the t-SNE analysis was carried out.</p>
</td></tr>
<tr><td><code id="cluster_tsne_mclust_+3A_tsne.norm">tsne.norm</code></td>
<td>
<p>The t-SNE results object, including the 2D t-SNE coordinates (<code>Y</code> matrix).</p>
</td></tr>
<tr><td><code id="cluster_tsne_mclust_+3A_settings">settings</code></td>
<td>
<p>A list of settings for the clustering analysis, including:
</p>

<ul>
<li> <p><code>clustGroups</code>: The number of groups (clusters) for Mclust to fit.
</p>
</li>
<li> <p><code>minPtsAdjustmentFactor</code>: A factor to adjust the minimum number of points required to form a cluster (MinPts) in DBSCAN.
</p>
</li>
<li> <p><code>epsQuantile</code>: The quantile used to determine the <code>eps</code> value for DBSCAN.
</p>
</li>
<li> <p><code>excludeOutliers</code>: A logical value indicating whether to exclude outliers detected by DBSCAN from the Mclust clustering.
</p>
</li>
<li> <p><code>pointSize</code>: A numeric value used to adjust the placement of outlier centroids.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first uses DBSCAN to detect outliers (marked as cluster &quot;100&quot;) and then applies Mclust clustering on the t-SNE
results. Outliers can be either included or excluded from the clustering, depending on the settings. Silhouette scores are
calculated to assess the quality of the clustering. Cluster centroids are returned, along with the sizes of each cluster,
and outliers are handled separately in the centroid calculation.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>info.norm</code>: The input data frame with an additional <code>pandora_cluster</code> column for cluster assignments.
</p>
</li>
<li> <p><code>cluster_data</code>: A data frame with cluster centroids and labeled clusters.
</p>
</li>
<li> <p><code>avg_silhouette_score</code>: The average silhouette score, providing a measure of clustering quality.
</p>
</li></ul>


<hr>
<h2 id='find_optimal_resolution'>Find Optimal Resolution for Louvain Clustering</h2><span id='topic+find_optimal_resolution'></span>

<h3>Description</h3>

<p>This function iterates over a range of resolution values to find the optimal resolution for
Louvain clustering, balancing the number of clusters and modularity. It aims to identify a
resolution that results in a reasonable number of clusters while maintaining a high modularity score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_optimal_resolution(
  graph,
  start_resolution = 0.1,
  end_resolution = 10,
  resolution_increment = 0.1,
  min_modularity = 0.3,
  target_clusters_range = c(3, 6)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_optimal_resolution_+3A_graph">graph</code></td>
<td>
<p>An <code>igraph</code> object representing the graph to be clustered.</p>
</td></tr>
<tr><td><code id="find_optimal_resolution_+3A_start_resolution">start_resolution</code></td>
<td>
<p>Numeric. The starting resolution for the Louvain algorithm. Default is 0.1.</p>
</td></tr>
<tr><td><code id="find_optimal_resolution_+3A_end_resolution">end_resolution</code></td>
<td>
<p>Numeric. The maximum resolution to test. Default is 10.</p>
</td></tr>
<tr><td><code id="find_optimal_resolution_+3A_resolution_increment">resolution_increment</code></td>
<td>
<p>Numeric. The increment to adjust the resolution at each step. Default is 0.1.</p>
</td></tr>
<tr><td><code id="find_optimal_resolution_+3A_min_modularity">min_modularity</code></td>
<td>
<p>Numeric. The minimum acceptable modularity for valid clusterings. Default is 0.3.</p>
</td></tr>
<tr><td><code id="find_optimal_resolution_+3A_target_clusters_range">target_clusters_range</code></td>
<td>
<p>Numeric vector of length 2. Specifies the acceptable range for the number of clusters (inclusive). Default is <code>c(3, 6)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs Louvain clustering at different resolutions, starting from <code>start_resolution</code> and
ending at <code>end_resolution</code>, incrementing by <code>resolution_increment</code> at each step. At each resolution,
the function calculates the number of clusters and modularity. The results are filtered to select those
where modularity exceeds <code>min_modularity</code> and the number of clusters falls within the specified range
<code>target_clusters_range</code>. The optimal resolution is chosen based on the most frequent number of clusters and
the median resolution that satisfies these criteria.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>selected</code></td>
<td>
<p>A list with the optimal resolution, best modularity, and number of clusters.</p>
</td></tr>
<tr><td><code>frequent_clusters_results</code></td>
<td>
<p>A data frame containing results for resolutions that yielded the most frequent number of clusters.</p>
</td></tr>
<tr><td><code>all_results</code></td>
<td>
<p>A data frame with the resolution, number of clusters, and modularity for all tested resolutions.</p>
</td></tr>
</table>

<hr>
<h2 id='generate_demo_data'>Generate a Demo Dataset with Specified Number of Clusters and Overlap</h2><span id='topic+generate_demo_data'></span>

<h3>Description</h3>

<p>This function generates a demo dataset with a specified number of subjects, features,
and desired number of clusters, ensuring that the generated clusters are not too far apart
and have some degree of overlap to simulate real-world data.
The generated dataset includes demographic information (<code>outcome</code>, <code>age</code>, and <code>gender</code>),
as well as numeric features with a specified probability of missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_demo_data(
  n_subjects = 1000,
  n_features = 200,
  missing_prob = 0.1,
  desired_number_clusters = 3,
  cluster_overlap_sd = 15
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_demo_data_+3A_n_subjects">n_subjects</code></td>
<td>
<p>Integer. The number of subjects (rows) to generate. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="generate_demo_data_+3A_n_features">n_features</code></td>
<td>
<p>Integer. The number of features (columns) to generate. Defaults to 200.</p>
</td></tr>
<tr><td><code id="generate_demo_data_+3A_missing_prob">missing_prob</code></td>
<td>
<p>Numeric. The probability of introducing missing values (NA) in the feature columns. Defaults to 0.1.</p>
</td></tr>
<tr><td><code id="generate_demo_data_+3A_desired_number_clusters">desired_number_clusters</code></td>
<td>
<p>Integer. The approximate number of clusters to generate in the feature space. Defaults to 3.</p>
</td></tr>
<tr><td><code id="generate_demo_data_+3A_cluster_overlap_sd">cluster_overlap_sd</code></td>
<td>
<p>Numeric. The standard deviation to control cluster overlap. Defaults to 15 for more overlap.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates <code>n_features</code> numeric columns based on Gaussian clusters
with some overlap between clusters to simulate more realistic data. Missing values are
introduced in each feature column based on the <code>missing_prob</code>.
</p>


<h3>Value</h3>

<p>A data frame containing the generated demo dataset, with columns:
</p>

<ul>
<li> <p><code>outcome</code>: A categorical variable with values &quot;low&quot; or &quot;high&quot;.
</p>
</li>
<li> <p><code>age</code>: A numeric variable representing the age of the subject (range 18-90).
</p>
</li>
<li> <p><code>gender</code>: A categorical variable with values &quot;male&quot; or &quot;female&quot;.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;Feature X&#8288;</code>: Numeric feature columns with random values and some missing data.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Generate a demo dataset with 1000 subjects, 200 features, and 3 clusters
demo_data &lt;- generate_demo_data(n_subjects = 1000, n_features = 200, 
                                desired_number_clusters = 3, 
                                cluster_overlap_sd = 15, missing_prob = 0.1)

# View the first few rows of the dataset
head(demo_data)


</code></pre>

<hr>
<h2 id='generate_file_header'>Generate a File Header</h2><span id='topic+generate_file_header'></span>

<h3>Description</h3>

<p>This function generates a fileHeader object from a given data frame
which includes original names and remapped names of the data frame columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_file_header(dataset)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_file_header_+3A_dataset">dataset</code></td>
<td>
<p>The input data frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing original and remapped column names.
</p>

<hr>
<h2 id='immunaut'>Main function to carry out Immunaut Analysis</h2><span id='topic+immunaut'></span>

<h3>Description</h3>

<p>This function performs clustering and dimensionality reduction analysis on a dataset using user-defined settings.
It handles various preprocessing steps, dimensionality reduction via t-SNE, multiple clustering methods, and
generates associated plots based on user-defined or default settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>immunaut(dataset, settings = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="immunaut_+3A_dataset">dataset</code></td>
<td>
<p>A data frame representing the dataset on which the analysis will be performed. The dataset must
contain numeric columns for dimensionality reduction and clustering.</p>
</td></tr>
<tr><td><code id="immunaut_+3A_settings">settings</code></td>
<td>
<p>A named list containing settings for the analysis. If NULL, defaults will be used. The settings list may contain:
</p>

<dl>
<dt>fileHeader</dt><dd><p>A data frame mapping the original column names to remapped column names. Used for t-SNE input preparation.</p>
</dd>
<dt>selectedColumns</dt><dd><p>Character vector of columns to be used for the analysis. Defaults to NULL.</p>
</dd>
<dt>cutOffColumnSize</dt><dd><p>Numeric. The maximum size of the dataset in terms of columns. Defaults to 50,000.</p>
</dd>
<dt>excludedColumns</dt><dd><p>Character vector of columns to exclude from the analysis. Defaults to NULL.</p>
</dd>
<dt>groupingVariables</dt><dd><p>Character vector of columns to use for grouping the data during analysis. Defaults to NULL.</p>
</dd>
<dt>colorVariables</dt><dd><p>Character vector of columns to use for coloring in the plots. Defaults to NULL.</p>
</dd>
<dt>preProcessDataset</dt><dd><p>Character vector of preprocessing methods to apply (e.g., scaling, normalization). Defaults to NULL.</p>
</dd>
<dt>fontSize</dt><dd><p>Numeric. Font size for plots. Defaults to 12.</p>
</dd>
<dt>pointSize</dt><dd><p>Numeric. Size of points in plots. Defaults to 1.5.</p>
</dd>
<dt>theme</dt><dd><p>Character. The ggplot2 theme to use (e.g., &quot;theme_gray&quot;). Defaults to &quot;theme_gray&quot;.</p>
</dd>
<dt>colorPalette</dt><dd><p>Character. Color palette for plots (e.g., &quot;RdPu&quot;). Defaults to &quot;RdPu&quot;.</p>
</dd>
<dt>aspect_ratio</dt><dd><p>Numeric. The aspect ratio of plots. Defaults to 1.</p>
</dd>
<dt>clusterType</dt><dd><p>Character. The clustering method to use. Options are &quot;Louvain&quot;, &quot;Hierarchical&quot;, &quot;Mclust&quot;, &quot;Density&quot;. Defaults to &quot;Louvain&quot;.</p>
</dd>
<dt>removeNA</dt><dd><p>Logical. Whether to remove rows with NA values. Defaults to FALSE.</p>
</dd>
<dt>datasetAnalysisGrouped</dt><dd><p>Logical. Whether to perform grouped dataset analysis. Defaults to FALSE.</p>
</dd>
<dt>plot_size</dt><dd><p>Numeric. The size of the plot. Defaults to 12.</p>
</dd>
<dt>knn_clusters</dt><dd><p>Numeric. The number of clusters for KNN-based clustering. Defaults to 250.</p>
</dd>
<dt>perplexity</dt><dd><p>Numeric. The perplexity parameter for t-SNE. Defaults to NULL (automatically determined).</p>
</dd>
<dt>exaggeration_factor</dt><dd><p>Numeric. The exaggeration factor for t-SNE. Defaults to NULL.</p>
</dd>
<dt>max_iter</dt><dd><p>Numeric. The maximum number of iterations for t-SNE. Defaults to NULL.</p>
</dd>
<dt>theta</dt><dd><p>Numeric. The Barnes-Hut approximation parameter for t-SNE. Defaults to NULL.</p>
</dd>
<dt>eta</dt><dd><p>Numeric. The learning rate for t-SNE. Defaults to NULL.</p>
</dd>
<dt>clustLinkage</dt><dd><p>Character. Linkage method for hierarchical clustering. Defaults to &quot;ward.D2&quot;.</p>
</dd>
<dt>clustGroups</dt><dd><p>Numeric. The number of groups for hierarchical clustering. Defaults to 9.</p>
</dd>
<dt>distMethod</dt><dd><p>Character. Distance metric for clustering. Defaults to &quot;euclidean&quot;.</p>
</dd>
<dt>minPtsAdjustmentFactor</dt><dd><p>Numeric. Adjustment factor for the minimum points in DBSCAN clustering. Defaults to 1.</p>
</dd>
<dt>epsQuantile</dt><dd><p>Numeric. Quantile to compute the epsilon parameter for DBSCAN clustering. Defaults to 0.9.</p>
</dd>
<dt>assignOutliers</dt><dd><p>Logical. Whether to assign outliers in the clustering step. Defaults to TRUE.</p>
</dd>
<dt>excludeOutliers</dt><dd><p>Logical. Whether to exclude outliers from clustering. Defaults to TRUE.</p>
</dd>
<dt>legendPosition</dt><dd><p>Character. Position of the legend in plots (e.g., &quot;right&quot;, &quot;bottom&quot;). Defaults to &quot;right&quot;.</p>
</dd>
<dt>datasetAnalysisClustLinkage</dt><dd><p>Character. Linkage method for dataset-level analysis. Defaults to &quot;ward.D2&quot;.</p>
</dd>
<dt>datasetAnalysisType</dt><dd><p>Character. Type of dataset analysis (e.g., &quot;heatmap&quot;). Defaults to &quot;heatmap&quot;.</p>
</dd>
<dt>datasetAnalysisRemoveOutliersDownstream</dt><dd><p>Logical. Whether to remove outliers during downstream dataset analysis (e.g., machine learning). Defaults to FALSE.</p>
</dd>
<dt>datasetAnalysisSortColumn</dt><dd><p>Character. The column used to sort dataset analysis results. Defaults to &quot;cluster&quot;.</p>
</dd>
<dt>datasetAnalysisClustOrdering</dt><dd><p>Numeric. The order of clusters for analysis. Defaults to 1.</p>
</dd>
<dt>anyNAValues</dt><dd><p>Logical. Whether the dataset contains NA values. Defaults to FALSE.</p>
</dd>
<dt>categoricalVariables</dt><dd><p>Logical. Whether the dataset contains categorical variables. Defaults to FALSE.</p>
</dd>
<dt>resolution_increments</dt><dd><p>Numeric vector. The resolution increments to be used for Louvain clustering. Defaults to <code>c(0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5)</code>.</p>
</dd>
<dt>min_modularities</dt><dd><p>Numeric vector. The minimum modularities to test for clustering. Defaults to <code>c(0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9)</code>.</p>
</dd>
<dt>target_clusters_range</dt><dd><p>Numeric vector. The range of acceptable clusters to identify. Defaults to <code>c(3, 6)</code>.</p>
</dd>
<dt>pickBestClusterMethod</dt><dd><p>Character. The method to use for picking the best clustering result (&quot;Modularity&quot;, &quot;Silhouette&quot;, or &quot;SIMON&quot;). Defaults to &quot;Modularity&quot;.</p>
</dd>
<dt>weights</dt><dd><p>List. Weights for evaluating clusters based on <code>AUROC</code>, <code>modularity</code>, and <code>silhouette</code>. Defaults to <code>list(AUROC = 0.5, modularity = 0.3, silhouette = 0.2)</code>. These weights are applied to help choose the most relevant clusters based on user goals:
</p>

<dl>
<dt><code>AUROC</code></dt><dd><p>Weight for predictive performance (area under the receiver operating characteristic curve). Prioritize this when predictive accuracy is the main goal. For predictive analysis, a recommended configuration could be <code>list(AUROC = 0.8, modularity = 0.1, silhouette = 0.1)</code>.</p>
</dd>
<dt><code>modularity</code></dt><dd><p>Weight for modularity score, which indicates the strength of clustering. Higher modularity suggests that clusters are well-separated. To prioritize well-separated clusters, use a configuration like <code>list(AUROC = 0.4, modularity = 0.4, silhouette = 0.2)</code>.</p>
</dd>
<dt><code>silhouette</code></dt><dd><p>Weight for silhouette score, a measure of cohesion within clusters. Useful when cluster cohesion and interpretability are desired. For balanced clusters, a suggested configuration is <code>list(AUROC = 0.4, modularity = 0.3, silhouette = 0.3)</code>.</p>
</dd>
</dl>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>

<ul>
<li> <p><code>tsne_calc</code>: The t-SNE results object.
</p>
</li>
<li> <p><code>tsne_clust</code>: The clustering results.
</p>
</li>
<li> <p><code>dataset</code>: A list containing the original dataset, the preprocessed dataset, and a dataset with machine learning-ready data.
</p>
</li>
<li> <p><code>clusters</code>: The final cluster assignments.
</p>
</li>
<li> <p><code>settings</code>: The list of settings used for the analysis.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
  data &lt;- matrix(runif(2000), ncol=20)
  settings &lt;- list(clusterType = "Louvain", 
  resolution_increments = c(0.05, 0.1), 
  min_modularities = c(0.3, 0.5))
  result &lt;- immunaut(data.frame(data), settings)
  print(result$clusters)


</code></pre>

<hr>
<h2 id='immunautDemo'>Demo data set from immunaut package.
This data is used in this package examples. It consist of 4x4 feature matrix + additional dummy columns that can be used for testing.</h2><span id='topic+immunautDemo'></span>

<h3>Description</h3>

<p>Demo data set from immunaut package.
This data is used in this package examples. It consist of 4x4 feature matrix + additional dummy columns that can be used for testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(immunautDemo)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 4 rows and 7 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
	data(immunautDemo)
	## define settings variable
	settings &lt;- list()
	settings$fileHeader &lt;- generate_file_header(immunautDemo)
	# ... and other settings
	results &lt;- immunaut(immunautDemo, settings)

## End(Not run)

</code></pre>

<hr>
<h2 id='is_var_empty'>Check if request variable is Empty</h2><span id='topic+is_var_empty'></span>

<h3>Description</h3>

<p>Checks if the given variable is empty and optionally logs the variable name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_var_empty(variable)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_var_empty_+3A_variable">variable</code></td>
<td>
<p>The variable to check.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>boolean TRUE if the variable is considered empty, FALSE otherwise.
</p>

<hr>
<h2 id='isNumeric'>Is Numeric</h2><span id='topic+isNumeric'></span>

<h3>Description</h3>

<p>Determines whether a variable is a number or a numeric string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isNumeric(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isNumeric_+3A_x">x</code></td>
<td>
<p>Variable to be checked</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Logical indicating whether x is numeric and non-NA
</p>

<hr>
<h2 id='pick_best_cluster_modularity'>Pick Best Cluster by Modularity</h2><span id='topic+pick_best_cluster_modularity'></span>

<h3>Description</h3>

<p>This function selects the best cluster from a list of clustering results
based on the highest modularity score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pick_best_cluster_modularity(tsne_clust)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pick_best_cluster_modularity_+3A_tsne_clust">tsne_clust</code></td>
<td>
<p>A list of clustering results where each element contains clustering information,
including the modularity score.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function iterates over a list of clustering results (<code>tsne_clust</code>) and
selects the cluster with the highest modularity score. If no clusters are valid or
the <code>tsne_clust</code> list is empty, the function will stop and return an error.
</p>


<h3>Value</h3>

<p>Returns the clustering result with the highest modularity score.
</p>

<hr>
<h2 id='pick_best_cluster_overall'>Pick the Best Clustering Result Based on Multiple Metrics</h2><span id='topic+pick_best_cluster_overall'></span>

<h3>Description</h3>

<p>This function evaluates multiple clustering results based on various metrics such as modularity, silhouette score,
Davies-Bouldin Index (DBI), and Calinski-Harabasz Index (CH). It normalizes the scores across all metrics,
calculates a combined score for each clustering result, and selects the best clustering result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pick_best_cluster_overall(tsne_clust, tsne_calc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pick_best_cluster_overall_+3A_tsne_clust">tsne_clust</code></td>
<td>
<p>A list of clustering results. Each result should contain metrics such as modularity, silhouette score,
and cluster assignments for the dataset.</p>
</td></tr>
<tr><td><code id="pick_best_cluster_overall_+3A_tsne_calc">tsne_calc</code></td>
<td>
<p>A list containing the t-SNE results. It includes the t-SNE coordinates of the dataset used for clustering.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes four different metrics for each clustering result:
</p>

<ul>
<li><p> Modularity: A measure of the quality of the division of the network into clusters.
</p>
</li>
<li><p> Silhouette score: A measure of how similar data points are to their own cluster compared to other clusters.
</p>
</li>
<li><p> Davies-Bouldin Index (DBI): A ratio of within-cluster distances to between-cluster distances, with lower values being better.
</p>
</li>
<li><p> Calinski-Harabasz Index (CH): The ratio of the sum of between-cluster dispersion to within-cluster dispersion, with higher values being better.
</p>
</li></ul>

<p>The scores for each metric are normalized between 0 and 1, and an overall score is calculated for each clustering result. The clustering result with the highest overall score is selected as the best.
</p>


<h3>Value</h3>

<p>The clustering result with the highest combined score based on modularity, silhouette score,
Davies-Bouldin Index (DBI), and Calinski-Harabasz Index (CH).
</p>

<hr>
<h2 id='pick_best_cluster_silhouette'>Pick Best Cluster by Silhouette Score</h2><span id='topic+pick_best_cluster_silhouette'></span>

<h3>Description</h3>

<p>This function selects the best cluster from a list of clustering results
based on the highest average silhouette score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pick_best_cluster_silhouette(tsne_clust)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pick_best_cluster_silhouette_+3A_tsne_clust">tsne_clust</code></td>
<td>
<p>A list of clustering results where each element contains clustering information,
including the average silhouette score.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function iterates over a list of clustering results (<code>tsne_clust</code>) and
selects the cluster with the highest average silhouette score. If no clusters are valid or
the <code>tsne_clust</code> list is empty, the function will stop and return an error.
</p>


<h3>Value</h3>

<p>Returns the clustering result with the highest average silhouette score.
</p>

<hr>
<h2 id='pick_best_cluster_simon'>Select the Best Clustering Based on Weighted Scores: AUROC, Modularity, and Silhouette</h2><span id='topic+pick_best_cluster_simon'></span>

<h3>Description</h3>

<p>This function selects the optimal clustering configuration from a list of <code>t-SNE</code> clustering results
by evaluating each configuration's AUROC, modularity, and silhouette scores. These scores are combined
using a weighted average, allowing for a more comprehensive assessment of each configuration's relevance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pick_best_cluster_simon(dataset, tsne_clust, tsne_calc, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pick_best_cluster_simon_+3A_dataset">dataset</code></td>
<td>
<p>A data frame representing the original dataset, where each observation will be assigned cluster labels
from each clustering configuration in <code>tsne_clust</code>.</p>
</td></tr>
<tr><td><code id="pick_best_cluster_simon_+3A_tsne_clust">tsne_clust</code></td>
<td>
<p>A list of clustering results from different t-SNE configurations, with each element containing
<code>pandora_cluster</code> assignments and clustering information.</p>
</td></tr>
<tr><td><code id="pick_best_cluster_simon_+3A_tsne_calc">tsne_calc</code></td>
<td>
<p>An object containing t-SNE results on <code>dataset</code>.</p>
</td></tr>
<tr><td><code id="pick_best_cluster_simon_+3A_settings">settings</code></td>
<td>
<p>A list of settings for machine learning model training and scoring, including:
</p>

<dl>
<dt>excludedColumns</dt><dd><p>A character vector of columns to exclude from the analysis.</p>
</dd>
<dt>preProcessDataset</dt><dd><p>A character vector of preprocessing steps (e.g., scaling, centering).</p>
</dd>
<dt>selectedPartitionSplit</dt><dd><p>Numeric; the partition split ratio for train/test splits.</p>
</dd>
<dt>selectedPackages</dt><dd><p>Character vector of machine learning models to train.</p>
</dd>
<dt>trainingTimeout</dt><dd><p>Numeric; time limit (in seconds) for training each model.</p>
</dd>
<dt>weights</dt><dd><p>A list of weights for scoring criteria: <code>weights$AUROC</code>, <code>weights$modularity</code>,
and <code>weights$silhouette</code> (default is 0.4, 0.3, and 0.3 respectively).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>For each clustering configuration in <code>tsne_clust</code>, this function:
</p>

<ol>
<li><p> Assigns cluster labels to the dataset.
</p>
</li>
<li><p> Trains machine learning models specified in <code>settings</code> on the dataset with cluster labels.
</p>
</li>
<li><p> Evaluates each model based on AUROC, modularity, and silhouette scores.
</p>
</li>
<li><p> Selects the clustering configuration with the highest weighted average score as the best clustering result.
</p>
</li></ol>



<h3>Value</h3>

<p>A list containing the best clustering configuration (with the highest weighted score) and its associated information.
</p>

<hr>
<h2 id='plot_clustered_tsne'>Plot Clustered t-SNE Results</h2><span id='topic+plot_clustered_tsne'></span>

<h3>Description</h3>

<p>This function generates a t-SNE plot with cluster assignments using consistent color mappings.
It includes options for plotting points based on their t-SNE coordinates and adding cluster
labels at the cluster centroids. The plot is saved as an SVG file in a temporary directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_clustered_tsne(info.norm, cluster_data, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_clustered_tsne_+3A_info.norm">info.norm</code></td>
<td>
<p>A data frame containing t-SNE coordinates (<code>tsne1</code>, <code>tsne2</code>) and cluster assignments (<code>pandora_cluster</code>) for each point.</p>
</td></tr>
<tr><td><code id="plot_clustered_tsne_+3A_cluster_data">cluster_data</code></td>
<td>
<p>A data frame containing the cluster centroids and labels, with columns <code>tsne1</code>, <code>tsne2</code>, <code>label</code>, and <code>pandora_cluster</code>.</p>
</td></tr>
<tr><td><code id="plot_clustered_tsne_+3A_settings">settings</code></td>
<td>
<p>A list of settings for the plot, including:
</p>

<ul>
<li> <p><code>theme</code>: The ggplot2 theme to use (e.g., <code>"theme_classic"</code>).
</p>
</li>
<li> <p><code>colorPalette</code>: The color palette to use for clusters (e.g., <code>"RdPu"</code>).
</p>
</li>
<li> <p><code>pointSize</code>: The size of points in the plot.
</p>
</li>
<li> <p><code>fontSize</code>: The font size used in the plot.
</p>
</li>
<li> <p><code>legendPosition</code>: The position of the legend (e.g., <code>"right"</code>).
</p>
</li>
<li> <p><code>plot_size</code>: The size of the plot.
</p>
</li>
<li> <p><code>aspect_ratio</code>: The aspect ratio of the plot.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object representing the clustered t-SNE plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example usage
plot &lt;- plot_clustered_tsne(info.norm, cluster_data, settings)
print(plot)

## End(Not run)
</code></pre>

<hr>
<h2 id='preProcessData'>Preprocess a Dataset Using Specified Methods</h2><span id='topic+preProcessData'></span>

<h3>Description</h3>

<p>This function preprocesses a dataset by applying a variety of transformation methods,
such as centering, scaling, or imputation. Users can also specify columns to exclude
from preprocessing. The function supports a variety of preprocessing methods, including
dimensionality reduction and imputation techniques, and ensures proper method application order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preProcessData(
  data,
  outcome,
  excludeClasses,
  methods = c("center", "scale"),
  settings
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preProcessData_+3A_data">data</code></td>
<td>
<p>A data frame or matrix representing the dataset to be preprocessed.</p>
</td></tr>
<tr><td><code id="preProcessData_+3A_outcome">outcome</code></td>
<td>
<p>A character string representing the outcome variable, if any,
for outcome-based transformations.</p>
</td></tr>
<tr><td><code id="preProcessData_+3A_excludeclasses">excludeClasses</code></td>
<td>
<p>A character vector specifying the column names to exclude from
preprocessing. Default is <code>NULL</code>, meaning all columns are included in the preprocessing.</p>
</td></tr>
<tr><td><code id="preProcessData_+3A_methods">methods</code></td>
<td>
<p>A character vector specifying the preprocessing methods to apply.
Default methods are <code>c("center", "scale")</code>. Available methods include:
- <code>"medianImpute"</code>: Impute missing values with the median.
- <code>"bagImpute"</code>: Impute missing values using bootstrap aggregation.
- <code>"knnImpute"</code>: Impute missing values using k-nearest neighbors.
- <code>"center"</code>: Subtract the mean from each feature.
- <code>"scale"</code>: Divide features by their standard deviation.
- <code>"pca"</code>: Principal Component Analysis for dimensionality reduction.
- Other methods such as <code>"BoxCox"</code>, <code>"YeoJohnson"</code>, <code>"range"</code>, etc.</p>
</td></tr>
<tr><td><code id="preProcessData_+3A_settings">settings</code></td>
<td>
<p>A named list containing settings for the analysis. If NULL, defaults will be used. The settings list may contain:
- <code>seed</code>: An integer seed value for reproducibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function applies various transformations to the dataset as specified by the user. It ensures
that methods are applied in the correct order to maintain data integrity and consistency. If fewer
than two columns remain after excluding specified columns, the function halts and returns <code>NULL</code>.
The function also handles categorical columns by skipping their transformation. Users can also
specify outcome variables for specialized preprocessing.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>processedMat</code>: The preprocessed dataset.
</p>
</li>
<li> <p><code>preprocessParams</code>: The preprocessing parameters that were applied to the dataset.
</p>
</li></ul>


<hr>
<h2 id='preProcessResample'>Pre-process and Resample Dataset</h2><span id='topic+preProcessResample'></span>

<h3>Description</h3>

<p>This function applies pre-processing transformations to the dataset, then resamples it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preProcessResample(
  datasetData,
  preProcess,
  selectedOutcomeColumns,
  outcome_and_classes,
  settings
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="preProcessResample_+3A_datasetdata">datasetData</code></td>
<td>
<p>Dataframe to be pre-processed</p>
</td></tr>
<tr><td><code id="preProcessResample_+3A_preprocess">preProcess</code></td>
<td>
<p>Vector of pre-processing methods to apply</p>
</td></tr>
<tr><td><code id="preProcessResample_+3A_selectedoutcomecolumns">selectedOutcomeColumns</code></td>
<td>
<p>Character vector of outcome columns</p>
</td></tr>
<tr><td><code id="preProcessResample_+3A_outcome_and_classes">outcome_and_classes</code></td>
<td>
<p>List of outcomes and their classes</p>
</td></tr>
<tr><td><code id="preProcessResample_+3A_settings">settings</code></td>
<td>
<p>A named list containing settings for the analysis. If NULL, defaults will be used. The settings list may contain:
- <code>seed</code>: An integer seed value for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the pre-processing mapping and the processed dataset
</p>

<hr>
<h2 id='remove_outliers'>Remove Outliers Based on Cluster Information</h2><span id='topic+remove_outliers'></span>

<h3>Description</h3>

<p>The <code>remove_outliers</code> function removes rows from a dataset based on the presence
of outliers marked by a specific cluster ID (typically 100) in the <code>pandora_cluster</code> column.
This function is meant to be used internally during downstream dataset analysis
to filter out data points that have been identified as outliers during clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_outliers(dataset, settings)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remove_outliers_+3A_dataset">dataset</code></td>
<td>
<p>A data frame that includes clustering results, particularly a <code>pandora_cluster</code> column.</p>
</td></tr>
<tr><td><code id="remove_outliers_+3A_settings">settings</code></td>
<td>
<p>A list of settings. Must contain the logical value <code>datasetAnalysisRemoveOutliersDownstream</code>.
If <code>datasetAnalysisRemoveOutliersDownstream</code> is TRUE, outliers (rows where <code>pandora_cluster == 100</code>)
will be removed from the dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A filtered data frame with outliers removed if applicable.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
