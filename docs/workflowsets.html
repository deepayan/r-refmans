<!DOCTYPE html><html><head><title>Help for package workflowsets</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {workflowsets}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as_workflow_set'><p>Convert existing objects to a workflow set</p></a></li>
<li><a href='#autoplot.workflow_set'><p>Plot the results of a workflow set</p></a></li>
<li><a href='#chi_features_set'><p>Chicago Features Example Data</p></a></li>
<li><a href='#collect_metrics.workflow_set'><p>Obtain and format results produced by tuning functions for workflow sets</p></a></li>
<li><a href='#comment_add'><p>Add annotations and comments for workflows</p></a></li>
<li><a href='#extract_workflow_set_result'><p>Extract elements of workflow sets</p></a></li>
<li><a href='#fit_best.workflow_set'><p>Fit a model to the numerically optimal configuration</p></a></li>
<li><a href='#leave_var_out_formulas'><p>Create formulas without each predictor</p></a></li>
<li><a href='#option_add'><p>Add and edit options saved in a workflow set</p></a></li>
<li><a href='#option_list'><p>Make a classed list of options</p></a></li>
<li><a href='#pull_workflow_set_result'><p>Extract elements from a workflow set</p></a></li>
<li><a href='#rank_results'><p>Rank the results by a metric</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#two_class_set'><p>Two Class Example Data</p></a></li>
<li><a href='#update_workflow_model'><p>Update components of a workflow within a workflow set</p></a></li>
<li><a href='#workflow_map'><p>Process a series of workflows</p></a></li>
<li><a href='#workflow_set'><p>Generate a set of workflow objects from preprocessing and model objects</p></a></li>
<li><a href='#workflowsets-package'><p>workflowsets: Create a Collection of 'tidymodels' Workflows</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Create a Collection of 'tidymodels' Workflows</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A workflow is a combination of a model and preprocessors
    (e.g, a formula, recipe, etc.) (Kuhn and Silge (2021)
    <a href="https://www.tmwr.org/">https://www.tmwr.org/</a>). In order to try different combinations of
    these, an object can be created that contains many workflows. There
    are functions to create workflows en masse as well as training them
    and visualizing the results.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tidymodels/workflowsets">https://github.com/tidymodels/workflowsets</a>,
<a href="https://workflowsets.tidymodels.org">https://workflowsets.tidymodels.org</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/workflowsets/issues">https://github.com/tidymodels/workflowsets/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cli, dplyr (&ge; 1.0.0), generics (&ge; 0.1.2), ggplot2, glue,
hardhat (&ge; 1.2.0), lifecycle (&ge; 1.0.0), parsnip (&ge; 1.2.0),
pillar (&ge; 1.7.0), prettyunits, purrr, rlang (&ge; 1.1.0),
rsample (&ge; 0.0.9), stats, tibble (&ge; 3.1.0), tidyr, tune (&ge;
1.2.0), vctrs, withr, workflows (&ge; 1.1.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, dials (&ge; 0.1.0), finetune, kknn, knitr, modeldata,
recipes (&ge; 1.0.0), rmarkdown, spelling, testthat (&ge; 3.0.0),
tidyclust, yardstick (&ge; 1.3.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>discrim, rpart, mda, klaR, earth, tidymodels,
tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-21 13:47:47 UTC; simoncouch</td>
</tr>
<tr>
<td>Author:</td>
<td>Max Kuhn <a href="https://orcid.org/0000-0003-2402-136X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Simon Couch <a href="https://orcid.org/0000-0001-5676-5107"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Posit Software, PBC [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Simon Couch &lt;simon.couch@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-21 14:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='as_workflow_set'>Convert existing objects to a workflow set</h2><span id='topic+as_workflow_set'></span>

<h3>Description</h3>

<p>Use existing objects to create a workflow set. A list of objects that are
either simple workflows or objects that have class <code>"tune_results"</code> can be
converted into a workflow set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_workflow_set(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_workflow_set_+3A_...">...</code></td>
<td>
<p>One or more named objects. Names should be unique and the
objects should have at least one of the following classes: <code>workflow</code>,
<code>iteration_results</code>, <code>tune_results</code>, <code>resample_results</code>, or <code>tune_race</code>. Each
<code>tune_results</code> element should also contain the original workflow
(accomplished using the <code>save_workflow</code> option in the control function).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A workflow set. Note that the <code>option</code> column will not reflect the
options that were used to create each object.
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ------------------------------------------------------------------------------
# Existing results

# Use the already worked example to show how to add tuned
# objects to a workflow set
two_class_res

results &lt;- two_class_res %&gt;% purrr::pluck("result")
names(results) &lt;- two_class_res$wflow_id

# These are all objects that have been resampled or tuned:
purrr::map_chr(results, ~ class(.x)[1])

# Use rlang's !!! operator to splice in the elements of the list
new_set &lt;- as_workflow_set(!!!results)

# ------------------------------------------------------------------------------
# Make a set from unfit workflows

library(parsnip)
library(workflows)

lr_spec &lt;- logistic_reg()

main_effects &lt;-
  workflow() %&gt;%
  add_model(lr_spec) %&gt;%
  add_formula(Class ~ .)

interactions &lt;-
  workflow() %&gt;%
  add_model(lr_spec) %&gt;%
  add_formula(Class ~ (.)^2)

as_workflow_set(main = main_effects, int = interactions)
</code></pre>

<hr>
<h2 id='autoplot.workflow_set'>Plot the results of a workflow set</h2><span id='topic+autoplot.workflow_set'></span>

<h3>Description</h3>

<p>This <code>autoplot()</code> method plots performance metrics that have been ranked using
a metric. It can also run <code>autoplot()</code> on the individual results (per
<code>wflow_id</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow_set'
autoplot(
  object,
  rank_metric = NULL,
  metric = NULL,
  id = "workflow_set",
  select_best = FALSE,
  std_errs = qnorm(0.95),
  type = "class",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.workflow_set_+3A_object">object</code></td>
<td>
<p>A <code>workflow_set</code> whose elements have results.</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_rank_metric">rank_metric</code></td>
<td>
<p>A character string for which metric should be used to rank
the results. If none is given, the first metric in the metric set is used
(after filtering by the <code>metric</code> option).</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_metric">metric</code></td>
<td>
<p>A character vector for which metrics (apart from <code>rank_metric</code>)
to be included in the visualization.</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_id">id</code></td>
<td>
<p>A character string for what to plot. If a value of
<code>"workflow_set"</code> is used, the results of each model (and sub-model) are ordered
and plotted. Alternatively, a value of the workflow set's <code>wflow_id</code> can be
given and the <code>autoplot()</code> method is executed on that workflow's results.</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_select_best">select_best</code></td>
<td>
<p>A logical; should the results only contain the numerically
best submodel per workflow?</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_std_errs">std_errs</code></td>
<td>
<p>The number of standard errors to plot (if the standard error
exists).</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_type">type</code></td>
<td>
<p>The aesthetics with which to differentiate workflows. The
default <code>"class"</code> maps color to the model type and shape to the preprocessor
type. The <code>"workflow"</code> option maps a color to each <code>"wflow_id"</code>. This
argument is ignored for values of <code>id</code> other than <code>"workflow_set"</code>.</p>
</td></tr>
<tr><td><code id="autoplot.workflow_set_+3A_...">...</code></td>
<td>
<p>Other options to pass to <code>autoplot()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is intended to produce a default plot to visualize helpful
information across all possible applications of a workflow set. A more
appropriate plot for your specific analysis can be created by
calling <code><a href="#topic+rank_results">rank_results()</a></code> and using standard <code>ggplot2</code> code for plotting.
</p>
<p>The x-axis is the workflow rank in the set (a value of one being the best)
versus the performance metric(s) on the y-axis. With multiple metrics, there
will be facets for each metric.
</p>
<p>If multiple resamples are used, confidence bounds are shown for each result
(90% confidence, by default).
</p>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>autoplot(two_class_res)
autoplot(two_class_res, select_best = TRUE)
autoplot(two_class_res, id = "yj_trans_cart", metric = "roc_auc")
</code></pre>

<hr>
<h2 id='chi_features_set'>Chicago Features Example Data</h2><span id='topic+chi_features_set'></span><span id='topic+chi_features_res'></span>

<h3>Description</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Details</h3>

<p>See below for the source code to generate the Chicago Features example
workflow sets:
</p>
<div class="sourceCode r"><pre>library(workflowsets)
library(workflows)
library(modeldata)
library(recipes)
library(parsnip)
library(dplyr)
library(rsample)
library(tune)
library(yardstick)
library(dials)

# ------------------------------------------------------------------------------
# Slightly smaller data size
data(Chicago)
Chicago &lt;- Chicago[1:1195,]

time_val_split &lt;-
   sliding_period(
      Chicago,
      date,
      "month",
      lookback = 38,
      assess_stop = 1
   )

# ------------------------------------------------------------------------------

base_recipe &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   step_holiday(date) %&gt;%
   # remove date from the list of predictors
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors()) %&gt;%
   step_normalize(all_predictors())

date_only &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors())

date_and_holidays &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   step_holiday(date) %&gt;%
   # remove date from the list of predictors
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors())

date_and_holidays_and_pca &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   step_holiday(date) %&gt;%
   # remove date from the list of predictors
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors()) %&gt;%
   step_pca(!!stations, num_comp = tune())

# ------------------------------------------------------------------------------

lm_spec &lt;- linear_reg() %&gt;% set_engine("lm")

# ------------------------------------------------------------------------------

pca_param &lt;-
   parameters(num_comp()) %&gt;%
   update(num_comp = num_comp(c(0, 20)))

# ------------------------------------------------------------------------------

chi_features_set &lt;-
   workflow_set(
      preproc = list(date = date_only,
                     plus_holidays = date_and_holidays,
                     plus_pca = date_and_holidays_and_pca),
      models = list(lm = lm_spec),
      cross = TRUE
   )

# ------------------------------------------------------------------------------

chi_features_res &lt;-
   chi_features_set %&gt;%
   option_add(param_info = pca_param, id = "plus_pca_lm") %&gt;%
   workflow_map(resamples = time_val_split, grid = 21, seed = 1, verbose = TRUE)
</pre></div>


<h3>References</h3>

<p>Max Kuhn and Kjell Johnson (2019) <em>Feature Engineering and
Selection</em>, <a href="https://bookdown.org/max/FES/a-more-complex-example.html">https://bookdown.org/max/FES/a-more-complex-example.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chi_features_set)

chi_features_set
</code></pre>

<hr>
<h2 id='collect_metrics.workflow_set'>Obtain and format results produced by tuning functions for workflow sets</h2><span id='topic+collect_metrics.workflow_set'></span><span id='topic+collect_predictions.workflow_set'></span><span id='topic+collect_notes.workflow_set'></span>

<h3>Description</h3>

<p>Return a tibble of performance metrics for all models or submodels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow_set'
collect_metrics(x, ..., summarize = TRUE)

## S3 method for class 'workflow_set'
collect_predictions(
  x,
  ...,
  summarize = TRUE,
  parameters = NULL,
  select_best = FALSE,
  metric = NULL
)

## S3 method for class 'workflow_set'
collect_notes(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collect_metrics.workflow_set_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+workflow_set">workflow_set</a></code> object that has been evaluated
with <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="collect_metrics.workflow_set_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
<tr><td><code id="collect_metrics.workflow_set_+3A_summarize">summarize</code></td>
<td>
<p>A logical for whether the performance estimates should be
summarized via the mean (over resamples) or the raw performance values (per
resample) should be returned along with the resampling identifiers. When
collecting predictions, these are averaged if multiple assessment sets
contain the same row.</p>
</td></tr>
<tr><td><code id="collect_metrics.workflow_set_+3A_parameters">parameters</code></td>
<td>
<p>An optional tibble of tuning parameter values that can be
used to filter the predicted values before processing. This tibble should
only have columns for each tuning parameter identifier (e.g. <code>"my_param"</code>
if <code>tune("my_param")</code> was used).</p>
</td></tr>
<tr><td><code id="collect_metrics.workflow_set_+3A_select_best">select_best</code></td>
<td>
<p>A single logical for whether the numerically best results
are retained. If <code>TRUE</code>, the <code>parameters</code> argument is ignored.</p>
</td></tr>
<tr><td><code id="collect_metrics.workflow_set_+3A_metric">metric</code></td>
<td>
<p>A character string for the metric that is used for
<code>select_best</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When applied to a workflow set, the metrics and predictions that are returned
do not contain the actual tuning parameter columns and values (unlike when
these collect functions are run on other objects). The reason is that workflow
sets can contain different types of models or models with different tuning
parameters.
</p>
<p>If the columns are needed, there are two options. First, the <code>.config</code> column
can be used to merge the tuning parameter columns into an appropriate object.
Alternatively, the <code>map()</code> function can be used to get the metrics from the
original objects (see the example below).
</p>


<h3>Value</h3>

<p>A tibble.
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>See Also</h3>

<p><code><a href="tune.html#topic+collect_predictions">tune::collect_metrics()</a></code>, <code><a href="#topic+rank_results">rank_results()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(purrr)
library(tidyr)

two_class_res

# ------------------------------------------------------------------------------

collect_metrics(two_class_res)

# Alternatively, if the tuning parameter values are needed:
two_class_res %&gt;%
  dplyr::filter(grepl("cart", wflow_id)) %&gt;%
  mutate(metrics = map(result, collect_metrics)) %&gt;%
  dplyr::select(wflow_id, metrics) %&gt;%
  tidyr::unnest(cols = metrics)


collect_metrics(two_class_res, summarize = FALSE)
</code></pre>

<hr>
<h2 id='comment_add'>Add annotations and comments for workflows</h2><span id='topic+comment_add'></span><span id='topic+comment_get'></span><span id='topic+comment_reset'></span><span id='topic+comment_print'></span>

<h3>Description</h3>

<p><code>comment_add()</code> can be used to log important information about the workflow or
its results as you work. Comments can be appended or removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comment_add(x, id, ..., append = TRUE, collapse = "\n")

comment_get(x, id)

comment_reset(x, id)

comment_print(x, id = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comment_add_+3A_x">x</code></td>
<td>
<p>A workflow set outputted by <code><a href="#topic+workflow_set">workflow_set()</a></code> or <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="comment_add_+3A_id">id</code></td>
<td>
<p>A single character string for a value in the <code>wflow_id</code> column. For
<code>comment_print()</code>, <code>id</code> can be a vector or <code>NULL</code> (and this indicates that
all comments are printed).</p>
</td></tr>
<tr><td><code id="comment_add_+3A_...">...</code></td>
<td>
<p>One or more character strings.</p>
</td></tr>
<tr><td><code id="comment_add_+3A_append">append</code></td>
<td>
<p>A logical value to determine if the new comment should be added
to the existing values.</p>
</td></tr>
<tr><td><code id="comment_add_+3A_collapse">collapse</code></td>
<td>
<p>A character string that separates the comments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>comment_add()</code> and <code>comment_reset()</code> return an updated workflow set.
<code>comment_get()</code> returns a character string. <code>comment_print()</code> returns <code>NULL</code>
invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>two_class_set

two_class_set %&gt;% comment_get("none_cart")

new_set &lt;-
  two_class_set %&gt;%
  comment_add("none_cart", "What does 'cart' stand for\u2753") %&gt;%
  comment_add("none_cart", "Classification And Regression Trees.")

comment_print(new_set)

new_set %&gt;% comment_get("none_cart")

new_set %&gt;%
  comment_reset("none_cart") %&gt;%
  comment_get("none_cart")
</code></pre>

<hr>
<h2 id='extract_workflow_set_result'>Extract elements of workflow sets</h2><span id='topic+extract_workflow_set_result'></span><span id='topic+extract_workflow.workflow_set'></span><span id='topic+extract_spec_parsnip.workflow_set'></span><span id='topic+extract_recipe.workflow_set'></span><span id='topic+extract_fit_parsnip.workflow_set'></span><span id='topic+extract_fit_engine.workflow_set'></span><span id='topic+extract_mold.workflow_set'></span><span id='topic+extract_preprocessor.workflow_set'></span><span id='topic+extract_parameter_set_dials.workflow_set'></span><span id='topic+extract_parameter_dials.workflow_set'></span>

<h3>Description</h3>

<p>These functions extract various elements from a workflow set object. If they
do not exist yet, an error is thrown.
</p>

<ul>
<li> <p><code>extract_preprocessor()</code> returns the formula, recipe, or variable
expressions used for preprocessing.
</p>
</li>
<li> <p><code>extract_spec_parsnip()</code> returns the parsnip model specification.
</p>
</li>
<li> <p><code>extract_fit_parsnip()</code> returns the parsnip model fit object.
</p>
</li>
<li> <p><code>extract_fit_engine()</code> returns the engine specific fit embedded within
a parsnip model fit. For example, when using <code><a href="parsnip.html#topic+linear_reg">parsnip::linear_reg()</a></code>
with the <code>"lm"</code> engine, this returns the underlying <code>lm</code> object.
</p>
</li>
<li> <p><code>extract_mold()</code> returns the preprocessed &quot;mold&quot; object returned
from <code><a href="hardhat.html#topic+mold">hardhat::mold()</a></code>. It contains information about the preprocessing,
including either the prepped recipe, the formula terms object, or
variable selectors.
</p>
</li>
<li> <p><code>extract_recipe()</code> returns the recipe. The <code>estimated</code> argument specifies
whether the fitted or original recipe is returned.
</p>
</li>
<li> <p><code>extract_workflow_set_result()</code> returns the results of <code><a href="#topic+workflow_map">workflow_map()</a></code>
for a particular workflow.
</p>
</li>
<li> <p><code>extract_workflow()</code> returns the workflow object. The workflow will not
have been estimated.
</p>
</li>
<li> <p><code>extract_parameter_set_dials()</code> returns the parameter set
<em>that will be used to fit</em> the supplied row <code>id</code> of the workflow set.
Note that workflow sets reference a parameter set associated with the
<code>workflow</code> contained in the <code>info</code> column by default, but can be
fitted with a modified parameter set via the <code><a href="#topic+option_add">option_add()</a></code> interface.
This extractor returns the latter, if it exists, and returns the former
if not, mirroring the process that <code><a href="#topic+workflow_map">workflow_map()</a></code> follows to provide
tuning functions a parameter set.
</p>
</li>
<li> <p><code>extract_parameter_dials()</code> returns the <code>parameters</code> object
<em>that will be used to fit</em> the supplied tuning <code>parameter</code> in the supplied
row <code>id</code> of the workflow set. See the above notes in
<code>extract_parameter_set_dials()</code> on precedence.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>extract_workflow_set_result(x, id, ...)

## S3 method for class 'workflow_set'
extract_workflow(x, id, ...)

## S3 method for class 'workflow_set'
extract_spec_parsnip(x, id, ...)

## S3 method for class 'workflow_set'
extract_recipe(x, id, ..., estimated = TRUE)

## S3 method for class 'workflow_set'
extract_fit_parsnip(x, id, ...)

## S3 method for class 'workflow_set'
extract_fit_engine(x, id, ...)

## S3 method for class 'workflow_set'
extract_mold(x, id, ...)

## S3 method for class 'workflow_set'
extract_preprocessor(x, id, ...)

## S3 method for class 'workflow_set'
extract_parameter_set_dials(x, id, ...)

## S3 method for class 'workflow_set'
extract_parameter_dials(x, id, parameter, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_workflow_set_result_+3A_x">x</code></td>
<td>
<p>A workflow set outputted by <code><a href="#topic+workflow_set">workflow_set()</a></code> or <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="extract_workflow_set_result_+3A_id">id</code></td>
<td>
<p>A single character string for a workflow ID.</p>
</td></tr>
<tr><td><code id="extract_workflow_set_result_+3A_...">...</code></td>
<td>
<p>Other options (not currently used).</p>
</td></tr>
<tr><td><code id="extract_workflow_set_result_+3A_estimated">estimated</code></td>
<td>
<p>A logical for whether the original (unfit) recipe or the
fitted recipe should be returned.</p>
</td></tr>
<tr><td><code id="extract_workflow_set_result_+3A_parameter">parameter</code></td>
<td>
<p>A single string for the parameter ID.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions supersede the <code style="white-space: pre;">&#8288;pull_*()&#8288;</code> functions (e.g.,
<code><a href="#topic+extract_workflow_set_result">extract_workflow_set_result()</a></code>).
</p>


<h3>Value</h3>

<p>The extracted value from the object, <code>x</code>, as described in the
description section.
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tune)

two_class_res

extract_workflow_set_result(two_class_res, "none_cart")

extract_workflow(two_class_res, "none_cart")
</code></pre>

<hr>
<h2 id='fit_best.workflow_set'>Fit a model to the numerically optimal configuration</h2><span id='topic+fit_best.workflow_set'></span>

<h3>Description</h3>

<p><code>fit_best()</code> takes results from tuning many models and fits the workflow
configuration associated with the best performance to the training set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'workflow_set'
fit_best(x, metric = NULL, eval_time = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_best.workflow_set_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+workflow_set">workflow_set</a></code> object that has been evaluated
with <code><a href="#topic+workflow_map">workflow_map()</a></code>. Note that the workflow set must have been fitted with
the <a href="#topic+option_add">control option</a> <code>save_workflow = TRUE</code>.</p>
</td></tr>
<tr><td><code id="fit_best.workflow_set_+3A_metric">metric</code></td>
<td>
<p>A character string giving the metric to rank results by.</p>
</td></tr>
<tr><td><code id="fit_best.workflow_set_+3A_eval_time">eval_time</code></td>
<td>
<p>A single numeric time point where dynamic event time
metrics should be chosen (e.g., the time-dependent ROC curve, etc). The
values should be consistent with the values used to create <code>x</code>. The <code>NULL</code>
default will automatically use the first evaluation time used by <code>x</code>.</p>
</td></tr>
<tr><td><code id="fit_best.workflow_set_+3A_...">...</code></td>
<td>
<p>Additional options to pass to
<a href="tune.html#topic+fit_best">tune::fit_best</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a shortcut for the steps needed to fit the
numerically optimal configuration in a fitted workflow set.
The function ranks results, extracts the tuning result pertaining
to the best result, and then again calls <code>fit_best()</code> (itself a
wrapper) on the tuning result containing the best result.
</p>
<p>In pseudocode:
</p>
<div class="sourceCode"><pre>rankings &lt;- rank_results(wf_set, metric, select_best = TRUE)
tune_res &lt;- extract_workflow_set_result(wf_set, rankings$wflow_id[1])
fit_best(tune_res, metric)
</pre></div>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(tune)
library(modeldata)
library(rsample)

data(Chicago)
Chicago &lt;- Chicago[1:1195,]

time_val_split &lt;-
   sliding_period(
      Chicago,
      date,
      "month",
      lookback = 38,
      assess_stop = 1
   )

chi_features_set

chi_features_res_new &lt;-
   chi_features_set %&gt;%
   # note: must set `save_workflow = TRUE` to use `fit_best()`
   option_add(control = control_grid(save_workflow = TRUE)) %&gt;%
   # evaluate with resamples
   workflow_map(resamples = time_val_split, grid = 21, seed = 1, verbose = TRUE)

chi_features_res_new

# sort models by performance metrics
rank_results(chi_features_res_new)

# fit the numerically optimal configuration to the training set
chi_features_wf &lt;- fit_best(chi_features_res_new)

chi_features_wf

# to select optimal value based on a specific metric:
fit_best(chi_features_res_new, metric = "rmse")

</code></pre>

<hr>
<h2 id='leave_var_out_formulas'>Create formulas without each predictor</h2><span id='topic+leave_var_out_formulas'></span>

<h3>Description</h3>

<p>From an initial model formula, create a list of formulas that exclude
each predictor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>leave_var_out_formulas(formula, data, full_model = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="leave_var_out_formulas_+3A_formula">formula</code></td>
<td>
<p>A model formula that contains at least two predictors.</p>
</td></tr>
<tr><td><code id="leave_var_out_formulas_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="leave_var_out_formulas_+3A_full_model">full_model</code></td>
<td>
<p>A logical; should the list include the original formula?</p>
</td></tr>
<tr><td><code id="leave_var_out_formulas_+3A_...">...</code></td>
<td>
<p>Options to pass to <code><a href="stats.html#topic+model.frame">stats::model.frame()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The new formulas obey the hierarchy rule so that interactions
without main effects are not included (unless the original formula contains
such terms).
</p>
<p>Factor predictors are left as-is (i.e., no indicator variables are created).
</p>


<h3>Value</h3>

<p>A named list of formulas
</p>


<h3>See Also</h3>

<p><code><a href="#topic+workflow_set">workflow_set()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(penguins, package = "modeldata")

leave_var_out_formulas(
  bill_length_mm ~ .,
  data = penguins
)

leave_var_out_formulas(
  bill_length_mm ~ (island + sex)^2 + flipper_length_mm,
  data = penguins
)

leave_var_out_formulas(
  bill_length_mm ~ (island + sex)^2 + flipper_length_mm +
    I(flipper_length_mm^2),
  data = penguins
)
</code></pre>

<hr>
<h2 id='option_add'>Add and edit options saved in a workflow set</h2><span id='topic+option_add'></span><span id='topic+option_remove'></span><span id='topic+option_add_parameters'></span>

<h3>Description</h3>

<p>The <code>option</code> column controls options for the functions that are used to
<em>evaluate</em> the workflow set, such as <code><a href="tune.html#topic+fit_resamples">tune::fit_resamples()</a></code> or
<code><a href="tune.html#topic+tune_grid">tune::tune_grid()</a></code>. Examples of common options to set for these functions
include <code>param_info</code> and <code>grid</code>.
</p>
<p>These functions are helpful for manipulating the information in the <code>option</code>
column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>option_add(x, ..., id = NULL, strict = FALSE)

option_remove(x, ...)

option_add_parameters(x, id = NULL, strict = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="option_add_+3A_x">x</code></td>
<td>
<p>A workflow set outputted by <code><a href="#topic+workflow_set">workflow_set()</a></code> or <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="option_add_+3A_...">...</code></td>
<td>
<p>Arguments to pass to the <code style="white-space: pre;">&#8288;tune_*()&#8288;</code> functions (e.g.
<code><a href="tune.html#topic+tune_grid">tune::tune_grid()</a></code>) or <code><a href="tune.html#topic+fit_resamples">tune::fit_resamples()</a></code>. For <code>option_remove()</code> this
can be a series of unquoted option names.</p>
</td></tr>
<tr><td><code id="option_add_+3A_id">id</code></td>
<td>
<p>A character string of one or more values from the <code>wflow_id</code>
column that indicates which options to update. By default, all workflows
are updated.</p>
</td></tr>
<tr><td><code id="option_add_+3A_strict">strict</code></td>
<td>
<p>A logical; should execution stop if existing options are being
replaced?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>option_add()</code> is used to update all of the options in a workflow set.
</p>
<p><code>option_remove()</code> will eliminate specific options across rows.
</p>
<p><code>option_add_parameters()</code> adds a parameter object to the <code>option</code> column
(if parameters are being tuned).
</p>
<p>Note that executing a function on the workflow set, such as <code>tune_grid()</code>,
will add any options given to that function to the <code>option</code> column.
</p>
<p>These functions do <em>not</em> control options for the individual workflows, such as
the recipe blueprint. When creating a workflow manually, use
<code><a href="workflows.html#topic+add_model">workflows::add_model()</a></code> or <code><a href="workflows.html#topic+add_recipe">workflows::add_recipe()</a></code> to specify
extra options. To alter these in a workflow set, use
<code><a href="#topic+update_workflow_model">update_workflow_model()</a></code> or <code><a href="#topic+update_workflow_recipe">update_workflow_recipe()</a></code>.
</p>


<h3>Value</h3>

<p>An updated workflow set.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tune)

two_class_set

two_class_set %&gt;%
  option_add(grid = 10)

two_class_set %&gt;%
  option_add(grid = 10) %&gt;%
  option_add(grid = 50, id = "none_cart")

two_class_set %&gt;%
  option_add_parameters()
</code></pre>

<hr>
<h2 id='option_list'>Make a classed list of options</h2><span id='topic+option_list'></span>

<h3>Description</h3>

<p>This function returns a named list with an extra class of
<code>"workflow_set_options"</code> that has corresponding formatting methods for
printing inside of tibbles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>option_list(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="option_list_+3A_...">...</code></td>
<td>
<p>A set of named options (or nothing)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A classed list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>option_list(a = 1, b = 2)
option_list()
</code></pre>

<hr>
<h2 id='pull_workflow_set_result'>Extract elements from a workflow set</h2><span id='topic+pull_workflow_set_result'></span><span id='topic+pull_workflow'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#soft-deprecated"><img src="../help/figures/lifecycle-soft-deprecated.svg" alt='[Soft-deprecated]' /></a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pull_workflow_set_result(x, id)

pull_workflow(x, id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pull_workflow_set_result_+3A_x">x</code></td>
<td>
<p>A workflow set outputted by <code><a href="#topic+workflow_set">workflow_set()</a></code> or <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="pull_workflow_set_result_+3A_id">id</code></td>
<td>
<p>A single character string for a workflow ID.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pull_workflow_set_result()</code> retrieves the results of <code><a href="#topic+workflow_map">workflow_map()</a></code> for a
particular workflow while <code>pull_workflow()</code> extracts the unfitted workflow
from the <code>info</code> column.
</p>
<p>The <code><a href="#topic+extract_workflow_set_result">extract_workflow_set_result()</a></code> and <code><a href="#topic+extract_workflow">extract_workflow()</a></code> functions should
be used instead of these functions.
</p>


<h3>Value</h3>

<p><code>pull_workflow_set_result()</code> produces a <code>tune_result</code> or
<code>resample_results</code> object. <code>pull_workflow()</code> returns an unfit workflow
object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tune)

two_class_res

pull_workflow_set_result(two_class_res, "none_cart")

pull_workflow(two_class_res, "none_cart")
</code></pre>

<hr>
<h2 id='rank_results'>Rank the results by a metric</h2><span id='topic+rank_results'></span>

<h3>Description</h3>

<p>This function sorts the results by a specific performance metric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank_results(x, rank_metric = NULL, eval_time = NULL, select_best = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rank_results_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+workflow_set">workflow_set</a></code> object that has been evaluated
with <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="rank_results_+3A_rank_metric">rank_metric</code></td>
<td>
<p>A character string for a metric.</p>
</td></tr>
<tr><td><code id="rank_results_+3A_eval_time">eval_time</code></td>
<td>
<p>A single numeric time point where dynamic event time
metrics should be chosen (e.g., the time-dependent ROC curve, etc). The
values should be consistent with the values used to create <code>x</code>. The <code>NULL</code>
default will automatically use the first evaluation time used by <code>x</code>.</p>
</td></tr>
<tr><td><code id="rank_results_+3A_select_best">select_best</code></td>
<td>
<p>A logical giving whether the results should only contain
the numerically best submodel per workflow.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If some models have the exact same performance,
<code>rank(value, ties.method = "random")</code> is used (with a reproducible seed) so
that all ranks are integers.
</p>
<p>No columns are returned for the tuning parameters since they are likely to
be different (or not exist) for some models. The <code>wflow_id</code> and <code>.config</code>
columns can be used to determine the corresponding parameter values.
</p>


<h3>Value</h3>

<p>A tibble with columns: <code>wflow_id</code>, <code>.config</code>, <code>.metric</code>, <code>mean</code>,
<code>std_err</code>, <code>n</code>, <code>preprocessor</code>, <code>model</code>, and <code>rank</code>.
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>chi_features_res

rank_results(chi_features_res)
rank_results(chi_features_res, select_best = TRUE)
rank_results(chi_features_res, rank_metric = "rsq")
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+collect_metrics'></span><span id='topic+collect_predictions'></span><span id='topic+collect_notes'></span><span id='topic++25+3E+25'></span><span id='topic+autoplot'></span><span id='topic+extract_spec_parsnip'></span><span id='topic+extract_recipe'></span><span id='topic+extract_fit_parsnip'></span><span id='topic+extract_fit_engine'></span><span id='topic+extract_mold'></span><span id='topic+extract_preprocessor'></span><span id='topic+extract_workflow'></span><span id='topic+extract_parameter_set_dials'></span><span id='topic+extract_parameter_dials'></span><span id='topic+fit_best'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>dplyr</dt><dd><p><code><a href="dplyr.html#topic+reexports">%&gt;%</a></code></p>
</dd>
<dt>ggplot2</dt><dd><p><code><a href="ggplot2.html#topic+autoplot">autoplot</a></code></p>
</dd>
<dt>hardhat</dt><dd><p><code><a href="hardhat.html#topic+hardhat-extract">extract_fit_engine</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_fit_parsnip</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_mold</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_parameter_dials</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_parameter_set_dials</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_preprocessor</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_recipe</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_spec_parsnip</a></code>, <code><a href="hardhat.html#topic+hardhat-extract">extract_workflow</a></code></p>
</dd>
<dt>tune</dt><dd><p><code><a href="tune.html#topic+collect_predictions">collect_metrics</a></code>, <code><a href="tune.html#topic+collect_predictions">collect_notes</a></code>, <code><a href="tune.html#topic+collect_predictions">collect_predictions</a></code>, <code><a href="tune.html#topic+fit_best">fit_best</a></code></p>
</dd>
</dl>

<hr>
<h2 id='two_class_set'>Two Class Example Data</h2><span id='topic+two_class_set'></span><span id='topic+two_class_res'></span>

<h3>Description</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Details</h3>

<p>See below for the source code to generate the Two Class example workflow
sets:
</p>
<div class="sourceCode r"><pre>library(workflowsets)
library(workflows)
library(modeldata)
library(recipes)
library(parsnip)
library(dplyr)
library(rsample)
library(tune)
library(yardstick)

# ------------------------------------------------------------------------------

data(two_class_dat, package = "modeldata")

set.seed(1)
folds &lt;- vfold_cv(two_class_dat, v = 5)

# ------------------------------------------------------------------------------

decision_tree_rpart_spec &lt;-
  decision_tree(min_n = tune(), cost_complexity = tune()) %&gt;%
  set_engine('rpart') %&gt;%
  set_mode('classification')

logistic_reg_glm_spec &lt;-
  logistic_reg() %&gt;%
  set_engine('glm')

mars_earth_spec &lt;-
  mars(prod_degree = tune()) %&gt;%
  set_engine('earth') %&gt;%
  set_mode('classification')

# ------------------------------------------------------------------------------

yj_recipe &lt;-
   recipe(Class ~ ., data = two_class_dat) %&gt;%
   step_YeoJohnson(A, B)

# ------------------------------------------------------------------------------

two_class_set &lt;-
   workflow_set(
      preproc = list(none = Class ~ A + B, yj_trans = yj_recipe),
      models = list(cart = decision_tree_rpart_spec, glm = logistic_reg_glm_spec,
                    mars = mars_earth_spec)
   )

# ------------------------------------------------------------------------------

two_class_res &lt;-
  two_class_set %&gt;%
  workflow_map(
    resamples = folds,
    grid = 10,
    seed = 2,
    verbose = TRUE,
    control = control_grid(save_workflow = TRUE)
  )
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'>data(two_class_set)

two_class_set
</code></pre>

<hr>
<h2 id='update_workflow_model'>Update components of a workflow within a workflow set</h2><span id='topic+update_workflow_model'></span><span id='topic+update_workflow_recipe'></span>

<h3>Description</h3>

<p>Workflows can take special arguments for the recipe (e.g. a blueprint) or a
model (e.g. a special formula). However, when creating a workflow set, there
is no way to specify these extra components.
</p>
<p><code>update_workflow_model()</code> and <code>update_workflow_recipe()</code> allow users to set
these values <em>after</em> the workflow set is initially created. They are
analogous to <code><a href="workflows.html#topic+add_model">workflows::add_model()</a></code> or <code><a href="workflows.html#topic+add_recipe">workflows::add_recipe()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_workflow_model(x, id, spec, formula = NULL)

update_workflow_recipe(x, id, recipe, blueprint = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_workflow_model_+3A_x">x</code></td>
<td>
<p>A workflow set outputted by <code><a href="#topic+workflow_set">workflow_set()</a></code> or <code><a href="#topic+workflow_map">workflow_map()</a></code>.</p>
</td></tr>
<tr><td><code id="update_workflow_model_+3A_id">id</code></td>
<td>
<p>A single character string from the <code>wflow_id</code> column indicating
which workflow to update.</p>
</td></tr>
<tr><td><code id="update_workflow_model_+3A_spec">spec</code></td>
<td>
<p>A parsnip model specification.</p>
</td></tr>
<tr><td><code id="update_workflow_model_+3A_formula">formula</code></td>
<td>
<p>An optional formula override to specify the terms of the
model. Typically, the terms are extracted from the formula or recipe
preprocessing methods. However, some models (like survival and bayesian
models) use the formula not to preprocess, but to specify the structure
of the model. In those cases, a formula specifying the model structure
must be passed unchanged into the model call itself. This argument is
used for those purposes.</p>
</td></tr>
<tr><td><code id="update_workflow_model_+3A_recipe">recipe</code></td>
<td>
<p>A recipe created using <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>. The recipe
should not have been trained already with <code><a href="recipes.html#topic+prep">recipes::prep()</a></code>; workflows
will handle training internally.</p>
</td></tr>
<tr><td><code id="update_workflow_model_+3A_blueprint">blueprint</code></td>
<td>
<p>A hardhat blueprint used for fine tuning the preprocessing.
</p>
<p>If <code>NULL</code>, <code><a href="hardhat.html#topic+default_recipe_blueprint">hardhat::default_recipe_blueprint()</a></code> is used.
</p>
<p>Note that preprocessing done here is separate from preprocessing that
might be done automatically by the underlying model.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parsnip)

new_mod &lt;-
  decision_tree() %&gt;%
  set_engine("rpart", method = "anova") %&gt;%
  set_mode("classification")

new_set &lt;- update_workflow_model(two_class_res, "none_cart", spec = new_mod)

new_set

extract_workflow(new_set, id = "none_cart")
</code></pre>

<hr>
<h2 id='workflow_map'>Process a series of workflows</h2><span id='topic+workflow_map'></span>

<h3>Description</h3>

<p><code>workflow_map()</code> will execute the same function across the workflows in the
set. The various <code style="white-space: pre;">&#8288;tune_*()&#8288;</code> functions can be used as well as
<code><a href="tune.html#topic+fit_resamples">tune::fit_resamples()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>workflow_map(
  object,
  fn = "tune_grid",
  verbose = FALSE,
  seed = sample.int(10^4, 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="workflow_map_+3A_object">object</code></td>
<td>
<p>A workflow set.</p>
</td></tr>
<tr><td><code id="workflow_map_+3A_fn">fn</code></td>
<td>
<p>The name of the function to run, as a character. Acceptable values are:
<a href="tune.html#topic+tune_grid">&quot;tune_grid&quot;</a>,
<a href="tune.html#topic+tune_bayes">&quot;tune_bayes&quot;</a>,
<a href="tune.html#topic+fit_resamples">&quot;fit_resamples&quot;</a>,
<a href="finetune.html#topic+tune_race_anova">&quot;tune_race_anova&quot;</a>,
<a href="finetune.html#topic+tune_race_win_loss">&quot;tune_race_win_loss&quot;</a>, or
<a href="finetune.html#topic+tune_sim_anneal">&quot;tune_sim_anneal&quot;</a>. Note that users need not
provide the namespace or parentheses in this argument,
e.g. provide <code>"tune_grid"</code> rather than <code>"tune::tune_grid"</code> or <code>"tune_grid()"</code>.</p>
</td></tr>
<tr><td><code id="workflow_map_+3A_verbose">verbose</code></td>
<td>
<p>A logical for logging progress.</p>
</td></tr>
<tr><td><code id="workflow_map_+3A_seed">seed</code></td>
<td>
<p>A single integer that is set prior to each function execution.</p>
</td></tr>
<tr><td><code id="workflow_map_+3A_...">...</code></td>
<td>
<p>Options to pass to the modeling function. See details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When passing options, anything passed in the <code>...</code> will be combined with any
values in the <code>option</code> column. The values in <code>...</code> will override that
column's values and the new options are added to the <code>options</code> column.
</p>
<p>Any failures in execution result in the corresponding row of <code>results</code> to
contain a <code>try-error</code> object.
</p>
<p>In cases where a model has no tuning parameters is mapped to one of the
tuning functions, <code><a href="tune.html#topic+fit_resamples">tune::fit_resamples()</a></code> will be used instead and a
warning is issued if <code>verbose = TRUE</code>.
</p>
<p>If a workflow requires packages that are not installed, a message is printed
and <code>workflow_map()</code> continues with the next workflow (if any).
</p>


<h3>Value</h3>

<p>An updated workflow set. The <code>option</code> column will be updated with
any options for the <code>tune</code> package functions given to <code>workflow_map()</code>. Also,
the results will be added to the <code>result</code> column. If the computations for a
workflow fail, a <code>try-catch</code> object will be saved in place of the results
(without stopping execution).
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+workflow_set">workflow_set()</a></code>, <code><a href="#topic+as_workflow_set">as_workflow_set()</a></code>, <code><a href="#topic+extract_workflow_set_result">extract_workflow_set_result()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(workflowsets)
library(workflows)
library(modeldata)
library(recipes)
library(parsnip)
library(dplyr)
library(rsample)
library(tune)
library(yardstick)
library(dials)

# An example of processed results
chi_features_res

# Recreating them:

# ---------------------------------------------------------------------------
data(Chicago)
Chicago &lt;- Chicago[1:1195,]

time_val_split &lt;-
   sliding_period(
      Chicago,
      date,
      "month",
      lookback = 38,
      assess_stop = 1
   )

# ---------------------------------------------------------------------------

base_recipe &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   step_holiday(date) %&gt;%
   # remove date from the list of predictors
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors()) %&gt;%
   step_normalize(all_predictors())

date_only &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors())

date_and_holidays &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   step_holiday(date) %&gt;%
   # remove date from the list of predictors
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors())

date_and_holidays_and_pca &lt;-
   recipe(ridership ~ ., data = Chicago) %&gt;%
   # create date features
   step_date(date) %&gt;%
   step_holiday(date) %&gt;%
   # remove date from the list of predictors
   update_role(date, new_role = "id") %&gt;%
   # create dummy variables from factor columns
   step_dummy(all_nominal()) %&gt;%
   # remove any columns with a single unique value
   step_zv(all_predictors()) %&gt;%
   step_pca(!!stations, num_comp = tune())

# ---------------------------------------------------------------------------

lm_spec &lt;- linear_reg() %&gt;% set_engine("lm")

# ---------------------------------------------------------------------------

pca_param &lt;-
   parameters(num_comp()) %&gt;%
   update(num_comp = num_comp(c(0, 20)))

# ---------------------------------------------------------------------------

chi_features_set &lt;-
   workflow_set(
      preproc = list(date = date_only,
                     plus_holidays = date_and_holidays,
                     plus_pca = date_and_holidays_and_pca),
      models = list(lm = lm_spec),
      cross = TRUE
   )

# ---------------------------------------------------------------------------

chi_features_res_new &lt;-
   chi_features_set %&gt;%
   option_add(param_info = pca_param, id = "plus_pca_lm") %&gt;%
   workflow_map(resamples = time_val_split, grid = 21, seed = 1, verbose = TRUE)

chi_features_res_new

</code></pre>

<hr>
<h2 id='workflow_set'>Generate a set of workflow objects from preprocessing and model objects</h2><span id='topic+workflow_set'></span>

<h3>Description</h3>

<p>Often a data practitioner needs to consider a large number of possible
modeling approaches for a task at hand, especially for new data sets
and/or when there is little knowledge about what modeling strategy
will work best. Workflow sets provide an expressive interface for
investigating multiple models or feature engineering strategies in such
a situation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>workflow_set(preproc, models, cross = TRUE, case_weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="workflow_set_+3A_preproc">preproc</code></td>
<td>
<p>A list (preferably named) with preprocessing objects:
formulas, recipes, or <code><a href="workflows.html#topic+add_variables">workflows::workflow_variables()</a></code>.</p>
</td></tr>
<tr><td><code id="workflow_set_+3A_models">models</code></td>
<td>
<p>A list (preferably named) of <code>parsnip</code> model specifications.</p>
</td></tr>
<tr><td><code id="workflow_set_+3A_cross">cross</code></td>
<td>
<p>A logical: should all combinations of the preprocessors and
models be used to create the workflows? If <code>FALSE</code>, the length of <code>preproc</code>
and <code>models</code> should be equal.</p>
</td></tr>
<tr><td><code id="workflow_set_+3A_case_weights">case_weights</code></td>
<td>
<p>A single unquoted column name specifying the case
weights for the models. This must be a classed case weights column, as
determined by <code><a href="hardhat.html#topic+is_case_weights">hardhat::is_case_weights()</a></code>. See the &quot;Case weights&quot; section
below for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The preprocessors that can be combined with the model objects can be one or
more of:
</p>

<ul>
<li><p> A traditional R formula.
</p>
</li>
<li><p> A recipe definition (un-prepared) via <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>.
</p>
</li>
<li><p> A selectors object created by <code><a href="workflows.html#topic+add_variables">workflows::workflow_variables()</a></code>.
</p>
</li></ul>

<p>Since <code>preproc</code> is a named list column, any combination of these can be
used in that argument (i.e., <code>preproc</code> can be mixed types).
</p>


<h3>Value</h3>

<p>A tibble with extra class 'workflow_set'. A new set includes four
columns (but others can be added):
</p>

<ul>
<li> <p><code>wflow_id</code> contains character strings for the preprocessor/workflow
combination. These can be changed but must be unique.
</p>
</li>
<li> <p><code>info</code> is a list column with tibbles containing more specific information,
including any comments added using <code><a href="#topic+comment_add">comment_add()</a></code>. This tibble also
contains the workflow object (which can be easily retrieved using
<code><a href="#topic+extract_workflow">extract_workflow()</a></code>).
</p>
</li>
<li> <p><code>option</code> is a list column that will include a list of optional arguments
passed to the functions from the <code>tune</code> package. They can be added
manually via <code><a href="#topic+option_add">option_add()</a></code> or automatically when options are passed to
<code><a href="#topic+workflow_map">workflow_map()</a></code>.
</p>
</li>
<li> <p><code>result</code> is a list column that will contain any objects produced when
<code><a href="#topic+workflow_map">workflow_map()</a></code> is used.
</p>
</li></ul>



<h3>Case weights</h3>

<p>The <code>case_weights</code> argument can be passed as a single unquoted column name
identifying the data column giving model case weights. For each workflow
in the workflow set using an engine that supports case weights, the case
weights will be added with <code><a href="workflows.html#topic+add_case_weights">workflows::add_case_weights()</a></code>. <code>workflow_set()</code>
will warn if any of the workflows specify an engine that does not support
case weights&mdash;and ignore the case weights argument for those workflows&mdash;but
will not fail.
</p>
<p>Read more about case weights in the tidymodels at <code>?parsnip::case_weights</code>.
</p>


<h3>Note</h3>

<p>The package supplies two pre-generated workflow sets, <code>two_class_set</code>
and <code>chi_features_set</code>, and associated sets of model fits
<code>two_class_res</code> and <code>chi_features_res</code>.
</p>
<p>The <code style="white-space: pre;">&#8288;two_class_*&#8288;</code> objects are based on a binary classification problem
using the <code>two_class_dat</code> data from the modeldata package. The six
models utilize either a bare formula or a basic recipe utilizing
<code>recipes::step_YeoJohnson()</code> as a preprocessor, and a decision tree,
logistic regression, or MARS model specification. See <code>?two_class_set</code>
for source code.
</p>
<p>The <code style="white-space: pre;">&#8288;chi_features_*&#8288;</code> objects are based on a regression problem using the
<code>Chicago</code> data from the modeldata package. Each of the three models
utilize a linear regression model specification, with three different
recipes of varying complexity. The objects are meant to approximate the
sequence of models built in Section 1.3 of Kuhn and Johnson (2019). See
<code>?chi_features_set</code> for source code.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+workflow_map">workflow_map()</a></code>, <code><a href="#topic+comment_add">comment_add()</a></code>, <code><a href="#topic+option_add">option_add()</a></code>,
<code><a href="#topic+as_workflow_set">as_workflow_set()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(workflowsets)
library(workflows)
library(modeldata)
library(recipes)
library(parsnip)
library(dplyr)
library(rsample)
library(tune)
library(yardstick)

# ------------------------------------------------------------------------------

data(cells)
cells &lt;- cells %&gt;% dplyr::select(-case)

set.seed(1)
val_set &lt;- validation_split(cells)

# ------------------------------------------------------------------------------

basic_recipe &lt;-
  recipe(class ~ ., data = cells) %&gt;%
  step_YeoJohnson(all_predictors()) %&gt;%
  step_normalize(all_predictors())

pca_recipe &lt;-
  basic_recipe %&gt;%
  step_pca(all_predictors(), num_comp = tune())

ss_recipe &lt;-
  basic_recipe %&gt;%
  step_spatialsign(all_predictors())

# ------------------------------------------------------------------------------

knn_mod &lt;-
  nearest_neighbor(neighbors = tune(), weight_func = tune()) %&gt;%
  set_engine("kknn") %&gt;%
  set_mode("classification")

lr_mod &lt;-
  logistic_reg() %&gt;%
  set_engine("glm")

# ------------------------------------------------------------------------------

preproc &lt;- list(none = basic_recipe, pca = pca_recipe, sp_sign = ss_recipe)
models &lt;- list(knn = knn_mod, logistic = lr_mod)

cell_set &lt;- workflow_set(preproc, models, cross = TRUE)
cell_set

# ------------------------------------------------------------------------------
# Using variables and formulas

# Select predictors by their names
channels &lt;- paste0("ch_", 1:4)
preproc &lt;- purrr::map(channels, ~ workflow_variables(class, c(contains(!!.x))))
names(preproc) &lt;- channels
preproc$everything &lt;- class ~ .
preproc

cell_set_by_group &lt;- workflow_set(preproc, models["logistic"])
cell_set_by_group

</code></pre>

<hr>
<h2 id='workflowsets-package'>workflowsets: Create a Collection of 'tidymodels' Workflows</h2><span id='topic+workflowsets'></span><span id='topic+workflowsets-package'></span>

<h3>Description</h3>

<p>A workflow is a combination of a model and preprocessors (e.g, a formula, recipe, etc.) (Kuhn and Silge (2021) <a href="https://www.tmwr.org/">https://www.tmwr.org/</a>). In order to try different combinations of these, an object can be created that contains many workflows. There are functions to create workflows en masse as well as training them and visualizing the results.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Simon Couch <a href="mailto:simon.couch@posit.co">simon.couch@posit.co</a> (<a href="https://orcid.org/0000-0001-5676-5107">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Max Kuhn <a href="mailto:max@posit.co">max@posit.co</a> (<a href="https://orcid.org/0000-0003-2402-136X">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tidymodels/workflowsets">https://github.com/tidymodels/workflowsets</a>
</p>
</li>
<li> <p><a href="https://workflowsets.tidymodels.org">https://workflowsets.tidymodels.org</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/workflowsets/issues">https://github.com/tidymodels/workflowsets/issues</a>
</p>
</li></ul>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
