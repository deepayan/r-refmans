<!DOCTYPE html><html><head><title>Help for package esaddle</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {esaddle}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#demvn'><p>Evaluate the density of a multivariate Gaussian fit</p></a></li>
<li><a href='#dsaddle'><p>Evaluating the Extended Empirical Saddlepoint (EES) density</p></a></li>
<li><a href='#ecgf'><p>Cumulant generating function estimation</p></a></li>
<li><a href='#findMode'><p>Finding the mode of the empirical saddlepoint density</p></a></li>
<li><a href='#robCov'><p>Robust covariance matrix estimation</p></a></li>
<li><a href='#rsaddle'><p>Simulate random variables from the Extended Empirical Saddlepoint density (ESS)</p></a></li>
<li><a href='#selectDecay'><p>Tuning the Extended Empirical Saddlepoint (EES) density by cross-validation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Extended Empirical Saddlepoint Density Approximations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-04-25</td>
</tr>
<tr>
<td>Author:</td>
<td>Matteo Fasiolo and Simon N. Wood</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for fitting the Extended Empirical Saddlepoint (EES) density of Fasiolo et al. (2018) &lt;<a href="https://doi.org/10.1214%2F18-EJS1433">doi:10.1214/18-EJS1433</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mfasiolo/esaddle">https://github.com/mfasiolo/esaddle</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>compiler, stats, graphics, parallel, plyr, doParallel, mvnfast</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, testthat</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-04-26 14:18:54 UTC; mf15002</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-26 14:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='demvn'>Evaluate the density of a multivariate Gaussian fit</h2><span id='topic+demvn'></span>

<h3>Description</h3>

<p>Given a sample X, it gives a pointwise evaluation of the multivariate normal (MVN) density fit at position y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>demvn(y, X, log = FALSE, verbose = TRUE, alpha = 2, beta = 1.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="demvn_+3A_y">y</code></td>
<td>
<p>points at which the MVN is evaluated. It can be either a d-dimensional vector or an n by d matrix, 
each row indicating a different position.</p>
</td></tr>
<tr><td><code id="demvn_+3A_x">X</code></td>
<td>
<p>an n by d matrix containing the data.</p>
</td></tr>
<tr><td><code id="demvn_+3A_log">log</code></td>
<td>
<p>if TRUE the log-density is returned.</p>
</td></tr>
<tr><td><code id="demvn_+3A_verbose">verbose</code></td>
<td>
<p>currently not used.</p>
</td></tr>
<tr><td><code id="demvn_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter of <code>robCov</code>, see <code>?robCov</code> for details.</p>
</td></tr>
<tr><td><code id="demvn_+3A_beta">beta</code></td>
<td>
<p>tuning parameter of <code>robCov</code>, see <code>?robCov</code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The covariance matrix is estimated robustly, using the <code>robCov</code> function.
</p>


<h3>Value</h3>

<p>A vector where the i-th entry is the density corresponding to the i-th row of y.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt; and Simon N. Wood.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(esaddle)
X &lt;- matrix(rnorm(2 * 1e3), 1e3, 2) # Sample used to fit a multivariate Gaussian
demvn(rnorm(2), X, log = TRUE)      # Evaluate the fitted log-density at a random location
</code></pre>

<hr>
<h2 id='dsaddle'>Evaluating the Extended Empirical Saddlepoint (EES) density</h2><span id='topic+dsaddle'></span>

<h3>Description</h3>

<p>Gives a pointwise evaluation of the EES density (and optionally of its gradient) at one or more 
locations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsaddle(
  y,
  X,
  decay,
  deriv = FALSE,
  log = FALSE,
  normalize = FALSE,
  control = list(),
  multicore = !is.null(cluster),
  ncores = detectCores() - 1,
  cluster = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsaddle_+3A_y">y</code></td>
<td>
<p>points at which the EES is evaluated (d dimensional vector) or an n by d matrix, each row indicating
a different position.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_x">X</code></td>
<td>
<p>n by d matrix containing the data.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_decay">decay</code></td>
<td>
<p>rate at which the EES falls back on a normal density approximation, fitted to <code>X</code>. 
It must be a positive number, and it is inversely proportional to the complexity of the fit.
Setting it to <code>Inf</code> leads to a Gaussian fit.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_deriv">deriv</code></td>
<td>
<p>If TRUE also the gradient of the log-saddlepoint density is returned.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_log">log</code></td>
<td>
<p>If TRUE the log of the saddlepoint density is returned.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_normalize">normalize</code></td>
<td>
<p>If TRUE the normalizing constant of the EES density will be computed. FALSE by 
default.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_control">control</code></td>
<td>
<p>A list of control parameters with entries:
</p>

<ul>
<li> <p><code>method</code> the method used to calculate the normalizing constant. 
Either &quot;LAP&quot; (laplace approximation) or &quot;IS&quot; (importance sampling).
</p>
</li>
<li> <p><code>nNorm</code> if control$method == &quot;IS&quot;, this is the number of importance samples used.
</p>
</li>
<li> <p><code>tol</code> the tolerance used to assess the convergence of the solution to the saddlepoint equation.
The default is 1e-6.
</p>
</li>
<li> <p><code>maxit</code> maximal number of iterations used to solve the saddlepoint equation.
The default is 100;
</p>
</li>
<li> <p><code>ml</code> Relevant only if <code>control$method=="IS"</code>. n random variables are generated from 
a Gaussian importance density with covariance matrix <code>ml*cov(X)</code>. 
By default the inflation factor is <code>ml=2</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="dsaddle_+3A_multicore">multicore</code></td>
<td>
<p>if TRUE the empirical saddlepoint density at each row of y will be evaluated in parallel.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to be used.</p>
</td></tr>
<tr><td><code id="dsaddle_+3A_cluster">cluster</code></td>
<td>
<p>an object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries:
</p>

<ul>
<li> <p><code>llk</code> the value of the EES log-density at each location y;
</p>
</li>
<li> <p><code>mix</code> for each location y, the fraction of saddlepoint used: 
1 means that only ESS is used and 0 means that only a Gaussian fit is used;
</p>
</li>
<li> <p><code>iter</code> for each location y, the number of iteration needed to solve the 
saddlepoint equation;
</p>
</li>
<li> <p><code>lambda</code> an n by d matrix, where the i-th row is the solution of the saddlepoint 
equation corresponding to the i-th row of y;
</p>
</li>
<li> <p><code>grad</code> the gradient of the log-density at y (optional);
</p>
</li>
<li> <p><code>logNorm</code> the estimated log normalizing constant (optional);
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt; and Simon N. Wood.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S. N., Hartig, F. and Bravington, M. V. (2016). 
An Extended Empirical Saddlepoint Approximation for Intractable Likelihoods. ArXiv http://arxiv.org/abs/1601.01849.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(esaddle)

### Simple univariate example
set.seed(4141)
x &lt;- rgamma(1000, 2, 1)

# Evaluating EES at several point
xSeq &lt;- seq(-2, 8, length.out = 200)
tmp &lt;- dsaddle(y = xSeq, X = x, decay = 0.05, log = TRUE)  # Un-normalized EES
tmp2 &lt;- dsaddle(y = xSeq, X = x, decay = 0.05,             # EES normalized by importance sampling
                normalize = TRUE, control = list("method" = "IS", nNorm = 500), log = TRUE)

# Plotting true density, EES and normal approximation
plot(xSeq, exp(tmp$llk), type = 'l', ylab = "Density", xlab = "x")
lines(xSeq, dgamma(xSeq, 2, 1), col = 3)
lines(xSeq, dnorm(xSeq, mean(x), sd(x)), col = 2)
lines(xSeq, exp(tmp2$llk), col = 4)
suppressWarnings( rug(x) )
legend("topright", c("EES un-norm", "EES normalized", "Truth", "Gaussian"), 
        col = c(1, 4, 3, 2), lty = 1)
</code></pre>

<hr>
<h2 id='ecgf'>Cumulant generating function estimation</h2><span id='topic+ecgf'></span>

<h3>Description</h3>

<p>Calculates the empirical cumulant generating function (CGF) and its derivatives
given a sample of n d-dimentional vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecgf(lambda, X, mix, grad = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecgf_+3A_lambda">lambda</code></td>
<td>
<p>point at which the empirical CGF is evaluated (d-dimensional vector).</p>
</td></tr>
<tr><td><code id="ecgf_+3A_x">X</code></td>
<td>
<p>an n by d matrix containing the data.</p>
</td></tr>
<tr><td><code id="ecgf_+3A_mix">mix</code></td>
<td>
<p>fraction of empirical and normal CGF to use. If <code>mix==1</code> only the empirical CGF is used, 
if <code>mix==0</code> only the normal CGF is used.</p>
</td></tr>
<tr><td><code id="ecgf_+3A_grad">grad</code></td>
<td>
<p>if <code>grad==0</code> only the value of the CGF at <code>lambda</code> is returned, 
if <code>grad==1</code> also its first derivative wrt <code>lambda</code> 
and <code>if grad==2</code> also the second derivarive wrt <code>lambda</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on the CGF estimator being used here, see Fasiolo et al. (2016).
</p>


<h3>Value</h3>

<p>A list with entries:
</p>

<ul>
<li> <p><code>K</code> the value of the empirical CGF at <code>lambda</code>;
</p>
</li>
<li> <p><code>dK</code> the value of the gradient empirical CGF wrt lambda at <code>lambda</code>;
</p>
</li>
<li> <p><code>d2K</code> the value of the hessian of the empirical CGF wrt lambda at <code>lambda</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt; and Simon N. Wood.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S. N., Hartig, F. and Bravington, M. V. (2016). 
An Extended Empirical Saddlepoint Approximation for Intractable Likelihoods. ArXiv http://arxiv.org/abs/1601.01849.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(2 * 1e3), 1e3, 2)
K &lt;- ecgf(lambda = c(0, 0), X = X, mix = 0.5, grad = 2) 
K$K # CGF
K$dK # CGF' (gradient)
K$d2K # CGF'' (Hessian)
</code></pre>

<hr>
<h2 id='findMode'>Finding the mode of the empirical saddlepoint density</h2><span id='topic+findMode'></span>

<h3>Description</h3>

<p>Given a sample from a d-dimensional distribution, the routine
finds the mode of the corresponding Extended Empirical Saddlepoint (EES) density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findMode(
  X,
  decay,
  init = NULL,
  method = "BFGS",
  hess = FALSE,
  sadControl = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findMode_+3A_x">X</code></td>
<td>
<p>an n by d matrix containing the data.</p>
</td></tr>
<tr><td><code id="findMode_+3A_decay">decay</code></td>
<td>
<p>rate at which the SPA falls back on a normal density. Should be a positive number. See Fasiolo et al. (2016)
for details.</p>
</td></tr>
<tr><td><code id="findMode_+3A_init">init</code></td>
<td>
<p>d-dimensional vector containing the starting point for the optimization. By default
it is equal to <code>colMeans(X)</code>.</p>
</td></tr>
<tr><td><code id="findMode_+3A_method">method</code></td>
<td>
<p>optimization method used by <code>stats::optim()</code>, see ?optim for details. By default it is &quot;BFGS&quot;.</p>
</td></tr>
<tr><td><code id="findMode_+3A_hess">hess</code></td>
<td>
<p>if TRUE also an estimate of the Hessian at the mode will be returned.</p>
</td></tr>
<tr><td><code id="findMode_+3A_sadcontrol">sadControl</code></td>
<td>
<p>list corresponding to the <code>control</code> argument in the <code>dsaddle</code> function.</p>
</td></tr>
<tr><td><code id="findMode_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to the optimization routine <code>stats::optim</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where <code>mode</code> is the location of mode of the empirical saddlepoint density,
<code>logDens</code> is the log-density at the mode and <code>hess</code> (present only if argument <code>hess==TRUE</code>)
is the approximate Hessian at convergence. The other entries are the same as for <code>stats::optim</code>.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S. N., Hartig, F. and Bravington, M. V. (2016). 
An Extended Empirical Saddlepoint Approximation for Intractable Likelihoods. ArXiv http://arxiv.org/abs/1601.01849.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># library(esaddle)
set.seed(4141)
x &lt;- rgamma(1000, 2, 1)

# Fixing tuning parameter of EES
decay &lt;-  0.05

# Evaluating EES at several point
xSeq &lt;- seq(-2, 8, length.out = 200)
tmp &lt;- dsaddle(y = xSeq, X = x, decay = decay, log = TRUE)  # Un-normalized EES

# Plotting true density, EES and normal approximation
plot(xSeq, exp(tmp$llk), type = 'l', ylab = "Density", xlab = "x")
lines(xSeq, dgamma(xSeq, 2, 1), col = 3)
suppressWarnings( rug(x) )
legend("topright", c("EES", "Truth"), col = c(1, 3), lty = 1)

# Find mode and plot it
res &lt;- findMode(x, init = mean(x), decay = decay)$mode
abline(v = res, lty = 2, lwd = 1.5)
</code></pre>

<hr>
<h2 id='robCov'>Robust covariance matrix estimation</h2><span id='topic+robCov'></span>

<h3>Description</h3>

<p>Obtains a robust estimate of the covariance matrix of a sample of multivariate data, 
using Campbell's (1980) method as described on p231-235 of Krzanowski (1988).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robCov(sY, alpha = 2, beta = 1.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="robCov_+3A_sy">sY</code></td>
<td>
<p>A matrix, where each column is a replicate observation on a multivariate r.v.</p>
</td></tr>
<tr><td><code id="robCov_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter, see details.</p>
</td></tr>
<tr><td><code id="robCov_+3A_beta">beta</code></td>
<td>
<p>tuning parameter, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Campbell (1980) suggests an estimator of the covariance matrix which downweights observations 
at more than some Mahalanobis distance <code>d.0</code> from the mean.
<code>d.0</code> is <code>sqrt(nrow(sY))+alpha/sqrt(2)</code>. Weights are one for observations 
with Mahalanobis distance, <code>d</code>, less than <code>d.0</code>. Otherwise weights are 
<code>d.0*exp(-.5*(d-d.0)^2/beta^2)/d</code>. The defaults are as recommended by Campbell.
This routine also uses pre-conditioning to ensure good scaling and stable 
numerical calculations. If some of the columns of <code>sY</code> has zero variance, these
are removed.
</p>


<h3>Value</h3>

<p>A list where:
</p>

<ul>
<li><p><code>COV</code> The estimated covariance matrix.
</p>
</li>
<li><p><code>E</code> A square root of the inverse covariance matrix. i.e. the inverse cov 
matrix is <code>t(E)%*%E</code>;
</p>
</li>
<li><p><code>half.ldet.V</code> Half the log of the determinant of the covariance matrix;
</p>
</li>
<li><p><code>mY</code> The estimated mean; 
</p>
</li>
<li><p><code>sd</code> The estimated standard deviations of each variable.
</p>
</li>
<li><p><code>weights</code> This is <code>w1/sum(w1)*ncol(sY)</code>, where <code>w1</code> are the weights of Campbell (1980).
</p>
</li>
<li><p><code>lowVar</code> The indexes of the columns of <code>sY</code> whose variance is zero (if any). These 
variable were removed and excluded from the covariance matrix. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Simon N. Wood, maintained by Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Krzanowski, W.J. (1988) Principles of Multivariate Analysis. Oxford.
Campbell, N.A. (1980) Robust procedures in multivariate analysis I: robust covariance estimation. JRSSC 29, 231-237.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- 5;n &lt;- 100
Y &lt;- matrix(runif(p*n),p,n)
robCov(Y)
</code></pre>

<hr>
<h2 id='rsaddle'>Simulate random variables from the Extended Empirical Saddlepoint density (ESS)</h2><span id='topic+rsaddle'></span>

<h3>Description</h3>

<p>Simulate random variables from the Extended Empirical Saddlepoint density (ESS), using importance 
sampling and then resampling according to the importance weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsaddle(
  n,
  X,
  decay,
  ml = 2,
  multicore = !is.null(cluster),
  cluster = NULL,
  ncores = detectCores() - 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsaddle_+3A_n">n</code></td>
<td>
<p>number of simulated vectors.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_x">X</code></td>
<td>
<p>an m by d matrix containing the data.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_decay">decay</code></td>
<td>
<p>rate at which the ESS falls back on a normal density. Should be a positive number. See Fasiolo et al. (2016)
for details.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_ml">ml</code></td>
<td>
<p>n random variables are generated from a Gaussian importance density with covariance matrix 
<code>ml*cov(X)</code>. By default the inflation factor is <code>ml=2</code>.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_multicore">multicore</code></td>
<td>
<p>if TRUE the ESS densities corresponding the samples will be evaluated in parallel.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_cluster">cluster</code></td>
<td>
<p>an object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to be used.</p>
</td></tr>
<tr><td><code id="rsaddle_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>dsaddle</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Notice that, while importance sampling is used, the output is a matrix of unweighted samples, obtained by resampling
with probabilities proportional to the importance weights.
</p>


<h3>Value</h3>

<p>An n by d matrix containing the simulated vectors.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S. N., Hartig, F. and Bravington, M. V. (2016). 
An Extended Empirical Saddlepoint Approximation for Intractable Likelihoods. ArXiv http://arxiv.org/abs/1601.01849.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate bivariate data, where each marginal distribution is Exp(2)
X &lt;- matrix(rexp(2 * 1e3), 1e3, 2)

# Simulate bivariate data from a saddlepoint fitted to X
Z &lt;- rsaddle(1000, X, decay = 0.5)

# Look at first marginal distribution
hist( Z[ , 1] )
</code></pre>

<hr>
<h2 id='selectDecay'>Tuning the Extended Empirical Saddlepoint (EES) density by cross-validation</h2><span id='topic+selectDecay'></span>

<h3>Description</h3>

<p>Performs k-fold cross-validation to choose the EES's tuning parameter,
which determines the mixture between a consistent and a Gaussian estimator
of the Cumulant Generating Function (CGF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectDecay(
  decay,
  simulator,
  K,
  nrep = 1,
  normalize = FALSE,
  draw = TRUE,
  multicore = !is.null(cluster),
  cluster = NULL,
  ncores = detectCores() - 1,
  control = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectDecay_+3A_decay">decay</code></td>
<td>
<p>Numeric vector containing the possible values of the tuning parameter.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_simulator">simulator</code></td>
<td>
<p>Function with prototype <code>function(...)</code> that will be called <code>nrep</code> times
to simulate <code>d</code>-dimensional random variables. 
Each time <code>simulator</code> is called, it will return a <code>n</code> by <code>d</code> matrix.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_k">K</code></td>
<td>
<p>the number of folds to be used in cross-validation.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_nrep">nrep</code></td>
<td>
<p>Number of times the whole cross-validation procedure will be repeated, by calling
<code>simulator</code> to generate random variable and computing the cross-validation score
for every element of the <code>decay</code> vector.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE the normalizing constant of EES is normalized at each value of <code>decay</code>.
FALSE by default.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_draw">draw</code></td>
<td>
<p>if <code>TRUE</code> the results of cross-validation will be plotted. <code>TRUE</code> by default.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_multicore">multicore</code></td>
<td>
<p>if TRUE each fold will run on a different core.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_cluster">cluster</code></td>
<td>
<p>an object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to be used.</p>
</td></tr>
<tr><td><code id="selectDecay_+3A_control">control</code></td>
<td>
<p>a list of control parameters, with entries:
</p>

<ul>
<li> <p><code>method</code> The method used to calculate the normalizing constant. 
Either &quot;LAP&quot; (laplace approximation) or &quot;IS&quot; (importance sampling).
</p>
</li>
<li> <p><code>tol</code> The tolerance used to assess the convergence of the solution to the saddlepoint equation.
The default is 1e-6.
</p>
</li>
<li> <p><code>nNorm</code>  Number of simulations to be used in order to estimate the normalizing constant of the saddlepoint density.
By default equal to 1e3.
</p>
</li>
<li> <p><code>ml</code>   if <code>method=="IS"</code> <code>nNorm</code>, random variables are generated from a Gaussian importance density 
with covariance matrix <code>ml*cov(X)</code>. By default the inflation factor is <code>ml=2</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="selectDecay_+3A_...">...</code></td>
<td>
<p>extra arguments to be passed to <code>simulator</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries:
</p>

<ul>
<li> <p><code>negLogLik</code> A matrix <code>length{decay}</code> by <code>K*nrep</code> where the i-th row represent the negative loglikelihood
estimated for the i-th value of <code>decay</code>, while each column represents a different fold and repetition.
</p>
</li>
<li> <p><code>summary</code>  A matrix of summary results from the cross-validation procedure.  
</p>
</li>
<li> <p><code>normConst</code>  A matrix <code>length{decay}</code> by <code>nrep</code> where the i-th row contains the estimates of the normalizing constant.
</p>
</li></ul>

<p>The list is returned invisibly. If <code>control$draw == TRUE</code> the function will also plot the cross-validation curve.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S. N., Hartig, F. and Bravington, M. V. (2016). 
An Extended Empirical Saddlepoint Approximation for Intractable Likelihoods. ArXiv http://arxiv.org/abs/1601.01849.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(esaddle)
# The data is far from normal: saddlepoint is needed and we expect 
# cross validation to be minimized at low "decay"
set.seed(4124)
selectDecay(decay = c(0.001, 0.01, 0.05, 0.1, 0.5, 1), 
            simulator = function(...) rgamma(500, 2, 1), 
            K = 5)
            
# The data is far from normal: saddlepoint is not needed and we expect 
#  the curve to be fairly flat for high "decay"
selectDecay(decay = c(0.001, 0.01, 0.05, 0.1, 0.5, 1), 
            simulator = function(...) rnorm(500, 0, 1), 
            K = 5)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
