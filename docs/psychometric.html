<!DOCTYPE html><html><head><title>Help for package psychometric</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {psychometric}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#psychometric-package'>
<p>Applied Psychometric Theory</p></a></li>
<li><a href='#ABHt32'><p>Table 3.2 from Arthur et al</p></a></li>
<li><a href='#alpha'><p> Cronbach's Coefficient Alpha</p></a></li>
<li><a href='#alpha.CI'><p> Confidence Interval for Coefficient Alpha</p></a></li>
<li><a href='#artifacts'><p> Artifact Distribtutions Used in Meta-Analysis</p></a></li>
<li><a href='#CAFAA'><p> Compound Attenuation Factor for Meta-Analytic Artifact Corrections</p></a></li>
<li><a href='#CI.Rsq'><p> Confidence Interval for R-squared</p></a></li>
<li><a href='#CI.Rsqlm'><p> Confidence Interval for Rsq - from lm()</p></a></li>
<li><a href='#CI.tscore'><p> Confidence Intervals for Test Scores</p></a></li>
<li><a href='#CIr'><p> Confidence Interval for a Correlation Coefficient</p></a></li>
<li><a href='#CIrb'><p> Confidence Interval about Sample Weighted Mean Correlation</p></a></li>
<li><a href='#CIrdif'><p> Confidence Interval for the difference in Correlation Coefficients</p></a></li>
<li><a href='#CIz'><p> Confidence Interval for Fisher z'</p></a></li>
<li><a href='#ClassUtil'><p> Classical Utility of a Test</p></a></li>
<li><a href='#CredIntRho'><p> Credibility Interval for Meta-Analytic Rho</p></a></li>
<li><a href='#cRRr'><p> Correction for Range Restriction</p></a></li>
<li><a href='#CVF'><p> Compound Variance Factor for Meta-Analytic Artifact Corrections</p></a></li>
<li><a href='#CVratio'><p> Content Validity Ratio</p></a></li>
<li><a href='#discrim'><p> Item Discrimination</p></a></li>
<li><a href='#EnterMeta'><p> Enter Meta-Analysis Data</p></a></li>
<li><a href='#Est.true'><p> Estimation of a True Score</p></a></li>
<li><a href='#FileDrawer'><p> File Drawer N</p></a></li>
<li><a href='#FunnelPlot'><p> Funnel Plot for Meta-Analysis</p></a></li>
<li><a href='#HSJt35'><p> Table 3.5 Hunter et al.</p></a></li>
<li><a href='#ICC.CI'><p> Confidence interval for the Intra-class Correlation</p></a></li>
<li><a href='#ICC.lme'><p> Intraclass Correlation Coefficient from a Mixed-Effects Model</p></a></li>
<li><a href='#item.exam'><p> Item Analysis</p></a></li>
<li><a href='#MetaTable'><p> Summary function for 'Complete' Meta-Analysis</p></a></li>
<li><a href='#pvaaa'><p> Percent of Variance Accounted for by Artifacts in Rho</p></a></li>
<li><a href='#pvse'><p> Percent of variance due to sampling error</p></a></li>
<li><a href='#Qrbar'><p> Meta-Analytic Q statistic for r-bar</p></a></li>
<li><a href='#Qrho'><p> Meta-Analytic Q statistic for rho</p></a></li>
<li><a href='#r.nil'><p> Nil hypothesis for a correlation</p></a></li>
<li><a href='#r2z'><p> Fisher r to z'</p></a></li>
<li><a href='#rbar'><p> Sample size weighted mean correlation</p></a></li>
<li><a href='#rdif.nul'><p> Null hypothesis for difference in two correlations</p></a></li>
<li><a href='#rhoCA'><p> Meta-Analytically Derived Correlation Coefficient Corrected for Artifacts</p></a></li>
<li><a href='#SE.Meas'><p> Standard Errors of Measurement (test scores)</p></a></li>
<li><a href='#SErbar'><p> Standard Error for Sample Size Weighted Mean Correlation</p></a></li>
<li><a href='#SEz'><p> Standard Error of Fishers z prime</p></a></li>
<li><a href='#SpearmanBrown'><p> Spearman-Brown Prophecy Formulae</p></a></li>
<li><a href='#TestScores'><p>Fictitious Test Scores for Illustrative Purposes</p></a></li>
<li><a href='#Utility'><p> Marginal and Total Utility of a Test</p></a></li>
<li><a href='#varAV'><p> Variance Due to Attenuating Artifacts</p></a></li>
<li><a href='#vare'><p> Sampling Error Variance</p></a></li>
<li><a href='#varr'><p> Sample Size weighted variance</p></a></li>
<li><a href='#varRCA'><p> Variance in Meta-Analytic Rho</p></a></li>
<li><a href='#varRes'><p> Residual Variance in Meta-Analytic Correlation</p></a></li>
<li><a href='#varResT'><p> True residual variance in correlations</p></a></li>
<li><a href='#z2r'><p> Fisher z' to r</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Applied Psychometric Theory</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4</td>
</tr>
<tr>
<td>Depends:</td>
<td>dplyr, multilevel, purrr, nlme</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas D. Fletcher</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas D. Fletcher &lt;t.d.fletcher05@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions useful for correlation theory, 
    meta-analysis (validity-generalization), reliability, 
    item analysis, inter-rater reliability, and classical utility.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-05 19:26:31 UTC; jodydaniel</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-05 21:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='psychometric-package'>
Applied Psychometric Theory</h2><span id='topic+psychometric-package'></span><span id='topic+psychometric'></span><span id='topic+apt'></span>

<h3>Description</h3>

<p>Contains functions useful for correlation theory, meta-analysis (validity-generalization), 
reliability, item analysis, inter-rater reliability, and classical utility</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> psychometric </td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package </td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.4 </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (version 2.0 or later) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>This package corresponds to the basic concepts encountered in an introductory course in 
Psychometric Theory at the Graduate level. It is especially useful for Industrial/Organizational
Psychologists, but will be useful for any student or practitioner of psychometric theory. I originally
developed this package to correspond with concepts covered illustrated in PSYC 7429 at the 
University of MO - St. Louis course in Psychometric Theory.
</p>


<h3>Author(s)</h3>

<p>Thomas D. Fletcher<br />
Strategic Resources<br />
State Farm Insurance Cos.<br />
</p>
<p>Maintainer: Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> <br />
</p>


<h3>See Also</h3>

<p><code>multilevel-package</code>
<code>ltm-package</code>
<code>psy-package</code>
<code>polycor-package</code>
<code>nlme-package</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Convert Pearson r to Fisher z'
r2z (.51)
# Convert Fisher z' to r
z2r (.563)

# Construct a CI about a True Score
# Observed = 700, Test Ave. = 500, SD = 100, and reliability = .9
CI.tscore (700, 500, 100, .9)

# Compute the classical utility of a test
# Assuming base-rate = .5, selection ratio = .5 and rxy = .5
ClassUtil(rxy=.5, BR=.5, SR=.5)

# Examine test score items
data(TestScores)
item.exam(TestScores[,1:10], y = TestScores[,11], discrim=TRUE)

</code></pre>

<hr>
<h2 id='ABHt32'>Table 3.2 from Arthur et al</h2><span id='topic+ABHt32'></span>

<h3>Description</h3>

<p>These data are used as an example in ch. 3 of Conducting Meta-Analysis using SAS.
The data appear in table 3.1 and 3.2 on pages 66 and 68. The example data are 
useful in illustrating simple meta-analysis concepts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ABHt32)</code></pre>


<h3>Format</h3>

<p>A data frame with 10 observations on the following 7 variables.
</p>

<ul>
<li> <p><em>study</em> Study code
</p>
</li>
<li> <p><em>Rxy</em> Published Correlation
</p>
</li>
<li> <p><em>n</em> Sample Size
</p>
</li>
<li> <p><em>Rxx</em> Reliability of Predictor
</p>
</li>
<li> <p><em>Ryy</em> Reliability of Criterion
</p>
</li>
<li> <p><em>u</em> Range Restriction Ratio
</p>
</li>
<li> <p><em>moderator</em> Gender
</p>
</li></ul>


<h3>References</h3>

<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ABHt32)
str(ABHt32) 
rbar(ABHt32)
FunnelPlot(ABHt32) 
</code></pre>

<hr>
<h2 id='alpha'> Cronbach's Coefficient Alpha</h2><span id='topic+alpha'></span>

<h3>Description</h3>

<p>Coefficient alpha is a measure of internal consistency. It is a standard measure of 
reliability for tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alpha(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alpha_+3A_x">x</code></td>
<td>
<p> Data.frame or matrix object with rows corresponding individuals and columns to items </p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can specify any portion of a matrix or data.frame. For instance, if using a data.frame 
with numerous variables corresponding to items, one can specify subsets of those items. See examples
below. <br />
alpha &lt;- <code class="reqn">k/(k-1)*(1-SumSxi/Sx)</code> <br />
where k is the number of items, Sx is the standard deviaton of the total test, and SumSxi is the
sum of the standard deviations for each item. 
</p>


<h3>Value</h3>

<p>coefficient alpha</p>


<h3>Author(s)</h3>

<p>Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. 
<em>Psychometrika, 6,</em> 297-334.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+alpha.CI">alpha.CI</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(attitude)
alpha(attitude)
alpha(attitude[,1:5])
</code></pre>

<hr>
<h2 id='alpha.CI'> Confidence Interval for Coefficient Alpha</h2><span id='topic+alpha.CI'></span><span id='topic+CI.alpha'></span>

<h3>Description</h3>

<p>Computes a one-tailed (or two-tailed) CI at the desired level for coefficient alpha </p>


<h3>Usage</h3>

<pre><code class='language-R'>alpha.CI(alpha, k, N, level = 0.90, onesided = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alpha.CI_+3A_alpha">alpha</code></td>
<td>
<p> coefficient alpha to use for CI construction </p>
</td></tr>
<tr><td><code id="alpha.CI_+3A_k">k</code></td>
<td>
<p> number if items </p>
</td></tr>
<tr><td><code id="alpha.CI_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="alpha.CI_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .90 </p>
</td></tr>
<tr><td><code id="alpha.CI_+3A_onesided">onesided</code></td>
<td>
<p> return a one-sided (one-tailed) test, default is FALSE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>By inputting alpha, number of items and sample size, one can make inferences via 
a confidence interval. This can be used to compare two alpha coefficients (e.g., from 
two groups), or to compare alpha to some specified value (e.g., &gt; = .7). onesided = FALSE renders
a two-sided test (i.e., this is the difference between tails of .025/.975 and .05/.95)
</p>


<h3>Value</h3>

<p>Returns a table with 3 elements
</p>
<table>
<tr><td><code>LCL</code></td>
<td>
<p>lower confidence limit of CI</p>
</td></tr>
<tr><td><code>ALPHA</code></td>
<td>
<p>coefficient alpha</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p>upper confidence limit of CI</p>
</td></tr>
</table>


<h3> Warning </h3>

<p>You must first compute alpha and then enter into function. <code>alpha.CI</code>
will not evaluate a data.frame or matrix object. </p>


<h3>Note</h3>

<p> Feldt et al., provide a number of procedures for making inferences about alpha
(e.g., F test of the null hypothesis). Since the CI is the most versatile, it is the only function
created in this package </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a></p>


<h3>References</h3>

 
<p>Feldt, L. S., Woodruff, D. J., &amp; Salih, F. A. (1987). 
Statistical inferences for coefficient alpha. <em>Applied Psychological Measurement, 11,</em> 93-103. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+alpha">alpha</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Feldt et al (1987)
# alpha = .79, #items = 26, #examinees = 41
# a two-tailed test 90% level

alpha.CI(.79, 26, 41)

</code></pre>

<hr>
<h2 id='artifacts'> Artifact Distribtutions Used in Meta-Analysis</h2><span id='topic+aRxx'></span><span id='topic+bRyy'></span><span id='topic+cRR'></span>

<h3>Description</h3>

<p>Three artifact distributions are computed with each of these three
functions which are then used to correct the observed sample-weighted
mean correlation for attenuation. The artifacts are reliability in predictor, 
reliability in criterion, and range-restriction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aRxx(x)
bRyy(x)
cRR(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="artifacts_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxx, Ryy, and u: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><em>aRxx </em> Distribution of measurement error in the predictor: a = sqrt(Rxx)
</p>
</li>
<li> <p><em>bRyy </em> Distribution of measurement error in the criterion: b = sqrt(Ryy)
</p>
</li>
<li> <p><em>cRR </em> Degree of range restriction indicated by ratio u <br />
(restricted SD/unrestricted SD): <code class="reqn">c = sqrt((1-u^2)*rb^2+u^2) </code>. 
</p>
</li></ul>

<p>These are used in the computation of the compound attentuation factor <code><a href="#topic+CAFAA">CAFAA</a></code> = 
mean(a)*mean(b)*mean(c).
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr><td><code>ma</code></td>
<td>
<p> Mean of a (or b or c)</p>
</td></tr>
<tr><td><code>va</code></td>
<td>
<p> Variance of a (or b or c)</p>
</td></tr>
</table>


<h3>Note</h3>

<p> One usually will not use these functions alone, but rather use functions that make use of 
these correction factors. </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rhoCA">rhoCA</a></code>, <code><a href="#topic+varAV">varAV</a></code>, <code><a href="#topic+varResT">varResT</a></code>, <code><a href="#topic+pvaaa">pvaaa</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# From Arthur et al
data(ABHt32)
aRxx(ABHt32)
bRyy(ABHt32)
cRR(ABHt32)
rhoCA(ABHt32)

# From Hunter et al
data(HSJt35)
aRxx(HSJt35)
bRyy(HSJt35)
cRR(HSJt35)
rhoCA(HSJt35)

</code></pre>

<hr>
<h2 id='CAFAA'> Compound Attenuation Factor for Meta-Analytic Artifact Corrections </h2><span id='topic+CAFAA'></span>

<h3>Description</h3>

<p>The compound attenuation factor is computed as the product of the mean for each 
artifact distribution (square root of artifact) when correcting for attenuation 
in a correlation coefficient. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAFAA(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CAFAA_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxx, Ryy, and u: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compound attenuation factor is computed as the product of mean(a)*mean(b)*mean(c) where <br />
a = sqrt(Rxx) and is computed with the function <code><a href="#topic+aRxx">aRxx</a></code> <br />
b = sqrt(Ryy) and is computed with the function <code><a href="#topic+bRyy">bRyy</a></code> <br />
c = <code class="reqn">sqrt((1-u^2)*rbar^2+u^2)</code> and is computed with the function <code><a href="#topic+cRR">cRR</a></code> 
</p>


<h3>Value</h3>

<p>A numeric value representing the compound attenuation factor
</p>


<h3>Note</h3>

<p> This value is used in the correction for artifacts of a correlation coefficient  </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a></p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rhoCA">rhoCA</a></code>, <code><a href="#topic+aRxx">aRxx</a></code>, <code><a href="#topic+bRyy">bRyy</a></code>, <code><a href="#topic+cRR">cRR</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#From Arthur et al
data(ABHt32)
CAFAA(ABHt32)
rhoCA(ABHt32)

# From Hunter et al
data(HSJt35)
CAFAA(HSJt35)
rhoCA(HSJt35)

</code></pre>

<hr>
<h2 id='CI.Rsq'> Confidence Interval for R-squared </h2><span id='topic+CI.Rsq'></span>

<h3>Description</h3>

<p>Computes the confidence interval for a desired level for the squared-multiple correlation</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI.Rsq(rsq, n, k, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CI.Rsq_+3A_rsq">rsq</code></td>
<td>
<p> Squared Multiple Correlation </p>
</td></tr>
<tr><td><code id="CI.Rsq_+3A_n">n</code></td>
<td>
<p> Sample Size </p>
</td></tr>
<tr><td><code id="CI.Rsq_+3A_k">k</code></td>
<td>
<p> Number of Predictors in Model </p>
</td></tr>
<tr><td><code id="CI.Rsq_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95 </p>
</td></tr>
</table>


<h3>Details</h3>

<p>CI is constructed based on the approximate SE of Rsq <br />
<code class="reqn">sersq &lt;- sqrt((4*rsq*(1-rsq)^2*(n-k-1)^2)/((n^2-1)*(n+3)))</code>
</p>


<h3>Value</h3>

<p>Returns a table with 4 elements
</p>
<table>
<tr><td><code>Rsq</code></td>
<td>
<p> Squared Multiple Correlation</p>
</td></tr>
<tr><td><code>SErsq</code></td>
<td>
<p> Standard error of Rsq</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr></table>


<h3>Note</h3>

<p> This is an adequate approximation for n &gt; 60 </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Olkin, I. &amp; Finn, J. D. (1995). Correlation Redux. <em>Psychological Bulletin, 118</em>, 155-164.
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CI.Rsqlm">CI.Rsqlm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see section 3.6.2 Cohen et al (2003)
# 95 percent CI
CI.Rsq(.5032, 62, 4, level = .95)
# 80 percent CI
CI.Rsq(.5032, 62, 4, level = .80)

</code></pre>

<hr>
<h2 id='CI.Rsqlm'> Confidence Interval for Rsq - from lm() </h2><span id='topic+CI.Rsqlm'></span>

<h3>Description</h3>

<p>Computes the CI for a desired level based on an object of class lm() </p>


<h3>Usage</h3>

<pre><code class='language-R'>CI.Rsqlm(obj, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CI.Rsqlm_+3A_obj">obj</code></td>
<td>
<p> object of a linear model </p>
</td></tr>
<tr><td><code id="CI.Rsqlm_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95 </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extracts the necessary information from the linear model object 
and uses <code><a href="#topic+CI.Rsq">CI.Rsq</a></code></p>


<h3>Value</h3>

<p>Returns a table with 4 elements
</p>
<table>
<tr><td><code>Rsq</code></td>
<td>
<p> Squared Multiple Correlation</p>
</td></tr>
<tr><td><code>SErsq</code></td>
<td>
<p> Standard error of Rsq</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This is an adequate approximation for n &gt; 60 </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Olkin, I. &amp; Finn, J. D. (1995). Correlation Redux. <em>Psychological Bulletin, 118</em>, 155-164.
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CI.Rsq">CI.Rsq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate data 
x &lt;- rnorm(100)
z &lt;- rnorm(100)
xz &lt;- x*z
y &lt;- .25*x - .25*z + .25*x*z + .25*rnorm(100)
# Create an lm() object
lm1 &lt;- lm(y ~ x*z)
CI.Rsqlm(lm1)

</code></pre>

<hr>
<h2 id='CI.tscore'> Confidence Intervals for Test Scores </h2><span id='topic+CI.tscore'></span><span id='topic+CI.obs'></span>

<h3>Description</h3>

<p>Computes the CI for a desired level for observed scores and estimated true scores</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI.tscore(obs, mx, s, rxx, level = 0.95)

CI.obs(obs, s, rxx, level = 0.95)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CI.tscore_+3A_obs">obs</code></td>
<td>
<p> Observed test score on test x</p>
</td></tr>
<tr><td><code id="CI.tscore_+3A_mx">mx</code></td>
<td>
<p> mean of test x </p>
</td></tr>
<tr><td><code id="CI.tscore_+3A_s">s</code></td>
<td>
<p> standard deviation of test x </p>
</td></tr>
<tr><td><code id="CI.tscore_+3A_rxx">rxx</code></td>
<td>
<p> reliability of test x</p>
</td></tr>
<tr><td><code id="CI.tscore_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CI.tscore</code> makes use of <code><a href="#topic+Est.true">Est.true</a></code> to correct the observed score for 
regression to the mean and <code><a href="#topic+SE.Est">SE.Est</a></code> for the correct standard error. <code>CI.tscore</code>
also requires entry of the mean of the test scores for correcting for regression to the mean. <br />
<code>CI.obs</code> is much simpler in construction as it only makes use of the observed score without any 
corrections. <code>CI.obs</code> uses <code><a href="#topic+SE.Meas">SE.Meas</a></code>, the SEM that appears in most test manuals and 
text books.
</p>


<h3>Value</h3>

<p>Both functions return a table with 4 elements
</p>
<table>
<tr><td><code>SE.</code></td>
<td>
<p> Standard Error of the Estimate or SE of Measurement</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p> lower confidence limit of the CIDescription of 'comp2'</p>
</td></tr>
<tr><td><code>T.Score</code></td>
<td>
<p> (or OBS) Estimate True Score or Observed score</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> upper confidence limit of the CI</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>Be Cautious in construction and interpretation of CIs <br />
To obtain percent for 1 SEM <br />
1-((1-pnorm(1))*2) <br />
To obtain percent for 2 SEM <br />
1-((1-pnorm(2))*2) <br />
</p>
<p>95 percent CI corresponds to 1.96 * SE <br />
1 * SE corresponds to .6827 <br />
2 * SE corresponds to 0.9772499 <br />
so, for two-sided, 2 * SE corresponds to 0.9544997 <br />
</p>


<h3>Note</h3>

<p> It is not in error to report any one of these. The misinterpretation is in taking the observed
score and making inferences about the true score without (1) using the correct standard error and (2) 
correcting for regression toward the mean of the observed scores. 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Dudek, F. J. (1979). The continuing misinterpretation of the standard error of measurement. 
<em>Psychological Bulletin, 86</em>, 335-337. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+SE.Meas">SE.Meas</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples from Dudek (1979)
# Suppose a test has mean = 500, SD = 100 rxx = .9
# If an individual scores 700 on the test
CI.tscore (700, 500, 100, .9, level=.68)
CI.obs(700, 100,.9, level=.68)
</code></pre>

<hr>
<h2 id='CIr'> Confidence Interval for a Correlation Coefficient </h2><span id='topic+CIr'></span>

<h3>Description</h3>

<p>Will construct the CI for a desired level given a correlation and sample size </p>


<h3>Usage</h3>

<pre><code class='language-R'>CIr(r, n, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CIr_+3A_r">r</code></td>
<td>
<p> Correlation Coefficient</p>
</td></tr>
<tr><td><code id="CIr_+3A_n">n</code></td>
<td>
<p> Sample Size </p>
</td></tr>
<tr><td><code id="CIr_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Does not compute r, you must enter it into the function</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+r2z">r2z</a></code>, 
<code><a href="#topic+CIz">CIz</a></code>, 
<code><a href="#topic+SEz">SEz</a></code>, 
<code><a href="#topic+z2r">z2r</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
CIr (.657, 15)
</code></pre>

<hr>
<h2 id='CIrb'> Confidence Interval about Sample Weighted Mean Correlation</h2><span id='topic+CIrb'></span><span id='topic+CIrbar'></span>

<h3>Description</h3>

<p>Produces a CI for the desired level of the sample weighted mean correlation 
using the appropriate standard error. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CIrb(x, LEVEL = 0.95, homogenous = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CIrb_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="CIrb_+3A_level">LEVEL</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95</p>
</td></tr>
<tr><td><code id="CIrb_+3A_homogenous">homogenous</code></td>
<td>
<p> Whether or not to use homogenous or heterogenous SE </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CI is constructed based on the uncorrected mean correlation. It is 
corrected for sampling error only. To get the CI for the mean correlation 
corrected for artifacts, use <code><a href="#topic+CredIntRho">CredIntRho</a></code>, but this is a 
credibility interval rather than a confidence interval. See Hunter &amp;
Schmidt (2004) for more details on the interpretation of the differences.
</p>
<p>If the CI is computed about a heterogenous mean correlation, one is 
implying that moderators are present, but that one can't determine what
those moderators might be. Otherwise, strive to parse the studies into 
homogenous subsets and create CI about those means within the subsets.
</p>


<h3>Value</h3>

<p>A list containing:  
</p>
<table>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+SErbar">SErbar</a></code>, <code><a href="#topic+rbar">rbar</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#From Arthur et al
data(ABHt32)
rbar(ABHt32)
CIrb(ABHt32)

# From Hunter et al
data(HSJt35)
rbar(HSJt35)
CIrb(HSJt35)

</code></pre>

<hr>
<h2 id='CIrdif'> Confidence Interval for the difference in Correlation Coefficients </h2><span id='topic+CIrdif'></span>

<h3>Description</h3>

<p>Will construct the CI for a difference in two correlations for a desired level</p>


<h3>Usage</h3>

<pre><code class='language-R'>CIrdif(r1, r2, n1, n2, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CIrdif_+3A_r1">r1</code></td>
<td>
<p> Correlation 1 </p>
</td></tr>
<tr><td><code id="CIrdif_+3A_r2">r2</code></td>
<td>
<p> Correlation 2 </p>
</td></tr>
<tr><td><code id="CIrdif_+3A_n1">n1</code></td>
<td>
<p> Sample size for <code>r1</code>  </p>
</td></tr>
<tr><td><code id="CIrdif_+3A_n2">n2</code></td>
<td>
<p> Sample size for <code>r2</code> </p>
</td></tr>
<tr><td><code id="CIrdif_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Constructs a confidence interval based on the standard error of the difference 
of two correlations <code class="reqn">(r1 - r2)</code>, sed <code class="reqn">&lt;- sqrt((1-r1^2)/n1 + (1-r2^2)/n2) </code></p>


<h3>Value</h3>

<p>Returns a table with 4 elements
</p>
<table>
<tr><td><code>DifR</code></td>
<td>
<p> Observed Difference in correlations</p>
</td></tr>
<tr><td><code>SED</code></td>
<td>
<p> Standard error of the difference</p>
</td></tr>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+rdif.nul">rdif.nul</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
CIrdif(.657, .430, 62, 143)

</code></pre>

<hr>
<h2 id='CIz'> Confidence Interval for Fisher z' </h2><span id='topic+CIz'></span>

<h3>Description</h3>

<p>Constructs a CI for a specified level about z'. 
This is useful for constructing CI for a correlation</p>


<h3>Usage</h3>

<pre><code class='language-R'>CIz(z, n, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CIz_+3A_z">z</code></td>
<td>
<p> Fishers z'</p>
</td></tr>
<tr><td><code id="CIz_+3A_n">n</code></td>
<td>
<p> Sample Size </p>
</td></tr>
<tr><td><code id="CIz_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+r2z">r2z</a></code>, 
<code><a href="#topic+CIr">CIr</a></code>, 
<code><a href="#topic+SEz">SEz</a></code>, 
<code><a href="#topic+z2r">z2r</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
zp &lt;- r2z(.657)
CIz(zp, 15)
</code></pre>

<hr>
<h2 id='ClassUtil'> Classical Utility of a Test </h2><span id='topic+ClassUtil'></span>

<h3>Description</h3>

<p>Calculate the classical utility of a test given a correlation, base-rate and selection ratio.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClassUtil(rxy = 0, BR = 0.5, SR = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ClassUtil_+3A_rxy">rxy</code></td>
<td>
<p> Correlation of Test X with Outcome Y </p>
</td></tr>
<tr><td><code id="ClassUtil_+3A_br">BR</code></td>
<td>
<p> Base Rate or prevalence without use of a test</p>
</td></tr>
<tr><td><code id="ClassUtil_+3A_sr">SR</code></td>
<td>
<p> Selection Ratio: Number selected out of those tested </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The degree of utility of using a test as a selection instrument over randomly 
selecting individuals can be reflected in the decision outcomes expected by using the 
selection instrument. Suppose you have a predictor (selection instrument) and a criterion 
(job performance). By regressing the criterion on the predictor, and selecting individuals 
based on some cut-off value, we have 4 possible outcomes. A = True Positives, B = True Negatives, 
C = False Negatives, and D = False Positives. The classical utility of using the test over 
current procedures (random selection) is:
</p>
<p>[A / (A+D)] - [(A + C) / (A + B + C + D)]
</p>
<p>Various manipulations of these relationships can be used to assist in decision making. 
</p>


<h3>Value</h3>

<p>Returns a table with the following elements reflecting decision outcomes:
</p>
<table>
<tr><td><code>True Positives</code></td>
<td>
<p> Probability of correctly selecting a successful candidate </p>
</td></tr>
<tr><td><code>False Negatives</code></td>
<td>
<p> Probability of incorrectly not selecting a successful candidate </p>
</td></tr>
<tr><td><code>False Positives</code></td>
<td>
<p> Probability of incorrectly selecting an unsuccessful candidate </p>
</td></tr>
<tr><td><code>True Negatives</code></td>
<td>
<p> Probability of correctly not selecting an unsuccessful candidate </p>
</td></tr>
<tr><td><code>Sensitivity</code></td>
<td>
<p> True Positives / (True Positives + False Negatives)</p>
</td></tr>
<tr><td><code>Specificity</code></td>
<td>
<p> True Negatives / (True Negatives + False Positives)</p>
</td></tr>
<tr><td><code>% of Decisions Correct</code></td>
<td>
<p> Percentage of correct decisions</p>
</td></tr>
<tr><td><code>Proportion Selected Succesful</code></td>
<td>
<p> Proportion of those selected expected to be successful</p>
</td></tr>
<tr><td><code>% Improvement over BR</code></td>
<td>
<p> Percentage of improvement using the test over random selection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Murphy, K. R. &amp; Davidshofer, C. O. (2005). <em>Psychological testing: Principles and 
applications (5th ed.).</em> Saddle River, NJ: Prentice Hall.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+Utility">Utility</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># 50 percent of those randomly selected are expected to be successful
# A company need only select 1/10 applicants
# The correlation between test scores and performance is .35
ClassUtil(.35, .5, .1)

</code></pre>

<hr>
<h2 id='CredIntRho'> Credibility Interval for Meta-Analytic Rho</h2><span id='topic+CredIntRho'></span>

<h3>Description</h3>

<p>Computed the credibility interval about the population correlation 
coefficient at the desired level.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CredIntRho(x, aprox = FALSE, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CredIntRho_+3A_x">x</code></td>
<td>
<p>  A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="CredIntRho_+3A_aprox">aprox</code></td>
<td>
<p> Logical test to determine if the approximate or exact var e is used</p>
</td></tr>
<tr><td><code id="CredIntRho_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95 </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The credibility interval is used for the detection of potential moderators. Intervals that 
large or include zero potentially reflect the presence of moderators. Credibility intervals
are constructed about rho, whereas confidence intervals are generally constructed about rbar.
See Hunter &amp; Schmidt (2004) for a description of the different uses. 
</p>
<p>The credibility interval is computed as: rho +/- z[crit] * SD(rho)
</p>
<p>where, rho is the corrected correlation, z[crit] is the critcal z value (1.96 for 95%), and
SD(rho) is the sqrt(variance in rho). 
</p>


<h3>Value</h3>

<table>
<tr><td><code>LCL</code></td>
<td>
<p> Lower Confidence Limit of the CI</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> Upper Confidence Limit of the CI</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a></p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rbar">rbar</a></code>, <code><a href="#topic+rhoCA">rhoCA</a></code>, <code><a href="#topic+CIrb">CIrb</a></code>, <code><a href="#topic+varRes">varRes</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
CredIntRho(ABHt32, aprox=TRUE)

# From Hunter et al
data(HSJt35)
CredIntRho(HSJt35)
</code></pre>

<hr>
<h2 id='cRRr'> Correction for Range Restriction </h2><span id='topic+cRRr'></span>

<h3>Description</h3>

<p>Corrects a correlation for Range restriction given population and sample standard deviations</p>


<h3>Usage</h3>

<pre><code class='language-R'>cRRr(rr, sdy, sdyu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cRRr_+3A_rr">rr</code></td>
<td>
<p> Observed or restricted correlation </p>
</td></tr>
<tr><td><code id="cRRr_+3A_sdy">sdy</code></td>
<td>
<p> Standard deviation of a restricted sample  </p>
</td></tr>
<tr><td><code id="cRRr_+3A_sdyu">sdyu</code></td>
<td>
<p> Standard deviation of an unrestricted sample </p>
</td></tr>
</table>


<h3>Details</h3>

<p>When one of the variables used to measure a correlation has a restricted variance
One the correlation will be attenuated. This commonly occurs for instance when using
incumbents (those already selected by previous procedures) to based decisions about 
validity of new selection procedures. Given u (ratio of unrestricted 
SD of one variable to the restricted SD of that variable), the following formula is used
to correct for attenuation in a correlation coefficient: <br />
<code class="reqn">rxy &lt;- (rr*(sdyu/sdy))/sqrt(1+rr^2*((sdyu^2/sdy^2)-1))</code></p>


<h3>Value</h3>

<table>
<tr><td><code>unrestricted</code></td>
<td>
<p>corrected correlation</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Do not confuse this function with the meta-analysis function cRR in this same package! 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+cRR">cRR</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># See section 2.10.3 of Cohen et al (2003)
cRRr(.25, 12, 5)

# Create two correlated variables 
x &lt;- rnorm(1000)
y &lt;- 0.71*x +rnorm(1000)
cor(x,y)
# order and select top 1/10 
tmp &lt;- cbind(x,y)[order(y,x),][1:100,]
rxyr &lt;- cor(tmp[,"x"],tmp[,"y"]) # restricted rxy
rxyr
# correct for restriction of range
cRRr(rxyr, sd(tmp[,"y"]), sd(y))


</code></pre>

<hr>
<h2 id='CVF'> Compound Variance Factor for Meta-Analytic Artifact Corrections </h2><span id='topic+CVF'></span>

<h3>Description</h3>

<p>The compound variance factor is computed by summing the individual squared coefficients 
of variation for each artifact when correcting for attenuation in a correlation coefficient
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVF(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVF_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns representing artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CVF is equal to scv(a) + scv(b) + scv(c), where scv is the squared coefficient of variation. 
The letters a, b, c represent artifacts reliability in predictor, reliability in criterion,
and restriction of range respectively. The scv is computed as the variance in the artifact divided 
by the square of the average for the artifact. 
</p>


<h3>Value</h3>

<p>a numeric value representing the compound variance factor
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+aRxx">aRxx</a></code>, <code><a href="#topic+bRyy">bRyy</a></code>, <code><a href="#topic+cRR">cRR</a></code>, <code><a href="#topic+varAV">varAV</a></code>,
<code><a href="#topic+CAFAA">CAFAA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
CVF(ABHt32)


# From Hunter et al
data(HSJt35)
CVF(HSJt35)
</code></pre>

<hr>
<h2 id='CVratio'> Content Validity Ratio </h2><span id='topic+CVratio'></span>

<h3>Description</h3>

<p>Computes Lawshe's CVR for determining whether items are essential or not. </p>


<h3>Usage</h3>

<pre><code class='language-R'>CVratio(NTOTAL, NESSENTIAL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CVratio_+3A_ntotal">NTOTAL</code></td>
<td>
<p> Total number of Experts</p>
</td></tr>
<tr><td><code id="CVratio_+3A_nessential">NESSENTIAL</code></td>
<td>
<p> Number of Experts indicating item 'essential' </p>
</td></tr>
</table>


<h3>Details</h3>

<p>To determine content validity (in relation to job performance), a panel of
subject matter experts will examine a set of items indicating 
whether the items are essential, useful, not necessary. The CVR is 
calculated to indicate whether the item is pertinent to the content validity. <br />
</p>
<p>CVR values range +1 to -1. Values closer to +1 indicated experts are in aggreement that
the item is essential to content validity.
</p>


<h3>Value</h3>

<p>Content Validity Ratio
</p>


<h3>Note</h3>

 
<p>CVR = (Ne - N/2)/(N-1) </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Lawshe, C. H. (1975). A quantitative approach to content validity. <em>Personnel Psychology, 28,</em>
563-575.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using 5 Expert panelists (SMEs)
# The ratings for an item is as follows:
# Rater1 = Essential
# Rater2 = Essential
# Rater3 = Essential
# Rater4 = Useful
# Rater5 = Not necessary
# # essential = 3
CVratio (5, 3)




</code></pre>

<hr>
<h2 id='discrim'> Item Discrimination </h2><span id='topic+discrim'></span>

<h3>Description</h3>

<p>Discrimination of an item is the ability for a specific item to distinguish among upper 
and lower ability individuals on a test</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discrim_+3A_x">x</code></td>
<td>
<p> matrix or data.frame of items to be examined. Rows represent persons, 
Columns represent items </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function takes data on individuals and their test scores and computes a total score to 
separate high and low ordered individuals. The upper and lower groups are defined as the top and 
bottom 1/3 of the total. Discrimination is then computed and returned for each item using the formula: <br />
(number correct in the upper group - number correct in the lower group ) / size of each group
</p>


<h3>Value</h3>

<p>Discrimination index for each item in the data.frame or matrix analyzed.
</p>


<h3>Note</h3>

 <p><code>discrim</code> is used by <code><a href="#topic+item.exam">item.exam</a></code> <code>discrim</code> is especially useful for 
dichotomously coded items such as correct/incorrect. If items are not dischotomously coded, the
interpretation of <code>discrim</code> has less meaning. </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Allen, M. J. &amp; Yen, W. M. (1979). <em>Introduction to measurement theory.</em> Monterey, CA: Brooks/Cole.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+item.exam">item.exam</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># see item.exam
# Scores on a test for 12 individuals
# 1 = correct
item1 &lt;- c(1,1,1,0,1,1,1,1,1,1,0,1)
item2 &lt;- c(1,0,1,1,1,1,1,1,1,1,1,0)
item3 &lt;- c(1,1,1,1,1,1,1,1,1,1,1,1)
item4 &lt;- c(0,1,0,1,0,1,0,1,1,1,1,1)
item5 &lt;- c(0,0,0,0,1,0,0,1,1,1,1,1)
item6 &lt;- c(0,0,0,0,0,0,1,0,0,1,1,1)
item7 &lt;- c(0,0,0,0,0,0,0,0,1,0,0,0)
exam &lt;- cbind(item1, item2, item3, item4, item5, item6, item7)
discrim(exam)


  </code></pre>

<hr>
<h2 id='EnterMeta'> Enter Meta-Analysis Data</h2><span id='topic+EnterMeta'></span>

<h3>Description</h3>

<p>This function creates data entry object suitable for creating an object needed
in the typical meta-analysis. The object will have the appropriate variable names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnterMeta()
</code></pre>


<h3>Details</h3>

<p>To create a data object appropriate for the meta-analysis functions in this package:
Type <br />
my.Meta.data &lt;- EnterMeta() <br />
Then use the data editor to enter data in the appropriate columns. 
</p>


<h3>Value</h3>

<p>Does not return a value, but rather is used for naming columns of a data.frame()
The final object (if saved) will contain: <br />
</p>
<table>
<tr><td><code>study</code></td>
<td>
<p> Enter Study Code or article name</p>
</td></tr>
<tr><td><code>Rxy</code></td>
<td>
<p> Correlation coefficient</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p> Sample size for study</p>
</td></tr>
<tr><td><code>Rxx</code></td>
<td>
<p> Reliability of predictor variable X </p>
</td></tr>
<tr><td><code>Ryy</code></td>
<td>
<p> Reliability of criterion variable Y</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p> Degree of range restriction - ratio of restricted to unrestricted standard deviations</p>
</td></tr>
<tr><td><code>moderator</code></td>
<td>
<p> moderator variable (if any)</p>
</td></tr>
</table>


<h3>Warning </h3>

<p> This function will not automatically save your data object. You must create the
object using the assignment operator. </p>


<h3>Note</h3>

<p> This is the general format required for data objects used for all the meta-analysis 
functions in this package. If certain variables are empty (e.g., Rxx, u), then the appropriate
correction is not made, but the placeholder must be there. Moderator is useful for the user 
to subset the data and re-run any functions. </p>


<h3>Author(s)</h3>

<p>Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>See Also</h3>

<p> As an alternative, consider <code><a href="utils.html#topic+read.csv">read.csv</a></code> for importing data prepared 
elsewhere (e.g., Excel)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# my.data &lt;- EnterMeta()
</code></pre>

<hr>
<h2 id='Est.true'> Estimation of a True Score </h2><span id='topic+Est.true'></span>

<h3>Description</h3>

<p>Given the mean and reliability of a test, this function estimates the true score based
on an observed score. The estimation is accounting for regression to the mean </p>


<h3>Usage</h3>

<pre><code class='language-R'>Est.true(obs, mx, rxx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Est.true_+3A_obs">obs</code></td>
<td>
<p> an observed score on test x</p>
</td></tr>
<tr><td><code id="Est.true_+3A_mx">mx</code></td>
<td>
<p> mean of test x </p>
</td></tr>
<tr><td><code id="Est.true_+3A_rxx">rxx</code></td>
<td>
<p> reliability of test x</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimated true score (that) is computed as <br />
that &lt;- mx*(1-rxx)+rxx*obs <br />
When the obs score is much higher than the mean, the that &lt; obs <br />
When the obs score is much lower than the mean, that &gt; obs
</p>


<h3>Value</h3>

<p>Estimated True score
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Dudek, F. J. (1979). The continuing misinterpretation of the standard error of measurement. 
<em>Psychological Bulletin, 86</em>, 335-337.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CI.tscore">CI.tscore</a></code>, <code><a href="#topic+SE.Est">SE.Est</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples from Dudek (1979)
# Suppose a test has mean = 500, SD = 100 rxx = .9
# If an individual scores 700 on the test
Est.true(700, 500, .9)

# If an individual scores 400 on the test
Est.true(400, 500, .9)

</code></pre>

<hr>
<h2 id='FileDrawer'> File Drawer N  </h2><span id='topic+FileDrawer'></span>

<h3>Description</h3>

<p>Computes the number of 'lost' studies needed to render the observed meta-analytic
correlation to non-significance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FileDrawer(x, rc = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FileDrawer_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="FileDrawer_+3A_rc">rc</code></td>
<td>
<p> cut-off correlation for which to make a comparison</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use to detect availability bias in published correlations. It is computed as 
n &lt;- k * (rb/rc - 1), where, n is the file drawer n, k is the number of studies in 
current meta-analyis, rb is rbar and rc is the cut-off correlation for which you wish 
to make a comparison. For a test of the null hypothesis, use rc = 0. In many instances, practitioners
are interested in reducing correlations to less than 1 percent of the variance accounted for
(i.e., rc = .1). 
</p>


<h3>Value</h3>

<table>
<tr><td><code>"# of 'lost' studies needed"</code></td>
<td>
<p> File drawer N needed to change decision</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Rosenthal, R. (1979). The &quot;file-drawer problem&quot; and tolerance for null results. <em>
Psychological Bulletin, 86,</em> 638-641.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+FunnelPlot">FunnelPlot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
FileDrawer(ABHt32)

# From Hunter et al
data(HSJt35)
FileDrawer(HSJt35)
 </code></pre>

<hr>
<h2 id='FunnelPlot'> Funnel Plot for Meta-Analysis </h2><span id='topic+FunnelPlot'></span>

<h3>Description</h3>

<p>Produces a simple x-y plot corresponding to the correlation and sample size. A vertical line 
is produced representing the sample weighted correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FunnelPlot(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FunnelPlot_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plot showing 'no evidence' of availabilty bias will resemble funnel getting smaller at the top, and 
larger at the bottom of the plot. A plot showing evidence of availablity bias will not resemble a funnel.
</p>


<h3>Value</h3>

<p>a plot 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+FileDrawer">FileDrawer</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
FunnelPlot(ABHt32)

# From Hunter et al
data(HSJt35)
FunnelPlot(HSJt35)
 </code></pre>

<hr>
<h2 id='HSJt35'> Table 3.5 Hunter et al.</h2><span id='topic+HSJt35'></span>

<h3>Description</h3>

<p>This is a useful and fictious example for conducting Meta-Analysis. 
It appeared in Hunter et al (1982)</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HSJt35)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 7 variables.
</p>

<ul>
<li> <p><em>study</em> Study code
</p>
</li>
<li> <p><em>Rxy</em> Published correlation
</p>
</li>
<li> <p><em>n</em> Sample size
</p>
</li>
<li> <p><em>Rxx</em> Reliability of predictor
</p>
</li>
<li> <p><em>Ryy</em> Reliability of criterion
</p>
</li>
<li> <p><em>u</em> Range Restriction Ratio
</p>
</li>
<li> <p><em>moderator</em> none &lt;na&gt; 
</p>
</li></ul>


<h3>Details</h3>

<p>This example has been replicated a number of times (e.g., Hunter &amp; Schmidt, 2004). 
It is useful in illustrating the basic concepts of validity generalization. 
The data can be used to demonstrate bare-bones MA as well as correction for artifacts.
This data format is the format necessary for the R functions in the psychometric package.
</p>


<h3>References</h3>

<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HSJt35)
rbar(HSJt35)
FunnelPlot(HSJt35)
CredIntRho(HSJt35)

</code></pre>

<hr>
<h2 id='ICC.CI'> Confidence interval for the Intra-class Correlation </h2><span id='topic+ICC.CI'></span><span id='topic+ICC1.CI'></span><span id='topic+ICC2.CI'></span>

<h3>Description</h3>

<p>Computes the CI at the desired level for the ICC1 and ICC2</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ICC1.CI(dv, iv, data, level = 0.95)

ICC2.CI(dv, iv, data, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICC.CI_+3A_dv">dv</code></td>
<td>
<p> The dependent variable of interest </p>
</td></tr>
<tr><td><code id="ICC.CI_+3A_iv">iv</code></td>
<td>
<p> cluster or grouping variable </p>
</td></tr>
<tr><td><code id="ICC.CI_+3A_data">data</code></td>
<td>
<p> data.frame containing the data </p>
</td></tr>
<tr><td><code id="ICC.CI_+3A_level">level</code></td>
<td>
<p> Significance Level for constructing the CI, default is .95</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the ICC from a one-way ANOVA. The CI is then computed at the desired level using 
formulae provided by McGraw &amp; Wong (1996). They use the terminology ICC(1) and ICC(k) for
ICC1 and ICC2 respectively. 
</p>


<h3>Value</h3>

<p>A table with 3 elements:  
</p>
<table>
<tr><td><code>LCL</code></td>
<td>
<p> lower confidence limit if CI</p>
</td></tr>
<tr><td><code>ICC</code></td>
<td>
<p> intra-class correlation</p>
</td></tr>
<tr><td><code>UCL</code></td>
<td>
<p> upper confidence limit if CI</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a></p>


<h3>References</h3>

 
<p>McGraw, K. O. &amp; Wong, S. P. (1996). Forming some inferences about some intraclass 
correlation coefficients. <em>Psychological Methods, 1,</em> 30-46.
</p>
<p>Bliese, P. (2000). Within-group agreement, non-independence, and reliability: Implications 
for data aggregation and analysis. In K. J. Klein &amp; S. W. J. Kozlowski (Eds.), 
<em>Multilevel theory, research, and methods in organizations: Foundations, extensions, 
and new directions (pp. 349-381).</em> San Francisco: Jossey-Bass.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+ICC.lme">ICC.lme</a></code>, <code><a href="multilevel.html#topic+ICC1">ICC1</a></code>, <code><a href="multilevel.html#topic+ICC2">ICC2</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>library(multilevel)
data(bh1996)
ICC1.CI(HRS, GRP, bh1996)
ICC2.CI(HRS, GRP, bh1996)

</code></pre>

<hr>
<h2 id='ICC.lme'> Intraclass Correlation Coefficient from a Mixed-Effects Model </h2><span id='topic+ICC.lme'></span><span id='topic+ICC1.lme'></span><span id='topic+ICC2.lme'></span>

<h3>Description</h3>

<p>ICC1 and ICC2 computed from a lme() model. </p>


<h3>Usage</h3>

<pre><code class='language-R'>ICC1.lme(dv, grp, data)

ICC2.lme(dv, grp, data, weighted = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICC.lme_+3A_dv">dv</code></td>
<td>
<p> The dependent variable of interest </p>
</td></tr>
<tr><td><code id="ICC.lme_+3A_grp">grp</code></td>
<td>
<p> cluster or grouping variable </p>
</td></tr>
<tr><td><code id="ICC.lme_+3A_data">data</code></td>
<td>
<p> data.frame containing the data </p>
</td></tr>
<tr><td><code id="ICC.lme_+3A_weighted">weighted</code></td>
<td>
<p> Whether or not a weighted mean is used in calculation of ICC2 </p>
</td></tr>
</table>


<h3>Details</h3>

<p>First a lme() model is computed from the data. Then ICC1 is computed as <code class="reqn">t00/(t00 + siqma^2)</code>,
where t00 is the variance in intercept of the model and <code class="reqn">sigma^2</code> is the residual variance for 
the model. The ICC2 is computed by computing the ICC2 for each group <code class="reqn">t00/(t00 + sigma^2/nj)</code> 
where nj is the size of group j. The mean across all groups is then taken to be the ICC2. 
However, one can specify that the mean should be weigted by group size such that larger groups 
are given more weight. The calculation of the individual group ICC2 is done by Bliese's 
<code><a href="multilevel.html#topic+gmeanrel">gmeanrel</a></code> function. An alternate specification not used here, 
but sometimes seen in the literature for ICC2 is to use the formula above for the total data 
set, but replace nj with the average group size. This is the method used in Bliese's 
<code><a href="multilevel.html#topic+mult.icc">mult.icc</a></code>. 
</p>


<h3>Value</h3>

<p>ICC1 or ICC2
</p>


<h3>Warning </h3>

<p> If data used are attached, you will sometimes receive a warning that can be ignored. 
The warning states that the following variables ... are masked. This is because the function first 
attaches the data and then detaches it within the function. </p>


<h3>Note</h3>

<p> ICC1.lme and ICC2.lme should in principle be equal an ICC computed from a one-way ANOVA 
only when the data are balanced (equal group sizes for all groups and no missing data). The ICC.lme
should be a more accurate measure of ICC in all other instances. The three specifications of ICC2 
mentioned above (details) will be similar by not exactly equal because of group variablity. 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Bliese, P. (2000). Within-group agreement, non-independence, and reliability: Implications 
for data aggregation and analysis. In K. J. Klein &amp; S. W. J. Kozlowski (Eds.), 
<em>Multilevel theory, research, and methods in organizations: Foundations, extensions, 
and new directions (pp. 349-381).</em> San Francisco: Jossey-Bass.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ICC.CI">ICC.CI</a></code>, <code><a href="multilevel.html#topic+mult.icc">mult.icc</a></code>, <code><a href="multilevel.html#topic+gmeanrel">gmeanrel</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(nlme)
library(multilevel)
data(bh1996)
ICC1.lme(HRS, GRP, data=bh1996)
ICC2.lme(HRS, GRP, data=bh1996)
</code></pre>

<hr>
<h2 id='item.exam'> Item Analysis </h2><span id='topic+item.exam'></span>

<h3>Description</h3>

<p>Conducts an item level analysis. Provides item-total correlations, Standard deviation in items,
difficulty, discrimination, and reliability and validity indices.</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.exam(x, y = NULL, discrim = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.exam_+3A_x">x</code></td>
<td>
<p> matrix or  data.frame of items </p>
</td></tr>
<tr><td><code id="item.exam_+3A_y">y</code></td>
<td>
<p> Criterion variable </p>
</td></tr>
<tr><td><code id="item.exam_+3A_discrim">discrim</code></td>
<td>
<p> Whether or not the discrimination of item is to be computed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If someone is interested in examining the items of a dataset contained in data.frame x, and 
the criterion measure is also in data.frame x, one must parse the matrix or data.frame and specify
each part into the function. See example below. Otherwise, one must be sure that x and y are properly 
merged/matched. If one is not interested in assessing item-criterion relationships, simply leave out 
that portion of the call. The function does not check whether the items are dichotomously coded, 
this is user specified. As such, one can specify that items are binary when in fact they are not. This
has the effect of computing the discrimination index for continuously coded variables. <br />
The difficulty index (p) is simply the mean of the item. When dichotomously coded, p reflects the
proportion endorsing the item. However, when continuously coded, p has a different interpretation.</p>


<h3>Value</h3>

<p>A table with rows representing each item and columns repsenting :
</p>
<table>
<tr><td><code>Sample.SD</code></td>
<td>
<p> Standard deviation of the item</p>
</td></tr>
<tr><td><code>Item.total</code></td>
<td>
<p> Correlation of the item with the total test score </p>
</td></tr>
<tr><td><code>Item.Tot.woi</code></td>
<td>
<p> Correlation of item with total test score (scored without item)</p>
</td></tr>
<tr><td><code>Difficulty</code></td>
<td>
<p> Mean of the item (p) </p>
</td></tr>
<tr><td><code>Discrimination</code></td>
<td>
<p> Discrimination of the item (u-l)/n </p>
</td></tr>
<tr><td><code>Item.Criterion</code></td>
<td>
<p> Correlation of the item with the Criterion (y)</p>
</td></tr>
<tr><td><code>Item.Reliab</code></td>
<td>
<p> Item reliability index</p>
</td></tr>
<tr><td><code>Item.Rel.woi</code></td>
<td>
<p> Item reliability index (scored without item) </p>
</td></tr>
<tr><td><code>Item.Validity</code></td>
<td>
<p> Item validity index </p>
</td></tr>
</table>


<h3>Warning </h3>

<p> Be cautious when using data with missing values or small data sets. <br />
</p>
<p>Listwise deletion is employed for both X (matrix of items to be analyzed) and Y (criterion). 
When the datasets are small, such listwise deletion can make a big impact. Further, since the 
upper and lower groups are defined as the upper and lower 1/3, the stability of this division of 
examinees is greatly increased with larger N.</p>


<h3>Note</h3>

<p> Most all text books suggest the point-biserial correlation for the item-total. 
Since the point-biserial is equivalent to the Pearson r, the <code>cor</code> function is used 
to render the Pearson r for each item-total. However, it might be suggested that the 
polyserial is more appropriate. For practical purposes, the Pearson is sufficient and is
used here. <br />
</p>
<p>If discrim = TRUE, then the discrimination index is computed and returned EVEN IF the items 
are not dichotomously coded. The interpretation of the discrimination index is then suspect. 
<code><a href="#topic+discrim">discrim</a></code> computes the number of correct responses in the upper and lower groups by
summation of the '1s' (correct responses). When data are continuous, the discrimination index
represents the difference in the sum of the scores divided by number in each group (1/3*N).</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Allen, M. J. &amp; Yen, W. M. (1979). <em>Introduction to measurement theory.</em> Monterey, CA: Brooks/Cole.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+alpha">alpha</a></code>, <code><a href="#topic+discrim">discrim</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(TestScores)
# Look at the data
TestScores
# Examine the items
item.exam(TestScores[,1:10], y = TestScores[,11], discrim=TRUE)

</code></pre>

<hr>
<h2 id='MetaTable'> Summary function for 'Complete' Meta-Analysis</h2><span id='topic+MetaTable'></span>

<h3>Description</h3>

<p>Computes and returns the major functions involved in a Meta-Analysis. It is generic
in the sense that no options are available to alter defaults. </p>


<h3>Usage</h3>

<pre><code class='language-R'>MetaTable(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MetaTable_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a set of correlations for each study (i), the following calculations are made and returned:
</p>
<p>r-bar <code><a href="#topic+rbar">rbar</a></code>, variance in r-bar <code><a href="#topic+varr">varr</a></code>, variance due to sampling error 
(not approximated) <code><a href="#topic+vare">vare</a></code>, percent of variance due to sampling error <code><a href="#topic+pvse">pvse</a></code>,
95% CI for r-bar (using both the heterogenous and homogenous SE) <code><a href="#topic+CIrb">CIrb</a></code>, rho (
corrected r-bar) <code><a href="#topic+rhoCA">rhoCA</a></code>, variance in rho <code><a href="#topic+varRCA">varRCA</a></code>, percent of variance 
attributable to artifacts <code><a href="#topic+pvaaa">pvaaa</a></code>, 90% Credibility interval <code><a href="#topic+CredIntRho">CredIntRho</a></code>
</p>


<h3>Value</h3>

<p>Data.frame with various statistics returned - see details above</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rbar">rbar</a></code>, <code><a href="#topic+rhoCA">rhoCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
MetaTable(ABHt32)
# From Hunter et al
data(HSJt35)
MetaTable(HSJt35)

</code></pre>

<hr>
<h2 id='pvaaa'> Percent of Variance Accounted for by Artifacts in Rho </h2><span id='topic+pvaaa'></span>

<h3>Description</h3>

<p>Computes the percentage variance attributed to attenuating artifacts (sampling error, 
restriction of range, reliability in predictor and criterion.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvaaa(x, aprox = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvaaa_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="pvaaa_+3A_aprox">aprox</code></td>
<td>
<p> Logical test to determine if the approximate or exact var e is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Percent of variance is computed as: ( <code>vare</code> + <code>varAV</code> ) / <code>varr</code> * 100
</p>


<h3>Value</h3>

<p>A numeric value representing the percent of variance accounted for by artifacts
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vare">vare</a></code>, <code><a href="#topic+varAV">varAV</a></code>, <code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+pvse">pvse</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
pvaaa(ABHt32)

# From Hunter et al
data(HSJt35)
pvaaa(HSJt35)
</code></pre>

<hr>
<h2 id='pvse'> Percent of variance due to sampling error </h2><span id='topic+pvse'></span>

<h3>Description</h3>

<p>Ratio of sampling error variance to weighted variance in correlations for a meta-analysis. 
This value is compared to 75 (e.g., 75% rule) to determine the presence of moderators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvse(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvse_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pvse</code> &lt;- <code><a href="#topic+vare">vare</a></code>/<code><a href="#topic+varr">varr</a></code>*100
</p>


<h3>Value</h3>

<p>A single numeric value of class matrix representing the % of variance 
accounted for by sampling error</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+vare">vare</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
pvse(ABHt32)
# From Hunter et al
data(HSJt35)
pvse(HSJt35)
</code></pre>

<hr>
<h2 id='Qrbar'> Meta-Analytic Q statistic for r-bar </h2><span id='topic+Qrbar'></span><span id='topic+aprox.Qrbar'></span>

<h3>Description</h3>

<p>Provides a chi-square test for significant variation in sample weighted correlation, rbar</p>


<h3>Usage</h3>

<pre><code class='language-R'>Qrbar(x)
aprox.Qrbar(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Qrbar_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Q is distributed as chi-square with df equal to the number of studies - 1. 
Multiple equations exist presumably because of a need to do the calculations &lsquo;by hand&rsquo; in the past. 
A significant Q statistic implies the presence of one or more moderating variables operating on the
observed correlations. 
</p>


<h3>Value</h3>

<p>A table containing the following items: <br />
</p>
<table>
<tr><td><code>CHISQ</code></td>
<td>
<p> Chi-square value</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p> degrees of freedom</p>
</td></tr>
<tr><td><code>p-val</code></td>
<td>
<p> probabilty value</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>The test is presented by Hunter et al. 1982, but is NOT recommended 
nor mentioned by Hunter &amp; Schmidt (2004). The test is sensitive to the number of studies
included in the meta-analysis. Large meta-analyses may find significant Q statistics when
variation in the population is not present, and small meta-analyses may find lack of 
significant Q statistics when moderators are present. Hunter &amp; Schmidt (2004) recommend
the credibility inteval, <code><a href="#topic+CredIntRho">CredIntRho</a></code>, or the 75% rule, <code><a href="#topic+pvse">pvse</a></code>, 
as determinants of the presence of moderators.</p>


<h3>Note</h3>

<p><code>Qrbar</code> is computed as: <code class="reqn">sum((((n-1)*(r-rb)^2)/(1-rb^2)^2),na.rm=TRUE)</code> <br />
<code>aprox.Qrbar</code> is computed as:  <code class="reqn">(N/(1-rb^2)^2)*vr</code>
</p>
<p>where n is sample size of study i, N is total sample size across studies, 
rb is <code><a href="#topic+rbar">rbar</a></code>, r is the correlation of study i, 
and vr is <code><a href="#topic+varr">varr</a></code>. </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+vare">vare</a></code>, <code><a href="#topic+rbar">rbar</a></code>, 
<code><a href="#topic+CredIntRho">CredIntRho</a></code>, <code><a href="#topic+pvse">pvse</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
aprox.Qrbar(ABHt32)

# From Hunter et al
data(HSJt35)
Qrbar(HSJt35)
aprox.Qrbar(HSJt35)
</code></pre>

<hr>
<h2 id='Qrho'> Meta-Analytic Q statistic for rho </h2><span id='topic+Qrho'></span>

<h3>Description</h3>

<p>Provides a chi-square test for significant variation in sample weighted correlation 
corrected for attenuating artifacts</p>


<h3>Usage</h3>

<pre><code class='language-R'>Qrho(x, aproxe = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Qrho_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="Qrho_+3A_aproxe">aproxe</code></td>
<td>
<p> Logical test to determine if the approximate or exact var e is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Q is distributed as chi-square with df equal to the number of studies - 1. 
A significant Q statistic implies the presence of one or more moderating variables operating on the
observed correlations after corrections for artifacts. 
</p>


<h3>Value</h3>

<p>A table containing the following items: <br />
</p>
<table>
<tr><td><code>CHISQ</code></td>
<td>
<p> Chi-square value</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p> degrees of freedom</p>
</td></tr>
<tr><td><code>p-val</code></td>
<td>
<p> probabilty value</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>The test is sensitive to the number of studies included in the meta-analysis.
Large meta-analyses may find significant Q statistics when variation in the population is not present, 
and small meta-analyses may find lack of significant Q statistics when moderators are present. Hunter &amp;
Schmidt (2004) recommend the credibility inteval, <code><a href="#topic+CredIntRho">CredIntRho</a></code>, or the 75% rule, 
<code><a href="#topic+pvse">pvse</a></code>, as determinants of the presence of moderators.</p>


<h3>Note</h3>

 
<p>Q is defined as: (k*vr)/(vav+ve) 
</p>
<p>where, k is the number of studies, vr is <code><a href="#topic+varr">varr</a></code>, vav is <code><a href="#topic+varAV">varAV</a></code>, and ve is
<code><a href="#topic+vare">vare</a></code> </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+vare">vare</a></code>, <code><a href="#topic+rbar">rbar</a></code>, 
<code><a href="#topic+CredIntRho">CredIntRho</a></code>, <code><a href="#topic+pvse">pvse</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
Qrho(ABHt32)

# From Hunter et al
data(HSJt35)
Qrho(HSJt35)
</code></pre>

<hr>
<h2 id='r.nil'> Nil hypothesis for a correlation </h2><span id='topic+r.nil'></span><span id='topic+r.null'></span>

<h3>Description</h3>

<p>Performs a two-tailed t-test of the H0 that r = 0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.nil(r, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r.nil_+3A_r">r</code></td>
<td>
<p> Correlation coefficient</p>
</td></tr>
<tr><td><code id="r.nil_+3A_n">n</code></td>
<td>
<p> Sample Size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a table with 4 elements
</p>

<dl>
<dt>H0:rNot0</dt><dd><p>correlation to be tested</p>
</dd>
</dl>

<table>
<tr><td><code>t</code></td>
<td>
<p> t value for the H0</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p> degrees of freedom</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p> p value</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+rdif.nul">rdif.nul</a></code>, 
<code><a href="#topic+CIrdif">CIrdif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
r.nil(.657, 15)
</code></pre>

<hr>
<h2 id='r2z'> Fisher r to z' </h2><span id='topic+r2z'></span><span id='topic+FISHER+20r+20to+20z'></span>

<h3>Description</h3>

<p>Converts a Pearson correlation coefficient to Fishers z'</p>


<h3>Usage</h3>

<pre><code class='language-R'>r2z(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r2z_+3A_x">x</code></td>
<td>
<p> Pearson correlation coefficient</p>
</td></tr>
</table>


<h3>Details</h3>

<p> z' = .5 * log((1+r)/(1-r))
</p>


<h3>Value</h3>

<p>Fisher z' </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+z2r">z2r</a></code>, 
<code><a href="#topic+CIr">CIr</a></code>, </p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
r2z(.657)

</code></pre>

<hr>
<h2 id='rbar'> Sample size weighted mean correlation</h2><span id='topic+rbar'></span>

<h3>Description</h3>

<p>Computes the weighted mean correlation from a data object of the general format found in 
<code><a href="#topic+EnterMeta">EnterMeta</a></code></p>


<h3>Usage</h3>

<pre><code class='language-R'>rbar(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbar_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a set of correlations for each study (i), rbar is computed as:
sum(Ni*ri)/sum(Ni)  where, Ni is the sample size of study i and ri
is the correlation in study i.
</p>


<h3>Value</h3>

<p>Sample Weighted Average Correlation: uncorrected for artifacts other than sampling error
</p>


<h3>Note</h3>

<p> This is the mean correlation across studies corrected for sampling error. It is also known as
bare-bones meta-analysis.</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+rhoCA">rhoCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
rbar(ABHt32)
# From Hunter et al
data(HSJt35)
rbar(HSJt35)

</code></pre>

<hr>
<h2 id='rdif.nul'> Null hypothesis for difference in two correlations </h2><span id='topic+rdif.nul'></span>

<h3>Description</h3>

<p>Tests the hypothesis that two correlations are significantly different </p>


<h3>Usage</h3>

<pre><code class='language-R'>rdif.nul(r1, r2, n1, n2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rdif.nul_+3A_r1">r1</code></td>
<td>
<p> Correlation 1</p>
</td></tr>
<tr><td><code id="rdif.nul_+3A_r2">r2</code></td>
<td>
<p> Correlation 2</p>
</td></tr>
<tr><td><code id="rdif.nul_+3A_n1">n1</code></td>
<td>
<p> Sample size for <code>r1</code> </p>
</td></tr>
<tr><td><code id="rdif.nul_+3A_n2">n2</code></td>
<td>
<p> Sample size for <code>r2</code>  </p>
</td></tr>
</table>


<h3>Details</h3>

<p> First converts r to z' for each correlation. Then constructs a z test for the difference
z &lt;- (z1 - z2)/sqrt(1/(n1-3)+1/(n2-3))</p>


<h3>Value</h3>

<p>Returns a table with 2 elements
</p>
<table>
<tr><td><code>zDIF</code></td>
<td>
<p> z value for the H0</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p> p value</p>
</td></tr>
</table>


<h3>Note</h3>

<p> Does not test alternate hypotheses (e.g., difference = .1) </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+r.nil">r.nil</a></code>, 
<code><a href="#topic+CIrdif">CIrdif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
rdif.nul(.657, .430, 62, 143)

</code></pre>

<hr>
<h2 id='rhoCA'> Meta-Analytically Derived Correlation Coefficient Corrected for Artifacts</h2><span id='topic+rhoCA'></span>

<h3>Description</h3>

<p>This represents the population correlation coefficient free from attenuaton due to 
artifacts (sampling error, range-restriction, reliability in the predictor and criterion).</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhoCA(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rhoCA_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the sample weighted correlation coefficient <code><a href="#topic+rbar">rbar</a></code> divided by the 
compound attenuation factor, <code><a href="#topic+CAFAA">CAFAA</a></code>.
</p>


<h3>Value</h3>

<p>A numeric value represting the corrected correlation coefficient.
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+CAFAA">CAFAA</a></code>, <code><a href="#topic+rbar">rbar</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
rhoCA(ABHt32)

# From Hunter et al
data(HSJt35)
rhoCA(HSJt35)
</code></pre>

<hr>
<h2 id='SE.Meas'> Standard Errors of Measurement (test scores) </h2><span id='topic+SE.Meas'></span><span id='topic+SE.Est'></span><span id='topic+SE.Pred'></span>

<h3>Description</h3>

<p>These functions will calculate the three Standard Errors of Measurement as 
described by Dudek(1979). They are useful in constructing CI about 
observed scores, true scores and predicting observed scores on parallel measures.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SE.Meas(s, rxx)
SE.Est (s, rxx)
SE.Pred(sy, rxx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SE.Meas_+3A_s">s</code></td>
<td>
<p> Standard Deviation in tests scores on test x </p>
</td></tr>
<tr><td><code id="SE.Meas_+3A_sy">sy</code></td>
<td>
<p> Standard Deviation in tests scores on parallel test y = x</p>
</td></tr>
<tr><td><code id="SE.Meas_+3A_rxx">rxx</code></td>
<td>
<p> Reliability of test x </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dudek (1979) notes that in practice, individuals often misinterpret the SEM. 
In fact, most textbooks misinterpret these measures. The SE.Meas <code class="reqn">(s*sqrt(1-rxx))</code>
is useful in the construction of CI about observed scores, but should not be 
interpreted as indicating the TRUE SCORE is necessarily included in the CI. The
SE.Est <code class="reqn">(s*sqrt(rxx*(1-rxx)))</code> is useful in the construction of CI about the TRUE 
SCORE. The estimate of a CI for a TRUE SCORE also requires the calculation of a 
TRUE SCORE (due to regression to the mean) from observed scores. The SE.Pred 
<code class="reqn">(sy*sqrt(1-rxx^2))</code> is useful in predicting the score on a parallel measure (Y) 
given a score on test X. SE.Pred is usually used to estimate the score of a 
re-test of an individual.
</p>


<h3>Value</h3>

<p>The returned value is the appropriate standard error
</p>


<h3>Note</h3>

<p> Since strictly parallel tests have the same SD, s and sy are equivalent in these functions. 
SE.Meas() is used by <code><a href="#topic+CI.obs">CI.obs</a></code>. SE.Est() is used by <code><a href="#topic+CI.tscore">CI.tscore</a></code>. You must use 
<code><a href="#topic+Est.true">Est.true</a></code> to first compute the estimated true score from an observed score accounting for regression
to the mean.
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Dudek, F. J. (1979). The continuing misinterpretation of the standard error of measurement. 
<em>Psychological Bulletin, 86</em>, 335-337.
</p>
<p>Lord, F. M. &amp; Novick, M. R. (1968). <em>Statistical theories of mental test scores.</em>
Reading, MA: Addison-Wesley.
</p>
<p>Nunnally, J. C. &amp; Bernstein, I. H. (1994). <em>Psychometric Theory (3rd ed.).</em> New York: McGraw-Hill.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+Est.true">Est.true</a></code>, <code><a href="#topic+CI.obs">CI.obs</a></code>, <code><a href="#topic+CI.tscore">CI.tscore</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples from Dudek (1979)
# Suppose a test has mean = 500, SD = 100 rxx = .9
# If an individual scores 700 on the test
# The three SE are:
SE.Meas (100, .9)
SE.Est (100, .9)
SE.Pred (100, 9)

# CI about the true score
CI.tscore(700, 500, 100, .9)

# CI about the observed score
CI.obs(700, 100, .9)

</code></pre>

<hr>
<h2 id='SErbar'> Standard Error for Sample Size Weighted Mean Correlation </h2><span id='topic+SErbar'></span><span id='topic+SERHET'></span><span id='topic+SERHOM'></span>

<h3>Description</h3>

<p>The standard error of homogenous or heterogenous samples is computed to be used for
construction of confidence intervals about the Sample Size Weighted Mean Correlation in 
meta-analysis. Use <code>SERHOM</code> if no moderators are present (population is homogenous), and 
use <code>SERHET</code> if moderators are present (population is heterogenous). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SERHOM(x)
SERHET(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SErbar_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula for each are: <br />
SERHOM &lt;- <code class="reqn">(1-rb^2)/sqrt(N-k)</code> <br />
SERHET &lt;- <code class="reqn">sqrt((1-rb^2)^2/(N-k)+varRes(x)/k)</code>
</p>
<p>where, rb is <code><a href="#topic+rbar">rbar</a></code>, N is the total sample size, k is the number of studies.
</p>


<h3>Value</h3>

<p>A numeric value, the standard error 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CIrb">CIrb</a></code>, <code><a href="#topic+rbar">rbar</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
SERHOM(ABHt32)
SERHET(ABHt32)
CIrb(ABHt32)

# From Hunter et al
data(HSJt35)
SERHOM(HSJt35)
SERHET(HSJt35)
CIrb(HSJt35)

</code></pre>

<hr>
<h2 id='SEz'> Standard Error of Fishers z prime </h2><span id='topic+SEz'></span>

<h3>Description</h3>

<p>Given a sample size, n, will compute the aproximate standard error for z prime
This is useful for constructing confidence intervals about a correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SEz(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SEz_+3A_n">n</code></td>
<td>
<p> sample size </p>
</td></tr>
</table>


<h3>Details</h3>

<p> SEz = 1/sqrt(n-3) </p>


<h3>Value</h3>

<p>The approximate standard error for Fisher's z prime </p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Olkin, I. &amp; Finn, J. D. (1995). Correlation Redux. <em>Psychological Bulletin, 118</em>, 155-164.
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+r2z">r2z</a></code>, 
<code><a href="#topic+CIr">CIr</a></code>, 
<code><a href="#topic+CIz">CIz</a></code>, 
<code><a href="#topic+z2r">z2r</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
zp &lt;- r2z(.657)
zp
SEz(15)

</code></pre>

<hr>
<h2 id='SpearmanBrown'> Spearman-Brown Prophecy Formulae</h2><span id='topic+SBrel'></span><span id='topic+SBlength'></span><span id='topic+SpearmanBrown'></span>

<h3>Description</h3>

<p>These two functions are various manipulations of the Spearman-Brown Prophecy Formula. 
They are useful in determining relibility if test length is changed or length of
a new test if reliability were to change.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBrel(Nlength, rxx)

SBlength(rxxp, rxx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpearmanBrown_+3A_nlength">Nlength</code></td>
<td>
<p> New length of a test in relation to original</p>
</td></tr>
<tr><td><code id="SpearmanBrown_+3A_rxx">rxx</code></td>
<td>
<p> reliability of test x </p>
</td></tr>
<tr><td><code id="SpearmanBrown_+3A_rxxp">rxxp</code></td>
<td>
<p> reliability of desired (parallel) test x </p>
</td></tr>
</table>


<h3>Details</h3>

<p> Nlength represents a ratio of new to original. If the new test has 10 items, and the
original test has 5 items, Nlength is 2. Likewise, if the original test has 5 items, and the new
test has 10 items, Nlength is .5. In general, researchers should aim for reliabilities &gt; .9. 
</p>
<p><code>SBrel</code> is used to address the question, what if I increased/decreased my test length? 
What will the new reliability be? This is used when computing split-half reliabilities
and when when concerned about reducing test length. <br />
<code>SBlength</code> is used to address the question, how long must my test be (in relation to the 
original test) in order to achieve a desired reliability? <br />
The formulae for each are: <br />
rxxp &lt;- Nlength*rxx/(1+(Nlength-1)*rxx) <br />
N &lt;- rxxp*(1-rxx)/(rxx*(1-rxxp))
</p>


<h3>Value</h3>

<table>
<tr><td><code>rxxp</code></td>
<td>
<p>the prophesized reliability </p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>Ratio of new test length to original test length </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

<p>Allen, M. J. &amp; Yen, W. M. (1979). <em>Introduction to measurement theory.</em> Monterey, CA: Brooks/Cole.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+alpha">alpha</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Given a test with rxx = .7, 10 items
# Desire a test with rxx=.9, how many items are needed?
new.length &lt;- SBlength(.9, .7)
new.length * 10
# 39 items are needed
# what is the reliability of a test 1/2 as long
SBrel(.5, .7)
</code></pre>

<hr>
<h2 id='TestScores'>Fictitious Test Scores for Illustrative Purposes</h2><span id='topic+TestScores'></span>

<h3>Description</h3>

<p>These data were created to correspond to scores for 30 examinees on 10 items
of test X plus a score on criterion Y. </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TestScores)</code></pre>


<h3>Format</h3>

<p>A matrix with 30 observations on the following 11 variables.
</p>

<dl>
<dt><code>i1</code></dt><dd><p> item1 on test x</p>
</dd>
<dt><code>i2</code></dt><dd><p> item2 on test x</p>
</dd>
<dt><code>i3</code></dt><dd><p> item3 on test x</p>
</dd>
<dt><code>i4</code></dt><dd><p> item4 on test x</p>
</dd>
<dt><code>i5</code></dt><dd><p> item5 on test x</p>
</dd>
<dt><code>i6</code></dt><dd><p> item6 on test x</p>
</dd>
<dt><code>i7</code></dt><dd><p> item7 on test x</p>
</dd>
<dt><code>i8</code></dt><dd><p> item8 on test x</p>
</dd>
<dt><code>i9</code></dt><dd><p> item9 on test x</p>
</dd>
<dt><code>i10</code></dt><dd><p> item10 on test x</p>
</dd>
<dt><code>y</code></dt><dd><p> Score on criterion Y</p>
</dd>
</dl>
    


<h3>Details</h3>

<p> These data are constructed such that items 1 - 10 are coded 0,1 for incorrect/correct
responses. The data illustate that some items are better for maintaining internal consistency, 
whereas others may be more useful for relating to external criteria. </p>


<h3>See Also</h3>

<p><code><a href="#topic+item.exam">item.exam</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TestScores)
str(TestScores) 
item.exam(TestScores[,1:10], y = TestScores[,11], discrim=TRUE)
alpha(TestScores[,1:10])
</code></pre>

<hr>
<h2 id='Utility'> Marginal and Total Utility of a Test</h2><span id='topic+Utility'></span><span id='topic+MargUtil'></span><span id='topic+TotUtil'></span>

<h3>Description</h3>

<p>Computes the marginal or total utility of a test.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MargUtil(Rxy, Sy, MXg, COST, Nselected)

TotUtil(Rxy, Sy, MXg, COST, Nselected)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Utility_+3A_rxy">Rxy</code></td>
<td>
<p> Correlation of Test X with Criterion Y </p>
</td></tr>
<tr><td><code id="Utility_+3A_sy">Sy</code></td>
<td>
<p> Standard Deviation of Y in monetary units </p>
</td></tr>
<tr><td><code id="Utility_+3A_mxg">MXg</code></td>
<td>
<p> Mean of selected group on test X in standard score units </p>
</td></tr>
<tr><td><code id="Utility_+3A_cost">COST</code></td>
<td>
<p> Total cost of testing </p>
</td></tr>
<tr><td><code id="Utility_+3A_nselected">Nselected</code></td>
<td>
<p> number of applicants selected</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Marginal utility</em> is the gain expected in the outcome (i.e., job performance), in 
monetary units, for a person from the predictor selected subgroup compared to a person who 
is randomly selected. 
</p>
<p><em>Total utility</em> is the total gain in the outcome (i.e., job performance), in monetary units,
expected for those selected using the test.  
</p>


<h3>Value</h3>

<p>Marginal or Total Utility of a Test (a numeric value in monetary units)
</p>


<h3>Note</h3>

<p> Computation for marginal and total utility are:  
</p>
<p>MU &lt;- Rxy*Sy*MXg - COST/Nselected <br />
TU &lt;- Nselected*Rxy*Sy*MXg - COST
</p>
<p>The computation of Sy should be done locally (within an organization) and is often difficult. 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cascio, W. F. &amp;  Aguinis, H. (2005). <em>Applied Psychology in Human Resource Management 
(6th ed.)</em> Englewood Cliffs, NJ: Prentice-Hall.  
</p>
<p>Murphy, K. R. &amp; Davidshofer, C. O. (2005). <em>Psychological testing: Principles and 
applications (5th ed.).</em> Saddle River, NJ: Prentice Hall.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ClassUtil">ClassUtil</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Rxy = .35
# Each year 72 workers are hired
# SD of performance in dollars is $4000
# 1 out of 10 applicants are selected
# cost per test = $5
# average test score for those selected = 1.76
MargUtil(.35, 4000, 1.76, 720*5, 72)
TotUtil (.35, 4000, 1.76, 720*5, 72)
</code></pre>

<hr>
<h2 id='varAV'> Variance Due to Attenuating Artifacts</h2><span id='topic+varAV'></span>

<h3>Description</h3>

<p>Since the presence of artifacts may inflate the observed variance in correlations, 
one needs to compute the variance attributed to the artifacts. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varAV(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varAV_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>varAV is computed as <code class="reqn">\code{rhoCA}^2 * \code{CAFAA}^2 * \code{CVF}</code>
</p>
<p>varAV is used to compute the residual variance in correlations <code><a href="#topic+varResT">varResT</a></code> </p>


<h3>Value</h3>

<p>A numeric value representing the variance due to attenuating artifacts</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+CAFAA">CAFAA</a></code>,<code><a href="#topic+rhoCA">rhoCA</a></code>, <code><a href="#topic+CVF">CVF</a></code>   </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
varAV(ABHt32)

# From Hunter et al
data(HSJt35)
varAV(HSJt35)
</code></pre>

<hr>
<h2 id='vare'> Sampling Error Variance</h2><span id='topic+vare'></span><span id='topic+aprox.vare'></span><span id='topic+vare36'></span>

<h3>Description</h3>

<p>Computes sampling error variance in correlations from a data object of the general format found in 
<code><a href="#topic+EnterMeta">EnterMeta</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vare(x)
aprox.vare(x)
vare36(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vare_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vare</code> is the 'core' equation for estimating the sampling error variance. Presumably because
of the history of meta-analysis and lack of desktop computing power, hand-calculatons were needed. 
Thus, two additional equations were developed. The <code>aprox.vare</code> appears in many textbooks and is
used often (Arthur et al.). Another variation is presented by Hunter &amp; Schmidt (2004)
as their equation 3.6 <code>vare36</code>.
</p>


<h3>Value</h3>

<p>Sampling error variance (exact, approximate, or alternate aproximate)
</p>


<h3>Note</h3>

<p> The equations for each function are: <br />
vare &lt;- <code class="reqn">sum(n*(1-rb^2)^2/(n-1),na.rm=TRUE)/sum(n,na.rm=TRUE)</code> <br />
aprox.vare &lt;- <code class="reqn">(1-rb^2)^2/(mean(n, na.rm=TRUE)-1)</code> <br />
vare36 &lt;- <code class="reqn">((1-rb^2)^2*k)/T</code>  where k is number of studies and T is total sample size
</p>
<p>These are only presented here for completeness. The recommended equation is <code>vare</code>. 
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+rbar">rbar</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
vare(ABHt32)
aprox.vare(ABHt32)
vare36(ABHt32)
# From Hunter et al
data(HSJt35)
vare(HSJt35)
aprox.vare(HSJt35)
vare36(HSJt35)
</code></pre>

<hr>
<h2 id='varr'> Sample Size weighted variance</h2><span id='topic+varr'></span>

<h3>Description</h3>

<p>Computes the weighted variance in correlations from a data object of the general format found in 
<code><a href="#topic+EnterMeta">EnterMeta</a></code></p>


<h3>Usage</h3>

<pre><code class='language-R'>varr(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varr_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a set of correlations for each study (i), varr is computed as:
<code class="reqn">sum(Ni*(ri-rbar)^2)/sum(Ni)</code> where, Ni is the sample size of study i and ri
is the correlation in study i and rbar is the weighted mean correlation.
</p>


<h3>Value</h3>

<p>Sample weighted variance in correlations: uncorrected for artifacts other than sampling error
</p>


<h3>Note</h3>

<p> This is the variance in correlations across studies corrected for sampling error. 
It is also known as bare-bones meta-analysis.</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+vare">vare</a></code>, <code><a href="#topic+rbar">rbar</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
varr(ABHt32)
# From Hunter et al
data(HSJt35)
varr(HSJt35)

</code></pre>

<hr>
<h2 id='varRCA'> Variance in Meta-Analytic Rho </h2><span id='topic+varRCA'></span>

<h3>Description</h3>

<p>Computes the estimate of the variance in the corrected correlation coefficient.</p>


<h3>Usage</h3>

<pre><code class='language-R'>varRCA(x, aprox = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varRCA_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="varRCA_+3A_aprox">aprox</code></td>
<td>
<p> Logical test to determine if the approximate or exact var e is used </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variance in Rho is computed as: <code class="reqn">\code{VarResT} / \code{CAFFA}^2</code>
</p>
<p>This is used to construct credibility intervals for rho <code><a href="#topic+CredIntRho">CredIntRho</a></code>
</p>


<h3>Value</h3>

<p>A numeric value representing the variance in the population correlation coefficient
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rhoCA">rhoCA</a></code>, <code><a href="#topic+CAFAA">CAFAA</a></code>, <code><a href="#topic+varResT">varResT</a></code>, <code><a href="#topic+varRes">varRes</a></code>  
<code><a href="#topic+CredIntRho">CredIntRho</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
varRCA(ABHt32)

# From Hunter et al
data(HSJt35)
varRCA(HSJt35)
</code></pre>

<hr>
<h2 id='varRes'> Residual Variance in Meta-Analytic Correlation </h2><span id='topic+varRes'></span>

<h3>Description</h3>

<p>Computes the residual variance in the sample-weighted correlation coefficient by removing
variance due to sampling error.</p>


<h3>Usage</h3>

<pre><code class='language-R'>varRes(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varRes_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy and n: see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>computed as <code>varr</code> - <code>vare</code>
</p>
<p>Useful in the construction of the SE for heterogenous populations <code><a href="#topic+SERHET">SERHET</a></code></p>


<h3>Value</h3>

<p>A numeric value representing the residual variance
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+vare">vare</a></code>, <code><a href="#topic+SERHET">SERHET</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
varRes(ABHt32)

# From Hunter et al
data(HSJt35)
varRes(HSJt35)
</code></pre>

<hr>
<h2 id='varResT'> True residual variance in correlations </h2><span id='topic+varResT'></span>

<h3>Description</h3>

<p>Residual variance attributed to both the variance due to sampling error and 
artifacts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varResT(x, aprox = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varResT_+3A_x">x</code></td>
<td>
<p> A matrix or data.frame with columns Rxy, n and artifacts (Rxx, Ryy, u): 
see <code><a href="#topic+EnterMeta">EnterMeta</a></code></p>
</td></tr>
<tr><td><code id="varResT_+3A_aprox">aprox</code></td>
<td>
<p> Logical test to determine if the approximate or exact var e is used </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>varResT</code> &lt;- <code>varr</code> - <code>vare</code> - <code>varAV</code>
</p>
<p>varResT is used in the compution of the variance in rho, <code>varRCA</code>
</p>


<h3>Value</h3>

<p>A numeric value representing the True residual variance
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Arthur, Jr., W., Bennett, Jr., W., and Huffcutt, A. I. (2001) 
<em>Conducting Meta-analysis using SAS.</em>
Mahwah, NJ: Erlbaum.
</p>
<p>Hunter, J.E. and Schmidt, F.L. (2004). <em>Methods of meta-analysis: 
Correcting error and bias in research findings (2nd ed.).</em> Thousand Oaks: Sage Publications.
</p>
<p>Hunter, J.E., Schmidt, F.L., and Jackson, G.B. (1982). <em>Meta-analysis: 
Cumulating research findings across studies.</em> Beverly Hills: Sage Publications.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+varr">varr</a></code>, <code><a href="#topic+vare">vare</a></code>, <code><a href="#topic+varAV">varAV</a></code>, <code><a href="#topic+varRCA">varRCA</a></code>    </p>


<h3>Examples</h3>

<pre><code class='language-R'># From Arthur et al
data(ABHt32)
varResT(ABHt32)

# From Hunter et al
data(HSJt35)
varResT(HSJt35)
</code></pre>

<hr>
<h2 id='z2r'> Fisher z' to r</h2><span id='topic+z2r'></span><span id='topic+Fisher+20z+20to+20r'></span>

<h3>Description</h3>

<p>Converts a Fishers z' to Pearson correlation coefficient
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z2r(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z2r_+3A_x">x</code></td>
<td>
<p> z' (Fishers z prime) </p>
</td></tr>
</table>


<h3>Details</h3>

<p> r = (exp(2*z)-1)/exp(2*z)+1)
</p>


<h3>Value</h3>

<p>A Pearson Correlation coefficient
</p>


<h3>Author(s)</h3>

<p> Thomas D. Fletcher <a href="mailto:t.d.fletcher05@gmail.com">t.d.fletcher05@gmail.com</a> </p>


<h3>References</h3>

 
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). 
<em>Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</em>
Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+r2z">r2z</a></code>, 
<code><a href="#topic+CIr">CIr</a></code>, 
<code><a href="#topic+CIz">CIz</a></code>, 
<code><a href="#topic+SEz">SEz</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># From ch. 2 in Cohen et al (2003)
zp &lt;- r2z(.657)
zp
z2r(zp)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
