<!DOCTYPE html><html><head><title>Help for package irrNA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {irrNA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Consist'><p>irrNA example data, showing perfect consistency between raters</p></a></li>
<li><a href='#ConsistNA'><p>irrNA example data, showing perfect consistency between raters and NAs</p></a></li>
<li><a href='#Ebel51'><p>Example data, given by Ebel (1951, Table 2)</p></a></li>
<li><a href='#EbelFILL'><p>Example data, based on Ebel (1951, Table 2)</p></a></li>
<li><a href='#icc_corr'><p>Intraclass correlation coefficients (ICCs) for oneway and twoway models &ndash; corrected version</p>
of icc{irr}</a></li>
<li><a href='#iccNA'><p>Intraclass correlation coefficients (ICCs) &ndash; generalized for randomly incomplete datasets</p></a></li>
<li><a href='#Indep'><p>irrNA example data, showing perfect independence among raters and objects</p></a></li>
<li><a href='#IndepNA'><p>irrNA example data, showing NAs and perfect independence among raters and objects</p></a></li>
<li><a href='#IndepW'><p>irrNA example data, showing perfect independence among raters and NAs</p></a></li>
<li><a href='#kendallNA'><p>Kendall's coefficient of concordance W &ndash; generalized for randomly incomplete datasets</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Coefficients of Interrater Reliability – Generalized for
Randomly Incomplete Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-04-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Markus Brueckl [aut, cre], Florian Heuer [aut, trl]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Markus Brueckl &lt;markus.brueckl@tu-berlin.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides coefficients of interrater reliability that are generalized to cope with randomly incomplete (i.e. unbalanced) datasets without any imputation of missing values or any (row-wise or column-wise) omissions of actually available data. Applied to complete (balanced) datasets, these generalizations yield the same results as the common procedures, namely the Intraclass Correlation according to McGraw &amp; Wong (1996) \doi{10.1037/1082-989X.1.1.30} and the Coefficient of Concordance according to Kendall &amp; Babington Smith (1939) \doi{10.1214/aoms/1177732186}.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://CRAN.R-project.org/package=irrNA">https://CRAN.R-project.org/package=irrNA</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-04 17:52:54 UTC; Brückl</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-04 18:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Consist'>irrNA example data, showing perfect consistency between raters</h2><span id='topic+Consist'></span>

<h3>Description</h3>

<p>This data set shows perfect consistency and moderate agreement between raters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Consist)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers.</p>

<hr>
<h2 id='ConsistNA'>irrNA example data, showing perfect consistency between raters and NAs</h2><span id='topic+ConsistNA'></span>

<h3>Description</h3>

<p>This data set shows missing values (NAs) and perfect consistency and moderate agreement between raters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ConsistNA)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers and NAs.</p>

<hr>
<h2 id='Ebel51'>Example data, given by Ebel (1951, Table 2)</h2><span id='topic+Ebel51'></span>

<h3>Description</h3>

<p>This data set is used by Ebel (1951) to demonstate the computation of an intraclass correlation on incomplete data sets.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Ebel51)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers and NAs.</p>


<h3>Source</h3>

<p>Psychometrika</p>


<h3>References</h3>

<p>Ebel, R.L. (1951). Estimation of the reliability of ratings. Psychometrika, 16(4), 407&ndash;424.</p>

<hr>
<h2 id='EbelFILL'>Example data, based on Ebel (1951, Table 2)</h2><span id='topic+EbelFILL'></span>

<h3>Description</h3>

<p>This data set is the same as Ebel51, but with the missing data filled up with arbitrary values.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(EbelFILL)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers.</p>


<h3>References</h3>

<p>Ebel, R.L. (1951). Estimation of the reliability of ratings. Psychometrika, 16(4), 407&ndash;424.</p>

<hr>
<h2 id='icc_corr'>Intraclass correlation coefficients (ICCs) for oneway and twoway models &ndash; corrected version 
of icc{irr}</h2><span id='topic+icc_corr'></span>

<h3>Description</h3>

<p>Computes single score or average score ICCs as an index of interrater reliability of 
quantitative data. Additionally, F-test and confidence interval are computed. icc_corr{irrNA}
corrects 3 errors of Matthias Gamer's function <a href="irr.html#topic+icc">icc</a> (version 0.84.1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icc_corr(
  ratings,
  model = c("oneway", "twoway"),
  type = c("consistency", "agreement"),
  unit = c("single", "average"),
  r0 = 0,
  conf.level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icc_corr_+3A_ratings">ratings</code></td>
<td>
<p>n*m matrix or dataframe, n subjects m raters.</p>
</td></tr>
<tr><td><code id="icc_corr_+3A_model">model</code></td>
<td>
<p>a character string specifying if a &quot;oneway&quot; model (default) with row effects random, 
or a &quot;twoway&quot; model with column and row effects random should be applied. You can specify just 
the initial letter.</p>
</td></tr>
<tr><td><code id="icc_corr_+3A_type">type</code></td>
<td>
<p>a character string specifying if &quot;consistency&quot; (default) or &quot;agreement&quot; between 
raters should be estimated. If a '&quot;oneway&quot;' model is used, only &quot;consistency&quot; could be computed. 
You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="icc_corr_+3A_unit">unit</code></td>
<td>
<p>a character string specifying the unit of analysis: Must be one of &quot;single&quot; (default) 
or &quot;average&quot;. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="icc_corr_+3A_r0">r0</code></td>
<td>
<p>specification of the null hypothesis r <code class="reqn">\le</code> r0. Note that a one sided test 
(H1: r &gt; r0) is performed.</p>
</td></tr>
<tr><td><code id="icc_corr_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By this ICC-function three bugs are corrected that were found in the function 
<a href="irr.html#topic+icc">icc</a> of the irr package (version 0.84.1): <br />
Due to the first bug the p-values of ICC(A,1) and ICC(A,k) are computed wrongly: 
McGraw &amp; Wong (1996) use the variable &quot;v&quot; both for the computation of the CIs and for the 
computation of the p-values. But &quot;v&quot; takes different values in these calculations. In the 
implementation of icc{irr} (version 0.84.1) this fact is missed. <br />
The second correction only affects the rare case of the residual mean square (of the twoway 
model) being zero, i.e. the case that the variance in the data may be explained completely 
by the two factors (Raters and Objects). In this case the F-value for determining all four
twoway p-values is not correctly computet by <a href="irr.html#topic+icc">icc</a>.<br />
The third correction addresses the problems arising in the rare cases of (a) no part or (b) 
nearly no part of variance may be explained by both factors.
</p>


<h3>Value</h3>

<p>A list with class '&quot;icclist&quot;' containing the following components:
</p>
<table>
<tr><td><code>$subjects</code></td>
<td>
<p>the number of subjects examined.</p>
</td></tr>
<tr><td><code>$raters</code></td>
<td>
<p>the number of raters.</p>
</td></tr>
<tr><td><code>$model</code></td>
<td>
<p>a character string describing the selected model for the analysis.</p>
</td></tr>
<tr><td><code>$type</code></td>
<td>
<p>a character string describing the selected type of interrater reliability.</p>
</td></tr>
<tr><td><code>$unit</code></td>
<td>
<p>a character string describing the unit of analysis.</p>
</td></tr>
<tr><td><code>$icc.name</code></td>
<td>
<p>a character string specifying the name of ICC according to McGraw &amp; Wong (1996).</p>
</td></tr>
<tr><td><code>$value</code></td>
<td>
<p>the intraclass correlation coefficient.</p>
</td></tr>
<tr><td><code>$r0</code></td>
<td>
<p>the specified null hypothesis.</p>
</td></tr>
<tr><td><code>$Fvalue</code></td>
<td>
<p>the value of the F-statistic.</p>
</td></tr>
<tr><td><code>$df1</code></td>
<td>
<p>the numerator degrees of freedom.</p>
</td></tr>
<tr><td><code>$df2</code></td>
<td>
<p>the denominator degrees of freedom.</p>
</td></tr>
<tr><td><code>$p.value</code></td>
<td>
<p>the p-value for a two-sided test.</p>
</td></tr>
<tr><td><code>$conf.level</code></td>
<td>
<p>the confidence level for the interval.</p>
</td></tr>
<tr><td><code>$lbound</code></td>
<td>
<p>the lower bound of the confidence interval.</p>
</td></tr>
<tr><td><code>$ubound</code></td>
<td>
<p>the upper bound of the confidence interval.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Gamer, Markus Brueckl
</p>


<h3>References</h3>

<p>McGraw, K.O., &amp; Wong, S.P. (1996). Forming inferences about some intraclass 
correlation coefficients. Psychological Methods, 1, 30&ndash;46.
</p>
<p>Shrout, P.E., &amp; Fleiss, J.L. (1979), Intraclass correlation: 
uses in assessing rater reliability. Psychological Bulletin, 86, 420&ndash;428.
</p>


<h3>See Also</h3>

<p><code><a href="irr.html#topic+icc">icc</a></code>, <code><a href="#topic+iccNA">iccNA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1:
data(EbelFILL)
# EbelFILL is a rather arbitrary data set:
EbelFILL
# If twoway agreement ICCs are computed (e.g. the single 
# measure) with icc{irr}, the 2nd df of F and thus the 
# p-value is erroneous (please install and load the irr 
# package):
#icc(EbelFILL, model="twoway", type="agreement")
# icc_corr calculates correctly: 
icc_corr(EbelFILL, model="twoway", type="agreement")
# 
# Example 2:
data(Consist)
# Consist exhibits a perfect consistency and 
# a moderate absolute agreement between raters:
Consist
# If twoway ICCs are computed with icc{irr}, the F-value is smaller
# than zero (!) and thus the p-value is enourmously erroneous:
#icc(Consist, model="twoway", type="consistency", unit="average")
# icc_corr calculates correctly: 
icc_corr(Consist, model="twoway", type="consistency", unit="average")
#
# Example 3:
data(Indep)
# Indep exhibits zero variance between the raters just as 
# well as between the objects:
Indep
# Errors occur, if twoway agreement ICCs are computed with icc{irr}:
# ICC(A,k) just as well as its CI-bounds are (falsely) positive 
# and greater than 1...
#icc(Indep, model="twoway", type="agreement", unit="average")
# ...but must be -Inf, just as icc_corr shows:
icc_corr(Indep, model="twoway", type="agreement", unit="average")
# ICC(A,1): 2nd df of F and thus the p-value are NaN
#icc(Indep, model="twoway", type="agreement")
# icc_corr calculates correlctly:
icc_corr(Indep, model="twoway", type="agreement")
</code></pre>

<hr>
<h2 id='iccNA'>Intraclass correlation coefficients (ICCs) &ndash; generalized for randomly incomplete datasets</h2><span id='topic+iccNA'></span>

<h3>Description</h3>

<p>This function computes intraclass correlation coefficients (ICCs) as indices of 
interrater reliability or agreement based on cardinally scaled data. This function also works on 
(unbalanced) incomplete datasets without any imputation of missing values (<em>NA</em>s) or (row- or 
cloumn-wise) omissions of data! p-values and confidence intervals are provided. In case of 
extreme input data (e.g. zero variances) output <em>NaN</em>s are avoided by approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iccNA(ratings, rho0 = 0, conf = 0.95, detail = FALSE, oneG = TRUE, Cs = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iccNA_+3A_ratings">ratings</code></td>
<td>
<p>n*m matrix or data frame; n objects (rows), m raters (columns)</p>
</td></tr>
<tr><td><code id="iccNA_+3A_rho0">rho0</code></td>
<td>
<p>numeric value; correlation in population (<code class="reqn">\rho</code>) according to the null 
hypothesis (0 is default)</p>
</td></tr>
<tr><td><code id="iccNA_+3A_conf">conf</code></td>
<td>
<p>numeric value; confidence level (95% is default)</p>
</td></tr>
<tr><td><code id="iccNA_+3A_detail">detail</code></td>
<td>
<p>logical; if TRUE (FALSE is default), returns additional information (sums of squares, degrees of 
freedom, the means per object, data corrected for the raters' biases)</p>
</td></tr>
<tr><td><code id="iccNA_+3A_oneg">oneG</code></td>
<td>
<p>logical; if TRUE (default), the ipsation (correction for the raters' effects) is done the 
simple way, using the difference of each raters mean to the one grand mean (<code class="reqn">G</code>) of all 
values to estimate the raters' biases. If FALSE the weighted sub-means (<code class="reqn">G_j</code>)
of those objects that an individual rater <code class="reqn">j</code> rated are used instead (cp. Brueckl, 2011, 
Equation 4.30).</p>
</td></tr>
<tr><td><code id="iccNA_+3A_cs">Cs</code></td>
<td>
<p>numeric value; denominator (10000 is default) of the effect-size-criterion to stop 
iteration of the correction for the raters' biases; the enumerator denotes a small effect 
(<code class="reqn">\eta</code>-squared = 1%)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is able to compute ICCs on randomly incomplete (i.e. unbalanced) data sets. 
Thus, both an imputation of missing values (<em>NA</em>s) and row-wise or column-wise omissions of 
data are obsolete. Working on complete datasets, it yields the same results as the common 
functions, e.g. <a href="#topic+icc_corr">icc_corr</a>.<br />
The method of Ebel (1951) is used to calculate the oneway ICCs. The solution for the twoway 
ICCs is derived from the oneway solution (cp. Brueckl, 2011, p. 96 ff.): The raters' individual 
effects (biases) are estimated, reducing this problem again to the oneway problem (cp. Greer &amp; 
Dunlap, 1997).<br />
This estimation can be done using the difference of a certain (<code class="reqn">j</code>) rater's mean to the 
grand mean (<code class="reqn">G</code>) or to the sub-mean (<code class="reqn">G_j</code>) representing only those objects 
that were rated by this rater. The first method is fail-safe. The second method is thought to 
provide the more precise estimates (of the raters' biases), the more the mean of the true values 
of the objects that each rater rated differ from the grand mean, e.g. if there are raters that 
only rate objects with low true values (and therefore also other raters that only rate objects 
with high true values).<br />
If the second method is chosen and if the ratings are unbalanced, which happens most of the time 
if not all raters rated all objects, the raters' biases cannot be determined exactly &ndash; but as 
approximately as desired. This approximation needs an iteration, thus a stop criterion 
(<code>Cs</code>): 
The iteration is stopped, when the difference in the raters' effect size (<code class="reqn">\eta</code>-squared) 
between subsequent iterations would be equal to or smaller than the <code>Cs</code>th part of a small 
effect (i.e. <code class="reqn">\eta</code>-squared = 1%).<br />
<br />
Just as in <a href="#topic+icc_corr">icc_corr</a> and <a href="irr.html#topic+icc">icc</a>, the designation established by McGraw 
&amp; Wong (1996) &ndash; <em>A</em> for <em>absolute agreement</em> and <em>C</em> for <em>consistency</em> 
&ndash; is used to differ between the (twoway) ICCs that rely on different cases and thus must be 
interpreted differently.<br />
<br />
The generalization of the procedure entails a generalization of the three cases that 
differentiate the ICCs (cp. Shrout &amp; Fleiss, 1979):<br />
- Case 1 (oneway case, treated by ICC(1) and ICC(k)): <br />
Each object &ndash; of a sample that was randomly drawn from the population of objects; also 
holds true for case 2 and case 3 &ndash; is rated by (a different number of) different raters 
that were randomly drawn from the population of raters.<br />
- Case 2 (twoway case, treated by ICC(A,1) and ICC(A,k)): <br />
Each object is rated by a random subset of the group of raters that is drawn randomly from 
the population of raters.<br />
- Case 3 (twoway case, treated by ICC(C,1) and ICC(C,k)): <br />
Each object is rated by a random subset of the group of all relevant (i.e. fixed) raters.<br />
<br />
Output NaNs, that usually occur (see e.g. <a href="irr.html#topic+icc">icc</a> or <a href="#topic+icc_corr">icc_corr</a>) in case 
of extreme input data (e.g. in case of zero variance(s), within or between objects) are 
avoided by approximation from little less extreme input data. Warning messages are given in 
these cases.<br />
<br />
</p>


<h3>Value</h3>

<table>
<tr><td><code>ICCs</code></td>
<td>
<p>data frame containing the intraclass correlation coefficients, the corresponding 
p-values, and confidence intervals</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of rated objects</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>maximum number of raters per object</p>
</td></tr>
<tr><td><code>amk</code></td>
<td>
<p>mean number of ratings per object</p>
</td></tr>
<tr><td><code>k_0</code></td>
<td>
<p>approximate harmonic mean (cp. Ebel, 1951) of the number of ratings per object</p>
</td></tr>
<tr><td><code>n_iter</code></td>
<td>
<p>number of iterations for correcting for the raters' biases</p>
</td></tr>
<tr><td><code>corr_ratings</code></td>
<td>
<p>ratings, corrected for the individual raters' biases</p>
</td></tr>
<tr><td><code>amO</code></td>
<td>
<p>means of ratings for each object, based on (1) the original data and on (2) the 
data that 
are corrected for the raters' biases</p>
</td></tr>
<tr><td><code>oneway</code></td>
<td>
<p>statistics for the oneway ICCs</p>
</td></tr>
<tr><td><code>twoway</code></td>
<td>
<p>statistics for the twoway ICCs</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Brueckl
</p>


<h3>References</h3>

<p>Brueckl, M. (2011). Statistische Verfahren zur Ermittlung der 
Urteileruebereinstimmung. in: Altersbedingte Veraenderungen der Stimme und Sprechweise von 
Frauen, Berlin: Logos, 88&ndash;103.
</p>
<p>Ebel, R.L. (1951). Estimation of the reliability of ratings. Psychometrika, 16(4), 
407&ndash;424.
</p>
<p>Greer, T., &amp; Dunlap, W.P. (1997). Analysis of variance with ipsative measures. 
Psychological Methods, 2, 200&ndash;207.
</p>
<p>McGraw, K.O., &amp; Wong, S.P. (1996). Forming inferences about some intraclass 
correlation coefficients. Psychological Methods, 1, 30&ndash;46.
</p>
<p>Shrout, P.E., &amp; Fleiss, J.L. (1979). Intraclass correlations: uses in assessing rater
reliability. Psychological Bulletin, 86(2), 420&ndash;428.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kendallNA">kendallNA</a>, <a href="#topic+icc_corr">icc_corr</a>, <a href="irr.html#topic+icc">icc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1:
data(ConsistNA)
# ConsistNA exhibits missing values, a perfect consistency, and 
# a moderate agreement between raters:
ConsistNA
# Common ICC-algorithms fail, since each row as well as each 
# column of ConsistNA exhibits unfilled cells and these missing 
# data are omitted column-wise or row-wise (please install and  
# load the irr package):
#icc(ConsistNA, r0=0.3)
# Ebel's (1951) method for computing ICC(1) and ICC(k) that is 
# implemented in iccNA can cope with such data without an 
# omission or an imputation of missing values, but still can 
# not depict the raters' interdependency...
iccNA(ConsistNA, rho0=0.3)
# ...but generalizations of Ebel's method for the twoway ICCs 
# are able to assess moderate agreement (ICC(A,1) and ICC(A,k)) 
# and perfect consistency (ICC(C,1) and ICC(C,k)), assuming that 
# the data were acquired under case 2 or case 3, see Details in 
# the Help file.
#
# Example 2:
data(IndepNA)
# IndepNA exhibits missing values and zero variance between 
# the raters just as well as between the objects:
IndepNA
# Again, common ICC-algorithms fail (cp. irr package):
#icc(IndepNA)
# But iccNA is able to include all available data in its 
# calculation and thereby to show the perfect independence of 
# the ratings:
iccNA(IndepNA)
#
# Example 3:
# The example provided by Ebel (1951, Tables 2 and 3):
# data(Ebel51)
Ebel51
# iCCNA achieves to include all available ratings and to assess 
# twoway ICCs, assuming that the data were acquired under 
# case 2 or case 3:
iccNA(Ebel51, detail=TRUE)
</code></pre>

<hr>
<h2 id='Indep'>irrNA example data, showing perfect independence among raters and objects</h2><span id='topic+Indep'></span>

<h3>Description</h3>

<p>This data set shows perfect independance among raters and objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Indep)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers.</p>

<hr>
<h2 id='IndepNA'>irrNA example data, showing NAs and perfect independence among raters and objects</h2><span id='topic+IndepNA'></span>

<h3>Description</h3>

<p>This data set shows missing values (NAs) and perfect independance among raters and objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(IndepNA)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers and NAs.</p>

<hr>
<h2 id='IndepW'>irrNA example data, showing perfect independence among raters and NAs</h2><span id='topic+IndepW'></span>

<h3>Description</h3>

<p>This data set shows missing values (NAs) and perfect independance among raters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(IndepW)</code></pre>


<h3>Format</h3>

<p>A 2-dimensional data frame including column and row headers and NAs.</p>

<hr>
<h2 id='kendallNA'>Kendall's coefficient of concordance W &ndash; generalized for randomly incomplete datasets</h2><span id='topic+kendallNA'></span>

<h3>Description</h3>

<p>This function computes Kendall's coefficient of concordance W that is an index of 
interrater reliability for ordinal ratings. This function also works on incomplete datasets without 
any imputation of missing values or (row- or cloumn-wise) omissions of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kendallNA(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kendallNA_+3A_x">X</code></td>
<td>
<p>n*m matrix or dataframe; n objects (rows), k  raters (columns)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is able to calculate W, also on randomly incomplete (i.e. unbalanced) 
data sets. Therefor it uses the mean Spearman's <code class="reqn">\rho</code> of all pairwise comparisons, see Kendall
(1962):
</p>
<p style="text-align: center;"><code class="reqn">W = [1 + mean \rho_S * (k-1)] / k</code>
</p>

<p>where k is the mean number of (pairwise) ratings per object and <code class="reqn">mean \rho_S</code> is calculated 
weighted, according to Taylor (1987), since the pairwise <code class="reqn">\rho_S</code> are possibly based on a 
different number of ratings, what must be reflected in weights.<br />
Thus, an imputation of missing values or (row- or cloumn-wise) omissions of data are obsolete. In 
case of complete datasets, it yields the same results as usual implementations of Kendall's W, 
except for tied ranks. In case of tied ranks, the (pairwise) correction of <code class="reqn">\rho_S</code> is used, 
which (already with complete datasets) results in slightly different values than the tie correction 
explicitly specified for W.<br />
More details are given in Brueckl (2011).
</p>


<h3>Value</h3>

<table>
<tr><td><code>amrho</code></td>
<td>
<p>mean Spearman's <code class="reqn">\rho</code></p>
</td></tr>
<tr><td><code>amk</code></td>
<td>
<p>mean number of (pairwise) ratings per object</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>Kendall's coefficient of concordance among raters</p>
</td></tr>
<tr><td><code>chisqu</code></td>
<td>
<p>value of the  <code class="reqn">\chi</code>-squared test statistic</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>one-tailed type I error probability (statistical significance)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Markus Brueckl
</p>


<h3>References</h3>

<p>Brueckl, M. (2011). Statistische Verfahren zur Ermittlung der Urteileruebereinstimmung. 
in: Altersbedingte Veraenderungen der Stimme und Sprechweise von Frauen, Berlin: Logos, 88&ndash;103.
</p>
<p>Kendall, M.G. (1962). Rank correlation methods (3rd ed.). London: Griffin.
</p>
<p>Taylor, J.M.G. (1987). Kendall's and Spearman's correlation coefficients in the 
presence of a blocking variable. Biometrics, 43, 409&ndash;416.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+iccNA">iccNA</a>, <a href="irr.html#topic+kendall">kendall</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1:
data(ConsistNA)
# ConsistNA exhibits missing values and a perfect concordance
# between raters:
ConsistNA
# Common W-algorithms fail, since each row as well as each 
# column of ConsistNA exhibits unfilled cells and these missing 
# data are omitted column-wise or row-wise (please install and 
# load the irr package):
#kendall(ConsistNA)
# But the generalization of Kendall's W implemeted in irrNA 
# is able to assess the perfect concordance, assuming that 
# the data were at least ordinally scaled and not tied, e.g. 
# that each rater really ranked the objects that he rated 
# without giving equal ranks to two or more objects.
kendallNA(ConsistNA)
#
# Example 2:
data(IndepNA)
# IndepNA exhibits missing values and zero variance between 
# the raters (just as well as between the objects):
IndepNA
# Common W-algorithms fail:
#kendall(IndepNA)
# kendallNA includes all (rater-pairwise) available data in 
# its calculation (e.g. only Objects 1--4 when Rater1 and 
# Rater2 are correlated):
kendallNA(IndepNA)
#
# Example 3:
data(IndepW)
# IndepW exhibits missing values and a mean Spearman's rho,
# that equals zero:
IndepW
# Again, common W-algorithms fail,
#kendall(IndepW)
# while kendallNA includes all (rater-pairwise) available 
# data:
kendallNA(IndepW)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
