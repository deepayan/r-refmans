<!DOCTYPE html><html lang="en"><head><title>Help for package bplsr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bplsr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bplsr-package'><p>bplsr: Bayesian partial least squares regression</p></a></li>
<li><a href='#bplsr'><p>Run the BPLS regression model</p></a></li>
<li><a href='#bplsr.predict'><p>Predict from a fitted BPLS regression model</p></a></li>
<li><a href='#milk_MIR'><p>Milk traits and corresponding mid-infrared spectra</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Bayesian partial least squares regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Szymon Urbas &lt;szymon.urbas@mu.ie&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits the Bayesian partial least squares regression model
    introduced in Urbas et al. (2024) &lt;<a href="https://doi.org/10.1214%2F24-AOAS1947">doi:10.1214/24-AOAS1947</a>&gt;. Suitable
    for univariate and multivariate regression with high-dimensional data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>coda, progress, statmod, stats, utils</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-21 11:58:31 UTC; surbas</td>
</tr>
<tr>
<td>Author:</td>
<td>Szymon Urbas [aut, cre],
  Pierre Lovera [ctb],
  Robert Daly [ctb],
  Alan O'Riordan [ctb],
  Donagh Berry [ctb],
  Isobel Claire Gormley [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-21 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bplsr-package'>bplsr: Bayesian partial least squares regression</h2><span id='topic+bplsr-package'></span>

<h3>Description</h3>

<p>Fits the Bayesian partial least squares regression model introduced in Urbas et al. (2024) <a href="https://doi.org/10.1214/24-AOAS1947">doi:10.1214/24-AOAS1947</a>. Suitable for univariate and multivariate regression with high-dimensional data.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Szymon Urbas <a href="mailto:szymon.urbas@mu.ie">szymon.urbas@mu.ie</a>
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Pierre Lovera [contributor]
</p>
</li>
<li><p> Robert Daly [contributor]
</p>
</li>
<li><p> Alan O'Riordan [contributor]
</p>
</li>
<li><p> Donagh Berry [contributor]
</p>
</li>
<li><p> Isobel Claire Gormley [contributor]
</p>
</li></ul>


<hr>
<h2 id='bplsr'>Run the BPLS regression model</h2><span id='topic+bplsr'></span>

<h3>Description</h3>

<p>Posterior inference of the Bayesian partial least squares regression model using a Gibbs sampler. There are three types of models available depending on the assumed prior structure on the model parameters (see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bplsr(
  X,
  Y,
  Xtest = NULL,
  Prior = NULL,
  Qs = NULL,
  N_MCMC = 20000,
  BURN = ceiling(0.3 * N_MCMC),
  Thin = 1,
  model.type = "standard",
  scale. = TRUE,
  center. = TRUE,
  PredInterval = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bplsr_+3A_x">X</code></td>
<td>
<p>Matrix of predictor variables.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_y">Y</code></td>
<td>
<p>Vector or matrix of responses.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_xtest">Xtest</code></td>
<td>
<p>Matrix of predictor variables to predict for.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_prior">Prior</code></td>
<td>
<p>List of hyperparameters specifying the parameter prior distributions. If left <code>NULL</code>, a generic set of priors will be generated.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_qs">Qs</code></td>
<td>
<p>Upper limit on the number of latent components. If <code>NULL</code> it is chosen automatically.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_n_mcmc">N_MCMC</code></td>
<td>
<p>Number of iterations to run the Markov chain Monte Carlo algorithm.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_burn">BURN</code></td>
<td>
<p>Number of iteration to be discarded as the burn-in.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_thin">Thin</code></td>
<td>
<p>Thinning procedure for the MArkov chain. <code>Thin = 1</code> results in no thinning. Only use for long chains to reduce memory.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_model.type">model.type</code></td>
<td>
<p>Type of BPLS model to use; one of <code>standard</code>, <code>ss</code> (spike-and-slab), or <code>LASSO</code> (see details).</p>
</td></tr>
<tr><td><code id="bplsr_+3A_scale.">scale.</code></td>
<td>
<p>Logical; if <code>TRUE</code> then the data variables will be scale to have unit variance.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_center.">center.</code></td>
<td>
<p>Logical; if <code>TRUE</code> then the data variables will be zero-centred.</p>
</td></tr>
<tr><td><code id="bplsr_+3A_predinterval">PredInterval</code></td>
<td>
<p>Coverage of prediction intervals if <code>Xtest</code> is provided; 0.95 by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of latent variables is inferred using the multiplicative gamma process prior (Bhattacharya and Dunson, 2011).
Posterior samples from the fitted model are stored as a list.
There are three types of parameter prior structures resulting in three different model types:
</p>

<ul>
<li> <p><strong>BPLS</strong>: No additional structure assumed; set <code>model.type=standard</code>. This model mimics the standard partial least squares regression (PLS; Wold, 1973).
</p>
</li>
<li> <p><strong>ss-BPLS</strong>: A spike-and-slab variant introducing additonal column-wise sparsity to the loading matrix relating to the response variables <code>Y</code>; set <code>model.type=ss</code>. This approach mimics the Two-way Orthogonal PLS regression (O2PLS; Trygg and Wold, 2003).
</p>
</li>
<li> <p><strong>L-BPLS</strong>: A LASSO variant introducing additonal element-wise sparsity to the loading matrix relating to the response variables <code>Y</code>; set <code>model.type=LASSO</code>. This approach mimics the sparse PLS regression (sPLS; Chun and Keles, 2010).
</p>
</li></ul>

<p>Empirical comparisons in Urbas et al. (2024) suggest that the LASSO variant is the best at point predictions and prediction interval coverage when applied to spectral data.
</p>


<h3>Value</h3>

<p>A list of:
</p>
<table role = "presentation">
<tr><td><code>chain</code></td>
<td>
<p>A Markov chain of samples from the parameter posterior.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>Original set of predictor variables.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>Original set of response variables.</p>
</td></tr>
<tr><td><code>Xtest</code></td>
<td>
<p>Original set of predictor variables to predict from; if <code>Xtest</code> is provided.</p>
</td></tr>
<tr><td><code>Ytest</code></td>
<td>
<p>Point predictions for new responses; if <code>Xtest</code> is provided.</p>
</td></tr>
<tr><td><code>Ytest_PI</code></td>
<td>
<p>Prediction intervals for new responses (by default 0.95 coverage); if <code>Xtest</code> is provided.</p>
</td></tr>
<tr><td><code>Ytest_dist</code></td>
<td>
<p>Posterior predictive distributions for new responses; if <code>Xtest</code> is provided.</p>
</td></tr>
<tr><td><code>diag</code></td>
<td>
<p>Additional diagnostics for assessing chain convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bhattacharya, A. and Dunson, D. B. (2011) Sparse Bayesian infinite factor models, <em>Biometrika</em>, 98(2): 291–306
</p>
<p>Chun, H. and Keles, S. (2010). Sparse partial least squares regression for simultaneous dimension reduction and variable selection. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 72(1):3–25.
</p>
<p>Trygg, J. and Wold, S. (2003). O2-PLS, a two-block (X–Y) latent variable regression (LVR) method with an integral OSC filter. <em>Journal of Chemometrics</em>, 17(1):53–64.
</p>
<p>Urbas, S., Lovera, P., Daly, R., O'Riordan, A., Berry, D., and Gormley, I. C. (2024). &quot;Predicting milk traits from spectral data using Bayesian probabilistic partial least squares regression.&quot; <em>The Annals of Applied Statistics</em>, 18(4): 3486-3506. <\doi{10.1214/24-AOAS1947}>
</p>
<p>Wold, H. (1973). Nonlinear iterative partial least squares (NIPALS) modelling: some current developments. In <em>Multivariate analysis–III</em>, pages 383–407. Elsevier.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data(milk_MIR)
X = milk_MIR$xMIR
Y = milk_MIR$yTraits[, c('Casein_content','Fat_content')]

set.seed(1)
# fit model to 25% of data and predict on remaining 75%
idx = sample(seq(nrow(X)),floor(nrow(X)*0.25),replace = FALSE)

Xtrain = X[idx,];Ytrain = Y[idx,]
Xtest = X[-idx,];Ytest = Y[-idx,]

# fit the model (default MCMC settings can take longer)
bplsr_Fit = bplsr(Xtrain,Ytrain)

# generate predictions
bplsr_pred = bplsr.predict(model = bplsr_Fit, newdata = Xtest)

# point predictions
head(bplsr_pred$Ytest)

# lower and upper limits of prediction interval
head(bplsr_pred$Ytest_PI)

# plot of predictive posterior distribution for single test sample
hist(bplsr_pred$Ytest_dist[1,'Casein_content',], freq = FALSE,
     main = 'Posterior predictive density', xlab = 'Casein_content')
</code></pre>

<hr>
<h2 id='bplsr.predict'>Predict from a fitted BPLS regression model</h2><span id='topic+bplsr.predict'></span>

<h3>Description</h3>

<p>Generates predictions from the fitted BPLS regression model using Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bplsr.predict(model, newdata, PredInterval = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bplsr.predict_+3A_model">model</code></td>
<td>
<p>Output of <code>bplsr</code>.</p>
</td></tr>
<tr><td><code id="bplsr.predict_+3A_newdata">newdata</code></td>
<td>
<p>Matrix of predictor variables to predict for.</p>
</td></tr>
<tr><td><code id="bplsr.predict_+3A_predinterval">PredInterval</code></td>
<td>
<p>Intended coverage of prediction intervals (between 0 and 1). Setting the value to 0 only produces point predictions without prediction intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions of the responses are generated from the posterior predictive distribution, marginalising out the model parameters; see Section 3.5 of Urbas et al. (2024).
</p>


<h3>Value</h3>

<p>A list of:
</p>
<table role = "presentation">
<tr><td><code>Ytest</code></td>
<td>
<p>Point predictions for new responses; if <code>Xtest</code> is provided.</p>
</td></tr>
<tr><td><code>Ytest_PI</code></td>
<td>
<p>Prediction intervals for new responses (by default 0.95 coverage); if <code>Xtest</code> is provided.</p>
</td></tr>
<tr><td><code>Ytest_dist</code></td>
<td>
<p>Posterior predictive distributions for new responses; if <code>Xtest</code> is provided.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Urbas, S., Lovera, P., Daly, R., O'Riordan, A., Berry, D., and Gormley, I. C. (2024). &quot;Predicting milk traits from spectral data using Bayesian probabilistic partial least squares regression.&quot; <em>The Annals of Applied Statistics</em>, 18(4): 3486-3506. <\doi{10.1214/24-AOAS1947}>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data(milk_MIR)
X = milk_MIR$xMIR
Y = milk_MIR$yTraits[, c('Casein_content','Fat_content')]

set.seed(1)
# fit model to 25% of data and predict on remaining 75%
idx = sample(seq(nrow(X)),floor(nrow(X)*0.25),replace = FALSE)

Xtrain = X[idx,];Ytrain = Y[idx,]
Xtest = X[-idx,];Ytest = Y[-idx,]

# fit the model (for default MCMC settings leave Qs and N_MCMC blank; can take longer)
bplsr_Fit = bplsr(Xtrain,Ytrain, Qs = 10, N_MCMC = 5000)

# generate predictions
bplsr_pred = bplsr.predict(model = bplsr_Fit, newdata = Xtest)

# point predictions
head(bplsr_pred$Ytest)

# lower and upper limits of prediction interval
head(bplsr_pred$Ytest_PI)

# plot of predictive posterior distribution for single test sample
hist(bplsr_pred$Ytest_dist[1,'Casein_content',], freq = FALSE,
     main = 'Posterior predictive density', xlab = 'Casein_content')
</code></pre>

<hr>
<h2 id='milk_MIR'>Milk traits and corresponding mid-infrared spectra</h2><span id='topic+milk_MIR'></span>

<h3>Description</h3>

<p>Data containing spectral measurements for 431 milk samples with various chemical and technological traits measures. Details can be found in Visentin et al. (2015) and McDermot et al. (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(milk_MIR)
</code></pre>


<h3>Format</h3>

<p>Data of 431 dairy milk samples with variables split into a list of 3 data frames:
</p>

<dl>
<dt><code>info</code></dt><dd><p>Information variables on the samples.</p>
</dd>
<dt><code>xMIR</code></dt><dd><p>531 spectral measurements in the mid-infrared region (predictors). Noisy water-regions have been removed.</p>
</dd>
<dt><code>yTraits</code></dt><dd><p>45 chemical and technological traits (responses); contains missing values.</p>
</dd>
</dl>



<h3>References</h3>

<p>McDermott, A., Visentin, G., De Marchi, M., Berry, D., Fenelon, M., O'connor, P., Kenny, O., and McParland, S. (2016). Prediction of individual milk proteins including free amino acids in bovine milk using mid-infrared spectroscopy and their correlations with milk processing characteristics. <em>Journal of Dairy Science, 99(4):3171–3182.</em>
</p>
<p>Visentin, G., McDermott, A., McParland, S., Berry, D., Kenny, O., Brodkorb, A., Fenelon, M., and De Marchi, M. (2015). Prediction of bovine milk technological traits from midinfrared spectroscopy analysis in dairy cows. <em>Journal of Dairy Science</em>, 98(9):6620–6629.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(milk_MIR, package="bplsr")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
