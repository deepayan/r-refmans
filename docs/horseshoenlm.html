<!DOCTYPE html><html lang="en"><head><title>Help for package horseshoenlm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {horseshoenlm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#afths'><p>Horseshoe shrinkage prior in Bayesian survival regression</p></a></li>
<li><a href='#lmhs'><p>Horseshoe shrinkage prior in Bayesian linear regression</p></a></li>
<li><a href='#logiths'><p>Horseshoe shrinkage prior in Bayesian Logistic regression</p></a></li>
<li><a href='#probiths'><p>Horseshoe shrinkage prior in Bayesian Probit regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Nonlinear Regression using Horseshoe Prior</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides the posterior estimates of the regression coefficients when horseshoe prior is specified. 
             The regression models considered here are logistic model for binary response and 
             log normal accelerated failure time model for right censored survival response. 
             The linear model analysis is also available for completeness. 
             All models provide deviance information criterion and widely applicable information criterion. 
             See &lt;<a href="https://doi.org/10.1111%2Frssc.12377">doi:10.1111/rssc.12377</a>&gt; Maity et. al. (2019) &lt;<a href="https://doi.org/10.1111%2Fbiom.13132">doi:10.1111/biom.13132</a>&gt; Maity et. al. (2020).  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>survival, msm</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, pgdraw, mvtnorm</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-12-16 21:35:11 UTC; MAITYA02</td>
</tr>
<tr>
<td>Author:</td>
<td>Arnab Kumar Maity [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Arnab Kumar Maity &lt;Arnab.Maity@pfizer.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-12-18 10:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='afths'>Horseshoe shrinkage prior in Bayesian survival regression</h2><span id='topic+afths'></span>

<h3>Description</h3>

<p>This function employs the algorithm provided by van der Pas et. al. (2016) for
log normal Accelerated Failure Rate (AFT) model to fit survival regression. The censored observations 
are updated according to the data augmentation approach described in Maity et. al. (2019) and 
Maity et. al. (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>afths(
  ct,
  X,
  method.tau = c("fixed", "truncatedCauchy", "halfCauchy"),
  tau = 1,
  method.sigma = c("fixed", "Jeffreys"),
  Sigma2 = 1,
  burn = 1000,
  nmc = 5000,
  thin = 1,
  alpha = 0.05,
  Xtest = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="afths_+3A_ct">ct</code></td>
<td>
<p>survival response, a <code class="reqn">n*2</code> matrix with first column as response and second column as right censored indicator,
1 is event time and 0 is right censored.</p>
</td></tr>
<tr><td><code id="afths_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, dimension <code class="reqn">n*p</code>.</p>
</td></tr>
<tr><td><code id="afths_+3A_method.tau">method.tau</code></td>
<td>
<p>Method for handling <code class="reqn">\tau</code>. Select &quot;truncatedCauchy&quot; for full
Bayes with the Cauchy prior truncated to [1/p, 1], &quot;halfCauchy&quot; for full Bayes with
the half-Cauchy prior, or &quot;fixed&quot; to use a fixed value (an empirical Bayes estimate,
for example).</p>
</td></tr>
<tr><td><code id="afths_+3A_tau">tau</code></td>
<td>
<p>Use this argument to pass the (estimated) value of <code class="reqn">\tau</code> in case &quot;fixed&quot;
is selected for method.tau. Not necessary when method.tau is equal to &quot;halfCauchy&quot; or
&quot;truncatedCauchy&quot;. The default (tau = 1) is not suitable for most purposes and should be replaced.</p>
</td></tr>
<tr><td><code id="afths_+3A_method.sigma">method.sigma</code></td>
<td>
<p>Select &quot;Jeffreys&quot; for full Bayes with Jeffrey's prior on the error
variance <code class="reqn">\sigma^2</code>, or &quot;fixed&quot; to use a fixed value (an empirical Bayes
estimate, for example).</p>
</td></tr>
<tr><td><code id="afths_+3A_sigma2">Sigma2</code></td>
<td>
<p>A fixed value for the error variance <code class="reqn">\sigma^2</code>. Not necessary
when method.sigma is equal to &quot;Jeffreys&quot;. Use this argument to pass the (estimated)
value of Sigma2 in case &quot;fixed&quot; is selected for method.sigma. The default (Sigma2 = 1)
is not suitable for most purposes and should be replaced.</p>
</td></tr>
<tr><td><code id="afths_+3A_burn">burn</code></td>
<td>
<p>Number of burn-in MCMC samples. Default is 1000.</p>
</td></tr>
<tr><td><code id="afths_+3A_nmc">nmc</code></td>
<td>
<p>Number of posterior draws to be saved. Default is 5000.</p>
</td></tr>
<tr><td><code id="afths_+3A_thin">thin</code></td>
<td>
<p>Thinning parameter of the chain. Default is 1 (no thinning).</p>
</td></tr>
<tr><td><code id="afths_+3A_alpha">alpha</code></td>
<td>
<p>Level for the credible intervals. For example, alpha = 0.05 results in
95% credible intervals.</p>
</td></tr>
<tr><td><code id="afths_+3A_xtest">Xtest</code></td>
<td>
<p>test design matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is:
<code class="reqn">t_i</code> is response,
<code class="reqn">c_i</code> is censored time,
<code class="reqn">t_i^* = \min_(t_i, c_i)</code> is observed time,
<code class="reqn">w_i</code> is censored data, so <code class="reqn">w_i = \log t_i^*</code> if <code class="reqn">t_i</code> is event time and
<code class="reqn">w_i = \log t_i^*</code> if <code class="reqn">t_i</code> is right censored
<code class="reqn">\log t_i=X\beta+\epsilon, \epsilon \sim N(0,\sigma^2)</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>SurvivalHat</code></td>
<td>
<p>Predictive survival probability</p>
</td></tr>
<tr><td><code>LogTimeHat</code></td>
<td>
<p>Predictive log time</p>
</td></tr>
<tr><td><code>BetaHat</code></td>
<td>
<p>Posterior mean of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LeftCI</code></td>
<td>
<p>The left bounds of the credible intervals</p>
</td></tr>
<tr><td><code>RightCI</code></td>
<td>
<p>The right bounds of the credible intervals</p>
</td></tr>
<tr><td><code>BetaMedian</code></td>
<td>
<p>Posterior median of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LambdaHat</code></td>
<td>
<p>Posterior samples of <code class="reqn">\lambda</code>, a <code class="reqn">p*1</code> vector</p>
</td></tr>
<tr><td><code>Sigma2Hat</code></td>
<td>
<p>Posterior mean of error variance <code class="reqn">\sigma^2</code>. If method.sigma =
&quot;fixed&quot; is used, this value will be equal to the user-selected value of Sigma2
passed to the function</p>
</td></tr>
<tr><td><code>TauHat</code></td>
<td>
<p>Posterior mean of global scale parameter tau, a positive scalar</p>
</td></tr>
<tr><td><code>BetaSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\beta</code></p>
</td></tr>
<tr><td><code>TauSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\tau</code></p>
</td></tr>
<tr><td><code>Sigma2Samples</code></td>
<td>
<p>Posterior samples of Sigma2</p>
</td></tr>
<tr><td><code>LikelihoodSamples</code></td>
<td>
<p>Posterior samples of likelihood</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>Devainace Information Criterion of the fitted model</p>
</td></tr>
<tr><td><code>WAIC</code></td>
<td>
<p>Widely Applicable Information Criterion</p>
</td></tr>
</table>


<h3>References</h3>

<p>Maity, A. K., Carroll, R. J., and Mallick, B. K. (2019) 
&quot;Integration of Survival and Binary Data for Variable Selection and Prediction: 
A Bayesian Approach&quot;, 
Journal of the Royal Statistical Society: Series C (Applied Statistics).
</p>
<p>Maity, A. K., Bhattacharya, A., Mallick, B. K., &amp; Baladandayuthapani, V. (2020). 
Bayesian data integration and variable selection for pan cancer survival prediction
using protein expression data. Biometrics, 76(1), 316-325.
</p>
<p>Stephanie van der Pas, James Scott, Antik Chakraborty and Anirban Bhattacharya (2016). horseshoe:
Implementation of the Horseshoe Prior. R package version 0.1.0.
https://CRAN.R-project.org/package=horseshoe
</p>
<p>Enes Makalic and Daniel Schmidt (2016). High-Dimensional Bayesian Regularised Regression with the
BayesReg Package arXiv:1611.06649
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
burnin &lt;- 500
nmc    &lt;- 1000
thin &lt;- 1
y.sd   &lt;- 1  # standard deviation of the response

p &lt;- 100  # number of predictors
ntrain &lt;- 100  # training size
ntest  &lt;- 50   # test size
n &lt;- ntest + ntrain  # sample size
q &lt;- 10   # number of true predictos

beta.t &lt;- c(sample(x = c(1, -1), size = q, replace = TRUE), rep(0, p - q)) 
x &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = diag(p))    

tmean &lt;- x %*% beta.t
y &lt;- rnorm(n, mean = tmean, sd = y.sd)
X &lt;- scale(as.matrix(x))  # standarization

T &lt;- exp(y)   # AFT model
C &lt;- rgamma(n, shape = 1.75, scale = 3)   # 42% censoring time
time &lt;- pmin(T, C)  # observed time is min of censored and true
status = time == T   # set to 1 if event is observed
ct &lt;- as.matrix(cbind(time = time, status = status))  # censored time


# Training set
cttrain &lt;- ct[1:ntrain, ]
Xtrain  &lt;- X[1:ntrain, ]

# Test set
cttest &lt;- ct[(ntrain + 1):n, ]
Xtest  &lt;- X[(ntrain + 1):n, ]

posterior.fit &lt;- afths(ct = cttrain, X = Xtrain, method.tau = "halfCauchy",
                             method.sigma = "Jeffreys", burn = burnin, nmc = nmc, thin = 1,
                             Xtest = Xtest)
                             
posterior.fit$BetaHat

# Posterior processing to recover the true predictors
cluster &lt;- kmeans(abs(posterior.fit$BetaHat), centers = 2)$cluster
cluster1 &lt;- which(cluster == 1)
cluster2 &lt;- which(cluster == 2)
min.cluster &lt;- ifelse(length(cluster1) &lt; length(cluster2), 1, 2)
which(cluster == min.cluster)  # this matches with the true variables


</code></pre>

<hr>
<h2 id='lmhs'>Horseshoe shrinkage prior in Bayesian linear regression</h2><span id='topic+lmhs'></span>

<h3>Description</h3>

<p>This function employs the algorithm provided by van der Pas et. al. (2016) for 
linear model to fit Bayesian regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmhs(
  y,
  X,
  method.tau = c("fixed", "truncatedCauchy", "halfCauchy"),
  tau = 1,
  method.sigma = c("fixed", "Jeffreys"),
  Sigma2 = 1,
  burn = 1000,
  nmc = 5000,
  thin = 1,
  alpha = 0.05,
  Xtest = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lmhs_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, dimension <code class="reqn">n*p</code>.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_method.tau">method.tau</code></td>
<td>
<p>Method for handling <code class="reqn">\tau</code>. Select &quot;truncatedCauchy&quot; for full
Bayes with the Cauchy prior truncated to [1/p, 1], &quot;halfCauchy&quot; for full Bayes with
the half-Cauchy prior, or &quot;fixed&quot; to use a fixed value (an empirical Bayes estimate,
for example).</p>
</td></tr>
<tr><td><code id="lmhs_+3A_tau">tau</code></td>
<td>
<p>Use this argument to pass the (estimated) value of <code class="reqn">\tau</code> in case &quot;fixed&quot;
is selected for method.tau. Not necessary when method.tau is equal to &quot;halfCauchy&quot; or
&quot;truncatedCauchy&quot;. The default (tau = 1) is not suitable for most purposes and should be replaced.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_method.sigma">method.sigma</code></td>
<td>
<p>Select &quot;Jeffreys&quot; for full Bayes with Jeffrey's prior on the error
variance <code class="reqn">\sigma^2</code>, or &quot;fixed&quot; to use a fixed value (an empirical Bayes
estimate, for example).</p>
</td></tr>
<tr><td><code id="lmhs_+3A_sigma2">Sigma2</code></td>
<td>
<p>A fixed value for the error variance <code class="reqn">\sigma^2</code>. Not necessary
when method.sigma is equal to &quot;Jeffreys&quot;. Use this argument to pass the (estimated)
value of Sigma2 in case &quot;fixed&quot; is selected for method.sigma. The default (Sigma2 = 1)
is not suitable for most purposes and should be replaced.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_burn">burn</code></td>
<td>
<p>Number of burn-in MCMC samples. Default is 1000.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_nmc">nmc</code></td>
<td>
<p>Number of posterior draws to be saved. Default is 5000.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_thin">thin</code></td>
<td>
<p>Thinning parameter of the chain. Default is 1 (no thinning).</p>
</td></tr>
<tr><td><code id="lmhs_+3A_alpha">alpha</code></td>
<td>
<p>Level for the credible intervals. For example, alpha = 0.05 results in
95% credible intervals.</p>
</td></tr>
<tr><td><code id="lmhs_+3A_xtest">Xtest</code></td>
<td>
<p>test design matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is:
<code class="reqn">y_i</code> is response,
<code class="reqn">y_i=X\beta+\epsilon, \epsilon \sim N(0,\sigma^2)</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>yHat</code></td>
<td>
<p>Predictive response</p>
</td></tr>
<tr><td><code>BetaHat</code></td>
<td>
<p>Posterior mean of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LeftCI</code></td>
<td>
<p>The left bounds of the credible intervals</p>
</td></tr>
<tr><td><code>RightCI</code></td>
<td>
<p>The right bounds of the credible intervals</p>
</td></tr>
<tr><td><code>BetaMedian</code></td>
<td>
<p>Posterior median of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LambdaHat</code></td>
<td>
<p>Posterior samples of <code class="reqn">\lambda</code>, a <code class="reqn">p*1</code> vector</p>
</td></tr>
<tr><td><code>Sigma2Hat</code></td>
<td>
<p>Posterior mean of error variance <code class="reqn">\sigma^2</code>. If method.sigma =
&quot;fixed&quot; is used, this value will be equal to the user-selected value of Sigma2
passed to the function</p>
</td></tr>
<tr><td><code>TauHat</code></td>
<td>
<p>Posterior mean of global scale parameter tau, a positive scalar</p>
</td></tr>
<tr><td><code>BetaSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\beta</code></p>
</td></tr>
<tr><td><code>TauSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\tau</code></p>
</td></tr>
<tr><td><code>Sigma2Samples</code></td>
<td>
<p>Posterior samples of Sigma2</p>
</td></tr>
<tr><td><code>LikelihoodSamples</code></td>
<td>
<p>Posterior samples of likelihood</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>Devainace Information Criterion of the fitted model</p>
</td></tr>
<tr><td><code>WAIC</code></td>
<td>
<p>Widely Applicable Information Criterion</p>
</td></tr>
</table>


<h3>References</h3>

<p>Maity, A. K., Carroll, R. J., and Mallick, B. K. (2019) 
&quot;Integration of Survival and Binary Data for Variable Selection and Prediction: 
A Bayesian Approach&quot;, 
Journal of the Royal Statistical Society: Series C (Applied Statistics).
</p>
<p>Maity, A. K., Bhattacharya, A., Mallick, B. K., &amp; Baladandayuthapani, V. (2020). 
Bayesian data integration and variable selection for pan cancer survival prediction
using protein expression data. Biometrics, 76(1), 316-325.
</p>
<p>Stephanie van der Pas, James Scott, Antik Chakraborty and Anirban Bhattacharya (2016). horseshoe:
Implementation of the Horseshoe Prior. R package version 0.1.0.
https://CRAN.R-project.org/package=horseshoe
</p>
<p>Enes Makalic and Daniel Schmidt (2016). High-Dimensional Bayesian Regularised Regression with the
BayesReg Package arXiv:1611.06649
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
burnin &lt;- 500
nmc    &lt;- 1000
thin &lt;- 1
y.sd   &lt;- 1  # standard deviation of the response

p &lt;- 100  # number of predictors
ntrain &lt;- 100  # training size
ntest  &lt;- 50   # test size
n &lt;- ntest + ntrain  # sample size
q &lt;- 10   # number of true predictos

beta.t &lt;- c(sample(x = c(1, -1), size = q, replace = TRUE), rep(0, p - q))  
x &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = diag(p))    

tmean &lt;- x %*% beta.t
y &lt;- rnorm(n, mean = tmean, sd = y.sd)
X &lt;- scale(as.matrix(x))  # standarization

# Training set
ytrain &lt;- y[1:ntrain]
Xtrain &lt;- X[1:ntrain, ]

# Test set
ytest &lt;- y[(ntrain + 1):n]
Xtest &lt;- X[(ntrain + 1):n, ]

posterior.fit &lt;- lmhs(y = ytrain, X = Xtrain, method.tau = "halfCauchy",
                       method.sigma = "Jeffreys", burn = burnin, nmc = nmc, thin = 1,
                       Xtest = Xtest)
                             
posterior.fit$BetaHat

# Posterior processing to recover the true predictors
cluster &lt;- kmeans(abs(posterior.fit$BetaHat), centers = 2)$cluster
cluster1 &lt;- which(cluster == 1)
cluster2 &lt;- which(cluster == 2)
min.cluster &lt;- ifelse(length(cluster1) &lt; length(cluster2), 1, 2)
which(cluster == min.cluster)  # this matches with the true variables


</code></pre>

<hr>
<h2 id='logiths'>Horseshoe shrinkage prior in Bayesian Logistic regression</h2><span id='topic+logiths'></span>

<h3>Description</h3>

<p>This function employs the algorithm provided by Makalic and Schmidt (2016) for 
binary logistic model to fit Bayesian logistic regression. The observations are updated 
according to the Polya-Gamma data augmentation of approach of Polson, Scott, and Windle (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logiths(
  z,
  X,
  method.tau = c("fixed", "truncatedCauchy", "halfCauchy"),
  tau = 1,
  burn = 1000,
  nmc = 5000,
  thin = 1,
  alpha = 0.05,
  Xtest = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logiths_+3A_z">z</code></td>
<td>
<p>Response, a <code class="reqn">n*1</code> vector of 1 or 0.</p>
</td></tr>
<tr><td><code id="logiths_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, dimension <code class="reqn">n*p</code>.</p>
</td></tr>
<tr><td><code id="logiths_+3A_method.tau">method.tau</code></td>
<td>
<p>Method for handling <code class="reqn">\tau</code>. Select &quot;truncatedCauchy&quot; for full
Bayes with the Cauchy prior truncated to [1/p, 1], &quot;halfCauchy&quot; for full Bayes with
the half-Cauchy prior, or &quot;fixed&quot; to use a fixed value (an empirical Bayes estimate,
for example).</p>
</td></tr>
<tr><td><code id="logiths_+3A_tau">tau</code></td>
<td>
<p>Use this argument to pass the (estimated) value of <code class="reqn">\tau</code> in case &quot;fixed&quot;
is selected for method.tau. Not necessary when method.tau is equal to &quot;halfCauchy&quot; or
&quot;truncatedCauchy&quot;. The default (tau = 1) is not suitable for most purposes and should be replaced.</p>
</td></tr>
<tr><td><code id="logiths_+3A_burn">burn</code></td>
<td>
<p>Number of burn-in MCMC samples. Default is 1000.</p>
</td></tr>
<tr><td><code id="logiths_+3A_nmc">nmc</code></td>
<td>
<p>Number of posterior draws to be saved. Default is 5000.</p>
</td></tr>
<tr><td><code id="logiths_+3A_thin">thin</code></td>
<td>
<p>Thinning parameter of the chain. Default is 1 (no thinning).</p>
</td></tr>
<tr><td><code id="logiths_+3A_alpha">alpha</code></td>
<td>
<p>Level for the credible intervals. For example, alpha = 0.05 results in
95% credible intervals.</p>
</td></tr>
<tr><td><code id="logiths_+3A_xtest">Xtest</code></td>
<td>
<p>test design matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is:
<code class="reqn">z_i</code> is response either 1 or 0,
<code class="reqn">\log \Pr(z_i = 1) = logit^{-1}(X\beta)</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>ProbHat</code></td>
<td>
<p>Predictive probability</p>
</td></tr>
<tr><td><code>BetaHat</code></td>
<td>
<p>Posterior mean of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LeftCI</code></td>
<td>
<p>The left bounds of the credible intervals</p>
</td></tr>
<tr><td><code>RightCI</code></td>
<td>
<p>The right bounds of the credible intervals</p>
</td></tr>
<tr><td><code>BetaMedian</code></td>
<td>
<p>Posterior median of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LambdaHat</code></td>
<td>
<p>Posterior samples of <code class="reqn">\lambda</code>, a <code class="reqn">p*1</code> vector</p>
</td></tr>
<tr><td><code>TauHat</code></td>
<td>
<p>Posterior mean of global scale parameter tau, a positive scalar</p>
</td></tr>
<tr><td><code>BetaSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\beta</code></p>
</td></tr>
<tr><td><code>TauSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\tau</code></p>
</td></tr>
<tr><td><code>LikelihoodSamples</code></td>
<td>
<p>Posterior samples of likelihood</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>Devainace Information Criterion of the fitted model</p>
</td></tr>
<tr><td><code>WAIC</code></td>
<td>
<p>Widely Applicable Information Criterion</p>
</td></tr>
</table>


<h3>References</h3>

<p>Stephanie van der Pas, James Scott, Antik Chakraborty and Anirban Bhattacharya (2016). horseshoe:
Implementation of the Horseshoe Prior. R package version 0.1.0.
https://CRAN.R-project.org/package=horseshoe
</p>
<p>Enes Makalic and Daniel Schmidt (2016). High-Dimensional Bayesian Regularised Regression with the
BayesReg Package arXiv:1611.06649
</p>
<p>Polson, N.G., Scott, J.G. and Windle, J. (2014) The Bayesian Bridge.
Journal of Royal Statistical Society, B, 76(4), 713-733.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
burnin &lt;- 100
nmc    &lt;- 500
thin &lt;- 1

 
p &lt;- 100  # number of predictors
ntrain &lt;- 250  # training size
ntest  &lt;- 100   # test size
n &lt;- ntest + ntrain  # sample size
q &lt;- 10   # number of true predictos

beta.t &lt;- c(sample(x = c(1, -1), size = q, replace = TRUE), rep(0, p - q))  
x &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = diag(p))    

zmean &lt;- x %*% beta.t
z &lt;- rbinom(n, size = 1, prob = boot::inv.logit(zmean))
X &lt;- scale(as.matrix(x))  # standarization


# Training set
ztrain &lt;- z[1:ntrain]
Xtrain  &lt;- X[1:ntrain, ]

# Test set
ztest &lt;- z[(ntrain + 1):n]
Xtest  &lt;- X[(ntrain + 1):n, ]

posterior.fit &lt;- logiths(z = ztrain, X = Xtrain, method.tau = "halfCauchy",
                         burn = burnin, nmc = nmc, thin = 1,
                         Xtest = Xtest)
                             
posterior.fit$BetaHat


# Posterior processing to recover the true predictors
cluster &lt;- kmeans(abs(posterior.fit$BetaHat), centers = 2)$cluster
cluster1 &lt;- which(cluster == 1)
cluster2 &lt;- which(cluster == 2)
min.cluster &lt;- ifelse(length(cluster1) &lt; length(cluster2), 1, 2)
which(cluster == min.cluster)  # this matches with the true variables



</code></pre>

<hr>
<h2 id='probiths'>Horseshoe shrinkage prior in Bayesian Probit regression</h2><span id='topic+probiths'></span>

<h3>Description</h3>

<p>This function employs the algorithm provided by Makalic and Schmidt (2016) for 
binary probit model to fit Bayesian probit regression. The observations are updated 
according to the data augmentation of approach of Albert and Chib (1993).
</p>
<p>The model is:
<code class="reqn">z_i</code> is response either 1 or 0,
<code class="reqn">\log \Pr(z_i = 1) = \Phi(X\beta), \Phi \sim N(0,\sigma^2)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probiths(
  z,
  X,
  method.tau = c("fixed", "truncatedCauchy", "halfCauchy"),
  tau = 1,
  burn = 1000,
  nmc = 5000,
  thin = 1,
  alpha = 0.05,
  Xtest = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probiths_+3A_z">z</code></td>
<td>
<p>Response, a <code class="reqn">n*1</code> vector of 1 or 0.</p>
</td></tr>
<tr><td><code id="probiths_+3A_x">X</code></td>
<td>
<p>Matrix of covariates, dimension <code class="reqn">n*p</code>.</p>
</td></tr>
<tr><td><code id="probiths_+3A_method.tau">method.tau</code></td>
<td>
<p>Method for handling <code class="reqn">\tau</code>. Select &quot;truncatedCauchy&quot; for full
Bayes with the Cauchy prior truncated to [1/p, 1], &quot;halfCauchy&quot; for full Bayes with
the half-Cauchy prior, or &quot;fixed&quot; to use a fixed value (an empirical Bayes estimate,
for example).</p>
</td></tr>
<tr><td><code id="probiths_+3A_tau">tau</code></td>
<td>
<p>Use this argument to pass the (estimated) value of <code class="reqn">\tau</code> in case &quot;fixed&quot;
is selected for method.tau. Not necessary when method.tau is equal to&quot;halfCauchy&quot; or
&quot;truncatedCauchy&quot;. The default (tau = 1) is not suitable for most purposes and should be replaced.</p>
</td></tr>
<tr><td><code id="probiths_+3A_burn">burn</code></td>
<td>
<p>Number of burn-in MCMC samples. Default is 1000.</p>
</td></tr>
<tr><td><code id="probiths_+3A_nmc">nmc</code></td>
<td>
<p>Number of posterior draws to be saved. Default is 5000.</p>
</td></tr>
<tr><td><code id="probiths_+3A_thin">thin</code></td>
<td>
<p>Thinning parameter of the chain. Default is 1 (no thinning).</p>
</td></tr>
<tr><td><code id="probiths_+3A_alpha">alpha</code></td>
<td>
<p>Level for the credible intervals. For example, alpha = 0.05 results in
95% credible intervals.</p>
</td></tr>
<tr><td><code id="probiths_+3A_xtest">Xtest</code></td>
<td>
<p>test design matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>ProbHat</code></td>
<td>
<p>Predictive probability</p>
</td></tr>
<tr><td><code>BetaHat</code></td>
<td>
<p>Posterior mean of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LeftCI</code></td>
<td>
<p>The left bounds of the credible intervals</p>
</td></tr>
<tr><td><code>RightCI</code></td>
<td>
<p>The right bounds of the credible intervals</p>
</td></tr>
<tr><td><code>BetaMedian</code></td>
<td>
<p>Posterior median of Beta, a <code class="reqn">p</code> by 1 vector</p>
</td></tr>
<tr><td><code>LambdaHat</code></td>
<td>
<p>Posterior samples of <code class="reqn">\lambda</code>, a <code class="reqn">p*1</code> vector</p>
</td></tr>
<tr><td><code>TauHat</code></td>
<td>
<p>Posterior mean of global scale parameter tau, a positive scalar</p>
</td></tr>
<tr><td><code>BetaSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\beta</code></p>
</td></tr>
<tr><td><code>TauSamples</code></td>
<td>
<p>Posterior samples of <code class="reqn">\tau</code></p>
</td></tr>
<tr><td><code>LikelihoodSamples</code></td>
<td>
<p>Posterior samples of likelihood</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>Devainace Information Criterion of the fitted model</p>
</td></tr>
<tr><td><code>WAIC</code></td>
<td>
<p>Widely Applicable Information Criterion</p>
</td></tr>
</table>


<h3>References</h3>

<p>Stephanie van der Pas, James Scott, Antik Chakraborty and Anirban Bhattacharya (2016). horseshoe:
Implementation of the Horseshoe Prior. R package version 0.1.0.
https://CRAN.R-project.org/package=horseshoe
</p>
<p>Enes Makalic and Daniel Schmidt (2016). High-Dimensional Bayesian Regularised Regression with the
BayesReg Package arXiv:1611.06649
</p>
<p>Albert, J. H., &amp; Chib, S. (1993). Bayesian analysis of binary and polychotomous response data. 
Journal of the American statistical Association, 88(422), 669-679.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
burnin &lt;- 100
nmc    &lt;- 200
thin   &lt;- 1
y.sd   &lt;- 1  # statndard deviation of the response

p &lt;- 200  # number of predictors
ntrain &lt;- 250  # training size
ntest  &lt;- 100   # test size
n &lt;- ntest + ntrain  # sample size
q &lt;- 10   # number of true predictos

beta.t &lt;- c(sample(x = c(1, -1), size = q, replace = TRUE), rep(0, p - q))  
x &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p))    
zmean &lt;- x %*% beta.t

y &lt;- rnorm(n, mean = zmean, sd = y.sd)
z &lt;- ifelse(y &gt; 0, 1, 0)
X &lt;- scale(as.matrix(x))  # standarization
z &lt;- as.numeric(as.matrix(c(z)))

# Training set
ztrain &lt;- z[1:ntrain]
Xtrain  &lt;- X[1:ntrain, ]

# Test set
ztest &lt;- z[(ntrain + 1):n]
Xtest &lt;- X[(ntrain + 1):n, ]
 
posterior.fit &lt;- probiths(z = ztrain, X = Xtrain, method.tau = "halfCauchy",
                          burn = burnin, nmc = nmc, thin = 1,
                          Xtest = Xtest)

posterior.fit$BetaHat

# Posterior processing to recover the significant predictors
cluster     &lt;- kmeans(abs(posterior.fit$BetaHat), centers = 2)$cluster  # return cluster indices
cluster1    &lt;- which(cluster == 1)
cluster2    &lt;- which(cluster == 2)
min.cluster &lt;- ifelse(length(cluster1) &lt; length(cluster2), 1, 2)
which(cluster == min.cluster)  # this matches with the true variables


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
