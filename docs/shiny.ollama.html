<!DOCTYPE html><html lang="en"><head><title>Help for package shiny.ollama</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {shiny.ollama}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#create_chat_server'><p>Create the Shiny server function for the chat interface</p></a></li>
<li><a href='#create_chat_ui'><p>Create the Shiny UI for the chat interface</p></a></li>
<li><a href='#fetch_models'><p>Fetch available models from Ollama API</p></a></li>
<li><a href='#format_chat_history'><p>Convert chat history to downloadable format</p></a></li>
<li><a href='#format_message_md'><p>Format a message as markdown</p></a></li>
<li><a href='#parse_message'><p>Parse a markdown-formatted message</p></a></li>
<li><a href='#run_app'><p>Run shiny Application for Chat Interface</p></a></li>
<li><a href='#send_ollama_message'><p>Send message to Ollama API and get response</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Title:</td>
<td>R 'shiny' Interface for Chatting with Large Language Models
Offline on Local with 'ollama'</td>
</tr>
<tr>
<td>Description:</td>
<td>Chat with large language models on your machine without internet with complete privacy via 'ollama', powered by R 'shiny' interface. For more information on 'ollama', visit <a href="https://ollama.com">https://ollama.com</a>.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Indraneel Chakraborty &lt;hello.indraneel@gmail.com&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License (&ge; 2)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.indraneelchakraborty.com/shiny.ollama/">https://www.indraneelchakraborty.com/shiny.ollama/</a>,
<a href="https://github.com/ineelhere/shiny.ollama">https://github.com/ineelhere/shiny.ollama</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ineelhere/shiny.ollama/issues">https://github.com/ineelhere/shiny.ollama/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>shiny (&ge; 1.7.0), bslib (&ge; 0.4.0), httr (&ge; 1.4.0), jsonlite
(&ge; 1.8.0), markdown, mockery</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), pkgdown (&ge; 2.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-12</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-27 04:59:21 UTC; neel0</td>
</tr>
<tr>
<td>Author:</td>
<td>Indraneel Chakraborty
    <a href="https://orcid.org/0000-0001-6958-8269"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-27 05:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='create_chat_server'>Create the Shiny server function for the chat interface</h2><span id='topic+create_chat_server'></span>

<h3>Description</h3>

<p>Create the Shiny server function for the chat interface
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_chat_server()
</code></pre>


<h3>Value</h3>

<p>A Shiny server function
</p>

<hr>
<h2 id='create_chat_ui'>Create the Shiny UI for the chat interface</h2><span id='topic+create_chat_ui'></span>

<h3>Description</h3>

<p>Create the Shiny UI for the chat interface
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_chat_ui()
</code></pre>


<h3>Value</h3>

<p>A Shiny UI object
</p>

<hr>
<h2 id='fetch_models'>Fetch available models from Ollama API</h2><span id='topic+fetch_models'></span>

<h3>Description</h3>

<p>Fetch available models from Ollama API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fetch_models()
</code></pre>


<h3>Value</h3>

<p>Character vector of model names or an error message
</p>

<hr>
<h2 id='format_chat_history'>Convert chat history to downloadable format</h2><span id='topic+format_chat_history'></span>

<h3>Description</h3>

<p>Convert chat history to downloadable format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_chat_history(messages, format = c("HTML", "CSV"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="format_chat_history_+3A_messages">messages</code></td>
<td>
<p>List of chat messages</p>
</td></tr>
<tr><td><code id="format_chat_history_+3A_format">format</code></td>
<td>
<p>Character string specifying format (&quot;HTML&quot; or &quot;CSV&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Formatted chat history as a character string (HTML) or a data frame (CSV)
</p>

<hr>
<h2 id='format_message_md'>Format a message as markdown</h2><span id='topic+format_message_md'></span>

<h3>Description</h3>

<p>This helper function formats a message with a specified role 
(User, Assistant, or System) into a markdown-styled string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_message_md(role, content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="format_message_md_+3A_role">role</code></td>
<td>
<p>A character string specifying the role (e.g., &quot;User&quot;, &quot;Assistant&quot;, &quot;System&quot;).</p>
</td></tr>
<tr><td><code id="format_message_md_+3A_content">content</code></td>
<td>
<p>A character string containing the message content.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string formatted as markdown.
</p>

<hr>
<h2 id='parse_message'>Parse a markdown-formatted message</h2><span id='topic+parse_message'></span>

<h3>Description</h3>

<p>This function extracts the role and content from a markdown-formatted message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_message(message)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parse_message_+3A_message">message</code></td>
<td>
<p>A character string containing the markdown-formatted message.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two elements:
</p>
<table role = "presentation">
<tr><td><code>role</code></td>
<td>
<p>A character string representing the role (e.g., &quot;User&quot;, &quot;Assistant&quot;, &quot;System&quot;).</p>
</td></tr>
<tr><td><code>content</code></td>
<td>
<p>A character string containing the extracted message content.</p>
</td></tr>
</table>

<hr>
<h2 id='run_app'>Run shiny Application for Chat Interface</h2><span id='topic+run_app'></span>

<h3>Description</h3>

<p>Launches a shiny app for interacting with the Ollama API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_app()
</code></pre>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='send_ollama_message'>Send message to Ollama API and get response</h2><span id='topic+send_ollama_message'></span>

<h3>Description</h3>

<p>Send message to Ollama API and get response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>send_ollama_message(message, model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="send_ollama_message_+3A_message">message</code></td>
<td>
<p>Character string containing the user message</p>
</td></tr>
<tr><td><code id="send_ollama_message_+3A_model">model</code></td>
<td>
<p>Character string specifying the model name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with elements 'success' (logical) and either 'response' (character) or 'error' (character)
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
