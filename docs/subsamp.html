<!DOCTYPE html><html><head><title>Help for package subsamp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {subsamp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#subsamp'><p>Subsample Winner Algorithm for Variable Selection in Linear Regression with a Large Number of Variables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Subsample Winner Algorithm for Variable Selection in Linear
Regression with a Large Number of Variables</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yiying Fan &lt;y.fan67@csuohio.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This subsample winner algorithm (SWA) for regression with a large-p data (X, Y) selects the important variables (or features) among the p features X in explaining the response Y.  The SWA first uses a base procedure,  here a linear regression, on each of subsamples randomly drawn from the p variables, and then computes the scores of all features, i.e., the p variables,  according to the performance of these features collected in each of the subsample analyses. It then obtains the 'semifinalist' of the features based on the resulting scores and determines the 'finalists', i.e., the important features, from the 'semifinalist'.  Fan, Sun and Qiao (2017) <a href="http://sr2c.case.edu/swa-reg/">http://sr2c.case.edu/swa-reg/</a>.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-11-14 17:29:43 UTC; 2566444</td>
</tr>
<tr>
<td>Author:</td>
<td>Yiying Fan [aut, cre],
  Jiayang Sun [aut],
  Xingye Qiao [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-11-14 18:52:55 UTC</td>
</tr>
</table>
<hr>
<h2 id='subsamp'>Subsample Winner Algorithm for Variable Selection in Linear Regression with a Large Number of Variables</h2><span id='topic+subsamp'></span>

<h3>Description</h3>

<p>This subsample winner algorithm (SWA) for regression with a large-p data (X, Y) selects the important variables (or features) among the p features X in explaining the response Y.  The SWA first uses a base procedure, here a linear regression, on each of subsamples randomly drawn from the p variables, and then computes the scores of all features, i.e., the p variables, according to the performance of these features collected in each of the subsample analyses. It then obtains the 'semifinalist' of the features based on the resulting scores and determines the 'finalists', i.e., the important features, from the 'semifinalist'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsamp(x, y, s, m = 1000, qnum, wplot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsamp_+3A_x+3A">x:</code></td>
<td>
<p>The n by p design matrix where n is the sample size and p is the demension.</p>
</td></tr>
<tr><td><code id="subsamp_+3A_y+3A">y:</code></td>
<td>
<p>The vector with length n.</p>
</td></tr>
<tr><td><code id="subsamp_+3A_s+3A">s:</code></td>
<td>
<p>The subsample size which must be greater than or equal to 2.</p>
</td></tr>
<tr><td><code id="subsamp_+3A_m+3A">m:</code></td>
<td>
<p>The number of subsample repetition. The default value is 1000.</p>
</td></tr>
<tr><td><code id="subsamp_+3A_qnum+3A">qnum:</code></td>
<td>
<p>The number of semi-finalists. It should be at least as big as s.</p>
</td></tr>
<tr><td><code id="subsamp_+3A_wplot+3A">wplot:</code></td>
<td>
<p>Boolean input showing whether the multi-panel weights plot is drawn to guide a selection of s, the subsample size. The default value is F (False), without the plot. If it is plotted, a user should look at the points above the elbow points in all panels, i.e. upper arm sets, where the current value of s is in the red color. Find the smallest s0 such that the upper arm sets, corresponding to next few s &gt;= s0,  are similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output a list of the finalists, i.e. the important features with their p-values, estimated coefficients and other corresponding statistics.
</p>


<h3>Author(s)</h3>

<p>Yiying Fan, Xingye Qiao, and Jiayang Sun
</p>


<h3>References</h3>

<p>http:sr2c.case.edu/swa-reg/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 80; p &lt;- 100
set.seed(2017)
x &lt;- matrix(rnorm(n*p),n);
coefs &lt;- c(.1, .5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 5)
y &lt;- x[, 1:length(coefs)]%*%coefs + rnorm(n)
d &lt;- data.frame(y,x)

## The number of true features in d is 10. The first 3 features,
## X1-X3, are not distinguishable from noises, while the next two
## X4 and X5 have a weak signal, X6 has a moderate signal,
## and X7-X10 have a strong signal in comparison with the noises
## in the data. A good feature selection procedure should capture
## X7-X10, at least. The ideal s here should be 10 or slightly
## bigger.

## Using the default values for m, wplot and a smaller value of s
## than desired:
subsamp(x, y, s=8, qnum=10)  #1st run
## This run captured X7-X10 and X5, with an adjusted
## R^2=0.9015.

## Next try a bigger s and include a diagnostic plot:
#  subsamp(x, y, s=10, qnum=10, wplot=TRUE) #2nd run
## It captured X5-X10, as expected from the truth.
## It is also good enough by looking at either the
## adjusted R^2, 0.955.  The diagnostic weights plot indicated that
## s=10 is a good choice.

## However, if a conservative user decided to try for an even
## bigger m and q:
#  subsamp(x, y, s=10, qnum=12, m=1200, wplot=TRUE) #3rd run
## It now definitely suggests selecting s=10, but this run only
## captured X5,X6,X8,X9,X10 without X7, and added a spurious X62,
## with a **smaller** adjusted R2 = 0.8827. Thus a user should
## now stop and conclude with using the outcome from the 2nd run.

## Regardless, if the user kept increasing both s&amp; m, we would have
#  subsamp(x, y, s=12, qnum=12, m=1500, wplot=TRUE)  #run4
## Its outcome is same as that from run2.

## Double Assurance Procedure: This is to further assure
## the outcome, by  applying the base procedure to
## the combined features from reasonable SWA runs. Combining run1
## and run2, with and without run3, lead to the same important
## features as those from the run2:
##
#  g &lt;- lm(formula = y ~ X8 + X10 + X9 + X6 + X5 + X95 + X61 +X20+X7+X17+X73+X82+X47,d)
#  summary(g)
#  step(g)

## We did not include the outcome from run4 into the double
## assurance procedure as its outputs is same as that of run2.
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
