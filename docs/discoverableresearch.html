<!DOCTYPE html><html><head><title>Help for package discoverableresearch</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {discoverableresearch}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#check_fields'><p>Check all field suitability</p></a></li>
<li><a href='#check_keywords'><p>Check keyword suitability</p></a></li>
<li><a href='#check_title'><p>Check title with those from a test set</p></a></li>
<li><a href='#check_title_length'><p>Check title suitability</p></a></li>
<li><a href='#fakerake'><p>Functions from litsearchr (not yet on CRAN)</p>
Quick keyword extraction</a></li>
<li><a href='#format_keywords'><p>Format input keywords</p></a></li>
<li><a href='#get_ngrams'><p>Extract n-grams from text</p></a></li>
<li><a href='#get_stopwords'><p>Retrieve stop words for a given language</p></a></li>
<li><a href='#get_tokens'><p>Remove stopwords from text</p></a></li>
<li><a href='#language_code'><p>Get short language codes</p></a></li>
<li><a href='#possible_langs'><p>Languages codes synthesisr can recognize</p></a></li>
<li><a href='#remove_punctuation'><p>Remove punctuation from text</p></a></li>
<li><a href='#suggest_keywords'><p>Suggest keywords</p></a></li>
<li><a href='#suggest_title'><p>Suggest title words</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Checks Title, Abstract and Keywords to Optimise Discoverability</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>A suite of tools are provided here to support authors in making their research more discoverable. 
    check_keywords() - this function checks the keywords to assess whether they are already represented in the 
    title and abstract. check_fields() - this function compares terminology used across the title, abstract 
    and keywords to assess where terminological diversity (i.e. the use of synonyms) could increase the likelihood 
    of the record being identified in a search. The function looks for terms in the title and abstract that also 
    exist in other fields and highlights these as needing attention. suggest_keywords() - this function takes a 
    full text document and produces a list of unigrams, bigrams and trigrams (1-, 2- or 2-word phrases) 
    present in the full text after removing stop words (words with a low utility in natural language processing) 
    that do not occur in the title or abstract that may be suitable candidates for keywords. suggest_title() - 
    this function takes a full text document and produces a list of the most frequently used unigrams, bigrams 
    and trigrams after removing stop words that do not occur in the abstract or keywords that may be suitable 
    candidates for title words. check_title() - this function carries out a number of sub tasks:  1) it compares 
    the length (number of words) of the title with the mean length of titles in major bibliographic databases to 
    assess whether the title is likely to be too short; 2) it assesses the proportion of stop words in the title 
    to highlight titles with low utility in search engines that strip out stop words; 3) it compares the title 
    with a given sample of record titles from an .ris import and calculates a similarity score based on phrase 
    overlap. This highlights the level of uniqueness of the title. This version of the package also contains 
    functions currently in a non-CRAN package called 'litsearchr' <a href="https://github.com/elizagrames/litsearchr">https://github.com/elizagrames/litsearchr</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, graphics, magrittr, ngram, readr, stats, stringdist,
stringi, stopwords, synthesisr, tm</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-05 06:04:53 UTC; nealhaddaway</td>
</tr>
<tr>
<td>Author:</td>
<td>Neal Haddaway <a href="https://orcid.org/0000-0003-3902-2234"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Neal Haddaway &lt;nealhaddaway@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-10 10:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='check_fields'>Check all field suitability</h2><span id='topic+check_fields'></span>

<h3>Description</h3>

<p>Check given fields (title, abstract and keywords) for an article to assess discoverability based
on similarities across the fields
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_fields(title, abstract, keywords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_fields_+3A_title">title</code></td>
<td>
<p>The article title: a short string</p>
</td></tr>
<tr><td><code id="check_fields_+3A_abstract">abstract</code></td>
<td>
<p>The article abstract: a string</p>
</td></tr>
<tr><td><code id="check_fields_+3A_keywords">keywords</code></td>
<td>
<p>The article keywords: a vector of strings</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe displaying the presence of the terms across the title, abstract, and keywords
</p>


<h3>Examples</h3>

<pre><code class='language-R'>title &lt;- "A methodology for systematic mapping in environmental sciences"
abstract &lt;- "Systematic mapping was developed in social sciences in response to a lack of empirical 
  data when answering questions using systematic review methods, and a need for a method to describe 
  the literature across a broad subject of interest. Systematic mapping does not attempt to answer 
  a specific question as do systematic reviews, but instead collates, describes and catalogues 
  available evidence (e.g. primary, secondary, theoretical, economic) relating to a topic or 
  question of interest. The included studies can be used to identify evidence for policy-relevant 
  questions, knowledge gaps (to help direct future primary research) and knowledge clusters (sub-
  sets of evidence that may be suitable for secondary research, for example systematic review). 
  Evidence synthesis in environmental sciences faces similar challenges to those found in social 
  sciences. Here we describe the translation of systematic mapping methodology from social sciences 
  for use in environmental sciences. We provide the first process-based methodology for systematic 
  maps, describing the stages involved: establishing the review team and engaging stakeholders; 
  setting the scope and question; setting inclusion criteria for studies; scoping stage; protocol 
  development and publication; searching for evidence; screening evidence; coding; production of a 
  systematic map database; critical appraisal (optional); describing and visualising the findings; 
  report production and supporting information. We discuss the similarities and differences in 
  methodology between systematic review and systematic mapping and provide guidance for those 
  choosing which type of synthesis is most suitable for their requirements. Furthermore, we discuss 
  the merits and uses of systematic mapping and make recommendations for improving this evolving 
  methodology in environmental sciences."
keywords &lt;- c("Systematic mapping", 
  "Evidence-based environmental management", 
  "Systematic evidence synthesis", 
  "Evidence review", 
  "Knowledge gaps", 
  "Knowledge clusters")
check &lt;- check_fields(title, abstract, keywords)
check$df
check$tit_terms
check$abs_terms
check$key_terms
check$report;
</code></pre>

<hr>
<h2 id='check_keywords'>Check keyword suitability</h2><span id='topic+check_keywords'></span>

<h3>Description</h3>

<p>Check given keywords for an article to assess whether they are already represented in the title and
abstract
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_keywords(title, abstract, keywords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_keywords_+3A_title">title</code></td>
<td>
<p>The article title: a short string</p>
</td></tr>
<tr><td><code id="check_keywords_+3A_abstract">abstract</code></td>
<td>
<p>The article abstract: a string</p>
</td></tr>
<tr><td><code id="check_keywords_+3A_keywords">keywords</code></td>
<td>
<p>The article keywords: a vector of strings</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe displaying the presence of the keywords in the title and abstract
</p>


<h3>Examples</h3>

<pre><code class='language-R'>title &lt;- "A methodology for systematic mapping in environmental sciences"
abstract &lt;- "Systematic mapping was developed in social sciences in response to a lack of empirical 
  data when answering questions using systematic review methods, and a need for a method to describe 
  the literature across a broad subject of interest. Systematic mapping does not attempt to answer 
  a specific question as do systematic reviews, but instead collates, describes and catalogues 
  available evidence (e.g. primary, secondary, theoretical, economic) relating to a topic or 
  question of interest. The included studies can be used to identify evidence for policy-relevant 
  questions, knowledge gaps (to help direct future primary research) and knowledge clusters (sub-
  sets of evidence that may be suitable for secondary research, for example systematic review). 
  Evidence synthesis in environmental sciences faces similar challenges to those found in social 
  sciences. Here we describe the translation of systematic mapping methodology from social sciences 
  for use in environmental sciences. We provide the first process-based methodology for systematic 
  maps, describing the stages involved: establishing the review team and engaging stakeholders; 
  setting the scope and question; setting inclusion criteria for studies; scoping stage; protocol 
  development and publication; searching for evidence; screening evidence; coding; production of a 
  systematic map database; critical appraisal (optional); describing and visualising the findings; 
  report production and supporting information. We discuss the similarities and differences in 
  methodology between systematic review and systematic mapping and provide guidance for those 
  choosing which type of synthesis is most suitable for their requirements. Furthermore, we discuss 
  the merits and uses of systematic mapping and make recommendations for improving this evolving 
  methodology in environmental sciences."
keywords &lt;- c("Systematic mapping", 
  "Evidence-based environmental management", 
  "Systematic evidence synthesis", 
  "Evidence review", 
  "Knowledge gaps", 
  "Knowledge clusters")
check &lt;- check_keywords(title, abstract, keywords)
check;
</code></pre>

<hr>
<h2 id='check_title'>Check title with those from a test set</h2><span id='topic+check_title'></span>

<h3>Description</h3>

<p>Check given title for an article to assess how discoverable it is
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_title(title, testset, threshold = 0.6, matches = FALSE, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_title_+3A_title">title</code></td>
<td>
<p>The article title: a short string</p>
</td></tr>
<tr><td><code id="check_title_+3A_testset">testset</code></td>
<td>
<p>A provided sample set of representative titles to compare with, entered as a .bib
or .ris file (or using the RIS .txt file in data as specified in the example below)</p>
</td></tr>
<tr><td><code id="check_title_+3A_threshold">threshold</code></td>
<td>
<p>A threshold between 0 and 1 for the similarity score of titles in the sample
set relative to the title provided, above which matching titles will be printed out in 'matches'.
Default threshold set to 0.6 (arbitrarily)</p>
</td></tr>
<tr><td><code id="check_title_+3A_matches">matches</code></td>
<td>
<p>Logical argument TRUE or FALSE. If TRUE, the matches with a similarity score above
the threshold are printed to a data frame ('matches'). If FALSE, no output is provided.</p>
</td></tr>
<tr><td><code id="check_title_+3A_plot">plot</code></td>
<td>
<p>Logical argument TRUE or FALSE. If TRUE, a histogram of the similarity scores of test
set titles compared to the title is plotted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A report describing the suitability of the title for research discovery based on a
comparison with the test set. If 'matches = TRUE', a list containing a report describing the
suitability of the title for research discovery based on a comparison with the test set and a
database containing matches with a similarity score above the threshold value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>title &lt;- "A methodology for systematic mapping in environmental sciences"
testset &lt;- system.file("extdata", "sample_titles.txt", package="discoverableresearch")
check &lt;- check_title(title, testset = testset, threshold = 0.7, matches = TRUE, plot = TRUE)
check$output
check$dat;
</code></pre>

<hr>
<h2 id='check_title_length'>Check title suitability</h2><span id='topic+check_title_length'></span>

<h3>Description</h3>

<p>Check given title for an article to assess how discoverable it is based on its length and proportion of words that are non-stop words
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_title_length(title)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_title_length_+3A_title">title</code></td>
<td>
<p>The article title: a short string</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An output describing the suitability of the title for research discovery based on its length and the number of non-stop words
</p>


<h3>Examples</h3>

<pre><code class='language-R'>title &lt;- "A methodology for systematic mapping in environmental sciences"
check &lt;- check_title_length(title)
check;
</code></pre>

<hr>
<h2 id='fakerake'>Functions from litsearchr (not yet on CRAN)
Quick keyword extraction</h2><span id='topic+fakerake'></span>

<h3>Description</h3>

<p>Extracts potential keywords from text separated by stop words
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fakerake(text, stopwords, min_n = 2, max_n = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fakerake_+3A_text">text</code></td>
<td>
<p>A string object to extract terms from</p>
</td></tr>
<tr><td><code id="fakerake_+3A_stopwords">stopwords</code></td>
<td>
<p>A character vector of stop words to remove</p>
</td></tr>
<tr><td><code id="fakerake_+3A_min_n">min_n</code></td>
<td>
<p>Numeric: the minimum length ngram to consider</p>
</td></tr>
<tr><td><code id="fakerake_+3A_max_n">max_n</code></td>
<td>
<p>Numeric: the maximum length ngram to consider</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of potential keywords
</p>

<hr>
<h2 id='format_keywords'>Format input keywords</h2><span id='topic+format_keywords'></span>

<h3>Description</h3>

<p>Convert string of keywords with separator into a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_keywords(keywords, sep = ";")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_keywords_+3A_keywords">keywords</code></td>
<td>
<p>The article keywords: a vector of strings</p>
</td></tr>
<tr><td><code id="format_keywords_+3A_sep">sep</code></td>
<td>
<p>Character that separates keywords in a single string</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of lowercase keywords
</p>


<h3>Examples</h3>

<pre><code class='language-R'>keywords &lt;- c("Systematic mapping; 
  Evidence-based environmental management; 
  Systematic evidence synthesis; 
  Evidence review; 
  Knowledge gaps; 
  Knowledge clusters")
newkeywords &lt;- format_keywords(keywords, sep = ";")
newkeywords;
</code></pre>

<hr>
<h2 id='get_ngrams'>Extract n-grams from text</h2><span id='topic+get_ngrams'></span>

<h3>Description</h3>

<p>This function extracts n-grams from text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ngrams(
  x,
  n = 2,
  min_freq = 1,
  ngram_quantile = NULL,
  stop_words,
  rm_punctuation = FALSE,
  preserve_chars = c("-", "_"),
  language = "English"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ngrams_+3A_x">x</code></td>
<td>
<p>A character vector from which to extract n-grams.</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_n">n</code></td>
<td>
<p>Numeric: the minimum number of terms in an n-gram.</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_min_freq">min_freq</code></td>
<td>
<p>Numeric: the minimum number of times an n-gram must occur to be returned.</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_ngram_quantile">ngram_quantile</code></td>
<td>
<p>Numeric: what quantile of ngrams should be retained. Defaults to 0.8; i.e. the 80th percentile of ngram frequencies.</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_stop_words">stop_words</code></td>
<td>
<p>A character vector of stopwords to ignore.</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_rm_punctuation">rm_punctuation</code></td>
<td>
<p>Logical: should punctuation be removed before selecting ngrams?</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_preserve_chars">preserve_chars</code></td>
<td>
<p>A character vector of punctuation marks to be retained if rm_punctuation is TRUE.</p>
</td></tr>
<tr><td><code id="get_ngrams_+3A_language">language</code></td>
<td>
<p>A string indicating the language to use for removing stopwords.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of n-grams.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_ngrams("On the Origin of Species By Means of Natural Selection")
</code></pre>

<hr>
<h2 id='get_stopwords'>Retrieve stop words for a given language</h2><span id='topic+get_stopwords'></span>

<h3>Description</h3>

<p>This function retrieves stop words to use for a specified language.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_stopwords(language = "English")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_stopwords_+3A_language">language</code></td>
<td>
<p>A character vector containing the name of the language for which to retrieve stop words. Defaults to &quot;English&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector of stop words.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_stopwords("English")
</code></pre>

<hr>
<h2 id='get_tokens'>Remove stopwords from text</h2><span id='topic+get_tokens'></span>

<h3>Description</h3>

<p>Removes stopwords from text in whichever language is specified.
</p>
<p>Removes stop words from a text string (adapted from 'litsearchr' <a href="https://github.com/elizagrames/litsearchr/">https://github.com/elizagrames/litsearchr/</a>)
and returns the remaining words as a vector of strings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tokens(text, language = "English")

get_tokens(text, language = "English")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_tokens_+3A_text">text</code></td>
<td>
<p>An input string</p>
</td></tr>
<tr><td><code id="get_tokens_+3A_language">language</code></td>
<td>
<p>The language used to look up stop words (default is &quot;English&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the input text with stopwords removed.
</p>
<p>A vector of strings consisting of the non-stop words from the 'text' input
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_tokens("On the Origin of Species", language="English")
text &lt;- "A methodology for systematic mapping in environmental sciences"
tokens &lt;- get_tokens(text)
tokens;
</code></pre>

<hr>
<h2 id='language_code'>Get short language codes</h2><span id='topic+language_code'></span>

<h3>Description</h3>

<p>This is a lookup function that returns the two-letter language code for specified language.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>language_code(language)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="language_code_+3A_language">language</code></td>
<td>
<p>A character vector containing the name of a language.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector containing a two-letter language code.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>language_code("French")
</code></pre>

<hr>
<h2 id='possible_langs'>Languages codes synthesisr can recognize</h2><span id='topic+possible_langs'></span>

<h3>Description</h3>

<p>A dataset of the languages that can be recognized by
synthesisr along with their short form, character encoding,
and whether a scientific journal indexed in 'ulrich' uses them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>possible_langs
</code></pre>


<h3>Format</h3>

<p>A database with 53 rows of 4 variables:
</p>

<dl>
<dt>Short</dt><dd><p>the short form language code</p>
</dd>
<dt>Language</dt><dd><p>the name of the language</p>
</dd>
<dt>Encoding</dt><dd><p>which character encoding to use for a language</p>
</dd>
<dt>Used</dt><dd><p>whether or not the language is used by a scientific journal</p>
</dd>
</dl>



<h3>Source</h3>

<p>'litsearchr' package on 'Github'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 possible_langs

</code></pre>

<hr>
<h2 id='remove_punctuation'>Remove punctuation from text</h2><span id='topic+remove_punctuation'></span>

<h3>Description</h3>

<p>Removes common punctuation marks from a text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_punctuation(text, preserve_punctuation = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_punctuation_+3A_text">text</code></td>
<td>
<p>A character vector from which to remove punctuation.</p>
</td></tr>
<tr><td><code id="remove_punctuation_+3A_preserve_punctuation">preserve_punctuation</code></td>
<td>
<p>A string or vector of punctuation to retain</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the input text with punctuation removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>remove_punctuation("#s&lt;&lt;&lt;//&lt;y&gt;!&amp;^n$$t/&gt;h%e&amp;s$is#!++r!//")
</code></pre>

<hr>
<h2 id='suggest_keywords'>Suggest keywords</h2><span id='topic+suggest_keywords'></span>

<h3>Description</h3>

<p>Suggests possible keywords by extracting uni-, bi-, and tri-grams from a long text (e.g. article full text), having
removed punctuation and stop words. Returns the remaining words as a vector of strings and assesses whether they are
already present in the abstract or title
</p>


<h3>Usage</h3>

<pre><code class='language-R'>suggest_keywords(title, abstract, fulltext, suggest = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suggest_keywords_+3A_title">title</code></td>
<td>
<p>An article title</p>
</td></tr>
<tr><td><code id="suggest_keywords_+3A_abstract">abstract</code></td>
<td>
<p>An article abstract</p>
</td></tr>
<tr><td><code id="suggest_keywords_+3A_fulltext">fulltext</code></td>
<td>
<p>An article full text</p>
</td></tr>
<tr><td><code id="suggest_keywords_+3A_suggest">suggest</code></td>
<td>
<p>A logical argument of TRUE or FALSE. If TRUE, the output data frame returned is a subset that only includes
potential keywords (i.e. those not already in the title or abstract)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame consisting of potential candidate keywords and their suitability. If suggest = FALSE, only good
candidates are returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>title &lt;- "A methodology for systematic mapping in environmental sciences"
abstract &lt;- "Systematic mapping was developed in social sciences in response to a lack of empirical 
  data when answering questions using systematic review methods, and a need for a method to describe 
  the literature across a broad subject of interest. Systematic mapping does not attempt to answer 
  a specific question as do systematic reviews, but instead collates, describes and catalogues 
  available evidence (e.g. primary, secondary, theoretical, economic) relating to a topic or 
  question of interest. The included studies can be used to identify evidence for policy-relevant 
  questions, knowledge gaps (to help direct future primary research) and knowledge clusters (sub-
  sets of evidence that may be suitable for secondary research, for example systematic review). 
  Evidence synthesis in environmental sciences faces similar challenges to those found in social 
  sciences. Here we describe the translation of systematic mapping methodology from social sciences 
  for use in environmental sciences. We provide the first process-based methodology for systematic 
  maps, describing the stages involved: establishing the review team and engaging stakeholders; 
  setting the scope and question; setting inclusion criteria for studies; scoping stage; protocol 
  development and publication; searching for evidence; screening evidence; coding; production of a 
  systematic map database; critical appraisal (optional); describing and visualising the findings; 
  report production and supporting information. We discuss the similarities and differences in 
  methodology between systematic review and systematic mapping and provide guidance for those 
  choosing which type of synthesis is most suitable for their requirements. Furthermore, we discuss 
  the merits and uses of systematic mapping and make recommendations for improving this evolving 
  methodology in environmental sciences."
filepath &lt;- system.file("extdata", "fulltext.rds", package="discoverableresearch")
fulltext &lt;- readRDS(filepath)
fulltext &lt;- gsub("\n", " ", fulltext)
fulltext &lt;- gsub("\\s+"," ",fulltext)
poss_keywords &lt;- suggest_keywords(title, abstract, fulltext)
poss_keywords;
</code></pre>

<hr>
<h2 id='suggest_title'>Suggest title words</h2><span id='topic+suggest_title'></span>

<h3>Description</h3>

<p>Suggests possible title words by extracting uni-, 'bi-, and tri-grams from a long text (e.g.
article full text), having removed punctuation and stop words. Returns the remaining words as a
vector of strings and assesses whether they are already present in the title or abstract
</p>


<h3>Usage</h3>

<pre><code class='language-R'>suggest_title(abstract, keywords, fulltext, suggest = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suggest_title_+3A_abstract">abstract</code></td>
<td>
<p>An article abstract</p>
</td></tr>
<tr><td><code id="suggest_title_+3A_keywords">keywords</code></td>
<td>
<p>An article keywords, supplied as a vector</p>
</td></tr>
<tr><td><code id="suggest_title_+3A_fulltext">fulltext</code></td>
<td>
<p>An article full text</p>
</td></tr>
<tr><td><code id="suggest_title_+3A_suggest">suggest</code></td>
<td>
<p>A logical argument of TRUE or FALSE. If TRUE, the output data frame returned is
sub-setting to only include potential keywords (i.e. those not already in the abstract or keywords)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame consisting of potential candidate title words and their suitability. If suggest
= FALSE, only good candidates are returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>abstract &lt;- "Systematic mapping was developed in social sciences in response to a lack of empirical 
  data when answering questions using systematic review methods, and a need for a method to describe 
  the literature across a broad subject of interest. Systematic mapping does not attempt to answer 
  a specific question as do systematic reviews, but instead collates, describes and catalogues 
  available evidence (e.g. primary, secondary, theoretical, economic) relating to a topic or 
  question of interest. The included studies can be used to identify evidence for policy-relevant 
  questions, knowledge gaps (to help direct future primary research) and knowledge clusters (sub-
  sets of evidence that may be suitable for secondary research, for example systematic review). 
  Evidence synthesis in environmental sciences faces similar challenges to those found in social 
  sciences. Here we describe the translation of systematic mapping methodology from social sciences 
  for use in environmental sciences. We provide the first process-based methodology for systematic 
  maps, describing the stages involved: establishing the review team and engaging stakeholders; 
  setting the scope and question; setting inclusion criteria for studies; scoping stage; protocol 
  development and publication; searching for evidence; screening evidence; coding; production of a 
  systematic map database; critical appraisal (optional); describing and visualising the findings; 
  report production and supporting information. We discuss the similarities and differences in 
  methodology between systematic review and systematic mapping and provide guidance for those 
  choosing which type of synthesis is most suitable for their requirements. Furthermore, we discuss 
  the merits and uses of systematic mapping and make recommendations for improving this evolving 
  methodology in environmental sciences."
keywords &lt;- c("Systematic mapping", 
  "Evidence-based environmental management", 
  "Systematic evidence synthesis", 
  "Evidence review", 
  "Knowledge gaps", 
  "Knowledge clusters")
filepath &lt;- system.file("extdata", "fulltext.rds", package="discoverableresearch")
fulltext &lt;- readRDS(filepath)
fulltext &lt;- gsub("\n", " ", fulltext)
fulltext &lt;- gsub("\\s+"," ",fulltext)
poss_titlewords &lt;- suggest_title(abstract, keywords, fulltext)
poss_titlewords;
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
