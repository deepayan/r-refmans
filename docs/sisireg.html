<!DOCTYPE html><html><head><title>Help for package sisireg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sisireg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#axe'>
<p>Data model for the AxE-Model (Axiomatic Econometric Modeling Paradigm)</p></a></li>
<li><a href='#axe_narch_model'><p>implementation of the AxE model based on the ssr-MLP</p></a></li>
<li><a href='#axe_narch_predict'><p>Prediction function for the AxE-NARCH model</p></a></li>
<li><a href='#fii_model'>
<p>Factor-wise Influence Indicator (Model-fii) for a given ssrmlp model</p></a></li>
<li><a href='#fii_prediction'>
<p>Factor-wise Influence Indicator (Prediction-fii) for a given ssrmlp model</p>
regarding a given input vector</a></li>
<li><a href='#onnx_load'>
<p>Loading a ssrmlp model from ONNX file</p></a></li>
<li><a href='#onnx_save'>
<p>Saving a ssrmlp model in onnx format to file</p></a></li>
<li><a href='#psplot'><p>Partial Sum Plot</p></a></li>
<li><a href='#psplot3d'><p>Partial Sum Plot for 2-dimensional coordinates</p></a></li>
<li><a href='#psplotnd'><p>Partial Sum Plot for the multidimensional coordinates</p></a></li>
<li><a href='#psvalid'><p>Partial Sum Validity Check</p></a></li>
<li><a href='#runvalid'><p>Maximum Run Validity Check</p></a></li>
<li><a href='#snarch'><p>S-NARCH Model</p></a></li>
<li><a href='#ssr'><p>Onedimensional SSR-model calculation</p></a></li>
<li><a href='#ssr_predict'><p>SSR model Prediction</p></a></li>
<li><a href='#ssr3d'><p>3-dimensional SSR model</p></a></li>
<li><a href='#ssr3d_predict'><p>3-dimensional SSR model prediction</p></a></li>
<li><a href='#ssrmlp_predict'><p>Prediction function for the ssrMLP</p></a></li>
<li><a href='#ssrmlp_train'><p>2-layer MLP with partial sum optimization</p></a></li>
<li><a href='#ssrnd'><p>Multi-dimensional SSR model</p></a></li>
<li><a href='#ssrnd_predict'><p>Prediction function for the multi-dimensional SSR model</p></a></li>
<li><a href='#tauM'><p>Trend-based Correlation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Sign-Simplicity-Regression-Solver</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the SSR-Algorithm. The Sign-Simplicity-Regression model is a nonparametric statistical model which is based on residual signs and simplicity assumptions on the regression function. Goal is to calculate the most parsimonious regression function satisfying the statistical adequacy requirements. Theory and functions are specified in Metzner (2020, ISBN: 979-8-68239-420-3, "Trendbasierte Prognostik") and Metzner (2021, ISBN: 979-8-59347-027-0, "Adäquates Maschinelles Lernen").</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>zoo, raster, reticulate</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-20 12:38:31 UTC; lme</td>
</tr>
<tr>
<td>Author:</td>
<td>Lars Metzner [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lars Metzner &lt;lars.metzner@ppi.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-20 13:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='axe'>
Data model for the AxE-Model (Axiomatic Econometric Modeling Paradigm)
</h2><span id='topic+axe'></span>

<h3>Description</h3>

<p>Calculation of the relevant data for the AxE-model from a financial time series: trend, volatiliy, change in quotes and risk level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>axe(quotes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="axe_+3A_quotes">quotes</code></td>
<td>
<p>financial time series</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>
<table>
<tr><td><code>quotes</code></td>
<td>
<p>the given time series</p>
</td></tr>
<tr><td><code>trend5</code></td>
<td>
<p>5-day trend</p>
</td></tr>
<tr><td><code>trend10</code></td>
<td>
<p>10-day trend</p>
</td></tr>
<tr><td><code>trend20</code></td>
<td>
<p>20-day trend</p>
</td></tr>
<tr><td><code>vola5</code></td>
<td>
<p>5-day volatility</p>
</td></tr>
<tr><td><code>vola10</code></td>
<td>
<p>10-day volatility</p>
</td></tr>
<tr><td><code>vola20</code></td>
<td>
<p>20-day volatility</p>
</td></tr>
<tr><td><code>chng5</code></td>
<td>
<p>5-day price change</p>
</td></tr>
<tr><td><code>chng10</code></td>
<td>
<p>10-day price change</p>
</td></tr>
<tr><td><code>chng20</code></td>
<td>
<p>20-day price change</p>
</td></tr>
<tr><td><code>risk5</code></td>
<td>
<p>5-day risk level</p>
</td></tr>
<tr><td><code>risk10</code></td>
<td>
<p>10-day risk level</p>
</td></tr>
<tr><td><code>risk20</code></td>
<td>
<p>20-day risk level</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2020) <em>Trendbasierte Prognostik</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
s &lt;- 13000 + cumsum(rnorm(100))
df_axe &lt;- axe(s)
op &lt;- par(mfrow=c(3,1))
plot(s, type = "l")
plot(df_axe$trend5, type = "l")
abline(a = 0, b = 0)
plot(df_axe$vola5, type = "l")
par(op)
</code></pre>

<hr>
<h2 id='axe_narch_model'>implementation of the AxE model based on the ssr-MLP</h2><span id='topic+axe_narch_model'></span>

<h3>Description</h3>

<p>Trains a 2-layer MLP with a given time series of quotes with price changes 
or volatility as target value. The coordinates (or independent factors) are given through
the AxE model)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>axe_narch_model(quotes, T, tgt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="axe_narch_model_+3A_quotes">quotes</code></td>
<td>
<p>array with observations.</p>
</td></tr>
<tr><td><code id="axe_narch_model_+3A_t">T</code></td>
<td>
<p>period: T = 5, 10 or 20.</p>
</td></tr>
<tr><td><code id="axe_narch_model_+3A_tgt">tgt</code></td>
<td>
<p>target variable: tgt = 'trend' or 'vola'.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>model</code></td>
<td>
<p>the trained model for prediction.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1234)
n &lt;- 250
s &lt;- 13000 + cumsum(rnorm(n))
T = 20
# create model for 5-day trend
model &lt;- axe_narch_model(s, T, 'trend')
# calculate prognosis for trend 
s_ &lt;- s[n] + cumsum(rnorm(20))
s_T &lt;- axe_narch_predict(model, s_, 'trend')
# plot the results
plot(seq(1:20), s_, type = "l", 
    xlim = c(0,21+T), ylim = c(min(s_, s_T)-5, max(s_, s_T)+5))
points(20+T, s_T, col='red', pch = 16)
# create model for 5-day vola
model &lt;- axe_narch_model(s, T, 'vola')
r_T &lt;- axe_narch_predict(model, s_, 'vola')
lines(c(20+T,20+T), c(s_T-r_T, s_T+r_T), col='orange')

</code></pre>

<hr>
<h2 id='axe_narch_predict'>Prediction function for the AxE-NARCH model</h2><span id='topic+axe_narch_predict'></span>

<h3>Description</h3>

<p>Calculates the prediction for a given model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>axe_narch_predict(model, quotes, tgt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="axe_narch_predict_+3A_model">model</code></td>
<td>
<p>previously calculated model.</p>
</td></tr>
<tr><td><code id="axe_narch_predict_+3A_quotes">quotes</code></td>
<td>
<p>20 days of history.</p>
</td></tr>
<tr><td><code id="axe_narch_predict_+3A_tgt">tgt</code></td>
<td>
<p>target variable: tgt = 'trend' or 'vola'.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>prediction</code></td>
<td>
<p>prediction based in the model and the given coordinates.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1234)
n &lt;- 250
s &lt;- 13000 + cumsum(rnorm(n))
T = 20
# create model for 5-day trend
model &lt;- axe_narch_model(s, T, 'trend')
# calculate prognosis for trend 
s_ &lt;- s[n] + cumsum(rnorm(20))
s_T &lt;- axe_narch_predict(model, s_, 'trend')
# plot the results
plot(seq(1:20), s_, type = "l", 
    xlim = c(0,21+T), ylim = c(min(s_, s_T)-5, max(s_, s_T)+5))
points(20+T, s_T, col='red', pch = 16)
# create model for 5-day vola
model &lt;- axe_narch_model(s, T, 'vola')
r_T &lt;- axe_narch_predict(model, s_, 'vola')
lines(c(20+T,20+T), c(s_T-r_T, s_T+r_T), col='orange')

</code></pre>

<hr>
<h2 id='fii_model'>
Factor-wise Influence Indicator (Model-fii) for a given ssrmlp model
</h2><span id='topic+fii_model'></span>

<h3>Description</h3>

<p>The Model-fii depicts the overall influence of the input factors on the resulting trained ssrmlp model. For computation a unit matrix is used to accumulate the weights for each factor separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fii_model(W)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fii_model_+3A_w">W</code></td>
<td>
<p>a trained ssrmlp model</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>fii</code></td>
<td>
<p>array of influence indicators</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(42)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
z &lt;- rnorm(300) + atan2(x, y)
# coordinates
X &lt;- matrix(cbind(x,y), ncol = 2)
Y &lt;- as.double(z)
# Training
W &lt;- ssrmlp_train(X, Y)
fii_model(W)


</code></pre>

<hr>
<h2 id='fii_prediction'>
Factor-wise Influence Indicator (Prediction-fii) for a given ssrmlp model
regarding a given input vector</h2><span id='topic+fii_prediction'></span>

<h3>Description</h3>

<p>The Prediction-fii depicts the overall influence of the given input factors on the resulting prediction from a trained ssrmlp model. For computation the components of the input vectors a taken separately as input for the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fii_prediction(W, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fii_prediction_+3A_w">W</code></td>
<td>
<p>a trained ssrmlp model</p>
</td></tr>
<tr><td><code id="fii_prediction_+3A_x">x</code></td>
<td>
<p>a matrix of input vectors</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>fii</code></td>
<td>
<p>array of influence indicators</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(42)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
z &lt;- rnorm(300) + atan2(x, y)
# coordinates
X &lt;- matrix(cbind(x,y), ncol = 2)
Y &lt;- as.double(z)
# Training
W &lt;- ssrmlp_train(X, Y)
fii_prediction(W, X)


</code></pre>

<hr>
<h2 id='onnx_load'>
Loading a ssrmlp model from ONNX file</h2><span id='topic+onnx_load'></span>

<h3>Description</h3>

<p>Loading a ssrmlp model from ONNX file (also see onnx.ai). This function uses the onnx python implementation, hence a python environment including modules onnx and numpy is required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onnx_load(filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="onnx_load_+3A_filename">filename</code></td>
<td>
<p>fully qualified file name</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>W</code></td>
<td>
<p>parameters of ssrmlp model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(42)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
z &lt;- rnorm(300) + atan2(x, y)
# coordinates
X &lt;- matrix(cbind(x,y), ncol = 2)
Y &lt;- as.double(z)
# Training
ssrmlp_model &lt;- ssrmlp_train(X, Y)
# only if python is available
if (reticulate::py_module_available('onnx')) {
  # save in ONNX format
  onnx_save(ssrmlp_model, 'file.onnx')
  # loading the file in ONNX format
  W &lt;- onnx_load('file.onnx')
  # prediction with original implementation
  p &lt;- t(c(0.25, 0.25))
  pred &lt;- ssrmlp_predict(p, W) 
  # predict with TensorFlow
  onnx &lt;- reticulate::import("onnx")
  backend &lt;-  reticulate::import('onnx_tf.backend')
  model = onnx$load('file.onnx') 
  tf_rep = backend$prepare(model)       
  tf_y = tf_rep$run(p)                
  print(tf_y$Y-pred)
  # cleanup
  file.remove('file.onnx')
  # to avoid NOTE in R CHECK
  tempfile &lt;-  reticulate::import("tempfile")
  tmp &lt;- tempfile$gettempdir()
  if (dir.exists(file.path(tmp, "__pycache__"))) {
    unlink(file.path(tmp, "__pycache__"), recursive = TRUE, force = TRUE)
  }
  tmp_py_files &lt;- list.files(tmp, 
                             pattern = "^__autograph_generated_file.*py$", full.names = TRUE)
  file.remove(tmp_py_files)
}


</code></pre>

<hr>
<h2 id='onnx_save'>
Saving a ssrmlp model in onnx format to file
</h2><span id='topic+onnx_save'></span>

<h3>Description</h3>

<p>Saving a ssrmlp model in onnx format to file (also see onnx.ai). This function uses the onnx python implementation, hence a python environment including modules onnx and numpy is required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onnx_save(ssrmlp_model, filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="onnx_save_+3A_ssrmlp_model">ssrmlp_model</code></td>
<td>
<p>a trained ssrmlp model</p>
</td></tr>
<tr><td><code id="onnx_save_+3A_filename">filename</code></td>
<td>
<p>fully qualified file name</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(42)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
z &lt;- rnorm(300) + atan2(x, y)
# coordinates
X &lt;- matrix(cbind(x,y), ncol = 2)
Y &lt;- as.double(z)
# Training
ssrmlp_model &lt;- ssrmlp_train(X, Y)
# prediction
p &lt;- t(c(0.25, 0.25))
pred &lt;- ssrmlp_predict(p, ssrmlp_model) 
# only if python is available
if (reticulate::py_module_available('onnx')) {
  # save in ONNX format
  onnx_save(ssrmlp_model, 'file.onnx')
  # load and run with TensorFlow
  onnx &lt;- reticulate::import("onnx")
  backend &lt;-  reticulate::import("onnx_tf.backend")
  model = onnx$load('file.onnx') 
  tf_rep = backend$prepare(model)       
  tf_y = tf_rep$run(p)
  print(tf_y$Y-pred)
  # cleanup
  file.remove('file.onnx')
  # to avoid NOTE in R CHECK
  tempfile &lt;-  reticulate::import("tempfile")
  tmp &lt;- tempfile$gettempdir()
  if (dir.exists(file.path(tmp, "__pycache__"))) {
    unlink(file.path(tmp, "__pycache__"), recursive = TRUE, force = TRUE)
  }
  tmp_py_files &lt;- list.files(tmp, 
                             pattern = "^__autograph_generated_file.*py$", full.names = TRUE)
  file.remove(tmp_py_files)
}


</code></pre>

<hr>
<h2 id='psplot'>Partial Sum Plot</h2><span id='topic+psplot'></span>

<h3>Description</h3>

<p>Plots the Partial Sums with their quantiles for a given set of observations und the corresponding regression function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>psplot(dat, mu, text = 'Sample')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psplot_+3A_dat">dat</code></td>
<td>
<p>observations.</p>
</td></tr>
<tr><td><code id="psplot_+3A_mu">mu</code></td>
<td>
<p>regression function.</p>
</td></tr>
<tr><td><code id="psplot_+3A_text">text</code></td>
<td>
<p>title of the chart.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No explicit return value: a plot is generated</p>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>psplot(sin(seq(-pi, pi, length.out = 200))+rnorm(200),
  sin(seq(-pi, pi, length.out = 200)), text='Test')
</code></pre>

<hr>
<h2 id='psplot3d'>Partial Sum Plot for 2-dimensional coordinates</h2><span id='topic+psplot3d'></span>

<h3>Description</h3>

<p>Plots the partial sum statistic for the 3-dimensional SSR model</p>


<h3>Usage</h3>

<pre><code class='language-R'>psplot3d(koord, z, mu, text = "Sample")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psplot3d_+3A_koord">koord</code></td>
<td>
<p>data frame with coordinates.</p>
</td></tr>
<tr><td><code id="psplot3d_+3A_z">z</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="psplot3d_+3A_mu">mu</code></td>
<td>
<p>vector of discrete regression function.</p>
</td></tr>
<tr><td><code id="psplot3d_+3A_text">text</code></td>
<td>
<p>optional: title for the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No explicit return value: a plot is generated</p>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(1234)
x &lt;- rnorm(900)
y &lt;- rnorm(900)
xy &lt;- data.frame(x=x, y=y)
z &lt;- rnorm(900) + atan2(x, y)
# Training
df_model &lt;- ssr3d(xy, z, k = 4, fn = 8)
# plot partial sum statistic
psplot3d(xy, z, df_model$mu, 'ssr3d')

</code></pre>

<hr>
<h2 id='psplotnd'>Partial Sum Plot for the multidimensional coordinates</h2><span id='topic+psplotnd'></span>

<h3>Description</h3>

<p>plots the partial sum statistic for the general n-dimensional SSR-model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psplotnd(koord, dat, mu, text = "Sample")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psplotnd_+3A_koord">koord</code></td>
<td>
<p>data frame with coordinates.</p>
</td></tr>
<tr><td><code id="psplotnd_+3A_dat">dat</code></td>
<td>
<p>data frame of observations.</p>
</td></tr>
<tr><td><code id="psplotnd_+3A_mu">mu</code></td>
<td>
<p>list of discrete regression function.</p>
</td></tr>
<tr><td><code id="psplotnd_+3A_text">text</code></td>
<td>
<p>optional: title for the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No explicit return value: a plot is generated</p>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(1234)
x &lt;- rnorm(900)
y &lt;- rnorm(900)
xy &lt;- data.frame(x=x, y=y)
z &lt;-data.frame(z=rnorm(900) + atan2(x, y))
# Training
df_model &lt;- ssrnd(xy, z, k = 4, fn = 8)
# plot partial sum statistic
psplotnd(xy, z, df_model$mu, 'ssr3d')

</code></pre>

<hr>
<h2 id='psvalid'>Partial Sum Validity Check</h2><span id='topic+psvalid'></span>

<h3>Description</h3>

<p>Checks, if a given regression function is adequate with respect to the partial sum criterium.</p>


<h3>Usage</h3>

<pre><code class='language-R'>psvalid(dat,mu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psvalid_+3A_dat">dat</code></td>
<td>
<p>obervations.</p>
</td></tr>
<tr><td><code id="psvalid_+3A_mu">mu</code></td>
<td>
<p>discrete regression function.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>valid</code></td>
<td>
<p>function is valid?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>psvalid(sin(seq(-pi, pi, length.out = 200))+rnorm(200), 
        sin(seq(-pi, pi, length.out = 200)))
</code></pre>

<hr>
<h2 id='runvalid'>Maximum Run Validity Check</h2><span id='topic+runvalid'></span>

<h3>Description</h3>

<p>Checks, if a given regression function is adequate with respect to the maximum run criterium.</p>


<h3>Usage</h3>

<pre><code class='language-R'>runvalid(dat,mu,k=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runvalid_+3A_dat">dat</code></td>
<td>
<p>obervations.</p>
</td></tr>
<tr><td><code id="runvalid_+3A_mu">mu</code></td>
<td>
<p>discrete regression function.</p>
</td></tr>
<tr><td><code id="runvalid_+3A_k">k</code></td>
<td>
<p>optional: maximum run length.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>valid</code></td>
<td>
<p>function is valid?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>runvalid(sin(seq(-pi, pi, length.out = 200))+rnorm(200)/2, 
          sin(seq(-pi, pi, length.out = 200)))
</code></pre>

<hr>
<h2 id='snarch'>S-NARCH Model</h2><span id='topic+snarch'></span>

<h3>Description</h3>

<p>Calculates the long-, middle- and short-term trends and vola for a financial time series.</p>


<h3>Usage</h3>

<pre><code class='language-R'>snarch(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snarch_+3A_dat">dat</code></td>
<td>
<p>financial time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame
</p>
<table>
<tr><td><code>tr20</code></td>
<td>
<p>long-term trend</p>
</td></tr>
<tr><td><code>vl20</code></td>
<td>
<p>long-term vola</p>
</td></tr>
<tr><td><code>tr10</code></td>
<td>
<p>middle-term trend</p>
</td></tr>
<tr><td><code>vl10</code></td>
<td>
<p>middle-term vola</p>
</td></tr>
<tr><td><code>tr5</code></td>
<td>
<p>short-term trend</p>
</td></tr>
<tr><td><code>vl5</code></td>
<td>
<p>short-term vola</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2019) <em>Finanzmathematische Zeitreihenanalyse</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate test data
set.seed(1234)
x &lt;- seq(1:250)
dat &lt;- 13000 + cumsum(rnorm(250))
# calculate the S-NARCH model
df &lt;- snarch(dat)
# plot the results
op &lt;- par(mfrow=c(1,3))
plot(x,dat)
lines(x,df$tr20)
lines(x,df$tr20 - df$vl20, lty = 'dotted')
lines(x,df$tr20 + df$vl20, lty = 'dotted')
plot(x,dat)
lines(x,df$tr10)
lines(x,df$tr10 - df$vl10, lty = 'dotted')
lines(x,df$tr10 + df$vl10, lty = 'dotted')
plot(x,dat)
lines(x,df$tr5)
lines(x,df$tr5 - df$vl5, lty = 'dotted')
lines(x,df$tr5 + df$vl5, lty = 'dotted')
par(op)
</code></pre>

<hr>
<h2 id='ssr'>Onedimensional SSR-model calculation</h2><span id='topic+ssr'></span>

<h3>Description</h3>

<p>Calculates L1- and L2-functions satisfiying the partial sum criterium.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssr(df, y1=NULL, yn=NULL, fn=0, iter=10000, 
        minStat=FALSE, ne=TRUE, l1=TRUE, ps=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssr_+3A_df">df</code></td>
<td>
<p>data frame with two-dimensional data.</p>
</td></tr>
<tr><td><code id="ssr_+3A_y1">y1</code></td>
<td>
<p>optional: fixed value left.</p>
</td></tr>
<tr><td><code id="ssr_+3A_yn">yn</code></td>
<td>
<p>optional: fixed value right.</p>
</td></tr>
<tr><td><code id="ssr_+3A_fn">fn</code></td>
<td>
<p>optional: partial-sum-quantile (standard: generic calculation from data).</p>
</td></tr>
<tr><td><code id="ssr_+3A_iter">iter</code></td>
<td>
<p>optional: maximum number of iterations.</p>
</td></tr>
<tr><td><code id="ssr_+3A_minstat">minStat</code></td>
<td>
<p>optional: boolean value for the minimum statistic.</p>
</td></tr>
<tr><td><code id="ssr_+3A_ne">ne</code></td>
<td>
<p>optional: boolean value for non-equidistant observations.</p>
</td></tr>
<tr><td><code id="ssr_+3A_l1">l1</code></td>
<td>
<p>optional: boolean value for function type.</p>
</td></tr>
<tr><td><code id="ssr_+3A_ps">ps</code></td>
<td>
<p>optional: sign criterium (partial sum or run).</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>mu</code></td>
<td>
<p>SSR-function as array.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate equidistant data
set.seed(1234)
x &lt;- seq(0, 2*pi, length.out = 200)
y &lt;- 4*sin(x) + rnorm(200)
df &lt;- data.frame(x=x, y=y)
# calculate regression functions
l1 &lt;- ssr(df, ne=FALSE, ps=FALSE)
l2 &lt;- ssr(df, ne=FALSE, l1=FALSE)
lmin &lt;- ssr(df, ne=FALSE, minStat=TRUE, ps=FALSE)
# plot results
plot(x, y, main = 'Sign-Simplicity-Regression', 
        xlab = 't', ylab = 'sin(t)+noise')
lines(x, l1, col = 'blue')
lines(x, l2, col = 'red')
lines(x, lmin, col = 'purple')
legend("topleft", inset=c(0.01,0.01), 
        legend=c("L1 run-crit.", "L2 ps-crit.", "L1 min-stat."),
        col=c("blue", "red", "purple"), lty=1:1)

# generate nonequidistant data
df &lt;- data.frame(x=runif(500, min=-1, max=1)*pi)
df$y &lt;- sin(df$x)*20 + rnorm(nrow(df), mean=0, sd=10)
# calculate regression function
dfl1 &lt;- ssr(df, fn = 5)
# plot results
plot(df)
lines(dfl1, col = 'red')
</code></pre>

<hr>
<h2 id='ssr_predict'>SSR model Prediction</h2><span id='topic+ssr_predict'></span>

<h3>Description</h3>

<p>Calculates the prediction for a given SSR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssr_predict(df, xx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssr_predict_+3A_df">df</code></td>
<td>
<p>dataframe containing two series with x- und y-values.</p>
</td></tr>
<tr><td><code id="ssr_predict_+3A_xx">xx</code></td>
<td>
<p>array containung locations for predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>yy</code></td>
<td>
<p>array containung the predicted values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(1234)
  df &lt;- data.frame(x=runif(500, min=-1, max=1)*pi)
  df$y &lt;- sin(df$x)*20 + rnorm(nrow(df), mean=0, sd=10)
  plot(df, xlim=c(-4, 4))
  dfl1 &lt;- ssr(df)
  lines(dfl1)
  xx &lt;- c(-4, -1, 0, 1, 4)
  yy &lt;- ssr_predict(dfl1, xx)
  points(xx,yy, pch='+', col='red', cex=2)
</code></pre>

<hr>
<h2 id='ssr3d'>3-dimensional SSR model</h2><span id='topic+ssr3d'></span>

<h3>Description</h3>

<p>Calculates the regression function for the 3-dimensional SSR-model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssr3d(koord, dat, k = NULL, fn = NULL, iter = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssr3d_+3A_koord">koord</code></td>
<td>
<p>data frame with 2-dimensional coordinates.</p>
</td></tr>
<tr><td><code id="ssr3d_+3A_dat">dat</code></td>
<td>
<p>vector with observations.</p>
</td></tr>
<tr><td><code id="ssr3d_+3A_k">k</code></td>
<td>
<p>optional: maxumum run length for the model.</p>
</td></tr>
<tr><td><code id="ssr3d_+3A_fn">fn</code></td>
<td>
<p>optional: quantile for partial sums.</p>
</td></tr>
<tr><td><code id="ssr3d_+3A_iter">iter</code></td>
<td>
<p>optional: number of iterations for the numeric solver.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>df</code></td>
<td>
<p>data frame with the relevant model data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(1234)
x &lt;- rnorm(900)
y &lt;- rnorm(900)
xy &lt;- data.frame(x=x, y=y)
z &lt;- rnorm(900) + atan2(x, y)
# Training
df_model &lt;- ssr3d(xy, z)

</code></pre>

<hr>
<h2 id='ssr3d_predict'>3-dimensional SSR model prediction</h2><span id='topic+ssr3d_predict'></span>

<h3>Description</h3>

<p>Calculates the prediction for a given 3-dimensional SSR model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssr3d_predict(df_model, xy, ms = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssr3d_predict_+3A_df_model">df_model</code></td>
<td>
<p>data frame with model coordinates.</p>
</td></tr>
<tr><td><code id="ssr3d_predict_+3A_xy">xy</code></td>
<td>
<p>data frame with coordinates for prediction.</p>
</td></tr>
<tr><td><code id="ssr3d_predict_+3A_ms">ms</code></td>
<td>
<p>optional: boolean value to use the minimal surface algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>z</code></td>
<td>
<p>array with predictions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(1234)
x &lt;- rnorm(900)
y &lt;- rnorm(900)
xy &lt;- data.frame(x=x, y=y)
z &lt;- rnorm(900) + atan2(x, y)
# Training
df_model &lt;- ssr3d(xy, z)
# Prediction
xx &lt;- c(c(0,1), c(-1,1), c(1,-1))
xx &lt;- matrix(xx, ncol = 2)
yy &lt;- ssr3d_predict(df_model, xx)

</code></pre>

<hr>
<h2 id='ssrmlp_predict'>Prediction function for the ssrMLP</h2><span id='topic+ssrmlp_predict'></span>

<h3>Description</h3>

<p>Calculates the prediction for a given ssrMLP
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssrmlp_predict(X, W)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssrmlp_predict_+3A_x">X</code></td>
<td>
<p>matrix of coordinates.</p>
</td></tr>
<tr><td><code id="ssrmlp_predict_+3A_w">W</code></td>
<td>
<p>the weight matrices from ssrmlp_train method.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Yp</code></td>
<td>
<p>array with predictions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(42)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
z &lt;- rnorm(300) + atan2(x, y)
# coordinates
X &lt;- matrix(cbind(x,y), ncol = 2)
Y &lt;- as.double(z)
# Training
W &lt;- ssrmlp_train(X, Y)
Yp &lt;- ssrmlp_predict(X, W)

</code></pre>

<hr>
<h2 id='ssrmlp_train'>2-layer MLP with partial sum optimization</h2><span id='topic+ssrmlp_train'></span>

<h3>Description</h3>

<p>Calculates the weights of a 2-layer MLP with respect to the partial sums 
critereon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssrmlp_train(X, Y, std=TRUE, opt='ps', hl = NULL, W = NULL,
  k=10, fn=4, eta=0.75, maxIter=1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssrmlp_train_+3A_x">X</code></td>
<td>
<p>matrix with n-dimensional coordinates.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_y">Y</code></td>
<td>
<p>array with observations.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_std">std</code></td>
<td>
<p>optional: standardizing values if TRUE.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_opt">opt</code></td>
<td>
<p>optional: optimizing function ('l2' or 'ps'.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_hl">hl</code></td>
<td>
<p>optional: array tupel with number of perceptrons in each layer.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_w">W</code></td>
<td>
<p>optional: previously calculates weights for refining the model.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_k">k</code></td>
<td>
<p>optional: number of neighbors per quadrant.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_fn">fn</code></td>
<td>
<p>optional: quantile for partial sums.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_eta">eta</code></td>
<td>
<p>optional: constant factor of the gradient algorithm.</p>
</td></tr>
<tr><td><code id="ssrmlp_train_+3A_maxiter">maxIter</code></td>
<td>
<p>optional: number of iterations for the numeric solver.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>W</code></td>
<td>
<p>List with weight matrices.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(42)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
z &lt;- rnorm(300) + atan2(x, y)
# coordinates
X &lt;- matrix(cbind(x,y), ncol = 2)
Y &lt;- as.double(z)
# Training
W &lt;- ssrmlp_train(X, Y)

</code></pre>

<hr>
<h2 id='ssrnd'>Multi-dimensional SSR model</h2><span id='topic+ssrnd'></span>

<h3>Description</h3>

<p>Calculates the multi-dimensional SSR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssrnd(koord, dat, k = NULL, fn = NULL, iter = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssrnd_+3A_koord">koord</code></td>
<td>
<p>data frame with n-dimensional coordinates.</p>
</td></tr>
<tr><td><code id="ssrnd_+3A_dat">dat</code></td>
<td>
<p>data frame with observations.</p>
</td></tr>
<tr><td><code id="ssrnd_+3A_k">k</code></td>
<td>
<p>optional: maxumum run length for the model.</p>
</td></tr>
<tr><td><code id="ssrnd_+3A_fn">fn</code></td>
<td>
<p>optional: quantile for partial sums.</p>
</td></tr>
<tr><td><code id="ssrnd_+3A_iter">iter</code></td>
<td>
<p>optional: number of iterations for the numeric solver.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>df</code></td>
<td>
<p>data frame with the relevant model data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(1234)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
xy &lt;- data.frame(x=x, y=y)
z &lt;-data.frame(z=rnorm(300) + atan2(x, y))
# Training
df_model &lt;- ssrnd(xy, z)

</code></pre>

<hr>
<h2 id='ssrnd_predict'>Prediction function for the multi-dimensional SSR model</h2><span id='topic+ssrnd_predict'></span>

<h3>Description</h3>

<p>Calculates the prediction for a given multi-dimensional SSR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssrnd_predict(df_model, xx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssrnd_predict_+3A_df_model">df_model</code></td>
<td>
<p>data frame with model coordinates.</p>
</td></tr>
<tr><td><code id="ssrnd_predict_+3A_xx">xx</code></td>
<td>
<p>data frame with coordinates for prediction.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>z</code></td>
<td>
<p>list with predictions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2021) <em>Adäquates Maschinelles Lernen</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate data
set.seed(1234)
x &lt;- rnorm(300)
y &lt;- rnorm(300)
xy &lt;- data.frame(x=x, y=y)
z &lt;-data.frame(z=rnorm(300) + atan2(x, y))
# Training
df_model &lt;- ssrnd(xy, z)
# Prediction
xx &lt;- c(c(0,1), c(-1,1), c(1,-1))
xx &lt;- matrix(xx, ncol = 2)
yy &lt;- ssrnd_predict(df_model, xx)

</code></pre>

<hr>
<h2 id='tauM'>Trend-based Correlation</h2><span id='topic+tauM'></span>

<h3>Description</h3>

<p>Calculates the trend-based correlation of two time series based on the trend function (Metzner's Tau)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tauM(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tauM_+3A_x">x</code></td>
<td>
<p>time series.</p>
</td></tr>
<tr><td><code id="tauM_+3A_y">y</code></td>
<td>
<p>time series.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>trend-based correlation.</p>


<h3>Author(s)</h3>

<p>Dr. Lars Metzner
</p>


<h3>References</h3>

<p>Dr. Lars Metzner (2020) <em>Trendbasierte Prognostik</em>.
Independently Published.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
s &lt;- seq(-pi, pi, length.out = 200)
x &lt;- s + rnorm(200)
y &lt;- exp(s) + 5*rnorm(length(s))
op &lt;- par(mfrow=c(1,2))
plot(x)
plot(y)
par(op)

p &lt;- cor(x,y) # 0.5037
t &lt;- cor(x,y, method = 'kendall') # 0.2959
tm &lt;- tauM(x, y) # 0.0867
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
