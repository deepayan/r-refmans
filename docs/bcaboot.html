<!DOCTYPE html><html lang="en"><head><title>Help for package bcaboot</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bcaboot}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bcaboot'><p>Automatic Construction of Bootstrap Confidence Intervals</p></a></li>
<li><a href='#bcajack'><p>Nonparametric bias-corrected and accelerated bootstrap</p>
confidence limits</a></li>
<li><a href='#bcajack2'><p>Nonparametric bias-corrected and accelerated bootstrap</p>
confidence limits</a></li>
<li><a href='#bcapar'><p>Compute parametric bootstrap confidence intervals</p></a></li>
<li><a href='#bcaplot'><p>Plots of bca confidence limits</p></a></li>
<li><a href='#diabetes'><p>Blood and other measurements in diabetics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Bias Corrected Bootstrap Confidence Intervals</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2-3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Computation of bootstrap confidence intervals in an almost automatic fashion as described in Efron and Narasimhan (2020, &lt;<a href="https://doi.org/10.1080%2F10618600.2020.1714633">doi:10.1080/10618600.2020.1714633</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bnaras.github.io/bcaboot/">https://bnaras.github.io/bcaboot/</a>,
<a href="https://github.com/bnaras/bcaboot">https://github.com/bnaras/bcaboot</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bnaras/bcaboot/issues">https://github.com/bnaras/bcaboot/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>glmnet, rmarkdown, knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, utils</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-08 17:00:19 UTC; naras</td>
</tr>
<tr>
<td>Author:</td>
<td>Bradley Efron [aut],
  Balasubramanian Narasimhan [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Balasubramanian Narasimhan &lt;naras@stat.stanford.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-09 05:10:19 UTC</td>
</tr>
</table>
<hr>
<h2 id='bcaboot'>Automatic Construction of Bootstrap Confidence Intervals</h2><span id='topic+bcaboot'></span>

<h3>Description</h3>

<p>Bootstrap confidence intervals depend on three elements: (a) the
cumulative distribution of the bootstrap replications, (b) the
bias-correction, and (c) the acceleration number that measures the
rate of change in the standard deviation of the estimate as the
data changes.  The first two of these depend only on the bootstrap
distribution, and not how it is generated: parametrically or
non-parametrically. Therefore, the only difference in a parametric
bca analysis would lie in the nonparametric estimation of the
acceleration, often a negligible error.
</p>

<hr>
<h2 id='bcajack'>Nonparametric bias-corrected and accelerated bootstrap
confidence limits</h2><span id='topic+bcajack'></span>

<h3>Description</h3>

<p>This routine computes nonparametric confidence
intervals for bootstrap estimates. For reproducibility, save or
set the random number state before calling this routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcajack(
  x,
  B,
  func,
  ...,
  m = nrow(x),
  mr = 5,
  K = 2,
  J = 10,
  alpha = c(0.025, 0.05, 0.1, 0.16),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bcajack_+3A_x">x</code></td>
<td>
<p>an <code class="reqn">n \times p</code> data matrix, rows are observed
<code class="reqn">p</code>-vectors, assumed to be independently sampled from
target population. If <code class="reqn">p</code> is 1 then <code>x</code> can be a vector.</p>
</td></tr>
<tr><td><code id="bcajack_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications. It can also be a vector
of <code>B</code> bootstrap replications of the estimated parameter of
interest, computed separately.</p>
</td></tr>
<tr><td><code id="bcajack_+3A_func">func</code></td>
<td>
<p>function <code class="reqn">\hat{\theta}=func(x)</code> computing estimate of the
parameter of interest; <code class="reqn">func(x)</code> should return a real value
for any <code class="reqn">n^\prime \times p</code> matrix <code class="reqn">x^\prime</code>,
<code class="reqn">n^\prime</code> not necessarily equal to <code class="reqn">n</code></p>
</td></tr>
<tr><td><code id="bcajack_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>func</code>.</p>
</td></tr>
<tr><td><code id="bcajack_+3A_m">m</code></td>
<td>
<p>an integer less than or equal to <code class="reqn">n</code>; the routine
collects the <code class="reqn">n</code> rows of <code>x</code> into <code>m</code> groups to speed up
the jackknife calculations for estimating the acceleration
value <code class="reqn">a</code>; typically <code>m</code> is 20 or 40 and does not have to
exactly divide <code class="reqn">n</code>. However, warnings will be shown.</p>
</td></tr>
<tr><td><code id="bcajack_+3A_mr">mr</code></td>
<td>
<p>if <code class="reqn">m &lt; n</code> then <code>mr</code> repetions of the randomly
grouped jackknife calculations are averaged.</p>
</td></tr>
<tr><td><code id="bcajack_+3A_k">K</code></td>
<td>
<p>a non-negative integer. If <code>K</code> &gt; 0, bcajack also returns
estimates of <em>internal standard error</em>, that is, of the
variability due to stopping at <code>B</code> bootstrap replications
rather than going on to infinity. These are obtained from a
second type of jackknifing, taking an average of <code>K</code> separate
jackknife estimates, each randomly splitting the <code>B</code> bootstrap
replications into <code>J</code> groups.</p>
</td></tr>
<tr><td><code id="bcajack_+3A_j">J</code></td>
<td>
<p>the number of groups into which the bootstrap replications
are split</p>
</td></tr>
<tr><td><code id="bcajack_+3A_alpha">alpha</code></td>
<td>
<p>percentiles desired for the bca confidence limits. One
only needs to provide <code>alpha</code> values below 0.5; the upper
limits are automatically computed</p>
</td></tr>
<tr><td><code id="bcajack_+3A_verbose">verbose</code></td>
<td>
<p>logical for verbose progress messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bootstrap confidence intervals depend on three elements:
</p>

<ul>
<li><p> the cdf of the <code class="reqn">B</code> bootstrap replications <code class="reqn">t_i^*</code>, <code class="reqn">i=1\ldots B</code>
</p>
</li>
<li><p> the bias-correction number <code class="reqn">z_0=\Phi(\sum_i^B I(t_i^* &lt; t_0) / B )</code>
where <code class="reqn">t_0=f(x)</code> is the original estimate
</p>
</li>
<li><p> the acceleration number <code class="reqn">a</code> that measures the rate of
change in <code class="reqn">\sigma_{t_0}</code> as <code class="reqn">x</code>, the data changes.
</p>
</li></ul>

<p>The first two of these depend only on the bootstrap distribution,
and not how it is generated: parametrically or
non-parametrically. Program bcajack can be used in a hybrid fashion
in which the vector <code>tt</code> of B bootstrap replications is first
generated from a parametric model.
</p>
<p>So, in the diabetes example below, we might first draw bootstrap
samples <code class="reqn">y^* \sim N(X\hat{\beta}, \hat{\sigma}^2 I)</code> where
<code class="reqn">\hat{\beta}</code> and <code class="reqn">\hat{\sigma}</code> were obtained from
<code>lm(y~X)</code>; each <code class="reqn">y^*</code> would then provide a bootstrap
replication <code>tstar = rfun(cbind(X, ystar))</code>.  Then we could get bca
intervals from <code style="white-space: pre;">&#8288;bcajack(Xy, tt, rfun ....)&#8288;</code> with <code>tt</code>,
the vector of B <code>tstar</code> values. The only difference from a full
parametric bca analysis would lie in the nonparametric estimation
of <code class="reqn">a</code>, often a negligible error.
</p>


<h3>Value</h3>

<p>a named list of several items
</p>

<ul>
<li> <p><strong>lims</strong> : first column shows the estimated bca confidence limits
at the requested alpha percentiles. These can be compared with
the standard limits <code class="reqn">\hat{\theta} +
    \hat{\sigma}z_{\alpha}</code>, third column. The second column
<code>jacksd</code> gives the internal standard errors for the bca limits,
quite small in the example. Column 4, <code>pct</code>, gives the
percentiles of the ordered B bootstrap replications
corresponding to the bca limits, eg the 897th largest
replication equalling the .975 bca limit .557.
</p>
</li>
<li> <p><strong>stats</strong> : top line of stats shows 5 estimates: theta is
<code class="reqn">f(x)</code>, original point estimate of the parameter of
interest; <code>sdboot</code> is its bootstrap estimate of standard error;
<code>z0</code> is the bca bias correction value, in this case quite
negative; <code>a</code> is the <em>acceleration</em>, a component of the bca
limits (nearly zero here); <code>sdjack</code> is the jackknife estimate
of standard error for theta. Bottom line gives the internal
standard errors for the five quantities above. This is
substantial for <code>z0</code> above.
</p>
</li>
<li> <p><strong>B.mean</strong> : bootstrap sample size B, and the mean of the B
bootstrap replications <code class="reqn">\hat{\theta^*}</code>
</p>
</li>
<li> <p><strong>ustats</strong> : The bias-corrected estimator <code>2 * t0 - mean(tt)</code>,
and an estimate <code>sdu</code> of its sampling error
</p>
</li>
<li> <p><strong>seed</strong> : The random number state for reproducibility
</p>
</li></ul>



<h3>References</h3>

<p>DiCiccio T and Efron B (1996). Bootstrap confidence
intervals. Statistical Science 11, 189-228
</p>
<p>Efron B (1987). Better bootstrap confidence
intervals. JASA 82 171-200
</p>
<p>B. Efron and B. Narasimhan. Automatic Construction of
Bootstrap Confidence Intervals, 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diabetes, package = "bcaboot")
Xy &lt;- cbind(diabetes$x, diabetes$y)
rfun &lt;- function(Xy) {
  y &lt;- Xy[, 11]
  X &lt;- Xy[, 1:10]
  summary(lm(y~X) )$adj.r.squared
}
set.seed(1234)
## n = 442 = 34 * 13
bcajack(x = Xy, B = 1000, func = rfun, m = 34, verbose = FALSE)
</code></pre>

<hr>
<h2 id='bcajack2'>Nonparametric bias-corrected and accelerated bootstrap
confidence limits</h2><span id='topic+bcajack2'></span>

<h3>Description</h3>

<p>This function is a version of <code>bcajack</code> that allows
all the recomputations of the original statistic function
<code class="reqn">f</code> to be carried out separately. This is an advantage
if <code class="reqn">f</code> is time-consuming, in which case the B
replications for the nonparametric bca calculations might need
to be done on a distributed basis.
</p>
<p>To use <code>bcajack2</code> in this mode, we first compute a list <code>Blist</code> via
<code>Blist &lt;- list(Y = Y, tt = tt, t0 = t0)</code>.  Here <code>tt</code> is a vector of
length <code>B</code> having i-th entry <code>tt[i] &lt;- func(x[Ii,], ...)</code>, where <code>x</code>
is the <code class="reqn">n \times p</code> data matrix and <code>Ii</code> is a bootstrap vector
of (observation) indices. <code>Y</code> is a <code>B</code> by <code class="reqn">n</code> count matrix,
whose i-th row is the counts corresponding to <code>Ii</code>. For example if
n = 5 and <code style="white-space: pre;">&#8288;Ii = (2, 5, 2, 1, 4)&#8288;</code>, then <code style="white-space: pre;">&#8288;Yi = (1, 2, 0, 1, 1)&#8288;</code>. Having computed <code>Blist</code>, <code>bcajack2</code> is invoked as
<code>bcajack2(Blist)</code> without need to enter the function <code class="reqn">func</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcajack2(
  x,
  B,
  func,
  ...,
  m = nrow(x),
  mr,
  pct = 0.333,
  K = 2,
  J = 12,
  alpha = c(0.025, 0.05, 0.1, 0.16),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bcajack2_+3A_x">x</code></td>
<td>
<p>an <code class="reqn">n \times p</code> data matrix, rows are observed
<code class="reqn">p</code>-vectors, assumed to be independently sampled from
target population. If <code class="reqn">p</code> is 1 then <code>x</code> can be a vector.</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications. <code>B</code> can also be a vector
of <code>B</code> bootstrap replications of the estimated parameter of
interest, computed separately. If <code>B</code> is <code>Blist</code> as explained
above, <code>x</code> is not needed.</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_func">func</code></td>
<td>
<p>function <code class="reqn">\hat{\theta}=func(x)</code> computing estimate of the
parameter of interest; <code class="reqn">func(x)</code> should return a real value
for any <code class="reqn">n^\prime \times p</code> matrix <code class="reqn">x^\prime</code>,
<code class="reqn">n^\prime</code> not necessarily equal to <code class="reqn">n</code></p>
</td></tr>
<tr><td><code id="bcajack2_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>func</code>.</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_m">m</code></td>
<td>
<p>an integer less than or equal to <code class="reqn">n</code>; the routine
collects the <code class="reqn">n</code> rows of <code>x</code> into <code>m</code> groups to speed up
the jackknife calculations for estimating the acceleration
value <code class="reqn">a</code>; typically <code>m</code> is 20 or 40 and does not have to
exactly divide <code class="reqn">n</code>. However, warnings will be shown.</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_mr">mr</code></td>
<td>
<p>if <code class="reqn">m &lt; n</code> then <code>mr</code> repetions of the randomly
grouped jackknife calculations are averaged.</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_pct">pct</code></td>
<td>
<p><code>bcajack2</code> uses those count vectors nearest (1,1,...1)
to estimate the gradient of the statistic, &quot;nearest&quot; being
defined as those count vectors in the smallest <code>pct</code> of all B
of them. Default value for 'pct is 1/3 (see appendix in Efron
and Narasimhan for further details)</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_k">K</code></td>
<td>
<p>a non-negative integer. If <code>K</code> &gt; 0, bcajack also returns
estimates of <em>internal standard error</em>, that is, of the
variability due to stopping at <code>B</code> bootstrap replications
rather than going on to infinity. These are obtained from a
second type of jackknifing, taking an average of <code>K</code> separate
jackknife estimates, each randomly splitting the <code>B</code> bootstrap
replications into <code>J</code> groups.</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_j">J</code></td>
<td>
<p>the number of groups into which the bootstrap replications
are split</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_alpha">alpha</code></td>
<td>
<p>percentiles desired for the bca confidence limits. One
only needs to provide <code>alpha</code> values below 0.5; the upper
limits are automatically computed</p>
</td></tr>
<tr><td><code id="bcajack2_+3A_verbose">verbose</code></td>
<td>
<p>logical for verbose progress messages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of several items
</p>

<ul>
<li> <p><strong>lims</strong> : first column shows the estimated bca confidence limits
at the requested alpha percentiles. These can be compared with
the standard limits <code class="reqn">\hat{\theta} +
    \hat{\sigma}z_{\alpha}</code>, third column. The second column
<code>jacksd</code> gives the internal standard errors for the bca limits,
quite small in the example. Column 4, <code>pct</code>, gives the
percentiles of the ordered B bootstrap replications
corresponding to the bca limits, eg the 897th largest
replication equalling the .975 bca limit .557.
</p>
</li>
<li> <p><strong>stats</strong> : top line of stats shows 5 estimates: theta is
<code class="reqn">func(x)</code>, original point estimate of the parameter of
interest; <code>sdboot</code> is its bootstrap estimate of standard error;
<code>z0</code> is the bca bias correction value, in this case quite
negative; <code>a</code> is the <em>acceleration</em>, a component of the bca
limits (nearly zero here); <code>sdjack</code> is the jackknife estimate
of standard error for theta. Bottom line gives the internal
standard errors for the five quantities above. This is
substantial for <code>z0</code> above.
</p>
</li>
<li> <p><strong>B.mean</strong> : bootstrap sample size B, and the mean of the B
bootstrap replications <code class="reqn">\hat{\theta^*}</code>
</p>
</li>
<li> <p><strong>ustats</strong> : The bias-corrected estimator <code>2 * t0 - mean(tt)</code>,
and an estimate <code>sdu</code> of its sampling error
</p>
</li>
<li> <p><strong>seed</strong> : The random number state for reproducibility
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(diabetes, package = "bcaboot")
Xy &lt;- cbind(diabetes$x, diabetes$y)
rfun &lt;- function(Xy) {
  y &lt;- Xy[, 11]
  X &lt;- Xy[, 1:10]
  summary(lm(y~X) )$adj.r.squared
}
set.seed(1234)
bcajack2(x = Xy, B = 1000, func = rfun, m = 40, verbose = FALSE)

</code></pre>

<hr>
<h2 id='bcapar'>Compute parametric bootstrap confidence intervals</h2><span id='topic+bcapar'></span>

<h3>Description</h3>

<p>bcapar computes parametric bootstrap confidence
intervals for a real-valued parameter theta in a p-parameter
exponential family. It is described in Section 4 of the
reference below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcapar(
  t0,
  tt,
  bb,
  alpha = c(0.025, 0.05, 0.1, 0.16),
  J = 10,
  K = 6,
  trun = 0.001,
  pct = 0.333,
  cd = 0,
  func
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bcapar_+3A_t0">t0</code></td>
<td>
<p>Observed estimate of theta, usually by maximum
likelihood.</p>
</td></tr>
<tr><td><code id="bcapar_+3A_tt">tt</code></td>
<td>
<p>A vector of parametric bootstrap replications of theta of
length <code>B</code>, usually large, say <code>B = 2000</code></p>
</td></tr>
<tr><td><code id="bcapar_+3A_bb">bb</code></td>
<td>
<p>A <code>B</code> by <code>p</code> matrix of natural sufficient vectors, where
<code>p</code> is the dimension of the exponential family.</p>
</td></tr>
<tr><td><code id="bcapar_+3A_alpha">alpha</code></td>
<td>
<p>percentiles desired for the bca confidence limits. One
only needs to provide <code>alpha</code> values below 0.5; the upper
limits are automatically computed</p>
</td></tr>
<tr><td><code id="bcapar_+3A_j">J</code>, <code id="bcapar_+3A_k">K</code></td>
<td>
<p>Parameters controlling the jackknife estimates of Monte
Carlo error: <code>J</code> jackknife folds, with the jackknife standard
errors averaged over <code>K</code> random divisions of <code>bb</code></p>
</td></tr>
<tr><td><code id="bcapar_+3A_trun">trun</code></td>
<td>
<p>Truncation parameter used in the calculation of the
acceleration <code>a</code>.</p>
</td></tr>
<tr><td><code id="bcapar_+3A_pct">pct</code></td>
<td>
<p>Proportion of &quot;nearby&quot; b vectors used in the calculation
of <code>t.</code>, the gradient vector of theta.</p>
</td></tr>
<tr><td><code id="bcapar_+3A_cd">cd</code></td>
<td>
<p>If cd is 1 the bca confidence density is also returned;
see Section 11.6 in reference Efron and Hastie (2016) below</p>
</td></tr>
<tr><td><code id="bcapar_+3A_func">func</code></td>
<td>
<p>Function <code class="reqn">\hat{\theta} = func(b)</code>. If this is not missing then
output includes <em>abc</em> estimates; see reference DiCiccio and Efron (1992) below</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of several items:
</p>

<ul>
<li> <p><strong>lims</strong> : Bca confidence limits (first column) and the standard
limits (fourth column). Also the abc limits (fifth column) if
<code>func</code> is provided. The second column, <code>jacksd</code>, are the
jackknife estimates of Monte Carlo error; <code>pct</code>, the third
column are the proportion of the replicates <code>tt</code> less than each
<code>bcalim</code> value
</p>
</li>
<li> <p><strong>stats</strong> : Estimates and their jackknife Monte Carlo errors:
<code>theta</code> = <code class="reqn">\hat{\theta}</code>; <code>sd</code>, the bootstrap standard deviation
for <code class="reqn">\hat{\theta}</code>; <code>a</code> the acceleration estimate; <code>az</code> another
acceleration estimate that depends less on extreme values of <code>tt</code>;
<code>z0</code> the bias-correction estimate; <code>A</code> the big-A measure of raw
acceleration; <code>sdd</code> delta method estimate for standard deviation of
<code class="reqn">\hat{\theta}</code>; <code>mean</code> the average of <code>tt</code>
</p>
</li>
<li> <p><strong>abcstats</strong> : The abc estimates of <code>a</code> and <code>z0</code>, returned if <code>func</code> was provided
</p>
</li>
<li> <p><strong>ustats</strong> : The bias-corrected estimator <code>2 * t0 - mean(tt)</code>. <code>ustats</code>
gives <code>ustat</code>, an estimate <code>sdu</code> of its sampling error, and jackknife
estimates of monte carlo error for both <code>ustat</code> and <code>sdu</code>. Also given
is <code>B</code>, the number of bootstrap replications
</p>
</li>
<li> <p><strong>seed</strong> : The random number state for reproducibility
</p>
</li></ul>



<h3>References</h3>

<p>DiCiccio T and Efron B (1996). Bootstrap confidence
intervals. Statistical Science 11, 189-228
</p>
<p>T. DiCiccio and B. Efron. More accurate confidence intervals in exponential families.
Biometrika (1992) p231-245.
</p>
<p>Efron B (1987). Better bootstrap confidence intervals. JASA 82, 171-200
</p>
<p>B. Efron and T. Hastie. Computer Age Statistical Inference. Cambridge University Press, 2016.
</p>
<p>B. Efron and B. Narasimhan. Automatic Construction of Bootstrap Confidence Intervals, 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diabetes, package = "bcaboot")
X &lt;- diabetes$x
y &lt;- scale(diabetes$y, center = TRUE, scale = FALSE)
lm.model &lt;- lm(y ~ X - 1)
mu.hat &lt;- lm.model$fitted.values
sigma.hat &lt;- stats::sd(lm.model$residuals)
t0 &lt;- summary(lm.model)$adj.r.squared
y.star &lt;- sapply(mu.hat, rnorm, n = 1000, sd = sigma.hat)
tt &lt;- apply(y.star, 1, function(y) summary(lm(y ~ X - 1))$adj.r.squared)
b.star &lt;- y.star %*% X
set.seed(1234)
bcapar(t0 = t0, tt = tt, bb = b.star)
</code></pre>

<hr>
<h2 id='bcaplot'>Plots of bca confidence limits</h2><span id='topic+bcaplot'></span>

<h3>Description</h3>

<p><code>bcaplot</code> uses the output of <code>bcajack</code>,
<code>bcajack2</code>, or <code>bcapar</code> to plot bca and standard
confidence limits for the parameter of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcaplot(
  vl,
  main = " ",
  xlab = "coverage",
  ylab = "limits",
  alpha = c(0.025, 0.05, 0.1, 0.16),
  ylim,
  xlim,
  add = 0,
  sub = "black=bca, green=standard",
  sw = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bcaplot_+3A_vl">vl</code></td>
<td>
<p>output of <code>bcajack</code>, <code>bcajack2</code>, or
<code>bcapar</code></p>
</td></tr>
<tr><td><code id="bcaplot_+3A_main">main</code></td>
<td>
<p>The main caption (can be empty)</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_xlab">xlab</code></td>
<td>
<p>The x axis label (supplied if not specified)</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_ylab">ylab</code></td>
<td>
<p>The y axis labels (supplied if not specified)</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_alpha">alpha</code></td>
<td>
<p>Coverages are <code class="reqn">1-2\alpha</code>,
e.g. <code>alpha=c(.025,.05)</code> plots intervals
<code>[.025,.975]</code> and <code>[.05,.95]</code>. Default is
<code>alpha=c(.025,.05,.1,.16)</code> giving coverages
.95,.90,.80,.68</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_ylim">ylim</code></td>
<td>
<p>y axis plot limits set automatically if not provided</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_xlim">xlim</code></td>
<td>
<p>x axis plot limits set automatically if not provided</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_add">add</code></td>
<td>
<p><code>add=1</code> adds a new plot of bca limits (in red) to
an existing plot</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_sub">sub</code></td>
<td>
<p>subtitle (can be empty)</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_sw">sw</code></td>
<td>
<p><code>sw=1</code> draws light vertical dashed lines showing the
bca intervals</p>
</td></tr>
<tr><td><code id="bcaplot_+3A_...">...</code></td>
<td>
<p>further args for plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>confidence interval endpoints are plotted vertically versus
two-sided coverages <code class="reqn">1-2\alpha</code>. Bca limits in black,
Standard limits in green (dashed.). If <code>vl$lims</code> includes
the column &quot;jacksd&quot; of jackknife internal standard deviations
then these are indicated by vertical red bars centered at the
bca limit points.
</p>

<hr>
<h2 id='diabetes'>Blood and other measurements in diabetics</h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>The <code>diabetes</code> data frame has 442 rows and 3 columns. These are the
data used in the Efron et al &quot;Least Angle Regression&quot; paper.
</p>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<ul>
<li> <p><strong>x</strong> a matrix with 10 columns
</p>
</li>
<li> <p><strong>y</strong> a numeric vector
</p>
</li>
<li> <p><strong>x2</strong> a matrix with 64 columns
</p>
</li></ul>



<h3>Details</h3>

<p>The x matrix has been standardized to have unit L2 norm in each column and
zero mean. The matrix x2 consists of x plus certain interactions.
</p>


<h3>Source</h3>

<p><a href="https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf">https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf</a>
</p>


<h3>References</h3>

<p>Efron, Hastie, Johnstone and Tibshirani (2003) &quot;Least Angle
Regression&quot; (with discussion) <em>Annals of Statistics</em>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
