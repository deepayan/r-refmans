<!DOCTYPE html><html><head><title>Help for package Compositional</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Compositional}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Aitchison's test for two mean vectors and/or covariance matrices'>
<p>Aitchison's test for two mean vectors and/or covariance matrices</p></a></li>
<li><a href='#All pairwise additive log-ratio transformations'>
<p>All pairwise additive log-ratio transformations</p></a></li>
<li><a href='#Alpha-generalised correlations between two compositional datasets'>
<p><code class="reqn">\alpha</code>-generalised correlations between two compositional datasets</p></a></li>
<li><a href='#ANOVA for the log-contrast GLM versus the uncostrained GLM'>
<p>ANOVA for the log-contrast GLM versus the uncostrained GLM</p></a></li>
<li><a href='#ANOVA for the log-contrast regression versus the uncostrained linear regression'>
<p>ANOVA for the log-contrast regression versus the uncostrained linear regression</p></a></li>
<li><a href='#Bayesian network learning with compositional data'>
<p>Bayesian network learning with compositional data</p></a></li>
<li><a href='#Beta regression'>
<p>Beta regression</p></a></li>
<li><a href='#Column-wise MLE of some univariate distributions'>
<p>Column-wise MLE of some univariate distributions</p></a></li>
<li><a href='#Compositional-package'>
<p>Compositional Data Analysis</p></a></li>
<li><a href='#Constrained linear least squares for compositional responses and predictors'>
<p>Constrained linear least squares for compositional responses and predictors</p></a></li>
<li><a href='#Contour plot of mixtures of Dirichlet distributions in S^2'>
<p>Contour plot of mixtures of Dirichlet distributions in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the alpha multivariate normal in S^2'>
<p>Contour plot of the <code class="reqn">\alpha</code> multivariate normal in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the alpha-folded model in S^2'>
<p>Contour plot of the <code class="reqn">\alpha</code>-folded model in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the Dirichlet distribution in S^2'>
<p>Contour plot of the Dirichlet distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the Flexible Dirichlet distribution in S^2'>
<p>Contour plot of the Flexible Dirichlet distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the Gaussian mixture model in S^2'>
<p>Contour plot of the Gaussian mixture model in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the generalised Dirichlet distribution in S^2'>
<p>Contour plot of the generalised Dirichlet distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the Kent distribution in S^2'>
<p>Contour plot of the Kent distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the kernel density estimate in S^2'>
<p>Contour plot of the kernel density estimate in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the normal distribution in S^2'>
<p>Contour plot of the normal distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the skew skew-normal distribution in S^2'>
<p>Contour plot of the skew skew-normal distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Contour plot of the t distribution in S^2'>
<p>Contour plot of the t distribution in <code class="reqn">S^2</code></p></a></li>
<li><a href='#Cross validation for some compositional regression models'>
<p>Cross validation for some compositional regression models</p></a></li>
<li><a href='#Cross validation for the alpha-k-NN regression with compositional predictor variables'>
<p>Cross validation for the <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables</p></a></li>
<li><a href='#Cross validation for the alpha-k-NN regression with compositional response data'>
<p>Cross validation for the <code class="reqn">\alpha</code>-k-NN regression with compositional response data</p></a></li>
<li><a href='#Cross validation for the alpha-kernel regression with compositional response data'>
<p>Cross validation for the <code class="reqn">\alpha</code>-kernel regression with compositional response data</p></a></li>
<li><a href='#Cross validation for the kernel regression with Euclidean response data'>
<p>Cross validation for the kernel regression with Euclidean response data</p></a></li>
<li><a href='#Cross validation for the regularised and flexible discriminant analysis with compositional data using the alpha-transformation'>
<p>Cross validation for the regularised and flexible discriminant analysis with compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Cross validation for the ridge regression'>
<p>Cross validation for the ridge regression</p></a></li>
<li><a href='#Cross validation for the ridge regression with compositional data as predictor using the alpha-transformation'>
<p>Cross validation for the ridge regression with compositional data as predictor using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Cross validation for the transformation-free linear regression for compositional responses and predictors'>
<p>Cross validation for the transformation-free linear regression for compositional</p>
responses and predictors</a></li>
<li><a href='#Cross-validation for the constrained linear least squares for compositional responses and predictors'>
<p>Cross-validation for the constrained linear least squares for compositional</p>
responses and predictors</a></li>
<li><a href='#Cross-validation for the Dirichlet discriminant analysis'>
<p>Cross-validation for the Dirichlet discriminant analysis</p></a></li>
<li><a href='#Cross-validation for the LASSO Kullback-Leibler divergence based regression'>
<p>Cross-validation for the LASSO Kullback-Leibler divergence based regression</p></a></li>
<li><a href='#Cross-validation for the LASSO log-ratio regression with compositional response'>
<p>Cross-validation for the LASSO log-ratio regression with compositional response</p></a></li>
<li><a href='#Cross-validation for the naive Bayes classifiers for compositional data'>
<p>Cross-validation for the naive Bayes classifiers for compositional data</p></a></li>
<li><a href='#Cross-validation for the naive Bayes classifiers for compositional data using the alpha-transformation'>
<p>Cross-validation for the naive Bayes classifiers for compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Density of compositional data from Gaussian mixture models'>
<p>Simulation of compositional data from Gaussian mixture models</p></a></li>
<li><a href='#Density of the Flexible Dirichlet distribution'>
<p>Density of the Flexible Dirichlet distribution</p></a></li>
<li><a href='#Density of the folded normal distribution'>
<p>Density of the folded model normal distribution</p></a></li>
<li><a href='#Density values of a Dirichlet distribution'>
<p>Density values of a Dirichlet distribution</p></a></li>
<li><a href='#Density values of a generalised Dirichlet distribution'>
<p>Density values of a generalised Dirichlet distribution</p></a></li>
<li><a href='#Density values of a mixture of Dirichlet distributions'>
<p>Density values of a mixture of Dirichlet distributions</p></a></li>
<li><a href='#Dirichlet discriminant analysis'>
<p>Dirichlet discriminant analysis</p></a></li>
<li><a href='#Dirichlet random values simulation'>
<p>Dirichlet random values simulation</p></a></li>
<li><a href='#Dirichlet regression'>
<p>Dirichlet regression</p></a></li>
<li><a href='#Distance based regression models for proportions'>
<p>Distance based regression models for proportions</p></a></li>
<li><a href='#Divergence based regression for compositional data'>
<p>Divergence based regression for compositional data</p></a></li>
<li><a href='#Divergence based regression for compositional data with compositional data in the covariates side using the alpha-transformation'>
<p>Divergence based regression for compositional data with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Divergence matrix of compositional data'>
<p>Divergence matrix of compositional data</p></a></li>
<li><a href='#Energy test of equality of distributions using the alpha-transformation'>
<p>Energy test of equality of distributions using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Estimating location and scatter parameters for compositional data'>
<p>Estimating location and scatter parameters for compositional data</p></a></li>
<li><a href='#Estimation of the probability left outside the simplex when using the alpha-transformation'>
<p>Estimation of the probability left outside the simplex when using the alpha-transformation</p></a></li>
<li><a href='#Estimation of the value of alpha in the folded model'>
<p>Estimation of the value of <code class="reqn">\alpha</code> in the folded model</p></a></li>
<li><a href='#Estimation of the value of alpha via the profile log-likelihood'>
<p>Estimation of the value of <code class="reqn">\alpha</code> via the alfa profile log-likelihood</p></a></li>
<li><a href='#Fast estimation of the value of alpha'>
<p>Fast estimation of the value of <code class="reqn">\alpha</code></p></a></li>
<li><a href='#Fitting a Flexible Dirichlet distribution'>
<p>Fitting a Flexible Dirichlet distribution</p></a></li>
<li><a href='#Gaussian mixture models for compositional data'>
<p>Gaussian mixture models for compositional data</p></a></li>
<li><a href='#Gaussian mixture models for compositional data using the alpha-transformation'>
<p>Gaussian mixture models for compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Generalised Dirichlet random values simulation'>
<p>Generalised Dirichlet random values simulation</p></a></li>
<li><a href='#Generate random folds for cross-validation'>
<p>Generate random folds for cross-validation</p></a></li>
<li><a href='#Greenacre's power transformation'>
<p>Greenacre's power transformation</p></a></li>
<li><a href='#Helper Frechet mean for compositional data'>
<p>Helper Frechet mean for compositional data</p></a></li>
<li><a href='#Helper functions for the Kullback-Leibler regression'>
<p>Helper functions for the Kullback-Leibler regression</p></a></li>
<li><a href='#Hypothesis testing for two or more compositional mean vectors'>
<p>Hypothesis testing for two or more compositional mean vectors</p></a></li>
<li><a href='#ICE plot for projection pursuit regression with compositional predictor variables'>
<p>ICE plot for projection pursuit regression with compositional predictor variables</p></a></li>
<li><a href='#ICE plot for the alpha-k-NN regression'>
<p>ICE plot for the <code class="reqn">\alpha-k-NN</code> regression</p></a></li>
<li><a href='#ICE plot for the alpha-kernel regression'>
<p>ICE plot for the <code class="reqn">\alpha</code>-kernel regression</p></a></li>
<li><a href='#ICE plot for univariate kernel regression'>
<p>ICE plot for univariate kernel regression</p></a></li>
<li><a href='#Inverse of the alpha-transformation'>
<p>Inverse of the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Kernel regression with a numerical response vector or matrix'>
<p>Kernel regression with a numerical response vector or matrix</p></a></li>
<li><a href='#Kullback-Leibler divergence and Bhattacharyya distance between two Dirichlet distributions'>
<p>Kullback-Leibler divergence and Bhattacharyya distance between two Dirichlet distributions</p></a></li>
<li><a href='#LASSO Kullback-Leibler divergence based regression'>
<p>LASSO Kullback-Leibler divergence based regression</p></a></li>
<li><a href='#LASSO log-ratio regression with compositional response'>
<p>LASSO log-ratio regression with compositional response</p></a></li>
<li><a href='#Log-contrast GLMs with compositional predictor variables'>
<p>Log-contrast GLMS with compositional predictor variables</p></a></li>
<li><a href='#Log-contrast logistic or Poisson regression with with multiple compositional predictors'>
<p>Log-contrast logistic or Poisson regression with with multiple compositional predictors</p></a></li>
<li><a href='#Log-contrast regression with compositional predictor variables'>
<p>Log-contrast regression with compositional predictor variables</p></a></li>
<li><a href='#Log-contrast regression with multiple compositional predictors'>
<p>Log-contrast regression with multiple compositional predictors</p></a></li>
<li><a href='#Log-likelihood ratio test for a Dirichlet mean vector'>
<p>Log-likelihood ratio test for a Dirichlet mean vector</p></a></li>
<li><a href='#Log-likelihood ratio test for a symmetric Dirichlet distribution'>
<p>Log-likelihood ratio test for a symmetric Dirichlet distribution</p></a></li>
<li><a href='#Minimized Kullback-Leibler divergence between Dirichlet and logistic normal'>
<p>Minimized Kullback-Leibler divergence between Dirichlet and logistic normal</p></a></li>
<li><a href='#Mixture model selection via BIC'>
<p>Mixture model selection via BIC</p></a></li>
<li><a href='#Mixture model selection with the alpha-transformation using BIC'>
<p>Mixture model selection with the <code class="reqn">\alpha</code>-transformation using BIC</p></a></li>
<li><a href='#MLE for the multivariate t distribution'>
<p>MLE for the multivariate t distribution</p></a></li>
<li><a href='#MLE of distributions defined in the (0, 1) interval'>
<p>MLE of distributions defined in the (0, 1) interval</p></a></li>
<li><a href='#MLE of the Dirichlet distribution'>
<p>MLE of the a Dirichlet distribution</p></a></li>
<li><a href='#MLE of the Dirichlet distribution via Newton-Rapshon'>
<p>MLE of the Dirichlet distribution via Newton-Rapshon</p></a></li>
<li><a href='#MLE of the folded model for a given value of alpha'>
<p>MLE of the folded model for a given value of <code class="reqn">\alpha</code></p></a></li>
<li><a href='#MLE of the zero adjusted Dirichlet distribution'>
<p>MLE of the zero adjusted Dirichlet distribution</p></a></li>
<li><a href='#Multivariate kernel density estimation'>
<p>Multivariate kernel density estimation</p></a></li>
<li><a href='#Multivariate kernel density estimation for compositional data'>
<p>Multivariate kernel density estimation for compositional data</p></a></li>
<li><a href='#Multivariate linear regression'>
<p>Multivariate linear regression</p></a></li>
<li><a href='#Multivariate normal random values simulation on the simplex'>
<p>Multivariate normal random values simulation on the simplex</p></a></li>
<li><a href='#Multivariate or univariate regression with compositional data in the covariates side using the alpha-transformation'>
<p>Multivariate or univariate regression with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Multivariate regression with compositional data'>
<p>Multivariate regression with compositional data</p></a></li>
<li><a href='#Multivariate skew normal random values simulation on the simplex'>
<p>Multivariate skew normal random values simulation on the simplex</p></a></li>
<li><a href='#Multivariate t random values simulation on the simplex'>
<p>Multivariate t random values simulation on the simplex</p></a></li>
<li><a href='#Naive Bayes classifiers for compositional data'>
<p>Naive Bayes classifiers for compositional data</p></a></li>
<li><a href='#Naive Bayes classifiers for compositional data using the alpha-transformation'>
<p>Naive Bayes classifiers for compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Non linear least squares regression for compositional data'>
<p>Non linear least squares regression for compositional data</p></a></li>
<li><a href='#Non-parametric zero replacement strategies'>
<p>Non-parametric zero replacement strategies</p></a></li>
<li><a href='#Permutation independence test in the constrained linear least squares for compositional responses and predictors'>
<p>Permutation independence test in the constrained linear least squares for compositional responses and predictors</p></a></li>
<li><a href='#Perturbation operation'>
<p>Perturbation operation</p></a></li>
<li><a href='#Plot of the LASSO coefficients'>
<p>Plot of the LASSO coefficients</p></a></li>
<li><a href='#Power operation'>
<p>Power operation</p></a></li>
<li><a href='#Principal component analysis'>
<p>Principal component analysis</p></a></li>
<li><a href='#Principal component analysis using the alpha-transformation'>
<p>Principal component analysis using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Principal component generalised linear models'>
<p>Principal component generalised linear models</p></a></li>
<li><a href='#Principal coordinate analysis using the alpha-distance'>
<p>Principal coordinate analysis using the <code class="reqn">\alpha</code>-distance</p></a></li>
<li><a href='#Principal coordinate analysis using the Jensen-Shannon divergence'>
<p>Principal coordinate analysis using the Jensen-Shannon divergence</p></a></li>
<li><a href='#Projection pursuit regression for compositional data'>
<p>Projection pursuit regression for compositional data</p></a></li>
<li><a href='#Projection pursuit regression with compositional predictor variables'>
<p>Projection pursuit regression with compositional predictor variables</p></a></li>
<li><a href='#Projection pursuit regression with compositional predictor variables using the alpha-transformation'>
<p>Projection pursuit regression with compositional predictor variables using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Projections based test for distributional equality of two groups'>
<p>Projections based test for distributional equality of two groups</p></a></li>
<li><a href='#Proportionality correlation coefficient matrix'>
<p>Proportionality correlation coefficient matrix</p></a></li>
<li><a href='#Quasi binomial regression for proportions'>
<p>Quasi binomial regression for proportions</p></a></li>
<li><a href='#Random values generation from some univariate distributions defined on the (0,1) interval'>
<p>Random values generation from some univariate distributions defined on the <code class="reqn">(0,1)</code> interval</p></a></li>
<li><a href='#Regression with compositional data using the alpha-transformation'>
<p>Regression with compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Regularised and flexible discriminant analysis for compositional data using the alpha-transformation'>
<p>Regularised and flexible discriminant analysis for compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Ridge regression'>
<p>Ridge regression</p></a></li>
<li><a href='#Ridge regression plot'>
<p>Ridge regression plot</p></a></li>
<li><a href='#Ridge regression with compositional data in the covariates side using the alpha-transformation'>
<p>Ridge regression with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Ridge regression with the alpha-transformation plot'>
<p>Ridge regression plot</p></a></li>
<li><a href='#Simulation of compositional data from Gaussian mixture models'>
<p>Simulation of compositional data from Gaussian mixture models</p></a></li>
<li><a href='#Simulation of compositional data from mixtures of Dirichlet distributions'>
<p>Simulation of compositional data from mixtures of Dirichlet distributions</p></a></li>
<li><a href='#Simulation of compositional data from the Flexible Dirichlet distribution'>
<p>Simulation of compositional data from the Flexible Dirichlet distribution</p></a></li>
<li><a href='#Simulation of compositional data from the folded normal distribution'>
<p>Simulation of compositional data from the folded model normal distribution</p></a></li>
<li><a href='#Spatial median regression'>
<p>Spatial median regression</p></a></li>
<li><a href='#Ternary diagram'>
<p>Ternary diagram</p></a></li>
<li><a href='#Ternary diagram of regression models'>
<p>Ternary diagram of regression models</p></a></li>
<li><a href='#The additive log-ratio transformation and its inverse'>
<p>The additive log-ratio transformation and its inverse</p></a></li>
<li><a href='#The alpha-distance'>
<p>The <code class="reqn">\alpha</code>-distance</p></a></li>
<li><a href='#The alpha-IT transformation'>
<p>The <code class="reqn">\alpha</code>-IT transformation</p></a></li>
<li><a href='#The alpha-IT-distance'>
<p>The <code class="reqn">\alpha</code>-IT-distance</p></a></li>
<li><a href='#The alpha-k-NN regression for compositional response data'>
<p>The <code class="reqn">\alpha</code>-k-NN regression for compositional response data</p></a></li>
<li><a href='#The alpha-k-NN regression with compositional predictor variables'>
<p>The <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables</p></a></li>
<li><a href='#The alpha-kernel regression with compositional response data'>
<p>The <code class="reqn">\alpha</code>-kernel regression with compositional response data</p></a></li>
<li><a href='#The alpha-transformation'>
<p>The <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#The Box-Cox transformation applied to ratios of components'>
<p>The Box-Cox transformation applied to ratios of components</p></a></li>
<li><a href='#The ESOV-distance'>
<p>The ESOV-distance</p></a></li>
<li><a href='#The folded power transformation'>
<p>The folded power transformation</p></a></li>
<li><a href='#The Frechet mean for compositional data'>
<p>The Frechet mean for compositional data</p></a></li>
<li><a href='#The Helmert sub-matrix'>
<p>The Helmert sub-matrix</p></a></li>
<li><a href='#The k-nearest neighbours using the alpha-distance'>
<p>The k-nearest neighbours using the <code class="reqn">\alpha</code>-distance</p></a></li>
<li><a href='#The k-NN algorithm for compositional data'>
<p>The k-NN algorithm for compositional data</p></a></li>
<li><a href='#The multiplicative log-ratio transformation and its inverse'>
<p>The multiplicative log-ratio transformation and its inverse</p></a></li>
<li><a href='#The pivot coordinate transformation and its inverse'>
<p>The pivot coordinate transformation and its inverse</p></a></li>
<li><a href='#Total variability'>
<p>Total variability</p></a></li>
<li><a href='#Transformation-free linear regression for compositional responses and predictors'>
<p>Transformation-free linear regression for compositional responses and predictors</p></a></li>
<li><a href='#Tuning of the alpha-generalised correlations between two compositional datasets'>
<p>Tuning of the <code class="reqn">\alpha</code>-generalised correlations between two compositional datasets</p></a></li>
<li><a href='#Tuning of the bandwidth h of the kernel using the maximum likelihood cross validation'>
<p>Tuning of the bandwidth h of the kernel using the maximum likelihood cross validation</p></a></li>
<li><a href='#Tuning of the divergence based regression for compositional data with compositional data in the covariates side using the alpha-transformation'>
<p>Tuning of the divergence based regression for compositional data with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Tuning of the k-NN algorithm for compositional data'>
<p>Tuning of the k-NN algorithm for compositional data</p></a></li>
<li><a href='#Tuning of the projection pursuit regression for compositional data'>
<p>Tuning of the projection pursuit regression for compositional data</p></a></li>
<li><a href='#Tuning of the projection pursuit regression with compositional predictor variables'>
<p>Tuning of the projection pursuit regression with compositional predictor variables</p></a></li>
<li><a href='#Tuning of the projection pursuit regression with compositional predictor variables using the alpha-transformation'>
<p>Tuning of the projection pursuit regression with compositional predictor variables using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Tuning the number of PCs in the PCR with compositional data using the alpha-transformation'>
<p>Tuning the number of PCs in the PCR with compositional data using the <code class="reqn">\alpha</code>-transformation</p></a></li>
<li><a href='#Tuning the principal components with GLMs'>
<p>Tuning the principal components with GLMs</p></a></li>
<li><a href='#Tuning the value of alpha in the alpha-regression'>
<p>Tuning the value of <code class="reqn">\alpha</code> in the <code class="reqn">\alpha</code>-regression</p></a></li>
<li><a href='#Two-sample test of high-dimensional means for compositional data'>
<p>Two-sample test of high-dimensional means for compositional data</p></a></li>
<li><a href='#Unconstrained GLMs with compositional predictor variables'>
<p>Unconstrained GLMs with compositional predictor variables</p></a></li>
<li><a href='#Unconstrained linear regression with compositional predictor variables'>
<p>Unconstrained linear regression with compositional predictor variables</p></a></li>
<li><a href='#Unconstrained linear regression with multiple compositional predictors'>
<p>Unconstrained linear regression with multiple compositional predictors</p></a></li>
<li><a href='#Unconstrained logistic or Poisson regression with multiple compositional predictors'>
<p>Unconstrained logistic or Poisson regression with multiple compositional predictors</p></a></li>
<li><a href='#Unit-Weibull regression models for proportions'>
<p>Unit-Weibull regression models for proportions</p></a></li>
<li><a href='#Zero adjusted Dirichlet regression'>
<p>Zero adjusted Dirichlet regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Compositional Data Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>6.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Michail Tsagris [aut, cre],
  Giorgos Athineou [aut],
  Abdulaziz Alenazi [ctb],
  Christos Adam [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michail Tsagris &lt;mtsagris@uoc.gr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>codalm, Directional, doParallel, emplik, energy, foreach,
FlexDir, glmnet, graphics, grDevices, MASS, mda, mixture,
mvhtests, nnet, pchc, quadprog, regda, Rfast, Rfast2,
Rnanoflann, sn, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>Regression, classification, contour plots, hypothesis testing and fitting of distributions for compositional data are some of the functions included. We further include functions for percentages (or proportions).
             The standard textbook for such data is John Aitchison's (1986) "The statistical analysis of compositional data". Relevant papers include:
			       a) Tsagris M.T., Preston S. and Wood A.T.A. (2011). "A data-based power transformation for compositional data". Fourth International International Workshop on Compositional Data Analysis. 
			       b) Tsagris M. (2014). "The k-NN algorithm for compositional data: a revised approach with and without zero values present". Journal of Data Science, 12(3): 519&ndash;534. 
			       c) Tsagris M. (2015). "A novel, divergence based, regression for compositional data". Proceedings of the 28th Panhellenic Statistics Conference, 15-18 April 2015, Athens, Greece, 430&ndash;444. 
			       d) Tsagris M. (2015). "Regression analysis with compositional data containing zero values". Chilean Journal of Statistics, 6(2): 47&ndash;57. 
			       e) Tsagris M., Preston S. and Wood A.T.A. (2016). "Improved supervised classification for compositional data using the alpha-transformation". Journal of Classification, 33(2): 243&ndash;261. &lt;<a href="https://doi.org/10.1007%2Fs00357-016-9207-5">doi:10.1007/s00357-016-9207-5</a>&gt;. 
			       f) Tsagris M., Preston S. and Wood A.T.A. (2017). "Nonparametric hypothesis testing for equality of means on the simplex". Journal of Statistical Computation and Simulation, 87(2): 406&ndash;422. &lt;<a href="https://doi.org/10.1080%2F00949655.2016.1216554">doi:10.1080/00949655.2016.1216554</a>&gt;. 
			       g) Tsagris M. and Stewart C. (2018). "A Dirichlet regression model for compositional data with zeros". Lobachevskii Journal of Mathematics, 39(3): 398&ndash;412. &lt;<a href="https://doi.org/10.1134%2FS1995080218030198">doi:10.1134/S1995080218030198</a>&gt;. 
			       h) Alenazi A. (2019). "Regression for compositional data with compositional data as predictor variables with or without zero values". Journal of Data Science, 17(1): 219&ndash;238. &lt;<a href="https://doi.org/10.6339%2FJDS.201901_17%281%29.0010">doi:10.6339/JDS.201901_17(1).0010</a>&gt;. 
		         i) Tsagris M. and Stewart C. (2020). "A folded model for compositional data analysis". Australian and New Zealand Journal of Statistics, 62(2): 249&ndash;277. &lt;<a href="https://doi.org/10.1111%2Fanzs.12289">doi:10.1111/anzs.12289</a>&gt;. 
		         j) Alenazi A. (2021). Alenazi, A. (2023). "A review of compositional data analysis and recent advances". Communications in Statistics&ndash;Theory and Methods, 52(16): 5535&ndash;5567. &lt;<a href="https://doi.org/10.1080%2F03610926.2021.2014890">doi:10.1080/03610926.2021.2014890</a>&gt;.
		         k) Alenazi A.A. (2022). "f-divergence regression models for compositional data". Pakistan Journal of Statistics and Operation Research, 18(4): 867&ndash;882. &lt;<a href="https://doi.org/10.18187%2Fpjsor.v18i4.3969">doi:10.18187/pjsor.v18i4.3969</a>&gt;.
		         l) Tsagris M. and Stewart C. (2022). "A Review of Flexible Transformations for Modeling Compositional Data". In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234. &lt;<a href="https://doi.org/10.1007%2F978-3-031-08329-7_10">doi:10.1007/978-3-031-08329-7_10</a>&gt;.
			       m) Tsagris M., Alenazi A. and Stewart C. (2023). "Flexible non-parametric regression models for compositional response data with zeros". Statistics and Computing, 33(106). &lt;<a href="https://doi.org/10.1007%2Fs11222-023-10277-5">doi:10.1007/s11222-023-10277-5</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-29 10:20:00 UTC; mtsag</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-29 13:22:37 UTC</td>
</tr>
</table>
<hr>
<h2 id='Aitchison+27s+20test+20for+20two+20mean+20vectors+20and+2For+20covariance+20matrices'>
Aitchison's test for two mean vectors and/or covariance matrices
</h2><span id='topic+ait.test'></span>

<h3>Description</h3>

<p>Aitchison's test for two mean vectors and/or covariance matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ait.test(x1, x2, type = 1, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Aitchison+2B27s+2B20test+2B20for+2B20two+2B20mean+2B20vectors+2B20and+2B2For+2B20covariance+2B20matrices_+3A_x1">x1</code></td>
<td>

<p>A matrix containing the compositional data of the first sample.
Zeros are not allowed.
</p>
</td></tr>
<tr><td><code id="Aitchison+2B27s+2B20test+2B20for+2B20two+2B20mean+2B20vectors+2B20and+2B2For+2B20covariance+2B20matrices_+3A_x2">x2</code></td>
<td>

<p>A matrix containing the compositional data of the second sample.
Zeros are not allowed.
</p>
</td></tr>
<tr><td><code id="Aitchison+2B27s+2B20test+2B20for+2B20two+2B20mean+2B20vectors+2B20and+2B2For+2B20covariance+2B20matrices_+3A_type">type</code></td>
<td>

<p>The type of hypothesis test to perform.
Type=1 refers to testing the equality of the mean vectors and the covariance matrices.
Type=2 refers to testing the equality of the covariance matrices.
Type=2 refers to testing the equality of the mean vectors.
</p>
</td></tr>
<tr><td><code id="Aitchison+2B27s+2B20test+2B20for+2B20two+2B20mean+2B20vectors+2B20and+2B2For+2B20covariance+2B20matrices_+3A_alpha">alpha</code></td>
<td>

<p>The significance level, set to 0.05 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is described in Aitchison (2003). See the references for more information.
</p>


<h3>Value</h3>

<p>A vector with the test statistic, the p-value, the critical value and the
degrees of freedom of the chi-square distribution.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>John Aitchison (2003). The Statistical Analysis of Compositional Data, p. 153-157.
Blackburn Press.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+comp.test">comp.test</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- as.matrix(iris[1:50, 1:4])
x1 &lt;- x1 / rowSums(x1)
x2 &lt;- as.matrix(iris[51:100, 1:4])
x2 &lt;- x2 / rowSums(x2)
ait.test(x1, x2, type = 1)
ait.test(x1, x2, type = 2)
ait.test(x1, x2, type = 3)
</code></pre>

<hr>
<h2 id='All+20pairwise+20additive+20log-ratio+20transformations'>
All pairwise additive log-ratio transformations
</h2><span id='topic+alr.all'></span>

<h3>Description</h3>

<p>All pairwise additive log-ratio transformations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alr.all(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="All+2B20pairwise+2B20additive+2B20log-ratio+2B20transformations_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The additive log-ratio transformation with the first component being the commn divisor is applied. Then all the other pairwise log-ratios are computed and added next to each column. For example, divide by the first component, then divide by the second component and so on. This means that no zeros are allowed.
</p>


<h3>Value</h3>

<p>A matrix with all pairwise alr transformed data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alr">alr</a>, <a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 2:4])
x &lt;- x / rowSums(x)
y &lt;- alr.all(x)
</code></pre>

<hr>
<h2 id='Alpha-generalised+20correlations+20between+20two+20compositional+20datasets'>
<code class="reqn">\alpha</code>-generalised correlations between two compositional datasets
</h2><span id='topic+acor'></span>

<h3>Description</h3>

<p><code class="reqn">\alpha</code>-generalised correlations between two compositional datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acor(y, x, a, type = "dcor")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero
values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric
log-ratio transformation is applied. If more than one valuesare supplied the
distance or canonical correlation are computed for all values.
</p>
</td></tr>
<tr><td><code id="Alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_type">type</code></td>
<td>

<p>The type of correlation to compute, the distance correlation (&quot;edist&quot;),
the canonical correlation (&quot;cancor&quot;) or &quot;both&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to each composition and then the distance correlation
or the canonical correlation is computed. If one value of <code class="reqn">\alpha</code> is supplied the type=&quot;cancor&quot;
will return all eigenvalues. If more than one values of <code class="reqn">\alpha</code> are provided then the first
eigenvalue only will be returned.
</p>


<h3>Value</h3>

<p>A vector or a matrix depending on the length of the values of <code class="reqn">\alpha</code>
and the type of the correlation to be computed.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>G.J. Szekely, M.L. Rizzo and N. K. Bakirov (2007). Measuring and Testing
Independence by Correlation of Distances. Annals of Statistics, 35(6): 2769-2794.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power
transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acor.tune">acor.tune</a>, <a href="#topic+aeqdist.etest">aeqdist.etest</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfa.profile">alfa.profile</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rdiri(30, runif(3) )
x &lt;- rdiri(30, runif(4) )
acor(y, x, a = 0.4)
</code></pre>

<hr>
<h2 id='ANOVA+20for+20the+20log-contrast+20GLM+20versus+20the+20uncostrained+20GLM'>
ANOVA for the log-contrast GLM versus the uncostrained GLM
</h2><span id='topic+lcglm.aov'></span>

<h3>Description</h3>

<p>ANOVA for the log-contrast GLM versus the uncostrained GLM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcglm.aov(mod0, mod1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ANOVA+2B20for+2B20the+2B20log-contrast+2B20GLM+2B20versus+2B20the+2B20uncostrained+2B20GLM_+3A_mod0">mod0</code></td>
<td>

<p>The log-contrast GLM. The object returned by <code><a href="#topic+lc.glm">lc.glm</a></code>.
</p>
</td></tr>
<tr><td><code id="ANOVA+2B20for+2B20the+2B20log-contrast+2B20GLM+2B20versus+2B20the+2B20uncostrained+2B20GLM_+3A_mod1">mod1</code></td>
<td>

<p>The unconstrained GLM. The object returned by <code><a href="#topic+ulc.glm">ulc.glm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A chi-square test is performed to test the zero-to-sum constraints of the regression coefficients.
</p>


<h3>Value</h3>

<p>A vector with two values, the chi-square test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lc.glm">lc.glm</a>, <a href="#topic+ulc.glm">ulc.glm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(150, 1, 0.5)
x &lt;- as.matrix(iris[, 2:4])
x &lt;- x / rowSums(x)
mod0 &lt;- lc.glm(y, x)
mod1 &lt;- ulc.glm(y, x)
lcglm.aov(mod0, mod1)
</code></pre>

<hr>
<h2 id='ANOVA+20for+20the+20log-contrast+20regression+20versus+20the+20uncostrained+20linear+20regression'>
ANOVA for the log-contrast regression versus the uncostrained linear regression
</h2><span id='topic+lcreg.aov'></span>

<h3>Description</h3>

<p>ANOVA for the log-contrast regression versus the uncostrained linear regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcreg.aov(mod0, mod1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ANOVA+2B20for+2B20the+2B20log-contrast+2B20regression+2B20versus+2B20the+2B20uncostrained+2B20linear+2B20regression_+3A_mod0">mod0</code></td>
<td>

<p>The log-contrast regression model. The object returned by <code><a href="#topic+lc.reg">lc.reg</a></code>.
</p>
</td></tr>
<tr><td><code id="ANOVA+2B20for+2B20the+2B20log-contrast+2B20regression+2B20versus+2B20the+2B20uncostrained+2B20linear+2B20regression_+3A_mod1">mod1</code></td>
<td>

<p>The unconstrained linear regression model. The object returned by <code><a href="#topic+ulc.reg">ulc.reg</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An F-test is performed to test the zero-to-sum constraints of the regression coefficients.
</p>


<h3>Value</h3>

<p>A vector with two values, the F test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lc.reg">lc.reg</a>, <a href="#topic+ulc.reg">ulc.reg</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.knn.reg">alfa.knn.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- as.matrix(iris[, 2:4])
x &lt;- x / rowSums(x)
mod0 &lt;- lc.reg(y, x)
mod1 &lt;- ulc.reg(y, x)
lcreg.aov(mod0, mod1)
</code></pre>

<hr>
<h2 id='Bayesian+20network+20learning+20with+20compositional+20data'>
Bayesian network learning with compositional data
</h2><span id='topic+compbn'></span>

<h3>Description</h3>

<p>Bayesian network learning with compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compbn(x, type = "fedhc", max_k = 3, alpha = 0.05, robust = FALSE,
ini.stat = NULL, R = NULL, restart = 10, tabu = 10, score = "bic-g",
blacklist = NULL, whitelist = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data. They can be either the logged compositional or the 
centred log-ratio transformed compositional data. We leave this open to the user.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>This can be either &quot;fedhc&quot;, &quot;pchc&quot;, &quot;mmhc&quot;, &quot;fedtabu&quot;, &quot;pctabu&quot; or &quot;mmtabu&quot;.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_max_k">max_k</code></td>
<td>

<p>The maximum conditioning set to use in the conditional indepedence test (see Details). 
Integer, default value is 3
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_alpha">alpha</code></td>
<td>

<p>The significance level for assessing the p-values.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_robust">robust</code></td>
<td>

<p>Do you want outliers to be removed prior to applying the algorithms? If yes, set this to TRUE to u
tilise the MCD.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_ini.stat">ini.stat</code></td>
<td>

<p>If the initial test statistics (univariate associations) are available, pass them through this parameter.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_r">R</code></td>
<td>

<p>If the correlation matrix is available, pass it here.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_restart">restart</code></td>
<td>

<p>An integer, the number of random restarts.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_tabu">tabu</code></td>
<td>

<p>An integer, the length of the tabu list used in the tabu function.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_score">score</code></td>
<td>

<p>A character string, the label of the network score to be used in the algorithm. If none is specified,
the default score is the Bayesian Information Criterion. Other available scores are: &quot;bic-g&quot; (default), 
&quot;loglik-g&quot;, &quot;aic-g&quot;, &quot;bic-g&quot; or &quot;bge&quot;.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_blacklist">blacklist</code></td>
<td>

<p>A data frame with two columns (optionally labeled &quot;from&quot; and &quot;to&quot;), containing a set of arcs not to
be included in the graph.
</p>
</td></tr>
<tr><td><code id="Bayesian+2B20network+2B20learning+2B20with+2B20compositional+2B20data_+3A_whitelist">whitelist</code></td>
<td>

<p>A data frame with two columns (optionally labeled &quot;from&quot; and &quot;to&quot;), containing a set of arcs to be
included in the graph.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The FEDHC algorithm is implemented. The FBED algortihm (Borboudakis and Tsamardinos, 2019), without 
the backward phase, is implemented during the skeleton identification phase. Next, the Hill Climbing 
greedy search or the Tabu search is employed to score the network.
</p>
<p>The PC algorithm as proposed by Spirtes et al. (2001) is first implemented followed by a scoring phase, 
such as hill climbing or tabu search. The PCHC was proposed by Tsagris (2021), while the PCTABU algorithm 
is the same but instead of the hill climbing scoring phase, the tabu search is employed.
</p>
<p>The MMHC algorithm is implemented without performing the backward elimination during the skeleton 
identification phase. The MMHC as described in Tsamardinos et al. (2006) employs the MMPC algorithm 
during the skeleton construction phase and the Tabu search in the scoring phase. In this package, 
the mmhc function employs the Hill Climbing greedy search in the scoring phase while the mmtabu 
employs the Tabu search.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>ini</code></td>
<td>

<p>A list including the output of the <code> mmhc.skel </code> function.
</p>
</td></tr>
<tr><td><code>dag</code></td>
<td>

<p>A &quot;bn&quot; class output. A list including the outcome of the Hill-Climbing or the Tabu search phase. 
See the package &quot;bnlearn&quot; for more details.
</p>
</td></tr>
<tr><td><code>scoring</code></td>
<td>

<p>The score value.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The duration of the algorithm.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. (2021). A new scalable Bayesian network learning algorithm with applications to economics. 
Computational Economics, 57(1):341-367.
</p>
<p>Tsagris M. (2021). The FEDHC Bayesian network learning algorithm. https://arxiv.org/pdf/2012.00113.pdf.
</p>
<p>Borboudakis G. and Tsamardinos I. (2019). Forward-backward selection with early dropping. 
Journal of Machine Learning Research, 20(8): 1-39.
</p>
<p>Tsamardinos I., Brown E.L. and Aliferis F.C. (2006). The max-min hill-climbing Bayesian network structure 
learning algorithm. Machine Learning, 65(1): 31-78.
</p>
<p>Spirtes P.,  Glymour C. and Scheines R. (2001). Causation, Prediction, and Search. 
The MIT Press, Cambridge, MA, USA, 3nd edition.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+acor">acor</a>, <a href="#topic+alr">alr</a>, <a href="#topic+alfa">alfa</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate a dataset with continuous data
x &lt;- rdiri( 100, runif(20) )
a &lt;- compbn( log(x) )
</code></pre>

<hr>
<h2 id='Beta+20regression'>
Beta regression
</h2><span id='topic+beta.reg'></span>

<h3>Description</h3>

<p>Beta regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta.reg(y, x, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta+2B20regression_+3A_y">y</code></td>
<td>

<p>The response variable. It must be a numerical vector with proportions excluding 0 and 1.
</p>
</td></tr>
<tr><td><code id="Beta+2B20regression_+3A_x">x</code></td>
<td>

<p>The indendent variable(s). It can be a vector, a matrix or a dataframe with continuous only variables,
a data frame with mixed or only categorical variables.
</p>
</td></tr>
<tr><td><code id="Beta+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new values for the predictor variables (dataset) whose response values you want to predict insert them here.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Beta regression is fitted.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>phi</code></td>
<td>

<p>The estimated precision parameter.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A matrix with the estimated regression parameters, their standard errors, Wald statistics and associated p-values.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood of the regression model.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated values if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ferrari S.L.P. and Cribari-Neto F. (2004). Beta Regression for Modelling Rates and Proportions.
Journal of Applied Statistics, 31(7): 799-815.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+beta.est">beta.est</a>, prop.reg, <a href="#topic+diri.reg">diri.reg</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbeta(300, 3, 5)
x &lt;- matrix( rnorm(300 * 2), ncol = 2)
beta.reg(y, x)
</code></pre>

<hr>
<h2 id='Column-wise+20MLE+20of+20some+20univariate+20distributions'>
Column-wise MLE of some univariate distributions
</h2><span id='topic+colbeta.est'></span><span id='topic+collogitnorm.est'></span><span id='topic+colunitweibull.est'></span><span id='topic+colzilogitnorm.est'></span>

<h3>Description</h3>

<p>Column-wise MLE of some univariate distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colbeta.est(x, tol = 1e-07, maxiters = 100, parallel = FALSE)
collogitnorm.est(x)
colunitweibull.est(x, tol = 1e-07, maxiters = 100, parallel = FALSE)
colzilogitnorm.est(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_x">x</code></td>
<td>

<p>A numerical matrix with data. Each column refers to a different vector of observations of the same distribution. The values must by percentages, exluding 0 and 1,
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Fisher algorithm.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations to implement.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to calculations to take place in parallel? The default value is FALSE
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each column, the same distribution is fitted and its parameters and log-likelihood are computed.
</p>


<h3>Value</h3>

<p>A matrix with two, three or four columns. The first one, two or three columns contain the parameter(s) of the distribution, while the last column contains the relevant log-likelihood.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>N.L. Johnson, S. Kotz &amp; N. Balakrishnan (1994). Continuous Univariate Distributions, Volume 1 (2nd Edition).
</p>
<p>N.L. Johnson, S. Kotz &amp; N. Balakrishnan (1970). Distributions in statistics: continuous univariate distributions,
Volume 2.
</p>
<p>J. Mazucheli, A. F. B. Menezes, L. B. Fernandes, R. P. de Oliveira &amp; M. E. Ghitany (2020).
The unit-Weibull distribution as an alternative to the Kumaraswamy distribution for the modeling of
quantiles conditional on covariates. Journal of Applied Statistics, DOI:10.1080/02664763.2019.1657813.
</p>


<h3>See Also</h3>

<p><code>censpois.mle, gammapois.mle
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rbeta(200, 3, 4), ncol = 4 )
a &lt;- colbeta.est(x)
</code></pre>

<hr>
<h2 id='Compositional-package'>
Compositional Data Analysis
</h2><span id='topic+Compositional-package'></span>

<h3>Description</h3>

<p>A Collection of Functions for Compositional Data Analysis.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Compositional</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 6.7 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-02-29</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Maintainers</h3>

<p>Michail Tsagris &lt;mtsagris@uoc.gr&gt;
</p>


<h3>Note</h3>

<p>Acknowledgments:
</p>
<p>Michail Tsagris would like to express his acknowledgments to Professor Andy Wood and Professor Simon
Preston from the university of Nottingham for being his supervisors during his PhD in compositional data analysis.
</p>
<p>We would also like to express our acknowledgments to Profesor Kurt Hornik (and also the rest of the R core team)
for his help with this package.
</p>
<p>Manos Papadakis, undergraduate student in the department of computer science, university of Crete, is also acknowledged for his programming tips.
</p>
<p>Ermanno Affuso from the university of South Alabama suggested that I have a default value in the function <code><a href="#topic+mkde">mkde</a></code>.
</p>
<p>Van Thang Hoang from Hasselt university spotted a bug in the function <code><a href="#topic+js.compreg">js.compreg</a></code>.
</p>
<p>Claudia Wehrhahn Cortes spotted a bug in the function <code><a href="#topic+diri.reg">diri.reg</a></code>.
</p>
<p>Philipp Kynast from Bruker Daltonik GmbH found a mistake in the function <code><a href="#topic+mkde">mkde</a></code> which is now fixed.
</p>
<p>Jasmine Heyse from the university of Ghent spotted a bug in the function <code><a href="#topic+kl.compreg">kl.compreg</a></code> which is now fixed.
</p>
<p>Magne Neby suggested to add names in the covariance matrix of the divergence based regression models.
</p>
<p>John Barry from the Centre for Environment, Fisheries, and Aquaculture Science (UK) suggested that I should add more explanation in the function <code><a href="#topic+diri.est">diri.est</a></code>. I hope it is clearer now.
</p>
<p>Charlotte Fabri and Laura Byrne spotted a possible problem in the function <code><a href="#topic+zadr">zadr</a></code>.
</p>
<p>Levi Bankston found a bug in the bootstrap version of the function <code><a href="#topic+kl.compreg">kl.compreg</a></code>.
</p>
<p>Sucharitha Dodamgodage suggested to add an extra case in the function <code><a href="#topic+dirimean.test">dirimean.test</a></code>.
</p>
<p>Loic Mangnier found a bug in the function <code><a href="#topic+lc.glm">lc.glm</a></code> which is now fixed and also became faster.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>, Giorgos Athineou &lt;gioathineou@gmail.com&gt;,
Abdulaziz Alenazi &lt;a.alenazi@nbu.edu.sa&gt; and Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>

<hr>
<h2 id='Constrained+20linear+20least+20squares+20for+20compositional+20responses+20and+20predictors'>
Constrained linear least squares for compositional responses and predictors
</h2><span id='topic+ols.compcomp'></span>

<h3>Description</h3>

<p>Constrained linear least squares for compositional responses and predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols.compcomp(y, x, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional predictors. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs least squares regression where the beta coefficients are constained to be positive and sum to 1. We were inspired by the transformation-free linear regression for compositional responses and predictors of Fiksel, Zeger and Datta (2020). Our implementation now uses quadratic programming instead of the function <code><a href="stats.html#topic+optim">optim</a></code>, and the solution is more accurate and extremely fast.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mse</code></td>
<td>

<p>The mean squared errors.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.olscompcomp">cv.olscompcomp</a>, <a href="#topic+tflr">tflr</a>, <a href="#topic+kl.alfapcr">kl.alfapcr</a>  </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
set.seed(1234)
y &lt;- rdiri(214, runif(4, 1, 3))
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
mod &lt;- ols.compcomp(y, x)
mod
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20mixtures+20of+20Dirichlet+20distributions+20in+20S+5E2'>
Contour plot of mixtures of Dirichlet distributions in <code class="reqn">S^2</code>
</h2><span id='topic+mixdiri.contour'></span>

<h3>Description</h3>

<p>Contour plot of mixtures of Dirichlet distributions in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixdiri.contour(a, prob, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions+2B20in+2B20S+2B5E2_+3A_a">a</code></td>
<td>

<p>A matrix where each row contains the parameters of each Dirichlet disctribution.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions+2B20in+2B20S+2B5E2_+3A_prob">prob</code></td>
<td>

<p>A vector with the mixing probabilities.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can plot only the contour lines of a Dirichlet with a given vector of parameters,
or can also add the relevant data should he/she wish to.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points and the Dirichlet contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions:
Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+gendiri.contour">gendiri.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>,
<a href="#topic+comp.kerncontour">comp.kerncontour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>,
<a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+dda">dda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix( c(12, 30, 45, 32, 50, 16), byrow = TRUE,ncol = 3)
prob &lt;- c(0.5, 0.5)
mixdiri.contour(a, prob)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20alpha+20multivariate+20normal+20in+20S+5E2'>
Contour plot of the <code class="reqn">\alpha</code> multivariate normal in <code class="reqn">S^2</code>
</h2><span id='topic+alfa.contour'></span>

<h3>Description</h3>

<p>Contour plot of the <code class="reqn">\alpha</code> multivariate normal in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.contour(m, s, a, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha+2B20multivariate+2B20normal+2B20in+2B20S+2B5E2_+3A_m">m</code></td>
<td>

<p>The mean vector of the <code class="reqn">\alpha</code> multivariate normal model.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha+2B20multivariate+2B20normal+2B20in+2B20S+2B5E2_+3A_s">s</code></td>
<td>

<p>The covariance matrix of the <code class="reqn">\alpha</code> multivariate normal model.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha+2B20multivariate+2B20normal+2B20in+2B20S+2B5E2_+3A_a">a</code></td>
<td>

<p>The value of a for the <code class="reqn">\alpha</code>-transformation.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha+2B20multivariate+2B20normal+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha+2B20multivariate+2B20normal+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha+2B20multivariate+2B20normal+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data and then for a grid of points within the 2-dimensional simplex, the density of the <code class="reqn">\alpha</code> multivariate normal is calculated and the contours are plotted.
</p>


<h3>Value</h3>

<p>The contour plot of the <code class="reqn">\alpha</code> multivariate normal appears.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2022). A Review of Flexible Transformations for Modeling Compositional Data. 
In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234.
https://link.springer.com/chapter/10.1007/978-3-031-08329-7_10
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+folded.contour">folded.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+skewnorm.contour">skewnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
a &lt;- a.est(x)$best
m &lt;- colMeans(alfa(x, a)$aff)
s &lt;- cov(alfa(x, a)$aff)
alfa.contour(m, s, a)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20alpha-folded+20model+20in+20S+5E2'>
Contour plot of the <code class="reqn">\alpha</code>-folded model in <code class="reqn">S^2</code>
</h2><span id='topic+folded.contour'></span>

<h3>Description</h3>

<p>Contour plot of the <code class="reqn">\alpha</code>-folded model in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>folded.contour(mu, su, p, a, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_mu">mu</code></td>
<td>

<p>The mean vector of the folded model.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_su">su</code></td>
<td>

<p>The covariance matrix of the folded model.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_p">p</code></td>
<td>

<p>The probability inside the simplex of the folded model.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_a">a</code></td>
<td>

<p>The value of a for the <code class="reqn">\alpha</code>-transformation.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20alpha-folded+2B20model+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data and then for a grid
of points within the 2-dimensional simplex the folded model's density is calculated and
the contours are plotted.
</p>


<h3>Value</h3>

<p>The contour plot of the folded model appears.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2022). A Review of Flexible Transformations for Modeling Compositional Data. In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234.
https://link.springer.com/chapter/10.1007/978-3-031-08329-7_10
</p>
<p>Tsagris M. and Stewart C. (2020). A folded model for compositional data analysis.
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.contour">alfa.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>,
<a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+skewnorm.contour">skewnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
a &lt;- a.est(x)$best
mod &lt;- alpha.mle(x, a)
folded.contour(mod$mu, mod$su, mod$p, a)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20Dirichlet+20distribution+20in+20S+5E2'>
Contour plot of the Dirichlet distribution in <code class="reqn">S^2</code>
</h2><span id='topic+diri.contour'></span>

<h3>Description</h3>

<p>Contour plot of the Dirichlet distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diri.contour(a, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_a">a</code></td>
<td>

<p>A vector with three elements corresponding to the 3 (estimated) parameters.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with
compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can plot only the contour lines of a Dirichlet with a given
vector of parameters,
or can also add the relevant data should he/she wish to.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points and the Dirichlet contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and
related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data.
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+mixdiri.contour">mixdiri.contour</a>, <a href="#topic+gendiri.contour">gendiri.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>,
<a href="#topic+comp.kerncontour">comp.kerncontour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 1:3] )
x &lt;- x / rowSums(x)
diri.contour( a = c(3, 4, 2) )
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20Flexible+20Dirichlet+20distribution+20in+20S+5E2'>
Contour plot of the Flexible Dirichlet distribution in <code class="reqn">S^2</code>
</h2><span id='topic+fd.contour'></span>

<h3>Description</h3>

<p>Contour plot of the Flexible Dirichlet distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fd.contour(alpha, prob, tau, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_alpha">alpha</code></td>
<td>

<p>A vector of the non-negative <code class="reqn">\alpha</code> parameters.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_prob">prob</code></td>
<td>

<p>A vector of the clusters' probabilities. It must sum to one.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_tau">tau</code></td>
<td>

<p>The non-negative scalar <code class="reqn">tau</code> parameter.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can plot only the contour lines of a Dirichlet with a given vector of parameters,
or can also add the relevant data should they wish to.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points and the Flexible Dirichlet contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Ongaro A. and Migliorati S. (2013). A generalization of the Dirichlet distribution.
Journal of Multivariate Analysis, 114, 412&ndash;426.
</p>
<p>Migliorati S., Ongaro A. and Monti G. S. (2017). A structured Dirichlet mixture model
for compositional data: inferential and applicative issues. Statistics and Computing, 27, 963&ndash;983.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fd.est">fd.est</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>, <a href="#topic+folded.contour">folded.contour</a>, <a href="#topic+bivt.contour">bivt.contour</a>,
<a href="#topic+comp.kerncontour">comp.kerncontour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fd.contour(alpha = c(10, 11, 12), prob = c(0.25, 0.25, 0.5), tau = 4)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20Gaussian+20mixture+20model+20in+20S+5E2'>
Contour plot of the Gaussian mixture model in <code class="reqn">S^2</code>
</h2><span id='topic+mix.compnorm.contour'></span>

<h3>Description</h3>

<p>Contour plot of the Gaussian mixture model in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix.compnorm.contour(mod, type = "alr", n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Gaussian+2B20mixture+2B20model+2B20in+2B20S+2B5E2_+3A_mod">mod</code></td>
<td>

<p>An object containing the output of a <code><a href="#topic+mix.compnorm">mix.compnorm</a></code> model.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Gaussian+2B20mixture+2B20model+2B20in+2B20S+2B5E2_+3A_type">type</code></td>
<td>

<p>The type of trasformation used, either the additive log-ratio (&quot;alr&quot;), the isometric log-ratio
(&quot;ilr&quot;) or the pivot coordinate (&quot;pivot&quot;) transformation.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Gaussian+2B20mixture+2B20model+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Gaussian+2B20mixture+2B20model+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Gaussian+2B20mixture+2B20model+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The contour plot of a Gaussian mixture model is plotted. For this you need the (fitted) model.
</p>


<h3>Value</h3>

<p>A ternary plot with the data and the contour lines of the fitted Gaussian mixture model.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2015). R package mixture: Mixture Models for
Clustering and Classification
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+bic.mixcompnorm">bic.mixcompnorm</a>, <a href="#topic+diri.contour">diri.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
mod &lt;- mix.compnorm(x, 3, model = "EII")
mix.compnorm.contour(mod, "alr")
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20generalised+20Dirichlet+20distribution+20in+20S+5E2'>
Contour plot of the generalised Dirichlet distribution in <code class="reqn">S^2</code>
</h2><span id='topic+gendiri.contour'></span>

<h3>Description</h3>

<p>Contour plot of the generalised Dirichlet distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendiri.contour(a, b, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20generalised+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_a">a</code></td>
<td>

<p>A vector with three elements corresponding to the 3 (estimated) shape parameter values.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20generalised+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_b">b</code></td>
<td>

<p>A vector with three elements corresponding to the 3 (estimated) scale parameter values.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20generalised+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20generalised+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with
compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20generalised+2B20Dirichlet+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can plot only the contour lines of a Dirichlet with a given
vector of parameters,
or can also add the relevant data should he/she wish to.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points and the Dirichlet contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and
related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data.
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mixdiri.contour">mixdiri.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>,
<a href="#topic+comp.kerncontour">comp.kerncontour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 1:3] )
x &lt;- x / rowSums(x)
gendiri.contour( a = c(3, 4, 2), b = c(1, 2, 3) )
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20Kent+20distribution+20in+20S+5E2'>
Contour plot of the Kent distribution in <code class="reqn">S^2</code>
</h2><span id='topic+kent.contour'></span>

<h3>Description</h3>

<p>Contour plot of the Kent distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kent.contour(G, param, n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Kent+2B20distribution+2B20in+2B20S+2B5E2_+3A_g">G</code></td>
<td>

<p>A 3 x 3 matrix whose first column is the mean direction. The second and third columns are
the major and minor axes respectively.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Kent+2B20distribution+2B20in+2B20S+2B5E2_+3A_param">param</code></td>
<td>

<p>A vector with the concentration <code class="reqn">kappa</code> and ovalness <code class="reqn">\beta</code> parameters (the <code class="reqn">\psi</code>
parameter has been absorbed inside the matrix G).
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Kent+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Kent+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20Kent+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can plot only the contour lines of a Dirichlet with a given vector of parameters,
or can also add the relevant data should they wish to.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points and the Dirichlet contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Graf, M. (2020). Regression for compositions based on a generalization of the Dirichlet distribution.
Statistical Methods &amp; Applications, (to appear).
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+compnorm.contour">compnorm.contour</a>, <a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+comp.kerncontour">comp.kerncontour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>G &lt;- matrix( c(0.05713382, 0.96029716, 0.27306608, -0.98809661,
0.01525976, 0.15307588, 0.1428314, -0.2785615, 0.9497382), ncol = 3 )
param &lt;- c(2361.8401338, 1171.3808172, 0.1435577)
kent.contour(G, param)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20kernel+20density+20estimate+20in+20S+5E2'>
Contour plot of the kernel density estimate in <code class="reqn">S^2</code>
</h2><span id='topic+comp.kerncontour'></span>

<h3>Description</h3>

<p>Contour plot of the kernel density estimate in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.kerncontour(x, type = "alr", n = 50, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20kernel+2B20density+2B20estimate+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. It has to be a 3 column matrix.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20kernel+2B20density+2B20estimate+2B20in+2B20S+2B5E2_+3A_type">type</code></td>
<td>

<p>This is either &quot;alr&quot; or &quot;ilr&quot;, corresponding to the additive and the isometric log-ratio transformation respectively.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20kernel+2B20density+2B20estimate+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider, over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20kernel+2B20density+2B20estimate+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The alr or the ilr transformation are applied to the compositional data. Then, the optimal bandwidth using maximum
likelihood cross-validation is chosen. The multivariate normal kernel density is calculated for a grid of points.
Those points are the points on the 2-dimensional simplex. Finally the contours are plotted.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points and the kernel contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>M.P. Wand and M.C. Jones (1995). Kernel smoothing, CrC Press.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
comp.kerncontour(x, type = "alr", n = 20)
comp.kerncontour(x, type = "ilr", n = 20)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20normal+20distribution+20in+20S+5E2'>
Contour plot of the normal distribution in <code class="reqn">S^2</code>
</h2><span id='topic+compnorm.contour'></span>

<h3>Description</h3>

<p>Contour plot of the normal distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compnorm.contour(m, s, type = "alr", n = 100, x = NULL, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_m">m</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_s">s</code></td>
<td>

<p>The covariance matrix.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_type">type</code></td>
<td>

<p>The type of trasformation used, either the additive log-ratio (&quot;alr&quot;),
the isometric log-ratio (&quot;ilr&quot;) or the pivot coordinate (&quot;pivot&quot;) transformation.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>This is either NULL (no data) or contains a 3 column matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The alr or the ilr transformation is applied to the compositional data at first. Then
for a grid  of points within the 2-dimensional simplex the bivariate normal density is
calculated and the contours are plotted along with the points.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points (if appear = TRUE) and the bivariate normal contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+skewnorm.contour">skewnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
y &lt;- Compositional::alr(x)
m &lt;- colMeans(y)
s &lt;- cov(y)
compnorm.contour(m, s)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20skew+20skew-normal+20distribution+20in+20S+5E2'>
Contour plot of the skew skew-normal distribution in <code class="reqn">S^2</code>
</h2><span id='topic+skewnorm.contour'></span>

<h3>Description</h3>

<p>Contour plot of the skew skew-normal distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewnorm.contour(x, type = "alr", n = 100, appear = TRUE, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20skew+2B20skew-normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. It has to be a 3 column matrix.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20skew+2B20skew-normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_type">type</code></td>
<td>

<p>This is either &quot;alr&quot; or &quot;ilr&quot;, corresponding to the additive and the isometric log-ratio transformation respectively.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20skew+2B20skew-normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20skew+2B20skew-normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_appear">appear</code></td>
<td>

<p>Should the available data appear on the ternary plot (TRUE) or not (FALSE)?
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20skew+2B20skew-normal+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The alr or the ilr transformation is applied to the compositional data at first. Then for a grid of points within the 2-dimensional
simplex the bivariate skew skew-normal density is calculated and the contours are plotted along with the points.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points (if appear = TRUE) and the bivariate skew skew-normal contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Azzalini A. and Valle A. D. (1996). The multivariate skew-skewnormal distribution. Biometrika 83(4):715-726.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[51:100, 1:3])
x &lt;- x / rowSums(x)
skewnorm.contour(x)
</code></pre>

<hr>
<h2 id='Contour+20plot+20of+20the+20t+20distribution+20in+20S+5E2'>
Contour plot of the t distribution in <code class="reqn">S^2</code>
</h2><span id='topic+bivt.contour'></span>

<h3>Description</h3>

<p>Contour plot of the t distribution in <code class="reqn">S^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bivt.contour(x, type = "alr", n = 100, appear = TRUE, cont.line = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20t+2B20distribution+2B20in+2B20S+2B5E2_+3A_x">x</code></td>
<td>

<p>A matrix with compositional data. It has to be a 3 column matrix.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20t+2B20distribution+2B20in+2B20S+2B5E2_+3A_type">type</code></td>
<td>

<p>This is either &quot;alr&quot; or &quot;ilr&quot;, corresponding to the additive and the isometric log-ratio transformation respectively.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20t+2B20distribution+2B20in+2B20S+2B5E2_+3A_n">n</code></td>
<td>

<p>The number of grid points to consider over which the density is calculated.
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20t+2B20distribution+2B20in+2B20S+2B5E2_+3A_appear">appear</code></td>
<td>

<p>Should the available data appear on the ternary plot (TRUE) or not (FALSE)?
</p>
</td></tr>
<tr><td><code id="Contour+2B20plot+2B20of+2B20the+2B20t+2B20distribution+2B20in+2B20S+2B5E2_+3A_cont.line">cont.line</code></td>
<td>

<p>Do you want the contour lines to appear? If yes, set this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The alr or the ilr transformation is applied to the compositional data at first and the location, scatter and degrees
of freedom of the bivariate t distribution are computed. Then for a grid of points within the 2-dimensional simplex the
bivariate t density is calculated and the contours are plotted along with the points.
</p>


<h3>Value</h3>

<p>A ternary diagram with the points (if appear = TRUE) and the bivariate t contour lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christos Adam.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Christos Adam <a href="mailto:pada4m4@gmail.com">pada4m4@gmail.com</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+compnorm.contour">compnorm.contour</a>, <a href="#topic+skewnorm.contour">skewnorm.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 1:3] )
x &lt;- x / rowSums(x)
bivt.contour(x)
bivt.contour(x, type = "ilr")
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20some+20compositional+20regression+20models'>
Cross validation for some compositional regression models
</h2><span id='topic+cv.comp.reg'></span>

<h3>Description</h3>

<p>Cross validation for some compositional regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.comp.reg(y, x, type = "comp.reg", nfolds = 10, folds = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20some+2B20compositional+2B20regression+2B20models_+3A_y">y</code></td>
<td>

<p>A matrix with compositional data. Zero values are allowed for some regression models.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20some+2B20compositional+2B20regression+2B20models_+3A_x">x</code></td>
<td>

<p>The predictor variable(s).
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20some+2B20compositional+2B20regression+2B20models_+3A_type">type</code></td>
<td>

<p>This can be one of the following: &quot;comp.reg&quot;, &quot;robust&quot;, &quot;kl.compreg&quot;, &quot;js.compreg&quot;, &quot;diri.reg&quot; or &quot;zadr&quot;.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20some+2B20compositional+2B20regression+2B20models_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if the folds argument is not supplied.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20some+2B20compositional+2B20regression+2B20models_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20some+2B20compositional+2B20regression+2B20models_+3A_seed">seed</code></td>
<td>

<p>If seed is TRUE the results will always be the same.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation for a compositional regression model is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
<tr><td><code>kl</code></td>
<td>

<p>The Kullback-Leibler divergences for all runs.
</p>
</td></tr>
<tr><td><code>js</code></td>
<td>

<p>The Jensen-Shannon divergences for all runs.
</p>
</td></tr>
<tr><td><code>perf</code></td>
<td>

<p>The average Kullback-Leibler divergence and average Jensen-Shannon divergence.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+compppr.tune">compppr.tune</a>, <a href="#topic+aknnreg.tune">aknnreg.tune</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 1:3] )
y &lt;- y / rowSums(y)
x &lt;- iris[, 4]
mod &lt;- cv.comp.reg(y, x)
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20alpha-k-NN+20regression+20with+20compositional+20predictor+20variables'>
Cross validation for the <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables
</h2><span id='topic+alfaknnreg.tune'></span>

<h3>Description</h3>

<p>Cross validation for the <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfaknnreg.tune(y, x, a = seq(-1, 1, by = 0.1), k = 2:10, nfolds = 10,
apostasi = "euclidean", method = "average", folds = NULL, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>The response variable, a numerical vector.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_a">a</code></td>
<td>

<p>A vector with a grid of values of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to consider. It can be a single number or a vector.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds. Set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use, either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_method">method</code></td>
<td>

<p>If you want to take the average of the reponses of the k closest observations, type &quot;average&quot;.
For the median, type &quot;median&quot; and for the harmonic mean, type &quot;harmonic&quot;.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_seed">seed</code></td>
<td>

<p>If seed is TRUE the results will always be the same.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation for the <code class="reqn">\alpha</code>-k-NN regression for compositional response data is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mspe</code></td>
<td>

<p>The mean square error of prediction.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum mean square error of prediction.
</p>
</td></tr>
<tr><td><code>opt_a</code></td>
<td>

<p>The optimal value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>opt_k</code></td>
<td>

<p>The optimal value of k.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.fda">alfa.fda</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y &lt;- fgl[, 1]
mod &lt;- alfaknnreg.tune(y, x, a = seq(0.2, 0.4, by = 0.1), k = 2:4, nfolds = 5)
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20alpha-k-NN+20regression+20with+20compositional+20response+20data'>
Cross validation for the <code class="reqn">\alpha</code>-k-NN regression with compositional response data
</h2><span id='topic+aknnreg.tune'></span>

<h3>Description</h3>

<p>Cross validation for the <code class="reqn">\alpha</code>-k-NN regression with compositional response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aknnreg.tune(y, x, a = seq(0.1, 1, by = 0.1), k = 2:10, apostasi = "euclidean",
nfolds = 10, folds = NULL, seed = NULL, rann = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional response data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_a">a</code></td>
<td>

<p>A vector with a grid of values of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to consider. It can be a single number or a vector.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use, either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds. Set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_rann">rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use kd-trees implemented in the R package &quot;Rnanoflann&quot;. 
In this case you must set this argument equal to TRUE. Note however, that in this case, the only available distance is by default &quot;euclidean&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation for the <code class="reqn">\alpha</code>-k-NN regression for compositional response data is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>kl</code></td>
<td>

<p>The Kullback-Leibler divergence for all combinations of <code class="reqn">\alpha</code> and <code class="reqn">k</code>.
</p>
</td></tr>
<tr><td><code>js</code></td>
<td>

<p>The Jensen-Shannon divergence for all combinations of <code class="reqn">\alpha</code> and <code class="reqn">k</code>.
</p>
</td></tr>
<tr><td><code>klmin</code></td>
<td>

<p>The minimum Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>jsmin</code></td>
<td>

<p>The minimum Jensen-Shannon divergence.
</p>
</td></tr>
<tr><td><code>kl.alpha</code></td>
<td>

<p>The optimal <code class="reqn">\alpha</code> that leads to the minimum Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>kl.k</code></td>
<td>

<p>The optimal <code class="reqn">k</code> that leads to the minimum Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>js.alpha</code></td>
<td>

<p>The optimal <code class="reqn">\alpha</code> that leads to the minimum Jensen-Shannon divergence.
</p>
</td></tr>
<tr><td><code>js.k</code></td>
<td>

<p>The optimal <code class="reqn">k</code> that leads to the minimum Jensen-Shannon divergence.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aknn.reg">aknn.reg</a>, <a href="#topic+akernreg.tune">akernreg.tune</a>, <a href="#topic+akern.reg">akern.reg</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.fda">alfa.fda</a>, rda.tune </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 1:3] )
y &lt;- y / rowSums(y)
x &lt;- iris[, 4]
mod &lt;- aknnreg.tune(y, x, a = c(0.4, 0.6), k = 2:4, nfolds = 5)
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20alpha-kernel+20regression+20with+20compositional+20response+20data'>
Cross validation for the <code class="reqn">\alpha</code>-kernel regression with compositional response data
</h2><span id='topic+akernreg.tune'></span>

<h3>Description</h3>

<p>Cross validation for the <code class="reqn">\alpha</code>-kernel regression with compositional response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>akernreg.tune(y, x, a = seq(0.1, 1, by = 0.1), h = seq(0.1, 1, length = 10),
type = "gauss", nfolds = 10, folds = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional response data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_a">a</code></td>
<td>

<p>A vector with a grid of values of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_h">h</code></td>
<td>

<p>A vector with the bandwidth value(s) to consider.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_type">type</code></td>
<td>

<p>The type of kernel to use, &quot;gauss&quot; or &quot;laplace&quot;.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds. Set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation for the <code class="reqn">\alpha</code>-kernel regression for compositional response data is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>kl</code></td>
<td>

<p>The Kullback-Leibler divergence for all combinations of <code class="reqn">\alpha</code> and <code class="reqn">h</code>.
</p>
</td></tr>
<tr><td><code>js</code></td>
<td>

<p>The Jensen-Shannon divergence for all combinations of <code class="reqn">\alpha</code> and <code class="reqn">h</code>.
</p>
</td></tr>
<tr><td><code>klmin</code></td>
<td>

<p>The minimum Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>jsmin</code></td>
<td>

<p>The minimum Jensen-Shannon divergence.
</p>
</td></tr>
<tr><td><code>kl.alpha</code></td>
<td>

<p>The optimal <code class="reqn">\alpha</code> that leads to the minimum Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>kl.h</code></td>
<td>

<p>The optimal <code class="reqn">h</code> that leads to the minimum Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>js.alpha</code></td>
<td>

<p>The optimal <code class="reqn">\alpha</code> that leads to the minimum Jensen-Shannon divergence.
</p>
</td></tr>
<tr><td><code>js.h</code></td>
<td>

<p>The optimal <code class="reqn">h</code> that leads to the minimum Jensen-Shannon divergence.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>


<h3>See Also</h3>

<p><code><a href="#topic+akern.reg">akern.reg</a>, <a href="#topic+aknnreg.tune">aknnreg.tune</a>, <a href="#topic+aknn.reg">aknn.reg</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.fda">alfa.fda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 1:3] )
y &lt;- y / rowSums(y)
x &lt;- iris[, 4]
mod &lt;- akernreg.tune(y, x, a = c(0.4, 0.6), h = c(0.1, 0.2), nfolds = 5)
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20kernel+20regression+20with+20Euclidean+20response+20data'>
Cross validation for the kernel regression with Euclidean response data
</h2><span id='topic+kernreg.tune'></span>

<h3>Description</h3>

<p>Cross validation for the kernel regression with Euclidean response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernreg.tune(y, x, h = seq(0.1, 1, length = 10), type = "gauss",
nfolds = 10, folds = NULL, seed = NULL, graph = FALSE, ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix or a vector with the Euclidean response.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_h">h</code></td>
<td>

<p>A vector with the bandwidth value(s) <code class="reqn">h</code> to consider.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_type">type</code></td>
<td>

<p>The type of kernel to use, &quot;gauss&quot; or &quot;laplace&quot;.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds. Set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a plot will appear.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20kernel+2B20regression+2B20with+2B20Euclidean+2B20response+2B20data_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use. Default value is 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation for the kernel regression with a euclidean response is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mspe</code></td>
<td>

<p>The mean squared prediction error (MSPE) for each fold and value of <code class="reqn">h</code>.
</p>
</td></tr>
<tr><td><code>h</code></td>
<td>

<p>The optimal <code class="reqn">h</code> that leads to the minimum MSPE.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum MSPE.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Wand M. P. and Jones M. C. (1994). Kernel smoothing. CRC press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kern.reg">kern.reg</a>, <a href="#topic+aknnreg.tune">aknnreg.tune</a>, <a href="#topic+aknn.reg">aknn.reg</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- iris[, 2:4]
mod &lt;- kernreg.tune(y, x, h = c(0.1, 0.2, 0.3) )
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20regularised+20and+20flexible+20discriminant+20analysis+20with+20compositional+20data+20using+20the+20alpha-transformation'>
Cross validation for the regularised and flexible discriminant analysis with compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfarda.tune'></span><span id='topic+alfafda.tune'></span>

<h3>Description</h3>

<p>Cross validation for the regularised and flexible discriminant analysis with compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfarda.tune(x, ina, a = seq(-1, 1, by = 0.1), nfolds = 10,
gam = seq(0, 1, by = 0.1), del = seq(0, 1, by = 0.1),
ncores = 1, folds = NULL, stratified = TRUE, seed = NULL)

alfafda.tune(x, ina, a = seq(-1, 1, by = 0.1), nfolds = 10,
folds = NULL, stratified = TRUE, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_ina">ina</code></td>
<td>

<p>A group indicator variable for the avaiable data.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>A vector with a grid of values of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds. Set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_gam">gam</code></td>
<td>

<p>A vector of values between 0 and 1. It is the weight of the pooled covariance
and the diagonal matrix.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_del">del</code></td>
<td>

<p>A vector of values between 0 and 1. It is the weight of the LDA and QDA.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use. If it is more than 1 parallel computing is performed.
It is advisable to use it if you have many observations and or
many variables, otherwise it will slow down th process.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL
and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be created in a stratified way? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a plot will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation is performed.
</p>


<h3>Value</h3>

<p>For the alfa.rda a list including:
</p>
<table>
<tr><td><code>res</code></td>
<td>

<p>The estimated optimal rate and the best values of <code class="reqn">\alpha</code>, <code class="reqn">\gamma</code>
and <code class="reqn">\delta</code>.
</p>
</td></tr>
<tr><td><code>percent</code></td>
<td>

<p>For the best value of <code class="reqn">\alpha</code> the averaged over all folds best rates of correct
classification. It is a matrix, where rows correspond to
the <code class="reqn">\gamma</code> values and columns correspond to <code class="reqn">\delta</code> values.
</p>
</td></tr>
<tr><td><code>se</code></td>
<td>

<p>The estimated standard errors of the &quot;percent&quot; matrix.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>
<p>For the alfa.fda a graph (if requested) with the estimated performance for each value of <code class="reqn">\alpha</code> and a list including:
</p>
<table>
<tr><td><code>per</code></td>
<td>

<p>The performance of the fda in each fold for each value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The average performance for each value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>opt_a</code></td>
<td>

<p>The optimal value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and
Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009).
The elements of statistical learning, 2nd edition. Springer, Berlin
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2016).
Improved classification for compositional data using the <code class="reqn">\alpha</code>-transformation.
Jounal of Classification, 33(2):243-261.
</p>
<p>Hastie, Tibshirani and Buja (1994). Flexible Disriminant Analysis by Optimal Scoring.
Journal of the American Statistical Association, 89(428):1255-1270.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfanb.tune">alfanb.tune</a>, <a href="#topic+cv.dda">cv.dda</a>, <a href="#topic+compknn.tune">compknn.tune</a> <a href="#topic+cv.compnb">cv.compnb</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
ina &lt;- fgl[, 10]
moda &lt;- alfarda.tune(x, ina, a = seq(0.7, 1, by = 0.1), nfolds = 10,
gam = seq(0.1, 0.3, by = 0.1), del = seq(0.1, 0.3, by = 0.1) )
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20ridge+20regression'>
Cross validation for the ridge regression
</h2><span id='topic+ridge.tune'></span>

<h3>Description</h3>

<p>Cross validation for the ridge regression is performed. There is an option for the GCV criterion which is automatic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridge.tune(y, x, nfolds = 10, lambda = seq(0, 2, by = 0.1), folds = NULL,
ncores = 1, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_y">y</code></td>
<td>

<p>A numeric vector containing the values of the target variable. If the values are proportions or percentages,
i.e. strictly within 0 and 1 they are mapped into R using the logit transformation.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_x">x</code></td>
<td>

<p>A numeric matrix containing the variables.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds in the cross validation.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_lambda">lambda</code></td>
<td>

<p>A vector with the a grid of values of <code class="reqn">\lambda</code> to be used.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use. If it is more than 1 parallel computing is performed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression_+3A_graph">graph</code></td>
<td>

<p>If graph is set to TRUE the performances for each fold as a function of the <code class="reqn">\lambda</code> values will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation is performed. This function is used by <code><a href="#topic+alfaridge.tune">alfaridge.tune</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>msp</code></td>
<td>

<p>The performance of the ridge regression for every fold.
</p>
</td></tr>
<tr><td><code>mspe</code></td>
<td>

<p>The values of the mean prediction error for each value of <code class="reqn">\lambda</code>.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>The value of <code class="reqn">\lambda</code> which corresponds to the minimum MSPE.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum MSPE.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Giorgos Athineou &lt;gioathineou@gmail.com&gt; 
and Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Hoerl A.E. and R.W. Kennard (1970). Ridge regression: Biased estimation for nonorthogonal problems.
Technometrics, 12(1):55-67.
</p>
<p>Brown P. J. (1994). Measurement, Regression and Calibration. Oxford Science Publications.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ridge.reg">ridge.reg</a>, <a href="#topic+alfaridge.tune">alfaridge.tune</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.vector(iris[, 1])
x &lt;- as.matrix(iris[, 2:4])
ridge.tune( y, x, nfolds = 10, lambda = seq(0, 2, by = 0.1), graph = TRUE )
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20ridge+20regression+20with+20compositional+20data+20as+20predictor+20using+20the+20alpha-transformation'>
Cross validation for the ridge regression with compositional data as predictor using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfaridge.tune'></span>

<h3>Description</h3>

<p>Cross validation for the ridge regression is performed.
There is an option for the GCV criterion which is automatic. The predictor variables are compositional data and the <code class="reqn">\alpha</code>-transformation is applied first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfaridge.tune(y, x, nfolds = 10, a = seq(-1, 1, by = 0.1),
lambda = seq(0, 2, by = 0.1), folds = NULL, ncores = 1,
graph = TRUE, col.nu = 15, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numeric vector containing the values of the target variable. If the values are proportions or percentages,
i.e. strictly within 0 and 1 they are mapped into R using the logit transformation.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A numeric matrix containing the compositional data, i.e. the predictor variables. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds in the cross validation.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>A vector with the a grid of values of <code class="reqn">\alpha</code> to be used.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_lambda">lambda</code></td>
<td>

<p>A vector with the a grid of values of <code class="reqn">\lambda</code> to be used.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use. If it is more than 1 parallel computing is performed. It is advisable to use it if you have many observations and or many variables, otherwise it will slow down th process.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_col.nu">col.nu</code></td>
<td>

<p>A number parameter for the filled contour plot, taken into account only if graph is TRUE.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20as+2B20predictor+2B20using+2B20the+2B20alpha-transformation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation is performed.
</p>


<h3>Value</h3>

<p>If graph is TRUE a fileld contour a filled contour will appear.
A list including:
</p>
<table>
<tr><td><code>mspe</code></td>
<td>

<p>The MSPE where rows correspond to the <code class="reqn">\alpha</code> values and the columns to the number of principal components.
</p>
</td></tr>
<tr><td><code>best.par</code></td>
<td>

<p>The best pair of <code class="reqn">\alpha</code> and <code class="reqn">\lambda</code>.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum mean squared error of prediction.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Giorgos Athineou &lt;gioathineou@gmail.com&gt; and Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Hoerl A.E. and R.W. Kennard (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1):55-67.
</p>
<p>Brown P. J. (1994). Measurement, Regression and Calibration. Oxford Science Publications.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa.ridge">alfa.ridge</a>, <a href="#topic+ridge.tune">ridge.tune</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.vector(fgl[, 1])
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
alfaridge.tune( y, x, nfolds = 10, a = seq(0.1, 1, by = 0.1),
lambda = seq(0, 1, by = 0.1) )
</code></pre>

<hr>
<h2 id='Cross+20validation+20for+20the+20transformation-free+20linear+20regression+20for+20compositional+20responses+20and+20predictors'>
Cross validation for the transformation-free linear regression for compositional
responses and predictors
</h2><span id='topic+cv.tflr'></span>

<h3>Description</h3>

<p>Cross validation for the transformation-free linear regression for compositional
responses and predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.tflr(y, x, nfolds = 10, folds = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_y">y</code></td>
<td>

<p>A matrix with compositional response data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_x">x</code></td>
<td>

<p>A matrix with compositional predictors. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if the
folds argument is not supplied.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL
and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross+2B20validation+2B20for+2B20the+2B20transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_seed">seed</code></td>
<td>

<p>If seed is TRUE the results will always be the same.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A k-fold cross validation for the transformation-free linear regression for
compositional responses and predictors is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
<tr><td><code>kl</code></td>
<td>

<p>The Kullback-Leibler divergences for all runs.
</p>
</td></tr>
<tr><td><code>js</code></td>
<td>

<p>The Jensen-Shannon divergences for all runs.
</p>
</td></tr>
<tr><td><code>perf</code></td>
<td>

<p>The average Kullback-Leibler divergence and average Jensen-Shannon divergence.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+tflr">tflr</a>, <a href="#topic+cv.olscompcomp">cv.olscompcomp</a>, <a href="#topic+klalfapcr.tune">klalfapcr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
y &lt;- rdiri(214, runif(3, 1, 3))
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
mod &lt;- cv.tflr(y, x)
mod

</code></pre>

<hr>
<h2 id='Cross-validation+20for+20the+20constrained+20linear+20least+20squares+20for+20compositional+20responses+20and+20predictors'>
Cross-validation for the constrained linear least squares for compositional
responses and predictors
</h2><span id='topic+cv.olscompcomp'></span>

<h3>Description</h3>

<p>Cross-validation for the constrained linear least squares for compositional
responses and predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.olscompcomp(y, x, tol = 1e-4, nfolds = 10,
folds = NULL, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_y">y</code></td>
<td>

<p>A matrix with compositional response data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_x">x</code></td>
<td>

<p>A matrix with compositional predictors. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_tol">tol</code></td>
<td>

<p>The threshold upon which to stop the iterations of the constrained optimisation.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if the
folds argument is not supplied.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL
and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs k-fold cross-validation for the least squares regression
where the beta coefficients are constained to be positive and sum to 1.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the cross-validation procedure.
</p>
</td></tr>
<tr><td><code>kl</code></td>
<td>

<p>The Kullback-Leibler divergences for all runs.
</p>
</td></tr>
<tr><td><code>js</code></td>
<td>

<p>The Jensen-Shannon divergences for all runs.
</p>
</td></tr>
<tr><td><code>perf</code></td>
<td>

<p>The average Kullback-Leibler divergence and average Jensen-Shannon divergence.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ols.compcomp">ols.compcomp</a>, <a href="#topic+cv.tflr">cv.tflr</a>, <a href="#topic+klalfapcr.tune">klalfapcr.tune</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
set.seed(1234)
y &lt;- rdiri(214, runif(3, 1, 3))
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
mod &lt;- cv.olscompcomp(y, x, tol = 1e-4, nfolds = 5, seed = 12345)
mod

</code></pre>

<hr>
<h2 id='Cross-validation+20for+20the+20Dirichlet+20discriminant+20analysis'>
Cross-validation for the Dirichlet discriminant analysis
</h2><span id='topic+cv.dda'></span>

<h3>Description</h3>

<p>Cross-validation for the Dirichlet discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.dda(x, ina, nfolds = 10, folds = NULL, stratified = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20Dirichlet+2B20discriminant+2B20analysis_+3A_x">x</code></td>
<td>

<p>A matrix with the available data, the predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20Dirichlet+2B20discriminant+2B20analysis_+3A_ina">ina</code></td>
<td>

<p>A vector of data. The response variable, which is categorical (factor is acceptable).
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20Dirichlet+2B20discriminant+2B20analysis_+3A_folds">folds</code></td>
<td>

<p>A list with the indices of the folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20Dirichlet+2B20discriminant+2B20analysis_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if &quot;folds&quot; is NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20Dirichlet+2B20discriminant+2B20analysis_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be selected using stratified random sampling? This preserves the analogy of the samples of each group. Make this TRUE if you wish.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20Dirichlet+2B20discriminant+2B20analysis_+3A_seed">seed</code></td>
<td>

<p>If you set this to TRUE, the same folds will be created every time.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the performance of the Dirichlet discriminant analysis via k-fold cross-validation.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>percent</code></td>
<td>

<p>The percentage of correct classification
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The duration of the cross-validation proecdure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning.
New York: Springer.
</p>
<p>Thomas P. Minka (2003). Estimating a Dirichlet distribution.
http://research.microsoft.com/en-us/um/people/minka/papers/dirichlet/minka-dirichlet.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+dda">dda</a>, <a href="#topic+alfanb.tune">alfanb.tune</a>, <a href="#topic+alfarda.tune">alfarda.tune</a>, <a href="#topic+compknn.tune">compknn.tune</a>, <a href="#topic+cv.compnb">cv.compnb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
mod &lt;- cv.dda(x, ina = iris[, 5] )
</code></pre>

<hr>
<h2 id='Cross-validation+20for+20the+20LASSO+20Kullback-Leibler+20divergence+20based+20regression'>
Cross-validation for the LASSO Kullback-Leibler divergence based regression
</h2><span id='topic+cv.lasso.klcompreg'></span>

<h3>Description</h3>

<p>Cross-validation for the LASSO Kullback-Leibler divergence based regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.lasso.klcompreg(y, x, alpha = 1, type = "grouped", nfolds = 10,
folds = NULL, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical matrix with compositional data with or without zeros.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_alpha">alpha</code></td>
<td>

<p>The elastic net mixing parameter, with <code class="reqn">0 \leq \alpha \leq 1</code>. The penalty is defined as a 
weighted combination of the ridge and of the Lasso regression. When <code class="reqn">\alpha=1</code> LASSO is 
applied, while <code class="reqn">\alpha=0</code> yields the ridge regression.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_type">type</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b>. If &quot;grouped&quot; then a grouped lasso 
penalty is used on the multinomial coefficients for a variable. This ensures they are all in our out 
together. The default in our case is &quot;grouped&quot;.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds for the K-fold cross validation, set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The K-fold cross validation is performed in order to select the optimal value for <code class="reqn">\lambda</code>, 
the penalty parameter in LASSO.
</p>


<h3>Value</h3>

<p>The outcome is the same as in the R package glmnet. The extra addition is that if &quot;graph = TRUE&quot;, 
then the plot of the cross-validated object is returned. The contains the logarithm of <code class="reqn">\lambda</code> 
and the deviance. The numbers on top of the figure show the number of set of coefficients for each 
component, that are not zero.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Abdulaziz Alenazi.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> 
and Abdulaziz Alenazi <a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a>.
</p>


<h3>References</h3>

<p>Alenazi, A. A. (2022). f-divergence regression models for compositional data. 
Pakistan Journal of Statistics and Operation Research, 18(4): 867&ndash;882.
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2010) Regularization Paths for Generalized Linear 
Models via Coordinate Descent. Journal of Statistical Software, Vol. 33(1), 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lasso.klcompreg">lasso.klcompreg</a>, <a href="#topic+lassocoef.plot">lassocoef.plot</a>, <a href="#topic+lasso.compreg">lasso.compreg</a>, <a href="#topic+cv.lasso.compreg">cv.lasso.compreg</a>, <a href="#topic+kl.compreg">kl.compreg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- rdiri( 214, runif(4, 1, 3) )
x &lt;- as.matrix( fgl[, 2:9] )
mod &lt;- cv.lasso.klcompreg(y, x)
</code></pre>

<hr>
<h2 id='Cross-validation+20for+20the+20LASSO+20log-ratio+20regression+20with+20compositional+20response'>
Cross-validation for the LASSO log-ratio regression with compositional response
</h2><span id='topic+cv.lasso.compreg'></span>

<h3>Description</h3>

<p>Cross-validation for the LASSO log-ratio regression with compositional response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.lasso.compreg(y, x, alpha = 1, nfolds = 10,
folds = NULL, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_y">y</code></td>
<td>

<p>A numerical matrix with compositional data. Zero values are not allowed as the additive 
log-ratio transformation (<code><a href="#topic+alr">alr</a></code>) is applied to the compositional response prior to implementing 
the LASSO algortihm.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_alpha">alpha</code></td>
<td>

<p>The elastic net mixing parameter, with <code class="reqn">0 \leq \alpha \leq 1</code>. The penalty is defined as a weighted
combination of the ridge and of the Lasso regression. When <code class="reqn">\alpha=1</code> LASSO is applied, while
<code class="reqn">\alpha=0</code> yields the ridge regression.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds for the K-fold cross validation, set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The K-fold cross validation is performed in order to select the optimal value for <code class="reqn">\lambda</code>, the
penalty parameter in LASSO.
</p>


<h3>Value</h3>

<p>The outcome is the same as in the R package glmnet. The extra addition is that if &quot;graph = TRUE&quot;, then the
plot of the cross-validated object is returned. The contains the logarithm of <code class="reqn">\lambda</code> and the mean
squared error. The numbers on top of the figure show the number of set of coefficients for each component,
that are not zero.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2010) Regularization Paths for Generalized Linear Models via
Coordinate Descent. Journal of Statistical Software, Vol. 33(1), 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lasso.compreg">lasso.compreg</a>, <a href="#topic+lasso.klcompreg">lasso.klcompreg</a>, <a href="#topic+lassocoef.plot">lassocoef.plot</a>, <a href="#topic+cv.lasso.klcompreg">cv.lasso.klcompreg</a>,
<a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- rdiri( 214, runif(4, 1, 3) )
x &lt;- as.matrix( fgl[, 2:9] )
mod &lt;- cv.lasso.compreg(y, x)
</code></pre>

<hr>
<h2 id='Cross-validation+20for+20the+20naive+20Bayes+20classifiers+20for+20compositional+20data'>
Cross-validation for the naive Bayes classifiers for compositional data
</h2><span id='topic+cv.compnb'></span>

<h3>Description</h3>

<p>Cross-validation for the naive Bayes classifiers for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.compnb(x, ina, type = "beta", folds = NULL, nfolds = 10,
      stratified = TRUE, seed = NULL, pred.ret = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available data, the predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_ina">ina</code></td>
<td>

<p>A vector of data. The response variable, which is categorical (factor is acceptable).
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>The type of naive Bayes, &quot;beta&quot;, &quot;logitnorm&quot;, &quot;cauchy&quot;, &quot;laplace&quot;, &quot;gamma&quot;, &quot;normlog&quot; or &quot;weibull&quot;. For the last 4 distributions, the negative of the logarithm of the compositional data is applied first.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_folds">folds</code></td>
<td>

<p>A list with the indices of the folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if &quot;folds&quot; is NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be selected using stratified random sampling? This preserves the analogy of the samples of each group.
Make this TRUE if you wish.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_pred.ret">pred.ret</code></td>
<td>

<p>If you want the predicted values returned set this to TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>preds</code></td>
<td>

<p>If pred.ret is TRUE the predicted values for each fold are returned as elements in a list.
</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>

<p>A vector whose length is equal to the number of k and is the accuracy metric for each k.
For the classification case it is the percentage of correct classification.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning.
New York: Springer.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+comp.nb">comp.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
mod &lt;- cv.compnb(x, ina = iris[, 5] )
</code></pre>

<hr>
<h2 id='Cross-validation+20for+20the+20naive+20Bayes+20classifiers+20for+20compositional+20data+20using+20the+20alpha-transformation'>
Cross-validation for the naive Bayes classifiers for compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfanb.tune'></span>

<h3>Description</h3>

<p>Cross-validation for the naive Bayes classifiers for compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfanb.tune(x, ina, a = seq(-1, 1, by = 0.1), type = "gaussian",
folds = NULL, nfolds = 10, stratified = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the available data, the predictor variables.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_ina">ina</code></td>
<td>

<p>A vector of data. The response variable, which is categorical (factor is acceptable).
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> for the <code class="reqn">\alpha</code>-transformation.
This can be a vector of values or a single number.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_type">type</code></td>
<td>

<p>The type of naive Bayes, &quot;gaussian&quot;, &quot;cauchy&quot; or &quot;laplace&quot;.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_folds">folds</code></td>
<td>

<p>A list with the indices of the folds.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if &quot;folds&quot; is NULL.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be selected using stratified random sampling? This preserves the analogy of the samples of each group.
Make this TRUE if you wish.
</p>
</td></tr>
<tr><td><code id="Cross-validation+2B20for+2B20the+2B20naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the performance of the naive Bayes classifier for each value of <code class="reqn">\alpha</code> of the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>crit</code></td>
<td>

<p>A vector whose length is equal to the number of k and is the accuracy metric for each k.
For the classification case it is the percentage of correct classification.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning.
New York: Springer.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa.nb">alfa.nb</a>, <a href="#topic+alfarda.tune">alfarda.tune</a>, <a href="#topic+compknn.tune">compknn.tune</a>, <a href="#topic+cv.dda">cv.dda</a>, <a href="#topic+cv.compnb">cv.compnb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
mod &lt;- alfanb.tune(x, ina = iris[, 5], a = c(0, 0.1, 0.2) )
</code></pre>

<hr>
<h2 id='Density+20of+20compositional+20data+20from+20Gaussian+20mixture+20models'>
Simulation of compositional data from Gaussian mixture models
</h2><span id='topic+dmix.compnorm'></span>

<h3>Description</h3>

<p>Simulation of compositional data from Gaussian mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmix.compnorm(x, mu, sigma, prob, type = "alr", logged = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_x">x</code></td>
<td>

<p>A vector or a matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_prob">prob</code></td>
<td>

<p>A vector with mixing  probabilities. Its length is equal to the number of clusters.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_mu">mu</code></td>
<td>

<p>A matrix where each row corresponds to the mean vector of each cluster.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_sigma">sigma</code></td>
<td>

<p>An array consisting of the covariance matrix of each cluster.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_type">type</code></td>
<td>

<p>The type of trasformation used, either the additive log-ratio (&quot;alr&quot;),
the isometric log-ratio (&quot;ilr&quot;) or the pivot coordinate (&quot;pivot&quot;) transformation.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_logged">logged</code></td>
<td>

<p>A boolean variable specifying whether the logarithm of the density values to
be returned. It is set to TRUE by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A sample from a multivariate Gaussian mixture model is generated.
</p>


<h3>Value</h3>

<p>A vector with the density values.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2015). R package mixture: Mixture
Models for Clustering and Classification.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+bic.mixcompnorm">bic.mixcompnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(1/3, 1/3, 1/3)
mu &lt;- matrix(nrow = 3, ncol = 4)
s &lt;- array( dim = c(4, 4, 3) )
x &lt;- as.matrix(iris[, 1:4])
ina &lt;- as.numeric(iris[, 5])
mu &lt;- rowsum(x, ina) / 50
s[, , 1] &lt;- cov(x[ina == 1, ])
s[, , 2] &lt;- cov(x[ina == 2, ])
s[, , 3] &lt;- cov(x[ina == 3, ])
y &lt;- rmixcomp(100, p, mu, s, type = "alr")$x
mod &lt;- dmix.compnorm(y, mu, s, p)
</code></pre>

<hr>
<h2 id='Density+20of+20the+20Flexible+20Dirichlet+20distribution'>
Density of the Flexible Dirichlet distribution
</h2><span id='topic+dfd'></span>

<h3>Description</h3>

<p>Density of the Flexible Dirichlet distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfd(x, alpha, prob, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A vector or a matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_alpha">alpha</code></td>
<td>

<p>A vector of the non-negative <code class="reqn">\alpha</code> parameters.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_prob">prob</code></td>
<td>

<p>A vector of the clusters' probabilities. It must sum to one.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_tau">tau</code></td>
<td>

<p>The non-negative scalar <code class="reqn">tau</code> parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information see the references.
</p>


<h3>Value</h3>

<p>The density value(s).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris ported from the R package FlexDir. <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ongaro A. and Migliorati S. (2013). A generalization of the Dirichlet
distribution. Journal of Multivariate Analysis, 114, 412&ndash;426.
</p>
<p>Migliorati S., Ongaro A. and Monti G. S. (2017). A structured Dirichlet mixture
model for compositional data: inferential and applicative issues.
Statistics and Computing, 27, 963&ndash;983.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+fd.est">fd.est</a>, <a href="#topic+rfd">rfd</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alpha &lt;- c(12, 11, 10)
prob &lt;- c(0.25, 0.25, 0.5)
tau &lt;- 8
x &lt;- rfd(20, alpha, prob, tau)
dfd(x, alpha, prob, tau)
</code></pre>

<hr>
<h2 id='Density+20of+20the+20folded+20normal+20distribution'>
Density of the folded model normal distribution
</h2><span id='topic+dfolded'></span>

<h3>Description</h3>

<p>Density of the folded model normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfolded(x, a, p, mu, su, logged = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20of+2B20the+2B20folded+2B20normal+2B20distribution_+3A_x">x</code></td>
<td>

<p>A vector or a matrix with compositional data. No zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20folded+2B20normal+2B20distribution_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20folded+2B20normal+2B20distribution_+3A_p">p</code></td>
<td>

<p>The probability inside the simplex of the folded model.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20folded+2B20normal+2B20distribution_+3A_mu">mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20folded+2B20normal+2B20distribution_+3A_su">su</code></td>
<td>

<p>The covariance matrix.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20folded+2B20normal+2B20distribution_+3A_logged">logged</code></td>
<td>

<p>A boolean variable specifying whether the logarithm of the density values to
be returned. It is set to TRUE by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Density values of the folded model.
</p>


<h3>Value</h3>

<p>The density value(s).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2020). A folded model for compositional data analysis.
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfolded">rfolded</a>, <a href="#topic+a.est">a.est</a>, <a href="#topic+folded.contour">folded.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- c(0.1490676523, -0.4580818209,  0.0020395316, -0.0047446076, -0.4580818209,
1.5227259250,  0.0002596411,  0.0074836251,  0.0020395316,  0.0002596411,
0.0365384838, -0.0471448849, -0.0047446076,  0.0074836251, -0.0471448849,
0.0611442781)
s &lt;- matrix(s, ncol = 4)
m &lt;- c(1.715, 0.914, 0.115, 0.167)
x &lt;- rfolded(100, m, s, 0.5)
mod &lt;- a.est(x)
den &lt;- dfolded(x, mod$best, mod$p, mod$mu, mod$su)
</code></pre>

<hr>
<h2 id='Density+20values+20of+20a+20Dirichlet+20distribution'>
Density values of a Dirichlet distribution
</h2><span id='topic+ddiri'></span>

<h3>Description</h3>

<p>Density values of a Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddiri(x, a, logged = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix containing compositional data. This can be a vector or a matrix with the data.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20Dirichlet+2B20distribution_+3A_a">a</code></td>
<td>

<p>A vector of parameters. Its length must be equal to the number of components,
or columns of the matrix with the compositional data and all values must be
greater than zero.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20Dirichlet+2B20distribution_+3A_logged">logged</code></td>
<td>

<p>A boolean variable specifying whether the logarithm of the density values to
be returned. It is set to TRUE by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density of the Dirichlet distribution for a vector or a matrix of compositional
data is returned.
</p>


<h3>Value</h3>

<p>A vector with the density values.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011).
Dirichlet and related distributions: Theory, methods and applications.
John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dgendiri">dgendiri</a>, <a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.est">diri.est</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+dda">dda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rdiri( 100, c(5, 7, 4, 8, 10, 6, 4) )
a &lt;- diri.est(x)
f &lt;- ddiri(x, a$param)
sum(f)
a
</code></pre>

<hr>
<h2 id='Density+20values+20of+20a+20generalised+20Dirichlet+20distribution'>
Density values of a generalised Dirichlet distribution
</h2><span id='topic+dgendiri'></span>

<h3>Description</h3>

<p>Density values of a generalised Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgendiri(x, a, b, logged = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20generalised+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix containing compositional data. This can be a vector or a matrix with the data.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20generalised+2B20Dirichlet+2B20distribution_+3A_a">a</code></td>
<td>

<p>A numerical vector with the shape parameter values of the Gamma distribution.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20generalised+2B20Dirichlet+2B20distribution_+3A_b">b</code></td>
<td>

<p>A numerical vector with the scale parameter values of the Gamma distribution.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20generalised+2B20Dirichlet+2B20distribution_+3A_logged">logged</code></td>
<td>

<p>A boolean variable specifying whether the logarithm of the density values to
be returned. It is set to TRUE by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density of the Dirichlet distribution for a vector or a matrix of compositional
data is returned.
</p>


<h3>Value</h3>

<p>A vector with the density values.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011).
Dirichlet and related distributions: Theory, methods and applications.
John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddiri">ddiri</a>, <a href="#topic+rgendiri">rgendiri</a>, <a href="#topic+diri.est">diri.est</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+dda">dda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- c(1, 2, 3)
b &lt;- c(2, 3, 4)
x &lt;- rgendiri(100, a, b)
y &lt;- dgendiri(x, a, b)
</code></pre>

<hr>
<h2 id='Density+20values+20of+20a+20mixture+20of+20Dirichlet+20distributions'>
Density values of a mixture of Dirichlet distributions
</h2><span id='topic+dmixdiri'></span>

<h3>Description</h3>

<p>Density values of a mixture of Dirichlet distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmixdiri(x, a, prob, logged = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20mixture+2B20of+2B20Dirichlet+2B20distributions_+3A_x">x</code></td>
<td>

<p>A vector or a matrix with compositional data. Zeros are not allowed.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20mixture+2B20of+2B20Dirichlet+2B20distributions_+3A_a">a</code></td>
<td>

<p>A matrix where each row contains the parameters of each Dirichlet component.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20mixture+2B20of+2B20Dirichlet+2B20distributions_+3A_prob">prob</code></td>
<td>

<p>A vector with the mixing probabilities.
</p>
</td></tr>
<tr><td><code id="Density+2B20values+2B20of+2B20a+2B20mixture+2B20of+2B20Dirichlet+2B20distributions_+3A_logged">logged</code></td>
<td>

<p>A boolean variable specifying whether the logarithm of the density values to
be returned. It is set to TRUE by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density of the mixture of Dirichlet distribution for a vector or a matrix
of compositional data is returned.
</p>


<h3>Value</h3>

<p>A vector with the density values.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ye X., Yu Y. K. and Altschul S. F. (2011). On the inference of
Dirichlet mixture priors for protein sequence comparison.
Journal of Computational Biology, 18(8), 941-954.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rmixdiri">rmixdiri</a>, <a href="#topic+mixdiri.contour">mixdiri.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix( c(12, 30, 45, 32, 50, 16), byrow = TRUE,ncol = 3)
prob &lt;- c(0.5, 0.5)
x &lt;- rmixdiri(100, a, prob)$x
f &lt;- dmixdiri(x, a, prob)
</code></pre>

<hr>
<h2 id='Dirichlet+20discriminant+20analysis'>
Dirichlet discriminant analysis
</h2><span id='topic+dda'></span>

<h3>Description</h3>

<p>Dirichlet discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dda(xnew, x, ina)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dirichlet+2B20discriminant+2B20analysis_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new compositional predictor data whose class you want to
predict. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Dirichlet+2B20discriminant+2B20analysis_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional predictor data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Dirichlet+2B20discriminant+2B20analysis_+3A_ina">ina</code></td>
<td>

<p>A vector of data. The response variable, which is categorical
(factor is acceptable).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The funcitons performs maximum likelihood discriminant analysis using
the Dirichlet distribution.
</p>


<h3>Value</h3>

<p>A vector with the estimated group.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical
learning. New York: Springer.
</p>
<p>Thomas P. Minka (2003). Estimating a Dirichlet distribution.
http://research.microsoft.com/en-us/um/people/minka/papers/dirichlet/minka-dirichlet.pdf
</p>
<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related
distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data.
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.dda">cv.dda</a>, <a href="#topic+comp.nb">comp.nb</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.knn">alfa.knn</a>,
<a href="#topic+comp.knn">comp.knn</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+zadr">zadr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Compositional::rdiri(100, runif(5) )
ina &lt;- rbinom(100, 1, 0.5) + 1
mod &lt;- dda(x, x, ina )
</code></pre>

<hr>
<h2 id='Dirichlet+20random+20values+20simulation'>
Dirichlet random values simulation
</h2><span id='topic+rdiri'></span>

<h3>Description</h3>

<p>Dirichlet random values simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdiri(n, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dirichlet+2B20random+2B20values+2B20simulation_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Dirichlet+2B20random+2B20values+2B20simulation_+3A_a">a</code></td>
<td>

<p>A numerical vector with the parameter values.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is straightforward, for each vector, independent gamma values are generated and then divided by their total sum.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.est">diri.est</a>, <a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+rgendiri">rgendiri</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rdiri( 100, c(5, 7, 1, 3, 10, 2, 4) )
diri.est(x)
</code></pre>

<hr>
<h2 id='Dirichlet+20regression'>
Dirichlet regression
</h2><span id='topic+diri.reg'></span><span id='topic+diri.reg2'></span><span id='topic+diri.reg3'></span>

<h3>Description</h3>

<p>Dirichlet regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diri.reg(y, x, plot = FALSE, xnew = NULL)

diri.reg2(y, x, xnew = NULL)

diri.reg3(y, x, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dirichlet+2B20regression_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). Zero values are not allowed.
</p>
</td></tr>
<tr><td><code id="Dirichlet+2B20regression_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they can be either continuous or categorical or both.
</p>
</td></tr>
<tr><td><code id="Dirichlet+2B20regression_+3A_plot">plot</code></td>
<td>

<p>A boolean variable specifying whether to plot the leverage values of the observations or not.
This is taken into account only when xnew = NULL.
</p>
</td></tr>
<tr><td><code id="Dirichlet+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Dirichlet distribution is assumed for the regression. This involves numerical optimization.
The function &quot;diri.reg2()&quot; allows for the covariates to be linked with the precision parameter
<code class="reqn">\phi</code> via the exponential link function <code class="reqn">\phi = e^{x*b}</code>. The function &quot;diri.reg3()&quot;
links the covariates to the alpha parameters of the Dirichlet distribution, i.e. it uses the
classical parametrization of the distribution. This means, that there is a set of regression
parameters for each component.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The precision parameter. If covariates are linked with it (function &quot;diri.reg2()&quot;), this will
be a vector.
</p>
</td></tr>
<tr><td><code>phipar</code></td>
<td>

<p>The coefficients of the phi parameter if it is linked to the covariates.
</p>
</td></tr>
<tr><td><code>std.phi</code></td>
<td>

<p>The standard errors of the coefficients of the phi parameter is it linked to the covariates.
</p>
</td></tr>
<tr><td><code>log.phi</code></td>
<td>

<p>The logarithm of the precision parameter.
</p>
</td></tr>
<tr><td><code>std.logphi</code></td>
<td>

<p>The standard error of the logarithm of the precision parameter.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the beta coefficients.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>Th covariance matrix of the regression parameters (for the mean vector and the phi parameter)&quot;.
</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>

<p>The leverage values.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>For the &quot;diri.reg&quot; this contains the fitted or the predicted values (if xnew is not NULL).
For the &quot;diri.reg2&quot; if xnew is NULL, this is also NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou
&lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Maier, Marco J. (2014) DirichletReg: Dirichlet Regression for Compositional Data in R.
Research Report Series/Department of Statistics and Mathematics, 125. WU Vienna University of
Economics and Business, Vienna.
http://epub.wu.ac.at/4077/1/Report125.pdf
</p>
<p>Gueorguieva, Ralitza, Robert Rosenheck, and Daniel Zelterman (2008). Dirichlet component
regression and its applications to psychiatric data. Computational statistics &amp; data analysis
52(12): 5344-5355.
</p>
<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+alfa.reg">alfa.reg</a>, <a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+dda">dda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.vector(iris[, 4])
y &lt;- as.matrix(iris[, 1:3])
y &lt;- y / rowSums(y)
mod1 &lt;- diri.reg(y, x)
mod2 &lt;- diri.reg2(y, x)
mod3 &lt;- comp.reg(y, x)
</code></pre>

<hr>
<h2 id='Distance+20based+20regression+20models+20for+20proportions'>
Distance based regression models for proportions
</h2><span id='topic+ols.prop.reg'></span><span id='topic+helling.prop.reg'></span>

<h3>Description</h3>

<p>Distance based regression models for proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols.prop.reg(y, x, cov = FALSE, tol = 1e-07, maxiters = 100)
helling.prop.reg(y, x, tol = 1e-07, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance+2B20based+2B20regression+2B20models+2B20for+2B20proportions_+3A_y">y</code></td>
<td>

<p>A numerical vector proportions. 0s and 1s are allowed.
</p>
</td></tr>
<tr><td><code id="Distance+2B20based+2B20regression+2B20models+2B20for+2B20proportions_+3A_x">x</code></td>
<td>

<p>A matrix or a data frame with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Distance+2B20based+2B20regression+2B20models+2B20for+2B20proportions_+3A_cov">cov</code></td>
<td>

<p>Should the covariance matrix be returned? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Distance+2B20based+2B20regression+2B20models+2B20for+2B20proportions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm. This is set to <code class="reqn">10^{-9}</code> by default.
</p>
</td></tr>
<tr><td><code id="Distance+2B20based+2B20regression+2B20models+2B20for+2B20proportions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations before the Newton-Raphson is terminated automatically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We are using the Newton-Raphson, but unlike R's built-in function &quot;glm&quot; we do no checks and no extra calculations, or whatever. Simply the model. The functions accept binary responses as well (0 or 1).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>sse</code></td>
<td>

<p>The sum of squres of errors for the &quot;ols.prop.reg&quot; function.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The estimated regression coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the regression coefficients if &quot;cov&quot; is TRUE.
</p>
</td></tr>
<tr><td><code>covb</code></td>
<td>

<p>The covariance matrix of the regression coefficients in &quot;ols.prop.reg&quot; if &quot;cov&quot; is TRUE.
</p>
</td></tr>
<tr><td><code>H</code></td>
<td>

<p>The Hellinger distance between the true and the obseervd proportions in &quot;helling.prop.reg&quot;.
</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response variables with
an application to 401(K) plan participation rates. Journal of Applied Econometrics, 11(6): 619&ndash;632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+propreg">propreg</a>, <a href="#topic+beta.reg">beta.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbeta(100, 1, 4)
x &lt;- matrix(rnorm(100 * 2), ncol = 2)
a1 &lt;- ols.prop.reg(y, x)
a2 &lt;- helling.prop.reg(y, x)
</code></pre>

<hr>
<h2 id='Divergence+20based+20regression+20for+20compositional+20data'>
Divergence based regression for compositional data
</h2><span id='topic+kl.compreg'></span><span id='topic+js.compreg'></span><span id='topic+tv.compreg'></span><span id='topic+symkl.compreg'></span>

<h3>Description</h3>

<p>Regression for compositional data based on the Kullback-Leibler the Jensen-Shannon divergence and the symmetric Kullback-Leibler divergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kl.compreg(y, x, con = TRUE, B = 1, ncores = 1, xnew = NULL, tol = 1e-07, maxiters = 50)
js.compreg(y, x, con = TRUE, B = 1, ncores = 1, xnew = NULL)
tv.compreg(y, x, con = TRUE, B = 1, ncores = 1, xnew = NULL)
symkl.compreg(y, x, con = TRUE, B = 1, ncores = 1, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they can be either continnuous or categorical or both.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_con">con</code></td>
<td>

<p>If this is TRUE (default) then the constant term is estimated, otherwise the model includes no constant term.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_b">B</code></td>
<td>

<p>If B is greater than 1 bootstrap estimates of the standard error are returned. If B=1, no standard errors are returned.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_ncores">ncores</code></td>
<td>

<p>If ncores is 2 or more parallel computing is performed. This is to be used for the case of bootstrap. If B=1, this is not taken into consideration.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson procedure.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of Newton-Raphson iterations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the kl.compreg() the Kullback-Leibler divergence is adopted as the objective function. In case of problematic
convergence the &quot;multinom&quot; function by the &quot;nnet&quot; package is employed. This will obviously be slower. The
js.compreg() uses the Jensen-Shannon divergence and the symkl.compreg() uses the symmetric Kullback-Leibler divergence.
The tv.compreg() uses the Total Variation divergence. There is no actual log-likelihood for the last three regression models.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson in the kl.compreg function.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood. This is actually a quasi multinomial regression. This is bascially half the negative deviance, or
<code class="reqn">- \sum_{i=1}^ny_i\log{y_i/\hat{y}_i}</code>.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>covbe</code></td>
<td>

<p>The covariance matrix of the beta coefficients, if bootstrap is chosen, i.e. if B &gt; 1.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Murteira, Jose MR, and Joaquim JS Ramalho 2016. Regression analysis of multivariate fractional data.
Econometric Reviews 35(4): 515-552.
</p>
<p>Tsagris, Michail (2015). A novel, divergence based, regression for compositional data.
Proceedings of the 28th Panhellenic Statistics Conference, 15-18/4/2015, Athens, Greece.
https://arxiv.org/pdf/1511.07600.pdf
</p>
<p>Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability distributions.
Information Theory, IEEE Transactions on 49, 1858-1860.
</p>
<p>Osterreicher, F. and Vajda, I. (2003). A new class of metric divergences on probability
spaces and its applicability in statistics. Annals of the Institute of Statistical
Mathematics 55, 639-653.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.vector(fgl[, 1])
y &lt;- as.matrix(fgl[, 2:9])
y &lt;- y / rowSums(y)
mod1&lt;- kl.compreg(y, x, B = 1, ncores = 1)
mod2 &lt;- js.compreg(y, x, B = 1, ncores = 1)
</code></pre>

<hr>
<h2 id='Divergence+20based+20regression+20for+20compositional+20data+20with+20compositional+20data+20in+20the+20covariates+20side+20using+20the+20alpha-transformation'>
Divergence based regression for compositional data with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+kl.alfapcr'></span>

<h3>Description</h3>

<p>Divergence based regression for compositional data with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kl.alfapcr(y, x, covar = NULL, a, k, xnew = NULL, B = 1, ncores = 1, tol = 1e-07,
maxiters = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numerical matrixc with compositional data with or without zeros.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_covar">covar</code></td>
<td>

<p>If you have other covariates as well put themn here.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_k">k</code></td>
<td>

<p>A number at least equal to 1. How many principal components to use.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted. If you have no new data,
leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_b">B</code></td>
<td>

<p>If B is greater than 1 bootstrap estimates of the standard error are returned. If B=1, no standard errors are returned.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_ncores">ncores</code></td>
<td>

<p>If ncores is 2 or more parallel computing is performed. This is to be used for the case of bootstrap.
If B=1, this is not taken into consideration.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson procedure.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of Newton-Raphson iterations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first, the first k principal component scores are calcualted and used as predictor variables for the Kullback-Leibler divergence based regression model.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson in the kl.compreg function.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood. This is actually a quasi multinomial regression. This is bascially minus the half deviance, or
<code class="reqn">- sum_{i=1}^ny_i\log{y_i/\hat{y}_i}</code>.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the beta coefficients, if bootstrap is chosen, i.e. if B &gt; 1.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Initial code by Abdulaziz Alenazi. Modifications by Michail Tsagris.
</p>
<p>R implementation and documentation: Abdulaziz Alenazi <a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a> 
and Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Alenazi A. (2019). Regression for compositional data with compositional data as predictor variables with or without zero values.
Journal of Data Science, 17(1): 219-238.
https://jds-online.org/journal/JDS/article/136/file/pdf
</p>
<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. Chilean Journal of Statistics, 6(2): 47-57.
http://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
http://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+klalfapcr.tune">klalfapcr.tune</a>, <a href="#topic+tflr">tflr</a>, <a href="#topic+pcr">pcr</a>, <a href="#topic+glm.pcr">glm.pcr</a>, <a href="#topic+alfapcr.tune">alfapcr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- rdiri(214, runif(4, 1, 3))
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
mod &lt;- alfa.pcr(y = y, x = x, a = 0.7, k = 1)
mod
</code></pre>

<hr>
<h2 id='Divergence+20matrix+20of+20compositional+20data'>
Divergence matrix of compositional data
</h2><span id='topic+divergence'></span>

<h3>Description</h3>

<p>Divergence matrix of compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divergence(x, type = "kullback_leibler", vector = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Divergence+2B20matrix+2B20of+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20matrix+2B20of+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>This is either &quot;kullback_leibler&quot; (Kullback-Leibler, which computes the symmetric Kullback-Leibler divergence) or &quot;jensen_shannon&quot; (Jensen-Shannon) divergence.
</p>
</td></tr>
<tr><td><code id="Divergence+2B20matrix+2B20of+2B20compositional+2B20data_+3A_vector">vector</code></td>
<td>

<p>For return a vector instead a matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces the distance matrix either using the Kullback-Leibler (distance) or the Jensen-Shannon (metric) divergence. The Kullback-Leibler refers to the symmetric Kullback-Leibler divergence.
</p>


<h3>Value</h3>

<p>if the vector argument is FALSE a symmetric matrix with the divergences, otherwise a vector with the divergences.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability distributions.
Information Theory, IEEE Transactions on 49, 1858-1860.
</p>
<p>Osterreicher, F. and Vajda, I. (2003). A new class of metric divergences on probability
spaces and its applicability in statistics. Annals of the Institute of Statistical
Mathematics 55, 639-653.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.knn">comp.knn</a>, <a href="#topic+js.compreg">js.compreg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:20, 1:4])
x &lt;- x / rowSums(x)
divergence(x)
</code></pre>

<hr>
<h2 id='Energy+20test+20of+20equality+20of+20distributions+20using+20the+20alpha-transformation'>
Energy test of equality of distributions using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+aeqdist.etest'></span>

<h3>Description</h3>

<p>Energy test of equality of distributions using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aeqdist.etest(x, sizes, a = 1, R = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Energy+2B20test+2B20of+2B20equality+2B20of+2B20distributions+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data with all groups stacked one under the other.
</p>
</td></tr>
<tr><td><code id="Energy+2B20test+2B20of+2B20equality+2B20of+2B20distributions+2B20using+2B20the+2B20alpha-transformation_+3A_sizes">sizes</code></td>
<td>

<p>A numeric vector matrix with the sample sizes.
</p>
</td></tr>
<tr><td><code id="Energy+2B20test+2B20of+2B20equality+2B20of+2B20distributions+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero
values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric
log-ratio transformation is applied. If more than one values are supplied the
energy distance of equality of distributions is applied for each value of
<code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code id="Energy+2B20test+2B20of+2B20equality+2B20of+2B20distributions+2B20using+2B20the+2B20alpha-transformation_+3A_r">R</code></td>
<td>

<p>The number of permutations to apply in order to compute the approximate p-value.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to each composition and then the
energy distance of equality of distributions is applied for each value of
<code class="reqn">\alpha</code> or for the single value of <code class="reqn">\alpha</code>.
</p>


<h3>Value</h3>

<p>A numerical value or a numerical vector, depending on the length of the values
of <code class="reqn">\alpha</code>, with the approximate p-value(s) of the energy test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Szekely, G. J. and Rizzo, M. L. (2004) Testing for Equal Distributions in
High Dimension. InterStat, November (5).
</p>
<p>Szekely, G. J. (2000) Technical Report 03-05: E-statistics: Energy of
Statistical Samples. Department of Mathematics and Statistics,
Bowling Green State University.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power
transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acor">acor</a>, <a href="#topic+acor.tune">acor.tune</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfa.profile">alfa.profile</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rdiri(50, c(3, 4, 5) )
x &lt;- rdiri(60, c(3, 4, 5) )
aeqdist.etest( rbind(x, y), c(dim(x)[1], dim(y)[1]), a = c(-1, 0, 1) )
</code></pre>

<hr>
<h2 id='Estimating+20location+20and+20scatter+20parameters+20for+20compositional+20data'>
Estimating location and scatter parameters for compositional data
</h2><span id='topic+comp.den'></span>

<h3>Description</h3>

<p>Estimating location and scatter parameters for compositional data in a robust and non robust way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.den(x, type = "alr", dist = "normal", tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimating+2B20location+2B20and+2B20scatter+2B20parameters+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix containing compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Estimating+2B20location+2B20and+2B20scatter+2B20parameters+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>A boolean variable indicating the transformation to be used. Either &quot;alr&quot; or &quot;ilr&quot; corresponding to the additive or the 
isometric log-ratio transformation respectively.
</p>
</td></tr>
<tr><td><code id="Estimating+2B20location+2B20and+2B20scatter+2B20parameters+2B20for+2B20compositional+2B20data_+3A_dist">dist</code></td>
<td>

<p>Takes values &quot;normal&quot;, &quot;t&quot;, &quot;skewnorm&quot;, &quot;rob&quot; and &quot;spatial&quot;. They first three options correspond to the parameters of the normal, t 
and skew normal distribution respectively. If it set to &quot;rob&quot; the MCD estimates are computed and if set to &quot;spatial&quot; the spatial 
median and spatial sign covariance matrix are computed.
</p>
</td></tr>
<tr><td><code id="Estimating+2B20location+2B20and+2B20scatter+2B20parameters+2B20for+2B20compositional+2B20data_+3A_tol">tol</code></td>
<td>

<p>A tolerance level to terminate the process of finding the spatial median when dist = &quot;spatial&quot;. This is set to 1e-09 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates robust and non robust estimates of location and scatter.
</p>


<h3>Value</h3>

<p>A list including:
The mean vector and covariance matrix mainly. Other parameters are also returned depending on the value of the argument &quot;dist&quot;.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>P. J. Rousseeuw and K. van Driessen (1999) A fast algorithm for the minimum covariance determinant estimator. Technometrics 41, 212-223.
</p>
<p>Mardia K.V., Kent J.T., and Bibby J.M. (1979). Multivariate analysis. Academic press.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>T. Karkkaminen and S. Ayramo (2005). On computation of spatial median for robust data mining. Evolutionary and Deterministic Methods for Design, 
Optimization  and Control with Applications to Industrial and Societal Problems EUROGEN 2005.
</p>
<p>A Durre, D Vogel, DE Tyler (2014). The spatial sign covariance matrix with unknown location.  Journal of Multivariate Analysis, 130: 107-117.
</p>
<p>J. T. Kent, D. E. Tyler and Y. Vardi (1994) A curious likelihood identity for the multivariate t-distribution. 
Communications in Statistics-Simulation and Computation 23, 441-453.
</p>
<p>Azzalini A. and Dalla Valle A. (1996). The multivariate skew-normal distribution. Biometrika 83(4): 715-726.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+spatmed.reg">spatmed.reg</a>, <a href="#topic+multivt">multivt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
comp.den(x)
comp.den(x, type = "alr", dist = "t")
comp.den(x, type = "alr", dist = "spatial")
</code></pre>

<hr>
<h2 id='Estimation+20of+20the+20probability+20left+20outside+20the+20simplex+20when+20using+20the+20alpha-transformation'>
Estimation of the probability left outside the simplex when using the alpha-transformation
</h2><span id='topic+probout'></span>

<h3>Description</h3>

<p>Estimation of the probability left outside the simplex when using the alpha-transformationn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probout(mu, su, a) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimation+2B20of+2B20the+2B20probability+2B20left+2B20outside+2B20the+2B20simplex+2B20when+2B20using+2B20the+2B20alpha-transformation_+3A_mu">mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Estimation+2B20of+2B20the+2B20probability+2B20left+2B20outside+2B20the+2B20simplex+2B20when+2B20using+2B20the+2B20alpha-transformation_+3A_su">su</code></td>
<td>

<p>The covariance matrix.
</p>
</td></tr>
<tr><td><code id="Estimation+2B20of+2B20the+2B20probability+2B20left+2B20outside+2B20the+2B20simplex+2B20when+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When applying the <code class="reqn">\alpha</code>-transformation based on a multivariate normal there might be 
probability left outside the simplex as the space of this transformation is a subspace of the 
Euclidean space. The function estimates the missing probability via Monte Carlo simulation using
40 million generated vectors.
</p>


<h3>Value</h3>

<p>The estimated probability left outside the simplex.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2020). A folded model for compositional data analysis. 
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation 
for compositional data. In Proceedings of the 4th Compositional Data Analysis Workshop, 
Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alpha.mle">alpha.mle</a>, <a href="#topic+a.est">a.est</a>, <a href="#topic+rfolded">rfolded</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
s &lt;-  c(0.1490676523, -0.4580818209,  0.0020395316, -0.0047446076, -0.4580818209,
1.5227259250,  0.0002596411,  0.0074836251,  0.0020395316,  0.0002596411,
0.0365384838, -0.0471448849, -0.0047446076,  0.0074836251, -0.0471448849,
0.0611442781)
s &lt;- matrix(s, ncol = 4)
m &lt;- c(1.715, 0.914, 0.115, 0.167)
probout(m, s, 0.5)

</code></pre>

<hr>
<h2 id='Estimation+20of+20the+20value+20of+20alpha+20in+20the+20folded+20model'>
Estimation of the value of <code class="reqn">\alpha</code> in the folded model
</h2><span id='topic+a.est'></span>

<h3>Description</h3>

<p>Estimation of the value of <code class="reqn">\alpha</code> in the folded model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>a.est(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimation+2B20of+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20folded+2B20model_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero vaues are allowed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a function for choosing or estimating the value of <code class="reqn">\alpha</code>
in the folded model (Tsagris and Stewart, 2020).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the algorithm.
</p>
</td></tr>
<tr><td><code>best</code></td>
<td>

<p>The estimated optimal <code class="reqn">\alpha</code> of the folded model.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The maximimised log-likelihood of the folded model.
</p>
</td></tr>
<tr><td><code>p</code></td>
<td>

<p>The estimated probability inside the simplex of the folded model.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The estimated mean vector of the folded model.
</p>
</td></tr>
<tr><td><code>su</code></td>
<td>

<p>The estimated covariance matrix of the folded model.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2022). A Review of Flexible Transformations for Modeling Compositional Data. In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234.
https://link.springer.com/chapter/10.1007/978-3-031-08329-7_10
</p>
<p>Tsagris M. and Stewart C. (2020). A folded model for compositional data analysis.
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation
for compositional data. In Proceedings of the 4th Compositional Data Analysis
Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.profile">alfa.profile</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>, <a href="#topic+alpha.mle">alpha.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
alfa.tune(x)
a.est(x)
</code></pre>

<hr>
<h2 id='Estimation+20of+20the+20value+20of+20alpha+20via+20the+20profile+20log-likelihood'>
Estimation of the value of <code class="reqn">\alpha</code> via the alfa profile log-likelihood
</h2><span id='topic+alfa.profile'></span>

<h3>Description</h3>

<p>Estimation of the value of <code class="reqn">\alpha</code> via the alfa profile log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.profile(x, a = seq(-1, 1, by = 0.01))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimation+2B20of+2B20the+2B20value+2B20of+2B20alpha+2B20via+2B20the+2B20profile+2B20log-likelihood_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are not allowed.
</p>
</td></tr>
<tr><td><code id="Estimation+2B20of+2B20the+2B20value+2B20of+2B20alpha+2B20via+2B20the+2B20profile+2B20log-likelihood_+3A_a">a</code></td>
<td>

<p>A grid of values of <code class="reqn">\alpha</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For every value of <code class="reqn">\alpha</code> the normal likelihood (see the refernece) is computed. At the end, the plot of the values is constructed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>res</code></td>
<td>

<p>The chosen value of <code class="reqn">\alpha</code>, the corresponding log-likelihood value and the log-likelihood when <code class="reqn">\alpha=0</code>.
</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>

<p>An asympotic 95% confidence interval computed from the log-likelihood ratio test.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> 
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.tune">alfa.tune</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
alfa.tune(x)
alfa.profile(x)
</code></pre>

<hr>
<h2 id='Fast+20estimation+20of+20the+20value+20of+20alpha'>
Fast estimation of the value of <code class="reqn">\alpha</code>
</h2><span id='topic+alfa.tune'></span>

<h3>Description</h3>

<p>Fast estimation of the value of <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.tune(x, B = 1, ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fast+2B20estimation+2B20of+2B20the+2B20value+2B20of+2B20alpha_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero vaues are allowed.
</p>
</td></tr>
<tr><td><code id="Fast+2B20estimation+2B20of+2B20the+2B20value+2B20of+2B20alpha_+3A_b">B</code></td>
<td>

<p>If no (bootstrap based) confidence intervals should be returned this should be 1 and more than 1 otherwise.
</p>
</td></tr>
<tr><td><code id="Fast+2B20estimation+2B20of+2B20the+2B20value+2B20of+2B20alpha_+3A_ncores">ncores</code></td>
<td>

<p>If ncores is greater than 1 parallel computing is performed. It is advisable to use it if you have many observations and or many variables, otherwise it will slow down th process.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a faster function than <code><a href="#topic+alfa.profile">alfa.profile</a></code> for choosing the value of <code class="reqn">\alpha</code>.
</p>


<h3>Value</h3>

<p>A vector with the best alpha, the maximised log-likelihood and the log-likelihood at <code class="reqn">\alpha=0</code>, when B = 1 (no bootstrap). If B&gt;1 a list including:
</p>
<table>
<tr><td><code>param</code></td>
<td>

<p>The best alpha and the value of the log-likelihod, along with the 95% bootstrap based confidence intervals.
</p>
</td></tr>
<tr><td><code>message</code></td>
<td>

<p>A message with some information about the histogram.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time (in seconds) of the process.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.profile">alfa.profile</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
alfa.tune(x)
alfa.profile(x)
</code></pre>

<hr>
<h2 id='Fitting+20a+20Flexible+20Dirichlet+20distribution'>
Fitting a Flexible Dirichlet distribution
</h2><span id='topic+fd.est'></span>

<h3>Description</h3>

<p>Fitting a Flexible Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fd.est(x, ini.iter = 50, final.iter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fitting+2B20a+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix or a dataframe containing the compositional data.
</p>
</td></tr>
<tr><td><code id="Fitting+2B20a+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_ini.iter">ini.iter</code></td>
<td>

<p>Number of iterations for the initial SEM step. Default value is 50.
</p>
</td></tr>
<tr><td><code id="Fitting+2B20a+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_final.iter">final.iter</code></td>
<td>

<p>Number of iterations for the final EM step. Default value is 100.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information see the references.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>

<p>Estimated values of the parameter vector <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>

<p>Estimated values of the parameter vector p.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>Estimated value of the parameter <code class="reqn">tau</code>.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The Log-likelihood value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris ported from the R package FlexDir. <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ongaro A. and Migliorati S. (2013). A generalization of the Dirichlet distribution.
Journal of Multivariate Analysis, 114, 412&ndash;426.
</p>
<p>Migliorati S., Ongaro A. and Monti G. S. (2017). A structured Dirichlet mixture model for compositional data: inferential and applicative issues. Statistics and Computing, 27, 963&ndash;983.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rfd">rfd</a>, <a href="#topic+rfd">rfd</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rfd(n = 50, a = c(12, 11, 10), p = c(0.25, 0.25, 0.5), tau = 4 )
ela &lt;- fd.est(x, ini.iter = 10, final.iter = 20)
ela

</code></pre>

<hr>
<h2 id='Gaussian+20mixture+20models+20for+20compositional+20data'>
Gaussian mixture models for compositional data
</h2><span id='topic+mix.compnorm'></span>

<h3>Description</h3>

<p>Gaussian mixture models for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix.compnorm(x, g, model, type = "alr", veo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data_+3A_g">g</code></td>
<td>

<p>How many clusters to create.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data_+3A_model">model</code></td>
<td>

<p>The type of model to be used.
</p>

<ol>
<li><p> &quot;EII&quot;: All groups have the same diagonal covariance matrix, with the same variance for all variables.
</p>
</li>
<li><p> &quot;VII&quot;: Different diagonal covariance matrices, with the same variance for all variables within each group.
</p>
</li>
<li><p> &quot;EEI&quot;: All groups have the same diagonal covariance matrix.
</p>
</li>
<li><p> &quot;VEI&quot;: Different diagonal covariance matrices. If we make all covariance matrices have determinant 1,
(divide the matrix
with the $p$-th root of its determinant) then all covariance matrices will be the same.
</p>
</li>
<li><p> &quot;EVI&quot;: Different diagonal covariance matrices with the same determinant.
</p>
</li>
<li><p> &quot;VVI&quot;: Different diagonal covariance matrices, with nothing in common.
</p>
</li>
<li><p> &quot;EEE&quot;: All covariance matrices are the same.
</p>
</li>
<li><p> &quot;EEV&quot;: Different covariance matrices, but with the same determinant and in addition, if we make them
have determinant 1,
they will have the same trace.
</p>
</li>
<li><p> &quot;VEV&quot;: Different covariance matrices but if we make the matrices have determinant 1, then they will
have the same trace.
</p>
</li>
<li><p> &quot;VVV&quot;: Different covariance matrices with nothing in common.
</p>
</li>
<li><p> &quot;EVE&quot;: Different covariance matrices, but with the same determinant. In addition, calculate the
eigenvectors for each covariance matrix and you will see the extra similarities.
</p>
</li>
<li><p> &quot;VVE&quot;: Different covariance matrices, but they have something in common with their directions.
Calculate the eigenvectors of each covariance matrix and you will see the similarities.
</p>
</li>
<li><p> &quot;VEE&quot;: Different covariance matrices, but if we make the matrices have determinant 1, then they will
have the same trace.
In addition, calculate the eigenvectors for each covariance matrix and you will see the extra similarities.
</p>
</li>
<li><p> &quot;EVV&quot;: Different covariance matrices, but with the same determinant.
</p>
</li></ol>

</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>The type of trasformation to be used, either the additive log-ratio (&quot;alr&quot;), the isometric log-ratio (&quot;ilr&quot;)
or the pivot coordinate (&quot;pivot&quot;) transformation.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data_+3A_veo">veo</code></td>
<td>

<p>Stands for &quot;Variables exceed observations&quot;. If TRUE then if the number variablesin the model exceeds
the number
of observations, but the model is still fitted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A log-ratio transformation is applied and then a Gaussian mixture model is constructed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mu</code></td>
<td>

<p>A matrix where each row corresponds to the mean vector of each cluster.
</p>
</td></tr>
<tr><td><code>su</code></td>
<td>

<p>An array containing the covariance matrix of each cluster.
</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>

<p>The estimated mixing probabilities.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated cluster membership values.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2015). R package mixture: Mixture Models
for Clustering and Classification.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bic.mixcompnorm">bic.mixcompnorm</a>, <a href="#topic+rmixcomp">rmixcomp</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+alfa.mix.norm">alfa.mix.norm</a>,
<a href="#topic+alfa.knn">alfa.knn</a>,
<a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+comp.nb">comp.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/ rowSums(x)
mod1 &lt;- mix.compnorm(x, 3, model = "EII" )
mod2 &lt;- mix.compnorm(x, 4, model = "VII")

</code></pre>

<hr>
<h2 id='Gaussian+20mixture+20models+20for+20compositional+20data+20using+20the+20alpha-transformation'>
Gaussian mixture models for compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.mix.norm'></span>

<h3>Description</h3>

<p>Gaussian mixture models for compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.mix.norm(x, g, a, model, veo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_g">g</code></td>
<td>

<p>How many clusters to create.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_model">model</code></td>
<td>

<p>The type of model to be used.
</p>

<ol>
<li><p> &quot;EII&quot;: All groups have the same diagonal covariance matrix, with the same variance for all variables.
</p>
</li>
<li><p> &quot;VII&quot;: Different diagonal covariance matrices, with the same variance for all variables within each group.
</p>
</li>
<li><p> &quot;EEI&quot;: All groups have the same diagonal covariance matrix.
</p>
</li>
<li><p> &quot;VEI&quot;: Different diagonal covariance matrices. If we make all covariance matrices have determinant 1, (divide the matrix with the $p$-th root of its determinant) then all covariance matrices will be the same.
</p>
</li>
<li><p> &quot;EVI&quot;: Different diagonal covariance matrices with the same determinant.
</p>
</li>
<li><p> &quot;VVI&quot;: Different diagonal covariance matrices, with nothing in common.
</p>
</li>
<li><p> &quot;EEE&quot;: All covariance matrices are the same.
</p>
</li>
<li><p> &quot;EEV&quot;: Different covariance matrices, but with the same determinant and in addition, if we make them have determinant 1, they will have the same trace.
</p>
</li>
<li><p> &quot;VEV&quot;: Different covariance matrices but if we make the matrices have determinant 1, then they will have the same trace.
</p>
</li>
<li><p> &quot;VVV&quot;: Different covariance matrices with nothing in common.
</p>
</li>
<li><p> &quot;EVE&quot;: Different covariance matrices, but with the same determinant. In addition, calculate the eigenvectors for each covariance matrix and you will see the extra similarities.
</p>
</li>
<li><p> &quot;VVE&quot;: Different covariance matrices, but they have something in common with their directions. Calculate the eigenvectors
of each covariance matrix and you will see the similarities.
</p>
</li>
<li><p> &quot;VEE&quot;: Different covariance matrices, but if we make the matrices have determinant 1, then they will have the same trace.
In addition, calculate the eigenvectors for each covariance matrix and you will see the extra similarities.
</p>
</li>
<li><p> &quot;EVV&quot;: Different covariance matrices, but with the same determinant.
</p>
</li></ol>

</td></tr>
<tr><td><code id="Gaussian+2B20mixture+2B20models+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_veo">veo</code></td>
<td>

<p>Stands for &quot;Variables exceed observations&quot;. If TRUE then if the number variablesin the model exceeds the number of observations, but the model is still fitted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A log-ratio transformation is applied and then a Gaussian mixture model is constructed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mu</code></td>
<td>

<p>A matrix where each row corresponds to the mean vector of each cluster.
</p>
</td></tr>
<tr><td><code>su</code></td>
<td>

<p>An array containing the covariance matrix of each cluster.
</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>

<p>The estimated mixing probabilities.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated cluster membership values.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2015). R package mixture: Mixture Models for Clustering and Classification.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bic.alfamixnorm">bic.alfamixnorm</a>, <a href="#topic+bic.mixcompnorm">bic.mixcompnorm</a>, <a href="#topic+rmixcomp">rmixcomp</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>,
<a href="#topic+alfa">alfa</a>, <a href="#topic+alfa.knn">alfa.knn</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+comp.nb">comp.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/ rowSums(x)
mod1 &lt;- alfa.mix.norm(x, 3, 0.4, model = "EII" )
mod2 &lt;- alfa.mix.norm(x, 4, 0.7, model = "VII")

</code></pre>

<hr>
<h2 id='Generalised+20Dirichlet+20random+20values+20simulation'>
Generalised Dirichlet random values simulation
</h2><span id='topic+rgendiri'></span>

<h3>Description</h3>

<p>Generalised Dirichlet random values simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgendiri(n, a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Generalised+2B20Dirichlet+2B20random+2B20values+2B20simulation_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Generalised+2B20Dirichlet+2B20random+2B20values+2B20simulation_+3A_a">a</code></td>
<td>

<p>A numerical vector with the shape parameter values of the Gamma distribution.
</p>
</td></tr>
<tr><td><code id="Generalised+2B20Dirichlet+2B20random+2B20values+2B20simulation_+3A_b">b</code></td>
<td>

<p>A numerical vector with the scale parameter values of the Gamma distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is straightforward, for each vector, independent gamma values are generated and
then divided by their total sum. The difference with <code><a href="#topic+rdiri">rdiri</a></code> is that
here the Gamma distributed variables are not equally scaled.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdiri">rdiri</a>, <a href="#topic+diri.est">diri.est</a>, <a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.contour">diri.contour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- c(1, 2, 3)
b &lt;- c(2, 3, 4)
x &lt;- rgendiri(100, a, b)
</code></pre>

<hr>
<h2 id='Generate+20random+20folds+20for+20cross-validation'>
Generate random folds for cross-validation
</h2><span id='topic+makefolds'></span>

<h3>Description</h3>

<p>Random folds for use in a cross validation are generated. There is the option for stratified splitting as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makefolds(ina, nfolds = 10, stratified = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_ina">ina</code></td>
<td>

<p>A variable indicating the groupings.
</p>
</td></tr>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to produce.
</p>
</td></tr>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_stratified">stratified</code></td>
<td>

<p>A boolean variable specifying whether stratified random (TRUE) or simple random (FALSE) sampling is to be used when producing the folds.
</p>
</td></tr>
<tr><td><code id="Generate+2B20random+2B20folds+2B20for+2B20cross-validation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>I was inspired by the command in the package <b>TunePareto</b> in order to do the stratified version.
</p>


<h3>Value</h3>

<p>A list with nfolds elements where each elements is a fold containing the indices of the data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compknn.tune">compknn.tune</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- makefolds(iris[, 5], nfolds = 5, stratified = TRUE)
table(iris[a[[1]], 5])  ## 10 values from each group
</code></pre>

<hr>
<h2 id='Greenacre+27s+20power+20transformation'>
Greenacre's power transformation
</h2><span id='topic+green'></span>

<h3>Description</h3>

<p>Greenacre's power transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>green(x, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Greenacre+2B27s+2B20power+2B20transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Greenacre+2B27s+2B20power+2B20transformation_+3A_theta">theta</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to
be greater than 0. If <code class="reqn">\theta=0</code> the log transformation is applied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Greenacre's transformation is applied to the compositional data.
</p>


<h3>Value</h3>

<p>A matrix with the power transformed data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Greenacre, M. (2009). Power transformations in correspondence analysis. Computational Statistics &amp; Data Analysis, 53(8): 3107-3116.
http://www.econ.upf.edu/~michael/work/PowerCA.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y1 &lt;- green(x, 0.1)
y2 &lt;- green(x, 0.2)
rbind( colMeans(y1), colMeans(y2) )
</code></pre>

<hr>
<h2 id='Helper+20Frechet+20mean+20for+20compositional+20data'>
Helper Frechet mean for compositional data
</h2><span id='topic+frechet2'></span>

<h3>Description</h3>

<p>Helper Frechet mean for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frechet2(x, di, a, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Helper+2B20Frechet+2B20mean+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Helper+2B20Frechet+2B20mean+2B20for+2B20compositional+2B20data_+3A_di">di</code></td>
<td>

<p>A matrix with indices as produced by the function &quot;dista&quot; of the package &quot;Rfast&quot;&quot; or the function &quot;nn&quot; 
of the package &quot;Rnanoflann&quot;. Better see the details section.
</p>
</td></tr>
<tr><td><code id="Helper+2B20Frechet+2B20mean+2B20for+2B20compositional+2B20data_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied and the closed geometric mean is calculated.
</p>
</td></tr>
<tr><td><code id="Helper+2B20Frechet+2B20mean+2B20for+2B20compositional+2B20data_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours used for the computation of the Frechet means.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power transformation is applied to the compositional data and the mean vector is calculated. Then the inverse of it is calculated and the inverse of the power transformation applied to the last vector is the Frechet mean.
</p>
<p>What this helper function do is to speed up the Frechet mean when used in the <code class="reqn">\alpha</code>-k-NN regression. The <code class="reqn">\alpha</code>-k-NN regression computes the Frechet mean of the k nearest neighbours for a value of <code class="reqn">\alpha</code> and this function does exactly that. Suppose you want to predict the compositional value of some new predictors. For each predictor value you must use the Frechet mean computed at various nearest neighbours. This function performs these computations in a fast way. It is not the fastest way, yet it is a pretty fast way. This function is being called inside the function <a href="#topic+aknn.reg">aknn.reg</a>.
</p>


<h3>Value</h3>

<p>A list where eqch element contains a matrix. Each matrix contains the Frechet means computed at various nearest neighbours.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data. In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>, <a href="stats.html#topic+profile">profile</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)
library(Rfast)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
xnew &lt;- x[1:10, ]
x &lt;- x[-c(1:10), ]
k &lt;- 2:5
di &lt;- Rfast::dista( xnew, x, k = max(k), index = TRUE, square = TRUE )
est &lt;- frechet2(x, di, 0.2, k)

</code></pre>

<hr>
<h2 id='Helper+20functions+20for+20the+20Kullback-Leibler+20regression'>
Helper functions for the Kullback-Leibler regression
</h2><span id='topic+kl.compreg2'></span><span id='topic+klcompreg.boot'></span>

<h3>Description</h3>

<p>Helper functions for the Kullback-Leibler regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kl.compreg2(y, x, con = TRUE, xnew = NULL, tol = 1e-07, maxiters = 50)
klcompreg.boot(y, x, der, der2, id, b1, n, p, d, tol = 1e-07, maxiters = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). Zero values are allowed. For the klcompreg.boot the first column is removed.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they can be either continuous or categorical or both. In the klcompreg.boot this is the design matrix.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_con">con</code></td>
<td>

<p>If this is TRUE (default) then the constant term is estimated, otherwise the model includes no constant term.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson procedure.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of Newton-Raphson iterations.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_der">der</code></td>
<td>

<p>An vector to put the first derivative there.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_der2">der2</code></td>
<td>

<p>An empty matrix to put the second derivatives there, the Hessian matrix will be put here.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_id">id</code></td>
<td>

<p>A help vector with indices.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_b1">b1</code></td>
<td>

<p>The matrix with the initial estimated coefficients.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_n">n</code></td>
<td>

<p>The sample size
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_p">p</code></td>
<td>

<p>The number of columns of the design matrix.
</p>
</td></tr>
<tr><td><code id="Helper+2B20functions+2B20for+2B20the+2B20Kullback-Leibler+2B20regression_+3A_d">d</code></td>
<td>

<p>The dimensionality of the simplex, that is the number of columns of the compositional data minus 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are help functions for the <code><a href="#topic+kl.compreg">kl.compreg</a></code> function. They are not to be called directly by the user.
</p>


<h3>Value</h3>

<p>For kl.compreg2 a list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The nubmer of iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The loglikelihood.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted or the predicted values (if xnew is not NULL).
</p>
</td></tr>
</table>
<p>For klcompreg.boot a list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The loglikelihood.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Murteira, Jose MR, and Joaquim JS Ramalho 2016. Regression analysis of multivariate fractional data.
Econometric Reviews 35(4): 515-552.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(MASS)
  x &lt;- as.vector(fgl[, 1])
  y &lt;- as.matrix(fgl[, 2:9])
  y &lt;- y / rowSums(y)
  mod1&lt;- kl.compreg(y, x, B = 1, ncores = 1)
  mod2 &lt;- js.compreg(y, x, B = 1, ncores = 1)
</code></pre>

<hr>
<h2 id='Hypothesis+20testing+20for+20two+20or+20more+20compositional+20mean+20vectors'>
Hypothesis testing for two or more compositional mean vectors
</h2><span id='topic+comp.test'></span>

<h3>Description</h3>

<p>Hypothesis testing for two or more compositional mean vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.test(x, ina, test = "james", R = 0, ncores = 1, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hypothesis+2B20testing+2B20for+2B20two+2B20or+2B20more+2B20compositional+2B20mean+2B20vectors_+3A_x">x</code></td>
<td>

<p>A matrix containing compositional data.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20testing+2B20for+2B20two+2B20or+2B20more+2B20compositional+2B20mean+2B20vectors_+3A_ina">ina</code></td>
<td>

<p>A numerical or factor variable indicating the groups of the data.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20testing+2B20for+2B20two+2B20or+2B20more+2B20compositional+2B20mean+2B20vectors_+3A_test">test</code></td>
<td>

<p>This can take the values of &quot;james&quot; for James' test, &quot;hotel&quot; for Hotelling's test, &quot;maov&quot; for multivariate analysis of variance assuming equality of the
covariance matrices, &quot;maovjames&quot; for multivariate analysis of variance without assuming equality of the covariance matrices. &quot;el&quot; for empirical likelihood
or &quot;eel&quot; for exponential empirical likelihood.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20testing+2B20for+2B20two+2B20or+2B20more+2B20compositional+2B20mean+2B20vectors_+3A_r">R</code></td>
<td>

<p>This depends upon the value of the argument &quot;test&quot;. If the test is &quot;maov&quot; or &quot;maovjames&quot;, R is not taken into consideration.
If test is &quot;hotel&quot;, then R denotes the number of bootstrap resamples. If test is &quot;james&quot;, then R can be 1 (chi-square distribution),
2 ( F distribution), or more for bootstrap calibration. If test is &quot;el&quot;, then R can be 0 (chi-square), 1 (corrected chi-sqaure), 2 (F distribution)
or more for bootstrap calibration. See the help page of each test for more information.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20testing+2B20for+2B20two+2B20or+2B20more+2B20compositional+2B20mean+2B20vectors_+3A_ncores">ncores</code></td>
<td>

<p>How many to cores to use. This is taken into consideration only if test is &quot;el&quot; and R is more than 2.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20testing+2B20for+2B20two+2B20or+2B20more+2B20compositional+2B20mean+2B20vectors_+3A_graph">graph</code></td>
<td>

<p>A boolean variable which is taken into consideration only when bootstrap calibration is performed. IF TRUE the histogram of the bootstrap test
statistic values is plotted. This is taken into account only when R is greater than 2.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The idea is to apply the <code class="reqn">\alpha</code>-transformation, with <code class="reqn">\alpha=1</code>, to the compositional data and then use a test to compare their mean vectors.
See the help page of each test for more information. The function is visible so you can see exactly what is going on.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>result</code></td>
<td>

<p>The outcome of each test.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M., Preston S. and Wood A.T.A. (2017). Nonparametric hypothesis testing for equality of means on the
simplex. Journal of Statistical Computation and Simulation, 87(2): 406-422.
</p>
<p>G.S. James (1954). Tests of Linear Hypothese in Univariate and Multivariate Analysis
when the Ratios of the Population Variances are Unknown. Biometrika, 41(1/2): 19-43
</p>
<p>Krishnamoorthy K. and Yanping Xia (2006).  On Selecting Tests for Equality of Two Normal Mean Vectors.
Multivariate Behavioral Research 41(4): 533-548.
</p>
<p>Owen A. B. (2001). Empirical likelihood. Chapman and Hall/CRC Press.
</p>
<p>Owen A.B. (1988). Empirical likelihood ratio confidence intervals for a single functional. Biometrika 75(2): 237-249.
</p>
<p>Amaral G.J.A., Dryden I.L. and Wood A.T.A. (2007). Pivotal bootstrap methods for k-sample problems in directional statistics and shape analysis.
Journal of the American Statistical Association 102(478): 695-707.
</p>
<p>Preston S.P. and Wood A.T.A. (2010). Two-Sample Bootstrap Hypothesis Tests for Three-Dimensional Labelled Landmark Data. Scandinavian Journal of Statistics 37(4): 568-587.
</p>
<p>Jing Bing-Yi and Andrew TA Wood (1996). Exponential empirical likelihood is not Bartlett correctable. Annals of Statistics 24(1): 365-369.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+hd.meantest2">hd.meantest2</a>, <a href="#topic+dptest">dptest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ina &lt;- rep(1:2, each = 50)
x &lt;- as.matrix(iris[1:100, 1:4])
x &lt;- x/ rowSums(x)
comp.test( x, ina, test = "james" )
comp.test( x, ina, test = "hotel" )
comp.test( x, ina, test = "el" )
comp.test( x, ina, test = "eel" )
</code></pre>

<hr>
<h2 id='ICE+20plot+20for+20projection+20pursuit+20regression+20with+20compositional+20predictor+20variables'>
ICE plot for projection pursuit regression with compositional predictor variables
</h2><span id='topic+ice.pprcomp'></span>

<h3>Description</h3>

<p>ICE plot for projection pursuit regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ice.pprcomp(model, x, k = 1, frac = 0.1, type = "log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICE+2B20plot+2B20for+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_model">model</code></td>
<td>

<p>The ppr model, the outcome of the <code><a href="#topic+pprcomp">pprcomp</a></code> function.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_k">k</code></td>
<td>

<p>Which variable to select?.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_frac">frac</code></td>
<td>

<p>Fraction of observations to use. The default value is 0.1.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_type">type</code></td>
<td>

<p>Either &quot;alr&quot; or &quot;log&quot; corresponding to the additive log-ratio transformation or the simple
logarithm applied to the compositional data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the Individual Conditional Expecation plots of Goldstein et al. (2015).
See the references for more details.
</p>


<h3>Value</h3>

<p>A graph with several curves. The horizontal axis contains the selected variable,
whereas the vertical axis contains the centered predicted values. The black curves
are the effects for each observation and the blue line is their average effect.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>https://christophm.github.io/interpretable-ml-book/ice.html
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J. and Pitkin, E. (2015).
Peeking inside the black box: Visualizing statistical
learning with plots of individual conditional expectation.
Journal of Computational and Graphical Statistics 24(1): 44-65.
</p>
<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression.
Journal of the American Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+pprcomp">pprcomp</a>, <a href="#topic+pprcomp.tune">pprcomp.tune</a>, <a href="#topic+ice.kernreg">ice.kernreg</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+lc.reg">lc.reg</a>, <a href="#topic+comp.ppr">comp.ppr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 2:4] )
x &lt;- x/ rowSums(x)
y &lt;- iris[, 1]
model &lt;- pprcomp(y, x)
ice &lt;- ice.pprcomp(model, x, k = 1)
</code></pre>

<hr>
<h2 id='ICE+20plot+20for+20the+20alpha-k-NN+20regression'>
ICE plot for the <code class="reqn">\alpha-k-NN</code> regression
</h2><span id='topic+ice.aknnreg'></span>

<h3>Description</h3>

<p>ICE plot for the <code class="reqn">\alpha-k-NN</code> regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ice.aknnreg(y, x, a, k, apostasi = "euclidean", rann = FALSE,
ind = 1, frac = 0.2, qpos = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response values.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_a">a</code></td>
<td>

<p>The value <code class="reqn">\alpha</code> to consider.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to consider.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use, either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_rann">rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use kd-trees implemented in the 
R package &quot;Rnanoflann&quot;. In this case you must set this argument equal to TRUE. 
Note however, that in this case, the only available distance is by default &quot;euclidean&quot;.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_ind">ind</code></td>
<td>

<p>Which variable to select?.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_frac">frac</code></td>
<td>

<p>Fraction of observations to use. The default value is 0.1.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-k-NN+2B20regression_+3A_qpos">qpos</code></td>
<td>

<p>A number between 0.8 and 1. This is used to place the legend of the figure better.
You can play with it. In the worst case scenario the code is open and you
tweak this argument as you prefer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the Individual Conditional Expecation plots of Goldstein et al. (2015).
See the references for more details.
</p>


<h3>Value</h3>

<p>A graph with several curves, one for each component. The horizontal axis contains the selected variable,
whereas the vertical axis contains the locally smoothed predicted compositional lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>https://christophm.github.io/interpretable-ml-book/ice.html
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J. and Pitkin, E. (2015).
Peeking inside the black box: Visualizing statistical
learning with plots of individual conditional expectation.
Journal of Computational and Graphical Statistics 24(1): 44-65.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ice.akernreg">ice.akernreg</a>, <a href="#topic+ice.pprcomp">ice.pprcomp</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 2:4] )
x &lt;- iris[, 1]
ice &lt;- ice.aknnreg(y, x, a = 0.6, k = 5, ind = 1)
</code></pre>

<hr>
<h2 id='ICE+20plot+20for+20the+20alpha-kernel+20regression'>
ICE plot for the <code class="reqn">\alpha</code>-kernel regression
</h2><span id='topic+ice.akernreg'></span>

<h3>Description</h3>

<p>ICE plot for the <code class="reqn">\alpha</code>-kernel regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ice.akernreg(y, x, a, h, type = "gauss", ind = 1, frac = 0.1, qpos = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response values.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_a">a</code></td>
<td>

<p>The value <code class="reqn">\alpha</code> to consider.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_h">h</code></td>
<td>

<p>The bandwidth value to consider.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_type">type</code></td>
<td>

<p>The type of kernel to use, &quot;gauss&quot; or &quot;laplace&quot;.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_ind">ind</code></td>
<td>

<p>Which variable to select?.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_frac">frac</code></td>
<td>

<p>Fraction of observations to use. The default value is 0.1.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20the+2B20alpha-kernel+2B20regression_+3A_qpos">qpos</code></td>
<td>

<p>A number between 0.8 and 1. This is used to place the legend of the figure better.
You can play with it. In the worst case scenario the code is open and you
tweak this argument as you prefer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the Individual Conditional Expecation plots of Goldstein et al. (2015).
See the references for more details.
</p>


<h3>Value</h3>

<p>A graph with several curves, one for each component. The horizontal axis contains the selected variable,
whereas the vertical axis contains the locally smoothed predicted compositional lines.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>https://christophm.github.io/interpretable-ml-book/ice.html
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J. and Pitkin, E. (2015).
Peeking inside the black box: Visualizing statistical
learning with plots of individual conditional expectation.
Journal of Computational and Graphical Statistics 24(1): 44-65.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ice.aknnreg">ice.aknnreg</a>, <a href="#topic+ice.pprcomp">ice.pprcomp</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 2:4] )
x &lt;- iris[, 1]
ice &lt;- ice.akernreg(y, x, a = 0.6, h = 0.1, ind = 1)
</code></pre>

<hr>
<h2 id='ICE+20plot+20for+20univariate+20kernel+20regression'>
ICE plot for univariate kernel regression
</h2><span id='topic+ice.kernreg'></span>

<h3>Description</h3>

<p>ICE plot for univariate kernel regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ice.kernreg(y, x, h, type = "gauss", k = 1, frac = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICE+2B20plot+2B20for+2B20univariate+2B20kernel+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response values.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20univariate+2B20kernel+2B20regression_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20univariate+2B20kernel+2B20regression_+3A_h">h</code></td>
<td>

<p>The bandwidth value to consider.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20univariate+2B20kernel+2B20regression_+3A_type">type</code></td>
<td>

<p>The type of kernel to use, &quot;gauss&quot; or &quot;laplace&quot;.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20univariate+2B20kernel+2B20regression_+3A_k">k</code></td>
<td>

<p>Which variable to select?.
</p>
</td></tr>
<tr><td><code id="ICE+2B20plot+2B20for+2B20univariate+2B20kernel+2B20regression_+3A_frac">frac</code></td>
<td>

<p>Fraction of observations to use. The default value is 0.1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the Individual Conditional Expecation plots of Goldstein et al. (2015).
See the references for more details.
</p>


<h3>Value</h3>

<p>A graph with several curves. The horizontal axis contains the selected variable,
whereas the vertical axis contains the centered predicted values. The black curves
are the effects for each observation and the blue line is their average effect.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>https://christophm.github.io/interpretable-ml-book/ice.html
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J. and Pitkin, E. (2015).
Peeking inside the black box: Visualizing statistical
learning with plots of individual conditional expectation.
Journal of Computational and Graphical Statistics 24(1): 44-65.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ice.pprcomp">ice.pprcomp</a>, <a href="#topic+kernreg.tune">kernreg.tune</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+lc.reg">lc.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 2:4] )
y &lt;- iris[, 1]
ice &lt;- ice.kernreg(y, x, h = 0.1, k = 1)
</code></pre>

<hr>
<h2 id='Inverse+20of+20the+20alpha-transformation'>
Inverse of the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfainv'></span>

<h3>Description</h3>

<p>The inverse of the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfainv(x, a, h = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inverse+2B20of+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with Euclidean data. However, they must lie within the feasible,
acceptable space. See references for more information.
</p>
</td></tr>
<tr><td><code id="Inverse+2B20of+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1.
If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code>,
the inverse of the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Inverse+2B20of+2B20the+2B20alpha-transformation_+3A_h">h</code></td>
<td>

<p>If h = TRUE this means that the multiplication with the Helmer sub-matrix
will take place. It is set to TRUe by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inverse of the <code class="reqn">\alpha</code>-transformation is applied to the data.
If the data lie outside the <code class="reqn">\alpha</code>-space, NAs will be returned for
some values.
</p>


<h3>Value</h3>

<p>A matrix with the pairwise distances.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2022). A Review of Flexible Transformations for Modeling Compositional Data. 
In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234.
https://link.springer.com/chapter/10.1007/978-3-031-08329-7_10
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2016). Improved classification for
compositional data using the <code class="reqn">\alpha</code>-transformation. 
Journal of Classification 33(2): 243&ndash;261.
https://arxiv.org/pdf/1506.04976v2.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power
transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alfadist">alfadist</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[1:10, 2:9])
x &lt;- x / rowSums(x)
y &lt;- alfa(x, 0.5)$aff
alfainv(y, 0.5)
</code></pre>

<hr>
<h2 id='Kernel+20regression+20with+20a+20numerical+20response+20vector+20or+20matrix'>
Kernel regression with a numerical response vector or matrix
</h2><span id='topic+kern.reg'></span>

<h3>Description</h3>

<p>Kernel regression (Nadaraya-Watson estimator) with a numerical response vector or matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern.reg(xnew, y, x, h = seq(0.1, 1, length = 10), type = "gauss" )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kernel+2B20regression+2B20with+2B20a+2B20numerical+2B20response+2B20vector+2B20or+2B20matrix_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new predictor variables whose compositions are to be predicted.
</p>
</td></tr>
<tr><td><code id="Kernel+2B20regression+2B20with+2B20a+2B20numerical+2B20response+2B20vector+2B20or+2B20matrix_+3A_y">y</code></td>
<td>

<p>A numerical vector or a matrix with the response value.
</p>
</td></tr>
<tr><td><code id="Kernel+2B20regression+2B20with+2B20a+2B20numerical+2B20response+2B20vector+2B20or+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with the available predictor variables.
</p>
</td></tr>
<tr><td><code id="Kernel+2B20regression+2B20with+2B20a+2B20numerical+2B20response+2B20vector+2B20or+2B20matrix_+3A_h">h</code></td>
<td>

<p>The bandwidth value(s) to consider.
</p>
</td></tr>
<tr><td><code id="Kernel+2B20regression+2B20with+2B20a+2B20numerical+2B20response+2B20vector+2B20or+2B20matrix_+3A_type">type</code></td>
<td>

<p>The type of kernel to use, &quot;gauss&quot; or &quot;laplace&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Nadaraya-Watson estimator regression is applied.
</p>


<h3>Value</h3>

<p>The fitted values. If a single bandwidth is considered then this is a vector or a matrix, depeding on the nature of the response. If multiple bandwidth values are considered then this is a matrix, if the response is a vector, or a list, if the response is a matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Wand M. P. and Jones M. C. (1994). Kernel smoothing. CRC press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kernreg.tune">kernreg.tune</a>, <a href="#topic+ice.kernreg">ice.kernreg</a>, <a href="#topic+akern.reg">akern.reg</a>, <a href="#topic+aknn.reg">aknn.reg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- iris[, 2:4]
est &lt;- kern.reg(x, y, x, h = c(0.1, 0.2) )
</code></pre>

<hr>
<h2 id='Kullback-Leibler+20divergence+20and+20Bhattacharyya+20distance+20between+20two+20Dirichlet+20distributions'>
Kullback-Leibler divergence and Bhattacharyya distance between two Dirichlet distributions
</h2><span id='topic+kl.diri'></span>

<h3>Description</h3>

<p>Kullback-Leibler divergence and Bhattacharyya distance between two Dirichlet distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kl.diri(a, b, type = "KL")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kullback-Leibler+2B20divergence+2B20and+2B20Bhattacharyya+2B20distance+2B20between+2B20two+2B20Dirichlet+2B20distributions_+3A_a">a</code></td>
<td>

<p>A vector with the parameters of the first Dirichlet distribution.
</p>
</td></tr>
<tr><td><code id="Kullback-Leibler+2B20divergence+2B20and+2B20Bhattacharyya+2B20distance+2B20between+2B20two+2B20Dirichlet+2B20distributions_+3A_b">b</code></td>
<td>

<p>A vector with the parameters of the second Dirichlet distribution.
</p>
</td></tr>
<tr><td><code id="Kullback-Leibler+2B20divergence+2B20and+2B20Bhattacharyya+2B20distance+2B20between+2B20two+2B20Dirichlet+2B20distributions_+3A_type">type</code></td>
<td>

<p>A variable indicating whether the Kullback-Leibler divergence (&quot;KL&quot;) or the Bhattacharyya distance (&quot;bhatt&quot;) is to be computed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the order is important in the Kullback-Leibler divergence, since this is asymmetric, but not in the Bhattacharyya distance, since it is a metric.
</p>


<h3>Value</h3>

<p>The value of the Kullback-Leibler divergence or the Bhattacharyya distance.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.est">diri.est</a>, <a href="#topic+diri.nr">diri.nr</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
a &lt;- runif(10, 0, 20)
b &lt;- runif(10, 1, 10)
kl.diri(a, b)
kl.diri(b, a)
kl.diri(a, b, type = "bhatt")
kl.diri(b, a, type = "bhatt")
</code></pre>

<hr>
<h2 id='LASSO+20Kullback-Leibler+20divergence+20based+20regression'>
LASSO Kullback-Leibler divergence based regression
</h2><span id='topic+lasso.klcompreg'></span>

<h3>Description</h3>

<p>LASSO Kullback-Leibler divergence based regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso.klcompreg(y, x, alpha = 1, lambda = NULL,
nlambda = 100, type = "grouped", xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical matrix with compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_x">x</code></td>
<td>

<p>A numerical matrix containing the predictor variables.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_alpha">alpha</code></td>
<td>

<p>The elastic net mixing parameter, with <code class="reqn">0 \leq \alpha \leq 1</code>. The penalty is defined as a 
weighted combination of the ridge and of the Lasso regression. When <code class="reqn">\alpha=1</code> LASSO is applied, 
while <code class="reqn">\alpha=0</code> yields the ridge regression.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_lambda">lambda</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b> A user supplied lambda sequence. 
Typical usage is to have the program compute its own lambda sequence based on nlambda and lambda.min.ratio. 
Supplying a value of lambda overrides this. WARNING: use with care. Avoid supplying a single value for 
lambda (for predictions after CV use predict() instead). Supply instead a decreasing sequence of lambda values. 
glmnet relies on its warms starts for speed, and its often faster to fit a whole path than compute a single fit.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_nlambda">nlambda</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b> The number of <code class="reqn">lambda</code> values, default is 100.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_type">type</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b>. If &quot;grouped&quot; then a grouped lasso penalty is 
used on the multinomial coefficients for a variable. This ensures they are all in our out together.
The default in our case is &quot;grouped&quot;.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20Kullback-Leibler+2B20divergence+2B20based+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the glmnet package to perform LASSO penalised regression. For more details see the 
function in that package.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mod</code></td>
<td>

<p>We decided to keep the same list that is returned by glmnet. So, see the function in that package 
for more information.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>
<p> If you supply a matrix in the &quot;xnew&quot; argument this will return an array of many matrices 
with the fitted values, where each matrix corresponds to each value of <code class="reqn">\lambda</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris and Abdulaziz Alenazi.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and 
Abdulaziz Alenazi <a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Alenazi, A. A. (2022). f-divergence regression models for compositional data. 
Pakistan Journal of Statistics and Operation Research, 18(4): 867&ndash;882.
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2010) Regularization Paths for Generalized Linear Models 
via Coordinate Descent. Journal of Statistical Software, Vol. 33(1), 1&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lassocoef.plot">lassocoef.plot</a>, <a href="#topic+cv.lasso.klcompreg">cv.lasso.klcompreg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+lasso.compreg">lasso.compreg</a>, <a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.knn.reg">alfa.knn.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix(iris[, 1:4])
y &lt;- y / rowSums(y)
x &lt;- matrix( rnorm(150 * 30), ncol = 30 )
a &lt;- lasso.klcompreg(y, x)
</code></pre>

<hr>
<h2 id='LASSO+20log-ratio+20regression+20with+20compositional+20response'>
LASSO log-ratio regression with compositional response
</h2><span id='topic+lasso.compreg'></span>

<h3>Description</h3>

<p>LASSO log-ratio regression with compositional response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso.compreg(y, x, alpha = 1, lambda = NULL,
nlambda = 100, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_y">y</code></td>
<td>

<p>A numerical matrix with compositional data. Zero values are not allowed as the additive log-ratio 
transformation (<code><a href="#topic+alr">alr</a></code>) is applied to the compositional response prior to implementing 
the LASSO algortihm.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_x">x</code></td>
<td>

<p>A numerical matrix containing the predictor variables.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_alpha">alpha</code></td>
<td>

<p>The elastic net mixing parameter, with <code class="reqn">0 \leq \alpha \leq 1</code>. The penalty is defined as a 
weighted combination of the ridge and of the Lasso regression. When <code class="reqn">\alpha=1</code> LASSO is 
applied, while <code class="reqn">\alpha=0</code>
yields the ridge regression.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_lambda">lambda</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b> A user supplied lambda sequence. 
Typical usage is to have the program compute its own lambda sequence based on nlambda and 
lambda.min.ratio. Supplying a value of lambda overrides this. WARNING: use with care. 
Avoid supplying a single value for lambda (for predictions after CV use predict() instead). 
Supply instead a decreasing sequence of lambda values. glmnet relies on its warms
starts for speed, and its often faster to fit a whole path than compute a single fit.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_nlambda">nlambda</code></td>
<td>

<p><b>This information is copied from the package glmnet.</b> The number of <code class="reqn">lambda</code> values, 
default is 100.
</p>
</td></tr>
<tr><td><code id="LASSO+2B20log-ratio+2B20regression+2B20with+2B20compositional+2B20response_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the glmnet package to perform LASSO penalised regression. 
For more details see the function in
that package.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mod</code></td>
<td>

<p>We decided to keep the same list that is returned by glmnet. So, see the function in 
that package for more information.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>
<p> If you supply a matrix in the &quot;xnew&quot; argument this will return an array of many 
matrices with the fitted values, where each matrix corresponds to each value of <code class="reqn">\lambda</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2010) Regularization Paths for Generalized Linear 
Models via Coordinate Descent. Journal of Statistical Software, Vol. 33(1), 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.lasso.compreg">cv.lasso.compreg</a>, <a href="#topic+lassocoef.plot">lassocoef.plot</a>, <a href="#topic+lasso.klcompreg">lasso.klcompreg</a>, <a href="#topic+cv.lasso.klcompreg">cv.lasso.klcompreg</a>,
<a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix(iris[, 1:4])
y &lt;- y / rowSums(y)
x &lt;- matrix( rnorm(150 * 30), ncol = 30 )
a &lt;- lasso.compreg(y, x)
</code></pre>

<hr>
<h2 id='Log-contrast+20GLMs+20with+20compositional+20predictor+20variables'>
Log-contrast GLMS with compositional predictor variables
</h2><span id='topic+lc.glm'></span>

<h3>Description</h3>

<p>Log-contrast GLMs with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lc.glm(y, x, z = NULL, model = "logistic", xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log-contrast+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This is either a binary variable or a vector with counts.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_model">model</code></td>
<td>

<p>For the ulc.glm(), this can be either &quot;logistic&quot; or &quot;poisson&quot;. 
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the log-contrast logistic or Poisson regression model. The logarithm of the
compositional predictor variables is used (hence no zero values are allowed). The response variable
is linked to the log-transformed data with the constraint that the sum of the regression coefficients
equals 0. If you want the regression without the zum-to-zero contraints see <code><a href="#topic+ulc.glm">ulc.glm</a></code>.
Extra predictors variables are allowed as well, for instance categorical or continuous.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>devi</code></td>
<td>

<p>The residual deviance of the logistic or Poisson regression model.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The constrained regression coefficients. Their sum (excluding the constant) equals 0.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and znew were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Lu J., Shi P. and Li H. (2019). Generalized linear models with linear constraints
for microbiome compositional data. Biometrics, 75(1): 235&ndash;244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ulc.glm">ulc.glm</a>, <a href="#topic+lc.glm2">lc.glm2</a>, <a href="#topic+ulc.glm2">ulc.glm2</a>, <a href="#topic+lcglm.aov">lcglm.aov</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(150, 1, 0.5)
x &lt;- rdiri(150, runif(3, 1, 4) )
mod1 &lt;- lc.glm(y, x)
</code></pre>

<hr>
<h2 id='Log-contrast+20logistic+20or+20Poisson+20regression+20with+20with+20multiple+20compositional+20predictors'>
Log-contrast logistic or Poisson regression with with multiple compositional predictors
</h2><span id='topic+lc.glm2'></span>

<h3>Description</h3>

<p>Log-contrast logistic or Poisson regression with with multiple compositional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lc.glm2(y, x, z = NULL, model = "logistic", xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log-contrast+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This is either a binary variable or a vector with counts.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_model">model</code></td>
<td>

<p>This can be either &quot;logistic&quot; or &quot;poisson&quot;.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the log-contrast logistic or Poisson regression model. The logarithm of the
compositional predictor variables is used (hence no zero values are allowed). The response variable
is linked to the log-transformed data with the constraint that the sum of the regression coefficients
equals 0. If you want the regression without the zum-to-zero contraints see <code><a href="#topic+ulc.glm2">ulc.glm2</a></code>.
Extra predictors variables are allowed as well, for instance categorical or continuous.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>devi</code></td>
<td>

<p>The residual deviance of the logistic or Poisson regression model.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The constrained regression coefficients. Their sum (excluding the constant) equals 0.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and znew were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Lu J., Shi P. and Li H. (2019). Generalized linear models with linear constraints
for microbiome compositional data. Biometrics, 75(1): 235&ndash;244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ulc.glm2">ulc.glm2</a>, <a href="#topic+ulc.glm">ulc.glm</a>, <a href="#topic+lc.glm">lc.glm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(150, 1, 0.5)
x &lt;- list()
x1 &lt;- as.matrix(iris[, 2:4])
x1 &lt;- x1 / rowSums(x1)
x[[ 1 ]] &lt;- x1
x[[ 2 ]] &lt;- rdiri(150, runif(4) )
x[[ 3 ]] &lt;- rdiri(150, runif(5) )
mod &lt;- lc.glm2(y, x)
</code></pre>

<hr>
<h2 id='Log-contrast+20regression+20with+20compositional+20predictor+20variables'>
Log-contrast regression with compositional predictor variables
</h2><span id='topic+lc.reg'></span>

<h3>Description</h3>

<p>Log-contrast regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lc.reg(y, x, z = NULL, xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This must be a continuous variable.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the log-contrast regression model as described in Aitchison (2003), pg. 84-85.
The logarithm of the compositional predictor variables is used (hence no zero values are allowed).
The response variable is linked to the log-transformed data with the constraint that the sum of the
regression coefficients equals 0. Hence, we apply constrained least squares, which has a closed form
solution. The constrained least squares is described in Chapter 8.2 of Hansen (2019). The idea is to
minimise the sum of squares of the residuals under the constraint <code class="reqn">R^T \beta = c</code>, where <code class="reqn">c=0</code>
in our case. If you want the regression without the zum-to-zero contraints see <code><a href="#topic+ulc.reg">ulc.reg</a></code>.
Extra predictors variables are allowed as well, for instance categorical or continuous.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The constrained regression coefficients. Their sum (excluding the constant) equals 0.
</p>
</td></tr>
<tr><td><code>covbe</code></td>
<td>

<p>The covariance matrix of the constrained regression coefficients.
</p>
</td></tr>
<tr><td><code>va</code></td>
<td>

<p>The estimated regression variance.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>

<p>The vector of residuals.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and znew were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Hansen, B. E. (2022). Econometrics. Princeton University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ulc.reg">ulc.reg</a>, <a href="#topic+lcreg.aov">lcreg.aov</a>, <a href="#topic+lc.reg2">lc.reg2</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.knn.reg">alfa.knn.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- as.matrix(iris[, 2:4])
x &lt;- x / rowSums(x)
mod1 &lt;- lc.reg(y, x)
mod2 &lt;- lc.reg(y, x, z = iris[, 5])
</code></pre>

<hr>
<h2 id='Log-contrast+20regression+20with+20multiple+20compositional+20predictors'>
Log-contrast regression with multiple compositional predictors
</h2><span id='topic+lc.reg2'></span>

<h3>Description</h3>

<p>Log-contrast regression with multiple compositional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lc.reg2(y, x, z = NULL, xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This must be a continuous variable.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_x">x</code></td>
<td>

<p>A list with multiple matrices with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing a list with multiple matrices with compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Log-contrast+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the log-contrast regression model as described in Aitchison (2003), pg. 84-85.
The logarithm of the compositional predictor variables is used (hence no zero values are allowed).
The response variable is linked to the log-transformed data with the constraint that the sum of the
regression coefficients for each composition equals 0. Hence, we apply constrained least squares, 
which has a closed form solution. The constrained least squares is described in Chapter 8.2 of Hansen (2019). 
The idea is to minimise the sum of squares of the residuals under the constraint <code class="reqn">R^T \beta = c</code>, 
where <code class="reqn">c=0</code> in our case. If you want the regression without the zum-to-zero contraints see 
<code><a href="#topic+ulc.reg2">ulc.reg2</a></code>. Extra predictors variables are allowed as well, for instance categorical 
or continuous. The difference with <code><a href="#topic+lc.reg">lc.reg</a></code> is that instead of one, there are multiple 
compositions treated as predictor variables.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The constrained regression coefficients. The sum of the sets of coefficients (excluding the constant) 
corresponding to each predictor composition sums to 0. 
</p>
</td></tr>
<tr><td><code>covbe</code></td>
<td>

<p>If covariance matrix of the constrained regression coefficients.
</p>
</td></tr>
<tr><td><code>va</code></td>
<td>

<p>The variance of the estimated regression coefficients.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>

<p>The vector of residuals.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and &quot;znew&quot; were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Hansen, B. E. (2022). Econometrics. Princeton University Press.
</p>
<p>Xiaokang Liu, Xiaomei Cong, Gen Li, Kendra Maas and Kun Chen (2020). Multivariate Log-Contrast Regression
with Sub-Compositional Predictors: Testing the Association Between Preterm Infants' Gut Microbiome and
Neurobehavioral Outcome.
<a href="https://arxiv.org/pdf/2006.00487.pdf">https://arxiv.org/pdf/2006.00487.pdf</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ulc.reg2">ulc.reg2</a>, <a href="#topic+lc.reg">lc.reg</a>, <a href="#topic+ulc.reg">ulc.reg</a>, <a href="#topic+lcreg.aov">lcreg.aov</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.knn.reg">alfa.knn.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- list()
x1 &lt;- as.matrix(iris[, 2:4])
x1 &lt;- x1 / rowSums(x1)
x[[ 1 ]] &lt;- x1
x[[ 2 ]] &lt;- rdiri(150, runif(4) )
x[[ 3 ]] &lt;- rdiri(150, runif(5) )
mod &lt;- lc.reg2(y, x)
be &lt;- mod$be
sum(be[2:4])
sum(be[5:8])
sum(be[9:13])
</code></pre>

<hr>
<h2 id='Log-likelihood+20ratio+20test+20for+20a+20Dirichlet+20mean+20vector'>
Log-likelihood ratio test for a Dirichlet mean vector
</h2><span id='topic+dirimean.test'></span>

<h3>Description</h3>

<p>Log-likelihood ratio test for a Dirichlet mean vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirimean.test(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log-likelihood+2B20ratio+2B20test+2B20for+2B20a+2B20Dirichlet+2B20mean+2B20vector_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Log-likelihood+2B20ratio+2B20test+2B20for+2B20a+2B20Dirichlet+2B20mean+2B20vector_+3A_a">a</code></td>
<td>

<p>A compositional mean vector. The concentration parameter is estimated at first. 
If the elements do not sum to 1, it is assumed that the Dirichlet parameters are supplied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Log-likelihood ratio test is performed for the hypothesis the given vector of parameters 
&quot;a&quot; describes the compositional data well.
</p>


<h3>Value</h3>

<p>If there are no zeros in  the data, a list including:
</p>
<table>
<tr><td><code>param</code></td>
<td>

<p>A matrix with the estimated parameters under the null and the alternative hypothesis.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood under the alternative and the null hypothesis.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>The value of the test statistic and its relevant p-value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and 
Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: 
Theory, methods and applications. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym.test">sym.test</a>, <a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.est">diri.est</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+ddiri">ddiri</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rdiri( 100, c(1, 2, 3) )
dirimean.test(x, c(1, 2, 3) )
dirimean.test( x, c(1, 2, 3)/6 )
</code></pre>

<hr>
<h2 id='Log-likelihood+20ratio+20test+20for+20a+20symmetric+20Dirichlet+20distribution'>
Log-likelihood ratio test for a symmetric Dirichlet distribution
</h2><span id='topic+sym.test'></span>

<h3>Description</h3>

<p>Log-likelihood ratio test for a symmetric Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sym.test(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log-likelihood+2B20ratio+2B20test+2B20for+2B20a+2B20symmetric+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero values are allowed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Log-likelihood ratio test is performed for the hypothesis that all Dirichelt parameters are equal.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>est.par</code></td>
<td>

<p>The estimated parameters under the alternative hypothesis.
</p>
</td></tr>
<tr><td><code>one.par</code></td>
<td>

<p>The value of the estimated parameter under the null hypothesis.
</p>
</td></tr>
<tr><td><code>res</code></td>
<td>

<p>The loglikelihood under the alternative and the null hypothesis, the value of the test statistic, its relevant p-value and the
associated degrees of freedom, which are actually the dimensionality of the simplex, <code class="reqn">D-1</code>, where <code class="reqn">D</code> is the number of
components.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: 
Theory, methods and applications. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.est">diri.est</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+dirimean.test">dirimean.test</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rdiri( 100, c(5, 7, 1, 3, 10, 2, 4) )
sym.test(x)
x &lt;- rdiri( 100, c(5, 5, 5, 5, 5) )
sym.test(x)
</code></pre>

<hr>
<h2 id='Minimized+20Kullback-Leibler+20divergence+20between+20Dirichlet+20and+20logistic+20normal'>
Minimized Kullback-Leibler divergence between Dirichlet and logistic normal
</h2><span id='topic+kl.diri.normal'></span>

<h3>Description</h3>

<p>Minimized Kullback-Leibler divergence between Dirichlet and logistic
normal distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kl.diri.normal(a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Minimized+2B20Kullback-Leibler+2B20divergence+2B20between+2B20Dirichlet+2B20and+2B20logistic+2B20normal_+3A_a">a</code></td>
<td>

<p>A vector with the parameters of the Dirichlet parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the minimized Kullback-Leibler divergence from the
Dirichlet distribution to the logistic normal distribution.
</p>


<h3>Value</h3>

<p>The minimized Kullback-Leibler divergence from the
Dirichlet distribution to the logistic normal distribution.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data, p. 127. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+ddiri">ddiri</a>, <a href="#topic+dda">dda</a>, <a href="#topic+diri.reg">diri.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- runif(5, 1, 5)
kl.diri.normal(a)
</code></pre>

<hr>
<h2 id='Mixture+20model+20selection+20via+20BIC'>
Mixture model selection via BIC
</h2><span id='topic+bic.mixcompnorm'></span>

<h3>Description</h3>

<p>Mixture model selection via BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic.mixcompnorm(x, G, type = "alr", veo = FALSE, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20via+2B20BIC_+3A_x">x</code></td>
<td>

<p>A matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20via+2B20BIC_+3A_g">G</code></td>
<td>

<p>A numeric vector with the number of components, clusters, to be considered, e.g. 1:3.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20via+2B20BIC_+3A_type">type</code></td>
<td>

<p>The type of trasformation to be used, either the additive log-ratio (&quot;alr&quot;), the isometric
log-ratio (&quot;ilr&quot;) or the pivot coordinate (&quot;pivot&quot;) transformation.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20via+2B20BIC_+3A_veo">veo</code></td>
<td>

<p>Stands for &quot;Variables exceed observations&quot;. If TRUE then if the number variablesin the model
exceeds the number of observations, but the model is still fitted.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20via+2B20BIC_+3A_graph">graph</code></td>
<td>

<p>A boolean variable, TRUE or FALSE specifying whether a graph should be drawn or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The alr or the ilr-transformation is applied to the compositional data first and then mixtures of
multivariate Gaussian distributions are fitted. BIC is used to decide on the optimal model and number
of components.
</p>


<h3>Value</h3>

<p>A plot with the BIC of the best model for each number of components versus the number of components.
A list including:
</p>
<table>
<tr><td><code>mod</code></td>
<td>

<p>A message informing the user about the best model.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>The BIC values for every possible model and number of components.
</p>
</td></tr>
<tr><td><code>optG</code></td>
<td>

<p>The number of components with the highest BIC.
</p>
</td></tr>
<tr><td><code>optmodel</code></td>
<td>

<p>The type of model corresponding to the highest BIC.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2018). mixture: Mixture Models for Clustering and
Classification. R package version 1.5.
</p>
<p>Ryan P. Browne and Paul D. McNicholas (2014). Estimating Common Principal Components in High Dimensions.
Advances in Data Analysis and Classification, 8(2), 217-226.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+rmixcomp">rmixcomp</a>, <a href="#topic+bic.alfamixnorm">bic.alfamixnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- as.matrix( iris[, 1:4] )
x &lt;- x/ rowSums(x)
bic.mixcompnorm(x, 1:3, type = "alr", graph = FALSE)
bic.mixcompnorm(x, 1:3, type = "ilr", graph = FALSE)

</code></pre>

<hr>
<h2 id='Mixture+20model+20selection+20with+20the+20alpha-transformation+20using+20BIC'>
Mixture model selection with the <code class="reqn">\alpha</code>-transformation using BIC
</h2><span id='topic+bic.alfamixnorm'></span>

<h3>Description</h3>

<p>Mixture model selection with the <code class="reqn">\alpha</code>-transformation using BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic.alfamixnorm(x, G, a = seq(-1, 1, by = 0.1), veo = FALSE, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20with+2B20the+2B20alpha-transformation+2B20using+2B20BIC_+3A_x">x</code></td>
<td>

<p>A matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20with+2B20the+2B20alpha-transformation+2B20using+2B20BIC_+3A_g">G</code></td>
<td>

<p>A numeric vector with the number of components, clusters, to be considered, e.g. 1:3.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20with+2B20the+2B20alpha-transformation+2B20using+2B20BIC_+3A_a">a</code></td>
<td>

<p>A vector with a grid of values of the power transformation, it has to be between -1 and 1. If zero values are present
it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20with+2B20the+2B20alpha-transformation+2B20using+2B20BIC_+3A_veo">veo</code></td>
<td>

<p>Stands for &quot;Variables exceed observations&quot;. If TRUE then if the number variablesin the model exceeds the number of
observations, but the model is still fitted.
</p>
</td></tr>
<tr><td><code id="Mixture+2B20model+2B20selection+2B20with+2B20the+2B20alpha-transformation+2B20using+2B20BIC_+3A_graph">graph</code></td>
<td>

<p>A boolean variable, TRUE or FALSE specifying whether a graph should be drawn or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first and then mixtures of multivariate Gaussian
distributions are fitted. BIC is used to decide on the optimal model and number of components.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>abic</code></td>
<td>

<p>A list that contains the matrices of all BIC values for all values of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>optalpha</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> that leads to the highest BIC.
</p>
</td></tr>
<tr><td><code>optG</code></td>
<td>

<p>The number of components with the highest BIC.
</p>
</td></tr>
<tr><td><code>optmodel</code></td>
<td>

<p>The type of model corresponding to the highest BIC.
</p>
</td></tr>
</table>
<p>If graph is set equal to TRUE a plot with the BIC of the best model for each number of components versus the number of components and a list with the results of the Gaussian mixture model for each value of <code class="reqn">\alpha</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2018). mixture: Mixture Models for Clustering and Classification.
R package version 1.5.
</p>
<p>Ryan P. Browne and Paul D. McNicholas (2014). Estimating Common Principal Components in High Dimensions. Advances
in Data Analysis and Classification, 8(2), 217-226.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.mix.norm">alfa.mix.norm</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+mix.compnorm.contour">mix.compnorm.contour</a>, <a href="#topic+rmixcomp">rmixcomp</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfa.knn">alfa.knn</a>,
<a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+comp.nb">comp.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- as.matrix( iris[, 1:4] )
x &lt;- x/ rowSums(x)
bic.alfamixnorm(x, 1:3, a = c(0.4, 0.5, 0.6), graph = FALSE)

</code></pre>

<hr>
<h2 id='MLE+20for+20the+20multivariate+20t+20distribution'>
MLE for the multivariate t distribution
</h2><span id='topic+multivt'></span>

<h3>Description</h3>

<p>MLE of the parameters of a multivariate t distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivt(y, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20for+2B20the+2B20multivariate+2B20t+2B20distribution_+3A_y">y</code></td>
<td>

<p>A matrix with continuous data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20for+2B20the+2B20multivariate+2B20t+2B20distribution_+3A_plot">plot</code></td>
<td>

<p>If plot is TRUE the value of the maximum log-likelihood as a function of the degres of freedom is presented.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters of a multivariate t distribution are estimated. This is used by the functions <code><a href="#topic+comp.den">comp.den</a></code> and <code><a href="#topic+bivt.contour">bivt.contour</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>center</code></td>
<td>

<p>The location estimate.
</p>
</td></tr>
<tr><td><code>scatter</code></td>
<td>

<p>The scatter matrix estimate.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The estimated degrees of freedom.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood value.
</p>
</td></tr>
<tr><td><code>mesos</code></td>
<td>

<p>The classical mean vector.
</p>
</td></tr>
<tr><td><code>covariance</code></td>
<td>

<p>The classical covariance matrix.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Nadarajah, S. and Kotz, S. (2008). Estimation methods for the multivariate t distribution.
Acta Applicandae Mathematicae, 102(1):99-118.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bivt.contour">bivt.contour</a>, <a href="#topic+comp.den">comp.den</a>, <a href="mvtnorm.html#topic+rmvt">rmvt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
multivt(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20distributions+20defined+20in+20the+20+280+2C+201+29+20interval'>
MLE of distributions defined in the (0, 1) interval
</h2><span id='topic+beta.est'></span><span id='topic+logitnorm.est'></span><span id='topic+hsecant01.est'></span><span id='topic+kumar.est'></span><span id='topic+unitweibull.est'></span><span id='topic+ibeta.est'></span><span id='topic+zilogitnorm.est'></span>

<h3>Description</h3>

<p>MLE of distributions defined in the (0, 1) interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta.est(x, tol = 1e-07)
logitnorm.est(x)
hsecant01.est(x, tol = 1e-07)
kumar.est(x, tol = 1e-07)
unitweibull.est(x, tol = 1e-07, maxiters = 100)
ibeta.est(x, tol = 1e-07)
zilogitnorm.est(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20distributions+2B20defined+2B20in+2B20the+2B20+2B280+2B2C+2B201+2B29+2B20interval_+3A_x">x</code></td>
<td>

<p>A numerical vector with proportions, i.e. numbers in (0, 1) (zeros and ones are not allowed).
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20distributions+2B20defined+2B20in+2B20the+2B20+2B280+2B2C+2B201+2B29+2B20interval_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20distributions+2B20defined+2B20in+2B20the+2B20+2B280+2B2C+2B201+2B29+2B20interval_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations the Newton-Raphson algorithm will perform.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood estimation of the parameters of some distributions are performed, some of which use the Newton-Raphson. Some distributions and hence the functions do not accept zeros. &quot;logitnorm.mle&quot; fits the logistic normal, hence no Newton-Raphson is required and the &quot;hypersecant01.mle&quot; use the golden ratio search as is it faster than the Newton-Raphson (less computations). The &quot;zilogitnorm.est&quot; stands for the zero inflated logistic normal distribution.
The &quot;ibeta.est&quot; fits the zero or the one inflated beta distribution.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>The estimated parameters. In the case of &quot;hypersecant01.est&quot; this is called &quot;theta&quot; as there is only one parameter.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Kumaraswamy, P. (1980). A generalized probability density function for double-bounded random processes.
Journal of Hydrology. 46(1-2): 79-88.
</p>
<p>Jones, M.C. (2009). Kumaraswamy's distribution: A beta-type distribution with some tractability advantages.
Statistical Methodology. 6(1): 70-81.
</p>
<p>You can also check the relevant wikipedia pages.
</p>


<h3>See Also</h3>

<p><code> diri.nr2,
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rbeta(1000, 1, 4)
beta.est(x)
ibeta.est(x)

x &lt;- runif(1000)
hsecant01.est(x)
logitnorm.est(x)
ibeta.est(x)

x &lt;- rbeta(1000, 2, 5)
x[sample(1:1000, 50)] &lt;- 0
ibeta.est(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20Dirichlet+20distribution'>
MLE of the a Dirichlet distribution
</h2><span id='topic+diri.est'></span>

<h3>Description</h3>

<p>MLE of the parameters of a Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diri.est(x, type = "mle")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix containing compositional data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20Dirichlet+2B20distribution_+3A_type">type</code></td>
<td>

<p>If you want to estimate the parameters use type=&quot;mle&quot;. If you want to estimate the mean vector along with the precision parameter,
the second parametrisation of the Dirichlet, use type=&quot;prec&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood estimation of the parameters of a Dirichlet distribution is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>The estimated parameters.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The estimated precision parameter, if type = &quot;prec&quot;.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The estimated mean vector, if type = &quot;prec&quot;.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the maximisation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> 
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Ng Kai Wang, Guo-Liang Tian and Man-Lai Tang (2011). Dirichlet and related distributions: Theory, methods and applications. John Wiley &amp; Sons.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+ddiri">ddiri</a>, <a href="#topic+dda">dda</a>, <a href="#topic+diri.reg">diri.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rdiri( 100, c(5, 7, 1, 3, 10, 2, 4) )
diri.est(x)
diri.est(x, type = "prec")
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20Dirichlet+20distribution+20via+20Newton-Rapshon'>
MLE of the Dirichlet distribution via Newton-Rapshon
</h2><span id='topic+diri.nr'></span>

<h3>Description</h3>

<p>MLE of the Dirichlet distribution via Newton-Rapshon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diri.nr(x, type = 1, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20via+2B20Newton-Rapshon_+3A_x">x</code></td>
<td>

<p>A matrix containing compositional data. Zeros are not allowed.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20via+2B20Newton-Rapshon_+3A_type">type</code></td>
<td>

<p>Type can either be 1, so that the Newton-Rapshon is used for the maximisation of the log-likelihood, as Minka (2012) suggested or it
can be 1. In the latter case the Newton-Raphson algorithm is implemented involving matrix inversions. In addition an even faster
implementation has been implemented (in C++) in the package <b>Rfast</b> and is used here.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20Dirichlet+2B20distribution+2B20via+2B20Newton-Rapshon_+3A_tol">tol</code></td>
<td>

<p>The tolerance level indicating no further increase in the log-likelihood.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood estimation of the parameters of a Dirichlet distribution is performed via Newton-Raphson.
Initial values suggested by Minka (2003) are used. The estimation is super faster than &quot;diri.est&quot; and the
difference becomes really apparent when the sample size and or the dimensions increase. In fact this will work with millions of observations.
So in general, I trust this one more than &quot;diri.est&quot;.
</p>
<p>The only problem I have seen with this method is that if the data are concentrated around a point,
say the center of the simplex, it will be hard for this and the previous methods to give estimates of the parameters.
In this extremely difficult scenario I would suggest the use of the previous function with the precision parametrization
&quot;diri.est(x, type = &quot;prec&quot;)&quot;. It will be extremely fast and accurate.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iter</code></td>
<td>

<p>The number of iterations required. If the argument &quot;type&quot; is set to 2 this is not returned.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>The estimated parameters.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Thomas P. Minka (2003). Estimating a Dirichlet distribution.
http://research.microsoft.com/en-us/um/people/minka/papers/dirichlet/minka-dirichlet.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.est">diri.est</a>, <a href="#topic+diri.contour">diri.contour</a> <a href="#topic+rdiri">rdiri</a>, <a href="#topic+ddiri">ddiri</a>, <a href="#topic+dda">dda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rdiri( 100, c(5, 7, 5, 8, 10, 6, 4) )
diri.nr(x)
diri.nr(x, type = 2)
diri.est(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20folded+20model+20for+20a+20given+20value+20of+20alpha'>
MLE of the folded model for a given value of <code class="reqn">\alpha</code>
</h2><span id='topic+alpha.mle'></span><span id='topic+a.mle'></span>

<h3>Description</h3>

<p>MLE of the folded model for a given value of <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alpha.mle(x, a)
a.mle(a, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20folded+2B20model+2B20for+2B20a+2B20given+2B20value+2B20of+2B20alpha_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero vaues are allowed.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20folded+2B20model+2B20for+2B20a+2B20given+2B20value+2B20of+2B20alpha_+3A_a">a</code></td>
<td>

<p>A value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a function for choosing or estimating the value of <code class="reqn">\alpha</code> in the folded model
(Tsagris and Stewart, 2020). It is called by <code><a href="#topic+a.est">a.est</a></code>.
</p>


<h3>Value</h3>

<p>If &quot;alpha.mle&quot; is called, a list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The nubmer of iterations the EM algorithm required.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The maximimized log-likelihood of the folded model.
</p>
</td></tr>
<tr><td><code>p</code></td>
<td>

<p>The estimated probability inside the simplex of the folded model.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The estimated mean vector of the folded model.
</p>
</td></tr>
<tr><td><code>su</code></td>
<td>

<p>The estimated covariance matrix of the folded model.
</p>
</td></tr>
</table>
<p>If &quot;a.mle&quot; is called, the log-likelihood is returned only.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2022). A Review of Flexible Transformations for Modeling Compositional Data. In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234.
https://link.springer.com/chapter/10.1007/978-3-031-08329-7_10
</p>
<p>Tsagris M. and Stewart C. (2020). A folded model for compositional data analysis.
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation
for compositional data. In Proceedings of the 4th Compositional Data Analysis Workshop,
Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.profile">alfa.profile</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>, <a href="#topic+a.est">a.est</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
mod &lt;- alfa.tune(x)
mod
alpha.mle(x, mod[1])
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20zero+20adjusted+20Dirichlet+20distribution'>
MLE of the zero adjusted Dirichlet distribution
</h2><span id='topic+zad.est'></span>

<h3>Description</h3>

<p>MLE of the zero adjusted Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zad.est(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20zero+2B20adjusted+2B20Dirichlet+2B20distribution_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). The number of observations (vectors)
with no zero values should be more than the columns of the predictor variables. Otherwise,
the initial values will not be calculated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A zero adjusted Dirichlet distribution is being fittd and its parameters are estimated.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The precision parameter. If covariates are linked with it (function &quot;diri.reg2&quot;), this will
be a vector.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean vector of the distribution.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2018). A Dirichlet regression model for compositional data with zeros.
Lobachevskii Journal of Mathematics,39(3): 398&ndash;412.
</p>
<p>Preprint available from https://arxiv.org/pdf/1410.5011.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zadr">zadr</a>, <a href="#topic+diri.nr">diri.nr</a>, <a href="#topic+zilogitnorm.est">zilogitnorm.est</a>, <a href="#topic+zeroreplace">zeroreplace</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix(iris[, 1:3])
y &lt;- y / rowSums(y)
mod1 &lt;- diri.nr(y)
y[sample(1:450, 15) ] &lt;- 0
mod2 &lt;- zad.est(y)
</code></pre>

<hr>
<h2 id='Multivariate+20kernel+20density+20estimation'>
Multivariate kernel density estimation
</h2><span id='topic+mkde'></span>

<h3>Description</h3>

<p>Multivariate kernel density estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mkde(x, h = NULL, thumb = "silverman")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation_+3A_x">x</code></td>
<td>

<p>A matrix with Euclidean (continuous) data.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation_+3A_h">h</code></td>
<td>

<p>The bandwidh value. It can be a single value, which is turned into a vector and
then into a diagonal matrix, or a vector which is turned into a diagonal matrix.
If you put this NULL then you need to specify the &quot;thumb&quot; argument below.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation_+3A_thumb">thumb</code></td>
<td>

<p>Do you want to use a rule of thumb for the bandwidth parameter? If no, set h
equal to NULL and put &quot;estim&quot; for maximum likelihood cross-validation, &quot;scott&quot;
or &quot;silverman&quot; for Scott's and Silverman's rules of thumb respectively.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multivariate kernel density estimate is calculated with a (not necssarily
given) bandwidth value.
</p>


<h3>Value</h3>

<p>A vector with the density estimates calculated for every vector.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Arsalane Chouaib Guidoum (2015). Kernel Estimator and Bandwidth Selection for Density and its Derivatives.
The kedd R package.
</p>
<p>M.P. Wand and M.C. Jones (1995). Kernel smoothing, pages 91-92.
</p>
<p>B.W. Silverman (1986). Density estimation for statistics and data analysis, pages 76-78.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mkde.tune">mkde.tune</a>, <a href="#topic+comp.kerncontour">comp.kerncontour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mkde( as.matrix(iris[, 1:4]), thumb = "scott" )
mkde( as.matrix(iris[, 1:4]), thumb = "silverman" )
</code></pre>

<hr>
<h2 id='Multivariate+20kernel+20density+20estimation+20for+20compositional+20data'>
Multivariate kernel density estimation for compositional data
</h2><span id='topic+comp.kern'></span>

<h3>Description</h3>

<p>Multivariate kernel density estimation for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.kern(x, type= "alr", h = NULL, thumb = "silverman")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with Euclidean (continuous) data.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>The type of trasformation used, either the additive log-ratio (&quot;alr&quot;), the
isometric log-ratio (&quot;ilr&quot;) or the pivot coordinate (&quot;pivot&quot;) transformation.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation+2B20for+2B20compositional+2B20data_+3A_h">h</code></td>
<td>

<p>The bandwidh value. It can be a single value, which is turned into a vector and
then into a diagonal matrix, or a vector which is turned into a diagonal matrix.
If it is NULL, then you need to specify the &quot;thumb&quot; argument below.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20kernel+2B20density+2B20estimation+2B20for+2B20compositional+2B20data_+3A_thumb">thumb</code></td>
<td>

<p>Do you want to use a rule of thumb for the bandwidth parameter? If no, leave
the &quot;h&quot; NULL and put &quot;estim&quot; for maximum likelihood cross-validation, &quot;scott&quot;
or &quot;silverman&quot; for Scott's and Silverman's rules of thumb respectively.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multivariate kernel density estimate is calculated with a (not necssarily
given) bandwidth value.
</p>


<h3>Value</h3>

<p>A vector with the density estimates calculated for every vector.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Arsalane Chouaib Guidoum (2015). Kernel Estimator and Bandwidth Selection for
Density and its Derivatives.
</p>
<p>The kedd R package.
</p>
<p>M.P. Wand and M.C. Jones (1995). Kernel smoothing, pages 91-92.
</p>
<p>B.W. Silverman (1986). Density estimation for statistics and data analysis, pages 76-78.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.kerncontour">comp.kerncontour</a>, <a href="#topic+mkde">mkde</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
f &lt;- comp.kern(x)
</code></pre>

<hr>
<h2 id='Multivariate+20linear+20regression'>
Multivariate linear regression
</h2><span id='topic+multivreg'></span>

<h3>Description</h3>

<p>Multivariate linear regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivreg(y, x, plot = TRUE, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20linear+2B20regression_+3A_y">y</code></td>
<td>

<p>A matrix with the Eucldidean (continuous) data.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20linear+2B20regression_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variable(s), they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20linear+2B20regression_+3A_plot">plot</code></td>
<td>

<p>Should a plot appear or not?
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20linear+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classical multivariate linear regression model is obtained.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>suma</code></td>
<td>

<p>A summary as produced by <code><a href="stats.html#topic+lm">lm</a></code>, which includes the coefficients, their standard error, t-values, p-values.
</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>

<p>The value of the <code class="reqn">R^2</code> for each univariate regression.
</p>
</td></tr>
<tr><td><code>resid.out</code></td>
<td>

<p>A vector with number indicating which vectors are potential residual outliers.
</p>
</td></tr>
<tr><td><code>x.leverage</code></td>
<td>

<p>A vector with number indicating which vectors are potential outliers in the predictor variables space.
</p>
</td></tr>
<tr><td><code>out</code></td>
<td>

<p>A vector with number indicating which vectors are potential outliers in the residuals and in the predictor variables space.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The predicted values if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>K.V. Mardia, J.T. Kent and J.M. Bibby (1979). Multivariate Analysis. Academic Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(iris[, 1:2])
y &lt;- as.matrix(iris[, 3:4])
multivreg(y, x, plot = TRUE)
</code></pre>

<hr>
<h2 id='Multivariate+20normal+20random+20values+20simulation+20on+20the+20simplex'>
Multivariate normal random values simulation on the simplex
</h2><span id='topic+rcompnorm'></span>

<h3>Description</h3>

<p>Multivariate normal random values simulation on the simplex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcompnorm(n, m, s, type = "alr")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_m">m</code></td>
<td>

<p>The mean vector in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_s">s</code></td>
<td>

<p>The covariance matrix in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_type">type</code></td>
<td>

<p>The alr (type = &quot;alr&quot;) or the ilr (type = &quot;ilr&quot;) is to be used for closing the Euclidean data onto the simplex.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is straightforward, generate random values from a multivariate normal distribution in <code class="reqn">R^d</code> and brings the
values to the simplex <code class="reqn">S^d</code> using the inverse of a log-ratio transformation.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.den">comp.den</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+rcompt">rcompt</a>, <a href="#topic+rcompsn">rcompsn</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:2])
m &lt;- colMeans(x)
s &lt;- var(x)
y &lt;- rcompnorm(100, m, s)
comp.den(y)
ternary(y)
</code></pre>

<hr>
<h2 id='Multivariate+20or+20univariate+20regression+20with+20compositional+20data+20in+20the+20covariates+20side+20using+20the+20alpha-transformation'>
Multivariate or univariate regression with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.pcr'></span>

<h3>Description</h3>

<p>Multivariate or univariate regression with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.pcr(y, x, a, k, model = "gaussian", xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20or+2B20univariate+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. They can be continuous, binary, discrete (counts).
This can also be a vector with discrete values or a factor for the multinomial regression (model = &quot;multinomial&quot;).
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20or+2B20univariate+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20or+2B20univariate+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20or+2B20univariate+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_k">k</code></td>
<td>

<p>How many principal components to use. You may also specify a vector and in this case the results produced will refer to each number of principal components.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20or+2B20univariate+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_model">model</code></td>
<td>

<p>The type of regression model to fit. The possible values are &quot;gaussian&quot;, &quot;multinomial&quot;, &quot;binomial&quot; and &quot;poisson&quot;.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20or+2B20univariate+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted. If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first ,the first k principal component scores are calcualted and used as predictor variables for a regression model. The family of distributions can be either, &quot;normal&quot; for continuous response and hence normal distribution, &quot;binomial&quot; corresponding to binary response and hence logistic regression or &quot;poisson&quot; for count response and poisson regression.
</p>


<h3>Value</h3>

<p>A list tincluding:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>If linear regression was fitted, the regression coefficients of the k principal component scores on the response variable y.
</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>

<p>If another regression model was fitted its outcome as produced in the package <b>Rfast</b>.
</p>
</td></tr>
<tr><td><code>per</code></td>
<td>

<p>The percentage of variance explained by the first k principal components.
</p>
</td></tr>
<tr><td><code>vec</code></td>
<td>

<p>The first k principal components, loadings or eigenvectors. These are useful for future prediction in the sense that one needs not fit the whole model again.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the argument &quot;xnew&quot; was given these are the predicted or estimated values (if xnew is not NULL). If the argument <code>k</code> is a vector then this is a matrix with the estimated values for each number of components.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. Chilean Journal of Statistics, 6(2): 47-57.
https://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcr">pcr</a>, <a href="#topic+glm.pcr">glm.pcr</a>, <a href="#topic+alfapcr.tune">alfapcr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.vector(fgl[, 1])
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
mod &lt;- alfa.pcr(y = y, x = x, 0.7, 1)
mod
</code></pre>

<hr>
<h2 id='Multivariate+20regression+20with+20compositional+20data'>
Multivariate regression with compositional data
</h2><span id='topic+comp.reg'></span>

<h3>Description</h3>

<p>Multivariate regression with compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.reg(y, x, type = "classical", xnew = NULL, yb = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20regression+2B20with+2B20compositional+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with compsitional data. Zero values are not allowed.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20regression+2B20with+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20regression+2B20with+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>The type of regression to be used, &quot;classical&quot; for standard multivariate regression, or &quot;spatial&quot; for the robust spatial median regression. Alternatively you can type &quot;lmfit&quot; for the fast classical multivariate regression that does not return standard errors whatsoever.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20regression+2B20with+2B20compositional+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>This is by default set to NULL. If you have new data whose compositional data values you want to predict, put them here.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20regression+2B20with+2B20compositional+2B20data_+3A_yb">yb</code></td>
<td>

<p>If you have already transformed the data using the additive log-ratio transformation, plut it here. Othewrise leave it NULL.
This is intended to be used in the function <code><a href="#topic+alfareg.tune">alfareg.tune</a></code> in order to speed up the process.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The additive log-ratio transformation is applied and then the chosen multivariate regression is implemented. The alr is easier to explain than the ilr and that is why the latter is avoided here.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the beta coefficients.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Mardia K.V., Kent J.T., and Bibby J.M. (1979). Multivariate analysis. Academic press.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multivreg">multivreg</a>, <a href="#topic+spatmed.reg">spatmed.reg</a>, <a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+diri.reg">diri.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.matrix(iris[, 1:3])
y &lt;- y / rowSums(y)
x &lt;- as.vector(iris[, 4])
mod1 &lt;- comp.reg(y, x)
mod2 &lt;- comp.reg(y, x, type = "spatial")
</code></pre>

<hr>
<h2 id='Multivariate+20skew+20normal+20random+20values+20simulation+20on+20the+20simplex'>
Multivariate skew normal random values simulation on the simplex
</h2><span id='topic+rcompsn'></span>

<h3>Description</h3>

<p>Multivariate skew normal random values simulation on the simplex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcompsn(n, xi, Omega, alpha, dp = NULL, type = "alr")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20skew+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20skew+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_xi">xi</code></td>
<td>

<p>A numeric vector of length <code class="reqn">d</code> representing the location parameter of the distribution.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20skew+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_omega">Omega</code></td>
<td>

<p>A <code class="reqn">d \times d</code> symmetric positive-definite matrix of dimension.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20skew+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_alpha">alpha</code></td>
<td>

<p>A numeric vector which regulates the slant of the density.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20skew+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_dp">dp</code></td>
<td>

<p>A list with three elements, corresponding to xi, Omega and alpha described above. The default value is FALSE.
If dp is assigned, individual parameters must not be specified.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20skew+2B20normal+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_type">type</code></td>
<td>

<p>The alr (type = &quot;alr&quot;) or the ilr (type = &quot;ilr&quot;) is to be used for closing the Euclidean data onto the simplex.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is straightforward, generate random values from a multivariate t distribution in <code class="reqn">R^d</code> and brings the
values to the simplex <code class="reqn">S^d</code> using the inverse of a log-ratio transformation.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Azzalini, A. and Dalla Valle, A. (1996). The multivariate skew-normal distribution. Biometrika, 83(4): 715-726.
</p>
<p>Azzalini, A. and Capitanio, A. (1999). Statistical applications of the multivariate skew normal distribution. Journal of the Royal 
Statistical Society Series B, 61(3):579-602. Full-length version available from http://arXiv.org/abs/0911.2093
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.den">comp.den</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+rcompnorm">rcompnorm</a>, <a href="mvtnorm.html#topic+rmvt">rmvt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:2])
par &lt;- sn::msn.mle(y = x)$dp
y &lt;- rcompsn(100, dp = par)
comp.den(y, dist = "skewnorm")
ternary(y)
</code></pre>

<hr>
<h2 id='Multivariate+20t+20random+20values+20simulation+20on+20the+20simplex'>
Multivariate t random values simulation on the simplex
</h2><span id='topic+rcompt'></span>

<h3>Description</h3>

<p>Multivariate t random values simulation on the simplex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcompt(n, m, s, dof, type = "alr")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20t+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20t+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_m">m</code></td>
<td>

<p>The mean vector in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20t+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_s">s</code></td>
<td>

<p>The covariance matrix in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20t+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_dof">dof</code></td>
<td>

<p>The degrees of freedom.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20t+2B20random+2B20values+2B20simulation+2B20on+2B20the+2B20simplex_+3A_type">type</code></td>
<td>

<p>The alr (type = &quot;alr&quot;) or the ilr (type = &quot;ilr&quot;) is to be used for closing the Euclidean data onto the simplex.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is straightforward, generate random values from a multivariate t distribution in <code class="reqn">R^d</code> and brings the
values to the simplex <code class="reqn">S^d</code> using the inverse of a log-ratio transformation.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.den">comp.den</a>, <a href="#topic+rdiri">rdiri</a>, <a href="#topic+rcompnorm">rcompnorm</a>, <a href="mvtnorm.html#topic+rmvt">rmvt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:2])
m &lt;- Rfast::colmeans(x)
s &lt;- var(x)
y &lt;- rcompt(100, m, s, 10)
comp.den(y, dist = "t")
ternary(y)
</code></pre>

<hr>
<h2 id='Naive+20Bayes+20classifiers+20for+20compositional+20data'>
Naive Bayes classifiers for compositional data
</h2><span id='topic+comp.nb'></span>

<h3>Description</h3>

<p>Naive Bayes classifiers for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.nb(xnew = NULL, x, ina, type = "beta")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new compositional predictor data whose class you want to predict. Zeros are not allowed
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional predictor data. Zeros are not allowed
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_ina">ina</code></td>
<td>

<p>A vector of data. The response variable, which is categorical (factor is acceptable).
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>The type of naive Bayes, &quot;beta&quot;, &quot;logitnorm&quot;, &quot;cauchy&quot;, &quot;laplace&quot;, &quot;gamma&quot;, &quot;normlog&quot; or &quot;weibull&quot;. For the last 4 distributions, the negative of the logarithm of the compositional data is applied first.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the classifier a list including (the ni and est are common for all classifiers):
</p>
<table>
<tr><td><code>shape</code></td>
<td>

<p>A matrix with the shape parameters.
</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>

<p>A matrix with the scale parameters.
</p>
</td></tr>
<tr><td><code>expmu</code></td>
<td>

<p>A matrix with the mean parameters.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>A matrix with the (MLE, hence biased) variance parameters.
</p>
</td></tr>
<tr><td><code>location</code></td>
<td>

<p>A matrix with the location parameters (medians).
</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>

<p>A matrix with the scale parameters.
</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>

<p>A matrix with the scale parameters.
</p>
</td></tr>
<tr><td><code>var</code></td>
<td>

<p>A matrix with the variance parameters.
</p>
</td></tr>
<tr><td><code>a</code></td>
<td>

<p>A matrix with the &quot;alpha&quot; parameters.
</p>
</td></tr>
<tr><td><code>b</code></td>
<td>

<p>A matrix with the &quot;beta&quot; parameters.
</p>
</td></tr>
<tr><td><code>ni</code></td>
<td>

<p>The sample size of each group in the dataset.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated group of the xnew observations. It returns a numerical value back regardless of the target
variable being numerical as well or factor. Hence, it is suggested that you do \&quot;as.numeric(ina)\&quot; in order to
see what is the predicted class of the new data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning.
New York: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.compnb">cv.compnb</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.knn">alfa.knn</a>, <a href="#topic+comp.knn">comp.knn</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+dda">dda</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Compositional::rdiri(100, runif(5) )
ina &lt;- rbinom(100, 1, 0.5) + 1
a &lt;- comp.nb(x, x, ina, type = "beta")
</code></pre>

<hr>
<h2 id='Naive+20Bayes+20classifiers+20for+20compositional+20data+20using+20the+20alpha-transformation'>
Naive Bayes classifiers for compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.nb'></span>

<h3>Description</h3>

<p>Naive Bayes classifiers for compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.nb(xnew, x, ina, a, type = "gaussian")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new compositional predictor data whose class you want to predict. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional predictor data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_ina">ina</code></td>
<td>

<p>A vector of data. The response variable, which is categorical (factor is acceptable).
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>This can be a vector of values or a single number.
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_type">type</code></td>
<td>

<p>The type of naive Bayes, &quot;gaussian&quot;, &quot;cauchy&quot; or &quot;laplace&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional and a naive Bayes classifier is employed.
</p>


<h3>Value</h3>

<p>A matrix with the estimated groups. One column for each value of <code class="reqn">\alpha</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning. New York: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.nb">comp.nb</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.knn">alfa.knn</a>, <a href="#topic+comp.knn">comp.knn</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Compositional::rdiri(100, runif(5) )
ina &lt;- rbinom(100, 1, 0.5) + 1
mod &lt;- alfa.nb(x, x, a = c(0, 0.1, 0.2), ina )
</code></pre>

<hr>
<h2 id='Non+20linear+20least+20squares+20regression+20for+20compositional+20data'>
Non linear least squares regression for compositional data
</h2><span id='topic+ols.compreg'></span>

<h3>Description</h3>

<p>Non linear least squares regression for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols.compreg(y, x, con = TRUE, B = 1, ncores = 1, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Non+2B20linear+2B20least+2B20squares+2B20regression+2B20for+2B20compositional+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Non+2B20linear+2B20least+2B20squares+2B20regression+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix or a data frame with the predictor variable(s).
</p>
</td></tr>
<tr><td><code id="Non+2B20linear+2B20least+2B20squares+2B20regression+2B20for+2B20compositional+2B20data_+3A_con">con</code></td>
<td>

<p>If this is TRUE (default) then the constant term is estimated, otherwise the model includes no constant term.
</p>
</td></tr>
<tr><td><code id="Non+2B20linear+2B20least+2B20squares+2B20regression+2B20for+2B20compositional+2B20data_+3A_b">B</code></td>
<td>

<p>If B is greater than 1 bootstrap estimates of the standard error are returned.
If B=1, no standard errors are returned.
</p>
</td></tr>
<tr><td><code id="Non+2B20linear+2B20least+2B20squares+2B20regression+2B20for+2B20compositional+2B20data_+3A_ncores">ncores</code></td>
<td>

<p>If ncores is 2 or more parallel computing is performed. This is to be used for the
case of bootstrap. If B=1, this is not taken into consideration.
</p>
</td></tr>
<tr><td><code id="Non+2B20linear+2B20least+2B20squares+2B20regression+2B20for+2B20compositional+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ordinary least squares between the observed and the fitted compositional data
is adopted as the objective function. This involves numerical optimization since
the relationship is non linear. There is no log-likelihood.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>covbe</code></td>
<td>

<p>The covariance matrix of the beta coefficients, if bootstrap is chosen, i.e. if B &gt; 1.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Murteira, Jose MR, and Joaquim JS Ramalho 2016. Regression analysis of multivariate fractional data.
Econometric Reviews 35(4): 515-552.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+alfa.reg">alfa.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.vector(fgl[, 1])
y &lt;- as.matrix(fgl[, 2:9])
y &lt;- y / rowSums(y)
mod1 &lt;- ols.compreg(y, x, B = 1, ncores = 1)
mod2 &lt;- js.compreg(y, x, B = 1, ncores = 1)
</code></pre>

<hr>
<h2 id='Non-parametric+20zero+20replacement+20strategies'>
Non-parametric zero replacement strategies
</h2><span id='topic+zeroreplace'></span>

<h3>Description</h3>

<p>Non-parametric zero replacement strategies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeroreplace(x, a = 0.65, delta = NULL, type = "multiplicative")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Non-parametric+2B20zero+2B20replacement+2B20strategies_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Non-parametric+2B20zero+2B20replacement+2B20strategies_+3A_a">a</code></td>
<td>

<p>The replacement value (<code class="reqn">\delta</code>) will be &quot;a&quot; times the minimum value observed in the compositional data.
</p>
</td></tr>
<tr><td><code id="Non-parametric+2B20zero+2B20replacement+2B20strategies_+3A_delta">delta</code></td>
<td>

<p>Unless you specify the replacement value <code class="reqn">\delta</code> here.
</p>
</td></tr>
<tr><td><code id="Non-parametric+2B20zero+2B20replacement+2B20strategies_+3A_type">type</code></td>
<td>

<p>This can be any of &quot;multiplicative&quot;, &quot;additive&quot; or &quot;simple&quot;. See the references for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;additive&quot; is the zero replacement strategy suggested in Aitchison (1986, pg. 269).
All of the three strategies can be found in Martin-Fernandez et al. (2003).
</p>


<h3>Value</h3>

<p>A matrix with the zero replaced compositional data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Martin-Fernandez J. A., Barcelo-Vidal C. &amp; Pawlowsky-Glahn, V. (2003).
Dealing with zeros and missing values in compositional data sets using nonparametric imputation.
Mathematical Geology, 35(3): 253-278.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perturbation">perturbation</a>, <a href="#topic+alfa">alfa</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:20, 1:4])
x &lt;- x/ rowSums(x)
x[ sample(1:20, 4),  sample(1:4, 1) ] &lt;- 0
x &lt;- x / rowSums(x)
zeroreplace(x)
</code></pre>

<hr>
<h2 id='Permutation+20independence+20test+20in+20the+20constrained+20linear+20least+20squares+20for+20compositional+20responses+20and+20predictors'>
Permutation independence test in the constrained linear least squares for compositional responses and predictors
</h2><span id='topic+ols.compcomp.test'></span>

<h3>Description</h3>

<p>Permutation independence test in the constrained linear least squares for compositional responses and predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols.compcomp.test(y, x, B = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Permutation+2B20independence+2B20test+2B20in+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Permutation+2B20independence+2B20test+2B20in+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional predictors. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Permutation+2B20independence+2B20test+2B20in+2B20the+2B20constrained+2B20linear+2B20least+2B20squares+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_b">B</code></td>
<td>

<p>The number of permutations to perform.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Permutation independence test in the constrained linear least squares for compositional
responses and predictors is performed. The observed test statistic is the MSE computed by <code><a href="#topic+ols.compcomp">ols.compcomp</a></code>. Then, the rows of X are permuted B times and each time the constrained OLS is performed and the
MSE is computed. The p-value is then computed in the usual way.
</p>


<h3>Value</h3>

<p>The p-value for the test of independence between Y and X.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ols.compcomp">ols.compcomp</a>, <a href="#topic+tflr">tflr</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
set.seed(1234)
y &lt;- rdiri(214, runif(4, 1, 3))
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
ols.compcomp.test(y, x, B = 99)
</code></pre>

<hr>
<h2 id='Perturbation+20operation'>
Perturbation operation
</h2><span id='topic+perturbation'></span>

<h3>Description</h3>

<p>Perturbation operation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perturbation(x, y, oper = "+")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Perturbation+2B20operation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Perturbation+2B20operation_+3A_y">y</code></td>
<td>

<p>Either a matrix with compositional data or a vector with compositional data. In either case, the data may not be compositional data, as long as they non negative.
</p>
</td></tr>
<tr><td><code id="Perturbation+2B20operation_+3A_oper">oper</code></td>
<td>

<p>For the summation this must be &quot;*&quot; and for the negation it must be &quot;/&quot;. According to Aitchison (1986), multiplication is equal to summation in the log-space, and division is equal to negation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the perturbation operation defined by Aitchison (1986).
</p>


<h3>Value</h3>

<p>A matrix with the perturbed compositional data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+power">power</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:15, 1:4])
y &lt;- as.matrix(iris[21:35, 1:4])
perturbation(x, y)
perturbation(x, y[1, ])
</code></pre>

<hr>
<h2 id='Plot+20of+20the+20LASSO+20coefficients'>
Plot of the LASSO coefficients
</h2><span id='topic+lassocoef.plot'></span>

<h3>Description</h3>

<p>Plot of the LASSO coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lassocoef.plot(lasso, lambda = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Plot+2B20of+2B20the+2B20LASSO+2B20coefficients_+3A_lasso">lasso</code></td>
<td>

<p>An object where you have saved the result of the LASSO regression. See the examples for more details.
</p>
</td></tr>
<tr><td><code id="Plot+2B20of+2B20the+2B20LASSO+2B20coefficients_+3A_lambda">lambda</code></td>
<td>

<p>If you want the x-axis to contain the logarithm of the penalty parameter <code class="reqn">\log(\lambda)</code> set this to TRUE.
Otherwise the x-axis will contain the <code class="reqn">L_1</code>-norm of the coefficients.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots the <code class="reqn">L_2</code>-norm of the coefficients of each predictor variable versus the
<code class="reqn">\log(\lambda)</code> or the <code class="reqn">L_1</code>-norm of the coefficients. This is the same plot as the one produced
by the glmnet package with type.coef = &quot;2norm&quot;.
</p>


<h3>Value</h3>

<p>A plot of the <code class="reqn">L_2</code>-norm of the coefficients of each predictor variable (y-axis) versus the <code class="reqn">L_1</code>-norm
of all the coefficients (x-axis).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Abdulaziz Alenazi.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Abdulaziz Alenazi <a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a>.
<a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a>.
</p>


<h3>References</h3>

<p>Alenazi, A. A. (2022). f-divergence regression models for compositional data. 
Pakistan Journal of Statistics and Operation Research, 18(4): 867&ndash;882.
</p>
<p>Friedman, J., Hastie, T. and Tibshirani, R. (2010) Regularization Paths for Generalized Linear Models via
Coordinate Descent. Journal of Statistical Software, Vol. 33(1), 1&ndash;22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lasso.klcompreg">lasso.klcompreg</a>, <a href="#topic+cv.lasso.klcompreg">cv.lasso.klcompreg</a>, <a href="#topic+lasso.compreg">lasso.compreg</a>, <a href="#topic+cv.lasso.compreg">cv.lasso.compreg</a>,
<a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix(iris[, 1:4])
y &lt;- y / rowSums(y)
x &lt;- matrix( rnorm(150 * 30), ncol = 30 )
a &lt;- lasso.klcompreg(y, x)
lassocoef.plot(a)
b &lt;- lasso.compreg(y, x)
lassocoef.plot(b)
</code></pre>

<hr>
<h2 id='Power+20operation'>
Power operation
</h2><span id='topic+pow'></span>

<h3>Description</h3>

<p>Power operation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pow(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Power+2B20operation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Power+2B20operation_+3A_a">a</code></td>
<td>

<p>Either a vector with numbers of a single number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the power operation defined by Aitchison (1986). It is also the starting point of the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Value</h3>

<p>A matrix with the power transformed compositional data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
http://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perturbation">perturbation</a>, <a href="#topic+alfa">alfa</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:15, 1:4])
a &lt;- runif(1)
pow(x, a)
</code></pre>

<hr>
<h2 id='Principal+20component+20analysis'>
Principal component analysis
</h2><span id='topic+logpca'></span>

<h3>Description</h3>

<p>Principal component analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logpca(x, center = TRUE, scale = TRUE, k = NULL, vectors = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Principal+2B20component+2B20analysis_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are not allowed.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis_+3A_center">center</code></td>
<td>

<p>Do you want your data centered? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis_+3A_scale">scale</code></td>
<td>

<p>Do you want each of your variables scaled, i.e. to have unit variance? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis_+3A_k">k</code></td>
<td>

<p>If you want a specific number of eigenvalues and eigenvectors set it here, otherwise all
eigenvalues (and eigenvectors if requested) will be returned.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis_+3A_vectors">vectors</code></td>
<td>

<p>Do you want the eigenvectors be returned? By dafault this is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The logarithm is applied to the compositional data and PCA is performed.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>values</code></td>
<td>

<p>The eigenvalues.
</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>

<p>The eigenvectors.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.pca">alfa.pca</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+kl.alfapcr">kl.alfapcr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/ rowSums(x)
a &lt;- logpca(x)
</code></pre>

<hr>
<h2 id='Principal+20component+20analysis+20using+20the+20alpha-transformation'>
Principal component analysis using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.pca'></span>

<h3>Description</h3>

<p>Principal component analysis using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.pca(x, a, center = TRUE, scale = TRUE, k = NULL, vectors = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Principal+2B20component+2B20analysis+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are allowed. In that case
&quot;a&quot; should be positive.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> to use in the <code class="reqn">\alpha</code>-transformation.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis+2B20using+2B20the+2B20alpha-transformation_+3A_center">center</code></td>
<td>

<p>Do you want your data centered? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis+2B20using+2B20the+2B20alpha-transformation_+3A_scale">scale</code></td>
<td>

<p>Do you want each of your variables scaled, i.e. to have unit variance?
TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis+2B20using+2B20the+2B20alpha-transformation_+3A_k">k</code></td>
<td>

<p>If you want a specific number of eigenvalues and eigenvectors set it here,
otherwise all eigenvalues (and eigenvectors if requested) will be returned.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20analysis+2B20using+2B20the+2B20alpha-transformation_+3A_vectors">vectors</code></td>
<td>

<p>Do you want the eigenvectors be returned? By dafault this is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data and then
PCA is performed. Note however, that the right multiplication by the Helmert
sub-matrix is not applied in order to be in accordance with Aitchison (1983).
When <code class="reqn">\alpha=0</code>, this results to the PCA proposed by Aitchison (1983).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>values</code></td>
<td>

<p>The eigenvalues.
</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>

<p>The eigenvectors.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data.
Chapman &amp; Hall.
</p>
<p>Aitchison, J. (1983). Principal component analysis of compositional data.
Biometrika, 70(1), 57-65.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power
transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
http://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logpca">logpca</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+kl.alfapcr">kl.alfapcr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/ rowSums(x)
a &lt;- alfa.pca(x, 0.5)
</code></pre>

<hr>
<h2 id='Principal+20component+20generalised+20linear+20models'>
Principal component generalised linear models
</h2><span id='topic+pcr'></span><span id='topic+glm.pcr'></span>

<h3>Description</h3>

<p>Principal component generalised linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcr(y, x, k = 1, xnew = NULL)
glm.pcr(y, x, k = 1, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Principal+2B20component+2B20generalised+2B20linear+2B20models_+3A_y">y</code></td>
<td>

<p>A numerical vector, a real values vector or a numeric vector with 0 and 1 (binary) or a
vector with discrete (count) data.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20generalised+2B20linear+2B20models_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variable(s), they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20generalised+2B20linear+2B20models_+3A_k">k</code></td>
<td>

<p>A number greater than or equal to 1. How many principal components to use. In the case of
&quot;pcr&quot; this can be a single number or a vector. In the second case you get results for the
sequence of principal components.
</p>
</td></tr>
<tr><td><code id="Principal+2B20component+2B20generalised+2B20linear+2B20models_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Principal component regression is performed with linear, binary logistic or Poisson regression,
depending on the nature of the response variable. The principal components of the cross product
of the independent variables are obtained and classical regression is performed. This is used
in the function <code><a href="#topic+alfa.pcr">alfa.pcr</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients of the predictor variables computed via the principcal components if &quot;pcr&quot; is used.
</p>
</td></tr>
<tr><td><code>model</code></td>
<td>

<p>The summary of the logistic or Poisson regression model.
</p>
</td></tr>
<tr><td><code>per</code></td>
<td>

<p>The percentage of variance of the predictor variables retained by the k principal components.
</p>
</td></tr>
<tr><td><code>vec</code></td>
<td>

<p>The principal components, the loadings.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted or the predicted values (if xnew is not NULL). If the argument <code>k</code> is a vector then this is a matrix with the estimated values for each number of components.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aguilera A.M., Escabias M. and Valderrama M.J. (2006). Using principal components for estimating
logistic regression with high-dimensional multicollinear data.
Computational Statistics &amp; Data Analysis 50(8): 1905-1924.
</p>
<p>Jolliffe I.T. (2002). Principal Component Analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfapcr.tune">alfapcr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
y &lt;- as.vector(fgl[, 1])
mod1 &lt;- pcr(y, x, 1)
mod2 &lt;- pcr(y, x, 2)
mod &lt;- pcr(y, x, k = 1:4)  ## many results at once

x &lt;- as.matrix(iris[, 1:4])
y&lt;- rbinom(150, 1, 0.6)
mod&lt;- glm.pcr(y, x, k = 1)
</code></pre>

<hr>
<h2 id='Principal+20coordinate+20analysis+20using+20the+20alpha-distance'>
Principal coordinate analysis using the <code class="reqn">\alpha</code>-distance
</h2><span id='topic+alfa.mds'></span>

<h3>Description</h3>

<p>Principal coordinate analysis using the <code class="reqn">\alpha</code>-distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.mds(x, a, k = 2, eig = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20alpha-distance_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20alpha-distance_+3A_a">a</code></td>
<td>

<p>The value of a. In case of zero values in the data it has to be greater than 1.
</p>
</td></tr>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20alpha-distance_+3A_k">k</code></td>
<td>

<p>The maximum dimension of the space which the data are to be represented in. This can be a number between
1 and <code class="reqn">D-1</code>, where <code class="reqn">D</code> denotes the number of dimensions.
</p>
</td></tr>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20alpha-distance_+3A_eig">eig</code></td>
<td>

<p>Should eigenvalues be returned? The default value is TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the <code class="reqn">\alpha</code>-distance matrix and then plugs it into the classical
multidimensional scaling function in the &quot;cmdscale&quot; function.
</p>


<h3>Value</h3>

<p>A list with the results of &quot;cmdscale&quot; function.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Cox, T. F. and Cox, M. A. A. (2001). Multidimensional Scaling. Second edition. Chapman and Hall.
</p>
<p>Mardia, K. V., Kent, J. T. and Bibby, J. M. (1979). Chapter 14 of Multivariate Analysis, London: Academic Press.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+esov.mds">esov.mds</a>, <a href="#topic+alfa.pca">alfa.pca</a>,
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- as.matrix(iris[, 1:4])
  x &lt;- x/ rowSums(x)
  a &lt;- esov.mds(x)
</code></pre>

<hr>
<h2 id='Principal+20coordinate+20analysis+20using+20the+20Jensen-Shannon+20divergence'>
Principal coordinate analysis using the Jensen-Shannon divergence
</h2><span id='topic+esov.mds'></span>

<h3>Description</h3>

<p>Principal coordinate analysis using the Jensen-Shannon divergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>esov.mds(x, k = 2, eig = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20Jensen-Shannon+2B20divergence_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20Jensen-Shannon+2B20divergence_+3A_k">k</code></td>
<td>

<p>The maximum dimension of the space which the data are to be represented in. This can be a number between
1 and <code class="reqn">D-1</code>, where <code class="reqn">D</code> denotes the number of dimensions.
</p>
</td></tr>
<tr><td><code id="Principal+2B20coordinate+2B20analysis+2B20using+2B20the+2B20Jensen-Shannon+2B20divergence_+3A_eig">eig</code></td>
<td>

<p>Should eigenvalues be returned? The default value is TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the Jensen-Shannon divergence matrix and then plugs it into the classical
multidimensional scaling function in the &quot;cmdscale&quot; function.
</p>


<h3>Value</h3>

<p>A list with the results of &quot;cmdscale&quot; function.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Cox, T. F. and Cox, M. A. A. (2001). Multidimensional Scaling. Second edition. Chapman and Hall.
</p>
<p>Mardia, K. V., Kent, J. T. and Bibby, J. M. (1979). Chapter 14 of Multivariate Analysis, London: Academic Press.
</p>
<p>Tsagris, Michail (2015). A novel, divergence based, regression for compositional data.
Proceedings of the 28th Panhellenic Statistics Conference, 15-18/4/2015, Athens, Greece.
https://arxiv.org/pdf/1511.07600.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.mds">alfa.mds</a>, <a href="#topic+alfa.pca">alfa.pca</a>,
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/ rowSums(x)
a &lt;- esov.mds(x)
</code></pre>

<hr>
<h2 id='Projection+20pursuit+20regression+20for+20compositional+20data'>
Projection pursuit regression for compositional data
</h2><span id='topic+comp.ppr'></span>

<h3>Description</h3>

<p>Projection pursuit regression for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.ppr(y, x, nterms = 3, type = "alr", xnew = NULL, yb = NULL )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the continuous predictor variables or a data frame including categorical
predictor variables.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_nterms">nterms</code></td>
<td>

<p>The number of terms to include in the final model.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>Either &quot;alr&quot; or &quot;ilr&quot; corresponding to the additive or the isometric log-ratio transformation respectively.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_yb">yb</code></td>
<td>

<p>If you have already transformed the data using a log-ratio transformation put it here.
Othewrise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the standard projection pursuit. See the built-in function &quot;ppr&quot; for more details.
</p>


<h3>Value</h3>

<p>A list includign:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the regression.
</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>

<p>The produced model as returned by the function &quot;ppr&quot;.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American
Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compppr.tune">compppr.tune</a>, <a href="#topic+aknn.reg">aknn.reg</a>, <a href="#topic+akern.reg">akern.reg</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+alfa.reg">alfa.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix(iris[, 1:3])
y &lt;- y/ rowSums(y)
x &lt;- iris[, 4]
mod &lt;- comp.ppr(y, x)
</code></pre>

<hr>
<h2 id='Projection+20pursuit+20regression+20with+20compositional+20predictor+20variables'>
Projection pursuit regression with compositional predictor variables
</h2><span id='topic+pprcomp'></span>

<h3>Description</h3>

<p>Projection pursuit regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pprcomp(y, x, nterms = 3, type = "log", xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>A numerical vector with the continuous variable.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_nterms">nterms</code></td>
<td>

<p>The number of terms to include in the final model.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_type">type</code></td>
<td>

<p>Either &quot;alr&quot; or &quot;log&quot; corresponding to the additive log-ratio transformation
or the simple logarithm applied to the compositional data.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the standard projection pursuit. See the built-in function &quot;ppr&quot; for
more details. When the data are transformed with the additive log-ratio
transformation this is close in spirit to the log-contrast regression.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the regression.
</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>

<p>The produced model as returned by the function &quot;ppr&quot;.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American
Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+pprcomp.tune">pprcomp.tune</a>, <a href="#topic+ice.pprcomp">ice.pprcomp</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+lc.reg">lc.reg</a>, <a href="#topic+comp.ppr">comp.ppr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 2:4] )
x &lt;- x/ rowSums(x)
y &lt;- iris[, 1]
pprcomp(y, x)
</code></pre>

<hr>
<h2 id='Projection+20pursuit+20regression+20with+20compositional+20predictor+20variables+20using+20the+20alpha-transformation'>
Projection pursuit regression with compositional predictor variables using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.pprcomp'></span>

<h3>Description</h3>

<p>Projection pursuit regression with compositional predictor variables using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.pprcomp(y, x, nterms = 3, a, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numerical vector with the continuous variable.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_nterms">nterms</code></td>
<td>

<p>The number of terms to include in the final model.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> for the <code class="reqn">\alpha</code>-transformation.
</p>
</td></tr>
<tr><td><code id="Projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the standard projection pursuit. See the built-in function &quot;ppr&quot; for
more details. The compositional data are transformed with the <code class="reqn">\alpha</code>-transformation
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the regression.
</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>

<p>The produced model as returned by the function &quot;ppr&quot;.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American
Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfapprcomp.tune">alfapprcomp.tune</a>, <a href="#topic+pprcomp">pprcomp</a>, <a href="#topic+comp.ppr">comp.ppr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 2:4] )
x &lt;- x / rowSums(x)
y &lt;- iris[, 1]
alfa.pprcomp(y, x, a = 0.5)
</code></pre>

<hr>
<h2 id='Projections+20based+20test+20for+20distributional+20equality+20of+20two+20groups'>
Projections based test for distributional equality of two groups
</h2><span id='topic+dptest'></span>

<h3>Description</h3>

<p>Projections based test for distributional equality of two groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dptest(x1, x2, B = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Projections+2B20based+2B20test+2B20for+2B20distributional+2B20equality+2B20of+2B20two+2B20groups_+3A_x1">x1</code></td>
<td>

<p>A matrix containing compositional data of the first group.
</p>
</td></tr>
<tr><td><code id="Projections+2B20based+2B20test+2B20for+2B20distributional+2B20equality+2B20of+2B20two+2B20groups_+3A_x2">x2</code></td>
<td>

<p>A matrix containing compositional data of the second group.
</p>
</td></tr>
<tr><td><code id="Projections+2B20based+2B20test+2B20for+2B20distributional+2B20equality+2B20of+2B20two+2B20groups_+3A_b">B</code></td>
<td>

<p>The number of random uniform projections to use.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test compares the distributions of two compositional datasets 
using random projections. For more details see 
Cuesta-Albertos, Cuevas and Fraiman (2009). 
</p>


<h3>Value</h3>

<p>A vector including:
</p>
<table>
<tr><td><code>pvalues</code></td>
<td>

<p>The p-values of the Kolmogorov-Smirnov tests.
</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>

<p>The p-value of the test based on the Benjamini and Heller (2008) procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Cuesta-Albertos J. A., Cuevas A. and Fraiman, R. (2009). 
On projection-based tests for directional and compositional data. 
Statistics and Computing, 19: 367&ndash;380.
</p>
<p>Benjamini Y. and Heller R. (2008). Screening for partial conjunction hypotheses. 
Biometrics, 64(4): 1215&ndash;1222.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.test">comp.test</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rdiri(50, c(3, 4, 5)) ## Fisher distribution with low concentration
x2 &lt;- rdiri(50, c(3, 4, 5))
dptest(x1, x2)
</code></pre>

<hr>
<h2 id='Proportionality+20correlation+20coefficient+20matrix'>
Proportionality correlation coefficient matrix
</h2><span id='topic+pcc'></span>

<h3>Description</h3>

<p>Proportionality correlation coefficient matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcc(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Proportionality+2B20correlation+2B20coefficient+2B20matrix_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data. Zeros are not allowed as the logarithm is applied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the proportionality correlation coefficient matrix. See Lovell et al. (2015) for more information.
</p>


<h3>Value</h3>

<p>A matrix with the alr transformed data (if alr is used) or with the compositional data (if the alrinv is used).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Zheng, B. (2000). Summarizing the goodness of fit of generalized linear models for longitudinal data.
Statistics in medicine, 19(10), 1265-1275.
</p>
<p>Lovell D., Pawlowsky-Glahn V., Egozcue J. J., Marguerat S. and Bahler, J. (2015). Proportionality: a valid alternative
to correlation for relative data. PLoS Computational Biology, 11(3), e1004075.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acor">acor</a>, <a href="#topic+alr">alr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Compositional::rdiri(100, runif(4) )
a &lt;- Compositional::pcc(x)
</code></pre>

<hr>
<h2 id='Quasi+20binomial+20regression+20for+20proportions'>
Quasi binomial regression for proportions
</h2><span id='topic+propreg'></span><span id='topic+propregs'></span>

<h3>Description</h3>

<p>Quasi binomial regression for proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propreg(y, x, varb = "quasi", tol = 1e-07, maxiters = 100) 
propregs(y, x, varb = "quasi", tol = 1e-07, logged = FALSE, maxiters = 100) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_y">y</code></td>
<td>

<p>A numerical vector proportions. 0s and 1s are allowed. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_x">x</code></td>
<td>

<p>For the &quot;propreg&quot; a matrix with data, the predictor variables. This can be a matrix or a data frame.
For the &quot;propregs&quot; this must be a numerical matrix, where each columns denotes a variable.
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm. This is set to <code class="reqn">10^{-9}</code> by default.
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_varb">varb</code></td>
<td>

<p>The type of estimate to be used in order to estimate the covariance matrix of the regression coefficients. 
There are two options, either &quot;quasi&quot; (default value) or &quot;glm&quot;. See the references for more information. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?  
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations before the Newton-Raphson is terminated automatically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We are using the Newton-Raphson, but unlike R's built-in function &quot;glm&quot; we do no checks and no extra calculations, 
or whatever. Simply the model. The &quot;propregs&quot; is to be used for very many univariate regressions. The &quot;x&quot; is a 
matrix in this case and the significance of each variable (column of the matrix) is tested. The function accepts binary 
responses as well (0 or 1).
</p>


<h3>Value</h3>

<p>For the &quot;propreg&quot; function a list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>varb</code></td>
<td>

<p>The covariance matrix of the regression coefficients.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The phi parameter is returned if the input argument &quot;varb&quot; was set to &quot;glm&quot;, othwerise this is NULL.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A table similar to the one produced by &quot;glm&quot; with the estimated regression coefficients, their standard error,
Wald test statistic and p-values.
</p>
</td></tr>
</table>
<p>For the &quot;propregs&quot; a two-column matrix with the test statistics (Wald statistic) and the associated p-values 
(or their loggarithm). 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response variables with 
an application to 401(K) plan participation rates. Journal of Applied Econometrics, 11(6): 619&ndash;632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> anova_propreg univglms, score.glms, logistic_only
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbeta(100, 1, 4)
x &lt;- matrix(rnorm(100 * 3), ncol = 3)
a &lt;- propreg(y, x)
y &lt;- rbeta(100, 1, 4)
x &lt;- matrix(rnorm(400 * 100), ncol = 400)
b &lt;- propregs(y, x)
mean(b[, 2] &lt; 0.05)
</code></pre>

<hr>
<h2 id='Random+20values+20generation+20from+20some+20univariate+20distributions+20defined+20on+20the+20+280+2C1+29+20interval'>
Random values generation from some univariate distributions defined on the <code class="reqn">(0,1)</code> interval
</h2><span id='topic+rbeta1'></span><span id='topic+runitweibull'></span><span id='topic+rlogitnorm'></span>

<h3>Description</h3>

<p>Random values generation from some univariate distributions defined on the <code class="reqn">(0,1)</code> interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbeta1(n, a)
runitweibull(n, a, b)
rlogitnorm(n, m, s, fast = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Random+2B20values+2B20generation+2B20from+2B20some+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20+2B280+2B2C1+2B29+2B20interval_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20generation+2B20from+2B20some+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20+2B280+2B2C1+2B29+2B20interval_+3A_a">a</code></td>
<td>

<p>The shape parameter of the beta distribution. In the case of the unit Weibull, this is the shape parameter.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20generation+2B20from+2B20some+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20+2B280+2B2C1+2B29+2B20interval_+3A_b">b</code></td>
<td>

<p>This is the scale parameter for the unit Weibull distribution.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20generation+2B20from+2B20some+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20+2B280+2B2C1+2B29+2B20interval_+3A_m">m</code></td>
<td>

<p>The mean of the univariate normal in <code class="reqn">R</code>.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20generation+2B20from+2B20some+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20+2B280+2B2C1+2B29+2B20interval_+3A_s">s</code></td>
<td>

<p>The standard deviation of the univariate normal in <code class="reqn">R</code>.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20generation+2B20from+2B20some+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20+2B280+2B2C1+2B29+2B20interval_+3A_fast">fast</code></td>
<td>

<p>If you want a faster generation set this equal to TRUE. This will use the Rnorm() function from
the Rfast package. However, the speed is only observable if you want to simulate at least 500
(this number may vary among computers) observations. The larger the sample size the higher the speed-up.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function genrates random values from the Be(a, 1), the unit Weibull or the univariate logistic
normal distribution.
</p>


<h3>Value</h3>

<p>A vector with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beta.est">beta.est</a>, <a href="#topic+colbeta.est">colbeta.est</a>, <a href="#topic+rdiri">rdiri</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rbeta1(100, 3)
</code></pre>

<hr>
<h2 id='Regression+20with+20compositional+20data+20using+20the+20alpha-transformation'>
Regression with compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.reg'></span><span id='topic+alfa.reg2'></span><span id='topic+alfa.reg3'></span>

<h3>Description</h3>

<p>Regression with compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.reg(y, x, a, xnew = NULL, yb = NULL, seb = FALSE)
alfa.reg2(y, x, a, xnew = NULL, yb = NULL, seb = FALSE)
alfa.reg3(y, x, a = c(-1, 1), xnew = NULL, seb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Regression+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Regression+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the continuous predictor variables or a data frame including categorical predictor variables.
</p>
</td></tr>
<tr><td><code id="Regression+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied and the solution exists in a closed form, since it the classical mutivariate regression. For the alfa.reg2() this should be a vector of <code class="reqn">\alpha</code> values and the function call repeatedly the alfa.reg() function. For the alfa.reg3() function it should be a vector with two values, the endpoints of the interval of <code class="reqn">\alpha</code>. This function searches for the optimal vaue of <code class="reqn">\alpha</code> that minimizes the sum of squares of the errors. Using the <code><a href="stats.html#topic+optimize">optimize</a></code> function it searches for the optimal value of <code class="reqn">\alpha</code>. Instead of choosing the value of <code class="reqn">\alpha</code> using <code><a href="#topic+alfareg.tune">alfareg.tune</a></code> (that uses cross-validation) one can select it this way.
</p>
</td></tr>
<tr><td><code id="Regression+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
<tr><td><code id="Regression+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_yb">yb</code></td>
<td>

<p>If you have already transformed the data using the <code class="reqn">\alpha</code>-transformation with the same <code class="reqn">\alpha</code> as given in the argument &quot;a&quot;, put it here. Othewrise leave it NULL.
</p>
<p>This is intended to be used in the function <code><a href="#topic+alfareg.tune">alfareg.tune</a></code> in order to speed up the process. The time difference in that function is small for small samples.
But, if you have a few thousands and or a few more components, there will be bigger differences.
</p>
</td></tr>
<tr><td><code id="Regression+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_seb">seb</code></td>
<td>

<p>Do you want the standard error of the coefficients to be returned? In the <code><a href="#topic+alfareg.tune">alfareg.tune</a></code> function this extra computation that is avoided can save some time.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first and then multivariate regression is applied. This involves numerical optimisation. The alfa.reg2() function accepts a vector with many values of <code class="reqn">\alpha</code>, while the the alfa.reg3() function searches for the value of <code class="reqn">\alpha</code> that minimizes the Kulback-Leibler divergence between the observed and the fitted compositional values.
</p>


<h3>Value</h3>

<p>For the alfa.reg() function a list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the beta coefficients.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values for xnew if xnew is not NULL.
</p>
</td></tr>
</table>
<p>For the alfa.reg2() function a list with as many sublists as the number of values of <code class="reqn">\alpha</code>. Each element (sublist) of the list contains the above outcomes of the alfa.reg() function.
</p>
<p>For the alfa.reg3() function a list with all previous elements plus an output &quot;alfa&quot;, the optimal value of <code class="reqn">\alpha</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. Chilean Journal of Statistics, 6(2): 47-57.
https://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Mardia K.V., Kent J.T., and Bibby J.M. (1979). Multivariate analysis. Academic press.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfareg.tune">alfareg.tune</a>, <a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+kl.compreg">kl.compreg</a>,
<a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+comp.reg">comp.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.vector(fgl[1:40, 1])
y &lt;- as.matrix(fgl[1:40, 2:9])
y &lt;- y / rowSums(y)
mod &lt;- alfa.reg(y, x, 0.2)
</code></pre>

<hr>
<h2 id='Regularised+20and+20flexible+20discriminant+20analysis+20for+20compositional+20data+20using+20the+20alpha-transformation'>
Regularised and flexible discriminant analysis for compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.rda'></span><span id='topic+alfa.fda'></span>

<h3>Description</h3>

<p>Regularised and flexible discriminant analysis for compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.rda(xnew, x, ina, a, gam = 1, del = 0)
alfa.fda(xnew, x, ina, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new compositional data whose group is to be predicted. Zeros are allowed, but you must be careful to choose strictly positive vcalues of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed, but you must be careful to choose strictly positive vcalues of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_ina">ina</code></td>
<td>

<p>A group indicator variable for the available data.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> for the <code class="reqn">\alpha</code>-transformation.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_gam">gam</code></td>
<td>

<p>This is a number between 0 and 1. It is the weight of the pooled covariance and the diagonal matrix.
</p>
</td></tr>
<tr><td><code id="Regularised+2B20and+2B20flexible+2B20discriminant+2B20analysis+2B20for+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_del">del</code></td>
<td>

<p>This is a number between 0 and 1. It is the weight of the LDA and QDA.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the alfa.rda, the covariance matrix of each group is calcualted and then the pooled covariance matrix. The spherical covariance matrix consists of the average of the pooled variances in its diagonal and zeros in the off-diagonal elements. gam is the weight of the pooled covariance matrix and 1-gam is the weight of the spherical covariance matrix, Sa = gam * Sp + (1-gam) * sp. Then it is a compromise between LDA and QDA. del is the weight of Sa and 1-del the weight of each group covariance group.
</p>
<p>For the alfa.fda a flexible discriminant analysis is performed. See the R package <b>fda</b> for more details.
</p>


<h3>Value</h3>

<p>For the alfa.rda a list including:
</p>
<table>
<tr><td><code>prob</code></td>
<td>

<p>The estimated probabilities of the new data of belonging to each group.
</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>

<p>The estimated socres of the new data of each group.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated group membership of the new data.
</p>
</td></tr>
</table>
<p>For the alfa.fda a list including:
</p>
<table>
<tr><td><code>mod</code></td>
<td>

<p>An fda object as returned by the command fda of the R package mda.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated group membership of the new data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009). The elements of statistical learning, 2nd edition. Springer, Berlin.
</p>
<p>Tsagris Michail, Simon Preston and Andrew T.A. Wood (2016). Improved classification for compositional data using the <code class="reqn">\alpha</code>-transformation. Journal of classification, 33(2): 243-261.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Hastie, Tibshirani and Buja (1994). Flexible Disriminant Analysis by Optimal Scoring. Journal of the American Statistical Association, 89(428):1255-1270.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa">alfa</a>, <a href="#topic+alfarda.tune">alfarda.tune</a>, <a href="#topic+alfa.knn">alfa.knn</a>, <a href="#topic+alfa.nb">alfa.nb</a>, <a href="#topic+comp.nb">comp.nb</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
ina &lt;- iris[, 5]
mod &lt;- alfa.rda(x, x, ina, 0)
table(ina, mod$est)
mod2 &lt;- alfa.fda(x, x, ina, 0)
table(ina, mod2$est)
</code></pre>

<hr>
<h2 id='Ridge+20regression'>
Ridge regression
</h2><span id='topic+ridge.reg'></span>

<h3>Description</h3>

<p>Ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridge.reg(y, x, lambda, B = 1, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ridge+2B20regression_+3A_y">y</code></td>
<td>

<p>A real valued vector. If it contains percentages, the logit transformation is applied.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variable(s), they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression_+3A_lambda">lambda</code></td>
<td>

<p>The value of the regularisation parameter <code class="reqn">\lambda</code>.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression_+3A_b">B</code></td>
<td>

<p>If B = 1 (default value) no bootstrpa is performed. Otherwise bootstrap standard errors are returned.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data whose response value you want to predict put it here, otherwise leave it as is.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is used in the function <code><a href="#topic+alfa.ridge">alfa.ridge</a></code>. There is also a built-in function available from the MASS library, called <code><a href="MASS.html#topic+lm.ridge">lm.ridge</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard eror of the coefficiens. If B &gt; 1 the bootstrap standard errors will be returned.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted or the predicted values (if xnew is not NULL).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> 
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Hoerl A.E. and R.W. Kennard (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1): 55-67.
</p>
<p>Brown P. J. (1994). Measurement, Regression and Calibration. Oxford Science Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ridge.tune">ridge.tune</a>, <a href="#topic+alfa.ridge">alfa.ridge</a>, <a href="#topic+ridge.plot">ridge.plot</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.vector(iris[, 1])
x &lt;- as.matrix(iris[, 2:4])
mod1 &lt;- ridge.reg(y, x, lambda = 0.1)
mod2 &lt;- ridge.reg(y, x, lambda = 0)
</code></pre>

<hr>
<h2 id='Ridge+20regression+20plot'>
Ridge regression plot
</h2><span id='topic+ridge.plot'></span>

<h3>Description</h3>

<p>A plot of the regularised regression coefficients is shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridge.plot(y, x, lambda = seq(0, 5, by = 0.1) )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ridge+2B20regression+2B20plot_+3A_y">y</code></td>
<td>

<p>A numeric vector containing the values of the target variable. If the values are proportions or percentages,
i.e. strictly within 0 and 1 they are mapped into R using the logit transformation. In any case, they must be continuous only.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20plot_+3A_x">x</code></td>
<td>

<p>A numeric matrix containing the continuous variables. Rows are samples and columns are features.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20plot_+3A_lambda">lambda</code></td>
<td>

<p>A grid of values of the regularisation parameter <code class="reqn">\lambda</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For every value of <code class="reqn">\lambda</code> the coefficients are obtained. They are plotted versus the <code class="reqn">\lambda</code> values.
</p>


<h3>Value</h3>

<p>A plot with the values of the coefficients as a function of <code class="reqn">\lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Giorgos Athineou &lt;gioathineou@gmail.com&gt; 
and Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Hoerl A.E. and R.W. Kennard (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1): 55-67.
</p>
<p>Brown P. J. (1994). Measurement, Regression and Calibration. Oxford Science Publications.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ridge.reg">ridge.reg</a>, <a href="#topic+ridge.tune">ridge.tune</a>, <a href="#topic+alfa.ridge">alfa.ridge</a>, <a href="#topic+alfaridge.plot">alfaridge.plot</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.vector(iris[, 1])
x &lt;- as.matrix(iris[, 2:4])
ridge.plot(y, x, lambda = seq(0, 2, by = 0.1) )
</code></pre>

<hr>
<h2 id='Ridge+20regression+20with+20compositional+20data+20in+20the+20covariates+20side+20using+20the+20alpha-transformation'>
Ridge regression with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa.ridge'></span>

<h3>Description</h3>

<p>Ridge regression with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.ridge(y, x, a, lambda, B = 1, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. If they are percentages, they are mapped onto <code class="reqn">R</code> using the logit transformation.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. Zero values are allowed, but you must be careful to choose strictly positive vcalues of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_lambda">lambda</code></td>
<td>

<p>The value of the regularisation parameter, <code class="reqn">\lambda</code>.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_b">B</code></td>
<td>

<p>If B &gt; 1 bootstrap estimation of the standard errors is implemented.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted. If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first and then ridge components regression is performed.
</p>


<h3>Value</h3>

<p>The output of the <a href="#topic+ridge.reg">ridge.reg</a>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. Chilean Journal of Statistics, 6(2): 47-57.
https://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ridge.reg">ridge.reg</a>, <a href="#topic+alfaridge.tune">alfaridge.tune</a>, <a href="#topic+alfaridge.plot">alfaridge.plot</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.vector(fgl[, 1])
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x/ rowSums(x)
mod1 &lt;- alfa.ridge(y, x, a = 0.5, lambda = 0.1, B = 1, xnew = NULL)
mod2 &lt;- alfa.ridge(y, x, a = 0.5, lambda = 1, B = 1, xnew = NULL)
</code></pre>

<hr>
<h2 id='Ridge+20regression+20with+20the+20alpha-transformation+20plot'>
Ridge regression plot
</h2><span id='topic+alfaridge.plot'></span>

<h3>Description</h3>

<p>A plot of the regularised regression coefficients is shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfaridge.plot(y, x, a, lambda = seq(0, 5, by = 0.1) )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20the+2B20alpha-transformation+2B20plot_+3A_y">y</code></td>
<td>

<p>A numeric vector containing the values of the target variable. If the values are proportions or percentages, i.e. strictly within 0 and 1 they are mapped into R using
the logit transformation. In any case, they must be continuous only.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20the+2B20alpha-transformation+2B20plot_+3A_x">x</code></td>
<td>

<p>A numeric matrix containing the continuous variables.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20the+2B20alpha-transformation+2B20plot_+3A_a">a</code></td>
<td>

<p>The value of the <code class="reqn">\alpha</code>-transformation. It has to be between -1 and 1. If there are zero values in the data, you must use a strictly positive value.
</p>
</td></tr>
<tr><td><code id="Ridge+2B20regression+2B20with+2B20the+2B20alpha-transformation+2B20plot_+3A_lambda">lambda</code></td>
<td>

<p>A grid of values of the regularisation parameter <code class="reqn">\lambda</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For every value of <code class="reqn">\lambda</code> the coefficients are obtained. They are plotted versus the <code class="reqn">\lambda</code> values.
</p>


<h3>Value</h3>

<p>A plot with the values of the coefficients as a function of <code class="reqn">\lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Giorgos Athineou &lt;gioathineou@gmail.com&gt; and Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Hoerl A.E. and R.W. Kennard (1970). Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1): 55-67.
</p>
<p>Brown P. J. (1994). Measurement, Regression and Calibration. Oxford Science Publications.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ridge.plot">ridge.plot</a>, <a href="#topic+alfa.ridge">alfa.ridge</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.vector(fgl[, 1])
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
alfaridge.plot(y, x, a = 0.5, lambda = seq(0, 5, by = 0.1) )
</code></pre>

<hr>
<h2 id='Simulation+20of+20compositional+20data+20from+20Gaussian+20mixture+20models'>
Simulation of compositional data from Gaussian mixture models
</h2><span id='topic+rmixcomp'></span>

<h3>Description</h3>

<p>Simulation of compositional data from Gaussian mixture models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmixcomp(n, prob, mu, sigma, type = "alr")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_n">n</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_prob">prob</code></td>
<td>

<p>A vector with mixing  probabilities. Its length is equal to the number of clusters.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_mu">mu</code></td>
<td>

<p>A matrix where each row corresponds to the mean vector of each cluster.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_sigma">sigma</code></td>
<td>

<p>An array consisting of the covariance matrix of each cluster.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20Gaussian+2B20mixture+2B20models_+3A_type">type</code></td>
<td>

<p>Should the additive (&quot;type=alr&quot;) or the isometric (type=&quot;ilr&quot;) log-ration be used? 
The default value is for the additive log-ratio transformation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A sample from a multivariate Gaussian mixture model is generated.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>id</code></td>
<td>

<p>A numeric variable indicating the cluster of simulated vector.
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>

<p>A matrix containing the simulated compositional data. The number of dimensions will be + 1.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ryan P. Browne, Aisha ElSherbiny and Paul D. McNicholas (2015). R package mixture: Mixture 
Models for Clustering and Classification.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mix.compnorm">mix.compnorm</a>, <a href="#topic+bic.mixcompnorm">bic.mixcompnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- c(1/3, 1/3, 1/3)
mu &lt;- matrix(nrow = 3, ncol = 4)
s &lt;- array( dim = c(4, 4, 3) )
x &lt;- as.matrix(iris[, 1:4])
ina &lt;- as.numeric(iris[, 5])
mu &lt;- rowsum(x, ina) / 50
s[, , 1] &lt;- cov(x[ina == 1, ])
s[, , 2] &lt;- cov(x[ina == 2, ])
s[, , 3] &lt;- cov(x[ina == 3, ])
y &lt;- rmixcomp(100, p, mu, s, type = "alr")
</code></pre>

<hr>
<h2 id='Simulation+20of+20compositional+20data+20from+20mixtures+20of+20Dirichlet+20distributions'>
Simulation of compositional data from mixtures of Dirichlet distributions
</h2><span id='topic+rmixdiri'></span>

<h3>Description</h3>

<p>Simulation of compositional data from mixtures of Dirichlet distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmixdiri(n, a, prob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions_+3A_n">n</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions_+3A_a">a</code></td>
<td>

<p>A matrix where each row contains the parameters of each Dirichlet component.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20mixtures+2B20of+2B20Dirichlet+2B20distributions_+3A_prob">prob</code></td>
<td>

<p>A vector with the mixing probabilities.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A sample from a Dirichlet mixture model is generated.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>id</code></td>
<td>

<p>A numeric variable indicating the cluster of simulated vector.
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>

<p>A matrix containing the simulated compositional data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ye X., Yu Y. K. and Altschul S. F. (2011). On the inference of
Dirichlet mixture priors for protein sequence comparison.
Journal of Computational Biology, 18(8), 941-954.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rmixcomp">rmixcomp</a>, <a href="#topic+mixdiri.contour">mixdiri.contour</a>,
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- matrix( c(12, 30, 45, 32, 50, 16), byrow = TRUE,ncol = 3)
prob &lt;- c(0.5, 0.5)
x &lt;- rmixdiri(100, a, prob)
</code></pre>

<hr>
<h2 id='Simulation+20of+20compositional+20data+20from+20the+20Flexible+20Dirichlet+20distribution'>
Simulation of compositional data from the Flexible Dirichlet distribution
</h2><span id='topic+rfd'></span>

<h3>Description</h3>

<p>Simulation of compositional data from the Flexible Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfd(n, alpha, prob, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_n">n</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_alpha">alpha</code></td>
<td>
<p>A vector of the non-negative <code class="reqn">\alpha</code> parameters.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_prob">prob</code></td>
<td>

<p>A vector of the clusters' probabilities that must sum to one.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20Flexible+2B20Dirichlet+2B20distribution_+3A_tau">tau</code></td>
<td>
<p>The positive scalar <code class="reqn">tau</code> parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information see the references.
</p>


<h3>Value</h3>

<p>A matrix with compositional data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris ported from the R package FlexDir. <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Ongaro A. and Migliorati S. (2013). A generalization of the Dirichlet distribution.
Journal of Multivariate Analysis, 114, 412&ndash;426.
</p>
<p>Migliorati S., Ongaro A. and Monti G. S. (2017). A structured Dirichlet mixture model for compositional data: inferential and applicative issues. Statistics and Computing, 27, 963&ndash;983.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+fd.est">fd.est</a>, <a href="#topic+dfd">dfd</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alpha &lt;- c(12, 11, 10)
prob &lt;- c(0.25, 0.25, 0.5)
x &lt;- rfd(100, alpha, prob, 7)
</code></pre>

<hr>
<h2 id='Simulation+20of+20compositional+20data+20from+20the+20folded+20normal+20distribution'>
Simulation of compositional data from the folded model normal distribution
</h2><span id='topic+rfolded'></span>

<h3>Description</h3>

<p>Simulation of compositional data from the folded model normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rfolded(n, mu, su, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20folded+2B20normal+2B20distribution_+3A_n">n</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20folded+2B20normal+2B20distribution_+3A_mu">mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20folded+2B20normal+2B20distribution_+3A_su">su</code></td>
<td>

<p>The covariance matrix.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20compositional+2B20data+2B20from+2B20the+2B20folded+2B20normal+2B20distribution_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A sample from the folded model is generated.
</p>


<h3>Value</h3>

<p>A matrix with compositional data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2020). A folded model for compositional data analysis.
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alpha.mle">alpha.mle</a>, <a href="#topic+a.est">a.est</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;-  c(0.1490676523, -0.4580818209,  0.0020395316, -0.0047446076, -0.4580818209,
1.5227259250,  0.0002596411,  0.0074836251,  0.0020395316,  0.0002596411,
0.0365384838, -0.0471448849, -0.0047446076,  0.0074836251, -0.0471448849,
0.0611442781)
s &lt;- matrix(s, ncol = 4)
m &lt;- c(1.715, 0.914, 0.115, 0.167)
x &lt;- rfolded(100, m, s, 0.5)
a.est(x)
</code></pre>

<hr>
<h2 id='Spatial+20median+20regression'>
Spatial median regression
</h2><span id='topic+spatmed.reg'></span>

<h3>Description</h3>

<p>Spatial median regression with Euclidean data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatmed.reg(y, x, xnew = NULL, tol = 1e-07, ses = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data. Zero values are not allowed.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_tol">tol</code></td>
<td>

<p>The threshold upon which to stop the iterations of the Newton-Rapshon algorithm.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_ses">ses</code></td>
<td>

<p>If you want to extract the standard errors of the parameters, set this to TRUE. Be careful though as this can slow
down the algorithm dramatically. In a run example with 10,000 observations and 10 variables for y and 30 for x, when
ses = FALSE the algorithm can take 0.20 seconds, but when ses = TRUE it can go up to 140 seconds.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objective function is the minimization of the sum of the absolute residuals. It is the multivariate generalization of the median regression.
This function is used by <code><a href="#topic+comp.reg">comp.reg</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iter</code></td>
<td>

<p>The number of iterations that were required.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the beta coefficients is returned if ses=TRUE and NULL otherwise.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Biman Chakraborty (2003). On multivariate quantile regression.
Journal of Statistical Planning and Inference, 110(1-2), 109-132.
http://www.stat.nus.edu.sg/export/sites/dsap/research/documents/tr01_2000.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multivreg">multivreg</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+alfa.reg">alfa.reg</a>, <a href="#topic+js.compreg">js.compreg</a>, <a href="#topic+diri.reg">diri.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(iris[, 3:4])
y &lt;- as.matrix(iris[, 1:2])
mod1 &lt;- spatmed.reg(y, x)
mod2 &lt;- multivreg(y, x, plot = FALSE)
</code></pre>

<hr>
<h2 id='Ternary+20diagram'>
Ternary diagram
</h2><span id='topic+ternary'></span>

<h3>Description</h3>

<p>Ternary diagram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternary(x, dg = FALSE, hg = FALSE, means = TRUE, pca = FALSE, colour = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ternary+2B20diagram_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram_+3A_dg">dg</code></td>
<td>

<p>Do you want diagonal grid lines to appear? If yes, set this TRUE. 
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram_+3A_hg">hg</code></td>
<td>

<p>Do you want horizontal grid lines to appear? If yes, set this TRUE. 
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram_+3A_means">means</code></td>
<td>

<p>A boolean variable. Should the closed geometric mean and the arithmetic mean appear 
(TRUE) or not (FALSE)?.
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram_+3A_pca">pca</code></td>
<td>

<p>Should the first PCA calculated Aitchison (1983) described appear? If yes, then this 
should be TRUE, or FALSE otherwise.
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram_+3A_colour">colour</code></td>
<td>

<p>If you want the points to appear in different colour put a vector with the colour 
numbers or colours.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two ways to create a ternary graph. We used here that one where each edge is equal to 1 
and it is what Aitchison (1986) uses. For every given point, the sum of the distances from the edges 
is equal to 1. Horizontal and or diagonal grid lines can appear, so as the closed geometric and the 
simple arithmetic mean. The first PCA is calculated using the centred log-ratio transformation 
as Aitchison (1983, 1986) suggested. If the data contain zero values, the first PCA will not be 
plotted. Zeros in the data appear with green circles in the triangle and you will also see NaN in 
the closed geometric mean.
</p>


<h3>Value</h3>

<p>The ternary plot and a 2-row matrix with the means. The closed geometric and the simple arithmetic 
mean vector and or the first principal component will appear as well if the user has asked for them. 
Additionally, horizontal or diagonal grid lines can appear as well.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> 
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Aitchison, J. (1983). Principal component analysis of compositional data. Biometrika 70(1):57-65.
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.den">comp.den</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+comp.kerncontour">comp.kerncontour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
x &lt;- x / rowSums(x)
ternary(x, means = TRUE, pca = TRUE)
</code></pre>

<hr>
<h2 id='Ternary+20diagram+20of+20regression+20models'>
Ternary diagram of regression models
</h2><span id='topic+ternary.reg'></span>

<h3>Description</h3>

<p>Ternary diagram of regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternary.reg(y, est, id, labs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ternary+2B20diagram+2B20of+2B20regression+2B20models_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram+2B20of+2B20regression+2B20models_+3A_est">est</code></td>
<td>

<p>A matrix with all fitted compositional data for all regression models, one under the other.
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram+2B20of+2B20regression+2B20models_+3A_id">id</code></td>
<td>

<p>A vector indicating the regression model of each fitted compositional data set.
</p>
</td></tr>
<tr><td><code id="Ternary+2B20diagram+2B20of+2B20regression+2B20models_+3A_labs">labs</code></td>
<td>

<p>The names of the regression models to appea in the legend.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The points first appear on the ternary plot. Then, the fitted compositional data appear with different lines for each regression model.
</p>


<h3>Value</h3>

<p>The ternary plot and lines for the fitted values of each regression model.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ternary">ternary</a>, <a href="#topic+diri.contour">diri.contour</a>, <a href="#topic+comp.kerncontour">comp.kerncontour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(1, rnorm(50) )
a &lt;- exp( x %*% matrix( rnorm(6,0, 0.4), ncol = 3) )
y &lt;- matrix(NA, 50, 3)
for (i in 1:50) y[i, ] &lt;- rdiri(1, a[i, ])
est &lt;- comp.reg(y, x[, -1], xnew = x[, -1])$est
ternary.reg(y, est, id = rep(1, 50), labs = "ALR regression")
</code></pre>

<hr>
<h2 id='The+20additive+20log-ratio+20transformation+20and+20its+20inverse'>
The additive log-ratio transformation and its inverse
</h2><span id='topic+alr'></span><span id='topic+alrinv'></span>

<h3>Description</h3>

<p>The additive log-ratio transformation and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alr(x)
alrinv(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20additive+2B20log-ratio+2B20transformation+2B20and+2B20its+2B20inverse_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20additive+2B20log-ratio+2B20transformation+2B20and+2B20its+2B20inverse_+3A_y">y</code></td>
<td>

<p>A numerical matrix with data to be closed into the simplex.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The additive log-ratio transformation with the first component being the common divisor is applied.
The inverse of this transformation is also available. This means that no zeros are allowed.
</p>


<h3>Value</h3>

<p>A matrix with the alr transformed data (if alr is used) or with the compositional data (if the alrinv is used).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bc">bc</a>, <a href="#topic+pivot">pivot</a>, <a href="#topic+fp">fp</a>, <a href="#topic+green">green</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y &lt;- alr(x)
x1 &lt;- alrinv(y)
</code></pre>

<hr>
<h2 id='The+20alpha-distance'>
The <code class="reqn">\alpha</code>-distance
</h2><span id='topic+alfadist'></span><span id='topic+alfadista'></span>

<h3>Description</h3>

<p>This is the Euclidean (or Manhattan) distance after the <code class="reqn">\alpha</code>-transformation has been applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfadist(x, a, type = "euclidean", square = FALSE)
alfadista(xnew, x, a, type = "euclidean", square = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-distance_+3A_xnew">xnew</code></td>
<td>

<p>A matrix or a vector with new compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-distance_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-distance_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code>, the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-distance_+3A_type">type</code></td>
<td>

<p>Which type distance do you want to calculate after the <code class="reqn">\alpha</code>-transformation, &quot;euclidean&quot;, or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-distance_+3A_square">square</code></td>
<td>

<p>In the case of the Euclidean distance, you can choose to return the squared distance by setting this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first and then the Euclidean or the Manhattan
distance is calculated.
</p>


<h3>Value</h3>

<p>For &quot;alfadist&quot; a matrix including the pairwise distances of all observations or the distances between xnew and x. For &quot;alfadista&quot; a matrix including the pairwise distances of all observations or the distances between xnew and x.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2016). Improved classification for compositional data using the
<code class="reqn">\alpha</code>-transformation. Journal of Classification. 33(2): 243&ndash;261.
https://arxiv.org/pdf/1506.04976v2.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>, <a href="#topic+alfa.reg">alfa.reg</a>, <a href="#topic+esov">esov</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[1:20, 2:9])
x &lt;- x / rowSums(x)
alfadist(x, 0.1)
alfadist(x, 1)
</code></pre>

<hr>
<h2 id='The+20alpha-IT+20transformation'>
The <code class="reqn">\alpha</code>-IT transformation
</h2><span id='topic+ait'></span>

<h3>Description</h3>

<p>The <code class="reqn">\alpha</code>-IT transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ait(x, a, h = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-IT+2B20transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-IT+2B20transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero
values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the
isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-IT+2B20transformation_+3A_h">h</code></td>
<td>

<p>A boolean variable. If is TRUE (default value) the multiplication with the
Helmert sub-matrix will take place. When <code class="reqn">\alpha=0</code> and h = FALSE,
the result is the centred log-ratio transformation (Aitchison, 1986).
In general, when h = FALSE the resulting transformation maps the data onto
a singualr space. The sum of the vectors is equal to 0. Hence, from the simplex
constraint the data go to another constraint.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-IT transformation is applied to the compositional data.
</p>


<h3>Value</h3>

<p>A matrix with the <code class="reqn">\alpha</code>-IT transformed data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Clarotto L., Allard D. and Menafoglio A. (2022). A new class of
<code class="reqn">\alpha</code>-transformations for the spatial analysis of Compositional 
Data. Spatial Statistics, 47.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aitdist">aitdist</a>, <a href="#topic+ait.knn">ait.knn</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+green">green</a>, <a href="#topic+alr">alr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y1 &lt;- ait(x, 0.2)
y2 &lt;- ait(x, 1)
rbind( colMeans(y1), colMeans(y2) )
</code></pre>

<hr>
<h2 id='The+20alpha-IT-distance'>
The <code class="reqn">\alpha</code>-IT-distance
</h2><span id='topic+aitdist'></span><span id='topic+aitdista'></span>

<h3>Description</h3>

<p>This is the Euclidean (or Manhattan) distance after the
<code class="reqn">\alpha</code>-IT-transformation has been applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aitdist(x, a, type = "euclidean", square = FALSE)
aitdista(xnew, x, a, type = "euclidean", square = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-IT-distance_+3A_xnew">xnew</code></td>
<td>

<p>A matrix or a vector with new compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-IT-distance_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-IT-distance_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1.
If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code>,
the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-IT-distance_+3A_type">type</code></td>
<td>

<p>Which type distance do you want to calculate after the
<code class="reqn">\alpha</code>-transformation, &quot;euclidean&quot;, or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-IT-distance_+3A_square">square</code></td>
<td>

<p>In the case of the Euclidean distance, you can choose to return the squared
distance by setting this TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-IT-transformation is applied to the compositional data first
and then the Euclidean or the Manhattan distance is calculated.
</p>


<h3>Value</h3>

<p>For &quot;alfadist&quot; a matrix including the pairwise distances of all observations
or the distances between xnew and x.
For &quot;alfadista&quot; a matrix including the pairwise distances of all observations
or the distances between xnew and x.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Clarotto L., Allard D. and Menafoglio A. (2021). A new class of
<code class="reqn">\alpha</code>-transformations for the spatial analysis of Compositional Data.
https://arxiv.org/abs/2110.07967
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ait">ait</a>, <a href="#topic+alfadist">alfadist</a>, <a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[1:20, 2:9])
x &lt;- x / rowSums(x)
aitdist(x, 0.1)
aitdist(x, 1)
</code></pre>

<hr>
<h2 id='The+20alpha-k-NN+20regression+20for+20compositional+20response+20data'>
The <code class="reqn">\alpha</code>-k-NN regression for compositional response data
</h2><span id='topic+aknn.reg'></span>

<h3>Description</h3>

<p>The <code class="reqn">\alpha</code>-k-NN regression for compositional response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aknn.reg(xnew, y, x, a = seq(0.1, 1, by = 0.1), k = 2:10,
apostasi = "euclidean", rann = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new predictor variables whose compositions are to be predicted.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional response data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available predictor variables.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_a">a</code></td>
<td>

<p>The value(s) of <code class="reqn">\alpha</code>. Either a single value or a vector of values.
As zero values in the compositional data are allowed, you must be careful
to choose strictly positive vcalues of <code class="reqn">\alpha</code>. However, if negative
values are passed, the positive ones are used only.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to consider. It can be a single number or a vector.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use, either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20for+2B20compositional+2B20response+2B20data_+3A_rann">rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use kd-trees implemented in the 
R package &quot;Rnanoflann&quot;. In this case you must set this argument equal to TRUE. Note however, that in this case, the only available distance is by default &quot;euclidean&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-k-NN regression for compositional response variables is applied.
</p>


<h3>Value</h3>

<p>A list with the estimated compositional response data for each value of <code class="reqn">\alpha</code> and k.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aknnreg.tune">aknnreg.tune</a>, <a href="#topic+akern.reg">akern.reg</a>, <a href="#topic+alfa.reg">alfa.reg</a>, <a href="#topic+comp.ppr">comp.ppr</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+kl.compreg">kl.compreg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 1:3] )
y &lt;- y / rowSums(y)
x &lt;- iris[, 4]
mod &lt;- aknn.reg(x, y, x, a = c(0.4, 0.5), k = 2:3, apostasi = "euclidean")
</code></pre>

<hr>
<h2 id='The+20alpha-k-NN+20regression+20with+20compositional+20predictor+20variables'>
The <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables
</h2><span id='topic+alfa.knn.reg'></span>

<h3>Description</h3>

<p>The <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa.knn.reg(xnew, y, x, a = 1, k = 2:10, apostasi = "euclidean", method = "average")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new compositional predictor variables whose response is to be predicted. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>The response variable, a numerical vector.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional predictor variables. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_a">a</code></td>
<td>

<p>A single value of <code class="reqn">\alpha</code>. As zero values in the compositional data are allowed, you must be careful to choose strictly positive vcalues of <code class="reqn">\alpha</code>. If negative values are passed, the positive ones are used only. If the data are already alpha-transformed, you can make this NULL.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to consider. It can be a single number or a vector.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use, either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-k-NN+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_method">method</code></td>
<td>

<p>If you want to take the average of the reponses of the k closest observations, type &quot;average&quot;.
For the median, type &quot;median&quot; and for the harmonic mean, type &quot;harmonic&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-k-NN regression with compositional predictor variables is applied.
</p>


<h3>Value</h3>

<p>A matrix with the estimated response data for each value of k.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aknn.reg">aknn.reg</a>, <a href="#topic+alfa.knn">alfa.knn</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.ridge">alfa.ridge</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y &lt;- fgl[, 1]
mod &lt;- alfa.knn.reg(x, y, x, a = 0.5, k = 2:4)
</code></pre>

<hr>
<h2 id='The+20alpha-kernel+20regression+20with+20compositional+20response+20data'>
The <code class="reqn">\alpha</code>-kernel regression with compositional response data
</h2><span id='topic+akern.reg'></span>

<h3>Description</h3>

<p>The <code class="reqn">\alpha</code>-kernel regression with compositional response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>akern.reg( xnew, y, x, a = seq(0.1, 1, by = 0.1),
h = seq(0.1, 1, length = 10), type = "gauss" )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new predictor variables whose compositions are to
be predicted.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional response data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available predictor variables.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_a">a</code></td>
<td>

<p>The value(s) of <code class="reqn">\alpha</code>. Either a single value or a vector of values.
As zero values in the compositional data are allowed, you must be careful
to choose strictly positive vcalues of <code class="reqn">\alpha</code>. However, if negative
values are passed, the positive ones are used only.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_h">h</code></td>
<td>

<p>The bandwidth value(s) to consider.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-kernel+2B20regression+2B20with+2B20compositional+2B20response+2B20data_+3A_type">type</code></td>
<td>

<p>The type of kernel to use, &quot;gauss&quot; or &quot;laplace&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-kernel regression for compositional response variables is
applied.
</p>


<h3>Value</h3>

<p>A list with the estimated compositional response data for each value of
<code class="reqn">\alpha</code> and h.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>


<h3>See Also</h3>

<p><code><a href="#topic+akernreg.tune">akernreg.tune</a>, <a href="#topic+aknn.reg">aknn.reg</a>, <a href="#topic+aknnreg.tune">aknnreg.tune</a>,
<a href="#topic+alfa.reg">alfa.reg</a>, <a href="#topic+comp.ppr">comp.ppr</a>, <a href="#topic+comp.reg">comp.reg</a>, <a href="#topic+kl.compreg">kl.compreg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix( iris[, 1:3] )
y &lt;- y / rowSums(y)
x &lt;- iris[, 4]
mod &lt;- akern.reg( x, y, x, a = c(0.4, 0.5), h = c(0.1, 0.2) )
</code></pre>

<hr>
<h2 id='The+20alpha-transformation'>
The <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfa'></span><span id='topic+alef'></span>

<h3>Description</h3>

<p>The <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfa(x, a, h = TRUE)
alef(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to
be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="The+2B20alpha-transformation_+3A_h">h</code></td>
<td>

<p>A boolean variable. If is TRUE (default value) the multiplication with the Helmert sub-matrix will take place.
When <code class="reqn">\alpha=0</code> and h = FALSE, the result is the centred log-ratio transformation (Aitchison, 1986).
In general, when h = FALSE the resulting transformation maps the data onto a singualr space. The sum of the vectors is equal to 0.
Hence, from the simplex constraint the data go to another constraint.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data. The command &quot;alef&quot; is the same as
&quot;alfa(x, a, h = FALSE)&quot;, but reurns a different element as well and is necessary for the functions <code><a href="#topic+a.est">a.est</a></code>, <code><a href="#topic+a.mle">a.mle</a></code> and <code><a href="#topic+alpha.mle">alpha.mle</a></code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>sa</code></td>
<td>

<p>The logarithm of the Jacobian determinant of the <code class="reqn">\alpha</code>-transformation. This is used in the &quot;profile&quot;
function to speed up the computations.
</p>
</td></tr>
<tr><td><code>sk</code></td>
<td>

<p>If the &quot;alef&quot; was called, this will return the sum of the <code class="reqn">\alpha</code>-power transformed data, prior to
being normalised to sum to 1. If <code class="reqn">\alpha=0</code>, this will not be returned.
</p>
</td></tr>
<tr><td><code>aff</code></td>
<td>

<p>The <code class="reqn">\alpha</code>-transformed data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2022). A Review of Flexible Transformations for Modeling Compositional Data. In Advances and Innovations in Statistics and Data Science, pp. 225&ndash;234.
https://link.springer.com/chapter/10.1007/978-3-031-08329-7_10
</p>
<p>Tsagris Michail and Stewart Connie (2020). A folded model for compositional data analysis.
Australian and New Zealand Journal of Statistics, 62(2): 249-277.
https://arxiv.org/pdf/1802.07330.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data. In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfainv">alfainv</a>, <a href="#topic+pivot">pivot</a>, <a href="#topic+alfa.profile">alfa.profile</a>, <a href="#topic+alfa.tune">alfa.tune</a>
<a href="#topic+a.est">a.est</a>, <a href="#topic+alpha.mle">alpha.mle</a>, <a href="#topic+alr">alr</a>, <a href="#topic+bc">bc</a>, <a href="#topic+fp">fp</a>, <a href="#topic+green">green</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y1 &lt;- alfa(x, 0.2)$aff
y2 &lt;- alfa(x, 1)$aff
rbind( colMeans(y1), colMeans(y2) )
y3 &lt;- alfa(x, 0.2)$aff
dim(y1)  ;  dim(y3)
rowSums(y1)
rowSums(y3)
</code></pre>

<hr>
<h2 id='The+20Box-Cox+20transformation+20applied+20to+20ratios+20of+20components'>
The Box-Cox transformation applied to ratios of components
</h2><span id='topic+bc'></span>

<h3>Description</h3>

<p>The Box-Cox transformation applied to ratios of components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bc(x, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20Box-Cox+2B20transformation+2B20applied+2B20to+2B20ratios+2B20of+2B20components_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. The first component must be zero values free.
</p>
</td></tr>
<tr><td><code id="The+2B20Box-Cox+2B20transformation+2B20applied+2B20to+2B20ratios+2B20of+2B20components_+3A_lambda">lambda</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to
be greater than 0. If <code class="reqn">\lambda=0</code> the additive log-ratio transformation (<code><a href="#topic+alr">alr</a></code>) is applied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Box-Cox transformation applied to ratios of components, as described in Aitchison (1986) is applied.
</p>


<h3>Value</h3>

<p>A matrix with the transformed data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alr">alr</a>, <a href="#topic+fp">fp</a>, <a href="#topic+green">green</a>, <a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y1 &lt;- bc(x, 0.2)
y2 &lt;- bc(x, 0)
rbind( colMeans(y1), colMeans(y2) )
rowSums(y1)
rowSums(y2)
</code></pre>

<hr>
<h2 id='The+20ESOV-distance'>
The ESOV-distance
</h2><span id='topic+esov'></span><span id='topic+esova'></span><span id='topic+es'></span>

<h3>Description</h3>

<p>The ESOV-distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>esov(x)
esova(xnew, x)
es(x1, x2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20ESOV-distance_+3A_x">x</code></td>
<td>

<p>A matrix with compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20ESOV-distance_+3A_xnew">xnew</code></td>
<td>

<p>A matrix or a vector with new compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20ESOV-distance_+3A_x1">x1</code></td>
<td>

<p>A vector with compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20ESOV-distance_+3A_x2">x2</code></td>
<td>

<p>A vector with compositional data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ESOV distance is calculated.
</p>


<h3>Value</h3>

<p>For &quot;esov()&quot; a matrix including the pairwise distances of all observations or the distances between xnew and x.
</p>
<p>For &quot;esova()&quot; a matrix including the pairwise distances of all observations or the distances between xnew and x.
</p>
<p>For &quot;es()&quot; a number, the ESOV distance between x1 and x2.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris, Michail (2014). The k-NN algorithm for compositional data: a revised approach with and without zero values present. Journal of Data Science, 12(3): 519-534.
</p>
<p>Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability distributions. Information Theory, IEEE Transactions on 49, 1858-1860.
</p>
<p>Osterreicher, F. and Vajda, I. (2003). A new class of metric divergences on probability spaces and its applicability in statistics. Annals of the Institute of Statistical Mathematics 55, 639-653.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfadist">alfadist</a>, <a href="#topic+comp.knn">comp.knn</a>, <a href="#topic+js.compreg">js.compreg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[1:20, 2:9])
x &lt;- x / rowSums(x)
esov(x)
</code></pre>

<hr>
<h2 id='The+20folded+20power+20transformation'>
The folded power transformation
</h2><span id='topic+fp'></span>

<h3>Description</h3>

<p>The folded power transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fp(x, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20folded+2B20power+2B20transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="The+2B20folded+2B20power+2B20transformation_+3A_lambda">lambda</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to
be greater than 0. If <code class="reqn">\lambda=0</code> the additive log-ratio transformation (<code><a href="#topic+alr">alr</a></code>) is applied.
If zero values are present <code class="reqn">\lambda</code> must be strictly positive.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The folded power transformation is applied to the compositional data.
</p>


<h3>Value</h3>

<p>A matrix with the transformed data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Atkinson, A. C. (1985). Plots, transformations and regression; an introduction to graphical methods
of diagnostic regression analysis Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alr">alr</a>, <a href="#topic+bc">bc</a>, <a href="#topic+green">green</a>, <a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y1 &lt;- fp(x, 0.2)
y2 &lt;- fp(x, 0)
rbind( colMeans(y1), colMeans(y2) )
rowSums(y1)
rowSums(y2)
</code></pre>

<hr>
<h2 id='The+20Frechet+20mean+20for+20compositional+20data'>
The Frechet mean for compositional data
</h2><span id='topic+frechet'></span>

<h3>Description</h3>

<p>Mean vector or matrix with mean vectors of compositional data using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frechet(x, a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20Frechet+2B20mean+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20Frechet+2B20mean+2B20for+2B20compositional+2B20data_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied and the closed geometric mean is calculated. You can also provide a sequence of values of alpha and in this case a matrix of Frechet means will be returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power transformation is applied to the compositional data and the mean vector is calculated. Then the inverse of it is calculated and the inverse of the power transformation applied to the last vector is the Frechet mean.
</p>


<h3>Value</h3>

<p>If <code class="reqn">\alpha</code> is a single value, the function will return a vector with the Frechet mean for the given value of <code class="reqn">\alpha</code>. Otherwise the function will return a matrix with the Frechet means for each value of <code class="reqn">\alpha</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data. In Proceedings of the 4th Compositional Data Analysis Workshop, Girona,
Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>, <a href="stats.html#topic+profile">profile</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
frechet(x, 0.2)
frechet(x, 1)
</code></pre>

<hr>
<h2 id='The+20Helmert+20sub-matrix'>
The Helmert sub-matrix
</h2><span id='topic+helm'></span>

<h3>Description</h3>

<p>The Helmert sub-matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>helm(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20Helmert+2B20sub-matrix_+3A_n">n</code></td>
<td>

<p>A number grater than or equal to 2.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Helmert sub-matrix is returned. It is an orthogonal matrix without the first row.
</p>


<h3>Value</h3>

<p>A <code class="reqn">(n-1) \times n</code> matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> 
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>John Aitchison (2003). The Statistical Analysis of Compositional Data, p. 99. Blackburn Press.
</p>
<p>Lancaster H. O. (1965). The Helmert matrices. The American Mathematical Monthly 72(1): 4-12.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>helm(3)
helm(5)
</code></pre>

<hr>
<h2 id='The+20k-nearest+20neighbours+20using+20the+20alpha-distance'>
The k-nearest neighbours using the <code class="reqn">\alpha</code>-distance
</h2><span id='topic+alfann'></span>

<h3>Description</h3>

<p>The k-nearest neighbours using the <code class="reqn">\alpha</code>-distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfann(xnew, x, a, k = 10, rann = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20k-nearest+2B20neighbours+2B20using+2B20the+2B20alpha-distance_+3A_xnew">xnew</code></td>
<td>

<p>A matrix or a vector with new compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20k-nearest+2B20neighbours+2B20using+2B20the+2B20alpha-distance_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20k-nearest+2B20neighbours+2B20using+2B20the+2B20alpha-distance_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1.
If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code>,
the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="The+2B20k-nearest+2B20neighbours+2B20using+2B20the+2B20alpha-distance_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to search for.
</p>
</td></tr>
<tr><td><code id="The+2B20k-nearest+2B20neighbours+2B20using+2B20the+2B20alpha-distance_+3A_rann">rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use
kd-trees implemented in the R package &quot;Rnanoflann&quot;. In this case you must set this
argument equal to TRUE. Note however, that in this case, the only available
distance is by default &quot;euclidean&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first
and the indices of the k-nearest neighbours using the Euclidean distance
are returned.
</p>


<h3>Value</h3>

<p>A matrix including the indices of the nearest neighbours of each xnew from x.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>MTsagris M., Alenazi A. and Stewart C. (2023).
Flexible non-parametric regression models for compositional response data with zeros.
Statistics and Computing, 33(106).
</p>
<p>https://link.springer.com/article/10.1007/s11222-023-10277-5
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power
transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
</p>
<p>https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa.knn">alfa.knn</a>, <a href="#topic+comp.nb">comp.nb</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+alfa.nb">alfa.nb</a>,
link{aknn.reg}, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
xnew &lt;- as.matrix(fgl[1:20, 2:9])
xnew &lt;- xnew / rowSums(xnew)
x &lt;- as.matrix(fgl[-c(1:20), 2:9])
x &lt;- x / rowSums(x)
b &lt;- alfann(xnew, x, a = 0.1, k = 10)
</code></pre>

<hr>
<h2 id='The+20k-NN+20algorithm+20for+20compositional+20data'>
The k-NN algorithm for compositional data
</h2><span id='topic+comp.knn'></span><span id='topic+alfa.knn'></span><span id='topic+ait.knn'></span>

<h3>Description</h3>

<p>The k-NN algorithm for compositional data with and without using the
power transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp.knn(xnew, x, ina, a = 1, k = 5,  apostasi = "ESOV", mesos = TRUE)

alfa.knn(xnew, x, ina, a = 1, k = 5, mesos = TRUE,
apostasi = "euclidean", rann = FALSE)

ait.knn(xnew, x, ina, a = 1, k = 5, mesos = TRUE,
apostasi = "euclidean", rann = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_xnew">xnew</code></td>
<td>

<p>A matrix with the new compositional data whose group is to be predicted. Zeros
are allowed, but you must be careful to choose strictly positive values
of <code class="reqn">\alpha</code> or not to set apostasi= &quot;Ait&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed, but you
must be careful to choose strictly positive values of <code class="reqn">\alpha</code> or not
to set apostasi= &quot;Ait&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_ina">ina</code></td>
<td>

<p>A group indicator variable for the available data.
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_a">a</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code>. As zero values in the compositional data are allowed,
you must be careful to choose strictly positive vcalues of <code class="reqn">\alpha</code>.
You have the option to put a = NULL. In this case, the xnew and x are
assumed to be the already <code class="reqn">\alpha</code>-transformed data.
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to consider. It can be a single number or a vector.
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use. For the compk.knn this can be one of the following:
&quot;ESOV&quot;, &quot;taxicab&quot;, &quot;Ait&quot;, &quot;Hellinger&quot;, &quot;angular&quot; or &quot;CS&quot;. See the references for
them. For the alfa.knn this can be either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_mesos">mesos</code></td>
<td>

<p>This is used in the non standard algorithm. If TRUE, the arithmetic mean of the
distances is calulated, otherwise the harmonic mean is used (see details).
</p>
</td></tr>
<tr><td><code id="The+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_rann">rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use
kd-trees implemented in the R package &quot;Rnanoflann&quot;. In this case you must set this
argument equal to TRUE. Note however, that in this case, the only available
distance is by default &quot;euclidean&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The k-NN algorithm is applied for the compositional data. There are many metrics
and possibilities to choose from. The algorithm finds the k nearest observations
to a new observation and allocates it to the class which appears most times in
the neighbours. It then computes the arithmetic or the harmonic mean of the
distances. The new point is allocated to the class with the minimum distance.
</p>


<h3>Value</h3>

<p>A vector with the estimated groups.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris, Michail (2014). The k-NN algorithm for compositional data: a revised
approach with and without zero values present. Journal of Data Science, 12(3): 519&ndash;534.
</p>
<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009). The elements of
statistical learning, 2nd edition. Springer, Berlin
</p>
<p>Tsagris Michail, Simon Preston and Andrew T.A. Wood (2016).
Improved classification for compositional data using the
<code class="reqn">\alpha</code>-transformation. Journal of Classification 33(2): 243&ndash;261.
</p>
<p>Connie Stewart (2017). An approach to measure distance between compositional
diet estimates containing essential zeros. Journal of Applied Statistics 44(7): 1137&ndash;1152.
</p>
<p>Clarotto L., Allard D. and Menafoglio A. (2022). A new class of
<code class="reqn">\alpha</code>-transformations for the spatial analysis of Compositional Data.
Spatial Statistics, 47.
</p>
<p>Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability
distributions. Information Theory, IEEE Transactions on 49, 1858&ndash;1860.
</p>
<p>Osterreicher, F. and Vajda, I. (2003). A new class of metric divergences on
probability spaces and its applicability in statistics.
Annals of the Institute of Statistical Mathematics 55, 639&ndash;653.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compknn.tune">compknn.tune</a>, <a href="#topic+alfa.rda">alfa.rda</a>, <a href="#topic+comp.nb">comp.nb</a>, <a href="#topic+alfa.nb">alfa.nb</a>, <a href="#topic+alfa">alfa</a>,
<a href="#topic+esov">esov</a>, <a href="#topic+mix.compnorm">mix.compnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[, 1:4] )
x &lt;- x/ rowSums(x)
ina &lt;- iris[, 5]
mod &lt;- comp.knn(x, x, ina, a = 1, k = 5)
table(ina, mod)
mod2 &lt;- alfa.knn(x, x, ina, a = 1, k = 5)
table(ina, mod2)

</code></pre>

<hr>
<h2 id='The+20multiplicative+20log-ratio+20transformation+20and+20its+20inverse'>
The multiplicative log-ratio transformation and its inverse
</h2><span id='topic+mlr'></span><span id='topic+mlrinv'></span>

<h3>Description</h3>

<p>The multiplicative log-ratio transformation and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlr(x)
mlrinv(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20multiplicative+2B20log-ratio+2B20transformation+2B20and+2B20its+2B20inverse_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20multiplicative+2B20log-ratio+2B20transformation+2B20and+2B20its+2B20inverse_+3A_y">y</code></td>
<td>

<p>A numerical matrix with data to be closed into the simplex.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multiplicative log-ratio transformation and its inverse are applied here.
This means that no zeros are allowed.
</p>


<h3>Value</h3>

<p>A matrix with the mlr transformed data (if mlr is used) or with the compositional data (if the mlrinv is used).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alr">alr</a>, <a href="#topic+pivot">pivot</a>, <a href="#topic+green">green</a>, <a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y &lt;- mlr(x)
x1 &lt;- mlrinv(y)
</code></pre>

<hr>
<h2 id='The+20pivot+20coordinate+20transformation+20and+20its+20inverse'>
The pivot coordinate transformation and its inverse
</h2><span id='topic+pivot'></span><span id='topic+pivotinv'></span>

<h3>Description</h3>

<p>The pivot coordinate transformation and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pivot(x)
pivotinv(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="The+2B20pivot+2B20coordinate+2B20transformation+2B20and+2B20its+2B20inverse_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="The+2B20pivot+2B20coordinate+2B20transformation+2B20and+2B20its+2B20inverse_+3A_y">y</code></td>
<td>

<p>A numerical matrix with data to be closed into the simplex.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The pivot coordinate transformation and its inverse are computed. This means that no zeros are allowed.
</p>


<h3>Value</h3>

<p>A matrix with the alr transformed data (if pivot is used) or with the compositional data (if the pivotinv is used).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Peter Filzmoser, Karel Hron and Matthias Templ (2018). Applied
Compositional Data Analysis With Worked Examples in R (pages 49 and 51). Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>, <a href="#topic+alr">alr</a>, <a href="#topic+green">green</a>  
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
y &lt;- pivot(x)
x1 &lt;- alrinv(y)
</code></pre>

<hr>
<h2 id='Total+20variability'>
Total variability
</h2><span id='topic+totvar'></span>

<h3>Description</h3>

<p>Total variability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>totvar(x, a = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Total+2B20variability_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Total+2B20variability_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the centred log-ratio transformation is used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied and the sum of the variances of the transformed variables is calculated. 
This is the total variability. Aitchison (1986) used the centred log-ratio transformation, but we have extended it to 
cover more geometries, via the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Value</h3>

<p>The total variability of the data in a given geometry as dictated by the value of <code class="reqn">\alpha</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, \ link{alfainv,} <a href="#topic+alfa.profile">alfa.profile</a>, <a href="#topic+alfa.tune">alfa.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / rowSums(x)
totvar(x)
</code></pre>

<hr>
<h2 id='Transformation-free+20linear+20regression+20for+20compositional+20responses+20and+20predictors'>
Transformation-free linear regression for compositional responses and predictors
</h2><span id='topic+tflr'></span>

<h3>Description</h3>

<p>Transformation-free linear regression for compositional responses and predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tflr(y, x, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional response. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional predictors. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Transformation-free+2B20linear+2B20regression+2B20for+2B20compositional+2B20responses+2B20and+2B20predictors_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The transformation-free linear regression for compositional responses and predictors is implemented. 
The function to be minized is <code class="reqn">-\sum_{i=1}^ny_i\log{y_i/(X_iB)}</code>.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted values of xnew if xnew is not NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Jacob Fiksel, Scott Zeger and Abhirup Datta (2020). A transformation-free linear regression for compositional outcomes and predictors.
https://arxiv.org/pdf/2004.07881.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.tflr">cv.tflr</a>, <a href="#topic+ols.compcomp">ols.compcomp</a> <a href="#topic+kl.alfapcr">kl.alfapcr</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- rdiri(214, runif(3, 1, 3))
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x / rowSums(x)
mod &lt;- tflr(y, x, x)
mod
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20alpha-generalised+20correlations+20between+20two+20compositional+20datasets'>
Tuning of the <code class="reqn">\alpha</code>-generalised correlations between two compositional datasets
</h2><span id='topic+acor.tune'></span>

<h3>Description</h3>

<p>Tuning of the <code class="reqn">alpha</code>-generalised correlations between two compositional datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acor.tune(y, x, a, type = "dcor")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_x">x</code></td>
<td>

<p>A matrix with the compositional data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_a">a</code></td>
<td>

<p>The range of values of the power transformation to search for the optimal one.
If zero values are present it has to be greater than 0.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20alpha-generalised+2B20correlations+2B20between+2B20two+2B20compositional+2B20datasets_+3A_type">type</code></td>
<td>

<p>the type of correlation to compute, the distance correlation (&quot;edist&quot;),
the canonical correlation type 1 (&quot;cancor1&quot;) or the canonical correlation
type 2 (&quot;cancor2&quot;). See details for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to each composition and then, if type=&quot;dcor&quot; the
distance correlation or the canonical correlation is computed. If type =
&quot;cancor1&quot; the function returns the value of <code class="reqn">\alpha</code> that maximizes the
product of the eigenvalues. If type = &quot;cancor2&quot; the function returns the value
of <code class="reqn">\alpha</code> that maximizes the the largest eigenvalue.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>alfa</code></td>
<td>
<p> The optimal value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>acor</code></td>
<td>

<p>The maximum value of the acor.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the optimization
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acor">acor</a>, <a href="#topic+alfa.profile">alfa.profile</a>, <a href="#topic+alfa">alfa</a>, <a href="#topic+alfainv">alfainv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rdiri(30, runif(3) )
x &lt;- rdiri(30, runif(4) )
acor(y, x, a = 0.4)
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20bandwidth+20h+20of+20the+20kernel+20using+20the+20maximum+20likelihood+20cross+20validation'>
Tuning of the bandwidth h of the kernel using the maximum likelihood cross validation
</h2><span id='topic+mkde.tune'></span>

<h3>Description</h3>

<p>Tuning of the bandwidth h of the kernel using the maximum likelihood cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mkde.tune( x, low = 0.1, up = 3, s = cov(x) )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20bandwidth+2B20h+2B20of+2B20the+2B20kernel+2B20using+2B20the+2B20maximum+2B20likelihood+2B20cross+2B20validation_+3A_x">x</code></td>
<td>

<p>A matrix with Euclidean (continuous) data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20bandwidth+2B20h+2B20of+2B20the+2B20kernel+2B20using+2B20the+2B20maximum+2B20likelihood+2B20cross+2B20validation_+3A_low">low</code></td>
<td>

<p>The minimum value to search for the optimal bandwidth value.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20bandwidth+2B20h+2B20of+2B20the+2B20kernel+2B20using+2B20the+2B20maximum+2B20likelihood+2B20cross+2B20validation_+3A_up">up</code></td>
<td>

<p>The maximum value to search for the optimal bandwidth value.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20bandwidth+2B20h+2B20of+2B20the+2B20kernel+2B20using+2B20the+2B20maximum+2B20likelihood+2B20cross+2B20validation_+3A_s">s</code></td>
<td>

<p>A covariance matrix. By default it is equal to the covariance matrix of the data, but can change to a robust covariance matrix, MCD for example.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood cross validation is applied in order to choose the optimal value of the bandwidth parameter. No plot is produced.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>hopt</code></td>
<td>

<p>The optimal bandwidth value.
</p>
</td></tr>
<tr><td><code>maximum</code></td>
<td>

<p>The value of the pseudo-log-likelihood at that given bandwidth value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a> and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Arsalane Chouaib Guidoum (2015). Kernel Estimator and Bandwidth Selection for Density and its Derivatives. The kedd R package.
http://cran.r-project.org/web/packages/kedd/vignettes/kedd.pdf
</p>
<p>M.P. Wand and M.C. Jones (1995). Kernel smoothing, pages 91-92.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mkde">mkde</a>, <a href="#topic+comp.kerncontour">comp.kerncontour</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
mkde.tune(as.matrix(iris[, 1:4]), c(0.1, 3) )
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20divergence+20based+20regression+20for+20compositional+20data+20with+20compositional+20data+20in+20the+20covariates+20side+20using+20the+20alpha-transformation'>
Tuning of the divergence based regression for compositional data with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+klalfapcr.tune'></span>

<h3>Description</h3>

<p>Tuning of the divergence based regression for compositional data with compositional data in the covariates side using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>klalfapcr.tune(y, x, covar = NULL, nfolds = 10, maxk = 50, a = seq(-1, 1, by = 0.1),
folds = NULL, graph = FALSE, tol = 1e-07, maxiters = 50, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numerical matrix with compositional data with or without zeros.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_covar">covar</code></td>
<td>

<p>If you have other continuous covariates put themn here.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds for the K-fold cross validation, set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_maxk">maxk</code></td>
<td>

<p>The maximum number of principal components to check.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0.
If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a plot will appear.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson procedure.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of Newton-Raphson iterations.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20divergence+2B20based+2B20regression+2B20for+2B20compositional+2B20data+2B20with+2B20compositional+2B20data+2B20in+2B20the+2B20covariates+2B20side+2B20using+2B20the+2B20alpha-transformation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The M-fold cross validation is performed in order to select the optimal values for <code class="reqn">\alpha</code> and k, the number of principal components.
The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first, the first k principal component scores are calcualted and used as predictor variables for the Kullback-Leibler divergence based regression model. This procedure is performed M times during the M-fold cross validation.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>mspe</code></td>
<td>

<p>A list with the KL divergence for each value of <code class="reqn">\alpha</code> and k in every fold.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>A matrix with the KL divergence for each value of <code class="reqn">\alpha</code> averaged over all folds. If graph is set to TRUE this matrix is plotted.
</p>
</td></tr>
<tr><td><code>best.perf</code></td>
<td>

<p>The minimum KL divergence.
</p>
</td></tr>
<tr><td><code>params</code></td>
<td>

<p>The values of <code class="reqn">\alpha</code> and k corresponding to the minimum KL divergence.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Initial code by Abdulaziz Alenazi. Modifications by Michail Tsagris.
</p>
<p>R implementation and documentation: Abdulaziz Alenazi <a href="mailto:a.alenazi@nbu.edu.sa">a.alenazi@nbu.edu.sa</a>
and Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Alenazi A. (2019). Regression for compositional data with compositional data as predictor variables with or without zero values.
Journal of Data Science, 17(1): 219&ndash;238.
https://jds-online.org/journal/JDS/article/136/file/pdf
</p>
<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. Chilean Journal of Statistics, 6(2): 47&ndash;57.
http://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
http://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kl.alfapcr">kl.alfapcr</a>, <a href="#topic+cv.tflr">cv.tflr</a>, <a href="#topic+pcr">pcr</a>, <a href="#topic+glm.pcr">glm.pcr</a>, <a href="#topic+alfapcr.tune">alfapcr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- rdiri( 214, runif(4, 1, 3) )
x &lt;- as.matrix( fgl[, 2:9] )
x &lt;- x / rowSums(x)
mod &lt;- klalfapcr.tune(y = y, x = x, a = c(0.7, 0.8) )
mod
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20k-NN+20algorithm+20for+20compositional+20data'>
Tuning of the k-NN algorithm for compositional data
</h2><span id='topic+compknn.tune'></span><span id='topic+alfaknn.tune'></span><span id='topic+aitknn.tune'></span>

<h3>Description</h3>

<p>Tuning of the k-NN algorithm for compositional data with and without using the
power or the <code class="reqn">\alpha</code>-transformation. In addition, estimation of the rate
of correct classification via K-fold cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compknn.tune(x, ina, nfolds = 10, k = 2:5, mesos = TRUE,
a = seq(-1, 1, by = 0.1), apostasi = "ESOV", folds = NULL,
stratified = TRUE, seed = NULL, graph = FALSE)

alfaknn.tune(x, ina, nfolds = 10, k = 2:5, mesos = TRUE,
a = seq(-1, 1, by = 0.1), apostasi = "euclidean", rann = FALSE,
folds = NULL, stratified = TRUE, seed = NULL, graph = FALSE)

aitknn.tune(x, ina, nfolds = 10, k = 2:5, mesos = TRUE,
a = seq(-1, 1, by = 0.1), apostasi = "euclidean", rann = FALSE,
folds = NULL, stratified = TRUE, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed, but you
must be careful to choose strictly positive values of <code class="reqn">\alpha</code> or not
to set apostasi= &quot;Ait&quot;.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_ina">ina</code></td>
<td>

<p>A group indicator variable for the available data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if
the folds argument is not supplied.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_k">k</code></td>
<td>

<p>A vector with the nearest neighbours to consider.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_mesos">mesos</code></td>
<td>

<p>This is used in the non standard algorithm. If TRUE, the arithmetic mean of
the distances is calculated, otherwise the harmonic mean is used (see details).
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_a">a</code></td>
<td>

<p>A grid of values of <code class="reqn">\alpha</code> to be used only if the distance chosen allows
for it.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_apostasi">apostasi</code></td>
<td>

<p>The type of distance to use. For the compk.knn this can be one of the following:
&quot;ESOV&quot;, &quot;taxicab&quot;, &quot;Ait&quot;, &quot;Hellinger&quot;, &quot;angular&quot; or &quot;CS&quot;. See the references
for them. For the alfa.knn this can be either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_rann">rann</code></td>
<td>

<p>If you have large scale datasets and want a faster k-NN search, you can use
kd-trees implemented in the R package &quot;Rnanoflann&quot;. In this case you must set this
argument equal to TRUE. Note however, that in this case, the only available
distance is by default &quot;euclidean&quot;.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL
and it will create folds.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be created in a stratified way? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20k-NN+2B20algorithm+2B20for+2B20compositional+2B20data_+3A_graph">graph</code></td>
<td>

<p>If set to TRUE a graph with the results will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The k-NN algorithm is applied for the compositional data. There are many metrics
and possibilities to choose from. The algorithm finds the k nearest
observations to a new observation and allocates it to the class which appears
most times in the neighbours.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>per</code></td>
<td>

<p>A matrix or a vector (depending on the distance chosen) with the averaged over
all folds rates of correct classification for all hyper-parameters
(<code class="reqn">\alpha</code> and k).
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The estimated rate of correct classification.
</p>
</td></tr>
<tr><td><code>best_a</code></td>
<td>

<p>The best value of <code class="reqn">\alpha</code>. This is returned for &quot;ESOV&quot; and &quot;taxicab&quot; only.
</p>
</td></tr>
<tr><td><code>best_k</code></td>
<td>

<p>The best number of nearest neighbours.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris, Michail (2014). The k-NN algorithm for compositional data:
a revised approach with and without zero values present.
Journal of Data Science, 12(3): 519&ndash;534.
https://arxiv.org/pdf/1506.05216.pdf
</p>
<p>Friedman Jerome, Trevor Hastie and Robert Tibshirani (2009).
The elements of statistical learning,
2nd edition. Springer, Berlin
</p>
<p>Tsagris M., Preston S. and Wood A.T.A. (2016). Improved classification for
compositional data using the <code class="reqn">\alpha</code>-transformation.
Journal of Classification, 33(2): 243&ndash;261.
http://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Connie Stewart (2017). An approach to measure distance between
compositional diet estimates containing essential zeros.
Journal of Applied Statistics 44(7): 1137&ndash;1152.
</p>
<p>Clarotto L., Allard D. and Menafoglio A. (2022).
A new class of <code class="reqn">\alpha</code>-transformations for the spatial analysis
of Compositional Data. Spatial Statistics, 47.
</p>
<p>Endres, D. M. and Schindelin, J. E. (2003). A new metric for probability distributions.
Information Theory, IEEE Transactions on 49, 1858&ndash;1860.
</p>
<p>Osterreicher, F. and Vajda, I. (2003). A new class of metric divergences on
probability spaces and its applicability in statistics.
Annals of the Institute of Statistical Mathematics 55, 639&ndash;653.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+comp.knn">comp.knn</a>, <a href="#topic+alfarda.tune">alfarda.tune</a>, <a href="#topic+cv.dda">cv.dda</a>, <a href="#topic+cv.compnb">cv.compnb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/ rowSums(x)
ina &lt;- iris[, 5]
mod1 &lt;- compknn.tune(x, ina, a = seq(1, 1, by = 0.1) )
mod2 &lt;- alfaknn.tune(x, ina, a = seq(-1, 1, by = 0.1) )
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20projection+20pursuit+20regression+20for+20compositional+20data'>
Tuning of the projection pursuit regression for compositional data
</h2><span id='topic+compppr.tune'></span>

<h3>Description</h3>

<p>Tuning of the projection pursuit regression for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compppr.tune(y, x, nfolds = 10, folds = NULL, seed = NULL,
nterms = 1:10, type = "alr", yb = NULL )

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_y">y</code></td>
<td>

<p>A matrix with the available compositional data, but zeros are not allowed.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the continuous predictor variables.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to use.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_nterms">nterms</code></td>
<td>

<p>The number of terms to try in the projection pursuit regression.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_type">type</code></td>
<td>

<p>Either &quot;alr&quot; or &quot;ilr&quot; corresponding to the additive or the isometric log-ratio transformation respectively.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20for+2B20compositional+2B20data_+3A_yb">yb</code></td>
<td>

<p>If you have already transformed the data using a log-ratio transformation put it here.
Othewrise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs tuning of the projection pursuit regression algorithm.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>kl</code></td>
<td>

<p>The average Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>perf</code></td>
<td>

<p>The average Kullback-Leibler divergence.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American
Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+comp.ppr">comp.ppr</a>, <a href="#topic+aknnreg.tune">aknnreg.tune</a>, <a href="#topic+akernreg.tune">akernreg.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.matrix(iris[, 1:3])
y &lt;- y/ rowSums(y)
x &lt;- iris[, 4]
mod &lt;- compppr.tune(y, x)
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20projection+20pursuit+20regression+20with+20compositional+20predictor+20variables'>
Tuning of the projection pursuit regression with compositional predictor variables
</h2><span id='topic+pprcomp.tune'></span>

<h3>Description</h3>

<p>Tuning of the projection pursuit regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pprcomp.tune(y, x, nfolds = 10, folds = NULL, seed = NULL,
nterms = 1:10, type = "log", graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>A numerical vector with the continuous variable.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data, but zeros are not allowed.
</p>
</td></tr><tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to use.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_nterms">nterms</code></td>
<td>

<p>The number of terms to try in the projection pursuit regression.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_type">type</code></td>
<td>

<p>Either &quot;alr&quot; or &quot;log&quot; corresponding to the additive log-ratio transformation
or the logarithm applied to the compositional predictor variables.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs tuning of the projection pursuit regression algorithm with compositional predictor variables.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the cross-validation procedure.
</p>
</td></tr>
<tr><td><code>mse</code></td>
<td>

<p>The mean squared error of prediction for each number of terms.
</p>
</td></tr>
<tr><td><code>opt.nterms</code></td>
<td>

<p>The number of terms corresponding to the minimum mean squared error of prediction.
</p>
</td></tr>
<tr><td><code>opt.alpha</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> corresponding to the minimum mean squared error of prediction.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum mean squared error of prediction.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American
Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+pprcomp">pprcomp</a>, <a href="#topic+ice.pprcomp">ice.pprcomp</a>, <a href="#topic+alfapcr.tune">alfapcr.tune</a>, <a href="#topic+compppr.tune">compppr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 2:4])
x &lt;- x/ rowSums(x)
y &lt;- iris[, 1]
mod &lt;- pprcomp.tune(y, x)
</code></pre>

<hr>
<h2 id='Tuning+20of+20the+20projection+20pursuit+20regression+20with+20compositional+20predictor+20variables+20using+20the+20alpha-transformation'>
Tuning of the projection pursuit regression with compositional predictor variables using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfapprcomp.tune'></span>

<h3>Description</h3>

<p>Tuning of the projection pursuit regression with compositional predictor variables using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfapprcomp.tune(y, x, nfolds = 10, folds = NULL, seed = NULL,
nterms = 1:10, a = seq(-1, 1, by = 0.1), graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A numerical vector with the continuous variable.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the available compositional data. Zeros are allowed.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to use.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_nterms">nterms</code></td>
<td>

<p>The number of terms to try in the projection pursuit regression.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>A vector with the values of <code class="reqn">\alpha</code> for the <code class="reqn">\alpha</code>-transformation.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20of+2B20the+2B20projection+2B20pursuit+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables+2B20using+2B20the+2B20alpha-transformation_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs tuning of the projection pursuit regression algorithm with
compositional predictor variables using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The run time of the cross-validation procedure.
</p>
</td></tr>
<tr><td><code>mse</code></td>
<td>

<p>The mean squared error of prediction for each number of terms.
</p>
</td></tr>
<tr><td><code>opt.nterms</code></td>
<td>

<p>The number of terms corresponding to the minimum mean squared error of prediction.
</p>
</td></tr>
<tr><td><code>opt.alpha</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> corresponding to the minimum mean squared error of prediction.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum mean squared error of prediction.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American
Statistical Association, 76, 817-823. doi: 10.2307/2287576.
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa.pprcomp">alfa.pprcomp</a>, <a href="#topic+pprcomp.tune">pprcomp.tune</a>, <a href="#topic+compppr.tune">compppr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 2:4])
x &lt;- x / rowSums(x)
y &lt;- iris[, 1]
mod &lt;- alfapprcomp.tune( y, x, a = c(0, 0.5, 1) )
</code></pre>

<hr>
<h2 id='Tuning+20the+20number+20of+20PCs+20in+20the+20PCR+20with+20compositional+20data+20using+20the+20alpha-transformation'>
Tuning the number of PCs in the PCR with compositional data using the <code class="reqn">\alpha</code>-transformation
</h2><span id='topic+alfapcr.tune'></span>

<h3>Description</h3>

<p>This is a cross-validation procedure to decide on the number of principal components when using regression with compositional data (as predictor variables) using the <code class="reqn">\alpha</code>-transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfapcr.tune(y, x, model = "gaussian", nfolds = 10, maxk = 50, a = seq(-1, 1, by = 0.1),
folds = NULL, ncores = 1, graph = TRUE, col.nu = 15, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_y">y</code></td>
<td>

<p>A vector with either continuous, binary or count data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. Zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_model">model</code></td>
<td>

<p>The type of regression model to fit. The possible values are &quot;gaussian&quot;, &quot;binomial&quot; and &quot;poisson&quot;.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds for the K-fold cross validation, set to 10 by default.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_maxk">maxk</code></td>
<td>

<p>The maximum number of principal components to check.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_a">a</code></td>
<td>

<p>A vector with a grid of values of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_ncores">ncores</code></td>
<td>

<p>How many cores to use. If you have heavy computations or do not want to wait for long time more than 1 core (if available) is suggested. It is advisable to use it if you have many observations and or many variables, otherwise it will slow down th process.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE (default value) a filled contour plot will appear.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_col.nu">col.nu</code></td>
<td>

<p>A number parameter for the filled contour plot, taken into account only if graph is TRUE.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20number+2B20of+2B20PCs+2B20in+2B20the+2B20PCR+2B20with+2B20compositional+2B20data+2B20using+2B20the+2B20alpha-transformation_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data first and the function &quot;pcr.tune&quot; or &quot;glmpcr.tune&quot; is called.
</p>


<h3>Value</h3>

<p>If graph is TRUE a filled contour will appear.
A list including:
</p>
<table>
<tr><td><code>mspe</code></td>
<td>

<p>The MSPE where rows correspond to the <code class="reqn">\alpha</code> values and the columns to the number of principal components.
</p>
</td></tr>
<tr><td><code>best.par</code></td>
<td>

<p>The best pair of <code class="reqn">\alpha</code> and number of principal components.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The minimum mean squared error of prediction.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. Chilean Journal of
Statistics, 6(2): 47-57.
https://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>
<p>Jolliffe I.T. (2002). Principal Component Analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alfa">alfa</a>, <a href="stats.html#topic+profile">profile</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+pcr.tune">pcr.tune</a>, <a href="#topic+glmpcr.tune">glmpcr.tune</a>, <a href="stats.html#topic+glm">glm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.vector(fgl[, 1])
x &lt;- as.matrix(fgl[, 2:9])
x &lt;- x/ rowSums(x)
mod &lt;- alfapcr.tune(y, x, nfolds = 10, maxk = 50, a = seq(-1, 1, by = 0.1) )
</code></pre>

<hr>
<h2 id='Tuning+20the+20principal+20components+20with+20GLMs'>
Tuning the principal components with GLMs
</h2><span id='topic+pcr.tune'></span><span id='topic+glmpcr.tune'></span><span id='topic+multinompcr.tune'></span>

<h3>Description</h3>

<p>Tuning the number of principal components in the generalised linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcr.tune(y, x, nfolds = 10, maxk = 50, folds = NULL, ncores = 1,
seed = NULL, graph = TRUE)

glmpcr.tune(y, x, nfolds = 10, maxk = 10, folds = NULL, ncores = 1,
seed = NULL, graph = TRUE)

multinompcr.tune(y, x, nfolds = 10, maxk = 10, folds = NULL, ncores = 1,
seed = NULL, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_y">y</code></td>
<td>

<p>A real valued vector for &quot;pcr.tune&quot;. A real valued vector for the &quot;glmpcr.tune&quot; with 
either two numbers, 0 and 1 for example, for the binomial regression or with positive 
discrete numbers for the poisson. For the &quot;multinompcr.tune&quot; a vector or a factor with 
more than just two values. This is a multinomial regression.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds in the cross validation.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_maxk">maxk</code></td>
<td>

<p>The maximum number of principal components to check.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use. If more than 1, parallel computing will take place. It is advisable 
to use it if you have many observations and or many variables, otherwise it will slow down th process.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20principal+2B20components+2B20with+2B20GLMs_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE a plot of the performance for each fold along the values of <code class="reqn">\alpha</code> will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cross validation is performed to select the optimal number of principal components in the GLMs 
or the multinomial regression. This is used
by <code><a href="#topic+alfapcr.tune">alfapcr.tune</a></code>.
</p>


<h3>Value</h3>

<p>If graph is TRUE a plot of the performance versus the number of principal components will appear.
A list including:
</p>
<table>
<tr><td><code>msp</code></td>
<td>

<p>A matrix with the mean deviance of prediction or mean accuracy for every fold.
</p>
</td></tr>
<tr><td><code>mpd</code></td>
<td>

<p>A vector with the mean deviance of prediction or mean accuracy, each value corresponds to a 
number of principal components.
</p>
</td></tr>
<tr><td><code>k</code></td>
<td>

<p>The number of principal components which minimizes the deviance or maximises the accuracy.
</p>
</td></tr>
<tr><td><code>performance</code></td>
<td>

<p>The optimal performance, MSE for the linea regression, minimum deviance for the GLMs and maximum 
accuracy for the multinomial regression.
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the cross-validation procedure.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aguilera A.M., Escabias M. and Valderrama M.J. (2006). Using principal components for estimating 
logistic regression with high-dimensional multicollinear data. Computational Statistics &amp; Data Analysis 50(8): 1905-1924.
</p>
<p>Jolliffe I.T. (2002). Principal Component Analysis.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcr.tune">pcr.tune</a>, <a href="#topic+glm.pcr">glm.pcr</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfapcr.tune">alfapcr.tune</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
x &lt;- as.matrix(fgl[, 2:9])
y &lt;- rpois(214, 10)
glmpcr.tune(y, x, nfolds = 10, maxk = 20, folds = NULL, ncores = 1)
</code></pre>

<hr>
<h2 id='Tuning+20the+20value+20of+20alpha+20in+20the+20alpha-regression'>
Tuning the value of <code class="reqn">\alpha</code> in the <code class="reqn">\alpha</code>-regression
</h2><span id='topic+alfareg.tune'></span>

<h3>Description</h3>

<p>Tuning the value of <code class="reqn">\alpha</code> in the <code class="reqn">\alpha</code>-regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alfareg.tune(y, x, a = seq(0.1, 1, by = 0.1), nfolds = 10,
folds = NULL, nc = 1, seed = NULL, graph = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_y">y</code></td>
<td>

<p>A matrix with compositional data. zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_x">x</code></td>
<td>

<p>A matrix with the continuous predictor variables or a data frame including categorical predictor variables.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_a">a</code></td>
<td>

<p>The value of the power transformation, it has to be between -1 and 1. If zero values are present it has to be greater than 0. If <code class="reqn">\alpha=0</code> the isometric log-ratio transformation is applied.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to split the data.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_folds">folds</code></td>
<td>

<p>If you have the list with the folds supply it here. You can also leave it NULL and it will create folds.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_nc">nc</code></td>
<td>

<p>The number of cores to use. IF you have a multicore computer it is advisable to use more than 1. It makes the procedure faster. It is advisable to use it if you have many observations and or many variables, otherwise it will slow down th process.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_seed">seed</code></td>
<td>

<p>You can specify your own seed number here or leave it NULL.
</p>
</td></tr>
<tr><td><code id="Tuning+2B20the+2B20value+2B20of+2B20alpha+2B20in+2B20the+2B20alpha-regression_+3A_graph">graph</code></td>
<td>

<p>If graph is TRUE a plot of the performance for each fold along the values of <code class="reqn">\alpha</code> will appear.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\alpha</code>-transformation is applied to the compositional data and the numerical optimisation is performed for the regression, unless <code class="reqn">\alpha=0</code>, where the coefficients are available in closed form.
</p>


<h3>Value</h3>

<p>A plot of the estimated Kullback-Leibler divergences (multiplied by 2) along the values of <code class="reqn">\alpha</code> (if graph is set to TRUE).
A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime required by the cross-validation.
</p>
</td></tr>
<tr><td><code>kula</code></td>
<td>

<p>A matrix with twice the Kullback-Leibler divergence of the observed from the fitted values. Each row corresponds to a fold and each column to a value of <code class="reqn">\alpha</code>. The average over the columns equal the next argument, &quot;kl&quot;.
</p>
</td></tr>
<tr><td><code>kl</code></td>
<td>

<p>A vector with twice the Kullback-Leibler divergence of the observed from the fitted values. Every value corresponds to a value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>

<p>The optimal value of <code class="reqn">\alpha</code>.
</p>
</td></tr>
<tr><td><code>value</code></td>
<td>

<p>The minimum value of twice the Kullback-Leibler.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>
and Giorgos Athineou &lt;gioathineou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. (2015). Regression analysis with compositional data containing zero values. 
Chilean Journal of Statistics, 6(2): 47-57.
https://arxiv.org/pdf/1508.01913v1.pdf
</p>
<p>Tsagris M.T., Preston S. and Wood A.T.A. (2011). A data-based power transformation for compositional data.
In Proceedings of the 4th Compositional Data Analysis Workshop, Girona, Spain.
https://arxiv.org/pdf/1106.1451.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+alfa.reg">alfa.reg</a>, <a href="#topic+alfa">alfa</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
y &lt;- as.matrix(fgl[1:40, 2:4])
y &lt;- y /rowSums(y)
x &lt;- as.vector(fgl[1:40, 1])
mod &lt;- alfareg.tune(y, x, a = seq(0, 1, by = 0.1), nfolds = 5)
</code></pre>

<hr>
<h2 id='Two-sample+20test+20of+20high-dimensional+20means+20for+20compositional+20data'>
Two-sample test of high-dimensional means for compositional data
</h2><span id='topic+hd.meantest2'></span>

<h3>Description</h3>

<p>Two-sample test of high-dimensional means for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hd.meantest2(y1, y2, R = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Two-sample+2B20test+2B20of+2B20high-dimensional+2B20means+2B20for+2B20compositional+2B20data_+3A_y1">y1</code></td>
<td>

<p>A matrix containing the compositional data of the first group.
</p>
</td></tr>
<tr><td><code id="Two-sample+2B20test+2B20of+2B20high-dimensional+2B20means+2B20for+2B20compositional+2B20data_+3A_y2">y2</code></td>
<td>

<p>A matrix containing the compositional data of the second group.
</p>
</td></tr>
<tr><td><code id="Two-sample+2B20test+2B20of+2B20high-dimensional+2B20means+2B20for+2B20compositional+2B20data_+3A_r">R</code></td>
<td>

<p>If R is 1 no bootstrap calibration is performed and the asymptotic p-value is returned. If R is greater than 1,
the bootstrap p-value is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A two sample for high dimensional mean vectors of compositional data is implemented. See references for more details.
</p>


<h3>Value</h3>

<p>A vector with the test statistic value and its associated (bootstrap) p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Cao Y., Lin W. and Li H. (2018). Two-sample tests of high-dimensional means for compositional data.
Biometrika, 105(1): 115-132.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+comp.test">comp.test</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- runif(200, 10, 15)
x1 &lt;- rdiri(100, m)
x2 &lt;- rdiri(100, m)
hd.meantest2(x1, x2)
</code></pre>

<hr>
<h2 id='Unconstrained+20GLMs+20with+20compositional+20predictor+20variables'>
Unconstrained GLMs with compositional predictor variables
</h2><span id='topic+ulc.glm'></span>

<h3>Description</h3>

<p>Unconstrained GLMs with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ulc.glm(y, x, z = NULL, model = "logistic", xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Unconstrained+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This is either a binary variable or a vector with counts.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_model">model</code></td>
<td>

<p>For the ulc.glm(), this can be either &quot;logistic&quot; or &quot;poisson&quot;. 
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20GLMs+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the unconstrained log-contrast logistic or Poisson regression model. The logarithm of the
compositional predictor variables is used (hence no zero values are allowed). The response variable
is linked to the log-transformed data <b>without</b> the constraint that the sum of the regression coefficients
equals 0. If you want the regression without the zum-to-zero contraints see <code><a href="#topic+lc.glm">lc.glm</a></code>.
Extra predictors variables are allowed as well, for instance categorical or continuous.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>devi</code></td>
<td>

<p>The residual deviance of the logistic or Poisson regression model.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The unconstrained regression coefficients. Their sum does not equal 0.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and znew were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Lu J., Shi P., and Li H. (2019). Generalized linear models with linear constraints
for microbiome compositional data. Biometrics, 75(1): 235-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lc.glm">lc.glm</a>, <a href="#topic+lc.glm2">lc.glm2</a>, <a href="#topic+ulc.glm2">ulc.glm2</a>,  <a href="#topic+lcglm.aov">lcglm.aov</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(150, 1, 0.5)
x &lt;- rdiri(150, runif(3, 1,3))
mod &lt;- ulc.glm(y, x)
</code></pre>

<hr>
<h2 id='Unconstrained+20linear+20regression+20with+20compositional+20predictor+20variables'>
Unconstrained linear regression with compositional predictor variables
</h2><span id='topic+ulc.reg'></span>

<h3>Description</h3>

<p>Unconstrained linear regression with compositional predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ulc.reg(y, x, z = NULL, xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This must be a continuous variable.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing the new compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20compositional+2B20predictor+2B20variables_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the unconstrained log-contrast regression model as opposed to the log-contrast
regression described in Aitchison (2003), pg. 84-85. The logarithm of the compositional predictor variables
is used (hence no zero values are allowed). The response variable is linked to the log-transformed data
<b>without</b> the constraint that the sum of the regression coefficients equals 0. If you want the regression model
with the zum-to-zero contraints see <code><a href="#topic+lc.reg">lc.reg</a></code>. Extra predictors variables are allowed as well,
for instance categorical or continuous.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The unconstrained regression coefficients. Their sum does not equal 0.
</p>
</td></tr>
<tr><td><code>covbe</code></td>
<td>

<p>If covariance matrix of the constrained regression coefficients.
</p>
</td></tr>
<tr><td><code>va</code></td>
<td>

<p>The estimated regression variance.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>

<p>The vector of residuals.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and &quot;znew&quot; were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lc.reg">lc.reg</a>, <a href="#topic+lcreg.aov">lcreg.aov</a>, <a href="#topic+lc.reg2">lc.reg2</a>, <a href="#topic+ulc.reg2">ulc.reg2</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.knn.reg">alfa.knn.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- as.matrix(iris[, 2:4])
x &lt;- x / rowSums(x)
mod1 &lt;- ulc.reg(y, x)
mod2 &lt;- ulc.reg(y, x, z = iris[, 5])
</code></pre>

<hr>
<h2 id='Unconstrained+20linear+20regression+20with+20multiple+20compositional+20predictors'>
Unconstrained linear regression with multiple compositional predictors
</h2><span id='topic+ulc.reg2'></span>

<h3>Description</h3>

<p>Unconstrained linear regression with multiple compositional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ulc.reg2(y, x, z = NULL, xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This must be a continuous variable.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_x">x</code></td>
<td>

<p>A list with multiple matrices with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing a list with multiple matrices with compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20linear+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the unconstrained log-contrast regression model as opposed to the log-contrast
regression described in Aitchison (2003), pg. 84-85. The logarithm of the compositional predictor variables
is used (hence no zero values are allowed). The response variable is linked to the log-transformed data
<b>without</b> the constraint that the sum of the regression coefficients equals 0. If you want the
regression model with the zum-to-zero contraints see <code><a href="#topic+lc.reg2">lc.reg2</a></code>. Extra predictors variables
are allowed as well, for instance categorical or continuous. Similarly to <code><a href="#topic+lc.reg2">lc.reg2</a></code> there
are multiple compositions treated as predictor variables.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The unconstrained regression coefficients. Their sum for each composition does not equal 0.
</p>
</td></tr>
<tr><td><code>covbe</code></td>
<td>

<p>If covariance matrix of the constrained regression coefficients.
</p>
</td></tr>
<tr><td><code>va</code></td>
<td>

<p>The estimated regression variance.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>

<p>The vector of residuals.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and &quot;znew&quot; were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Xiaokang Liu, Xiaomei Cong, Gen Li, Kendra Maas and Kun Chen (2020). Multivariate Log-Contrast Regression
with Sub-Compositional Predictors: Testing the Association Between Preterm Infants' Gut Microbiome and
Neurobehavioral Outcome.
<a href="https://arxiv.org/pdf/2006.00487.pdf">https://arxiv.org/pdf/2006.00487.pdf</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lc.reg2">lc.reg2</a>, <a href="#topic+ulc.reg">ulc.reg</a>, <a href="#topic+lc.reg">lc.reg</a>, <a href="#topic+alfa.pcr">alfa.pcr</a>, <a href="#topic+alfa.knn.reg">alfa.knn.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- iris[, 1]
x &lt;- list()
x1 &lt;- as.matrix(iris[, 2:4])
x1 &lt;- x1 / rowSums(x1)
x[[ 1 ]] &lt;- x1
x[[ 2 ]] &lt;- rdiri(150, runif(4) )
x[[ 3 ]] &lt;- rdiri(150, runif(5) )
mod &lt;- lc.reg2(y, x)
</code></pre>

<hr>
<h2 id='Unconstrained+20logistic+20or+20Poisson+20regression+20with+20multiple+20compositional+20predictors'>
Unconstrained logistic or Poisson regression with multiple compositional predictors
</h2><span id='topic+ulc.glm2'></span>

<h3>Description</h3>

<p>Unconstrained logistic or Poisson regression with multiple compositional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ulc.glm2(y, x, z = NULL, model = "logistic", xnew = NULL, znew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Unconstrained+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_y">y</code></td>
<td>

<p>A numerical vector containing the response variable values. This is either a binary variable or a vector with counts.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_x">x</code></td>
<td>

<p>A list with multiple matrices with the predictor variables, the compositional data. No zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_z">z</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with some other covariate(s).
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_model">model</code></td>
<td>

<p>This can be either &quot;logistic&quot; or &quot;poisson&quot;.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_xnew">xnew</code></td>
<td>

<p>A matrix containing a list with multiple matrices with compositional data whose response is to be predicted.
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
<tr><td><code id="Unconstrained+2B20logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20multiple+2B20compositional+2B20predictors_+3A_znew">znew</code></td>
<td>

<p>A matrix, data.frame, factor or a vector with the values of some other covariate(s).
If you have no new data, leave this NULL as is by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the unconstrained log-contrast logistic or Poisson regression model. The logarithm of the
compositional predictor variables is used (hence no zero values are allowed). The response variable
is linked to the log-transformed data <b>without</b> the constraint that the sum of the regression coefficients
equals 0. If you want the regression without the zum-to-zero contraints see <code><a href="#topic+lc.glm2">lc.glm2</a></code>.
Extra predictors variables are allowed as well, for instance categorical or continuous.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>devi</code></td>
<td>

<p>The residual deviance of the logistic or Poisson regression model.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The unconstrained regression coefficients. Their sum does not equal 0.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>If the arguments &quot;xnew&quot; and znew were given these are the predicted or estimated values, otherwise it is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>
<p>Lu J., Shi P., and Li H. (2019). Generalized linear models with linear constraints
for microbiome compositional data. Biometrics, 75(1): 235-244.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lc.glm2">lc.glm2</a>, <a href="#topic+ulc.glm">ulc.glm</a>, <a href="#topic+lc.glm">lc.glm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(150, 1, 0.5)
x &lt;- list()
x1 &lt;- as.matrix(iris[, 2:4])
x1 &lt;- x1 / rowSums(x1)
x[[ 1 ]] &lt;- x1
x[[ 2 ]] &lt;- rdiri(150, runif(4) )
x[[ 3 ]] &lt;- rdiri(150, runif(5) )
mod &lt;- ulc.glm2(y, x)
</code></pre>

<hr>
<h2 id='Unit-Weibull+20regression+20models+20for+20proportions'>
Unit-Weibull regression models for proportions
</h2><span id='topic+unitweib.reg'></span>

<h3>Description</h3>

<p>Unit-Weibull regression models for proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unitweib.reg(y, x, tau = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Unit-Weibull+2B20regression+2B20models+2B20for+2B20proportions_+3A_y">y</code></td>
<td>

<p>A numerical vector proportions. 0s and 1s are allowed.
</p>
</td></tr>
<tr><td><code id="Unit-Weibull+2B20regression+2B20models+2B20for+2B20proportions_+3A_x">x</code></td>
<td>

<p>A matrix or a data frame with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Unit-Weibull+2B20regression+2B20models+2B20for+2B20proportions_+3A_tau">tau</code></td>
<td>

<p>The quantile to be used for estimation. The default value is 0.5 yielding the median.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference paper.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The loglikelihood of the regression model.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A matrix with all estimated parameters, their standard error, their Wald-statistic and its associated p-value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Mazucheli J., Menezes A. F. B., Fernandes L. B., de Oliveira R. P. and Ghitany M. E. (2020).
The unit-Weibull distribution as an alternative to the Kumaraswamy distribution for the modeling of quantiles conditional on covariates.
Journal of Applied Statistics, 47(6): 954&ndash;974.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+propreg">propreg</a>, <a href="#topic+beta.reg">beta.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- exp( - rweibull(100, 1, 1) )
x &lt;- matrix( rnorm(100 * 2), ncol = 2 )
a &lt;- unitweib.reg(y, x)
</code></pre>

<hr>
<h2 id='Zero+20adjusted+20Dirichlet+20regression'>
Zero adjusted Dirichlet regression
</h2><span id='topic+zadr'></span><span id='topic+zadr2'></span>

<h3>Description</h3>

<p>Zero adjusted Dirichlet regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zadr(y, x, con = TRUE, B = 1, ncores = 2, xnew = NULL)
zadr2(y, x, con = TRUE, B = 1, ncores = 2, xnew = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zero+2B20adjusted+2B20Dirichlet+2B20regression_+3A_y">y</code></td>
<td>

<p>A matrix with the compositional data (dependent variable). The number of observations
(vectors) with no zero values should be more than the columns of the predictor variables.
Otherwise, the initial values will not be calculated.
</p>
</td></tr>
<tr><td><code id="Zero+2B20adjusted+2B20Dirichlet+2B20regression_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they can be either continnuous or categorical or both.
</p>
</td></tr>
<tr><td><code id="Zero+2B20adjusted+2B20Dirichlet+2B20regression_+3A_con">con</code></td>
<td>

<p>If this is TRUE (default) then the constant term is estimated, otherwise the model includes no constant term.
</p>
</td></tr>
<tr><td><code id="Zero+2B20adjusted+2B20Dirichlet+2B20regression_+3A_b">B</code></td>
<td>

<p>If B is greater than 1 bootstrap estimates of the standard error are returned.
If you set this greater than 1, then you must define the number of clusters in
order to run in parallel.
</p>
</td></tr>
<tr><td><code id="Zero+2B20adjusted+2B20Dirichlet+2B20regression_+3A_ncores">ncores</code></td>
<td>

<p>The number of cores to use when B&gt;1. This is to be used for the
case of bootstrap. If B = 1, this is not taken into consideration.
If this does not work then you might need to load the doParallel yourselves.
</p>
</td></tr>
<tr><td><code id="Zero+2B20adjusted+2B20Dirichlet+2B20regression_+3A_xnew">xnew</code></td>
<td>

<p>If you have new data use it, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A zero adjusted Dirichlet regression is being fittd. The likelihood conists of two components.
The contributions of the non zero compositional values and the contributions of the compositional
vectors with at least one zero value. The second component may have many different sub-categories,
one for each pattern of zeros. The function &quot;zadr2()&quot; links the covariates to the alpha parameters
of the Dirichlet distribution, i.e. it uses the classical parametrization of the distribution.
This means, that there is a set of regression parameters for each component.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The time required by the regression.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The precision parameter.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard error of the beta coefficients.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>Th covariance matrix of the regression parameters (for the mean vector and the phi parameter).
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The fitted or the predicted values (if xnew is not NULL).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Tsagris M. and Stewart C. (2018). A Dirichlet regression model for compositional data with zeros.
Lobachevskii Journal of Mathematics,39(3): 398&ndash;412.
</p>
<p>Preprint available from https://arxiv.org/pdf/1410.5011.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zad.est">zad.est</a>, <a href="#topic+diri.reg">diri.reg</a>, <a href="#topic+kl.compreg">kl.compreg</a>, <a href="#topic+ols.compreg">ols.compreg</a>, <a href="#topic+alfa.reg">alfa.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.vector(iris[, 4])
y &lt;- as.matrix(iris[, 1:3])
y &lt;- y / rowSums(y)
mod1 &lt;- diri.reg(y, x)
y[sample(1:450, 15) ] &lt;- 0
mod2 &lt;- zadr(y, x)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
