<!DOCTYPE html><html lang="en"><head><title>Help for package ufRisk</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ufRisk}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ufRisk'><p>ufRisk: A package for user friendly and practical usage of various</p>
backtesting methods.</a></li>
<li><a href='#covtest'><p>Unconditional and Conditional Coverage Tests, Independence Test</p></a></li>
<li><a href='#ESTX'><p>EURO STOXX 50 (ESTX) Financial Time Series Data</p></a></li>
<li><a href='#lossfunc'><p>Loss Functions</p></a></li>
<li><a href='#plot.ufRisk'><p>Plot Method for the Package 'ufRisk'</p></a></li>
<li><a href='#print.ufRisk'><p>Print Method for Objects of Class 'ufRisk'</p></a></li>
<li><a href='#trafftest'><p>Backtesting of Value-at-Risk and Expected Shortfall via Traffic Light Tests</p></a></li>
<li><a href='#varcast'><p>Calculation of one-step ahead forecasts of Value at Risk and Expected Shortfall (parametric and</p>
semiparametric)</a></li>
<li><a href='#WMT'><p>Walmart Inc. (WMT) Financial Time Series Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Risk Measure Calculation in Financial TS</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.7</td>
</tr>
<tr>
<td>Description:</td>
<td>Enables the user to calculate Value at Risk (VaR) and Expected 
    Shortfall (ES) by means of various parametric and semiparametric 
    GARCH-type models. For the latter the estimation of the nonparametric scale
    function is carried out by means of a data-driven smoothing approach. Model
    quality, in terms of forecasting VaR and ES, can be assessed by means of 
    various backtesting methods such as the traffic light test for VaR and a 
    newly developed traffic light test for ES. The approaches implemented in 
    this package are described in e.g. Feng Y., Beran J., Letmathe S. and 
    Ghosh S. (2020) <a href="https://ideas.repec.org/p/pdn/ciepap/137.html">https://ideas.repec.org/p/pdn/ciepap/137.html</a> as well as 
    Letmathe S., Feng Y. and Uhde A. (2021) 
    <a href="https://ideas.repec.org/p/pdn/ciepap/141.html">https://ideas.repec.org/p/pdn/ciepap/141.html</a>. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>esemifar, fracdiff, rugarch, smoots, stats, utils</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-22 07:55:10 UTC; Letmode</td>
</tr>
<tr>
<td>Author:</td>
<td>Yuanhua Feng [aut] (Paderborn University, Germany),
  Xuehai Zhang [aut] (Former research associate at Paderborn University,
    Germany),
  Christian Peitz [aut] (Paderborn University, Germany),
  Dominik Schulz [aut] (Paderborn University, Germany),
  Shujie Li [aut] (Paderborn Universtiy, Germany),
  Sebastian Letmathe [aut, cre] (Paderborn University, Germany)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Letmathe &lt;sebastian.letmathe@uni-paderborn.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-22 08:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ufRisk'>ufRisk: A package for user friendly and practical usage of various
backtesting methods.</h2><span id='topic+ufRisk'></span><span id='topic+ufRisk-package'></span>

<h3>Description</h3>

<p>The goal of the <code>ufRisk</code> package (univariate financial risk) is to
enable the user to compute one-step ahead forecasts of Value at Risk (VaR)
and Expected Shortfall (ES) by means of various parametric and semiparametric
GARCH-type models. For the latter the estimation of the nonparametric scale
function is carried out by means of a data-driven smoothing approach.
Currently the GARCH, the exponential GARCH (EGARCH), the Log-GARCH, the
asymmetric power ARCH (APARCH), the FIGARCH and FI-Log-GARCH can be employed
within the scope of <code>ufRisk</code>. Model quality, in terms of forecasting VaR
and ES, can be assessed by means of various backtesting methods.
</p>


<h3>Functions</h3>

<p><code>varcast</code> is a function to calculate rolling one-step ahead forecasts
of VaR and ES for a selection of parametric and semiparametric GARCH-type models (see also
<code><a href="#topic+varcast">varcast</a></code>).
</p>
<p><code>trafftest</code> is a function for backtesting VaR and ES. ES is backtested
via a newly developed traffic light approach. (see also
<code><a href="#topic+trafftest">trafftest</a></code>).
</p>
<p><code>covtest</code> is a function for conducting the conditional and the
unconditional coverage tests introduced by Kupiec (1995) and Christoffersen
(1998). (see also <code><a href="#topic+covtest">covtest</a></code>).
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Xuehai Zhang (Former research associate at Paderborn University),<br />
Author <br />
</p>
</li>
<li><p> Shujie Li (Scientific Employee) (Department of Economics,
Paderborn University), <br />
Author <br />
</p>
</li>
<li><p> Christian Peitz (Department of Economics, Paderborn University), <br />
Author <br />
</p>
</li>
<li><p> Dominik Schulz (Scientific Employee) (Department of Economics,
Paderborn University), <br />
Author <br />
</p>
</li>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Basel Committee on Banking Supervision (1996). Supervisory Framework For The
Use of Back-Testing in Conjunction With The Internal Models Approach to
Market Risk Capital Requirements.
Available online: <a href="https://www.bis.org/publ/bcbs22.htm">https://www.bis.org/publ/bcbs22.htm</a> (accessed on 23 June
2020).
</p>
<p>Beran, J., and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54(2), pp. 291-311.
</p>
<p>Constanzino, N., and Curran, M. (2018). A Simple Traffic Light Approach to
Backtesting Expected Shortfall. In: Risks 6.1.2.
</p>
<p>Feng, Y. (2004). Simultaneously modeling conditional heteroskedasticity and
scale change. In: Econometric Theory, pp. 563-596.
</p>
<p>Feng, Y., Beran, J., Letmathe, S., &amp; Ghosh, S. (2020). Fractionally
integrated Log-GARCH with application to value at risk and expected
shortfall (No. 137). Paderborn University, CIE Center for
International Economics.
</p>
<p>Letmathe, S., Feng, Y., &amp; Uhde, A. (2021). Semiparametric GARCH models with
long memory applied to Value at Risk and Expected Shortfall (No. 141).
Paderborn University, CIE Center for International Economics.
</p>
<p>McNeil, A.J., Frey, R., and Embrechts, P. (2015). Quantitative risk
management: concepts, techniques and tools - revised edition. Princeton
University Press.
</p>

<hr>
<h2 id='covtest'>Unconditional and Conditional Coverage Tests, Independence Test</h2><span id='topic+covtest'></span>

<h3>Description</h3>

<p>The conditional (Kupiec, 1995), the unconditional coverage
test (Christoffersen, 1998) and the independence test (Christoffersen, 1998)
of the Value-at-Risk (VaR) can be applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covtest(obj = list(Loss = NULL, VaR = NULL, p = NULL), conflvl = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covtest_+3A_obj">obj</code></td>
<td>
<p>a list that contains the following elements:
</p>

<dl>
<dt><code>Loss</code></dt><dd><p>a numeric vector that contains the values of a loss series
ordered from past to present; is set to <code>NULL</code> by default.</p>
</dd>
<dt><code>VaR</code></dt><dd><p>a numeric vector that contains the estimated values of the
VaR for the same time points of the loss series <code>Loss</code>;
is set to <code>NULL</code> by default.</p>
</dd>
<dt><code>p</code></dt><dd><p>a numeric vector with one element; defines the probability p
stated in the null hypotheses of the coverage tests (see the section
<code>Details</code> for more information); is set to <code>NULL</code> by default.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="covtest_+3A_conflvl">conflvl</code></td>
<td>
<p>a numeric vector with one element; the significance
level at which the null hypotheses are evaluated; is set to <code>0.95</code> by
default.
Please note that a list returned by the <code>varcast</code> function can be directly
passed to <code>covtest</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With this function, the conditional and the unconditional coverage
tests introduced by Kupiec (1995) and Christoffersen (1998) can be applied.
Given a return series <code class="reqn">r_t</code> with <code class="reqn">n</code> observations, divide the
series into <code class="reqn">n-K</code> in-sample and <code class="reqn">K</code> out-of-sample observations,
fit a model to the in-sample data and obtain rolling one-step forecasts of
the VaR for the out-of-sample time points.
</p>
<p>Define
</p>
<p style="text-align: center;"><code class="reqn">I_t = 1,</code>
</p>

<p>if <code class="reqn">-r_t &gt; \widehat{VaR}_t (\alpha)</code> or
</p>
<p style="text-align: center;"><code class="reqn">I_t = 0,</code>
</p>
<p> otherwise,
</p>
<p>for <code class="reqn">t = n + 1, n + 2, ..., n + K</code> as the hit sequence, where <code class="reqn">\alpha</code> is
the confidence level for the VaR (often <code class="reqn">\alpha = 0.95</code> or <code class="reqn">\alpha = 0.99</code>).
Furthermore, denote <code class="reqn">p = \alpha</code> and let <code class="reqn">w</code> be the actual covered
proportion of losses in the data.
</p>
<p>1. Unconditional coverage test:
</p>
<p style="text-align: center;"><code class="reqn">H_{0, uc}: p = w</code>
</p>

<p>Let <code class="reqn">K_1</code> be the number of ones in <code class="reqn">I_t</code> and analogously <code class="reqn">K_0</code> the number of
zeros (all conditional on the first observation).
Also calculate <code class="reqn">\hat{w} = K_0 / (K - 1)</code>. Obtain
</p>
<p style="text-align: center;"><code class="reqn">L(I_t, p) = p^{K_0}(1 - p)^{K_1}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(I_t, \hat{w}) = \hat{w}^{K_0}(1 - \hat{w})^{K_1}</code>
</p>

<p>and subsequently the test statistic
</p>
<p style="text-align: center;"><code class="reqn">LR_{uc} = -2  * \ln \{L(I_t, p) / L(I_t, \hat{w})\}.</code>
</p>

<p><code class="reqn">LR_{uc}</code> now asymptotically follows a chi-square-distribution with one degree
of freedom.
</p>
<p>2. Conditional coverage test:
</p>
<p>The conditional coverage test combines the unconditional coverage test
with a test on independence. Denote by <code class="reqn">w_{ij}</code> the probability of an <code class="reqn">i</code> on day
<code class="reqn">t-1</code> being followed by a <code class="reqn">j</code> on day <code class="reqn">t</code>, where <code class="reqn">i</code> and <code class="reqn">j</code> correspond to the value of
<code class="reqn">I_t</code> on the respective day.
</p>
<p style="text-align: center;"><code class="reqn">H_{0, cc}: w_{00} = w{10} = p</code>
</p>

<p>with <code class="reqn">i = 0, 1</code> and <code class="reqn">j = 0, 1</code>.
</p>
<p>Let <code class="reqn">K_{ij}</code> be the number of observations, where the values on two following days
follow the pattern <code class="reqn">ij</code>. Calculate
</p>
<p style="text-align: center;"><code class="reqn">L(I_t, \hat{w}_{00}, \hat{w}_{10})
= \hat{w}_{00}^{K_{00}}(1 - \hat{w}_{00})^{K_{01}} * \hat{w}_{10})^{K_{10}}(1 - \hat{w}_{10})^{K_{11}},</code>
</p>

<p>where <code class="reqn">\hat{w}_{00} = K_{00} / K_0</code> and <code class="reqn">\hat{w}_{10} = K_{10} / K_1</code>. The test
statistic is then given by
</p>
<p style="text-align: center;"><code class="reqn">LR_{cc} = -2  * \ln \{ L(I_t, p) / L(I_t, \hat{w}_{00}, \hat{w}_{10}) \},</code>
</p>

<p>which asymptotically follows a chi-square-distribution with two degrees of
freedom.
</p>
<p>3. Independence test:
</p>
<p style="text-align: center;"><code class="reqn">H_{0,ind}: w_{00} = w_{10}</code>
</p>

<p>The asymptotically chi-square-distributed test statistic (one degree of
freedom) is given by
</p>
<p style="text-align: center;"><code class="reqn">LR_{ind} = -2  * \ln \{L(I_t, \hat{w}_{00}, \hat{w}_{10}) / L(I_t, \hat{w})\}.</code>
</p>

<p>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
</p>
<p>The function needs four inputs: the out-of-sample loss series <code>obj$Loss</code>, the
corresponding estimated VaR series <code>obj$VaR</code>, the coverage level <code>obj$p</code>,
for which the VaR has been calculated and the significance level <code>conflvl</code>,
at which the null hypotheses are evaluated. If an object returned by this function
is entered into the R console, a detailed overview of the test
results is printed.
</p>


<h3>Value</h3>

<p>A list of class <code>ufRisk</code> with the following four elements:
</p>

<dl>
<dt>p</dt><dd><p>probability p stated in the null hypotheses of the coverage tests.</p>
</dd>
<dt>p.uc</dt><dd><p>the p-value of the unconditional coverage test.</p>
</dd>
<dt>p.cc</dt><dd><p>the p-value of the conditional coverage test.</p>
</dd>
<dt>p.ind</dt><dd><p>the p-value of the independence test.</p>
</dd>
<dt>conflvl</dt><dd><p>the significance level at which the null hypotheses are
evaluated.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University) <br />
</p>
</li>
<li><p> Dominik Schulz (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>



<h3>References</h3>

<p>Christoffersen, P. F. (1998). Evaluating interval forecasts. International
economic review, pp. 841-862.
</p>
<p>Kupiec, P. (1995). Techniques for verifying the accuracy of risk measurement
models. The J. of Derivatives, 3(2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Example for Walmart Inc. (WMT)
prices &lt;- WMT$price.close
output &lt;- varcast(prices)
Loss &lt;- -output$ret.out
VaR &lt;- output$VaR.v
covtest.data &lt;- list(Loss = Loss, VaR = VaR, p = 0.99)
covtest(covtest.data)

# directly passing an output object of 'varcast()' to 'covtest()'
output &lt;- varcast(prices)
covtest(output)

</code></pre>

<hr>
<h2 id='ESTX'>EURO STOXX 50 (ESTX) Financial Time Series Data</h2><span id='topic+ESTX'></span>

<h3>Description</h3>

<p>A dataset that contains the daily financial data of the ESTX from
April 2007 to December 2021 (currency in EUR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESTX
</code></pre>


<h3>Format</h3>

<p>A data frame with 3697 rows and 10 variables:
</p>

<dl>
<dt>price.open</dt><dd><p>opening price (daily)</p>
</dd>
<dt>price.high</dt><dd><p>highest price (daily)</p>
</dd>
<dt>price.low</dt><dd><p>lowest price (daily)</p>
</dd>
<dt>price.close</dt><dd><p>closing price (daily)</p>
</dd>
<dt>volume</dt><dd><p>trading volume</p>
</dd>
<dt>price.adjusted</dt><dd><p>adjusted closing price (daily)</p>
</dd>
<dt>ref.date</dt><dd><p>date in format YY-MM-DD</p>
</dd>
<dt>ticker</dt><dd><p>ticker symbol</p>
</dd>
<dt>ret.adjusted.prices</dt><dd><p>returns obtained from the adjusted closing
prices</p>
</dd>
<dt>ret.closing.prices</dt><dd><p>returns obtained from the closing prices</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data was obtained from Yahoo Finance.
</p>

<hr>
<h2 id='lossfunc'>Loss Functions</h2><span id='topic+lossfunc'></span>

<h3>Description</h3>

<p>This functions allows for the calculation of loss functions for the
selection of models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lossfunc(obj = list(Loss = NULL, ES = NULL), beta = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lossfunc_+3A_obj">obj</code></td>
<td>
<p>a list that contains the following elements:
</p>

<dl>
<dt><code>Loss</code></dt><dd><p>a numeric vector that contains the values of a loss series
ordered from past to present; is set to <code>NULL</code> by default</p>
</dd>
<dt><code>ES</code></dt><dd><p>a numeric vector that contains the estimated values of the
ES for the same time points of the loss series <code>Loss</code>; is set to
<code>NULL</code> by default</p>
</dd>
</dl>

<p>Please note that a list returned by the <code>varcast</code> function can be directly
passed to <code>lossfunc</code>.</p>
</td></tr>
<tr><td><code id="lossfunc_+3A_beta">beta</code></td>
<td>
<p>a single numeric value; a measure for the opportunity cost of
capital; default is <code>1e-04</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a negative return series <code>obj$Loss</code>, the corresponding Expected
Shortfall (ES) estimates <code>obj$ES</code> and a parameter <code>beta</code> that
defines the opportunity cost of capital, four different definitions of loss
functions are considered.
</p>
<p>Let <code class="reqn">K</code> be the number of observations and <code class="reqn">r_t</code> the observed return series.
Following Sarma et al. (2003)
</p>
<p style="text-align: center;"><code class="reqn">l_{t,1} = \{\widehat{ES}_t (\alpha) + r_t \}^2,</code>
</p>

<p>if <code class="reqn">-r_t &gt; \widehat{ES}_t(\alpha)</code>
</p>
<p style="text-align: center;"><code class="reqn">l_{t,1} = \beta * \widehat{ES}_t (\alpha),</code>
</p>

<p>otherwise,
</p>
<p>is a suitable loss function (firm's loss function), where <code class="reqn">\beta</code> is the
opportunity cost of capital. The regulatory loss function
is identical to the firm's loss function with the exception of
<code class="reqn">l_{t,1} = 0</code> for <code class="reqn">-r_t \leq \widehat{ES}_t (\alpha)</code>.
</p>
<p>Abad et al. (2015) proposed another loss function
</p>
<p style="text-align: center;"><code class="reqn">l_{t,a} = \{\widehat{ES}_t(\alpha) + r_t\}^2,</code>
</p>

<p>if <code class="reqn">-r_t &gt; \widehat{ES}_t(\alpha)</code>
</p>
<p style="text-align: center;"><code class="reqn">l_{t,a} = \beta * (\widehat{ES}_t (\alpha) + r_t),</code>
</p>

<p>otherwise,
</p>
<p>that, however, also considers opportunity costs for <code class="reqn">r_t &gt; 0</code>. An adjustment has
been proposed by Feng. Following his idea,
</p>
<p style="text-align: center;"><code class="reqn">l_{t,2} = \{\widehat{ES}_t(\alpha) + r_t\}^2,</code>
</p>

<p>if <code class="reqn">-r_t &gt; \widehat{ES}_t (\alpha)</code>
</p>
<p style="text-align: center;"><code class="reqn">l_{t,2} = \beta * \min\{\widehat{ES}_t(\alpha) + r_t, \widehat{ES}_t(\alpha)\},</code>
</p>

<p>otherwise,
</p>
<p>should be considered as a compromise of the regulatory and the firm's loss
functions. Note that instead of the ES, also a series of Value-at-Risk values
can be inserted for the argument <code>obj$ES</code>. However this is not possible if
a list returned by the <code>varcast</code> function is directly passed to
<code>lossfunc</code>.
</p>


<h3>Value</h3>

<p>an S3 class object, which is a list of
</p>

<dl>
<dt>loss.func1</dt><dd><p>Regulatory loss function.</p>
</dd>
<dt>loss.func2</dt><dd><p>Firm's loss function following Sarma et al. (2003).</p>
</dd>
<dt>loss.func3</dt><dd><p>Loss function following Abad et al. (2015).</p>
</dd>
<dt>loss.func4</dt><dd><p>Feng's loss function. A compromise of regulatory and
firm's loss function.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University) <br />
</p>
</li>
<li><p> Dominik Schulz (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>



<h3>References</h3>

<p>Abad, P., Muela, S. B., &amp; Mart√≠n, C. L. (2015). The role of the loss function
in value-at-risk comparisons. The Journal of Risk Model Validation, 9(1), 1-19.
</p>
<p>Sarma, M., Thomas, S., &amp; Shah, A. (2003). Selection of Value-at-Risk models.
Journal of Forecasting, 22(4), 337-358.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Example for Walmart Inc. (WMT)
prices &lt;- WMT$price.close
output &lt;- varcast(prices)
Loss &lt;- -output$ret.out
ES &lt;- output$ES
loss.data &lt;- list(Loss = Loss, ES = ES)
lossfunc(loss.data)

# directly passing an output object of 'varcast()' to 'lossfunc()'
x &lt;- WMT$price.close
output &lt;- varcast(prices)
lossfunc(output)

</code></pre>

<hr>
<h2 id='plot.ufRisk'>Plot Method for the Package 'ufRisk'</h2><span id='topic+plot.ufRisk'></span>

<h3>Description</h3>

<p>This function regulates how objects created by the package <code>ufRisk</code> are
plotted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ufRisk'
plot(x, plot.option = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.ufRisk_+3A_x">x</code></td>
<td>
<p>an input object of class <code>ufRisk</code>.</p>
</td></tr>
<tr><td><code id="plot.ufRisk_+3A_plot.option">plot.option</code></td>
<td>
<p>plot choice for an object of class <code>ufRisk</code>; viable
choices are:
</p>

<dl>
<dt>1</dt><dd><p>Plotting out-of-sample loss series</p>
</dd>
<dt>2</dt><dd><p>Plotting out-of-sample losses, VaR.v &amp; breaches</p>
</dd>
<dt>3</dt><dd><p>Plotting out-of-sample losses, VaR.e, ES &amp; breaches</p>
</dd>
</dl>

<p>Please note if no value is passed to <code>plot.option</code> a selection menu is
prompted; is set to <code>NULL</code> by default.</p>
</td></tr>
<tr><td><code id="plot.ufRisk_+3A_...">...</code></td>
<td>
<p>additional arguments of the standard plot method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University) <br />
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
</p>
</li></ul>


<hr>
<h2 id='print.ufRisk'>Print Method for Objects of Class 'ufRisk'</h2><span id='topic+print.ufRisk'></span>

<h3>Description</h3>

<p>This function regulates how objects of class <code>ufRisk</code> are printed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ufRisk'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.ufRisk_+3A_x">x</code></td>
<td>
<p>an object of class <code>ufRisk</code>; for the current package version,
only the function <code>br_test</code> returns such an object.</p>
</td></tr>
<tr><td><code id="print.ufRisk_+3A_...">...</code></td>
<td>
<p>implemented for compatibility with the generic function;
additional arguments, however, will not affect this print method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University) <br />
</p>
</li>
<li><p> Dominik Schulz (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>


<hr>
<h2 id='trafftest'>Backtesting of Value-at-Risk and Expected Shortfall via Traffic Light Tests</h2><span id='topic+trafftest'></span>

<h3>Description</h3>

<p>Backtesting methods, most importantly traffic light tests, are applied to
previously calculated Value-at-Risk and Expected Shortfall series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trafftest(obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trafftest_+3A_obj">obj</code></td>
<td>
<p>A list returned by the <code>varcast</code> function, that contains
different estimated Value-at-Risk and Expected Shortfall series; any
other list that follows the name conventions of the <code>varcast</code> function
can be used as well.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Traffic Light Test for backtesting the Value-at-Risk (VaR) was proposed
by the Basel Committee on Banking Supervision (1996). A formal mathematical
description was given by Constanzino and Curran (2018). Following
Constanzino and Curran (2018), define the Value-at-Risk breach indicator by
</p>
<p style="text-align: center;"><code class="reqn">X_{VaR}^{(i)}(\alpha) = 1_{ \{L_i \geq VaR_i(\alpha)\} },</code>
</p>

<p>where <code class="reqn">i</code> defines the corresponding trading day, <code class="reqn">L_i</code> is the loss
(denoted as a positive value) on day <code class="reqn">i</code> and <code class="reqn">\alpha</code> is the confidence
level of the VaR (e.g. if <code class="reqn">\alpha = 0.95</code>, the 95%-VaR is considered). The
total number of breaches over all trading days <code class="reqn">i = 1, 2, ..., N</code> is then
given by
</p>
<p style="text-align: center;"><code class="reqn">X_{VaR}^{N}(\alpha) = \sum_{i=1}^{N} 1_{\{L_i \geq VaR_i(\alpha)\}}.</code>
</p>

<p>Following a Binomial Distribution, the cumulative probabilities of observing
a specific number of breaches or less can be computed. Under the hypothesis
that the selected volatility model is true, the cumulative probability of
observing <code class="reqn">X_{VaR}^N (\alpha)</code> breaches is therefore easily obtainable. The
Basel Committee on Banking Supervision (1996) defined three zones. Depending
on the zone the calculated cumulative probability can be sorted into, the
suitability of the selected model can be assessed. Models with calculated
cumulative probabilities &lt; 95% belong to the green zone and are considered
appropriate. Furthermore, if the probabilities are greater or equal to 95%
but smaller than 99.99%, the corresponding models are categorized into the
yellow zone. The red zone is for models with cumulative probabilities greater
or equal to 99.99%. If the test results in a yellow zone classification, the
respective VaR values require additional monitoring. Moreover, the Basel
Committee recommended to consider additional capital requirements of a bank,
if its model used is in the yellow zone. Models in the red zone are
considered to be heavily flawed.
</p>
<p>Based on the same three-zone approach with the same zone boundaries,
Constanzino and Curran (2018) proposed a traffic light test for the Expected
Shortfall (ES). The total severity of breaches is given by
</p>
<p style="text-align: center;"><code class="reqn">X_{ES}^N(\alpha) = \sum_{i=1}^N(1 - (1 - F(L_i))/(1 - \alpha))
 * 1_{\{L_i \geq VaR_i(\alpha)\}},</code>
</p>

<p>with <code class="reqn">F(L_i)</code> being the cumulative distribution of the loss at day <code class="reqn">i</code>. As stated
by Constanzino and Curran (2018), <code class="reqn">X_{ES}^N(\alpha)</code> is approximately normally
distributed <code class="reqn">\mathcal{N}(\mu_{ES}</code>, <code class="reqn">N \sigma_{ES}^2)</code> for large samples, where
<code class="reqn">\mu_{ES} = 0.5(1 - \alpha)N</code> and
<code class="reqn">\sigma_{ES}^2 = (1 - \alpha)(4 - 3(1 - \alpha)) / 12</code>, from which cumulative
probabilities for the observed breaches <code class="reqn">X_{ES}^N</code> can be easily obtained.
</p>
<p>For semiparametric models, the backtesting of the VaR is analogous to the
described approach. Backtesting the ES, however, requires minor adjustments.
Given that the model's underlying innovations follow a standardized
t-distribution with degrees of freedom <code class="reqn">\nu</code>, define by <code class="reqn">r_t</code> the demeaned
returns and by <code class="reqn">\hat{s}_t</code> the estimated total volatility.
</p>
<p style="text-align: center;"><code class="reqn">\hat{\epsilon}_t^* = -r_t / \hat{s}_t \sqrt{\nu / (\nu - 2)}</code>
</p>

<p>are now suitable to calculate the total severity of breaches under the
assumption that <code class="reqn">\epsilon_t^*</code> are identically and independently
distributed t-distributed random variables.
</p>
<p>This function uses an object returned by the <code>varcast</code> function
of the <code>ufRisk</code> package as an input for the
function argument <code>obj</code>. A list with different elements, such as
the cumulative probabilities for the VaR and ES series within <code>obj</code>,
is returned. Instead of the list, only the traffic light backtesting results
are printed to the R console.
</p>
<p>NOTE:
</p>
<p>More information on VaR and ES can be found in the documentation of the
<code>varcast</code> function of the <code>ufRisk</code> package
<code><a href="#topic+varcast">varcast</a></code>.
</p>


<h3>Value</h3>

<p>A list of class <code>ufRisk</code> is returned with the following elements.
</p>

<dl>
<dt>model</dt><dd><p>selected model for estimation</p>
</dd>
<dt>p_VaR.e</dt><dd><p>cumulative probability of observing the number of
breaches or fewer for (1 - <code>a.e</code>)100%-VaR</p>
</dd>
<dt>p_VaR.v</dt><dd><p>cumulative probability of observing the number of
breaches or fewer for (1 - <code>a.v</code>)100%-VaR</p>
</dd>
<dt>p_ES</dt><dd><p>cumulative probability of observing the number of
breaches or fewer for (1 - <code>a.e</code>)100%-ES</p>
</dd>
<dt>pot_VaR.e</dt><dd><p>number of exceedances for (1 - <code>a.e</code>)100%-VaR</p>
</dd>
<dt>pot_VaR.v</dt><dd><p>number of exceedances for (1 - <code>a.v</code>)100%-VaR</p>
</dd>
<dt>potES</dt><dd><p>number of exceedances for (1 - <code>a.e</code>)100%-ES</p>
</dd>
<dt>br.sum</dt><dd><p>sum of breaches for (1 - <code>a.e</code>)100%-ES</p>
</dd>
<dt>WAD</dt><dd><p>weighted absolute deviations - a model selection criterion</p>
</dd>
<dt>a.v</dt><dd><p>coverage level for the (1-<code>a.v</code>)100% VaR</p>
</dd>
<dt>a.e</dt><dd><p>coverage level for (1-<code>a.e</code>)100% VaR</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li>
<li><p> Dominik Schulz (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>



<h3>References</h3>

<p>Basel Committee on Banking Supervision (1996). Supervisory Framework For The
Use of Back-Testing in Conjunction With The Internal Models Approach to
Market Risk Capital Requirements.
Available online: <a href="https://www.bis.org/publ/bcbs22.htm">https://www.bis.org/publ/bcbs22.htm</a> (accessed on 23 June
2020).
</p>
<p>Constanzino, N., and Curran, M. (2018). A Simple Traffic Light Approach to
Backtesting Expected Shortfall. In: Risks 6.1.2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example for Walmart Inc. (WMT)
prices = WMT$price.close
output = varcast(prices)
trafftest(output)

</code></pre>

<hr>
<h2 id='varcast'>Calculation of one-step ahead forecasts of Value at Risk and Expected Shortfall (parametric and
semiparametric)</h2><span id='topic+varcast'></span>

<h3>Description</h3>

<p>One-step ahead forecasts of Value at Risk and Expected Shortfall for a selection of short-memory
and long-memory parametric as well as semiparametric GARCH-type models are
computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varcast(
  x,
  a.v = 0.99,
  a.e = 0.975,
  model = c("sGARCH", "lGARCH", "eGARCH", "apARCH", "fiGARCH", "filGARCH"),
  garchOrder = c(1, 1),
  distr = c("norm", "std"),
  n.out = 250,
  smooth = c("none", "lpr"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varcast_+3A_x">x</code></td>
<td>
<p>a vector containing the price series.</p>
</td></tr>
<tr><td><code id="varcast_+3A_a.v">a.v</code></td>
<td>
<p>confidence level for calculating VaR; is set to <code>0.99</code> by default.</p>
</td></tr>
<tr><td><code id="varcast_+3A_a.e">a.e</code></td>
<td>
<p>confidence level for calculating ES; is set to <code>0.975</code> by default.</p>
</td></tr>
<tr><td><code id="varcast_+3A_model">model</code></td>
<td>
<p>model to be estimated. Options are 'sGARCH', 'eGARCH', 'apARCH',
'lGARCH', 'fiGARCH' and 'filGARCH'; is set to <code>'sGARCH'</code> by default.</p>
</td></tr>
<tr><td><code id="varcast_+3A_garchorder">garchOrder</code></td>
<td>
<p>orders to be estimated; c(1, 1), i.e. p = q = 1, is the
default.</p>
</td></tr>
<tr><td><code id="varcast_+3A_distr">distr</code></td>
<td>
<p>distribution to use for the innovations of the respective GARCH model;
is set to <code>'std'</code> by default</p>
</td></tr>
<tr><td><code id="varcast_+3A_n.out">n.out</code></td>
<td>
<p>size of out-sample; is set to <code>250</code> by default.</p>
</td></tr>
<tr><td><code id="varcast_+3A_smooth">smooth</code></td>
<td>
<p>a character object; defines the data-driven smoothing approach
for the estimation of the nonparametric scale function; for
<code>smooth = 'lpr'</code>, the scale function is obtained from the logarithm
of the squared centralized returns by means of the <code>msmooth()</code> function or
<code>tsmoothlm()</code> function if <code>model</code> is set to <code>'sGARCH'</code>, <code>'eGARCH'</code>,
<code>'apARCH'</code> and <code>lGARCH'} or \code{'fiGARCH</code> and <code>'filGARCH'</code>,
respectively; is set to <code>smooth = 'none'</code> by default.</p>
</td></tr>
<tr><td><code id="varcast_+3A_...">...</code></td>
<td>
<p>depending on the choice of <code>model</code>, further arguments can be
passed to either <code>smoots::msmooth()</code> or to <code>tsmoothlm()</code>;
if no other arguments are given, the default settings
are used for both functions with the exception of <code>p = 3</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">Y_t</code> be a (demeaned) return series. The semiparametric extension of
the GARCH(p,q) model (Bollerslev, 1986) is called a Semi-GARCH model
(Feng, 2004) and is defined by
</p>
<p style="text-align: center;"><code class="reqn">Y_t = s(x_t)\sigma_t \eta_t,</code>
</p>

<p>with <code class="reqn">\eta_t \sim IID(0,1)</code> and
</p>
<p style="text-align: center;"><code class="reqn">\sigma^2_t = \alpha_0 + \sum_{i=1}^p \alpha_i Y^2_{t-i}
+ \sum_{j=1}^q \beta_j \sigma^2_{t-j},</code>
</p>

<p>where <code class="reqn">\sigma_t &gt; 0</code> are the conditional standard deviations, <code class="reqn">s(x_t) &gt; 0</code> is
a nonparametric scale function with <code class="reqn">x_t</code> being the rescaled observation
time points on the interval [0,1] and <code class="reqn">\alpha_i</code>
and <code class="reqn">\beta_j</code> are non-negative real valued coefficients, except for
<code class="reqn">\alpha_0</code>, which must satisfy <code class="reqn">\alpha_0 &gt; 0</code>. Furthermore, it is assumed that
Var<code class="reqn">(\sigma_t \eta_t) = 1</code>. In this functions, different
short-memory and long-memory GARCH-type models are selectable for the parametric part of the
model. More specifically, the standard GARCH (Bollerslev, 1986), the
Log-GARCH (Pantula, 1986; Geweke, 1986; Milhoj, 1988), the eGARCH
(Nelson, 1991), the APARCH (Ding et al., 1993), the FIGARCH (Baillie et al., 1996)
and the FI-Log-GARCH (Feng et al., 2020) model are implemented. For more
information on the representations of the last three models mentioned, we
refer the reader to the corresponding references listed in the references
section.
</p>
<p>While the innovations <code class="reqn">\eta_t</code> must be i.i.d. (independent and identically
distributed) with zero-mean and unit-variance and while any
distribution that satisfies these conditions is suitable, the standardized
t-distribution is selected for the estimation of the models and computation
of the Value at Risk (VaR) as well as the Expected Shortfall (ES) within
this function.
</p>
<p>For a given level <code class="reqn">\alpha \in (0, 1)</code>,
</p>
<p style="text-align: center;"><code class="reqn">VaR(\alpha) = inf \{z \in R: F_L(z) \geq \alpha\}</code>
</p>

<p>defines the VaR at level alpha. In this definition, <code class="reqn">L</code> is the
loss variable (making a loss is denoted as a positive value, whereas gains
are negative values) and <code class="reqn">F_L</code> is its cumulative distribution function.
Explained differently, <code class="reqn">VaR(\alpha)</code> is the <code class="reqn">\alpha</code>-quantile of the loss
distribution.
</p>
<p>The ES for a level <code class="reqn">\alpha</code>, however, is given by
</p>
<p style="text-align: center;"><code class="reqn">ES(\alpha) = (1 / (1 - \alpha)) \int_{\alpha}^1 VaR(u)du,</code>
</p>

<p>i.e. it is the expected loss in case <code class="reqn">VaR(\alpha)</code> is exceeded. More
information on these risk measures can be found on pp. 64-72 in McNeil et
al. (2015).
</p>
<p>To apply the function, a numeric vector that contains the price series that
is to be analyzed ordered from past to present must be passed to the
argument <code>x</code>. Furthermore, the user can set different levels of alpha
for the VaR and the ES via the arguments <code>a.v</code> and <code>a.e</code>,
respectively. A parametric short-memory or long-memory GARCH-type model can be
selected by means of <code>model</code>, which only accepts a single-element character vector
as input. At the time of the release of package version 1.0.0, a standard
GARCH ('sGARCH'), a Log-GARCH ('lGARCH'), an eGARCH ('eGARCH'), an APARCH
('apARCH'), a FIGARCH ('fiGARCH') and a FI-Log-GARCH ('filGARCH') model can be selected,
each with conditional t-distribution. By default, a standard GARCH model is applied.
The orders of the GARCH-type models can be defined with <code>garchOrder</code>,
which is a numeric vector with two elements. Its first element is the
ARCH order p, whereas the GARCH order q can be adjusted via the second
element. If no adjustments are made, the orders p = q = 1 are selected. The
number of out-sample observations is set via the argument <code>n.out</code>. If n
is the total number of observations of the
whole price series, the model is estimated for the first n - n.out
observations (in-sample), while the VaR and the ES are obtained for the last
n.out observations (out-sample) based on the estimated model for the
in-sample. Moreover, the data-driven estimation method of the underlying
scale function can be adjusted via the argument <code>smooth</code>. If
<code>smooth = 'lpr'</code> is selected, the scale function is obtained by
applying an iterative plug-in algorithm logarithm of the squared
centralized returns. Depending on the setting of <code>model</code> an algorithm
proposed by Feng, Gries and Fritz (2020) or by Letmathe, Feng and Uhde
(2021) is employed. In the former case, the function <code>msmooth()</code> of the
<code>smoots</code> package is applied and for the latter the <code>tsmoothlm()</code>
function of the <code>esemifar</code> package is used. An ellipsis <code>...</code> is
implemented to allow for additional arguments for <code>msmooth()</code> and
<code>tsmoothlm()</code>.
</p>
<p>NOTE:
</p>
<p>This function makes use of the <code>arima()</code> function of the stats package,
of the <code>fracdiff()</code> function of the <code>fracdiff</code> package, of the
<code>ugarchspec()</code> and <code>ugarchfit()</code> functions of the <code>rugarch</code>
package, of the <code>msmooth()</code> function of the <code>smoots</code> package
and of the <code>esemifar()</code> function of the <code>esemifar</code> for estimation.
Moreover, Log-GARCH and FI-Log-GARCH models in the parametric part of the
complete models are estimated via their ARMA and FARIMA representations,
respectively, and must therefore satisfy <code class="reqn">p \geq q</code>.
</p>


<h3>Value</h3>

<p>This function returns a list with the following elements.
</p>

<dl>
<dt>model</dt><dd><p>selected model for estimation</p>
</dd>
<dt>mean</dt><dd><p>the estimated mean of the in-sample returns</p>
</dd>
<dt>model.fit</dt><dd><p>estimated model parameters for the parametric part of the
in-sample</p>
</dd>
<dt>np.est</dt><dd><p>the estimation results for the nonparametric part of the
in-sample model</p>
</dd>
<dt>ret.in</dt><dd><p>in-sample return series</p>
</dd>
<dt>ret.out</dt><dd><p>out-sample return series</p>
</dd>
<dt>sig.in</dt><dd><p>estimated in-sample total volatility</p>
</dd>
<dt>sig.fc</dt><dd><p>out-sample forecasts of the total volatility</p>
</dd>
<dt>scale</dt><dd><p>the estimated nonparametric scale function values for the
in-sample</p>
</dd>
<dt>scale.fc</dt><dd><p>the scale function forecast for the out-sample</p>
</dd>
<dt>VaR.e</dt><dd><p>out-sample forecasts of the (1-<code>a.e</code>)100% VaR</p>
</dd>
<dt>VaR.v</dt><dd><p>out-sample forecasts of the (1-<code>a.v</code>)100% VaR</p>
</dd>
<dt>ES</dt><dd><p>out-sample forecasts of the (1-<code>a.e</code>)100% ES</p>
</dd>
<dt>dfree</dt><dd><p>estimated degrees of freedom for the standardized returns</p>
</dd>
<dt>a.v</dt><dd><p>coverage level for the 99 % VaR</p>
</dd>
<dt>a.e</dt><dd><p>coverage level for 97.5 % VaR</p>
</dd>
<dt>garchOrder</dt><dd><p>the orders p and q of the implemented GARCH-type model</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University) <br />
</p>
</li>
<li><p> Dominik Schulz (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>



<h3>References</h3>

<p>Baillie, R. T., Bollerslev, T., &amp; Mikkelsen, H. O. (1996). Fractionally
integrated generalized autoregressive conditional heteroskedasticity.
In: Journal of Econometrics, 74.1, pp. 3-30.
</p>
<p>Bollerslev, T. (1986) Generalized autoregressive conditional
heteroskedasticity. In: Journal of Econometrics 31.3, pp. 307-327.
</p>
<p>Ding, Z., Granger, C.W., and Engle, R.F. (1993). A long memory property
of stock market returns and a new model. In: Journal of Empirical Finance
1.1, pp. 83-106.
</p>
<p>Feng, Y. (2004). Simultaneously modeling conditional heteroskedasticity and
scale change. In: Econometric Theory 20.3, pp. 563-596.
</p>
<p>Feng, Y., Beran, J., Letmathe, S., &amp; Ghosh, S. (2020). Fractionally
integrated Log-GARCH with application to value at risk and expected
shortfall (No. 137). Paderborn University, CIE Center for
International Economics.
</p>
<p>Pantula, S.G. (1986). Modeling the persistence of conditional variances:
a comment. In: Econometric Reviews 5, pp. 79-97.
</p>
<p>Geweke, J. (1986). Comment on: Modelling the persistence of conditional
variances. In: Econometric Reviews 5, pp. 57-61.
</p>
<p>Letmathe, S., Feng, Y., &amp; Uhde, A. (2021). Semiparametric GARCH models with
long memory applied to Value at Risk and Expected Shortfall (No. 141).
Paderborn University, CIE Center for International Economics.
</p>
<p>McNeil, A.J., Frey, R., and Embrechts, P. (2015). Quantitative risk
management: concepts, techniques and tools - revised edition. Princeton
University Press.
</p>
<p>Milhoj, A. (1988). A Multiplicative parametrization of ARCH models.
Universitetets Statistiske Institut.
</p>
<p>Nelson, D. B. (1991). Conditional heteroskedasticity in asset returns: A
new approach. In: Econometrica: Journal of the Econometric Society, 347-370.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example for Walmart Inc. (WMT)
prices = WMT$price.close

# forecasting VaR and ES
results = varcast(prices, model = 'sGARCH', n.out = 250)
ret.out = results$ret.out
n.out = length(ret.out)
VaR97.5 = results$VaR.e
VaR99 = results$VaR.v
ES = results$ES

# plotting VaR at 99% coverage
matplot(1:n.out, cbind(-ret.out, VaR99),
  type = 'hl',
  xlab = 'number of out-of-sample obs.', ylab = 'losses, VaR and ES',
  main = '99% VaR (red) for the WMT return series')

# plotting VaR at 97.5% coverage and corresponding ES
matplot(1:n.out, cbind(-ret.out, ES, VaR97.5),
  type = 'hll',
  xlab = 'number of out-of-sample obs.', ylab = 'losses, VaR and ES',
  main = '97.5% VaR (green) and ES (red) for the WMT return series')

</code></pre>

<hr>
<h2 id='WMT'>Walmart Inc. (WMT) Financial Time Series Data</h2><span id='topic+WMT'></span>

<h3>Description</h3>

<p>A dataset that contains the daily financial data of WMT from
January 2000 to December 2021 (currency in EUR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WMT
</code></pre>


<h3>Format</h3>

<p>A data frame with 5535 rows and 10 variables:
</p>

<dl>
<dt>price.open</dt><dd><p>opening price (daily)</p>
</dd>
<dt>price.high</dt><dd><p>highest price (daily)</p>
</dd>
<dt>price.low</dt><dd><p>lowest price (daily)</p>
</dd>
<dt>price.close</dt><dd><p>closing price (daily)</p>
</dd>
<dt>volume</dt><dd><p>trading volume</p>
</dd>
<dt>price.adjusted</dt><dd><p>adjusted closing price (daily)</p>
</dd>
<dt>ref.date</dt><dd><p>date in format YY-MM-DD</p>
</dd>
<dt>ticker</dt><dd><p>ticker symbol</p>
</dd>
<dt>ret.adjusted.prices</dt><dd><p>returns obtained from the adjusted closing
prices</p>
</dd>
<dt>ret.closing.prices</dt><dd><p>returns obtained from the closing prices</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data was obtained from Yahoo Finance.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
