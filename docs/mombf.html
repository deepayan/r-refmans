<!DOCTYPE html><html><head><title>Help for package mombf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mombf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bbPrior'><p> Priors on model space for variable selection problems</p></a></li>
<li><a href='#bestBIC'>
<p>Model with best AIC, BIC, EBIC or other general information criteria (getIC)</p></a></li>
<li><a href='#bfnormmix'><p> Number of Normal mixture components under Normal-IW and</p>
Non-local priors</a></li>
<li><a href='#cil'><p>Treatment effect estimation for linear models via Confounder Importance</p>
Learning using non-local priors.</a></li>
<li><a href='#dalapl'><p> Density and random draws from the asymmetric Laplace distribution</p></a></li>
<li><a href='#ddir'><p> Dirichlet density</p></a></li>
<li><a href='#diwish'><p>Density for Inverse Wishart distribution</p></a></li>
<li><a href='#dmom'><p> Non-local prior density, cdf and quantile functions.</p></a></li>
<li><a href='#dpostNIW'><p>Posterior Normal-IWishart density</p></a></li>
<li><a href='#eprod'><p> Expectation of a product of powers of Normal or T random</p>
variables</a></li>
<li><a href='#getBIC'>
<p>Obtain AIC, BIC, EBIC or other general information criteria (getIC)</p></a></li>
<li><a href='#hald'><p>Hald Data</p></a></li>
<li><a href='#icfit-class'><p>Class &quot;icfit&quot;</p></a></li>
<li><a href='#icov'><p> Extract estimated inverse covariance</p></a></li>
<li><a href='#localnulltest'><p> Local variable selection</p></a></li>
<li><a href='#marginalNIW'>
<p>Marginal likelihood under a multivariate Normal likelihood and a conjugate</p>
Normal-inverse Wishart prior.</a></li>
<li><a href='#mixturebf-class'><p>Class &quot;mixturebf&quot;</p></a></li>
<li><a href='#modelSelection'><p> Bayesian variable selection for linear models via non-local priors.</p></a></li>
<li><a href='#modelSelectionGGM'><p> Bayesian variable selection for linear models via non-local priors.</p></a></li>
<li><a href='#mombf'><p> Moment and inverse moment Bayes factors for linear models.</p></a></li>
<li><a href='#momknown'><p> Bayes factors for moment and inverse moment priors</p></a></li>
<li><a href='#msfit_ggm-class'><p>Class &quot;msfit_ggm&quot;</p></a></li>
<li><a href='#msfit-class'><p>Class &quot;msfit&quot;</p></a></li>
<li><a href='#msPriorSpec-class'><p>Class &quot;msPriorSpec&quot;</p></a></li>
<li><a href='#nlpmarginals'><p> Marginal density of the observed data for linear regression with</p>
Normal, two-piece Normal, Laplace or two-piece Laplace residuals
under non-local and Zellner priors</a></li>
<li><a href='#plotprior'>
<p>Plot estimated marginal prior inclusion probabilities</p></a></li>
<li><a href='#postModeOrtho'><p>Bayesian model selection and averaging under block-diagonal X'X for linear models.</p></a></li>
<li><a href='#postProb'>
<p>Obtain posterior model probabilities</p></a></li>
<li><a href='#postSamples'>
<p>Extract posterior samples from an object</p></a></li>
<li><a href='#priorp2g'><p> Moment and inverse moment prior elicitation</p></a></li>
<li><a href='#rnlp'>
<p>Posterior sampling for regression parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>3.5.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-05</td>
</tr>
<tr>
<td>Title:</td>
<td>Model Selection with Bayesian Methods and Information Criteria</td>
</tr>
<tr>
<td>Author:</td>
<td>David Rossell, John D. Cook, Donatello Telesca, P. Roebuck, Oriol Abril, Miquel Torrens</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Rossell &lt;rosselldavid@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14.0), methods, mvtnorm, ncvreg, mgcv</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel, testthat, patrick</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.16), dplyr, glasso, glmnet, intervals, Matrix,
mclust, pracma, sparseMatrixStats, survival</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Description:</td>
<td>Model selection and averaging for regression and mixtures, inclusing Bayesian model selection and information criteria (BIC, EBIC, AIC, GIC).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE [expanded from: GPL (&ge; 2) | file LICENSE]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/davidrusi/mombf">https://github.com/davidrusi/mombf</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/davidrusi/mombf/issues">https://github.com/davidrusi/mombf/issues</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Collate:</td>
<td>AllClasses.R AllGenerics.R alapl.R bms_ortho.R cil.R cox.R
derivatives_nlps.R distribs.R dmom.R gam.R ggm.R greedyGLM.R
infocriteria.R initParameters.R localnulltest.R msPriorSpec.R
modelsearch.R modelSelection.R modelSelectionGLM.R mombf.R
normaliwish.R normmix.R nlpMarginal.R postMode.R rmom.R
RcppExports.R testfunction.R</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-05 21:30:23 UTC; u138097</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-06 23:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bbPrior'> Priors on model space for variable selection problems </h2><span id='topic+bbPrior'></span><span id='topic+unifPrior'></span><span id='topic+binomPrior'></span>

<h3>Description</h3>

<p><code>unifPrior</code>
implements a uniform prior (equal a priori probability for all
models). <code>binomPrior</code> implements a Binomial prior.
<code>bbPrior</code> implements a Beta-Binomial prior. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unifPrior(sel, logscale=TRUE, groups=1:length(sel),
constraints=lapply(1:length(unique(groups)), function(z) integer(0)))

binomPrior(sel, prob=.5, logscale=TRUE, probconstr=prob, groups=1:length(sel),
constraints=lapply(1:length(unique(groups)), function(z) integer(0)))

bbPrior(sel, alpha=1, beta=1, logscale=TRUE, alphaconstr=alpha,
betaconstr=beta, groups=1:length(sel),
constraints=lapply(1:length(unique(groups)), function(z) integer(0)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bbPrior_+3A_sel">sel</code></td>
<td>
<p> Logical vector indicating which variables are included in
the model</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_logscale">logscale</code></td>
<td>
<p> Set to <code>TRUE</code> to return the log-prior
probability.</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_groups">groups</code></td>
<td>
<p>Group that each variable belongs to (e.g. dummy
indicators for categorical variables with &gt;2 categories). The idea
is that all variables in a group are jointly added/removed from the
model. By default all variables are assumed to be in separate groups</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_constraints">constraints</code></td>
<td>
<p>List with length equal to the number of groups
(distinct elements in <code>groups</code>). Element j in the list should
indicate any hierarchical constraints on the group, for instance
constraints[[3]]==c(1,2) indicates that group 3 can only be included
in the model if groups 1 and 2 are also in the model. This can be used
to enforce that an interaction can only be in the model if the main
effects are also in the model.
</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_prob">prob</code></td>
<td>
<p> Success probability for the Binomial prior</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_probconstr">probconstr</code></td>
<td>
<p>Success probability for the Binomial prior for
groups that are subject to constraints</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_alpha">alpha</code></td>
<td>
<p> First parameter of the Beta-Binomial prior, which is equivalent
to specifying a Beta(alpha,beta) prior on <code>prob</code>.</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_beta">beta</code></td>
<td>
<p> First parameter of the Beta-Binomial prior, which is equivalent
to specifying a Beta(alpha,beta) prior on <code>prob</code>.</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_alphaconstr">alphaconstr</code></td>
<td>
<p>Same as alpha for the groups that are subject to constraints</p>
</td></tr>
<tr><td><code id="bbPrior_+3A_betaconstr">betaconstr</code></td>
<td>
<p>Same as beta for the groups that are subject to constraints</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prior probability of the specified model
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mombf)
sel &lt;- c(TRUE,TRUE,FALSE,FALSE)
unifPrior(sel,logscale=FALSE)
binomPrior(sel,prob=.5,logscale=FALSE)
bbPrior(sel,alpha=1,beta=1,logscale=FALSE)
</code></pre>

<hr>
<h2 id='bestBIC'>
Model with best AIC, BIC, EBIC or other general information criteria (getIC)
</h2><span id='topic+bestAIC'></span><span id='topic+bestBIC'></span><span id='topic+bestEBIC'></span><span id='topic+bestIC'></span>

<h3>Description</h3>

<p>Search for the regression model attaining the best value of the
specified information criterion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  bestAIC(...)

  bestBIC(...)

  bestEBIC(...)

  bestIC(..., penalty)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bestBIC_+3A_...">...</code></td>
<td>
<p>Arguments passed on to <code>modelSelection</code>. The first and
main argument is a model formula, see the examples</p>
</td></tr>
<tr><td><code id="bestBIC_+3A_penalty">penalty</code></td>
<td>
<p>General information penalty. For example, since the AIC
penalty is 2, bestIC(...,penalty=2) is the same as bestAIC(...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on the information criteria see help(getBIC).
</p>
<p>Function modelSelection returns the log posterior probability of a
model, postProb = log(m_k) + log(prior k), where m_k is the marginal
likelihood of the model and prior k its prior probability.
</p>
<p>When running function modelSelection with priorCoef=bicprior()
and priorDelta=modelunifprior(), the BIC approximation is used for
m_k, that is
</p>
<p>log(m_k) = L_k - 0.5 * p_k log(n)
</p>
<p>and all models are equally likely a priori, log(prior k)= p
log(1/2). Then the BIC can be easily recovered
</p>
<p>BIC_k= -2 * [postProb + p log(2)]
</p>
<p>When using priorCoef=bicprior() and priorDelta=modelbbprior(),
log(prior k)= - log(p+1) - log(p choose p_k), hence
</p>
<p>EBIC_k= -2 * [postProb + log(p+1)].
</p>


<h3>Value</h3>

<p>Object of class <code>icfit</code>. Use (coef, summary,
confint, predict) to get inference for the top model,
and <code>help(icfit-class)</code> for more details on the returned object.
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelSelection">modelSelection</a></code> to perform model selection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*3),nrow=100,ncol=3)
theta &lt;- matrix(c(1,1,0),ncol=1)
y &lt;- x %*% theta + rnorm(100)
ybin &lt;- y&gt;0

#BIC for all models (the intercept is also selected in/out)
fit= bestBIC(y ~ x[,1] + x[,2])
fit

#Same, but setting the BIC's log(n) penalty manually
#change the penalty for other General Info Criteria
#n= nrow(x)
#fit= bestIC(y ~ x[,1] + x[,2], penalty=log(n))

summary(fit) #usual GLM summary

coef(fit) #MLE under top model

#confint(fit) #conf int under top model (requires MASS package)



</code></pre>

<hr>
<h2 id='bfnormmix'> Number of Normal mixture components under Normal-IW and
Non-local priors</h2><span id='topic+bfnormmix'></span>

<h3>Description</h3>

<p>Posterior sampling and Bayesian model selection to choose the number
of components k in multivariate Normal mixtures.
</p>
<p><code>bfnormmix</code> computes posterior probabilities under non-local
MOM-IW-Dir(q) priors, and also for local Normal-IW-Dir(q.niw) priors.
It also computes posterior probabilities on cluster occupancy
and posterior samples on the model parameters for several k.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bfnormmix(x, k=1:2, mu0=rep(0,ncol(x)), g, nu0, S0, q=3, q.niw=1,
B=10^4, burnin= round(B/10), logscale=TRUE, returndraws=TRUE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bfnormmix_+3A_x">x</code></td>
<td>
<p>n x p input data matrix</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_k">k</code></td>
<td>
<p>Number of components</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_mu0">mu0</code></td>
<td>
<p>Prior on mu[j] is N(mu0,g Sigma[j])</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_g">g</code></td>
<td>
<p>Prior on mu[j] is N(mu0,g Sigma[j]). This is a critical MOM-IW prior
parameter that specifies the separation between
components deemed practically relevant. It defaults to assigning 0.95
prior probability to any pair of mu's giving a bimodal mixture, see details</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_s0">S0</code></td>
<td>
<p>Prior on Sigma[j] is IW(Sigma_j; nu0, S0)</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_nu0">nu0</code></td>
<td>
<p>Prior on Sigma[j] is IW(Sigma_j; nu0, S0)</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_q">q</code></td>
<td>
<p>Prior parameter in MOM-IW-Dir(q) prior</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_q.niw">q.niw</code></td>
<td>
<p>Prior parameter in Normal-IW-Dir(q.niw) prior</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_b">B</code></td>
<td>
<p>Number of MCMC iterations</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_burnin">burnin</code></td>
<td>
<p>Number of burn-in iterations</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_logscale">logscale</code></td>
<td>
<p>If set to TRUE then log-Bayes factors are returned</p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_returndraws">returndraws</code></td>
<td>
<p>If set to <code>TRUE</code> the MCMC posterior draws under
the Normal-IW-Dir prior are returned for all <code>k</code></p>
</td></tr>
<tr><td><code id="bfnormmix_+3A_verbose">verbose</code></td>
<td>
<p>Set to <code>TRUE</code> to print iteration progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood is
</p>
<p>p(x[i,] | mu,Sigma,eta)= sum_j eta_j N(x[i,]; mu_j,Sigma_j)
</p>
<p>The Normal-IW-Dir prior is
</p>
<p>Dir(eta; q.niw) prod_j N(mu_j; mu0, g Sigma) IW(Sigma_j; nu0, S0)
</p>
<p>The MOM-IW-Dir prior is
</p>
<p style="text-align: center;"><code class="reqn">d(\mu,A) Dir(\eta; q) \prod_j N(\mu_j; \mu0, g \Sigma_j) IW(\Sigma_j; \nu_0, S0)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">d(\mu,A)= [\prod_{j&lt;l} (\mu_j-\mu_l)' A (\mu_j-\mu_l)]</code>
</p>

<p>and A is the average of <code class="reqn">\Sigma_1^{-1},...,\Sigma_k^{-1}</code>. Note that
one must have q&gt;1 for the MOM-IW-Dir to define a non-local prior.
</p>
<p>By default the prior parameter g is set such that
</p>
<p>P( (mu[j]-mu[l])' A (mu[j]-mu[l]) &lt; 4)= 0.05.
</p>
<p>The reasonale when Sigma[j]=Sigma[l] and eta[j]=eta[l]
then (mu[j]-mu[l])' A (mu[j]-mu[l])&gt;4 corresponds to a bimodal
density. That is, the default g focuses 0.95 prior prob on a degree of
separation between components giving rise to a bimodal mixture density.
</p>
<p><code>bfnormmix</code> computes posterior model probabilities under the
MOM-IW-Dir and Normal-IW-Dir priors using MCMC output. As described in
Fuquene, Steel and Rossell (2018) the estimate is based on the
posterior probability that one cluster is empty under each possible k.
</p>


<h3>Value</h3>

<p>A list with elements
</p>
<table>
<tr><td><code>k</code></td>
<td>
<p>Number of components</p>
</td></tr>
<tr><td><code>pp.momiw</code></td>
<td>
<p>Posterior probability of k components under a
MOM-IW-Dir(q) prior</p>
</td></tr>
<tr><td><code>pp.niw</code></td>
<td>
<p>Posterior probability of k components under a
Normal-IW-Dir(q.niw) prior</p>
</td></tr>
<tr><td><code>probempty</code></td>
<td>
<p>Posterior probability that any one cluster is empty under a
MOM-IW-Dir(q.niw) prior</p>
</td></tr>
<tr><td><code>bf.momiw</code></td>
<td>
<p>Bayes factor comparing 1 vs k components under a
MOM-IW-Dir(q) prior</p>
</td></tr>
<tr><td><code>logpen</code></td>
<td>
<p>log of the posterior mean of the MOM-IW-Dir(q) penalty term</p>
</td></tr>
<tr><td><code>logbf.niw</code></td>
<td>
<p>Bayes factor comparing 1 vs k components under a
Normal-IW-Dir(q.niw) prior</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p>Fuquene J., Steel M.F.J., Rossell D. On choosing mixture components via
non-local priors. 2018. arXiv
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*2),ncol=2)

bfnormmix(x=x,k=1:3)
</code></pre>

<hr>
<h2 id='cil'>Treatment effect estimation for linear models via Confounder Importance
Learning using non-local priors.</h2><span id='topic+cil'></span>

<h3>Description</h3>

<p>Treatment effect estimation for linear models in the presence of
multiple treatments and a potentially high-dimensional number of controls,
i.e. <code class="reqn">p \gg n</code> can be handled.
</p>
<p>Confounder Importance Learning (CIL) proposes an estimation framework where
the importance of the relationship between treatments and controls is
factored in into the establishment of prior inclusion probabilities for each
of these controls on the response model. This is combined with the use of
non-local priors to obtain BMA estimates and posterior model probabilities.
</p>
<p><code>cil</code> is built on <code>modelSelection</code> and produces objects of type
<code>cilfit</code>. Use <code>coef</code> and <code>postProb</code> to obtain treatment effect
point estimates and posterior model probabilities, respectively, on this
object class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cil(y, D, X, I = NULL, family = 'normal', familyD = 'normal',
  R = 1e4, Rinit = 500, th.search = 'EB', mod1 = 'lasso_bic',
  th.prior = 'unif', priorCoef, rho.min = NULL,
  th.range = NULL, max.mod = 2^20, lpen = 'lambda.1se',
  eps = 1e-10, bvs.fit0 = NULL, th.EP = NULL, center = TRUE, scale =
  TRUE, includevars, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cil_+3A_y">y</code></td>
<td>
<p>one-column matrix containing the observed responses. The response must
be continuous (currently the only type supported)</p>
</td></tr>
<tr><td><code id="cil_+3A_d">D</code></td>
<td>
<p>treatment matrix with numeric columns, continuous or discrete. Any finite
number of treatments are supported. If only one treatment is provided, supply
this object in the same format used for <code>y</code></p>
</td></tr>
<tr><td><code id="cil_+3A_x">X</code></td>
<td>
<p>matrix of controls with numeric columns, continuous or discrete. If only
one treatment is provided, supply this object in the same format used for <code>y</code></p>
</td></tr>
<tr><td><code id="cil_+3A_i">I</code></td>
<td>
<p>matrix with the desired interaction terms between <code>D</code> and
<code>X</code>. If not informed, i.e. supplied as the default <code>NULL</code>, this term
will not be included into the response model</p>
</td></tr>
<tr><td><code id="cil_+3A_family">family</code></td>
<td>
<p>Distribution of the outcome, e.g. 'normal', 'binomial' or
'poisson'. See <code>help</code>(modelSelection) for a full list of options</p>
</td></tr>
<tr><td><code id="cil_+3A_familyd">familyD</code></td>
<td>
<p>Distribution of the treatment(s). Only 'normal' or
'binomial' currently allowed</p>
</td></tr>
<tr><td><code id="cil_+3A_r">R</code></td>
<td>
<p>Number of MCMC iterations to be
run by <code>modelSelection</code> on each stage of CIL (see argument <code>niter</code>
therein)</p>
</td></tr>
<tr><td><code id="cil_+3A_rinit">Rinit</code></td>
<td>
<p>MCMC iterations to estimate marginal posterior
inclusion probabilities under a uniform model prior, needed for EP</p>
</td></tr>
<tr><td><code id="cil_+3A_th.search">th.search</code></td>
<td>
<p>method to estimate theta values in the marginal prior inclusion
probabilities of the CIL model. Options are: <code>EB</code> (Empirical Bayes, based
on maximum marginal likelihood) and <code>EP</code> (Expectation propagation
approximation)</p>
</td></tr>
<tr><td><code id="cil_+3A_mod1">mod1</code></td>
<td>
<p>method to estimate the feature parameters corresponding to the
influence of the controls on the treatments. Supported values for this
argument are 'ginv' (generalised pseudo-inverse), <code>lasso</code> (see
argument <code>lpen</code>), <code>lasso_bic</code> (default), and <code>ridge</code>)</p>
</td></tr>
<tr><td><code id="cil_+3A_th.prior">th.prior</code></td>
<td>
<p>prior associated to the thetas for the Empirical Bayes
estimation. Currently only <code>unif</code> (Uniform prior) is supported,
effectively making the EB approach the maximisation of the marginal likelihood</p>
</td></tr>
<tr><td><code id="cil_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior on the response model parameters, see <code>modelSelection</code></p>
</td></tr>
<tr><td><code id="cil_+3A_rho.min">rho.min</code></td>
<td>
<p>value of <code class="reqn">\rho</code> in (0, 1/2) employed in the prior probability
model of CIL. If left uninformed, i.e. supplied as the default <code>NULL</code>,
it will be set to <code class="reqn">1/p^2</code>, where p is the dimension of the response model.</p>
</td></tr>
<tr><td><code id="cil_+3A_th.range">th.range</code></td>
<td>
<p>sequence of values to be considered in the grid when searching
for points to initialise the search for the optimal theta parameters. If left
uninformed, the function will determine a computationally suitable grid
depending on the number of parameters to be estimated</p>
</td></tr>
<tr><td><code id="cil_+3A_max.mod">max.mod</code></td>
<td>
<p>Maximum number of models considered when computing the marginal
likelihood required by empirical Bayes.
If set to <code>Inf</code> all visited models by the enumeration/MCMC
are considered, but it might be computationally desirable to restrict this
number when the dimension of <code>D</code> and/or <code>X</code> is large</p>
</td></tr>
<tr><td><code id="cil_+3A_lpen">lpen</code></td>
<td>
<p>penalty type supplied to <code>glmnet</code> if <code>mod1</code> is set to
<code>lasso</code>. Default is <code>lambda.1se</code> (see documentation corresponding to
<code>glmnet</code> for options on how to set this parameter)</p>
</td></tr>
<tr><td><code id="cil_+3A_eps">eps</code></td>
<td>
<p>small scalar used to avoid round-offs to absolute zeroes or ones in
marginal prior inclusion probabilities.</p>
</td></tr>
<tr><td><code id="cil_+3A_bvs.fit0">bvs.fit0</code></td>
<td>
<p>object returned by <code>modelSelection</code> under <code class="reqn">\theta = 0</code>,
used as a model exploration tool to compute EB approximation on the thetas.
This argument is only supposed to be used in case of a second computation the
model on the same data where <code>th.search</code> has ben changed to <code>EB</code>,
in order to avoid repeating the computation of the initial
<code>modelSelection</code> fit. To use this argument, supply the object residing
in the slot <code>init.msfit</code> of a <code>cilfit</code>-class object.</p>
</td></tr>
<tr><td><code id="cil_+3A_th.ep">th.EP</code></td>
<td>
<p>Optimal theta values under the EP approximation, obtained in a
previous CIL run. This argument is only supposed to be used in case of
a second computation the model on the same data where <code>th.search</code>
has ben changed to <code>EB</code>, in order to save the cost of the EP search
to initialise the optimisation algorithm. To use this argument, supply the
object residing int the slot <code>th.hat</code> of a <code>cilfit</code>-class
object.</p>
</td></tr>
<tr><td><code id="cil_+3A_center">center</code></td>
<td>
<p>If <code>TRUE</code>, <code>y</code> and <code>x</code> are centered to have
zero mean. Dummy variables corresponding to factors are NOT centered</p>
</td></tr>
<tr><td><code id="cil_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, <code>y</code> and columns in <code>x</code> are
scaled to have variance=1. Dummy variables corresponding to factors are NOT scaled</p>
</td></tr>
<tr><td><code id="cil_+3A_includevars">includevars</code></td>
<td>
<p>Logical vector of length ncol(x) indicating variables
that should always be included in the model, i.e. variable selection is
not performed for these variables</p>
</td></tr>
<tr><td><code id="cil_+3A_verbose">verbose</code></td>
<td>
<p>Set <code>verbose==TRUE</code> to print iteration progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We estimate treatment effects for the features present in the treatment
matrix <code>D</code>. Features in <code>X</code>, which may or may not be causal
factors of the treatments of interest, only act as controls and, therefore,
are not used as inferential subjects.
</p>
<p>Confounder importance learning is a flexible treatment effect estimation
framework that essentially determines how the role of the influence of
<code>X</code> on <code>D</code> should affect their relationship with the response,
through establishing prior inclusion probabilities on the response model
for <code>y</code> according to said role. This is regulated through a hyper-
parameter theta that is set according to the method supplied to
<code>th.search</code>. While the <code>EB</code> option obtains a more precise estimate
a priori, the <code>EP</code> alternative achieves a reasonable approximation at a
fraction of the computational cost.
</p>
<p>See references for further details on implementation and computation.
</p>


<h3>Value</h3>

<p>Object of class <code>cilfit</code>, which extends a list with elements
</p>
<table>
<tr><td><code>cil.teff</code></td>
<td>
<p>BMA estimates, 0.95 intervals and posterior inclusion
probabilities for treatment effects in <code>D</code></p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>BMA inference for treatment effects and all other covariates</p>
</td></tr>
<tr><td><code>model.postprobs</code></td>
<td>
<p><code>matrix</code> returning the posterior model probabilities
computed in the CIL model</p>
</td></tr>
<tr><td><code>margpp</code></td>
<td>
<p><code>numeric</code> vector containing the estimated marginal
posterior inclusion probabilities of the featured treatments and controls</p>
</td></tr>
<tr><td><code>margprior</code></td>
<td>
<p>Marginal prior inclusion probabilities, as estimated by
CIL</p>
</td></tr>
<tr><td><code>margpp.unif</code></td>
<td>
<p>Marginal posterior inclusion probabilities that would
be obtained under a uniform model prior</p>
</td></tr>
<tr><td><code>theta.hat</code></td>
<td>
<p>Values used for the hyper-parameter theta, estimated according
to the argument <code>th.search</code> specified</p>
</td></tr>
<tr><td><code>treat.coefs</code></td>
<td>
<p>Estimated weights of the effect of the control variables
on each of the treatments, as estimated with the method specified in argument
<code>mod1</code></p>
</td></tr>
<tr><td><code>msfit</code></td>
<td>
<p>Object returned by <code>modelSelection</code> (of class <code>msfit</code>)
of the final model estimated by CIL.</p>
</td></tr>
<tr><td><code>theta.EP</code></td>
<td>
<p>Estimated values of theta using the EP algorithm. It coincides
with <code>theta.hat</code> if the argument <code>th.search</code> is set to <code>EB</code></p>
</td></tr>
<tr><td><code>init.msfit</code></td>
<td>
<p>Initial <code>msfit</code> object used to estimate the inital model
where all elements in theta are set to zero (used in the optimisation process
of this hyper-parameter)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Miquel Torrens
</p>


<h3>References</h3>

<p>Torrens i Dinares M., Papaspiliopoulos O., Rossell D. Confounder
importance learning for treatment effect inference.
https://arxiv.org/abs/2110.00314, 2021, 1&ndash;48.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+postProb">postProb</a></code> to obtain posterior model probabilities.
</p>
<p><code>coef</code> for inference on the treatment parameters.



</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate data
set.seed(1)
X &lt;- matrix(rnorm(100 * 50), nrow = 100, ncol = 50)
beta_y &lt;- matrix(c(rep(1, 6), rep(0, 44)), ncol = 1)
beta_d &lt;- matrix(c(rep(1, 6), rep(0, 44)), ncol = 1)
alpha &lt;- 1
d &lt;- X %*% beta_d + rnorm(100)
y &lt;- d * alpha + X %*% beta_y + rnorm(100)

# Confounder Importance Learning
fit1 &lt;- cil(y = y, D = d, X = X, th.search = 'EP')

# BMA for treatment effects
coef(fit1)

# BMA for all covariates
head(fit1$coef)

# Estimated prior inclusion prob
# vs. treatment regression coefficients
plotprior(fit1)

</code></pre>

<hr>
<h2 id='dalapl'> Density and random draws from the asymmetric Laplace distribution </h2><span id='topic+dalapl'></span><span id='topic+palapl'></span><span id='topic+ralapl'></span>

<h3>Description</h3>

<p><code>dalapl</code> evaluates the probability density function,
<code>palapl</code> the cumulative probability function
and <code>ralapl</code> generates random draws.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dalapl(x, th=0, scale=1, alpha=0, logscale=FALSE)

palapl(x, th=0, scale=1, alpha=0)

ralapl(n, th=0, scale=1, alpha=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dalapl_+3A_x">x</code></td>
<td>
<p>Vector of values at which to evaluate the pdf/cdf</p>
</td></tr>
<tr><td><code id="dalapl_+3A_n">n</code></td>
<td>
<p> Number of random draws</p>
</td></tr>
<tr><td><code id="dalapl_+3A_th">th</code></td>
<td>
<p> Location parameter (mode) </p>
</td></tr>
<tr><td><code id="dalapl_+3A_scale">scale</code></td>
<td>
<p> Scale parameter (proportional to variance)</p>
</td></tr>
<tr><td><code id="dalapl_+3A_alpha">alpha</code></td>
<td>
<p> Asymmetry parameter, must be between -1 and 1</p>
</td></tr>
<tr><td><code id="dalapl_+3A_logscale">logscale</code></td>
<td>
<p>If TRUE the log-pdf is returned</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For x&lt;=th the asymmetric Laplace pdf is
</p>
<p>0.5*exp(-abs(th-x)/(sqrt(scale)*(1+alpha)))/sqrt(scale)
</p>
<p>and for x&gt;th it is
</p>
<p>0.5*exp(-abs(th-x)/(sqrt(scale)*(1-alpha)))/sqrt(scale)
</p>


<h3>Value</h3>

<p><code>dalapl</code> returns the density function,
<code>palapl</code> the cumulative probability,
<code>ralapl</code> random draws.
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mombf)
e &lt;- ralapl(n=10^4, th=1, scale=2, alpha=0.5)
thseq &lt;- seq(min(e),max(e),length=1000)
hist(e, main='', breaks=30, prob=TRUE)
lines(thseq, dalapl(thseq, th=1, scale=2, alpha=0.5), col=2)
</code></pre>

<hr>
<h2 id='ddir'> Dirichlet density </h2><span id='topic+ddir'></span>

<h3>Description</h3>

<p>Evaluate the density of a Dirichlet distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddir(x, q, logscale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddir_+3A_x">x</code></td>
<td>
<p> Vector or matrix containing the value at which to evaluate
the density. If a matrix, the density is evaluated for each
row. Rows are renormalized to ensure they add up to 1</p>
</td></tr>
<tr><td><code id="ddir_+3A_q">q</code></td>
<td>
<p> Dirichlet parameters. Must have the same length as
<code>ncol(x)</code>, or length 1 (in which case a symmetric Dirichlet
density is valuated)</p>
</td></tr>
<tr><td><code id="ddir_+3A_logscale">logscale</code></td>
<td>
<p> For <code>logscale==TRUE</code>, <code>dimom</code> returns the
natural log of the prior density</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Density of a Dirichlet(q) distribution evaluated at each row of <code>x</code>
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mombf)
x= matrix(c(1/3,2/3,.5,.5),nrow=2,byrow=TRUE)
ddir(x,q=2)
</code></pre>

<hr>
<h2 id='diwish'>Density for Inverse Wishart distribution</h2><span id='topic+diwish'></span>

<h3>Description</h3>

<p><code>diwish</code> returns the density for the inverse Wishart(nu,S)
evaluated at Sigma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diwish(Sigma, nu, S, logscale=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diwish_+3A_sigma">Sigma</code></td>
<td>
<p>Positive-definite matrix</p>
</td></tr>
<tr><td><code id="diwish_+3A_nu">nu</code></td>
<td>
<p> Degrees of freedom of the inverse Wishart</p>
</td></tr>
<tr><td><code id="diwish_+3A_s">S</code></td>
<td>
<p> Scale matrix of the inverse Wishart</p>
</td></tr>
<tr><td><code id="diwish_+3A_logscale">logscale</code></td>
<td>
<p> If <code>logscale==TRUE</code> the log-density is returned</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Inverse Wishart(nu,S) density evaluated at Sigma
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>See Also</h3>

 <p><code><a href="#topic+dpostNIW">dpostNIW</a></code> for the Normal-IW posterior density</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mombf)
Sigma= matrix(c(2,1,1,2),nrow=2)
diwish(Sigma,nu=4,S=diag(2))
</code></pre>

<hr>
<h2 id='dmom'> Non-local prior density, cdf and quantile functions. </h2><span id='topic+dmom'></span><span id='topic+dimom'></span><span id='topic+pmom'></span><span id='topic+pimom'></span><span id='topic+qmom'></span><span id='topic+qimom'></span><span id='topic+demom'></span><span id='topic+demom-methods'></span><span id='topic+demom+2Cdata.frame-method'></span><span id='topic+demom+2Cmatrix-method'></span><span id='topic+demom+2Cvector-method'></span><span id='topic+pemom'></span><span id='topic+dmomigmarg'></span><span id='topic+pmomigmarg'></span><span id='topic+demomigmarg'></span><span id='topic+pemomigmarg'></span>

<h3>Description</h3>

<p><code>dmom</code>, <code>dimom</code> and <code>demom</code> return the density for the
moment, inverse moment and exponential moment priors.
<code>pmom</code>, <code>pimom</code> and <code>pemom</code> return the distribution function for the univariate
moment, inverse moment and exponential moment priors (respectively).
<code>qmom</code> and <code>qimom</code> return the quantiles for the univariate
moment and inverse moment priors.
<code>dmomigmarg</code> returns the marginal density implied by a
MOM(x;tau*phi)*Invgamma(phi;a/2,b/2), <code>pmomigmarg</code> its cdf.
Analogously <code>demomigmarg</code> and <code>demomigmarg</code> for
eMOM(x;tau*phi)*Invgamma(phi;a/2,b/2)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmom(x, tau, a.tau, b.tau, phi=1, r=1, V1, baseDensity='normal', nu=3,
logscale=FALSE, penalty='product')
dimom(x, tau=1, phi=1, V1, logscale=FALSE, penalty='product')
demom(x, tau, a.tau, b.tau, phi=1, logscale=FALSE)

pmom(q, V1 = 1, tau = 1)
pimom(q, V1 = 1, tau = 1, nu = 1)
pemom(q, tau, a.tau, b.tau)

qmom(p, V1 = 1, tau = 1)
qimom(p, V1 = 1, tau = 1, nu = 1)

dmomigmarg(x,tau,a,b,logscale=FALSE)
pmomigmarg(x,tau,a,b)

demomigmarg(x,tau,a,b,logscale=FALSE)
pemomigmarg(x,tau,a,b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dmom_+3A_x">x</code></td>
<td>
<p> In the univariate setting, <code>x</code> is a vector with the
values at which to evaluate the density. In the multivariate setting
it is a matrix with an observation in each row.</p>
</td></tr>
<tr><td><code id="dmom_+3A_q">q</code></td>
<td>
<p> Vector of quantiles.</p>
</td></tr>
<tr><td><code id="dmom_+3A_p">p</code></td>
<td>
<p> Vector of probabilities.</p>
</td></tr>
<tr><td><code id="dmom_+3A_v1">V1</code></td>
<td>
<p> Scale matrix (ignored if <code>penalty=='product'</code>). Defaults to 1 in univariate setting and
the identity matrix in the multivariate setting. </p>
</td></tr>
<tr><td><code id="dmom_+3A_tau">tau</code></td>
<td>
<p> Prior dispersion parameter is <code>tau*phi</code>. See
details. </p>
</td></tr>
<tr><td><code id="dmom_+3A_a.tau">a.tau</code></td>
<td>
<p>If <code>tau</code> is left missing, an Inverse Gamma(a.tau/2,b.tau/2)
is placed on <code>tau</code>. In this case <code>dmom</code> and <code>demom</code> return the density
marginalized with respect to <code>tau</code>.</p>
</td></tr>
<tr><td><code id="dmom_+3A_b.tau">b.tau</code></td>
<td>
<p>See <code>a.tau</code>.</p>
</td></tr>
<tr><td><code id="dmom_+3A_phi">phi</code></td>
<td>
<p> Prior dispersion parameter is <code>tau*phi</code>. See
details. </p>
</td></tr>
<tr><td><code id="dmom_+3A_r">r</code></td>
<td>
<p>Prior power parameter for MOM prior is <code>2*r</code></p>
</td></tr>
<tr><td><code id="dmom_+3A_basedensity">baseDensity</code></td>
<td>
<p>For <code>baseDensity=='normal'</code> a Normal MOM prior
is used, for <code>baseDensity=='laplace'</code> a Laplace MOM prior,
for <code>baseDensity=='t'</code> a T MOM prior with <code>nu</code>
degrees of freedom is used.</p>
</td></tr>
<tr><td><code id="dmom_+3A_nu">nu</code></td>
<td>
<p> Prior parameter indicating the degrees of freedom for the
quadratic T MOM and iMOM prior densities. The
tails of the inverse moment prior are proportional to the tails of a
multivariate T with <code>nu</code> degrees of freedom.</p>
</td></tr>
<tr><td><code id="dmom_+3A_penalty">penalty</code></td>
<td>
<p><code>penalty=='product'</code> indicates that product MOM/iMOM should
be used. <code>penalty=='quadratic'</code> indicates quadratic iMOM. See Details.</p>
</td></tr>
<tr><td><code id="dmom_+3A_logscale">logscale</code></td>
<td>
<p> For <code>logscale==TRUE</code>, <code>dimom</code> returns the
natural log of the prior density.</p>
</td></tr>
<tr><td><code id="dmom_+3A_a">a</code></td>
<td>
<p>The marginal prior on phi is IG(a/2,b/2)</p>
</td></tr>
<tr><td><code id="dmom_+3A_b">b</code></td>
<td>
<p>The marginal prior on phi is IG(a/2,b/2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>type=='quadratic'</code> the density is as follows.
Define the quadratic form q(theta)= (theta-theta0)' *
solve(V1) * (theta-theta0) / (tau*phi).
The normal moment prior density is proportional to
q(theta)*dmvnorm(theta,theta0,tau*phi*V1).
The T moment prior is proportional to
q(theta)*dmvt(theta,theta0,tau*phi*V1,df=nu).
The inverse moment prior density is proportional to
<code>q(theta)^(-(nu+d)/2) * exp(-1/q(theta))</code>.
</p>
<p>pmom, pimom and qimom use closed-form expressions, while qmom uses
nlminb to find quantiles numerically.
Only the univariate version is implemented. In this case the product
MOM is equivalent to the quadratic MOM. The same happens for the
iMOM.
</p>
<p><code>dmomigmarg</code> returns the marginal density
</p>
<p>p(x)= int MOM(x;0,tau*phi) IG(phi;a/2,b/2) dphi
</p>


<h3>Value</h3>

<p>Prior density, cumulative distribution function or quantile.
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p>Johnson V.E., Rossell D. Non-Local Prior Densities for Default
Bayesian Hypothesis Tests. Journal of the Royal Statistical Society B,
2010, 72, 143-170.
</p>
<p>Johnson V.E., Rossell D. Bayesian model selection in high-dimensional
settings. Journal of the American Statistical Assocation, 2012, 107,
649-660
</p>
<p>See http://rosselldavid.googlepages.com for technical
reports. </p>


<h3>Examples</h3>

<pre><code class='language-R'>#evaluate and plot the moment and inverse moment priors
library(mombf)
tau &lt;- 1
thseq &lt;- seq(-3,3,length=1000)
plot(thseq,dmom(thseq,tau=tau),type='l',ylab='Prior density')
lines(thseq,dimom(thseq,tau=tau),lty=2,col=2)
</code></pre>

<hr>
<h2 id='dpostNIW'>Posterior Normal-IWishart density</h2><span id='topic+dpostNIW'></span><span id='topic+rpostNIW'></span>

<h3>Description</h3>

<p>dpostNIW evalutes the posterior Normal-IWishart density at (mu,Sigma).
rpostNIW draws independent samples.
This posterior corresponds to a Normal model for the data
</p>
<p>x[i,] ~ N(mu,Sigma) iid i=1,...,n
</p>
<p>under conjugate priors
</p>
<p>mu | Sigma ~ N(mu0, g Sigma)
Sigma      ~ IW(nu0, S0)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpostNIW(mu, Sigma, x, g=1, mu0=rep(0,length(mu)), nu0=nrow(Sigma)+1, S0,
  logscale=FALSE)

rpostNIW(n, x, g=1, mu0=0, nu0, S0, precision=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpostNIW_+3A_mu">mu</code></td>
<td>
<p>Vector of length p</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_sigma">Sigma</code></td>
<td>
<p>p x p positive-definite covariance matrix</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_x">x</code></td>
<td>
<p>n x p data matrix (individuals in rows, variables in columns)</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_g">g</code></td>
<td>
<p>Prior dispersion parameter for mu</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_mu0">mu0</code></td>
<td>
<p>Prior mean for mu</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_nu0">nu0</code></td>
<td>
<p>Prior degrees of freedom for Sigma</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_s0">S0</code></td>
<td>
<p>Prior scale matrix for Sigma, by default set to I/nu0</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_logscale">logscale</code></td>
<td>
<p>set to TRUE to get the log-posterior density</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_n">n</code></td>
<td>
<p>Number of samples to draw</p>
</td></tr>
<tr><td><code id="dpostNIW_+3A_precision">precision</code></td>
<td>
<p>If set to <code>TRUE</code>, samples from the precision
matrix (inverse of Sigma) are returned instead</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dpostNIW</code> returns the Normal-IW posterior density evaluated at
(mu,Sigma).
</p>
<p><code>rpostNIW</code> returns a list with two elements. The first element are
posterior draws for the mean. The second element are posterior draws for
the covariance (or its inverse if <code>precision==TRUE</code>). Only
lower-diagonal elements are returned (<code>Sigma[lower.tri(Sigma,diag=TRUE)]</code>).
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>See Also</h3>

 <p><code><a href="#topic+diwish">diwish</a></code> for the inverse Wishart prior density,
<code><a href="#topic+marginalNIW">marginalNIW</a></code> for the integrated likelihood under a
Normal-IW prior</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data
x= matrix(rnorm(100),ncol=2)
#Evaluate posterior at data-generating truth
mu= c(0,0)
Sigma= diag(2)
dpostNIW(mu,Sigma,x=x,g=1,nu0=4,log=FALSE)
</code></pre>

<hr>
<h2 id='eprod'> Expectation of a product of powers of Normal or T random
variables </h2><span id='topic+eprod'></span>

<h3>Description</h3>

<p>Compute the mean of prod(x)^power when x follows T_dof(mu,sigma)
distribution (dof= -1 for multivariate Normal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eprod(m, S, power = 1, dof = -1) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eprod_+3A_m">m</code></td>
<td>
<p>Location parameter</p>
</td></tr>
<tr><td><code id="eprod_+3A_s">S</code></td>
<td>
<p>Scale matrix. For multivariate T with dof&gt;2 the covariance is
S*dof/(dof-2). For the multivariate Normal the covariance is S.</p>
</td></tr>
<tr><td><code id="eprod_+3A_power">power</code></td>
<td>
<p>Power that the product is raised to</p>
</td></tr>
<tr><td><code id="eprod_+3A_dof">dof</code></td>
<td>
<p>Degrees of freedom of the multivariate T. Set to -1 for the
multivariate Normal.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation is based on the computationally efficient approach by Kan (2008).
</p>


<h3>Value</h3>

<p>Expectation of the above-mentioned product
</p>


<h3>Author(s)</h3>

<p> John Cook </p>


<h3>References</h3>

<p>Kan R. From moments of sum to moments of product. Journal of
Multivariate Analysis 99 (2008), 542-554.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Check easy independence case
m &lt;- c(0,3); S &lt;- matrix(c(2,0,0,1),ncol=2)

eprod(m, S, power=2)

(m[1]^2+S[1][1])*(m[2]^2+S[2][2])
</code></pre>

<hr>
<h2 id='getBIC'>
Obtain AIC, BIC, EBIC or other general information criteria (getIC)
</h2><span id='topic+getAIC'></span><span id='topic+getAIC-methods'></span><span id='topic+getAIC+2Cmsfit-method'></span><span id='topic+getBIC'></span><span id='topic+getBIC-methods'></span><span id='topic+getBIC+2Cmsfit-method'></span><span id='topic+getEBIC'></span><span id='topic+getEBIC-methods'></span><span id='topic+getEBIC+2Cmsfit-method'></span><span id='topic+getIC'></span><span id='topic+getIC-methods'></span><span id='topic+getIC+2Cmsfit-method'></span>

<h3>Description</h3>

<p>Extract information criteria from an msfit object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  getAIC(object)

  getBIC(object)

  getEBIC(object)

  getIC(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBIC_+3A_object">object</code></td>
<td>
<p>Object of class msfit returned by <code>modelSelection</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let p be the total number of parameters and n the sample size. The BIC of a model k with p_k
parameters is
</p>
<p>- 2 L_k + p_k log(n)
</p>
<p>the AIC is
</p>
<p>- 2 L_k + p_k 2
</p>
<p>the EBIC is
</p>
<p>- 2 L_k + p_k log(n) + 2 log(p choose p_k)
</p>
<p>and a general information criterion with a given model size penalty
</p>
<p>- 2 L_k + p_k penalty
</p>
<p>For getBIC() to work, object must be the result returned by
modelSelection setting priorCoef=bic() and priorDelta=modelunifprior()
</p>
<p>For getEBIC() it is priorCoef=bic() and priorDelta=modelbbprior()
</p>
<p>For getAIC() it is priorCoef=aic() and priorDelta=modelunifprior()
</p>
<p>For getIC() it is priorCoef=ic() and priorDelta=modelunifprior()
</p>
<p>Function modelSelection returns the log posterior probability of a
model, postProb = log(m_k) + log(prior k), where m_k is the marginal
likelihood of the model and prior k its prior probability.
</p>
<p>When running function modelSelection with priorCoef=bicprior()
and priorDelta=modelunifprior(), the BIC approximation is used for
m_k, that is
</p>
<p>log(m_k) = L_k - 0.5 * p_k log(n)
</p>
<p>and all models are equally likely a priori, log(prior k)= p
log(1/2). Then the BIC can be easily recovered
</p>
<p>BIC_k= -2 * [postProb + p log(2)]
</p>
<p>When using priorCoef=bicprior() and priorDelta=modelbbprior(),
log(prior k)= - log(p+1) - log(p choose p_k), hence
</p>
<p>EBIC_k= -2 * [postProb + log(p+1)].
</p>


<h3>Value</h3>

<p>BIC or EBIC values for all models enumerated / visited by modelSelection
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelSelection">modelSelection</a></code> to perform model selection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*3),nrow=100,ncol=3)
theta &lt;- matrix(c(1,1,0),ncol=1)
y &lt;- x %*% theta + rnorm(100)
ybin &lt;- y&gt;0

#Obtain BIC
ms= modelSelection(ybin, x=x, priorCoef=bicprior(),
priorDelta=modelunifprior(), family='binomial')
getBIC(ms)

#Obtain EBIC
ms2= modelSelection(ybin, x=x, priorCoef=bicprior(),
priorDelta=modelbbprior(), family='binomial')
getEBIC(ms2)

</code></pre>

<hr>
<h2 id='hald'>Hald Data</h2><span id='topic+hald'></span><span id='topic+x.hald'></span><span id='topic+y.hald'></span>

<h3>Description</h3>

<p>Montgomery and Peck (1982) illustrated variable selection techniques on the Hald cement data and gave several references to other analysis. The response variable <em>y</em> is the <em>heat evolved</em> in a cement mix. The four explanatory variables are ingredients of the mix, i.e., x1: <em>tricalcium aluminate</em>, x2: <em>tricalcium silicate</em>, x3: <em>tetracalcium alumino ferrite</em>, x4: <em>dicalcium silicate</em>. An important feature of these data is that the variables x1 and x3 are highly correlated (corr(x1,x3)=-0.824), as well as the variables x2 and x4 (with corr(x2,x4)=-0.975). Thus we should expect any subset of (x1,x2,x3,x4) that includes one variable from highly correlated pair to do as any subset that also includes the other member.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hald)
</code></pre>


<h3>Format</h3>

<p><code>hald</code> is a matrix with 13 observations (rows) and 5 variables (columns), the first column is the dependent variable. <code>y.hald</code> and <code>x.hald</code> are also availables.
</p>


<h3>Source</h3>

<p>Montgomery, D.C., Peck, E.A. (1982) 
<em>Introduction to linear regression analysis,</em>
John Wiley, New York.
</p>

<hr>
<h2 id='icfit-class'>Class &quot;icfit&quot;</h2><span id='topic+icfit-class'></span><span id='topic+icfit'></span><span id='topic+show+2Cicfit-method'></span><span id='topic+icfit.coef'></span><span id='topic+icfit.predict'></span><span id='topic+icfit.summary'></span>

<h3>Description</h3>

<p>Stores the output of the search for the model with best information
criterion value, e.g. produced by <code>bestBIC</code>, <code>bestBIC</code>,
<code>bestAIC</code> or <code>bestIC</code>.
The class extends a list, so all usual methods for lists also work for
<code>icfit</code> objects, e.g. accessing elements, retrieving names etc.
</p>
<p>Methods are provided to extract coefficients, predictions, confidence
intervals and summary information about the best model.
</p>


<h3>Objects from the Class</h3>

<p>icfit objects are automatically created by a call to
<code>bestBIC</code> or similar.
</p>


<h3>Slots</h3>

<p>The class extends a list with elements:
</p>

<dl>
<dt>topmodel</dt><dd><p>names of the variables in the top model</p>
</dd>
<dt>topmodel.fit</dt><dd><p>top model as fitted by glm</p>
</dd>
<dt>models</dt><dd><p>data frame with the information criterion for all models
(when enumeration is feasible) or those visited by an MCMC model
search in modelSelection (when enumeration is not feasible)</p>
</dd>
<dt>varnames</dt><dd><p>the names of all variables in the design matrix</p>
</dd>
<dt>msfit</dt><dd><p>Output of modelSelection (used to search the top model)</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p>glm fit for the top model</p>
</dd>
<dt>confint</dt><dd><p>Confidence intervals under the top model</p>
</dd>
<dt>predict</dt><dd><p>Predictions for the top model (predict.glm)</p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "icfit")</code>: Displays general information about the object. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+bestBIC">bestBIC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("icfit")
</code></pre>

<hr>
<h2 id='icov'> Extract estimated inverse covariance </h2><span id='topic+icov'></span>

<h3>Description</h3>

<p>Extract the estimated inverse covariance from an <code>msfit_ggm</code>
object.
</p>
<p>Bayesian model averaging is used, optionally entries with posterior
probability of being non-zero below a threshold are set to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
icov(fit, threshold) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="icov_+3A_fit">fit</code></td>
<td>
<p>Object of class <code>msfit_ggm</code>, returned by
<code>modelSelectionGGM</code></p>
</td></tr>
<tr><td><code id="icov_+3A_threshold">threshold</code></td>
<td>
<p>Entries with posterior probability of being non-zero
below threshold are set to 0. If missing this argument is ignored and 
no entries are set to exact zeroes. When the goal is to identify
zeroes, a sensible default is <code>threshold=0.95</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inverse covariance is obtained via Bayesian model averaging, using
posterior samples of Omega. When <code>threshold</code> is specified,
entries in the BMA estimate are set to zero, which may result in a non
positive-definite matrix.
</p>


<h3>Value</h3>

<p>Estimated inverse covariance matrix.
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>See Also</h3>

<p><code><a href="#topic+modelSelectionGGM">modelSelectionGGM</a></code>, 
<code>coef.msfit_ggm</code> for Bayesian model averaging estimates and
intervals. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See modelSelectionGGM
</code></pre>

<hr>
<h2 id='localnulltest'> Local variable selection </h2><span id='topic+localnulltest'></span><span id='topic+localnulltest_fda'></span><span id='topic+localnulltest_givenknots'></span><span id='topic+localnulltest_fda_givenknots'></span>

<h3>Description</h3>

<p>Learn whether covariate effects are zero at given coordinates using
Bayesian model selection or information criteria.
</p>
<p>Use <code>coef</code> to extract estimates and posterior
probabilities for local effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
localnulltest(y, x, z, x.adjust, localgridsize=100, localgrid,
nbaseknots=20, nlocalknots=c(5,10,15), basedegree=3, cutdegree=0,
usecutbasis=TRUE, priorCoef=normalidprior(taustd=1),
priorGroup=normalidprior(taustd=1), priorDelta=modelbbprior(),
mc.cores=min(4,length(nlocalknots)), return.mcmc=FALSE, verbose=FALSE,
...)

localnulltest_fda(y, x, z, x.adjust, function_id,
Sigma='AR/MA', localgridsize=100, localgrid, nbaseknots=20,
nlocalknots=c(5,10,15), basedegree=3, cutdegree=0, usecutbasis=TRUE,
priorCoef=momprior(), priorGroup=groupmomprior(),
priorDelta=modelbbprior(), mc.cores=min(4,length(nlocalknots)),
return.mcmc=FALSE, verbose=FALSE, ...)

localnulltest_givenknots(y, x, z, x.adjust, localgridsize=100,
localgrid, nbaseknots=20, nlocalknots=10, basedegree=3, cutdegree=0,
usecutbasis=TRUE, priorCoef=normalidprior(taustd=1),
priorGroup=normalidprior(taustd=1), priorDelta=modelbbprior(),
verbose=FALSE, ...)

localnulltest_fda_givenknots(y, x, z, x.adjust, function_id,
Sigma='AR/MA', localgridsize=100, localgrid, nbaseknots=20,
nlocalknots=10, basedegree=3, cutdegree=0, usecutbasis=TRUE,
priorCoef=normalidprior(taustd=1), priorGroup=normalidprior(taustd=1),
priorDelta=modelbbprior(), verbose=FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="localnulltest_+3A_y">y</code></td>
<td>
<p>Vector with the outcome variable</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_x">x</code></td>
<td>
<p>Numerical matrix with covariate values</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_z">z</code></td>
<td>
<p>Matrix with d-dimensional coordinates (d&gt;=1$ for each entry in <code>y</code>, and d columns)</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_x.adjust">x.adjust</code></td>
<td>
<p>Optionally, further adjustment covariates to be included
in the model with no testing being performed</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_function_id">function_id</code></td>
<td>
<p>Function identifier. It is assumed that one observes
multiple functions over z, this is the identifier of each individual
function</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_sigma">Sigma</code></td>
<td>
<p>Error covariance. By default 'identity', other options are
'MA', 'AR' or 'AR/MA' (meaning that BIC is used to choose between MA
and AR). Alternatively the user can supply a function such that
<code>Sigma(z[i,],z[j,])</code> returns the within-function <code>cov(y[i,], y[j,])</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_localgridsize">localgridsize</code></td>
<td>
<p>Local test probabilities will be returned for a
grid of <code>z</code> values of size <code>localgridsize</code> for each dimension</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_localgrid">localgrid</code></td>
<td>
<p>Regions at which tests will be performed. Defaults to
dividing each <code>[min(z[,i]),  max(z[,i])]</code> into 10 equal
intervals. If provided, <code>localgrid</code> must be a list with one entry
for each <code>z[,i]</code>, containing a vector with the desired grid for that <code>z[,i]</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_nbaseknots">nbaseknots</code></td>
<td>
<p>Number of knots for the spline approximation to the
baseline effect of <code>x</code> on <code>y</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_nlocalknots">nlocalknots</code></td>
<td>
<p>Number of knots for the basis capturing the local effects</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_basedegree">basedegree</code></td>
<td>
<p>Degree of the spline approximation to the baseline</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_cutdegree">cutdegree</code></td>
<td>
<p>Degree of the cut spline basis used for testing</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_usecutbasis">usecutbasis</code></td>
<td>
<p>If <code>FALSE</code>, then the basis is not cut and a
standard spline basis is returned (not recommended unless you know
what you're doing)</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior on the coefficients, passed on to
<code>modelSelection</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_priorgroup">priorGroup</code></td>
<td>
<p>Prior on grouped coefficients, passed on to
<code>modelSelection</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_priordelta">priorDelta</code></td>
<td>
<p>Prior on the models, passed on to
<code>modelSelection</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_mc.cores">mc.cores</code></td>
<td>
<p>If package parallel is available on your system and
<code>nlocalknots</code> has several entries defining several resolution
levels, they will be run in parallel on <code>mc.cores</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_return.mcmc">return.mcmc</code></td>
<td>
<p>Set to <code>TRUE</code> to return the MCMC output from <code>modelSelection</code></p>
</td></tr>
<tr><td><code id="localnulltest_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> some progress information is printed</p>
</td></tr>
<tr><td><code id="localnulltest_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed on to <code>modelSelection</code>,
e.g. <code>family='binomial'</code> for logistic regression</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Local variable selection considers the model
</p>
<p style="text-align: center;"><code class="reqn">y_i= \beta_0(z_i) + sum_{j=1}^p \beta_j(z_i, x_i) + e_i</code>
</p>

<p><code class="reqn">\beta_0(z_i)</code> is the baseline mean
</p>
<p><code class="reqn">\beta_j(z_i,x_i)</code> is local effect of covariate j at coordinate z_i
</p>
<p><code class="reqn">e_i</code> a Gaussian error term assumed either independent or with a
covariance structure given by Sigma. If assuming independence it is
possible to consider alternatives to Gaussianity,
e.g. set <code>family='binomial'</code> for logistic regression
or <code>family='poisson'</code> for Poisson regression
</p>
<p>Note: a sum-to-zero type constraint is set on <code class="reqn">\beta_1(z_i,x_i)</code> so
that it defines a deviation from the baseline mean <code class="reqn">\beta_0(z_i)</code>
</p>
<p>We model <code class="reqn">\beta_0</code> using B-splines of degree <code>basedegree</code> with
<code>nbaseknots</code> knots.
We model <code class="reqn">\beta_j</code> using B-splines of degree <code>cutdegree</code> with
<code>nlocalknots</code>. Using <code>cutdegree=0</code> runs fastest is usually
gives similar inference than higher degrees, and is hence recommended
by default.
</p>


<h3>Value</h3>

<p>Object of class <code>localtest</code>, which extends a list with elements
</p>
<table>
<tr><td><code>covareffects</code></td>
<td>
<p>Estimated local covariate effects at different
<code>z</code> values, 0.95 posterior intervals and posterior probability
for the existence of an effect</p>
</td></tr>
<tr><td><code>pplocalgrid</code></td>
<td>
<p>Posterior probabilities for the existence of an
effect for regions of <code>z</code> values. Do not use these unless you
know what you're doing</p>
</td></tr>
<tr><td><code>covareffects.mcmc</code></td>
<td>
<p>MCMC output used to build covareffects. Only
returned if <code>return.mcmc=TRUE</code></p>
</td></tr>
<tr><td><code>ms</code></td>
<td>
<p>Objects of class <code>msfit</code> returned by <code>modelSelection</code></p>
</td></tr>
<tr><td><code>pp_localknots</code></td>
<td>
<p>Posterior probability for each resolution level
(value of <code>nlocalknots</code>)</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>Input parameter</p>
</td></tr>
<tr><td><code>nlocalknots</code></td>
<td>
<p>Input parameter</p>
</td></tr>
<tr><td><code>basedegree</code></td>
<td>
<p>Input parameter</p>
</td></tr>
<tr><td><code>cutdegree</code></td>
<td>
<p>Input parameter</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>Input parameters</p>
</td></tr>
<tr><td><code>regionbounds</code></td>
<td>
<p>List with region bounds defined by the local testing
knots at each resolution level</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Simulate outcome and 2 covariates
#Covariate 1 has local effect for z&gt;0
#Covariate 2 has no effect for any z

truemean= function(x,z) {
    ans= double(nrow(x))
    group1= (x[,1]==1)
    ans[group1]= ifelse(z[group1] &lt;=0, cos(z[group1]), 1)
    ans[!group1]= ifelse(z[!group1]&lt;=0, cos(z[!group1]), 1/(z[!group1]+1)^2)
    return(ans)
}

n= 1000
x1= rep(0:1,c(n/2,n/2))
x2= x1 + rnorm(n)
x= cbind(x1,x2)
z= runif(n,-3,3)
m= truemean(x,z)
y= truemean(x,z) + rnorm(n, 0, .5)

#Run localnulltest with 10 knots
fit0= localnulltest(y, x=x, z=z, nlocalknots=10, niter=1000)

#Estimated covariate effects and posterior probabilities
b= coef(fit0)
b

</code></pre>

<hr>
<h2 id='marginalNIW'>
Marginal likelihood under a multivariate Normal likelihood and a conjugate
Normal-inverse Wishart prior.
</h2><span id='topic+marginalNIW'></span><span id='topic+marginalNIW-methods'></span><span id='topic+marginalNIW+2Cmissing+2CANY+2Cmatrix+2Cnumeric+2Cmissing-method'></span><span id='topic+marginalNIW+2Cmatrix+2Cmissing+2Cmissing+2Cmissing+2Cmissing-method'></span><span id='topic+marginalNIW+2Cmatrix+2Cmissing+2Cmissing+2Cmissing+2Cvector-method'></span><span id='topic+marginalNIW+2Cmissing+2Clist+2Clist+2Cnumeric+2Cmissing-method'></span>

<h3>Description</h3>

<p>The argument <code>z</code> can be used to specify cluster allocations. If
left missing then the usual marginal likelihood is computed, else it is
computed conditional on the clusters (this is equivalent to the product
of marginal likelihoods across clusters)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>marginalNIW(x, xbar, samplecov, n, z, g,  mu0=rep(0,ncol(x)),
nu0=ncol(x)+4, S0, logscale=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="marginalNIW_+3A_x">x</code></td>
<td>
<p>Data matrix (individuals in rows, variables in
columns). Alternatively you can leave missing and specify
<code>xbar</code>, <code>samplecov</code> and <code>n</code> instead</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_xbar">xbar</code></td>
<td>
<p>Either a vector with column means of <code>x</code> or a list
where each element corresponds to the column means for each cluster</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_samplecov">samplecov</code></td>
<td>
<p>Either the sample covariance matrix <code>cov(x)</code> or
a list where each element contains the covariance for each clsuter</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_n">n</code></td>
<td>
<p>Either an integer indicating the sample size <code>nrow(x)</code>
or a vector indicating the cluster counts <code>table(z)</code></p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_z">z</code></td>
<td>
<p>Optional argument specifying cluster allocations</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_g">g</code></td>
<td>
<p>Prior dispersion parameter for mu</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_mu0">mu0</code></td>
<td>
<p>Prior mean for mu</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_nu0">nu0</code></td>
<td>
<p>Prior degrees of freedom for Sigma</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_s0">S0</code></td>
<td>
<p>Prior scale matrix for Sigma, by default set to I/nu0</p>
</td></tr>
<tr><td><code id="marginalNIW_+3A_logscale">logscale</code></td>
<td>
<p>set to TRUE to get the log-posterior density</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes
</p>
<p>p(x)= int p(x | mu,Sigma) p(mu,Sigma) dmu dSigma
</p>
<p>where p(x[i])= N(x[i]; mu,Sigma) iid i=1,...,n
</p>
<p>p(mu | Sigma)= N(mu; mu0, g Sigma)
p(Sigma)=     IW(Sigma; nu0, S0)
</p>


<h3>Value</h3>

<p>If <code>z</code> is missing the integrated likelihood under a Normal-IW
prior. If <code>z</code> was specified then the product of integrated
likelihoods across clusters
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dpostNIW">dpostNIW</a></code> for the posterior Normal-IW density.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data
x= matrix(rnorm(100),ncol=2)

#Integrated likelihood under correct model
marginalNIW(x,g=1,nu0=4,log=FALSE)

#Integrated likelihood under random cluster allocations
z= rep(1:2,each=25)
marginalNIW(x,z=z,g=1,nu0=4,log=FALSE)
</code></pre>

<hr>
<h2 id='mixturebf-class'>Class &quot;mixturebf&quot;</h2><span id='topic+mixturebf-class'></span><span id='topic+mixturebf'></span><span id='topic+show+2Cmixturebf-method'></span><span id='topic+coef.mixturebf'></span>

<h3>Description</h3>

<p>Stores the output of Bayesian model selection for mixture models,
e.g. as produced by function <code>bfnormmix</code>.
</p>
<p>Methods are provided for retrieving the posterior probability of a given
number of mixture components, posterior means and posterior samples of
the mixture model parameters.
</p>


<h3>Objects from the Class</h3>

<p>Typically objects are automatically created by a call to <code>bfnormmix</code>.
</p>


<h3>Slots</h3>

<p>The class has the following slots:
</p>

<dl>
<dt>postprob</dt><dd><p>data.frame containing posterior probabilities for
different numbers of components (k) and log-posterior probability of
a component being empty (contain no individuals)</p>
</dd>
<dt>p</dt><dd><p>Number of variables in the data to which the model was fit</p>
</dd>
<dt>n</dt><dd><p>Number of observations in the data to which the model was fit</p>
</dd>
<dt>priorpars</dt><dd><p>Prior parameters used when fitting the model</p>
</dd>
<dt>postpars</dt><dd><p>Posterior parameters for a 1-component mixture,
e.g. for a Normal mixture the posterior is N(mu1,Sigma/prec)
IW(nu1,S1)</p>
</dd>
<dt>mcmc</dt><dd><p>For each considered value of k, posterior samples for
the parameters of the k-component model are stored</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p>Computes posterior means for all parameters</p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "mixturebf")</code>: Displays general
information about the object. </p>
</dd>
<dt>postProb</dt><dd><p><code>signature(object = "mixturebf")</code>: Extracts
posterior model probabilities, Bayes factors and posterior
probability of a cluster being empty</p>
</dd>
<dt>postSamples</dt><dd><p><code>signature(object = "mixturebf")</code>: Extracts
posterior samples</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>References</h3>

<p>Fuquene J., Steel M.F.J., Rossell D. On choosing mixture components via
non-local priors. 2018. arXiv
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+bfnormmix">bfnormmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("mixturebf")
</code></pre>

<hr>
<h2 id='modelSelection'> Bayesian variable selection for linear models via non-local priors. </h2><span id='topic+modelSelection'></span><span id='topic+modelsearchBlockDiag'></span>

<h3>Description</h3>

<p>Bayesian model selection for linear, asymmetric linear,
median and quantile regression under
non-local or Zellner priors. p&gt;&gt;n can be handled.
</p>
<p>modelSelection enumerates all models when feasible
and uses a Gibbs scheme otherwise.
See <code>coef</code> and <code>coefByModel</code> for estimates and posterior
intervals of regression coefficients, and <code>rnlp</code> for posterior samples.
</p>
<p>modelsearchBlockDiag seeks the highest posterior
probability model using an iterative block search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelSelection(y, x, data, smoothterms, nknots=9,
groups=1:ncol(x), constraints, center=TRUE, scale=TRUE,
enumerate, includevars=rep(FALSE,ncol(x)), models,
maxvars, niter=5000, thinning=1,
burnin=round(niter/10), family='normal', priorCoef,
priorGroup, priorDelta=modelbbprior(1,1),
priorConstraints,
priorVar=igprior(.01,.01),
priorSkew=momprior(tau=0.348), phi, deltaini=rep(FALSE,ncol(x)),
initSearch='greedy', method='auto', adj.overdisp='intercept',
hess='asymp', optimMethod, optim_maxit, initpar='none', B=10^5,
XtXprecomp= ifelse(ncol(x)&lt;10^4,TRUE,FALSE), verbose=TRUE)

modelsearchBlockDiag(y, x, priorCoef=momprior(tau=0.348),
priorDelta=modelbbprior(1,1), priorVar=igprior(0.01,0.01),
blocksize=10, maxiter=10, maxvars=100, maxlogmargdrop=20,
maxenum=10, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelSelection_+3A_y">y</code></td>
<td>
<p>Either a formula with the regression equation or a vector with
observed responses. The response can be either continuous or of class
<code>Surv</code> (survival outcome). If <code>y</code> is a formula then <code>x</code>,
<code>groups</code> and <code>constraints</code> are automatically created</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_x">x</code></td>
<td>
<p>Design matrix with linear covariates for which we want to
assess if they have a linear effect on the response. Ignored if
<code>y</code> is a formula</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_data">data</code></td>
<td>
<p>If <code>y</code> is a formula then <code>data</code> should be a data
frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_smoothterms">smoothterms</code></td>
<td>
<p>Formula for non-linear covariates (cubic splines),
modelSelection assesses if the variable has no effect, linear or
non-linear effect. <code>smoothterms</code> can also be a design matrix or
data.frame containing linear terms, for each column modelSelection
creates a spline basis and tests no/linear/non-linear effects</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_nknots">nknots</code></td>
<td>
<p>Number of spline knots. For cubic splines the non-linear
basis adds knots-4 coefficients for each linear term, we recommend
setting <code>nknots</code> to a small/moderate value</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_groups">groups</code></td>
<td>
<p>If variables in <code>x</code> such be added/dropped in groups,
<code>groups</code> indicates the group that each variable corresponds to
(by default each variable goes in a separate group)</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_constraints">constraints</code></td>
<td>
<p>Constraints on the model space. List with length
equal to the number of groups;
if group[[i]]=c(j,k) then group i can only be in the model if groups j and k are also in the model</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_center">center</code></td>
<td>
<p>If <code>TRUE</code>, <code>y</code> and <code>x</code> are centered to have
zero mean. Dummy variables corresponding to factors are NOT centered</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, <code>y</code> and columns in <code>x</code> are
scaled to have variance=1. Dummy variables corresponding to factors are NOT scaled</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_enumerate">enumerate</code></td>
<td>
<p>Default is <code>TRUE</code> if there's less than 15 variable
groups. If <code>TRUE</code> all models with up to <code>maxvars</code> are
enumerated, else Gibbs sampling is used to explore the model space</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_includevars">includevars</code></td>
<td>
<p>Logical vector of length ncol(x) indicating variables
that should always be included in the model, i.e. variable selection is
not performed for these variables</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_models">models</code></td>
<td>
<p>Optional logical matrix indicating the models to be
enumerated with rows equal to the number of desired models and columns
to the number of variables in <code>x</code>. </p>
</td></tr>
<tr><td><code id="modelSelection_+3A_maxvars">maxvars</code></td>
<td>
<p>When <code>enumerate==TRUE</code> only models with up to maxvars variables
enumerated (defaults to all variables). In <code>modelsearchBlockDiag</code> a sequence of models
is defined from 1 up to <code>maxvars</code></p>
</td></tr>
<tr><td><code id="modelSelection_+3A_niter">niter</code></td>
<td>
<p>Number of Gibbs sampling iterations</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_thinning">thinning</code></td>
<td>
<p>MCMC thinning factor, i.e. only one out of each <code>thinning</code> iterations are reported. Defaults to thinning=1, i.e. no thinning</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_burnin">burnin</code></td>
<td>
<p>Number of burn-in MCMC iterations. Defaults to
<code>.1*niter</code>. Set to 0 for no burn-in</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_family">family</code></td>
<td>
<p>Family of parametric distribution. Use
'normal' for Normal errors, 'binomial' for logistic regression,
'poisson' for Poisson regression.
'twopiecenormal' for two-piece Normal,
'laplace' for Laplace errors and 'twopiecelaplace' for double
exponential.
For 'auto' the errors are assumed continuous and their distribution
is inferred from the data among
'normal', 'laplace', 'twopiecenormal' and 'twopiecelaplace'.
'laplace' corresponds to median regression and 'twopiecelaplace'
to quantile regression. See argument <code>priorSkew</code></p>
</td></tr>
<tr><td><code id="modelSelection_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior on coefficients, created
by <code>momprior</code>, <code>imomprior</code>, <code>emomprior</code> or
<code>zellnerprior</code>.
Prior dispersion is on coefficients/sqrt(scale) for Normal and
two-piece Normal, and on coefficients/sqrt(2*scale) for Laplace
and two-piece Laplace.</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_priorgroup">priorGroup</code></td>
<td>
<p>Prior on grouped coefficients (e.g. categorical
predictors with &gt;2 categories, splines). Created by
<code>groupmomprior</code>, <code>groupemomprior</code>,
<code>groupimomprior</code> or <code>groupzellnerprior</code></p>
</td></tr>
<tr><td><code id="modelSelection_+3A_priordelta">priorDelta</code></td>
<td>
<p>Prior on model space. Use <code>modelbbprior()</code>
for Beta-Binomial prior, <code>modelbinomprior(p)</code> for Binomial
prior with prior inclusion probability <code>p</code>,
<code>modelcomplexprior</code> for Complexity prior,
or <code>modelunifprior()</code> for Uniform prior</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_priorconstraints">priorConstraints</code></td>
<td>
<p>Prior distribution on the number of terms
subject to hierarchical constrains that are included in the model</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_priorvar">priorVar</code></td>
<td>
<p>Inverse gamma prior on scale parameter.
For Normal outcomes variance=scale, for Laplace outcomes
variance=2*scale</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_priorskew">priorSkew</code></td>
<td>
<p>Either a fixed value for tanh(alpha) where alpha is
the asymmetry parameter or a prior on tanh(alpha).
For <code>family=='twopiecelaplace'</code> setting alpha=a is equivalent
to performing quantile regression for the quantile (1+a)/2.
Ignored if <code>family</code> is 'normal' or 'laplace'.</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_phi">phi</code></td>
<td>
<p>The error variance in Gaussian models, typically this is
unknown and is left missing</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_deltaini">deltaini</code></td>
<td>
<p>Logical vector of length <code>ncol(x)</code> indicating which
coefficients should be initialized to be non-zero.
Defaults to all variables being excluded from the model</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_initsearch">initSearch</code></td>
<td>
<p>Algorithm to refine
<code>deltaini</code>. <code>initSearch=='greedy'</code> uses a greedy Gibbs
sampling search. <code>initSearch=='SCAD'</code> sets <code>deltaini</code> to the
non-zero elements in a SCAD fit with cross-validated regularization
parameter. <code>initSearch=='none'</code> leaves <code>deltaini</code> unmodified</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_method">method</code></td>
<td>
<p>Method to compute marginal likelihood.
<code>method=='Laplace'</code> for Laplace approx, <code>method=='ALA'</code>
for approximate Laplace approximation.
<code>method=='MC'</code> for Importance Sampling, <code>method=='Hybrid'</code>
for Hybrid Laplace-IS (only available for piMOM prior). See Details.</p>
</td></tr>
</table>
<p><code>method=='auto'</code> attempts to use exact calculations when
possible, otherwise ALA if available, otherwise Laplace approx.
</p>
<table>
<tr><td><code id="modelSelection_+3A_adj.overdisp">adj.overdisp</code></td>
<td>
<p>Only used when method=='ALA'. Over-dispersion
adjustment in models with fixed dispersion parameter, as in logistic
and Poisson regression. adj.overdisp='none' for no adjustment (not
recommended, particularly for Poisson
models). adj.overdisp='intercept' to estimate over-dispersion from the
intercept-only model, and adj.overdisp='residuals' from the Pearson
residuals of each model</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_hess">hess</code></td>
<td>
<p>Method to estimat the hessian in the Laplace approximation to the integrated
likelihood under Laplace or asymmetric Laplace errors. When
hess=='asymp' the asymptotic hessian is used, hess=='asympDiagAdj' a
diagonal adjustment is applied (see Rossell and Rubio for details).</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_optimmethod">optimMethod</code></td>
<td>
<p>Algorithm to maximize objective function when
method=='Laplace'. Leave unspecified or set optimMethod=='auto' for an
automatic choice. optimMethod=='LMA' uses modified
Newton-Raphson algorithm, 'CDA' coordinate descent algorithm</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_optim_maxit">optim_maxit</code></td>
<td>
<p>Maximum number of iterations when method=='Laplace'</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_initpar">initpar</code></td>
<td>
<p>Initial regression parameter values when finding the
posterior mode to approximate the integrated likelihood. 'none', 'MLE',
'L1', or a numeric vector with initial
values. 'auto': if p&lt;n/2 MLE is used, else L1 (regularization parameter set
via BIC)</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_b">B</code></td>
<td>
<p>Number of samples to use in Importance Sampling scheme. Ignored
if <code>method=='Laplace'</code></p>
</td></tr>
<tr><td><code id="modelSelection_+3A_xtxprecomp">XtXprecomp</code></td>
<td>
<p>Set to <code>TRUE</code> to pre-compute the Gram matrix x'x
upfront (saves time), to <code>FALSE</code> to compute and store elements
only as needed (saves memory)</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_verbose">verbose</code></td>
<td>
<p>Set <code>verbose==TRUE</code> to print iteration progress</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_blocksize">blocksize</code></td>
<td>
<p>Maximum number of variables in a block. Careful, the
cost of the algorithm is of order <code>2^blocksize</code></p>
</td></tr>
<tr><td><code id="modelSelection_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations, each iteration includes a
screening pass to add and subtract variables</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_maxlogmargdrop">maxlogmargdrop</code></td>
<td>
<p>Stop the sequence of models when the drop in log
p(y|model) is greater than <code>maxlogmargdrop</code>. This option avoids
spending unnecessary time exploring overly large models</p>
</td></tr>
<tr><td><code id="modelSelection_+3A_maxenum">maxenum</code></td>
<td>
<p>If the posterior mode found has less than <code>maxenum</code>
variables then do a full enumeration of all its submodels</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let delta be the vector indicating inclusion/exclusion of each
column of x in the model. The Gibbs algorithm sequentially samples from the
posterior of each element in delta conditional on all the remaining
elements in delta and the data.
To do this it is necessary to evaluate the marginal likelihood for any
given model. These have closed-form expression for the MOM prior, but
for models with &gt;15 variables these are expensive to compute and
Laplace approximations are used instead (for the residual variance a
log change of variables is used, which improves the approximation).
For other priors closed forms
are not available, so by default Laplace approximations are used.
For the iMOM prior we also implement a Hybrid Laplace-IS
which uses a Laplace approximation to evaluate the integral wrt beta
and integrates wrt phi (residual variance) numerically.
</p>
<p>It should be noted that Laplace approximations tend to under-estimate
the marginal densities when the MLE for some parameter is very close
to 0. That is, it tends to be conservative in the sense of excluding
more variables from the model than an exact calculation would.
</p>
<p>Finally, method=='plugin' provides a BIC-type approximation that is
faster than exact or Laplace methods, at the expense of some
accuracy. In non-sparse situations where models with many variables
have large posterior probability method=='plugin' can be substantially
faster.
</p>
<p>For more details on the methods used to compute marginal densities see
Johnson &amp; Rossell (2012).
</p>
<p><code>modelsearchBlockDiag</code> uses the block search method described in
Papaspiliopoulos &amp; Rossell. Briefly, spectral clustering is run on
X'X to cluster variables into blocks of <code>blocksize</code> and
subsequently the Coolblock algorithm is used to define a sequence
of models of increasing size. The exact integrated likelihood
is evaluated for all models in this path, the best model chosen,
and the scheme iteratively repeated to add and drop variables
until convergence.
</p>


<h3>Value</h3>

<p>Object of class <code>msfit</code>, which extends a list with elements
</p>
<table>
<tr><td><code>postSample</code></td>
<td>
<p><code>matrix</code> with posterior samples for the model
indicator. <code>postSample[i,j]==1</code>
indicates that variable j was included in the model in the MCMC
iteration i</p>
</td></tr>
<tr><td><code>postOther</code></td>
<td>
<p><code>postOther</code>
returns posterior samples for parameters other than the model
indicator, i.e. basically hyper-parameters.
If hyper-parameters were fixed in the model specification, <code>postOther</code> will be empty.</p>
</td></tr>
<tr><td><code>margpp</code></td>
<td>
<p>Marginal posterior probability for inclusion of each
covariate. This is computed by averaging marginal post prob for
inclusion in each Gibbs iteration, which is much more accurate than
simply taking <code>colMeans(postSample)</code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code>postMode</code></td>
<td>
<p>Model with highest posterior probability amongst all those visited</p>
</td></tr>
<tr><td><code>postModeProb</code></td>
<td>
<p>Unnormalized posterior prob of posterior mode (log scale)</p>
</td></tr>
<tr><td><code>postProb</code></td>
<td>
<p>Unnormalized posterior prob of each visited model (log
scale)</p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p>List with priors specified when calling <code>modelSelection</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p>Johnson V.E., Rossell D. Non-Local Prior Densities for Default
Bayesian Hypothesis Tests. Journal of the Royal Statistical Society B,
2010, 72, 143-170.
</p>
<p>Johnson V.E., Rossell D. Bayesian model selection in high-dimensional
settings. Journal of the American Statistical Association, 2012, 107,
649-660.
</p>
<p>Papaspiliopoulos O., Rossell, D. Scalable Bayesian variable selection
and model averaging under block orthogonal design. 2016
</p>
<p>Rossell D., Rubio F.J. Tractable Bayesian variable selection: beyond
normality. 2016
</p>


<h3>See Also</h3>

<p><code><a href="#topic+msfit-class">msfit-class</a></code> for details on the output.
<code><a href="#topic+postProb">postProb</a></code> to obtain posterior model probabilities.
<code>coef.msfit</code> for Bayesian model averaging estimates and
intervals. <code>predict.msfit</code> for BMA estimates and intervals
for user-supplied covariate values.
<code>plot.msfit</code> for an MCMC diagnostic plot showing estimated
marginal posterior inclusion probabilities vs. iteration number.
<code><a href="#topic+rnlp">rnlp</a></code> to obtain posterior samples for the coefficients.
<code><a href="#topic+nlpMarginal">nlpMarginal</a></code> to compute marginal densities for a given model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data
x &lt;- matrix(rnorm(100*3),nrow=100,ncol=3)
theta &lt;- matrix(c(1,1,0),ncol=1)
y &lt;- x %*% theta + rnorm(100)

#Specify prior parameters
priorCoef &lt;- momprior(tau=0.348)
priorDelta &lt;- modelunifprior()

#Alternative model space prior: 0.5 prior prob for including any covariate
priorDelta &lt;- modelbinomprior(p=0.5)

#Alternative: Beta-Binomial prior for model space
priorDelta &lt;- modelbbprior(alpha.p=1,beta.p=1)

#Model selection
fit1 &lt;- modelSelection(y=y, x=x, center=FALSE, scale=FALSE,
priorCoef=priorCoef, priorDelta=priorDelta)
postProb(fit1) #posterior model probabilities

fit1$margpp #posterior marginal inclusion prob

coef(fit1) #BMA estimates, 95% intervals, marginal post prob
</code></pre>

<hr>
<h2 id='modelSelectionGGM'> Bayesian variable selection for linear models via non-local priors. </h2><span id='topic+modelSelectionGGM'></span>

<h3>Description</h3>

<p>Bayesian model selection for linear, asymmetric linear,
median and quantile regression under
non-local or Zellner priors. p&gt;&gt;n can be handled.
</p>
<p>modelSelection enumerates all models when feasible
and uses a Gibbs scheme otherwise.
See <code>coef</code> and <code>coefByModel</code> for estimates and posterior
intervals of regression coefficients, and <code>rnlp</code> for posterior samples.
</p>
<p>modelsearchBlockDiag seeks the highest posterior
probability model using an iterative block search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>

modelSelectionGGM(y, priorCoef=normalidprior(tau=1), 
priorModel=modelbinomprior(1/ncol(y)), 
priorDiag=exponentialprior(lambda=1), center=TRUE, scale=TRUE, 
almost_parallel= FALSE, sampler='Gibbs', niter=10^3, 
burnin= round(niter/10), pbirth=0.5, nbirth, 
Omegaini='glasso-ebic', verbose=TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelSelectionGGM_+3A_y">y</code></td>
<td>
<p>Data matrix</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior on off-diagonal entries of the precision
matrix, conditional on their not being zero (slab)</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_priormodel">priorModel</code></td>
<td>
<p>Prior probabilities on having non-zero diagonal
entries</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_priordiag">priorDiag</code></td>
<td>
<p>Prior on diagonal entries of the precision matrix</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_center">center</code></td>
<td>
<p>If <code>TRUE</code>, the columns of <code>y</code> will be centered
to zero mean</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_scale">scale</code></td>
<td>
<p>If <code>TRUE</code>, the columns of <code>y</code> will be scaled to
unit sample variance</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_almost_parallel">almost_parallel</code></td>
<td>
<p>Use almost parallel algorithm sampling from each 
column independently and using an MH step</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_sampler">sampler</code></td>
<td>
<p>Posterior sampler. Options are &quot;Gibbs&quot;, &quot;birthdeath&quot;
and &quot;zigzag&quot;</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_niter">niter</code></td>
<td>
<p>Number of posterior samples to be obtained</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_pbirth">pbirth</code></td>
<td>
<p>Probability of a birth move. Ignored unless
<code>sampler=="birthdeath"</code></p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_nbirth">nbirth</code></td>
<td>
<p>Number of birth/death updates to perform for each row of
the precision matrix. Defaults to <code>ncol(y)</code></p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_burnin">burnin</code></td>
<td>
<p>The first burnin samples will be discarded</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_omegaini">Omegaini</code></td>
<td>
<p>Initial value of the precision matrix Omega. &quot;null&quot;
sets all off-diagonal entries to 0. &quot;glasso-bic&quot; and &quot;glasso-ebic&quot; use
GLASSO with regularization parameter set via BIC/EBIC,
respectively. Alternatively, <code>Omegaini</code> can be a matrix</p>
</td></tr>
<tr><td><code id="modelSelectionGGM_+3A_verbose">verbose</code></td>
<td>
<p>Set <code>verbose==TRUE</code> to print iteration progress</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let Omega be the inverse covariance matrix.
A spike-and-slab prior is used. Specifically,
independent priors are set on all Omega[j,k], and then a
positive-definiteness truncation is added.
</p>
<p>The prior on diagonal entries Omega[j,j] is given by <code>priorDiag</code>.
Off-diagonal Omega[j,k] are equal to zero with probability given by
<code>modelPrior</code> and, when non-zero, they are
</p>
<p>Independent spike-and-slab priors are set on the off-diagonal entries of Omega,
i.e. Omega[j,k]=0 with positive probability (spike) and otherwise
arises from the distribution indicated in <code>priorCoef</code> (slab).
</p>


<h3>Value</h3>

<p>Posterior inference on the inverse covariance of <code>y</code>.
Object of class <code>msfit_ggm</code>, which extends a list with elements
</p>
<table>
<tr><td><code>postSample</code></td>
<td>
<p>Posterior samples for the upper-diagonal entries of
the precision matrix. Stored as a sparse matrix, see package Matrix
to utilities to work with such matrices</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>Number of columns in <code>y</code></p>
</td></tr>
<tr><td><code>priors</code></td>
<td>
<p>List storing the priors specified when calling
<code>modelSelectionGGM</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>See Also</h3>

<p><code><a href="#topic+msfit_ggm-class">msfit_ggm-class</a></code> for further details on the output.
<code>icov</code> for the estimated precision (inverse covariance) matrix.
<code>coef.msfit_ggm</code> for Bayesian model averaging estimates and
intervals. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Simulate data with p=3
Th= diag(3); Th[1,2]= Th[2,1]= 0.5
sigma= solve(Th)

z= matrix(rnorm(1000*3), ncol=3)
y= z 

#Obtain posterior samples
fit= modelSelectionGGM(y, scale=FALSE)

#Parameter estimates, intervals, prob of non-zero
coef(fit)

#Estimated inverse covariance
icov(fit)

#Estimated inverse covariance, entries set to 0
icov(fit, threshold=0.95)

#Shows first posterior samples
head(fit$postSample)

</code></pre>

<hr>
<h2 id='mombf'> Moment and inverse moment Bayes factors for linear models. </h2><span id='topic+mombf'></span><span id='topic+mombf.lm'></span><span id='topic+imombf'></span><span id='topic+imombf.lm'></span>

<h3>Description</h3>

<p><code>mombf</code> computes moment Bayes factors to test whether a subset of
regression coefficients are equal to some user-specified value.
<code>imombf</code> computes inverse moment Bayes factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mombf(lm1, coef, g, prior.mode, baseDensity='normal', nu=3, theta0,
logbf=FALSE, B=10^5)
imombf(lm1, coef, g, prior.mode, nu = 1, theta0 , method='adapt',
nquant=100, B = 10^5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mombf_+3A_lm1">lm1</code></td>
<td>
<p> Linear model fit, as returned by <code>lm1</code>. </p>
</td></tr>
<tr><td><code id="mombf_+3A_coef">coef</code></td>
<td>
<p> Vector with indexes of coefficients to be
tested. e.g. <code>coef==c(2,3)</code>
and <code>theta0==c(0,0)</code> tests <code>coef(lm1)[2]=coef(lm1)[3]=0</code>. </p>
</td></tr>
<tr><td><code id="mombf_+3A_g">g</code></td>
<td>
<p> Vector with prior parameter values. See <code>dmom</code> and
<code>dimom</code> for details. </p>
</td></tr>
<tr><td><code id="mombf_+3A_prior.mode">prior.mode</code></td>
<td>
<p> If specified, <code>g</code> is set such that the prior
mode is <code>prior.mode</code> </p>
</td></tr>
<tr><td><code id="mombf_+3A_basedensity">baseDensity</code></td>
<td>
<p>Density upon which the Mom prior is
based. <code>baseDensity=='normal'</code> results in the normal Mom prior,
<code>baseDensity=='t'</code> in the t Mom prior with <code>nu</code> degrees of freedom.</p>
</td></tr>
<tr><td><code id="mombf_+3A_nu">nu</code></td>
<td>
<p>For <code>mombf</code>, <code>nu</code> specifies the degrees of freedom
of the t Mom prior. It is ignored unless
<code>baseDensity=='t'</code>. <code>nu</code> defaults to 3.
For <code>imombf</code>, <code>nu</code> specifies the degrees of freedom for
the inverse moment prior (see
<code>dimom</code> for details). Defaults to <code>nu=1</code>, which Cauchy-like
tails.</p>
</td></tr>
<tr><td><code id="mombf_+3A_theta0">theta0</code></td>
<td>
<p> Null value for the regression coefficients. Defaults to
0. </p>
</td></tr>
<tr><td><code id="mombf_+3A_logbf">logbf</code></td>
<td>
<p> If <code>logbf==TRUE</code> the natural logarithm of the Bayes
factor is returned.</p>
</td></tr>
<tr><td><code id="mombf_+3A_method">method</code></td>
<td>
<p> Numerical integration method to compute the bivariate
integral (only used by <code>imombf</code>).
For <code>method=='adapt'</code>, the inner integral is evaluated (via <code>integrate</code>) at a series of
<code>nquant</code> quantiles of the residual variance posterior distribution, and then
averaged as described in Johnson (1992).
Set <code>method=='MC'</code> to use Monte Carlo integration.</p>
</td></tr>
<tr><td><code id="mombf_+3A_nquant">nquant</code></td>
<td>
<p> Number of quantiles at which to evaluate the integral
for known <code>sigma</code>. Only used if <code>method=='adapt'</code>.</p>
</td></tr>
<tr><td><code id="mombf_+3A_b">B</code></td>
<td>
<p>Number of Monte Carlo samples to estimate the T Mom and the inverse moment
Bayes factor. Only used in <code>mombf</code> if <code>baseDensity=='t'</code>. Only used in <code>imombf</code> if <code>method=='MC'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions actually call <code>momunknown</code> and
<code>imomunknown</code>, but they have a simpler interface.
See <code>dmom</code> and <code>dimom</code> for details on the moment and inverse
moment priors.
</p>


<h3>Value</h3>

<p><code>mombf</code> returns the moment Bayes factor to compare the model where
<code>theta!=theta0</code>
with the null model where <code>theta==theta0</code>. Large values favor the
alternative model; small values favor the null.
<code>imombf</code> returns
inverse moment Bayes factors.
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p> See http://rosselldavid.googlepages.com for technical
reports.
For details on the quantile integration, see Johnson, V.E. A Technique for Estimating Marginal Posterior Densities in Hierarchical Models
Using Mixtures of Conditional Densities. Journal of the American Statistical Association, Vol. 87, No. 419. (Sep., 1992), pp. 852-860.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlpMarginal">nlpMarginal</a></code> for a better interface to
integrated likelihoods and <code><a href="#topic+modelSelection">modelSelection</a></code> to also
search over the model space</p>


<h3>Examples</h3>

<pre><code class='language-R'>##compute Bayes factor for Hald's data
data(hald)
lm1 &lt;- lm(hald[,1] ~ hald[,2] + hald[,3] + hald[,4] + hald[,5])

# Set g so that interval (-0.2,0.2) has 5% prior probability
# (in standardized effect size scale)
priorp &lt;- .05; q &lt;- .2
gmom &lt;- priorp2g(priorp=priorp,q=q,prior='normalMom')
gimom &lt;- priorp2g(priorp=priorp,q=q,prior='iMom')

mombf(lm1,coef=2,g=gmom) #moment BF
imombf(lm1,coef=2,g=gimom,B=10^5) #inverse moment BF

</code></pre>

<hr>
<h2 id='momknown'> Bayes factors for moment and inverse moment priors</h2><span id='topic+momknown'></span><span id='topic+momunknown'></span><span id='topic+imomknown'></span><span id='topic+imomunknown'></span>

<h3>Description</h3>

<p><code>momknown</code> and <code>momunknown</code> compute moment Bayes
factors for linear models when <code>sigma^2</code> is known and unknown,
respectively. The functions can also be used to compute approximate
Bayes factors for generalized linear models and other settings.
<code>imomknown</code>, <code>imomunknown</code> compute inverse
moment Bayes factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>momknown(theta1hat, V1, n, g = 1, theta0, sigma, logbf = FALSE)
momunknown(theta1hat, V1, n, nuisance.theta, g = 1, theta0, ssr, logbf =
FALSE)
imomknown(theta1hat, V1, n, nuisance.theta, g = 1, nu = 1, theta0,
sigma, method='adapt', B=10^5)
imomunknown(theta1hat, V1, n, nuisance.theta, g = 1, nu = 1, theta0,
ssr, method='adapt', nquant = 100, B = 10^5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="momknown_+3A_theta1hat">theta1hat</code></td>
<td>
<p> Vector with regression coefficients estimates. </p>
</td></tr>
<tr><td><code id="momknown_+3A_v1">V1</code></td>
<td>
<p> Matrix proportional to the covariance of
<code>theta1hat</code>. For linear models, the covariance is <code>sigma^2*V1</code>. </p>
</td></tr>
<tr><td><code id="momknown_+3A_n">n</code></td>
<td>
<p> Sample size. </p>
</td></tr>
<tr><td><code id="momknown_+3A_nuisance.theta">nuisance.theta</code></td>
<td>
<p>Number of nuisance regression coefficients, i.e.
coefficients that we do not wish to test for.</p>
</td></tr>
<tr><td><code id="momknown_+3A_ssr">ssr</code></td>
<td>
<p>Sum of squared residuals from a linear model call.</p>
</td></tr>
<tr><td><code id="momknown_+3A_g">g</code></td>
<td>
<p> Prior parameter. See <code>dmom</code> and <code>dimom</code> for details. </p>
</td></tr>
<tr><td><code id="momknown_+3A_theta0">theta0</code></td>
<td>
<p> Null value for the regression coefficients. Defaults to
0. </p>
</td></tr>
<tr><td><code id="momknown_+3A_sigma">sigma</code></td>
<td>
<p> Dispersion parameter is <code>sigma^2</code>. </p>
</td></tr>
<tr><td><code id="momknown_+3A_logbf">logbf</code></td>
<td>
<p> If <code>logbf==TRUE</code> the natural logarithm of the Bayes
factor is returned.</p>
</td></tr>
<tr><td><code id="momknown_+3A_nu">nu</code></td>
<td>
<p> Prior parameter for the inverse moment prior. See
<code>dimom</code> for details. Defaults to <code>nu=1</code>, which Cauchy-like
tails.</p>
</td></tr>
<tr><td><code id="momknown_+3A_method">method</code></td>
<td>
<p> Numerical integration method (only used by
<code>imomknown</code> and <code>imomunknown</code>).
Set <code>method=='adapt'</code> in <code>imomknown</code> to integrate using adaptive
quadrature of functions as implemented in the function
<code>integrate</code>. In <code>imomunknown</code> the integral is evaluated as in
<code>imomknown</code> at a series of
<code>nquant</code> quantiles of the posterior for <code>sigma</code>, and then
averaged as described in Johnson (1992).
Set <code>method=='MC'</code> to use Monte Carlo integration.</p>
</td></tr>
<tr><td><code id="momknown_+3A_nquant">nquant</code></td>
<td>
<p> Number of quantiles at which to evaluate the integral
for known <code>sigma</code>. </p>
</td></tr>
<tr><td><code id="momknown_+3A_b">B</code></td>
<td>
<p>Number of Monte Carlo samples to estimate the inverse moment
Bayes factor. Ignored if <code>method!='MC'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code>dmom</code> and <code>dimom</code> for details on the moment and inverse
moment priors.
The Zellner-Siow g-prior is given by dmvnorm(theta,theta0,n*g*V1).
</p>


<h3>Value</h3>

<p><code>momknown</code> and <code>momunknown</code> return the moment Bayes factor to compare the model where
<code>theta!=theta0</code>
with the null model where <code>theta==theta0</code>. Large values favor the
alternative model; small values favor the null.
<code>imomknown</code> and <code>imomunknown</code> return
inverse moment Bayes factors.
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p> See http://rosselldavid.googlepages.com for technical
reports.
</p>
<p>For details on the quantile integration, see Johnson, V.E. A Technique for Estimating Marginal Posterior Densities in Hierarchical Models
Using Mixtures of Conditional Densities. Journal of the American Statistical Association, Vol. 87, No. 419. (Sep., 1992), pp. 852-860.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+mombf">mombf</a></code> and
<code><a href="#topic+imombf">imombf</a></code> for a simpler interface to compute Bayes
factors in linear regression </p>


<h3>Examples</h3>

<pre><code class='language-R'>#simulate data from probit regression
set.seed(4*2*2008)
n &lt;- 50; theta &lt;- c(log(2),0)
x &lt;- matrix(NA,nrow=n,ncol=2)
x[,1] &lt;- rnorm(n,0,1); x[,2] &lt;- rnorm(n,.5*x[,1],1)
p &lt;- pnorm(x[,1]*theta[1]+x[,2]+theta[2])
y &lt;- rbinom(n,1,p)

#fit model
glm1 &lt;- glm(y~x[,1]+x[,2],family=binomial(link = "probit"))
thetahat &lt;- coef(glm1)
V &lt;- summary(glm1)$cov.scaled

#compute Bayes factors to test whether x[,1] can be dropped from the model
g &lt;- .5
bfmom.1 &lt;- momknown(thetahat[2],V[2,2],n=n,g=g,sigma=1)
bfimom.1 &lt;- imomknown(thetahat[2],V[2,2],n=n,nuisance.theta=2,g=g,sigma=1)
bfmom.1
bfimom.1

</code></pre>

<hr>
<h2 id='msfit_ggm-class'>Class &quot;msfit_ggm&quot;</h2><span id='topic+msfit_ggm-class'></span><span id='topic+msfit_ggm'></span><span id='topic+show+2Cmsfit_ggm-method'></span><span id='topic+msfit_ggm.coef'></span>

<h3>Description</h3>

<p>Stores the output of Bayesian Gaussian graphical model selection and
averaging, as produced by function <code>modelSelectionGGM</code>.
The class extends a list, so all usual methods for lists also work for
<code>msfit_ggm</code> objects, e.g. accessing elements, retrieving names etc.
</p>
<p>Methods are provided to obtain parameter estimates, posterior intervals
(Bayesian model averaging), and posterior probabilities of parameters
being non-zero
</p>


<h3>Objects from the Class</h3>

<p>Objects are created by a call to <code>modelSelectionGGM</code>.
</p>


<h3>Slots</h3>

<p>The class extends a list with elements:
</p>

<dl>
<dt>postSample</dt><dd><p>Sparse matrix (<code>dgCMatrix</code>) with posterior
samples for the Gaussian precision (inverse covariance)
parameters. Each row is a posterior sample. Within each row, only
the upper-diagonal of the precision matrix is stored in a flat
manner. The row and column indexes are stored in indexes</p>
</dd>
<dt>indexes</dt><dd><p>For each column in postSample, it indicates the row
and column of the precision matrix</p>
</dd>
<dt>p</dt><dd><p>Number of variables</p>
</dd>
<dt>priors</dt><dd><p>Priors specified when calling <code>modelSelection</code></p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p>Obtain BMA posterior means, intervals and posterior
probability of non-zeroes</p>
</dd>
<dt>plot</dt><dd><p>Shows estimated posterior inclusion probability for each
parameter vs. number of MCMC iterations. Only up to the first 5000
parameters are shown</p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "msfit_ggm")</code>:
Displays general information about the object. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelSelectionGGM">modelSelectionGGM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("msfit_ggm")
</code></pre>

<hr>
<h2 id='msfit-class'>Class &quot;msfit&quot;</h2><span id='topic+msfit-class'></span><span id='topic+msfit'></span><span id='topic+show+2Cmsfit-method'></span><span id='topic+msfit.coef'></span><span id='topic+msfit.plot'></span><span id='topic+msfit.predict'></span><span id='topic+coefByModel'></span><span id='topic+coefByModel-methods'></span><span id='topic+coefByModel+2Cmsfit-method'></span>

<h3>Description</h3>

<p>Stores the output of Bayesian variable selection, as produced by
function <code>modelSelection</code>.
The class extends a list, so all usual methods for lists also work for
<code>msfit</code> objects, e.g. accessing elements, retrieving names etc.
</p>
<p>Methods are provided to compute posterior probabilities,
obtaining regression coefficient estimates and posterior intervals
(both via Bayesian model averaging and for individual models),
and sampling from their posterior distribution, as indicated below.
</p>


<h3>Objects from the Class</h3>

<p>Typically objects are automatically created by a call to <code>modelSelection</code>.
Alternatively, objects can be created by calls of the form
<code>new("msfit",x)</code> where <code>x</code> is a list with the adequate
elements (see slots).
</p>


<h3>Slots</h3>

<p>The class extends a list with elements:
</p>

<dl>
<dt>postSample</dt><dd><p><code>matrix</code> with posterior samples for the model
indicator. <code>postSample[i,j]==1</code>
indicates that variable j was included in the model in the MCMC
iteration i</p>
</dd>
<dt>postOther</dt><dd><p><code>postOther</code>
returns posterior samples for parameters other than the model
indicator, i.e. basically hyper-parameters.
If hyper-parameters were fixed in the model specification, <code>postOther</code> will be empty.</p>
</dd>
<dt>margpp</dt><dd><p>Marginal posterior probability for inclusion of each
covariate. This is computed by averaging marginal post prob for
inclusion in each Gibbs iteration, which is much more accurate than
simply taking <code>colMeans(postSample)</code></p>
</dd></dl>
<p>.
</p>
<dl>
<dt>postMode</dt><dd><p>Model with highest posterior probability amongst all those visited</p>
</dd>
<dt>postModeProb</dt><dd><p>Unnormalized posterior prob of posterior mode (log scale)</p>
</dd>
<dt>postProb</dt><dd><p>Unnormalized posterior prob of each visited model (log
scale)</p>
</dd>
<dt>family</dt><dd><p>Residual distribution, i.e. argument <code>family</code>
when calling <code>modelSelection</code></p>
</dd>
<dt>p</dt><dd><p>Number of variables</p>
</dd>
<dt>priors</dt><dd><p>Priors specified when calling <code>modelSelection</code></p>
</dd>
<dt>ystd</dt><dd><p>For internal use. Stores the response variable,
standardized if <code>center</code> or <code>scale</code> were set to
<code>TRUE</code></p>
</dd>
<dt>xstd</dt><dd><p>For internal use. Stores the covariates,
standardized if <code>center</code> or <code>scale</code> were set to
<code>TRUE</code></p>
</dd>
<dt>stdconstants</dt><dd><p>For internal use. If <code>center</code> or
<code>scale</code> were set to <code>TRUE</code>, stores the sample mean
and standard deviation of the outcome and covariates</p>
</dd>
<dt>call</dt><dd><p>Stores info about the call, the formula used (if any),
splines used etc</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p>Obtains posterior means and intervals via Bayesian model
averaging</p>
</dd>
<dt>coefByModel</dt><dd><p>Obtains posterior means and intervals for
individual models</p>
</dd>
<dt>plot</dt><dd><p>Shows estimated posterior inclusion probability for each
parameter vs. number of MCMC iterations</p>
</dd>
<dt>predict</dt><dd><p>Obtains posterior means and intervals for given
covariate values. These are posterior intervals for the mean, not
posterior predictive intervals for the outcome</p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "msfit")</code>: Displays general information about the object. </p>
</dd>
<dt>postProb</dt><dd><p><code>signature(object = "msfit")</code>: Extracts
posterior model probabilities. </p>
</dd>
<dt>rnlp</dt><dd><p><code>signature(object = "msfit")</code>: Obtain posterior
samples for regression coefficients. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>References</h3>

<p>Johnson VE, Rossell D. Non-Local Prior Densities for Default Bayesian Hypothesis Tests. Journal of the Royal Statistical Society B, 2010, 72, 143-170
</p>
<p>Johnson VE, Rossell D. Bayesian model selection in high-dimensional
settings. Journal of the American Statistical Association, 107, 498:649-660.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+modelSelection">modelSelection</a></code> and <code><a href="#topic+rnlp">rnlp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("msfit")
</code></pre>

<hr>
<h2 id='msPriorSpec-class'>Class &quot;msPriorSpec&quot;</h2><span id='topic+msPriorSpec'></span><span id='topic+msPriorSpec-class'></span><span id='topic+aic'></span><span id='topic+bic'></span><span id='topic+bicprior'></span><span id='topic+ic'></span><span id='topic+emomprior'></span><span id='topic+exponentialprior'></span><span id='topic+imomprior'></span><span id='topic+momprior'></span><span id='topic+zellnerprior'></span><span id='topic+normalidprior'></span><span id='topic+groupmomprior'></span><span id='topic+groupemomprior'></span><span id='topic+groupimomprior'></span><span id='topic+groupzellnerprior'></span><span id='topic+modelunifprior'></span><span id='topic+modelbinomprior'></span><span id='topic+modelbbprior'></span><span id='topic+modelcomplexprior'></span><span id='topic+igprior'></span>

<h3>Description</h3>

<p>Stores the prior distributions to be used for Bayesian variable selection
in normal regression models.
This class can be used to specify the prior on non-zero regression coefficients,
the model indicator or the nuisance parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aic()
bic()
bicprior()
ic(penalty)

momprior(taustd=1, tau, tau.adj=10^6, r=1)
imomprior(tau, tau.adj=10^6)
emomprior(tau, tau.adj=10^6)
zellnerprior(taustd=1, tau, tau.adj=10^6)
normalidprior(taustd=1, tau, tau.adj=10^6)

exponentialprior(lambda = 1)

groupmomprior(taustd=1, tau, tau.adj=10^6)
groupimomprior(tau, tau.adj=10^6)
groupemomprior(tau, tau.adj=10^6)
groupzellnerprior(taustd=1, tau, tau.adj=10^6)

modelunifprior()
modelbinomprior(p=0.5)
modelbbprior(alpha.p=1, beta.p=1)
modelcomplexprior(c=1)

igprior(alpha=.01, lambda=.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msPriorSpec-class_+3A_penalty">penalty</code></td>
<td>
<p>Penalty on model dimension, i.e. for the AIC penalty=2</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_tau">tau</code></td>
<td>
<p>Prior dispersion parameter for covariates undergoing selection</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_taustd">taustd</code></td>
<td>
<p>Prior dispersion parameter for covariates undergoing selection.
It is calibrated so that 'taustd=1' equals the unit information prior.</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_tau.adj">tau.adj</code></td>
<td>
<p>Prior variance in Normal prior for covariates not undergoing selection</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_r">r</code></td>
<td>
<p>MOM prior parameter is <code>2*r</code></p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_p">p</code></td>
<td>
<p>Prior inclusion probability for binomial prior on model space</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_alpha.p">alpha.p</code></td>
<td>
<p>Beta-binomial prior on model space has parameters alpha.p, beta.p</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_beta.p">beta.p</code></td>
<td>
<p>Beta-binomial prior on model space has parameters
alpha.p, beta.p</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_c">c</code></td>
<td>
<p>Under the Complexity prior the prior
probability of having k variables in the model is proportional to <code>1/p^(ck)</code></p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_alpha">alpha</code></td>
<td>
<p>Inverse gamma prior has parameters alpha/2, lambda/2</p>
</td></tr>
<tr><td><code id="msPriorSpec-class_+3A_lambda">lambda</code></td>
<td>
<p><code>igprior</code> defines an inverse gamma prior with
parameters alpha/2, lambda/2. <code>exponentialprior</code> defines an
exponential prior with rate parameter <code>lambda</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>DISCUSSION OF PRIOR ON PARAMETERS
</p>
<p>Let beta=(beta_1,...,beta_p) be the regression coefficients for
individual variables and delta=(delta_1,...,delta_q) those for grouped
variables (e.g. factors or smooth terms in modelSelection).
</p>
<p>momprior, emomprior, imomprior, zellnerprior and normalid can be priors on
both beta or delta. For further information see the vignette.
</p>
<p>groupzellnerprior is the prior density on delta
</p>
<p style="text-align: center;"><code class="reqn">p_z(\delta; \tau)= \prod_j N(\delta_j; 0, (\tau/p_j)) (X_j'X_j)^{-1}</code>
</p>

<p>where <code class="reqn">X_j</code> are the design matrix columns associated to <code class="reqn">delta_j</code> and p_j=ncol(X_j)
is the number of covariates in the group (for groupmomprior, the term in the
denominator is (p_j +2) instead of p_j). A default
tau=n=nrow(X_j) mimics the unit information prior and implies that the
ratio of variance explained by X_j / residual variance is expected to be
1 a priori. To set the dispersion in terms of unit information prior, taustd
is also available.
</p>
<p>groupmomprior adds a quadratic MOM penalty
</p>
<p>p_m(delta; tau)= p_z(delta; tau * n) prod_j delta_j'X_j'X_jdelta_j ncol(X_j)/(tau * n * p_j / (p_j + 2))
</p>
<p>and analogously for eMOM and iMOM. Note that unlike groupzellnerprior, the nrow(X_j)
factor is already included in the code. This is done to give user introduced tau values
a roughly similar meaning between momprior and groupmomprior.
</p>
<p>DISCUSSION OF PRIOR ON MODELS
</p>
<p>Under the uniform prior, the prior probability of any model is
1 / number of models.
</p>
<p>Under the Binomial, Beta-Binomial and Complexity priors a model with k
out of K active variables has prior probability
P(Z=k) / (K choose k), where
where Z ~ Binomial(K,p),
Z ~ BetaBinomial(K,alpha.p,beta.p)
or for the Complexity prior P(Z=k) proportional to <code>1/K^(c*k)</code>.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("msPriorSpec",
  ...)</code>, but it is easier to use creator functions.
</p>
<p>For priors on regression coefficients use <code>momprior</code>,
<code>imomprior</code> or <code>emomprior</code>.
For prior on model space <code>modelunifprior</code>, <code>modelbinomprior</code>
<code>modelbbprior</code>, or <code>modelcomplexprior</code>.
For prior on residual variance use <code>igprior</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>priorType</code>:</dt><dd><p>Object of class <code>"character"</code>. <code>"coefficients"</code> indicates
that the prior is for the non-zero regression coefficients.
<code>"modelIndicator"</code> that it is for the model indicator,
and <code>"nuisancePars"</code> that it is for the nuisance parameteres.
Several prior distributions are available for each choice of <code>priorType</code>,
and these can be speicified in the slot <code>priorDist</code>. </p>
</dd>
<dt><code>priorDistr</code>:</dt><dd><p>Object of class <code>"character"</code>.
If <code>priorType=="coefficients"</code>, <code>priorDistr</code> can be equal to
&quot;pMOM&quot;, &quot;piMOM&quot;, &quot;peMOM&quot;, &quot;zellner&quot;, &quot;normalid&quot;, &quot;groupMOM&quot; or &quot;groupzellner&quot;
(product moment, product inverse moment, product exponential moment, Zellner prior, normal prior with <code class="reqn">\Sigma=\mathbf{I}</code>, respectively).
If <code>priorType=="modelIndicator"</code>, <code>priorDistr</code> can be equal to &quot;uniform&quot; or &quot;binomial&quot;
to specify a uniform prior (all models equaly likely a priori) or a
binomial prior, or to &quot;complexity&quot; for the Complexity prior of Castillo
et al 2015. For a binomial prior,
the prior inclusion probability for any single variable must be
specified in slot <code>priorPars['p']</code>. For a beta-binomial prior, the
Beta hyper-prior parameters must be in <code>priorPars['alpha.p']</code> and
<code>priorPars['beta.p']</code>.
For the Complexity prior, the prior parameter must be in the slot
<code>priorPars['c']</code>.
If <code>priorType=="nuisancePars"</code>, <code>priorDistr</code> must be equal to &quot;invgamma&quot;. This corresponds to an
inverse gamma distribution for the residual variance, with parameters
specified in the slot <code>priorPars</code>.</p>
</dd>
<dt><code>priorPars</code>:</dt><dd><p>Object of class <code>"vector"</code>, where each element must be named.
For <code>priorDistr=='pMOM'</code>, there must be an element &quot;r&quot; (MOM power
is 2r).
For any <code>priorDistr</code> there must be either an element &quot;tau&quot; indicating
the prior dispersion or elements &quot;a.tau&quot; and &quot;b.tau&quot; specifying an
inverse gamma hyper-prior for &quot;tau&quot;.
Optionally, there may be an element &quot;tau.adj&quot; indicating the prior
dispersion for the adjustment variables (i.e. not undergoing variable
selection). If not defined, &quot;tau.adj&quot; is set to 0.001 by default.
For <code>priorDistr=='binomial'</code>, there must be either an element &quot;p&quot; specifying the prior inclusion probability
for any single covariate, or a vector with elements &quot;alpha.p&quot; and
&quot;beta.p&quot; specifying a Beta(alpha.p,beta.p) hyper-prior on p.
For <code>priorDistr=='invgamma'</code> there must be elements &quot;alpha&quot; and &quot;lambda&quot;. The prior for the residual variance
is an inverse gamma with parameteres <code>.5*alpha</code> and <code>.5*lambda</code>.
</p>
</dd>
</dl>



<h3>Methods</h3>

<p>No methods defined with class &quot;msPriorSpec&quot; in the signature.
</p>


<h3>Note</h3>

<p>When new instances of the class are created a series of check are performed to ensure that a valid prior
specification is produced.
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>References</h3>

<p>Johnson VE, Rossell D. Non-Local Prior Densities for Default Bayesian Hypothesis Tests. Journal of the Royal Statistical Society B, 2010, 72, 143-170
</p>
<p>Johnson VE, Rossell D. Bayesian model selection in high-dimensional
settings. Journal of the American Statistical Association, 107, 498:649-660.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+modelSelection">modelSelection</a></code> for an example of defining an instance of the class
and perform Bayesian model selection.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("msPriorSpec")
</code></pre>

<hr>
<h2 id='nlpmarginals'> Marginal density of the observed data for linear regression with
Normal, two-piece Normal, Laplace or two-piece Laplace residuals
under non-local and Zellner priors </h2><span id='topic+nlpmarginals'></span><span id='topic+nlpMarginal'></span><span id='topic+pimomMarginalK'></span><span id='topic+pimomMarginalU'></span><span id='topic+pmomMarginalK'></span><span id='topic+pmomMarginalU'></span>

<h3>Description</h3>

<p>The marginal density of the data, i.e. the likelihood
integrated with respect to the given prior distribution on the
regression coefficients of the variables included in the model and
an inverse gamma prior on the residual variance.
</p>
<p><code>nlpMarginal</code> is the general function, the remaining ones
correspond to particular cases and are kept for backwards
compatibility with old code, and will be deprecated in the future.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlpMarginal(sel, y, x, data, smoothterms, nknots=9, groups=1:ncol(x),
family="normal", priorCoef, priorGroup,
priorVar=igprior(alpha=0.01,lambda=0.01), priorSkew=momprior(tau=0.348),
phi, method='auto', adj.overdisp='intercept', hess='asymp', optimMethod,
optim_maxit, initpar='none', B=10^5, logscale=TRUE, XtX, ytX)

pimomMarginalK(sel, y, x, phi, tau=1, method='Laplace', B=10^5, logscale=TRUE, XtX, ytX)
pimomMarginalU(sel, y, x, alpha=0.001, lambda=0.001, tau=1,
method='Laplace', B=10^5, logscale=TRUE, XtX, ytX)
pmomMarginalK(sel, y, x, phi, tau, r=1, method='auto', B=10^5,
logscale=TRUE, XtX, ytX)
pmomMarginalU(sel, y, x, alpha=0.001, lambda=0.001, tau=1,
r=1, method='auto', B=10^5, logscale=TRUE, XtX, ytX)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlpmarginals_+3A_sel">sel</code></td>
<td>
<p>Vector with indexes of columns in x to be included in the model.
Ignored if <code>y</code> is a formula</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_y">y</code></td>
<td>
<p>Either a formula with the regression equation or a vector with
observed responses. The response can be either continuous or of class
<code>Surv</code> (survival outcome). If <code>y</code> is a formula then <code>x</code>,
<code>groups</code> and <code>constraints</code> are automatically created</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_x">x</code></td>
<td>
<p>Design matrix with linear covariates for which we want to
assess if they have a linear effect on the response. Ignored if
<code>y</code> is a formula</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_data">data</code></td>
<td>
<p>If <code>y</code> is a formula then <code>data</code> should be a data
frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_smoothterms">smoothterms</code></td>
<td>
<p>Formula for non-linear covariates (cubic splines),
modelSelection assesses if the variable has no effect, linear or
non-linear effect. <code>smoothterms</code> can also be a design matrix or
data.frame containing linear terms, for each column modelSelection
creates a spline basis and tests no/linear/non-linear effects</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_nknots">nknots</code></td>
<td>
<p>Number of spline knots. For cubic splines the non-linear
basis adds knots-4 coefficients for each linear term, we recommend
setting <code>nknots</code> to a small/moderate value</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_groups">groups</code></td>
<td>
<p>If variables in <code>x</code> such be added/dropped in groups,
<code>groups</code> indicates the group that each variable corresponds to
(by default each variable goes in a separate group)</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_family">family</code></td>
<td>
<p>Residual distribution. Possible values are
'normal','twopiecenormal','laplace', 'twopiecelaplace'</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior on coefficients, created
by <code>momprior</code>, <code>imomprior</code>, <code>emomprior</code> or
<code>zellnerprior</code>.
Prior dispersion is on coefficients/sqrt(scale) for Normal and
two-piece Normal, and on coefficients/sqrt(2*scale) for Laplace
and two-piece Laplace.</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_priorgroup">priorGroup</code></td>
<td>
<p>Prior on grouped coefficients (e.g. categorical
predictors with &gt;2 categories, splines). Created by
<code>groupmomprior</code>, <code>groupemomprior</code>,
<code>groupimomprior</code> or <code>groupzellnerprior</code></p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_priorvar">priorVar</code></td>
<td>
<p>Inverse gamma prior on scale parameter, created by
<code>igprior(). For Normal variance=scale, for Laplace variance=2*scale.</code></p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_priorskew">priorSkew</code></td>
<td>
<p>Either a number fixing tanh(alpha) where alpha is the
asymmetry parameter or a prior on residual skewness parameter,
assumed to be of
the same family as priorCoef. Ignored if <code>family</code> is 'normal' or
'laplace'.</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_method">method</code></td>
<td>
<p>Method to approximate the integral. See
<code>help(modelSelection)</code>.</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_adj.overdisp">adj.overdisp</code></td>
<td>
<p>Only used for method=='ALA'. Over-dispersion adjustment for models with fixed
dispersion parameter such as logistic and Poisson regression</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_hess">hess</code></td>
<td>
<p>Method to estimat the hessian in the Laplace approximation to the integrated
likelihood under Laplace or asymmetric Laplace errors. When
hess=='asymp' the asymptotic hessian is used, hess=='asympDiagAdj' a
diagonal adjustment is applied (see Rossell and Rubio for details).</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_optimmethod">optimMethod</code></td>
<td>
<p>Algorithm to maximize objective function when
method=='Laplace'. Leave unspecified or set optimMethod=='auto' for an
automatic choice. optimMethod=='LMA' uses modified
Newton-Raphson algorithm, 'CDA' coordinate descent algorithm</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_optim_maxit">optim_maxit</code></td>
<td>
<p>Maximum number of iterations when method=='Laplace'</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_initpar">initpar</code></td>
<td>
<p>Initial regression parameter values when finding the
posterior mode to approximate the integrated likelihood. See
help(modelSelection)</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_b">B</code></td>
<td>
<p>Number of Monte Carlo samples to use (ignored unless
<code>method=='MC'</code>)</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_logscale">logscale</code></td>
<td>
<p>If <code>logscale==TRUE</code> the log marginal density is returned.</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_xtx">XtX</code></td>
<td>
<p>Optionally, specify the matrix X'X.
Useful when the function must be called a large number of times.</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_ytx">ytX</code></td>
<td>
<p>Optionally, specify the vector y'X.
Useful when the function must be called a large number of times.</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_phi">phi</code></td>
<td>
<p>Disperson parameter. See <code>help(modelSelection)</code></p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_alpha">alpha</code></td>
<td>
<p>Prior for phi is inverse gamma <code>alpha/2</code>,
<code>lambda/2</code></p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_lambda">lambda</code></td>
<td>
<p>Prior for phi is inverse gamma <code>alpha/2</code>,
<code>lambda/2</code></p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_tau">tau</code></td>
<td>
<p>Prior dispersion parameter for MOM and iMOM priors (see details)</p>
</td></tr>
<tr><td><code id="nlpmarginals_+3A_r">r</code></td>
<td>
<p>Prior power parameter for MOM prior is <code>2*r</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The marginal density of the data is equal to the integral of
N(y;x[,sel]*theta,phi*I) * pi(theta|phi,tau) * IG(phi;alpha/2,lambda/2)
with respect to theta, where pi(theta|phi,tau) is a non-local prior
and IG denotes the density of an inverse gamma.
</p>
<p><code>pmomMarginalK</code> and <code>pimomMarginalK</code> assume that the
residual variance is known and therefore the inverse-gamma term in the
integrand can be ommitted.
</p>
<p>The product MOM and iMOM densities can be evaluated using the
functions <code>dmom</code> and <code>dimom</code>.
</p>


<h3>Value</h3>

<p>Marginal density of the observed data under the specified prior.
</p>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p>Johnson V.E., Rossell D. Non-Local Prior Densities for Default Bayesian Hypothesis Tests. Journal of the Royal Statistical Society B, 2010, 72, 143-170.
See http://rosselldavid.googlepages.com for technical reports.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+modelSelection">modelSelection</a></code> to perform model selection based
on product non-local priors.
<code><a href="#topic+momunknown">momunknown</a></code>, <code><a href="#topic+imomunknown">imomunknown</a></code>, <code><a href="#topic+momknown">momknown</a></code>, <code><a href="#topic+imomknown">imomknown</a></code>
to compute Bayes factors for additive MOM and iMOM priors </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*2),ncol=2)
y &lt;- x %*% matrix(c(.5,1),ncol=1) + rnorm(nrow(x))
pmomMarginalK(sel=1, y=y, x=x, phi=1, tau=1, method='Laplace')
pmomMarginalK(sel=1:2, y=y, x=x, phi=1, tau=1, method='Laplace')
</code></pre>

<hr>
<h2 id='plotprior'>
Plot estimated marginal prior inclusion probabilities
</h2><span id='topic+plotprior'></span><span id='topic+plotprior-methods'></span><span id='topic+plotprior+2Ccilfit-method'></span>

<h3>Description</h3>

<p>Plot marginal prior inclusion probabilities as estimated by cil versus
regression coefficients for the treatment(s) equation(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotprior(object, xlab, ylab, ylim=c(0,1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotprior_+3A_object">object</code></td>
<td>
<p>Object of class cilfit returned by <code>cil</code></p>
</td></tr>
<tr><td><code id="plotprior_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="plotprior_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="plotprior_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limits</p>
</td></tr>
<tr><td><code id="plotprior_+3A_...">...</code></td>
<td>
<p>Other arguments passed on to <code>plot</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of prior inclusion probabilities vs treatment regression
coefficients (dots). The line shows the (empirical Bayes) fit
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cil">cil</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See help(cil)
</code></pre>

<hr>
<h2 id='postModeOrtho'>Bayesian model selection and averaging under block-diagonal X'X for linear models.</h2><span id='topic+postModeOrtho'></span><span id='topic+postModeBlockDiag'></span>

<h3>Description</h3>

<p>postModeOrtho is for diagonal X'X,
postModeBlockDiag for the more general block-diagonal X'X,
where X is the matrix with predictors.
</p>
<p>Both functions return the model of highest posterior probability of any given
size using an efficient search algorithm. This sequence of models includes
the highest posterior probability model (HPM).
Posterior model probabilities, marginal variable inclusion probabilities
and Bayesian model averaging estimates are also provided.
The unknown residual variance is integrated out using an exact deterministic
algorithm of low computational cost (see details in reference).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>postModeOrtho(y, x, priorCoef=momprior(tau=0.348), priorDelta=modelbbprior(1,1),
priorVar=igprior(0.01,0.01), bma=FALSE, includeModels, maxvars=100)

postModeBlockDiag(y, x, blocks, priorCoef=zellnerprior(tau=nrow(x)),
priorDelta=modelbinomprior(p=1/ncol(x)),priorVar=igprior(0.01,0.01), bma=FALSE,
maxvars=100, momcoef)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postModeOrtho_+3A_y">y</code></td>
<td>
<p>Outcome</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_x">x</code></td>
<td>
<p>Matrix with predictors. If an intercept is desired x should include
a column of 1's.</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_blocks">blocks</code></td>
<td>
<p>Factor or integer vector of length ncol(x) indicating the block
that each column in x belongs to.</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior distribution for the coefficients. Object created
with <code>momprior</code>, <code>imomprior</code>, <code>emomprior</code> or <code>zellnerprior</code>.</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_priordelta">priorDelta</code></td>
<td>
<p>Prior on model space. Use <code>modelbbprior()</code> for Beta-Binomial prior,
<code>modelbinomprior(p)</code> for Binomial prior with prior inclusion
probability <code>p</code>,
<code>modelcomplexprior</code> for Complexity prior,
or <code>modelunifprior()</code> for Uniform prior</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_priorvar">priorVar</code></td>
<td>
<p>Inverse gamma prior on residual variance, created with <code>igprior()</code></p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_bma">bma</code></td>
<td>
<p>Set to TRUE to obtain marginal inclusion probabilities and
Bayesian model averaging parameter estimates for each column of x.</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_includemodels">includeModels</code></td>
<td>
<p>Models that should always be included when
computing posterior model probabilities. It must be a list, each
element in the list corresponds to a model and must be a logical or
numeric vector indicating the variables in that model</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_maxvars">maxvars</code></td>
<td>
<p>The search for the HPM is restricted to models with up to maxvars variables
(note: posterior model probabilities and BMA are valid regardless of maxvars)</p>
</td></tr>
<tr><td><code id="postModeOrtho_+3A_momcoef">momcoef</code></td>
<td>
<p>optional argument containing pre-computed coefficients needed to obtain
the marginal likelihood under the pMOM prior.
A first call to postModeBlockDiag returns these coefficients,
thus this argument is useful to speed up successive calls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first step is to list a sequence of models with 0,...,maxvars variables which,
under fairly general conditions listed in Papaspiliopoulos &amp; Rossell (2016),
is guaranteed to include the HPM.
Then posterior model probabilities are computed for all these models to determine
the HPM, evaluate the marginal posterior of the residual variance on a grid,
and subsequently compute the marginal density p(y) via adaptive quadrature.
Finally this adaptive grid is used to compute marginal inclusion probabilities
and Bayesian model averaging estimates.
For more details see Papaspiliopoulos &amp; Rossell (2016).
</p>


<h3>Value</h3>

<p>List with elemants
</p>
<table>
<tr><td><code>models</code></td>
<td>
<p>data.frame indicating the variables included in the sequence of models found
during the search of the HPM, and their posterior probabilities. The model with highest
posterior probability in this list is guaranteed to be the HPM.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>data.frame containing an adaptive grid of phi (residual variance) values and
their marginal posterior density p(phi|y).</p>
</td></tr>
<tr><td><code>logpy</code></td>
<td>
<p>log-marginal density p(y), i.e. normalization constant of p(phi|y).</p>
</td></tr>
<tr><td><code>bma</code></td>
<td>
<p>Marginal posterior inclusion probabilities and Bayesian model averaging estimates
for each column in x.</p>
</td></tr>
<tr><td><code>postmean.model</code></td>
<td>
<p>Coefficient estimates conditional on each of the models in <code>models</code></p>
</td></tr>
<tr><td><code>momcoef</code></td>
<td>
<p>If a MOM prior was specified in priorCoef, momcoef stores some coefficients needed
to compute its marginal likelihood</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> David Rossell </p>


<h3>References</h3>

<p>Papaspiliopoulos O., Rossell D. Scalable Bayesian variable selection
and model averaging under block-orthogonal design. 2016
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data
set.seed(1)
p &lt;- 400; n &lt;- 410
x &lt;- scale(matrix(rnorm(n*p),nrow=n,ncol=p),center=TRUE,scale=TRUE)
S &lt;- cov(x)
e &lt;- eigen(cov(x))
x &lt;- t(t(x %*% e$vectors)/sqrt(e$values))
th &lt;- c(rep(0,p-3),c(.5,.75,1)); phi &lt;- 1
y &lt;- x %*% matrix(th,ncol=1) + rnorm(n,sd=sqrt(phi))

#Fit
priorCoef=zellnerprior(tau=n); priorDelta=modelbinomprior(p=1/p); priorVar=igprior(0.01,0.01)
pm.zell &lt;- postModeOrtho(y,x=x,priorCoef=priorCoef,priorDelta=priorDelta,priorVar=priorVar,
bma=TRUE)

#Best models
head(pm.zell$models)

#Posterior probabilities for sequence of models
nvars &lt;- sapply(strsplit(as.character(pm.zell$models$modelid),split=','),length)
plot(nvars,pm.zell$models$pp,ylab='post prob',xlab='number of vars',ylim=0:1,xlim=c(0,50))

#Marginal posterior of phi
plot(pm.zell$phi,type='l',xlab='phi',ylab='p(phi|y)')

#Marginal inclusion prob &amp; BMA estimates
plot(pm.zell$bma$margpp,ylab='Marginal inclusion prob')
plot(pm.zell$bma$coef,ylab='BMA estimate')
</code></pre>

<hr>
<h2 id='postProb'>
Obtain posterior model probabilities
</h2><span id='topic+postProb'></span><span id='topic+postProb-methods'></span><span id='topic+postProb+2Cmsfit-method'></span><span id='topic+postProb+2Ccilfit-method'></span><span id='topic+postProb+2Clocaltest-method'></span><span id='topic+postProb+2Cmixturebf-method'></span>

<h3>Description</h3>

<p>Obtain posterior model probabilities after running Bayesian model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  postProb(object, nmax, method='norm')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postProb_+3A_object">object</code></td>
<td>
<p>Object of class msfit returned by <code>modelSelection</code>,
class mixturebf returned by <code>bfnormmix</code>,
class cilfit returned by <code>cil</code>
or class localtest returned by <code>localnulltest</code></p>
</td></tr>
<tr><td><code id="postProb_+3A_nmax">nmax</code></td>
<td>
<p>Maximum number of models to report (defaults to no max)</p>
</td></tr>
<tr><td><code id="postProb_+3A_method">method</code></td>
<td>
<p>Only when <code>class(object)</code> is msfit.
For 'norm' probabilities are obtained by renormalizing the
stored integrated likelihoods, for 'exact' they are given by the proportion
of MCMC visits to each model. 'norm' has less variability but can be biased
if the chain has not converged.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> with posterior model probabilities in column pp.
Column modelid indicates the indexes of the selected covariates (empty
for the null model with no covariates)
</p>
<p>For <code>mixturebf</code> objects, posterior probabilities for the
specified number of components
</p>
<p>For <code>localtest</code> objects, posterior probabilities of a local covariate
effect at various regions
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelSelection">modelSelection</a></code> to perform model selection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See help(modelSelection)
</code></pre>

<hr>
<h2 id='postSamples'>
Extract posterior samples from an object
</h2><span id='topic+postSamples'></span><span id='topic+postSamples-methods'></span><span id='topic+postSamples+2Cmixturebf-method'></span>

<h3>Description</h3>

<p>Obtain posterior model probabilities after running Bayesian model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  postSamples(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="postSamples_+3A_object">object</code></td>
<td>
<p>Object containing posterior samples, e.g. of class
mixture bf as returned by <code>bfnormmix</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>For objects of class <code>mixturebf</code>, a list with one element for
each considered number of mixture components.
</p>
<p>Each element in the list
contains posterior samples on the mixture weights (eta) and other
component-specific parameters such as means (mu) and Cholesky
decomposition of the inverse covariance matrix (cholSigmainv)
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See help(bfnormmix)
</code></pre>

<hr>
<h2 id='priorp2g'> Moment and inverse moment prior elicitation </h2><span id='topic+priorp2g'></span>

<h3>Description</h3>

<p><code>priorp2g</code> finds the <code>g</code> value giving <code>priorp</code> prior
probability to the interval (<code>-q</code>,<code>q</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priorp2g(priorp, q, nu=1, prior=c("iMom", "normalMom", "tMom"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="priorp2g_+3A_prior">prior</code></td>
<td>
<p><code>prior=='normalMom'</code> does computations for the normal
moment prior, <code>prior=='tMom'</code> for the T moment prior,
<code>prior=='iMom'</code> does computations for the inverse moment prior.
Currently <code>prior=='tMom'</code> is not implemented in <code>priorp2g</code>.</p>
</td></tr>
<tr><td><code id="priorp2g_+3A_q">q</code></td>
<td>
 <p><code>priorp2g</code> returns g giving <code>priorp</code> prior
probability to the interval <code>(-q,q)</code>.</p>
</td></tr>
<tr><td><code id="priorp2g_+3A_nu">nu</code></td>
<td>
<p> Prior degrees of freedom for the T moment prior or the iMom
prior (ignored if <code>prior=='normalMom'</code>).</p>
</td></tr>
<tr><td><code id="priorp2g_+3A_priorp">priorp</code></td>
<td>
 <p><code>priorp2g</code> returns g giving <code>priorp</code> prior
probability to the interval <code>(-q,q)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code>pmom</code> and <code>pimom</code> for the MOM/iMOM cumulative
distribution functions.
</p>


<h3>Value</h3>

<p><code>priorp2g</code> returns g giving <code>priorp</code> prior probability to the
interval <code>(-q,q)</code>.
</p>


<h3>Author(s)</h3>

<p>David Rossell <a href="mailto:rosselldavid@gmail.com">rosselldavid@gmail.com</a>
</p>


<h3>References</h3>

<p>See http://rosselldavid.googlepages.com for technical reports.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pmom">pmom</a></code>,
<code><a href="#topic+pimom">pimom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hald)
lm1 &lt;- lm(hald[, 1] ~ hald[, 2] + hald[, 3] + hald[, 4] + hald[, 5])

#find g value giving 0.05 probability to interval (-.2,.2)
priorp &lt;- .05; q &lt;- .2
gmom &lt;- priorp2g(priorp=priorp, q=q, prior='normalMom')
gimom &lt;- priorp2g(priorp=priorp, q=q, prior='iMom')
gmom
gimom
</code></pre>

<hr>
<h2 id='rnlp'>
Posterior sampling for regression parameters
</h2><span id='topic+rnlp'></span><span id='topic+rnlp-methods'></span><span id='topic+rnlp+2Cmissing+2Cmissing+2Cmissing+2Cmissing+2Cmsfit+2Cmissing+2Cmissing-method'></span><span id='topic+rnlp+2CANY+2Cmatrix+2Cmissing+2Cmissing+2Cmissing+2Cmissing+2Cmissing-method'></span><span id='topic+rnlp+2CANY+2Cmatrix+2Cmissing+2Cmissing+2Cmsfit+2Cmissing+2Cmissing-method'></span><span id='topic+rnlp+2Cmissing+2Cmissing+2Cnumeric+2Cmatrix+2Cmissing+2Cmissing+2Cmissing-method'></span><span id='topic+rnlp+2CANY+2Cmatrix+2Cmissing+2Cmissing+2Cmissing+2Ccharacter+2Ccharacter-method'></span>

<h3>Description</h3>

<p>Gibbs sampler for linear, generalized linear and survival models
under product non-local priors, Zellner's prior and a Normal
approximation to the posterior.
Both sampling conditional on a model and Bayesian model averaging are
implemented (see Details).
</p>
<p>If x and y not specified samples from non-local priors/posteriors with
density proportional to d(theta) N(theta; m, V) are produced,
where d(theta) is the non-local penalty term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnlp(y, x, m, V, msfit, outcometype, family, priorCoef, priorGroup,
priorVar, isgroup, niter=10^3, burnin=round(niter/10), thinning=1, pp='norm')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rnlp_+3A_y">y</code></td>
<td>
<p>Vector with observed responses. When <code>class(y)=='Surv'</code>
sampling is based on the Cox partial likelihood, else a linear model
is assumed.</p>
</td></tr>
<tr><td><code id="rnlp_+3A_x">x</code></td>
<td>
<p>Design matrix with all potential predictors</p>
</td></tr>
<tr><td><code id="rnlp_+3A_m">m</code></td>
<td>
<p>Mean for the Normal kernel</p>
</td></tr>
<tr><td><code id="rnlp_+3A_v">V</code></td>
<td>
<p>Covariance for the Normal kernel</p>
</td></tr>
<tr><td><code id="rnlp_+3A_msfit">msfit</code></td>
<td>
<p>Object of class <code>msfit</code> returned by
<code>modelSelection</code>. If specified Bayesian model averaging
posterior samples are returned, according to posterior model
probabilities in <code>msfit</code>, and then arguments <code>y</code>,
<code>x</code>, <code>m</code>, <code>V</code> etc. If <code>msfit</code> is missing then
posterior samples under the full model <code>y ~ x</code> are returned</p>
</td></tr>
<tr><td><code id="rnlp_+3A_outcometype">outcometype</code></td>
<td>
<p>Type of outcome. Possible values are &quot;Continuous&quot;,
&quot;glm&quot; or &quot;Survival&quot;</p>
</td></tr>
<tr><td><code id="rnlp_+3A_family">family</code></td>
<td>
<p>Assumed family for the family. Some possible values are
&quot;normal&quot;, &quot;binomial logit&quot; and &quot;Cox&quot;</p>
</td></tr>
<tr><td><code id="rnlp_+3A_priorcoef">priorCoef</code></td>
<td>
<p>Prior distribution for the coefficients. Ignored if
<code>msfit</code> is supplied. Must be object of class
<code>msPriorSpec</code>, e.g. created by <code>momprior</code>,
<code>emomprior</code>, <code>imomprior</code>, <code>zellnerprior</code></p>
</td></tr>
<tr><td><code id="rnlp_+3A_priorgroup">priorGroup</code></td>
<td>
<p>Prior on grouped coefficients (e.g. categorical
predictors with &gt;2 categories, splines), as passed to <code>modelSelection</code></p>
</td></tr>
<tr><td><code id="rnlp_+3A_priorvar">priorVar</code></td>
<td>
<p>Prior on residual variance. Ignored if <code>msfit</code>
supplied. Must be object of class <code>msPriorSpec</code>, e.g. created
with <code>igprior</code></p>
</td></tr>
<tr><td><code id="rnlp_+3A_isgroup">isgroup</code></td>
<td>
<p>Logical vector where <code>TRUE</code> indicates that the
variable is part of a group, e.g. one of several dummy indicators
for a discrete covariate</p>
</td></tr>
<tr><td><code id="rnlp_+3A_niter">niter</code></td>
<td>
<p>Number of MCMC iterations</p>
</td></tr>
<tr><td><code id="rnlp_+3A_burnin">burnin</code></td>
<td>
<p>Number of burn-in MCMC iterations. Defaults to <code>.1*niter</code>. Set to 0 for no burn-in</p>
</td></tr>
<tr><td><code id="rnlp_+3A_thinning">thinning</code></td>
<td>
<p>MCMC thinning factor, i.e. only one out of each <code>thinning</code> iterations are reported. Defaults to no thinning</p>
</td></tr>
<tr><td><code id="rnlp_+3A_pp">pp</code></td>
<td>
<p>When <code>msfit</code> is provided this is the method to compute posterior model probabilities,
which determine the sampled models. Can be 'norm' or 'exact', see <code>postProb</code> for details. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is implemented for product MOM (pMOM), product iMOM
(piMOM) and product eMOM (peMOM) priors.
The algorithm combines an
orthogonalization that provides low serial correlation
with a latent truncation representation that allows fast sampling.
</p>
<p>When <code>y</code> and <code>x</code> are specified sampling is for the linear
regression posterior.
When argument <code>msfit</code> is left missing, posterior sampling is for
the full model regressing <code>y</code> on all covariates in <code>x</code>.
When <code>msfit</code> is specified each model is drawn with
probability given by <code>postProb(msfit)</code>. In this case, a Bayesian
Model Averaging estimate of the regression coefficients can be
obtained by applying <code>colMeans</code> to the <code>rnlp</code> ouput matrix.
</p>
<p>When <code>y</code> and <code>x</code> are left missing, sampling is from a
density proportional to d(theta) N(theta; m,V), where d(theta) is the
non-local penalty (e.g. d(theta)=prod(theta^(2r)) for the pMOM prior).
</p>


<h3>Value</h3>

<p>Matrix with posterior samples
</p>


<h3>Author(s)</h3>

<p>David Rossell
</p>


<h3>References</h3>

<p>D. Rossell and D. Telesca. Non-local priors for high-dimensional
estimation, 2014. http://arxiv.org/pdf/1402.5107v2.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelSelection">modelSelection</a></code> to perform model selection and compute
posterior model probabilities.
For more details on prior specification see <code><a href="#topic+msPriorSpec-class">msPriorSpec-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data
x &lt;- matrix(rnorm(100*3),nrow=100,ncol=3)
theta &lt;- matrix(c(1,1,0),ncol=1)
y &lt;- x %*% theta + rnorm(100)
fit1 &lt;- modelSelection(y=y, x=x, center=FALSE, scale=FALSE)

th &lt;- rnlp(msfit=fit1, niter=100)
colMeans(th)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
