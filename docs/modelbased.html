<!DOCTYPE html><html lang="en-US"><head><title>Help for package modelbased</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {modelbased}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#modelbased-package'><p>modelbased: Estimation of Model-Based Predictions, Contrasts and Means</p></a></li>
<li><a href='#.uniroot.all'><p>Copied from rootSolve package</p></a></li>
<li><a href='#coffee_data'><p>Sample dataset from a course about analysis of factorial designs</p></a></li>
<li><a href='#describe_nonlinear'><p>Describe the smooth term (for GAMs) or non-linear predictors</p></a></li>
<li><a href='#efc'><p>Sample dataset from the EFC Survey</p></a></li>
<li><a href='#estimate_contrasts'><p>Estimate Marginal Contrasts</p></a></li>
<li><a href='#estimate_expectation'><p>Model-based predictions</p></a></li>
<li><a href='#estimate_grouplevel'><p>Group-specific parameters of mixed models random effects</p></a></li>
<li><a href='#estimate_means'><p>Estimate Marginal Means (Model-based average at each factor level)</p></a></li>
<li><a href='#estimate_slopes'><p>Estimate Marginal Effects</p></a></li>
<li><a href='#fish'><p>Sample data set</p></a></li>
<li><a href='#get_emcontrasts'><p>Consistent API for 'emmeans' and 'marginaleffects'</p></a></li>
<li><a href='#modelbased-options'><p>Global options from the modelbased package</p></a></li>
<li><a href='#pool_contrasts'><p>Pool contrasts and comparisons from <code>estimate_contrasts()</code></p></a></li>
<li><a href='#pool_predictions'><p>Pool Predictions and Estimated Marginal Means</p></a></li>
<li><a href='#print.estimate_contrasts'><p>Printing modelbased-objects</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#smoothing'><p>Smoothing a vector or a time series</p></a></li>
<li><a href='#visualisation_recipe.estimate_predicted'><p>Automated plotting for 'modelbased' objects</p></a></li>
<li><a href='#zero_crossings'><p>Find zero-crossings and inversion points</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimation of Model-Based Predictions, Contrasts and Means</td>
</tr>
<tr>
<td>Version:</td>
<td>0.10.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dominique Makowski &lt;dom.makowski@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements a general interface for model-based estimations
    for a wide variety of models, used in the computation of
    marginal means, contrast analysis and predictions. For a list of supported models,
    see 'insight::supported_models()'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://easystats.github.io/modelbased/">https://easystats.github.io/modelbased/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/easystats/modelbased/issues">https://github.com/easystats/modelbased/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bayestestR (&ge; 0.15.1), datawizard (&ge; 1.0.0), insight (&ge;
1.0.1), parameters (&ge; 0.24.1), graphics, stats, tools, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>BH, betareg, bootES, brms, coda, collapse, correlation, curl,
easystats, effectsize (&ge; 1.0.0), emmeans (&ge; 1.10.2), Formula,
gamm4, gganimate, ggplot2, glmmTMB, httr2, knitr, lme4,
lmerTest, logspline, MASS, Matrix, marginaleffects (&ge; 0.25.0),
mice, mgcv, nanoparquet, ordinal, performance (&ge; 0.13.0),
patchwork, pbkrtest, poorman, pscl, RcppEigen, report,
rmarkdown, rstanarm, rtdists, sandwich, see (&ge; 0.9.0),
testthat (&ge; 3.2.1), vdiffr, withr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>true</td>
</tr>
<tr>
<td>Config/Needs/check:</td>
<td>stan-dev/cmdstanr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>easystats/easystatstemplate</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-10 13:29:57 UTC; domma</td>
</tr>
<tr>
<td>Author:</td>
<td>Dominique Makowski
    <a href="https://orcid.org/0000-0001-5375-9967"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Daniel Lüdecke <a href="https://orcid.org/0000-0002-8895-3206"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Mattan S. Ben-Shachar
    <a href="https://orcid.org/0000-0002-4287-4801"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Indrajeet Patil <a href="https://orcid.org/0000-0003-1995-6531"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Rémi Thériault <a href="https://orcid.org/0000-0003-4315-6788"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-10 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='modelbased-package'>modelbased: Estimation of Model-Based Predictions, Contrasts and Means</h2><span id='topic+modelbased-package'></span><span id='topic+modelbased'></span>

<h3>Description</h3>

<p><code>modelbased</code> is a package helping with model-based estimations, to
easily compute of marginal means, contrast analysis and model predictions.
</p>


<h3>Details</h3>

<p><code>modelbased</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Dominique Makowski <a href="mailto:dom.makowski@gmail.com">dom.makowski@gmail.com</a> (<a href="https://orcid.org/0000-0001-5375-9967">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Daniel Lüdecke <a href="mailto:d.luedecke@uke.de">d.luedecke@uke.de</a> (<a href="https://orcid.org/0000-0002-8895-3206">ORCID</a>)
</p>
</li>
<li><p> Mattan S. Ben-Shachar <a href="mailto:matanshm@post.bgu.ac.il">matanshm@post.bgu.ac.il</a> (<a href="https://orcid.org/0000-0002-4287-4801">ORCID</a>)
</p>
</li>
<li><p> Indrajeet Patil <a href="mailto:patilindrajeet.science@gmail.com">patilindrajeet.science@gmail.com</a> (<a href="https://orcid.org/0000-0003-1995-6531">ORCID</a>)
</p>
</li>
<li><p> Rémi Thériault <a href="mailto:remi.theriault@mail.mcgill.ca">remi.theriault@mail.mcgill.ca</a> (<a href="https://orcid.org/0000-0003-4315-6788">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://easystats.github.io/modelbased/">https://easystats.github.io/modelbased/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/easystats/modelbased/issues">https://github.com/easystats/modelbased/issues</a>
</p>
</li></ul>


<hr>
<h2 id='.uniroot.all'>Copied from rootSolve package</h2><span id='topic+.uniroot.all'></span>

<h3>Description</h3>

<p>Copied from rootSolve package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.uniroot.all(
  f,
  interval,
  lower = min(interval),
  upper = max(interval),
  tol = .Machine$double.eps^0.2,
  maxiter = 1000,
  n = 100,
  ...
)
</code></pre>

<hr>
<h2 id='coffee_data'>Sample dataset from a course about analysis of factorial designs</h2><span id='topic+coffee_data'></span>

<h3>Description</h3>

<p>A sample data set from a course about the analysis of factorial
designs, by Mattan S. Ben-Shachar. See following link for more information:
https://github.com/mattansb/Analysis-of-Factorial-Designs-foR-Psychologists
</p>
<p>The data consists of five variables from 120 observations:
</p>

<ul>
<li> <p><code>ID</code>: A unique identifier for each participant
</p>
</li>
<li> <p><code>sex</code>: The participant's sex
</p>
</li>
<li> <p><code>time</code>: The time of day the participant was tested (morning, noon, or afternoon)
</p>
</li>
<li> <p><code>coffee</code>: Group indicator, whether participant drank coffee or not
(&quot;<code style="white-space: pre;">&#8288;coffee"&#8288;</code> or <code>"control"</code>).
</p>
</li>
<li> <p><code>alertness</code>: The participant's alertness score.
</p>
</li></ul>


<hr>
<h2 id='describe_nonlinear'>Describe the smooth term (for GAMs) or non-linear predictors</h2><span id='topic+describe_nonlinear'></span><span id='topic+describe_nonlinear.data.frame'></span><span id='topic+estimate_smooth'></span>

<h3>Description</h3>

<p>This function summarises the smooth term trend in terms of linear segments.
Using the approximate derivative, it separates a non-linear vector into
quasi-linear segments (in which the trend is either positive or negative).
Each of this segment its characterized by its beginning, end, size (in
proportion, relative to the total size) trend (the linear regression
coefficient) and linearity (the R2 of the linear regression).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>describe_nonlinear(data, ...)

## S3 method for class 'data.frame'
describe_nonlinear(data, x = NULL, y = NULL, ...)

estimate_smooth(data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="describe_nonlinear_+3A_data">data</code></td>
<td>
<p>The data containing the link, as for instance obtained by
<code><a href="#topic+estimate_relation">estimate_relation()</a></code>.</p>
</td></tr>
<tr><td><code id="describe_nonlinear_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from.</p>
</td></tr>
<tr><td><code id="describe_nonlinear_+3A_x">x</code>, <code id="describe_nonlinear_+3A_y">y</code></td>
<td>
<p>The name of the responses variable (<code>y</code>) predicting variable
(<code>x</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of linear description of non-linear terms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create data
data &lt;- data.frame(x = rnorm(200))
data$y &lt;- data$x^2 + rnorm(200, 0, 0.5)

model &lt;&lt;- lm(y ~ poly(x, 2), data = data)
link_data &lt;- estimate_relation(model, length = 100)

describe_nonlinear(link_data, x = "x")

</code></pre>

<hr>
<h2 id='efc'>Sample dataset from the EFC Survey</h2><span id='topic+efc'></span>

<h3>Description</h3>

<p>Selected variables from the EUROFAMCARE survey. Useful when
testing on &quot;real-life&quot; data sets, including random missing values. This
data set also has value and variable label attributes.
</p>

<hr>
<h2 id='estimate_contrasts'>Estimate Marginal Contrasts</h2><span id='topic+estimate_contrasts'></span><span id='topic+estimate_contrasts.default'></span>

<h3>Description</h3>

<p>Run a contrast analysis by estimating the differences between each level of a
factor. See also other related functions such as <code><a href="#topic+estimate_means">estimate_means()</a></code>
and <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_contrasts(model, ...)

## Default S3 method:
estimate_contrasts(
  model,
  contrast = NULL,
  by = NULL,
  predict = NULL,
  ci = 0.95,
  comparison = "pairwise",
  estimate = getOption("modelbased_estimate", "typical"),
  p_adjust = "none",
  transform = NULL,
  keep_iterations = FALSE,
  effectsize = NULL,
  iterations = 200,
  es_type = "cohens.d",
  backend = getOption("modelbased_backend", "marginaleffects"),
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_contrasts_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_...">...</code></td>
<td>
<p>Other arguments passed, for instance, to <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>,
to functions from the <strong>emmeans</strong> or <strong>marginaleffects</strong> package, or to process
Bayesian models via <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>. Examples:
</p>

<ul>
<li> <p><code>insight::get_datagrid()</code>: Argument such as <code>length</code>, <code>digits</code> or <code>range</code>
can be used to control the (number of) representative values.
</p>
</li>
<li> <p><strong>marginaleffects</strong>: Internally used functions are <code>avg_predictions()</code> for
means and contrasts, and <code>avg_slope()</code> for slopes. Therefore, arguments for
instance like <code>vcov</code>, <code>equivalence</code>, <code>df</code>, <code>slope</code> or even <code>newdata</code> can be
passed to those functions. A <code>weights</code> argument is passed to the <code>wts</code>
argument in <code>avg_predictions()</code> or <code>avg_slopes()</code>, however, weights can
only be applied when <code>estimate</code> is <code>"average"</code> or <code>"population"</code> (i.e. for
those marginalization options that do not use data grids). Other arguments,
such as <code>re.form</code> or <code>allow.new.levels</code>, may be passed to <code>predict()</code> (which
is internally used by <em>marginaleffects</em>) if supported by that model class.
</p>
</li>
<li> <p><strong>emmeans</strong>: Internally used functions are <code>emmeans()</code> and <code>emtrends()</code>.
Additional arguments can be passed to these functions.
</p>
</li>
<li><p> Bayesian models: For Bayesian models, parameters are cleaned using
<code>describe_posterior()</code>, thus, arguments like, for example, <code>centrality</code>,
<code>rope_range</code>, or <code>test</code> are passed to that function.
</p>
</li></ul>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_contrast">contrast</code></td>
<td>
<p>A character vector indicating the name of the variable(s) for
which to compute the contrasts, optionally including representative values or
levels at which contrasts are evaluated (e.g., <code>contrast="x=c('a','b')"</code>).</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_by">by</code></td>
<td>
<p>The (focal) predictor variable(s) at which to evaluate the desired
effect / mean / contrasts. Other predictors of the model that are not
included here will be collapsed and &quot;averaged&quot; over (the effect will be
estimated across them). <code>by</code> can be a character (vector) naming the focal
predictors, optionally including representative values or levels at which
focal predictors are evaluated (e.g., <code>by="x=c(1,2)"</code>). When <code>estimate</code> is
<em>not</em> <code>"average"</code>, the <code>by</code> argument is used to create a &quot;reference grid&quot; or
&quot;data grid&quot; with representative values for the focal predictors. In this
case, <code>by</code> can also be list of named elements. See details in
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code> to learn more about how to create data grids for
predictors of interest.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_predict">predict</code></td>
<td>
<p>Is passed to the <code>type</code> argument in <code>emmeans::emmeans()</code> (when
<code>backend = "emmeans"</code>) or in <code>marginaleffects::avg_predictions()</code> (when
<code>backend = "marginaleffects"</code>). For emmeans, see also
<a href="https://CRAN.R-project.org/package=emmeans/vignettes/transformations.html">this vignette</a>.
Valid options for <code>predict</code> are:
</p>

<ul>
<li> <p><code>backend = "marginaleffects"</code>: <code>predict</code> can be <code>"response"</code>, <code>"link"</code>,
<code>"inverse_link"</code> or any valid <code>type</code> option supported by model's class
<code>predict()</code> method (e.g., for zero-inflation models from package
<strong>glmmTMB</strong>, you can choose <code>predict = "zprob"</code> or <code>predict = "conditional"</code>
etc., see <a href="glmmTMB.html#topic+predict.glmmTMB">glmmTMB::predict.glmmTMB</a>). By default, when <code>predict = NULL</code>,
the most appropriate transformation is selected, which usually returns
predictions or contrasts on the response-scale. The <code>"inverse_link"</code> is a
special option, comparable to <em>marginaleffects</em>' <code>invlink(link)</code> option. It
will calculate predictions on the link scale and then back-transform to the
response scale.
</p>
</li>
<li> <p><code>backend = "emmeans"</code>: <code>predict</code> can be <code>"response"</code>, <code>"link"</code>, <code>"mu"</code>,
<code>"unlink"</code>, or <code>"log"</code>. If <code>predict = NULL</code> (default), the most appropriate
transformation is selected (which usually is <code>"response"</code>).
</p>
</li></ul>

<p><code>"link"</code> will leave the values on scale of the linear predictors.
<code>"response"</code> (or <code>NULL</code>) will transform them on scale of the response
variable. Thus for a logistic model, <code>"link"</code> will give estimations expressed
in log-odds (probabilities on logit scale) and <code>"response"</code> in terms of
probabilities. To predict distributional parameters (called &quot;dpar&quot; in other
packages), for instance when using complex formulae in <code>brms</code> models, the
<code>predict</code> argument can take the value of the parameter you want to estimate,
for instance <code>"sigma"</code>, <code>"kappa"</code>, etc.
</p>
<p><code>"response"</code> and <code>"inverse_link"</code> both return predictions on the response
scale, however, <code>"response"</code> first calculates predictions on the response
scale for each observation and <em>then</em> aggregates them by groups or levels
defined in <code>by</code>. <code>"inverse_link"</code> first calculates predictions on the link
scale for each observation, then aggregates them by groups or levels defined
in <code>by</code>, and finally back-transforms the predictions to the response scale.
Both approaches have advantages and disadvantages. <code>"response"</code> usually
produces less biased predictions, but confidence intervals might be outside
reasonable bounds (i.e., for instance can be negative for count data). The
<code>"inverse_link"</code> approach is more robust in terms of confidence intervals, but
might produce biased predictions. In particular for mixed models, using
<code>"response"</code> is recommended, because averaging across random effects groups
is more accurate.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_comparison">comparison</code></td>
<td>
<p>Specify the type of contrasts or tests that should be
carried out.
</p>

<ul>
<li><p> When <code>backend = "emmeans"</code>, can be one of <code>"pairwise"</code>, <code>"poly"</code>,
<code>"consec"</code>, <code>"eff"</code>, <code>"del.eff"</code>, <code>"mean_chg"</code>, <code>"trt.vs.ctrl"</code>,
<code>"dunnett"</code>, <code>"wtcon"</code> and some more. See also <code>method</code> argument in
<a href="emmeans.html#topic+contrast">emmeans::contrast</a> and the <code>?emmeans::emmc-functions</code>.
</p>
</li>
<li><p> For <code>backend = "marginaleffects"</code>, can be a numeric value, vector, or
matrix, a string equation specifying the hypothesis to test, a string
naming the comparison method, a formula, or a function. Strings, string
equations and formula are probably the most common options and described
below. For other options and detailed descriptions of those options, see
also <a href="marginaleffects.html#topic+comparisons">marginaleffects::comparisons</a> and
<a href="https://marginaleffects.com/bonus/hypothesis.html">this website</a>.
</p>

<ul>
<li><p> String: One of <code>"pairwise"</code>, <code>"reference"</code>, <code>"sequential"</code>, <code>"meandev"</code>
<code>"meanotherdev"</code>, <code>"poly"</code>, <code>"helmert"</code>, or <code>"trt_vs_ctrl"</code>.
</p>
</li>
<li><p> String equation: To identify parameters from the output, either specify
the term name, or <code>"b1"</code>, <code>"b2"</code> etc. to indicate rows, e.g.:<code>"hp = drat"</code>,
<code>"b1 = b2"</code>, or <code>"b1 + b2 + b3 = 0"</code>.
</p>
</li>
<li><p> Formula: A formula like <code>comparison ~ pairs | group</code>, where the left-hand
side indicates the type of comparison (<code>difference</code> or <code>ratio</code>), the
right-hand side determines the pairs of estimates to compare (<code>reference</code>,
<code>sequential</code>, <code>meandev</code>, etc., see string-options). Optionally, comparisons
can be carried out within subsets by indicating the grouping variable
after a vertical bar ( <code>|</code>).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_estimate">estimate</code></td>
<td>
<p>The <code>estimate</code> argument determines how predictions are
averaged (&quot;marginalized&quot;) over variables not specified in <code>by</code> or <code>contrast</code>
(non-focal predictors). It controls whether predictions represent a &quot;typical&quot;
individual, an &quot;average&quot; individual from the sample, or an &quot;average&quot;
individual from a broader population.
</p>

<ul>
<li> <p><code>"typical"</code> (Default): Calculates predictions for a balanced data grid
representing all combinations of focal predictor levels (specified in <code>by</code>).
For non-focal numeric predictors, it uses the mean; for non-focal
categorical predictors, it marginalizes (averages) over the levels. This
represents a &quot;typical&quot; observation based on the data grid and is useful for
comparing groups. It answers: &quot;What would the average outcome be for a
'typical' observation?&quot;. This is the default approach when estimating
marginal means using the <em>emmeans</em> package.
</p>
</li>
<li> <p><code>"average"</code>: Calculates predictions for each observation in the sample and
then averages these predictions within each group defined by the focal
predictors. This reflects the sample's actual distribution of non-focal
predictors, not a balanced grid. It answers: &quot;What is the predicted value
for an average observation in my data?&quot;
</p>
</li>
<li> <p><code>"population"</code>: &quot;Clones&quot; each observation, creating copies with all
possible combinations of focal predictor levels. It then averages the
predictions across these &quot;counterfactual&quot; observations (non-observed
permutations) within each group. This extrapolates to a hypothetical
broader population, considering &quot;what if&quot; scenarios. It answers: &quot;What is
the predicted response for the 'average' observation in a broader possible
target population?&quot; This approach entails more assumptions about the
likelihood of different combinations, but can be more apt to generalize.
This is also the option that should be used for <strong>G-computation</strong>
(<em>Chatton and Rohrer 2024</em>).
</p>
</li></ul>

<p>You can set a default option for the <code>estimate</code> argument via <code>options()</code>,
e.g. <code>options(modelbased_estimate = "average")</code></p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_p_adjust">p_adjust</code></td>
<td>
<p>The p-values adjustment method for frequentist multiple
comparisons. Can be one of <code>"none"</code> (default), <code>"hochberg"</code>, <code>"hommel"</code>,
<code>"bonferroni"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>, <code>"tukey"</code>, <code>"sidak"</code>, <code>"esarey"</code> or
<code>"holm"</code>. The <code>"esarey"</code> option is specifically for the case of Johnson-Neyman
intervals, i.e. when calling <code>estimate_slopes()</code> with two numeric predictors
in an interaction term. Details for the other options can be found in the
p-value adjustment section of the <code>emmeans::test</code> documentation or
<code>?stats::p.adjust</code>.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_transform">transform</code></td>
<td>
<p>A function applied to predictions and confidence intervals
to (back-) transform results, which can be useful in case the regression
model has a transformed response variable (e.g., <code>lm(log(y) ~ x)</code>). For
Bayesian models, this function is applied to individual draws from the
posterior distribution, before computing summaries. Can also be <code>TRUE</code>, in
which case <code>insight::get_transformation()</code> is called to determine the
appropriate transformation-function. Note that no standard errors are returned
when transformations are applied.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_keep_iterations">keep_iterations</code></td>
<td>
<p>If <code>TRUE</code>, will keep all iterations (draws) of
bootstrapped or Bayesian models. They will be added as additional columns
named <code>iter_1</code>, <code>iter_2</code>, and so on. If <code>keep_iterations</code> is a positive
number, only as many columns as indicated in <code>keep_iterations</code> will be added
to the output. You can reshape them to a long format by running
<code><a href="bayestestR.html#topic+reshape_iterations">bayestestR::reshape_iterations()</a></code>.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_effectsize">effectsize</code></td>
<td>
<p>Desired measure of standardized effect size, one of
<code>"emmeans"</code>, <code>"marginal"</code>, or <code>"boot"</code>. Default is <code>NULL</code>, i.e. no effect
size will be computed.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap resamples to perform.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_es_type">es_type</code></td>
<td>
<p>Specifies the type of effect-size measure to estimate when
using <code>effectsize = "boot"</code>. One of <code>"unstandardized"</code>, <code>"cohens.d"</code>,
<code>"hedges.g"</code>, <code>"cohens.d.sigma"</code>, <code>"r"</code>, or <code>"akp.robust.d"</code>. See<code> effect.type</code> argument of <a href="bootES.html#topic+bootES">bootES::bootES</a> for details.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_backend">backend</code></td>
<td>
<p>Whether to use <code>"marginaleffects"</code> or <code>"emmeans"</code>as a backend.
Results are usually very similar. The major difference will be found for mixed
models, where <code>backend = "marginaleffects"</code> will also average across random
effects levels, producing &quot;marginal predictions&quot; (instead of &quot;conditional
predictions&quot;, see Heiss 2022).
</p>
<p>You can set a default backend via <code>options()</code>, e.g. use
<code>options(modelbased_backend = "emmeans")</code> to use the <strong>emmeans</strong> package or
<code>options(modelbased_backend = "marginaleffects")</code> to set <strong>marginaleffects</strong>
as default backend.</p>
</td></tr>
<tr><td><code id="estimate_contrasts_+3A_verbose">verbose</code></td>
<td>
<p>Use <code>FALSE</code> to silence messages and warnings.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>, <code><a href="#topic+estimate_means">estimate_means()</a></code> and <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>
functions are forming a group, as they are all based on <em>marginal</em>
estimations (estimations based on a model). All three are built on the
<strong>emmeans</strong> or <strong>marginaleffects</strong> package (depending on the <code>backend</code>
argument), so reading its documentation (for instance <code><a href="emmeans.html#topic+emmeans">emmeans::emmeans()</a></code>,
<code><a href="emmeans.html#topic+emtrends">emmeans::emtrends()</a></code> or this <a href="https://marginaleffects.com/">website</a>) is
recommended to understand the idea behind these types of procedures.
</p>

<ul>
<li><p> Model-based <strong>predictions</strong> is the basis for all that follows. Indeed,
the first thing to understand is how models can be used to make predictions
(see <code><a href="#topic+estimate_link">estimate_link()</a></code>). This corresponds to the predicted response (or
&quot;outcome variable&quot;) given specific predictor values of the predictors (i.e.,
given a specific data configuration). This is why the concept of <code><a href="insight.html#topic+get_datagrid">reference grid()</a></code> is so important for direct predictions.
</p>
</li>
<li> <p><strong>Marginal &quot;means&quot;</strong>, obtained via <code><a href="#topic+estimate_means">estimate_means()</a></code>, are an extension
of such predictions, allowing to &quot;average&quot; (collapse) some of the predictors,
to obtain the average response value at a specific predictors configuration.
This is typically used when some of the predictors of interest are factors.
Indeed, the parameters of the model will usually give you the intercept value
and then the &quot;effect&quot; of each factor level (how different it is from the
intercept). Marginal means can be used to directly give you the mean value of
the response variable at all the levels of a factor. Moreover, it can also be
used to control, or average over predictors, which is useful in the case of
multiple predictors with or without interactions.
</p>
</li>
<li> <p><strong>Marginal contrasts</strong>, obtained via <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>, are
themselves at extension of marginal means, in that they allow to investigate
the difference (i.e., the contrast) between the marginal means. This is,
again, often used to get all pairwise differences between all levels of a
factor. It works also for continuous predictors, for instance one could also
be interested in whether the difference at two extremes of a continuous
predictor is significant.
</p>
</li>
<li><p> Finally, <strong>marginal effects</strong>, obtained via <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>, are
different in that their focus is not values on the response variable, but the
model's parameters. The idea is to assess the effect of a predictor at a
specific configuration of the other predictors. This is relevant in the case
of interactions or non-linear relationships, when the effect of a predictor
variable changes depending on the other predictors. Moreover, these effects
can also be &quot;averaged&quot; over other predictors, to get for instance the
&quot;general trend&quot; of a predictor over different factor levels.
</p>
</li></ul>

<p><strong>Example:</strong> Let's imagine the following model <code>lm(y ~ condition * x)</code> where
<code>condition</code> is a factor with 3 levels A, B and C and <code>x</code> a continuous
variable (like age for example). One idea is to see how this model performs,
and compare the actual response y to the one predicted by the model (using
<code><a href="#topic+estimate_expectation">estimate_expectation()</a></code>). Another idea is evaluate the average mean at each of
the condition's levels (using <code><a href="#topic+estimate_means">estimate_means()</a></code>), which can be useful to
visualize them. Another possibility is to evaluate the difference between
these levels (using <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>). Finally, one could also estimate
the effect of x averaged over all conditions, or instead within each
condition (<code>using [estimate_slopes]</code>).
</p>


<h3>Value</h3>

<p>A data frame of estimated contrasts.
</p>


<h3>Effect Size</h3>

<p>By default, <code>estimate_contrasts()</code> reports no standardized effect size on
purpose. Should one request one, some things are to keep in mind. As the
authors of <em>emmeans</em> write, &quot;There is substantial disagreement among
practitioners on what is the appropriate sigma to use in computing effect
sizes; or, indeed, whether any effect-size measure is appropriate for some
situations. The user is completely responsible for specifying appropriate
parameters (or for failing to do so).&quot;
</p>
<p>In particular, effect size method <code>"boot"</code> does not correct for covariates
in the model, so should probably only be used when there is just one
categorical predictor (with however many levels). Some believe that if there
are multiple predictors or any covariates, it is important to re-compute
sigma adding back in the response variance associated with the variables that
aren't part of the contrast.
</p>
<p><code>effectsize = "emmeans"</code> uses <a href="emmeans.html#topic+eff_size">emmeans::eff_size</a> with
<code>sigma = stats::sigma(model)</code>, <code>edf = stats::df.residual(model)</code> and
<code>method = "identity"</code>. This standardizes using the MSE (sigma). Some believe
this works when the contrasts are the only predictors in the model, but not
when there are covariates. The response variance accounted for by the
covariates should not be removed from the SD used to standardize. Otherwise,
<em>d</em> will be overestimated.
</p>
<p><code>effectsize = "marginal"</code> uses the following formula to compute effect
size: <code>d_adj &lt;- difference * (1- R2)/ sigma</code>. This standardizes
using the response SD with only the between-groups variance on the focal
factor/contrast removed. This allows for groups to be equated on their
covariates, but creates an appropriate scale for standardizing the response.
</p>
<p><code>effectsize = "boot"</code> uses bootstrapping (defaults to a low value of
200) through <a href="bootES.html#topic+bootES">bootES::bootES</a>. Adjusts for contrasts, but not for covariates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# Basic usage
model &lt;- lm(Sepal.Width ~ Species, data = iris)
estimate_contrasts(model)

# Dealing with interactions
model &lt;- lm(Sepal.Width ~ Species * Petal.Width, data = iris)

# By default: selects first factor
estimate_contrasts(model)

# Can also run contrasts between points of numeric, stratified by "Species"
estimate_contrasts(model, contrast = "Petal.Width", by = "Species")

# Or both
estimate_contrasts(model, contrast = c("Species", "Petal.Width"), length = 2)

# Or with custom specifications
estimate_contrasts(model, contrast = c("Species", "Petal.Width=c(1, 2)"))

# Or modulate it
estimate_contrasts(model, by = "Petal.Width", length = 4)

# Standardized differences
estimated &lt;- estimate_contrasts(lm(Sepal.Width ~ Species, data = iris))
standardize(estimated)

# Other models (mixed, Bayesian, ...)
data &lt;- iris
data$Petal.Length_factor &lt;- ifelse(data$Petal.Length &lt; 4.2, "A", "B")

model &lt;- lme4::lmer(Sepal.Width ~ Species + (1 | Petal.Length_factor), data = data)
estimate_contrasts(model)

data &lt;- mtcars
data$cyl &lt;- as.factor(data$cyl)
data$am &lt;- as.factor(data$am)

model &lt;- rstanarm::stan_glm(mpg ~ cyl * wt, data = data, refresh = 0)
estimate_contrasts(model)
estimate_contrasts(model, by = "wt", length = 4)

model &lt;- rstanarm::stan_glm(
  Sepal.Width ~ Species + Petal.Width + Petal.Length,
  data = iris,
  refresh = 0
)
estimate_contrasts(model, by = "Petal.Length=[sd]", test = "bf")

## End(Not run)

</code></pre>

<hr>
<h2 id='estimate_expectation'>Model-based predictions</h2><span id='topic+estimate_expectation'></span><span id='topic+estimate_link'></span><span id='topic+estimate_prediction'></span><span id='topic+estimate_relation'></span>

<h3>Description</h3>

<p>After fitting a model, it is useful generate model-based estimates of the
response variables for different combinations of predictor values. Such
estimates can be used to make inferences about <strong>relationships</strong> between
variables, to make predictions about individual cases, or to compare the
<strong>predicted</strong> values against the observed data.
</p>
<p>The <code>modelbased</code> package includes 4 &quot;related&quot; functions, that mostly differ in
their default arguments (in particular, <code>data</code> and <code>predict</code>):
</p>

<ul>
<li> <p><code>estimate_prediction(data = NULL, predict = "prediction", ...)</code>
</p>
</li>
<li> <p><code>estimate_expectation(data = NULL, predict = "expectation", ...)</code>
</p>
</li>
<li> <p><code>estimate_relation(data = "grid", predict = "expectation", ...)</code>
</p>
</li>
<li> <p><code>estimate_link(data = "grid", predict = "link", ...)</code>
</p>
</li></ul>

<p>While they are all based on model-based predictions (using
<code><a href="insight.html#topic+get_predicted">insight::get_predicted()</a></code>), they differ in terms of the <strong>type</strong> of
predictions they make by default. For instance, <code>estimate_prediction()</code> and
<code>estimate_expectation()</code> return predictions for the original data used to fit
the model, while <code>estimate_relation()</code> and <code>estimate_link()</code> return
predictions on a <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>. Similarly, <code>estimate_link</code>
returns predictions on the link scale, while the others return predictions on
the response scale. Note that the relevance of these differences depends on
the model family (for instance, for linear models, <code>estimate_relation</code> is
equivalent to <code>estimate_link()</code>, since there is no difference between the
link-scale and the response scale).
</p>
<p>Note that you can run <code><a href="#topic+visualisation_recipe.estimate_predicted">plot()</a></code> on
the output of these functions to get some visual insights (see the
<a href="#topic+visualisation_recipe.estimate_predicted">plotting examples</a>).
</p>
<p>See the <strong>details</strong> section below for details about the different possibilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_expectation(
  model,
  data = NULL,
  by = NULL,
  predict = "expectation",
  ci = 0.95,
  transform = NULL,
  keep_iterations = FALSE,
  ...
)

estimate_link(
  model,
  data = "grid",
  by = NULL,
  predict = "link",
  ci = 0.95,
  transform = NULL,
  keep_iterations = FALSE,
  ...
)

estimate_prediction(
  model,
  data = NULL,
  by = NULL,
  predict = "prediction",
  ci = 0.95,
  transform = NULL,
  keep_iterations = FALSE,
  ...
)

estimate_relation(
  model,
  data = "grid",
  by = NULL,
  predict = "expectation",
  ci = 0.95,
  transform = NULL,
  keep_iterations = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_expectation_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_data">data</code></td>
<td>
<p>A data frame with model's predictors to estimate the response. If
<code>NULL</code>, the model's data is used. If <code>"grid"</code>, the model matrix is obtained
(through <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>).</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_by">by</code></td>
<td>
<p>The predictor variable(s) at which to estimate the response. Other
predictors of the model that are not included here will be set to their mean
value (for numeric predictors), reference level (for factors) or mode (other
types). The <code>by</code> argument will be used to create a data grid via
<code>insight::get_datagrid()</code>, which will then be used as <code>data</code> argument. Thus,
you cannot specify both <code>data</code> and <code>by</code> but only of these two arguments.</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_predict">predict</code></td>
<td>
<p>This parameter controls what is predicted (and gets internally
passed to <code><a href="insight.html#topic+get_predicted">insight::get_predicted()</a></code>). In most cases, you don't need to care
about it: it is changed automatically according to the different predicting
functions (i.e., <code>estimate_expectation()</code>, <code>estimate_prediction()</code>, <code>estimate_link()</code>
or <code>estimate_relation()</code>). The only time you might be interested in manually
changing it is to estimate other distributional parameters (called &quot;dpar&quot; in
other packages) - for instance when using complex formulae in <code>brms</code> models.
The <code>predict</code> argument can then be set to the parameter you want to
estimate, for instance <code>"sigma"</code>, <code>"kappa"</code>, etc. Note that the distinction
between <code>"expectation"</code>, <code>"link"</code> and <code>"prediction"</code> does not then apply (as
you are directly predicting the value of some distributional parameter), and
the corresponding functions will then only differ in the default value of
their <code>data</code> argument.</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_transform">transform</code></td>
<td>
<p>A function applied to predictions and confidence intervals
to (back-) transform results, which can be useful in case the regression
model has a transformed response variable (e.g., <code>lm(log(y) ~ x)</code>). Can also
be <code>TRUE</code>, in which case <code>insight::get_transformation()</code> is called to
determine the appropriate transformation-function. Note that no standard
errors are returned when transformations are applied.</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_keep_iterations">keep_iterations</code></td>
<td>
<p>If <code>TRUE</code>, will keep all iterations (draws) of
bootstrapped or Bayesian models. They will be added as additional columns
named <code>iter_1</code>, <code>iter_2</code>, and so on. If <code>keep_iterations</code> is a positive
number, only as many columns as indicated in <code>keep_iterations</code> will be added
to the output. You can reshape them to a long format by running
<code><a href="bayestestR.html#topic+reshape_iterations">bayestestR::reshape_iterations()</a></code>.</p>
</td></tr>
<tr><td><code id="estimate_expectation_+3A_...">...</code></td>
<td>
<p>You can add all the additional control arguments from
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code> (used when <code>data = "grid"</code>) and
<code><a href="insight.html#topic+get_predicted">insight::get_predicted()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of predicted values and uncertainty intervals, with
class <code>"estimate_predicted"</code>. Methods for <code><a href="#topic+visualisation_recipe.estimate_predicted">visualisation_recipe()</a></code>
and <code><a href="#topic+visualisation_recipe.estimate_predicted">plot()</a></code> are available.
</p>


<h3>Expected (average) values</h3>

<p>The most important way that various types of response estimates differ is in
terms of what quantity is being estimated and the meaning of the uncertainty
intervals. The major choices are <strong>expected values</strong> for uncertainty in the
regression line and <strong>predicted values</strong> for uncertainty in the individual
case predictions.
</p>
<p><strong>Expected values</strong> refer to the fitted regression line - the estimated
<em>average</em> response value (i.e., the &quot;expectation&quot;) for individuals with
specific predictor values. For example, in a linear model <em>y</em> = 2 + 3<em>x</em> +
4<em>z</em> + <em>e</em>, the estimated average <em>y</em> for individuals with <em>x</em> = 1 and <em>z</em> =
2 is 11.
</p>
<p>For expected values, uncertainty intervals refer to uncertainty in the
estimated <strong>conditional average</strong> (where might the true regression line
actually fall)? Uncertainty intervals for expected values are also called
&quot;confidence intervals&quot;.
</p>
<p>Expected values and their uncertainty intervals are useful for describing the
relationship between variables and for describing how precisely a model has
been estimated.
</p>
<p>For generalized linear models, expected values are reported on one of two scales:
</p>

<ul>
<li><p> The <strong>link scale</strong> refers to scale of the fitted regression line, after
transformation by the link function. For example, for a logistic regression
(logit binomial) model, the link scale gives expected log-odds. For a
log-link Poisson model, the link scale gives the expected log-count.
</p>
</li>
<li><p> The <strong>response scale</strong> refers to the original scale of the response
variable (i.e., without any link function transformation). Expected values
on the link scale are back-transformed to the original response variable
metric (e.g., expected probabilities for binomial models, expected counts
for Poisson models).
</p>
</li></ul>



<h3>Individual case predictions</h3>

<p>In contrast to expected values, <strong>predicted values</strong> refer to predictions for
<strong>individual cases</strong>. Predicted values are also called &quot;posterior
predictions&quot; or &quot;posterior predictive draws&quot;.
</p>
<p>For predicted values, uncertainty intervals refer to uncertainty in the
<strong>individual response values for each case</strong> (where might any single case
actually fall)? Uncertainty intervals for predicted values are also called
&quot;prediction intervals&quot; or &quot;posterior predictive intervals&quot;.
</p>
<p>Predicted values and their uncertainty intervals are useful for forecasting
the range of values that might be observed in new data, for making decisions
about individual cases, and for checking if model predictions are reasonable
(&quot;posterior predictive checks&quot;).
</p>
<p>Predicted values and intervals are always on the scale of the original
response variable (not the link scale).
</p>


<h3>Functions for estimating predicted values and uncertainty</h3>

<p><em>modelbased</em> provides 4 functions for generating model-based response
estimates and their uncertainty:
</p>

<ul>
<li> <p><strong><code>estimate_expectation()</code></strong>:
</p>

<ul>
<li><p> Generates <strong>expected values</strong> (conditional average) on the <strong>response scale</strong>.
</p>
</li>
<li><p> The uncertainty interval is a <em>confidence interval</em>.
</p>
</li>
<li><p> By default, values are computed using the data used to fit the model.
</p>
</li></ul>

</li>
<li> <p><strong><code>estimate_link()</code></strong>:
</p>

<ul>
<li><p> Generates <strong>expected values</strong> (conditional average) on the <strong>link scale</strong>.
</p>
</li>
<li><p> The uncertainty interval is a <em>confidence interval</em>.
</p>
</li>
<li><p> By default, values are computed using a reference grid spanning the
observed range of predictor values (see <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>).
</p>
</li></ul>

</li>
<li> <p><strong><code>estimate_prediction()</code></strong>:
</p>

<ul>
<li><p> Generates <strong>predicted values</strong> (for individual cases) on the <strong>response scale</strong>.
</p>
</li>
<li><p> The uncertainty interval is a <em>prediction interval</em>.
</p>
</li>
<li><p> By default, values are computed using the data used to fit the model.
</p>
</li></ul>

</li>
<li> <p><strong><code>estimate_relation()</code></strong>:
</p>

<ul>
<li><p> Like <code>estimate_expectation()</code>.
</p>
</li>
<li><p> Useful for visualizing a model.
</p>
</li>
<li><p> Generates <strong>expected values</strong> (conditional average) on the <strong>response scale</strong>.
</p>
</li>
<li><p> The uncertainty interval is a <em>confidence interval</em>.
</p>
</li>
<li><p> By default, values are computed using a reference grid spanning the
observed range of predictor values (see <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>).
</p>
</li></ul>

</li></ul>



<h3>Data for predictions</h3>

<p>If the <code>data = NULL</code>, values are estimated using the data used to fit the
model. If <code>data = "grid"</code>, values are computed using a reference grid
spanning the observed range of predictor values with
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>. This can be useful for model visualization. The
number of predictor values used for each variable can be controlled with the
<code>length</code> argument. <code>data</code> can also be a data frame containing columns with
names matching the model frame (see <code><a href="insight.html#topic+get_data">insight::get_data()</a></code>). This can be used
to generate model predictions for specific combinations of predictor values.
</p>


<h3>Note</h3>

<p>These functions are built on top of <code><a href="insight.html#topic+get_predicted">insight::get_predicted()</a></code> and correspond
to different specifications of its parameters. It may be useful to read its
<a href="https://easystats.github.io/insight/reference/get_predicted.html">documentation</a>,
in particular the description of the <code>predict</code> argument for additional
details on the difference between expected vs. predicted values and link vs.
response scales.
</p>
<p>Additional control parameters can be used to control results from
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code> (when <code>data = "grid"</code>) and from
<code><a href="insight.html#topic+get_predicted">insight::get_predicted()</a></code> (the function used internally to compute
predictions).
</p>
<p>For plotting, check the examples in <code><a href="#topic+visualisation_recipe">visualisation_recipe()</a></code>. Also check out
the <a href="https://easystats.github.io/modelbased/articles/">Vignettes</a> and <a href="https://easystats.github.io/modelbased/index.html#features">README examples</a> for
various examples, tutorials and usecases.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(modelbased)

# Linear Models
model &lt;- lm(mpg ~ wt, data = mtcars)

# Get predicted and prediction interval (see insight::get_predicted)
estimate_expectation(model)

# Get expected values with confidence interval
pred &lt;- estimate_relation(model)
pred

# Visualisation (see visualisation_recipe())
plot(pred)

# Standardize predictions
pred &lt;- estimate_relation(lm(mpg ~ wt + am, data = mtcars))
z &lt;- standardize(pred, include_response = FALSE)
z
unstandardize(z, include_response = FALSE)

# Logistic Models
model &lt;- glm(vs ~ wt, data = mtcars, family = "binomial")
estimate_expectation(model)
estimate_relation(model)

# Mixed models
model &lt;- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars)
estimate_expectation(model)
estimate_relation(model)

# Bayesian models

model &lt;- suppressWarnings(rstanarm::stan_glm(
  mpg ~ wt,
  data = mtcars, refresh = 0, iter = 200
))
estimate_expectation(model)
estimate_relation(model)


</code></pre>

<hr>
<h2 id='estimate_grouplevel'>Group-specific parameters of mixed models random effects</h2><span id='topic+estimate_grouplevel'></span><span id='topic+reshape_grouplevel'></span>

<h3>Description</h3>

<p>Extract random parameters of each individual group in the context of mixed
models, commonly referred to as BLUPs (Best Linear Unbiased Predictors).
Can be reshaped to be of the same dimensions as the original data,
which can be useful to add the random effects to the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_grouplevel(model, type = "random", ...)

reshape_grouplevel(x, indices = "all", group = "all", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_grouplevel_+3A_model">model</code></td>
<td>
<p>A mixed model with random effects.</p>
</td></tr>
<tr><td><code id="estimate_grouplevel_+3A_type">type</code></td>
<td>
<p><code>"random"</code> or <code>"total"</code>. If <code>"random"</code> (default), the coefficients correspond to the
conditional estimates of  the random effects (as they are returned by
<code>lme4::ranef()</code>). They typically correspond to the deviation of each
individual group from their fixed effect (assuming the random effect is
also included as a fixed effect). As such, a coefficient close to 0
means that the participants' effect is the same as the population-level
effect (in other words, it is &quot;in the norm&quot;). If <code>"total"</code>, it will return
the sum of the random effect and its corresponding fixed effects, which
internally relies on the <code>coef()</code> method (see <code>?coef.merMod</code>). Note that
<code>type = "total"</code> yet does not return uncertainty indices (such as SE and CI)
for models from <em>lme4</em> or <em>glmmTMB</em>, as the necessary information to
compute them is not yet available. However, for Bayesian models, it is
possible to compute them.</p>
</td></tr>
<tr><td><code id="estimate_grouplevel_+3A_...">...</code></td>
<td>
<p>Other arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="estimate_grouplevel_+3A_x">x</code></td>
<td>
<p>The output of <code>estimate_grouplevel()</code>.</p>
</td></tr>
<tr><td><code id="estimate_grouplevel_+3A_indices">indices</code></td>
<td>
<p>A list containing the indices to extract (e.g., &quot;Coefficient&quot;).</p>
</td></tr>
<tr><td><code id="estimate_grouplevel_+3A_group">group</code></td>
<td>
<p>A list containing the random factors to select.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike raw group means, BLUPs apply shrinkage: they are a compromise between
the group estimate and the population estimate. This improves generalizability
and prevents overfitting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# lme4 model
data(mtcars)
model &lt;- lme4::lmer(mpg ~ hp + (1 | carb), data = mtcars)
random &lt;- estimate_grouplevel(model)

# Show group-specific effects
random

# Visualize random effects
plot(random)

# Reshape to wide data so that it matches the original dataframe...
reshaped &lt;- reshape_grouplevel(random, indices = c("Coefficient", "SE"))

# ...and can be easily combined with the original data
alldata &lt;- cbind(mtcars, reshaped)

# Use summary() to remove duplicated rows
summary(reshaped)

# overall coefficients
estimate_grouplevel(model, type = "total")

</code></pre>

<hr>
<h2 id='estimate_means'>Estimate Marginal Means (Model-based average at each factor level)</h2><span id='topic+estimate_means'></span>

<h3>Description</h3>

<p>Estimate average value of response variable at each factor level or
representative value, respectively at values defined in a &quot;data grid&quot; or
&quot;reference grid&quot;. For plotting, check the examples in
<code><a href="#topic+visualisation_recipe">visualisation_recipe()</a></code>. See also other related functions such as
<code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code> and <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_means(
  model,
  by = "auto",
  predict = NULL,
  ci = 0.95,
  estimate = getOption("modelbased_estimate", "typical"),
  transform = NULL,
  keep_iterations = FALSE,
  backend = getOption("modelbased_backend", "marginaleffects"),
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_means_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_by">by</code></td>
<td>
<p>The (focal) predictor variable(s) at which to evaluate the desired
effect / mean / contrasts. Other predictors of the model that are not
included here will be collapsed and &quot;averaged&quot; over (the effect will be
estimated across them). <code>by</code> can be a character (vector) naming the focal
predictors, optionally including representative values or levels at which
focal predictors are evaluated (e.g., <code>by="x=c(1,2)"</code>). When <code>estimate</code> is
<em>not</em> <code>"average"</code>, the <code>by</code> argument is used to create a &quot;reference grid&quot; or
&quot;data grid&quot; with representative values for the focal predictors. In this
case, <code>by</code> can also be list of named elements. See details in
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code> to learn more about how to create data grids for
predictors of interest.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_predict">predict</code></td>
<td>
<p>Is passed to the <code>type</code> argument in <code>emmeans::emmeans()</code> (when
<code>backend = "emmeans"</code>) or in <code>marginaleffects::avg_predictions()</code> (when
<code>backend = "marginaleffects"</code>). For emmeans, see also
<a href="https://CRAN.R-project.org/package=emmeans/vignettes/transformations.html">this vignette</a>.
Valid options for <code>predict</code> are:
</p>

<ul>
<li> <p><code>backend = "marginaleffects"</code>: <code>predict</code> can be <code>"response"</code>, <code>"link"</code>,
<code>"inverse_link"</code> or any valid <code>type</code> option supported by model's class
<code>predict()</code> method (e.g., for zero-inflation models from package
<strong>glmmTMB</strong>, you can choose <code>predict = "zprob"</code> or <code>predict = "conditional"</code>
etc., see <a href="glmmTMB.html#topic+predict.glmmTMB">glmmTMB::predict.glmmTMB</a>). By default, when <code>predict = NULL</code>,
the most appropriate transformation is selected, which usually returns
predictions or contrasts on the response-scale. The <code>"inverse_link"</code> is a
special option, comparable to <em>marginaleffects</em>' <code>invlink(link)</code> option. It
will calculate predictions on the link scale and then back-transform to the
response scale.
</p>
</li>
<li> <p><code>backend = "emmeans"</code>: <code>predict</code> can be <code>"response"</code>, <code>"link"</code>, <code>"mu"</code>,
<code>"unlink"</code>, or <code>"log"</code>. If <code>predict = NULL</code> (default), the most appropriate
transformation is selected (which usually is <code>"response"</code>).
</p>
</li></ul>

<p><code>"link"</code> will leave the values on scale of the linear predictors.
<code>"response"</code> (or <code>NULL</code>) will transform them on scale of the response
variable. Thus for a logistic model, <code>"link"</code> will give estimations expressed
in log-odds (probabilities on logit scale) and <code>"response"</code> in terms of
probabilities. To predict distributional parameters (called &quot;dpar&quot; in other
packages), for instance when using complex formulae in <code>brms</code> models, the
<code>predict</code> argument can take the value of the parameter you want to estimate,
for instance <code>"sigma"</code>, <code>"kappa"</code>, etc.
</p>
<p><code>"response"</code> and <code>"inverse_link"</code> both return predictions on the response
scale, however, <code>"response"</code> first calculates predictions on the response
scale for each observation and <em>then</em> aggregates them by groups or levels
defined in <code>by</code>. <code>"inverse_link"</code> first calculates predictions on the link
scale for each observation, then aggregates them by groups or levels defined
in <code>by</code>, and finally back-transforms the predictions to the response scale.
Both approaches have advantages and disadvantages. <code>"response"</code> usually
produces less biased predictions, but confidence intervals might be outside
reasonable bounds (i.e., for instance can be negative for count data). The
<code>"inverse_link"</code> approach is more robust in terms of confidence intervals, but
might produce biased predictions. In particular for mixed models, using
<code>"response"</code> is recommended, because averaging across random effects groups
is more accurate.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_estimate">estimate</code></td>
<td>
<p>The <code>estimate</code> argument determines how predictions are
averaged (&quot;marginalized&quot;) over variables not specified in <code>by</code> or <code>contrast</code>
(non-focal predictors). It controls whether predictions represent a &quot;typical&quot;
individual, an &quot;average&quot; individual from the sample, or an &quot;average&quot;
individual from a broader population.
</p>

<ul>
<li> <p><code>"typical"</code> (Default): Calculates predictions for a balanced data grid
representing all combinations of focal predictor levels (specified in <code>by</code>).
For non-focal numeric predictors, it uses the mean; for non-focal
categorical predictors, it marginalizes (averages) over the levels. This
represents a &quot;typical&quot; observation based on the data grid and is useful for
comparing groups. It answers: &quot;What would the average outcome be for a
'typical' observation?&quot;. This is the default approach when estimating
marginal means using the <em>emmeans</em> package.
</p>
</li>
<li> <p><code>"average"</code>: Calculates predictions for each observation in the sample and
then averages these predictions within each group defined by the focal
predictors. This reflects the sample's actual distribution of non-focal
predictors, not a balanced grid. It answers: &quot;What is the predicted value
for an average observation in my data?&quot;
</p>
</li>
<li> <p><code>"population"</code>: &quot;Clones&quot; each observation, creating copies with all
possible combinations of focal predictor levels. It then averages the
predictions across these &quot;counterfactual&quot; observations (non-observed
permutations) within each group. This extrapolates to a hypothetical
broader population, considering &quot;what if&quot; scenarios. It answers: &quot;What is
the predicted response for the 'average' observation in a broader possible
target population?&quot; This approach entails more assumptions about the
likelihood of different combinations, but can be more apt to generalize.
This is also the option that should be used for <strong>G-computation</strong>
(<em>Chatton and Rohrer 2024</em>).
</p>
</li></ul>

<p>You can set a default option for the <code>estimate</code> argument via <code>options()</code>,
e.g. <code>options(modelbased_estimate = "average")</code></p>
</td></tr>
<tr><td><code id="estimate_means_+3A_transform">transform</code></td>
<td>
<p>A function applied to predictions and confidence intervals
to (back-) transform results, which can be useful in case the regression
model has a transformed response variable (e.g., <code>lm(log(y) ~ x)</code>). For
Bayesian models, this function is applied to individual draws from the
posterior distribution, before computing summaries. Can also be <code>TRUE</code>, in
which case <code>insight::get_transformation()</code> is called to determine the
appropriate transformation-function. Note that no standard errors are returned
when transformations are applied.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_keep_iterations">keep_iterations</code></td>
<td>
<p>If <code>TRUE</code>, will keep all iterations (draws) of
bootstrapped or Bayesian models. They will be added as additional columns
named <code>iter_1</code>, <code>iter_2</code>, and so on. If <code>keep_iterations</code> is a positive
number, only as many columns as indicated in <code>keep_iterations</code> will be added
to the output. You can reshape them to a long format by running
<code><a href="bayestestR.html#topic+reshape_iterations">bayestestR::reshape_iterations()</a></code>.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_backend">backend</code></td>
<td>
<p>Whether to use <code>"marginaleffects"</code> or <code>"emmeans"</code>as a backend.
Results are usually very similar. The major difference will be found for mixed
models, where <code>backend = "marginaleffects"</code> will also average across random
effects levels, producing &quot;marginal predictions&quot; (instead of &quot;conditional
predictions&quot;, see Heiss 2022).
</p>
<p>You can set a default backend via <code>options()</code>, e.g. use
<code>options(modelbased_backend = "emmeans")</code> to use the <strong>emmeans</strong> package or
<code>options(modelbased_backend = "marginaleffects")</code> to set <strong>marginaleffects</strong>
as default backend.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_verbose">verbose</code></td>
<td>
<p>Use <code>FALSE</code> to silence messages and warnings.</p>
</td></tr>
<tr><td><code id="estimate_means_+3A_...">...</code></td>
<td>
<p>Other arguments passed, for instance, to <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>,
to functions from the <strong>emmeans</strong> or <strong>marginaleffects</strong> package, or to process
Bayesian models via <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>. Examples:
</p>

<ul>
<li> <p><code>insight::get_datagrid()</code>: Argument such as <code>length</code>, <code>digits</code> or <code>range</code>
can be used to control the (number of) representative values.
</p>
</li>
<li> <p><strong>marginaleffects</strong>: Internally used functions are <code>avg_predictions()</code> for
means and contrasts, and <code>avg_slope()</code> for slopes. Therefore, arguments for
instance like <code>vcov</code>, <code>equivalence</code>, <code>df</code>, <code>slope</code> or even <code>newdata</code> can be
passed to those functions. A <code>weights</code> argument is passed to the <code>wts</code>
argument in <code>avg_predictions()</code> or <code>avg_slopes()</code>, however, weights can
only be applied when <code>estimate</code> is <code>"average"</code> or <code>"population"</code> (i.e. for
those marginalization options that do not use data grids). Other arguments,
such as <code>re.form</code> or <code>allow.new.levels</code>, may be passed to <code>predict()</code> (which
is internally used by <em>marginaleffects</em>) if supported by that model class.
</p>
</li>
<li> <p><strong>emmeans</strong>: Internally used functions are <code>emmeans()</code> and <code>emtrends()</code>.
Additional arguments can be passed to these functions.
</p>
</li>
<li><p> Bayesian models: For Bayesian models, parameters are cleaned using
<code>describe_posterior()</code>, thus, arguments like, for example, <code>centrality</code>,
<code>rope_range</code>, or <code>test</code> are passed to that function.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>, <code><a href="#topic+estimate_means">estimate_means()</a></code> and <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>
functions are forming a group, as they are all based on <em>marginal</em>
estimations (estimations based on a model). All three are built on the
<strong>emmeans</strong> or <strong>marginaleffects</strong> package (depending on the <code>backend</code>
argument), so reading its documentation (for instance <code><a href="emmeans.html#topic+emmeans">emmeans::emmeans()</a></code>,
<code><a href="emmeans.html#topic+emtrends">emmeans::emtrends()</a></code> or this <a href="https://marginaleffects.com/">website</a>) is
recommended to understand the idea behind these types of procedures.
</p>

<ul>
<li><p> Model-based <strong>predictions</strong> is the basis for all that follows. Indeed,
the first thing to understand is how models can be used to make predictions
(see <code><a href="#topic+estimate_link">estimate_link()</a></code>). This corresponds to the predicted response (or
&quot;outcome variable&quot;) given specific predictor values of the predictors (i.e.,
given a specific data configuration). This is why the concept of <code><a href="insight.html#topic+get_datagrid">reference grid()</a></code> is so important for direct predictions.
</p>
</li>
<li> <p><strong>Marginal &quot;means&quot;</strong>, obtained via <code><a href="#topic+estimate_means">estimate_means()</a></code>, are an extension
of such predictions, allowing to &quot;average&quot; (collapse) some of the predictors,
to obtain the average response value at a specific predictors configuration.
This is typically used when some of the predictors of interest are factors.
Indeed, the parameters of the model will usually give you the intercept value
and then the &quot;effect&quot; of each factor level (how different it is from the
intercept). Marginal means can be used to directly give you the mean value of
the response variable at all the levels of a factor. Moreover, it can also be
used to control, or average over predictors, which is useful in the case of
multiple predictors with or without interactions.
</p>
</li>
<li> <p><strong>Marginal contrasts</strong>, obtained via <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>, are
themselves at extension of marginal means, in that they allow to investigate
the difference (i.e., the contrast) between the marginal means. This is,
again, often used to get all pairwise differences between all levels of a
factor. It works also for continuous predictors, for instance one could also
be interested in whether the difference at two extremes of a continuous
predictor is significant.
</p>
</li>
<li><p> Finally, <strong>marginal effects</strong>, obtained via <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>, are
different in that their focus is not values on the response variable, but the
model's parameters. The idea is to assess the effect of a predictor at a
specific configuration of the other predictors. This is relevant in the case
of interactions or non-linear relationships, when the effect of a predictor
variable changes depending on the other predictors. Moreover, these effects
can also be &quot;averaged&quot; over other predictors, to get for instance the
&quot;general trend&quot; of a predictor over different factor levels.
</p>
</li></ul>

<p><strong>Example:</strong> Let's imagine the following model <code>lm(y ~ condition * x)</code> where
<code>condition</code> is a factor with 3 levels A, B and C and <code>x</code> a continuous
variable (like age for example). One idea is to see how this model performs,
and compare the actual response y to the one predicted by the model (using
<code><a href="#topic+estimate_expectation">estimate_expectation()</a></code>). Another idea is evaluate the average mean at each of
the condition's levels (using <code><a href="#topic+estimate_means">estimate_means()</a></code>), which can be useful to
visualize them. Another possibility is to evaluate the difference between
these levels (using <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>). Finally, one could also estimate
the effect of x averaged over all conditions, or instead within each
condition (<code>using [estimate_slopes]</code>).
</p>


<h3>Value</h3>

<p>A data frame of estimated marginal means.
</p>


<h3>Global Options to Customize Estimation of Marginal Means</h3>


<ul>
<li> <p><code>modelbased_backend</code>: <code style="white-space: pre;">&#8288;options(modelbased_backend = &lt;string&gt;)&#8288;</code> will set a
default value for the <code>backend</code> argument and can be used to set the package
used by default to calculate marginal means. Can be <code>"marginalmeans"</code> or
<code>"emmeans"</code>.
</p>
</li>
<li> <p><code>modelbased_estimate</code>: <code style="white-space: pre;">&#8288;options(modelbased_estimate = &lt;string&gt;)&#8288;</code> will
set a default value for the <code>estimate</code> argument.
</p>
</li></ul>



<h3>References</h3>

<p>Chatton, A. and Rohrer, J.M. 2024. The Causal Cookbook: Recipes for
Propensity Scores, G-Computation, and Doubly Robust Standardization. Advances
in Methods and Practices in Psychological Science. 2024;7(1).
<a href="https://doi.org/10.1177/25152459241236149">doi:10.1177/25152459241236149</a>
</p>
<p>Dickerman, Barbra A., and Miguel A. Hernán. 2020. Counterfactual Prediction
Is Not Only for Causal Inference. European Journal of Epidemiology 35 (7):
615–17. <a href="https://doi.org/10.1007/s10654-020-00659-8">doi:10.1007/s10654-020-00659-8</a>
</p>
<p>Heiss, A. (2022). Marginal and conditional effects for GLMMs with
marginaleffects. Andrew Heiss. <a href="https://doi.org/10.59350/xwnfm-x1827">doi:10.59350/xwnfm-x1827</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(modelbased)

# Frequentist models
# -------------------
model &lt;- lm(Petal.Length ~ Sepal.Width * Species, data = iris)

estimate_means(model)

# the `length` argument is passed to `insight::get_datagrid()` and modulates
# the number of representative values to return for numeric predictors
estimate_means(model, by = c("Species", "Sepal.Width"), length = 2)

# an alternative way to setup your data grid is specify the values directly
estimate_means(model, by = c("Species", "Sepal.Width = c(2, 4)"))

# or use one of the many predefined "tokens" that help you creating a useful
# data grid - to learn more about creating data grids, see help in
# `?insight::get_datagrid`.
estimate_means(model, by = c("Species", "Sepal.Width = [fivenum]"))

## Not run: 
# same for factors: filter by specific levels
estimate_means(model, by = "Species=c('versicolor', 'setosa')")
estimate_means(model, by = c("Species", "Sepal.Width=0"))

# estimate marginal average of response at values for numeric predictor
estimate_means(model, by = "Sepal.Width", length = 5)
estimate_means(model, by = "Sepal.Width=c(2, 4)")

# or provide the definition of the data grid as list
estimate_means(
  model,
  by = list(Sepal.Width = c(2, 4), Species = c("versicolor", "setosa"))
)

# Methods that can be applied to it:
means &lt;- estimate_means(model, by = c("Species", "Sepal.Width=0"))

plot(means) # which runs visualisation_recipe()
standardize(means)

# grids for numeric predictors, combine range and length
model &lt;- lm(Sepal.Length ~ Sepal.Width * Petal.Length, data = iris)
# range from minimum to maximum spread over four values,
# and mean +/- 1 SD (a total of three values)
estimate_means(
  model,
  by = c("Sepal.Width", "Petal.Length"),
  range = c("range", "sd"),
  length = c(4, 3)
)

data &lt;- iris
data$Petal.Length_factor &lt;- ifelse(data$Petal.Length &lt; 4.2, "A", "B")

model &lt;- lme4::lmer(
  Petal.Length ~ Sepal.Width + Species + (1 | Petal.Length_factor),
  data = data
)
estimate_means(model)
estimate_means(model, by = "Sepal.Width", length = 3)

## End(Not run)

</code></pre>

<hr>
<h2 id='estimate_slopes'>Estimate Marginal Effects</h2><span id='topic+estimate_slopes'></span>

<h3>Description</h3>

<p>Estimate the slopes (i.e., the coefficient) of a predictor over or within
different factor levels, or alongside a numeric variable. In other words, to
assess the effect of a predictor <em>at</em> specific configurations data. It corresponds
to the derivative and can be useful to understand where a predictor has a
significant role when interactions or non-linear relationships are present.
</p>
<p>Other related functions based on marginal estimations includes
<code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code> and <code><a href="#topic+estimate_means">estimate_means()</a></code>.
</p>
<p>See the <strong>Details</strong> section below, and don't forget to also check out the
<a href="https://easystats.github.io/modelbased/articles/estimate_slopes.html">Vignettes</a>
and <a href="https://easystats.github.io/modelbased/index.html#features">README examples</a> for
various examples, tutorials and use cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_slopes(
  model,
  trend = NULL,
  by = NULL,
  ci = 0.95,
  p_adjust = "none",
  transform = NULL,
  keep_iterations = FALSE,
  backend = getOption("modelbased_backend", "marginaleffects"),
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_slopes_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_trend">trend</code></td>
<td>
<p>A character indicating the name of the variable for which to
compute the slopes.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_by">by</code></td>
<td>
<p>The (focal) predictor variable(s) at which to evaluate the desired
effect / mean / contrasts. Other predictors of the model that are not
included here will be collapsed and &quot;averaged&quot; over (the effect will be
estimated across them). <code>by</code> can be a character (vector) naming the focal
predictors, optionally including representative values or levels at which
focal predictors are evaluated (e.g., <code>by="x=c(1,2)"</code>). When <code>estimate</code> is
<em>not</em> <code>"average"</code>, the <code>by</code> argument is used to create a &quot;reference grid&quot; or
&quot;data grid&quot; with representative values for the focal predictors. In this
case, <code>by</code> can also be list of named elements. See details in
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code> to learn more about how to create data grids for
predictors of interest.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_p_adjust">p_adjust</code></td>
<td>
<p>The p-values adjustment method for frequentist multiple
comparisons. For <code>estimate_slopes()</code>, multiple comparison only occurs for
Johnson-Neyman intervals, i.e. in case of interactions with two numeric
predictors (one specified in <code>trend</code>, one in <code>by</code>). In this case, the <code>"esarey"</code>
option is recommended, but <code>p_adjust</code> can also be one of <code>"none"</code> (default),
<code>"hochberg"</code>, <code>"hommel"</code>, <code>"bonferroni"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>, <code>"tukey"</code>,
<code>"sidak"</code>, or <code>"holm"</code>.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_transform">transform</code></td>
<td>
<p>A function applied to predictions and confidence intervals
to (back-) transform results, which can be useful in case the regression
model has a transformed response variable (e.g., <code>lm(log(y) ~ x)</code>). For
Bayesian models, this function is applied to individual draws from the
posterior distribution, before computing summaries. Can also be <code>TRUE</code>, in
which case <code>insight::get_transformation()</code> is called to determine the
appropriate transformation-function. Note that no standard errors are returned
when transformations are applied.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_keep_iterations">keep_iterations</code></td>
<td>
<p>If <code>TRUE</code>, will keep all iterations (draws) of
bootstrapped or Bayesian models. They will be added as additional columns
named <code>iter_1</code>, <code>iter_2</code>, and so on. If <code>keep_iterations</code> is a positive
number, only as many columns as indicated in <code>keep_iterations</code> will be added
to the output. You can reshape them to a long format by running
<code><a href="bayestestR.html#topic+reshape_iterations">bayestestR::reshape_iterations()</a></code>.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_backend">backend</code></td>
<td>
<p>Whether to use <code>"marginaleffects"</code> or <code>"emmeans"</code>as a backend.
Results are usually very similar. The major difference will be found for mixed
models, where <code>backend = "marginaleffects"</code> will also average across random
effects levels, producing &quot;marginal predictions&quot; (instead of &quot;conditional
predictions&quot;, see Heiss 2022).
</p>
<p>You can set a default backend via <code>options()</code>, e.g. use
<code>options(modelbased_backend = "emmeans")</code> to use the <strong>emmeans</strong> package or
<code>options(modelbased_backend = "marginaleffects")</code> to set <strong>marginaleffects</strong>
as default backend.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_verbose">verbose</code></td>
<td>
<p>Use <code>FALSE</code> to silence messages and warnings.</p>
</td></tr>
<tr><td><code id="estimate_slopes_+3A_...">...</code></td>
<td>
<p>Other arguments passed, for instance, to <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>,
to functions from the <strong>emmeans</strong> or <strong>marginaleffects</strong> package, or to process
Bayesian models via <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>. Examples:
</p>

<ul>
<li> <p><code>insight::get_datagrid()</code>: Argument such as <code>length</code>, <code>digits</code> or <code>range</code>
can be used to control the (number of) representative values.
</p>
</li>
<li> <p><strong>marginaleffects</strong>: Internally used functions are <code>avg_predictions()</code> for
means and contrasts, and <code>avg_slope()</code> for slopes. Therefore, arguments for
instance like <code>vcov</code>, <code>equivalence</code>, <code>df</code>, <code>slope</code> or even <code>newdata</code> can be
passed to those functions. A <code>weights</code> argument is passed to the <code>wts</code>
argument in <code>avg_predictions()</code> or <code>avg_slopes()</code>, however, weights can
only be applied when <code>estimate</code> is <code>"average"</code> or <code>"population"</code> (i.e. for
those marginalization options that do not use data grids). Other arguments,
such as <code>re.form</code> or <code>allow.new.levels</code>, may be passed to <code>predict()</code> (which
is internally used by <em>marginaleffects</em>) if supported by that model class.
</p>
</li>
<li> <p><strong>emmeans</strong>: Internally used functions are <code>emmeans()</code> and <code>emtrends()</code>.
Additional arguments can be passed to these functions.
</p>
</li>
<li><p> Bayesian models: For Bayesian models, parameters are cleaned using
<code>describe_posterior()</code>, thus, arguments like, for example, <code>centrality</code>,
<code>rope_range</code>, or <code>test</code> are passed to that function.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>, <code><a href="#topic+estimate_means">estimate_means()</a></code> and <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>
functions are forming a group, as they are all based on <em>marginal</em>
estimations (estimations based on a model). All three are built on the
<strong>emmeans</strong> or <strong>marginaleffects</strong> package (depending on the <code>backend</code>
argument), so reading its documentation (for instance <code><a href="emmeans.html#topic+emmeans">emmeans::emmeans()</a></code>,
<code><a href="emmeans.html#topic+emtrends">emmeans::emtrends()</a></code> or this <a href="https://marginaleffects.com/">website</a>) is
recommended to understand the idea behind these types of procedures.
</p>

<ul>
<li><p> Model-based <strong>predictions</strong> is the basis for all that follows. Indeed,
the first thing to understand is how models can be used to make predictions
(see <code><a href="#topic+estimate_link">estimate_link()</a></code>). This corresponds to the predicted response (or
&quot;outcome variable&quot;) given specific predictor values of the predictors (i.e.,
given a specific data configuration). This is why the concept of <code><a href="insight.html#topic+get_datagrid">reference grid()</a></code> is so important for direct predictions.
</p>
</li>
<li> <p><strong>Marginal &quot;means&quot;</strong>, obtained via <code><a href="#topic+estimate_means">estimate_means()</a></code>, are an extension
of such predictions, allowing to &quot;average&quot; (collapse) some of the predictors,
to obtain the average response value at a specific predictors configuration.
This is typically used when some of the predictors of interest are factors.
Indeed, the parameters of the model will usually give you the intercept value
and then the &quot;effect&quot; of each factor level (how different it is from the
intercept). Marginal means can be used to directly give you the mean value of
the response variable at all the levels of a factor. Moreover, it can also be
used to control, or average over predictors, which is useful in the case of
multiple predictors with or without interactions.
</p>
</li>
<li> <p><strong>Marginal contrasts</strong>, obtained via <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>, are
themselves at extension of marginal means, in that they allow to investigate
the difference (i.e., the contrast) between the marginal means. This is,
again, often used to get all pairwise differences between all levels of a
factor. It works also for continuous predictors, for instance one could also
be interested in whether the difference at two extremes of a continuous
predictor is significant.
</p>
</li>
<li><p> Finally, <strong>marginal effects</strong>, obtained via <code><a href="#topic+estimate_slopes">estimate_slopes()</a></code>, are
different in that their focus is not values on the response variable, but the
model's parameters. The idea is to assess the effect of a predictor at a
specific configuration of the other predictors. This is relevant in the case
of interactions or non-linear relationships, when the effect of a predictor
variable changes depending on the other predictors. Moreover, these effects
can also be &quot;averaged&quot; over other predictors, to get for instance the
&quot;general trend&quot; of a predictor over different factor levels.
</p>
</li></ul>

<p><strong>Example:</strong> Let's imagine the following model <code>lm(y ~ condition * x)</code> where
<code>condition</code> is a factor with 3 levels A, B and C and <code>x</code> a continuous
variable (like age for example). One idea is to see how this model performs,
and compare the actual response y to the one predicted by the model (using
<code><a href="#topic+estimate_expectation">estimate_expectation()</a></code>). Another idea is evaluate the average mean at each of
the condition's levels (using <code><a href="#topic+estimate_means">estimate_means()</a></code>), which can be useful to
visualize them. Another possibility is to evaluate the difference between
these levels (using <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>). Finally, one could also estimate
the effect of x averaged over all conditions, or instead within each
condition (<code>using [estimate_slopes]</code>).
</p>


<h3>Value</h3>

<p>A data.frame of class <code>estimate_slopes</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(ggplot2)
# Get an idea of the data
ggplot(iris, aes(x = Petal.Length, y = Sepal.Width)) +
  geom_point(aes(color = Species)) +
  geom_smooth(color = "black", se = FALSE) +
  geom_smooth(aes(color = Species), linetype = "dotted", se = FALSE) +
  geom_smooth(aes(color = Species), method = "lm", se = FALSE)

# Model it
model &lt;- lm(Sepal.Width ~ Species * Petal.Length, data = iris)
# Compute the marginal effect of Petal.Length at each level of Species
slopes &lt;- estimate_slopes(model, trend = "Petal.Length", by = "Species")
slopes

## Not run: 
# Plot it
plot(slopes)
standardize(slopes)

model &lt;- mgcv::gam(Sepal.Width ~ s(Petal.Length), data = iris)
slopes &lt;- estimate_slopes(model, by = "Petal.Length", length = 50)
summary(slopes)
plot(slopes)

model &lt;- mgcv::gam(Sepal.Width ~ s(Petal.Length, by = Species), data = iris)
slopes &lt;- estimate_slopes(model,
  trend = "Petal.Length",
  by = c("Petal.Length", "Species"), length = 20
)
summary(slopes)
plot(slopes)

## End(Not run)

</code></pre>

<hr>
<h2 id='fish'>Sample data set</h2><span id='topic+fish'></span>

<h3>Description</h3>

<p>A sample data set, used in tests and some examples. Useful for
demonstrating count models (with or without zero-inflation component). It
consists of nine variables from 250 observations.
</p>

<hr>
<h2 id='get_emcontrasts'>Consistent API for 'emmeans' and 'marginaleffects'</h2><span id='topic+get_emcontrasts'></span><span id='topic+get_emmeans'></span><span id='topic+get_emtrends'></span><span id='topic+get_marginalcontrasts'></span><span id='topic+get_marginalmeans'></span><span id='topic+get_marginaltrends'></span>

<h3>Description</h3>

<p>These functions are convenient wrappers around the <strong>emmeans</strong> and the
<strong>marginaleffects</strong> packages. They are mostly available for developers who want
to leverage a unified API for getting model-based estimates, and regular users
should use the <code style="white-space: pre;">&#8288;estimate_*&#8288;</code> set of functions.
</p>
<p>The <code>get_emmeans()</code>, <code>get_emcontrasts()</code> and <code>get_emtrends()</code> functions are
wrappers around <code>emmeans::emmeans()</code> and <code>emmeans::emtrends()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_emcontrasts(
  model,
  contrast = NULL,
  by = NULL,
  predict = NULL,
  comparison = "pairwise",
  transform = NULL,
  keep_iterations = FALSE,
  verbose = TRUE,
  ...
)

get_emmeans(
  model,
  by = "auto",
  predict = NULL,
  transform = NULL,
  keep_iterations = FALSE,
  verbose = TRUE,
  ...
)

get_emtrends(
  model,
  trend = NULL,
  by = NULL,
  keep_iterations = FALSE,
  verbose = TRUE,
  ...
)

get_marginalcontrasts(
  model,
  contrast = NULL,
  by = NULL,
  predict = NULL,
  ci = 0.95,
  comparison = "pairwise",
  estimate = getOption("modelbased_estimate", "typical"),
  p_adjust = "none",
  transform = NULL,
  keep_iterations = FALSE,
  verbose = TRUE,
  ...
)

get_marginalmeans(
  model,
  by = "auto",
  predict = NULL,
  ci = 0.95,
  estimate = getOption("modelbased_estimate", "typical"),
  transform = NULL,
  keep_iterations = FALSE,
  verbose = TRUE,
  ...
)

get_marginaltrends(
  model,
  trend = NULL,
  by = NULL,
  ci = 0.95,
  p_adjust = "none",
  transform = NULL,
  keep_iterations = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_emcontrasts_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_contrast">contrast</code></td>
<td>
<p>A character vector indicating the name of the variable(s) for
which to compute the contrasts, optionally including representative values or
levels at which contrasts are evaluated (e.g., <code>contrast="x=c('a','b')"</code>).</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_by">by</code></td>
<td>
<p>The (focal) predictor variable(s) at which to evaluate the desired
effect / mean / contrasts. Other predictors of the model that are not
included here will be collapsed and &quot;averaged&quot; over (the effect will be
estimated across them). <code>by</code> can be a character (vector) naming the focal
predictors, optionally including representative values or levels at which
focal predictors are evaluated (e.g., <code>by="x=c(1,2)"</code>). When <code>estimate</code> is
<em>not</em> <code>"average"</code>, the <code>by</code> argument is used to create a &quot;reference grid&quot; or
&quot;data grid&quot; with representative values for the focal predictors. In this
case, <code>by</code> can also be list of named elements. See details in
<code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code> to learn more about how to create data grids for
predictors of interest.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_predict">predict</code></td>
<td>
<p>Is passed to the <code>type</code> argument in <code>emmeans::emmeans()</code> (when
<code>backend = "emmeans"</code>) or in <code>marginaleffects::avg_predictions()</code> (when
<code>backend = "marginaleffects"</code>). For emmeans, see also
<a href="https://CRAN.R-project.org/package=emmeans/vignettes/transformations.html">this vignette</a>.
Valid options for <code>predict</code> are:
</p>

<ul>
<li> <p><code>backend = "marginaleffects"</code>: <code>predict</code> can be <code>"response"</code>, <code>"link"</code>,
<code>"inverse_link"</code> or any valid <code>type</code> option supported by model's class
<code>predict()</code> method (e.g., for zero-inflation models from package
<strong>glmmTMB</strong>, you can choose <code>predict = "zprob"</code> or <code>predict = "conditional"</code>
etc., see <a href="glmmTMB.html#topic+predict.glmmTMB">glmmTMB::predict.glmmTMB</a>). By default, when <code>predict = NULL</code>,
the most appropriate transformation is selected, which usually returns
predictions or contrasts on the response-scale. The <code>"inverse_link"</code> is a
special option, comparable to <em>marginaleffects</em>' <code>invlink(link)</code> option. It
will calculate predictions on the link scale and then back-transform to the
response scale.
</p>
</li>
<li> <p><code>backend = "emmeans"</code>: <code>predict</code> can be <code>"response"</code>, <code>"link"</code>, <code>"mu"</code>,
<code>"unlink"</code>, or <code>"log"</code>. If <code>predict = NULL</code> (default), the most appropriate
transformation is selected (which usually is <code>"response"</code>).
</p>
</li></ul>

<p><code>"link"</code> will leave the values on scale of the linear predictors.
<code>"response"</code> (or <code>NULL</code>) will transform them on scale of the response
variable. Thus for a logistic model, <code>"link"</code> will give estimations expressed
in log-odds (probabilities on logit scale) and <code>"response"</code> in terms of
probabilities. To predict distributional parameters (called &quot;dpar&quot; in other
packages), for instance when using complex formulae in <code>brms</code> models, the
<code>predict</code> argument can take the value of the parameter you want to estimate,
for instance <code>"sigma"</code>, <code>"kappa"</code>, etc.
</p>
<p><code>"response"</code> and <code>"inverse_link"</code> both return predictions on the response
scale, however, <code>"response"</code> first calculates predictions on the response
scale for each observation and <em>then</em> aggregates them by groups or levels
defined in <code>by</code>. <code>"inverse_link"</code> first calculates predictions on the link
scale for each observation, then aggregates them by groups or levels defined
in <code>by</code>, and finally back-transforms the predictions to the response scale.
Both approaches have advantages and disadvantages. <code>"response"</code> usually
produces less biased predictions, but confidence intervals might be outside
reasonable bounds (i.e., for instance can be negative for count data). The
<code>"inverse_link"</code> approach is more robust in terms of confidence intervals, but
might produce biased predictions. In particular for mixed models, using
<code>"response"</code> is recommended, because averaging across random effects groups
is more accurate.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_comparison">comparison</code></td>
<td>
<p>Specify the type of contrasts or tests that should be
carried out.
</p>

<ul>
<li><p> When <code>backend = "emmeans"</code>, can be one of <code>"pairwise"</code>, <code>"poly"</code>,
<code>"consec"</code>, <code>"eff"</code>, <code>"del.eff"</code>, <code>"mean_chg"</code>, <code>"trt.vs.ctrl"</code>,
<code>"dunnett"</code>, <code>"wtcon"</code> and some more. See also <code>method</code> argument in
<a href="emmeans.html#topic+contrast">emmeans::contrast</a> and the <code>?emmeans::emmc-functions</code>.
</p>
</li>
<li><p> For <code>backend = "marginaleffects"</code>, can be a numeric value, vector, or
matrix, a string equation specifying the hypothesis to test, a string
naming the comparison method, a formula, or a function. Strings, string
equations and formula are probably the most common options and described
below. For other options and detailed descriptions of those options, see
also <a href="marginaleffects.html#topic+comparisons">marginaleffects::comparisons</a> and
<a href="https://marginaleffects.com/bonus/hypothesis.html">this website</a>.
</p>

<ul>
<li><p> String: One of <code>"pairwise"</code>, <code>"reference"</code>, <code>"sequential"</code>, <code>"meandev"</code>
<code>"meanotherdev"</code>, <code>"poly"</code>, <code>"helmert"</code>, or <code>"trt_vs_ctrl"</code>.
</p>
</li>
<li><p> String equation: To identify parameters from the output, either specify
the term name, or <code>"b1"</code>, <code>"b2"</code> etc. to indicate rows, e.g.:<code>"hp = drat"</code>,
<code>"b1 = b2"</code>, or <code>"b1 + b2 + b3 = 0"</code>.
</p>
</li>
<li><p> Formula: A formula like <code>comparison ~ pairs | group</code>, where the left-hand
side indicates the type of comparison (<code>difference</code> or <code>ratio</code>), the
right-hand side determines the pairs of estimates to compare (<code>reference</code>,
<code>sequential</code>, <code>meandev</code>, etc., see string-options). Optionally, comparisons
can be carried out within subsets by indicating the grouping variable
after a vertical bar ( <code>|</code>).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_transform">transform</code></td>
<td>
<p>A function applied to predictions and confidence intervals
to (back-) transform results, which can be useful in case the regression
model has a transformed response variable (e.g., <code>lm(log(y) ~ x)</code>). For
Bayesian models, this function is applied to individual draws from the
posterior distribution, before computing summaries. Can also be <code>TRUE</code>, in
which case <code>insight::get_transformation()</code> is called to determine the
appropriate transformation-function. Note that no standard errors are returned
when transformations are applied.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_keep_iterations">keep_iterations</code></td>
<td>
<p>If <code>TRUE</code>, will keep all iterations (draws) of
bootstrapped or Bayesian models. They will be added as additional columns
named <code>iter_1</code>, <code>iter_2</code>, and so on. If <code>keep_iterations</code> is a positive
number, only as many columns as indicated in <code>keep_iterations</code> will be added
to the output. You can reshape them to a long format by running
<code><a href="bayestestR.html#topic+reshape_iterations">bayestestR::reshape_iterations()</a></code>.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_verbose">verbose</code></td>
<td>
<p>Use <code>FALSE</code> to silence messages and warnings.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_...">...</code></td>
<td>
<p>Other arguments passed, for instance, to <code><a href="insight.html#topic+get_datagrid">insight::get_datagrid()</a></code>,
to functions from the <strong>emmeans</strong> or <strong>marginaleffects</strong> package, or to process
Bayesian models via <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>. Examples:
</p>

<ul>
<li> <p><code>insight::get_datagrid()</code>: Argument such as <code>length</code>, <code>digits</code> or <code>range</code>
can be used to control the (number of) representative values.
</p>
</li>
<li> <p><strong>marginaleffects</strong>: Internally used functions are <code>avg_predictions()</code> for
means and contrasts, and <code>avg_slope()</code> for slopes. Therefore, arguments for
instance like <code>vcov</code>, <code>equivalence</code>, <code>df</code>, <code>slope</code> or even <code>newdata</code> can be
passed to those functions. A <code>weights</code> argument is passed to the <code>wts</code>
argument in <code>avg_predictions()</code> or <code>avg_slopes()</code>, however, weights can
only be applied when <code>estimate</code> is <code>"average"</code> or <code>"population"</code> (i.e. for
those marginalization options that do not use data grids). Other arguments,
such as <code>re.form</code> or <code>allow.new.levels</code>, may be passed to <code>predict()</code> (which
is internally used by <em>marginaleffects</em>) if supported by that model class.
</p>
</li>
<li> <p><strong>emmeans</strong>: Internally used functions are <code>emmeans()</code> and <code>emtrends()</code>.
Additional arguments can be passed to these functions.
</p>
</li>
<li><p> Bayesian models: For Bayesian models, parameters are cleaned using
<code>describe_posterior()</code>, thus, arguments like, for example, <code>centrality</code>,
<code>rope_range</code>, or <code>test</code> are passed to that function.
</p>
</li></ul>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_trend">trend</code></td>
<td>
<p>A character indicating the name of the variable for which to
compute the slopes.</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_estimate">estimate</code></td>
<td>
<p>The <code>estimate</code> argument determines how predictions are
averaged (&quot;marginalized&quot;) over variables not specified in <code>by</code> or <code>contrast</code>
(non-focal predictors). It controls whether predictions represent a &quot;typical&quot;
individual, an &quot;average&quot; individual from the sample, or an &quot;average&quot;
individual from a broader population.
</p>

<ul>
<li> <p><code>"typical"</code> (Default): Calculates predictions for a balanced data grid
representing all combinations of focal predictor levels (specified in <code>by</code>).
For non-focal numeric predictors, it uses the mean; for non-focal
categorical predictors, it marginalizes (averages) over the levels. This
represents a &quot;typical&quot; observation based on the data grid and is useful for
comparing groups. It answers: &quot;What would the average outcome be for a
'typical' observation?&quot;. This is the default approach when estimating
marginal means using the <em>emmeans</em> package.
</p>
</li>
<li> <p><code>"average"</code>: Calculates predictions for each observation in the sample and
then averages these predictions within each group defined by the focal
predictors. This reflects the sample's actual distribution of non-focal
predictors, not a balanced grid. It answers: &quot;What is the predicted value
for an average observation in my data?&quot;
</p>
</li>
<li> <p><code>"population"</code>: &quot;Clones&quot; each observation, creating copies with all
possible combinations of focal predictor levels. It then averages the
predictions across these &quot;counterfactual&quot; observations (non-observed
permutations) within each group. This extrapolates to a hypothetical
broader population, considering &quot;what if&quot; scenarios. It answers: &quot;What is
the predicted response for the 'average' observation in a broader possible
target population?&quot; This approach entails more assumptions about the
likelihood of different combinations, but can be more apt to generalize.
This is also the option that should be used for <strong>G-computation</strong>
(<em>Chatton and Rohrer 2024</em>).
</p>
</li></ul>

<p>You can set a default option for the <code>estimate</code> argument via <code>options()</code>,
e.g. <code>options(modelbased_estimate = "average")</code></p>
</td></tr>
<tr><td><code id="get_emcontrasts_+3A_p_adjust">p_adjust</code></td>
<td>
<p>The p-values adjustment method for frequentist multiple
comparisons. For <code>estimate_slopes()</code>, multiple comparison only occurs for
Johnson-Neyman intervals, i.e. in case of interactions with two numeric
predictors (one specified in <code>trend</code>, one in <code>by</code>). In this case, the <code>"esarey"</code>
option is recommended, but <code>p_adjust</code> can also be one of <code>"none"</code> (default),
<code>"hochberg"</code>, <code>"hommel"</code>, <code>"bonferroni"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>, <code>"tukey"</code>,
<code>"sidak"</code>, or <code>"holm"</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Basic usage
model &lt;- lm(Sepal.Width ~ Species, data = iris)
get_emcontrasts(model)

## Not run: 
# Dealing with interactions
model &lt;- lm(Sepal.Width ~ Species * Petal.Width, data = iris)
# By default: selects first factor
get_emcontrasts(model)
# Or both
get_emcontrasts(model, contrast = c("Species", "Petal.Width"), length = 2)
# Or with custom specifications
get_emcontrasts(model, contrast = c("Species", "Petal.Width=c(1, 2)"))
# Or modulate it
get_emcontrasts(model, by = "Petal.Width", length = 4)

## End(Not run)


model &lt;- lm(Sepal.Length ~ Species + Petal.Width, data = iris)

# By default, 'by' is set to "Species"
get_emmeans(model)

## Not run: 
# Overall mean (close to 'mean(iris$Sepal.Length)')
get_emmeans(model, by = NULL)

# One can estimate marginal means at several values of a 'modulate' variable
get_emmeans(model, by = "Petal.Width", length = 3)

# Interactions
model &lt;- lm(Sepal.Width ~ Species * Petal.Length, data = iris)

get_emmeans(model)
get_emmeans(model, by = c("Species", "Petal.Length"), length = 2)
get_emmeans(model, by = c("Species", "Petal.Length = c(1, 3, 5)"), length = 2)

## End(Not run)


## Not run: 
model &lt;- lm(Sepal.Width ~ Species * Petal.Length, data = iris)

get_emtrends(model)
get_emtrends(model, by = "Species")
get_emtrends(model, by = "Petal.Length")
get_emtrends(model, by = c("Species", "Petal.Length"))

## End(Not run)

model &lt;- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris)
get_emtrends(model)
get_emtrends(model, by = "Sepal.Width")


model &lt;- lm(Sepal.Length ~ Species + Petal.Width, data = iris)

# By default, 'by' is set to "Species"
get_marginalmeans(model)

# Overall mean (close to 'mean(iris$Sepal.Length)')
get_marginalmeans(model, by = NULL)

## Not run: 
# One can estimate marginal means at several values of a 'modulate' variable
get_marginalmeans(model, by = "Petal.Width", length = 3)

# Interactions
model &lt;- lm(Sepal.Width ~ Species * Petal.Length, data = iris)

get_marginalmeans(model)
get_marginalmeans(model, by = c("Species", "Petal.Length"), length = 2)
get_marginalmeans(model, by = c("Species", "Petal.Length = c(1, 3, 5)"), length = 2)

## End(Not run)


model &lt;- lm(Sepal.Width ~ Species * Petal.Length, data = iris)

get_marginaltrends(model, trend = "Petal.Length", by = "Species")
get_marginaltrends(model, trend = "Petal.Length", by = "Petal.Length")
get_marginaltrends(model, trend = "Petal.Length", by = c("Species", "Petal.Length"))

</code></pre>

<hr>
<h2 id='modelbased-options'>Global options from the modelbased package</h2><span id='topic+modelbased-options'></span>

<h3>Description</h3>

<p>Global options from the modelbased package
</p>


<h3>Global options to set defaults for function arguments</h3>

<p><strong>For calculating marginal means</strong>
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;options(modelbased_backend = &lt;string&gt;)&#8288;</code> will set a default value for the
<code>backend</code> argument and can be used to set the package used by default to
calculate marginal means. Can be <code>"marginaleffects"</code> or <code>"emmeans"</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;options(modelbased_estimate = &lt;string&gt;)&#8288;</code> will set a default value for the
<code>estimate</code> argument, which modulates the type of target population
predictions refer to.
</p>
</li></ul>

<p><strong>For printing</strong>
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;options(modelbased_select = &lt;string&gt;)&#8288;</code> will set a default value for the
<code>select</code> argument and can be used to define a custom default layout for
printing.
</p>
</li>
<li> <p><code>options(modelbased_include_grid = TRUE)</code> will set a default value for the
<code>include_grid</code> argument and can be used to include data grids in the output
by default or not.
</p>
</li>
<li> <p><code>options(modelbased_full_labels = FALSE)</code> will remove redundant
(duplicated) labels from rows.
</p>
</li></ul>

<p><strong>For plotting</strong>
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;options(modelbased_join_dots = &lt;logical&gt;)&#8288;</code> will set a default value for
the <code>join_dots</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;options(modelbased_numeric_as_discrete = &lt;number&gt;)&#8288;</code> will set a default
value for the <code>modelbased_numeric_as_discrete</code> argument. Can also be
<code>FALSE</code>.
</p>
</li></ul>


<hr>
<h2 id='pool_contrasts'>Pool contrasts and comparisons from <code>estimate_contrasts()</code></h2><span id='topic+pool_contrasts'></span>

<h3>Description</h3>

<p>This function &quot;pools&quot; (i.e. combines) multiple <code>estimate_contrasts</code> objects,
returned by <code><a href="#topic+estimate_contrasts">estimate_contrasts()</a></code>, in a similar fashion as <code><a href="mice.html#topic+pool">mice::pool()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool_contrasts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pool_contrasts_+3A_x">x</code></td>
<td>
<p>A list of <code>estimate_contrasts</code> objects, as returned by
<code>estimate_contrasts()</code>.</p>
</td></tr>
<tr><td><code id="pool_contrasts_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Averaging of parameters follows Rubin's rules (<em>Rubin, 1987, p. 76</em>).
</p>


<h3>Value</h3>

<p>A data frame with pooled comparisons or contrasts of predictions.
</p>


<h3>References</h3>

<p>Rubin, D.B. (1987). Multiple Imputation for Nonresponse in Surveys. New York:
John Wiley and Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("nhanes2", package = "mice")
imp &lt;- mice::mice(nhanes2, printFlag = FALSE)
comparisons &lt;- lapply(1:5, function(i) {
  m &lt;- lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i))
  estimate_contrasts(m, "age")
})
pool_contrasts(comparisons)

</code></pre>

<hr>
<h2 id='pool_predictions'>Pool Predictions and Estimated Marginal Means</h2><span id='topic+pool_predictions'></span>

<h3>Description</h3>

<p>This function &quot;pools&quot; (i.e. combines) multiple <code>estimate_means</code> objects, in
a similar fashion as <code><a href="mice.html#topic+pool">mice::pool()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool_predictions(x, transform = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pool_predictions_+3A_x">x</code></td>
<td>
<p>A list of <code>estimate_means</code> objects, as returned by <code><a href="#topic+estimate_means">estimate_means()</a></code>,
or <code>estimate_predicted</code>, as returned by <code><a href="#topic+estimate_relation">estimate_relation()</a></code> and related
functions.</p>
</td></tr>
<tr><td><code id="pool_predictions_+3A_transform">transform</code></td>
<td>
<p>A function applied to predictions and confidence intervals
to (back-) transform results, which can be useful in case the regression
model has a transformed response variable (e.g., <code>lm(log(y) ~ x)</code>). For
Bayesian models, this function is applied to individual draws from the
posterior distribution, before computing summaries. Can also be <code>TRUE</code>, in
which case <code>insight::get_transformation()</code> is called to determine the
appropriate transformation-function. Note that no standard errors are returned
when transformations are applied.</p>
</td></tr>
<tr><td><code id="pool_predictions_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Averaging of parameters follows Rubin's rules (<em>Rubin, 1987, p. 76</em>).
Pooling is applied to the predicted values on the scale of the <em>linear predictor</em>,
not on the response scale, in order to have accurate pooled estimates and
standard errors. The final pooled predicted values are then transformed to
the response scale, using <code><a href="insight.html#topic+link_inverse">insight::link_inverse()</a></code>.
</p>


<h3>Value</h3>

<p>A data frame with pooled predictions.
</p>


<h3>References</h3>

<p>Rubin, D.B. (1987). Multiple Imputation for Nonresponse in Surveys. New York:
John Wiley and Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example for multiple imputed datasets
data("nhanes2", package = "mice")
imp &lt;- mice::mice(nhanes2, printFlag = FALSE)
predictions &lt;- lapply(1:5, function(i) {
  m &lt;- lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i))
  estimate_means(m, "age")
})
pool_predictions(predictions)

</code></pre>

<hr>
<h2 id='print.estimate_contrasts'>Printing modelbased-objects</h2><span id='topic+print.estimate_contrasts'></span>

<h3>Description</h3>

<p><code>print()</code> method for <strong>modelbased</strong> objects. Can be used to tweak the output
of tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'estimate_contrasts'
print(
  x,
  select = getOption("modelbased_select", NULL),
  include_grid = getOption("modelbased_include_grid", FALSE),
  full_labels = getOption("modelbased_full_labels", TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.estimate_contrasts_+3A_x">x</code></td>
<td>
<p>An object returned by the different <code style="white-space: pre;">&#8288;estimate_*()&#8288;</code> functions.</p>
</td></tr>
<tr><td><code id="print.estimate_contrasts_+3A_select">select</code></td>
<td>
<p>Determines which columns are printed and the table layout.
There are two options for this argument:
</p>

<ul>
<li> <p><strong>A string expression with layout pattern</strong>
</p>
<p><code>select</code> is a string with &quot;tokens&quot; enclosed in braces. These tokens will be
replaced by their associated columns, where the selected columns will be
collapsed into one column. Following tokens are replaced by the related
coefficients or statistics: <code>{estimate}</code>, <code>{se}</code>, <code>{ci}</code> (or <code>{ci_low}</code> and
<code>{ci_high}</code>), <code>{p}</code>, <code>{pd}</code> and <code>{stars}</code>. The token <code>{ci}</code> will be replaced
by <code style="white-space: pre;">&#8288;{ci_low}, {ci_high}&#8288;</code>. Example: <code>select = "{estimate}{stars} ({ci})"</code>
</p>
<p>It is possible to create multiple columns as well. A <code>|</code> separates values
into new cells/columns. Example: <code>select = "{estimate} ({ci})|{p}"</code>.
</p>
</li>
<li> <p><strong>A string indicating a pre-defined layout</strong>
</p>
<p><code>select</code> can be one of the following string values, to create one of the
following pre-defined column layouts:
</p>

<ul>
<li> <p><code>"minimal"</code>: Estimates, confidence intervals and numeric p-values, in two
columns. This is equivalent to <code>select = "{estimate} ({ci})|{p}"</code>.
</p>
</li>
<li> <p><code>"short"</code>: Estimate, standard errors and numeric p-values, in two columns.
This is equivalent to <code>select = "{estimate} ({se})|{p}"</code>.
</p>
</li>
<li> <p><code>"ci"</code>: Estimates and confidence intervals, no asterisks for p-values.
This is equivalent to <code>select = "{estimate} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se"</code>: Estimates and standard errors, no asterisks for p-values. This is
equivalent to <code>select = "{estimate} ({se})"</code>.
</p>
</li>
<li> <p><code>"ci_p"</code>: Estimates, confidence intervals and asterisks for p-values. This
is equivalent to <code>select = "{estimate}{stars} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se_p"</code>: Estimates, standard errors and asterisks for p-values. This is
equivalent to <code>select = "{estimate}{stars} ({se})"</code>..
</p>
</li></ul>

</li></ul>

<p>Using <code>select</code> to define columns will re-order columns and remove all columns
related to uncertainty (standard errors, confidence intervals), test statistics,
and p-values (and similar, like <code>pd</code> or <code>BF</code> for Bayesian models), because
these are assumed to be included or intentionally excluded when using <code>select</code>.
The new column order will be: Parameter columns first, followed by the &quot;glue&quot;
columns, followed by all remaining columns. If further columns should also be
placed first, add those as <code>focal_terms</code> attributes to <code>x</code>. I.e., following
columns are considers as &quot;parameter columns&quot; and placed first:
<code>c(easystats_columns("parameter"), attributes(x)$focal_terms)</code>.
</p>
<p><strong>Note:</strong> glue-like syntax is still experimental in the case of more complex models
(like mixed models) and may not return expected results.</p>
</td></tr>
<tr><td><code id="print.estimate_contrasts_+3A_include_grid">include_grid</code></td>
<td>
<p>Logical, if <code>TRUE</code>, the data grid is included in the
table output. Only applies to prediction-functions like <code>estimate_relation()</code>
or <code>estimate_link()</code>.</p>
</td></tr>
<tr><td><code id="print.estimate_contrasts_+3A_full_labels">full_labels</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), all labels for focal terms
are shown. If <code>FALSE</code>, redundant (duplicated) labels are removed from rows.</p>
</td></tr>
<tr><td><code id="print.estimate_contrasts_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>insight::format_table()</code> or
<code>insight::export_table()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns <code>x</code>.
</p>


<h3>Global Options to Customize Tables when Printing</h3>

<p>Columns and table layout can be customized using <code>options()</code>:
</p>

<ul>
<li> <p><code>modelbased_select</code>: <code style="white-space: pre;">&#8288;options(modelbased_select = &lt;string&gt;)&#8288;</code> will set a
default value for the <code>select</code> argument and can be used to define a custom
default layout for printing.
</p>
</li>
<li> <p><code>modelbased_include_grid</code>: <code>options(modelbased_include_grid = TRUE)</code> will
set a default value for the <code>include_grid</code> argument and can be used to
include data grids in the output by default or not.
</p>
</li>
<li> <p><code>modelbased_full_labels</code>: <code>options(modelbased_full_labels = FALSE)</code> will
remove redundant (duplicated) labels from rows.
</p>
</li></ul>



<h3>Note</h3>

<p>Use <code>print_html()</code> and <code>print_md()</code> to create tables in HTML or
markdown format, respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- lm(Petal.Length ~ Species, data = iris)
out &lt;- estimate_means(model, "Species")

# default
print(out)

# smaller set of columns
print(out, select = "minimal")

# remove redundant labels
data(efc, package = "modelbased")
efc &lt;- datawizard::to_factor(efc, c("c161sex", "c172code", "e16sex"))
levels(efc$c172code) &lt;- c("low", "mid", "high")
fit &lt;- lm(neg_c_7 ~ c161sex * c172code * e16sex, data = efc)
out &lt;- estimate_means(fit, c("c161sex", "c172code", "e16sex"))
print(out, full_labels = FALSE, select = "{estimate} ({se})")

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+visualisation_recipe'></span><span id='topic+standardize'></span><span id='topic+unstandardize'></span><span id='topic+print_md'></span><span id='topic+print_html'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>datawizard</dt><dd><p><code><a href="datawizard.html#topic+standardize">standardize</a></code>, <code><a href="datawizard.html#topic+standardize">unstandardize</a></code>, <code><a href="datawizard.html#topic+visualisation_recipe">visualisation_recipe</a></code></p>
</dd>
<dt>insight</dt><dd><p><code><a href="insight.html#topic+display">print_html</a></code>, <code><a href="insight.html#topic+display">print_md</a></code></p>
</dd>
</dl>

<hr>
<h2 id='smoothing'>Smoothing a vector or a time series</h2><span id='topic+smoothing'></span>

<h3>Description</h3>

<p>Smoothing a vector or a time series. For data.frames, the function will
smooth all numeric variables stratified by factor levels (i.e., will smooth
within each factor level combination).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothing(x, method = "loess", strength = 0.25, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smoothing_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="smoothing_+3A_method">method</code></td>
<td>
<p>Can be <a href="stats.html#topic+loess">&quot;loess&quot;</a> (default) or
<a href="stats.html#topic+smooth">&quot;smooth&quot;</a>. A loess smoothing can be slow.</p>
</td></tr>
<tr><td><code id="smoothing_+3A_strength">strength</code></td>
<td>
<p>This argument only applies when <code>method = "loess"</code>.
Degree of smoothing passed to <code>span</code> (see <code><a href="stats.html#topic+loess">loess()</a></code>).</p>
</td></tr>
<tr><td><code id="smoothing_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A smoothed vector or data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sin(seq(0, 4 * pi, length.out = 100)) + rnorm(100, 0, 0.2)
plot(x, type = "l")
lines(smoothing(x, method = "smooth"), type = "l", col = "blue")
lines(smoothing(x, method = "loess"), type = "l", col = "red")

x &lt;- sin(seq(0, 4 * pi, length.out = 10000)) + rnorm(10000, 0, 0.2)
plot(x, type = "l")
lines(smoothing(x, method = "smooth"), type = "l", col = "blue")
lines(smoothing(x, method = "loess"), type = "l", col = "red")
</code></pre>

<hr>
<h2 id='visualisation_recipe.estimate_predicted'>Automated plotting for 'modelbased' objects</h2><span id='topic+visualisation_recipe.estimate_predicted'></span><span id='topic+visualisation_recipe.estimate_slopes'></span><span id='topic+visualisation_recipe.estimate_grouplevel'></span>

<h3>Description</h3>

<p>Most 'modelbased' objects can be visualized using the <code>plot()</code> function, which
internally calls the <code>visualisation_recipe()</code> function. See the <strong>examples</strong>
below for more information and examples on how to create and customize plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'estimate_predicted'
visualisation_recipe(
  x,
  show_data = FALSE,
  point = NULL,
  line = NULL,
  pointrange = NULL,
  ribbon = NULL,
  facet = NULL,
  grid = NULL,
  join_dots = getOption("modelbased_join_dots", TRUE),
  numeric_as_discrete = getOption("modelbased_numeric_as_discrete", 8),
  ...
)

## S3 method for class 'estimate_slopes'
visualisation_recipe(
  x,
  line = NULL,
  pointrange = NULL,
  ribbon = NULL,
  facet = NULL,
  grid = NULL,
  ...
)

## S3 method for class 'estimate_grouplevel'
visualisation_recipe(
  x,
  line = NULL,
  pointrange = NULL,
  ribbon = NULL,
  facet = NULL,
  grid = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="visualisation_recipe.estimate_predicted_+3A_x">x</code></td>
<td>
<p>A modelbased object.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.estimate_predicted_+3A_show_data">show_data</code></td>
<td>
<p>Logical, if <code>TRUE</code>, display the &quot;raw&quot; data as a background
to the model-based estimation.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.estimate_predicted_+3A_point">point</code>, <code id="visualisation_recipe.estimate_predicted_+3A_line">line</code>, <code id="visualisation_recipe.estimate_predicted_+3A_pointrange">pointrange</code>, <code id="visualisation_recipe.estimate_predicted_+3A_ribbon">ribbon</code>, <code id="visualisation_recipe.estimate_predicted_+3A_facet">facet</code>, <code id="visualisation_recipe.estimate_predicted_+3A_grid">grid</code></td>
<td>
<p>Additional
aesthetics and parameters for the geoms (see customization example).</p>
</td></tr>
<tr><td><code id="visualisation_recipe.estimate_predicted_+3A_join_dots">join_dots</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default) and for categorical focal terms
in <code>by</code>, dots (estimates) are connected by lines, i.e. plots will be a
combination of dots with error bars and connecting lines. If <code>FALSE</code>, only
dots and error bars are shown. It is possible to set a global default value
using <code>options()</code>, e.g. <code>options(modelbased_join_dots = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.estimate_predicted_+3A_numeric_as_discrete">numeric_as_discrete</code></td>
<td>
<p>Maximum number of unique values in a numeric
predictor to treat that predictor as discrete. Defaults to <code>8</code>. Numeric
predictors are usually mapped to a continuous color scale, unless they have
only few unique values. In the latter case, numeric predictors are assumed to
represent &quot;categories&quot;, e.g. when only the mean value and +/- 1 standard
deviation around the mean are chosen as representative values for that
predictor. Use <code>FALSE</code> to always use continuous color scales for numeric
predictors. It is possible to set a global default value using <code>options()</code>,
e.g. <code>options(modelbased_numeric_as_discrete = 10)</code>.</p>
</td></tr>
<tr><td><code id="visualisation_recipe.estimate_predicted_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plotting works by mapping any predictors from the <code>by</code> argument to the x-axis,
colors, alpha (transparency) and facets. Thus, the appearance of the plot depends
on the order of the variables that you specify in the <code>by</code> argument. For instance,
the plots corresponding to <code>estimate_relation(model, by=c("Species", "Sepal.Length"))</code>
and <code>estimate_relation(model, by=c("Sepal.Length", "Species"))</code> will look different.
</p>
<p>The automated plotting is primarily meant for convenient visual checks, but
for publication-ready figures, we recommend re-creating the figures using the
<code>ggplot2</code> package directly.
</p>
<p>There are two options to remove the confidence bands or errors bars
from the plot. To remove error bars, simply set the <code>pointrange</code> geom to
<code>point</code>, e.g. <code>plot(..., pointrange = list(geom = "point"))</code>. To remove the
confidence bands from line geoms, use <code>ribbon = "none"</code>.
</p>


<h3>Global Options to Customize Plots</h3>

<p>Some arguments for <code>plot()</code> can get global defaults using <code>options()</code>:
</p>

<ul>
<li> <p><code>modelbased_join_dots</code>: <code style="white-space: pre;">&#8288;options(modelbased_join_dots = &lt;logical&gt;)&#8288;</code> will
set a default value for the <code>join_dots</code>.
</p>
</li>
<li> <p><code>modelbased_numeric_as_discrete</code>: <code style="white-space: pre;">&#8288;options(modelbased_numeric_as_discrete = &lt;number&gt;)&#8288;</code>
will set a default value for the <code>modelbased_numeric_as_discrete</code> argument.
Can also be <code>FALSE</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(ggplot2)
library(see)
# ==============================================
# estimate_relation, estimate_expectation, ...
# ==============================================
# Simple Model ---------------
x &lt;- estimate_relation(lm(mpg ~ wt, data = mtcars))
layers &lt;- visualisation_recipe(x)
layers
plot(layers)

# visualization_recipe() is called implicitly when you call plot()
plot(estimate_relation(lm(mpg ~ qsec, data = mtcars)))

## Not run: 
# And can be used in a pipe workflow
lm(mpg ~ qsec, data = mtcars) |&gt;
  estimate_relation(ci = c(0.5, 0.8, 0.9)) |&gt;
  plot()

# Customize aesthetics ----------

plot(x,
  point = list(color = "red", alpha = 0.6, size = 3),
  line = list(color = "blue", size = 3),
  ribbon = list(fill = "green", alpha = 0.7)
) +
  theme_minimal() +
  labs(title = "Relationship between MPG and WT")

# Customize raw data -------------

plot(x, point = list(geom = "density_2d_filled"), line = list(color = "white")) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(legend.position = "none")

# Single predictors examples -----------

plot(estimate_relation(lm(Sepal.Length ~ Species, data = iris)))

# 2-ways interaction ------------

# Numeric * numeric
x &lt;- estimate_relation(lm(mpg ~ wt * qsec, data = mtcars))
plot(x)

# Numeric * factor
x &lt;- estimate_relation(lm(Sepal.Width ~ Sepal.Length * Species, data = iris))
plot(x)

# ==============================================
# estimate_means
# ==============================================
# Simple Model ---------------
x &lt;- estimate_means(lm(Sepal.Width ~ Species, data = iris), by = "Species")
layers &lt;- visualisation_recipe(x)
layers
plot(layers)

# Customize aesthetics
layers &lt;- visualisation_recipe(x,
  point = list(width = 0.03, color = "red"),
  pointrange = list(size = 2, linewidth = 2),
  line = list(linetype = "dashed", color = "blue")
)
plot(layers)

# Two levels ---------------
data &lt;- mtcars
data$cyl &lt;- as.factor(data$cyl)

model &lt;- lm(mpg ~ cyl * wt, data = data)

x &lt;- estimate_means(model, by = c("cyl", "wt"))
plot(x)


# GLMs ---------------------
data &lt;- data.frame(vs = mtcars$vs, cyl = as.factor(mtcars$cyl))
x &lt;- estimate_means(glm(vs ~ cyl, data = data, family = "binomial"), by = c("cyl"))
plot(x)

## End(Not run)


# ==============================================
# estimate_slopes
# ==============================================
model &lt;- lm(Sepal.Width ~ Species * Petal.Length, data = iris)
x &lt;- estimate_slopes(model, trend = "Petal.Length", by = "Species")

layers &lt;- visualisation_recipe(x)
layers
plot(layers)

## Not run: 
# Customize aesthetics and add horizontal line and theme
layers &lt;- visualisation_recipe(x, pointrange = list(size = 2, linewidth = 2))
plot(layers) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(y = "Effect of Petal.Length", title = "Marginal Effects")

model &lt;- lm(Petal.Length ~ poly(Sepal.Width, 4), data = iris)
x &lt;- estimate_slopes(model, trend = "Sepal.Width", by = "Sepal.Width", length = 20)
plot(visualisation_recipe(x))

model &lt;- lm(Petal.Length ~ Species * poly(Sepal.Width, 3), data = iris)
x &lt;- estimate_slopes(model, trend = "Sepal.Width", by = c("Sepal.Width", "Species"))
plot(visualisation_recipe(x))

## End(Not run)


# ==============================================
# estimate_grouplevel
# ==============================================
## Not run: 
data &lt;- lme4::sleepstudy
data &lt;- rbind(data, data)
data$Newfactor &lt;- rep(c("A", "B", "C", "D"))

# 1 random intercept
model &lt;- lme4::lmer(Reaction ~ Days + (1 | Subject), data = data)
x &lt;- estimate_grouplevel(model)
layers &lt;- visualisation_recipe(x)
layers
plot(layers)

# 2 random intercepts
model &lt;- lme4::lmer(Reaction ~ Days + (1 | Subject) + (1 | Newfactor), data = data)
x &lt;- estimate_grouplevel(model)
plot(x) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  theme_minimal()
# Note: we need to use hline instead of vline because the axes is flipped

model &lt;- lme4::lmer(Reaction ~ Days + (1 + Days | Subject) + (1 | Newfactor), data = data)
x &lt;- estimate_grouplevel(model)
plot(x)

## End(Not run)

</code></pre>

<hr>
<h2 id='zero_crossings'>Find zero-crossings and inversion points</h2><span id='topic+zero_crossings'></span><span id='topic+find_inversions'></span>

<h3>Description</h3>

<p>Find zero crossings of a vector, i.e., indices when the numeric variable
crosses 0. It is useful for finding the points where a function changes by
looking at the zero crossings of its derivative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zero_crossings(x)

find_inversions(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zero_crossings_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of zero crossings or points of inversion.
</p>


<h3>See Also</h3>

<p>Based on the <code>uniroot.all</code> function from the rootSolve package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sin(seq(0, 4 * pi, length.out = 100))
# plot(x, type = "b")

modelbased::zero_crossings(x)
modelbased::find_inversions(x)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
