<!DOCTYPE html><html lang="en"><head><title>Help for package conTree</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {conTree}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#conTree-package'><p>Contrast and Boosted Trees</p></a></li>
<li><a href='#age_data'><p>Age and Demographics data</p></a></li>
<li><a href='#air_quality'><p>Air Quality Data from UC Irvine Machine Learning Repository</p></a></li>
<li><a href='#census'><p>Census Data Example from UC Irvine Machine Learning Repository</p></a></li>
<li><a href='#contrast'><p>Build contrast tree</p></a></li>
<li><a href='#getnodes'><p>Get terminal node observation assignments</p></a></li>
<li><a href='#lofcurve'><p>Produce lack-of-fit curve for a contrast tree</p></a></li>
<li><a href='#nodesum'><p>Summarize contrast tree</p></a></li>
<li><a href='#onesample_parameters'><p>Return the one sample parameters used in fortran discrepancy</p>
functions</a></li>
<li><a href='#predtrast'><p>Predict y-values from boosted contrast model</p></a></li>
<li><a href='#prune'><p>Prune a contrast tree</p></a></li>
<li><a href='#prune.seq'><p>Show all possible pruned subtrees</p></a></li>
<li><a href='#save_rfun'><p>Save the function f for calling from fortran</p></a></li>
<li><a href='#treesum'><p>Print terminal node x-region boundaries</p></a></li>
<li><a href='#xval'><p>Cross-validate boosted contrast tree boosted with (new) data</p></a></li>
<li><a href='#ydist'><p>Transform z-values t(z) such that the distribution of <code class="reqn">p(t(z) | x)</code> approximates <code class="reqn">p(t(y | x)</code> for type = 'dist' only</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Contrast Trees and Boosting</td>
</tr>
<tr>
<td>Description:</td>
<td>Contrast trees represent a new approach for assessing the
    accuracy of many types of machine learning estimates that are not
    amenable to standard (cross) validation methods; see "Contrast
    trees and distribution boosting", Jerome H. Friedman (2020)
    &lt;<a href="https://doi.org/10.1073%2Fpnas.1921562117">doi:10.1073/pnas.1921562117</a>&gt;. In situations where inaccuracies
    are detected, boosted contrast trees can often improve
    performance. Functions are provided to to build such trees in
    addition to a special case, distribution boosting, an assumption
    free method for estimating the full probability distribution of an
    outcome variable given any set of joint input predictor variable
    values.</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3-1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://jhfhub.github.io/conTree_tutorial/">https://jhfhub.github.io/conTree_tutorial/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bnaras/conTree/issues">https://github.com/bnaras/conTree/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>randomForest, knitr, rmarkdown</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-21 20:55:53 UTC; naras</td>
</tr>
<tr>
<td>Author:</td>
<td>Jerome Friedman [aut, cph],
  Balasubramanian Narasimhan [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Balasubramanian Narasimhan &lt;naras@stanford.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-22 09:20:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='conTree-package'>Contrast and Boosted Trees</h2><span id='topic+conTree-package'></span>

<h3>Description</h3>

<p>Contrast trees represent a new approach for assessing the accuracy
of many types of machine learning estimates that are not amenable
to standard (cross) validation methods. In situations where
inaccuracies are detected, boosted contrast trees can often improve
performance. Functions are provided to to build such trees in
addition to a special case, distribution boosting, an assumption
free method for estimating the full probability distribution of an
outcome variable given any set of joint input predictor variable
values.
</p>


<h3>Author(s)</h3>

<p>Original code (C) by Jerome H. Friedman, minor modifications,
formatting, and packaging by Balasubramanian Narasimhan
</p>


<h3>References</h3>

<p>Jerome Friedman (2019). <em>Contrast Trees and
Distribution Boosting</em> <a href="https://arxiv.org/abs/1912.03785">https://arxiv.org/abs/1912.03785</a>
</p>

<hr>
<h2 id='age_data'>Age and Demographics data</h2><span id='topic+age_data'></span>

<h3>Description</h3>

<p>The data come from 9243 questionnaires filled out by shopping mall
customers in the San Francisco Bay Area (Impact Resources, Inc.,
Columbus, OH). Here we attempt to estimate a persons age as a
function of the other 13 demographic variables. For this data set
age value is reported as being in one of seven intervals <code style="white-space: pre;">&#8288;{13-17, 18-24, 25-34, 35-44, 45-54, 55-64, &gt;= 65}&#8288;</code>. Each persons age is
randomly generated uniformly within its corresponding reported
interval. For the last interval an exponential distribution was
used with mean corresponding to life expectancy after reaching age
65.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>age_data
</code></pre>


<h3>Format</h3>



<h4><code>age_data</code></h4>

<p>A list of 3 items.
</p>

<dl>
<dt>xage</dt><dd><p>data frame of 8856 observations on 13 variables</p>
</dd>
<dt>yage</dt><dd><p>Randomly generated age in the range above</p>
</dd>
<dt>gbage</dt><dd><p>gradient boosting model for median age given x</p>
</dd>
</dl>




<h3>Source</h3>

<p>The Elements of Statistical Learning, Data Mining, Second Edition, by Hastie,
Tibshirani, and Friedman.
</p>

<hr>
<h2 id='air_quality'>Air Quality Data from UC Irvine Machine Learning Repository</h2><span id='topic+air_quality'></span>

<h3>Description</h3>

<p>The data set consists of hourly averaged measurements from an array
of 5 metal oxide chemical sensors embedded in an air quality
chemical multisensor device. The outcome variable <code>y</code> is the
corresponding true hourly averaged concentration CO taken from a
reference analyzer. The input variables <code>x</code> are taken to be the
corresponding hourly averaged measurements of the 13 other
quantities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>air_quality
</code></pre>


<h3>Format</h3>



<h4><code>air_quality</code></h4>

<p>A list with 4 items.
</p>

<dl>
<dt>xco</dt><dd><p>data frame of 9357 observations on 13 variables</p>
</dd>
<dt>yco</dt><dd><p>hourly averaged CO concentration</p>
</dd>
<dt>zco</dt><dd><p>sample membership indicator</p>
</dd>
<dt>pr2</dt><dd><p>probability propensity score</p>
</dd>
</dl>




<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/air+quality">https://archive.ics.uci.edu/ml/datasets/air+quality</a>
</p>

<hr>
<h2 id='census'>Census Data Example from UC Irvine Machine Learning Repository</h2><span id='topic+census'></span>

<h3>Description</h3>

<p>Includes a data frame of 1994 US census income from 48,842 people
divided into a training set of 32,561 and an independent test set
of 16,281. The training outcome variable <code>y</code> (<code>yt</code> for test) is
binary and indicates whether or not a person’s income is greater
than $50,000 per year. There are 12 predictor variables <code>x</code> (<code>xt</code>
for test) consisting of various demographic and financial
properties associated with each person. It also included estimates
of <code class="reqn">Pr(y=1|x)</code> obtained by several machine learning methods:
gradient boosting on logistic scale using maximum likelihood (GBL),
random forest (RF), and gradient boosting on the probability scale
(GBP) using least–squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>census
</code></pre>


<h3>Format</h3>



<h4><code>census</code></h4>

<p>A list of 10 items.
</p>

<dl>
<dt>x</dt><dd><p>training data frame of 32561 observations on 12 predictor variables</p>
</dd>
<dt>y</dt><dd><p>training binary response whether salary is above $50K or not</p>
</dd>
<dt>xt</dt><dd><p>test data frame of 16281 observations predictor variables</p>
</dd>
<dt>yt</dt><dd><p>test binary response whether salary is above $50K or not</p>
</dd>
<dt>gbl</dt><dd><p>training GBL response variable</p>
</dd>
<dt>gblt</dt><dd><p>test GBL response variable</p>
</dd>
<dt>gbp</dt><dd><p>training GBP response variable</p>
</dd>
<dt>gbpt</dt><dd><p>test GBP response variable</p>
</dd>
<dt>rf</dt><dd><p>training RF response probabilities</p>
</dd>
<dt>rft</dt><dd><p>test GBP response probabilities</p>
</dd>
</dl>




<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/census+income">https://archive.ics.uci.edu/ml/datasets/census+income</a>
</p>

<hr>
<h2 id='contrast'>Build contrast tree</h2><span id='topic+contrast'></span><span id='topic+modtrast'></span><span id='topic+bootcri'></span>

<h3>Description</h3>

<p>Build contrast tree
</p>
<p>Build boosted contrast tree model
</p>
<p>Bootstrap contrast trees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contrast(
  x,
  y,
  z,
  w = rep(1, nrow(x)),
  cat.vars = NULL,
  not.used = NULL,
  qint = 10,
  xmiss = 9e+35,
  tree.size = 10,
  min.node = 500,
  mode = c("onesamp", "twosamp"),
  type = "dist",
  pwr = 2,
  quant = 0.5,
  nclass = NULL,
  costs = NULL,
  cdfsamp = 500,
  verbose = FALSE,
  tree.store = 1e+06,
  cat.store = 1e+05,
  nbump = 1,
  fnodes = 0.25,
  fsamp = 1,
  doprint = FALSE
)

modtrast(
  x,
  y,
  z,
  w = rep(1, nrow(x)),
  cat.vars = NULL,
  not.used = NULL,
  qint = 10,
  xmiss = 9e+35,
  tree.size = 10,
  min.node = 500,
  learn.rate = 0.1,
  type = c("dist", "diff", "class", "quant", "prob", "maxmean", "diffmean"),
  pwr = 2,
  quant = 0.5,
  cdfsamp = 500,
  verbose = FALSE,
  tree.store = 1e+06,
  cat.store = 1e+05,
  nbump = 1,
  fnodes = 0.25,
  fsamp = 1,
  doprint = FALSE,
  niter = 100,
  doplot = FALSE,
  span = 0,
  plot.span = 0.15,
  print.itr = 10
)

bootcri(
  x,
  y,
  z,
  w = rep(1, nrow(x)),
  cat.vars = NULL,
  not.used = NULL,
  qint = 10,
  xmiss = 9e+35,
  tree.size = 10,
  min.node = 500,
  mode = "onesamp",
  type = "dist",
  pwr = 2,
  quant = 0.5,
  nclass = NULL,
  costs = NULL,
  cdfsamp = 500,
  verbose = FALSE,
  tree.store = 1e+06,
  cat.store = 1e+05,
  nbump = 100,
  fnodes = 1,
  fsamp = 1,
  doprint = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="contrast_+3A_x">x</code></td>
<td>
<p>training input predictor data matrix or data frame. Rows
are observations and columns are variables. Must be a numeric
matrix or a data frame.</p>
</td></tr>
<tr><td><code id="contrast_+3A_y">y</code></td>
<td>
<p>vector, or matrix containing training data input outcome
values or censoring intervals for each observation. if y is a
vector then it implies that y uncensored outcome values or
other contrasting quantity. If y is a matrix, then then y is
assumed to be censoring intervals for each observation; see
details below</p>
</td></tr>
<tr><td><code id="contrast_+3A_z">z</code></td>
<td>
<p>vector containing values of a second contrasting quantity
for each observation</p>
</td></tr>
<tr><td><code id="contrast_+3A_w">w</code></td>
<td>
<p>training observation weights</p>
</td></tr>
<tr><td><code id="contrast_+3A_cat.vars">cat.vars</code></td>
<td>
<p>vector of column labels (numbers or names)
indicating categorical variables (factors). All variables not
so indicated are assumed to be orderable numeric; see details
below</p>
</td></tr>
<tr><td><code id="contrast_+3A_not.used">not.used</code></td>
<td>
<p>vector of column labels (numbers or names)
indicating predictor variables not to be used in the model</p>
</td></tr>
<tr><td><code id="contrast_+3A_qint">qint</code></td>
<td>
<p>maximum number of split evaluation points on each
predictor variable</p>
</td></tr>
<tr><td><code id="contrast_+3A_xmiss">xmiss</code></td>
<td>
<p>missing value flag. Must be numeric and larger than
any non missing predictor/abs(response) variable value.
Predictor variable values greater than or equal to xmiss are
regarded as missing. Predictor variable data values of <code>NA</code> are
internally set to the value of xmiss and thereby regarded as
missing</p>
</td></tr>
<tr><td><code id="contrast_+3A_tree.size">tree.size</code></td>
<td>
<p>maximum number of terminal nodes in generated
trees</p>
</td></tr>
<tr><td><code id="contrast_+3A_min.node">min.node</code></td>
<td>
<p>minimum number of training observations in each
tree terminal node</p>
</td></tr>
<tr><td><code id="contrast_+3A_mode">mode</code></td>
<td>
<p>indicating one or two-sample contrast; see details
below for how it works with type</p>
</td></tr>
<tr><td><code id="contrast_+3A_type">type</code></td>
<td>
<p>type of contrast; see details below for how it works
with mode</p>
</td></tr>
<tr><td><code id="contrast_+3A_pwr">pwr</code></td>
<td>
<p>center split bias parameter. Larger values produce less
center split bias.</p>
</td></tr>
<tr><td><code id="contrast_+3A_quant">quant</code></td>
<td>
<p>specified quantile p (type='quant' only)</p>
</td></tr>
<tr><td><code id="contrast_+3A_nclass">nclass</code></td>
<td>
<p>number of classes (type ='class' only) default=2</p>
</td></tr>
<tr><td><code id="contrast_+3A_costs">costs</code></td>
<td>
<p>nclass by nclass misclassification cost matrix
(type='class' only); default is equal valued diagonal (error
rate)</p>
</td></tr>
<tr><td><code id="contrast_+3A_cdfsamp">cdfsamp</code></td>
<td>
<p>= maximum subsample size used to compute censored
CDF (censoring only)</p>
</td></tr>
<tr><td><code id="contrast_+3A_verbose">verbose</code></td>
<td>
<p>a logical flag indicating print/don't print censored
CDF computation progress, default <code>FALSE</code></p>
</td></tr>
<tr><td><code id="contrast_+3A_tree.store">tree.store</code></td>
<td>
<p>size of internal tree storage. Decrease value in
response to memory allocation error. Increase value for very
large values of max.trees and/or tree.size, or in response to
diagnostic message or erratic program behavior</p>
</td></tr>
<tr><td><code id="contrast_+3A_cat.store">cat.store</code></td>
<td>
<p>size of internal categorical value
storage. Decrease value in response to memory allocation
error. Increase value for very large values of max.trees and/or
tree.size in the presence of many categorical variables
(factors) with many levels, or in response to diagnostic
message or erratic program behavior</p>
</td></tr>
<tr><td><code id="contrast_+3A_nbump">nbump</code></td>
<td>
<p>number of bootstrap replications</p>
</td></tr>
<tr><td><code id="contrast_+3A_fnodes">fnodes</code></td>
<td>
<p>top fraction of node criteria used to evaluate trial
bumped trees</p>
</td></tr>
<tr><td><code id="contrast_+3A_fsamp">fsamp</code></td>
<td>
<p>fraction of observations used in each bootstrap sample
for bumped trees</p>
</td></tr>
<tr><td><code id="contrast_+3A_doprint">doprint</code></td>
<td>
<p>logical flag <code>TRUE/FALSE</code> implies do/don't plot iteration progress</p>
</td></tr>
<tr><td><code id="contrast_+3A_learn.rate">learn.rate</code></td>
<td>
<p>learning rate parameter in <code style="white-space: pre;">&#8288;(0,1]&#8288;</code></p>
</td></tr>
<tr><td><code id="contrast_+3A_niter">niter</code></td>
<td>
<p>number of trees</p>
</td></tr>
<tr><td><code id="contrast_+3A_doplot">doplot</code></td>
<td>
<p>a flag to display/not display graphical plots</p>
</td></tr>
<tr><td><code id="contrast_+3A_span">span</code></td>
<td>
<p>span for qq-plot transformation smoother</p>
</td></tr>
<tr><td><code id="contrast_+3A_plot.span">plot.span</code></td>
<td>
<p>running median smoother span for discrepancy plot (<code>doplot = TRUE</code>, only)</p>
</td></tr>
<tr><td><code id="contrast_+3A_print.itr">print.itr</code></td>
<td>
<p>tree discrepancy printing iteration interval</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The varible <code>xmiss</code> is the missing value flag, Must be
numeric and larger than any non missing predictor/abs(response) variable value.  Predictor variable values greater than or equal to <code>xmiss</code> are regarded as missing. Predictor variable data values of <code>NA</code> are internally set to the value of xmiss and thereby regarded as missing.
</p>
<p>If the response y is a matrix, it is assumed to contain censoring
intervals for each observation. Rows are observations.
</p>

<ul>
<li><p> First/second column are lower/upper boundary of censoring interval (Can be same value for uncensored observations) respectively
</p>
</li>
<li> <p><code>y[,1] = -xmiss</code> implies outcome less than or equal to <code>y[,2]</code> (censored from above)
</p>
</li>
<li> <p><code>y[,2] = xmiss</code> implies outcome greater than or equal to <code>y[,1]</code>
</p>
</li></ul>

<p>Note that censoring is only allowed for <code>type='dist'</code>; see further below.
</p>
<p>If x is a data frame and <code>cat.vars</code> (the columns indicating
categorical variables), is missing, then components of type factor
are treated as categorical variables. Ordered factors should be
input as type numeric with appropriate numerical scores. If
<code>cat.vars</code> is present it will over ride the data frame typing.
</p>
<p>The <code>mode</code> argument is either
</p>

<ul>
<li> <p><code>'onesamp'</code> (default) meaning one <code>x</code>-vector for each <code style="white-space: pre;">&#8288;(x,z)&#8288;</code> pair
</p>
</li>
<li> <p><code>'twosamp'</code> implies two-sample contrast with
</p>

<ul>
<li> <p><code>x</code> are predictor variables for both samples
</p>
</li>
<li> <p><code>y</code> are outcomes for both samples
</p>
</li>
<li> <p><code>z</code> is sample identity flag with <code>z &lt; 0</code> implying first sample observations and <code>z &gt; 0</code>, the second sample observations.
The <code>type</code> argument indicates the type of contrast. It can be either a user defined function or a string. If <code>mode</code> is <code>'onesamp'</code>, the default,
</p>
</li></ul>

</li>
<li> <p><code>type = 'dist'</code> (default) implies contrast distribution of <code>y</code> with that of <code>z</code> (<code>y</code> may be censored - see above)
</p>
</li>
<li> <p><code>type = 'diff'</code> implies contrast joint paired values of <code>y</code> and <code>z</code>
</p>
</li>
<li> <p><code>type = 'class'</code> implies classification: contrast class labels <code>y[i]</code> and <code>z[i]</code> are two class labels (in <code>1:nclass</code>) for each observation.
</p>
</li>
<li> <p><code>type = 'prob'</code> implies contrast predicted with empirical probabilities: <code>y[i] = 0/1</code> and  <code>z[i]</code> is predicted probability <code class="reqn">P(y=1)</code> for <code class="reqn">i</code>-th observation
</p>
</li>
<li> <p><code>type = 'quant'</code> is contrast predicted with empirical quantiles: <code>y[i]</code> is outcome value for <code class="reqn">i</code>-th observation and <code>z[i]</code> is predicted <code class="reqn">p</code>-th quantile value (see below) for <code class="reqn">i</code>-th observation <code class="reqn">(0 &lt; p &lt;1)</code>
</p>
</li>
<li> <p><code>type = 'diffmean'</code> implies maximize absolute mean difference between <code>y</code> and <code>z</code>
</p>
</li>
<li> <p><code>type = 'maxmean'</code> implies maximize signed mean difference between <code>y</code> and <code>z</code>
</p>
</li></ul>

<p>When mode is <code>'twosamp'</code>
</p>

<ul>
<li> <p><code>type= 'dist'</code> (default) implies contrast <code>y</code> distributions of both samples
</p>
</li>
<li> <p><code>type = 'diffmean'</code> implies maximize absolute difference between means of two samples
</p>
</li>
<li> <p><code>type = 'maxmean'</code> maximize signed difference between means of two samples
</p>
</li></ul>

<p>When <code>type</code> is a function, it must be a function of three arguments
<code>f(y,z,w)</code> where <code>y</code> and <code>z</code> are double vectors and <code>w</code> is a weight
vector, not necessarily normalized. The function should return a
double vector of length 1 as the result. See example below.
</p>


<h3>Value</h3>

<p>a contrast model object use as input to interpretation
procedures
</p>
<p>a contrast model object to be used with predtrast()
</p>
<p>a named list with <code>out$bcri</code> the bootstraped discrepancy values
</p>


<h3>Author(s)</h3>

<p>Jerome H. Friedman
</p>


<h3>References</h3>

<p>Jerome H. Friedman (2020). <a href="doi:10.1073/pnas.1921562117">doi:10.1073/pnas.1921562117</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(census, package = "conTree")
dx &lt;- 1:10000; dxt &lt;- 10001:16281;
# Build contrast tree
tree &lt;- contrast(census$xt[dx,], census$yt[dx], census$gblt[dx], type = 'prob')
# Summarize tree
treesum(tree)
# Get terminal node identifiers for regions containing observations 1 through 10
getnodes(tree, x = census$xt[1:10, ])
# Plot nodes
nodeplots(tree, x = census$xt[dx, ], y = census$yt[dx], z = census$gblt[dx])
# Summarize contrast tree against (precomputed) gradient boosting
# on logistic scale using maximum likelihood (GBL)
nodesum(tree, census$xt[dxt,], census$yt[dxt], census$gblt[dxt])
# Use a custom R discrepancy function to build a contrast tree
dfun &lt;- function(y, z, w) {
   w  &lt;- w / sum(w)
   abs(sum(w * (y - z)))
}
tree2 &lt;- contrast(census$xt[dx,], census$yt[dx], census$gblt[dx], type = dfun)
nodesum(tree2, census$xt[dxt,], census$yt[dxt], census$gblt[dxt])
# Generate lack of fit curve
lofcurve(tree, census$xt[dx,], census$yt[dx], census$gblt[dx])
# Build contrast tree boosting models
# Use small # of iterations for illustration (typically &gt;= 200)
modgbl = modtrast(census$x, census$y, census$gbl, type = 'prob', niter = 10)
# Plot model accuracy as a function of iteration number
xval(modgbl, census$x, census$y, census$gbl, col = 'red')
# Produce predictions from modtrast() for new data.
ypred &lt;- predtrast(modgbl, census$xt, census$gblt, num = modgbl$niter)
# Produce distribution boosting estimates
yhat &lt;- predtrast(modgbl, census$xt, census$gblt, num = modgbl$niter)
</code></pre>

<hr>
<h2 id='getnodes'>Get terminal node observation assignments</h2><span id='topic+getnodes'></span>

<h3>Description</h3>

<p>Get terminal node observation assignments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getnodes(tree, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getnodes_+3A_tree">tree</code></td>
<td>
<p>model object output from contrast() or prune()</p>
</td></tr>
<tr><td><code id="getnodes_+3A_x">x</code></td>
<td>
<p>training input predictor data matrix or data frame in same format as in contrast()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of tree terminal node identifiers (numbers) corresponding to each observation (row of x)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+contrast">contrast()</a></code>
</p>

<hr>
<h2 id='lofcurve'>Produce lack-of-fit curve for a contrast tree</h2><span id='topic+lofcurve'></span>

<h3>Description</h3>

<p>Produce lack-of-fit curve for a contrast tree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lofcurve(
  tree,
  x,
  y,
  z,
  w = rep(1, length(y)),
  doplot = "first",
  col = "black",
  ylim = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lofcurve_+3A_tree">tree</code></td>
<td>
<p>model object output from contrast() or prune()</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_x">x</code></td>
<td>
<p>training input predictor data matrix or data frame in same format as in contrast()</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_y">y</code></td>
<td>
<p>vector, or matrix containing training data input outcome values or censoring intervals for each observation in same format as in contrast()</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_z">z</code></td>
<td>
<p>vector containing values of a second contrasting quantity for each observation in same observation format as in contrast ()</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_w">w</code></td>
<td>
<p>observation weights</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_doplot">doplot</code></td>
<td>
<p>logical flag. doplot=&quot;first&quot; implies start new display. doplot=&quot;next&quot; implies super impose plot on existing display. doplot=&quot;none&quot; implies no plot displayed.</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_col">col</code></td>
<td>
<p>color of plotted curve</p>
</td></tr>
<tr><td><code id="lofcurve_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of plotted <code>x</code> and <code>y</code> points
</p>

<hr>
<h2 id='nodesum'>Summarize contrast tree</h2><span id='topic+nodesum'></span><span id='topic+nodeplots'></span>

<h3>Description</h3>

<p>Summarize contrast tree
</p>
<p>Show graphical terminal node summaries
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nodesum(tree, x, y, z, w = rep(1, nrow(x)), doplot = FALSE)

nodeplots(
  tree,
  x,
  y,
  z,
  w = rep(1, nrow(x)),
  nodes = NULL,
  xlim = NULL,
  ylim = NULL,
  pts = "FALSE",
  span = 0.15
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nodesum_+3A_tree">tree</code></td>
<td>
<p>model object output from contrast() or prune()</p>
</td></tr>
<tr><td><code id="nodesum_+3A_x">x</code></td>
<td>
<p>training input predictor data matrix or data frame in same format as in contrast()</p>
</td></tr>
<tr><td><code id="nodesum_+3A_y">y</code></td>
<td>
<p>vector, or matrix containing training data input outcome values or censoring intervals for each observation in same format as in contrast()</p>
</td></tr>
<tr><td><code id="nodesum_+3A_z">z</code></td>
<td>
<p>vector containing values of a second contrasting quantity for each observation in same observation format as in contrast()</p>
</td></tr>
<tr><td><code id="nodesum_+3A_w">w</code></td>
<td>
<p>observation weights</p>
</td></tr>
<tr><td><code id="nodesum_+3A_doplot">doplot</code></td>
<td>
<p>a flag to display/not display plots of output quantities</p>
</td></tr>
<tr><td><code id="nodesum_+3A_nodes">nodes</code></td>
<td>
<p>selected tree terminal node identifiers. Default is all terminal nodes</p>
</td></tr>
<tr><td><code id="nodesum_+3A_xlim">xlim</code></td>
<td>
<p>x-axis limit</p>
</td></tr>
<tr><td><code id="nodesum_+3A_ylim">ylim</code></td>
<td>
<p>y-axis limit</p>
</td></tr>
<tr><td><code id="nodesum_+3A_pts">pts</code></td>
<td>
<p>logical flag indicating whether to show <code>y</code>-values as circles/points (<code>type = 'pp'</code> only)</p>
</td></tr>
<tr><td><code id="nodesum_+3A_span">span</code></td>
<td>
<p>running median smoother span (<code>type = 'diff'</code> only)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The graphical representations of terminal node contrasts depend on the tree type
graphical representations of terminal node contrasts depending on tree type
-<code>type = 'dist'</code> implies CDFs of y and z in each terminal node. (Only top nine nodes are shown). Note that y can be censored (see above)
-<code>type = 'diff'</code> implies plot y versus z in each terminal node. (Only top nine nodes are shown).
-<code>type = 'class'</code> implies barplot of misclassification risk (upper) amd total weight (lower) in each terminal node
-<code>type = 'prob'</code> implies upper barplot contrasting empirical (blue) and predicted (red) <code class="reqn">p(y=1)</code> in each terminal node. Lower barplot showing total weight in each terminal node.
</p>

<ul>
<li><p> type = 'quant' =&gt; upper barplot of fraction of y-values greater than or equal to corresponding z-values (quantile prediction) in each terminal node. Horizontal line reflects specified target quantile. Lower barplot showing total  weight in each terminal node.
</p>
</li>
<li> <p><code>type = 'diffmean'</code> or <code>type = 'maxmean'</code> implies upper barplot contrasting y-mean (blue) and z-mean (red) in each terminal node. Lower barplot showing total weight in each terminal node.
</p>
</li></ul>



<h3>Value</h3>

<p>a named list of four items:
</p>

<ul>
<li> <p><code>nodes</code> the tree terminal node identifiers
</p>
</li>
<li> <p><code>cri</code> the terminal node criterion values (depends on contrast type see above)
</p>
</li>
<li> <p><code>wt</code> sum of weights in each terminal node
</p>
</li>
<li> <p><code>avecri</code> weighted criterion average over all terminal nodes
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+contrast">contrast()</a></code>
</p>

<hr>
<h2 id='onesample_parameters'>Return the one sample parameters used in fortran discrepancy
functions</h2><span id='topic+onesample_parameters'></span><span id='topic+twosample_parameters'></span>

<h3>Description</h3>

<p>These functions are mostly useful when one wants to
test one's own discrepancy function in R <code>f(y, z, w)</code> to
determine if the results are correct. So a natural test
is to experiment by programming one of the already implemented
discrepancy functions in R. However, the Fortran
implementations of such discrepancy measures use some
parameters in the computations and therefore the returned
results from a simple R implementation may not exactly
match. Using these parameters, one can ensure that they
do. These are to be interpreted as follows.  For one sample,
the <code>type = "dist"</code> implementation in the package returns 0 if
the length of <code>y</code> is less than <code>nmin</code> which is (100L). The <code>eps = 1.0e-5</code> parameter is used to ensure that the denominator in
the formula for the Anderson-Darling statistic is at least
<code>eps</code>. Next, for <code>type = "prob"</code>, if the length of the vector
is less than <code>nmin = 20</code> the discrepancy is computed to be
0. And so on. Refer to the R and Fortran source for further
details as this is an advanced topic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>onesample_parameters()

twosample_parameters()
</code></pre>


<h3>Value</h3>

<p>a named list for each of the types.
</p>

<hr>
<h2 id='predtrast'>Predict y-values from boosted contrast model</h2><span id='topic+predtrast'></span>

<h3>Description</h3>

<p>Predict y-values from boosted contrast model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predtrast(model, x, z, num = model$niter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predtrast_+3A_model">model</code></td>
<td>
<p>model object output from modtrast()</p>
</td></tr>
<tr><td><code id="predtrast_+3A_x">x</code></td>
<td>
<p>x-values for new data</p>
</td></tr>
<tr><td><code id="predtrast_+3A_z">z</code></td>
<td>
<p>z-values for new data</p>
</td></tr>
<tr><td><code id="predtrast_+3A_num">num</code></td>
<td>
<p>number of trees used to compute model values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted y-values for new data from model
</p>


<h3>See Also</h3>

<p><code><a href="#topic+contrast">contrast()</a></code>
</p>

<hr>
<h2 id='prune'>Prune a contrast tree</h2><span id='topic+prune'></span>

<h3>Description</h3>

<p>Prune a contrast tree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prune(tree, thr = 0.1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prune_+3A_tree">tree</code></td>
<td>
<p>a tree model object output from contrast</p>
</td></tr>
<tr><td><code id="prune_+3A_thr">thr</code></td>
<td>
<p>a split improvement threshold, default is 0.1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a bottom-up pruned tree with splits corresponding to improvement less than threshold <code>thr</code> removed
</p>

<hr>
<h2 id='prune.seq'>Show all possible pruned subtrees</h2><span id='topic+prune.seq'></span>

<h3>Description</h3>

<p>Show all possible pruned subtrees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prune.seq(tree, eps = 0.01, plot.it = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prune.seq_+3A_tree">tree</code></td>
<td>
<p>a tree model object output from contrast</p>
</td></tr>
<tr><td><code id="prune.seq_+3A_eps">eps</code></td>
<td>
<p>small increment defining grid of threshold values</p>
</td></tr>
<tr><td><code id="prune.seq_+3A_plot.it">plot.it</code></td>
<td>
<p>a logical flag indicating plot/don't plot of number of nodes versus threshold value for all pruned subtrees, default <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of two items:
</p>

<ul>
<li> <p><code>thr</code> a set of threshold values that sequentially reduce tree size
</p>
</li>
<li> <p><code>nodes</code> the corresponding tree sizes (number of terminal nodes)
</p>
</li></ul>


<hr>
<h2 id='save_rfun'>Save the function f for calling from fortran</h2><span id='topic+save_rfun'></span>

<h3>Description</h3>

<p>Save the function f for calling from fortran
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_rfun(f)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="save_rfun_+3A_f">f</code></td>
<td>
<p>the R function to be called using <code>.Fortran</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE, invisibly.
</p>

<hr>
<h2 id='treesum'>Print terminal node x-region boundaries</h2><span id='topic+treesum'></span>

<h3>Description</h3>

<p>Print terminal node x-region boundaries
</p>


<h3>Usage</h3>

<pre><code class='language-R'>treesum(tree, nodes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="treesum_+3A_tree">tree</code></td>
<td>
<p>model object output from contrast() or prune()</p>
</td></tr>
<tr><td><code id="treesum_+3A_nodes">nodes</code></td>
<td>
<p>vector of terminal node identifiers for the tree specifying the desired regions. The default is all terminal nodes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predictor variable x-boundaries defining each terminal node are printed.
</p>
<p>For numeric variables: variable | sign | value
</p>

<ul>
<li><p> sign + =&gt; value=lower boundary on variable
</p>
</li>
<li><p> sign - =&gt; value upper boundary on variable
</p>
</li></ul>

<p>For categorical variables:  cat variable | sign | set of values
</p>

<ul>
<li><p> sign + =&gt; values in node
</p>
</li>
<li><p> sign - =&gt; values not in node (compliment values in node) graphical representations of terminal node contrasts depend on the tree type
</p>
</li></ul>



<h3>Value</h3>

<p>No return value (invisble <code>NULL</code>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+contrast">contrast()</a></code>
</p>

<hr>
<h2 id='xval'>Cross-validate boosted contrast tree boosted with (new) data</h2><span id='topic+xval'></span>

<h3>Description</h3>

<p>Cross-validate boosted contrast tree boosted with (new) data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xval(
  mdl,
  x,
  y,
  z,
  num = length(mdl$tree),
  del = 10,
  span = 0.15,
  ylab = "Average  Discrepancy",
  doplot = "first",
  doprint = FALSE,
  col = "red"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="xval_+3A_mdl">mdl</code></td>
<td>
<p>model output from modtrast()</p>
</td></tr>
<tr><td><code id="xval_+3A_x">x</code></td>
<td>
<p>data predictor variables is same format as input to modtrast</p>
</td></tr>
<tr><td><code id="xval_+3A_y">y</code></td>
<td>
<p>data y values is same format as input to modtrast</p>
</td></tr>
<tr><td><code id="xval_+3A_z">z</code></td>
<td>
<p>data z values is same format as input to modtrast</p>
</td></tr>
<tr><td><code id="xval_+3A_num">num</code></td>
<td>
<p>number of trees used to compute model values</p>
</td></tr>
<tr><td><code id="xval_+3A_del">del</code></td>
<td>
<p>plot discrepancy value computed every del-th iteration (tree)</p>
</td></tr>
<tr><td><code id="xval_+3A_span">span</code></td>
<td>
<p>running median smoother span (<code>doplot=TRUE</code>, only)</p>
</td></tr>
<tr><td><code id="xval_+3A_ylab">ylab</code></td>
<td>
<p>graphical parameter ('doplot=&quot;first&quot;, only)</p>
</td></tr>
<tr><td><code id="xval_+3A_doplot">doplot</code></td>
<td>
<p>logical flag. doplot=&quot;first&quot; implies start new display. doplot=&quot;next&quot; implies super impose plot on existing display. doplot=&quot;none&quot; implies no plot displayed.</p>
</td></tr>
<tr><td><code id="xval_+3A_doprint">doprint</code></td>
<td>
<p>logical flag <code>TRUE/FALSE</code> implies do/don't print progress while executing, default <code>FALSE</code></p>
</td></tr>
<tr><td><code id="xval_+3A_col">col</code></td>
<td>
<p>color of plotted curve</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of two items: <code>ntree</code> the iteration numbers, and <code>error</code> the corresponding discrepancy values
</p>


<h3>See Also</h3>

<p><code><a href="#topic+contrast">contrast()</a></code>
</p>

<hr>
<h2 id='ydist'>Transform z-values t(z) such that the distribution of <code class="reqn">p(t(z) | x)</code> approximates <code class="reqn">p(t(y | x)</code> for type = 'dist' only</h2><span id='topic+ydist'></span>

<h3>Description</h3>

<p>Transform z-values t(z) such that the distribution of <code class="reqn">p(t(z) | x)</code> approximates <code class="reqn">p(t(y | x)</code> for type = 'dist' only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ydist(model, x, z, num = model$niter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ydist_+3A_model">model</code></td>
<td>
<p>model object output from modtrast()</p>
</td></tr>
<tr><td><code id="ydist_+3A_x">x</code></td>
<td>
<p>vector of predictor variable values for a (single) observation</p>
</td></tr>
<tr><td><code id="ydist_+3A_z">z</code></td>
<td>
<p>sample of z-values drawn from <code class="reqn">p(z | x)</code></p>
</td></tr>
<tr><td><code id="ydist_+3A_num">num</code></td>
<td>
<p>number of trees used to compute model values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of <code>length(z)</code> containing transformed values t(z) approximating <code class="reqn">p(y | x)</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+contrast">contrast()</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
