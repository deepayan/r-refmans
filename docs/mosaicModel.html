<!DOCTYPE html><html><head><title>Help for package mosaicModel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mosaicModel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AARP'><p>Prices for life insurance</p></a></li>
<li><a href='#Alder'><p>Nitrogen fixing by alder plants</p></a></li>
<li><a href='#Birth_weight'><p>Birth weights and maternal data</p></a></li>
<li><a href='#ci.proportion'><p>Function builder for confidence intervals on proportions</p></a></li>
<li><a href='#College_grades'><p>Grades at a small college</p></a></li>
<li><a href='#collinearity'><p>Calculate measures of collinearity</p></a></li>
<li><a href='#construct_fitting_call'><p>Construct a call for refitting a model from the model itself</p></a></li>
<li><a href='#coverage'><p>Interval statistics for use with df_stats()</p></a></li>
<li><a href='#Crime'><p>Data from the US FBI Uniform Crime Report, 1960</p></a></li>
<li><a href='#data_from_mod'><p>Extract training data from model</p></a></li>
<li><a href='#df_counts'><p>Formula interface to counts</p></a></li>
<li><a href='#df_props'><p>Joint and conditional proportions</p></a></li>
<li><a href='#df_typical'><p>Find typical levels of explanatory variables in a model/dataset.</p></a></li>
<li><a href='#explanatory_vars'><p>Get the names of the explanatory or response variables in a model</p></a></li>
<li><a href='#formula_from_mod'><p>Extract the model formula used in specifying the model</p></a></li>
<li><a href='#HDD_Minneapolis'><p>Heating degree days in Minneapolis, Minnesota, USA</p></a></li>
<li><a href='#Houses_for_sale'><p>Houses for sale</p></a></li>
<li><a href='#mod_cv'><p>Compare models with k-fold cross validation</p></a></li>
<li><a href='#mod_effect'><p>Calculate effect sizes in a model</p></a></li>
<li><a href='#mod_ensemble'><p>Create bootstrapped ensembles of a model</p></a></li>
<li><a href='#mod_error'><p>Mean square prediction error</p></a></li>
<li><a href='#mod_eval'><p>Evaluate a model for specified inputs</p></a></li>
<li><a href='#mod_eval_fun'><p>Internal functions for evaluating models</p></a></li>
<li><a href='#mod_fun'><p>Transforms a model into a function of inputs -&gt; output</p></a></li>
<li><a href='#mod_plot'><p>Plot out model values</p></a></li>
<li><a href='#mosaicModel'><p><code>mosaicModel</code> package</p></a></li>
<li><a href='#Mussels'><p>Metabolism of zebra mussels</p></a></li>
<li><a href='#NCI60_snippet'><p>Gene expression in cancer cells.</p></a></li>
<li><a href='#Oil_history'><p>Historical production of crude oil, worldwide 1880-2014</p></a></li>
<li><a href='#proportion'><p>Function builder for proportions.</p></a></li>
<li><a href='#reference_values'><p>Compute sensible values from a data set for use as a baseline</p></a></li>
<li><a href='#Runners'><p>Performance of runners in a ten-mile race as they age</p></a></li>
<li><a href='#School_data'><p>Simulated data bearing on school vouchers</p></a></li>
<li><a href='#Tadpoles'><p>Swimming speed of tadpoles.</p></a></li>
<li><a href='#Trucking_jobs'><p>Earnings of workers at a trucking company.</p></a></li>
<li><a href='#Used_Fords'><p>Prices of used Ford automobiles in 2009</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>An Interface to Statistical Modeling Independent of Model
Architecture</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Kaplan Daniel [aut, cre],
  Pruim Randall [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Kaplan &lt;kaplan@macalester.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for evaluating, displaying, and interpreting statistical models. The goal is to abstract the operations on models from the particular architecture of the model. For instance, calculating effect sizes rather than looking at coefficients. The package includes interfaces to both regression and classification architectures, including lm(), glm(), rlm() in 'MASS', random forests and recursive partitioning, k-nearest neighbors, linear and quadratic discriminant analysis, and models produced by the 'caret' package's train(). It's straightforward to add in other other model architectures.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1), mosaicCore, splines, dplyr</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, ggplot2, ggformula, lazyeval, knitr, MASS, testthat,
tibble, tidyr, tidyverse</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mosaic, mosaicData, randomForest, rpart</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-09-22 16:14:02 UTC; kaplan</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-09-22 16:21:41 UTC</td>
</tr>
</table>
<hr>
<h2 id='AARP'>Prices for life insurance</h2><span id='topic+AARP'></span>

<h3>Description</h3>

<p>The AARP (original named the &quot;American Association of Retired People&quot;
but now just AARP) offers life insurance
to it's members. The data come from a full-page advertisement (circa 2012) in the &quot;AARP
Bulletin&quot;, which has the second largest circulation in the world of any magazine, with
upward of 40 million subscribers. (Only the &quot;AARP Magazine&quot; has a larger circulation.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AARP)
</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following variables.
</p>

<ul>
<li><p><code>Age</code> The age of the person covered by the insurance policy.
</p>
</li>
<li><p><code>Sex</code> The sex of the person covered by the insurance policy.
</p>
</li>
<li><p><code>Coverage</code> The &quot;death benefit&quot; in 1000 USD.
</p>
</li>
<li><p><code>Cost</code> Monthly cost in USD.
</p>
</li></ul>


<h3>Details</h3>

<p>Life insurance provides a &quot;death benefit&quot;, money paid out to the insured person's survivors
upon death of the insured. There is a cost for the insurance. Among other factors, the cost
depends on both age and sex. (For this type of insurance, called &quot;term insurance&quot;, the cost
changes as the insured person ages.)
</p>


<h3>Source</h3>

<p>The &quot;AARP Bulletin&quot;.
A copy of the ad is available <a href="http://tiny.cc/mosaic/AARP-insurance-ad.pdf">at this link.</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 &lt;- lm(Cost ~ Age + Coverage, data = AARP)
mod_effect(mod_1, ~ Coverage)
</code></pre>

<hr>
<h2 id='Alder'>Nitrogen fixing by alder plants</h2><span id='topic+Alder'></span>

<h3>Description</h3>

<p>These data were collected by biologist Mike Anderson in a study of
nitrogen fixation by bacteria growing on the root nodules of alder
bushes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Alder)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>Alder</code> with 196 rows and 24 variables:
</p>

<ul>
<li><p> LAND. landscape, floodplain vs. upland.
</p>
</li>
<li><p> SAMPPER. sampling period: early, mid, late
</p>
</li>
<li><p> SPECIES. host species, Alnus tenuifolia (AT) vs. A. crispa (AC)
</p>
</li>
<li><p> STAGE.  successional stage, early vs. late in
floodplain and upland landscapes. This is not equivalent across landscapes.
</p>
</li>
<li><p> JULDAY. Julian day
</p>
</li>
<li><p> PERNODN. nodule percent nitrogen by mass
</p>
</li>
<li><p> RF. bacterial genotype
</p>
</li>
<li><p> SNF. nitrogen fixation rate of nodule tissue, umol N2/gram of nodule dry weight/hr
</p>
</li>
<li><p> SLA. specific leaf weight, grams of leaf weight/square-meter, dry
</p>
</li>
<li><p> ONECM. soil temperature at 1 cm depth
</p>
</li>
<li><p> FIVECM. soil temperature at 5 cm depth
</p>
</li>
<li><p> PERH2O. soil moisture, percent H2O by mass
</p>
</li>
<li><p> DEL. del15N of leaf tissue
</p>
</li>
<li><p> DELNOD. del15N of nodule tissue
</p>
</li>
<li><p> NPERAREA. leaf nitrogen content per unit leaf area
</p>
</li>
<li><p> NDiff. nitrogen content difference between leaf and nodule
of the same plant
</p>
</li>
<li><p> delDiff. del15N difference between leaf and nodule of the same plant
</p>
</li>
<li><p> SITE. Site designations: 1A,B,C for replicate early succession floodplain sites, 4A,B,C for late succession floodplain, UP1A,B,C
for early succession upland and UP3A,B,C for late succession upland
</p>
</li>
<li><p> HABSPEC. habitat+species, concatenated LAND, STAGE, SPECIES
</p>
</li>
<li><p> SITESPEC. concatenated SITE, SPECIES
</p>
</li>
<li><p> REP. replicate site within a given level of HABSPEC
</p>
</li>
<li><p> PLNO. plant number, unique for individuals of each species (AT1-180, AC1-270)
</p>
</li></ul>


<h3>Details</h3>

<p>Two questions that Anderson wanted to answer are:
(1) Can any variation in nitrogen fixation (variable <code>SNF</code>)
be attributed to genotype (variable <code>RF</code>)? (2) What are
the major sources of variation in <code>SNF</code> and
<code>PERLEAFN</code>? Variables of biological interest are
seasonality (<code>SAMPPER</code> or <code>JULDAY</code>),
soil temperature and moisture, and habitat differences (<code>STAGE</code> for
host species AT and<code>STAGE</code> and <code>LAND</code> for host species AC).
</p>
<p>Three replicate sites were sampled for each landscape/stage combination in three sampling periods across the growing season. Site sampling was arranged in a Latin Square design in order to systematize any effects of seasonality on N2-fixation rates.
</p>


<h3>Source</h3>

<p>Michael Anderson
</p>


<h3>References</h3>

<p>Anderson MD, Ruess RW, Myrold DD, Taylor DL.
&ldquo;Host species and habitat affect modulation by specific
Frankia genotypes in interior Alaska&rdquo;  Oecologia (2009) 160:619-630.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- lm(logSNF ~ RF + SITESPEC, data = Alder)
</code></pre>

<hr>
<h2 id='Birth_weight'>Birth weights and maternal data</h2><span id='topic+Birth_weight'></span>

<h3>Description</h3>

<p>Birth weight, date, and gestational period collected as part
of the Child Health and Development Studies in 1961 and 1962.
Information about the baby's parents &mdash; age, education, height,
weight, and whether the mother smoked is also recorded.
The data were present by Nolan and Speed to address the question
of whether there is a link between maternal smoking and the
baby's health.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Birth_weight)
</code></pre>


<h3>Format</h3>

<p>A data frame with 886 observations on the following variables.
</p>

<ul>
<li><p><code>baby_wt</code> Birth weight of baby, in ounces.
</p>
</li>
<li><p><code>mother_wt</code> in pounds
</p>
</li>
<li><p><code>gestation</code> Length of the pregnancy, in days.
</p>
</li>
<li><p><code>smoker</code> Whether the mother smoked during the pregnancy.
</p>
</li>
<li><p><code>income</code>Family yearly income in 2500USD increments 0 = under 2500, 1=2500-4999, ..., 8= 12,500-14,999, 9=15000+
</p>
</li></ul>


<h3>Source</h3>

<p>D. Nolan and T.P. Speed (2009) &quot;Stat Labs: Mathematical
Statistics Through Applications&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 &lt;- lm(baby_wt ~ gestation + mother_wt, data = Birth_weight)
mod_effect(mod_1, ~ gestation)
</code></pre>

<hr>
<h2 id='ci.proportion'>Function builder for confidence intervals on proportions</h2><span id='topic+ci.proportion'></span>

<h3>Description</h3>

<p>Similar to <code>proportion</code>, but
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.proportion(nm = NULL, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.proportion_+3A_nm">nm</code></td>
<td>
<p>The level for which to find the proportion</p>
</td></tr>
<tr><td><code id="ci.proportion_+3A_level">level</code></td>
<td>
<p>The confidence interval (Default: 0.95)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
df_stats(mtcars, ~ cyl, cyl_prop = ci.proportion(6, level = 0.90))

## End(Not run)
</code></pre>

<hr>
<h2 id='College_grades'>Grades at a small college</h2><span id='topic+College_grades'></span>

<h3>Description</h3>

<p>These are the actual grades for 400+ individual students in the courses they took
at a small, liberal-arts college in the midwest US. All the students graduated in 2006.
Each row corresponds to a single student in a single course. The data have been de-identified by translating the student ID, the instructor
ID, and the name of the department. Typically a graduating student has taken about 32 courses.
As another form of de-identification, only half of the courses each student, selected randomly,
are included. Only courses with 10 or more students enrolled were included.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(College_grades)
</code></pre>


<h3>Format</h3>

<p>A data frame with 6146 Grades for 443 students.
</p>

<ul>
<li><p><code>grade</code> The letter grade for the student in this course: A is the highest.
</p>
</li>
<li><p><code>sessionID</code> An identifier for the course taken. Courses
offered multiple times in one semester or across semesters have individual IDs.
</p>
</li>
<li><p><code>sid</code> The student ID
</p>
</li>
<li><p><code>dept</code> The department in which the course was offered. 100 is entry-level,
200 sophomore-level, 300 junior-level, 400 senior-level.
</p>
</li>
<li><p><code>enroll</code> Student enrollment in the course. This includes students who are not
part of this sample.
</p>
</li>
<li><p><code>iid</code> Instructor ID
</p>
</li>
<li><p><code>gradepoint</code> A translation of the letter grade into a numerical scale. 4 is high.
Some letter grades are not counted in a student's gradepoint average. These have <code>NA</code> for
the gradepoint.
</p>
</li></ul>


<h3>Source</h3>

<p>The data were helpfully provided by the registrar of the college with the proviso
that the de-identification steps outlined above be performed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
GPA &lt;- lm(gradepoint ~ sid - 1, data = College_grades)

## End(Not run)
</code></pre>

<hr>
<h2 id='collinearity'>Calculate measures of collinearity</h2><span id='topic+collinearity'></span>

<h3>Description</h3>

<p>Calculate measures of collinearity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collinearity(formula, data, format = c("SeIF", "degrees", "radians", "VIF"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collinearity_+3A_formula">formula</code></td>
<td>
<p>a formula giving, on the right-hand side, the explanatory
variables to be considered. Iteractions, etc. may also be specified.</p>
</td></tr>
<tr><td><code id="collinearity_+3A_data">data</code></td>
<td>
<p>a data frame from which to draw the variables in the formula</p>
</td></tr>
<tr><td><code id="collinearity_+3A_format">format</code></td>
<td>
<p>choice of <code>"SeIF"</code> for inflation of standard errors,
<code>"degrees"</code> or <code>"radians"</code> for collinearity described as an angle
or <code>"VIF"</code> for the variance inflation factor (which is the square of SeIF).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>collinearity( ~ cyl * disp * hp, data = mtcars)
collinearity( ~ cyl * disp * hp, data = mtcars, format = "degrees")
</code></pre>

<hr>
<h2 id='construct_fitting_call'>Construct a call for refitting a model from the model itself</h2><span id='topic+construct_fitting_call'></span>

<h3>Description</h3>

<p>This will typically <em>not</em> be used by the end-user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>construct_fitting_call(model, data_name = "training", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="construct_fitting_call_+3A_model">model</code></td>
<td>
<p>the model in question</p>
</td></tr>
<tr><td><code id="construct_fitting_call_+3A_data_name">data_name</code></td>
<td>
<p>character string specifying the name of the data
frame used for the refitting. This object <em>must</em> be defined in the environment in which the
call is being made.</p>
</td></tr>
<tr><td><code id="construct_fitting_call_+3A_...">...</code></td>
<td>
<p>(not used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This provides a way to refit a model on either resampled or sub-sampled data.
Not all model architectures support this. If not, then you can't use <code>mod_ensemble</code> or <code>mod_cv</code>,
or use the <code>bootstrap=</code> argument in any of the other functions.
</p>

<hr>
<h2 id='coverage'>Interval statistics for use with df_stats()</h2><span id='topic+coverage'></span><span id='topic+ci.mean'></span><span id='topic+ci.median'></span><span id='topic+ci.sd'></span>

<h3>Description</h3>

<p>Function builders for calculating intervals. These must <em>always</em> be evaluated
with the <em>result</em> being handed as a argument to <code>df_stats()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coverage(level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coverage_+3A_level">level</code></td>
<td>
<p>Number in 0 to 1 specifying the confidence level for the interval. (Default: 0.95)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>cover &lt;- coverage(0.95)
df_stats(hp ~ cyl, data = mtcars, c95 = cover)

</code></pre>

<hr>
<h2 id='Crime'>Data from the US FBI Uniform Crime Report, 1960</h2><span id='topic+Crime'></span>

<h3>Description</h3>

<p>A report of the number of offenses reported to police per million
population, and many other social and demographic variables. Each
case corresponds to a state in the US.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Crime)
</code></pre>


<h3>Format</h3>

<p>A data frame with 47 cases, each of which is a US state, with observations on the following variables.
</p>

<ul>
<li><p><code>R</code> Crime rate: number of offenses reported to police per million population.
</p>
</li>
<li><p><code>Age</code> Number of males aged 14-24 per 1000 population
</p>
</li>
<li><p><code>N</code> State population (in 100,000s)
</p>
</li>
<li><p><code>W</code> State-wise median value of transferable goods and assets or family income in tens of dollars.
</p>
</li>
<li><p><code>X</code> Number of families per 1000 earning below half the median income.
</p>
</li>
<li><p><code>ExDiff</code> Change in per capita expenditure on police by state and local government from 1950 to 1960
</p>
</li>
<li><p><code>Ex0</code> 1960 per capita expenditures on police.
</p>
</li></ul>


<h3>Source</h3>

<p>FBI Uniform Crime Report via <a href="http://dasl.datadesk.com/data/view/114">DASL: Data and Story Library</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 &lt;- lm(R ~ W, data = Crime)
mod_2 &lt;- lm(R ~ X, data = Crime)
mod_3 &lt;- lm(R ~ W + X, data = Crime)
mod_effect(mod_1, ~ W)
mod_effect(mod_3, ~ W)
mod_effect(mod_2, ~ X)
mod_effect(mod_3, ~ X)
</code></pre>

<hr>
<h2 id='data_from_mod'>Extract training data from model</h2><span id='topic+data_from_mod'></span>

<h3>Description</h3>

<p>This typically will <em>not</em> be used by an end-user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_from_mod(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data_from_mod_+3A_model">model</code></td>
<td>
<p>the model from which to extract the training data</p>
</td></tr>
<tr><td><code id="data_from_mod_+3A_...">...</code></td>
<td>
<p>additional arguments (not used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>not all model architectures keep track of the training data
If a model architecture isn't recognized, you'll have to add a method for that class. See vignette.
</p>

<hr>
<h2 id='df_counts'>Formula interface to counts</h2><span id='topic+df_counts'></span>

<h3>Description</h3>

<p>Counts the number of cases in a data frame broken down by the
variables in the formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_counts(formula, data, wide = FALSE, margins = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df_counts_+3A_formula">formula</code></td>
<td>
<p>the formula describing the relationship</p>
</td></tr>
<tr><td><code id="df_counts_+3A_data">data</code></td>
<td>
<p>a data frame (or you can pipe this in)</p>
</td></tr>
<tr><td><code id="df_counts_+3A_wide">wide</code></td>
<td>
<p>reformat the output as a cross-tabulation. This makes sense only when there are just two variables</p>
</td></tr>
<tr><td><code id="df_counts_+3A_margins">margins</code></td>
<td>
<p>show the marginal counts. Makes the most sense if <code>wide = TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>df_props</code>
</p>

<hr>
<h2 id='df_props'>Joint and conditional proportions</h2><span id='topic+df_props'></span>

<h3>Description</h3>

<p>Uses a formula interface to specify how the proportions are to be calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_props(formula, data, as.percent = FALSE, ..., wide = FALSE,
  margins = FALSE, format = c("proportion", "percent", "count"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df_props_+3A_formula">formula</code></td>
<td>
<p>the formula describing the relationship</p>
</td></tr>
<tr><td><code id="df_props_+3A_data">data</code></td>
<td>
<p>a data frame (or you can pipe this in)</p>
</td></tr>
<tr><td><code id="df_props_+3A_as.percent">as.percent</code></td>
<td>
<p>show proportions in percent (e.g. multiply by 100)</p>
</td></tr>
<tr><td><code id="df_props_+3A_...">...</code></td>
<td>
<p>statistics functions to be applied to the data, e.g. mean, sd, confidence(0.95)</p>
</td></tr>
<tr><td><code id="df_props_+3A_wide">wide</code></td>
<td>
<p>reformat the output as a cross-tabulation. This makes sense only when there are just two variables</p>
</td></tr>
<tr><td><code id="df_props_+3A_margins">margins</code></td>
<td>
<p>show the marginal probabilities. Makes the most sense if <code>wide = TRUE</code>.</p>
</td></tr>
<tr><td><code id="df_props_+3A_format">format</code></td>
<td>
<p>Use just for internal purposes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using <code>|</code> in the formula specifies a conditional proportion
</p>

<ul>
<li><p> ~ A : proportion of cases in each level of A
</p>
</li>
<li><p> ~ A + B: joint proportion: each level of A crossed with B
</p>
</li>
<li><p> ~ A | B: conditional proportion: for each level of B, what fraction are in each level of A
</p>
</li>
<li><p> A ~ B: another way of specifying the conditional proportion
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>df_props(mtcars, ~ cyl + gear) 
df_props(mtcars, ~ cyl | gear)
df_props(mtcars, ~ cyl + gear, wide = TRUE)
df_props(mtcars, ~ cyl + gear, margins = TRUE)
df_props(mtcars, ~ cyl | gear, margins = TRUE)

</code></pre>

<hr>
<h2 id='df_typical'>Find typical levels of explanatory variables in a model/dataset.</h2><span id='topic+df_typical'></span>

<h3>Description</h3>

<p>This function tries to choose sensible values of the explanatory variables
from the data used to build a model or any other specified data.
(or from data specified with the <code>data =</code> argument.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_typical(data = NULL, nlevels = 3, at = list(), model = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df_typical_+3A_data">data</code></td>
<td>
<p>optional data frame from which to extract levels for explanatory variables</p>
</td></tr>
<tr><td><code id="df_typical_+3A_nlevels">nlevels</code></td>
<td>
<p>how many levels to construct for input variables.
For quantitative variables, this is a suggestion. Set to <code>Inf</code> to get all levels
for categorical variables and 100 levels for quantitative variables.</p>
</td></tr>
<tr><td><code id="df_typical_+3A_at">at</code></td>
<td>
<p>named list giving specific values at which to hold the variables. Use this to
override the automatic generation of levels for any or all explanatory variables.</p>
</td></tr>
<tr><td><code id="df_typical_+3A_model">model</code></td>
<td>
<p>the model to display graphically</p>
</td></tr>
<tr><td><code id="df_typical_+3A_...">...</code></td>
<td>
<p>a more concise mechanism to passing desired values for variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For categorical variables, the most populated levels are used. For quantitative
variables, a sequence of <code>pretty()</code> values is generated.
</p>
<p>For categorical variables, will return the nlevels most popular levels, unless
the levels are specified explicitly in an argument.
</p>


<h3>Value</h3>

<p>A dataframe containing all combinations of the selected values for
the explanatory variables. If there are p explanatory variables,
there will be about <code>nlevels^p</code> cases.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
df_typical(mosaicData::Galton, nlevels = 2, father = 70, mother = 68, nkids = 3)
df_typical(mosaicData::Galton, nlevels = 2)
mod1 &lt;- lm(wage ~ age * sex + sector, data = mosaicData::CPS85)
df_typical(model = mod1, nlevels = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='explanatory_vars'>Get the names of the explanatory or response variables in a model</h2><span id='topic+explanatory_vars'></span>

<h3>Description</h3>

<p>This will typically <em>not</em> be used by the end_user. These functions let you
interrogate any model architecture that's covered by mosaicModel about the response and
explanatory variables. These are used internally in functions such as <code>mod_plot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explanatory_vars(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explanatory_vars_+3A_model">model</code></td>
<td>
<p>the model in question</p>
</td></tr>
<tr><td><code id="explanatory_vars_+3A_...">...</code></td>
<td>
<p>(not used)</p>
</td></tr>
</table>

<hr>
<h2 id='formula_from_mod'>Extract the model formula used in specifying the model</h2><span id='topic+formula_from_mod'></span>

<h3>Description</h3>

<p>This typically will <em>not</em> be used by an end-user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formula_from_mod(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formula_from_mod_+3A_model">model</code></td>
<td>
<p>the model</p>
</td></tr>
<tr><td><code id="formula_from_mod_+3A_...">...</code></td>
<td>
<p>(not used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not all model architectures support this. If a model architecture isn't recognized,
you'll have to add a method for that class. See vignette.
</p>

<hr>
<h2 id='HDD_Minneapolis'>Heating degree days in Minneapolis, Minnesota, USA</h2><span id='topic+HDD_Minneapolis'></span>

<h3>Description</h3>

<p>A &quot;heating degree day&quot; is a measure of weather coldness. It's defined to be the difference
between the outdoor ambient temperature and 65 degrees F, but has a value of zero when the ambient
temperature is above 65 degrees. This difference is averaged over time and multiplied by the number
of days in the time period covered. The heating degree day is often used as a measure of the demand for
domestic heating in a locale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HDD_Minneapolis)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>HDD_Minneapolis</code> with 1412 rows and 4 variables:
</p>

<ul>
<li><p> year the year
</p>
</li>
<li><p> month the month
</p>
</li>
<li><p> hdd the number of heating degree days for that period.
</p>
</li>
<li><p> loc the location at which the temperature was measured. In the early years, this was downtown Minneapolis.
Later, the site was moved to the Minneapolis/Saint-Paul International Airport.
</p>
</li></ul>


<h3>Details</h3>

<p>These data report monthly heating degree days. For teaching purposes, the data give an extreme example
of how a relationship (hdd vs year) can be revealed by including a covariate (month). Although interest focusses
on the change in temperature over the century the data cover, there is such regular seasonal variation that
no systematic trend over the years is evident unless month is taken into account.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 &lt;- lm(hdd ~ year, data = HDD_Minneapolis)
mod_2 &lt;- lm(hdd ~ year + month, data = HDD_Minneapolis)
</code></pre>

<hr>
<h2 id='Houses_for_sale'>Houses for sale</h2><span id='topic+Houses_for_sale'></span>

<h3>Description</h3>

<p>A random sample of 1,728 homes taken from public records
from the Saratoga County
(http://www.saratogacountyny.gov/departments/real-property-tax-service-agency/).
Collected by Candice Corvetti (Williams College '07) for her senior thesis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Houses_for_sale)
</code></pre>


<h3>Format</h3>

<p>A dataframe with 1728 cases, each of which is a house for sale.</p>


<h3>Details</h3>

<p>These data are part of a case study developed by Prof. Dick de Veaux at
Williams. They are available from the American Statistical Association's <a href="http://community.amstat.org/stats101/home">Stat 101</a> collection
of case studies and included in this package for convenience.
</p>


<h3>References</h3>

<p>Dick De Veaux (2015) &quot;How much is a fireplace worth?&quot; Stats 101: A resource for teaching introductory statistics, American Statistical Association
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 &lt;- lm(price ~ fireplaces, data = Houses_for_sale)
mod_2 &lt;- lm(price ~ fireplaces + living_area, data = Houses_for_sale)
mod_effect(mod_1, ~ fireplaces)
mod_effect(mod_2, ~ fireplaces)
mod_plot(mod_2, ~ living_area + fireplaces)
</code></pre>

<hr>
<h2 id='mod_cv'>Compare models with k-fold cross validation</h2><span id='topic+mod_cv'></span>

<h3>Description</h3>

<p>Compare models with k-fold cross validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_cv(..., k = 10, ntrials = 5, error_type = c("default", "mse", "sse",
  "mad", "LL", "mLL", "dev", "class_error"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_cv_+3A_...">...</code></td>
<td>
<p>one or more models on which to perform the cross validation</p>
</td></tr>
<tr><td><code id="mod_cv_+3A_k">k</code></td>
<td>
<p>the k in k-fold. cross-validation will use k-1/k of the data for training.</p>
</td></tr>
<tr><td><code id="mod_cv_+3A_ntrials">ntrials</code></td>
<td>
<p>how many random partitions to make. Each partition will be one case in the
output of the function</p>
</td></tr>
<tr><td><code id="mod_cv_+3A_error_type">error_type</code></td>
<td>
<p>The kind of output to produce from each cross-validation. See <code><a href="#topic+mod_error">mod_error</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The purpose of cross-validation is to provide &quot;new&quot; data on which to test a model's
performance. In k-fold cross-validation, the data set used to train the model is broken into
new training and testing data. This is accomplished simply by using most of the data for training while
reserving the remaining data for evaluating the model: testing. Rather than training a single model, k models
are trained, each with its own particular testing set. The testing sets in the k models are arranged to cover the
whole of the data set. On each of the k testing sets, a performance output is calculated. Which output is
most appropriate depends on the kind of model: regression model or classifier. The most basic measure is the mean square error: the
difference between the actual response variable in the testing data and the output of the model
when presented with inputs from the testing data. This is appropriate in many regression models.
</p>

<hr>
<h2 id='mod_effect'>Calculate effect sizes in a model</h2><span id='topic+mod_effect'></span>

<h3>Description</h3>

<p>Like a derivative or finite-difference
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_effect(model, formula, step = NULL, bootstrap = 0, to = step,
  nlevels = 1, data = NULL, at = NULL, class_level = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_effect_+3A_model">model</code></td>
<td>
<p>the model from which the effect size is to be calculated</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_formula">formula</code></td>
<td>
<p>a formula whose right-hand side is the variable with respect
to which the effect size is to be calculated.</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_step">step</code></td>
<td>
<p>the numerical stepsize for the change var, or a comparison category
for a categorical change var. This will be either a character string or a number,
depending on the type of variable specified in the formula.</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_bootstrap">bootstrap</code></td>
<td>
<p>The number of bootstrap replications to construct.
If greater than 1, calculate a standard error using that number of replications.</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_to">to</code></td>
<td>
<p>a synonym for step. (In English, &quot;to&quot; is more appropriate for a
categorical input, &quot;step&quot; for a quantitative. But you can use either.)</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_nlevels">nlevels</code></td>
<td>
<p>integer specifying the number of levels to use for &quot;typical&quot; inputs. (Default: up to 3)</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_data">data</code></td>
<td>
<p>Specifies exactly the cases at which you want to calculate the effect size.</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_at">at</code></td>
<td>
<p>similar to <code>...</code> but expects a list or dataframe of the values you want to set.
Like <code>...</code>, all combinations of the values specified will be used as inputs.</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_class_level">class_level</code></td>
<td>
<p>Name of the categorical level for which the probability is to be used. Applies
only to classifiers. (Default: Use the first level.)
Unlike <code>...</code> or <code>at</code>, no new combinations will be created.</p>
</td></tr>
<tr><td><code id="mod_effect_+3A_...">...</code></td>
<td>
<p>additional arguments for evaluation levels of explanatory
variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When you want to force or restrict the effect size calculation to specific values for
explanatory variables, list those variables and levels as a vector in ...
For example, <code>educ = c(10, 12, 16)</code> will cause the effect size to be calculated
at each of those three levels of education. Any variables whose levels are not specified in
... will have values selected automatically.
</p>


<h3>Value</h3>

<p>a data frame giving the effect size and the values of the explanatory variables at which
the effect size was calculated. There will also be a column <code>to_</code> showing the value jumped to for the
variable with respect to which the effect size is calculated. When <code>bootstrap</code> is greater than 1, there will
be a standard error reported on the effect size; see the variable ending in <code>_se</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod1 &lt;- lm(wage ~ age * sex * educ + sector, data = mosaicData::CPS85)
mod_effect(mod1, ~ sex)
mod_effect(mod1, ~ sector)
mod_effect(mod1, ~ age, sex = "M", educ = c(10, 12, 16), age = c(30, 40))
mod_effect(mod1, ~ age, sex = "F", age = 34, step = 1)
mod_effect(mod1, ~ sex, age = 35, sex = "M", to = "F" )
# For classifiers, the change in *probability* of a level is reported.
mod2 &lt;- rpart::rpart(sector ~ age + sex + educ + wage, data = mosaicData::CPS85)
mod_effect(mod2, ~ educ)
mod_effect(mod2, ~ educ, class_level = "manag")
</code></pre>

<hr>
<h2 id='mod_ensemble'>Create bootstrapped ensembles of a model</h2><span id='topic+mod_ensemble'></span>

<h3>Description</h3>

<p>Create bootstrapped ensembles of a model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_ensemble(model, nreps = 2, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_ensemble_+3A_model">model</code></td>
<td>
<p>a model whose data will be used for resampling</p>
</td></tr>
<tr><td><code id="mod_ensemble_+3A_nreps">nreps</code></td>
<td>
<p>how many resampling trials should be created</p>
</td></tr>
<tr><td><code id="mod_ensemble_+3A_data">data</code></td>
<td>
<p>a data table to use for resampling. This is not needed for many common
model types, such as <code>lm</code>, <code>glm</code>, etc. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The approach to bootstrapping implemented by this function is to create a set of bootstrap
trials all in one go. Then, other functions such as <code>mod_effect()</code> and <code>mod_eval()</code> will be
used to extract the information from each of the bootstrap replicates. Many model types in R carry the
data used to train the model as part of the model object produced. For these types of models, e.g. <code>lm</code> and
<code>glm</code>, there is no need to provide a value for the <code>data</code> argument. But there are some
types of models for which the training data cannot be extracted from the model object. In such situations,
you use <code>data =</code> to provide the data set to use for resampling.
</p>

<hr>
<h2 id='mod_error'>Mean square prediction error</h2><span id='topic+mod_error'></span>

<h3>Description</h3>

<p>Compares model predictions to the actual value of the response variable.
To do this, testing data must be provided with <em>both</em> the input variables and the
corresponding response variable. The measure calculated for a quantitative response
variable is the mean square prediction error (MSPE).
For categorical response variables, an analog of MSPE can be calculated (see details)
but by default, a mean log-likelihood (mean per case) is computed instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_error(model, testdata, error_type = c("default", "mse", "sse", "mad",
  "LL", "mLL", "dev", "class_error"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_error_+3A_model">model</code></td>
<td>
<p>The model whose prediction error is to be estimated.</p>
</td></tr>
<tr><td><code id="mod_error_+3A_testdata">testdata</code></td>
<td>
<p>A data frame giving both model inputs and the actual value of the response
variable. If no testing data is provided, the training data will be used and a warning issued.</p>
</td></tr>
<tr><td><code id="mod_error_+3A_error_type">error_type</code></td>
<td>
<p>The measure of error you are interested in. By default, this is mean-square error for
regression models and log-likelihood for classifiers. The choices are:
</p>

<ul>
<li> <p><code>"mse"</code> &ndash; mean square error
</p>
</li>
<li> <p><code>"sse"</code> &ndash; sum of square errors
</p>
</li>
<li> <p><code>"mad"</code> &ndash; mean absolute deviation
</p>
</li>
<li> <p><code>"LL"</code>  &ndash; log-likelihood
</p>
</li>
<li> <p><code>"mLL"</code> &ndash; mean log-likehood (per case in the testing data)
</p>
</li>
<li> <p><code>"dev"</code> &ndash; deviance. (Plus a constant, which is often zero. The constant is fixed for a given testing data set,
regardless of the model. So differences between deviances of two models are correct.)
</p>
</li>
<li> <p><code>"class_error"</code> &ndash; classification error rate.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>When the response variable is categorical, the model
(called a 'classifier' in such situations) must be capable of
computing <em>probabilities</em> for each output rather than just a bare category.
This is true for many commonly encountered classifier model architectures.
</p>
<p>The analog of the mean squared error for classifiers is the mean of (1-p)^2, where p is the
probability assigned by the model to the actual output. This is a rough approximation
to the log-likelihood. By default, the log-likelihood will be calculated, but for pedagogical
reasons you may prefer (1-p)^2, in which case set <code>error_type = "mse"</code>. Classifiers can assign a probability
of zero to the actual output, in which case the log-likelihood is <code>-Inf</code>. The <code>"mse"</code> error type avoids this.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod &lt;- lm(mpg ~ hp + wt, data = mtcars)
mod_error(mod) # In-sample prediction error.
## Not run: 
classifier &lt;- rpart::rpart(Species ~ ., data = iris)
mod_error(classifier)
mod_error(classifier, error_type = "LL") 
# More typically
inds &lt;- sample(1:nrow(iris), size = 100)
Training &lt;- iris[inds, ]
Testing  &lt;- iris[ - inds, ]
classifier &lt;- rpart::rpart(Species ~ ., data = Training)
# This may well assign zero probability to events that appeared in the
# Testing data 
mod_error(classifier, testdata = Testing)
mod_error(classifier, testdata = Testing, error_type = "mse")

## End(Not run)
</code></pre>

<hr>
<h2 id='mod_eval'>Evaluate a model for specified inputs</h2><span id='topic+mod_eval'></span>

<h3>Description</h3>

<p>Find the model outputs for specified inputs. This is equivalent to the
generic <code>predict()</code> function, except it will choose sensible values
by default.  This simplifies getting a quick look at model values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_eval(model = NULL, data = NULL, append = TRUE, interval = c("none",
  "prediction", "confidence"), nlevels = 2, bootstrap = 0, ...,
  on_training = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_eval_+3A_model">model</code></td>
<td>
<p>the model to display graphically</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_data">data</code></td>
<td>
<p>optional set of cases from which to extract levels for explanatory variables</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_append">append</code></td>
<td>
<p>flag whether to include the inputs to the model along with the calculated
model value in the output. Default: <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_interval">interval</code></td>
<td>
<p>the type of interval to use: &quot;none&quot;, &quot;confidence&quot;, &quot;prediction&quot;. But not all
types are available for all model architectures.</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_nlevels">nlevels</code></td>
<td>
<p>how many levels to construct for input variables. (default: 3)
For quantitative variables, this is a suggestion; an attempt is made to have the levels equally spaced. If you're dissatisfied
with the result, use the ... to specify exactly what levels you want for any variable.</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_bootstrap">bootstrap</code></td>
<td>
<p>if &gt; 1, the number of bootstrap trials to run to construct a
standard error on the model output for each value of the inputs. This is an alternative to
<code>interval</code>; you can't use both.</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_...">...</code></td>
<td>
<p>arguments about or values at which to evaluate the model or the kind of output to be passed along to predict().
Unlike <code>data =</code> the variables given in <code>at =</code> or <code>...</code> will be crossed, so that
the evaluation will occur at all combinations of the various levels.</p>
</td></tr>
<tr><td><code id="mod_eval_+3A_on_training">on_training</code></td>
<td>
<p>flag whether to use the training data for evaluation. Only needed
when there are random terms, e.g. from <code>rand()</code>, <code>shuffle()</code>, .... See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are four distinct ways to specify the values at which the model is to be evaluated.
(1) Look for some &quot;typical values&quot; in the data to create a handful of inputs. This is useful for
getting a quick look at what the output of the model looks like. This is the default behavior. (2) Using <code>data =</code> to a dataframe containing the explanatory variables will evaluate the model
at all of the cases contained in that dataframe. (3) Setting input variables explicitly by using
arguments of the form var_name = values, e.g. <code>sex = "F"</code>. If not all input variables are specified in
this way, the ones that are not will have values set per (1). All combinations of the various variables
will be created. See the <code>nlevels</code> argument. (4) Evaluating the model on the training data.
There are two ways to do this. The first is
to set the <code>data</code> argument to the same data frame used to train the model. The second
is to use the <code>on_training = TRUE</code> argument. These are equivalent unless there is
some random component among the explanatory terms, as with <code>mosaic::rand()</code>, <code>mosaic::shuffle()</code> and so on.
</p>


<h3>Value</h3>

<p>A dataframe containing both the explanatory variable inputs and
the resulting model output (in the <code>model_value</code> field). This differs from the output
of <code>predict()</code>, which for many model classes/architectures may be a vector or matrix.
</p>
<p>A data frame containing both the inputs to the model and the corresponding outputs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mod1 &lt;- lm(wage ~ age * sex + sector, data = mosaicData::CPS85)
mod_eval(mod1)
mod2 &lt;- glm(married == "Married" ~ age + sex * sector,
            data = mosaicData::CPS85, family = "binomial")
mod_eval(mod2, nlevels = 2)
mod_eval(mod2, nlevels = 2, sex = "F") 

## End(Not run)
</code></pre>

<hr>
<h2 id='mod_eval_fun'>Internal functions for evaluating models</h2><span id='topic+mod_eval_fun'></span>

<h3>Description</h3>

<p>These functions are the interface to the various model types for <code>mod_eval()</code>, and through
that to all the other <code>mod_</code> functions that need to evaluate models, e.g. <code>mod_effect()</code>, <code>mod_cv()</code>, and so on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_eval_fun(model, data = NULL, interval = "none", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_eval_fun_+3A_model">model</code></td>
<td>
<p>A model object of the classes permitted</p>
</td></tr>
<tr><td><code id="mod_eval_fun_+3A_data">data</code></td>
<td>
<p>Usually, a data table specifying the inputs to the model. But if
not specified, the training data will be used.</p>
</td></tr>
<tr><td><code id="mod_eval_fun_+3A_interval">interval</code></td>
<td>
<p>One of &quot;none&quot;, &quot;confidence&quot;, or &quot;prediction&quot;. Not all model
types support &quot;prediction&quot; or even &quot;confidence&quot;.</p>
</td></tr>
<tr><td><code id="mod_eval_fun_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All of the <code>eval_</code> functions are ex
These functions return a numerical vector (for regression types) or
a matrix of probabilities (for classifiers)
</p>

<hr>
<h2 id='mod_fun'>Transforms a model into a function of inputs -&gt; output</h2><span id='topic+mod_fun'></span>

<h3>Description</h3>

<p>Implicit in many statistical models is a function that takes the explanatory
variables as inputs and returns the corresponding model value at those inputs.
<code>mod_fun</code> creates an R function that works this way. The function returned
by 'mod_fun&ldquo; has arguments named for each of the explanatory variables. In calling
that returned function, you can specify as many or as few of these as you like.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_fun(mod, nlevels = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_fun_+3A_mod">mod</code></td>
<td>
<p>the model to be rendered in a functional form</p>
</td></tr>
<tr><td><code id="mod_fun_+3A_nlevels">nlevels</code></td>
<td>
<p>the number of levels for which to find &quot;typical levels&quot;
for those arguments not specified in the call to the returned function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When you evaluate the function, you can set the values of all, any, or none of
the arguments. Any arguments that you do not set will automatically be set
to &quot;typical values&quot; as in <code>mod_eval</code>.
</p>
<p>There's nothing essential about the behavior of 'mod_eval&ldquo; that explicitly
names the arguments to the model function with the names of the explanatory variables.
This has been done purely for pedagogical reasons, as a reminder of what those variables
are and to make it possible to spot mistaken inputs to models.
</p>


<h3>Value</h3>

<p>a function whose arguments are the explanatory variable used in the model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my_mod &lt;- lm(mpg ~ hp * cyl, data = mtcars)
f &lt;- mod_fun(my_mod)
names(formals(f)) # the arguments will be the explanatory variables
f(hp = 1:2)
f(hp = 1:2, cyl = 3:4)
f() # typical values for inputs
</code></pre>

<hr>
<h2 id='mod_plot'>Plot out model values</h2><span id='topic+mod_plot'></span>

<h3>Description</h3>

<p>Plot out model values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod_plot(model = NULL, formula = NULL, data = NULL, bootstrap = 0,
  nlevels = 3, at = list(), class_level = NULL, interval = c("none",
  "confidence", "prediction"), post_transform = NULL, size = 1,
  alpha = 0.8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod_plot_+3A_model">model</code></td>
<td>
<p>the model to display graphically.
Can also be an ensemble produced with <code>mod_ensemble()</code></p>
</td></tr>
<tr><td><code id="mod_plot_+3A_formula">formula</code></td>
<td>
<p>setting the y ~ x + color variables</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_data">data</code></td>
<td>
<p>optional data set from which to extract levels for explanatory variables</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_bootstrap">bootstrap</code></td>
<td>
<p>when &gt; 1, this will generate bootstrap replications of the model
and plot all of them. Use as an alternative to <code>interval</code> for confidence intervals.</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_nlevels">nlevels</code></td>
<td>
<p>how many levels to display for those variables shown at discrete levels</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_at">at</code></td>
<td>
<p>named list giving specific values at which to hold the variables. You can accomplish
this without forming a list by using <code>...</code>. See examples.</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_class_level">class_level</code></td>
<td>
<p>character string. If a probability for a classifier is being shown,
which levels of the response variable to use in the plot. (Default: the first one.)</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_interval">interval</code></td>
<td>
<p>show confidence or prediction intervals: values &quot;none&quot;, &quot;confidence&quot;, &quot;prediction&quot;</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_post_transform">post_transform</code></td>
<td>
<p>a scalar transformation and new name for the response variable,
e.g. <code>post_transform = c(price = exp)</code> to undo a log transformation of price.</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_size">size</code></td>
<td>
<p>numerical value for line width (default: 1)</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_alpha">alpha</code></td>
<td>
<p>numerical value in 0 to 1 for transparency (default: 0.8)</p>
</td></tr>
<tr><td><code id="mod_plot_+3A_...">...</code></td>
<td>
<p>specific values for explantory variables</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mod1 &lt;- lm(wage ~ age * sex + sector, data = mosaicData::CPS85)
mod_plot(mod1)
mod_plot(mod1, n = Inf, interval = "confidence") 
mod_plot(mod1, ~ sector + sex + age) # not necessarily a good ordering
mod_plot(mod1, ~ age + sex + sector, nlevels = 8) 
mod2 &lt;- lm(log(wage) ~ age + sex + sector, data = mosaicData::CPS85)
mod_plot(mod2, post_transform = c(wage = exp), 
     interval = "confidence") # undo the log in the display
mod3 &lt;- glm(married == "Married" ~ age + sex * sector,
            data = mosaicData::CPS85, family = "binomial")
mod_plot(mod3)
E3 &lt;- mod_ensemble(mod3, 10)
mod_plot(E3)
mod4 &lt;- rpart::rpart(sector ~ age + sex + married, data = mosaicData::CPS85)
mod_plot(mod4)
mod_plot(mod4, class_level = "manag")
mod5 &lt;- randomForest::randomForest(
         sector ~ age + sex + married, data = mosaicData::CPS85)
mod_plot(mod5)
mod_plot(mod5, class_level = "manag")

## End(Not run)
</code></pre>

<hr>
<h2 id='mosaicModel'><code>mosaicModel</code> package</h2><span id='topic+mosaicModel'></span><span id='topic+mosaicModel-package'></span>

<h3>Description</h3>

<p>Functions for teaching about modeling.
</p>


<h3>Details</h3>

<p>The package offers a handful of high-level functions for evaluating, displaying,
and interpreting models that work in a consistent way across model architectures, e.g.
lm, glm, rpart, randomForest, knn3, caret-train, and so on.
</p>

<ul>
<li> <p><code>mod_eval()</code> &ndash; evaluate a model, that is, turn inputs into model values. For many model architectures, you can also get prediction or confidence intervals on the outputs.
</p>
</li>
<li> <p><code>mod_plot()</code> &ndash; produce a graphical display of the &quot;shape&quot; of a model. There can be as many as 4 input variables shown, along with the output.
</p>
</li>
<li> <p><code>mod_effect()</code> &ndash; calculate effect sizes, that is, how a change in an input variable changes the output
</p>
</li>
<li> <p><code>mod_error()</code> &ndash; find the mean square prediction error (or the log likelihood)
</p>
</li>
<li> <p><code>mod_ensemble()</code> &ndash; create an ensemble of bootstrap replications of the model, that is, models fit to resampled data from the original model.
</p>
</li>
<li> <p><code>mod_cv()</code> &ndash; carry out cross validation on one or more models.
</p>
</li>
<li> <p><code>mod_fun()</code> &ndash; extract a function from a model that implements the inputs-to-output relationship.
<code>mosaicModel</code> stays out of the business of training models. You do that using functions, e.g.
</p>
</li></ul>


<ul>
<li><p> the familiar <code>lm</code> or <code>glm</code> provided by the <code>stats</code> package
</p>
</li>
<li> <p><code>train</code> from the <code>caret</code> package for machine learning
</p>
</li>
<li> <p><code>rpart</code>, <code>randomForest</code>, <code>rlm</code>, and other functions provided by other packages
</p>
</li></ul>


<hr>
<h2 id='Mussels'>Metabolism of zebra mussels</h2><span id='topic+Mussels'></span>

<h3>Description</h3>

<p>Zebra mussels are a small, fast reproducing species of freshwater mussel
native to the lakes of southeast Russia. They have accidentally been introduced in other
areas, competing with native species and creating problems for people as they cover the
undersides of docks and boats, clog water intakes and other underwater structures.
Zebra mussels even attach themselves to other mussels, sometimes starving those mussels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Mussels)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>Mussels</code> with 30 rows and 11 variables.
</p>

<ul>
<li><p><code>GroupID</code> ID for the cluster of mussels growing on a substrate. 
</p>
</li>
<li><p><code>dry.mass</code> The mass of the mussels (as a group) after dehydration.
</p>
</li>
<li><p><code>count</code> How many mussels were in the cluster.
</p>
</li>
<li><p><code>attachment</code> The substrate to which the mussels were attached.
</p>
</li>
<li><p><code>lipid</code> Percentage of dry mass that is lipid.
</p>
</li>
<li><p><code>protein</code> Percentage of dry mass that is protein.
</p>
</li>
<li><p><code>carbo</code> Percentage of dry mass that is carbohydrate.
</p>
</li>
<li><p><code>ash</code> Percentage of dry mass that is ash.
</p>
</li>
<li><p><code>ammonia</code> Nitrogen excretion measured as ammonia in mg per hour for the group.
</p>
</li>
<li><p><code>Kcal</code> Total calorific value of the tissue in kilo-calories per gram.
</p>
</li>
<li><p><code>O2</code> Oxygen uptake in mg per hour for the group.
</p>
</li></ul>


<h3>Details</h3>

<p>Ecologists Shirley Baker and Daniel Hornbach examined whether zebra mussels gain an advantage by attaching to other mussels rather than to rocks.(baker-hornbach-2008) The ecologists collected samples of small rocks and Amblema plicata mussels, each of which had a collection of zebra mussels attached. The samples were transported to a laboratory where the group of mussels from each individual rock or Amblema were removed and placed in an aquarium equipped to measure oxygen uptake and ammonia excretion. After these physiological measurements were made, the biochemical composition of the mussel tissue was determined: the percentage of protein, lipid, carbohydrate, and ash.
Baker and Hornbach found that zebra mussels attached to Amblema had greater
physiological activity than those attached to rocks as measured by oxygen uptake and
ammonia excretion. But this appears to be a sign of extra effort for the Amblema-attached
zebra mussels, since they had lower carbohydrate and lipid levels. In other words, attaching to
Amblema appears to be disadvantageous to the zebra mussels compared to attaching to a rock.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Mussels$ind.mass &lt;- with(Mussels, dry.mass/count)
mod_1 &lt;- lm(O2/count ~ attachment, data = Mussels)
mod_2 &lt;- lm(ammonia/count ~ attachment, data = Mussels)
mod_3 &lt;- lm(O2/count ~ ind.mass + attachment, data = Mussels)
mod_4 &lt;- lm(ammonia/count ~ ind.mass + attachment, data = Mussels)
</code></pre>

<hr>
<h2 id='NCI60_snippet'>Gene expression in cancer cells.</h2><span id='topic+NCI60_snippet'></span>

<h3>Description</h3>

<p>The data come from a National Cancer Institute study of gene expression in cell lines
drawn from various sorts of cancer. Each row corresponds to a different cell line. The type
of cancer is identified by the first two or three letters of the row names, e.g. CO is colon, ME is melanoma, RE is kidney.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NCI60_snippet)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>NCI60_snippet</code> with 60 rows and 6000 variables.</p>


<h3>Details</h3>

<p>For each row, there are 6000 measurements of the gene expression as identified by activity on
a microarray probe. The variable names are the names of the probes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NCI60_snippet)
</code></pre>

<hr>
<h2 id='Oil_history'>Historical production of crude oil, worldwide 1880-2014</h2><span id='topic+Oil_history'></span>

<h3>Description</h3>

<p>Annual production of crude oil, in millions of barrels (mbbl).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Oil_history)
</code></pre>


<h3>Format</h3>

<p>A data frame with 47 cases, each of which is a US state, with observations on the following variables.
</p>

<ul>
<li><p><code>year</code> the year for which production is reported
</p>
</li>
<li><p><code>mbbl</code> oil production in millions of barrels
</p>
</li></ul>


<h3>Source</h3>

<p>Assembled from older information from  RH Romer (1976) &quot;Energy: An Introduction to Physics&quot; and more recent
data from <code>data.oecd.org</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(log(mbbl) ~ year, data = Oil_history)
mod_plot(model)
</code></pre>

<hr>
<h2 id='proportion'>Function builder for proportions.</h2><span id='topic+proportion'></span>

<h3>Description</h3>

<p>Evaluate this and hand the result to <code>df_stats()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proportion(nm = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proportion_+3A_nm">nm</code></td>
<td>
<p>The level for which to find the proportion</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
df_stats(mtcars, ~ cyl, proportion(6))

## End(Not run)
</code></pre>

<hr>
<h2 id='reference_values'>Compute sensible values from a data set for use as a baseline</h2><span id='topic+reference_values'></span>

<h3>Description</h3>

<p>Compute sensible values from a data set for use as a baseline
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reference_values(data, n = 1, at = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reference_values_+3A_data">data</code></td>
<td>
<p>a data frame</p>
</td></tr>
<tr><td><code id="reference_values_+3A_n">n</code></td>
<td>
<p>number of values for specified variables: could be a single number or
a list assigning a number of levels for individual variables</p>
</td></tr>
<tr><td><code id="reference_values_+3A_at">at</code></td>
<td>
<p>optional values at which to set values: a list whose names are the
variables whose values are to be set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variables not listed in <code>at</code> will be assigned levels using these principles:
Categorical variables: the most populated levels.
Quantitative variables: central quantiles, e.g. median for n=1,
</p>

<hr>
<h2 id='Runners'>Performance of runners in a ten-mile race as they age</h2><span id='topic+Runners'></span>

<h3>Description</h3>

<p>These data are assembled from the records of the &quot;Cherry Blossom Ten Miler&quot;
held in Washington, DC each April. The records span the years 1999 to 2008.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Runners)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>Runners</code> with 24,334 rows and 8 variables.
</p>

<ul>
<li><p><code>age</code> The runners age at the time of the race.
</p>
</li>
<li><p><code>net</code> The time (in min.) elapsed from when the runner crossed the start line until the finish.
</p>
</li>
<li><p><code>gun</code> The time (in min.) from when the starter's gun was fired to when the runner finished the race. With
so many participants, some runners do not reach the start line until several minutes after the gun.
</p>
</li>
<li><p><code>sex</code> The runner's sex.
</p>
</li>
<li><p><code>previous</code> How many times the runner participated before this year's race.
</p>
</li>
<li><p><code>nruns</code> How many of the 10 years' runs the runner eventually participated in.
</p>
</li>
<li><p><code>start_position</code> A made-up categorical description of where the runner was situated in the
line up for the race..
</p>
</li></ul>


<h3>Details</h3>

<p>There are about 10,000 participants each year, of whom roughly half have run the race previously. During the
ten years of these records, some 25 runners ran in ech of the years, 73 ran in nine of the years, and so on.
The data allow you to track the performace of runners as they age. This simplified version of the data does
not include personal identifying data other than sex, age, and number of previous runs in any given year. (Runs
before 1999 are not considered.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 = lm(net ~ age + sex, data = Runners)
</code></pre>

<hr>
<h2 id='School_data'>Simulated data bearing on school vouchers</h2><span id='topic+School_data'></span>

<h3>Description</h3>

<p>In the US, there have been controversial proposals to provide vouchers
to students in failing public schools. The vouchers would allow the students to attend
private schools. There are arguments pro and con that are often rooted in political
philosophy (free choice!) and politics. The presumption behind the <em>pro</em> arguments
is that attending private schools would create better outcomes for students.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(School_data)
</code></pre>


<h3>Format</h3>

<p>A data frame with 500 cases, each of which is a simulated student, with observations on the following variables.
</p>

<ul>
<li><p><code>test_score</code> a simulated test score for the student
</p>
</li>
<li><p><code>school</code> whether the student attended public or private school
</p>
</li>
<li><p><code>lottery</code> whether the student was entered into a lottery for a private-school voucher
</p>
</li>
<li><p><code>group</code> the racial/ethnic group of the student
</p>
</li>
<li><p><code>acad_motivation</code> the overall level of involvement and concern of the student's parents for the student's academic performance
</p>
</li>
<li><p><code>relig_motivation</code> the overall level of interest motivated by religion. This is
potentially an issue because a large majority of urban private schools are Catholic.
</p>
</li></ul>


<h3>Details</h3>

<p>A reasonable way to test this presumption is to compare test scores for students
in public and private schools.
One famous analysis (Howell and Peterson, 2003, &quot;The Education Gap: Vouchers and Urban Schools&quot;)
found that voucher schools are most helpful for African-American students,
and not so much for white or Hispanic students.
</p>
<p>The <code>School_data</code> data frame comes from a simulation designed by the package author to
replicate the overall results but supporting a very different policy recommendation. WARNING: This is
just a simulation, reflecting one hypothesis about how the world might work. Don't be tempted
to draw conclusions about the actual factors involved in school performance from such simulated data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lm(test_score ~ school, data = School_data)
# the simulation mechanism itself:
nstudents &lt;- 500
acad_motivation &lt;- rnorm(nstudents)
group &lt;- sample(c("black", "hispanic", "white"), replace = TRUE, size = nstudents)
relig_motivation &lt;- ifelse( group == "black", -1, ifelse(group == "white", 0, 1))
relig_motivation &lt;- rnorm(nstudents, mean = relig_motivation)
lottery &lt;- (acad_motivation + relig_motivation) &gt; 0
school &lt;- ifelse( (runif(nstudents) + .8* lottery ) &gt; 1, "private", "public")
test_score &lt;- rnorm(nstudents, mean = 100 - 5 * (school == "private") + 20 * acad_motivation)
School_data &lt;- data.frame(test_score, acad_motivation, group, relig_motivation, lottery, school)
</code></pre>

<hr>
<h2 id='Tadpoles'>Swimming speed of tadpoles.</h2><span id='topic+Tadpoles'></span>

<h3>Description</h3>

<p>Tim Watkins examined the swimming speed of tadpoles as a function of the water temperature, and the
water temperature at which the tadpoles had been raised. Since size is a major determinant of speed,
the tadpole's length was measured as well.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Tadpoles)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>Trucking_jobs</code> with 129 rows and 11 variables.
</p>

<ul>
<li><p><code>group</code> Whether the tadpole was raised in cold water (&quot;c&quot;) or warm (&quot;w&quot;).
</p>
</li>
<li><p><code>rtemp</code> The temperature (C) of the water in which the swimming speed was measured. (The swimming channel is called a &quot;race&quot;.)
</p>
</li>
<li><p><code>length</code> The tadpole's length, in mm.
</p>
</li>
<li><p><code>vmax</code> The maximum swimming speed attained in one trial, in mm/sec.
</p>
</li></ul>


<h3>Details</h3>

<p>It was hypothesized that tadpoles would swim faster in the temperature of water close to that in which they had been raised.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 = lm(vmax ~ poly(rtemp, 2) * group + length, data = Tadpoles)
</code></pre>

<hr>
<h2 id='Trucking_jobs'>Earnings of workers at a trucking company.</h2><span id='topic+Trucking_jobs'></span>

<h3>Description</h3>

<p>A dataset from a mid-western US trucking company on annual earnings of its employees in 2007.
Datasets like this are used in audits by the Federal Government to look for signs of discrimination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Trucking_jobs)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>Trucking_jobs</code> with 129 rows and 11 variables.
</p>

<ul>
<li><p><code>sex</code> The employee's sex: M or F
</p>
</li>
<li><p><code>earnings</code> Annual earnings, in dollars. Hourly wages have been converted to a full-time basis.
</p>
</li>
<li><p><code>age</code> The employee's age, in years.
</p>
</li>
<li><p><code>title</code> The employee's job title.
</p>
</li>
<li><p><code>hiredyears</code> How long the employee has been working for the company.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 = lm(earnings ~ age + hiredyears + sex, data = Trucking_jobs)
</code></pre>

<hr>
<h2 id='Used_Fords'>Prices of used Ford automobiles in 2009</h2><span id='topic+Used_Fords'></span>

<h3>Description</h3>

<p>These data were compiled by Macalester College students for a class project.
Then-undergraduates Elise delMas, Emiliano Urbina, and Candace Groth collected the data from
<code>cars.com</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Used_Fords)
</code></pre>


<h3>Format</h3>

<p>A data frame <code>Used_Fords</code> with 635 rows and 7 variables.
</p>

<ul>
<li><p><code>Price</code> The asking price for the car in USD.
</p>
</li>
<li><p><code>Year</code> The model year of the car.
</p>
</li>
<li><p><code>Mileage</code> The reported odometer reading.
</p>
</li>
<li><p><code>Location</code> Which of the several regions the car was marketed in.
</p>
</li>
<li><p><code>Color</code> The car's body color.
</p>
</li>
<li><p><code>Age</code> The age of the car at the time the data were collected in 2009. This is directly related to <code>Year</code>
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>mod_1 &lt;- lm(Price ~ Mileage, data = Used_Fords)
mod_2 &lt;- lm(Price ~ Mileage + Age, data = Used_Fords)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
