<!DOCTYPE html><html lang="en"><head><title>Help for package Dforest</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Dforest}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cal_MCC'><p>Performance evaluation from other modeling algorithm Result</p></a></li>
<li><a href='#Con_DT'><p>Construct Decision Tree model with pruning</p></a></li>
<li><a href='#data_dili'><p>QSAR dataset with DILI endpoint for demo</p></a></li>
<li><a href='#DF_acc'><p>Performance evaluation from Decision Tree Predictions</p></a></li>
<li><a href='#DF_calp'><p>T-test for feature selection</p></a></li>
<li><a href='#DF_ConfPlot'><p>Decision Forest algorithm: confidence level accumulated plot</p></a></li>
<li><a href='#DF_ConfPlot_accu'><p>Decision Forest algorithm: confidence level accumulated plot (accumulated version)</p></a></li>
<li><a href='#DF_CV'><p>Decision Forest algorithm: Model training with Cross-validation</p></a></li>
<li><a href='#DF_CVsummary'><p>output summary for Dforest Cross-validation results</p></a></li>
<li><a href='#DF_dataFs'><p>Decision Forest algorithm: Feature Selection in pre-processing</p></a></li>
<li><a href='#DF_dataPre'><p>Decision Forest algorithm: Data pre-processing</p></a></li>
<li><a href='#DF_easy'><p>Simple pre-defined pipeline for Decision forest</p></a></li>
<li><a href='#DF_perf'><p>performance evaluation between two factors</p></a></li>
<li><a href='#DF_pred'><p>Decision Forest algorithm: Model prediction</p></a></li>
<li><a href='#DF_train'><p>Decision Forest algorithm: Model training</p></a></li>
<li><a href='#DF_Trainsummary'><p>output summary for Dforest test results</p></a></li>
<li><a href='#Dforest'><p>Demo script to lean Decision Forest package</p>
Demo data are located in data/ folder</a></li>
<li><a href='#multiplot'><p>multiplot</p></a></li>
<li><a href='#Pred_DT'><p>Doing Prediction with Decision Tree model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Decision Forest</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-11-28</td>
</tr>
<tr>
<td>Author:</td>
<td>Leihong Wu &lt;leihong.wu@fda.hhs.gov&gt;,
    Weida Tong (Weida.tong@fda.hhs.gov)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Leihong Wu &lt;leihong.wu@fda.hhs.gov&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>rpart, ggplot2, methods, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides R-implementation of Decision forest algorithm, which combines the predictions of
    multiple independent decision tree models for a consensus decision. In particular, Decision Forest is a novel 
    pattern-recognition method which can be used to analyze: (1) DNA microarray data; 
    (2) Surface-Enhanced Laser Desorption/Ionization Time-of-Flight Mass Spectrometry  (SELDI-TOF-MS) data; and 
    (3) Structure-Activity Relation (SAR) data.
    In this package, three fundamental functions are provided, as (1)DF_train, (2)DF_pred, and (3)DF_CV.  
    run Dforest() to see more instructions.
    Weida Tong (2003) &lt;<a href="https://doi.org/10.1021%2Fci020058s">doi:10.1021/ci020058s</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-11-28 19:17:32 UTC; Leihong.Wu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-11-28 22:03:57 UTC</td>
</tr>
</table>
<hr>
<h2 id='cal_MCC'>Performance evaluation from other modeling algorithm Result</h2><span id='topic+cal_MCC'></span>

<h3>Description</h3>

<p>Performance evaluation from other modeling algorithm Result
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_MCC(pred, label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cal_MCC_+3A_pred">pred</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code id="cal_MCC_+3A_label">label</code></td>
<td>
<p>Known-endpoint</p>
</td></tr>
</table>


<h3>Value</h3>

<p>result$ACC:   Predicting Accuracy
</p>
<p>result$MIS:   MisClassfication Counts
</p>
<p>result$MCC:   Matthew's Correlation Coefficients
</p>
<p>result$bACC:  balanced Accuracy
</p>

<hr>
<h2 id='Con_DT'>Construct Decision Tree model with pruning</h2><span id='topic+Con_DT'></span>

<h3>Description</h3>

<p>Construct Decision Tree model with pruning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Con_DT(X, Y, min_split = 10, cp = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Con_DT_+3A_x">X</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="Con_DT_+3A_y">Y</code></td>
<td>
<p>data_Labels</p>
</td></tr>
<tr><td><code id="Con_DT_+3A_min_split">min_split</code></td>
<td>
<p>minimum number of node in each leaf</p>
</td></tr>
<tr><td><code id="Con_DT_+3A_cp">cp</code></td>
<td>
<p>pre-defined Complexity Parameter (CP) rpart program</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Decision Tree Model with pruning
Implemented by rpart
</p>


<h3>See Also</h3>

<p><code>rpart</code>
</p>

<hr>
<h2 id='data_dili'>QSAR dataset with DILI endpoint for demo</h2><span id='topic+data_dili'></span>

<h3>Description</h3>

<p>This data set gives the DILI endpoint of various compounds (Most or No DILI-concern)
with QSAR descriptors generated by MOLD2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rivers</code></pre>


<h3>Format</h3>

<p>A List containing two vectors:
X contains 958 observations and 777 variables.
Y contains DILI endpoints of 958 observations
</p>


<h3>Source</h3>

<p>In-house data</p>


<h3>References</h3>

<p>Minjun Chen (2011) <em>FDA-approved drug labeling for the study of drug-induced liver injury</em>.
Drug discovery today
</p>

<hr>
<h2 id='DF_acc'>Performance evaluation from Decision Tree Predictions</h2><span id='topic+DF_acc'></span>

<h3>Description</h3>

<p>Performance evaluation from Decision Tree Predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_acc(pred, label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_acc_+3A_pred">pred</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code id="DF_acc_+3A_label">label</code></td>
<td>
<p>Known-endpoint</p>
</td></tr>
</table>


<h3>Value</h3>

<p>result$ACC:   Predicting Accuracy
</p>
<p>result$MIS:   MisClassfication Counts
</p>
<p>result$MCC:   Matthew's Correlation Coefficients
</p>
<p>result$bACC:  balanced Accuracy
</p>

<hr>
<h2 id='DF_calp'>T-test for feature selection</h2><span id='topic+DF_calp'></span>

<h3>Description</h3>

<p>T-test for feature selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_calp(X, Y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_calp_+3A_x">X</code></td>
<td>
<p>X variable matrix</p>
</td></tr>
<tr><td><code id="DF_calp_+3A_y">Y</code></td>
<td>
<p>Y label</p>
</td></tr>
</table>

<hr>
<h2 id='DF_ConfPlot'>Decision Forest algorithm: confidence level accumulated plot</h2><span id='topic+DF_ConfPlot'></span>

<h3>Description</h3>

<p>Draw accuracy curve according to the confidence level of predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_ConfPlot(Pred_result, Label, bin = 20, plot = T, smooth = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_ConfPlot_+3A_pred_result">Pred_result</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_+3A_label">Label</code></td>
<td>
<p>known label for Test Dataset</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_+3A_bin">bin</code></td>
<td>
<p>How many bins occurred in Conf Plot (Default is 20)</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_+3A_plot">plot</code></td>
<td>
<p>Draw Plot if True, otherwise output the datamatrix</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_+3A_smooth">smooth</code></td>
<td>
<p>if TRUE, Fit the performance curve with smooth function (by ggplot2)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ACC_Conf: return data Matrix (&quot;ConfidenceLevel&quot;, &quot;Accuracy&quot;, &quot;Matched Samples&quot;) for confidence plot (no plot)
</p>
<p>ConfPlot: Draw Confidence Plot if True, need install ggplot2
</p>

<hr>
<h2 id='DF_ConfPlot_accu'>Decision Forest algorithm: confidence level accumulated plot (accumulated version)</h2><span id='topic+DF_ConfPlot_accu'></span>

<h3>Description</h3>

<p>Draw accuracy curve according to the confidence level of predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_ConfPlot_accu(Pred_result, Label, bin = 20, plot = T, smooth = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_ConfPlot_accu_+3A_pred_result">Pred_result</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_accu_+3A_label">Label</code></td>
<td>
<p>known label for Test Dataset</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_accu_+3A_bin">bin</code></td>
<td>
<p>How many bins occurred in Conf Plot (Default is 20)</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_accu_+3A_plot">plot</code></td>
<td>
<p>Draw Plot if True, otherwise output the datamatrix</p>
</td></tr>
<tr><td><code id="DF_ConfPlot_accu_+3A_smooth">smooth</code></td>
<td>
<p>if TRUE, Fit the performance curve with smooth function (by ggplot2)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ACC_Conf: return data Matrix (&quot;ConfidenceLevel&quot;, &quot;Accuracy&quot;, &quot;Matched Samples&quot;) for confidence plot (no plot)
</p>
<p>ConfPlot: Draw Confidence Plot if True, need install ggplot2
</p>

<hr>
<h2 id='DF_CV'>Decision Forest algorithm: Model training with Cross-validation</h2><span id='topic+DF_CV'></span>

<h3>Description</h3>

<p>Decision Forest algorithm: Model training with Cross-validation
Default is 5-fold cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_CV(X, Y, stop_step = 10, CV_fold = 5, Max_tree = 20, min_split = 10,
  cp = 0.1, Filter = F, p_val = 0.05, Method = "bACC", Quiet = T,
  Grace_val = 0.05, imp_accu_val = 0.01, imp_accu_criteria = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_CV_+3A_x">X</code></td>
<td>
<p>Training Dataset</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_y">Y</code></td>
<td>
<p>Training data endpoint</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_stop_step">stop_step</code></td>
<td>
<p>How many extra step would be processed when performance not improved, 1 means one extra step</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_cv_fold">CV_fold</code></td>
<td>
<p>Fold of cross-validation (Default = 5)</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_max_tree">Max_tree</code></td>
<td>
<p>Maximum tree number in Forest</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_min_split">min_split</code></td>
<td>
<p>minimum leaves in tree nodes</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_cp">cp</code></td>
<td>
<p>parameters to pruning decision tree, default is 0.1</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_filter">Filter</code></td>
<td>
<p>doing feature selection before training</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_p_val">p_val</code></td>
<td>
<p>P-value threshold measured by t-test used in feature selection, default is 0.05</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_method">Method</code></td>
<td>
<p>Which is used for evaluating training process. MIS: Misclassification rate; ACC: accuracy</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_quiet">Quiet</code></td>
<td>
<p>if TRUE (default), don't show any message during the process</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_grace_val">Grace_val</code></td>
<td>
<p>Grace Value in evaluation: the next model should have a performance (Accuracy, bACC, MCC) not bad than previous model with threshold</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_imp_accu_val">imp_accu_val</code></td>
<td>
<p>improvement in evaluation: adding new tree should improve the overall model performance (Accuracy, bACC, MCC) by threshold</p>
</td></tr>
<tr><td><code id="DF_CV_+3A_imp_accu_criteria">imp_accu_criteria</code></td>
<td>
<p>if TRUE, model must have improvement in accumulated accuracy</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.$performance:      Overall training accuracy (Cross-validation)
</p>
<p>.$pred:          Detailed training prediction (Cross-validation)
</p>
<p>.$detail:        Detailed usage of Decision tree Features/Models and their performances in all CVs
</p>
<p>.$Method:        pass evaluating Methods used in training
</p>
<p>.$cp:            pass cp value used in training decision trees
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ##data(iris)
  X = iris[,1:4]
  Y = iris[,5]
  names(Y)=rownames(X)

  random_seq=sample(nrow(X))
  split_rate=3
  split_sample = suppressWarnings(split(random_seq,1:split_rate))
  Train_X = X[-random_seq[split_sample[[1]]],]
  Train_Y = Y[-random_seq[split_sample[[1]]]]

  CV_result = DF_CV(Train_X, Train_Y)


</code></pre>

<hr>
<h2 id='DF_CVsummary'>output summary for Dforest Cross-validation results</h2><span id='topic+DF_CVsummary'></span>

<h3>Description</h3>

<p>Draw plot for Dforest Cross-validation results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_CVsummary(CV_result, plot = T)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_CVsummary_+3A_cv_result">CV_result</code></td>
<td>
<p>Training Dataset</p>
</td></tr>
<tr><td><code id="DF_CVsummary_+3A_plot">plot</code></td>
<td>
<p>if TRUE (default), draw plot</p>
</td></tr>
</table>

<hr>
<h2 id='DF_dataFs'>Decision Forest algorithm: Feature Selection in pre-processing</h2><span id='topic+DF_dataFs'></span>

<h3>Description</h3>

<p>Decision Forest algorithm: feature selection for two-class predictions,
kept statistical significant features pass the t-test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_dataFs(X, Y, p_val = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_dataFs_+3A_x">X</code></td>
<td>
<p>Training Dataset</p>
</td></tr>
<tr><td><code id="DF_dataFs_+3A_y">Y</code></td>
<td>
<p>Training Labels</p>
</td></tr>
<tr><td><code id="DF_dataFs_+3A_p_val">p_val</code></td>
<td>
<p>Correlation Coefficient threshold to filter out high correlated features; default is 0.95</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Keep_feat: qualified features in data matrix after filtering
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ##data(iris)
  X = iris[iris[,5]!="setosa",1:4]
  Y = iris[iris[,5]!="setosa",5]
  used_feat = DF_dataFs(X, Y)
</code></pre>

<hr>
<h2 id='DF_dataPre'>Decision Forest algorithm: Data pre-processing</h2><span id='topic+DF_dataPre'></span>

<h3>Description</h3>

<p>Decision Forest algorithm: Data pre-processing, remove All-Zero columns/features and high correlated features
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_dataPre(X, thres = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_dataPre_+3A_x">X</code></td>
<td>
<p>Training Dataset</p>
</td></tr>
<tr><td><code id="DF_dataPre_+3A_thres">thres</code></td>
<td>
<p>Correlation Coefficient threshold to filter out high correlated features; default is 0.95</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Keep_feat: qualified features in data matrix after filtering
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ##data(iris)
  X = iris[,1:4]
  Keep_feat = DF_dataPre(X)
</code></pre>

<hr>
<h2 id='DF_easy'>Simple pre-defined pipeline for Decision forest</h2><span id='topic+DF_easy'></span>

<h3>Description</h3>

<p>This is a script of decision forest for easy use t
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_easy(Train_X, Train_Y, Test_X, Test_Y, mode = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_easy_+3A_train_x">Train_X</code></td>
<td>
<p>Training Dataset</p>
</td></tr>
<tr><td><code id="DF_easy_+3A_train_y">Train_Y</code></td>
<td>
<p>Training data endpoint</p>
</td></tr>
<tr><td><code id="DF_easy_+3A_test_x">Test_X</code></td>
<td>
<p>Testing Dataset</p>
</td></tr>
<tr><td><code id="DF_easy_+3A_test_y">Test_Y</code></td>
<td>
<p>Testing data endpoint</p>
</td></tr>
<tr><td><code id="DF_easy_+3A_mode">mode</code></td>
<td>
<p>pre-defined modeling</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data_matrix training and testing result
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # data(demo_simple)
  X = iris[,1:4]
  Y = iris[,5]
  names(Y)=rownames(X)

  random_seq=sample(nrow(X))
  split_rate=3
  split_sample = suppressWarnings(split(random_seq,1:split_rate))
  Train_X = X[-random_seq[split_sample[[1]]],]
  Train_Y = Y[-random_seq[split_sample[[1]]]]
  Test_X = X[random_seq[split_sample[[1]]],]
  Test_Y = Y[random_seq[split_sample[[1]]]]

  Result = DF_easy(Train_X, Train_Y, Test_X, Test_Y)
</code></pre>

<hr>
<h2 id='DF_perf'>performance evaluation between two factors</h2><span id='topic+DF_perf'></span>

<h3>Description</h3>

<p>performance evaluation between two factors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_perf(pred, label)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_perf_+3A_pred">pred</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code id="DF_perf_+3A_label">label</code></td>
<td>
<p>Known-endpoint</p>
</td></tr>
</table>


<h3>Value</h3>

<p>result$ACC:   Predicting Accuracy
</p>
<p>result$MIS:   MisClassfication Counts
</p>
<p>result$MCC:   Matthew's Correlation Coefficients
</p>
<p>result$bACC:  balanced Accuracy
</p>

<hr>
<h2 id='DF_pred'>Decision Forest algorithm: Model prediction</h2><span id='topic+DF_pred'></span>

<h3>Description</h3>

<p>Decision Forest algorithm: Model prediction with constructed DF models.
DT_models is a list of Decision Tree models (rpart.objects) generated by DF_train()
DT_train_CV() is only designed for Cross-validation and won't generate models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_pred(DT_models, X, Y = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_pred_+3A_dt_models">DT_models</code></td>
<td>
<p>Constructed DF models</p>
</td></tr>
<tr><td><code id="DF_pred_+3A_x">X</code></td>
<td>
<p>Test Dataset</p>
</td></tr>
<tr><td><code id="DF_pred_+3A_y">Y</code></td>
<td>
<p>Test data endpoint</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.$accuracy:      Overall test accuracy
</p>
<p>.$predictions:    Detailed test prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # data(demo_simple)
  X = data_dili$X
  Y = data_dili$Y
  names(Y)=rownames(X)

  random_seq=sample(nrow(X))
  split_rate=3
  split_sample = suppressWarnings(split(random_seq,1:split_rate))
  Train_X = X[-random_seq[split_sample[[1]]],]
  Train_Y = Y[-random_seq[split_sample[[1]]]]
  Test_X = X[random_seq[split_sample[[1]]],]
  Test_Y = Y[random_seq[split_sample[[1]]]]

  used_model = DF_train(Train_X, Train_Y)
  Pred_result = DF_pred(used_model,Test_X,Test_Y)



</code></pre>

<hr>
<h2 id='DF_train'>Decision Forest algorithm: Model training</h2><span id='topic+DF_train'></span>

<h3>Description</h3>

<p>Decision Forest algorithm: Model training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_train(X, Y, stop_step = 5, Max_tree = 20, min_split = 10, cp = 0.1,
  Filter = F, p_val = 0.05, Method = "bACC", Quiet = T,
  Grace_val = 0.05, imp_accu_val = 0.01, imp_accu_criteria = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_train_+3A_x">X</code></td>
<td>
<p>Training Dataset</p>
</td></tr>
<tr><td><code id="DF_train_+3A_y">Y</code></td>
<td>
<p>Training data endpoint</p>
</td></tr>
<tr><td><code id="DF_train_+3A_stop_step">stop_step</code></td>
<td>
<p>How many extra step would be processed when performance not improved, 1 means one extra step</p>
</td></tr>
<tr><td><code id="DF_train_+3A_max_tree">Max_tree</code></td>
<td>
<p>Maximum tree number in Forest</p>
</td></tr>
<tr><td><code id="DF_train_+3A_min_split">min_split</code></td>
<td>
<p>minimum leaves in tree nodes</p>
</td></tr>
<tr><td><code id="DF_train_+3A_cp">cp</code></td>
<td>
<p>parameters to pruning decision tree, default is 0.1</p>
</td></tr>
<tr><td><code id="DF_train_+3A_filter">Filter</code></td>
<td>
<p>doing feature selection before training</p>
</td></tr>
<tr><td><code id="DF_train_+3A_p_val">p_val</code></td>
<td>
<p>P-value threshold measured by t-test used in feature selection, default is 0.05</p>
</td></tr>
<tr><td><code id="DF_train_+3A_method">Method</code></td>
<td>
<p>Which is used for evaluating training process. MIS: Misclassification rate; ACC: accuracy</p>
</td></tr>
<tr><td><code id="DF_train_+3A_quiet">Quiet</code></td>
<td>
<p>if TRUE (default), don't show any message during the process</p>
</td></tr>
<tr><td><code id="DF_train_+3A_grace_val">Grace_val</code></td>
<td>
<p>Grace Value in evaluation: the next model should have a performance (Accuracy, bACC, MCC) not bad than previous model with threshold</p>
</td></tr>
<tr><td><code id="DF_train_+3A_imp_accu_val">imp_accu_val</code></td>
<td>
<p>improvement in evaluation: adding new tree should improve the overall model performance (Accuracy, bACC, MCC) by threshold</p>
</td></tr>
<tr><td><code id="DF_train_+3A_imp_accu_criteria">imp_accu_criteria</code></td>
<td>
<p>if TRUE, model must have improvement in accumulated accuracy</p>
</td></tr>
</table>


<h3>Value</h3>

<p>.$accuracy:     Overall training accuracy
</p>
<p>.$pred:         Detailed training prediction (fitting)
</p>
<p>.$detail:       Detailed usage of Decision tree Features/Models and their performances
</p>
<p>.$models:       Constructed (list of) Decision tree models
</p>
<p>.$Method:        pass evaluating Methods used in training
</p>
<p>.$cp:            pass cp value used in training decision trees
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ##data(iris)
  X = iris[,1:4]
  Y = iris[,5]
  names(Y)=rownames(X)
  used_model = DF_train(X,factor(Y))

</code></pre>

<hr>
<h2 id='DF_Trainsummary'>output summary for Dforest test results</h2><span id='topic+DF_Trainsummary'></span>

<h3>Description</h3>

<p>Draw plot for Dforest test results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DF_Trainsummary(used_model, plot = T)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DF_Trainsummary_+3A_used_model">used_model</code></td>
<td>
<p>Training result</p>
</td></tr>
<tr><td><code id="DF_Trainsummary_+3A_plot">plot</code></td>
<td>
<p>if TRUE (default), draw plot</p>
</td></tr>
</table>

<hr>
<h2 id='Dforest'>Demo script to lean Decision Forest package
Demo data are located in data/ folder</h2><span id='topic+Dforest'></span>

<h3>Description</h3>

<p>Demo script to lean Decision Forest package
Demo data are located in data/ folder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dforest()
</code></pre>


<h3>Author(s)</h3>

<p>Leihong.Wu
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  Dforest()
</code></pre>

<hr>
<h2 id='multiplot'>multiplot</h2><span id='topic+multiplot'></span>

<h3>Description</h3>

<p>Multiple plot function
</p>
<p>If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
then plot 1 will go in the upper left, 2 will go in the upper right, and
3 will go all the way across the bottom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiplot(..., plotlist = NULL, cols = 1, layout = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiplot_+3A_...">...</code></td>
<td>
<p>ggplot objects</p>
</td></tr>
<tr><td><code id="multiplot_+3A_plotlist">plotlist</code></td>
<td>
<p>a list of ggplot objects</p>
</td></tr>
<tr><td><code id="multiplot_+3A_cols">cols</code></td>
<td>
<p>Number of columns in layout</p>
</td></tr>
<tr><td><code id="multiplot_+3A_layout">layout</code></td>
<td>
<p>A matrix specifying the layout. If present, 'cols' is ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='Pred_DT'>Doing Prediction with Decision Tree model</h2><span id='topic+Pred_DT'></span>

<h3>Description</h3>

<p>Doing Prediction with Decision Tree model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pred_DT(model, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Pred_DT_+3A_model">model</code></td>
<td>
<p>Decision Tree Model</p>
</td></tr>
<tr><td><code id="Pred_DT_+3A_x">X</code></td>
<td>
<p>dataset</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Decision Tree Predictions
Different endpoints presented in multiple columns
</p>


<h3>Source</h3>

<p>rpart
</p>


<h3>See Also</h3>

<p><code>rpart</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
