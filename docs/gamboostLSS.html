<!DOCTYPE html><html lang="en"><head><title>Help for package gamboostLSS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gamboostLSS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gamboostLSS-package'>
<p>Boosting algorithms for GAMLSS</p></a></li>
<li><a href='#as.families'>
<p>Include <code>gamlss</code> families in the boosting framework of <code>gamboostLSS</code></p></a></li>
<li><a href='#cvrisk.mboostLSS'><p> Cross-Validation</p></a></li>
<li><a href='#Families'>
<p>Families for GAMLSS models</p></a></li>
<li><a href='#gamboostLSS_intern'>
<p>Call internal functions.</p></a></li>
<li><a href='#india'>
<p>Malnutrition of Children in India (DHS, 1998-99)</p></a></li>
<li><a href='#mboostLSS'>
<p>Fitting GAMLSS by Boosting</p></a></li>
<li><a href='#methods'>
<p>Methods for mboostLSS</p></a></li>
<li><a href='#stabsel'>
<p>Stability Selection</p></a></li>
<li><a href='#weighted.median'>
<p>Weighted Median</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Boosting Methods for 'GAMLSS'</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1-0</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-14</td>
</tr>
<tr>
<td>Description:</td>
<td>Boosting models for fitting generalized additive models for
  location, shape and scale ('GAMLSS') to potentially high dimensional
  data.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0), mboost (&ge; 2.8-0), stabs (&ge; 0.5-0), parallel</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gamlss, gamlss.dist, survival, BayesX, R2BayesX, DirichletReg</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/boost-R/gamboostLSS">https://github.com/boost-R/gamboostLSS</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-24 09:39:00 UTC; Benjamin (PEI)</td>
</tr>
<tr>
<td>Author:</td>
<td>Benjamin Hofner <a href="https://orcid.org/0000-0003-2810-3186"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Andreas Mayr [aut],
  Nora Fenske [aut],
  Janek Thomas [aut],
  Matthias Schmid [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Benjamin Hofner &lt;benjamin.hofner@pei.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-24 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='gamboostLSS-package'>
Boosting algorithms for GAMLSS
</h2><span id='topic+gamboostLSS-package'></span>

<h3>Description</h3>

<p>Boosting methods for fitting generalized additive models for
location, scale and shape (GAMLSS).
</p>


<h3>Details</h3>

<p>This package uses boosting algorithms for fitting GAMLSS (generalized
additive models for location, scale and shape). For information on
GAMLSS theory see Rigby and Stasinopoulos (2005), or the information
provided at <a href="https://www.gamlss.com/">https://www.gamlss.com/</a>. For a tutorial on
<code><a href="#topic+gamboostLSS">gamboostLSS</a></code> see Hofner et al. (2015). Thomas et al. (2018) 
developed a novel non-cyclic approach to fit <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> models. 
This approach is suitable for the combination with <code><a href="mboost.html#topic+stabsel">stabsel</a></code> and 
speeds up model tuning via <code><a href="#topic+cvrisk">cvrisk</a></code>. 
</p>
<p>The fitting methods <code><a href="#topic+glmboostLSS">glmboostLSS</a></code> and
<code><a href="#topic+gamboostLSS">gamboostLSS</a></code>, are alternatives for the algorithms
provided with <code><a href="gamlss.html#topic+gamlss">gamlss</a></code> in the <code>gamlss</code>
package. They offer shrinkage of effect estimates, intrinsic variable
selecion and model choice for potentially high-dimensional data
settings.
</p>
<p><code><a href="#topic+glmboostLSS">glmboostLSS</a></code> (for linear effects) and
<code><a href="#topic+gamboostLSS">gamboostLSS</a></code> (for smooth effects) depend on their
analogous companions <code><a href="mboost.html#topic+glmboost">glmboost</a></code> and
<code><a href="mboost.html#topic+gamboost">gamboost</a></code> for generalized additive models
(contained in package <code>mboost</code>, see Hothorn et al. 2010,
2015) and are similar in their usage.
</p>
<p>The package includes some pre-defined GAMLSS distributions, but the
user can also specify new distributions with <code><a href="#topic+Families">Families</a></code>.
</p>
<p>A wide range of different base-learners is available for covariate
effects (see <code><a href="mboost.html#topic+baselearners">baselearners</a></code>) including linear
(<code>bols</code>), non-linear (<code>bbs</code>), random (<code>brandom</code>) or
spatial effects (<code>bspatial</code> or Markov random fields <code>bmrf</code>).
Each bease-learner can be included seperately for each predictor. The
selection of base-learnes is crucial as it implies the kind of effect
the covariate has on each distribution parameter in the final GAMLSS.
</p>


<h3>Author(s)</h3>

<p>Benjamin Hofner, Andreas Mayr, Nora Fenske, Janek Thomas, Matthias Schmid
</p>
<p>Maintainer:  Benjamin Hofner &lt;benjamin.hofner@pei.de&gt;
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>
<p>Mayr, A., Fenske, N., Hofner, B., Kneib, T. and Schmid, M. (2012):
Generalized additive models for location, scale and shape for
high-dimensional data - a flexible approach based on boosting. Journal
of the Royal Statistical Society, Series C (Applied Statistics) 61(3):
403-427.
</p>
<p>M. Schmid, S. Potapov, A. Pfahlberg, and T. Hothorn. Estimation and
regularization techniques for regression models with multidimensional
prediction functions. Statistics and Computing, 20(2):139-150, 2010.
</p>
<p>Rigby, R. A. and D. M. Stasinopoulos (2005). Generalized additive models
for location, scale and shape (with discussion). Journal of the Royal
Statistical Society, Series C (Applied Statistics), 54, 507-554.
</p>
<p>Stasinopoulos, D. M. and R. A. Rigby (2007). Generalized additive models
for location scale and shape (GAMLSS) in R. Journal of Statistical
Software 23(7).
</p>
<p>Buehlmann, P. and Hothorn, T. (2007). Boosting algorithms: Regularization,
prediction and model fitting. Statistical Science, 22(4), 477&ndash;505.
</p>
<p>Hothorn, T., Buehlmann, P., Kneib, T., Schmid, M. and Hofner, B. (2010).
Model-based boosting 2.0. Journal of Machine Learning Research 11(Aug),
2109-2113.
</p>
<p>Hothorn, T., Buehlmann, P., Kneib, T., Schmid, M. and Hofner, B. (2015).
mboost: Model-based boosting. R package version 2.4-2.
<a href="https://CRAN.R-project.org/package=mboost">https://CRAN.R-project.org/package=mboost</a>
</p>
<p>Thomas, J., Mayr, A., Bischl, B., Schmid, M., Smith, A., and Hofner, B. (2018), 
Gradient boosting for distributional regression - faster tuning and improved 
variable selection via noncyclical updates. 
<em>Statistics and Computing</em>. 28: 673-687. 
<a href="https://doi.org/10.1007/s11222-017-9754-6">doi:10.1007/s11222-017-9754-6</a><br />
(Preliminary version: <a href="https://arxiv.org/abs/1611.10171">https://arxiv.org/abs/1611.10171</a>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamboostLSS">gamboostLSS</a></code> and <code><a href="#topic+glmboostLSS">glmboostLSS</a></code> for model
fitting. Available distributions (families) are documented here:
<code><a href="#topic+Families">Families</a></code>.
</p>
<p>See also the <code>mboost</code> package for more on model-based boosting, or
the <code><a href="gamlss.html#topic+gamlss">gamlss</a></code> package for the original GAMLSS
algorithms provided by Rigby and Stasinopoulos.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate covariates
x1 &lt;- runif(100)
x2 &lt;- runif(100)
eta_mu &lt;-     2 - 2*x1
eta_sigma &lt;-  -1  + 2*x2

# Generate response: Negative Binomial Distribution
y &lt;- numeric(100)
for( i in 1:100)  y[i] &lt;- rnbinom(1, size=exp(eta_sigma[i]), mu=exp(eta_mu[i]))

# Model fitting, 300 boosting steps, same formula for both distribution parameters
mod1 &lt;- glmboostLSS( y ~ x1 + x2, families=NBinomialLSS(),
        control=boost_control(mstop=300), center = TRUE)

# Shrinked effect estimates
coef(mod1, off2int=TRUE)

# Empirical risk with respect to mu
plot(risk(mod1)$mu)

# Empirical risk with respect to sigma
plot(risk(mod1)$sigma)
</code></pre>

<hr>
<h2 id='as.families'>
Include <code>gamlss</code> families in the boosting framework of <code>gamboostLSS</code>
</h2><span id='topic+as.families'></span><span id='topic+gamlss.Families'></span><span id='topic+gamlss1parMu'></span><span id='topic+gamlss2parMu'></span><span id='topic+gamlss2parSigma'></span><span id='topic+gamlss3parMu'></span><span id='topic+gamlss3parSigma'></span><span id='topic+gamlss3parNu'></span><span id='topic+gamlss4parMu'></span><span id='topic+gamlss4parSigma'></span><span id='topic+gamlss4parNu'></span><span id='topic+gamlss4parTau'></span>

<h3>Description</h3>

<p>The function <code>as.families()</code> provides an interface to apply
the available distributions (families) of the <code>gamlss.dist</code> package
for boosting GAMLSS via <code>gamboostLSS</code>.
</p>
<p>The function automatically builds sub-families for every distribution
parameter and uses the constructor function <code><a href="#topic+Families">Families</a></code> to
build a <code>families</code> object, which can be then included in the
fitting functions <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> and
<code><a href="#topic+glmboostLSS">glmboostLSS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.families(fname = "NO", stabilization = c("none", "MAD", "L2"),
            mu = NULL, sigma = NULL, nu = NULL, tau = NULL,
            mu.link = NULL, sigma.link = NULL, nu.link = NULL, 
            tau.link = NULL)

## a wrapper to as.families:
gamlss.Families(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.families_+3A_fname">fname</code></td>
<td>

<p>name of the distribution in the <code>gamlss</code> framework,
as specified in the <code>gamlss.dist</code> package (e.g., <code>"NO"</code> for a
normal distribution with parameters <code>mu</code> and <code>sigma</code>).
Alternatively, one can directly specify the function (i.e.,
<code>NO</code>) or the evaluated function <code>NO()</code>.
</p>
</td></tr>
<tr><td><code id="as.families_+3A_mu">mu</code></td>
<td>
<p>possible offset value for parameter <code>mu</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_sigma">sigma</code></td>
<td>
<p>possible offset value for parameter <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_nu">nu</code></td>
<td>
<p>possible offset value for parameter <code>nu</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_tau">tau</code></td>
<td>
<p>possible offset value for parameter <code>tau</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_mu.link">mu.link</code></td>
<td>
<p>different link function for parameter <code>mu</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_sigma.link">sigma.link</code></td>
<td>
<p>different link function for parameter <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_nu.link">nu.link</code></td>
<td>
<p>different link function for parameter <code>nu</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_tau.link">tau.link</code></td>
<td>
<p>different link function for parameter <code>tau</code>.</p>
</td></tr>
<tr><td><code id="as.families_+3A_stabilization">stabilization</code></td>
<td>
<p> governs if the negative gradient should be
standardized in each boosting step. It can be either &quot;none&quot; or
&quot;MAD&quot;. For details see <code><a href="#topic+Families">Families</a></code>.
</p>
</td></tr>
<tr><td><code id="as.families_+3A_...">...</code></td>
<td>
<p>same arguments as above.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function aims at providing an interface to include all available
GAMLSS distributions which are implemented with the original
<code>gamlss.dist</code> package in the model-based boosting framework. The user
specifies the name of the family (as it is called in
<code>gamlss.dist</code>), and the function automatically builds the
corresponding <code>mboost</code>-like sub-families and the final
<code>families</code> object, which can be then used with the fitting
functions <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> and <code><a href="#topic+glmboostLSS">glmboostLSS</a></code>.
</p>
<p>If no different link functions are specified, the standard links for the
corresponding family in <code>gamlss.dist</code> are applied. 
</p>
<p>To extract the necessary information regarding partial derivatives
(for the <code>ngradient</code> - see <code><a href="mboost.html#topic+Family">Family</a></code> for details) and
the log-likelihood (for the <code>loss</code>) the <code>gamlss.dist</code>
package is loaded. If the package is not installed yet, this will
prompt an error message.
</p>
<p>The functions <code>gamlss1parMu</code>, <code>gamlss2parMu</code>,
<code>gamlss2parSigma</code>, ... , <code>gamlss4parTau</code> are called
internally to construct the sub-families. For one-parametric
distributions, the function will prompt a warning and returns a
<code>mboost</code> family, which can be then used by the fitting
functions of the <code>mboost</code> package.
</p>
<p>For information on GAMLSS theory see Rigby and Stasinopoulos (2005),
lists of available distributions are provided at
<a href="https://www.gamlss.com/">https://www.gamlss.com/</a>. For more on details boosting GAMLSS see Mayr
et al. (2012). Hofner et al. (2016) provides a worked example and more
details on <code>as.families</code>.
</p>
<p>To (potentially) stabilize the model estimation by standardizing the
negative gradients one can use the argument <code>stabilization</code> of
the families. See <code><a href="#topic+Families">Families</a></code> for details.
</p>


<h3>Value</h3>

<p>An object of class <code>families</code>. If the user specifies a
one-parametric distribution, an object of class <code>family</code> is
returned.
</p>


<h3>Author(s)</h3>

<p>The help of Mikis Stasinpoulos during the work on this function is
gratefully acknowledged.
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>
<p>Mayr, A., Fenske, N., Hofner, B., Kneib, T. and Schmid, M. (2012):
Generalized additive models for location, scale and shape for
high-dimensional data - a flexible approach based on boosting. Journal
of the Royal Statistical Society, Series C (Applied Statistics) 61(3):
403-427.
</p>
<p>Rigby, R. A. and D. M. Stasinopoulos (2005). Generalized additive models
for location, scale and shape (with discussion). Journal of the Royal
Statistical Society, Series C (Applied Statistics), 54, 507-554.
</p>


<h3>See Also</h3>

<p><code>gamlss.dist</code> for available distributions in the <code>gamlss</code>
framework.
</p>
<p><code><a href="#topic+Families">Families</a></code> for a documentation of pre-implemented
distributions for <code>gamboostLSS</code>, as well as possibilities for
user-defined distributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## simulate small example
set.seed(123)
x &lt;- runif(1000)

y &lt;- rnorm(mean = 2 + 3 * x,        # effect on mu
           sd   = exp( 1 - 1 * x ), # effect on sigma
           n    = 1000)

## boosting
glmss &lt;- glmboostLSS(y ~ x, families = as.families("NO"))
## the same:
if (require("gamlss.dist")) {
    glmss &lt;- glmboostLSS(y ~ x, families = as.families(NO))
    glmss &lt;- glmboostLSS(y ~ x, families = as.families(NO()))
}

coef(glmss, off2int = TRUE)

## compare to gamlss
library(gamlss)
glmss2 &lt;- gamlss(y ~ x, sigma.formula = ~x, family = "NO")
coef(glmss2)
glmss2$sigma.coef

</code></pre>

<hr>
<h2 id='cvrisk.mboostLSS'> Cross-Validation </h2><span id='topic+cvrisk'></span><span id='topic+cvrisk.mboostLSS'></span><span id='topic+cvrisk.nc_mboostLSS'></span><span id='topic+make.grid'></span><span id='topic+plot.cvriskLSS'></span><span id='topic+plot.nc_cvriskLSS'></span>

<h3>Description</h3>

<p>Multidimensional cross-validated estimation of the empirical risk for
hyper-parameter selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mboostLSS'
cvrisk(object, folds = cv(model.weights(object)),
       grid = make.grid(mstop(object)), papply = mclapply,
       trace = TRUE, mc.preschedule = FALSE, fun = NULL, ...)

make.grid(max, length.out = 10, min = NULL, log = TRUE,
          dense_mu_grid = TRUE)
          
## S3 method for class 'nc_mboostLSS'
cvrisk(object, folds = cv(model.weights(object)),
       grid = 1:sum(mstop(object)), papply = mclapply,
       trace = TRUE, mc.preschedule = FALSE, fun = NULL, ...)          

## S3 method for class 'cvriskLSS'
plot(x, type = c("heatmap", "lines"),
     xlab = NULL, ylab = NULL, ylim = range(x),
     main = attr(x, "type"), ...)
     
## S3 method for class 'nc_cvriskLSS'
plot(x, xlab = "Number of boosting iterations", ylab = NULL,
     ylim = range(x), main = attr(x, "type"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cvrisk.mboostLSS_+3A_object">object</code></td>
<td>

<p>an object of class <code>mboostLSS</code> (i.e., a boosted GAMLSS model with 
<code>method = "cyclic"</code>) or class <code>nc_mboostLSS</code> (i.e., a boosted
GAMLSS model with <code>method = "noncyclic"</code>)
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_folds">folds</code></td>
<td>

<p>a weight matrix with number of rows equal to the number of
observations. The number of columns corresponds to the number of
cross-validation runs. Can be computed using function
<code><a href="mboost.html#topic+cv">cv</a></code> from package <span class="pkg">mboost</span> and defaults to 25
bootstrap samples.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_grid">grid</code></td>
<td>

<p>If the model was fitted with <code>method = "cyclic"</code>, grid is
a matrix of stopping parameters the empirical risk is to be evaluated for. 
Each row represents a parameter combination. The number of columns must be 
equal to the number of parameters of the GAMLSS family. Per default, 
<code>make.grid(mstop(object))</code> is used.
</p>
<p>Otherwise (i.e., for <code>method = "noncyclic"</code>) grid
is a vector of mstop values. Per default all steps up to the intial stopping 
iteration, i.e., <code>1:mstop(object)</code> are used.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_papply">papply</code></td>
<td>

<p>(parallel) apply function, defaults to  <code><a href="parallel.html#topic+mclapply">mclapply</a></code>.
Alternatively, <code><a href="parallel.html#topic+parLapply">parLapply</a></code> can be used. In the
latter case, usually more setup is needed. To run <code>cvrisk</code>
sequentially (i.e. not in parallel), one can use <code><a href="base.html#topic+lapply">lapply</a></code>.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_trace">trace</code></td>
<td>

<p>should status information beein printed during cross-validation?
Default: <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_mc.preschedule">mc.preschedule</code></td>
<td>

<p>preschedule tasks if are parallelized using <code><a href="parallel.html#topic+mclapply">mclapply</a></code>
(default: <code>FALSE</code>)? For details see <code><a href="parallel.html#topic+mclapply">mclapply</a></code>.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_fun">fun</code></td>
<td>

<p>if <code>fun</code> is NULL, the out-of-sample risk is returned. <code>fun</code>,
as a function of <code>object</code>, may extract any other characteristic
of the cross-validated models. These are returned as is.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_...">...</code></td>
<td>

<p>additional arguments passed to <code><a href="parallel.html#topic+mclapply">mclapply</a></code> or
the <code>plot</code> function depending on the context.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_max">max</code></td>
<td>

<p>a named vector of length equal to the number of parameters of the GAMLSS
family (and names equal to the names of <code>families</code>) that
determines the maximal values of the grid.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_length.out">length.out</code></td>
<td>

<p>the number of grid points (default: 10). This can be either a vector
of the same length as <code>max</code> (with different values) or a scalar
(which is then used as length for all grids).
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_min">min</code></td>
<td>

<p>minimal value of the grid. Per default the grid starts at 1 but
other values (smaller <code>max</code>) are possible. This can be either a
vector of the same length as <code>max</code> (with different values) or a
scalar (which is then used as <code>min</code> for all grids).
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_log">log</code></td>
<td>

<p>should the grid be on a logarithmic scale? Default: <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_dense_mu_grid">dense_mu_grid</code></td>
<td>

<p>should the grid in the <code>mu</code> component be extended for all
values of the <code>mstop</code> values corresponding to <code>mu</code> that
are greater or equal to all other parameters in this combination.
These values can be computed without or with very little additional
computational costs. For details see examples.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_x">x</code></td>
<td>

<p>an object of class <code>cvriskLSS</code> (cyclic fitting) or <code>nc_cvriskLSS</code>
(non-cyclic fitting), which results from running <code>cvrisk</code>.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_type">type</code></td>
<td>

<p>should <code>"lines"</code> or a <code>"heatmap"</code> (default) be plotted?
See details.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_xlab">xlab</code>, <code id="cvrisk.mboostLSS_+3A_ylab">ylab</code></td>
<td>

<p>user-specified labels for the x-axis and y-axis of the plot (which
are usually not needed). The defaults depend on the plot <code>type</code>.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_ylim">ylim</code></td>
<td>

<p>limits of the y-axis. Only applicable for the line plot.
</p>
</td></tr>
<tr><td><code id="cvrisk.mboostLSS_+3A_main">main</code></td>
<td>

<p>a title for the plots.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of boosting iterations is a hyper-parameter of the
boosting algorithms implemented in this package. Honest,
i.e., cross-validated, estimates of the empirical risk
for different stopping parameters <code>mstop</code> are computed by
this function which can be utilized to choose an appropriate
number of boosting iterations to be applied. For details see
<code><a href="mboost.html#topic+cvrisk.mboost">cvrisk.mboost</a></code>.
</p>
<p><code>make.grid</code> eases the creation of an equidistand, integer-valued
grids, which can be used with <code>cvrisk</code>. Per default, the grid is
equidistant on a logarithmic scale.
</p>
<p>The line plot depicts the avarage risk for each grid point and
additionally shows information on the variability of the risk from
fold to fold. The heatmap shows only the average risk but in a nicer
fashion.
</p>
<p>For the <code>method = "noncyclic"</code> only the line plot exists.
</p>
<p>Hofner et al. (2016) provide a detailed description of
cross-validation for <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> models and show a
worked example. Thomas et al. (2018) compare cross-validation for the
the cyclic and non-cyclic boosting approach and provide worked examples.
</p>


<h3>Value</h3>

<p>An object of class <code>cvriskLSS</code> or <code>nc_cvriskLSS</code> for cyclic and
non-cyclic fitting, respectively, (when <code>fun</code> wasn't specified); 
Basically a matrix containing estimates of the empirical
risk for a varying number of bootstrap iterations. <code>plot</code> and
<code>print</code> methods are available as well as an <code>mstop</code> method.
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>
<p>Thomas, J., Mayr, A., Bischl, B., Schmid, M., Smith, A., and Hofner, B. (2018), 
Gradient boosting for distributional regression - faster tuning and improved 
variable selection via noncyclical updates. 
<em>Statistics and Computing</em>. 28: 673-687. 
<a href="https://doi.org/10.1007/s11222-017-9754-6">doi:10.1007/s11222-017-9754-6</a><br />
(Preliminary version: <a href="https://arxiv.org/abs/1611.10171">https://arxiv.org/abs/1611.10171</a>).
</p>


<h3>See Also</h3>

<p><code><a href="mboost.html#topic+cvrisk.mboost">cvrisk.mboost</a></code> and <code><a href="mboost.html#topic+cv">cv</a></code> (both in package
<span class="pkg">mboost</span>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data generating process:
set.seed(1907)
x1 &lt;- rnorm(1000)
x2 &lt;- rnorm(1000)
x3 &lt;- rnorm(1000)
x4 &lt;- rnorm(1000)
x5 &lt;- rnorm(1000)
x6 &lt;- rnorm(1000)
mu    &lt;- exp(1.5 +1 * x1 +0.5 * x2 -0.5 * x3 -1 * x4)
sigma &lt;- exp(-0.4 * x3 -0.2 * x4 +0.2 * x5 +0.4 * x6)
y &lt;- numeric(1000)
for( i in 1:1000)
    y[i] &lt;- rnbinom(1, size = sigma[i], mu = mu[i])
dat &lt;- data.frame(x1, x2, x3, x4, x5, x6, y)

## linear model with y ~ . for both components: 100 boosting iterations
model &lt;- glmboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
                     control = boost_control(mstop = 100),
                     center = TRUE)

## set up a grid
grid &lt;-  make.grid(mstop(model), length.out = 5, dense_mu_grid = FALSE)
plot(grid)

### Do not test the following code per default on CRAN as it takes some time to run:
### a tiny toy example (5-fold bootsrap with maximum stopping value 100)
## (to run it on multiple cores of a Linux or Mac OS computer remove
##  set papply = mclapply (default) and set mc.nodes to the
##  appropriate number of nodes)
cvr &lt;- cvrisk(model, folds = cv(model.weights(model), B = 5),
              papply = lapply, grid = grid)
cvr
## plot the results
par(mfrow = c(1, 2))
plot(cvr)
plot(cvr, type = "lines")
## extract optimal mstop (here: grid to small)
mstop(cvr)
### END (don't test automatically)


### Do not test the following code per default on CRAN as it takes some time to run:
### a more realistic example
grid &lt;- make.grid(c(mu = 400, sigma = 400), dense_mu_grid = FALSE)
plot(grid)
cvr &lt;- cvrisk(model, grid = grid)
mstop(cvr)
## set model to optimal values:
mstop(model) &lt;- mstop(cvr)
### END (don't test automatically)


### Other grids:
plot(make.grid(mstop(model), length.out = 3, dense_mu_grid = FALSE))
plot(make.grid(c(mu = 400, sigma = 400), log = FALSE, dense_mu_grid = FALSE))
plot(make.grid(c(mu = 400, sigma = 400), length.out = 4,
               min = 100, log = FALSE, dense_mu_grid = FALSE))


### Now use dense mu grids
# standard grid
plot(make.grid(c(mu = 100, sigma = 100), dense = FALSE),
     pch = 20, col = "red")
# dense grid for all mstop_mu values greater than mstop_sigma
grid &lt;- make.grid(c(mu = 100, sigma = 100))
points(grid, pch = 20, cex = 0.2)
abline(0,1)

# now with three parameters
grid &lt;- make.grid(c(mu = 100, sigma = 100, df = 30),
                  length.out = c(5, 5, 2), dense = FALSE)
densegrid &lt;- make.grid(c(mu = 100, sigma = 100, df = 30),
                       length.out = c(5, 5, 2))
par(mfrow = c(1,2))
# first for df = 1
plot(grid[grid$df == 1, 1:2], main = "df = 1", pch = 20, col = "red")
abline(0,1)
abline(v = 1)
# now expand grid for all mu values greater the corresponding sigma
# value (i.e. below the bisecting line) and above df (i.e. 1)
points(densegrid[densegrid$df == 1, 1:2], pch = 20, cex = 0.2)

# now for df = 30
plot(grid[grid$df == 30, 1:2], main = "df = 30", pch = 20, col = "red")
abline(0,1)
abline(v = 30)
# now expand grid for all mu values greater the corresponding sigma
# value (i.e. below the bisecting line) and above df (i.e. 30)
points(densegrid[densegrid$df == 30, 1:2], pch = 20, cex = 0.2)
</code></pre>

<hr>
<h2 id='Families'>
Families for GAMLSS models
</h2><span id='topic+Families'></span><span id='topic+families'></span><span id='topic+GaussianLSS'></span><span id='topic+GaussianMu'></span><span id='topic+GaussianSigma'></span><span id='topic+GammaLSS'></span><span id='topic+GammaMu'></span><span id='topic+GammaSigma'></span><span id='topic+BetaLSS'></span><span id='topic+BetaMu'></span><span id='topic+BetaPhi'></span><span id='topic+NBinomialLSS'></span><span id='topic+NBinomialMu'></span><span id='topic+NBinomialSigma'></span><span id='topic+StudentTLSS'></span><span id='topic+StudentTMu'></span><span id='topic+StudentTSigma'></span><span id='topic+StudentTDf'></span><span id='topic+LogNormalLSS'></span><span id='topic+LogNormalMu'></span><span id='topic+LogNormalSigma'></span><span id='topic+WeibullLSS'></span><span id='topic+WeibullMu'></span><span id='topic+WeibullSigma'></span><span id='topic+LogLogLSS'></span><span id='topic+LogLogMu'></span><span id='topic+LogLogSigma'></span><span id='topic+ZIPoLSS'></span><span id='topic+ZINBLSS'></span><span id='topic+DirichletAlpha'></span><span id='topic+DirichletLSS'></span><span id='topic+options'></span><span id='topic+stab_ngrad'></span><span id='topic+stabilize_ngrad'></span><span id='topic+stabilize_ngradient'></span>

<h3>Description</h3>

<p>The package provides some pre-defined GAMLSS families, e.g.
<code>NBionomialLSS</code>. Objects of the class <code>families</code> provide a
convenient way to specify GAMLSS distributions to be fitted by one of
the boosting algorithms implemented in this package. By using the
function <code>Families</code>, a new object of the class <code>families</code>
can be generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>############################################################
# Families for continuous response

# Gaussian distribution
GaussianLSS(mu = NULL, sigma = NULL,
            stabilization = c("none", "MAD", "L2"))

# Student's t-distribution
StudentTLSS(mu = NULL, sigma = NULL, df = NULL,
            stabilization = c("none", "MAD", "L2"))

############################################################
# Families for continuous non-negative response

# Gamma distribution
GammaLSS(mu = NULL, sigma = NULL,
         stabilization = c("none", "MAD", "L2"))

############################################################
# Families for fractions and bounded continuous response

# Beta distribution
BetaLSS(mu = NULL, phi = NULL,
        stabilization = c("none", "MAD", "L2"))

############################################################
# Families for count data

# Negative binomial distribution
NBinomialLSS(mu = NULL, sigma = NULL,
             stabilization = c("none", "MAD", "L2"))

# Zero-inflated Poisson distribution
ZIPoLSS(mu = NULL, sigma = NULL,
        stabilization = c("none", "MAD", "L2"))

# Zero-inflated negative binomial distribution
ZINBLSS(mu = NULL, sigma = NULL, nu = NULL,
        stabilization = c("none", "MAD", "L2"))

############################################################
# Families for survival models (accelerated failure time
# models) for data with right censoring

# Log-normal distribution
LogNormalLSS(mu = NULL, sigma = NULL,
             stabilization = c("none", "MAD", "L2"))

# Log-logistic distribution
LogLogLSS(mu = NULL, sigma = NULL,
          stabilization = c("none", "MAD", "L2"))

# Weibull distribution
WeibullLSS(mu = NULL, sigma = NULL,
           stabilization = c("none", "MAD", "L2"))
           
############################################################
# Family for Dirichlet regression models
DirichletLSS(K = NULL, stabilization = c("none", "MAD", "L2"))

############################################################
# Constructor function for new GAMLSS distributions
Families(..., qfun = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Families_+3A_...">...</code></td>
<td>
<p> sub-families to be passed to constructor. </p>
</td></tr>
<tr><td><code id="Families_+3A_qfun">qfun</code></td>
<td>
<p> quantile function. This function can for example be used
to compute (marginal) prediction intervals. See
<code><a href="#topic+predint">predint</a></code>.</p>
</td></tr>
<tr><td><code id="Families_+3A_name">name</code></td>
<td>
<p> name of the families. </p>
</td></tr>
<tr><td><code id="Families_+3A_mu">mu</code></td>
<td>
<p> offset value for mu. </p>
</td></tr>
<tr><td><code id="Families_+3A_sigma">sigma</code></td>
<td>
<p> offset value for sigma. </p>
</td></tr>
<tr><td><code id="Families_+3A_phi">phi</code></td>
<td>
<p> offset value for phi. </p>
</td></tr>
<tr><td><code id="Families_+3A_df">df</code></td>
<td>
<p> offset value for df. </p>
</td></tr>
<tr><td><code id="Families_+3A_nu">nu</code></td>
<td>
<p> offset value for nu. </p>
</td></tr>
<tr><td><code id="Families_+3A_stabilization">stabilization</code></td>
<td>
<p> governs if the negative gradient should be
standardized in each boosting step. It can be either &quot;none&quot;, 
&quot;MAD&quot; or &quot;L2&quot;. See also Details below.
</p>
</td></tr>
<tr><td><code id="Families_+3A_k">K</code></td>
<td>
<p>An integer specifying the number of categories in the Dirichlet distribution. This must be provided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments of the families are the offsets for each distribution
parameter. Offsets can be either scalar, a vector with length equal to
the number of observations or <code>NULL</code> (default). In the latter
case, a scalar offset for this component is computed by minimizing the
risk function w.r.t. the corresponding distribution parameter (keeping
the other parameters fixed).
</p>
<p>Note that <code>gamboostLSS</code> is not restricted to three components but
can handle an arbitrary number of components (which, of course,
depends on the GAMLSS distribution). However, it is important that the
names (for the offsets, in the sub-families etc.) are chosen
<em>consistently</em>.
</p>
<p>The <code>ZIPoLSS</code> families can be used to fit zero-inflated Poisson
models. Here, <code>mu</code> and <code>sigma</code> refer to the location
parameter of the Poisson component (with log link) and the mean of the
zero-generating process (with logit link), respectively.
</p>
<p>Similarly, <code>ZINBLSS</code> can be used to fit zero-inflated negative
binomial models. Here, <code>mu</code> and <code>sigma</code> refer to the
location and scale parameters (with log link) of the negative binomial
component of the model. The zero-generating process (with logit link)
is represented by <code>nu</code>.
</p>
<p>The <code>DirichletLSS</code> family can be used to fit Dirichlet regression models.
Here, <code>DirichletAlpha</code> corresponds to the distributional parameters in
the Dirichlet distribution which are dependent on the number of categories 
in the respective compositional data (that is, proportions, amounts or rates.)
The number of categories, thereby distributional parameters in the data set
(K) has to be specified manually in the beginning of the fitting process
of the model.
</p>
<p>The <code>Families</code> function can be used to implements a new GAMLSS
distribution which can be used for fitting by <code><a href="#topic+mboostLSS">mboostLSS</a></code>.
Thereby, the function builds a list of sub-families, one for each
distribution parameter. The sub-families themselves are objects of the
class <code>boost_family</code>, and can be constructed via the function
<code><a href="mboost.html#topic+Family">Family</a></code> of the <span class="pkg">mboost</span> Package.
</p>
<p>Arguments to be passed to <code><a href="mboost.html#topic+Family">Family</a></code>: The <code>loss</code> for every
distribution parameter (contained in objects of class
<code>boost_family</code>) is the negative log-likelihood of the
corresponding distribution. The <code>ngradient</code> is the negative
partial derivative of the loss function with respect to the
distribution parameter. For a two-parameter distribution (e.g. mu and
sigma), the user therefore has to specify two sub-families with
<code><a href="mboost.html#topic+Family">Family</a></code>. The <code>loss</code> is basically the same function
for both paramters, only <code>ngradient</code> differs. Both sub-families
are passed to the <code>Families</code> constructor, which returns an object
of the class <code>families</code>.
</p>
<p>To (potentially) stabilize the model estimation by standardizing the
negative gradients one can use the argument <code>stabilization</code> of
the families. If <code>stabilization = "MAD"</code>, the negative gradient
is divided by its (weighted) median absolute deviation </p>
<p style="text-align: center;"><code class="reqn">median_i
  (|u_{k,i} - median_j(u_{k,j})|)</code>
</p>
<p> in each boosting step. See Hofner et 
al. (2016) for details. An alternative is <code>stabilization = "L2"</code>, 
where the gradient is divided by its (weighted) mean L2 norm. This 
results in negative gradient vectors (and hence also updates) of similar 
size for each distribution parameter, but also for every boosting iteration.  
</p>


<h3>Value</h3>

<p>An object of class <code>families</code>.
</p>


<h3>Author(s)</h3>

<p><code>BetaLSS</code> for boosting beta regression was implemented by Florian
Wickler.
<code>DirichletLSS</code> for boosting Dirichlet regression models was implemented by
Michael Balzer.
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>
<p>Mayr, A., Fenske, N., Hofner, B., Kneib, T. and Schmid, M. (2012):
Generalized additive models for location, scale and shape for
high-dimensional data - a flexible approach based on boosting. Journal
of the Royal Statistical Society, Series C (Applied Statistics) 61(3):
403-427.
</p>
<p>Rigby, R. A. and D. M. Stasinopoulos (2005). Generalized additive
models for location, scale and shape (with discussion). Journal of the
Royal Statistical Society, Series C (Applied Statistics), 54, 507-554.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.families">as.families</a></code> for applying GAMLSS distributions provided
in the framework of the <code>gamlss</code> package.
</p>
<p>The functions <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> and <code><a href="#topic+glmboostLSS">glmboostLSS</a></code>
can be used for model fitting.
</p>
<p>See also the corresponding constructor function
<code><a href="mboost.html#topic+Family">Family</a></code> in <code><a href="mboost.html#topic+mboost">mboost</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example to define a new distribution:
## Students t-distribution with two parameters, df and mu:

## sub-Family for mu
## -&gt; generate object of the class family from the package mboost
newStudentTMu  &lt;- function(mu, df){

    # loss is negative log-Likelihood, f is the parameter to be fitted with
    # id link -&gt; f = mu
    loss &lt;- function(df,  y, f) {
        -1 * (lgamma((df + 1)/2)  - lgamma(1/2) -
              lgamma(df/2) - 0.5 * log(df) -
              (df + 1)/2 * log(1 + (y - f)^2/(df )))
    }
    # risk is sum of loss
    risk &lt;- function(y, f, w = 1) {
        sum(w * loss(y = y, f = f, df = df))
    }
    # ngradient is the negative derivate w.r.t. mu (=f)
    ngradient &lt;- function(y, f, w = 1) {
        (df + 1) * (y - f)/(df  + (y - f)^2)
    }

    # use the Family constructor of mboost
    mboost::Family(ngradient = ngradient, risk = risk, loss = loss,
                   response = function(f) f,
                   name = "new Student's t-distribution: mu (id link)")
}

## sub-Family for df
newStudentTDf &lt;- function(mu, df){

    # loss is negative log-Likelihood, f is the parameter to be fitted with
    # log-link: exp(f) = df
    loss &lt;- function( mu, y, f) {
        -1 * (lgamma((exp(f) + 1)/2)  - lgamma(1/2) -
              lgamma(exp(f)/2) - 0.5 * f -
              (exp(f) + 1)/2 * log(1 + (y - mu)^2/(exp(f) )))
    }
    # risk is sum of loss
    risk &lt;- function(y, f, w = 1) {
        sum(w * loss(y = y, f = f,  mu = mu))
    }
    # ngradient is the negative derivate of the loss w.r.t. f
    # in this case, just the derivative of the log-likelihood 
    ngradient &lt;- function(y, f, w = 1) {
        exp(f)/2 * (digamma((exp(f) + 1)/2) - digamma(exp(f)/2)) -
            0.5 - (exp(f)/2 * log(1 + (y - mu)^2 / (exp(f) )) -
                   (y - mu)^2 / (1 + (y - mu)^2 / exp(f)) * (exp(-f) + 1)/2)
    }
    # use the Family constructor of mboost
    mboost::Family(ngradient = ngradient, risk = risk, loss = loss,
                   response = function(f) exp(f),
                   name = "Student's t-distribution: df (log link)")
}

## families object for new distribution
newStudentT &lt;- Families(mu= newStudentTMu(mu=mu, df=df),
                        df=newStudentTDf(mu=mu, df=df))

### Do not test the following code per default on CRAN as it takes some time to run:
### usage of the new Student's t distribution:
library(gamlss)   ## required for rTF
set.seed(1907)
n &lt;- 5000
x1  &lt;- runif(n)
x2 &lt;- runif(n)
mu &lt;- 2 -1*x1 - 3*x2
df &lt;- exp(1 + 0.5*x1 )
y &lt;- rTF(n = n, mu = mu, nu = df)

## model fitting
model &lt;- glmboostLSS(y ~ x1 + x2, families = newStudentT,
                     control = boost_control(mstop = 100),
                     center = TRUE)
## shrinked effect estimates
coef(model, off2int = TRUE)

## compare to pre-defined three parametric t-distribution:
model2 &lt;- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(),
                      control = boost_control(mstop = 100),
                      center = TRUE)
coef(model2, off2int = TRUE)

## with effect on sigma:
sigma &lt;- 3+ 1*x2
y &lt;- rTF(n = n, mu = mu, nu = df, sigma=sigma)
model3 &lt;- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(),
                      control = boost_control(mstop = 100),
                      center = TRUE)
coef(model3, off2int = TRUE)


</code></pre>

<hr>
<h2 id='gamboostLSS_intern'>
Call internal functions.
</h2><span id='topic+gamboostLSS_intern'></span>

<h3>Description</h3>

<p>Call one of the internal gamboostLSS functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamboostLSS_intern(..., fun = c("check", "do_trace"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gamboostLSS_intern_+3A_...">...</code></td>
<td>
<p> Arguments to <code>fun</code>. </p>
</td></tr>
<tr><td><code id="gamboostLSS_intern_+3A_fun">fun</code></td>
<td>
<p> The name on an internal gamboostLSS function. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function must not be called under any circumstances.
</p>

<hr>
<h2 id='india'>
Malnutrition of Children in India (DHS, 1998-99)
</h2><span id='topic+india'></span><span id='topic+india.bnd'></span>

<h3>Description</h3>

<p>Data sample from the Standard Demographic and Health Survey, 1998-99,
on malnutrition of children in India. The data set contains
approximately 12% of the observations in the original data set and
only a (very small) subset  of variables. Additionally, a boundary
file representing the districts of India is provided for spatial analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(india)
data(india.bnd)
</code></pre>


<h3>Format</h3>

<p>A data frame with 4000 observations on the following 6 variables:
</p>

<dl>
<dt><code>stunting</code></dt><dd><p>A numeric z-score for malnutrition, stunted
growth to be more precise, which ranges from -6 to 6, where
negative values represent malnourished children. Children with
values below -2 are considered stunted (height-for-age).</p>
</dd>
<dt><code>cbmi</code></dt><dd><p>BMI of the child.</p>
</dd>
<dt><code>cage</code></dt><dd><p>Age of the child in months.</p>
</dd>
<dt><code>mbmi</code></dt><dd><p>BMI of the mother.</p>
</dd>
<dt><code>mage</code></dt><dd><p>Age of the mother in years.</p>
</dd>
<dt><code>mcdist</code></dt><dd><p>The district in India, where mother and child live.
A factor encoded to match the map <code><a href="#topic+india.bnd">india.bnd</a></code>.</p>
</dd>
<dt><code>mcdist_lab</code></dt><dd><p>The district in India, where mother and child live.
A factor with actual district names.</p>
</dd>
</dl>



<h3>Details</h3>

<p>For details on the boundary file see function <code><a href="BayesX.html#topic+read.bnd">read.bnd</a></code>
from package <span class="pkg">BayesX</span>.
</p>


<h3>Source</h3>

<p>The complete data set is provided by the Monitoring and Evaluation to
Assess and Use Results Demographic and Health Surveys (MEASURE DHS)
which is funded by the U.S. Agency of International Development
(USAID). It can be obtained for research purposes (after registration)
from
<a href="https://dhsprogram.com/data/dataset/India_Standard-DHS_1999.cfm">https://dhsprogram.com/data/dataset/India_Standard-DHS_1999.cfm</a>
(Data set for All-India, Children's Recode: iakr42dt.zip) </p>


<h3>References</h3>

<p> For details on the data set see also:
</p>
<p>Fahrmeir L and Kneib T (2011),
<em>Bayesian smoothing and regression for longitudinal, spatial and
event history data</em>, Oxford University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("BayesX")) {
  ## plot distribution of stunting in India
  drawmap(india, map = india.bnd, regionvar = "mcdist", plotvar = "stunting")
}
</code></pre>

<hr>
<h2 id='mboostLSS'>
Fitting GAMLSS by Boosting
</h2><span id='topic+mboostLSS'></span><span id='topic+blackboostLSS'></span><span id='topic+glmboostLSS'></span><span id='topic+gamboostLSS'></span><span id='topic+mboostLSS_fit'></span>

<h3>Description</h3>

<p>Functions for fitting GAMLSS (generalized additive models for
location, scale and shape) using boosting techniques. 
Two algorithms are implemented: (a) The cyclic algorithm
iteratively rotates between the distribution parameters, updating one while using
the current fits of the others as offsets (for details see Mayr et
al., 2012). 
(b) The noncyclic algorithm selects in each step the update of a base-learner 
for the distribution parameter that best fits the negative gradient 
(algorithm with inner loss of Thomas et al., 2018). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mboostLSS(formula, data = list(), families = GaussianLSS(),
          control = boost_control(), weights = NULL, 
          method = c("cyclic", "noncyclic"), ...)
glmboostLSS(formula, data = list(), families = GaussianLSS(),
            control = boost_control(), weights = NULL, 
            method = c("cyclic", "noncyclic"), ...)
gamboostLSS(formula, data = list(), families = GaussianLSS(),
            control = boost_control(), weights = NULL, 
            method = c("cyclic", "noncyclic"), ...)
blackboostLSS(formula, data = list(), families = GaussianLSS(),
              control = boost_control(), weights = NULL,
              method = c("cyclic", "noncyclic"), ...)

## fit function:
mboostLSS_fit(formula, data = list(), families = GaussianLSS(),
              control = boost_control(), weights = NULL,
              fun = mboost, funchar = "mboost", call = NULL, method, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mboostLSS_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit. See
<code><a href="mboost.html#topic+mboost">mboost</a></code> for details. If <code>formula</code> is a single formula,
the same formula is used for all distribution parameters. <code>formula</code>
can also be a (named) list, where each list element corresponds
to one distribution parameter of the GAMLSS distribution. The names must be
the same as in the family (see example for details). </p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_data">data</code></td>
<td>
<p> a data frame containing the variables in the model.</p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_families">families</code></td>
<td>
<p> an object of class <code>families</code>. It can be either one of
the pre-defined distributions that come along with the package or a new distribution
specified by the user (see <code><a href="#topic+Families">Families</a></code> for details). Per
default, we use the two-parametric <code><a href="#topic+GaussianLSS">GaussianLSS</a></code> family.</p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_control">control</code></td>
<td>
<p> a list of parameters controlling the algorithm. For
more details see <code><a href="mboost.html#topic+boost_control">boost_control</a></code>. </p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_weights">weights</code></td>
<td>
<p> a numeric vector of weights (optional). </p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_method">method</code></td>
<td>
<p> fitting method, currently two methods are supported:
<code>"cyclic"</code> (see Mayr et al., 2012) and <code>"noncyclic"</code> 
(algorithm with inner loss of Thomas et al., 2018). 
The latter requires a one dimensional <code>mstop</code> value.</p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_fun">fun</code></td>
<td>
<p> fit function. Either <code><a href="mboost.html#topic+mboost">mboost</a></code>,
<code><a href="mboost.html#topic+glmboost">glmboost</a></code>, <code><a href="mboost.html#topic+gamboost">gamboost</a></code> or
<code><a href="mboost.html#topic+blackboost">blackboost</a></code>. Specified directly via the corresponding LSS
function. E.g. <code>gamboostLSS()</code> calls
<code>mboostLSS_fit(..., fun = gamboost)</code>. </p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_funchar">funchar</code></td>
<td>
<p> character representation of fit function. Either <code>"mboost"</code>,
<code>"glmboost"</code>, <code>"gamboost"</code> or <code>"blackboost"</code>.
Specified directly via the corresponding LSS function.</p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_call">call</code></td>
<td>
<p> used to forward the call from <code>mboostLSS</code>,
<code>glmboostLSS</code>, <code>gamboostLSS</code> and <code>blackboostLSS</code>.
This argument should not be directly specified by users!</p>
</td></tr>
<tr><td><code id="mboostLSS_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>mboostLSS_fit</code>.
In  <code>mboostLSS_fit</code>, <code>...</code> represent further arguments to be
passed to <code><a href="mboost.html#topic+mboost">mboost</a></code> and <code><a href="mboost.html#topic+mboost_fit">mboost_fit</a></code>. So
<code>...</code> can be all arguments of <code>mboostLSS_fit</code>and
<code><a href="mboost.html#topic+mboost_fit">mboost_fit</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For information on GAMLSS theory see Rigby and Stasinopoulos (2005) or
the information provided at <a href="https://www.gamlss.com/">https://www.gamlss.com/</a>. For a tutorial on
<code><a href="#topic+gamboostLSS">gamboostLSS</a></code> see Hofner et al. (2016). Thomas et al. (2018) 
developed a novel non-cyclic approach to fit gamboostLSS models. This approach
is suitable for the combination with <code><a href="mboost.html#topic+stabsel">stabsel</a></code> and speeds up
model tuning via <code><a href="#topic+cvrisk">cvrisk</a></code> (see also below).
</p>
<p><code>glmboostLSS</code> uses <code><a href="mboost.html#topic+glmboost">glmboost</a></code> to fit the
distribution parameters of a GAMLSS &ndash; a linear boosting model is
fitted for each parameter.
</p>
<p><code>gamboostLSS</code> uses <code><a href="mboost.html#topic+gamboost">gamboost</a></code> to fit the
distribution parameters of a GAMLSS &ndash; an additive boosting model (by
default with smooth effects) is fitted for each parameter. With the
<code>formula</code> argument, a wide range of different base-learners can
be specified (see <code><a href="mboost.html#topic+baselearners">baselearners</a></code>). The
base-learners imply the type of effect each covariate has on the
corresponding distribution parameter.
</p>
<p><code>mboostLSS</code> uses <code><a href="mboost.html#topic+mboost">mboost</a></code> to fit the
distribution parameters of a GAMLSS. The type of model (linear,
tree-based or smooth) is specified by <code>fun</code>.
</p>
<p><code>blackboostLSS</code> uses <code><a href="mboost.html#topic+blackboost">blackboost</a></code> to fit the
distribution parameters of a GAMLSS &ndash; a tree-based boosting model is
fitted for each parameter.
</p>
<p><code>mboostLSS</code>, <code>glmboostLSS</code>, <code>gamboostLSS</code> and
<code>blackboostLSS</code> all call <code>mboostLSS_fit</code> while <code>fun</code> is
the corresponding <span class="pkg">mboost</span> function, i.e., the same
function without <code>LSS</code>. For further possible arguments see
these functions as well as <code><a href="mboost.html#topic+mboost_fit">mboost_fit</a></code>. 
Note that <code>mboostLSS_fit</code> is usually not called directly by the user. 
</p>
<p>For <code>method = "cyclic"</code> it is possible to specify one or
multiple <code>mstop</code> and <code>nu</code> values via
<code><a href="mboost.html#topic+boost_control">boost_control</a></code>. In the case of one single value, this
value is used for all distribution parameters of the GAMLSS model.
Alternatively, a (named) vector or a (named) list with separate values
for each component can be used to specify a separate value for each
parameter of the GAMLSS model. The names of the list must correspond
to the names of the distribution parameters of the GAMLSS family. If
no names are given, the order of the <code>mstop</code> or <code>nu</code> values
is assumed to be the same as the order of the components in the
<code>families</code>. For one-dimensional stopping, the user therefore can
specify, e.g., <code>mstop = 100</code> via <code><a href="mboost.html#topic+boost_control">boost_control</a></code>. For
more-dimensional stopping, one can specify, e.g., <code>mstop =
  list(mu = 100, sigma = 200)</code> (see examples).
</p>
<p>If <code>method</code> is set to <code>"noncyclic"</code>, <code>mstop</code> has
to be a one dimensional integer. Instead of cycling through all distribution 
parameters, in each iteration only the best base-learner is used. One base-learner of every 
parameter is selected via RSS, the distribution parameter is then chosen via the loss 
(in Thomas et. al., 2018, called inner loss). 
For details on the noncyclic fitting method see Thomas et. al. (2018). 
</p>
<p>To (potentially) stabilize the model estimation by standardizing the
negative gradients one can use the argument <code>stabilization</code> of
the families. See <code><a href="#topic+Families">Families</a></code> for details.
</p>


<h3>Value</h3>

<p>An object of class <code>mboostLSS</code> or <code>nc_mboostLSS</code> (inheriting from 
class <code>mboostLSS</code>) for models fitted with <code>method = "cyclic"</code>
and <code>method = "non-cyclic"</code>, respectively, with corresponding methods to
extract information. A <code>mboostLSS</code> model object is a named list 
with one list entry for each modelled distribution parameter. 
Special &quot;subclasses&quot; inheriting from <code>mboostLSS</code> exist for each of the 
model-types (with the same name as the function, e.g., <code>gamboostLSS</code>).
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>
<p>Mayr, A., Fenske, N., Hofner, B., Kneib, T. and Schmid, M. (2012):
Generalized additive models for location, scale and shape for
high-dimensional data - a flexible approach based on boosting. Journal
of the Royal Statistical Society, Series C (Applied Statistics) 61(3):
403-427.
</p>
<p>M. Schmid, S. Potapov, A. Pfahlberg, and T. Hothorn. Estimation and
regularization techniques for regression models with multidimensional
prediction functions. Statistics and Computing, 20(2):139-150, 2010.
</p>
<p>Rigby, R. A. and D. M. Stasinopoulos (2005). Generalized additive models
for location, scale and shape (with discussion). Journal of the Royal
Statistical Society, Series C (Applied Statistics), 54, 507-554.
</p>
<p>Buehlmann, P. and Hothorn, T. (2007), Boosting algorithms: Regularization,
prediction and model fitting. Statistical Science, 22(4), 477&ndash;505.
</p>
<p>Thomas, J., Mayr, A., Bischl, B., Schmid, M., Smith, A., and Hofner, B. (2018), 
Gradient boosting for distributional regression - faster tuning and improved 
variable selection via noncyclical updates. 
<em>Statistics and Computing</em>. 28: 673-687. 
<a href="https://doi.org/10.1007/s11222-017-9754-6">doi:10.1007/s11222-017-9754-6</a><br />
(Preliminary version: <a href="https://arxiv.org/abs/1611.10171">https://arxiv.org/abs/1611.10171</a>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Families">Families</a></code> for a documentation of available GAMLSS distributions.
</p>
<p>The underlying boosting functions <code><a href="mboost.html#topic+mboost">mboost</a></code>, <code><a href="mboost.html#topic+gamboost">gamboost</a></code>, <code><a href="mboost.html#topic+glmboost">glmboost</a></code>,
<code><a href="mboost.html#topic+blackboost">blackboost</a></code> are contained in the <span class="pkg">mboost</span> package.
</p>
<p>See for example <code><a href="#topic+risk">risk</a></code> or <code><a href="stats.html#topic+coef">coef</a></code> for methods
that can be used to extract information from <code><a href="#topic+mboostLSS">mboostLSS</a></code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Data generating process:
set.seed(1907)
x1 &lt;- rnorm(1000)
x2 &lt;- rnorm(1000)
x3 &lt;- rnorm(1000)
x4 &lt;- rnorm(1000)
x5 &lt;- rnorm(1000)
x6 &lt;- rnorm(1000)
mu    &lt;- exp(1.5 +1 * x1 +0.5 * x2 -0.5 * x3 -1 * x4)
sigma &lt;- exp(-0.4 * x3 -0.2 * x4 +0.2 * x5 +0.4 * x6)
y &lt;- numeric(1000)
for( i in 1:1000)
    y[i] &lt;- rnbinom(1, size = sigma[i], mu = mu[i])
dat &lt;- data.frame(x1, x2, x3, x4, x5, x6, y)

### linear model with y ~ . for both components: 400 boosting iterations
model &lt;- glmboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
                     control = boost_control(mstop = 400),
                     center = TRUE)
coef(model, off2int = TRUE)


### estimate model with different formulas for mu and sigma:
names(NBinomialLSS())      # names of the family

### Do not test the following code per default on CRAN as it takes some time to run:
# Note: Multiple formulas must be specified via a _named list_
#       where the names correspond to the names of the distribution parameters
#       in the family (see above)
model2 &lt;- glmboostLSS(formula = list(mu = y ~ x1 + x2 + x3 + x4,
                                    sigma = y ~ x3 + x4 + x5 + x6),
                     families = NBinomialLSS(), data = dat,
                     control = boost_control(mstop = 400, trace = TRUE),
                     center = TRUE)
coef(model2, off2int = TRUE)
### END (don't test automatically)



### Offset needs to be specified via the arguments of families object:
model &lt;- glmboostLSS(y ~ ., data = dat,
                     families = NBinomialLSS(mu = mean(mu),
                                             sigma = mean(sigma)),
                     control = boost_control(mstop = 10),
                     center = TRUE)
# Note: mu-offset = log(mean(mu)) and sigma-offset = log(mean(sigma))
#       as we use a log-link in both families
coef(model)
log(mean(mu))
log(mean(sigma))

### Do not test the following code per default on CRAN as it takes some time to run:
### use different mstop values for the two distribution parameters
### (two-dimensional early stopping)
### the number of iterations is passed to boost_control via a named list
model3 &lt;- glmboostLSS(formula = list(mu = y ~ x1 + x2 + x3 + x4,
                                    sigma = y ~ x3 + x4 + x5 + x6),
                     families = NBinomialLSS(), data = dat,
                     control = boost_control(mstop = list(mu = 400,
                                                          sigma = 300),
                                             trace  = TRUE),
                     center = TRUE)
coef(model3, off2int = TRUE)

### Alternatively we can change mstop of model2:
# here it is assumed that the first element in the vector corresponds to
# the first distribution parameter of model2 etc.
mstop(model2) &lt;- c(400, 300)
par(mfrow = c(1,2))
plot(model2, xlim = c(0, max(mstop(model2))))
## all.equal(coef(model2), coef(model3)) # same!
### END (don't test automatically)

</code></pre>

<hr>
<h2 id='methods'>
Methods for mboostLSS
</h2><span id='topic+print.mboostLSS'></span><span id='topic+summary.mboostLSS'></span><span id='topic+coef.mboostLSS'></span><span id='topic+coef.glmboostLSS'></span><span id='topic+risk'></span><span id='topic+risk.mboostLSS'></span><span id='topic+risk.nc_mboostLSS'></span><span id='topic++5B.mboostLSS'></span><span id='topic+mstop.mboostLSS'></span><span id='topic+mstop.oobag'></span><span id='topic+mstop.cvriskLSS'></span><span id='topic+selected'></span><span id='topic+selected.mboostLSS'></span><span id='topic+fitted.mboostLSS'></span><span id='topic+predict.mboostLSS'></span><span id='topic+predint'></span><span id='topic+PI'></span><span id='topic+plot.glmboostLSS'></span><span id='topic+plot.gamboostLSS'></span><span id='topic+plot.predint'></span><span id='topic+update.mboostLSS'></span><span id='topic+model.weights'></span><span id='topic+model.weights.default'></span><span id='topic+model.weights.mboostLSS'></span>

<h3>Description</h3>

<p>Methods for GAMLSS models fitted by boosting algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>### print model
## S3 method for class 'mboostLSS'
print(x, ...)

### summarize model
## S3 method for class 'mboostLSS'
summary(object, ...)

### extract coefficients
## S3 method for class 'glmboostLSS'
coef(object, which = NULL,
     aggregate = c("sum", "cumsum", "none"),
     off2int = FALSE, parameter = names(object), ...)
## S3 method for class 'mboostLSS'
coef(object, which = NULL,
     aggregate = c("sum", "cumsum", "none"),
     parameter = names(object), ...)

### plot partial effects
## S3 method for class 'glmboostLSS'
plot(x, main = names(x), parameter = names(x),
     off2int = FALSE, ...)
## S3 method for class 'gamboostLSS'
plot(x, main = names(x), parameter = names(x), ...)

### extract and plot marginal prediction intervals
predint(x, which, pi = 0.9, newdata = NULL, ...)
PI(x, which, pi = 0.9, newdata = NULL, ...)
## S3 method for class 'predint'
plot(x, main = "Marginal Prediction Interval(s)",
     xlab = NULL, ylab = NULL, lty = c("solid", "dashed"),
     lcol = c("black", "black"), log = "", ...)

### extract mstop
## S3 method for class 'mboostLSS'
mstop(object, parameter = names(object), ...)
## S3 method for class 'oobag'
mstop(object, parameter = names(object), ...)
## S3 method for class 'cvriskLSS'
mstop(object, parameter = NULL, ...)

### set mstop
## S3 method for class 'mboostLSS'
x[i, return = TRUE, ...]

### extract risk
## S3 method for class 'mboostLSS'
risk(object, merge = FALSE, parameter = names(object), ...)

### extract selected base-learners
## S3 method for class 'mboostLSS'
selected(object, merge = FALSE, parameter = names(object), ...)

### extract fitted values
## S3 method for class 'mboostLSS'
fitted(object, parameter = names(object), ...)

### make predictions
## S3 method for class 'mboostLSS'
predict(object, newdata = NULL,
        type = c("link", "response", "class"), which = NULL,
        aggregate = c("sum", "cumsum", "none"),
        parameter = names(object), ...)

### update weights of the fitted model
## S3 method for class 'mboostLSS'
update(object, weights, oobweights = NULL,
       risk = NULL, trace = NULL, mstop = NULL, ...)

### extract model weights
## S3 method for class 'mboostLSS'
model.weights(x, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="methods_+3A_x">x</code>, <code id="methods_+3A_object">object</code></td>
<td>
<p> an object of the appropriate class (see usage). </p>
</td></tr>
<tr><td><code id="methods_+3A_which">which</code></td>
<td>
<p> a subset of base-learners to take into account when computing
predictions or coefficients. If <code>which</code> is given
(as an integer vector or characters corresponding
to base-learners), a list or matrix is returned. In <code>plot_PI</code>
the argument <code>which</code> must be specified and it must be given as
a character string containing the name of the variable.</p>
</td></tr>
<tr><td><code id="methods_+3A_aggregate">aggregate</code></td>
<td>
<p> a character specifying how to aggregate predictions
or coefficients of single base-learners. The default
returns the prediction or coefficient for the final number of
boosting iterations. <code>"cumsum"</code> returns a
matrix with the predictions for all iterations
simultaneously (in columns). <code>"none"</code> returns a
list with matrices where the <code class="reqn">j</code>th columns of the
respective matrix contains the predictions
of the base-learner of the <code class="reqn">j</code>th boosting
iteration (and zero if the base-learner is not
selected in this iteration).</p>
</td></tr>
<tr><td><code id="methods_+3A_parameter">parameter</code></td>
<td>
<p> This can be either a vector of indices or a vector
of parameter names which should be processed. See expamles for
details. Per default all distribution parameters of the GAMLSS family are
returned. </p>
</td></tr>
<tr><td><code id="methods_+3A_off2int">off2int</code></td>
<td>
<p> logical indicating whether the offset should be
added to the intercept (if there is any) or if the offset is
neglected for plotting (default).</p>
</td></tr>
<tr><td><code id="methods_+3A_merge">merge</code></td>
<td>
<p> logical. Should the risk vectors of the single
components be merged to one risk vector for the model in total? Per
default (<code>merge = FALSE</code>) a (named) list of risk vectors is
returned.</p>
</td></tr>
<tr><td><code id="methods_+3A_i">i</code></td>
<td>
<p> integer. Index specifying the model to extract. If <code>i</code>
is smaller than the initial <code>mstop</code>, a subset is used.
If <code>i</code> is larger than the initial <code>mstop</code>,
additional boosting steps are performed until step <code>i</code>
is reached. One can specify a scalar, a (possibly named) vector or a
(possibly named) list with separate values  for each component. See
the details section of <code><a href="#topic+mboostLSS">mboostLSS</a></code> for more information.</p>
</td></tr>
<tr><td><code id="methods_+3A_return">return</code></td>
<td>
<p> a logical indicating whether the changed object is
returned. </p>
</td></tr>
<tr><td><code id="methods_+3A_main">main</code></td>
<td>
<p> a title for the plots.</p>
</td></tr>
<tr><td><code id="methods_+3A_xlab">xlab</code>, <code id="methods_+3A_ylab">ylab</code></td>
<td>
<p> x- and y axis labels for the plots.</p>
</td></tr>
<tr><td><code id="methods_+3A_pi">pi</code></td>
<td>
<p> the level(s) of the prediction interval(s); Per default a
90% prediction interval is used.</p>
</td></tr>
<tr><td><code id="methods_+3A_lty">lty</code></td>
<td>
<p> (vector) of line types to be used for plotting the
prediction intervals. The vector should contain <code>length(pi) +
    1</code> elements. If less elements are specified, the last element is
recycled. The first value <code>lty[1]</code> is used for the marginal
median, the second value <code>lty[2]</code> is used for the <code>pi[1]</code>
prediction interval, etc.</p>
</td></tr>
<tr><td><code id="methods_+3A_lcol">lcol</code></td>
<td>
<p> (vector) of (line) colors to be used for plotting the
prediction intervals. The vector should contain <code>length(pi) +
    1</code> elements. If less elements are specified, the last element is
recycled. The first value <code>lcol[1]</code> is used for the marginal
median, the second value <code>lcol[2]</code> is used for the <code>pi[1]</code>
prediction interval, etc.</p>
</td></tr>
<tr><td><code id="methods_+3A_log">log</code></td>
<td>
<p> a character string which determines if and if so which
axis should be logarithmic. See <code><a href="graphics.html#topic+plot.default">plot.default</a></code> for details.</p>
</td></tr>
<tr><td><code id="methods_+3A_newdata">newdata</code></td>
<td>
<p> optional; A data frame in which to look for variables with
which to predict or with which to plot the marginal prediction intervals.</p>
</td></tr>
<tr><td><code id="methods_+3A_type">type</code></td>
<td>
<p> the type of prediction required.  The default is on the scale
of the predictors; the alternative <code>"response"</code> is on
the scale of the response variable.  Thus for a
binomial model the default predictions are on the log-odds scale
(probabilities on logit scale) and <code>type = "response"</code> gives
the predicted probabilities.  The <code>"class"</code> option returns
predicted classes.</p>
</td></tr>
<tr><td><code id="methods_+3A_weights">weights</code></td>
<td>

<p>a numeric vector of weights for the model
</p>
</td></tr>
<tr><td><code id="methods_+3A_oobweights">oobweights</code></td>
<td>

<p>an additional vector of out-of-bag weights (used internally
by <code><a href="#topic+cvrisk">cvrisk</a></code>. For details see there.).
</p>
</td></tr>
<tr><td><code id="methods_+3A_risk">risk</code></td>
<td>

<p>a character indicating how the empirical risk should be
computed for each boosting iteration. Per default <code>risk</code> is set
to the risk type specified for model fitting via
<code><a href="mboost.html#topic+boost_control">boost_control</a></code>. For details and alternatives see there.
</p>
</td></tr>
<tr><td><code id="methods_+3A_trace">trace</code></td>
<td>

<p>a logical triggering printout of status information during the
fitting process.
</p>
</td></tr>
<tr><td><code id="methods_+3A_mstop">mstop</code></td>
<td>

<p>number of boosting iterations.
</p>
</td></tr>
<tr><td><code id="methods_+3A_...">...</code></td>
<td>

<p>Further arguments to the functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions can be used to extract details from fitted models. For
a tutorial with worked examples see Hofner et al. (2016).
</p>
<p><code>print</code> shows a dense representation of the model fit.
</p>
<p>The function <code>coef</code> extracts the regression coefficients of
linear predictors fitted using the <code><a href="#topic+glmboostLSS">glmboostLSS</a></code> function or
additive predictors fitted using <code><a href="#topic+gamboostLSS">gamboostLSS</a></code>. Per default,
only coefficients of selected base-learners are returned for all
distribution parameters. However, any desired coefficient can be
extracted using the <code>which</code> argument. Furhtermore, one can
extract only coefficients for a single distribution parameter via the
<code>parameter</code> argument (see examples for details).
</p>
<p>Analogical, the function <code>plot</code> per default displays the
coefficient paths for the complete GAMLSS but can be restricted to
single distribution parameters or covariates (or subsets) using the
<code>parameter</code> or <code>which</code> arguments, respectively.
</p>
<p>The function <code>predint</code> (or <code>PI</code> which is just an alias)
computes marginal prediction intervals and returns a data frame with
the predictors used for the marginal prediction interval, the computed
median prediction and the marginal prediction intervals. A plot
function (<code>plot.predint</code>) for the resulting object exists. Note
that marginal predictions from AFT models (i.e., families
<code><a href="#topic+LogLogLSS">LogLogLSS</a></code>, <code><a href="#topic+LogNormalLSS">LogNormalLSS</a></code>, and
<code><a href="#topic+WeibullLSS">WeibullLSS</a></code>) represent the predicted &ldquo;true&rdquo;
survival time and not the observed survival time which is possible
subject to censoring. Hence, comparing observed survival times with
the marginal prediction interval is only sensible for uncensored
observations.
</p>
<p>The <code>predict</code> function can be used for predictions for the
distribution parameters depending on new observations whereas
<code>fitted</code> extracts the regression fits for the observations in the
learning sample. For <code>predict</code>, <code>newdata</code> can be specified
&ndash; otherwise the fitted values are returned. If <code>which</code> is
specified, marginal effects of the corresponding base-learner(s) are
returned. The argument <code>type</code> can be used to make predictions on
the scale of the link (i.e., the linear predictor X * beta), the
<code>response</code> (i.e. h(X * beta), where h is the response function)
or the <code>class</code> (in case of classification).
</p>
<p>The function <code>update</code> updates models fit with <span class="pkg">gamboostLSS</span>
and is primarily used within <code><a href="#topic+cvrisk">cvrisk</a></code>. It
updates the weights and refits the model to the altered data.
Furthermore, the type of <code>risk</code>, the <code>trace</code> and the number
of boosting iterations <code>mstop</code> can be modified.
</p>
<p>The function <code>model.weights</code> is a generic version of the same
function provided by package <span class="pkg">stats</span>, which is required to make
<code>model.weights</code> work with <code>mboostLSS</code> models.
</p>


<h3>Warning</h3>

<p>The <code>[.mboostLSS</code> function changes the original object, i.e.,
<code>LSSmodel[10]</code> changes <code>LSSmodel</code> directly!
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>
<p>Mayr, A., Fenske, N., Hofner, B., Kneib, T. and Schmid, M. (2012):
Generalized additive models for location, scale and shape for
high-dimensional data - a flexible approach based on boosting. Journal
of the Royal Statistical Society, Series C (Applied Statistics) 61(3):
403-427.
</p>
<p>Buehlmann, P. and Hothorn, T. (2007), Boosting algorithms:
regularization, prediction and model fitting. Statistical Science,
22(4), 477&ndash;505.
</p>
<p>Rigby, R. A. and D. M. Stasinopoulos (2005). Generalized additive models
for location, scale and shape (with discussion). Journal of the Royal
Statistical Society, Series C (Applied Statistics), 54, 507-554.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmboostLSS">glmboostLSS</a></code>, <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> and
<code><a href="#topic+blackboostLSS">blackboostLSS</a></code> for fitting of GAMLSS.
</p>
<p>Available distributions (families) are documented here:
<code><a href="#topic+Families">Families</a></code>.
</p>
<p>See <code><a href="mboost.html#topic+methods">methods</a></code> in the <code>mboost</code> package for the
corresponding methods for <code><a href="mboost.html#topic+mboost">mboost</a></code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### generate data
set.seed(1907)
x1 &lt;- rnorm(1000)
x2 &lt;- rnorm(1000)
x3 &lt;- rnorm(1000)
x4 &lt;- rnorm(1000)
x5 &lt;- rnorm(1000)
x6 &lt;- rnorm(1000)
mu    &lt;- exp(1.5 + x1^2 +0.5 * x2 - 3 * sin(x3) -1 * x4)
sigma &lt;- exp(-0.2 * x4 +0.2 * x5 +0.4 * x6)
y &lt;- numeric(1000)
for( i in 1:1000)
    y[i] &lt;- rnbinom(1, size = sigma[i], mu = mu[i])
dat &lt;- data.frame(x1, x2, x3, x4, x5, x6, y)

### fit a model
model &lt;- gamboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
                     control = boost_control(mstop = 100))

### Do not test the following line per default on CRAN as it takes some time to run:
### use a model with more iterations for a better fit
mstop(model) &lt;- 400

### extract coefficients
coef(model)

### only for distribution parameter mu
coef(model, parameter = "mu")

### only for covariate x1
coef(model, which = "x1")


### plot complete model
par(mfrow = c(4, 3))
plot(model)
### plot first parameter only
par(mfrow = c(2, 3))
plot(model, parameter = "mu")
### now plot only effect of x3 of both parameters
par(mfrow = c(1, 2))
plot(model, which = "x3")
### first component second parameter (sigma)
par(mfrow = c(1, 1))
plot(model, which = 1, parameter = 2)

### Do not test the following code per default on CRAN as it takes some time to run:
### plot marginal prediction interval
pi &lt;- predint(model, pi = 0.9, which = "x1")
pi &lt;- predint(model, pi = c(0.8, 0.9), which = "x1")
plot(pi, log = "y")  # warning as some y values are below 0
## here it would be better to plot x1 against
## sqrt(y) and sqrt(pi)

### set model to mstop = 300 (one-dimensional)
mstop(model) &lt;- 300
### END (don't test automatically)


par(mfrow = c(2, 2))
plot(risk(model, parameter = "mu")[[1]])
plot(risk(model, parameter = "sigma")[[1]])

### Do not test the following code per default on CRAN as it takes some time to run:
### get back to orignal fit
mstop(model) &lt;- 400
plot(risk(model, parameter = "mu")[[1]])
plot(risk(model, parameter = "sigma")[[1]])

### use different mstop values for the components
mstop(model) &lt;- c(100, 200)
## same as
  mstop(model) &lt;- c(mu = 100, sigma = 200)
## or
  mstop(model) &lt;- list(mu = 100, sigma = 200)
## or
  mstop(model) &lt;- list(100, 200)

plot(risk(model, parameter = "mu")[[1]])
plot(risk(model, parameter = "sigma")[[1]])
### END (don't test automatically)

</code></pre>

<hr>
<h2 id='stabsel'>
Stability Selection
</h2><span id='topic+stabsel.mboostLSS'></span><span id='topic+selected.stabsel_mboostLSS'></span>

<h3>Description</h3>

<p>Selection of influential variables or model components with error control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## a method to compute stability selection paths for fitted mboostLSS models
## S3 method for class 'mboostLSS'
stabsel(x, cutoff, q, PFER, mstop = NULL,
        folds = subsample(model.weights(x), B = B),
        B = ifelse(sampling.type == "MB", 100, 50),
        assumption = c("unimodal", "r-concave", "none"),
        sampling.type = c("SS", "MB"),
        papply = mclapply, verbose = TRUE, FWER, eval = TRUE, ...)
## a method to get the selected parameters
## S3 method for class 'stabsel_mboostLSS'
selected(object, parameter = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stabsel_+3A_x">x</code></td>
<td>
<p>an fitted model of class <code>"mboostLSS"</code> or <code>"nc_mboostLSS"</code>.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_cutoff">cutoff</code></td>
<td>
<p>cutoff between 0.5 and 1. Preferably a value between 0.6
and 0.9 should be used.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_q">q</code></td>
<td>
<p>number of (unique) selected variables (or groups of variables
depending on the model) that are selected on each subsample.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_pfer">PFER</code></td>
<td>
<p>upper bound for the per-family error rate. This
specifies the amount of falsely selected base-learners, which is
tolerated. See details.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_mstop">mstop</code></td>
<td>
<p>mstop value to use, if no value is supplied the mstop value of the fitted model is used.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_folds">folds</code></td>
<td>
<p> a weight matrix with number of rows equal to the number
of observations, see <code><a href="#topic+cvrisk">cvrisk</a></code> and
<code><a href="stabs.html#topic+subsample">subsample</a></code>. Usually one should not
change the default here as subsampling with a fraction of <code class="reqn">1/2</code>
is needed for the error bounds to hold. One usage scenario where
specifying the folds by hand might be the case when one has
dependent data (e.g. clusters) and thus wants to draw clusters
(i.e., multiple rows together) not individuals.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_assumption">assumption</code></td>
<td>
<p> Defines the type of assumptions on the
distributions of the selection probabilities and simultaneous
selection probabilities. Only applicable for
<code>sampling.type = "SS"</code>. For <code>sampling.type = "MB"</code> we
always use <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_sampling.type">sampling.type</code></td>
<td>
<p> use sampling scheme of of Shah &amp; Samworth
(2013), i.e., with complementarty pairs (<code>sampling.type = "SS"</code>),
or the original sampling scheme of Meinshausen &amp; Buehlmann (2010).</p>
</td></tr>
<tr><td><code id="stabsel_+3A_b">B</code></td>
<td>
<p> number of subsampling replicates. Per default, we use 50
complementary pairs for the error bounds of Shah &amp; Samworth (2013)
and 100 for the error bound derived in  Meinshausen &amp; Buehlmann
(2010). As we use <code class="reqn">B</code> complementray pairs in the former case
this leads to <code class="reqn">2B</code> subsamples.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_papply">papply</code></td>
<td>
<p> (parallel) apply function, defaults to
<code><a href="parallel.html#topic+mclapply">mclapply</a></code>. Alternatively, <code>parLapply</code>
can be used. In the latter case, usually more setup is needed (see
example of <code><a href="#topic+cvrisk">cvrisk</a></code> for some details).</p>
</td></tr>
<tr><td><code id="stabsel_+3A_verbose">verbose</code></td>
<td>
<p> logical (default: <code>TRUE</code>) that determines wether
<code>warnings</code> should be issued. </p>
</td></tr>
<tr><td><code id="stabsel_+3A_fwer">FWER</code></td>
<td>
<p> deprecated. Only for compatibility with older versions,
use PFER instead.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_eval">eval</code></td>
<td>
<p> logical. Determines whether stability selection is
evaluated (<code>eval = TRUE</code>; default) or if only the parameter
combination is returned.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_object">object</code></td>
<td>
<p> a object of class <code>"stabsel_mboostLSS"</code>.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_parameter">parameter</code></td>
<td>
<p> select one or multiple effects.</p>
</td></tr>
<tr><td><code id="stabsel_+3A_...">...</code></td>
<td>
<p> additional arguments to parallel apply methods such as
<code><a href="parallel.html#topic+mclapply">mclapply</a></code> and to <code><a href="#topic+cvrisk">cvrisk</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stability selection is to be preferably used with non-cyclic <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> 
models, as proposed by Thomas et al. (2018). In this publication, the combination 
of package <span class="pkg">gamboostLSS</span> with stability selection was devoloped and is 
investigated in depth. 
</p>
<p>For details on stability selection see <code><a href="stabs.html#topic+stabsel">stabsel</a></code> in package 
<span class="pkg">stabs</span> and Hofner et al. (2014).
</p>


<h3>Value</h3>

<p>An object of class <code>stabsel</code> with a special <code>print</code> method.
The object has the following elements:
</p>
<table role = "presentation">
<tr><td><code>phat</code></td>
<td>
<p>selection probabilities.</p>
</td></tr>
<tr><td><code>selected</code></td>
<td>
<p>elements with maximal selection probability greater
<code>cutoff</code>.</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>maximum of selection probabilities.</p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>cutoff used.</p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>average number of selected variables used.</p>
</td></tr>
<tr><td><code>PFER</code></td>
<td>
<p>per-family error rate.</p>
</td></tr>
<tr><td><code>sampling.type</code></td>
<td>
<p>the sampling type used for stability selection.</p>
</td></tr>
<tr><td><code>assumption</code></td>
<td>
<p>the assumptions made on the selection
probabilities.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>B. Hofner, L. Boccuto and M. Goeker (2015),
Controlling false discoveries in high-dimensional situations: Boosting
with stability selection. <em>BMC Bioinformatics</em>, <b>16:144</b>.
</p>
<p>N. Meinshausen and P. Buehlmann (2010), Stability selection.
<em>Journal of the Royal Statistical Society, Series B</em>,
<b>72</b>, 417&ndash;473.
</p>
<p>R.D. Shah and R.J. Samworth (2013), Variable selection with error
control: another look at stability selection. <em>Journal of the Royal
Statistical Society, Series B</em>, <b>75</b>, 55&ndash;80.
</p>
<p>Thomas, J., Mayr, A., Bischl, B., Schmid, M., Smith, A., and Hofner, B. (2018), 
Gradient boosting for distributional regression - faster tuning and improved 
variable selection via noncyclical updates. 
<em>Statistics and Computing</em>. 28: 673-687. 
<a href="https://doi.org/10.1007/s11222-017-9754-6">doi:10.1007/s11222-017-9754-6</a><br />
(Preliminary version: <a href="https://arxiv.org/abs/1611.10171">https://arxiv.org/abs/1611.10171</a>).
</p>


<h3>See Also</h3>

<p><code><a href="stabs.html#topic+stabsel">stabsel</a></code> and
<code><a href="stabs.html#topic+stabsel_parameters">stabsel_parameters</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Data generating process:
set.seed(1907)
x1 &lt;- rnorm(500)
x2 &lt;- rnorm(500)
x3 &lt;- rnorm(500)
x4 &lt;- rnorm(500)
x5 &lt;- rnorm(500)
x6 &lt;- rnorm(500)
mu    &lt;- exp(1.5 +1 * x1 +0.5 * x2 -0.5 * x3 -1 * x4)
sigma &lt;- exp(-0.4 * x3 -0.2 * x4 +0.2 * x5 +0.4 * x6)
y &lt;- numeric(500)
for( i in 1:500)
    y[i] &lt;- rnbinom(1, size = sigma[i], mu = mu[i])
dat &lt;- data.frame(x1, x2, x3, x4, x5, x6, y)

### linear model with y ~ . for both components: 400 boosting iterations
model &lt;- glmboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
                     control = boost_control(mstop = 400),
                     center = TRUE, method = "noncyclic")

### Do not test the following code per default on CRAN as it takes some time to run:

#run stability selection 
(s &lt;- stabsel(model, q = 5, PFER = 1))
#get selected effects
selected(s)

#visualize selection frequencies 
plot(s)

### END (don't test automatically)

</code></pre>

<hr>
<h2 id='weighted.median'>
Weighted Median
</h2><span id='topic+weighted.median'></span>

<h3>Description</h3>

<p>Function to compute the weighted median.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted.median(x, w = 1, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weighted.median_+3A_x">x</code></td>
<td>

<p>a numeric vector containing the values whose median is to be
computed.
</p>
</td></tr>
<tr><td><code id="weighted.median_+3A_w">w</code></td>
<td>

<p>weights that are used to compute the median. This can be either a
single value (which will be used as weight for all observations)
or a numeric vector of the same length as <code>x</code>.
</p>
</td></tr>
<tr><td><code id="weighted.median_+3A_na.rm">na.rm</code></td>
<td>

<p>logical. Should <code>NA</code>s (from weights <code>w</code> and/or data
<code>x</code>) be removed?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weighted median is computed as the value where the cumulative
relative weights (relative to the sum of all weights) crosses 0.5.
</p>
<p>This function is used in the stabilization of the negative gradient
via the meadian absolute deviation (MAD). For details see Hofner et al
(2015).
</p>


<h3>References</h3>

<p>B. Hofner, A. Mayr, M. Schmid (2016). gamboostLSS: An R Package for
Model Building and Variable Selection in the GAMLSS Framework.
Journal of Statistical Software, 74(1), 1-31.
</p>
<p>Available as <code>vignette("gamboostLSS_Tutorial")</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmboostLSS">glmboostLSS</a></code>, <code><a href="#topic+gamboostLSS">gamboostLSS</a></code> and
<code><a href="#topic+blackboostLSS">blackboostLSS</a></code> for fitting of GAMLSS where the
standardization is explained in more detail.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## compute the weighted median with case weights
x &lt;- c(1, 2, 3, 4)
w &lt;- c(0, 1, 2, 3)
weighted.median(x, w)

## compute the weighted median with arbitrary weights
x &lt;- rnorm(100)
w &lt;- runif(100)
weighted.median(x, w)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
