<!DOCTYPE html><html lang="en"><head><title>Help for package modsem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {modsem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#modsem-package'><p>modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)</p></a></li>
<li><a href='#coef_modsem_da'><p>Wrapper for coef</p></a></li>
<li><a href='#compare_fit'><p>compare model fit for qml and lms models</p></a></li>
<li><a href='#default_settings_da'><p>default arguments fro LMS and QML approach</p></a></li>
<li><a href='#default_settings_pi'><p>default arguments for product indicator approaches</p></a></li>
<li><a href='#extract_lavaan'><p>extract lavaan object from modsem object estimated using product indicators</p></a></li>
<li><a href='#fit_modsem_da'><p>Fit measures for QML and LMS models</p></a></li>
<li><a href='#get_pi_data'><p>Get data with product indicators for different approaches</p></a></li>
<li><a href='#get_pi_syntax'><p>Get <code>lavaan</code> syntax for product indicator approaches</p></a></li>
<li><a href='#jordan'><p>Jordan subset of PISA 2006 data</p></a></li>
<li><a href='#modsem'><p>Estimate interaction effects in structural equation models (SEMs)</p></a></li>
<li><a href='#modsem_da'><p>Interaction between latent variables using lms and qml approaches</p></a></li>
<li><a href='#modsem_inspect'><p>Inspect model information</p></a></li>
<li><a href='#modsem_mplus'><p>Estimation latent interactions through mplus</p></a></li>
<li><a href='#modsem_pi'><p>Interaction between latent variables using product indicators</p></a></li>
<li><a href='#modsemify'><p>Generate parameter table for <code>lavaan</code> syntax</p></a></li>
<li><a href='#multiplyIndicatorsCpp'><p>Multiply indicators</p></a></li>
<li><a href='#oneInt'><p>oneInt</p></a></li>
<li><a href='#parameter_estimates'><p>Extract parameterEstimates from an estimated model</p></a></li>
<li><a href='#plot_interaction'><p>Plot Interaction Effects in a SEM Model</p></a></li>
<li><a href='#plot_jn'><p>Plot Interaction Effect Using the Johnson-Neyman Technique</p></a></li>
<li><a href='#plot_surface'><p>Plot Surface for Interaction Effects</p></a></li>
<li><a href='#simple_slopes'><p>Get the simple slopes of a SEM model</p></a></li>
<li><a href='#standardized_estimates'><p>Get standardized estimates</p></a></li>
<li><a href='#summary.modsem_da'><p>summary for modsem objects</p></a></li>
<li><a href='#TPB'><p>TPB</p></a></li>
<li><a href='#TPB_1SO'><p>TPB_1SO</p></a></li>
<li><a href='#TPB_2SO'><p>TPB_2SO</p></a></li>
<li><a href='#TPB_UK'><p>TPB_UK</p></a></li>
<li><a href='#trace_path'><p>Estimate formulas for (co-)variance paths using Wright's path tracing rules</p></a></li>
<li><a href='#var_interactions'><p>Extract or modify parTable from an estimated model with estimated variances of interaction terms</p></a></li>
<li><a href='#vcov_modsem_da'><p>Wrapper for vcov</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Latent Interaction (and Moderation) Analysis in Structural
Equation Models (SEM)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.6</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kjell Solem Slupphaug &lt;slupphaugkjell@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Estimation of interaction (i.e., moderation) effects between latent variables
    in structural equation models (SEM). 
    The supported methods are:
      The constrained approach (Algina &amp; Moulder, 2001).
      The unconstrained approach (Marsh et al., 2004).
      The residual centering approach (Little et al., 2006).
      The double centering approach (Lin et al., 2010).
      The latent moderated structural equations (LMS) approach (Klein &amp; Moosbrugger, 2000).
      The quasi-maximum likelihood (QML) approach (Klein &amp; Muthén, 2007) (temporarily unavailable)
    The constrained- unconstrained, residual- and double centering- approaches
    are estimated via 'lavaan' (Rosseel, 2012), whilst the LMS- and QML- approaches
    are estimated via 'modsem' it self. Alternatively model can be
    estimated via 'Mplus' (Muthén &amp; Muthén, 1998-2017).
    References:
    Algina, J., &amp; Moulder, B. C. (2001). 
      &lt;<a href="https://doi.org/10.1207%2FS15328007SEM0801_3">doi:10.1207/S15328007SEM0801_3</a>&gt;.
      "A note on estimating the Jöreskog-Yang model for latent variable interaction using 'LISREL' 8.3."
    Klein, A., &amp; Moosbrugger, H. (2000). 
      &lt;<a href="https://doi.org/10.1007%2FBF02296338">doi:10.1007/BF02296338</a>&gt;.
      "Maximum likelihood estimation of latent interaction effects with the LMS method."
    Klein, A. G., &amp; Muthén, B. O. (2007). 
      &lt;<a href="https://doi.org/10.1080%2F00273170701710205">doi:10.1080/00273170701710205</a>&gt;.
      "Quasi-maximum likelihood estimation of structural equation models with multiple interaction and quadratic effects."
    Lin, G. C., Wen, Z., Marsh, H. W., &amp; Lin, H. S. (2010). 
      &lt;<a href="https://doi.org/10.1080%2F10705511.2010.488999">doi:10.1080/10705511.2010.488999</a>&gt;.
      "Structural equation models of latent interactions: Clarification of orthogonalizing and double-mean-centering strategies."
    Little, T. D., Bovaird, J. A., &amp; Widaman, K. F. (2006). 
      &lt;<a href="https://doi.org/10.1207%2Fs15328007sem1304_1">doi:10.1207/s15328007sem1304_1</a>&gt;.
      "On the merits of orthogonalizing powered and product terms: Implications for modeling interactions among latent variables."
    Marsh, H. W., Wen, Z., &amp; Hau, K. T. (2004). 
      &lt;<a href="https://doi.org/10.1037%2F1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>&gt;.
      "Structural equation models of latent interactions: evaluation of alternative estimation strategies and indicator construction."
    Muthén, L.K. and Muthén, B.O. (1998-2017).  
      "'Mplus' User’s Guide. Eighth Edition."
      <a href="https://www.statmodel.com/">https://www.statmodel.com/</a>.
    Rosseel Y (2012). 
      &lt;<a href="https://doi.org/10.18637%2Fjss.v048.i02">doi:10.18637/jss.v048.i02</a>&gt;.
      "'lavaan': An R Package for Structural Equation Modeling." </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, purrr, stringr, lavaan, rlang, MplusAutomation, nlme,
dplyr, mvnfast, stats, fastGHQuad, mvtnorm, ggplot2, parallel,
plotly</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://modsem.org">https://modsem.org</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-20 14:19:22 UTC; kss</td>
</tr>
<tr>
<td>Author:</td>
<td>Kjell Solem Slupphaug
    <a href="https://orcid.org/0009-0005-8324-2834"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Mehmet Mehmetoglu <a href="https://orcid.org/0000-0002-6092-8551"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Matthias Mittner <a href="https://orcid.org/0000-0003-0205-7353"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-20 14:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='modsem-package'>modsem: Latent Interaction (and Moderation) Analysis in Structural Equation Models (SEM)</h2><span id='topic+modsem-package'></span>

<h3>Description</h3>

<p>Estimation of interaction (i.e., moderation) effects between latent variables in structural equation models (SEM). The supported methods are: The constrained approach (Algina &amp; Moulder, 2001). The unconstrained approach (Marsh et al., 2004). The residual centering approach (Little et al., 2006). The double centering approach (Lin et al., 2010). The latent moderated structural equations (LMS) approach (Klein &amp; Moosbrugger, 2000). The quasi-maximum likelihood (QML) approach (Klein &amp; Muthén, 2007) (temporarily unavailable) The constrained- unconstrained, residual- and double centering- approaches are estimated via 'lavaan' (Rosseel, 2012), whilst the LMS- and QML- approaches are estimated via 'modsem' it self. Alternatively model can be estimated via 'Mplus' (Muthén &amp; Muthén, 1998-2017). References: Algina, J., &amp; Moulder, B. C. (2001). <a href="https://doi.org/10.1207/S15328007SEM0801_3">doi:10.1207/S15328007SEM0801_3</a>. &quot;A note on estimating the Jöreskog-Yang model for latent variable interaction using 'LISREL' 8.3.&quot; Klein, A., &amp; Moosbrugger, H. (2000). <a href="https://doi.org/10.1007/BF02296338">doi:10.1007/BF02296338</a>. &quot;Maximum likelihood estimation of latent interaction effects with the LMS method.&quot; Klein, A. G., &amp; Muthén, B. O. (2007). <a href="https://doi.org/10.1080/00273170701710205">doi:10.1080/00273170701710205</a>. &quot;Quasi-maximum likelihood estimation of structural equation models with multiple interaction and quadratic effects.&quot; Lin, G. C., Wen, Z., Marsh, H. W., &amp; Lin, H. S. (2010). <a href="https://doi.org/10.1080/10705511.2010.488999">doi:10.1080/10705511.2010.488999</a>. &quot;Structural equation models of latent interactions: Clarification of orthogonalizing and double-mean-centering strategies.&quot; Little, T. D., Bovaird, J. A., &amp; Widaman, K. F. (2006). <a href="https://doi.org/10.1207/s15328007sem1304_1">doi:10.1207/s15328007sem1304_1</a>. &quot;On the merits of orthogonalizing powered and product terms: Implications for modeling interactions among latent variables.&quot; Marsh, H. W., Wen, Z., &amp; Hau, K. T. (2004). <a href="https://doi.org/10.1037/1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>. &quot;Structural equation models of latent interactions: evaluation of alternative estimation strategies and indicator construction.&quot; Muthén, L.K. and Muthén, B.O. (1998-2017). &quot;'Mplus' User’s Guide. Eighth Edition.&quot; <a href="https://www.statmodel.com/">https://www.statmodel.com/</a>. Rosseel Y (2012). <a href="https://doi.org/10.18637/jss.v048.i02">doi:10.18637/jss.v048.i02</a>. &quot;'lavaan': An R Package for Structural Equation Modeling.&quot;
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Kjell Solem Slupphaug <a href="mailto:slupphaugkjell@gmail.com">slupphaugkjell@gmail.com</a> (<a href="https://orcid.org/0009-0005-8324-2834">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Mehmet Mehmetoglu <a href="mailto:mehmetm@ntnu.no">mehmetm@ntnu.no</a> (<a href="https://orcid.org/0000-0002-6092-8551">ORCID</a>) [contributor]
</p>
</li>
<li><p> Matthias Mittner <a href="mailto:matthias.mittner@uit.no">matthias.mittner@uit.no</a> (<a href="https://orcid.org/0000-0003-0205-7353">ORCID</a>) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://modsem.org">https://modsem.org</a>
</p>
</li></ul>


<hr>
<h2 id='coef_modsem_da'>Wrapper for coef</h2><span id='topic+coef_modsem_da'></span>

<h3>Description</h3>

<p>wrapper for coef, to be used with modsem::coef_modsem_da,
since coef is not in the namespace of modsem, but stats
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coef_modsem_da(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef_modsem_da_+3A_object">object</code></td>
<td>
<p>fittet model to inspect</p>
</td></tr>
<tr><td><code id="coef_modsem_da_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>

<hr>
<h2 id='compare_fit'>compare model fit for qml and lms models</h2><span id='topic+compare_fit'></span>

<h3>Description</h3>

<p>Compare the fit of two models using the likelihood ratio test.
'estH0' representing the null
hypothesis model, and 'estH1' the alternative hypothesis model. Importantly,
the function assumes that 'estH0' does not have more free parameters
(i.e., degrees of freedom) than 'estH1'.
alternative hypothesis model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_fit(estH0, estH1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_fit_+3A_esth0">estH0</code></td>
<td>
<p>object of class 'modsem_da' representing the
null hypothesis model</p>
</td></tr>
<tr><td><code id="compare_fit_+3A_esth1">estH1</code></td>
<td>
<p>object of class 'modsem_da' representing the</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
H0 &lt;- "
 # Outer Model
 X =~ x1 + x2 + x3
 Y =~ y1 + y2 + y3
 Z =~ z1 + z2 + z3

 # Inner model
 Y ~ X + Z
"

estH0 &lt;- modsem(m1, oneInt, "lms")

H1 &lt;- "
 # Outer Model
 X =~ x1 + x2 + x3
 Y =~ y1 + y2 + y3
 Z =~ z1 + z2 + z3

 # Inner model
 Y ~ X + Z + X:Z
"

estH1 &lt;- modsem(m1, oneInt, "lms")
compare_fit(estH0, estH1)

## End(Not run)
</code></pre>

<hr>
<h2 id='default_settings_da'>default arguments fro LMS and QML approach</h2><span id='topic+default_settings_da'></span>

<h3>Description</h3>

<p>This function returns the default settings for the LMS and QML approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default_settings_da(method = c("lms", "qml"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="default_settings_da_+3A_method">method</code></td>
<td>
<p>which method to get the settings for</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
default_settings_da()
</code></pre>

<hr>
<h2 id='default_settings_pi'>default arguments for product indicator approaches</h2><span id='topic+default_settings_pi'></span>

<h3>Description</h3>

<p>This function returns the default settings for the product indicator approaches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>default_settings_pi(method = c("rca", "uca", "pind", "dblcent", "ca"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="default_settings_pi_+3A_method">method</code></td>
<td>
<p>which method to get the settings for</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
default_settings_pi()
</code></pre>

<hr>
<h2 id='extract_lavaan'>extract lavaan object from modsem object estimated using product indicators</h2><span id='topic+extract_lavaan'></span>

<h3>Description</h3>

<p>extract lavaan object from modsem object estimated using product indicators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_lavaan(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_lavaan_+3A_object">object</code></td>
<td>
<p>modsem object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lavaan object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 + x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'
est &lt;- modsem_pi(m1, oneInt)
lav_est &lt;- extract_lavaan(est)
</code></pre>

<hr>
<h2 id='fit_modsem_da'>Fit measures for QML and LMS models</h2><span id='topic+fit_modsem_da'></span>

<h3>Description</h3>

<p>Calculates chi-sq test and p-value, as well as RMSEA for
the LMS and QML models. Note that the Chi-Square based fit measures should be calculated
for the baseline model, i.e., the model without the interaction effect
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_modsem_da(model, chisq = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_modsem_da_+3A_model">model</code></td>
<td>
<p>fitted model. Thereafter, you can use 'compare_fit()'
to assess the comparative fit of the models. If the interaction effect makes
the model better, and e.g., the RMSEA is good for the baseline model,
the interaction model likely has a good RMSEA as well.</p>
</td></tr>
<tr><td><code id="fit_modsem_da_+3A_chisq">chisq</code></td>
<td>
<p>should Chi-Square based fit-measures be calculated?</p>
</td></tr>
</table>

<hr>
<h2 id='get_pi_data'>Get data with product indicators for different approaches</h2><span id='topic+get_pi_data'></span>

<h3>Description</h3>

<p><code>get_pi_syntax()</code> is a function for creating the <code>lavaan</code> syntax used for estimating
latent interaction models using one of the product indicators in <code>lavaan</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pi_data(model.syntax, data, method = "dblcent", match = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pi_data_+3A_model.syntax">model.syntax</code></td>
<td>
<p><code>lavaan</code> syntax</p>
</td></tr>
<tr><td><code id="get_pi_data_+3A_data">data</code></td>
<td>
<p>data to create product indicators from</p>
</td></tr>
<tr><td><code id="get_pi_data_+3A_method">method</code></td>
<td>
<p>method to use:
<code>"rca"</code> = residual centering approach,
<code>"uca"</code> = unconstrained approach,
<code>"dblcent"</code> = double centering approach,
<code>"pind"</code> = prod ind approach, with no constraints or centering,
<code>"custom"</code> = use parameters specified in the function call</p>
</td></tr>
<tr><td><code id="get_pi_data_+3A_match">match</code></td>
<td>
<p>should the product indicators be created by using the match-strategy</p>
</td></tr>
<tr><td><code id="get_pi_data_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions (e.g., <a href="#topic+modsem_pi">modsem_pi</a>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
library(lavaan)
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 +x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'
syntax &lt;- get_pi_syntax(m1)
data &lt;- get_pi_data(m1, oneInt)
est &lt;- sem(syntax, data)
</code></pre>

<hr>
<h2 id='get_pi_syntax'>Get <code>lavaan</code> syntax for product indicator approaches</h2><span id='topic+get_pi_syntax'></span>

<h3>Description</h3>

<p><code>get_pi_syntax()</code> is a function for creating the <code>lavaan</code> syntax used for estimating
latent interaction models using one of the product indicators in <code>lavaan</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pi_syntax(model.syntax, method = "dblcent", match = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pi_syntax_+3A_model.syntax">model.syntax</code></td>
<td>
<p><code>lavaan</code> syntax</p>
</td></tr>
<tr><td><code id="get_pi_syntax_+3A_method">method</code></td>
<td>
<p>method to use:
<code>"rca"</code> = residual centering approach,
<code>"uca"</code> = unconstrained approach,
<code>"dblcent"</code> = double centering approach,
<code>"pind"</code> = prod ind approach, with no constraints or centering,
<code>"custom"</code> = use parameters specified in the function call</p>
</td></tr>
<tr><td><code id="get_pi_syntax_+3A_match">match</code></td>
<td>
<p>should the product indicators be created by using the match-strategy</p>
</td></tr>
<tr><td><code id="get_pi_syntax_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions (e.g., <a href="#topic+modsem_pi">modsem_pi</a>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>character</code> vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
library(lavaan)
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 + x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'
syntax &lt;- get_pi_syntax(m1)
data &lt;- get_pi_data(m1, oneInt)
est &lt;- sem(syntax, data)
</code></pre>

<hr>
<h2 id='jordan'>Jordan subset of PISA 2006 data</h2><span id='topic+jordan'></span>

<h3>Description</h3>

<p>The data stem from the large-scale assessment study PISA 2006
(Organisation for Economic Co-Operation and Development, 2009) where
competencies of 15-year-old students in reading, mathematics, and science
are assessed using nationally representative samples in 3-year cycles.
In this eacademicample, data from the student background questionnaire from the
Jordan sample of PISA 2006 were used. Only data of students with complete
responses to all 15 items (N = 6,038) were considered.
</p>


<h3>Format</h3>

<p>A data frame of fifteen variables and 6,038 observations:
</p>
<p>enjoy1
indicator for enjoyment of science, item ST16Q01: I generally have fun when I am learning &lt;broad science&gt; topics.
</p>
<p>enjoy2
indicator for enjoyment of science, item ST16Q02: I like reading about &lt;broad science&gt;.
</p>
<p>enjoy3
indicator for enjoyment of science, item ST16Q03: I am happy doing &lt;broad science&gt; problems.
</p>
<p>enjoy4
indicator for enjoyment of science, item ST16Q04: I enjoy acquiring new knowledge in &lt;broad science&gt;.
</p>
<p>enjoy5
indicator for enjoyment of science, item ST16Q05: I am interested in learning about &lt;broad science&gt;.
</p>
<p>academic1
indicator for academic self-concept in science, item ST37Q01: I can easily understand new ideas in &lt;school science&gt;.
</p>
<p>academic2
indicator for academic self-concept in science, item ST37Q02: Learning advanced &lt;school science&gt; topics would be easy for me.
</p>
<p>academic3
indicator for academic self-concept in science, item ST37Q03: I can usually give good answers to &lt;test questions&gt; on &lt;school science&gt; topics.
</p>
<p>academic4
indicator for academic self-concept in science, item ST37Q04: I learn &lt;school science&gt; topics quickly.
</p>
<p>academic5
indicator for academic self-concept in science, item ST37Q05: &lt;School science&gt; topics are easy for me.
</p>
<p>academic6
indicator for academic self-concept in science, item ST37Q06: When I am being taught &lt;school science&gt;, I can understand the concepts very well.
</p>
<p>career1
indicator for career aspirations in science, item ST29Q01: I would like to work in a career involving &lt;broad science&gt;.
</p>
<p>career2
indicator for career aspirations in science, item ST29Q02: I would like to study &lt;broad science&gt; after &lt;secondary school&gt;.
</p>
<p>career3
indicator for career aspirations in science, item ST29Q03: I would like to spend my life doing advanced &lt;broad science&gt;.
</p>
<p>career4
indicator for career aspirations in science, item ST29Q04: I would like to work on &lt;broad science&gt; projects as an adult.
</p>


<h3>Source</h3>

<p>This version of the dataset, as well as the description was gathered from the
documentation of the 'nlsem' package (https://cran.r-project.org/package=nlsem),
where the only difference is that the names of the variables were changed
</p>
<p>Originally the dataset was gathered by the Organisation for Economic Co-Operation and Development (2009).
Pisa 2006: Science competencies for tomorrow's world (Tech. Rep.).
Paris, France. Obtained from: https://www.oecd.org/pisa/pisaproducts/database-pisa2006.htm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
m1 &lt;- "
  ENJ =~ enjoy1 + enjoy2 + enjoy3 + enjoy4 + enjoy5
  CAREER =~ career1 + career2 + career3 + career4
  SC =~ academic1 + academic2 + academic3 + academic4 + academic5 + academic6
  CAREER ~ ENJ + SC + ENJ:ENJ + SC:SC + ENJ:SC
"

est &lt;- modsem(m1, data = jordan)

## End(Not run)
</code></pre>

<hr>
<h2 id='modsem'>Estimate interaction effects in structural equation models (SEMs)</h2><span id='topic+modsem'></span>

<h3>Description</h3>

<p><code>modsem()</code> is a function for estimating interaction effects between latent variables
in structural equation models (SEMs).
Methods for estimating interaction effects in SEMs can basically be split into
two frameworks:
1. Product Indicator-based approaches (<code>"dblcent"</code>, <code>"rca"</code>, <code>"uca"</code>,
<code>"ca"</code>, <code>"pind"</code>)
2. Distributionally based approaches (<code>"lms"</code>, <code>"qml"</code>).
</p>
<p>For the product indicator-based approaches, <code>modsem()</code> is essentially a fancy wrapper for <code>lavaan::sem()</code> which generates the
necessary syntax and variables for the estimation of models with latent product indicators.
</p>
<p>The distributionally based approaches are implemented separately and are
not estimated using <code>lavaan::sem()</code>, but rather using custom functions (largely
written in <code>C++</code> for performance reasons). For greater control, it is advised that
you use one of the sub-functions (<a href="#topic+modsem_pi">modsem_pi</a>, <a href="#topic+modsem_da">modsem_da</a>, <a href="#topic+modsem_mplus">modsem_mplus</a>) directly,
as passing additional arguments to them via <code>modsem()</code> can lead to unexpected behavior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modsem(model.syntax = NULL, data = NULL, method = "dblcent", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modsem_+3A_model.syntax">model.syntax</code></td>
<td>
<p><code>lavaan</code> syntax</p>
</td></tr>
<tr><td><code id="modsem_+3A_data">data</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="modsem_+3A_method">method</code></td>
<td>
<p>method to use:
<code>"rca"</code> = residual centering approach (passed to <code>lavaan</code>),
<code>"uca"</code> = unconstrained approach (passed to <code>lavaan</code>),
<code>"dblcent"</code> = double centering approach (passed to <code>lavaan</code>),
<code>"pind"</code> = prod ind approach, with no constraints or centering (passed to <code>lavaan</code>),
<code>"lms"</code> = latent model structural equations (not passed to <code>lavaan</code>),
<code>"qml"</code> = quasi maximum likelihood estimation of latent model structural equations (not passed to <code>lavaan</code>),
<code>"custom"</code> = use parameters specified in the function call (passed to <code>lavaan</code>).</p>
</td></tr>
<tr><td><code id="modsem_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions depending on the method (see <code><a href="#topic+modsem_pi">modsem_pi</a></code>, <code><a href="#topic+modsem_da">modsem_da</a></code>, and <code><a href="#topic+modsem_mplus">modsem_mplus</a></code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>modsem</code> object with class <code><a href="#topic+modsem_pi">modsem_pi</a></code>, <code><a href="#topic+modsem_da">modsem_da</a></code>, or <code><a href="#topic+modsem_mplus">modsem_mplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
# For more examples, check README and/or GitHub.
# One interaction
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 +x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'

# Double centering approach
est1 &lt;- modsem(m1, oneInt)
summary(est1)

## Not run: 
# The Constrained Approach
est1_ca &lt;- modsem(m1, oneInt, method = "ca")
summary(est1_ca)

# LMS approach
est1_lms &lt;- modsem(m1, oneInt, method = "lms", EFIM.S=1000)
summary(est1_lms)

# QML approach
est1_qml &lt;- modsem(m1, oneInt, method = "qml")
summary(est1_qml)

## End(Not run)

# Theory Of Planned Behavior
tpb &lt;- '
# Outer Model (Based on Hagger et al., 2007)
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model (Based on Steinmetz et al., 2011)
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC
  BEH ~ INT:PBC
'

# Double centering approach
est_tpb &lt;- modsem(tpb, data = TPB)
summary(est_tpb)

## Not run: 
# The Constrained Approach
est_tpb_ca &lt;- modsem(tpb, data = TPB, method = "ca")
summary(est_tpb_ca)

# LMS approach
est_tpb_lms &lt;- modsem(tpb, data = TPB, method = "lms")
summary(est_tpb_lms)

# QML approach
est_tpb_qml &lt;- modsem(tpb, data = TPB, method = "qml")
summary(est_tpb_qml)

## End(Not run)
</code></pre>

<hr>
<h2 id='modsem_da'>Interaction between latent variables using lms and qml approaches</h2><span id='topic+modsem_da'></span>

<h3>Description</h3>

<p><code>modsem_da()</code> is a function for estimating interaction effects between latent variables
in structural equation models (SEMs) using distributional analytic (DA) approaches.
Methods for estimating interaction effects in SEMs can basically be split into
two frameworks:
1. Product Indicator-based approaches (<code>"dblcent"</code>, <code>"rca"</code>, <code>"uca"</code>,
<code>"ca"</code>, <code>"pind"</code>)
2. Distributionally based approaches (<code>"lms"</code>, <code>"qml"</code>).
</p>
<p><code>modsem_da()</code> handles the latter and can estimate models using both QML and LMS,
necessary syntax, and variables for the estimation of models with latent product indicators.
</p>
<p><strong>NOTE</strong>: Run <code><a href="#topic+default_settings_da">default_settings_da</a></code> to see default arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modsem_da(
  model.syntax = NULL,
  data = NULL,
  method = "lms",
  verbose = NULL,
  optimize = NULL,
  nodes = NULL,
  convergence = NULL,
  optimizer = NULL,
  center.data = NULL,
  standardize.data = NULL,
  standardize.out = NULL,
  standardize = NULL,
  mean.observed = NULL,
  cov.syntax = NULL,
  double = NULL,
  calc.se = NULL,
  FIM = NULL,
  EFIM.S = NULL,
  OFIM.hessian = NULL,
  EFIM.parametric = NULL,
  robust.se = NULL,
  R.max = NULL,
  max.iter = NULL,
  max.step = NULL,
  fix.estep = NULL,
  start = NULL,
  epsilon = NULL,
  quad.range = NULL,
  n.threads = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modsem_da_+3A_model.syntax">model.syntax</code></td>
<td>
<p><code>lavaan</code> syntax</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_data">data</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_method">method</code></td>
<td>
<p>method to use:
<code>"lms"</code> = latent model structural equations (not passed to <code>lavaan</code>).
<code>"qml"</code> = quasi maximum likelihood estimation of latent model structural equations (not passed to <code>lavaan</code>).</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_verbose">verbose</code></td>
<td>
<p>should estimation progress be shown</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_optimize">optimize</code></td>
<td>
<p>should starting parameters be optimized</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_nodes">nodes</code></td>
<td>
<p>number of quadrature nodes (points of integration) used in <code>lms</code>,
increased number gives better estimates but slower computation. How many are needed depends on the complexity of the model.
For simple models, somewhere between 16-24 nodes should be enough; for more complex models, higher numbers may be needed.
For models where there is an interaction effect between an endogenous and exogenous variable,
the number of nodes should be at least 32, but practically (e.g., ordinal/skewed data), more than 32 is recommended. In cases
where data is non-normal, it might be better to use the <code>qml</code> approach instead. For large
numbers of nodes, you might want to change the <code>'quad.range'</code> argument.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_convergence">convergence</code></td>
<td>
<p>convergence criterion. Lower values give better estimates but slower computation.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_optimizer">optimizer</code></td>
<td>
<p>optimizer to use, can be either <code>"nlminb"</code> or <code>"L-BFGS-B"</code>. For LMS, <code>"nlminb"</code> is recommended.
For QML, <code>"L-BFGS-B"</code> may be faster if there is a large number of iterations, but slower if there are few iterations.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_center.data">center.data</code></td>
<td>
<p>should data be centered before fitting model</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_standardize.data">standardize.data</code></td>
<td>
<p>should data be scaled before fitting model, will be overridden by
<code>standardize</code> if <code>standardize</code> is set to <code>TRUE</code>.
</p>
<p><strong>NOTE</strong>: It is recommended that you estimate the model normally and then standardize the output using
<code><a href="#topic+standardized_estimates">standardized_estimates</a></code>.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_standardize.out">standardize.out</code></td>
<td>
<p>should output be standardized (note will alter the relationships of
parameter constraints since parameters are scaled unevenly, even if they
have the same label). This does not alter the estimation of the model, only the
output.
</p>
<p><strong>NOTE</strong>: It is recommended that you estimate the model normally and then standardize the output using
<code><a href="#topic+standardized_estimates">standardized_estimates</a></code>.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_standardize">standardize</code></td>
<td>
<p>will standardize the data before fitting the model, remove the mean
structure of the observed variables, and standardize the output. Note that <code>standardize.data</code>,
<code>mean.observed</code>, and <code>standardize.out</code> will be overridden by <code>standardize</code> if <code>standardize</code> is set to <code>TRUE</code>.
</p>
<p><strong>NOTE</strong>: It is recommended that you estimate the model normally and then standardize the output using
<code><a href="#topic+standardized_estimates">standardized_estimates</a></code>.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_mean.observed">mean.observed</code></td>
<td>
<p>should the mean structure of the observed variables be estimated?
This will be overridden by <code>standardize</code> if <code>standardize</code> is set to <code>TRUE</code>.
</p>
<p><strong>NOTE</strong>: Not recommended unless you know what you are doing.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_cov.syntax">cov.syntax</code></td>
<td>
<p>model syntax for implied covariance matrix (see <code>vignette("interaction_two_etas", "modsem")</code>)</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_double">double</code></td>
<td>
<p>try to double the number of dimensions of integration used in LMS,
this will be extremely slow but should be more similar to <code>mplus</code>.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_calc.se">calc.se</code></td>
<td>
<p>should standard errors be computed? <strong>NOTE</strong>: If <code>FALSE</code>, the information matrix will not be computed either.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_fim">FIM</code></td>
<td>
<p>should the Fisher information matrix be calculated using the observed or expected values? Must be either <code>"observed"</code> or <code>"expected"</code>.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_efim.s">EFIM.S</code></td>
<td>
<p>if the expected Fisher information matrix is computed, <code>EFIM.S</code> selects the number of Monte Carlo samples. Defaults to 100. 
<strong>NOTE</strong>: This number should likely be increased for better estimates (e.g., 1000-10000), but it might drasticly increase computation time.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_ofim.hessian">OFIM.hessian</code></td>
<td>
<p>should the observed Fisher information be computed using the Hessian? If <code>FALSE</code>, it is computed using the gradient.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_efim.parametric">EFIM.parametric</code></td>
<td>
<p>should data for calculating the expected Fisher information matrix be
simulated parametrically (simulated based on the assumptions and implied parameters
from the model), or non-parametrically (stochastically sampled)? If you believe that
normality assumptions are violated, <code>EFIM.parametric = FALSE</code> might be the better option.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_robust.se">robust.se</code></td>
<td>
<p>should robust standard errors be computed? Meant to be used for QML,
can be unreliable with the LMS approach.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_r.max">R.max</code></td>
<td>
<p>Maximum population size (not sample size) used in the calculated of the expected
fischer information matrix.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_max.step">max.step</code></td>
<td>
<p>maximum steps for the M-step in the EM algorithm (LMS).</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_fix.estep">fix.estep</code></td>
<td>
<p>if <code>TRUE</code>, the E-step will be fixed, and the prior probabilities will be set to the best prior probabilities,
if the log-likelihood decreases for more than 30 iterations.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_start">start</code></td>
<td>
<p>starting parameters.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_epsilon">epsilon</code></td>
<td>
<p>finite difference for numerical derivatives.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_quad.range">quad.range</code></td>
<td>
<p>range in z-scores to perform numerical integration in LMS using
Gaussian-Hermite Quadratures. By default <code>Inf</code>, such that <code>f(t)</code> is integrated from -Inf to Inf,
but this will likely be inefficient and pointless at a large number of nodes. Nodes outside
<code>+/- quad.range</code> will be ignored.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_n.threads">n.threads</code></td>
<td>
<p>number of cores to use for parallel processing. If <code>NULL</code>, it will use &lt;= 2 threads.
If an integer is specified, it will use that number of threads (e.g., <code>n.threads = 4</code> will use 4 threads).
If <code>"default"</code>, it will use the default number of threads (2).
If <code>"max"</code>, it will use all available threads, <code>"min"</code> will use 1 thread.</p>
</td></tr>
<tr><td><code id="modsem_da_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the estimation function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>modsem_da</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
# For more examples, check README and/or GitHub.
# One interaction
m1 &lt;- "
  # Outer Model
  X =~ x1 + x2 +x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
"

## Not run: 
# QML Approach
est1 &lt;- modsem_da(m1, oneInt, method = "qml")
summary(est1)

# Theory Of Planned Behavior
tpb &lt;- "
# Outer Model (Based on Hagger et al., 2007)
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model (Based on Steinmetz et al., 2011)
  # Covariances
  ATT ~~ SN + PBC
  PBC ~~ SN
  # Causal Relationships
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC
  BEH ~ INT:PBC
"

# LMS Approach
estTpb &lt;- modsem_da(tpb, data = TPB, method = lms, EFIM.S = 1000)
summary(estTpb)

## End(Not run)
</code></pre>

<hr>
<h2 id='modsem_inspect'>Inspect model information</h2><span id='topic+modsem_inspect'></span>

<h3>Description</h3>

<p>function used to inspect fittet object. similar to 'lavInspect()'
argument 'what' decides what to inspect
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modsem_inspect(object, what = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modsem_inspect_+3A_object">object</code></td>
<td>
<p>fittet model to inspect</p>
</td></tr>
<tr><td><code id="modsem_inspect_+3A_what">what</code></td>
<td>
<p>what to inspect</p>
</td></tr>
<tr><td><code id="modsem_inspect_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to other functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>for 'modsem_da', and 'modsem_lavaan'
for 'modsem_lavaan', it is just a wrapper for 'lavInspect()'
for 'modsem_da' and &ldquo; what can either be &quot;all&quot;, &quot;matrices&quot;, &quot;optim&quot;,
or just the name of what to extract.
</p>

<hr>
<h2 id='modsem_mplus'>Estimation latent interactions through mplus</h2><span id='topic+modsem_mplus'></span>

<h3>Description</h3>

<p>Estimation latent interactions through mplus
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modsem_mplus(
  model.syntax,
  data,
  estimator = "ml",
  type = "random",
  algorithm = "integration",
  process = "8",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modsem_mplus_+3A_model.syntax">model.syntax</code></td>
<td>
<p>lavaan/modsem syntax</p>
</td></tr>
<tr><td><code id="modsem_mplus_+3A_data">data</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="modsem_mplus_+3A_estimator">estimator</code></td>
<td>
<p>estimator argument passed to mplus</p>
</td></tr>
<tr><td><code id="modsem_mplus_+3A_type">type</code></td>
<td>
<p>type argument passed to mplus</p>
</td></tr>
<tr><td><code id="modsem_mplus_+3A_algorithm">algorithm</code></td>
<td>
<p>algorithm argument passed to mplus</p>
</td></tr>
<tr><td><code id="modsem_mplus_+3A_process">process</code></td>
<td>
<p>process argument passed to mplus</p>
</td></tr>
<tr><td><code id="modsem_mplus_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>modsem_mplus object
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Theory Of Planned Behavior
tpb &lt;- '
# Outer Model (Based on Hagger et al., 2007)
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model (Based on Steinmetz et al., 2011)
  # Covariances
  ATT ~~ SN + PBC
  PBC ~~ SN
  # Causal Relationsships
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC
  BEH ~ INT:PBC
'

## Not run: 
estTpbMplus &lt;- modsem_mplus(tpb, data = TPB)
summary(estTpbLMS)

## End(Not run)

</code></pre>

<hr>
<h2 id='modsem_pi'>Interaction between latent variables using product indicators</h2><span id='topic+modsem_pi'></span>

<h3>Description</h3>

<p><code>modsem_pi()</code> is a function for estimating interaction effects between latent variables,
in structural equation models (SEMs), using product indicators.
Methods for estimating interaction effects in SEMs can basically be split into
two frameworks:
1. Product Indicator based approaches (<code>"dblcent"</code>, <code>"rca"</code>, <code>"uca"</code>,
<code>"ca"</code>, <code>"pind"</code>), and
2. Distributionally based approaches (<code>"lms"</code>, <code>"qml"</code>).
<code>modsem_pi()</code> is essentially a fancy wrapper for <code>lavaan::sem()</code> which generates the
necessary syntax and variables for the estimation of models with latent product indicators.
Use <code>default_settings_pi()</code> to get the default settings for the different methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modsem_pi(
  model.syntax = NULL,
  data = NULL,
  method = "dblcent",
  match = NULL,
  standardize.data = FALSE,
  center.data = FALSE,
  first.loading.fixed = TRUE,
  center.before = NULL,
  center.after = NULL,
  residuals.prods = NULL,
  residual.cov.syntax = NULL,
  constrained.prod.mean = NULL,
  constrained.loadings = NULL,
  constrained.var = NULL,
  constrained.res.cov.method = NULL,
  auto.scale = "none",
  auto.center = "none",
  estimator = "ML",
  group = NULL,
  run = TRUE,
  na.rm = FALSE,
  suppress.warnings.lavaan = FALSE,
  suppress.warnings.match = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modsem_pi_+3A_model.syntax">model.syntax</code></td>
<td>
<p><code>lavaan</code> syntax</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_data">data</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_method">method</code></td>
<td>
<p>method to use:
<code>"rca"</code> = residual centering approach (passed to <code>lavaan</code>),
<code>"uca"</code> = unconstrained approach (passed to <code>lavaan</code>),
<code>"dblcent"</code> = double centering approach (passed to <code>lavaan</code>),
<code>"pind"</code> = prod ind approach, with no constraints or centering (passed to <code>lavaan</code>),
<code>"custom"</code> = use parameters specified in the function call (passed to <code>lavaan</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_match">match</code></td>
<td>
<p>should the product indicators be created by using the match-strategy</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_standardize.data">standardize.data</code></td>
<td>
<p>should data be scaled before fitting model</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_center.data">center.data</code></td>
<td>
<p>should data be centered before fitting model</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_first.loading.fixed">first.loading.fixed</code></td>
<td>
<p>Should the first factor loading in the latent product be fixed to one?</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_center.before">center.before</code></td>
<td>
<p>should indicators in products be centered before computing products (overwritten by <code>method</code>, if <code>method != NULL</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_center.after">center.after</code></td>
<td>
<p>should indicator products be centered after they have been computed?</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_residuals.prods">residuals.prods</code></td>
<td>
<p>should indicator products be centered using residuals (overwritten by <code>method</code>, if <code>method != NULL</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_residual.cov.syntax">residual.cov.syntax</code></td>
<td>
<p>should syntax for residual covariances be produced (overwritten by <code>method</code>, if <code>method != NULL</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_constrained.prod.mean">constrained.prod.mean</code></td>
<td>
<p>should syntax for product mean be produced (overwritten by <code>method</code>, if <code>method != NULL</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_constrained.loadings">constrained.loadings</code></td>
<td>
<p>should syntax for constrained loadings be produced (overwritten by <code>method</code>, if <code>method != NULL</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_constrained.var">constrained.var</code></td>
<td>
<p>should syntax for constrained variances be produced (overwritten by <code>method</code>, if <code>method != NULL</code>)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_constrained.res.cov.method">constrained.res.cov.method</code></td>
<td>
<p>method for constraining residual covariances</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_auto.scale">auto.scale</code></td>
<td>
<p>methods which should be scaled automatically (usually not useful)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_auto.center">auto.center</code></td>
<td>
<p>methods which should be centered automatically (usually not useful)</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_estimator">estimator</code></td>
<td>
<p>estimator to use in <code>lavaan</code></p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_group">group</code></td>
<td>
<p>group variable for multigroup analysis</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_run">run</code></td>
<td>
<p>should the model be run via <code>lavaan</code>, if <code>FALSE</code> only modified syntax and data is returned</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_na.rm">na.rm</code></td>
<td>
<p>should missing values be removed (case-wise)? Defaults to FALSE. If <code>TRUE</code>, missing values are removed case-wise.
If <code>FALSE</code> they are not removed.</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_suppress.warnings.lavaan">suppress.warnings.lavaan</code></td>
<td>
<p>should warnings from <code>lavaan</code> be suppressed?</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_suppress.warnings.match">suppress.warnings.match</code></td>
<td>
<p>should warnings from <code>match</code> be suppressed?</p>
</td></tr>
<tr><td><code id="modsem_pi_+3A_...">...</code></td>
<td>
<p>arguments passed to other functions, e.g., <code>lavaan</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>modsem</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
# For more examples, check README and/or GitHub.
# One interaction
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 +x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'

# Double centering approach
est1 &lt;- modsem_pi(m1, oneInt)
summary(est1)

## Not run: 
# The Constrained Approach
est1Constrained &lt;- modsem_pi(m1, oneInt, method = "ca")
summary(est1Constrained)

## End(Not run)

# Theory Of Planned Behavior
tpb &lt;- '
# Outer Model (Based on Hagger et al., 2007)
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model (Based on Steinmetz et al., 2011)
  # Covariances
  ATT ~~ SN + PBC
  PBC ~~ SN
  # Causal Relationships
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC
  BEH ~ INT:PBC
'

# Double centering approach
estTpb &lt;- modsem_pi(tpb, data = TPB)
summary(estTpb)

## Not run: 
# The Constrained Approach
estTpbConstrained &lt;- modsem_pi(tpb, data = TPB, method = "ca")
summary(estTpbConstrained)

## End(Not run)
</code></pre>

<hr>
<h2 id='modsemify'>Generate parameter table for <code>lavaan</code> syntax</h2><span id='topic+modsemify'></span>

<h3>Description</h3>

<p>Generate parameter table for <code>lavaan</code> syntax
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modsemify(syntax)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modsemify_+3A_syntax">syntax</code></td>
<td>
<p>model syntax</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code> with columns <code>lhs, op, rhs, mod</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 +x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'
modsemify(m1)
</code></pre>

<hr>
<h2 id='multiplyIndicatorsCpp'>Multiply indicators</h2><span id='topic+multiplyIndicatorsCpp'></span>

<h3>Description</h3>

<p>Multiply indicators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiplyIndicatorsCpp(df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiplyIndicatorsCpp_+3A_df">df</code></td>
<td>
<p>A data DataFrame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A NumericVector
</p>

<hr>
<h2 id='oneInt'>oneInt</h2><span id='topic+oneInt'></span>

<h3>Description</h3>

<p>A simulated dataset with one interaction effect
</p>

<hr>
<h2 id='parameter_estimates'>Extract parameterEstimates from an estimated model</h2><span id='topic+parameter_estimates'></span>

<h3>Description</h3>

<p>Extract parameterEstimates from an estimated model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parameter_estimates(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parameter_estimates_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+modsem_pi">modsem_pi</a></code>, <code><a href="#topic+modsem_da">modsem_da</a></code>, or <code><a href="#topic+modsem_mplus">modsem_mplus</a></code></p>
</td></tr>
<tr><td><code id="parameter_estimates_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to other functions</p>
</td></tr>
</table>

<hr>
<h2 id='plot_interaction'>Plot Interaction Effects in a SEM Model</h2><span id='topic+plot_interaction'></span>

<h3>Description</h3>

<p>This function creates an interaction plot of the outcome variable (<code>y</code>) as a function
of a focal predictor (<code>x</code>) at multiple values of a moderator (<code>z</code>). It is
designed for use with structural equation modeling (SEM) objects (e.g., those from
<code><a href="#topic+modsem">modsem</a></code>). Predicted means (or predicted individual values) are calculated
via <code><a href="#topic+simple_slopes">simple_slopes</a></code>, and then plotted with <code>ggplot2</code> to display
multiple regression lines and confidence/prediction bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_interaction(
  x,
  z,
  y,
  xz = NULL,
  vals_x = seq(-3, 3, 0.001),
  vals_z,
  model,
  alpha_se = 0.15,
  digits = 2,
  ci_width = 0.95,
  ci_type = "confidence",
  rescale = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_interaction_+3A_x">x</code></td>
<td>
<p>A character string specifying the focal predictor (x-axis variable).</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_z">z</code></td>
<td>
<p>A character string specifying the moderator variable.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_y">y</code></td>
<td>
<p>A character string specifying the outcome (dependent) variable.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_xz">xz</code></td>
<td>
<p>A character string specifying the interaction term (<code>x:z</code>).
If <code>NULL</code>, the term is created automatically as <code>paste(x, z, sep = ":")</code>.
Some SEM backends may handle the interaction term differently (for instance, by
removing or modifying the colon), and this function attempts to reconcile that
internally.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_vals_x">vals_x</code></td>
<td>
<p>A numeric vector of values at which to compute and plot the focal
predictor <code>x</code>. The default is <code>seq(-3, 3, .001)</code>, which provides a
relatively fine grid for smooth lines. If <code>rescale=TRUE</code>, these values
are in standardized (mean-centered and scaled) units, and will be converted back
to the original metric in the internal computation of predicted means.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_vals_z">vals_z</code></td>
<td>
<p>A numeric vector of values of the moderator <code>z</code> at which to draw
separate regression lines. Each distinct value in <code>vals_z</code> defines a separate
group (plotted with a different color). If <code>rescale=TRUE</code>, these values
are also assumed to be in standardized units.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_model">model</code></td>
<td>
<p>An object of class <code><a href="#topic+modsem_pi">modsem_pi</a></code>, <code><a href="#topic+modsem_da">modsem_da</a></code>, 
<code><a href="#topic+modsem_mplus">modsem_mplus</a></code>, or possibly a <code>lavaan</code> object. Must be a fitted
SEM model containing paths for <code>y ~ x + z + x:z</code>.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_alpha_se">alpha_se</code></td>
<td>
<p>A numeric value in \([0, 1]\) specifying the transparency of
the confidence/prediction interval ribbon. Default is <code>0.15</code>.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_digits">digits</code></td>
<td>
<p>An integer specifying the number of decimal places to which the
moderator values (<code>z</code>) are rounded for labeling/grouping in the plot.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_ci_width">ci_width</code></td>
<td>
<p>A numeric value in \((0,1)\) indicating the coverage of the
confidence (or prediction) interval. The default is <code>0.95</code> for a 95%
interval.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_ci_type">ci_type</code></td>
<td>
<p>A character string specifying whether to compute
<code>"confidence"</code> intervals (for the mean of the predicted values, default)
or <code>"prediction"</code> intervals (which include residual variance).</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_rescale">rescale</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), <code>vals_x</code> and <code>vals_z</code>
are interpreted as standardized units, which are mapped back to the raw scale
before computing predictions. If <code>FALSE</code>, <code>vals_x</code> and <code>vals_z</code>
are taken as raw-scale values directly.</p>
</td></tr>
<tr><td><code id="plot_interaction_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code><a href="#topic+simple_slopes">simple_slopes</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Computation Steps:</strong>
</p>

<ol>
<li><p> Calls <code><a href="#topic+simple_slopes">simple_slopes</a></code> to compute the predicted values of <code>y</code>
at the specified grid of <code>x</code> and <code>z</code> values.
</p>
</li>
<li><p> Groups the resulting predictions by unique <code>z</code>-values (rounded to
<code>digits</code>) to create colored lines.
</p>
</li>
<li><p> Plots these lines using <code>ggplot2</code>, adding ribbons for confidence
(or prediction) intervals, with transparency controlled by <code>alpha_se</code>.
</p>
</li></ol>

<p><strong>Interpretation:</strong>
Each line in the plot corresponds to the regression of <code>y</code> on <code>x</code> at
a given level of <code>z</code>. The shaded region around each line (ribbon) shows
either the confidence interval for the predicted mean (if <code>ci_type =
"confidence"</code>) or the prediction interval for individual observations (if
<code>ci_type = "prediction"</code>). Where the ribbons do not overlap, there is
evidence that the lines differ significantly over that range of <code>x</code>.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object that can be further customized (e.g., with
additional <code>+ theme(...)</code> layers). By default, it shows lines for each
moderator value and a shaded region corresponding to the interval type
(confidence or prediction).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(modsem)

# Example 1: Interaction of X and Z in a simple SEM
m1 &lt;- "
# Outer Model
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

# Inner Model
  Y ~ X + Z + X:Z
"
est1 &lt;- modsem(m1, data = oneInt)

# Plot interaction using a moderate range of X and two values of Z
plot_interaction(x = "X", z = "Z", y = "Y", xz = "X:Z",
                 vals_x = -3:3, vals_z = c(-0.2, 0), model = est1)

# Example 2: Interaction in a theory-of-planned-behavior-style model
tpb &lt;- "
# Outer Model
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN  =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC
  BEH ~ PBC:INT
"
est2 &lt;- modsem(tpb, data = TPB, method = "lms")

# Plot with custom Z values and a denser X grid
plot_interaction(x = "INT", z = "PBC", y = "BEH",
                 xz = "PBC:INT",
                 vals_x = seq(-3, 3, 0.01),
                 vals_z = c(-0.5, 0.5),
                 model = est2)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot_jn'>Plot Interaction Effect Using the Johnson-Neyman Technique</h2><span id='topic+plot_jn'></span>

<h3>Description</h3>

<p>This function plots the simple slopes of an interaction effect across different values of a moderator variable using the Johnson-Neyman technique. It identifies regions where the effect of the predictor on the outcome is statistically significant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_jn(
  x,
  z,
  y,
  xz = NULL,
  model,
  min_z = -3,
  max_z = 3,
  sig.level = 0.05,
  alpha = 0.2,
  detail = 1000,
  sd.line = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_jn_+3A_x">x</code></td>
<td>
<p>The name of the predictor variable (as a character string).</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_z">z</code></td>
<td>
<p>The name of the moderator variable (as a character string).</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_y">y</code></td>
<td>
<p>The name of the outcome variable (as a character string).</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_xz">xz</code></td>
<td>
<p>The name of the interaction term. If not specified, it will be created using <code>x</code> and <code>z</code>.</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_model">model</code></td>
<td>
<p>A fitted model object of class <code>modsem_da</code>, <code>modsem_mplus</code>, <code>modsem_pi</code>, or <code>lavaan</code>.</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_min_z">min_z</code></td>
<td>
<p>The minimum value of the moderator variable <code>z</code> to be used in the plot (default is -3). It is relative to the mean of z.</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_max_z">max_z</code></td>
<td>
<p>The maximum value of the moderator variable <code>z</code> to be used in the plot (default is 3). It is relative to the mean of z.</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_sig.level">sig.level</code></td>
<td>
<p>The significance level for the confidence intervals (default is 0.05).</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_alpha">alpha</code></td>
<td>
<p>alpha setting used in 'ggplot' (i.e., the opposite of opacity)</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_detail">detail</code></td>
<td>
<p>The number of generated data points to use for the plot (default is 1000). You can increase this value for smoother plots.</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_sd.line">sd.line</code></td>
<td>
<p>A thick black line showing <code>+/- sd.line * sd(z)</code>. NOTE: This line will be truncated by <code>min_z</code> and <code>max_z</code> if 
the sd.line falls outside of <code>[min_z, max_z]</code>.</p>
</td></tr>
<tr><td><code id="plot_jn_+3A_...">...</code></td>
<td>
<p>Additional arguments (currently not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the simple slopes of the predictor variable <code>x</code> on the outcome variable <code>y</code> at different levels of the moderator variable <code>z</code>. It uses the Johnson-Neyman technique to identify the regions of <code>z</code> where the effect of <code>x</code> on <code>y</code> is statistically significant.
</p>
<p>It extracts the necessary coefficients and variance-covariance information from the fitted model object. The function then computes the critical t-value and solves the quadratic equation derived from the t-statistic equation to find the Johnson-Neyman points.
</p>
<p>The plot displays:
</p>

<ul>
<li><p> The estimated simple slopes across the range of <code>z</code>.
</p>
</li>
<li><p> Confidence intervals around the slopes.
</p>
</li>
<li><p> Regions where the effect is significant (shaded areas).
</p>
</li>
<li><p> Vertical dashed lines indicating the Johnson-Neyman points.
</p>
</li>
<li><p> Text annotations providing the exact values of the Johnson-Neyman points.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>ggplot</code> object showing the interaction plot with regions of significance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(modsem)

m1 &lt;-  ' 
  visual  =~ x1 + x2 + x3 
  textual =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9

  visual ~ speed + textual + speed:textual
'

est &lt;- modsem(m1, data = lavaan::HolzingerSwineford1939, method = "ca")
plot_jn(x = "speed", z = "textual", y = "visual", model = est, max_z = 6)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot_surface'>Plot Surface for Interaction Effects</h2><span id='topic+plot_surface'></span>

<h3>Description</h3>

<p>Generates a 3D surface plot to visualize the interaction effect of two variables ('x' and 'z') on an outcome ('y')
using parameter estimates from a supported model object (e.g., 'lavaan' or 'modsem').
The function allows specifying ranges for 'x' and 'z' in standardized z-scores, which are then transformed
back to the original scale based on their means and standard deviations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_surface(
  x,
  z,
  y,
  xz = NULL,
  model,
  min_x = -3,
  max_x = 3,
  min_z = -3,
  max_z = 3,
  detail = 0.01,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_surface_+3A_x">x</code></td>
<td>
<p>A character string specifying the name of the first predictor variable.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_z">z</code></td>
<td>
<p>A character string specifying the name of the second predictor variable.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_y">y</code></td>
<td>
<p>A character string specifying the name of the outcome variable.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_xz">xz</code></td>
<td>
<p>Optional. A character string or vector specifying the interaction term between 'x' and 'z'.
If 'NULL', the interaction term is constructed as 'paste(x, z, sep = &quot;:&quot;)' and adjusted for specific model classes.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_model">model</code></td>
<td>
<p>A model object of class ''modsem_pi'&lsquo;, '&rsquo;modsem_da'&lsquo;, '&rsquo;modsem_mplus'&lsquo;, or '&rsquo;lavaan''. The model should
include paths for the predictors ('x', 'z', and 'xz') to the outcome ('y').</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_min_x">min_x</code></td>
<td>
<p>Numeric. Minimum value of 'x' in z-scores. Default is -3.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_max_x">max_x</code></td>
<td>
<p>Numeric. Maximum value of 'x' in z-scores. Default is 3.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_min_z">min_z</code></td>
<td>
<p>Numeric. Minimum value of 'z' in z-scores. Default is -3.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_max_z">max_z</code></td>
<td>
<p>Numeric. Maximum value of 'z' in z-scores. Default is 3.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_detail">detail</code></td>
<td>
<p>Numeric. Step size for the grid of 'x' and 'z' values, determining the resolution of the surface.
Smaller values increase plot resolution. Default is '1e-2'.</p>
</td></tr>
<tr><td><code id="plot_surface_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to 'plotly::plot_ly'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input 'min_x', 'max_x', 'min_z', and 'max_z' define the range of 'x' and 'z' values in z-scores.
These are scaled by the standard deviations and shifted by the means of the respective variables, obtained
from the model parameter table. The resulting surface shows the predicted values of 'y' over the grid of 'x' and 'z'.
</p>
<p>The function supports models of class 'modsem' (with subclasses 'modsem_pi', 'modsem_da', 'modsem_mplus') and 'lavaan'.
For 'lavaan' models, it is not designed for multigroup models, and a warning will be issued if multiple groups are detected.
</p>


<h3>Value</h3>

<p>A 'plotly' surface plot object displaying the predicted values of 'y' across the grid of 'x' and 'z' values.
The color bar shows the values of 'y'.
</p>


<h3>Note</h3>

<p>The interaction term ('xz') may need to be manually specified for some models. For non-'lavaan' models,
interaction terms may have their separator (':') removed based on circumstances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
m1 &lt;- "
# Outer Model
  X =~ x1
  X =~ x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

# Inner model
  Y ~ X + Z + X:Z
"
est1 &lt;- modsem(m1, data = oneInt)
plot_surface("X", "Z", "Y", model = est1)

tpb &lt;- "
# Outer Model (Based on Hagger et al., 2007)
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model (Based on Steinmetz et al., 2011)
  # Causal Relationsships
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC
  # BEH ~ ATT:PBC
  BEH ~ PBC:INT
  # BEH ~ PBC:PBC
"

est2 &lt;- modsem(tpb, TPB, method = "lms")
plot_surface(x = "INT", z = "PBC", y = "BEH", model = est1)

## End(Not run)

</code></pre>

<hr>
<h2 id='simple_slopes'>Get the simple slopes of a SEM model</h2><span id='topic+simple_slopes'></span>

<h3>Description</h3>

<p>This function calculates simple slopes (predicted values of the outcome variable)
at user-specified values of the focal predictor (<code>x</code>) and moderator (<code>z</code>)
in a structural equation modeling (SEM) framework. It supports interaction terms
(<code>xz</code>), computes standard errors (SE), and optionally returns confidence or
prediction intervals for these predicted values. It also provides p-values for
hypothesis testing. This is useful for visualizing and interpreting moderation
effects or to see how the slope changes at different values of the moderator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple_slopes(
  x,
  z,
  y,
  xz = NULL,
  model,
  vals_x = -3:3,
  vals_z = -1:1,
  rescale = TRUE,
  ci_width = 0.95,
  ci_type = "confidence",
  relative_h0 = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simple_slopes_+3A_x">x</code></td>
<td>
<p>The name of the variable on the x-axis (focal predictor).</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_z">z</code></td>
<td>
<p>The name of the moderator variable.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_y">y</code></td>
<td>
<p>The name of the outcome variable.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_xz">xz</code></td>
<td>
<p>The name of the interaction term (<code>x:z</code>). If <code>NULL</code>, it will
be created by combining <code>x</code> and <code>z</code> with a colon (e.g., <code>"x:z"</code>).
Some backends may remove or alter the colon symbol, so the function tries to
account for that internally.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_model">model</code></td>
<td>
<p>An object of class <code><a href="#topic+modsem_pi">modsem_pi</a></code>, <code><a href="#topic+modsem_da">modsem_da</a></code>,
<code><a href="#topic+modsem_mplus">modsem_mplus</a></code>, or a <code>lavaan</code> object. This should be a fitted SEM
model that includes paths for <code>y ~ x + z + x:z</code>.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_vals_x">vals_x</code></td>
<td>
<p>Numeric vector of values of <code>x</code> at which to compute predicted
slopes. Defaults to <code>-3:3</code>. If <code>rescale = TRUE</code>, these values are taken
relative to the mean and standard deviation of <code>x</code>. A higher density of points
(e.g., <code>seq(-3, 3, 0.1)</code>) will produce smoother curves and confidence bands.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_vals_z">vals_z</code></td>
<td>
<p>Numeric vector of values of the moderator <code>z</code> at which to compute
predicted slopes. Defaults to <code>-1:1</code>. If <code>rescale = TRUE</code>, these values
are taken relative to the mean and standard deviation of <code>z</code>. Each unique value
of <code>z</code> generates a separate regression line <code>y ~ x | z</code>.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_rescale">rescale</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), <code>x</code> and <code>z</code> are standardized
according to their means and standard deviations in the model. The values in
<code>vals_x</code> and <code>vals_z</code> are interpreted in those standardized units. The
raw (unscaled) values corresponding to these standardized points will be displayed
in the returned table.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_ci_width">ci_width</code></td>
<td>
<p>A numeric value between 0 and 1 indicating the confidence (or
prediction) interval width. The default is 0.95 (i.e., 95% interval).</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_ci_type">ci_type</code></td>
<td>
<p>A string indicating whether to compute a <code>"confidence"</code> interval
for the predicted mean (<em>i.e.</em>, uncertainty in the regression line) or a
<code>"prediction"</code> interval for individual outcomes. The default is
<code>"confidence"</code>. If <code>"prediction"</code>, the residual variance is added to the
variance of the fitted mean, resulting in a wider interval.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_relative_h0">relative_h0</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), hypothesis tests for the
predicted values (<code>predicted - h0</code>) assume <code>h0</code> is the model-estimated
mean of <code>y</code>. If <code>FALSE</code>, the null hypothesis is <code>h0 = 0</code>.</p>
</td></tr>
<tr><td><code id="simple_slopes_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to lower-level functions or other internal
helpers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Computation Steps</strong>  
1. The function extracts parameter estimates (and, if necessary, their covariance
matrix) from the fitted SEM model (<code>model</code>).  
2. It identifies the coefficients for <code>x</code>, <code>z</code>, and <code>x:z</code> in the model's
parameter table, as well as the variance of <code>x</code>, <code>z</code>, and the residual.  
3. If <code>xz</code> is not provided, it will be constructed by combining <code>x</code> and
<code>z</code> with a colon (<code>":"</code>). In certain SEM software, the colon may be
removed or replaced internally; the function attempts to reconcile that.  
4. A grid of <code>x</code> and <code>z</code> values is created from <code>vals_x</code> and
<code>vals_z</code>. If <code>rescale = TRUE</code>, these values are transformed back into raw
metric units for display in the output.  
5. For each point in the grid, a predicted value of <code>y</code> is computed via
<code>(beta0 + beta_x * x + beta_z * z + beta_xz * x * z)</code> and, if included, a
mean offset.  
6. The standard error (<code>std.error</code>) is derived from the covariance matrix of
the relevant parameters, and if <code>ci_type = "prediction"</code>, adds the residual
variance.  
7. Confidence (or prediction) intervals are formed using <code>ci_width</code> (defaulting
to 95%). The result is a table-like data frame with predicted values, CIs,
standard errors, z-values, and p-values.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> (invisibly inheriting class <code>"simple_slopes"</code>)
with columns:
</p>

<ul>
<li> <p><code>vals_x</code>, <code>vals_z</code>: The requested grid values of <code>x</code> and <code>z</code>.
</p>
</li>
<li> <p><code>predicted</code>: The predicted value of <code>y</code> at that combination of
<code>x</code> and <code>z</code>.
</p>
</li>
<li> <p><code>std.error</code>: The standard error of the predicted value.
</p>
</li>
<li> <p><code>z.value</code>, <code>p.value</code>: The z-statistic and corresponding p-value
for testing the null hypothesis that <code>predicted == h0</code>.
</p>
</li>
<li> <p><code>ci.lower</code>, <code>ci.upper</code>: Lower and upper bounds of the confidence
(or prediction) interval.
</p>
</li></ul>

<p>An attribute <code>"variable_names"</code> (list of <code>x</code>, <code>z</code>, <code>y</code>)
is attached for convenience.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(modsem)

m1 &lt;- "
# Outer Model
  X =~ x1 + x2 + x3
  Z =~ z1 + z2 + z3
  Y =~ y1 + y2 + y3

# Inner model
  Y ~ X + Z + X:Z
"
est1 &lt;- modsem(m1, data = oneInt)

# Simple slopes at X in [-3, 3] and Z in [-1, 1], rescaled to the raw metric.
simple_slopes(x = "X", z = "Z", y = "Y", model = est1)

# If the data or user wants unscaled values, set rescale = FALSE, etc.
simple_slopes(x = "X", z = "Z", y = "Y", model = est1, rescale = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='standardized_estimates'>Get standardized estimates</h2><span id='topic+standardized_estimates'></span>

<h3>Description</h3>

<p>Get standardized estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardized_estimates(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="standardized_estimates_+3A_object">object</code></td>
<td>
<p>An object of class <code>modsem_da</code>, <code>modsem_mplus</code>,
or a <code>parTable</code> of class <code>data.frame</code></p>
</td></tr>
<tr><td><code id="standardized_estimates_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to other functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>modsem_da</code>, and <code>modsem_mplus</code> objects,
the interaction term is not standardized such that <code>var(xz) = 1</code>.
The interaction term is not an actual variable in the model, meaning that it does not
have a variance. It must therefore be calculated from the other parameters in the model.
Assuming normality and zero-means, the variance is calculated as
<code>var(xz) = var(x) * var(z) + cov(x, z)^2</code>. Thus setting the variance of the interaction
term to 1 would only be 'correct' if the correlation between <code>x</code> and <code>z</code> is zero.
This means that the standardized estimates for the interaction term will
be different from those using <code>lavaan</code>, since there the interaction term is an
actual latent variable in the model, with a standardized variance of 1.
</p>

<hr>
<h2 id='summary.modsem_da'>summary for modsem objects</h2><span id='topic+summary.modsem_da'></span><span id='topic+summary.modsem_mplus'></span><span id='topic+summary.modsem_pi'></span>

<h3>Description</h3>

<p>summary for modsem objects
</p>
<p>summary for modsem objects
</p>
<p>summary for modsem objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'modsem_da'
summary(
  object,
  H0 = TRUE,
  verbose = interactive(),
  r.squared = TRUE,
  adjusted.stat = FALSE,
  digits = 3,
  scientific = FALSE,
  ci = FALSE,
  standardized = FALSE,
  loadings = TRUE,
  regressions = TRUE,
  covariances = TRUE,
  intercepts = !standardized,
  variances = TRUE,
  var.interaction = FALSE,
  ...
)

## S3 method for class 'modsem_mplus'
summary(
  object,
  scientific = FALSE,
  standardize = FALSE,
  ci = FALSE,
  digits = 3,
  loadings = TRUE,
  regressions = TRUE,
  covariances = TRUE,
  intercepts = TRUE,
  variances = TRUE,
  ...
)

## S3 method for class 'modsem_pi'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.modsem_da_+3A_object">object</code></td>
<td>
<p>modsem object to summarized</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_h0">H0</code></td>
<td>
<p>should a null model be estimated (used for comparison)</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_verbose">verbose</code></td>
<td>
<p>print progress for the estimation of null model</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_r.squared">r.squared</code></td>
<td>
<p>calculate R-squared</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_adjusted.stat">adjusted.stat</code></td>
<td>
<p>should sample size corrected/adjustes AIC and BIC be reported?</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_digits">digits</code></td>
<td>
<p>number of digits to print</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_scientific">scientific</code></td>
<td>
<p>print p-values in scientific notation</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_ci">ci</code></td>
<td>
<p>print confidence intervals</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_standardized">standardized</code></td>
<td>
<p>print standardized estimates</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_loadings">loadings</code></td>
<td>
<p>print loadings</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_regressions">regressions</code></td>
<td>
<p>print regressions</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_covariances">covariances</code></td>
<td>
<p>print covariances</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_intercepts">intercepts</code></td>
<td>
<p>print intercepts</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_variances">variances</code></td>
<td>
<p>print variances</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_var.interaction">var.interaction</code></td>
<td>
<p>if FALSE (default) variances for interaction terms will be removed (if present)</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_...">...</code></td>
<td>
<p>arguments passed to lavaan::summary()</p>
</td></tr>
<tr><td><code id="summary.modsem_da_+3A_standardize">standardize</code></td>
<td>
<p>standardize estimates</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
m1 &lt;- "
 # Outer Model
 X =~ x1 + x2 + x3
 Y =~ y1 + y2 + y3
 Z =~ z1 + z2 + z3

 # Inner model
 Y ~ X + Z + X:Z
"

est1 &lt;- modsem(m1, oneInt, "qml")
summary(est1, ci = TRUE, scientific = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='TPB'>TPB</h2><span id='topic+TPB'></span>

<h3>Description</h3>

<p>A simulated dataset based on the Theory of Planned Behaviour
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
tpb &lt;- "
# Outer Model (Based on Hagger et al., 2007)
  ATT =~ att1 + att2 + att3 + att4 + att5
  SN =~ sn1 + sn2
  PBC =~ pbc1 + pbc2 + pbc3
  INT =~ int1 + int2 + int3
  BEH =~ b1 + b2

# Inner Model (Based on Steinmetz et al., 2011)
  INT ~ ATT + SN + PBC
  BEH ~ INT + PBC + INT:PBC
"

est &lt;- modsem(tpb, data = TPB)
</code></pre>

<hr>
<h2 id='TPB_1SO'>TPB_1SO</h2><span id='topic+TPB_1SO'></span>

<h3>Description</h3>

<p>A simulated dataset based on the Theory of Planned Behaviour,
where INT is a higher order construct of ATT, SN, and PBC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tpb &lt;- '
  # First order constructs
  ATT =~ att1 + att2 + att3
  SN  =~ sn1 + sn2 + sn3
  PBC =~ pbc1 + pbc2 + pbc3
  BEH =~ b1 + b2

  # Higher order constructs
  INT =~ ATT + PBC + SN

  # Higher order interaction
  INTxPBC =~ ATT:PBC + SN:PBC + PBC:PBC
  
  # Structural model
  BEH ~ PBC + INT + INTxPBC
'

## Not run: 
est &lt;- modsem(tpb, data = TPB_2SO, method = "ca")
summary(est)

## End(Not run)
</code></pre>

<hr>
<h2 id='TPB_2SO'>TPB_2SO</h2><span id='topic+TPB_2SO'></span>

<h3>Description</h3>

<p>A simulated dataset based on the Theory of Planned Behaviour,
where INT is a higher order construct of ATT and SN, and PBC is a higher order
construct of PC and PB.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tpb &lt;- "
  # First order constructs
  ATT =~ att1 + att2 + att3
  SN  =~ sn1 + sn2 + sn3
  PB =~ pb1 + pb2 + pb3
  PC =~ pc1 + pc2 + pc3
  BEH =~ b1 + b2

  # Higher order constructs
  INT =~ ATT + SN
  PBC =~ PC + PB

  # Higher order interaction
  INTxPBC =~ ATT:PC + ATT:PB + SN:PC + SN:PB

  # Structural model
  BEH ~ PBC + INT + INTxPBC
"

## Not run: 
est &lt;- modsem(tpb, data = TPB_2SO, method = "ca")
summary(est)

## End(Not run)
</code></pre>

<hr>
<h2 id='TPB_UK'>TPB_UK</h2><span id='topic+TPB_UK'></span>

<h3>Description</h3>

<p>A dataset based on the Theory of Planned Behaviour from a
UK sample. 4 variables with high communality were selected for each
latent variable (ATT, SN, PBC, INT, BEH), from two time points (t1 and t2).
</p>


<h3>Source</h3>

<p>Gathered from a replciation study of the original by Hagger et al. (2023).
Obtained from https://doi.org/10.23668/psycharchives.12187
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
tpb_uk &lt;- "
# Outer Model (Based on Hagger et al., 2007)
 ATT =~ att3 + att2 + att1 + att4
 SN =~ sn4 + sn2 + sn3 + sn1
 PBC =~ pbc2 + pbc1 + pbc3 + pbc4
 INT =~ int2 + int1 + int3 + int4
 BEH =~ beh3 + beh2 + beh1 + beh4

# Inner Model (Based on Steinmetz et al., 2011)
 # Causal Relationsships
 INT ~ ATT + SN + PBC
 BEH ~ INT + PBC
 BEH ~ INT:PBC
"

est &lt;- modsem(tpb_uk, data = TPB_UK)
</code></pre>

<hr>
<h2 id='trace_path'>Estimate formulas for (co-)variance paths using Wright's path tracing rules</h2><span id='topic+trace_path'></span>

<h3>Description</h3>

<p>This function estimates the path from <code>x</code> to <code>y</code> using the path tracing rules.
Note that it only works with structural parameters, so <code>"=~"</code> are ignored, unless
<code>measurement.model = TRUE</code>.
If you want to use the measurement model,
<code>"~"</code> should be in the <code>mod</code> column of <code>pt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trace_path(
  pt,
  x,
  y,
  parenthesis = TRUE,
  missing.cov = FALSE,
  measurement.model = FALSE,
  maxlen = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trace_path_+3A_pt">pt</code></td>
<td>
<p>A data frame with columns <code>lhs</code>, <code>op</code>, <code>rhs</code>, and <code>mod</code>, from <a href="#topic+modsemify">modsemify</a></p>
</td></tr>
<tr><td><code id="trace_path_+3A_x">x</code></td>
<td>
<p>Source variable</p>
</td></tr>
<tr><td><code id="trace_path_+3A_y">y</code></td>
<td>
<p>Destination variable</p>
</td></tr>
<tr><td><code id="trace_path_+3A_parenthesis">parenthesis</code></td>
<td>
<p>If <code>TRUE</code>, the output will be enclosed in parenthesis</p>
</td></tr>
<tr><td><code id="trace_path_+3A_missing.cov">missing.cov</code></td>
<td>
<p>If <code>TRUE</code>, covariances missing from the model syntax will be added</p>
</td></tr>
<tr><td><code id="trace_path_+3A_measurement.model">measurement.model</code></td>
<td>
<p>If <code>TRUE</code>, the function will use the measurement model</p>
</td></tr>
<tr><td><code id="trace_path_+3A_maxlen">maxlen</code></td>
<td>
<p>Maximum length of a path before aborting</p>
</td></tr>
<tr><td><code id="trace_path_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <a href="#topic+trace_path">trace_path</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string with the estimated path (simplified if possible)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(modsem)
m1 &lt;- '
  # Outer Model
  X =~ x1 + x2 +x3
  Y =~ y1 + y2 + y3
  Z =~ z1 + z2 + z3

  # Inner model
  Y ~ X + Z + X:Z
'
pt &lt;- modsemify(m1)
trace_path(pt, x = "Y", y = "Y", missing.cov = TRUE) # variance of Y
</code></pre>

<hr>
<h2 id='var_interactions'>Extract or modify parTable from an estimated model with estimated variances of interaction terms</h2><span id='topic+var_interactions'></span>

<h3>Description</h3>

<p>Extract or modify parTable from an estimated model with estimated variances of interaction terms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_interactions(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="var_interactions_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+modsem_da">modsem_da</a></code>,  <code><a href="#topic+modsem_mplus">modsem_mplus</a></code>,
or a parTable of class <code><a href="base.html#topic+data.frame">data.frame</a></code></p>
</td></tr>
<tr><td><code id="var_interactions_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to other functions</p>
</td></tr>
</table>

<hr>
<h2 id='vcov_modsem_da'>Wrapper for vcov</h2><span id='topic+vcov_modsem_da'></span>

<h3>Description</h3>

<p>wrapper for vcov, to be used with modsem::vcov_modsem_da,
since vcov is not in the namespace of modsem, but stats
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcov_modsem_da(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vcov_modsem_da_+3A_object">object</code></td>
<td>
<p>fittet model to inspect</p>
</td></tr>
<tr><td><code id="vcov_modsem_da_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
