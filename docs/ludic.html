<!DOCTYPE html><html><head><title>Help for package ludic</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ludic}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ludic-package'><p>ludic</p></a></li>
<li><a href='#agree_C'><p>Fast C++ implementation of agreement vector for the element-wise comparison of 2 matrices</p></a></li>
<li><a href='#atlas'><p>Association testing by combining several matching thresholds</p></a></li>
<li><a href='#comb_pvals'><p>Fisher's rule for combining several p-values</p></a></li>
<li><a href='#em_winkler'><p>Implementation of Winkler's EM algorithm for Fellegi-Sunter matching method</p></a></li>
<li><a href='#EMstep_C_sparse_big'><p>C++ implementation of the E and M steps from Winkler's EM algorithm estimating FS method</p>
using sparse matrices for big sample sizes</a></li>
<li><a href='#estep_C_vect'><p>Fast C++ implementation of Winkler's Method E step</p></a></li>
<li><a href='#logit'><p>Logit link function</p></a></li>
<li><a href='#loglikC_bin'><p>C++ implementation of the pseudo-likelihood computation</p></a></li>
<li><a href='#matching_score'><p>Computes a matching score from agreement vectors and weights</p></a></li>
<li><a href='#matchingScore_C'><p>Fast C++ computation of the final posterior probabilities in the E-M Winkler's method</p></a></li>
<li><a href='#matchProbs_rank_full_C'><p>Compute the matching probabilities for each pair of observations</p></a></li>
<li><a href='#pval_zscore'><p>Compute p-values for a Z-score</p></a></li>
<li><a href='#RA'><p>Anonymized binarized diagnosis codes from RA study.</p></a></li>
<li><a href='#recordLink'><p>Probabilistic Patient Record Linkage</p></a></li>
<li><a href='#strsplitC'><p>Splitting a character string in C++</p></a></li>
<li><a href='#test_han2018'><p>Association testing using Han &amp; Lahiri estimating equations and jackknife approach</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Linkage Using Diagnosis Codes</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-08-18</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), Rcpp (&ge; 0.12.11),</td>
</tr>
<tr>
<td>Imports:</td>
<td>fGarch, landpred, Matrix, methods, rootSolve</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Description:</td>
<td>Probabilistic record linkage without direct identifiers using only 
    diagnosis codes. Method is detailed in: Hejblum, Weber, Liao, Palmer, 
    Churchill, Szolovits, Murphy, Kohane &amp; Cai (2019) &lt;<a href="https://doi.org/10.1038%2Fsdata.2018.298">doi:10.1038/sdata.2018.298</a>&gt; ;
    Zhang, Hejblum, Weber, Palmer, Churchill, Szolovits, Murphy, Liao, Kohane 
    &amp; Cai (2021) &lt;<a href="https://doi.org/10.1101%2F2021.05.02.21256490">doi:10.1101/2021.05.02.21256490</a>&gt;.</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/borishejblum/ludic/issues">https://github.com/borishejblum/ludic/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-08-18 11:00:16 UTC; boris</td>
</tr>
<tr>
<td>Author:</td>
<td>Boris P Hejblum [aut, cre],
  Harrison G Zhang [aut],
  Tianxi Cai [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Boris P Hejblum &lt;boris.hejblum@u-bordeaux.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-08-18 14:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='ludic-package'>ludic</h2><span id='topic+ludic-package'></span><span id='topic+ludic'></span>

<h3>Description</h3>

<p>Linkage Using Diagnosis Codes
</p>


<h3>Details</h3>

<p>This package implements probabilistic record linkage methods that relies on the use of diagnosis 
codes only, in the absence of direct identifiers .
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ludic</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> ludic 0.2.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2021-08-18</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> <a href="https://cran.r-project.org/web/licenses/MIT">The &quot;MIT License&quot; (MIT)</a></td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The main function of <code>ludic</code> is <code><a href="#topic+recordLink">recordLink</a></code>.
</p>


<h3>Author(s)</h3>

<p>Boris P. Hejblum, Tianxi Cai
&mdash; Maintainer: Boris P. Hejblum
</p>


<h3>References</h3>

<p>Hejblum BP, Weber G, Liao KP, Palmer N, Churchill S, Szolovits P, 
Murphy S, Kohane I and Cai T, Probabilistic Record Linkage of De-Identified 
Research Datasets Using Diagnosis Codes, <em>Scientific Data</em>, 6:180298 (2019). 
doi: <a href="https://doi.org/10.1038/sdata.2018.298">10.1038/sdata.2018.298</a>.
</p>
<p>Zhang HG, Hejblum BP, Weber G, Palmer N, Churchill S, Szolovits P, 
Murphy S, Liao KP, Kohane I and Cai T, ATLAS: An automated association test using 
probabilistically linked health records with application to genetic studies, 
<em>JAMIA</em>, in press (2021). 
doi: <a href="https://doi.org/10.1101/2021.05.02.21256490">10.1101/2021.05.02.21256490</a>.
</p>

<hr>
<h2 id='agree_C'>Fast C++ implementation of agreement vector for the element-wise comparison of 2 matrices</h2><span id='topic+agree_C'></span><span id='topic+agree_C_sparse'></span>

<h3>Description</h3>

<p><code>agree_C_sparse</code> uses sparse matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agree_C(mat_A, mat_B)

agree_C_sparse(mat_A, mat_B)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="agree_C_+3A_mat_a">mat_A</code></td>
<td>
<p>a <code>nB x K</code> matrix of the observations to be matched. Must be integers.</p>
</td></tr>
<tr><td><code id="agree_C_+3A_mat_b">mat_B</code></td>
<td>
<p>a <code>nA x K</code> matrix of the database into which a match is looked for. Must be integers.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>mat1 &lt;- matrix(round(rnorm(n=1000, sd=1.2)), ncol=10, nrow=100)
mat2 &lt;- rbind(mat1[1:10, ],
             matrix(round(rnorm(n=900, sd=1.2)), ncol=10, nrow=90)
             )
rownames(mat1) &lt;- paste0("A", 1:nrow(mat1))
rownames(mat1) &lt;- paste0("B", 1:nrow(mat1))
mat1 &lt;- 1*(mat1&gt;1)
mat2 &lt;- 1*(mat2&gt;1)

</code></pre>

<hr>
<h2 id='atlas'>Association testing by combining several matching thresholds</h2><span id='topic+atlas'></span>

<h3>Description</h3>

<p>Computes association test p-values from a generalized linear model for each considered 
threshold, and computes a p-value for the combination of all the envisioned thresholds 
through Fisher's method using perturbation resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>atlas(
  match_prob,
  y,
  x,
  covar = NULL,
  thresholds = seq(from = 0.1, to = 0.9, by = 0.2),
  nb_perturb = 200,
  dist_family = c("gaussian", "binomial"),
  impute_strategy = c("weighted average", "best")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="atlas_+3A_match_prob">match_prob</code></td>
<td>
<p>matching probabilities matrix (e.g. obtained through <code><a href="#topic+recordLink">recordLink</a></code>) of 
dimensions <code>n1 x n2</code>.</p>
</td></tr>
<tr><td><code id="atlas_+3A_y">y</code></td>
<td>
<p>response variable of length <code>n1</code>. Only binary phenotypes are supported at the moment.</p>
</td></tr>
<tr><td><code id="atlas_+3A_x">x</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code> of predictors of dimensions <code>n2 x p</code>. 
An intercept is automatically added within the function.</p>
</td></tr>
<tr><td><code id="atlas_+3A_covar">covar</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code> of variables to be adjusted on
in the test of dimensions <code>n3 x p</code>. 
Default is <code>NULL</code> in which case there is no adjustment.</p>
</td></tr>
<tr><td><code id="atlas_+3A_thresholds">thresholds</code></td>
<td>
<p>a vector (possibly of length <code>1</code>) containing the different threshold 
to use to call a match. Default is <code>seq(from = 0.5, to = 0.95, by = 0.05)</code>.</p>
</td></tr>
<tr><td><code id="atlas_+3A_nb_perturb">nb_perturb</code></td>
<td>
<p>the number of perturbation used for the p-value combination.
Default is 200.</p>
</td></tr>
<tr><td><code id="atlas_+3A_dist_family">dist_family</code></td>
<td>
<p>a character string indicating the distribution family for the glm. 
Currently, only <code>'gaussian'</code> and  <code>'binomial'</code> are supported. Default 
is <code>'gaussian'</code>.</p>
</td></tr>
<tr><td><code id="atlas_+3A_impute_strategy">impute_strategy</code></td>
<td>
<p>a character string indicating which strategy to use to impute x 
from the matching probabilities <code>match_prob</code>. Either <code>"best"</code> (in which 
case the highest probable match above the threshold is imputed) or <code>"weighted average"</code>
(in which case weighted mean is imputed for each individual who has at least
one match with a posterior probability above the threshold). Default is 
<code>"weighted average"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following:
</p>

<ul>
<li> <p><code>influencefn_pvals</code> p-values obtained from influence function perturbations
with the covariates as columns and the <code>thresholds</code> as rows, with an additional row 
at the top for the combination 
</p>
</li>
<li> <p><code>wald_pvals</code> a matrix containing the p-values obtained from the Wald 
test with the covariates as columns and the <code>thresholds</code> as rows
</p>
</li>
<li> <p><code>ptbed_pvals</code> a list containing, for each covariates, a matrix with
the <code>nb_perturb</code> perturbed p-values with the different <code>thresholds</code>
as rows
</p>
</li>
<li> <p><code>theta_impute</code> a matrix of the estimated coefficients from the glm when imputing 
the weighted average for covariates (as columns) with the <code>thresholds</code> as rows
</p>
</li>
<li> <p><code>sd_theta</code> a matrix of the estimated SD (from the influence function) of the 
coefficients from the glm when imputing the weighted average for covariates (as columns),
with the <code>thresholds</code> as rows
</p>
</li>
<li> <p><code>ptbed_theta_impute</code> a list containing, for each covariates, a matrix with
the <code>nb_perturb</code> perturbed estimated coefficients from the glm when imputing 
the weighted average for covariates, with the different <code>thresholds</code>
as rows
</p>
</li>
<li> <p><code>impute_strategy</code> a character string indicating which impute 
strategy was used (either <code>"weighted average"</code> or <code>"best"</code>)
</p>
</li></ul>



<h3>References</h3>

<p>Zhang HG, Hejblum BP, Weber G, Palmer N, Churchill S, Szolovits P, 
Murphy S, Liao KP, Kohane I and Cai T, ATLAS: An automated association test using 
probabilistically linked health records with application to genetic studies, 
<em>JAMIA</em>, in press (2021). 
doi: <a href="https://doi.org/10.1101/2021.05.02.21256490">10.1101/2021.05.02.21256490</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#rm(list=ls())

n_sims &lt;- 1#5000

mysim &lt;- function(i){
 x &lt;- matrix(ncol=2, nrow=99, stats::rnorm(n=99*2))
 #plot(density(rbeta(n=1000, 1,2)))
 match_prob &lt;- matrix(rbeta(n=103*99, 1, 2), nrow=103, ncol=99)

 #y &lt;- rnorm(n=103, mean = 1, sd = 0.5)
 #return(atlas(match_prob, y, x, dist_family="gaussian")$influencefn_pvals)
 y &lt;- rbinom(n=103, size = 1, prob=0.5)
 return(atlas(match_prob, y, x, dist_family="binomial")$influencefn_pvals)
}
#res &lt;- pbapply::pblapply(1:n_sims, mysim, cl = parallel::detectCores()-1)
res &lt;- lapply(1:n_sims, mysim)

size &lt;- sapply(1:(ncol(res[[1]])-2), 
              FUN = function(i){
           rowMeans(sapply(res, function(m){m[, i]&lt;0.05}), na.rm = TRUE)
           }
)
rownames(size) &lt;- rownames(res[[1]])
colnames(size) &lt;- colnames(res[[1]])[-(-1:0 + ncol(res[[1]]))]
size
</code></pre>

<hr>
<h2 id='comb_pvals'>Fisher's rule for combining several p-values</h2><span id='topic+comb_pvals'></span>

<h3>Description</h3>

<p>Compute the negative of the log-sum for a vector of p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comb_pvals(pv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comb_pvals_+3A_pv">pv</code></td>
<td>
<p>the vector of p-values to be combined together</p>
</td></tr>
</table>


<h3>Details</h3>

<p>According to Fisher's rule, if the p-values are correlated, then this does not follow a simple chi-square 
mixture under the null.
</p>


<h3>Value</h3>

<p>the Fisher combination of the p-values. See Details.
</p>

<hr>
<h2 id='em_winkler'>Implementation of Winkler's EM algorithm for Fellegi-Sunter matching method</h2><span id='topic+em_winkler'></span><span id='topic+em_winkler_big'></span>

<h3>Description</h3>

<p><code>em_winkler_big</code> implements the same method when the data are too big to compute 
the agreement matrix. Agreement is then recomputed on the fly each time it is needed. The EM steps 
are completely done in C++. This decreases the RAM usage (still important though), at the cost of 
increasing computational time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>em_winkler(
  data1,
  data2,
  tol = 0.001,
  maxit = 500,
  do_plot = TRUE,
  oneone = FALSE,
  verbose = FALSE
)

em_winkler_big(
  data1,
  data2,
  tol = 0.001,
  maxit = 500,
  do_plot = TRUE,
  oneone = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="em_winkler_+3A_data1">data1</code></td>
<td>
<p>either a binary (<code>1</code> or <code>0</code> values only) matrix or binary 
data frame of dimension <code>n1 x K</code> whose rownames are the observation identifiers.</p>
</td></tr>
<tr><td><code id="em_winkler_+3A_data2">data2</code></td>
<td>
<p>either a binary (<code>1</code> or <code>0</code> values only) matrix or a binary
data frame of dimension <code>n2 x K</code> whose rownames are the observation identifiers.</p>
</td></tr>
<tr><td><code id="em_winkler_+3A_tol">tol</code></td>
<td>
<p>tolerance for the EM algorithm convergence.</p>
</td></tr>
<tr><td><code id="em_winkler_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations for the EM algorithm.</p>
</td></tr>
<tr><td><code id="em_winkler_+3A_do_plot">do_plot</code></td>
<td>
<p>a logical flag indicating whether a plot should be drawn for the EM convergence. 
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="em_winkler_+3A_oneone">oneone</code></td>
<td>
<p>a logical flag indicating whether 1-1 matching should be enforced. 
If <code>TRUE</code>, then returned <code>matchingScores</code> are only kept for the maximum 
score per column while lower scores are replace by <code>threshold-1</code>. 
Default is <code>FALSE</code> in which case original <code>matchingScores</code> are returned.</p>
</td></tr>
<tr><td><code id="em_winkler_+3A_verbose">verbose</code></td>
<td>
<p>a logical flag indicating whether intermediate values from the EM algorithm should 
be printed. Useful for debugging. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing:
</p>

<ul>
<li><p><code>matchingScore</code> a matrix of size <code>n1 x n2</code> with the matching score for each <code>n1*n2</code> pair.
</p>
</li>
<li><p><code>threshold_ms</code> threshold value for the matching scores above which pairs are considered true matches.
</p>
</li>
<li><p><code>estim_nbmatch</code> an estimation of the number of true matches (<code>N</code> pairs 
considered multiplied by <code>p</code> the estimated proportion of true matches from the EM algorithm) 
</p>
</li>
<li><p><code>convergence_status</code> a logical flag indicating whether the EM algorithm converged
</p>
</li></ul>



<h3>References</h3>

<p>Winkler WE. Using the EM Algorithm for Weight Computation in the Fellegi-Sunter Model of Record Linkage. <em>Proc Sect Surv Res Methods</em>, Am Stat Assoc 1988: 667-71.
</p>
<p>Grannis SJ, Overhage JM, Hui S, <em>et al</em>. Analysis of a probabilistic record linkage technique without human review. <em>AMIA 2003 Symp Proc</em> 2003: 259-63.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat1 &lt;- matrix(round(rnorm(n=1000, sd=1.2)), ncol=10, nrow=100)
mat2 &lt;- rbind(mat1[1:10, ],
             matrix(round(rnorm(n=900, sd=1.2)), ncol=10, nrow=90)
             )
rownames(mat1) &lt;- paste0("A", 1:nrow(mat1))
rownames(mat1) &lt;- paste0("B", 1:nrow(mat1))
mat1 &lt;- 1*(mat1&gt;1)
mat2 &lt;- 1*(mat2&gt;1)
em_winkler(mat1, mat2)

</code></pre>

<hr>
<h2 id='EMstep_C_sparse_big'>C++ implementation of the E and M steps from Winkler's EM algorithm estimating FS method 
using sparse matrices for big sample sizes</h2><span id='topic+EMstep_C_sparse_big'></span>

<h3>Description</h3>

<p>C++ implementation of the E and M steps from Winkler's EM algorithm estimating FS method 
using sparse matrices for big sample sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMstep_C_sparse_big(mat_A, mat_B, p, m, u)
</code></pre>

<hr>
<h2 id='estep_C_vect'>Fast C++ implementation of Winkler's Method E step</h2><span id='topic+estep_C_vect'></span>

<h3>Description</h3>

<p>Fast C++ implementation of Winkler's Method E step
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estep_C_vect(agreemat, p, m, u)
</code></pre>

<hr>
<h2 id='logit'>Logit link function</h2><span id='topic+logit'></span><span id='topic+expit'></span><span id='topic+expit_dev1'></span>

<h3>Description</h3>

<p>inverse of the logistic transformation function
</p>
<p>logistic transformation function
</p>
<p>logistic transformation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(p)

expit(x)

expit_dev1(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_+3A_p">p</code></td>
<td>
<p>a real number in [0,1] to be transformed to the real scale 
( ]-infinity,infinity[ )</p>
</td></tr>
<tr><td><code id="logit_+3A_x">x</code></td>
<td>
<p>a real number in ]-infinity,infinity[ to be transformed to the 
probability scale ( [0,1] )</p>
</td></tr>
</table>

<hr>
<h2 id='loglikC_bin'>C++ implementation of the pseudo-likelihood computation</h2><span id='topic+loglikC_bin'></span><span id='topic+loglikC_bin_wDates'></span><span id='topic+loglikratioC_diff_arbitrary'></span>

<h3>Description</h3>

<p><code>loglikC_bin</code> implements an even faster C++ implementation of the pseudo-likelihood computation for binary
variables
</p>
<p><code>loglikC_bin_wDates</code> implements a C++ implementation of the pseudo-likelihood computation for binary
variables with dates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglikC_bin(Bmat, Amat, eps_p, eps_n, piA, piB)

loglikC_bin_wDates(Bmat, Amat, Bdates, Adates, eps_p, eps_n, piA, piB)

loglikratioC_diff_arbitrary(Bmat, Amat, d_max, cost)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglikC_bin_+3A_bmat">Bmat</code></td>
<td>
<p><code>K x nB</code> matrix of the observations to be matched.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_amat">Amat</code></td>
<td>
<p><code>nA x K</code> matrix the database into which a match is looked for.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_eps_p">eps_p</code></td>
<td>
<p>a vector of length <code>K</code> giving the prior discrepancy rate 
expected from A to B for the positives, for each variable.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_eps_n">eps_n</code></td>
<td>
<p>a vector of length <code>K</code> giving the prior discrepancy rate 
expected from A to B for the negatives, for each variable.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_pia">piA</code></td>
<td>
<p>a vector of length <code>K</code> giving the prior probabilities of 
observing each variable in A.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_pib">piB</code></td>
<td>
<p>a vector of length <code>K</code> giving the prior probabilities of 
observing each variable in B.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_bdates">Bdates</code></td>
<td>
<p><code>nB x K</code> matrix of the dates for each observations to be matched.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_adates">Adates</code></td>
<td>
<p><code>nA x K</code> matrix of the dates for database into which a match is looked for.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_d_max">d_max</code></td>
<td>
<p>a numeric vector of length <code>K</code> giving the minimum difference 
from which it is considered a discrepancy.</p>
</td></tr>
<tr><td><code id="loglikC_bin_+3A_cost">cost</code></td>
<td>
<p>a numeric vector of length <code>K</code> giving the arbitrary cost of discrepancy.</p>
</td></tr>
</table>

<hr>
<h2 id='matching_score'>Computes a matching score from agreement vectors and weights</h2><span id='topic+matching_score'></span>

<h3>Description</h3>

<p>Computes a matching score from agreement vectors and weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matching_score(agree, m, u)
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>estep_vect &lt;- function(ag_score, p, m, u){
  a &lt;-exp(log(p) + ag_score%*%log(m) + (1-ag_score)%*%log(1-m))
  b &lt;- exp(log(1-p) + ag_score%*%log(u) + (1-ag_score)%*%log(1-u))
  return(cbind(a/(a+b), b/(a+b)))
}


</code></pre>

<hr>
<h2 id='matchingScore_C'>Fast C++ computation of the final posterior probabilities in the E-M Winkler's method</h2><span id='topic+matchingScore_C'></span><span id='topic+matchingScore_C_sparse_big'></span>

<h3>Description</h3>

<p><code>matchingScore_C_sparse_big</code> implements a version using sparse matrices. It has a better 
management of memory but is a little bit slower (indicated for big matrices)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchingScore_C(agreemat, m, u, nA, nB)

matchingScore_C_sparse_big(mat_A, mat_B, m, u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matchingScore_C_+3A_agreemat">agreemat</code></td>
<td>
<p>binary sparse matrix of dimensions <code>N x K</code> containing the agreement rows for each pair of potential matches.</p>
</td></tr>
<tr><td><code id="matchingScore_C_+3A_m">m</code></td>
<td>
<p>vector of length <code>K</code> containing the agreement weights.</p>
</td></tr>
<tr><td><code id="matchingScore_C_+3A_u">u</code></td>
<td>
<p>vector of length <code>K</code> containing the disagreement weights.</p>
</td></tr>
<tr><td><code id="matchingScore_C_+3A_na">nA</code></td>
<td>
<p>integer indicating the number of observations to be matched.</p>
</td></tr>
<tr><td><code id="matchingScore_C_+3A_nb">nB</code></td>
<td>
<p>integer indicating the number of observations to be matched with.</p>
</td></tr>
<tr><td><code id="matchingScore_C_+3A_mat_a">mat_A</code></td>
<td>
<p>a <code>nB x K</code> matrix of the observations to be matched.</p>
</td></tr>
<tr><td><code id="matchingScore_C_+3A_mat_b">mat_B</code></td>
<td>
<p>a <code>nA x K</code> matrix of the database into which a match is looked for.</p>
</td></tr>
</table>

<hr>
<h2 id='matchProbs_rank_full_C'>Compute the matching probabilities for each pair of observations</h2><span id='topic+matchProbs_rank_full_C'></span>

<h3>Description</h3>

<p>C++ version: for each observations in <code>(1:n)</code>, all the matching probabilities are computed
for the <code>p</code> possible pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matchProbs_rank_full_C(computed_dist, prop_match)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matchProbs_rank_full_C_+3A_computed_dist">computed_dist</code></td>
<td>
<p>a <code>n x p</code> matrix of computed distances used for ranking.</p>
</td></tr>
<tr><td><code id="matchProbs_rank_full_C_+3A_prop_match">prop_match</code></td>
<td>
<p>a priori proportion of matches (&quot;rho_1&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>n x p</code> matrix containing the matching probabilities for each pair
</p>

<hr>
<h2 id='pval_zscore'>Compute p-values for a Z-score</h2><span id='topic+pval_zscore'></span>

<h3>Description</h3>

<p>Compute p-values for a Z-score assuming normal distribution of the z-score 
under the null Hypothesis H0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pval_zscore(beta, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pval_zscore_+3A_beta">beta</code></td>
<td>
<p>the estimate</p>
</td></tr>
<tr><td><code id="pval_zscore_+3A_sigma">sigma</code></td>
<td>
<p>estimate's estimated variance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the p-value
</p>

<hr>
<h2 id='RA'>Anonymized binarized diagnosis codes from RA study.</h2><span id='topic+RA'></span><span id='topic+RA1_6y'></span><span id='topic+RA2_6y'></span><span id='topic+RA1_11y'></span><span id='topic+RA2_11y'></span><span id='topic+silverstandard_truematches'></span>

<h3>Description</h3>

<p>An anonymized version of the binarized diagnosis code data from the RA1 and RA2 
datasets, over both 6-year and 11-year time span.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(RA)
</code></pre>


<h3>Format</h3>

<p>5 objects</p>

<ul>
<li><p><code>RA1_6y</code>: an integer matrix of 0s and 1s containing 4,936 
renamed diagnosis codes for 26,681 patients from the dataset RA1 recorded 
over a 6-year time span.
</p>
</li>
<li><p><code>RA2_6y</code>: an integer matrix of 0s and 1s containing 4,936 
renamed diagnosis codes for 5,707 patients from the dataset RA2 recorded 
over a 6-year time span.
</p>
</li>
<li><p><code>RA1_11y</code>: an integer matrix of 0s and 1s containing 5,593 
renamed diagnosis codes for 26,687 patients from the dataset RA1 recorded 
over a 11-year time span.
</p>
</li>
<li><p><code>RA2_11y</code>: an integer matrix of 0s and 1s containing 5,593 
renamed diagnosis codes for 6,394 patients from the dataset RA2 recorded 
over a 11-year time span.
</p>
</li>
<li><p><code>silverstandard_truematches</code>: a character matrix with two 
columns containing the identifiers of the 3,831 pairs of silver-standard 
matches.
</p>
</li></ul>



<h3>Details</h3>

<p>The ICD-9 diagnosis codes have also been masked and randomly reordered, replaced by 
meaningless names. Finally, the silver-standard matching pairs are also provided to 
allow the benchmarking of methods for probabilistic record linkage using diagnosis codes.
</p>


<h3>References</h3>

<p>Hejblum BP, Weber G, Liao KP, Palmer N, Churchill S, Szolovits P, 
Murphy S, Kohane I and Cai T, Probabilistic Record Linkage of De-Identified 
Research Datasets Using Diagnosis Codes, <em>Scientific Data</em>, 6:180298 (2019). 
doi: <a href="https://doi.org/10.1038/sdata.2018.298">10.1038/sdata.2018.298</a>.
</p>
<p>Liao, K. P. et al. Electronic medical records for discovery research 
in rheumatoid arthritis. <em>Arthritis Care &amp; Research</em> 62, 1120-1127 (2010). 
doi: <a href="https://doi.org/10.1002/acr.20184">10.1002/acr.20184</a>
</p>
<p>Liao, K. P. et al. Methods to Develop an Electronic Medical Record 
Phenotype Algorithm to Compare the Risk of Coronary Artery Disease across 3 
Chronic Disease Cohorts. <em>PLoS ONE</em> 10, e0136651 (2015). 
doi: <a href="https://doi.org/10.1371/journal.pone.0136651">10.1371/journal.pone.0136651</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(interactive()){
rm(list=ls())
library(ludic)
data(RA)
res_match_6y &lt;- recordLink(data1 = RA1_6y, data2 = RA2_6y, 
                          eps_plus = 0.01, eps_minus = 0.01,
                          aggreg_2ways ="mean",
                          min_prev = 0,
                          use_diff = FALSE)

res_match_11y &lt;- recordLink(data1 = RA1_11y, data2 = RA2_11y, 
                           eps_plus = 0.01, eps_minus = 0.01,
                           aggreg_2ways ="mean",
                           min_prev = 0,
                           use_diff = FALSE)


print.res_matching &lt;- function(res, threshold=0.9, ref=silverstandard_truematches){
 have_match_row &lt;- rowSums(res&gt;threshold)
 have_match_col &lt;- colSums(res&gt;threshold)
 bestmatched_pairs_all &lt;- cbind.data.frame(
   "D1"=rownames(res)[apply(res[,which(have_match_col&gt;0), drop=FALSE], 2, which.max)],
   "D2"=names(have_match_col)[which(have_match_col&gt;0)]
 )
 nTM_all &lt;- nrow(ref)
 nP_all &lt;- nrow(bestmatched_pairs_all)
 TPR_all &lt;- sum(apply(bestmatched_pairs_all, 1, paste0, collapse="") 
                %in% apply(ref, 1, paste0, collapse=""))/nTM_all
 PPV_all &lt;- sum(apply(bestmatched_pairs_all, 1, paste0, collapse="") 
                %in% apply(ref, 1, paste0, collapse=""))/nP_all
 cat("threshold: ", threshold, 
     "\nnb matched: ", nP_all,"; nb true matches: ", nTM_all, 
     "\nTPR: ", TPR_all, ";   PPV: ", PPV_all, "\n\n", sep="")
}
print.res_matching(res_match_6y)
print.res_matching(res_match_11y)

}

</code></pre>

<hr>
<h2 id='recordLink'>Probabilistic Patient Record Linkage</h2><span id='topic+recordLink'></span>

<h3>Description</h3>

<p>Probabilistic Patient Record Linkage
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recordLink(
  data1,
  data2,
  dates1 = NULL,
  dates2 = NULL,
  eps_plus,
  eps_minus,
  aggreg_2ways = "mean",
  min_prev = 0.01,
  data1_cont2diff = NULL,
  data2_cont2diff = NULL,
  d_max,
  use_diff = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recordLink_+3A_data1">data1</code></td>
<td>
<p>either a binary (<code>1</code> or <code>0</code> values only) matrix or binary 
data frame of dimension <code>n1 x K</code> whose rownames are the observation identifiers.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_data2">data2</code></td>
<td>
<p>either a binary (<code>1</code> or <code>0</code> values only) matrix or a binary
data frame of dimension <code>n2 x K</code> whose rownames are the observation identifiers. 
Columns should be in the same order as in <code>data1</code>.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_dates1">dates1</code></td>
<td>
<p>matrix or dataframe of dimension <code>n1 x K</code> including the concatenated dates intervals for each corresponding 
diagnosis codes in <code>data1</code>. Default is <code>NULL</code> in which case dates are not used.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_dates2">dates2</code></td>
<td>
<p>matrix or dataframe of dimension <code>n2 x K</code> including the concatenated dates intervals for each corresponding 
diagnosis codes in <code>data2</code>. Default is <code>NULL</code> in which case dates are not used. See details.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_eps_plus">eps_plus</code></td>
<td>
<p>discrepancy rate between <code>data1</code> and <code>data2</code></p>
</td></tr>
<tr><td><code id="recordLink_+3A_eps_minus">eps_minus</code></td>
<td>
<p>discrepancy rate between <code>data2</code> and <code>data1</code></p>
</td></tr>
<tr><td><code id="recordLink_+3A_aggreg_2ways">aggreg_2ways</code></td>
<td>
<p>a character string indicating how to merge the posterior two 
probability matrices obtained for each of the 2 databases. Four possibility are 
currently implemented: <code>"maxnorm"</code>, <code>"max"</code>, <code>"min"</code>, <code>"mean"</code> 
and <code>"prod"</code>. Default is <code>"mean"</code>.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_min_prev">min_prev</code></td>
<td>
<p>minimum prevalence for the variables used in matching.
Default is 1%.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_data1_cont2diff">data1_cont2diff</code></td>
<td>
<p>either a matrix or dataframe of continuous features, 
such as age, for which the similarity measure uses the difference with 
<code>data2_cont2diff</code>, whose rownames are . Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_data2_cont2diff">data2_cont2diff</code></td>
<td>
<p>either a matrix or dataframe of continuous features, 
such as age, for which the similarity measure uses the difference with 
<code>data2_cont1diff</code>, whose rownames are . Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_d_max">d_max</code></td>
<td>
<p>a numeric vector of length <code>K</code> giving the minimum difference 
from which it is considered a discrepancy.</p>
</td></tr>
<tr><td><code id="recordLink_+3A_use_diff">use_diff</code></td>
<td>
<p>logical flag indicating whether continuous differentiable variables should be used in the</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Dates:</code> the use of <code>dates1</code> and <code>dates2</code> requires that at least one date interval matches across 
<code>dates1</code> and <code>dates2</code> for claiming an agreement on a diagnosis code between <code>data1</code> and <code>data2</code>, 
in addition of having that very same code recorded in both.
</p>


<h3>Value</h3>

<p>a matrix of size <code>n1 x n2</code> with the posterior probability of matching for each <code>n1*n2</code> pair
</p>


<h3>References</h3>

<p>Hejblum BP, Weber G, Liao KP, Palmer N, Churchill S, Szolovits P, 
Murphy S, Kohane I and Cai T, Probabilistic Record Linkage of De-Identified 
Research Datasets Using Diagnosis Codes, <em>Scientific Data</em>, 6:180298 (2019). 
doi: <a href="https://doi.org/10.1038/sdata.2018.298">10.1038/sdata.2018.298</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
ncodes &lt;- 500
npat &lt;- 200
incid &lt;- abs(rnorm(n=ncodes, 0.15, 0.07))
bin_codes &lt;- rbinom(n=npat*ncodes, size=1,  prob=rep(incid, npat))
bin_codes_mat &lt;- matrix(bin_codes, ncol=ncodes, byrow = TRUE)
data1_ex &lt;- bin_codes_mat[1:(npat/2+npat/10),]
data2_ex &lt;- bin_codes_mat[c(1:(npat/10), (npat/2+npat/10 + 1):npat), ]
rownames(data1_ex) &lt;- paste0("ID", 1:(npat/2+npat/10), "_data1")
rownames(data2_ex) &lt;- paste0("ID", c(1:(npat/10), (npat/2+npat/10 + 1):npat), "_data2")

if(interactive()){
res &lt;- recordLink(data1 = data1_ex, data2 = data2_ex, 
                 use_diff = FALSE, eps_minus = 0.01, eps_plus = 0.01)
round(res[c(1:3, 19:23), c(1:3, 19:23)], 3)
}

</code></pre>

<hr>
<h2 id='strsplitC'>Splitting a character string in C++</h2><span id='topic+strsplitC'></span>

<h3>Description</h3>

<p>Splitting a character string in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strsplitC(s, sep)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strsplitC_+3A_s">s</code></td>
<td>
<p>a character string to be split</p>
</td></tr>
<tr><td><code id="strsplitC_+3A_sep">sep</code></td>
<td>
<p>a character that delimits the splits</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>strsplitC(c(";aaa;bb;cccc;ee;"), sep=";")
</code></pre>

<hr>
<h2 id='test_han2018'>Association testing using Han &amp; Lahiri estimating equations and jackknife approach</h2><span id='topic+test_han2018'></span>

<h3>Description</h3>

<p>Association testing using Han &amp; Lahiri estimating equations and jackknife approach
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_han2018(
  match_prob,
  y,
  x,
  covar_y = NULL,
  covar_x = NULL,
  jackknife_nrep = 100,
  jackknife_blocksize = max(floor(min(length(y), nrow(x))/jackknife_nrep), 1),
  methods = c("F", "M", "M2"),
  dist_family = c("gaussian", "binomial")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test_han2018_+3A_match_prob">match_prob</code></td>
<td>
<p>matching probabilities matrix (e.g. obtained through <code><a href="#topic+recordLink">recordLink</a></code>) of 
dimensions <code>n1 x n2</code>.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_y">y</code></td>
<td>
<p>response variable of length <code>n1</code>. Only binary or gaussian phenotypes 
are supported at the moment.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_x">x</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code> of predictors of dimensions <code>n2 x p</code>. 
An intercept is automatically added within the function.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_covar_y">covar_y</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code> of predictors of dimensions <code>n1 x q1</code>. 
An intercept is automatically added within the function.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_covar_x">covar_x</code></td>
<td>
<p>a <code>matrix</code> or a <code>data.frame</code> of predictors of dimensions <code>n2 x q2</code>. 
An intercept is automatically added within the function.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_jackknife_nrep">jackknife_nrep</code></td>
<td>
<p>the number of jackknife repetitions.
Default is 100 (from Han et al.).</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_jackknife_blocksize">jackknife_blocksize</code></td>
<td>
<p>the number of observations to remove in each jackknife.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_methods">methods</code></td>
<td>
<p>a character vector which must be a subset of <code>("F", "M", "M2")</code> 
indicating which estimator from Han et al. 2018 should be computed. Default is all 3.</p>
</td></tr>
<tr><td><code id="test_han2018_+3A_dist_family">dist_family</code></td>
<td>
<p>a character string indicating the distribution family for the glm. 
Currently, only <code>'gaussian'</code> and  <code>'binomial'</code> are supported. Default 
is <code>'gaussian'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following for each estimator in <code>methods</code>:
</p>

<ul>
<li> <p><code>beta</code> a vector containing the <code>p</code> estimated coefficients
</p>
</li>
<li> <p><code>varcov</code> the <code>p x p</code> variance-covariance <code>matrix</code> of the <code>beta</code> coefficients
</p>
</li>
<li> <p><code>zscores</code> a vector containing the <code>p</code> Z-scores
</p>
</li>
<li> <p><code>pval</code> the corresponding Gaussian assumption p-values
</p>
</li></ul>



<h3>References</h3>

<p>Han, Y., and Lahiri, P. (2019) Statistical Analysis with Linked Data. 
International Statistical Review, 87: S139– S157. 
doi: <a href="https://doi.org/10.1111/insr.12295">10.1111/insr.12295</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># rm(list=ls())
# n_sims &lt;- 500
# res &lt;- pbapply::pblapply(1:n_sims, function(n){
# nx &lt;- 99
# ny &lt;- 103
# x &lt;- matrix(ncol=2, nrow=ny, stats::rnorm(n=ny*2))
# 
# #plot(density(rbeta(n=1000, 1,2)))
# match_prob &lt;- diag(ny)[, 1:nx]#matrix(rbeta(n=ny*nx, 1, 2), nrow=ny, ncol=99)
# 
# covar_y &lt;- matrix(rnorm(n=ny, 1, 0.5), ncol=1)
# covar_x &lt;- matrix(ncol=3, nrow=ny, stats::rnorm(n=ny*3))
# 
# #y &lt;- rnorm(n=ny, mean = x %*% c(2,-3)  + covar_x %*% rep(0.2, ncol(covar_x)) + 0.5*covar_y, 0.5)
# y &lt;- rbinom(n=ny, 1, prob=expit(x %*% c(2,-3)  + covar_x %*% 
#             rep(0.2, ncol(covar_x)) + 0.5*covar_y))
# #glm(y~0+x+covar_y+covar_x, family = "binomial")
# return(
# #test_han2018(match_prob, y, x, jackknife_blocksize = 10, covar_x = NULL, covar_y = NULL)
# test_han2018(match_prob, y[1:ny], x[1:nx, ], dist_family = "binomial", 
#              jackknife_blocksize = 10, covar_x = covar_x[1:nx, ], 
#              covar_y = covar_y[1:ny, , drop=FALSE])
# )
# }, cl=parallel::detectCores()-1)
# pvals_F &lt;- sapply(lapply(res, "[[", "F"), "[[", "beta")
# pvals_M &lt;- sapply(lapply(res, "[[", "M"), "[[", "beta")
# pvals_M2 &lt;- sapply(lapply(res, "[[", "M2"), "[[", "beta")
# quantile(pvals_F)
# quantile(pvals_M)
# quantile(pvals_M2)
# rowMeans(pvals_F&lt;0.05)
# rowMeans(pvals_M&lt;0.05)
# rowMeans(pvals_M2&lt;0.05)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
