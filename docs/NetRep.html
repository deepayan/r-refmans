<!DOCTYPE html><html><head><title>Help for package NetRep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NetRep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#NetRep'><p>Fast permutation procedure for testing network module replication</p></a></li>
<li><a href='#combineAnalyses'><p>Combine results of multiple permutation procedures</p></a></li>
<li><a href='#common_params'><p>Template parameters</p></a></li>
<li><a href='#disk.matrix'><p>The 'disk.matrix' class</p></a></li>
<li><a href='#example-data'><p>Example data</p></a></li>
<li><a href='#load.bigMatrix'><p>Load a 'bigMatrix' (deprecated)</p></a></li>
<li><a href='#modulePreservation'><p>Replication and preservation of network modules across datasets</p></a></li>
<li><a href='#networkProperties'><p>Calculate the topological properties for a network module</p></a></li>
<li><a href='#nodeOrder'><p>Order nodes in descending order of <em>weighted degree</em> and order</p>
modules by the similarity of their summary vectors.</a></li>
<li><a href='#orderModules_param'><p>Template parameters</p></a></li>
<li><a href='#permutationTest'><p>Permutation test P-values for module preservation statistics</p></a></li>
<li><a href='#plot_params'><p>Template parameters</p></a></li>
<li><a href='#plotModule'><p>Plot the topology of a network module</p></a></li>
<li><a href='#plotTopology'><p>Plot a topological feature of network module</p></a></li>
<li><a href='#requiredPerms'><p>How many permutations do I need to test at my desired significance level?</p></a></li>
<li><a href='#sampleOrder'><p>Order samples within a network.</p></a></li>
<li><a href='#simplify_param'><p>Template parameters</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Permutation Testing Network Module Preservation Across Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.7</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/sritchie73/NetRep/issues">https://github.com/sritchie73/NetRep/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for assessing the replication/preservation of a network 
  module's topology across datasets through permutation testing; Ritchie et al. 
  (2015) &lt;<a href="https://doi.org/10.1016%2Fj.cels.2016.06.012">doi:10.1016/j.cels.2016.06.012</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach, Rcpp (&ge; 0.11), statmod, RhpcBLASctl, abind,
RColorBrewer, utils, stats, graphics, grDevices</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bigmemory, testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, BH, RcppArmadillo (&ge; 0.4)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-19 14:45:26 UTC; scritchie</td>
</tr>
<tr>
<td>Author:</td>
<td>Scott Ritchie [aut, cre] (0000-0002-8454-9548)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Scott Ritchie &lt;sritchie73@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-19 15:12:32 UTC</td>
</tr>
</table>
<hr>
<h2 id='NetRep'>Fast permutation procedure for testing network module replication</h2><span id='topic+NetRep'></span><span id='topic+NetRep-package'></span>

<h3>Description</h3>

<p>Functions for assessing the replication/preservation of a network module's 
topology across datasets through permutation testing. This is suitable for 
networks that can be meaningfully inferred from multiple datasets. These 
include gene coexpression networks, protein-protein interaction networks, and
microbial interaction networks. Modules within these networks consist of 
groups of nodes that are particularly interesting: for example a group of 
tightly connected genes associated with a disease, groups of genes annotated
with the same term in the Gene Ontology database, or groups of interacting
microbial species, i.e. communities. Application of this method can answer
questions such as; (1) do the relationships between genes in a module 
replicate in an independent cohort? (2) are these gene coexpression modules
preserved across tissues or tissue specific? (3) are these modules conserved
across species? (4) are microbial communities preserved across multiple spatial
locations?
</p>


<h3>Details</h3>

<p>The main function for this package is <code><a href="#topic+modulePreservation">modulePreservation</a></code>. 
Several functions for downstream are also provided: 
<code><a href="#topic+networkProperties">networkProperties</a></code> for calculating the topological properties 
of a module, and <code><a href="#topic+plotModule">plotModule</a></code> for visualising a module.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Scott Ritchie <a href="mailto:sritchie73@gmail.com">sritchie73@gmail.com</a> (0000-0002-8454-9548)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li><p> Report bugs at <a href="https://github.com/sritchie73/NetRep/issues">https://github.com/sritchie73/NetRep/issues</a>
</p>
</li></ul>


<hr>
<h2 id='combineAnalyses'>Combine results of multiple permutation procedures</h2><span id='topic+combineAnalyses'></span>

<h3>Description</h3>

<p>This function takes the output from multiple runs of 
<code><a href="#topic+modulePreservation">modulePreservation</a></code>, combines their results, and returns a new
set of permutation test P-values. This is useful for parallelising 
calculations across multiple machines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combineAnalyses(pres1, pres2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combineAnalyses_+3A_pres1">pres1</code>, <code id="combineAnalyses_+3A_pres2">pres2</code></td>
<td>
<p>lists returned by <code><a href="#topic+modulePreservation">modulePreservation</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calls to 'modulePreservation' must have been identical for both input
lists, with the exception of the number of threads used and the number of
permutations calculated.
</p>


<h3>Value</h3>

<p>A nested list containing the same elements as 
<code><a href="#topic+modulePreservation">modulePreservation</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

pres1 &lt;- modulePreservation(
 network=network_list, data=data_list, correlation=correlation_list,
 moduleAssignments=labels_list, nPerm=1000, discovery="discovery", 
 test="test", nThreads=2
)

pres2 &lt;- modulePreservation(
 network=network_list, data=data_list, correlation=correlation_list, 
 moduleAssignments=labels_list, nPerm=1000, discovery="discovery", 
 test="test", nThreads=2
)

combined &lt;- combineAnalyses(pres1, pres2)

</code></pre>

<hr>
<h2 id='common_params'>Template parameters</h2><span id='topic+common_params'></span>

<h3>Description</h3>

<p>Template parameters to be imported into other function documentation. This 
is not intended to be a stand-alone help file.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="common_params_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="common_params_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="common_params_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="common_params_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="common_params_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="common_params_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="common_params_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="common_params_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="common_params_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='disk.matrix'>The 'disk.matrix' class</h2><span id='topic+disk.matrix'></span><span id='topic+attach.disk.matrix'></span><span id='topic+serialize.table'></span><span id='topic+is.disk.matrix'></span><span id='topic+as.disk.matrix'></span><span id='topic+as.disk.matrix+2Cdisk.matrix-method'></span><span id='topic+as.disk.matrix+2Cmatrix-method'></span><span id='topic+as.disk.matrix+2CANY-method'></span><span id='topic+as.matrix+2Cdisk.matrix-method'></span><span id='topic+show+2Cdisk.matrix-method'></span>

<h3>Description</h3>

<p>A <code>'disk.matrix'</code> contains a file path to a matrix stored on disk,
along with meta data for how to read that file. This allows <span class="pkg">NetRep</span>
to load datasets into RAM only when required, i.e. one at a time. This 
significantly reduces the memory usage of R when analysing large datasets.
<code>'disk.matrix'</code> objects may be supplied instead of <code>'matrix'</code> 
objects in the input list arguments <code>'network'</code>, <code>'data'</code>, and 
<code>'correlation'</code>, which are common to most of <span class="pkg">NetRep</span>'s functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>attach.disk.matrix(file, serialized = TRUE, ...)

serialize.table(file, ...)

is.disk.matrix(x)

as.disk.matrix(x, file, serialize = TRUE)

## S4 method for signature 'disk.matrix'
as.disk.matrix(x, file, serialize = TRUE)

## S4 method for signature 'matrix'
as.disk.matrix(x, file, serialize = TRUE)

## S4 method for signature 'ANY'
as.disk.matrix(x, file, serialize = TRUE)

## S4 method for signature 'disk.matrix'
as.matrix(x)

## S4 method for signature 'disk.matrix'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disk.matrix_+3A_file">file</code></td>
<td>
<p>for <code>attach.disk.matrix</code> the file name of a matrix on disk. 
For <code>as.disk.matrix</code> the file name to save the matrix to. For 
<code>serialize.table</code> the file name of a matrix in table format on disk.</p>
</td></tr>
<tr><td><code id="disk.matrix_+3A_serialized">serialized</code></td>
<td>
<p>determines how the matrix will be loaded from disk into R
by <code>as.matrix</code>. If <code>TRUE</code>, the <code>readRDS</code> function 
will be used. If <code>FALSE</code>, the <code>read.table</code> function will 
be used.</p>
</td></tr>
<tr><td><code id="disk.matrix_+3A_...">...</code></td>
<td>
<p>arguments to be used by <code>read.table</code> when reading in matrix 
data from a file in table format.</p>
</td></tr>
<tr><td><code id="disk.matrix_+3A_x">x</code></td>
<td>
<p>for <code>as.matrix</code> a <code>disk.matrix</code> object to load into R. 
For <code>as.disk.matrix</code> an object to convert to a <code>disk.matrix</code>. For 
<code>is.disk.matrix</code> an object to check if its a <code>disk.matrix</code>.</p>
</td></tr>
<tr><td><code id="disk.matrix_+3A_serialize">serialize</code></td>
<td>
<p>determines how the matrix is saved to disk by 
<code>as.disk.matrix</code>. If <code>TRUE</code> it will be stored as a serialized R 
object using <code>saveRDS</code>. If <code>FALSE</code> it will be stored as a 
tab-separated file using <code>write.table</code>.</p>
</td></tr>
<tr><td><code id="disk.matrix_+3A_object">object</code></td>
<td>
<p>a <code>'disk.matrix'</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Matrices may either be stored as regular table files that can be read by
<code><a href="utils.html#topic+read.table">read.table</a></code>, or as serialized R objects that can be read by
<code><a href="base.html#topic+readRDS">readRDS</a></code>. Serialized objects are much faster to load, but 
cannot be read by other programs. 
</p>
<p>The <code>attach.disk.matrix</code> function creates a <code>disk.matrix</code> object
from a file path. The <code>as.matrix</code> function will load the data from disk
into the R session as a regular <code><a href="base.html#topic+matrix">matrix</a></code> object.
</p>
<p>The <code>as.disk.matrix</code> function converts a matrix into a 
<code>disk.matrix</code> by saving its contents to the specified <code>file</code>. The
<code>serialize</code> argument determines whether the data is stored as a 
serialized R object or as a tab-separated file (i.e. <code>sep="\t"</code>). We
recommend storing the matrix as a serialized R object unless disk space is
a concern. More control over the storage format can be obtained by using
<code>saveRDS</code> or <code>write.table</code> directly.
</p>
<p>The <code>serialize.matrix</code> function converts a file in table format to a
serialized R object with the same file name, but with the &quot;.rds&quot; extension.
</p>


<h3>Value</h3>

<p>A <code>disk.matrix</code> object (<code>attach.disk.matrix</code>, <code>as.disk.matrix</code>),
a <code>matrix</code> (<code>as.matrix</code>), the file path to a serialized matrix
(<code>serialize.table</code>), or a <code>TRUE</code> or <code>FALSE</code> indicating 
whether an object is a <code>disk.matrix</code> (<code>is.disk.matrix</code>).
</p>


<h3>Slots</h3>


<dl>
<dt><code>file</code></dt><dd><p>the name of the file where the matrix is saved.</p>
</dd>
<dt><code>read.func</code></dt><dd><p>either <code>"read.table"</code> or <code>"readRDS"</code>.</p>
</dd>
<dt><code>func.args</code></dt><dd><p>a list of arguments to be supplied to the <code>'read.func'</code>.</p>
</dd>
</dl>


<h3>Warning</h3>

<p><code>attach.disk.matrix</code> does not check whether the specified file can be
read into R. <code>as.matrix</code> will fail and throw an error if this is the
case.
</p>

<hr>
<h2 id='example-data'>Example data</h2><span id='topic+example-data'></span><span id='topic+NetRep-data'></span><span id='topic+discovery_network'></span><span id='topic+discovery_data'></span><span id='topic+discovery_correlation'></span><span id='topic+module_labels'></span><span id='topic+test_network'></span><span id='topic+test_data'></span><span id='topic+test_correlation'></span>

<h3>Description</h3>

<p>Example gene coexpression networks inferred from two independent datasets 
to demonstrate the usage of package functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("NetRep")
</code></pre>


<h3>Format</h3>


<dl>
<dt>&quot;discovery_network&quot;</dt><dd>
<p>a <code>matrix</code> with 150 columns and 150 rows containing the network 
edge weights encoding the interaction strength between each pair of
genes in the <em>discovery</em> dataset.
</p>
</dd>
<dt>&quot;discovery_data&quot;</dt><dd>
<p>a <code>matrix</code> with 150 columns (genes) and 30 rows (samples) whose 
entries correspond to the expression level of each gene in each sample
in the <em>discovery</em> dataset.
</p>
</dd>
<dt>&quot;discovery_correlation&quot;</dt><dd>
<p>a <code>matrix</code> with 150 columns and 150 rows containing the 
correlation-coefficients between each pair of genes calculated from the
&quot;discovery_data&quot; <code>matrix</code>.
</p>
</dd>
<dt>\&quot;module_labels&quot;</dt><dd>
<p>a named <code>vector</code> with 150 entries containing the module assignment
for each gene as identified in the <em>discovery</em> dataset.
</p>
</dd>  
<dt>&quot;test_network&quot;</dt><dd>
<p>a <code>matrix</code> with 150 columns and 150 rows containing the network 
edge weights encoding the interaction strength between each pair of
genes in the <em>test</em> dataset.
</p>
</dd>  
<dt>&quot;test_data&quot;</dt><dd>
<p>a <code>matrix</code> with 150 columns (genes) and 30 rows (samples) whose 
entries correspond to the expression level of each gene in each sample
in the <em>test</em> dataset.
</p>
</dd>
<dt>&quot;test_correlation&quot;</dt><dd>
<p>a <code>matrix</code> with 150 columns and 150 rows containing the 
correlation-coefficients between each pair of genes calculated from the
&quot;test_data&quot; <code>matrix</code>.
</p>
</dd>
</dl>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 150 rows and 150 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 30 rows and 150 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 150 rows and 150 columns.
</p>
<p>An object of class <code>numeric</code> of length 150.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 150 rows and 150 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 30 rows and 150 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 150 rows and 150 columns.
</p>


<h3>Details</h3>

<p>The <a href="#topic+modulePreservation">preservation of network modules</a> in a second
dataset is quantified by measuring the preservation of topological
properties between the <em>discovery</em> and <em>test</em> datasets. These 
properties are calculated not only from the interaction networks inferred
in each dataset, but also from the data used to infer those networks (e.g.
gene expression data) as well as the correlation structure between 
variables/nodes. Thus, all functions in the <code>NetRep</code> package have the 
following arguments: 
</p>

<dl>
<dt><code>network</code>:</dt><dd>
<p>a list of interaction networks, one for each dataset.
</p>
</dd>
<dt><code>data</code>:</dt><dd>
<p>a list of data matrices used to infer those networks, one for each 
dataset.
</p>
</dd>
<dt><code>correlation</code>:</dt><dd>
<p>a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
</p>
</dd> 
<dt><code>moduleAssignments</code>:</dt><dd>
<p>a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.
</p>
</dd>
<dt><code>modules</code>:</dt><dd>
<p>a list of vectors, one vector for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  
</p>
</dd>
<dt><code>discovery</code>:</dt><dd>
<p>a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.
</p>
</dd>
<dt><code>test</code>:</dt><dd>
<p>a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.
</p>
</dd>
</dl>

<p>This data is used to provide concrete examples of the usage of these 
arguments in each package function.
</p>


<h3>Simulation details</h3>

<p>The <em>discovery</em> gene expression dataset (<code>"discovery_data"</code>)
containing 30 samples and 150 genes was simulated to contain four distinct
modules of sizes 20, 25, 30, and 35 genes. Data for each module were
simulated as:
</p>
<p style="text-align: center;"><code class="reqn">
     G^{(w)}_{simulated} = E^{(w)} r_i + \sqrt{1 - r^2_i} \epsilon
   </code>
</p>

<p>Where <code class="reqn">E^{(w)}</code> is the simulated module's <em>summary vector</em>, 
<code class="reqn">r</code> is the simulated module's <em>node contributions</em> for each gene,
and <code class="reqn">\epsilon</code> is the error term drawn from a standard normal 
distribution. <code class="reqn">E^{(w)}</code> and <code class="reqn">r</code> were simulated by bootstrapping 
(sampling with replacement) samples and genes from the corresponding 
vectors in modules 63, 51, 57, and 50 discovered in the liver tissue gene 
expression data from a 
<a href="https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE2814">publicly 
available</a> mouse dataset (see reference <em>(1)</em> for details on the 
dataset and network discovery). The remaining 40 genes that were not part 
of any module were simulated by randomly selecting 40 liver genes and 
bootstrapping 30 samples and adding the noise term, <code class="reqn">\epsilon</code>. A
vector of module assignments was created (&quot;module_labels&quot;) in which
each gene was labelled with a number 1-4 corresponding to the module they
were simulated to be coexpressed with, or a label of 0 for the for the 40
&quot;background&quot; genes not participating in any module. The correlation
structure (&quot;discovery_correlation&quot;) was calculated as the Pearson's
correlation coefficient between genes 
(cor(discovery_data)). Edge weights in the
interaction network (&quot;discovery_network&quot;) were calculated as the
absolute value of the correlation coefficient exponentiated to the power 5
(abs(discovery_correlation)^5).
</p>
<p>An independent test dataset (&quot;test_data&quot;) containing the same 150
genes as the <em>discovery</em> dataset but 30 different samples was
simulated as above. Modules 1 and 4 (containing 20 and 35 genes
respectively) were simulated to be preserved using the same equation
above, where the <em>summary vector</em> <code class="reqn">E^{(w)}</code> was bootstrapped from
the same liver modules (modules 63 and 50) as in the <em>discovery</em> and
with identical <em>node contributions</em> <code class="reqn">r</code> as in the
<em>discovery</em> dataset. Genes in modules 2 and 3 were simulated as
&quot;background&quot; genes, <em>i.e.</em> not preserved as described above. The
correlation structure between genes in the <em>test</em> dataset
(&quot;test_correlation&quot;) and the interaction network
(&quot;test_network&quot;) were calculated the same way as in the
<em>discovery</em> dataset.
</p>
<p>The random seed used for the simulations was 37.
</p>


<h3>References</h3>


<ol>
<li>
<p>Ritchie, S.C., <em>et al.</em>, <em>A scalable permutation approach 
reveals replication and preservation patterns of network modules in 
large datasets</em>. Cell Systems. <strong>3</strong>, 71-82 (2016).

</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+modulePreservation">modulePreservation</a></code>, <code><a href="#topic+plotModule">plotModule</a></code>, and
<code><a href="#topic+networkProperties">networkProperties</a></code>.
</p>

<hr>
<h2 id='load.bigMatrix'>Load a 'bigMatrix' (deprecated)</h2><span id='topic+load.bigMatrix'></span>

<h3>Description</h3>

<p>The <code>'bigMatrix'</code> class is no longer implemented in the <code>NetRep</code>
package: the shared memory approach was incompatabile with high performance
compute clusters, so the parallel permutation procedure has been translated
into C++ code (which is also much faster). The <code><a href="#topic+disk.matrix">disk.matrix</a></code>
class should now be used instead when analysing large datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load.bigMatrix(backingfile)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load.bigMatrix_+3A_backingfile">backingfile</code></td>
<td>
<p>path to the backingfile for the <code>'bigMatrix'</code>. The
file extension must be omitted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will convert <code>'bigMatrix'</code> data saved by previous 
versions of <span class="pkg">NetRep</span> to a serialized R matrix saved in the same location
and return a <code><a href="#topic+disk.matrix">disk.matrix</a></code> object with the associated file path.
If this conversion has taken place already the function will throw a warning.
</p>
<p>This function will also convert the <code>'bigMatrix'</code> descriptor file to a 
<code><a href="bigmemory.html#topic+big.matrix">big.matrix</a></code> descriptor file to preserve 
compatability with functions in the <span class="pkg">bigmemory</span> package. If this 
functionality is not required, the files with the extensions &quot;.bin&quot; and 
&quot;.desc&quot; may be removed.
</p>
<p>A note for users using multi-node high performance clusters:
<code>'big.matrix'</code> objects are not suitable for general usage. Access
to file-backed shared memory segments on multi-node systems is very slow
due to consistency checks performed by the operating system. This becomes
exponentially worse the more R sessions there are simultaneously accessing
the shared memory segment, e.g. through parallel <span class="pkg">foreach</span> loops.
</p>

<hr>
<h2 id='modulePreservation'>Replication and preservation of network modules across datasets</h2><span id='topic+modulePreservation'></span>

<h3>Description</h3>

<p>Quantify the preservation of network modules (sub-graphs) in an independent
dataset through permutation testing on module topology. Seven network
statistics (see details) are calculated for each module and then tested by
comparing to distributions generated from their calculation on random subsets
in the test dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modulePreservation(
  network,
  data,
  correlation,
  moduleAssignments,
  modules = NULL,
  backgroundLabel = "0",
  discovery = 1,
  test = 2,
  selfPreservation = FALSE,
  nThreads = NULL,
  nPerm = NULL,
  null = "overlap",
  alternative = "greater",
  simplify = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modulePreservation_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_selfpreservation">selfPreservation</code></td>
<td>
<p>logical; if <code>FALSE</code> (default) then module 
preservation analysis will not be performed within a dataset (<em>i.e.</em> 
where the <code>discovery</code> and <code>test</code> datasets are the same).</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_nthreads">nThreads</code></td>
<td>
<p>number of threads to parallelise the calculation of network 
properties over. Automatically determined as the number of cores - 1 if 
not specified.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_nperm">nPerm</code></td>
<td>
<p>number of permutations to use. If not specified, the number of 
permutations will be automatically determined (see details). When set to 0
the permutation procedure will be skipped and the observed module 
preservation will be returned without p-values.</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_null">null</code></td>
<td>
<p>variables to include when generating the null distributions. 
Must be either &quot;overlap&quot; or &quot;all&quot; (see details).</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_alternative">alternative</code></td>
<td>
<p>The type of module preservation test to perform. Must be 
one of &quot;greater&quot; (default), &quot;less&quot; or &quot;two.sided&quot; (see details).</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_simplify">simplify</code></td>
<td>
<p>logical; if <code>TRUE</code>, simplify the structure of the output
list if possible (see Return Value).</p>
</td></tr>
<tr><td><code id="modulePreservation_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input data structures:</h4>

<p>The preservation of network modules in a second dataset is quantified by
measuring the preservation of topological properties between the
<em>discovery</em> and <em>test</em> datasets. These properties are calculated
not only from the interaction networks inferred in each dataset, but also
from the data used to infer those networks (e.g. gene expression data) as
well as the correlation structure between variables/nodes. Thus, all
functions in the <code>NetRep</code> package have the following arguments:
</p>

<ul>
<li><p><code>network</code>:
a list of interaction networks, one for each dataset.

</p>
</li>
<li><p><code>data</code>:
a list of data matrices used to infer those networks, one for each 
dataset.

</p>
</li>
<li><p><code>correlation</code>:
a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
 
</p>
</li>
<li><p><code>moduleAssignments</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.

</p>
</li>
<li><p><code>modules</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  

</p>
</li>
<li><p><code>discovery</code>:
a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.

</p>
</li>
<li><p><code>test</code>:
a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.

</p>
</li></ul>

<p>The formatting of these arguments is not strict: each function will attempt
to make sense of the user input. For example, if there is only one 
<code>discovery</code> dataset, then input to the <code>moduleAssigments</code> and 
<code>test</code> arguments may be vectors, rather than lists. 
</p>



<h4>Analysing large datasets:</h4>

<p>Matrices in the <code>network</code>, <code>data</code>, and <code>correlation</code> lists
can be supplied as <code><a href="#topic+disk.matrix">disk.matrix</a></code> objects. This class allows 
matrix data to be kept on disk and loaded as required by <span class="pkg">NetRep</span>. 
This dramatically decreases memory usage: the matrices for only one 
dataset will be kept in RAM at any point in time.
</p>
<p>Additional memory usage of the permutation procedure is directly
proportional to the sum of module sizes squared multiplied by the number 
of threads. Very large modules may result in significant additional memory
usage per core due to extraction of the correlation coefficient sub-matrix
at each permutation.
</p>



<h4>Module Preservation Statistics:</h4>

<p>Module preservation is assessed through seven module preservation statistics,
each of which captures a different aspect of a module's topology; <em>i.e.</em>
the structure of the relationships between its nodes <em>(1,2)</em>. Below is
a description of each statistic, what they seek to measure, and where their
interpretation may be inappropriate. 
</p>
<p>The <em>module coherence</em> (<code>'coherence'</code>), <em>average node 
contribution</em> (<code>'avg.contrib'</code>), and <em>concordance of node 
contribution</em> (<code>'cor.contrib'</code>) are all calculated from the data used 
to infer the network (provided in the <code>'data'</code> argument). They are 
calculated from the module's <em>summary profile</em>. This is the eigenvector
of the 1st principal component across all observations for every node
composing the module. For gene coexpression modules this can be interpreted
as a &quot;summary expression profile&quot;. It is typically referred to as the
&quot;module eigengene&quot; in the weighted gene coexpression network analysis
literature <em>(4)</em>.
</p>
<p>The <em>module coherence</em> (<code>'coherence'</code>) quantifies the proportion 
of module variance explained by the module's &quot;summary profile&quot;. The higher
this value, the more &quot;coherent&quot; the data is, <em>i.e.</em> the more similar
the observations are nodes for each sample. With the default alternate
hypothesis, a small permutation <em>P</em>-value indicates that the module is
more coherent than expected by chance.
</p>
<p>The <em>average node contribution</em> (<code>'avg.contrib'</code>) and 
<em>concordance of node contribution</em> (<code>'cor.contrib'</code>) are calculated 
from the <em>node contribution</em>, which quantifies how similar each node is 
to the modules's <em>summary profile</em>. It is calculated as the Pearson
correlation coefficient between each node and the module summary profile. In
the weighted gene coexpression network literature it is typically called the
&quot;module membership&quot; <em>(2)</em>.
</p>
<p>The <em>average node contribution</em> (<code>'avg.contrib'</code>) quantifies how
similar nodes are to the module summary profile in the test dataset. Nodes
detract from this score where the sign of their node contribution flips 
between the discovery and test datasets, <em>e.g.</em> in the case of 
differential gene expression across conditions. A high <em>average node
contribution</em> with a small permutation <em>P</em>-value indicates that the
module remains coherent in the test dataset, and that the nodes are acting
together in a similar way.  
</p>
<p>The <em>concordance of node contribution</em> (<code>'cor.contrib'</code>) measures 
whether the relative rank of nodes (in terms of their node contribution) is 
preserved across datasets. If a module is coherent enough that all nodes 
contribute strongly, then this statistic will not be meaningful as its value
will be heavily influenced by tiny variations in node rank. This can be
assessed through visualisation of the module topology (see 
<code><a href="#topic+plotContribution">plotContribution</a></code>.) Similarly, a strong
<code>'cor.contrib'</code> is unlikely to be meaningful if the
<code>'avg.contrib'</code> is not significant.
</p>
<p>The <em>concordance of correlation strucutre</em> (<code>'cor.cor'</code>) and 
<em>density of correlation structure</em> (<code>'avg.cor'</code>) are calculated 
from the user-provided correlation structure between nodes (provided in the 
<code>'correlation'</code> argument). This is referred to as &quot;coexpression&quot; when
calculated on gene expression data.
</p>
<p>The <code>'avg.cor'</code> measures how strongly nodes within a module are 
correlation on average in the test dataset. This average depends on the 
correlation coefficients in the discovery dataset: the score is penalised 
where correlation coefficients change in sign between datasets. A high 
<code>'avg.cor'</code> with a small permutation <em>P</em>-value indicates that the 
module is (a) more strongly correlated than expected by chance for a module 
of the same size, and (b) more consistently correlated with respect to the 
discovery dataset than expected by chance.
</p>
<p>The <code>'cor.cor'</code> measures how similar the correlation coefficients are 
across the two datasets. A high <code>'cor.cor'</code> with a small permutation 
<em>P</em>-value indicates that the correlation structure within a module is 
more similar across datasets than expected by chance. If all nodes within a 
module are very similarly correlated then this statistic will not be 
meaningful, as its value will be heavily influenced by tiny, non-meaningful, 
variations in correlation strength. This can be assessed through
visualisation of the module topology (see <code><a href="#topic+plotCorrelation">plotCorrelation</a></code>.)
Similarly, a strong <code>'cor.cor'</code> is unlikely to be meaningful if the
<code>'avg.cor'</code> is not significant.
</p>
<p>The <em>average edge weight</em> (<code>'avg.weight'</code>) and <em>concordance
of weighted degree</em> (<code>'cor.degree'</code>) are both calculated from the 
interaction network (provided as adjacency matrices to the <code>'network'</code>
argument). 
</p>
<p>The <code>'avg.weight'</code> measures the average connection strength between 
nodes in the test dataset. In the weighted gene coexpression network 
literature this is typically called the &quot;module density&quot; <em>(2)</em>. A high
<code>'avg.weight'</code> with a small permutation <em>P</em>-value indicates that
the module is more strongly connected in the test dataset than expected by
chance. 
</p>
<p>The <code>'cor.degree'</code> calculates whether the relative rank of each node's 
<em>weighted degree</em> is similar across datasets. The <em>weighted
degree</em> is calculated as the sum of a node's edge weights to all other nodes
in the module. In the weighted gene coexpression network literature this is 
typically called the &quot;intramodular connectivity&quot; <em>(2)</em>. This statistic 
will not be meaningful where all nodes are connected to each other with 
similar strength, as its value will be heavily influenced by tiny,
non-meaningful, variations in weighted degree. This can be assessed through
visualisation of the module topology (see <code><a href="#topic+plotDegree">plotDegree</a></code>.)
</p>
<p>Both the <code>'avg.weight'</code> and <code>'cor.degree'</code> assume edges are 
weighted, and that the network is densely connected. Note that for sparse 
networks, edges with zero weight are included when calculating both
statistics. Only the magnitude of the weights, not their sign, contribute to
the score. If the network is <em>unweighted</em>, <em>i.e.</em> edges indicate
presence or absence of a relationship, then the <code>'avg.weight'</code> will be
the proportion of the number of edges to the total number of possible edges
while the <em>weighted degree</em> simply becomes the <em>degree</em>. A high
<code>'avg.weight'</code> in this case measures how interconnected a module is in
the test dataset. A high <em>degree</em> indicates that a node is connected to
many other nodes. The interpretation of the <code>'cor.degree'</code> remains
unchanged between weighted and unweighted networks. If the network is
directed the interpretation of the <code>'avg.weight'</code> remains unchanged,
while the <em>cor.degree</em> will measure the concordance of the node
<em>in-</em>degree in the test network. To measure the <em>out-</em>degree
instead, the adjacency matrices provided to the <code>'network'</code> argument
should be transposed.
</p>



<h4>Sparse data:</h4>

<p>Caution should be used when running <code>NetRep</code>
on sparse data (<em>i.e.</em> where there are many zero values in the data 
used to infer the network). For this data, the <em>average node contribution</em> 
(<code>'avg.contrib'</code>), <em>concordance of node contribution</em> 
(<code>'cor.contrib'</code>), and <em>module coherence</em> (<code>'coherence'</code>)
will all be systematically underestimated due to their reliance on the 
Pearson correlation coefficient to calculate the <em>node contribution</em>.
</p>
<p>Care should also be taken to use appropriate methods for inferring the
correlation structure when the data is sparse for the same reason.
</p>



<h4>Proportional data:</h4>

<p>Caution should be used when running <code>NetRep</code> on proportional data (
<em>i.e.</em> where observations across samples all sum to the same value, 
<em>e.g.</em> 1). For this data, the <em>average node contribution</em> 
(<code>'avg.contrib'</code>), <em>concordance of node contribution</em> 
(<code>'cor.contrib'</code>), and <em>module coherence</em> (<code>'coherence'</code>)
will all be systematically overestimated due to their reliance on the 
Pearson correlation coefficient to calculate the <em>node contribution</em>.
</p>
<p>Care should also be taken to use appropriate methods for inferring the
correlation structure from proportional data for the same reason.
</p>



<h4>Hypothesis testing:</h4>

<p>Three alternative hypotheses are available. &quot;greater&quot;, the default, tests
whether each module preservation statistic is larger than expected by 
chance. &quot;lesser&quot; tests whether each module preservation statistic is smaller
than expected by chance, which may be useful for identifying modules that
are extremely different in the <em>test</em> dataset. &quot;two.sided&quot; can be used
to test both alternate hypotheses.
</p>
<p>To determine whether a module preservation statistic deviates from chance, a
permutation procedure is employed. Each statistic is calculated between the
module in the <em>discovery</em> dataset and <code>nPerm</code> random subsets of
the same size in the <em>test</em> dataset in order to assess the distribution
of each statistic under the null hypothesis. 
</p>
<p>Two models for the null hypothesis are available: &quot;overlap&quot;, the default, 
only nodes that are present in both the <em>discovery</em> and <em>test</em>
networks are used when generating null distributions. This is appropriate
under an assumption that nodes that are present in the <em>test</em> dataset, 
but not present in the <em>discovery</em> dataset, are unobserved: that is,
they may fall in the module(s) of interest in the <em>discovery</em> dataset
if they were to be measured there. Alternatively, &quot;all&quot; will use all nodes
in the <em>test</em> network when generating the null distributions.
</p>
<p>The number of permutations required for any given significance threshold is 
approximately 1 / the desired significance for one sided tests, and double 
that for two-sided tests. This can be calculated with 
<code><a href="#topic+requiredPerms">requiredPerms</a></code>. When <code>nPerm</code> is not specified, the number 
of permutations is automatically calculated as the number required for a 
Bonferroni corrected significance threshold adjusting for the total number 
of tests for each statistic, i.e. the total number of modules to be analysed
multiplied by the number of <em>test</em> datasets each module is tested in. 
Although assessing the replication of a small numberof modules calls for 
very few permutations, we recommend using no fewer than 1,000 as fewer 
permutations are unlikely to generate representative null distributions. 
<strong>Note:</strong> the assumption used by <code><a href="#topic+requiredPerms">requiredPerms</a></code> to 
determine the correct number of permtutations breaks down when assessing the
preservation of modules in a very small dataset (e.g. gene sets in a dataset
with less than 100 genes total). However, the reported p-values will still
be accurate (see <code><a href="#topic+permutationTest">permutationTest</a></code>) <em>(3)</em>.
</p>



<h3>Value</h3>

<p>A nested list structure. At the top level, the list has one element per 
<code>'discovery'</code> dataset. Each of these elements is a list that has one
element per <code>'test'</code> dataset analysed for that <code>'discovery'</code> 
dataset. Each of these elements is also a list, containing the following
objects:
</p>

<ul>
<li><p><code>observed</code>:
A matrix of the observed values for the module preservation statistics.
Rows correspond to modules, and columns to the module preservation
statistics.

</p>
</li>
<li><p><code>nulls</code>:
A three dimensional array containing the values of the module 
preservation statistics evaluated on random permutation of module 
assignment in the test network. Rows correspond to modules, columns to
the module preservation statistics, and the third dimension to the 
permutations.

</p>
</li>
<li><p><code>p.values</code>:
A matrix of p-values for the <code>observed</code> module preservation 
statistics as evaluated through a permutation test using the 
corresponding values in <code>nulls</code>.

</p>
</li>
<li><p><code>nVarsPresent</code>:
A vector containing the number of variables that are present in the test
dataset for each module.

</p>
</li>
<li><p><code>propVarsPresent</code>:
A vector containing the proportion of variables present in the test dataset
for each module. Modules where this is less than 1 should be 
investigated further before making judgements about preservation to 
ensure that the missing variables are not the most connected ones.

</p>
</li>
<li><p><code>contingency</code>: 
If <code>moduleAssignments</code> are present for both the <em>discovery</em>
and <em>test</em> datasets, then a contingency table showing the overlap
between modules across datasets is returned. Rows correspond to modules
in the <em>discovery</em> dataset, columns to modules in the <em>test</em>
dataset.

</p>
</li></ul>

<p>When <code>simplify = TRUE</code> then the simplest possible structure will be 
returned. E.g. if module preservation is tested in only one dataset, then
the returned list will have only the above elements. 
</p>
<p>When <code>simplify = FALSE</code> then a nested list of datasets will always be 
returned, i.e. each element at the top level and second level correspond to
a dataset, e.g. <code>results[["Dataset1"]][["Dataset2"]]</code> indicates an 
analysis where modules discovered in &quot;Dataset1&quot; are assessed for 
preservation in &quot;Dataset2&quot;. Dataset comparisons which have not been 
assessed will contain <code>NULL</code>.
</p>


<h3>References</h3>


<ol>
<li>
<p>Ritchie, S.C., <em>et al.</em>, <em>A scalable permutation approach 
reveals replication and preservation patterns of network modules in 
large datasets</em>. Cell Systems. <strong>3</strong>, 71-82 (2016).

</p>
</li>
<li>
<p>Langfelder, P., Luo, R., Oldham, M. C. &amp; Horvath, S. <em>Is my
network module preserved and reproducible?</em> PLoS Comput. Biol. 
<strong>7</strong>, e1001057 (2011). 

</p>
</li>
<li>
<p>Phipson, B. &amp; Smyth, G. K. <em>Permutation P-values should never be 
zero: calculating exact P-values when permutations are randomly drawn.</em>
Stat. Appl. Genet. Mol. Biol. <strong>9</strong>, Article39 (2010). 

</p>
</li>
<li>
<p>Langfelder, P. &amp; Horvath, S. <em>WGCNA: an R package for weighted 
correlation network analysis.</em> BMC Bioinformatics <strong>9</strong>, 559 
(2008).

</p>
</li></ol>



<h3>See Also</h3>

<p>Functions for: 
<a href="#topic+plotModule">visualising network modules</a>,
<a href="#topic+networkProperties">calculating module topology</a>, 
<a href="#topic+permutationTest">calculating permutation test P-values</a>, and 
<a href="#topic+combineAnalyses">splitting computation over multiple machines</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in example data, correlation, and network matrices for a discovery and test dataset:
data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Assess module preservation: you should run at least 10,000 permutations
preservation &lt;- modulePreservation(
 network=network_list, data=data_list, correlation=correlation_list, 
 moduleAssignments=labels_list, nPerm=1000, discovery="discovery", 
 test="test", nThreads=2
)

</code></pre>

<hr>
<h2 id='networkProperties'>Calculate the topological properties for a network module</h2><span id='topic+networkProperties'></span>

<h3>Description</h3>

<p>Calculates the network properties used to assess module preservation for one
or more modules in a user specified dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>networkProperties(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  simplify = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="networkProperties_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_simplify">simplify</code></td>
<td>
<p>logical; if <code>TRUE</code>, simplify the structure of the output
list if possible (see Return Value).</p>
</td></tr>
<tr><td><code id="networkProperties_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input data structures:</h4>

<p>The <a href="#topic+modulePreservation">preservation of network modules</a> in a second
dataset is quantified by measuring the preservation of topological
properties between the <em>discovery</em> and <em>test</em> datasets. These 
properties are calculated not only from the interaction networks inferred
in each dataset, but also from the data used to infer those networks (e.g.
gene expression data) as well as the correlation structure between 
variables/nodes. Thus, all functions in the <code>NetRep</code> package have the 
following arguments: 
</p>

<ul>
<li><p><code>network</code>:
a list of interaction networks, one for each dataset.

</p>
</li>
<li><p><code>data</code>:
a list of data matrices used to infer those networks, one for each 
dataset.

</p>
</li>
<li><p><code>correlation</code>:
a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
 
</p>
</li>
<li><p><code>moduleAssignments</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.

</p>
</li>
<li><p><code>modules</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  

</p>
</li>
<li><p><code>discovery</code>:
a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.

</p>
</li>
<li><p><code>test</code>:
a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.

</p>
</li></ul>

<p>The formatting of these arguments is not strict: each function will attempt
to make sense of the user input. For example, if there is only one 
<code>discovery</code> dataset, then input to the <code>moduleAssigments</code> and 
<code>test</code> arguments may be vectors, rather than lists. If the 
<code>networkProperties</code> are being calculate within the <em>discovery</em> or
<em>test</em> datasets, then the <code>discovery</code> and <code>test</code> arguments do
not need to be specified, and the input matrices for the <code>network</code>,
<code>data</code>, and <code>correlation</code> arguments do not need to be wrapped in
a list.
</p>



<h4>Analysing large datasets:</h4>

<p>Matrices in the <code>network</code>, <code>data</code>, and <code>correlation</code> lists
can be supplied as <code><a href="#topic+disk.matrix">disk.matrix</a></code> objects. This class allows 
matrix data to be kept on disk and loaded as required by <span class="pkg">NetRep</span>. 
This dramatically decreases memory usage: the matrices for only one 
dataset will be kept in RAM at any point in time.
</p>



<h3>Value</h3>

<p>A nested list structure. At the top level, the list has one element per 
<code>'discovery'</code> dataset. Each of these elements is a list that has one
element per <code>'test'</code> dataset analysed for that <code>'discovery'</code> 
dataset. Each of these elements is a list that has one element per 
<code>'modules'</code> specified. Each of these is a list containing the following  
objects:
</p>

<ul>
<li><p><code>'degree'</code>:
The weighted within-module degree: the sum of edge weights for each 
node in the module.

</p>
</li>
<li><p><code>'avgWeight'</code>:
The average edge weight within the module.

</p>
</li></ul>

<p>If the <code>'data'</code> used to infer the <code>'test'</code> network is provided  
then the following are also returned:
</p>

<ul>
<li><p><code>'summary'</code>:
A vector summarising the module across each sample. This is calculated 
as the first eigenvector of the module from a principal component 
analysis.

</p>
</li>
<li><p><code>'contribution'</code>:
The <em>node contribution</em>: the similarity between each node and the
<em>module summary profile</em> (<code>'summary'</code>).

</p>
</li>
<li><p><code>'coherence'</code>:
The proportion of module variance explained by the <code>'summary'</code>
vector.

</p>
</li></ul>

<p>When <code>simplify = TRUE</code> then the simplest possible structure will be 
returned. E.g. if the network properties are requested for only one module 
in only one dataset, then the returned list will have only the above elements. 
</p>
<p>When <code>simplify = FALSE</code> then a nested list of datasets will always be 
returned, i.e. each element at the top level and second level correspond to
a dataset, and each element at the third level will correspond to modules 
discovered in the dataset specified at the top level if module labels are 
provided in the corresponding <code>moduleAssignments</code> list element. E.g. 
<code>results[["Dataset1"]][["Dataset2"]][["module1"]]</code> will contain the 
properties of &quot;module1&quot; as calculated in &quot;Dataset2&quot;, where &quot;module1&quot; was 
indentified in &quot;Dataset1&quot;. Modules and datasets for which calculation of 
the network properties have not been requested will contain <code>NULL</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+nodeOrder">Getting nodes ordered by degree.</a>, and
<a href="#topic+sampleOrder">Ordering samples by module summary</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in example data, correlation, and network matrices for a discovery and test dataset:
data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Calculate the topological properties of all network modules in the discovery dataset
props &lt;- networkProperties(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list
)
  
# Calculate the topological properties in the test dataset for the same modules
test_props &lt;- networkProperties(
  network=network_list, data=data_list, correlation=correlation_list,
  moduleAssignments=labels_list, discovery="discovery", test="test"
)

</code></pre>

<hr>
<h2 id='nodeOrder'>Order nodes in descending order of <em>weighted degree</em> and order 
modules by the similarity of their summary vectors.</h2><span id='topic+nodeOrder'></span>

<h3>Description</h3>

<p>Order nodes in descending order of <em>weighted degree</em> and order 
modules by the similarity of their summary vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nodeOrder(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  na.rm = FALSE,
  orderModules = TRUE,
  mean = FALSE,
  simplify = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nodeOrder_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; If <code>TRUE</code>, nodes and modules present in the 
<code>discovery</code> dataset but missing from the test dataset are excluded. If
<code>FALSE</code>, missing nodes and modules are put last in the ordering.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_ordermodules">orderModules</code></td>
<td>
<p>logical; if <code>TRUE</code> modules ordered by clustering 
their summary vectors. If <code>FALSE</code> modules are returned in the order
provided.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_mean">mean</code></td>
<td>
<p>logical; if <code>TRUE</code>, node order will be calculated for each
<code>discovery</code> dataset by averaging the weighted degree and pooling 
<em>module summary</em> vectors across the specified <code>test</code> datasets.
If <code>FALSE</code>, the node order is calculated separately in each test 
dataset.</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_simplify">simplify</code></td>
<td>
<p>logical; if <code>TRUE</code>, simplify the structure of the output
list if possible (see Return Value).</p>
</td></tr>
<tr><td><code id="nodeOrder_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input data structures:</h4>

<p>The <a href="#topic+modulePreservation">preservation of network modules</a> in a second
dataset is quantified by measuring the preservation of topological
properties between the <em>discovery</em> and <em>test</em> datasets. These 
properties are calculated not only from the interaction networks inferred
in each dataset, but also from the data used to infer those networks (e.g.
gene expression data) as well as the correlation structure between 
variables/nodes. Thus, all functions in the <code>NetRep</code> package have the 
following arguments: 
</p>

<ul>
<li><p><code>network</code>:
a list of interaction networks, one for each dataset.

</p>
</li>
<li><p><code>data</code>:
a list of data matrices used to infer those networks, one for each 
dataset.

</p>
</li>
<li><p><code>correlation</code>:
a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
 
</p>
</li>
<li><p><code>moduleAssignments</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.

</p>
</li>
<li><p><code>modules</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  

</p>
</li>
<li><p><code>discovery</code>:
a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.

</p>
</li>
<li><p><code>test</code>:
a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.

</p>
</li></ul>

<p>The formatting of these arguments is not strict: each function will attempt
to make sense of the user input. For example, if there is only one 
<code>discovery</code> dataset, then input to the <code>moduleAssigments</code> and 
<code>test</code> arguments may be vectors, rather than lists. If the 
<code>nodeOrder</code> are being calculate within the <em>discovery</em> or
<em>test</em> datasets, then the <code>discovery</code> and <code>test</code> arguments do
not need to be specified, and the input matrices for the <code>network</code>,
<code>data</code>, and <code>correlation</code> arguments do not need to be wrapped in
a list.
</p>



<h4>Analysing large datasets:</h4>

<p>Matrices in the <code>network</code>, <code>data</code>, and <code>correlation</code> lists
can be supplied as <code><a href="#topic+disk.matrix">disk.matrix</a></code> objects. This class allows 
matrix data to be kept on disk and loaded as required by <span class="pkg">NetRep</span>. 
This dramatically decreases memory usage: the matrices for only one 
dataset will be kept in RAM at any point in time.
</p>



<h4>Mean weighted degree:</h4>

<p>When multiple <code>'test'</code> datasets are specified and <code>'mean'</code> is
<code>TRUE</code>, then the order of nodes will be determine by the average of
each node's weighted degree across datasets. The weighted degree in each 
dataset is scaled to the node with the maximum weighted degree in that
module in that dataset: this prevents differences in average edge weight 
across datasets from influencing the outcome (otherwise the mean would be
weighted by the overall density of connections in the module). Thus, the 
mean weighted degree is a robust measure of a node's relative importance 
to a module across datasets. The mean is calculated with 
<code>'na.rm=TRUE'</code>: where a node is missing it does not contribute to 
the mean.
</p>



<h3>Value</h3>

<p>A nested list structure. At the top level, the list has one element per 
<code>'discovery'</code> dataset. Each of these elements is a list that has one
element per <code>'test'</code> dataset analysed for that <code>'discovery'</code> 
dataset. Each of these elements is a list that has one element per 
<code>'modules'</code> specified, containing a vector of node names for the
requested module. When <code>simplify = TRUE</code> then the simplest possible 
structure will be returned. E.g. if the node ordering are requested for 
module(s) in only one dataset, then a single vector of node labels will
be returned. 
</p>
<p>When <code>simplify = FALSE</code> then a nested list of datasets will always be 
returned, i.e. each element at the top level and second level correspond to 
a dataset, and each element at the third level will correspond to modules 
discovered in the dataset specified at the top level if module labels are 
provided in the corresponding <code>moduleAssignments</code> list element. E.g. 
<code>results[["Dataset1"]][["Dataset2"]][["module1"]]</code> will contain the 
order of nodes calculated in &quot;Dataset2&quot;, where &quot;module1&quot; was indentified in
&quot;Dataset1&quot;. Modules and datasets for which calculation of the node order 
have not been requested will contain <code>NULL</code>.
</p>


<h3>References</h3>


<ol>
<li>
<p>Langfelder, P., Mischel, P. S. &amp; Horvath, S. <em>When is hub gene 
selection better than standard meta-analysis?</em> PLoS One <strong>8</strong>, 
e61505 (2013).

</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+networkProperties">networkProperties</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in example data, correlation, and network matrices for a discovery
# and test dataset:
data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Sort modules by similarity and nodes within each module by their weighted 
# degree
nodes &lt;- nodeOrder(
  network=network_list, data=data_list, correlation=correlation_list,  
  moduleAssignments=labels_list
)

</code></pre>

<hr>
<h2 id='orderModules_param'>Template parameters</h2><span id='topic+orderModules_param'></span>

<h3>Description</h3>

<p>Template parameters to be imported into other function documentation. This 
is not intended to be a stand-alone help file.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="orderModules_param_+3A_ordermodules">orderModules</code></td>
<td>
<p>logical; if <code>TRUE</code> modules ordered by clustering 
their summary vectors. If <code>FALSE</code> modules are returned in the order
provided.</p>
</td></tr>
</table>

<hr>
<h2 id='permutationTest'>Permutation test P-values for module preservation statistics</h2><span id='topic+permutationTest'></span><span id='topic+permutation'></span><span id='topic+permuted'></span>

<h3>Description</h3>

<p>Evaluates the statistical significance of each module preservation test 
statistic for one or more modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permutationTest(
  nulls,
  observed,
  nVarsPresent,
  totalSize,
  alternative = "greater"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permutationTest_+3A_nulls">nulls</code></td>
<td>
<p>a 3-dimension matrix where the columns correspond to module
preservation statistics, rows correspond to modules, and the third 
dimension to null distribution observations drawn from the permutation 
procedure in <code><a href="#topic+modulePreservation">modulePreservation</a></code>.</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_observed">observed</code></td>
<td>
<p>a matrix of observed values for each module preservation
statistc (columns) for each module (rows) returned from 
<code><a href="#topic+modulePreservation">modulePreservation</a></code>.</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_nvarspresent">nVarsPresent</code></td>
<td>
<p>a vector containing the number of variables/nodes in each
module that was present in the <em>test</em> dataset. Returned as a list 
element of the same name by <code><a href="#topic+modulePreservation">modulePreservation</a></code>.</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_totalsize">totalSize</code></td>
<td>
<p>the size of the test network used to perform the test. 
Returned as a list element of the same name by 
<code><a href="#topic+modulePreservation">modulePreservation</a></code>.</p>
</td></tr>
<tr><td><code id="permutationTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, 
must be one of &quot;greater&quot; (default), &quot;less&quot;, or &quot;two.sided&quot;. 
You can specify just the initial letter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates exact p-values for permutation tests when permutations are 
randomly drawn with replacement using the <code><a href="statmod.html#topic+permp">permp</a></code> 
function in the <code><a href="statmod.html#topic+statmod">statmod</a></code> package. 
</p>
<p>This function may be useful for re-calculating permutation test P-values,
for example when there are missing values due to sparse data. In this case
the user may decide that these missing values should be assigned 0 so that
P-values aren't signficant purely due to many incalculable statistics leading
to low power.
</p>


<h3>References</h3>


<ol>
<li>
<p>Phipson, B. &amp; Smyth, G. K. <em>Permutation P-values should never be 
zero: calculating exact P-values when permutations are randomly drawn.</em>
Stat. Appl. Genet. Mol. Biol. <strong>9</strong>, Article39 (2010). 

</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Note that we recommend running at least 10,000 permutations to make sure 
# that the null distributions are representative.

preservation &lt;- modulePreservation(
 network=network_list, data=data_list, correlation=correlation_list, 
 moduleAssignments=labels_list, nPerm=1000, discovery="discovery", 
 test="test"
)

# Re-calculate the permutation test P-values
p.values &lt;- permutationTest(
  preservation$nulls, preservation$observed, preservation$nVarsPresent,
  preservation$totalSize, preservation$alternative
)

</code></pre>

<hr>
<h2 id='plot_params'>Template parameters</h2><span id='topic+plot_params'></span>

<h3>Description</h3>

<p>Template parameters to be imported into other function documentation. This 
is not intended to be a stand-alone help file.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_params_+3A_ordernodesby">orderNodesBy</code></td>
<td>
<p><code>NULL</code> (default), <code>NA</code>, or a vector of dataset
names or indices. Controls how nodes are ordered on the plot (see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_ordersamplesby">orderSamplesBy</code></td>
<td>
<p><code>NULL</code> (default), <code>NA</code>, or a vector 
containing a single dataset name or index. Controls how samples are ordered 
on the plot (see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_plotnodenames">plotNodeNames</code></td>
<td>
<p>logical; controls whether the node names are 
drawed on the bottom axis.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_plotsamplenames">plotSampleNames</code></td>
<td>
<p>logical; controls whether the sample names are 
drawed on the left axis.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_plotmodulenames">plotModuleNames</code></td>
<td>
<p>logical; controls whether module names are drawed.
The default is for module names to be drawed when multiple <code>modules</code> 
are drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_main">main</code></td>
<td>
<p>title for the plot.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_main.line">main.line</code></td>
<td>
<p>the number of lines into the top margin at which the plot
title will be drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_drawborders">drawBorders</code></td>
<td>
<p>logical; if <code>TRUE</code>, borders are drawn around the 
<em>weighted degree</em>, <em>node conribution</em>, and <em>module summary</em>
bar plots.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and axes.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_naxt.line">naxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the node
names will be drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_saxt.line">saxt.line</code></td>
<td>
<p>the number of lines into the left margin at which the sample
names will be drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_maxt.line">maxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
module names will be drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_xaxt.line">xaxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
x-axis tick labels will be drawn on the module summary bar plot.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_xaxt.tck">xaxt.tck</code></td>
<td>
<p>the size of the x-axis ticks for the module summary bar 
plot.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_xlab.line">xlab.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
x axis label on the <em>module summary</em> bar plot(s) will be drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_yaxt.line">yaxt.line</code></td>
<td>
<p>the number of lines into the left margin at which the 
y-axis tick labels will be drawn on the weighted degree and node 
contribution bar plots.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_ylab.line">ylab.line</code></td>
<td>
<p>the number of lines into the left margin at which the 
y axis labels on the <em>weighted degree</em> and <em>node contribution</em> 
bar plots will be drawn.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_yaxt.tck">yaxt.tck</code></td>
<td>
<p>the size of the y-axis ticks for the weighted degree and 
node contribution bar plots.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_laxt.line">laxt.line</code></td>
<td>
<p>the distance from the legend to draw the legend axis 
labels, as multiple of <code>laxt.tck</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_laxt.tck">laxt.tck</code></td>
<td>
<p>size of the ticks on each axis legend relative to the
size of the correlation, edge weights, and data matrix heatmaps.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_legend.main.line">legend.main.line</code></td>
<td>
<p>the distance from the legend to draw the legend 
title.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_cex.axis">cex.axis</code></td>
<td>
<p>relative size of the node and sample names.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_cex.lab">cex.lab</code></td>
<td>
<p>relative size of the module names and legend titles.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_cex.main">cex.main</code></td>
<td>
<p>relative size of the plot titles.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_datacols">dataCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the data heatmap (see details). Automatically determined if <code>NA</code> or 
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_datarange">dataRange</code></td>
<td>
<p>the range of values to map to the <code>dataCols</code> gradient
(see details). Automatically determined if <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_corcols">corCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the correlation structure heatmap (see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_corrange">corRange</code></td>
<td>
<p>the range of values to map to the <code>corCols</code> gradient
(see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_netcols">netCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the network edge weight heatmap (see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_netrange">netRange</code></td>
<td>
<p>the range of values to map to the <code>corCols</code> gradient
(see details). Automatically determined if <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_degreecol">degreeCol</code></td>
<td>
<p>color to use for the weighted degree bar plot.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_contribcols">contribCols</code></td>
<td>
<p>color(s) to use for the node contribution bar plot 
(see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_summarycols">summaryCols</code></td>
<td>
<p>color(s) to use for the node contribution bar plot 
(see details).</p>
</td></tr>
<tr><td><code id="plot_params_+3A_nacol">naCol</code></td>
<td>
<p>color to use for missing nodes and samples on the data, 
correlation structure, and network edge weight heat maps.</p>
</td></tr>
<tr><td><code id="plot_params_+3A_dryrun">dryRun</code></td>
<td>
<p>logical; if <code>TRUE</code>, only the axes and labels will be 
drawed.</p>
</td></tr>
</table>

<hr>
<h2 id='plotModule'>Plot the topology of a network module</h2><span id='topic+plotModule'></span>

<h3>Description</h3>

<p>Plot the correlation structure, network edges, scaled weighted degree, 
node contribtuion, module data, and module summary vectors of one or
more network modules.
</p>
<p>Individual components of the module plot can be plotted using 
<code><a href="#topic+plotCorrelation">plotCorrelation</a></code>, <code><a href="#topic+plotNetwork">plotNetwork</a></code>, 
<code><a href="#topic+plotDegree">plotDegree</a></code>, <code><a href="#topic+plotContribution">plotContribution</a></code>, 
<code><a href="#topic+plotData">plotData</a></code>, and <code><a href="#topic+plotSummary">plotSummary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotModule(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderSamplesBy = NULL,
  orderNodesBy = NULL,
  orderModules = TRUE,
  plotNodeNames = TRUE,
  plotSampleNames = TRUE,
  plotModuleNames = NULL,
  main = "Module Topology",
  main.line = 1,
  drawBorders = FALSE,
  lwd = 1,
  naxt.line = -0.5,
  saxt.line = -0.5,
  maxt.line = NULL,
  xaxt.line = -0.5,
  xaxt.tck = -0.025,
  xlab.line = 2.5,
  yaxt.line = 0,
  yaxt.tck = -0.15,
  ylab.line = 2.5,
  laxt.line = 2.5,
  laxt.tck = 0.04,
  cex.axis = 0.8,
  legend.main.line = 1.5,
  cex.lab = 1.2,
  cex.main = 2,
  dataCols = NULL,
  dataRange = NULL,
  corCols = correlation.palette(),
  corRange = c(-1, 1),
  netCols = network.palette(),
  netRange = c(0, 1),
  degreeCol = "#feb24c",
  contribCols = c("#A50026", "#313695"),
  summaryCols = c("#1B7837", "#762A83"),
  naCol = "#bdbdbd",
  dryRun = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotModule_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_ordersamplesby">orderSamplesBy</code></td>
<td>
<p><code>NULL</code> (default), <code>NA</code>, or a vector 
containing a single dataset name or index. Controls how samples are ordered 
on the plot (see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_ordernodesby">orderNodesBy</code></td>
<td>
<p><code>NULL</code> (default), <code>NA</code>, or a vector of dataset
names or indices. Controls how nodes are ordered on the plot (see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_ordermodules">orderModules</code></td>
<td>
<p>logical; if <code>TRUE</code> modules ordered by clustering 
their summary vectors. If <code>FALSE</code> modules are returned in the order
provided.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_plotnodenames">plotNodeNames</code></td>
<td>
<p>logical; controls whether the node names are 
drawed on the bottom axis.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_plotsamplenames">plotSampleNames</code></td>
<td>
<p>logical; controls whether the sample names are 
drawed on the left axis.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_plotmodulenames">plotModuleNames</code></td>
<td>
<p>logical; controls whether module names are drawed.
The default is for module names to be drawed when multiple <code>modules</code> 
are drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_main">main</code></td>
<td>
<p>title for the plot.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_main.line">main.line</code></td>
<td>
<p>the number of lines into the top margin at which the plot
title will be drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_drawborders">drawBorders</code></td>
<td>
<p>logical; if <code>TRUE</code>, borders are drawn around the 
<em>weighted degree</em>, <em>node conribution</em>, and <em>module summary</em>
bar plots.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and axes.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_naxt.line">naxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the node
names will be drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_saxt.line">saxt.line</code></td>
<td>
<p>the number of lines into the left margin at which the sample
names will be drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_maxt.line">maxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
module names will be drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_xaxt.line">xaxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
x-axis tick labels will be drawn on the module summary bar plot.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_xaxt.tck">xaxt.tck</code></td>
<td>
<p>the size of the x-axis ticks for the module summary bar 
plot.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_xlab.line">xlab.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
x axis label on the <em>module summary</em> bar plot(s) will be drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_yaxt.line">yaxt.line</code></td>
<td>
<p>the number of lines into the left margin at which the 
y-axis tick labels will be drawn on the weighted degree and node 
contribution bar plots.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_yaxt.tck">yaxt.tck</code></td>
<td>
<p>the size of the y-axis ticks for the weighted degree and 
node contribution bar plots.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_ylab.line">ylab.line</code></td>
<td>
<p>the number of lines into the left margin at which the 
y axis labels on the <em>weighted degree</em> and <em>node contribution</em> 
bar plots will be drawn.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_laxt.line">laxt.line</code></td>
<td>
<p>the distance from the legend to draw the legend axis 
labels, as multiple of <code>laxt.tck</code>.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_laxt.tck">laxt.tck</code></td>
<td>
<p>size of the ticks on each axis legend relative to the
size of the correlation, edge weights, and data matrix heatmaps.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_cex.axis">cex.axis</code></td>
<td>
<p>relative size of the node and sample names.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_legend.main.line">legend.main.line</code></td>
<td>
<p>the distance from the legend to draw the legend 
title.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_cex.lab">cex.lab</code></td>
<td>
<p>relative size of the module names and legend titles.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_cex.main">cex.main</code></td>
<td>
<p>relative size of the plot titles.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_datacols">dataCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the data heatmap (see details). Automatically determined if <code>NA</code> or 
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_datarange">dataRange</code></td>
<td>
<p>the range of values to map to the <code>dataCols</code> gradient
(see details). Automatically determined if <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_corcols">corCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the correlation structure heatmap (see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_corrange">corRange</code></td>
<td>
<p>the range of values to map to the <code>corCols</code> gradient
(see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_netcols">netCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the network edge weight heatmap (see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_netrange">netRange</code></td>
<td>
<p>the range of values to map to the <code>corCols</code> gradient
(see details). Automatically determined if <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_degreecol">degreeCol</code></td>
<td>
<p>color to use for the weighted degree bar plot.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_contribcols">contribCols</code></td>
<td>
<p>color(s) to use for the node contribution bar plot 
(see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_summarycols">summaryCols</code></td>
<td>
<p>color(s) to use for the node contribution bar plot 
(see details).</p>
</td></tr>
<tr><td><code id="plotModule_+3A_nacol">naCol</code></td>
<td>
<p>color to use for missing nodes and samples on the data, 
correlation structure, and network edge weight heat maps.</p>
</td></tr>
<tr><td><code id="plotModule_+3A_dryrun">dryRun</code></td>
<td>
<p>logical; if <code>TRUE</code>, only the axes and labels will be 
drawed.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input data structures:</h4>

<p>The <a href="#topic+modulePreservation">preservation of network modules</a> in a second
dataset is quantified by measuring the preservation of topological
properties between the <em>discovery</em> and <em>test</em> datasets. These 
properties are calculated not only from the interaction networks inferred
in each dataset, but also from the data used to infer those networks (e.g.
gene expression data) as well as the correlation structure between 
variables/nodes. Thus, all functions in the <code>NetRep</code> package have the 
following arguments: 
</p>

<ul>
<li><p><code>network</code>: 
a list of interaction networks, one for each dataset.

</p>
</li>
<li><p><code>data</code>: 
a list of data matrices used to infer those networks, one for each 
dataset.

</p>
</li>
<li><p><code>correlation</code>: 
a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
 
</p>
</li>
<li><p><code>moduleAssignments</code>: 
a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.

</p>
</li>
<li><p><code>modules</code>: 
a list of vectors, one for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  

</p>
</li>
<li><p><code>discovery</code>: 
a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.

</p>
</li>
<li><p><code>test</code>: 
a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.

</p>
</li></ul>

<p>The formatting of these arguments is not strict: each function will attempt
to make sense of the user input. For example, if there is only one 
<code>discovery</code> dataset, then input to the <code>moduleAssigments</code> and 
<code>test</code> arguments may be vectors, rather than lists. If the node and
sample ordering is being calculated within the same dataset being 
visualised, then the <code>discovery</code> and <code>test</code> arguments do
not need to be specified, and the input matrices for the <code>network</code>,
<code>data</code>, and <code>correlation</code> arguments do not need to be wrapped in
a list.
</p>



<h4>Analysing large datasets:</h4>

<p>Matrices in the <code>network</code>, <code>data</code>, and <code>correlation</code> lists
can be supplied as <code><a href="#topic+disk.matrix">disk.matrix</a></code> objects. This class allows 
matrix data to be kept on disk and loaded as required by <span class="pkg">NetRep</span>. 
This dramatically decreases memory usage: the matrices for only one 
dataset will be kept in RAM at any point in time.
</p>



<h4>Node, sample, and module ordering:</h4>

<p>By default, nodes are ordered in decreasing order of <em>weighted degree</em>
in the <code>discovery</code> dataset (see <code><a href="#topic+nodeOrder">nodeOrder</a></code>). Missing 
nodes are colored in grey. This facilitates the visual comparison of 
modules across datasets, as the node ordering will be preserved. 
</p>
<p>Alternatively, a vector containing the names or indices of one or more
datasets can be provided to the <code>orderNodesBy</code> argument. 
</p>
<p>If a single dataset is provided, then nodes will be ordered in decreasing 
order of <em>weighted degree</em> in that dataset. Only nodes that are 
present in this dataset will be drawn when ordering nodes by a dataset 
that is not the <code>discovery</code> dataset for the requested modules(s).
</p>
<p>If multiple datasets are provided then the <em>weighted degree</em> will be
averaged across these datasets (see <a href="#topic+nodeOrder">nodeOrder</a> for more details). 
This is useful for obtaining a robust ordering of nodes by relative 
importance, assuming the modules displayed are preserved in those 
datasets.
</p>
<p>Ordering of nodes by <em>weighted degree</em> can be suppressed by setting
<code>orderNodesBy</code> to <code>NA</code>, in which case nodes will be ordered as 
in the matrices provided in the <code>network</code>, <code>data</code>, and
<code>correlation</code> arguments.
</p>
<p>When multiple modules are drawn, modules are ordered by the similarity
of their summary vectors in the dataset(s) specified in <code>orderNodesBy</code>
argument. If multiple datasets are provided to the <code>orderNodesBy</code>
argument then the module summary vectors are concatenated across datasets.
</p>
<p>By default, samples in the data heatmap and accompanying module summary bar
plot are ordered in descending order of <em>module summary</em> in the drawn 
dataset (specified by the <code>test</code> argument). If multiple modules are 
drawn, samples are ordered as per the left-most module on the plot.
</p>
<p>Alternatively, a vector containing the name or index of another dataset 
may be provided to the <code>orderSamplesBy</code> argument. In this case, 
samples will be ordered in descending order of <em>module summary</em> in 
the specified dataset. This is useful when comparing different 
measurements across samples, for example, gene expression data obtained 
from multiple tissues samples across the same individuals. If the dataset 
specified is the <code>discovery</code> dataset, then missing samples will be 
displayed as horizontal grey bars. If the dataset specified is one of the 
other datasets, samples present in both the specified dataset and the 
<code>test</code> dataset will be displayed first in order of the specified 
dataset, then samples present in only the test dataset will be displayed
underneath a horizontal black line ordered by their module summary vector 
in the test dataset.
</p>
<p>Order of samples by <em>module summary</em> can be suppressed by setting 
<code>orderSamplesBy</code> to <code>NA</code>, in which case samples will be order as
in the matrix provided to the <code>data</code> argument for the drawn dataset.
</p>



<h4>Weighted degree scaling:</h4>

<p>When drawn on a plot, the weighted degree of each node is scaled to the 
maximum weighted degree within its module. The scaled weighted degree is 
measure of relative importance for each node to its module. This makes 
visualisation of multiple modules with different sizes and densities 
possible. However, the scaled weighted degree should only be interpreted
for groups of nodes that have an apparent module structure.
</p>



<h4>Plot layout and device size</h4>

<p>For optimal results we recommend viewing single modules on a PNG device
with a width of 1500, a height of 2700 and a nominal resolution of 300 
(<code>png(filename, width=5*300, height=9*300, res=300))</code>).
</p>
<p><strong>Warning</strong>: PDF and other vectorized devices should not be used when
plotting more than a hundred nodes. Large files will be generated which
may cause image editing programs such as Inkscape or Illustrator to crash
when polishing figures for publication.
</p>
<p>When <code>dryRun</code> is <code>TRUE</code> only the axes, legends, labels, and
title will be drawn, allowing for quick iteration of customisable
parameters to get the plot layout correct.
</p>
<p>If axis labels or legends are drawn off screen then the margins of the 
plot should be adjusted prior to plotting using the 
<code><a href="graphics.html#topic+par">par</a></code> command to increase the margin size 
(see the &quot;mar&quot; option in the <code>par</code> help page).
</p>
<p>The size of text labels can be modified by increasing or decreasing the
<code>cex.main</code>, <code>cex.lab</code>, and <code>cex.axis</code> arguments:
</p>

<ul>
<li><p><code>cex.main</code>: controls the size of the plot title (specified 
in the <code>main</code> argument).
</p>
</li>
<li><p><code>cex.lab</code>: controls the size of the axis labels on the
<em>weighted degree</em>, <em>node contribution</em>,
and <em>module summary</em> bar plots as well as
the size of the module labels and the heatmap 
legend titles.
</p>
</li>
<li><p><code>cex.axis</code>: contols the size of the axis tick labels, 
including the node and sample labels.
</p>
</li></ul>

<p>The position of these labels can be changed through the following 
arguments:
</p>

<ul>
<li><p><code>xaxt.line</code>: controls the distance from the plot the x-axis
tick labels are drawn on the <em>module summary</em> bar plot.
</p>
</li>
<li><p><code>xlab.line</code>: controls the distance from the plot the x-axis 
label is drawn on the <em>module summary</em> bar plot.
</p>
</li>
<li><p><code>yaxt.line</code>: controls the distance from the plot the y-axis 
tick labels are drawn on the <em>weighted degree</em> and  
<em>node contribution</em> bar plots.
</p>
</li>
<li><p><code>ylab.line</code>: controls the distance from the plot the y-axis
label is drawn on the <em>weighted degree</em> and 
<em>node contribution</em> bar plots.
</p>
</li>
<li><p><code>main.line</code>: controls the distance from the plot the title is
drawn.
</p>
</li>
<li><p><code>naxt.line</code>: controls the distance from the plot the node 
labels are drawn.
</p>
</li>
<li><p><code>saxt.line</code>: controls the distance from the plot the sample 
labels are drawn.
</p>
</li>
<li><p><code>maxt.line</code>: controls the distance from the plot the module
labels are drawn.
</p>
</li>
<li><p><code>laxt.line</code>: controls the distance from the heatmap legends
that the gradient legend labels are drawn.
</p>
</li>
<li><p><code>legend.main.line</code>: controls the distance from the heatmap
legends that the legend title is drawn.
</p>
</li></ul>

<p>The rendering of node, sample, and module names can be disabled by setting
<code>plotNodeNames</code>, <code>plotSampleNames</code>, and <code>plotModuleNames</code>
to <code>FALSE</code>.
</p>
<p>The size of the axis ticks can be changed by increasing or decreasing the
following arguments:
</p>

<ul>
<li><p><code>xaxt.tck</code>: size of the x-axis tick labels as a multiple of
the height of the <em>module summary</em> bar plot
</p>
</li>
<li><p><code>yaxt.tck</code>: size of the y-axis tick labels as a multiple of 
the width of the <em>weighted degree</em> or <em>node contribution</em>
bar plots.
</p>
</li>
<li><p><code>laxt.tck</code>: size of the heatmap legend axis ticks as a 
multiple of the width of the data, correlation structure, or 
network edge weight heatmaps.
</p>
</li></ul>

<p>The <code>drawBorders</code> argument controls whether borders are drawn around 
the weighted degree, node contribution, or module summary bar plots. The 
<code>lwd</code> argument controls the thickness of these borders, as well as 
the thickness of axes and axis ticks.
</p>



<h4>Modifying the color palettes:</h4>

<p>The <code>dataCols</code> and <code>dataRange</code> arguments control the appearance 
of the data heatmap (see <code><a href="#topic+plotData">plotData</a></code>). The gradient of colors 
used on the heatmap can be changed by specifying a vector of colors to 
interpolate between in <code>dataCols</code> and <code>dataRange</code> specifies the 
range of values that maps to this gradient. Values outside of the 
specified <code>dataRange</code> will be rendered with the colors used at either
extreme of the gradient. The default gradient is determined based on the 
<code>data</code> shown on the plot. If all values in the <code>data</code> matrix are
positive, then the gradient is interpolated between white and green, where
white is used for the smallest value and green for the largest. If all
values are negative, then the gradient is interpolated between purple and
white, where purple is used for the smallest value and white for the value
closest to zero. If the data contains both positive and negative values, 
then the gradient is interpolated between purple, white, and green, where 
white is used for values of zero. In this case the range shown is always 
centered at zero, with the values at either extreme determined by the 
value in the rendered <code>data</code> with the strongest magnitude (the 
maximum of the absolute value).
</p>
<p>The <code>corCols</code> and <code>corRange</code> arguments control the appearance of
the correlation structure heatmap (see <code><a href="#topic+plotCorrelation">plotCorrelation</a></code>). The
gradient of colors used on the heatmap can be changed by specifying a
vector of colors to interpolate between in <code>corCols</code>. By default,
strong negative correlations are shown in blue, and strong positive
correlations in red, and weak correlations as white. <code>corRange</code> 
controls the range of values that this gradient maps to, by default, -1 to
1. Changing this may be useful for showing differences where range of 
correlation coefficients is small.
</p>
<p>The <code>netCols</code> and <code>netRange</code> arguments control the appearance of
the network edge weight heatmap (see <code><a href="#topic+plotNetwork">plotNetwork</a></code>). The
gradient of colors used on the heatmap can be changed by specifying a
vector of colors to interpolate between in <code>netCols</code>. By default,
weak or non-edges are shown in white, while strong edges are shown in red.
The <code>netRange</code> controls the range of values this gradient maps to, 
by default, 0 to 1. If <code>netRange</code> is set to <code>NA</code>, then the 
gradient will be mapped to values between 0 and the maximum edge weight of
the shown network.
</p>
<p>The <code>degreeCol</code> argument controls the color of the weighted degree
bar plot (see <code><a href="#topic+plotDegree">plotDegree</a></code>).
</p>
<p>The <code>contribCols</code> argument controls the color of the node 
contribution bar plot (see <code><a href="#topic+plotContribution">plotContribution</a></code>. This can be 
specified as single value to be used for all nodes, or as two colors: one
to use for nodes with positive contributions and one to use for nodes with
negative contributions.
</p>
<p>The <code>summaryCols</code> argument controls the color of the module summary 
bar plot (see <code><a href="#topic+plotSummary">plotSummary</a></code>. This can be specified as single
value to be used for all samples, or as two colors: one to use for samples
with a positive module summary value and one fpr samples with a negative
module summary value.
</p>
<p>The <code>naCol</code> argument controls the color of missing nodes and samples
on the data, correlaton structure, and network edge weight heatmaps.
</p>



<h4>Embedding in Rmarkdown documents</h4>

<p>The chunk option <code>fig.keep="last"</code> should be set to avoid an empty 
plot being embedded above the plot generated by <code>plotModule</code>. This
empty plot is generated so that an error will be thrown as early as 
possible if the margins are too small to be displayed. Normally, these
are drawn over with the actual plot components when drawing the plot on
other graphical devices.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+plotCorrelation">plotCorrelation</a></code>, 
<code><a href="#topic+plotNetwork">plotNetwork</a></code>,
<code><a href="#topic+plotDegree">plotDegree</a></code>,
<code><a href="#topic+plotContribution">plotContribution</a></code>,
<code><a href="#topic+plotData">plotData</a></code>, and
<code><a href="#topic+plotSummary">plotSummary</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in example data, correlation, and network matrices for a discovery 
# and test dataset:
data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Plot module 1, 2 and 4 in the discovery dataset
plotModule(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 2, 4)
)

# Now plot them in the test dataset (module 2 does not replicate)
plotModule(
  network=network_list,data=data_list, correlation=correlation_list,
  moduleAssignments=labels_list, modules=c(1, 2, 4), discovery="discovery",
  test="test"
)

# Plot modules 1 and 4, which replicate, in the test datset ordering nodes
# by weighted degree averaged across the two datasets
plotModule(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 4), discovery="discovery",
  test="test", orderNodesBy=c("discovery", "test")
)

</code></pre>

<hr>
<h2 id='plotTopology'>Plot a topological feature of network module</h2><span id='topic+plotTopology'></span><span id='topic+plotData'></span><span id='topic+plotCorrelation'></span><span id='topic+plotNetwork'></span><span id='topic+plotContribution'></span><span id='topic+plotDegree'></span><span id='topic+plotSummary'></span>

<h3>Description</h3>

<p>Functions for plotting the topology of a network module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotData(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderSamplesBy = NULL,
  orderNodesBy = NULL,
  orderModules = TRUE,
  plotNodeNames = TRUE,
  plotSampleNames = TRUE,
  plotModuleNames = NULL,
  main = "",
  main.line = 1,
  lwd = 1,
  plotLegend = TRUE,
  legend.main = "Data",
  legend.main.line = 1,
  naxt.line = -0.5,
  saxt.line = -0.5,
  maxt.line = 3,
  legend.position = 0.15,
  laxt.tck = 0.03,
  laxt.line = 3,
  cex.axis = 0.8,
  cex.lab = 1.2,
  cex.main = 2,
  dataCols = NULL,
  dataRange = NULL,
  naCol = "#bdbdbd",
  dryRun = FALSE
)

plotCorrelation(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderNodesBy = NULL,
  symmetric = FALSE,
  orderModules = TRUE,
  plotNodeNames = TRUE,
  plotModuleNames = NULL,
  main = "",
  main.line = 1,
  lwd = 1,
  plotLegend = TRUE,
  legend.main = "Correlation",
  legend.main.line = 1,
  naxt.line = -0.5,
  maxt.line = 3,
  legend.position = NULL,
  laxt.tck = NULL,
  laxt.line = NULL,
  cex.axis = 0.8,
  cex.lab = 1.2,
  cex.main = 2,
  corCols = correlation.palette(),
  corRange = c(-1, 1),
  naCol = "#bdbdbd",
  dryRun = FALSE
)

plotNetwork(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderNodesBy = NULL,
  symmetric = FALSE,
  orderModules = TRUE,
  plotNodeNames = TRUE,
  plotModuleNames = NULL,
  main = "",
  main.line = 1,
  lwd = 1,
  plotLegend = TRUE,
  legend.main = "Edge weight",
  legend.main.line = 1,
  naxt.line = -0.5,
  maxt.line = 3,
  legend.position = NULL,
  laxt.tck = NULL,
  laxt.line = NULL,
  cex.axis = 0.8,
  cex.lab = 1.2,
  cex.main = 2,
  netCols = network.palette(),
  netRange = c(0, 1),
  naCol = "#bdbdbd",
  dryRun = FALSE
)

plotContribution(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderNodesBy = NULL,
  orderModules = TRUE,
  plotNodeNames = TRUE,
  plotModuleNames = NULL,
  main = "",
  main.line = 1,
  ylab.line = 2.5,
  lwd = 1,
  drawBorders = FALSE,
  naxt.line = -0.5,
  maxt.line = 3,
  yaxt.line = 0,
  yaxt.tck = -0.035,
  cex.axis = 0.8,
  cex.lab = 1.2,
  cex.main = 2,
  contribCols = c("#A50026", "#313695"),
  naCol = "#bdbdbd",
  dryRun = FALSE
)

plotDegree(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderNodesBy = NULL,
  orderModules = TRUE,
  plotNodeNames = TRUE,
  plotModuleNames = NULL,
  main = "",
  main.line = 1,
  lwd = 1,
  drawBorders = FALSE,
  naxt.line = -0.5,
  maxt.line = 3,
  yaxt.line = 0,
  yaxt.tck = -0.035,
  ylab.line = 2.5,
  cex.axis = 0.8,
  cex.lab = 1.2,
  cex.main = 2,
  degreeCol = "#feb24c",
  naCol = "#bdbdbd",
  dryRun = FALSE
)

plotSummary(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  verbose = TRUE,
  orderSamplesBy = NULL,
  orderNodesBy = NULL,
  orderModules = TRUE,
  plotSampleNames = TRUE,
  plotModuleNames = NULL,
  main = "",
  main.line = 1,
  xlab.line = 2.5,
  lwd = 1,
  drawBorders = FALSE,
  saxt.line = -0.5,
  maxt.line = 0,
  xaxt.line = 0,
  xaxt.tck = -0.025,
  cex.axis = 0.8,
  cex.lab = 1.2,
  cex.main = 2,
  summaryCols = c("#1B7837", "#762A83"),
  naCol = "#bdbdbd",
  dryRun = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotTopology_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_ordersamplesby">orderSamplesBy</code></td>
<td>
<p><code>NULL</code> (default), <code>NA</code>, or a vector 
containing a single dataset name or index. Controls how samples are ordered 
on the plot (see details).</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_ordernodesby">orderNodesBy</code></td>
<td>
<p><code>NULL</code> (default), <code>NA</code>, or a vector of dataset
names or indices. Controls how nodes are ordered on the plot (see details).</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_ordermodules">orderModules</code></td>
<td>
<p>logical; if <code>TRUE</code> modules ordered by clustering 
their summary vectors. If <code>FALSE</code> modules are returned in the order
provided.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_plotnodenames">plotNodeNames</code></td>
<td>
<p>logical; controls whether the node names are 
drawed on the bottom axis.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_plotsamplenames">plotSampleNames</code></td>
<td>
<p>logical; controls whether the sample names are 
drawed on the left axis.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_plotmodulenames">plotModuleNames</code></td>
<td>
<p>logical; controls whether module names are drawed.
The default is for module names to be drawed when multiple <code>modules</code> 
are drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_main">main</code></td>
<td>
<p>title for the plot.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_main.line">main.line</code></td>
<td>
<p>the number of lines into the top margin at which the plot
title will be drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and axes.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_plotlegend">plotLegend</code></td>
<td>
<p>logical; controls whether a legend is drawn when using
<code>plotCorrelation</code>, <code>plotNetwork</code>, or <code>plotData</code>.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_legend.main">legend.main</code></td>
<td>
<p>title for the legend.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_legend.main.line">legend.main.line</code></td>
<td>
<p>the distance from the legend to draw the legend 
title.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_naxt.line">naxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the node
names will be drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_saxt.line">saxt.line</code></td>
<td>
<p>the number of lines into the left margin at which the sample
names will be drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_maxt.line">maxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
module names will be drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_legend.position">legend.position</code></td>
<td>
<p>the distance from the plot to start the legend, as a
proportion of the plot width.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_laxt.tck">laxt.tck</code></td>
<td>
<p>size of the ticks on each axis legend relative to the
size of the correlation, edge weights, and data matrix heatmaps.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_laxt.line">laxt.line</code></td>
<td>
<p>the distance from the legend to draw the legend axis 
labels, as multiple of <code>laxt.tck</code>.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_cex.axis">cex.axis</code></td>
<td>
<p>relative size of the node and sample names.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_cex.lab">cex.lab</code></td>
<td>
<p>relative size of the module names and legend titles.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_cex.main">cex.main</code></td>
<td>
<p>relative size of the plot titles.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_datacols">dataCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the data heatmap (see details). Automatically determined if <code>NA</code> or 
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_datarange">dataRange</code></td>
<td>
<p>the range of values to map to the <code>dataCols</code> gradient
(see details). Automatically determined if <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_nacol">naCol</code></td>
<td>
<p>color to use for missing nodes and samples on the data, 
correlation structure, and network edge weight heat maps.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_dryrun">dryRun</code></td>
<td>
<p>logical; if <code>TRUE</code>, only the axes and labels will be 
drawed.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_symmetric">symmetric</code></td>
<td>
<p>logical; controls whether the correlation and network 
heatmaps are drawn as symmetric (square) heatmaps or asymettric triangle 
heatmaps. If symmetric, then the node and module names will also be rendered
on the left axis.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_corcols">corCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the correlation structure heatmap (see details).</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_corrange">corRange</code></td>
<td>
<p>the range of values to map to the <code>corCols</code> gradient
(see details).</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_netcols">netCols</code></td>
<td>
<p>a character vector of colors to create a gradient from for
the network edge weight heatmap (see details).</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_netrange">netRange</code></td>
<td>
<p>the range of values to map to the <code>corCols</code> gradient
(see details). Automatically determined if <code>NA</code> or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_ylab.line">ylab.line</code></td>
<td>
<p>the number of lines into the left margin at which the 
y axis labels on the <em>weighted degree</em> and <em>node contribution</em> 
bar plots will be drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_drawborders">drawBorders</code></td>
<td>
<p>logical; if <code>TRUE</code>, borders are drawn around the 
<em>weighted degree</em>, <em>node conribution</em>, and <em>module summary</em>
bar plots.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_yaxt.line">yaxt.line</code></td>
<td>
<p>the number of lines into the left margin at which the 
y-axis tick labels will be drawn on the weighted degree and node 
contribution bar plots.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_yaxt.tck">yaxt.tck</code></td>
<td>
<p>the size of the y-axis ticks for the weighted degree and 
node contribution bar plots.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_contribcols">contribCols</code></td>
<td>
<p>color(s) to use for the node contribution bar plot 
(see details).</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_degreecol">degreeCol</code></td>
<td>
<p>color to use for the weighted degree bar plot.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_xlab.line">xlab.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
x axis label on the <em>module summary</em> bar plot(s) will be drawn.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_xaxt.line">xaxt.line</code></td>
<td>
<p>the number of lines into the bottom margin at which the 
x-axis tick labels will be drawn on the module summary bar plot.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_xaxt.tck">xaxt.tck</code></td>
<td>
<p>the size of the x-axis ticks for the module summary bar 
plot.</p>
</td></tr>
<tr><td><code id="plotTopology_+3A_summarycols">summaryCols</code></td>
<td>
<p>color(s) to use for the node contribution bar plot 
(see details).</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input data structures:</h4>

<p>The <a href="#topic+modulePreservation">preservation of network modules</a> in a second
dataset is quantified by measuring the preservation of topological
properties between the <em>discovery</em> and <em>test</em> datasets. These 
properties are calculated not only from the interaction networks inferred
in each dataset, but also from the data used to infer those networks (e.g.
gene expression data) as well as the correlation structure between 
variables/nodes. Thus, all functions in the <code>NetRep</code> package have the 
following arguments: 
</p>

<ul>
<li><p><code>network</code>:
a list of interaction networks, one for each dataset.

</p>
</li>
<li><p><code>data</code>:
a list of data matrices used to infer those networks, one for each 
dataset.

</p>
</li>
<li><p><code>correlation</code>:
a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
 
</p>
</li>
<li><p><code>moduleAssignments</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.

</p>
</li>
<li><p><code>modules</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  

</p>
</li>
<li><p><code>discovery</code>:
a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.

</p>
</li>
<li><p><code>test</code>:
a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.

</p>
</li></ul>

<p>The formatting of these arguments is not strict: each function will attempt
to make sense of the user input. For example, if there is only one 
<code>discovery</code> dataset, then input to the <code>moduleAssigments</code> and 
<code>test</code> arguments may be vectors, rather than lists. If the node and
sample ordering is being calculated within the same dataset being 
visualised, then the <code>discovery</code> and <code>test</code> arguments do
not need to be specified, and the input matrices for the <code>network</code>,
<code>data</code>, and <code>correlation</code> arguments do not need to be wrapped in
a list.
</p>



<h4>Analysing large datasets:</h4>

<p>Matrices in the <code>network</code>, <code>data</code>, and <code>correlation</code> lists
can be supplied as <code><a href="#topic+disk.matrix">disk.matrix</a></code> objects. This class allows 
matrix data to be kept on disk and loaded as required by <span class="pkg">NetRep</span>. 
This dramatically decreases memory usage: the matrices for only one 
dataset will be kept in RAM at any point in time.
</p>



<h4>Node, sample, and module ordering:</h4>

<p>By default, nodes are ordered in decreasing order of <em>weighted degree</em>
in the <code>discovery</code> dataset (see <code><a href="#topic+nodeOrder">nodeOrder</a></code>). Missing 
nodes are colored in grey. This facilitates the visual comparison of 
modules across datasets, as the node ordering will be preserved. 
</p>
<p>Alternatively, a vector containing the names or indices of one or more
datasets can be provided to the <code>orderNodesBy</code> argument. 
</p>
<p>If a single dataset is provided, then nodes will be ordered in decreasing 
order of <em>weighted degree</em> in that dataset. Only nodes that are 
present in this dataset will be drawn when ordering nodes by a dataset 
that is not the <code>discovery</code> dataset for the requested modules(s).
</p>
<p>If multiple datasets are provided then the <em>weighted degree</em> will be
averaged across these datasets (see <a href="#topic+nodeOrder">nodeOrder</a> for more details). 
This is useful for obtaining a robust ordering of nodes by relative 
importance, assuming the modules displayed are preserved in those 
datasets.
</p>
<p>Ordering of nodes by <em>weighted degree</em> can be suppressed by setting
<code>orderNodesBy</code> to <code>NA</code>, in which case nodes will be ordered as 
in the matrices provided in the <code>network</code>, <code>data</code>, and
<code>correlation</code> arguments.
</p>
<p>When multiple modules are drawn, modules are ordered by the similarity
of their summary vectors in the dataset(s) specified in <code>orderNodesBy</code>
argument. If multiple datasets are provided to the <code>orderNodesBy</code>
argument then the module summary vectors are concatenated across datasets.
</p>
<p>By default, samples in the data heatmap and accompanying module summary bar
plot are ordered in descending order of <em>module summary</em> in the drawn 
dataset (specified by the <code>test</code> argument). If multiple modules are 
drawn, samples are ordered as per the left-most module on the plot.
</p>
<p>Alternatively, a vector containing the name or index of another dataset 
may be provided to the <code>orderSamplesBy</code> argument. In this case, 
samples will be ordered in descending order of <em>module summary</em> in 
the specified dataset. This is useful when comparing different 
measurements across samples, for example, gene expression data obtained 
from multiple tissues samples across the same individuals. If the dataset 
specified is the <code>discovery</code> dataset, then missing samples will be 
displayed as horizontal grey bars. If the dataset specified is one of the 
other datasets, samples present in both the specified dataset and the 
<code>test</code> dataset will be displayed first in order of the specified 
dataset, then samples present in only the test dataset will be displayed
underneath a horizontal black line ordered by their module summary vector 
in the test dataset.  
</p>
<p>Order of samples by <em>module summary</em> can be suppressed by setting 
<code>orderSamplesBy</code> to <code>NA</code>, in which case samples will be order as
in the matrix provided to the <code>data</code> argument for the drawn dataset.
</p>



<h4>Weighted degree scaling:</h4>

<p>When drawn on a plot, the weighted degree of each node is scaled to the 
maximum weighted degree within its module. The scaled weighted degree is 
measure of relative importance for each node to its module. This makes 
visualisation of multiple modules with different sizes and densities 
possible. However, the scaled weighted degree should only be interpreted
for groups of nodes that have an apparent module structure.
</p>



<h4>Plot layout and device size</h4>

<p>Although reasonable default values for most parameters have been provided,
the rendering of axes and titles may need adjusting depending on the size
of the plot window. The <code>dryRun</code> argument is useful for quickly 
determining whether the plot will render correctly. When <code>dryRun</code> 
is <code>TRUE</code> only the axes, legends, labels, and title will be drawn, 
allowing for quick iteration of customisable parameters to get the plot 
layout correct. 
</p>
<p><strong>Warning</strong>: PDF and other vectorized devices should not be used when
plotting the heatmaps with more than a hundred nodes. Large files will be
generated which may cause image editing programs such as Inkscape or
Illustrator to crash when polishing figures for publication.
</p>
<p>If axis labels or legends are drawn off screen then the margins of the 
plot should be adjusted prior to plotting using the 
<code><a href="graphics.html#topic+par">par</a></code> command to increase the margin size 
(see the &quot;mar&quot; option in the <code>par</code> help page).
</p>
<p>The size of text labels can be modified by increasing or decreasing the
<code>cex.main</code>, <code>cex.lab</code>, and <code>cex.axis</code> arguments:
</p>

<ul>
<li><p><code>cex.main</code>: controls the size of the plot title (specified 
in the <code>main</code> argument).
</p>
</li>
<li><p><code>cex.lab</code>: controls the size of the axis labels on the
<em>weighted degree</em>, <em>node contribution</em>,
and <em>module summary</em> bar plots as well as
the size of the module labels and the heatmap 
legend titles.
</p>
</li>
<li><p><code>cex.axis</code>: contols the size of the axis tick labels, 
including the node and sample labels.
</p>
</li></ul>

<p>The position of these labels can be changed through the following 
arguments:
</p>

<ul>
<li><p><code>xaxt.line</code>: controls the distance from the plot the x-axis
tick labels are drawn on the <em>module summary</em> bar plot.
</p>
</li>
<li><p><code>xlab.line</code>: controls the distance from the plot the x-axis 
label is drawn on the <em>module summary</em> bar plot.
</p>
</li>
<li><p><code>yaxt.line</code>: controls the distance from the plot the y-axis 
tick labels are drawn on the <em>weighted degree</em> and  
<em>node contribution</em> bar plots.
</p>
</li>
<li><p><code>ylab.line</code>: controls the distance from the plot the y-axis
label is drawn on the <em>weighted degree</em> and 
<em>node contribution</em> bar plots.
</p>
</li>
<li><p><code>main.line</code>: controls the distance from the plot the title is
drawn.
</p>
</li>
<li><p><code>naxt.line</code>: controls the distance from the plot the node 
labels are drawn.
</p>
</li>
<li><p><code>saxt.line</code>: controls the distance from the plot the sample 
labels are drawn.
</p>
</li>
<li><p><code>maxt.line</code>: controls the distance from the plot the module
labels are drawn.
</p>
</li>
<li><p><code>laxt.line</code>: controls the distance from the heatmap legends
that the gradient legend labels are drawn.
</p>
</li>
<li><p><code>legend.main.line</code>: controls the distance from the heatmap
legends that the legend title is drawn.
</p>
</li></ul>

<p>The rendering of node, sample, and module names can be disabled by setting
<code>plotNodeNames</code>, <code>plotSampleNames</code>, and <code>plotModuleNames</code>
to <code>FALSE</code>.
</p>
<p>The size of the axis ticks can be changed by increasing or decreasing the
following arguments:
</p>

<ul>
<li><p><code>xaxt.tck</code>: size of the x-axis tick labels as a multiple of
the height of the <em>module summary</em> bar plot
</p>
</li>
<li><p><code>yaxt.tck</code>: size of the y-axis tick labels as a multiple of 
the width of the <em>weighted degree</em> or <em>node contribution</em>
bar plots.
</p>
</li>
<li><p><code>laxt.tck</code>: size of the heatmap legend axis ticks as a 
multiple of the width of the data, correlation structure, or 
network edge weight heatmaps.
</p>
</li></ul>

<p>The placement of heatmap legends is controlled by the following arguments:
</p>

<ul>
<li><p><code>plotLegend</code>: if <code>FALSE</code> legend will not be drawn.
</p>
</li>
<li><p><code>legend.position</code>: a multiple of the plot width, controls 
the horizontal distance from the plot the legend is drawn.
</p>
</li></ul>
 
<p>The <code>drawBorders</code> argument controls whether borders are drawn around 
the weighted degree, node contribution, or module summary bar plots. The 
<code>lwd</code> argument controls the thickness of these borders, as well as 
the thickness of axes and axis ticks.
</p>



<h4>Modifying the color palettes:</h4>

<p>The <code>dataCols</code> and <code>dataRange</code> arguments control the appearance 
of the data heatmap (see <code><a href="#topic+plotData">plotData</a></code>). The gradient of colors 
used on the heatmap can be changed by specifying a vector of colors to 
interpolate between in <code>dataCols</code> and <code>dataRange</code> specifies the 
range of values that maps to this gradient. Values outside of the 
specified <code>dataRange</code> will be rendered with the colors used at either
extreme of the gradient. The default gradient is determined based on the 
<code>data</code> shown on the plot. If all values in the <code>data</code> matrix are
positive, then the gradient is interpolated between white and green, where
white is used for the smallest value and green for the largest. If all
values are negative, then the gradient is interpolated between purple and
white, where purple is used for the smallest value and white for the value
closest to zero. If the data contains both positive and negative values, 
then the gradient is interpolated between purple, white, and green, where 
white is used for values of zero. In this case the range shown is always 
centered at zero, with the values at either extreme determined by the 
value in the rendered <code>data</code> with the strongest magnitude (the 
maximum of the absolute value).
</p>
<p>The <code>corCols</code> and <code>corRange</code> arguments control the appearance of
the correlation structure heatmap (see <code><a href="#topic+plotCorrelation">plotCorrelation</a></code>). The
gradient of colors used on the heatmap can be changed by specifying a
vector of colors to interpolate between in <code>corCols</code>. By default,
strong negative correlations are shown in blue, and strong positive
correlations in red, and weak correlations as white. <code>corRange</code> 
controls the range of values that this gradient maps to, by default, -1 to
1. Changing this may be useful for showing differences where range of 
correlation coefficients is small.
</p>
<p>The <code>netCols</code> and <code>netRange</code> arguments control the appearance of
the network edge weight heatmap (see <code><a href="#topic+plotNetwork">plotNetwork</a></code>). The
gradient of colors used on the heatmap can be changed by specifying a
vector of colors to interpolate between in <code>netCols</code>. By default,
weak or non-edges are shown in white, while strong edges are shown in red.
The <code>netRange</code> controls the range of values this gradient maps to, 
by default, 0 to 1. If <code>netRange</code> is set to <code>NA</code>, then the 
gradient will be mapped to values between 0 and the maximum edge weight of
the shown network.
</p>
<p>The <code>degreeCol</code> argument controls the color of the weighted degree
bar plot (see <code><a href="#topic+plotDegree">plotDegree</a></code>).
</p>
<p>The <code>contribCols</code> argument controls the color of the node 
contribution bar plot (see <code><a href="#topic+plotContribution">plotContribution</a></code>. This can be 
specified as single value to be used for all nodes, or as two colors: one
to use for nodes with positive contributions and one to use for nodes with
negative contributions.
</p>
<p>The <code>summaryCols</code> argument controls the color of the module summary 
bar plot (see <code><a href="#topic+plotSummary">plotSummary</a></code>. This can be specified as single
value to be used for all samples, or as two colors: one to use for samples
with a positive module summary value and one fpr samples with a negative
module summary value.
</p>
<p>The <code>naCol</code> argument controls the color of missing nodes and samples
on the data, correlaton structure, and network edge weight heatmaps.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+plotModule">plotModule</a></code> for a combined plot showing all topological 
properties for a network module.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in example data, correlation, and network matrices for a discovery and test dataset:
data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Plot the data for module 1, 2 and 4 in the discovery dataset
plotData(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 2, 4)
)

# Symmetric = TRUE gives a traditional heatmap for the correlation structure
# and weighted network
plotCorrelation(
  network=network_list, data=data_list, correlation=correlation_list,
  moduleAssignments=labels_list, modules=c(1, 2, 4), symmetric=TRUE
)

# While the default is to render only one half of the (symmetric) matrix
plotNetwork(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 2, 4)
)

# Plot the degree of nodes in each module in the test dataset, but show them
# in the same order as the discovery dataset to compare how node degree 
# changes
plotDegree(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 2, 4), discovery="discovery",
  test="test"
)

# Alternatively nodes can be ordered on the plot by degree in the test dataset
plotDegree(
  network=network_list, data=data_list, correlation=correlation_list,
  moduleAssignments=labels_list, modules=c(1, 2, 4), discovery="discovery",
  test="test", orderNodesBy="test"
)

# Or by averaging the degree across datasets for a more robust ordering  
plotDegree(
 network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 2, 4), discovery="discovery",
  test="test", orderNodesBy=c("discovery", "test")
)

# Arbitrary subsets can be plotted:
plotContribution(
  network=network_list[[1]][1:10, 1:10], data=data_list[[1]][, 1:10], 
  correlation=correlation_list[[1]][1:10, 1:10], orderNodesBy=NA
)

# Plot the module summary vectors for multiple modules:
plotSummary(
  network=network_list, data=data_list, correlation=correlation_list, 
  moduleAssignments=labels_list, modules=c(1, 2, 4), discovery="discovery",
  test="test", orderSamplesBy="test"
)

</code></pre>

<hr>
<h2 id='requiredPerms'>How many permutations do I need to test at my desired significance level?</h2><span id='topic+requiredPerms'></span>

<h3>Description</h3>

<p>How many permutations do I need to test at my desired significance level?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>requiredPerms(alpha, alternative = "greater")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="requiredPerms_+3A_alpha">alpha</code></td>
<td>
<p>desired significance threshold.</p>
</td></tr>
<tr><td><code id="requiredPerms_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, 
must be one of &quot;greater&quot; (default), &quot;less&quot;, or &quot;two.sided&quot;. 
You can specify just the initial letter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The minimum number of permutations required to detect any significant
associations at the provided <code>alpha</code>. The minimum p-value will always
be smaller than <code>alpha</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# How many permutations are required to Bonferroni adjust for the 4 modules 
# in the example data? 
nPerm &lt;- requiredPerms(0.05/4) 

# Note that we recommend running at least 10,000 permutations to make sure 
# that the null distributions are representative.

preservation &lt;- modulePreservation(
 network=network_list, data=data_list, correlation=correlation_list, 
 moduleAssignments=labels_list, nPerm=nPerm, discovery="discovery", 
 test="test"
)

</code></pre>

<hr>
<h2 id='sampleOrder'>Order samples within a network.</h2><span id='topic+sampleOrder'></span>

<h3>Description</h3>

<p>Get the order of samples within a module based on the module summary vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleOrder(
  network,
  data,
  correlation,
  moduleAssignments = NULL,
  modules = NULL,
  backgroundLabel = "0",
  discovery = NULL,
  test = NULL,
  na.rm = FALSE,
  simplify = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleOrder_+3A_network">network</code></td>
<td>
<p>a list of interaction networks, one for each dataset. Each 
entry of the list should be a <code class="reqn">n * n</code> matrix or where each element 
contains the edge weight between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the inferred 
network for that dataset.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_data">data</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of the list 
should be the data used to infer the interaction <code>network</code> for that 
dataset. The columns should correspond to variables in the data
(nodes in the network) and rows to samples in that dataset.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_correlation">correlation</code></td>
<td>
<p>a list of matrices, one for each dataset. Each entry of
the list should be a <code class="reqn">n * n</code> matrix where each element contains the 
correlation coefficient between nodes <code class="reqn">i</code> and <code class="reqn">j</code> in the 
<code>data</code> used to infer the interaction network for that dataset.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_moduleassignments">moduleAssignments</code></td>
<td>
<p>a list of vectors, one for each <em>discovery</em> 
dataset, containing the module assignments for each node in that dataset.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_modules">modules</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset, 
of modules to perform the analysis on. If unspecified, all modules
in each <code>discovery</code> dataset will be analysed, with the exception of 
those specified in <code>backgroundLabel</code> argument.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_backgroundlabel">backgroundLabel</code></td>
<td>
<p>a single label given to nodes that do not belong to 
any module in the <code>moduleAssignments</code> argument. Defaults to &quot;0&quot;. Set 
to <code>NULL</code> if you do not want to skip the network background module.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_discovery">discovery</code></td>
<td>
<p>a vector of names or indices denoting the <em>discovery</em>
dataset(s) in the <code>data</code>, <code>correlation</code>, <code>network</code>, 
<code>moduleAssignments</code>, <code>modules</code>, and <code>test</code> lists.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_test">test</code></td>
<td>
<p>a list of vectors, one for each <code>discovery</code> dataset,
of names or indices denoting the <em>test</em> dataset(s) in the <code>data</code>, 
<code>correlation</code>, and <code>network</code> lists.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; If <code>TRUE</code> variables present in the 
<code>discovery</code> dataset but missing from the <code>test</code> dataset are 
excluded. If <code>FALSE</code> missing variables are put last in the ordering.</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_simplify">simplify</code></td>
<td>
<p>logical; if <code>TRUE</code>, simplify the structure of the output
list if possible (see Return Value).</p>
</td></tr>
<tr><td><code id="sampleOrder_+3A_verbose">verbose</code></td>
<td>
<p>logical; should progress be reported? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input data structures:</h4>

<p>The <a href="#topic+modulePreservation">preservation of network modules</a> in a second
dataset is quantified by measuring the preservation of topological
properties between the <em>discovery</em> and <em>test</em> datasets. These 
properties are calculated not only from the interaction networks inferred
in each dataset, but also from the data used to infer those networks (e.g.
gene expression data) as well as the correlation structure between 
variables/nodes. Thus, all functions in the <code>NetRep</code> package have the 
following arguments: 
</p>

<ul>
<li><p><code>network</code>:
a list of interaction networks, one for each dataset.

</p>
</li>
<li><p><code>data</code>:
a list of data matrices used to infer those networks, one for each 
dataset.

</p>
</li>
<li><p><code>correlation</code>:
a list of matrices containing the pairwise correlation coefficients 
between variables/nodes in each dataset.
 
</p>
</li>
<li><p><code>moduleAssignments</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing 
the module assignments for each node in that dataset.

</p>
</li>
<li><p><code>modules</code>:
a list of vectors, one for each <em>discovery</em> dataset, containing
the names of the modules from that dataset to analyse.  

</p>
</li>
<li><p><code>discovery</code>:
a vector indicating the names or indices of the previous arguments' 
lists to use as the <em>discovery</em> dataset(s) for the analyses.

</p>
</li>
<li><p><code>test</code>:
a list of vectors, one vector for each <em>discovery</em> dataset, 
containing the names or indices of the <code>network</code>, <code>data</code>, and 
<code>correlation</code> argument lists to use as the <em>test</em> dataset(s) 
for the analysis of each <em>discovery</em> dataset.

</p>
</li></ul>

<p>The formatting of these arguments is not strict: each function will attempt
to make sense of the user input. For example, if there is only one 
<code>discovery</code> dataset, then input to the <code>moduleAssigments</code> and 
<code>test</code> arguments may be vectors, rather than lists. If the 
<code>sampleOrder</code> are being calculate within the <em>discovery</em> or
<em>test</em> datasets, then the <code>discovery</code> and <code>test</code> arguments do
not need to be specified, and the input matrices for the <code>network</code>,
<code>data</code>, and <code>correlation</code> arguments do not need to be wrapped in
a list.
</p>



<h4>Analysing large datasets:</h4>

<p>Matrices in the <code>network</code>, <code>data</code>, and <code>correlation</code> lists
can be supplied as <code><a href="#topic+disk.matrix">disk.matrix</a></code> objects. This class allows 
matrix data to be kept on disk and loaded as required by <span class="pkg">NetRep</span>. 
This dramatically decreases memory usage: the matrices for only one 
dataset will be kept in RAM at any point in time.
</p>



<h3>Value</h3>

<p>A nested list structure. At the top level, the list has one element per 
<code>'discovery'</code> dataset. Each of these elements is a list that has one
element per <code>'test'</code> dataset analysed for that <code>'discovery'</code> 
dataset. Each of these elements is a list that has one element per 
<code>'modules'</code> specified, containing a vector of node names for the
requested module. When <code>simplify = TRUE</code> then the simplest possible 
structure will be returned. E.g. if the sample ordering are requested for 
in only one dataset, then a single vector of node labels will be returned. 
</p>
<p>When <code>simplify = FALSE</code> then a nested list of datasets will always be 
returned, i.e. each element at the top level and second level correspond to 
a dataset, and each element at the third level will correspond to modules 
discovered in the dataset specified at the top level if module labels are 
provided in the corresponding <code>moduleAssignments</code> list element. E.g. 
<code>results[["Dataset1"]][["Dataset2"]][["module1"]]</code> will contain the 
order of samples calculated in &quot;Dataset2&quot;, where &quot;module1&quot; was indentified
in &quot;Dataset1&quot;. Modules and datasets for which calculation of the sample
order have not been requested will contain <code>NULL</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+networkProperties">networkProperties</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load in example data, correlation, and network matrices for a discovery 
# and test dataset:
data("NetRep")

# Set up input lists for each input matrix type across datasets. The list
# elements can have any names, so long as they are consistent between the
# inputs.
network_list &lt;- list(discovery=discovery_network, test=test_network)
data_list &lt;- list(discovery=discovery_data, test=test_data)
correlation_list &lt;- list(discovery=discovery_correlation, test=test_correlation)
labels_list &lt;- list(discovery=module_labels)

# Sort nodes within module 1 in descending order by module summary
samples &lt;- sampleOrder(
  network=network_list, data=data_list, correlation=correlation_list,
  moduleAssignments=labels_list, modules="1" 
)

</code></pre>

<hr>
<h2 id='simplify_param'>Template parameters</h2><span id='topic+simplify_param'></span>

<h3>Description</h3>

<p>Template parameters to be imported into other function documentation. This 
is not intended to be a stand-alone help file.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplify_param_+3A_simplify">simplify</code></td>
<td>
<p>logical; if <code>TRUE</code>, simplify the structure of the output
list if possible (see Return Value).</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
