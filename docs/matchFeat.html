<!DOCTYPE html><html lang="en"><head><title>Help for package matchFeat</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {matchFeat}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#matchFeat-package'>
<p>One-to-One Feature Matching</p></a></li>
<li><a href='#match.2x'>
<p>Pairwise Interchange Heuristic (2-Assignment-Exchange)</p></a></li>
<li><a href='#match.bca'>
<p>Block Coordinate Ascent Method</p></a></li>
<li><a href='#match.bca.gen'>
<p>Block Coordinate Ascent Method for General (Balanced or Unbalanced) Data</p></a></li>
<li><a href='#match.gaussmix'><p>Gaussian Mixture Approach to One-To-One Feature Matching</p></a></li>
<li><a href='#match.kmeans'>
<p>K-Means Matching Algorithm</p></a></li>
<li><a href='#match.rec'>
<p>Recursive Initialization Method</p></a></li>
<li><a href='#match.template'><p>Template Matching</p></a></li>
<li><a href='#objective.fun'>
<p>Calculate Cost of Multidimensional Assignment</p></a></li>
<li><a href='#objective.gen.fun'>
<p>Objective Value in One-To-One Feature Matching with Balanced or Unbalanced Data</p></a></li>
<li><a href='#optdigits'>
<p>Handwritten Digits Data</p></a></li>
<li><a href='#predict.matchFeat'>
<p>Match New Feature Vectors To Existing Clusters</p></a></li>
<li><a href='#print.matchFeat'>
<p>Print a matchFeat Object</p></a></li>
<li><a href='#Rand.index'>
<p>Rand Index of Agreement Between Two Partitions</p></a></li>
<li><a href='#summary.matchFeat'><p>Summarize a matchFeat Object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>One-to-One Feature Matching</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-12-10</td>
</tr>
<tr>
<td>Author:</td>
<td>David Degras</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Degras &lt;david.degras@umb.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Statistical methods to match feature vectors between multiple datasets in a one-to-one fashion. Given a fixed number of classes/distributions, for each unit, exactly one vector of each class is observed without label. The goal is to label the feature vectors using each label exactly once so to produce the best match across datasets, e.g. by minimizing the variability within classes. Statistical solutions based on empirical loss functions and probabilistic modeling are provided. The 'Gurobi' software and its 'R' interface package are required for one of the package functions (match.2x()) and can be obtained at <a href="https://www.gurobi.com/">https://www.gurobi.com/</a> (free academic license). For more details, refer to Degras (2022) &lt;<a href="https://doi.org/10.1080%2F10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a>&gt; "Scalable feature matching for large data collections" and Bandelt, Maas, and Spieksma (2004) &lt;<a href="https://doi.org/10.1057%2Fpalgrave.jors.2601723">doi:10.1057/palgrave.jors.2601723</a>&gt; "Local search heuristics for multi-index assignment problems with decomposable costs".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>clue, foreach, methods, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gurobi</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-10 20:03:42 UTC; daviddegras</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-12-13 12:30:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='matchFeat-package'>
One-to-One Feature Matching
</h2><span id='topic+matchFeat-package'></span>

<h3>Description</h3>

<p>Statistical methods to match feature vectors between multiple datasets in a one-to-one fashion. Given a fixed number of classes/distributions, for each unit, exactly one vector of each class is observed without label. The goal is to label the feature vectors using each label exactly once so to produce the best match across datasets, e.g. by minimizing the variability within classes. Statistical solutions based on empirical loss functions and probabilistic modeling are provided. The 'Gurobi' software and its 'R' interface package are required for one of the package functions (match.2x()) and can be obtained at &lt;https://www.gurobi.com/&gt; (free academic license). For more details, refer to Degras (2022) &lt;doi:10.1080/10618600.2022.2074429&gt; &quot;Scalable feature matching for large data collections&quot; and Bandelt, Maas, and Spieksma (2004) &lt;doi:10.1057/palgrave.jors.2601723&gt; &quot;Local search heuristics for multi-index assignment problems with decomposable costs&quot;.
</p>


<h3>Details</h3>

<p>This package serves to match feature vectors across a collection of datasets 
in a one-to-one fashion. This task is formulated as a multidimensional assignment problem with decomposable costs (MDADC). 
We propose fast algorithms with time complexity roughly linear in the number <code class="reqn">n</code> of datasets and space complexity a small fraction of the data size. 
</p>

<ul>
<li><p> Initialization methods: <code><a href="#topic+match.rec">match.rec</a></code> (recursive) and <code><a href="#topic+match.template">match.template</a></code> (template-based). <br />
</p>
</li>
<li><p> Main matching algorithms: <code><a href="#topic+match.bca">match.bca</a></code>, <code><a href="#topic+match.bca.gen">match.bca.gen</a></code> (for unbalanced data), and <code><a href="#topic+match.kmeans">match.kmeans</a></code> (<code class="reqn">k</code>-means matching). <br />
</p>
</li>
<li><p> Refinement methods (post-processing): <code><a href="#topic+match.2x">match.2x</a></code> (pairwise interchange) and <code><a href="#topic+match.gaussmix">match.gaussmix</a></code> (Gaussian mixture model with permutation constraints).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Author: David Degras<br />
Maintainer: David Degras &lt;david.degras@umb.edu&gt;
</p>


<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a>
<br />
Wright (2015). Coordinate descent algorithms.
<a href="https://arxiv.org/abs/1502.04759">https://arxiv.org/abs/1502.04759</a> <br />
McLachlan and Krishnan (2008). <em>The EM Algorithm and Extensions</em>
</p>

<hr>
<h2 id='match.2x'>
Pairwise Interchange Heuristic (2-Assignment-Exchange)
</h2><span id='topic+match.2x'></span>

<h3>Description</h3>

<p>This function implements the Pairwise Interchange Heuristic for the multidimensional assignment problem with decomposable costs (MDADC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.2x(x, sigma = NULL, unit = NULL, w = NULL, control = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.2x_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="match.2x_+3A_sigma">sigma</code></td>
<td>

<p>permutations: matrix of dimensions <code class="reqn">(m,n)</code>
</p>
</td></tr>
<tr><td><code id="match.2x_+3A_unit">unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="match.2x_+3A_w">w</code></td>
<td>
<p>weights for loss function: single positive number, 
<code class="reqn">p</code>-vector of length, or <code class="reqn">(p,p)</code> positive definite matrix</p>
</td></tr>
<tr><td><code id="match.2x_+3A_control">control</code></td>
<td>
<p>tuning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use of this function requires to have the GUROBI software and its R interface package installed. Both can be downloaded from <a href="https://www.gurobi.com">https://www.gurobi.com</a> after obtaining a free academic license.  
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with components
</p>

<dl>
<dt><code>sigma</code></dt><dd><p>best assignment as set of permutations (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt><dd><p>best assignment as a cluster membership vector</p>
</dd>
<dt><code>objective</code></dt><dd><p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt><dd><p>mean vector for each class/label (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>covariance matrix for each class/label (<code class="reqn">(p,p,m)</code> array)</p>
</dd>
<dt><code>call</code></dt><dd><p>function call</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.bca">match.bca</a></code>,  <code><a href="#topic+match.bca.gen">match.bca.gen</a></code>,
<code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, <code><a href="#topic+match.kmeans">match.kmeans</a></code>, 
<code><a href="#topic+match.rec">match.rec</a></code>, <code><a href="#topic+match.template">match.template</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require(gurobi)) {
## Generate small example
  m &lt;- 3  # number of classes
  n &lt;- 10 # number of statistical units 
  p &lt;- 5  # number of variables
  mu &lt;- matrix(rnorm(p*m),p,m) # mean vectors
  sigma &lt;- 0.1
  x &lt;- array(as.vector(mu) + rnorm(p*m*n,sigma), c(p,m,n))

## Match all feature vectors
  result &lt;- match.2x(x)

## Display results 
  result$cost  # objective value = assignment cost
  result$sigma # solution permutations
  xmatched &lt;- array(dim=dim(x)) 
  
## Matched feature vectors
  for (i in 1:n)
	  xmatched[,,i] &lt;- x[,result$sigma[,i],i]
	
}
</code></pre>

<hr>
<h2 id='match.bca'>
Block Coordinate Ascent Method
</h2><span id='topic+match.bca'></span>

<h3>Description</h3>

<p>This function solves the multidimensional assignment problem with decomposable costs (MDADC) by block coordinate ascent. The dissimilarity function is the squared Euclidean distance. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.bca(x, unit = NULL, w = NULL, 
	method = c("cyclical", "random"), control = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.bca_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="match.bca_+3A_unit">unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="match.bca_+3A_w">w</code></td>
<td>
<p>weights for loss function: single positive number, 
<code class="reqn">p</code>-vector of length, or <code class="reqn">(p,p)</code> positive definite matrix</p>
</td></tr>
<tr><td><code id="match.bca_+3A_method">method</code></td>
<td>
<p>sweeping method for block coordinate ascent: <code>cyclical</code> or <code>random</code> (simple random sampling without replacement)</p>
</td></tr>
<tr><td><code id="match.bca_+3A_control">control</code></td>
<td>
<p>tuning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a set of <code class="reqn">n</code> statistical units, each having <code class="reqn">m</code> possibly mislabeled feature vectors, the one-to-one matching problem is to find a set of <code class="reqn">n</code> label permutations that produce the best match of feature vectors across units. The objective function to minimize is the sum of (weighted) squared Euclidean distances between all pairs of feature vectors having the same (new) label. This amounts to minimizing the sum of the within-label variances.  
The sample means and sample covariances of the matched feature vectors are calculated as a post-processing step.  
</p>
<p>The block-coordinate ascent (BCA) algorithm successively sweeps through the statistical units (=blocks), each time relabeling the <code class="reqn">m</code> feature vectors of a unit to best match those of the other <code class="reqn">n-1</code> units. 
</p>
<p>If <code>x</code> is a matrix, the rows should be sorted by increasing unit label and  <code>unit</code> should be a nondecreasing sequence of integers, for example <code class="reqn">(1,...,1,2,...,2,...,n,...,n)</code> with each integer <code class="reqn">1,...,n</code> replicated <code class="reqn">m</code> times. 
</p>
<p>The argument <code>w</code> can be specified as a vector of positive numbers (will be recycled to length <code class="reqn">p</code> if needed) or as a positive definite matrix of size <code class="reqn">(p,p)</code>.
</p>
<p>The optional argument <code>control</code> is a list with three fields: <code>sigma</code>, starting point for the optimization (<code class="reqn">(m,n)</code> matrix of permutations; <code>maxit</code>, maximum number of iterations; and <code>equal.variance</code>, logical value that specifies whether the returned sample covariance matrices <code>V</code> for matched features should be equal between labels/classes (TRUE) or label-specific (FALSE, default).  
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with components
</p>

<dl>
<dt><code>sigma</code></dt><dd><p>best set of permutations for feature vectors (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt><dd><p>associated clusters (=inverse permutations)</p>
</dd>
<dt><code>objective</code></dt><dd><p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt><dd><p>sample mean for each class/label (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>sample covariance for each class/label (<code class="reqn">(p,m)</code> matrix</p>
</dd>
<dt><code>call</code></dt><dd><p>function call</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br />
Wright (2015). Coordinate descent algorithms. <a href="https://arxiv.org/abs/1502.04759">https://arxiv.org/abs/1502.04759</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.2x">match.2x</a></code>,
<code><a href="#topic+match.bca.gen">match.bca.gen</a></code>, <code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, 
<code><a href="#topic+match.kmeans">match.kmeans</a></code>, <code><a href="#topic+match.rec">match.rec</a></code>, <code><a href="#topic+match.template">match.template</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
m &lt;- length(unique(optdigits$label)) # number of classes
n &lt;- nrow(optdigits$x) / m # number of units

## Use function with data in matrix form
fit1 &lt;- match.bca(optdigits$x, unit=n)

## Use function with data in array form
p &lt;- ncol(optdigits$x)
x &lt;- t(optdigits$x)
dim(x) &lt;- c(p,m,n)
fit2 &lt;- match.bca(x)

</code></pre>

<hr>
<h2 id='match.bca.gen'>
Block Coordinate Ascent Method for General (Balanced or Unbalanced) Data
</h2><span id='topic+match.bca.gen'></span>

<h3>Description</h3>

<p>Solve a feature matching problem by block coordinate ascent
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.bca.gen(x, unit = NULL, cluster = NULL, w = NULL, 
	method = c("cyclical", "random"), control = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.bca.gen_+3A_x">x</code></td>
<td>
<p>data matrix (rows=instances, columns=features)</p>
</td></tr>
<tr><td><code id="match.bca.gen_+3A_unit">unit</code></td>
<td>
<p>vector of unit labels (length = number of rows of <code>x</code>)</p>
</td></tr>
<tr><td><code id="match.bca.gen_+3A_cluster">cluster</code></td>
<td>
<p>integer specifying the number of classes/clusters to assign the feature vectors to OR integer vector specifiying the initial cluster assignment. </p>
</td></tr>
<tr><td><code id="match.bca.gen_+3A_w">w</code></td>
<td>
<p>feature weights in loss function. Can be specified as single positive number, vector, or positive definite matrix</p>
</td></tr>
<tr><td><code id="match.bca.gen_+3A_method">method</code></td>
<td>
<p>sweeping method for block coordinate ascent: <code>cyclical</code> or <code>random</code> (simple random sampling without replacement)</p>
</td></tr>
<tr><td><code id="match.bca.gen_+3A_control">control</code></td>
<td>
<p>optional list of tuning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>cluster</code> is an integer vector, it must have the same length as <code>unit</code> 
and its values must range between 1 and the number of clusters. 
</p>
<p>The list <code>control</code> can contain a field <code>maxit</code>, 
an integer that fixes the maximum number of algorithm iterations.
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with components
</p>

<dl>
<dt><code>cluster</code></dt><dd><p>integer vector of cluster assignments (length = <code>now(x)</code>)</p>
</dd>
<dt><code>objective</code></dt><dd><p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt><dd><p>sample mean for each cluster/class (feature-by-cluster matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>sample covariance for each cluster/class (feature-by-feature-by-cluster 3D array)</p>
</dd>
<dt><code>size</code></dt><dd><p>integer vector of cluster sizes</p>
</dd>	
<dt><code>call</code></dt><dd><p>function call</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br />
Wright (2015). Coordinate descent algorithms. 
<a href="https://arxiv.org/abs/1502.04759">https://arxiv.org/abs/1502.04759</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.2x">match.2x</a></code>, <code><a href="#topic+match.bca">match.bca</a></code>, 
<code><a href="#topic+match.bca.gen">match.bca.gen</a></code>, <code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, 
<code><a href="#topic+match.kmeans">match.kmeans</a></code>, <code><a href="#topic+match.rec">match.rec</a></code>, <code><a href="#topic+match.template">match.template</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
nobs &lt;- nrow(optdigits$x) # total number of observations
n &lt;- length(unique(optdigits$unit)) # number of statistical units
rmv &lt;- sample.int(nobs, n-1) # remove (n-1) observations to make data unbalanced
min.m &lt;- max(table(optdigits$unit[-rmv])) # smallest possible number of clusters
# lower values will result in an error message 
m &lt;- min.m
result &lt;- match.bca.gen(optdigits$x[-rmv,], optdigits$unit[-rmv], m)



</code></pre>

<hr>
<h2 id='match.gaussmix'>Gaussian Mixture Approach to One-To-One Feature Matching</h2><span id='topic+match.gaussmix'></span>

<h3>Description</h3>

<p>This function performs maximum likelihood estimation (MLE) for the one-to-one feature matching problem represented as a multivariate Gaussian mixture model. MLE is carried out via the EM algorithm. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.gaussmix(x, unit = NULL, mu = NULL, V = NULL, equal.variance = FALSE, 
	method = c("exact", "approx"), fixed = FALSE, control = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.gaussmix_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_unit">unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_mu">mu</code></td>
<td>
<p>matrix of initial estimates of mean vectors (dimension <code class="reqn">(p,m)</code>)</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_v">V</code></td>
<td>
<p>array of initial estimates of covariance matrices (dimension <code class="reqn">(p,p,m)</code>)</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_equal.variance">equal.variance</code></td>
<td>
<p>logical: if <code>TRUE</code>, all covariance matrices are assumed to be equal</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_method">method</code></td>
<td>
<p>method for calculating class probabilities of feature vectors</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_fixed">fixed</code></td>
<td>
<p>logical; if <code>TRUE</code>, the model parameters <code>mu</code> and <code>V</code> are fixed to their initial values</p>
</td></tr>
<tr><td><code id="match.gaussmix_+3A_control">control</code></td>
<td>
<p>list of tuning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a sample of <code class="reqn">n</code> statistical units, each having <code class="reqn">m</code> possibly mislabeled feature vectors, the one-to-one matching problem is to find a set of <code class="reqn">n</code> label permutations that produce the best match of feature vectors across units. This problem is sometimes referred to as &quot;data association ambiguity&quot;. 
</p>
<p>The feature vectors of all units are represented as independent realizations of <code class="reqn">m</code> multivariate normal distributions with unknown parameters. For each sample unit, exactly one vector from each distribution is observed and the <code class="reqn">m</code> corresponding labels are randomly permuted. The goal is to estimate the true class of each feature vector, as well as the mean vector and covariance matrix of each distribution. These quantities are evaluated by ML estimation via the Expectation-Maximization (EM) algorithm. 
</p>
<p>If <code>x</code> is a matrix, the rows should be sorted by increasing unit label and  <code>unit</code> should be a nondecreasing sequence of integers, for example <code class="reqn">(1,...,1,2,...,2,...,n,...,n)</code> with each integer <code class="reqn">1,...,n</code> replicated <code class="reqn">m</code> times. 
</p>
<p>The arguments <code>mu</code> and <code>V</code> should be specified only if a good guess is available for these parameters. Otherwise bad starting values may cause the EM algorithm to converge to a local maximum of the likelihood function quite far from the global maximum. 
</p>
<p>If <code>method</code> is set to <code>exact</code> (default), the class probabilities of the feature vectors (given the data) are calculated exactly at each iteration of the EM algorithm. This operation can be slow as it involves calculating the permanent of matrices. The argument <code>method</code> can be set to <code>approximate</code> to speed up calculations, but this option is not recommended in general as the approximations used are very crude and may produce &quot;bad&quot; EM solutions. 
</p>
<p>The optional argument <code>control</code> can be specified with these fields: 
<code>maxit</code>, maximum number of EM iterations (default=1e4); 
<code>eps</code>, relative tolerance for EM convergence (default=1e-8), 
the EM algorithm stops if the relative increase in log-likelihood between two iterations is less than this tolerance; <code>verbose</code>, set to TRUE to display
algorithm progress (default=FALSE). 
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with fields
</p>

<dl>
<dt><code>sigma</code></dt><dd><p>permutations that best match feature vectors across units (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt><dd><p>associated clusters (=inverse permutations)</p>
</dd>
<dt><code>P</code></dt><dd><p>conditional probability that a feature vector is assigned to its 'true' label
(<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>mu</code></dt><dd><p>MLE of true mean vectors (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>MLE of true covariance matrices (<code class="reqn">(p,p,m)</code> array or <code class="reqn">(p,p)</code>matrix if <code>equal.variance=TRUE</code>)</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Maximum value of log-likelihood</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br />
'McLachlan and Krishnan (2008). The EM Algorithm and Extensions.'
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.2x">match.2x</a></code>,
<code><a href="#topic+match.bca">match.bca</a></code>, 
<code><a href="#topic+match.bca.gen">match.bca.gen</a></code>,  
<code><a href="#topic+match.kmeans">match.kmeans</a></code>, 
<code><a href="#topic+match.rec">match.rec</a></code>, 
<code><a href="#topic+match.template">match.template</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(optdigits)
x &lt;- optdigits$x
label &lt;- optdigits$label
m &lt;- length(unique(label))
n &lt;- length(unique(optdigits$unit))

## Randomly permute labels to make problem harder
for (i in 1:n)
{
	idx &lt;- seq.int((i-1) * m + 1, i * m)
	sigma &lt;- sample.int(m)
	x[idx,] &lt;- x[idx[sigma],]
	label[idx] &lt;- label[idx[sigma]]
}

## Fit Gaussian mixture model
fit &lt;- match.gaussmix(x, unit = n)

## Calculate Rand index
Rand.index(fit$cluster,label)
	
</code></pre>

<hr>
<h2 id='match.kmeans'>
K-Means Matching Algorithm
</h2><span id='topic+match.kmeans'></span>

<h3>Description</h3>

<p>This function matches collections of feature vectors in a one-to-one fashion using a <code class="reqn">k</code>-means-like method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.kmeans(x, unit = NULL, w = NULL, method = c("hungarian", "bruteforce"), 
	control = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.kmeans_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="match.kmeans_+3A_unit">unit</code></td>
<td>
<p>integer (= number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="match.kmeans_+3A_w">w</code></td>
<td>
<p>weights for the (squared Euclidean) loss function. Can be specified as single positive number, <code class="reqn">p</code>-vector, or <code class="reqn">p \times p</code> positive definite matrix</p>
</td></tr>
<tr><td><code id="match.kmeans_+3A_method">method</code></td>
<td>
<p>method for linear assignment problem: <code>hungarian</code> algorithm or <code>bruteforce</code></p>
</td></tr>
<tr><td><code id="match.kmeans_+3A_control">control</code></td>
<td>
<p>optional list of tuning parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a set of <code class="reqn">n</code> units or datasets, each having <code class="reqn">m</code> unlabeled feature vectors, the one-to-one matching problem is to find a set of <code class="reqn">n</code> labels that produce the best match of feature vectors across units. The objective function to minimize is the sum of (weighted) squared Euclidean distances between all pairs of feature vectors having the same label. This amounts to minimizing the sum of the within-label variances.  
The sample means and sample covariances of the matched feature vectors are calculated as a post-processing step.  
</p>
<p>If <code>x</code> is a matrix, the rows should be sorted by increasing unit label and  <code>unit</code> should be a nondecreasing sequence of integers, for example <code class="reqn">(1,...,1,2,...,2,...,n,...,n)</code> with each integer <code class="reqn">1,...,n</code> replicated <code class="reqn">m</code> times. 
</p>
<p>The argument <code>w</code> can be specified as a vector of positive numbers (will be recycled to length <code class="reqn">p</code> if needed) or as a positive definite matrix of size <code class="reqn">(p,p)</code>.
</p>
<p>The optional argument <code>control</code> is a list with three fields: <code>sigma</code>, starting point for the optimization (<code class="reqn">(m,n)</code> matrix of permutations; <code>maxit</code>, maximum number of iterations; and <code>equal.variance</code>, logical value that specifies whether the returned sample covariance matrices <code>V</code> for matched features should be equal between labels/classes (TRUE) or label-specific (FALSE, default). 
</p>


<h3>Value</h3>

<p>A  list of class <code>matchFeat</code> with components
</p>

<dl>
<dt>sigma</dt><dd><p>best set of permutations for feature vectors (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt>cluster</dt><dd><p>associated clusters (= inverse permutations)</p>
</dd>
<dt>cost</dt><dd><p>minimum objective value</p>
</dd>
<dt>mu</dt><dd><p>sample mean for each class/label (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt>V</dt><dd><p>sample covariance for each class/label (<code class="reqn">(p,m)</code> matrix</p>
</dd>
<dt>call</dt><dd><p>function call</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a><br />
<a href="https://en.wikipedia.org/wiki/Assignment_problem">https://en.wikipedia.org/wiki/Assignment_problem</a><br />
<a href="https://en.wikipedia.org/wiki/Hungarian_algorithm">https://en.wikipedia.org/wiki/Hungarian_algorithm</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.2x">match.2x</a></code>, <code><a href="#topic+match.bca">match.bca</a></code>,
<code><a href="#topic+match.bca.gen">match.bca.gen</a></code>, <code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, 
<code><a href="#topic+match.rec">match.rec</a></code>, <code><a href="#topic+match.template">match.template</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
  m &lt;- 3
  n &lt;- 10
  p &lt;- 5
  mu &lt;- matrix(rnorm(p*m),p,m)
  sigma &lt;- 0.1
  x &lt;- array(as.vector(mu) + rnorm(p*m*n,sigma), c(p,m,n))

## Match all feature vectors
  result &lt;- match.kmeans(x)

## Display results 
  result$objective # cost function
  xmatched &lt;- array(dim=dim(x)) 
  
## re-arranged (matched) feature vectors
  for (i in 1:n){
	  xmatched[,,i] &lt;- x[,result$sigma[,i],i]}
</code></pre>

<hr>
<h2 id='match.rec'>
Recursive Initialization Method
</h2><span id='topic+match.rec'></span>

<h3>Description</h3>

<p>RECUR1 algorithm of Bandelt et al (2004) to find starting point in the multidimensional assignment problem with decomposable costs (MDADC)  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.rec(x, unit = NULL, w = NULL, control = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.rec_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="match.rec_+3A_unit">unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="match.rec_+3A_w">w</code></td>
<td>
<p>weights for loss function: single positive number, 
<code class="reqn">p</code>-vector of length, or <code class="reqn">(p,p)</code> positive definite matrix</p>
</td></tr>
<tr><td><code id="match.rec_+3A_control">control</code></td>
<td>
<p>tuning parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with components
</p>

<dl>
<dt><code>sigma</code></dt><dd><p>best set of permutations for feature vectors (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt><dd><p>associated clusters (= inverse permutations)</p>
</dd>
<dt><code>cost</code></dt><dd><p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt><dd><p>sample mean for each class/label (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>sample covariance for each class/label (<code class="reqn">(p,m)</code> matrix</p>
</dd>
<dt><code>call</code></dt><dd><p>function call</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a> <br />
Bandelt, Maas, and Spieksma (2004), &quot;Local search heuristics for multi-index assignment problems with decomposable costs.&quot; <a href="https://doi.org/10.1057/palgrave.jors.2601723">doi:10.1057/palgrave.jors.2601723</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.2x">match.2x</a></code>, <code><a href="#topic+match.bca">match.bca</a></code>,
<code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, <code><a href="#topic+match.template">match.template</a></code>, 
<code><a href="#topic+match.kmeans">match.kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
m &lt;- length(unique(optdigits$label)) # number of classes
n &lt;- nrow(optdigits$x) / m # number of units

## Use function with data in matrix form
fit1 &lt;- match.rec(optdigits$x, unit=n)

## Use function with data in array form
p &lt;- ncol(optdigits$x)
x &lt;- t(optdigits$x)
dim(x) &lt;- c(p,m,n)
fit2 &lt;- match.rec(x)
</code></pre>

<hr>
<h2 id='match.template'>Template Matching</h2><span id='topic+match.template'></span>

<h3>Description</h3>

<p>This function solves the multidimensional assignment problem with decomposable costs (MDADC) by matching the data to a pre-specified set of vectors (the template). The dissimilarity function is the squared Euclidean distance. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.template(x, template = 1L, unit = NULL, w = NULL, 
	method = c("hungarian","bruteforce"), equal.variance = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="match.template_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">mn \times p</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="match.template_+3A_template">template</code></td>
<td>
<p>integer (= which sample unit to take as template) or <code class="reqn">(p,m)</code> matrix</p>
</td></tr>
<tr><td><code id="match.template_+3A_unit">unit</code></td>
<td>
<p>integer (=number of units/datasets) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="match.template_+3A_w">w</code></td>
<td>
<p>weights for the loss function. Can be specified as a <code class="reqn">p</code>-vector of diagonal weights or as a full <code class="reqn">p \times p</code> (positive definite) matrix</p>
</td></tr>
<tr><td><code id="match.template_+3A_method">method</code></td>
<td>
<p>method for the linear assignment problem: <code>hungarian</code> algorithm or <code>bruteforce</code></p>
</td></tr>
<tr><td><code id="match.template_+3A_equal.variance">equal.variance</code></td>
<td>
<p>logical; if TRUE, resp. FALSE, return common, resp. label-specific, covariance of matched features</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given <code class="reqn">n</code> datasets or statistical units, each containing <code class="reqn">m</code> feature vectors, the one-to-one matching problem is to find a set of <code class="reqn">n</code> label permutations that produce the best match of feature vectors across units. The objective function to minimize is the sum of squared (Euclidean) distances between all feature vectors having the same (new) label. This amounts to minimizing the sum of the within-label variances.  
</p>
<p>The template-based method consists in relabeling successively each sample unit to best match a template matrix of feature vectors. This method is very fast but its optimization performance is only as good as the template. For best results, the template should be representative of the collected data. 
</p>
<p>If <code>x</code> is a matrix, the rows should be sorted by increasing unit label and  <code>unit</code> should be a nondecreasing sequence of integers, for example <code class="reqn">(1,...,1,2,...,2,...,n,...,n)</code> with each integer <code class="reqn">1,...,n</code> replicated <code class="reqn">m</code> times. 
</p>
<p>The argument <code>w</code> can be specified as a vector of positive numbers (will be recycled to length <code class="reqn">p</code> if needed) or as a positive definite matrix of size <code class="reqn">(p,p)</code>.
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with fields 
</p>

<dl>
<dt><code>sigma</code></dt><dd><p>best assignement as set of permutations (<code class="reqn">m\times n</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt><dd><p>best assignement as cluster indicators (<code class="reqn">m \times n</code> matrix)</p>
</dd>
<dt><code>objective</code></dt><dd><p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt><dd><p>mean vector for each class/label (<code class="reqn">p \times m</code> matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>covariance matrix for each class/label (<code class="reqn">p \times p \times m</code> array if <code>equal.variance</code> is FALSE, <code class="reqn">p \times p </code> matrix otherwise</p>
</dd>
<dt><code>call</code></dt><dd><p>function call</p>
</dd>
</dl>



<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a><br />
<a href="https://en.wikipedia.org/wiki/Assignment_problem">https://en.wikipedia.org/wiki/Assignment_problem</a><br />
<a href="https://en.wikipedia.org/wiki/Hungarian_algorithm">https://en.wikipedia.org/wiki/Hungarian_algorithm</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+match.2x">match.2x</a></code>, <code><a href="#topic+match.bca">match.bca</a></code>, 
<code><a href="#topic+match.bca.gen">match.bca.gen</a></code>, <code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, <code><a href="#topic+match.kmeans">match.kmeans</a></code>, <code><a href="#topic+match.rec">match.rec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
n &lt;- 10
k &lt;- 3
d &lt;- 5
mu &lt;- matrix(1:k, nrow=d, ncol=k, byrow=TRUE)
sigma &lt;- 0.3
x &lt;- array(mu, c(d,k,n)) + rnorm(d*k*n,sigma)
## Match all feature vectors with first case as template
result &lt;- match.template(x,1)
## Display results 
result$cost # cost function
xmatched &lt;- array(dim=dim(x)) 
# re-arranged (matched) feature vectors
for (i in 1:n)
	xmatched[,,i] &lt;- x[,result$sigma[,i],i]
</code></pre>

<hr>
<h2 id='objective.fun'>
Calculate Cost of Multidimensional Assignment
</h2><span id='topic+objective.fun'></span>

<h3>Description</h3>

<p>Calculates the objective value in the multidimensional assignment problem with decomposable costs (MDADC). The dissimilarity function used in this problem is the squared Euclidean distance.</p>


<h3>Usage</h3>

<pre><code class='language-R'>objective.fun(x, sigma = NULL, unit = NULL, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="objective.fun_+3A_x">x</code></td>
<td>
<p>data: matrix of dimensions <code class="reqn">(mn,p)</code> or 3D array of dimensions <code class="reqn">(p,m,n)</code> with <code class="reqn">m</code> = number of labels/classes, <code class="reqn">n</code> = number of sample units, and <code class="reqn">p</code> = number of variables)</p>
</td></tr>
<tr><td><code id="objective.fun_+3A_sigma">sigma</code></td>
<td>

<p>permutations: matrix of dimensions <code class="reqn">(m,n)</code>
</p>
</td></tr>
<tr><td><code id="objective.fun_+3A_unit">unit</code></td>
<td>
<p>integer (=number of units) or vector mapping rows of <code>x</code> to sample units (length <code class="reqn">mn</code>). Must be specified only if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="objective.fun_+3A_w">w</code></td>
<td>
<p>weights for loss function: single positive number, 
<code class="reqn">p</code>-vector of length, or <code class="reqn">(p,p)</code> positive definite matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given <code class="reqn">n</code> datasets having each <code class="reqn">m</code> vectors of same size, 
say <code class="reqn">{x_{11},...,x_{1m}},...,x_{n1},...,x_{nm}</code>, and permutations 
<code class="reqn">\sigma_1,...,\sigma_n</code> of <code class="reqn">{1,...,m}</code>, the function calculates 
<code class="reqn">1/(n(n-1)) sum_{i,j} sum_{k} || x_{i,sigma_i(k)- x_{j,\sigma_j(k) \|^2}}</code> where <code class="reqn">i</code> and <code class="reqn">n</code> run from 1 to <code class="reqn">n</code> and <code class="reqn">k</code> runs from 1 to <code class="reqn">m</code>. This is the objective value (1) of Degras (2021), up to the factor <code class="reqn">1/(n(n-1))</code>.
</p>


<h3>Value</h3>

<p>Objective value</p>


<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+objective.gen.fun">objective.gen.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
m &lt;- 10
n &lt;- 100
sigma &lt;- matrix(1:m,m,n) # identity permutations
objective.fun(optdigits$x, sigma, optdigits$unit)
</code></pre>

<hr>
<h2 id='objective.gen.fun'>
Objective Value in One-To-One Feature Matching with Balanced or Unbalanced Data
</h2><span id='topic+objective.gen.fun'></span>

<h3>Description</h3>

<p>Calculates the objective value in the multidimensional assignment problem with decomposable costs (MDADC). The dissimilarity function used in this problem is the squared Euclidean distance. The data can be balanced OR unbalanced.</p>


<h3>Usage</h3>

<pre><code class='language-R'>objective.gen.fun(x, unit, cluster)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="objective.gen.fun_+3A_x">x</code></td>
<td>

<p>data matrix with feature vectors in rows
</p>
</td></tr>
<tr><td><code id="objective.gen.fun_+3A_unit">unit</code></td>
<td>

<p>vector of unit labels (length should equal number of rows in <code>x</code>)
</p>
</td></tr>
<tr><td><code id="objective.gen.fun_+3A_cluster">cluster</code></td>
<td>

<p>vector of cluster labels (length should equal number of rows in <code>x</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See equation (2) in Degras (2022). This function gives the same value as <code><a href="#topic+objective.fun">objective.fun</a></code> when the data are balanced.   
</p>


<h3>Value</h3>

<p>Objective value</p>


<h3>References</h3>

<p>Degras (2022) &quot;Scalable feature matching across large data collections.&quot;  
<a href="https://doi.org/10.1080/10618600.2022.2074429">doi:10.1080/10618600.2022.2074429</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+objective.fun">objective.fun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
m &lt;- 10
n &lt;- 100

## Balanced example: both 'objective.fun' and 'objective.gen.fun' work
sigma &lt;- matrix(1:m,m,n)
cluster &lt;- rep(1:m,n)
objective.fun(optdigits$x, sigma, optdigits$unit)
objective.gen.fun(optdigits$x, optdigits$unit, cluster)

## Unbalanced example
idx &lt;- 1:999
objective.gen.fun(optdigits$x[idx,], optdigits$unit[idx], cluster[idx])


</code></pre>

<hr>
<h2 id='optdigits'>
Handwritten Digits Data
</h2><span id='topic+optdigits'></span>

<h3>Description</h3>

<p>Digitized images of handwritten digits used in optical recognition tasks</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("optdigits")</code></pre>


<h3>Format</h3>

<p>The format is:<br />
List of 2<br />
$ x    : int [1:1000, 1:64] 0 0 0 0 0 0 0 0 0 0 ...<br />
$ label: int [1:1000] 0 1 2 3 4 5 6 7 8 9 ...
</p>


<h3>Details</h3>

<p>This is a subset of a larger dataset containing handwritten digits contributed by 30 people  on a preprinted form. The forms were converted to normalized bitmaps of size 32x32 which were divided into nonoverlapping blocks of size 4x4. The number of pixels was counted in each block, producing a matrix of size 8x8 with integer coefficients ranging in 0..16.  
These matrix are vectorized in the rows of <code>optdigits$x</code>. The corresponding digits are in <code>optdigits$label</code>. 100 examples are available for each digit 0..9.   
</p>


<h3>Source</h3>

<p>UCI Machine Learning Repository. 
<a href="https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits">https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits</a></p>


<h3>References</h3>

<p>Alpaydin and Kaynak (1998). Cascading Classifiers. 
<a href="ftp://ftp.icsi.berkeley.edu/pub/ai/ethem/kyb.ps.Z">ftp://ftp.icsi.berkeley.edu/pub/ai/ethem/kyb.ps.Z</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
## Quick visualization
oldpar &lt;- par(no.readonly = TRUE)
par(mfrow=c(2,5))
for (i in 1:10) {
	mat &lt;- matrix(optdigits$x[i,],8,8)
	image(mat[,8:1], xaxt="n", yaxt="n")
	title(optdigits$label[i])
}
par(oldpar)
</code></pre>

<hr>
<h2 id='predict.matchFeat'>
Match New Feature Vectors To Existing Clusters</h2><span id='topic+predict.matchFeat'></span>

<h3>Description</h3>

<p><code>predict</code> method for class <code>"matchFeat"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matchFeat'
predict(object, newdata, unit = NULL, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.matchFeat_+3A_object">object</code></td>
<td>
<p>an object of class <code>"matchFeat"</code>.</p>
</td></tr>
<tr><td><code id="predict.matchFeat_+3A_newdata">newdata</code></td>
<td>
<p>new dataset of feature vectors</p>
</td></tr>
<tr><td><code id="predict.matchFeat_+3A_unit">unit</code></td>
<td>
<p>unit labels for new data. Only necessary if <code>newdata</code> is a matrix</p>
</td></tr>
<tr><td><code id="predict.matchFeat_+3A_...">...</code></td>
<td>
<p>for compatibility with the generic <code>predict</code> method; argument not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>predict.matchFeat</code> finds the best matching for new feature vectors relative to an existing set of cluster/class centers. If codeobject results from a call to <code><a href="#topic+match.gaussmix">match.gaussmix</a></code>, the same function is used for prediction (with fixed mean vectors and covariance matrices). In other cases, the function <code><a href="#topic+match.template">match.template</a></code> is used for prediction. 
</p>


<h3>Value</h3>

<p>A list of class <code>matchFeat</code> with fields
</p>

<dl>
<dt><code>sigma</code></dt><dd><p>best matching as set of permutations (<code class="reqn">(m,n)</code> matrix)</p>
</dd>
<dt><code>cluster</code></dt><dd><p>best matching as cluster indicators (<code class="reqn">(m,n)</code>-matrix)</p>
</dd>
<dt><code>objective</code></dt><dd><p>minimum objective value</p>
</dd>
<dt><code>mu</code></dt><dd><p>mean vector for each class/label (<code class="reqn">(p,m)</code> matrix)</p>
</dd>
<dt><code>V</code></dt><dd><p>covariance matrix for each class/label (<code class="reqn">(p,p,m)</code> array if <code>equal.variance</code> is FALSE, <code class="reqn">(p,p)</code> matrix otherwise</p>
</dd>
<dt><code>call</code></dt><dd><p>function call</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+print.matchFeat">print.matchFeat</a></code>, <code><a href="#topic+summary.matchFeat">summary.matchFeat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
train.result &lt;- match.bca(optdigits$x[1:900,], optdigits$unit[1:900])  
test.result &lt;- predict(train.result, optdigits$x[901:1000,], optdigits$unit[901:1000])
test.result
</code></pre>

<hr>
<h2 id='print.matchFeat'>
Print a matchFeat Object</h2><span id='topic+print.matchFeat'></span>

<h3>Description</h3>

<p><code>print</code> method for class <code>"matchFeat"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matchFeat'
print(x,...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.matchFeat_+3A_x">x</code></td>
<td>
<p>an object of class <code>"matchFeat"</code>.</p>
</td></tr>
<tr><td><code id="print.matchFeat_+3A_...">...</code></td>
<td>
<p>for compatibility with the generic <code>print</code> method; argument not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>print.matchFeat</code> concisely displays the information of an object of class <code>"matchFeat"</code>. More precisely it shows the  
data range, bandwidth used in local polynomial estimation, and key information on SCB and statistical tests. 
</p>


<h3>Value</h3>

<p>No return value, called for side effects</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.matchFeat">predict.matchFeat</a></code>, <code><a href="#topic+summary.matchFeat">summary.matchFeat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
result &lt;- match.bca(optdigits$x, optdigits$unit)
print(result)
</code></pre>

<hr>
<h2 id='Rand.index'>
Rand Index of Agreement Between Two Partitions</h2><span id='topic+Rand.index'></span>

<h3>Description</h3>

<p>Calculates the Rand Index between two partitions of a set</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rand.index(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Rand.index_+3A_x">x</code></td>
<td>

<p>first partition vector</p>
</td></tr>
<tr><td><code id="Rand.index_+3A_y">y</code></td>
<td>

<p>second partition vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two vectors <code>x</code> and <code>y</code> must have equal length. Given a set <code class="reqn">S</code> and two partitions <code class="reqn">X</code> and <code class="reqn">Y</code> of <code class="reqn">S</code>, the Rand index is the proportion of pairs of elements in <code class="reqn">S</code> (out of all pairs) that are either concordant in both <code class="reqn">X</code> and <code class="reqn">Y</code> (i.e., they belong to the same member of <code class="reqn">X</code> and to the same member of <code class="reqn">Y</code>) or discordant (i.e., not concordant) in both <code class="reqn">X</code> and Y.  
</p>


<h3>Value</h3>

<p>The Rand index (not adjusted for chance)</p>


<h3>References</h3>

<p>W. M. Rand (1971). &quot;Objective criteria for the evaluation of clustering methods&quot;<br />
<a href="https://en.wikipedia.org/wiki/Rand_index">https://en.wikipedia.org/wiki/Rand_index</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1
x &lt;- sample.int(3, 20, replace = TRUE)
y &lt;- sample.int(3, 20, replace = TRUE)
table(x,y)
Rand.index(x,y)

## Example 2
data(optdigits)
label &lt;- optdigits$label 
m &lt;- length(unique(label)) # 10 
n &lt;- length(unique(optdigits$unit)) # 100
dim(label) &lt;- c(m,n)
p &lt;- ncol(optdigits$x) # 64
x &lt;- array(t(optdigits$x),c(p,m,n))
## Permute data and labels to make problem harder
for (i in 1:n) {
	sigma &lt;- sample.int(m)
	x[,,i] &lt;- x[,sigma,i]
	label[,i] &lt;- label[sigma,i]
}
## Compare Rand indices of matching methods
Rand.index(match.bca(x)$cluster, label)
Rand.index(match.rec(x)$cluster, label)
Rand.index(match.template(x)$cluster, label)
Rand.index(match.kmeans(x)$cluster, label)


</code></pre>

<hr>
<h2 id='summary.matchFeat'>Summarize a matchFeat Object</h2><span id='topic+summary.matchFeat'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"matchFeat"</code> </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matchFeat'
summary(object, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.matchFeat_+3A_object">object</code></td>
<td>
<p>an object of class <code>"matchFeat"</code></p>
</td></tr>
<tr><td><code id="summary.matchFeat_+3A_...">...</code></td>
<td>
<p>additional arguments; not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>summary.matchFeat</code> displays all fields of a <code>matchFeat</code> object at the exception of <code>x</code>, <code>y</code>, <code>par</code>, <code>nonpar</code>, <code>normscb</code>, and <code>bootscb</code> which are potentially big. It provides information on the function call, data, local polynomial fit, SCB, and statistical tests.
</p>


<h3>Value</h3>

<p>No return value, called for side effects</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.matchFeat">predict.matchFeat</a></code>,
<code><a href="#topic+print.matchFeat">print.matchFeat</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(optdigits)
result &lt;- match.bca(optdigits$x, optdigits$unit)
summary(result)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
