<!DOCTYPE html><html lang="en"><head><title>Help for package RobustCalibration</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RobustCalibration}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RobustCalibration-package'>
<p>Robust Calibration of Imperfect Mathematical Models</p></a></li>
<li><a href='#Accept_proposal'>
<p>Determine whether we accept the proposed poserior sample at one step of MCMC.</p></a></li>
<li><a href='#Chol_Eigen'>
<p>Cholesky decomposition of a symmetric matrix.</p></a></li>
<li><a href='#Get_inv_all'>
<p>Produce the inversion of the covariances of the model discrepancy and the measurement bias.</p></a></li>
<li><a href='#Get_R_new'>
<p>Cholesky decomposition of the correlation matrix in GaSP.</p></a></li>
<li><a href='#Get_R_z_new'>
<p>Cholesky decomposition of the covariance matrix in S-GaSP.</p></a></li>
<li><a href='#Log_marginal_post'>
<p>Natural Logorithm of the posterior.</p></a></li>
<li><a href='#Log_marginal_post_delta'>
<p>Natural Logorithm of the posterior of the discrepancy in model calibration with multiple sources with measurement bias.</p></a></li>
<li><a href='#Log_marginal_post_no_discrepancy'>
<p>Natural Logorithm of the posterior with no discrepancy function.</p></a></li>
<li><a href='#mathematical_model_eval'>
<p>Evaluation of the mathmatical model at given observed inputs and calibration parameters.</p></a></li>
<li><a href='#Mogihammer'>
<p>A geophysical model for the ground deformation in Kilauea.</p></a></li>
<li><a href='#post_sample'>
<p>Posterior sampling.</p></a></li>
<li><a href='#post_sample_MS'>
<p>Posterior sampling.</p></a></li>
<li><a href='#post_sample_no_discrepancy'>
<p>Posterior sampling for the model with no discrepancy function.</p></a></li>
<li><a href='#post_sample_with_discrepancy'>
<p>Posterior sampling for the model with a discrepancy function</p></a></li>
<li><a href='#predict'>
<p>Prediction for the robust calibration model</p></a></li>
<li><a href='#predict_MS'>
<p>Prediction for the robust calibration model for multiple sources</p></a></li>
<li><a href='#predict_separable_2dim'>
<p>Fast prediction when the test points lie on a 2D lattice.</p></a></li>
<li><a href='#predict_separable_2dim_MS'>
<p>Fast prediction when the test points lie on a 2D lattice for multiple sources of observations.</p></a></li>
<li><a href='#predictobj.rcalibration_MS-class'><p>Predictive results for the Robust Calibration class</p></a></li>
<li><a href='#predictobj.rcalibration-class'><p>Predictive results for the Robust Calibration class</p></a></li>
<li><a href='#rcalibration'><p> Setting up the robust Calibration model</p></a></li>
<li><a href='#rcalibration_MS'><p> Setting up the robust Calibration model for multiple sources data</p></a></li>
<li><a href='#rcalibration_MS-class'><p> Robust Calibration for multiple sources class</p></a></li>
<li><a href='#rcalibration-class'><p> Robust Calibration class</p></a></li>
<li><a href='#Sample_delta'>
<p>Sample the model discrepancy.</p></a></li>
<li><a href='#Sample_sigma_2_theta_m'>
<p>Sample the variance and mean parameters.</p></a></li>
<li><a href='#Sample_sigma_2_theta_m_no_discrepancy'>
<p>Sample the variance and mean parameters with no discrepancy function.</p></a></li>
<li><a href='#separable_kernel'><p>Product correlation matrix with the product form</p></a></li>
<li><a href='#show'>
<p>Show an Robust Calibration object.</p></a></li>
<li><a href='#Update_R_inv_y'>
<p>Update the inverse of covariance multiplied by the outputs in the S-GaSP model.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Calibration of Imperfect Mathematical Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-29</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;</td>
</tr>
<tr>
<td>Author:</td>
<td>Mengyang Gu [aut, cre]</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements full Bayesian analysis for calibrating mathematical models with new   methodology for modeling the discrepancy function. It allows for emulation, calibration and prediction using complex mathematical model outputs and experimental data. See the reference: Mengyang Gu and Long Wang, 2018, Journal of Uncertainty Quantification; Mengyang Gu, Fangzheng Xie and Long Wang, 2022, Journal of Uncertainty Quantification; Mengyang Gu, Kyle Anderson and Erika McPhillips, 2023, Technometrics. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.3), RobustGaSP (&ge; 0.6.4), nloptr (&ge; 1.0.4)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-30 06:42:08 UTC; mengyanggu</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-30 07:10:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='RobustCalibration-package'>
Robust Calibration of Imperfect Mathematical Models
</h2><span id='topic+RobustCalibration-package'></span><span id='topic+RobustCalibration'></span>

<h3>Description</h3>

<p>Implements full Bayesian analysis for calibrating mathematical models with new   methodology for modeling the discrepancy function. It allows for emulation, calibration and prediction using complex mathematical model outputs and experimental data. See the reference: Mengyang Gu and Long Wang, 2018, Journal of Uncertainty Quantification; Mengyang Gu, Fangzheng Xie and Long Wang, 2022, Journal of Uncertainty Quantification; Mengyang Gu, Kyle Anderson and Erika McPhillips, 2023, Technometrics. 
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> RobustCalibration</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Robust Calibration of Imperfect Mathematical Models</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.5.5</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-05-29</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person(given="Mengyang",family="Gu",role=c("aut","cre"),email="mengyang@pstat.ucsb.edu"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Mengyang Gu [aut, cre]</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Implements full Bayesian analysis for calibrating mathematical models with new   methodology for modeling the discrepancy function. It allows for emulation, calibration and prediction using complex mathematical model outputs and experimental data. See the reference: Mengyang Gu and Long Wang, 2018, Journal of Uncertainty Quantification; Mengyang Gu, Fangzheng Xie and Long Wang, 2022, Journal of Uncertainty Quantification; Mengyang Gu, Kyle Anderson and Erika McPhillips, 2023, Technometrics. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> methods</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> Rcpp (&gt;= 0.12.3), RobustGaSP (&gt;= 0.6.4), nloptr (&gt;= 1.0.4)</td>
</tr>
<tr>
 <td style="text-align: left;">
LinkingTo: </td><td style="text-align: left;"> Rcpp, RcppEigen</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Repository: </td><td style="text-align: left;"> CRAN</td>
</tr>
<tr>
 <td style="text-align: left;">
Packaged: </td><td style="text-align: left;"> 2018-10-07 20:06:35 UTC; gumengyang</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 5.0.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date/Publication: </td><td style="text-align: left;"> 2018-05-14 04:26:37 UTC</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
RobustCalibration-package
                        Robust Calibration of Imperfect Mathematical
                        Models
predict                 Prediction for the robust calibration model
predict_MS              Prediction for the robust calibration model for
                        multiple sources
predictobj.rcalibration-class
                        Predictive results for the Robust Calibration
                        class
predictobj.rcalibration_MS-class
                        Predictive results for the Robust Calibration
                        class
rcalibration            Setting up the robust Calibration model
rcalibration-class      Robust Calibration class
rcalibration_MS         Setting up the robust Calibration model for
                        multiple sources data
rcalibration_MS-class   Robust Calibration for multiple sources class
show                    Show an Robust Calibration object.
</pre>
<p>Robust calibration of imperfect mathematical models and prediction using experimental data
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Bayarri, Maria J and Berger, James O and Paulo, Rui and Sacks, Jerry and Cafeo, John A and Cavendish, James and Lin, Chin-Hsu and Tu, Jian (2007) <em>A framework for validation of computer models</em>. <em>Technometrics</em>. <b>49</b>, 138&ndash;154.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>See Also</h3>

<p><code><a href="RobustGaSP.html#topic+RobustGaSP">RobustGaSP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##---------------------------------------------------
##A simple example where the math model is not biased
##---------------------------------------------------
## the reality 
test_funct_eg1&lt;-function(x){
  sin(pi/2*x)
}



## obtain 25 data from the reality plus a noise
set.seed(1)
## 10 data points are very small, one may want to add more data
n=15
input=seq(0,4,4/(n-1))
input=as.matrix(input)

output=test_funct_eg1(input)+rnorm(length(input),mean=0,sd=0.2)

## plot input and output 
#plot(input,output)
#num_obs=n=length(output)



## the math model 
math_model_eg1&lt;-function(x,theta){
  sin(theta*x)  
}

##fit the S-GaSP model for the discrepancy
##one can choose the discrepancy_type to GaSP, S-GaSP or no discrepancy
##p_theta is the number of parameters to calibrate and user needs to specifiy 
##one may also want to change the number of posterior samples by change S and S_0
##one may change sd_proposal for the standard derivation of the proposal distribution
## one may also add a mean by setting X=... and have_trend=TRUE
model_sgasp=rcalibration(design=input, observations=output, p_theta=1,simul_type=1,
                         math_model=math_model_eg1,theta_range=matrix(c(0,3),1,2)
                         ,S=10000,S_0=2000,discrepancy_type='S-GaSP')


##posterior samples of calibration parameter and value
## the value is 
plot(model_sgasp@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
plot(model_sgasp@post_value,type='l',xlab='num',ylab='posterior value')   


show(model_sgasp)



#------------------------------------------------------------------------------
# Example: an example used in Susie Bayarri et. al. 2007 Technometrics paper
#------------------------------------------------------------------------------

##reality
test_funct_eg1&lt;-function(x){
  3.5*exp(-1.7*x)+1.5
}


##math model
math_model_eg1&lt;-function(x,theta){
  5*exp(-x*theta) 
}

## noise observations (sampled from reality + independent Gaussian noises)
## each has 3 replicates
input=c(rep(.110,3),rep(.432,3),rep(.754,3),rep(1.077,3),rep(1.399,3),rep(1.721,3),
        rep(2.043,3),rep(2.366,3),rep(2.688,3),rep(3.010,3))
output=c(4.730,4.720,4.234,3.177,2.966,3.653,1.970,2.267,2.084,2.079,2.409,2.371,1.908,1.665,1.685,
         1.773,1.603,1.922,1.370,1.661,1.757,1.868,1.505,1.638,1.390,1.275,1.679,1.461,1.157,1.530)


n_stack=length(output)/3
output_stack=rep(0,n_stack)
input_stack=rep(0,n_stack)
for(j in 1:n_stack){
  output_stack[j]=mean(output[ ((j-1)*3+1):(3*j)])
  input_stack[j]=mean(input[ ((j-1)*3+1):(3*j)])
  
}
output_stack=as.matrix(output_stack)
input_stack=as.matrix(input_stack)
## plot the output and stack
#plot(input,output,pch=16,col='red')
#lines(input_stack,output_stack,pch=16,col='blue',type='p')



## fit the model with S-GaSP for the discrepancy
model_sgasp=rcalibration(design=input_stack, observations=output_stack, p_theta=1,simul_type=1,
                         math_model=math_model_eg1,theta_range=matrix(c(0,10),1,2),S=10000,
                         S_0=2000,discrepancy_type='S-GaSP')

#posterior
plot(model_sgasp@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
show(model_sgasp)



</code></pre>

<hr>
<h2 id='Accept_proposal'>
Determine whether we accept the proposed poserior sample at one step of MCMC.
</h2><span id='topic+Accept_proposal'></span>

<h3>Description</h3>

<p>Determine whether the proposed poserior sample is accepted at one step of MCMC. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Accept_proposal(r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Accept_proposal_+3A_r">r</code></td>
<td>

<p>r is a real number calculated by the ratio of posterior distribution with a new proposed sample of parameters and the posterior distribution with the current parameters.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bool value. If it is true, the proporsed sample gets accepted; if not, it gets rejected. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>

<hr>
<h2 id='Chol_Eigen'>
Cholesky decomposition of a symmetric matrix.
</h2><span id='topic+Chol_Eigen'></span>

<h3>Description</h3>

<p>This function provides a faster Cholesky decomposition of a symmetric matrix using the Eigen package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Chol_Eigen(R)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Chol_Eigen_+3A_r">R</code></td>
<td>

<p>R is a symmetric matrix.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lower triangular matrix of Cholesky decomposition</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>

<hr>
<h2 id='Get_inv_all'>
Produce the inversion of the covariances of the model discrepancy and the measurement bias.
</h2><span id='topic+Get_inv_all'></span>

<h3>Description</h3>

<p>This function computes inversion of the covariances of the model discrepancy and the measurement bias. This is applicable to model calibration with multiple sources of data and measurement bias. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Get_inv_all(param,  lambda_z, is_SGaSP, R0, kernel_type,  alpha_list,
p_x, num_sources)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Get_inv_all_+3A_param">param</code></td>
<td>

<p>a list of the current parameters values in MCMC.
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_lambda_z">lambda_z</code></td>
<td>

<p>the value of lambda_z 
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_is_sgasp">is_SGaSP</code></td>
<td>

<p>a vector of integer values to indicate whether it is S-GaSP model or not. 0 means the model is GaSP and 1 means the model is S-GaSP.
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_r0">R0</code></td>
<td>

<p>A List of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_kernel_type">kernel_type</code></td>
<td>

<p>Type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_alpha_list">alpha_list</code></td>
<td>

<p>A list of roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_p_x">p_x</code></td>
<td>

<p>a list of dimensions of the observable inputs.
</p>
</td></tr>
<tr><td><code id="Get_inv_all_+3A_num_sources">num_sources</code></td>
<td>

<p>a integer value of the number of sources.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of inverse covariances of discrepancy and measurement bias.</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>

<hr>
<h2 id='Get_R_new'>
Cholesky decomposition of the correlation matrix in GaSP.
</h2><span id='topic+Get_R_new'></span>

<h3>Description</h3>

<p>This function computes the Cholesky decomposition of the correlation matrix in GaSP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Get_R_new(beta_delta,  eta_delta,  R0, kernel_type,  alpha, inv_output_weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Get_R_new_+3A_beta_delta">beta_delta</code></td>
<td>

<p>Inverse range parameters.
</p>
</td></tr>
<tr><td><code id="Get_R_new_+3A_eta_delta">eta_delta</code></td>
<td>

<p>nugget parameters.
</p>
</td></tr>
<tr><td><code id="Get_R_new_+3A_r0">R0</code></td>
<td>

<p>A List of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="Get_R_new_+3A_kernel_type">kernel_type</code></td>
<td>

<p>Type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.
</p>
</td></tr>
<tr><td><code id="Get_R_new_+3A_alpha">alpha</code></td>
<td>

<p>Roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="Get_R_new_+3A_inv_output_weights">inv_output_weights</code></td>
<td>

<p>The inverse of output weights.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lower triangular matrix of Cholesky decomposition of the correlation matrix in GaSP.</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>

<hr>
<h2 id='Get_R_z_new'>
Cholesky decomposition of the covariance matrix in S-GaSP.
</h2><span id='topic+Get_R_z_new'></span>

<h3>Description</h3>

<p>This function computes the Cholesky decomposition of the covariance matrix in GaSP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Get_R_z_new(beta_delta,  eta_delta, lambda_z,  R0, kernel_type,  alpha, 
            inv_output_weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Get_R_z_new_+3A_beta_delta">beta_delta</code></td>
<td>

<p>a vector of inverse range parameters.
</p>
</td></tr>
<tr><td><code id="Get_R_z_new_+3A_eta_delta">eta_delta</code></td>
<td>

<p>a scalar of nugget parameters.
</p>
</td></tr>
<tr><td><code id="Get_R_z_new_+3A_lambda_z">lambda_z</code></td>
<td>

<p>a scalar parameter controling how close the math model to the reality in squared distance.
</p>
</td></tr>
<tr><td><code id="Get_R_z_new_+3A_r0">R0</code></td>
<td>

<p>a list of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="Get_R_z_new_+3A_kernel_type">kernel_type</code></td>
<td>

<p>type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.
</p>
</td></tr>
<tr><td><code id="Get_R_z_new_+3A_alpha">alpha</code></td>
<td>

<p>roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="Get_R_z_new_+3A_inv_output_weights">inv_output_weights</code></td>
<td>

<p>the inverse of output weights.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>lower triangular matrix of Cholesky decomposition of the covariance matrix in S-GaSP.</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>

<hr>
<h2 id='Log_marginal_post'>
Natural Logorithm of the posterior. </h2><span id='topic+Log_marginal_post'></span>

<h3>Description</h3>

<p>This function compute the natural Logorithm of the posterior assuming the GaSP or S-GaSP models for the discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Log_marginal_post(param, L_cur, output,  p_theta,  p_x, X, have_mean, CL, a, b,  cm_obs
,S_2_f,num_obs_all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Log_marginal_post_+3A_param">param</code></td>
<td>

<p>Current parameters in the MCMC. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_l_cur">L_cur</code></td>
<td>

<p>Cholesky decomposition of the covariance matrix. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_output">output</code></td>
<td>

<p>Experimental observations.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_p_theta">p_theta</code></td>
<td>

<p>Number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_p_x">p_x</code></td>
<td>

<p>Number of range parameters.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_x">X</code></td>
<td>

<p>Number of mean discrepancy parameters.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_have_mean">have_mean</code></td>
<td>

<p>Whether the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_cl">CL</code></td>
<td>

<p>Prior parameter in the jointly robust prior.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_a">a</code></td>
<td>

<p>Prior parameter in the jointly robust prior.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_b">b</code></td>
<td>

<p>Prior parameter in the jointly robust prior.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_cm_obs">cm_obs</code></td>
<td>

<p>Outputs from the mathematical model.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Natural logorithm of the posterior assuming the GaSP or S-GaSP models for the discrepancy function. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='Log_marginal_post_delta'>
Natural Logorithm of the posterior of the discrepancy in model calibration with multiple sources with measurement bias. </h2><span id='topic+Log_marginal_post_delta'></span>

<h3>Description</h3>

<p>This function compute the natural Logorithm of the posterior assuming the GaSP or S-GaSP models for the discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Log_marginal_post_delta(param, L, delta,  p_x, CL, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Log_marginal_post_delta_+3A_param">param</code></td>
<td>

<p>current parameters in the MCMC. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_delta_+3A_l">L</code></td>
<td>

<p>Cholesky decomposition of the covariance matrix. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_delta_+3A_delta">delta</code></td>
<td>

<p>a vector of the discrepancy.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_delta_+3A_p_x">p_x</code></td>
<td>

<p>dimension of observable inputs.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_delta_+3A_cl">CL</code></td>
<td>

<p>Prior parameter in the jointly robust prior.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_delta_+3A_a">a</code></td>
<td>

<p>Prior parameter in the jointly robust prior.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_delta_+3A_b">b</code></td>
<td>

<p>Prior parameter in the jointly robust prior.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Natural logorithm of the posterior of the discrepancy function. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='Log_marginal_post_no_discrepancy'>
Natural Logorithm of the posterior with no discrepancy function. </h2><span id='topic+Log_marginal_post_no_discrepancy'></span>

<h3>Description</h3>

<p>This function compute the natural Logorithm of the posterior assuming no discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Log_marginal_post_no_discrepancy(param,  output,  p_theta,   X, have_mean, 
inv_output_weights,  cm_obs,S_2_f,num_obs_all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_param">param</code></td>
<td>

<p>Current parameters in the MCMC. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_output">output</code></td>
<td>

<p>Experimental observations.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_p_theta">p_theta</code></td>
<td>

<p>Number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_x">X</code></td>
<td>

<p>Number of mean discrepancy parameters.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_have_mean">have_mean</code></td>
<td>

<p>Whether the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_inv_output_weights">inv_output_weights</code></td>
<td>

<p>Inverse of the weights of the outputs</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_cm_obs">cm_obs</code></td>
<td>

<p>Outputs from the mathematical model.
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="Log_marginal_post_no_discrepancy_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Natural logorithm of the posterior assuming no discrepancy function. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='mathematical_model_eval'>
Evaluation of the mathmatical model at given observed inputs and calibration parameters. </h2><span id='topic+mathematical_model_eval'></span>

<h3>Description</h3>

<p>This function evaluates the mathematical model at given observed inputs and calibration parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mathematical_model_eval(input,theta,simul_type, emulator,
emulator_type,loc_index_emulator,math_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mathematical_model_eval_+3A_input">input</code></td>
<td>

<p>a matrix of the observed inputs.
</p>
</td></tr>
<tr><td><code id="mathematical_model_eval_+3A_theta">theta</code></td>
<td>

<p>a vector of calibration parameters.
</p>
</td></tr>
<tr><td><code id="mathematical_model_eval_+3A_simul_type">simul_type</code></td>
<td>

<p>tpye of math model. If the simul_type is 0, it means we use the RobustGaSP R package to emulate the math model. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.
</p>
</td></tr>
<tr><td><code id="mathematical_model_eval_+3A_emulator">emulator</code></td>
<td>

<p>an S4 class of rgasp model from the RobustGaSP R Package.
</p>
</td></tr>
<tr><td><code id="mathematical_model_eval_+3A_emulator_type">emulator_type</code></td>
<td>

<p>a character to specify the type of emulator.  'rgasp' is for computer models with scalar-valued output and 'ppgasp'  for computer models with vectorized output.
</p>
</td></tr>
<tr><td><code id="mathematical_model_eval_+3A_loc_index_emulator">loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
<tr><td><code id="mathematical_model_eval_+3A_math_model">math_model</code></td>
<td>

<p>a function for the math model to be calibrated.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of outputs from the math model or its emulator at given observed inputs and calibration parameters. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>K. R. Anderson and M. P. Poland (2016), <em>Bayesian estimation of magma supply, storage, and eroption rates using a multiphysical volcano model: Kilauea volcano, 2000-2012.</em>. <em>Eath and Planetary Science Letters</em>, <b>447</b>, 161-171.
</p>
<p>K. R. Anderson and M. P. Poland (2017), <em>Abundant carbon in the mantle beneath Hawaii</em>. <em>Nature Geoscience</em>, <b>10</b>, 704-708.
</p>

<hr>
<h2 id='Mogihammer'>
A geophysical model for the ground deformation in Kilauea. </h2><span id='topic+Mogihammer'></span>

<h3>Description</h3>

<p>This function produces outputs of ground deformation at given coordinates and parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mogihammer(obsCoords, m, simul_type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Mogihammer_+3A_obscoords">obsCoords</code></td>
<td>

<p>spatial coordinate system.
</p>
</td></tr>
<tr><td><code id="Mogihammer_+3A_m">m</code></td>
<td>

<p>A five dimensional input parameters. The first two are the location of the magma chamber; the third one is the depth of the chamber; the fourth one is magma storage rate; the last one is the Possion ratio, which is related to the rock properties. 
</p>
</td></tr>
<tr><td><code id="Mogihammer_+3A_simul_type">simul_type</code></td>
<td>

<p>If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.  </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of outputs for ground deformation. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>K. R. Anderson and M. P. Poland (2016), <em>Bayesian estimation of magma supply, storage, and eroption rates using a multiphysical volcano model: Kilauea volcano, 2000-2012.</em>. <em>Eath and Planetary Science Letters</em>, <b>447</b>, 161-171.
</p>
<p>K. R. Anderson and M. P. Poland (2017), <em>Abundant carbon in the mantle beneath Hawaii</em>. <em>Nature Geoscience</em>, <b>10</b>, 704-708.
</p>

<hr>
<h2 id='post_sample'>
Posterior sampling. </h2><span id='topic+post_sample'></span>

<h3>Description</h3>

<p>This function performs the posterior sampling for calibration parameters and other parameters in the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_sample(input, output, R0_list, kernel_type, p_theta, output_weights, par_cur, 
            lambda_z,prior_par,theta_range,S,thinning, X, have_trend,alpha,
            sd_proposal,discrepancy_type, simul_type,emulator,
            emulator_type, loc_index_emulator,math_model,
            S_2_f,num_obs_all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="post_sample_+3A_input">input</code></td>
<td>

<p>a matrix of observed inputs/design points of the experimental data. 
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_output">output</code></td>
<td>

<p>a vector of experimental data.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_r0_list">R0_list</code></td>
<td>

<p>a List of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_kernel_type">kernel_type</code></td>
<td>

<p>type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_p_theta">p_theta</code></td>
<td>

<p>number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_output_weights">output_weights</code></td>
<td>

<p>a vector of the weights of the output.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_par_cur">par_cur</code></td>
<td>

<p>current value of the posterior samples.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_lambda_z">lambda_z</code></td>
<td>

<p>a scalar parameter controling how close the math model to the reality in squared distance.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_prior_par">prior_par</code></td>
<td>

<p>a vector of prior parameters in the prior.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_theta_range">theta_range</code></td>
<td>

<p>a matrix for the range of the calibration parameters. The first column is the lower bound and the second column is the upper bound of the calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_s">S</code></td>
<td>

<p>number of MCMC to run.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_thinning">thinning</code></td>
<td>
<p>the ratio between the number of posterior samples and the number of
recorded samples.</p>
</td></tr>
<tr><td><code id="post_sample_+3A_x">X</code></td>
<td>

<p>a matrix for the basis of the mean discrepancy. 
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_have_trend">have_trend</code></td>
<td>

<p>a bool value. It means the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_alpha">alpha</code></td>
<td>

<p>a vector of roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_sd_proposal">sd_proposal</code></td>
<td>

<p>a vector for the standard deviation of the proposal distribution. 
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_discrepancy_type">discrepancy_type</code></td>
<td>

<p>A string for type of discrepancy funcation. It can be chosen from 'no-discrepancy', 'GaSP' or 'S-GaSP'.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_simul_type">simul_type</code></td>
<td>

<p>tpye of math model. If the simul_type is 0, it means we use the RobustGaSP R package to emulate the math model. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_emulator">emulator</code></td>
<td>

<p>an S4 class of rgasp model from the RobustGaSP R Package.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_emulator_type">emulator_type</code></td>
<td>

<p>a character to specify the type of emulator.  'rgasp' is for computer models with scalar-valued output and 'ppgasp'  for computer models with vectorized output.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_loc_index_emulator">loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_math_model">math_model</code></td>
<td>

<p>a function for the math model to be calibrated.
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="post_sample_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. The first element is a matrix of the posterior samples after burn-in. The second element is a vector of posterior values after burn-in. The third element is the number of times of the proposed samples are accepted. The first value of the vector is the number of times that the proposed calibration parameters are accepted and the second value is the number of times of the proposed log inverse range parameter and the log nugget parameters are accepted, if there is a specification of the discrepancy function. The fourth element is the number of times the proposed samples of the calibration parameters are outside the  range of the calibration parameters.
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='post_sample_MS'>
Posterior sampling. </h2><span id='topic+post_sample_MS'></span>

<h3>Description</h3>

<p>This function performs the posterior sampling for calibration parameters and other parameters in the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_sample_MS(model,par_cur_theta, par_cur_individual, emulator,math_model_MS)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="post_sample_MS_+3A_model">model</code></td>
<td>

<p>a S4 object of rcalibration_MS. 
</p>
</td></tr>
<tr><td><code id="post_sample_MS_+3A_par_cur_theta">par_cur_theta</code></td>
<td>

<p>a list of current value of the posterior sample of calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_MS_+3A_par_cur_individual">par_cur_individual</code></td>
<td>

<p>a list of the current values of the posterior sample of the individual parameter of multiple sources.
</p>
</td></tr>
<tr><td><code id="post_sample_MS_+3A_emulator">emulator</code></td>
<td>

<p>a list of emulators if specified of multiple sources.
</p>
</td></tr>
<tr><td><code id="post_sample_MS_+3A_math_model_ms">math_model_MS</code></td>
<td>

<p>a list of mathematical models of multiple sources. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. The record_post is a vector of posterior values after burn-in samples. The record_theta is a matrix of of the posterior samples of theta after burn-in samples. The individual_par is a list where each element is a matrix of posterior samples of the range and nugget parameters for each source. The accept_S_theta is a vector where each element is the number of accepted posterior samples of calibration parameters. The accept_S_beta is a vector where each element is the number of accepted posterior samples of range and nugget parameters. The count_dec_record is vector where each element is the number of times the proposed samples of the calibration parameters are outside the  range of the calibration parameters for each source.
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='post_sample_no_discrepancy'>
Posterior sampling for the model with no discrepancy function. </h2><span id='topic+post_sample_no_discrepancy'></span>

<h3>Description</h3>

<p>This function performs the posterior sampling for calibration parameters and other parameters in the model assuming no discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
post_sample_no_discrepancy(input, output, R0_list,  p_theta, output_weights,
                                par_cur, theta_range,S,thinning, X, have_trend, 
                                alpha,sd_proposal, discrepancy_type, simul_type,emulator,
                                emulator_type, loc_index_emulator,
                                math_model,S_2_f,num_obs_all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="post_sample_no_discrepancy_+3A_input">input</code></td>
<td>

<p>a matrix of observed inputs/design points of the experimental data. 
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_output">output</code></td>
<td>

<p>a vector of experimental data.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_r0_list">R0_list</code></td>
<td>

<p>a List of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_p_theta">p_theta</code></td>
<td>

<p>number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_output_weights">output_weights</code></td>
<td>

<p>a vector of the weights of the output.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_par_cur">par_cur</code></td>
<td>

<p>current value of the posterior samples.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_theta_range">theta_range</code></td>
<td>

<p>a matrix for the range of the calibration parameters. The first column is the lower bound and the second column is the upper bound of the calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_s">S</code></td>
<td>

<p>number of MCMC to run.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_thinning">thinning</code></td>
<td>
<p>the ratio between the number of posterior samples and the number of
recorded samples.</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_x">X</code></td>
<td>

<p>a matrix for the basis of the mean discrepancy. 
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_have_trend">have_trend</code></td>
<td>

<p>a bool value. It means the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_alpha">alpha</code></td>
<td>

<p>a vector of roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_sd_proposal">sd_proposal</code></td>
<td>

<p>a vector for the standard deviation of the proposal distribution. 
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_discrepancy_type">discrepancy_type</code></td>
<td>

<p>A string for type of discrepancy funcation. It can be chosen from 'no-discrepancy', 'GaSP' or 'S-GaSP'.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_simul_type">simul_type</code></td>
<td>

<p>tpye of math model. If the simul_type is 0, it means we use the RobustGaSP R package to emulate the math model. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_emulator">emulator</code></td>
<td>

<p>an S4 class of rgasp model from the RobustGaSP R Package.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_emulator_type">emulator_type</code></td>
<td>

<p>a character to specify the type of emulator.  'rgasp' is for computer models with scalar-valued output and 'ppgasp'  for computer models with vectorized output.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_loc_index_emulator">loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_math_model">math_model</code></td>
<td>

<p>a function for the math model to be calibrated.
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="post_sample_no_discrepancy_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list. The first element is a matrix of the posterior samples after burn-in. The second element is a vector of posterior values after burn-in. The third element is the number of times of the proposed calibration parameters are accepted. The fourth element is the number of times the proposed samples of the calibration parameters are outside the  range of the calibration parameters.
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='post_sample_with_discrepancy'>
Posterior sampling for the model with a discrepancy function </h2><span id='topic+post_sample_with_discrepancy'></span>

<h3>Description</h3>

<p>This function performs the posterior sampling for calibration parameters and other parameters in the model, assuming the GaSP or S-GaSP model for the discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>post_sample_with_discrepancy(input, output, R0_list, kernel_type, p_theta, 
                             output_weights, par_cur, lambda_z,prior_par,theta_range,
                             S, thinning,X, have_trend, alpha,sd_proposal, 
                             discrepancy_type, simul_type,emulator,
                             emulator_type, loc_index_emulator,math_model,
                             S_2_f,num_obs_all)
                       
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="post_sample_with_discrepancy_+3A_input">input</code></td>
<td>

<p>a matrix of observed inputs/design points of the experimental data. 
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_output">output</code></td>
<td>

<p>a vector of experimental data.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_r0_list">R0_list</code></td>
<td>

<p>a List of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_kernel_type">kernel_type</code></td>
<td>

<p>type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_p_theta">p_theta</code></td>
<td>

<p>number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_output_weights">output_weights</code></td>
<td>

<p>a vector of the weights of the output.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_par_cur">par_cur</code></td>
<td>

<p>current value of the posterior samples.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_lambda_z">lambda_z</code></td>
<td>

<p>a scalar parameter controling how close the math model to the reality in squared distance.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_prior_par">prior_par</code></td>
<td>

<p>a vector of prior parameters in the prior.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_theta_range">theta_range</code></td>
<td>

<p>a matrix for the range of the calibration parameters. The first column is the lower bound and the second column is the upper bound of the calibration parameters.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_s">S</code></td>
<td>

<p>number of MCMC to run.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_thinning">thinning</code></td>
<td>
<p>the ratio between the number of posterior samples and the number of
recorded samples.</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_x">X</code></td>
<td>

<p>a matrix for the basis of the mean discrepancy. 
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_have_trend">have_trend</code></td>
<td>

<p>a bool value. It means the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_alpha">alpha</code></td>
<td>

<p>a vector of roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_sd_proposal">sd_proposal</code></td>
<td>

<p>a vector for the standard deviation of the proposal distribution. 
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_discrepancy_type">discrepancy_type</code></td>
<td>

<p>A string for type of discrepancy funcation. It can be chosen from 'no-discrepancy', 'GaSP' or 'S-GaSP'.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_simul_type">simul_type</code></td>
<td>

<p>tpye of math model. If the simul_type is 0, it means we use the RobustGaSP R package to emulate the math model. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_emulator">emulator</code></td>
<td>

<p>an S4 class of rgasp object from the RobustGaSP R Package.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_emulator_type">emulator_type</code></td>
<td>

<p>a character to specify the type of emulator.  'rgasp' is for computer models with scalar-valued output and 'ppgasp'  for computer models with vectorized output.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_loc_index_emulator">loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_math_model">math_model</code></td>
<td>

<p>a function for the math model to be calibrated.
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="post_sample_with_discrepancy_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code>. The first element is a matrix of the posterior samples after burn-in. The second element is a vector of posterior values after burn-in. The third element is the number of times the proposed samples are accepted. The first value of the vector is the number of times that the proposed calibration parameters are accepted and the second value is the number of times of the proposed log inverse range parameter and the log nugget parameters are accepted. The fourth element is the number of times the proposed samples of the calibration parameters are outside the  range of the calibration parameters.
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='predict'>
Prediction for the robust calibration model
</h2><span id='topic+predict'></span><span id='topic+predict.rcalibration'></span><span id='topic+predict+2Crcalibration-method'></span>

<h3>Description</h3>

<p>Function to make prediction on Robust Calibration models after the rcalibration class has been constructed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'rcalibration'
predict(object, testing_input,X_testing=NULL,
                                 n_thinning=10,
                                 testing_output_weights=NULL,
                                 interval_est=NULL,interval_data=F,
                                 math_model=NULL,test_loc_index_emulator=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>an object of  class <code>rcalibration</code>.</p>
</td></tr>
<tr><td><code id="predict_+3A_testing_input">testing_input</code></td>
<td>
<p>a matrix containing the inputs where the <code>predict</code> is to perform prediction. To predict one observable input with multiple dimension, user should supply a row vector. </p>
</td></tr>
<tr><td><code id="predict_+3A_x_testing">X_testing</code></td>
<td>
<p>a matrix of mean/trend for prediction.</p>
</td></tr>
<tr><td><code id="predict_+3A_n_thinning">n_thinning</code></td>
<td>
<p>number of points further thinning the MCMC posterior samples.</p>
</td></tr>
<tr><td><code id="predict_+3A_testing_output_weights">testing_output_weights</code></td>
<td>
<p>the weight of testing outputs.</p>
</td></tr>
<tr><td><code id="predict_+3A_interval_est">interval_est</code></td>
<td>
<p>a vector for the the posterior credible interval. If interval_est is NULL, we do  not compute the posterior credible interval.  It can be specified as a vector of values ranging from zero to one. E.g. if <code>interval_est=c(0.025, 0.975)</code>, the 95 posterior credible interval will be computed. </p>
</td></tr>
<tr><td><code id="predict_+3A_interval_data">interval_data</code></td>
<td>
<p>a bool value to decide whether the experimental noise is included for computing the posterior credible interval.  </p>
</td></tr>
<tr><td><code id="predict_+3A_math_model">math_model</code></td>
<td>

<p>a function for the math model to be calibrated.
</p>
</td></tr>
<tr><td><code id="predict_+3A_test_loc_index_emulator">test_loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>extra arguments to be passed to the function (not implemented yet).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned value is a S4 CLass <code>predictobj.rcalibration</code>. 
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Bayarri, Maria J and Berger, James O and Paulo, Rui and Sacks, Jerry and Cafeo, John A and Cavendish, James and Lin, Chin-Hsu and Tu, Jian (2007) <em>A framework for validation of computer models</em>. <em>Technometrics</em>. <b>49</b>, 138&ndash;154.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#------------------------------------------------------------------------------
# Example: an example used in Susie Bayarri et. al. 2007 Technometrics paper
#------------------------------------------------------------------------------
    

##reality
test_funct_eg1&lt;-function(x){
  3.5*exp(-1.7*x)+1.5
}


##math model
math_model_eg1&lt;-function(x,theta){
  5*exp(-x*theta) 
}


## noise observations (sampled from reality + independent Gaussian noises)
## each has 3 replicates
input=c(rep(.110,3),rep(.432,3),rep(.754,3),rep(1.077,3),rep(1.399,3),rep(1.721,3),
        rep(2.043,3),rep(2.366,3),rep(2.688,3),rep(3.010,3))
output=c(4.730,4.720,4.234,3.177,2.966,3.653,1.970,2.267,2.084,2.079,2.409,2.371,1.908,1.665,1.685,
         1.773,1.603,1.922,1.370,1.661,1.757,1.868,1.505,1.638,1.390,1.275,1.679,1.461,1.157,1.530)


## calculating the average or the stack data
n_stack=length(output)/3
output_stack=rep(0,n_stack)
input_stack=rep(0,n_stack)
for(j in 1:n_stack){
  output_stack[j]=mean(output[ ((j-1)*3+1):(3*j)])
  input_stack[j]=mean(input[ ((j-1)*3+1):(3*j)])
}
output_stack=as.matrix(output_stack)
input_stack=as.matrix(input_stack)
## plot the output and stack output
#plot(input,output,pch=16,col='red')
#lines(input_stack,output_stack,pch=16,col='blue',type='p')



## fit model using S-GaSP for the discrepancy
## one can change S and S_0 for the number of posterior and burn-in samples
## Normallly you may need a larger number of posterior sample
## you can set S=50000 and S_0=5000
## one may also change the sd of the proposal distribution using sd_proposal
model_sgasp=rcalibration(design=input_stack, observations=output_stack, p_theta=1,simul_type=1,
                         math_model=math_model_eg1,theta_range=matrix(c(0,10),1,2),
                         S=10000,S_0=2000,discrepancy_type='S-GaSP')

# one can  fit the GaSP model for discrepancy function by discrepancy_type='GaSP'
# one can  fit a model without the discrepancy function by discrepancy_type='no-discrepancy'

## posterior of the calibration parameter
#plot(model_sgasp@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
show(model_sgasp)

##

## test data set
testing_input=as.matrix(seq(0,6,0.02))

##perform prediction
prediction_sgasp=predict(model_sgasp,testing_input,math_model=math_model_eg1,
                         interval_est=c(0.025,0.975),interval_data=TRUE,
                         n_thinning =20 )

##real test output
testing_output=test_funct_eg1(testing_input)

##the prediction by S-GaSP
min_val=min(prediction_sgasp@mean,prediction_sgasp@interval,output,testing_output)
max_val=max(prediction_sgasp@mean,prediction_sgasp@interval,output,testing_output)

plot(testing_input,prediction_sgasp@mean,type='l',col='blue',xlab='x',ylab='y',
     ylim=c(min_val,max_val) )
lines(testing_input,prediction_sgasp@interval[,1],col='blue',lty=2)
lines(testing_input,prediction_sgasp@interval[,2],col='blue',lty=2)

lines(input,output,type='p')
lines(testing_input,prediction_sgasp@math_model_mean,col='blue',lty=3)

lines(testing_input,testing_output,type='l')

legend("topright", legend=c("reality", "predictive mean","95 percent posterior credible interval",
                            "predictive mean of the math model"),
                            col=c("black", "blue","blue","blue"), lty=c(1,1,2,3),cex=.6)


## MSE if the math model and discrepancy are used for prediction
mean((testing_output-prediction_sgasp@mean)^2)

## MSE if the math model is used for prediction 
mean((testing_output-prediction_sgasp@math_model_mean)^2)



##################################
#the example with a mean structure
##################################

##now let's fit  model with mean
model_sgasp_with_mean=rcalibration(design=input_stack, observations=output_stack,
                                   p_theta=1,X=matrix(1,dim(input_stack)[1],1),
                                   have_trend=TRUE,simul_type=1,
                                   math_model=math_model_eg1,
                                   theta_range=matrix(c(0,10),1,2),
                                   S=10000,S_0=2000,
                                   discrepancy_type='S-GaSP')

#posterior
#plot(model_sgasp_with_mean@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
show(model_sgasp_with_mean)

## test data set
testing_input=as.matrix(seq(0,6,0.02))


prediction_sgasp_with_mean=predict(model_sgasp_with_mean,testing_input, X_testing=matrix(1,dim
(testing_input)[1],1),
math_model=math_model_eg1,n_thinning = 50,
interval_est=c(0.025,0.975),interval_data=TRUE)


##plot for the S-GaSP 
##for this example, with a mean structure, it fits much better
min_val=min(prediction_sgasp_with_mean@mean,output,testing_output,
prediction_sgasp_with_mean@interval[,1])
max_val=max(prediction_sgasp_with_mean@mean,output,testing_output,
prediction_sgasp_with_mean@interval[,2])

plot(testing_input,prediction_sgasp_with_mean@mean,type='l',col='blue',xlab='x',
     ylab='y',ylim=c(min_val,max_val) )
#lines(testing_input,prediction_sgasp_with_mean@interval[,1],col='blue',lty=2)
#lines(testing_input,prediction_sgasp_with_mean@interval[,2],col='blue',lty=2)

lines(input,output,type='p')
lines(testing_input,prediction_sgasp_with_mean@math_model_mean,col='blue',lty=3)
lines(testing_input,prediction_sgasp_with_mean@interval[,1],col='blue',lty=2)
lines(testing_input,prediction_sgasp_with_mean@interval[,2],col='blue',lty=2)

lines(testing_input,testing_output,type='l')

legend("topright", legend=c("reality", "predictive mean", "predictive mean of the math model"),
       col=c("black", "blue","blue"), lty=c(1,1,3),cex=.6)


## MSE if the math model and discrepancy are used for prediction
mean((testing_output-prediction_sgasp_with_mean@mean)^2)

## MSE if the math model is used for prediction 
mean((testing_output-prediction_sgasp_with_mean@math_model_mean)^2)


## Not run: 
  #-------------------------------------------------------------
  #the example with the emulator
  #-------------------------------------------------------------
  
  n_design=80
  
  design_simul=matrix(runif(n_design*2),n_design,2)
  #library(lhs)
  #design_simul=maximinLHS(n=n_design,k=2)
  
  design_simul[,1]=6*design_simul[,1]   ##the first one is the observed input x
  design_simul[,2]=10*design_simul[,2]   ##the second one is the calibration parameter \theta
  
  output_simul=math_model_eg1(design_simul[,1],design_simul[,2])
  
  
  ##this is a little slow compared with the previous model
  
  model_sgasp_with_mean_emulator=rcalibration(design=input_stack, observations=output_stack,
                                              p_theta=1,simul_type=0, 
                                              have_trend=T,X=matrix(1,dim(input_stack)[1],1),
                                              input_simul=design_simul, output_simul=output_simul,
                                              theta_range=matrix(c(0,10),1,2),
                                              S=10000,S_0=2000,discrepancy_type='S-GaSP')
  
  ##now the output is a list
  show(model_sgasp_with_mean_emulator)
  
  ##here is the plot
  plot(model_sgasp_with_mean_emulator@post_sample[,4],type='l',xlab='num',ylab=expression(theta))   
  plot(model_sgasp_with_mean_emulator@post_value,type='l',xlab='num',ylab='posterior value')   
  
  
  prediction_sgasp_with_mean_emulator=predict(model_sgasp_with_mean_emulator,testing_input,
                                              X_testing=matrix(1,dim(testing_input)[1],1),
                                              interval_est=c(0.025,0.975),
                                              interval_data=TRUE)
  
  ##for this example, with a mean structure, it fits much better
  min_val=min(prediction_sgasp_with_mean_emulator@mean,output,testing_output,
              prediction_sgasp_with_mean_emulator@math_model_mean)
  max_val=max(prediction_sgasp_with_mean_emulator@mean,output,testing_output,
              prediction_sgasp_with_mean_emulator@math_model_mean)
  
  plot(testing_input,prediction_sgasp_with_mean_emulator@mean,type='l',col='blue',xlab='x',
       ylab='y',ylim=c(min_val,max_val) )
  #lines(testing_input,prediction_sgasp_with_mean@interval[,1],col='blue',lty=2)
  #lines(testing_input,prediction_sgasp_with_mean@interval[,2],col='blue',lty=2)
  
  lines(input,output,type='p')
  lines(testing_input,prediction_sgasp_with_mean_emulator@math_model_mean,col='blue',lty=3)
  
  lines(testing_input,testing_output,type='l')
  
  legend("topright", legend=c("reality", "predictive mean", "predictive mean of the math model"),
         col=c("black", "blue","blue"), lty=c(1,1,3),cex=.6)
  
  
  ## MSE if the math model and discrepancy are used for prediction
  mean((testing_output-prediction_sgasp_with_mean_emulator@mean)^2)
  
  ## MSE if the math model is used for prediction 
  mean((testing_output-prediction_sgasp_with_mean_emulator@math_model_mean)^2)


## End(Not run)


</code></pre>

<hr>
<h2 id='predict_MS'>
Prediction for the robust calibration model for multiple sources
</h2><span id='topic+predict_MS'></span><span id='topic+predict_MS.rcalibration_MS'></span><span id='topic+predict_MS+2Crcalibration_MS-method'></span>

<h3>Description</h3>

<p>Function to make prediction on Robust Calibration models after the rcalibration class has been constructed for multiple sources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'rcalibration_MS'
predict_MS(object, testing_input,
                                       X_testing=as.list(rep(0,object@num_sources)),
                                       testing_output_weights=NULL, 
                                       n_thinning=10,
                                       interval_est=NULL,
                                       interval_data=rep(F,length(testing_input)),
                                       math_model=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_MS_+3A_object">object</code></td>
<td>
<p>an object of  class <code>rcalibration_MS</code>.</p>
</td></tr>
<tr><td><code id="predict_MS_+3A_testing_input">testing_input</code></td>
<td>
<p>a list of matrices containing the inputs where the <code>predict_MS</code> is to perform prediction. Each element of the list is a matrix of testing inputs for the corresponding source of data. The number of rows of the matrix is equal to the number of predictive outputs for the corresponding source. </p>
</td></tr>
<tr><td><code id="predict_MS_+3A_x_testing">X_testing</code></td>
<td>
<p>a list of matrices of mean/trend for prediction if specified.  The number of rows of the matrix is equal to the number of predictive outputs for the corresponding source.</p>
</td></tr>
<tr><td><code id="predict_MS_+3A_testing_output_weights">testing_output_weights</code></td>
<td>
<p>a list of vecots for the weight of testing outputs for multiple sources.</p>
</td></tr>
<tr><td><code id="predict_MS_+3A_n_thinning">n_thinning</code></td>
<td>
<p>number of points further thinning the MCMC posterior samples.</p>
</td></tr>
<tr><td><code id="predict_MS_+3A_interval_est">interval_est</code></td>
<td>
<p>a list of vectors for the posterior predctive credible interval for multiple sources. If interval_est is NULL, we do  not compute the posterior credible interval.  It can be specified as a vector of values ranging from zero to one. E.g.  </p>
</td></tr>
<tr><td><code id="predict_MS_+3A_interval_data">interval_data</code></td>
<td>
<p>a vector of bool values to decide whether the experimental noise is included for computing the posterior credible interval.  </p>
</td></tr>
<tr><td><code id="predict_MS_+3A_math_model">math_model</code></td>
<td>

<p>a list of functions  for the math model to be calibrated for multiple sources.
</p>
</td></tr>
<tr><td><code id="predict_MS_+3A_...">...</code></td>
<td>
<p>extra arguments to be passed to the function (not implemented yet).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned value is a S4 CLass <code>predictobj.rcalibration</code>. 
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>K. R. Anderson and M. P. Poland (2016), <em>Bayesian estimation of magma supply, storage, and eroption rates using a multiphysical volcano model: Kilauea volcano, 2000-2012.</em>. <em>Eath and Planetary Science Letters</em>, <b>447</b>, 161-171.
</p>
<p>K. R. Anderson and M. P. Poland (2017), <em>Abundant carbon in the mantle beneath Hawaii</em>. <em>Nature Geoscience</em>, <b>10</b>, 704-708.
</p>
<p>Bayarri, Maria J and Berger, James O and Paulo, Rui and Sacks, Jerry and Cafeo, John A and Cavendish, James and Lin, Chin-Hsu and Tu, Jian (2007) <em>A framework for validation of computer models</em>. <em>Technometrics</em>. <b>49</b>, 138&ndash;154.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------------------------
# An example for calibrating and predicting mathematical models for data from multiple sources
#---------------------------------------------------------------------------------------------
    


library(RobustCalibration)


##reality
test_funct&lt;-function(x){
  sin(pi*x/2)+2*cos(pi*x/2)
}


##math model from two sources
math_model_source_1&lt;-function(x,theta){
  sin(theta*x) 
}

math_model_source_2&lt;-function(x,theta){
  cos(theta*x) 
}

input1=seq(0,2,2/(10-1))
input2=seq(0,3,3/(10-1))
##
output1=test_funct(input1)+rnorm(length(input1), sd=0.01)
output2=test_funct(input2)+rnorm(length(input2), sd=0.02)

plot(input1, output1)
plot(input2, output2)



design=list()
design[[1]]=as.matrix(input1)
design[[2]]=as.matrix(input2)

observations=list()
observations[[1]]=output1
observations[[2]]=output2


p_theta=1


theta_range=matrix(0,p_theta,2)
theta_range[1,]=c(0, 8)  
simul_type=c(1,1)

math_model=list()

math_model[[1]]=math_model_source_1
math_model[[2]]=math_model_source_2


## calibrating two mathematical models for these two sources
model_sgasp=rcalibration_MS(design=design, observations=observations, p_theta=1,
                            simul_type=simul_type,math_model=math_model,
                            theta_range=theta_range, 
                            S=10000,S_0=2000,
                            discrepancy_type=rep('S-GaSP',length(design)))

#plot(model_sgasp@post_theta[,1],type='l')
mean(model_sgasp@post_theta[,1])

testing_input1=seq(0,2,2/(25-1))

testing_input2=seq(0,3,3/(25-1))

testing_input=list()
testing_input[[1]]=as.matrix(testing_input1)
testing_input[[2]]=as.matrix(testing_input2)


predict_sgasp=predict_MS(model_sgasp, testing_input, math_model=math_model)
  

testing_output1=test_funct(testing_input1)
testing_output2=test_funct(testing_input2)


plot(predict_sgasp@mean[[1]])
lines(testing_output1)

plot(predict_sgasp@mean[[2]])
lines(testing_output2)



</code></pre>

<hr>
<h2 id='predict_separable_2dim'>
Fast prediction when the test points lie on a 2D lattice.
</h2><span id='topic+predict_separable_2dim'></span>

<h3>Description</h3>

<p>This function computes fast computation when the test points lie on a 2D lattice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_separable_2dim(object, testing_input_separable,
X_testing=matrix(0,length(testing_input_separable[[1]])*
length(testing_input_separable[[2]]),1), n_thinning=10,  
interval_est = NULL,math_model=NULL,test_loc_index_emulator=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_separable_2dim_+3A_object">object</code></td>
<td>
<p>an object of  class <code>rcalibration</code>.</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_+3A_testing_input_separable">testing_input_separable</code></td>
<td>

<p>a list. The first element is a vector of the coordinate of the latitue 
and the second element is a vector of the coordinate of the longitude.
</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_+3A_x_testing">X_testing</code></td>
<td>
<p>a matrix of mean/trend for prediction.</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_+3A_n_thinning">n_thinning</code></td>
<td>
<p>number of points thinning the MCMC posterior samples.</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_+3A_math_model">math_model</code></td>
<td>

<p>a function for the math model to be calibrated.
</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_+3A_test_loc_index_emulator">test_loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned value is a S4 CLass <code>predictobj.rcalibration</code>. 
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='predict_separable_2dim_MS'>
Fast prediction when the test points lie on a 2D lattice for multiple sources of observations.
</h2><span id='topic+predict_separable_2dim_MS'></span>

<h3>Description</h3>

<p>This function computes fast computation when the test points lie on a 2D lattice for multiple sources of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_separable_2dim_MS(object, testing_input_separable,
X_testing=NULL, math_model=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_separable_2dim_MS_+3A_object">object</code></td>
<td>
<p>an object of  class <code>rcalibration</code>.</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_MS_+3A_testing_input_separable">testing_input_separable</code></td>
<td>

<p>a list of two. In the first (outer) list, each list is a source of test input. Then in the second (interior) list,  The first element is a vector of the coordinate of the latitue 
and the second element is a vector of the coordinate of the longitude.
</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_MS_+3A_x_testing">X_testing</code></td>
<td>
<p>mean/trend for prediction where the defaul value is NULL.</p>
</td></tr>
<tr><td><code id="predict_separable_2dim_MS_+3A_math_model">math_model</code></td>
<td>

<p>a list of functions of math models to be calibrated.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned value is a S4 CLass <code>predictobj.rcalibration_MS</code>. 
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2018) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. SIAM/ASA Journal on Uncertainty Quantification, <b>6</b>, 1555-1583.
</p>
<p>M. Gu (2019) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. Bayesian Analysis,  <b>14</b>, 857-885.
</p>

<hr>
<h2 id='predictobj.rcalibration_MS-class'>Predictive results for the Robust Calibration class </h2><span id='topic+predictobj.rcalibration_MS-class'></span><span id='topic+predictobj.rcalibration_MS'></span>

<h3>Description</h3>

<p>S4 class for prediction after Robust rcalibration for multiple sources.</p>


<h3>Objects from the Class</h3>

<p>Objects of this class are created and initialized with the function <code><a href="#topic+predict_MS">predict_MS</a></code> that computes the prediction and the uncertainty quantification.</p>


<h3>Slots</h3>


<dl>
<dt><code>mean</code>:</dt><dd><p>object of class <code>list</code>. Each element is a <code>vector</code> of the predictive mean at testing inputs combing the mathematical model and discrepancy function for each source.</p>
</dd>
<dt><code>math_model_mean</code>:</dt><dd><p>object of class  <code>list</code>. Each element is a <code>vector</code> of the predictive mean at testing inputs using only the mathematical model (and the trend if specified).</p>
</dd>
<dt><code>math_model_mean_no_trend</code>:</dt><dd><p>object of class  <code>list</code>. Each element is a <code>vector</code> of the predictive mean at testing inputs using only the mathematical model without the trend for each source.</p>
</dd>
<dt><code>interval</code>:</dt><dd><p>object of class <code>list</code>. Each element is a <code>matrix</code> of  the upper and lower predictive credible interval. If interval_data is TRUE in the <code><a href="#topic+predict_MS">predict_MS</a></code>, the experimental noise is included for computing the predictive credible interval. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+predict_MS">predict_MS</a></code> for more details about how to do prediction for a <code>rcalibration_MS</code> object.
</p>

<hr>
<h2 id='predictobj.rcalibration-class'>Predictive results for the Robust Calibration class </h2><span id='topic+predictobj.rcalibration-class'></span><span id='topic+predictobj.rcalibration'></span>

<h3>Description</h3>

<p>S4 class for prediction after Robust rcalibration with or without the specification of the discrepancy model.</p>


<h3>Objects from the Class</h3>

<p>Objects of this class are created and initialized with the function <code><a href="#topic+predict">predict</a></code> that computes the prediction and the uncertainty quantification.</p>


<h3>Slots</h3>


<dl>
<dt><code>mean</code>:</dt><dd><p>object of class <code>vector</code>. The predictive mean at testing inputs combing the mathematical model and discrepancy function.</p>
</dd>
<dt><code>math_model_mean</code>:</dt><dd><p>object of class <code>vector</code>. The predictive mean at testing inputs using only the mathematical model (and the trend if specified).</p>
</dd>
<dt><code>math_model_mean_no_trend</code>:</dt><dd><p>object of class <code>vector</code>. The predictive mean at testing inputs using only the mathematical model without the trend.</p>
</dd>
<dt><code>delta</code>:</dt><dd><p>object of class <code>vector</code>. The predictive discrepancy function.</p>
</dd>
<dt><code>interval</code>:</dt><dd><p>object of class <code>matrix</code>.  The upper and lower predictive credible interval. If interval_data is TRUE in the <code><a href="#topic+predict.rcalibration">predict.rcalibration</a></code>, the experimental noise is included for computing the predictive credible interval. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+predict.rcalibration">predict.rcalibration</a></code> for more details about how to do prediction for a <code>rcalibration</code> object.
</p>

<hr>
<h2 id='rcalibration'> Setting up the robust Calibration model
</h2><span id='topic+rcalibration'></span><span id='topic+rcalibration-method'></span>

<h3>Description</h3>

<p>Setting up the Calibration model for estimating the parameters via MCMC with or without a discrepancy function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  rcalibration(design, observations, p_theta=NULL, 
  X=matrix(0,dim(as.matrix(design))[1],1), 
  have_trend=FALSE, simul_type=1, input_simul=NULL,output_simul=NULL,simul_nug=FALSE,
  loc_index_emulator=NULL,math_model=NULL, theta_range=NULL,
  sd_proposal=NULL, 
  S=10000,S_0=2000,thinning=1, discrepancy_type='S-GaSP',
  kernel_type='matern_5_2', lambda_z=NA, a=1/2-dim(as.matrix(design))[2], b=1,
  alpha=rep(1.9,dim(as.matrix(design))[2]), 
  output_weights=rep(1,dim(as.matrix(design))[1]),method='post_sample',
  initial_values=NULL,num_initial_values=3,...)
 
      
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rcalibration_+3A_design">design</code></td>
<td>
<p>a matrix of observed inputs where each row is a row vector of observable inputs corresponding to one observation, and the number of field or experimental data is the total number of rows. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_observations">observations</code></td>
<td>
<p>a vector of field or experimental data. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_p_theta">p_theta</code></td>
<td>
<p>an integer about the number of parameters, which should be specified by the user. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_x">X</code></td>
<td>
<p>a matrix of the mean/trend discrepancy between the reality and math model. The number of rows of X is equal to the number of observations. The default values are a vector of zeros. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_have_trend">have_trend</code></td>
<td>
<p>a bool value meaning whether we assume a mean/trend discrepancy  function.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_simul_type">simul_type</code></td>
<td>
<p>an integer about the math model/simulator. If the simul_type is 0, it means we use RobustGaSP R package to build an emulator for emulation. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_input_simul">input_simul</code></td>
<td>
<p>an D x (p_x+p_theta) matrix of design for emulating the math model. It is only useful if simul_type is 0, meaning that we emulate the output of the math model.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_output_simul">output_simul</code></td>
<td>
<p>a D dimensional vector of the math model runs on the design (input_simul). It is only useful if simul_type is 0, meaning that we emulate the output of the math model.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_simul_nug">simul_nug</code></td>
<td>
<p>a bool value meaning whether we have a nugget for emulating the math model/simulator. If the math model is stochastic, we often need a nugget. If simul_Nug is TRUE, it means we have a nugget for the emulator. If simul_Nug is FALSE, it means we do not have a nugget for the emulator.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_loc_index_emulator">loc_index_emulator</code></td>
<td>

<p>a vector of the location index from the ppgasp emulator to output. Only useful for vectorized output computer model emulated by the ppgasp emulator.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_math_model">math_model</code></td>
<td>
<p>a function of the math model provided by the user. It is only useful if simul_type is 1, meaning that we know the math model and it can be computed fast. If the math model is computationally slow, one should set simul_type to be 0 to emulate the math model. One can input a function to define  a math_model where the first input of the function is a vector of observable inputs and the second input is a vector of  calibration parameters. The output of each function is a scalar. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_theta_range">theta_range</code></td>
<td>
<p>a p_theta x 2 matrix of the range of the calibration parameters. The first column is the lower bound and the second column  is the upper bound. It should be specified by the user if the simul_type is 0. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_sd_proposal">sd_proposal</code></td>
<td>
<p>a vector of the standard deviation of the proposal distribution in MCMC. The default value of sd of the calibration parameter is 0.05 times <code>theta_range</code>. The rest is set to be 0.05. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_s">S</code></td>
<td>
<p>number of posterior samples to run. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_s_0">S_0</code></td>
<td>
<p>number of burn-in samples. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_thinning">thinning</code></td>
<td>
<p>number of posterior samples to record. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_discrepancy_type">discrepancy_type</code></td>
<td>
<p>characters about the type of the discrepancy.  If it is 'no-discrepancy', it means no discrepancy function. If it is 'GaSP', it means the GaSP model for the discrepancy function. If it is 'S-GaSP', it means the S-GaSP model for the discrepancy function.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_kernel_type">kernel_type</code></td>
<td>
<p>characters about the type of the discrepancy type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_lambda_z">lambda_z</code></td>
<td>
<p>a <code>vector</code> value about how close the math model to the reality in squared distance when the S-GaSP model is used for modeling the discrepancy.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_a">a</code></td>
<td>
<p>a scalar of the prior parameter.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_b">b</code></td>
<td>
<p>a scalar of the prior parameter.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_alpha">alpha</code></td>
<td>
<p>a numeric parameter for the roughness in the kernel.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_output_weights">output_weights</code></td>
<td>
<p>a vector of the weights of the outputs.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_method">method</code></td>
<td>
<p>characters for method of parameter estimation. If it is 'post_sample', the posterior sampling will be used. If it is 'mle', the maximum likelihood estimator will be used.</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_initial_values">initial_values</code></td>
<td>

<p>either a vector or a matrix of initial values of parameters. If posterior sampling method is used, it needs to be vector of the initial values of the calibration parameters. If an optimization method is used, it can be a matrix of the calbiration parameters and kernel parameters (log inverse range parameters and the log nugget parameter) to be optimized numerically, where each row of the matrix contains a set of initial values. 
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_num_initial_values">num_initial_values</code></td>
<td>

<p>the number of initial values of the kernel parameters in optimization.
</p>
</td></tr>
<tr><td><code id="rcalibration_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to the function (not implemented yet)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rcalibration</code> returns an S4 object of class <code>rcalibration</code> (see <code>rcalibration-class</code>).
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>K. R. Anderson and M. P. Poland (2016), <em>Bayesian estimation of magma supply, storage, and eroption rates using a multiphysical volcano model: Kilauea volcano, 2000-2012.</em>. <em>Eath and Planetary Science Letters</em>, <b>447</b>, 161-171.
</p>
<p>K. R. Anderson and M. P. Poland (2017), <em>Abundant carbon in the mantle beneath Hawaii</em>. <em>Nature Geoscience</em>, <b>10</b>, 704-708.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(RobustCalibration)

#-------------------------------------------------------------
# an example with multiple local maximum of minimum in L2 loss
#-------------------------------------------------------------

## the reality 
test_funct_eg1&lt;-function(x){
  x*cos(3/2*x)+x
}



## obtain 25 data from the reality plus a noise
set.seed(1)
## 10 data points are very small, one may want to add more data
n=15
input=seq(0,5,5/(n-1))
input=as.matrix(input)

output=test_funct_eg1(input)+rnorm(length(input),mean=0,sd=0.1)

num_obs=n=length(output)



## the math model 
math_model_eg1&lt;-function(x,theta){
  sin(theta*x)+x  
}

##fit the S-GaSP model for the discrepancy
##one can choose the discrepancy_type to GaSP, S-GaSP or no discrepancy
##p_theta is the number of parameters to calibrate and user needs to specifiy 
##one may also want to change the number of posterior samples by change S and S_0
p_theta=1
model_sgasp=rcalibration(design=input, observations=output, p_theta=p_theta,simul_type=1,
                         math_model=math_model_eg1,theta_range=matrix(c(0,3),1,2)
                         ,S=10000,S_0=2000,discrepancy_type='S-GaSP')

##if the acceptance rate is too low or two high, one can adjust sd_proposal, e.g.
#model_sgasp=rcalibration(design=input, observations=output, p_theta=1,simul_type=1,
#                         sd_proposal=c(rep(0.02,p_theta),rep(0.2,dim(input)[2]),0.2)
#                         math_model=math_model_eg1,theta_range=matrix(c(0,3),1,2)
#                         ,S=10000,S_0=2000,discrepancy_type='S-GaSP')

##posterior samples of calibration parameter and value
plot(model_sgasp@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
plot(model_sgasp@post_value,type='l',xlab='num',ylab='posterior value')   


show(model_sgasp)




##one may want to fit a a model with an estimated baseline mean discrepancy by setting 
##X=matrix(1,dim(input_stack)[1],1),have_trend=TRUE

model_sgasp_with_mean=rcalibration(design=input, observations=output, p_theta=1,simul_type=1,
                                   X=matrix(1,dim(input)[1],1),have_trend=TRUE,
                                   math_model=math_model_eg1,theta_range=matrix(c(0,3),1,2),
                                   S=10000,S_0=2000,discrepancy_type='S-GaSP')

show(model_sgasp_with_mean)

##posterior samples of calibration parameter and value
plot(model_sgasp_with_mean@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
plot(model_sgasp_with_mean@post_value,type='l',xlab='num',ylab='posterior value')   


## Not run: 
  #-------------------------------------------------------------
  # an example with multiple local maximum of minimum in L2 loss
  # for combing the emulator
  #-------------------------------------------------------------
  
  ## the reality 
  test_funct_eg1&lt;-function(x){
    x*cos(3/2*x)+x
  }
  
  ## obtain 20 data from the reality plus a noise
  set.seed(1)
  n=20
  input=seq(0,5,5/(n-1))
  input=as.matrix(input)
  
  output=test_funct_eg1(input)+rnorm(length(input),mean=0,sd=0.05)
  
  num_obs=n=length(output)
  
  ## the math model 
  math_model_eg1&lt;-function(x,theta){
    sin(theta*x)+x  
  }
  
  ##let's build an emulator for the case if the math model is too slow
  
  # let's say we can only run the math model n_design times
  n_design=80
  
  design_simul=matrix(runif(n_design*2),n_design,2)
  design_simul[,1]=5*design_simul[,1]   ##the first one is the observed input x
  design_simul[,2]=3*design_simul[,2]   ##the second one is the calibration parameter 
  
  output_simul=math_model_eg1(design_simul[,1],design_simul[,2])
  
  
  
  ##this is a little slow compared with the previous model
  model_sgasp_emulator=rcalibration(design=input, observations=output, p_theta=1,simul_type=0, 
                                    input_simul=design_simul, output_simul=output_simul,
                                    theta_range=matrix(c(0,3),1,2),
                                    S=10000,S_0=2000,discrepancy_type='S-GaSP')
  
  ##now the output is a list
  show(model_sgasp_emulator)

  ##here is the plot
  plot(model_sgasp_emulator@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
  plot(model_sgasp_emulator@post_value,type='l',xlab='num',ylab='posterior value')   

## End(Not run)



</code></pre>

<hr>
<h2 id='rcalibration_MS'> Setting up the robust Calibration model for multiple sources data
</h2><span id='topic+rcalibration_MS'></span><span id='topic+rcalibration_MS-method'></span>

<h3>Description</h3>

<p>Setting up the Calibration model for estimating the parameters via MCMC for multiple sources. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  rcalibration_MS(design, observations, p_theta=NULL, index_theta=NULL,
                  X=as.list(rep(0,length(design))), 
                  have_trend=rep(FALSE,length(design)),
                  simul_type=rep(1, length(design)),
                  input_simul=NULL, output_simul=NULL,
                  simul_nug=rep(FALSE,length(design)),loc_index_emulator=NULL,
                  math_model=NULL, 
                  theta_range=NULL, 
                  sd_proposal_theta=NULL, 
                  sd_proposal_cov_par=NULL,
                  S=10000,S_0=2000, thinning=1,measurement_bias=FALSE, 
                  shared_design=NULL,have_measurement_bias_recorded=F,
                            shared_X=0,have_shared_trend=FALSE,
                  discrepancy_type=rep('S-GaSP',length(design)+measurement_bias),
                  kernel_type=rep('matern_5_2',length(design)+measurement_bias),
                  lambda_z=as.list(rep(NA,length(design)+measurement_bias)),
                  a=NULL,b=NULL,alpha=NULL,
                  output_weights=NULL,...)
 
      
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rcalibration_MS_+3A_design">design</code></td>
<td>
<p>a list of observed inputs from multiple sources. Each element of the list is a matrix of observable inputs, where each row is a row vector of observable inputs corresponding to one observation and the number of field or experimental data is the total number of rows. 
</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_observations">observations</code></td>
<td>
<p>a list of experimental data from multiple sources. Each element is a vector of observations. 
</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_index_theta">index_theta</code></td>
<td>
<p>a list of vectors for the index of calibration parameter contained in each source.
</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_p_theta">p_theta</code></td>
<td>
<p>an integer about the number of parameters, which should be specified by the user. 
</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_x">X</code></td>
<td>
<p>a list of matrices of the mean/trend discrepancy between the reality and math model for multiple sources. 
</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_have_trend">have_trend</code></td>
<td>
<p>a vector of bool value meaning whether we assume a mean/trend discrepancy  function.
</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_simul_type">simul_type</code></td>
<td>
<p>a vector of integer about the math model/simulator for multiple sources. If the simul_type is 0, it means we use RobustGaSP R package to build an emulator for emulation. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_input_simul">input_simul</code></td>
<td>
<p>a list of matices, each having dimension D x (p_x+p_theta) being the design for emulating the math model. It is only useful if the ith value of simul_type is 0 for the ith source, meaning that we emulate the output of the math model.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_output_simul">output_simul</code></td>
<td>
<p>a list of vectors, each having dimension D x 1 being the math model outputs on the design (input_simul). It is only useful if the ith value of simul_type is 0 for the ith source, meaning that we emulate the output of the math model.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_simul_nug">simul_nug</code></td>
<td>
<p>a vectors of bool values meaning whether we have a nugget for emulating the math model/simulator for this source. If the math model is stochastic, we often need a nugget. If simul_Nug is TRUE, it means we have a nugget for the emulator. If simul_Nug is FALSE, it means we do not have a nugget for the emulator.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_loc_index_emulator">loc_index_emulator</code></td>
<td>
<p>a list for location index to output in the ppgasp emulator  for computer models with vectorized output.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_math_model">math_model</code></td>
<td>
<p>a list of functions of the math models provided by the user for multiple sources. It is only useful if simul_type is 1, meaning that we know the math model and it can be computed fast. If  the math model is computationally slow, one should set simul_type to be 0 to emulate the math model. If defined, each element of the list is a function of math models, where the first input of the function is a vector of observable inputs and the second input is a vector of  calibration parameters. The output of each function is a scalar. Each function corresponds to one source of data. </p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_theta_range">theta_range</code></td>
<td>
<p>a p_theta x 2 matrix of the range of the calibration parameters. The first column is the lower bound and the second column  is the upper bound. It should be specified by the user if the simul_type is 0.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_sd_proposal_theta">sd_proposal_theta</code></td>
<td>
<p>a vector of the standard deviation of the proposal distribution for the calibration parameters in MCMC. The default value of sd of the calibration parameter is 0.05 times <code>theta_range</code>. </p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_sd_proposal_cov_par">sd_proposal_cov_par</code></td>
<td>
<p>a list of vectors of the standard deviation of the proposal distribution for range and nugget parameters in MCMC for each source.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_s">S</code></td>
<td>
<p>an integer about about how many posterior samples to run.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_s_0">S_0</code></td>
<td>
<p>an integer about about the number of burn-in samples.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_thinning">thinning</code></td>
<td>
<p>the ratio between the number of posterior samples and the number of recorded samples.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_measurement_bias">measurement_bias</code></td>
<td>
<p>containing measurement bias or not.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_shared_design">shared_design</code></td>
<td>
<p>A matrix for shared design across different sources of data used 
when measurement bias exists.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_have_measurement_bias_recorded">have_measurement_bias_recorded</code></td>
<td>
<p>A bool value whether we record measurement bias or not.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_shared_x">shared_X</code></td>
<td>
<p>A matrix of shared trend when measurement bias exists.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_have_shared_trend">have_shared_trend</code></td>
<td>
<p>A bool value whether we have shared trend when measurement bias exist.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_discrepancy_type">discrepancy_type</code></td>
<td>
<p>a vector of characters about the type of the discrepancy for each source.  If it is 'no-discrepancy', it means no discrepancy function. If it is 'GaSP', it means the GaSP model for the discrepancy function. If it is 'S-GaSP', it means the S-GaSP model for the discrepancy function.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_kernel_type">kernel_type</code></td>
<td>
<p>a vector of characters about the type of kernel for each data source. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_lambda_z">lambda_z</code></td>
<td>
<p>a <code>vector</code> numeric values about how close the math model to the reality in squared distance when the S-GaSP model is used for modeling the discrepancy for each source.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_a">a</code></td>
<td>
<p>a vector of the prior parameter for multiple sources.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_b">b</code></td>
<td>
<p>a vector of the prior parameter for multiple sources.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_alpha">alpha</code></td>
<td>
<p>a list of vectors of roughness parameters in the kernel for multiple sources.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_output_weights">output_weights</code></td>
<td>
<p>a list of vectors of the weights of the outputs for multiple sources.</p>
</td></tr>
<tr><td><code id="rcalibration_MS_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to the function (not implemented yet).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rcalibration_MS</code> returns an S4 object of class <code>rcalibration_MS</code> (see <code>rcalibration_MS-class</code>).
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>K. R. Anderson and M. P. Poland (2016), <em>Bayesian estimation of magma supply, storage, and eroption rates using a multiphysical volcano model: Kilauea volcano, 2000-2012.</em>. <em>Eath and Planetary Science Letters</em>, <b>447</b>, 161-171.
</p>
<p>K. R. Anderson and M. P. Poland (2017), <em>Abundant carbon in the mantle beneath Hawaii</em>. <em>Nature Geoscience</em>, <b>10</b>, 704-708.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#------------------------------------------------------------------------------
# An example for calibrating mathematical models for data from multiple sources
#------------------------------------------------------------------------------

library(RobustCalibration)


##reality
test_funct&lt;-function(x){
  sin(pi*x/2)+2*cos(pi*x/2)
}


##math model from two sources
math_model_source_1&lt;-function(x,theta){
  sin(theta*x) 
}

math_model_source_2&lt;-function(x,theta){
  cos(theta*x) 
}

input1=seq(0,2,2/(10-1))
input2=seq(0,3,3/(15-1))
##
output1=test_funct(input1)+rnorm(length(input1), sd=0.01)
output2=test_funct(input2)+rnorm(length(input2), sd=0.02)

plot(input1, output1)
plot(input2, output2)



design=list()
design[[1]]=as.matrix(input1)
design[[2]]=as.matrix(input2)

observations=list()
observations[[1]]=output1
observations[[2]]=output2


p_theta=1


theta_range=matrix(0,p_theta,2)
theta_range[1,]=c(0, 8)  
simul_type=c(1,1)

math_model=list()

math_model[[1]]=math_model_source_1
math_model[[2]]=math_model_source_2


## calibrating two mathematical models for these two sources
model_sgasp=rcalibration_MS(design=design, observations=observations, p_theta=1,
                            simul_type=simul_type,math_model=math_model,
                            theta_range=theta_range, 
                            S=10000,S_0=2000,
                            discrepancy_type=rep('S-GaSP',length(design)))

plot(model_sgasp@post_theta[,1],type='l')
mean(model_sgasp@post_theta[,1])


</code></pre>

<hr>
<h2 id='rcalibration_MS-class'> Robust Calibration for multiple sources class </h2><span id='topic+rcalibration_MS-class'></span>

<h3>Description</h3>

<p>S4 class for multiple sources Robust rcalibration with or without the specification of the discrepancy model.</p>


<h3>Objects from the Class</h3>

<p>Objects of this class are created and initialized with the function <code><a href="#topic+rcalibration_MS">rcalibration_MS</a></code> that computes the prediction after calibrating the mathematical models from multiple sources.</p>


<h3>Slots</h3>


<dl>
<dt><code>num_sources</code>:</dt><dd><p>Object of class <code>integer</code>. The number of sources.</p>
</dd>
<dt><code>p_x</code>:</dt><dd><p>Object of class <code>vector</code>. Each element is the dimension of the observed inputs in each source.</p>
</dd>
<dt><code>p_theta</code>:</dt><dd><p>Object of class <code>integer</code>. The number of calibration parameters.</p>
</dd>
<dt><code>num_obs</code>:</dt><dd><p>Object of class <code>vector</code>.Each element is the number of experimental observations of each source.</p>
</dd>
<dt><code>index_theta</code>:</dt><dd><p>Object of class <code>list</code>. The each element is a <code>vector</code> of the index of calibration parameters (theta) contained in each source. </p>
</dd>
<dt><code>input</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>matrix</code> of the design of experiments in each source with dimension <code>n_i x p_{x,i}</code>, for i=1,...,num_sources.</p>
</dd>
<dt><code>output</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>vector</code> of the experimental observations in each source with dimension n_i x 1, for i=1,...,num_sources.</p>
</dd>
<dt><code>X</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>matrix</code> of the mean/trend discrepancy basis function in each source with dimension n_i x q_i,  for i=1,...,num_sources.</p>
</dd>
<dt><code>have_trend</code>:</dt><dd><p>Object of class <code>vector</code>. Each element is a  <code>bool</code> to specify whether the mean/trend discrepancy is zero in each source. &quot;TRUE&quot; means it has zero mean discrepancy and &quot;FALSE&quot;&quot; means the mean discrepancy is not zero.</p>
</dd>
<dt><code>q</code>:</dt><dd><p>Object of class <code>vector</code>.  Each element is <code>integer</code> of the number of basis functions of the mean/trend discrepancy in each source. </p>
</dd>
<dt><code>R0</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a list of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector in each source.</p>
</dd>
<dt><code>kernel_type</code>:</dt><dd><p>Object of class <code>vector</code>. Each element is a <code>character</code> to specify the type of kernel to use in each source.</p>
</dd>
<dt><code>alpha</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>vector</code> of parameters for the roughness parameters in the kernel in each source.</p>
</dd>
<dt><code>theta_range</code>:</dt><dd><p>A <code>matrix</code> for the range of the calibration parameters.</p>
</dd>
<dt><code>lambda_z</code>:</dt><dd><p>Object of class <code>vector</code>.  Each element is a <code>numeric</code> value about how close the math model to the reality in squared distance when the S-GaSP model is used for modeling the discrepancy in each source.</p>
</dd>
<dt><code>S</code>:</dt><dd><p>Object of class <code>integer</code> about how many posterior samples to run.</p>
</dd>
<dt><code>S_0</code>:</dt><dd><p>Object of class <code>integer</code> about the number of burn-in samples.</p>
</dd>
<dt><code>prior_par</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>vector</code> about prior parameters.</p>
</dd>
<dt><code>output_weights</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>vector</code> about the weights of the experimental data.</p>
</dd>
<dt><code>sd_proposal_theta</code>:</dt><dd><p>Object of class <code>vector</code> about the standard deviation of the proposal distribution for the calibration parameters.</p>
</dd>
<dt><code>sd_proposal_cov_par</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>vector</code> about the standard deviation of the proposal distribution for the calibration parameters in each source.</p>
</dd>
<dt><code>discrepancy_type</code>:</dt><dd><p>Object of class <code>vector</code>.  Each element is a <code>character</code> about the type of the discrepancy in each source. If it is 'no-discrepancy', it means no discrepancy function. If it is 'GaSP', it means the GaSP model for the discrepancy function. If it is 'S-GaSP', it means the S-GaSP model for the discrepancy function.</p>
</dd>
<dt><code>simul_type</code>:</dt><dd><p>Object of class <code>vector</code>. Each element is an <code>integer</code> about the math model/simulator. If the simul_type is 0, it means we use RobustGaSP R package to build an emulator for emulation. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.</p>
</dd>
<dt><code>emulator_rgasp</code>:</dt><dd><p>Object of class <code>list</code>.  Each element is an S4 class of <code>rgasp</code> from the RobustGaSP package in each source.</p>
</dd>
<dt><code>emulator_ppgasp</code>:</dt><dd><p>Object of class <code>list</code>.  Each element is an S4 class of <code>ppgasp</code> from the RobustGaSP package in each source.</p>
</dd>
<dt><code>post_theta</code>:</dt><dd><p>Object of class <code>matrix</code> for the posterior samples of the calibration parameters after burn-in.</p>
</dd>
<dt><code>post_individual_par</code>:</dt><dd><p>Object of class <code>list</code>. Each element is a <code>matrix</code> for the posterior samples after burn-in in each source.</p>
</dd>
<dt><code>post_value</code>:</dt><dd><p>Object of class <code>vector</code> for the posterior values after burn-in.</p>
</dd>
<dt><code>accept_S_theta</code>:</dt><dd><p>Object of class <code>numerical</code> for the number of proposed samples of the calibration parameters are accepted in MCMC.</p>
</dd>
<dt><code>accept_S_beta</code>:</dt><dd><p>Object of class <code>vector</code> for the number of proposed samples of the range and nugget parameters in each source are accepted in MCMC.</p>
</dd>
<dt><code>count_boundary</code>:</dt><dd><p>Object of class <code>vector</code> for the number of proposed samples of the calibation parameters are outside the range and they are rejected directly.</p>
</dd>
<dt><code>have_measurement_bias_recorded</code>:</dt><dd><p>Object of class <code>bool</code> for whether measurement bias will be recorded or not.</p>
</dd>
<dt><code>measurement_bias</code>:</dt><dd><p>Object of class <code>bool</code> for whether measurement bias exists or not.</p>
</dd>
<dt><code>post_delta</code>:</dt><dd><p>Object of class <code>matrix</code> of samples of model discrepancy.</p>
</dd>
<dt><code>post_measurement_bias</code>:</dt><dd><p>Object of class <code>list</code> of samples of measurement_bias if measurement bias is chosen to be recorded.</p>
</dd>
<dt><code>thinning</code>:</dt><dd><p>Object of class <code>integer</code> for the ratio between the number of posterior samples and the number of  samples to be recorded.</p>
</dd>
<dt><code>emulator_type</code>:</dt><dd><p>Object of class <code>vector</code> for the type of emulator for each source of data. 'rgasp' means scalar-valued emulator and 'ppgasp' means vectorized emulator.</p>
</dd>
<dt><code>loc_index_emulator</code>:</dt><dd><p>Object of class <code>list</code> for location index to output in ghe ppgasp emulator  for computer models with vectorized output.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>predict_MS</dt><dd><p>See <code><a href="#topic+predict_MS.rcalibration_MS">predict_MS</a></code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rcalibration_MS">rcalibration_MS</a></code> for more details about how to create a <code>rcalibration_MS</code> object.
</p>

<hr>
<h2 id='rcalibration-class'> Robust Calibration class </h2><span id='topic+rcalibration-class'></span>

<h3>Description</h3>

<p>S4 class for Robust rcalibration with or without the specification of the discrepancy model.</p>


<h3>Objects from the Class</h3>

<p>Objects of this class are created and initialized with the function <code><a href="#topic+rcalibration">rcalibration</a></code> that computes the calculations needed for setting up the calibration and prediction.</p>


<h3>Slots</h3>


<dl>
<dt><code>p_x</code>:</dt><dd><p>Object of class <code>integer</code>. The dimension of the observed inputs.</p>
</dd>
<dt><code>p_theta</code>:</dt><dd><p>Object of class <code>integer</code>. The  calibration parameters.</p>
</dd>
<dt><code>num_obs</code>:</dt><dd><p>Object of class <code>integer</code>. The number of experimental observations.</p>
</dd>
<dt><code>input</code>:</dt><dd><p>Object of class <code>matrix</code> with dimension n x p_x. The design of experiments.</p>
</dd>
<dt><code>output</code>:</dt><dd><p>Object of class <code>vector</code> with dimension n x 1. The vector of the experimental observations.</p>
</dd>
<dt><code>X</code>:</dt><dd><p>Object of class <code>matrix</code> of with dimension n x q. The mean/trend discrepancy basis function.</p>
</dd>
<dt><code>have_trend</code>:</dt><dd><p>Object of class <code>bool</code> to specify whether the mean/trend discrepancy is zero. &quot;TRUE&quot; means it has zero mean discrepancy and &quot;FALSE&quot;&quot; means the mean discrepancy is not zero.</p>
</dd>
<dt><code>q</code>:</dt><dd><p>Object of class <code>integer</code>. The number of basis functions of the mean/trend discrepancy.</p>
</dd>
<dt><code>R0</code>:</dt><dd><p>Object of class <code>list</code> of matrices where the j-th matrix is an absolute difference matrix of the j-th input vector.</p>
</dd>
<dt><code>kernel_type</code>:</dt><dd><p>A <code>character</code> to specify the type of kernel to use.</p>
</dd>
<dt><code>alpha</code>:</dt><dd><p>Object of class <code>vector</code>. Each element is the parameter for the roughness for each input coordinate in the kernel.</p>
</dd>
<dt><code>theta_range</code>:</dt><dd><p>A <code>matrix</code> for the range of the calibration parameters.</p>
</dd>
<dt><code>lambda_z</code>:</dt><dd><p>Object of class <code>vector</code> about how close the math model to the reality in squared distance when the S-GaSP model is used for modeling the discrepancy.</p>
</dd>
<dt><code>S</code>:</dt><dd><p>Object of class <code>integer</code> about how many posterior samples to run.</p>
</dd>
<dt><code>S_0</code>:</dt><dd><p>Object of class <code>integer</code> about the number of burn-in samples.</p>
</dd>
<dt><code>prior_par</code>:</dt><dd><p>Object of class <code>vector</code> about prior parameters.</p>
</dd>
<dt><code>output_weights</code>:</dt><dd><p>Object of class <code>vector</code> about the weights of the experimental data.</p>
</dd>
<dt><code>sd_proposal</code>:</dt><dd><p>Object of class <code>vector</code> about the standard deviation of the proposal distribution.</p>
</dd>
<dt><code>discrepancy_type</code>:</dt><dd><p>Object of class <code>character</code> about the discrepancy. If it is 'no-discrepancy', it means no discrepancy function. If it is 'GaSP', it means the GaSP model for the discrepancy function. If it is 'S-GaSP', it means the S-GaSP model for the discrepancy function.</p>
</dd>
<dt><code>simul_type</code>:</dt><dd><p>Object of class <code>integer</code> about the math model/simulator. If the simul_type is 0, it means we use RobustGaSP R package to build an emulator for emulation. If the simul_type is 1, it means the function of the math model is given by the user. When simul_type is 2 or 3, the mathematical model is the geophyiscal model for Kilauea Volcano.  If the simul_type is 2, it means it is for the ascending mode InSAR data; if the simul_type is 3, it means it is for the descending mode InSAR data.</p>
</dd>
<dt><code>emulator_rgasp</code>:</dt><dd><p>An S4 class of <code>rgasp</code> from the RobustGaSP package.</p>
</dd>
<dt><code>emulator_ppgasp</code>:</dt><dd><p>An S4 class of <code>ppgasp</code> from the RobustGaSP package.</p>
</dd>
<dt><code>post_sample</code>:</dt><dd><p>Object of class <code>matrix</code> for the posterior samples after burn-in.</p>
</dd>
<dt><code>post_value</code>:</dt><dd><p>Object of class <code>vector</code> for the posterior values after burn-in.</p>
</dd>
<dt><code>accept_S</code>:</dt><dd><p>Object of class <code>vector</code> for the number of proposed samples of the calibation parameters are accepted in MCMC. The first value is the number of proposed calibration parameters  are accepted in MCMC. The second value is  the number of proposed range and nugget parameters  are accepted.</p>
</dd>
<dt><code>count_boundary</code>:</dt><dd><p>Object of class <code>vector</code> for the number of proposed samples of the calibation parameters are outside the range and they are rejected directly.</p>
</dd>
<dt><code>have_replicates</code>:</dt><dd><p>Object of class <code>bool</code> for having repeated experiments (replicates) or not.</p>
</dd>
<dt><code>num_replicates</code>:</dt><dd><p>Object of class <code>vector</code> for the number of replicates at each observable input.</p>
</dd>
<dt><code>thinning</code>:</dt><dd><p>Object of class <code>integer</code> for the ratio between the number of posterior samples and the number of  samples to be recorded.</p>
</dd>
<dt><code>S_2_f</code>:</dt><dd><p>Object of class <code>numeric</code> for the variance of the field observations.</p>
</dd>
<dt><code>num_obs_all</code>:</dt><dd><p>Object of class <code>integer</code> for the total number of field observations.</p>
</dd>
<dt><code>method</code>:</dt><dd><p>Object of class <code>character</code> for posterior sampling or maximum likelihood estimation.</p>
</dd>
<dt><code>initial_values</code>:</dt><dd><p>Object of class <code>matrix</code> for initial starts of kernel parameters in maximum likelihood estimation.</p>
</dd>
<dt><code>param_est</code>:</dt><dd><p>Object of class <code>vector</code> for estimated range and nugget parameter in parameter estimation.</p>
</dd>
<dt><code>opt_value</code>:</dt><dd><p>Object of class <code>numeric</code> for optimized likelihood or loss function.</p>
</dd>
<dt><code>emulator_type</code>:</dt><dd><p>Object of class <code>character</code> for the type of emulator. 'rgasp' means scalar-valued emulator and 'ppgasp' means vectorized emulator.</p>
</dd>
<dt><code>loc_index_emulator</code>:</dt><dd><p>Object of class <code>vector</code> for location index to output in the ppgasp emulator  for computer models with vectorized output.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>show</dt><dd><p>Prints the main slots of the object. </p>
</dd>
<dt>predict</dt><dd><p>See <code><a href="#topic+predict.rcalibration">predict</a></code>.</p>
</dd>
<dt>predict_separable_2dim</dt><dd><p>See <code><a href="#topic+predict_separable_2dim">predict_separable_2dim</a></code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rcalibration">rcalibration</a></code> for more details about how to create a <code>rcalibration</code> object.
</p>

<hr>
<h2 id='Sample_delta'>
Sample the model discrepancy. </h2><span id='topic+Sample_delta'></span>

<h3>Description</h3>

<p>This function samples a vector of the model discrepancy for the scenario with 
multiple sources and measurement bias. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sample_delta(cov_inv_all,  tilde_output_cur,   param,  p_x,   
num_sources, num_obs, rand_norm)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sample_delta_+3A_cov_inv_all">cov_inv_all</code></td>
<td>

<p>a list of inverse covariances of discrepancy and measurement bias. 
</p>
</td></tr>
<tr><td><code id="Sample_delta_+3A_tilde_output_cur">tilde_output_cur</code></td>
<td>

<p>a list of transformed observations.
</p>
</td></tr>
<tr><td><code id="Sample_delta_+3A_param">param</code></td>
<td>

<p>a list of the current parameters values in MCMC.
</p>
</td></tr>
<tr><td><code id="Sample_delta_+3A_p_x">p_x</code></td>
<td>

<p>a list of dimensions of the observable inputs.
</p>
</td></tr>
<tr><td><code id="Sample_delta_+3A_num_sources">num_sources</code></td>
<td>

<p>the number of sources.
</p>
</td></tr>
<tr><td><code id="Sample_delta_+3A_num_obs">num_obs</code></td>
<td>

<p>the number of observations. 
</p>
</td></tr>
<tr><td><code id="Sample_delta_+3A_rand_norm">rand_norm</code></td>
<td>

<p>the vector of i.i.d. standard normal samples. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of samples of model discrepancy. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='Sample_sigma_2_theta_m'>
Sample the variance and mean parameters. </h2><span id='topic+Sample_sigma_2_theta_m'></span>

<h3>Description</h3>

<p>This function Samples the variance and mean parameters assuming the GaSP or S-GaSP models for the discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sample_sigma_2_theta_m(param,  L_cur,  output,   p_theta,  p_x,  X,  have_mean, cm_obs
,S_2_f,num_obs_all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sample_sigma_2_theta_m_+3A_param">param</code></td>
<td>

<p>Current parameters in the MCMC. 
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_l_cur">L_cur</code></td>
<td>

<p>Cholesky decomposition of the covariance matrix. 
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_output">output</code></td>
<td>

<p>Experimental observations.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_p_theta">p_theta</code></td>
<td>

<p>Number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_p_x">p_x</code></td>
<td>

<p>Number of range parameters.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_x">X</code></td>
<td>

<p>Number of mean discrepancy parameters.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_have_mean">have_mean</code></td>
<td>

<p>Whether the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_cm_obs">cm_obs</code></td>
<td>

<p>outputs from the mathematical model.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of samples of the variance and mean discrepancy parameters. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='Sample_sigma_2_theta_m_no_discrepancy'>
Sample the variance and mean parameters with no discrepancy function. </h2><span id='topic+Sample_sigma_2_theta_m_no_discrepancy'></span>

<h3>Description</h3>

<p>This function samples the variance and mean parameters assuming no discrepancy function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Sample_sigma_2_theta_m_no_discrepancy(param,  output,   p_theta,   
                                      X,  have_mean, inv_output_weights, cm_obs,
                                      S_2_f,num_obs_all)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_param">param</code></td>
<td>

<p>Current parameters in the MCMC. 
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_output">output</code></td>
<td>

<p>Experimental observations.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_p_theta">p_theta</code></td>
<td>

<p>Number of calibration parameters.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_x">X</code></td>
<td>

<p>Number of mean discrepancy parameters.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_have_mean">have_mean</code></td>
<td>

<p>Whether the mean discrepancy is zero or not.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_inv_output_weights">inv_output_weights</code></td>
<td>

<p>The inverse of the weights of outputs..
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_cm_obs">cm_obs</code></td>
<td>

<p>outputs from the mathematical model.
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_s_2_f">S_2_f</code></td>
<td>

<p>Variance of the data. This term is useful when there are repeated experiments. 
</p>
</td></tr>
<tr><td><code id="Sample_sigma_2_theta_m_no_discrepancy_+3A_num_obs_all">num_obs_all</code></td>
<td>

<p>Total number of observations. If there is no repeated experiment, this is equal to the number of observable inputs. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of samples of the variance and trend parameters. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>

<hr>
<h2 id='separable_kernel'>Product correlation matrix with the product form
</h2><span id='topic+separable_kernel'></span>

<h3>Description</h3>

<p>Function to construct the product correlation matrix with the product form. This is imported from the RobustGaSP package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>separable_kernel(R0, beta, kernel_type, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="separable_kernel_+3A_r0">R0</code></td>
<td>

<p>A List of matrix where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="separable_kernel_+3A_beta">beta</code></td>
<td>

<p>The range parameters.
</p>
</td></tr>
<tr><td><code id="separable_kernel_+3A_kernel_type">kernel_type</code></td>
<td>

<p>A vector specifying the type of kernels of each coordinate of the input. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential correlation with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha. The default choice is <code>matern_5_2</code>. The <code>periodic_gauss</code> means the Gaussian kernel with periodic folding method with be used. The <code>periodic_exp</code> means the exponential kernel with periodic folding method will be used.
</p>
</td></tr>
<tr><td><code id="separable_kernel_+3A_alpha">alpha</code></td>
<td>

<p>Roughness parameters in the kernel functions.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The product correlation matrix with the product form.
</p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>

<hr>
<h2 id='show'>
Show an Robust Calibration object.
</h2><span id='topic+show'></span><span id='topic+show.rcalibration'></span><span id='topic+show.rcalibration-class'></span><span id='topic+show+2Crcalibration-method'></span>

<h3>Description</h3>

<p>Function to print the Robust Calibration model after the rcalibration class has been constructed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'rcalibration'
show(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="show_+3A_object">object</code></td>
<td>
<p> an object of  class <code>rcalibration</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>M. Gu (2016), <em>Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output</em>, Ph.D. thesis., Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>
<p>M. Gu (2018) <em>Jointly Robust Prior for Gaussian Stochastic Process in Emulation, Calibration and Variable Selection
</em>. arXiv preprint arXiv:1804.09329.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##-------------------------------------------------
#A simple example where the math model is not biased
##-------------------------------------------------
## the reality 
test_funct_eg1&lt;-function(x){
  sin(pi/2*x)
}



## obtain 15 data from the reality plus a noise
set.seed(1)
## 10 data points are very small, one may want to add more data
n=15
input=seq(0,4,4/(n-1))
input=as.matrix(input)

output=test_funct_eg1(input)+rnorm(length(input),mean=0,sd=0.2)

## plot input and output 
#plot(input,output)
#num_obs=n=length(output)



## the math model 
math_model_eg1&lt;-function(x,theta){
  sin(theta*x)  
}

##fit the S-GaSP model for the discrepancy
##one can choose the discrepancy_type to GaSP, S-GaSP or no discrepancy
##p_theta is the number of parameters to calibrate and user needs to specifiy 
##one may also want to change the number of posterior samples by change S and S_0
##one may change sd_proposal for the standard derivation of the proposal distribution
## one may also add a mean by setting X=... and have_trend=TRUE
model_sgasp=rcalibration(design=input, observations=output, p_theta=1,simul_type=1,
                         math_model=math_model_eg1,theta_range=matrix(c(0,3),1,2)
                         ,S=10000,S_0=2000,discrepancy_type='S-GaSP')


##posterior samples of calibration parameter and value
## the value is 
plot(model_sgasp@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
plot(model_sgasp@post_value,type='l',xlab='num',ylab='posterior value')   


show(model_sgasp)


#-------------------------------------------------------------
# an example with multiple local maximum of minimum in L2 loss
#-------------------------------------------------------------

## the reality 
test_funct_eg1&lt;-function(x){
  x*cos(3/2*x)+x
}



## obtain 15 data from the reality plus a noise
set.seed(1)
n=15
input=seq(0,5,5/(n-1))
input=as.matrix(input)

output=test_funct_eg1(input)+rnorm(length(input),mean=0,sd=0.05)

num_obs=n=length(output)


## the math model 
math_model_eg1&lt;-function(x,theta){
  sin(theta*x)+x  
}

## fit the S-GaSP model for the discrepancy

model_sgasp=rcalibration(design=input, observations=output, p_theta=1,simul_type=1,
                         math_model=math_model_eg1,theta_range=matrix(c(0,3),1,2),
                         discrepancy_type='S-GaSP')


## posterior samples 
plot(model_sgasp@post_sample[,1],type='l',xlab='num',ylab=expression(theta))   
show(model_sgasp)

</code></pre>

<hr>
<h2 id='Update_R_inv_y'>
Update the inverse of covariance multiplied by the outputs in the S-GaSP model. </h2><span id='topic+Update_R_inv_y'></span>

<h3>Description</h3>

<p>This function update the inverse of R_z multiple the outputs in the S-GaSP model for prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Update_R_inv_y(R_inv_y,  R0,  beta_delta,   kernel_type,  alpha,  lambda_z,  num_obs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Update_R_inv_y_+3A_r_inv_y">R_inv_y</code></td>
<td>

<p>A vector of inverse of covariance  multiplied by the outputs.
</p>
</td></tr>
<tr><td><code id="Update_R_inv_y_+3A_r0">R0</code></td>
<td>

<p>A List of matrix where the j-th matrix is an absolute difference matrix of the j-th input vector.
</p>
</td></tr>
<tr><td><code id="Update_R_inv_y_+3A_beta_delta">beta_delta</code></td>
<td>

<p>Inverse range parameters.
</p>
</td></tr>
<tr><td><code id="Update_R_inv_y_+3A_kernel_type">kernel_type</code></td>
<td>

<p>Type of kernel. <code>matern_3_2</code> and <code>matern_5_2</code> are <code>Matern kernel</code> with roughness parameter 3/2 and 5/2 respectively. <code>pow_exp</code> is power exponential kernel with roughness parameter alpha. If <code>pow_exp</code> is to be used, one needs to specify its roughness parameter alpha.
</p>
</td></tr>
<tr><td><code id="Update_R_inv_y_+3A_alpha">alpha</code></td>
<td>

<p>Roughness parameters in the kernel functions. It is only useful if the power exponential correlation function is used.
</p>
</td></tr>
<tr><td><code id="Update_R_inv_y_+3A_lambda_z">lambda_z</code></td>
<td>

<p>A parameter controling how close the math model to the reality in squared distance.
</p>
</td></tr>
<tr><td><code id="Update_R_inv_y_+3A_num_obs">num_obs</code></td>
<td>

<p>Number of observations.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the inverse of covariance multiplied by the outputs in the S-GaSP model. </p>


<h3>Author(s)</h3>

<p>Mengyang Gu [aut, cre]
</p>
<p>Maintainer: Mengyang Gu &lt;mengyang@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>A. O'Hagan and M. C. Kennedy (2001), <em>Bayesian calibration of computer models</em>, <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology</em>, <b>63</b>, 425-464.
</p>
<p>Mengyang Gu. (2016). Robust Uncertainty Quantification and Scalable Computation for Computer Models with Massive Output. Ph.D. thesis. Duke University.
</p>
<p>M. Gu and L. Wang (2017) <em>Scaled Gaussian Stochastic Process for Computer Model Calibration and Prediction</em>. arXiv preprint arXiv:1707.08215.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
