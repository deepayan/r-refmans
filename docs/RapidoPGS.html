<!DOCTYPE html><html lang="en"><head><title>Help for package RapidoPGS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RapidoPGS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#create_1000G'><p>Download 1000 Genomes Phase III panel</p></a></li>
<li><a href='#EUR_ld.blocks19'><p>LD block architecture for European populations (hg19).</p></a></li>
<li><a href='#EUR_ld.blocks38'><p>LD block architecture for European populations (hg38).</p></a></li>
<li><a href='#find_file_in_ftp'><p>Finding a file in an FTP directory</p>
This is an internal function to help <code>gwascat.download</code> find the right file</a></li>
<li><a href='#gwascat.download'><p>Retrieve GWAS summary datasets from GWAS catalog</p>
'<code>gwascat.download</code> takes a PMID from the user and downloads the associated summary statistics datasets published in GWAS catalog</a></li>
<li><a href='#logsum'><p>Helper function to sum logs without loss of precision</p></a></li>
<li><a href='#michailidou19'><p>Subset of Michailidou BRCA GWAS sumstat dataset.</p></a></li>
<li><a href='#michailidou38'><p>Subset of Michailidou BRCA GWAS sumstat dataset.</p></a></li>
<li><a href='#rapidopgs_multi'><p>Compute PGS from GWAS summary statistics using Bayesian sum of single-effect</p>
(SuSiE) linear regression using z scores</a></li>
<li><a href='#rapidopgs_single'><p>Compute PGS from GWAS summary statistics using posteriors from Wakefield's approximate Bayes Factors</p></a></li>
<li><a href='#sd.prior.est'><p>Compute Standard deviation prior (SD prior) for quantitative traits</p>
using pre-computed heritability.</a></li>
<li><a href='#sdY.est'><p>Estimate trait variance, internal function</p></a></li>
<li><a href='#wakefield_pp'><p>compute posterior probabilities using Wakefield's approximate Bayes Factors</p>
<code>wakefield_pp</code> computes posterior probabilities for a given SNP to be causal for a given SNP under the assumption of a single causal variant.</a></li>
<li><a href='#wakefield_pp_quant'><p>Compute posterior probabilities using Wakefield's approximate Bayes Factors for quantitative traits</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>A Fast and Light Package to Compute Polygenic Risk Scores</td>
</tr>
<tr>
<td>Version:</td>
<td>2.3.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Quickly computes polygenic scores from GWAS summary statistics of either case-control or quantitative traits without parameter tuning. Reales,G., Vigorito, E., Kelemen,M., Wallace,C. (2021) &lt;<a href="https://doi.org/10.1101%2F2020.07.24.220392">doi:10.1101/2020.07.24.220392</a>&gt; "RÃ¡pidoPGS: A rapid polygenic score calculator for summary GWAS data without a test dataset".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3), data.table, RCurl, curl, magrittr</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr (&ge; 1.1.3), GenomicRanges (&ge; 1.52.0), IRanges (&ge;
2.34.1), bigsnpr (&ge; 1.12.2), coloc (&ge; 5.2.3), bigreadr (&ge;
0.2.5)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-19 11:42:09 UTC; gr440</td>
</tr>
<tr>
<td>Author:</td>
<td>Guillermo Reales <a href="https://orcid.org/0000-0001-9993-3916"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Chris Wallace <a href="https://orcid.org/0000-0001-9755-1703"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Olly Burren <a href="https://orcid.org/0000-0002-3388-5760"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Guillermo Reales &lt;gr440@cam.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-19 12:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='create_1000G'>Download 1000 Genomes Phase III panel</h2><span id='topic+create_1000G'></span>

<h3>Description</h3>

<p><code>create_1000G</code> downloads and gets 1000 Genomes Phase III panel (hg19) in
PLINK format, and apply quality control for being used to compute PGS using
<code>rapidopgs_multi</code>.
Given the size of the files, running this function can take long, depending
on broadband speed and server status. We also recommend to ensure that there
is at least 60GB free space available in disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_1000G(
  directory = "ref-data",
  remove.related = TRUE,
  qc.maf = 0.01,
  qc.hwe = 1e-10,
  qc.geno = 0,
  autosomes.only = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_1000G_+3A_directory">directory</code></td>
<td>
<p>a string indicating the directory to download the panel</p>
</td></tr>
<tr><td><code id="create_1000G_+3A_remove.related">remove.related</code></td>
<td>
<p>a logical stating if related individuals should be removed.
Default TRUE.</p>
</td></tr>
<tr><td><code id="create_1000G_+3A_qc.maf">qc.maf</code></td>
<td>
<p>a numeric to set the MAF threshold for variants to be removed. DEFAULT 0.01</p>
</td></tr>
<tr><td><code id="create_1000G_+3A_qc.hwe">qc.hwe</code></td>
<td>
<p>a numeric indicating the threshold for Hardy-Weinberg exact test
p-value, below which variants will be removed. DEFAULT 1e-10.</p>
</td></tr>
<tr><td><code id="create_1000G_+3A_qc.geno">qc.geno</code></td>
<td>
<p>a numeric to set maximum missing call rates for variants. DEFAULT = 0.</p>
</td></tr>
<tr><td><code id="create_1000G_+3A_autosomes.only">autosomes.only</code></td>
<td>
<p>If FALSE, it will include X and Y chromosomes, too.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>bed, fam and bim files for each chromosome in the chosen directory.
</p>


<h3>Author(s)</h3>

<p>Guillermo Reales
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
create_1000G()

## End(Not run)
</code></pre>

<hr>
<h2 id='EUR_ld.blocks19'>LD block architecture for European populations (hg19).</h2><span id='topic+EUR_ld.blocks19'></span>

<h3>Description</h3>

<p>A GRanges object containing the LD block for European ancestry, in hg19 build.
This dataset was obtained from <a href="https://doi.org/10.1093/bioinformatics/btv546">doi:10.1093/bioinformatics/btv546</a>, in bed format,
then converted to GRanges. See manuscript for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EUR_ld.blocks19
</code></pre>


<h3>Format</h3>

<p>A GRanges object containing 1703 ranges
</p>

<dl>
<dt>seqnames</dt><dd><p>chromosome</p>
</dd>
<dt>ranges</dt><dd><p>start and stop positions for the block</p>
</dd>
<dt>strand</dt><dd><p>genomic strand, irrelevant here</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://bitbucket.org/nygcresearch/ldetect-data/src">https://bitbucket.org/nygcresearch/ldetect-data/src</a>
</p>

<hr>
<h2 id='EUR_ld.blocks38'>LD block architecture for European populations (hg38).</h2><span id='topic+EUR_ld.blocks38'></span>

<h3>Description</h3>

<p>A GRanges object containing the LD block for European ancestry, in hg38 build.
This dataset was obtained from <a href="https://doi.org/10.1101/2022.03.04.483057">doi:10.1101/2022.03.04.483057</a>, in bed format,
then transformed to GRanges.
See manuscript for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EUR_ld.blocks38
</code></pre>


<h3>Format</h3>

<p>A GRanges object containing 1361 ranges
</p>

<dl>
<dt>seqnames</dt><dd><p>chromosome</p>
</dd>
<dt>ranges</dt><dd><p>start and stop positions for the block</p>
</dd>
<dt>strand</dt><dd><p>genomic strand, irrelevant here</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/jmacdon/LDblocks_GRCh38/tree/master/data">https://github.com/jmacdon/LDblocks_GRCh38/tree/master/data</a>
</p>

<hr>
<h2 id='find_file_in_ftp'>Finding a file in an FTP directory
This is an internal function to help <code>gwascat.download</code> find the right file</h2><span id='topic+find_file_in_ftp'></span>

<h3>Description</h3>

<p>Finding a file in an FTP directory
This is an internal function to help <code>gwascat.download</code> find the right file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_file_in_ftp(ftp_address, acc, hm)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_file_in_ftp_+3A_ftp_address">ftp_address</code></td>
<td>
<p>a string. An FTP address provided by <code>gwascat.download</code>.</p>
</td></tr>
<tr><td><code id="find_file_in_ftp_+3A_acc">acc</code></td>
<td>
<p>a string containing the accession for the desired study.</p>
</td></tr>
<tr><td><code id="find_file_in_ftp_+3A_hm">hm</code></td>
<td>
<p>a logical. Should it look in the harmonised directory?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table containing the dataset.
</p>


<h3>Author(s)</h3>

<p>Guillermo Reales
</p>

<hr>
<h2 id='gwascat.download'>Retrieve GWAS summary datasets from GWAS catalog
'<code>gwascat.download</code> takes a PMID from the user and downloads the associated summary statistics datasets published in GWAS catalog</h2><span id='topic+gwascat.download'></span>

<h3>Description</h3>

<p>This function, takes PUBMED ids as an input, searches at the GWAS catalog
for harmonised datasets associated to that, interactively asking the
user to choose if there are more than one, and fetches the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gwascat.download(ID, harmonised = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gwascat.download_+3A_id">ID</code></td>
<td>
<p>a numeric. A PubMed ID (PMID) reference number from a GWAS paper.</p>
</td></tr>
<tr><td><code id="gwascat.download_+3A_harmonised">harmonised</code></td>
<td>
<p>a logical. Should GWAS catalog harmonised files be pursued?
If not available, the function will fall back to non-harmonised</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If multiple files are available for the same study, R will prompt an interactive
dialogue to select a specific file, by number.
</p>


<h3>Value</h3>

<p>a character vector containing the url(s) to the dataset(s).
</p>


<h3>Author(s)</h3>

<p>Guillermo Reales
</p>

<hr>
<h2 id='logsum'>Helper function to sum logs without loss of precision</h2><span id='topic+logsum'></span>

<h3>Description</h3>

<p>Sums logs without loss of precision
This function is verbatim of its namesake in cupcake package (github.com/ollyburren/cupcake/)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logsum(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logsum_+3A_x">x</code></td>
<td>
<p>a vector of logs to sum</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a scalar
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>

<hr>
<h2 id='michailidou19'>Subset of Michailidou BRCA GWAS sumstat dataset.</h2><span id='topic+michailidou19'></span>

<h3>Description</h3>

<p>A data.table containing a subset of <a href="https://doi.org/10.1038/nature24284">doi:10.1038/nature24284</a> breast cancer summary statistic dataset, in hg19 build.
This dataset is freely available in GWAS catalog (see link below). We used &quot;chromosome&quot;, &quot;base_pair_location columns&quot;, removed unnecessary and all-missing columns, and took a random sample of 100,000 SNPs without replacement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>michailidou19
</code></pre>


<h3>Format</h3>

<p>A data.table object containing 100,000 SNPs
</p>

<p>SNPID, CHR, BP, REF, ALT, ALT_FREQ, BETA, SE, P
</p>
<dl>
<dt>SNPID</dt><dd><p>rsids, or SNP ids</p>
</dd>
<dt>CHR</dt><dd><p>chromosome</p>
</dd>
<dt>BP</dt><dd><p>base position, in hg38</p>
</dd>
<dt>REF</dt><dd><p>reference, or non-effect allele</p>
</dd>
<dt>ALT</dt><dd><p>alternative, or effect allele</p>
</dd>
<dt>ALT_FREQ</dt><dd><p>effect allele frequency</p>
</dd>
<dt>BETA</dt><dd><p>beta, log(OR), or effect size</p>
</dd>
<dt>SE</dt><dd><p>standard error of beta</p>
</dd>
<dt>P</dt><dd><p>p-value</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST004001-GCST005000/GCST004988/harmonised/29059683-GCST004988-EFO_0000305-build37.f.tsv.gz">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST004001-GCST005000/GCST004988/harmonised/29059683-GCST004988-EFO_0000305-build37.f.tsv.gz</a>
</p>

<hr>
<h2 id='michailidou38'>Subset of Michailidou BRCA GWAS sumstat dataset.</h2><span id='topic+michailidou38'></span>

<h3>Description</h3>

<p>A data.table containing a subset of <a href="https://doi.org/10.1038/nature24284">doi:10.1038/nature24284</a> breast cancer summary statistic dataset, in hg38 build.
This dataset is freely available in GWAS catalog (see link below). We removed unnecessary and all-missing columns, and rows
with missing data at hm_beta and hm_effect_allele_frequency, and took a random sample of 100,000 SNPs without replacement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>michailidou38
</code></pre>


<h3>Format</h3>

<p>A data.table object containing 100,000 SNPs
</p>

<dl>
<dt>hm_rsid</dt><dd><p>rsids, or SNP ids</p>
</dd>
<dt>hm_chrom</dt><dd><p>chromosome</p>
</dd>
<dt>hm_pos</dt><dd><p>base position, in hg38</p>
</dd>
<dt>hm_other_allele</dt><dd><p>reference, or non-effect allele</p>
</dd>
<dt>hm_effect_allele</dt><dd><p>alternative, or effect allele</p>
</dd>
<dt>hm_beta</dt><dd><p>beta, log(OR), or effect size</p>
</dd>
<dt>hm_effect_allele_frequency</dt><dd><p>effect allele frequency</p>
</dd>
<dt>standard_error</dt><dd><p>standard error of beta</p>
</dd>
<dt>p_value</dt><dd><p>p-value</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST004001-GCST005000/GCST004988/harmonised/29059683-GCST004988-EFO_0000305.h.tsv.gz">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST004001-GCST005000/GCST004988/harmonised/29059683-GCST004988-EFO_0000305.h.tsv.gz</a>
</p>

<hr>
<h2 id='rapidopgs_multi'>Compute PGS from GWAS summary statistics using Bayesian sum of single-effect
(SuSiE) linear regression using z scores</h2><span id='topic+rapidopgs_multi'></span>

<h3>Description</h3>

<p>'<code>rapidopgs_multi</code> computes PGS from a from GWAS summary statistics
using Bayesian sum of single-effect (SuSiE) linear regression using z scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rapidopgs_multi(
  data,
  reference = NULL,
  LDmatrices = NULL,
  N = NULL,
  build = c("hg19", "hg38"),
  trait = c("cc", "quant"),
  ncores = 1,
  alpha.block = 1e-04,
  alpha.snp = 0.01,
  sd.prior = NULL,
  ancestry = "EUR",
  LDblocks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rapidopgs_multi_+3A_data">data</code></td>
<td>
<p>a data.table containing GWAS summary statistic dataset
with all required information.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_reference">reference</code></td>
<td>
<p>a string representing the path to the directory containing
the reference panel (eg. &quot;../ref-data&quot;).</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_ldmatrices">LDmatrices</code></td>
<td>
<p>a string representing the path to the directory containing
the pre-computed LD matrices.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_n">N</code></td>
<td>
<p>a numeric indicating the number of individuals used to generate input
GWAS dataset, or a string indicating the column name containing per-SNP sample size.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_build">build</code></td>
<td>
<p>a string indicating the genome build. 'hg19' and 'hg38' are supported. Note that your LD matrices or reference panel should match the build.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_trait">trait</code></td>
<td>
<p>a string indicating if trait is a case-control (&quot;cc&quot;) or quantitative (&quot;quant&quot;).</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_ncores">ncores</code></td>
<td>
<p>a numeric specifying the number of cores (CPUs) to be used.
If using pre-computed LD matrices, one core is enough for best performance.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_alpha.block">alpha.block</code></td>
<td>
<p>a numeric threshold for minimum P-value in LD blocks.
Blocks with minimum P above <code>alpha.block</code> will be skipped. Default: 1e-4.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_alpha.snp">alpha.snp</code></td>
<td>
<p>a numeric threshold for P-value pruning within LD block.
SNPs with P above <code>alpha.snp</code> will be removed. Default: 0.01.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_sd.prior">sd.prior</code></td>
<td>
<p>the prior specifies that BETA at causal SNPs
follows a centred normal distribution with standard deviation
sd.prior.
If NULL (default) it will be automatically estimated (recommended).</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_ancestry">ancestry</code></td>
<td>
<p>a string indicating the ancestral population (DEFAULT: &quot;EUR&quot;, European).
If using an alternative population, bear in mind that your LD matrices or reference must be from the same population.
You'll also need to provide matching LD.blocks via the LDblocks argument.</p>
</td></tr>
<tr><td><code id="rapidopgs_multi_+3A_ldblocks">LDblocks</code></td>
<td>
<p>a string indicating the path to an alternative LD block file in .RData format. Only required for non-European PGS.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will take a GWAS summary statistic dataset as an input,
will assign LD blocks to it, then use user-provided LD matrices or a preset
reference panel in Plink format to compute LD matrices for each block.
Then SuSiE method will be used to compute posterior probabilities of variants to be causal
and generate PGS weights by multiplying those posteriors by effect sizes (<code class="reqn">\beta</code>).
Unlike <code>rapidopgs_single</code>, this approach will assume one or more causal variants.
</p>
<p>The GWAS summary statistics file to compute PGS using our method must contain
the following minimum columns, with these exact column names:
</p>

<dl>
<dt>CHR</dt><dd><p>Chromosome</p>
</dd>
<dt>BP</dt><dd><p>Base position (in GRCh37/hg19).</p>
</dd>
<dt>REF</dt><dd><p>Reference, or non-effect allele</p>
</dd>
<dt>ALT</dt><dd><p>Alternative, or effect allele, the one <code class="reqn">\beta</code> refers to</p>
</dd>
<dt>BETA</dt><dd><p><code class="reqn">\beta</code> (or log(OR)), or effect sizes</p>
</dd>
<dt>SE</dt><dd><p>standard error of <code class="reqn">\beta</code></p>
</dd>
<dt>P</dt><dd><p>P-value for the association test</p>
</dd>
</dl>

<p>In addition, quantitative traits must have the following extra column:
</p>

<dl>
<dt>ALT_FREQ</dt><dd><p>Minor allele frequency.</p>
</dd>
</dl>

<p>Also, for quantitative traits, sample size must be supplied, either as a number,
or indicating the column name, for per-SNP sample size datasets (see below).
Other columns are allowed, and will be ignored.
</p>
<p>Reference panel should be divided by chromosome, in Plink format.
Both reference panel and summary statistic dataset should be in GRCh37/hg19.
For 1000 Genomes panel, you can use <code>create_1000G</code> function to set it up
automatically.
</p>
<p>If prefer to use LD matrices, you must indicate the path to the directory
where they are stored. They must be in RDS format, named LD_chrZ.rds (where
Z is the 1-22 chromosome number). If you don't have LD matrices already,
we recommend downloading those gently provided by Prive et al., at
<a href="https://figshare.com/articles/dataset/European_LD_reference/13034123">https://figshare.com/articles/dataset/European_LD_reference/13034123</a>.
These matrices were computed using for 1,054,330 HapMap3 variants based on
362,320 European individuals of the UK biobank.
</p>


<h3>Value</h3>

<p>a data.table containing the sumstats dataset with
computed PGS weights.
</p>


<h3>Author(s)</h3>

<p>Guillermo Reales, Chris Wallace
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ss &lt;- data.table(
		CHR=c(4,20,14,2,4,6,6,21,13), 
		BP=c(1479959, 13000913, 29107209, 203573414, 57331393, 11003529, 149256398, 
				25630085, 79166661), 
		REF=c("C","C","C","T","G","C","C","G","T"), 
		ALT=c("A","T","T","A","A","A","T","A","C"), 
		BETA=c(0.012,0.0079,0.0224,0.0033,0.0153,0.058,0.0742,0.001,-0.0131),
		SE=c(0.0099,0.0066,0.0203,0.0171,0.0063,0.0255,0.043,0.0188,0.0074),
		P=c(0.2237,0.2316,0.2682,0.8477,0.01473,0.02298,0.08472,0.9573,0.07535))
PGS &lt;- rapidopgs_multi(ss, reference = "ref-data/", N = 20000, build = "hg19", trait="cc", ncores=5)

## End(Not run)
</code></pre>

<hr>
<h2 id='rapidopgs_single'>Compute PGS from GWAS summary statistics using posteriors from Wakefield's approximate Bayes Factors</h2><span id='topic+rapidopgs_single'></span>

<h3>Description</h3>

<p>'<code>rapidopgs_single</code> computes PGS from a from GWAS summary statistics using posteriors from Wakefield's approximate Bayes Factors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rapidopgs_single(
  data,
  N = NULL,
  trait = c("cc", "quant"),
  build = "hg19",
  pi_i = 1e-04,
  sd.prior = if (trait == "quant") {
     0.15
 } else {
     0.2
 },
  filt_threshold = NULL,
  recalc = TRUE,
  reference = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rapidopgs_single_+3A_data">data</code></td>
<td>
<p>a data.table containing GWAS summary statistic dataset
with all required information.</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_n">N</code></td>
<td>
<p>a scalar representing the sample in the study, or a string indicating
the column name containing it. Required for quantitative traits only.</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_trait">trait</code></td>
<td>
<p>a string specifying if the dataset corresponds to a case-control
(&quot;cc&quot;) or a quantitative trait (&quot;quant&quot;) GWAS. If trait = &quot;quant&quot;, an
ALT_FREQ column is required.</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_build">build</code></td>
<td>
<p>a string containing the genome build of the dataset,
either &quot;hg19&quot; (for hg19/GRCh37) or &quot;hg38&quot; (hg38/GRCh38). DEFAULT
&quot;hg19&quot;.</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_pi_i">pi_i</code></td>
<td>
<p>a scalar representing the prior probability (DEFAULT:
<code class="reqn">1 \times 10^{-4}</code>).</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_sd.prior">sd.prior</code></td>
<td>
<p>the prior specifies that BETA at causal SNPs
follows a centred normal distribution with standard deviation
sd.prior. Sensible and widely used DEFAULTs are 0.2 for case
control traits, and 0.15 * var(trait) for quantitative (selected
if trait == &quot;quant&quot;).</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_filt_threshold">filt_threshold</code></td>
<td>
<p>a scalar indicating the ppi threshold (if
<code>filt_threshold</code> &lt; 1) or the number of top SNPs by absolute
weights (if <code>filt_threshold</code> &gt;= 1) to filter the dataset
after PGS computation. If NULL (DEFAULT), no thresholding will
be applied.</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_recalc">recalc</code></td>
<td>
<p>a logical indicating if weights should be
recalculated after thresholding. Only relevant if <code>filt_threshold</code>
is defined.</p>
</td></tr>
<tr><td><code id="rapidopgs_single_+3A_reference">reference</code></td>
<td>
<p>a string indicating the path of the reference file
SNPs should be filtered and aligned to, see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will take a GWAS summary statistic dataset as an input,
will assign align it to a reference panel file (if provided), then it will assign
SNPs to LD blocks and compute Wakefield's ppi by LD block, then will use it
to generate PGS weights by multiplying those posteriors by effect sizes (<code class="reqn">\beta</code>).
Optionally, it will filter SNPs by a custom filter on ppi and then recalculate weights, to improve accuracy.
</p>
<p>Alternatively, if filt_threshold is larger than one, RapidoPGS will select the top
<code>filt_threshold</code> SNPs by absolute weights (note, not ppi but weights).
</p>
<p>The GWAS summary statistics file to compute PGS using our method must contain the following minimum columns, with these exact column names:
</p>

<dl>
<dt>CHR</dt><dd><p>Chromosome</p>
</dd>
<dt>BP</dt><dd><p>Base position (in GRCh37/hg19 or GRCh38/hg38). If using hg38, use build = &quot;hg38&quot; in parameters</p>
</dd>
<dt>REF</dt><dd><p>Reference, or non-effect allele</p>
</dd>
<dt>ALT</dt><dd><p>Alternative, or effect allele, the one <code class="reqn">\beta</code> refers to</p>
</dd>
<dt>ALT_FREQ</dt><dd><p>Minor/ALT allele frequency in the tested population, or in a close population from a reference panel. Required for Quantitative traits only</p>
</dd>
<dt>BETA</dt><dd><p><code class="reqn">\beta</code> (or log(OR)), or effect sizes</p>
</dd>
<dt>SE</dt><dd><p>standard error of <code class="reqn">\beta</code></p>
</dd>
</dl>

<p>If a reference is provided,  it should have 5 columns: CHR, BP,
SNPID, REF, and ALT. Also, it should be in the same build as
the summary statistics. In both files, column order does not matter.
</p>


<h3>Value</h3>

<p>a data.table containing the formatted sumstats dataset with
computed PGS weights.
</p>


<h3>Author(s)</h3>

<p>Guillermo Reales, Chris Wallace
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sumstats &lt;- data.table(SNPID=c("rs139096444","rs3843766","rs61977545", "rs544733737",
		"rs2177641", "rs183491817", "rs72995775","rs78598863", "rs1411315"), 
		CHR=c(4,20,14,2,4,6,6,21,13), 
		BP=c(1479959, 13000913, 29107209, 203573414, 57331393, 11003529, 149256398, 
				25630085, 79166661), 
		REF=c("C","C","C","T","G","C","C","G","T"), 
		ALT=c("A","T","T","A","A","A","T","A","C"), 
		BETA=c(0.012,0.0079,0.0224,0.0033,0.0153,0.058,0.0742,0.001,-0.0131),
		SE=c(0.0099,0.0066,0.0203,0.0171,0.0063,0.0255,0.043,0.0188,0.0074))

PGS  &lt;- rapidopgs_single(sumstats,  trait = "cc")
</code></pre>

<hr>
<h2 id='sd.prior.est'>Compute Standard deviation prior (SD prior) for quantitative traits
using pre-computed heritability.</h2><span id='topic+sd.prior.est'></span>

<h3>Description</h3>

<p><code>sd.prior.est</code> function will take the dataset as an input, a <code class="reqn">h^2</code>
value obtained from a public repository such as LDhub,
(http://ldsc.broadinstitute.org/ldhub/), sample size and number of variants,
and will provide a sd.prior estimate that can be used to improve prediction
performance of RapidoPGS functions on quantitative traits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sd.prior.est(data, h2, N, pi_i = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sd.prior.est_+3A_data">data</code></td>
<td>
<p>a data.table containing the GWAS summary statistic input dataset.
Must contain SNPID and SE columns.</p>
</td></tr>
<tr><td><code id="sd.prior.est_+3A_h2">h2</code></td>
<td>
<p>a numeric. Heritability estimate or h^2 (See details).</p>
</td></tr>
<tr><td><code id="sd.prior.est_+3A_n">N</code></td>
<td>
<p>a numeric. Sample size of the GWAS input dataset.</p>
</td></tr>
<tr><td><code id="sd.prior.est_+3A_pi_i">pi_i</code></td>
<td>
<p>a numeric. Prior that a given variant is causal. DEFAULT = 1e-4.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guillermo Reales, Elena Vigorito, Chris Wallace
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sumstats &lt;- data.table(SNPID=c("4:1479959","20:13000913","14:29107209","2:203573414",
"4:57331393","6:11003529","6:149256398","21:25630085","13:79166661"), 
		REF=c("C","C","C","T","G","C","C","G","T"), 
		ALT=c("A","T","T","A","A","A","T","A","C"), 
		ALT_FREQ=c(0.2611,0.4482,0.0321,0.0538,0.574,0.0174,0.0084,0.0304,0.7528),
		BETA=c(0.012,0.0079,0.0224,0.0033,0.0153,0.058,0.0742,0.001,-0.0131),
		SE=c(0.0099,0.0066,0.0203,0.0171,0.0063,0.0255,0.043,0.0188,0.0074),
		P=c(0.2237,0.2316,0.2682,0.8477,0.01473,0.02298,0.08472,0.9573,0.07535)) 
sd.prior &lt;- sd.prior.est(sumstats, h2 = 0.2456, N = 45658, pi_i=1e-4)


</code></pre>

<hr>
<h2 id='sdY.est'>Estimate trait variance, internal function</h2><span id='topic+sdY.est'></span>

<h3>Description</h3>

<p>Estimate trait standard deviation given vectors of variance of coefficients,  MAF and sample size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdY.est(vbeta, maf, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sdY.est_+3A_vbeta">vbeta</code></td>
<td>
<p>vector of variance of coefficients</p>
</td></tr>
<tr><td><code id="sdY.est_+3A_maf">maf</code></td>
<td>
<p>vector of MAF (same length as vbeta)</p>
</td></tr>
<tr><td><code id="sdY.est_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate is based on var(beta-hat) = var(Y) / (n * var(X))
var(X) = 2* maf*(1-maf)
so we can estimate var(Y) by regressing n*var(X) against 1/var(beta)
This function is verbatim from its namesake in coloc package (github.com/chr1swallace/coloc/), by Chris Wallace
</p>


<h3>Value</h3>

<p>estimated standard deviation of Y
</p>


<h3>Author(s)</h3>

<p>Chris Wallace
</p>

<hr>
<h2 id='wakefield_pp'>compute posterior probabilities using Wakefield's approximate Bayes Factors
<code>wakefield_pp</code> computes posterior probabilities for a given SNP to be causal for a given SNP under the assumption of a single causal variant.</h2><span id='topic+wakefield_pp'></span>

<h3>Description</h3>

<p>This function was adapted from its namesake in cupcake package (github.com/ollyburren/cupcake/) to no longer require allele frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wakefield_pp(beta, se, pi_i = 1e-04, sd.prior = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wakefield_pp_+3A_beta">beta</code></td>
<td>
<p>a vector of effect sizes (<code class="reqn">\beta</code>) from a quantitative trait GWAS</p>
</td></tr>
<tr><td><code id="wakefield_pp_+3A_se">se</code></td>
<td>
<p>vector of standard errors of effect sizes (<code class="reqn">\beta</code>)</p>
</td></tr>
<tr><td><code id="wakefield_pp_+3A_pi_i">pi_i</code></td>
<td>
<p>a scalar representing the prior probability (DEFAULT <code class="reqn">1 \times 10^{-4}</code>)</p>
</td></tr>
<tr><td><code id="wakefield_pp_+3A_sd.prior">sd.prior</code></td>
<td>
<p>a scalar representing our prior expectation of <code class="reqn">\beta</code> (DEFAULT 0.2).
The method assumes a normal prior on the population log relative risk centred at 0 and the DEFAULT
value sets the variance of this distribution to 0.04, equivalent to a 95\
is in the range of 0.66-1.5 at any causal variant.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of posterior probabilities.
</p>


<h3>Author(s)</h3>

<p>Olly Burren, Chris Wallace, Guillermo Reales
</p>

<hr>
<h2 id='wakefield_pp_quant'>Compute posterior probabilities using Wakefield's approximate Bayes Factors for quantitative traits</h2><span id='topic+wakefield_pp_quant'></span>

<h3>Description</h3>

<p><code>wakefield_pp_quant</code> computes posterior probabilities for a given SNP to be causal for a given SNP under the assumption of a single causal variant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wakefield_pp_quant(beta, se, sdY, sd.prior = 0.15, pi_i = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="wakefield_pp_quant_+3A_beta">beta</code></td>
<td>
<p>a vector of effect sizes (<code class="reqn">\beta</code>) from a quantitative trait GWAS</p>
</td></tr>
<tr><td><code id="wakefield_pp_quant_+3A_se">se</code></td>
<td>
<p>vector of standard errors of effect sizes (<code class="reqn">\beta</code>)</p>
</td></tr>
<tr><td><code id="wakefield_pp_quant_+3A_sdy">sdY</code></td>
<td>
<p>a scalar of the standard deviation given vectors of variance of coefficients,  MAF and sample size. Can be calculated using <code>sdY.est</code></p>
</td></tr>
<tr><td><code id="wakefield_pp_quant_+3A_sd.prior">sd.prior</code></td>
<td>
<p>a scalar representing our prior expectation of <code class="reqn">\beta</code> (DEFAULT 0.15).</p>
</td></tr>
<tr><td><code id="wakefield_pp_quant_+3A_pi_i">pi_i</code></td>
<td>
<p>a scalar representing the prior probability (DEFAULT <code class="reqn">1 \times 10^{-4}</code>)
The method assumes a normal prior on the population log relative risk centred at 0 and the DEFAULT
value sets the variance of this distribution to 0.04, equivalent to a 95\
is in the range of 0.66-1.5 at any causal variant.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was adapted from <code>wakefield_pp</code> in cupcake package (github.com/ollyburren/cupcake/)
</p>


<h3>Value</h3>

<p>a vector of posterior probabilities.
</p>


<h3>Author(s)</h3>

<p>Guillermo Reales, Chris Wallace
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
