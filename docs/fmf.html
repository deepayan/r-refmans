<!DOCTYPE html><html><head><title>Help for package fmf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fmf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#australian'>
<p>Australian Credit Approval</p></a></li>
<li><a href='#class_folds'><p>stratified folds (in classification)                      [ detailed information about class_folds in the FeatureSelection package ]</p></a></li>
<li><a href='#entropy'><p>this function compute entropy</p></a></li>
<li><a href='#fmf'><p>Fast Class Noise Detector with Multi-Factor-Based Learning</p></a></li>
<li><a href='#func_categorical_preds'><p>OPTION to convert categorical features TO either numeric [ if levels more than 32] OR to dummy variables [ if levels less than 32 ]</p></a></li>
<li><a href='#func_shuffle'><p>shuffle data</p></a></li>
<li><a href='#func_tbl'><p>this function returns a table of probabilities for each label</p></a></li>
<li><a href='#func_tbl_dist'><p>this function returns the probabilities in case of classification</p></a></li>
<li><a href='#FUNCTION_weights'><p>this function is used as a kernel-function-identifier [ takes the distances and a weights-kernel (in form of a function) and returns weights ]</p></a></li>
<li><a href='#iris'>
<p>Iris Data Set</p></a></li>
<li><a href='#kernelknn'><p>kernel k-nearest-neighbors</p></a></li>
<li><a href='#normalization'><p>The Max-Min Normalization</p></a></li>
<li><a href='#normalized'><p>this function normalizes the data</p></a></li>
<li><a href='#ozone'>
<p>Ozone Level Detection Data Set</p></a></li>
<li><a href='#plot'><p>PCA Plot of the Noise Score of Each Individual</p></a></li>
<li><a href='#regr_folds'><p>create folds (in regression)                                           [ detailed information about class_folds in the FeatureSelection package ]</p></a></li>
<li><a href='#switch.ops'><p>Arithmetic operations on lists</p></a></li>
<li><a href='#tuning'><p>Tuning For Fast Class Noise Detector with Multi-Factor-Based Learning</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Class Noise Detector with Multi-Factor-Based Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-08-07</td>
</tr>
<tr>
<td>Author:</td>
<td>Wanwan Zheng [aut, cre],
  Mingzhe Jin [aut],
  Lampros Mouselimis [ctb, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Wanwan Zheng &lt;teiwanwan@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A fast class noise detector which provides noise score for each observations. The package takes advantage of 'RcppArmadillo' to speed up the calculation of distances between observations.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>libarmadillo: apt-get install -y libarmadillo-dev
(deb), libblas: apt-get install -y libblas-dev (deb),
liblapack: apt-get install -y liblapack-dev (deb),
libarpack++2: apt-get install -y libarpack++2-dev (deb),
gfortran: apt-get install -y gfortran (deb)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 2.10.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, caret, solitude, kernlab, C50, e1071, FactoMineR, dplyr,
factoextra, ggplot2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr, knitr, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-08-29 04:52:56 UTC; Mjin</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-09-03 07:32:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='australian'>
Australian Credit Approval
</h2><span id='topic+australian'></span>

<h3>Description</h3>

<p>This is the famous Australian Credit Approval dataset, originating from the StatLog project. It concerns credit card applications. 
All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(australian)</code></pre>


<h3>Format</h3>

<p>A data frame with 690 Instances and 15 attributes (including the class attribute, &quot;Class&quot;)
</p>


<h3>Details</h3>

<p>There are 6 numerical and 8 categorical attributes, all normalized to [-1,1]. The original formatting was as follows:
A1: A,B class attribute (formerly: +,-)
A2: 0,1 CATEGORICAL (formerly: a,b)
A3: continuous.
A4: continuous.
A5: 1,2,3 CATEGORICAL (formerly: p,g,gg)
A6: 1, 2,3,4,5, 6,7,8,9,10,11,12,13,14 CATEGORICAL (formerly: ff,d,i,k,j,aa,m,c,w, e, q, r,cc, x)
A7: 1, 2,3, 4,5,6,7,8,9 CATEGORICAL (formerly: ff,dd,j,bb,v,n,o,h,z)
A8: continuous.
A9: 1, 0 CATEGORICAL (formerly: t, f)
A10: 1, 0 CATEGORICAL (formerly: t, f)
A11: continuous.
A12: 1, 0 CATEGORICAL (formerly t, f)
A13: 1, 2, 3 CATEGORICAL (formerly: s, g, p)
A14: continuous.
A15: continuous.
</p>


<h3>Source</h3>

<p>Confidential. Donated by Ross Quinlan
</p>


<h3>References</h3>

<p>[LibSVM] (https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html), UCI - 1987 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(australian)

X = australian[, -1]

y = australian[, 1]
</code></pre>

<hr>
<h2 id='class_folds'>stratified folds (in classification)                      [ detailed information about class_folds in the FeatureSelection package ]</h2><span id='topic+class_folds'></span>

<h3>Description</h3>

<p>this function creates stratified folds in binary and multiclass classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>class_folds(folds, RESP)
</code></pre>

<hr>
<h2 id='entropy'>this function compute entropy</h2><span id='topic+entropy'></span>

<h3>Description</h3>

<p>this function compute entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropy(x)
</code></pre>

<hr>
<h2 id='fmf'>Fast Class Noise Detector with Multi-Factor-Based Learning</h2><span id='topic+fmf'></span><span id='topic+fmf.formula'></span><span id='topic+fmf.default'></span>

<h3>Description</h3>

<p>This function computes the noise score for each observation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmf(x, ...)

## S3 method for class 'formula'
fmf(formula, data, ...)

## Default S3 method:
fmf(
  x,
  knn = 5,
  classColumn = 1,
  boxplot_range = 1,
  iForest = TRUE,
  threads = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fmf_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to other methods.</p>
</td></tr>
<tr><td><code id="fmf_+3A_formula">formula</code></td>
<td>
<p>a formula describing the classification variable and the attributes to be used.</p>
</td></tr>
<tr><td><code id="fmf_+3A_data">data</code>, <code id="fmf_+3A_x">x</code></td>
<td>
<p>data frame containing the tranining dataset to be filtered.</p>
</td></tr>
<tr><td><code id="fmf_+3A_knn">knn</code></td>
<td>
<p>total number of nearest neighbors to be used.The default is 5.</p>
</td></tr>
<tr><td><code id="fmf_+3A_classcolumn">classColumn</code></td>
<td>
<p>positive integer indicating the column which contains the
(factor of) classes. By default, a dataframe built from 'data' using the variables indicated in 'formula' and The first column is the response variable, thus no need to define the classColumn.</p>
</td></tr>
<tr><td><code id="fmf_+3A_boxplot_range">boxplot_range</code></td>
<td>
<p>range of box and whisker diagram. The dafault is 1.</p>
</td></tr>
<tr><td><code id="fmf_+3A_iforest">iForest</code></td>
<td>
<p>compute iForest score or not. The dafault is TRUE.</p>
</td></tr>
<tr><td><code id="fmf_+3A_threads">threads</code></td>
<td>
<p>the number of cores to be used in parallel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>filter</code>, which is a list with four components:
</p>

<ul>
<li> <p><code>cleanData</code> is a data frame containing the filtered dataset.
</p>
</li>
<li> <p><code>remIdx</code> is a vector of integers indicating the indexes for
removed instances (i.e. their row number with respect to the original data frame).
</p>
</li>
<li> <p><code>noise_score</code> is a vector of values indicating the optential of being a noise.
</p>
</li>
<li> <p><code>call</code> contains the original call to the filter.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Wanwan Zheng
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)
out = fmf(Species~.,iris)

</code></pre>

<hr>
<h2 id='func_categorical_preds'>OPTION to convert categorical features TO either numeric [ if levels more than 32] OR to dummy variables [ if levels less than 32 ]</h2><span id='topic+func_categorical_preds'></span>

<h3>Description</h3>

<p>OPTION to convert categorical features TO either numeric [ if levels more than 32] OR to dummy variables [ if levels less than 32 ]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>func_categorical_preds(prepr_categ)
</code></pre>

<hr>
<h2 id='func_shuffle'>shuffle data</h2><span id='topic+func_shuffle'></span>

<h3>Description</h3>

<p>this function shuffles the items of a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>func_shuffle(vec, times = 10)
</code></pre>

<hr>
<h2 id='func_tbl'>this function returns a table of probabilities for each label</h2><span id='topic+func_tbl'></span>

<h3>Description</h3>

<p>this function returns a table of probabilities for each label
</p>


<h3>Usage</h3>

<pre><code class='language-R'>func_tbl(DF, W, labels)
</code></pre>

<hr>
<h2 id='func_tbl_dist'>this function returns the probabilities in case of classification</h2><span id='topic+func_tbl_dist'></span>

<h3>Description</h3>

<p>this function returns the probabilities in case of classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>func_tbl_dist(DF, Levels)
</code></pre>

<hr>
<h2 id='FUNCTION_weights'>this function is used as a kernel-function-identifier [ takes the distances and a weights-kernel (in form of a function) and returns weights ]</h2><span id='topic+FUNCTION_weights'></span>

<h3>Description</h3>

<p>this function is used as a kernel-function-identifier [ takes the distances and a weights-kernel (in form of a function) and returns weights ]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FUNCTION_weights(W_dist_matrix, weights_function, eps = 1e-06)
</code></pre>

<hr>
<h2 id='iris'>
Iris Data Set
</h2><span id='topic+iris'></span>

<h3>Description</h3>

<p>This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda &amp; Hart, for example.) 
The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(iris)</code></pre>


<h3>Format</h3>

<p>A data frame with 150 Instances and 4 attributes (including the class attribute, &quot;Species&quot;)
In this package, the iris dataset has been normalized by the max-min normalization.
</p>


<h3>Details</h3>

<p>Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot; Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to Mathematical Statistics&quot; (John Wiley, NY, 1950). 
</p>
<p>Predicted attribute: class of iris plant. 
</p>
<p>This is an exceedingly simple domain. 
</p>
<p>This data differs from the data presented in Fishers article (identified by Steve Chadwick, spchadwick '@' espeedaz.net ). 
The 35th sample should be: 4.9,3.1,1.5,0.2,&quot;setosa&quot; where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,&quot;setosa&quot; where the errors are in the second and third features. 
</p>


<h3>Source</h3>

<p>Creator: 
</p>
<p>R.A. Fisher 
</p>
<p>Donor: 
</p>
<p>Michael Marshall 
</p>


<h3>References</h3>

<p>https://archive.ics.uci.edu/ml/datasets/iris
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)

X = iris[, -1]

y = iris[, 1]
</code></pre>

<hr>
<h2 id='kernelknn'>kernel k-nearest-neighbors</h2><span id='topic+kernelknn'></span>

<h3>Description</h3>

<p>This function utilizes kernel k nearest neighbors to predict new observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernelknn(
  data,
  TEST_data = NULL,
  y,
  k = 5,
  h = 1,
  method = "euclidean",
  weights_function = NULL,
  regression = FALSE,
  transf_categ_cols = FALSE,
  threads = 1,
  extrema = FALSE,
  Levels = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernelknn_+3A_data">data</code></td>
<td>
<p>a data frame or matrix</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_test_data">TEST_data</code></td>
<td>
<p>a data frame or matrix (it can be also NULL)</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_y">y</code></td>
<td>
<p>a numeric vector (in classification the labels must be numeric from 1:Inf)</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_k">k</code></td>
<td>
<p>an integer specifying the k-nearest-neighbors</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_h">h</code></td>
<td>
<p>the bandwidth (applicable if the weights_function is not NULL, defaults to 1.0)</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_method">method</code></td>
<td>
<p>a string specifying the method. Valid methods are 'euclidean', 'canberra', 'mahalanobis','schi',&quot;pearson_correlation&quot;</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_weights_function">weights_function</code></td>
<td>
<p>there are various ways of specifying the kernel function. See the details section.</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_regression">regression</code></td>
<td>
<p>a boolean (TRUE,FALSE) specifying if regression or classification should be performed</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_transf_categ_cols">transf_categ_cols</code></td>
<td>
<p>a boolean (TRUE, FALSE) specifying if the categorical columns should be converted to numeric or to dummy variables</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_threads">threads</code></td>
<td>
<p>the number of cores to be used in parallel (openmp will be employed)</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_extrema">extrema</code></td>
<td>
<p>if TRUE then the minimum and maximum values from the k-nearest-neighbors will be removed (can be thought as outlier removal)</p>
</td></tr>
<tr><td><code id="kernelknn_+3A_levels">Levels</code></td>
<td>
<p>a numeric vector. In case of classification the unique levels of the response variable are necessary</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a number of arguments and it returns the predicted values. If TEST_data is NULL then the predictions for the train data will be returned, whereas if TEST_data is not NULL then the predictions for the TEST_data will be returned.
There are three possible ways to specify the weights function, 1st option : if the weights_function is NULL then a simple k-nearest-neighbor is performed. 2nd option : the weights_function is one of 'uniform', 'triangular', 'epanechnikov', 'biweight', 'triweight', 'tricube', 'gaussian', 'cosine', 'logistic', 'gaussianSimple', 'silverman', 'inverse', 'exponential'. The 2nd option can be extended by combining kernels from the existing ones (adding or multiplying). For instance, I can multiply the tricube with the gaussian kernel by giving 'tricube_gaussian_MULT' or I can add the previously mentioned kernels by giving 'tricube_gaussian_ADD'. 3rd option : a user defined kernel function
</p>


<h3>Value</h3>

<p>a vector (if regression is TRUE), or a data frame with class probabilities (if regression is FALSE)
</p>


<h3>Author(s)</h3>

<p>Lampros Mouselimis  edit by Wanwan Zheng
</p>

<hr>
<h2 id='normalization'>The Max-Min Normalization</h2><span id='topic+normalization'></span>

<h3>Description</h3>

<p>This function normalizes the data using the max-min normalization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalization(x, margin = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalization_+3A_x">x</code></td>
<td>
<p>the dataset.</p>
</td></tr>
<tr><td><code id="normalization_+3A_margin">margin</code></td>
<td>
<p>data is normalized by row (margin = 1) or by column (margin = 2). The default is 2.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wanwan Zheng
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ozone)
scaled.data = normalization(ozone[,-1])
ozone.scale = data.frame(y = as.character(ozone[,1]), scaled.data[,-1])

</code></pre>

<hr>
<h2 id='normalized'>this function normalizes the data</h2><span id='topic+normalized'></span>

<h3>Description</h3>

<p>this function normalizes the data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalized(x)
</code></pre>

<hr>
<h2 id='ozone'>
Ozone Level Detection Data Set
</h2><span id='topic+ozone'></span>

<h3>Description</h3>

<p>Forecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008.
Discusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods.
</p>
<p>A shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in:
Forecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ozone)</code></pre>


<h3>Format</h3>

<p>A data frame with 2536 Instances and 73 attributes (including the class attribute, &quot;Class&quot;: ozone day, normal day)
</p>


<h3>Details</h3>

<p>The following are specifications for several most important attributes 
that are highly valued by Texas Commission on Environmental Quality (TCEQ). 
More details can be found in the two relevant papers.
</p>
<p>&ndash; O 3 - Local ozone peak prediction
&ndash; Upwind - Upwind ozone background level
&ndash; EmFactor - Precursor emissions related factor
&ndash; Tmax - Maximum temperature in degrees F
&ndash; Tb - Base temperature where net ozone production begins (50 F)
&ndash; SRd - Solar radiation total for the day
&ndash; WSa - Wind speed near sunrise (using 09-12 UTC forecast mode)
&ndash; WSp - Wind speed mid-day (using 15-21 UTC forecast mode) 
</p>


<h3>Source</h3>

<p>Kun Zhang
zhang.kun05 '@' gmail.com
Department of Computer Science, 
Xavier University of Lousiana
</p>
<p>Wei Fan
wei.fan '@' gmail.com
IBM T.J.Watson Research
</p>
<p>XiaoJing Yuan
xyuan '@' uh.edu
Engineering Technology Department, 
College of Technology, University of Houston 
</p>


<h3>References</h3>

<p>https://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ozone)

X = ozone[, -1]

y = ozone[, 1]
</code></pre>

<hr>
<h2 id='plot'>PCA Plot of the Noise Score of Each Individual</h2><span id='topic+plot'></span>

<h3>Description</h3>

<p>This function plots the noise score for each observation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot(
  score,
  data,
  cl,
  geom.ind = "text",
  labelsize = 3,
  geom_point_size = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_score">score</code></td>
<td>
<p>a vector of values indicating the optential of being a noise.</p>
</td></tr>
<tr><td><code id="plot_+3A_data">data</code></td>
<td>
<p>matrix or data frame with no label.</p>
</td></tr>
<tr><td><code id="plot_+3A_cl">cl</code></td>
<td>
<p>factor of true classifications of data set.</p>
</td></tr>
<tr><td><code id="plot_+3A_geom.ind">geom.ind</code></td>
<td>
<p>as geom for observations, which can be set to &quot;text&quot;, &quot;point&quot; and &quot;none&quot;. The default is &quot;text&quot;.</p>
</td></tr>
<tr><td><code id="plot_+3A_labelsize">labelsize</code></td>
<td>
<p>size of geom_text.</p>
</td></tr>
<tr><td><code id="plot_+3A_geom_point_size">geom_point_size</code></td>
<td>
<p>size of geom_point and geom_none.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>optional parameters to be passed to other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an plot of PCA with the noise score of each observation
</p>


<h3>Author(s)</h3>

<p>Wanwan Zheng
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)
out = fmf(Species~.,iris)
plot(out$noise_score, iris[,-1], iris[,1])

</code></pre>

<hr>
<h2 id='regr_folds'>create folds (in regression)                                           [ detailed information about class_folds in the FeatureSelection package ]</h2><span id='topic+regr_folds'></span>

<h3>Description</h3>

<p>this function creates both stratified and non-stratified folds in regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regr_folds(folds, RESP)
</code></pre>

<hr>
<h2 id='switch.ops'>Arithmetic operations on lists</h2><span id='topic+switch.ops'></span>

<h3>Description</h3>

<p>Arithmetic operations on lists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>switch.ops(LST, MODE = "ADD")
</code></pre>

<hr>
<h2 id='tuning'>Tuning For Fast Class Noise Detector with Multi-Factor-Based Learning</h2><span id='topic+tuning'></span><span id='topic+tuning.formula'></span><span id='topic+tuning.default'></span>

<h3>Description</h3>

<p>This function tunes the hyper-parameters the threshold and the k of k-NN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuning(x, ...)

## S3 method for class 'formula'
tuning(formula, data, ...)

## Default S3 method:
tuning(
  x,
  knn_k = seq(3, 7, 2),
  classColumn = 1,
  boxplot_range = seq(0.1, 1.1, 0.2),
  repeats = 10,
  method = "svm",
  iForest = TRUE,
  threads = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuning_+3A_...">...</code></td>
<td>
<p>Optional parameters to be passed to other methods.</p>
</td></tr>
<tr><td><code id="tuning_+3A_formula">formula</code></td>
<td>
<p>a formula describing the classification variable and the attributes to be used.</p>
</td></tr>
<tr><td><code id="tuning_+3A_data">data</code>, <code id="tuning_+3A_x">x</code></td>
<td>
<p>data frame containing the tranining dataset to be filtered.</p>
</td></tr>
<tr><td><code id="tuning_+3A_knn_k">knn_k</code></td>
<td>
<p>range of the total number of nearest neighbors to be used.The default is 3:5.</p>
</td></tr>
<tr><td><code id="tuning_+3A_classcolumn">classColumn</code></td>
<td>
<p>positive integer indicating the column which contains the
(factor of) classes. By default, a dataframe built from 'data' using the variables indicated in 'formula' and The first column is the response variable, thus no need to define the classColumn.</p>
</td></tr>
<tr><td><code id="tuning_+3A_boxplot_range">boxplot_range</code></td>
<td>
<p>range of box and whisker diagram. The default is seq(0.8,1.2,0.1).</p>
</td></tr>
<tr><td><code id="tuning_+3A_repeats">repeats</code></td>
<td>
<p>the number of cross-validation. The default is 10.</p>
</td></tr>
<tr><td><code id="tuning_+3A_method">method</code></td>
<td>
<p>the classifier to be used to compute the accuracy. The valid methods are svm (default) and c50.</p>
</td></tr>
<tr><td><code id="tuning_+3A_iforest">iForest</code></td>
<td>
<p>compute iForest score or not. The dafault is TRUE.</p>
</td></tr>
<tr><td><code id="tuning_+3A_threads">threads</code></td>
<td>
<p>the number of cores to be used in parallel</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>filter</code>, which is a list with two components:
</p>

<ul>
<li> <p><code>summary</code> is the a vector of values when different hyper-parameter is set.
</p>
</li>
<li> <p><code>call</code> contains the original call to the filter.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Wanwan Zheng
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)
out = tuning(Species~.,iris)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
