<!DOCTYPE html><html lang="en"><head><title>Help for package infer</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {infer}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#infer'><p>infer: a grammar for statistical inference</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe</p></a></li>
<li><a href='#assume'><p>Define a theoretical distribution</p></a></li>
<li><a href='#calculate'><p>Calculate summary statistics</p></a></li>
<li><a href='#chisq_stat'><p>Tidy chi-squared test statistic</p></a></li>
<li><a href='#chisq_test'><p>Tidy chi-squared test</p></a></li>
<li><a href='#deprecated'><p>Deprecated functions and objects</p></a></li>
<li><a href='#fit.infer'><p>Fit linear models to infer objects</p></a></li>
<li><a href='#generate'><p>Generate resamples, permutations, or simulations</p></a></li>
<li><a href='#get_confidence_interval'><p>Compute confidence interval</p></a></li>
<li><a href='#get_p_value'><p>Compute p-value</p></a></li>
<li><a href='#gss'><p>Subset of data from the General Social Survey (GSS).</p></a></li>
<li><a href='#hypothesize'><p>Declare a null hypothesis</p></a></li>
<li><a href='#observe'><p>Calculate observed statistics</p></a></li>
<li><a href='#print.infer'><p>Print methods</p></a></li>
<li><a href='#prop_test'><p>Tidy proportion test</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#rep_sample_n'><p>Perform repeated sampling</p></a></li>
<li><a href='#shade_confidence_interval'><p>Add information about confidence interval</p></a></li>
<li><a href='#shade_p_value'><p>Shade histogram area beyond an observed statistic</p></a></li>
<li><a href='#specify'><p>Specify response and explanatory variables</p></a></li>
<li><a href='#t_stat'><p>Tidy t-test statistic</p></a></li>
<li><a href='#t_test'><p>Tidy t-test</p></a></li>
<li><a href='#visualize'><p>Visualize statistical inference</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tidy Statistical Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.7</td>
</tr>
<tr>
<td>Description:</td>
<td>The objective of this package is to perform inference using
    an expressive statistical grammar that coheres with the tidy design
    framework.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tidymodels/infer">https://github.com/tidymodels/infer</a>, <a href="https://infer.tidymodels.org/">https://infer.tidymodels.org/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/infer/issues">https://github.com/tidymodels/infer/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>broom, cli, dplyr (&ge; 0.7.0), generics, ggplot2, glue (&ge;
1.3.0), grDevices, lifecycle, magrittr, methods, patchwork,
purrr, rlang (&ge; 0.2.0), tibble, tidyr, vctrs</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, devtools (&ge; 1.12.0), fs, knitr, nycflights13, parsnip,
rmarkdown, stringr, testthat (&ge; 3.0.0), vdiffr (&ge; 1.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-25 18:25:40 UTC; simoncouch</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrew Bray [aut],
  Chester Ismay <a href="https://orcid.org/0000-0003-2820-2547"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Evgeni Chasnovski <a href="https://orcid.org/0000-0002-1617-4019"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Simon Couch <a href="https://orcid.org/0000-0001-5676-5107"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Ben Baumer <a href="https://orcid.org/0000-0002-3279-0516"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Mine Cetinkaya-Rundel
    <a href="https://orcid.org/0000-0001-6452-2420"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Ted Laderas <a href="https://orcid.org/0000-0002-6207-7068"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Nick Solomon [ctb],
  Johanna Hardin [ctb],
  Albert Y. Kim <a href="https://orcid.org/0000-0001-7824-306X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Neal Fultz [ctb],
  Doug Friedman [ctb],
  Richie Cotton <a href="https://orcid.org/0000-0003-2504-802X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Brian Fannin [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Simon Couch &lt;simon.couch@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-25 21:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='infer'>infer: a grammar for statistical inference</h2><span id='topic+infer-package'></span><span id='topic+infer'></span>

<h3>Description</h3>

<p>The objective of this package is to perform statistical inference using a
grammar that illustrates the underlying concepts and a format that coheres
with the tidyverse.
</p>


<h3>Details</h3>

<p>For an overview of how to use the core functionality, see <code>vignette("infer")</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Simon Couch <a href="mailto:simon.couch@posit.co">simon.couch@posit.co</a> (<a href="https://orcid.org/0000-0001-5676-5107">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Andrew Bray <a href="mailto:abray@reed.edu">abray@reed.edu</a>
</p>
</li>
<li><p> Chester Ismay <a href="mailto:chester.ismay@gmail.com">chester.ismay@gmail.com</a> (<a href="https://orcid.org/0000-0003-2820-2547">ORCID</a>)
</p>
</li>
<li><p> Evgeni Chasnovski <a href="mailto:evgeni.chasnovski@gmail.com">evgeni.chasnovski@gmail.com</a> (<a href="https://orcid.org/0000-0002-1617-4019">ORCID</a>)
</p>
</li>
<li><p> Ben Baumer <a href="mailto:ben.baumer@gmail.com">ben.baumer@gmail.com</a> (<a href="https://orcid.org/0000-0002-3279-0516">ORCID</a>)
</p>
</li>
<li><p> Mine Cetinkaya-Rundel <a href="mailto:mine@stat.duke.edu">mine@stat.duke.edu</a> (<a href="https://orcid.org/0000-0001-6452-2420">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Ted Laderas <a href="mailto:tedladeras@gmail.com">tedladeras@gmail.com</a> (<a href="https://orcid.org/0000-0002-6207-7068">ORCID</a>) [contributor]
</p>
</li>
<li><p> Nick Solomon <a href="mailto:nick.solomon@datacamp.com">nick.solomon@datacamp.com</a> [contributor]
</p>
</li>
<li><p> Johanna Hardin <a href="mailto:Jo.Hardin@pomona.edu">Jo.Hardin@pomona.edu</a> [contributor]
</p>
</li>
<li><p> Albert Y. Kim <a href="mailto:albert.ys.kim@gmail.com">albert.ys.kim@gmail.com</a> (<a href="https://orcid.org/0000-0001-7824-306X">ORCID</a>) [contributor]
</p>
</li>
<li><p> Neal Fultz <a href="mailto:nfultz@gmail.com">nfultz@gmail.com</a> [contributor]
</p>
</li>
<li><p> Doug Friedman <a href="mailto:doug.nhp@gmail.com">doug.nhp@gmail.com</a> [contributor]
</p>
</li>
<li><p> Richie Cotton <a href="mailto:richie@datacamp.com">richie@datacamp.com</a> (<a href="https://orcid.org/0000-0003-2504-802X">ORCID</a>) [contributor]
</p>
</li>
<li><p> Brian Fannin <a href="mailto:captain@pirategrunt.com">captain@pirategrunt.com</a> [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tidymodels/infer">https://github.com/tidymodels/infer</a>
</p>
</li>
<li> <p><a href="https://infer.tidymodels.org/">https://infer.tidymodels.org/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/infer/issues">https://github.com/tidymodels/infer/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>Like {dplyr}, {infer} also uses the pipe (<code>%&gt;%</code>) function
from <code>magrittr</code> to turn function composition into a series of
iterative statements.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code>, <code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>Inference functions and the initial data frame.</p>
</td></tr>
</table>

<hr>
<h2 id='assume'>Define a theoretical distribution</h2><span id='topic+assume'></span>

<h3>Description</h3>

<p>This function allows the user to define a null distribution based on
theoretical methods. In many infer pipelines, <code>assume()</code> can be
used in place of <code><a href="#topic+generate">generate()</a></code> and <code><a href="#topic+calculate">calculate()</a></code> to create a null
distribution. Rather than outputting a data frame containing a
distribution of test statistics calculated from resamples of the observed
data, <code>assume()</code> outputs a more abstract type of object just containing
the distributional details supplied in the <code>distribution</code> and <code>df</code> arguments.
However, <code>assume()</code> output can be passed to <code><a href="#topic+visualize">visualize()</a></code>, <code><a href="#topic+get_p_value">get_p_value()</a></code>,
and <code><a href="#topic+get_confidence_interval">get_confidence_interval()</a></code> in the same way that simulation-based
distributions can.
</p>
<p>To define a theoretical null distribution (for use in hypothesis testing),
be sure to provide a null hypothesis via <code><a href="#topic+hypothesize">hypothesize()</a></code>. To define a
theoretical sampling distribution (for use in confidence intervals),
provide the output of <code><a href="#topic+specify">specify()</a></code>. Sampling distributions (only
implemented for <code>t</code> and <code>z</code>) lie on the scale of the data, and will be
recentered and rescaled to match the corresponding <code>stat</code> given in
<code><a href="#topic+calculate">calculate()</a></code> to calculate the observed statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assume(x, distribution, df = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assume_+3A_x">x</code></td>
<td>
<p>The output of <code><a href="#topic+specify">specify()</a></code> or <code><a href="#topic+hypothesize">hypothesize()</a></code>, giving the
observed data, variable(s) of interest, and (optionally) null hypothesis.</p>
</td></tr>
<tr><td><code id="assume_+3A_distribution">distribution</code></td>
<td>
<p>The distribution in question, as a string. One of
<code>"F"</code>, <code>"Chisq"</code>, <code>"t"</code>, or <code>"z"</code>.</p>
</td></tr>
<tr><td><code id="assume_+3A_df">df</code></td>
<td>
<p>Optional. The degrees of freedom parameter(s) for the <code>distribution</code>
supplied, as a numeric vector. For <code>distribution = "F"</code>, this should have
length two (e.g. <code>c(10, 3)</code>). For <code>distribution = "Chisq"</code> or
<code>distribution = "t"</code>, this should have length one. For
<code>distribution = "z"</code>, this argument is not required. The package
will supply a message if the supplied <code>df</code> argument is different from
recognized values. See the Details section below for more information.</p>
</td></tr>
<tr><td><code id="assume_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the assumption being expressed here, for use in theory-based
inference, only extends to <em>distributional</em> assumptions: the null
distribution in question and its parameters. Statistical inference with
infer, whether carried out via simulation (i.e. based on pipelines
using <code><a href="#topic+generate">generate()</a></code> and <code><a href="#topic+calculate">calculate()</a></code>) or theory (i.e. with <code>assume()</code>),
always involves the condition that observations are independent of
each other.
</p>
<p><code>infer</code> only supports theoretical tests on one or two means via the
<code>t</code> distribution and one or two proportions via the <code>z</code>.
</p>
<p>For tests comparing two means, if <code>n1</code> is the group size for one level of
the explanatory variable, and <code>n2</code> is that for the other level, <code>infer</code>
will recognize the following degrees of freedom (<code>df</code>) arguments:
</p>

<ul>
<li> <p><code>min(n1 - 1, n2 - 1)</code>
</p>
</li>
<li> <p><code>n1 + n2 - 2</code>
</p>
</li>
<li><p> The <code>"parameter"</code> entry of the analogous <code>stats::t.test()</code> call
</p>
</li>
<li><p> The <code>"parameter"</code> entry of the analogous <code>stats::t.test()</code> call with <code>var.equal = TRUE</code>
</p>
</li></ul>

<p>By default, the package will use the <code>"parameter"</code> entry of the analogous
<code>stats::t.test()</code> call with <code>var.equal = FALSE</code> (the default).
</p>


<h3>Value</h3>

<p>An infer theoretical distribution that can be passed to helpers
like <code><a href="#topic+visualize">visualize()</a></code>, <code><a href="#topic+get_p_value">get_p_value()</a></code>, and <code><a href="#topic+get_confidence_interval">get_confidence_interval()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># construct theoretical distributions ---------------------------------

# F distribution
# with the `partyid` explanatory variable
gss %&gt;%
  specify(age ~ partyid) %&gt;%
  assume(distribution = "F")

# Chi-squared goodness of fit distribution
# on the `finrela` variable
gss %&gt;%
  specify(response = finrela) %&gt;%
  hypothesize(null = "point",
              p = c("far below average" = 1/6,
                    "below average" = 1/6,
                    "average" = 1/6,
                    "above average" = 1/6,
                    "far above average" = 1/6,
                    "DK" = 1/6)) %&gt;%
  assume("Chisq")

# Chi-squared test of independence
# on the `finrela` and `sex` variables
gss %&gt;%
  specify(formula = finrela ~ sex) %&gt;%
  assume(distribution = "Chisq")

# T distribution
gss %&gt;%
  specify(age ~ college) %&gt;%
  assume("t")

# Z distribution
gss %&gt;%
  specify(response = sex, success = "female") %&gt;%
  assume("z")

## Not run: 
# each of these distributions can be passed to infer helper
# functions alongside observed statistics!

# for example, a 1-sample t-test -------------------------------------

# calculate the observed statistic
obs_stat &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  calculate(stat = "t")

# construct a null distribution
null_dist &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  assume("t")

# juxtapose them visually
visualize(null_dist) +
  shade_p_value(obs_stat, direction = "both")

# calculate a p-value
get_p_value(null_dist, obs_stat, direction = "both")

# or, an F test ------------------------------------------------------

# calculate the observed statistic
obs_stat &lt;- gss %&gt;%
  specify(age ~ partyid) %&gt;%
  hypothesize(null = "independence") %&gt;%
  calculate(stat = "F")

# construct a null distribution
null_dist &lt;- gss %&gt;%
  specify(age ~ partyid) %&gt;%
  assume(distribution = "F")

# juxtapose them visually
visualize(null_dist) +
  shade_p_value(obs_stat, direction = "both")

# calculate a p-value
get_p_value(null_dist, obs_stat, direction = "both")

## End(Not run)

</code></pre>

<hr>
<h2 id='calculate'>Calculate summary statistics</h2><span id='topic+calculate'></span>

<h3>Description</h3>

<p>Given the output of <code><a href="#topic+specify">specify()</a></code> and/or <code><a href="#topic+hypothesize">hypothesize()</a></code>, this function will
return the observed statistic specified with the <code>stat</code> argument. Some test
statistics, such as <code>Chisq</code>, <code>t</code>, and <code>z</code>, require a null hypothesis. If
provided the output of <code><a href="#topic+generate">generate()</a></code>, the function will calculate the
supplied <code>stat</code> for each <code>replicate</code>.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate(
  x,
  stat = c("mean", "median", "sum", "sd", "prop", "count", "diff in means",
    "diff in medians", "diff in props", "Chisq", "F", "slope", "correlation", "t", "z",
    "ratio of props", "odds ratio", "ratio of means"),
  order = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate_+3A_x">x</code></td>
<td>
<p>The output from <code><a href="#topic+generate">generate()</a></code> for computation-based inference or the
output from <code><a href="#topic+hypothesize">hypothesize()</a></code> piped in to here for theory-based inference.</p>
</td></tr>
<tr><td><code id="calculate_+3A_stat">stat</code></td>
<td>
<p>A string giving the type of the statistic to calculate. Current
options include <code>"mean"</code>, <code>"median"</code>, <code>"sum"</code>, <code>"sd"</code>, <code>"prop"</code>, <code>"count"</code>,
<code>"diff in means"</code>, <code>"diff in medians"</code>, <code>"diff in props"</code>, <code>"Chisq"</code> (or
<code>"chisq"</code>), <code>"F"</code> (or <code>"f"</code>), <code>"t"</code>, <code>"z"</code>, <code>"ratio of props"</code>, <code>"slope"</code>,
<code>"odds ratio"</code>, <code>"ratio of means"</code>, and <code>"correlation"</code>. <code>infer</code> only
supports theoretical tests on one or two means via the <code>"t"</code> distribution
and one or two proportions via the <code>"z"</code>.</p>
</td></tr>
<tr><td><code id="calculate_+3A_order">order</code></td>
<td>
<p>A string vector of specifying the order in which the levels of
the explanatory variable should be ordered for subtraction (or division
for ratio-based statistics), where <code>order = c("first", "second")</code> means
<code>("first" - "second")</code>, or the analogue for ratios. Needed for inference on
difference in means, medians, proportions, ratios, t, and z statistics.</p>
</td></tr>
<tr><td><code id="calculate_+3A_...">...</code></td>
<td>
<p>To pass options like <code>na.rm = TRUE</code> into functions like
<a href="base.html#topic+mean">mean()</a>, <a href="stats.html#topic+sd">sd()</a>, etc. Can also be used to
supply hypothesized null values for the <code>"t"</code> statistic or additional
arguments to <code><a href="stats.html#topic+chisq.test">stats::chisq.test()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing a <code>stat</code> column of calculated statistics.
</p>


<h3>Missing levels in small samples</h3>

<p>In some cases, when bootstrapping with small samples, some generated
bootstrap samples will have only one level of the explanatory variable
present. For some test statistics, the calculated statistic in these
cases will be NaN. The package will omit non-finite values from
visualizations (with a warning) and raise an error in p-value calculations.
</p>


<h3>Reproducibility</h3>

<p>When using the infer package for research, or in other cases when exact
reproducibility is a priority, be sure the set the seed for R’s random
number generator. infer will respect the random seed specified in the
<code>set.seed()</code> function, returning the same result when <code>generate()</code>ing
data given an identical seed. For instance, we can calculate the
difference in mean <code>age</code> by <code>college</code> degree status using the <code>gss</code>
dataset from 10 versions of the <code>gss</code> resampled with permutation using
the following code.
</p>
<div class="sourceCode r"><pre>set.seed(1)

gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 5, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))
</pre></div>
<div class="sourceCode"><pre>## Response: age (numeric)
## Explanatory: college (factor)
## Null Hypothesis: independence
## # A tibble: 5 x 2
##   replicate   stat
##       &lt;int&gt;  &lt;dbl&gt;
## 1         1 -0.531
## 2         2 -2.35 
## 3         3  0.764
## 4         4  0.280
## 5         5  0.350
</pre></div>
<p>Setting the seed to the same value again and rerunning the same code
will produce the same result.
</p>
<div class="sourceCode r"><pre># set the seed
set.seed(1)

gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 5, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))
</pre></div>
<div class="sourceCode"><pre>## Response: age (numeric)
## Explanatory: college (factor)
## Null Hypothesis: independence
## # A tibble: 5 x 2
##   replicate   stat
##       &lt;int&gt;  &lt;dbl&gt;
## 1         1 -0.531
## 2         2 -2.35 
## 3         3  0.764
## 4         4  0.280
## 5         5  0.350
</pre></div>
<p>Please keep this in mind when writing infer code that utilizes
resampling with <code>generate()</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+visualize">visualize()</a></code>, <code><a href="#topic+get_p_value">get_p_value()</a></code>, and <code><a href="#topic+get_confidence_interval">get_confidence_interval()</a></code>
to extract value from this function's outputs.
</p>
<p>Other core functions: 
<code><a href="#topic+generate">generate</a>()</code>,
<code><a href="#topic+hypothesize">hypothesize</a>()</code>,
<code><a href="#topic+specify">specify</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# calculate a null distribution of hours worked per week under
# the null hypothesis that the mean is 40
gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  generate(reps = 200, type = "bootstrap") %&gt;%
  calculate(stat = "mean")

# calculate the corresponding observed statistic
gss %&gt;%
  specify(response = hours) %&gt;%
  calculate(stat = "mean")

# calculate a null distribution assuming independence between age
# of respondent and whether they have a college degree
gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 200, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))

# calculate the corresponding observed statistic
gss %&gt;%
  specify(age ~ college) %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))

# some statistics require a null hypothesis
 gss %&gt;%
   specify(response = hours) %&gt;%
   hypothesize(null = "point", mu = 40) %&gt;%
   calculate(stat = "t")

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='chisq_stat'>Tidy chi-squared test statistic</h2><span id='topic+chisq_stat'></span>

<h3>Description</h3>

<p>@description
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq_stat(x, formula, response = NULL, explanatory = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisq_stat_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="chisq_stat_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="chisq_stat_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="chisq_stat_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="chisq_stat_+3A_...">...</code></td>
<td>
<p>Additional arguments for <a href="stats.html#topic+chisq.test">chisq.test()</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A shortcut wrapper function to get the observed test statistic for a chisq
test. Uses <a href="stats.html#topic+chisq.test">chisq.test()</a>, which applies a continuity
correction. This function has been deprecated in favor of the more
general <code><a href="#topic+observe">observe()</a></code>.
</p>


<h3>See Also</h3>

<p>Other wrapper functions: 
<code><a href="#topic+chisq_test">chisq_test</a>()</code>,
<code><a href="#topic+observe">observe</a>()</code>,
<code><a href="#topic+prop_test">prop_test</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>,
<code><a href="#topic+t_test">t_test</a>()</code>
</p>
<p>Other functions for calculating observed statistics: 
<code><a href="#topic+observe">observe</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># chi-squared test statistic for test of independence
# of college completion status depending and one's
# self-identified income class
chisq_stat(gss, college ~ finrela)

# chi-squared test statistic for a goodness of fit
# test on whether self-identified income class
# follows a uniform distribution
chisq_stat(gss,
           response = finrela,
           p = c("far below average" = 1/6,
                 "below average" = 1/6,
                 "average" = 1/6,
                 "above average" = 1/6,
                 "far above average" = 1/6,
                 "DK" = 1/6))

</code></pre>

<hr>
<h2 id='chisq_test'>Tidy chi-squared test</h2><span id='topic+chisq_test'></span>

<h3>Description</h3>

<p>A tidier version of <a href="stats.html#topic+chisq.test">chisq.test()</a> for goodness of fit
tests and tests of independence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq_test(x, formula, response = NULL, explanatory = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisq_test_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="chisq_test_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="chisq_test_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="chisq_test_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="chisq_test_+3A_...">...</code></td>
<td>
<p>Additional arguments for <a href="stats.html#topic+chisq.test">chisq.test()</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other wrapper functions: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+observe">observe</a>()</code>,
<code><a href="#topic+prop_test">prop_test</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>,
<code><a href="#topic+t_test">t_test</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># chi-squared test of independence for college completion
# status depending on one's self-identified income class
chisq_test(gss, college ~ finrela)

# chi-squared goodness of fit test on whether self-identified
# income class follows a uniform distribution
chisq_test(gss,
           response = finrela,
           p = c("far below average" = 1/6,
                 "below average" = 1/6,
                 "average" = 1/6,
                 "above average" = 1/6,
                 "far above average" = 1/6,
                 "DK" = 1/6))

</code></pre>

<hr>
<h2 id='deprecated'>Deprecated functions and objects</h2><span id='topic+deprecated'></span><span id='topic+conf_int'></span><span id='topic+p_value'></span>

<h3>Description</h3>

<p>These functions and objects should no longer be used. They will be removed
in a future release of infer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf_int(x, level = 0.95, type = "percentile", point_estimate = NULL)

p_value(x, obs_stat, direction)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deprecated_+3A_x">x</code></td>
<td>
<p>See the non-deprecated function.</p>
</td></tr>
<tr><td><code id="deprecated_+3A_level">level</code></td>
<td>
<p>See the non-deprecated function.</p>
</td></tr>
<tr><td><code id="deprecated_+3A_type">type</code></td>
<td>
<p>See the non-deprecated function.</p>
</td></tr>
<tr><td><code id="deprecated_+3A_point_estimate">point_estimate</code></td>
<td>
<p>See the non-deprecated function.</p>
</td></tr>
<tr><td><code id="deprecated_+3A_obs_stat">obs_stat</code></td>
<td>
<p>See the non-deprecated function.</p>
</td></tr>
<tr><td><code id="deprecated_+3A_direction">direction</code></td>
<td>
<p>See the non-deprecated function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+get_p_value">get_p_value()</a></code>, <code><a href="#topic+get_confidence_interval">get_confidence_interval()</a></code>, <code><a href="#topic+generate">generate()</a></code>
</p>

<hr>
<h2 id='fit.infer'>Fit linear models to infer objects</h2><span id='topic+fit.infer'></span>

<h3>Description</h3>

<p>Given the output of an infer core function, this function will fit
a linear model using <code><a href="stats.html#topic+glm">stats::glm()</a></code> according to the formula and data supplied
earlier in the pipeline. If passed the output of <code><a href="#topic+specify">specify()</a></code> or
<code><a href="#topic+hypothesize">hypothesize()</a></code>, the function will fit one model. If passed the output
of <code><a href="#topic+generate">generate()</a></code>, it will fit a model to each data resample, denoted in
the <code>replicate</code> column. The family of the fitted model depends on the type
of the response variable. If the response is numeric, <code>fit()</code> will use
<code>family = "gaussian"</code> (linear regression). If the response is a 2-level
factor or character, <code>fit()</code> will use <code>family = "binomial"</code> (logistic
regression). To fit character or factor response variables with more than
two levels, we recommend <code><a href="parsnip.html#topic+multinom_reg">parsnip::multinom_reg()</a></code>.
</p>
<p>infer provides a fit &quot;method&quot; for infer objects, which is a way of carrying
out model fitting as applied to infer output. The &quot;generic,&quot; imported from
the generics package and re-exported from this package, provides the
general form of <code>fit()</code> that points to infer's method when called on an
infer object. That generic is also documented here.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'infer'
fit(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.infer_+3A_object">object</code></td>
<td>
<p>Output from an infer function&mdash;likely <code><a href="#topic+generate">generate()</a></code> or
<code><a href="#topic+specify">specify()</a></code>&mdash;which specifies the formula and data to fit a model to.</p>
</td></tr>
<tr><td><code id="fit.infer_+3A_...">...</code></td>
<td>
<p>Any optional arguments to pass along to the model fitting
function. See <code><a href="stats.html#topic+glm">stats::glm()</a></code> for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Randomization-based statistical inference with multiple explanatory
variables requires careful consideration of the null hypothesis in question
and its implications for permutation procedures. Inference for partial
regression coefficients via the permutation method implemented in
<code><a href="#topic+generate">generate()</a></code> for multiple explanatory variables, consistent with its meaning
elsewhere in the package, is subject to additional distributional assumptions
beyond those required for one explanatory variable. Namely, the distribution
of the response variable must be similar to the distribution of the errors
under the null hypothesis' specification of a fixed effect of the explanatory
variables. (This null hypothesis is reflected in the <code>variables</code> argument to
<code><a href="#topic+generate">generate()</a></code>. By default, all of the explanatory variables are treated
as fixed.) A general rule of thumb here is, if there are large outliers
in the distributions of any of the explanatory variables, this distributional
assumption will not be satisfied; when the response variable is permuted,
the (presumably outlying) value of the response will no longer be paired
with the outlier in the explanatory variable, causing an outsize effect
on the resulting slope coefficient for that explanatory variable.
</p>
<p>More sophisticated methods that are outside of the scope of this package
requiring fewer&mdash;or less strict&mdash;distributional assumptions
exist. For an overview, see &quot;Permutation tests for univariate or
multivariate analysis of variance and regression&quot; (Marti J. Anderson,
2001), <a href="https://doi.org/10.1139/cjfas-58-3-626">doi:10.1139/cjfas-58-3-626</a>.
</p>


<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble">tibble</a> containing the following columns:
</p>

<ul>
<li> <p><code>replicate</code>: Only supplied if the input object had been previously
passed to <code><a href="#topic+generate">generate()</a></code>. A number corresponding to which resample of the
original data set the model was fitted to.
</p>
</li>
<li> <p><code>term</code>: The explanatory variable (or intercept) in question.
</p>
</li>
<li> <p><code>estimate</code>: The model coefficient for the given resample (<code>replicate</code>) and
explanatory variable (<code>term</code>).
</p>
</li></ul>



<h3>Reproducibility</h3>

<p>When using the infer package for research, or in other cases when exact
reproducibility is a priority, be sure the set the seed for R’s random
number generator. infer will respect the random seed specified in the
<code>set.seed()</code> function, returning the same result when <code>generate()</code>ing
data given an identical seed. For instance, we can calculate the
difference in mean <code>age</code> by <code>college</code> degree status using the <code>gss</code>
dataset from 10 versions of the <code>gss</code> resampled with permutation using
the following code.
</p>
<div class="sourceCode r"><pre>set.seed(1)

gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 5, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))
</pre></div>
<div class="sourceCode"><pre>## Response: age (numeric)
## Explanatory: college (factor)
## Null Hypothesis: independence
## # A tibble: 5 x 2
##   replicate   stat
##       &lt;int&gt;  &lt;dbl&gt;
## 1         1 -0.531
## 2         2 -2.35 
## 3         3  0.764
## 4         4  0.280
## 5         5  0.350
</pre></div>
<p>Setting the seed to the same value again and rerunning the same code
will produce the same result.
</p>
<div class="sourceCode r"><pre># set the seed
set.seed(1)

gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 5, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))
</pre></div>
<div class="sourceCode"><pre>## Response: age (numeric)
## Explanatory: college (factor)
## Null Hypothesis: independence
## # A tibble: 5 x 2
##   replicate   stat
##       &lt;int&gt;  &lt;dbl&gt;
## 1         1 -0.531
## 2         2 -2.35 
## 3         3  0.764
## 4         4  0.280
## 5         5  0.350
</pre></div>
<p>Please keep this in mind when writing infer code that utilizes
resampling with <code>generate()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># fit a linear model predicting number of hours worked per
# week using respondent age and degree status.
observed_fit &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  fit()

observed_fit

# fit 100 models to resamples of the gss dataset, where the response
# `hours` is permuted in each. note that this code is the same as
# the above except for the addition of the `generate` step.
null_fits &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 100, type = "permute") %&gt;%
  fit()

null_fits

# for logistic regression, just supply a binary response variable!
# (this can also be made explicit via the `family` argument in ...)
gss %&gt;%
  specify(college ~ age + hours) %&gt;%
  fit()

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='generate'>Generate resamples, permutations, or simulations</h2><span id='topic+generate'></span>

<h3>Description</h3>

<p>Generation creates a simulated distribution from <code>specify()</code>.
In the context of confidence intervals, this is a bootstrap distribution
based on the result of <code>specify()</code>. In the context of hypothesis testing,
this is a null distribution based on the result of <code>specify()</code> and
<code style="white-space: pre;">&#8288;hypothesize().&#8288;</code>
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate(x, reps = 1, type = NULL, variables = !!response_expr(x), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="generate_+3A_reps">reps</code></td>
<td>
<p>The number of resamples to generate.</p>
</td></tr>
<tr><td><code id="generate_+3A_type">type</code></td>
<td>
<p>The method used to generate resamples of the observed
data reflecting the null hypothesis. Currently one of
<code>"bootstrap"</code>, <code>"permute"</code>, or <code>"draw"</code> (see below).</p>
</td></tr>
<tr><td><code id="generate_+3A_variables">variables</code></td>
<td>
<p>If <code>type = "permute"</code>, a set of unquoted column names in the
data to permute (independently of each other). Defaults to only the
response variable. Note that any derived effects that depend on these
columns (e.g., interaction effects) will also be affected.</p>
</td></tr>
<tr><td><code id="generate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing <code>reps</code> generated datasets, indicated by the
<code>replicate</code> column.
</p>


<h3>Generation Types</h3>

<p>The <code>type</code> argument determines the method used to create the null
distribution.
</p>

<ul>
<li> <p><code>bootstrap</code>: A bootstrap sample will be drawn for each replicate,
where a sample of size equal to the input sample size is drawn (with
replacement) from the input sample data.
</p>
</li>
<li> <p><code>permute</code>: For each replicate, each input value will be randomly
reassigned (without replacement) to a new output value in the sample.
</p>
</li>
<li> <p><code>draw</code>: A value will be sampled from a theoretical distribution
with parameter <code>p</code> specified in <code><a href="#topic+hypothesize">hypothesize()</a></code> for each replicate. This
option is currently only applicable for testing on one proportion. This
generation type was previously called <code>"simulate"</code>, which has been
superseded.
</p>
</li></ul>



<h3>Reproducibility</h3>

<p>When using the infer package for research, or in other cases when exact
reproducibility is a priority, be sure the set the seed for R’s random
number generator. infer will respect the random seed specified in the
<code>set.seed()</code> function, returning the same result when <code>generate()</code>ing
data given an identical seed. For instance, we can calculate the
difference in mean <code>age</code> by <code>college</code> degree status using the <code>gss</code>
dataset from 10 versions of the <code>gss</code> resampled with permutation using
the following code.
</p>
<div class="sourceCode r"><pre>set.seed(1)

gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 5, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))
</pre></div>
<div class="sourceCode"><pre>## Response: age (numeric)
## Explanatory: college (factor)
## Null Hypothesis: independence
## # A tibble: 5 x 2
##   replicate   stat
##       &lt;int&gt;  &lt;dbl&gt;
## 1         1 -0.531
## 2         2 -2.35 
## 3         3  0.764
## 4         4  0.280
## 5         5  0.350
</pre></div>
<p>Setting the seed to the same value again and rerunning the same code
will produce the same result.
</p>
<div class="sourceCode r"><pre># set the seed
set.seed(1)

gss %&gt;%
  specify(age ~ college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 5, type = "permute") %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))
</pre></div>
<div class="sourceCode"><pre>## Response: age (numeric)
## Explanatory: college (factor)
## Null Hypothesis: independence
## # A tibble: 5 x 2
##   replicate   stat
##       &lt;int&gt;  &lt;dbl&gt;
## 1         1 -0.531
## 2         2 -2.35 
## 3         3  0.764
## 4         4  0.280
## 5         5  0.350
</pre></div>
<p>Please keep this in mind when writing infer code that utilizes
resampling with <code>generate()</code>.
</p>


<h3>See Also</h3>

<p>Other core functions: 
<code><a href="#topic+calculate">calculate</a>()</code>,
<code><a href="#topic+hypothesize">hypothesize</a>()</code>,
<code><a href="#topic+specify">specify</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate a null distribution by taking 200 bootstrap samples
gss %&gt;%
 specify(response = hours) %&gt;%
 hypothesize(null = "point", mu = 40) %&gt;%
 generate(reps = 200, type = "bootstrap")

# generate a null distribution for the independence of
# two variables by permuting their values 200 times
gss %&gt;%
 specify(partyid ~ age) %&gt;%
 hypothesize(null = "independence") %&gt;%
 generate(reps = 200, type = "permute")

# generate a null distribution via sampling from a
# binomial distribution 200 times
gss %&gt;%
specify(response = sex, success = "female") %&gt;%
  hypothesize(null = "point", p = .5) %&gt;%
  generate(reps = 200, type = "draw") %&gt;%
  calculate(stat = "z")

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='get_confidence_interval'>Compute confidence interval</h2><span id='topic+get_confidence_interval'></span><span id='topic+get_ci'></span>

<h3>Description</h3>

<p>Compute a confidence interval around a summary statistic. Both
simulation-based and theoretical methods are supported, though only
<code>type = "se"</code> is supported for theoretical methods.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_confidence_interval(x, level = 0.95, type = NULL, point_estimate = NULL)

get_ci(x, level = 0.95, type = NULL, point_estimate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_confidence_interval_+3A_x">x</code></td>
<td>
<p>A distribution. For simulation-based inference, a data frame
containing a distribution of <code><a href="#topic+calculate">calculate()</a></code>d statistics
or <code><a href="#topic+fit.infer">fit()</a></code>ted coefficient estimates. This object should
have been passed to <code><a href="#topic+generate">generate()</a></code> before being supplied or
<code><a href="#topic+calculate">calculate()</a></code> to <code><a href="#topic+fit.infer">fit()</a></code>. For theory-based inference,
output of <code><a href="#topic+assume">assume()</a></code>. Distributions for confidence intervals do not
require a null hypothesis via <code><a href="#topic+hypothesize">hypothesize()</a></code>.</p>
</td></tr>
<tr><td><code id="get_confidence_interval_+3A_level">level</code></td>
<td>
<p>A numerical value between 0 and 1 giving the confidence level.
Default value is 0.95.</p>
</td></tr>
<tr><td><code id="get_confidence_interval_+3A_type">type</code></td>
<td>
<p>A string giving which method should be used for creating the
confidence interval. The default is <code>"percentile"</code> with <code>"se"</code>
corresponding to (multiplier * standard error) and <code>"bias-corrected"</code> for
bias-corrected interval as other options.</p>
</td></tr>
<tr><td><code id="get_confidence_interval_+3A_point_estimate">point_estimate</code></td>
<td>
<p>A data frame containing the observed statistic (in a
<code><a href="#topic+calculate">calculate()</a></code>-based workflow) or observed fit (in a
<code><a href="#topic+fit.infer">fit()</a></code>-based workflow). This object is likely the output
of <code><a href="#topic+calculate">calculate()</a></code> or <code><a href="#topic+fit.infer">fit()</a></code> and need not
to have been passed to <code><a href="#topic+generate">generate()</a></code>. Set to <code>NULL</code> by
default. Must be provided if <code>type</code> is <code>"se"</code> or <code>"bias-corrected"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A null hypothesis is not required to compute a confidence interval. However,
including <code><a href="#topic+hypothesize">hypothesize()</a></code> in a pipeline leading to <code>get_confidence_interval()</code>
will not break anything. This can be useful when computing a confidence
interval using the same distribution used to compute a p-value.
</p>
<p>Theoretical confidence intervals (i.e. calculated by supplying the output
of <code><a href="#topic+assume">assume()</a></code> to the <code>x</code> argument) require that the point estimate lies on
the scale of the data. The distribution defined in <code><a href="#topic+assume">assume()</a></code> will be
recentered and rescaled to align with the point estimate, as can be shown
in the output of <code><a href="#topic+visualize">visualize()</a></code> when paired with <code><a href="#topic+shade_confidence_interval">shade_confidence_interval()</a></code>.
Confidence intervals are implemented for the following distributions and
point estimates:
</p>

<ul>
<li> <p><code>distribution = "t"</code>: <code>point_estimate</code> should be the output of
<code><a href="#topic+calculate">calculate()</a></code> with <code>stat = "mean"</code> or <code>stat = "diff in means"</code>
</p>
</li>
<li> <p><code>distribution = "z"</code>: <code>point_estimate</code> should be the output of
<code><a href="#topic+calculate">calculate()</a></code> with <code>stat = "prop"</code> or <code>stat = "diff in props"</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble">tibble</a> containing the following columns:
</p>

<ul>
<li> <p><code>term</code>: The explanatory variable (or intercept) in question. Only
supplied if the input had been previously passed to <code><a href="#topic+fit.infer">fit()</a></code>.
</p>
</li>
<li> <p><code>lower_ci</code>, <code>upper_ci</code>: The lower and upper bounds of the confidence
interval, respectively.
</p>
</li></ul>



<h3>Aliases</h3>

<p><code>get_ci()</code> is an alias of <code>get_confidence_interval()</code>.
<code>conf_int()</code> is a deprecated alias of <code>get_confidence_interval()</code>.
</p>


<h3>See Also</h3>

<p>Other auxillary functions: 
<code><a href="#topic+get_p_value">get_p_value</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
boot_dist &lt;- gss %&gt;%
  # We're interested in the number of hours worked per week
  specify(response = hours) %&gt;%
  # Generate bootstrap samples
  generate(reps = 1000, type = "bootstrap") %&gt;%
  # Calculate mean of each bootstrap sample
  calculate(stat = "mean")

boot_dist %&gt;%
  # Calculate the confidence interval around the point estimate
  get_confidence_interval(
    # At the 95% confidence level; percentile method
    level = 0.95
  )

# for type = "se" or type = "bias-corrected" we need a point estimate
sample_mean &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  calculate(stat = "mean")

boot_dist %&gt;%
  get_confidence_interval(
    point_estimate = sample_mean,
    # At the 95% confidence level
    level = 0.95,
    # Using the standard error method
    type = "se"
  )

# using a theoretical distribution -----------------------------------

# define a sampling distribution
sampling_dist &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  assume("t")

# get the confidence interval---note that the
# point estimate is required here
get_confidence_interval(
  sampling_dist,
  level = .95,
  point_estimate = sample_mean
)

# using a model fitting workflow -----------------------

# fit a linear model predicting number of hours worked per
# week using respondent age and degree status.
observed_fit &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  fit()

observed_fit

# fit 100 models to resamples of the gss dataset, where the response
# `hours` is permuted in each. note that this code is the same as
# the above except for the addition of the `generate` step.
null_fits &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 100, type = "permute") %&gt;%
  fit()

null_fits

get_confidence_interval(
  null_fits,
  point_estimate = observed_fit,
  level = .95
)

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='get_p_value'>Compute p-value</h2><span id='topic+get_p_value'></span><span id='topic+get_p_value.default'></span><span id='topic+get_pvalue'></span><span id='topic+get_p_value.infer_dist'></span>

<h3>Description</h3>

<p>Compute a p-value from a null distribution and observed statistic.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_p_value(x, obs_stat, direction)

## Default S3 method:
get_p_value(x, obs_stat, direction)

get_pvalue(x, obs_stat, direction)

## S3 method for class 'infer_dist'
get_p_value(x, obs_stat, direction)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_p_value_+3A_x">x</code></td>
<td>
<p>A null distribution. For simulation-based inference, a data frame
containing a distribution of <code><a href="#topic+calculate">calculate()</a></code>d statistics
or <code><a href="#topic+fit.infer">fit()</a></code>ted coefficient estimates. This object should
have been passed to <code><a href="#topic+generate">generate()</a></code> before being supplied or
<code><a href="#topic+calculate">calculate()</a></code> to <code><a href="#topic+fit.infer">fit()</a></code>. For theory-based inference,
the output of <code><a href="#topic+assume">assume()</a></code>.</p>
</td></tr>
<tr><td><code id="get_p_value_+3A_obs_stat">obs_stat</code></td>
<td>
<p>A data frame containing the observed statistic (in a
<code><a href="#topic+calculate">calculate()</a></code>-based workflow) or observed fit (in a
<code><a href="#topic+fit.infer">fit()</a></code>-based workflow). This object is likely the output
of <code><a href="#topic+calculate">calculate()</a></code> or <code><a href="#topic+fit.infer">fit()</a></code> and need not
to have been passed to <code><a href="#topic+generate">generate()</a></code>.</p>
</td></tr>
<tr><td><code id="get_p_value_+3A_direction">direction</code></td>
<td>
<p>A character string. Options are <code>"less"</code>, <code>"greater"</code>, or
<code>"two-sided"</code>. Can also use <code>"left"</code>, <code>"right"</code>, <code>"both"</code>,
<code>"two_sided"</code>, or <code>"two sided"</code>, <code>"two.sided"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble">tibble</a> containing the following columns:
</p>

<ul>
<li> <p><code>term</code>: The explanatory variable (or intercept) in question. Only
supplied if the input had been previously passed to <code><a href="#topic+fit.infer">fit()</a></code>.
</p>
</li>
<li> <p><code>p_value</code>: A value in [0, 1] giving the probability that a
statistic/coefficient as or more extreme than the observed
statistic/coefficient would occur if the null hypothesis were true.
</p>
</li></ul>



<h3>Aliases</h3>

<p><code>get_pvalue()</code> is an alias of <code>get_p_value()</code>.
<code>p_value</code> is a deprecated alias of <code>get_p_value()</code>.
</p>


<h3>Zero p-value</h3>

<p>Though a true p-value of 0 is impossible, <code>get_p_value()</code> may return 0 in
some cases. This is due to the simulation-based nature of the {infer}
package; the output of this function is an approximation based on
the number of <code>reps</code> chosen in the <code>generate()</code> step. When the observed
statistic is very unlikely given the null hypothesis, and only a small
number of <code>reps</code> have been generated to form a null distribution,
it is possible that the observed statistic will be more extreme than
every test statistic generated to form the null distribution, resulting
in an approximate p-value of 0. In this case, the true p-value is a small
value likely less than <code>3/reps</code> (based on a poisson approximation).
</p>
<p>In the case that a p-value of zero is reported, a warning message will be
raised to caution the user against reporting a p-value exactly equal to 0.
</p>


<h3>See Also</h3>

<p>Other auxillary functions: 
<code><a href="#topic+get_confidence_interval">get_confidence_interval</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# using a simulation-based null distribution ------------------------------

# find the point estimate---mean number of hours worked per week
point_estimate &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  calculate(stat = "mean")

# starting with the gss dataset
gss %&gt;%
  # ...we're interested in the number of hours worked per week
  specify(response = hours) %&gt;%
  # hypothesizing that the mean is 40
  hypothesize(null = "point", mu = 40) %&gt;%
  # generating data points for a null distribution
  generate(reps = 1000, type = "bootstrap") %&gt;%
  # finding the null distribution
  calculate(stat = "mean") %&gt;%
  get_p_value(obs_stat = point_estimate, direction = "two-sided")

# using a theoretical null distribution -----------------------------------

# calculate the observed statistic
obs_stat &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  calculate(stat = "t")

# define a null distribution
null_dist &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  assume("t")

# calculate a p-value
get_p_value(null_dist, obs_stat, direction = "both")

# using a model fitting workflow -----------------------------------------

# fit a linear model predicting number of hours worked per
# week using respondent age and degree status.
observed_fit &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  fit()

observed_fit

# fit 100 models to resamples of the gss dataset, where the response
# `hours` is permuted in each. note that this code is the same as
# the above except for the addition of the `generate` step.
null_fits &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  hypothesize(null = "independence") %&gt;%
  generate(reps = 100, type = "permute") %&gt;%
  fit()

null_fits

get_p_value(null_fits, obs_stat = observed_fit, direction = "two-sided")

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='gss'>Subset of data from the General Social Survey (GSS).</h2><span id='topic+gss'></span>

<h3>Description</h3>

<p>The General Social Survey is a high-quality survey which gathers data on
American society and opinions, conducted since 1972. This data set is a
sample of 500 entries from the GSS, spanning years 1973-2018,
including demographic markers and some
economic variables. Note that this data is included for demonstration only,
and should not be assumed to provide accurate estimates relating to the GSS.
However, due to the high quality of the GSS, the unweighted data will
approximate the weighted data in some analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gss
</code></pre>


<h3>Format</h3>

<p>A tibble with 500 rows and 11 variables:
</p>

<dl>
<dt>year</dt><dd><p>year respondent was surveyed</p>
</dd>
<dt>age</dt><dd><p>age at time of survey, truncated at 89</p>
</dd>
<dt>sex</dt><dd><p>respondent's sex (self-identified)</p>
</dd>
<dt>college</dt><dd><p>whether on not respondent has a college degree, including
junior/community college</p>
</dd>
<dt>partyid</dt><dd><p>political party affiliation</p>
</dd>
<dt>hompop</dt><dd><p>number of persons in household</p>
</dd>
<dt>hours</dt><dd><p>number of hours worked in week before survey, truncated at 89</p>
</dd>
<dt>income</dt><dd><p>total family income</p>
</dd>
<dt>class</dt><dd><p>subjective socioeconomic class identification</p>
</dd>
<dt>finrela</dt><dd><p>opinion of family income</p>
</dd>
<dt>weight</dt><dd><p>survey weight</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://gss.norc.org">https://gss.norc.org</a>
</p>

<hr>
<h2 id='hypothesize'>Declare a null hypothesis</h2><span id='topic+hypothesize'></span><span id='topic+hypothesise'></span>

<h3>Description</h3>

<p>Declare a null hypothesis about variables selected in <code><a href="#topic+specify">specify()</a></code>.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypothesize(x, null, p = NULL, mu = NULL, med = NULL, sigma = NULL)

hypothesise(x, null, p = NULL, mu = NULL, med = NULL, sigma = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypothesize_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="hypothesize_+3A_null">null</code></td>
<td>
<p>The null hypothesis. Options include <code>"independence"</code>,
<code>"point"</code>, and <code>"paired independence"</code>.
</p>

<ul>
<li> <p><code>independence</code>: Should be used with both a <code>response</code> and <code>explanatory</code>
variable. Indicates that the values of the specified <code>response</code> variable
are independent of the associated values in <code>explanatory</code>.
</p>
</li>
<li> <p><code>point</code>: Should be used with only a <code>response</code> variable. Indicates
that a point estimate based on the values in <code>response</code> is associated
with a parameter. Sometimes requires supplying one of <code>p</code>, <code>mu</code>, <code>med</code>, or
<code>sigma</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;paired independence&#8288;</code>: Should be used with only a <code>response</code> variable
giving the pre-computed difference between paired observations. Indicates
that the order of subtraction between paired values does not affect the
resulting distribution.
</p>
</li></ul>
</td></tr>
<tr><td><code id="hypothesize_+3A_p">p</code></td>
<td>
<p>The true proportion of successes (a number between 0 and 1). To be used with point null hypotheses when the specified response
variable is categorical.</p>
</td></tr>
<tr><td><code id="hypothesize_+3A_mu">mu</code></td>
<td>
<p>The true mean (any numerical value). To be used with point null
hypotheses when the specified response variable is continuous.</p>
</td></tr>
<tr><td><code id="hypothesize_+3A_med">med</code></td>
<td>
<p>The true median (any numerical value). To be used with point null
hypotheses when the specified response variable is continuous.</p>
</td></tr>
<tr><td><code id="hypothesize_+3A_sigma">sigma</code></td>
<td>
<p>The true standard deviation (any numerical value). To be used with
point null hypotheses.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the response (and explanatory, if specified)
variable data with parameter information stored as well.
</p>


<h3>See Also</h3>

<p>Other core functions: 
<code><a href="#topic+calculate">calculate</a>()</code>,
<code><a href="#topic+generate">generate</a>()</code>,
<code><a href="#topic+specify">specify</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># hypothesize independence of two variables
gss %&gt;%
 specify(college ~ partyid, success = "degree") %&gt;%
 hypothesize(null = "independence")

# hypothesize a mean number of hours worked per week of 40
gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40)

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='observe'>Calculate observed statistics</h2><span id='topic+observe'></span>

<h3>Description</h3>

<p>This function is a wrapper that calls <code><a href="#topic+specify">specify()</a></code>, <code><a href="#topic+hypothesize">hypothesize()</a></code>, and
<code><a href="#topic+calculate">calculate()</a></code> consecutively that can be used to calculate observed
statistics from data. <code><a href="#topic+hypothesize">hypothesize()</a></code> will only be called if a point
null hypothesis parameter is supplied.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observe(
  x,
  formula,
  response = NULL,
  explanatory = NULL,
  success = NULL,
  null = NULL,
  p = NULL,
  mu = NULL,
  med = NULL,
  sigma = NULL,
  stat = c("mean", "median", "sum", "sd", "prop", "count", "diff in means",
    "diff in medians", "diff in props", "Chisq", "F", "slope", "correlation", "t", "z",
    "ratio of props", "odds ratio"),
  order = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="observe_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="observe_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="observe_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="observe_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="observe_+3A_success">success</code></td>
<td>
<p>The level of <code>response</code> that will be considered a success, as
a string. Needed for inference on one proportion, a difference in
proportions, and corresponding z stats.</p>
</td></tr>
<tr><td><code id="observe_+3A_null">null</code></td>
<td>
<p>The null hypothesis. Options include <code>"independence"</code>,
<code>"point"</code>, and <code>"paired independence"</code>.
</p>

<ul>
<li> <p><code>independence</code>: Should be used with both a <code>response</code> and <code>explanatory</code>
variable. Indicates that the values of the specified <code>response</code> variable
are independent of the associated values in <code>explanatory</code>.
</p>
</li>
<li> <p><code>point</code>: Should be used with only a <code>response</code> variable. Indicates
that a point estimate based on the values in <code>response</code> is associated
with a parameter. Sometimes requires supplying one of <code>p</code>, <code>mu</code>, <code>med</code>, or
<code>sigma</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;paired independence&#8288;</code>: Should be used with only a <code>response</code> variable
giving the pre-computed difference between paired observations. Indicates
that the order of subtraction between paired values does not affect the
resulting distribution.
</p>
</li></ul>
</td></tr>
<tr><td><code id="observe_+3A_p">p</code></td>
<td>
<p>The true proportion of successes (a number between 0 and 1). To be used with point null hypotheses when the specified response
variable is categorical.</p>
</td></tr>
<tr><td><code id="observe_+3A_mu">mu</code></td>
<td>
<p>The true mean (any numerical value). To be used with point null
hypotheses when the specified response variable is continuous.</p>
</td></tr>
<tr><td><code id="observe_+3A_med">med</code></td>
<td>
<p>The true median (any numerical value). To be used with point null
hypotheses when the specified response variable is continuous.</p>
</td></tr>
<tr><td><code id="observe_+3A_sigma">sigma</code></td>
<td>
<p>The true standard deviation (any numerical value). To be used with
point null hypotheses.</p>
</td></tr>
<tr><td><code id="observe_+3A_stat">stat</code></td>
<td>
<p>A string giving the type of the statistic to calculate. Current
options include <code>"mean"</code>, <code>"median"</code>, <code>"sum"</code>, <code>"sd"</code>, <code>"prop"</code>, <code>"count"</code>,
<code>"diff in means"</code>, <code>"diff in medians"</code>, <code>"diff in props"</code>, <code>"Chisq"</code> (or
<code>"chisq"</code>), <code>"F"</code> (or <code>"f"</code>), <code>"t"</code>, <code>"z"</code>, <code>"ratio of props"</code>, <code>"slope"</code>,
<code>"odds ratio"</code>, <code>"ratio of means"</code>, and <code>"correlation"</code>. <code>infer</code> only
supports theoretical tests on one or two means via the <code>"t"</code> distribution
and one or two proportions via the <code>"z"</code>.</p>
</td></tr>
<tr><td><code id="observe_+3A_order">order</code></td>
<td>
<p>A string vector of specifying the order in which the levels of
the explanatory variable should be ordered for subtraction (or division
for ratio-based statistics), where <code>order = c("first", "second")</code> means
<code>("first" - "second")</code>, or the analogue for ratios. Needed for inference on
difference in means, medians, proportions, ratios, t, and z statistics.</p>
</td></tr>
<tr><td><code id="observe_+3A_...">...</code></td>
<td>
<p>To pass options like <code>na.rm = TRUE</code> into functions like
<a href="base.html#topic+mean">mean()</a>, <a href="stats.html#topic+sd">sd()</a>, etc. Can also be used to
supply hypothesized null values for the <code>"t"</code> statistic or additional
arguments to <code><a href="stats.html#topic+chisq.test">stats::chisq.test()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1-column tibble containing the calculated statistic <code>stat</code>.
</p>


<h3>See Also</h3>

<p>Other wrapper functions: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+chisq_test">chisq_test</a>()</code>,
<code><a href="#topic+prop_test">prop_test</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>,
<code><a href="#topic+t_test">t_test</a>()</code>
</p>
<p>Other functions for calculating observed statistics: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># calculating the observed mean number of hours worked per week
gss %&gt;%
  observe(hours ~ NULL, stat = "mean")

# equivalently, calculating the same statistic with the core verbs
gss %&gt;%
  specify(response = hours) %&gt;%
  calculate(stat = "mean")

# calculating a t statistic for hypothesized mu = 40 hours worked/week
gss %&gt;%
  observe(hours ~ NULL, stat = "t", null = "point", mu = 40)

# equivalently, calculating the same statistic with the core verbs
gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  calculate(stat = "t")

# similarly for a difference in means in age based on whether
# the respondent has a college degree
observe(
  gss,
  age ~ college,
  stat = "diff in means",
  order = c("degree", "no degree")
)

# equivalently, calculating the same statistic with the core verbs
gss %&gt;%
  specify(age ~ college) %&gt;%
  calculate("diff in means", order = c("degree", "no degree"))

# for a more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='print.infer'>Print methods</h2><span id='topic+print.infer'></span><span id='topic+print.infer_layer'></span><span id='topic+print.infer_dist'></span>

<h3>Description</h3>

<p>Print methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'infer'
print(x, ...)

## S3 method for class 'infer_layer'
print(x, ...)

## S3 method for class 'infer_dist'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.infer_+3A_x">x</code></td>
<td>
<p>An object of class <code>infer</code>, i.e. output from <code><a href="#topic+specify">specify()</a></code> or
<code><a href="#topic+hypothesize">hypothesize()</a></code>, or of class <code>infer_layer</code>, i.e. output from
<code><a href="#topic+shade_p_value">shade_p_value()</a></code> or <code><a href="#topic+shade_confidence_interval">shade_confidence_interval()</a></code>.</p>
</td></tr>
<tr><td><code id="print.infer_+3A_...">...</code></td>
<td>
<p>Arguments passed to methods.</p>
</td></tr>
</table>

<hr>
<h2 id='prop_test'>Tidy proportion test</h2><span id='topic+prop_test'></span>

<h3>Description</h3>

<p>A tidier version of <a href="stats.html#topic+prop.test">prop.test()</a> for equal or given
proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop_test(
  x,
  formula,
  response = NULL,
  explanatory = NULL,
  p = NULL,
  order = NULL,
  alternative = "two-sided",
  conf_int = TRUE,
  conf_level = 0.95,
  success = NULL,
  correct = NULL,
  z = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prop_test_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_p">p</code></td>
<td>
<p>A numeric vector giving the hypothesized null proportion of
success for each group.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_order">order</code></td>
<td>
<p>A string vector specifying the order in which the proportions
should be subtracted, where  <code>order = c("first", "second")</code> means
<code>"first" - "second"</code>. Ignored for one-sample tests, and optional for two
sample tests.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_alternative">alternative</code></td>
<td>
<p>Character string giving the direction of the alternative
hypothesis. Options are <code>"two-sided"</code> (default), <code>"greater"</code>, or <code>"less"</code>.
Only used when testing the null that a single proportion equals a given
value, or that two proportions are equal; ignored otherwise.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_conf_int">conf_int</code></td>
<td>
<p>A logical value for whether to include the confidence
interval or not. <code>TRUE</code> by default.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_conf_level">conf_level</code></td>
<td>
<p>A numeric value between 0 and 1. Default value is 0.95.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_success">success</code></td>
<td>
<p>The level of <code>response</code> that will be considered a success, as
a string. Only used when testing the null that a single
proportion equals a given value, or that two proportions are equal;
ignored otherwise.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_correct">correct</code></td>
<td>
<p>A logical indicating whether Yates' continuity correction
should be applied where possible. If <code>z = TRUE</code>, the <code>correct</code> argument will
be overwritten as <code>FALSE</code>. Otherwise defaults to <code>correct = TRUE</code>.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_z">z</code></td>
<td>
<p>A logical value for whether to report the statistic as a standard
normal deviate or a Pearson's chi-square statistic. <code class="reqn">z^2</code>  is distributed
chi-square with 1 degree of freedom, though note that the user will likely
need to turn off Yates' continuity correction by setting <code>correct = FALSE</code>
to see this connection.</p>
</td></tr>
<tr><td><code id="prop_test_+3A_...">...</code></td>
<td>
<p>Additional arguments for <a href="stats.html#topic+prop.test">prop.test()</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When testing with an explanatory variable with more than two levels, the
<code>order</code> argument as used in the package is no longer well-defined. The function
will thus raise a warning and ignore the value if supplied a non-NULL <code>order</code>
argument.
</p>
<p>The columns present in the output depend on the output of both <code><a href="stats.html#topic+prop.test">prop.test()</a></code>
and <code><a href="broom.html#topic+tidy.htest">broom::glance.htest()</a></code>. See the latter's documentation for column
definitions; columns have been renamed with the following mapping:
</p>

<ul>
<li> <p><code>chisq_df</code> = <code>parameter</code>
</p>
</li>
<li> <p><code>p_value</code> = <code>p.value</code>
</p>
</li>
<li> <p><code>lower_ci</code> = <code>conf.low</code>
</p>
</li>
<li> <p><code>upper_ci</code> = <code>conf.high</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other wrapper functions: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+chisq_test">chisq_test</a>()</code>,
<code><a href="#topic+observe">observe</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>,
<code><a href="#topic+t_test">t_test</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># two-sample proportion test for difference in proportions of
# college completion by respondent sex
prop_test(gss,
          college ~ sex,
          order = c("female", "male"))

# one-sample proportion test for hypothesized null
# proportion of college completion of .2
prop_test(gss,
          college ~ NULL,
          p = .2)

# report as a z-statistic rather than chi-square
# and specify the success level of the response
prop_test(gss,
          college ~ NULL,
          success = "degree",
          p = .2,
          z = TRUE)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+fit'></span><span id='topic+ggplot_add'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+fit">fit</a></code></p>
</dd>
<dt>ggplot2</dt><dd><p><code><a href="ggplot2.html#topic+ggplot_add">ggplot_add</a></code></p>
</dd>
</dl>


<h3>Details</h3>

<p>Read more about infer's <a href="#topic+fit.infer">fit</a> function <a href="#topic+fit.infer">here</a> or
by running <code>?fit.infer</code> in your console.
</p>

<hr>
<h2 id='rep_sample_n'>Perform repeated sampling</h2><span id='topic+rep_sample_n'></span><span id='topic+rep_slice_sample'></span>

<h3>Description</h3>

<p>These functions extend the functionality of <code><a href="dplyr.html#topic+sample_n">dplyr::sample_n()</a></code> and
<code><a href="dplyr.html#topic+slice">dplyr::slice_sample()</a></code> by allowing for repeated sampling of data.
This operation is especially helpful while creating sampling
distributions—see the examples below!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rep_sample_n(tbl, size, replace = FALSE, reps = 1, prob = NULL)

rep_slice_sample(
  .data,
  n = NULL,
  prop = NULL,
  replace = FALSE,
  weight_by = NULL,
  reps = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rep_sample_n_+3A_tbl">tbl</code>, <code id="rep_sample_n_+3A_.data">.data</code></td>
<td>
<p>Data frame of population from which to sample.</p>
</td></tr>
<tr><td><code id="rep_sample_n_+3A_size">size</code>, <code id="rep_sample_n_+3A_n">n</code>, <code id="rep_sample_n_+3A_prop">prop</code></td>
<td>
<p><code>size</code> and <code>n</code> refer to the sample size of each sample.
The <code>size</code> argument to <code>rep_sample_n()</code> is required, while in
<code>rep_slice_sample()</code> sample size defaults to 1 if not specified. <code>prop</code>, an
argument to <code>rep_slice_sample()</code>, refers to the proportion of rows to sample
in each sample, and is rounded down in the case that <code>prop * nrow(.data)</code> is
not an integer. When using <code>rep_slice_sample()</code>, please only supply one of
<code>n</code> or <code>prop</code>.</p>
</td></tr>
<tr><td><code id="rep_sample_n_+3A_replace">replace</code></td>
<td>
<p>Should samples be taken with replacement?</p>
</td></tr>
<tr><td><code id="rep_sample_n_+3A_reps">reps</code></td>
<td>
<p>Number of samples to take.</p>
</td></tr>
<tr><td><code id="rep_sample_n_+3A_prob">prob</code>, <code id="rep_sample_n_+3A_weight_by">weight_by</code></td>
<td>
<p>A vector of sampling weights for each of the rows in
<code>.data</code>—must have length equal to <code>nrow(.data)</code>. For <code>weight_by</code>, this
may also be an unquoted column name in <code>.data</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rep_sample_n()</code> and <code>rep_slice_sample()</code> are designed to behave similar to
their dplyr counterparts. As such, they have at least the following
differences:
</p>

<ul>
<li><p> In case <code>replace = FALSE</code> having <code>size</code> bigger than number of data rows in
<code>rep_sample_n()</code> will give an error. In <code>rep_slice_sample()</code> having such <code>n</code>
or <code>prop &gt; 1</code> will give warning and output sample size will be set to number
of rows in data.
</p>
</li></ul>

<p>Note that the <code><a href="dplyr.html#topic+sample_n">dplyr::sample_n()</a></code> function  has been superseded by
<code><a href="dplyr.html#topic+slice">dplyr::slice_sample()</a></code>.
</p>


<h3>Value</h3>

<p>A tibble of size <code>reps * n</code> rows corresponding to <code>reps</code>
samples of size <code>n</code> from <code>.data</code>, grouped by <code>replicate</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(ggplot2)
library(tibble)

# take 1000 samples of size n = 50, without replacement
slices &lt;- gss %&gt;%
  rep_slice_sample(n = 50, reps = 1000)

slices

# compute the proportion of respondents with a college
# degree in each replicate
p_hats &lt;- slices %&gt;%
  group_by(replicate) %&gt;%
  summarize(prop_college = mean(college == "degree"))

# plot sampling distribution
ggplot(p_hats, aes(x = prop_college)) +
  geom_density() +
  labs(
    x = "p_hat", y = "Number of samples",
    title = "Sampling distribution of p_hat"
  )

# sampling with probability weights. Note probabilities are automatically
# renormalized to sum to 1
df &lt;- tibble(
  id = 1:5,
  letter = factor(c("a", "b", "c", "d", "e"))
)

rep_slice_sample(df, n = 2, reps = 5, weight_by = c(.5, .4, .3, .2, .1))

# alternatively, pass an unquoted column name in `.data` as `weight_by`
df &lt;- df %&gt;% mutate(wts = c(.5, .4, .3, .2, .1))

rep_slice_sample(df, n = 2, reps = 5, weight_by = wts)
</code></pre>

<hr>
<h2 id='shade_confidence_interval'>Add information about confidence interval</h2><span id='topic+shade_confidence_interval'></span><span id='topic+shade_ci'></span>

<h3>Description</h3>

<p><code>shade_confidence_interval()</code> plots a confidence interval region on top of
<code><a href="#topic+visualize">visualize()</a></code> output. The output is a ggplot2 layer that can be added with
<code>+</code>. The function has a shorter alias, <code>shade_ci()</code>.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shade_confidence_interval(
  endpoints,
  color = "mediumaquamarine",
  fill = "turquoise",
  ...
)

shade_ci(endpoints, color = "mediumaquamarine", fill = "turquoise", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shade_confidence_interval_+3A_endpoints">endpoints</code></td>
<td>
<p>The lower and upper bounds of the interval to be plotted.
Likely, this will be the output of <code><a href="#topic+get_confidence_interval">get_confidence_interval()</a></code>.
For <code><a href="#topic+calculate">calculate()</a></code>-based workflows, this will be a 2-element vector
or a <code style="white-space: pre;">&#8288;1 x 2&#8288;</code> data frame containing the lower and upper values to be plotted.
For <code><a href="#topic+fit.infer">fit()</a></code>-based workflows, a <code style="white-space: pre;">&#8288;(p + 1) x 3&#8288;</code> data frame
with columns <code>term</code>, <code>lower_ci</code>, and <code>upper_ci</code>, giving the upper and
lower bounds for each regression term. For use in visualizations of
<code><a href="#topic+assume">assume()</a></code> output, this must be the output of <code><a href="#topic+get_confidence_interval">get_confidence_interval()</a></code>.</p>
</td></tr>
<tr><td><code id="shade_confidence_interval_+3A_color">color</code></td>
<td>
<p>A character or hex string specifying the color of the
end points as a vertical lines on the plot.</p>
</td></tr>
<tr><td><code id="shade_confidence_interval_+3A_fill">fill</code></td>
<td>
<p>A character or hex string specifying the color to shade the
confidence interval. If <code>NULL</code> then no shading is actually done.</p>
</td></tr>
<tr><td><code id="shade_confidence_interval_+3A_...">...</code></td>
<td>
<p>Other arguments passed along to ggplot2 functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If added to an existing infer visualization, a ggplot2
object displaying the supplied intervals on top of its corresponding
distribution. Otherwise, an <code>infer_layer</code> list.
</p>


<h3>See Also</h3>

<p>Other visualization functions: 
<code><a href="#topic+shade_p_value">shade_p_value</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># find the point estimate---mean number of hours worked per week
point_estimate &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  calculate(stat = "mean")

# ...and a bootstrap distribution
boot_dist &lt;- gss %&gt;%
  # ...we're interested in the number of hours worked per week
  specify(response = hours) %&gt;%
  # generating data points
  generate(reps = 1000, type = "bootstrap") %&gt;%
  # finding the distribution from the generated data
  calculate(stat = "mean")

# find a confidence interval around the point estimate
ci &lt;- boot_dist %&gt;%
  get_confidence_interval(point_estimate = point_estimate,
                          # at the 95% confidence level
                          level = .95,
                          # using the standard error method
                          type = "se")


# and plot it!
boot_dist %&gt;%
  visualize() +
  shade_confidence_interval(ci)

# or just plot the bounds
boot_dist %&gt;%
  visualize() +
  shade_confidence_interval(ci, fill = NULL)

# you can shade confidence intervals on top of
# theoretical distributions, too---the theoretical
# distribution will be recentered and rescaled to
# align with the confidence interval
sampling_dist &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  assume(distribution = "t")

visualize(sampling_dist) +
  shade_confidence_interval(ci)


# to visualize distributions of coefficients for multiple
# explanatory variables, use a `fit()`-based workflow

# fit 1000 linear models with the `hours` variable permuted
null_fits &lt;- gss %&gt;%
 specify(hours ~ age + college) %&gt;%
 hypothesize(null = "independence") %&gt;%
 generate(reps = 1000, type = "permute") %&gt;%
 fit()

null_fits

# fit a linear model to the observed data
obs_fit &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  fit()

obs_fit

# get confidence intervals for each term
conf_ints &lt;-
  get_confidence_interval(
    null_fits,
    point_estimate = obs_fit,
    level = .95
  )

# visualize distributions of coefficients
# generated under the null
visualize(null_fits)

# add a confidence interval shading layer to juxtapose
# the null fits with the observed fit for each term
visualize(null_fits) +
  shade_confidence_interval(conf_ints)


# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='shade_p_value'>Shade histogram area beyond an observed statistic</h2><span id='topic+shade_p_value'></span><span id='topic+shade_pvalue'></span>

<h3>Description</h3>

<p><code>shade_p_value()</code> plots a p-value region on top of
<code><a href="#topic+visualize">visualize()</a></code> output. The output is a ggplot2 layer that can be added with
<code>+</code>. The function has a shorter alias, <code>shade_pvalue()</code>.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shade_p_value(obs_stat, direction, color = "red2", fill = "pink", ...)

shade_pvalue(obs_stat, direction, color = "red2", fill = "pink", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shade_p_value_+3A_obs_stat">obs_stat</code></td>
<td>
<p>The observed statistic or estimate. For
<code><a href="#topic+calculate">calculate()</a></code>-based workflows, this will be a 1-element numeric vector or
a <code style="white-space: pre;">&#8288;1 x 1&#8288;</code> data frame containing the observed statistic.
For <code><a href="#topic+fit.infer">fit()</a></code>-based workflows, a <code style="white-space: pre;">&#8288;(p + 1) x 2&#8288;</code> data frame
with columns <code>term</code> and <code>estimate</code> giving the observed estimate for
each term.</p>
</td></tr>
<tr><td><code id="shade_p_value_+3A_direction">direction</code></td>
<td>
<p>A string specifying in which direction the shading should
occur. Options are <code>"less"</code>, <code>"greater"</code>, or <code>"two-sided"</code>. Can
also give <code>"left"</code>, <code>"right"</code>, <code>"both"</code>, <code>"two_sided"</code>, <code>"two sided"</code>,
or <code>"two.sided"</code>. If <code>NULL</code>, the function will not shade any area.</p>
</td></tr>
<tr><td><code id="shade_p_value_+3A_color">color</code></td>
<td>
<p>A character or hex string specifying the color of the observed
statistic as a vertical line on the plot.</p>
</td></tr>
<tr><td><code id="shade_p_value_+3A_fill">fill</code></td>
<td>
<p>A character or hex string specifying the color to shade the
p-value region. If <code>NULL</code>, the function will not shade any area.</p>
</td></tr>
<tr><td><code id="shade_p_value_+3A_...">...</code></td>
<td>
<p>Other arguments passed along to ggplot2 functions.
For expert use only.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If added to an existing infer visualization, a ggplot2
object displaying the supplied statistic on top of its corresponding
distribution. Otherwise, an <code>infer_layer</code> list.
</p>


<h3>See Also</h3>

<p>Other visualization functions: 
<code><a href="#topic+shade_confidence_interval">shade_confidence_interval</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># find the point estimate---mean number of hours worked per week
point_estimate &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  calculate(stat = "t")

# ...and a null distribution
null_dist &lt;- gss %&gt;%
  # ...we're interested in the number of hours worked per week
  specify(response = hours) %&gt;%
  # hypothesizing that the mean is 40
  hypothesize(null = "point", mu = 40) %&gt;%
  # generating data points for a null distribution
  generate(reps = 1000, type = "bootstrap") %&gt;%
  # estimating the null distribution
  calculate(stat = "t")

# shade the p-value of the point estimate
null_dist %&gt;%
  visualize() +
  shade_p_value(obs_stat = point_estimate, direction = "two-sided")

# you can shade confidence intervals on top of
# theoretical distributions, too!
null_dist_theory &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  assume(distribution = "t")

null_dist_theory %&gt;%
  visualize() +
  shade_p_value(obs_stat = point_estimate, direction = "two-sided")


# to visualize distributions of coefficients for multiple
# explanatory variables, use a `fit()`-based workflow

# fit 1000 linear models with the `hours` variable permuted
null_fits &lt;- gss %&gt;%
 specify(hours ~ age + college) %&gt;%
 hypothesize(null = "independence") %&gt;%
 generate(reps = 1000, type = "permute") %&gt;%
 fit()

null_fits

# fit a linear model to the observed data
obs_fit &lt;- gss %&gt;%
  specify(hours ~ age + college) %&gt;%
  fit()

obs_fit

# visualize distributions of coefficients
# generated under the null
visualize(null_fits)

# add a p-value shading layer to juxtapose the null
# fits with the observed fit for each term
visualize(null_fits) +
  shade_p_value(obs_fit, direction = "both")

# the direction argument will be applied
# to the plot for each term
visualize(null_fits) +
  shade_p_value(obs_fit, direction = "left")


# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='specify'>Specify response and explanatory variables</h2><span id='topic+specify'></span>

<h3>Description</h3>

<p><code>specify()</code> is used to specify which columns in the supplied data frame are
the relevant response (and, if applicable, explanatory) variables. Note that
character variables are converted to <code>factor</code>s.
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specify(x, formula, response = NULL, explanatory = NULL, success = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="specify_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="specify_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="specify_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="specify_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="specify_+3A_success">success</code></td>
<td>
<p>The level of <code>response</code> that will be considered a success, as
a string. Needed for inference on one proportion, a difference in
proportions, and corresponding z stats.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the response (and explanatory, if specified)
variable data.
</p>


<h3>See Also</h3>

<p>Other core functions: 
<code><a href="#topic+calculate">calculate</a>()</code>,
<code><a href="#topic+generate">generate</a>()</code>,
<code><a href="#topic+hypothesize">hypothesize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specifying for a point estimate on one variable
gss %&gt;%
   specify(response = age)

# specify a relationship between variables as a formula...
gss %&gt;%
  specify(age ~ partyid)

# ...or with named arguments!
gss %&gt;%
  specify(response = age, explanatory = partyid)

# more in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

<hr>
<h2 id='t_stat'>Tidy t-test statistic</h2><span id='topic+t_stat'></span>

<h3>Description</h3>

<p>A shortcut wrapper function to get the observed test statistic for a t test.
This function has been deprecated in favor of the more general <code><a href="#topic+observe">observe()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_stat(
  x,
  formula,
  response = NULL,
  explanatory = NULL,
  order = NULL,
  alternative = "two-sided",
  mu = 0,
  conf_int = FALSE,
  conf_level = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="t_stat_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_order">order</code></td>
<td>
<p>A string vector of specifying the order in which the levels of
the explanatory variable should be ordered for subtraction, where <code>order = c("first", "second")</code> means <code>("first" - "second")</code>.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_alternative">alternative</code></td>
<td>
<p>Character string giving the direction of the alternative
hypothesis. Options are <code>"two-sided"</code> (default), <code>"greater"</code>, or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_mu">mu</code></td>
<td>
<p>A numeric value giving the hypothesized null mean value for a one
sample test and the hypothesized difference for a two sample test.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_conf_int">conf_int</code></td>
<td>
<p>A logical value for whether to include the confidence
interval or not. <code>TRUE</code> by default.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_conf_level">conf_level</code></td>
<td>
<p>A numeric value between 0 and 1. Default value is 0.95.</p>
</td></tr>
<tr><td><code id="t_stat_+3A_...">...</code></td>
<td>
<p>Pass in arguments to infer functions.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other wrapper functions: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+chisq_test">chisq_test</a>()</code>,
<code><a href="#topic+observe">observe</a>()</code>,
<code><a href="#topic+prop_test">prop_test</a>()</code>,
<code><a href="#topic+t_test">t_test</a>()</code>
</p>
<p>Other functions for calculating observed statistics: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+observe">observe</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tidyr)

# t test statistic for true mean number of hours worked
# per week of 40
gss %&gt;%
   t_stat(response = hours, mu = 40)

# t test statistic for number of hours worked per week
# by college degree status
gss %&gt;%
   tidyr::drop_na(college) %&gt;%
   t_stat(formula = hours ~ college,
      order = c("degree", "no degree"),
      alternative = "two-sided")

</code></pre>

<hr>
<h2 id='t_test'>Tidy t-test</h2><span id='topic+t_test'></span>

<h3>Description</h3>

<p>A tidier version of <a href="stats.html#topic+t.test">t.test()</a> for two sample tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_test(
  x,
  formula,
  response = NULL,
  explanatory = NULL,
  order = NULL,
  alternative = "two-sided",
  mu = 0,
  conf_int = TRUE,
  conf_level = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="t_test_+3A_x">x</code></td>
<td>
<p>A data frame that can be coerced into a <a href="tibble.html#topic+tibble">tibble</a>.</p>
</td></tr>
<tr><td><code id="t_test_+3A_formula">formula</code></td>
<td>
<p>A formula with the response variable on the left and the
explanatory on the right. Alternatively, a <code>response</code> and <code>explanatory</code>
argument can be supplied.</p>
</td></tr>
<tr><td><code id="t_test_+3A_response">response</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the response.
This is an alternative to using the <code>formula</code> argument.</p>
</td></tr>
<tr><td><code id="t_test_+3A_explanatory">explanatory</code></td>
<td>
<p>The variable name in <code>x</code> that will serve as the
explanatory variable. This is an alternative to using the formula argument.</p>
</td></tr>
<tr><td><code id="t_test_+3A_order">order</code></td>
<td>
<p>A string vector of specifying the order in which the levels of
the explanatory variable should be ordered for subtraction, where <code>order = c("first", "second")</code> means <code>("first" - "second")</code>.</p>
</td></tr>
<tr><td><code id="t_test_+3A_alternative">alternative</code></td>
<td>
<p>Character string giving the direction of the alternative
hypothesis. Options are <code>"two-sided"</code> (default), <code>"greater"</code>, or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="t_test_+3A_mu">mu</code></td>
<td>
<p>A numeric value giving the hypothesized null mean value for a one
sample test and the hypothesized difference for a two sample test.</p>
</td></tr>
<tr><td><code id="t_test_+3A_conf_int">conf_int</code></td>
<td>
<p>A logical value for whether to include the confidence
interval or not. <code>TRUE</code> by default.</p>
</td></tr>
<tr><td><code id="t_test_+3A_conf_level">conf_level</code></td>
<td>
<p>A numeric value between 0 and 1. Default value is 0.95.</p>
</td></tr>
<tr><td><code id="t_test_+3A_...">...</code></td>
<td>
<p>For passing in other arguments to <a href="stats.html#topic+t.test">t.test()</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other wrapper functions: 
<code><a href="#topic+chisq_stat">chisq_stat</a>()</code>,
<code><a href="#topic+chisq_test">chisq_test</a>()</code>,
<code><a href="#topic+observe">observe</a>()</code>,
<code><a href="#topic+prop_test">prop_test</a>()</code>,
<code><a href="#topic+t_stat">t_stat</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tidyr)

# t test for number of hours worked per week
# by college degree status
gss %&gt;%
   tidyr::drop_na(college) %&gt;%
   t_test(formula = hours ~ college,
      order = c("degree", "no degree"),
      alternative = "two-sided")

# see vignette("infer") for more explanation of the
# intuition behind the infer package, and vignette("t_test")
# for more examples of t-tests using infer

</code></pre>

<hr>
<h2 id='visualize'>Visualize statistical inference</h2><span id='topic+visualize'></span><span id='topic+visualise'></span>

<h3>Description</h3>

<p>Visualize the distribution of the simulation-based inferential statistics or
the theoretical distribution (or both!).
</p>
<p>Learn more in <code>vignette("infer")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualize(data, bins = 15, method = "simulation", dens_color = "black", ...)

visualise(data, bins = 15, method = "simulation", dens_color = "black", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="visualize_+3A_data">data</code></td>
<td>
<p>A distribution. For simulation-based inference, a data frame
containing a distribution of <code><a href="#topic+calculate">calculate()</a></code>d statistics
or <code><a href="#topic+fit.infer">fit()</a></code>ted coefficient estimates. This object should
have been passed to <code><a href="#topic+generate">generate()</a></code> before being supplied or
<code><a href="#topic+calculate">calculate()</a></code> to <code><a href="#topic+fit.infer">fit()</a></code>. For theory-based inference,
the output of <code><a href="#topic+assume">assume()</a></code>.</p>
</td></tr>
<tr><td><code id="visualize_+3A_bins">bins</code></td>
<td>
<p>The number of bins in the histogram.</p>
</td></tr>
<tr><td><code id="visualize_+3A_method">method</code></td>
<td>
<p>A string giving the method to display. Options are
<code>"simulation"</code>, <code>"theoretical"</code>, or <code>"both"</code> with <code>"both"</code> corresponding to
<code>"simulation"</code> and <code>"theoretical"</code>. If <code>data</code> is the output of <code><a href="#topic+assume">assume()</a></code>,
this argument will be ignored and default to <code>"theoretical"</code>.</p>
</td></tr>
<tr><td><code id="visualize_+3A_dens_color">dens_color</code></td>
<td>
<p>A character or hex string specifying the color of the
theoretical density curve.</p>
</td></tr>
<tr><td><code id="visualize_+3A_...">...</code></td>
<td>
<p>Additional arguments passed along to functions in ggplot2.
For <code>method = "simulation"</code>, <code>stat_bin()</code>, and for <code>method = "theoretical"</code>,
<code>geom_path()</code>. Some values may be overwritten by infer internally.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to make the visualization workflow more straightforward
and explicit, <code>visualize()</code> now only should be used to plot distributions
of statistics directly. A number of arguments related to shading p-values and
confidence intervals are now deprecated in <code>visualize()</code> and should
now be passed to <code><a href="#topic+shade_p_value">shade_p_value()</a></code> and <code><a href="#topic+shade_confidence_interval">shade_confidence_interval()</a></code>,
respectively. <code><a href="#topic+visualize">visualize()</a></code> will raise a warning if deprecated arguments
are supplied.
</p>


<h3>Value</h3>

<p>For <code><a href="#topic+calculate">calculate()</a></code>-based workflows, a ggplot showing the simulation-based
distribution as a histogram or bar graph. Can also be used to display
theoretical distributions.
</p>
<p>For <code><a href="#topic+assume">assume()</a></code>-based workflows, a ggplot showing the theoretical distribution.
</p>
<p>For <code><a href="#topic+fit.infer">fit()</a></code>-based workflows, a <code>patchwork</code> object
showing the simulation-based distributions as a histogram or bar graph.
The interface to adjust plot options and themes is a bit different
for <code>patchwork</code> plots than ggplot2 plots. The examples highlight the
biggest differences here, but see <code><a href="patchwork.html#topic+plot_annotation">patchwork::plot_annotation()</a></code> and
<a href="patchwork.html#topic+plot_arithmetic">patchwork::&amp;.gg</a> for more details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shade_p_value">shade_p_value()</a></code>, <code><a href="#topic+shade_confidence_interval">shade_confidence_interval()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generate a null distribution
null_dist &lt;- gss %&gt;%
  # we're interested in the number of hours worked per week
  specify(response = hours) %&gt;%
  # hypothesizing that the mean is 40
  hypothesize(null = "point", mu = 40) %&gt;%
  # generating data points for a null distribution
  generate(reps = 1000, type = "bootstrap") %&gt;%
  # calculating a distribution of means
  calculate(stat = "mean")

# or a bootstrap distribution, omitting the hypothesize() step,
# for use in confidence intervals
boot_dist &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  generate(reps = 1000, type = "bootstrap") %&gt;%
  calculate(stat = "mean")

# we can easily plot the null distribution by piping into visualize
null_dist %&gt;%
  visualize()

# we can add layers to the plot as in ggplot, as well...
# find the point estimate---mean number of hours worked per week
point_estimate &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  calculate(stat = "mean")

# find a confidence interval around the point estimate
ci &lt;- boot_dist %&gt;%
  get_confidence_interval(point_estimate = point_estimate,
                          # at the 95% confidence level
                          level = .95,
                          # using the standard error method
                          type = "se")

# display a shading of the area beyond the p-value on the plot
null_dist %&gt;%
  visualize() +
  shade_p_value(obs_stat = point_estimate, direction = "two-sided")

# ...or within the bounds of the confidence interval
null_dist %&gt;%
  visualize() +
  shade_confidence_interval(ci)

# plot a theoretical sampling distribution by creating
# a theory-based distribution with `assume()`
sampling_dist &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  assume(distribution = "t")

visualize(sampling_dist)

# you can shade confidence intervals on top of
# theoretical distributions, too---the theoretical
# distribution will be recentered and rescaled to
# align with the confidence interval
visualize(sampling_dist) +
  shade_confidence_interval(ci)


# to plot both a theory-based and simulation-based null distribution,
# use a theorized statistic (i.e. one of t, z, F, or Chisq)
# and supply the simulation-based null distribution
null_dist_t &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  generate(reps = 1000, type = "bootstrap") %&gt;%
  calculate(stat = "t")

obs_stat &lt;- gss %&gt;%
  specify(response = hours) %&gt;%
  hypothesize(null = "point", mu = 40) %&gt;%
  calculate(stat = "t")

visualize(null_dist_t, method = "both")

visualize(null_dist_t, method = "both") +
  shade_p_value(obs_stat, "both")


# to visualize distributions of coefficients for multiple
# explanatory variables, use a `fit()`-based workflow

# fit 1000 models with the `hours` variable permuted
null_fits &lt;- gss %&gt;%
 specify(hours ~ age + college) %&gt;%
 hypothesize(null = "independence") %&gt;%
 generate(reps = 1000, type = "permute") %&gt;%
 fit()

null_fits

# visualize distributions of resulting coefficients
visualize(null_fits)

# the interface to add themes and other elements to patchwork
# plots (outputted by `visualize` when the inputted data
# is from the `fit()` function) is a bit different than adding
# them to ggplot2 plots.
library(ggplot2)

# to add a ggplot2 theme to a `calculate()`-based visualization, use `+`
null_dist %&gt;% visualize() + theme_dark()

# to add a ggplot2 theme to a `fit()`-based visualization, use `&amp;`
null_fits %&gt;% visualize() &amp; theme_dark()


# More in-depth explanation of how to use the infer package
## Not run: 
vignette("infer")

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
