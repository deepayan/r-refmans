<!DOCTYPE html><html><head><title>Help for package mlr3measures</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlr3measures}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mlr3measures-package'><p>mlr3measures: Performance Measures for 'mlr3'</p></a></li>
<li><a href='#acc'><p>Classification Accuracy</p></a></li>
<li><a href='#ae'><p>Absolute Error (per observation)</p></a></li>
<li><a href='#ape'><p>Absolute Percentage Error (per observation)</p></a></li>
<li><a href='#auc'><p>Area Under the ROC Curve</p></a></li>
<li><a href='#bacc'><p>Balanced Accuracy</p></a></li>
<li><a href='#bbrier'><p>Binary Brier Score</p></a></li>
<li><a href='#bias'><p>Bias</p></a></li>
<li><a href='#binary_params'><p>Binary Classification Parameters</p></a></li>
<li><a href='#ce'><p>Classification Error</p></a></li>
<li><a href='#classif_params'><p>Classification Parameters</p></a></li>
<li><a href='#confusion_matrix'><p>Calculate Binary Confusion Matrix</p></a></li>
<li><a href='#dor'><p>Diagnostic Odds Ratio</p></a></li>
<li><a href='#fbeta'><p>F-beta Score</p></a></li>
<li><a href='#fdr'><p>False Discovery Rate</p></a></li>
<li><a href='#fn'><p>False Negatives</p></a></li>
<li><a href='#fnr'><p>False Negative Rate</p></a></li>
<li><a href='#fomr'><p>False Omission Rate</p></a></li>
<li><a href='#fp'><p>False Positives</p></a></li>
<li><a href='#fpr'><p>False Positive Rate</p></a></li>
<li><a href='#jaccard'><p>Jaccard Similarity Index</p></a></li>
<li><a href='#ktau'><p>Kendall's tau</p></a></li>
<li><a href='#logloss'><p>Log Loss</p></a></li>
<li><a href='#mae'><p>Mean Absolute Error</p></a></li>
<li><a href='#mape'><p>Mean Absolute Percent Error</p></a></li>
<li><a href='#mauc_aunu'><p>Multiclass AUC Scores</p></a></li>
<li><a href='#maxae'><p>Max Absolute Error</p></a></li>
<li><a href='#maxse'><p>Max Squared Error</p></a></li>
<li><a href='#mbrier'><p>Multiclass Brier Score</p></a></li>
<li><a href='#mcc'><p>Matthews Correlation Coefficient</p></a></li>
<li><a href='#measures'><p>Measure Registry</p></a></li>
<li><a href='#medae'><p>Median Absolute Error</p></a></li>
<li><a href='#medse'><p>Median Squared Error</p></a></li>
<li><a href='#mse'><p>Mean Squared Error</p></a></li>
<li><a href='#msle'><p>Mean Squared Log Error</p></a></li>
<li><a href='#npv'><p>Negative Predictive Value</p></a></li>
<li><a href='#pbias'><p>Percent Bias</p></a></li>
<li><a href='#phi'><p>Phi Coefficient Similarity</p></a></li>
<li><a href='#ppv'><p>Positive Predictive Value</p></a></li>
<li><a href='#prauc'><p>Area Under the Precision-Recall Curve</p></a></li>
<li><a href='#rae'><p>Relative Absolute Error</p></a></li>
<li><a href='#regr_params'><p>Regression Parameters</p></a></li>
<li><a href='#rmse'><p>Root Mean Squared Error</p></a></li>
<li><a href='#rmsle'><p>Root Mean Squared Log Error</p></a></li>
<li><a href='#rrse'><p>Root Relative Squared Error</p></a></li>
<li><a href='#rse'><p>Relative Squared Error</p></a></li>
<li><a href='#rsq'><p>R Squared</p></a></li>
<li><a href='#sae'><p>Sum of Absolute Errors</p></a></li>
<li><a href='#se'><p>Squared Error (per observation)</p></a></li>
<li><a href='#similarity_params'><p>Similarity Parameters</p></a></li>
<li><a href='#sle'><p>Squared Log Error (per observation)</p></a></li>
<li><a href='#smape'><p>Symmetric Mean Absolute Percent Error</p></a></li>
<li><a href='#srho'><p>Spearman's rho</p></a></li>
<li><a href='#sse'><p>Sum of Squared Errors</p></a></li>
<li><a href='#tn'><p>True Negatives</p></a></li>
<li><a href='#tnr'><p>True Negative Rate</p></a></li>
<li><a href='#tp'><p>True Positives</p></a></li>
<li><a href='#tpr'><p>True Positive Rate</p></a></li>
<li><a href='#zero_one'><p>Zero-One Classification Loss (per observation)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Performance Measures for 'mlr3'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements multiple performance measures for
    supervised learning.  Includes over 40 measures for regression and
    classification. Additionally, meta information about the performance
    measures can be queried, e.g. what the best and worst possible
    performances scores are.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https:///mlr3measures.mlr-org.com">https:///mlr3measures.mlr-org.com</a>,
<a href="https://github.com/mlr-org/mlr3measures">https://github.com/mlr-org/mlr3measures</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mlr-org/mlr3measures/issues">https://github.com/mlr-org/mlr3measures/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate, PRROC</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Collate:</td>
<td>'assertions.R' 'bibentries.R' 'measures.R' 'binary_auc.R'
'binary_bbrier.R' 'binary_dor.R' 'binary_fbeta.R'
'binary_fdr.R' 'binary_fn.R' 'binary_fnr.R' 'binary_fomr.R'
'binary_fp.R' 'binary_fpr.R' 'binary_mcc.R' 'binary_npv.R'
'binary_ppv.R' 'binary_prauc.R' 'binary_tn.R' 'binary_tnr.R'
'binary_tp.R' 'binary_tpr.R' 'classif_acc.R' 'classif_auc.R'
'classif_bacc.R' 'classif_ce.R' 'classif_logloss.R'
'classif_mbrier.R' 'classif_zero_one.R' 'confusion_matrix.R'
'helper.R' 'regr_ae.R' 'regr_ape.R' 'regr_bias.R' 'regr_ktau.R'
'regr_mae.R' 'regr_mape.R' 'regr_maxae.R' 'regr_maxse.R'
'regr_medae.R' 'regr_medse.R' 'regr_mse.R' 'regr_msle.R'
'regr_pbias.R' 'regr_rae.R' 'regr_rmse.R' 'regr_rmsle.R'
'regr_rrse.R' 'regr_rse.R' 'regr_rsq.R' 'regr_sae.R'
'regr_se.R' 'regr_sle.R' 'regr_smape.R' 'regr_srho.R'
'regr_sse.R' 'roxygen.R' 'similarity_jaccard.R'
'similarity_phi.R' 'zzz.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-05 12:06:16 UTC; michel</td>
</tr>
<tr>
<td>Author:</td>
<td>Michel Lang <a href="https://orcid.org/0000-0001-9754-0393"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre,
    aut],
  Martin Binder [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michel Lang &lt;michellang@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-05 12:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mlr3measures-package'>mlr3measures: Performance Measures for 'mlr3'</h2><span id='topic+mlr3measures'></span><span id='topic+mlr3measures-package'></span>

<h3>Description</h3>

<p>Implements multiple performance measures for supervised learning. Includes over 40 measures for regression and classification. Additionally, meta information about the performance measures can be queried, e.g. what the best and worst possible performances scores are.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Michel Lang <a href="mailto:michellang@gmail.com">michellang@gmail.com</a> (<a href="https://orcid.org/0000-0001-9754-0393">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Martin Binder <a href="mailto:mlr.developer@mb706.com">mlr.developer@mb706.com</a> [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https:///mlr3measures.mlr-org.com">https:///mlr3measures.mlr-org.com</a>
</p>
</li>
<li> <p><a href="https://github.com/mlr-org/mlr3measures">https://github.com/mlr-org/mlr3measures</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/mlr-org/mlr3measures/issues">https://github.com/mlr-org/mlr3measures/issues</a>
</p>
</li></ul>


<hr>
<h2 id='acc'>Classification Accuracy</h2><span id='topic+acc'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in multiclass classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acc(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acc_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="acc_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the same levels and length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="acc_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="acc_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Classification Accuracy is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \left( t_i = r_i \right).
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+bacc">bacc</a>()</code>,
<code><a href="#topic+ce">ce</a>()</code>,
<code><a href="#topic+logloss">logloss</a>()</code>,
<code><a href="#topic+mauc_aunu">mauc_aunu</a>()</code>,
<code><a href="#topic+mbrier">mbrier</a>()</code>,
<code><a href="#topic+zero_one">zero_one</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b", "c")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
acc(truth, response)
</code></pre>

<hr>
<h2 id='ae'>Absolute Error (per observation)</h2><span id='topic+ae'></span>

<h3>Description</h3>

<p>Calculates the per-observation absolute error as </p>
<p style="text-align: center;"><code class="reqn">
  \left| t_i - r_i \right|.
</code>
</p>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>
<p>Note that this is an unaggregated measure, returning the losses per observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ae(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ae_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="ae_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="ae_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Performance value as <code>numeric(length(truth))</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range (per observation): <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize (per observation): <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>

<hr>
<h2 id='ape'>Absolute Percentage Error (per observation)</h2><span id='topic+ape'></span>

<h3>Description</h3>

<p>Calculates the per-observation absolute percentage error as </p>
<p style="text-align: center;"><code class="reqn">
  \left| \frac{ t_i - r_i}{t_i} \right|.
</code>
</p>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>
<p>Note that this is an unaggregated measure, returning the losses per observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ape(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ape_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="ape_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="ape_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Performance value as <code>numeric(length(truth))</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range (per observation): <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize (per observation): <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>

<hr>
<h2 id='auc'>Area Under the ROC Curve</h2><span id='topic+auc'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
probabilities
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc(truth, prob, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auc_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="auc_+3A_prob">prob</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted probability for positive class.
Must have exactly same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="auc_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="auc_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="auc_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the area under the Receiver Operator Characteristic (ROC) curve.
The AUC can be interpreted as the probability that a randomly chosen positive observation
has a higher predicted probability than a randomly chosen negative observation.
</p>
<p>This measure is undefined if the true values are either all positive or
all negative.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>prob</code>
</p>
</li></ul>



<h3>References</h3>

<p>Youden WJ (1950).
&ldquo;Index for rating diagnostic tests.&rdquo;
<em>Cancer</em>, <b>3</b>(1), 32&ndash;35.
<a href="https://doi.org/10.1002/1097-0142%281950%293%3A1%3C32%3A%3Aaid-cncr2820030106%3E3.0.co%3B2-3">doi:10.1002/1097-0142(1950)3:1&lt;32::aid-cncr2820030106&gt;3.0.co;2-3</a>.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>truth = factor(c("a", "a", "a", "b"))
prob = c(.6, .7, .1, .4)
auc(truth, prob, "a")
</code></pre>

<hr>
<h2 id='bacc'>Balanced Accuracy</h2><span id='topic+bacc'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in multiclass classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bacc(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bacc_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="bacc_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the same levels and length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="bacc_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="bacc_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Balanced Accuracy computes the weighted balanced accuracy, suitable for imbalanced data sets.
It is defined analogously to the definition in <a href="https://scikit-learn.org/">sklearn</a>.
</p>
<p>First, the sample weights <code class="reqn">w</code> are normalized per class:
</p>
<p style="text-align: center;"><code class="reqn">
 \hat{w}_i = \frac{w_i}{\sum_j 1(y_j = y_i) w_i}.
</code>
</p>

<p>The balanced accuracy is calculated as
</p>
<p style="text-align: center;"><code class="reqn">
 \frac{1}{\sum_i \hat{w}_i} \sum_i 1(r_i = t_i) \hat{w}_i.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p>Brodersen KH, Ong CS, Stephan KE, Buhmann JM (2010).
&ldquo;The Balanced Accuracy and Its Posterior Distribution.&rdquo;
In <em>2010 20th International Conference on Pattern Recognition</em>.
<a href="https://doi.org/10.1109/icpr.2010.764">doi:10.1109/icpr.2010.764</a>.
</p>
<p>Guyon I, Bennett K, Cawley G, Escalante HJ, Escalera S, Ho TK, Macia N, Ray B, Saeed M, Statnikov A, Viegas E (2015).
&ldquo;Design of the 2015 ChaLearn AutoML challenge.&rdquo;
In <em>2015 International Joint Conference on Neural Networks (IJCNN)</em>.
<a href="https://doi.org/10.1109/ijcnn.2015.7280767">doi:10.1109/ijcnn.2015.7280767</a>.
</p>


<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+acc">acc</a>()</code>,
<code><a href="#topic+ce">ce</a>()</code>,
<code><a href="#topic+logloss">logloss</a>()</code>,
<code><a href="#topic+mauc_aunu">mauc_aunu</a>()</code>,
<code><a href="#topic+mbrier">mbrier</a>()</code>,
<code><a href="#topic+zero_one">zero_one</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b", "c")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
bacc(truth, response)
</code></pre>

<hr>
<h2 id='bbrier'>Binary Brier Score</h2><span id='topic+bbrier'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
probabilities
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bbrier(truth, prob, positive, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bbrier_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="bbrier_+3A_prob">prob</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted probability for positive class.
Must have exactly same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="bbrier_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="bbrier_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="bbrier_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Binary Brier Score is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{1}{n} \sum_{i=1}^n w_i (I_i - p_i)^2.
</code>
</p>


<p>Note that this (more common) definition of the Brier score is equivalent to the
original definition of the multi-class Brier score (see <code><a href="#topic+mbrier">mbrier()</a></code>) divided by 2.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>prob</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Brier_score">https://en.wikipedia.org/wiki/Brier_score</a>
</p>
<p>Brier GW (1950).
&ldquo;Verification of forecasts expressed in terms of probability.&rdquo;
<em>Monthly Weather Review</em>, <b>78</b>(1), 1&ndash;3.
<a href="https://doi.org/10.1175/1520-0493%281950%29078%3C0001%3Avofeit%3E2.0.co%3B2">doi:10.1175/1520-0493(1950)078&lt;0001:vofeit&gt;2.0.co;2</a>.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
prob = runif(10)
bbrier(truth, prob, positive = "a")
</code></pre>

<hr>
<h2 id='bias'>Bias</h2><span id='topic+bias'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bias_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="bias_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="bias_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="bias_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bias is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \left( t_i - r_i \right).
</code>
</p>

<p>Good predictions score close to 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">(-\infty, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>NA</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
bias(truth, response)
</code></pre>

<hr>
<h2 id='binary_params'>Binary Classification Parameters</h2><span id='topic+binary_params'></span>

<h3>Description</h3>

<p>Binary Classification Parameters
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="binary_params_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="binary_params_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="binary_params_+3A_prob">prob</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted probability for positive class.
Must have exactly same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="binary_params_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="binary_params_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="binary_params_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="binary_params_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='ce'>Classification Error</h2><span id='topic+ce'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in multiclass classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ce(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ce_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="ce_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the same levels and length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="ce_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="ce_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Classification Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \left( t_i \neq r_i \right).
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+acc">acc</a>()</code>,
<code><a href="#topic+bacc">bacc</a>()</code>,
<code><a href="#topic+logloss">logloss</a>()</code>,
<code><a href="#topic+mauc_aunu">mauc_aunu</a>()</code>,
<code><a href="#topic+mbrier">mbrier</a>()</code>,
<code><a href="#topic+zero_one">zero_one</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b", "c")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
ce(truth, response)
</code></pre>

<hr>
<h2 id='classif_params'>Classification Parameters</h2><span id='topic+classif_params'></span>

<h3>Description</h3>

<p>Classification Parameters
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="classif_params_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="classif_params_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the same levels and length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="classif_params_+3A_prob">prob</code></td>
<td>
<p>(<code>matrix()</code>)<br />
Matrix of predicted probabilities, each column is a vector of probabilities for a
specific class label.
Columns must be named with levels of <code>truth</code>.</p>
</td></tr>
<tr><td><code id="classif_params_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="classif_params_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="classif_params_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='confusion_matrix'>Calculate Binary Confusion Matrix</h2><span id='topic+confusion_matrix'></span>

<h3>Description</h3>

<p>Calculates the confusion matrix for a binary classification problem
once and then calculates all confusion measures of this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion_matrix(truth, response, positive, na_value = NaN, relative = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion_matrix_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_relative">relative</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code>, the returned confusion matrix contains relative frequencies
instead of absolute frequencies.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with two elements:
</p>

<ul>
<li> <p><code>matrix</code> stores the calculated confusion matrix.
</p>
</li>
<li> <p><code>measures</code> stores the metrics as named numeric vector.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
lvls = c("a", "b")
truth = factor(sample(lvls, 20, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 20, replace = TRUE), levels = lvls)

confusion_matrix(truth, response, positive = "a")
confusion_matrix(truth, response, positive = "a", relative = TRUE)
confusion_matrix(truth, response, positive = "b")
</code></pre>

<hr>
<h2 id='dor'>Diagnostic Odds Ratio</h2><span id='topic+dor'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dor(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dor_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="dor_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="dor_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="dor_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="dor_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Diagnostic Odds Ratio is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{TP}/\mathrm{FP}}{\mathrm{FN}/\mathrm{TN}}.
</code>
</p>

<p>This measure is undefined if FP = 0 or FN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
dor(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fbeta'>F-beta Score</h2><span id='topic+fbeta'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbeta(truth, response, positive, beta = 1, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fbeta_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fbeta_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fbeta_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fbeta_+3A_beta">beta</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Parameter to give either precision or recall more weight.
Default is 1, resulting in balanced weights.</p>
</td></tr>
<tr><td><code id="fbeta_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="fbeta_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With <code class="reqn">P</code> as <code><a href="#topic+precision">precision()</a></code> and <code class="reqn">R</code> as <code><a href="#topic+recall">recall()</a></code>, the F-beta Score is defined as </p>
<p style="text-align: center;"><code class="reqn">
   (1 + \beta^2) \frac{P \cdot R}{(\beta^2 P) + R}.
</code>
</p>

<p>It measures the effectiveness of retrieval with respect to a user who attaches <code class="reqn">\beta</code> times
as much importance to recall as precision.
For <code class="reqn">\beta = 1</code>, this measure is called &quot;F1&quot; score.
</p>
<p>This measure is undefined if <a href="#topic+precision">precision</a> or <a href="#topic+recall">recall</a> is undefined, i.e. TP + FP = 0 or TP + FN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p>Rijsbergen, Van CJ (1979).
<em>Information Retrieval</em>, 2nd edition.
Butterworth-Heinemann, Newton, MA, USA.
ISBN 408709294.
</p>
<p>Goutte C, Gaussier E (2005).
&ldquo;A Probabilistic Interpretation of Precision,  Recall and F-Score,  with Implication for Evaluation.&rdquo;
In <em>Lecture Notes in Computer Science</em>, 345&ndash;359.
<a href="https://doi.org/10.1007/978-3-540-31865-1_25">doi:10.1007/978-3-540-31865-1_25</a>.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fbeta(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fdr'>False Discovery Rate</h2><span id='topic+fdr'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdr(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fdr_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fdr_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fdr_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fdr_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="fdr_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The False Discovery Rate is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{FP}}{\mathrm{TP} + \mathrm{FP}}.
</code>
</p>

<p>This measure is undefined if TP + FP = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fdr(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fn'>False Negatives</h2><span id='topic+fn'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fn(truth, response, positive, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fn_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fn_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fn_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fn_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This measure counts the false negatives (type 2 error), i.e. the number of
predictions indicating a negative class label while in fact it is positive.
This is sometimes also called a &quot;false alarm&quot;.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fn(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fnr'>False Negative Rate</h2><span id='topic+fnr'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnr(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fnr_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fnr_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fnr_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fnr_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="fnr_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The False Negative Rate is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{FN}}{\mathrm{TP} + \mathrm{FN}}.
</code>
</p>

<p>Also know as &quot;miss rate&quot;.
</p>
<p>This measure is undefined if TP + FN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fnr(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fomr'>False Omission Rate</h2><span id='topic+fomr'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fomr(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fomr_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fomr_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fomr_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fomr_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="fomr_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The False Omission Rate is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{FN}}{\mathrm{FN} + \mathrm{TN}}.
</code>
</p>

<p>This measure is undefined if FN + TN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fomr(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fp'>False Positives</h2><span id='topic+fp'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fp(truth, response, positive, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fp_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fp_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fp_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fp_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This measure counts the false positives (type 1 error), i.e. the number of
predictions indicating a positive class label while in fact it is negative.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fp(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='fpr'>False Positive Rate</h2><span id='topic+fpr'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpr(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpr_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="fpr_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="fpr_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="fpr_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="fpr_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The False Positive Rate is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}}.
</code>
</p>

<p>Also know as fall out or probability of false alarm.
</p>
<p>This measure is undefined if FP + TN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
fpr(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='jaccard'>Jaccard Similarity Index</h2><span id='topic+jaccard'></span>

<h3>Description</h3>

<p>Measure to compare two or more sets w.r.t. their similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jaccard(sets, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jaccard_+3A_sets">sets</code></td>
<td>
<p>(<code>list()</code>)<br />
List of character or integer vectors.
<code>sets</code> must have at least 2 elements.</p>
</td></tr>
<tr><td><code id="jaccard_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="jaccard_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For two sets <code class="reqn">A</code> and <code class="reqn">B</code>, the Jaccard Index is defined as
</p>
<p style="text-align: center;"><code class="reqn">
  J(A, B) = \frac{|A \cap B|}{|A \cup B|}.
</code>
</p>

<p>If more than two sets are provided, the mean of all pairwise scores
is calculated.
</p>
<p>This measure is undefined if two or more sets are empty.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"similarity"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li></ul>



<h3>References</h3>

<p>Jaccard, Paul (1901).
&ldquo;Étude comparative de la distribution florale dans une portion des Alpes et du Jura.&rdquo;
<em>Bulletin de la Société Vaudoise des Sciences Naturelles</em>, <b>37</b>, 547-579.
<a href="https://doi.org/10.5169/SEALS-266450">doi:10.5169/SEALS-266450</a>.
</p>
<p>Bommert A, Rahnenführer J, Lang M (2017).
&ldquo;A Multicriteria Approach to Find Predictive and Sparse Models with Stable Feature Selection for High-Dimensional Data.&rdquo;
<em>Computational and Mathematical Methods in Medicine</em>, <b>2017</b>, 1&ndash;18.
<a href="https://doi.org/10.1155/2017/7907163">doi:10.1155/2017/7907163</a>.
</p>
<p>Bommert A, Lang M (2021).
&ldquo;stabm: Stability Measures for Feature Selection.&rdquo;
<em>Journal of Open Source Software</em>, <b>6</b>(59), 3010.
<a href="https://doi.org/10.21105/joss.03010">doi:10.21105/joss.03010</a>.
</p>


<h3>See Also</h3>

<p>Package <a href="https://CRAN.R-project.org/package=stabm"><span class="pkg">stabm</span></a> which implements many more stability measures with included
correction for chance.
</p>
<p>Other Similarity Measures: 
<code><a href="#topic+phi">phi</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
sets = list(
  sample(letters[1:3], 1),
  sample(letters[1:3], 2)
)
jaccard(sets)
</code></pre>

<hr>
<h2 id='ktau'>Kendall's tau</h2><span id='topic+ktau'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ktau(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ktau_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="ktau_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="ktau_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kendall's tau is defined as Kendall's rank correlation coefficient between truth and response.
Calls <code><a href="stats.html#topic+cor">stats::cor()</a></code> with <code>method</code> set to <code>"kendall"</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[-1, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p>Rosset S, Perlich C, Zadrozny B (2006).
&ldquo;Ranking-based evaluation of regression models.&rdquo;
<em>Knowledge and Information Systems</em>, <b>12</b>(3), 331&ndash;353.
<a href="https://doi.org/10.1007/s10115-006-0037-3">doi:10.1007/s10115-006-0037-3</a>.
</p>


<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
ktau(truth, response)
</code></pre>

<hr>
<h2 id='logloss'>Log Loss</h2><span id='topic+logloss'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
probabilities
in multiclass classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logloss(truth, prob, sample_weights = NULL, eps = 1e-15, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logloss_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="logloss_+3A_prob">prob</code></td>
<td>
<p>(<code>matrix()</code>)<br />
Matrix of predicted probabilities, each column is a vector of probabilities for a
specific class label.
Columns must be named with levels of <code>truth</code>.</p>
</td></tr>
<tr><td><code id="logloss_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="logloss_+3A_eps">eps</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Probabilities are clipped to <code>max(eps, min(1 - eps, p))</code>.
Otherwise the measure would be undefined for probabilities <code>p = 0</code> and <code>p = 1</code>.</p>
</td></tr>
<tr><td><code id="logloss_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Log Loss is defined as </p>
<p style="text-align: center;"><code class="reqn">
  -\frac{1}{n} \sum_{i=1}^n w_i \log \left(  p_i \right )
</code>
</p>

<p>where <code class="reqn">p_i</code> is the probability for the true class of observation <code class="reqn">i</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>prob</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+acc">acc</a>()</code>,
<code><a href="#topic+bacc">bacc</a>()</code>,
<code><a href="#topic+ce">ce</a>()</code>,
<code><a href="#topic+mauc_aunu">mauc_aunu</a>()</code>,
<code><a href="#topic+mbrier">mbrier</a>()</code>,
<code><a href="#topic+zero_one">zero_one</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b", "c")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
prob = matrix(runif(3 * 10), ncol = 3, dimnames = list(NULL, lvls))
prob = t(apply(prob, 1, function(x) x / sum(x)))
logloss(truth, prob)
</code></pre>

<hr>
<h2 id='mae'>Mean Absolute Error</h2><span id='topic+mae'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mae(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mae_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="mae_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="mae_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="mae_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mean Absolute Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \left| t_i - r_i \right|.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
mae(truth, response)
</code></pre>

<hr>
<h2 id='mape'>Mean Absolute Percent Error</h2><span id='topic+mape'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mape(truth, response, sample_weights = NULL, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mape_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="mape_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="mape_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="mape_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="mape_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mean Absolute Percent Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \left| \frac{ t_i - r_i}{t_i} \right|.
 </code>
</p>

<p>This measure is undefined if any element of <code class="reqn">t</code> is <code class="reqn">0</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p>de Myttenaere, Arnaud, Golden, Boris, Le Grand, Bénédicte, Rossi, Fabrice (2016).
&ldquo;Mean Absolute Percentage Error for regression models.&rdquo;
<em>Neurocomputing</em>, <b>192</b>, 38-48.
ISSN 0925-2312, <a href="https://doi.org/10.1016/j.neucom.2015.12.114">doi:10.1016/j.neucom.2015.12.114</a>.
</p>


<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
mape(truth, response)
</code></pre>

<hr>
<h2 id='mauc_aunu'>Multiclass AUC Scores</h2><span id='topic+mauc_aunu'></span><span id='topic+mauc_aunp'></span><span id='topic+mauc_au1u'></span><span id='topic+mauc_au1p'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
probabilities
in multiclass classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mauc_aunu(truth, prob, na_value = NaN, ...)

mauc_aunp(truth, prob, na_value = NaN, ...)

mauc_au1u(truth, prob, na_value = NaN, ...)

mauc_au1p(truth, prob, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mauc_aunu_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="mauc_aunu_+3A_prob">prob</code></td>
<td>
<p>(<code>matrix()</code>)<br />
Matrix of predicted probabilities, each column is a vector of probabilities for a
specific class label.
Columns must be named with levels of <code>truth</code>.</p>
</td></tr>
<tr><td><code id="mauc_aunu_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="mauc_aunu_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multiclass AUC measures.
</p>

<ul>
<li> <p><em>AUNU</em>: AUC of each class against the rest, using the uniform class
distribution. Computes the AUC treating a <code>c</code>-dimensional classifier
as <code>c</code> two-dimensional 1-vs-rest classifiers, where classes are assumed to have
uniform distribution, in order to have a measure which is independent
of class distribution change (Fawcett 2001).
</p>
</li>
<li> <p><em>AUNP</em>: AUC of each class against the rest, using the a-priori class
distribution. Computes the AUC treating a <code>c</code>-dimensional classifier as <code>c</code>
two-dimensional 1-vs-rest classifiers, taking into account the prior probability of
each class (Fawcett 2001).
</p>
</li>
<li> <p><em>AU1U</em>: AUC of each class against each other, using the uniform class
distribution. Computes something like the AUC of <code>c(c - 1)</code> binary classifiers
(all possible pairwise combinations). See Hand (2001) for details.
</p>
</li>
<li> <p><em>AU1P</em>: AUC of each class against each other, using the a-priori class
distribution. Computes something like AUC of <code>c(c - 1)</code> binary classifiers
while considering the a-priori distribution of the classes as suggested
in Ferri (2009). Note we deviate from the definition in
Ferri (2009) by a factor of <code>c</code>.
The person implementing this function and writing this very
documentation right now cautions against using this measure because it is
an imperfect generalization of AU1U.
</p>
</li></ul>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>prob</code>
</p>
</li></ul>



<h3>References</h3>

<p>Fawcett, Tom (2001).
&ldquo;Using rule sets to maximize ROC performance.&rdquo;
In <em>Proceedings 2001 IEEE international conference on data mining</em>, 131&ndash;138.
IEEE.
</p>
<p>Ferri, César, Hernández-Orallo, José, Modroiu, R (2009).
&ldquo;An experimental comparison of performance measures for classification.&rdquo;
<em>Pattern Recognition Letters</em>, <b>30</b>(1), 27&ndash;38.
<a href="https://doi.org/10.1016/j.patrec.2008.08.010">doi:10.1016/j.patrec.2008.08.010</a>.
</p>
<p>Hand, J D, Till, J R (2001).
&ldquo;A simple generalisation of the area under the ROC curve for multiple class classification problems.&rdquo;
<em>Machine learning</em>, <b>45</b>(2), 171&ndash;186.
</p>


<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+acc">acc</a>()</code>,
<code><a href="#topic+bacc">bacc</a>()</code>,
<code><a href="#topic+ce">ce</a>()</code>,
<code><a href="#topic+logloss">logloss</a>()</code>,
<code><a href="#topic+mbrier">mbrier</a>()</code>,
<code><a href="#topic+zero_one">zero_one</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b", "c")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
prob = matrix(runif(3 * 10), ncol = 3)
colnames(prob) = levels(truth)
mauc_aunu(truth, prob)
</code></pre>

<hr>
<h2 id='maxae'>Max Absolute Error</h2><span id='topic+maxae'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxae(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxae_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="maxae_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="maxae_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Max Absolute Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \max \left( \left| t_i - r_i \right| \right).
 </code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
maxae(truth, response)
</code></pre>

<hr>
<h2 id='maxse'>Max Squared Error</h2><span id='topic+maxse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxse(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="maxse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="maxse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Max Squared Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \max \left( t_i - r_i \right)^2.
 </code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
maxse(truth, response)
</code></pre>

<hr>
<h2 id='mbrier'>Multiclass Brier Score</h2><span id='topic+mbrier'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
probabilities
in multiclass classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mbrier(truth, prob, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mbrier_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="mbrier_+3A_prob">prob</code></td>
<td>
<p>(<code>matrix()</code>)<br />
Matrix of predicted probabilities, each column is a vector of probabilities for a
specific class label.
Columns must be named with levels of <code>truth</code>.</p>
</td></tr>
<tr><td><code id="mbrier_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Brier score for multi-class classification problems with <code class="reqn">r</code> labels defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{1}{n} \sum_{i=1}^n \sum_{j=1}^r (I_{ij} - p_{ij})^2.
</code>
</p>

<p><code class="reqn">I_{ij}</code> is 1 if observation <code class="reqn">i</code> has true label <code class="reqn">j</code>, and 0 otherwise.
</p>
<p>Note that there also is the more common definition of the Brier score for binary
classification problems in <code><a href="#topic+bbrier">bbrier()</a></code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 2]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>prob</code>
</p>
</li></ul>



<h3>References</h3>

<p>Brier GW (1950).
&ldquo;Verification of forecasts expressed in terms of probability.&rdquo;
<em>Monthly Weather Review</em>, <b>78</b>(1), 1&ndash;3.
<a href="https://doi.org/10.1175/1520-0493%281950%29078%3C0001%3Avofeit%3E2.0.co%3B2">doi:10.1175/1520-0493(1950)078&lt;0001:vofeit&gt;2.0.co;2</a>.
</p>


<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+acc">acc</a>()</code>,
<code><a href="#topic+bacc">bacc</a>()</code>,
<code><a href="#topic+ce">ce</a>()</code>,
<code><a href="#topic+logloss">logloss</a>()</code>,
<code><a href="#topic+mauc_aunu">mauc_aunu</a>()</code>,
<code><a href="#topic+zero_one">zero_one</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b", "c")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
prob = matrix(runif(3 * 10), ncol = 3)
colnames(prob) = levels(truth)
mbrier(truth, prob)
</code></pre>

<hr>
<h2 id='mcc'>Matthews Correlation Coefficient</h2><span id='topic+mcc'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcc(truth, response, positive, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcc_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="mcc_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="mcc_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="mcc_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Matthews Correlation Coefficient is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{TP} \cdot \mathrm{TN} - \mathrm{FP} \cdot \mathrm{FN}}{\sqrt{(\mathrm{TP} + \mathrm{FP}) (\mathrm{TP} + \mathrm{FN}) (\mathrm{TN} + \mathrm{FP}) (\mathrm{TN} + \mathrm{FN})}}.
</code>
</p>

<p>This above formula is undefined if any of the four sums in the denominator is 0.
The denominator is then set to 1.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[-1, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p>Matthews BW (1975).
&ldquo;Comparison of the predicted and observed secondary structure of T4 phage lysozyme.&rdquo;
<em>Biochimica et Biophysica Acta (BBA) - Protein Structure</em>, <b>405</b>(2), 442&ndash;451.
<a href="https://doi.org/10.1016/0005-2795%2875%2990109-9">doi:10.1016/0005-2795(75)90109-9</a>.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
mcc(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='measures'>Measure Registry</h2><span id='topic+measures'></span>

<h3>Description</h3>

<p>The <code><a href="base.html#topic+environment">environment()</a></code> <code>measures</code> keeps track of all measures in this package.
It stores meta information such as minimum, maximum or if the
measure must be minimized or maximized.
The following information is available for each measure:
</p>

<ul>
<li> <p><code>id</code>: Name of the measure.
</p>
</li>
<li> <p><code>title</code>: Short descriptive title.
</p>
</li>
<li> <p><code>type</code>: <code>"binary"</code> for binary classification, <code>"classif"</code> for binary or multi-class classification,
<code>"regr"</code> for regression and <code>"similarity"</code> for similarity measures.
</p>
</li>
<li> <p><code>lower</code>: lower bound.
</p>
</li>
<li> <p><code>upper</code>: upper bound.
</p>
</li>
<li> <p><code>predict_type</code>: prediction type the measure operates on.
<code>"response"</code> corresponds to class labels for classification and the numeric response for regression.
<code>"prob"</code> corresponds to class probabilities, provided as a matrix with class labels as column names.
<code>"se"</code> corresponds to to the vector of predicted standard errors for regression.
</p>
</li>
<li> <p><code>minimize</code>: If <code>TRUE</code> or <code>FALSE</code>, the objective is to minimize or maximize the measure, respectively.
Can also be <code>NA</code>.
</p>
</li>
<li> <p><code>obs_loss</code>: Name of the function which is called to calculate the (unaggregated) loss per observation.
</p>
</li>
<li> <p><code>aggregated</code>: If <code>TRUE</code>, this function aggregates the losses to a single numeric value.
Otherwise, a vector of losses is returned.
</p>
</li>
<li> <p><code>sample_weights</code>: If <code>TRUE</code>, it is possible calculate a weighted measure.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>measures
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 59.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>names(measures)
measures$tpr
</code></pre>

<hr>
<h2 id='medae'>Median Absolute Error</h2><span id='topic+medae'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medae(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="medae_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="medae_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="medae_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Median Absolute Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \mathop{\mathrm{median}}_i \left| t_i - r_i \right|.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
medae(truth, response)
</code></pre>

<hr>
<h2 id='medse'>Median Squared Error</h2><span id='topic+medse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medse(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="medse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="medse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="medse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Median Squared Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \mathop{\mathrm{median}}_i \left[ \left( t_i - r_i \right)^2 \right].
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
medse(truth, response)
</code></pre>

<hr>
<h2 id='mse'>Mean Squared Error</h2><span id='topic+mse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="mse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="mse_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="mse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mean Squared Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} w_i \sum_{i=1}^n \left( t_i - r_i \right)^2.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
mse(truth, response)
</code></pre>

<hr>
<h2 id='msle'>Mean Squared Log Error</h2><span id='topic+msle'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msle(truth, response, sample_weights = NULL, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msle_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="msle_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="msle_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="msle_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="msle_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mean Squared Log Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \left( \ln (1 + t_i) - \ln (1 + r_i) \right)^2.
</code>
</p>

<p>This measure is undefined if any element of <code class="reqn">t</code> or <code class="reqn">r</code> is less than or equal to <code class="reqn">-1</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
msle(truth, response)
</code></pre>

<hr>
<h2 id='npv'>Negative Predictive Value</h2><span id='topic+npv'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npv(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npv_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="npv_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="npv_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="npv_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="npv_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Negative Predictive Value is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{TN}}{\mathrm{FN} + \mathrm{TN}}.
</code>
</p>

<p>This measure is undefined if FN + TN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
npv(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='pbias'>Percent Bias</h2><span id='topic+pbias'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbias(truth, response, sample_weights = NULL, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbias_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="pbias_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="pbias_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="pbias_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="pbias_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Percent Bias is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{n} \sum_{i=1}^n w_i \frac{\left( t_i - r_i \right)}{\left| t_i \right|}.
</code>
</p>

<p>Good predictions score close to 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">(-\infty, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>NA</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
pbias(truth, response)
</code></pre>

<hr>
<h2 id='phi'>Phi Coefficient Similarity</h2><span id='topic+phi'></span>

<h3>Description</h3>

<p>Measure to compare two or more sets w.r.t. their similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phi(sets, p, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phi_+3A_sets">sets</code></td>
<td>
<p>(<code>list()</code>)<br />
List of character or integer vectors.
<code>sets</code> must have at least 2 elements.</p>
</td></tr>
<tr><td><code id="phi_+3A_p">p</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Total number of possible elements.</p>
</td></tr>
<tr><td><code id="phi_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="phi_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Phi Coefficient is defined as the Pearson correlation between the binary
representation of two sets <code class="reqn">A</code> and <code class="reqn">B</code>.
The binary representation for <code class="reqn">A</code> is a logical vector of
length <code class="reqn">p</code> with the i-th element being 1 if the corresponding
element is in <code class="reqn">A</code>, and 0 otherwise.
</p>
<p>If more than two sets are provided, the mean of all pairwise scores
is calculated.
</p>
<p>This measure is undefined if one set contains none or all possible elements.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"similarity"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[-1, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li></ul>



<h3>References</h3>

<p>Nogueira S, Brown G (2016).
&ldquo;Measuring the Stability of Feature Selection.&rdquo;
In <em>Machine Learning and Knowledge Discovery in Databases</em>, 442&ndash;457.
Springer International Publishing.
<a href="https://doi.org/10.1007/978-3-319-46227-1_28">doi:10.1007/978-3-319-46227-1_28</a>.
</p>
<p>Bommert A, Rahnenführer J, Lang M (2017).
&ldquo;A Multicriteria Approach to Find Predictive and Sparse Models with Stable Feature Selection for High-Dimensional Data.&rdquo;
<em>Computational and Mathematical Methods in Medicine</em>, <b>2017</b>, 1&ndash;18.
<a href="https://doi.org/10.1155/2017/7907163">doi:10.1155/2017/7907163</a>.
</p>
<p>Bommert A, Lang M (2021).
&ldquo;stabm: Stability Measures for Feature Selection.&rdquo;
<em>Journal of Open Source Software</em>, <b>6</b>(59), 3010.
<a href="https://doi.org/10.21105/joss.03010">doi:10.21105/joss.03010</a>.
</p>


<h3>See Also</h3>

<p>Package <a href="https://CRAN.R-project.org/package=stabm"><span class="pkg">stabm</span></a> which implements many more stability measures with included
correction for chance.
</p>
<p>Other Similarity Measures: 
<code><a href="#topic+jaccard">jaccard</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
sets = list(
  sample(letters[1:3], 1),
  sample(letters[1:3], 2)
)
phi(sets, p = 3)
</code></pre>

<hr>
<h2 id='ppv'>Positive Predictive Value</h2><span id='topic+ppv'></span><span id='topic+precision'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppv(truth, response, positive, na_value = NaN, ...)

precision(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppv_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="ppv_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="ppv_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="ppv_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="ppv_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Positive Predictive Value is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}.
</code>
</p>

<p>Also know as &quot;precision&quot;.
</p>
<p>This measure is undefined if TP + FP = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>
<p>Goutte C, Gaussier E (2005).
&ldquo;A Probabilistic Interpretation of Precision,  Recall and F-Score,  with Implication for Evaluation.&rdquo;
In <em>Lecture Notes in Computer Science</em>, 345&ndash;359.
<a href="https://doi.org/10.1007/978-3-540-31865-1_25">doi:10.1007/978-3-540-31865-1_25</a>.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
ppv(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='prauc'>Area Under the Precision-Recall Curve</h2><span id='topic+prauc'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
probabilities
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prauc(truth, prob, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prauc_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="prauc_+3A_prob">prob</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted probability for positive class.
Must have exactly same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="prauc_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="prauc_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="prauc_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the area under the Precision-Recall curve (PRC).
The PRC can be interpreted as the relationship between precision and recall (sensitivity),
and is considered to be a more appropriate measure for unbalanced datasets than the ROC curve.
The PRC is computed by integration of the piecewise function.
</p>
<p>This measure is undefined if the true values are either all positive or
all negative.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>prob</code>
</p>
</li></ul>



<h3>References</h3>

<p>Davis J, Goadrich M (2006).
&ldquo;The relationship between precision-recall and ROC curves.&rdquo;
In <em>Proceedings of the 23rd International Conference on Machine Learning</em>.
ISBN 9781595933836.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>truth = factor(c("a", "a", "a", "b"))
prob = c(.6, .7, .1, .4)
prauc(truth, prob, "a")
</code></pre>

<hr>
<h2 id='rae'>Relative Absolute Error</h2><span id='topic+rae'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rae(truth, response, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rae_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="rae_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="rae_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="rae_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Relative Absolute Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{\sum_{i=1}^n \left| t_i - r_i \right|}{\sum_{i=1}^n \left| t_i - \bar{t} \right|}.
</code>
</p>

<p>Can be interpreted as absolute error of the predictions relative to a naive model predicting the mean.
</p>
<p>This measure is undefined for constant <code class="reqn">t</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
rae(truth, response)
</code></pre>

<hr>
<h2 id='regr_params'>Regression Parameters</h2><span id='topic+regr_params'></span>

<h3>Description</h3>

<p>Regression Parameters
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="regr_params_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="regr_params_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="regr_params_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="regr_params_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="regr_params_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='rmse'>Root Mean Squared Error</h2><span id='topic+rmse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmse(truth, response, sample_weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="rmse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="rmse_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="rmse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Root Mean Squared Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \sqrt{\frac{1}{n} \sum_{i=1}^n w_i \left( t_i - r_i \right)^2}.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
rmse(truth, response)
</code></pre>

<hr>
<h2 id='rmsle'>Root Mean Squared Log Error</h2><span id='topic+rmsle'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmsle(truth, response, sample_weights = NULL, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmsle_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="rmsle_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="rmsle_+3A_sample_weights">sample_weights</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Vector of non-negative and finite sample weights.
Must have the same length as <code>truth</code>.
The vector gets automatically normalized to sum to one.
Defaults to equal sample weights.</p>
</td></tr>
<tr><td><code id="rmsle_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="rmsle_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Root Mean Squared Log Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \sqrt{\frac{1}{n} \sum_{i=1}^n w_i \left( \ln (1 + t_i) - \ln (1 + r_i) \right)^2}.
</code>
</p>

<p>This measure is undefined if any element of <code class="reqn">t</code> or <code class="reqn">r</code> is less than or equal to <code class="reqn">-1</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
rmsle(truth, response)
</code></pre>

<hr>
<h2 id='rrse'>Root Relative Squared Error</h2><span id='topic+rrse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrse(truth, response, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="rrse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="rrse_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="rrse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Root Relative Squared Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \sqrt{\frac{\sum_{i=1}^n \left( t_i - r_i \right)^2}{\sum_{i=1}^n \left( t_i - \bar{t} \right)^2}}.
</code>
</p>

<p>Can be interpreted as root of the squared error of the predictions relative to a naive model predicting the mean.
</p>
<p>This measure is undefined for constant <code class="reqn">t</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
rrse(truth, response)
</code></pre>

<hr>
<h2 id='rse'>Relative Squared Error</h2><span id='topic+rse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rse(truth, response, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="rse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="rse_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="rse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Relative Squared Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{\sum_{i=1}^n \left( t_i - r_i \right)^2}{\sum_{i=1}^n \left( t_i - \bar{t} \right)^2}.
</code>
</p>

<p>Can be interpreted as squared error of the predictions relative to a naive model predicting the mean.
</p>
<p>This measure is undefined for constant <code class="reqn">t</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
rse(truth, response)
</code></pre>

<hr>
<h2 id='rsq'>R Squared</h2><span id='topic+rsq'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsq(truth, response, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsq_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="rsq_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="rsq_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="rsq_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>R Squared is defined as </p>
<p style="text-align: center;"><code class="reqn">
  1 - \frac{\sum_{i=1}^n \left( t_i - r_i \right)^2}{\sum_{i=1}^n \left( t_i - \bar{t} \right)^2}.
</code>
</p>

<p>Also known as coefficient of determination or explained variation.
Subtracts the <code><a href="#topic+rse">rse()</a></code> from 1, hence it compares the squared error of
the predictions relative to a naive model predicting the mean.
</p>
<p>This measure is undefined for constant <code class="reqn">t</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">(-\infty, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
rsq(truth, response)
</code></pre>

<hr>
<h2 id='sae'>Sum of Absolute Errors</h2><span id='topic+sae'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sae(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sae_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="sae_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="sae_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Sum of Absolute Errors is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \sum_{i=1}^n \left| t_i - r_i \right|.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
sae(truth, response)
</code></pre>

<hr>
<h2 id='se'>Squared Error (per observation)</h2><span id='topic+se'></span>

<h3>Description</h3>

<p>Calculates the per-observation squared error as </p>
<p style="text-align: center;"><code class="reqn">
  \left( t_i - r_i \right)^2.
</code>
</p>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>
<p>Note that this is an unaggregated measure, returning the losses per observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>se(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="se_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="se_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="se_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Performance value as <code>numeric(length(truth))</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range (per observation): <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize (per observation): <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>

<hr>
<h2 id='similarity_params'>Similarity Parameters</h2><span id='topic+similarity_params'></span>

<h3>Description</h3>

<p>Similarity Parameters
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="similarity_params_+3A_sets">sets</code></td>
<td>
<p>(<code>list()</code>)<br />
List of character or integer vectors.
<code>sets</code> must have at least 2 elements.</p>
</td></tr>
<tr><td><code id="similarity_params_+3A_p">p</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Total number of possible elements.</p>
</td></tr>
<tr><td><code id="similarity_params_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="similarity_params_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='sle'>Squared Log Error (per observation)</h2><span id='topic+sle'></span>

<h3>Description</h3>

<p>Calculates the per-observation squared error as </p>
<p style="text-align: center;"><code class="reqn">
  \left( \ln (1 + t_i) - \ln (1 + r_i) \right)^2.
</code>
</p>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>
<p>Note that this is an unaggregated measure, returning the losses per observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sle(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sle_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="sle_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="sle_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Performance value as <code>numeric(length(truth))</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range (per observation): <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize (per observation): <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>

<hr>
<h2 id='smape'>Symmetric Mean Absolute Percent Error</h2><span id='topic+smape'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smape(truth, response, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smape_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="smape_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="smape_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="smape_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Symmetric Mean Absolute Percent Error is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{2}{n} \sum_{i=1}^n \frac{\left| t_i - r_i \right|}{\left| t_i \right| + \left| r_i \right|}.
</code>
</p>

<p>This measure is undefined if if any <code class="reqn">|t| + |r|</code> is <code class="reqn">0</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 2]</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
smape(truth, response)
</code></pre>

<hr>
<h2 id='srho'>Spearman's rho</h2><span id='topic+srho'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>srho(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="srho_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="srho_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="srho_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Spearman's rho is defined as Spearman's rank correlation coefficient between truth and response.
Calls <code><a href="stats.html#topic+cor">stats::cor()</a></code> with <code>method</code> set to <code>"spearman"</code>.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[-1, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p>Rosset S, Perlich C, Zadrozny B (2006).
&ldquo;Ranking-based evaluation of regression models.&rdquo;
<em>Knowledge and Information Systems</em>, <b>12</b>(3), 331&ndash;353.
<a href="https://doi.org/10.1007/s10115-006-0037-3">doi:10.1007/s10115-006-0037-3</a>.
</p>


<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+sse">sse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
srho(truth, response)
</code></pre>

<hr>
<h2 id='sse'>Sum of Squared Errors</h2><span id='topic+sse'></span>

<h3>Description</h3>

<p>Measure to compare true observed response with predicted response in regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sse(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sse_+3A_truth">truth</code></td>
<td>
<p>(<code>numeric()</code>)<br />
True (observed) values.
Must have the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="sse_+3A_response">response</code></td>
<td>
<p>(<code>numeric()</code>)<br />
Predicted response values.
Must have the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="sse_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Sum of Squared Errors is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \sum_{i=1}^n \left( t_i - r_i \right)^2.
</code>
</p>



<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"regr"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Regression Measures: 
<code><a href="#topic+ae">ae</a>()</code>,
<code><a href="#topic+ape">ape</a>()</code>,
<code><a href="#topic+bias">bias</a>()</code>,
<code><a href="#topic+ktau">ktau</a>()</code>,
<code><a href="#topic+mae">mae</a>()</code>,
<code><a href="#topic+mape">mape</a>()</code>,
<code><a href="#topic+maxae">maxae</a>()</code>,
<code><a href="#topic+maxse">maxse</a>()</code>,
<code><a href="#topic+medae">medae</a>()</code>,
<code><a href="#topic+medse">medse</a>()</code>,
<code><a href="#topic+mse">mse</a>()</code>,
<code><a href="#topic+msle">msle</a>()</code>,
<code><a href="#topic+pbias">pbias</a>()</code>,
<code><a href="#topic+rae">rae</a>()</code>,
<code><a href="#topic+rmse">rmse</a>()</code>,
<code><a href="#topic+rmsle">rmsle</a>()</code>,
<code><a href="#topic+rrse">rrse</a>()</code>,
<code><a href="#topic+rse">rse</a>()</code>,
<code><a href="#topic+rsq">rsq</a>()</code>,
<code><a href="#topic+sae">sae</a>()</code>,
<code><a href="#topic+se">se</a>()</code>,
<code><a href="#topic+sle">sle</a>()</code>,
<code><a href="#topic+smape">smape</a>()</code>,
<code><a href="#topic+srho">srho</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
truth = 1:10
response = truth + rnorm(10)
sse(truth, response)
</code></pre>

<hr>
<h2 id='tn'>True Negatives</h2><span id='topic+tn'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tn(truth, response, positive, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tn_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="tn_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="tn_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="tn_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This measure counts the true negatives, i.e. the number of
predictions correctly indicating a negative class label.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
tn(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='tnr'>True Negative Rate</h2><span id='topic+tnr'></span><span id='topic+specificity'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tnr(truth, response, positive, na_value = NaN, ...)

specificity(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tnr_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="tnr_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="tnr_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="tnr_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="tnr_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The True Negative Rate is defined as </p>
<p style="text-align: center;"><code class="reqn">
   \frac{\mathrm{TN}}{\mathrm{FP} + \mathrm{TN}}.
</code>
</p>

<p>Also know as &quot;specificity&quot;.
</p>
<p>This measure is undefined if FP + TN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
tnr(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='tp'>True Positives</h2><span id='topic+tp'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tp(truth, response, positive, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tp_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="tp_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="tp_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="tp_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This measure counts the true positives, i.e. the number of
predictions correctly indicating a positive class label.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, \infty)</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tpr">tpr</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
tp(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='tpr'>True Positive Rate</h2><span id='topic+tpr'></span><span id='topic+recall'></span><span id='topic+sensitivity'></span>

<h3>Description</h3>

<p>Measure to compare true observed labels with predicted
labels
in binary classification tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpr(truth, response, positive, na_value = NaN, ...)

recall(truth, response, positive, na_value = NaN, ...)

sensitivity(truth, response, positive, na_value = NaN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpr_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the exactly same two levels and the same length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="tpr_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the exactly same two levels and the same length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="tpr_+3A_positive">positive</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;character(1))&#8288;</code><br />
Name of the positive class.</p>
</td></tr>
<tr><td><code id="tpr_+3A_na_value">na_value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that should be returned if the measure is not defined for the input
(as described in the note). Default is <code>NaN</code>.</p>
</td></tr>
<tr><td><code id="tpr_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The True Positive Rate is defined as </p>
<p style="text-align: center;"><code class="reqn">
  \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}.
</code>
</p>

<p>Also know as &quot;recall&quot; or &quot;sensitivity&quot;.
</p>
<p>This measure is undefined if TP + FN = 0.
</p>


<h3>Value</h3>

<p>Performance value as <code>numeric(1)</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"binary"</code>
</p>
</li>
<li><p> Range: <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize: <code>FALSE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram">https://en.wikipedia.org/wiki/Template:DiagnosticTesting_Diagram</a>
</p>
<p>Goutte C, Gaussier E (2005).
&ldquo;A Probabilistic Interpretation of Precision,  Recall and F-Score,  with Implication for Evaluation.&rdquo;
In <em>Lecture Notes in Computer Science</em>, 345&ndash;359.
<a href="https://doi.org/10.1007/978-3-540-31865-1_25">doi:10.1007/978-3-540-31865-1_25</a>.
</p>


<h3>See Also</h3>

<p>Other Binary Classification Measures: 
<code><a href="#topic+auc">auc</a>()</code>,
<code><a href="#topic+bbrier">bbrier</a>()</code>,
<code><a href="#topic+dor">dor</a>()</code>,
<code><a href="#topic+fbeta">fbeta</a>()</code>,
<code><a href="#topic+fdr">fdr</a>()</code>,
<code><a href="#topic+fnr">fnr</a>()</code>,
<code><a href="#topic+fn">fn</a>()</code>,
<code><a href="#topic+fomr">fomr</a>()</code>,
<code><a href="#topic+fpr">fpr</a>()</code>,
<code><a href="#topic+fp">fp</a>()</code>,
<code><a href="#topic+mcc">mcc</a>()</code>,
<code><a href="#topic+npv">npv</a>()</code>,
<code><a href="#topic+ppv">ppv</a>()</code>,
<code><a href="#topic+prauc">prauc</a>()</code>,
<code><a href="#topic+tnr">tnr</a>()</code>,
<code><a href="#topic+tn">tn</a>()</code>,
<code><a href="#topic+tp">tp</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
lvls = c("a", "b")
truth = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
response = factor(sample(lvls, 10, replace = TRUE), levels = lvls)
tpr(truth, response, positive = "a")
</code></pre>

<hr>
<h2 id='zero_one'>Zero-One Classification Loss (per observation)</h2><span id='topic+zero_one'></span>

<h3>Description</h3>

<p>Calculates the per-observation 0/1 loss as </p>
<p style="text-align: center;"><code class="reqn">
  t_i \neq r_1.
</code>
</p>

<p>Measure to compare true observed labels with predicted
labels
in multiclass classification tasks.
</p>
<p>Note that this is an unaggregated measure, returning the losses per observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zero_one(truth, response, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zero_one_+3A_truth">truth</code></td>
<td>
<p>(<code>factor()</code>)<br />
True (observed) labels.
Must have the same levels and length as <code>response</code>.</p>
</td></tr>
<tr><td><code id="zero_one_+3A_response">response</code></td>
<td>
<p>(<code>factor()</code>)<br />
Predicted response labels.
Must have the same levels and length as <code>truth</code>.</p>
</td></tr>
<tr><td><code id="zero_one_+3A_...">...</code></td>
<td>
<p>(<code>any</code>)<br />
Additional arguments. Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Performance value as <code>numeric(length(truth))</code>.
</p>


<h3>Meta Information</h3>


<ul>
<li><p> Type: <code>"classif"</code>
</p>
</li>
<li><p> Range (per observation): <code class="reqn">[0, 1]</code>
</p>
</li>
<li><p> Minimize (per observation): <code>TRUE</code>
</p>
</li>
<li><p> Required prediction: <code>response</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Classification Measures: 
<code><a href="#topic+acc">acc</a>()</code>,
<code><a href="#topic+bacc">bacc</a>()</code>,
<code><a href="#topic+ce">ce</a>()</code>,
<code><a href="#topic+logloss">logloss</a>()</code>,
<code><a href="#topic+mauc_aunu">mauc_aunu</a>()</code>,
<code><a href="#topic+mbrier">mbrier</a>()</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
