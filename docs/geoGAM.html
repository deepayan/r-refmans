<!DOCTYPE html><html><head><title>Help for package geoGAM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {geoGAM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#berne'>
<p>Berne &ndash; soil mapping case study</p></a></li>
<li><a href='#berne.grid'>
<p>Berne &ndash; very small extract of prediction grid</p></a></li>
<li><a href='#bootstrap.geoGAM'><p>Bootstrapped predictive distribution</p>
</p></a></li>
<li><a href='#geoGAM'>
<p>Select sparse geoadditive model</p></a></li>
<li><a href='#methods'>
<p>Methods for <code>geoGAM</code> objects</p></a></li>
<li><a href='#predict.geoGAM'>
<p>Prediction from fitted geoGAM model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Select Sparse Geoadditive Models for Spatial Prediction</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-30</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 2.14.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>mboost, mgcv, grpreg, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>raster, sp</td>
</tr>
<tr>
<td>Description:</td>
<td>A model building procedure to build parsimonious geoadditive model from a large number of covariates. Continuous, binary and ordered categorical responses are supported. The model building is based on component wise gradient boosting with linear effects, smoothing splines and a smooth spatial surface to model spatial autocorrelation. The resulting covariate set after gradient boosting is further reduced through backward elimination and aggregation of factor levels. The package provides a model based bootstrap method to simulate prediction intervals for point predictions. A test data set of a soil mapping case study in Berne (Switzerland) is provided. Nussbaum, M., Walthert, L., Fraefel, M., Greiner, L., and Papritz, A. (2017) &lt;<a href="https://doi.org/10.5194%2Fsoil-3-191-2017">doi:10.5194/soil-3-191-2017</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Author:</td>
<td>Madlene Nussbaum [cre, aut],
  Andreas Papritz [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Madlene Nussbaum &lt;m.nussbaum@uu.nl&gt;</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-14 15:44:13 UTC; madlene</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-14 18:00:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='berne'>
Berne &ndash; soil mapping case study
</h2><span id='topic+berne'></span>

<h3>Description</h3>

<p>The Berne dataset contains soil responses and a large set of explanatory covariates. The study area is located to the Northwest of the city of Berne and covers agricultural area.
Soil responses included are soil pH (4 depth intervals calculated from soil horizon), drainage classes (3 ordered classes) and presence of waterlogging characteristics down to a specified depth (binary response).
</p>
<p>Covariates cover environmental conditions by representing climate, topography, parent material and soil.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("berne")</code></pre>


<h3>Format</h3>

<p>A data frame with 1052 observations on the following 238 variables.

</p>

<dl>
<dt><code>site_id_unique</code></dt><dd><p>ID of original profile sampling</p>
</dd>
<dt><code>x</code></dt><dd><p>easting, Swiss grid in m, EPSG: 21781 (CH1903/LV03)</p>
</dd>
<dt><code>y</code></dt><dd><p>northing, Swiss grid in m, EPSG: 21781 (CH1903/LV03)</p>
</dd>
<dt><code>dataset</code></dt><dd><p>Factor splitting dataset for <code>calibration</code> and independent <code>validation</code>. <code>validation</code> was assigned at random by using weights to ensure even spatial coverage of the agricultural area.</p>
</dd>
<dt><code>dclass</code></dt><dd><p>Drainage class, ordered Factor.</p>
</dd>
<dt><code>waterlog.30</code></dt><dd><p>Presence of waterlogging characteristics down to 30 cm (1: presence, 0: absence)</p>
</dd>
<dt><code>waterlog.50</code></dt><dd><p>Presence of waterlogging characteristics down to 50 cm (1: presence, 0: absence)</p>
</dd>
<dt><code>waterlog.100</code></dt><dd><p>Presence of waterlogging characteristics down to 100 cm (1: presence, 0: absence)</p>
</dd>
<dt><code>ph.0.10</code></dt><dd><p>Soil pH in 0-10 cm depth.</p>
</dd>
<dt><code>ph.10.30</code></dt><dd><p>Soil pH in 10-30 cm depth.</p>
</dd>
<dt><code>ph.30.50</code></dt><dd><p>Soil pH in 30-50 cm depth.</p>
</dd>
<dt><code>ph.50.100</code></dt><dd><p>Soil pH in 50-100 cm depth.</p>
</dd>
<dt><code>timeset</code></dt><dd><p>Factor with range of sampling year and label for sampling type for soil pH. no label: <code class="reqn">CaCl_{2}</code> laboratory measurements, <code>field</code>: field estimate by indicator solution, <code>ptf</code>: <code class="reqn">H_{2}0</code> laboratory measurements transferred by pedotransfer function (univariate linear regression) to level of <code class="reqn">CaCl_{2}</code> measures.</p>
</dd>
<dt><code>cl_mt_etap_pe</code></dt><dd><p>columns 14 to 238 contain environmental covariates representing soil forming factors. For more information see Details below.</p>
</dd>
<dt><code>cl_mt_etap_ro</code></dt><dd></dd>
<dt><code>cl_mt_gh_1</code></dt><dd></dd>
<dt><code>cl_mt_gh_10</code></dt><dd></dd>
<dt><code>cl_mt_gh_11</code></dt><dd></dd>
<dt><code>cl_mt_gh_12</code></dt><dd></dd>
<dt><code>cl_mt_gh_2</code></dt><dd></dd>
<dt><code>cl_mt_gh_3</code></dt><dd></dd>
<dt><code>cl_mt_gh_4</code></dt><dd></dd>
<dt><code>cl_mt_gh_5</code></dt><dd></dd>
<dt><code>cl_mt_gh_6</code></dt><dd></dd>
<dt><code>cl_mt_gh_7</code></dt><dd></dd>
<dt><code>cl_mt_gh_8</code></dt><dd></dd>
<dt><code>cl_mt_gh_9</code></dt><dd></dd>
<dt><code>cl_mt_gh_y</code></dt><dd></dd>
<dt><code>cl_mt_pet_pe</code></dt><dd></dd>
<dt><code>cl_mt_pet_ro</code></dt><dd></dd>
<dt><code>cl_mt_rr_1</code></dt><dd></dd>
<dt><code>cl_mt_rr_10</code></dt><dd></dd>
<dt><code>cl_mt_rr_11</code></dt><dd></dd>
<dt><code>cl_mt_rr_12</code></dt><dd></dd>
<dt><code>cl_mt_rr_2</code></dt><dd></dd>
<dt><code>cl_mt_rr_3</code></dt><dd></dd>
<dt><code>cl_mt_rr_4</code></dt><dd></dd>
<dt><code>cl_mt_rr_5</code></dt><dd></dd>
<dt><code>cl_mt_rr_6</code></dt><dd></dd>
<dt><code>cl_mt_rr_7</code></dt><dd></dd>
<dt><code>cl_mt_rr_8</code></dt><dd></dd>
<dt><code>cl_mt_rr_9</code></dt><dd></dd>
<dt><code>cl_mt_rr_y</code></dt><dd></dd>
<dt><code>cl_mt_swb_pe</code></dt><dd></dd>
<dt><code>cl_mt_swb_ro</code></dt><dd></dd>
<dt><code>cl_mt_td_1</code></dt><dd></dd>
<dt><code>cl_mt_td_10</code></dt><dd></dd>
<dt><code>cl_mt_td_11</code></dt><dd></dd>
<dt><code>cl_mt_td_12</code></dt><dd></dd>
<dt><code>cl_mt_td_2</code></dt><dd></dd>
<dt><code>cl_mt_tt_1</code></dt><dd></dd>
<dt><code>cl_mt_tt_11</code></dt><dd></dd>
<dt><code>cl_mt_tt_12</code></dt><dd></dd>
<dt><code>cl_mt_tt_3</code></dt><dd></dd>
<dt><code>cl_mt_tt_4</code></dt><dd></dd>
<dt><code>cl_mt_tt_5</code></dt><dd></dd>
<dt><code>cl_mt_tt_6</code></dt><dd></dd>
<dt><code>cl_mt_tt_7</code></dt><dd></dd>
<dt><code>cl_mt_tt_8</code></dt><dd></dd>
<dt><code>cl_mt_tt_9</code></dt><dd></dd>
<dt><code>cl_mt_tt_y</code></dt><dd></dd>
<dt><code>ge_caco3</code></dt><dd></dd>
<dt><code>ge_geo500h1id</code></dt><dd></dd>
<dt><code>ge_geo500h3id</code></dt><dd></dd>
<dt><code>ge_gt_ch_fil</code></dt><dd></dd>
<dt><code>ge_lgm</code></dt><dd></dd>
<dt><code>ge_vszone</code></dt><dd></dd>
<dt><code>sl_nutr_fil</code></dt><dd></dd>
<dt><code>sl_physio_neu</code></dt><dd></dd>
<dt><code>sl_retention_fil</code></dt><dd></dd>
<dt><code>sl_skelett_r_fil</code></dt><dd></dd>
<dt><code>sl_wet_fil</code></dt><dd></dd>
<dt><code>tr_be_gwn25_hdist</code></dt><dd></dd>
<dt><code>tr_be_gwn25_vdist</code></dt><dd></dd>
<dt><code>tr_be_twi2m_7s_tcilow</code></dt><dd></dd>
<dt><code>tr_be_twi2m_s60_tcilow</code></dt><dd></dd>
<dt><code>tr_ch_3_80_10</code></dt><dd></dd>
<dt><code>tr_ch_3_80_10s</code></dt><dd></dd>
<dt><code>tr_ch_3_80_20s</code></dt><dd></dd>
<dt><code>tr_cindx10_25</code></dt><dd></dd>
<dt><code>tr_cindx50_25</code></dt><dd></dd>
<dt><code>tr_curv_all</code></dt><dd></dd>
<dt><code>tr_curv_plan</code></dt><dd></dd>
<dt><code>tr_curv_prof</code></dt><dd></dd>
<dt><code>tr_enessk</code></dt><dd></dd>
<dt><code>tr_es25</code></dt><dd></dd>
<dt><code>tr_flowlength_up</code></dt><dd></dd>
<dt><code>tr_global_rad_ch</code></dt><dd></dd>
<dt><code>tr_lsf</code></dt><dd></dd>
<dt><code>tr_mrrtf25</code></dt><dd></dd>
<dt><code>tr_mrvbf25</code></dt><dd></dd>
<dt><code>tr_ndom_veg2m_fm</code></dt><dd></dd>
<dt><code>tr_nego</code></dt><dd></dd>
<dt><code>tr_nnessk</code></dt><dd></dd>
<dt><code>tr_ns25</code></dt><dd></dd>
<dt><code>tr_ns25_145mn</code></dt><dd></dd>
<dt><code>tr_ns25_145sd</code></dt><dd></dd>
<dt><code>tr_ns25_75mn</code></dt><dd></dd>
<dt><code>tr_ns25_75sd</code></dt><dd></dd>
<dt><code>tr_poso</code></dt><dd></dd>
<dt><code>tr_protindx</code></dt><dd></dd>
<dt><code>tr_se_alti10m_c</code></dt><dd></dd>
<dt><code>tr_se_alti25m_c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_10c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_25c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_50c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_5c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_alti50m_c</code></dt><dd></dd>
<dt><code>tr_se_alti6m_c</code></dt><dd></dd>
<dt><code>tr_se_conv2m</code></dt><dd></dd>
<dt><code>tr_se_curv10m</code></dt><dd></dd>
<dt><code>tr_se_curv25m</code></dt><dd></dd>
<dt><code>tr_se_curv2m</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s15</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s30</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s60</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s7</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_curv50m</code></dt><dd></dd>
<dt><code>tr_se_curv6m</code></dt><dd></dd>
<dt><code>tr_se_curvplan10m</code></dt><dd></dd>
<dt><code>tr_se_curvplan25m</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s15</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s30</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s60</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s7</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_curvplan50m</code></dt><dd></dd>
<dt><code>tr_se_curvplan6m</code></dt><dd></dd>
<dt><code>tr_se_curvprof10m</code></dt><dd></dd>
<dt><code>tr_se_curvprof25m</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s15</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s30</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s60</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s7</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_curvprof50m</code></dt><dd></dd>
<dt><code>tr_se_curvprof6m</code></dt><dd></dd>
<dt><code>tr_se_diss2m_10c</code></dt><dd></dd>
<dt><code>tr_se_diss2m_25c</code></dt><dd></dd>
<dt><code>tr_se_diss2m_50c</code></dt><dd></dd>
<dt><code>tr_se_diss2m_5c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect10m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect25m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_10c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_25c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_50c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_5c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect50m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect6m</code></dt><dd></dd>
<dt><code>tr_se_mrrtf2m</code></dt><dd></dd>
<dt><code>tr_se_mrvbf2m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect10m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect25m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_10c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_25c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_50c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_5c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect50m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect6m</code></dt><dd></dd>
<dt><code>tr_se_no2m_r500</code></dt><dd></dd>
<dt><code>tr_se_po2m_r500</code></dt><dd></dd>
<dt><code>tr_se_rough2m_10c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_25c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_50c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_5c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_rect3c</code></dt><dd></dd>
<dt><code>tr_se_sar2m</code></dt><dd></dd>
<dt><code>tr_se_sca2m</code></dt><dd></dd>
<dt><code>tr_se_slope10m</code></dt><dd></dd>
<dt><code>tr_se_slope25m</code></dt><dd></dd>
<dt><code>tr_se_slope2m</code></dt><dd></dd>
<dt><code>tr_se_slope2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s15</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s30</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s60</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s7</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_slope50m</code></dt><dd></dd>
<dt><code>tr_se_slope6m</code></dt><dd></dd>
<dt><code>tr_se_toposcale2m_r3_r50_i10s</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_10c</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_25c</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_50c</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_5c</code></dt><dd></dd>
<dt><code>tr_se_tri2m_altern_3c</code></dt><dd></dd>
<dt><code>tr_se_tsc10_2m</code></dt><dd></dd>
<dt><code>tr_se_twi2m</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s15</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s30</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s60</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s7</code></dt><dd></dd>
<dt><code>tr_se_vrm2m</code></dt><dd></dd>
<dt><code>tr_se_vrm2m_r10c</code></dt><dd></dd>
<dt><code>tr_slope25_l2g</code></dt><dd></dd>
<dt><code>tr_terrtextur</code></dt><dd></dd>
<dt><code>tr_tpi2000c</code></dt><dd></dd>
<dt><code>tr_tpi5000c</code></dt><dd></dd>
<dt><code>tr_tpi500c</code></dt><dd></dd>
<dt><code>tr_tsc25_18</code></dt><dd></dd>
<dt><code>tr_tsc25_40</code></dt><dd></dd>
<dt><code>tr_twi2</code></dt><dd></dd>
<dt><code>tr_twi_normal</code></dt><dd></dd>
<dt><code>tr_vdcn25</code></dt><dd></dd>
</dl>



<h3>Details</h3>

<p><strong>Soil data</strong>
</p>
<p>The soil data originates from various soil sampling campaigns since 1968. Most of the data was collected in conventional soil surveys in the 1970ties in the course of amelioration and farm land exchanges. As frequently observed in legacy soil data sampling site allocation followed a purposive sampling strategy identifying typical soils in an area in the course of polygon soil mapping.
</p>
<p><b><code>dclass</code></b> contains drainage classes of three levels.
Swiss soil classification differentiates stagnic (I), gleyic (G) and anoxic/reduced (R) soil profile qualifiers with each 4, 6 resp. 5 levels. To reduce complexity the qualifiers  I, G and R  were aggregated to the degree of hydromorphic
characteristic of a site with the ordered levels <em><code>well</code></em> (qualifier labels I1&ndash;I2, G1&ndash;G3, R1 and no hydromorphic qualifier), <em><code>moderate</code></em> well drained (I3&ndash;I4, G4) and <em><code>poor</code></em> drained (G5&ndash;G6, R2&ndash;R5).
</p>
<p><b><code>waterlog</code></b> indicates the <em><code>presence</code></em> or <em><code>absence</code></em> of waterlogging characteristics down 30, 50 and 100 cm soil depth. The responses were based on horizon qualifiers &lsquo;gg&rsquo; or &lsquo;r&rsquo; of the Swiss classification (<cite>Brunner et al. 1997</cite>) as those were considered to limit plant growth. A horizon was given the qualifier &lsquo;gg&rsquo; if it was strongly gleyic predominantly oxidized (rich in <code class="reqn">Fe^{3+}</code>) and &lsquo;r&rsquo; if it was anoxic predominantly reduced (poor in <code class="reqn">Fe^{3+}</code>).
</p>
<p><b><code>pH</code></b> was mostly sampled following genetic soil horizons. To ensure comparability between sites pH was transferred to fixed depth intervals of 0&ndash;10, 10&ndash;30, 30&ndash;50 and 50&ndash;100 cm by weighting soil horizons falling into a given interval. The data contains laboratory measurements that solved samples in <code class="reqn">CaCl_{2}</code> or <code class="reqn">H_{2}0</code>. The latter were transferred to the level of <code class="reqn">CaCl_{2}</code> measurements by univariate linear regression (label <code>ptf</code> in <em><code>timeset</code></em>). Further, the dataset contains estimates of pH in the field by an indicator solution (Hellige pH, label <code>field</code> in <em><code>timeset</code></em>).
The column <em><code>timeset</code></em> can be used to partly correct for the long sampling period and the different sampling methods.
</p>
<p><strong>Environmental covariates</strong>
</p>
<p>The numerous covariates were assembled from the available spatial data in the case study area.
Each covariate name was given a prefix:
</p>

<ul>
<li> <p><em><code>cl_</code></em> climate covariates as precipitation, temperature, radiation
</p>
</li>
<li> <p><em><code>tr_</code></em> terrain attributes, covariates derived from digital elevation models
</p>
</li>
<li> <p><em><code>ge_</code></em> covariates from geological maps
</p>
</li>
<li> <p><em><code>sl_</code></em> covariates from an overview soil map
</p>
</li></ul>

<p>References to the used datasets can be found in <cite>Nussbaum et al. 2017b</cite>.
</p>


<h3>References</h3>

<p>Brunner, J., Jaeggli, F., Nievergelt, J., and Peyer, K. (1997). Kartieren und Beurteilen von Landwirtschaftsboeden.
FAL Schriftenreihe 24, Eidgenoessische Forschungsanstalt fuer Agraroekologie und Landbau, Zuerich-Reckenholz (FAL).
</p>
<p>Nussbaum, M., Spiess, K., Baltensweiler, A., Grob, U., Keller, A., Greiner, L., Schaepman, M. E., and Papritz, A., 2017b. Evaluation of digital soil mapping approaches with large sets of environmental covariates, SOIL Discuss., https://www.soil-discuss.net/soil-2017-14/, in review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(berne)
</code></pre>

<hr>
<h2 id='berne.grid'>
Berne &ndash; very small extract of prediction grid
</h2><span id='topic+berne.grid'></span>

<h3>Description</h3>

<p>The Berne grid dataset contains values of spatial covariates on the nodes of a 20 m grid. The dataset is intended for spatial continouous predictions of soil properties modelled from the sampling locations in <code><a href="#topic+berne">berne</a></code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("berne")</code></pre>


<h3>Format</h3>

<p>A data frame with 4594 observations on the following 228 variables.

</p>

<dl>
<dt><code>id</code></dt><dd><p>node identifier number.</p>
</dd>
<dt><code>x</code></dt><dd><p>easting, Swiss grid in m, EPSG: 21781 (CH1903/LV03)</p>
</dd>
<dt><code>y</code></dt><dd><p>northing, Swiss grid in m, EPSG: 21781 (CH1903/LV03)</p>
</dd>
<dt><code>cl_mt_etap_pe</code></dt><dd><p>columns 4 to 228 contain environmental covariates representing soil forming factors. For more information see <code>Details</code> in <code><a href="#topic+berne">berne</a></code>.</p>
</dd>
<dt><code>cl_mt_etap_ro</code></dt><dd></dd>
<dt><code>cl_mt_gh_1</code></dt><dd></dd>
<dt><code>cl_mt_gh_10</code></dt><dd></dd>
<dt><code>cl_mt_gh_11</code></dt><dd></dd>
<dt><code>cl_mt_gh_12</code></dt><dd></dd>
<dt><code>cl_mt_gh_2</code></dt><dd></dd>
<dt><code>cl_mt_gh_3</code></dt><dd></dd>
<dt><code>cl_mt_gh_4</code></dt><dd></dd>
<dt><code>cl_mt_gh_5</code></dt><dd></dd>
<dt><code>cl_mt_gh_6</code></dt><dd></dd>
<dt><code>cl_mt_gh_7</code></dt><dd></dd>
<dt><code>cl_mt_gh_8</code></dt><dd></dd>
<dt><code>cl_mt_gh_9</code></dt><dd></dd>
<dt><code>cl_mt_gh_y</code></dt><dd></dd>
<dt><code>cl_mt_pet_pe</code></dt><dd></dd>
<dt><code>cl_mt_pet_ro</code></dt><dd></dd>
<dt><code>cl_mt_rr_1</code></dt><dd></dd>
<dt><code>cl_mt_rr_10</code></dt><dd></dd>
<dt><code>cl_mt_rr_11</code></dt><dd></dd>
<dt><code>cl_mt_rr_12</code></dt><dd></dd>
<dt><code>cl_mt_rr_2</code></dt><dd></dd>
<dt><code>cl_mt_rr_3</code></dt><dd></dd>
<dt><code>cl_mt_rr_4</code></dt><dd></dd>
<dt><code>cl_mt_rr_5</code></dt><dd></dd>
<dt><code>cl_mt_rr_6</code></dt><dd></dd>
<dt><code>cl_mt_rr_7</code></dt><dd></dd>
<dt><code>cl_mt_rr_8</code></dt><dd></dd>
<dt><code>cl_mt_rr_9</code></dt><dd></dd>
<dt><code>cl_mt_rr_y</code></dt><dd></dd>
<dt><code>cl_mt_swb_pe</code></dt><dd></dd>
<dt><code>cl_mt_swb_ro</code></dt><dd></dd>
<dt><code>cl_mt_td_1</code></dt><dd></dd>
<dt><code>cl_mt_td_10</code></dt><dd></dd>
<dt><code>cl_mt_td_11</code></dt><dd></dd>
<dt><code>cl_mt_td_12</code></dt><dd></dd>
<dt><code>cl_mt_td_2</code></dt><dd></dd>
<dt><code>cl_mt_tt_1</code></dt><dd></dd>
<dt><code>cl_mt_tt_11</code></dt><dd></dd>
<dt><code>cl_mt_tt_12</code></dt><dd></dd>
<dt><code>cl_mt_tt_3</code></dt><dd></dd>
<dt><code>cl_mt_tt_4</code></dt><dd></dd>
<dt><code>cl_mt_tt_5</code></dt><dd></dd>
<dt><code>cl_mt_tt_6</code></dt><dd></dd>
<dt><code>cl_mt_tt_7</code></dt><dd></dd>
<dt><code>cl_mt_tt_8</code></dt><dd></dd>
<dt><code>cl_mt_tt_9</code></dt><dd></dd>
<dt><code>cl_mt_tt_y</code></dt><dd></dd>
<dt><code>ge_caco3</code></dt><dd></dd>
<dt><code>ge_geo500h1id</code></dt><dd></dd>
<dt><code>ge_geo500h3id</code></dt><dd></dd>
<dt><code>ge_gt_ch_fil</code></dt><dd></dd>
<dt><code>ge_lgm</code></dt><dd></dd>
<dt><code>ge_vszone</code></dt><dd></dd>
<dt><code>sl_nutr_fil</code></dt><dd></dd>
<dt><code>sl_physio_neu</code></dt><dd></dd>
<dt><code>sl_retention_fil</code></dt><dd></dd>
<dt><code>sl_skelett_r_fil</code></dt><dd></dd>
<dt><code>sl_wet_fil</code></dt><dd></dd>
<dt><code>tr_be_gwn25_hdist</code></dt><dd></dd>
<dt><code>tr_be_gwn25_vdist</code></dt><dd></dd>
<dt><code>tr_be_twi2m_7s_tcilow</code></dt><dd></dd>
<dt><code>tr_be_twi2m_s60_tcilow</code></dt><dd></dd>
<dt><code>tr_ch_3_80_10</code></dt><dd></dd>
<dt><code>tr_ch_3_80_10s</code></dt><dd></dd>
<dt><code>tr_ch_3_80_20s</code></dt><dd></dd>
<dt><code>tr_cindx10_25</code></dt><dd></dd>
<dt><code>tr_cindx50_25</code></dt><dd></dd>
<dt><code>tr_curv_all</code></dt><dd></dd>
<dt><code>tr_curv_plan</code></dt><dd></dd>
<dt><code>tr_curv_prof</code></dt><dd></dd>
<dt><code>tr_enessk</code></dt><dd></dd>
<dt><code>tr_es25</code></dt><dd></dd>
<dt><code>tr_flowlength_up</code></dt><dd></dd>
<dt><code>tr_global_rad_ch</code></dt><dd></dd>
<dt><code>tr_lsf</code></dt><dd></dd>
<dt><code>tr_mrrtf25</code></dt><dd></dd>
<dt><code>tr_mrvbf25</code></dt><dd></dd>
<dt><code>tr_ndom_veg2m_fm</code></dt><dd></dd>
<dt><code>tr_nego</code></dt><dd></dd>
<dt><code>tr_nnessk</code></dt><dd></dd>
<dt><code>tr_ns25</code></dt><dd></dd>
<dt><code>tr_ns25_145mn</code></dt><dd></dd>
<dt><code>tr_ns25_145sd</code></dt><dd></dd>
<dt><code>tr_ns25_75mn</code></dt><dd></dd>
<dt><code>tr_ns25_75sd</code></dt><dd></dd>
<dt><code>tr_poso</code></dt><dd></dd>
<dt><code>tr_protindx</code></dt><dd></dd>
<dt><code>tr_se_alti10m_c</code></dt><dd></dd>
<dt><code>tr_se_alti25m_c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_10c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_25c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_50c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_fmean_5c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_alti2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_alti50m_c</code></dt><dd></dd>
<dt><code>tr_se_alti6m_c</code></dt><dd></dd>
<dt><code>tr_se_conv2m</code></dt><dd></dd>
<dt><code>tr_se_curv10m</code></dt><dd></dd>
<dt><code>tr_se_curv25m</code></dt><dd></dd>
<dt><code>tr_se_curv2m</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s15</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s30</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s60</code></dt><dd></dd>
<dt><code>tr_se_curv2m_s7</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_curv2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_curv50m</code></dt><dd></dd>
<dt><code>tr_se_curv6m</code></dt><dd></dd>
<dt><code>tr_se_curvplan10m</code></dt><dd></dd>
<dt><code>tr_se_curvplan25m</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s15</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s30</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s60</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_s7</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_curvplan2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_curvplan50m</code></dt><dd></dd>
<dt><code>tr_se_curvplan6m</code></dt><dd></dd>
<dt><code>tr_se_curvprof10m</code></dt><dd></dd>
<dt><code>tr_se_curvprof25m</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s15</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s30</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s60</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_s7</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_curvprof2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_curvprof50m</code></dt><dd></dd>
<dt><code>tr_se_curvprof6m</code></dt><dd></dd>
<dt><code>tr_se_diss2m_10c</code></dt><dd></dd>
<dt><code>tr_se_diss2m_25c</code></dt><dd></dd>
<dt><code>tr_se_diss2m_50c</code></dt><dd></dd>
<dt><code>tr_se_diss2m_5c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect10m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect25m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_10c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_25c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_50c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_5c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_e_aspect50m</code></dt><dd></dd>
<dt><code>tr_se_e_aspect6m</code></dt><dd></dd>
<dt><code>tr_se_mrrtf2m</code></dt><dd></dd>
<dt><code>tr_se_mrvbf2m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect10m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect25m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_10c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_25c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_50c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_5c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_n_aspect50m</code></dt><dd></dd>
<dt><code>tr_se_n_aspect6m</code></dt><dd></dd>
<dt><code>tr_se_no2m_r500</code></dt><dd></dd>
<dt><code>tr_se_po2m_r500</code></dt><dd></dd>
<dt><code>tr_se_rough2m_10c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_25c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_50c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_5c</code></dt><dd></dd>
<dt><code>tr_se_rough2m_rect3c</code></dt><dd></dd>
<dt><code>tr_se_sar2m</code></dt><dd></dd>
<dt><code>tr_se_sca2m</code></dt><dd></dd>
<dt><code>tr_se_slope10m</code></dt><dd></dd>
<dt><code>tr_se_slope25m</code></dt><dd></dd>
<dt><code>tr_se_slope2m</code></dt><dd></dd>
<dt><code>tr_se_slope2m_grass_17c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_grass_45c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_grass_9c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s15</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s30</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s60</code></dt><dd></dd>
<dt><code>tr_se_slope2m_s7</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_10c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_25c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_50c</code></dt><dd></dd>
<dt><code>tr_se_slope2m_std_5c</code></dt><dd></dd>
<dt><code>tr_se_slope50m</code></dt><dd></dd>
<dt><code>tr_se_slope6m</code></dt><dd></dd>
<dt><code>tr_se_toposcale2m_r3_r50_i10s</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_10c</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_25c</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_50c</code></dt><dd></dd>
<dt><code>tr_se_tpi_2m_5c</code></dt><dd></dd>
<dt><code>tr_se_tri2m_altern_3c</code></dt><dd></dd>
<dt><code>tr_se_tsc10_2m</code></dt><dd></dd>
<dt><code>tr_se_twi2m</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s15</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s30</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s60</code></dt><dd></dd>
<dt><code>tr_se_twi2m_s7</code></dt><dd></dd>
<dt><code>tr_se_vrm2m</code></dt><dd></dd>
<dt><code>tr_se_vrm2m_r10c</code></dt><dd></dd>
<dt><code>tr_slope25_l2g</code></dt><dd></dd>
<dt><code>tr_terrtextur</code></dt><dd></dd>
<dt><code>tr_tpi2000c</code></dt><dd></dd>
<dt><code>tr_tpi5000c</code></dt><dd></dd>
<dt><code>tr_tpi500c</code></dt><dd></dd>
<dt><code>tr_tsc25_18</code></dt><dd></dd>
<dt><code>tr_tsc25_40</code></dt><dd></dd>
<dt><code>tr_twi2</code></dt><dd></dd>
<dt><code>tr_twi_normal</code></dt><dd></dd>
<dt><code>tr_vdcn25</code></dt><dd></dd>
</dl>



<h3>Details</h3>

<p>Due to CRAN file size restrictions the grid for spatial predictions only shows a very small excerpt of the original study area.
</p>
<p>The environmental covariates for prediction of soil properties from dataset <code><a href="#topic+berne">berne</a></code> were extracted at the nodes of a 20 m grid. For higher resolution geodata sets no averaging over the area of the 20x20 pixel was done. <code>Berne.grid</code> therefore has the same spatial support for each covariate as <code><a href="#topic+berne">berne</a></code>.
</p>
<p>For more information on the environmental covariates see <code><a href="#topic+berne">berne</a></code>.
</p>


<h3>References</h3>

<p>Nussbaum, M., Spiess, K., Baltensweiler, A., Grob, U., Keller, A., Greiner, L., Schaepman, M. E., and Papritz, A.: Evaluation of digital soil mapping approaches with large sets of environmental covariates, SOIL, 4, 1-22, doi:10.5194/soil-4-1-2018, 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(berne.grid)

</code></pre>

<hr>
<h2 id='bootstrap.geoGAM'>Bootstrapped predictive distribution
</h2><span id='topic+bootstrap.geoGAM'></span><span id='topic+bootstrap'></span><span id='topic+bootstrap.default'></span>

<h3>Description</h3>

<p>Method for class <code>geoGAM</code> to compute model based bootstrap for point predictions. Returns complete predictive distribution of which prediction intervals can be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
bootstrap(object, ...)

## S3 method for class 'geoGAM'
bootstrap(object, newdata, R = 100,
          back.transform = c("none", "log", "sqrt"),
          seed = NULL, cores = detectCores(), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap.geoGAM_+3A_object">object</code></td>
<td>
<p>geoGAM object</p>
</td></tr>
<tr><td><code id="bootstrap.geoGAM_+3A_newdata">newdata</code></td>
<td>
<p>data frame in which to look for covariates with which to predict.</p>
</td></tr>
<tr><td><code id="bootstrap.geoGAM_+3A_r">R</code></td>
<td>
<p>number of bootstrap replicates, single positive integer.</p>
</td></tr>
<tr><td><code id="bootstrap.geoGAM_+3A_back.transform">back.transform</code></td>
<td>
<p>sould to <code>log</code> or <code>sqrt</code> transformed responses unbiased back transformation be applied? Default is <code>none</code>.</p>
</td></tr>
<tr><td><code id="bootstrap.geoGAM_+3A_seed">seed</code></td>
<td>
<p>seed for simulation of new response. Set seed for reproducible results.</p>
</td></tr>
<tr><td><code id="bootstrap.geoGAM_+3A_cores">cores</code></td>
<td>
<p>number of cores to be used for parallel computing.</p>
</td></tr>
<tr><td><code id="bootstrap.geoGAM_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Soil properties are predicted for new locations <code class="reqn">\mathbf{s_{+}}</code> from the final <code><a href="#topic+geoGAM">geoGAM</a></code> fit by <code class="reqn">\tilde{Y}(\mathbf{s_+})=\hat f(\mathbf{x}\mathbf{(s_+)})</code>, see function <code><a href="#topic+predict.geoGAM">predict.geoGAM</a></code>.


To model the predictive distributions for continuous responses <code><a href="#topic+bootstrap.geoGAM">bootstrap.geoGAM</a></code> uses a
non-parametric, model-based bootstrapping approach (<cite>Davison and Hinkley 1997</cite>, pp. 262, 285) as follows:

</p>

<ol>
<li><p> New values of the response are simulated according to <code class="reqn">Y(\mathbf{s})^{*} = \hat f(\mathbf{x}(\mathbf{s}))+\mathbf{\epsilon}</code>, where <code class="reqn">\hat f(\mathbf{x}(\mathbf{s}))</code> are the fitted values of the final model
and <code class="reqn">\epsilon</code> are errors randomly sampled with replacement from the centred, homoscedastic residuals of the final model <cite>Wood 2006</cite>, p. 129).
</p>
</li>
<li> <p><code><a href="#topic+geoGAM">geoGAM</a></code> is fitted to <code class="reqn">Y(\mathbf{s})^{*}</code>.
</p>
</li>
<li><p> Prediction errors are computed according to <code class="reqn">\delta_{+}^{*} =  \hat f(\mathbf{x}(\mathbf{s_{+}}))^{*} - (\, \hat f(\mathbf{x}(\mathbf{s_{+}})) + \mathbf{\epsilon} \,)</code>,
where <code class="reqn">\hat f(\mathbf{x}(\mathbf{s_{+}}))^{*}</code> are predicted values at new locations <code class="reqn">\mathbf{s_{+}}</code> of the
model built with the simulated response <code class="reqn">Y(\mathbf{s})^{*}</code> in step B above, and the errors <code class="reqn">\epsilon</code> are again randomly sampled from the centred, homoscedastic residuals of the final model (see step A).
</p>
</li></ol>

<p>Prediction intervals are computed according to

</p>
<p style="text-align: center;"><code class="reqn">
	[\hat f(\mathbf{x}(\mathbf{s_{+})}) - \delta_{+\,(1-\alpha)}^{*}\,; \hat f(\mathbf{x}\mathbf{(s_{+}})) - \delta_{+\,(\alpha)}^{*}]</code>
</p>


<p>where <code class="reqn">\delta_{+\,(\alpha)}^{*}</code> and <code class="reqn">\delta_{+\,(1-\alpha)}^{*}</code> are the <code class="reqn">\alpha</code>- and <code class="reqn">(1-\alpha)</code>-quantiles of <code class="reqn">\delta_{+}^{*}</code>, pooled over all 1000 bootstrap repetitions.
</p>
<p>Predictive distributions for binary and ordinal responses are
directly obtained from a final <code><a href="#topic+geoGAM">geoGAM</a></code> fit by predicting probabilities
of occurrence <code class="reqn">\mathrm{\widetilde{Prob}}(Y(\mathbf{s})=r\,|\,\mathbf{x}(\mathbf{s)})</code>
(<cite>Davison and Hinkley 1997</cite>, p. 358).
</p>


<h3>Value</h3>

<p>Data frame of <code>nrows(newdata)</code> rows and <code>R + 2</code> columns with <code>x</code> and <code>y</code> indicating coordinates of the location and <code>P1</code> to <code>P...R</code> the prediction at this location from <code>1...R</code> replications.
</p>


<h3>Author(s)</h3>

<p>M. Nussbaum
</p>


<h3>References</h3>

<p>Nussbaum, M., Walthert, L., Fraefel, M., Greiner, L., and Papritz, A.: Mapping of soil properties at high resolution in Switzerland using boosted geoadditive models, SOIL, 3, 191-210, doi:10.5194/soil-3-191-2017, 2017.
</p>
<p>Davison, A. C. and Hinkley, D. V., 2008. Bootstrap Methods and Their Applications. Cambridge University Press.
</p>


<h3>See Also</h3>

<p>To create geoGAM objects see <code><a href="#topic+geoGAM">geoGAM</a></code> and to predict without simulation of the predictive distribution see <code><a href="#topic+predict.geoGAM">predict.geoGAM</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(quakes)

# group stations to ensure min 20 observations per factor level
# and reduce number of levels for speed
quakes$stations &lt;- factor( cut( quakes$stations, breaks = c(0,15,19,23,30,39,132)) )

# Artificially split data to create prediction data set
set.seed(1)
quakes.pred &lt;- quakes[ ss &lt;- sample(1:nrow(quakes), 500), ]
quakes &lt;- quakes[ -ss, ]

quakes.geogam &lt;- geoGAM(response = "mag",
                        covariates = c("stations", "depth"),
                        coords = c("lat", "long"),
                        data = quakes,
                        max.stop = 20,
                        cores = 1)


## compute model based bootstrap with 10 repetitions (use at least 100)
quakes.boot &lt;- bootstrap(quakes.geogam,
                         newdata = quakes.pred,
                         R = 10, cores = 1)


# plot predictive distribution for site in row 9
hist( as.numeric( quakes.boot[ 9, -c(1:2)] ), col = "grey",
      main = paste("Predictive distribution at", paste( quakes.boot[9, 1:2], collapse = "/" )),
      xlab = "predicted magnitude")

# compute 95 % prediction interval and add to plot
quant95 &lt;- quantile( as.numeric( quakes.boot[ 9, -c(1:2)] ), probs = c(0.025, 0.975) )
abline(v = quant95[1], lty = "dashed")
abline(v = quant95[2], lty = "dashed")

</code></pre>

<hr>
<h2 id='geoGAM'>
Select sparse geoadditive model
</h2><span id='topic+geoGAM'></span>

<h3>Description</h3>

<p>Selects a parsimonious geoadditive model from a large set of covariates with the aim of (spatial) prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geoGAM(response, covariates = names(data)[!(names(data) %in% c(response,coords))],
       data, coords = NULL, weights = rep(1, nrow(data)),
       offset = TRUE, max.stop = 300, non.stationary = FALSE,
       sets = NULL, seed = NULL, validation.data = NULL,
       verbose = 0, cores = min(detectCores(),10))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geoGAM_+3A_response">response</code></td>
<td>
<p> name of response as character. Responses currently supported: gaussian, binary, ordered.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_covariates">covariates</code></td>
<td>
<p> character vector of all covariates (factor, continuous). If not given, all columns of <code>data</code> are used.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_data">data</code></td>
<td>
<p> data frame containing response, coordinates and covariates. </p>
</td></tr>
<tr><td><code id="geoGAM_+3A_coords">coords</code></td>
<td>
<p>character vector of column names indicating spatial coordinates.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_weights">weights</code></td>
<td>
<p> weights used for model fitting.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_offset">offset</code></td>
<td>
<p> logical, use offset for component wise gradient boosting algorithm.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_max.stop">max.stop</code></td>
<td>
<p> maximal number of boosting iterations.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_non.stationary">non.stationary</code></td>
<td>
<p>logical, include non-stationary effects in model selection. This allows for spatial varying coefficients for continuous covariates, but increases computational effort.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_sets">sets</code></td>
<td>
<p> give predefined cross validation sets. </p>
</td></tr>
<tr><td><code id="geoGAM_+3A_seed">seed</code></td>
<td>
<p> set random seed for splitting of the cross validation sets, if no <code>sets</code> are given.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_validation.data">validation.data</code></td>
<td>
<p>data frame containing response, coordinates and covariates to compute independent validation statistics. This data set is used to calculate predictive performance at the end of model selection only.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_verbose">verbose</code></td>
<td>
<p>Should screen output be generated? 0 = none, &gt;0 create output.</p>
</td></tr>
<tr><td><code id="geoGAM_+3A_cores">cores</code></td>
<td>
<p> number of cores to be used for parallel computing </p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Summary</strong>
</p>
<p><code><a href="#topic+geoGAM">geoGAM</a></code> models smooth nonlinear relations between responses and single covariates and combines these model terms additively. Residual spatial autocorrelation is captured by a smooth function of spatial coordinates and nonstationary effects are included by interactions between covariates and smooth spatial functions. The core of fully automated model building for geoGAM is componentwise gradient boosting. The model selection procedures aims at obtaining sparse models that are open to check feasibilty of modelled relationships (<cite>Nussbaum et al. 2017a</cite>).
</p>
<p><code><a href="#topic+geoGAM">geoGAM</a></code> to date models continuous, binary and ordinal responses. It is able to cope with numerous continuous and categorical covariates.
</p>
<p><strong>Generic model representation</strong>
</p>
<p>GAM expand the (possibly transformed) conditional
expectation of a response at given covariates <code class="reqn">s</code> as an additive series

</p>
<p style="text-align: center;"><code class="reqn">
    g\left(\rule{0pt}{14pt}\mathrm{E}[Y(\mathbf{s})\,|\,\mathbf{x}(\mathbf{s})]\right)
        = \nu + f(\mathbf{x}(\mathbf{s}))
    = \nu +  \sum_{j} f_{j}(x_{j}(\mathbf{s})),
  </code>
</p>


<p>where <code class="reqn">\nu</code> is a constant and <code class="reqn">f_{j}(x_{j}(\mathbf{s}))</code> are linear
terms or unspecified &ldquo;smooth&rdquo; nonlinear functions of single covariates <code class="reqn">x_{j}(\mathbf{s})</code>
(e.g. smoothing spline, kernel or
any other scatterplot smoother) and <code class="reqn">g(\cdot)</code> is again a link function. A generalized additive model (GAM) is based on the following components (<cite>Hastie and Tibshirani 1990, Chapt. 6</cite>):
</p>


<ol>
<li> <p><em>Response distribution</em>: Given <code class="reqn">\mathbf{x}(\mathbf{s}) = x_1(\mathbf{s}), x_2(\mathbf{s}), ..., x_p(\mathbf{s})</code>, the
<code class="reqn">Y(\mathbf{s})</code> are conditionally independent observations from simple
exponential family distributions.

</p>
</li>
<li> <p><em>Link function</em>: <code class="reqn">g(\cdot)</code> relates the expectation
<code class="reqn">\mu(\mathbf{x}(\mathbf{s})) = \mathrm{E}[Y(\mathbf{s})|\mathbf{x}(\mathbf{s})]</code> of the response
distribution to

</p>
</li>
<li><p> the <em>additive predictor</em>  <code class="reqn">\sum_{j} f_{j}(x_{j}(\mathbf{s}))</code>.
</p>
</li></ol>

<p>geoGAM extend GAM by allowing a more complex form of the additive
predictor (<cite>Kneib et al. 2009, Hothorn et al. 2011</cite>): First, one can
add a smooth function <code class="reqn">f_{{\scriptstyle \mathbf{s}}}(\mathbf{s})</code> of the spatial
coordinates (smooth spatial surface) to the additive predictor to account for residual
autocorrelation.

More complex relationships between <code class="reqn">Y</code> and <code class="reqn">\mathbf{x}</code> can be modelled
by adding terms like <code class="reqn">f_{j}(x_{j}(\mathbf{s})) \cdot
  f_{k}(x_{k}(\mathbf{s}))</code> &ndash; capturing the effect of interactions
between covariates &ndash; and <code class="reqn">f_{{\scriptstyle \mathbf{s}}}(\mathbf{s}) \cdot
  f_{j}(x_{k}(\mathbf{s}))</code> &ndash; accounting for spatially changing
dependence between <code class="reqn">Y</code> and <code class="reqn">\mathbf{x}</code>.  Hence, in its full generality,
a generalized additive model for spatial data is represented by

</p>
<p style="text-align: center;"><code class="reqn">
    g(\mu(\mathbf{x}(\mathbf{s}))) = \nu + f(\mathbf{x}(\mathbf{s}))   =  \nonumber </code>
</p>

<p style="text-align: center;"><code class="reqn">
    \nu +
    \underbrace{
    \sum_{u} f_{j_{u}}(x_{j_{u}}(\mathbf{s})) + \sum_{v}
    f_{j_{v}}(x_{j_{v}}(\mathbf{s})) \cdot f_{k_{v}}(x_{k_{v}}(\mathbf{s}))
    }_{\mbox{global marginal and interaction effects}} \nonumber </code>
</p>

<p style="text-align: center;"><code class="reqn">
     +
    \underbrace{ \sum_{w} f_{{\scriptstyle \mathbf{{s}}_{w}}}(\mathbf{s}) \cdot
    f_{j_{w}}(x_{j_{w}}(\mathbf{s})) }_{\mbox{nonstationary effects}} +
    \underbrace{\hspace{5mm} f_{{\scriptstyle \mathbf{s} }}(\mathbf{s})
    \hspace{5mm}}_{\mbox{autocorrelation}}.
    </code>
</p>


<p><cite>Kneib et al. (2009)</cite> called the above equation a geoadditive model,
a name coined before by <cite>Kammann and Wand 2003</cite> for a combination
of additive models with a geostatistical error model.
It remains to specify what response distributions and link functions
should be used for the various response types: For (possibly
transformed) <em>continuous</em> responses one uses often a normal
response distribution combined with the identity link
<code class="reqn">g\left(\mu(\mathbf{x}(\mathbf{s}))\right) = \mu(\mathbf{x}(\mathbf{s}))</code>.
For binary data (coded as 0 and 1), one assumes a Bernoulli
distribution and uses often a logit link

</p>
<p style="text-align: center;"><code class="reqn">
     g\left(\mu(\mathbf{x}(\mathbf{s}))\right) =\log\left(
     \frac{\mu(\mathbf{x}(\mathbf{s}))}{1-\mu(\mathbf{x}(\mathbf{s}))} \right),
  </code>
</p>


<p>where

</p>
<p style="text-align: center;"><code class="reqn">
    \mu(\mathbf{x}(\mathbf{s})) =
    \mathrm{Prob}[Y(\mathbf{s})=1\,|\,\mathbf{x}(\mathbf{s})] =
    \frac{\exp(\nu +f(\mathbf{x}(\mathbf{s})))}{1+\exp(\nu +f(\mathbf{x}(\mathbf{s})))}.
  </code>
</p>


<p>For ordinal data, with ordered response levels, <code class="reqn">1, 2, \ldots, k</code>,
the cumulative logit or proportional odds model
(<cite>Tutz 2012</cite>, Sect. 9.1) is used.  For any given level <code class="reqn">r \in (1, 2,
  \ldots, k)</code>, the logarithm of the odds of the event <code class="reqn">Y(\mathbf{s}) \leq
  r \, | \, \mathbf{x}(\mathbf{s})</code> is then modelled by

</p>
<p style="text-align: center;"><code class="reqn">
    \log\left(
    \frac{\mathrm{Prob}[Y(\mathbf{s}) \leq
    r \, | \, \mathbf{x}(\mathbf{s}))]}{\mathrm{Prob}[Y(\mathbf{s}) &gt; r \, | \,
    \mathbf{x}(\mathbf{s}))]}\right) = \nu_{r} + f(\mathbf{x}(\mathbf{s})),
  </code>
</p>

<p>with <code class="reqn">\nu_{r}</code> a sequence of level-specific constants satisfying
<code class="reqn">\nu_{1} \leq \nu_{2} \leq \ldots \leq \nu_{r}</code>. Conversely,

</p>
<p style="text-align: center;"><code class="reqn">
    \mathrm{Prob}[Y(\mathbf{s})\leq r\,|\,\mathbf{x}(\mathbf{s})] =
    \frac{\exp(\nu_{r} + f(\mathbf{x}(\mathbf{s})))}{1+\exp(\nu_{r} + f(\mathbf{x}(\mathbf{s})))}. </code>
</p>


<p>Note that <code class="reqn">\mathrm{Prob}[Y(\mathbf{s})\leq r\,|\,\mathbf{x}(\mathbf{s})]</code>
depends on <code class="reqn">r</code> only through the constant <code class="reqn">\nu_{r}</code>.  Hence, the ratio
of the odds of two events <code class="reqn">Y(\mathbf{s}) \leq r \, | \,
  \mathbf{x}(\mathbf{s})</code> and <code class="reqn">(\mathbf{s}) \leq r \, | \,
  \tilde{\mathbf{x}}(\mathbf{s})</code> is the same for all <code class="reqn">r</code>
(<cite>Tutz 2012</cite>, p. 245).
</p>
<p><strong>Model building (selection of covariates)</strong>
</p>
<p>To build parsimonious models that can readily be checked for agreement understanding in regards to the analized subject. The following steps 1&ndash;6 are implemented in <code><a href="#topic+geoGAM">geoGAM</a></code> toa achieve sparse models in a fully automated way.
In several of these steps tuning parameters are optimized by 10-fold cross-validation with fixed subsets using either root mean squared error (RMSE), continuous responses), Brier score (BS), binary responses) or ranked probability score (RPS), ordinal responses) as optimization criteria (see <cite>Wilks, 2011</cite>).
To improve the stability of the algorithm continuous covariates are first scaled (by difference of maximum and minimum value) and centred.
</p>


<ol>
<li><p> Boosting (see step 2 below) is more stable and converges more quickly when the effects of categorical covariates (factors) are accounted for as model offset. Therefore, the group lasso (least absolute shrinkage and selection operator, <cite>Breheny and Huang 2015</cite>, <code>grpreg</code>))  &ndash; an algorithm that likely
excludes non-relevant covariates and treats factors
as groups &ndash; is used to select important factors for the offset. 
For ordinal responses
stepwise proportional odds logistic regression in both directions
with BIC (e. g. <cite>Faraway 2005</cite>, p. 126) is used to select the offset covariates because lasso cannot be
used for such responses.
</p>

</li>
<li><p> Next, a subset of
relevant factors, continuous covariates and spatial effects is selected by componentwise gradient boosting.
Boosting is a slow stagewise additive learning algorithm. It
expands <code class="reqn">f(\mathbf{x}(\mathbf{s}))</code> in a set of base procedures (baselearners)
and approximates the additive predictor by a finite sum of
them as follows (<cite>Buehlmann and Hothorn 2007</cite>):
</p>

<ol>
<li><p> Initialize <code class="reqn">\hat{f}( \mathbf{x}(\mathbf{s}))^{[m]}</code>
with offset of step 1 above and set <code class="reqn">m=0</code>.
</p>
</li>
<li><p> Increase <code class="reqn">m</code> by 1. Compute
the negative gradient vector <code class="reqn">\mathbf{U}^{[m]}</code> (e.g. residuals) for a loss
function <code class="reqn">l(\cdot)</code>.
</p>
</li>
<li><p> Fit all baselearners <code class="reqn">g(
			\mathbf{x}(\mathbf{s}))_{1..p}</code> to <code class="reqn">\mathbf{U}^{[m]}</code> and select the baselearner, say
<code class="reqn">g(\mathbf{x}(\mathbf{s}))_{j}^{[m]}</code> that minimizes <code class="reqn">l(\cdot)</code>.
</p>
</li>
<li><p> Update
<code class="reqn">\hat{f}( \mathbf{x}(\mathbf{s}))^{[m]} = \hat{f}( \mathbf{x}(\mathbf{s}))^{[m-1]} +
			v\cdot g( \mathbf{x}(\mathbf{s}))_{j}^{[m]}</code> with step size <code class="reqn">v\leq1</code>.
</p>
</li>
<li><p> Iterate steps (b) to (d) until <code class="reqn">m = m_{stop}</code> (main tuning
parameter).
</p>
</li></ol>


<p>The following settings are used in above algorithm: 
As loss functions <code class="reqn">l(\cdot)</code> <code class="reqn">L_2</code> is used for continuous,
negative binomial likelihood for binary
(<cite>Buehlmann and Hothorn 2007</cite>) and proportional odds likelihood
for ordinal responses (<cite>Schmid et al. 2011</cite>). 

Early stopping of the boosting algorithm is achieved by
determining optimal <code class="reqn">m_{stop}</code> by cross-validation. 
Default step length (<code class="reqn">\upsilon = 0.1</code>) is used. This is not a
sensitive parameter as long as it is clearly below 1 (<cite>Hofner et al. 2014</cite>).

For continuous covariates penalized smoothing
spline baselearners (<cite>Kneib et al. 2009</cite>) are used. Factors
are treated as linear baselearners. To capture residual autocorrelation
a bivariate tensor-product P-spline of spatial coordinates
(<cite>Wood 2006, pp. 162</cite>) is added to the additive predictor. Spatially varying effects
are modelled by baselearners formed by multiplication of
continuous covariates with tensor-product P-splines of spatial coordinates
(<cite>Wood 2006, pp. 168</cite>). Uneven degree of freedom of baselearners biases
baselearner selection (<cite>Hofner et al. 2011b</cite>). Therefore, each baselearner is penalized to 5 degrees of
freedom (<code class="reqn">df</code>). Factors with less than 6 levels (<code class="reqn">df&lt;5</code>)
are aggregated to grouped baselearners. By using an offset, effects of important factors with more than 6 levels
are implicitly accounted for without penalization.
</p>

</li>
<li><p> At <code class="reqn">m_{stop}</code> (see step 2 above), many included baselearners may have very small effects only. To remove these
the effect size <code class="reqn">e_j</code> of each baselearner <code class="reqn">f_j(x_j(\mathbf{s}))</code> is computed. 	For factors the effect size <code class="reqn">e_j</code> is the largest difference between effects of two levels and for continuous covariates it is equal to the maximum contrast of estimated partial effects (after removal of extreme values as in boxplots, <cite>Frigge et al. 1989</cite>). Generalized additive models (GAM, <cite>Wood 2011</cite>) are fitted including smooth and factor effects depending on the effect size <code class="reqn">e_j</code> of the corresponding baselearner <code class="reqn">j</code>. The procedure iterates through <code class="reqn">e_j</code> and excludes covariates with <code class="reqn">e_j</code> smaller than a threshold effect size <code class="reqn">e_t</code>. Optimal <code class="reqn">e_t</code> is determined by 10-fold cross-validation of GAM. In these GAM fits smooth effects are penalized to 5 degrees of freedom as imposed by componentwise gradient boosting (step 2 above). The factors selected as offset in step 1 are included in the main GAM, that is now fitted without offset.
</p>

</li>
<li><p> The GAM is further reduced by stepwise removal of
covariates by cross-validation. The candidate covariate to drop is chosen by largest <code class="reqn">p</code> value
of <code class="reqn">F</code> tests for linear factors and approximate <code class="reqn">F</code> test
(<cite>Wood 2011</cite>) for smooth terms. 


</p>

</li>
<li><p> Factor levels with similar estimated effects are merged stepwise again by cross-validation
based on largest <code class="reqn">p</code> values from two sample <code class="reqn">t</code>-tests of partial
residuals.
</p>

</li>
<li><p> The final model (used to compute spatial predictions) results ideally in a parsimonious
GAM. Because of step 5, factors have possibly a reduced number of coefficients.
Effects of continuous covariates are modelled by smooth functions and  &ndash; if at all present &ndash;
spatially structured residual variation (autocorrelation) is represented by a smooth spatial surface.
To avoid over-fitting both types of smooth effects are penalized to 5 degrees of freedom (as imposed by step 2).
</p>
</li></ol>



<h3>Value</h3>

<p>Object of class <code>geoGAM</code>:
</p>
<table>
<tr><td><code>offset.grplasso</code></td>
<td>
<p>Cross validation for grouped LASSO, object of class <code>cv.grpreg</code> of package <code>grpreg</code>). Empty for <code>offset = FALSE</code>.</p>
</td></tr>
<tr><td><code>offset.factors</code></td>
<td>
<p>Character vector of factor names chosen for the offset computation. Empty for <code>offset = FALSE</code>.</p>
</td></tr>
<tr><td><code>gamboost</code></td>
<td>
<p>Gradient boosting with smooth components, object of class <code>gamboost</code> of package <code>mboost</code>.</p>
</td></tr>
<tr><td><code>gamboost.cv</code></td>
<td>
<p>Cross validation for gradient boosting, object of class <code>cvrisk</code> of package <code>mboost</code>.</p>
</td></tr>
<tr><td><code>gamboost.mstop</code></td>
<td>
<p>Mstop used for gamboost.</p>
</td></tr>
<tr><td><code>gamback.cv</code></td>
<td>
<p>List of cross validation error for tuning parameter magnitude.</p>
</td></tr>
<tr><td><code>gamback.backward</code></td>
<td>
<p>List of cross validation error path for backward selection of <code><a href="mgcv.html#topic+gam">gam</a></code> fit.</p>
</td></tr>
<tr><td><code>gamback.aggregation</code></td>
<td>
<p>List(s) of cross validation error path for aggregation of factor levels.</p>
</td></tr>
<tr><td><code>gam.final</code></td>
<td>
<p>Final selected geoadditive model fit, object of class <code><a href="mgcv.html#topic+gam">gam</a></code>.</p>
</td></tr>
<tr><td><code>gam.final.cv</code></td>
<td>
<p>Data frame with original response and cross validation predictions.</p>
</td></tr>
<tr><td><code>gam.final.extern</code></td>
<td>
<p>Data frame with original response data and predictions of <code>gam.final</code>.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>Original data frame for model calibration.</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>List of parameters handed to geoGAM (used for subsequent bootstrap of prediction intervals).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. Nussbaum
</p>


<h3>References</h3>

<p>Breheny, P. and Huang, J., 2015. Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors. Statistics and Computing, 25, 173&ndash;187.
</p>
<p>Buehlmann, P. and Hothorn, T., 2007. Boosting algorithms: Regularization, prediction and model fitting, Stat Sci, 22, 477&ndash;505, doi:10.1214/07-sts242.
</p>
<p>Faraway, J. J., 2005. Linear Models with R, vol. 63 of Texts in Statistical Science, Chapman &amp; Hall/CRC, Boca Raton.
</p>
<p>Frigge, M., Hoaglin, D. C., and Iglewicz, B., 1989. Some implementations of the boxplot. The American Statistician, 43(1), 50&ndash;54.
</p>
<p>Hastie, T. J. and Tibshirani, R. J., 1990. Generalized Additive Models, vol. 43 of Monographs on Statistics and Applied Probability, Chapman and Hall, London.
</p>
<p>Hofner, B., Hothorn, T., Kneib, T., and Schmid, M., 2011. A framework for unbiased model selection based on boosting. Journal of Computational and Graphical Statistics, 20(4), 956&ndash;971.
</p>
<p>Hofner, B., Mayr, A., Robinzonov, N., and Schmid, M., 2014. Model-based boosting in R: A hands-on tutorial using the R package mboost, Computation Stat, 29, 3&ndash;35, doi:10.1007/s00180-012-0382-5.
</p>
<p>Hothorn, T., Mueller, J., Schroder, B., Kneib, T., and Brandl, R., 2011. Decomposing environmental, spatial, and spatiotemporal components of species distributions, Ecol Monogr, 81, 329&ndash;347.
</p>
<p>Kneib, T., Hothorn, T., and Tutz, G., 2009. Variable selection and model choice in geoadditive regression models. Biometrics, 65(2), 626&ndash;634.
</p>
<p>Nussbaum, M., Walthert, L., Fraefel, M., Greiner, L., and Papritz, A.: Mapping of soil properties at high resolution in Switzerland using boosted geoadditive models, SOIL, 3, 191-210, doi:10.5194/soil-3-191-2017, 2017.
</p>
<p>Schmid, M., Hothorn, T., Maloney, K. O., Weller, D. E., and Potapov, S., 2011. Geoadditive regression modeling of stream biological condition, Environ Ecol Stat, 18, 709&ndash;733, doi:10.1007/s10651-010-0158-4.
</p>
<p>Tutz, G., 2012, Regression for Categorical Data, Cambridge University Press,
doi:10.1017/cbo9780511842061.
</p>
<p>Wilks, D. S., 2011. Statistical Methods in the Atmospheric Sciences, Academic Press, 3 edn.
</p>
<p>Wood, S. N., 2006. Generalized Additive Models: An Introduction with R, Chapman and Hall/CRC.
</p>
<p>Wood, S. N., 2011. Fast stable restricted maximum likelihood and marginal likelihood
estimation of semiparametric generalized linear models. Journal of the Royal Statistical
Society (B), 73(1), 3&ndash;36.
</p>


<h3>See Also</h3>

<p>The model selection is based on packages <code>grpreg</code> (function <code>cv.grpreg</code>), <code>MASS</code> (function <code><a href="MASS.html#topic+polr">polr</a></code>), <code>mboost</code> (functions <code>gamboost</code>, <code><a href="ipred.html#topic+cv">cv</a></code>, <code>cvrisk</code>) and <code><a href="mgcv.html#topic+mgcv">mgcv</a></code> (function <code><a href="mgcv.html#topic+gam">gam</a></code>). For further information please see documentation and vignettes for these packages.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### small examples with earthquake data

data(quakes)
set.seed(2)
quakes &lt;- quakes[ sample(1:nrow(quakes), 50), ]

quakes.geogam &lt;- geoGAM(response = "mag",
                        covariates = c("depth", "stations"),
                        data = quakes,
                        seed = 2,
                        max.stop = 5,
                        cores = 1)
summary(quakes.geogam)


data(quakes)

# create grouped factor with reduced number of levels
quakes$stations &lt;- factor( cut( quakes$stations, breaks = c(0,15,19,23,30,39,132)) )

quakes.geogam &lt;- geoGAM(response = "mag",
                        covariates = c("stations", "depth"),
                        coords = c("lat", "long"),
                        data = quakes,
                        max.stop = 10,
                        cores = 1)

summary(quakes.geogam)
summary(quakes.geogam, what = "path")




## Use soil data set of soil mapping study area near Berne

data(berne)
set.seed(1)

# Split data sets and
# remove rows with missing values in response and covariates

d.cal &lt;- berne[ berne$dataset == "calibration" &amp; complete.cases(berne), ]
d.val &lt;- berne[ berne$dataset == "validation" &amp; complete.cases(berne), ]


### Model selection for continuous response
ph10.geogam &lt;- geoGAM(response = "ph.0.10",
                      covariates = names(d.cal)[14:ncol(d.cal)],
                      coords = c("x", "y"),
                      data = d.cal,
                      offset = TRUE,
                      sets = mboost::cv(rep(1, nrow(d.cal)), type = "kfold"),
                      validation.data = d.val,
                      cores = 1)
summary(ph10.geogam)
summary(ph10.geogam, what = "path")


### Model selection for binary response
waterlog100.geogam &lt;- geoGAM(response = "waterlog.100",
                             covariates = names(d.cal)[c(14:54, 56:ncol(d.cal))],
                             coords = c("x", "y"),
                             data = d.cal,
                             offset = FALSE,
                             sets = sample( cut(seq(1,nrow(d.cal)),breaks=10,labels=FALSE) ),
                             validation.data = d.val,
                             cores = 1)
summary(waterlog100.geogam)
summary(waterlog100.geogam, what = "path")


### Model selection for ordered response
dclass.geogam &lt;- geoGAM(response = "dclass",
                        covariates = names(d.cal)[14:ncol(d.cal)],
                        coords = c("x", "y"),
                        data = d.cal,
                        offset = TRUE,
                        non.stationary = TRUE,
                        seed = 1,
                        validation.data = d.val,
                        cores = 1)
summary(dclass.geogam)
summary(dclass.geogam, what = "path")



</code></pre>

<hr>
<h2 id='methods'>
Methods for <code>geoGAM</code> objects
</h2><span id='topic+summary.geoGAM'></span><span id='topic+print.geoGAM'></span><span id='topic+plot.geoGAM'></span><span id='topic+summary'></span><span id='topic+print'></span><span id='topic+plot'></span>

<h3>Description</h3>

<p>Methods for models fitted by <code>geoGAM()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'geoGAM'
summary(object, ..., what = c("final", "path"))

## S3 method for class 'geoGAM'
print(x, ...)

## S3 method for class 'geoGAM'
plot(x, ..., what = c("final", "path"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="methods_+3A_object">object</code></td>
<td>
<p>an object of class <code>geoGAM</code></p>
</td></tr>
<tr><td><code id="methods_+3A_x">x</code></td>
<td>
<p>an object of class <code>geoGAM</code></p>
</td></tr>
<tr><td><code id="methods_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code>summary.gam</code>, <code>plot.gam</code> or <code>plot.mboost</code></p>
</td></tr>
<tr><td><code id="methods_+3A_what">what</code></td>
<td>
<p>print summary or plot partial effects of <code>final</code> selected model or print summary or plot gradient boosting path of model selection <code>path</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary</code> with <code>what = "final"</code> calls <code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code> to display a summary of the final (geo)additive model. <code>plot</code> with  <code>what = "final"</code> calls <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code> to plot partial residual plots of the final model.
</p>
<p><code>summary</code> with <code>what = "path"</code> give a summary of covariates selected in each step of model building.
<code>plot</code> with <code>what = "path"</code> calls <code>plot.mboost</code> to plot the path of the gradient boosting algorithm.
</p>


<h3>Value</h3>

<p>For <code>what == "final"</code> summary returns a list of 3:
</p>
<table>
<tr><td><code>summary.gam</code></td>
<td>
<p>containing the values of <code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code>.</p>
</td></tr>
<tr><td><code>summary.validation$cv</code></td>
<td>
<p>cross validation statistics.</p>
</td></tr>
<tr><td><code>summary.validation$validation</code></td>
<td>
<p>validation set statistics.</p>
</td></tr>
</table>
<p>For <code>what == "path"</code> summary returns a list of 13:
</p>
<table>
<tr><td><code>response</code></td>
<td>
<p>name of response.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>family used for <code>geoGAM</code> fit.</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations used for model fitting.</p>
</td></tr>
<tr><td><code>n.obs.val</code></td>
<td>
<p>number of observations used for model validation.</p>
</td></tr>
<tr><td><code>n.covariates</code></td>
<td>
<p>number of initial covariates including factors.</p>
</td></tr>
<tr><td><code>n.cov.chosen</code></td>
<td>
<p>number of covariates in final model.</p>
</td></tr>
<tr><td><code>list.factors</code></td>
<td>
<p>list of factors chosen as offset.</p>
</td></tr>
<tr><td><code>mstop</code></td>
<td>
<p>number of optimal iterations of gradient boosting.</p>
</td></tr>
<tr><td><code>list.baselearners</code></td>
<td>
<p>list of covariate names selected by gradient boosting.</p>
</td></tr>
<tr><td><code>list.effect.size</code></td>
<td>
<p>list of covariate names after cross validation of effect size in gradient boosting.</p>
</td></tr>
<tr><td><code>list.backward</code></td>
<td>
<p>list of covariate names after backward selection.</p>
</td></tr>
<tr><td><code>list.aggregation</code></td>
<td>
<p>list of aggregated factor levels.</p>
</td></tr>
<tr><td><code>list.gam.final</code></td>
<td>
<p>list of covariate names in final model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>M. Nussbaum
</p>


<h3>References</h3>

<p>Nussbaum, M., Walthert, L., Fraefel, M., Greiner, L., and Papritz, A.: Mapping of soil properties at high resolution in Switzerland using boosted geoadditive models, SOIL, 3, 191-210, doi:10.5194/soil-3-191-2017, 2017.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+geoGAM">geoGAM</a></code>, <code><a href="mgcv.html#topic+gam">gam</a></code>, <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### small example with earthquake data

data(quakes)
set.seed(2)

quakes &lt;- quakes[ sample(1:nrow(quakes), 50), ]

quakes.geogam &lt;- geoGAM(response = "mag",
                        covariates = c("depth", "stations"),
                        data = quakes,
                        seed = 2,
                        max.stop = 5,
                        cores = 1)

summary(quakes.geogam)
summary(quakes.geogam, what = "path")

plot(quakes.geogam)
plot(quakes.geogam, what = "path")

</code></pre>

<hr>
<h2 id='predict.geoGAM'>
Prediction from fitted geoGAM model
</h2><span id='topic+predict'></span><span id='topic+predict.default'></span><span id='topic+predict.geoGAM'></span>

<h3>Description</h3>

<p>Takes a fitted <code><a href="#topic+geoGAM">geoGAM</a></code> object and produces point predictions for a new set of covariate values. If no new data is provided fitted values are returned. Centering and scaling is applied with the same parameters as for the calibration <code>data</code> set given to <code><a href="#topic+geoGAM">geoGAM</a></code>. Factor levels are aggregated according to the final model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'geoGAM'
predict(object, newdata,
        type = c("response", "link", "probs", "class"),
        back.transform = c("none", "log", "sqrt"),
        threshold = 0.5, se.fit = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.geoGAM_+3A_object">object</code></td>
<td>
<p>an object of class <code>geoGAM</code></p>
</td></tr>
<tr><td><code id="predict.geoGAM_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame in which to look for variables with which to predict. If omitted, the fitted values are used. If newdata is provided then it should contain all the variables needed for prediction: a warning is generated if not. Factors aggregated by the function <code>geoGAM</code> will be aggregated in the same way for prediction within this function.</p>
</td></tr>
<tr><td><code id="predict.geoGAM_+3A_type">type</code></td>
<td>
<p>Type of prediction.</p>
</td></tr>
<tr><td><code id="predict.geoGAM_+3A_back.transform">back.transform</code></td>
<td>
<p>Should to <code>log</code> or <code>sqrt</code> transformed responses unbiased back transformation be applied? Default is <code>none</code>. Ignored for categorical responses.</p>
</td></tr>
<tr><td><code id="predict.geoGAM_+3A_threshold">threshold</code></td>
<td>
<p> Ignored for <code>type = c("response", "link", "probs")</code> and for <code>type = "class"</code> for responses with more than two levels.</p>
</td></tr>
<tr><td><code id="predict.geoGAM_+3A_se.fit">se.fit</code></td>
<td>
<p>logical. Default is FALSE.</p>
</td></tr>
<tr><td><code id="predict.geoGAM_+3A_...">...</code></td>
<td>
<p>further arguments to <code>predict()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns point predictions for new locations <code class="reqn">s</code> from linear and smooth trends <code class="reqn">\hat f(\mathbf{x},s)</code> estimated
by penalized least squares geoGAM by calling the function <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>.
</p>
<p><strong>Back transformation of log and sqrt</strong>
</p>
<p>For lognormal responses (<code>back.transform = 'log'</code>) in full analogy to lognormal kriging (<cite>Cressie-2006</cite>, Eq. 20) the predictions are backtransformed by

</p>
<p style="text-align: center;"><code class="reqn">
	\mathrm{E}[ Y(\mathbf{s})\,|\,\mathbf{x}] = \exp\left(~ \hat
	f(\mathbf{x}(\mathbf{s})) + \frac{1}{2} \hat \sigma^2 -
	\frac{1}{2} \mbox{Var}[ \hat
	f(\mathbf{x}(\mathbf{s}) ] \right)
	</code>
</p>


<p>with <code class="reqn">\hat f(\mathbf{x}(\mathbf{s}))</code> being the prediction of the log-transformed response,
<code class="reqn">\hat \sigma^2</code> the estimated residual variance of the final <code><a href="#topic+geoGAM">geoGAM</a></code> fit (see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> with <code>se.fit=TRUE</code>) and
<code class="reqn">\mbox{Var}[ \hat f(\mathbf{x}(\mathbf{s}) ) ]</code> the variance of <code class="reqn">\hat f(\mathbf{x}(\mathbf{s}))</code> as provided again by the final <code><a href="#topic+geoGAM">geoGAM</a></code>.
</p>
<p>For responses with square root transformation (<code>back.transform = 'sqrt'</code>) unbiased backtransform is computed by (<cite>Nussbaum et al. 2017b</cite>)

</p>
<p style="text-align: center;"><code class="reqn">
\tilde{Y}(s) = \hat{f}(\mathbf{x}(\mathbf{s}))^2 + \hat{\sigma}^2 - Var[ \hat{f}(\mathbf{x}(\mathbf{s}))]
</code>
</p>


<p>with <code class="reqn">\hat{f}(\mathbf{x}(\mathbf{s}))^2</code> being the prediction of the sqrt-transformed response, <code class="reqn">\hat{\sigma}^2</code> the estimated residual variance of the fitted model and <code class="reqn">Var[ \hat{f}(\mathbf{x}(\mathbf{s}))]</code> the variance of <code class="reqn">\hat{f}(\mathbf{x}(\mathbf{s}))</code> as provided again by <code><a href="#topic+geoGAM">geoGAM</a></code>.
</p>
<p><strong>Discretization of probability predictions</strong>
</p>
<p>For binary and ordered responses predictions yield
predicted occurrence probabilities <code class="reqn">\tilde
	P(Y(\mathbf{s})=\mathbf{r}|\mathbf{x},s)</code> for response classes <code class="reqn">\mathbf{r}</code>.
</p>
<p>To obtain binary class predictions a <code>threshold</code> can be given. A threshold of 0.5 (default) maximizes percentage correct of predicted classes. For binary responses of rare events this threshold may not be optimal. Maximizing on e.g. Gilbert Skill Score (GSS, Wilks, 2011, chap. 8) on cross-validation predictions of the final geoGAM might be a better strategy. GSS is excluding the correct predictions of the more abundant class 	and is preferably used in case of unequal distribution of binary responses
(direct implementation of such a cross validation procedure planed.)
</p>
<p>For ordered responses <code>predict</code> with <code>type = 'class'</code> selects the class to which the median of the
probability distribution over the ordered categories is assigned (<cite>Tutz 2012, p. 475</cite>).
</p>


<h3>Value</h3>

<p>Vector of point predictions for the sites in <code>newdata</code> is returned, with unbiased back transformation applied according to option <code>back.transform</code>.
</p>
<p>If <code>se.fit = TRUE</code> then a 2 item list is returned with items <code>fit</code> and <code>se.fit</code> containing predictions and associated standard error estimates as computed by <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>.
</p>


<h3>Author(s)</h3>

<p>M. Nussbaum
</p>


<h3>References</h3>

<p>Cressie, N. A. C., 1993. Statistics for Spatial Data, John Wiley and Sons.
</p>
<p>Nussbaum, M., Walthert, L., Fraefel, M., Greiner, L., and Papritz, A.: Mapping of soil properties at high resolution in Switzerland using boosted geoadditive models, SOIL, 3, 191-210, doi:10.5194/soil-3-191-2017, 2017.
</p>
<p>Nussbaum, M., Spiess, K., Baltensweiler, A., Grob, U., Keller, A., Greiner, L., Schaepman, M. E., and Papritz, A.: Evaluation of digital soil mapping approaches with large sets of environmental covariates, SOIL, 4, 1-22, doi:10.5194/soil-4-1-2018, 2018.
</p>
<p>Tutz, G., 2012. Regression for Categorical Data, Cambridge University Press.
</p>
<p>Wilks, D. S., 2011. Statistical Methods in the Atmospheric Sciences, Academic Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+geoGAM">geoGAM</a></code>, <code><a href="mgcv.html#topic+gam">gam</a></code>, <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>, <code><a href="#topic+summary.geoGAM">summary.geoGAM</a></code>, <code><a href="#topic+plot.geoGAM">plot.geoGAM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(quakes)
set.seed(2)

quakes &lt;- quakes[ ss &lt;- sample(1:nrow(quakes), 50), ]

# Artificially split data to create prediction data set
quakes.pred &lt;- quakes[ -ss, ]

quakes.geogam &lt;- geoGAM(response = "mag",
                        covariates = c("depth", "stations"),
                        data = quakes,
                        max.stop = 5,
                        cores = 1)

predicted &lt;- predict(quakes.geogam, newdata = quakes.pred, type = "response" )





## Use soil data set of soil mapping study area near Berne

data(berne)
data(berne.grid)

# Split data sets and
# remove rows with missing values in response and covariates

d.cal &lt;- berne[ berne$dataset == "calibration" &amp; complete.cases(berne), ]

### Model selection for numeric response
ph10.geogam &lt;- geoGAM(response = "ph.0.10",
                      covariates = names(d.cal)[14:ncol(d.cal)],
                      coords = c("x", "y"),
                      data = d.cal,
                      seed = 1,
                      cores = 1)

# Create GRID output with predictions
sp.grid &lt;- berne.grid[, c("x", "y")]

sp.grid$pred.ph.0.10 &lt;- predict(ph10.geogam, newdata = berne.grid)

if(requireNamespace("raster")){

  require("sp")

  # transform to sp object
  coordinates(sp.grid) &lt;- ~ x + y

  # assign Swiss CH1903 / LV03 projection
  proj4string(sp.grid) &lt;- CRS("EPSG:21781")

  # transform to grid
  gridded(sp.grid) &lt;- TRUE

  plot(sp.grid)

  # optionally save result to GeoTiff
  # writeRaster(raster(sp.grid, layer = "pred.ph.0.10"),
  #             filename= "raspH10.tif", datatype = "FLT4S", format ="GTiff")

}




</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
