<!DOCTYPE html><html><head><title>Help for package LPCM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LPCM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calspeedflow'>
<p>Speed-flow data from California.</p></a></li>
<li><a href='#coverage'>
<p>Coverage and self-coverage plots.</p></a></li>
<li><a href='#followx'>
<p>Fit an individual branch of a local principal curve.</p></a></li>
<li><a href='#gaia'>
<p>Gaia data</p></a></li>
<li><a href='#gvessel'>
<p>North Atlantic Water Temperature Data.</p></a></li>
<li><a href='#kernels.and.distances'>
<p>Auxiliary  kernel and distance functions.</p></a></li>
<li><a href='#lpc'>
<p>Local principal curves</p></a></li>
<li><a href='#lpc.control'>
<p>Auxiliary parameters for controlling local principal curves.</p></a></li>
<li><a href='#lpc.project'>
<p>Projection onto LPC</p></a></li>
<li><a href='#lpc.spline'>
<p>Representing local principal curves through a  cubic spline.</p></a></li>
<li><a href='#lpc.spline.auxiliary.functions'>
<p>Auxiliary functions for spline fitting and projection.</p></a></li>
<li><a href='#LPCM-package'>
<p>Local principal curve methods</p></a></li>
<li><a href='#ms'>
<p>Mean shift clustering.</p></a></li>
<li><a href='#ms.rep'>
<p>Mean shift procedures.</p></a></li>
<li><a href='#plot.lpc'><p>Plotting local principal curves and mean shift trajectories</p></a></li>
<li><a href='#print.lpc'><p>Printing output for lpc, lpc.spline, and ms objects</p></a></li>
<li><a href='#Rc'>
<p>Measuring goodness-of-fit for principal objects.</p></a></li>
<li><a href='#unscale'>
<p>Unscaling local principal objects.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Local Principal Curve Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.47-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-06</td>
</tr>
<tr>
<td>Author:</td>
<td>Jochen Einbeck and Ludger Evers</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jochen Einbeck &lt;jochen.einbeck@durham.ac.uk&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>scatterplot3d, lattice, dr, multimode</td>
</tr>
<tr>
<td>Description:</td>
<td>Fitting multivariate data patterns with local principal curves, including tools for data compression (projection) and measuring goodness-of-fit; with some additional functions for mean shift clustering.  See Einbeck, Tutz and Evers (2005) &lt;<a href="https://doi.org/10.1007%2Fs11222-005-4073-8">doi:10.1007/s11222-005-4073-8</a>&gt; and Ameijeiras-Alonso and Einbeck (2023) &lt;<a href="https://doi.org/10.1007%2Fs11634-023-00575-1">doi:10.1007/s11634-023-00575-1</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-06 22:52:02 UTC; jeinb</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-07 00:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calspeedflow'>
Speed-flow data from California. 
</h2><span id='topic+calspeedflow'></span>

<h3>Description</h3>

<p>A &lsquo;fundamental diagram&rsquo; with observations of speed and flow recorded from 9th of July 2007, 9am, to 10th of July 2007, 10pm, on Line 5 of the Californian Freeway SR57-N, VDS number 1202263. The data were originally measured in intervals of thirty seconds, and then aggregated over intervals of 5 minutes length. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(calspeedflow)</code></pre>


<h3>Format</h3>

<p>A data frame with 444 observations on the following 4 variables.
</p>

<dl>
<dt><code>Date</code></dt><dd><p>a factor with levels <code>07/09/2007</code>... <code>07/10/2007</code>.</p>
</dd>
<dt><code>Timestamp</code></dt><dd><p>a factor with a timestamps in intervals of five minutes.</p>
</dd>
<dt><code>Lane5Flow</code></dt><dd><p>a numeric vector of vehicle flow in vehicles per 5 minutes.</p>
</dd>
<dt><code>Lane5Speed</code></dt><dd><p>a numeric vector of vehicle speed in miles per hour.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Retrieved from PeMS.
</p>


<h3>References</h3>

<p>Einbeck, J.,  and Dwyer, J. (2011). Using principal curves to analyze traffic patterns on freeways. Transportmetrica 7, 229-246.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calspeedflow)
plot(calspeedflow[,3:4])
</code></pre>

<hr>
<h2 id='coverage'>
Coverage and self-coverage plots.
</h2><span id='topic+coverage'></span><span id='topic+coverage.raw'></span><span id='topic+lpc.coverage'></span><span id='topic+lpc.self.coverage'></span><span id='topic+ms.self.coverage'></span><span id='topic+select.self.coverage'></span>

<h3>Description</h3>

<p>These functions compute coverages and self-coverages, and produce corresponding plots, for any principal curve object.  The former may be used as goodness-of-fit measures, and the latter for for bandwidth selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coverage.raw(X, vec, tau, weights=1, plot.type="p", print=FALSE,
      label=NULL,...)

coverage(X, vec, taumin=0.02, taumax, gridsize=25, weights=1,
      plot.type="o", print=FALSE,...)

lpc.coverage(object, taumin=0.02, taumax, gridsize=25, quick=TRUE,
      plot.type="o", print=FALSE, ...)

lpc.self.coverage(X,  taumin=0.02, taumax=0.5,   gridsize=25, x0=1,
     way = "two", scaled=1,  weights=1, pen=2, depth=1,
     control=lpc.control(boundary=0, cross=FALSE),   quick=TRUE,
     plot.type="o", print=FALSE, ... )
 
ms.self.coverage(X, taumin=0.02, taumax=0.5, gridsize=25,
       thr=0.001, scaled=1, cluster=FALSE, plot.type="o", 
       print=FALSE, ...)
       
select.self.coverage(self,  smin, plot.type="o", plot.segments=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coverage_+3A_x">X</code></td>
<td>
<p>a <code class="reqn">N \times d</code> data matrix.</p>
</td></tr>
<tr><td><code id="coverage_+3A_object">object</code></td>
<td>
<p>An object of type <code>lpc</code>, <code>lpc.spline</code> or <code>ms</code>.</p>
</td></tr>
<tr><td><code id="coverage_+3A_vec">vec</code></td>
<td>
<p>A matrix with <code class="reqn">d</code> columns. The rows contain the points which
make up the fitted object.</p>
</td></tr>
<tr><td><code id="coverage_+3A_tau">tau</code></td>
<td>
<p>tube size.</p>
</td></tr>
<tr><td><code id="coverage_+3A_taumin">taumin</code></td>
<td>
<p>Minimal tube size.</p>
</td></tr>
<tr><td><code id="coverage_+3A_taumax">taumax</code></td>
<td>
<p>Maximal tube size.</p>
</td></tr>
<tr><td><code id="coverage_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights.  If weights are specified,
then the coverage is the weighted mean of the indicator functions
for falling within the tube. The function <code>lpc.coverage</code> does not have a
<code>weights</code> argument, as it extracts the weights from the
<code>$weights</code> component of the fitted <code>object</code>. </p>
</td></tr>
<tr><td><code id="coverage_+3A_label">label</code></td>
<td>
<p>Experimental option; don't use.</p>
</td></tr>   
<tr><td><code id="coverage_+3A_gridsize">gridsize</code></td>
<td>
<p>The number of different tube sizes to consider.</p>
</td></tr>
<tr><td><code id="coverage_+3A_quick">quick</code></td>
<td>
<p>If TRUE, an approximate coverage curve is provided by
computing distances between data points and the curve through  the
closest local centers or mass; whereas with FALSE  we use the
distances of the points when projected orthogonally onto the spline
representation of the local principal curve. The latter takes considerably
more computing time. The resulting coverage curves are generally very
similar, but the quick version may deliver little spurious peaks occasionally.  
</p>
</td></tr>
<tr><td><code id="coverage_+3A_thr">thr</code></td>
<td>
<p>adjacent mean shift clusters are merged if their relative
distance falls below this threshold.</p>
</td></tr>
<tr><td><code id="coverage_+3A_cluster">cluster</code></td>
<td>
<p>if <code>TRUE</code>, distances are always measured to the
cluster to which an observation is assigned, rather than to the
nearest cluster.</p>
</td></tr>
<tr><td><code id="coverage_+3A_self">self</code></td>
<td>
<p>An object of class <code>self</code>, or a matrix with two columns
providing a self-coverage curve.</p>
</td></tr> 
<tr><td><code id="coverage_+3A_smin">smin</code></td>
<td>
<p>Minimum coverage for bandwidth selection. Default: 1/3 for
clustering, 2/3 for principal curves.</p>
</td></tr>
<tr><td><code id="coverage_+3A_plot.type">plot.type</code></td>
<td>
<p>If set to 0, no plotted output is given. Otherwise,
an appropriate plot is provided, using the plotting type as
specified. </p>
</td></tr>
<tr><td><code id="coverage_+3A_plot.segments">plot.segments</code></td>
<td>
<p>A list with default <code>list(lty=c(1,2,3),
    lwd=c(2,1,1),lcol=c(3,3,3))</code> which specifies how (and how many)
bandwidth candidates, in order of decreasing negative second derivative of
self-coverage, are to be highlighted.</p>
</td></tr>
<tr><td><code id="coverage_+3A_print">print</code></td>
<td>
<p>If TRUE, coverage values are printed on the screen as soon as
computed. This is quite helpful especially if <code>gridsize</code> is large.</p>
</td></tr> 
<tr><td><code id="coverage_+3A_x0">x0</code>, <code id="coverage_+3A_way">way</code>, <code id="coverage_+3A_scaled">scaled</code>, <code id="coverage_+3A_pen">pen</code>, <code id="coverage_+3A_depth">depth</code>, <code id="coverage_+3A_control">control</code></td>
<td>
<p>Auxiliary parameters as outlined in
<code><a href="#topic+lpc">lpc</a></code>, <code><a href="#topic+lpc.control">lpc.control</a></code>, and <code><a href="#topic+ms">ms</a></code>.</p>
</td></tr>
<tr><td><code id="coverage_+3A_...">...</code></td>
<td>
<p>Optional graphical parameters passed to the corresponding
plotting functions.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function <code>coverage.raw</code> computes the coverage, i.e. the
proportion of data points lying inside a circle or band with radius
<code class="reqn">\tau</code>, for a fixed value <code>tau</code>.  The whole coverage curve
<code class="reqn">C(\tau)</code> is constructed through function <code>coverage</code>.  
</p>
<p>Functions <code>coverage.raw</code> and <code>coverage</code> can be used for any
object fitted by an unsupervised learning technique (for instance, HS principal curves, or even clustering
algorithms), while the functions prefixing with <code>lpc.</code> and <code>ms.</code> can only be
used for the corresponding objects. The functions <code>lpc.coverage</code> and <code>ms.coverage</code> are wrappers around 
<code>coverage</code> which operate directly a fitted object, rather
than a data matrix.
</p>
<p>Function <code>select.self.coverage</code> extracts suitable bandwidths from the
self-coverage curve, and produces a plot. The function is called from
within <code>lpc.self.coverage</code> or <code>ms.self.coverage</code>
but can also be called directly by the user (for instance, if the graphical output is to be reproduced, or if
the minimum coverage <code>smin</code> is to be modified). The component
<code>$select</code>  contains the selected candidate bandwidths, in the order
of strength of evidence provided by the self-coverage criterion (the
best bandwidth comes first, etc.). A plot is produced as a by-product,
which symbolizes the best bandwidth by a thick solid line, the
second-best by a dashed line, and the third-best by a dotted line. It is
recommended to run the self-coverage functions with fixed starting
points, as in the examples below, and to scale by the range only.
</p>
<p>See Einbeck (2011) for details. Note that the original publication by Einbeck, Tutz, and Evers (2005) uses &lsquo;quick&rsquo; coverage curves.
</p>


<h3>Value</h3>

<p>A list of items, and a plot (unless <code>plot.type=0</code>).
</p>
<p>The functions <code>lpc.self.coverage</code> and <code>ms.self.coverage</code> produce an object of class
<code>self</code>.  The component <code>$select</code> recommends suitable
bandwidths for the use in <code>lpc</code>, in the order of strength of
evidence. These correspond to points of strong negative curvature (implemented via second
differences) of the self-coverage curve.    
</p>


<h3>Author(s)</h3>

<p>J. Einbeck 
</p>


<h3>References</h3>

<p>Einbeck, J.,  Tutz, G.,  &amp; Evers, L. (2005). Local principal curves. Statistics and Computing 15, 301-313.
</p>
<p>Einbeck, J. (2011). Bandwidth selection for mean-shift based
unsupervised learning techniques: a unified approach via
self-coverage. Journal of Pattern Recognition Research 6, 175-192.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc">lpc</a></code>, <code><a href="#topic+ms">ms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(faithful)
mfit &lt;- ms(faithful)
coverage(mfit$data, mfit$cluster.center, gridsize=16)


f.self &lt;- ms.self.coverage(faithful,gridsize= 50, taumin=0.1, taumax=0.5, plot.type="o")   
h &lt;- select.self.coverage(f.self)$select
mfit2 &lt;- ms(faithful,h=h[2]) # using `second-best' suggested bandwidth 



data(gvessel)
g.self &lt;-lpc.self.coverage(gvessel[,c(2,4,5)], x0=c(35, 1870, 6.3), print=FALSE, plot.type=0)
h &lt;- select.self.coverage(g.self)$select
g.lfit &lt;- lpc(gvessel[,c(2,4,5)], h=h[1],  x0=c(35, 1870, 6.3))
lpc.coverage(g.lfit, gridsize=10, print=FALSE)


</code></pre>

<hr>
<h2 id='followx'>
Fit an individual branch of a local principal curve.
</h2><span id='topic+followx'></span>

<h3>Description</h3>

<p>Internal function of package <span class="pkg">LPCM</span> called by <code>lpc</code>. Do not use! 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>followx(Xi, x0, h, t0, iter, way, weights, pen = 2, 
    lasteigenvector = 0, rho0 = 0.4, boundary=0.005,
    convergence.at= 0.000001, cross=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="followx_+3A_xi">Xi</code></td>
<td>

<p>data matrix
</p>
</td></tr>
<tr><td><code id="followx_+3A_x0">x0</code></td>
<td>

<p>branch starting point
</p>
</td></tr>
<tr><td><code id="followx_+3A_h">h</code></td>
<td>

<p>bandwidth
</p>
</td></tr>
<tr><td><code id="followx_+3A_t0">t0</code></td>
<td>

<p>step length
</p>
</td></tr>
<tr><td><code id="followx_+3A_iter">iter</code></td>
<td>

<p>number of iterations (within the given curve branch)
</p>
</td></tr>
<tr><td><code id="followx_+3A_way">way</code></td>
<td>

<p>possible values &quot;one&quot;, &quot;two&quot;, &quot;back&quot; (in which directions the curve should proceed)
</p>
</td></tr>
<tr><td><code id="followx_+3A_weights">weights</code></td>
<td>

<p>vector of weights
</p>
</td></tr>
<tr><td><code id="followx_+3A_pen">pen</code></td>
<td>

<p>power used for angle penalization
</p>
</td></tr>
<tr><td><code id="followx_+3A_lasteigenvector">lasteigenvector</code></td>
<td>

<p>to be passed on from <code>lpc</code>
</p>
</td></tr>
<tr><td><code id="followx_+3A_rho0">rho0</code></td>
<td>

<p>constant; see reference [1] in <code><a href="#topic+lpc.control">lpc.control</a></code>.
</p>
</td></tr>
<tr><td><code id="followx_+3A_boundary">boundary</code></td>
<td>

<p>boundary correction, see Einbeck and Zayed (2014)
</p>
</td></tr>
<tr><td><code id="followx_+3A_convergence.at">convergence.at</code></td>
<td>

<p>convergence parameter
</p>
</td></tr>
<tr><td><code id="followx_+3A_cross">cross</code></td>
<td>

<p>Boolean; are curves allowed to cross?
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>JE
</p>


<h3>References</h3>

<p>Einbeck, J., &amp; Zayed, M. (2014). Some asymptotics for localized principal components and curves. Communications in Statistics - Theory and Methods, 43(8), 1736-1749. doi: 10.1080/03610926.2012.673676
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc">lpc</a></code>
</p>

<hr>
<h2 id='gaia'>
Gaia data
</h2><span id='topic+gaia'></span>

<h3>Description</h3>

<p>(Simulated) spectral decomposition of stellar objects, generated in the framework of the Gaia project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gaia)</code></pre>


<h3>Format</h3>

<p>A data frame with 8286 observations on the following 22 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>ID of the object</p>
</dd>
<dt><code>metallicity</code></dt><dd><p>metallicity (abundance); that is proportion of matter  other than hydrogen and helium relative to that of the sun.</p>
</dd>
<dt><code>gravity</code></dt><dd><p>the surface gravity; that is acceleration due to gravity at the surface of the star. </p>
</dd>
<dt><code>temperature</code></dt><dd><p>the &lsquo;effective&rsquo; temperature (K); that is the temperature of the observable part of the stellar atmosphere.</p>
</dd>
<dt><code>band1</code></dt><dd><p>photon counts in band 1</p>
</dd>
<dt><code>band2</code></dt><dd><p>photon counts in band 2</p>
</dd>
<dt><code>band3</code></dt><dd><p>photon counts in band 3</p>
</dd>
<dt><code>band4</code></dt><dd><p>photon counts in band 4</p>
</dd>
<dt><code>band5</code></dt><dd><p>photon counts in band 5</p>
</dd>
<dt><code>band6</code></dt><dd><p>photon counts in band 6</p>
</dd>
<dt><code>band7</code></dt><dd><p>photon counts in band 7</p>
</dd>
<dt><code>band8</code></dt><dd><p>photon counts in band 8</p>
</dd>
<dt><code>band9</code></dt><dd><p>photon counts in band 9</p>
</dd>
<dt><code>band10</code></dt><dd><p>photon counts in band 10</p>
</dd>
<dt><code>band11</code></dt><dd><p>photon counts in band 11</p>
</dd>
<dt><code>band12</code></dt><dd><p>photon counts in band 12</p>
</dd>
<dt><code>band13</code></dt><dd><p>photon counts in band 13</p>
</dd>
<dt><code>band14</code></dt><dd><p>photon counts in band 14</p>
</dd>
<dt><code>band15</code></dt><dd><p>photon counts in band 15</p>
</dd>
<dt><code>band16</code></dt><dd><p>photon counts in band 16</p>
</dd>
</dl>



<h3>Details</h3>

<p>Gaia is an astrophysics mission of the European Space Agency (ESA) which will
undertake a detailed survey of over 10^9 stars in our Galaxy and
extragalactic objects.  An important part of the scientific analysis of these
data is the classification of all the objects as well as the estimation of
stellar astrophysical parameters (effective stellar temperature, surface gravity, metallicity). This will be done on the basis of
high-dimensional spectroscopic and astrometric data such as those ones given here. 
</p>
<p>More precisely, the  spectral data come in form of photon counts (&quot;fluxes&quot;) observed in (originally) 96 wavelength intervals (&quot;bands&quot;), see Bailer-Jones (2010) for more details. The data given here are a 16-dimensional subset created by binning/selecting from the 96 bands.  The counts given here are standardized, i.e. they are divided by the total number of incoming photons over all filters  (in other words, they add up to 1).  Note that these data are simulated using computer models. The satellite which will collect the actual data will be launched in 2012.
</p>
<p>The 16-d spectral data  have been used in Einbeck, Evers and Bailer-Jones (2008) as well as Einbeck, Evers and Powell (2010) in order to predict the stellar temperature.
</p>


<h3>Source</h3>

<p>Coryn Bailer-Jones (MPIA Heidelberg).
</p>


<h3>References</h3>

<p>Bailer-Jones, C.A.L. (2010). The ILIUM forward modelling algorithm for multivariate parameter estimation and its application to derive stellar parameters from Gaia spectrophotometry, Monthly Notices of the Royal Astronomical Society, vol. 403, pp. 96-116.
</p>
<p>Einbeck, J., Evers, L., and Bailer-Jones, C.A.L. (2008).  Representing complex data using localized principal components with application to astronomical data. In: Gorban, A, Kegl, B, Wunsch, D, &amp; Zinovyev, A:  Principal Manifolds for Data Visualization and Dimension Reduction; Lecture Notes in Computational Science and Engineering  58, 180-204, ISSN/ISBN: 978-3-540-73749-0. 
</p>
<p>Einbeck, J., Evers, L., and Powell, B. (2010): Data compression and regression through local principal curves and surfaces, International Journal of Neural Systems, 20, 177-192.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gaia)
s &lt;- sample(nrow(gaia),200)
library(lattice)
splom(gaia[s,5:20], cex=0.3, pscales=0)


gaia.pc &lt;-  princomp(gaia[s,5:20])
temp &lt;- gaia$temperature
tempcol     &lt;- (temp[s]- min(temp[s]))/max(temp[s]- min(temp[s]))
library(scatterplot3d)
scatterplot3d(gaia.pc$scores[,c(2,1,3)], pch="+",
     color=rgb(sqrt(tempcol),0,1-sqrt(tempcol)))
     # This is a 3D scatterplot of the first three principal component scores;
     # with higher stellar temperatures shaded in red colour.

</code></pre>

<hr>
<h2 id='gvessel'>
North Atlantic Water Temperature Data.
</h2><span id='topic+gvessel'></span>

<h3>Description</h3>

<p>These are observations taken over nine days in May 2000 by the German vessel Gauss in the North Atlantic. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gvessel)</code></pre>


<h3>Format</h3>

<p>A data frame with 643 observations on the following 7 variables. 
</p>

<dl>
<dt><code>day2g</code></dt><dd><p>an integer for the day at which the measurement was taken.</p>
</dd>
<dt><code>salg</code></dt><dd><p>a numeric vector with measurements of salinity according to the PSS (Practical Salinity Scale).</p>
</dd>
<dt><code>tempg</code></dt><dd><p>a numeric vector with measurements of water temperature in degrees Celsius.</p>
</dd>
<dt><code>depthg</code></dt><dd><p>a numeric vector with the water depths (in meters) at which the measurements were taken.</p>
</dd>
<dt><code>oxyg</code></dt><dd><p>a numeric vector with measurements of oxygen content (mm per litre of water)</p>
</dd>
<dt><code>longg</code></dt><dd><p>longitude</p>
</dd>
<dt><code>latg</code></dt><dd><p>latitude</p>
</dd>
</dl>



<h3>Source</h3>

<p>Retrieved by B. Powell from the World Ocean Database.
</p>


<h3>References</h3>

<p>Einbeck, J., Evers, L., and Powell, B. (2010): Data compression and regression through local principal curves and surfaces, International Journal of Neural Systems, 20, 177-192.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gvessel)
pairs(gvessel[,c(3,2,4,5)])
tcol &lt;- (gvessel$tempg- min(gvessel$tempg))/(max(gvessel$tempg)- min(gvessel$tempg))
require(scatterplot3d)
scatterplot3d(gvessel[,2],gvessel[,4],gvessel[,5], color=rgb(tcol,0,1-tcol))
</code></pre>

<hr>
<h2 id='kernels.and.distances'>
Auxiliary  kernel and distance functions.</h2><span id='topic+kern'></span><span id='topic+kernd'></span><span id='topic+kdex'></span><span id='topic+vecdist'></span><span id='topic+mindist'></span><span id='topic+distancevector'></span><span id='topic+enorm'></span>

<h3>Description</h3>

<p>Internal  <span class="pkg">LPCM</span> functions which are normally not to be called by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern(y, x = 0, h = 1)
kernd(X, x, h)
kdex(X, x, h)
distancevector(X, y, d = "euclid", na.rm = TRUE)
vecdist(X,Y)
mindist(X,y)
enorm(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernels.and.distances_+3A_x">x</code></td>
<td>
<p>a number or vector.</p>
</td></tr>
<tr><td><code id="kernels.and.distances_+3A_y">y</code></td>
<td>
<p>a vector.</p>
</td></tr>
<tr><td><code id="kernels.and.distances_+3A_h">h</code></td>
<td>
<p>a bandwidth.</p>
</td></tr>
<tr><td><code id="kernels.and.distances_+3A_x">X</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="kernels.and.distances_+3A_y">Y</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="kernels.and.distances_+3A_d">d</code></td>
<td>
<p>type of distance measure (only &lsquo;euclid&rsquo;).</p>
</td></tr>
<tr><td><code id="kernels.and.distances_+3A_na.rm">na.rm</code></td>
<td>
<p>...</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>kern</code> specifies the base kernel (by default Gaussian) used in
<code>lpc</code> ; <code>kernd</code> is the corresponding multivariate product
kernel.  <code>kdex</code> is a pointwise multivariate kernel density estimator.
</p>
<p><code>distancevector</code> makes use of function <code>vdisseuclid</code> from <span class="rlang"><b>R</b></span> package <span class="pkg">hopach</span> (but that package does not need to be loaded). <code>enorm</code> is the Euclidean norm.
</p>


<h3>Author(s)</h3>

<p>JE
</p>


<h3>References</h3>

<p>Pollard, van der Laan, and Wall (2010). Hierarchical Ordered Partitioning and Collapsing Hybrid (HOPACH). <span class="rlang"><b>R</b></span> package <span class="pkg">hopach</span> version 2.9.1.
</p>

<hr>
<h2 id='lpc'>
Local principal curves
</h2><span id='topic+lpc'></span>

<h3>Description</h3>

<p>This is the main function which computes the actual local principal curve, i.e. a sequence of local centers of mass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpc(X, h, t0 = mean(h),  x0,  way = "two",  scaled = 1,
      weights=1, pen = 2, depth = 1, control=lpc.control())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpc_+3A_x">X</code></td>
<td>

<p>data matrix with <code class="reqn">N</code> rows (observations) and <code class="reqn">d</code> columns (variables). 
</p>
</td></tr>
<tr><td><code id="lpc_+3A_h">h</code></td>
<td>

<p>bandwidth. May be either specified as a single number, then the same bandwidth is used in
all dimensions, or as a <code class="reqn">d</code>-dimensional bandwidth vector. If the data are scaled, then the bandwidth has to be
specified in fractions of the data range or standard deviation, respectively, e.g. <code>scaled=1</code> and <code>h= c(0.2,0.1)</code> gives 20 percent of the range of the first variable and 10 percent of the range of the second variable.  If left unspecified, then default settings are invoked; see the &lsquo;Notes&rsquo; section below. 
</p>
</td></tr>
<tr><td><code id="lpc_+3A_t0">t0</code></td>
<td>
<p>scalar step length. Default setting is <code>t0=h</code>, if <code>h</code> is a scalar, and <code>t0=mean(h)</code>, if <code>h</code> is a vector.
</p>
</td></tr>
<tr><td><code id="lpc_+3A_x0">x0</code></td>
<td>
<p> specifies the choice of starting points.  The default
choice <code>x0=1</code> will select one suitable starting point automatically (in
form of a local density mode). The second built-in option <code>x0=0</code> will
use all local density modes as starting points, hence produce
as many branches as modes.  Optionally, one
can also set one or more  starting points manually here. This can
be done in form of a matrix, where each row corresponds to a
starting point, or in form of a vector, where starting points are
read in consecutive order from the entries of the vector. 
The starting point has always to be specified on the original data
scale, even if <code>scaled&gt;0</code>.  A fixed  number of starting
points can be enforced through option <code>mult</code> in <code>lpc.control</code>.
</p>
</td></tr>
<tr><td><code id="lpc_+3A_way">way</code></td>
<td>
<p>&quot;one&quot;: go only in direction of the first local eigenvector,
&quot;back&quot;: go only in opposite direction,
&quot;two&quot;: go from starting point in both directions.
</p>
</td></tr>
<tr><td><code id="lpc_+3A_scaled">scaled</code></td>
<td>

<p>if 1 (or <code>TRUE</code>), scales each variable by dividing through its range. If <code>scaled=2</code>, scaling is performed by dividing through the standard deviation (see also the Notes section below).
</p>
</td></tr>
<tr><td><code id="lpc_+3A_weights">weights</code></td>
<td>
<p>a vector of observation weights (can also be used to exclude
individual observations from the computation by setting their weight to
zero.)</p>
</td></tr> 
<tr><td><code id="lpc_+3A_pen">pen</code></td>
<td>

<p>power used for angle penalization (see [1]). If set to 0, the angle
penalization is switched off.
</p>
</td></tr>
<tr><td><code id="lpc_+3A_depth">depth</code></td>
<td>

<p>maximum depth of branches (<code class="reqn">\phi_{max}</code> in [2]),
restricted to the values 1,2 or 3  (The original LPC branch has
depth 1.  If, along this curve, a point features a high  second local
PC, this launches a new starting point, and the resulting branch has
depth 2.   If, along this branch, a point features a high second local
PC, this launches a new starting point, and the resulting branch has
depth 3. ) 
</p>
</td></tr>
<tr><td><code id="lpc_+3A_control">control</code></td>
<td>

<p>Additional parameters steering particularly the starting-, boundary-, and convergence
behavior of the fitted curve. See <code><a href="#topic+lpc.control">lpc.control</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of items:
</p>
<table>
<tr><td><code>LPC</code></td>
<td>

<p>The coordinates of the local centers of mass of the fitted
principal curve.
</p>
</td></tr>
<tr><td><code>Parametrization</code></td>
<td>
<p>Curve parameters and branch labels for
each local center of mass.</p>
</td></tr> 
<tr><td><code>h</code></td>
<td>

<p>The bandwidth used for the curve estimation.
</p>
</td></tr>
<tr><td><code>to</code></td>
<td>

<p>The constant <code class="reqn">t_0</code> used for the curve estimation.
</p>
</td></tr>
<tr><td><code>starting.points</code></td>
<td>

<p>The coordinates of the starting point(s) used.
</p>
</td></tr>  
<tr><td><code>data</code></td>
<td>

<p>The data frame used for curve estimation.
</p>
</td></tr>
<tr><td><code>scaled</code></td>
<td>
<p>the user-supplied value, could be boolean or numerical</p>
</td></tr> 
<tr><td><code>weights</code></td>
<td>
<p>The vector of weights used for curve estimation.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>The settings used in <code>lpc.control()</code></p>
</td></tr> 
<tr><td><code>Misc</code></td>
<td>
<p> Miscellanea.</p>
</td></tr>





</table>


<h3>Note</h3>

<p>All values provided in the output refer to the scaled data, unless <code>scaled=0</code> or (equivalently) <code>scaled=FALSE</code>. Use <code><a href="#topic+unscale">unscale</a></code> to convert the results back to the original data scale. 
</p>
<p>The default option <code>scaled=1</code> or  <code>scaled=TRUE</code>  scales the data by dividing each variable through their
range (differing from the scaling through
the standard deviation as common e.g. for  PCA).  The setting <code>scaled=2</code>, and in fact all other settings  <code>scaled&gt;0</code>, will scale the data by their standard deviation.
</p>
<p>If <code>scaled=1</code> or if no scaling is applied, then the default bandwidth setting is 10 percent of the data range in each direction. If the data are scaled through the standard deviation, then the default setting is 40 percent of the standard deviation in each direction. 
</p>


<h3>Author(s)</h3>

<p>J. Einbeck and L. Evers.  See <code><a href="#topic+LPCM-package">LPCM-package</a></code> for further acknowledgements.
</p>


<h3>References</h3>

<p>[1] Einbeck, J., Tutz, G., &amp; Evers, L. (2005). Local principal curves. Statistics and Computing 15, 301-313.
</p>
<p>[2] Einbeck, J., Tutz, G., &amp; Evers, L. (2005): Exploring Multivariate Data Structures with Local Principal Curves. In: Weihs, C. and Gaul, W. (Eds.): Classification - The Ubiquitous Challenge. Springer, Heidelberg, pages 256-263. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(calspeedflow)
lpc1 &lt;- lpc(calspeedflow[,3:4])
plot(lpc1)

data(mussels, package="dr")
 lpc2 &lt;- lpc(mussels[,-3], x0=as.numeric(mussels[49,-3]),scaled=0)
 plot(lpc2, curvecol=2)

data(gaia)
s &lt;- sample(nrow(gaia),200)
gaia.pc &lt;-  princomp(gaia[s,5:20])
lpc3 &lt;- lpc(gaia.pc$scores[,c(2,1,3)],scaled=0)
plot(lpc3, curvecol=2, type=c("curve","mass"))

# Simulated letter 'E' with branched LPC
ex&lt;- c(rep(0,40), seq(0,1,length=20), seq(0,1,length=20), seq(0,1,length=20))
ey&lt;- c(seq(0,2,length=40), rep(0,20), rep(1,20), rep(2,20))
sex&lt;-rnorm(100,0,0.01); sey&lt;-rnorm(100,0,0.01)
eex&lt;-rnorm(100,0,0.1);  eey&lt;-rnorm(100,0,0.1)
ex1&lt;-ex+sex; ey1&lt;-ey+sey
ex2&lt;-ex+eex; ey2&lt;-ey+eey
e1&lt;-cbind(ex1,ey1); e2&lt;-cbind(ex2,ey2)
lpc.e1 &lt;- lpc(e1, h= c(0.1,0.1),  depth=2, scaled=0)
plot(lpc.e1, type=c("curve","mass", "start"))
</code></pre>

<hr>
<h2 id='lpc.control'>
Auxiliary parameters for controlling local principal curves.
</h2><span id='topic+lpc.control'></span>

<h3>Description</h3>

<p>This function bundles parameters controlling mainly the starting-, convergence-, boundary-,
and stopping-behaviour of the local principal curve. It will be used
only inside the <code>lpc()</code> function argument. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpc.control(iter =100, cross=TRUE,
            boundary = 0.005, convergence.at = 0.00001,
            mult=NULL, ms.h=NULL, ms.sub=30, 
            pruning.thresh=0.0, rho0=0.4) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpc.control_+3A_iter">iter</code></td>
<td>

<p>Maximum number of iterations on either side of the starting point within each branch.
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_cross">cross</code></td>
<td>
<p>Logical parameter. If <code>FALSE</code>, a curve is stopped when it
comes too close to an another part of itself. Note: Even when
<code>cross=FALSE</code>, different branches of the curve (for higher depth
or multiple starting points) are still allowed
to cross. This option only avoids crossing of each particular branch
with itself. Used in the self-coverage functions to avoid overfitting. </p>
</td></tr>
<tr><td><code id="lpc.control_+3A_boundary">boundary</code></td>
<td>

<p>This boundary correction [2] reduces the bandwidth adaptively once the
relative difference of parameter values between two centers of mass
falls below the given threshold. This measure delays convergence and
enables the curve to proceed further into the end points. If set to 0,
this boundary correction is switched off. 
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_convergence.at">convergence.at</code></td>
<td>

<p>This forces the curve to stop if  the
relative difference of parameter values between two centers of mass
falls below the given threshold.  If set to 0, then the curve will
always stop after exactly <code>iter</code> iterations.
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_mult">mult</code></td>
<td>
<p> numerical value which enforces a fixed number of starting points.  If the
number  given here is larger than the number of starting points
provided at <code>x0</code>,  then the missing points will be set at
random (For example, if <code class="reqn">d=2</code>, <code>mult=3</code>, and
<code>x0=c(58.5, 17.8, 80,20)</code>,  then one gets the starting points (58.5, 17.8), (80,20), and a randomly
chosen  third one.  Another example for such a situation is <code>x0=NULL</code> with
<code>mult=1</code>, in which one random starting point is chosen). If the number given here is smaller the number of starting points
provided at <code>x0</code>, then only the first <code>mult</code> starting
points will be used.
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_ms.h">ms.h</code></td>
<td>
<p>sets the bandwidth (vector) for the initial mean shift procedure
which finds the local density modes, and, hence, the starting points
for the LPC. If unspecified, the bandwidth <code>h</code>  used in
function <code>lpc</code> is used here too.
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_ms.sub">ms.sub</code></td>
<td>
<p> proportion of data points (default=30) which are used to initialize
mean shift trajectories for the mode finding. In fact, we use
</p>
<p><code>min(max(ms.sub, floor(ms.sub*N/100)), 10*ms.sub)</code>
</p>
<p>trajectories.
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_pruning.thresh">pruning.thresh</code></td>
<td>

<p>Prunes branches corresponding to higher-depth starting points if
their density estimate falls below this threshold.  Typically, a value between 0.0
and 1.0. The setting 0.0 means no pruning.
</p>
</td></tr>
<tr><td><code id="lpc.control_+3A_rho0">rho0</code></td>
<td>

<p>A numerical value which  steers the birth process of higher-depth starting
points. Usually, between 0.3 and 0.4 (see reference [1]). 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the nine specified input parameters, which can be read by the
<code>control</code> argument of the <code>lpc</code> function. 





</p>


<h3>Author(s)</h3>

<p>JE
</p>


<h3>References</h3>

<p>[1] Einbeck, J., Tutz, G. &amp; Evers, L. (2005): Exploring Multivariate Data Structures with Local Principal Curves. In: Weihs, C. and Gaul, W. (Eds.): Classification - The Ubiquitous Challenge. Springer, Heidelberg, pages 256-263. 
</p>
<p>[2] Einbeck, J. and Zayed, M. (2014). Some asymptotics for localized
principal components and curves. Communications in Statistics - Theory and Methods 43, 1736-1749.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calspeedflow)
fit1 &lt;- lpc(calspeedflow[,c(3,4)], x0=c(50,60),scaled=1,
   control=lpc.control(iter=20, boundary=0))
plot(fit1, type=c("curve","start","mass"))
</code></pre>

<hr>
<h2 id='lpc.project'>
Projection onto LPC
</h2><span id='topic+lpc.project'></span>

<h3>Description</h3>

<p>Projects a new observation onto the spline representation of the local principal curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpc.project(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpc.project_+3A_object">object</code></td>
<td>
<p> Object of class <code>lpc</code> or <code>lpc.spline</code>.</p>
</td></tr>

<tr><td><code id="lpc.project_+3A_newdata">newdata</code></td>
<td>
<p>A data frame containing the new data to be projected.</p>
</td></tr>
<tr><td><code id="lpc.project_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code>lpc.project.spline</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>closest.pi</code></td>
<td>
<p>Projection index of projected point(s) (in cubic spline parametrization).</p>
</td></tr>
<tr><td><code>closest.or.pi</code></td>
<td>
<p>Projection index of projected point(s) (in terms of the original LPC parametrization). </p>
</td></tr>
<tr><td><code>closest.coords</code></td>
<td>
<p>Coordinates of projected data point(s)</p>
</td></tr>
<tr><td><code>closest.dist</code></td>
<td>
<p>Euclidean distance between data point(s) and their projected counterpart(s).</p>
</td></tr> 
<tr><td><code>closest.branch</code></td>
<td>
<p>ID of branch onto which the data point was
projected (the IDs get allocated in the  output component
<code>$Parametrization</code> of function <code>lpc</code>).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The parametrization of the cubic spline function is not exactly the same as that of the original LPC. The reason is that the latter uses Euclidean distances between centers of masses, while the former uses the arc length along the cubic spline. The differences are normally quite small, though.  
</p>


<h3>Author(s)</h3>

<p>J. Einbeck and L. Evers
</p>


<h3>References</h3>

<p>Einbeck, J., Evers, L. &amp; Hinchliff, K. (2010):  Data compression and regression based on local principal curves. In A. Fink, B. Lausen, W. Seidel, and A. Ultsch (Eds),  Advances in Data Analysis, Data Handling, and Business Intelligence, Heidelberg, pp. 701&ndash;712, Springer. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc">lpc</a></code>, <code><a href="#topic+lpc.spline">lpc.spline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gvessel)
gvessel.lpc &lt;- lpc(gvessel[,c(2,4,5)], scaled=TRUE,   h=0.11,  x0=c(35, 1870, 6.3))
lpc.project(gvessel.lpc, newdata=data.frame(salg=35,dephtg= 2000,oxyg=6))
</code></pre>

<hr>
<h2 id='lpc.spline'>
Representing local principal curves through a  cubic spline.
</h2><span id='topic+lpc.spline'></span>

<h3>Description</h3>

<p>Fits a natural cubic spline component-wise through the series of local centers of mass. This provides a continuous parametrization in terms of arc length distance, which can be used to compute a projection index for the original or new data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpc.spline(lpcobject, optimize = TRUE, compute.Rc=FALSE,
     project=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpc.spline_+3A_lpcobject">lpcobject</code></td>
<td>
<p>Object of class <code>lpc</code>.</p>
</td></tr>
<tr><td><code id="lpc.spline_+3A_optimize">optimize</code></td>
<td>
<p>Boolean. If TRUE, <code>optimize</code> is used to find the point on the curve with minimum distance. Otherwise, data points are only projected onto the closest knot.</p>
</td></tr>
<tr><td><code id="lpc.spline_+3A_compute.rc">compute.Rc</code></td>
<td>
<p>Boolean. If TRUE, the goodness-of-fit measure
<code class="reqn">R_C</code> suggested in [1] is computed  and returned (using the scaled data, if <code>scaled=TRUE</code> in <code>lpcobject</code>).  </p>
</td></tr>
<tr><td><code id="lpc.spline_+3A_project">project</code></td>
<td>
<p>Boolean. If TRUE, projections onto curve are computed.</p>
</td></tr>
<tr><td><code id="lpc.spline_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code>lpc.project.spline</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See  reference [2].
</p>


<h3>Value</h3>

<table>
<tr><td><code>knots.pi</code></td>
<td>
<p>LPC parameters (in cubic spline parametrization) at
position of the knots of the spline function (these are not
identical to the LPC mass points!)</p>
</td></tr>
<tr><td><code>knots.coords</code></td>
<td>
<p>Coordinates of the spline knots. </p>
</td></tr>
<tr><td><code>closest.pi</code></td>
<td>
<p>Parameter of the projected data points.</p>
</td></tr>
<tr><td><code>closest.coords</code></td>
<td>
<p>Coordinates of projected data points.</p>
</td></tr>
<tr><td><code>closest.dist</code></td>
<td>
<p>Euclidean distance between original and projected data point.</p>
</td></tr>
<tr><td><code>closest.branch</code></td>
<td>
<p>ID Number of the branch on which the data point
was 
projected (the IDs are given in the output of function <code>lpc</code>).</p>
</td></tr>
<tr><td><code>Rc</code></td>
<td>
<p>Value of <code class="reqn">R_C</code>. </p>
</td></tr>
<tr><td><code>project</code></td>
<td>
<p>repeats the input value of  <code>project</code>.</p>
</td></tr>
<tr><td><code>lpcobject</code></td>
<td>
<p>returns the provided object <code>lpcobject</code>.</p>
</td></tr>
<tr><td><code>splinefun</code></td>
<td>
<p>returns the cubic spline function (generated by
<code>lpc.splinefun</code>).</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>Careful with options <code>project</code> and <code>compute.Rc</code> - they can take rather long
if the data set is large!
</p>


<h3>Note</h3>

<p>The parametrization of the cubic spline function is not exactly the same as that of the original LPC. The reason is that the latter uses Euclidean distances between centers of masses, while the former uses the arc length along the cubic spline. However, the differences are normally quite small.  
</p>


<h3>Author(s)</h3>

<p>J. Einbeck and L. Evers
</p>


<h3>References</h3>

<p>[1] Einbeck, J., Tutz, G.,  and Evers, L. (2005). Local principal curves. Statistics and Computing 15, 301-313.
</p>
<p>[2] Einbeck, J., Evers, L. &amp; Hinchliff, K. (2010):  Data compression and regression based on local principal curves. In A. Fink, B. Lausen, W. Seidel, and A. Ultsch (Eds),  Advances in Data Analysis, Data Handling, and Business Intelligence, Heidelberg, pp. 701&ndash;712, Springer. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc">lpc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gvessel)
gvessel.lpc &lt;- lpc(gvessel[,c(2,4,5)],   h=0.11,  x0=c(35, 1870, 6.3))
gvessel.spline  &lt;- lpc.spline(gvessel.lpc)
plot(gvessel.spline, lwd=2)
</code></pre>

<hr>
<h2 id='lpc.spline.auxiliary.functions'>
Auxiliary functions for spline fitting and projection.
</h2><span id='topic+lpc.splinefun'></span><span id='topic+lpc.fit.spline'></span><span id='topic+lpc.spline.eval'></span><span id='topic+lpc.project.spline'></span><span id='topic+lpc.curve.length'></span>

<h3>Description</h3>

<p>Internal functions of package <span class="pkg">LPCM</span> called by <code>lpc.spline</code> and others. These will rarely be called directly by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpc.splinefun(lpcobject)

lpc.fit.spline(lpcsl, num.knots = 100)

lpc.spline.eval(lpcsl, or.pi, branch = 0)

lpc.project.spline(lpcsl, newdata, num.knots = 100, optimize = TRUE)

lpc.curve.length(lpcsl, or.pi, branch = 0, total.subdivisions = 10000,
      min.subdivisions = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_lpcobject">lpcobject</code></td>
<td>
<p>Object of type <code>lpc</code>.</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_lpcsl">lpcsl</code></td>
<td>
<p> Object generated by <code>lpc.splinefun</code>.</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_num.knots">num.knots</code></td>
<td>
<p>number of spline knots </p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_or.pi">or.pi</code></td>
<td>
<p>original projection index</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_branch">branch</code></td>
<td>
<p>branch ID</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_newdata">newdata</code></td>
<td>
<p>new data frame</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_optimize">optimize</code></td>
<td>
<p>Boolean.</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_total.subdivisions">total.subdivisions</code></td>
<td>
<p>total number of subdivisions for arc length computation.</p>
</td></tr>
<tr><td><code id="lpc.spline.auxiliary.functions_+3A_min.subdivisions">min.subdivisions</code></td>
<td>
<p>minimum number of subdivisions for arc length computation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>L. Evers and J. Einbeck
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc.spline">lpc.spline</a></code>
</p>

<hr>
<h2 id='LPCM-package'>
Local principal curve methods
</h2><span id='topic+LPCM-package'></span><span id='topic+LPCM'></span>

<h3>Description</h3>

<p>Fitting multivariate data patterns with local principal curves,
including tools for data compression (projection) and measuring goodness-of-fit; 
with some additional functions for mean shift clustering.
</p>
<p>This package implements the techniques introduced in Einbeck, Tutz
&amp; Evers (2005), Einbeck, Evers &amp; Powell (2010), Einbeck (2011), Almeijeiras-Alonso and Einbeck (2023).
</p>
<p>The main functions to be called by the user are
</p>

<ul>
<li> <p><code><a href="#topic+lpc">lpc</a></code>, for the estimation of the local centers of mass
which describe the principal curve;
</p>
</li>
<li> <p><code><a href="#topic+ms">ms</a></code>, for calculation of mean shift trajectories and associated clusters.









</p>
</li></ul>

<p>The package contains also specialized functions for projection and spline fitting (<code><a href="#topic+lpc.project">lpc.project</a></code>, <code><a href="#topic+lpc.spline">lpc.spline</a></code>), functions for bandwidth selection (<code><a href="#topic+lpc.self.coverage">lpc.self.coverage</a></code>, <code><a href="#topic+ms.self.coverage">ms.self.coverage</a></code>), goodness of fit assessment (<code><a href="#topic+Rc">Rc</a></code>, <code><a href="#topic+coverage">coverage</a></code>), as well as some methods for generic functions such as  <code><a href="base.html#topic+print">print</a></code> and <code><a href="graphics.html#topic+plot">plot</a></code>. 
</p>







<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> LPCM</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Acknowledgements</h3>

<p>Contributions (in form of pieces of code, or useful suggestions for
improvements) by Jo Dwyer, Mohammad Zayed, and
Ben Oakley are gratefully acknowledged.
</p>


<h3>Author(s)</h3>

<p>Jochen Einbeck and Ludger Evers
</p>
<p>Maintainer: Jochen Einbeck &lt;jochen.einbeck@durham.ac.uk&gt;
</p>


<h3>References</h3>

<p>Einbeck, J., Tutz, G., &amp; Evers, L. (2005): Local principal curves, Statistics and Computing 15, 301-313.
</p>
<p>Einbeck, J., Evers, L., &amp; Powell, B. (2010): Data compression and regression through local principal curves and surfaces, International Journal of Neural Systems 20, 177-192.
</p>
<p>Einbeck, J. (2011): Bandwidth selection for nonparametric unsupervised
learning techniques &ndash; a unified approach via self-coverage. Journal of
Pattern Recognition Research 6, 175-192. 
</p>
<p>Almeijeiras-Alonso, J. and Einbeck, J. (2023). A fresh look at mean-shift based modal clustering, Advances in Data Analysis and Classification, doi:10.1007/s11634-023-00575-1.
</p>


<h3>See Also</h3>

<p>pcurve, princurve
</p>

<hr>
<h2 id='ms'>
Mean shift clustering.
</h2><span id='topic+ms'></span>

<h3>Description</h3>

<p>Function for mean shift clustering, which, for a given bandwidth, detects the local modes and performs the clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ms(X, h, subset,  thr=0.01, scaled= 1, iter=200, plot=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ms_+3A_x">X</code></td>
<td>
<p>data matrix or vector.</p>
</td></tr>
<tr><td><code id="ms_+3A_h">h</code></td>
<td>
<p>scalar or vector-valued bandwidth (by default, 5 percent of
the  data range, or 20 percent of the standard deviation, respectively, in each direction). If set manually and <code>scaled&gt;0</code>, this
bandwidth needs to be set on the scaled scale; for instance setting scale; for instance <code>scaled=1</code> and <code>h=0.10</code> will use a bandwidth of <code class="reqn">10</code> percent of the  data range in either direction. </p>
</td></tr>
<tr><td><code id="ms_+3A_subset">subset</code></td>
<td>
<p>vector specifying a subset of 1:n, where n is the sample
size. This allows to run the iterative mean shift procedure only
from a subset of points (if unspecified, 1:n is used here,
i.e. each data point serves as a starting point).</p>
</td></tr> 
<tr><td><code id="ms_+3A_thr">thr</code></td>
<td>
<p>adjacent mean shift clusters are merged if their relative
distance falls below this threshold (see Note section).</p>
</td></tr>
<tr><td><code id="ms_+3A_scaled">scaled</code></td>
<td>
<p>if equal to 1 (default), each variable is divided by its range, and if equal to 2 (or any other positive value other than 1), each variable is divided by its standard deviation. If equal to 0, then no scaling is applied.</p>
</td></tr>
<tr><td><code id="ms_+3A_iter">iter</code></td>
<td>
<p>maximum mean shift iterations (passed to <code>ms.rep</code>).</p>
</td></tr>
<tr><td><code id="ms_+3A_plot">plot</code></td>
<td>
<p>if equal to 0, then no plotted output. For bivariate
data, <code>plot=1</code> gives by default a dynamically created color plot showing the mean
shift trajectories and the resulting clustering.</p>
</td></tr> 
<tr><td><code id="ms_+3A_...">...</code></td>
<td>
<p>further graphical parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods implemented here can be used for density mode estimation,
clustering, and the selection of starting points for the LPC algorithm. They are based on Almeijeiras-Alonso and Einbeck (2023).
</p>
<p>It can be shown (Chen, 1995, Comaniciu &amp; Meer, 2002, Li, 2005) that, if the mean shift is computed iteratively, the
resulting sequence of local means converges to a mode of the estimated
density function.  By assigning each data point to the mode to which it
has converged, this turns into a clustering technique.
</p>


<h3>Value</h3>

<p>The function <code>ms</code> produces an object of class <code>ms</code>,
with components:
</p>
<table>
<tr><td><code>cluster.center</code></td>
<td>
<p>a matrix which gives the coordinates of the
estimated density modes (i.e., of the mean-shift based cluster centers).</p>
</td></tr>
<tr><td><code>cluster.label</code></td>
<td>
<p>assigns each data point to the cluster center to
which its mean shift trajectory has converged. </p>
</td></tr>
<tr><td><code>closest.label</code></td>
<td>
<p>assigns each data point to the closest cluster
center in terms of Euclidean distance.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the data frame (scaled if <code>scaled=TRUE</code>).</p>
</td></tr>
<tr><td><code>scaled</code></td>
<td>
<p>the user-supplied value, could be boolean or numerical.</p>
</td></tr>
<tr><td><code>scaled.by</code></td>
<td>
<p>the data were scaled by dividing each variable through
the values provided in this vector.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>All values provided in the output refer to the scaled data, unless <code>scaled=0</code> or (equivalently) <code>scaled=FALSE</code>. 
</p>
<p>The default option <code>scaled=1</code> or  <code>scaled=TRUE</code>  scales the data by dividing each variable through their range (differing from the scaling through the standard deviation as common e.g. for  PCA).  All other settings  <code>scaled&gt;0</code> will scale the data by their standard deviation.
</p>
<p>If <code>scaled=1</code> or if no scaling is applied, then the default bandwidth setting is 5 percent of the data range in each direction. If the data are scaled through the standard deviation, then the default setting is 20 percent of the standard deviation in each direction. 
</p>
<p>The threshold <code>thr</code> for merging cluster centers works as follows: After identification of a new cluster center, we compute the Euclidean distance of the new center to (each) existing center, relative to the Euclidean distance of the existing center to the overall mean. If this distance falls below <code>thr</code>, then the new center is deemed identical to the old one.
</p>
<p>The goodness-of-fit measure <code>Rc</code> can also be  applied in this context. For
instance, a value of <code class="reqn">R_C=0.8</code> means that,
after the clustering, the mean absolute residual length has been
reduced by <code class="reqn">80\%</code> (compared to the distances to the overall mean).
</p>


<h3>Author(s)</h3>

<p>J. Einbeck. See <code><a href="#topic+LPCM-package">LPCM-package</a></code> for further
acknowledgements. 
</p>


<h3>References</h3>

<p>Almeijeiras-Alonso, J. and Einbeck, J. (2023). A fresh look at mean-shift based modal clustering, Advances in Data Analysis and Classification, doi:10.1007/s11634-023-00575-1.
</p>
<p>Chen, Y. (1995).  Mean Shift, Mode Seeking, and Clustering. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 17, 790-799.
</p>
<p>Comaniciu, D. and Meer,P. (2002). Mean shift: a robust approach toward feature 
space analysis, IEEE Transactions on Pattern Analysis and Machine Intelligence
24, 603-619.
</p>
<p>Li, X,  Hu, Z, and Wu, F. (2007). A note on the convergence of the mean shift, Pattern
Recognition 40, 1756 - 1762.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ms.rep">ms.rep</a></code>, <code><a href="#topic+Rc">Rc</a></code>, <code><a href="#topic+plot.ms">plot.ms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(faithful)
# Mean shift clustering with default bandwidth (5 percent of data range)
ms(faithful)


</code></pre>

<hr>
<h2 id='ms.rep'>
Mean shift procedures.
</h2><span id='topic+ms.rep'></span><span id='topic+meanshift'></span><span id='topic+ms.rep.min'></span>

<h3>Description</h3>

<p>Functions for mean shift, iterative mean shift, and inverse mean shift. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanshift(X, x, h)
ms.rep(X, x, h, thresh= 0.0001, iter=200)
ms.rep.min(X, x, h, thresh=0.000001, iter=200, adjust.convergence=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ms.rep_+3A_x">X</code></td>
<td>
<p>data matrix or vector.</p>
</td></tr>
<tr><td><code id="ms.rep_+3A_x">x</code></td>
<td>
<p>point from which we wish to shift to the local mean.</p>
</td></tr>
<tr><td><code id="ms.rep_+3A_h">h</code></td>
<td>
<p>scalar or vector-valued bandwidth; see also description in <code><a href="#topic+ms">ms</a></code>.</p>
</td></tr>
<tr><td><code id="ms.rep_+3A_thresh">thresh</code>, <code id="ms.rep_+3A_iter">iter</code></td>
<td>
<p>mean shift iterations are stopped when the
mean shift length (relative to the distance of of <code>x</code> to the overall mean; see Note section) falls below <code>thresh</code>, or  after <code>iter</code> iterations (whatever event happens first).</p>
</td></tr> 
<tr><td><code id="ms.rep_+3A_adjust.convergence">adjust.convergence</code></td>
<td>
<p>Unimplemented. See also Notes section below.</p>
</td></tr>  
<tr><td><code id="ms.rep_+3A_verbose">verbose</code></td>
<td>
<p>Allows or suppresses text output messages.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function <code>meanshift</code> computes a single mean shift iteration, and <code>ms.rep</code> computes an iterative series of mean shift iterations. Both of these functions are rarely used on their own, but are typically called by the overarching function <code><a href="#topic+ms">ms</a></code>.
</p>
<p>The function <code>ms.rep.min</code> is an experimental function for the computation of antimodes based on an inverse version of the mean shift procedure. This function has only be tested for one-dimensional data (Ameijeiras-Alonso and Einbeck, 202x). It may or may not produce a result for higher data dimensions, but the methodology has not been properly investigated for this case, i.e. any result obtained could be something different to an antimode.
</p>


<h3>Value</h3>

<p>The function <code>meanshift</code> delivers a single (vector-valued) value.
</p>
<p>The functions <code>ms.rep</code> and <code>ms.rep.min</code> produce a list with the following items:
</p>
<table>
<tr><td><code>Meanshift.points</code></td>
<td>
<p>(called <code>M</code> for <code>ms.rep.min</code>); the trajectory of points found while proceeding from the starting value <code>x</code> to the mode (or antimode, respectively)</p>
</td></tr>
<tr><td><code>Threshold.values</code></td>
<td>
<p>These give the iteration-wise values of the relative length of the mean shift step (explained in the Note section) which are then compared to <code>thresh</code>.</p>
</td></tr>
<tr><td><code>start</code></td>
<td>
<p>The starting value.</p>
</td></tr>
<tr><td><code>final</code></td>
<td>
<p>The mode or antimode, respectively.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The threshold <code>thresh</code> for stopping mean shift iterations works as follows. At each iteration, we compare
the length of the mean shift, that is the Euclidean distance between the point <code>x</code> and its local mean <code>m</code>, to the Euclidean distance between the point <code>x</code> and the overall data mean <code>M</code>. If this distance falls below <code>thresh</code>, the mean shift procedure is stopped.
</p>
<p>When <code>ms.rep</code> is called by function <code>ms</code>,  the relation of the thresholds <code>thr</code> and <code>thresh</code> is <code>thresh = thr^2</code>.
</p>
<p>Convergence of inverse mean shift algorithm is not mathematically guaranteed. Of course, no antimode will be found if there is none (i.e., if the value <code>x</code> is not situated between two modes), in which case the method will return a NA.
But the algorithm may also fail to converge if the antimode is associated with a very small density value, which however rarely happens in practice unless the two distributions are fully separated. In this case the inverse mean shift algorithm will oscillate around the antimode, and the mean of these oscillating values (available from the function output) could give a suitable estimate of the antimode. Such adjustments are not yet implemented in an automated form in the present version of <span class="pkg">LPCM</span>; so any estimate given in the output is the &lsquo;plain&rsquo; estimate (whether it exists or not). 
</p>


<h3>Author(s)</h3>

<p>J. Einbeck. See <code><a href="#topic+LPCM-package">LPCM-package</a></code> for further
acknowledgements. 
</p>


<h3>References</h3>

<p>Ameijeiras-Alonso, J. and Einbeck, J. (202x). A fresh look at mean-shift based modal
clustering. Under submission.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ms">ms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stamps, package="multimode")
h0 &lt;- 0.005
hist(stamps, breaks=20)
# Take arbitrary starting value x=0.08, sitting between a mode and antimode
mode &lt;- ms.rep(stamps, 0.08,h0)$final
antimode &lt;- ms.rep.min(stamps, 0.08,h0, verbose=FALSE)$final
segments(mode, 0, mode, 100, col=2, lwd=3)
segments(antimode, 0, antimode,100, col=3, lwd=3)
</code></pre>

<hr>
<h2 id='plot.lpc'>Plotting local principal curves and mean shift trajectories</h2><span id='topic+plot.lpc'></span><span id='topic+plot.lpc.spline'></span><span id='topic+plot.ms'></span>

<h3>Description</h3>

<p>Takes an object of class <code>lpc</code>, <code>lpc.spline</code> or <code>ms</code>. In the case of principal curves, it plots any subset of the following components of the local principal curve:  Centers of mass; the curve connecting the local centers of mass; the cubic spline representation of the curve; the projections onto the curve; the starting points. For the mean shift procedure, it produces a plot of mean shift trajectories and cluster centers. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lpc'
plot(x, type, unscale = TRUE, lwd = 1, datcol = "grey60", 
    datpch = 21, masscol = NULL, masspch = 15, curvecol = 1, splinecol = 3, 
    projectcol = 4, startcol = NULL,  startpch=NULL,...)  
## S3 method for class 'lpc.spline'
plot(x, type, unscale = TRUE, lwd = 1, datcol = "grey60", 
    datpch = 21, masscol = NULL, masspch = 15, curvecol = 1, splinecol = 3, 
    projectcol = 4, startcol = NULL,  startpch=NULL,...)
## S3 method for class 'ms'
plot(x, unscale=FALSE, lwd=1, datcol="grey70",   datpch=21, masscol=NULL, 
    masspch=15, curvecol=NULL, ...)    
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lpc_+3A_x">x</code></td>
<td>
<p>an object of class <code>lpc</code>, <code>lpc.spline</code>, or <code>ms</code>.   </p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_type">type</code></td>
<td>
<p>a vector of type <code>c("mass", "spline",...)</code> with possible entries <code>mass, curve</code>, <code>spline, project, start.</code></p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_unscale">unscale</code></td>
<td>
<p>if TRUE, then data (and all fitted components) are scaled back to their original scale; otherwise the scaled data are plotted (only relevant if <code>scaled=TRUE</code>  in the fitted object). For <code>ms</code>, this is currently unimplemented.</p>
</td></tr>  
<tr><td><code id="plot.lpc_+3A_lwd">lwd</code></td>
<td>
<p>width of principal curves or trajectories.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_datcol">datcol</code></td>
<td>
<p>color of data points.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_datpch">datpch</code></td>
<td>
<p>plotting symbol for data points.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_masscol">masscol</code></td>
<td>
<p>color of centers of mass (see below) or cluster centers.  </p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_masspch">masspch</code></td>
<td>
<p>plotting symbol for centers of mass or cluster centers.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_curvecol">curvecol</code></td>
<td>
<p>color of the curve interpolating the local centers of mass (this is the &quot;local principal curve&quot;!).</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_splinecol">splinecol</code></td>
<td>
<p>color of the spline representation of the local principal curve.</p>
</td></tr> 
<tr><td><code id="plot.lpc_+3A_projectcol">projectcol</code></td>
<td>
<p>color of projections onto the spline representation of the local principal curve.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_startcol">startcol</code></td>
<td>
<p>color of the plotted starting points.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_startpch">startpch</code></td>
<td>
<p>plotting symbol for starting points; needs to be either a
single symbol, or a vector of symbols of the same length as the number
of starting points.</p>
</td></tr>
<tr><td><code id="plot.lpc_+3A_...">...</code></td>
<td>
<p> further arguments passed to <code>plot</code> or <code>scatterplot3d</code>.  </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of adequate dimensionality (depending on the type of object). 
</p>
<p>For local principal curves, the minimum supported dimension is <code class="reqn">d=2</code>, and for the mean shift it is <code class="reqn">d=1</code>. In either case, the maximum supported dimension is <code class="reqn">d=16</code>. With increasing dimension <code class="reqn">d</code>, less plotting options tend to be supported. The nicest plots are obtained  for <code class="reqn">d=2</code> and <code class="reqn">d=3</code>.
</p>
<p>The most flexible plotting option is <code>masscol</code>. Depending on the
length of the specified vector, this will be interpreted differently. If
a scalar is provided, the corresponding color will be given to all centers of
mass (or cluster centers). For LPCs, if the length of the vector is larger than 1, then this option
will assign different colours to  different depths, or different branch
numbers, or to individual data points, depending on the length. The
default setting is assigning colours according to depth, in the order
red, blue, black. 
</p>


<h3>Warning</h3>

<p>This function computes all missing information (if possible), so computation will take the longer the less informative the given object is, and the more advanced aspects are asked to plot!
</p>


<h3>Author(s)</h3>

<p> JE </p>


<h3>References</h3>

<p>Almeijeiras-Alonso, J. and Einbeck, J. (2023). A fresh look at mean-shift based modal clustering, Advances in Data Analysis and Classification, doi:10.1007/s11634-023-00575-1.
</p>
<p>Einbeck, J., Tutz, G.,  and Evers, L. (2005). Local principal curves. Statistics and Computing 15, 301-313.
</p>
<p>Einbeck, J., Evers, L. &amp; Hinchliff, K. (2010):  Data compression and regression based on local principal curves. In A. Fink, B. Lausen, W. Seidel, and A. Ultsch (Eds),  Advances in Data Analysis, Data Handling, and Business Intelligence, Heidelberg, pp. 701&ndash;712, Springer. 
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+lpc">lpc</a></code>, <code><a href="#topic+lpc.spline">lpc.spline</a></code>  , <code><a href="#topic+ms">ms</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calspeedflow)
lpc1 &lt;- lpc(calspeedflow[,3:4])
plot(lpc1, type=c("spline","project"), lwd=2)
ms1&lt;- ms(calspeedflow[,3:4], subset=sample.int(444,100), plot=FALSE) 
    # starts trajectories from 100 random obs'n
plot(ms1, masscol=1)
plot(ms1, curvecol="grey30")

data(mussels, package="dr")
ms2 &lt;- ms(mussels[,-3], scaled=1, h=0.1, plot=FALSE)
plot(ms2, datpch=20, masspch=24)
</code></pre>

<hr>
<h2 id='print.lpc'>Printing output for lpc, lpc.spline, and ms objects</h2><span id='topic+print.lpc'></span><span id='topic+print.lpc.spline'></span><span id='topic+print.ms'></span>

<h3>Description</h3>

<p>Takes an object of class <code>lpc</code>, <code>lpc.spline</code>, <code>ms</code> and displays some standard output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lpc'
print( x, digits = max(3, getOption("digits") - 3), ...) 
## S3 method for class 'lpc.spline'
print( x, digits = max(3, getOption("digits") - 3), ...) 
## S3 method for class 'ms'
print( x, digits = max(3, getOption("digits") - 3), ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lpc_+3A_x">x</code></td>
<td>
<p>an object of class <code>lpc</code>, <code>lpc.spline</code>, or <code>ms</code>.</p>
</td></tr>
<tr><td><code id="print.lpc_+3A_digits">digits</code></td>
<td>
<p>not yet in use.</p>
</td></tr>
<tr><td><code id="print.lpc_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Some short text.
</p>


<h3>Author(s)</h3>

<p> JE </p>


<h3>See Also</h3>

 
<p><code><a href="#topic+lpc">lpc</a></code>, <code><a href="#topic+ms">ms</a></code>   
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calspeedflow)
lpc1 &lt;- lpc(calspeedflow[,3:4])
print(lpc1)
lpc2 &lt;- lpc.spline(lpc1)
print(lpc2)

ms1&lt;- ms(calspeedflow[,3:4], plot=FALSE) 
print(ms1)
</code></pre>

<hr>
<h2 id='Rc'>
Measuring goodness-of-fit for principal objects.
</h2><span id='topic+Rc'></span><span id='topic+Rc.lpc'></span><span id='topic+Rc.lpc.spline'></span><span id='topic+Rc.ms'></span><span id='topic+base.Rc'></span>

<h3>Description</h3>

<p>These functions compute the &lsquo;coverage coefficient&rsquo; <code class="reqn">R_C</code>
for local principal curves, local principal points
(i.e., kernel density estimates obtained through iterated mean shift), and other principal objects.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rc(x,...)

## S3 method for class 'lpc'
Rc(x,...)
## S3 method for class 'lpc.spline'
Rc(x,...)
## S3 method for class 'ms'
Rc(x,...)

base.Rc(data,  closest.coords, type="curve")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rc_+3A_x">x</code></td>
<td>
<p> an object used to select a method.</p>
</td></tr>
<tr><td><code id="Rc_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods (not
needed yet).</p>
</td></tr>
<tr><td><code id="Rc_+3A_data">data</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="Rc_+3A_closest.coords">closest.coords</code></td>
<td>
<p>A matrix of coordinates of the projected data.</p>
</td></tr>
<tr><td><code id="Rc_+3A_type">type</code></td>
<td>
<p>For principal curves, don't modify. For principal points,
set &quot;points&quot;. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Rc</code> computes the coverage coefficient <code class="reqn">R_C</code>, a quantity which
estimates the goodness-of-fit of a fitted principal object.   This
quantity can be interpreted similar to the coefficient of determination in
regression analysis: Values close to 1 indicate a good fit, while values
close to 0 indicate a &lsquo;bad&rsquo; fit (corresponding to linear PCA).
</p>
<p>For objects of type <code>lpc</code>, <code>lpc.spline</code>, and <code>ms</code>,  S3 methods are available which use the generic function
<code>Rc</code>.  This, in turn, calls the base function <code>base.Rc</code>, which
can also be used manually if the fitted object is of another class.
In principle, function <code>base.Rc</code> can be used for assessing
goodness-of-fit of any principal object provided that
the coordinates (<code>closest.coords</code>) of the projected data are
available. For instance, for HS principal curves fitted via
<code>princurve</code>, this information is contained in component <code>$s</code>,
and for a a k-means object, say <code>fitk</code>, this information can be
obtained via <code>fitk$centers[fitk$cluster,]</code>. Set <code>type="points"</code> in
the latter case.
</p>
<p>The function <code>Rc</code> attempts to compute all missing information, so
computation will take the longer the less informative the given
object <code>x</code> is. Note also,  <code>Rc</code> looks up the option <code>scaled</code> in the fitted
object, and accounts for the scaling automatically. Important: If the data
were scaled, then do NOT unscale the results by hand in order to feed
the unscaled version into  <code>base.Rc</code>, this will give a wrong result.
</p>
<p>In terms of methodology, these functions compute  <code class="reqn">R_C</code> directly through the mean
reduction of absolute residual length, rather than through the
area above the coverage curve.
</p>
<p>These functions do currently not account for observation
weights, i.e.  <code class="reqn">R_C</code> is computed through the unweighted mean
reduction in absolute residual length (even if weights have been used for
the curve fitting).  
</p>
<p>In the clustering context, a value of <code class="reqn">R_C=0.8</code> means that,
after the clustering, the mean absolute residual length has been
reduced by <code class="reqn">80\%</code> (compared to the distances to the overall mean).
</p>


<h3>Author(s)</h3>

<p>J. Einbeck.
</p>


<h3>References</h3>

<p>Einbeck, Tutz, and Evers (2005). Local principal curves. Statistics and
Computing 15, 301-313.
</p>
<p>Einbeck (2011).  Bandwidth selection for nonparametric unsupervised
learning techniques &ndash; a unified approach via self-coverage. Journal of
Pattern Recognition Research  6, 175-192. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc.spline">lpc.spline</a></code>, <code><a href="#topic+ms">ms</a></code>, <code><a href="#topic+coverage">coverage</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(calspeedflow)
lpc1 &lt;- lpc.spline(lpc(calspeedflow[,3:4]), project=TRUE)
Rc(lpc1)

# is the same as:
base.Rc(lpc1$lpcobject$data, lpc1$closest.coords)



ms1 &lt;- ms(calspeedflow[,3:4], plot=FALSE)
Rc(ms1)
# is the same as:
base.Rc(ms1$data, ms1$cluster.center[ms1$closest.label,], type="points")

</code></pre>

<hr>
<h2 id='unscale'>
Unscaling local principal objects.
</h2><span id='topic+unscale'></span><span id='topic+unscale.lpc'></span><span id='topic+unscale.lpc.spline'></span><span id='topic+unscale.ms'></span>

<h3>Description</h3>

<p><code>unscale</code> takes an object of type <code>lpc</code>,
<code>lpc.spline</code>, or <code>ms</code>,  which had been fitted using option
<code>scaled=TRUE</code>, and transforms the scaled components back to the
original data scale.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unscale(x, ...)

## S3 method for class 'lpc'
unscale(x,...)
## S3 method for class 'lpc.spline'
unscale(x,...)
## S3 method for class 'ms'
unscale(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unscale_+3A_x">x</code></td>
<td>
<p> an object used to select a method.</p>
</td></tr>
<tr><td><code id="unscale_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods (not
needed yet). </p>
</td></tr>
</table>


<h3>Value</h3>

  
<p>A list of relevant items, such as <code>LPC</code>, <code>start</code>, <code>cluster.centers</code>,
etc., which gives the unscaled versions of these
quantities (some of them may carry the value <code>NULL</code>, if the
corresponding information was not available from <code>x</code>). 
</p>


<h3>Author(s)</h3>

<p>JE
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lpc">lpc</a></code>, <code><a href="#topic+lpc.spline">lpc.spline</a></code>, <code><a href="#topic+ms">ms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gvessel)
unscale(lpc(gvessel[,c(2,4,5)],  h=0.11,  x0=c(35, 1870, 6.3)) )

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
