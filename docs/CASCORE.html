<!DOCTYPE html><html><head><title>Help for package CASCORE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CASCORE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ADMM'><p>Penalized Optimization Framework for Community Detection in Networks with Covariates.</p></a></li>
<li><a href='#CASC'><p>Covariate Assisted Spectral Clustering.</p></a></li>
<li><a href='#CASCORE'><p>Covariate Assisted Spectral Clustering on Ratios of Eigenvectors.</p></a></li>
<li><a href='#Cov_based'><p>Covariates-based Clustering.</p></a></li>
<li><a href='#Net_based'><p>Network-based Clustering.</p></a></li>
<li><a href='#nPCA'><p>Normalized Principle Component Analysis.</p></a></li>
<li><a href='#oPCA'><p>Ordinary Principle Component Analysis.</p></a></li>
<li><a href='#SCORE'><p>Spectral Clustering On Ratios-of-Eigenvectors.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Covariate Assisted Spectral Clustering on Ratios of Eigenvectors</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Yaofang Hu [aut, cre],
  Wanjie Wang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yaofang Hu &lt;yaofangh@smu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for implementing the novel algorithm CASCORE, which is designed to detect latent community structure in graphs with node covariates. This algorithm can handle models such as the covariate-assisted degree corrected stochastic block model (CADCSBM). CASCORE specifically addresses the disagreement between the community structure inferred from the adjacency information and the community structure inferred from the covariate information. For more detailed information, please refer to the reference paper: Yaofang Hu and Wanjie Wang (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2306.15616">doi:10.48550/arXiv.2306.15616</a>&gt;. 
    In addition to CASCORE, this package includes several classical community detection algorithms that are compared to CASCORE in our paper. These algorithms are: Spectral Clustering On Ratios-of Eigenvectors (SCORE), normalized PCA, ordinary PCA, network-based clustering, covariates-based clustering and covariate-assisted spectral clustering (CASC). By providing these additional algorithms, the package enables users to compare their performance with CASCORE in community detection tasks.</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, pracma</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://arxiv.org/abs/2306.15616">https://arxiv.org/abs/2306.15616</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, igraph</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-02 04:38:14 UTC; yaofang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-02 05:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ADMM'>Penalized Optimization Framework for Community Detection in Networks with Covariates.</h2><span id='topic+ADMM'></span>

<h3>Description</h3>

<p>Semidefinite programming for optimizing the inner product between combined network and the
solution matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ADMM(
  Adj,
  Covariate,
  lambda,
  K,
  alpha,
  rho,
  TT,
  tol,
  quiet = NULL,
  report_interval = NULL,
  r = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ADMM_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_covariate">Covariate</code></td>
<td>
<p>A covariate matrix. The rows correspond to nodes and the columns correspond to covariates.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_lambda">lambda</code></td>
<td>
<p>A tuning parameter to weigh the covariate matrix.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_alpha">alpha</code></td>
<td>
<p>A number. The elementwise upper bound in the SDP.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_rho">rho</code></td>
<td>
<p>The learning rate of ADMM.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_tt">TT</code></td>
<td>
<p>The maximum of iteration.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_tol">tol</code></td>
<td>
<p>The tolerance for stopping criterion.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_quiet">quiet</code></td>
<td>
<p>An optional inoput. Whether to print result at each step.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_report_interval">report_interval</code></td>
<td>
<p>An optional inoput. The frequency to print intermediate result.</p>
</td></tr>
<tr><td><code id="ADMM_+3A_r">r</code></td>
<td>
<p>An optional inoput. The expected rank of the solution, leave NULL if no constraint is required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>ADMM</em> is proposed in <em>Covariate Regularized Community Detection in Sparse Graphs</em>
of Yan &amp; Sarkar (2021). <em>ADMM</em> relies on semidefinite programming (SDP) relaxations for detecting
the community structure in sparse networks with covariates.
</p>


<h3>Value</h3>

<table>
<tr><td><code>estall</code></td>
<td>
<p>A lavel vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yan, B., &amp; Sarkar, P. (2021). <em>Covariate Regularized Community Detection in Sparse Graphs</em>.
<em>Journal of the American Statistical Association, 116(534), 734-745</em>.
<br /><a href="https://doi.org/10.1080/01621459.2019.1706541">doi:10.1080/01621459.2019.1706541</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
caseno = 4; Nrange = 10; Nmin = 10; prob1 = 0.9; p = n*4;
Q = matrix(runif(p*K, 0, 1), nrow = p, ncol = K)
Q = sweep(Q,2,colSums(Q),`/`)
W = matrix(0, nrow = n, ncol = K);
for(jj in 1:n) {
  if(runif(1) &lt;= prob1) {W[jj, 1:K] = Pi[jj, ];}
  else W[jj, sample(K, 1)] = 1;
}
W = t(W)
D0 = Q %*% W
X = matrix(0, n, p)
N = switch(caseno, rep(100, n), rep(100, n), round(runif(n)*Nrange+ Nmin),
  round(runif(n)* Nrange+Nmin))
for (i in 1: ncol(D0)){
  X[i, ] = rmultinom(1, N[i], D0[, i])
}
ADMM(Adj, X, lambda = 0.2, K = K, alpha = 0.5, rho = 2, TT = 100, tol = 5)
</code></pre>

<hr>
<h2 id='CASC'>Covariate Assisted Spectral Clustering.</h2><span id='topic+CASC'></span>

<h3>Description</h3>

<p><em>CASC</em> clusters graph nodes by applying spectral clustering with the assistance from
node covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CASC(Adj, Covariate, K, alphan = 5, itermax = 100, startn = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CASC_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="CASC_+3A_covariate">Covariate</code></td>
<td>
<p>A covariate matrix. The rows correspond to nodes and the columns correspond to covariates.</p>
</td></tr>
<tr><td><code id="CASC_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="CASC_+3A_alphan">alphan</code></td>
<td>
<p>A tuning parameter to balance between the contributions of the graph and the covariates.</p>
</td></tr>
<tr><td><code id="CASC_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of iterations allowed.
The default value is 100.</p>
</td></tr>
<tr><td><code id="CASC_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many random sets should
be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>CASC</em> is a community detection algorithm for networks with node covariates, proposed
in <em>Covariate-assisted spectral clustering</em> of Binkiewicz, et al. (2017). <em>CASC</em> applies
<code>k-means</code> on the first <code>K</code> leading eigenvectors of the balanced matrix between the Laplacian
matrix and the covariate matrix.
</p>


<h3>Value</h3>

<table>
<tr><td><code>estall</code></td>
<td>
<p>A lavel vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Binkiewicz, N., Vogelstein, J. T., &amp; Rohe, K. (2017). <em>Covariate-assisted spectral clustering</em>.
<em>Biometrika, 104(2), 361-377.</em><br /><a href="https://doi.org/10.1093/biomet/asx008">doi:10.1093/biomet/asx008</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
caseno = 4; Nrange = 10; Nmin = 10; prob1 = 0.9; p = n*4;
Q = matrix(runif(p*K, 0, 1), nrow = p, ncol = K)
Q = sweep(Q,2,colSums(Q),`/`)
W = matrix(0, nrow = n, ncol = K);
for(jj in 1:n) {
  if(runif(1) &lt;= prob1) {W[jj, 1:K] = Pi[jj, ];}
  else W[jj, sample(K, 1)] = 1;
}
W = t(W)
D0 = Q %*% W
X = matrix(0, n, p)
N = switch(caseno, rep(100, n), rep(100, n), round(runif(n)*Nrange+ Nmin),
  round(runif(n)* Nrange+Nmin))
for (i in 1: ncol(D0)){
  X[i, ] = rmultinom(1, N[i], D0[, i])
}
CASC(Adj, X, 2)
</code></pre>

<hr>
<h2 id='CASCORE'>Covariate Assisted Spectral Clustering on Ratios of Eigenvectors.</h2><span id='topic+CASCORE'></span>

<h3>Description</h3>

<p>Using ratios-of-eigenvectors to detect underlying communities in networks with node covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CASCORE(
  Adj,
  Covariate,
  K,
  alpha = NULL,
  alphan = 5,
  itermax = 100,
  startn = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CASCORE_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="CASCORE_+3A_covariate">Covariate</code></td>
<td>
<p>A covariate matrix. The rows correspond to nodes and the columns correspond to covariates.</p>
</td></tr>
<tr><td><code id="CASCORE_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="CASCORE_+3A_alpha">alpha</code></td>
<td>
<p>A numeric vector, each element of which is a tuning parameter to weigh the covariate matrix.</p>
</td></tr>
<tr><td><code id="CASCORE_+3A_alphan">alphan</code></td>
<td>
<p>The number of candidates <code class="reqn">\alpha</code>. The default number is 5.</p>
</td></tr>
<tr><td><code id="CASCORE_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of
iterations allowed. The default value is 100.</p>
</td></tr>
<tr><td><code id="CASCORE_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many
random sets should be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>CASCORE</em> is fully established in <em>Network-Adjusted Covariates for Community Detection</em>
of Hu &amp; Wang (2023). <em>CASCORE</em> detects the latent community structure under the covariate
assisted degree corrected stochastic block model (CADCSBM), and it allows the disagreement
between the community structures indicated in the graph and the covariates, respectively.
<code>K-means</code> is applied on the entry-wise ratios between first leading eigenvector and
each of the other <code class="reqn">K</code> leading eigenvectors of the combined matrix of the adjacency matrix
and the covariate matrix, to reveal the underlying memberships.
</p>


<h3>Value</h3>

<table>
<tr><td><code>estall</code></td>
<td>
<p>A lavel vector</p>
</td></tr></table>
<p>.
</p>


<h3>References</h3>

<p>Hu, Y., &amp; Wang, W. (2023) <em>Network-AdjustedCovariatesforCommunity Detection</em>,
<br /><a href="https://arxiv.org/abs/2306.15616">https://arxiv.org/abs/2306.15616</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
caseno = 4; Nrange = 10; Nmin = 10; prob1 = 0.9; p = n*4;
Q = matrix(runif(p*K, 0, 1), nrow = p, ncol = K)
Q = sweep(Q,2,colSums(Q),`/`)
W = matrix(0, nrow = n, ncol = K);
for(jj in 1:n) {
  if(runif(1) &lt;= prob1) {W[jj, 1:K] = Pi[jj, ];}
  else W[jj, sample(K, 1)] = 1;
}
W = t(W)
D0 = Q %*% W
X = matrix(0, n, p)
N = switch(caseno, rep(100, n), rep(100, n), round(runif(n)*Nrange+ Nmin),
  round(runif(n)* Nrange+Nmin))
for (i in 1: ncol(D0)){
  X[i, ] = rmultinom(1, N[i], D0[, i])
}
CASCORE(Adj, X, 2)
</code></pre>

<hr>
<h2 id='Cov_based'>Covariates-based Clustering.</h2><span id='topic+Cov_based'></span>

<h3>Description</h3>

<p><em>Covariates-based Clustering</em> is a spectral clustering method that focuses
solely on the covariates structure of a network. It employs <code>k-means</code> on the first
<code class="reqn">K</code> leading eigenvectors of the weighted cogariates matrix of a graph, with each
eigenvector normalized to have unit magnitude.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cov_based(Adj, K, tau = NULL, itermax = NULL, startn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cov_based_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="Cov_based_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in
graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="Cov_based_+3A_tau">tau</code></td>
<td>
<p>An optional tuning parameter, the default value is the mean of adajacency matrix.</p>
</td></tr>
<tr><td><code id="Cov_based_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of
iterations allowed. The default value is 100.</p>
</td></tr>
<tr><td><code id="Cov_based_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many
random sets should be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A label vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
Cov_based(Adj, 2)
</code></pre>

<hr>
<h2 id='Net_based'>Network-based Clustering.</h2><span id='topic+Net_based'></span>

<h3>Description</h3>

<p><em>Network-based Clustering</em> is a spectral clustering method that focuses
solely on the topological structure of a network. It employs <code>k-means</code> on the first
<code class="reqn">K</code> leading eigenvectors of the weighted adjacency matrix of a graph, with each
eigenvector normalized to have unit magnitude.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Net_based(Adj, K, tau = NULL, itermax = NULL, startn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Net_based_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="Net_based_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in
graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="Net_based_+3A_tau">tau</code></td>
<td>
<p>An optional tuning parameter, the default value is the mean of adajacency matrix.</p>
</td></tr>
<tr><td><code id="Net_based_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of
iterations allowed. The default value is 100.</p>
</td></tr>
<tr><td><code id="Net_based_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many
random sets should be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A label vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
Net_based(Adj, 2)
</code></pre>

<hr>
<h2 id='nPCA'>Normalized Principle Component Analysis.</h2><span id='topic+nPCA'></span>

<h3>Description</h3>

<p><em>Normalized Principle Component Analysis (nPCA)</em>, also known as spectral clustering on the
graph Laplacian, is a classical spectral clustering method that applies <code>k-means</code> on the first <code class="reqn">K</code>
leading (unit-norm) eigenvectors of the degree-corrected normalized graph laplacian.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nPCA(Adj, K, tau = NULL, itermax = 100, startn = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nPCA_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="nPCA_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in
graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="nPCA_+3A_tau">tau</code></td>
<td>
<p>An optional regularization parameter for suitable degree normalization. The default value is the
average degree of graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="nPCA_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of
iterations allowed. The default value is 100.</p>
</td></tr>
<tr><td><code id="nPCA_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many
random sets should be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>estall</code></td>
<td>
<p>A lavel vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chung, F. R., &amp; Graham, F. C. (1997). <em>Spectral graph theory (Vol. 92)</em>.
<em>American Mathematical Soc..</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
nPCA(Adj, 2)

</code></pre>

<hr>
<h2 id='oPCA'>Ordinary Principle Component Analysis.</h2><span id='topic+oPCA'></span>

<h3>Description</h3>

<p><em>Ordinary Principle Component Analysis (oPCA)</em>, also known as spectral clustering
on the adjacency matrix is a classical spectral clustering method that applies <code>k-means</code> on
the first <code class="reqn">K</code> leading (unit-norm) eigenvectors of the adjacency matrix of a graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oPCA(Adj, K, itermax = 100, startn = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oPCA_+3A_adj">Adj</code></td>
<td>
<p>A 0/1 adjacency matrix.</p>
</td></tr>
<tr><td><code id="oPCA_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in
graph <code>Adj</code>.</p>
</td></tr>
<tr><td><code id="oPCA_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of
iterations allowed. The default value is 100.</p>
</td></tr>
<tr><td><code id="oPCA_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many
random sets should be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>estall</code></td>
<td>
<p>A lavel vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chung, F. R., &amp; Graham, F. C. (1997). <em>Spectral graph theory (Vol. 92)</em>.
<em>American Mathematical Soc..</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
oPCA(Adj, 2)
</code></pre>

<hr>
<h2 id='SCORE'>Spectral Clustering On Ratios-of-Eigenvectors.</h2><span id='topic+SCORE'></span>

<h3>Description</h3>

<p>Using ratios-of-eigenvectors to detect underlying communities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SCORE(G, K, itermax = NULL, startn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SCORE_+3A_g">G</code></td>
<td>
<p>A 0/1 adjacency matrix of a connected graph.</p>
</td></tr>
<tr><td><code id="SCORE_+3A_k">K</code></td>
<td>
<p>A positive integer, indicating the number of underlying communities in graph <code>G</code>.</p>
</td></tr>
<tr><td><code id="SCORE_+3A_itermax">itermax</code></td>
<td>
<p><code>k-means</code> parameter, indicating the maximum number of
iterations allowed. The default value is 100.</p>
</td></tr>
<tr><td><code id="SCORE_+3A_startn">startn</code></td>
<td>
<p><code>k-means</code> parameter. If centers is a number, how many
random sets should be chosen? The default value is 10.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>SCORE</em> is fully established in <em>Fast community detection by
SCORE</em> of Jin (2015). <em>SCORE</em> uses the entry-wise ratios between the
first leading eigenvector and each of the other <code class="reqn">K-1</code> leading eigenvectors for
clustering. It is noteworthy that SCORE only works on connected graphs,
in other words, it does not allow for isolated vertices.
</p>


<h3>Value</h3>

<table>
<tr><td><code>estall</code></td>
<td>
<p>A lavel vector.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jin, J. (2015). <em>Fast community detection by score</em>.
<em>The Annals of Statistics 43 (1), 57–89.</em><br /><a href="https://doi.org/10.1214/14-AOS1265">doi:10.1214/14-AOS1265</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the Network
n = 10; K = 2;
theta = 0.4 + (0.45-0.05)*(seq(1:n)/n)^2; Theta = diag(theta);
P  = matrix(c(0.8, 0.2, 0.2, 0.8), byrow = TRUE, nrow = K)
set.seed(2022)
l = sample(1:K, n, replace=TRUE); # node labels
Pi = matrix(0, n, K) # label matrix
for (k in 1:K){
  Pi[l == k, k] = 1
}
Omega = Theta %*% Pi %*% P %*% t(Pi) %*% Theta;
Adj = matrix(runif(n*n, 0, 1), nrow = n);
Adj = Omega - Adj;
Adj = 1*(Adj &gt;= 0)
diag(Adj) = 0
Adj[lower.tri(Adj)] = t(Adj)[lower.tri(Adj)]
library(igraph)
is.igraph(Adj) # [1] FALSE
ix = components(graph.adjacency(Adj))
componentLabel = ix$membership
giantLabel = which(componentLabel == which.max(ix$csize))
Giant = Adj[giantLabel, giantLabel]
SCORE(Giant, 2)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
