<!DOCTYPE html><html><head><title>Help for package luz</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {luz}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#accelerator'><p>Create an accelerator</p></a></li>
<li><a href='#as_dataloader'><p>Creates a dataloader from its input</p></a></li>
<li><a href='#context'><p>Context object</p></a></li>
<li><a href='#ctx'><p>Context object</p></a></li>
<li><a href='#evaluate'><p>Evaluates a fitted model on a dataset</p></a></li>
<li><a href='#fit.luz_module_generator'><p>Fit a <code>nn_module</code></p></a></li>
<li><a href='#get_metrics'><p>Get metrics from the object</p></a></li>
<li><a href='#lr_finder'><p>Learning Rate Finder</p></a></li>
<li><a href='#luz_callback'><p>Create a new callback</p></a></li>
<li><a href='#luz_callback_auto_resume'><p>Resume training callback</p></a></li>
<li><a href='#luz_callback_csv_logger'><p>CSV logger callback</p></a></li>
<li><a href='#luz_callback_early_stopping'><p>Early stopping callback</p></a></li>
<li><a href='#luz_callback_gradient_clip'><p>Gradient clipping callback</p></a></li>
<li><a href='#luz_callback_interrupt'><p>Interrupt callback</p></a></li>
<li><a href='#luz_callback_keep_best_model'><p>Keep the best model</p></a></li>
<li><a href='#luz_callback_lr_scheduler'><p>Learning rate scheduler callback</p></a></li>
<li><a href='#luz_callback_metrics'><p>Metrics callback</p></a></li>
<li><a href='#luz_callback_mixup'><p>Mixup callback</p></a></li>
<li><a href='#luz_callback_model_checkpoint'><p>Checkpoints model weights</p></a></li>
<li><a href='#luz_callback_profile'><p>Profile callback</p></a></li>
<li><a href='#luz_callback_progress'><p>Progress callback</p></a></li>
<li><a href='#luz_callback_resume_from_checkpoint'><p>Allow resume model training from a specific checkpoint</p></a></li>
<li><a href='#luz_callback_tfevents'><p>tfevents callback</p></a></li>
<li><a href='#luz_callback_train_valid'><p>Train-eval callback</p></a></li>
<li><a href='#luz_load'><p>Load trained model</p></a></li>
<li><a href='#luz_load_checkpoint'><p>Loads a checkpoint</p></a></li>
<li><a href='#luz_load_model_weights'><p>Loads model weights into a fitted object.</p></a></li>
<li><a href='#luz_metric'><p>Creates a new luz metric</p></a></li>
<li><a href='#luz_metric_accuracy'><p>Accuracy</p></a></li>
<li><a href='#luz_metric_binary_accuracy'><p>Binary accuracy</p></a></li>
<li><a href='#luz_metric_binary_accuracy_with_logits'><p>Binary accuracy with logits</p></a></li>
<li><a href='#luz_metric_binary_auroc'><p>Computes the area under the ROC</p></a></li>
<li><a href='#luz_metric_mae'><p>Mean absolute error</p></a></li>
<li><a href='#luz_metric_mse'><p>Mean squared error</p></a></li>
<li><a href='#luz_metric_multiclass_auroc'><p>Computes the multi-class AUROC</p></a></li>
<li><a href='#luz_metric_rmse'><p>Root mean squared error</p></a></li>
<li><a href='#luz_metric_set'><p>Creates a metric set</p></a></li>
<li><a href='#luz_save'><p>Saves luz objects to disk</p></a></li>
<li><a href='#nn_mixup_loss'><p>Loss to be used with <code>callbacks_mixup()</code>.</p></a></li>
<li><a href='#nnf_mixup'><p>Mixup logic</p></a></li>
<li><a href='#predict.luz_module_fitted'><p>Create predictions for a fitted model</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#set_hparams'><p>Set hyper-parameter of a module</p></a></li>
<li><a href='#set_opt_hparams'><p>Set optimizer hyper-parameters</p></a></li>
<li><a href='#setup'><p>Set's up a <code>nn_module</code> to use with luz</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Higher Level 'API' for 'torch'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A high level interface for 'torch' providing utilities to reduce the
    the amount of code needed for common tasks, abstract away torch details and 
    make the same code work on both the 'CPU' and 'GPU'. It's flexible enough to
    support expressing a large range of models. It's heavily inspired by 'fastai' by 
    Howard et al. (2020) &lt;<a href="https://arxiv.org/abs/2002.04688">arXiv:2002.04688</a>&gt;, 'Keras' by Chollet et al. (2015) and 
    'PyTorch Lightning' by Falcon et al. (2019) &lt;<a href="https://doi.org/10.5281%2Fzenodo.3828935">doi:10.5281/zenodo.3828935</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://mlverse.github.io/luz/">https://mlverse.github.io/luz/</a>, <a href="https://github.com/mlverse/luz">https://github.com/mlverse/luz</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>torch (&ge; 0.9.0), magrittr, zeallot, rlang (&ge; 1.0.0), coro,
glue, progress, R6, generics, purrr, ellipsis, fs, prettyunits,
cli</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0), covr, Metrics, withr,
vdiffr, ggplot2 (&ge; 3.0.0), dplyr, torchvision, tfevents (&ge;
0.0.2), tidyr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Collate:</td>
<td>'accelerator.R' 'as_dataloader.R' 'utils.R' 'callbacks.R'
'callbacks-interrupt.R' 'callbacks-mixup.R'
'callbacks-monitor-metrics.R' 'callbacks-profile.R'
'callbacks-resume.R' 'callbacks-tfevents.R' 'context.R'
'losses.R' 'lr-finder.R' 'metrics.R' 'metrics-auc.R'
'module-plot.R' 'module-print.R' 'module.R' 'reexports.R'
'serialization.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-17 09:26:49 UTC; dfalbel</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Falbel [aut, cre, cph],
  RStudio [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Falbel &lt;daniel@rstudio.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-17 10:00:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='accelerator'>Create an accelerator</h2><span id='topic+accelerator'></span>

<h3>Description</h3>

<p>Create an accelerator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accelerator(
  device_placement = TRUE,
  cpu = FALSE,
  cuda_index = torch::cuda_current_device()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accelerator_+3A_device_placement">device_placement</code></td>
<td>
<p>(logical) whether the <code>accelerator</code> object should
handle device placement. Default: <code>TRUE</code></p>
</td></tr>
<tr><td><code id="accelerator_+3A_cpu">cpu</code></td>
<td>
<p>(logical) whether the training procedure should run on the CPU.</p>
</td></tr>
<tr><td><code id="accelerator_+3A_cuda_index">cuda_index</code></td>
<td>
<p>(integer) index of the CUDA device to use if multiple GPUs
are available. Default: the result of torch::cuda_current_device().</p>
</td></tr>
</table>

<hr>
<h2 id='as_dataloader'>Creates a dataloader from its input</h2><span id='topic+as_dataloader'></span><span id='topic+as_dataloader.dataset'></span><span id='topic+as_dataloader.list'></span><span id='topic+as_dataloader.dataloader'></span><span id='topic+as_dataloader.matrix'></span><span id='topic+as_dataloader.numeric'></span><span id='topic+as_dataloader.array'></span><span id='topic+as_dataloader.torch_tensor'></span>

<h3>Description</h3>

<p><code>as_dataloader</code> is used internally by luz to convert input
<code>data</code> and <code>valid_data</code> as passed to <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code> to a
<a href="torch.html#topic+dataloader">torch::dataloader</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_dataloader(x, ...)

## S3 method for class 'dataset'
as_dataloader(x, ..., batch_size = 32)

## S3 method for class 'list'
as_dataloader(x, ...)

## S3 method for class 'dataloader'
as_dataloader(x, ...)

## S3 method for class 'matrix'
as_dataloader(x, ...)

## S3 method for class 'numeric'
as_dataloader(x, ...)

## S3 method for class 'array'
as_dataloader(x, ...)

## S3 method for class 'torch_tensor'
as_dataloader(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_dataloader_+3A_x">x</code></td>
<td>
<p>the input object.</p>
</td></tr>
<tr><td><code id="as_dataloader_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>.</p>
</td></tr>
<tr><td><code id="as_dataloader_+3A_batch_size">batch_size</code></td>
<td>
<p>(int, optional): how many samples per batch to load
(default: <code>1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>as_dataloader</code> methods should have sensible defaults for batch_size,
parallel workers, etc.
</p>
<p>It allows users to quickly experiment with <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code> by not requiring
to create a <a href="torch.html#topic+dataset">torch::dataset</a> and a <a href="torch.html#topic+dataloader">torch::dataloader</a> in simple
experiments.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>as_dataloader(dataset)</code>: Converts a <code><a href="torch.html#topic+dataset">torch::dataset()</a></code> to a <code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>.
</p>
</li>
<li> <p><code>as_dataloader(list)</code>: Converts a list of tensors or arrays with the same
size in the first dimension to a  <code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>
</p>
</li>
<li> <p><code>as_dataloader(dataloader)</code>: Returns the same dataloader
</p>
</li>
<li> <p><code>as_dataloader(matrix)</code>: Converts the matrix to a dataloader
</p>
</li>
<li> <p><code>as_dataloader(numeric)</code>: Converts the numeric vector to a dataloader
</p>
</li>
<li> <p><code>as_dataloader(array)</code>: Converts the array to a dataloader
</p>
</li>
<li> <p><code>as_dataloader(torch_tensor)</code>: Converts the tensor to a dataloader
</p>
</li></ul>


<h3>Overriding</h3>

<p>You can implement your own <code>as_dataloader</code> S3 method if you want your data
structure to be automatically supported by luz's <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
The method must satisfy the following conditions:
</p>

<ul>
<li><p> The method should return a <code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>.
</p>
</li>
<li><p> The only required argument is <code>x</code>. You have good default for all other
arguments.
</p>
</li></ul>

<p>It's better to avoid implementing <code>as_dataloader</code> methods for common S3 classes
like <code>data.frames</code>. In this case, its better to assign a different class to
the inputs and implement <code>as_dataloader</code> for it.
</p>

<hr>
<h2 id='context'>Context object</h2><span id='topic+context'></span>

<h3>Description</h3>

<p>Context object storing information about the model training context.
See also <a href="#topic+ctx">ctx</a>.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>buffers</code></dt><dd><p>This is a list of buffers that callbacks can use to write temporary
information into <code>ctx</code>.</p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>records</code></dt><dd><p>stores information about values logged with <code>self$log</code>.</p>
</dd>
<dt><code>device</code></dt><dd><p>allows querying the current accelerator device</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>list of callbacks that will be called.</p>
</dd>
<dt><code>iter</code></dt><dd><p>current iteration</p>
</dd>
<dt><code>batch</code></dt><dd><p>the current batch data. a list with input data and targets.</p>
</dd>
<dt><code>input</code></dt><dd><p>a shortcut for <code>ctx$batch[[1]]</code></p>
</dd>
<dt><code>target</code></dt><dd><p>a shortcut for <code>ctx$batch[[2]]</code></p>
</dd>
<dt><code>min_epochs</code></dt><dd><p>the minimum number of epochs that the model will run on.</p>
</dd>
<dt><code>max_epochs</code></dt><dd><p>the maximum number of epochs that the model will run.</p>
</dd>
<dt><code>hparams</code></dt><dd><p>a list of hyperparameters that were used to initialize <code>ctx$model</code>.</p>
</dd>
<dt><code>opt_hparams</code></dt><dd><p>a list of hyperparameters used to initialize the <code>ctx$optimizers</code>.</p>
</dd>
<dt><code>train_data</code></dt><dd><p>a dataloader that is used for training the model</p>
</dd>
<dt><code>valid_data</code></dt><dd><p>a dataloader using during model validation</p>
</dd>
<dt><code>accelerator</code></dt><dd><p>an <code><a href="#topic+accelerator">accelerator()</a></code> used to move data, model and etc the the correct
device.</p>
</dd>
<dt><code>optimizers</code></dt><dd><p>a named list of optimizers that will be used during model training.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>bool wether the process is in verbose mode or not.</p>
</dd>
<dt><code>handlers</code></dt><dd><p>List of error handlers that can be used. See <code><a href="rlang.html#topic+try_fetch">rlang::try_fetch()</a></code>
for more info.</p>
</dd>
<dt><code>epoch_handlers</code></dt><dd><p>List of error handlers that can be used. See <code><a href="rlang.html#topic+try_fetch">rlang::try_fetch()</a></code>
for more info.</p>
</dd>
<dt><code>training</code></dt><dd><p>A bool indicating if the model is in training or validation mode.</p>
</dd>
<dt><code>model</code></dt><dd><p>The model being trained.</p>
</dd>
<dt><code>pred</code></dt><dd><p>Last predicted values.</p>
</dd>
<dt><code>opt</code></dt><dd><p>Current optimizer.</p>
</dd>
<dt><code>opt_name</code></dt><dd><p>Current optimizer name.</p>
</dd>
<dt><code>data</code></dt><dd><p>Current dataloader in use.</p>
</dd>
<dt><code>loss_fn</code></dt><dd><p>Loss function used to train the model</p>
</dd>
<dt><code>loss</code></dt><dd><p>Last computed loss values. Detached from the graph.</p>
</dd>
<dt><code>loss_grad</code></dt><dd><p>Last computed loss value, not detached, so you can do additional
tranformation.</p>
</dd>
<dt><code>epoch</code></dt><dd><p>Current epoch.</p>
</dd>
<dt><code>metrics</code></dt><dd><p>List of metrics that are tracked by the process.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-luz_context-new"><code>context$new()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-log"><code>context$log()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-log_metric"><code>context$log_metric()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-get_log"><code>context$get_log()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-get_metrics"><code>context$get_metrics()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-get_metric"><code>context$get_metric()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-get_formatted_metrics"><code>context$get_formatted_metrics()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-get_metrics_df"><code>context$get_metrics_df()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-set_verbose"><code>context$set_verbose()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-clean"><code>context$clean()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-call_callbacks"><code>context$call_callbacks()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-state_dict"><code>context$state_dict()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-unsafe_set_records"><code>context$unsafe_set_records()</code></a>
</p>
</li>
<li> <p><a href="#method-luz_context-clone"><code>context$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-luz_context-new"></a>



<h4>Method <code>new()</code></h4>

<p>Initializes the context object with minimal necessary information.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$new(verbose, accelerator, callbacks, training)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>verbose</code></dt><dd><p>Whether the context should be in verbose mode or not.</p>
</dd>
<dt><code>accelerator</code></dt><dd><p>A luz <code><a href="#topic+accelerator">accelerator()</a></code> that configures device placement and
others.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>A list of callbacks used by the model. See <code><a href="#topic+luz_callback">luz_callback()</a></code>.</p>
</dd>
<dt><code>training</code></dt><dd><p>A boolean that indicates if the context is in training mode or not.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-log"></a>



<h4>Method <code>log()</code></h4>

<p>Allows logging arbitrary information in the <code>ctx</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$log(what, set, value, index = NULL, append = TRUE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>what</code></dt><dd><p>(string) What you are logging.</p>
</dd>
<dt><code>set</code></dt><dd><p>(string) Usually 'train' or 'valid' indicating the set you want
to lot to. But can be arbitrary info.</p>
</dd>
<dt><code>value</code></dt><dd><p>value to log</p>
</dd>
<dt><code>value</code></dt><dd><p>Arbitrary value to log.</p>
</dd>
<dt><code>index</code></dt><dd><p>Index that this value should be logged. If <code>NULL</code> the value
is added to the end of list, otherwise the index is used.</p>
</dd>
<dt><code>append</code></dt><dd><p>If <code>TRUE</code> and a value in the corresponding index already
exists, then value is appended to the current value. If <code>FALSE</code> value
is overwritten in favor of the new value.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-log_metric"></a>



<h4>Method <code>log_metric()</code></h4>

<p>Log a metric gen its name and value.
Metric values are indexed by epoch.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$log_metric(name, value)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>name</code></dt><dd><p>name of the metric</p>
</dd>
<dt><code>value</code></dt><dd><p>value to log</p>
</dd>
<dt><code>value</code></dt><dd><p>Arbitrary value to log.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-get_log"></a>



<h4>Method <code>get_log()</code></h4>

<p>Get a specific value from the log.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$get_log(what, set, index = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>what</code></dt><dd><p>(string) What you are logging.</p>
</dd>
<dt><code>set</code></dt><dd><p>(string) Usually 'train' or 'valid' indicating the set you want
to lot to. But can be arbitrary info.</p>
</dd>
<dt><code>index</code></dt><dd><p>Index that this value should be logged. If <code>NULL</code> the value
is added to the end of list, otherwise the index is used.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-get_metrics"></a>



<h4>Method <code>get_metrics()</code></h4>

<p>Get all metric given an epoch and set.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$get_metrics(set, epoch = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>set</code></dt><dd><p>(string) Usually 'train' or 'valid' indicating the set you want
to lot to. But can be arbitrary info.</p>
</dd>
<dt><code>epoch</code></dt><dd><p>The epoch you want to extract metrics from.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-get_metric"></a>



<h4>Method <code>get_metric()</code></h4>

<p>Get the value of a metric given its name, epoch and set.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$get_metric(name, set, epoch = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>name</code></dt><dd><p>name of the metric</p>
</dd>
<dt><code>set</code></dt><dd><p>(string) Usually 'train' or 'valid' indicating the set you want
to lot to. But can be arbitrary info.</p>
</dd>
<dt><code>epoch</code></dt><dd><p>The epoch you want to extract metrics from.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-get_formatted_metrics"></a>



<h4>Method <code>get_formatted_metrics()</code></h4>

<p>Get formatted metrics values
</p>


<h5>Usage</h5>

<div class="r"><pre>context$get_formatted_metrics(set, epoch = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>set</code></dt><dd><p>(string) Usually 'train' or 'valid' indicating the set you want
to lot to. But can be arbitrary info.</p>
</dd>
<dt><code>epoch</code></dt><dd><p>The epoch you want to extract metrics from.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-get_metrics_df"></a>



<h4>Method <code>get_metrics_df()</code></h4>

<p>Get a data.frame containing all metrics.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$get_metrics_df()</pre></div>


<hr>
<a id="method-luz_context-set_verbose"></a>



<h4>Method <code>set_verbose()</code></h4>

<p>Allows setting the <code>verbose</code> attribute.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$set_verbose(verbose = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>verbose</code></dt><dd><p>boolean. If <code>TRUE</code> verbose mode is used. If <code>FALSE</code> non verbose.
if <code>NULL</code> we use the result of <code><a href="base.html#topic+interactive">interactive()</a></code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-clean"></a>



<h4>Method <code>clean()</code></h4>

<p>Removes unnecessary information from the context object.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$clean()</pre></div>


<hr>
<a id="method-luz_context-call_callbacks"></a>



<h4>Method <code>call_callbacks()</code></h4>

<p>Call the selected callbacks. Where <code>name</code> is the callback types to call, eg
'on_epoch_begin'.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$call_callbacks(name)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>name</code></dt><dd><p>name of the metric</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-state_dict"></a>



<h4>Method <code>state_dict()</code></h4>

<p>Returns a list containing minimal information from the context. Used to
create the returned values.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$state_dict()</pre></div>


<hr>
<a id="method-luz_context-unsafe_set_records"></a>



<h4>Method <code>unsafe_set_records()</code></h4>

<p>Are you sure you know what you are doing?
</p>


<h5>Usage</h5>

<div class="r"><pre>context$unsafe_set_records(records)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>records</code></dt><dd><p>New set of records to be set.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-luz_context-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>context$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='ctx'>Context object</h2><span id='topic+ctx'></span>

<h3>Description</h3>

<p>Context objects used in luz to share information between model methods,
metrics and callbacks.
</p>


<h3>Details</h3>

<p>The <code>ctx</code> object is used in luz to share information between the
training loop and callbacks, model methods, and metrics. The table below
describes information available in the <code>ctx</code> by default. Other callbacks
could potentially modify these attributes or add new ones.
<!-- It's recommended to use the RStudio Visual editor to edit this table. -->

</p>

<table>
<tr>
 <td style="text-align: left;">
   Attribute </td><td style="text-align: left;"> Description </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>verbose</code> </td><td style="text-align: left;"> The value (<code>TRUE</code> or <code>FALSE</code>) attributed to the <code>verbose</code> argument in <code>fit</code> . </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>accelerator</code> </td><td style="text-align: left;"> Accelerator object used to query the correct device to place models, data, etc. It assumes the value passed to the <code>accelerator</code> parameter in <code>fit</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>model</code> </td><td style="text-align: left;"> Initialized <code>nn_module</code> object that will be trained during the <code>fit</code> procedure. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>optimizers</code> </td><td style="text-align: left;"> A named list of optimizers used during training. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>data</code> </td><td style="text-align: left;"> The currently in-use dataloader. When training it’s <code>ctx$train_data</code>, when doing validation its <code>ctx$valid_data</code>. It can also be the prediction dataset when in <code>predict</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>train_data</code> </td><td style="text-align: left;"> Dataloader passed to the <code>data</code> argument in <code>fit</code>. Modified to yield data in the selected device. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>valid_data</code> </td><td style="text-align: left;"> Dataloader passed to the <code>valid_data</code> argument in <code>fit</code>. Modified to yield data in the selected device. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>min_epochs</code> </td><td style="text-align: left;"> Minimum number of epochs the model will be trained for. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>max_epochs</code> </td><td style="text-align: left;"> Maximum number of epochs the model will be trained for. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>epoch</code> </td><td style="text-align: left;"> Current training epoch. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>iter</code> </td><td style="text-align: left;"> Current training iteration. It’s reset every epoch and when going from training to validation. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>training</code> </td><td style="text-align: left;"> Whether the model is in training or validation mode. See also <code>help("luz_callback_train_valid")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>callbacks</code> </td><td style="text-align: left;"> List of callbacks that will be called during the training procedure. It’s the union of the list passed to the <code>callbacks</code> parameter and the default <code>callbacks</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>step</code> </td><td style="text-align: left;"> Closure that will be used to do one <code>step</code> of the model. It’s used for both training and validation. Takes no argument, but can access the <code>ctx</code> object. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>call_callbacks</code> </td><td style="text-align: left;"> Call callbacks by name. For example <code>call_callbacks("on_train_begin")</code> will call all callbacks that provide methods for this point. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>batch</code> </td><td style="text-align: left;"> Last batch obtained by the dataloader. A batch is a <code>list()</code> with 2 elements, one that is used as <code>input</code> and the other as <code>target</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>input</code> </td><td style="text-align: left;"> First element of the last batch obtained by the current dataloader. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>target</code> </td><td style="text-align: left;"> Second element of the last batch obtained by the current dataloader. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>pred</code> </td><td style="text-align: left;"> Last predictions obtained by <code>ctx$model$forward</code> . <strong>Note:</strong> can be potentially modified by previously ran callbacks. Also note that this might not be available if you used a custom training step. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>loss_fn</code> </td><td style="text-align: left;"> The active loss function that will be minimized during training. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>loss</code> </td><td style="text-align: left;"> Last computed loss from the model. <strong>Note:</strong> this might not be available if you modified the training or validation step. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>opt</code> </td><td style="text-align: left;"> Current optimizer, ie. the optimizer that will be used to do the next <code>step</code> to update parameters. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>opt_nm</code> </td><td style="text-align: left;"> Current optimizer name. By default it’s <code>opt</code> , but can change if your model uses more than one optimizer depending on the set of parameters being optimized. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>metrics</code> </td><td style="text-align: left;"> <code>list()</code> with current metric objects that are <code>update</code>d at every <code>on_train_batch_end()</code> or <code>on_valid_batch_end()</code>. See also <code>help("luz_callback_metrics")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>records</code> </td><td style="text-align: left;"> <code>list()</code> recording metric values for training and validation for each epoch. See also <code>help("luz_callback_metrics")</code> . Also records profiling metrics. See <code>help("luz_callback_profile")</code> for more information. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>handlers</code> </td><td style="text-align: left;"> A named <code>list()</code> of handlers that is passed to <code>rlang::with_handlers()</code> during the training loop and can be used to handle errors or conditions that might be raised by other callbacks. </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>epoch_handlers</code> </td><td style="text-align: left;"> A named list of handlers that is used with <code>rlang::with_handlers()</code>. Those handlers are used inside the epochs loop, thus you can handle epoch specific conditions, that won’t necessarily end training. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Context attributes
</p>


<h3>See Also</h3>

<p>Context object: <a href="#topic+context">context</a>
</p>

<hr>
<h2 id='evaluate'>Evaluates a fitted model on a dataset</h2><span id='topic+evaluate'></span>

<h3>Description</h3>

<p>Evaluates a fitted model on a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate(
  object,
  data,
  ...,
  metrics = NULL,
  callbacks = list(),
  accelerator = NULL,
  verbose = NULL,
  dataloader_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate_+3A_object">object</code></td>
<td>
<p>A fitted model to evaluate.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_data">data</code></td>
<td>
<p>(dataloader, dataset or list) A dataloader created with
<code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code> used for training the model, or a dataset created
with <code><a href="torch.html#topic+dataset">torch::dataset()</a></code> or a list. Dataloaders and datasets must return a
list with at most 2 items. The first item will be used as input for the
module and the second will be used as a target for the loss function.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_metrics">metrics</code></td>
<td>
<p>A list of luz metrics to be tracked during evaluation. If <code>NULL</code>
(default) then the same metrics that were used during training are tracked.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_callbacks">callbacks</code></td>
<td>
<p>(list, optional) A list of callbacks defined with
<code><a href="#topic+luz_callback">luz_callback()</a></code> that will be called during the training procedure. The
callbacks <code><a href="#topic+luz_callback_metrics">luz_callback_metrics()</a></code>, <code><a href="#topic+luz_callback_progress">luz_callback_progress()</a></code> and
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid()</a></code> are always added by default.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_accelerator">accelerator</code></td>
<td>
<p>(accelerator, optional) An optional <code><a href="#topic+accelerator">accelerator()</a></code> object
used to configure device placement of the components like <a href="torch.html#topic+nn_module">nn_module</a>s,
optimizers and batches of data.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_verbose">verbose</code></td>
<td>
<p>(logical, optional) An optional boolean value indicating if
the fitting procedure should emit output to the console during training.
By default, it will produce output if <code><a href="base.html#topic+interactive">interactive()</a></code> is <code>TRUE</code>, otherwise
it won't print to the console.</p>
</td></tr>
<tr><td><code id="evaluate_+3A_dataloader_options">dataloader_options</code></td>
<td>
<p>Options used when creating a dataloader. See
<code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>. <code>shuffle=TRUE</code> by default for the training data and
<code>batch_size=32</code> by default. It will error if not <code>NULL</code> and <code>data</code> is
already a dataloader.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Once a model has been trained you might want to evaluate its performance
on a different dataset. For that reason, luz provides the <code>?evaluate</code>
function that takes a fitted model and a dataset and computes the
metrics attached to the model.
</p>
<p>Evaluate returns a <code>luz_module_evaluation</code> object that you can query for
metrics using the <code>get_metrics</code> function or simply <code>print</code> to see the
results.
</p>
<p>For example:
</p>
<div class="sourceCode r"><pre>evaluation &lt;- fitted %&gt;% evaluate(data = valid_dl)
metrics &lt;- get_metrics(evaluation)
print(evaluation)
</pre></div>
<div class="sourceCode"><pre>## A `luz_module_evaluation`
## -- Results ---------------------------------------------------------------------
## loss: 1.5146
## mae: 1.0251
## mse: 1.5159
## rmse: 1.2312
</pre></div>


<h3>See Also</h3>

<p>Other training: 
<code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator</a>()</code>,
<code><a href="#topic+predict.luz_module_fitted">predict.luz_module_fitted</a>()</code>,
<code><a href="#topic+setup">setup</a>()</code>
</p>

<hr>
<h2 id='fit.luz_module_generator'>Fit a <code>nn_module</code></h2><span id='topic+fit.luz_module_generator'></span>

<h3>Description</h3>

<p>Fit a <code>nn_module</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'luz_module_generator'
fit(
  object,
  data,
  epochs = 10,
  callbacks = NULL,
  valid_data = NULL,
  accelerator = NULL,
  verbose = NULL,
  ...,
  dataloader_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.luz_module_generator_+3A_object">object</code></td>
<td>
<p>An <code>nn_module</code> that has been <code><a href="#topic+setup">setup()</a></code>.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_data">data</code></td>
<td>
<p>(dataloader, dataset or list) A dataloader created with
<code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code> used for training the model, or a dataset created
with <code><a href="torch.html#topic+dataset">torch::dataset()</a></code> or a list. Dataloaders and datasets must return a
list with at most 2 items. The first item will be used as input for the
module and the second will be used as a target for the loss function.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_epochs">epochs</code></td>
<td>
<p>(int) The maximum number of epochs for training the model. If a
single value is provided, this is taken to be the <code>max_epochs</code> and
<code>min_epochs</code> is set to 0. If a vector of two numbers is provided, the first
value is <code>min_epochs</code> and the second value is <code>max_epochs</code>. The minimum and
maximum number of epochs are included in the context object as
<code>ctx$min_epochs</code> and <code>ctx$max_epochs</code>, respectively.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_callbacks">callbacks</code></td>
<td>
<p>(list, optional) A list of callbacks defined with
<code><a href="#topic+luz_callback">luz_callback()</a></code> that will be called during the training procedure. The
callbacks <code><a href="#topic+luz_callback_metrics">luz_callback_metrics()</a></code>, <code><a href="#topic+luz_callback_progress">luz_callback_progress()</a></code> and
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid()</a></code> are always added by default.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_valid_data">valid_data</code></td>
<td>
<p>(dataloader, dataset, list or scalar value; optional) A
dataloader created with <code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code> or a dataset created with
<code><a href="torch.html#topic+dataset">torch::dataset()</a></code> that will be used during the validation procedure. They
must return a list with (input, target). If <code>data</code> is a torch dataset or a
list, then you can also supply a numeric value between 0 and 1 - and in
this case a random sample with size corresponding to that proportion from
<code>data</code> will be used for validation.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_accelerator">accelerator</code></td>
<td>
<p>(accelerator, optional) An optional <code><a href="#topic+accelerator">accelerator()</a></code> object
used to configure device placement of the components like <a href="torch.html#topic+nn_module">nn_module</a>s,
optimizers and batches of data.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_verbose">verbose</code></td>
<td>
<p>(logical, optional) An optional boolean value indicating if
the fitting procedure should emit output to the console during training.
By default, it will produce output if <code><a href="base.html#topic+interactive">interactive()</a></code> is <code>TRUE</code>, otherwise
it won't print to the console.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="fit.luz_module_generator_+3A_dataloader_options">dataloader_options</code></td>
<td>
<p>Options used when creating a dataloader. See
<code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>. <code>shuffle=TRUE</code> by default for the training data and
<code>batch_size=32</code> by default. It will error if not <code>NULL</code> and <code>data</code> is
already a dataloader.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted object that can be saved with <code><a href="#topic+luz_save">luz_save()</a></code> and can be
printed with <code><a href="base.html#topic+print">print()</a></code> and plotted with <code><a href="graphics.html#topic+plot">plot()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.luz_module_fitted">predict.luz_module_fitted()</a></code> for how to create predictions.
<code><a href="#topic+setup">setup()</a></code> to find out how to create modules that can be trained with <code>fit</code>.
</p>
<p>Other training: 
<code><a href="#topic+evaluate">evaluate</a>()</code>,
<code><a href="#topic+predict.luz_module_fitted">predict.luz_module_fitted</a>()</code>,
<code><a href="#topic+setup">setup</a>()</code>
</p>

<hr>
<h2 id='get_metrics'>Get metrics from the object</h2><span id='topic+get_metrics'></span><span id='topic+get_metrics.luz_module_fitted'></span>

<h3>Description</h3>

<p>Get metrics from the object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_metrics(object, ...)

## S3 method for class 'luz_module_fitted'
get_metrics(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_metrics_+3A_object">object</code></td>
<td>
<p>The object to query for metrics.</p>
</td></tr>
<tr><td><code id="get_metrics_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing the metric values.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>get_metrics(luz_module_fitted)</code>: Extract metrics from a luz fitted model.
</p>
</li></ul>

<hr>
<h2 id='lr_finder'>Learning Rate Finder</h2><span id='topic+lr_finder'></span>

<h3>Description</h3>

<p>Learning Rate Finder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lr_finder(
  object,
  data,
  steps = 100,
  start_lr = 1e-07,
  end_lr = 0.1,
  log_spaced_intervals = TRUE,
  ...,
  verbose = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lr_finder_+3A_object">object</code></td>
<td>
<p>An nn_module that has been setup().</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_data">data</code></td>
<td>
<p>(dataloader) A dataloader created with torch::dataloader()  used for learning rate finding.</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_steps">steps</code></td>
<td>
<p>(integer) The number of steps to iterate over in the learning rate finder. Default: 100.</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_start_lr">start_lr</code></td>
<td>
<p>(float) The smallest learning rate. Default: 1e-7.</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_end_lr">end_lr</code></td>
<td>
<p>(float) The highest learning rate. Default: 1e-1.</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_log_spaced_intervals">log_spaced_intervals</code></td>
<td>
<p>(logical) Whether to divide the range between start_lr and end_lr into log-spaced intervals (alternative: uniform intervals). Default: TRUE</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>fit</code>.</p>
</td></tr>
<tr><td><code id="lr_finder_+3A_verbose">verbose</code></td>
<td>
<p>Wether to show a progress bar during the process.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with two columns: learning rate and loss
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
ds &lt;- torch::tensor_dataset(x = torch_randn(100, 10), y = torch_randn(100, 1))
dl &lt;- torch::dataloader(ds, batch_size = 32)
model &lt;- torch::nn_linear
model &lt;- model %&gt;% setup(
  loss = torch::nn_mse_loss(),
  optimizer = torch::optim_adam
) %&gt;%
  set_hparams(in_features = 10, out_features = 1)
records &lt;- lr_finder(model, dl, verbose = FALSE)
plot(records)
}
</code></pre>

<hr>
<h2 id='luz_callback'>Create a new callback</h2><span id='topic+luz_callback'></span>

<h3>Description</h3>

<p>Create a new callback
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback(
  name = NULL,
  ...,
  private = NULL,
  active = NULL,
  parent_env = parent.frame(),
  inherit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_+3A_name">name</code></td>
<td>
<p>name of the callback</p>
</td></tr>
<tr><td><code id="luz_callback_+3A_...">...</code></td>
<td>
<p>Public methods of the callback. The name of the methods is used
to know how they should be called. See the details section.</p>
</td></tr>
<tr><td><code id="luz_callback_+3A_private">private</code></td>
<td>
<p>An optional list of private members, which can be functions
and non-functions.</p>
</td></tr>
<tr><td><code id="luz_callback_+3A_active">active</code></td>
<td>
<p>An optional list of active binding functions.</p>
</td></tr>
<tr><td><code id="luz_callback_+3A_parent_env">parent_env</code></td>
<td>
<p>An environment to use as the parent of newly-created
objects.</p>
</td></tr>
<tr><td><code id="luz_callback_+3A_inherit">inherit</code></td>
<td>
<p>A R6ClassGenerator object to inherit from; in other words, a
superclass. This is captured as an unevaluated expression which is
evaluated in <code>parent_env</code> each time an object is instantiated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let’s implement a callback that prints ‘Iteration <code>n</code>’ (where <code>n</code> is the
iteration number) for every batch in the training set and ‘Done’ when an
epoch is finished. For that task we use the <code>luz_callback</code> function:
</p>
<div class="sourceCode r"><pre>print_callback &lt;- luz_callback(
  name = "print_callback",
  initialize = function(message) {
    self$message &lt;- message
  },
  on_train_batch_end = function() {
    cat("Iteration ", ctx$iter, "\n")
  },
  on_epoch_end = function() {
    cat(self$message, "\n")
  }
)
</pre></div>
<p><code>luz_callback()</code> takes named functions as <code>...</code> arguments, where the
name indicates the moment at which the callback should be called. For
instance <code>on_train_batch_end()</code> is called for every batch at the end of
the training procedure, and <code>on_epoch_end()</code> is called at the end of
every epoch.
</p>
<p>The returned value of <code>luz_callback()</code> is a function that initializes an
instance of the callback. Callbacks can have initialization parameters,
like the name of a file where you want to log the results. In that case,
you can pass an <code>initialize</code> method when creating the callback
definition, and save these parameters to the <code>self</code> object. In the above
example, the callback has a <code>message</code> parameter that is printed at the
end of each epoch.
</p>
<p>Once a callback is defined it can be passed to the <code>fit</code> function via
the <code>callbacks</code> parameter:
</p>
<div class="sourceCode r"><pre>fitted &lt;- net %&gt;%
  setup(...) %&gt;%
  fit(..., callbacks = list(
    print_callback(message = "Done!")
  ))
</pre></div>
<p>Callbacks can be called in many different positions of the training
loop, including combinations of them. Here’s an overview of possible
callback <em>breakpoints</em>:
</p>
<div class="sourceCode"><pre>Start Fit
   - on_fit_begin
  Start Epoch Loop
     - on_epoch_begin
    Start Train
       - on_train_begin
      Start Batch Loop
         - on_train_batch_begin
          Start Default Training Step
            - on_train_batch_after_pred
            - on_train_batch_after_loss
            - on_train_batch_before_backward
            - on_train_batch_before_step
            - on_train_batch_after_step
          End Default Training Step:
         - on_train_batch_end
      End Batch Loop
       - on_train_end
    End Train
    Start Valid
       - on_valid_begin
      Start Batch Loop
         - on_valid_batch_begin
          Start Default Validation Step
            - on_valid_batch_after_pred
            - on_valid_batch_after_loss
          End Default Validation Step
         - on_valid_batch_end
      End Batch Loop
       - on_valid_end
    End Valid
      - on_epoch_end
  End Epoch Loop
   - on_fit_end
End Fit
</pre></div>
<p>Every step market with <code style="white-space: pre;">&#8288;on_*&#8288;</code> is a point in the training procedure that
is available for callbacks to be called.
</p>
<p>The other important part of callbacks is the <code>ctx</code> (context) object. See
<code>help("ctx")</code> for details.
</p>
<p>By default, callbacks are called in the same order as they were passed
to <code>fit</code> (or <code>predict</code> or <code>evaluate</code>), but you can provide a <code>weight</code>
attribute that will control the order in which it will be called. For
example, if one callback has <code>weight = 10</code> and another has <code>weight = 1</code>,
then the first one is called after the second one. Callbacks that don’t
specify a <code>weight</code> attribute are considered <code>weight = 0</code>. A few built-in
callbacks in luz already provide a weight value. For example, the
<code>?luz_callback_early_stopping</code> has a weight of <code>Inf</code>, since in general
we want to run it as the last thing in the loop.
</p>


<h3>Value</h3>

<p>A <code>luz_callback</code> that can be passed to <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>


<h3>Prediction callbacks</h3>

<p>You can also use callbacks when using <code><a href="stats.html#topic+predict">predict()</a></code>. In this case the supported
callback methods are detailed above.
</p>
<div class="sourceCode"><pre>Start predict
 - on_predict_begin
 Start prediction loop
  - on_predict_batch_begin
  - on_predict_batch_end
 End prediction loop
 - on_predict_end
End predict
</pre></div>


<h3>Evaluate callbacks</h3>

<p>Callbacks can also be used with <code><a href="#topic+evaluate">evaluate()</a></code>, in this case, the callbacks that
are used are equivalent to those of the validation loop when using <code><a href="#topic+fit">fit()</a></code>:
</p>
<div class="sourceCode"><pre>Start Valid
 - on_valid_begin
 Start Batch Loop
  - on_valid_batch_begin
  Start Default Validation Step
   - on_valid_batch_after_pred
   - on_valid_batch_after_loss
  End Default Validation Step
  - on_valid_batch_end
 End Batch Loop
 - on_valid_end
End Valid
</pre></div>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print_callback &lt;- luz_callback(
 name = "print_callback",
 on_train_batch_end = function() {
   cat("Iteration ", ctx$iter, "\n")
 },
 on_epoch_end = function() {
   cat("Done!\n")
 }
)
</code></pre>

<hr>
<h2 id='luz_callback_auto_resume'>Resume training callback</h2><span id='topic+luz_callback_auto_resume'></span>

<h3>Description</h3>

<p>This callback allows you to resume training a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_auto_resume(path = "./state.pt")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_auto_resume_+3A_path">path</code></td>
<td>
<p>Path to save state files for the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When using it, model weights, optimizer state are serialized at the end of
each epoch. If something fails during training simply re-running the same
script will restart the model training from the epoch right after the last
epoch that was serialized.
</p>


<h3>Customizing serialization</h3>

<p>By default model, optimizer state and records are serialized. Callbacks can
be used to customize serialization by implementing the <code>state_dict()</code> and
<code>load_state_dict()</code> methods.
If those methods are implemented, then <code>state_dict()</code> is called at the end of
each epoch and <code>load_state_dict()</code> is called when the model is resumed.
</p>


<h3>Note</h3>

<p>In general you will want to add this callback as the last in the callbacks
list, this way, the serialized state is likely to contain all possible changes
that other callbacks could have made at <code>'on_epoch_end'</code>. The default <code>weight</code>
attribute of this callback is <code>Inf</code>.
</p>
<p>Read the checkpointing article in the pkgdown website for more
information.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
library(luz)

x &lt;- torch_randn(1000, 10)
y &lt;- torch_randn(1000, 1)

model &lt;- nn_linear %&gt;%
  setup(optimizer = optim_sgd, loss = nnf_mse_loss) %&gt;%
  set_hparams(in_features = 10, out_features = 1) %&gt;%
  set_opt_hparams(lr = 0.01)


# simulate a failure in the middle of epoch 5 happening only once.
callback_stop &lt;- luz_callback(
  "interrupt",
  failed = FALSE,
  on_epoch_end = function() {
    if (ctx$epoch == 5 &amp;&amp; !self$failed) {
      self$failed &lt;- TRUE
      stop("Error on epoch 5")
    }
  }
)

path &lt;- tempfile()
autoresume &lt;- luz_callback_auto_resume(path = path)
interrupt &lt;- callback_stop()

# try once and the model fails
try({
  results &lt;- model %&gt;% fit(
    list(x, y),
    callbacks = list(autoresume, interrupt),
    verbose = FALSE
  )
})

# model resumes and completes
results &lt;- model %&gt;% fit(
  list(x, y),
  callbacks = list(autoresume, interrupt),
  verbose = FALSE
)

get_metrics(results)

}
</code></pre>

<hr>
<h2 id='luz_callback_csv_logger'>CSV logger callback</h2><span id='topic+luz_callback_csv_logger'></span>

<h3>Description</h3>

<p>Logs metrics obtained during training a fiel on disk.
The file will have 1 line for each epoch/validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_csv_logger(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_csv_logger_+3A_path">path</code></td>
<td>
<p>path to a file on disk.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>

<hr>
<h2 id='luz_callback_early_stopping'>Early stopping callback</h2><span id='topic+luz_callback_early_stopping'></span>

<h3>Description</h3>

<p>Stops training when a monitored metric stops improving
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_early_stopping(
  monitor = "valid_loss",
  min_delta = 0,
  patience = 0,
  mode = "min",
  baseline = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_early_stopping_+3A_monitor">monitor</code></td>
<td>
<p>A string in the format <code style="white-space: pre;">&#8288;&lt;set&gt;_&lt;metric&gt;&#8288;</code> where <code style="white-space: pre;">&#8288;&lt;set&gt;&#8288;</code> can be
'train' or 'valid' and <code style="white-space: pre;">&#8288;&lt;metric&gt;&#8288;</code> can be the abbreviation of any metric
that you are tracking during training. The metric name is case insensitive.</p>
</td></tr>
<tr><td><code id="luz_callback_early_stopping_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement to reset the patience counter.</p>
</td></tr>
<tr><td><code id="luz_callback_early_stopping_+3A_patience">patience</code></td>
<td>
<p>Number of epochs without improving until stoping training.</p>
</td></tr>
<tr><td><code id="luz_callback_early_stopping_+3A_mode">mode</code></td>
<td>
<p>Specifies the direction that is considered an improvement. By default
'min' is used. Can also be 'max' (higher is better) and 'zero'
(closer to zero is better).</p>
</td></tr>
<tr><td><code id="luz_callback_early_stopping_+3A_baseline">baseline</code></td>
<td>
<p>An initial value that will be used as the best seen value
in the begining. Model will stopm training if no better than baseline value
is found in the first <code>patience</code> epochs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>luz_callback</code> that does early stopping.
</p>


<h3>Note</h3>

<p>This callback adds a <code>on_early_stopping</code> callback that can be used to
call callbacks as soon as the model stops training.
</p>
<p>If <code>verbose=TRUE</code> in <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code> a message is printed when
early stopping.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cb &lt;- luz_callback_early_stopping()

</code></pre>

<hr>
<h2 id='luz_callback_gradient_clip'>Gradient clipping callback</h2><span id='topic+luz_callback_gradient_clip'></span>

<h3>Description</h3>

<p>By adding the GradientClip callback, the gradient <code>norm_type</code> (default:2) norm
is clipped to at most <code>max_norm</code> (default:1) using <code><a href="torch.html#topic+nn_utils_clip_grad_norm_">torch::nn_utils_clip_grad_norm_()</a></code>,
which can avoid loss divergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_gradient_clip(max_norm = 1, norm_type = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_gradient_clip_+3A_max_norm">max_norm</code></td>
<td>
<p>(float or int): max norm of the gradients</p>
</td></tr>
<tr><td><code id="luz_callback_gradient_clip_+3A_norm_type">norm_type</code></td>
<td>
<p>(float or int): type of the used p-norm. Can be <code>Inf</code> for
infinity norm.</p>
</td></tr>
</table>


<h3>References</h3>

<p>See FastAI <a href="https://docs.fast.ai/callback.training.html#GradientClip">documentation</a>
for the GradientClip callback.
</p>

<hr>
<h2 id='luz_callback_interrupt'>Interrupt callback</h2><span id='topic+luz_callback_interrupt'></span>

<h3>Description</h3>

<p>Adds a handler that allows interrupting the training loop using <code>ctrl + C</code>.
Also registers a <code>on_interrupt</code> breakpoint so users can register callbacks to
be run on training loop interruption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_interrupt()
</code></pre>


<h3>Value</h3>

<p>A <code>luz_callback</code>
</p>


<h3>Note</h3>

<p>In general you don't need to use these callback by yourself because it's always
included by default in <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>interrupt_callback &lt;- luz_callback_interrupt()

</code></pre>

<hr>
<h2 id='luz_callback_keep_best_model'>Keep the best model</h2><span id='topic+luz_callback_keep_best_model'></span>

<h3>Description</h3>

<p>Each epoch, if there's improvement in the monitored metric we serialize the
model weights to a temp file. When training is done, we reload weights from
the best model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_keep_best_model(
  monitor = "valid_loss",
  mode = "min",
  min_delta = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_keep_best_model_+3A_monitor">monitor</code></td>
<td>
<p>A string in the format <code style="white-space: pre;">&#8288;&lt;set&gt;_&lt;metric&gt;&#8288;</code> where <code style="white-space: pre;">&#8288;&lt;set&gt;&#8288;</code> can be
'train' or 'valid' and <code style="white-space: pre;">&#8288;&lt;metric&gt;&#8288;</code> can be the abbreviation of any metric
that you are tracking during training. The metric name is case insensitive.</p>
</td></tr>
<tr><td><code id="luz_callback_keep_best_model_+3A_mode">mode</code></td>
<td>
<p>Specifies the direction that is considered an improvement. By default
'min' is used. Can also be 'max' (higher is better) and 'zero'
(closer to zero is better).</p>
</td></tr>
<tr><td><code id="luz_callback_keep_best_model_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement to reset the patience counter.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cb &lt;- luz_callback_keep_best_model()

</code></pre>

<hr>
<h2 id='luz_callback_lr_scheduler'>Learning rate scheduler callback</h2><span id='topic+luz_callback_lr_scheduler'></span>

<h3>Description</h3>

<p>Initializes and runs <code><a href="torch.html#topic+lr_scheduler">torch::lr_scheduler()</a></code>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_lr_scheduler(
  lr_scheduler,
  ...,
  call_on = "on_epoch_end",
  opt_name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_lr_scheduler_+3A_lr_scheduler">lr_scheduler</code></td>
<td>
<p>A <code><a href="torch.html#topic+lr_scheduler">torch::lr_scheduler()</a></code> that will be initialized with
the optimizer and the <code>...</code> parameters.</p>
</td></tr>
<tr><td><code id="luz_callback_lr_scheduler_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>lr_scheduler</code> together with
the optimizers.</p>
</td></tr>
<tr><td><code id="luz_callback_lr_scheduler_+3A_call_on">call_on</code></td>
<td>
<p>The callback breakpoint that <code>scheduler$step()</code> is called.
Default is <code>'on_epoch_end'</code>. See <code><a href="#topic+luz_callback">luz_callback()</a></code> for more information.</p>
</td></tr>
<tr><td><code id="luz_callback_lr_scheduler_+3A_opt_name">opt_name</code></td>
<td>
<p>name of the optimizer that will be affected by this callback.
Should match the name given in <code>set_optimizers</code>. If your module has a single
optimizer, <code>opt_name</code> is not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+luz_callback">luz_callback()</a></code> generator.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
cb &lt;- luz_callback_lr_scheduler(torch::lr_step, step_size = 30)
}
</code></pre>

<hr>
<h2 id='luz_callback_metrics'>Metrics callback</h2><span id='topic+luz_callback_metrics'></span>

<h3>Description</h3>

<p>Tracks metrics passed to <code><a href="#topic+setup">setup()</a></code> during training and validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_metrics()
</code></pre>


<h3>Details</h3>

<p>This callback takes care of 2 <a href="#topic+ctx">ctx</a> attributes:
</p>

<ul>
<li> <p><code>ctx$metrics</code>: stores the current metrics objects that are initialized once for epoch,
and are further <code>update()</code>d and <code>compute()</code>d every batch. You will rarely need
to work with these metrics.
</p>
</li>
<li> <p><code>ctx$records$metrics</code>: Stores metrics per training/validation and epoch. The
structure is very similar to <code>ctx$losses</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>luz_callback</code>
</p>


<h3>Note</h3>

<p>In general you won't need to explicitly use the metrics callback as it's
used by default in <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>

<hr>
<h2 id='luz_callback_mixup'>Mixup callback</h2><span id='topic+luz_callback_mixup'></span>

<h3>Description</h3>

<p>Implementation of <a href="https://arxiv.org/abs/1710.09412">'mixup: Beyond Empirical Risk Minimization'</a>.
As of today, tested only for categorical data,
where targets are expected to be integers, not one-hot encoded vectors.
This callback is supposed to be used together with <code><a href="#topic+nn_mixup_loss">nn_mixup_loss()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_mixup(alpha = 0.4, ..., run_valid = FALSE, auto_loss = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_mixup_+3A_alpha">alpha</code></td>
<td>
<p>parameter for the beta distribution used to sample mixing coefficients</p>
</td></tr>
<tr><td><code id="luz_callback_mixup_+3A_...">...</code></td>
<td>
<p>currently unused. Just to force named arguments.</p>
</td></tr>
<tr><td><code id="luz_callback_mixup_+3A_run_valid">run_valid</code></td>
<td>
<p>Should it run during validation</p>
</td></tr>
<tr><td><code id="luz_callback_mixup_+3A_auto_loss">auto_loss</code></td>
<td>
<p>Should it automatically modify the loss function? This will wrap
the loss function to create the mixup loss. If <code>TRUE</code> make sure that your loss
function does not apply reductions. If <code>run_valid=FALSE</code>, then loss will be
mean reduced during validation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Overall, we follow the <a href="https://github.com/fastai/fastai/blob/master/fastai/callback/mixup.py">fastai implementation</a>
described <a href="https://forums.fast.ai/t/mixup-data-augmentation/22764">here</a>.
Namely,
</p>

<ul>
<li><p> We work with a single dataloader only, randomly mixing two observations from the same batch.
</p>
</li>
<li><p> We linearly combine losses computed for both targets:
<code>loss(output, new_target) = weight * loss(output, target1) + (1-weight) * loss(output, target2)</code>
</p>
</li>
<li><p> We draw different mixing coefficients for every pair.
</p>
</li>
<li><p> We replace <code>weight</code> with <code>weight = max(weight, 1-weight)</code> to avoid duplicates.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>luz_callback</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nn_mixup_loss">nn_mixup_loss()</a></code>, <code><a href="#topic+nnf_mixup">nnf_mixup()</a></code>
</p>
<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
mixup_callback &lt;- luz_callback_mixup()
}

</code></pre>

<hr>
<h2 id='luz_callback_model_checkpoint'>Checkpoints model weights</h2><span id='topic+luz_callback_model_checkpoint'></span>

<h3>Description</h3>

<p>This saves checkpoints of the model according to the specified metric and
behavior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_model_checkpoint(
  path,
  monitor = "valid_loss",
  save_best_only = FALSE,
  mode = "min",
  min_delta = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_model_checkpoint_+3A_path">path</code></td>
<td>
<p>Path to save the model on disk. The path is interpolated with <code>glue</code>,
so you can use any attribute within the <a href="#topic+ctx">ctx</a> by using <code>'{ctx$epoch}'</code>. Specially
the <code>epoch</code> and <code>monitor</code> quantities are already in the environment. If the specified
path is a path to a directory (ends with <code>/</code> or <code style="white-space: pre;">&#8288;\&#8288;</code>), then models are saved with the name given by
<code style="white-space: pre;">&#8288;epoch-{epoch:02d}-{self$monitor}-{monitor:.3f}.pt&#8288;</code>. See more in the examples.
You can use <code><a href="base.html#topic+sprintf">sprintf()</a></code> to quickly format quantities, for example:<code>'{epoch:02d}'</code>.</p>
</td></tr>
<tr><td><code id="luz_callback_model_checkpoint_+3A_monitor">monitor</code></td>
<td>
<p>A string in the format <code style="white-space: pre;">&#8288;&lt;set&gt;_&lt;metric&gt;&#8288;</code> where <code style="white-space: pre;">&#8288;&lt;set&gt;&#8288;</code> can be
'train' or 'valid' and <code style="white-space: pre;">&#8288;&lt;metric&gt;&#8288;</code> can be the abbreviation of any metric
that you are tracking during training. The metric name is case insensitive.</p>
</td></tr>
<tr><td><code id="luz_callback_model_checkpoint_+3A_save_best_only">save_best_only</code></td>
<td>
<p>if <code>TRUE</code> models are only saved if they have an improvement
over a previously saved model.</p>
</td></tr>
<tr><td><code id="luz_callback_model_checkpoint_+3A_mode">mode</code></td>
<td>
<p>Specifies the direction that is considered an improvement. By default
'min' is used. Can also be 'max' (higher is better) and 'zero'
(closer to zero is better).</p>
</td></tr>
<tr><td><code id="luz_callback_model_checkpoint_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum difference to consider as improvement. Only used when
<code>save_best_only=TRUE</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>mode</code> and <code>min_delta</code> are only used when <code>save_best_only=TRUE</code>.
<code>save_best_only</code> will overwrite the saved models if the <code>path</code> parameter
don't differentiate by epochs.
</p>
<p>Read the checkpointing article in the pkgdown website for more
information.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>luz_callback_model_checkpoint(path= "path/to/dir")
luz_callback_model_checkpoint(path= "path/to/dir/epoch-{epoch:02d}/model.pt")
luz_callback_model_checkpoint(path= "path/to/dir/epoch-{epoch:02d}/model-{monitor:.2f}.pt")

</code></pre>

<hr>
<h2 id='luz_callback_profile'>Profile callback</h2><span id='topic+luz_callback_profile'></span>

<h3>Description</h3>

<p>Computes the times for high-level operations in the training loops.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_profile()
</code></pre>


<h3>Details</h3>

<p>Records are saved in <code>ctx$records$profile</code>. Times are stored as seconds.
Data is stored in the following structure:
</p>

<ul>
<li> <p><strong>fit</strong> time for the entire fit procedure.
</p>
</li>
<li> <p><strong>epoch</strong> times per epoch
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>luz_callback</code>
</p>


<h3>Note</h3>

<p>In general you don't need to use these callback by yourself because it's always
included by default in <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>profile_callback &lt;- luz_callback_profile()

</code></pre>

<hr>
<h2 id='luz_callback_progress'>Progress callback</h2><span id='topic+luz_callback_progress'></span>

<h3>Description</h3>

<p>Responsible for printing progress during training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_progress()
</code></pre>


<h3>Value</h3>

<p>A <code>luz_callback</code>
</p>


<h3>Note</h3>

<p>In general you don't need to use these callback by yourself because it's always
included by default in <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>
<p>Printing can be disabled by passing <code>verbose=FALSE</code> to <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>

<hr>
<h2 id='luz_callback_resume_from_checkpoint'>Allow resume model training from a specific checkpoint</h2><span id='topic+luz_callback_resume_from_checkpoint'></span>

<h3>Description</h3>

<p>Allow resume model training from a specific checkpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_resume_from_checkpoint(
  path,
  ...,
  restore_model_state = TRUE,
  restore_records = FALSE,
  restore_optimizer_state = FALSE,
  restore_callbacks_state = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_resume_from_checkpoint_+3A_path">path</code></td>
<td>
<p>Path to the checkpoint that you want to resume.</p>
</td></tr>
<tr><td><code id="luz_callback_resume_from_checkpoint_+3A_...">...</code></td>
<td>
<p>currently unused.</p>
</td></tr>
<tr><td><code id="luz_callback_resume_from_checkpoint_+3A_restore_model_state">restore_model_state</code></td>
<td>
<p>Wether to restore the model state from the callback.</p>
</td></tr>
<tr><td><code id="luz_callback_resume_from_checkpoint_+3A_restore_records">restore_records</code></td>
<td>
<p>Wether to restore records from the checkpoint.</p>
</td></tr>
<tr><td><code id="luz_callback_resume_from_checkpoint_+3A_restore_optimizer_state">restore_optimizer_state</code></td>
<td>
<p>Wether to restore the optimizer state from the
checkpoint.</p>
</td></tr>
<tr><td><code id="luz_callback_resume_from_checkpoint_+3A_restore_callbacks_state">restore_callbacks_state</code></td>
<td>
<p>Wether to restore the callbacks state from the
checkpoint.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Read the checkpointing article in the pkgdown website for more
information.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint()</a></code>
</p>
<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>

<hr>
<h2 id='luz_callback_tfevents'>tfevents callback</h2><span id='topic+luz_callback_tfevents'></span>

<h3>Description</h3>

<p>Logs metrics and other model information in the tfevents file format.
Assuming tensorboard is installed, result can be visualized with
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_tfevents(logdir = "logs", histograms = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_callback_tfevents_+3A_logdir">logdir</code></td>
<td>
<p>A directory to where log will be written to.</p>
</td></tr>
<tr><td><code id="luz_callback_tfevents_+3A_histograms">histograms</code></td>
<td>
<p>A boolean specifying if histograms of model weights should
be logged. It can also be a character vector specifying the name of the parameters
that should be logged (names are the same as <code>names(model$parameters)</code>).</p>
</td></tr>
<tr><td><code id="luz_callback_tfevents_+3A_...">...</code></td>
<td>
<p>Currently not used. For future expansion.</p>
</td></tr>
</table>


<h3>Details</h3>

<div class="sourceCode"><pre>tensorboard --logdir=logs
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
x &lt;- torch_randn(1000, 10)
y &lt;- torch_randn(1000, 1)

model &lt;- nn_linear %&gt;%
  setup(loss = nnf_mse_loss, optimizer = optim_adam) %&gt;%
  set_hparams(in_features = 10, out_features = 1) %&gt;%
  set_opt_hparams(lr = 1e-4)

tmp &lt;- tempfile()

model %&gt;% fit(list(x, y), valid_data = 0.2, callbacks = list(
  luz_callback_tfevents(tmp, histograms = TRUE)
))
}
</code></pre>

<hr>
<h2 id='luz_callback_train_valid'>Train-eval callback</h2><span id='topic+luz_callback_train_valid'></span>

<h3>Description</h3>

<p>Switches important flags for training and evaluation modes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_callback_train_valid()
</code></pre>


<h3>Details</h3>

<p>It takes care of the three <code>ctx</code> attributes:
</p>

<ul>
<li> <p><code>ctx$model</code>: Responsible for calling <code>ctx$model$train()</code> and <code>ctx$model$eval()</code>,
when appropriate.
</p>
</li>
<li> <p><code>ctx$training</code>: Sets this flag to <code>TRUE</code> when training and <code>FALSE</code> when in
validation mode.
</p>
</li>
<li> <p><code>ctx$loss</code>: Resets the <code>loss</code> attribute to <code>list()</code> when finished training/ or
validating.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>luz_callback</code>
</p>


<h3>Note</h3>

<p>In general you won't need to explicitly use the metrics callback as it's
used by default in <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.
</p>


<h3>See Also</h3>

<p>Other luz_callbacks: 
<code><a href="#topic+luz_callback_auto_resume">luz_callback_auto_resume</a>()</code>,
<code><a href="#topic+luz_callback_csv_logger">luz_callback_csv_logger</a>()</code>,
<code><a href="#topic+luz_callback_early_stopping">luz_callback_early_stopping</a>()</code>,
<code><a href="#topic+luz_callback_interrupt">luz_callback_interrupt</a>()</code>,
<code><a href="#topic+luz_callback_keep_best_model">luz_callback_keep_best_model</a>()</code>,
<code><a href="#topic+luz_callback_lr_scheduler">luz_callback_lr_scheduler</a>()</code>,
<code><a href="#topic+luz_callback_metrics">luz_callback_metrics</a>()</code>,
<code><a href="#topic+luz_callback_mixup">luz_callback_mixup</a>()</code>,
<code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback_profile">luz_callback_profile</a>()</code>,
<code><a href="#topic+luz_callback_progress">luz_callback_progress</a>()</code>,
<code><a href="#topic+luz_callback_resume_from_checkpoint">luz_callback_resume_from_checkpoint</a>()</code>,
<code><a href="#topic+luz_callback">luz_callback</a>()</code>
</p>

<hr>
<h2 id='luz_load'>Load trained model</h2><span id='topic+luz_load'></span>

<h3>Description</h3>

<p>Loads a fitted model. See documentation in <code><a href="#topic+luz_save">luz_save()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_load(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_load_+3A_path">path</code></td>
<td>
<p>path in file system so save the object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other luz_save: 
<code><a href="#topic+luz_save">luz_save</a>()</code>
</p>

<hr>
<h2 id='luz_load_checkpoint'>Loads a checkpoint</h2><span id='topic+luz_load_checkpoint'></span>

<h3>Description</h3>

<p>Works with checkpoints created typically with <code><a href="#topic+luz_callback_model_checkpoint">luz_callback_model_checkpoint()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_load_checkpoint(obj, path, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_load_checkpoint_+3A_obj">obj</code></td>
<td>
<p>Object to which we want to laod the checkpoint.</p>
</td></tr>
<tr><td><code id="luz_load_checkpoint_+3A_path">path</code></td>
<td>
<p>Path of the checkpoint on disk.</p>
</td></tr>
<tr><td><code id="luz_load_checkpoint_+3A_...">...</code></td>
<td>
<p>unused. Is there to allow future extensions.</p>
</td></tr>
</table>

<hr>
<h2 id='luz_load_model_weights'>Loads model weights into a fitted object.</h2><span id='topic+luz_load_model_weights'></span><span id='topic+luz_save_model_weights'></span>

<h3>Description</h3>

<p>This can be useful when you have saved model checkpoints during training and
want to reload the best checkpoint in the end.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_load_model_weights(obj, path, ...)

luz_save_model_weights(obj, path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_load_model_weights_+3A_obj">obj</code></td>
<td>
<p>luz object to which you want to copy the new weights.</p>
</td></tr>
<tr><td><code id="luz_load_model_weights_+3A_path">path</code></td>
<td>
<p>path to saved model in disk.</p>
</td></tr>
<tr><td><code id="luz_load_model_weights_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="torch.html#topic+torch_load">torch_load()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>NULL</code> invisibly.
</p>


<h3>Warning</h3>

<p><code>luz_save_model_weights</code> operates inplace, ie modifies the model object to contain the
new weights.
</p>

<hr>
<h2 id='luz_metric'>Creates a new luz metric</h2><span id='topic+luz_metric'></span>

<h3>Description</h3>

<p>Creates a new luz metric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric(
  name = NULL,
  ...,
  private = NULL,
  active = NULL,
  parent_env = parent.frame(),
  inherit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_metric_+3A_name">name</code></td>
<td>
<p>string naming the new metric.</p>
</td></tr>
<tr><td><code id="luz_metric_+3A_...">...</code></td>
<td>
<p>named list of public methods. You should implement at least
<code>initialize</code>, <code>update</code> and <code>compute</code>. See the details section for more
information.</p>
</td></tr>
<tr><td><code id="luz_metric_+3A_private">private</code></td>
<td>
<p>An optional list of private members, which can be functions
and non-functions.</p>
</td></tr>
<tr><td><code id="luz_metric_+3A_active">active</code></td>
<td>
<p>An optional list of active binding functions.</p>
</td></tr>
<tr><td><code id="luz_metric_+3A_parent_env">parent_env</code></td>
<td>
<p>An environment to use as the parent of newly-created
objects.</p>
</td></tr>
<tr><td><code id="luz_metric_+3A_inherit">inherit</code></td>
<td>
<p>A R6ClassGenerator object to inherit from; in other words, a
superclass. This is captured as an unevaluated expression which is
evaluated in <code>parent_env</code> each time an object is instantiated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to implement a new <code>luz_metric</code> we need to implement 3 methods:
</p>

<ul>
<li> <p><code>initialize</code>: defines the metric initial state. This function is
called for each epoch for both training and validation loops.
</p>
</li>
<li> <p><code>update</code>: updates the metric internal state. This function is called
at every training and validation step with the predictions obtained by
the model and the target values obtained from the dataloader.
</p>
</li>
<li> <p><code>compute</code>: uses the internal state to compute metric values. This
function is called whenever we need to obtain the current metric
value. Eg, it’s called every training step for metrics displayed in
the progress bar, but only called once per epoch to record it’s value
when the progress bar is not displayed.
</p>
</li></ul>

<p>Optionally, you can implement an <code>abbrev</code> field that gives the metric an
abbreviation that will be used when displaying metric information in the
console or tracking record. If no <code>abbrev</code> is passed, the class name
will be used.
</p>
<p>Let’s take a look at the implementation of <code>luz_metric_accuracy</code> so you
can see how to implement a new one:
</p>
<div class="sourceCode r"><pre>luz_metric_accuracy &lt;- luz_metric(
  # An abbreviation to be shown in progress bars, or 
  # when printing progress
  abbrev = "Acc", 
  # Initial setup for the metric. Metrics are initialized
  # every epoch, for both training and validation
  initialize = function() {
    self$correct &lt;- 0
    self$total &lt;- 0
  },
  # Run at every training or validation step and updates
  # the internal state. The update function takes `preds`
  # and `target` as parameters.
  update = function(preds, target) {
    pred &lt;- torch::torch_argmax(preds, dim = 2)
    self$correct &lt;- self$correct + (pred == target)$
      to(dtype = torch::torch_float())$
      sum()$
      item()
    self$total &lt;- self$total + pred$numel()
  },
  # Use the internal state to query the metric value
  compute = function() {
    self$correct/self$total
  }
)
</pre></div>
<p><strong>Note</strong>: It’s good practice that the <code>compute</code> metric returns regular R
values instead of torch tensors and other parts of luz will expect that.
</p>


<h3>Value</h3>

<p>Returns new luz metric.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>luz_metric_accuracy &lt;- luz_metric(
  # An abbreviation to be shown in progress bars, or
  # when printing progress
  abbrev = "Acc",
  # Initial setup for the metric. Metrics are initialized
  # every epoch, for both training and validation
  initialize = function() {
    self$correct &lt;- 0
    self$total &lt;- 0
  },
  # Run at every training or validation step and updates
  # the internal state. The update function takes `preds`
  # and `target` as parameters.
  update = function(preds, target) {
    pred &lt;- torch::torch_argmax(preds, dim = 2)
    self$correct &lt;- self$correct + (pred == target)$
      to(dtype = torch::torch_float())$
      sum()$
      item()
    self$total &lt;- self$total + pred$numel()
  },
  # Use the internal state to query the metric value
  compute = function() {
    self$correct/self$total
  }
)

</code></pre>

<hr>
<h2 id='luz_metric_accuracy'>Accuracy</h2><span id='topic+luz_metric_accuracy'></span>

<h3>Description</h3>

<p>Computes accuracy for multi-class classification problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_accuracy()
</code></pre>


<h3>Details</h3>

<p>This metric expects to take logits or probabilities at every
update. It will then take the columnwise argmax and compare
to the target.
</p>


<h3>Value</h3>

<p>Returns new luz metric.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
metric &lt;- luz_metric_accuracy()
metric &lt;- metric$new()
metric$update(torch_randn(100, 10), torch::torch_randint(1, 10, size = 100))
metric$compute()
}
</code></pre>

<hr>
<h2 id='luz_metric_binary_accuracy'>Binary accuracy</h2><span id='topic+luz_metric_binary_accuracy'></span>

<h3>Description</h3>

<p>Computes the accuracy for binary classification problems where the
model returns probabilities. Commonly used when the loss is <code><a href="torch.html#topic+nn_bce_loss">torch::nn_bce_loss()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_binary_accuracy(threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_metric_binary_accuracy_+3A_threshold">threshold</code></td>
<td>
<p>value used to classifiy observations between 0 and 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns new luz metric.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
metric &lt;- luz_metric_binary_accuracy(threshold = 0.5)
metric &lt;- metric$new()
metric$update(torch_rand(100), torch::torch_randint(0, 1, size = 100))
metric$compute()
}

</code></pre>

<hr>
<h2 id='luz_metric_binary_accuracy_with_logits'>Binary accuracy with logits</h2><span id='topic+luz_metric_binary_accuracy_with_logits'></span>

<h3>Description</h3>

<p>Computes accuracy for binary classification problems where the model
return logits. Commonly used together with <code><a href="torch.html#topic+nn_bce_with_logits_loss">torch::nn_bce_with_logits_loss()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_binary_accuracy_with_logits(threshold = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_metric_binary_accuracy_with_logits_+3A_threshold">threshold</code></td>
<td>
<p>value used to classifiy observations between 0 and 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Probabilities are generated using <code><a href="torch.html#topic+nnf_sigmoid">torch::nnf_sigmoid()</a></code> and <code>threshold</code> is used to
classify between 0 or 1.
</p>


<h3>Value</h3>

<p>Returns new luz metric.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
metric &lt;- luz_metric_binary_accuracy_with_logits(threshold = 0.5)
metric &lt;- metric$new()
metric$update(torch_randn(100), torch::torch_randint(0, 1, size = 100))
metric$compute()
}
</code></pre>

<hr>
<h2 id='luz_metric_binary_auroc'>Computes the area under the ROC</h2><span id='topic+luz_metric_binary_auroc'></span>

<h3>Description</h3>

<p>To avoid storing all predictions and targets for an epoch we compute confusion
matrices across a range of pre-established thresholds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_binary_auroc(
  num_thresholds = 200,
  thresholds = NULL,
  from_logits = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_metric_binary_auroc_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>Number of thresholds used to compute confusion matrices.
In that case, thresholds are created by getting <code>num_thresholds</code> values linearly
spaced in the unit interval.</p>
</td></tr>
<tr><td><code id="luz_metric_binary_auroc_+3A_thresholds">thresholds</code></td>
<td>
<p>(optional) If threshold are passed, then those are used to compute the
confusion matrices and <code>num_thresholds</code> is ignored.</p>
</td></tr>
<tr><td><code id="luz_metric_binary_auroc_+3A_from_logits">from_logits</code></td>
<td>
<p>Boolean indicating if predictions are logits, in that case
we use sigmoid to put them in the unit interval.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()){
library(torch)
actual &lt;- c(1, 1, 1, 0, 0, 0)
predicted &lt;- c(0.9, 0.8, 0.4, 0.5, 0.3, 0.2)

y_true &lt;- torch_tensor(actual)
y_pred &lt;- torch_tensor(predicted)

m &lt;- luz_metric_binary_auroc(thresholds = predicted)
m &lt;- m$new()

m$update(y_pred[1:2], y_true[1:2])
m$update(y_pred[3:4], y_true[3:4])
m$update(y_pred[5:6], y_true[5:6])

m$compute()
}
</code></pre>

<hr>
<h2 id='luz_metric_mae'>Mean absolute error</h2><span id='topic+luz_metric_mae'></span>

<h3>Description</h3>

<p>Computes the mean absolute error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_mae()
</code></pre>


<h3>Value</h3>

<p>Returns new luz metric.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
metric &lt;- luz_metric_mae()
metric &lt;- metric$new()
metric$update(torch_randn(100), torch_randn(100))
metric$compute()
}
</code></pre>

<hr>
<h2 id='luz_metric_mse'>Mean squared error</h2><span id='topic+luz_metric_mse'></span>

<h3>Description</h3>

<p>Computes the mean squared error
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_mse()
</code></pre>


<h3>Value</h3>

<p>A luz_metric object.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>

<hr>
<h2 id='luz_metric_multiclass_auroc'>Computes the multi-class AUROC</h2><span id='topic+luz_metric_multiclass_auroc'></span>

<h3>Description</h3>

<p>The same definition as <a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC">Keras</a>
is used by default. This is equivalent to the <code>'micro'</code> method in SciKit Learn
too. See <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html">docs</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_multiclass_auroc(
  num_thresholds = 200,
  thresholds = NULL,
  from_logits = FALSE,
  average = c("micro", "macro", "weighted", "none")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_metric_multiclass_auroc_+3A_num_thresholds">num_thresholds</code></td>
<td>
<p>Number of thresholds used to compute confusion matrices.
In that case, thresholds are created by getting <code>num_thresholds</code> values linearly
spaced in the unit interval.</p>
</td></tr>
<tr><td><code id="luz_metric_multiclass_auroc_+3A_thresholds">thresholds</code></td>
<td>
<p>(optional) If threshold are passed, then those are used to compute the
confusion matrices and <code>num_thresholds</code> is ignored.</p>
</td></tr>
<tr><td><code id="luz_metric_multiclass_auroc_+3A_from_logits">from_logits</code></td>
<td>
<p>If <code>TRUE</code> then we call <code><a href="torch.html#topic+nnf_softmax">torch::nnf_softmax()</a></code> in the predictions
before computing the metric.</p>
</td></tr>
<tr><td><code id="luz_metric_multiclass_auroc_+3A_average">average</code></td>
<td>
<p>The averaging method:
</p>

<ul>
<li> <p><code>'micro'</code>: Stack all classes and computes the AUROC as if it was a binary
classification problem.
</p>
</li>
<li> <p><code>'macro'</code>: Finds the AUCROC for each class and computes their mean.
</p>
</li>
<li> <p><code>'weighted'</code>: Finds the AUROC for each class and computes their weighted
mean pondering by the number of instances for each class.
</p>
</li>
<li> <p><code>'none'</code>: Returns the AUROC for each class in a list.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Note</strong> that class imbalance can affect this metric unlike
the AUC for binary classification.
</p>
<p>Currently the AUC is approximated using the 'interpolation' method described in
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC">Keras</a>.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_rmse">luz_metric_rmse</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
library(torch)
actual &lt;- c(1, 1, 1, 0, 0, 0) + 1L
predicted &lt;- c(0.9, 0.8, 0.4, 0.5, 0.3, 0.2)
predicted &lt;- cbind(1-predicted, predicted)

y_true &lt;- torch_tensor(as.integer(actual))
y_pred &lt;- torch_tensor(predicted)

m &lt;- luz_metric_multiclass_auroc(thresholds = as.numeric(predicted),
                                 average = "micro")
m &lt;- m$new()

m$update(y_pred[1:2,], y_true[1:2])
m$update(y_pred[3:4,], y_true[3:4])
m$update(y_pred[5:6,], y_true[5:6])
m$compute()
}
</code></pre>

<hr>
<h2 id='luz_metric_rmse'>Root mean squared error</h2><span id='topic+luz_metric_rmse'></span>

<h3>Description</h3>

<p>Computes the root mean squared error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_rmse()
</code></pre>


<h3>Value</h3>

<p>Returns new luz metric.
</p>


<h3>See Also</h3>

<p>Other luz_metrics: 
<code><a href="#topic+luz_metric_accuracy">luz_metric_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy_with_logits">luz_metric_binary_accuracy_with_logits</a>()</code>,
<code><a href="#topic+luz_metric_binary_accuracy">luz_metric_binary_accuracy</a>()</code>,
<code><a href="#topic+luz_metric_binary_auroc">luz_metric_binary_auroc</a>()</code>,
<code><a href="#topic+luz_metric_mae">luz_metric_mae</a>()</code>,
<code><a href="#topic+luz_metric_mse">luz_metric_mse</a>()</code>,
<code><a href="#topic+luz_metric_multiclass_auroc">luz_metric_multiclass_auroc</a>()</code>,
<code><a href="#topic+luz_metric">luz_metric</a>()</code>
</p>

<hr>
<h2 id='luz_metric_set'>Creates a metric set</h2><span id='topic+luz_metric_set'></span>

<h3>Description</h3>

<p>A metric set can be used to specify metrics that are only evaluated during
training, validation or both.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_metric_set(metrics = NULL, train_metrics = NULL, valid_metrics = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_metric_set_+3A_metrics">metrics</code></td>
<td>
<p>A list of luz_metrics that are meant to be used in both training
and validation.</p>
</td></tr>
<tr><td><code id="luz_metric_set_+3A_train_metrics">train_metrics</code></td>
<td>
<p>A list of luz_metrics that are only used during training.</p>
</td></tr>
<tr><td><code id="luz_metric_set_+3A_valid_metrics">valid_metrics</code></td>
<td>
<p>A list of luz_metrics that are only sued for validation.</p>
</td></tr>
</table>

<hr>
<h2 id='luz_save'>Saves luz objects to disk</h2><span id='topic+luz_save'></span>

<h3>Description</h3>

<p>Allows saving luz fitted models to the disk. Objects can be loaded back with
<code><a href="#topic+luz_load">luz_load()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>luz_save(obj, path, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="luz_save_+3A_obj">obj</code></td>
<td>
<p>an object of class 'luz_module_fitted' as returned by
<code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code>.</p>
</td></tr>
<tr><td><code id="luz_save_+3A_path">path</code></td>
<td>
<p>path in file system so save the object.</p>
</td></tr>
<tr><td><code id="luz_save_+3A_...">...</code></td>
<td>
<p>currently unused.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>The <a href="#topic+ctx">ctx</a> is naively serialized. Ie, we only use <code><a href="base.html#topic+saveRDS">saveRDS()</a></code> to serialize it.
Don't expect <code>luz_save</code> to work correctly if you have unserializable objects
in the <a href="#topic+ctx">ctx</a> like <code>torch_tensor</code>s and external pointers in general.
</p>


<h3>Note</h3>

<p>Objects are saved as plain <code>.rds</code> files but <code>obj$model</code> is serialized
with <code>torch_save</code> before saving it.
</p>


<h3>See Also</h3>

<p>Other luz_save: 
<code><a href="#topic+luz_load">luz_load</a>()</code>
</p>

<hr>
<h2 id='nn_mixup_loss'>Loss to be used with <code>callbacks_mixup()</code>.</h2><span id='topic+nn_mixup_loss'></span>

<h3>Description</h3>

<p>In the training phase, computes individual losses with regard to two targets, weights them item-wise,
and averages the linear combinations to yield the mean batch loss.
For validation and testing, defers to the passed-in loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_mixup_loss(loss)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_mixup_loss_+3A_loss">loss</code></td>
<td>
<p>the underlying loss <code>nn_module</code> to call. It must
support the <code>reduction</code> field. During training the attribute will be changed to
<code>'none'</code> so we get the loss for individual observations. See for for example
documentation for the <code>reduction</code> argument in <code><a href="torch.html#topic+nn_cross_entropy_loss">torch::nn_cross_entropy_loss()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It should be used together with <code><a href="#topic+luz_callback_mixup">luz_callback_mixup()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+luz_callback_mixup">luz_callback_mixup()</a></code>
</p>

<hr>
<h2 id='nnf_mixup'>Mixup logic</h2><span id='topic+nnf_mixup'></span>

<h3>Description</h3>

<p>Logic underlying <code><a href="#topic+luz_callback_mixup">luz_callback_mixup()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nnf_mixup(x, y, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnf_mixup_+3A_x">x</code></td>
<td>
<p>an input batch</p>
</td></tr>
<tr><td><code id="nnf_mixup_+3A_y">y</code></td>
<td>
<p>a target batch</p>
</td></tr>
<tr><td><code id="nnf_mixup_+3A_weight">weight</code></td>
<td>
<p>weighting coefficient to be used by <code>torch_lerp()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on the passed-in input and target batches, as well as applicable mixing weights,
we return new tensors intended to replace the current batch.
The new input batch is a weighted linear combination of input batch items, while
the new target batch bundles the original targets, as well as the mixing weights, in
a nested list.
</p>


<h3>Value</h3>

<p>A <code>list</code> of:
</p>

<ul>
<li> <p><code>x</code>, the new, mixed-up input batch
</p>
</li>
<li> <p><code>y</code>, a <code>list</code> of:
</p>

<ul>
<li> <p><code>ys</code>, a <code>list</code> of:
</p>

<ul>
<li> <p><code>y1</code>, the original target <code>y1</code>
</p>
</li>
<li> <p><code>y2</code>, the mixed-in target <code>y2</code>
</p>
</li></ul>

</li>
<li> <p><code>weight</code>, the mixing weights
</p>
</li></ul>

</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+luz_callback_mixup">luz_callback_mixup()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (torch::torch_is_installed()) {
batch_x &lt;- torch::torch_randn(c(10, 768))
batch_y &lt;- torch::torch_randn(10)
weight &lt;- torch::torch_tensor(rep(0.9, 10))$view(c(10, 1))
nnf_mixup(batch_x, batch_y, weight)
}

</code></pre>

<hr>
<h2 id='predict.luz_module_fitted'>Create predictions for a fitted model</h2><span id='topic+predict.luz_module_fitted'></span>

<h3>Description</h3>

<p>Create predictions for a fitted model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'luz_module_fitted'
predict(
  object,
  newdata,
  ...,
  callbacks = list(),
  accelerator = NULL,
  verbose = NULL,
  dataloader_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.luz_module_fitted_+3A_object">object</code></td>
<td>
<p>(fitted model) the fitted model object returned from <code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator()</a></code></p>
</td></tr>
<tr><td><code id="predict.luz_module_fitted_+3A_newdata">newdata</code></td>
<td>
<p>(dataloader, dataset, list or array) returning a list with at
least 1 element. The other elements aren't used.</p>
</td></tr>
<tr><td><code id="predict.luz_module_fitted_+3A_...">...</code></td>
<td>
<p>Currently unused.</p>
</td></tr>
<tr><td><code id="predict.luz_module_fitted_+3A_callbacks">callbacks</code></td>
<td>
<p>(list, optional) A list of callbacks defined with
<code><a href="#topic+luz_callback">luz_callback()</a></code> that will be called during the training procedure. The
callbacks <code><a href="#topic+luz_callback_metrics">luz_callback_metrics()</a></code>, <code><a href="#topic+luz_callback_progress">luz_callback_progress()</a></code> and
<code><a href="#topic+luz_callback_train_valid">luz_callback_train_valid()</a></code> are always added by default.</p>
</td></tr>
<tr><td><code id="predict.luz_module_fitted_+3A_accelerator">accelerator</code></td>
<td>
<p>(accelerator, optional) An optional <code><a href="#topic+accelerator">accelerator()</a></code> object
used to configure device placement of the components like <a href="torch.html#topic+nn_module">nn_module</a>s,
optimizers and batches of data.</p>
</td></tr>
<tr><td><code id="predict.luz_module_fitted_+3A_verbose">verbose</code></td>
<td>
<p>(logical, optional) An optional boolean value indicating if
the fitting procedure should emit output to the console during training.
By default, it will produce output if <code><a href="base.html#topic+interactive">interactive()</a></code> is <code>TRUE</code>, otherwise
it won't print to the console.</p>
</td></tr>
<tr><td><code id="predict.luz_module_fitted_+3A_dataloader_options">dataloader_options</code></td>
<td>
<p>Options used when creating a dataloader. See
<code><a href="torch.html#topic+dataloader">torch::dataloader()</a></code>. <code>shuffle=TRUE</code> by default for the training data and
<code>batch_size=32</code> by default. It will error if not <code>NULL</code> and <code>data</code> is
already a dataloader.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other training: 
<code><a href="#topic+evaluate">evaluate</a>()</code>,
<code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator</a>()</code>,
<code><a href="#topic+setup">setup</a>()</code>
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+fit'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+fit">fit</a></code></p>
</dd>
</dl>

<hr>
<h2 id='set_hparams'>Set hyper-parameter of a module</h2><span id='topic+set_hparams'></span>

<h3>Description</h3>

<p>This function is used to define hyper-parameters before calling <code>fit</code> for
<code>luz_modules</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_hparams(module, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_hparams_+3A_module">module</code></td>
<td>
<p>An <code>nn_module</code> that has been <code><a href="#topic+setup">setup()</a></code>.</p>
</td></tr>
<tr><td><code id="set_hparams_+3A_...">...</code></td>
<td>
<p>The parameters set here will be used to initialize the <code>nn_module</code>, ie they
are passed unchanged to the <code>initialize</code> method of the base <code>nn_module</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same luz module
</p>


<h3>See Also</h3>

<p>Other set_hparam: 
<code><a href="#topic+set_opt_hparams">set_opt_hparams</a>()</code>
</p>

<hr>
<h2 id='set_opt_hparams'>Set optimizer hyper-parameters</h2><span id='topic+set_opt_hparams'></span>

<h3>Description</h3>

<p>This function is used to define hyper-parameters for the optimizer initialization
method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_opt_hparams(module, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_opt_hparams_+3A_module">module</code></td>
<td>
<p>An <code>nn_module</code> that has been <code><a href="#topic+setup">setup()</a></code>.</p>
</td></tr>
<tr><td><code id="set_opt_hparams_+3A_...">...</code></td>
<td>
<p>The parameters passed here will be used to initialize the optimizers.
For example, if your optimizer is <code>optim_adam</code> and you pass <code>lr=0.1</code>, then the
<code>optim_adam</code> function is called with <code>optim_adam(parameters, lr=0.1)</code> when fitting
the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same luz module
</p>


<h3>See Also</h3>

<p>Other set_hparam: 
<code><a href="#topic+set_hparams">set_hparams</a>()</code>
</p>

<hr>
<h2 id='setup'>Set's up a <code>nn_module</code> to use with luz</h2><span id='topic+setup'></span>

<h3>Description</h3>

<p>The setup function is used to set important attributes and method for <code>nn_modules</code>
to be used with luz.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup(module, loss = NULL, optimizer = NULL, metrics = NULL, backward = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup_+3A_module">module</code></td>
<td>
<p>(<code>nn_module</code>) The <code>nn_module</code> that you want set up.</p>
</td></tr>
<tr><td><code id="setup_+3A_loss">loss</code></td>
<td>
<p>(<code>function</code>, optional) An optional function with the signature
<code style="white-space: pre;">&#8288;function(input, target)&#8288;</code>. It's only requires if your <code>nn_module</code> doesn't
implement a method called <code>loss</code>.</p>
</td></tr>
<tr><td><code id="setup_+3A_optimizer">optimizer</code></td>
<td>
<p>(<code>torch_optimizer</code>, optional) A function with the signature
<code style="white-space: pre;">&#8288;function(parameters, ...)&#8288;</code> that is used to initialize an optimizer given
the model parameters.</p>
</td></tr>
<tr><td><code id="setup_+3A_metrics">metrics</code></td>
<td>
<p>(<code>list</code>, optional) A list of metrics to be tracked during
the training procedure. Sometimes, you want some metrics to be evaluated
only during training or validation, in this case you can pass a <code><a href="#topic+luz_metric_set">luz_metric_set()</a></code>
object to specify mmetrics used in each stage.</p>
</td></tr>
<tr><td><code id="setup_+3A_backward">backward</code></td>
<td>
<p>(<code>function</code>) A functions that takes the loss scalar values as
it's parameter. It must call <code style="white-space: pre;">&#8288;$backward()&#8288;</code> or <code><a href="torch.html#topic+autograd_backward">torch::autograd_backward()</a></code>.
In general you don't need to set this parameter unless you need to customize
how luz calls the <code>backward()</code>, for example, if you need to add additional
arguments to the backward call. Note that this becomes a method of the <code>nn_module</code>
thus can be used by your custom <code>step()</code> if you override it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It makes sure the module have all the necessary ingredients in order to be fitted.
</p>


<h3>Value</h3>

<p>A luz module that can be trained with <code><a href="#topic+fit">fit()</a></code>.
</p>


<h3>Note</h3>

<p>It also adds a <code>device</code> active field that can be used to query the current
module <code>device</code> within methods, with eg <code>self$device</code>. This is useful when
<code><a href="#topic+ctx">ctx()</a></code> is not available, eg, when calling methods from outside the <code>luz</code>
wrappers. Users can override the default by implementing a <code>device</code> active
method in the input <code>module</code>.
</p>


<h3>See Also</h3>

<p>Other training: 
<code><a href="#topic+evaluate">evaluate</a>()</code>,
<code><a href="#topic+fit.luz_module_generator">fit.luz_module_generator</a>()</code>,
<code><a href="#topic+predict.luz_module_fitted">predict.luz_module_fitted</a>()</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
