<!DOCTYPE html><html><head><title>Help for package SelectBoost</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SelectBoost}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AICc_BIC_glmnetB'><p>AICc and BIC for glmnet logistic models</p></a></li>
<li><a href='#auto.analyze'><p>Find limits for selectboost analysis</p></a></li>
<li><a href='#autoboost'><p>Autoboost</p></a></li>
<li><a href='#autoboost.res.x'><p>Autoboost lasso diabetes first order.</p></a></li>
<li><a href='#autoboost.res.x.adapt'><p>Autoboost adaptative lasso diabetes first order.</p></a></li>
<li><a href='#autoboost.res.x2'><p>Autoboost lasso diabetes second order.</p></a></li>
<li><a href='#autoboost.res.x2.adapt'><p>Autoboost adaptative lasso diabetes second order.</p></a></li>
<li><a href='#boost'><p>Boost step by step functions</p></a></li>
<li><a href='#Cascade_confidence'><p>Confidence indices</p></a></li>
<li><a href='#Cascade_example'><p>Simulated Cascade network and inference</p></a></li>
<li><a href='#fastboost'><p>Fastboost</p></a></li>
<li><a href='#fastboost.res.x'><p>Fastboost lasso diabetes first order.</p></a></li>
<li><a href='#fastboost.res.x.adapt'><p>Fastboost adaptative lasso diabetes first order.</p></a></li>
<li><a href='#fastboost.res.x2'><p>Fastboost lasso diabetes second order.</p></a></li>
<li><a href='#fastboost.res.x2.adapt'><p>Fastboost adaptative lasso diabetes second order.</p></a></li>
<li><a href='#force.non.inc'><p>Non increasing post processinng step for selectboost analysis</p></a></li>
<li><a href='#group_func_1'><p>Generate groups by thresholding.</p></a></li>
<li><a href='#group_func_2'><p>Generate groups using community analysis.</p></a></li>
<li><a href='#miscplot'><p>Miscellaneous plot functions</p></a></li>
<li><a href='#network.confidence-class'><p>Network confidence class.</p></a></li>
<li><a href='#plot_selectboost_cascade'><p>plot_Selectboost_cascade</p></a></li>
<li><a href='#plot.selectboost'><p>Plot selectboost object</p></a></li>
<li><a href='#plot.summary.selectboost'><p>Plot a summary of selectboost results</p></a></li>
<li><a href='#results_simuls_reverse_engineering_v3'><p>Simulations for reverse-engineering</p></a></li>
<li><a href='#SelectBoost'><p>SelectBoost</p></a></li>
<li><a href='#selectboost_cascade'><p>Selectboost_cascade</p></a></li>
<li><a href='#simulation'><p>Miscellaneous simulation functions</p></a></li>
<li><a href='#summary.selectboost'><p>Summarize a selectboost analysis</p></a></li>
<li><a href='#trajC0'><p>Plot trajectories</p></a></li>
<li><a href='#var_select'><p>Variable selection functions</p></a></li>
<li><a href='#var_select_all'><p>Variable selection functions (all)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A General Algorithm to Enhance the Performance of Variable
Selection Methods in Correlated Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-11-29</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lars, glmnet, igraph, parallel, msgps, Rfast, methods,
Cascade, graphics, grDevices, varbvs, spls, abind</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, rmarkdown, mixOmics, CascadeData</td>
</tr>
<tr>
<td>Author:</td>
<td>Frederic Bertrand <a href="https://orcid.org/0000-0002-0837-8281"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Myriam Maumy-Bertrand
    <a href="https://orcid.org/0000-0002-4615-1512"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Ismail Aouadi [ctb],
  Nicolas Jung [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Frederic Bertrand &lt;frederic.bertrand@utt.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of the selectboost algorithm (Bertrand et al. 2020, 'Bioinformatics', &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtaa855">doi:10.1093/bioinformatics/btaa855</a>&gt;), which is a general algorithm that improves the precision of any existing variable selection method. This algorithm is based on highly intensive simulations and takes into account the correlation structure of the data. It can either produce a confidence index for variable selection or it can be used in an experimental design planning perspective.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Classification/MSC:</td>
<td>62H11, 62J12, 62J99</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://fbertran.github.io/SelectBoost/">https://fbertran.github.io/SelectBoost/</a>,
<a href="https://github.com/fbertran/SelectBoost/">https://github.com/fbertran/SelectBoost/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/fbertran/SelectBoost/issues/">https://github.com/fbertran/SelectBoost/issues/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-29 22:08:35 UTC; fbertran</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-30 09:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='AICc_BIC_glmnetB'>AICc and BIC for glmnet logistic models</h2><span id='topic+AICc_BIC_glmnetB'></span><span id='topic+rerr'></span><span id='topic+ridge_logistic'></span><span id='topic+BIC_glmnetB'></span><span id='topic+AICc_glmnetB'></span>

<h3>Description</h3>

<p>Compute AICc and BIC for glmnet logistic models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rerr(v1, v2)

ridge_logistic(X, Y, lambda, beta0, beta, maxiter = 1000, tol = 1e-10)

BIC_glmnetB(Z, Y, glmnet.model, alpha, modelSet, reducer = "median")

AICc_glmnetB(Z, Y, glmnet.model, alpha, modelSet, reducer = "median")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AICc_BIC_glmnetB_+3A_v1">v1</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_v2">v2</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_x">X</code></td>
<td>
<p>A numeric matrix</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_y">Y</code></td>
<td>
<p>A numeric 0/1 vector.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_lambda">lambda</code></td>
<td>
<p>A numeric value.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_beta0">beta0</code></td>
<td>
<p>A numeric value Initial intercept value.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_beta">beta</code></td>
<td>
<p>A numeric vector. Initial coefficient values.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_maxiter">maxiter</code></td>
<td>
<p>A numeric value. Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_tol">tol</code></td>
<td>
<p>A numeric value. Tolerance value.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_z">Z</code></td>
<td>
<p>A numeric matrix</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_glmnet.model">glmnet.model</code></td>
<td>
<p>A fitted glmnet model.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_modelset">modelSet</code></td>
<td>
<p>Modelset to consider.</p>
</td></tr>
<tr><td><code id="AICc_BIC_glmnetB_+3A_reducer">reducer</code></td>
<td>
<p>A character value. Reducer function. Either 'median' or 'mean'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculate AICc and BIC for glmnet logistic models from the glmnetB function
of the package rLogistic <a href="https://github.com/echi/rLogistic">https://github.com/echi/rLogistic</a> and adapted
to deal with non finite exponential values in AICc and BIC computations
</p>


<h3>Value</h3>

<p>A list relevant to model selection.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>Robust Parametric Classification and Variable Selection by a Minimum Distance Criterion</em>, Chi and Scott, Journal of Computational and Graphical Statistics, <b>23</b>(1), 2014, p111&ndash;128, <a href="https://doi.org/10.1080/10618600.2012.737296">doi:10.1080/10618600.2012.737296</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+var_select">var_select</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(150),30,5)
ybin=sample(0:1,30,replace=TRUE)
glmnet.fit &lt;- glmnet.fit &lt;- glmnet::glmnet(xran,ybin,family="binomial",standardize=FALSE)
set.seed(314)
rerr(1:10,10:1)

set.seed(314)
ridge_logistic(xran,ybin,lambda=.5,beta0=rnorm(5),beta=rnorm(5,1))

set.seed(314)
if(is.factor(ybin)){ynum=unclass(ybin)-1} else {ynum=ybin}
subSample &lt;- 1:min(ncol(xran),100)
BIC_glmnetB(xran,ynum,glmnet.fit,alpha=1,subSample, reducer='median')

set.seed(314)
if(is.factor(ybin)){ynum=unclass(ybin)-1} else {ynum=ybin}
subSample &lt;- 1:min(ncol(xran),100)
AICc_glmnetB(xran,ynum,glmnet.fit,alpha=1,subSample, reducer='median')

</code></pre>

<hr>
<h2 id='auto.analyze'>Find limits for selectboost analysis</h2><span id='topic+auto.analyze'></span><span id='topic+auto.analyze.selectboost'></span>

<h3>Description</h3>

<p>Find limits for selectboost analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto.analyze(x, ...)

## S3 method for class 'selectboost'
auto.analyze(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auto.analyze_+3A_x">x</code></td>
<td>
<p>Numerical matrix. Selectboost object.</p>
</td></tr>
<tr><td><code id="auto.analyze_+3A_...">...</code></td>
<td>
<p>. Passed to the summary.selectboost function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.summary.selectboost</code> returns an invisible list and creates four graphics.
Two plots the proportion of selection with respect to c0 (by step or according to real scale).
On the third graph, no bar means a proportion of selection less than prop.level.
Confidence intervals are computed at the conf.int.level level.
Barplot of the confidence index (1-min(c0, such that proportion|c0&gt;conf.threshold)).
</p>


<h3>Value</h3>

<p>list of results.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code> and <code><a href="#topic+autoboost">autoboost</a></code>
</p>
<p>Other Selectboost analyze functions: 
<code><a href="#topic+plot.summary.selectboost">plot.summary.selectboost</a>()</code>,
<code><a href="#topic+trajC0">trajC0</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(autoboost.res.x)
auto.analyze(autoboost.res.x)

data(autoboost.res.x2)
auto.analyze(autoboost.res.x2)

</code></pre>

<hr>
<h2 id='autoboost'>Autoboost</h2><span id='topic+autoboost'></span>

<h3>Description</h3>

<p>All in one use of selectboost that avoids redondant fitting of distributions
and saves some memory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoboost(
  X,
  Y,
  ncores = 4,
  group = group_func_1,
  func = lasso_msgps_AICc,
  corrfunc = "cor",
  use.parallel = FALSE,
  B = 100,
  step.num = 0.1,
  step.limit = "none",
  risk = 0.05,
  verbose = FALSE,
  step.scale = "quantile",
  normalize = TRUE,
  steps.seq = NULL,
  debug = FALSE,
  version = "lars",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoboost_+3A_x">X</code></td>
<td>
<p>Numerical matrix. Matrix of the variables.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_y">Y</code></td>
<td>
<p>Numerical vector or factor. Response vector.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_ncores">ncores</code></td>
<td>
<p>Numerical value. Number of cores for parallel computing.
Defaults to <code>4</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_group">group</code></td>
<td>
<p>Function. The grouping function.
Defaults to <code>group_func_1</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_func">func</code></td>
<td>
<p>Function. The variable selection function.
Defaults to <code>lasso_msgps_AICc</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_corrfunc">corrfunc</code></td>
<td>
<p>Character value or function. Used to compute associations between
the variables. Defaults to <code>"cor"</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_use.parallel">use.parallel</code></td>
<td>
<p>Boolean. To use parallel computing (doMC) download the extended package from Github.
Set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_b">B</code></td>
<td>
<p>Numerical value. Number of resampled fits of the model.
Defaults to <code>100</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_step.num">step.num</code></td>
<td>
<p>Numerical value. Step value for the c0 sequence.
Defaults to <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_step.limit">step.limit</code></td>
<td>
<p>Character value. If &quot;Pearson&quot;, truncates the c0 sequence using a
Pearson based p-value.
Defaults to <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_risk">risk</code></td>
<td>
<p>Numerical value. Risk level when finding limits based on c0=0 values.
Defaults to <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_verbose">verbose</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_step.scale">step.scale</code></td>
<td>
<p>Character value. How to compute the c0 sequence if not user-provided:
either &quot;quantile&quot; or &quot;linear&quot;.
Defaults to <code>"quantile"</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_normalize">normalize</code></td>
<td>
<p>Boolean. Shall the X matrix be centered and scaled?
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_steps.seq">steps.seq</code></td>
<td>
<p>Numeric vector. User provided sequence of c0 values to use.
Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_debug">debug</code></td>
<td>
<p>Boolean value. If more results are required. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="autoboost_+3A_version">version</code></td>
<td>
<p>Character value. Passed to the <code>boost.select</code> function.
Defaults to <code>lars</code></p>
</td></tr>
<tr><td><code id="autoboost_+3A_...">...</code></td>
<td>
<p>. Arguments passed to the variable selection function used in <code>boost.apply</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>autoboost</code> returns a numeric matrix. For each of the variable (column)
and each of the c0 (row), the entry is proportion of times that the variable was
selected among the B resampled fits of the model. Fitting to the same group of variables is
only perfomed once (even if it occured for another value of c0), which greatly speeds up
the algorithm.
</p>


<h3>Value</h3>

<p>A numeric matrix with attributes.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boost">boost</a></code>, <code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+plot.selectboost">plot.selectboost</a></code>
</p>
<p>Other Selectboost functions: 
<code><a href="#topic+boost">boost</a></code>,
<code><a href="#topic+fastboost">fastboost</a>()</code>,
<code><a href="#topic+plot_selectboost_cascade">plot_selectboost_cascade</a></code>,
<code><a href="#topic+selectboost_cascade">selectboost_cascade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(75),15,5)
ybin=sample(0:1,15,replace=TRUE)
yran=rnorm(15)
set.seed(314)
#For quick test purpose, not meaningful, should be run with greater value of B
#and disabling parallel computing as well
res.autoboost &lt;- autoboost(xran,yran,B=3,use.parallel=FALSE)


autoboost(xran,yran)
#Customize resampling levels
autoboost(xran,yran,steps.seq=c(.99,.95,.9))

#Binary logistic regression
autoboost(xran,ybin,func=lasso_cv_glmnet_bin_min)


</code></pre>

<hr>
<h2 id='autoboost.res.x'>Autoboost lasso diabetes first order.</h2><span id='topic+autoboost.res.x'></span>

<h3>Description</h3>

<p>Result of autoboost analysis of diabetes data from <cite>lars</cite> package with lasso
and first order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoboost.res.x
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 10 variables with attributes.
</p>

<hr>
<h2 id='autoboost.res.x.adapt'>Autoboost adaptative lasso diabetes first order.</h2><span id='topic+autoboost.res.x.adapt'></span>

<h3>Description</h3>

<p>Result of autoboost analysis of diabetes data from <cite>lars</cite> package with adaptative
lasso and first order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoboost.res.x.adapt
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 10 variables with attributes.
</p>

<hr>
<h2 id='autoboost.res.x2'>Autoboost lasso diabetes second order.</h2><span id='topic+autoboost.res.x2'></span>

<h3>Description</h3>

<p>Result of autoboost analysis of diabetes data from <cite>lars</cite> package with lasso
and second order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoboost.res.x2
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 64 variables with attributes.
</p>

<hr>
<h2 id='autoboost.res.x2.adapt'>Autoboost adaptative lasso diabetes second order.</h2><span id='topic+autoboost.res.x2.adapt'></span>

<h3>Description</h3>

<p>Result of autoboost analysis of diabetes data from <cite>lars</cite> package with adaptative
lasso and second order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoboost.res.x2.adapt
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 64 variables with attributes.
</p>

<hr>
<h2 id='boost'>Boost step by step functions</h2><span id='topic+boost'></span><span id='topic+boost.normalize'></span><span id='topic+boost.compcorrs'></span><span id='topic+boost.correlation_sign'></span><span id='topic+boost.findgroups'></span><span id='topic+boost.Xpass'></span><span id='topic+boost.adjust'></span><span id='topic+boost.random'></span><span id='topic+boost.apply'></span><span id='topic+boost.select'></span>

<h3>Description</h3>

<p>Step by step functions to apply the selectboost algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boost.normalize(X, eps = 1e-08)

boost.compcorrs(
  Xnorm,
  corrfunc = "cor",
  verbose = FALSE,
  testvarindic = rep(TRUE, ncol(Xnorm))
)

boost.correlation_sign(Correlation_matrice, verbose = FALSE)

boost.findgroups(Correlation_matrice, group, corr = 1, verbose = FALSE)

boost.Xpass(nrowX, ncolX)

boost.adjust(
  X,
  groups,
  Correlation_sign,
  Xpass = boost.Xpass(nrowX, ncolX),
  verbose = FALSE,
  use.parallel = FALSE,
  ncores = 4
)

boost.random(
  X,
  Xpass,
  vmf.params,
  verbose = FALSE,
  B = 100,
  use.parallel = FALSE,
  ncores = 4
)

boost.apply(
  X,
  cols.simul,
  Y,
  func,
  verbose = FALSE,
  use.parallel = FALSE,
  ncores = 4,
  ...
)

boost.select(Boost.coeffs, eps = 10^(-4), version = "lars", verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boost_+3A_x">X</code></td>
<td>
<p>Numerical matrix. Matrix of the variables.</p>
</td></tr>
<tr><td><code id="boost_+3A_eps">eps</code></td>
<td>
<p>Numerical value. Response vector.</p>
</td></tr>
<tr><td><code id="boost_+3A_xnorm">Xnorm</code></td>
<td>
<p>Numerical matrix. Needs to be centered and l2 normalized.</p>
</td></tr>
<tr><td><code id="boost_+3A_corrfunc">corrfunc</code></td>
<td>
<p>Character value or function. The function to compute associations between the variables.</p>
</td></tr>
<tr><td><code id="boost_+3A_verbose">verbose</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="boost_+3A_testvarindic">testvarindic</code></td>
<td>
<p>Boolean vector. Compute associations for a subset of variables.
By default, the scope of the computation is the whole dataset, i.e. <code>rep(TRUE,ncol(Xnorm))</code>.</p>
</td></tr>
<tr><td><code id="boost_+3A_correlation_matrice">Correlation_matrice</code></td>
<td>
<p>Numerical matrix.</p>
</td></tr>
<tr><td><code id="boost_+3A_group">group</code></td>
<td>
<p>Character value or function. The grouping function.</p>
</td></tr>
<tr><td><code id="boost_+3A_corr">corr</code></td>
<td>
<p>Numerical value. Thresholding value. Defaults to <code>1</code>.</p>
</td></tr>
<tr><td><code id="boost_+3A_nrowx">nrowX</code></td>
<td>
<p>Numerical value</p>
</td></tr>
<tr><td><code id="boost_+3A_ncolx">ncolX</code></td>
<td>
<p>Numerical value.</p>
</td></tr>
<tr><td><code id="boost_+3A_groups">groups</code></td>
<td>
<p>List. List of groups or communities (compact form).</p>
</td></tr>
<tr><td><code id="boost_+3A_correlation_sign">Correlation_sign</code></td>
<td>
<p>Numerical -1/1 matrix.</p>
</td></tr>
<tr><td><code id="boost_+3A_xpass">Xpass</code></td>
<td>
<p>Numerical value. Transformation matrix.
Defaults to <code>boost.Xpass(nrowX,ncolX)</code>, with <code>nrowX=nrow(X)</code> and <code>ncolX=ncol(X)</code>.</p>
</td></tr>
<tr><td><code id="boost_+3A_use.parallel">use.parallel</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="boost_+3A_ncores">ncores</code></td>
<td>
<p>Numerical value. Number of cores to use.
Defaults to <code>4</code>.</p>
</td></tr>
<tr><td><code id="boost_+3A_vmf.params">vmf.params</code></td>
<td>
<p>List. List of the parameters ot the fitted von-Mises distributions.</p>
</td></tr>
<tr><td><code id="boost_+3A_b">B</code></td>
<td>
<p>Integer value. Number of resampling.</p>
</td></tr>
<tr><td><code id="boost_+3A_cols.simul">cols.simul</code></td>
<td>
<p>Numerical value. Transformation matrix.</p>
</td></tr>
<tr><td><code id="boost_+3A_y">Y</code></td>
<td>
<p>Numerical vector or factor. Response.</p>
</td></tr>
<tr><td><code id="boost_+3A_func">func</code></td>
<td>
<p>Function. Variable selection function.</p>
</td></tr>
<tr><td><code id="boost_+3A_...">...</code></td>
<td>
<p>. Additionnal parameters passed to the <code>func</code> function.</p>
</td></tr>
<tr><td><code id="boost_+3A_boost.coeffs">Boost.coeffs</code></td>
<td>
<p>Numerical matrix. l2 normed matrix of predictors.</p>
</td></tr>
<tr><td><code id="boost_+3A_version">version</code></td>
<td>
<p>Character value. &quot;lars&quot; (no intercept value) or &quot;glmnet&quot; (first coefficient is the intercept value).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>boost.normalize</code> returns a numeric matrix whose colun are centered and l2 normalized.
</p>
<p><code>boost.compcorrs</code> returns a correlation like matrix computed using the <code>corrfunc</code> function.
</p>
<p><code>boost.Xpass</code> returns the transformation matrix.
</p>
<p><code>boost.findgroups</code> returns a list of groups or communities found using the <code>group</code> function.
</p>
<p><code>boost.Xpass</code> returns the transformation matrix.
</p>
<p><code>boost.adjust</code> returns the list of the parameters ot the fitted von-Mises distributions.
</p>
<p><code>boost.random</code> returns an array with the resampled datasets.
</p>
<p><code>boost.apply</code> returns a matrix with the coefficients estimated using the resampled datasets.
</p>
<p><code>boost.select</code> returns a vector with the proportion of times each variable was selected.
</p>


<h3>Value</h3>

<p>Various types depending on the function.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code>
</p>
<p>Other Selectboost functions: 
<code><a href="#topic+autoboost">autoboost</a>()</code>,
<code><a href="#topic+fastboost">fastboost</a>()</code>,
<code><a href="#topic+plot_selectboost_cascade">plot_selectboost_cascade</a></code>,
<code><a href="#topic+selectboost_cascade">selectboost_cascade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(200),20,10)
yran=rnorm(20)
xran_norm &lt;- boost.normalize(xran)

xran_corr&lt;- boost.compcorrs(xran_norm)

xran_corr_sign &lt;- boost.correlation_sign(xran_corr)

xran_groups &lt;- boost.findgroups(xran_corr, group=group_func_1, .3)
xran_groups_2 &lt;- boost.findgroups(xran_corr, group=group_func_2, .3)

xran_Xpass &lt;- boost.Xpass(nrow(xran_norm),ncol(xran_norm))

xran_adjust &lt;- boost.adjust(xran_norm, xran_groups$groups, xran_corr_sign)

#Not meaningful, should be run with B&gt;=100
xran_random &lt;- boost.random(xran_norm, xran_Xpass, xran_adjust$vmf.params, B=5)


xran_random &lt;- boost.random(xran_norm, xran_Xpass, xran_adjust$vmf.params, B=100)


xran_apply &lt;- boost.apply(xran_norm, xran_random, yran, lasso_msgps_AICc)

xran_select &lt;- boost.select(xran_apply)

</code></pre>

<hr>
<h2 id='Cascade_confidence'>Confidence indices</h2><span id='topic+Cascade_confidence'></span><span id='topic+net_confidence'></span><span id='topic+net_confidence_.5'></span><span id='topic+net_confidence_thr'></span>

<h3>Description</h3>

<p>Result for confidence indices derivation using the Cascade package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>net_confidence

net_confidence_.5

net_confidence_thr
</code></pre>


<h3>Format</h3>

<p>A <code>network.confidence</code> object with four slots :
</p>

<dl>
<dt>network.confidence</dt><dd><p>The confidence matrix</p>
</dd>
<dt>name</dt><dd><p>Names of the variables (genes)</p>
</dd>
<dt>F</dt><dd><p>F array, see Cascade for more details</p>
</dd>
<dt>time_pt</dt><dd><p>Repeated measurements</p>
</dd>
<dt>cv.subjects</dt><dd><p>Logical. Was crossvalidation carried out subjectwise?</p>
</dd>
</dl>

<p>An object of class <code>network.confidence</code> of length 1.
</p>
<p>An object of class <code>network.confidence</code> of length 1.
</p>

<hr>
<h2 id='Cascade_example'>Simulated Cascade network and inference</h2><span id='topic+Cascade_example'></span><span id='topic+M'></span><span id='topic+Net'></span><span id='topic+Net_inf_C'></span>

<h3>Description</h3>

<p>Result for the reverse engineering of a simulated Cascade network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M

Net

Net_inf_C
</code></pre>


<h3>Format</h3>

<p>Three objects :
</p>

<dl>
<dt>M</dt><dd><p>Simulated microarray</p>
</dd>
<dt>Net</dt><dd><p>Simulated network</p>
</dd>
<dt>Net_inf_C</dt><dd><p>Inferred network</p>
</dd>
</dl>

<p>An object of class <code>network</code> of length 1.
</p>
<p>An object of class <code>network</code> of length 1.
</p>

<hr>
<h2 id='fastboost'>Fastboost</h2><span id='topic+fastboost'></span>

<h3>Description</h3>

<p>All in one use of selectboost that avoids redondant fitting of distributions
and saves some memory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastboost(
  X,
  Y,
  ncores = 4,
  group = group_func_1,
  func = lasso_msgps_AICc,
  corrfunc = "cor",
  use.parallel = FALSE,
  B = 100,
  step.num = 0.1,
  step.limit = "none",
  verbose = FALSE,
  step.scale = "quantile",
  normalize = TRUE,
  steps.seq = NULL,
  debug = FALSE,
  version = "lars",
  c0lim = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastboost_+3A_x">X</code></td>
<td>
<p>Numerical matrix. Matrix of the variables.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_y">Y</code></td>
<td>
<p>Numerical vector or factor. Response vector.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_ncores">ncores</code></td>
<td>
<p>Numerical value. Number of cores for parallel computing.
Defaults to <code>4</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_group">group</code></td>
<td>
<p>Function. The grouping function.
Defaults to <code>group_func_1</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_func">func</code></td>
<td>
<p>Function. The variable selection function.
Defaults to <code>lasso_msgps_AICc</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_corrfunc">corrfunc</code></td>
<td>
<p>Character value or function. Used to compute associations between
the variables. Defaults to <code>"cor"</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_use.parallel">use.parallel</code></td>
<td>
<p>Boolean. To use parallel computing (doMC) download the extended package from Github.
Set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_b">B</code></td>
<td>
<p>Numerical value. Number of resampled fits of the model.
Defaults to <code>100</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_step.num">step.num</code></td>
<td>
<p>Numerical value. Step value for the c0 sequence.
Defaults to <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_step.limit">step.limit</code></td>
<td>
<p>Defaults to <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_verbose">verbose</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_step.scale">step.scale</code></td>
<td>
<p>Character value. How to compute the c0 sequence if not user-provided:
either &quot;quantile&quot; or &quot;linear&quot;, &quot;zoom_l&quot;, &quot;zoom_q&quot; and &quot;mixed&quot;.
Defaults to <code>"quantile"</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_normalize">normalize</code></td>
<td>
<p>Boolean. Shall the X matrix be centered and scaled?
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_steps.seq">steps.seq</code></td>
<td>
<p>Numeric vector. User provided sequence of c0 values to use.
Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_debug">debug</code></td>
<td>
<p>Boolean value. If more results are required. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fastboost_+3A_version">version</code></td>
<td>
<p>Character value. Passed to the <code>boost.select</code> function.
Defaults to <code>lars</code></p>
</td></tr>
<tr><td><code id="fastboost_+3A_c0lim">c0lim</code></td>
<td>
<p>Boolean. Shall the c0=0 and c0=1 values be used?
Defaults to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="fastboost_+3A_...">...</code></td>
<td>
<p>. Arguments passed to the variable selection function used in <code>boost.apply</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fastboost</code> returns a numeric matrix. For each of the variable (column)
and each of the c0 (row), the entry is proportion of times that the variable was
selected among the B resampled fits of the model. Fitting to the same group of variables is
only perfomed once (even if it occured for another value of c0), which greatly speeds up
the algorithm. In order to limit memory usage, <code>fastboost</code> uses a compact way to
save the group memberships, which is especially useful with community grouping function
and fairly big datasets.
</p>


<h3>Value</h3>

<p>A numeric matrix with attributes.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boost">boost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code>, <code><a href="#topic+plot.selectboost">plot.selectboost</a></code>
</p>
<p>Other Selectboost functions: 
<code><a href="#topic+autoboost">autoboost</a>()</code>,
<code><a href="#topic+boost">boost</a></code>,
<code><a href="#topic+plot_selectboost_cascade">plot_selectboost_cascade</a></code>,
<code><a href="#topic+selectboost_cascade">selectboost_cascade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(75),15,5)
ybin=sample(0:1,15,replace=TRUE)
yran=rnorm(15)
set.seed(314)
#For quick test purpose, not meaningful, should be run with greater value of B
#and disabling parallel computing as well
res.fastboost &lt;- fastboost(xran,yran,B=3,use.parallel=FALSE)


fastboost(xran,yran)
#Customize resampling levels
fastboost(xran,yran,steps.seq=c(.99,.95,.9),c0lim=FALSE)
fastboost(xran,yran,step.scale="mixed",c0lim=TRUE)
fastboost(xran,yran,step.scale="zoom_l",c0lim=FALSE)
fastboost(xran,yran,step.scale="zoom_l",step.num = c(1,.9,.01),c0lim=FALSE)
fastboost(xran,yran,step.scale="zoom_q",c0lim=FALSE)
fastboost(xran,yran,step.scale="linear",c0lim=TRUE)
fastboost(xran,yran,step.scale="quantile",c0lim=TRUE)

#Binary logistic regression
fastboost(xran,ybin,func=lasso_cv_glmnet_bin_min)


</code></pre>

<hr>
<h2 id='fastboost.res.x'>Fastboost lasso diabetes first order.</h2><span id='topic+fastboost.res.x'></span>

<h3>Description</h3>

<p>Result of fastboost analysis of diabetes data from <cite>lars</cite> package with lasso
and first order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastboost.res.x
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 10 variables with attributes.
</p>

<hr>
<h2 id='fastboost.res.x.adapt'>Fastboost adaptative lasso diabetes first order.</h2><span id='topic+fastboost.res.x.adapt'></span>

<h3>Description</h3>

<p>Result of fastboost analysis of diabetes data from <cite>lars</cite> package with adaptative
lasso and first order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastboost.res.x.adapt
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 10 variables with attributes.
</p>

<hr>
<h2 id='fastboost.res.x2'>Fastboost lasso diabetes second order.</h2><span id='topic+fastboost.res.x2'></span>

<h3>Description</h3>

<p>Result of fastboost analysis of diabetes data from <cite>lars</cite> package with lasso
and second order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastboost.res.x2
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 64 variables with attributes.
</p>

<hr>
<h2 id='fastboost.res.x2.adapt'>Fastboost adaptative lasso diabetes second order.</h2><span id='topic+fastboost.res.x2.adapt'></span>

<h3>Description</h3>

<p>Result of fastboost analysis of diabetes data from <cite>lars</cite> package with adaptative
lasso and second order model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastboost.res.x2.adapt
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 13 rows and 64 variables with attributes.
</p>

<hr>
<h2 id='force.non.inc'>Non increasing post processinng step for selectboost analysis</h2><span id='topic+force.non.inc'></span>

<h3>Description</h3>

<p>Post processes a selectboost analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>force.non.inc(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="force.non.inc_+3A_object">object</code></td>
<td>
<p>Numerical matrix. Result of selectboost (autoboost, fastboost, ...).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>force.non.inc</code> returns a vector after ensuring that the proportion of times each variable was
selected is non increasing with respect to the 1-c0 value.
</p>


<h3>Value</h3>

<p>A matrix with the results.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code>
</p>
<p>Other Selectboost analyse functions: 
<code><a href="#topic+plot.selectboost">plot.selectboost</a>()</code>,
<code><a href="#topic+summary.selectboost">summary.selectboost</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(autoboost.res.x)
res.fastboost.force.non.inc &lt;- force.non.inc(autoboost.res.x)

</code></pre>

<hr>
<h2 id='group_func_1'>Generate groups by thresholding.</h2><span id='topic+group_func_1'></span>

<h3>Description</h3>

<p><code>group_func_1</code> creates groups of variables based on thresholding the input matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>group_func_1(absXcor, c0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="group_func_1_+3A_absxcor">absXcor</code></td>
<td>
<p>A numeric matrix. The absolute value of a correlation or distance matrix.</p>
</td></tr>
<tr><td><code id="group_func_1_+3A_c0">c0</code></td>
<td>
<p>A numeric scalar. The thresholding</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a function used to create a list of groups using an input matrix and a
thresholding value c0. A group is made, for every column in the input matrix.
</p>


<h3>Value</h3>

<p>A list with one entry: the list of groups.
Attributes:
</p>

<ul>
<li><p> &quot;type&quot;: &quot;normal&quot;
</p>
</li>
<li><p> &quot;length.groups&quot; the length of each groups.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+group_func_2">group_func_2</a></code> and <code><a href="#topic+boost.findgroups">boost.findgroups</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
group_func_1(cor(matrix(rnorm(50),10,5)),.4)

</code></pre>

<hr>
<h2 id='group_func_2'>Generate groups using community analysis.</h2><span id='topic+group_func_2'></span>

<h3>Description</h3>

<p><code>group_func_2</code> creates groups of variables based on community analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>group_func_2(absXcor, c0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="group_func_2_+3A_absxcor">absXcor</code></td>
<td>
<p>A numeric matrix. The absolute value of a correlation or distance matrix.</p>
</td></tr>
<tr><td><code id="group_func_2_+3A_c0">c0</code></td>
<td>
<p>A numeric scalar. The thresholding</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a function used to create a list of groups using an input matrix and a
thresholding value c0. A group is made, for every column in the input matrix.
It uses the <code>infomap.community</code> function of the <code>igraph</code> package.
</p>


<h3>Value</h3>

<p>A list with one entry: the list of groups.
Attributes:
</p>

<ul>
<li><p> &quot;type&quot;: &quot;normal&quot;
</p>
</li>
<li><p> &quot;length.groups&quot; the length of each groups.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+group_func_2">group_func_2</a></code> <code><a href="#topic+boost.findgroups">boost.findgroups</a></code>, <code><a href="igraph.html#topic+infomap.community">infomap.community</a></code> and <code><a href="igraph.html#topic+igraph">igraph</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
group_func_2(cor(matrix(rnorm(100),10,10)),.5)

</code></pre>

<hr>
<h2 id='miscplot'>Miscellaneous plot functions</h2><span id='topic+miscplot'></span><span id='topic+plot.matrix'></span>

<h3>Description</h3>

<p>Define some additional plot functions to be used in the demos of the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="miscplot_+3A_x">x</code></td>
<td>
<p>A numeric matrix. A matrix to be plotted.</p>
</td></tr>
<tr><td><code id="miscplot_+3A_...">...</code></td>
<td>
<p>. Additionnal arguments passed to the plot function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>matrixplot</code> plots a numeric matrix <code>x</code>.
</p>


<h3>Value</h3>

<p><code>matrixplot</code> returns <code>1</code>.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a> with contributions from Nicolas Jung.
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(3141)
randmat=matrix(rnorm(360),60,60)
plot(randmat)

</code></pre>

<hr>
<h2 id='network.confidence-class'>Network confidence class.</h2><span id='topic+network.confidence-class'></span>

<h3>Description</h3>

<p>Some details about this class and my plans for it in the body.
</p>


<h3>Details</h3>


<dl>
<dt>network.confidence</dt><dd><p>Matrix of confidence indices.</p>
</dd>
<dt>name</dt><dd><p>Vector.</p>
</dd>
<dt>array</dt><dd><p>F array</p>
</dd>
<dt>time_pt</dt><dd><p>Vector</p>
</dd>
<dt>cv.subjects</dt><dd><p>Logical. Was crossvalidation carried out subjectwise?</p>
</dd>
</dl>


<hr>
<h2 id='plot_selectboost_cascade'>plot_Selectboost_cascade</h2><span id='topic+plot_selectboost_cascade'></span><span id='topic+plot+2Cnetwork.confidence+2CANY-method'></span><span id='topic+plot+2Cnetwork.confidence+2Cnetwork.confidence-method'></span>

<h3>Description</h3>

<p>Plot result of Selectboost for Cascade inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'network.confidence,ANY'
plot(x, col = gray((1:99)/100, alpha = NULL), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_selectboost_cascade_+3A_x">x</code></td>
<td>
<p>A <code>network.confidence</code> object to be plotted.</p>
</td></tr>
<tr><td><code id="plot_selectboost_cascade_+3A_col">col</code></td>
<td>
<p>Colors for the plot.</p>
</td></tr>
<tr><td><code id="plot_selectboost_cascade_+3A_...">...</code></td>
<td>
<p>Additionnal arguments passed to the heatmap function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extending results from the Cascade package: providing confidence indices for the reverse engineered links.
</p>
<p>Reference for the Cascade modelling
Vallat, L., Kemper, C. a., Jung, N., Maumy-Bertrand, M., Bertrand, F.,
Meyer, N., Pocheville, A., Fisher, J. W., Gribben, J. G. et Bahram, S.
(2013). Reverse-engineering the genetic circuitry of a cancer cell with predicted
intervention in chronic lymphocytic leukemia. Proceedings of the National
Academy of Sciences of the United States of America, 110(2), 459-64.
</p>
<p>Reference for the Cascade package
Jung, N., Bertrand, F., Bahram, S., Vallat, L. et Maumy-Bertrand, M. (2014).
Cascade : A R package to study, predict and simulate the diffusion of a signal
through a temporal gene network. Bioinformatics. ISSN 13674803..
</p>


<h3>Value</h3>

<p>Nothing.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boost">boost</a></code>, <code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+selectboost">selectboost</a></code>, <code><a href="Cascade.html#topic+inference">inference</a></code>
</p>
<p>Other Selectboost functions: 
<code><a href="#topic+autoboost">autoboost</a>()</code>,
<code><a href="#topic+boost">boost</a></code>,
<code><a href="#topic+fastboost">fastboost</a>()</code>,
<code><a href="#topic+selectboost_cascade">selectboost_cascade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(net_confidences)
plot(net_confidence)
plot(net_confidence_.5)
plot(net_confidence_thr)

</code></pre>

<hr>
<h2 id='plot.selectboost'>Plot selectboost object</h2><span id='topic+plot.selectboost'></span>

<h3>Description</h3>

<p>Plot a selectboostboost object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'selectboost'
plot(
  x,
  verbose = FALSE,
  prop.level = 0.95,
  conf.int.level = 0.95,
  conf.threshold = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.selectboost_+3A_x">x</code></td>
<td>
<p>Numerical matrix. Result of selectboost (autoboost, fastboost, ...).</p>
</td></tr>
<tr><td><code id="plot.selectboost_+3A_verbose">verbose</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.selectboost_+3A_prop.level">prop.level</code></td>
<td>
<p>Numeric value. Used to compute the proportion of selection is
greater than prop.level. Defaults to <code>.95</code>.</p>
</td></tr>
<tr><td><code id="plot.selectboost_+3A_conf.int.level">conf.int.level</code></td>
<td>
<p>Numeric value. Confidence level for confidence intervals on estimated
proportions of selection. Defaults to <code>.95</code>.</p>
</td></tr>
<tr><td><code id="plot.selectboost_+3A_conf.threshold">conf.threshold</code></td>
<td>
<p>Numeric value. Used to compute the number of steps (c0) for which
the proportion of selection remains greater than conf.threshold. Defaults to <code>.95</code>.</p>
</td></tr>
<tr><td><code id="plot.selectboost_+3A_...">...</code></td>
<td>
<p>. Passed to the plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.selectboost</code> returns an invisible list and creates four graphics.
Two plots the proportion of selection with respect to c0 (by step or according to real scale).
On the third graph, no bar means a proportion of selection less than prop.level.
Confidence intervals are computed at the conf.int.level level.
Barplot of the confidence index (1-min(c0, such that proportion|c0&gt;conf.threshold)).
</p>


<h3>Value</h3>

<p>An invisible list.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code>
</p>
<p>Other Selectboost analyse functions: 
<code><a href="#topic+force.non.inc">force.non.inc</a>()</code>,
<code><a href="#topic+summary.selectboost">summary.selectboost</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(75),15,5)
ybin=sample(0:1,15,replace=TRUE)
yran=rnorm(15)
layout(matrix(1:4,2,2))

data(autoboost.res.x)
plot(autoboost.res.x)

data(autoboost.res.x2)
plot(autoboost.res.x2)

</code></pre>

<hr>
<h2 id='plot.summary.selectboost'>Plot a summary of selectboost results</h2><span id='topic+plot.summary.selectboost'></span>

<h3>Description</h3>

<p>Plot a summary of selectboost results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.selectboost'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.selectboost_+3A_x">x</code></td>
<td>
<p>Numerical matrix. Summary of selectboost object.</p>
</td></tr>
<tr><td><code id="plot.summary.selectboost_+3A_...">...</code></td>
<td>
<p>. Passed to the plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.summary.selectboost</code> returns an invisible list and creates four graphics.
Two plots the proportion of selection with respect to c0 (by step or according to real scale).
On the third graph, no bar means a proportion of selection less than prop.level.
Confidence intervals are computed at the conf.int.level level.
Barplot of the confidence index (1-min(c0, such that proportion|c0&gt;conf.threshold)).
</p>


<h3>Value</h3>

<p>An invisible list.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code> and <code><a href="#topic+summary.selectboost">summary.selectboost</a></code>
</p>
<p>Other Selectboost analyze functions: 
<code><a href="#topic+auto.analyze">auto.analyze</a>()</code>,
<code><a href="#topic+trajC0">trajC0</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(autoboost.res.x)
plot(summary(autoboost.res.x))

data(autoboost.res.x2)
plot(summary(autoboost.res.x2))

</code></pre>

<hr>
<h2 id='results_simuls_reverse_engineering_v3'>Simulations for reverse-engineering</h2><span id='topic+results_simuls_reverse_engineering_v3'></span><span id='topic+test.seq_C'></span><span id='topic+test.seq_PL'></span><span id='topic+test.seq_PL2'></span><span id='topic+test.seq_PL2_W'></span><span id='topic+test.seq_PL2_tW'></span><span id='topic+test.seq_PSel'></span><span id='topic+test.seq_PSel.5'></span><span id='topic+test.seq_PSel.e2'></span><span id='topic+test.seq_PSel.5.e2'></span><span id='topic+test.seq_PSel_W'></span><span id='topic+test.seq_robust'></span><span id='topic+test.seq_PB'></span><span id='topic+test.seq_PB_095_075'></span><span id='topic+test.seq_PB_075_075'></span><span id='topic+test.seq_PB_W'></span><span id='topic+sensitivity_C'></span><span id='topic+sensitivity_PL'></span><span id='topic+sensitivity_PL2'></span><span id='topic+sensitivity_PL2_W'></span><span id='topic+sensitivity_PL2_tW'></span><span id='topic+sensitivity_PSel'></span><span id='topic+sensitivity_PSel.5'></span><span id='topic+sensitivity_PSel.e2'></span><span id='topic+sensitivity_PSel.5.e2'></span><span id='topic+sensitivity_PSel_W'></span><span id='topic+sensitivity_robust'></span><span id='topic+sensitivity_PB'></span><span id='topic+sensitivity_PB_095_075'></span><span id='topic+sensitivity_PB_075_075'></span><span id='topic+sensitivity_PB_W'></span><span id='topic+predictive_positive_value_C'></span><span id='topic+predictive_positive_value_PL'></span><span id='topic+predictive_positive_value_PL2'></span><span id='topic+predictive_positive_value_PL2_W'></span><span id='topic+predictive_positive_value_PL2_tW'></span><span id='topic+predictive_positive_value_PSel'></span><span id='topic+predictive_positive_value_PSel.5'></span><span id='topic+predictive_positive_value_PSel.e2'></span><span id='topic+predictive_positive_value_PSel.5.e2'></span><span id='topic+predictive_positive_value_PSel_W'></span><span id='topic+predictive_positive_value_robust'></span><span id='topic+predictive_positive_value_PB'></span><span id='topic+predictive_positive_value_PB_095_075'></span><span id='topic+predictive_positive_value_PB_075_075'></span><span id='topic+predictive_positive_value_PB_W'></span><span id='topic+F_score_C'></span><span id='topic+F_score_PL'></span><span id='topic+F_score_PL2'></span><span id='topic+F_score_PL2_W'></span><span id='topic+F_score_PL2_tW'></span><span id='topic+F_score_PSel'></span><span id='topic+F_score_PSel.5'></span><span id='topic+F_score_PSel.e2'></span><span id='topic+F_score_PSel.5.e2'></span><span id='topic+F_score_PSel_W'></span><span id='topic+F_score_robust'></span><span id='topic+F_score_PB'></span><span id='topic+F_score_PB_095_075'></span><span id='topic+F_score_PB_075_075'></span><span id='topic+F_score_PB_W'></span><span id='topic+nv_C'></span><span id='topic+nv_PL'></span><span id='topic+nv_PL2'></span><span id='topic+nv_PL2_W'></span><span id='topic+nv_PL2_tW'></span><span id='topic+nv_PSel'></span><span id='topic+nv_PSel.5'></span><span id='topic+nv_PSel.e2'></span><span id='topic+nv_PSel.5.e2'></span><span id='topic+nv_PSel_W'></span><span id='topic+nv_robust'></span><span id='topic+nv_PB'></span><span id='topic+nv_PB_095_075'></span><span id='topic+nv_PB_075_075'></span><span id='topic+nv_PB_W'></span>

<h3>Description</h3>

<p>Result of fastboost analysis applied to biological network reverse engineering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.seq_C

test.seq_PL

test.seq_PL2

test.seq_PL2_W

test.seq_PL2_tW

test.seq_PSel

test.seq_PSel.5

test.seq_PSel.e2

test.seq_PSel.5.e2

test.seq_PSel_W

test.seq_robust

test.seq_PB

test.seq_PB_095_075

test.seq_PB_075_075

test.seq_PB_W

sensitivity_C

sensitivity_PL

sensitivity_PL2

sensitivity_PL2_W

sensitivity_PL2_tW

sensitivity_PSel

sensitivity_PSel.5

sensitivity_PSel.e2

sensitivity_PSel.5.e2

sensitivity_PSel_W

sensitivity_robust

sensitivity_PB

sensitivity_PB_095_075

sensitivity_PB_075_075

sensitivity_PB_W

predictive_positive_value_C

predictive_positive_value_PL

predictive_positive_value_PL2

predictive_positive_value_PL2_W

predictive_positive_value_PL2_tW

predictive_positive_value_PSel

predictive_positive_value_PSel.5

predictive_positive_value_PSel.e2

predictive_positive_value_PSel.5.e2

predictive_positive_value_PSel_W

predictive_positive_value_robust

predictive_positive_value_PB

predictive_positive_value_PB_095_075

predictive_positive_value_PB_075_075

predictive_positive_value_PB_W

F_score_C

F_score_PL

F_score_PL2

F_score_PL2_W

F_score_PL2_tW

F_score_PSel

F_score_PSel.5

F_score_PSel.e2

F_score_PSel.5.e2

F_score_PSel_W

F_score_robust

F_score_PB

F_score_PB_095_075

F_score_PB_075_075

F_score_PB_W

nv_C

nv_PL

nv_PL2

nv_PL2_W

nv_PL2_tW

nv_PSel

nv_PSel.5

nv_PSel.e2

nv_PSel.5.e2

nv_PSel_W

nv_robust

nv_PB

nv_PB_095_075

nv_PB_075_075

nv_PB_W
</code></pre>


<h3>Format</h3>

<p>A numerical matrix frame with 100 rows and 200 variables or a numerical vector of length 100.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 100 rows and 200 columns.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>
<p>An object of class <code>numeric</code> of length 100.
</p>

<hr>
<h2 id='SelectBoost'>SelectBoost</h2><span id='topic+SelectBoost'></span>

<h3>Description</h3>

<p>Motivation: With the growth of big data, variable selection has become one of the major
challenges in statistics. Although many methods have been proposed in the literature their
performance in terms of recall and precision are limited in a context where the number of
variables by far exceeds the number of observations or in a high correlated setting.
Results: This package implements a new general algorithm which improves the precision of any
existing variable selection method. This algorithm is based on highly intensive simulations and
takes into account the correlation structure of the data. Our algorithm can either produce a
confidence index for variable selection or it can be used in an experimental design planning
perspective.
</p>


<h3>References</h3>

<p>F. Bertrand, I. Aouadi, N. Jung, R. Carapito, L. Vallat, S. Bahram, M. Maumy-Bertrand (2020). SelectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets, <em>Bioinformatics</em>. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>
<p>SelectBoost was used to decypher networks in
C. Schleiss, [...], M. Maumy-Bertrand, S. Bahram, F. Bertrand, and L. Vallat. (2021). Temporal multiomic modelling reveals a B-cell receptor proliferative program in chronic lymphocytic leukemia. <em>Leukemia</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(75),15,5)
ybin=sample(0:1,15,replace=TRUE)
yran=rnorm(15)

#For quick test purpose, not meaningful, should be run with greater value of B
#(disabling parallel computing as well)
res.fastboost &lt;- fastboost(xran,yran,B=3,use.parallel=FALSE)


fastboost(xran,yran)
#Customize resampling levels
fastboost(xran,yran,steps.seq=c(.99,.95,.9),c0lim=FALSE)

#Binary logistic regression
fastboost(xran,ybin,func=lasso_cv_glmnet_bin_min)

</code></pre>

<hr>
<h2 id='selectboost_cascade'>Selectboost_cascade</h2><span id='topic+selectboost_cascade'></span><span id='topic+selectboost'></span><span id='topic+selectboost+2Cmicro_array-method'></span><span id='topic+selectboost+2Cmicro_array+2Cmicro_array-method'></span>

<h3>Description</h3>

<p>Selectboost for Cascade inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectboost(M, ...)

## S4 method for signature 'micro_array'
selectboost(
  M,
  Fabhat,
  K = 5,
  eps = 10^-5,
  cv.subjects = TRUE,
  ncores = 4,
  use.parallel = FALSE,
  verbose = FALSE,
  group = group_func_2,
  c0value = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectboost_cascade_+3A_m">M</code></td>
<td>
<p>Microarray class from the Cascade package.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_...">...</code></td>
<td>
<p>Additionnal arguments. Not used.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_fabhat">Fabhat</code></td>
<td>
<p>F matrix inferred using the inference function from the Cascade package.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_k">K</code></td>
<td>
<p>Number of crossvalidation folds.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_eps">eps</code></td>
<td>
<p>Threshold for assinging a zero value to an inferred parameter. Defaults to 10^-5.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_cv.subjects">cv.subjects</code></td>
<td>
<p>Crossvalidation is made subjectwise using leave one out. Discards the K option.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_ncores">ncores</code></td>
<td>
<p>Numerical value. Number of cores for parallel computing.
Defaults to <code>4</code>.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_use.parallel">use.parallel</code></td>
<td>
<p>Boolean. To use parallel computing (doMC) download the extended package from Github.
Set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_verbose">verbose</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_group">group</code></td>
<td>
<p>Function. The grouping function.
Defaults to <code>group_func_2</code>.</p>
</td></tr>
<tr><td><code id="selectboost_cascade_+3A_c0value">c0value</code></td>
<td>
<p>Numeric. c0 value to use for confidence computation.
Defaults to <code>TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extending results from the Cascade package: providing confidence indices for the reverse engineered links.
</p>
<p>Reference for the Cascade modelling
Vallat, L., Kemper, C. a., Jung, N., Maumy-Bertrand, M., Bertrand, F.,
Meyer, N., Pocheville, A., Fisher, J. W., Gribben, J. G. et Bahram, S.
(2013). Reverse-engineering the genetic circuitry of a cancer cell with predicted
intervention in chronic lymphocytic leukemia. Proceedings of the National
Academy of Sciences of the United States of America, 110(2), 459-64.
</p>
<p>Reference for the Cascade package
Jung, N., Bertrand, F., Bahram, S., Vallat, L. et Maumy-Bertrand, M. (2014).
Cascade : A R package to study, predict and simulate the diffusion of a signal
through a temporal gene network. Bioinformatics. ISSN 13674803..
</p>


<h3>Value</h3>

<p>A <code>network.confidence</code> object.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boost">boost</a></code>, <code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+plot.selectboost">plot.selectboost</a></code>, <code><a href="Cascade.html#topic+inference">inference</a></code>
</p>
<p>Other Selectboost functions: 
<code><a href="#topic+autoboost">autoboost</a>()</code>,
<code><a href="#topic+boost">boost</a></code>,
<code><a href="#topic+fastboost">fastboost</a>()</code>,
<code><a href="#topic+plot_selectboost_cascade">plot_selectboost_cascade</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
set.seed(314)


data(Cascade_example)
Fab_inf_C &lt;- Net_inf_C@F
#By default community grouping of variables
set.seed(1)
net_confidence &lt;- selectboost(M, Fab_inf_C)
net_confidence_.5 &lt;- selectboost(M, Fab_inf_C, c0value = .5)
#With group_func_1, variables are grouped by thresholding the correlation matrix
net_confidence_thr &lt;- selectboost(M, Fab_inf_C, group = group_func_1)


</code></pre>

<hr>
<h2 id='simulation'>Miscellaneous simulation functions</h2><span id='topic+simulation'></span><span id='topic+simulation_cor'></span><span id='topic+simulation_X'></span><span id='topic+simulation_DATA'></span><span id='topic+compsim'></span><span id='topic+compsim.simuls'></span>

<h3>Description</h3>

<p>Define several simulation functions to be used in the demos of the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulation_cor(group, cor_group, v = 1)

simulation_X(N, Cor)

simulation_DATA(X, supp, minB, maxB, stn)

compsim(x, ...)

## S3 method for class 'simuls'
compsim(x, result.boost, level = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulation_+3A_group">group</code></td>
<td>
<p>A numeric vector. Group membership of each of the variables.</p>
</td></tr>
<tr><td><code id="simulation_+3A_cor_group">cor_group</code></td>
<td>
<p>A numeric vector. Intra-group Pearson correlation.</p>
</td></tr>
<tr><td><code id="simulation_+3A_v">v</code></td>
<td>
<p>A numeric value. The diagonal value of the generated matrix.</p>
</td></tr>
<tr><td><code id="simulation_+3A_n">N</code></td>
<td>
<p>A numeric value. The number of observations.</p>
</td></tr>
<tr><td><code id="simulation_+3A_cor">Cor</code></td>
<td>
<p>A numeric matrix. A correlation matrix to be used for random sampling.</p>
</td></tr>
<tr><td><code id="simulation_+3A_x">X</code></td>
<td>
<p>A numeric matrix. Observations*variables.</p>
</td></tr>
<tr><td><code id="simulation_+3A_supp">supp</code></td>
<td>
<p>A numeric vector. The true predictors.</p>
</td></tr>
<tr><td><code id="simulation_+3A_minb">minB</code></td>
<td>
<p>A numeric value. Minimum absolute value for a beta coefficient.</p>
</td></tr>
<tr><td><code id="simulation_+3A_maxb">maxB</code></td>
<td>
<p>A numeric value. Maximum absolute value for a beta coefficient.</p>
</td></tr>
<tr><td><code id="simulation_+3A_stn">stn</code></td>
<td>
<p>A numeric value. A scaling factor for the noise in the response. The higher, the smaller the noise.</p>
</td></tr>
<tr><td><code id="simulation_+3A_x">x</code></td>
<td>
<p>List. Simulated dataset.</p>
</td></tr>
<tr><td><code id="simulation_+3A_...">...</code></td>
<td>
<p>For compatibility issues.</p>
</td></tr>
<tr><td><code id="simulation_+3A_result.boost">result.boost</code></td>
<td>
<p>Row matrix of numerical value. Result of selecboost for a given c0.</p>
</td></tr>
<tr><td><code id="simulation_+3A_level">level</code></td>
<td>
<p>List. Threshold for proportions of selected variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>simulation_cor</code> returns a numeric symetric matrix c whose order
is the number of variables. An entry <code class="reqn">c_{i,j}</code> is equal to
</p>

<ul>
<li> <p><code class="reqn">i=j</code>, entries on the diagonal are equal to the v value
</p>
</li>
<li> <p><code class="reqn">i&lt;&gt;j</code>, 0 if the variable i and j do not belong to the same group
</p>
</li>
<li> <p><code class="reqn">i&lt;&gt;j</code>, <code>cor_group[k]</code> if the variable i and j belong to the group k
</p>
</li></ul>

<p><code>simulation_X</code> returns a numeric matrix of replicates (by row) of
random samples generated according to the Cor matrix.
</p>
<p><code>simulation_DATA</code> returns a list with the X matrix, the response vector Y,
the true predictors, the beta coefficients, the scaling factor and the standard deviation.
</p>
<p><code>compsim.simuls</code> computes recall (sensitivity), precision (positive predictive value), and several Fscores (non-weighted Fscore, F1/2 and F2 weighted Fscores).
</p>


<h3>Value</h3>

<p><code>simulation_cor</code> returns a numeric matrix.
</p>
<p><code>simulation_X</code> returns a numeric matrix.
</p>
<p><code>simulation_DATA</code> returns a list.
</p>
<p><code>compsim.simuls</code> returns a numerical vector.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a> with contributions from Nicolas Jung.
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code>, <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>, <code><a href="#topic+AICc_BIC_glmnetB">AICc_BIC_glmnetB</a></code>, <code><a href="lars.html#topic+lars">lars</a></code>, <code><a href="lars.html#topic+cv.lars">cv.lars</a></code>, <code><a href="msgps.html#topic+msgps">msgps</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N&lt;-10
group&lt;-c(rep(1:2,5))
cor_group&lt;-c(.8,.4)
supp&lt;-c(1,1,1,0,0,0,0,0,0,0)
minB&lt;-1
maxB&lt;-2
stn&lt;-5
C&lt;-simulation_cor(group,cor_group)

set.seed(314)
X&lt;-simulation_X(10,C)
G&lt;-abs(cor(X))
hist(G[lower.tri(G)])

set.seed(314)
DATA_exemple&lt;-simulation_DATA(X,supp,1,2,stn)

set.seed(314)
result.boost = fastboost(DATA_exemple$X, DATA_exemple$Y, steps.seq = .7, c0lim = FALSE,
use.parallel = FALSE, B=10)
compsim(DATA_exemple, result.boost, level=.7)

</code></pre>

<hr>
<h2 id='summary.selectboost'>Summarize a selectboost analysis</h2><span id='topic+summary.selectboost'></span>

<h3>Description</h3>

<p>Summarize a selectboost analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'selectboost'
summary(
  object,
  crit.func = mean,
  crit.int = "mean",
  custom.values.lim = NULL,
  index.lim = NULL,
  alpha.conf.level = 0.99,
  force.dec = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.selectboost_+3A_object">object</code></td>
<td>
<p>Numerical matrix. Result of selectboost (autoboost, fastboost, ...).</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_crit.func">crit.func</code></td>
<td>
<p>Function . Defaults to the <code>mean</code> function.</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_crit.int">crit.int</code></td>
<td>
<p>Character value. Mean or median based confidence intervals. Defaults to <code>"mean"</code> based confidence intervals.</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_custom.values.lim">custom.values.lim</code></td>
<td>
<p>Vector of numeric values. Defults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_index.lim">index.lim</code></td>
<td>
<p>Vector of numeric values. Defults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_alpha.conf.level">alpha.conf.level</code></td>
<td>
<p>Numeric value. Defults to <code>0.99</code>.</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_force.dec">force.dec</code></td>
<td>
<p>Boolean. Force trajectories to be non-increasing.</p>
</td></tr>
<tr><td><code id="summary.selectboost_+3A_...">...</code></td>
<td>
<p>Additionnal arguments. Passed to the <code>crit.func</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary.selectboost</code> returns a list with the results.
</p>


<h3>Value</h3>

<p>A list with the results.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code>
</p>
<p>Other Selectboost analyse functions: 
<code><a href="#topic+force.non.inc">force.non.inc</a>()</code>,
<code><a href="#topic+plot.selectboost">plot.selectboost</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(autoboost.res.x)
summary(autoboost.res.x)
summary(autoboost.res.x, force.dec=FALSE)

data(autoboost.res.x.adapt)
summary(autoboost.res.x.adapt)

data(autoboost.res.x2)
summary(autoboost.res.x2)
summary(autoboost.res.x2, force.dec=FALSE)

data(autoboost.res.x2.adapt)
summary(autoboost.res.x2.adapt)

data(fastboost.res.x)
summary(fastboost.res.x)
summary(fastboost.res.x, force.dec=FALSE)

data(fastboost.res.x.adapt)
summary(fastboost.res.x.adapt)

data(fastboost.res.x2)
summary(fastboost.res.x2)
summary(fastboost.res.x2, force.dec=FALSE)

data(fastboost.res.x2.adapt)
summary(fastboost.res.x2.adapt)
</code></pre>

<hr>
<h2 id='trajC0'>Plot trajectories</h2><span id='topic+trajC0'></span><span id='topic+trajC0.selectboost'></span>

<h3>Description</h3>

<p>Plot trajectories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trajC0(x, ...)

## S3 method for class 'selectboost'
trajC0(
  x,
  summary.selectboost.res,
  lasso.coef.path,
  type.x.axis = "noscale",
  type.graph = "boost",
  threshold.level = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trajC0_+3A_x">x</code></td>
<td>
<p>Numerical matrix. Selectboost object.</p>
</td></tr>
<tr><td><code id="trajC0_+3A_...">...</code></td>
<td>
<p>. Passed to the plotting functions.</p>
</td></tr>
<tr><td><code id="trajC0_+3A_summary.selectboost.res">summary.selectboost.res</code></td>
<td>
<p>List. Summary of selectboost object.</p>
</td></tr>
<tr><td><code id="trajC0_+3A_lasso.coef.path">lasso.coef.path</code></td>
<td>
<p>List. Result of <code>predict.lars</code>.</p>
</td></tr>
<tr><td><code id="trajC0_+3A_type.x.axis">type.x.axis</code></td>
<td>
<p>Character value. &quot;scale&quot; or &quot;noscale&quot; for the X axis.</p>
</td></tr>
<tr><td><code id="trajC0_+3A_type.graph">type.graph</code></td>
<td>
<p>Character value. Type of graphs: &quot;bars&quot;, &quot;lasso&quot; and &quot;boost&quot;.</p>
</td></tr>
<tr><td><code id="trajC0_+3A_threshold.level">threshold.level</code></td>
<td>
<p>Numeric value. Threshold for the graphs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>trajC0</code> returns an invisible list and creates four graphics.
</p>


<h3>Value</h3>

<p>An invisible list.
</p>
<p>invisible list.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fastboost">fastboost</a></code>, <code><a href="#topic+autoboost">autoboost</a></code> and <code><a href="#topic+summary.selectboost">summary.selectboost</a></code>
</p>
<p>Other Selectboost analyze functions: 
<code><a href="#topic+auto.analyze">auto.analyze</a>()</code>,
<code><a href="#topic+plot.summary.selectboost">plot.summary.selectboost</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(autoboost.res.x)
data(diabetes, package="lars")

### With lasso trajectories
m.x&lt;-lars::lars(diabetes$x,diabetes$y)
plot(m.x)
mm.x&lt;-predict(m.x,type="coef",mode="lambda")
autoboost.res.x.mean = summary(autoboost.res.x)

par(mfrow=c(2,2),mar=c(4,4,1,1))
trajC0(autoboost.res.x,autoboost.res.x.mean,lasso.coef.path=mm.x,type.graph="lasso")
trajC0(autoboost.res.x,autoboost.res.x.mean)
trajC0(autoboost.res.x,autoboost.res.x.mean,type.graph="bars")
trajC0(autoboost.res.x,autoboost.res.x.mean,type.x.axis ="scale")

</code></pre>

<hr>
<h2 id='var_select'>Variable selection functions</h2><span id='topic+var_select'></span><span id='topic+lasso_cv_glmnet_bin_min'></span><span id='topic+lasso_cv_glmnet_bin_1se'></span><span id='topic+lasso_glmnet_bin_AICc'></span><span id='topic+lasso_glmnet_bin_BIC'></span><span id='topic+lasso_cv_lars_min'></span><span id='topic+lasso_cv_lars_1se'></span><span id='topic+lasso_cv_glmnet_min'></span><span id='topic+lasso_cv_glmnet_min_weighted'></span><span id='topic+lasso_cv_glmnet_1se'></span><span id='topic+lasso_cv_glmnet_1se_weighted'></span><span id='topic+lasso_msgps_Cp'></span><span id='topic+lasso_msgps_AICc'></span><span id='topic+lasso_msgps_GCV'></span><span id='topic+lasso_msgps_BIC'></span><span id='topic+enetf_msgps_Cp'></span><span id='topic+enetf_msgps_AICc'></span><span id='topic+enetf_msgps_GCV'></span><span id='topic+enetf_msgps_BIC'></span><span id='topic+lasso_cascade'></span>

<h3>Description</h3>

<p>Compute coefficient vector after variable selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso_cv_glmnet_bin_min(X, Y)

lasso_cv_glmnet_bin_1se(X, Y)

lasso_glmnet_bin_AICc(X, Y)

lasso_glmnet_bin_BIC(X, Y)

lasso_cv_lars_min(X, Y)

lasso_cv_lars_1se(X, Y)

lasso_cv_glmnet_min(X, Y)

lasso_cv_glmnet_min_weighted(X, Y, priors)

lasso_cv_glmnet_1se(X, Y)

lasso_cv_glmnet_1se_weighted(X, Y, priors)

lasso_msgps_Cp(X, Y, penalty = "enet")

lasso_msgps_AICc(X, Y, penalty = "enet")

lasso_msgps_GCV(X, Y, penalty = "enet")

lasso_msgps_BIC(X, Y, penalty = "enet")

enetf_msgps_Cp(X, Y, penalty = "enet", alpha = 0.5)

enetf_msgps_AICc(X, Y, penalty = "enet", alpha = 0.5)

enetf_msgps_GCV(X, Y, penalty = "enet", alpha = 0.5)

enetf_msgps_BIC(X, Y, penalty = "enet", alpha = 0.5)

lasso_cascade(M, Y, K, eps = 10^-5, cv.fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_select_+3A_x">X</code></td>
<td>
<p>A numeric matrix. The predictors matrix.</p>
</td></tr>
<tr><td><code id="var_select_+3A_y">Y</code></td>
<td>
<p>A binary factor. The 0/1 classification response.</p>
</td></tr>
<tr><td><code id="var_select_+3A_priors">priors</code></td>
<td>
<p>A numeric vector. Weighting vector for the variable selection. When used with the <code>glmnet</code> estimation function, the weights share the following meanings:
</p>

<ul>
<li><p> 0: the variable is always included in the model
</p>
</li>
<li><p> 1: neutral weight
</p>
</li>
<li><p> Inf: variable is always excluded from the model
</p>
</li></ul>
</td></tr>
<tr><td><code id="var_select_+3A_penalty">penalty</code></td>
<td>
<p>A character value to select the penalty term in msgps
(Model Selection Criteria via Generalized Path Seeking). Defaults to &quot;enet&quot;.
&quot;genet&quot; is the generalized elastic net and &quot;alasso&quot; is the adaptive lasso,
which is a weighted version of the lasso.</p>
</td></tr>
<tr><td><code id="var_select_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to set the value of <code class="reqn">\alpha</code> on &quot;enet&quot; and &quot;genet&quot; penalty in msgps
(Model Selection Criteria via Generalized Path Seeking).</p>
</td></tr>
<tr><td><code id="var_select_+3A_m">M</code></td>
<td>
<p>A numeric matrix. The transposed predictors matrix.</p>
</td></tr>
<tr><td><code id="var_select_+3A_k">K</code></td>
<td>
<p>A numeric value. Number of folds to use.</p>
</td></tr>
<tr><td><code id="var_select_+3A_eps">eps</code></td>
<td>
<p>A numeric value. Threshold to set to 0 the inferred value of a parameter.</p>
</td></tr>
<tr><td><code id="var_select_+3A_cv.fun">cv.fun</code></td>
<td>
<p>A function. Fonction used to create folds. Used to perform corss-validation subkectwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lasso_cv_glmnet_bin_min</code> returns the vector of coefficients
for a binary logistic model estimated by the lasso using the <code>lambda.min</code> value
computed by 10 fold cross validation. It uses the <code>glmnet</code> function of
the <code>glmnet</code>package.
</p>
<p><code>lasso_cv_glmnet_bin_1se</code> returns the vector of coefficients
for a binary logistic model estimated by the lasso using the <code>lambda.1se</code>
(lambda.min+1se) value computed by 10 fold cross validation. It uses the <code>glmnet</code>
function of the <code>glmnet</code>package.
</p>
<p><code>lasso_glmnet_bin_AICc</code> returns the vector of coefficients
for a binary logistic model estimated by the lasso and selected according to the
bias-corrected AIC (AICC) criterion. It uses the <code>glmnet</code>
</p>
<p><code>lasso_glmnet_bin_BIC</code> returns the vector of coefficients
for a binary logistic model estimated by the lasso and selected according to the BIC
criterion. It uses the <code>glmnet</code>
</p>
<p><code>lasso_cv_lars_min</code> returns the vector of coefficients
for a linear model estimated by the lasso using the <code>lambda.min</code> value
computed by 5 fold cross validation. It uses the <code>lars</code> function of the
<code>lars</code> package.
</p>
<p><code>lasso_cv_lars_1se</code> returns the vector of coefficients
for a linear model estimated by the lasso using the <code>lambda.1se</code>
(lambda.min+1se) value computed by 5 fold cross validation.
It uses the <code>lars</code> function of the <code>lars</code> package.
</p>
<p><code>lasso_cv_glmnet_min</code> returns the vector of coefficients
for a linear model estimated by the lasso using the <code>lambda.min</code> value
computed by 10 fold cross validation. It uses the <code>glmnet</code> function of the
<code>glmnet</code> package.
</p>
<p><code>lasso_cv_glmnet_min_weighted</code> returns the vector of coefficients
for a linear model estimated by the weighted lasso using the <code>lambda.min</code> value
computed by 10 fold cross validation. It uses the <code>glmnet</code> function of the
<code>glmnet</code> package.
</p>
<p><code>lasso_cv_glmnet_1se</code> returns the vector of coefficients
for a linear model estimated by the lasso using the <code>lambda.1se</code>
(lambda.min+1se) value computed by 10 fold cross validation. It uses the <code>glmnet</code>
function of the
<code>glmnet</code> package.
</p>
<p><code>lasso_cv_glmnet_1se_weighted</code> returns the vector of coefficients
for a linear model estimated by the weighted lasso using the <code>lambda.1se</code>
(lambda.min+1se) value computed by 10 fold cross validation. It uses the <code>glmnet</code>
function of the <code>glmnet</code> package.
</p>
<p><code>lasso_msgps_Cp</code> returns the vector of coefficients
for a linear model estimated by the lasso selectd using Mallows' Cp.
It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>lasso_msgps_AICc</code> returns the vector of coefficients
for a linear model estimated by the lasso selected according to the bias-corrected AIC
(AICC) criterion. It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>lasso_msgps_GCV</code> returns the vector of coefficients
for a linear model estimated by the lasso selected according to the generalized
cross validation criterion. It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>lasso_msgps_BIC</code> returns the vector of coefficients
for a linear model estimated by the lasso selected according to the BIC criterion.
It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>enetf_msgps_Cp</code> returns the vector of coefficients
for a linear model estimated by the elastic net selectd using Mallows' Cp.
It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>enetf_msgps_AICc</code> returns the vector of coefficients
for a linear model estimated by the elastic net selected according to the bias-corrected AIC
(AICC) criterion. It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>enetf_msgps_GCV</code> returns the vector of coefficients
for a linear model estimated by the elastic net selected according to the generalized
cross validation criterion. It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>enetf_msgps_BIC</code> returns the vector of coefficients
for a linear model estimated by the elastic net selected according to the BIC criterion.
It uses the <code>msgps</code> function of the <code>msgps</code> package.
</p>
<p><code>lasso_cascade</code> returns the vector of coefficients
for a linear model estimated by the lasso.
It uses the <code>lars</code> function of the <code>lars</code> package.
</p>


<h3>Value</h3>

<p>A vector of coefficients.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code>, <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>, <code><a href="#topic+AICc_BIC_glmnetB">AICc_BIC_glmnetB</a></code>, <code><a href="lars.html#topic+lars">lars</a></code>, <code><a href="lars.html#topic+cv.lars">cv.lars</a></code>, <code><a href="msgps.html#topic+msgps">msgps</a></code>
</p>
<p>Other Variable selection functions: 
<code><a href="#topic+var_select_all">var_select_all</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran=matrix(rnorm(150),30,5)
ybin=sample(0:1,30,replace=TRUE)
yran=rnorm(30)
set.seed(314)
lasso_cv_glmnet_bin_min(xran,ybin)

set.seed(314)
lasso_cv_glmnet_bin_1se(xran,ybin)

set.seed(314)
lasso_glmnet_bin_AICc(xran,ybin)

set.seed(314)
lasso_glmnet_bin_BIC(xran,ybin)

set.seed(314)
lasso_cv_lars_min(xran,yran)

set.seed(314)
lasso_cv_lars_1se(xran,yran)

set.seed(314)
lasso_cv_glmnet_min(xran,yran)

set.seed(314)
lasso_cv_glmnet_min_weighted(xran,yran,c(1000,0,0,1,1))

set.seed(314)
lasso_cv_glmnet_1se(xran,yran)

set.seed(314)
lasso_cv_glmnet_1se_weighted(xran,yran,c(1000,0,0,1,1))

set.seed(314)
lasso_msgps_Cp(xran,yran)

set.seed(314)
lasso_msgps_AICc(xran,yran)

set.seed(314)
lasso_msgps_GCV(xran,yran)

set.seed(314)
lasso_msgps_BIC(xran,yran)

set.seed(314)
enetf_msgps_Cp(xran,yran)

set.seed(314)
enetf_msgps_AICc(xran,yran)

set.seed(314)
enetf_msgps_GCV(xran,yran)

set.seed(314)
enetf_msgps_BIC(xran,yran)

set.seed(314)
lasso_cascade(t(xran),yran,5,cv.fun=lars::cv.folds)

</code></pre>

<hr>
<h2 id='var_select_all'>Variable selection functions (all)</h2><span id='topic+var_select_all'></span><span id='topic+lasso_msgps_all'></span><span id='topic+enet_msgps_all'></span><span id='topic+alasso_msgps_all'></span><span id='topic+alasso_enet_msgps_all'></span><span id='topic+lasso_cv_glmnet_all_5f'></span><span id='topic+spls_spls_all'></span><span id='topic+varbvs_linear_all'></span><span id='topic+lasso_cv_glmnet_bin_all'></span><span id='topic+lasso_glmnet_bin_all'></span><span id='topic+splsda_spls_all'></span><span id='topic+sgpls_spls_all'></span><span id='topic+varbvs_binomial_all'></span>

<h3>Description</h3>

<p>Compute coefficient vector after variable selection for the fitting criteria of a given model. May be used for a step by step use of Selectboost.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso_msgps_all(X, Y, penalty = "enet")

enet_msgps_all(X, Y, penalty = "enet", alpha = 0.5)

alasso_msgps_all(X, Y, penalty = "alasso")

alasso_enet_msgps_all(X, Y, penalty = "alasso", alpha = 0.5)

lasso_cv_glmnet_all_5f(X, Y)

spls_spls_all(X, Y, K.seq = c(1:5), eta.seq = (1:9)/10, fold.val = 5)

varbvs_linear_all(X, Y, include.threshold.list = (1:19)/20)

lasso_cv_glmnet_bin_all(X, Y)

lasso_glmnet_bin_all(X, Y)

splsda_spls_all(X, Y, K.seq = c(1:10), eta.seq = (1:9)/10)

sgpls_spls_all(X, Y, K.seq = c(1:10), eta.seq = (1:9)/10)

varbvs_binomial_all(X, Y, include.threshold.list = (1:19)/20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_select_all_+3A_x">X</code></td>
<td>
<p>A numeric matrix. The predictors matrix.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_y">Y</code></td>
<td>
<p>A binary factor. The 0/1 classification response.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_penalty">penalty</code></td>
<td>
<p>A character value to select the penalty term in msgps
(Model Selection Criteria via Generalized Path Seeking). Defaults to &quot;enet&quot;.
&quot;genet&quot; is the generalized elastic net and &quot;alasso&quot; is the adaptive lasso,
which is a weighted version of the lasso.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to set the value of <code class="reqn">\alpha</code> on &quot;enet&quot; and &quot;genet&quot; penalty in msgps
(Model Selection Criteria via Generalized Path Seeking).</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_k.seq">K.seq</code></td>
<td>
<p>A numeric vector. Number of components to test.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_eta.seq">eta.seq</code></td>
<td>
<p>A numeric vector. Eta sequence to test.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_fold.val">fold.val</code></td>
<td>
<p>A numeric value. Number of folds to use.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_include.threshold.list">include.threshold.list</code></td>
<td>
<p>A numeric vector. Vector of threshold to use.</p>
</td></tr>
<tr><td><code id="var_select_all_+3A_k">K</code></td>
<td>
<p>A numeric value. Number of folds to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lasso_msgps_all</code> returns the matrix of coefficients
for an optimal linear model estimated by the LASSO estimator and selected
by model selection criteria including Mallows' Cp, bias-corrected AIC (AICc),
generalized cross validation (GCV) and BIC.
The the <code>msgps</code> function of the <code>msgps</code> package implements
Model Selection Criteria via Generalized Path Seeking to compute the degrees
of freedom of the LASSO.
</p>
<p><code>enet_msgps_all</code> returns the matrix of coefficients
for an optimal linear model estimated by the ELASTIC NET estimator and selected
by model selection criteria including Mallows' Cp, bias-corrected AIC (AICc),
generalized cross validation (GCV) and BIC.
The the <code>msgps</code> function of the <code>msgps</code> package implements
Model Selection Criteria via Generalized Path Seeking to compute the degrees
of freedom of the ELASTIC NET.
</p>
<p><code>alasso_msgps_all</code> returns the matrix of coefficients
for an optimal linear model estimated by the adaptive LASSO estimator and selected
by model selection criteria including Mallows' Cp, bias-corrected AIC (AICc),
generalized cross validation (GCV) and BIC.
The the <code>msgps</code> function of the <code>msgps</code> package implements
Model Selection Criteria via Generalized Path Seeking to compute the degrees
of freedom of the adaptive LASSO.
</p>
<p><code>alasso_enet_msgps_all</code> returns the matrix of coefficients
for an optimal linear model estimated by the adaptive ELASTIC NET estimator and selected
by model selection criteria including Mallows' Cp, bias-corrected AIC (AICc),
generalized cross validation (GCV) and BIC.
The the <code>msgps</code> function of the <code>msgps</code> package implements
Model Selection Criteria via Generalized Path Seeking to compute the degrees
of freedom of the adaptive ELASTIC NET.
</p>
<p><code>lasso_cv_glmnet_all_5f</code> returns the matrix of coefficients
for a linear model estimated by the LASSO using the <code>lambda.min</code> and <code>lambda.1se</code>
(lambda.min+1se) values computed by 5 fold cross validation. It uses the <code>glmnet</code>
and <code>cv.glmnet</code> functions of the <code>glmnet</code> package.
</p>
<p><code>spls_spls_all</code> returns the matrix of the raw (<code>coef.spls</code>)
and <code>correct.spls</code> and bootstrap corrected coefficients
for a linear model estimated by the SPLS (sparse partial least squares) and 5 fold cross validation.
It uses the <code>spls</code>, <code>cv.spls</code>, <code>ci.spls</code>, <code>coef.spls</code> and
<code>correct.spls</code> functions of the <code>spls</code> package.
</p>
<p><code>varbvs_linear_all</code> returns the matrix of the coefficients
for a linear model estimated by the varbvs (variational approximation for Bayesian
variable selection in linear regression, <code>family = gaussian</code>) and the requested threshold values.
It uses the <code>varbvs</code>, <code>coef</code> and <code>variable.names</code> functions of the <code>varbvs</code> package.
</p>
<p><code>lasso_cv_glmnet_bin_all</code> returns the matrix of coefficients
for a logistic model estimated by the LASSO using the <code>lambda.min</code> and <code>lambda.1se</code>
(lambda.min+1se) values computed by 5 fold cross validation. It uses the <code>glmnet</code> and <code>cv.glmnet</code>
functions of the <code>glmnet</code> package.
</p>
<p><code>lasso_glmnet_bin_all</code> returns the matrix of coefficients
for a logistic model estimated by the LASSO using the <code>AICc_glmnetB</code> and <code>BIC_glmnetB</code>
information criteria. It uses the <code>glmnet</code> function of the <code>glmnet</code> package and the
<code>AICc_glmnetB</code> and <code>BIC_glmnetB</code> functions of the <code>SelectBoost</code> package that were
adapted from the <code>AICc_glmnetB</code> and <code>BIC_glmnetB</code> functions of the <code>rLogistic</code>
(<a href="https://github.com/echi/rLogistic">https://github.com/echi/rLogistic</a>) package.
</p>
<p><code>splsda_spls_all</code> returns the matrix of the raw (<code>coef.splsda</code>) coefficients
for logistic regression model estimated by the SGPLS (sparse généralized partial least squares) and
5 fold cross validation. It uses the <code>splsda</code>, <code>cv.splsda</code> and <code>coef.splsda</code> functions
of the <code>sgpls</code> package.
</p>
<p><code>sgpls_spls_all</code> returns the matrix of the raw (<code>coef.sgpls</code>) coefficients
for logistic regression model estimated by the SGPLS (sparse généralized partial least squares) and
5 fold cross validation. It uses the <code>sgpls</code>, <code>cv.sgpls</code> and <code>coef.sgpls</code> functions
of the <code>sgpls</code> package.
</p>
<p><code>varbvs_binomial_all</code> returns the matrix of the coefficients
for a linear model estimated by the varbvs (variational approximation for Bayesian
variable selection in logistic regression, <code>family = binomial</code>) and the requested threshold values.
It uses the <code>varbvs</code>, <code>coef</code> and <code>variable.names</code> functions of the <code>varbvs</code> package.
</p>


<h3>Value</h3>

<p>A vector or matrix of coefficients.
</p>


<h3>Author(s)</h3>

<p>Frederic Bertrand, <a href="mailto:frederic.bertrand@utt.fr">frederic.bertrand@utt.fr</a>
</p>


<h3>References</h3>

<p><em>selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets</em>, Frédéric Bertrand, Ismaïl Aouadi, Nicolas Jung, Raphael Carapito, Laurent Vallat, Seiamak Bahram, Myriam Maumy-Bertrand, Bioinformatics, 2020. <a href="https://doi.org/10.1093/bioinformatics/btaa855">doi:10.1093/bioinformatics/btaa855</a>
</p>


<h3>See Also</h3>

<p><code><a href="glmnet.html#topic+glmnet">glmnet</a></code>, <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>, <code><a href="msgps.html#topic+msgps">msgps</a></code>, <code><a href="#topic+AICc_BIC_glmnetB">AICc_BIC_glmnetB</a></code>, <code><a href="spls.html#topic+spls">spls</a></code>, <code><a href="spls.html#topic+cv.spls">cv.spls</a></code>, <code><a href="spls.html#topic+correct.spls">correct.spls</a></code>, <code><a href="spls.html#topic+splsda">splsda</a></code>, <code><a href="spls.html#topic+cv.splsda">cv.splsda</a></code>, <code><a href="spls.html#topic+sgpls">sgpls</a></code>, <code><a href="spls.html#topic+cv.sgpls">cv.sgpls</a></code>, <code><a href="varbvs.html#topic+varbvs">varbvs</a></code>
</p>
<p>Other Variable selection functions: 
<code><a href="#topic+var_select">var_select</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(314)
xran &lt;- matrix(rnorm(100*6),100,6)
beta0 &lt;- c(3,1.5,0,0,2,0)
epsilon &lt;- rnorm(100,sd=3)
yran &lt;- c(xran %*% beta0 + epsilon)
ybin &lt;- ifelse(yran&gt;=0,1,0)
set.seed(314)
lasso_msgps_all(xran,yran)

set.seed(314)
enet_msgps_all(xran,yran)

set.seed(314)
alasso_msgps_all(xran,yran)

set.seed(314)
alasso_enet_msgps_all(xran,yran)

set.seed(314)
lasso_cv_glmnet_all_5f(xran,yran)

set.seed(314)
spls_spls_all(xran,yran)

set.seed(314)
varbvs_linear_all(xran,yran)

set.seed(314)
lasso_cv_glmnet_bin_all(xran,ybin)

set.seed(314)
lasso_glmnet_bin_all(xran,ybin)

set.seed(314)

splsda_spls_all(xran,ybin, K.seq=1:3)


set.seed(314)

sgpls_spls_all(xran,ybin, K.seq=1:3)


set.seed(314)
varbvs_binomial_all(xran,ybin)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
