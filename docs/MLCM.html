<!DOCTYPE html><html lang="en"><head><title>Help for package MLCM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MLCM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MLCM-package'>
<p>Maximum Likelihood Conjoint Measurement</p></a></li>
<li><a href='#anova.mlcm'><p> Analysis of Deviance for Maximum Likelihood Conjoint Measurement Model Fits</p></a></li>
<li><a href='#as.mlcm.df'>
<p>Coerce data frame to mlcm.df</p></a></li>
<li><a href='#binom.diagnostics'><p> Diagnostics for Binary GLM</p></a></li>
<li><a href='#boot.mlcm'><p> Resampling of an Estimated Conjoint Measurement Scale</p></a></li>
<li><a href='#BumpyGlossy'><p> Conjoint Measurement Data for Bumpiness and Glossiness</p></a></li>
<li><a href='#fitted.mlcm'><p> Fitted Responses for a Conjoint Measurement Scale</p></a></li>
<li><a href='#logLik.mlcm'><p>Extract Log-Likelihood from mlcm Object</p></a></li>
<li><a href='#make.wide'><p> Create data frame for Fitting Conjoint Measurment Models by glm</p></a></li>
<li><a href='#mlcm'><p>Fit Conjoint Measurement Models by Maximum Likelihood</p></a></li>
<li><a href='#plot.mlcm'><p> Plot an mlcm Object</p></a></li>
<li><a href='#plot.mlcm.df'>
<p>Create Conjoint Proportion Plot from mlcm.df Object</p></a></li>
<li><a href='#predict.mlcm'>
<p>Predict Method for MLCM Objects</p></a></li>
<li><a href='#summary.mlcm'><p> Summary Method for mlcm objects</p></a></li>
<li><a href='#Texture'>
<p>Three-way Conjoint Measurement Data for Texture Regularity.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Maximum Likelihood Conjoint Measurement</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-01-03</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5), graphics, stats, utils, base</td>
</tr>
<tr>
<td>Description:</td>
<td>Conjoint measurement is a psychophysical procedure in which stimulus pairs are presented that vary along 2 or more dimensions and the observer is required to compare the stimuli along one of them.  This package contains functions to estimate the contribution of the n scales to the judgment by a maximum likelihood method under several hypotheses of how the perceptual dimensions interact. Reference: Knoblauch &amp; Maloney (2012) "Modeling Psychophysical Data in R". &lt;<a href="https://doi.org/10.1007%2F978-1-4614-4475-6">doi:10.1007/978-1-4614-4475-6</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-11 16:24:36 UTC; guille</td>
</tr>
<tr>
<td>Author:</td>
<td>Ken Knoblauch [aut],
  Laurence T. Maloney [aut],
  Guillermo Aguilar [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Guillermo Aguilar &lt;guillermo.aguilar@mail.tu-berlin.de&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-11 17:22:43 UTC</td>
</tr>
</table>
<hr>
<h2 id='MLCM-package'>
Maximum Likelihood Conjoint Measurement
</h2><span id='topic+MLCM-package'></span><span id='topic+MLCM'></span>

<h3>Description</h3>

<p>Estimate perceptual scales from data collected in a conjoint measurement experiment by maximum likelihood. 
Data for conjoint measurement are typically collected using a psychophysical procedure. The stimuli vary along <code class="reqn">n \ge 2</code> dimensions.  The observer views pairs of stimuli and judges which stimulus of each pair is higher on a specified dimension.  For example, stimuli may be goods baskets containing amounts of milk and honey (dimensions) and the subject may order each pair of baskets by subjective desirability.
This package contains functions to estimate the additive contribution of the <code class="reqn">n</code> scales to the judgment by a maximum likelihood method under several hypotheses of how the perceptual dimensions interact.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> MLCM</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.4.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2020-01-11</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyData: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Index:
</p>
<pre>
BumpyGlossy		Dataset: Conjoint Measurement for Bumpiness and Glossiness (Ho et al. 2008)

Texture			Dataset: 3-way conjoint Measurement for Texture (Sun et. al, 2021)

MLCM-package		Estimate perceptual scales from a conjoint measurement experiment by maximum likelihood

anova.mlcm		Likelihood ratio tests for Maximum Likelihood Conjoint Measurement models

logLik.mlcm		Calculate log likelihood for Conjoint Measurement models 

make.wide		Create data frame for Fitting Conjoint Measurement Scale by glm

mlcm			Fit Conjoint Measurement Models by Maximum Likelihood 

plot.mlcm		plot method for Maximum Likelihood Conjoint Measurement models

print.mlcm		print method for Maximum Likelihood Conjoint Measurement models

print.summary.mlcm	print  method for summary of Maximum Likelihood Conjoint Measurement models

summary.mlcm		summary method for Maximum Likelihood Conjoint Measurement models
</pre>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch
</p>
<p>Maintainers: Guillermo Aguilar &lt;guillermo.aguilar@mail.tu-berlin.de&gt;, Ken Knoblauch &lt;ken.knoblauch@inserm.fr&gt;
</p>


<h3>References</h3>

<p>Luce, R. D., and Tukey, J. W. (1964). Simultaneous conjoint measurement. 
<em>Journal of Mathematical Psychology</em>, <b>1</b>, 
1&ndash;27.	
</p>
<p>Krantz, D. H., Luce, R. D., Suppes, P., and Tversky, A. (1971).
<em>Foundations of Measurement, Vol. 1: Additive and Polynomial Representations</em>.
New York: Academic Press.	
</p>
<p>Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bg.acm &lt;- mlcm(BumpyGlossy)
plot(bg.acm, pch = 21:22, bg = c("blue", "red"), col = "black",
	ylab = "Contributions to Perceived Bumpiness")
</code></pre>

<hr>
<h2 id='anova.mlcm'> Analysis of Deviance for Maximum Likelihood Conjoint Measurement Model Fits </h2><span id='topic+anova.mlcm'></span>

<h3>Description</h3>

<p>Compute an analysis of deviance table for one or more maximum likelihood conjoint measurement model fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm'
anova(object, ..., dispersion = NULL, test = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="anova.mlcm_+3A_object">object</code>, <code id="anova.mlcm_+3A_...">...</code></td>
<td>
<p>objects of class <code>mlcm</code>, typically the result of a call to <code>mlcm</code></p>
</td></tr>
<tr><td><code id="anova.mlcm_+3A_dispersion">dispersion</code></td>
<td>
<p>the dispersion parameter for the fitting family.  By default, it is obtained from the object(s)</p>
</td></tr>
<tr><td><code id="anova.mlcm_+3A_test">test</code></td>
<td>
<p>a character string (partially) matching one of &quot;Chisq&quot;, &quot;F&quot;, or &quot;Cp&quot;.  See <code><a href="stats.html#topic+stat.anova">stat.anova</a></code>.  Normally, &quot;Chisq&quot; is the appropriate value, here. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="stats.html#topic+anova.glm">anova.glm</a></code> for details.  In brief, specifying a single object, results in the display of a sequential analysis of deviance table for that model.  Specifying several objects, a table indicating the results of the likelihood ratio tests between successive models is displayed.  The models must be nested and fit to the same data set.  One can mix a <code>formula</code> method model with a <code>glm</code> model, but not more than one comparison between a pair of such models at a time.
</p>


<h3>Value</h3>

<p>An object of class &quot;anova&quot; inheriting from class &quot;data.frame&quot;. </p>


<h3>Warning </h3>

<p>see section Warnings in <code><a href="stats.html#topic+anova">anova</a></code> for warnings.</p>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch</p>


<h3>References</h3>

<p>  Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+anova.glm">anova.glm</a></code>, <code><a href="stats.html#topic+anova">anova</a></code>,  <code><a href="stats.html#topic+glm">glm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>bg.add &lt;- mlcm(BumpyGlossy)
bg.ind &lt;- mlcm(BumpyGlossy, model = "ind", whichdim = 2)
bg.full &lt;- mlcm(BumpyGlossy, model = "full")

anova(bg.ind, bg.add, bg.full, test = "Chisq")
</code></pre>

<hr>
<h2 id='as.mlcm.df'>
Coerce data frame to mlcm.df
</h2><span id='topic+as.mlcm.df'></span>

<h3>Description</h3>

<p>Coerce a data frame from an MLCM experiment to an object of class <code>mlcm.df</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.mlcm.df(d, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as.mlcm.df_+3A_d">d</code></td>
<td>

<p>object of class <code>data.frame</code> typically obtained from an MLCM experiment.  It should have an odd number of columns and no less than 5.
</p>
</td></tr>
<tr><td><code id="as.mlcm.df_+3A_...">...</code></td>
<td>

<p>Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first column should be named <code>Resp</code>.  Subsequent columns contain integer indices to the stimulus levels of the stimuli presented for each trial.  As there are two stimuli per trial and at least 2 dimensions tested per experiment, the minimun number of total columns will be 5.
</p>


<h3>Value</h3>

<p>Returns a data frame of class <code>mlcm.df</code>.
</p>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+mlcm">mlcm</a></code>,
</p>

<hr>
<h2 id='binom.diagnostics'> Diagnostics for Binary GLM</h2><span id='topic+binom.diagnostics'></span><span id='topic+plot.mlcm.diag'></span>

<h3>Description</h3>

<p>Two techniques for evaluating the adequacy of the binary glm model used in <code>mlcm</code>, based on code in Wood (2006).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binom.diagnostics(obj, nsim = 200, type = "deviance")

## S3 method for class 'mlcm.diag'
plot(x, alpha = 0.025, breaks = "Sturges", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binom.diagnostics_+3A_obj">obj</code></td>
<td>
<p>list of class &lsquo;mlcm&rsquo; typically generated by a call to the <code>mlcm</code> </p>
</td></tr>
<tr><td><code id="binom.diagnostics_+3A_nsim">nsim</code></td>
<td>
<p> integer giving the number of sets of data to simulate </p>
</td></tr>
<tr><td><code id="binom.diagnostics_+3A_type">type</code></td>
<td>
<p>character indicating type of residuals.  Default is deviance residuals.  See <code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code> for other choices </p>
</td></tr>
<tr><td><code id="binom.diagnostics_+3A_x">x</code></td>
<td>
<p>list of class &lsquo;mlcm.diag&rsquo; typically generated by a call to <code>binom.diagnostics</code></p>
</td></tr>
<tr><td><code id="binom.diagnostics_+3A_alpha">alpha</code></td>
<td>
<p>numeric between 0 and 1, the envelope limits for the cdf of the deviance residuals</p>
</td></tr>
<tr><td><code id="binom.diagnostics_+3A_breaks">breaks</code></td>
<td>
<p>character or numeric indicating either the method for calculating the number of breaks or the suggested number of breaks to employ.  See <code><a href="graphics.html#topic+hist">hist</a></code> for more details.</p>
</td></tr>
<tr><td><code id="binom.diagnostics_+3A_...">...</code></td>
<td>
<p>additional parameters specifications for the empirical cdf plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wood (2006) describes two diagnostics of the adequacy of a binary glm model based on analyses of residuals (see, p. 115, Exercise 2 and his solution on pp 346-347).  The first one compares the empirical cdf of the deviance residuals to a bootstrapped confidence envelope of the curve.  The second examines the number of runs in the sorted residuals with those expected on the basis of independence in the residuals, again using a resampling based on the models fitted values. The plot method generates two graphs, the first being the empirical cdf and the envelope.  The second is a histogram of the number of runs from the bootstrap procedure with the observed number indicated by a vertical line.  Currently, this only works if the &lsquo;glm&rsquo; method is used to perform the fit and <em>not</em> the &lsquo;optim&rsquo; method
</p>


<h3>Value</h3>

<p><code>binom.diagnostics</code> returns a list of class &lsquo;mlcm.diag&rsquo; with components
</p>
<table role = "presentation">
<tr><td><code>NumRuns</code></td>
<td>
<p>integer vector giving the number of runs obtained for each simulation</p>
</td></tr>
<tr><td><code>resid</code></td>
<td>
<p>numeric matrix giving the sorted deviance residuals in each column from each simulation</p>
</td></tr>
<tr><td><code>Obs.resid</code></td>
<td>
<p>numeric vector of the sorted observed deviance residuals</p>
</td></tr>
<tr><td><code>ObsRuns</code></td>
<td>
<p>integer giving the observed number of runs in the sorted deviance residuals</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>numeric giving the proportion of runs in the simulation less than the observed value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Knoblauch </p>


<h3>References</h3>

<p>Wood, SN <em>Generalized Additive Models: An Introduction with R</em>, Chapman \&amp; Hall/CRC, 2006 
</p>
<p>Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlcm">mlcm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(BumpyGlossy)
bg.mlcm &lt;- mlcm(BumpyGlossy)
bg.diag &lt;- binom.diagnostics(bg.mlcm)
plot(bg.diag)

## End(Not run)
</code></pre>

<hr>
<h2 id='boot.mlcm'> Resampling of an Estimated Conjoint Measurement Scale </h2><span id='topic+boot.mlcm'></span>

<h3>Description</h3>

<p>Using the <code>fitted</code> responses (probabilities) to the conjoint measurement scale, new responses are generated which permit new bootstrap replications of estimated scales to be generated. The mean scale is useful for evaluating bias and the standard deviation for estimating standard errors of the scale values. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.mlcm(x, nsim, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot.mlcm_+3A_x">x</code></td>
<td>
<p> an object of class &lsquo;mlcm&rsquo;</p>
</td></tr>
<tr><td><code id="boot.mlcm_+3A_nsim">nsim</code></td>
<td>
<p> an integer, the number of simulations. </p>
</td></tr>
<tr><td><code id="boot.mlcm_+3A_...">...</code></td>
<td>
<p> Additional options passed along to the function <code>mlcm</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The scale values (from &lsquo;glm&rsquo; method) permit the fitted probabilities to be estimated.  These are used to generate new responses to the stimulus pairs using <code>rbinom</code>.  The new responses are then used with <code>mlcm</code> to estimate a bootstrapped scale.  This is repeated <code class="reqn">N</code> times and stored in the output with the mean and standard deviation of the bootstrapped scales.
</p>


<h3>Value</h3>

<p>A list of 4 elements:  
</p>
<table role = "presentation">
<tr><td><code>boot.samp</code></td>
<td>
<p>A <code class="reqn">p</code> x <code class="reqn">N</code> matrix of the bootstrap samples of the scale, where p is the number of scale values and N is the number of simulations.  </p>
</td></tr>
<tr><td><code>bt.mean</code></td>
<td>
<p>A vector of length <code class="reqn">p</code> giving the mean of the bootstrap scales.</p>
</td></tr>
<tr><td><code>bt.sd</code></td>
<td>
<p>A vector of length <code class="reqn">p</code> giving the standard deviation of the boostrap scales. </p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The number of bootstrap simulations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch and Laurence T. Maloney</p>


<h3>References</h3>

 
<p>Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlcm">mlcm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(BumpyGlossy)
	bg.mlcm &lt;- mlcm(BumpyGlossy)
	#nsim should be near 10,000 for stability,
	# but this will take a little time
	boot.mlcm(bg.mlcm, 100)
</code></pre>

<hr>
<h2 id='BumpyGlossy'> Conjoint Measurement Data for Bumpiness and Glossiness</h2><span id='topic+BumpyGlossy'></span><span id='topic+GlossyBumpy'></span>

<h3>Description</h3>

<p>Data sets from two observers who were asked to judge which of two samples appeared bumpier (<code>BumpyGlossy</code>) or glossier (<code>GlossyBumpy</code>) when the two attributes were covaried simultaneously.
The data sets are of class &lsquo;mlcm.df&rsquo; and
&lsquo;data.frame&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	data(BumpyGlossy)
	data(GlossyBumpy)
	</code></pre>


<h3>Format</h3>

<p>A data frame with 975 observations on the following 5 variables.
</p>

<dl>
<dt><code>Resp</code></dt><dd><p>a factor with levels <code>0</code> <code>1</code> indicating whether the first or second sample was judged to be bumpier (glossier).</p>
</dd>
<dt><code>G1</code></dt><dd><p>a numeric vector indicating the indexed level of glossiness of the first sample.</p>
</dd>
<dt><code>G2</code></dt><dd><p>a numeric vector indicating the indexed level of glossiness of the second sample.</p>
</dd>
<dt><code>B1</code></dt><dd><p>a numeric vector indicating the indexed level of bumpiness of the first sample.</p>
</dd>
<dt><code>B2</code></dt><dd><p>a numeric vector indicating the indexed level of bumpiness of the second sample.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Synthetic images of textures composed of random arrays of overlapping balls were created with varying degress of bumpiness and glossiness of the surfaces.  In separate experiments observers judged which of a pair of images appeared bumpier or glossier.  These data permit evaluating whether the level of glossiness (bumpiness) affects judgments of bumpiness (glossiness).  The data are from the observers (RK and FC) indicated in Figure 4C of the Ho et al (2008) paper.  Each data set contains three replications of the same stimuli with each session being 325 trials long.
</p>


<h3>Source</h3>

<p>Ho, Y.-H., Landy. M. S., Maloney, L. T. (2008), Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19(2)</b>, 196&ndash;204.</p>


<h3>References</h3>

<p>Ho, Y.-H., Landy. M. S., Maloney, L. T. (2008), Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19(2)</b>, 196&ndash;204.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BumpyGlossy)
data(GlossyBumpy)
</code></pre>

<hr>
<h2 id='fitted.mlcm'> Fitted Responses for a Conjoint Measurement Scale </h2><span id='topic+fitted.mlcm'></span>

<h3>Description</h3>

<p><code>fitted.mlcm</code> returns the fitted responses from an estimated conjoing measurement scale obtained by <code>mlcm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.mlcm_+3A_object">object</code></td>
<td>
<p>object of class &lsquo;mlcm&rsquo;, typically obtained from the output of <code>mlcm</code>. </p>
</td></tr>
<tr><td><code id="fitted.mlcm_+3A_...">...</code></td>
<td>
<p>currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector contained the fitted probabilities to the responses of the observer for each pair of stimuli.
</p>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch</p>


<h3>References</h3>

<p>Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204. </p>


<h3>See Also</h3>

<p><code><a href="#topic+mlcm">mlcm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BumpyGlossy)
fitted(mlcm(BumpyGlossy))
</code></pre>

<hr>
<h2 id='logLik.mlcm'>Extract Log-Likelihood from mlcm Object </h2><span id='topic+logLik.mlcm'></span>

<h3>Description</h3>

<p>This is a method function for extracting the log likelihood from objects of class &lsquo;mlcm&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLik.mlcm_+3A_object">object</code>, <code id="logLik.mlcm_+3A_...">...</code></td>
<td>
<p> object of class <code>mlcm</code> typically generated by <code>mlcm</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the help page for the generic function <code><a href="stats.html#topic+logLik">logLik</a> for details.</code>
</p>


<h3>Value</h3>

<p>Returns an object of class <code>logLik</code> with an attribute, <code>df</code>, giving the degrees of freedom.
</p>


<h3>Author(s)</h3>

<p> Kenneth Knoblauch </p>


<h3>See Also</h3>

  <p><code><a href="stats.html#topic+logLik">logLik</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> logLik(mlcm(BumpyGlossy))
</code></pre>

<hr>
<h2 id='make.wide'> Create data frame for Fitting Conjoint Measurment Models by glm </h2><span id='topic+make.wide'></span><span id='topic+make.wide.full'></span>

<h3>Description</h3>

<p><code>make.wide</code> and <code>make.wide.full</code> generate a <code class="reqn">n</code> x <code class="reqn">q - 1</code> matrix from an <code class="reqn">n</code> x <code class="reqn">2</code> column subset of a data frame storing the results of a conjoint measurement experiment, where <code class="reqn">n</code> is the number of trials and <code class="reqn">q</code> is the number of levels per dimension in the stimulus set tested. Currently, <code>make.wide.full</code> is limited to data sets with only 2 stimulus dimensions. The columns code covariates for all but the first stimulus level, which is constrained to be 0, along each dimension.  These columns take the value 0 unless one of the stimuli in the trial corresponded to a level along that dimension, in which case it takes a 1 or a -1, depending on which of the two stimuli represented that level. If both stimuli represent the same level for a dimension, then they cancel out and the column contains a 0.  This function is used for each dimension along which the stimuli vary to create a design matrix for each dimension.  The final design matrix is constructed inside the <code>mlcm</code> method by putting together the design matrices from each dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.wide(d)

make.wide.full(d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make.wide_+3A_d">d</code></td>
<td>
<p>a <code class="reqn">n x 2</code> column data frame.  The columns give the indices of the levels of the dimensions along which the two stimuli presented in a trial vary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a helper function, normally used inside <code>mlcm</code>, and not typically exploited by the casual user.  
</p>


<h3>Value</h3>

<p>A data frame with <code class="reqn">n</code> rows and <code class="reqn">q - 1</code> columns
</p>
<table role = "presentation">
<tr><td><code>D2--Dq</code></td>
<td>
<p>For each dimension along which the stimulus can vary, there are <code class="reqn">q - 1</code> columns coding the absence or presence of that level of the dimension in the stimulus.  If the level is present, then the value is -1 or 1 as a function of which of the two stimuli contained that level, unless both do, in which case it is, also, 0. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch </p>

<hr>
<h2 id='mlcm'>Fit Conjoint Measurement Models by Maximum Likelihood</h2><span id='topic+mlcm'></span><span id='topic+mlcm.default'></span><span id='topic+mlcm.formula'></span><span id='topic+print.mlcm'></span>

<h3>Description</h3>

<p>Generic function <code>mlcm</code> uses different methods to fit the results of a conjoint measurement experiment using <code>glm</code> (Generalized Linear Model).  The default method permits fitting the data with a choice of 3 different models. The formula method permits fitting the data with a parametric model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlcm(x, ...)

## Default S3 method:
mlcm(x, model = "add", whichdim = NULL, lnk = "probit", 
	control = glm.control(maxit = 50000, epsilon = 1e-14), ...
	)
## S3 method for class 'formula'
mlcm(x, p, data, 
	model = "add", whichdim = NULL,
	lnk = "probit", opt.meth = "BFGS",
	control = list(maxit = 50000, reltol = 1e-14), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlcm_+3A_x">x</code></td>
<td>
<p> a data frame of an odd number of columns (at least 5) or a formula object.  In the case of a data frame, the first should be logical or a 2-level factor named <code>Resp</code> indicating the response of the observer.  The next columns give the indices in pairs along each dimension for each of the two stimuli being compared. </p>
</td></tr>
<tr><td><code id="mlcm_+3A_p">p</code></td>
<td>
<p> numeric indicating initial values of parameters for the formula method.</p>
</td></tr>
<tr><td><code id="mlcm_+3A_data">data</code></td>
<td>
<p>data frame of class &lsquo;mlcm.df&rsquo; for the formula method.</p>
</td></tr>
<tr><td><code id="mlcm_+3A_model">model</code></td>
<td>
<p>character indicating which of three conjoint measurement models to fit to the data:  &ldquo;add&rdquo;, for additive (default), &ldquo;ind&rdquo;, for independence or &ldquo;full&rdquo;, for including a dependence with the levels of each dimension with the others. The &ldquo;full&rdquo; is not applicable for the formula method.</p>
</td></tr>
<tr><td><code id="mlcm_+3A_whichdim">whichdim</code></td>
<td>
<p>integer indicating which dimension of the data set to fit when the independence model is chosen</p>
</td></tr>
<tr><td><code id="mlcm_+3A_lnk">lnk</code></td>
<td>
<p>character indicating the link function to use with the binomial family.  Current default is the probit link.</p>
</td></tr>
<tr><td><code id="mlcm_+3A_control">control</code></td>
<td>
<p>information to control the fit.  See <code>glm</code> and <code>glm.control</code> or <code>optim</code> for the formula method.</p>
</td></tr>
<tr><td><code id="mlcm_+3A_opt.meth">opt.meth</code></td>
<td>
<p>character indicating optimization method (default: &ldquo;BFGS&rdquo;) for <code>optim</code> with the formula method.</p>
</td></tr>
<tr><td><code id="mlcm_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>glm</code> or <code>optim</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a conjoint measurement experiment, observers are presented with pairs of stimuli that vary along 2 or more dimensions.  The observer's task is to choose which stimulus of the pair is greater along one of the dimensions.  Over a large number of trials, <code>mlcm</code> estimates numbers, 
</p>
<p style="text-align: center;"><code class="reqn">\psi_1, ..., \psi_p, \psi'_1, ..., \psi'_q, ...</code>
</p>
<p>, 
</p>
<p>by maximum likelihood using <code>glm</code> that best predict the observer's judgments.  
</p>
<p>The function permits the estimation of 3 different models, independent, additive (the default) and full,
by specifying the <code>model</code> argument.  The independent model fits the data along only 1 dimension, specified by the <code>whichdim</code> argument.  The additive model fits all dimensions with each fixed at 0 at the lowest level on each dimension.  Thus, if there are <code class="reqn">n</code> dimensions each with <code class="reqn">p_i</code> levels, <code>mlcm</code> estimates <code class="reqn">\sum p_i - n</code> coefficients. 
</p>
<p>Specifying the full model will fit a saturated model in which an estimate will be made for each combination of the scale values except the lowest (0 on all scales). This option, now, allows any number of dimensions to be fit.
</p>


<h3>Value</h3>

<p>a list of class &lsquo;mlcm&rsquo; that will include some of the following components depending on whether the default or formual method is used:
</p>
<table role = "presentation">
<tr><td><code>pscale</code></td>
<td>
<p>a vector or matrix giving the perceptual scale value estimates</p>
</td></tr>
<tr><td><code>stimulus</code></td>
<td>
<p>numeric indicating the scale values along each dimension</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>numeric indicating judgment <code class="reqn">\sigma</code>, currently always set to 1</p>
</td></tr>
<tr><td><code>par</code></td>
<td>
<p>numeric indicating the fitted parameter values when the formula method is used</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>log likelihood returned with the formula method</p>
</td></tr>
<tr><td><code>hess</code></td>
<td>
<p>Hessian matrix returned with the formual method</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character indicating whether the model was fit by <code>glm</code> or with the formula method</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>standard errors returned with the formula method</p>
</td></tr>
<tr><td><code>NumDim</code></td>
<td>
<p>numeric indicating number of stimulus dimensions in data set</p>
</td></tr>
<tr><td><code>NumLev</code></td>
<td>
<p>numeric indicating the number of levels along both dimensions, currently assumed to be the same</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>character indicating which of the 3 models were fit</p>
</td></tr>
<tr><td><code>link</code></td>
<td>
<p>character indicating the link used for the binomial family with <code>glm</code></p>
</td></tr>
<tr><td><code>obj</code></td>
<td>
<p>the &lsquo;glm&rsquo; object</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the &lsquo;mlcm&rsquo; data frame</p>
</td></tr>
<tr><td><code>conv</code></td>
<td>
<p>numeric indicating whether convergence was reached in the case of the formula method</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula object from argument to formula method</p>
</td></tr>
<tr><td><code>func</code></td>
<td>
<p>function constructed from formula object</p>
</td></tr>
<tr><td><code>whichdim</code></td>
<td>
<p>numeric indicating which dimension was fit in the case of the &ldquo;ind&rdquo; model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Knoblauch </p>


<h3>References</h3>

<p> Luce, R. D., and Tukey, J. W. (1964). Simultaneous conjoint measurement. 
<em>Journal of Mathematical Psychology</em>, <b>1</b>, 
1&ndash;27.	
</p>
<p>Krantz, D. H., Luce, R. D., Suppes, P., and Tversky, A. (1971).
<em>Foundations of Measurement, Vol. 1: Additive and Polynomial Representations</em>.
New York: Academic Press.	
</p>
<p>Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.</p>


<h3>See Also</h3>

  <p><code><a href="stats.html#topic+glm">glm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Additive model
bg.add &lt;- mlcm(BumpyGlossy)
plot(bg.add, type = "b")

# Independence model for Bumpiness
bg.ind &lt;- mlcm(BumpyGlossy, model = "ind", whichdim = 2)

anova(bg.ind, bg.add, test = "Chisq")

# Full model
bg.full &lt;- mlcm(BumpyGlossy, model = "full")

anova(bg.add, bg.full, test = "Chisq")

opar &lt;- par(mfrow = c(1, 2), pty = "s")
# Compare additive and full model graphically
plot(bg.full, standard.scale = TRUE, type = "b", 
	lty = 2, ylim = c(0, 1.05),
	xlab = "Gloss Level",
	ylab = "Bumpiness Model Estimates")
# additive prediction
bg.pr &lt;- with(bg.add, outer(pscale[, 1], pscale[, 2], "+"))
# predictions are same for arbitrary scaling,
#  so we adjust additive predictions to best fit
#  those from the full model by a scale factor.
cf &lt;- coef(lm(as.vector(bg.full$pscale/bg.full$pscale[5, 5]) ~ 
	as.vector(bg.pr) - 1))
matplot(cf * bg.pr, type = "b", add = TRUE, lty = 1)

#### Now make image of residuals between 2 models
bg.full.sc &lt;- bg.full$pscale/bg.full$pscale[5, 5]
bg.add.adj &lt;- cf * bg.pr
bg.res &lt;- (bg.add.adj - bg.full.sc) + 0.5
image(1:5, 1:5, bg.res, 
	col = grey.colors(100, min(bg.res), max(bg.res)),
	xlab = "Gloss Level", ylab = "Bumpiness Level" 
	)
	
#### Example with formula
# additive model
bg.frm &lt;- mlcm(~ p[1] * (x - 1)^p[2] + p[3] * (y - 1)^p[4], 
   p = c(0.1, 1.3, 1.6, 0.8), data = BumpyGlossy)
summary(bg.frm)
# independence model
bg.frm1 &lt;- mlcm(~ p[1] * (x - 1)^p[2], p = c(1.6, 0.8),
	data = BumpyGlossy, model = "ind", whichdim = 2)
summary(bg.frm1)

### Test additive against independent fits
ddev &lt;- -2 * (logLik(bg.frm1) - logLik(bg.frm))
df &lt;- attr(logLik(bg.frm), "df") - attr(logLik(bg.frm1), "df")
pchisq(as.vector(ddev), df, lower = FALSE)

# Compare additive power law and nonparametric models 
xx &lt;- seq(1, 5, len = 100)
par(mfrow = c(1, 1))
plot(bg.add, pch = 21, bg = c("red", "blue"))
lines(xx, predict(bg.frm, newdata = xx)[seq_along(xx)])
lines(xx, predict(bg.frm, newdata = xx)[-seq_along(xx)])
AIC(bg.frm, bg.add)
par(opar)


#### Analysis of 3-way MLCM data set
# additive model
T.mlcm &lt;- mlcm(Texture)
summary(T.mlcm)
plot(T.mlcm, type = "b")
# independent models
lapply(seq(1, 3), function(wh){ 
	m0 &lt;- mlcm(Texture, model = "ind", which = wh)
	anova(m0, T.mlcm, test = "Chisq")
	})
	
# Deviance differences for 2-way interactions vs 2-way additive models

mlcm(Texture[, -c(4, 5)])$obj$deviance - 
		mlcm(Texture[, -c(4, 5)], model = "full")$obj$deviance
mlcm(Texture[, -c(2, 3)])$obj$deviance - 
		mlcm(Texture[, -c(2, 3)], model = "full")$obj$deviance
mlcm(Texture[, -c(6, 7)])$obj$deviance - 
		mlcm(Texture[, -c(6, 7)], model = "full")$obj$deviance

# deviance differences for 3-way interaction tested against 3 2-way interactions
T3way.mlcm &lt;-  mlcm(Texture, model = "full")  
## construct model matrix from 3 2-way interactions
T3_2way.mf &lt;- cbind(model.frame(mlcm(Texture[, -c(4, 5)], model = "full")$obj), 
		model.matrix(mlcm(Texture[, -c(2, 3)], model = "full")$obj),
		model.matrix(mlcm(Texture[, -c(6, 7)], model = "full")$obj)
	)
T3_2way.mlcm &lt;- glm(Resp ~ . + 0, family = binomial(probit), data = T3_2way.mf) 
Chi2 &lt;- T3_2way.mlcm$deviance -  T3way.mlcm$obj$deviance
degfr &lt;- T3_2way.mlcm$df.residual -  T3way.mlcm$obj$df.residual
pchisq(Chi2, degfr, lower.tail = FALSE)
</code></pre>

<hr>
<h2 id='plot.mlcm'> Plot an mlcm Object </h2><span id='topic+plot.mlcm'></span><span id='topic+lines.mlcm'></span><span id='topic+points.mlcm'></span>

<h3>Description</h3>

<p>Plots the conjoint measurement scale(s) as a function of stimulus level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm'
plot(x, standard.scale = FALSE, transpose = FALSE, SD.scale = FALSE, ...)
## S3 method for class 'mlcm'
lines(x, standard.scale = FALSE, transpose = FALSE, SD.scale = FALSE, ...)
## S3 method for class 'mlcm'
points(x, standard.scale = FALSE, transpose = FALSE, SD.scale = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mlcm_+3A_x">x</code></td>
<td>
 <p><code>mlcm</code> object, typically result of <code>mlcm</code> </p>
</td></tr>
<tr><td><code id="plot.mlcm_+3A_standard.scale">standard.scale</code></td>
<td>
<p>logical indicating whether the plotted scales should be normalized so that the maximum scale value is 1 </p>
</td></tr>
<tr><td><code id="plot.mlcm_+3A_transpose">transpose</code></td>
<td>
<p>logical, indicating whether to transpose the matrix of the perceptual scale, when the full model is fit. Not defined if there are more than 2 dimensions.</p>
</td></tr>
<tr><td><code id="plot.mlcm_+3A_sd.scale">SD.scale</code></td>
<td>
<p>logical indicating whether to plot results in units of d', the signal detection measure of signal strength in which the variance for each stimulus level is unity.  Ignored if <code>standard.scale = TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.mlcm_+3A_...">...</code></td>
<td>
<p> other parameters to be passed through to the plotting function. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use <code>matplot</code>, <code>matlines</code> and <code>matpoints</code> so their help page should be examined for information on additional parameters that can be specified.
</p>


<h3>Author(s)</h3>

<p> Kenneth Knoblauch </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+matplot">matplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(mlcm(BumpyGlossy), type = "b")

bg.full &lt;- mlcm(BumpyGlossy, model = "full")
opar &lt;- par(mfrow = c(1, 2), pty = "s")
plot(bg.full, type = "b", 
	xlab = "Gloss Level",
	ylab = "Bumpiness Model Estimates")
plot(bg.full, transpose = TRUE, type = "b",
	xlab = "Bumpiness Level",
	ylab = "Glossiness Model Estimates")
par(opar)
</code></pre>

<hr>
<h2 id='plot.mlcm.df'>
Create Conjoint Proportion Plot from mlcm.df Object
</h2><span id='topic+plot.mlcm.df'></span>

<h3>Description</h3>

<p>Creates a conjoint proportions plot as in Ho et al. (2008) in which the proportion of responses of one type are indicated as a function of the stimulus pairs used in the experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm.df'
plot(x, clr = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.mlcm.df_+3A_x">x</code></td>
<td>
<p>object of class &lsquo;mlcm.df&rsquo; typically the result of a conjoint measurement experiment of 2 dimensions.
</p>
</td></tr>
<tr><td><code id="plot.mlcm.df_+3A_clr">clr</code></td>
<td>
<p>a palette for the color scale in the plot. If none specified, then a grey level palette will be calculated based on the maximum number of repetitions.
</p>
</td></tr>
<tr><td><code id="plot.mlcm.df_+3A_...">...</code></td>
<td>
<p>additional graphical parameters passed to <code>image</code> used for generating the plot.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input should be a data frame of class &lsquo;mlcm.df&rsquo; that contains 5 columns.  The first column contains the responses of the observer.  The next two correspond to the indices of the stimuli along the first dimensions and the last two the indices of the two stimuli along the second dimension.  The plot shows a color-coded (grey-level by default) map of the proportion of responses for each combination of indices in one stimulus with respect to the combinations of the indices in the other.  There should be several replications of each pairing for the plot to make some sense.
</p>


<h3>Value</h3>

<p>Currently, nothing is returned.  Used for its side-effect of producing a plot.
</p>


<h3>Note</h3>

<p>Will not work on experiments using more than 2 dimensions.
</p>


<h3>Author(s)</h3>

<p>Ken Knoblauch</p>


<h3>References</h3>

<p>Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+image">image</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(BumpyGlossy)
	plot(BumpyGlossy, 
		xlab = expression(paste("Surface ", S[ij], 
		" Gloss Level (i) and Bump level (j)")),
		ylab = expression(paste("Surface ", S[kl], 
		" Gloss Level (k) and Bump level (l)")) 
	)
</code></pre>

<hr>
<h2 id='predict.mlcm'>
Predict Method for MLCM Objects
</h2><span id='topic+predict.mlcm'></span>

<h3>Description</h3>

<p>Predict values based on conjoint measurment scale fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm'
predict(object, newdata = NULL, type = "link", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.mlcm_+3A_object">object</code></td>
<td>
<p>object of class &lsquo;mlcm&rsquo; usually created from running <code>mlcm</code>.
</p>
</td></tr>
<tr><td><code id="predict.mlcm_+3A_newdata">newdata</code></td>
<td>
<p>numeric vector of new data for which to predict scale values.  Only relevant when the <code>formula</code> method is used.
</p>
</td></tr>
<tr><td><code id="predict.mlcm_+3A_type">type</code></td>
<td>

<p>character indicating whether the predicted value should be on the &ldquo;link&rdquo; or &ldquo;response&rdquo; scale. Only relevant when the <code>glm</code> method is used.
</p>
</td></tr>
<tr><td><code id="predict.mlcm_+3A_...">...</code></td>
<td>

<p>Other parameters passed along to the <code>predict</code> method of <code>glm</code> when the <code>glm</code> method is used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For data sets fit with the <code>glm</code> method, the predicted values are returned either on the &ldquo;link&rdquo; or &ldquo;response&rdquo; scale.  For the <code>formula</code> method, predicted values are returned on the &ldquo;link&rdquo; scale.  The &ldquo;newdata&rdquo; argument is there for this case.
</p>


<h3>Value</h3>

<p>Numeric vector of predicted values.
</p>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlcm">mlcm</a></code>, <code><a href="#topic+fitted.mlcm">fitted.mlcm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bg.add &lt;- mlcm(BumpyGlossy)
bg.frm &lt;- mlcm(~ p[1] * (x - 1)^p[2] + p[3] * (y - 1)^p[4],
	p = c(0.1, 1.3, 1.6, 0.8), data = BumpyGlossy)
xx &lt;- seq(1, 5, len = 100)
plot(bg.add)
lines(xx, predict(bg.frm, newdata = xx)[seq_along(xx)])
lines(xx, predict(bg.frm, newdata = xx)[-seq_along(xx)])
</code></pre>

<hr>
<h2 id='summary.mlcm'> Summary Method for mlcm objects </h2><span id='topic+summary.mlcm'></span><span id='topic+print.summary.mlcm'></span>

<h3>Description</h3>

<p>Method functions for <code>mlcm</code> and <code>summary.glm</code> objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcm'
summary(object, digits = max(3, getOption("digits") - 4), ...)

## S3 method for class 'summary.mlcm'
print(x, digits = max(3, getOption("digits") - 4), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.mlcm_+3A_object">object</code></td>
<td>
<p> an object of class &ldquo;mlcm&rdquo;, a result of a call to <code>mlcm</code> </p>
</td></tr>
<tr><td><code id="summary.mlcm_+3A_x">x</code></td>
<td>
<p>an object of class &ldquo;summary.mlcm&rdquo;, usually a call to <code>summary.mlcm</code></p>
</td></tr>
<tr><td><code id="summary.mlcm_+3A_digits">digits</code></td>
<td>
<p> the number of significant digits to use when printing </p>
</td></tr>
<tr><td><code id="summary.mlcm_+3A_...">...</code></td>
<td>
<p> further arguments passed to or from other methods </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Displays summary information from a &ldquo;mlcm&rdquo; object.
</p>


<h3>Value</h3>

<p>A list of 5 elements
</p>
<table role = "presentation">
<tr><td><code>pscale</code></td>
<td>
<p>A named vector or matrix indicting the estimated scale values.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The estimate of the scale parameter, currently always set to 1.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>The logarithm of the likelihood.</p>
</td></tr>
<tr><td><code>link</code></td>
<td>
<p>The link used for the binomial family.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>A character string giving the name of the model fit.</p>
</td></tr>
</table>
<p>Normally, <code>print.summary.mlcm</code> is not meant to be called directly by the user.
</p>


<h3>Author(s)</h3>

<p>Kenneth Knoblauch</p>


<h3>References</h3>

<p>  Ho, Y. H., Landy. M. S.  and Maloney, L. T. (2008). Conjoint measurement of gloss and surface texture. <em>Psychological Science</em>, <b>19</b>, 196&ndash;204.</p>


<h3>See Also</h3>

  <p><code><a href="#topic+mlcm">mlcm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(mlcm(BumpyGlossy))
</code></pre>

<hr>
<h2 id='Texture'>
Three-way Conjoint Measurement Data for Texture Regularity.
</h2><span id='topic+Texture'></span>

<h3>Description</h3>

<p>Data from one subject, S1, for a 3-way MLCM experiment in which the element spacing, element size and  inter-element jitter of dot patterns were systematically varied.  Pairs of stimuli were presented with the 3 attributes varied independently, and the subject judged which of the pair appeared more regular.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Texture")</code></pre>


<h3>Format</h3>

<p>A data frame with 4140 observations on the following 7 variables.
</p>

<dl>
<dt><code>Resp</code></dt><dd><p>a numeric vector taking values 0/1 depending on whether the subject chose the first or second stimulus as more regular.</p>
</dd>
<dt><code>S1</code></dt><dd><p>a numeric vector indicating which of 3 levels of average element spacing for the first stimulus.</p>
</dd>
<dt><code>S2</code></dt><dd><p>a numeric vector indicating which of 3 levels of average element spacing for the second stimulus.</p>
</dd>
<dt><code>Z1</code></dt><dd><p>a numeric vector indicating which of 3 levels of element size for the first stimulus.</p>
</dd>
<dt><code>Z2</code></dt><dd><p>a numeric vector indicating which of 3 levels of element size for the second stimulus.</p>
</dd>
<dt><code>J1</code></dt><dd><p>a numeric vector indicating which of 5 levels of element jitter for the first stimulus.</p>
</dd>
<dt><code>J2</code></dt><dd><p>a numeric vector indicating which of 5 levels of element jitter for the second stimulus.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The authors describe the data sets as follows.  Each participant completed 4140 experimental trials, as shown in the 4140 rows: Column 1: response value. 0: participant chose stimulus 1 of a pair as more regular. 1: participant chose stimulus 2 as more regular. Column 2: element spacing level (1&ndash;3) for stimulus 1. Column 3: element spacing level (1&ndash;3) for stimulus 2. Column 4: element size level (1&ndash;3) for stimulus 1. Column 5: element size level (1&ndash;3) for stimulus 2. Column 6: element jitter level (1&ndash;5) for stimulus 1. Column 7: element jitter level (1&ndash;5) for stimulus 2. Note, the trial order was randomized during the experiment.
</p>
<p>Additional data files for the other 5 participants in the study can be found in csv format files at
doi: <a href="https://doi.org/10.1371/journal.pcbi.1008802">10.1371/journal.pcbi.1008802</a>.  With respect to the original file, the current data set was modified to include column names.
</p>
<p>A fuller analysis of this data set can be found in the examples at <code><a href="#topic+mlcm">mlcm</a></code>.
</p>


<h3>Source</h3>

<p>Sun H.-C., St-Amand D., Baker C. L. Jr, Kingdom F. A. A. (2021), Visual perception of texture regularity: Conjoint measurements and a wavelet response-distribution model. <em>PLoS Computational Biology</em> <b>17(10)</b>, e1008802. doi: <a href="https://doi.org/10.1371/journal.pcbi.1008802">10.1371/journal.pcbi.1008802</a>.
</p>


<h3>References</h3>

<p>Knoblauch K., Maloney L. T. (2012) Modeling Psychophysical Data in R, Springer Science \&amp; Business Media, doi: <a href="https://doi.org/10.1007/978-1-4614-4475-6">10.1007/978-1-4614-4475-6</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Texture)
# additive model fit
Texture.mlcm &lt;- mlcm(Texture)
summary(Texture.mlcm)
plot(Texture.mlcm, type = "b")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
