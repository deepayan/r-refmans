<!DOCTYPE html><html><head><title>Help for package EntropyMCMC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EntropyMCMC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EntropyMCMC-package'><p>(A)MCMC Simulation and Convergence Evaluation using Entropy and</p>
Kullback-Leibler Divergence  Estimation</a></li>
<li><a href='#accept_ratio'><p>Acceptance ratio for Hastings-Metropolis simulated MCMC chains</p></a></li>
<li><a href='#CollectChains'><p>Collect MCMC chains in a single object</p></a></li>
<li><a href='#DrawInit'><p>Random draws for initialization</p></a></li>
<li><a href='#EntropyMCMC'><p>Kullback and entropy estimation from MCMC simulation output -</p>
single and multicore versions</a></li>
<li><a href='#EntropyMCMC-internal'><p>Internal 'EntropyMCMC' Functions</p></a></li>
<li><a href='#EntropyParallel'><p>Parallel simulation and Entropy estimation of MCMC's</p>
- single core and cluster versions</a></li>
<li><a href='#gaussian_pdf'><p>Proposal density evaluation and simulation</p></a></li>
<li><a href='#MCMCcopies'><p>Simulates iid copies of a MCMC algorithm</p></a></li>
<li><a href='#MCMCcopies.cl'><p>Parallel simulation of iid copies of a MCMC algorithm - cluster versions</p></a></li>
<li><a href='#MCMCcopies.mc'><p>Simulates iid copies of a MCMC algorithm - multicore version</p></a></li>
<li><a href='#normEntropy'><p>Theoretical value of the entropy for the multivariate gaussian</p></a></li>
<li><a href='#plot_Kblist'>
<p>Plot sequences of Kullback distance estimates for comparison of several MCMC algorithms for a same target density</p></a></li>
<li><a href='#plot.KbMCMC'><p>Plot sequences of estimates of Kullback distance or Entropy against iterations</p></a></li>
<li><a href='#plot.plMCMC'>
<p>Plot paths of copies of Markov chains</p></a></li>
<li><a href='#plottarget3d'><p>3D plot of a two-dimensional  MCMC target, or any function</p></a></li>
<li><a href='#RWHM_chain'><p>Simulating MCMC single chains using MCMC algorithms</p></a></li>
<li><a href='#summary.plMCMC'><p>Summarizes content of a <code>plMCMC</code> object</p>
holding iid copies of MCMC's</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>MCMC Simulation and Convergence Evaluation using Entropy and
Kullback-Leibler Divergence Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-03-08</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for Markov Chain Monte Carlo (MCMC) simulation and performance analysis. Simulate MCMC algorithms including adaptive MCMC, evaluate their convergence rate, and compare candidate MCMC algorithms for a same target density, based on entropy and Kullback-Leibler divergence criteria. MCMC algorithms can be simulated using provided functions, or imported from external codes. This package is based upon work starting with Chauveau, D. and Vandekerkhove, P. (2013) &lt;<a href="https://doi.org/10.1051%2Fps%2F2012004">doi:10.1051/ps/2012004</a>&gt; and next articles.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RANN, parallel, mixtools</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rmpi, snow</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Didier Chauveau [aut, cre],
  Houssam Alrachid [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Didier Chauveau &lt;didier.chauveau@univ-orleans.fr&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-08 16:27:10 UTC; didier</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-08 17:22:51 UTC</td>
</tr>
</table>
<hr>
<h2 id='EntropyMCMC-package'>(A)MCMC Simulation and Convergence Evaluation using Entropy and
Kullback-Leibler Divergence  Estimation</h2><span id='topic+EntropyMCMC-package'></span>

<h3>Description</h3>

<p>Contains functions to analyse (Adaptive) Markov Chain Monte Carlo (MCMC) algorithms, evaluate their convergence rate, and compare candidate MCMC algorithms for a same target density, based on entropy and Kullback-Leibler divergence criteria. MCMC algorithms can be simulated using provided functions, or imported from external codes.
The diagnostics are based on consistent estimates of entropy and Kulback distance 
between the density at
iteration <code class="reqn">t</code> and the target density <code class="reqn">f</code>, based on iid (parallel) chains.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> EntropyMCMC</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0.4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2019-03-08</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 3)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p><b>Statistical background:</b>
</p>
<p>This package allows for simulation of standard or adaptive MCMC samplers for a user-defined
target density, and provides statistical tools to evaluate convergence of MCMC's 
and compare performance of algorithms for the same target density
(typically against benchmark samplers).
</p>
<p>The criteria are graphical and based on plots against iterations (time) <code class="reqn">t</code>,
of the <em>Kullback divergence</em> 
<code class="reqn">K(p^t,f)</code>
between the density <code class="reqn">p^t</code> of the MCMC algorithm at time <code class="reqn">t</code>, 
and the target density <code class="reqn">f</code>, for <code class="reqn">t=1</code> up to the number of iterations 
that have been simulated.
This requires estimation of the  entropy of  <code class="reqn">p^t</code>,
</p>
<p style="text-align: center;"><code class="reqn">E_{p^t} [\log(p^t)],</code>
</p>

<p>and of the external entropy  
</p>
<p style="text-align: center;"><code class="reqn">E_{p^t} [\log(f)].</code>
</p>

<p>Consistent estimates are computed based on <code class="reqn">N</code> iid (parallel) chains, 
since the <code class="reqn">N</code> positions of the chains at iterations <code class="reqn">t</code> 
forms a <code class="reqn">N</code>-iid sample from the density <code class="reqn">p^t</code>.
</p>
<p><b>Computational considerations:</b>
</p>
<p>The simulation of iid chains can be performed in this package, which provides a mechanism 
for defining (A)MCMC algorithms and building the iid chains required for convergence evaluation.
Each MCMC algorithm is defined by a list with five elements.
Each user can define its own MCMC, starting from the standard MCMC algorithms
that are already defined:
</p>

<ul>
<li> <p><code>RWHM</code>: a standard Randow-Walk Hastings-Metropolis (HM) algorithm.
</p>
</li>
<li> <p><code>HMIS_norm</code>: an Independence Sampler HM with gaussian proposal
</p>
</li>
<li> <p><code>AMHaario</code>: the
Haario (2001) Adaptive Hastings-Metropolis algorithm, provided as an example 
of a standard AMCMC.
</p>
</li>
<li> <p><code>IID_norm</code>: a &ldquo;fake&rdquo; MCMC that is just a gaussian IID sampler, used mostly
for testing purpose. Simulation of <code class="reqn">N</code> iid chains for <code class="reqn">n</code> iterations using this algorithm just returns <code class="reqn">N\times n</code> gaussian <code class="reqn">d</code>-dimensional vectors.
</p>
</li></ul>

<p>Functions for doing the simulations and the convergence evaluation
automatically using these algorithms in their first argument are provided.
Two strategies are available:
</p>

<ul>
<li> <p><em>Simulation and Kullback estimation separately:</em>
A &ldquo;cube&rdquo; of <code class="reqn">N</code> chains for <code class="reqn">n</code> iterations in a space of dimension <code class="reqn">d</code>
is first simulated and stored using <code><a href="#topic+MCMCcopies">MCMCcopies</a></code> or its multicore or cluser versions, 
then the entropy and Kullback divergence 
are estimated from that object using <code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code> or its multicore version.
</p>
</li>
<li> <p><em>Simulation and Kullback estimation simultaneously:</em>
For each iteration <code class="reqn">t</code>, the next step of all the  <code>N</code>
chains are generated,
then the Entropy and Kullback divergence <code class="reqn">K(p^t,f)</code>
are estimated, and the past of the parallel chains 
is discarded so that the amount of memory requirement is kept small, and
only entropy-related estimates are stored and returned. Functions for this strategy are
<code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and its multicore and cluster version.
</p>
</li></ul>

<p>See the Examples section of <code><a href="#topic+plot_Kblist">plot_Kblist</a></code> for an illustration of these two methods.
</p>
<p><b>Doing the simulations outside from this package</b>
</p>
<p>A third hybrid strategy is also available:
the simulation of iid chains can be done using an external code
(in <span class="rlang"><b>R</b></span>, <code>C</code> or any language) and imported 
in the <span class="pkg">EntropyMCMC</span> package (defining an object of the appropriate class 
<code>"plMCMC"</code> and structure, see <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>).
</p>
<p>Then the Kullback divergence criterion can be computed using <code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code> 
or its multicore version, and convergence/comparison diagnostics can be displayed 
using the associated <code>plot</code> method.
</p>
<p><b>About High Performance Computing</b>
</p>
<p>The required simulations can be done using singlecore or
HCP (multicore computers, snow or clusters using the <span class="pkg"><a href="lattice.html#topic+parallel">parallel</a></span> or
<span class="pkg">Rmpi</span> pakages). Note that the <span class="pkg"><a href="lattice.html#topic+parallel">parallel</a></span> package using socket cluster is not 
available on Windows machines.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau,
Institut Denis Poisson, 
University of Orleans, CNRS, Orleans France.
<a href="https://www.idpoisson.fr/chauveau/">https://www.idpoisson.fr/chauveau/</a>
</p>
<p>Maintainer: Didier Chauveau <a href="mailto:didier.chauveau@univ-orleans.fr">didier.chauveau@univ-orleans.fr</a>
</p>
<p>Contributor: Houssam Alrachid
</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>


<hr>
<h2 id='accept_ratio'>Acceptance ratio for Hastings-Metropolis simulated MCMC chains</h2><span id='topic+accept_ratio'></span>

<h3>Description</h3>

<p>Internal function for the package <code>EntropyMCMC</code>, computes the acceptance ratio required in the definition of any Hastings-Metropolis algorithm.</p>


<h3>Usage</h3>

<pre><code class='language-R'>accept_ratio(x, y, target, q_pdf, f_param, q_param, symmetric = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accept_ratio_+3A_x">x</code></td>
<td>
<p>The current position.
</p>
</td></tr>
<tr><td><code id="accept_ratio_+3A_y">y</code></td>
<td>
<p>The next (proposal) position.
</p>
</td></tr>
<tr><td><code id="accept_ratio_+3A_target">target</code></td>
<td>

<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
Target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code>.
</p>
</td></tr>
<tr><td><code id="accept_ratio_+3A_q_pdf">q_pdf</code></td>
<td>
<p>The  density of the proposal.
</p>
</td></tr>
<tr><td><code id="accept_ratio_+3A_f_param">f_param</code></td>
<td>

<p>A list holding all the necessary target parameters, 
consistent with the target definition.
</p>
</td></tr>
<tr><td><code id="accept_ratio_+3A_q_param">q_param</code></td>
<td>

<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm <code>mcmc_algo</code>.
</p>
</td></tr>
<tr><td><code id="accept_ratio_+3A_symmetric">symmetric</code></td>
<td>

<p>If <code>TRUE</code>, the proposal <code>q_pdf</code> is symmetric which simplifies the acceptance ratio compuatation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>accept_ratio</code> is used to decide whether to accept or reject a candidate 
<code class="reqn">y</code>. The acceptance ratio indicates how probable the new proposed candidate is with respect to the current candidate <code class="reqn">x</code>, according to the distribution <code>target</code>.
</p>


<h3>Value</h3>

<p><code>accept_ratio</code> returns a real value <code>alpha</code>, which indicates the computed value of the current <code>accept_ratio</code>.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau, Houssam Alrachid.</p>

<hr>
<h2 id='CollectChains'>Collect MCMC chains in a single object</h2><span id='topic+CollectChains'></span>

<h3>Description</h3>

<p>Utility function for the package <span class="pkg">EntropyMCMC</span>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CollectChains(s)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CollectChains_+3A_s">s</code></td>
<td>
<p> An object of class <code>plMCMC</code>, such as the one 
returned by <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, containing in particular an array of dimension 
<code class="reqn">(n,d,nmc)</code>
holding the simulation of <code class="reqn">n</code> steps of <code class="reqn">nmc</code> parallel chains in dimension <code class="reqn">d</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Concatenates all simulated copies together in one matrix of dimension <code>(n*nmc,d)</code>.</p>


<h3>Value</h3>

<p>Returns a matrix of dimension <code>(n*nmc,d)</code>.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>

<hr>
<h2 id='DrawInit'>Random draws for initialization</h2><span id='topic+DrawInit'></span>

<h3>Description</h3>

<p>Utility function for the package <span class="pkg">EntropyMCMC</span>, for generating random 
starting positions for the parallel Markov chains, used by, e.g., 
<code><a href="#topic+MCMCcopies">MCMCcopies</a></code> or <code><a href="#topic+EntropyParallel">EntropyParallel</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawInit(nmc, d, initpdf="rnorm", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawInit_+3A_nmc">nmc</code></td>
<td>
<p>Number of parallel chains = initial points.
</p>
</td></tr>
<tr><td><code id="DrawInit_+3A_d">d</code></td>
<td>
<p>Space dimension.
</p>
</td></tr>
<tr><td><code id="DrawInit_+3A_initpdf">initpdf</code></td>
<td>
<p>Random generator. Generators currently implemented are: &quot;rnorm&quot; as the Normal distribution and &quot;runif&quot; as the uniform distribution.
</p>
</td></tr>
<tr><td><code id="DrawInit_+3A_...">...</code></td>
<td>
<p>Parameters passed to initpdf</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>DrawInit</code> returns a matrix of dimension (nmc,d) where each row is a
<code class="reqn">d</code>-dimensional point.
</p>


<h3>Note</h3>

<p>It is better for mixing properties to use diffuse initial distributions, such as the one 
proposed here. However Dirac initial points can also be used, precisely to evaluate the 
efficiency of a MCMC to escape from a wrong initial position (e.g., in the tails of the target density).</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>See Also</h3>

<p><code><a href="#topic+MCMCcopies">MCMCcopies</a></code> and 
<code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code> for iid MCMC simulations,
<code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and <code><a href="#topic+EntropyParallel.cl">EntropyParallel.cl</a></code>
for simultaneous simulation and entropy estimation.</p>


<h3>Examples</h3>

<pre><code class='language-R'>Ptheta0 &lt;- DrawInit(10, 5, initpdf="rnorm", mean=0, sd=5)
</code></pre>

<hr>
<h2 id='EntropyMCMC'>Kullback and entropy estimation from MCMC simulation output - 
single and multicore versions</h2><span id='topic+EntropyMCMC'></span><span id='topic+EntropyMCMC.mc'></span>

<h3>Description</h3>

<p>These functions return estimates of the entropy 
of the density <code class="reqn">p^t</code> of a MCMC algorithm at time <code class="reqn">t</code>, 
<code class="reqn">E_{p^t}[\log(p^t)]</code>,
and of the Kullback divergence between <code class="reqn">p^t</code> and the target density,
for <code class="reqn">t=1</code> up to the number of iterations that have been simulated. 
The MCMC simulations must be computed before or externally, 
and passed as a &quot;<code>plMCMC</code>&quot; object 
in the first argument (see details).
The target may be known only up to a multiplicative constant (see details).
</p>
<p><code><a href="#topic+EntropyMCMC.mc">EntropyMCMC.mc</a></code> is a parallel computing
version  that uses the
<span class="pkg"><a href="lattice.html#topic+parallel">parallel</a></span> package to split the task between the available (virtual) cores on the computer. This version using socket cluster is not available for Windows computers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EntropyMCMC(plmc1, method = "A.Nearest.Neighbor", k=1, trim = 0.02, eps=0, 
        all.f = TRUE, verb = FALSE, EntVect = FALSE,
        uselogtarget = FALSE, logtarget = NULL)

EntropyMCMC.mc(plmc1, method = "A.Nearest.Neighbor", k = 1, trim = 0.02, eps=0,
        all.f = TRUE, verb = FALSE, EntVect = FALSE, nbcores=detectCores(), 
		    uselogtarget = FALSE, logtarget = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EntropyMCMC_+3A_plmc1">plmc1</code></td>
<td>
<p>an objects of class <code>plMCMC</code> 
(for parallel MCMC), like the output of <code>MCMCcopies</code>,
which contains all the simulations plus target <code class="reqn">f</code> definition and parameters.</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_method">method</code></td>
<td>
<p>The method for estimating the entropy <code class="reqn">E_{p^t}[\log(p^t)]</code>. 
Methods currently  implemented are :
<code>"NearestNeighbor"</code> as in Kozachenko and Leonenko (1987),  
<code>"k.NearestNeighbor"</code> as in Leonenko et al. (2005), 
<code>"A.Nearest.Neighbor"</code> (the default) which is as 
<code>"k.NearestNeighbor"</code> but uses the <span class="pkg">RANN</span> package for (Approximate) fast computation of nearest neighbors,
<code>"Gyorfi.trim"</code> subsampling method as defined in Gyorfi and Vander Mulen (1989), 
plus a tuning parameter <code>trim</code> for trimming the data 
(see Chauveau and Vandekerkhove (2011)).</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_k">k</code></td>
<td>
<p>The k-nearest neighbor index, the default is <code class="reqn">k=1</code>.</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_trim">trim</code></td>
<td>
<p>Parameter controlling the percentage of smallest data from one subsample
that is removed, only for <code>method = "Gyorfi.trim"</code>.</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_eps">eps</code></td>
<td>
<p>A parameter controlling precision in the <code>"A.Nearest.Neighbor"</code>&quot; method, 
the default means no approximation, see the <span class="pkg">RANN</span> package.</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_all.f">all.f</code></td>
<td>
<p>If <code>TRUE</code> (the default) relative entropy is computed
over the whole sample. Should be removed in next version.</p>
</td></tr>  	 
<tr><td><code id="EntropyMCMC_+3A_verb">verb</code></td>
<td>
<p>Verbose mode</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_entvect">EntVect</code></td>
<td>
<p>If <code>FALSE</code> (the default), the entropy is computed only on the kth-nearest neighbor. If <code>TRUE</code>,  the entropy is computed for all j-NN's for <code class="reqn">j=1</code> to <code class="reqn">k</code> (the latter being mostly for testing purposes).</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_nbcores">nbcores</code></td>
<td>
<p>Number of required (virtual) cores, defaults to all as returned
by <code>detectCores()</code>.</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_uselogtarget">uselogtarget</code></td>
<td>
<p>Set to <code>FALSE</code> by default; 
useful in some cases where <code class="reqn">log(f(\theta))</code> returns <code>-Inf</code> values in 
Kullback computations because   
<code class="reqn">f(\theta)</code> itself returns too small values for some <code class="reqn">\theta</code> far from modal regions.
In these case using a function computing the logarithm of the target 
can remove the infinity values.</p>
</td></tr>
<tr><td><code id="EntropyMCMC_+3A_logtarget">logtarget</code></td>
<td>
<p>The function defining <code class="reqn">log(f(theta))</code>, <code>NULL</code> by default, 
required if <code>uselogtarget</code> equals <code>TRUE</code>.
This option and <code>uselogtarget</code> are currently implemented only for the 
<code>"A.Nearest.Neighbor"</code> method,
and for the default <code>EntVect = FALSE</code> option.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods based on  Nearest Neighbors (NN) should be preferred since these require less tuning parameters. 
Some options, as <code>uselogtarget</code> are in testing phase and are not implemented in all the available methods (see Arguments). 
</p>


<h3>Value</h3>

<p>An object of class <code>KbMCMC</code> (for Kullback MCMC), containing:
</p>
<table>
<tr><td><code>Kullback</code></td>
<td>
<p>A vector of estimated divergences <code class="reqn">K(p^t,f)</code>, 
for <code class="reqn">t=1</code> up to the number of iterations that have been simulated. 
This is the convergence/comparison criterion.</p>
</td></tr>
<tr><td><code>Entp</code></td>
<td>
<p>A vector of estimated entropies <code class="reqn">E_{p^t}[\log(p^t)]</code>, 
for <code class="reqn">t=1</code> up to the number of iterations that have been simulated.</p>
</td></tr>
<tr><td><code>nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>The state space dimension of the MCMC algorithm.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>The name of the MCMC algorithm that have been used to simulate
the copies of chains, see <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
ususally given only up to a multiplicative constant for MCMC in Bayesian models. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in the example below.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The <code>method</code> input parameter (see above).</p>
</td></tr>
<tr><td><code>f_param</code></td>
<td>
<p>A list holding all the necessary target parameters, 
consistent with the target definition.</p>
</td></tr>
<tr><td><code>q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm that have been used.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The method <code>"Resubst"</code> is implemented for testing, without theoretical guarantee of convergence.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau, Houssam Alrachid.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+MCMCcopies">MCMCcopies</a></code> and 
<code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code> for iid MCMC simulations (single core and multicore),
<code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and <code><a href="#topic+EntropyParallel.cl">EntropyParallel.cl</a></code>
for simultaneous simulation and entropy estimation (single core and multicore).</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Toy example using the bivariate gaussian target
## with default parameters value, see target_norm_param
n = 150; nmc = 50; d=2 # bivariate example
varq=0.1 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 
# simulation of the nmc iid chains, singlecore 
s1 &lt;- MCMCcopies(RWHM, n, nmc, Ptheta0, target_norm,
                 target_norm_param, q_param, verb = FALSE)
summary(s1) # method for "plMCMC" object
e1 &lt;- EntropyMCMC(s1) # computes Entropy and Kullback divergence estimates
par(mfrow=c(1,2))
plot(e1) # default plot.plMCMC method, convergence after about 80 iterations
plot(e1, Kullback = FALSE) # Plot Entropy estimates over time
abline(normEntropy(target_norm_param), 0, col=8, lty=2) # true E_f[log(f)]
</code></pre>

<hr>
<h2 id='EntropyMCMC-internal'>Internal 'EntropyMCMC' Functions</h2><span id='topic+AMHaario'></span><span id='topic+RWHM'></span><span id='topic+IID_norm'></span><span id='topic+HMIS_norm'></span><span id='topic+IID_step'></span><span id='topic+HM_step'></span><span id='topic+RWHM_step'></span><span id='topic+q_pdf_ISnorm'></span><span id='topic+q_proposal_ISnorm'></span><span id='topic+target_norm'></span><span id='topic+target_norm_param'></span><span id='topic+mvkde'></span><span id='topic+mvwkde'></span><span id='topic+cutTask.mc'></span><span id='topic+ellipse'></span><span id='topic+mvbw'></span><span id='topic+RmseEnt'></span><span id='topic+logdmvnorm'></span><span id='topic+dist.fun'></span><span id='topic+entropyNNC'></span><span id='topic+Entropy.ANN'></span><span id='topic+Entropy.ANN.mc'></span><span id='topic+Entropy.ANN.vect'></span><span id='topic+Entropy.ANN.vect.mc'></span><span id='topic+Entropy.Gf'></span><span id='topic+Entropy.NN'></span><span id='topic+Entropy.NN.mc'></span><span id='topic+Entropy.Resubst'></span><span id='topic+Entropy.kNN'></span><span id='topic+Entropy.kNN.mc'></span><span id='topic+Entropy.kNN.vect'></span><span id='topic+Entropy.kNN.vect.mc'></span>

<h3>Description</h3>

<p>Various internal functions 
for the package <span class="pkg">EntropyMCMC</span>; usage for some of these
are displayed below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>target_norm(x, param)
RWHM_step(theta, target, q_pdf = gaussian_pdf, 
          q_proposal = gaussian_proposal, f_param, q_param, nba)
HM_step(theta, target, q_pdf, q_proposal, 
          f_param, q_param, nba)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EntropyMCMC-internal_+3A_x">x</code></td>
<td>
<p>a vector of values, or objects.</p>
</td></tr>
<tr><td><code id="EntropyMCMC-internal_+3A_target">target</code></td>
<td>
<p>a target  density definition.</p>
</td></tr>
<tr><td><code id="EntropyMCMC-internal_+3A_param">param</code></td>
<td>
<p>target - or proposal -  density parameters (including data in a Bayesian model.</p>
</td></tr>
<tr><td><code id="EntropyMCMC-internal_+3A_f_param">f_param</code></td>
<td>
<p>target density parameters (including data in a Bayesian model.</p>
</td></tr>
<tr><td><code id="EntropyMCMC-internal_+3A_q_param">q_param</code></td>
<td>
<p>proposal density parameters.</p>
</td></tr>
<tr><td><code id="EntropyMCMC-internal_+3A_theta">theta</code></td>
<td>
<p>the <code class="reqn">d</code>-dimensional parameter of the Markov chain.</p>
</td></tr>
<tr><td><code id="EntropyMCMC-internal_+3A_nba">nba</code></td>
<td>
<p>number of accepted moves along simulation, for HAstings-Metropolis MCMC's</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions and objects (lists) are usually not to be called by the user.
</p>

<hr>
<h2 id='EntropyParallel'>Parallel simulation and Entropy estimation of MCMC's
- single core and cluster versions
</h2><span id='topic+EntropyParallel'></span><span id='topic+EntropyParallel.cl'></span>

<h3>Description</h3>

<p>This function simulates &ldquo;parallel chains&rdquo; (iid copies) 
of a MCMC algorithm, i.e.
for each &ldquo;time&rdquo; iteration <code class="reqn">t</code> the next step of all the  <code>nmc</code>
chains are generated,
then the Entropy of the density <code class="reqn">p^t</code> of the algorithm at iteration
<code class="reqn">t</code>, 
<code class="reqn">E_{p^t}[\log(p^t)]</code>,
and the Kullback divergence between <code class="reqn">p^t</code> and the target density
are estimated, based on these <code>nmc</code> steps iid from <code class="reqn">p^t</code>.
By default <code>keep.all = FALSE</code> i.e. the past of the parallel chains 
is discarded so that the amount of memory requirement is kept small, and
only entropy-related estimates are returned. 
If <code>keep.all = TRUE</code>, the entire set of chains trajectories
is saved in an array of dimensions <code>(n,d,nmc)</code>, such as the one
returned by <code><a href="#topic+MCMCcopies">MCMCcopies</a></code> or <code><a href="#topic+MCMCcopies.cl">MCMCcopies.cl</a></code>.
</p>
<p>A version of this function implementing several HPC (parallel) computing
strategies is available (see details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EntropyParallel(mcmc_algo, n = 100, nmc = 10, Ptheta0, target, f_param, q_param,
          method = "A.Nearest.Neighbor",k=1, trim = 0.02, keep.all = FALSE,
          verb = TRUE, EntVect = FALSE)

EntropyParallel.cl(mcmc_algo, n = 100, nmc = 10, Ptheta0, target, f_param, q_param,
          method = "A.Nearest.Neighbor",k=1, eps = 0, trim=0.02,
          verb=TRUE, EntVect = FALSE, cltype="PAR_SOCK", nbnodes = 4,
          par.logf = FALSE, uselogtarget = FALSE, logtarget = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EntropyParallel_+3A_mcmc_algo">mcmc_algo</code></td>
<td>
<p>a list defining an MCMC algorithm in terms of the 
functions it uses, such as <code>RWHM</code>, see details below.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_n">n</code></td>
<td>
<p>The number of (time) iterations of each single chain to run.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_nmc">nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_ptheta0">Ptheta0</code></td>
<td>
<p>A <code>(nmc,d)</code> matrix, with the ith row giving a d-dimensional 
initial theta values for the ith chain.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_target">target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in the example below.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_f_param">f_param</code></td>
<td>
<p>A list holding all the necessary target parameters,
including the data in an actual Bayesian model, and
consistent with the target definition.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_q_param">q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm <code>mcmc_algo</code>.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_method">method</code></td>
<td>
<p>The method for estimating the entropy 
<code class="reqn">E_{p^t}[\log(p^t)]</code>. 
The methods currently  implemented for this function are
<code>"Nearest.Neighbor"</code> as in Kozachenko and Leonenko (1987), 
<code>"k.Nearest.Neighbor"</code> as in      
Leonenko et al. (2005) (the default in the single core version),	and 
<code>"A.Nearest.Neighbor"</code> which is as <code>"k.NearestNeighbor"</code> using the
<span class="pkg">RANN</span> package for (Approximate) fast computation of nearest neighbors, 
instead of R code (the default for the cluster version).
Other methods such as  <code>"Gyorfi.trim"</code> subsampling method as defined in 
Gyorfi and Vander Mulen (1989) are available as well
(see Chauveau and Vandekerkhove (2012)).</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_k">k</code></td>
<td>
<p>The k-nearest neighbor index, the default is <code class="reqn">k=1</code>.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_eps">eps</code></td>
<td>
<p>Error bound: default of 0.0 implies exact nearest neighbour search, see
the <span class="pkg">RANN</span> package.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_trim">trim</code></td>
<td>
<p>not used in this implementation, only for <code>method="Gyorfi.trim"</code></p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_keep.all">keep.all</code></td>
<td>
<p>If <code>TRUE</code>, all the simulated chains are stored in a 3-dimensional
array of dimensions <code>(n,d,nmc)</code>, such as the one returned by
<code><a href="#topic+MCMCcopies">MCMCcopies</a></code></p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_verb">verb</code></td>
<td>
<p>Verbose mode for summarizing output during the simulation.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_entvect">EntVect</code></td>
<td>
<p>If <code>FALSE</code> (the default), the entropy is computed only on the kth-nearest neighbor. If <code>TRUE</code>,  the entropy is computed for all j-NN's for <code class="reqn">j=1</code> to <code class="reqn">k</code> (the latter being mostly for testing purposes).</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_cltype">cltype</code></td>
<td>
<p>Character string specifying the type of cluster; 
currently implemented 
types are: &quot;PAR_SOCK&quot; for socket cluster with <code>parallel</code> library, the default;
&quot;SNOW_SOCK&quot; for socket cluster with <code>snow</code> library, and
&quot;SNOW_RMPI&quot; for <code>snow</code> MPI cluster with <code>Rmpi</code> library.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_nbnodes">nbnodes</code></td>
<td>
<p>The number of nodes or virtual cores requested to run the <code>nmc</code>
simulations in parallel. For the snow version, defaults to all; 
for the cluster version, defaults to 4.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_par.logf">par.logf</code></td>
<td>
<p>if <code>TRUE</code>, then the computation of the log of the target density
at each of the  <code>nmc</code> chain locations, needed for the NN procedure is also
executed in parallel using <code>parRapply()</code>. 
This may speed up the process if the target is complicated
i.e. takes some time to evaluate. If the target is simple enough
(like <code>target_norm</code>), then communications between nodes are slower than
computations, in which case <code>par.logf = FALSE</code> (the default) should be preferred.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_uselogtarget">uselogtarget</code></td>
<td>
<p>Set to <code>FALSE</code> by default; 
useful in some cases where <code class="reqn">log(f(\theta))</code> returns <code>-Inf</code> values in 
Kullback computations because   
<code class="reqn">f(\theta)</code> itself returns too small values for some <code class="reqn">\theta</code> far from modal regions.
In these case using a function computing the logarithm of the target can remove the infinity values.</p>
</td></tr>
<tr><td><code id="EntropyParallel_+3A_logtarget">logtarget</code></td>
<td>
<p>The function defining <code class="reqn">log(f(theta))</code>, <code>NULL</code> by default, 
required if <code>uselogtarget</code> equals <code>TRUE</code>.
This option and <code>uselogtarget</code> are currently implemented only for the &quot;A.Nearest.Neighbor&quot; method,
and for the default <code>EntVect = FALSE</code> option.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>About parallel computing:</b>
</p>
<p>For the HPC (parallel) version, the computation of the <code>nmc</code> chains next step
are done by the cluster nodes:
<code>EntropyParallel.cl</code> is a generic <em>cluster</em> version implementing 
several types of cluster for running on a single, multicore computer
or on a true cluster using MPI communications. It is under development and may not 
work on all platform/OS. For instance the parallel socket cluster version 
does not work on Windows machines (see the <span class="pkg">parallel</span> package documentation).
Currently tested under LINUX, Mac OSX, and a cluster
using OpenMPI and Sun Grid Engine.
</p>
<p>Note that the parallel computing for this approach is less efficient 
than the two-steps procedure consisting in 
(i) parallel simulation of the iid chains using <code><a href="#topic+MCMCcopies.cl">MCMCcopies.cl</a></code> to generate the 
&ldquo;cube&rdquo; of simulated values,
and then (ii) entropy and Kullback estimation using <code><a href="#topic+EntropyMCMC.mc">EntropyMCMC.mc</a></code>.
This is because  each node computes only one iteration at a time for the <code>nmc</code> chains
here, whereas it computes all the <code class="reqn">n</code> iterations once for the <code>nmc</code> chains
when the entire cube is saved first. This is a trade-off between memory and speed.
</p>
<p>Note also that the <code>Rmpi</code> option is less efficient than the default option
using <span class="pkg">parallel</span> if you are running on a single computer. 
MPI communication are required only for running on a true cluster/grid.
</p>
<p><b>About passing your MCMC algorithm:</b>
</p>
<p>The list <code>mcmc_algo</code> must contain the named elements:
</p>

<ul>
<li> <p><code>name</code>, the name of the MCMC, such as &quot;RWHM&quot;
</p>
</li>
<li> <p><code>chain</code>, the function for simulation of n steps of a single chain
</p>
</li>
<li> <p><code>step</code>, the function for simulation of 1 step of that algorithm
</p>
</li>
<li> <p><code>q_pdf</code>, the density of the proposal
</p>
</li>
<li> <p><code>q_proposal</code>, the function that simulates a proposal
</p>
</li></ul>

<p>For examples, see the algorithms currently implemented:
<code>RWHM</code>, the Random Walk Hasting-Metropolis with gaussian proposal;
<code>HMIS_norm</code>, an Independence Sampler HM with gaussian proposal;
<code>IID_norm</code>, a gaussian iid sampler which is merely 
a &quot;fake&quot; MCMC for testing purposes. 
</p>
<p>Currently only non-adaptive Markov chains or adaptive chains for which
the past can be summarized by some sufficient statistics are eligible for this
computation forgetting the past of the <code>nmc</code> chains.
Adaptive chains such as <code>AMHaario</code>, the Adaptive-Metropolis (AM) from Haario (2001) are 
not yet tested for this function.
</p>


<h3>Value</h3>

<p>An object of class <code>"KbMCMC"</code>, containing
</p>
<table>
<tr><td><code>Kullback</code></td>
<td>
<p>A vector of estimated <code class="reqn">K(p^t,f)</code>, 
for <code class="reqn">t=1</code> up to the number of iterations <code>n</code>. This is the 
convergence/comparison criterion.</p>
</td></tr>
<tr><td><code>Entp</code></td>
<td>
<p>A vector of estimated <code class="reqn">E_{p^t}[\log(p^t)]</code>, 
for <code class="reqn">t=1</code> up to the number of iterations that have been simulated.</p>
</td></tr>
<tr><td><code>nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>The state space dimension of the MCMC algorithm.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>The name of the MCMC algorithm that have been used to simulate
the copies of chains, see <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in this example.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The <code>method</code> input parameter (see above).</p>
</td></tr>
<tr><td><code>f_param</code></td>
<td>
<p>A list holding all the necessary target parameters, 
consistent with the target definition.</p>
</td></tr>
<tr><td><code>q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm that have been used.</p>
</td></tr>
<tr><td><code>prob.accept</code></td>
<td>
<p>Estimated rate of acceptation 
(meaningful for accept/reject-type algorithms).</p>
</td></tr>
<tr><td><code>Ptheta</code></td>
<td>
<p>The <code>nmc</code> copies of chains in an array(n,d,nmc) 
of simulated values, where 1st value (1,d,nmc) is <code>Ptheta0</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau, Houssam Alrachid.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, <code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code> and 
<code><a href="#topic+MCMCcopies.cl">MCMCcopies.cl</a></code> for just simulating the iid chains, and 
<code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code> or <code><a href="#topic+EntropyMCMC.mc">EntropyMCMC.mc</a></code>
for computing entropy and Kullback estimates from an already simulated
set of iid chains (internally or from external code).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Toy example using the bivariate gaussian target
## same as for MCMCcopies
n = 150; nmc = 50; d=2 # bivariate example
varq=0.1 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 
# simulations and entropy + Kullback using the singlecore version
e1 &lt;- EntropyParallel(RWHM, n, nmc, Ptheta0, target_norm,
                target_norm_param, q_param, verb = FALSE)
par(mfrow=c(1,2))
plot(e1) # default plot.plMCMC method, convergence after about 80 iterations
plot(e1, Kullback = FALSE) # Plot Entropy estimates over time
abline(normEntropy(target_norm_param), 0, col=8, lty=2) # true E_f[log(f)]

# Another example using multicore version, (not available on Windows)
varq=0.05 # variance of the proposal, even smaller
q_param=list(mean=rep(0,d),v=varq*diag(d))
n=300 # requires more iterations to show convergence
e1 &lt;- EntropyParallel.cl(RWHM, n, nmc, Ptheta0, target_norm,
                         target_norm_param, q_param, cltype="PAR_SOCK",
                         verb = FALSE, nbnodes = 2)
plot(e1) # convergence after about 150 iterations
  
</code></pre>

<hr>
<h2 id='gaussian_pdf'>Proposal density evaluation and simulation</h2><span id='topic+gaussian_pdf'></span><span id='topic+gaussian_proposal'></span>

<h3>Description</h3>

<p>Functions for proposal density evaluation and random generation in MCMC algorithms,
in the case where these are Gaussian.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussian_pdf(y, x, param)

gaussian_proposal(x, param)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaussian_pdf_+3A_y">y</code></td>
<td>
<p>Candidate for next move, a vector of dimension <code class="reqn">d</code></p>
</td></tr>
<tr><td><code id="gaussian_pdf_+3A_x">x</code></td>
<td>
<p>Current position of a chain, a vector of dimension <code class="reqn">d</code></p>
</td></tr>
<tr><td><code id="gaussian_pdf_+3A_param">param</code></td>
<td>
<p>The proposal parameters, that must contains the 
<code class="reqn">d\times d</code> variance matrix
in <code>param$v</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gaussian proposal density <code class="reqn">q(y|x)</code> used in, e.g.,
random walk Hastings-Metropolis algorithm <code>RWHM</code>
is the multivariate Gaussian <code class="reqn">N(x,v)</code> density evaluated at point <code class="reqn">y</code>. 
Similarly, the Gaussian proposal (next move) is a random draw 
<code class="reqn">y \sim N(x,v)</code> when the chain is at position <code class="reqn">x</code>.
</p>


<h3>Value</h3>

<p>The value of the density, or the random draw, both in dimension <code class="reqn">d</code></p>


<h3>Note</h3>

<p>These functions are calling multivariate 
Gaussian density and random generation functions imported from the 
<span class="pkg">mixtools</span> package (chosen for efficiency) and wrapped
in the format required by the <span class="pkg">EntropyMCMC</span> package.
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>

<hr>
<h2 id='MCMCcopies'>Simulates iid copies of a MCMC algorithm</h2><span id='topic+MCMCcopies'></span>

<h3>Description</h3>

<p>Simulates <code>nmc</code> iid copies of a MCMC algorithm <code>mcmc_algo</code>
for <code>n</code>
(time) iterations and returns an object of class <code>plMCMC</code> 
(for parallel MCMC) holding an array of the trajectories and running information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCMCcopies(mcmc_algo, n = 100, nmc = 10, Ptheta0, target, f_param, q_param, verb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCMCcopies_+3A_mcmc_algo">mcmc_algo</code></td>
<td>
<p>a list defining an MCMC algorithm in terms of the 
functions it uses, such as <code>RWHM</code>, see details below.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_n">n</code></td>
<td>
<p>The number of (time) iterations of each single chain to run.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_nmc">nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_ptheta0">Ptheta0</code></td>
<td>
<p>A (nmc x d) matrix, with the ith row giving a d-dimensional initial theta values for the ith chain.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_target">target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
Target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in this example.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_f_param">f_param</code></td>
<td>
<p>A list holding all the necessary target parameters, 
consistent with the target definition.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_q_param">q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm <code>mcmc_algo</code>.</p>
</td></tr>
<tr><td><code id="MCMCcopies_+3A_verb">verb</code></td>
<td>
<p>Verbose mode for summarizing output during the simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MCMCcopies</code> sequentially simulates <code>nmc</code> iid copies of the
MCMC algorithm passed in the list <code>mcmc_algo</code>, 
for <code>n</code> (time) iterations, and returns an object of class <code>plMCMC</code> holding an array of the trajectories and running information.
The list <code>mcmc_algo</code> must contain the named elements:
</p>

<ul>
<li> <p><code>name</code>, the name of the MCMC, such as &quot;RWHM&quot;
</p>
</li>
<li> <p><code>chain</code>, the function for simulation of n steps of a single chain
</p>
</li>
<li> <p><code>step</code>, the function for simulation of 1 step of that algorithm
</p>
</li>
<li> <p><code>q_pdf</code>, the density of the proposal
</p>
</li>
<li> <p><code>q_proposal</code>, the function that simulates a proposal
</p>
</li></ul>

<p>For examples, see the algorithms currently implemented:
<code>RWHM</code>, the Random Walk Hasting-Metropolis with gaussian proposal;
<code>HMIS_norm</code>, an Independence Sampler HM with gaussian proposal;
<code>AMHaario</code>, the Adaptive-Metropolis (AM) from Haario (2001); 
<code>IID_norm</code>, a gaussian iid sampler which is merely 
a &quot;fake&quot; MCMC for testing purposes. 
</p>


<h3>Value</h3>

<p><code>MCMCcopies</code> returns a list of class <code>plMCMC</code> with items:
</p>
<table>
<tr><td><code>Ptheta</code></td>
<td>
<p>The <code>nmc</code> copies of chains in an array(n,d,nmc) 
of simulated values, where 1st value (1,d,nmc) is <code>Ptheta0</code>.</p>
</td></tr>
<tr><td><code>prob.accept</code></td>
<td>
<p>The estimated rate of acceptation over all simulations.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>The MCMC algorithm name i.e. <code>mcmc_algo$name</code>.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>The target density.</p>
</td></tr>
<tr><td><code>f_param</code></td>
<td>
<p>The list holding all the target parameters.</p>
</td></tr>
<tr><td><code>q_param</code></td>
<td>
<p>The list holding all the proposal density parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li></ul>



<h3>See Also</h3>

<p>Two multicore and cluster version 
<code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code> and
<code><a href="#topic+MCMCcopies.cl">MCMCcopies.cl</a></code>,
and functions doing simulation and entropy and Kullback  estimation simultaneously:
<code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and <code><a href="#topic+EntropyParallel.cl">EntropyParallel.cl</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Toy example using the bivariate gaussian target
## with default parameters value, see target_norm_param
n = 150; nmc = 20; d=2 # bivariate example
varq=0.1 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 
# simulation
s1 &lt;- MCMCcopies(RWHM, n, nmc, Ptheta0, target_norm,
                 target_norm_param, q_param, verb = FALSE)
summary(s1) # method for "plMCMC" object
par(mfrow=c(1,2))
plot(s1) # just a path of the iid chains, method for "plMCMC" object
hist(s1$Ptheta[,1,], col=8) # marginal 1
</code></pre>

<hr>
<h2 id='MCMCcopies.cl'>Parallel simulation of iid copies of a MCMC algorithm - cluster versions</h2><span id='topic+MCMCcopies.cl'></span>

<h3>Description</h3>

<p> This function simulates &ldquo;parallel chains&rdquo; (iid copies)	of a MCMC algorithm 
for <code>n</code> (time) iterations, i.e. for each chain <code class="reqn">k</code>, the whole trajectory of the chain is generated. It returns an object of class <code>plMCMC</code> (for parallel MCMC) 
holding  an array of the trajectories and running information.  
This functions is similar to <code><a href="#topic+MCMCcopies">MCMCcopies</a></code> and <code>MCMCcopies.mc</code> except that it uses 
HPC in a more generic way, implementing several types of HPC for running on a single, multicore computer or on a true cluster using MPI communications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCMCcopies.cl(mcmc_algo, n=100, nmc=10, Ptheta0, target, f_param, q_param,
              cltype="PAR_SOCK", nbnodes=4) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCMCcopies.cl_+3A_mcmc_algo">mcmc_algo</code></td>
<td>
<p>a list defining an MCMC algorithm in terms of the 
functions it uses, such as <code>RWHM</code>, see details below.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_n">n</code></td>
<td>
<p>The number of (time) iterations of each single chain to run.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_nmc">nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_ptheta0">Ptheta0</code></td>
<td>
<p>A <code class="reqn">(nmc x d)</code> matrix, with the ith row giving a 
d-dimensional initial theta values for the ith chain.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_target">target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in this example.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_f_param">f_param</code></td>
<td>
<p>A list holding all the necessary target parameters, 
consistent with the target definition.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_q_param">q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm <code>mcmc_algo</code>.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_cltype">cltype</code></td>
<td>
<p>Character string specifying the type of cluster; 
currently implemented 
types are: &quot;PAR_SOCK&quot; for socket cluster with <code>parallel</code> library, the default;
&quot;SNOW_SOCK&quot; for socket cluster with <code>snow</code> library, and
&quot;SNOW_RMPI&quot; for <code>snow</code> MPI cluster with <code>Rmpi</code> library.</p>
</td></tr>
<tr><td><code id="MCMCcopies.cl_+3A_nbnodes">nbnodes</code></td>
<td>
<p>The number of nodes or virtual cores requested to run the <code>nmc</code>
simulations in parallel. For the snow version, defaults to all; 
for the cluster version, defaults to 4.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MCMCcopies.cl</code> simulates in parallel
<code>nmc</code> iid copies of the MCMC algorithm passed in the list <code>mcmc_algo</code>, 
for <code>n</code> (time) iterations, and returns an object of class <code>plMCMC</code> holding an array of the trajectories and running information.
</p>
<p><b>About parallel computing:</b>
</p>
<p>The <code>Rmpi</code> option is less efficient than the default option
using <span class="pkg">parallel</span> if you are running on a single computer. 
MPI communication are required only for running on a true cluster/grid.
</p>
<p>This generic <em>cluster</em> version implementing 
several types of cluster for running on a single, multicore computer
or on a true cluster using MPI communications may not 
work on all platform/OS. For instance the parallel socket cluster version 
does not work on Windows machines (see the <span class="pkg">parallel</span> package documentation).
</p>
<p><b>About passing your MCMC algorithm:</b>
</p>
<p>The list <code>mcmc_algo</code> must contain the named elements:
</p>

<ul>
<li> <p><code>name</code>, the name of the MCMC, such as &quot;RWHM&quot;
</p>
</li>
<li> <p><code>chain</code>, the function for simulation of n steps of a single chain
</p>
</li>
<li> <p><code>step</code>, the function for simulation of 1 step of that algorithm
</p>
</li>
<li> <p><code>q_pdf</code>, the density of the proposal
</p>
</li>
<li> <p><code>q_proposal</code>, the function that simulates a proposal
</p>
</li></ul>

<p>For examples, see the algorithms currently implemented:
<code>RWHM</code>, the Random Walk Hasting-Metropolis with gaussian proposal;
<code>HMIS_norm</code>, an Independence Sampler HM with gaussian proposal;
<code>AMHaario</code>, the Adaptive-Metropolis (AM) from Haario (2001); 
<code>IID_norm</code>, a gaussian iid sampler which is merely 
a &quot;fake&quot; MCMC for testing purposes. 
</p>


<h3>Value</h3>

<p><code>MCMCcopies.cl</code> returns a list of class <code>plMCMC</code> with items:
</p>
<table>
<tr><td><code>Ptheta</code></td>
<td>
<p>The <code>nmc</code> copies of chains in an array(n,d,nmc) 
of simulated values, where 1st value (1,d,nmc) is <code>Ptheta0</code>.</p>
</td></tr>
<tr><td><code>prob.accept</code></td>
<td>
<p>The estimated rate of acceptation over all simulations.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>The MCMC algorithm name i.e. <code>mcmc_algo$name</code>.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>The target density.</p>
</td></tr>
<tr><td><code>f_param</code></td>
<td>
<p>The list holding all the target parameters.</p>
</td></tr>
<tr><td><code>q_param</code></td>
<td>
<p>The list holding all the proposal density parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Houssam Alrachid and Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p>A simpler cluster version <code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code>,
a single core version <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, 
and functions doing simulation and entropy and Kullback  estimation simultaneously:
<code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and <code><a href="#topic+EntropyParallel.cl">EntropyParallel.cl</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Toy example using the bivariate gaussian target

n = 150; nmc = 20; d=2 # bivariate example
varq=0.1 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 
# simulations (may be compared with the singlecore version using system.time)
s1 &lt;- MCMCcopies.cl(RWHM, n, nmc, Ptheta0, target_norm,
		              target_norm_param, q_param, nbnodes = 2)
summary(s1) # method for "plMCMC" object
  
## see MCMCcopies example for plots
</code></pre>

<hr>
<h2 id='MCMCcopies.mc'>Simulates iid copies of a MCMC algorithm - multicore version</h2><span id='topic+MCMCcopies.mc'></span>

<h3>Description</h3>

<p>Simulates <code>nmc</code> iid copies of a MCMC algorithm <code>mcmc_algo</code>
for <code>n</code>
(time) iterations and returns an object of class <code>plMCMC</code> 
(for parallel MCMC) holding
an array of the trajectories and running information.
This functions is similar to <code><a href="#topic+MCMCcopies">MCMCcopies</a></code> except that it uses the
<span class="pkg">parallel</span> package (available in the main distribution, but not for Windows machines) 
to split the task between the available
virtual cores on the computer. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCMCcopies.mc(mcmc_algo, n = 100, nmc = 10, Ptheta0, target, f_param, q_param, 
			verb = TRUE, nbcores=detectCores())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCMCcopies.mc_+3A_mcmc_algo">mcmc_algo</code></td>
<td>
<p>a list defining an MCMC algorithm in terms of the 
functions it uses, such as <code>RWHM</code>, see details below.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_n">n</code></td>
<td>
<p>The number of (time) iterations of each single chain to run.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_nmc">nmc</code></td>
<td>
<p>The number of iid copies of each single chain.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_ptheta0">Ptheta0</code></td>
<td>
<p>A <code class="reqn">(nmc x d)</code> matrix, with the ith row giving a 
d-dimensional initial theta values for the ith chain.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_target">target</code></td>
<td>
<p>The target density for which the MCMC algorithm is defined; 
may be given only up to a multiplicative constant for most MCMC. 
target must be a function such as the multidimensional gaussian
<code>target_norm(x,param)</code> with argument and parameters passed 
like in this example.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_f_param">f_param</code></td>
<td>
<p>A list holding all the necessary target parameters, 
consistent with the target definition.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_q_param">q_param</code></td>
<td>
<p>A list holding all the necessary parameters 
for the proposal density of the MCMC algorithm <code>mcmc_algo</code>.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_verb">verb</code></td>
<td>
<p>Verbose mode for summarizing output during the simulation.</p>
</td></tr>
<tr><td><code id="MCMCcopies.mc_+3A_nbcores">nbcores</code></td>
<td>
<p>Number of required (virtual) cores, defaults to all as returned
by <code>detectCores()</code>.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p><code>MCMCcopies.mc</code>, like <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, sequentially simulates 
<code>nmc</code> iid copies of the
MCMC algorithm passed in the list <code>mcmc_algo</code>, 
for <code>n</code> (time) iterations, and returns an object of class <code>plMCMC</code> holding an array of the trajectories and running information.
The list <code>mcmc_algo</code> must contain the named elements:
</p>

<ul>
<li> <p><code>name</code>, the name of the MCMC, such as &quot;RWHM&quot;
</p>
</li>
<li> <p><code>chain</code>, the function for simulation of n steps of a single chain
</p>
</li>
<li> <p><code>step</code>, the function for simulation of 1 step of that algorithm
</p>
</li>
<li> <p><code>q_pdf</code>, the density of the proposal
</p>
</li>
<li> <p><code>q_proposal</code>, the function that simulates a proposal
</p>
</li></ul>

<p>For examples, see the algorithms currently implemented:
<code>RWHM</code>, the Random Walk Hasting-Metropolis with gaussian proposal;
<code>HMIS_norm</code>, an Independence Sampler HM with gaussian proposal;
<code>AMHaario</code>, the Adaptive-Metropolis (AM) from Haario (2001); 
<code>IID_norm</code>, a gaussian iid sampler which is merely 
a &quot;fake&quot; MCMC for testing purposes. 
</p>


<h3>Value</h3>

<p><code>MCMCcopies</code> returns a list of class <code>plMCMC</code> with items:
</p>
<table>
<tr><td><code>Ptheta</code></td>
<td>
<p>The <code>nmc</code> copies of chains in an array(n,d,nmc) 
of simulated values, where 1st value (1,d,nmc) is <code>Ptheta0</code>.</p>
</td></tr>
<tr><td><code>prob.accept</code></td>
<td>
<p>The estimated rate of acceptation over all simulations.</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>The MCMC algorithm name i.e. <code>mcmc_algo$name</code>.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>The target density.</p>
</td></tr>
<tr><td><code>f_param</code></td>
<td>
<p>The list holding all the target parameters.</p>
</td></tr>
<tr><td><code>q_param</code></td>
<td>
<p>The list holding all the proposal density parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2013), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p>A more general cluster version <code><a href="#topic+MCMCcopies.cl">MCMCcopies.cl</a></code>,
a single core version <code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, 
and functions doing simulation and entropy and Kullback  estimation simultaneously:
<code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and <code><a href="#topic+EntropyParallel.cl">EntropyParallel.cl</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Toy example using the bivariate gaussian target

## not working on Windows since socket cluster not implemented
n = 150; nmc = 20; d=2 # bivariate example
varq=0.1 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 
# simulations (may be compared with the singlecore version using system.time)
s1 &lt;- MCMCcopies.mc(RWHM, n, nmc, Ptheta0, target_norm,
                    target_norm_param, q_param, nbcores = 2)
summary(s1) # method for "plMCMC" object
  
## see MCMCcopies example for plots
</code></pre>

<hr>
<h2 id='normEntropy'>Theoretical value of the entropy for the multivariate gaussian</h2><span id='topic+normEntropy'></span>

<h3>Description</h3>

<p>This function computes the entropy
<code class="reqn">E_{f} [\log(f)]</code> of the density of the multivariate gaussian,
with parameters in a list, as it is the case for 
MCMC target density parameters. This function is used
mostly for benchmarking entropy estimation performed by the package
(using, e.g., the iid algorithm <code>IID_norm</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normEntropy(target_param)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normEntropy_+3A_target_param">target_param</code></td>
<td>
<p>A list of two elements: the mean <code>target_param$mean</code>
and the covariance matrix <code>target_param$v</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The entropy of the Gaussian with these parameters.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>Examples</h3>

<pre><code class='language-R'>d=2 # model dimension
mu=rep(0,d); v = diag(d) # mean and variance
target_param = list(mean=mu, v=v) # parameters
normEntropy(target_param) # the entropy
</code></pre>

<hr>
<h2 id='plot_Kblist'>
Plot sequences of Kullback distance estimates for comparison of several MCMC algorithms for a same target density
</h2><span id='topic+plot_Kblist'></span>

<h3>Description</h3>

<p>This  function draws on a same plot several sequences of estimates of 
Kullback distances <code class="reqn">K(p^t,f)</code>, i.e. the convergence criterion vs. time (iteration <code class="reqn">t</code>), 
for each MCMC algorithm for which the convergence criterion has been computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_Kblist(Kb, which = 1, lim = NULL, ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_Kblist_+3A_kb">Kb</code></td>
<td>
<p>A list of objects of class <code>"KbMCMC"</code>, such as the ones returned by
<code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code> or <code><a href="#topic+EntropyParallel">EntropyParallel</a></code>, or their HPC versions. </p>
</td></tr>
<tr><td><code id="plot_Kblist_+3A_which">which</code></td>
<td>
<p>Controls the level of details in the legend  added to the plot (see details)</p>
</td></tr>
<tr><td><code id="plot_Kblist_+3A_lim">lim</code></td>
<td>
<p>for zooming over <code>1:lim</code> iterations only. </p>
</td></tr>
<tr><td><code id="plot_Kblist_+3A_ylim">ylim</code></td>
<td>
<p>limits on the <code class="reqn">y</code> axis for zooming, passed to <code>plot</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The purpose of this plot if to compare <code class="reqn">K</code> MCMC algorithms (typically based on <code class="reqn">K</code> different 
simulation strategies or kernels) for convergence or efficiency in estimating a same target density <code class="reqn">f</code>. 
For the <code class="reqn">k</code>th algorithm, the user has to generate the convergence criterion,
i.e. the sequence  <code class="reqn">K(p^t(_k)k), f)</code> for <code class="reqn">t=1</code> up to the number of iterations 
that has been chosen, and where <code class="reqn">p^t(k)</code> is  the estimated pdf of the algorithm at time <code class="reqn">t</code>.
</p>
<p>For the legend, <code>which=1</code> displays the MCMC's names together with some technical information depending on the algorithms definition (e.g. the proposal variance for the <code><a href="#topic+RWHM">RWHM</a></code> algorithm) and the 
method used for entropy estimation. The legend for
<code>which=2</code> is shorter, only displaying the MCMC's names together with the number of parallel chains used for each, 
typically to compare the effect of that number for a single MCMC algorithm.
</p>


<h3>Value</h3>

<p>The graphic to plot.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2012), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, (2013) 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code>, <code><a href="#topic+EntropyMCMC.mc">EntropyMCMC.mc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Toy example using the bivariate centered gaussian target
## with default parameters value, see target_norm_param
d = 2           # state space dimension
n=300; nmc=100  # number of iterations and iid Markov chains
## initial distribution, located in (2,2), "far" from target center (0,0)
Ptheta0 &lt;- DrawInit(nmc, d, initpdf = "rnorm", mean = 2, sd = 1) 

## MCMC 1: Random-Walk Hasting-Metropolis
varq=0.05 # variance of the proposal (chosen too small)
q_param=list(mean=rep(0,d),v=varq*diag(d))

## using Method 1: simulation with storage, and *then* entropy estimation
# simulation of the nmc iid chains, single core here
s1 &lt;- MCMCcopies(RWHM, n, nmc, Ptheta0, target_norm,
                 target_norm_param, q_param)
summary(s1) # method for "plMCMC" object
e1 &lt;- EntropyMCMC(s1) # computes Entropy and Kullback divergence

## MCMC 2: Independence Sampler with large enough gaussian proposal
varq=1; q_param &lt;- list(mean=rep(0,d),v=varq*diag(d))

## using Method 2: simulation &amp; estimation for each t, forgetting the past
## HPC with 2 cores here (using parallel socket cluser, not available on Windows machines)
e2 &lt;- EntropyParallel.cl(HMIS_norm, n, nmc, Ptheta0, target_norm,
                      target_norm_param, q_param, 
                      cltype="PAR_SOCK", nbnodes=2)

## Compare these two MCMC algorithms
plot_Kblist(list(e1,e2)) # MCMC 2 (HMIS, red plot) converges faster.
  
</code></pre>

<hr>
<h2 id='plot.KbMCMC'>Plot sequences of estimates of Kullback distance or Entropy against iterations</h2><span id='topic+plot.KbMCMC'></span>

<h3>Description</h3>

<p>This S3 method for <code>plot</code>
plots by default sequences of estimates of 
the Kullback distance <code class="reqn">K(p^t,f)</code>
between the (estimated) pdf of the MCMC algorithm at time <code class="reqn">t</code>,
<code class="reqn">p^t</code>, and the target  density <code class="reqn">f</code>,
for <code class="reqn">t=1</code> up to the number of iterations that have been provided/computed.
It can also plot the first term in the Kullback distance, i.e.
the Entropy <code class="reqn">E_{p^t}[\log(p^t)]</code>. 
Its argument is an object of class
<code>KbMCMC</code> such as the one returned by, e.g., <code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KbMCMC'
plot(x, Kullback = TRUE, lim = NULL, ylim = NULL, 
            new.plot = TRUE, title = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.KbMCMC_+3A_x">x</code></td>
<td>
<p>An object of class <code>KbMCMC</code>, such as the one returned by
<code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code>.</p>
</td></tr>
<tr><td><code id="plot.KbMCMC_+3A_kullback">Kullback</code></td>
<td>
<p><code>TRUE</code> to plot the Kullback distance, 
<code>FALSE</code> to plot the Entropy.</p>
</td></tr>
<tr><td><code id="plot.KbMCMC_+3A_lim">lim</code></td>
<td>
<p>for zooming over <code>1:lim</code> iterations only.</p>
</td></tr>
<tr><td><code id="plot.KbMCMC_+3A_ylim">ylim</code></td>
<td>
<p><code>y</code> limits, passed to <code>plot</code>.</p>
</td></tr>
<tr><td><code id="plot.KbMCMC_+3A_new.plot">new.plot</code></td>
<td>
<p>set to <code>FALSE</code> to add the plot to an existing plot.</p>
</td></tr>
<tr><td><code id="plot.KbMCMC_+3A_title">title</code></td>
<td>
<p>The title; if <code>NULL</code>, then a default title is displayed.</p>
</td></tr>
<tr><td><code id="plot.KbMCMC_+3A_...">...</code></td>
<td>
<p>Further parameters passed to <code>plot</code> or <code>lines</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The graphic to plot.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2012), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, (2013) 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+EntropyMCMC">EntropyMCMC</a></code>, <code><a href="#topic+EntropyMCMC.mc">EntropyMCMC.mc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See the EntropyMCMC Examples.
</code></pre>

<hr>
<h2 id='plot.plMCMC'>
Plot paths of copies of Markov chains
</h2><span id='topic+plot.plMCMC'></span>

<h3>Description</h3>

<p>This function plots 2d-projections of the paths of i.i.d. copies of Markov chains 
output by an MCMC algorithm and stored in an object of class <code>plMCMC</code> (for parallel MCMC) 
such as the one returned by, e.g., <code><a href="#topic+MCMCcopies">MCMCcopies</a></code> or the multicore version 
<code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plMCMC'
plot(x, xax = 1, yax = 2, title = NULL, cname = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.plMCMC_+3A_x">x</code></td>
<td>
<p>An object of class <code>plMCMC</code>, such as output from
<code><a href="#topic+MCMCcopies">MCMCcopies</a></code>.</p>
</td></tr>
<tr><td><code id="plot.plMCMC_+3A_xax">xax</code></td>
<td>
<p>Coordinate for the horizontal axis.</p>
</td></tr>
<tr><td><code id="plot.plMCMC_+3A_yax">yax</code></td>
<td>
<p>Coordinate for the vertical axis.</p>
</td></tr>
<tr><td><code id="plot.plMCMC_+3A_title">title</code></td>
<td>
<p>The title; if <code>NULL</code>, then a default title is displayed.</p>
</td></tr>
<tr><td><code id="plot.plMCMC_+3A_cname">cname</code></td>
<td>
<p>Coordinate base name; &quot;var&quot; is the default, so that coordinates
are named &quot;var1&quot;, &quot;var2&quot;, and so on.</p>
</td></tr>
<tr><td><code id="plot.plMCMC_+3A_...">...</code></td>
<td>
<p>Further parameters except <code>pch</code> which is already used, 
passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is currently limited to a 2D projection path of all the i.i.d. chains for
the two selected coordinates.
The copies of the Markov chain must be in the 3-dimensional
array <code>s$Ptheta</code>.</p>


<h3>Value</h3>

<p>The graphic to plot.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2012), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, (2013) 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, <code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code>,
<code><a href="#topic+MCMCcopies.cl">MCMCcopies.cl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See MCMCcopie Example
</code></pre>

<hr>
<h2 id='plottarget3d'>3D plot of a two-dimensional  MCMC target, or any function</h2><span id='topic+plottarget3d'></span>

<h3>Description</h3>

<p>Utility function for the package <span class="pkg">EntropyMCMC</span>, to visualize a 
2-dimensional target of a MCMC algorithm, mostly for testing purpose.
This uses the function <code>persp</code> from package <span class="pkg">graphics</span>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>plottarget3d(zft, l, r, ms, theta, phi, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plottarget3d_+3A_zft">zft</code></td>
<td>
<p>a function, typically a 2-dimensional target of a MCMC.</p>
</td></tr>
<tr><td><code id="plottarget3d_+3A_l">l</code>, <code id="plottarget3d_+3A_r">r</code>, <code id="plottarget3d_+3A_ms">ms</code></td>
<td>
<p>mesh boundaries and size.</p>
</td></tr>
<tr><td><code id="plottarget3d_+3A_theta">theta</code>, <code id="plottarget3d_+3A_phi">phi</code></td>
<td>
<p>angles defining the viewing direction. <cite>theta</cite> 
gives the azimuthal direction and <cite>phi</cite> the colatitude.</p>
</td></tr>
<tr><td><code id="plottarget3d_+3A_...">...</code></td>
<td>
<p>additional graphical parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a 3D plot on a mesh of size <code>(l, r, ms)</code>.</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>

<hr>
<h2 id='RWHM_chain'>Simulating MCMC single chains using MCMC algorithms</h2><span id='topic+RWHM_chain'></span><span id='topic+HMIS_norm_chain'></span><span id='topic+AMHaario_chain'></span><span id='topic+IID_chain'></span>

<h3>Description</h3>

<p>These functions are used to define the elements <code>$chain</code> of the MCMC algorithms
that are (and must be) implemented as lists in <span class="pkg">EntropyMCMC</span>.
These functions are usually only called by higher-level functions, see details below. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWHM_chain(theta0, it = 100, target, f_param, q_param, q_pdf = gaussian_pdf, 
                q_proposal = gaussian_proposal) 
HMIS_norm_chain(theta0, it = 100, target, f_param, q_param, q_pdf = q_pdf_ISnorm, 
                q_proposal = q_proposal_ISnorm)
AMHaario_chain(theta0, it = 100, target, f_param, q_param, q_pdf = gaussian_pdf,
                q_proposal = gaussian_proposal)
IID_chain(theta0 = NULL, it = 100, target, f_param, q_param = NULL, q_pdf = NULL,
                q_proposal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RWHM_chain_+3A_it">it</code></td>
<td>
<p>the number of iterations to simulate</p>
</td></tr>
<tr><td><code id="RWHM_chain_+3A_theta0">theta0</code></td>
<td>
<p>the initial position of the chain, a <code class="reqn">d</code>-dim vector</p>
</td></tr>
<tr><td><code id="RWHM_chain_+3A_target">target</code></td>
<td>
<p>the user-defined target density</p>
</td></tr>
<tr><td><code id="RWHM_chain_+3A_f_param">f_param</code></td>
<td>
<p>the parameters (hyperparameters, data) of the user-defined target density</p>
</td></tr>
<tr><td><code id="RWHM_chain_+3A_q_param">q_param</code></td>
<td>
<p>the parameters of the proposal density, which structure depends on the algorithm and the proposal density chosen by the user. Defaults are
for <code>RWHM</code>: a list with the mean and covariance matrix of the proposal.
For <code>AMHaario</code>: a list that must contain three elements:
<code>v</code> the initial covariance matrix, <code>t0</code> the iteration of the end of initial stage 
with that matrix, and <code>epsi</code> the epsilon parameter (for the nondegenerate matrix part),
see Haario et. al.(2001).</p>
</td></tr>
<tr><td><code id="RWHM_chain_+3A_q_pdf">q_pdf</code></td>
<td>
<p>the proposal density</p>
</td></tr>
<tr><td><code id="RWHM_chain_+3A_q_proposal">q_proposal</code></td>
<td>
<p>the function simulating the proposal for the next move</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each MCMC algorithm is defined as a list with five elements, see 
the object <code>RWHM</code> for an example. The element <code>$chain</code> must provide
the name of the function performing simulation of a single chain and returning that chain,
with arguments that must follow the definition above.
Each user can define its own MCMC
starting with the algorithms provided (see also section below).
These functions are thus usually called by higher-level functions like
<code>MCMCcopies</code>, <code>EntropyParallel</code>, or their multicore versions,
for simulating copies of MCMC chains in an automatic manner.
</p>

<ul>
<li> <p><code>RWHM_chain</code> is used in <code>RWHM</code>, a standard Randow-Walk Hastings-Metropolis algorithm.
</p>
</li>
<li> <p><code>HMIS_norm_chain</code> is used in <code>HMIS_norm</code>,
an Independence Sampler HM with gaussian proposal
</p>
</li>
<li> <p><code>AMHaario_chain</code> is used in <code>AMHaario</code>, the
Haario Adaptive Hastings-Metropolis algorithm (Haario 2001), and is provided as an example 
of a benchmark AMCMC.
</p>
</li>
<li> <p><code>IID_chain</code> is used in <code>IID_norm</code>, a &ldquo;fake&rdquo; MCMC that is just a gaussian IID sampler.
</p>
</li></ul>



<h3>Value</h3>

<p>A list with elements:
</p>
<table>
<tr><td><code>theta</code></td>
<td>
<p>the simulated chain in an array of <code class="reqn">it</code> rows and <code class="reqn">d</code> columns (the dimension)</p>
</td></tr> 
<tr><td><code>paccept</code></td>
<td>
<p>the empirical acceptance rate</p>
</td></tr>
<tr><td><code>finalcov</code></td>
<td>
<p>the last covariance matrix</p>
</td></tr>
<tr><td><code>algo</code></td>
<td>
<p>the name of the algorithm (for plot methods)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>

<p>H. Haario, E. Saksman, and J. Tamminen (2001), 
An adaptive Metropolis algorithm. 
Bernoulli 7, 223&ndash;242.
</p>


<h3>See Also</h3>

<p>The algorithm already implemented, listed in <code><a href="#topic+EntropyMCMC-package">EntropyMCMC-package</a></code>.
</p>
<p>The higher level functions that use these functions for simulation:
<code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, <code><a href="#topic+EntropyParallel">EntropyParallel</a></code> and their multicore versions.
</p>

<hr>
<h2 id='summary.plMCMC'>Summarizes content of a <code>plMCMC</code> object 
holding iid copies of MCMC's</h2><span id='topic+summary.plMCMC'></span>

<h3>Description</h3>

<p>This S3 method for <code>summary</code> summarizes the content of an object 
of class <code>plMCMC</code> (for parallel MCMC) as returned by, e.g.,
<code>MCMCcopies</code>, containing the trajectories of iid copies of trajectories 
from a MCMC algorithm, and its associated kernel, target and proposal densities. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plMCMC'
summary(object, stats = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.plMCMC_+3A_object">object</code></td>
<td>
<p>An object of class <code>plMCMC</code> as returned by, e.g.,<code>MCMCcopies</code>.</p>
</td></tr>
<tr><td><code id="summary.plMCMC_+3A_stats">stats</code></td>
<td>
<p>print additional summary statistics for the variables over all chains.</p>
</td></tr>
<tr><td><code id="summary.plMCMC_+3A_...">...</code></td>
<td>
<p>additional arguments passed to other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the object associated dimensions, the overall rate of acceptation,
and descriptive statistics over the variable coordinates if <code>stats = TRUE</code>. 
</p>


<h3>Author(s)</h3>

<p>Didier Chauveau.</p>


<h3>References</h3>


<ul>
<li><p> Chauveau, D. and Vandekerkhove, P. (2012), 
Smoothness of Metropolis-Hastings algorithm and application to entropy estimation.
<em>ESAIM: Probability and Statistics</em>,  <b>17</b>, (2013) 419&ndash;431.
DOI: <a href="http://dx.doi.org/10.1051/ps/2012004">http://dx.doi.org/10.1051/ps/2012004</a>
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
Simulation Based Nearest Neighbor Entropy Estimation for (Adaptive) MCMC Evaluation,
In <em>JSM Proceedings, Statistical Computing Section</em>.
Alexandria, VA: American Statistical Association. 2816&ndash;2827.
</p>
</li>
<li><p> Chauveau D. and Vandekerkhove, P. (2014),
The Nearest Neighbor entropy estimate: an adequate tool for adaptive MCMC evaluation.
<em>Preprint HAL</em> <a href="http://hal.archives-ouvertes.fr/hal-01068081">http://hal.archives-ouvertes.fr/hal-01068081</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+MCMCcopies">MCMCcopies</a></code>, <code><a href="#topic+MCMCcopies.mc">MCMCcopies.mc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See Example for MCMCcopies
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
