<!DOCTYPE html><html><head><title>Help for package regclass</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {regclass}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ACCOUNT'>
<p>Predicting whether a customer will open a new kind of account</p></a></li>
<li><a href='#all_correlations'>
<p>Pairwise correlations between quantitative variables</p></a></li>
<li><a href='#APPLIANCE'>
<p>Appliance shipments</p></a></li>
<li><a href='#associate'>
<p>Association Analysis</p></a></li>
<li><a href='#ATTRACTF'>
<p>Attractiveness Score (female)</p></a></li>
<li><a href='#ATTRACTM'>
<p>Attractiveness Score (male)</p></a></li>
<li><a href='#AUTO'>
<p>AUTO dataset</p></a></li>
<li><a href='#BODYFAT'>
<p>BODYFAT data</p></a></li>
<li><a href='#BODYFAT2'>
<p>Secondary BODYFAT dataset</p></a></li>
<li><a href='#build_model'>
<p>Variable selection for descriptive or predictive linear and logistic regression models</p></a></li>
<li><a href='#build_tree'>
<p>Exploratory building of partition models</p></a></li>
<li><a href='#BULLDOZER'>
<p>BULLDOZER data</p></a></li>
<li><a href='#BULLDOZER2'>
<p>Modified BULLDOZER data</p></a></li>
<li><a href='#CALLS'>
<p>CALLS dataset</p></a></li>
<li><a href='#CENSUS'>
<p>CENSUS data</p></a></li>
<li><a href='#CENSUSMLR'>
<p>Subset of CENSUS data</p></a></li>
<li><a href='#CHARITY'>
<p>CHARITY dataset</p></a></li>
<li><a href='#check_regression'>
<p>Linear and Logistic Regression diagnostics</p></a></li>
<li><a href='#choose_order'>
<p>Choosing order of a polynomial model</p></a></li>
<li><a href='#CHURN'>
<p>CHURN dataset</p></a></li>
<li><a href='#combine_rare_levels'>
<p>Combines rare levels of a categorical variable</p></a></li>
<li><a href='#confusion_matrix'>
<p>Confusion matrix for logistic regression models</p></a></li>
<li><a href='#cor_demo'>
<p>Correlation demo</p></a></li>
<li><a href='#cor_matrix'>
<p>Correlation Matrix</p></a></li>
<li><a href='#CUSTCHURN'>
<p>CUSTCHURN dataset</p></a></li>
<li><a href='#CUSTLOYALTY'>
<p>CUSTLOYALTY dataset</p></a></li>
<li><a href='#CUSTREACQUIRE'>
<p>CUSTREACQUIRE dataset</p></a></li>
<li><a href='#CUSTVALUE'>
<p>CUSTVALUE dataset</p></a></li>
<li><a href='#DIET'>
<p>DIET data</p></a></li>
<li><a href='#DONOR'>
<p>DONOR dataset</p></a></li>
<li><a href='#EDUCATION'>
<p>EDUCATION data</p></a></li>
<li><a href='#EX2.CENSUS'>
<p>CENSUS data for Exercise 5 in Chapter 2</p></a></li>
<li><a href='#EX2.TIPS'>
<p>TIPS data for Exercise 6 in Chapter 2</p></a></li>
<li><a href='#EX3.ABALONE'>
<p>ABALONE dataset for Exercise D in Chapter 3</p></a></li>
<li><a href='#EX3.BODYFAT'>
<p>Bodyfat data for Exercise F in Chapter 3</p></a></li>
<li><a href='#EX3.HOUSING'>
<p>Housing data for Exercise E in Chapter 3</p></a></li>
<li><a href='#EX3.NFL'>
<p>NFL data for Exercise A in Chapter 3</p></a></li>
<li><a href='#EX4.BIKE'>
<p>Bike data for Exercise 1 in Chapter 4</p></a></li>
<li><a href='#EX4.STOCKPREDICT'>
<p>Stock data for Exercise 2 in Chapter 4 (prediction set)</p></a></li>
<li><a href='#EX4.STOCKS'>
<p>Stock data for Exercise 2 in Chapter 4</p></a></li>
<li><a href='#EX5.BIKE'>
<p>BIKE dataset for Exercise 4 Chapter 5</p></a></li>
<li><a href='#EX5.DONOR'>
<p>DONOR dataset for Exercise 4 in Chapter 5</p></a></li>
<li><a href='#EX6.CLICK'>
<p>CLICK data for Exercise 2 in Chapter 6</p></a></li>
<li><a href='#EX6.DONOR'>
<p>DONOR dataset for Exercise 1 in Chapter 6</p></a></li>
<li><a href='#EX6.WINE'>
<p>WINE data for Exercise 3 Chapter 6</p></a></li>
<li><a href='#EX7.BIKE'>
<p>BIKE dataset for Exercise 1 Chapters 7 and 8</p></a></li>
<li><a href='#EX7.CATALOG'>
<p>CATALOG data for Exercise 2 in Chapters 7 and 8</p></a></li>
<li><a href='#EX9.BIRTHWEIGHT'>
<p>Birthweight dataset for Exercise 1 in Chapter 9</p></a></li>
<li><a href='#EX9.NFL'>
<p>NFL data for Exercise 2 Chapter 9</p></a></li>
<li><a href='#EX9.STORE'>
<p>Data for Exercise 3 Chapter 9</p></a></li>
<li><a href='#extrapolation_check'>
<p>A crude check for extrapolation</p></a></li>
<li><a href='#find_transformations'>
<p>Transformations for simple linear regression</p></a></li>
<li><a href='#FRIEND'>
<p>Friendship Potential vs. Attractiveness Ratings</p></a></li>
<li><a href='#FUMBLES'>
<p>Wins vs. Fumbles of an NFL team</p></a></li>
<li><a href='#generalization_error'>
<p>Calculating the generalization error of a model on a set of data</p></a></li>
<li><a href='#getcp'>
<p>Complexity Parameter table for partition models</p></a></li>
<li><a href='#influence_plot'>
<p>Influence plot for regression diganostics</p></a></li>
<li><a href='#JUNK'>
<p>Junk-mail dataset</p></a></li>
<li><a href='#LARGEFLYER'>
<p>Interest in frequent flier program (large version)</p></a></li>
<li><a href='#LAUNCH'>
<p>New product launch data</p></a></li>
<li><a href='#mode_factor'>
<p>Find the mode of a categorical variable</p></a></li>
<li><a href='#mosaic'>
<p>Mosaic plot</p></a></li>
<li><a href='#MOVIE'>
<p>Movie grosses</p></a></li>
<li><a href='#NFL'>
<p>NFL database</p></a></li>
<li><a href='#OFFENSE'>
<p>Some offensive statistics from <code>NFL</code> dataset</p></a></li>
<li><a href='#outlier_demo'>
<p>Interactive demonstration of the effect of an outlier on a regression</p></a></li>
<li><a href='#overfit_demo'>
<p>Demonstration of overfitting</p></a></li>
<li><a href='#PIMA'>
<p>Pima Diabetes dataset</p></a></li>
<li><a href='#POISON'>
<p>Cockroach poisoning data</p></a></li>
<li><a href='#possible_regressions'>
<p>Illustrating how a simple linear/logistic regression could have turned out via permutations</p></a></li>
<li><a href='#PRODUCT'>
<p>Sales of a product one quarter after release</p></a></li>
<li><a href='#PURCHASE'>
<p>PURCHASE data</p></a></li>
<li><a href='#qq'>
<p>QQ plot</p></a></li>
<li><a href='#SALARY'>
<p>Harris Bank Salary data</p></a></li>
<li><a href='#see_interactions'>
<p>Examining pairwise interactions between quantitative variables for a fitted regression model</p></a></li>
<li><a href='#see_models'>
<p>Examining model AICs from the &quot;all possible&quot; regressions procedure using regsubsets</p></a></li>
<li><a href='#segmented_barchart'>
<p>Segmented barchart</p></a></li>
<li><a href='#SMALLFLYER'>
<p>Interest in a frequent flier program (small version)</p></a></li>
<li><a href='#SOLD26'>
<p>Predicting future sales</p></a></li>
<li><a href='#SPEED'>
<p>Speed vs. Fuel Efficiency</p></a></li>
<li><a href='#STUDENT'>
<p>STUDENT data</p></a></li>
<li><a href='#suggest_levels'>
<p>Combining levels of a categorical variable</p></a></li>
<li><a href='#summarize_tree'>
<p>Useful summaries of partition models from rpart</p></a></li>
<li><a href='#SURVEY09'>
<p>Student survey 2009</p></a></li>
<li><a href='#SURVEY10'><p>Student survey 2010</p></a></li>
<li><a href='#SURVEY11'>
<p>Student survey 2011</p></a></li>
<li><a href='#TIPS'>
<p>TIPS dataset</p></a></li>
<li><a href='#VIF'>
<p>Variance Inflation Factor</p></a></li>
<li><a href='#visualize_model'>
<p>Visualizations of one or two variable linear or logistic regressions or of partitions models</p></a></li>
<li><a href='#visualize_relationship'>
<p>Visualizing the relationship between y and x in a partition model</p></a></li>
<li><a href='#WINE'>
<p>WINE data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for an Introductory Class in Regression and Modeling</td>
</tr>
<tr>
<td>Version:</td>
<td>1.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-2-19</td>
</tr>
<tr>
<td>Author:</td>
<td>Adam Petrie</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adam Petrie &lt;apetrie@utk.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6), bestglm, leaps, VGAM, rpart, randomForest</td>
</tr>
<tr>
<td>Imports:</td>
<td>rpart.plot</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains basic tools for visualizing, interpreting, and building regression models.  It has been designed for use with the book Introduction to Regression and Modeling with R by Adam Petrie, Cognella Publishers, ISBN: 978-1-63189-250-9 <a href="https://titles.cognella.com/introduction-to-regression-and-modeling-with-r-9781631892509">https://titles.cognella.com/introduction-to-regression-and-modeling-with-r-9781631892509</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-21 17:16:41 UTC; adamp</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-21 18:00:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='ACCOUNT'>
Predicting whether a customer will open a new kind of account
</h2><span id='topic+ACCOUNT'></span>

<h3>Description</h3>

<p>Customers were marketed a new type of account at a bank.  It is desired to model what factors seemed to be associated with the probability of opening the account to tune marketing strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ACCOUNT")</code></pre>


<h3>Format</h3>

<p>A data frame with 24242 observations on the following 8 variables.
</p>

<dl>
<dt><code>Purchase</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Tenure</code></dt><dd><p>a numeric vector, the number of years the customer has been with the bank</p>
</dd>
<dt><code>CheckingBalance</code></dt><dd><p>a numeric vector, amount currently held in checking (may be negative if overdrafted)</p>
</dd>
<dt><code>SavingBalance</code></dt><dd><p>a numeric vector, amount currently held in savings (0 or larger) </p>
</dd>
<dt><code>Income</code></dt><dd><p>a numeric vector, yearly income in thousands of dollars</p>
</dd>
<dt><code>Homeowner</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Area.Classification</code></dt><dd><p>a factor with levels <code>R</code> <code>S</code> <code>U</code> for rural, suburban, or urban</p>
</dd>
</dl>



<h3>Details</h3>

<p>Who is more likely to open a new type of account that a bank wants to try to sell its customers?  Try logistic regression or partition models to see if you can develop a model that accurately classifies purchasers vs. non-purchasers.  Or, try to develop a model that does well in promoting to nearly all customers who would buy the account.
</p>

<hr>
<h2 id='all_correlations'>
Pairwise correlations between quantitative variables
</h2><span id='topic+all_correlations'></span><span id='topic+all.correlations'></span>

<h3>Description</h3>

<p>This function gives a list of all pairwise correlations between quantitative variables in a dataframe.  Alternatively, it can provide all pairwise correlations with just a particular variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>all_correlations(X,type="pearson",interest=NA,sorted="none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="all_correlations_+3A_x">X</code></td>
<td>

<p>A data frame
</p>
</td></tr>
<tr><td><code id="all_correlations_+3A_type">type</code></td>
<td>

<p>Either <code>pearson</code>, <code>spearman</code>, or <code>both</code>.  If <code>pearson</code>, the Pearson correlations are returned.  If <code>spearman</code>, the Spearman's rank correlations are returned.
</p>
</td></tr>
<tr><td><code id="all_correlations_+3A_interest">interest</code></td>
<td>
<p>If specified, returns only pairwise correlations with this variable.  Argument should be in quotes and must give the exact name of the column of the variable of interest.</p>
</td></tr>
<tr><td><code id="all_correlations_+3A_sorted">sorted</code></td>
<td>
<p>Either <code>none</code>, <code>strength</code>, <code>significance</code>, or <code>magnitude</code>.   If <code>strength</code>, sorts the list from most negative correlation to most positive (remember, correlations are stronger the farther they are from 0 (positive or negative).  If <code>significance</code>, sorts the list by p-value.  If <code>none</code>, no sorting takes place.  Note:  if <code>both</code> is requested, no sorting takes place and an error message is output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function filters out any non-numerical variables in the data frame and provides correlations only between quantitative variables.  It is useful for quickly glancing at the size of the correlations between many pairs of variables or all correlations with a particular variable.  Further analysis should be done on pairs of interest using <code><a href="#topic+associate">associate</a></code>.
</p>
<p>Note:  if Spearmans' rank correlations are computed, warnings message result indicating that the exact p-value cannot be computed with ties.  Running <code>associate</code> will give you an approximate p-value using the permutation procedure.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+associate">associate</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>	#all pairwise (Pearson) correlations between all quantitative variables
	data(STUDENT)
	all_correlations(STUDENT)  
	#Spearman correlations between all quantitative variables and CollegeGPA, sorted by pvalue. 
	#Gives warnings due to ties
	all_correlations(STUDENT,interest="CollegeGPA",type="spearman",sorted="significance")
	 </code></pre>

<hr>
<h2 id='APPLIANCE'>
Appliance shipments
</h2><span id='topic+APPLIANCE'></span>

<h3>Description</h3>

<p>Appliance shipments from 1960 to 1985</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("APPLIANCE")</code></pre>


<h3>Format</h3>

<p>A data frame with 26 observations on the following 7 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Dishwasher</code></dt><dd><p>a numeric vector, Factory shipments (domestic) of dishwashers (thousands)</p>
</dd>
<dt><code>Disposal</code></dt><dd><p>a numeric vector, Factory shipments (domestic) of disposers (thousands)</p>
</dd>
<dt><code>Refrigerator</code></dt><dd><p>a numeric vector, Factory shipments (domestic) of refrigerators (thousands)</p>
</dd>
<dt><code>Washer</code></dt><dd><p>a numeric vector, Factory shipments (domestic) of washing machines (thousands)</p>
</dd>
<dt><code>DurableGoodsExp</code></dt><dd><p>a numeric vector, Durable goods expenditures (billions of 1972 dollars)</p>
</dd>
<dt><code>PrivateResInvest</code></dt><dd><p>a numeric vector, Private residential investment (billions of 1972 dollars)</p>
</dd>
</dl>



<h3>Details</h3>

<p>From the (former) Data and Story library.
</p>
<p>The file gives unit shipments of dishwashers, disposers, refrigerators, and washers in the United States from 1960 to 1985. This and other data are published currently in the Department of Commerce's Survey of Current Business, and are summarized from time to time in their publication, Business Statistics. Also included in the file are durable goods expenditures and private residential investment in the United States.
</p>

<hr>
<h2 id='associate'>
Association Analysis
</h2><span id='topic+associate'></span>

<h3>Description</h3>

<p>This function takes two quantities and computes relevent numerical measures of association.  The p-values of the associations are estimated via permutation tests.  Plots for diagnostics are provided as well, with optional arguments that allow for classic tests. </p>


<h3>Usage</h3>

<pre><code class='language-R'>associate(formula, data, permutations = 500, seed=NA, plot = TRUE, classic = FALSE, 
  cex.leg=0.7, n.levels=NA,prompt=TRUE,color=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="associate_+3A_formula">formula</code></td>
<td>

<p>A standard R formula written as y~x, where y is the name of the variable playing the role of y and x is the name of the variable playing the role of x.  
</p>
</td></tr>
<tr><td><code id="associate_+3A_data">data</code></td>
<td>

<p>An optional argument giving the name of the data frame that contains x and y.  If not specified, the function will use existing definitions in the parent environment.
</p>
</td></tr>
<tr><td><code id="associate_+3A_permutations">permutations</code></td>
<td>

<p>The number of permutations for Monte Carlo estimation of the p-value.  If 0, function defaults to reporting classic results.
</p>
</td></tr>
<tr><td><code id="associate_+3A_seed">seed</code></td>
<td>

<p>An optional argument specifying the random number seed for permutations. 
</p>
</td></tr>
<tr><td><code id="associate_+3A_plot">plot</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.  Indicates whether the relevent plots are displayed. 
</p>
</td></tr>
<tr><td><code id="associate_+3A_classic">classic</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.  Indicates whether p-values should (also) be found using classic approximations.
</p>
</td></tr>
<tr><td><code id="associate_+3A_cex.leg">cex.leg</code></td>
<td>

<p>Scale factor for the size of legends in plots.  Larger values make legends bigger.
</p>
</td></tr>
<tr><td><code id="associate_+3A_n.levels">n.levels</code></td>
<td>

<p>An optional argument of interest only when y is categorical and x is quantitative.  It specifies the number of levels when converting x to a categorical variable during the analysis.  Each level will have the same number of cases.  If this does not work out evenly, some levels are randomly picked to have one more case than the others.  If unspecified, the default is to pick the number of levels so that there are 10 cases per level or a maximum of 6 levels (whichever is smaller).
</p>
</td></tr>
<tr><td><code id="associate_+3A_prompt">prompt</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.  If <code>FALSE</code>, function proceeds without prompting user when the number of observations or number of permutation is large (5000 threshold for each for a prompt).  Usually only run with <code>FALSE</code> for documentation purposes.
</p>
</td></tr>
<tr><td><code id="associate_+3A_color">color</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.  Mostly used for mosaic plots.  If <code>FALSE</code>, plots are presented in greyscale.  If <code>TRUE</code>, an intelligent color scheme is chosen to shade the plot.  
</p>
</td></tr>
<tr><td><code id="associate_+3A_...">...</code></td>
<td>

<p>Additional arguments related to plotting, e.g., pch, lty, lwd
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses Monte Carlo simulation (permutation procedure) to approximate the p-value of an association.   Only complete cases are considered in the analysis.
</p>
<p>Valid formulas may include functions of the variable, e.g. y^2, log10(x), or more complicated functions like I(x1/(x2+x3)).  In the latter case, I() must surround the function of interest to be computed correctly.
</p>
<p>When both x and y are quantitative variables, an analysis of Pearson's correlation and Spearman's rank correlation is provided. Scatterplots and histograms of the variables are provided.  If <code>classic</code> is <code>TRUE</code>, the QQ-plots of the variables are provided along with tests of assumptions.
</p>
<p>When x is categorical and y is quantitative, the averages (as well as mean ranks and medians) of y are compared between levels of x.  The &quot;discrepancy&quot; is the F statistic for averages, Kruskal-Wallis statistic for mean ranks, and the chi-squared statistic for the median test.  Side-by-side boxplots are also provided.   If <code>classic</code> is <code>TRUE</code>, the QQ-plots of the distribution of y for each level of x are provided.
</p>
<p>When x is quantitative and y is categorical, x is converted to a categorical variable with <code>n.levels</code> levels with equal numbers of cases.  A chi-squared test is performed for the association.  The classic approach assumes a multinomial logistic regression to check significance.  A mosaic plot showing the distribution of y for each induced level of x is provided as well as a probability &quot;curve&quot;.  If <code>classic</code> is <code>TRUE</code>, the multinomial logistic curves for each level are provided versus x..
</p>
<p>When both x and y are categorical, a chi-squared test is performed.  The contingency table, table of expected counts, and conditional distributions are also reported along with a mosaic plot.
</p>
<p>If the permutation procedure is used, the sampling distribution of the measure of association is displayed over the requested amount of permutations along with the observed value on the actual data (except when y is categorical with x quantitative).
</p>
<p>If classic results are desired, then plots and tests to check assumptions are supplied.  <code>white.test</code> from package bstats (version 1.1-11-5) and  <code>mshapiro.test</code> from package mvnormtest (version 0.1-9) are built into the function to avoid directly referencing the libraries (which sometimes causes problems). 
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+anova">anova</a></code>, <code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>, <code>vglm</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  #Two quantitative variables
  data(SALARY)
	associate(Salary~Education,data=SALARY,permutations=1000)
	
	#y is quantitative while x is categorical
	data(SURVEY11)
	associate(X07.GPA~X40.FavAlcohol,data=SURVEY11,permutations=0,classic=TRUE)
	
	#y is categorical while x is quantitative
	data(WINE)
	associate(Quality~alcohol,data=WINE,classic=TRUE,n.levels=5) 

  #Two categorical variables (many cases, turns off prompt asking for user input)
  data(ACCOUNT)
  set.seed(320)
  #Work with a smaller subset
  SUBSET &lt;- ACCOUNT[sample(nrow(ACCOUNT),1000),]
	associate(Purchase~Area.Classification,data=SUBSET,classic=TRUE,prompt=FALSE)
	
	 </code></pre>

<hr>
<h2 id='ATTRACTF'>
Attractiveness Score (female)
</h2><span id='topic+ATTRACTF'></span>

<h3>Description</h3>

<p>The average attractiveness scores of 70 females along with physical attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ATTRACTF")</code></pre>


<h3>Format</h3>

<p>A data frame with 70 observations on the following 21 variables.
</p>

<dl>
<dt><code>Score</code></dt><dd><p>a numeric vector giving the average attractivness score compiled after 100 student ratings</p>
</dd>
<dt><code>Actual.Sexuality</code></dt><dd><p>a factor with levels <code>Gay</code> <code>Straight</code> indicating the self-reported sexuality of the person in the picture</p>
</dd>
<dt><code>ApparentRace</code></dt><dd><p>a factor with levels <code>black</code> <code>other</code> <code>white</code> indicating the consensus regarding the apparent race of the person</p>
</dd>
<dt><code>Chin</code></dt><dd><p>a factor with levels <code>pointed</code> <code>rounded</code> indicating the consensus regarding the shape of the person's chin</p>
</dd> 
<dt><code>Cleavage</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code> indicating the consensus regarding whether the pictured woman was prominently displaying cleavage</p>
</dd>
<dt><code>ClothingStyle</code></dt><dd><p>a factor with levels <code>conservative</code> <code>revealing</code> indicating the consensus regarding how the women was dressed</p>
</dd>
<dt><code>FaceSymmetryScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 2) who agreed the woman's case was symmetric</p>
</dd>
<dt><code>FashionScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 4) who agreed the woman was fashionable</p>
</dd>
<dt><code>FitnessScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 4) who agreed the woman was physically fit</p>
</dd>
<dt><code>GayScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 16) who agreed the woman was a lesbian</p>
</dd>
<dt><code>Glasses</code></dt><dd><p>a factor with levels <code>Glasses</code> <code>No Glasses</code></p>
</dd>
<dt><code>GroomedScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 4) who agreed the woman made a noticeable effort to look nice</p>
</dd>
<dt><code>HairColor</code></dt><dd><p>a factor with levels <code>dark</code> <code>light</code> indicating the consensus regarding the woman's hair color</p>
</dd>
<dt><code>HairstyleUniquess</code></dt><dd><p>a numeric vector indicating the number of people (out of 2) who agreed the woman had an unconventional haircut</p>
</dd>
<dt><code>HappinessRating</code></dt><dd><p>a numeric vector indicating the number of people (out of 2) who agreed the woman looked happy in her photo</p>
</dd>
<dt><code>LookingAtCamera</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>MakeupScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 5) who agreed the woman was wearing a noticeable amount of makeup</p>
</dd>
<dt><code>NoseOddScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 3) who agreed the woman had an unusually shaped nose</p>
</dd>
<dt><code>Selfie</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>SkinClearScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 2) who agreed the woman's complexion was clear.</p>
</dd>
<dt><code>Smile</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Students were asked to rate on a scale of 1 (very unattractive) to 5 (very attractive) the attractiveness of 70 college-aged women who had posted their photos on a dating website.  Of the nearly 100 respondents, most were straight males.  <code>Score</code> represents the average of these ratings.
</p>
<p>In a separate survey, students (of both genders) were asked to rate characteristics of the woman by answering the questions:  what is her race, is she displaying her cleavage prominently, is she a lesbian, is she physically fit, etc.  The variables ending &ldquo;Score&quot; represent the number of students who answered Yes to the question.  Other variables (such as <code>Selfie</code>, <code>Smile</code>) represent the consensus among the students.  The only attribute taken from the woman's profile was <code>Actual.Sexuality</code>.
</p>


<h3>Source</h3>

<p>Students in BAS 320 at the University of Tennessee from 2013-2015.
</p>

<hr>
<h2 id='ATTRACTM'>
Attractiveness Score (male)
</h2><span id='topic+ATTRACTM'></span>

<h3>Description</h3>

<p>The average attractiveness scores of 70 males along with physical attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ATTRACTM")</code></pre>


<h3>Format</h3>

<p>A data frame with 70 observations on the following 23 variables.
</p>

<dl>
<dt><code>Score</code></dt><dd><p>a numeric vector giving the average attractivness score compiled after 60 student ratings</p>
</dd>
<dt><code>Actual.Sexuality</code></dt><dd><p>a factor with levels <code>Gay</code> <code>Straight</code>  indicating the self-reported sexuality of the person in the picture</p>
</dd>
<dt><code>ApparentRace</code></dt><dd><p>a factor with levels <code>black</code> <code>other</code> <code>white</code> indicating the consensus regarding the apparent race of the person</p>
</dd>
<dt><code>Chin</code></dt><dd><p>a factor with levels <code>pointed</code> <code>rounded</code> indicating the consensus regarding the shape of the person's chin</p>
</dd>
<dt><code>ClothingStyle</code></dt><dd><p>a factor with levels <code>conservative</code> <code>revealing</code> indicating the consensus regarding how the man was dressed</p>
</dd>
<dt><code>FaceSymmetryScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 7) who agreed the woman's case was symmetric</p>
</dd>
<dt><code>FacialHair</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code> indicating the consensus regarding whether the man appeared to maintain facial hair</p>
</dd>
<dt><code>FashionScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 7) who agreed the woman was fashionable</p>
</dd>
<dt><code>FitnessScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 8) who agreed the woman was physically fit</p>
</dd>
<dt><code>GayScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 16) who agreed the man was gay</p>
</dd>
<dt><code>Glasses</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>GroomedScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 6) who agreed the woman made a noticeable effort to look nice</p>
</dd>
<dt><code>HairColor</code></dt><dd><p>a factor with levels <code>dark</code> <code>light</code> <code>unseen</code> indicating the consensus regarding the man's hair color</p>
</dd>
<dt><code>HairstyleUniquess</code></dt><dd><p>a numeric vector indicating the number of people (out of 4) who agreed the woman had an unconventional haircut</p>
</dd>
<dt><code>HappinessRating</code></dt><dd><p>a numeric vector indicating the number of people (out of 6) who agreed the man looked happy in her photo</p>
</dd>
<dt><code>Hat</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>LookingAtCamera</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>NoseOddScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 3) who agreed the woman had an unusually shaped nose</p>
</dd>
<dt><code>Piercings</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code> indicating whether the man had visible piercings</p>
</dd>
<dt><code>Selfie</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>SkinClearScore</code></dt><dd><p>a numeric vector indicating the number of people (out of 2) who agreed the woman's complexion was clear.</p>
</dd>
<dt><code>Smile</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>Tattoo</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Students were asked to rate on a scale of 1 (very unattractive) to 5 (very attractive) the attractiveness of 70 college-aged men who had posted their photos on a dating website.  Of the nearly 60 respondents, most were straight females.  <code>Score</code> represents the average of these ratings.
</p>
<p>In a separate survey, students (of both genders) were asked to rate characteristics of the man by answering the questions:  what is his race, how symmetric does his face look, is he gay, is he physically fit, etc.  The variables ending &ldquo;Score&quot; represent the number of students who answered Yes to the question.  Other variables (such as <code>Hat</code>, <code>Smile</code>) represent the consensus among the students.  The only attribute taken from the man's profile was <code>Actual.Sexuality</code>.
</p>


<h3>Source</h3>

<p>Students in BAS 320 at the University of Tennessee from 2013-2015.
</p>

<hr>
<h2 id='AUTO'>
AUTO dataset
</h2><span id='topic+AUTO'></span>

<h3>Description</h3>

<p>Characteristics of cars from 1991
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("AUTO")</code></pre>


<h3>Format</h3>

<p>A data frame with 82 observations on the following 5 variables.
</p>

<dl>
<dt><code>CabVolume</code></dt><dd><p>a numeric vector, cubic feet of cab space</p>
</dd>
<dt><code>Horsepower</code></dt><dd><p>a numeric vector, engine horsepower</p>
</dd>
<dt><code>FuelEfficiency</code></dt><dd><p>a numeric vector, average miles per gallon</p>
</dd>
<dt><code>TopSpeed</code></dt><dd><p>a numeric vector, miles per hour</p>
</dd>
<dt><code>Weight</code></dt><dd><p>a numeric vector, in units of 100 lbs</p>
</dd>
</dl>



<h3>Details</h3>

<p>Although this is a popular dataset, there is some question as to the units of the fuel efficiency.  The source claims it to be in miles per gallon, but the numbers reported seem unrealistic.  However, the units do not appear to be in km/gallon or km/L.
</p>


<h3>Source</h3>

<p>Data provided by the U.S. Environmental Protection Agency and obtained from the (former) Data and Story library
</p>


<h3>References</h3>

<p>R.M. Heavenrich, J.D. Murrell, and K.H. Hellman, Light Duty Automotive
Technology and Fuel Economy Trends Through 1991, U.S. Environmental Protection
Agency, 1991 (EPA/AA/CTAB/91-02)</p>

<hr>
<h2 id='BODYFAT'>
BODYFAT data
</h2><span id='topic+BODYFAT'></span>

<h3>Description</h3>

<p>Popular Bodyfat dataset 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("BODYFAT")</code></pre>


<h3>Format</h3>

<p>A data frame with 252 observations on the following 14 variables.
</p>

<dl>
<dt><code>BodyFat</code></dt><dd><p>a numeric vector indicating the percentage body fat 0-100</p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector, yrs</p>
</dd>
<dt><code>Weight</code></dt><dd><p>a numeric vector, lbs</p>
</dd>
<dt><code>Height</code></dt><dd><p>a numeric vector, inches</p>
</dd>
<dt><code>Neck</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Chest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Abdomen</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Hip</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Thigh</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Knee</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Ankle</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Biceps</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Forearm</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Wrist</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Bodyfat can be accurately measured by the hydrostatic technique, where someone is submereged in a tank of water.  It would be useful to be able to predict body fat from measurements that are simpler to obtain.  Unless otherwise specified, all physical measurements are in centimeters.
</p>


<h3>Source</h3>

<p>This is a modified version of the data available in &ldquo;Fitting Percentage of Body Fat to Simple Body Measurements&quot; as appearing in Journal of Statistics Education v4 n1 (1996).  <a href="http://www.amstat.org/publications/jse/v4n1/datasets.johnson.html">http://www.amstat.org/publications/jse/v4n1/datasets.johnson.html</a>
</p>

<hr>
<h2 id='BODYFAT2'>
Secondary BODYFAT dataset
</h2><span id='topic+BODYFAT2'></span>

<h3>Description</h3>

<p>Bodyfat dataset illustrating quirks of statistical significance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("BODYFAT2")</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 4 variables.
</p>

<dl>
<dt><code>Triceps</code></dt><dd><p>a numeric vector, cm</p>
</dd>
<dt><code>Thigh</code></dt><dd><p>a numeric vector, cm</p>
</dd>
<dt><code>Midarm</code></dt><dd><p>a numeric vector, cm</p>
</dd>
<dt><code>BodyFat</code></dt><dd><p>a numeric vector, 0-100 representing percent</p>
</dd>
</dl>



<h3>Details</h3>

<p>The physical measurements are circumferences of body parts of 25-34 year-old healthy females.
</p>


<h3>Source</h3>

<p>This is a classic dataset found in many textbooks and in many places online.  The original source may be Neter, Kutner, Nachtsheim, Wasserman, 1997, p. 261: Applied Statistical Models (4th Edition). 
</p>

<hr>
<h2 id='build_model'>
Variable selection for descriptive or predictive linear and logistic regression models
</h2><span id='topic+build.model'></span><span id='topic+build_model'></span>

<h3>Description</h3>

<p>This function uses <code>bestglm</code> to consider an extensive array of models and makes recommendations on what set of variables is appropriate for the final model.  Model hierarchy is not preserved.  Interactions and multi-level categorical variables are allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_model(form,data,type="predictive",Kfold=5,repeats=10,
prompt=TRUE,seed=NA,holdout=NA,...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build_model_+3A_form">form</code></td>
<td>

<p>A model formula giving the most complex model to consider (often predicting y from all variables <code>y~.</code> or all variables including two-way interactions <code>y~.^2</code>)
</p>
</td></tr>
<tr><td><code id="build_model_+3A_data">data</code></td>
<td>

<p>Name of the data frame that contain all variables specifed by <code>form</code>
</p>
</td></tr>
<tr><td><code id="build_model_+3A_type">type</code></td>
<td>

<p>Either &quot;predictive&quot; or &quot;descriptive&quot;.  If <code>predictive</code>, the procedure estimates the generalization error of candidate models via repeated K-fold cross-validation.  If <code>descriptive</code>, the procedure calculates the AICs of models.
</p>
</td></tr>
<tr><td><code id="build_model_+3A_kfold">Kfold</code></td>
<td>

<p>The number of folds for repeated K-fold cross-validation for predictive model building
</p>
</td></tr>
<tr><td><code id="build_model_+3A_repeats">repeats</code></td>
<td>

<p>The number of repeats for repeated K-fold cross-validation for predictive model building
</p>
</td></tr>
<tr><td><code id="build_model_+3A_seed">seed</code></td>
<td>

<p>If specified, the random number seed used to initialize the repeated K-fold cross-validation procedure so that results can be reproduced.
</p>
</td></tr>
<tr><td><code id="build_model_+3A_prompt">prompt</code></td>
<td>

<p>If <code>FALSE</code>, the procedure will not output a warning to the user if fitting the candidate set will take &quot;long&quot;.  Usually only run with <code>FALSE</code> for documentation purposes.  
</p>
</td></tr>
<tr><td><code id="build_model_+3A_holdout">holdout</code></td>
<td>

<p>A optional dataframe to serve as a holdout sample.  The generalization error on the holdout sample will be calculated and displayed for the best model at each number of predictors.
</p>
</td></tr>
<tr><td><code id="build_model_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code>bestglm</code>.  This allows the procedure to do a search rather than exhaustive enumeration or allows tweaking of the number of reported models or maximum number of independent variables (<code>nvmax</code>), etc.  See <code>bestglm</code> and <code><a href="leaps.html#topic+regsubsets">regsubsets</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This procedure takes the formula specified by <code>form</code> and the original dataframe and simply converts it into a form that <code>bestglm</code> (which normally cannot do cross-validation when categorical variables are involved) can use by adding in columns to represent interactions and categorical variables.
</p>
<p>One the dataframe has been generated, a warning is given to the user if the procedure may take too long (many rows or many potential predictors), and then <code>bestglm</code> is run.  A plot and table of models' performances is given, as well as a recommendation for a final set of variables (model with the lowest AIC/estimated generalization error, or a simpler model that is more or less equivalent). 
</p>
<p>The command returns a list with <code>bestformula</code> (the formula of the model with the lowest AIC or the model chosen by the one standard deviation rule), <code>bestmodel</code> (the fitted model that had the lowest AIC or the one chosen by the one standard deviation rule), <code>predictors</code> (a list giving the predictors that appeared in the best model with 1 predictor, with 2 predictors, etc).   
</p>
<p>If a descriptive model is sought, the last component of the returned list is <code>AICtable</code> (a data frame containing the number of predictors and the AIC of the best model with that number of predictors; a * denotes the model with the lowest AIC while a + denotes the simplest model whose AIC is within 2 of the lowest).  
</p>
<p>If a predictive model is sought, the last component of the returned list is <code>CVtable</code> (a data frame containing the number of predictors and the estimated generalization error of the best model with that number of predictors along with the SD from repeated K-fold cross validation; a * denotes the model with the lowest error while the + denotes the model selected with the one standard deviation rule).  Note that the generalization error in the second column of this table is the squared error if the response is quantitative and is another measure of error (not the misclassification rate) if the response is categorical.  Additional columns are provided to give the root mean squared error or misclassification rate.
</p>
<p>Note:  <code>bestmodel</code> is the one selected by the one standard deviation rule or the simplest one whose AIC is no more than 2 above the model with the lowest AIC.  Because the procedure does not respect model hierarchy and can include interactions, the formula returned may not be immediately useable if it involves a categorical variable since the variable returned is how R names indicator variables.  You may have to manually fit the model based on the selected predictors.
</p>
<p>If <code>HOLDOUT</code> is given a plot of the error on the holdout sample versus the number of predictors (for the best model at that number of predictors) is provided along with the estimated generalization error from the training set.  This can be used to see if the models generalize well, but is in general not used to tune which model is selected.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling with R
</p>


<h3>See Also</h3>

<p><code>bestglm</code>, <code><a href="leaps.html#topic+regsubsets">regsubsets</a></code>, <code><a href="#topic+see.models">see.models</a></code>, <code><a href="#topic+generalization.error">generalization.error</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  #Descriptive model.  Note: Tip and Bill should not be used simultaneously as 
  #predictors of TipPercentage, so leave Tip out since it's not known ahead of time
  data(TIPS)
  MODELS &lt;- build_model(TipPercentage~.-Tip,data=TIPS,type="descriptive")
  MODELS$AICtable
  MODELS$predictors[[1]] #Variable in best model with a single predictors
  MODELS$predictors[[2]] #Variables in best model with two predictors
  summary(MODELS$bestmodel) #Summary of best model, in this case with two predictors

  #Another descriptive model (large dataset so changing prompt=FALSE for documentation)
  data(PURCHASE)
  set.seed(320)
  #Take a subset of full dataframe for quick illustration
  SUBSET &lt;- PURCHASE[sample(nrow(PURCHASE),500),]
  MODELS &lt;- build_model(Purchase~.,data=SUBSET,type="descriptive",prompt=FALSE)
  MODELS$AICtable  #Model with 1 or 2 variables look pretty good
  #Predict whether a purchase is made by # of previous visits and distance to store
	MODELS$predictors[[2]]  

  #Predictive model.  
  data(SALARY)
  set.seed(2010)
  train.rows &lt;- sample(nrow(SALARY),0.7*nrow(SALARY),replace=TRUE)
  TRAIN &lt;- SALARY[train.rows,]
  HOLDOUT &lt;- SALARY[-train.rows,]
  MODELS &lt;- build_model(Salary~.^2,data=TRAIN,holdout=HOLDOUT)
  summary(MODELS$bestmodel)
  M &lt;- lm(Salary~Gender+Education:Months,data=TRAIN)
  generalization_error(M,HOLDOUT)
  
  #Predictive model for WINE data, takes a while.  Misclassification rate on holdout sample is 18%.
  data(WINE)
  set.seed(2010)
  train.rows &lt;- sample(nrow(WINE),0.7*nrow(WINE),replace=TRUE)
  TRAIN &lt;- WINE[train.rows,]
  HOLDOUT &lt;- WINE[-train.rows,]
  ## Not run: MODELS &lt;- build_model(Quality~.,data=TRAIN,seed=1919,holdout=HOLDOUT)
  ## Not run: MODELS$CVtable
	 </code></pre>

<hr>
<h2 id='build_tree'>
Exploratory building of partition models
</h2><span id='topic+build.tree'></span><span id='topic+build_tree'></span>

<h3>Description</h3>

<p>A tool to choose the &quot;correct&quot; complexity parameter of a tree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_tree(form, data, minbucket = 5, seed=NA, holdout, mincp=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build_tree_+3A_form">form</code></td>
<td>

<p>A formula describing the tree to be built
</p>
</td></tr>
<tr><td><code id="build_tree_+3A_data">data</code></td>
<td>

<p>Data frame containing the variables to build the tree
</p>
</td></tr>
<tr><td><code id="build_tree_+3A_minbucket">minbucket</code></td>
<td>

<p>The minimum number of cases allowed in any leaf in the tree
</p>
</td></tr>
<tr><td><code id="build_tree_+3A_seed">seed</code></td>
<td>

<p>If given, specifies the random number seed so the crossvalidation error can be reproduced.
</p>
</td></tr>
<tr><td><code id="build_tree_+3A_holdout">holdout</code></td>
<td>

<p>If given, the error on the holdout sample is calculated and given in the cp table.
</p>
</td></tr>
<tr><td><code id="build_tree_+3A_mincp">mincp</code></td>
<td>
<p>The <code>cp</code> parameter to which the tree will be grown.  By default it is 0 (recommended), but it can be changed for large datasets.  A value of 0.0001 is likely reasonable.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This command combines the action of building a tree to its maximum possible extent using <code>rpart</code> and looking at the results using <code>getcp</code>.  A plot of the estimated relative generalization error (as determined by 10-fold cross validation) versus the number of splits is provided.  In addition, the complexity parameter table giving the <code>cp</code> of the tree with the lowest error (and of the simplest tree with an error within one standard deviation of the lowest error) is reported.
</p>
<p>If <code>holdout</code> is given, the RMSE/misclassification rate on the training and holdout samples are provided in the cp table.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="rpart.html#topic+rpart">rpart</a></code>, <code><a href="#topic+getcp">getcp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(JUNK)
  build_tree(Junk~.,data=JUNK,seed=1337)
  data(CENSUS)
  build_tree(ResponseRate~.,data=CENSUS,seed=2017,mincp=0.001)
  data(OFFENSE)
  build_tree(Win~.,data=OFFENSE[1:200,],seed=2029,holdout=OFFENSE[201:352,])
</code></pre>

<hr>
<h2 id='BULLDOZER'>
BULLDOZER data
</h2><span id='topic+BULLDOZER'></span>

<h3>Description</h3>

<p>Predicting the sales price of a bulldozer at auction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("BULLDOZER")</code></pre>


<h3>Format</h3>

<p>A data frame with 924 observations on the following 6 variables.
</p>

<dl>
<dt><code>SalePrice</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>YearsAgo</code></dt><dd><p>a numeric vector, the number of years ago (before present) that the sale occurred</p>
</dd>
<dt><code>YearMade</code></dt><dd><p>a numeric vector, year of manufacture of machine</p>
</dd>
<dt><code>Usage</code></dt><dd><p>a numeric vector, hours of usage at time of sale</p>
</dd>
<dt><code>Blade</code></dt><dd><p>a numeric vector, width of the bulldozer blade (feet)</p>
</dd>
<dt><code>Tire</code></dt><dd><p>a numeric vector, size of primary tires</p>
</dd>
</dl>



<h3>Details</h3>

<p>The goal is to predict the sale price of a particular piece of heavy equiment at auction based on its usage, equipment type, and configuration.  The data represents a heavily modified version of competition data found on kaggle.com.  See original source for actual dataset</p>


<h3>References</h3>

<p><a href="https://www.kaggle.com/c/bluebook-for-bulldozers">https://www.kaggle.com/c/bluebook-for-bulldozers</a>
</p>

<hr>
<h2 id='BULLDOZER2'>
Modified BULLDOZER data
</h2><span id='topic+BULLDOZER2'></span>

<h3>Description</h3>

<p>The BULLDOZER dataset but with the year the dozer was made as a categorical variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("BULLDOZER2")</code></pre>


<h3>Format</h3>

<p>A data frame with 924 observations on the following 6 variables.
</p>

<dl>
<dt><code>Price</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>YearsAgo</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Usage</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Tire</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Decade</code></dt><dd><p>a factor with levels <code>1960s and 1970s</code> <code>1980s</code> <code>1990s</code> <code>2000s</code></p>
</dd>
<dt><code>BladeSize</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is the <code>BULLDOZER</code> data except here <code>YearMade</code> has been coded into a four level categorical varaible called <code>Decade</code>
</p>

<hr>
<h2 id='CALLS'>
CALLS dataset
</h2><span id='topic+CALLS'></span>

<h3>Description</h3>

<p>Summary of students' cell phone providers and relative frequency of dropped calls
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CALLS")</code></pre>


<h3>Format</h3>

<p>A data frame with 579 observations on the following 2 variables.
</p>

<dl>
<dt><code>Provider</code></dt><dd><p>a factor with levels <code>ATT</code> <code>Sprint</code> <code>USCellular</code> <code>Verizon</code></p>
</dd>
<dt><code>DropCallFreq</code></dt><dd><p>a factor with levels <code>Occasionally</code> <code>Often</code> <code>Rarely</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Data is self-reported by students.  The dropped call frequency is based on individuals' perceptions and not any independent quantititatve measure.  The data is a subset of <code>SURVEY09</code>.
</p>


<h3>Source</h3>

<p>Student survey from STAT 201, University of Tennessee Knoxville, Fall 2009
</p>

<hr>
<h2 id='CENSUS'>
CENSUS data
</h2><span id='topic+CENSUS'></span>

<h3>Description</h3>

<p>Information from the 2010 US Census
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CENSUS")</code></pre>


<h3>Format</h3>

<p>A data frame with 3534 observations on the following 39 variables.
</p>

<dl>
<dt><code>ResponseRate</code></dt><dd><p>a numeric vector, 0-100 representing the percentage of households in a block group that mailed in the form</p>
</dd>
<dt><code>Area</code></dt><dd><p>a numeric vector, land area in square miles</p>
</dd>
<dt><code>Urban</code></dt><dd><p>a numeric vector, percentage of block group in Urbanized area (50000 or greater)</p>
</dd>
<dt><code>Suburban</code></dt><dd><p>a numeric vector, percentage of block group in an Urban Cluster area (2500 to 49999)</p>
</dd>
<dt><code>Rural</code></dt><dd><p>a numeric vector, percentage of block group in an Urban Cluster area (2500 to 49999)</p>
</dd>
<dt><code>Male</code></dt><dd><p>a numeric vector, percentage of males</p>
</dd>
<dt><code>AgeLess5</code></dt><dd><p>a numeric vector, percentage of individuals aged less than 5 years old</p>
</dd>
<dt><code>Age5to17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age18to24</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age25to44</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age45to64</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age65plus</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Hispanics</code></dt><dd><p>a numeric vector, percentage of individuals who identify as Hispanic</p>
</dd>
<dt><code>Whites</code></dt><dd><p>a numeric vector, percentage of individuals who identify as white (alone)</p>
</dd>
<dt><code>Blacks</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NativeAmericans</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Asians</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Hawaiians</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Other</code></dt><dd><p>a numeric vector, percentage of individuals who identify as another ethnicity</p>
</dd>
<dt><code>RelatedHH</code></dt><dd><p>a numeric vector, percentage of households where
at least 2 members are related by birth,
marriage, or adoption; same-sex couple
households with no relatives of the
householder present are not included</p>
</dd>
<dt><code>MarriedHH</code></dt><dd><p>a numeric vector, percentage of  households in
which the householder and his or her
spouse are listed as members of the same
household; does not include same-sex
married couples</p>
</dd>
<dt><code>NoSpouseHH</code></dt><dd><p>a numeric vector, percentage of  households with
no spousal relationship present</p>
</dd>
<dt><code>FemaleHH</code></dt><dd><p>a numeric vector, percentage of  households with a
female householder and no husband of
householder present</p>
</dd>
<dt><code>AloneHH</code></dt><dd><p>a numeric vector, percentage of  households where householder is living alone</p>
</dd>
<dt><code>WithKidHH</code></dt><dd><p>a numeric vector, percentage of  households which have at least one person under the age of 18</p>
</dd>
<dt><code>MedianHHIncomeBlock</code></dt><dd><p>a numeric vector, median income of households in the block group (from American Community Survey)</p>
</dd>
<dt><code>MedianHHIncomeCity</code></dt><dd><p>a numeric vector, median income of households in the tract</p>
</dd>
<dt><code>OccupiedUnits</code></dt><dd><p>a numeric vector, percentage of housing units that are occupied</p>
</dd>
<dt><code>RentingHH</code></dt><dd><p>a numeric vector, percentage of housing units occupied by renters</p>
</dd>
<dt><code>HomeownerHH</code></dt><dd><p>a numeric vector, percentage of housing units occupied by the owner</p>
</dd>
<dt><code>MobileHomeUnits</code></dt><dd><p>a numeric vector, percentage of housing units that are mobile homes (from American Community Survey)</p>
</dd>
<dt><code>CrowdedUnits</code></dt><dd><p>a numeric vector, percentage of housing units with more than 1 person per room on average</p>
</dd>
<dt><code>NoPhoneUnits</code></dt><dd><p>a numeric vector, percentage of housing units without a landline</p>
</dd>
<dt><code>NoPlumbingUnits</code></dt><dd><p>a numeric vector, percentage of housing units without active plumbing</p>
</dd>
<dt><code>NewUnits</code></dt><dd><p>a numeric vector, percentage of housing units constructed in 2010 or later</p>
</dd>
<dt><code>Population</code></dt><dd><p>a numeric vector, number of people in the block group</p>
</dd>
<dt><code>NumHH</code></dt><dd><p>a numeric vector, number of households in the block group</p>
</dd>
<dt><code>NumUnits</code></dt><dd><p>a numeric vector, number of housing units in the block group</p>
</dd>
<dt><code>logMedianHouseValue</code></dt><dd><p>a numeric vector, the logarithm of the median home value in the block group</p>
</dd>
</dl>



<h3>Details</h3>

<p>The goal is to predict <code>ResponseRate</code> from the other predictors.  <code>ResponseRate</code> is the percentage of households in a block group that mailed in the census forms.  A block group is on average about 40 blocks, each typically bounded by streets, roads, or water. The number of block groups per county in the US is typically between about 5 and 165 with a median of about 20.
</p>


<h3>References</h3>

<p>See <a href="https://www2.census.gov/programs-surveys/research/guidance/planning-databases/2014/pdb-block-2014-11-20a.pdf">https://www2.census.gov/programs-surveys/research/guidance/planning-databases/2014/pdb-block-2014-11-20a.pdf</a> for variable definitions.
</p>

<hr>
<h2 id='CENSUSMLR'>
Subset of CENSUS data
</h2><span id='topic+CENSUSMLR'></span>

<h3>Description</h3>

<p>A portion of the CENSUS dataset used for illustration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CENSUSMLR")</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 observations on the following 7 variables.
</p>

<dl>
<dt><code>Response</code></dt><dd><p>a numeric vector, percentage 0-100 of household that mailed in the census form</p>
</dd>
<dt><code>Population</code></dt><dd><p>a numeric vector, the number of people living in the census block based on 2010 census</p>
</dd>
<dt><code>ACSPopulation</code></dt><dd><p>a numeric vector, the number of people living in the census block based on 2010 census</p>
</dd>
<dt><code>Rural</code></dt><dd><p>a numeric vector, the number of people living in a rural area (in that census block)</p>
</dd>
<dt><code>Males</code></dt><dd><p>a numeric vector, the number of males living in the census block</p>
</dd>
<dt><code>Elderly</code></dt><dd><p>a numeric vector, the number of people aged 65+ living in the census block</p>
</dd>
<dt><code>Hispanic</code></dt><dd><p>a numeric vector, the number of people who self-identify as Hispanic in the census block</p>
</dd>
</dl>



<h3>Details</h3>

<p>See <code>CENSUS</code> data for more information.
</p>

<hr>
<h2 id='CHARITY'>
CHARITY dataset </h2><span id='topic+CHARITY'></span>

<h3>Description</h3>

<p>Charity data (adapted from a small section of a charity's donor database)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CHARITY")</code></pre>


<h3>Format</h3>

<p>A data frame with 15283 observations on the following 11 variables.
</p>

<dl>
<dt><code>Donate</code></dt><dd><p>a factor with levels <code>Donate</code> <code>No</code></p>
</dd>
<dt><code>Homeowner</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>F</code> <code>M</code></p>
</dd>
<dt><code>UnlistedPhone</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>ResponseProportion</code></dt><dd><p>a numeric vector giving the fraction of solications that resulted in a donation</p>
</dd>
<dt><code>NumResponses</code></dt><dd><p>a numeric vector giving the number of past donations</p>
</dd>
<dt><code>CardResponseCount</code></dt><dd><p>a numeric vector giving the number of past solicitations</p>
</dd>
<dt><code>MonthsSinceLastResponse</code></dt><dd><p>a numeric vector giving the number of months since last response to solicitation (which may have been declining to give)</p>
</dd>
<dt><code>LastGiftAmount</code></dt><dd><p>a numeric vector giving the amount of the last donation</p>
</dd>
<dt><code>MonthSinceLastGift</code></dt><dd><p>a numeric vector giving the number of months since last donation</p>
</dd>
<dt><code>LogIncome</code></dt><dd><p>a numeric vector giving the logarithm of a scaled and normalized yearly income</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is adapted from a real-world database of donors to a charity.
</p>


<h3>Source</h3>

<p>Unknown
</p>

<hr>
<h2 id='check_regression'>
Linear and Logistic Regression diagnostics
</h2><span id='topic+check.regression'></span><span id='topic+check_regression'></span>

<h3>Description</h3>

<p>If the model is a linear regression, obtain tests of linearity, equal spread, and Normality as well as relevant plots (residuals vs. fitted values, histogram of residuals, QQ plot of residuals, and predictor vs. residuals plots).  If the model is a logistic regression model, a goodness of fit test is given. </p>


<h3>Usage</h3>

<pre><code class='language-R'>check_regression(M,extra=FALSE,tests=TRUE,simulations=500,n.cats=10,seed=NA,prompt=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_regression_+3A_m">M</code></td>
<td>

<p>A regression model fitted with either <code><a href="stats.html#topic+lm">lm</a></code> or <code><a href="stats.html#topic+glm">glm</a></code>
</p>
</td></tr>
<tr><td><code id="check_regression_+3A_extra">extra</code></td>
<td>

<p>If <code>TRUE</code>, allows user to generate the predictor vs. residual plots for linear regression models.  
</p>
</td></tr>
<tr><td><code id="check_regression_+3A_tests">tests</code></td>
<td>

<p>If <code>TRUE</code>, performs statistical tests of assumptions.  If <code>FALSE</code>, only visual diagnostics are provided.
</p>
</td></tr>
<tr><td><code id="check_regression_+3A_simulations">simulations</code></td>
<td>

<p>The number of artificial samples to generate for estimating the p-value of the goodness of fit test for logistic regression models.  These artificial samples are generated assuming the fitted logistic regression is correct.
</p>
</td></tr>
<tr><td><code id="check_regression_+3A_n.cats">n.cats</code></td>
<td>

<p>Number of (roughly) equal sized categories for the Hosmer-Lemeshow goodness of fit test for logistic regression models
</p>
</td></tr>
<tr><td><code id="check_regression_+3A_seed">seed</code></td>
<td>

<p>If specified, sets the random number seed before generation of artificial samples in the goodness of fit tests for logistic regression models.
</p>
</td></tr>
<tr><td><code id="check_regression_+3A_prompt">prompt</code></td>
<td>

<p>For documentation only, if <code>FALSE</code>, skips prompting user for extra plots
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides standard visual and statistical diagnostics for regression models.  
</p>
<p>For linear regression, tests of linearity, equal spread, and Normality are performed and residuals plots are generated.
</p>
<p>The test for linearity (a goodness of fit test) is an F-test.  A simple linear regression model predicting y from x is fit and compared to a model treating each value of the predictor as some level of a categorical variable.  If this more sophisticated model does not offer a significant improvement in the sum of squared errors, the linearity assumption in that predictor is reasonable.  If the p-value is larger 0.05, then statistically we can consider the relationship to be linear.  If the p-value is smaller than 0.05, check the residuals plot and the predictor vs residuals plots for signs of obvious curvature (the test can be overly sensitive to inconsequential violations for larger sample sizes).  The test can only be run if are two or more individuals that have a common value of x.  A test of the model as a whole is run similarly if at least two individuals have identical combinations of all predictor variables.
</p>
<p>Note:  if categorical variables, interactions, polynomial terms, etc., are present in the model, the test for linearity is conducted for each term even when it does not necessarily make sense to do so.
</p>
<p>The test for equal spread is the Breusch-Pagan test.  If the p-value is larger 0.05, then statistically we can consider the residuals to have equal spread everywhere.  If the p-value is smaller than 0.05, check the residuals plot for obvious signs of unequal spread (the test can be overly sensitive to inconsequential violations for larger sample sizes).
</p>
<p>The test for Normality is the Shapiro-Wilk test when the sample size is smaller than 5000, or the KS-test for larger sample sizes.  If the p-value is larger 0.05, then statistically we can consider the residuals to be Normally distributed. If the p-value is smaller than 0.05, check the histogram and QQ plot of residuals to look for obvious signs of non-Normality (e.g., skewness or outlier).  The test can be overly sensitive to inconsequential violations for larger sample sizes.
</p>
<p>The first three plots displayed are the residuals plot (residuals vs. fitted values), histogram of residuals, and QQ plot of residuals.  The function gives the option of pressing Enter to display additional predictor vs. residual plots if <code>extra=TRUE</code>, or to terminate by typing 'q' in the console and pressing Enter.  If polynomial or interactions terms are present in the model, a plot is provided for each term.  If categorical predictors are present, plots are provided for each indicator variable.
</p>
<p>For logistic regression, two goodness of fit tests are offered.
</p>
<p>Method 1 is a crude test that assumes the fitted logistic regression is correct, then generates an artifical sample according the predicted probabilities.  A chi-squared test is conducted that compares the observed levels to the predicted levels.  The test is failed is the p-value is less than 0.05.  The test is not sensitive to departures from the logistic curve unless the sample size is very large or the logistic curve is a really bad model.
</p>
<p>Method 2 is a Hosmer-Lemeshow type goodness of fit test.  The observations are put into 10 groups according to the probability predicted by the logistic regression model.  For example, if there were 200 observations, the first group would have the cases with the 20 smallest predicted probabilities, the second group would have the cases with the 20 next smallest probabilities, etc.  The number of cases with the level of interest is compared with the expected number given the fitted logistic regression model via a chi-squared test.  The test is failed is the p-value is less than 0.05. 
</p>
<p>Note:  for both methods, the p-values of the chi-squared tests are estimate via Monte Carlo simulation instead of any asymptotic results.  
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code>, <code><a href="stats.html#topic+ks.test">ks.test</a></code>, bptest (in package lmtest).  The goodness of fit test for logistic regression is further detailed and implemented in package 'rms' using the commands lrm and residuals. </p>


<h3>Examples</h3>

<pre><code class='language-R'>  #Simple linear regression where everything looks good 
  data(FRIEND)
  M &lt;- lm(FriendshipPotential~Attractiveness,data=FRIEND)
  check_regression(M)
  
  #Multiple linear regression (prompt is FALSE only for documentation)
  data(AUTO)
  M &lt;- lm(FuelEfficiency~.,data=AUTO)
  check_regression(M,extra=TRUE,prompt=FALSE)
  
  
  #Multiple linear regression with a categorical predictors and an interaction
  data(TIPS)
  M &lt;- lm(TipPercentage~Bill*PartySize*Weekday,data=TIPS)
  check_regression(M)
  
  #Multiple linear regression with polynomial term (prompt is FALSE only for documentation)
  #Note:  in this example only plots are provided
  data(BULLDOZER)
  M &lt;- lm(SalePrice~.-YearMade+poly(YearMade,2),data=BULLDOZER)
  check_regression(M,extra=TRUE,tests=FALSE,prompt=FALSE)

  #Simple logistic regression.  Use 8 categories since only 8 unique values of Dose
  data(POISON)
	M &lt;- glm(Outcome~Dose,data=POISON,family=binomial)
	check_regression(M,n.cats=8,seed=892)

  #Multiple logistic regression
  data(WINE)
  M &lt;- glm(Quality~.,data=WINE,family=binomial)
	check_regression(M,seed=2010)

  
	 </code></pre>

<hr>
<h2 id='choose_order'>
Choosing order of a polynomial model
</h2><span id='topic+choose.order'></span><span id='topic+choose_order'></span>

<h3>Description</h3>

<p>This function takes a simple linear regression model and displays the adjusted R^2 and AICc for the original model (order 1) and for polynomial models up to a specified maximum order and plots the fitted models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose_order(M,max.order=6,sort=FALSE,loc="topleft",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose_order_+3A_m">M</code></td>
<td>

<p>A simple linear regression model fitted with lm()
</p>
</td></tr>
<tr><td><code id="choose_order_+3A_max.order">max.order</code></td>
<td>

<p>The maximum order of the polynomial model to consider.
</p>
</td></tr>
<tr><td><code id="choose_order_+3A_sort">sort</code></td>
<td>

<p>How to sort the results.  If TRUE, &quot;R2&quot;, &quot;r2&quot;, &quot;r2adj&quot;, or &quot;R2adj&quot;, sorts from highest to lowest adjusted R^2.  If &quot;AIC&quot;, &quot;aic&quot;, &quot;AICC&quot;, &quot;AICc&quot;, sorts by AICc.
</p>
</td></tr>
<tr><td><code id="choose_order_+3A_loc">loc</code></td>
<td>

<p>Location of the legend.  Can also be &quot;top&quot;, &quot;topright&quot;, &quot;bottomleft&quot;, &quot;bottom&quot;, &quot;bottomright&quot;, &quot;left&quot;, &quot;right&quot;, &quot;center&quot;
</p>
</td></tr>
<tr><td><code id="choose_order_+3A_...">...</code></td>
<td>

<p>Additional arguments to plot(), e.g., pch </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function outputs a table of the order of the polynomial and the according adjusted R^2 and AICc.  One strategy for picking the best order is to find the highest value of R^2 adjusted, then to choose the smallest order (simplest model) that has an R^2 adjusted within 0.005.  Another strategy is the find the lowest value of AICc, then to choose the smallest order that has an AICc no more than 2 higher.
</p>
<p>The scatterplot of the data is provided and the fitted models are displayed as well.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(BULLDOZER)
	M &lt;- lm(SalePrice~YearMade,data=BULLDOZER)
  #Unsorted list, messing with plot options to make it look alright
	choose_order(M,pch=20,cex=.3)
	
	#Sort by R2adj.  A 10th order polynomial is highest, but this seems overly complex
	choose_order(M,max.order=10,sort=TRUE)

	#Sort by AICc.  4th order is lowest, but 2nd order is simpler and within 2 of lowest
	choose_order(M,max.order=10,sort="aic")

	 </code></pre>

<hr>
<h2 id='CHURN'>
CHURN dataset </h2><span id='topic+CHURN'></span>

<h3>Description</h3>

<p>Churn data (artificial based on claims similar to real world) from the UCI data repository
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CHURN")</code></pre>


<h3>Format</h3>

<p>A data frame with 5000 observations on the following 18 variables.
</p>

<dl>
<dt><code>churn</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>accountlength</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>internationalplan</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>voicemailplan</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>numbervmailmessages</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totaldayminutes</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totaldaycalls</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totaldaycharge</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totaleveminutes</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalevecalls</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalevecharge</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalnightminutes</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalnightcalls</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalnightcharge</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalintlminutes</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalintlcalls</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>totalintlcharge</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>numbercustomerservicecalls</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is modified from the one stored at the UCI data repository (namely, the area code and phone number have been deleted).  This is artificial data similar to what is found in actual customer profiles.  Charges are in dollars.
</p>


<h3>Source</h3>

<p>Though originally on the UCI data repository, actual data was obtained via <a href="https://www.sgi.com/tech/mlc/db/">https://www.sgi.com/tech/mlc/db/</a>
</p>

<hr>
<h2 id='combine_rare_levels'>
Combines rare levels of a categorical variable
</h2><span id='topic+combine_rare_levels'></span>

<h3>Description</h3>

<p>This function takes a categorical variable and combines all levels with frequencies less than a user-specified threshold named <code>Combined</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_rare_levels(x,threshold=20,newname="Combined")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combine_rare_levels_+3A_x">x</code></td>
<td>
<p>a vector of categorical values</p>
</td></tr>
<tr><td><code id="combine_rare_levels_+3A_threshold">threshold</code></td>
<td>
<p>levels that appear a total of <code>threshold</code> times or fewer will be combined into a new level called <code>Combined</code> </p>
</td></tr>
<tr><td><code id="combine_rare_levels_+3A_newname">newname</code></td>
<td>
<p>defaults to <code>Combined</code>, but give the option as to what this new level will be called</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a list of two objects:
</p>
<p><code>values</code> - The recoded values of the categorical variable.  All levels which appeared <code>threshold</code> times or fewer are now known as <code>Combined</code>
<code>combined</code> - The levels that have been combined together
</p>
<p>If, after being combined, the <code>newname</code> level has <code>threshold</code> or fewer instances, the remaining level that appears least often is combined as well.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(EX6.CLICK)
	x &lt;- EX6.CLICK[,15]
	table(x)
	
	#Combine all levels which appear 700 or fewer times (AA, CC, DD)
	y &lt;- combine_rare_levels(x,700)
  table( y$values )
  
  #Combine all levels which appear 1350 or fewer times.  This forces BB (which
  #occurs 2422 times) into the Combined level since the three levels that appear
  #fewer than 1350 times do not appear more than 1350 times combined
	y &lt;- combine_rare_levels(x,1350)
  table( y$values )

</code></pre>

<hr>
<h2 id='confusion_matrix'>
Confusion matrix for logistic regression models
</h2><span id='topic+confusion.matrix'></span><span id='topic+confusion_matrix'></span>

<h3>Description</h3>

<p>This function takes the output of a logistic regression created with <code>glm</code> and returns the confusion matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion_matrix(M,DATA=NA) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion_matrix_+3A_m">M</code></td>
<td>

<p>A logistic regression model created with <code><a href="stats.html#topic+glm">glm</a></code>
</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_data">DATA</code></td>
<td>

<p>A data frame on which the confusion matrix will be made.  If omitted, the confusion matrix is on the data used in <code>M</code>.  If specified, the data frame must have the same column names as the data used to build the model in <code>M</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes classifications on the data used to build a logistic regression model by predicting the &quot;level of interest&quot; (last alphabetically) when the predicted probability exceeds 50%.  
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+glm">glm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
  #On WINE data as a whole
  data(WINE)
  M &lt;- glm(Quality~.,data=WINE,family=binomial)
  confusion_matrix(M)
  
  #Calculate generalization error using training/holdout
  set.seed(1010)
  train.rows &lt;- sample(nrow(WINE),0.7*nrow(WINE),replace=TRUE)
  TRAIN &lt;- WINE[train.rows,]
  HOLDOUT &lt;- WINE[-train.rows,]
  M &lt;- glm(Quality~.,data=TRAIN,family=binomial)
	confusion_matrix(M,HOLDOUT)
	
	
	#Predicting donation
	#Model predicting from recent average gift amount is significant, but its
	#classifications are the same as the naive model (majority rules)
	data(DONOR)
	M.naive &lt;- glm(Donate~1,data=DONOR,family=binomial)
	confusion_matrix(M.naive)
	M &lt;- glm(Donate~RECENT_AVG_GIFT_AMT,data=DONOR,family=binomial)
	confusion_matrix(M)
	
	 </code></pre>

<hr>
<h2 id='cor_demo'>
Correlation demo
</h2><span id='topic+cor.demo'></span><span id='topic+cor_demo'></span>

<h3>Description</h3>

<p>This function shows the correlation and coefficient of determination as user interactively adds datapoints.  Useful for seeing what different values of correlation look like and seeing the effect of outliers.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_demo(cex.leg=0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_demo_+3A_cex.leg">cex.leg</code></td>
<td>

<p>A number specifying the magnification of legends inside the plot.  Smaller numbers mean smaller font.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows the user to generate data by click on a plot.  Once two points are added, the correlation (r) and coefficient of determination (r^2) are displayed.  When an additional point is added, these values are updated in the upper left with previous values being displayed in the upper right.  The effect of outliers on the correlation and coefficient of determination can easily be illustrated.  Pressing the red UNDO button on the plot will allow you to take away recently added points for further exploration.
</p>
<p>Note:  To end the demo, you MUST click on the red box labeled &quot;End&quot; (or press Escape, which will return an error)
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>

<hr>
<h2 id='cor_matrix'>
Correlation Matrix
</h2><span id='topic+cor.matrix'></span><span id='topic+cor_matrix'></span>

<h3>Description</h3>

<p>This function produces the matrix of correlations between all quantitative variables in a dataframe. </p>


<h3>Usage</h3>

<pre><code class='language-R'>cor_matrix(X,type="pearson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor_matrix_+3A_x">X</code></td>
<td>

<p>A data frame
</p>
</td></tr>
<tr><td><code id="cor_matrix_+3A_type">type</code></td>
<td>

<p>Either <code>pearson</code> or <code>spearman</code>.  If <code>pearson</code>, the Pearson correlations are returned.  If <code>spearman</code>, the Spearman's rank correlations are returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function filters out any non-numerical variables and provides correlations only between quantitative variables.  Best for datasets with only a few variables.  The correlation matrix is returned (with class <code>matrix</code>).
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+cor">cor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(TIPS)
	cor_matrix(TIPS)
	data(AUTO)
	cor_matrix(AUTO,type="spearman")
	 </code></pre>

<hr>
<h2 id='CUSTCHURN'>
CUSTCHURN dataset </h2><span id='topic+CUSTCHURN'></span>

<h3>Description</h3>

<p>Customer database describing customer churn (adapted from a former case study)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CUSTCHURN")</code></pre>


<h3>Format</h3>

<p>A data frame with 500 observations on the following 11 variables.
</p>

<dl>
<dt><code>Duration</code></dt><dd><p>a numeric vector giving the days that the company was considered a customer.  Note:  censored at 730 days, which is the value for someone who is currently a customer (not churned)</p>
</dd>
<dt><code>Churn</code></dt><dd><p>a factor with levels <code>N</code> <code>Y</code> giving whether the customer has churned or not</p>
</dd>
<dt><code>RetentionCost</code></dt><dd><p>a numeric vector giving the average amount of money spent per year to retain the individual or company as a customer</p>
</dd>
<dt><code>EBiz</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code> giving whether the customer was an e-business or not</p>
</dd>
<dt><code>CompanyRevenue</code></dt><dd><p>a numeric vector giving the company's revenue</p>
</dd>
<dt><code>CompanyEmployees</code></dt><dd><p>a numeric vector giving the number of employees working for the company</p>
</dd>
<dt><code>Categories</code></dt><dd><p>a numeric vector giving the number of product categories from which customer made a purchase of their lifetime</p>
</dd>
<dt><code>NumPurchases</code></dt><dd><p>a numeric vector giving the total amount of purchases over the customer's lifetime</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each row corresponds to a customer of a Fortune 500 company.  These customers are businesses, which may or may not exclusively be an e-business.  Whether a customer is still a customer (or has churned) after 730 days is recorded.
</p>


<h3>Source</h3>

<p>Unknown</p>

<hr>
<h2 id='CUSTLOYALTY'>
CUSTLOYALTY dataset </h2><span id='topic+CUSTLOYALTY'></span>

<h3>Description</h3>

<p>Customer database describing customer value (adapted from a former case study) and whether they have a loyalty card
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CUSTLOYALTY")</code></pre>


<h3>Format</h3>

<p>A data frame with 500 observations on the following 9 variables.
</p>

<dl>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code> giving the customer's gender</p>
</dd>
<dt><code>Married</code></dt><dd><p>a factor with levels <code>Married</code> <code>Single</code> giving the customer's marital status</p>
</dd>
<dt><code>Income</code></dt><dd><p>a factor with levels <code>f0t30</code>, <code>f30t45</code>, <code>f45t60</code>, <code>f60t75</code>, <code>f75t90</code>, <code>f90toINF</code> giving the approximate yearly income of the customer.  The first level corresponds to 30K or less, the second level corresponds to 30K to 45K, and the last level corresponds to 90K or above
</p>
</dd>
<dt><code>FirstPurchase</code></dt><dd><p>a numeric vector giving the amount of the customer's first purchase amount</p>
</dd>
<dt><code>LoyaltyCard</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code> that gives whether the customer has a loyalty card for the store</p>
</dd>
<dt><code>WalletShare</code></dt><dd><p>a numeric vector giving the percentage from 0 to 100 of similar products that the customer makes at this store.  A value of 100 means the customer uses this store exclusively for such purchases.</p>
</dd>
<dt><code>CustomerLV</code></dt><dd><p>a numeric vector giving the lifetime value of the customer and reflects the amount spent acquiring and retaining the customer along with the revenue brought in by the customer</p>
</dd>
<dt><code>TotTransactions</code></dt><dd><p>a numeric vector giving the total number of consecutive months the customer has made a transaction in the last year</p>
</dd>
<dt><code>LastTransaction</code></dt><dd><p>a numeric vector giving the total amount of months since the customers last transaction</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each row corresponds to a customer of a local chain.  Does having a loyalty card increase the customer's value?
</p>


<h3>Source</h3>

<p>Unknown</p>

<hr>
<h2 id='CUSTREACQUIRE'>
CUSTREACQUIRE dataset </h2><span id='topic+CUSTREACQUIRE'></span>

<h3>Description</h3>

<p>Customer reacquisition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CUSTREACQUIRE")</code></pre>


<h3>Format</h3>

<p>A data frame with 500 observations on the following 9 variables.
</p>

<dl>
<dt><code>Reacquire</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code> indicating whether a customer who has previously churned was reacquired</p>
</dd>
<dt><code>Lifetime2</code></dt><dd><p>a numeric vector giving the days that the company was considered a customer</p>
</dd>
<dt><code>Value2</code></dt><dd><p>a numeric vector giving the lifetime value of the customer (related to the amount of money spent on reacquisition and the revenue brought in by the customer; can be negative)</p>
</dd>
<dt><code>Lifetime1</code></dt><dd><p>a numeric vector giving the days that the company was considered a customer before churning the first time</p>
</dd>
<dt><code>OfferAmount</code></dt><dd><p>a numeric vector giving the money equivalent of a special offer given to the former customer in an attempt to reacquire</p>
</dd>
<dt><code>Lapse</code></dt><dd><p>a numeric vector giving the number of days between the customer churning and the time of the offer</p>
</dd>
<dt><code>PriceChange</code></dt><dd><p>a numeric vector giving the percentage by which the typical product purchased by the customer has changed from the time they churned to the time the special offer was sent</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code> giving the gender of the customer</p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector giving the age of the customer</p>
</dd>
</dl>



<h3>Details</h3>

<p>A company kept records of its success in reacquiring customers that had previously churned.  Data is based on a previous case study.
</p>


<h3>Source</h3>

<p>Unknown</p>

<hr>
<h2 id='CUSTVALUE'>
CUSTVALUE dataset </h2><span id='topic+CUSTVALUE'></span>

<h3>Description</h3>

<p>Customer database describing customer value (adapted from a former case study)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CUSTVALUE")</code></pre>


<h3>Format</h3>

<p>A data frame with 500 observations on the following 11 variables.
</p>

<dl>
<dt><code>Acquired</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code> indicating whether a potential customer was acquired </p>
</dd>
<dt><code>Duration</code></dt><dd><p>a numeric vector giving the days that the company was considered a customer</p>
</dd>
<dt><code>LifetimeValue</code></dt><dd><p>a numeric vector giving the lifetime value of the customer (related to the amount of money spent on acquisition and the revenue brought in by the customer; can be negative)</p>
</dd>
<dt><code>AcquisitionCost</code></dt><dd><p>a numeric vector giving the amount of money spent attempting to acquire as a customer</p>
</dd>
<dt><code>RetentionCost</code></dt><dd><p>a numeric vector giving the average amount of money spent per year to retain the individual or company as a customer</p>
</dd>
<dt><code>NumPurchases</code></dt><dd><p>a numeric vector giving the total amount of purchases over the customer's lifetime</p>
</dd>
<dt><code>Categories</code></dt><dd><p>a numeric vector giving the number of product categories from which customer made a purchase of their lifetime</p>
</dd>
<dt><code>WalletShare</code></dt><dd><p>a numeric vector giving the percentage of purchases of similar products the customer makes with this company; a few values exceed 100 for some reason</p>
</dd>
<dt><code>EBiz</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code> giving whether the customer was an e-business or not</p>
</dd>
<dt><code>CompanyRevenue</code></dt><dd><p>a numeric vector giving the company's revenue</p>
</dd>
<dt><code>CompanyEmployees</code></dt><dd><p>a numeric vector giving the number of employees working for the company</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each row corresponds to a (potential) customer of a Fortune 500 company.  These customers are businesses, which may or may not exclusively an e-business.
</p>


<h3>Source</h3>

<p>Unknown</p>

<hr>
<h2 id='DIET'>
DIET data
</h2><span id='topic+DIET'></span>

<h3>Description</h3>

<p>The weight of a person over time who is dieting and exercising
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("DIET")</code></pre>


<h3>Format</h3>

<p>A data frame with 35 observations on the following 2 variables.
</p>

<dl>
<dt><code>Weight</code></dt><dd><p>a numeric vector, lbs</p>
</dd>
<dt><code>Day</code></dt><dd><p>a numeric vector, the number of days after the diet started</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data was collected by the author and consists of his weight measured first thing in the morning over the course of amount a month.  The scale round to the nearest 0.2 lbs.
</p>

<hr>
<h2 id='DONOR'>
DONOR dataset
</h2><span id='topic+DONOR'></span>

<h3>Description</h3>

<p>Adapted from the KDD-CUP-98 data set concerning data regarding donations made to a national veterans organization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("DONOR")</code></pre>


<h3>Format</h3>

<p>A data frame with 19372 observations on the following 50 variables.
</p>

<dl>
<dt><code>Donate</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Donation.Amount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>ID</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MONTHS_SINCE_ORIGIN</code></dt><dd><p>a numeric vector, number of months donor has been in the database</p>
</dd>
<dt><code>DONOR_AGE</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>IN_HOUSE</code></dt><dd><p>a numeric vector, 1 if person has donated to the charity's &ldquo;In House&quot; program</p>
</dd>
<dt><code>URBANICITY</code></dt><dd><p>a factor with levels <code>?</code> <code>C</code> <code>R</code> <code>S</code> <code>T</code> <code>U</code></p>
</dd>
<dt><code>SES</code></dt><dd><p>a factor with levels <code>?</code> <code>1</code> <code>2</code> <code>3</code> <code>4</code>, one of five possible codes indicating socioeconomic status</p>
</dd>
<dt><code>CLUSTER_CODE</code></dt><dd><p>a factor with levels <code> .</code> <code>01</code> <code>02</code>  ... <code>53</code>, one of 54 possible cluster codes, which are
unique in terms of socioeconomic status,
urbanicity, ethnicity, and other demographic
characteristics</p>
</dd>
<dt><code>HOME_OWNER</code></dt><dd><p>a factor with levels <code>H</code> <code>U</code></p>
</dd>
<dt><code>DONOR_GENDER</code></dt><dd><p>a factor with levels <code>A</code> <code>F</code> <code>M</code> <code>U</code></p>
</dd>
<dt><code>INCOME_GROUP</code></dt><dd><p>a numeric vector, but in reality one of 7 possible income groups inferred from demographics</p>
</dd>
<dt><code>PUBLISHED_PHONE</code></dt><dd><p>a numeric vector, listed (1) vs not listed (0)</p>
</dd>
<dt><code>OVERLAY_SOURCE</code></dt><dd><p>a factor with levels <code>B</code> <code>M</code> <code>N</code> <code>P</code>, source from which the donor was match; B is both sources and N is neither</p>
</dd>
<dt><code>MOR_HIT_RATE</code></dt><dd><p>a numeric vector, number of known times donor has responded to a mailed solicitation from a group other than the charity</p>
</dd>
<dt><code>WEALTH_RATING</code></dt><dd><p>a numeric vector, but in reality one of 10 groups based on demographics</p>
</dd>
<dt><code>MEDIAN_HOME_VALUE</code></dt><dd><p>a numeric vector, inferred from other variables</p>
</dd>
<dt><code>MEDIAN_HOUSEHOLD_INCOME</code></dt><dd><p>a numeric vector, inferred from other variables</p>
</dd>
<dt><code>PCT_OWNER_OCCUPIED</code></dt><dd><p>a numeric vector, percent of owner-occupied housing near where person lives</p>
</dd>
<dt><code>PER_CAPITA_INCOME</code></dt><dd><p>a numeric vector, of neighborhood in which person lives</p>
</dd>
<dt><code>PCT_ATTRIBUTE1</code></dt><dd><p>a numeric vector, percent of residents in person's neighborhood that are male and active military</p>
</dd>
<dt><code>PCT_ATTRIBUTE2</code></dt><dd><p>a numeric vector, percent of residents in person's neighborhood that are male and veterans </p>
</dd>
<dt><code>PCT_ATTRIBUTE3</code></dt><dd><p>a numeric vector, percent of residents in person's neighborhood that are Vietnam veterans</p>
</dd>
<dt><code>PCT_ATTRIBUTE4</code></dt><dd><p>a numeric vector, percent of residents in person's neighborhood that are WW2 veterans</p>
</dd>
<dt><code>PEP_STAR</code></dt><dd><p>a numeric vector, 1 if has achieved STAR donor status and 0 otherwise</p>
</dd>
<dt><code>RECENT_STAR_STATUS</code></dt><dd><p>a numeric vector, 1 if achieved STAR within last 4 years</p>
</dd>
<dt><code>RECENCY_STATUS_96NK</code></dt><dd><p>a factor with levels <code>A</code> (active) <code>E</code> (inactive) <code>F</code> (first time) <code>L</code> (lapsing)<code>N</code> (new) <code>S</code> (star donor) as of 1996.</p>
</dd>
<dt><code>FREQUENCY_STATUS_97NK</code></dt><dd><p>a numeric vector indicating number of times donated in last period (but period is determined by RECENCY STATUS 96NK)</p>
</dd>
<dt><code>RECENT_RESPONSE_PROP</code></dt><dd><p>a numeric vector, proportion of responses to the individual to the
number of (card or other) solicitations from the
charitable organization since four years ago </p>
</dd>
<dt><code>RECENT_AVG_GIFT_AMT</code></dt><dd><p>a numeric vector, average donation from the individual to the charitable organization since four years ago</p>
</dd>
<dt><code>RECENT_CARD_RESPONSE_PROP</code></dt><dd><p>a numeric vector, number of times the individual has responded to
a card solicitation from the charitable
organization since four years ago </p>
</dd>
<dt><code>RECENT_AVG_CARD_GIFT_AMT</code></dt><dd><p>a numeric vector, average donation from the individual in response
to a card solicitation from the charitable
organization since four years ago </p>
</dd>
<dt><code>RECENT_RESPONSE_COUNT</code></dt><dd><p>a numeric vector, number of times the individual has responded to
a promotion (card or other) from the charitable
organization since four years ago </p>
</dd>
<dt><code>RECENT_CARD_RESPONSE_COUNT</code></dt><dd><p>a numeric vector, number of times the individual has responded to
a card solicitation from the charitable
organization since four years ago </p>
</dd>
<dt><code>MONTHS_SINCE_LAST_PROM_RESP</code></dt><dd><p>a numeric vector, number of months since the individual has
responded to a promotion by the charitable
organization </p>
</dd>
<dt><code>LIFETIME_CARD_PROM</code></dt><dd><p>a numeric vector, total number of card promotions sent to the
individual by the charitable organization </p>
</dd>
<dt><code>LIFETIME_PROM</code></dt><dd><p>a numeric vector, total number of promotions sent to the individual
by the charitable organization </p>
</dd>
<dt><code>LIFETIME_GIFT_AMOUNT</code></dt><dd><p>a numeric vector, total lifetime donation amount from the
individual to the charitable organization </p>
</dd>
<dt><code>LIFETIME_GIFT_COUNT</code></dt><dd><p>a numeric vector, total number of donations from the individual to
the charitable organization </p>
</dd>
<dt><code>LIFETIME_AVG_GIFT_AMT</code></dt><dd><p>a numeric vector, lifetime average donation from the
individual to the charitable organization</p>
</dd>
<dt><code>LIFETIME_GIFT_RANGE</code></dt><dd><p>a numeric vector, difference between maximum and minimum donation amounts from the individual</p>
</dd>
<dt><code>LIFETIME_MAX_GIFT_AMT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>LIFETIME_MIN_GIFT_AMT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>LAST_GIFT_AMT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CARD_PROM_12</code></dt><dd><p>a numeric vector, number of card promotions sent to the individual
by the charitable organization in the last 12
months </p>
</dd>
<dt><code>NUMBER_PROM_12</code></dt><dd><p>a numeric vector, number of promotions (card or other) sent to the
individual by the charitable organization in the
last 12 months </p>
</dd>
<dt><code>MONTHS_SINCE_LAST_GIFT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MONTHS_SINCE_FIRST_GIFT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>FILE_AVG_GIFT</code></dt><dd><p>a numeric vector, same as <code>LIFETIME_AVG_GIFT_AMT</code> </p>
</dd>
<dt><code>FILE_CARD_GIFT</code></dt><dd><p>a numeric vector, lifetime average donation from the
individual in response to all card solicitations
from the charitable organization </p>
</dd>
</dl>



<h3>Details</h3>

<p>Originally, this data was used with the 1998 KDD competition (<a href="https://kdd.ics.uci.edu/databases/kddcup98/kddcup98.html">https://kdd.ics.uci.edu/databases/kddcup98/kddcup98.html</a>).  This particular version has been adapted from the version available in SAS Enterprise Miner (<a href="http://support.sas.com/documentation/cdl/en/emgsj/61207/PDF/default/emgsj.pdf">http://support.sas.com/documentation/cdl/en/emgsj/61207/PDF/default/emgsj.pdf</a> Appendix 2 for descriptions of variable names).  One goal is to determine whether a past donor donated in response to the 97NK mail solicitation and (if so), how much, based on  age, gender, most recent donation amount, total gift amount, etc.
</p>

<hr>
<h2 id='EDUCATION'>
EDUCATION data
</h2><span id='topic+EDUCATION'></span>

<h3>Description</h3>

<p>Data on the College GPAs of students in an introductory statistics class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EDUCATION")</code></pre>


<h3>Format</h3>

<p>A data frame with 607 observations on the following 18 variables.
</p>

<dl>
<dt><code>CollegeGPA</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>HSGPA</code></dt><dd><p>a numeric vector, can range up to 5 if the high school allowed it</p>
</dd>
<dt><code>ACT</code></dt><dd><p>a numeric vector, ACT score</p>
</dd>
<dt><code>APHours</code></dt><dd><p>a numeric vector, number of AP hours student took in HS</p>
</dd>
<dt><code>JobHours</code></dt><dd><p>a numeric vector, number of hours student currently works on average</p>
</dd>
<dt><code>School</code></dt><dd><p>a factor with levels <code>Private</code> <code>Public</code>, type of HS</p>
</dd>
<dt><code>LanguagesSpoken</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HSHonorsClasses</code></dt><dd><p>a numeric vector, number of honors classes taken in HS</p>
</dd>
<dt><code>SmokeInHS</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>PayCollegeNoLoans</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, can the student and his/her family pay for the University of Tennessee without taking out loans?</p>
</dd>
<dt><code>ClubsInHS</code></dt><dd><p>a numeric vector, number of clubs belonged to in HS</p>
</dd>
<dt><code>JobInHS</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, whether the student maintained a job at some point while in HS </p>
</dd>
<dt><code>Churchgoer</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, answer to the question Do you regularly attend chruch?</p>
</dd>
<dt><code>Height</code></dt><dd><p>a numeric vector (inches)</p>
</dd>
<dt><code>Weight</code></dt><dd><p>a numeric vector (lbs)</p>
</dd>
<dt><code>Family</code></dt><dd><p>what position they are in the family, a factor with levels <code>Middle Child</code> <code>Oldest Child</code> <code>Only Child</code> <code>Youngest Child</code></p>
</dd>
<dt><code>Pet</code></dt><dd><p>favorite pet, a factor with levels <code>Both</code> <code>Cat</code> <code>Dog</code> <code>Neither</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Responses are from students in an introductory statistics class at the University of Tennessee in 2010.  One goal to try to predict someone's college GPA from some of the students' characteristics.  What information about a high school student could a college admission's counselor use to anticipate that student's performance in college?
</p>

<hr>
<h2 id='EX2.CENSUS'>
CENSUS data for Exercise 5 in Chapter 2 
</h2><span id='topic+EX2.CENSUS'></span>

<h3>Description</h3>

<p>CENSUS data for Exercise 5 in Chapter 2 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX2.CENSUS")</code></pre>


<h3>Format</h3>

<p>A data frame with 3534 observations on the following 41 variables.
</p>

<dl>
<dt><code>ResponseRate</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Area</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Urban</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Suburban</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Rural</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Male</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Female</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AgeLess5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age5to17</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age18to24</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age25to44</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age45to64</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age65plus</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Hispanics</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Whites</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Blacks</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NativeAmericans</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Asians</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Hawaiians</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Other</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>RelatedHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MarriedHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NoSpouseHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>FemaleHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AloneHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>WithKidHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MedianHHIncomeBlock</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MedianHHIncomeCity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>OccupiedUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>VacantUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>RentingHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HomeownerHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MobileHomeUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CrowdedUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NoPhoneUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NoPlumbingUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NewUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Population</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NumHH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NumUnits</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>logMedianHouseValue</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>See <code>CENSUS</code> for variable descriptions (this data is nearly identical).  The goal is to predict <code>ResponseRate</code> from the other predictors.  <code>ResponseRate</code> is the percentage of households in a block group that mailed in the census forms.  A block group is on average about 40 blocks, each typically bounded by streets, roads, or water. The number of block groups per county in the US is typically between about 5 and 165 with a median of about 20.
</p>

<hr>
<h2 id='EX2.TIPS'>
TIPS data for Exercise 6 in Chapter 2 
</h2><span id='topic+EX2.TIPS'></span>

<h3>Description</h3>

<p>TIPS data for Exercise 6 in Chapter 2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX2.TIPS")</code></pre>


<h3>Format</h3>

<p>A data frame with 244 observations on the following 8 variables.
</p>

<dl>
<dt><code>Tip.Percentage</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Bill_in_USD</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Tip_in_USD</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>Smoker</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Weekday</code></dt><dd><p>a factor with levels <code>Friday</code> <code>Saturday</code> <code>Sunday</code> <code>Thursday</code></p>
</dd>
<dt><code>Day_Night</code></dt><dd><p>a factor with levels <code>Day</code> <code>Night</code></p>
</dd>
<dt><code>Size_of_Party</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>See <code>TIPS</code> for more details.  This is the same dataset except that the names of the variables are different. 
</p>

<hr>
<h2 id='EX3.ABALONE'>
ABALONE dataset for Exercise D in Chapter 3 
</h2><span id='topic+EX3.ABALONE'></span>

<h3>Description</h3>

<p>ABALONE dataset for Exercise D in Chapter 3 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX3.ABALONE")</code></pre>


<h3>Format</h3>

<p>A data frame with 1528 observations on the following 7 variables.
</p>

<dl>
<dt><code>Length</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Diameter</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Height</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Whole.Weight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Meat.Weight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Shell.Weight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Rings</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Abalone are sea creatures that are considered a delicacy and have very pretty iridescent shells.  See <a href="https://en.wikipedia.org/wiki/Abalone">https://en.wikipedia.org/wiki/Abalone</a>.  Predicting the age of the abalone from physical measurements could be useful for harvesting purposes.  Dimensions are in mm and weights are in grams.  <code>Rings</code> is an indicator of the age of the abalone (Age is about 1.5 plus the number of rings).
</p>


<h3>Source</h3>

<p>Data is adapted from the abalone dataset on UCI Data Repository <a href="https://archive.ics.uci.edu/ml/datasets/Abalone">https://archive.ics.uci.edu/ml/datasets/Abalone</a>.  Only the male abalone are represented in this dataset.
</p>


<h3>References</h3>

<p>See page on UCI for full details of owner and donor of this data.
</p>

<hr>
<h2 id='EX3.BODYFAT'>
Bodyfat data for Exercise F in Chapter 3
</h2><span id='topic+EX3.BODYFAT'></span>

<h3>Description</h3>

<p>Bodyfat data for Exercise F in Chapter 3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX3.BODYFAT")</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 4 variables.
</p>

<dl>
<dt><code>Triceps</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Thigh</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Midarm</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Fat</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Same data as <code>BODYFAT2</code>, which you can see for more details.
</p>

<hr>
<h2 id='EX3.HOUSING'>
Housing data for Exercise E in Chapter 3</h2><span id='topic+EX3.HOUSING'></span>

<h3>Description</h3>

<p>Housing data for Exercise E in Chapter 3</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX3.HOUSING")</code></pre>


<h3>Format</h3>

<p>A data frame with 522 observations on the following 2 variables.
</p>

<dl>
<dt><code>AREA</code></dt><dd><p>a numeric vector, square area of house</p>
</dd>
<dt><code>PRICE</code></dt><dd><p>a numeric vector, selling price</p>
</dd>
</dl>



<h3>Details</h3>

<p>Selling prices of houses (perhaps in the Boston area in Massachusettes).
</p>


<h3>Source</h3>

<p>Original source unknown, but it appears in many places around the internet, e.g., <code>public.iastate.edu/~pdixon/stat500/data/realestate.txt</code> </p>

<hr>
<h2 id='EX3.NFL'>
NFL data for Exercise A in Chapter 3
</h2><span id='topic+EX3.NFL'></span>

<h3>Description</h3>

<p>NFL data for Exercise A in Chapter 3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX3.NFL")</code></pre>


<h3>Format</h3>

<p>A data frame with 352 observations on the following 137 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Team</code></dt><dd><p>a factor with levels <code>Arizona</code> <code>Atlanta</code> <code>Baltimore</code> <code>Buffalo</code> <code>Carolina</code> <code>Chicago</code> <code>Cincinnati</code> <code>Cleveland</code> <code>Dallas</code> <code>Denver</code> <code>Detroit</code> <code>GreenBay</code> <code>Houston</code> <code>Indianapolis</code> <code>Jacksonville</code> <code>KansasCity</code> <code>Miami</code> <code>Minnesota</code> <code>NewEngland</code> <code>NewOrleans</code> <code>NYGiants</code> <code>NYJets</code> <code>Oakland</code> <code>Philadelphia</code> <code>Pittsburgh</code> <code>SanDiego</code> <code>SanFrancisco</code> <code>Seattle</code> <code>St.Louis</code> <code>TampaBay</code> <code>Tennessee</code> <code>Washington</code></p>
</dd>
<dt><code>Next.Years.Wins</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Wins</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X1.Off.Tot.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X2.Off.Tot.Plays</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X3.Off.Tot.Yds.per.Ply</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X4.Off.Tot.1st.Dwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X5.Off.Pass.1st.Dwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X6.Off.Rush.1st.Dwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X7.Off.Tot.Turnovers</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X8.Off.Fumbles.Lost</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X9.Off.1st.Dwns.by.Penalty</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X10.Off.Pass.Comp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X11.Off.Pass.Comp.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X12.Off.Pass.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X13.Off.Pass.Tds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X14.Off.Pass.INTs</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X15.Off.Pass.INT.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X16.Off.Pass.Longest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X17.Off.Pass.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X18.Off.Pass.Adj.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X19.Off.Pass.Yds.per.Comp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X20.Off.Pass.Yds.per.Game</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X21.Off.Passer.Rating</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X22.Off.Pass.Sacks.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X23.Off.Pass.Sack.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X24.Off.Pass.Net.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X25.Off.Pass.Adj.Net.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X26.Off.Pass.Sack.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X27.Off.Game.Winning.Drives</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X28.Off.Rush.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X29.Off.Rush.Tds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X30.Off.Rush.Longest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X31.Off.Rush.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X32.Off.Rush.Yds.per.Game</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X33.Off.Fumbles</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X34.Off.Punt.Returns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X35.Off.PR.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X36.Off.PR.Tds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X37.Off.PR.Longest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X38.Off.PR.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X39.Off.Kick.Returns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X40.Off.KR.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X41.Off.KR.Tds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X42.Off.KR.Longest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X43.Off.KR.Yds.per.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X44.Off.All.Purpose.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X45.X1.19.yd.FG.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X46.X1.19.yd.FG.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X47.X20.29.yd.FG.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X48.X20.29.yd.FG.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X49.X1.29.yd.FG.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X50.X30.39.yd.FG.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X51.X30.39.yd.FG.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X52.X30.39.yd.FG.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X53.X40.49.yd.FG.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X54.X40.49.yd.FG.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X55.X50yd.FG.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X56.X50yd.FG.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X57.X40yd.FG.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X58.Total.FG.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X59.Off.Tot.FG.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X60.Off.Tot.FG.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X61.Off.XP.Att</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X62.Off.XP.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X63.Off.XP.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X64.Off.Times.Punted</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X65.Off.Punt.Yards</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X66.Off.Longest.Punt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X67.Off.Times.Had.Punt.Blocked</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X68.Off.Yards.Per.Punt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X69.Fmbl.Tds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X70.Def.INT.Tds.Scored</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X71.Blocked.Kick.or.Missed.FG.Ret.Tds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X72.Total.Tds.Scored</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X73.Off.2pt.Conv.Made</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X74.Def.Safeties.Scored</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X75.Def.Tot.Yds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X76.Def.Tot.Plays.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X77.Def.Tot.Yds.per.Play.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X78.Def.Tot.1st.Dwns.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X79.Def.Pass.1st.Dwns.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X80.Def.Rush.1st.Dwns.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X81.Def.Turnovers.Created</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X82.Def.Fumbles.Recovered</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X83.Def.1st.Dwns.Alwd.by.Penalty</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X84.Def.Pass.Comp.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X85.Def.Pass.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X86.Def.Pass.Comp..Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X87.Def.Pass.Yds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X88.Def.Pass.Tds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X89.Def.Pass.TDAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X90.Def.Pass.INTs</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X91.Def.Pass.INT.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X92.Def.Pass.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X93.Def.Pass.Adj.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X94.Def.Pass.Yds.per.Comp.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X95.Def.Pass.Yds.per.Game.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X96.Def.Passer.Rating.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X97.Def.Pass.Sacks</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X98.Def.Pass.Sack.Yds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X99.Def.Pass.Net.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X100.Def.Pass.Adj.Net.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X101.Def.Pass.Sack.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X102.Def.Rush.Yds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X103.Def.Rush.Tds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X104.Def.Rush.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X105.Def.Rush.Yds.per.Game.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X106.Def.Punt.Returns.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X107.Def.PR.Tds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X108.Def.Kick.Returns.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X109.Def.KR.Yds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X110.Def.KR.Tds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X111.Def.KR.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X112.Def.Tot.FG.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X113.Def.Tot.FG.Made.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X114.Def.Tot.FG..Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X115.Def.XP.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X116.Def.XP.Made.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X117.Def.XP..Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X118.Def.Punts.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X119.Def.Punt.Yds.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X120.Def.Punt.Yds.per.Att.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X121.Def.2pt.Conv.Alwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X122.Off.Safeties</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X123.Off.Rush.Success.Rate</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X124.Head.Coach.Disturbance.</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X125.QB.Disturbance</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X126.RB.Disturbance</code></dt><dd><p>a factor with levels <code>?</code> <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X127.Off.Run.Pass.Ratio</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X128.Off.Pass.Ply.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X129.Off.Run.Ply.</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X130.Off.Yds.Pt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X131.Def.Yds.Pt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X132.Off.Pass.Drop.rate</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X133.Def.Pass.Drop.Rate</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>See <code>NFL</code> for more details.  This dataset is actually a more complete version of <code>NFL</code> and contains additional variables such as the year, team, next year's wins of the team, etc., and could be used in place of the <code>NFL</code> data</p>

<hr>
<h2 id='EX4.BIKE'>
Bike data for Exercise 1 in Chapter 4
</h2><span id='topic+EX4.BIKE'></span>

<h3>Description</h3>

<p>Bike data for Exercise 1 in Chapter 4
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX4.BIKE")</code></pre>


<h3>Format</h3>

<p>A data frame with 414 observations on the following 5 variables.
</p>

<dl>
<dt><code>Demand</code></dt><dd><p>a numeric vector, total number of rental bikes</p>
</dd>
<dt><code>AvgTemp</code></dt><dd><p>a numeric vector, average temperature of the day</p>
</dd>
<dt><code>EffectiveAvgTemp</code></dt><dd><p>a numeric vector, average temperature it feels like (taking into account dewpoint) for the day</p>
</dd>
<dt><code>AvgHumidity</code></dt><dd><p>a numeric vector, average humidity for the day</p>
</dd>
<dt><code>AvgWindspeed</code></dt><dd><p>a numeric vector, average wind speed for the day</p>
</dd>
</dl>



<h3>Details</h3>

<p>Adapted from the bike sharing dataset on the UCI data repository <a href="http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset">http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset</a>.  This concerns the demand for rental bikes in the DC area.
</p>
<p>Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. 
</p>
<p>Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.
</p>


<h3>References</h3>

<p>Fanaee-T, Hadi, and Gama, Joao, Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg.</p>

<hr>
<h2 id='EX4.STOCKPREDICT'>
Stock data for Exercise 2 in Chapter 4 (prediction set)
</h2><span id='topic+EX4.STOCKPREDICT'></span>

<h3>Description</h3>

<p>Stock data for Exercise 2 in Chapter 4 (prediction set)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX4.STOCKPREDICT")</code></pre>


<h3>Format</h3>

<p>A data frame with 5 observations on the following 40 variables.
</p>

<dl>
<dt><code>AAPLlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AXPlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BAlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BAClag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CATlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CSCOlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CVXlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DDlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DISlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GElag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HDlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HPQlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>IBMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>INTClag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>JNJlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>JPMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>KOlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MCDlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MMMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MRKlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MSFTlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PFElag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PGlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Tlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TRVlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>UNHlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>VZlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>WMTlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>XOMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Australialag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Copperlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DollarIndexlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Europelag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Exchangelag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GlobalDowlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HongKonglag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Indialag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Japanlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Oillag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Shanghailag2</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data frame for which you are to predict the closing price of Alcoa stock based on the model built using <code>EX4.STOCKS</code>.  The actual closing prices are not given.
</p>

<hr>
<h2 id='EX4.STOCKS'>
Stock data for Exercise 2 in Chapter 4
</h2><span id='topic+EX4.STOCKS'></span>

<h3>Description</h3>

<p>Stock data for Exercise 2 in Chapter 4
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX4.STOCKS")</code></pre>


<h3>Format</h3>

<p>A data frame with 216 observations on the following 41 variables.
</p>

<dl>
<dt><code>AA</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AAPLlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AXPlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BAlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>BAClag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CATlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CSCOlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CVXlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DDlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DISlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GElag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HDlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HPQlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>IBMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>INTClag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>JNJlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>JPMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>KOlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MCDlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MMMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MRKlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MSFTlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PFElag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PGlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Tlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TRVlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>UNHlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>VZlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>WMTlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>XOMlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Australialag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Copperlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DollarIndexlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Europelag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Exchangelag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GlobalDowlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>HongKonglag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Indialag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Japanlag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Oillag2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Shanghailag2</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The goal is to predict the closing price of Alcoa stock (<code>AA</code>) from the closing prices of other stocks and commodities two days prior (<code>IMBlag2</code>, <code>HongKonglag2</code>, etc.).  If this were possible, and if the association between the prices continued into the future, it would be possible to use this information to make smart trades.
</p>


<h3>Source</h3>

<p>Compiled from various sources on the internet, e.g., Yahoo historical prices.
</p>

<hr>
<h2 id='EX5.BIKE'>
BIKE dataset for Exercise 4 Chapter 5</h2><span id='topic+EX5.BIKE'></span>

<h3>Description</h3>

<p>BIKE dataset for Exercise 4 Chapter 5</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX5.BIKE")</code></pre>


<h3>Format</h3>

<p>A data frame with 413 observations on the following 9 variables.
</p>

<dl>
<dt><code>Demand</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Day</code></dt><dd><p>a factor with levels <code>Friday</code> <code>Monday</code> <code>Saturday</code> <code>Sunday</code> <code>Thursday</code> <code>Tuesday</code> <code>Wednesday</code></p>
</dd>
<dt><code>Workingday</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>Holiday</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>Weather</code></dt><dd><p>a factor with levels <code>No rain</code> <code>Rain</code></p>
</dd>
<dt><code>AvgTemp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>EffectiveAvgTemp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AvgHumidity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AvgWindspeed</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Adapted from the bike sharing dataset on the UCI data repository <a href="http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset">http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset</a>.  This concerns the demand for rental bikes in the DC area.  This is an expanded version of <code>EX4.BIKE</code> with more variables and without the row containing bad data.
</p>
<p>Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. 
</p>
<p>Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.
</p>


<h3>References</h3>

<p>Fanaee-T, Hadi, and Gama, Joao, Event labeling combining ensemble detectors and background knowledge, Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg.</p>

<hr>
<h2 id='EX5.DONOR'>
DONOR dataset for Exercise 4 in Chapter 5
</h2><span id='topic+EX5.DONOR'></span>

<h3>Description</h3>

<p>DONOR dataset for Exercise 4 in Chapter 5
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX5.DONOR")</code></pre>


<h3>Format</h3>

<p>A data frame with 8132 observations on the following 18 variables.
</p>

<dl>
<dt><code>Donate</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>LastAmount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AccountAge</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Setting</code></dt><dd><p>a factor with levels <code>Rural</code> <code>Suburban</code> <code>Urban</code></p>
</dd>
<dt><code>Homeowner</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code> <code>Unknown</code></p>
</dd>
<dt><code>Phone</code></dt><dd><p>a factor with levels <code>Listed</code> <code>Unlisted</code></p>
</dd>
<dt><code>Source</code></dt><dd><p>a factor with levels <code>B</code> <code>M</code> <code>N</code> <code>P</code>, source from which the donor was match; B is both sources and N is neither</p>
</dd>
<dt><code>MedianHomeValue</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MedianIncome</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercentOwnerOccupied</code></dt><dd><p>a numeric vector, of the neighborhood in which donor lives</p>
</dd>
<dt><code>Recent</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>RecentResponsePercent</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>RecentAvgAmount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MonthsSinceLastGift</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TotalAmount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TotalDonations</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>See <code>DONOR</code> for details.  This data is a subset, though attributes have been renamed.
</p>

<hr>
<h2 id='EX6.CLICK'>
CLICK data for Exercise 2 in Chapter 6</h2><span id='topic+EX6.CLICK'></span>

<h3>Description</h3>

<p>CLICK data for Exercise 2 in Chapter 6</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX6.CLICK")</code></pre>


<h3>Format</h3>

<p>A data frame with 13594 observations on the following 15 variables.
</p>

<dl>
<dt><code>Click</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>BannerPosition</code></dt><dd><p>a factor with levels <code>Pos1</code> <code>Pos2</code>, location of ad</p>
</dd>
<dt><code>SiteID</code></dt><dd><p>a factor with levels <code>S1</code> <code>S2</code> <code>S3</code> <code>S4</code> <code>S5</code> <code>S6</code> <code>S7</code> <code>S8</code></p>
</dd>
<dt><code>SiteDomain</code></dt><dd><p>a factor with levels <code>SD1</code> <code>SD2</code> <code>SD3</code> <code>SD4</code> <code>SD5</code> <code>SD6</code> <code>SD7</code> <code>SD8</code></p>
</dd>
<dt><code>SiteCategory</code></dt><dd><p>a factor with levels <code>SCat1</code> <code>SCat2</code> <code>SCat3</code> <code>SCat4</code> <code>SCat5</code></p>
</dd>
<dt><code>AppDomain</code></dt><dd><p>a factor with levels <code>AD1</code> <code>AD2</code> <code>AD3</code></p>
</dd>
<dt><code>AppCategory</code></dt><dd><p>a factor with levels <code>AC1</code> <code>AC2</code></p>
</dd>
<dt><code>DeviceModel</code></dt><dd><p>a factor with levels <code>D1</code> <code>D10</code> <code>D11</code> <code>D12</code> <code>D13</code> <code>D14</code> <code>D15</code> <code>D16</code> <code>D17</code> <code>D18</code> <code>D2</code> <code>D3</code> <code>D4</code> <code>D5</code> <code>D6</code> <code>D7</code> <code>D8</code> <code>D9</code></p>
</dd>
<dt><code>x1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>x2</code></dt><dd><p>a factor with levels <code>A</code> <code>B</code> <code>C</code> <code>D</code> <code>E</code> <code>F</code> <code>G</code> <code>H</code> <code>I</code> <code>J</code> <code>K</code> <code>L</code> <code>M</code> <code>N</code> <code>O</code> <code>P</code> <code>Q</code> <code>R</code></p>
</dd>
<dt><code>x3</code></dt><dd><p>a factor with levels <code>a</code> <code>b</code> <code>c</code> <code>d</code> <code>e</code> <code>f</code></p>
</dd>
<dt><code>x4</code></dt><dd><p>a factor with levels <code>val1</code> <code>val2</code> <code>val3</code></p>
</dd>
<dt><code>x5</code></dt><dd><p>a factor with levels <code>type1</code> <code>type2</code> <code>type3</code> <code>type4</code></p>
</dd>
<dt><code>x6</code></dt><dd><p>a factor with levels <code>class1</code> <code>class2</code> <code>class3</code> <code>class4</code></p>
</dd>
<dt><code>x7</code></dt><dd><p>a factor with levels <code>AA</code> <code>BB</code> <code>CC</code> <code>DD</code> <code>EE</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Inspired from a competition to predict the click-thru rates of ads displayed on mobile devices <a href="https://www.kaggle.com/c/avazu-ctr-prediction">https://www.kaggle.com/c/avazu-ctr-prediction</a>.  Does the click-thru rate vary based on where the ad placed, what kind of site and device is used to view the ad, something else?  All variables are anonymized.
</p>

<hr>
<h2 id='EX6.DONOR'>
DONOR dataset for Exercise 1 in Chapter 6
</h2><span id='topic+EX6.DONOR'></span>

<h3>Description</h3>

<p>DONOR dataset for Exercise 1 in Chapter 6
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX6.DONOR")</code></pre>


<h3>Format</h3>

<p>A data frame with 8132 observations on the following 18 variables.
</p>

<dl>
<dt><code>Donate</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>LastAmount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AccountAge</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Setting</code></dt><dd><p>a factor with levels <code>Rural</code> <code>Suburban</code> <code>Urban</code></p>
</dd>
<dt><code>Homeowner</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code> <code>Unknown</code></p>
</dd>
<dt><code>Phone</code></dt><dd><p>a factor with levels <code>Listed</code> <code>Unlisted</code></p>
</dd>
<dt><code>Source</code></dt><dd><p>a factor with levels <code>B</code> <code>M</code> <code>N</code> <code>P</code></p>
</dd>
<dt><code>MedianHomeValue</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MedianIncome</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercentOwnerOccupied</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Recent</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>RecentResponsePercent</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>RecentAvgAmount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MonthsSinceLastGift</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TotalAmount</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TotalDonations</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Identical to <code>EX5.DONOR</code>, so see that for details</p>

<hr>
<h2 id='EX6.WINE'>
WINE data for Exercise 3 Chapter 6 </h2><span id='topic+EX6.WINE'></span>

<h3>Description</h3>

<p>WINE data for Exercise 3 Chapter 6 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX6.WINE")</code></pre>


<h3>Format</h3>

<p>A data frame with 2700 observations on the following 12 variables.
</p>

<dl>
<dt><code>Quality</code></dt><dd><p>a factor with levels <code>High</code> <code>Low</code></p>
</dd>
<dt><code>fixed.acidity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>volatile.acidity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>citric.acid</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>residual.sugar</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>free.sulfur.dioxide</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>total.sulfur.dioxide</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>density</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>pH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sulphates</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>alcohol</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>chlorides</code></dt><dd><p>a factor with levels <code>Little</code> <code>Lots</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Adapted from the wine quality dataset at the UCI data repository.  In this case, the original quality metric has been recoded from a score between 0 and 10 to either <code>High</code> or <code>Low</code>, and the <code>chlorides</code> is treated here as a categorical variable instead of a quantitative variable.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality">https://archive.ics.uci.edu/ml/datasets/Wine+Quality</a>
</p>
<p>P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. 
In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
</p>

<hr>
<h2 id='EX7.BIKE'>
BIKE dataset for Exercise 1 Chapters 7 and 8</h2><span id='topic+EX7.BIKE'></span>

<h3>Description</h3>

<p>BIKE dataset for Exercise 1 Chapters 7 and 8
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX7.BIKE")</code></pre>


<h3>Format</h3>

<p>A data frame with 410 observations on the following 9 variables.
</p>

<dl>
<dt><code>Demand</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Day</code></dt><dd><p>a factor with levels <code>Friday</code> <code>Monday</code> <code>Saturday</code> <code>Sunday</code> <code>Thursday</code> <code>Tuesday</code> <code>Wednesday</code></p>
</dd>
<dt><code>Workingday</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>Holiday</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>Weather</code></dt><dd><p>a factor with levels <code>No rain</code> <code>Rain</code></p>
</dd>
<dt><code>AvgTemp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>EffectiveAvgTemp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AvgHumidity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>AvgWindspeed</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Identical to <code>EX5.BIKE</code> except with three additional rows deleted.  See that dataset for details.
</p>

<hr>
<h2 id='EX7.CATALOG'>
CATALOG data for Exercise 2 in Chapters 7 and 8
</h2><span id='topic+EX7.CATALOG'></span>

<h3>Description</h3>

<p>CATALOG data for Exercise 2 in Chapters 7 and 8
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX7.CATALOG")</code></pre>


<h3>Format</h3>

<p>A data frame with 4000 observations on the following 7 variables.
</p>

<dl>
<dt><code>Buy</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, whether customer made a purchase through the catalog next quarter</p>
</dd>
<dt><code>QuartersWithPurchase</code></dt><dd><p>a numeric vector, number of quarters where customer made a purchase through the catalog</p>
</dd>
<dt><code>PercentQuartersWithPurchase</code></dt><dd><p>a numeric vector, percentage of quarters where customer made a purchase through the catalog</p>
</dd>
<dt><code>CatalogsReceived</code></dt><dd><p>a numeric vector, total number of catalogs customer has received</p>
</dd>
<dt><code>DaysSinceLastPurchase</code></dt><dd><p>a numeric vector, number of days since customer placed his or her last order</p>
</dd>
<dt><code>AvgOrderSize</code></dt><dd><p>a numeric vector, the typical number of items per order when customers buys through the catalog</p>
</dd>
<dt><code>LifetimeOrder</code></dt><dd><p>a numeric vector, the number of orders the customer has placed through the catalog</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original source of this data is lost, but it is likely adapted from real data.
</p>

<hr>
<h2 id='EX9.BIRTHWEIGHT'>
Birthweight dataset for Exercise 1 in Chapter 9
</h2><span id='topic+EX9.BIRTHWEIGHT'></span>

<h3>Description</h3>

<p>Birthweight dataset for Exercise 1 in Chapter 9
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX9.BIRTHWEIGHT")</code></pre>


<h3>Format</h3>

<p>A data frame with 553 observations on the following 13 variables.
</p>

<dl>
<dt><code>Birthweight</code></dt><dd><p>a numeric vector, grams</p>
</dd>
<dt><code>Gestation</code></dt><dd><p>a numeric vector, weeks</p>
</dd>
<dt><code>MotherRace</code></dt><dd><p>a factor with levels <code>Asian</code> <code>Black</code> <code>Mexican</code> <code>Mixed</code> <code>White</code>, self-reported</p>
</dd>
<dt><code>MotherAge</code></dt><dd><p>a numeric vector, self-reported</p>
</dd>
<dt><code>MotherEducation</code></dt><dd><p>a factor with levels <code>below HS</code> <code>College</code> <code>HS</code>, self-reported</p>
</dd>
<dt><code>MotherHeight</code></dt><dd><p>a numeric vector, inches</p>
</dd>
<dt><code>MotherWeight</code></dt><dd><p>a numeric vector, pounds</p>
</dd>
<dt><code>FatherRace</code></dt><dd><p>a factor with levels <code>Asian</code> <code>Black</code> <code>Mexican</code> <code>Mixed</code> <code>White</code>, self-reported</p>
</dd>
<dt><code>FatherAge</code></dt><dd><p>a numeric vector, self-reported</p>
</dd>
<dt><code>Father_Education</code></dt><dd><p>a factor with levels <code>below HS</code> <code>College</code> <code>HS</code>, self-reported</p>
</dd>
<dt><code>FatherHeight</code></dt><dd><p>a numeric vector, inches</p>
</dd>
<dt><code>FatherWeight</code></dt><dd><p>a numeric vector, pounds</p>
</dd>
<dt><code>Smoking</code></dt><dd><p>a factor with levels <code>never</code> <code>now</code>, self-reported</p>
</dd>
</dl>



<h3>Details</h3>

<p>An examination of birthweights and their link to gestation, mother and father characteristics, and whether the mother smoked during pregnancy.  
</p>


<h3>Source</h3>

<p>Adapted from a subset of a study from Nolan and Speed (2000) consisting of male, single births which survived for at least 28 days.  Some rows that contained bad data have been omitted.  <a href="http://had.co.nz/stat645/week-05/birthweight.txt">http://had.co.nz/stat645/week-05/birthweight.txt</a></p>

<hr>
<h2 id='EX9.NFL'>
NFL data for Exercise 2 Chapter 9
</h2><span id='topic+EX9.NFL'></span>

<h3>Description</h3>

<p>NFL data for Exercise 2 Chapter 9
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX9.NFL")</code></pre>


<h3>Format</h3>

<p>A data frame with 352 observations on the following 26 variables.
</p>

<dl>
<dt><code>Wins</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X1.OffTotPlays</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X2.OffTotYdsperPly</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X3.OffPass1stDwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X4.OffRush1stDwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X5.OffFumblesLost</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X6.OffPassComp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X7.OffPassINT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X8.OffPassLongest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X9.OffPassYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X10.OffPassYdsperComp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X11.OffPassSackYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X12.OffPassSack</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X13.OffRushLongest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X14.OffRushYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X15.OffRushYdsperGame</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X16.OffFumbles</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X17.1to29ydFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X18.30to39ydFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X19.40.ydFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X20.TotalFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X21.OffTimesPunted</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X22.OffTimesHadPuntBlocked</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X23.OffYardsPerPunt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X24.Off2ptConvMade</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X25.OffSafeties</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>A subset of the <code>NFL</code> data (see entry for details) containing statistics on the offense.
</p>

<hr>
<h2 id='EX9.STORE'>
Data for Exercise 3 Chapter 9
</h2><span id='topic+EX9.STORE'></span>

<h3>Description</h3>

<p>Data for Exercise 3 Chapter 9
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EX9.STORE")</code></pre>


<h3>Format</h3>

<p>A data frame with 1500 observations on the following 68 variables.
</p>

<dl>
<dt><code>Store1</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store2</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store3</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store4</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store5</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store6</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store7</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store8</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store9</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store10</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store11</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store12</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store13</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store14</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store15</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store16</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store17</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store18</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store19</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store20</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store21</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store22</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store23</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store24</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store25</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store26</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store27</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store28</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store29</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store30</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store31</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store32</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store33</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store34</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store35</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store36</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store37</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store38</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store39</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store40</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store41</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store42</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store43</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store44</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store45</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store46</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store47</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store48</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store49</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store50</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store51</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store52</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store53</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store54</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store55</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store56</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store57</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store58</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store59</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store60</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store61</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store62</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store63</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store64</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store65</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store66</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store67</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
<dt><code>Store68</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>The data consists of a random sample of 1500 credit card customers and their shopping habits regarding 68 different stores (whether they did or did not make a purchase in the last 90 days).  Shoppers don't pick and choose places to shop at random, so it is interesting to study which stores appear together in a customers' history.
</p>


<h3>Source</h3>

<p>Consultation with an anonymous client.  Stores have been anonymized to protect the source.
</p>

<hr>
<h2 id='extrapolation_check'>
A crude check for extrapolation
</h2><span id='topic+extrapolation.check'></span><span id='topic+extrapolation_check'></span>

<h3>Description</h3>

<p>This function computes the Mahalanobis distance of points as a check for potential extrapolation. </p>


<h3>Usage</h3>

<pre><code class='language-R'>extrapolation_check(M,newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extrapolation_check_+3A_m">M</code></td>
<td>

<p>A fitted model that uses only quantitative variables
</p>
</td></tr>
<tr><td><code id="extrapolation_check_+3A_newdata">newdata</code></td>
<td>

<p>Data frame (that has the exact same columns as predictors used to fit the model <code>M</code>) whose Mahalanobis distances are to be calculated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the shape of the predictor data cloud and calculates the distances of points from the center (with respect to the shape of the data cloud).  Extrapolation occurs at a combination of predictors that is far from combinations used to build the model.  An observation with a large Mahalanobis distance MAY be far from the observations used to build the model and thus MAY require extrapolation.
</p>
<p>Note:  analysis assumes the predictor data cloud is roughly elliptical (this may not be a good assumptions).  
</p>
<p>The function reports the percentiles of the Mahalanobis distances of the points in <code>newdata</code>.  Percentiles are the fraction of observations used in model that are CLOSER to
the center than the point(s) in question.  Large values of these percentages indicate a greater risk for extrapolation.  If <code>Percentile</code> is about 99
you may be extrapolating.  
</p>
<p>The method is sensitive to outliers clusters of outliers and gives only a crude idea of the potential for extrapolation.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(SALARY)
  M &lt;- lm(Salary~Education*Experience+Months,data=SALARY)
  newdata &lt;- data.frame(Education=c(0,5,10),Experience=c(15,15,15),Months=c(0,0,0))
  extrapolation_check(M,newdata) 
  #Individuals 1 and 3 are rather unusual (though not terribly) while individual 2 is typical.  
</code></pre>

<hr>
<h2 id='find_transformations'>
Transformations for simple linear regression
</h2><span id='topic+find.transformations'></span><span id='topic+find_transformations'></span>

<h3>Description</h3>

<p>This function takes a simple linear regression model and finds the transformation of x and y that results in the highest R2 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_transformations(M,powers=seq(from=-3,to=3,by=.25),threshold=0.02,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_transformations_+3A_m">M</code></td>
<td>

<p>A simple linear regression model fitted with <code><a href="stats.html#topic+lm">lm</a></code>
</p>
</td></tr>
<tr><td><code id="find_transformations_+3A_powers">powers</code></td>
<td>

<p>A sequence of powers to try for x and y.  By default this ranges from -3 to 3 in steps of 0.25.  If 0 is a valid power, then the logarithm is used instead.
</p>
</td></tr>
<tr><td><code id="find_transformations_+3A_threshold">threshold</code></td>
<td>

<p>Report all models that have an R2 that is within <code>threshold</code> of the model with the highest R2 
</p>
</td></tr>
<tr><td><code id="find_transformations_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code>plot</code> such as <code>pch</code> and <code>cex</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relationship between y and x may not be linear.  However, some transformation of y may have a linear relationship with some transformation of x.  This function considers simple linear regression with x and y raised to powers between -3 and 3 (in 0.25 increments) by default.  The function outputs a list of the top models as gauged by R^2 (all models within 0.02 of the highest R^2).  Note:  there is no guarantee that these &quot;best&quot; transformations are actually good, since a large R^2 can be produced by outliers created during transformations.  A plot of the transformation is also provided.
</p>
<p>It is exceedingly rare that the &quot;best&quot; transformation is raising x and y to the 1 power (i.e., the original variables).  Transformations are typically used only when there are issues in the residuals plots, highly skewed variables, or physical/logical justifications.
</p>
<p>Note:  if a variable has 0s or negative numbers, only integer transformations are considered.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  #Straightforward example
  data(BULLDOZER)
	M &lt;- lm(SalePrice~YearMade,data=BULLDOZER)
	find_transformations(M,pch=20,cex=0.3)

  #Results are very misleading since selected models have high R2 due to outliers
  data(MOVIE)
  M &lt;- lm(Total~Weekend,data=MOVIE)
	find_transformations(M,powers=seq(-2,2,by=0.5),threshold=0.05)
	 </code></pre>

<hr>
<h2 id='FRIEND'>
Friendship Potential vs. Attractiveness Ratings
</h2><span id='topic+FRIEND'></span>

<h3>Description</h3>

<p>Examining the relationship between how likely someone would be friends with a person based on that person's level of attractiveness
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("FRIEND")</code></pre>


<h3>Format</h3>

<p>A data frame with 54 observations on the following 2 variables.
</p>

<dl>
<dt><code>Attractiveness</code></dt><dd><p>a numeric vector - the average scores (1-5) from about 80 male students who rated the attractiveness of the women in each picture </p>
</dd>
<dt><code>FriendshipPotential</code></dt><dd><p>a numeric vector - the average scores (1-5) from about 30 female students who rated how likely they would be to be friends with the pictured woman </p>
</dd>
</dl>



<h3>Details</h3>

<p>The data contain information on 54 pictures of women posted on the (now defunct/renamed) site hotornot.com.  The women in two classes of introductory statistics at the University of Tennessee rated how likely they would be friends with the pictured women (on a scale of 1-5, 1 being very unlikely and 5 being very likely).  The men in three (different) classes of introductory statistics gave an attractiveness score to each woman (on a scale of 1-5, 1 being very unattractive and 5 being very attractive).  The numbers presented are the averages over all student ratings.  
</p>


<h3>Source</h3>

<p>Surveys administered to introductory statistics students at the University of Tennessee from 2008-2010.
</p>

<hr>
<h2 id='FUMBLES'>
Wins vs. Fumbles of an NFL team
</h2><span id='topic+FUMBLES'></span>

<h3>Description</h3>

<p>Wins vs. Fumbles of an NFL team</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("FUMBLES")</code></pre>


<h3>Format</h3>

<p>A data frame with 352 observations on the following 2 variables.
</p>

<dl>
<dt><code>Wins</code></dt><dd><p>a numeric vector, number of wins (0-16) of an NFL team over the course of a season</p>
</dd>
<dt><code>FumblesLost</code></dt><dd><p>a numeric vector, the number of fumbles lost by that team over the course of a season</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is a subset of the <code>NFL</code> data.  Data is from the 2002-2012 seasons.
</p>


<h3>Source</h3>

<p>Collected by an undergraduate student from available web data in 2013.
</p>

<hr>
<h2 id='generalization_error'>
Calculating the generalization error of a model on a set of data
</h2><span id='topic+generalization.error'></span><span id='topic+generalization_error'></span>

<h3>Description</h3>

<p>This function takes a linear regression from <code>lm</code>, logistic regression from <code>glm</code>, partition model from <code>rpart</code>, or random forest from <code>randomForest</code> and calculates the generalization error on a dataframe.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>generalization_error(MODEL,HOLDOUT,Kfold=FALSE,K=5,R=10,seed=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generalization_error_+3A_model">MODEL</code></td>
<td>

<p>A linear regression model created using <code><a href="stats.html#topic+lm">lm</a></code>, a logistic regression model created using <code><a href="stats.html#topic+glm">glm</a></code>, a partition model created using <code><a href="rpart.html#topic+rpart">rpart</a></code>, or a random forest created using <code>randomForest</code>.</p>
</td></tr>
<tr><td><code id="generalization_error_+3A_holdout">HOLDOUT</code></td>
<td>

<p>A dataset for which the generalization error will be calculated.  If not given, the error on the data used to build the model (<code>MODEL</code>) is used.
</p>
</td></tr>
<tr><td><code id="generalization_error_+3A_kfold">Kfold</code></td>
<td>

<p>If <code>TRUE</code>, function will estimate the generalization error of <code>MODEL</code> using repeated K-fold cross validation (regression models only)
</p>
</td></tr>
<tr><td><code id="generalization_error_+3A_k">K</code></td>
<td>

<p>The number of folds used in repeated K-fold cross-validation for the estimation of the generalization error for the model <code>MODEL</code>.  It is useful to compare this number to the actual generalization error on <code>HOLDOUT</code>.
</p>
</td></tr>
<tr><td><code id="generalization_error_+3A_r">R</code></td>
<td>

<p>The number of repeats used in repeated K-fold cross-validation.
</p>
</td></tr>
<tr><td><code id="generalization_error_+3A_seed">seed</code></td>
<td>
<p>an optional argument priming the random number seed for estimating the generalization error</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the error on <code>MODEL</code>, its estimated generalization error from repeated K-fold cross-validation (for regression models only), and the actual generalization error on <code>HOLDOUT</code>.  If the response is quantitative, the RMSE is reported.  If the response is categorical, the confusion matrices and misclassification rates are returned.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  #Education analytics
  data(STUDENT)
  set.seed(1010)
  train.rows &lt;- sample(1:nrow(STUDENT),0.7*nrow(STUDENT))
  TRAIN &lt;- STUDENT[train.rows,]
  HOLDOUT &lt;- STUDENT[-train.rows,]
  M &lt;- lm(CollegeGPA~.,data=TRAIN)
  #Also estimate the generalization error of the model
  generalization_error(M,HOLDOUT,Kfold=TRUE,seed=5020)
  #Try partition and randomforest, though they do not perform as well as regression here
  TREE &lt;- rpart(CollegeGPA~.,data=TRAIN)
  FOREST &lt;- randomForest(CollegeGPA~.,data=TRAIN)
  generalization_error(TREE,HOLDOUT)
  generalization_error(FOREST,HOLDOUT) 

  #Wine
  data(WINE)
  set.seed(2020)
  train.rows &lt;- sample(1:nrow(WINE),0.7*nrow(WINE))
  TRAIN &lt;- WINE[train.rows,]
  HOLDOUT &lt;- WINE[-train.rows,]
  M &lt;- glm(Quality~.^2,data=TRAIN,family=binomial)
  generalization_error(M,HOLDOUT)
  #Random forest predicts best on the holdout sample
  TREE &lt;- rpart(Quality~.,data=TRAIN)
  FOREST &lt;- randomForest(Quality~.,data=TRAIN)
  generalization_error(TREE,HOLDOUT)
  generalization_error(FOREST,HOLDOUT) 

</code></pre>

<hr>
<h2 id='getcp'>
Complexity Parameter table for partition models
</h2><span id='topic+getcp'></span>

<h3>Description</h3>

<p>A simple function to take the output of a partition model created with <code>rpart</code> and return information abouthe complexity parameter and performance of varies models. </p>


<h3>Usage</h3>

<pre><code class='language-R'>getcp(TREE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getcp_+3A_tree">TREE</code></td>
<td>

<p>An object of class <code>rpart</code>.  This is created by making a partition model using <code>rpart</code>.    
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function prints out a table of the complexity parameter, number of splits, relative error, cross validation error, and standard deviation of cross validation error for a partition model.  It adds helpful advice for what the value of CP is for the tree that had the lowest cross validation error and also the value of CP for the simplest tree with a cross validation error at most 1 standard deviation above the lowest. 
</p>
<p>Further, a plot is made of the estimated generalization error (<code>xerror</code>) versus the number of splits to illustrate when the tree stops improving.  Vertical lines are draw at the number of splits corresponding to the lowest estimated generalization error to the tree selected by the one standard deviation rule.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="rpart.html#topic+rpart">rpart</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(JUNK)
	TREE &lt;- rpart(Junk~.,data=JUNK,control=rpart.control(cp=0,xval=10,minbucket=5))
	getcp(TREE)
	 </code></pre>

<hr>
<h2 id='influence_plot'>
Influence plot for regression diganostics
</h2><span id='topic+influence_plot'></span><span id='topic+influence.plot'></span>

<h3>Description</h3>

<p>This function plots the leverage vs. deleted studentized residuals for a regression model, highlighting points that are influent based on these two factors as well as Cook's distance  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>influence_plot(M,large.cook,cooks=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="influence_plot_+3A_m">M</code></td>
<td>

<p>A linear regression model fitted with lm()
</p>
</td></tr>
<tr><td><code id="influence_plot_+3A_large.cook">large.cook</code></td>
<td>

<p>The threshold for a &quot;large&quot; Cook's distance.  If not specified, a default of 4/n is used.
</p>
</td></tr>
<tr><td><code id="influence_plot_+3A_cooks">cooks</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code> (default) regarding whether to return the row numbers of observations with unusually large Cooks distances 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A point is influential if its addition to the data changes the regression substantially.   One way of measuring influence is by looking at the point's leverage (distance from the center of the predictor's datacloud with respect to it shape) and deleted studentized residual (relative size of the residual with respect to a regression made without that point).  Points with leverages larger than 2(k+1)/n (where k is the number of predictors) and deleted studentized residuals larger than 2 in magnitude are considered influential.  
</p>
<p>Influence can also be measured by Cook's distance, which essentially combines the above two measures.  This function considers the Cook's distances to be large when it exceeds 4/n, but the user can specify another cutoff.
</p>
<p>The radius of a point is proportional to the square root of the Cook's distance.  Influential points according to leverage/residual criteria have an X through them while influential points according to Cook's distance are bolded.  
</p>
<p>The function returns the row numbers of influential observations.
</p>


<h3>Value</h3>

<p>A list with the row numbers of influential points according to Cook's distance (<code>$Cooks</code>) and according to leverage/residual criteria (<code>$Leverage</code>).
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+cooks.distance">cooks.distance</a></code>, <code><a href="stats.html#topic+hatvalues">hatvalues</a></code>, <code><a href="stats.html#topic+rstudent">rstudent</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(TIPS)
  M &lt;- lm(TipPercentage~.-Tip,data=TIPS)
	influence_plot(M)

	
	 </code></pre>

<hr>
<h2 id='JUNK'>
Junk-mail dataset
</h2><span id='topic+JUNK'></span>

<h3>Description</h3>

<p>Building a junk mail classifier based on word and character frequencies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("JUNK")</code></pre>


<h3>Format</h3>

<p>A data frame with 4601 observations on the following 58 variables.
</p>

<dl>
<dt><code>Junk</code></dt><dd><p>a factor with levels <code>Junk</code> <code>Safe</code></p>
</dd>
<dt><code>make</code></dt><dd><p>a numeric vector, the percentage (0-100) of words in the email that are the word <code>make</code> </p>
</dd>
<dt><code>address</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>all</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X3d</code></dt><dd><p>a numeric vector, the percentage (0-100) of words in the email that are the word <code>3d</code></p>
</dd>
<dt><code>our</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>over</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>remove</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>internet</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>order</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>mail</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>receive</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>will</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>people</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>report</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>addresses</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>free</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>business</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>email</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>you</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>credit</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>your</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>font</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X000</code></dt><dd><p>a numeric vector, the percentage (0-100) of words in the email that are the word <code>000</code></p>
</dd>
<dt><code>money</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>hp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>hpl</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>george</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X650</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>lab</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>labs</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>telnet</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X857</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>data</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X415</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X85</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>technology</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X1999</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>parts</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>pm</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>direct</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>cs</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>meeting</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>original</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>project</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>re</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>edu</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>table</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>conference</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>semicolon</code></dt><dd><p>a numeric vector, the percentage (0-100) of characters in the email that are semicolons</p>
</dd>
<dt><code>parenthesis</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>bracket</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>exclamation</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>dollarsign</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>hashtag</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>capital_run_length_average</code></dt><dd><p>a numeric vector, average length of uninterrupted sequence of capital letters</p>
</dd>
<dt><code>capital_run_length_longest</code></dt><dd><p>a numeric vector, length of longest uninterrupted sequence of capital letters</p>
</dd>
<dt><code>capital_run_length_total</code></dt><dd><p>a numeric vector, total number of capital letters in the email</p>
</dd>
</dl>



<h3>Details</h3>

<p>The collection of junk emails came from the postmaster and individuals who classified the email as junk.  The collection of safe emails were from work and personal emails.  Note that most of the variables are percents and can vary from 0-100, though most values are much less than 1 (1%).  
</p>


<h3>Source</h3>

<p>Adapted from the Spambase Data Set at the UCI data repository <a href="https://archive.ics.uci.edu/ml/datasets/Spambase">https://archive.ics.uci.edu/ml/datasets/Spambase</a>.  Creators:   Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt; Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304.   Donor:  George Forman (gforman at nospam hpl.hp.com)
</p>

<hr>
<h2 id='LARGEFLYER'>
Interest in frequent flier program (large version)
</h2><span id='topic+LARGEFLYER'></span>

<h3>Description</h3>

<p>Interest in frequent flier program (artificial)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("LARGEFLYER")</code></pre>


<h3>Format</h3>

<p>A data frame with 100000 observations on the following 2 variables.
</p>

<dl>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>Interest</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>This artificial datasets tabulates the interest in a new frequent flyer program based on gender.  It illustrates that a statistically significant association may have absolutely no practical significance.
</p>

<hr>
<h2 id='LAUNCH'>
New product launch data
</h2><span id='topic+LAUNCH'></span>

<h3>Description</h3>

<p>The profit of newly released products over the first few months of their release
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("LAUNCH")</code></pre>


<h3>Format</h3>

<p>A data frame with 652 observations on the following 420 variables.
</p>

<dl>
<dt><code>Profit</code></dt><dd><p>an anonymized numeric vector, the profit from the product over the first few months of release</p>
</dd>
<dt><code>x1</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x2</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x3</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x4</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x5</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x6</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x7</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x8</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x9</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x10</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x11</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x12</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x13</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x14</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x15</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x16</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x17</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x18</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x19</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x20</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x21</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x22</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x23</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x24</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x25</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x26</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x27</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x28</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x29</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x30</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x31</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x32</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x33</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x34</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x35</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x36</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x37</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x38</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x39</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x40</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x41</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x42</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x43</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x44</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x45</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x46</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x47</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x48</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x49</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x50</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x51</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x52</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x53</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x54</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x55</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x56</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x57</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x58</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x59</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x60</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x61</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x62</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x63</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x64</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x65</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x66</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x67</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x68</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x69</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x70</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x71</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x72</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x73</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x74</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x75</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x76</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x77</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x78</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x79</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x80</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x81</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x82</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x83</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x84</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x85</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x86</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x87</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x88</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x89</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x90</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x91</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x92</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x93</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x94</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x95</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x96</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x97</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x98</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x99</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x100</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x101</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x102</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x103</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x104</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x105</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x106</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x107</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x108</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x109</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x110</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x111</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x112</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x113</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x114</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x115</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x116</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x117</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x118</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x119</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x120</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x121</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x122</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x123</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x124</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x125</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x126</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x127</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x128</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x129</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x130</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x131</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x132</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x133</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x134</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x135</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x136</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x137</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x138</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x139</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x140</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x141</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x142</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x143</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x144</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x145</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x146</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x147</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x148</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x149</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x150</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x151</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x152</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x153</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x154</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x155</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x156</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x157</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x158</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x159</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x160</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x161</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x162</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x163</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x164</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x165</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x166</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x167</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x168</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x169</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x170</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x171</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x172</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x173</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x174</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x175</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x176</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x177</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x178</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x179</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x180</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x181</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x182</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x183</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x184</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x185</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x186</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x187</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x188</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x189</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x190</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x191</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x192</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x193</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x194</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x195</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x196</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x197</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x198</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x199</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x200</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x201</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x202</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x203</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x204</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x205</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x206</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x207</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x208</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x209</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x210</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x211</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x212</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x213</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x214</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x215</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x216</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x217</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x218</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x219</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x220</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x221</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x222</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x223</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x224</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x225</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x226</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x227</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x228</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x229</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x230</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x231</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x232</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x233</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x234</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x235</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x236</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x237</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x238</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x239</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x240</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x241</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x242</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x243</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x244</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x245</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x246</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x247</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x248</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x249</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x250</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x251</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x252</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x253</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x254</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x255</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x256</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x257</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x258</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x259</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x260</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x261</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x262</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x263</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x264</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x265</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x266</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x267</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x268</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x269</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x270</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x271</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x272</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x273</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x274</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x275</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x276</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x277</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x278</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x279</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x280</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x281</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x282</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x283</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x284</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x285</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x286</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x287</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x288</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x289</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x290</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x291</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x292</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x293</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x294</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x295</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x296</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x297</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x298</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x299</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x300</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x301</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x302</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x303</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x304</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x305</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x306</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x307</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x308</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x309</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x310</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x311</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x312</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x313</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x314</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x315</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x316</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x317</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x318</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x319</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x320</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x321</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x322</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x323</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x324</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x325</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x326</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x327</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x328</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x329</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x330</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x331</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x332</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x333</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x334</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x335</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x336</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x337</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x338</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x339</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x340</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x341</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x342</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x343</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x344</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x345</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x346</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x347</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x348</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x349</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x350</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x351</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x352</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x353</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x354</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x355</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x356</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x357</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x358</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x359</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x360</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x361</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x362</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x363</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x364</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x365</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x366</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x367</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x368</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x369</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x370</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x371</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x372</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x373</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x374</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x375</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x376</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x377</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x378</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x379</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x380</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x381</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x382</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x383</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x384</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x385</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x386</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x387</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x388</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x389</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x390</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x391</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x392</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x393</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x394</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x395</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x396</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x397</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x398</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x399</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x400</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x401</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x402</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x403</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x404</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x405</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x406</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x407</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x408</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x409</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x410</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x411</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x412</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x413</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x414</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x415</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x416</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x417</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x418</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
<dt><code>x419</code></dt><dd><p>an anonymized numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>This example is inspired by the Online Product Sales competition on kaggle.com.  The goal is to isolate the minimum number predictors required for accurately predicting <code>Profit</code>.  Since the data is based on an actual case, all predictors are anonymized (some were originally categorical but are treated as numerical for the example).
</p>


<h3>Source</h3>

<p>Inspired by <a href="https://www.kaggle.com/c/online-sales">https://www.kaggle.com/c/online-sales</a>
</p>

<hr>
<h2 id='mode_factor'>
Find the mode of a categorical variable
</h2><span id='topic+mode_factor'></span>

<h3>Description</h3>

<p>This function finds the mode of a categorical variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mode_factor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mode_factor_+3A_x">x</code></td>
<td>
<p>a factor</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mode is the most frequently occuring level of a categorical variable.  This function returns the mode of a categorical variable.  If there is a tie for the most frequent level, it returns all modes.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(EX6.CLICK)
  mode_factor(EX6.CLICK$DeviceModel)
  
  #To see how often it appears try sorting a table
  sort( table(EX6.CLICK$DeviceModel),decreasing=TRUE )
  
  x &lt;- c( rep(letters[1:4],5), "e", "f" )  #multimodel
  mode_factor(x)

  
</code></pre>

<hr>
<h2 id='mosaic'>
Mosaic plot
</h2><span id='topic+mosaic'></span>

<h3>Description</h3>

<p>Provides a mosaic plot to visualize the association between two categorical variables </p>


<h3>Usage</h3>

<pre><code class='language-R'>mosaic(formula,data,color=TRUE,labelat=c(),xlab=c(),ylab=c(),
                            magnification=1,equal=FALSE,inside=FALSE,ordered=FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mosaic_+3A_formula">formula</code></td>
<td>

<p>A standard R formula written as y~x, where y is the name of the variable playing the role of y and x is the name of the variable playing the role of x.  
</p>
</td></tr>
<tr><td><code id="mosaic_+3A_data">data</code></td>
<td>

<p>An optional argument giving the name of the data frame that contains x and y.  If not specified, the function will use existing definitions in the parent environment.
</p>
</td></tr>
<tr><td><code id="mosaic_+3A_color">color</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.   If <code>FALSE</code>, plots are presented in greyscale.  If <code>TRUE</code>, an intelligent color scheme is chosen to shade the plot.  
</p>
</td></tr>
<tr><td><code id="mosaic_+3A_labelat">labelat</code></td>
<td>
<p>a vector of factor levels of <code>x</code> to be labeled (in the case that you want only certain levels to be labeled) </p>
</td></tr>
<tr><td><code id="mosaic_+3A_xlab">xlab</code></td>
<td>
<p>Label of horizontal axis if you want something different that the name of the <code>x</code> variable</p>
</td></tr>
<tr><td><code id="mosaic_+3A_ylab">ylab</code></td>
<td>
<p>Label of vertical axis if you want something different that the name of the <code>y</code> variable</p>
</td></tr>
<tr><td><code id="mosaic_+3A_magnification">magnification</code></td>
<td>
<p>Magnification of the labels of the <code>x</code> variable.  A number smaller than 1 shrinks everything.  A number larger than 1 makes everything larger </p>
</td></tr>
<tr><td><code id="mosaic_+3A_equal">equal</code></td>
<td>
<p>If <code>FALSE</code>, the bar widths are proportional to the frequency of the corresponding level.  If <code>TRUE</code>, the bar widths are all equal (useful if there are many levels or some are extremely rare).</p>
</td></tr>
<tr><td><code id="mosaic_+3A_inside">inside</code></td>
<td>
<p>If <code>FALSE</code>, labels are beneath the bars.  If <code>TRUE</code>, labels are placed inside the bars and rotated (useful if the levels have long names) </p>
</td></tr>
<tr><td><code id="mosaic_+3A_ordered">ordered</code></td>
<td>
<p>If <code>FALSE</code>, bars are in alphabetical order.  If <code>TRUE</code>, the ordering of the bars reflects the ordering of the factor levels.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function shows a mosaic plot to visualize the conditional distributions of <code>y</code> for each level of <code>x</code>, along with the marginal distribution of <code>y</code> to the right of the plot.  The widths of the segmented bar charts are proportional to the frequency of each level of <code>x</code>.  These plots are the same that appear using <code>associate</code>.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+associate">associate</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(ACCOUNT)
	mosaic(Area.Classification~Purchase,data=ACCOUNT,color=TRUE)
	
	data(EX6.CLICK)
	#Default presentation:  not very useful
	mosaic(Click~DeviceModel,data=EX6.CLICK)  
	#Better presentation
	mosaic(Click~DeviceModel,data=EX6.CLICK,equal=TRUE,inside=TRUE,magnification=0.8)  
	 </code></pre>

<hr>
<h2 id='MOVIE'>
Movie grosses
</h2><span id='topic+MOVIE'></span>

<h3>Description</h3>

<p>Movie grosses from the late 1990s
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("MOVIE")</code></pre>


<h3>Format</h3>

<p>A data frame with 309 observations on the following 3 variables.
</p>

<dl>
<dt><code>Movie</code></dt><dd><p>a factor giving the name of the movie </p>
</dd>
<dt><code>Weekend</code></dt><dd><p>a numeric vector, the opening weekend gross (millions of dollars)</p>
</dd>
<dt><code>Total</code></dt><dd><p>a numeric vector, the total US gross (millions of dollars)</p>
</dd>
</dl>



<h3>Details</h3>

<p>The goal is to predict the total gross of a movie based on its opening weekend gross.  
</p>


<h3>Source</h3>

<p>Compiled via information provided on <a href="https://www.imdb.com/">https://www.imdb.com/</a>
</p>

<hr>
<h2 id='NFL'>
NFL database
</h2><span id='topic+NFL'></span>

<h3>Description</h3>

<p>Statistics for NFL teams from the 2002-2012 seasons
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("NFL")</code></pre>


<h3>Format</h3>

<p>A data frame with 352 observations on the following 113 variables.
</p>

<dl>
<dt><code>X4.Wins</code></dt><dd><p>a numeric vector, number of wins (0-16) of an NFL team for the season</p>
</dd>
<dt><code>X5.OffTotPlays</code></dt><dd><p>a numeric vector, number of total plays made on offense for the season</p>
</dd>
<dt><code>X6.OffTotYdsperPly</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X7.OffTot1stDwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X8.OffPass1stDwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X9.OffRush1stDwns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X10.OffFumblesLost</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X11.OffPassComp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X12.OffPassComp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X13.OffPassYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X14.OffPassTds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X15.OffPassTD</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X16.OffPassINTs</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X17.OffPassINT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X18.OffPassLongest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X19.OffPassYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X20.OffPassAdjYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X21.OffPassYdsperComp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X22.OffPasserRating</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X23.OffPassSacksAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X24.OffPassSackYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X25.OffPassNetYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X26.OffPassAdjNetYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X27.OffPassSack</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X28.OffRushYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X29.OffRushTds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X30.OffRushLongest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X31.OffRushYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X32.OffFumbles</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X33.OffPuntReturns</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X34.OffPRYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X35.OffPRTds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X36.OffPRLongest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X37.OffPRYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X38.OffKRTds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X39.OffKRLongest</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X40.OffKRYdsperAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X41.OffAllPurposeYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X42.1to19ydFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X43.1to19ydFGMade</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X44.20to29ydFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X45.20to29ydFGMade</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X46.1to29ydFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X47.30to39ydFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X48.30to39ydFGMade</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X49.30to39ydFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X50.40to49ydFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X51.40to49ydFGMade</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X52.50ydFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X53.50ydFGAtt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X54.40ydFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X55.OffTotFG</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X56.OffXP</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X57.OffTimesPunted</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X58.OffPuntYards</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X59.OffLongestPunt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X60.OffTimesHadPuntBlocked</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X61.OffYardsPerPunt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X62.FmblTds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X63.DefINTTdsScored</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X64.BlockedKickorMissedFGRetTds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X65.Off2ptConvMade</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X66.DefSafetiesScored</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X67.DefTotYdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X68.DefTotPlaysAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X69.DefTotYdsperPlayAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X70.DefTot1stDwnsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X71.DefPass1stDwnsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X72.DefRush1stDwnsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X73.DefFumblesRecovered</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X74.DefPassCompAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X75.DefPassAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X76.DefPassCompAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X77.DefPassYdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X78.DefPassTdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X79.DefPassTDAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X80.DefPassINTs</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X81.DefPassINT</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X82.DefPassYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X83.DefPassAdjYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X84.DefPassYdsperCompAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X85.DefPasserRatingAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X86.DefPassSacks</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X87.DefPassSackYds</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X88.DefPassNetYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X89.DefPassAdjNetYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X90.DefPassSack</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X91.DefRushYdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X92.DefRushTdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X93.DefRushYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X94.DefPuntReturnsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X95.DefPRTdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X96.DefKickReturnsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X97.DefKRTdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X98.DefKRYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X99.DefTotFGAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X100.DefTotFGAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X101.DefXPAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X102.DefPuntsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X103.DefPuntYdsAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X104.DefPuntYdsperAttAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X105.Def2ptConvAlwd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X106.OffSafeties</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X107.OffRushSuccessRate</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X108.OffRunPassRatio</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X109.OffRunPly</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X110.OffYdsPt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X111.DefYdsPt</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X112.HeadCoachDisturbance</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, whether the head coached changed between this season and the last</p>
</dd>
<dt><code>X113.QBDisturbance</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, whether the quarterback changed between this season and the last</p>
</dd>
<dt><code>X114.RBDisturbance</code></dt><dd><p>a factor with levels <code>?</code> <code>No</code> <code>Yes</code>, whether the runningback changed between this seasons and the last</p>
</dd>
<dt><code>X115.OffPassDropRate</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X116.DefPassDropRate</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data was collected from many sources on the internet by a student for use in an independent study in the spring of 2013.  Abbreviations for predictor variables typically follow the full name in prior variables, e.g., KR = kick returns, PR = punt returns, XP = extra point.  Data is organized by year, so rows 1-32 rows are from 2002, rows 33-64 are from 2003, etc.
</p>


<h3>Source</h3>

<p>Contact the originator Weller Ross (jwellerross@gmail.com) for further details.
</p>

<hr>
<h2 id='OFFENSE'>
Some offensive statistics from <code>NFL</code> dataset
</h2><span id='topic+OFFENSE'></span>

<h3>Description</h3>

<p>A subset of the <code>NFL</code> dataset contain some statistics of teams on offense
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("OFFENSE")</code></pre>


<h3>Format</h3>

<p>A data frame with 352 observations on the following 10 variables.
</p>

<dl>
<dt><code>Win</code></dt><dd><p>a numeric vector, number of wins of team over the season (0-16)</p>
</dd>
<dt><code>FirstDowns</code></dt><dd><p>a numeric vector, number of first downs made over the season</p>
</dd>
<dt><code>PassingYards</code></dt><dd><p>a numeric vector, number of passing yards over the season</p>
</dd>
<dt><code>Interceptions</code></dt><dd><p>a numeric vector, number of times ball was intercepted on offense</p>
</dd>
<dt><code>RushingYards</code></dt><dd><p>a numeric vector, number of rushing yards over the season</p>
</dd>
<dt><code>Fumbles</code></dt><dd><p>a numeric vector, number of fumbles made on offense</p>
</dd>
<dt><code>X1to19FGAttempts</code></dt><dd><p>a numeric vector, number of field goal attempts made from 1-19 yards</p>
</dd>
<dt><code>X20to29FGAttempts</code></dt><dd><p>a numeric vector, number of field goal attemps made from 20-29 yards</p>
</dd>
<dt><code>X30to39FGAttempts</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X40to50FGAttempts</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>A small subset of the <code>NFL</code> dataset contain select statistics.  Seasons are from 2002-2012
</p>

<hr>
<h2 id='outlier_demo'>
Interactive demonstration of the effect of an outlier on a regression
</h2><span id='topic+outlier_demo'></span><span id='topic+outlier_demo'></span>

<h3>Description</h3>

<p>This function shows regression lines on user-defined data before and after adding an additional point.</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlier_demo(cex.leg=0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlier_demo_+3A_cex.leg">cex.leg</code></td>
<td>

<p>A number specifying the magnification of legends inside the plot.  Smaller numbers mean smaller font.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows the user to generate data by click on a plot.  Once two points are added, the least squares regression line is draw.  When an additional point is added, the regression line updates while also showing the line without that point.  The effect of outliers on a regression line can easily be illustrated.  Pressing the red UNDO button on the plot will allow you to take away recently added points for further exploration. 
</p>
<p>Note:  To end the demo, you MUST click on the red box labeled &quot;End&quot; (or press Escape, which will return an error)
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>

<hr>
<h2 id='overfit_demo'>
Demonstration of overfitting
</h2><span id='topic+overfit.demo'></span><span id='topic+overfit_demo'></span>

<h3>Description</h3>

<p>This function gives a demonstration of how overfitting occurs on a user-inputted dataset by showing the estimated generalization error as additional variables are added to the regression model (up to all two-way interactions). </p>


<h3>Usage</h3>

<pre><code class='language-R'>overfit_demo(DF,y=NA,seed=NA,aic=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overfit_demo_+3A_df">DF</code></td>
<td>

<p>The data frame where demonstration will occur.
</p>
</td></tr>
<tr><td><code id="overfit_demo_+3A_y">y</code></td>
<td>

<p>The response variable (in quotes)
</p>
</td></tr>
<tr><td><code id="overfit_demo_+3A_seed">seed</code></td>
<td>
<p>Optional argument setting the random number seed if results need to be reproduced</p>
</td></tr>
<tr><td><code id="overfit_demo_+3A_aic">aic</code></td>
<td>

<p>logical, if <code>FALSE</code> the demo will show the RMSE on the training sample instead of the AIC.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function splits <code>DF</code> in half to obtain training and holdout samples.  Regression models are constructed using a forward selection procedure (adding the variable that decreases the AIC the most on the training set), starting at the naive model and terminating at the full model with all two-way interactions.  
</p>
<p>The generalization error of each model is computed on the holdout sample.  The AIC (or RMSE on the training) and generalization errors are plotted versus the number of variables in the model to illustrate overfitting.  Typically, the generalization error decreases at first as useful variables are added to the model, then the generalization error increases after the new variables added start to fit the quirks present only in the training data.  When this happens, the model is said to be overfit.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  #Overfitting occurs after about 10 predictors (AIC begins to increase after 12/13)
  data(BODYFAT)
  overfit_demo(BODYFAT,y="BodyFat",seed=1010)
  
  #Overfitting occurs after about 5 predictors 
  data(OFFENSE)
  overfit_demo(OFFENSE,y="Win",seed=1997,aic=FALSE)
	 </code></pre>

<hr>
<h2 id='PIMA'>
Pima Diabetes dataset</h2><span id='topic+PIMA'></span>

<h3>Description</h3>

<p>Diabetes among women aged 21+ with Pima heritage
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PIMA")</code></pre>


<h3>Format</h3>

<p>A data frame with 392 observations on the following 8 variables.
</p>

<dl>
<dt><code>Pregnant</code></dt><dd><p>a numeric vector, number of times the woman has been pregnant</p>
</dd>
<dt><code>Glucose</code></dt><dd><p>a numeric vector, plasma glucose concentration </p>
</dd>
<dt><code>BloodPressure</code></dt><dd><p>a numeric vector, diastolic blood pressure in mm Hg</p>
</dd>
<dt><code>BodyFat</code></dt><dd><p>a numeric vector, a measurement of the triceps skinfold thickness which is an indicator of body fat percentage</p>
</dd>
<dt><code>Insulin</code></dt><dd><p>a numeric vector, 2-hour serum insulin</p>
</dd>
<dt><code>BMI</code></dt><dd><p>a numeric vector, body mass index</p>
</dd>
<dt><code>Age</code></dt><dd><p>a numeric vector, years</p>
</dd>
<dt><code>Diabetes</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Data on 768 women belonging to the Pima tribe.  The purpose is to study the associations between having diabetes and various physiological characteristics.  Although there are surely other factors (including genetic) that influence the chance of having diabetes, the hope is that by having women who are genetically similar (all from the Pima tribe), that these other factors are naturally accounted for.
</p>


<h3>Source</h3>

<p> Adapted from the UCI data repository <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes</a>.  A variable measuring the &ldquo;diabetes pedigree function&quot; has been omitted.</p>

<hr>
<h2 id='POISON'>
Cockroach poisoning data
</h2><span id='topic+POISON'></span>

<h3>Description</h3>

<p>Dosages and mortality of cockroaches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("POISON")</code></pre>


<h3>Format</h3>

<p>A data frame with 481 observations on the following 2 variables.
</p>

<dl>
<dt><code>Dose</code></dt><dd><p>a numeric vector indicated the dosage of the poison administered to the cockroach</p>
</dd>
<dt><code>Outcome</code></dt><dd><p>a factor with levels <code>Die</code> <code>Live</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Artificial data illustrating a dose-reponse curve.  The probability of dying is well-modeled by a logistic regression model.
</p>

<hr>
<h2 id='possible_regressions'>
Illustrating how a simple linear/logistic regression could have turned out via permutations
</h2><span id='topic+possible.regressions'></span><span id='topic+possible_regressions'></span>

<h3>Description</h3>

<p>This function gives a demonstration of what simple linear or logistic regression lines could have looked like &quot;by chance&quot; if x and y were unrelated.  A scatterplot and fitted regression line is displayed along with the regression lines produced when x and y are unrelated via the permutation procedure.  The sum of squared error reductions for all lines (for linear regressions) are also displayed for an informal assessement of significance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>possible_regressions(M,permutations=100,sse=TRUE,reduction=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="possible_regressions_+3A_m">M</code></td>
<td>

<p>A simple linear regression model from <code>lm</code>
</p>
</td></tr>
<tr><td><code id="possible_regressions_+3A_permutations">permutations</code></td>
<td>

<p>The number of artificial samples generated with the permutation procedure to consider (each will have y and x be independent by design).
</p>
</td></tr>
<tr><td><code id="possible_regressions_+3A_sse">sse</code></td>
<td>
<p>Optional argument to either show or hide the histogram of sum of squared errors of the regression lines.</p>
</td></tr>
<tr><td><code id="possible_regressions_+3A_reduction">reduction</code></td>
<td>
<p>Optional argument that, if <code>sse</code> is <code>TRUE</code>, shows the reduction in the sum of squared errors or the raw sum of squared errors of the regressions themselves.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function gives a scatterplot and fitted regression line for <code>M</code> in red for a linear regression, or the fitted logistic curve (in black) for logistic regression.  Then, via the permutation procedure, it generates <code>permutations</code>, artificial samples where the observed values of x and y are paired up at random, ensuring that no relationship exists between them.  A regression is fit on this permutation sample, and the regression line is drawn in grey to illustrate how it may look &quot;by chance&quot; when x and y are unrelated.
</p>
<p>If requested, a histogram of the sum of squared error reductions of each of the regressions on the permutation datasets (and the original regression in red) is displayed to allow for an informal assessement of the statistical significance of the regression.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  
  #A weak but statistically significant relationship
  data(TIPS)
  M &lt;- lm(TipPercentage~Bill,data=TIPS)
  possible_regressions(M)
  
  #A very strong relationship
  data(SURVEY10)
  M &lt;- lm(PercMoreIntelligentThan~PercMoreAttractiveThan,data=SURVEY10)
  possible_regressions(M,permutations=1000)

  #Show raw SSE instead of reductions
  M &lt;- lm(TipPercentage~PartySize,data=TIPS)
  possible_regressions(M,reduction=FALSE)
	 </code></pre>

<hr>
<h2 id='PRODUCT'>
Sales of a product one quarter after release
</h2><span id='topic+PRODUCT'></span>

<h3>Description</h3>

<p>Sales of a product two quarters after release
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PRODUCT")</code></pre>


<h3>Format</h3>

<p>A data frame with 2768 observations on the following 4 variables.
</p>

<dl>
<dt><code>Outcome</code></dt><dd><p>a factor with levels <code>fail</code> <code>success</code> indicating whether the product was deemed a success or failure </p>
</dd>
<dt><code>Category</code></dt><dd><p>a factor with levels <code>A</code> <code>B</code> <code>C</code> <code>D</code>, the type of item (e.g., kitchen, toys, consumables) </p>
</dd>
<dt><code>Trend</code></dt><dd><p>a factor with levels <code>down</code> <code>up</code>, indicating whether the sales over the first 13 weeks had an upward trend or downward trend according to a simple linear regression</p>
</dd>
<dt><code>SoldWeek13</code></dt><dd><p>a numeric vector, the number of items sold 13 weeks after release</p>
</dd>
</dl>



<h3>Details</h3>

<p>Inspired by the dunnhumby hackathon hosted at <a href="https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon">https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon</a>.  The goal is to predict whether a product will be a success or failure half a year after its release based on its characteristics and performance during the first quarter after its release.
</p>


<h3>Source</h3>

<p>Adapted from <a href="https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon">https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon</a>
</p>

<hr>
<h2 id='PURCHASE'>
PURCHASE data</h2><span id='topic+PURCHASE'></span>

<h3>Description</h3>

<p>Purchase habits of customers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PURCHASE")</code></pre>


<h3>Format</h3>

<p>A data frame with 27723 observations on the following 6 variables.
</p>

<dl>
<dt><code>Purchase</code></dt><dd><p>a factor with levels <code>Buy</code> <code>No</code>, whether the customer made a purchase in the following 30 days</p>
</dd>
<dt><code>Visits</code></dt><dd><p>a numeric vector, number of visits customer has made to the chain in last 90 days</p>
</dd>
<dt><code>Spent</code></dt><dd><p>a numeric vector, amount of money customer has spent at the chain the last 90 days</p>
</dd>
<dt><code>PercentClose</code></dt><dd><p>a numeric vector, the percentage of customers' purchases that occur within 5 miles of their home</p>
</dd>
<dt><code>Closest</code></dt><dd><p>a numeric vector, the distance between the customer's home and the nearest store in the chain</p>
</dd>
<dt><code>CloseStores</code></dt><dd><p>a numeric vector, the number of stores in the chain within 5 miles of the customer's home</p>
</dd>
</dl>



<h3>Details</h3>

<p>A nation-wide chain is curious as to whether it can predict whether a former customer will make a purchase at one of its stores in the next 30 days based on the customer's spending habits.  Some variables are known by the chain (e.g., <code>Visits</code>) and some are available to purchase from credit card companies (e.g., <code>PercentClose</code>).  Is purchasing additional information about the customer worth it?
</p>


<h3>Source</h3>

<p>Adapted from real data on the condition that neither the name of the chain nor other parties be disclosed.
</p>

<hr>
<h2 id='qq'>
QQ plot
</h2><span id='topic+qq'></span>

<h3>Description</h3>

<p>A QQ plot designed with statistics students in mind
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qq(x,ax=NA,leg=NA,cex.leg=0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qq_+3A_x">x</code></td>
<td>

<p>A vector of data
</p>
</td></tr>
<tr><td><code id="qq_+3A_ax">ax</code></td>
<td>

<p>The name you want to call <code>x</code> for the x-axis (if omitted, defaults to what was passed as the first argument).  Useful if the variable is a column in a dataframe. 
</p>
</td></tr>
<tr><td><code id="qq_+3A_leg">leg</code></td>
<td>
<p>Optional argument that places a legend in the top left of the plot with the text given by <code>leg</code></p>
</td></tr>
<tr><td><code id="qq_+3A_cex.leg">cex.leg</code></td>
<td>
<p>Optional argument that gives the magnification of the text in the legend</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function gives a &quot;QQ plot&quot; that is more easily interpreted than the standard QQ plot.  Instead of plotting quantiles, it plots the observed values of <code>x</code> versus the values expected had <code>x</code> come from a Normal distribution.  
</p>
<p>The distribution can be considered approximately Normal if the points stay within the upper/lower dashed red lines (with the possible exception at the far left/right) and if there is no overall global curvature.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   #Distribution does not resemble a Normal
   data(TIPS)
   qq(TIPS$Bill,ax="Bill")
   
   #Distribution resembles aNormal
   data(ATTRACTF)
   qq(ATTRACTF$Score,ax="Attractiveness Score")
   
   
	 </code></pre>

<hr>
<h2 id='SALARY'>
Harris Bank Salary data
</h2><span id='topic+SALARY'></span>

<h3>Description</h3>

<p>Harris Bank Salary data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SALARY")</code></pre>


<h3>Format</h3>

<p>A data frame with 93 observations on the following 5 variables.
</p>

<dl>
<dt><code>Salary</code></dt><dd><p>a numeric vector, starting monthly salary in dollars</p>
</dd>
<dt><code>Education</code></dt><dd><p>a numeric vector, years of schooling at the time of hire</p>
</dd>
<dt><code>Experience</code></dt><dd><p>a numeric vector, number of years of previous work experience</p>
</dd>
<dt><code>Months</code></dt><dd><p>a numeric vector, number of months after Jan 1 1969 that the individual was hired</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Real data used in a court lawsuit.  93 randomly selected employees of Harris Bank Chicago from 1977.  Values in this data have been scaled from the original values (e.g., <code>Experience</code> in years instead of months, <code>Education</code> starts at 0 instead of 8, etc.)
</p>


<h3>Source</h3>

<p>Adapted from the case study at <a href="http://www.stat.ualberta.ca/statslabs/casestudies/sexdiscrimination.htm">http://www.stat.ualberta.ca/statslabs/casestudies/sexdiscrimination.htm</a>
</p>

<hr>
<h2 id='see_interactions'>
Examining pairwise interactions between quantitative variables for a fitted regression model
</h2><span id='topic+see.interactions'></span><span id='topic+see_interactions'></span>

<h3>Description</h3>

<p>Plots all pairwise interactions present in a regression model to allow for an informal assessment of their strength.  When both variables are quantitative, the implicit regression lines of y vs. x1 for a small, the median, and a large value of x2 are provided (and vice versa).  If one of the variables is categorical, the implicit regression lines of y vs. x as displayed for each level of the categorical variable. </p>


<h3>Usage</h3>

<pre><code class='language-R'>see_interactions(M,pos="bottomright",many=FALSE,level=0.95,...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="see_interactions_+3A_m">M</code></td>
<td>

<p>A fitted linear regression model with interactions between quantitative variables. 
</p>
</td></tr>
<tr><td><code id="see_interactions_+3A_pos">pos</code></td>
<td>

<p>Where to put the legend, one of &quot;topleft&quot;, &quot;top&quot;, &quot;topright&quot;, &quot;left&quot;,&quot;center&quot;,&quot;right&quot;,&quot;bottomleft&quot;,&quot;bottom&quot;,&quot;bottomright&quot;
</p>
</td></tr>
<tr><td><code id="see_interactions_+3A_many">many</code></td>
<td>

<p>If <code>TRUE</code>, will give one pair of interaction plots per page and prompt the user to go to the next set (useful if 3+ interactions).  If <code>FALSE</code>, tries to put all pairs on one plot (recommended when 1 or 2 interactions in model).
</p>
</td></tr>
<tr><td><code id="see_interactions_+3A_level">level</code></td>
<td>

<p>Defines what makes a &quot;small&quot; and &quot;large&quot; value of x1 and x2.  By default <code>level</code> is 0.95 so that a large value is the 95th percentile and a small value is the 5th percentile.
</p>
</td></tr>
<tr><td><code id="see_interactions_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code>legend</code>, namely <code>cex</code> to make them smaller.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When determining the implicit regression lines, all variables not involved in the interaction are assumed to be equal 0 (if quantitative) or equal to the level that comes first alphabetically (if categorical).  Tickmarks on the y axis are thus irrelevant and are not displayed.  
</p>
<p>The plots allow an informal assessment of the presence of an interaction between the variables x1 and x2 in the model, after accounting for the other predictors.  If the implicit regression lines are nearly parallel, then the interaction is weak if it exists at all.  If the implicit regression lines have noticeably different slopes, then the interaction is strong.
</p>
<p>When an interaction is present, then the strength of the relationship between y and x1 depends on the value of x2.  In other words, the difference in the average value of y between two individuals who differ in x1 by 1 unit depends on their (common) value of x2 (sometimes the expected difference is large; sometimes it is small).
</p>
<p>If one of the variables in the interaction is cateogorical, the presence of an interaction implies that the strength of the relationship between y and x is different between levels of the categorical variable.  In other words, sometimes the difference in the expected value of y between an individual with level A and an individual with level B is large and sometimes it is small (and this depends on the common value of x of the individuals we are comparing).
</p>
<p>The command <code>visualize.model</code> gives a better representation when only two predictors are in the model.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+visualize.model">visualize.model</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  
  data(SALARY)
	M &lt;- lm(Salary~.^2,data=SALARY)
	#see_interactions(M,many=TRUE)  #not run since it requires user input
	
	data(STUDENT)
	M &lt;- lm(CollegeGPA~(Gender+HSGPA+Family)^2+HSGPA*ACT,data=STUDENT)
	see_interactions(M,cex=0.6)
	 </code></pre>

<hr>
<h2 id='see_models'>
Examining model AICs from the &quot;all possible&quot; regressions procedure using regsubsets
</h2><span id='topic+see.models'></span><span id='topic+see_models'></span>

<h3>Description</h3>

<p>This function takes the output of <code>regsubsets</code> and prints out a table of the top performing models based on AIC criteria. </p>


<h3>Usage</h3>

<pre><code class='language-R'>see_models(ALLMODELS,report=0,aicc=FALSE,reltomin=FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="see_models_+3A_allmodels">ALLMODELS</code></td>
<td>

<p>An object of class regsubsets created from <code><a href="leaps.html#topic+regsubsets">regsubsets</a></code> in package leaps. 
</p>
</td></tr>
<tr><td><code id="see_models_+3A_report">report</code></td>
<td>

<p>An optional argument specifying the number of top models to print out.  If left at a default of 0, the function reports all models whose AICs are within 4 of the lowest overall AIC.
</p>
</td></tr>
<tr><td><code id="see_models_+3A_aicc">aicc</code></td>
<td>

<p>Either <code>TRUE</code> or <code>FALSE</code>.  If <code>TRUE</code>, the AICc of a model is reported instead of the AIC.
</p>
</td></tr>
<tr><td><code id="see_models_+3A_reltomin">reltomin</code></td>
<td>

<p>Either <code>TRUE</code> or <code>FALSE</code>, specifying whether the actual value of the AIC is reported (<code>FALSE</code>) or if AICs should be reported relative to the smallest overall AIC (<code>TRUE</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code><a href="base.html#topic+summary">summary</a></code> function applied to the output of <code><a href="leaps.html#topic+regsubsets">regsubsets</a></code>.  The AIC is calculated to be the one obtained via <code><a href="stats.html#topic+extractAIC">extractAIC</a></code> to allow for easy comparison with <code><a href="#topic+build.model">build.model</a></code> and <code><a href="stats.html#topic+step">step</a></code>.  
</p>
<p>Although the model with the lowest AIC is typically chosen when making a descriptive model, models with AICs within 2 are essentially functionally equivalent.   Any model with an AIC within 2 of the smallest is a reasonable choice since there is no statistical reason to prefer one over the other.   The function returns a data frame of the AIC (or AICc), the number of variables, and the predictors in the &quot;best&quot; models.
</p>
<p>Recall that the function <code><a href="leaps.html#topic+regsubsets">regsubsets</a></code> by default considers up to 8 predictors and does not preserve model hierarchy.  Interactions may appear without both component terms.  Further, only a subset of the indicator variables used to represent a categorical variable may appear.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="leaps.html#topic+regsubsets">regsubsets</a></code>,  <code><a href="stats.html#topic+extractAIC">extractAIC</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  
  data(SALARY)
	ALL &lt;- regsubsets(Salary~.^2,data=SALARY,method="exhaustive",nbest=4)
	see_models(ALL)
	
	#By default, regsubsets considers up to 8 predictors, here it looks at up to 15
	data(ATTRACTF)
	ALL &lt;- regsubsets(Score~.,data=ATTRACTF,nvmax=15,nbest=1)
	see_models(ALL,aicc=TRUE,report=5)
	 </code></pre>

<hr>
<h2 id='segmented_barchart'>
Segmented barchart
</h2><span id='topic+segmented.barchart'></span><span id='topic+segmented_barchart'></span>

<h3>Description</h3>

<p>Produces a segmented barchart of the input variable, forcing it to be categorical if necessary</p>


<h3>Usage</h3>

<pre><code class='language-R'>segmented_barchart(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segmented_barchart_+3A_x">x</code></td>
<td>

<p>A vector.  If numerical, it is treated as categorical variable in the form of a factor
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard segmented barchart.  Shaded areas are labeled with the levels they represent, and the percentage of cases with that level is labeled on the axis to the right.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(STUDENT)
	segmented_barchart(STUDENT$Family)  #Categorical variable
	data(TIPS)
	segmented_barchart(TIPS$PartySize)  #Numerical variable treated as categorical

	 </code></pre>

<hr>
<h2 id='SMALLFLYER'>
Interest in a frequent flier program (small version)
</h2><span id='topic+SMALLFLYER'></span>

<h3>Description</h3>

<p>Interest in a frequent flier program (artificial)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SMALLFLYER")</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 2 variables.
</p>

<dl>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>Interest</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>This artificial datasets tabulates the interest in a new frequent flyer program based on gender.  A larger version of the same data is in <code>LARGEFLYER</code>.  
</p>

<hr>
<h2 id='SOLD26'>
Predicting future sales
</h2><span id='topic+SOLD26'></span>

<h3>Description</h3>

<p>Predicting future sales based on sales data in first quarter after release
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SOLD26")</code></pre>


<h3>Format</h3>

<p>A data frame with 2768 observations on the following 16 variables.
</p>

<dl>
<dt><code>SoldWeek26</code></dt><dd><p>a numeric vector, the number of items sold 26 weeks after release and the quantity to predict</p>
</dd>
<dt><code>StoresSelling1</code></dt><dd><p>a numeric vector, the number of stores selling the item 1 week after release</p>
</dd>
<dt><code>StoresSelling3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>StoresSelling5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>StoresSelling7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>StoresSelling9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>StoresSelling11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>StoresSelling13</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>StoresSelling26</code></dt><dd><p>a numeric vector, the planned number of stores selling the item 26 weeks after release</p>
</dd>
<dt><code>Sold1</code></dt><dd><p>a numeric vector, the number of items sold 1 week after release</p>
</dd>
<dt><code>Sold3</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sold5</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sold7</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sold9</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sold11</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Sold13</code></dt><dd><p>a numeric vector, the number of items sold 13 weeks after release</p>
</dd>
</dl>



<h3>Details</h3>

<p>Inspired by the dunnhumby hackathon hosted at <a href="https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon">https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon</a>.  The goal is to predict the number of items sold 26 weeks after released based on the characteristics of its sales during the first 13 weeks after release (along with information about how many stores are planning to sell the product 26 weeks after release). 
</p>


<h3>Source</h3>

<p>Adapted from <a href="https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon">https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon</a>
</p>

<hr>
<h2 id='SPEED'>
Speed vs. Fuel Efficiency
</h2><span id='topic+SPEED'></span>

<h3>Description</h3>

<p>Speed vs. Fuel Efficiency
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SPEED")</code></pre>


<h3>Format</h3>

<p>A data frame with 40 observations on the following 2 variables.
</p>

<dl>
<dt><code>AverageSpeed</code></dt><dd><p>a numeric vector describing the average speed that the vehicle was driven</p>
</dd>
<dt><code>FuelEfficiency</code></dt><dd><p>a numeric vector describing the measured fuel efficiency </p>
</dd>
</dl>



<h3>Details</h3>

<p>The relationship between fuel efficiency and speed is non-monotonic.
</p>


<h3>Source</h3>

<p>Artificial 
</p>

<hr>
<h2 id='STUDENT'>
STUDENT data
</h2><span id='topic+STUDENT'></span>

<h3>Description</h3>

<p>Data on the College GPAs of students in an introductory statistics class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("STUDENT")</code></pre>


<h3>Format</h3>

<p>A data frame with 607 observations on the following 19 variables.
</p>

<dl>
<dt><code>CollegeGPA</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>HSGPA</code></dt><dd><p>a numeric vector, can range up to 5 if the high school allowed it</p>
</dd>
<dt><code>ACT</code></dt><dd><p>a numeric vector, ACT score</p>
</dd>
<dt><code>APHours</code></dt><dd><p>a numeric vector, number of AP hours student took in HS</p>
</dd>
<dt><code>JobHours</code></dt><dd><p>a numeric vector, number of hours student currently works on average</p>
</dd>
<dt><code>School</code></dt><dd><p>a factor with levels <code>Private</code> <code>Public</code>, type of HS</p>
</dd>
<dt><code>Languages</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Honors</code></dt><dd><p>a numeric vector, number of honors classes taken in HS</p>
</dd>
<dt><code>Smoker</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>AffordCollege</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, can the student and his/her family pay for the University of Tennessee without taking out loans?</p>
</dd>
<dt><code>HSClubs</code></dt><dd><p>a numeric vector, number of clubs belonged to in HS</p>
</dd>
<dt><code>HSJob</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, whether the student maintained a job at some point while in HS </p>
</dd>
<dt><code>Churchgoer</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, answer to the question Do you regularly attend chruch?</p>
</dd>
<dt><code>Height</code></dt><dd><p>a numeric vector (inches)</p>
</dd>
<dt><code>Weight</code></dt><dd><p>a numeric vector (lbs)</p>
</dd>
<dt><code>Class</code></dt><dd><p>a factor with levels <code>Junior</code> <code>Senior</code> <code>Sophomore</code></p>
</dd>
<dt><code>Family</code></dt><dd><p>what position they are in the family, a factor with levels <code>Middle Child</code> <code>Oldest Child</code> <code>Only Child</code> <code>Youngest Child</code></p>
</dd>
<dt><code>Pet</code></dt><dd><p>favorite pet, a factor with levels <code>Both</code> <code>Cat</code> <code>Dog</code> <code>Neither</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>Same data as <code>EDUCATION</code> with the addition of the <code>Class</code> variable and with slighly different names for variables.
</p>


<h3>Source</h3>

<p>Responses are from students in an introductory statistics class at the University of Tennessee in 2010.
</p>

<hr>
<h2 id='suggest_levels'>
Combining levels of a categorical variable
</h2><span id='topic+suggest_levels'></span>

<h3>Description</h3>

<p>This function determines levels that are similar to each other either in terms of their average value of some quantitative variable or the percentages of each level of a two-level categorical variable.  Use it to get a rough idea of what levels are &quot;about the same&quot; with regard to some variable.</p>


<h3>Usage</h3>

<pre><code class='language-R'>suggest_levels(formula,data,maxlevels=NA,target=NA,recode=FALSE,plot=TRUE,...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suggest_levels_+3A_formula">formula</code></td>
<td>

<p>A standard R formula written as y~x.  Here, x is the variable whose levels you wish to combine, and y is the quantitative or two-level categorical variable.  
</p>
</td></tr>
<tr><td><code id="suggest_levels_+3A_data">data</code></td>
<td>

<p>An optional argument giving the name of the data frame that contains x and y.  If not specified, the function will use existing definitions in the parent environment.
</p>
</td></tr>
<tr><td><code id="suggest_levels_+3A_maxlevels">maxlevels</code></td>
<td>

<p>The maximum number of combined levels to consider (cannot exceed 26).
</p>
</td></tr>
<tr><td><code id="suggest_levels_+3A_target">target</code></td>
<td>

<p>The number of resulting levels into which the levels of x will be combined.  Will default to the suggested value of the fewest number whose resulting BIC is no more than 4 above the lowest BIC of any combination.
</p>
</td></tr>
<tr><td><code id="suggest_levels_+3A_recode">recode</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.  If <code>TRUE</code>, the function outputs a conversion table as well as the new level identities
</p>
</td></tr>
<tr><td><code id="suggest_levels_+3A_plot">plot</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code>.  If <code>TRUE</code>, a plot is provided which shows the distribution of <code>y</code> for each level of <code>x</code> and lines showing which levels are grouped together.
</p>
</td></tr>
<tr><td><code id="suggest_levels_+3A_...">...</code></td>
<td>

<p>Additional arguments used to make the plot.  Typically this will be <code>equal=TRUE</code> and <code>inside=TRUE</code> to be passed to <code>mosaic</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the average value (or percentage of each level) of y for each level of x.  It then builds a partition model taking y to be this average value (or percentage) with x being the predictor variable.  The first split yields the &quot;best&quot; scheme for combining levels of x into 2 values.  The second split yields the &quot;best&quot; scheme for combining levels of x into 3 values, etc.  
</p>
<p>The argument <code>maxlevels</code> specifies the maximum numbers of levels in the combination scheme.  By default, it will use the number of levels of x (ie, no combination).  Setting this to a lower number saves time, since most likely a small number of combined levels is desired.  This is useful for seeing how different combination schemes compare.
</p>
<p>The argument <code>target</code> will force the algorithm to producing exactly this number of combined levels.  This is useful once you have determined how many levels of x you want.
</p>
<p>If <code>recode</code> is <code>FALSE</code>, a table showing the combined levels along with the &quot;BIC&quot; of the combination scheme (lower is better, but a difference of around 4 or less is negligible).  The suggested combination will be the fewer number of levels which has as BIC no more than 4 above the scheme that gave the lowest BIC.  
</p>
<p>If <code>recode</code> is <code>TRUE</code>, a list of three elements is produced.  <code>$Conversion1</code> gives a table of the Old and New levels alphabetized by Old while <code>$Conversion2</code> gives a table of the Old and New levels alphabized by New.  <code>$newlevels</code> gives a factor of the cases levels under the new combination scheme.  If <code>target</code> is not set, it will use the suggested number of levels.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
 
  data(DONOR)
  
  #Can levels of URBANICITY be treated the same with regards to probability of donation?
  #Analysis suggests yes (all levels in one)
  suggest_levels(Donate~URBANICITY,data=DONOR)

  #Can levels of URBANICITY be treated the same with regards to donation amount?
  #Analysis suggests yes, but perhaps there are four "effective levels"
  
  suggest_levels(Donation.Amount~URBANICITY,data=DONOR)
  SL &lt;- suggest_levels(Donation.Amount~URBANICITY,data=DONOR,target=4,recode=TRUE)
	SL$Conversion

	#Add a column to the DONOR dataframe that contains these new cluster identities
  DONOR$newCLUSTER_CODE &lt;- SL$newlevels
	 </code></pre>

<hr>
<h2 id='summarize_tree'>
Useful summaries of partition models from rpart
</h2><span id='topic+summarize.tree'></span><span id='topic+summarize_tree'></span>

<h3>Description</h3>

<p>Reports the RMSE, AIC, and variable importances for a partition model or the variable importances from a random forest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_tree(TREE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_tree_+3A_tree">TREE</code></td>
<td>

<p>A partition model created with <code>rpart</code> or a random forest from <code>randomForest</code> 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extracts the RMSE and AIC of a partition model and the variable importances of partition models or random forests.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="rpart.html#topic+rpart">rpart</a></code>, <code>randomForest</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(WINE)
	TREE &lt;- rpart(Quality~.,data=WINE,control=rpart.control(cp=0.01,xval=10,minbucket=5))
	summarize_tree(TREE)
	RF &lt;- randomForest(Quality~.,data=WINE,ntree=50)
	summarize_tree(RF)
	
	data(NFL)
	TREE &lt;- rpart(X4.Wins~.,data=NFL,control=rpart.control(cp=0.002,xval=10,minbucket=5))
	summarize_tree(TREE)
	RF &lt;- randomForest(X4.Wins~.,data=NFL,ntree=50)
	summarize_tree(RF)
	 </code></pre>

<hr>
<h2 id='SURVEY09'>
Student survey 2009
</h2><span id='topic+SURVEY09'></span>

<h3>Description</h3>

<p>Characteristics of students in an introductory statistics class at the University of Tennessee in 2009
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SURVEY09")</code></pre>


<h3>Format</h3>

<p>A data frame with 579 observations on the following 47 variables.
</p>

<dl>
<dt><code>X01.ID</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X02.Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>X03.Weight</code></dt><dd><p>a numeric vector, estimated weight</p>
</dd>
<dt><code>X04.DesiredWeight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X05.Class</code></dt><dd><p>a factor with levels <code>Freshman</code> <code>Junior</code> <code>Senior</code> <code>Sophmore</code></p>
</dd>
<dt><code>X06.BornInTN</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X07.Greek</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, if the student belongs to a fraternity/sorority</p>
</dd>
<dt><code>X08.UTFirstChoice</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X09.Churchgoer</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, does student attend a religious service once a week</p>
</dd>
<dt><code>X10.ParentsMarried</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X11.GPA</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X12.SittingLocation</code></dt><dd><p>a factor with levels <code>Back</code> <code>Front</code> <code>Middle</code> <code>Varies</code></p>
</dd>
<dt><code>X13.WeeklyHoursStudied</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X14.Scholarship</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X15.FacebookFriends</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X16.AgeFirstKiss</code></dt><dd><p>a numeric vector, age at which student had their first romantic kiss</p>
</dd>
<dt><code>X17.CarYear</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X18.DaysPerWeekAlcohol</code></dt><dd><p>a numeric vector, how many days a week student typically drinks</p>
</dd>
<dt><code>X19.NumDrinksParty</code></dt><dd><p>a numeric vector, how many drinks student typically has when he or she goes to a party</p>
</dd>
<dt><code>X20.CellProvider</code></dt><dd><p>a factor with levels <code>ATT</code> <code>Sprint</code> <code>USCellar</code> <code>Verizon</code></p>
</dd>
<dt><code>X21.FreqDroppedCalls</code></dt><dd><p>a factor with levels <code>Occasionally</code> <code>Often</code> <code>Rarely</code></p>
</dd>
<dt><code>X22.MarriedAt</code></dt><dd><p>a numeric vector, age by which student hopes to be married</p>
</dd>
<dt><code>X23.KidsBy</code></dt><dd><p>a numeric vector, age by which students hopes to have kids</p>
</dd>
<dt><code>X24.Computer</code></dt><dd><p>a factor with levels <code>Mac</code> <code>Windows</code></p>
</dd>
<dt><code>X25.FastestDrivingSpeed</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X26.BusinessMajor</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X27.Major</code></dt><dd><p>a factor with levels <code>Business</code> <code>NonBusiness</code></p>
</dd>
<dt><code>X28.TxtsPerDay</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X29.FootballGames</code></dt><dd><p>a numeric vector, games student hopes to attend</p>
</dd>
<dt><code>X30.HoursWorkOut</code></dt><dd><p>a numeric vector, per week</p>
</dd>
<dt><code>X31.MilesToSchool</code></dt><dd><p>a numeric vector, each day</p>
</dd>
<dt><code>X32.MoneyInBank</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X33.MoneyOnHaircut</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X34.PercentTuitionYouPay</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X35.SongsDownloaded</code></dt><dd><p>a numeric vector, songs typically downloaded (legally/illegally) a month</p>
</dd>
<dt><code>X36.ParentCollegeGraduate</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X37.HoursSleepPerNight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X38.Last2DigitsPhone</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X39.NumClassesMissed</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X40.BooksReadThisYear</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X41.UseChopsticks</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X42.YourAttractiveness</code></dt><dd><p>a numeric vector, 1 (unattractive) to 5 (very attractive)</p>
</dd>
<dt><code>X43.Obama</code></dt><dd><p>a factor with levels <code>No</code> <code>NotVote</code> <code>Yes</code></p>
</dd>
<dt><code>X44.HoursWorkedPerWeek</code></dt><dd><p>a numeric vector, at a job outside of a school</p>
</dd>
<dt><code>X45.MoviesInTheater</code></dt><dd><p>a numeric vector, number watched in theater this year</p>
</dd>
<dt><code>X46.KnowSomeoneH1N1</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X47.ReadBeacon</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, the school newspaper</p>
</dd>
</dl>



<h3>Details</h3>

<p>Students answered 47 questions to generate data for a project in an introductory statistics class at the University of Tennessee in the Fall of 2009.  The responses here have only had minimal cleaning (negative numbers omitted) so some data is bad (e.g., a weight of 16).  The questions were:
</p>
<p>Stat 201 Fall 2009 Survey Questions
1. What section are you in? 
2. Gender [Male, Female]
3. Your weight (in pounds) [0 to 500]
4. What is your desired weight (in pounds)? [0 to 1000]
5. What year are you? [Freshman, Sophomore, Junior, Senior, Other]
6. Were you born in Tennessee? [Yes, No]
7. Are you a member of a Greek social society (i.e., a Fraternity/Sorority? [Yes, No]
8. Was UT your first choice? [Yes, No]
9. Do you usually attend a religious service once a week? [Yes, No]
10. Are your parents married? [Yes, No]
11. Thus far, what is your GPA (look up on CPO if you need to)? [0 to 4]
12. Given a choice, where do you like to sit in class? [The front row, Near the front,
Around the middle, Near the back, The back row, Somewhere different all the
time]
13. On average, how many hours per day do you study/do homework? [0 to 24]
14. Do you receive one or more scholarships? [Yes, No]
15. How many Facebook friends do you have? Type -1 if you dont use Facebook.
[-1 to 5000]
16. How old were you when you had your first romantic kiss? Type -1 if it has not
happened yet. [-1 to 100]
17. What is the year of the car you drive most often? Type a four digit number.
Enter 1908 if you never drive a car. [1908 to 2011]
18. On average, how many days per week do you consume one or more alcoholic
beverage? Type -1 if you never drink alcoholic beverages. [-1 to 7]
19. On average, how many alcoholic drinks do you have when you party? Type -1 if
you never drink alcoholic beverages. [-1 to 100]
20. Which cell phone provider do you use (the most, if you have multiple services)?
[ATT (Cingular), Cricket, Sprint, T-Mobile, U.S. Cellular, Verizon, Other, I
dont use a cell phone]
21. How often do you have dropped calls? [Never, Rarely, Sometimes, Often,
Constantly]
22. What is the age at which you hope to be married? Type -1 if you are already
married and type -2 if you never want to get married. [-2 to 100]
23. What is the age at which you hope to have your first child? Type -1 if you
already have one or more children, type -2 if you never want to have children. [-2
to 100]
24. What type of computer do you use most often? [PC running Windows, PC
running linux, Mac running Mac OS, Mac running linux, Mac running Windows,
Other, I dont understand the choices above]
25. What is the fastest speed (in miles per hour) you have ever achieved while driving
a car? [0 to 300]
26. Do you plan on going into the Business School? [Yes, No]
27. What is your desired (or actual) major? [Accounting, Economics, Finance,
Logistics, Marketing, Statistics, Other]
28. How many text messages do you typically send on any given day? Type -1 if you never send text messages. [-1 to 1000]
29. How many UT football games do you hope to attend this year? (Include games already attended this year. Do not include scrimmages.) [0 to 14]
30. How many hours a week do you work out/play sports/exercise, etc.? [0 to 168]
31. How many miles do you drive to school on a typical day? [0 to 500]
32. How much money do you have in your bank account? Type -999 if you think its
none of our business. [-999 to 10000000]
33. How much do you typically spend on a hair cut? [0 to 1000]
34. What percent of tuition are you personally responsible for? Type a number
between 0 and 100.  [0 to 100]
35. Typically, how many songs do you download a month (both legally and/or
illegally)? [0 to 10000]
36. Did at least one of your parents graduate from college? [Yes, No]
37. On average, how many hours do you sleep a night? [0 to 24]
38. What are the last two digits of your phone number? (Type 0 for 00, 1 for 01, 2 for
02, etc.) [0 to 99]
39. Approximately how many classes have you missed/skipped so far this semester?
(For all your courses, including absences for legitimate excuses) [0 to 150]
40. How many books (other than textbooks) have you read so far this year? [0 to
1000]
41. Are you proficient with a pair of chopsticks? [Yes, No]
42. How would you rate your attractiveness on a scale of 1 to 5, with 5 being the most
attractive? [1 to 5]
43. Did you vote for Barack Obama in last Novembers election? [Yes, No I voted
for someone else, No I didnt vote at all]
44. On average, how many hours do you work at a job per week? [0 to 168]
45. How many movies have you watched in theaters this year? [0 to 1000]
46. Do you personally know someone who has come down with H1N1 virus? [Yes,
No]
47. Do you read the Daily Beacon on a regular basis? [Yes, No]
</p>

<hr>
<h2 id='SURVEY10'>Student survey 2010</h2><span id='topic+SURVEY10'></span>

<h3>Description</h3>

<p>Characteristics of students in an introductory statistics class at the University of Tennessee in 2010
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SURVEY10")</code></pre>


<h3>Format</h3>

<p>A data frame with 699 observations on the following 20 variables.
</p>

<dl>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>Height</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Weight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DesiredWeight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GPA</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TxtPerDay</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>MinPerDayFaceBook</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NumTattoos</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NumBodyPiercings</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Handedness</code></dt><dd><p>a factor with levels <code>Ambidextrous</code> <code>Left</code> <code>Right</code></p>
</dd>
<dt><code>WeeklyHrsVideoGame</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>DistanceMovedToSchool</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercentDateable</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>NumPhoneContacts</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercMoreAttractiveThan</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercMoreIntelligentThan</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercMoreAthleticThan</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>PercFunnierThan</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SigificantOther</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>OwnAttractiveness</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Students answered 50 questions to generate data for a project in an introductory statistics class at the University of Tennessee in the Fall of 2010.  The data here represent a selection of the questions.  The responses have been somewhat cleaned (unlike <code>SURVEY09</code>) where obviously bogus responses have been omitted, but there may still be issue.
</p>
<p>The selected questions were:
</p>
<p><code>Gender</code> Gender [Male, Female]
<code>Height</code> Your height (in inches) [48 to 96]
<code>Weight</code> Your weight (in pounds) [0 to 500]
<code>DesiredWeight</code> What is your desired weight (in pounds)? [0 to 1000]
<code>GPA</code> Thus far, what is your GPA (look up on CPO if you need to)? [0 to 4]
<code>TxtPerDay</code> How many text messages do you typically send on any given day? Type 0 if you
never send text messages. [0 to 1000]
<code>MinPerDayFaceBook</code> On average, how many minutes per day do you spend on internet social networks
(such as Facebook, MySpace, Twitter, LinkedIn, etc.)? [0 to 1440]
<code>NumTattoos</code> How many tattoos do you have? [0 to 100]
<code>NumBodyPiercings</code> How many body piercings do you have (do not include piercings you have let heal
up and are gone)? Count each piercing separately (i.e., pierced ears counts as 2
piercings). [0 to 100]
<code>Handedness</code> Are you right-handed, left-handed, or ambidextrous? [Right-Handed, Left-
Handed, Ambidextrous]
<code>WeeklyHrsVideoGame</code> About how many hours a week do you play video games? This includes console games like Wii, Playstation, Xbox, as well as gaming apps for your phone, online games in Facebook, general computer games, etc. [0 to 168]
<code>DistanceMovedToSchool</code> Go to maps.google.com or another website that provides maps. Get directions from your home address (the house/apartment/etc. you most recently lived in before coming to college) and the zip code 37996. How many miles does it say the trip is? Type the smallest number if offered multiple routes. Type 0 if you are unable to get driving directions for any reason. [0 to 5000]
<code>PercentDateable</code> What percentage of people around your age in your preferred gender do you
consider dateable? [0 to 100]
<code>NumPhoneContacts</code> How many contacts do you have in your cell phone? Answer 0 if you don't use a
cell phone, or have no contacts in your cell phone. [0 to 1000]
<code>PercMoreAttractiveThan</code> What percentage of people at UT of your own gender and class level do you think you are more attractive than? [0 to 100]
<code>PercMoreIntelligentThan</code> What percentage of people at UT of your own gender and class level do you think you are more intelligent than? [0 to 100]
<code>PercMoreAthleticThan</code> What percentage of people at UT of your own gender and class level do you think you are more athletic than? [0 to 100]
<code>PercFunnierThan</code> What percentage of people at UT of your own gender and class level do you think you are funnier than? [0 to 100]
<code>SigificantOther</code>  Do you have a significant other? [Yes, No]
<code>OwnAttractiveness</code> On a scale of 1-100, with 100 being the most attractive, rate your own
attractiveness. [1 to 100]
</p>

<hr>
<h2 id='SURVEY11'>
Student survey 2011
</h2><span id='topic+SURVEY11'></span>

<h3>Description</h3>

<p>Characteristics of students in an introductory statistics class at the University of Tennessee in 2011
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SURVEY11")</code></pre>


<h3>Format</h3>

<p>A data frame with 628 observations on the following 51 variables.
</p>

<dl>
<dt><code>X01.ID</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X02.Gender</code></dt><dd><p>a factor with levels <code>F</code> <code>M</code></p>
</dd>
<dt><code>X03.Height</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X04.Weight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X05.SatisfiedWithWeight</code></dt><dd><p>a factor with levels <code>No I Wish I Weighed Less</code> <code>No I Wish I Weighed More</code> <code>Yes</code></p>
</dd>
<dt><code>X06.Class</code></dt><dd><p>a factor with levels <code>Freshman</code> <code>Junior</code> <code>Senior</code> <code>Sophomore</code></p>
</dd>
<dt><code>X07.GPA</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X08.Greek</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X09.PoliticalBeliefs</code></dt><dd><p>a factor with levels <code>Conservative</code> <code>Liberal</code> <code>Mix</code></p>
</dd>
<dt><code>X10.BornInTN</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X11.HairColor</code></dt><dd><p>a factor with levels <code>Black</code> <code>Blonde</code> <code>Brown</code> <code>Red</code></p>
</dd>
<dt><code>X12.GrowUpInUS</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X13.NumberHousemates</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X14.FacebookFriends</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X15.NumPeopleTalkToOnPhone</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X16.MinutesTalkOnPhone</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X17.PeopleSendTextsTo</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X18.NumSentTexts</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X19.Computer</code></dt><dd><p>a factor with levels <code>Mac</code> <code>PC</code></p>
</dd>
<dt><code>X20.Churchgoer</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X21.HoursAtJob</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X22.FastestCarSpeed</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X23.NumTimesBrushTeeth</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X24.SleepPerNight</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X25.MinutesExercisingDay</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X26.BooksReadMonth</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X27.ShowerLength</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X28.PercentRecordedTV</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X29.MostMilesRunOneDay</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X30.MorningPerson</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X31.PercentStudentsDateable</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X32.PercentYouAreMoreAttractive</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X33.PercentYouAreSmarter</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X34.RelationshipStatus</code></dt><dd><p>a factor with levels <code>Complicated</code> <code>Dating</code> <code>Married</code> <code>Single</code></p>
</dd>
<dt><code>X35.AgeFirstKiss</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X36.WeaponAttractMate</code></dt><dd><p>a factor with levels <code>Humor</code> <code>Intelligence</code> <code>Looks</code> <code>Other</code></p>
</dd>
<dt><code>X37.NumSignificantOthers</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X38.WeeksLongestRelationship</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X39.NumDrinksWeek</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X40.FavAlcohol</code></dt><dd><p>a factor with levels <code>Beer</code> <code>Liquor</code> <code>None</code> <code>Wine</code></p>
</dd>
<dt><code>X41.SpeedingTickets</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X42.Smoker</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X43.IllegalDrugs</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X44.DefendantInCourt</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X45.NightInJail</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X46.BrokenBone</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X47.CentsCarrying</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X48.SawLastHarryPotter</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code></p>
</dd>
<dt><code>X49.NumHarryPotterRead</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X50.HoursContinuouslyAwake</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>X51.NumCountriesVisited</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Students answered 51 questions to generate data for a project in an introductory statistics class at the University of Tennessee in the Fall of 2011.   The responses have been minimally modified or cleaned. The questions were:
</p>
<p>1. What section are you in? (To be viewed only by the Stat 201 coordinator, and removed prior to distributing the data.)
2. What is your gender? [M,F]
3. What is your height (in inches)? [0,100]
4. What is your weight (in pounds)? [0,1000]
5. Are you satisfied with your current weight? [Yes, No I wish I weighed less, No I wish I weighed more]
6. What is your class level? [Freshman, Sophomore, Junior, Senior, 5+ year senior, Non-traditional]
7. What is your current GPA? [0,4]
8. Are you a member of a fraternity/sorority? [Yes, No]
9. Overall, do you consider your social/political beliefs to be: [more liberal, more conservative, a mix of
liberal and conservative views]
10. Were you born in Tennessee? [Yes, No]
11. What is your natural hair color? [Black, Brown, Red, Blond, Gray] ##There was a database error
requiring Blond and Gray to be combined into one category.
12. Did you grow up in the US? [Yes, No, Some time in the US but a significant time in another country]
13. How many people share your current residence? Count yourself, so if you live alone, answer 1. Also, if
you live in a dorm, count yourself plus just your roommates/suitemates. [1, 1000]
14. How many Facebook friends do you currently have? (To see how many friends you have in Facebook,
open a new tab or browser window and log in to Facebook, click the down arrow next to Account,
select Edit Friends, and on the left of your screen your friends count is in parentheses.) [0,10000]
15. How many people do you talk to on the phone in a typical day? [0,1000]
16. How many MINUTES a day do you typically spend on the phone talking to people? [0,1440]
17. How many different people do you typically send text messages to on a typical day? [0,1000]
18. How many total texts do you think you send to people on a typical day? [0,5000]
19. What type of computer do you use the most? [Mac, PC, Linux]
20. Do you currently attend religious services at least once a month? [Yes, No]
21. About how many HOURS PER WEEK do you work at a job? [0,168]
22. What is the fastest speed you have achieved while driving a car (in miles per hour)? [0, 500]
23. How many times per day do you typically brush your teeth? [0, 100]
24. On a typical school night, how many HOURS do you sleep? [0, 24]
25. How many MINUTES PER DAY do you typically engage in physical activity (e.g., walking to and
from class, working out at the gym, sports practice, etc.)? [0, 1440]
26. How many books have you read from cover to cover over the last month for pleasure? [0, 1000]
27. How many MINUTES do you typically spend when you take a shower? [0, 1440]
28. Advertisers are concerned that people are &quot;fast forwarding&quot; past their TV commercials, because more
and more people are recording broadcast television and watching it later (for example, on a DVR). Approximately what percent of the TV that you watch (that HAS commercials in it) is something you recorded, and therefore you can &quot;fast forward&quot; past the commercials? [0, 100]
29. What is the longest that you've ever walked/run/hiked in a single day (in MILES)? [0,189]
30. Do you consider yourself a &quot;morning person&quot;? [Yes, No]
31. What percentage of UT students in your preferred gender do you think are dateable? [0, 100]
32. What percentage of UT students do you think you are more attractive than? [0, 100]
33. What percentage of UT students do you think you are more intelligent than? [0, 100]
34. What is your relationship status? [Single, Casually dating one or more people, Dating someone regularly, Engaged, Married, It's complicated]
35. How old were you when you had your first romantic kiss? (Enter 0 if this has not yet happened.) [0, 99]
36. Which of the following would you consider to be your main weapon for attracting a potential mate?
[Looks, Intelligence, Sense of Humor, Other]
37. How many boyfriends/girlfriends have you had? (We'll leave it up to you as to what constitutes a
boyfriend or girlfriend.) [0, 1000]
38. What is the longest amount of time (in WEEKS) that you have been in a relationship with a significant
other? (A shortcut: take the number of months and multiply by 4, or the number of years and multiply
by 52.) [0, 4000]
39. How many alcoholic beverages do you typically consume PER WEEK? (consider 1 alcoholic beverage
a 12 oz. beer, a 4 oz. glass of wine, a 1 oz. shot of liquor, etc.) [0, 200]
40. What is your favorite kind of alcoholic beverage? [I don't drink alcoholic beverages, Beer, Wine,
Whiskey, Vodka, Gin, Tequila, Rum, Other]
41. How may speeding tickets have you received? [0, 500]
42. Do you consider yourself a &quot;smoker&quot;? [Yes, No]
43. Have you ever used an illegal/controlled substance? (Exclude alcohol/cigarettes consumed when
underaged.) [Yes, No]
44. Have you ever appeared before a judge/jury as a defendant? (Exclude speeding or parking tickets.)
[Yes, No]
45. Have you ever spent the night in a jail cell? [Yes, No]
46. Have you ever broken a bone that required surgery or a cast (or both)? [Yes, No]
47. Check your pockets and/or purse and report how much money in coins (in CENTS) that you currently
are carrying. For example, if you have one quarter and one penny, type 26, not 0.26. [0, 1000]
48. Have you seen the latest Harry Potter movie that came out in July 2011? [Yes, No]
49. How many of the seven Harry Potter books have you completely read? [0, 7]
50. Estimate the longest amount of time (in HOURS) that you have continuously stayed awake. [0, 450]
51. How many countries have you ever stepped foot in outside an airport (include the US in your count)?
[1, 196]
</p>

<hr>
<h2 id='TIPS'>
TIPS dataset
</h2><span id='topic+TIPS'></span>

<h3>Description</h3>

<p>One waiter recorded information about each tip he received over a period of a few months working in one restaurant. He collected several variables:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("TIPS")</code></pre>


<h3>Format</h3>

<p>A data frame with 244 observations on the following 8 variables.
</p>

<dl>
<dt><code>TipPercentage</code></dt><dd><p>a numeric vector, the tip written as a percentage (0-100) of the total bill</p>
</dd>
<dt><code>Bill</code></dt><dd><p>a numeric vector, the bill amount (dollars)</p>
</dd>
<dt><code>Tip</code></dt><dd><p>a numeric vector, the tip amount (dollars)</p>
</dd>
<dt><code>Gender</code></dt><dd><p>a factor with levels <code>Female</code> <code>Male</code>, gender of the payer of the bill</p>
</dd>
<dt><code>Smoker</code></dt><dd><p>a factor with levels <code>No</code> <code>Yes</code>, whether the party included smokers</p>
</dd>
<dt><code>Weekday</code></dt><dd><p>a factor with levels <code>Friday</code> <code>Saturday</code> <code>Sunday</code> <code>Thursday</code>, day of the week</p>
</dd>
<dt><code>Time</code></dt><dd><p>a factor with levels <code>Day</code> <code>Night</code>, rough time of day</p>
</dd>
<dt><code>PartySize</code></dt><dd><p>a numeric vector, number of people in party</p>
</dd>
</dl>



<h3>Source</h3>

<p>This is the <code>Tips</code> dataset in package <code>reshape</code>, modified to include the tip percentage.
</p>

<hr>
<h2 id='VIF'>
Variance Inflation Factor
</h2><span id='topic+VIF'></span>

<h3>Description</h3>

<p>Calculates the variation inflation factors of all predictors in regression models</p>


<h3>Usage</h3>

<pre><code class='language-R'>VIF(mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VIF_+3A_mod">mod</code></td>
<td>

<p>A linear or logistic regression model
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a simple port of <code>vif</code> from the <code>car</code> package.  The VIF of a predictor is a measure for how easily it is predicted from a linear regression using the other predictors.  Taking the square root of the VIF tells you how much larger the standard error of the estimated coefficient is respect to the case when that predictor is independent of the other predictors.  
</p>
<p>A general guideline is that a VIF larger than 5 or 10 is large, indicating that the model has problems estimating the coefficient.  However, this in general does not degrade the quality of predictions.  If the VIF is larger than 1/(1-R2), where R2 is the Multiple R-squared of the regression, then that predictor is more related to the other predictors than it is to the response.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling with R
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	#A case where the VIFs are small
	data(SALARY)
	M &lt;- lm(Salary~.,data=SALARY)
	VIF(M)

  #A case where (some of) the VIFs are large
  data(BODYFAT)
  M &lt;- lm(BodyFat~.,data=BODYFAT)
  VIF(M)
	 </code></pre>

<hr>
<h2 id='visualize_model'>
Visualizations of one or two variable linear or logistic regressions or of partitions models
</h2><span id='topic+visualize_model'></span><span id='topic+visualize.model'></span>

<h3>Description</h3>

<p>Provides useful plots to illustrate the inner-workings of regression models with one or two predictors or a partition model with not too many branches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualize_model(M,loc="topleft",level=0.95,cex.leg=0.7,midline=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualize_model_+3A_m">M</code></td>
<td>

<p>A linear or logistic regression model with one or two predictors (not all categorical) produced by  <code>lm</code> or <code>glm</code>, respectively, or a partition model produced by <code>rpart</code>.  It is ok to pass an object made with <code>train</code> from the <code>caret</code> package if method <code>lm</code> or <code>glm</code> is used.
</p>
</td></tr>
<tr><td><code id="visualize_model_+3A_loc">loc</code></td>
<td>

<p>The location for the legend, if one is to be displayed.  Can also be &quot;top&quot;, &quot;topright&quot;, &quot;left&quot;, &quot;center&quot;, &quot;right&quot;, &quot;bottomleft&quot;, &quot;bottom&quot;, or &quot;bottomright&quot;.
</p>
</td></tr>
<tr><td><code id="visualize_model_+3A_level">level</code></td>
<td>

<p>The level of confidence for confidence and prediction intervals for the case of simple linear regression.
</p>
</td></tr>
<tr><td><code id="visualize_model_+3A_cex.leg">cex.leg</code></td>
<td>

<p>Magnification factor for text in legends.  Smaller numbers indicate smaller text.  Default is 0.7.
</p>
</td></tr>
<tr><td><code id="visualize_model_+3A_midline">midline</code></td>
<td>

<p>logical, either <code>TRUE</code> (draw a dotted line at p=0.5 for logistic regression) or <code>FALSE</code> (do not draw line)
</p>
</td></tr>
<tr><td><code id="visualize_model_+3A_...">...</code></td>
<td>

<p>Additional arguments to <code>plot</code>.  This is typically only used for logistic regression models where <code>xlim</code> is to be specified to see the entirety of the curve instead of using the default range.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>M</code> is a simple linear regression model, this provides a scatter plot, fitted line, and confidence/prediction intervals.
</p>
<p>If <code>M</code> is a simple logistic regression model, this provides the fitted logistic curve.
</p>
<p>If <code>M</code> is a regression with two quantitative predictors, this provides the implicit regression lines when one of the variables equals its 5th (small), 50th (median), and 95th (large) percentiles.  The model may have interaction terms.  In this case, the p-value of the interaction is output.  The definition of small and large can be changed with the <code>level</code> argument.
</p>
<p>If <code>M</code> is a regression with a quantitative predictor and a categorical predictor (with or without interactions), this provides the implicit regression lines for each level of the categorical predictor.  The p-value of the effect test is displayed if an interaction is in the model.
</p>
<p>If <code>M</code> is a partition model from <code>rpart</code>, this shows the tree.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="rpart.html#topic+rpart">rpart</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+glm">glm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(SALARY)
  #Simple linear regression with 90% confidence and prediction intervals
  M &lt;- lm(Salary~Education,data=SALARY)
  visualize_model(M,level=0.90,loc="bottomright")
  
  #Multiple linear regression with two quantitative predictors (no interaction)
  M &lt;- lm(Salary~Education+Experience,data=SALARY)
  visualize_model(M)

  #Multiple linear regression with two quantitative predictors (with interaction)
  #Take small and large to be the 25th and 75th percentiles
  M &lt;- lm(Salary~Education*Experience,data=SALARY)
  visualize_model(M,level=0.75)
  
  #Multiple linear regression with one categorical and one quantitative predictor
  M &lt;- lm(Salary~Education*Gender,data=SALARY)
  visualize_model(M)

  data(WINE)
  #Simple logistic regression with expanded x limits
  M &lt;- glm(Quality~alcohol,data=WINE,family=binomial)
  visualize_model(M,xlim=c(0,20))

  #Multiple logistic regression with two quantitative predictors
  M &lt;- glm(Quality~alcohol*sulphates,data=WINE,family=binomial)
  visualize_model(M,loc="left",midline=FALSE)

  data(TIPS)
  #Multiple logistic regression with one categorical and one quantitative predictor
  #expanded x-limits to see more of the curve
  M &lt;- glm(Smoker~PartySize*Weekday,data=TIPS,family=binomial)
  visualize_model(M,loc="topright",xlim=c(-5,15))
  
  #Partition model predicting a quantitative response
  TREE &lt;- rpart(Salary~.,data=SALARY)
  visualize_model(TREE)
  
  #Partition model predicting a categorical response
  TREE &lt;- rpart(Quality~.,data=WINE)
  visualize_model(TREE)
</code></pre>

<hr>
<h2 id='visualize_relationship'>
Visualizing the relationship between y and x in a partition model
</h2><span id='topic+visualize.relationship'></span><span id='topic+visualize_relationship'></span>

<h3>Description</h3>

<p>Attempts to show how the relationship between y and x is being modeled in a partition or random forest model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualize_relationship(TREE,interest,on,smooth=TRUE,marginal=TRUE,nplots=5,
  seed=NA,pos="topright",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualize_relationship_+3A_tree">TREE</code></td>
<td>

<p>A partition or random forest model (though it works with many regression models as well)
</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_interest">interest</code></td>
<td>

<p>The name of the predictor variable for which the plot of y vs. x is to be made.
</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_on">on</code></td>
<td>

<p>A dataframe giving the values of the other predictor variables for which the relationship is to be visualized.  Typically this is the dataframe on which the partition model was built.
</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_smooth">smooth</code></td>
<td>

<p>If <code>TRUE</code>, the relationship is plotted using a <code>loess</code> to smooth out the relationship
</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_marginal">marginal</code></td>
<td>

<p>If <code>TRUE</code>, the modeled value of y at a particular value of x is the average of the predicted values of y over all rows which have that common value of x.  If <code>FALSE</code>, then <code>nplots</code> rows from <code>on</code> will be selected and all other predictors will be fixed, showing the relationship between y and x for that particular set of characteristics.
</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_nplots">nplots</code></td>
<td>

<p>The number of rows of <code>on</code> for which the relationship is plotted (if <code>marginal</code> is set to <code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_seed">seed</code></td>
<td>
<p>the seed for the random number seed if reproducibility is required</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_pos">pos</code></td>
<td>
<p>the location of the legend</p>
</td></tr>
<tr><td><code id="visualize_relationship_+3A_...">...</code></td>
<td>
<p>additional arguments past to <code>plot</code>, namely <code>xlim</code> and <code>ylim</code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function shows a scatterplot of y vs. x in the <code>on</code> dataframe, then shows how <code>TREE</code> is modeling the relationship between y and x with predicted values of y for each row in the data and also a curve illustrating the relationship.  It is useful for seeing what the relationship between y and x as modeled by <code>TREE</code> &quot;looks like&quot;, both as a whole and for particular combinations of other variables.  If <code>marginal</code> is <code>FALSE</code>, then differences  in the curves indicate the presence of some interaction between x and another variable.
</p>


<h3>Author(s)</h3>

<p>Adam Petrie
</p>


<h3>References</h3>

<p>Introduction to Regression and Modeling
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+loess">loess</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+glm">glm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(SALARY)
  FOREST &lt;- randomForest(Salary~.,data=SALARY)
  visualize_relationship(FOREST,interest="Experience",on=SALARY)
  visualize_relationship(FOREST,interest="Months",on=SALARY,xlim=c(1,15),ylim=c(2500,4500))

  data(WINE)
  TREE &lt;- rpart(Quality~.,data=WINE)
  visualize_relationship(TREE,interest="alcohol",on=WINE,smooth=FALSE)
  visualize_relationship(TREE,interest="alcohol",on=WINE,marginal=FALSE,nplots=7,smooth=FALSE)
</code></pre>

<hr>
<h2 id='WINE'>
WINE data
</h2><span id='topic+WINE'></span>

<h3>Description</h3>

<p>Predicting the quality of wine based on its chemical characteristics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("WINE")</code></pre>


<h3>Format</h3>

<p>A data frame with 2700 observations on the following 12 variables.
</p>

<dl>
<dt><code>Quality</code></dt><dd><p>a factor with levels <code>high</code> <code>low</code></p>
</dd>
<dt><code>fixed.acidity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>volatile.acidity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>citric.acid</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>residual.sugar</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>chlorides</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>free.sulfur.dioxide</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>total.sulfur.dioxide</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>density</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>pH</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sulphates</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>alcohol</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is the famous wine dataset from the UCI data repository <a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality">https://archive.ics.uci.edu/ml/datasets/Wine+Quality</a> with some modifications. Namely, the quality in the original data was a score between 0 and 10.  These has been coded as either high or low.  See description on UCI for description of variables.
</p>


<h3>References</h3>

<p>P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
