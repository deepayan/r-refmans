<!DOCTYPE html><html lang="en"><head><title>Help for package scalablebayesm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scalablebayesm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#combine_draws'><p>Combine Lists of Draws From a Posterior Predictive Distribution</p></a></li>
<li><a href='#drawMixture'><p>Gibbs Sampler Inference for a Mixture of Multivariate Normals</p></a></li>
<li><a href='#drawPosteriorParallel'><p>Draw from Posterior Parallel Distribution</p></a></li>
<li><a href='#hello'><p>A placeholder function using roxygen</p></a></li>
<li><a href='#partition_data'><p>Partition Data Into Shards</p></a></li>
<li><a href='#rheteroLinearIndepMetrop'><p>Distributed Independence Metropolis-Hastings Algorithm for Draws From Multivariate Normal Distribution</p></a></li>
<li><a href='#rheteroMnlIndepMetrop'><p>Independence Metropolis-Hastings Algorithm for Draws From Multinomial Distribution</p></a></li>
<li><a href='#rhierLinearDPParallel'><p>MCMC Algorithm for Hierarchical Linear Model with Dirichlet Process Prior Heterogeneity</p></a></li>
<li><a href='#rhierLinearMixtureParallel'><p>MCMC Algorithm for Hierarchical Multinomial Linear Model with Mixture-of-Normals Heterogeneity</p></a></li>
<li><a href='#rhierMnlDPParallel'><p>MCMC Algorithm for Hierarchical Multinomial Logit with Dirichlet Process Prior Heterogeneity</p></a></li>
<li><a href='#rhierMnlRwMixtureParallel'><p>MCMC Algorithm for Hierarchical Multinomial Logit with Mixture-of-Normals Heterogeneity</p></a></li>
<li><a href='#s_max'><p>Calculate Maximum Number of Shards</p></a></li>
<li><a href='#sample_data'><p>Sample Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Distributed Markov Chain Monte Carlo for Bayesian Inference in
Marketing</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-28</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Federico Bumbaca &lt;federico.bumbaca@colorado.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimates unit-level and population-level parameters from a hierarchical model in marketing applications. The package includes:
  Hierarchical Linear Models with a mixture of normals prior and covariates,
  Hierarchical Multinomial Logits with a mixture of normals prior and covariates,
  Hierarchical Multinomial Logits with a Dirichlet Process prior and covariates. For more details, see Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020) &lt;<a href="https://doi.org/10.1177%2F0022243720952410">doi:10.1177/0022243720952410</a>&gt; "Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models". Journal of Marketing Research, 57(6), 999-1018.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.9), parallel, bayesm</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, bayesm</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-23 19:33:42 UTC; jacknovak</td>
</tr>
<tr>
<td>Author:</td>
<td>Federico Bumbaca [aut, cre],
  Jackson Novak [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-25 12:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='combine_draws'>Combine Lists of Draws From a Posterior Predictive Distribution</h2><span id='topic+combine_draws'></span>

<h3>Description</h3>

<p><code>combine_draws</code> combines and resamples parameter draws returned from an MCMC algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_draws(draws, r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combine_draws_+3A_draws">draws</code></td>
<td>
<p>A list of draws from a posterior predictive distribution</p>
</td></tr>
<tr><td><code id="combine_draws_+3A_r">r</code></td>
<td>
<p>Number of MCMC draws</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix or data frame containing 'R' randomly sampled rows 
from the combined 'betadraw' components.
</p>


<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rhierLinearMixtureParallel">rhierLinearMixtureParallel</a></code>, 
<code><a href="#topic+rhierMnlRwMixtureParallel">rhierMnlRwMixtureParallel</a></code>, 
<code><a href="#topic+rhierLinearDPParallel">rhierLinearDPParallel</a></code>, 
<code><a href="#topic+rhierMnlDPParallel">rhierMnlDPParallel</a></code>
</p>

<hr>
<h2 id='drawMixture'>Gibbs Sampler Inference for a Mixture of Multivariate Normals</h2><span id='topic+drawMixture'></span>

<h3>Description</h3>

<p><code>drawMixture</code> implements a Gibbs sampler to conduct inference on draws from a multivariate normal mixture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drawMixture(out, N, Z, Prior, Mcmc, verbose)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drawMixture_+3A_out">out</code></td>
<td>
<p>A list containing compdraw, probdraw, and (optionally) Deltadraw.</p>
</td></tr>
<tr><td><code id="drawMixture_+3A_n">N</code></td>
<td>
<p>An integer specifying the number of observational units to sample</p>
</td></tr>
<tr><td><code id="drawMixture_+3A_z">Z</code></td>
<td>
<p>An <code class="reqn">(nreg) \times nz</code> or <code class="reqn">(nlgt) \times nz</code> matrix of unit characteristics</p>
</td></tr>
<tr><td><code id="drawMixture_+3A_prior">Prior</code></td>
<td>
<p>A list with one required parameter: 'ncomp', and optional parameters: 'mubar', 'Amu', 'nu', 'V', 'Ad', 'deltaBar', and 'a'.</p>
</td></tr>
<tr><td><code id="drawMixture_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R' - number of iterations, and optional parameters: 's', 'w', 'keep', 'nprint', and 'drawcomp'.</p>
</td></tr>
<tr><td><code id="drawMixture_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, enumerates model parameters and timing information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>

<ul>
<li> <p><strong>nmix</strong>: A list with the following components:
</p>

<ul>
<li> <p><strong>probdraw</strong>: A matrix of size <code>(R/keep) x (ncomp)</code>, containing the probability draws at each Gibbs iteration.
</p>
</li>
<li> <p><strong>compdraw</strong>: A list containing the drawn mixture components at each Gibbs iteration.
</p>
</li></ul>

</li>
<li> <p><strong>Deltadraw</strong> (optional): A matrix of size <code>(R/keep) x (nz * nvar)</code>, containing the delta draws, if <code>Z</code> is not <code>NULL</code>. If <code>Z</code> is <code>NULL</code>, this element is not included.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, Federico (Rico), Sanjog Misra, and Peter E. Rossi (2020), &quot;Scalable Target Marketing:
Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models&quot;, Journal of Marketing
Research, 57(6), 999-1018.
</p>
<p>Chapter 5, <em>Bayesian Statistics and Marketing</em> by Rossi, Allenby, and McCulloch.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rhierLinearDPParallel">rhierLinearDPParallel</a></code>, 
<code><a href="#topic+rhierMnlDPParallel">rhierMnlDPParallel</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


# Linear DP
## Generate single component linear data with Z
R = 1000
nreg = 1000
nobs = 5 #number of observations
nvar = 3 #columns
nz = 2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))
Delta=matrix(c(1,0,1,0,1,2),ncol=nz) 
tau0=1
iota=c(rep(1,nobs)) 

## create arguments for rmixture
tcomps=NULL
a = diag(1, nrow=3)
tcomps[[1]] = list(mu=c(1,-2,0),rooti=a) 
tpvec = 1                            
ncomp=length(tcomps)

regdata=NULL
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) { 
 tempout=bayesm::rmixture(1,tpvec,tcomps)
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta%*%Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X%*%betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau) 
}

Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep)
Data1=list(list(regdata=regdata,Z=Z))

#subsample data
N = length(Data1[[1]]$regdata)

s=1

#Partition data into s shards
Data2 = partition_data(Data = Data1, s = s)

#Run distributed first stage
timing_result1 = system.time({
 out_distributed = parallel::mclapply(Data2, FUN = rhierLinearDPParallel, 
 Prior = Prior1, Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)
})

Z = matrix(unlist(Z), ncol = nz, byrow = TRUE)

# Conduct inference on first-stage draws
draws = parallel::mclapply(out_distributed, FUN = drawMixture, 
Prior=Prior1, Mcmc=Mcmc1, N=N, Z = Z,
                          mc.cores = s, mc.set.seed = FALSE) 

#Generate single component multinomial data with Z
##parameters
R = 1000
p = 3 # number of choice alternatives                            
ncoef = 3
nlgt=1000
nz = 2

# Define Z matrix
Z = matrix(runif(nz*nlgt),ncol=nz)
Z = t(t(Z)-apply(Z,2,mean))          # demean Z
Delta=matrix(c(1,0,1,0,1,2),ncol=2)

tcomps=NULL
a = diag(1, nrow=3)
tcomps[[1]] = list(mu=c(-1,2,4),rooti=a) 
tpvec = 1                             
ncomp=length(tcomps)

simmnlwX= function(n,X,beta){
 k=length(beta)
 Xbeta=X %*% beta
 j=nrow(Xbeta)/n
 Xbeta=matrix(Xbeta,byrow=TRUE,ncol=j)
 Prob=exp(Xbeta)
 iota=c(rep(1,j))
 denom=Prob %*% iota
 Prob=Prob/as.vector(denom)
 y=vector("double",n)
 ind=1:j
 for (i in 1:n) { 
   yvec = rmultinom(1, 1, Prob[i,])
   y[i] = ind%*%yvec
 }
 return(list(y=y,X=X,beta=beta,prob=Prob))
}

## simulate data
simlgtdata=NULL
ni=rep(5,nlgt) 
for (i in 1:nlgt) 
{
 if (is.null(Z))
 {
   betai=as.vector(bayesm::rmixture(1,tpvec,tcomps)$x)
 } else {
   betai=Delta %*% Z[i,]+as.vector(bayesm::rmixture(1,tpvec,tcomps)$x)
 }
 Xa=matrix(runif(ni[i]*p,min=-1.5,max=0),ncol=p)
 X=bayesm::createX(p,na=1,nd=NULL,Xa=Xa,Xd=NULL,base=1)
 outa=simmnlwX(ni[i],X,betai)
 simlgtdata[[i]]=list(y=outa$y,X=X,beta=betai)
}

## set parms for priors and Z
Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep) 
Data1=list(list(lgtdata=simlgtdata, p=p, Z=Z))

N = length(Data1[[1]]$lgtdata)

s=1

#Partition data into s shards
Data2 = partition_data(Data = Data1, s = s)

#Run distributed first stage
timing_result1 = system.time({
 out_distributed = parallel::mclapply(Data2, FUN = rhierMnlDPParallel, 
 Prior = Prior1, Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)
})

#Conduct inference on first-stage draws
draws = parallel::mclapply(out_distributed, FUN = drawMixture, 
Prior=Prior1, Mcmc=Mcmc1, N=N, Z = Z, mc.cores = s, mc.set.seed = FALSE) 




</code></pre>

<hr>
<h2 id='drawPosteriorParallel'>Draw from Posterior Parallel Distribution</h2><span id='topic+drawPosteriorParallel'></span>

<h3>Description</h3>

<p><code>drawPosteriorParallel</code> draws from a posterior predictive distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drawPosteriorParallel(draws, Z, Prior, Mcmc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drawPosteriorParallel_+3A_draws">draws</code></td>
<td>
<p>(list) - a list of length s where each sublist contains compdraw,</p>
</td></tr>
<tr><td><code id="drawPosteriorParallel_+3A_z">Z</code></td>
<td>
<p>(matrix) - (optional) an <code class="reqn">nreg/s \times nz</code> matrix of unit characteristics</p>
</td></tr>
<tr><td><code id="drawPosteriorParallel_+3A_prior">Prior</code></td>
<td>
<p>(list) - (optional) a list of optional parameters 'v' and 'nu'</p>
</td></tr>
<tr><td><code id="drawPosteriorParallel_+3A_mcmc">Mcmc</code></td>
<td>
<p>(list) - a list containing 'R' and optionally 'keep'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><strong>betadraw</strong>: A matrix of size <code class="reqn">R \times nvar</code> containing the drawn <code>beta</code> values from the Gibbs sampling procedure.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>
<p>Federico Bumbaca, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


s=1
R=2000
nreg = 2000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=NULL
Delta=matrix(c(1,0,1,0,1,2),ncol=nz) 
tau0=1
iota=c(rep(1,nobs)) 

## create arguments for rmixture

#Default
tcomps=NULL
a = diag(1, nrow=3)
tcomps[[1]] = list(mu=c(0,-1,-2),rooti=a) 
tpvec = 1                             
ncomp=length(tcomps)

regdata=NULL
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) { 
 tempout=bayesm::rmixture(1,tpvec,tcomps)
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta%*%Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X%*%betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau) 
}

Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep)
Data1=list(list(regdata=regdata,Z=Z))


Data2 = partition_data(Data1, s)

draws = parallel::mclapply(Data2, FUN = rhierLinearMixtureParallel, Prior = Prior1, Mcmc = Mcmc1, 
mc.cores = s, mc.set.seed = TRUE)

out = parallel::mclapply(draws,FUN=drawPosteriorParallel,
Z=Z, Prior = Prior1, Mcmc = Mcmc1, mc.cores=s,
mc.set.seed = TRUE)



</code></pre>

<hr>
<h2 id='hello'>A placeholder function using roxygen</h2><span id='topic+hello'></span>

<h3>Description</h3>

<p>This function shows a standard text on the console. In a time-honored
tradition, it defaults to displaying <em>hello, world</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hello(txt = "world")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hello_+3A_txt">txt</code></td>
<td>
<p>An optional character variable, defaults to &lsquo;world&rsquo;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing is returned but as a side effect output is printed
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hello()
hello("and goodbye")
</code></pre>

<hr>
<h2 id='partition_data'>Partition Data Into Shards</h2><span id='topic+partition_data'></span>

<h3>Description</h3>

<p>A function to partition data into s shards for use in distributed estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partition_data(Data, s)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partition_data_+3A_data">Data</code></td>
<td>
<p>A list of containing either 'regdata' or 'lgtdata' and 'Z'(optional). If 'Data' contains 'lgtdata', it should also contain 'p' number of choice alternatives.</p>
</td></tr>
<tr><td><code id="partition_data_+3A_s">s</code></td>
<td>
<p>The number of shards to partition the data into.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of 's' shards where each shard contains:
</p>
<table role = "presentation">
<tr><td><code>p</code></td>
<td>
<p>(integer) - Number of choice alternatives (only if 'Data' contains 'lgtdata')</p>
</td></tr>
<tr><td><code>lgtdata or regdata</code></td>
<td>
<p>(list, length: n) - A list of n elements where each element contains 'X', 'y', 'beta', and 'tau'</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>(Matrix) - A n x nz matrix of units chars. Null if 'Data' does not contain Z [Optional]</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Generate hierarchical linear data
R=1000 #number of draws
nreg=2000 #number of observational units
nobs=5 #number of observations per unit
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))
Delta=matrix(c(1,-1,2,0,1,0), ncol = nz) 
tau0=.1
iota=c(rep(1,nobs)) 

## create arguments for rmixture
tcomps=NULL
a = diag(1, nrow=3)
tcomps[[1]] = list(mu=c(-5,0,0),rooti=a) 
tcomps[[2]] = list(mu=c(5, -5, 2),rooti=a)
tcomps[[3]] = list(mu=c(5,5,-2),rooti=a)
tpvec = c(.33,.33,.34)                               
ncomp=length(tcomps)
regdata=NULL
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 
for (reg in 1:nreg) { 
  tempout=bayesm::rmixture(1,tpvec,tcomps)
  if (is.null(Z)){
    betas[reg,]= as.vector(tempout$x)  
  }else{
    betas[reg,]=Delta%*%Z[reg,]+as.vector(tempout$x)} 
  tind[reg]=tempout$z
  X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
  tau=tau0*runif(1,min=0.5,max=1) 
  y=X%*%betas[reg,]+sqrt(tau)*rnorm(nobs)
  regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau) 
}

Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep)
Data1=list(list(regdata=regdata,Z=Z))

length(Data1)

Data2 = partition_data(Data1, s = 3)
length(Data2)

</code></pre>

<hr>
<h2 id='rheteroLinearIndepMetrop'>Distributed Independence Metropolis-Hastings Algorithm for Draws From Multivariate Normal Distribution</h2><span id='topic+rheteroLinearIndepMetrop'></span>

<h3>Description</h3>

<p><code>rheteroLinearIndepMetrop</code> implements an Independence Metropolis-Hastings algorithm with a Gibbs sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rheteroLinearIndepMetrop(Data, betadraws, Mcmc, Prior)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rheteroLinearIndepMetrop_+3A_data">Data</code></td>
<td>
<p>A list of data partitions where each partition includes: 'regdata' - A <code class="reqn">nreg</code> size list of multinomial regdata, and optional 'Z'- <code class="reqn">nreg \times nz</code> matrix of unit characteristics.</p>
</td></tr>
<tr><td><code id="rheteroLinearIndepMetrop_+3A_betadraws">betadraws</code></td>
<td>
<p>A list of betadraws returned from either <code>rhierLinearMixtureParallel</code> or <code>rhierLinearDPParallel</code></p>
</td></tr>
<tr><td><code id="rheteroLinearIndepMetrop_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R'-number of iterations, and optional parameters: 'keep' and 'nprint'.</p>
</td></tr>
<tr><td><code id="rheteroLinearIndepMetrop_+3A_prior">Prior</code></td>
<td>
<p>A list with one required parameter: 'ncomp', and optional parameters: 'deltabar', 'Ad', 'mubar', 'Amu', 'nu', 'V', 'nu.e', and 'ssq'.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Model and Priors</h4>

<p><code>nreg</code> regression equations with <code>nvar</code> as the number of <code class="reqn">X</code> vars in each equation <br />
<code class="reqn">y_i = X_i\beta_i + e_i</code> with <code class="reqn">e_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \tau_i)</code>
</p>
<p><code class="reqn">\tau_i</code> <code class="reqn">\sim</code> <code class="reqn">nu.e*ssq_i/\chi^2_{nu.e}</code> where  <code class="reqn">\tau_i</code> is the variance of <code class="reqn">e_i</code><br />
<code class="reqn">B = Z\Delta + U</code> or <code class="reqn">\beta_i = \Delta' Z[i,]' + u_i</code> <br />
<code class="reqn">\Delta</code> is an <code class="reqn">nz \times nvar</code> matrix <br />
</p>
<p><code class="reqn">u_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_{ind}, \Sigma_{ind})</code><br />
</p>
<p><code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br />
<code class="reqn">\mu_j</code> <code class="reqn">\sim</code> <code class="reqn">N(mubar, \Sigma_j(x) Amu^{-1})</code><br />
<code class="reqn">\Sigma_j</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, V)</code> <br />
</p>
<p><code class="reqn">\theta_i = (\mu_i, \Sigma_i)</code> <code class="reqn">\sim</code> <code class="reqn">DP(G_0(\lambda), alpha)</code><br />
</p>
<p><code class="reqn">G_0(\lambda):</code><br />
<code class="reqn">\mu_i | \Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \Sigma_i (x) a^{-1})</code><br />
<code class="reqn">\Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, nu*v*I)</code><br />
<code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br />
</p>
<p><code class="reqn">\lambda(a, nu, v):</code><br />
<code class="reqn">a</code> <code class="reqn">\sim</code> uniform[alim[1], alimb[2]]<br />
<code class="reqn">nu</code> <code class="reqn">\sim</code>  dim(data)-1 + exp(z) <br />
<code class="reqn">z</code> <code class="reqn">\sim</code>  uniform[dim(data)-1+nulim[1], nulim[2]]<br />
<code class="reqn">v</code> <code class="reqn">\sim</code> uniform[vlim[1], vlim[2]]
</p>
<p><code class="reqn">Z</code> should <em>not</em> include an intercept and should be centered for ease of interpretation. 
The mean of each of the <code>nreg</code> <code class="reqn">\beta</code>s is the mean of the normal mixture. 
Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.
</p>
<p>The prior on <code class="reqn">\Sigma_i</code> is parameterized such that <code class="reqn">mode(\Sigma) = nu/(nu+2) vI</code>. The support of nu enforces a non-degenerate IW density; <code class="reqn">nulim[1] &gt; 0</code>
</p>
<p>The default choices of alim, nulim, and vlim determine the location and approximate size of candidate &quot;atoms&quot; or possible normal components. The defaults are sensible given a reasonable scaling of the X variables. You want to insure that alim is set for a wide enough range of values (remember a is a precision parameter) and the v is big enough to propose Sigma matrices wide enough to cover the data range.
</p>
<p>A careful analyst should look at the posterior distribution of a, nu, v to make sure that the support is set correctly in alim, nulim, vlim. In other words, if we see the posterior bunched up at one end of these support ranges, we should widen the range and rerun.
</p>
<p>If you want to force the procedure to use many small atoms, then set nulim to consider only large values and set vlim to consider only small scaling constants. Set alphamax to a large number. This will create a very &quot;lumpy&quot; density estimate somewhat like the classical Kernel density estimates. Of course, this is not advised if you have a prior belief that densities are relatively smooth.
</p>



<h4>Argument Details</h4>

<p><em><code>Data  = list(regdata, Z)</code> [<code>Z</code> optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>regdata:        </code> </td><td style="text-align: left;"> A <code class="reqn">nreg/s_shard</code> size list of regdata </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>regdata[[i]]$X: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times nvar</code> design matrix for equation <code class="reqn">i</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>regdata[[i]]$y: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times 1</code> vector of observations for equation <code class="reqn">i</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Z:              </code> </td><td style="text-align: left;"> A list of s partitions where each partition include <code class="reqn">(nreg/s_shard) \times nz</code> matrix of unit characteristics 
    </td>
</tr>

</table>

<p><em><code>betadraw:</code></em> A matrix with <code class="reqn">R</code> rows and <code class="reqn">nvar</code> columns of beta draws.
</p>
<p><em><code>Prior = list(deltabar, Ad, Prioralphalist, lambda_hyper, nu, V, nu_e, mubar, Amu, ssq, ncomp)</code> [all but <code>ncomp</code> are optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>deltabar:       </code> </td><td style="text-align: left;"> <code class="reqn">(nz \times nvar) \times 1</code> vector of prior means (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Ad:             </code> </td><td style="text-align: left;"> prior precision matrix for vec(D) (def: 0.01*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>mubar:          </code> </td><td style="text-align: left;"> <code class="reqn">nvar \times 1</code> prior mean vector for normal component mean (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Amu:            </code> </td><td style="text-align: left;"> prior precision for normal component mean (def: 0.01) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>nu.e:             </code> </td><td style="text-align: left;"> d.f. parameter for regression error variance prior (def: 3) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>V:              </code> </td><td style="text-align: left;"> PDS location parameter for IW prior on normal component Sigma (def: nu*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>ssq:            </code> </td><td style="text-align: left;"> scale parameter for regression error variance prior (def: <code>var(y_i)</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>ncomp:          </code> </td><td style="text-align: left;"> number of components used in normal mixture </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>

<p><em><code>Mcmc  = list(R, keep, nprint)</code> [only <code>R</code> required]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>R:              </code> </td><td style="text-align: left;"> number of MCMC draws </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>keep:           </code> </td><td style="text-align: left;"> MCMC thinning parameter -- keep every <code>keep</code>th draw (def: 1) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>nprint:         </code> </td><td style="text-align: left;"> print the estimated time remaining for every <code>nprint</code>'th draw (def: 100, set to 0 for no print) </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>
 



<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><strong>betadraw</strong>: A matrix of size <code class="reqn">R \times nvar</code> containing the drawn <code>beta</code> values from the Gibbs sampling procedure.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rhierLinearMixtureParallel">rhierLinearMixtureParallel</a></code>,
<code><a href="#topic+rheteroMnlIndepMetrop">rheteroMnlIndepMetrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
######### Single Component with rhierLinearMixtureParallel########
R = 500

set.seed(66)
nreg=1000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))

Delta=matrix(c(1,-1,2,0,1,0),ncol=nz)
tau0=.1
iota=c(rep(1,nobs)) 

#Default
tcomps=NULL
a=matrix(c(1,0,0,0.5773503,1.1547005,0,-0.4082483,0.4082483,1.2247449),ncol=3) 
tcomps[[1]]=list(mu=c(0,-1,-2),rooti=a) 
tpvec=c(1)                               

regdata=NULL						  
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) {
 tempout=bayesm::rmixture(1,tpvec,tcomps) 
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta %*% Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X %*% betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau)
}


Data1=list(list(regdata=regdata,Z=Z))
s = 1
Data2=scalablebayesm::partition_data(Data1,s=s)

Prior1=list(ncomp=1)
Mcmc1=list(R=R,keep=1)

set.seed(1)
out2 = parallel::mclapply(Data2, FUN = rhierLinearMixtureParallel, 
Prior = Prior1, Mcmc = Mcmc1,
mc.cores = s, mc.set.seed = FALSE)

betadraws = parallel::mclapply(out2,FUN=drawPosteriorParallel,Z=Z, 
Prior = Prior1, Mcmc = Mcmc1, mc.cores=s,mc.set.seed = FALSE)
betadraws = combine_draws(betadraws, R)

out_indep = parallel::mclapply(Data2, FUN=rheteroLinearIndepMetrop, 
betadraws = betadraws, Mcmc = Mcmc1, Prior = Prior1, mc.cores = s, mc.set.seed = FALSE)


######### Multiple Components with rhierLinearMixtureParallel########
R = 500

set.seed(66)
nreg=1000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))

Delta=matrix(c(1,-1,2,0,1,0),ncol=nz)
tau0=.1
iota=c(rep(1,nobs)) 

#Default
tcomps=NULL
a=matrix(c(1,0,0,0.5773503,1.1547005,0,-0.4082483,0.4082483,1.2247449),ncol=3) 
tcomps[[1]]=list(mu=c(0,-1,-2),rooti=a) 
tcomps[[2]]=list(mu=c(0,-1,-2)*2,rooti=a)
tcomps[[3]]=list(mu=c(0,-1,-2)*4,rooti=a)
tpvec=c(.4,.2,.4)                                   

regdata=NULL						  
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) {
 tempout=bayesm::rmixture(1,tpvec,tcomps) 
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta %*% Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X %*% betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau)
}


Data1=list(list(regdata=regdata,Z=Z))
s = 1
Data2=scalablebayesm::partition_data(Data1, s=s)

Prior1=list(ncomp=3)
Mcmc1=list(R=R,keep=1)

set.seed(1)
out2 = parallel::mclapply(Data2, FUN = rhierLinearMixtureParallel, Prior = Prior1, Mcmc = Mcmc1,
mc.cores = s, mc.set.seed = FALSE)

betadraws = parallel::mclapply(out2,FUN=drawPosteriorParallel,Z=Z, 
Prior = Prior1, Mcmc = Mcmc1, mc.cores=s,mc.set.seed = TRUE)
betadraws = combine_draws(betadraws, R)

out_indep = parallel::mclapply(Data2, FUN=rheteroLinearIndepMetrop, 
betadraws = betadraws, Mcmc = Mcmc1, Prior = Prior1, mc.cores = s, mc.set.seed = TRUE)



</code></pre>

<hr>
<h2 id='rheteroMnlIndepMetrop'>Independence Metropolis-Hastings Algorithm for Draws From Multinomial Distribution</h2><span id='topic+rheteroMnlIndepMetrop'></span>

<h3>Description</h3>

<p><code>rheteroMnlIndepMetrop</code> implements an Independence Metropolis algorithm with a Gibbs sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rheteroMnlIndepMetrop(Data, draws, Mcmc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rheteroMnlIndepMetrop_+3A_data">Data</code></td>
<td>
<p>A list of s partitions where each partition includes: 'p'- number of choice alternatives, 'lgtdata' - An <code class="reqn">nlgt</code> size list of multinomial logistic data, and optional 'Z'- matrix of unit characteristics.</p>
</td></tr>
<tr><td><code id="rheteroMnlIndepMetrop_+3A_draws">draws</code></td>
<td>
<p>A list of draws returned from either <code>rhierMnlRwMixtureParallel</code>.</p>
</td></tr>
<tr><td><code id="rheteroMnlIndepMetrop_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R'-number of iterations, and optional parameters: 'keep' and 'nprint'.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Model and Priors</h4>

<p><code class="reqn">y_i</code> <code class="reqn">\sim</code> <code class="reqn">MNL(X_i,\beta_i)</code> with <code class="reqn">i = 1, \ldots,</code> length(lgtdata) 
and where <code class="reqn">\beta_i</code> is <code class="reqn">1 \times nvar</code>
</p>
<p><code class="reqn">\beta_i</code> = <code class="reqn">Z\Delta</code>[i,] + <code class="reqn">u_i</code> <br />
Note:  Z<code class="reqn">\Delta</code> is the matrix Z <code class="reqn"> \times \Delta</code> and [i,] refers to <code class="reqn">i</code>th row of this product <br />
Delta is an <code class="reqn">nz \times nvar</code> array 
</p>
<p><code class="reqn">u_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_{ind},\Sigma_{ind})</code> with <code class="reqn">ind</code> <code class="reqn">\sim</code> multinomial(pvec)
</p>
<p><code class="reqn">pvec</code>                <code class="reqn">\sim</code> dirichlet(a) <br />
<code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code> <br />
<code class="reqn">\mu_j</code>               <code class="reqn">\sim</code> <code class="reqn">N(mubar, \Sigma_j (x) Amu^{-1})</code> <br />
<code class="reqn">\Sigma_j</code>            <code class="reqn">\sim</code> <code class="reqn">IW(nu, V)</code>
</p>
<p>Note: <code class="reqn">Z</code> should NOT include an intercept and is centered for ease of interpretation. 
The mean of each of the <code>nlgt</code> <code class="reqn">\beta</code>s is the mean of the normal mixture. 
Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.<br />
</p>
<p>Be careful in assessing prior parameter <code>Amu</code>: 0.01 is too small for many applications. 
See chapter 5 of Rossi et al for full discussion.
</p>



<h4>Argument Details</h4>

<p><em><code>Data  = list(lgtdata, Z, p)</code> [<code>Z</code> optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>lgtdata:        </code> </td><td style="text-align: left;"> A <code class="reqn">nlgt/shards</code> size list of multinominal lgtdata </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>lgtdata[[i]]$y: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times 1</code> vector of multinomial outcomes (1, ..., p) for <code class="reqn">i</code>th unit</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>lgtdata[[i]]$X: </code> </td><td style="text-align: left;"> <code class="reqn">(n_i \times p) \times nvar</code> design matrix for <code class="reqn">i</code>th unit </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Z:              </code> </td><td style="text-align: left;"> A list of s partitions where each partition include <code class="reqn">(nlgt/number of shards) \times nz</code> matrix of unit characteristics</td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code>p:              </code> </td><td style="text-align: left;"> number of choice alternatives 
</td>
</tr>

</table>

<p><em><code>draws:</code></em> A matrix with <code class="reqn">R</code> rows and <code class="reqn">nlgt</code> columns of beta draws.
</p>
<p><em><code>Mcmc  = list(R, keep, nprint, s, w)</code> [only <code>R</code> required]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>R:              </code> </td><td style="text-align: left;"> number of MCMC draws </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>keep:           </code> </td><td style="text-align: left;"> MCMC thinning parameter -- keep every <code>keep</code>th draw (def: 1) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nprint:         </code> </td><td style="text-align: left;"> print the estimated time remaining for every <code>nprint</code>'th draw (def: 100, set to 0 for no print) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>s:              </code> </td><td style="text-align: left;"> scaling parameter for RW Metropolis (def: 2.93/<code>sqrt(nvar)</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>w:              </code> </td><td style="text-align: left;"> fractional likelihood weighting parameter (def: 0.1)
</td>
</tr>

</table>




<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><strong>betadraw</strong>: A matrix of size <code class="reqn">R \times nvar</code> containing the drawn <code>beta</code> values from the Gibbs sampling procedure.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rhierMnlRwMixtureParallel">rhierMnlRwMixtureParallel</a></code>,
<code><a href="#topic+rheteroLinearIndepMetrop">rheteroLinearIndepMetrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

R = 500

######### Single Component with rhierMnlRwMixtureParallel########
##parameters
p=3 # num of choice alterns                            
ncoef=3  
nlgt=1000                          
nz=2
Z=matrix(runif(nz*nlgt),ncol=nz)
Z=t(t(Z)-apply(Z,2,mean)) # demean Z

ncomp=1 # no of mixture components
Delta=matrix(c(1,0,1,0,1,2),ncol=2)
comps=NULL
comps[[1]]=list(mu=c(0,2,1),rooti=diag(rep(1,3)))
pvec=c(1)

simmnlwX= function(n,X,beta){
  k=length(beta)
  Xbeta=X %*% beta
  j=nrow(Xbeta)/n
  Xbeta=matrix(Xbeta,byrow=TRUE,ncol=j)
  Prob=exp(Xbeta)
  iota=c(rep(1,j))
  denom=Prob %*% iota
  Prob=Prob/as.vector(denom)
  y=vector("double",n)
  ind=1:j
  for (i in 1:n) { 
    yvec = rmultinom(1, 1, Prob[i,])
    y[i] = ind%*%yvec
  }
  return(list(y=y,X=X,beta=beta,prob=Prob))
}

## simulate data
simlgtdata=NULL
ni=rep(5,nlgt) 
for (i in 1:nlgt) 
{
  if (is.null(Z))
  {
    betai=as.vector(bayesm::rmixture(1,pvec,comps)$x)
  } else {
    betai=Delta %*% Z[i,]+as.vector(bayesm::rmixture(1,pvec,comps)$x)
  }
  Xa=matrix(runif(ni[i]*p,min=-1.5,max=0),ncol=p)
  X=bayesm::createX(p,na=1,nd=NULL,Xa=Xa,Xd=NULL,base=1)
  outa=simmnlwX(ni[i],X,betai)
  simlgtdata[[i]]=list(y=outa$y,X=X,beta=betai)
}

## set MCMC parameters
Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep) 
Data1=list(list(p=p,lgtdata=simlgtdata,Z=Z))
s = 1
Data2 = partition_data(Data1, s=s)

out2 = parallel::mclapply(Data2, FUN = rhierMnlRwMixtureParallel, Prior = Prior1,
Mcmc = Mcmc1,mc.cores = s, mc.set.seed = FALSE)

betadraws = parallel::mclapply(out2,FUN=drawPosteriorParallel,Z=Z, 
Prior = Prior1, Mcmc = Mcmc1, mc.cores=s,mc.set.seed = FALSE)
betadraws = combine_draws(betadraws, R)

out_indep = parallel::mclapply(Data2, FUN=rheteroMnlIndepMetrop, draws = betadraws, 
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)


######### Multiple Components with rhierMnlRwMixtureParallel########
##parameters
R=500
p=3 # num of choice alterns                            
ncoef=3  
nlgt=1000  # num of cross sectional units                         
nz=2
Z=matrix(runif(nz*nlgt),ncol=nz)
Z=t(t(Z)-apply(Z,2,mean)) # demean Z

ncomp=3
Delta=matrix(c(1,0,1,0,1,2),ncol=2) 

comps=NULL 
comps[[1]]=list(mu=c(0,2,1),rooti=diag(rep(1,3)))
comps[[2]]=list(mu=c(1,0,2),rooti=diag(rep(1,3)))
comps[[3]]=list(mu=c(2,1,0),rooti=diag(rep(1,3)))
pvec=c(.4,.2,.4)

simmnlwX= function(n,X,beta) {
  k=length(beta)
  Xbeta=X %*% beta
  j=nrow(Xbeta)/n
  Xbeta=matrix(Xbeta,byrow=TRUE,ncol=j)
  Prob=exp(Xbeta)
  iota=c(rep(1,j))
  denom=Prob %*% iota
  Prob=Prob/as.vector(denom)
  y=vector("double",n)
  ind=1:j
  for (i in 1:n) 
  {yvec=rmultinom(1,1,Prob[i,]); y[i]=ind %*% yvec}
  return(list(y=y,X=X,beta=beta,prob=Prob))
}

## simulate data
simlgtdata=NULL
ni=rep(5,nlgt) 
for (i in 1:nlgt) 
{
  if (is.null(Z))
  {
    betai=as.vector(bayesm::rmixture(1,pvec,comps)$x)
  } else {
    betai=Delta %*% Z[i,]+as.vector(bayesm::rmixture(1,pvec,comps)$x)
  }
  Xa=matrix(runif(ni[i]*p,min=-1.5,max=0),ncol=p)
  X=bayesm::createX(p,na=1,nd=NULL,Xa=Xa,Xd=NULL,base=1)
  outa=simmnlwX(ni[i],X,betai) 
  simlgtdata[[i]]=list(y=outa$y,X=X,beta=betai)
}

## set parameters for priors and Z
Prior1=list(ncomp=ncomp) 
keep = 1
Mcmc1=list(R=R,keep=keep) 
Data1=list(list(p=p,lgtdata=simlgtdata,Z=Z))
s = 1
Data2 = partition_data(Data1,s)

out2 = parallel::mclapply(Data2, FUN = rhierMnlRwMixtureParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

betadraws = parallel::mclapply(out2,FUN=drawPosteriorParallel,Z=Z, 
Prior = Prior1, Mcmc = Mcmc1, mc.cores=s,mc.set.seed = FALSE)
betadraws = combine_draws(betadraws, R)

out_indep = parallel::mclapply(Data2, FUN=rheteroMnlIndepMetrop, draws = betadraws, 
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

</code></pre>

<hr>
<h2 id='rhierLinearDPParallel'>MCMC Algorithm for Hierarchical Linear Model with Dirichlet Process Prior Heterogeneity</h2><span id='topic+rhierLinearDPParallel'></span>

<h3>Description</h3>

<p><code>rhierLinearDPParallel</code> is an MCMC algorithm for a hierarchical linear model with a Dirichlet Process prior for the distribution of heterogeneity. A base normal model is used so that the DP can be interpreted as allowing for a mixture of normals with as many components as panel units. The function implements a Gibbs sampler on the coefficients for each panel unit. This procedure can be interpreted as a Bayesian semi-parametric method since the DP prior accommodates heterogeneity of unknown form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhierLinearDPParallel(Data, Prior, Mcmc, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhierLinearDPParallel_+3A_data">Data</code></td>
<td>
<p>A list of: 'regdata' - A <code class="reqn">nreg</code> size list of regdata, and optional 'Z'- <code class="reqn">nreg \times nz</code> matrix of unit characteristics.</p>
</td></tr>
<tr><td><code id="rhierLinearDPParallel_+3A_prior">Prior</code></td>
<td>
<p>A list with one required parameter: 'ncomp', and optional parameters: 'deltabar', 'Ad', 'mubar', 'Amu', 'nu', 'V', 'nu.e', and 'ssq'.</p>
</td></tr>
<tr><td><code id="rhierLinearDPParallel_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R'-number of iterations, and optional parameters: 'keep' and 'nprint'.</p>
</td></tr>
<tr><td><code id="rhierLinearDPParallel_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, enumerates model parameters and timing information.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Model and Priors</h4>

<p><code>nreg</code> regression equations with <code>nvar</code> as the number of <code class="reqn">X</code> vars in each equation <br />
<code class="reqn">y_i = X_i\beta_i + e_i</code> with <code class="reqn">e_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \tau_i)</code>
</p>
<p><code class="reqn">\tau_i</code> <code class="reqn">\sim</code> <code class="reqn">nu.e*ssq_i/\chi^2_{nu.e}</code> where  <code class="reqn">\tau_i</code> is the variance of <code class="reqn">e_i</code><br />
<code class="reqn">B = Z\Delta + U</code> or <code class="reqn">\beta_i = \Delta' Z[i,]' + u_i</code> <br />
<code class="reqn">\Delta</code> is an <code class="reqn">nz \times nvar</code> matrix <br />
</p>
<p><code class="reqn">u_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_{ind}, \Sigma_{ind})</code><br />
</p>
<p><code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br />
<code class="reqn">\mu_j</code> <code class="reqn">\sim</code> <code class="reqn">N(mubar, \Sigma_j(x) Amu^{-1})</code><br />
<code class="reqn">\Sigma_j</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, V)</code> <br />
</p>
<p><code class="reqn">\theta_i = (\mu_i, \Sigma_i)</code> <code class="reqn">\sim</code> <code class="reqn">DP(G_0(\lambda), alpha)</code><br />
</p>
<p><code class="reqn">G_0(\lambda):</code><br />
<code class="reqn">\mu_i | \Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \Sigma_i (x) a^{-1})</code><br />
<code class="reqn">\Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, nu*v*I)</code><br />
<code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br />
</p>
<p><code class="reqn">\lambda(a, nu, v):</code><br />
<code class="reqn">a</code> <code class="reqn">\sim</code> uniform[alim[1], alimb[2]]<br />
<code class="reqn">nu</code> <code class="reqn">\sim</code>  dim(data)-1 + exp(z) <br />
<code class="reqn">z</code> <code class="reqn">\sim</code>  uniform[dim(data)-1+nulim[1], nulim[2]]<br />
<code class="reqn">v</code> <code class="reqn">\sim</code> uniform[vlim[1], vlim[2]]
</p>
<p><code class="reqn">Z</code> should <em>not</em> include an intercept and should be centered for ease of interpretation. 
The mean of each of the <code>nreg</code> <code class="reqn">\beta</code>s is the mean of the normal mixture. 
Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.
</p>
<p>The prior on <code class="reqn">\Sigma_i</code> is parameterized such that <code class="reqn">mode(\Sigma) = nu/(nu+2) vI</code>. The support of nu enforces a non-degenerate IW density; <code class="reqn">nulim[1] &gt; 0</code>
</p>
<p>The default choices of alim, nulim, and vlim determine the location and approximate size of candidate &quot;atoms&quot; or possible normal components. The defaults are sensible given a reasonable scaling of the X variables. You want to insure that alim is set for a wide enough range of values (remember a is a precision parameter) and the v is big enough to propose Sigma matrices wide enough to cover the data range.
</p>
<p>A careful analyst should look at the posterior distribution of a, nu, v to make sure that the support is set correctly in alim, nulim, vlim. In other words, if we see the posterior bunched up at one end of these support ranges, we should widen the range and rerun.
</p>
<p>If you want to force the procedure to use many small atoms, then set nulim to consider only large values and set vlim to consider only small scaling constants. Set alphamax to a large number. This will create a very &quot;lumpy&quot; density estimate somewhat like the classical Kernel density estimates. Of course, this is not advised if you have a prior belief that densities are relatively smooth.
</p>



<h4>Argument Details</h4>

<p><em><code>Data  = list(regdata, Z)</code> [<code>Z</code> optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>regdata:        </code> </td><td style="text-align: left;"> A <code class="reqn">nreg/s_shard</code> size list of regdata </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>regdata[[i]]$X: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times nvar</code> design matrix for equation <code class="reqn">i</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>regdata[[i]]$y: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times 1</code> vector of observations for equation <code class="reqn">i</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Z:              </code> </td><td style="text-align: left;"> A list of s partitions where each partition include <code class="reqn">(nreg/s_shard) \times nz</code> matrix of unit characteristics 
    </td>
</tr>

</table>

<p><em><code>Prior = list(deltabar, Ad, Prioralphalist, lambda_hyper, nu, V, nu_e, mubar, Amu, ssq, ncomp)</code> [all but <code>ncomp</code> are optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>deltabar:       </code> </td><td style="text-align: left;"> <code class="reqn">(nz \times nvar) \times 1</code> vector of prior means (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Ad:             </code> </td><td style="text-align: left;"> prior precision matrix for vec(D) (def: 0.01*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>mubar:          </code> </td><td style="text-align: left;"> <code class="reqn">nvar \times 1</code> prior mean vector for normal component mean (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Amu:            </code> </td><td style="text-align: left;"> prior precision for normal component mean (def: 0.01) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>nu.e:             </code> </td><td style="text-align: left;"> d.f. parameter for regression error variance prior (def: 3) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>V:              </code> </td><td style="text-align: left;"> PDS location parameter for IW prior on normal component Sigma (def: nu*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>ssq:            </code> </td><td style="text-align: left;"> scale parameter for regression error variance prior (def: <code>var(y_i)</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>ncomp:          </code> </td><td style="text-align: left;"> number of components used in normal mixture </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>

<p><em><code>Mcmc  = list(R, keep, nprint)</code> [only <code>R</code> required]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>R:              </code> </td><td style="text-align: left;"> number of MCMC draws </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>keep:           </code> </td><td style="text-align: left;"> MCMC thinning parameter -- keep every <code>keep</code>th draw (def: 1) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>nprint:         </code> </td><td style="text-align: left;"> print the estimated time remaining for every <code>nprint</code>'th draw (def: 100, set to 0 for no print) </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>
 



<h3>Value</h3>

<p>A list containing: 
</p>
<table role = "presentation">
<tr><td><code>compdraw</code></td>
<td>
<p>A list (length: R/keep) where each list contains 'mu' (vector, length: 'ncomp') and 'rooti' (matrix, shape: ncomp <code class="reqn">\times</code> ncomp)</p>
</td></tr>
<tr><td><code>probdraw</code></td>
<td>
<p>A <code class="reqn">(R/keep) \times (ncomp)</code> matrix that reports the probability that each draw came from a particular component</p>
</td></tr>
<tr><td><code>Deltadraw</code></td>
<td>
<p>A <code class="reqn">(R/keep) \times (nz \times nvar)</code> matrix of draws of Delta, first row is initial value. Deltadraw is NULL if Z is NULL</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, Federico (Rico), Sanjog Misra, and Peter E. Rossi (2020), &quot;Scalable Target Marketing:
Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models&quot;, Journal of Marketing
Research, 57(6), 999-1018.
</p>
<p>Chapter 5, <em>Bayesian Statistics and Marketing</em> by Rossi, Allenby, and McCulloch.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partition_data">partition_data</a></code>, 
<code><a href="#topic+drawPosteriorParallel">drawPosteriorParallel</a></code>, 
<code><a href="#topic+combine_draws">combine_draws</a></code>, 
<code><a href="#topic+rheteroLinearIndepMetrop">rheteroLinearIndepMetrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

######### Single Component with rhierLinearDPParallel########
R = 1000

nreg = 2000
nobs = 5 #number of observations
nvar = 3 #columns
nz = 2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))

Delta=matrix(c(1,-1,2,0,1,0),ncol=nz)
tau0=.1
iota=c(rep(1,nobs)) 

#Default
tcomps=NULL
a=matrix(c(1,0,0,0.5773503,1.1547005,0,-0.4082483,0.4082483,1.2247449),ncol=3) 
tcomps[[1]]=list(mu=c(0,-1,-2),rooti=a) 
tpvec=c(1)                               

regdata=NULL						  
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) {
 tempout=bayesm::rmixture(1,tpvec,tcomps) 
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta %*% Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X %*% betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau)
}


Data1=list(list(regdata=regdata,Z=Z))
s = 1
Data2=scalablebayesm::partition_data(Data1,s=s)

Prior1=list(ncomp=1)
Mcmc1=list(R=R,keep=1)

out2 = parallel::mclapply(Data2, FUN = rhierLinearDPParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

######### Multiple Components with rhierLinearDPParallel########
R = 1000

set.seed(66)
nreg=2000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))

Delta=matrix(c(1,-1,2,0,1,0),ncol=nz)
tau0=.1
iota=c(rep(1,nobs)) 

#Default
tcomps=NULL
a=matrix(c(1,0,0,0.5773503,1.1547005,0,-0.4082483,0.4082483,1.2247449),ncol=3) 
tcomps[[1]]=list(mu=c(0,-1,-2),rooti=a) 
tcomps[[2]]=list(mu=c(0,-1,-2)*2,rooti=a)
tcomps[[3]]=list(mu=c(0,-1,-2)*4,rooti=a)
tpvec=c(.4,.2,.4)                                   

regdata=NULL						  
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) {
 tempout=bayesm::rmixture(1,tpvec,tcomps) 
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta %*% Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X %*% betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau)
}


Data1=list(list(regdata=regdata,Z=Z))
s = 1
Data2=scalablebayesm::partition_data(Data1, s=s)

Prior1=list(ncomp=3)
Mcmc1=list(R=R,keep=1)

out2 = parallel::mclapply(Data2, FUN = rhierLinearDPParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

</code></pre>

<hr>
<h2 id='rhierLinearMixtureParallel'>MCMC Algorithm for Hierarchical Multinomial Linear Model with Mixture-of-Normals Heterogeneity</h2><span id='topic+rhierLinearMixtureParallel'></span>

<h3>Description</h3>

<p><code>rhierLinearMixtureParallel</code> implements a MCMC algorithm for hierarchical linear model with a mixture of normals heterogeneity distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhierLinearMixtureParallel(Data, Prior, Mcmc, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhierLinearMixtureParallel_+3A_data">Data</code></td>
<td>
<p>A list containing: 'regdata' - A <code class="reqn">nreg</code> size list of multinomial regdata, and optional 'Z'- <code class="reqn">nreg \times nz</code> matrix of unit characteristics.</p>
</td></tr>
<tr><td><code id="rhierLinearMixtureParallel_+3A_prior">Prior</code></td>
<td>
<p>A list with one required parameter: 'ncomp', and optional parameters: 'deltabar', 'Ad', 'mubar', 'Amu', 'nu', 'V', 'nu.e', and 'ssq'.</p>
</td></tr>
<tr><td><code id="rhierLinearMixtureParallel_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R'-number of iterations, and optional parameters: 'keep' and 'nprint'.</p>
</td></tr>
<tr><td><code id="rhierLinearMixtureParallel_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, enumerates model parameters and timing information.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Model and Priors</h4>

<p><code>nreg</code> regression equations with <code>nvar</code> as the number of <code class="reqn">X</code> vars in each equation <br />
<code class="reqn">y_i = X_i\beta_i + e_i</code> with <code class="reqn">e_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \tau_i)</code>  
</p>
<p><code class="reqn">\tau_i</code> <code class="reqn">\sim</code> <code class="reqn">nu.e*ssq_i/\chi^2_{nu.e}</code> where  <code class="reqn">\tau_i</code> is the variance of <code class="reqn">e_i</code><br />
<code class="reqn">B = Z\Delta + U</code> or <code class="reqn">\beta_i = \Delta' Z[i,]' + u_i</code> <br />
<code class="reqn">\Delta</code> is an <code class="reqn">nz \times nvar</code> matrix <br />
</p>
<p><code class="reqn">Z</code> should <em>not</em> include an intercept and should be centered for ease of interpretation. 
The mean of each of the <code>nreg</code> <code class="reqn">\beta</code>s is the mean of the normal mixture. 
Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.
</p>
<p><code class="reqn">u_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_{ind}, \Sigma_{ind})</code><br />
<code class="reqn">ind</code> <code class="reqn">\sim</code> <code class="reqn">multinomial(pvec)</code> <br />
</p>
<p><code class="reqn">pvec</code> <code class="reqn">\sim</code> <code class="reqn">dirichlet(a)</code><br />
<code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br />
<code class="reqn">\mu_j</code> <code class="reqn">\sim</code> <code class="reqn">N(mubar, \Sigma_j(x) Amu^{-1})</code><br />
<code class="reqn">\Sigma_j</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, V)</code> <br />
</p>
<p>Be careful in assessing the prior parameter <code>Amu</code>: 0.01 can be too small for some applications. 
See chapter 5 of Rossi et al for full discussion.<br />    
</p>



<h4>Argument Details</h4>

<p><em><code>Data  = list(regdata, Z)</code> [<code>Z</code> optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>regdata:        </code> </td><td style="text-align: left;"> A <code class="reqn">nreg</code> size list of regdata </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>regdata[[i]]$X: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times nvar</code> design matrix for equation <code class="reqn">i</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>regdata[[i]]$y: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times 1</code> vector of observations for equation <code class="reqn">i</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Z:              </code> </td><td style="text-align: left;"> An <code class="reqn">(nreg) \times nz</code> matrix of unit characteristics 
    </td>
</tr>

</table>

<p><em><code>Prior = list(deltabar, Ad, mubar, Amu, nu.e, V, ssq, ncomp)</code> [all but <code>ncomp</code> are optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>deltabar:       </code> </td><td style="text-align: left;"> <code class="reqn">(nz \times nvar) \times 1</code> vector of prior means (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Ad:             </code> </td><td style="text-align: left;"> prior precision matrix for vec(D) (def: 0.01*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>mubar:          </code> </td><td style="text-align: left;"> <code class="reqn">nvar \times 1</code> prior mean vector for normal component mean (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>Amu:            </code> </td><td style="text-align: left;"> prior precision for normal component mean (def: 0.01) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>nu.e:             </code> </td><td style="text-align: left;"> d.f. parameter for regression error variance prior (def: 3) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>V:              </code> </td><td style="text-align: left;"> PDS location parameter for IW prior on normal component Sigma (def: nu*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>ssq:            </code> </td><td style="text-align: left;"> scale parameter for regression error variance prior (def: <code>var(y_i)</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>ncomp:          </code> </td><td style="text-align: left;"> number of components used in normal mixture </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>

<p><em><code>Mcmc  = list(R, keep, nprint)</code> [only <code>R</code> required]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>R:              </code> </td><td style="text-align: left;"> number of MCMC draws </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>keep:           </code> </td><td style="text-align: left;"> MCMC thinning parameter -- keep every <code>keep</code>th draw (def: 1) </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>nprint:         </code> </td><td style="text-align: left;"> print the estimated time remaining for every <code>nprint</code>'th draw (def: 100, set to 0 for no print) </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>
 



<h3>Value</h3>

<p>A list of sharded partitions where each partition contains the following: 
</p>
<table role = "presentation">
<tr><td><code>compdraw</code></td>
<td>
<p>A list (length: R/keep) where each list contains 'mu' (vector, length: 'ncomp') and 'rooti' (matrix, shape: ncomp <code class="reqn">\times</code> ncomp)</p>
</td></tr>
<tr><td><code>probdraw</code></td>
<td>
<p>A <code class="reqn">(R/keep) \times (ncomp)</code> matrix that reports the probability that each draw came from a particular component</p>
</td></tr>
<tr><td><code>Deltadraw</code></td>
<td>
<p>A <code class="reqn">(R/keep) \times (nz \times nvar)</code> matrix of draws of Delta, first row is initial value. Deltadraw is NULL if Z is NULL</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, Federico (Rico), Sanjog Misra, and Peter E. Rossi (2020), &quot;Scalable Target Marketing:
Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models&quot;, Journal of Marketing
Research, 57(6), 999-1018.
</p>
<p>Chapter 5, <em>Bayesian Statistics and Marketing</em> by Rossi, Allenby, and McCulloch.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partition_data">partition_data</a></code>, 
<code><a href="#topic+drawPosteriorParallel">drawPosteriorParallel</a></code>, 
<code><a href="#topic+combine_draws">combine_draws</a></code>, 
<code><a href="#topic+rheteroLinearIndepMetrop">rheteroLinearIndepMetrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

######### Single Component with rhierLinearMixtureParallel########
R = 500

nreg=1000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))

Delta=matrix(c(1,-1,2,0,1,0),ncol=nz)
tau0=.1
iota=c(rep(1,nobs)) 

#Default
tcomps=NULL
a=matrix(c(1,0,0,0.5773503,1.1547005,0,-0.4082483,0.4082483,1.2247449),ncol=3) 
tcomps[[1]]=list(mu=c(0,-1,-2),rooti=a) 
tpvec=c(1)                               

regdata=NULL						  
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) {
 tempout=bayesm::rmixture(1,tpvec,tcomps) 
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta %*% Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X %*% betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau)
}


Data1=list(list(regdata=regdata,Z=Z))
s = 1
Data2=scalablebayesm::partition_data(Data1,s=s)

Prior1=list(ncomp=1)
Mcmc1=list(R=R,keep=1)

out2 = parallel::mclapply(Data2, FUN = rhierLinearMixtureParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

######### Multiple Components with rhierLinearMixtureParallel########
R = 500

set.seed(66)
nreg=1000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))

Delta=matrix(c(1,-1,2,0,1,0),ncol=nz)
tau0=.1
iota=c(rep(1,nobs)) 

#Default
tcomps=NULL
a=matrix(c(1,0,0,0.5773503,1.1547005,0,-0.4082483,0.4082483,1.2247449),ncol=3) 
tcomps[[1]]=list(mu=c(0,-1,-2),rooti=a) 
tcomps[[2]]=list(mu=c(0,-1,-2)*2,rooti=a)
tcomps[[3]]=list(mu=c(0,-1,-2)*4,rooti=a)
tpvec=c(.4,.2,.4)                                   

regdata=NULL						  
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 

for (reg in 1:nreg) {
 tempout=bayesm::rmixture(1,tpvec,tcomps) 
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta %*% Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X %*% betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau)
}


Data1=list(list(regdata=regdata,Z=Z))
s = 1
Data2=scalablebayesm::partition_data(Data1, s=s)

Prior1=list(ncomp=3)
Mcmc1=list(R=R,keep=1)

set.seed(1)
out2 = parallel::mclapply(Data2, FUN = rhierLinearMixtureParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

</code></pre>

<hr>
<h2 id='rhierMnlDPParallel'>MCMC Algorithm for Hierarchical Multinomial Logit with Dirichlet Process Prior Heterogeneity</h2><span id='topic+rhierMnlDPParallel'></span>

<h3>Description</h3>

<p><code>rhierMnlDPParallel</code> is an MCMC algorithm for a hierarchical multinomial logit with a Dirichlet Process prior describing the distribution of heteorogeneity. A base normal model is used so that the DP can be interpreted as allowing for a mixture of normals with as many components as panel units. This is a hybrid Gibbs Sampler with a RW Metropolis step for the MNL coefficients for each panel unit. This procedure can be interpreted as a Bayesian semi-parametric method in the sense that the DP prior can accommodate heterogeneity of an unknown form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhierMnlDPParallel(Data, Prior, Mcmc, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhierMnlDPParallel_+3A_data">Data</code></td>
<td>
<p>A list of: 'p'- number of choice alternatives, 'lgtdata' - An <code class="reqn">nlgt</code> size list of multinomial logistic data, and optional 'Z'- matrix of unit characteristics.</p>
</td></tr>
<tr><td><code id="rhierMnlDPParallel_+3A_prior">Prior</code></td>
<td>
<p>A list with one required parameter: 'ncomp', and optional parameters: 'mubar', 'Amu', 'nu', 'V', 'Ad', 'deltaBar', and 'a'.</p>
</td></tr>
<tr><td><code id="rhierMnlDPParallel_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R' - number of iterations, and optional parameters: 's', 'w', 'keep', 'nprint', and 'drawcomp'.</p>
</td></tr>
<tr><td><code id="rhierMnlDPParallel_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, enumerates model parameters and timing information.</p>
</td></tr>
</table>


<h3>Details</h3>




<h4>Model and Priors</h4>

<p><code class="reqn">y_i</code> <code class="reqn">\sim</code> <code class="reqn">MNL(X_i, \beta_i)</code> with <code class="reqn">i = 1, \ldots, length(lgtdata)</code> and where <code class="reqn">\theta_i</code> is <code class="reqn">nvar x 1</code>
</p>
<p><code class="reqn">\beta_i = Z\Delta</code>[i,] + <code class="reqn">u_i</code> <br />
Note:  Z<code class="reqn">\Delta</code> is the matrix <code class="reqn">Z * \Delta</code>; [i,] refers to <code class="reqn">i</code>th row of this product <br />
Delta is an <code class="reqn">nz x nvar</code> matrix 
</p>
<p><code class="reqn">\beta_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_i, \Sigma_i)</code>
</p>
<p><code class="reqn">\theta_i = (\mu_i, \Sigma_i)</code> <code class="reqn">\sim</code> <code class="reqn">DP(G_0(\lambda), alpha)</code><br />
</p>
<p><code class="reqn">G_0(\lambda):</code><br />
<code class="reqn">\mu_i | \Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \Sigma_i (x) a^{-1})</code><br />
<code class="reqn">\Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, nu*v*I)</code><br />
<code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br />
</p>
<p><code class="reqn">\lambda(a, nu, v):</code><br />
<code class="reqn">a</code> <code class="reqn">\sim</code> uniform[alim[1], alimb[2]]<br />
<code class="reqn">nu</code> <code class="reqn">\sim</code>  dim(data)-1 + exp(z) <br />
<code class="reqn">z</code> <code class="reqn">\sim</code>  uniform[dim(data)-1+nulim[1], nulim[2]]<br />
<code class="reqn">v</code> <code class="reqn">\sim</code> uniform[vlim[1], vlim[2]]
</p>
<p><code class="reqn">alpha</code> <code class="reqn">\sim</code> <code class="reqn">(1-(alpha-alphamin) / (alphamax-alphamin))^{power}</code> <br />
alpha = alphamin then expected number of components = <code>Istarmin</code> <br />
alpha = alphamax then expected number of components = <code>Istarmax</code>
</p>
<p><code class="reqn">Z</code> should NOT include an intercept and is centered for ease of interpretation. The mean of each of the <code>nlgt</code> <code class="reqn">\beta</code>s is the mean of the normal mixture.  Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.
</p>
<p>We parameterize the prior on <code class="reqn">\Sigma_i</code> such that <code class="reqn">mode(\Sigma) = nu/(nu+2) vI</code>. The support of nu enforces a non-degenerate IW density; <code class="reqn">nulim[1] &gt; 0</code>.
</p>
<p>The default choices of alim, nulim, and vlim determine the location and approximate size of candidate &quot;atoms&quot; or possible normal components. The defaults are sensible given a reasonable scaling of the X variables. You want to insure that alim is set for a wide enough range of values (remember a is a precision parameter) and the v is big enough to propose Sigma matrices wide enough to cover the data range.  
</p>
<p>A careful analyst should look at the posterior distribution of a, nu, v to make sure that the support is set correctly in alim, nulim, vlim.  In other words, if we see the posterior bunched up at one end of these support ranges, we should widen the range and rerun.  
</p>
<p>If you want to force the procedure to use many small atoms, then set nulim to consider only large values and set vlim to consider only small scaling constants.  Set alphamax to a large number.  This will create a very &quot;lumpy&quot; density estimate somewhat like the classical Kernel density estimates. Of course, this is not advised if you have a prior belief that densities are relatively smooth.
</p>




<h3>Value</h3>

<p>A list containing the following elements:
</p>

<ul>
<li> <p><strong>nmix</strong>: A list with the following components:
</p>

<ul>
<li> <p><strong>probdraw</strong>: A matrix of size <code>(R/keep) x (ncomp</code>, containing the probability draws at each Gibbs iteration.
</p>
</li>
<li> <p><strong>compdraw</strong>: A list containing the drawn mixture components at each Gibbs iteration.</p>
</li></ul>

</li>
<li> <p><strong>Deltadraw</strong> (optional): A matrix of size <code>(R/keep) x (nz * nvar)</code>, containing the delta draws, if <code>Z</code> is not <code>NULL</code>. If <code>Z</code> is <code>NULL</code>, this element is not included.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(66)
R = 500

p = 3                                # num of choice alterns
ncoef = 3  
nlgt = 1000                           # num of cross sectional units
nz = 2
nvar = 3
Z = matrix(runif(nz*nlgt), ncol=nz)
Z = t(t(Z)-apply(Z,2,mean))          # demean Z
ncomp = 3                            # no of mixture components
Delta=matrix(c(1,0,1,0,1,2), ncol=2)

comps = NULL
comps[[1]] = list(mu=c(0,-1,-2),   rooti=diag(rep(2,3)))
comps[[2]] = list(mu=c(0,-1,-2)*2, rooti=diag(rep(2,3)))
comps[[3]] = list(mu=c(0,-1,-2)*4, rooti=diag(rep(2,3)))
pvec=c(0.4, 0.2, 0.4)

##  simulate from MNL model conditional on X matrix
simmnlwX = function(n,X,beta) {
  k = length(beta)
  Xbeta = X%*%beta
  j = nrow(Xbeta) / n
  Xbeta = matrix(Xbeta, byrow=TRUE, ncol=j)
  Prob = exp(Xbeta)
  iota = c(rep(1,j))
  denom = Prob%*%iota
  Prob = Prob / as.vector(denom)
  y = vector("double", n)
  ind = 1:j
  for (i in 1:n) {
    yvec = rmultinom(1, 1, Prob[i,])
    y[i] = ind%*%yvec}
  return(list(y=y, X=X, beta=beta, prob=Prob))
}

## simulate data with a mixture of 3 normals
simlgtdata = NULL
ni = rep(50,nlgt)
for (i in 1:nlgt) {
  betai = Delta%*%Z[i,] + as.vector(bayesm::rmixture(1,pvec,comps)$x)
  Xa = matrix(runif(ni[i]*p,min=-1.5,max=0), ncol=p)
  X = bayesm::createX(p, na=1, nd=NULL, Xa=Xa, Xd=NULL, base=1)
  outa = simmnlwX(ni[i], X, betai)
  simlgtdata[[i]] = list(y=outa$y, X=X, beta=betai)
}

## plot betas

  old.par = par(no.readonly = TRUE)
  bmat = matrix(0, nlgt, ncoef)
  for(i in 1:nlgt) { bmat[i,] = simlgtdata[[i]]$beta }
  par(mfrow = c(ncoef,1))
  for(i in 1:ncoef) { hist(bmat[,i], breaks=30, col="magenta") }
  par(old.par)

## set Data and Mcmc lists
keep = 5
Mcmc1 = list(R=R, keep=keep)
Prior1=list(ncomp=1)
Data1 = list(p=p, lgtdata=simlgtdata, Z=Z)
Data2 = partition_data(Data = list(Data1), s = 1)

out = parallel::mclapply(Data2, FUN = rhierMnlDPParallel,
Prior = Prior1, Mcmc = Mcmc1, mc.cores = 1, mc.set.seed = FALSE)


</code></pre>

<hr>
<h2 id='rhierMnlRwMixtureParallel'>MCMC Algorithm for Hierarchical Multinomial Logit with Mixture-of-Normals Heterogeneity</h2><span id='topic+rhierMnlRwMixtureParallel'></span>

<h3>Description</h3>

<p><code>rhierMnlRwMixtureParallel</code> implements a MCMC algorithm for a hierarchical multinomial logit model with a mixture of normals heterogeneity distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhierMnlRwMixtureParallel(Data, Prior, Mcmc, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhierMnlRwMixtureParallel_+3A_data">Data</code></td>
<td>
<p>A list containing: 'p'- number of choice alternatives, 'lgtdata' - A <code class="reqn">nlgt</code> size list of multinomial logistic data, and optional 'Z'- matrix of unit characteristics.</p>
</td></tr>
<tr><td><code id="rhierMnlRwMixtureParallel_+3A_prior">Prior</code></td>
<td>
<p>A list with one required parameter: 'ncomp', and optional parameters: 'mubar', 'Amu', 'nu', 'V', 'Ad', 'deltaBar', and 'a'.</p>
</td></tr>
<tr><td><code id="rhierMnlRwMixtureParallel_+3A_mcmc">Mcmc</code></td>
<td>
<p>A list with one required parameter: 'R' - number of iterations, and optional parameters: 's', 'w', 'keep', 'nprint', and 'drawcomp'.</p>
</td></tr>
<tr><td><code id="rhierMnlRwMixtureParallel_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, enumerates model parameters and timing information.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Model and Priors</h4>

<p><code class="reqn">y_i</code> <code class="reqn">\sim</code> <code class="reqn">MNL(X_i,\beta_i)</code> with <code class="reqn">i = 1, \ldots,</code> length(lgtdata) 
and where <code class="reqn">\beta_i</code> is <code class="reqn">1 \times nvar</code>
</p>
<p><code class="reqn">\beta_i</code> = <code class="reqn">Z\Delta</code>[i,] + <code class="reqn">u_i</code> <br />
Note:  Z<code class="reqn">\Delta</code> is the matrix Z <code class="reqn"> \times \Delta</code> and [i,] refers to <code class="reqn">i</code>th row of this product <br />
Delta is an <code class="reqn">nz \times nvar</code> array 
</p>
<p><code class="reqn">u_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_{ind},\Sigma_{ind})</code> with <code class="reqn">ind</code> <code class="reqn">\sim</code> multinomial(pvec)
</p>
<p><code class="reqn">pvec</code>                <code class="reqn">\sim</code> dirichlet(a) <br />
<code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code> <br />
<code class="reqn">\mu_j</code>               <code class="reqn">\sim</code> <code class="reqn">N(mubar, \Sigma_j (x) Amu^{-1})</code> <br />
<code class="reqn">\Sigma_j</code>            <code class="reqn">\sim</code> <code class="reqn">IW(nu, V)</code>
</p>
<p>Note: <code class="reqn">Z</code> should NOT include an intercept and is centered for ease of interpretation. 
The mean of each of the <code>nlgt</code> <code class="reqn">\beta</code>s is the mean of the normal mixture. 
Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.<br />
</p>
<p>Be careful in assessing prior parameter <code>Amu</code>: 0.01 is too small for many applications. 
See chapter 5 of Rossi et al for full discussion.
</p>



<h4>Argument Details</h4>

<p><em><code>Data  = list(lgtdata, Z, p)</code> [<code>Z</code> optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>lgtdata:        </code> </td><td style="text-align: left;"> A <code class="reqn">nlgt</code> size list of multinominal lgtdata </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>lgtdata[[i]]$y: </code> </td><td style="text-align: left;"> <code class="reqn">n_i \times 1</code> vector of multinomial outcomes (1, ..., p) for <code class="reqn">i</code>th unit</td>
</tr>
<tr>
 <td style="text-align: left;">
<code>lgtdata[[i]]$X: </code> </td><td style="text-align: left;"> <code class="reqn">(n_i \times p) \times nvar</code> design matrix for <code class="reqn">i</code>th unit </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Z:              </code> </td><td style="text-align: left;"> An <code class="reqn">(nlgt) \times nz</code> matrix of unit characteristics</td>
</tr>
<tr>
 <td style="text-align: left;"> 
<code>p:              </code> </td><td style="text-align: left;"> number of choice alternatives 
</td>
</tr>

</table>

<p><em><code>Prior = list(a, deltabar, Ad, mubar, Amu, nu, V, a, ncomp)</code> [all but <code>ncomp</code> are optional]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>a:              </code> </td><td style="text-align: left;"> <code class="reqn">ncomp \times 1</code> vector of Dirichlet prior parameters (def: <code>rep(5,ncomp)</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>deltabar:       </code> </td><td style="text-align: left;"> <code class="reqn">(nz \times nvar) \times 1</code> vector of prior means (def: 0) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Ad:             </code> </td><td style="text-align: left;"> prior precision matrix for vec(D) (def: 0.01*I) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mubar:          </code> </td><td style="text-align: left;"> <code class="reqn">nvar \times 1</code> prior mean vector for normal component mean (def: 0 if unrestricted; 2 if restricted) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>Amu:            </code> </td><td style="text-align: left;"> prior precision for normal component mean (def: 0.01 if unrestricted; 0.1 if restricted) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nu:             </code> </td><td style="text-align: left;"> d.f. parameter for IW prior on normal component Sigma (def: nvar+3 if unrestricted; nvar+15 if restricted) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>V:              </code> </td><td style="text-align: left;"> PDS location parameter for IW prior on normal component Sigma (def: nu*I if unrestricted; nu*D if restricted with d_pp = 4 if unrestricted and d_pp = 0.01 if restricted) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ncomp:          </code> </td><td style="text-align: left;"> number of components used in normal mixture 
</td>
</tr>

</table>

<p><em><code>Mcmc  = list(R, keep, nprint, s, w)</code> [only <code>R</code> required]</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>R:              </code> </td><td style="text-align: left;"> number of MCMC draws </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>keep:           </code> </td><td style="text-align: left;"> MCMC thinning parameter -- keep every <code>keep</code>th draw (def: 1) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>nprint:         </code> </td><td style="text-align: left;"> print the estimated time remaining for every <code>nprint</code>'th draw (def: 100, set to 0 for no print) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>s:              </code> </td><td style="text-align: left;"> scaling parameter for RW Metropolis (def: 2.93/<code>sqrt(nvar)</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>w:              </code> </td><td style="text-align: left;"> fractional likelihood weighting parameter (def: 0.1)
</td>
</tr>

</table>




<h3>Value</h3>

<p>A list of sharded partitions where each partition contains the following:
</p>
<table role = "presentation">
<tr><td><code>compdraw</code></td>
<td>
<p>A list (length: R/keep) where each list contains 'mu' (vector, length: 'ncomp') and 'rooti' (matrix, shape: ncomp <code class="reqn">\times</code> ncomp)</p>
</td></tr>
<tr><td><code>probdraw</code></td>
<td>
<p>A <code class="reqn">(R/keep) \times (ncomp)</code> matrix that reports the probability that each draw came from a particular component</p>
</td></tr>
<tr><td><code>Deltadraw</code></td>
<td>
<p>A <code class="reqn">(R/keep) \times (nz \times nvar)</code> matrix of draws of Delta, first row is initial value. This could be null if Z is NULL</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, Federico (Rico), Sanjog Misra, and Peter E. Rossi (2020), &quot;Scalable Target Marketing:
Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models&quot;, Journal of Marketing
Research, 57(6), 999-1018.
</p>
<p>Chapter 5, <em>Bayesian Statistics and Marketing</em> by Rossi, Allenby, and McCulloch.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partition_data">partition_data</a></code>, 
<code><a href="#topic+drawPosteriorParallel">drawPosteriorParallel</a></code>, 
<code><a href="#topic+combine_draws">combine_draws</a></code>, 
<code><a href="#topic+rheteroMnlIndepMetrop">rheteroMnlIndepMetrop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


R=500

######### Single Component with rhierMnlRwMixtureParallel########
##parameters
p = 3 # num of choice alterns                            
ncoef = 3  
nlgt = 1000                          
nz = 2
Z = matrix(runif(nz*nlgt),ncol=nz)
Z = t(t(Z)-apply(Z,2,mean)) # demean Z

ncomp = 1 # no of mixture components
Delta = matrix(c(1,0,1,0,1,2),ncol=2)
comps = NULL
comps[[1]] = list(mu=c(0,2,1),rooti=diag(rep(1,3)))
pvec = c(1)

simmnlwX = function(n,X,beta){
  k=length(beta)
  Xbeta=X %*% beta
  j=nrow(Xbeta)/n
  Xbeta=matrix(Xbeta,byrow=TRUE,ncol=j)
  Prob=exp(Xbeta)
  iota=c(rep(1,j))
  denom=Prob %*% iota
  Prob=Prob/as.vector(denom)
  y=vector("double",n)
  ind=1:j
  for (i in 1:n) { 
    yvec = rmultinom(1, 1, Prob[i,])
    y[i] = ind%*%yvec
  }
  return(list(y=y,X=X,beta=beta,prob=Prob))
}

## simulate data
simlgtdata=NULL
ni=rep(5,nlgt) 
for (i in 1:nlgt) 
{
  if (is.null(Z))
  {
    betai=as.vector(bayesm::rmixture(1,pvec,comps)$x)
  } else {
    betai=Delta %*% Z[i,]+as.vector(bayesm::rmixture(1,pvec,comps)$x)
  }
  Xa=matrix(runif(ni[i]*p,min=-1.5,max=0),ncol=p)
  X=bayesm::createX(p,na=1,nd=NULL,Xa=Xa,Xd=NULL,base=1)
  outa=simmnlwX(ni[i],X,betai)
  simlgtdata[[i]]=list(y=outa$y,X=X,beta=betai)
}

## set MCMC parameters
Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep) 
Data1=list(list(p=p,lgtdata=simlgtdata,Z=Z))
s = 1
Data2 = partition_data(Data1, s=s)

out2 = parallel::mclapply(Data2, FUN = rhierMnlRwMixtureParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)

######### Multiple Components with rhierMnlRwMixtureParallel########
##parameters
R = 500
p=3 # num of choice alterns                            
ncoef=3  
nlgt=1000  # num of cross sectional units                         
nz=2
Z=matrix(runif(nz*nlgt),ncol=nz)
Z=t(t(Z)-apply(Z,2,mean)) # demean Z

ncomp=3
Delta=matrix(c(1,0,1,0,1,2),ncol=2) 

comps=NULL 
comps[[1]]=list(mu=c(0,2,1),rooti=diag(rep(1,3)))
comps[[2]]=list(mu=c(1,0,2),rooti=diag(rep(1,3)))
comps[[3]]=list(mu=c(2,1,0),rooti=diag(rep(1,3)))
pvec=c(.4,.2,.4)

simmnlwX= function(n,X,beta) {
  k=length(beta)
  Xbeta=X %*% beta
  j=nrow(Xbeta)/n
  Xbeta=matrix(Xbeta,byrow=TRUE,ncol=j)
  Prob=exp(Xbeta)
  iota=c(rep(1,j))
  denom=Prob %*% iota
  Prob=Prob/as.vector(denom)
  y=vector("double",n)
  ind=1:j
  for (i in 1:n) 
  {yvec=rmultinom(1,1,Prob[i,]); y[i]=ind %*% yvec}
  return(list(y=y,X=X,beta=beta,prob=Prob))
}

## simulate data
simlgtdata=NULL
ni=rep(5,nlgt) 
for (i in 1:nlgt) 
{
  if (is.null(Z))
  {
    betai=as.vector(bayesm::rmixture(1,pvec,comps)$x)
  } else {
    betai=Delta %*% Z[i,]+as.vector(bayesm::rmixture(1,pvec,comps)$x)
  }
  Xa=matrix(runif(ni[i]*p,min=-1.5,max=0),ncol=p)
  X=bayesm::createX(p,na=1,nd=NULL,Xa=Xa,Xd=NULL,base=1)
  outa=simmnlwX(ni[i],X,betai) 
  simlgtdata[[i]]=list(y=outa$y,X=X,beta=betai)
}

## set parameters for priors and Z
Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep) 
Data1=list(list(p=p,lgtdata=simlgtdata,Z=Z))
s = 1
Data2 = partition_data(Data1,s)

out2 = parallel::mclapply(Data2, FUN = rhierMnlRwMixtureParallel, Prior = Prior1,
Mcmc = Mcmc1, mc.cores = s, mc.set.seed = FALSE)



</code></pre>

<hr>
<h2 id='s_max'>Calculate Maximum Number of Shards</h2><span id='topic+s_max'></span>

<h3>Description</h3>

<p>A function to calculate the maximum number of shards to be used in distributed hierarchical Bayesian algorithm for scalable target marketing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s_max(
  R,
  N,
  Data,
  s = 3,
  ep_squaremax = 0.001,
  ncomp = 1,
  Bpercent = 0.5,
  iterations = 10,
  keep = 1,
  npoints = 1000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="s_max_+3A_r">R</code></td>
<td>
<p>(integer) - Number of MCMC draws.</p>
</td></tr>
<tr><td><code id="s_max_+3A_n">N</code></td>
<td>
<p>(integer) - The number of observational units in the full dataset.</p>
</td></tr>
<tr><td><code id="s_max_+3A_data">Data</code></td>
<td>
<p>(list) - A list of lists where each sublist contains either 'regdata' or 'lgtdata'.</p>
</td></tr>
<tr><td><code id="s_max_+3A_s">s</code></td>
<td>
<p>(integer) - A small number of shards used to evaluate the distributed algorithm.</p>
</td></tr>
<tr><td><code id="s_max_+3A_ep_squaremax">ep_squaremax</code></td>
<td>
<p>(numeric) - A value indicating the user's maximum expected error tolerance.</p>
</td></tr>
<tr><td><code id="s_max_+3A_ncomp">ncomp</code></td>
<td>
<p>(integer) - The number of components in the mixture.</p>
</td></tr>
<tr><td><code id="s_max_+3A_bpercent">Bpercent</code></td>
<td>
<p>(numeric) - A decimal value representing the proportion of draws to burn-in</p>
</td></tr>
<tr><td><code id="s_max_+3A_iterations">iterations</code></td>
<td>
<p>(numeric) - The number of times to estimate the maximum number of shards</p>
</td></tr>
<tr><td><code id="s_max_+3A_keep">keep</code></td>
<td>
<p>(numeric) - MCMC thinning parameter &ndash; keep every <code>keep</code>th draw (default: 1)</p>
</td></tr>
<tr><td><code id="s_max_+3A_npoints">npoints</code></td>
<td>
<p>(integer) - The number of points at which to evaluate the difference in posterior distributions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list of: (1) A vector of s_max estimated for each iteration, (2) s_max_min calculated using C_0_min,
(3) epsilon_square, (4) ep_squaremax, (5) R, (6) N, (7) Np, (8) C_0, and (9) C_0_min
</p>


<h3>Author(s)</h3>

<p>Federico Bumbaca, Leeds School of Business, University of Colorado Boulder, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>References</h3>

<p>Bumbaca, F. (Rico), Misra, S., &amp; Rossi, P. E. (2020). Scalable Target Marketing: Distributed Markov Chain Monte Carlo for Bayesian Hierarchical Models. Journal of Marketing Research, 57(6), 999-1018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Generate hierarchical linear data
R = 1000
N = 2000
nobs = 5 #number of observations
nvar = 3 #columns
nz = 2

Z = matrix(runif(N*nz),ncol=nz) 
Z = t(t(Z)-apply(Z,2,mean))
Delta = matrix(c(1,-1,2,0,1,0), ncol = nz) 
tau0 = 0.1
iota = c(rep(1,nobs)) 
tcomps=NULL
a = diag(1, nrow=3)
tcomps[[1]] = list(mu=c(-5,0,0),rooti=a) 
tcomps[[2]] = list(mu=c(5, -5, 2),rooti=a)
tcomps[[3]] = list(mu=c(5,5,-2),rooti=a)
tpvec = c(.33,.33,.34)                               
ncomp=length(tcomps)
regdata=NULL
betas=matrix(double(N*nvar),ncol=nvar) 
tind=double(N) 
for (reg in 1:N) { 
 tempout=bayesm::rmixture(1,tpvec,tcomps)
 if (is.null(Z)){
   betas[reg,]= as.vector(tempout$x)  
 }else{
   betas[reg,]=Delta%*%Z[reg,]+as.vector(tempout$x)} 
 tind[reg]=tempout$z
 X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
 tau=tau0*runif(1,min=0.5,max=1) 
 y=X%*%betas[reg,]+sqrt(tau)*rnorm(nobs)
 regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau) 
}

Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep)
Data1=list(list(regdata=regdata,Z=Z))
returns = s_max(R = R, N = N, Data = Data1, s = 1, iterations = 2)
returns

</code></pre>

<hr>
<h2 id='sample_data'>Sample Data</h2><span id='topic+sample_data'></span>

<h3>Description</h3>

<p>A function to subset data for use in distributed hierarchical bayesian algorithm for scalable target marketing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_data(Data, Rate = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_data_+3A_data">Data</code></td>
<td>
<p>(list) - A list of lists where each sublist contains either 'regdata' or 'lgtdata'.</p>
</td></tr>
<tr><td><code id="sample_data_+3A_rate">Rate</code></td>
<td>
<p>(numeric) - Proportion of the data to be sampled</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of the same structure as <code>Data</code>, but with length scaled by <code>Rate</code>.
</p>


<h3>Author(s)</h3>

<p>Federico Bumbaca, <a href="mailto:federico.bumbaca@colorado.edu">federico.bumbaca@colorado.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Generate hierarchical linear data
R=1000
nreg=10000
nobs=5 #number of observations
nvar=3 #columns
nz=2

Z=matrix(runif(nreg*nz),ncol=nz) 
Z=t(t(Z)-apply(Z,2,mean))
Delta=matrix(c(1,-1,2,0,1,0), ncol = nz) 
tau0=.1
iota=c(rep(1,nobs)) 

## create arguments for rmixture
tcomps=NULL
a = diag(1, nrow=3)
tcomps[[1]] = list(mu=c(-5,0,0),rooti=a) 
tcomps[[2]] = list(mu=c(5, -5, 2),rooti=a)
tcomps[[3]] = list(mu=c(5,5,-2),rooti=a)
tpvec = c(.33,.33,.34)                               
ncomp=length(tcomps)
regdata=NULL
betas=matrix(double(nreg*nvar),ncol=nvar) 
tind=double(nreg) 
for (reg in 1:nreg) { 
  tempout=bayesm::rmixture(1,tpvec,tcomps)
  if (is.null(Z)){
    betas[reg,]= as.vector(tempout$x)  
  }else{
    betas[reg,]=Delta%*%Z[reg,]+as.vector(tempout$x)} 
  tind[reg]=tempout$z
  X=cbind(iota,matrix(runif(nobs*(nvar-1)),ncol=(nvar-1))) 
  tau=tau0*runif(1,min=0.5,max=1) 
  y=X%*%betas[reg,]+sqrt(tau)*rnorm(nobs)
  regdata[[reg]]=list(y=y,X=X,beta=betas[reg,],tau=tau) 
}

Prior1=list(ncomp=ncomp) 
keep=1
Mcmc1=list(R=R,keep=keep)
Data1=list(list(regdata=regdata,Z=Z))

length(Data1[[1]]$regdata)

data_s = sample_data(Data = Data1, Rate = 0.1)
length(data_s[[1]]$regdata)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
