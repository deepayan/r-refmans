<!DOCTYPE html><html lang="en"><head><title>Help for package asus</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {asus}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#asus'><p>Adaptive SURE thresholding with side information (asus)</p></a></li>
<li><a href='#asus.cuts'><p>Risk of asus with pre-defined grouping thresholds</p></a></li>
<li><a href='#ejs'><p>Extended James-Stein (ejs) estimator</p></a></li>
<li><a href='#softTh'><p>Soft Thresholding estimator</p></a></li>
<li><a href='#sureshrink'><p>SureShrink estimator</p></a></li>
<li><a href='#sureshrink.mse'><p>SURE estimate of risk</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Adaptive SURE Thresholding Using Side Information</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides the ASUS procedure for estimating a high dimensional sparse parameter in the presence of auxiliary data that encode side information on sparsity. It is a robust data combination procedure in the sense that even when pooling non-informative auxiliary data ASUS would be at least as efficient as competing soft thresholding based methods that do not use auxiliary data. 
    For more information, please see the paper Adaptive Sparse Estimation with Side Information by Banerjee, Mukherjee and Sun (JASA 2020).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/trambakbanerjee/asus#asus">https://github.com/trambakbanerjee/asus#asus</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>wavethresh, stats, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-24 15:45:11 UTC; Trambak Banerjee</td>
</tr>
<tr>
<td>Author:</td>
<td>Trambak Banerjee [aut, cre],
  Gourab Mukherjee [aut],
  Wenguang Sun [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Trambak Banerjee &lt;trambak@ku.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-24 16:20:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='asus'>Adaptive SURE thresholding with side information (asus)</h2><span id='topic+asus'></span>

<h3>Description</h3>

<p>ASUS procedure for shrinkage estimation of a high dimensional sparse parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asus(d, v.d, s, k = 2, m = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="asus_+3A_d">d</code></td>
<td>
<p>an n vector of primary observations</p>
</td></tr>
<tr><td><code id="asus_+3A_v.d">v.d</code></td>
<td>
<p>an n vector of variances for each component of d</p>
</td></tr>
<tr><td><code id="asus_+3A_s">s</code></td>
<td>
<p>an n vector of side information</p>
</td></tr>
<tr><td><code id="asus_+3A_k">k</code></td>
<td>
<p>number of groups. Default is k=2</p>
</td></tr>
<tr><td><code id="asus_+3A_m">m</code></td>
<td>
<p>partitions the support of <code class="reqn">|s|</code> into <code class="reqn">m</code> equidistant points.
Default is <code class="reqn">m=50</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates a sparse high dimensional vector using the ASUS procedure described in Banerjee et al. (2017).
If k = 1 then ASUS is the SureShrink estimator. The current implementation of ASUS estimates the grouping thresholds
based on the magnitude of <code class="reqn">|s|</code>. See the reference for more details.
</p>


<h3>Value</h3>


<ol>
<li><p> est - an n vector holding the estimates
</p>
</li>
<li><p> mse - estimate of risk
</p>
</li>
<li><p> tau - k-1 vector of grouping parameters if k&gt;=2
</p>
</li>
<li><p> t - k vector of thresholding parameters
</p>
</li>
<li><p> size - k vector of group sizes
</p>
</li></ol>



<h3>References</h3>

<p>Banerjee. T, Mukherjee. G and Sun. W. Adaptive Sparse Estimation with Side Information.
Journal of the American Statistical Association 115, no. 532 (2020): 2053-2067.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sureshrink">sureshrink</a></code>,<code><a href="#topic+ejs">ejs</a></code>,<code><a href="#topic+sureshrink.mse">sureshrink.mse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(asus)
set.seed(42)
d&lt;-rnorm(10,2,1)
v.d&lt;- rep(1,10)
set.seed(42)
s&lt;-rnorm(10,3,0.1)
asus.out&lt;-asus(d,v.d,s)

</code></pre>

<hr>
<h2 id='asus.cuts'>Risk of asus with pre-defined grouping thresholds</h2><span id='topic+asus.cuts'></span>

<h3>Description</h3>

<p>Estimates the risk of asus when there are k(&gt;2) groups with pre-defined grouping thresholds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asus.cuts(d, v.d, s, cutpoints)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="asus.cuts_+3A_d">d</code></td>
<td>
<p>an n vector of primary observations</p>
</td></tr>
<tr><td><code id="asus.cuts_+3A_v.d">v.d</code></td>
<td>
<p>an n vector of variances for each component of d</p>
</td></tr>
<tr><td><code id="asus.cuts_+3A_s">s</code></td>
<td>
<p>an n vector of side information</p>
</td></tr>
<tr><td><code id="asus.cuts_+3A_cutpoints">cutpoints</code></td>
<td>
<p>k-1 pre-defined grouping thresholds for k groups. k must be bigger than 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates the risk of asus when there are k(&gt;2) groups
with k pre-defined grouping thresholds. This function is called when <code><a href="#topic+asus">asus</a></code>
executes.
</p>


<h3>Value</h3>

<p>mse - estimate of risk
</p>


<h3>References</h3>

<p>Banerjee. T, Mukherjee. G and Sun. W. Adaptive Sparse Estimation with Side Information.
Journal of the American Statistical Association 115, no. 532 (2020): 2053-2067.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+asus">asus</a></code>,<code><a href="#topic+sureshrink">sureshrink</a></code>,<code><a href="#topic+ejs">ejs</a></code>,<code><a href="#topic+sureshrink.mse">sureshrink.mse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(asus)
set.seed(42)
d&lt;-rnorm(10)
v.d&lt;- rep(1,10)
set.seed(42)
s&lt;-rnorm(10)
out&lt;-asus.cuts(d,v.d,s,c(0.1,0.5,1))

</code></pre>

<hr>
<h2 id='ejs'>Extended James-Stein (ejs) estimator</h2><span id='topic+ejs'></span>

<h3>Description</h3>

<p>Extended James-Stein estimator of a high dimensional sparse parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ejs(d, v.d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ejs_+3A_d">d</code></td>
<td>
<p>an n vector of observations</p>
</td></tr>
<tr><td><code id="ejs_+3A_v.d">v.d</code></td>
<td>
<p>an n vector of variances for each component of d</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extended James-Stein estimator of mean from Brown (2008) and equation (7.3) in Xie et al. (2012)
</p>


<h3>Value</h3>

<p>est - an n vector holding the estimates
</p>


<h3>References</h3>


<ol>
<li><p> Brown, L.D. (2008). In-Season Prediction of Batting Averages: A Field Test of Empirical
Bayes and Bayes Methodologies. The Annals of Applied Statistics, 2, 113-152
</p>
</li>
<li><p> Xie, X. C., Kou, S. C., and Brown, L. D. (2012). SURE Estimates for a Heteroscedastic
Hierarchical Model. Journal of the American Statistical Association, 107, 1465-1479.
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+sureshrink">sureshrink</a></code>,<code><a href="#topic+asus">asus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(asus)
set.seed(42)
d&lt;-rnorm(10,2,1)
v.d&lt;- rep(1,10)
theta.hat&lt;-ejs(d,v.d)

</code></pre>

<hr>
<h2 id='softTh'>Soft Thresholding estimator</h2><span id='topic+softTh'></span>

<h3>Description</h3>

<p>Soft thresholds the input signal y with the threshold value thld
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softTh(y, thld)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="softTh_+3A_y">y</code></td>
<td>
<p>1D signal to be thresholded</p>
</td></tr>
<tr><td><code id="softTh_+3A_thld">thld</code></td>
<td>
<p>numeric threshold value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of thresholded values of the same length as y.
</p>


<h3>References</h3>

<p>Donoho, David L. &quot;De-noising by soft-thresholding.&quot;
IEEE transactions on information theory 41, no. 3 (1995): 613-627.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(asus)
set.seed(42)
y&lt;-rnorm(10,2,1)
thld&lt;- 3
x&lt;-softTh(y,thld)

</code></pre>

<hr>
<h2 id='sureshrink'>SureShrink estimator</h2><span id='topic+sureshrink'></span>

<h3>Description</h3>

<p>SureShrink estimator of a high dimensional sparse parameter from Donoho and Johnstone (1995)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sureshrink(d, v.d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sureshrink_+3A_d">d</code></td>
<td>
<p>an n vector of observations</p>
</td></tr>
<tr><td><code id="sureshrink_+3A_v.d">v.d</code></td>
<td>
<p>an n vector of variances for each component of d</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates a threshold t by minimizing the SURE function and then soft thresholds
d using t.
</p>


<h3>Value</h3>


<ol>
<li><p> est - an n vector holding the estimates
</p>
</li>
<li><p> t - estimated threshold
</p>
</li></ol>



<h3>References</h3>

<p>David L Donoho and Iain M Johnstone. Adapting to unknown smoothness via wavelet shrinkage.
Journal of the american statistical association, 90(432):1200-1224, 1995
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sureshrink.mse">sureshrink.mse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(asus)
set.seed(42)
d&lt;-rnorm(10,2,1)
v.d&lt;- rep(1,10)
theta.hat&lt;-sureshrink(d,v.d)

</code></pre>

<hr>
<h2 id='sureshrink.mse'>SURE estimate of risk</h2><span id='topic+sureshrink.mse'></span>

<h3>Description</h3>

<p>Stein's Unbiased Risk Estimate for the sureshrink estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sureshrink.mse(d, v.d, type = 1, t = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sureshrink.mse_+3A_d">d</code></td>
<td>
<p>an n vector of observations</p>
</td></tr>
<tr><td><code id="sureshrink.mse_+3A_v.d">v.d</code></td>
<td>
<p>an n vector of variances for each component of d</p>
</td></tr>
<tr><td><code id="sureshrink.mse_+3A_type">type</code></td>
<td>
<p>set type=1 if you want the thresholding parameter t to be estimated. Otherwise
set type = 0 in which case you must provide t. Default is type = 1</p>
</td></tr>
<tr><td><code id="sureshrink.mse_+3A_t">t</code></td>
<td>
<p>soft thresholding parameter. If type = 1, then t is estimated whereas if type = 0
then you must provide t. Default is t = 0 (and type = 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimates the risk of the surehsrink estimator of Donoho and Johnstone (1995).
</p>


<h3>Value</h3>


<ol>
<li><p> sure.est - SURE estimate of risk
</p>
</li>
<li><p> t - estimated threshold (meaningless if type = 0)
</p>
</li></ol>



<h3>References</h3>


<ol>
<li><p> Charles M Stein. Estimation of the mean of a multivariate normal distribution. The annals of
Statistics, pages 1135-1151, 1981
</p>
</li>
<li><p> David L Donoho and Iain M Johnstone. Adapting to unknown smoothness via wavelet shrinkage.
Journal of the american statistical association, 90(432):1200-1224, 1995
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+sureshrink">sureshrink</a></code>,<code><a href="#topic+asus">asus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(asus)
set.seed(42)
d&lt;-rnorm(10,2,1)
v.d&lt;- rep(1,10)
mse&lt;-sureshrink.mse(d,v.d)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
