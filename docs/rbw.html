<!DOCTYPE html><html><head><title>Help for package rbw</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rbw}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#advertisement'><p>Data on Political Advertisement and Campaign Contributions in US Presidential Elections</p></a></li>
<li><a href='#campaign_long'><p>Long-format Data on Negative Campaign Advertising in US Senate and Gubernatorial Elections</p></a></li>
<li><a href='#campaign_wide'><p>Wide-format Data on Negative Campaign Advertising in US Senate and Gubernatorial Elections</p></a></li>
<li><a href='#eb2'><p>Function for Generating Minimum Entropy Weights Subject to a Set of Balancing</p>
Constraints</a></li>
<li><a href='#peace'><p>Data on Public Support for War in a Sample of US Respondents</p></a></li>
<li><a href='#rbwMed'><p>Residual Balancing Weights for Causal Mediation Analysis</p></a></li>
<li><a href='#rbwPanel'><p>Residual Balancing Weights for Analyzing Time-varying Treatments</p></a></li>
<li><a href='#rbwPoint'><p>Residual Balancing Weights for Estimating the Average Treatment Effect (ATE) in a Point Treatment Setting</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-03-01</td>
</tr>
<tr>
<td>Title:</td>
<td>Residual Balancing Weights for Marginal Structural Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Residual balancing is a robust method of constructing weights for
  marginal structural models, which can be used to estimate (a) the average treatment effect in 
  a cross-sectional observational study, (b) controlled direct/mediator effects in causal mediation
  analysis, and (c) the effects of time-varying treatments in panel data (Zhou and Wodtke 2020
  &lt;<a href="https://doi.org/10.1017%2Fpan.2020.2">doi:10.1017/pan.2020.2</a>&gt;). This package provides three functions, rbwPoint(), rbwMed(), and rbwPanel(),
  that produce residual balancing weights for estimating (a), (b), (c), respectively.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr (&ge; 0.8.4), stats, rlang (&ge; 0.4.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ebal, knitr, survey, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/xiangzhou09/rbw">https://github.com/xiangzhou09/rbw</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/xiangzhou09/rbw">https://github.com/xiangzhou09/rbw</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-03-01 17:23:40 UTC; Xiang</td>
</tr>
<tr>
<td>Author:</td>
<td>Xiang Zhou [cre],
  Derick da Silva Baum [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xiang Zhou &lt;xiang_zhou@fas.harvard.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-03-01 18:10:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='advertisement'>Data on Political Advertisement and Campaign Contributions in US Presidential Elections</h2><span id='topic+advertisement'></span>

<h3>Description</h3>

<p>A dataset containing 15 variables on the campaign contributions of 16,265 zip codes to the
2004 and 2008 US presidential elections in addition to the demographic characteristics of each area
(Urban and Niebler 2014; Fong, Hazlett, and Imai 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>advertisement
</code></pre>


<h3>Format</h3>

<p>A data frame with 16,265 rows and 15 columns: </p>

<dl>
<dt>zip</dt><dd><p>zip code</p>
</dd>
<dt>treat</dt><dd><p>the log transformed TotAds</p>
</dd>
<dt>TotAds</dt><dd><p>the total number of political advertisements aired in the zip code</p>
</dd>
<dt>TotalPop</dt><dd><p>population size</p>
</dd>
<dt>PercentOver65</dt><dd><p>percent of the population over 65</p>
</dd>
<dt>Inc</dt><dd><p>median household income</p>
</dd>
<dt>PercentHispanic</dt><dd><p>percent Hispanic</p>
</dd>
<dt>PercentBlack</dt><dd><p>percent black</p>
</dd>
<dt>density</dt><dd><p>population density (people per sq mile)</p>
</dd>
<dt>per_collegegrads</dt><dd><p>percent college graduates</p>
</dd>
<dt>CanCommute</dt><dd><p>a dummy variable indicating whether it is possible to commute to the zip code from a competitive state</p>
</dd>
<dt>StFIPS</dt><dd><p>state FIPS code</p>
</dd>
<dt>Cont</dt><dd><p>campaign contributions (in thousands of dollars)</p>
</dd>
<dt>log_TotalPop</dt><dd><p>log population</p>
</dd>
<dt>log_Inc</dt><dd><p>log median income</p>
</dd>
</dl>



<h3>References</h3>

<p>Fong, Christian, Chad Hazlett, and Kosuke Imai. 2018. Covariate Balancing Propensity Score for a Continuous
Treatment: Application to The Efficacy of Political Advertisements. The Annals of Applied Statistics 12(1):156-77.
</p>
<p>Urban, Carly, and Sarah Niebler. 2014. Dollars on the Sidewalk: Should U.S. Presidential Candidates Advertise in Uncontested States?
American Journal of Political Science 58(2):322-36.
</p>

<hr>
<h2 id='campaign_long'>Long-format Data on Negative Campaign Advertising in US Senate and Gubernatorial Elections</h2><span id='topic+campaign_long'></span>

<h3>Description</h3>

<p>A dataset containing 19 variables and 565 unit-week records on the campaign of 113 Democratic candidates
in US Senate and Gubernatorial Elections from 2000 to 2006 (Blackwell 2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>campaign_long
</code></pre>


<h3>Format</h3>

<p>A data frame with 565 rows and 19 columns: </p>

<dl>
<dt>demName</dt><dd><p>name of the Democratic candidate</p>
</dd>
<dt>d.gone.neg</dt><dd><p>whether the candidate went negative in a campaign-week,
defined as whether more than 10% of the candidate's political advertising was negative</p>
</dd>
<dt>d.gone.neg.l1</dt><dd><p>whether the candidate went negative in the previous campaign-week</p>
</dd>
<dt>camp.length</dt><dd><p>length of the candidate's campaign (in weeks)</p>
</dd>
<dt>deminc</dt><dd><p>whether the candidate was an incumbent</p>
</dd>
<dt>base.poll</dt><dd><p>Democratic share in the baseline polls</p>
</dd>
<dt>base.und</dt><dd><p>share of undecided voters in the baseline polls</p>
</dd>
<dt>office</dt><dd><p>type of office in contest. 0: governor; 1: senator</p>
</dd>
<dt>demprcnt</dt><dd><p>Democratic share of the two-party vote in the election</p>
</dd>
<dt>week</dt><dd><p>week in the campaign (in the final five weeks preceding the election)</p>
</dd>
<dt>year</dt><dd><p>year of the election</p>
</dd>
<dt>state</dt><dd><p>state of the election</p>
</dd>
<dt>dem.polls</dt><dd><p>Democratic share in the polls</p>
</dd>
<dt>dem.polls.l1</dt><dd><p>Democratic share in the polls in the previous campaign-week</p>
</dd>
<dt>undother</dt><dd><p>share of undecided voters in the polls</p>
</dd>
<dt>undother.l1</dt><dd><p>share of undecided voters in the polls in the previous campaign-week</p>
</dd>
<dt>neg.dem</dt><dd><p>the proportion of advertisements that were negative in a campaign-week</p>
</dd>
<dt>neg.dem.l1</dt><dd><p>the proportion of advertisements that were negative in the previous campaign-week</p>
</dd>
<dt>id</dt><dd><p>candidate id</p>
</dd>
</dl>



<h3>References</h3>

<p>Blackwell, Matthew. 2013. A Framework for Dynamic Causal Inference in
Political Science. American Journal of Political Science 57(2): 504-619.
</p>

<hr>
<h2 id='campaign_wide'>Wide-format Data on Negative Campaign Advertising in US Senate and Gubernatorial Elections</h2><span id='topic+campaign_wide'></span>

<h3>Description</h3>

<p>A dataset containing 32 variables and 113 unit records from Blackwell (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>campaign_wide
</code></pre>


<h3>Format</h3>

<p>A data frame with 113 rows and 26 columns: </p>

<dl>
<dt>demName</dt><dd><p>name of the Democratic candidate</p>
</dd>
<dt>camp.length</dt><dd><p>length of the candidate's campaign (in weeks)</p>
</dd>
<dt>deminc</dt><dd><p>whether the candidate was an incumbent.</p>
</dd>
<dt>base.poll</dt><dd><p>Democratic share in the baseline polls</p>
</dd>
<dt>base.und</dt><dd><p>share of undecided voters in the baseline polls</p>
</dd>
<dt>office</dt><dd><p>type of office in contest. 0: governor; 1: senator</p>
</dd>
<dt>demprcnt</dt><dd><p>Democratic share of the two-party vote in the election</p>
</dd>
<dt>year</dt><dd><p>year of the election</p>
</dd>
<dt>state</dt><dd><p>state of the election</p>
</dd>
<dt>id</dt><dd><p>candidate id</p>
</dd>
<dt>dem.polls_1</dt><dd><p>Democratic share in week 1 polls</p>
</dd>
<dt>dem.polls_2</dt><dd><p>Democratic share in week 2 polls</p>
</dd>
<dt>dem.polls_3</dt><dd><p>Democratic share in week 3 polls</p>
</dd>
<dt>dem.polls_4</dt><dd><p>Democratic share in week 4 polls</p>
</dd>
<dt>dem.polls_5</dt><dd><p>Democratic share in week 5 polls</p>
</dd>
<dt>d.gone.neg_1</dt><dd><p>whether the candidate went negative in week 1</p>
</dd>
<dt>d.gone.neg_2</dt><dd><p>whether the candidate went negative in week 2</p>
</dd>
<dt>d.gone.neg_3</dt><dd><p>whether the candidate went negative in week 3</p>
</dd>
<dt>d.gone.neg_4</dt><dd><p>whether the candidate went negative in week 4</p>
</dd>
<dt>d.gone.neg_5</dt><dd><p>whether the candidate went negative in week 5</p>
</dd>
<dt>neg.dem_1</dt><dd><p>the proportion of advertisements that were negative in week 1 polls</p>
</dd>
<dt>neg.dem_2</dt><dd><p>the proportion of advertisements that were negative in week 2 polls</p>
</dd>
<dt>neg.dem_3</dt><dd><p>the proportion of advertisements that were negative in week 3 polls</p>
</dd>
<dt>neg.dem_4</dt><dd><p>the proportion of advertisements that were negative in week 4 polls</p>
</dd>
<dt>neg.dem_5</dt><dd><p>the proportion of advertisements that were negative in week 5 polls</p>
</dd>
<dt>undother_1</dt><dd><p>share of undecided voters in week 1 polls</p>
</dd>
<dt>undother_2</dt><dd><p>share of undecided voters in week 2 polls</p>
</dd>
<dt>undother_3</dt><dd><p>share of undecided voters in week 3 polls</p>
</dd>
<dt>undother_4</dt><dd><p>share of undecided voters in week 4 polls</p>
</dd>
<dt>undother_5</dt><dd><p>share of undecided voters in week 5 polls</p>
</dd>
<dt>cum_neg</dt><dd><p>the total number of campaign-weeks in which a candidate went negative</p>
</dd>
<dt>ave_neg</dt><dd><p>the average proportion of advertisements that were negative over the final five weeks of the campaign multiplied by ten</p>
</dd>
</dl>



<h3>References</h3>

<p>Blackwell, Matthew. 2013. A Framework for Dynamic Causal Inference in
Political Science. American Journal of Political Science 57(2): 504-619.
</p>

<hr>
<h2 id='eb2'>Function for Generating Minimum Entropy Weights Subject to a Set of Balancing
Constraints</h2><span id='topic+eb2'></span>

<h3>Description</h3>

<p><code>eb2</code> is an adaptation of <code><a href="ebal.html#topic+eb">eb</a></code> that generates
minimum entropy weights subject to a set of balancing constraints. Using
the method of Lagrange multipliers, the dual problem is an unconstrained
optimization problem that can be solved using Newton's method. When a full
Newton step is excessive, an exact line search is used to find the best step
size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eb2(C, M, Q, Z = rep(0, ncol(C)), max_iter = 200, tol = 1e-04, print_level = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eb2_+3A_c">C</code></td>
<td>
<p>A constraint matrix where each column corresponds to a balancing constraint.</p>
</td></tr>
<tr><td><code id="eb2_+3A_m">M</code></td>
<td>
<p>A vector of moment conditions to be met in the reweighted sample. Specifically,
in the reweighted sample, we should have <code class="reqn">C'W=M</code>, where <code class="reqn">W</code> is a column vector representing
the new weights. When called internally, it is a vector of zeros with length equal to the number of
columns in <code>C</code>.</p>
</td></tr>
<tr><td><code id="eb2_+3A_q">Q</code></td>
<td>
<p>A vector of base weights.</p>
</td></tr>
<tr><td><code id="eb2_+3A_z">Z</code></td>
<td>
<p>A vector of Lagrange multipliers to be initialized.</p>
</td></tr>
<tr><td><code id="eb2_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations for Newton's method in entropy minimization.</p>
</td></tr>
<tr><td><code id="eb2_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter used to determine convergence. Specifically, convergence is achieved if
<code>tol</code> is greater than the maximum absolute value of the deviations between the moments of the
reweighted data and the target moments (i.e., <code>M</code>).</p>
</td></tr>
<tr><td><code id="eb2_+3A_print_level">print_level</code></td>
<td>
<p>The level of printing: </p>

<dl>
<dt>1</dt><dd><p>normal: print whether the algorithm converges or not.</p>
</dd>
<dt>2</dt><dd><p>detailed: print also the maximum absolute value of the deviations between the moments
of the reweighted data and the target moments in each iteration.</p>
</dd>
<dt>3</dt><dd><p>very detailed: print also the step length of the line searcher in iterations where
a full Newton step is excessive.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results from the algorithm.
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>A vector of normalized minimum entropy weights.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>A vector of Lagrange multipliers.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>A logical indicator for convergence.</p>
</td></tr>
<tr><td><code>maxdiff</code></td>
<td>
<p>A scalar indicating the maximum deviation between the
moments of the reweighted data and the target moments.</p>
</td></tr>
</table>

<hr>
<h2 id='peace'>Data on Public Support for War in a Sample of US Respondents</h2><span id='topic+peace'></span>

<h3>Description</h3>

<p>A dataset containing 17 variables on the views of 1,273 US adults about their support
for war against countries that were hypothetically developing nuclear weapons. The data include
several variables on the country's features and respondents' demographic and attitudinal characteristics
(Tomz and Weeks 2013; Zhou and Wodtke 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>peace
</code></pre>


<h3>Format</h3>

<p>A data frame with 1,273 rows and 17 columns: </p>

<dl>
<dt>threatc</dt><dd><p>number of adverse events respondents considered probable if the US did not engage in war</p>
</dd>
<dt>ally</dt><dd><p>a dummy variable indicating whether the country had signed a military alliance with the US</p>
</dd>
<dt>trade</dt><dd><p>a dummy variable indicating whether the country had high levels of trade with the US</p>
</dd>
<dt>h1</dt><dd><p>an index measuring respondent's attitude toward militarism</p>
</dd>
<dt>i1</dt><dd><p>an index measuring respondent's attitude toward internationalism</p>
</dd>
<dt>p1</dt><dd><p>an index measuring respondent's identification with the Republican party</p>
</dd>
<dt>e1</dt><dd><p>an index measuring respondent's attitude toward ethnocentrism</p>
</dd>
<dt>r1</dt><dd><p>an index measuring respondent's attitude toward religiosity</p>
</dd>
<dt>male</dt><dd><p>a dummy variable indicating whether the respondent is male</p>
</dd>
<dt>white</dt><dd><p>a dummy variable indicating whether the respondent is white</p>
</dd>
<dt>age</dt><dd><p>respondent's age</p>
</dd>
<dt>ed4</dt><dd><p>respondent's education with categories ranging from high school or less to postgraduate degree</p>
</dd>
<dt>democ</dt><dd><p>a dummy variable indicating whether the country was a democracy</p>
</dd>
<dt>strike</dt><dd><p>a measure of support for war on a five-point scale</p>
</dd>
<dt>cost</dt><dd><p>number of negative consequences anticipated if the US engaged in war</p>
</dd>
<dt>successc</dt><dd><p>whether the respondent thought the operation would succeed. 0: less than 50-50 chance of working even in the short run; 1: efficacious only in the short run; 2: successful both in the short and long run</p>
</dd>
<dt>immoral</dt><dd><p>a dummy variable indicating whether respondents thought it would be morally wrong to strike the country</p>
</dd>
</dl>



<h3>References</h3>

<p>Tomz, Michael R., and Jessica L. P. Weeks. 2013. Public Opinion and the Democratic Peace.
The American Political Science Review 107(4):849-65.
</p>
<p>Zhou, Xiang, and Geoffrey T. Wodtke. 2020. Residual Balancing:
A Method of Constructing Weights for Marginal Structural Models. Political Analysis 28(4):487-506.
</p>

<hr>
<h2 id='rbwMed'>Residual Balancing Weights for Causal Mediation Analysis</h2><span id='topic+rbwMed'></span>

<h3>Description</h3>

<p><code>rbwMed</code> is a function that produces residual balancing weights for estimating
controlled direct/mediator effects in causal mediation analysis. The user supplies
a (optional) set of baseline confounders and a list of model objects for the conditional
mean of each post-treatment confounder given the treatment and baseline confounders.
The weights can be used to fit marginal structural models for the joint effects of the
treatment and a mediator on an outcome of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbwMed(
  treatment,
  mediator,
  zmodels,
  data,
  baseline_x,
  interact = FALSE,
  base_weights,
  max_iter = 200,
  tol = 1e-04,
  print_level = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbwMed_+3A_treatment">treatment</code></td>
<td>
<p>A symbol or character string for the treatment variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_mediator">mediator</code></td>
<td>
<p>A symbol or character string for the mediator variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_zmodels">zmodels</code></td>
<td>
<p>A list of fitted <code>lm</code> or <code>glm</code> objects for
post-treatment confounders of the mediator-outcome relationship. If there's no
post-treatment confounder, set it to be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_data">data</code></td>
<td>
<p>A data frame containing all variables in the model.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_baseline_x">baseline_x</code></td>
<td>
<p>(Optional) An expression for a set of baseline confounders stored in <code>data</code> or
a character vector of the names of these variables.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_interact">interact</code></td>
<td>
<p>A logical variable indicating whether baseline and post-treatment covariates
should be balanced against the treatment-mediator interaction term(s).</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_base_weights">base_weights</code></td>
<td>
<p>(Optional) A vector of base weights (or its name).</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations for Newton's method in entropy minimization.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter used to determine convergence in entropy minimization.
See documentation for <code><a href="#topic+eb2">eb2</a></code>.</p>
</td></tr>
<tr><td><code id="rbwMed_+3A_print_level">print_level</code></td>
<td>
<p>The level of printing. See documentation for <code><a href="#topic+eb2">eb2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results.
</p>
<table>
<tr><td><code>weights</code></td>
<td>
<p>A vector of residual balancing weights.</p>
</td></tr>
<tr><td><code>constraints</code></td>
<td>
<p>A matrix of (linearly independent) residual balancing constraints</p>
</td></tr>
<tr><td><code>eb_out</code></td>
<td>
<p>Results from calling the <code><a href="#topic+eb2">eb2</a></code> function</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># models for post-treatment confounders
m1 &lt;- lm(threatc ~ ally + trade + h1 + i1 + p1 + e1 + r1 +
  male + white + age + ed4 + democ, data = peace)

m2 &lt;- lm(cost ~ ally + trade + h1 + i1 + p1 + e1 + r1 +
  male + white + age + ed4 + democ, data = peace)

m3 &lt;- lm(successc ~ ally + trade + h1 + i1 + p1 + e1 + r1 +
  male + white + age + ed4 + democ, data = peace)

# residual balancing weights
rbwMed_fit &lt;- rbwMed(treatment = democ, mediator = immoral,
  zmodels = list(m1, m2, m3), interact = TRUE,
  baseline_x = c(ally, trade, h1, i1, p1, e1, r1, male, white, age, ed4),
  data = peace)

# attach residual balancing weights to data
peace$rbw_cde &lt;- rbwMed_fit$weights

# fit marginal structural model
if(require(survey)){
  rbw_design &lt;- svydesign(ids = ~ 1, weights = ~ rbw_cde, data = peace)
  msm_rbwMed &lt;- svyglm(strike ~ democ * immoral, design = rbw_design)
  summary(msm_rbwMed)
}
</code></pre>

<hr>
<h2 id='rbwPanel'>Residual Balancing Weights for Analyzing Time-varying Treatments</h2><span id='topic+rbwPanel'></span>

<h3>Description</h3>

<p><code>rbwPanel</code> is a function that produces residual balancing weights (rbw) for
estimating the marginal effects of time-varying treatments. The user supplies
a long format data frame (each row being a unit-period) and a list of
fitted model objects for the conditional mean of each post-treatment confounder given
past treatments and past confounders. The residuals of each time-varying confounder
are balanced across both the current treatment <code class="reqn">A_t</code> and the regressors of the confounder
model. In addition, when <code>future &gt; 0</code>, the residuals are also balanced across future
treatments <code class="reqn">A_{t+1},\ldots A_{t + future}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbwPanel(
  treatment,
  xmodels,
  id,
  time,
  data,
  base_weights,
  future = 1L,
  max_iter = 200,
  tol = 1e-04,
  print_level = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbwPanel_+3A_treatment">treatment</code></td>
<td>
<p>A symbol or character string for the treatment variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_xmodels">xmodels</code></td>
<td>
<p>A list of fitted <code>lm</code> or <code>glm</code> objects for
time-varying confounders.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_id">id</code></td>
<td>
<p>A symbol or character string for the unit id variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_time">time</code></td>
<td>
<p>A symbol or character string for the time variable in <code>data</code>. The time variable should be numeric.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_data">data</code></td>
<td>
<p>A data frame containing all variables in the model.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_base_weights">base_weights</code></td>
<td>
<p>(Optional) A vector of base weights (or its name).</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_future">future</code></td>
<td>
<p>An integer indicating the number of future treatments in the balancing conditions. When
<code>future &gt; 0</code>, the residualized time-varying covariates are balanced not only with respect to
current treatment <code class="reqn">A_t</code>, but also with respect to future treatments <code class="reqn">A_{t+1},\ldots A_{t + future}</code>.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations for Newton's method in entropy minimization.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter used to determine convergence in entropy minimization.
See documentation for <code><a href="#topic+eb2">eb2</a></code>.</p>
</td></tr>
<tr><td><code id="rbwPanel_+3A_print_level">print_level</code></td>
<td>
<p>The level of printing. See documentation for <code><a href="#topic+eb2">eb2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results.
</p>
<table>
<tr><td><code>weights</code></td>
<td>
<p>A data frame containing the unit id variable and residual balancing weights.</p>
</td></tr>
<tr><td><code>constraints</code></td>
<td>
<p>A matrix of (linearly independent) residual balancing constraints</p>
</td></tr>
<tr><td><code>eb_out</code></td>
<td>
<p>Results from calling the <code><a href="#topic+eb2">eb2</a></code> function</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># models for time-varying confounders
m1 &lt;- lm(dem.polls ~ (d.gone.neg.l1 + dem.polls.l1 + undother.l1) * factor(week),
data = campaign_long)
m2 &lt;- lm(undother ~ (d.gone.neg.l1 + dem.polls.l1 + undother.l1) * factor(week),
data = campaign_long)

xmodels &lt;- list(m1, m2)

# residual balancing weights
rbwPanel_fit &lt;- rbwPanel(treatment = d.gone.neg, xmodels = xmodels, id = id,
time = week, data = campaign_long)

summary(rbwPanel_fit$weights)

# merge weights into wide-format data
campaign_wide2 &lt;- merge(campaign_wide, rbwPanel_fit$weights, by = "id")

# fit a marginal structural model (adjusting for baseline confounders)
if(require(survey)){
  rbw_design &lt;- svydesign(ids = ~ 1, weights = ~ rbw, data = campaign_wide2)
  msm_rbwPanel &lt;- svyglm(demprcnt ~ cum_neg * deminc + camp.length + factor(year) + office,
  design = rbw_design)
  summary(msm_rbwPanel)
}
</code></pre>

<hr>
<h2 id='rbwPoint'>Residual Balancing Weights for Estimating the Average Treatment Effect (ATE) in a Point Treatment Setting</h2><span id='topic+rbwPoint'></span>

<h3>Description</h3>

<p><code>rbwPoint</code> is a function that produces residual balancing weights in a point treatment setting. It takes
a set of baseline confounders and computes the residuals for each confounder by centering it around
its sample mean. The weights can be used to fit marginal structural models to estimate the average treatment
effect (ATE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbwPoint(
  treatment,
  data,
  baseline_x,
  base_weights,
  max_iter = 200,
  tol = 1e-04,
  print_level = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbwPoint_+3A_treatment">treatment</code></td>
<td>
<p>A symbol or character string for the treatment variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="rbwPoint_+3A_data">data</code></td>
<td>
<p>A data frame containing all variables in the model.</p>
</td></tr>
<tr><td><code id="rbwPoint_+3A_baseline_x">baseline_x</code></td>
<td>
<p>An expression for a set of baseline confounders stored in <code>data</code> or a character
vector of the names of these variables.</p>
</td></tr>
<tr><td><code id="rbwPoint_+3A_base_weights">base_weights</code></td>
<td>
<p>(Optional) A vector of base weights (or its name).</p>
</td></tr>
<tr><td><code id="rbwPoint_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations for Newton's method in entropy minimization.</p>
</td></tr>
<tr><td><code id="rbwPoint_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter used to determine convergence in entropy minimization.
See documentation for <code><a href="#topic+eb2">eb2</a></code>.</p>
</td></tr>
<tr><td><code id="rbwPoint_+3A_print_level">print_level</code></td>
<td>
<p>The level of printing. See documentation for <code><a href="#topic+eb2">eb2</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the results.
</p>
<table>
<tr><td><code>weights</code></td>
<td>
<p>A vector of residual balancing weights.</p>
</td></tr>
<tr><td><code>constraints</code></td>
<td>
<p>A matrix of (linearly independent) residual balancing constraints</p>
</td></tr>
<tr><td><code>eb_out</code></td>
<td>
<p>Results from calling the <code><a href="#topic+eb2">eb2</a></code> function</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># residual balancing weights
rbwPoint_fit &lt;- rbwPoint(treat, baseline_x = c(log_TotalPop, PercentOver65, log_Inc,
  PercentHispanic, PercentBlack, density,
  per_collegegrads, CanCommute), data = advertisement)

# attach residual balancing weights to data
advertisement$rbw_point &lt;- rbwPoint_fit$weights

# fit marginal structural model
if(require(survey)){
  rbw_design &lt;- svydesign(ids = ~ 1, weights = ~ rbw_point, data = advertisement)
  # the outcome model includes the treatment, the square of the treatment,
  # and state-level fixed effects (Fong, Hazlett, and Imai 2018)
  msm_rbwPoint &lt;- svyglm(Cont ~ treat + I(treat^2) + factor(StFIPS), design = rbw_design)
  summary(msm_rbwPoint)
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
