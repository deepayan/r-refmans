<!DOCTYPE html><html><head><title>Help for package imagefx</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {imagefx}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#amp.sig'>
<p>Amplify Time Varying Signals in Video</p></a></li>
<li><a href='#blob.extract'>
<p>Extract Blob Region from Image (Matrix)</p></a></li>
<li><a href='#blob.stats'>
<p>Blob Statistics from Erebus Volcano, Antarctica</p></a></li>
<li><a href='#build.gaus'>
<p>Build 2D Gaussian Image (Matrix)</p></a></li>
<li><a href='#build.lap'>
<p>Build 5-Point Laplacian Stencil</p></a></li>
<li><a href='#calc.blob.stats'>
<p>Calculate Color and Spatial Statistics from Blob Region</p></a></li>
<li><a href='#cor.mat'>
<p>Correlate Matrix Rows</p></a></li>
<li><a href='#crop.image'>
<p>Crop an Image</p></a></li>
<li><a href='#erebus'>
<p>Image of Erebus Volcano, Antarctica</p></a></li>
<li><a href='#erebus.40'>
<p>Image of Erebus Volcano, Antarctica</p></a></li>
<li><a href='#erebus.70'>
<p>Image of Erebus Volcano, Antarctica</p></a></li>
<li><a href='#erebus.90'>
<p>Image of Erebus Volcano, Antarctica</p></a></li>
<li><a href='#fftshift'>
<p>Shift Zero Frequency to Center</p></a></li>
<li><a href='#filt3d'>
<p>Filter Image (Matrix) with Mask via Convolution</p></a></li>
<li><a href='#fit3d'>
<p>Fit a Plane to Image (Matrix) with SVD</p></a></li>
<li><a href='#gen.eg.img.list'>
<p>Generate Example Image List Data</p></a></li>
<li><a href='#image2'>
<p>Plot Images (Matrices) with Intuitive Axes</p></a></li>
<li><a href='#pcorr3d'>
<p>Phase Correlation of Images</p></a></li>
<li><a href='#points2'>
<p>Plot points on image</p></a></li>
<li><a href='#range01'>
<p>Scale Object Values Between Zero and One</p></a></li>
<li><a href='#run.avg'>
<p>Perform Running Average via Convolution</p></a></li>
<li><a href='#sakurajima'>
<p>Image of Sakurajima Volcano, Japan</p></a></li>
<li><a href='#shift.vec'>
<p>Shift Vector</p></a></li>
<li><a href='#sig.extract'>
<p>Extract Time-Series Signal from Video Data</p></a></li>
<li><a href='#tux1'>
<p>Image of Tux</p></a></li>
<li><a href='#tux2'>
<p>Image of Tux</p></a></li>
<li><a href='#xcorr3d'>
<p>Normalized Cross Correlation of Images</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Extract Features from Images</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Alex J.C. Witsil</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alex J.C. Witsil &lt;alexjcwitsil@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Synthesize images into characteristic features for time-series analysis or machine learning applications.  The package was originally intended for monitoring volcanic eruptions in video data by highlighting and extracting regions above the vent associated with plume activity.  However, the functions within are general and have wide applications for image processing, analyzing, filtering, and plotting.       </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>moments, signal</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, jpeg</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-13 18:23:54 UTC; alexmiller</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-13 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='amp.sig'>
Amplify Time Varying Signals in Video
</h2><span id='topic+amp.sig'></span>

<h3>Description</h3>

<p>Filters then amplifies each pixel's time series signal.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amp.sig(img.list, fps, f.corners, amp ,n.poles, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amp.sig_+3A_img.list">img.list</code></td>
<td>

<p>A series of images saved in a list.  Each list element is a matrix that represents pixel values of an image, the dimensions of which correspond to the rows and columns of the matrix.
</p>
</td></tr>
<tr><td><code id="amp.sig_+3A_fps">fps</code></td>
<td>

<p>Sample rate of video in frames per second (FPS).  Each list element of <code>img.list</code> should be separated by <code>1/fps</code> seconds. Defaults to 30. 
</p>
</td></tr>
<tr><td><code id="amp.sig_+3A_f.corners">f.corners</code></td>
<td>

<p>Corners to use in the filter.  Currently only a Butterworth filter is implemented.
</p>
</td></tr>
<tr><td><code id="amp.sig_+3A_amp">amp</code></td>
<td>

<p>Scalar to multiply filtered signals by.  Defaults to 10. 
</p>
</td></tr>
<tr><td><code id="amp.sig_+3A_n.poles">n.poles</code></td>
<td>

<p>Number of poles used in Butterworth filter.  Defaults to two. 
</p>
</td></tr>
<tr><td><code id="amp.sig_+3A_type">type</code></td>
<td>

<p>Type of filter used in Butterworth filter (i.e. 'low', 'high', 'stop', 'pass'.  Defaults to 'pass' if <code>n.poles==2</code> and 'high' if <code>n.poles==1</code>.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm is based on the landmark study by Wu et. al (2012) though is organized and implemented slightly differently.  Namely, this algorithm takes advantage of R functionality instead of the original development language, MATLAB.     
</p>
<p>If the goal is to amplify subtle time variations in an image (e.g. heartbeat, breathing, volcanic emissions, etc...) choose corner frequencies that contain the desired signal.  For example, most adult resting heart rates range between 1 and 1.5 Hz.  To amplify these signals, use a filter type of either <code>low</code>, <code>high</code>, or <code>pass</code>.  If the goal is to dampen or remove signals, choose appropriate corner frequencies and use a filter type of <code>low</code>, <code>high</code>, or <code>stop</code>.  To help choose appropriate corner frequencies, see <code><a href="#topic+sig.extract">sig.extract</a></code>.  
</p>
<p>Filtering is accomplished via the <code>apply</code> function for speed.  However, if the dimensions of the images are large (i.e. <code>dim(img.list[[1]])</code>) or if the number of frames is large (i.e. <code>length(img.list)</code>), the RAM may fill up and the R session may crash. 
</p>


<h3>Value</h3>

<p>List with the same length and element dimensions as <code>img.list</code>.  Each list element contains the amplified version of the original image list.   
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>References</h3>

<p>Wu, Hao-Yu, et al. &quot;Eulerian video magnification for revealing subtle changes in the world.&quot; (2012) 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sig.extract">sig.extract</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##############################
### SYNTHETIC VIDEO INPUTS ###
##############################

## x and y dimension of the frame
dim.x = 64
dim.y = 64

## sample rate in frames per second
fps = 30

## how many seconds does the video last
n.secs =3 

## what is the frequency at which the boxed region oscillates
sig.f = 2 

## what is the peak amplitude of the signal
sig.peak = 0.2 

## size of the boxed region
box.width = 10
box.height = 10


##################################
### VIDEO AMPLIFICATION INPUTS ###
##################################

## how much to amplify the signal by
amp=500

## filter corners -- should contain the signal of interest
f.corners = c(sig.f-0.2, sig.f+0.2)

## number of poles in Butterworth filter
n.poles = 2

## type of filter
type = 'pass'


################################
### GENERATE SYNTHETIC VIDEO ###
################################

## use the inputs to generate an image list (i.e. video)
img.list &lt;- gen.eg.img.list(dim.x, dim.y, fps, n.secs, sig.f, sig.peak, box.width, box.height)


################################
### AMPLIFY THE VIDEO SIGNAL ###
################################

## amplify the video signal
amp.list &lt;- amp.sig(img.list, fps, f.corners, amp, n.poles, type)


################
### PLOTTING ###
################

## save the users original margins
mar.org  &lt;- par()$mar

## generate a time axis
tax &lt;- (1:(n.secs*fps)) / fps 

## get the raw video into a spatiotemporal matrix
org.spat.temp &lt;- matrix(unlist(lapply(img.list,rowSums)),ncol=length(tax))
amp.spat.temp &lt;- matrix(unlist(lapply(amp.list,rowSums)),ncol=length(tax))

## define some example frames to plot
eg.frames = c(18,26,34,41)

## define a layout matrix 
layout.mat &lt;- matrix(c(1:length(eg.frames), rep(5,4),6:9,rep(10,4)),nrow=2,byrow=TRUE)
layout(layout.mat)

## plot some example 'frames' from the original video
i=1
while(i&lt;=length(eg.frames)) {
    par(mar=c(2,1,3,1))
    
    ## make the current title
    c.main = paste('Org. Frame ', eg.frames[i], sep='')
    image2(img.list[[eg.frames[i]]],axes=FALSE,main=c.main,cex.main=2,asp=1)
      
    i=i+1
}

## plot the spatiotemporal variations of the original and amplified video
par(mar=c(2,1,3,1))
image2(org.spat.temp, ylab='y',axes=FALSE,xaxs='i',asp=1)
mtext('y', side=2,line=0.5)
axis(1)
box()

## plot the same example frames from the amplified video
i=1
while(i&lt;=length(eg.frames)) {
    par(mar=c(2,1,3,1))
    ## make the current title
    c.main = paste('Amp. Frame ', eg.frames[i], sep='')
    
    ## add the image
    image2(amp.list[[eg.frames[i]]],axes=FALSE,main=c.main,cex.main=2,asp=1)
      
    i=i+1
}

par(mar=c(2,1,3,1))
image2(amp.spat.temp, xlab='',ylab='',axes=FALSE,xaxs='i',asp=1)
axis(3)
mtext('y', side=2,line=0.5)
mtext('frames', side=1,line=0.5)
box()


## set the layout and par back to the users original value
par(mfrow=c(1,1),mar=mar.org)

</code></pre>

<hr>
<h2 id='blob.extract'>
Extract Blob Region from Image (Matrix)
</h2><span id='topic+blob.extract'></span>

<h3>Description</h3>

<p>Find the predominant blob region in an image using a Laplacian of Gaussian (LoG) blob detection algorithm.  Blob points are found using a connected component algorithm (see Details)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blob.extract(img, blob.point, win.size, gaus, lap)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blob.extract_+3A_img">img</code></td>
<td>

<p>Matrix with numeric values representing pixel color intensities
</p>
</td></tr>
<tr><td><code id="blob.extract_+3A_blob.point">blob.point</code></td>
<td>

<p>x,y locations of a point that is contained within the sought after blob region.  Normally the image's max (or min) value location.
</p>
</td></tr>
<tr><td><code id="blob.extract_+3A_win.size">win.size</code></td>
<td>

<p>Window size used in connected component algorithm (see Details).
</p>
</td></tr>
<tr><td><code id="blob.extract_+3A_gaus">gaus</code></td>
<td>

<p>Low pass Gaussian mask that has same dimensions as img
</p>
</td></tr>
<tr><td><code id="blob.extract_+3A_lap">lap</code></td>
<td>

<p>Optional high pass Laplacian filter of same dimensions as img.  Defaults to standard 5-point stencil.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LoG algorithm first applies a Gaussian then a Laplacian operator to the image.  The resulting image is binarized (values either 0 or 1) depending on sign of values in the LoG Image.
</p>
<p>The blob x,y locations surrounding the <code>blob.point</code> and are found via a connected component algorithm.  This algorithm is designed for speed and may miss x,y locations if the blob is highly irregular or concave.  Adjusting the <code>win.size</code> can yield more accurate blob locations but has a slower run time.
</p>


<h3>Value</h3>

<p>List of length 2 where
</p>
<table>
<tr><td><code>xy.coords</code></td>
<td>
<p>Matrix of x,y locations of blob in image</p>
</td></tr>
<tr><td><code>bin.image</code></td>
<td>
<p>Image (matrix) of same dimension of <code>img</code> that gives the binarized result from the LoG Blob Detection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+build.gaus">build.gaus</a></code>
<code><a href="#topic+filt3d">filt3d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>############
### EG 1 ###
############
## example with synthetic data

## create an image that is a simple gaussian
img &lt;- build.gaus(100,100,sig.x=2,sig.y=10,x.mid=80,y.mid=60)

## find the where the maximum value is
img.max &lt;- which(img==max(img),arr.ind=TRUE)

## define a sigma for the low pass filter
sig=5

## define the low pass filter as another gaussian
lp.filt &lt;- build.gaus(nrow(img),ncol(img),sig.x=sig)

## define a window size for the connected component algorithm
win.size=0.05

## perform the blob detection
blob &lt;- blob.extract(img=img, blob.point=img.max,win.size=win.size,gaus=lp.filt)

####################
### PLOTTING EG1 ###
####################

## define x and y grid lines
grid.x &lt;- 1:nrow(img)
grid.y &lt;- 1:ncol(img)

dev.new()
close.screen(all.screens=TRUE)
split.screen(c(1,3))

screen(1)
image(grid.x,grid.y,img,main='Image')

screen(2)
image(grid.x,grid.y,blob$bin.image,col=gray.colors(2),main='Binarized LoG Image')

screen(3)
image(grid.x,grid.y,img,main='Img with Blob Detected')
points(blob$xy.coords,col='black',pch=16,cex=1)

## close the screens
close.screen(all.screens=TRUE)


############
### EG 2 ###
############
## example with volcano image data.
## This RBG image shows ash erupting above the crater, which is cropped out

data(sakurajima)

## crop accroding to these corner values
xleft = 1
xright = 188
ybottom = 1
ytop = 396

## crop the image using crop.image
cropped &lt;- crop.image(sakurajima, xleft, ybottom, xright, ytop)

## redefine the crop image
img &lt;- cropped$img.crop

######################
### PRE PROCESSING ###
######################

## separate the image into red, green, and blue images
r.img &lt;- img[,,1]
g.img &lt;- img[,,2]
b.img &lt;- img[,,3]

## remove the mean
r.img &lt;- r.img-mean(r.img)
g.img &lt;- g.img-mean(g.img)
b.img &lt;- b.img-mean(b.img)

## calculate the the plane trend...
r.img.trend &lt;- fit3d(r.img)
g.img.trend &lt;- fit3d(g.img)
b.img.trend &lt;- fit3d(b.img)

## remove the trend
r.img.dtrend &lt;- r.img-r.img.trend
g.img.dtrend &lt;- g.img-g.img.trend
b.img.dtrend &lt;- b.img-b.img.trend


################################
### SET UP SOME FILTER MASKS ###
################################

## define a sigma for the LP Gaussian Filter
gaus.sig=15

## build the Gaussian filter
gaus &lt;- build.gaus(nrow(img),ncol(img),gaus.sig)

## find the extreme (absolute valued maximum) value of each RGB channel
blob.r.point &lt;- which(abs(r.img.dtrend)==max(abs(r.img.dtrend)),arr.ind=TRUE)
blob.g.point &lt;- which(abs(g.img.dtrend)==max(abs(g.img.dtrend)),arr.ind=TRUE)
blob.b.point &lt;- which(abs(b.img.dtrend)==max(abs(b.img.dtrend)),arr.ind=TRUE)

## set a window size to be used in the connected component algorithm
win.size = 0.05

## extract the blob xy locations
blob.r &lt;- blob.extract(r.img.dtrend,blob.r.point,win.size,gaus)
blob.g &lt;- blob.extract(g.img.dtrend,blob.r.point,win.size,gaus)
blob.b &lt;- blob.extract(b.img.dtrend,blob.r.point,win.size,gaus)


####################
### PLOTTING EG2 ###
####################

## note the blob points (blob$xy.coords) must be adjusted according to
## where the origin (0,0) is located in R plots image plots
blob.coords.r  &lt;- blob.r$xy.coords
blob.coords.r[,1] &lt;- blob.r$xy.coords[,2]
blob.coords.r[,2] &lt;- (blob.r$xy.coords[,1]-nrow(r.img))*-1

blob.coords.g  &lt;- blob.g$xy.coords
blob.coords.g[,1] &lt;- blob.g$xy.coords[,2]
blob.coords.g[,2] &lt;- (blob.g$xy.coords[,1]-nrow(g.img))*-1

blob.coords.b  &lt;- blob.b$xy.coords
blob.coords.b[,1] &lt;- blob.b$xy.coords[,2]
blob.coords.b[,2] &lt;- (blob.b$xy.coords[,1]-nrow(b.img))*-1


## save the users options
mar.usr=par()$mar

dev.new()
close.screen(all.screen=TRUE)
par(mar=c(0,0,2,0))
split.screen(c(1,2))
split.screen(c(3,1),screen=2)

screen(1)
image2(sakurajima,asp=1,axes=FALSE)
rect(ybottom,nrow(sakurajima)-xleft,ytop,nrow(sakurajima)-xright,lwd=3,border='white',lty=3)
title('Original Image',line=0,font=2,col='white',cex=2,)

screen(3)
image2(r.img,asp=1,axes=FALSE)
points(blob.coords.r,col=rgb(1,0,0,alpha=0.05),pch=16,cex=0.3)
title('Red Channel',line=0,font=2,col='red',cex=2)

screen(4)
image2(g.img,asp=1,axes=FALSE)
points(blob.coords.g,col=rgb(0,1,0,alpha=0.05),pch=16,cex=0.3)
title('Green Channel',line=0,font=2,col='darkgreen',cex=2)

screen(5)
image2(b.img,asp=1,axes=FALSE)
points(blob.coords.b,col=rgb(0,0,1,alpha=0.05),pch=16,cex=0.3)
title('Blue Channel',line=0,font=2,col='darkblue',cex=2)

## return the users original margins and close screens
par(mar=mar.usr)
close.screen(all.screens=TRUE)

</code></pre>

<hr>
<h2 id='blob.stats'>
Blob Statistics from Erebus Volcano, Antarctica
</h2><span id='topic+blob.stats'></span>

<h3>Description</h3>

<p>Raw statistics output from <code>calc.blob.stats</code> that show a single bubble bursting event from the lava lake at Mount Erebus.  Each list component corresponds to statistics calculated from the red, green, and blue color channels from the image frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("blob.stats")</code></pre>


<h3>Format</h3>

<p>The format is:
List of 3
$ r: num [1:200, 1:14] 331 332 330 334 330 ...
$ g: num [1:200, 1:14] 567.15 568.84 -3.13 -3.08 -4.33 ...
$ b: num [1:200, 1:14] 454.8 473.3 461.6 476.2 -2.5 ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(blob.stats)
## maybe str(blob.stats) ; plot(blob.stats) ...
</code></pre>

<hr>
<h2 id='build.gaus'>
Build 2D Gaussian Image (Matrix)
</h2><span id='topic+build.gaus'></span>

<h3>Description</h3>

<p>Build a 2-dimensional Gaussian matrix for filtering, correlations, data testing, or other various uses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build.gaus(xdim, ydim, sig.x, sig.y, x.mid, y.mid)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build.gaus_+3A_xdim">xdim</code></td>
<td>

<p>size in the x dimension
</p>
</td></tr>
<tr><td><code id="build.gaus_+3A_ydim">ydim</code></td>
<td>

<p>size in the y dimension
</p>
</td></tr>
<tr><td><code id="build.gaus_+3A_sig.x">sig.x</code></td>
<td>

<p>Gaussian sqrt(variance) in x direction
</p>
</td></tr>
<tr><td><code id="build.gaus_+3A_sig.y">sig.y</code></td>
<td>

<p>Gaussian sqrt(variance) in y direction.  Defaults to <code>sig.x</code> if undefined
</p>
</td></tr>
<tr><td><code id="build.gaus_+3A_x.mid">x.mid</code></td>
<td>

<p>peak location in x direction
</p>
</td></tr>
<tr><td><code id="build.gaus_+3A_y.mid">y.mid</code></td>
<td>

<p>peak location in the y direction
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if <code>xdim</code> or <code>ydim</code> are even and <code>x.mid</code> and <code>y.mid</code> are left undefined, the Gaussian peak will be off center.  This can be a problem when using a Gaussian matrix for multiple filtering operations.
</p>


<h3>Value</h3>

<p>matrix with values corresponding to values in the 2D Gaussian.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
############
### EG 1 ###
############

## define the dimensions of the gaussian image (matrix)
xdim=101
ydim=101

## sigma in the x direction.  The y sigma defaults to the sig.x if not supplied
sig.x=5

## build the first example
gaus1 &lt;- build.gaus(xdim,ydim,sig.x)


###################
## PLOTTING EG 1 ##
###################
image(1:nrow(gaus1),1:ncol(gaus1),useRaster=TRUE,gaus1)


############
### EG 2 ###
############

## define the dimensions of the gaussian image (matrix)
xdim=101
ydim=201

## define a sigma in the both the x and y direction
sig.y=5
sig.y=20

## define the center (peak) location of the guassian
x.mid = 30
y.mid = 120

## now build the gaussian
gaus2 &lt;- build.gaus(xdim,ydim,sig.x,sig.y,x.mid,y.mid)

##################
## PLOTTING EG2 ##
##################
image(1:nrow(gaus2),1:ncol(gaus2),useRaster=TRUE,gaus2)

</code></pre>

<hr>
<h2 id='build.lap'>
Build 5-Point Laplacian Stencil
</h2><span id='topic+build.lap'></span>

<h3>Description</h3>

<p>Given an x and y dimension, build a five point stencil of matching dimensions whose values are either -4, 0, and 1 and whose sum = 0.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build.lap(xdim,ydim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build.lap_+3A_xdim">xdim</code></td>
<td>

<p>x dimension of desired matrix output
</p>
</td></tr>
<tr><td><code id="build.lap_+3A_ydim">ydim</code></td>
<td>

<p>y dimension of desired matrix output
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if <code>xdim</code> or <code>ydim</code> are even, the stencil values will be off center.  This can be a problem when using a Laplacian matrix for multiple filtering operations.
</p>


<h3>Value</h3>

<p>Matrix with dimensions equal to <code>xdim</code> and <code>ydim</code> with five point stencil located near the middle of the matrix (see Details). 
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+build.gaus">build.gaus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## build a 5 point stencil laplacian
lap=build.lap(9,9)
image(lap)
</code></pre>

<hr>
<h2 id='calc.blob.stats'>
Calculate Color and Spatial Statistics from Blob Region
</h2><span id='topic+calc.blob.stats'></span>

<h3>Description</h3>

<p>Wrapper function (see details) that calculates various statistics on x,y data that corresponds to an image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.blob.stats(img, xy.coords)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.blob.stats_+3A_img">img</code></td>
<td>

<p>Matrix whose values at <code>xy.coords</code> are statistically analyzed.
</p>
</td></tr>
<tr><td><code id="calc.blob.stats_+3A_xy.coords">xy.coords</code></td>
<td>

<p>Index locations corresponding region of interest (e.g. blob region) in the <code>img</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function calls multiple statistical functions (e.g. <code>mean</code>, <code>sd</code>) and applies them to regions in the <code>img</code> according to the index locations given by <code>xy.coords</code>.  In general, this function is commented to promote any modifications needed to fit the users needs.  For example, adding or removing statistical analyses is straight forward.
</p>


<h3>Value</h3>

<p>Numeric vector giving the statistics of the blob region.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>
<code><a href="stats.html#topic+sd">sd</a></code>
<code><a href="base.html#topic+sum">sum</a></code>
<code><a href="Matrix.html#topic+colMeans">colMeans</a></code>
<code><a href="Matrix.html#topic+rowMeans">rowMeans</a></code>
<code><a href="base.html#topic+length">length</a></code>
<code><a href="moments.html#topic+skewness">skewness</a></code>
<code><a href="moments.html#topic+kurtosis">kurtosis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
############
### EG 1 ###
############
## example with synthetic data

## create an image that is a simple gaussian
img &lt;- build.gaus(100,100,sig.x=2,sig.y=10,x.mid=80,y.mid=60)

## find the where the maximum value is
img.max &lt;- which(img==max(img),arr.ind=TRUE)

## define a sigma for the low pass filter
sig=5

## define the low pass filter as another gaussian
lp.filt &lt;- build.gaus(nrow(img),ncol(img),sig.x=sig)

## define a window size for the connected component algorithm
win.size=0.05

## perform the blob detection
blob &lt;- blob.extract(img=img, blob.point=img.max,win.size=win.size,gaus=lp.filt)

#################################
### CALCULATE BLOB STATISTICS ###
#################################

blob.stats &lt;- calc.blob.stats(img, blob$xy.coords)
print(blob.stats)


############
### EG 2 ###
############

## example with volcano image data.
data(sakurajima)

######################
### PRE PROCESSING ###
######################

## crop accroding to these corner values
xleft = 1
xright = 188
ybottom = 1
ytop = 396

## crop the image using crop.image
cropped &lt;- crop.image(sakurajima, xleft, ybottom, xright, ytop)

## redefine the crop image
img &lt;- cropped$img.crop

## separate the image into red, green, and blue images
r.img &lt;- img[,,1]
g.img &lt;- img[,,2]
b.img &lt;- img[,,3]

## remove the mean
r.img &lt;- r.img-mean(r.img)
g.img &lt;- g.img-mean(g.img)
b.img &lt;- b.img-mean(b.img)

## calculate the the plane trend...
r.img.trend &lt;- fit3d(r.img)
g.img.trend &lt;- fit3d(g.img)
b.img.trend &lt;- fit3d(b.img)

## remove the trend
r.img.dtrend &lt;- r.img-r.img.trend
g.img.dtrend &lt;- g.img-g.img.trend
b.img.dtrend &lt;- b.img-b.img.trend


################################
### SET UP SOME FILTER MASKS ###
################################

## define a sigma for the LP Gaussian Filter
gaus.sig=30

## build the Gaussian filter
gaus &lt;- build.gaus(nrow(img),ncol(img),gaus.sig)

## find the maximum value of each RGB channel
blob.r.point &lt;- which(r.img.dtrend==max(r.img.dtrend),arr.ind=TRUE)
blob.g.point &lt;- which(g.img.dtrend==max(g.img.dtrend),arr.ind=TRUE)
blob.b.point &lt;- which(b.img.dtrend==max(b.img.dtrend),arr.ind=TRUE)

## set a window size to be used in the connected component algorithm
win.size = 0.05

## extract the blob xy locations
blob.r &lt;- blob.extract(r.img.dtrend,blob.r.point,win.size,gaus)
blob.g &lt;- blob.extract(g.img.dtrend,blob.r.point,win.size,gaus)
blob.b &lt;- blob.extract(b.img.dtrend,blob.r.point,win.size,gaus)


#################################
### CALCULATE BLOB STATISTICS ###
#################################

r.blob.stats &lt;- calc.blob.stats(r.img.dtrend, blob.r$xy.coords)
g.blob.stats &lt;- calc.blob.stats(g.img.dtrend, blob.g$xy.coords)
b.blob.stats &lt;- calc.blob.stats(b.img.dtrend, blob.b$xy.coords)

print(r.blob.stats)
print(g.blob.stats)
print(b.blob.stats)

</code></pre>

<hr>
<h2 id='cor.mat'>
Correlate Matrix Rows
</h2><span id='topic+cor.mat'></span>

<h3>Description</h3>

<p>Wrapper function of ccf used to find best lag time between two vectors. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.mat(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor.mat_+3A_x">x</code></td>
<td>

<p>Vector. 
</p>
</td></tr>
<tr><td><code id="cor.mat_+3A_y">y</code></td>
<td>

<p>Vector. 
</p>
</td></tr>
<tr><td><code id="cor.mat_+3A_...">...</code></td>
<td>

<p>Additional arguments to pass to ccf (e.g. <code>max.lag</code>)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Scalar indicating the lag associated with the maximum correlation value between <code>x</code> and <code>y</code>.  
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ccf">ccf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate a time axis
tax = seq(0,10,by=0.1)

## generate two signals with a phase offset
sig1 &lt;- sin(2*pi*1/2*tax)
sig2 &lt;- sin(2*pi*1/2*tax + pi/2)

best.lag &lt;- cor.mat(sig1,sig2)

################
### PLOTTING ###
################

plot(sig1,type='l',col='blue',main=paste('lag is: ',best.lag,sep=''))
lines(sig2,col='green')

</code></pre>

<hr>
<h2 id='crop.image'>
Crop an Image
</h2><span id='topic+crop.image'></span>

<h3>Description</h3>

<p>Crop an image (matrix or array) with either pre determined bottom-left and top-right locations or interactively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crop.image(img, xleft, ybottom, xright, ytop, pick)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crop.image_+3A_img">img</code></td>
<td>

<p>matrix or array of image to crop
</p>
</td></tr>
<tr><td><code id="crop.image_+3A_xleft">xleft</code></td>
<td>

<p>left extreme of crop area
</p>
</td></tr>
<tr><td><code id="crop.image_+3A_ybottom">ybottom</code></td>
<td>

<p>bottom extreme of crop area
</p>
</td></tr>
<tr><td><code id="crop.image_+3A_xright">xright</code></td>
<td>

<p>right extreme of crop area
</p>
</td></tr>
<tr><td><code id="crop.image_+3A_ytop">ytop</code></td>
<td>

<p>top extreme of crop area
</p>
</td></tr>
<tr><td><code id="crop.image_+3A_pick">pick</code></td>
<td>

<p>logical value indicating whether crop region should be selected interactively (see details)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>if any of the <code>xleft</code>, <code>xright</code>, <code>ybottom</code>, <code>ytop</code> are missing, or if <code>pick</code> is <code>TRUE</code>, an interactive plot will aid in picking crop regions.  The original image will be plotted and the user must first select the bottom left corner, then the top right corner of the desired crop area.  A corresponding rectangle will be plotted indicating the current crop region.  If the region is sufficient, the user should then click <em>crop</em> in the top right corner of the plotting area.  If the region should be modified, the user should click <em>repick</em>.
</p>
<p>Note that the <code>xleft</code>, <code>xright</code>, <code>ybottom</code>, and <code>ytop</code> locations correspond to R's reference frame for matrices, which can be confusing.
</p>


<h3>Value</h3>

<p>List of length two with
</p>
<table>
<tr><td><code>img.crop</code></td>
<td>
<p>an object giving the cropped image with the same class (either matrix or array) of <code>img</code> </p>
</td></tr>
<tr><td><code>img.corners</code></td>
<td>
<p>a vector with length 4 giving the the left, right, bottom, and top crop coordinates in the original image. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+locator">locator</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
############
### EG 1 ###
############
## example where you know where to crop the image

sakurajima.crop &lt;- crop.image(sakurajima,xleft=146,ybottom=7,xright=203,ytop=256)
split.screen(c(1,2))
screen(1)
image2(sakurajima,asp=1,main='Original')
screen(2)
image2(sakurajima.crop[[1]],asp=1,main='Cropped')

## close screens
close.screen(all.screens=TRUE)

############
### EG 2 ###
############
## example where you choose where to crop using interactive plot

sakurajima.crop &lt;- crop.image(sakurajima)

split.screen(c(1,2))
screen(1)
image2(sakurajima,asp=1,main='Original')
screen(2)
image2(sakurajima.crop[[1]],asp=1,main='Cropped')
print(sakurajima.crop[[2]])

## close screens
close.screen(all.screens=TRUE)

</code></pre>

<hr>
<h2 id='erebus'>
Image of Erebus Volcano, Antarctica
</h2><span id='topic+erebus'></span>

<h3>Description</h3>

<p>JPEG image read in as an array where the third dimension corresponds to the red, green, and blue color channels.  Note the image has been compressed significantly to reduce the memory size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("erebus")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:300, 1:400, 1:3] 0.019768 0.0011 0.002516 0 0.000495 ...
</p>


<h3>References</h3>

<p>Witsil and Johnson (2018) &lt;10.1016/j.jvolgeores.2018.05.002&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(erebus)
image2(erebus,asp=1)
## maybe str(erebus) ; plot(erebus) ...
</code></pre>

<hr>
<h2 id='erebus.40'>
Image of Erebus Volcano, Antarctica
</h2><span id='topic+erebus.40'></span>

<h3>Description</h3>

<p>The 40th frame in a series of images that was recorded seconds prior to a bubble bursting event at Mount Erebus.
</p>
<p>JPEG image read in as an array where the third dimension corresponds to the red, green, and blue color channels.  Note the image has been compressed significantly to reduce the memory size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("erebus.40")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:225, 1:300, 1:3] 0.0588 0 0 0 0 ...
</p>


<h3>References</h3>

<p>Witsil and Johnson (2018) &lt;10.1016/j.jvolgeores.2018.05.002&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(erebus.40)
image2(erebus.40)
</code></pre>

<hr>
<h2 id='erebus.70'>
Image of Erebus Volcano, Antarctica
</h2><span id='topic+erebus.70'></span>

<h3>Description</h3>

<p>The 70th frame in a series of images that was recorded during a bubble bursting event at Mount Erebus.
</p>
<p>JPEG image read in as an array where the third dimension corresponds to the red, green, and blue color channels. Note the image has been compressed significantly to reduce the memory size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("erebus.70")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:225, 1:300, 1:3] 0.06667 0 0 0.02353 0.00392 ...
</p>


<h3>References</h3>

<p>Witsil and Johnson (2018) &lt;10.1016/j.jvolgeores.2018.05.002&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(erebus.70)
image2(erebus.70)
</code></pre>

<hr>
<h2 id='erebus.90'>
Image of Erebus Volcano, Antarctica
</h2><span id='topic+erebus.90'></span>

<h3>Description</h3>

<p>The 90th frame in a series of images that was recorded seconds after a bubble bursting event at Mount Erebus.
</p>
<p>JPEG image read in as an array where the third dimension corresponds to the red, green, and blue color channels. Note the image has been compressed significantly to reduce the memory size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("erebus.90")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:225, 1:300, 1:3] 0.03922 0.00392 0.01176 0 0.01569 ...
</p>


<h3>References</h3>

<p>Witsil and Johnson (2018) &lt;10.1016/j.jvolgeores.2018.05.002&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(erebus.90)
image2(erebus.90)
</code></pre>

<hr>
<h2 id='fftshift'>
Shift Zero Frequency to Center
</h2><span id='topic+fftshift'></span>

<h3>Description</h3>

<p>Rearranges matrix such that the first quadrant is swapped with the third and the second quadrant is swapped with the fourth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fftshift(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fftshift_+3A_x">x</code></td>
<td>

<p>matrix whose quadrants should be shifted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is generally used after applying an <code>fft</code> to force the zero-frequency to the middle of the matrix.
</p>
<p>Note that if the matrix <code>x</code> has even dimensions, the zero frequency will be 1 unit from the center.
</p>


<h3>Value</h3>

<p>Shifted matrix with same dimensions as <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fft">fft</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## build the four components of a matrix with four values (i.e. 1:4)
x1 &lt;- matrix(1,nrow=1,ncol=1)
x2 &lt;- x1+1
x3 &lt;- x2+1
x4 &lt;- x3+1

## combine all components together
x &lt;- rbind(cbind(x1,x2),cbind(x3,x4))

## shift the matrix
x.shift &lt;- fftshift(x)

## note the difference of the shifted and original
print(x)
print(x.shift)

################
### PLOTTING ###
################
## note the difference of the shifted and original graphically

close.screen(all.screens=TRUE)
split.screen(c(1,2))
screen(1)
image(x,main='Original',col=rainbow(4))
screen(2)
image(x.shift,main='FFT Shifted', col=rainbow(4))

## close screens
close.screen(all.screens=TRUE)

</code></pre>

<hr>
<h2 id='filt3d'>
Filter Image (Matrix) with Mask via Convolution
</h2><span id='topic+filt3d'></span>

<h3>Description</h3>

<p>Apply a filter mask to smooth, sharpen, shift, or otherwise modify an image (matrix)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filt3d(x, mask)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filt3d_+3A_x">x</code></td>
<td>

<p>Image (matrix) to be filtered
</p>
</td></tr>
<tr><td><code id="filt3d_+3A_mask">mask</code></td>
<td>

<p>Filter mask (matrix) with same dimensions as <code>x</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>x</code> and <code>mask</code> are convolved in the frequency domain via multiplication and returned to the spatial domain using the fast Fourier transform.
</p>


<h3>Value</h3>

<p>Filtered matrix with same dimensions as <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fft">fft</a></code>
<code><a href="#topic+fftshift">fftshift</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########
## EG 1 ##
##########
## example of a low pass filter

## generate test data
data &lt;- matrix(0,nrow=256,ncol=256)

box.width = 100
box.height = 100
box.mid=c(nrow(data)/2,ncol(data)/2)

## define where the box indices are
box.row.inds &lt;- (box.mid[1]-box.width/2):(box.mid[1]+box.width/2)
box.col.inds &lt;- (box.mid[2]-box.height/2):(box.mid[2]+box.height/2)

## create the box in the data matrix
data[box.row.inds,box.col.inds] = 1

## define the sigma in the low pass Gaussian filter
sig=5

## create a low pass Gaussian filter
gaus &lt;- build.gaus(nrow(data),ncol(data),sig)

## filter the data matrix with the Gaussian filter mask
data.lp &lt;- filt3d(data,gaus)


## PLOTTING EG1 ##

dev.new()
close.screen(all.screens=TRUE)
split.screen(c(1,3))

## set up some grid lines
grid.xs &lt;- 1:nrow(data)
grid.ys &lt;- 1:ncol(data)

screen(1)
image(grid.xs,grid.ys,data,col=gray.colors(200),useRaster=TRUE,main="Data")

screen(2)
image(grid.xs,grid.ys,gaus,col=gray.colors(200),useRaster=TRUE,main="Low Pass Gaussian Mask")

screen(3)
image(grid.xs,grid.ys,data.lp,col=gray.colors(200),useRaster=TRUE,main='Filtered Data')

## close screens
close.screen(all.screens=TRUE)


##########
## EG 2 ##
##########
## example of a high pass filter

## generate test data
data &lt;- matrix(0,nrow=256,ncol=256)

box.width = 100
box.height = 100
box.mid=c(nrow(data)/2,ncol(data)/2)

## define where the box indices are
box.row.inds &lt;- (box.mid[1]-box.width/2):(box.mid[1]+box.width/2)
box.col.inds &lt;- (box.mid[2]-box.height/2):(box.mid[2]+box.height/2)

## create the box in the data matrix
data[box.row.inds,box.col.inds] = 1

## find the middle of the data matrix
mid &lt;- c(nrow(data)/2,ncol(data)/2)

## create a 5-point Laplacian high pass filter
lap &lt;- matrix(0,nrow=nrow(data),ncol=ncol(data))
lap[(mid[1]-1):(mid[1]+1),mid[2]] = c(1,-4,1)
lap[mid[1],(mid[2]-1):(mid[2]+1)] = c(1,-4,1)

## perform  high pass filter on the data using the Laplacian mask
data.hp &lt;- filt3d(data,lap)


## PLOTTING EG2 ##

## set up some grid lines
grid.xs &lt;- 1:nrow(data)
grid.ys &lt;- 1:ncol(data)

dev.new()
close.screen(all.screens=TRUE)
split.screen(c(1,3))

screen(1)
image(grid.xs,grid.ys,data,col=gray.colors(200),useRaster=TRUE,main="Data")

screen(2)
image(grid.xs,grid.ys,lap,col=gray.colors(200),useRaster=TRUE,main="High Pass Laplacian Mask")

screen(3)
image(grid.xs,grid.ys,data.hp,col=gray.colors(200),useRaster=TRUE,main='Filtered Data')

## close screens
close.screen(all.screens=TRUE)


##########
## EG 3 ##
##########
## example of a shift transform filter

## generate test data
data &lt;- matrix(0,nrow=256,ncol=256)

box.width = 100
box.height = 100
box.mid=c(nrow(data)/2,ncol(data)/2)

## define where the box indices are
box.row.inds &lt;- (box.mid[1]-box.width/2):(box.mid[1]+box.width/2)
box.col.inds &lt;- (box.mid[2]-box.height/2):(box.mid[2]+box.height/2)

## create the box in the data matrix
data[box.row.inds,box.col.inds] = 1

## create a delta function at some (x,y) location
delta.x = 80
delta.y = 180
delta &lt;- matrix(0,nrow=nrow(data),ncol=ncol(data))
delta[delta.x,delta.y] = 1

## perform the shift transform filter
data.shift &lt;- filt3d(data,delta)


## PLOTTING EG3 ##

## set up some grid lines
grid.xs &lt;- 1:nrow(data)
grid.ys &lt;- 1:ncol(data)

dev.new()
close.screen(all.screens=TRUE)
split.screen(c(1,3))

screen(1)
image(grid.xs,grid.ys,data,col=gray.colors(200),useRaster=TRUE,main="Data")

screen(2)
image(grid.xs,grid.ys,delta,col=gray.colors(200),useRaster=TRUE,main="Shift Delta Mask")

screen(3)
image(grid.xs,grid.ys,data.shift,col=gray.colors(200),useRaster=TRUE,main='Filtered Data')

## close screens
close.screen(all.screens=TRUE)

</code></pre>

<hr>
<h2 id='fit3d'>
Fit a Plane to Image (Matrix) with SVD
</h2><span id='topic+fit3d'></span>

<h3>Description</h3>

<p>Find plane that best fits trend in image (matrix)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit3d(mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit3d_+3A_mat">mat</code></td>
<td>

<p>image (matrix) of values to fit plane to
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns the best fit plane with the DC offset included.  In other words average of the matrix values is added to the best fit plane within the function.
</p>


<h3>Value</h3>

<p>matrix with same dimensions as <code>mat</code> whose values represent the best fit plane.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## break the RGB image into 3 matrices
img.r &lt;- erebus[,,1]
img.g &lt;- erebus[,,2]
img.b &lt;- erebus[,,3]

## find the planar trend in the red channel
trend.r &lt;- fit3d(img.r)
trend.g &lt;- fit3d(img.g)
trend.b &lt;- fit3d(img.b)

## subtract the red channel trend from the original red channel image
img.r.detrend &lt;- img.r-trend.r
img.g.detrend &lt;- img.g-trend.g
img.b.detrend &lt;- img.b-trend.b

## combine the RGB detrended matrices into an array
img.detrend = array(dim=dim(erebus))
img.detrend[,,1] &lt;- img.r.detrend
img.detrend[,,2] &lt;- img.g.detrend
img.detrend[,,3] &lt;- img.b.detrend

################
### PLOTTING ###
################

close.screen(all.screens=TRUE)
split.screen(c(1,3))
screen(1)
image2(erebus,asp=1,main='Original Image',ylab='image rows',xlab='image cols')
screen(2)
image2(trend.r,asp=1,main='Fitted Trend',ylab='image rows',xlab='image cols')
screen(3)
image2(img.detrend,asp=1,main='Detrended Image',ylab='image rows',xlab='image cols')

## close screens
close.screen(all.screens=TRUE)

</code></pre>

<hr>
<h2 id='gen.eg.img.list'>
Generate Example Image List Data
</h2><span id='topic+gen.eg.img.list'></span>

<h3>Description</h3>

<p>Generates synthetic video data comprising noise around each frame's peripheral and a boxed region whose pixel values oscillate according to the input parameters.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.eg.img.list(dim.x, dim.y, fps, n.secs, sig.f, sig.peak, box.width, box.height)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.eg.img.list_+3A_dim.x">dim.x</code></td>
<td>

<p>x dimension of the video frames.  Defaults to 64 pixels.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_dim.y">dim.y</code></td>
<td>
 
<p>y dimension of the video frames.  Defaults to 64 pixels.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_fps">fps</code></td>
<td>
 
<p>Sampling rate of the synthetic video in frames per second.  Defaults to 30 frames per second.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_n.secs">n.secs</code></td>
<td>
 
<p>Number of seconds in the synthetic video.  Defaults to 3 s.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_sig.f">sig.f</code></td>
<td>
 
<p>Frequency at which the boxed region's pixel values oscillate.  Defaults to 2 Hz.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_sig.peak">sig.peak</code></td>
<td>
 
<p>Peak of signal.  Defaults to 0.2.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_box.width">box.width</code></td>
<td>
 
<p>Width of box region.  Defaults to 10 pixels.
</p>
</td></tr>
<tr><td><code id="gen.eg.img.list_+3A_box.height">box.height</code></td>
<td>
 
<p>Height of box region.  Defaults to 10 pixels.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use this function to create synthetic video data in the list structure required for functions like <code><a href="#topic+amp.sig">amp.sig</a></code> and <code><a href="#topic+sig.extract">sig.extract</a></code>.  
</p>
<p>Note that noise in the frames fluctuates between -1 and 1.  Therefore, if you choose <code>sig.peak&lt;1</code> in each frame the boxed region's pixel values will be below the signal to noise ratio.  If you were to 'play' this video (i.e. cycle through the list elements) the boxed region would be difficult or impossible to distinguish without first amplifying the signal using <code><a href="#topic+amp.sig">amp.sig</a></code>.
</p>


<h3>Value</h3>

<p>List whose elements correspond to individual video frames, each of which are separated by <code>1/fps</code>.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amp.sig">amp.sig</a></code> and <code><a href="#topic+sig.extract">sig.extract</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
###############
### INPUTS ####
###############

## x and y dimension of the frame
dim.x = 64
dim.y = 64

## sample rate in frames per second
fps = 30

## how many seconds does the video last
n.secs =3 

## what is the frequency at which the boxed region oscillates
sig.f = 2 

## what is the peak amplitude of the signal
sig.peak = 0.2 

## size of the boxed region
box.width = 10
box.height = 10

################################  
### GENERATE SYNTHETIC VIDEO ###
################################

## use the inputs to generate an image list (i.e. video)
img.list &lt;- gen.eg.img.list(dim.x, dim.y, fps, n.secs, sig.f, sig.peak, box.width, box.height)

## or use the defaults in the function
img.list &lt;- gen.eg.img.list()

</code></pre>

<hr>
<h2 id='image2'>
Plot Images (Matrices) with Intuitive Axes
</h2><span id='topic+image2'></span>

<h3>Description</h3>

<p>Plot images (array or matrix) using the <code>rasterImage</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>image2(img, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="image2_+3A_img">img</code></td>
<td>

<p>numeric matrix or array to plot
</p>
</td></tr>
<tr><td><code id="image2_+3A_...">...</code></td>
<td>

<p>additional arguments to pass to the <code>plot</code> function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note the difference in image orientation between <code>image()</code> and <code>image2()</code>.  These two plots will have the origin in different locations and can make things tricky when picking areas to crop, etc...
</p>


<h3>Value</h3>

<p>Nothing.  Returns a plotting window.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+rasterImage">rasterImage</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>image2(sakurajima)
</code></pre>

<hr>
<h2 id='pcorr3d'>
Phase Correlation of Images 
</h2><span id='topic+pcorr3d'></span>

<h3>Description</h3>

<p>Input two images (matrices) and perform phase correlation by multiplication in the frequency domain.  Return the maximum phase correlation value, its associated shift vector (x and y), and the phase correlation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcorr3d(img1,img2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcorr3d_+3A_img1">img1</code></td>
<td>

<p>Image (matrix) 1
</p>
</td></tr>
<tr><td><code id="pcorr3d_+3A_img2">img2</code></td>
<td>

<p>Image (matrix) 2 with same dimensions of <code>img1</code> 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Phase correlation calculated in the frequency domain as a multiplication.  The dimensions of <code>img1</code> and <code>img2</code> must match.  If <code>pcorr3d</code> is used to apply a match filter, it is logical to input the image to be searched over as <code>img1</code> and the match filter as <code>img2</code>.  Similarly, if tracking relative motion between images, it is logical to input the first image at time t=n as <code>img1</code> and the second image at time t=n+1 as <code>img2</code>, otherwise motions will backwards.  
</p>


<h3>Value</h3>

<p>List whose values correspond to:
</p>
<table>
<tr><td><code>max.shifts</code></td>
<td>
<p>Vector of length two whose values are the x and y indices associated with the highest phase correlation value.  Note these values are shifted according to the zero frequency which changes depending on the dimensions of <code>img1</code> and/or <code>img2</code>.</p>
</td></tr>
<tr><td><code>max.corr</code></td>
<td>
<p>Highest normalized phase correlation value in the correlation matrix</p>
</td></tr>
<tr><td><code>corr.mat</code></td>
<td>
<p>Normalized phase correlation matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+xcorr3d">xcorr3d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#################
### Example 1 ###
#################
## track movement between images

## load in the images
data(tux1,tux2)

## now find the shift vector by using the phase correlation function 
shifts &lt;- pcorr3d(tux1,tux2)

## ---- Plotting Example 1  ----- ##

split.screen(c(1,2))
screen(1)
image(1:nrow(tux1),1:ncol(tux1),tux1,col=gray.colors(200))

## define an example arrow starting and end points based on the shift found
x0 = nrow(tux1)/2
y0 = ncol(tux1)/2
x1 = x0 + shifts$max.shifts[1]
y1 = y0 + shifts$max.shifts[2]

## add arrows indicating how the image shifted
arrows(x0,y0,x1,y1)

## add a point where the arrow is
points(nrow(tux1)/2+shifts$max.shifts[1],ncol(tux1)/2+shifts$max.shifts[2],pch=21,bg='green')

screen(2)
image(1:nrow(tux2),1:ncol(tux2),tux2,col=gray.colors(200))
points(nrow(tux1)/2+shifts$max.shifts[1],ncol(tux1)/2+shifts$max.shifts[2],pch=21,bg='green')

## close the screen
close.screen(all.screens=TRUE)

</code></pre>

<hr>
<h2 id='points2'>
Plot points on image 
</h2><span id='topic+points2'></span>

<h3>Description</h3>

<p>This is a plotting function that should be used with <code>image2</code>.  This function is in line with <code>image2</code>, which locates the origin to the top-left corner as opposed to the bottom-left as <code>image</code> does.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>points2(x,y,img,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="points2_+3A_x">x</code></td>
<td>

<p>x location of points to plot
</p>
</td></tr>
<tr><td><code id="points2_+3A_y">y</code></td>
<td>

<p>y location of points to plot
</p>
</td></tr>
<tr><td><code id="points2_+3A_img">img</code></td>
<td>

<p>original image (matrix) which was plotted using <code>image2</code>.  This is supplied simply for dimensional information. 
</p>
</td></tr>
<tr><td><code id="points2_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed to <code>points</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing.  This is a plotting function.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+image2">image2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## build a test matrix
mat = matrix(0,nrow=20,ncol=20)
mat[1,1]=1

image2(mat,axes=FALSE,xlab='',ylab='')
points2(1,1,img=mat,col='red',pch=16)
</code></pre>

<hr>
<h2 id='range01'>
Scale Object Values Between Zero and One
</h2><span id='topic+range01'></span>

<h3>Description</h3>

<p>Force the minimum value and maximum value of an object to 0 and 1, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>range01(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="range01_+3A_x">x</code></td>
<td>

<p>Matrix, vector, or other R object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with same dimensions as <code>x</code> and whose values range between zero and one.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate a signal to normalize
sig &lt;- 10*sin(2*pi*5*seq(0,1,by=0.001))

## normalize between 0 and 1
sig01 &lt;- range01(sig)

## check the ranges
range(sig)
##[1] -10 10
range(sig01)
##[1] 0 1
</code></pre>

<hr>
<h2 id='run.avg'>
Perform Running Average via Convolution
</h2><span id='topic+run.avg'></span>

<h3>Description</h3>

<p>Smooth input data by convolution it with with a boxcar function of specified width.  This is done in the frequency domain using multiplication.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run.avg(data, win)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run.avg_+3A_data">data</code></td>
<td>

<p>signal (vector) to convolve.
</p>
</td></tr>
<tr><td><code id="run.avg_+3A_win">win</code></td>
<td>

<p>width of the boxcar in samples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Convolution occurs in the frequency domain via a multiplication.
</p>


<h3>Value</h3>

<p>Smoothed vector with the same dimension as <code>data</code>
</p>


<h3>Note</h3>

<p>This function uses <code>fft</code> which can take significantly long run times if the input signal is prime or is divisible by few integers.
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fft">fft</a></code>
<code><a href="#topic+fftshift">fftshift</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## make a delta 2D (time series) function
delta &lt;- rep(0,101)
delta[floor(length(delta)/2)] = 1

## define a window length to average over
win = 20

## filter the delta function...this will result in a boxcar
box.car &lt;- run.avg(delta,win)

## note sum(box.car) should equal the sum of the original signal...
## in this case sum(box.car)==1

##############
## PLOTTING ##
##############

plot(delta,type='h',lwd=2)
lines(box.car,col='blue',lwd=2,type='h')

legend('topright',col=c('black','blue'),legend=c('delta','running average'),lwd=2)
</code></pre>

<hr>
<h2 id='sakurajima'>
Image of Sakurajima Volcano, Japan
</h2><span id='topic+sakurajima'></span>

<h3>Description</h3>

<p>JPEG image read in as an array where the third dimension corresponds to the red, green, and blue color channels.  Note the image has been compressed significantly to reduce the memory size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("sakurajima")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:300, 1:400, 1:3] 0.471 0.475 0.475 0.478 0.475 ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(sakurajima)
image2(sakurajima,asp=1)

</code></pre>

<hr>
<h2 id='shift.vec'>
Shift Vector
</h2><span id='topic+shift.vec'></span>

<h3>Description</h3>

<p>Shift a vector to the left or right by a certain amount (i.e. perform a simple phase shift).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shift.vec(shift, vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shift.vec_+3A_shift">shift</code></td>
<td>

<p>Amount of samples to shift vector in either the positive or negative direction. 
</p>
</td></tr>
<tr><td><code id="shift.vec_+3A_vec">vec</code></td>
<td>

<p>Vector to shift. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The shift is accomplished by padding the head or tail of the vector with <code>NA</code> values. 
</p>


<h3>Value</h3>

<p>Shifted vector.  
</p>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate a delta function
vec=rep(0,5)
vec[3] = 1 

## shift vector by -2
new.vec = shift.vec(-2,vec)

</code></pre>

<hr>
<h2 id='sig.extract'>
Extract Time-Series Signal from Video Data
</h2><span id='topic+sig.extract'></span>

<h3>Description</h3>

<p>This function investigates time variations of pixel values in video frames via both a simple stack and also a cross correlation analysis.  Both methods attempt to highlight signals present within video data. See Details.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sig.extract(img.list, fps, base.vec, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sig.extract_+3A_img.list">img.list</code></td>
<td>

<p>A series of images saved in a list.  Each list element is a matrix that represents pixel values of an image, the dimensions of which correspond to the rows and columns of the matrix.
</p>
</td></tr>
<tr><td><code id="sig.extract_+3A_fps">fps</code></td>
<td>

<p>Sample rate of video in frames per second (FPS).  Each list element of <code>img.list</code> should be separated by <code>1/fps</code> seconds. Defaults to 30. 
</p>
</td></tr>
<tr><td><code id="sig.extract_+3A_base.vec">base.vec</code></td>
<td>

<p>Vector to correlate all pixel signals with.  Defaults to <code>rowMeans(img.series)</code>.
</p>
</td></tr>
<tr><td><code id="sig.extract_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to ccf (i.e., <code>lag.max</code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm first synthesizes the video frames into a matrix of time series signals. In other words, a time-series is generated for each pixel that records the value of that pixel in each frame.  These original pixel time-series are then simply stacked and then analyzed in terms of their frequency components.  Additionally, each pixel time-series is cross correlated with the <code>base.vec</code> and then shifted according to the lag associated with the maximum correlation value.  These shifted time-series are then stacked and analyzed in terms of their frequency components.  
</p>
<p>Note the function gives two basic outputs.  The first is a simple stack (without applying any shift to the pixel time-series), while the second applies a shift then stack.  Both outputs may prove useful and should be investigated. 
</p>


<h3>Value</h3>

<p>List of length four whose elements correspond to both original and shifted stacks.  Note the nomenclature is that lower case objects correspond to time-series data while upper case corresponds to frequency domain data.  
</p>
<table>
<tr><td><code>org</code></td>
<td>
<p>Matrix of stacked time-series from original pixel values.  The first column corresponds to the time axis while second column is the stacked values.</p>
</td></tr>
<tr><td><code>ORG</code></td>
<td>
<p>Matrix of stacked frequency components from original pixel values.  The first column corresponds to the frequency axis while second column is the stacked frequency amplitudes.</p>
</td></tr>
<tr><td><code>shifted</code></td>
<td>
<p>Matrix of stacked time-series from shifted pixel values.  The first column corresponds to the time axis while second column is the stacked values.</p>
</td></tr>
<tr><td><code>SHIFTED</code></td>
<td>
<p>Matrix of stacked frequency components from shifted pixel values.  The first column corresponds to the frequency axis while second column is the stacked frequency amplitudes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gen.eg.img.list">gen.eg.img.list</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##############################
### SYNTHETIC VIDEO INPUTS ###
##############################

## x and y dimension of the frame
dim.x = 64
dim.y = 64

## sample rate in frames per second
fps = 30

## how many seconds does the video last
n.secs = 3 

## what is the frequency at which the boxed region oscillates
sig.f = 2 

## what is the peak amplitude of the signal
sig.peak = 0.5

## size of the boxed region
box.width = 20
box.height = 20


################################
### GENERATE SYNTHETIC VIDEO ###
################################

## use the inputs to generate an image list (i.e. video)
img.list &lt;- gen.eg.img.list(dim.x, dim.y, fps, n.secs, sig.f, sig.peak, box.width, box.height)


#################################
### EXTRACT SIGNAL FROM VIDEO ###
#################################

sig.x &lt;- sig.extract(img.list,fps)

################
### PLOTTING ###
################

## set up a plot
split.screen(c(1,2))
screen(1)
plot(sig.x$org,col='blue',type='l',main='Time Domain')
lines(sig.x$shifted,col='red')

screen(2)
plot(sig.x$ORG,col='blue',type='l',xlim=c(0,5),main='Frequency Domain')
lines(sig.x$SHIFTED,col='red')

## close the screens
close.screen(all.screens=TRUE)


</code></pre>

<hr>
<h2 id='tux1'>
Image of Tux
</h2><span id='topic+tux1'></span>

<h3>Description</h3>

<p>Gray scaled image of Tux, the Linux Penguin.  Here Tux is centered in the image.  Originally this was a gray scaled jpeg image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tux1")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:56, 1:66] 0.996 0.996 0.996 0.996 0.996 ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tux1)
## maybe str(tux1) ; plot(tux1) ...
</code></pre>

<hr>
<h2 id='tux2'>
Image of Tux
</h2><span id='topic+tux2'></span>

<h3>Description</h3>

<p>Gray scaled image of Tux, the Linux Penguin.  Here Tux is shifted to the bottom right of the image.  Originally this was a gray scaled jpeg image.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("tux2")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:56, 1:66] 0.996 0.996 0.996 0.996 0.996 ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tux2)
## maybe str(tux2) ; plot(tux2) ...
</code></pre>

<hr>
<h2 id='xcorr3d'>
Normalized Cross Correlation of Images 
</h2><span id='topic+xcorr3d'></span>

<h3>Description</h3>

<p>Input two images (matrices) and perform normalized cross correlation by multiplication in the frequency domain.  Return the maximum normalized cross correlation value, its associated shift vector (x and y), and the correlation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xcorr3d(img1,img2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xcorr3d_+3A_img1">img1</code></td>
<td>

<p>Image (matrix) 1
</p>
</td></tr>
<tr><td><code id="xcorr3d_+3A_img2">img2</code></td>
<td>

<p>Image (matrix) 2 with same dimensions of <code>img1</code> 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Correlation calculated in the frequency domain as a multiplication.  The dimensions of <code>img1</code> and <code>img2</code> must match.  If <code>xcorr3d</code> is used to apply a match filter, it is logical to input the image to be searched over as <code>img1</code> and the match filter as <code>img2</code>.  Similarly, if tracking relative motion between images, it is logical to input the first image at time t=n as <code>img1</code> and the second image at time t=n+1 as <code>img2</code>, otherwise motions will backwards.  
</p>


<h3>Value</h3>

<p>List whose values correspond to:
</p>
<table>
<tr><td><code>max.shifts</code></td>
<td>
<p>Vector of length two whose values are the x and y indices associated with the highest correlation value.  Note these values are shifted according to the zero frequency which changes depending on the dimensions of <code>img1</code> and/or <code>img2</code>.</p>
</td></tr>
<tr><td><code>max.corr</code></td>
<td>
<p>Highest normalized correlation value in the correlation matrix</p>
</td></tr>
<tr><td><code>corr.mat</code></td>
<td>
<p>Normalized correlation matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alex J.C. Witsil
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcorr3d">pcorr3d</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
############################
### Optical Flow Example ###
############################
## track movement between images

## set up the image domain
xdim = 256
ydim = 256

## shift vectors accounting for movement between the two images
x.vec = 100
y.vec = 100

## declare the indices where the Gaussian peak will be in the first image
gaus1.x = 50
gaus1.y = 50

## shift the Gaussian according to the shift vector
gaus2.x &lt;- gaus1.x + x.vec
gaus2.y &lt;- gaus1.y + y.vec

## create the first synthetic image
img1 = build.gaus(xdim,ydim,sig.x=10,x.mid=gaus1.x,y.mid=gaus1.y)

## create the second synthetic image
img2 = build.gaus(xdim,ydim,sig.x=10,x.mid=gaus1.x+x.vec,y.mid=gaus1.y+y.vec)

## now find the shift vector by using the cross correlation function 
shifts &lt;- xcorr3d(img1,img2)

#############################
### Plotting Optical Flow ###
#############################

split.screen(c(1,2))
screen(1)
image(1:xdim,1:ydim,img1)

## add arrows indicating how the image shifted
arrows(gaus1.x,gaus1.y,gaus1.x+shifts$max.shifts[1],gaus1.y+shifts$max.shifts[2])

## add a point where the arrow is
points(gaus1.x+shifts$max.shifts[1],gaus1.y+shifts$max.shifts[2],pch=21,bg='green')

screen(2)
image(1:xdim,1:ydim,img2)

## add the point showing where the arrow is pointing
points(gaus1.x+shifts$max.shifts[1],gaus1.y+shifts$max.shifts[2],pch=21,bg='green')

## close the screen
close.screen(all.screens=TRUE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
