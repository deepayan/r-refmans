<!DOCTYPE html><html><head><title>Help for package prospectr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<script type="text/javascript" src="mathjax-config.js"></script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {prospectr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#prospectr-package'><p>Overview of the functions in the prospectr package</p></a></li>
<li><a href='#baseline'><p>baseline</p></a></li>
<li><a href='#binning'><p>Signal binning</p></a></li>
<li><a href='#bitAND'><p>bitwise operations</p></a></li>
<li><a href='#blockNorm'><p>Sum of squares block weighting</p></a></li>
<li><a href='#blockScale'><p>Hard or soft block scaling</p></a></li>
<li><a href='#cochranTest'><p>Cochran <em>C</em> Test</p></a></li>
<li><a href='#continuumRemoval'><p>Continuum Removal</p></a></li>
<li><a href='#convCppM'><p>Convolve</p></a></li>
<li><a href='#Cul'><p>Cochran C critical value</p></a></li>
<li><a href='#detrend'><p>Detrending spectral data</p></a></li>
<li><a href='#duplex'><p>DUPLEX algorithm for calibration sampling</p></a></li>
<li><a href='#e2m'><p>A function for transforming a matrix from its Euclidean space to its Mahalanobis space</p></a></li>
<li><a href='#fastDist'><p>A fast distance algorithm for two matrices written in C++</p></a></li>
<li><a href='#fastDistV'><p>A fast distance algorithm for a matrix and a vector written in C++</p></a></li>
<li><a href='#gapDer'><p>Gap-Segment derivative</p></a></li>
<li><a href='#get_msc_coeff'><p>get_msc_coeff</p></a></li>
<li><a href='#get_nircal_comments'><p>get the comments of the spectra in the nircal file</p></a></li>
<li><a href='#get_nircal_description'><p>get the description of the spectra in the nircal file</p></a></li>
<li><a href='#get_nircal_indices'><p>get the positions of relevant data witihi the nircal file</p></a></li>
<li><a href='#get_nircal_lengthspc'><p>get the number of spectral variables in the nircaa file</p></a></li>
<li><a href='#get_nircal_metadata'><p>get the metadata of the samples in the nircal file</p></a></li>
<li><a href='#get_nircal_response'><p>get the response variables in the nircal file</p></a></li>
<li><a href='#get_nircal_spectra'><p>get the spectra in the nircal file</p></a></li>
<li><a href='#honigs'><p>Honigs algorithm for calibration sampling</p></a></li>
<li><a href='#kenStone'><p>Kennard-Stone algorithm for calibration sampling</p></a></li>
<li><a href='#movav'><p>Moving average</p></a></li>
<li><a href='#msc'><p>Multiplicative Scatter Correction (msc)</p></a></li>
<li><a href='#naes'><p>k-means sampling</p></a></li>
<li><a href='#NIRsoil'><p>NIRSoil</p></a></li>
<li><a href='#pkg_info'><p>Get the package version info</p></a></li>
<li><a href='#puchwein'><p>Puchwein algorithm for calibration sampling</p></a></li>
<li><a href='#read_nircal'><p>Import BUCHI NIRCal files</p></a></li>
<li><a href='#readASD'><p>Read ASD FieldSpec Pro binary and ASCII files</p></a></li>
<li><a href='#resample'><p>Resample spectral data</p></a></li>
<li><a href='#resample_fwhm'><p>Resample to given band position and fwhm</p></a></li>
<li><a href='#resample2'><p>Resample a high resolution signal to a low resolution signal using full</p>
width half maximum (FWHM) values</a></li>
<li><a href='#savitzkyGolay'><p>Savitzky-Golay smoothing and differentiation</p></a></li>
<li><a href='#shenkWest'><p>SELECT algorithm for calibration sampling</p></a></li>
<li><a href='#spliceCorrection'><p>Splice correction of a spectral matrix acquired with an ASD spectrometer</p></a></li>
<li><a href='#sqrtSm'><p>Square root of (square) symetric matrices</p></a></li>
<li><a href='#standardNormalVariate'><p>Standard normal variate transformation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Miscellaneous Functions for Processing and Sample Selection of
Spectroscopic Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-16</td>
</tr>
<tr>
<td>Author:</td>
<td>
    Antoine Stevens [aut, cre] (&lt;https://orcid.org/0000-0002-1588-7519&gt;), 
    Leonardo Ramirez-Lopez [aut, cre] (&lt;https://orcid.org/0000-0002-5369-5120&gt;)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Leonardo Ramirez-Lopez &lt;ramirez.lopez.leo@gmail.com&gt;</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/l-ramirez-lopez/prospectr/issues">https://github.com/l-ramirez-lopez/prospectr/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to preprocess spectroscopic data 
    and conduct (representative) sample selection/calibration sampling.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/l-ramirez-lopez/prospectr">https://github.com/l-ramirez-lopez/prospectr</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, formatR, testthat, bookdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach, iterators, Rcpp (&ge; 1.0.1), mathjaxr (&ge; 1.0),
lifecycle (&ge; 0.2.0)</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>mathjaxr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Config/VersionName:</td>
<td>cakes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-16 14:41:34 UTC; leo</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-16 15:10:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='prospectr-package'>Overview of the functions in the prospectr package</h2><span id='topic+prospectr-package'></span><span id='topic+prospectr'></span>

<h3>Description</h3>

<a href='https://www.tidyverse.org/lifecycle/#stable'><img src='figures/lifecycle-stable.svg' alt='Stable lifecycle'></a>
<p>Misc functions for spectral data
<img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>This package implements a number of functions useful for
pre-processing spectral data well as for selecting representative samples/spectra.
The functions included here are particularly useful in Near-Infrared and Infrared
Spectroscopy applications.
</p>


<h3>Details</h3>

<p>#' This is the version
0.2.7 &ndash; cakes of the package.
The main functionality is listed here.
</p>
<p>Currently, the following preprocessing functions are available:
</p>

<ul>
<li><p><code><a href="#topic+resample">resample</a></code>
</p>
</li>
<li><p><code><a href="#topic+resample2">resample2</a></code>
</p>
</li>
<li><p><code><a href="#topic+movav">movav</a></code>
</p>
</li>
<li><p><code><a href="#topic+standardNormalVariate">standardNormalVariate</a></code>
</p>
</li>
<li><p><code><a href="#topic+msc">msc</a></code>
</p>
</li>
<li><p><code><a href="#topic+detrend">detrend</a></code>
</p>
</li>
<li><p><code><a href="#topic+baseline">baseline</a></code>
</p>
</li>
<li><p><code><a href="#topic+blockScale">blockScale</a></code>
</p>
</li>
<li><p><code><a href="#topic+blockNorm">blockNorm</a></code>
</p>
</li>
<li><p><code><a href="#topic+binning">binning</a></code>
</p>
</li>
<li><p><code><a href="#topic+savitzkyGolay">savitzkyGolay</a></code>
</p>
</li>
<li><p><code><a href="#topic+gapDer">gapDer</a></code>
</p>
</li>
<li><p><code><a href="#topic+continuumRemoval">continuumRemoval</a></code>
</p>
</li></ul>

<p>For the selection of representative samples/observations for calibrating
spectral models the following functions ca be used:
</p>

<ul>
<li><p><code><a href="#topic+naes">naes</a></code>
</p>
</li>
<li><p><code><a href="#topic+honigs">honigs</a></code>
</p>
</li>
<li><p><code><a href="#topic+shenkWest">shenkWest</a></code>
</p>
</li>
<li><p><code><a href="#topic+kenStone">kenStone</a></code>
</p>
</li>
<li><p><code><a href="#topic+duplex">duplex</a></code>
</p>
</li>
<li><p><code><a href="#topic+puchwein">puchwein</a></code>
</p>
</li></ul>

<p>Other useful functions are also available:
</p>

<ul>
<li><p><code><a href="#topic+read_nircal">read_nircal</a></code>
</p>
</li>
<li><p><code><a href="#topic+readASD">readASD</a></code>
</p>
</li>
<li><p><code><a href="#topic+spliceCorrection">spliceCorrection</a></code>
</p>
</li>
<li><p><code><a href="#topic+cochranTest">cochranTest</a></code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Leonardo Ramirez-Lopez <a href="mailto:ramirez.lopez.leo@gmail.com">ramirez.lopez.leo@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Antoine Stevens (<a href="https://orcid.org/0000-0002-1588-7519">ORCID</a>)
</p>
</li>
<li><p> Leonardo Ramirez-Lopez (<a href="https://orcid.org/0000-0002-5369-5120">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/l-ramirez-lopez/prospectr">https://github.com/l-ramirez-lopez/prospectr</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/l-ramirez-lopez/prospectr/issues">https://github.com/l-ramirez-lopez/prospectr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='baseline'>baseline</h2><span id='topic+baseline'></span>

<h3>Description</h3>

<a href='https://www.tidyverse.org/lifecycle/#maturing'><img src='figures/lifecycle-maturing.svg' alt='Maturing lifecycle'></a>
<p>Fits a baseline to each spectrum in a matrix and removes it from the
corresponding input spectrum. A vector can also be passed to this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>baseline(X, wav)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="baseline_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process (optionally a data frame that
can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="baseline_+3A_wav">wav</code></td>
<td>
<p>optional. A numeric vector of band positions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The baseline function find points lying on the convex hull
of a spectrum, connects the points by linear interpolation and
subtracts the interpolated line (baseline) from the corresponding spectrum.
</p>


<h3>Value</h3>

<p>a matrix or vector with the baselined spectra. The resulting matrix
is output with an attribute called <code>baselines</code> which contain the spectra
of the fitted baselines.
</p>
<p>This function is similar to <code><a href="#topic+continuumRemoval">continuumRemoval</a></code> and it might
replace some of its functionality in the future.
</p>


<h3>Author(s)</h3>

<p><a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
with contributions from Mervin Manalili
</p>


<h3>See Also</h3>

<p><code><a href="#topic+savitzkyGolay">savitzkyGolay</a></code>, <code><a href="#topic+movav">movav</a></code>,
<code><a href="#topic+gapDer">gapDer</a></code>, <code><a href="#topic+binning">binning</a></code>, <code><a href="#topic+continuumRemoval">continuumRemoval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# plot of the 5 first absorbance spectra
matplot(wav,
  t(NIRsoil$spc[1:5, ]),
  type = "l",
  ylim = c(0, .6),
  xlab = "Wavelength /nm",
  ylab = "Absorbance"
)

bs &lt;- baseline(NIRsoil$spc, wav)
matlines(wav, t(bs[1:5, ]))

fitted_baselines &lt;- attr(bs, "baselines")
matlines(wav, t(fitted_baselines[1:5, ]))
title("Original spectra, baselines and baselined spectra")
</code></pre>

<hr>
<h2 id='binning'>Signal binning</h2><span id='topic+binning'></span>

<h3>Description</h3>

<p>Compute average values of a signal in pre-determined bins (col-wise subsets).
The bin size can be determined either directly or by specifying the number of
bins. Sometimes called boxcar transformation in signal processing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binning(X, bins, bin.size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binning_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process (optionally a data frame that
can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="binning_+3A_bins">bins</code></td>
<td>
<p>the number of bins.</p>
</td></tr>
<tr><td><code id="binning_+3A_bin.size">bin.size</code></td>
<td>
<p>the desired size of the bins.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix or vector with average values per bin.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens &amp; <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+savitzkyGolay">savitzkyGolay</a></code>, <code><a href="#topic+movav">movav</a></code>,
<code><a href="#topic+gapDer">gapDer</a></code>, <code><a href="#topic+continuumRemoval">continuumRemoval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))

# 5 first spectra
matplot(wav, t(NIRsoil$spc[1:5, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "Absorbance"
)

NIRsoil$spc_binned &lt;- binning(NIRsoil$spc, bin.size = 20)

# bin means
matpoints(as.numeric(colnames(NIRsoil$spc_binned)),
  t(NIRsoil$spc_binned[1:5, ]),
  pch = 1:5
)

NIRsoil$spc_binned &lt;- binning(NIRsoil$spc, bins = 20)
dim(NIRsoil$spc_binned) # 20 bins

# 5 first spectra
matplot(wav,
  t(NIRsoil$spc[1:5, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "Absorbance"
)

# bin means
matpoints(as.numeric(colnames(NIRsoil$spc_binned)),
  t(NIRsoil$spc_binned[1:5, ]),
  pch = 1:5
)
</code></pre>

<hr>
<h2 id='bitAND'>bitwise operations</h2><span id='topic+bitAND'></span>

<h3>Description</h3>

<p>bitwise operations  in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bitAND(aa, bb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bitAND_+3A_aa">aa</code></td>
<td>
<p>integer</p>
</td></tr>
<tr><td><code id="bitAND_+3A_bb">bb</code></td>
<td>
<p>integer</p>
</td></tr>
</table>

<hr>
<h2 id='blockNorm'>Sum of squares block weighting</h2><span id='topic+blockNorm'></span>

<h3>Description</h3>

<p>Sum of squares block weighting: allows to scale blocks of variables,
but keeping the relative weights of the variables inside a block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockNorm(X, targetnorm = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blockNorm_+3A_x">X</code></td>
<td>
<p>a numeric matrix to transform (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="blockNorm_+3A_targetnorm">targetnorm</code></td>
<td>
<p>desired sum of squares for a block of variables
(default = 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes a scaling factor, which, multiplied by the
input matrix,
produces a matrix with a pre&ndash;determined sum of squares.
</p>


<h3>Value</h3>

<p>a list with components <code>Xscaled</code>, the scaled matrix and <code>f</code>, the
scaling factor
</p>


<h3>Note</h3>

<p>This is a <span class="rlang"><b>R</b></span> port of the &lsquo;<span class="file">MBnorm.m</span>&rsquo; function of the MB matlab toolbox
by Fran van den Berg.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Eriksson, L., Johansson, E., Kettaneh, N., Trygg, J.,
Wikstrom, C., and Wold, S., 2006. Multi- and Megavariate Data Analysis.
MKS Umetrics AB.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockScale">blockScale</a></code>, <code><a href="#topic+standardNormalVariate">standardNormalVariate</a></code>,
<code><a href="#topic+detrend">detrend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(100), ncol = 10)
# Block normalize to sum of square equals to 1
res &lt;- blockNorm(X, targetnorm = 1)
sum(res$Xscaled^2) # check
</code></pre>

<hr>
<h2 id='blockScale'>Hard or soft block scaling</h2><span id='topic+blockScale'></span>

<h3>Description</h3>

<p>Hard or soft block scaling of a spectral matrix to constant group variance.
In multivariate calibration, block scaling is used to down-weight variables,
when one block of variables dominates other blocks.
With hard block scaling, the variables in a block are scaled so that the sum
of their variances equals 1. When soft block scaling is used, the variables
are scaled such that the sum of variable variances is equal to the square
root of the number of variables in a particular block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockScale(X, type = 'hard', sigma2 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blockScale_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process (optionally a data frame that
can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="blockScale_+3A_type">type</code></td>
<td>
<p>the type of block scaling: 'hard' or 'soft'.</p>
</td></tr>
<tr><td><code id="blockScale_+3A_sigma2">sigma2</code></td>
<td>
<p>the desired total variance of a block (ie sum of the variances
of all variables, default = 1), applicable when <code>type = 'hard'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code> with <code>Xscaled</code>, the scaled matrix and <code>f</code>, the scaling
factor.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Eriksson, L., Johansson, E., Kettaneh, N., Trygg, J.,
Wikstrom, C., and Wold, S., 2006. Multi- and Megavariate Data Analysis.
MKS Umetrics AB.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockNorm">blockNorm</a></code>, <code><a href="#topic+standardNormalVariate">standardNormalVariate</a></code>,
<code><a href="#topic+detrend">detrend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(100), ncol = 10)
# Hard block scaling
res &lt;- blockScale(X)
# sum of column variances == 1
apply(res$Xscaled, 2, var)
</code></pre>

<hr>
<h2 id='cochranTest'>Cochran <em>C</em> Test</h2><span id='topic+cochranTest'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>Detects and removes replicate outliers in data series based on the Cochran
<em>C</em> test for homogeneity in variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cochranTest(X, id, fun = 'sum', alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cochranTest_+3A_x">X</code></td>
<td>
<p>a a numeric matrix (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="cochranTest_+3A_id">id</code></td>
<td>
<p>factor of the replicate identifiers.</p>
</td></tr>
<tr><td><code id="cochranTest_+3A_fun">fun</code></td>
<td>
<p>function to aggregate data: 'sum' (default), 'mean', 'PC1' or 'PC2'.</p>
</td></tr>
<tr><td><code id="cochranTest_+3A_alpha">alpha</code></td>
<td>
<p><em>p</em>-value of the Cochran <em>C</em> test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cochran <em>C</em> test is test whether a single estimate of variance is
significantly larger than a a group of variances.
It can be computed as:
</p>
\[RMSD = \sqrt{\frac{1}{n} \sum_{i=1}^n {(y_i - \ddot{y}_i)^2}}\]
<p>where \(y_i\) is the value of the side variable of the \(i\)th sample,
\(\ddot{y}_i\) is the value of the side variable of the nearest neighbor
of the \(i\)th sample and \(n\) is the total number of observations.
</p>
<p>For multivariate data, the variance \(S_i^2\) can be computed on aggregated
data, using a summary function (<code>fun</code> argument)
such as <code>sum</code>, <code>mean</code>, or first principal components ('PC1' and 'PC2').
</p>
<p>An observation is considered to have an outlying variance if the Cochran <em>C</em>
statistic is higher than an upper limit critical value \(C_{UL}\)
which can be evaluated with ('t Lam, 2010):
</p>
\[C_{UL}(\alpha, n, N) = 1 + [\frac{N-1}{F_{c}(\alpha/N,(n-1),(N-1)(n-1))}]^{-1} \]
<p>where \(\alpha\) is the <em>p</em>-value of the test, \(n\) is the (average)
number of replicates and \(F_c\) is the critical value of the Fisher's \(F\) ratio.
</p>
<p>The replicates with outlying variance are removed and the test can be applied
iteratively until no outlying variance is detected under the given <em>p</em>-value.
Such iterative procedure is implemented in <code>cochranTest</code>, allowing the user
to specify whether a set of replicates must be removed or not from the
dataset by graphical inspection of the outlying replicates. The user has then
the possibility to (i) remove all replicates at once, (ii) remove one or more
replicates by giving their indices or (iii) remove nothing.
</p>


<h3>Value</h3>

<p>a list with components:
</p>

<ul>
<li><p>'<code>X</code>': input matrix from which outlying observations (rows) have
been removed
</p>
</li>
<li><p>'<code>outliers</code>': numeric vector giving the row indices of the input
data that have been flagged as outliers
</p>
</li></ul>



<h3>Note</h3>

<p>The test assumes a balanced design (i.e. data series have the same
number of replicates).
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Centner, V., Massart, D.L., and De Noord, O.E., 1996. Detection of
inhomogeneities in sets of NIR spectra. Analytica Chimica Acta 330, 1-17.
</p>
<p>R.U.E. 't Lam (2010). Scrutiny of variance results for outliers: Cochran's
test optimized. Analytica Chimica Acta 659, 68-84.
</p>
<p><a href="https://en.wikipedia.org/wiki/Cochran's_C_test">https://en.wikipedia.org/wiki/Cochran's_C_test</a>
</p>

<hr>
<h2 id='continuumRemoval'>Continuum Removal</h2><span id='topic+continuumRemoval'></span>

<h3>Description</h3>

<a href='https://www.tidyverse.org/lifecycle/#maturing'><img src='figures/lifecycle-maturing.svg' alt='Maturing lifecycle'></a>
<p>Compute the continuum removed values of a data matrix or vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>continuumRemoval(X, wav, type = c("R", "A"),
                 interpol = c("linear", "spline"),
                 method = c("division", "substraction"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="continuumRemoval_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="continuumRemoval_+3A_wav">wav</code></td>
<td>
<p>optional. A numeric vector of band positions.</p>
</td></tr>
<tr><td><code id="continuumRemoval_+3A_type">type</code></td>
<td>
<p>the type of data: 'R' for reflectance (default), 'A' for
absorbance.</p>
</td></tr>
<tr><td><code id="continuumRemoval_+3A_interpol">interpol</code></td>
<td>
<p>the interpolation method between points on the convex hull:
'linear' (default) or 'spline'.</p>
</td></tr>
<tr><td><code id="continuumRemoval_+3A_method">method</code></td>
<td>
<p>normalization method: 'division' (default) or 'subtraction'
(see details section).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The continuum removal technique was introduced by Clark and Roush (1984)
as a method to highlight energy absorption features of minerals.
It can be viewed as a way to perform albedo normalization.
The algorithm find points lying on the convex hull (local maxima or envelope)
of a spectrum, connects the points by linear or spline interpolation and
normalizes the spectrum by dividing (or subtracting) the input data by the
interpolated line.
</p>


<h3>Value</h3>

<p>a matrix or vector with the filtered spectra.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens &amp; <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>References</h3>

<p>Clark, R.N., and Roush, T.L., 1984. Reflectance Spectroscopy: Quantitative
Analysis Techniques for Remote Sensing Applications. J. Geophys. Res. 89,
6329-6340.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+savitzkyGolay">savitzkyGolay</a></code>, <code><a href="#topic+movav">movav</a></code>,
<code><a href="#topic+gapDer">gapDer</a></code>, <code><a href="#topic+binning">binning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# plot of the 10 first abs spectra
matplot(wav,
  t(NIRsoil$spc[1:10, ]),
  type = "l",
  ylim = c(0, .6),
  xlab = "Wavelength /nm",
  ylab = "Abs"
)
#  # type = 'A' is used for absorbance spectra
cr &lt;- continuumRemoval(NIRsoil$spc, wav, type = "A")
matlines(wav, t(cr[1:10, ]))
</code></pre>

<hr>
<h2 id='convCppM'>Convolve</h2><span id='topic+convCppM'></span>

<h3>Description</h3>

<p>Convolution, written in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convCppM(X, f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convCppM_+3A_x">X</code></td>
<td>
<p>matrix to convolve</p>
</td></tr>
<tr><td><code id="convCppM_+3A_f">f</code></td>
<td>
<p>filter</p>
</td></tr>
</table>

<hr>
<h2 id='Cul'>Cochran C critical value</h2><span id='topic+Cul'></span>

<h3>Description</h3>

<p>Upper limit critical value Cul for one-sided test on balanced design
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cul(a,n,N)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cul_+3A_a">a</code></td>
<td>
<p>significance level.</p>
</td></tr>
<tr><td><code id="Cul_+3A_n">n</code></td>
<td>
<p>number of points per series.</p>
</td></tr>
<tr><td><code id="Cul_+3A_n">N</code></td>
<td>
<p>number of data series.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Cochran's_C_test">https://en.wikipedia.org/wiki/Cochran's_C_test</a>
</p>

<hr>
<h2 id='detrend'>Detrending spectral data</h2><span id='topic+detrend'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>Normalizes each row of an input matrix by applying a SNV transformation
followed by fitting a second order linear model and returning the fitted
residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detrend(X, wav, p = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detrend_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process  (optionally a data frame that
can be coerced to a numerical matrix)</p>
</td></tr>
<tr><td><code id="detrend_+3A_wav">wav</code></td>
<td>
<p>the wavelengths/ band centers.</p>
</td></tr>
<tr><td><code id="detrend_+3A_p">p</code></td>
<td>
<p>an integer larger than 1 indicating the polynomial order (default is
2, as in the original paper of Barnes et al., 1989).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The detrend is a row-wise transformation that allows to correct for
wavelength-dependent scattering effects (variations in curvilinearity). A
\(p\) order polynomial is fit for each spectrum (\(x_i\))
using the vector of bands (\(\lambda\), e.g. wavelengths) as
explanatory variable as follows:
</p>
\[x_i = a\lambda^p + ... + b\lambda + c + e_i\]
<p>were a, b, c are estimated by least squares, and \(e_i\) are the
spectral residuals of the least square fit. The residuals of the \(i\)th
correspond to the \(i\)th detrended spectrum.
</p>


<h3>Value</h3>

<p>a matrix or vector with the detrended data.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>References</h3>

<p>Barnes RJ, Dhanoa MS, Lister SJ. 1989. Standard normal variate
transformation and de-trending of near-infrared diffuse reflectance spectra.
Applied spectroscopy, 43(5): 772-777.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+standardNormalVariate">standardNormalVariate</a></code>, <code><a href="#topic+blockScale">blockScale</a></code>,
<code><a href="#topic+blockNorm">blockNorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# conversion to reflectance
opar &lt;- par(no.readonly = TRUE)
par(mfrow = c(2, 1), mar = c(4, 4, 2, 2))
# plot of the 10 first spectra
matplot(wav, t(NIRsoil$spc[1:10, ]),
  type = "l",
  xlab = "",
  ylab = "Absorbance"
)
mtext("Raw spectra")
det &lt;- detrend(NIRsoil$spc, wav)
matplot(wav, t(det[1:10, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "Absorbance"
)
mtext("Detrend spectra")
par(opar)
</code></pre>

<hr>
<h2 id='duplex'>DUPLEX algorithm for calibration sampling</h2><span id='topic+duplex'></span>

<h3>Description</h3>

<p>Select calibration samples from a large multivariate data using the DUPLEX
algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duplex(X,
       k,
       metric = c("mahal", "euclid"),
       pc,
       group,
       .center = TRUE,
       .scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="duplex_+3A_x">X</code></td>
<td>
<p>a numeric matrix.</p>
</td></tr>
<tr><td><code id="duplex_+3A_k">k</code></td>
<td>
<p>the number of calibration/validation samples.</p>
</td></tr>
<tr><td><code id="duplex_+3A_metric">metric</code></td>
<td>
<p>the distance metric to be used: 'euclid' (Euclidean distance)
or 'mahal' (Mahalanobis distance, default).</p>
</td></tr>
<tr><td><code id="duplex_+3A_pc">pc</code></td>
<td>
<p>optional. The number of Principal Components to be used to select
the samples. If not specified, distance are computed in the Euclidean space.
Alternatively, distances are computed in the principal component space and
<code>pc</code> is the number of principal components retained.
If <code>pc &lt; 1</code>, the number of principal components kept corresponds to the
number
of components explaining at least (<code>pc * 100</code>) percent of the total variance.</p>
</td></tr>
<tr><td><code id="duplex_+3A_group">group</code></td>
<td>
<p>An optional <code>factor</code> (or vector that can be coerced to a factor
by <code><a href="base.html#topic+as.factor">as.factor</a></code>) of length equal to nrow(X), giving the identifier
of related observations (e.g. samples of the same batch of measurements,
samples of the same origin, or of the same soil profile). When one
observation is
selected by the procedure all observations of the same group are removed
together and assigned to the calibration/validation sets. This allows to
select calibration and validation samples that are independent from each
other.</p>
</td></tr>
<tr><td><code id="duplex_+3A_.center">.center</code></td>
<td>
<p>logical value indicating whether the input matrix must be
centered before projecting <code>X</code> onto the Principal Component space.
Analysis. Default set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="duplex_+3A_.scale">.scale</code></td>
<td>
<p>logical value indicating whether the input matrix must be
scaled before <code>X</code> onto the Principal Component space.
Analysis. Default set to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DUPLEX algorithm is similar to the Kennard-Stone algorithm (see
<code><a href="#topic+kenStone">kenStone</a></code>) but allows to select both calibration and validation
points that are independent. Similarly to the Kennard-Stone algorithm,
it starts by selecting the pair of points that are the farthest apart. They
are assigned to the calibration sets and removed from the list of points.
Then, the next pair of points which are farthest apart are assigned to the
validation sets and removed from the list. In a third step, the procedure
assigns each remaining point alternatively to the calibration
and validation sets based on the distance to the points already selected.
Similarly to the Kennard-Stone algorithm, the default distance metric used
by the procedure is the Euclidean distance, but the Mahalanobis distance can
be used as well using the <code>pc</code> argument (see <code><a href="#topic+kenStone">kenStone</a></code>).
</p>


<h3>Value</h3>

<p>a <code>list</code> with components:
</p>

<ul>
<li><p>'<code>model</code>': numeric vector giving the row indices of the input data
selected for calibration
</p>
</li>
<li><p>'<code>test</code>': numeric vector giving the row indices of the input data
selected for validation
</p>
</li>
<li><p>'<code>pc</code>': if the <code>pc</code> argument is specified, a numeric matrix of the
scaled pc scores
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Antoine Stevens &amp; <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>References</h3>

<p>Kennard, R.W., and Stone, L.A., 1969. Computer aided design of experiments.
Technometrics 11, 137-148.
</p>
<p>Snee, R.D., 1977. Validation of regression models: methods and examples.
Technometrics 19, 415-428.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kenStone">kenStone</a></code>, <code><a href="#topic+honigs">honigs</a></code>, <code><a href="#topic+shenkWest">shenkWest</a></code>,
<code><a href="#topic+naes">naes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
sel &lt;- duplex(NIRsoil$spc, k = 30, metric = "mahal", pc = .99)
plot(sel$pc[, 1:2], xlab = "PC1", ylab = "PC2")
points(sel$pc[sel$model, 1:2], pch = 19, col = 2) # points selected for calibration
points(sel$pc[sel$test, 1:2], pch = 18, col = 3) # points selected for validation
# Test on artificial data
X &lt;- expand.grid(1:20, 1:20) + rnorm(1e5, 0, .1)
plot(X[, 1], X[, 2], xlab = "VAR1", ylab = "VAR2")
sel &lt;- duplex(X, k = 25, metric = "mahal")
points(X[sel$model, ], pch = 19, col = 2) # points selected for calibration
points(X[sel$test, ], pch = 15, col = 3) # points selected for validation
</code></pre>

<hr>
<h2 id='e2m'>A function for transforming a matrix from its Euclidean space to its Mahalanobis space</h2><span id='topic+e2m'></span>

<h3>Description</h3>

<p>A function for transforming a matrix from its Euclidean space to its Mahalanobis space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>e2m(X, sm.method = c("svd", "eigen"))
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'># test data
## Not run: 
X &lt;- matrix(rnorm(500), ncol = 5)
# Normal way to compute the Mahalanobis distance
md1 &lt;- sqrt(mahalanobis(X, center = colMeans(X), cov = cov(X)))
# Projection approach for computing the Mahalanobis distance
# 1. Projecting from the Euclidean to the Mahalanobis space
Xm &lt;- e2m(X, sm.method = "svd")
# 2. Use the normal Euclidean distance on the Mahalanobis space
md2 &lt;- sqrt(rowSums((sweep(Xm, 2, colMeans(Xm), "-"))^2))
# Plot the results of both methods
plot(md1, md2)
# Test on a real dataset
# Mahalanobis in the spectral space
data(NIRsoil)
X &lt;- NIRsoil$spc
Xm &lt;- e2m(X, sm.method = "svd")
md2 &lt;- sqrt(rowSums((sweep(Xm, 2, colMeans(Xm), "-"))^2))

md1 &lt;- sqrt(mahalanobis(X, center = colMeans(X), cov = cov(X))) # does not work
# Mahalanobis in the PC space
pc &lt;- 20
pca &lt;- prcomp(X, center = TRUE, scale = TRUE)
X &lt;- pca$x[, 1:pc]
X2 &lt;- sweep(pca$x[, 1:pc, drop = FALSE], 2, pca$sdev[1:pc], "/")
md4 &lt;- sqrt(rowSums((sweep(Xm, 2, colMeans(Xm), "-"))^2))
md5 &lt;- sqrt(rowSums((sweep(X2, 2, colMeans(X2), "-"))^2))
md3 &lt;- sqrt(mahalanobis(X, center = colMeans(X), cov = cov(X))) # does work

## End(Not run)
</code></pre>

<hr>
<h2 id='fastDist'>A fast distance algorithm for two matrices written in C++</h2><span id='topic+fastDist'></span>

<h3>Description</h3>

<p>A fast distance algorithm for two matrices written in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastDist(X,Y,method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastDist_+3A_x">X</code></td>
<td>
<p>a <code>matrix</code></p>
</td></tr>
<tr><td><code id="fastDist_+3A_y">Y</code></td>
<td>
<p>a <code>matrix</code></p>
</td></tr>
<tr><td><code id="fastDist_+3A_method">method</code></td>
<td>
<p>a <code>string</code> with possible values &quot;euclid&quot;, &quot;cor&quot;, &quot;cosine&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a distance <code>matrix</code>
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and Leonardo Ramirez-Lopez
</p>

<hr>
<h2 id='fastDistV'>A fast distance algorithm for a matrix and a vector written in C++</h2><span id='topic+fastDistV'></span>

<h3>Description</h3>

<p>A fast distance algorithm for a matrix and a vector written in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastDistV(X,Y,method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastDistV_+3A_x">X</code></td>
<td>
<p>a <code>matrix</code></p>
</td></tr>
<tr><td><code id="fastDistV_+3A_y">Y</code></td>
<td>
<p>a <code>vector</code></p>
</td></tr>
<tr><td><code id="fastDistV_+3A_method">method</code></td>
<td>
<p>a <code>string</code> with possible values &quot;euclid&quot;, &quot;cor&quot;, &quot;cosine&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a distance <code>vector</code>
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and Leonardo Ramirez-Lopez
</p>

<hr>
<h2 id='gapDer'>Gap-Segment derivative</h2><span id='topic+gapDer'></span>

<h3>Description</h3>

<p>Gap-Segment derivatives of a data matrix or vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gapDer(X, m = 1, w = 1, s = 1, delta.wav)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gapDer_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector' to transform (optionally a data frame
that can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="gapDer_+3A_m">m</code></td>
<td>
<p>an integer indicating the order of the derivative, larger than 1
(default is 1). Note that this function allows for high order derivatives
(e.g. m = 6).</p>
</td></tr>
<tr><td><code id="gapDer_+3A_w">w</code></td>
<td>
<p>an integer indicating the gap size (must be odd and &gt;=1), i.e. the spacing
between points over which the derivative is computed.</p>
</td></tr>
<tr><td><code id="gapDer_+3A_s">s</code></td>
<td>
<p>an integer indicating the segment size (must be odd and &gt;=1), i.e.
the range over which the points are averaged (default = 1, i.e. no
smoothing corresponding to Norris-Gap Derivative).</p>
</td></tr>
<tr><td><code id="gapDer_+3A_delta.wav">delta.wav</code></td>
<td>
<p>the sampling interval (or band spacing).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this type of derivatives, the gap size denotes the length of the x
interval that separates the two segments that are averaged.  A detailed
explanation of gap segment derivatives can be found in Hopkins (2001).
</p>
<p>The sampling interval specified with the <code>delta.wav</code> argument is used for
scaling and get numerically correct derivatives.
</p>
<p>The convolution function is written in C++/Rcpp for faster computations.
</p>


<h3>Value</h3>

<p>a matrix or vector with the filtered signal(s)
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>References</h3>

<p>Hopkins, D. W. (2001). What is a Norris derivative?. NIR news, 12(3), 3-5.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+savitzkyGolay">savitzkyGolay</a></code>, <code><a href="#topic+movav">movav</a></code>,
<code><a href="#topic+binning">binning</a></code>, <code><a href="#topic+continuumRemoval">continuumRemoval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
opar &lt;- par(no.readonly = TRUE)
par(mfrow = c(2, 2), mar = c(4, 4, 2, 2))
# plot of the 10 first spectra
matplot(as.numeric(colnames(NIRsoil$spc)),
  t(NIRsoil$spc[1:10, ]),
  type = "l",
  xlab = "",
  ylab = "Absorbance"
)
mtext("Raw spectra")

der &lt;- gapDer(NIRsoil$spc, m = 1, w = 1, s = 1, delta.wav = 2)
matplot(as.numeric(colnames(der)),
  t(der[1:10, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "gap derivative"
)

mtext("1st derivative spectra")
der &lt;- gapDer(NIRsoil$spc, m = 1, w = 11, s = 1, delta.wav = 2)
matplot(as.numeric(colnames(der)), t(der[1:10, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "gap derivative"
)

mtext("1st derivative spectra with a window size = 11 nm")
der &lt;- gapDer(NIRsoil$spc, m = 1, w = 11, s = 5, delta.wav = 2)
matplot(as.numeric(colnames(der)), t(der[1:10, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "gap derivative"
)
mtext("1st derivative spectra with: window size: 11 nm, smoothing: 5 nm")
par(opar)
</code></pre>

<hr>
<h2 id='get_msc_coeff'>get_msc_coeff</h2><span id='topic+get_msc_coeff'></span>

<h3>Description</h3>

<p>Coefficients for multiplicative Scatter Correction written in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_msc_coeff(X, ref_spectrum)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_msc_coeff_+3A_x">X</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="get_msc_coeff_+3A_ref_spectrum">ref_spectrum</code></td>
<td>
<p>a matrix of one row and same columns as in X</p>
</td></tr>
</table>

<hr>
<h2 id='get_nircal_comments'>get the comments of the spectra in the nircal file</h2><span id='topic+get_nircal_comments'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_comments(connection, metanumbers, begin_s, comment_s, comment_f, n)
</code></pre>

<hr>
<h2 id='get_nircal_description'>get the description of the spectra in the nircal file</h2><span id='topic+get_nircal_description'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_description(x, begin_s, spcinfo, comment_s, comment_f, n)
</code></pre>

<hr>
<h2 id='get_nircal_indices'>get the positions of relevant data witihi the nircal file</h2><span id='topic+get_nircal_indices'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_indices(x)
</code></pre>

<hr>
<h2 id='get_nircal_lengthspc'>get the number of spectral variables in the nircaa file</h2><span id='topic+get_nircal_lengthspc'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_lengthspc(connection, from, to)
</code></pre>

<hr>
<h2 id='get_nircal_metadata'>get the metadata of the samples in the nircal file</h2><span id='topic+get_nircal_metadata'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_metadata(
  connection,
  n,
  spctra_start,
  spcinfo,
  progress,
  pb,
  progress.start,
  progress.steps
)
</code></pre>

<hr>
<h2 id='get_nircal_response'>get the response variables in the nircal file</h2><span id='topic+get_nircal_response'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_response(x, n)
</code></pre>

<hr>
<h2 id='get_nircal_spectra'>get the spectra in the nircal file</h2><span id='topic+get_nircal_spectra'></span>

<h3>Description</h3>

<p>internal
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nircal_spectra(x, values_s, spctra_start, speclength, n)
</code></pre>

<hr>
<h2 id='honigs'>Honigs algorithm for calibration sampling</h2><span id='topic+honigs'></span>

<h3>Description</h3>

<p>Select calibration samples from a data matrix using the Honings et al. (1985)
method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>honigs(X, k, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="honigs_+3A_x">X</code></td>
<td>
<p>a numeric matrix with absorbance or continuum-removed reflectance
values (optionally a data frame that can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="honigs_+3A_k">k</code></td>
<td>
<p>the number of samples to select for calibration.</p>
</td></tr>
<tr><td><code id="honigs_+3A_type">type</code></td>
<td>
<p>type of data: 'A' for absorbance (default), 'R' for reflectance,
'CR' for continuum-removed reflectance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Honigs algorithm is a simple method to select calibration samples based
on their absorption features. Absorbance, reflectance and continuum-removed
reflectance values (see <code><a href="#topic+continuumRemoval">continuumRemoval</a></code>) can be used (<code>type</code>
argument).
The algorithm can be described as follows: let <code class="reqn">A</code> be a matrix of
<code class="reqn">(i \times j)</code> absorbance values:
</p>

<ol>
<li><p> the observation (row) with the maximum absolute absorbance
(<code class="reqn">max(|A|)</code>) is selected and assigned to the calibration set.
</p>
</li>
<li><p> a vector of weights <code class="reqn">W</code> is computed as <code class="reqn">A_j/max_A</code> where
<code class="reqn">A_j</code> is the column of <code class="reqn">A</code> having the maximum absolute absorbance
and <code class="reqn">max_A</code> is the absorbance value corresponding to the maximum
absolute absorbance of <code class="reqn">A</code>
</p>
</li>
<li><p> each row <code class="reqn">A_i</code> is multiplied by the corresponding weight <code class="reqn">W_i</code>
and the resulting vector is subtracted from the original row <code class="reqn">A_i</code>.
</p>
</li>
<li><p> the row of the selected observation and the column with the maximum
absolute absorbance is removed from the matrix
</p>
</li>
<li><p> go back to step 1 and repeat the procedure until the desired number
of selected samples is reached
</p>
</li></ol>

<p>The observation with the maximum absorbance is considered to have
an unusual composition. The algorithm selects therefore this observation and
remove from other samples the selected absorption feature by subtraction.
Samples with low concentration related to this absorption will then have
large negative absorption after the subtraction step
and hence will be likely to be selected rapidly by the selection procedure
as well.
</p>


<h3>Value</h3>

<p>a <code>list</code> with components:
</p>

<ul>
<li><p>'<code>model</code>': numeric vector giving the row indices of the input data
selected for calibration
</p>
</li>
<li><p>'<code>test</code>': numeric vector giving the row indices of the remaining
observations
</p>
</li>
<li><p>'<code>bands</code>': indices of the columns used during the selection procedure
</p>
</li></ul>



<h3>Note</h3>

<p>The selection procedure is sensitive to noisy features in the signal.
The number of samples selected <code>k</code> selected by the algorithm cannot be
greater than the number of wavelengths.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Honigs D.E., Hieftje, G.M., Mark, H.L. and Hirschfeld, T.B. 1985.
Unique-sample selection via Near-Infrared spectral substraction.
Analytical Chemistry, 57, 2299-2303
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kenStone">kenStone</a></code>, <code><a href="#topic+naes">naes</a></code>, <code><a href="#topic+duplex">duplex</a></code>,
<code><a href="#topic+shenkWest">shenkWest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
sel &lt;- honigs(NIRsoil$spc, k = 10, type = "A")
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# spectral library
matplot(wav,
  t(NIRsoil$spc),
  type = "l",
  xlab = "wavelength /nm",
  ylab = "Abs",
  col = "grey50"
)
# plot calibration spectra
matlines(wav,
  t(NIRsoil$spc[sel$model, ]),
  type = "l",
  xlab = "wavelength /nm",
  ylab = "Abs",
  lwd = 2,
  lty = 1
)
# add bands used during the selection process
abline(v = wav[sel$bands])
</code></pre>

<hr>
<h2 id='kenStone'>Kennard-Stone algorithm for calibration sampling</h2><span id='topic+kenStone'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>Select calibration samples from a large multivariate data using the
Kennard-Stone algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kenStone(X, k, metric = "mahal", pc, group,
         .center = TRUE, .scale = FALSE, init = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kenStone_+3A_x">X</code></td>
<td>
<p>a numeric matrix.</p>
</td></tr>
<tr><td><code id="kenStone_+3A_k">k</code></td>
<td>
<p>number of calibration samples to be selected.</p>
</td></tr>
<tr><td><code id="kenStone_+3A_metric">metric</code></td>
<td>
<p>distance metric to be used: 'euclid' (Euclidean distance) or
'mahal' (Mahalanobis distance, default).</p>
</td></tr>
<tr><td><code id="kenStone_+3A_pc">pc</code></td>
<td>
<p>optional. If not specified, distance are computed in the Euclidean
space. Alternatively, distance are computed
in the principal component score space and  <code>pc</code> is the number of principal
components retained.
If <code>pc &lt; 1</code>, the number of principal components kept corresponds to the
number of components explaining at least (<code>pc * 100</code>) percent of the total
variance.</p>
</td></tr>
<tr><td><code id="kenStone_+3A_group">group</code></td>
<td>
<p>An optional <code>factor</code> (or vector that can be coerced to a factor
by <code><a href="base.html#topic+as.factor">as.factor</a></code>) of length equal to <code>nrow(X)</code>, giving the identifier
of related observations (e.g. samples of the same batch of measurements,
samples of the same origin, or of the same soil profile). Note that by using
this option in some cases, the number of samples retrieved is not exactly the
one specified in <code>k</code> as it will depend on the groups. See details.</p>
</td></tr>
<tr><td><code id="kenStone_+3A_.center">.center</code></td>
<td>
<p>logical value indicating whether the input matrix should be
centered before Principal Component Analysis. Default set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="kenStone_+3A_.scale">.scale</code></td>
<td>
<p>logical value indicating whether the input matrix should be
scaled before Principal Component
Analysis. Default set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="kenStone_+3A_init">init</code></td>
<td>
<p>(optional) a vector of integers indicating the indices of the
observations/rows that are to be used as observations that must be included
at the first iteration of the search process. Default is <code>NULL</code>, i.e. no
fixed initialization. The function will take by default the two most distant
observations. If the <code>group</code> argument is used, then all the observations
in the groups covered by the <code>init</code> observations will be also included
in the <code>init</code> subset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kennard&ndash;Stone algorithm allows to select samples with a uniform
distribution over the predictor space (Kennard and Stone, 1969).
It starts by selecting the pair of points that are the farthest apart.
They are assigned to the calibration set and removed from the list of points.
Then, the procedure assigns remaining points to the calibration set
by computing the distance between each unassigned points
\(i_0\) and selected points \(i\)
and finding the point for which:
</p>
\[d_{selected} = \max\limits_{i_0}(\min\limits_{i}(d_{i,i_{0}}))\]
<p>This essentially selects point \(i_0\) which is the farthest apart from its
closest neighbors \(i\) in the calibration set.
The algorithm uses the Euclidean distance to select the points. However,
the Mahalanobis distance can also be used. This can be achieved by performing
a PCA on the input data and computing the Euclidean distance on the truncated
score matrix according to the following definition of the Mahalanobis \(H\)
distance:
</p>
\[H_{ij}^2 = \sum_{a=1}^A (\hat t_{ia} - \hat t_{ja})^{2} / \hat \lambda_a\]
<p>where \(\hat t_{ia}\) is the \(a^{th}\) principal component
score of point \(i\), \(\hat t_{ja}\) is the
corresponding value for point \(j\),
\(\hat \lambda_a\) is the eigenvalue of principal
component \(a\) and \(A\) is the number of principal components
included in the computation.
</p>
<p>When the <code>group</code> argument is used, the sampling is conducted in such a
way that at each iteration, when a single sample is selected, this sample
along with all the samples that belong to its group, are assigned to the
final calibration set. In this respect, at each iteration, the algorithm
will select one sample (in case that sample is the only one in that group)
or more to the calibration set. This also implies that the argument <code>k</code>
passed to the function will not necessary reflect the exact number of samples
selected. For example, if <code>k = 2</code> and if the first sample identified
belongs to with group of 5 samples and the second one belongs to a group with
10 samples, then, the total amount of samples retrieved by the
function will be 15.
</p>


<h3>Value</h3>

<p>a list with the following components:
</p>

<ul>
<li><p><code>model</code>: numeric vector giving the row indices of the input data
selected for calibration
</p>
</li>
<li><p><code>test</code>: numeric vector giving the row indices of the remaining
observations
</p>
</li>
<li><p><code>pc</code>: if the <code>pc</code> argument is specified, a numeric matrix of the
scaled pc scores
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Antoine Stevens &amp;
<a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a> with
contributions from Thorsten Behrens and Philipp Baumann
</p>


<h3>References</h3>

<p>Kennard, R.W., and Stone, L.A., 1969. Computer aided design of experiments.
Technometrics 11, 137-148.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+duplex">duplex</a></code>, <code><a href="#topic+shenkWest">shenkWest</a></code>, <code><a href="#topic+naes">naes</a></code>,
<code><a href="#topic+honigs">honigs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
sel &lt;- kenStone(NIRsoil$spc, k = 30, pc = .99)
plot(sel$pc[, 1:2], xlab = "PC1", ylab = "PC2")
# points selected for calibration
points(sel$pc[sel$model, 1:2], pch = 19, col = 2)
# Test on artificial data
X &lt;- expand.grid(1:20, 1:20) + rnorm(1e5, 0, .1)
plot(X, xlab = "VAR1", ylab = "VAR2")
sel &lt;- kenStone(X, k = 25, metric = "euclid")
points(X[sel$model, ], pch = 19, col = 2)

# Using the group argument
library(prospectr)

# create groups
set.seed(1)
my_groups &lt;- sample(1:275, nrow(NIRsoil$spc), replace = TRUE) |&gt; as.factor()

# check the group size 
table(my_groups)

results_group &lt;- kenStone(X = NIRsoil$spc, k = 2, pc = 3, group = my_groups)

# as the first two samples selected belong to groups
# which have in total more than 2 samples (k).
my_groups[results_group$model] |&gt;  factor() |&gt; table()

</code></pre>

<hr>
<h2 id='movav'>Moving average</h2><span id='topic+movav'></span>

<h3>Description</h3>

<p>A simple moving average of a matrix or vector using a convolution
function written in C++/Rcpp for fast computing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movav(X, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="movav_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="movav_+3A_w">w</code></td>
<td>
<p>filter length.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix or vector with the filtered signal(s)
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>See Also</h3>

<p><code><a href="#topic+savitzkyGolay">savitzkyGolay</a></code>, <code><a href="#topic+gapDer">gapDer</a></code>,
<code><a href="#topic+binning">binning</a></code>, <code><a href="#topic+continuumRemoval">continuumRemoval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# adding some noise
NIRsoil$spc_noise &lt;- NIRsoil$spc + rnorm(length(NIRsoil$spc), 0, 0.001)
matplot(wav,
  t(NIRsoil$spc_noise[1:10, ]),
  type = "l",
  lty = 1,
  xlab = "Wavelength /nm",
  ylab = "Absorbance",
  col = "grey"
)

# window size of 11 bands
NIRsoil$spc_mov &lt;- movav(NIRsoil$spc_noise, w = 15)
# smoothed data
matlines(as.numeric(colnames(NIRsoil$spc_mov)),
  t(NIRsoil$spc_mov[1:10, ]),
  type = "l",
  lty = 1
)
</code></pre>

<hr>
<h2 id='msc'>Multiplicative Scatter Correction (msc)</h2><span id='topic+msc'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<a href='https://www.tidyverse.org/lifecycle/#maturing'><img src='figures/lifecycle-maturing.svg' alt='Maturing lifecycle'></a>
<p>This function implements the multiplicative scatter correction method
which attempts to remove physical light scatter by accounting for additive
and multiplicative effects (Geladi et al., 1985).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msc(X, ref_spectrum = colMeans(X))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msc_+3A_x">X</code></td>
<td>
<p>a numeric matrix of spectral data.</p>
</td></tr>
<tr><td><code id="msc_+3A_ref_spectrum">ref_spectrum</code></td>
<td>
<p>a numeric vector corresponding to an &quot;ideal&quot; reference
spectrum (e.g. free of scattering effects). By default the function uses the
mean spectrum of the input <code>X</code>. See details. Note that this argument was
previously named as <code>reference_spc</code>, however, it has been renamed to
<code>ref_spectrum</code> to emphasize that this argument is a vector and not a
matrix of spectra.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Multiplicative Scatter Correction (MSC) is a normalization method that
attempts to account for additive and multiplicative effects by aligning each
spectrum (\(x_i\)) to an ideal reference one (\(x_r\)) as
follows:
</p>
\[x_i = m_i x_r + a_i\]
\[MSC(x_i) = \frac{a_i - x_i}{m_i}\]
<p>where \(a_i\) and \(m_i\) are the additive and
multiplicative terms respectively.
</p>


<h3>Value</h3>

<p>a matrix of normalized spectral data with an attribute which indicates the
reference spectrum used.
</p>


<h3>Author(s)</h3>

<p><a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a> and Guillaume Hans
</p>


<h3>References</h3>

<p>Geladi, P., MacDougall, D., and Martens, H. 1985. Linearization and
Scatter-Correction for Near-Infrared Reflectance Spectra of Meat.
Applied Spectroscopy, 39(3):491-500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+standardNormalVariate">standardNormalVariate</a></code>, <code><a href="#topic+detrend">detrend</a></code>,
<code><a href="#topic+blockScale">blockScale</a></code>, <code><a href="#topic+blockNorm">blockNorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
NIRsoil$msc_spc &lt;- msc(X = NIRsoil$spc)

# 10 first msc spectra
matplot(
  x = as.numeric(colnames(NIRsoil$msc_spc)),
  y = t(NIRsoil$msc_spc[1:10, ]),
  type = "l",
  xlab = "wavelength, nm",
  ylab = "msc"
)

# another example
spectra_a &lt;- NIRsoil$spc[1:40, ]
spectra_b &lt;- NIRsoil$spc[-(1:40), ]

spectra_a_msc &lt;- msc(spectra_a, colMeans(spectra_a))

# correct spectra_a based on the reference spectrum used to correct
# spectra_a

spectra_b_msc &lt;- msc(
  spectra_b,
  ref_spectrum = attr(spectra_a_msc, "Reference spectrum")
)
</code></pre>

<hr>
<h2 id='naes'>k-means sampling</h2><span id='topic+naes'></span>

<h3>Description</h3>

<p>Perform a k-means sampling on a matrix for multivariate calibration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naes(X, k, pc, iter.max = 10, method = 0, .center = TRUE, .scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naes_+3A_x">X</code></td>
<td>
<p>a numeric matrix (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="naes_+3A_k">k</code></td>
<td>
<p>either the number of calibration samples to select or a set of
cluster centres to initiate the k-means clustering.</p>
</td></tr>
<tr><td><code id="naes_+3A_pc">pc</code></td>
<td>
<p>optional. If not specified, k-means is run directly on the variable
(Euclidean) space.
Alternatively, a PCA is performed before k-means and <code>pc</code> is the number of
principal components kept. If <code>pc &lt; 1</code>,the number of principal components
kept corresponds to the number of components explaining at least (<code>pc * 100</code>)
percent of the total variance.</p>
</td></tr>
<tr><td><code id="naes_+3A_iter.max">iter.max</code></td>
<td>
<p>maximum number of iterations allowed for the k-means
clustering. Default is <code>iter.max = 10</code> (see <code>?kmeans</code>).</p>
</td></tr>
<tr><td><code id="naes_+3A_method">method</code></td>
<td>
<p>the method used for selecting calibration samples within each
cluster: either samples closest to the cluster.
centers (<code>method = 0</code>, default), samples farthest away from the centre of the
data (<code>method = 1</code>) or
random selection (<code>method = 2</code>).</p>
</td></tr>
<tr><td><code id="naes_+3A_.center">.center</code></td>
<td>
<p>logical value indicating whether the input matrix must be
centered before Principal Component Analysis. Default set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="naes_+3A_.scale">.scale</code></td>
<td>
<p>logical value indicating whether the input matrix must be
scaled before Principal Component Analysis. Default set to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>K-means sampling is a simple procedure based on cluster analysis to
select calibration samples from large multivariate datasets.
The method can be described in three points (Naes et al.,2001):
</p>

<ol>
<li><p> Perform a PCA and decide how many principal component to keep,
</p>
</li>
<li><p> Carry out a k-means clustering on the principal component scores and
choose the number of resulting clusters to be equal to
the number of desired calibration samples,
</p>
</li>
<li><p> Select one sample from each cluster.
</p>
</li></ol>



<h3>Value</h3>

<p>a list with components:
</p>

<ul>
<li><p>'<code>model</code>': numeric vector giving the row indices of the input data
selected for calibration
</p>
</li>
<li><p>'<code>test</code>': numeric vector giving the row indices of the remaining
observations
</p>
</li>
<li><p>'<code>pc</code>': if the <code>pc</code> argument is specified, a numeric matrix of the
scaled pc scores
</p>
</li>
<li><p>'<code>cluster</code>': integer vector indicating the cluster to which each
point was assigned
</p>
</li>
<li><p>'<code>centers</code>': a matrix of cluster centres
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Antoine Stevens &amp; <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>References</h3>

<p>Naes, T., 1987. The design of calibration in near infra-red reflectance
analysis by clustering. Journal of Chemometrics 1, 121-134.
</p>
<p>Naes, T., Isaksson, T., Fearn, T., and Davies, T., 2002. A user friendly
guide to multivariate calibration and classification. NIR Publications,
Chichester, United Kingdom.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kenStone">kenStone</a></code>, <code><a href="#topic+honigs">honigs</a></code>, <code><a href="#topic+duplex">duplex</a></code>,
<code><a href="#topic+shenkWest">shenkWest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
sel &lt;- naes(NIRsoil$spc, k = 5, p = .99, method = 0)
# clusters
plot(sel$pc[, 1:2], col = sel$cluster + 2)
# points selected for calibration with method = 0
points(sel$pc[sel$model, 1:2],
  col = 2,
  pch = 19,
  cex = 1
)
# pre-defined centers can also be provided
sel2 &lt;- naes(NIRsoil$spc,
  k = sel$centers,
  p = .99, method = 1
)
# points selected for calibration with method = 1
points(sel$pc[sel2$model, 1:2],
  col = 1,
  pch = 15,
  cex = 1
)
</code></pre>

<hr>
<h2 id='NIRsoil'>NIRSoil</h2><span id='topic+NIRsoil'></span>

<h3>Description</h3>

<p>Soil spectral library of the &lsquo;Chimiometrie 2006&rsquo; challenge.
The database contains absorbance spectra of dried and sieved soil samples
measured between 1100 nm and 2498 nm at 2 nm interval. The soil samples come
from agricultural fields collected from all over the Walloon region in Belgium.
Three parameters are associated with the spectral library: Nt (Total Nitrogen
in g/Kg of dry soil), CEC (Cation Exchange Capacity in meq/100 g of dry soil)
and Ciso (Carbon in g/100 g of dry soil). Carbon content has been measured
following the ISO14235 method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NIRsoil)
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> of 825 observations and 5 variables (where the spectral
data is embedded in one variable <code>NIRSoil$spc</code>).
</p>


<h3>Details</h3>

<p>The dataset includes 618 training and 207 test samples with 5 variables:
</p>

<ul>
<li><p>Nt (Total Nitrogen).
</p>
</li>
<li><p>Ciso (Carbon).
</p>
</li>
<li><p>CEC (Cation Exchange Capacity).
</p>
</li>
<li><p>train (binary vector indicating training (1) and validation (0) samples).
</p>
</li>
<li><p>and spc (a matrix of spectral NIR absorbance values, where the band/wavelength positions are stored as <code>colnames</code>).
</p>
</li></ul>

<p>Nt, Ciso and CEC have respectively 22 \
with missing values.
</p>


<h3>Source</h3>

<p>Pierre Dardenne from Walloon Agricultural Research Centre, Belgium.
</p>


<h3>References</h3>

<p>Fernandez Pierna, J.A., and Dardenne, P., 2008. Soil parameter quantification
by NIRS as a Chemometric challenge at 'Chimiometrie 2006'. Chemometrics and
Intelligent Laboratory Systems 91, 94-98.
</p>

<hr>
<h2 id='pkg_info'>Get the package version info</h2><span id='topic+pkg_info'></span>

<h3>Description</h3>

<p>returns package info.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pkg_info(pkg = "prospectr")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pkg_info_+3A_pkg">pkg</code></td>
<td>
<p>the package name i.e &quot;prospectr&quot;</p>
</td></tr>
</table>

<hr>
<h2 id='puchwein'>Puchwein algorithm for calibration sampling</h2><span id='topic+puchwein'></span>

<h3>Description</h3>

<p>Select calibration samples from multivariate data using the Puchwein
algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>puchwein(X,
         pc = 0.95,
         k,
         min.sel,
         details = FALSE,
         .center = TRUE,
         .scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="puchwein_+3A_x">X</code></td>
<td>
<p>a matrix from which the calibration samples are to be selected
(optionally a data frame that can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="puchwein_+3A_pc">pc</code></td>
<td>
<p>the number of principal components retained in the computation of
the distance in the standardized Principal Component space (Mahalanobis
distance).
If <code>pc &lt; 1</code>, the number of principal components kept corresponds to the
number of components
explaining at least (<code>pc * 100</code>) percent of the total variance
(default = 0.95 as in the Puchwein paper).</p>
</td></tr>
<tr><td><code id="puchwein_+3A_k">k</code></td>
<td>
<p>the initial limiting distance parameter, if not specified (default),
set to 0.2. According to Puchwein, a good starting value for the limiting
distance is <code class="reqn">d_{ini} = k(p-2)</code> where <code class="reqn">p</code> is the number of
principal components</p>
</td></tr>
<tr><td><code id="puchwein_+3A_min.sel">min.sel</code></td>
<td>
<p>minimum number of samples to select for calibration
(default = 5).</p>
</td></tr>
<tr><td><code id="puchwein_+3A_details">details</code></td>
<td>
<p>logical value, if <code>TRUE</code>, adds a component in the output list
with the indices of the objects kept in each loop (default to <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="puchwein_+3A_.center">.center</code></td>
<td>
<p>logical value indicating whether the input matrix must be
centered before Principal Component.
Analysis. Default set to TRUE.</p>
</td></tr>
<tr><td><code id="puchwein_+3A_.scale">.scale</code></td>
<td>
<p>logical value indicating whether the input matrix must be
scaled before Principal Component
Analysis. Default set to FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Puchwein algorithm select samples from a data matrix by iteratively
eliminating similar samples using the Mahalanobis distance.
It starts by performing a PCA on the input matrix and extracts the score
matrix truncated to <code class="reqn">A</code>, the number of principal components. The score
matrix is then normalized to unit variance and the Euclidean distance of each
sample to the centre of the data is computed, which is identical to the
Mahalanobis distance <code class="reqn">H</code>. Additionally, the Mahalanobis distances between
samples are comptuted. The algorithm then proceeds as follows:
</p>

<ol>
<li><p> Choose a initial limiting distance <code class="reqn">d_{ini}</code>
</p>
</li>
<li><p> Select the sample with the highest <code class="reqn">H</code> distance to the centre
</p>
</li>
<li><p> Remove all samples within the minimum distance <code class="reqn">d_{ini}</code> from
the sample selected in step 2
</p>
</li>
<li><p> Go back to step 2 and proceed until there are no samples/observations
left in the dataset
</p>
</li>
<li><p> Go back to step 1 and increase the minimum distance by multiplying
the limiting distance by the loop number
</p>
</li></ol>

<p>It is not possible to obtain a pre-defined number of samples selected by the
method. To choose the adequate number of samples, a data frame is returned
by <code>puchwein</code> function (<code>leverage</code>) giving the observed and theoretical
cumulative sum of leverages of the points selected in each iteration. The
theoretical cumulative sum of leverage is computed such as each point has the
same leverage (the sum of leverages divided by the number of observations).
The loop having the largest difference between the observed and theoretical
sums is considered as producing the optimal selection of points (the subset
that best reproduces the variability of the predictor space).
</p>


<h3>Value</h3>

<p>a <code>list</code> with components:
</p>

<ul>
<li><p>'<code>model</code>': indices of the observations (row indices of the input
data)
selected for calibration
</p>
</li>
<li><p>'<code>test</code>': indices of the remaining observations (row indices of the
input data)
</p>
</li>
<li><p>'<code>pc</code>': a numeric matrix of the scaled pc scores
</p>
</li>
<li><p>'<code>loop.optimal</code>': index of the loop producing the maximum difference
between the observed and
theoretical sum of leverages of the selected samples
</p>
</li>
<li><p>'<code>leverage</code>': data frame giving the observed and theoretical
cumulative sums of leverage of the points selected in each loop
</p>
</li>
<li><p>'<code>details</code>': list with the indices of the observations kept in each
loop
</p>
</li></ul>



<h3>Note</h3>

<p>The Puchwein algorithm is an iterative method and can be slow for large
data matrices.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Puchwein, G., 1988. Selection of calibration samples for near-infrared
spectrometry by factor analysis of spectra. Analytical Chemystry 60, 569-573.
</p>
<p>Shetty, N., Rinnan, A., and Gislum, R., 2012. Selection of representative
calibration sample sets for near-infrared reflectance spectroscopy to predict
nitrogen concentration in grasses. Chemometrics and Intelligent Laboratory
Systems 111, 59-65.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kenStone">kenStone</a></code>, <code><a href="#topic+duplex">duplex</a></code>,
<code><a href="#topic+shenkWest">shenkWest</a></code>, <code><a href="#topic+honigs">honigs</a></code>, <code><a href="#topic+naes">naes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
sel &lt;- puchwein(NIRsoil$spc, k = 0.2, pc = .99)
plot(sel$pc[, 1:2])
# points selected for calibration
points(NIRsoil$spc[sel$model, 1:2], col = 2, pch = 2)
# Leverage plot
opar &lt;- par(no.readonly = TRUE)
par(mar = c(4, 5, 2, 2))
plot(sel$leverage$loop, sel$leverage$diff,
  type = "l",
  xlab = "# loops",
  ylab = "Difference between theoretical and \n observed sum of leverages"
)
par(opar)
</code></pre>

<hr>
<h2 id='read_nircal'>Import BUCHI NIRCal files</h2><span id='topic+read_nircal'></span>

<h3>Description</h3>

<a href='https://www.tidyverse.org/lifecycle/#maturing'><img src='figures/lifecycle-maturing.svg' alt='Maturing lifecycle'></a>
<p>This function imports .nir files generated by BUCHI NIRCal software.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_nircal(file, response = TRUE, spectra = TRUE,
            metadata = TRUE, progress = TRUE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_nircal_+3A_file">file</code></td>
<td>
<p>the name of the NIRCal (.nir) file which the data are to be read
from. For URLs a temporary file is first downloaded and is then read.</p>
</td></tr>
<tr><td><code id="read_nircal_+3A_response">response</code></td>
<td>
<p>a logical indicating if the data of the response variables
must be returned (default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="read_nircal_+3A_spectra">spectra</code></td>
<td>
<p>a logical indicating if the spectral data must be returned
(default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="read_nircal_+3A_metadata">metadata</code></td>
<td>
<p>a logical indicating if the metadada must be returned
(default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="read_nircal_+3A_progress">progress</code></td>
<td>
<p>a logical indicating if a progress bar must be printed
(default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="read_nircal_+3A_verbose">verbose</code></td>
<td>
<p>a logical indicating if the number of spectra and response
variables (an also the ID's of the spectra without gain and/or temperature
information) must be printed (default is <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extension of the BUCHI NIRCal files is .nir. These files are used to
store spectra generated by BUCHI N-500 and BUCHI NIRMaster FT-NIR sensors.
See
<a href="https://assets.buchi.com/image/upload/v1605790933/pdf/Technical-Datasheet/TDS_11593569_NIRCal.pdf">NIRCal technical data sheet.</a>
</p>


<h3>Value</h3>

<p>a data.frame containing the metadata, response variables (if
<code>response = TRUE</code>) and spectra (if <code>spectra = TRUE</code>, embedded in the
<code>data.frame</code> as a matrix named <code>...$spc</code>).
</p>


<h3>Author(s)</h3>

<p><a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>

<hr>
<h2 id='readASD'>Read ASD FieldSpec Pro binary and ASCII files</h2><span id='topic+readASD'></span>

<h3>Description</h3>

<a href='https://www.tidyverse.org/lifecycle/#maturing'><img src='figures/lifecycle-maturing.svg' alt='Maturing lifecycle'></a>
<p>Read single or multiple binary and ASCII files acquired with an ASD FieldSpec
Pro (<a href="https://www.malvernpanalytical.com/en/products/product-range/asd-range">ASDi</a>,
Boulder, CO) spectroradiometer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readASD(fnames, in_format, out_format)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readASD_+3A_fnames">fnames</code></td>
<td>
<p>a character vector of the name(s) (with absolute path) of the file(s) to read.</p>
</td></tr>
<tr><td><code id="readASD_+3A_in_format">in_format</code></td>
<td>
<p>the format of the input file: <code>'binary'</code> or <code>'txt'</code>.</p>
</td></tr>
<tr><td><code id="readASD_+3A_out_format">out_format</code></td>
<td>
<p>the format of the output: 'matrix' (default) or 'list' (see below).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>out_format</code> = <code>'matrix'</code>, reflectance values of the input file(s) in a single matrix.
</p>
<p>if <code>out_format</code> = <code>'list'</code>, a <code>list</code> of the input file(s) data consisting of a list with components:
</p>

<ul>
<li><p><code>Name</code>: name of the file imported
</p>
</li>
<li><p><code>datetime</code>: date and time of acquisition in <code>POSIXct</code> format
</p>
</li>
<li><p><code>header</code>: list with information from the header file
</p>
</li>
<li><p><code>radiance</code>: if applicable, a numeric vector of radiance values
</p>
</li>
<li><p><code>reference</code>: if applicable, a numeric vector of radiance values of the white reference
</p>
</li>
<li><p><code>reflectance</code>: numeric vector of reflectance values
</p>
</li>
<li><p><code>wavelength</code>: numeric vector of the band positions
</p>
</li></ul>



<h3>Note</h3>

<p>There is a <span class="rlang"><b>R</b></span> port of the &lsquo;<span class="file">importasd.m</span>&rsquo; function from the
&lsquo;FSFPostProcessing&rsquo; Matlab toolbox by Iain Robinson
(University of Edinburgh), which is based on some Java code provided
by Andreas Hunei (University of Zurich).
</p>
<p>It seems that ASD file format has changed quite a lot with file versions. The
function will possibly not work as expected for
all versions. Please report any bugs to the package maintainer.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens (<span class="rlang"><b>R</b></span> port), Iain Robinson (matlab function) &amp; Leonardo Ramirez-Lopez (<span class="rlang"><b>R</b></span> port)
</p>


<h3>References</h3>

<p>Robinson, I., and A. MacArthur. 2011. The Field Spectroscopy Facility Post
Processing Toolbox User Guide. Post processing spectral data in MATLAB,
University of Edinburgh, Edinburgh, UK.
</p>

<hr>
<h2 id='resample'>Resample spectral data</h2><span id='topic+resample'></span>

<h3>Description</h3>

<p>Resample a data matrix or vector to new coordinates (e.g.
band positions) using spline or linear interpolation. This function is a
simple wrapper around <code><a href="stats.html#topic+approx">approx</a></code> and <code><a href="stats.html#topic+splinefun">splinefun</a></code> in
<span class="pkg">base</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample(X, wav, new.wav, interpol = "spline", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resample_+3A_x">X</code></td>
<td>
<p>numeric matrix or vector to resample (optionally a data frame that
can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="resample_+3A_wav">wav</code></td>
<td>
<p>a numeric vector giving the original band positions.</p>
</td></tr>
<tr><td><code id="resample_+3A_new.wav">new.wav</code></td>
<td>
<p>a numeric vector giving the new band positions.</p>
</td></tr>
<tr><td><code id="resample_+3A_interpol">interpol</code></td>
<td>
<p>the interpolation method: 'linear' or 'spline' (default).</p>
</td></tr>
<tr><td><code id="resample_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code><a href="stats.html#topic+splinefun">splinefun</a></code>
function when <code>interpol = 'spline'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix or vector with resampled values.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resample2">resample2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# increase spectral resolution by 2
NIRsoil$spc_resampled &lt;- resample(NIRsoil$spc, wav, seq(1100, 2498, 2))
dim(NIRsoil$spc)
dim(NIRsoil$spc_resampled)
</code></pre>

<hr>
<h2 id='resample_fwhm'>Resample to given band position and fwhm</h2><span id='topic+resample_fwhm'></span>

<h3>Description</h3>

<p>Resample, written in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample_fwhm(X, wav, new_wav, fwhm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resample_fwhm_+3A_x">X</code></td>
<td>
<p>matrix to resample</p>
</td></tr>
<tr><td><code id="resample_fwhm_+3A_wav">wav</code></td>
<td>
<p>a numeric <code>vector</code> giving the original band positions</p>
</td></tr>
<tr><td><code id="resample_fwhm_+3A_new_wav">new_wav</code></td>
<td>
<p>a numeric <code>vector</code> giving the new band positions</p>
</td></tr>
<tr><td><code id="resample_fwhm_+3A_fwhm">fwhm</code></td>
<td>
<p>numeric <code>vector</code> giving the full width half maximums of the new band positions.</p>
</td></tr>
</table>

<hr>
<h2 id='resample2'>Resample a high resolution signal to a low resolution signal using full
width half maximum (FWHM) values</h2><span id='topic+resample2'></span>

<h3>Description</h3>

<p>Resample a data matrix or vector to match the response of another instrument
using full width half maximum (FWHM) values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample2(X, wav, new.wav, fwhm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resample2_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to resample (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="resample2_+3A_wav">wav</code></td>
<td>
<p>a numeric vector giving the original band positions.</p>
</td></tr>
<tr><td><code id="resample2_+3A_new.wav">new.wav</code></td>
<td>
<p>a numeric vector giving the new band positions.</p>
</td></tr>
<tr><td><code id="resample2_+3A_fwhm">fwhm</code></td>
<td>
<p>a numeric vector giving the full width half maximums of the new
band positions. If no value is specified, it is assumed that the fwhm is
equal to the sampling interval (i.e. band spacing). If only one value is
specified, the fwhm is assumed to be constant over the spectral range.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses gaussian models defined by fwhm values to resample the high
resolution data to new band positions and resolution.
It assumes that band spacing and fwhm of the input data is constant over the
spectral range.
The interpolated values are set to 0 if input data fall outside by 3 standard
deviations of the gaussian densities defined by fwhm.
</p>


<h3>Value</h3>

<p>a matrix or vector with resampled values
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resample">resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
wav &lt;- as.numeric(colnames(NIRsoil$spc))
# Plot 10 first spectra
matplot(wav, t(NIRsoil$spc[1:10, ]),
  type = "l", xlab = "Wavelength /nm",
  ylab = "Absorbance"
)
# ASTER SWIR bands (nm)
new_wav &lt;- c(1650, 2165, 2205, 2260, 2330, 2395) # positions
fwhm &lt;- c(100, 40, 40, 50, 70, 70) #  fwhm's
# Resample NIRsoil to ASTER band positions
aster &lt;- resample2(NIRsoil$spc, wav, new_wav, fwhm)
matpoints(as.numeric(colnames(aster)), t(aster[1:10, ]), pch = 1:5)
</code></pre>

<hr>
<h2 id='savitzkyGolay'>Savitzky-Golay smoothing and differentiation</h2><span id='topic+savitzkyGolay'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>Savitzky-Golay smoothing and derivative of a data matrix or vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>savitzkyGolay(X, m, p, w, delta.wav)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="savitzkyGolay_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to process (optionally a data frame that
can be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="savitzkyGolay_+3A_m">m</code></td>
<td>
<p>an integer indcating the differentiation order.</p>
</td></tr>
<tr><td><code id="savitzkyGolay_+3A_p">p</code></td>
<td>
<p>an integer indicating the polynomial order.</p>
</td></tr>
<tr><td><code id="savitzkyGolay_+3A_w">w</code></td>
<td>
<p>an integer indicating the window size (must be odd).</p>
</td></tr>
<tr><td><code id="savitzkyGolay_+3A_delta.wav">delta.wav</code></td>
<td>
<p>(optional) sampling interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Savitzky-Golay algorithm fits a local polynomial regression on the signal.
It requires evenly spaced data points. Mathematically, it operates simply as
a weighted sum over a given window:
</p>
\[ x_j\ast = \frac{1}{N}\sum_{h=-k}^{k}{c_hx_{j+h}}\]
<p>where \(x_j\ast\) is the new value, \(N\) is a
normalizing coefficient, \(k\) is the gap size on each side of
\(j\) and \(c_h\) are pre-computed coefficients, that depends
on the chosen polynomial order and degree.
</p>
<p>The sampling interval specified with the <code>delta.wav</code> argument is used for
scaling and get numerically correct derivatives.
</p>
<p>The convolution function is written in C++/Rcpp for faster computations.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>


<h3>References</h3>

<p>Luo, J., Ying, K., He, P., &amp; Bai, J. (2005). Properties of Savitzky–Golay
digital differentiators. Digital Signal Processing, 15(2), 122-136.
</p>
<p>Savitzky, A., and Golay, M.J.E., 1964. Smoothing and
differentiation of data by simplified least squares procedures.
Anal. Chem. 36, 1627-1639.
</p>
<p>Schafer, R. W. (2011). What is a Savitzky-Golay filter? (lecture notes). IEEE
Signal processing magazine, 28(4), 111-117.
</p>
<p>Wentzell, P.D., and Brown, C.D., 2000. Signal processing in analytical
chemistry. Encyclopedia of Analytical Chemistry, 9764-9800.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
opar &lt;- par(no.readonly = TRUE)
par(mfrow = c(2, 1), mar = c(4, 4, 2, 2))

# plot of the 10 first spectra
matplot(as.numeric(colnames(NIRsoil$spc)),
  t(NIRsoil$spc[1:10, ]),
  type = "l",
  xlab = "",
  ylab = "Absorbance"
)

mtext("Raw spectra")
NIRsoil$spc_sg &lt;- savitzkyGolay(
  X = NIRsoil$spc,
  m = 1,
  p = 3,
  w = 11,
  delta.wav = 2
)

matplot(as.numeric(colnames(NIRsoil$spc_sg)),
  t(NIRsoil$spc_sg[1:10, ]),
  type = "l",
  xlab = "Wavelength /nm",
  ylab = "1st derivative"
)

mtext("1st derivative spectra")
par(opar)
</code></pre>

<hr>
<h2 id='shenkWest'>SELECT algorithm for calibration sampling</h2><span id='topic+shenkWest'></span>

<h3>Description</h3>

<p>Select calibration samples from a large multivariate data using the SELECT
algorithm as described in Shenk and Westerhaus (1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shenkWest(X,
          d.min = 0.6,
          pc = 0.95,
          rm.outlier = FALSE,
          .center = TRUE,
          .scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shenkWest_+3A_x">X</code></td>
<td>
<p>a numeric matrix (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="shenkWest_+3A_d.min">d.min</code></td>
<td>
<p>a minimum distance (default = 0.6).</p>
</td></tr>
<tr><td><code id="shenkWest_+3A_pc">pc</code></td>
<td>
<p>the number of principal components retained in the computation
distance in the standardized Principal Component space (Mahalanobis distance).
If <code>pc &lt; 1</code>, the number of principal components kept corresponds to the
number of components explaining at least (<code>pc * 100</code>) percent of the total
variance (default = 0.95).</p>
</td></tr>
<tr><td><code id="shenkWest_+3A_rm.outlier">rm.outlier</code></td>
<td>
<p>logical. If <code>TRUE</code>, remove observations with a standardized
mahalanobis distance to the center of the data greater than 3
(default = <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="shenkWest_+3A_.center">.center</code></td>
<td>
<p>logical. Indicates whether the input matrix should be centered
before Principal Component Analysis. Default set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="shenkWest_+3A_.scale">.scale</code></td>
<td>
<p>logical. Indicates whether the input matrix should be scaled
before Principal Component Analysis. Default set to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SELECT algorithm is an iterative procedure based on the standardized
Mahalanobis distance between observations.
First, the observation having the highest number of neighbours within a given
minimum distance is selected and its neighbours are discarded. The procedure
is repeated until there is no observation left.
</p>
<p>If the <code>rm.outlier</code> argument is set to <code>TRUE</code>, outliers will be removed
before running the SELECT algorithm, using the CENTER algorithm of
Shenk and Westerhaus (1991), i.e. samples with a standardized Mahalanobis
distance <code style="white-space: pre;">&#8288;&gt;3&#8288;</code> are removed.
</p>


<h3>Value</h3>

<p>a <code>list</code> with components:
</p>

<ul>
<li><p>'<code>model</code>': numeric vector giving the row indices of the input data
selected for calibration
</p>
</li>
<li><p>'<code>test</code>': numeric vector giving the row indices of the remaining
observations
</p>
</li>
<li><p>'<code>pc</code>': a numeric matrix of the scaled pc scores
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Shenk, J.S., and Westerhaus, M.O., 1991. Population Definition,
Sample Selection, and Calibration Procedures for Near Infrared Reflectance
Spectroscopy. Crop Science 31, 469-474.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kenStone">kenStone</a></code>, <code><a href="#topic+duplex">duplex</a></code>, <code><a href="#topic+puchwein">puchwein</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
# reduce data size
NIRsoil$spc &lt;- binning(X = NIRsoil$spc, bin.size = 5)
sel &lt;- shenkWest(NIRsoil$spc, pc = .99, d.min = .3, rm.outlier = FALSE)
plot(sel$pc[, 1:2], xlab = "PC1", ylab = "PC2")
# points selected for calibration
points(sel$pc[sel$model, 1:2], pch = 19, col = 2)
# without outliers
sel &lt;- shenkWest(NIRsoil$spc, pc = .99, d.min = .3, rm.outlier = TRUE)
plot(sel$pc[, 1:2], xlab = "PC1", ylab = "PC2")
# points selected for calibration
points(sel$pc[sel$model, 1:2], pch = 15, col = 3)
</code></pre>

<hr>
<h2 id='spliceCorrection'>Splice correction of a spectral matrix acquired with an ASD spectrometer</h2><span id='topic+spliceCorrection'></span>

<h3>Description</h3>

<p>Corrects steps in an input spectral matrix by linear interpolation of the
values of the edges of the middle sensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spliceCorrection(X, wav, splice = c(1000, 1830), interpol.bands = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spliceCorrection_+3A_x">X</code></td>
<td>
<p>a numeric matrix or vector to transform (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
<tr><td><code id="spliceCorrection_+3A_wav">wav</code></td>
<td>
<p>a numeric vector with band positions.</p>
</td></tr>
<tr><td><code id="spliceCorrection_+3A_splice">splice</code></td>
<td>
<p>a numeric vector of length 1 or 2 with the positions of the
splice(s). Default:
<code>c(1000, 1830)</code> (as for the ASD FieldSpec Pro spectrometer of Malvern
Panalytical). See details.</p>
</td></tr>
<tr><td><code id="spliceCorrection_+3A_interpol.bands">interpol.bands</code></td>
<td>
<p>the number of interpolation bands.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses by default the positions for the ASD FieldSpec Pro
spectroradiometer (Malvern Panalytical) which usually exhibit
steps at the splice of the three built-in detectors,
positioned at 1000 nm (end of VNIR detector) and 1830 nm (end of SWIR1 detector).
The data corresponding to the spectral region after the first step is used as
reference for correcting the first region and the laste region (if 2 steps
are supplied).
Other typical examples of splice artifacts caused by concatenating data
captured by different detectors inside the spectrometer:
</p>

<ul>
<li><p>XDS (FOSS): 1100 nm
</p>
</li>
<li><p>ProxiMate (BUCHI Labortechnik): 900 nm
</p>
</li></ul>



<h3>Value</h3>

<p>a matrix with the splice corrected data.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens and <a href="https://orcid.org/0000-0002-5369-5120">Leonardo Ramirez-Lopez</a>
</p>

<hr>
<h2 id='sqrtSm'>Square root of (square) symetric matrices</h2><span id='topic+sqrtSm'></span>

<h3>Description</h3>

<p>Square root of (square) symetric matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sqrtSm(X, method = c("svd", "eigen"))
</code></pre>

<hr>
<h2 id='standardNormalVariate'>Standard normal variate transformation</h2><span id='topic+standardNormalVariate'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>This function normalizes each row of an input matrix by
subtracting each row by its mean and dividing it by its standard deviation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardNormalVariate(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardNormalVariate_+3A_x">X</code></td>
<td>
<p>a numeric matrix of spectral data (optionally a data frame that can
be coerced to a numerical matrix).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SNV is simple way for normalizing spectral data that intends to correct for
light scatter.
It operates row-wise:
</p>
\[SNV_i = \frac{x_i - \bar{x}_i}{s_i}\]
<p>where \(x_i\) is the signal of the \(i\)th observation,
\(\bar{x}_i\) is its mean and \(s_i\) its standard
deviation.
</p>


<h3>Value</h3>

<p>a matrix of normalized spectral data.
</p>


<h3>Author(s)</h3>

<p>Antoine Stevens
</p>


<h3>References</h3>

<p>Barnes RJ, Dhanoa MS, Lister SJ. 1989. Standard normal variate
transformation and de-trending of near-infrared diffuse reflectance spectra.
Applied spectroscopy, 43(5): 772-777.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+msc">msc</a></code>, <code><a href="#topic+detrend">detrend</a></code>, <code><a href="#topic+blockScale">blockScale</a></code>,
<code><a href="#topic+blockNorm">blockNorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NIRsoil)
NIRsoil$spc_snv &lt;- standardNormalVariate(X = NIRsoil$spc)
# 10 first snv spectra
matplot(
  x = as.numeric(colnames(NIRsoil$spc_snv)),
  y = t(NIRsoil$spc_snv[1:10, ]),
  type = "l",
  xlab = "wavelength, nm",
  ylab = "snv"
)
## Not run: 
apply(NIRsoil$spc_snv, 1, sd) # check

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
