<!DOCTYPE html><html><head><title>Help for package JADE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {JADE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#JADE-package'>
<p>Blind Source Separation Methods Based on Joint Diagonalization and Some BSS Performance Criteria</p></a></li>
<li><a href='#amari.error'><p>Amari Error</p></a></li>
<li><a href='#AMUSE'>
<p>AMUSE Method for Blind Source Separation</p></a></li>
<li><a href='#bss.components'>
<p>Function to Extract Estimated Sources from an Object of Class bss</p></a></li>
<li><a href='#cjd'><p>Joint Diagonalization of Complex Matrices</p></a></li>
<li><a href='#coef.bss'>
<p>Coefficients of a bss Object</p></a></li>
<li><a href='#ComonGAP'><p> Comon's Gap</p></a></li>
<li><a href='#CPPdata'>
<p>Cocktail Party Problem Data</p></a></li>
<li><a href='#djd'>
<p>Function for Joint Diagonalization of k Square Matrices in a Deflation Based Manner</p></a></li>
<li><a href='#FG'>
<p>Joint Diagonalization of Real Positive-definite Matrices</p></a></li>
<li><a href='#FOBI'>
<p>Function to perform FOBI for ICA</p></a></li>
<li><a href='#JADE'><p> JADE Algorithm for ICA</p></a></li>
<li><a href='#k_JADE'>
<p>Fast Equivariant k-JADE Algorithm for ICA</p></a></li>
<li><a href='#MD'><p>Minimum Distance index MD</p></a></li>
<li><a href='#multscatter'>
<p>Function to Compute Several Scatter Matrices for the Same Data</p></a></li>
<li><a href='#NSS.JD'>
<p>NSS.JD Method for Nonstationary Blind Source Separation</p></a></li>
<li><a href='#NSS.SD'>
<p>NSS.SD Method for Nonstationary Blind Source Separation</p></a></li>
<li><a href='#NSS.TD.JD'>
<p>NSS.TD.JD Method for Nonstationary Blind Source Separation</p></a></li>
<li><a href='#plot.bss'><p>Plotting an Object of Class bss</p></a></li>
<li><a href='#print.bss'><p>Printing an Object of Class bss</p></a></li>
<li><a href='#rjd'><p>Joint Diagonalization of Real Matrices</p></a></li>
<li><a href='#SIR'><p> Signal to Interference Ratio</p></a></li>
<li><a href='#SOBI'>
<p>SOBI Method for Blind Source Separation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Blind Source Separation Methods Based on Joint Diagonalization
and Some BSS Performance Criteria</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Klaus Nordhausen <a href="https://orcid.org/0000-0002-3758-8501"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Jean-Francois Cardoso [aut],
  Jari Miettinen <a href="https://orcid.org/0000-0002-3270-7014"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Hannu Oja <a href="https://orcid.org/0000-0002-4945-5976"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Esa Ollila [aut],
  Sara Taskinen <a href="https://orcid.org/0000-0001-9470-7258"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Klaus Nordhausen &lt;klausnordhausenR@gmail.com&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>clue, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ICS, ICSNP</td>
</tr>
<tr>
<td>Description:</td>
<td>Cardoso's JADE algorithm as well as his functions for joint diagonalization are ported to R. Also several other blind source separation (BSS) methods, like AMUSE and SOBI, and some criteria for performance evaluation of BSS algorithms, are given. The package is described in Miettinen, Nordhausen and Taskinen (2017) &lt;<a href="https://doi.org/10.18637%2Fjss.v076.i02">doi:10.18637/jss.v076.i02</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-17 14:20:22 UTC; admin</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-17 23:02:33 UTC</td>
</tr>
</table>
<hr>
<h2 id='JADE-package'>
Blind Source Separation Methods Based on Joint Diagonalization and Some BSS Performance Criteria
</h2><span id='topic+JADE-package'></span>

<h3>Description</h3>

<p>Cardoso's JADE algorithm as well as his functions for joint diagonalization are ported to R. Also several other blind source separation (BSS) methods, like AMUSE and SOBI, and some criteria for performance evaluation of BSS algorithms, are given. The package is described in Miettinen, Nordhausen and Taskinen (2017) &lt;doi:10.18637/jss.v076.i02&gt;. 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> JADE</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Blind Source Separation Methods Based on Joint Diagonalization
and Some BSS Performance Criteria</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.0-4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-09-17</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person(given = "Klaus", family = "Nordhausen", role = c("aut", "cre"), email = "klausnordhausenR@gmail.com",
    comment = c(ORCID = "0000-0002-3758-8501")),
    person(given = "Jean-Francois", family = "Cardoso", role = "aut"),
    person(given = "Jari", family = "Miettinen", role = "aut",
    comment = c(ORCID = "0000-0002-3270-7014")),
    person(given = "Hannu", family = "Oja", role = "aut", comment = c(ORCID = "0000-0002-4945-5976")),
    person(given = "Esa", family = "Ollila", role = "aut"),
    person(given = "Sara", family = "Taskinen", role = "aut",
    comment = c(ORCID = "0000-0001-9470-7258")))</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> 
    Klaus Nordhausen [aut, cre] (&lt;https://orcid.org/0000-0002-3758-8501&gt;),
    Jean-Francois Cardoso [aut], 
    Jari Miettinen [aut] (&lt;https://orcid.org/0000-0002-3270-7014&gt;),
    Hannu Oja [aut] (&lt;https://orcid.org/0000-0002-4945-5976&gt;),
    Esa Ollila [aut],
    Sara Taskinen [aut] (&lt;https://orcid.org/0000-0001-9470-7258&gt;)</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Klaus Nordhausen &lt;klausnordhausenR@gmail.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> clue, graphics</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> ICS, ICSNP</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Cardoso's JADE algorithm as well as his functions for joint diagonalization are ported to R. Also several other blind source separation (BSS) methods, like AMUSE and SOBI, and some criteria for performance evaluation of BSS algorithms, are given. The package is described in Miettinen, Nordhausen and Taskinen (2017) &lt;doi:10.18637/jss.v076.i02&gt;. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyData: </td><td style="text-align: left;"> true</td>
</tr>
<tr>
 <td style="text-align: left;">
Archs: </td><td style="text-align: left;"> x64</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
AMUSE                   AMUSE Method for Blind Source Separation
CPPdata                 Cocktail Party Problem Data
ComonGAP                Comon's Gap
FG                      Joint Diagonalization of Real Positive-definite
                        Matrices
FOBI                    Function to perform FOBI for ICA
JADE                    JADE Algorithm for ICA
JADE-package            Blind Source Separation Methods Based on Joint
                        Diagonalization and Some BSS Performance
                        Criteria
MD                      Minimum Distance index MD
NSS.JD                  NSS.JD Method for Nonstationary Blind Source
                        Separation
NSS.SD                  NSS.SD Method for Nonstationary Blind Source
                        Separation
NSS.TD.JD               NSS.TD.JD Method for Nonstationary Blind Source
                        Separation
SIR                     Signal to Interference Ratio
SOBI                    SOBI Method for Blind Source Separation
amari.error             Amari Error
bss.components          Function to Extract Estimated Sources from an
                        Object of Class bss
cjd                     Joint Diagonalization of Complex Matrices
coef.bss                Coefficients of a bss Object
djd                     Function for Joint Diagonalization of k Square
                        Matrices in a Deflation Based Manner
k_JADE                  Fast Equivariant k-JADE Algorithm for ICA
multscatter             Function to Compute Several Scatter Matrices
                        for the Same Data
plot.bss                Plotting an Object of Class bss
print.bss               Printing an Object of Class bss
rjd                     Joint Diagonalization of Real Matrices
</pre>


<h3>Author(s)</h3>


<p>    Klaus Nordhausen [aut, cre] (&lt;https://orcid.org/0000-0002-3758-8501&gt;),
    Jean-Francois Cardoso [aut], 
    Jari Miettinen [aut] (&lt;https://orcid.org/0000-0002-3270-7014&gt;),
    Hannu Oja [aut] (&lt;https://orcid.org/0000-0002-4945-5976&gt;),
    Esa Ollila [aut],
    Sara Taskinen [aut] (&lt;https://orcid.org/0000-0001-9470-7258&gt;)
</p>
<p>Maintainer: Klaus Nordhausen &lt;klausnordhausenR@gmail.com&gt;
</p>


<h3>References</h3>

<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>

<hr>
<h2 id='amari.error'>Amari Error</h2><span id='topic+amari.error'></span>

<h3>Description</h3>

<p>Computes the Amari Error to evaluate the performance of an ICA algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amari.error(W.hat, A, standardize = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amari.error_+3A_w.hat">W.hat</code></td>
<td>
<p>The estimated square unmixing matrix W.</p>
</td></tr>
<tr><td><code id="amari.error_+3A_a">A</code></td>
<td>
<p>The true square mixing matrix A.</p>
</td></tr>
<tr><td><code id="amari.error_+3A_standardize">standardize</code></td>
<td>
<p>Logical value if A and W.hat need to be standardized. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Amari Error can be used in simulation studies to evaluate the performance of an
ICA algorithm. The Amari error is permutation invariant but not scale invariant. Therefore if different
algorithms should be compared the matrices should be scaled in the same way.
If <code>standardize</code> is TRUE, this will be done by the function by standardizing 'W.hat' and the inverse of 'A'
in such a way, that every row has length 1, the largest absolute value of the row has a positive sign
and the rows are ordered decreasingly according to their largest values.
</p>
<p>Note that this function assumes the ICA model is <code class="reqn">X = S A'</code>, as is assumed by <code><a href="#topic+JADE">JADE</a></code> and <code>ics</code>. However <code>fastICA</code> and 
<code>PearsonICA</code> assume <code class="reqn">X = S A</code>. Therefore matrices from those functions have to be transposed first.
</p>
<p>The Amari Error is scaled in such a way, that it takes a value between 0 and 1. And 0 corresponds to an optimal separation.  
</p>


<h3>Value</h3>

<p>The value of the Amari Error.
</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Amari, S., Cichocki, A. and Yang, H.H. (1996), A new learning algorithm for blind signal separation, <em>Advances in Neural Information Processing Systems</em>, <b>8</b>,  757&ndash;763. </cite>
</p>
<p><cite>Nordhausen, K., Ollila, E. and Oja, H. (2011), On the Performance Indices of ICA and Blind Source Separation. In the Proceedings of <em>2011 IEEE 12th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC 2011)</em>, 486&ndash;490.</cite>  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ComonGAP">ComonGAP</a></code>, <code><a href="#topic+SIR">SIR</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)

W.hat &lt;- JADE(X, 3)$W
amari.error(W.hat, A)
amari.error(W.hat, A, TRUE)
</code></pre>

<hr>
<h2 id='AMUSE'>
AMUSE Method for Blind Source Separation
</h2><span id='topic+AMUSE'></span><span id='topic+AMUSE.default'></span><span id='topic+AMUSE.ts'></span>

<h3>Description</h3>

<p>AMUSE method for the second order blind source separation problem. The function estimates
the unmixing matrix in a second order stationary source separation model by jointly diagonalizing
the covariance matrix and an autocovariance matrix at lag k.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AMUSE(x, ...)

## Default S3 method:
AMUSE(x, k = 1, ...)
## S3 method for class 'ts'
AMUSE(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AMUSE_+3A_x">x</code></td>
<td>
<p>a numeric matrix or a multivariate time series object of class <code><a href="stats.html#topic+ts">ts</a></code>. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="AMUSE_+3A_k">k</code></td>
<td>
<p>integer lag for the autocovariance matrix, must be larger than 0. Default is 1.</p>
</td></tr>
<tr><td><code id="AMUSE_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The lag <code>k</code> has a huge effect on the performance and it should be chosen so that the eigenvalues of autocovariance matrix are distinct. The function assumes always as many sources as there are time series.
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>EV</code></td>
<td>
<p>eigenvectors of autocovariance matrix.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>lag of the autocovariance matrix used.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>estimated sources as time series objected standardized to have mean 0 and unit variances.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Tong, L., Soon, V.C., Huang, Y.F. and Liu, R. (1990), AMUSE: a new blind identification algorithm, in Proceedings of IEEE International Symposium on
<em>Circuits and Systems 1990</em>, 1784&ndash;1787.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K., Oja, H. and Taskinen, S. (2012), Statistical properties of a blind source separation estimator for stationary time series, 
<em>Statistics &amp; Probability Letters</em>, 82, 1865&ndash;1873.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>            
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># creating some toy data
A&lt;- matrix(rnorm(9),3,3)
s1 &lt;- arima.sim(list(ar=c(0.3,0.6)),1000)
s2 &lt;- arima.sim(list(ma=c(-0.3,0.3)),1000)
s3 &lt;- arima.sim(list(ar=c(-0.8,0.1)),1000)

S &lt;- cbind(s1,s2,s3)
X &lt;- S %*% t(A)

res1&lt;-AMUSE(X)
res1
coef(res1)
plot(res1) # compare to plot.ts(S)
MD(coef(res1),A)

# input of a time series
X2&lt;- ts(X, start=c(1961, 1), frequency=12)
plot(X2)
res2&lt;-AMUSE(X2, k=2)
plot(res2)
</code></pre>

<hr>
<h2 id='bss.components'>
Function to Extract Estimated Sources from an Object of Class bss
</h2><span id='topic+bss.components'></span>

<h3>Description</h3>

<p>Extracts the sources estimated by an bss method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bss.components(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bss.components_+3A_object">object</code></td>
<td>
<p>object of class bss</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>Examples</h3>

<pre><code class='language-R'>A&lt;- matrix(rnorm(9),3,3)
s1 &lt;- arima.sim(list(ar=c(0.3,0.6)),1000)
s2 &lt;- arima.sim(list(ma=c(-0.3,0.3)),1000)
s3 &lt;- arima.sim(list(ar=c(-0.8,0.1)),1000)

S &lt;- cbind(s1,s2,s3)
X &lt;- S %*% t(A)

res1&lt;-AMUSE(X)
head(bss.components(res1))
colMeans(bss.components(res1))
cov(bss.components(res1))
</code></pre>

<hr>
<h2 id='cjd'>Joint Diagonalization of Complex Matrices</h2><span id='topic+cjd'></span>

<h3>Description</h3>

<p>This is an <span class="pkg">R</span> version of Cardoso's joint_diag matlab function for joint diagonalization of k complex-valued square matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cjd(X, eps = 1e-06, maxiter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cjd_+3A_x">X</code></td>
<td>
<p>A matrix of k stacked pxp complex matrices with dimension c(kp,p) or an array with dimension c(p,p,k).</p>
</td></tr>
<tr><td><code id="cjd_+3A_eps">eps</code></td>
<td>
<p> Convergence tolerance.</p>
</td></tr>
<tr><td><code id="cjd_+3A_maxiter">maxiter</code></td>
<td>
<p> Maximum number of iterations.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>V</code></td>
<td>
<p>An orthogonal matrix.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>A stacked matrix with the diagonal matrices or an array with the diagonal matrices. The form of the output
depends on the form of the input.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jean-Francois Cardoso. Ported to <span class="pkg">R</span> by Klaus Nordhausen.</p>


<h3>References</h3>

<p><cite>Cardoso, J.-F. and Souloumiac, A., (1996), Jacobi angles for simultaneous diagonalization, <em>SIAM J. Mat. Anal. Appl.</em>, <b>17</b>,  161&ndash;164.</cite>  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rjd">rjd</a></code>, <code><a href="#topic+rjd.fortran">rjd.fortran</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D1 &lt;- diag(complex(real=runif(3,0,2), imaginary=runif(3)))
D2 &lt;- diag(complex(real=runif(3,0,2), imaginary=runif(3)))
D3 &lt;- diag(complex(real=runif(3,0,2), imaginary=runif(3)))
D4 &lt;- diag(complex(real=runif(3,0,2), imaginary=runif(3)))

Z &lt;- matrix(runif(9), ncol = 3)
V &lt;- eigen(Z %*% t(Z))$vectors

M1 &lt;- t(V)%*%D1%*%V
M2 &lt;- t(V)%*%D2%*%V
M3 &lt;- t(V)%*%D3%*%V
M4 &lt;- t(V)%*%D4%*%V
MS &lt;- rbind(M1,M2,M3,M4)
Ms &lt;- array(0,dim=c(3,3,4))
Ms[,,1]&lt;-M1
Ms[,,3]&lt;-M3
Ms[,,2]&lt;-M2
Ms[,,4]&lt;-M4
res.array &lt;- cjd(Ms)
res.mat &lt;- cjd(MS)
Re(res.array$V)
V
round(V%*%Re(res.array$V),2)
round(V%*%Re(res.mat$V),2)
</code></pre>

<hr>
<h2 id='coef.bss'>
Coefficients of a bss Object
</h2><span id='topic+coef.bss'></span>

<h3>Description</h3>

<p>Extracts the estimated unmixing matrix from an object of class bss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bss'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.bss_+3A_object">object</code></td>
<td>
<p>object of class bss.</p>
</td></tr>
<tr><td><code id="coef.bss_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>Examples</h3>

<pre><code class='language-R'>A&lt;- matrix(rnorm(9),3,3)
s1 &lt;- arima.sim(list(ar=c(0.3,0.6)),1000)
s2 &lt;- arima.sim(list(ma=c(-0.3,0.3)),1000)
s3 &lt;- arima.sim(list(ar=c(-0.8,0.1)),1000)

S &lt;- cbind(s1,s2,s3)
X &lt;- S %*% t(A)

res1&lt;-AMUSE(X)
coef(res1)
coef(res1) %*% A # should be a matrix with one dominant element in each row and column
</code></pre>

<hr>
<h2 id='ComonGAP'> Comon's Gap</h2><span id='topic+ComonGAP'></span>

<h3>Description</h3>

<p>Comon's GAP criterion to evaluate the performance of an ICA algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ComonGAP(A, A.hat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ComonGAP_+3A_a">A</code></td>
<td>
<p>The true square mixing matrix.</p>
</td></tr>
<tr><td><code id="ComonGAP_+3A_a.hat">A.hat</code></td>
<td>
<p>The estimated square mixing matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Comon's GAP criterion is permutation and scale invariant. It can take every positive value and 0 corresponds to an optimal separation.
If <code>A</code> is however nearly singular the values of the criterion can be huge.
</p>
<p>Note that this function assumes the ICA model is <code class="reqn">X = S A'</code>, as is assumed by <code><a href="#topic+JADE">JADE</a></code> and <code>ics</code>. However <code>fastICA</code> and 
<code>PearsonICA</code> assume <code class="reqn">X = S A</code>. Therefore matrices from those functions have to be transposed first.
</p>


<h3>Value</h3>

<p>The value of the Comon's GAP.
</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Comon, P., (1994), Independent Component Analysis, A new concept?, <em>Signal Processing</em>, <b>36</b>,  287&ndash;314. </cite>  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amari.error">amari.error</a></code>, <code><a href="#topic+SIR">SIR</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)

A.hat &lt;- JADE(X, 3)$A
ComonGAP(A, A.hat)
</code></pre>

<hr>
<h2 id='CPPdata'>
Cocktail Party Problem Data
</h2><span id='topic+CPPdata'></span>

<h3>Description</h3>

<p>This data set is a toy example for the so called cocktail party problem. In this case three sounds are mixed together with one noise source using four microphones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CPPdata")</code></pre>


<h3>Format</h3>

<p>A data frame with 50000 observations on the following 4 variables.
</p>

<dl>
<dt><code>Mic1</code></dt><dd><p>the mixture recorded by the first microphone.</p>
</dd>
<dt><code>Mic2</code></dt><dd><p>the mixture recorded by the second microphone.</p>
</dd>
<dt><code>Mic3</code></dt><dd><p>the mixture recorded by the third microphone.</p>
</dd>
<dt><code>Mic4</code></dt><dd><p>the mixture recorded by the fourth microphone.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The three original source files were kindly provided by Ella Bingham and are also available online at the following locations:
<a href="https://research.ics.aalto.fi/ica/cocktail/source5.wav">https://research.ics.aalto.fi/ica/cocktail/source5.wav</a>, <a href="https://research.ics.aalto.fi/ica/cocktail/source7.wav">https://research.ics.aalto.fi/ica/cocktail/source7.wav</a> and <a href="https://research.ics.aalto.fi/ica/cocktail/source9.wav">https://research.ics.aalto.fi/ica/cocktail/source9.wav</a>.
</p>
<p>Note that the original sound files are included in the package's subfolder datafiles. In the example section we illustrate how the CPPdata was created. 
An example analysis of the data is given in Miettinen et al. (2017).
</p>


<h3>Source</h3>

<p>Ella Bingham
</p>


<h3>References</h3>

<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the data was created as follows:
library("tuneR")
S1 &lt;- readWave(system.file("datafiles/source5.wav", package = "JADE"))
S2 &lt;- readWave(system.file("datafiles/source7.wav", package = "JADE"))
S3 &lt;- readWave(system.file("datafiles/source9.wav", package = "JADE"))

set.seed(321)
NOISE &lt;- noise("white", duration = 50000)
S &lt;- cbind(S1@left, S2@left, S3@left, NOISE@left)
S &lt;- scale(S, center = FALSE, scale = apply(S, 2, sd))
St &lt;- ts(S, start = 0, frequency = 8000)
p &lt;- 4
A &lt;- matrix(runif(p^2, 0, 1), p, p)
A

X &lt;- tcrossprod(St, A)
Xt &lt;- as.ts(X)

colnames(X) &lt;- c("Mic1", "Mic2", "Mic3", "Mic4")
CPPdata &lt;- as.data.frame(X)

## End(Not run)
</code></pre>

<hr>
<h2 id='djd'>
Function for Joint Diagonalization of k Square Matrices in a Deflation Based Manner  
</h2><span id='topic+djd'></span>

<h3>Description</h3>

<p>This function jointly diagonalizes k real-valued square matrices by searching an orthogonal matrix in a deflation based manner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>djd(X, G = "max", r = 2, eps = 1e-06, maxiter = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="djd_+3A_x">X</code></td>
<td>

<p>an array containing the k p times p real valued matrices of dimension  c(p, p, k).
</p>
</td></tr>
<tr><td><code id="djd_+3A_g">G</code></td>
<td>

<p>criterion function used for the the algorithm. Options are <code>max</code>, <code>pow</code> and <code>log</code>. See details.
</p>
</td></tr>
<tr><td><code id="djd_+3A_r">r</code></td>
<td>

<p>power value used if <code>G="pow"</code> or <code>G="max"</code>. 0 is not meaningful for this value. See details.
</p>
</td></tr>
<tr><td><code id="djd_+3A_eps">eps</code></td>
<td>

<p>convergence tolerance.
</p>
</td></tr>
<tr><td><code id="djd_+3A_maxiter">maxiter</code></td>
<td>

<p>maximum number of iterations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Denote the square matrices as <code class="reqn">A_i</code>, <code class="reqn">i=1,\ldots,k</code>. This algorithm searches then an orthogonal matrix W
so that  <code class="reqn">D_i=W'A_iW</code> is diagonal for all <code class="reqn">i</code>. If the <code class="reqn">A_i</code> commute then there is an exact solution. If not, the function
will perform an approximate joint diagonalization by maximizing <code class="reqn">\sum G(w_j' A_i w_j)</code> where <code class="reqn">w_j</code> are the orthogonal vectors in W. 
</p>
<p>The function G can be choosen to be of the form <code class="reqn">G(x) = |x|^r</code> or  <code class="reqn">G(x) = log(x)</code>. If <code>G="max"</code> is chosen, the function G is of the form <code class="reqn">G(x) = |x|^r</code>, and the diagonalization criterion will be maximized globally at each stage by choosing an appropriate initial value from a set
of random vectors. If <code>G="pow"</code> or <code>G="log"</code> are chosen, the initial values are the eigenvectors of <code class="reqn">A_1</code> which plays hence a special role.
</p>


<h3>Value</h3>

<p>The matrix W
</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen, Jari Miettinen</p>


<h3>References</h3>

<p><cite>Nordhausen, K., Gutch, H. W., Oja, H. and Theis, F.J. (2012): Joint Diagonalization of Several Scatter Matrices for ICA, in <em>LVA/ICA 2012</em>, LNCS 7191, pp. 172&ndash;179.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K., Oja, H. and Taskinen, S. (2014),  Deflation-based Separation of Uncorrelated Stationary Time Series, 
<em>Journal of Multivariate Analysis</em>, 123, 214&ndash;227.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Z &lt;- matrix(runif(9), ncol = 3)
U &lt;- eigen(Z %*% t(Z))$vectors
D1 &lt;- diag(runif(3))
D2 &lt;- diag(runif(3))
D3 &lt;- diag(runif(3))
D4 &lt;- diag(runif(3))

X.matrix &lt;- array(0, dim=c(3, 3, 4))
X.matrix[,,1] &lt;- t(U) %*% D1 %*% U
X.matrix[,,2] &lt;- t(U) %*% D2 %*% U
X.matrix[,,3] &lt;- t(U) %*% D3 %*% U
X.matrix[,,4] &lt;- t(U) %*% D4 %*% U

W1 &lt;- djd(X.matrix)
round(U %*% W1, 4) # should be a signed permutation 
                     # matrix if W1 is correct.

W2 &lt;- djd(X.matrix, r=1)
round(U %*% W2, 4) # should be a signed permutation 
                     # matrix if W2 is correct.

W3 &lt;- djd(X.matrix, G="l")
round(U %*% W3, 4) # should be a signed permutation 
                     # matrix if W3 is correct.

</code></pre>

<hr>
<h2 id='FG'>
Joint Diagonalization of Real Positive-definite Matrices
</h2><span id='topic+FG'></span>

<h3>Description</h3>

<p>This is a slightly modified version of Flury's FG algorithm for the joint diagonalization of k positive-definite matrices.
The underlying function is written in C.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FG(X, weight = NULL, init = NULL, maxiter = 100, eps = 1e-06, na.action = na.fail)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FG_+3A_x">X</code></td>
<td>
<p>A matrix of k stacked pxp matrices with dimension c(kp,p) or an array with dimension c(p,p,k).</p>
</td></tr>
<tr><td><code id="FG_+3A_weight">weight</code></td>
<td>
<p>A vector of length k to give weight to the different matrices, if NULL, all matrices have equal weight.</p>
</td></tr>
<tr><td><code id="FG_+3A_init">init</code></td>
<td>
<p>Initial value for the orthogonal matrix to be estimated, if NULL, the identity matrix is used.</p>
</td></tr>
<tr><td><code id="FG_+3A_maxiter">maxiter</code></td>
<td>
<p> Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="FG_+3A_eps">eps</code></td>
<td>
<p> Convergence tolerance.</p>
</td></tr>
<tr><td><code id="FG_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when the data
contain 'NA's.  Default is to fail.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the components
</p>
<table>
<tr><td><code>V</code></td>
<td>
<p>An orthogonal matrix.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>A stacked matrix with the diagonal matrices or an array with the diagonal matrices. The form of the output
depends on the form of the input.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The Fortran function returns also the number of iterations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jari Miettinen</p>


<h3>References</h3>

<p><cite>Flury, B. D. (1998), Common principal components and related models, Wiley, New York.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rjd">rjd</a></code>, <code><a href="#topic+rjd.fortran">rjd.fortran</a></code>
</p>

<hr>
<h2 id='FOBI'>
Function to perform FOBI for ICA
</h2><span id='topic+FOBI'></span>

<h3>Description</h3>

<p>The FOBI method for independent component analysis (ICA). We assume that all components have different kurtosis values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FOBI(X, na.action = na.fail)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FOBI_+3A_x">X</code></td>
<td>
<p>a numeric matrix.</p>
</td></tr>
<tr><td><code id="FOBI_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when the data
contain 'NA's.  Default is to fail.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>EV</code></td>
<td>
<p>eigenvectors of autocovariance matrix.</p>
</td></tr>
<tr><td><code>Xmu</code></td>
<td>
<p>the original mean of the data.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>estimated sources as time series objected standardized to have mean 0 and unit variances.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>More general is the function <code><a href="ICS.html#topic+ics">ics</a></code> in the <span class="pkg">ICS</span> package. 
</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Cardoso, J.-F. (1989), Source separation using higher order moments, in Proceedings of IEEE International Conference
on Accoustics, Speech and Signal Processing, 2109&ndash;2112.</cite>
</p>
<p><cite>Miettinen, J., Taskinen S., Nordhausen, K. and Oja, H. (2015), Fourth Moments and Independent
Component Analysis, <em>Statistical Science</em>, 30, 372&ndash;390.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="ICS.html#topic+ics">ics</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 3 source and 3 signals

S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)
res&lt;-FOBI(X)
MD(coef(res),A)
</code></pre>

<hr>
<h2 id='JADE'> JADE Algorithm for ICA </h2><span id='topic+JADE'></span>

<h3>Description</h3>

<p>This is an <span class="pkg">R</span> version of Cardoso's JADE ICA algorithm (for real data) ported from matlab. The ported version is 1.5. Some minor changes compared to the matlab function are explained in the details section. The matlab code can be found for example on the ICA central homepage.
</p>
<p>The function uses <code><a href="#topic+frjd">frjd</a></code> for the joint diagonalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JADE(X, n.comp = NULL, eps = 1e-06, maxiter = 100, na.action = na.fail)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JADE_+3A_x">X</code></td>
<td>
<p>Numeric data matrix or dataframe. </p>
</td></tr>
<tr><td><code id="JADE_+3A_n.comp">n.comp</code></td>
<td>
<p>Number of components to extract.</p>
</td></tr>
<tr><td><code id="JADE_+3A_eps">eps</code></td>
<td>
<p>Convergence tolerance.</p>
</td></tr>
<tr><td><code id="JADE_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="JADE_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when the data
contain 'NA's.  Default is to fail.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some minor modifications were done when porting the function to <span class="pkg">R</span>, and they are:
</p>

<dl>
<dt>1</dt><dd><p>the model assumed here is <code class="reqn">X=S A' +\mu</code>. Therefore <code class="reqn">S</code> and <code class="reqn">X</code> have one row per observation. Note that this still differs from 
the model definition in <span class="pkg">R</span> of <code>FastICA</code> and <code>PearsonICA</code> but agrees with <code>ics</code>.</p>
</dd>
<dt>2</dt><dd><p>The whitening covariance matrix is divided by n-1 and not n (n = number of observations).</p>
</dd>
<dt>3</dt><dd><p>The initial value for the joint diagonalisation is always I.</p>
</dd>
<dt>4</dt><dd><p>The original eps would be <code class="reqn">\frac{1}{100\sqrt{n}}</code>.</p>
</dd>
</dl>

<p>It is also worth mentioning that the estimated independent components <code class="reqn">S</code> are scaled to unit variance and are ordered in such a way, that their fourth moments are in the decreasing order.
The signs of the unmixing matrix <code class="reqn">W</code> are fixed so that the sum of the elements on each row is positive.
</p>
<p>The code is based on the original matlab code (&quot;MatlabjadeR.m&quot;). 
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>A</code></td>
<td>
<p>The estimated mixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>The estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>Dataframe with the estimated independent components.</p>
</td></tr>
<tr><td><code>Xmu</code></td>
<td>
<p>The location of the original data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jean-Francois Cardoso. Ported to <span class="pkg">R</span> by Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Cardoso, J.-F. and Souloumiac, A., (1993), Blind beamforming for non Gaussian signals, <em>IEE Proceedings-F</em>, <b>140</b>,  362&ndash;370.</cite>  
</p>
<p><cite>Miettinen, J., Taskinen S., Nordhausen, K. and Oja, H. (2015), Fourth Moments and Independent
Component Analysis, <em>Statistical Science</em>, 30, 372&ndash;390.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 3 source and 3 signals

S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)
res&lt;-JADE(X,3)
res$A
res$W
res$S[1:10,]
(sweep(X,2,res$Xmu) %*% t(res$W))[1:10,]
round(res$W %*% A,4) 

# 2 sources and 3 signals

S2 &lt;- cbind(rt(1000, 4), rnorm(1000)) 
A2 &lt;- matrix(rnorm(6), ncol = 2)
X2 &lt;- S2 %*% t(A2)
res2 &lt;-JADE(X2,2)
res2$A
res2$W
res2$S[1:10,]
(sweep(X2,2,res2$Xmu) %*% t(res2$W))[1:10,]
SIR(S2,res2$S)
</code></pre>

<hr>
<h2 id='k_JADE'>
Fast Equivariant k-JADE Algorithm for ICA 
</h2><span id='topic+k_JADE'></span>

<h3>Description</h3>

<p>This algorithm generalizes the <code><a href="#topic+JADE">JADE</a></code> algorithm, as it provides <code><a href="#topic+JADE">JADE</a></code> when k is set to the number of dimensions. Otherwise k can be considered as a way to reduce the number of cumulant matrices to be jointly diagonalized. Hence small values of k speed up the method considerably in high-dimensional cases. In general, k can be considered as maximum number of underlying identical sources.  
</p>
<p>The function uses <code><a href="#topic+FOBI">FOBI</a></code> as an initial estimate and <code><a href="#topic+frjd">frjd</a></code> for the joint diagonalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>k_JADE(X, k = 1, eps = 1e-06, maxiter = 100, na.action = na.fail)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k_JADE_+3A_x">X</code></td>
<td>
<p>Numeric data matrix or dataframe.</p>
</td></tr>
<tr><td><code id="k_JADE_+3A_k">k</code></td>
<td>
<p>integer value between 1 and the number of columns of X. Default is 1.</p>
</td></tr>
<tr><td><code id="k_JADE_+3A_eps">eps</code></td>
<td>
<p>Convergence tolerance.</p>
</td></tr>
<tr><td><code id="k_JADE_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="k_JADE_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when the data
contain 'NA's.  Default is to fail.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The order of the estimated components is fixed so that their fourth moments are in the decreasing order.
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>A</code></td>
<td>
<p>The estimated mixing matrix.</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>The estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>Matrix with the estimated independent components.</p>
</td></tr>
<tr><td><code>Xmu</code></td>
<td>
<p>The location of the original data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses <code><a href="#topic+FOBI">FOBI</a></code> as initial estimate and <code><a href="#topic+frjd">frjd</a></code> for the joint diagonalization.
</p>


<h3>Author(s)</h3>

<p>Jari Miettinen
</p>


<h3>References</h3>

<p><cite>Miettinen, J., Nordhausen, K., Oja, H. and Taskinen, S. (2013), Fast Equivariant JADE, 
In the Proceedings of <em>38th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2013)</em>, 6153&ndash;6157.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+JADE">JADE</a></code>, <code><a href="#topic+FOBI">FOBI</a></code>, <code><a href="#topic+frjd">frjd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 3 source and 3 signals

S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)
res_k1&lt;-k_JADE(X,1)
res_k1$A
res_k1$W
res_k1$S[1:10,]

MD(coef(res_k1),A) 

</code></pre>

<hr>
<h2 id='MD'>Minimum Distance index MD</h2><span id='topic+MD'></span>

<h3>Description</h3>

<p>Computes the Minimum Distance index MD to evaluate the performance of an ICA algorithm.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MD(W.hat, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MD_+3A_w.hat">W.hat</code></td>
<td>
<p>The estimated square unmixing matrix W.</p>
</td></tr>
<tr><td><code id="MD_+3A_a">A</code></td>
<td>
<p>The true square mixing matrix A.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">MD(\hat{W},A)=\frac{1}{\sqrt{p-1}} \inf_{P D}{||PD \hat{W} A-I||,}</code>
</p>

<p>where <code class="reqn">P</code> is a permutation matrix and <code class="reqn">D</code> a diagonal matrix with nonzero diagonal entries.
</p>
<p>The step that minimizes the index of the set over all permutation matrix can be expressed as a linear sum assignment problem (LSAP)
for which we use as solver the Hungarian method implemented as <code>solve_LASP</code> in the <span class="pkg">clue</span> package.
</p>
<p>Note that this function assumes the ICA model is <code class="reqn">X = S A'</code>, as is assumed by <code><a href="#topic+JADE">JADE</a></code> and <code>ics</code>. However <code>fastICA</code> and 
<code>PearsonICA</code> assume <code class="reqn">X = S A</code>. Therefore matrices from those functions have to be transposed first.
</p>
<p>The MD index is scaled in such a way, that it takes a value between 0 and 1. And 0 corresponds to an optimal separation.  
</p>


<h3>Value</h3>

<p>The value of the MD index.</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Ilmonen, P., Nordhausen, K., Oja, H. and Ollila, E. (2010), A New Performance Index for ICA: Properties, Computation and Asymptotic Analysis. 
In Vigneron, V., Zarzoso, V., Moreau, E., Gribonval, R. and Vincent, E. (editors) <em>Latent Variable Analysis and Signal Separation</em>, 229&ndash;236, Springer.</cite>
</p>
<p><cite>Nordhausen, K., Ollila, E. and Oja, H. (2011), On the Performance Indices of ICA and Blind Source Separation. In the Proceedings of <em>2011 IEEE 12th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC 2011)</em>, 486&ndash;490.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ComonGAP">ComonGAP</a></code>, <code><a href="#topic+SIR">SIR</a></code>, <code><a href="#topic+amari.error">amari.error</a></code>, <code><a href="clue.html#topic+solve_LSAP">solve_LSAP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)

W.hat &lt;- JADE(X, 3)$W
MD(W.hat, A)
</code></pre>

<hr>
<h2 id='multscatter'>
Function to Compute Several Scatter Matrices for the Same Data 
</h2><span id='topic+multscatter'></span>

<h3>Description</h3>

<p>The function can be used to compute several scatter matrices for the same data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multscatter(scatterlist, X, toshape = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multscatter_+3A_scatterlist">scatterlist</code></td>
<td>

<p>a vector with the names of the scatter matrices to be computed. Note that each of these functions should only return a matrix of size p times p.
</p>
</td></tr>
<tr><td><code id="multscatter_+3A_x">X</code></td>
<td>

<p>the n times p data matrix for which the scatter should be computed.
</p>
</td></tr>
<tr><td><code id="multscatter_+3A_toshape">toshape</code></td>
<td>

<p>logical, whether scatter matrices should be converted to shape matrices. If TRUE, all matrices will have determinant 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is important that the functions do not need any additional imput and that they return only the p times p scatter matrix. Hence it might be sometimes necessary
to write wrappers for some of the functions. See examples.
</p>


<h3>Value</h3>

<p>An array of dimension c(p,p,k) where k is the number of scatter matrices.
</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>Examples</h3>

<pre><code class='language-R'># example requires the packages ICS and ICSNP
library(ICSNP)
X &lt;- cbind(rexp(1000), rt(1000,6), runif(1000)) 

my.tM1 &lt;- function(X,df=1) tM(X,)$V
my.tM2 &lt;- function(X,df=2) tM(X,)$V

multscatter(c("cov","cov4","HP1.shape","my.tM1", "my.tM2"), X)
multscatter(c("cov","cov4","HP1.shape","my.tM1", "my.tM2"), X, toshape=FALSE)
</code></pre>

<hr>
<h2 id='NSS.JD'>
NSS.JD Method for Nonstationary Blind Source Separation
</h2><span id='topic+NSS.JD'></span><span id='topic+NSS.JD.default'></span><span id='topic+NSS.JD.ts'></span>

<h3>Description</h3>

<p>The NSS.JD method for nonstationary blind source separation. The method first whitens the complete data and then divides it into K time intervals.
Then <code><a href="#topic+frjd">frjd</a></code> is used to jointly diagonalize the covariance matrices computed for the individual time intervals to find the sources.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NSS.JD(X, ...)

## Default S3 method:
NSS.JD(X,  K=12, Tau=0, n.cuts=NULL, eps = 1e-06, maxiter = 100, ...)
## S3 method for class 'ts'
NSS.JD(X, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSS.JD_+3A_x">X</code></td>
<td>
<p>a numeric matrix or a multivariate time series object of class <code><a href="stats.html#topic+ts">ts</a></code>. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="NSS.JD_+3A_k">K</code></td>
<td>
<p>number of intervals to be used.</p>
</td></tr>
<tr><td><code id="NSS.JD_+3A_tau">Tau</code></td>
<td>
<p>By default 0 which means covariance are computed of each time interval, if Tau is an integer &gt; 0 then rather autocovariance matrices at lag Tau are used for the joint diagonaliation.</p>
</td></tr>
<tr><td><code id="NSS.JD_+3A_n.cuts">n.cuts</code></td>
<td>
<p>if NULL, then the time series is divided into K equally long intervals. To specify intervals n.cuts should be given in the form c(1,n.cut.1,...,n.cut.k, nrow(X)) to specify where to split the time series.</p>
</td></tr>
<tr><td><code id="NSS.JD_+3A_eps">eps</code></td>
<td>
<p>maximum number of iterations for <code><a href="#topic+frjd">frjd</a></code>.</p>
</td></tr>
<tr><td><code id="NSS.JD_+3A_maxiter">maxiter</code></td>
<td>
<p>convergence tolerance for <code><a href="#topic+frjd">frjd</a></code>.</p>
</td></tr>
<tr><td><code id="NSS.JD_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model assumes that the mean of the p-variate time series is constant but the variances change over time.
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the lag used for the autocovariance matrix.</p>
</td></tr>
<tr><td><code>n.cut</code></td>
<td>
<p>specifying the intervals where data is split</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>the number of intervals used</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>estimated sources as time series objected standardized to have mean 0 and that the variance of the sources are 1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Choi S. and Cichocki A. (2000), Blind separation of nonstationary sources in noisy mixtures, 
<em>Electronics Letters</em>, 36, 848&ndash;849.</cite>
</p>
<p><cite>Choi S. and Cichocki A. (2000), Blind separation of nonstationary and temporally correlated
sources from noisy mixtures, Proceedings of the 2000
<em>IEEE Signal Processing Society Workshop Neural Networks for Signal Processing X</em>, 1, 405&ndash;414.</cite>
</p>
<p><cite>Nordhausen K. (2014), On robustifying some second order blind source separation methods for nonstationary time series, 
<em>Statistical Papers</em>, 55, 141&ndash;156.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a>, <a href="#topic+NSS.SD">NSS.SD</a>, <a href="#topic+NSS.TD.JD">NSS.TD.JD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
s1 &lt;- rnorm(n)
s2 &lt;- 2*sin(pi/200*1:n)* rnorm(n)
s3 &lt;- c(rnorm(n/2), rnorm(100,0,2), rnorm(n/2-100,0,1.5))
S &lt;- cbind(s1,s2,s3)
plot.ts(S)
A&lt;-matrix(rnorm(9),3,3)
X&lt;- S%*%t(A)

NSS2 &lt;- NSS.JD(X)
NSS2
MD(coef(NSS2),A)
plot(NSS2)
cor(NSS2$S,S)

NSS2b &lt;- NSS.JD(X, Tau=1)
MD(coef(NSS2b),A)

NSS2c &lt;- NSS.JD(X, n.cuts=c(1,300,500,600,1000))
MD(coef(NSS2c),A)
</code></pre>

<hr>
<h2 id='NSS.SD'>
NSS.SD Method for Nonstationary Blind Source Separation
</h2><span id='topic+NSS.SD'></span><span id='topic+NSS.SD.default'></span><span id='topic+NSS.SD.ts'></span>

<h3>Description</h3>

<p>The NSS.SD method for nonstationary blind source separation. The function estimates
the unmixing matrix in a nonstationary source separation model by simultaneously diagonalizing
two covariance matrices computed for different time intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NSS.SD(X, ...)

## Default S3 method:
NSS.SD(X, n.cut=NULL, ...)
## S3 method for class 'ts'
NSS.SD(X, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSS.SD_+3A_x">X</code></td>
<td>
<p>a numeric matrix or a multivariate time series object of class <code><a href="stats.html#topic+ts">ts</a></code>. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="NSS.SD_+3A_n.cut">n.cut</code></td>
<td>
<p>either an integer between 1 and nrow(X) or an vector of length 3 of the form c(1,n.cut,nrow(X)) to specify where to split the time series. If NULL, then
c(1,floor(nrow(X)/2),nrow(X)) is used.</p>
</td></tr>
<tr><td><code id="NSS.SD_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model assumes that the mean of the p-variate time series is constant but the variances change over time.
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>EV</code></td>
<td>
<p>eigenvalues from the eigenvalue-eigenvector decomposition.</p>
</td></tr>
<tr><td><code>n.cut</code></td>
<td>
<p>specifying the intervals where data is split</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>estimated sources as time series objected standardized to have mean 0 and that the sources in the first interval are 1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Choi S. and Cichocki A. (2000), Blind separation of nonstationary sources in noisy mixtures, 
<em>Electronics Letters</em>, 36, 848&ndash;849.</cite>
</p>
<p><cite>Choi S. and Cichocki A. (2000), Blind separation of nonstationary and temporally correlated
sources from noisy mixtures, Proceedings of the 2000
<em>IEEE Signal Processing Society Workshop Neural Networks for Signal Processing X</em>, 1, 405&ndash;414.</cite>
</p>
<p><cite>Nordhausen K. (2014), On robustifying some second order blind source separation methods for nonstationary time series, 
<em>Statistical Papers</em>, 55, 141&ndash;156.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a>, <a href="#topic+NSS.JD">NSS.JD</a>, <a href="#topic+NSS.TD.JD">NSS.TD.JD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
s1 &lt;- rnorm(n)
s2 &lt;- 2*sin(pi/200*1:n)* rnorm(n)
s3 &lt;- c(rnorm(n/2), rnorm(100,0,2), rnorm(n/2-100,0,1.5))
S &lt;- cbind(s1,s2,s3)
plot.ts(S)
A&lt;-matrix(rnorm(9),3,3)
X&lt;- S%*%t(A)

NSS1 &lt;- NSS.SD(X)
NSS1
MD(coef(NSS1),A)
plot(NSS1)
cor(NSS1$S,S)

NSS1b &lt;- NSS.SD(X, n.cut=400)
MD(coef(NSS1b),A)

NSS1c &lt;- NSS.SD(X, n.cut=c(1,600,1000))
MD(coef(NSS1c),A)
</code></pre>

<hr>
<h2 id='NSS.TD.JD'>
NSS.TD.JD Method for Nonstationary Blind Source Separation
</h2><span id='topic+NSS.TD.JD'></span><span id='topic+NSS.TD.JD.default'></span><span id='topic+NSS.TD.JD.ts'></span>

<h3>Description</h3>

<p>The NSS.TD.JD method for nonstationary blind source separation. The method first whitens the complete data and then divides it into K time intervals.
It is then assumed that within each interval the time series is approximately second order stationary and within each interval L autocovariance are computed.
The underlying sources are then found by jointly diagonalizing the K*L autocovariance matrices using  <code><a href="#topic+frjd">frjd</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NSS.TD.JD(X, ...)

## Default S3 method:
NSS.TD.JD(X, K=12, Tau=0:11, n.cuts=NULL, eps = 1e-06, maxiter = 100, ...)
## S3 method for class 'ts'
NSS.TD.JD(X, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSS.TD.JD_+3A_x">X</code></td>
<td>
<p>a numeric matrix or a multivariate time series object of class <code><a href="stats.html#topic+ts">ts</a></code>. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="NSS.TD.JD_+3A_k">K</code></td>
<td>
<p>number of intervals to be used.</p>
</td></tr>
<tr><td><code id="NSS.TD.JD_+3A_tau">Tau</code></td>
<td>
<p>Lags for the autovariance matrices to be computed within each interval.</p>
</td></tr>
<tr><td><code id="NSS.TD.JD_+3A_n.cuts">n.cuts</code></td>
<td>
<p>if NULL, then the time series is divided into K equally long intervals. To specify intervals n.cuts should be given in the form c(1,n.cut.1,...,n.cut.k, nrow(X)) to specify where to split the time series.</p>
</td></tr>
<tr><td><code id="NSS.TD.JD_+3A_eps">eps</code></td>
<td>
<p>maximum number of iterations for <code><a href="#topic+frjd">frjd</a></code>.</p>
</td></tr>
<tr><td><code id="NSS.TD.JD_+3A_maxiter">maxiter</code></td>
<td>
<p>convergence tolerance for <code><a href="#topic+frjd">frjd</a></code>.</p>
</td></tr>
<tr><td><code id="NSS.TD.JD_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model assumes that the mean of the p-variate time series is constant but the variances change over time.
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the lags used for the autocovariance matrix used in each interval.</p>
</td></tr>
<tr><td><code>n.cut</code></td>
<td>
<p>specifying the intervals where data is split</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>the number of intervals used</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>estimated sources as time series objected standardized to have mean 0 and that the sources 1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Choi S. and Cichocki A. (2000), Blind separation of nonstationary sources in noisy mixtures, 
<em>Electronics Letters</em>, 36, 848&ndash;849.</cite>
</p>
<p><cite>Choi S. and Cichocki A. (2000), Blind separation of nonstationary and temporally correlated
sources from noisy mixtures, Proceedings of the 2000
<em>IEEE Signal Processing Society Workshop Neural Networks for Signal Processing X</em>, 1, 405&ndash;414.</cite>
</p>
<p><cite>Nordhausen K. (2014), On robustifying some second order blind source separation methods for nonstationary time series, 
<em>Statistical Papers</em>, 55, 141&ndash;156.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a>, <a href="#topic+NSS.JD">NSS.JD</a>, <a href="#topic+NSS.JD">NSS.JD</a>, <a href="#topic+SOBI">SOBI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
s1 &lt;- rnorm(n)
s2 &lt;- 2*sin(pi/200*1:n)* rnorm(n)
s3 &lt;- c(rnorm(n/2), rnorm(100,0,2), rnorm(n/2-100,0,1.5))
S &lt;- cbind(s1,s2,s3)
plot.ts(S)
A&lt;-matrix(rnorm(9),3,3)
X&lt;- S%*%t(A)

NSS3 &lt;- NSS.TD.JD(X)
NSS3
MD(coef(NSS3),A)
plot(NSS3)
cor(NSS3$S,S)

NSS3b &lt;- NSS.TD.JD(X, Tau=c(0,3,7,12), K=6)
MD(coef(NSS3b),A)

NSS3c &lt;- NSS.TD.JD(X, n.cuts=c(1,300,500,600,1000))
MD(coef(NSS3c),A)
</code></pre>

<hr>
<h2 id='plot.bss'>Plotting an Object of Class bss</h2><span id='topic+plot.bss'></span>

<h3>Description</h3>

<p>Plots the estimated sources resulting from an bss method. If the bss method is based on second order assumptions and returned the sources as a time series object it will plot the sources 
using <code>plot.ts</code>, otherwise it will plot a scatter plot matrix using <code>pairs</code> or <code>plot</code> if there are only two sources. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bss'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.bss_+3A_x">x</code></td>
<td>
<p>object of class bss.</p>
</td></tr>
<tr><td><code id="plot.bss_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+plot.ts">plot.ts</a></code>, <code><a href="graphics.html#topic+pairs">pairs</a></code>, <code><a href="base.html#topic+plot">plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A&lt;- matrix(rnorm(9),3,3)
s1 &lt;- arima.sim(list(ar=c(0.3,0.6)),1000)
s2 &lt;- arima.sim(list(ma=c(-0.3,0.3)),1000)
s3 &lt;- arima.sim(list(ar=c(-0.8,0.1)),1000)

S &lt;- cbind(s1,s2,s3)
X &lt;- S %*% t(A)

res1 &lt;- AMUSE(X)
plot(res1)
# not so useful:
plot(res1, plot.type = "single", col=1:3)

# not meaningful for this data
res2 &lt;- JADE(X)
plot(res2)
</code></pre>

<hr>
<h2 id='print.bss'>Printing an Object of Class bss</h2><span id='topic+print.bss'></span>

<h3>Description</h3>

<p>Prints an object of class bss. It prints all elements of the list of class bss except the component S
which is the source matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bss'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bss_+3A_x">x</code></td>
<td>
<p>object of class bss.</p>
</td></tr>
<tr><td><code id="print.bss_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>

<hr>
<h2 id='rjd'>Joint Diagonalization of Real Matrices  </h2><span id='topic+rjd'></span><span id='topic+frjd'></span><span id='topic+rjd.fortran'></span><span id='topic+frjd.int'></span>

<h3>Description</h3>

<p>This is an <span class="pkg">R</span> version of Cardoso's rjd matlab function for joint diagonalization of k real-valued square matrices. A version written in C is also available and preferrable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rjd(X, eps = 1e-06, maxiter = 100, na.action = na.fail)
frjd(X, weight = NULL, maxiter = 100, eps = 1e-06, na.action = na.fail)
frjd.int(X, maxiter = 100, eps = 1e-06)
rjd.fortran(X, weight = NULL, maxiter = 100, eps = 1e-06, na.action = na.fail)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rjd_+3A_x">X</code></td>
<td>
<p>A matrix of k stacked pxp matrices with dimension c(kp,p) or an array with dimension c(p,p,k). In case of <code>frjd_int</code> it has to be an array.</p>
</td></tr>
<tr><td><code id="rjd_+3A_weight">weight</code></td>
<td>
<p>A vector of length k to give weight to the different matrices, if NULL, all matrices have equal weight</p>
</td></tr>
<tr><td><code id="rjd_+3A_eps">eps</code></td>
<td>
<p> Convergence tolerance.</p>
</td></tr>
<tr><td><code id="rjd_+3A_maxiter">maxiter</code></td>
<td>
<p> Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="rjd_+3A_na.action">na.action</code></td>
<td>
<p>A function which indicates what should happen when the data
contain 'NA's.  Default is to fail.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Denote the square matrices as <code class="reqn">A_i</code>, <code class="reqn">i=1,\ldots,k</code>. The algorithm searches an orthogonal matrix <code class="reqn">V</code> so that <code class="reqn">D_i=V'A_iV</code> is diagonal for all <code class="reqn">i</code>. If the <code class="reqn">A_i</code> commute then there is an exact solution. Otherwise, the function will perform an approximate joint diagonalization by trying to make the <code class="reqn">D_i</code> as diagonal as possible.
</p>
<p>Cardoso points out that notion of approximate joint diagonalization
is ad hoc and very small values of <code>eps</code> make in that case not much sense since the diagonality 
criterion is ad hoc itself.
</p>
<p><code>rjd</code>, <code>frjd</code> and <code>rjd.fortran</code> terminate with an error in case maxiter is reach without convergence whereas <code>frjd_int</code> returns the current state at when <code>maxiter</code> is reached and does not warn about convergence problems.
</p>


<h3>Value</h3>

<p>A list with the components
</p>
<table>
<tr><td><code>V</code></td>
<td>
<p>An orthogonal matrix.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>A stacked matrix with the diagonal matrices or an array with the diagonal matrices. The form of the output
depends on the form of the input.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The <code>frjd</code> function returns also the number of iterations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jean-Francois Cardoso. Ported to <span class="pkg">R</span> by Klaus Nordhausen. C code by Jari Miettinen</p>


<h3>References</h3>

<p><cite>Cardoso, J.-F. and Souloumiac, A., (1996), Jacobi angles for simultaneous diagonalization, <em>SIAM J. Mat. Anal. Appl.</em>, <b>17</b>,  161&ndash;164.</cite>  
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Z &lt;- matrix(runif(9), ncol = 3)
U &lt;- eigen(Z %*% t(Z))$vectors
D1 &lt;- diag(runif(3))
D2 &lt;- diag(runif(3))
D3 &lt;- diag(runif(3))
D4 &lt;- diag(runif(3))

X.matrix &lt;- rbind(t(U) %*% D1 %*% U, t(U) %*% D2 %*% U,
                  t(U) %*% D3 %*% U, t(U) %*% D4 %*% U)
res.matrix &lt;- rjd(X.matrix)
res.matrix$V
round(U %*% res.matrix$V, 4) # should be a signed permutation 
                             # matrix if V is correct.

round(res.matrix$D, 4)

# compare to C version

#res.matrix.C &lt;- frjd(X.matrix)
#res.matrix.C$V
#round(U %*% res.matrix.C$V, 4)
#round(res.matrix.C$D, 4)

X.array &lt;- aperm(array(t(X.matrix), dim = c(3,3,4)), c(2,1,3))

res.array &lt;- rjd(X.array)
round(res.array$D, 4)

res.array.C &lt;- frjd(X.array)
round(res.array.C$D, 4)

res.array.C2 &lt;- frjd.int(X.array)
round(res.array.C2$D, 4)
</code></pre>

<hr>
<h2 id='SIR'> Signal to Interference Ratio </h2><span id='topic+SIR'></span>

<h3>Description</h3>

<p>Computes the signal to interference ratio between true and estimated signals 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIR(S, S.hat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SIR_+3A_s">S</code></td>
<td>
<p>Matrix or dataframe with the true numeric signals.</p>
</td></tr>
<tr><td><code id="SIR_+3A_s.hat">S.hat</code></td>
<td>
<p>Matrix or dataframe with the estimated numeric signals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The signal to interference ratio is measured in dB and values over 20 are thought to be good.
It is scale and permutation invariant and can be seen as measuring the correlation between the matched true and estimated signals. 
</p>


<h3>Value</h3>

<p>The value of the signal to interference ratio.
</p>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Eriksson, J., Karvanen, J. and Koivunen, V. (2000), Source distribution adaptive maximum likelihood estimation in ICA model, <em>Proceedings of
the second international workshop on independent component analysis and blind source separation (ICA 2000)</em>,  227&ndash;232. </cite>  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amari.error">amari.error</a></code>, <code><a href="#topic+ComonGAP">ComonGAP</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>S &lt;- cbind(rt(1000, 4), rnorm(1000), runif(1000))
A &lt;- matrix(rnorm(9), ncol = 3)
X &lt;- S %*% t(A)

S.hat &lt;- JADE(X, 3)$S
SIR(S, S.hat)
</code></pre>

<hr>
<h2 id='SOBI'>
SOBI Method for Blind Source Separation
</h2><span id='topic+SOBI'></span><span id='topic+SOBI.default'></span><span id='topic+SOBI.ts'></span>

<h3>Description</h3>

<p>The SOBI method for the second order blind source separation problem. The function estimates
the unmixing matrix in a second order stationary source separation model by jointly diagonalizing
the covariance matrix and several autocovariance matrices at different lags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SOBI(X, ...)

## Default S3 method:
SOBI(X, k=12, method="frjd", eps = 1e-06, maxiter = 100, ...)
## S3 method for class 'ts'
SOBI(X, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SOBI_+3A_x">X</code></td>
<td>
<p>a numeric matrix or a multivariate time series object of class <code><a href="stats.html#topic+ts">ts</a></code>. Missing values are not allowed.</p>
</td></tr>
<tr><td><code id="SOBI_+3A_k">k</code></td>
<td>
<p>if a single integer, then the lags 1:k are used, if an integer vector, then these are used as the lags.</p>
</td></tr>
<tr><td><code id="SOBI_+3A_method">method</code></td>
<td>
<p>method to use for the joint diagonalization, options are <code><a href="#topic+djd">djd</a></code>, <code><a href="#topic+rjd">rjd</a></code> and <code><a href="#topic+frjd">frjd</a></code></p>
</td></tr></table>
<p>. 
</p>
<table>
<tr><td><code id="SOBI_+3A_eps">eps</code></td>
<td>
<p>convergence tolerance.</p>
</td></tr>
<tr><td><code id="SOBI_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id="SOBI_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The order of the estimated components is fixed so that the sums of squared autocovariances are in the decreasing order.
</p>


<h3>Value</h3>

<p>A list with class 'bss' containing the following components:
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>estimated unmixing matrix.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>lags used.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>method used for the joint diagonalization.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>estimated sources as time series objected standardized to have mean 0 and unit variances.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen</p>


<h3>References</h3>

<p><cite>Belouchrani, A., Abed-Meriam, K., Cardoso, J.F. and Moulines, R. (1997), A blind source separation technique using second-order statistics, 
<em>IEEE Transactions on Signal Processing</em>, 434&ndash;444.</cite>
</p>
<p><cite>Miettinen, J., Nordhausen, K., Oja, H. and Taskinen, S. (2014),  Deflation-based Separation of Uncorrelated Stationary Time Series, 
<em>Journal of Multivariate Analysis</em>, 123, 214&ndash;227.</cite> 
</p>
<p><cite>Miettinen, J., Illner, K., Nordhausen, K., Oja, H., Taskinen, S. and Theis, F.J. (2016),  Separation of Uncorrelated Stationary Time Series Using Autocovariance Matrices, 
<em>Journal of Time Series Analysis</em>, 37, 337&ndash;354.</cite> 
</p>
<p><cite>Miettinen, J., Nordhausen, K. and Taskinen, S. (2017), Blind Source Separation Based on Joint Diagonalization in R: The Packages JADE and BSSasymp, <em>Journal of Statistical Software</em>, <b>76</b>, 1&ndash;31, &lt;doi:10.18637/jss.v076.i02&gt;.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># creating some toy data
A&lt;- matrix(rnorm(9),3,3)
s1 &lt;- arima.sim(list(ar=c(0.3,0.6)),1000)
s2 &lt;- arima.sim(list(ma=c(-0.3,0.3)),1000)
s3 &lt;- arima.sim(list(ar=c(-0.8,0.1)),1000)

S &lt;- cbind(s1,s2,s3)
X &lt;- S %*% t(A)

res1&lt;-SOBI(X)
res1
coef(res1)
plot(res1) # compare to plot.ts(S)
MD(coef(res1),A)

# input of a time series
X2&lt;- ts(X, start=c(1961, 1), frequency=12)
plot(X2)
res2&lt;-SOBI(X2, k=c(5,10,1,4,2,9,10))
plot(res2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
