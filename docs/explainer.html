<!DOCTYPE html><html><head><title>Help for package explainer</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {explainer}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#explainer-package'><p>explainer: Machine Learning Model Explainer</p></a></li>
<li><a href='#eCM_plot'><p>Enhanced Confusion Matrix Plot</p></a></li>
<li><a href='#eDecisionCurve'><p>Decision Curve Plot</p></a></li>
<li><a href='#eFairness'><p>Enhanced Fairness Analysis</p></a></li>
<li><a href='#ePerformance'><p>Enhanced Performance Evaluation</p></a></li>
<li><a href='#eROC_plot'><p>Enhanced ROC and Precision-Recall Plots</p></a></li>
<li><a href='#eSHAP_plot'><p>Enhanced SHAP Analysis for Binary Classification Models</p></a></li>
<li><a href='#eSHAP_plot_reg'><p>Enhanced SHAP Analysis for Regression Models</p></a></li>
<li><a href='#range01'><p>Data Scale to 0 and 1</p></a></li>
<li><a href='#regressmdl_eval'><p>Regression Model Evaluation</p></a></li>
<li><a href='#SHAPclust'><p>Clustered SHAP Summary Plot</p></a></li>
<li><a href='#ShapFeaturePlot'><p>SHAP Values versus Feature Values</p></a></li>
<li><a href='#ShapPartialPlot'><p>SHAP Partial Plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Machine Learning Model Explainer</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>It enables detailed interpretation of complex classification and regression models through Shapley analysis including data-driven characterization of subgroups of individuals. Furthermore, it facilitates multi-measure model evaluation, model fairness, and decision curve analysis. Additionally, it offers enhanced visualizations with interactive elements.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://persimune.github.io/explainer/">https://persimune.github.io/explainer/</a>,
<a href="https://github.com/PERSIMUNE/explainer">https://github.com/PERSIMUNE/explainer</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/PERSIMUNE/explainer/issues">https://github.com/PERSIMUNE/explainer/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>cvms, data.table, dplyr, egg, ggplot2, ggpmisc, ggpubr,
magrittr, plotly, tibble, tidyr, writexl</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cowplot, mlr3, mlr3learners, knitr, broom, iml, forcats,
mlr3viz, plotROC, psych, reshape2, remotes, mlbench, ranger,
precrec</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-15 09:53:49 UTC; rzar0002</td>
</tr>
<tr>
<td>Author:</td>
<td>Ramtin Zargari Marandi
    <a href="https://orcid.org/0000-0001-9233-1656"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ramtin Zargari Marandi &lt;ramtin.zargari.marandi@regionh.dk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-15 12:40:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='explainer-package'>explainer: Machine Learning Model Explainer</h2><span id='topic+explainer'></span><span id='topic+explainer-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>It enables detailed interpretation of complex classification and regression models through Shapley analysis including data-driven characterization of subgroups of individuals. Furthermore, it facilitates multi-measure model evaluation, model fairness, and decision curve analysis. Additionally, it offers enhanced visualizations with interactive elements.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Ramtin Zargari Marandi <a href="mailto:ramtin.zargari.marandi@regionh.dk">ramtin.zargari.marandi@regionh.dk</a> (<a href="https://orcid.org/0000-0001-9233-1656">ORCID</a>)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://persimune.github.io/explainer/">https://persimune.github.io/explainer/</a>
</p>
</li>
<li> <p><a href="https://github.com/PERSIMUNE/explainer">https://github.com/PERSIMUNE/explainer</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/PERSIMUNE/explainer/issues">https://github.com/PERSIMUNE/explainer/issues</a>
</p>
</li></ul>


<hr>
<h2 id='eCM_plot'>Enhanced Confusion Matrix Plot</h2><span id='topic+eCM_plot'></span>

<h3>Description</h3>

<p>This function generates an enhanced confusion matrix plot using the CVMS package. The plot includes visualizations of sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eCM_plot(task, trained_model, splits, add_sums = TRUE, palette = "Green")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eCM_plot_+3A_task">task</code></td>
<td>
<p>mlr3 task object specifying the task details</p>
</td></tr>
<tr><td><code id="eCM_plot_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object obtained after training</p>
</td></tr>
<tr><td><code id="eCM_plot_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
<tr><td><code id="eCM_plot_+3A_add_sums">add_sums</code></td>
<td>
<p>logical, indicating whether total numbers should be displayed in the plot (default: TRUE)</p>
</td></tr>
<tr><td><code id="eCM_plot_+3A_palette">palette</code></td>
<td>
<p>character, the color palette for the confusion matrix (default: &quot;Green&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A confusion matrix plot visualizing sensitivity, specificity, PPV, and NPV
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("explainer")
seed &lt;- 246
set.seed(seed)

# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
myplot &lt;- eCM_plot(
  task = maintask,
  trained_model = mylrn,
  splits = splits
)
</code></pre>

<hr>
<h2 id='eDecisionCurve'>Decision Curve Plot</h2><span id='topic+eDecisionCurve'></span>

<h3>Description</h3>

<p>Decision curve analysis is a statistical method used in medical research to evaluate and compare the clinical utility of different diagnostic or predictive models. It assesses the net benefit of a model across a range of decision thresholds, aiding in the selection of the most informative and practical approach for guiding clinical decisions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eDecisionCurve(task, trained_model, splits, seed = 246)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eDecisionCurve_+3A_task">task</code></td>
<td>
<p>mlr3 task object specifying the task details</p>
</td></tr>
<tr><td><code id="eDecisionCurve_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object obtained after training</p>
</td></tr>
<tr><td><code id="eDecisionCurve_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
<tr><td><code id="eDecisionCurve_+3A_seed">seed</code></td>
<td>
<p>numeric, seed for reproducibility (default: 246)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An interactive decision curve plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
myplot &lt;- eDecisionCurve(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  seed = seed
)
</code></pre>

<hr>
<h2 id='eFairness'>Enhanced Fairness Analysis</h2><span id='topic+eFairness'></span>

<h3>Description</h3>

<p>This function generates Precision-Recall and ROC curves for sample subgroups, facilitating fairness analysis of a binary classification model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eFairness(task, trained_model, splits, target_variable, var_levels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eFairness_+3A_task">task</code></td>
<td>
<p>mlr3 binary classification task object specifying the task details</p>
</td></tr>
<tr><td><code id="eFairness_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object obtained after training</p>
</td></tr>
<tr><td><code id="eFairness_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
<tr><td><code id="eFairness_+3A_target_variable">target_variable</code></td>
<td>
<p>character, the variable from the dataset used to test the model's performance against</p>
</td></tr>
<tr><td><code id="eFairness_+3A_var_levels">var_levels</code></td>
<td>
<p>list, defining the levels for the specified variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model performance metrics for user-specified subgroups using Precision-Recall and ROC curves
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
# sex is chosen for fairness analysis
Fairness_results &lt;- eFairness(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  target_variable = "sex",
  var_levels = c("Male", "Female")
)
</code></pre>

<hr>
<h2 id='ePerformance'>Enhanced Performance Evaluation</h2><span id='topic+ePerformance'></span>

<h3>Description</h3>

<p>This function generates Precision-Recall and ROC curves, including threshold information for binary classification models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ePerformance(task, trained_model, splits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ePerformance_+3A_task">task</code></td>
<td>
<p>mlr3 binary classification task object specifying the task details</p>
</td></tr>
<tr><td><code id="ePerformance_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object obtained after training</p>
</td></tr>
<tr><td><code id="ePerformance_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ROC and Precision-Recall curves with threshold information
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Set environment variables for reproducibility
Sys.setenv(LANG = "en") # Change R language to English!
RNGkind("L'Ecuyer-CMRG") # Change to L'Ecuyer-CMRG instead of the default "Mersenne-Twister"

# Load required libraries
library("explainer")

# Set seed for reproducibility
seed &lt;- 246
set.seed(seed)

# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")

# Keep the target column as "Class"
target_col &lt;- "Class"

# Change the positive class to "malignant"
positive_class &lt;- "malignant"

# Keep only the predictor variables and outcome
mydata &lt;- BreastCancer[, -1] # 1 is ID

# Remove rows with missing values
mydata &lt;- na.omit(mydata)

# Create a vector of sex categories
sex &lt;- sample(c("Male", "Female"), size = nrow(mydata), replace = TRUE)

# Create a vector of age categories
mydata$age &lt;- as.numeric(sample(seq(18, 60), size = nrow(mydata), replace = TRUE))

# Add a sex column to the mydata data frame (for fairness analysis)
mydata$sex &lt;- factor(sex, levels = c("Male", "Female"), labels = c(1, 0))

# Create a classification task
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)

# Create a train-test split
set.seed(seed)
splits &lt;- mlr3::partition(maintask)

# Add a learner (machine learning model base)
# Here we use random forest for example (you can use any other available model)
mylrn &lt;- mlr3::lrn("classif.ranger", predict_type = "prob")

# Train the model
mylrn$train(maintask, splits$train)

# Make predictions on new data
mylrn$predict(maintask, splits$test)
ePerformance(task = maintask, trained_model = mylrn, splits = splits)
</code></pre>

<hr>
<h2 id='eROC_plot'>Enhanced ROC and Precision-Recall Plots</h2><span id='topic+eROC_plot'></span>

<h3>Description</h3>

<p>This function generates Precision-Recall and ROC curves for binary classification models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eROC_plot(task, trained_model, splits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eROC_plot_+3A_task">task</code></td>
<td>
<p>mlr3 binary classification task object specifying the task details</p>
</td></tr>
<tr><td><code id="eROC_plot_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object obtained after training</p>
</td></tr>
<tr><td><code id="eROC_plot_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ROC and Precision-Recall curves
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
myplot &lt;- eROC_plot(
  task = maintask,
  trained_model = mylrn,
  splits = splits
)
</code></pre>

<hr>
<h2 id='eSHAP_plot'>Enhanced SHAP Analysis for Binary Classification Models</h2><span id='topic+eSHAP_plot'></span>

<h3>Description</h3>

<p>The SHAP plot for classification models is a visualization tool that uses the Shapley value, an approach from cooperative game theory, to compute feature contributions for single predictions. The Shapley value fairly distributes the difference of the instance’s prediction and the datasets average prediction among the features. This method is available from the iml package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eSHAP_plot(
  task,
  trained_model,
  splits,
  sample.size = 30,
  seed = 246,
  subset = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eSHAP_plot_+3A_task">task</code></td>
<td>
<p>mlr3 task object for binary classification</p>
</td></tr>
<tr><td><code id="eSHAP_plot_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner object</p>
</td></tr>
<tr><td><code id="eSHAP_plot_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
<tr><td><code id="eSHAP_plot_+3A_sample.size">sample.size</code></td>
<td>
<p>numeric, default to 30. The larger the value, the slower but more accurate the estimate of SHAP values</p>
</td></tr>
<tr><td><code id="eSHAP_plot_+3A_seed">seed</code></td>
<td>
<p>numeric, an integer for reproducibility. Default to 246</p>
</td></tr>
<tr><td><code id="eSHAP_plot_+3A_subset">subset</code></td>
<td>
<p>numeric, what percentage of the instances to use from 0 to 1 where 1 means all</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr><td><code>shap_plot</code></td>
<td>
<p>An enhanced SHAP plot with user interactive elements.</p>
</td></tr>
<tr><td><code>shap_Mean_wide</code></td>
<td>
<p>A matrix of SHAP values.</p>
</td></tr>
<tr><td><code>shap_Mean</code></td>
<td>
<p>A data.table with aggregated SHAP values.</p>
</td></tr>
<tr><td><code>shap</code></td>
<td>
<p>Raw SHAP values.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Molnar C, Casalicchio G, Bischl B. iml: An R package for interpretable machine learning. Journal of Open Source Software. 2018 Jun 27;3(26):786.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+eSHAP_plot_reg">eSHAP_plot_reg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(c("Male", "Female"), size = nrow(mydata), replace = TRUE)
mydata$age &lt;- as.numeric(sample(seq(18,60), size = nrow(mydata), replace = TRUE))
mydata$sex &lt;- factor(sex, levels = c("Male", "Female"), labels = c(1, 0))
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn("classif.ranger", predict_type = "prob")
mylrn$train(maintask, splits$train)
SHAP_output &lt;- eSHAP_plot(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  sample.size = 2, # also 30 or more
  seed = seed,
  subset = 0.02 # up to 1
)


</code></pre>

<hr>
<h2 id='eSHAP_plot_reg'>Enhanced SHAP Analysis for Regression Models</h2><span id='topic+eSHAP_plot_reg'></span>

<h3>Description</h3>

<p>The SHAP plot for regression models is a visualization tool that uses the Shapley value, an approach from cooperative game theory, to compute feature contributions for single predictions. The Shapley value fairly distributes the difference of the instance’s prediction and the datasets average prediction among the features. This method is available from the iml package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eSHAP_plot_reg(
  task,
  trained_model,
  splits,
  sample.size = 30,
  seed = 246,
  subset = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eSHAP_plot_reg_+3A_task">task</code></td>
<td>
<p>mlr3 regression task object specifying the task details</p>
</td></tr>
<tr><td><code id="eSHAP_plot_reg_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object obtained after training</p>
</td></tr>
<tr><td><code id="eSHAP_plot_reg_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
<tr><td><code id="eSHAP_plot_reg_+3A_sample.size">sample.size</code></td>
<td>
<p>numeric, number of samples to calculate SHAP values (default: 30)</p>
</td></tr>
<tr><td><code id="eSHAP_plot_reg_+3A_seed">seed</code></td>
<td>
<p>numeric, seed for reproducibility (default: 246)</p>
</td></tr>
<tr><td><code id="eSHAP_plot_reg_+3A_subset">subset</code></td>
<td>
<p>numeric, proportion of the test set to use for visualization (default: 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two objects:
</p>

<ol>
<li><p> An enhanced SHAP plot with user interactive elements,
</p>
</li>
<li><p> A matrix of SHAP values
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>
library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(c("Male", "Female"), size = nrow(mydata), replace = TRUE)
mydata$age &lt;- sample(seq(18, 60), size = nrow(mydata), replace = TRUE)
mydata$sex &lt;- factor(sex, levels = c("Male", "Female"), labels = c(1, 0))
mydata$Class &lt;- NULL
mydata$Cl.thickness &lt;- as.numeric(mydata$Cl.thickness)
target_col &lt;- "Cl.thickness"
maintask &lt;- mlr3::TaskRegr$new(
  id = "my_regression_task",
  backend = mydata,
  target = target_col
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn("regr.ranger", predict_type = "response")
mylrn$train(maintask, splits$train)
reg_model_outputs &lt;- mylrn$predict(maintask, splits$test)
SHAP_output &lt;- eSHAP_plot_reg(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  sample.size = 2, # also 30 or more
  seed = seed,
  subset = 0.02 # up to 1
)
myplot &lt;- SHAP_output[[1]]

</code></pre>

<hr>
<h2 id='range01'>Data Scale to 0 and 1</h2><span id='topic+range01'></span>

<h3>Description</h3>

<p>Scale the data to the range of 0 to 1. It uses the Hampel filter to adjust outliers, followed by min-max normalization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>range01(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="range01_+3A_x">x</code></td>
<td>
<p>Vector or array of numbers to be normalized</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Normalized vector
</p>


<h3>References</h3>

<p>Pearson, R. K. (1999). “Data cleaning for dynamic modeling and control”. European Control Conference, ETH Zurich, Switzerland.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+eSHAP_plot">eSHAP_plot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>normalized_vector &lt;- range01(seq(-10:1000))

</code></pre>

<hr>
<h2 id='regressmdl_eval'>Regression Model Evaluation</h2><span id='topic+regressmdl_eval'></span>

<h3>Description</h3>

<p>Provides calculations of measures to evaluate regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regressmdl_eval(task, trained_model, splits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regressmdl_eval_+3A_task">task</code></td>
<td>
<p>mlr3 regression task object</p>
</td></tr>
<tr><td><code id="regressmdl_eval_+3A_trained_model">trained_model</code></td>
<td>
<p>mlr3 trained learner (model) object</p>
</td></tr>
<tr><td><code id="regressmdl_eval_+3A_splits">splits</code></td>
<td>
<p>mlr3 object defining data splits for train and test sets</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing regression evaluation measures
</p>


<h3>References</h3>

<p>Lang M, Binder M, Richter J, Schratz P, Pfisterer F, Coors S, Au Q, Casalicchio G, Kotthoff L, Bischl B. mlr3: A modern object-oriented machine learning framework in R. Journal of Open Source Software. 2019 Dec 11;4(44):1903.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+eCM_plot">eCM_plot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- sample(
  seq(18, 60),
  size = nrow(mydata),
  replace = TRUE
)
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
mydata$Class &lt;- NULL
mydata$Cl.thickness &lt;- as.numeric(mydata$Cl.thickness)
target_col &lt;- "Cl.thickness"
maintask &lt;- mlr3::TaskRegr$new(
  id = "my_regression_task",
  backend = mydata,
  target = target_col
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "regr.ranger",
  predict_type = "response"
)
mylrn$train(maintask, splits$train)
regressmdl_eval_results &lt;- regressmdl_eval(
  task = maintask,
  trained_model = mylrn,
  splits = splits
)

</code></pre>

<hr>
<h2 id='SHAPclust'>Clustered SHAP Summary Plot</h2><span id='topic+SHAPclust'></span>

<h3>Description</h3>

<p>SHAP values are used to cluster data samples using the k-means method to identify subgroups of individuals with specific patterns of feature contributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SHAPclust(
  task,
  trained_model,
  splits,
  shap_Mean_wide,
  shap_Mean_long,
  num_of_clusters = 4,
  seed = 246,
  subset = 1,
  algorithm = "Hartigan-Wong",
  iter.max = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SHAPclust_+3A_task">task</code></td>
<td>
<p>an mlr3 task for binary classification</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_trained_model">trained_model</code></td>
<td>
<p>an mlr3 trained learner object</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_splits">splits</code></td>
<td>
<p>an mlr3 object defining data splits for train and test sets</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_shap_mean_wide">shap_Mean_wide</code></td>
<td>
<p>the data frame of SHAP values in wide format from eSHAP_plot.R</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_shap_mean_long">shap_Mean_long</code></td>
<td>
<p>the data frame of SHAP values in long format from eSHAP_plot.R</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_num_of_clusters">num_of_clusters</code></td>
<td>
<p>number of clusters to make based on SHAP values, default: 4</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_seed">seed</code></td>
<td>
<p>an integer for reproducibility, Default to 246</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_subset">subset</code></td>
<td>
<p>what percentage of the instances to use from 0 to 1 where 1 means all</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_algorithm">algorithm</code></td>
<td>
<p>k-means algorithm character: &quot;Hartigan-Wong&quot;, &quot;Lloyd&quot;, &quot;Forgy&quot;, &quot;MacQueen&quot;.</p>
</td></tr>
<tr><td><code id="SHAPclust_+3A_iter.max">iter.max</code></td>
<td>
<p>maximum number of iterations allowed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing four elements:
</p>
<table>
<tr><td><code>shap_plot_onerow</code></td>
<td>
<p>A plotly interactive plot displaying the SHAP values for each feature, clustered by the specified number of clusters. Each cluster is shown in a facet.</p>
</td></tr>
<tr><td><code>combined_plot</code></td>
<td>
<p>A ggplot2 figure combining confusion matrices for each cluster, providing insights into the model's performance within each identified subgroup.</p>
</td></tr>
<tr><td><code>kmeans_fvals_desc</code></td>
<td>
<p>A summary table containing statistical descriptions of the clusters based on feature values.</p>
</td></tr>
<tr><td><code>shap_Mean_wide_kmeans</code></td>
<td>
<p>A data frame containing clustered SHAP values along with predictions and ground truth information.</p>
</td></tr>
<tr><td><code>kmeans_info</code></td>
<td>
<p>Information about the k-means clustering process, including cluster centers and assignment details.</p>
</td></tr>
</table>


<h3>References</h3>

<p>For more details on SHAP analysis, refer to Lundberg, S. M., &amp; Lee, S. I. (2017). A Unified Approach to Interpreting Model Predictions. In Advances in Neural Information Processing Systems (NIPS) (pp. 4765-4774).
</p>


<h3>See Also</h3>

<p>Other functions to visualize and interpret machine learning models: <code><a href="#topic+eSHAP_plot">eSHAP_plot</a></code>, <code><a href="cvms.html#topic+plot_confusion_matrix">plot_confusion_matrix</a></code>, <code><a href="cvms.html#topic+confusion_matrix">confusion_matrix</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
SHAP_output &lt;- eSHAP_plot(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  sample.size = 2, # also 30 or more
  seed = seed,
  subset = 0.02 # up to 1
)
shap_Mean_wide &lt;- SHAP_output[[2]]
shap_Mean_long &lt;- SHAP_output[[3]]
SHAP_plot_clusters &lt;- SHAPclust(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  shap_Mean_wide = shap_Mean_wide,
  shap_Mean_long = shap_Mean_long,
  num_of_clusters = 3, # your choice
  seed = seed,
  subset = 0.02, # match with eSHAP_plot
  algorithm="Hartigan-Wong",
  iter.max = 10
)


</code></pre>

<hr>
<h2 id='ShapFeaturePlot'>SHAP Values versus Feature Values</h2><span id='topic+ShapFeaturePlot'></span>

<h3>Description</h3>

<p>SHAP values in association with feature values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShapFeaturePlot(shap_Mean_long)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShapFeaturePlot_+3A_shap_mean_long">shap_Mean_long</code></td>
<td>
<p>the data frame containing SHAP values in long format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an interactive plot of SHAP values in association with feature values
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
SHAP_output &lt;- eSHAP_plot(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  sample.size = 2, # also 30 or more
  seed = seed,
  subset = 0.02 # up to 1
)
shap_Mean_long &lt;- SHAP_output[[3]]
myplot &lt;- ShapFeaturePlot(shap_Mean_long)

</code></pre>

<hr>
<h2 id='ShapPartialPlot'>SHAP Partial Plot</h2><span id='topic+ShapPartialPlot'></span>

<h3>Description</h3>

<p>Generates an interactive partial dependence plot based on SHAP values, visualizing the marginal effect of one or two features on the predicted outcome of a machine learning model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShapPartialPlot(shap_Mean_long)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShapPartialPlot_+3A_shap_mean_long">shap_Mean_long</code></td>
<td>
<p>data frame containing SHAP values in long format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an interactive partial dependence plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("explainer")
seed &lt;- 246
set.seed(seed)
# Load necessary packages
if (!requireNamespace("mlbench", quietly = TRUE)) stop("mlbench not installed.")
if (!requireNamespace("mlr3learners", quietly = TRUE)) stop("mlr3learners not installed.")
if (!requireNamespace("ranger", quietly = TRUE)) stop("ranger not installed.")
# Load BreastCancer dataset
utils::data("BreastCancer", package = "mlbench")
target_col &lt;- "Class"
positive_class &lt;- "malignant"
mydata &lt;- BreastCancer[, -1]
mydata &lt;- na.omit(mydata)
sex &lt;- sample(
  c("Male", "Female"),
  size = nrow(mydata),
  replace = TRUE
)
mydata$age &lt;- as.numeric(sample(
  seq(18,60),
  size = nrow(mydata),
  replace = TRUE
))
mydata$sex &lt;- factor(
  sex,
  levels = c("Male", "Female"),
  labels = c(1, 0)
)
maintask &lt;- mlr3::TaskClassif$new(
  id = "my_classification_task",
  backend = mydata,
  target = target_col,
  positive = positive_class
)
splits &lt;- mlr3::partition(maintask)
mylrn &lt;- mlr3::lrn(
  "classif.ranger",
  predict_type = "prob"
)
mylrn$train(maintask, splits$train)
SHAP_output &lt;- eSHAP_plot(
  task = maintask,
  trained_model = mylrn,
  splits = splits,
  sample.size = 2, # also 30 or more
  seed = seed,
  subset = 0.02 # up to 1
)
shap_Mean_long &lt;- SHAP_output[[3]]
myplot &lt;- ShapPartialPlot(shap_Mean_long)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
