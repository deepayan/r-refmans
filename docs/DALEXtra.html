<!DOCTYPE html><html lang="en"><head><title>Help for package DALEXtra</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DALEXtra}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#champion_challenger'><p>Compare machine learning models</p></a></li>
<li><a href='#create_env'><p>Create your conda virtual env with DALEX</p></a></li>
<li><a href='#dalex_load_explainer'><p>DALEX load explainer</p></a></li>
<li><a href='#explain_h2o'><p>Create explainer from your h2o model</p></a></li>
<li><a href='#explain_keras'><p>Wrapper for Python Keras Models</p></a></li>
<li><a href='#explain_mlr'><p>Create explainer from your mlr model</p></a></li>
<li><a href='#explain_mlr3'><p>Create explainer from your mlr model</p></a></li>
<li><a href='#explain_scikitlearn'><p>Wrapper for Python Scikit-Learn Models</p></a></li>
<li><a href='#explain_tidymodels'><p>Create explainer from your tidymodels workflow.</p></a></li>
<li><a href='#explain_xgboost'><p>Create explainer from your xgboost model</p></a></li>
<li><a href='#funnel_measure'><p>Caluculate difference in performance in models across different categories</p></a></li>
<li><a href='#model_info.WrappedModel'><p>Exract info from model</p></a></li>
<li><a href='#overall_comparison'><p>Compare champion with challengers globally</p></a></li>
<li><a href='#plot.funnel_measure'><p>Funnel plot for difference in measures</p></a></li>
<li><a href='#plot.overall_comparison'><p>Plot function for overall_comparison</p></a></li>
<li><a href='#plot.training_test_comparison'><p>Plot and compare performance of model between training and test set</p></a></li>
<li><a href='#predict_surrogate'><p>Instance Level Surrogate Models</p></a></li>
<li><a href='#print.funnel_measure'><p>Print funnel_measure object</p></a></li>
<li><a href='#print.overall_comparison'><p>Print overall_comparison object</p></a></li>
<li><a href='#print.scikitlearn_set'><p>Prints scikitlearn_set class</p></a></li>
<li><a href='#print.training_test_comparison'><p>Print funnel_measure object</p></a></li>
<li><a href='#training_test_comparison'><p>Compare performance of model between training and test set</p></a></li>
<li><a href='#yhat.WrappedModel'><p>Wrapper over the predict function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Extension for 'DALEX' Package</td>
</tr>
<tr>
<td>Version:</td>
<td>2.3.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides wrapper of various machine learning models. 
  In applied machine learning, there 
  is a strong belief that we need to strike a balance 
  between interpretability and accuracy. 
  However, in field of the interpretable machine learning, 
  there are more and more new ideas for explaining black-box models, 
  that are implemented in 'R'. 
  'DALEXtra' creates 'DALEX' Biecek (2018) &lt;<a href="https://doi.org/10.48550/arXiv.1806.08915">doi:10.48550/arXiv.1806.08915</a>&gt; explainer for many type of models
  including those created using 'python' 'scikit-learn' and 'keras' libraries, and 'java' 'h2o' library. 
  Important part of the package is Champion-Challenger analysis and innovative approach
  to model performance across subsets of test data presented in Funnel Plot. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), DALEX (&ge; 2.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>auditor, gbm, ggrepel, h2o, iml, ingredients, lime,
localModel, mlr, mlr3, ranger, recipes, reticulate, rmarkdown,
rpart, stacks, xgboost, testthat, tidymodels</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ModelOriented.github.io/DALEXtra/">https://ModelOriented.github.io/DALEXtra/</a>,
<a href="https://github.com/ModelOriented/DALEXtra">https://github.com/ModelOriented/DALEXtra</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ModelOriented/DALEXtra/issues">https://github.com/ModelOriented/DALEXtra/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-25 23:48:32 UTC; 01131304</td>
</tr>
<tr>
<td>Author:</td>
<td>Szymon Maksymiuk <a href="https://orcid.org/0000-0002-3120-1601"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Przemyslaw Biecek <a href="https://orcid.org/0000-0001-8423-1823"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Hubert Baniecki [aut],
  Anna Kozak [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Szymon Maksymiuk &lt;sz.maksymiuk@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-26 00:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='champion_challenger'>Compare machine learning models</h2><span id='topic+champion_challenger'></span>

<h3>Description</h3>

<p>Determining if one model is better than the other one is a difficult task. Mostly because there is a lot of fields that have to be
covered to make such a judgement. Overall performance, performance on the crucial subset, distribution of residuals, those are only
few among many ideas related to that issue. Following function allow user to create a report based on various sections. Each says something different
about relation between champion and challengers. <code>DALEXtra</code> package share 3 base sections which are <code><a href="#topic+funnel_measure">funnel_measure</a></code>
<code><a href="#topic+overall_comparison">overall_comparison</a></code> and <code><a href="#topic+training_test_comparison">training_test_comparison</a></code> but any object that has generic <code>plot</code> function can
be included at report.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>champion_challenger(
  sections,
  dot_size = 4,
  output_dir_path = getwd(),
  output_name = "Report",
  model_performance_table = FALSE,
  title = "ChampionChallenger",
  author = Sys.info()[["user"]],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="champion_challenger_+3A_sections">sections</code></td>
<td>
<p>- list of sections to be attached to report. Could be sections available with DALEXtra which are <code><a href="#topic+funnel_measure">funnel_measure</a></code>
<code><a href="#topic+training_test_comparison">training_test_comparison</a></code>, <code><a href="#topic+overall_comparison">overall_comparison</a></code> or any other explanation that can work with <code>plot</code> function. Please
provide name for not standard sections, that will be presented as section titles. Otherwise class of the object will be used.</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_dot_size">dot_size</code></td>
<td>
<p>- dot_size argument passed to <code><a href="#topic+plot.funnel_measure">plot.funnel_measure</a></code> if <code><a href="#topic+funnel_measure">funnel_measure</a></code> section present</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_output_dir_path">output_dir_path</code></td>
<td>
<p>- path to directory where Report should be created. By default it is current working directory.</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_output_name">output_name</code></td>
<td>
<p>- name of the Report. By default it is &quot;Report&quot;</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_model_performance_table">model_performance_table</code></td>
<td>
<p>- If TRUE and <code><a href="#topic+overall_comparison">overall_comparison</a></code> section present, table of scores will be displayed.</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_title">title</code></td>
<td>
<p>- Title for report, by default it is &quot;ChampionChallenger&quot;.</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_author">author</code></td>
<td>
<p>- Author of , report. By default it is current user name.</p>
</td></tr>
<tr><td><code id="champion_challenger_+3A_...">...</code></td>
<td>
<p>- other parameters passed to rmarkdown::render.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>rmarkdown report
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("mlr")
library("DALEXtra")
task &lt;- mlr::makeRegrTask(
 id = "R",
  data = apartments,
   target = "m2.price"
 )
 learner_lm &lt;- mlr::makeLearner(
   "regr.lm"
 )
 model_lm &lt;- mlr::train(learner_lm, task)
 explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

 learner_rf &lt;- mlr::makeLearner(
 "regr.ranger"
 )
 model_rf &lt;- mlr::train(learner_rf, task)
 explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

 learner_gbm &lt;- mlr::makeLearner(
 "regr.gbm"
 )
 model_gbm &lt;- mlr::train(learner_gbm, task)
 explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")


 plot_data &lt;- funnel_measure(explainer_lm, list(explainer_rf, explainer_gbm),
                          nbins = 5, measure_function = DALEX::loss_root_mean_square)

champion_challenger(list(plot_data), dot_size = 3, output_dir_path = tempdir())


</code></pre>

<hr>
<h2 id='create_env'>Create your conda virtual env with DALEX</h2><span id='topic+create_env'></span>

<h3>Description</h3>

<p>Python objects may be loaded into R. However, it requires versions of the Python and libraries to match between both machines.
This functions allow user to create conda virtual environment based on provided .yml file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_env(yml, condaenv)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_env_+3A_yml">yml</code></td>
<td>
<p>a path to the .yml file. If OS is Windows conda has to be added to the PATH first</p>
</td></tr>
<tr><td><code id="create_env_+3A_condaenv">condaenv</code></td>
<td>
<p>path to main conda folder. If OS is Unix You may want to specify it. When passed with windows, param will be omitted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Name of created virtual env.
</p>


<h3>Author(s)</h3>

<p>Szymon Maksymiuk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  create_env(system.file("extdata", "testing_environment.yml", package = "DALEXtra"))

## End(Not run)
</code></pre>

<hr>
<h2 id='dalex_load_explainer'>DALEX load explainer</h2><span id='topic+dalex_load_explainer'></span>

<h3>Description</h3>

<p>Load DALEX explainer created with Python library into the R environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dalex_load_explainer(path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dalex_load_explainer_+3A_path">path</code></td>
<td>
<p>Path to the pickle file with explainer saved.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function uses the <code>reticulate</code> package to load Python object saved
in a pickle and make it accessible within R session. It also adds explainer
class to the object so it can be used with DALEX R functions.
</p>

<hr>
<h2 id='explain_h2o'>Create explainer from your h2o model</h2><span id='topic+explain_h2o'></span>

<h3>Description</h3>

<p>DALEX is designed to work with various black-box models like tree ensembles, linear models, neural networks etc.
Unfortunately R packages that create such models are very inconsistent. Different tools use different interfaces to train, validate and use models.
One of those tools, we would like to make more accessible is H2O.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_h2o(
  model,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_h2o_+3A_model">model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_h2o_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>explainer object (<code><a href="DALEX.html#topic+explain">explain</a></code>) ready to work with DALEX
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


# load packages and data
library(h2o)
library(DALEXtra)

# data &lt;- DALEX::titanic_imputed

# init h2o
 cluster &lt;- try(h2o::h2o.init())
if (!inherits(cluster, "try-error")) {
# stop h2o progress printing
 h2o.no_progress()

# split the data
# h2o_split &lt;- h2o.splitFrame(as.h2o(data))
# train &lt;- h2o_split[[1]]
# test &lt;- as.data.frame(h2o_split[[2]])
# h2o automl takes target as factor
# train$survived &lt;- as.factor(train$survived)

# fit a model
# automl &lt;- h2o.automl(y = "survived",
#                   training_frame = train,
#                    max_runtime_secs = 30)


# create an explainer for the model
# explainer &lt;- explain_h2o(automl,
#                        data = test,
#                         y = test$survived,
#                          label = "h2o")


titanic_test &lt;- read.csv(system.file("extdata", "titanic_test.csv", package = "DALEXtra"))
titanic_train &lt;- read.csv(system.file("extdata", "titanic_train.csv", package = "DALEXtra"))
titanic_h2o &lt;- h2o::as.h2o(titanic_train)
titanic_h2o["survived"] &lt;- h2o::as.factor(titanic_h2o["survived"])
titanic_test_h2o &lt;- h2o::as.h2o(titanic_test)
model &lt;- h2o::h2o.gbm(
training_frame = titanic_h2o,
y = "survived",
distribution = "bernoulli",
ntrees = 500,
max_depth = 4,
min_rows =  12,
learn_rate = 0.001
)
explain_h2o(model, titanic_test[,1:17], titanic_test[,18])

try(h2o.shutdown(prompt = FALSE))
 }

</code></pre>

<hr>
<h2 id='explain_keras'>Wrapper for Python Keras Models</h2><span id='topic+explain_keras'></span>

<h3>Description</h3>

<p>Keras models may be loaded into R environment like any other Python object. This function helps to inspect performance of Python model
and compare it with other models, using R tools like DALEX. This function creates an object that is easily accessible R version of Keras model
exported from Python via pickle file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_keras(
  path,
  yml = NULL,
  condaenv = NULL,
  env = NULL,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_keras_+3A_path">path</code></td>
<td>
<p>a path to the pickle file. Can be used without other arguments if you are sure that active Python version match pickle version.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_yml">yml</code></td>
<td>
<p>a path to the yml file. Conda virtual env will be recreated from this file. If OS is Windows conda has to be added to the PATH first</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_condaenv">condaenv</code></td>
<td>
<p>If yml param is provided, a path to the main conda folder. If yml is null, a name of existing conda environment.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_env">env</code></td>
<td>
<p>A path to python virtual environment.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_keras_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_keras_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_keras_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class 'explainer'.
</p>
<p><b>Example of Python code available at documentation <code><a href="#topic+explain_scikitlearn">explain_scikitlearn</a></code></b><br />
</p>
<p><b>Errors use case</b><br />
Here is shortened version of solution for specific errors <br />
<br />
<b>There already exists environment with a name specified by given .yml file</b><br />
If you provide .yml file that in its header contains name exact to name of environment that already exists, existing will be set active without changing it. <br />
You have two ways of solving that issue. Both connected with anaconda prompt. First is removing conda env with command: <br />
<code>conda env remove --name myenv</code><br />
And execute function once again. Second is updating env via: <br />
<code>conda env create -f environment.yml</code><br />
<br />
<b>Conda cannot find specified packages at channels you have provided.</b><br />
That error may be caused by a lot of things. One of those is that specified version is too old to be available from the official conda repo.
Edit Your .yml file and add link to proper repository at channels section.<br />
<br />
Issue may be also connected with the platform. If model was created on the platform with different OS yo may need to remove specific version from .yml file.<br />
<code>- numpy=1.16.4=py36h19fb1c0_0</code><br />
<code>- numpy-base=1.16.4=py36hc3f5095_0</code><br />
In the example above You have to remove <code>=py36h19fb1c0_0</code> and <code>=py36hc3f5095_0</code> <br />
If some packages are not available for anaconda at all, use pip statement<br />
<br />
If .yml file seems not to work, virtual env can be created manually using anaconda promt. <br />
<code>conda create -n name_of_env python=3.4</code> <br />
<code>conda install -n name_of_env name_of_package=0.20</code> <br />
</p>


<h3>Author(s)</h3>

<p>Szymon Maksymiuk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("DALEXtra")
## Not run: 

if (Sys.info()["sysname"] != "Darwin") {
   # Explainer build (Keep in mind that 9th column is target)
   create_env(system.file("extdata", "testing_environment.yml", package = "DALEXtra"))
   test_data &lt;-
   read.csv(
   "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv",
   sep = ",")
   # Keep in mind that when pickle is being built and loaded,
   # not only Python version but libraries versions has to match aswell
   explainer &lt;- explain_keras(system.file("extdata", "keras.pkl", package = "DALEXtra"),
   condaenv = "myenv",
   data = test_data[,1:8], y = test_data[,9])
   plot(model_performance(explainer))

   # Predictions with newdata
   predict(explainer, test_data[1:10,1:8])
}


## End(Not run)

</code></pre>

<hr>
<h2 id='explain_mlr'>Create explainer from your mlr model</h2><span id='topic+explain_mlr'></span>

<h3>Description</h3>

<p>DALEX is designed to work with various black-box models like tree ensembles, linear models, neural networks etc.
Unfortunately R packages that create such models are very inconsistent. Different tools use different interfaces to train, validate and use models.
One of those tools, which is one of the most popular one is the mlr package. We would like to present dedicated explain function for it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_mlr(
  model,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_mlr_+3A_model">model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_mlr_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>explainer object (<code><a href="DALEX.html#topic+explain">explain</a></code>) ready to work with DALEX
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library("DALEXtra")
titanic_test &lt;- read.csv(system.file("extdata", "titanic_test.csv", package = "DALEXtra"))
titanic_train &lt;- read.csv(system.file("extdata", "titanic_train.csv", package = "DALEXtra"))
library("mlr")
task &lt;- mlr::makeClassifTask(
id = "R",
data = titanic_train,
target = "survived"
)
learner &lt;- mlr::makeLearner(
  "classif.gbm",
  par.vals = list(
    distribution = "bernoulli",
    n.trees = 500,
    interaction.depth = 4,
    n.minobsinnode = 12,
    shrinkage = 0.001,
    bag.fraction = 0.5,
    train.fraction = 1
  ),
  predict.type = "prob"
)
gbm &lt;- mlr::train(learner, task)
explain_mlr(gbm, titanic_test[,1:17], titanic_test[,18])

## End(Not run)

</code></pre>

<hr>
<h2 id='explain_mlr3'>Create explainer from your mlr model</h2><span id='topic+explain_mlr3'></span>

<h3>Description</h3>

<p>DALEX is designed to work with various black-box models like tree ensembles, linear models, neural networks etc.
Unfortunately R packages that create such models are very inconsistent. Different tools use different interfaces to train, validate and use models.
One of those tools, which is one of the most popular one is mlr3 package. We would like to present dedicated explain function for it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_mlr3(
  model,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_mlr3_+3A_model">model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_mlr3_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>explainer object (<code><a href="DALEX.html#topic+explain">explain</a></code>) ready to work with DALEX
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library("DALEXtra")
library(mlr3)
titanic_imputed$survived &lt;- as.factor(titanic_imputed$survived)
task_classif &lt;- TaskClassif$new(id = "1", backend = titanic_imputed, target = "survived")
learner_classif &lt;- lrn("classif.rpart", predict_type = "prob")
learner_classif$train(task_classif)
explain_mlr3(learner_classif, data = titanic_imputed,
             y = as.numeric(as.character(titanic_imputed$survived)))


task_regr &lt;- TaskRegr$new(id = "2", backend = apartments, target = "m2.price")
learner_regr &lt;- lrn("regr.rpart")
learner_regr$train(task_regr)
explain_mlr3(learner_regr, data = apartments, apartments$m2.price)

## End(Not run)

</code></pre>

<hr>
<h2 id='explain_scikitlearn'>Wrapper for Python Scikit-Learn Models</h2><span id='topic+explain_scikitlearn'></span>

<h3>Description</h3>

<p>scikit-learn models may be loaded into R environment like any other Python object. This function helps to inspect performance of Python model
and compare it with other models, using R tools like DALEX. This function creates an object that is easily accessible R version of scikit-learn model
exported from Python via pickle file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_scikitlearn(
  path,
  yml = NULL,
  condaenv = NULL,
  env = NULL,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_scikitlearn_+3A_path">path</code></td>
<td>
<p>a path to the pickle file. Can be used without other arguments if you are sure that active Python version match pickle version.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_yml">yml</code></td>
<td>
<p>a path to the yml file. Conda virtual env will be recreated from this file. If OS is Windows conda has to be added to the PATH first</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_condaenv">condaenv</code></td>
<td>
<p>If yml param is provided, a path to the main conda folder. If yml is null, a name of existing conda environment.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_env">env</code></td>
<td>
<p>A path to python virtual environment.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_scikitlearn_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class 'explainer'. It has additional field param_set when user can check parameters of scikit-learn model
</p>
<p><b>Example of Python code</b><br />
</p>
<p>from pandas import DataFrame, read_csv <br />
import pandas as pd<br />
import pickle<br />
import sklearn.ensemble<br />
model = sklearn.ensemble.GradientBoostingClassifier() <br />
model = model.fit(titanic_train_X, titanic_train_Y)<br />
pickle.dump(model, open(&quot;gbm.pkl&quot;, &quot;wb&quot;), protocol = 2)<br />
<br />
<br />
In order to export environment into .yml, activating virtual env via <code>activate name_of_the_env</code> and execution of the following shell command is necessary <br />
<code>conda env export &gt; environment.yml</code><br />
<br />
</p>
<p><b>Errors use case</b><br />
Here is shortened version of solution for specific errors <br />
<br />
<b>There already exists environment with a name specified by given .yml file</b><br />
If you provide .yml file that in its header contatins name exact to name of environment that already exists, existing will be set active without changing it. <br />
You have two ways of solving that issue. Both connected with anaconda prompt. First is removing conda env with command: <br />
<code>conda env remove --name myenv</code><br />
And execute function once again. Second is updating env via: <br />
<code>conda env create -f environment.yml</code><br />
<br />
<b>Conda cannot find specified packages at channels you have provided.</b><br />
That error may be casued by a lot of things. One of those is that specified version is too old to be avaialble from offcial conda repo.
Edit Your .yml file and add link to proper repository at channels section.<br />
<br />
Issue may be also connected with the platform. If model was created on the platform with different OS yo may need to remove specific version from .yml file.<br />
<code>- numpy=1.16.4=py36h19fb1c0_0</code><br />
<code>- numpy-base=1.16.4=py36hc3f5095_0</code><br />
In the example above You have to remove <code>=py36h19fb1c0_0</code> and <code>=py36hc3f5095_0</code> <br />
If some packages are not availbe for anaconda at all, use pip statement<br />
<br />
If .yml file seems not to work, virtual env can be created manually using anaconda promt. <br />
<code>conda create -n name_of_env python=3.4</code> <br />
<code>conda install -n name_of_env name_of_package=0.20</code> <br />
</p>


<h3>Author(s)</h3>

<p>Szymon Maksymiuk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

 if (Sys.info()["sysname"] != "Darwin") {
   # Explainer build (Keep in mind that 18th column is target)
   titanic_test &lt;- read.csv(system.file("extdata", "titanic_test.csv", package = "DALEXtra"))
   # Keep in mind that when pickle is being built and loaded,
   # not only Python version but libraries versions has to match aswell
   explainer &lt;- explain_scikitlearn(system.file("extdata", "scikitlearn.pkl", package = "DALEXtra"),
   yml = system.file("extdata", "testing_environment.yml", package = "DALEXtra"),
   data = titanic_test[,1:17], y = titanic_test$survived)
   plot(model_performance(explainer))

   # Predictions with newdata
   predict(explainer, titanic_test[1:10,1:17])
 }

## End(Not run)

</code></pre>

<hr>
<h2 id='explain_tidymodels'>Create explainer from your tidymodels workflow.</h2><span id='topic+explain_tidymodels'></span>

<h3>Description</h3>

<p>DALEX is designed to work with various black-box models like tree ensembles, linear models, neural networks etc.
Unfortunately R packages that create such models are very inconsistent. Different tools use different interfaces to train, validate and use models.
One of those tools, which is one of the most popular one is the tidymodels package. We would like to present dedicated explain function for it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_tidymodels(
  model,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_tidymodels_+3A_model">model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_tidymodels_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>explainer object (<code><a href="DALEX.html#topic+explain">explain</a></code>) ready to work with DALEX
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library("DALEXtra")
library("tidymodels")
library("recipes")
data &lt;- titanic_imputed
data$survived &lt;- as.factor(data$survived)
rec &lt;- recipe(survived ~ ., data = data) %&gt;%
       step_normalize(fare)
model &lt;- decision_tree(tree_depth = 25) %&gt;%
         set_engine("rpart") %&gt;%
         set_mode("classification")

wflow &lt;- workflow() %&gt;%
         add_recipe(rec) %&gt;%
         add_model(model)


model_fitted &lt;- wflow %&gt;%
                fit(data = data)

explain_tidymodels(model_fitted, data = titanic_imputed, y = titanic_imputed$survived)

## End(Not run)

</code></pre>

<hr>
<h2 id='explain_xgboost'>Create explainer from your xgboost model</h2><span id='topic+explain_xgboost'></span>

<h3>Description</h3>

<p>DALEX is designed to work with various black-box models like tree ensembles, linear models, neural networks etc.
Unfortunately R packages that create such models are very inconsistent. Different tools use different interfaces to train, validate and use models.
One of those tools, we would like to make more accessible is the xgboost package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explain_xgboost(
  model,
  data = NULL,
  y = NULL,
  weights = NULL,
  predict_function = NULL,
  predict_function_target_column = NULL,
  residual_function = NULL,
  ...,
  label = NULL,
  verbose = TRUE,
  precalculate = TRUE,
  colorize = !isTRUE(getOption("knitr.in.progress")),
  model_info = NULL,
  type = NULL,
  encode_function = NULL,
  true_labels = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="explain_xgboost_+3A_model">model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_data">data</code></td>
<td>
<p>data.frame or matrix - data which will be used to calculate the explanations. If not provided, then it will be extracted from the model. Data should be passed without a target column (this shall be provided as the <code>y</code> argument). NOTE: If the target variable is present in the <code>data</code>, some of the functionalities may not work properly.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_y">y</code></td>
<td>
<p>numeric vector with outputs/scores. If provided, then it shall have the same size as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_weights">weights</code></td>
<td>
<p>numeric vector with sampling weights. By default it's <code>NULL</code>. If provided, then it shall have the same length as <code>data</code></p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_predict_function">predict_function</code></td>
<td>
<p>function that takes two arguments: model and new data and returns a numeric vector with predictions.   By default it is <code>yhat</code>.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_predict_function_target_column">predict_function_target_column</code></td>
<td>
<p>Character or numeric containing either column name or column number in the model prediction object of the class that should be considered as positive (i.e. the class that is associated with probability 1). If NULL, the second column of the output will be taken for binary classification. For a multiclass classification setting, that parameter cause switch to binary classification mode with one vs others probabilities.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_residual_function">residual_function</code></td>
<td>
<p>function that takes four arguments: model, data, target vector y and predict function (optionally). It should return a numeric vector with model residuals for given data. If not provided, response residuals (<code class="reqn">y-\hat{y}</code>) are calculated. By default it is <code>residual_function_default</code>.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_label">label</code></td>
<td>
<p>character - the name of the model. By default it's extracted from the 'class' attribute of the model</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE (default) then diagnostic messages will be printed</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_precalculate">precalculate</code></td>
<td>
<p>logical. If TRUE (default) then <code>predicted_values</code> and <code>residual</code> are calculated when explainer is created.
This will happen also if <code>verbose</code> is TRUE. Set both <code>verbose</code> and <code>precalculate</code> to FALSE to omit calculations.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_colorize">colorize</code></td>
<td>
<p>logical. If TRUE (default) then <code>WARNINGS</code>, <code>ERRORS</code> and <code>NOTES</code> are colorized. Will work only in the R console. Now by default it is <code>FALSE</code> while knitting and <code>TRUE</code> otherwise.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_model_info">model_info</code></td>
<td>
<p>a named list (<code>package</code>, <code>version</code>, <code>type</code>) containing information about model. If <code>NULL</code>, <code>DALEX</code> will seek for information on it's own.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_type">type</code></td>
<td>
<p>type of a model, either <code>classification</code> or <code>regression</code>. If not specified then <code>type</code> will be extracted from <code>model_info</code>.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_encode_function">encode_function</code></td>
<td>
<p>function(data, ...) that if executed with <code>data</code> 
parameters returns encoded dataframe that was used to fit model. Xgboost does 
not handle factors on it's own so such function is needed to acquire better explanations.</p>
</td></tr>
<tr><td><code id="explain_xgboost_+3A_true_labels">true_labels</code></td>
<td>
<p>a vector of <code>y</code> before encoding.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>explainer object (<code><a href="DALEX.html#topic+explain">explain</a></code>) ready to work with DALEX
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("xgboost")
library("DALEXtra")
library("mlr")
# 8th column is target that has to be omitted in X data
data &lt;- as.matrix(createDummyFeatures(titanic_imputed[,-8]))
model &lt;- xgboost(data, titanic_imputed$survived, nrounds = 10,
                 params = list(objective = "binary:logistic"),
                prediction = TRUE)
# explainer with encode functiom
explainer_1 &lt;- explain_xgboost(model, data = titanic_imputed[,-8],
                               titanic_imputed$survived,
                               encode_function = function(data) {
 as.matrix(createDummyFeatures(data))
})
plot(predict_parts(explainer_1, titanic_imputed[1,-8]))

# explainer without encode function
explainer_2 &lt;- explain_xgboost(model, data = data, titanic_imputed$survived)
plot(predict_parts(explainer_2, data[1,,drop = FALSE]))

</code></pre>

<hr>
<h2 id='funnel_measure'>Caluculate difference in performance in models across different categories</h2><span id='topic+funnel_measure'></span>

<h3>Description</h3>

<p>Function <code>funnel_measure</code> allows users to compare two models based on their explainers. It partitions dataset on which models were built
and creates categories according to quantiles of columns in <code>parition data</code>. <code>nbins</code> parameter determines number of quantiles.
For each category difference in provided measure is being calculated. Positive value of that difference means that Champion model
has better performance in specified category, while negative value means that one of the Challengers was better. Function allows
to compare multiple Challengers at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>funnel_measure(
  champion,
  challengers,
  measure_function = NULL,
  nbins = 5,
  partition_data = champion$data,
  cutoff = 0.01,
  cutoff_name = "Other",
  factor_conversion_threshold = 7,
  show_info = TRUE,
  categories = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="funnel_measure_+3A_champion">champion</code></td>
<td>
<p>- explainer of champion model.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_challengers">challengers</code></td>
<td>
<p>- explainer of challenger model or list of explainers.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_measure_function">measure_function</code></td>
<td>
<p>- measure function that calculates performance of model based on true observation and prediction.
Order of parameters is important and should be (y, y_hat). The measure calculated by the function
should have the property that lower score value indicates better model. If NULL, RMSE will be used for regression,
one minus auc for classification and crossentropy for multiclass classification.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_nbins">nbins</code></td>
<td>
<p>- Number of quantiles (partition points) for numeric columns. In case when more than one quantile have the same value, there will be less partition points.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_partition_data">partition_data</code></td>
<td>
<p>- Data by which test dataset will be partitioned for computation. Can be either data.frame or character vector.
When second is passed, it has to indicate names of columns that will be extracted from test data.
By default full test data. If data.frame, number of rows has to be equal to number of rows in test data.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_cutoff">cutoff</code></td>
<td>
<p>- Threshold for categorical data. Entries less frequent than specified value will be merged into one category.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_cutoff_name">cutoff_name</code></td>
<td>
<p>- Name for new category that arised after merging entries less frequent than <code>cutoff</code></p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_factor_conversion_threshold">factor_conversion_threshold</code></td>
<td>
<p>- Numeric columns with lower number of unique values than value of this parameter will be treated as factors</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_show_info">show_info</code></td>
<td>
<p>- Logical value indicating if progress bar should be shown.</p>
</td></tr>
<tr><td><code id="funnel_measure_+3A_categories">categories</code></td>
<td>
<p>- a named list of variable names that will be plotted in a different colour. By default it is partitioned on Explanatory, External and Target.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>funnel_measure</code>
</p>
<p>It is a named list containing following fields:
</p>

<ul>
<li> <p><code>data</code> data.frame that consists of columns:
</p>

<ul>
<li> <p><code>Variable</code> Variable according to which partitions were made
</p>
</li>
<li> <p><code>Measure</code> Difference in measures. Positive value indicates that champion was better, while negative that challenger.
</p>
</li>
<li> <p><code>Label</code> String that defines subset of <code>Variable</code> values (partition rule).
</p>
</li>
<li> <p><code>Challenger</code> Label of challenger explainer that was used in <code>Measure</code>
</p>
</li>
<li> <p><code>Category</code> a category of the variable passed to function
</p>
</li></ul>

</li>
<li> <p><code>models_info</code> data.frame containing information about models used in analysis
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library("mlr")
library("DALEXtra")
task &lt;- mlr::makeRegrTask(
  id = "R",
  data = apartments,
  target = "m2.price"
)
learner_lm &lt;- mlr::makeLearner(
  "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
  "regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
  "regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")


plot_data &lt;- funnel_measure(explainer_lm, list(explainer_rf, explainer_gbm),
                            nbins = 5, measure_function = DALEX::loss_root_mean_square)
plot(plot_data)

</code></pre>

<hr>
<h2 id='model_info.WrappedModel'>Exract info from model</h2><span id='topic+model_info.WrappedModel'></span><span id='topic+model_info.H2ORegressionModel'></span><span id='topic+model_info.H2OBinomialModel'></span><span id='topic+model_info.H2OMultinomialModel'></span><span id='topic+model_info.scikitlearn_model'></span><span id='topic+model_info.keras'></span><span id='topic+model_info.LearnerRegr'></span><span id='topic+model_info.LearnerClassif'></span><span id='topic+model_info.GraphLearner'></span><span id='topic+model_info.xgb.Booster'></span><span id='topic+model_info.workflow'></span><span id='topic+model_info.model_stack'></span>

<h3>Description</h3>

<p>This generic function let user extract base information about model. The function returns a named list of class <code>model_info</code> that
contain about package of model, version and task type. For wrappers like <code>mlr</code> or <code>caret</code> both, package and wrapper information
are stored
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'WrappedModel'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'H2ORegressionModel'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'H2OBinomialModel'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'H2OMultinomialModel'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'scikitlearn_model'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'keras'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'LearnerRegr'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'LearnerClassif'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'GraphLearner'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'xgb.Booster'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'workflow'
model_info(model, is_multiclass = FALSE, ...)

## S3 method for class 'model_stack'
model_info(model, is_multiclass = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model_info.WrappedModel_+3A_model">model</code></td>
<td>
<p>- model object</p>
</td></tr>
<tr><td><code id="model_info.WrappedModel_+3A_is_multiclass">is_multiclass</code></td>
<td>
<p>- if TRUE and task is classification, then multitask classification is set. Else is omitted. If <code>model_info</code>
was executed withing <code>explain</code> function. DALEX will recognize subtype on it's own. @param is_multiclass</p>
</td></tr>
<tr><td><code id="model_info.WrappedModel_+3A_...">...</code></td>
<td>
<p>- another arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently supported packages are:
</p>

<ul>
<li> <p><code>mlr</code> models created with <code>mlr</code> package
</p>
</li>
<li> <p><code>h2o</code> models created with <code>h2o</code> package
</p>
</li>
<li> <p><code>scikit-learn</code> models created with <code>scikit-learn</code> Python library and accessed via <code>reticulate</code>
</p>
</li>
<li> <p><code>keras</code> models created with <code>keras</code> Python library and accessed via <code>reticulate</code>
</p>
</li>
<li> <p><code>mlr3</code> models created with <code>mlr3</code> package
</p>
</li>
<li> <p><code>xgboost</code> models created with <code>xgboost</code> package
</p>
</li>
<li> <p><code>tidymodels</code> models created with <code>tidymodels</code> package
</p>
</li></ul>



<h3>Value</h3>

<p>A named list of class <code>model_info</code>
</p>

<hr>
<h2 id='overall_comparison'>Compare champion with challengers globally</h2><span id='topic+overall_comparison'></span>

<h3>Description</h3>

<p>The function creates objects that present global model performance using various measures. Those date can be easily
plotted with <code>plot</code> function. It uses <code>auditor</code> package to create <code><a href="auditor.html#topic+model_performance">model_performance</a></code> of all passed
explainers. Keep in mind that type of task has to be specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overall_comparison(champion, challengers, type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overall_comparison_+3A_champion">champion</code></td>
<td>
<p>- explainer of champion model.</p>
</td></tr>
<tr><td><code id="overall_comparison_+3A_challengers">challengers</code></td>
<td>
<p>- explainer of challenger model or list of explainers.</p>
</td></tr>
<tr><td><code id="overall_comparison_+3A_type">type</code></td>
<td>
<p>- type of the task. Either classification or regression</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class overall_comparison
</p>
<p>It is a named list containing following fields:
</p>

<ul>
<li> <p><code>radar</code> list of <code><a href="auditor.html#topic+model_performance">model_performance</a></code> objects and other parameters that will be passed to generic <code>plot</code> function
</p>
</li>
<li> <p><code>accordance</code> data.frame object of champion responses and challenger's corresponding to them. Used to plot accordance.
</p>
</li>
<li> <p><code>models_info</code> data.frame containing information about models used in analysis
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library("DALEXtra")
library("mlr")
task &lt;- mlr::makeRegrTask(
  id = "R",
  data = apartments,
  target = "m2.price"
)
learner_lm &lt;- mlr::makeLearner(
  "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
  "regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
  "regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "gbm")

data &lt;- overall_comparison(explainer_lm, list(explainer_gbm, explainer_rf), type = "regression")
plot(data)

</code></pre>

<hr>
<h2 id='plot.funnel_measure'>Funnel plot for difference in measures</h2><span id='topic+plot.funnel_measure'></span>

<h3>Description</h3>

<p>Function <code>plot.funnel_measure</code> creates funnel plot of differences in measures for two models across variable areas.
It uses data created with 'funnel_measure' function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'funnel_measure'
plot(x, ..., dot_size = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.funnel_measure_+3A_x">x</code></td>
<td>
<p>- funnel_measure object created with <code><a href="#topic+funnel_measure">funnel_measure</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.funnel_measure_+3A_...">...</code></td>
<td>
<p>- other parameters</p>
</td></tr>
<tr><td><code id="plot.funnel_measure_+3A_dot_size">dot_size</code></td>
<td>
<p>- size of the dot on plots. Passed to <code><a href="ggplot2.html#topic+geom_point">geom_point</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("mlr")
library("DALEXtra")
task &lt;- mlr::makeRegrTask(
  id = "R",
  data = apartments,
  target = "m2.price"
)
learner_lm &lt;- mlr::makeLearner(
  "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
  "regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
  "regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")


plot_data &lt;- funnel_measure(explainer_lm, list(explainer_rf, explainer_gbm),
                            nbins = 5, measure_function = DALEX::loss_root_mean_square)
plot(plot_data)

</code></pre>

<hr>
<h2 id='plot.overall_comparison'>Plot function for overall_comparison</h2><span id='topic+plot.overall_comparison'></span>

<h3>Description</h3>

<p>The function plots data created with <code><a href="#topic+overall_comparison">overall_comparison</a></code>. For radar plot it uses auditor's
<code><a href="auditor.html#topic+plot_radar">plot_radar</a></code>. Keep in mind that the function creates two plots returned as list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'overall_comparison'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.overall_comparison_+3A_x">x</code></td>
<td>
<p>- data created with <code><a href="#topic+overall_comparison">overall_comparison</a></code></p>
</td></tr>
<tr><td><code id="plot.overall_comparison_+3A_...">...</code></td>
<td>
<p>- other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of ggplot objects.
</p>
<p>It consists of:
</p>

<ul>
<li> <p><code>radar_plot</code> plot created with <code><a href="auditor.html#topic+plot_radar">plot_radar</a></code>
</p>
</li>
<li> <p><code>accordance_plot</code> accordance plot of responses. OX axis stand for champion response, while OY for one of challengers
responses. Colour indicates on challenger.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library("DALEXtra")
library("mlr")
task &lt;- mlr::makeRegrTask(
  id = "R",
  data = apartments,
  target = "m2.price"
)
learner_lm &lt;- mlr::makeLearner(
  "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
  "regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
  "regr.gbm"
)
model_gbm&lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")

data &lt;- overall_comparison(explainer_lm, list(explainer_gbm, explainer_rf), type = "regression")
plot(data)

</code></pre>

<hr>
<h2 id='plot.training_test_comparison'>Plot and compare performance of model between training and test set</h2><span id='topic+plot.training_test_comparison'></span>

<h3>Description</h3>

<p>Function <code>plot.training_test_comparison</code> plots dependency between model performance on test and training dataset based on
<code>training_test_comparison</code> object. Green line indicates <code>y = x</code> line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'training_test_comparison'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.training_test_comparison_+3A_x">x</code></td>
<td>
<p>- object created with <code><a href="#topic+training_test_comparison">training_test_comparison</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.training_test_comparison_+3A_...">...</code></td>
<td>
<p>- other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("mlr")
library("DALEXtra")
task &lt;- mlr::makeRegrTask(
 id = "R",
  data = apartments,
   target = "m2.price"
)
 learner_lm &lt;- mlr::makeLearner(
 "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
"regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
"regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")

data &lt;- training_test_comparison(explainer_lm, list(explainer_gbm, explainer_rf),
                                 training_data = apartments,
                                 training_y = apartments$m2.price)
plot(data)

</code></pre>

<hr>
<h2 id='predict_surrogate'>Instance Level Surrogate Models</h2><span id='topic+predict_surrogate'></span><span id='topic+predict_parts_break_down'></span><span id='topic+predict_parts'></span><span id='topic+predict_parts_ibreak_down'></span><span id='topic+predict_parts_shap'></span><span id='topic+predict_surrogate_local_model'></span><span id='topic+predict_model.dalex_explainer'></span><span id='topic+model_type.dalex_explainer'></span><span id='topic+predict_surrogate_lime'></span><span id='topic+plot.predict_surrogate_lime'></span><span id='topic+predict_surrogate_iml'></span>

<h3>Description</h3>

<p>Interface to different implementations of the LIME method.
Find information how the LIME method works here: <a href="https://ema.drwhy.ai/LIME.html">https://ema.drwhy.ai/LIME.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_surrogate(explainer, new_observation, ..., type = "localModel")

predict_surrogate_local_model(
  explainer,
  new_observation,
  size = 1000,
  seed = 1313,
  ...
)

predict_model.dalex_explainer(x, newdata, ...)

model_type.dalex_explainer(x, ...)

predict_surrogate_lime(
  explainer,
  new_observation,
  n_features = 4,
  n_permutations = 1000,
  labels = unique(explainer$y)[1],
  ...
)

## S3 method for class 'predict_surrogate_lime'
plot(x, ...)

predict_surrogate_iml(explainer, new_observation, k = 4, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_surrogate_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the 'explain' function</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_new_observation">new_observation</code></td>
<td>
<p>a new observation for which predictions need to be explained</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_type">type</code></td>
<td>
<p>which implementation of thee LIME method should be used. Either <code>localModel</code> (default), <code>lime</code> or <code>iml</code>.</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_size">size</code></td>
<td>
<p>will be passed to the localModel implementation, by default 1000</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_seed">seed</code></td>
<td>
<p>seed for random number generator, by default 1313</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_x">x</code></td>
<td>
<p>an object to be plotted</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_newdata">newdata</code></td>
<td>
<p>alias for new_observation</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_n_features">n_features</code></td>
<td>
<p>will be passed to the lime implementation, by default 4</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_n_permutations">n_permutations</code></td>
<td>
<p>will be passed to the lime implementation, by default 1000</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_labels">labels</code></td>
<td>
<p>will be passed to the lime implementation, by default first value in the y vector</p>
</td></tr>
<tr><td><code id="predict_surrogate_+3A_k">k</code></td>
<td>
<p>will be passed to the iml implementation, by default 4</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the <code>type</code> there are different classess of the resulting object.
</p>


<h3>References</h3>

<p>Explanatory Model Analysis. Explore, Explain and Examine Predictive Models. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a>
</p>

<hr>
<h2 id='print.funnel_measure'>Print funnel_measure object</h2><span id='topic+print.funnel_measure'></span>

<h3>Description</h3>

<p>Print funnel_measure object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'funnel_measure'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.funnel_measure_+3A_x">x</code></td>
<td>
<p>an object of class <code>funnel_measure</code></p>
</td></tr>
<tr><td><code id="print.funnel_measure_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library("DALEXtra")
library("mlr")
task &lt;- mlr::makeRegrTask(
  id = "R",
  data = apartments,
  target = "m2.price"
)
learner_lm &lt;- mlr::makeLearner(
  "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
  "regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
  "regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")

plot_data &lt;- funnel_measure(explainer_lm, list(explainer_rf, explainer_gbm),
                            nbins = 5, measure_function = DALEX::loss_root_mean_square)
print(plot_data)

</code></pre>

<hr>
<h2 id='print.overall_comparison'>Print overall_comparison object</h2><span id='topic+print.overall_comparison'></span>

<h3>Description</h3>

<p>Print overall_comparison object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'overall_comparison'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.overall_comparison_+3A_x">x</code></td>
<td>
<p>an object of class <code>overall_comparison</code></p>
</td></tr>
<tr><td><code id="print.overall_comparison_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library("DALEXtra")
library("mlr")
task &lt;- mlr::makeRegrTask(
  id = "R",
  data = apartments,
  target = "m2.price"
)
learner_lm &lt;- mlr::makeLearner(
  "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
  "regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
  "regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "gbm")

data &lt;- overall_comparison(explainer_lm, list(explainer_gbm, explainer_rf), type = "regression")
print(data)

</code></pre>

<hr>
<h2 id='print.scikitlearn_set'>Prints scikitlearn_set class</h2><span id='topic+print.scikitlearn_set'></span>

<h3>Description</h3>

<p>Prints scikitlearn_set class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scikitlearn_set'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.scikitlearn_set_+3A_x">x</code></td>
<td>
<p>a list from explainer created with <code><a href="#topic+explain_scikitlearn">explain_scikitlearn</a></code></p>
</td></tr>
<tr><td><code id="print.scikitlearn_set_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>

<hr>
<h2 id='print.training_test_comparison'>Print funnel_measure object</h2><span id='topic+print.training_test_comparison'></span>

<h3>Description</h3>

<p>Print funnel_measure object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'training_test_comparison'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.training_test_comparison_+3A_x">x</code></td>
<td>
<p>an object of class <code>funnel_measure</code></p>
</td></tr>
<tr><td><code id="print.training_test_comparison_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("mlr")
library("DALEXtra")
task &lt;- mlr::makeRegrTask(
 id = "R",
  data = apartments,
   target = "m2.price"
)
 learner_lm &lt;- mlr::makeLearner(
 "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
"regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
"regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")

data &lt;- training_test_comparison(explainer_lm, list(explainer_gbm, explainer_rf),
                                 training_data = apartments,
                                 training_y = apartments$m2.price)
print(data)
</code></pre>

<hr>
<h2 id='training_test_comparison'>Compare performance of model between training and test set</h2><span id='topic+training_test_comparison'></span>

<h3>Description</h3>

<p>Function <code>training_test_comparison</code> calculates performance of the provided model based on specified measure function.
Response of the model is calculated based on test data, extracted from the explainer and training data, provided by the user.
Output can be easily shown with <code>print</code> or <code>plot</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>training_test_comparison(
  champion,
  challengers,
  training_data,
  training_y,
  measure_function = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="training_test_comparison_+3A_champion">champion</code></td>
<td>
<p>- explainer of champion model.</p>
</td></tr>
<tr><td><code id="training_test_comparison_+3A_challengers">challengers</code></td>
<td>
<p>- explainer of challenger model or list of explainers.</p>
</td></tr>
<tr><td><code id="training_test_comparison_+3A_training_data">training_data</code></td>
<td>
<p>- data without target column that will be passed to predict function and then to measure function. Keep in mind that
they have to differ from data passed to an explainer.</p>
</td></tr>
<tr><td><code id="training_test_comparison_+3A_training_y">training_y</code></td>
<td>
<p>- target column for <code>training_data</code></p>
</td></tr>
<tr><td><code id="training_test_comparison_+3A_measure_function">measure_function</code></td>
<td>
<p>- measure function that calculates performance of model based on true observation and prediction.
Order of parameters is important and should be (y, y_hat). By default it is RMSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>training_test_comparison</code>.
</p>
<p>It is a named list containing:
</p>

<ul>
<li> <p><code>data</code> data.frame with following columns
</p>

<ul>
<li> <p><code>measure_test</code> performance on test set
</p>
</li>
<li> <p><code>measure_train</code> performance on training set
</p>
</li>
<li> <p><code>label</code> label of explainer
</p>
</li>
<li> <p><code>type</code> flag that indicates if explainer was passed as champion or as challenger.
</p>
</li></ul>

</li>
<li> <p><code>models_info</code> data.frame containing information about models used in analysis
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library("mlr")
library("DALEXtra")
task &lt;- mlr::makeRegrTask(
 id = "R",
  data = apartments,
   target = "m2.price"
)
 learner_lm &lt;- mlr::makeLearner(
 "regr.lm"
)
model_lm &lt;- mlr::train(learner_lm, task)
explainer_lm &lt;- explain_mlr(model_lm, apartmentsTest, apartmentsTest$m2.price, label = "LM")

learner_rf &lt;- mlr::makeLearner(
"regr.ranger"
)
model_rf &lt;- mlr::train(learner_rf, task)
explainer_rf &lt;- explain_mlr(model_rf, apartmentsTest, apartmentsTest$m2.price, label = "RF")

learner_gbm &lt;- mlr::makeLearner(
"regr.gbm"
)
model_gbm &lt;- mlr::train(learner_gbm, task)
explainer_gbm &lt;- explain_mlr(model_gbm, apartmentsTest, apartmentsTest$m2.price, label = "GBM")

data &lt;- training_test_comparison(explainer_lm, list(explainer_gbm, explainer_rf),
                                 training_data = apartments,
                                 training_y = apartments$m2.price)
plot(data)
</code></pre>

<hr>
<h2 id='yhat.WrappedModel'>Wrapper over the predict function</h2><span id='topic+yhat.WrappedModel'></span><span id='topic+yhat.H2ORegressionModel'></span><span id='topic+yhat.H2OBinomialModel'></span><span id='topic+yhat.H2OMultinomialModel'></span><span id='topic+yhat.scikitlearn_model'></span><span id='topic+yhat.keras'></span><span id='topic+yhat.LearnerRegr'></span><span id='topic+yhat.LearnerClassif'></span><span id='topic+yhat.GraphLearner'></span><span id='topic+yhat.xgb.Booster'></span><span id='topic+yhat.workflow'></span><span id='topic+yhat.model_stack'></span>

<h3>Description</h3>

<p>These functions are default predict functions.
Each function returns a single numeric score for each new observation.
Those functions are very important since information from many models have to be extracted with various techniques.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'WrappedModel'
yhat(X.model, newdata, ...)

## S3 method for class 'H2ORegressionModel'
yhat(X.model, newdata, ...)

## S3 method for class 'H2OBinomialModel'
yhat(X.model, newdata, ...)

## S3 method for class 'H2OMultinomialModel'
yhat(X.model, newdata, ...)

## S3 method for class 'scikitlearn_model'
yhat(X.model, newdata, ...)

## S3 method for class 'keras'
yhat(X.model, newdata, ...)

## S3 method for class 'LearnerRegr'
yhat(X.model, newdata, ...)

## S3 method for class 'LearnerClassif'
yhat(X.model, newdata, ...)

## S3 method for class 'GraphLearner'
yhat(X.model, newdata, ...)

## S3 method for class 'xgb.Booster'
yhat(X.model, newdata, ...)

## S3 method for class 'workflow'
yhat(X.model, newdata, ...)

## S3 method for class 'model_stack'
yhat(X.model, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="yhat.WrappedModel_+3A_x.model">X.model</code></td>
<td>
<p>object - a model to be explained</p>
</td></tr>
<tr><td><code id="yhat.WrappedModel_+3A_newdata">newdata</code></td>
<td>
<p>data.frame or matrix - observations for prediction</p>
</td></tr>
<tr><td><code id="yhat.WrappedModel_+3A_...">...</code></td>
<td>
<p>other parameters that will be passed to the predict function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently supported packages are:
</p>

<ul>
<li> <p><code>mlr</code> see more in <code><a href="#topic+explain_mlr">explain_mlr</a></code>
</p>
</li>
<li> <p><code>h2o</code> see more in <code><a href="#topic+explain_h2o">explain_h2o</a></code>
</p>
</li>
<li> <p><code>scikit-learn</code> see more in <code><a href="#topic+explain_scikitlearn">explain_scikitlearn</a></code>
</p>
</li>
<li> <p><code>keras</code> see more in <code><a href="#topic+explain_keras">explain_keras</a></code>
</p>
</li>
<li> <p><code>mlr3</code> see more in <code><a href="#topic+explain_mlr3">explain_mlr3</a></code>
</p>
</li>
<li> <p><code>xgboost</code> see more in <code><a href="#topic+explain_xgboost">explain_xgboost</a></code>
</p>
</li>
<li> <p><code>tidymodels</code> see more in <code><a href="#topic+explain_tidymodels">explain_tidymodels</a></code>
</p>
</li></ul>



<h3>Value</h3>

<p>An numeric vector of predictions
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
