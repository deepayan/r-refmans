<!DOCTYPE html><html><head><title>Help for package nlpred</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nlpred}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.Dy'><p>Compute one of the terms of the efficient influence function</p></a></li>
<li><a href='#.estim_fn'><p>An estimating function for cvAUC</p></a></li>
<li><a href='#.estim_fn_nested_cv'><p>An estimating function for cvAUC with initial estimates generated via</p>
nested cross-validation</a></li>
<li><a href='#.get_auc'><p>Compute the AUC given the cdf and pdf of psi</p></a></li>
<li><a href='#.get_cv_estim'><p>Helper function to turn prediction_list into CV estimate of SCRNP</p></a></li>
<li><a href='#.get_density'><p>Function to estimate density needed to evaluate standard errors.</p></a></li>
<li><a href='#.get_nested_cv_quantile'><p>Helper function to get quantile for a single training fold data</p>
when nested CV is used.</a></li>
<li><a href='#.get_one_fold'><p>Helper function to get results for a single cross-validation fold</p></a></li>
<li><a href='#.get_predictions'><p>Worker function for fitting prediction functions (possibly in parallel)</p></a></li>
<li><a href='#.get_psi_distribution'><p>Compute the conditional (given Y = y) estimated distribution of psi</p></a></li>
<li><a href='#.get_psi_distribution_nested_cv'><p>Compute the conditional (given Y = y) CV-estimated distribution of psi</p></a></li>
<li><a href='#.get_quantile'><p>Helper function to get quantile for a single training fold data</p>
when nested CV is NOT used.</a></li>
<li><a href='#.make_long_data'><p>Worker function to make long form data set needed for</p>
CVTMLE targeting step</a></li>
<li><a href='#.make_long_data_nested_cv'><p>Worker function to make long form data set needed for</p>
CVTMLE targeting step when nested cv is used</a></li>
<li><a href='#.make_targeting_data'><p>Helper function for making data set in proper format for CVTMLE</p></a></li>
<li><a href='#.process_input'><p>Unexported function from cvAUC package</p></a></li>
<li><a href='#adult'><p>adult</p></a></li>
<li><a href='#bank'><p>bank</p></a></li>
<li><a href='#boot_auc'><p>Compute the bootstrap-corrected estimator of AUC.</p></a></li>
<li><a href='#boot_scrnp'><p>Compute the bootstrap-corrected estimator of SCRNP.</p></a></li>
<li><a href='#cardio'><p>Cardiotocography</p></a></li>
<li><a href='#ci.cvAUC_withIC'><p>ci.cvAUC_withIC</p></a></li>
<li><a href='#cv_auc'><p>Estimates of CVAUC</p></a></li>
<li><a href='#cv_scrnp'><p>Estimates of CV SCNP</p></a></li>
<li><a href='#drugs'><p>drugs</p></a></li>
<li><a href='#F_nBn_star'><p>Compute the targeted conditional cumulative distribution of the learner at a point</p></a></li>
<li><a href='#F_nBn_star_nested_cv'><p>Compute the targeted conditional cumulative distribution of the learner at a point</p>
where the initial distribution is based on cross validation</a></li>
<li><a href='#fluc_mod_optim_0'><p>Helper function for CVTMLE grid search</p></a></li>
<li><a href='#fluc_mod_optim_1'><p>Helper function for CVTMLE grid search</p></a></li>
<li><a href='#glm_wrapper'><p>Wrapper for fitting a logistic regression using <code>glm</code>.</p></a></li>
<li><a href='#glmnet_wrapper'><p>Wrapper for fitting a lasso using package <code>glmnet</code>.</p></a></li>
<li><a href='#lpo_auc'><p>Compute the leave-pair-out cross-validation estimator of AUC.</p></a></li>
<li><a href='#one_boot_auc'><p>Internal function used to perform one bootstrap sample. The function</p>
<code>try</code>s to fit <code>learner</code> on a bootstrap sample. If for some reason
(e.g., the bootstrap sample contains no observations with <code>Y = 1</code>)
the learner fails, then the function returns <code>NA</code>. These <code>NA</code>s
are ignored later when computing the bootstrap corrected estimate.</a></li>
<li><a href='#one_boot_scrnp'><p>Internal function used to perform one bootstrap sample. The function</p>
<code>try</code>s to fit <code>learner</code> on a bootstrap sample. If for some reason
(e.g., the bootstrap sample contains no observations with <code>Y = 1</code>)
the learner fails, then the function returns <code>NA</code>. These <code>NA</code>s
are ignored later when computing the bootstrap corrected estimate.</a></li>
<li><a href='#print.cvauc'><p>Print results of cv_auc</p></a></li>
<li><a href='#print.scrnp'><p>Print results of cv_scrnp</p></a></li>
<li><a href='#randomforest_wrapper'><p>Wrapper for fitting a random forest using randomForest.</p></a></li>
<li><a href='#ranger_wrapper'><p>Wrapper for fitting a random forest using ranger.</p></a></li>
<li><a href='#stepglm_wrapper'><p>Wrapper for fitting a forward stepwise logistic regression using <code>glm</code>.</p></a></li>
<li><a href='#superlearner_wrapper'><p>Wrapper for fitting a super learner based on <code>SuperLearner</code>.</p></a></li>
<li><a href='#wine'><p>wine</p></a></li>
<li><a href='#xgboost_wrapper'><p>Wrapper for fitting eXtreme gradient boosting via <code>xgboost</code></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Estimators of Non-Linear Cross-Validated Risks Optimized for
Small Samples</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for obtaining improved estimates of non-linear cross-validated risks are obtained using targeted minimum loss-based estimation, estimating equations, and one-step estimation (Benkeser, Petersen, van der Laan (2019), &lt;<a href="https://doi.org/10.1080%2F01621459.2019.1668794">doi:10.1080/01621459.2019.1668794</a>&gt;). Cross-validated area under the receiver operating characteristics curve (LeDell, Petersen, van der Laan (2015), &lt;<a href="https://doi.org/10.1214%2F15-EJS1035">doi:10.1214/15-EJS1035</a>&gt;) and other metrics are included.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0), data.table</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, SuperLearner, cvAUC, ROCR, Rdpack, bde, np,
assertthat</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, prettydoc, randomForest, ranger,
xgboost, glmnet,</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-23 17:11:12 UTC; davidbenkeser</td>
</tr>
<tr>
<td>Author:</td>
<td>David Benkeser [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Benkeser &lt;benkeser@emory.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-23 17:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='.Dy'>Compute one of the terms of the efficient influence function</h2><span id='topic+.Dy'></span>

<h3>Description</h3>

<p>Compute one of the terms of the efficient influence function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.Dy(full_long_data, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".Dy_+3A_full_long_data">full_long_data</code></td>
<td>
<p>A long form data set</p>
</td></tr>
<tr><td><code id=".Dy_+3A_y">y</code></td>
<td>
<p>Which portion of the EIF to compute</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of one piece of EIF evaluated at estimates in <code>full_long_data</code>
</p>

<hr>
<h2 id='.estim_fn'>An estimating function for cvAUC</h2><span id='topic+.estim_fn'></span>

<h3>Description</h3>

<p>An estimating function for cvAUC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.estim_fn(auc = 0.5, prediction_list, gn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".estim_fn_+3A_auc">auc</code></td>
<td>
<p>The value of auc to find root for</p>
</td></tr>
<tr><td><code id=".estim_fn_+3A_prediction_list">prediction_list</code></td>
<td>
<p>Entry in prediction_list</p>
</td></tr>
<tr><td><code id=".estim_fn_+3A_gn">gn</code></td>
<td>
<p>Marginal probability of outcome</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value of the estimating function evaluated at current
<code>auc</code> estimate.
</p>

<hr>
<h2 id='.estim_fn_nested_cv'>An estimating function for cvAUC with initial estimates generated via 
nested cross-validation</h2><span id='topic+.estim_fn_nested_cv'></span>

<h3>Description</h3>

<p>An estimating function for cvAUC with initial estimates generated via 
nested cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.estim_fn_nested_cv(auc = 0.5, prediction_list, folds, gn, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".estim_fn_nested_cv_+3A_auc">auc</code></td>
<td>
<p>The value of auc to find root for</p>
</td></tr>
<tr><td><code id=".estim_fn_nested_cv_+3A_prediction_list">prediction_list</code></td>
<td>
<p>Entry in prediction_list</p>
</td></tr>
<tr><td><code id=".estim_fn_nested_cv_+3A_folds">folds</code></td>
<td>
<p>Cross-validation folds</p>
</td></tr>
<tr><td><code id=".estim_fn_nested_cv_+3A_gn">gn</code></td>
<td>
<p>Marginal probability of outcome</p>
</td></tr>
<tr><td><code id=".estim_fn_nested_cv_+3A_k">K</code></td>
<td>
<p>Number of CV folds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value of the estimating function evaluated at current
<code>auc</code> estimate.
</p>

<hr>
<h2 id='.get_auc'>Compute the AUC given the cdf and pdf of psi</h2><span id='topic+.get_auc'></span>

<h3>Description</h3>

<p>See <code>?.get_psi_distribution</code> to understand expected input format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_auc(dist_y0, dist_y1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_auc_+3A_dist_y0">dist_y0</code></td>
<td>
<p>Distribution of psi given Y = 0</p>
</td></tr>
<tr><td><code id=".get_auc_+3A_dist_y1">dist_y1</code></td>
<td>
<p>Distribution of psi given Y = 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value of AUC
</p>

<hr>
<h2 id='.get_cv_estim'>Helper function to turn prediction_list into CV estimate of SCRNP</h2><span id='topic+.get_cv_estim'></span>

<h3>Description</h3>

<p>Helper function to turn prediction_list into CV estimate of SCRNP
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_cv_estim(prediction_list, sens, gn, quantile_type = 8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_cv_estim_+3A_prediction_list">prediction_list</code></td>
<td>
<p>Properly formatted list of predictions.</p>
</td></tr>
<tr><td><code id=".get_cv_estim_+3A_sens">sens</code></td>
<td>
<p>The sensitivity constraint.</p>
</td></tr>
<tr><td><code id=".get_cv_estim_+3A_gn">gn</code></td>
<td>
<p>The marginal probability that <code>Y = 1</code>.</p>
</td></tr>
<tr><td><code id=".get_cv_estim_+3A_quantile_type">quantile_type</code></td>
<td>
<p>The type of quantile estimate to use.</p>
</td></tr>
<tr><td><code id=".get_cv_estim_+3A_...">...</code></td>
<td>
<p>Other options (not currently used)</p>
</td></tr>
</table>

<hr>
<h2 id='.get_density'>Function to estimate density needed to evaluate standard errors.</h2><span id='topic+.get_density'></span>

<h3>Description</h3>

<p>Function to estimate density needed to evaluate standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_density(
  x,
  c0,
  bounded_kernel = FALSE,
  x_name = "train_pred",
  y_name = "train_y",
  nested_cv = FALSE,
  prediction_list = NULL,
  folds = NULL,
  maxDens = 1000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_density_+3A_x">x</code></td>
<td>
<p>An entry in prediction_list.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_c0">c0</code></td>
<td>
<p>The point at which the density estimate is evaluated.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_bounded_kernel">bounded_kernel</code></td>
<td>
<p>Should a bounded kernel be used? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_x_name">x_name</code></td>
<td>
<p>Name of variable to compute density of.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_y_name">y_name</code></td>
<td>
<p>Name of variable to stratify density computation on.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_nested_cv">nested_cv</code></td>
<td>
<p>Use nested CV to estimate density?</p>
</td></tr>
<tr><td><code id=".get_density_+3A_prediction_list">prediction_list</code></td>
<td>
<p>Properly formatted list of predictions.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_folds">folds</code></td>
<td>
<p>Cross-validation fold assignments.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_maxdens">maxDens</code></td>
<td>
<p>The maximum allowed value for the density.</p>
</td></tr>
<tr><td><code id=".get_density_+3A_...">...</code></td>
<td>
<p>Other options (not currently used)</p>
</td></tr>
</table>

<hr>
<h2 id='.get_nested_cv_quantile'>Helper function to get quantile for a single training fold data 
when nested CV is used.</h2><span id='topic+.get_nested_cv_quantile'></span>

<h3>Description</h3>

<p>Helper function to get quantile for a single training fold data 
when nested CV is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_nested_cv_quantile(x, p, prediction_list, folds, quantile_type = 8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_nested_cv_quantile_+3A_x">x</code></td>
<td>
<p>An entry in prediction_list.</p>
</td></tr>
<tr><td><code id=".get_nested_cv_quantile_+3A_p">p</code></td>
<td>
<p>The quantile to get.</p>
</td></tr>
<tr><td><code id=".get_nested_cv_quantile_+3A_prediction_list">prediction_list</code></td>
<td>
<p>Properly formatted list of predictions.</p>
</td></tr>
<tr><td><code id=".get_nested_cv_quantile_+3A_folds">folds</code></td>
<td>
<p>Cross-validation fold assignments.</p>
</td></tr>
<tr><td><code id=".get_nested_cv_quantile_+3A_quantile_type">quantile_type</code></td>
<td>
<p>The type of quantile estimate to use.</p>
</td></tr>
</table>

<hr>
<h2 id='.get_one_fold'>Helper function to get results for a single cross-validation fold</h2><span id='topic+.get_one_fold'></span>

<h3>Description</h3>

<p>Helper function to get results for a single cross-validation fold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_one_fold(x, sens, gn, quantile_type = 8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_one_fold_+3A_x">x</code></td>
<td>
<p>An entry in prediction_list.</p>
</td></tr>
<tr><td><code id=".get_one_fold_+3A_sens">sens</code></td>
<td>
<p>The sensitivity constraint.</p>
</td></tr>
<tr><td><code id=".get_one_fold_+3A_gn">gn</code></td>
<td>
<p>An estimate of the marginal probability that <code>Y = 1</code>.</p>
</td></tr>
<tr><td><code id=".get_one_fold_+3A_quantile_type">quantile_type</code></td>
<td>
<p>The type of quantile estimate to use.</p>
</td></tr>
<tr><td><code id=".get_one_fold_+3A_...">...</code></td>
<td>
<p>Other options (not currently used)</p>
</td></tr>
</table>

<hr>
<h2 id='.get_predictions'>Worker function for fitting prediction functions (possibly in parallel)</h2><span id='topic+.get_predictions'></span>

<h3>Description</h3>

<p>Worker function for fitting prediction functions (possibly in parallel)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_predictions(
  learner,
  Y,
  X,
  K = 10,
  folds,
  parallel,
  nested_cv = FALSE,
  nested_K = K - 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_predictions_+3A_learner">learner</code></td>
<td>
<p>The wrapper to use</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_y">Y</code></td>
<td>
<p>The outcome</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_x">X</code></td>
<td>
<p>The predictors</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_k">K</code></td>
<td>
<p>The number of folds</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_folds">folds</code></td>
<td>
<p>Vector of CV fold assignments</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_parallel">parallel</code></td>
<td>
<p>Whether to compute things in parallel using future</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_nested_cv">nested_cv</code></td>
<td>
<p>Is nested CV being used?</p>
</td></tr>
<tr><td><code id=".get_predictions_+3A_nested_k">nested_K</code></td>
<td>
<p>How many folds of nested CV?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the result of the wrapper executed in each fold
</p>

<hr>
<h2 id='.get_psi_distribution'>Compute the conditional (given Y = y) estimated distribution of psi</h2><span id='topic+.get_psi_distribution'></span>

<h3>Description</h3>

<p>Compute the conditional (given Y = y) estimated distribution of psi
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_psi_distribution(x, y, epsilon = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_psi_distribution_+3A_x">x</code></td>
<td>
<p>An entry in the output from .get_predictions</p>
</td></tr>
<tr><td><code id=".get_psi_distribution_+3A_y">y</code></td>
<td>
<p>What value of Y to compute dist. est.</p>
</td></tr>
<tr><td><code id=".get_psi_distribution_+3A_epsilon">epsilon</code></td>
<td>
<p>A vector of estimated coefficients form tmle fluctuation 
submodels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the distribution of psi given Y = y with names
psix (what value estimates are evaluated at), dFn (density estimates),
Fn (cdf estimates)
</p>

<hr>
<h2 id='.get_psi_distribution_nested_cv'>Compute the conditional (given Y = y) CV-estimated distribution of psi</h2><span id='topic+.get_psi_distribution_nested_cv'></span>

<h3>Description</h3>

<p>Compute the conditional (given Y = y) CV-estimated distribution of psi
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_psi_distribution_nested_cv(x, y, prediction_list, folds, epsilon = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_psi_distribution_nested_cv_+3A_x">x</code></td>
<td>
<p>The outer validation fold withheld</p>
</td></tr>
<tr><td><code id=".get_psi_distribution_nested_cv_+3A_y">y</code></td>
<td>
<p>What value of Y to compute dist. est.</p>
</td></tr>
<tr><td><code id=".get_psi_distribution_nested_cv_+3A_prediction_list">prediction_list</code></td>
<td>
<p>List output from .get_predictions.</p>
</td></tr>
<tr><td><code id=".get_psi_distribution_nested_cv_+3A_folds">folds</code></td>
<td>
<p>Cross validation fold indicator.</p>
</td></tr>
<tr><td><code id=".get_psi_distribution_nested_cv_+3A_epsilon">epsilon</code></td>
<td>
<p>A vector of estimated coefficients form tmle fluctuation 
submodels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the distribution of psi given Y = y with names
psix (what value estimates are evaluated at), dFn (density estimates),
Fn (cdf estimates)
</p>

<hr>
<h2 id='.get_quantile'>Helper function to get quantile for a single training fold data 
when nested CV is NOT used.</h2><span id='topic+.get_quantile'></span>

<h3>Description</h3>

<p>Helper function to get quantile for a single training fold data 
when nested CV is NOT used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.get_quantile(x, p, quantile_type = 8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".get_quantile_+3A_x">x</code></td>
<td>
<p>An entry in prediction_list.</p>
</td></tr>
<tr><td><code id=".get_quantile_+3A_p">p</code></td>
<td>
<p>The quantile to get.</p>
</td></tr>
<tr><td><code id=".get_quantile_+3A_quantile_type">quantile_type</code></td>
<td>
<p>The type of quantile estimate to use.</p>
</td></tr>
</table>

<hr>
<h2 id='.make_long_data'>Worker function to make long form data set needed for
CVTMLE targeting step</h2><span id='topic+.make_long_data'></span>

<h3>Description</h3>

<p>Worker function to make long form data set needed for
CVTMLE targeting step
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.make_long_data(
  x,
  gn,
  update = FALSE,
  epsilon_0 = 0,
  epsilon_1 = 0,
  tol = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".make_long_data_+3A_x">x</code></td>
<td>
<p>An entry in the &quot;predictions list&quot; that has certain
named values (see <code>?.get_predictions</code>)</p>
</td></tr>
<tr><td><code id=".make_long_data_+3A_gn">gn</code></td>
<td>
<p>An estimate of the probability that <code>Y = 1</code>.</p>
</td></tr>
<tr><td><code id=".make_long_data_+3A_update">update</code></td>
<td>
<p>A boolean of whether this is called for initial
construction of the long data set or as part of the targeting loop. 
If the former, empirical &quot;density&quot; estimates are used. If the latter
these are derived from the targeted cdf.</p>
</td></tr>
<tr><td><code id=".make_long_data_+3A_epsilon_0">epsilon_0</code></td>
<td>
<p>If <code>update = TRUE</code>, a vector of TMLE fluctuation
parameter estimates used to add the CDF and PDF of Psi(X) to the data set.</p>
</td></tr>
<tr><td><code id=".make_long_data_+3A_epsilon_1">epsilon_1</code></td>
<td>
<p>Same as for <code>epsilon_0</code>.</p>
</td></tr>
<tr><td><code id=".make_long_data_+3A_tol">tol</code></td>
<td>
<p>A truncation level when taking logit transformations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A long form data list of a particular set up. Columns are named id 
(multiple rows per observation in validation sample), 
u (if Yi = 0, these are the values of psi(x) in the
training sample for obs with Y = 1, if Yi = 1, these are values of psi(x) in
the training sample for obs. with Y = 0), 
Yi (this observation's value of Y), Fn (estimated value of the cdf of psi(X) 
given Y = Yi in the training sample), 
dFn (estimated value of the density of psi(X) given Y = (1-Yi) in the 
training sample), psi (the value of this observations Psihat(P_n,B_n^0)),
gn (estimate of marginal of Y e.g., computed in whole sample), outcome (indicator
that psix &lt;= u), logit_Fn (the cdf estimate on the logit scale, needed for 
offset in targeting model).
</p>

<hr>
<h2 id='.make_long_data_nested_cv'>Worker function to make long form data set needed for
CVTMLE targeting step when nested cv is used</h2><span id='topic+.make_long_data_nested_cv'></span>

<h3>Description</h3>

<p>Worker function to make long form data set needed for
CVTMLE targeting step when nested cv is used
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.make_long_data_nested_cv(
  x,
  prediction_list,
  folds,
  gn,
  update = FALSE,
  epsilon_0 = 0,
  epsilon_1 = 0,
  tol = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".make_long_data_nested_cv_+3A_x">x</code></td>
<td>
<p>The outer validation fold</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_prediction_list">prediction_list</code></td>
<td>
<p>The full prediction list</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_folds">folds</code></td>
<td>
<p>Vector of CV folds</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_gn">gn</code></td>
<td>
<p>An estimate of the marginal dist. of Y</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_update">update</code></td>
<td>
<p>Boolean of whether this is called for initial
construction of the long data set or as part of the targeting loop. 
If the former, cross-validated empirical &quot;density&quot; estimates are used. 
If the latter these are derived from the targeted cdf.</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_epsilon_0">epsilon_0</code></td>
<td>
<p>If <code>update = TRUE</code>, a vector of TMLE fluctuation
parameter estimates used to add the CDF and PDF of Psi(X) to the data set</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_epsilon_1">epsilon_1</code></td>
<td>
<p>Ditto above</p>
</td></tr>
<tr><td><code id=".make_long_data_nested_cv_+3A_tol">tol</code></td>
<td>
<p>A truncation level when taking logit transformations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A long form data list of a particular set up. Columns are named id 
(multiple per obs. in validation sample), u (if Yi = 0, these are the unique 
values of psi(x) in the inner validation samples for psi fit on inner training
samples for obs with Y = 1, if Yi = 1, these are values of psi(x) in
the inner validation samples for psi fit on inner training samples for obs. 
with Y = 0), Yi (this id's value of Y), Fn (cross-validation estimated value 
of the cdf of psi(X) given Y = Yi in the training sample), 
dFn (cross-validated estimate of the density of psi(X) given Y = (1-Yi) in the 
training sample), psi (the value of this observations Psihat(P_n,B_n^0)),
gn (estimate of marginal of Y e.g., computed in whole sample), outcome (indicator
that psix &lt;= u), logit_Fn (the cdf estimate on the logit scale, needed for 
offset in targeting model).
</p>

<hr>
<h2 id='.make_targeting_data'>Helper function for making data set in proper format for CVTMLE</h2><span id='topic+.make_targeting_data'></span>

<h3>Description</h3>

<p>Helper function for making data set in proper format for CVTMLE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.make_targeting_data(
  x,
  prediction_list,
  quantile_list,
  density_list,
  folds,
  nested_cv = FALSE,
  gn
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".make_targeting_data_+3A_x">x</code></td>
<td>
<p>A numeric identifier of which entry in <code>prediction_list</code> to operate on.</p>
</td></tr>
<tr><td><code id=".make_targeting_data_+3A_prediction_list">prediction_list</code></td>
<td>
<p>Properly formatted list of predictions.</p>
</td></tr>
<tr><td><code id=".make_targeting_data_+3A_quantile_list">quantile_list</code></td>
<td>
<p>List of estimated quantile for each fold.</p>
</td></tr>
<tr><td><code id=".make_targeting_data_+3A_density_list">density_list</code></td>
<td>
<p>List of density estimates for each fold.</p>
</td></tr>
<tr><td><code id=".make_targeting_data_+3A_folds">folds</code></td>
<td>
<p>Cross-validation fold assignments.</p>
</td></tr>
<tr><td><code id=".make_targeting_data_+3A_nested_cv">nested_cv</code></td>
<td>
<p>A boolean indicating whether nested CV was used in estimation.</p>
</td></tr>
<tr><td><code id=".make_targeting_data_+3A_gn">gn</code></td>
<td>
<p>An estimate of the marginal probability that <code>Y = 1</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='.process_input'>Unexported function from cvAUC package</h2><span id='topic+.process_input'></span>

<h3>Description</h3>

<p>Unexported function from cvAUC package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.process_input(
  predictions,
  labels,
  label.ordering = NULL,
  folds = NULL,
  ids = NULL,
  confidence = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".process_input_+3A_predictions">predictions</code></td>
<td>
<p>A vector, matrix, list, or data frame containing the predictions.</p>
</td></tr>
<tr><td><code id=".process_input_+3A_labels">labels</code></td>
<td>
<p>A vector, matrix, list, or data frame containing the true class labels. Must have the 
same dimensions as <code>predictions</code>.</p>
</td></tr>
<tr><td><code id=".process_input_+3A_label.ordering">label.ordering</code></td>
<td>
<p>The default ordering of the classes can be changed by supplying 
a vector containing the negative and the positive class label (negative label first, 
positive label second).</p>
</td></tr>
<tr><td><code id=".process_input_+3A_folds">folds</code></td>
<td>
<p>If specified, this must be a vector of fold ids equal in length to <code>predictions</code> 
and <code>labels</code>, or a list of length V (for V-fold cross-validation) of vectors of indexes for 
the observations contained in each fold. The <code>folds</code> argument must only be specified if 
the <code>predictions</code> and <code>labels</code> arguments are vectors.</p>
</td></tr>
<tr><td><code id=".process_input_+3A_ids">ids</code></td>
<td>
<p>Vector of ids</p>
</td></tr>
<tr><td><code id=".process_input_+3A_confidence">confidence</code></td>
<td>
<p>confidence interval level</p>
</td></tr>
</table>

<hr>
<h2 id='adult'>adult</h2><span id='topic+adult'></span>

<h3>Description</h3>

<p>The &quot;Adult&quot; data set from UCI machine learning repository. Raw data have been processed
and an <code>outcome</code> column added.
</p>


<h3>Details</h3>

<p>Description (copied from UCI):
</p>
<p>Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE&gt;16) &amp;&amp; (AGI&gt;100) &amp;&amp; (AFNLWGT&gt;1)&amp;&amp; (HRSWK&gt;0)) 
</p>
<p>Prediction task is to determine whether a person makes over 50K a year (column <code>outcome</code>). 
</p>
<p>Listing of attributes: 
</p>
<p>&gt;50K, &lt;=50K 
</p>
<p>age: continuous. 
</p>
<p>workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. 
</p>
<p>fnlwgt: continuous. 
</p>
<p>education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. 
</p>
<p>education-num: continuous. 
</p>
<p>marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. 
</p>
<p>occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. 
</p>
<p>relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. 
</p>
<p>race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. 
</p>
<p>sex: Female, Male. 
</p>
<p>capital-gain: continuous. 
</p>
<p>capital-loss: continuous. 
</p>
<p>hours-per-week: continuous. 
</p>
<p>native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&amp;Tobago, Peru, Hong, Holand-Netherlands.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Adult">https://archive.ics.uci.edu/ml/datasets/Adult</a>
</p>


<h3>References</h3>

<p><a href="http://robotics.stanford.edu/~ronnyk/nbtree.pdf">http://robotics.stanford.edu/~ronnyk/nbtree.pdf</a>
</p>

<hr>
<h2 id='bank'>bank</h2><span id='topic+bank'></span>

<h3>Description</h3>

<p>Bank data from UCI Machine Learning Repository. The raw bank data have been processed
and an <code>outcome</code> column added.
</p>


<h3>Details</h3>

<p>Description (copied from UCI):
</p>
<p>The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. 
There are four datasets: 
</p>
<p>1) (included in <code>predtmle</code>) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]
</p>
<p>2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.
</p>
<p>3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). 
</p>
<p>4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). 
</p>
<p>The smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). 
The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).
</p>
<p>Attribute Information:
</p>
<p>Input variables:
</p>
<p># bank client data:
</p>
<p>1 - age (numeric)
</p>
<p>2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')
</p>
<p>3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
</p>
<p>4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')
</p>
<p>5 - default: has credit in default? (categorical: 'no','yes','unknown')
6 - housing: has housing loan? (categorical: 'no','yes','unknown')
</p>
<p>7 - loan: has personal loan? (categorical: 'no','yes','unknown')
</p>
<p># related with the last contact of the current campaign:
</p>
<p>8 - contact: contact communication type (categorical: 'cellular','telephone') 
</p>
<p>9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')
</p>
<p>10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')
</p>
<p>11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.
</p>
<p># other attributes:
</p>
<p>12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
</p>
<p>13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)
</p>
<p>14 - previous: number of contacts performed before this campaign and for this client (numeric)
</p>
<p>15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')
</p>
<p># social and economic context attributes
</p>
<p>16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)
</p>
<p>17 - cons.price.idx: consumer price index - monthly indicator (numeric) 
</p>
<p>18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric) 
</p>
<p>19 - euribor3m: euribor 3 month rate - daily indicator (numeric)
</p>
<p>20 - nr.employed: number of employees - quarterly indicator (numeric)
</p>
<p>Output variable (desired target):
</p>
<p>21 - y - has the client subscribed a term deposit? (binary: 'yes','no')
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">https://archive.ics.uci.edu/ml/datasets/Bank+Marketing</a>
</p>


<h3>References</h3>

<p>S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014
</p>

<hr>
<h2 id='boot_auc'>Compute the bootstrap-corrected estimator of AUC.</h2><span id='topic+boot_auc'></span>

<h3>Description</h3>

<p>This estimator is computed by re-sampling with replacement (i.e., bootstrap
sampling) from the data. The AUC is computed for the learner trained on the 
full data. The AUC is then computed for the learner trained on each bootstrap
sample. The average difference between the full data-trained learner and 
the bootstrap-trained learner is computed to estimate the bias in the full-data-estimated
AUC. The final estimate of AUC is given by the difference in the full-data AUC 
and the estimated bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_auc(Y, X, B = 500, learner = "glm_wrapper", correct632 = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot_auc_+3A_y">Y</code></td>
<td>
<p>A numeric vector of outcomes, assume to equal <code>0</code> or <code>1</code>.</p>
</td></tr>
<tr><td><code id="boot_auc_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="boot_auc_+3A_b">B</code></td>
<td>
<p>The number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="boot_auc_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm. See <code>?glm_wrapper</code> or read the package vignette
for more information on formatting <code>learner</code>s.</p>
</td></tr>
<tr><td><code id="boot_auc_+3A_correct632">correct632</code></td>
<td>
<p>A boolean indicating whether to use the .632 correction.</p>
</td></tr>
<tr><td><code id="boot_auc_+3A_...">...</code></td>
<td>
<p>Other options, not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with <code>$auc</code> as the bootstrap-corrected AUC estimate and 
<code>$n_valid_boot</code> as the number of bootstrap of bootstrap samples where <code>learner</code> 
successfully executed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
X &lt;- data.frame(x1 = rnorm(50))
Y &lt;- rbinom(50, 1, plogis(X$x1))
# compute lpo_auc for logistic regression 
# use small B for fast run
boot &lt;- boot_auc(Y = Y, X = X, B = 25, learner = "glm_wrapper")

</code></pre>

<hr>
<h2 id='boot_scrnp'>Compute the bootstrap-corrected estimator of SCRNP.</h2><span id='topic+boot_scrnp'></span>

<h3>Description</h3>

<p>This estimator is computed by re-sampling with replacement (i.e., bootstrap
sampling) from the data. The SCRNP is computed for the learner trained on the 
full data. The SCRNP is then computed for the learner trained on each bootstrap
sample. The average difference between the full data-trained learner and 
the bootstrap-trained learner is computed to estimate the bias in the full-data-estimated
SCRNP. The final estimate of SCRNP is given by the difference in the full-data SCRNP 
and the estimated bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot_scrnp(
  Y,
  X,
  B = 200,
  learner = "glm_wrapper",
  sens = 0.95,
  correct632 = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot_scrnp_+3A_y">Y</code></td>
<td>
<p>A numeric vector of outcomes, assume to equal <code>0</code> or <code>1</code>.</p>
</td></tr>
<tr><td><code id="boot_scrnp_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="boot_scrnp_+3A_b">B</code></td>
<td>
<p>The number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="boot_scrnp_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm. See <code>?glm_wrapper</code> or read the package vignette
for more information on formatting <code>learner</code>s.</p>
</td></tr>
<tr><td><code id="boot_scrnp_+3A_sens">sens</code></td>
<td>
<p>The sensitivity constraint to use.</p>
</td></tr>
<tr><td><code id="boot_scrnp_+3A_correct632">correct632</code></td>
<td>
<p>A boolean indicating whether to use the .632 correction.</p>
</td></tr>
<tr><td><code id="boot_scrnp_+3A_...">...</code></td>
<td>
<p>Other options, not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with <code>$scrnp</code> the bootstrap-corrected estimate of SCRNP and
<code>$n_valid_boot</code> as the number of bootstrap of bootstrap samples where <code>learner</code> 
successfully executed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
X &lt;- data.frame(x1 = rnorm(50))
Y &lt;- rbinom(50, 1, plogis(X$x1))
# compute bootstrap estimate of scrnp for logistic regression
# use small B for fast run
boot &lt;- boot_scrnp(Y = Y, X = X, B = 25, learner = "glm_wrapper")
</code></pre>

<hr>
<h2 id='cardio'>Cardiotocography</h2><span id='topic+cardio'></span>

<h3>Description</h3>

<p>Cardiotocography data from UCI machine learning repository. Raw data have been 
cleaned and an <code>outcome</code> column added that is a binary variable of predicting
NSP (described below) = 2.
</p>


<h3>Details</h3>

<p>Data Set Information:
2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. 
The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.
</p>
<p>Attribute Information:
</p>
<p>LB - FHR baseline (beats per minute) 
</p>
<p>AC - # of accelerations per second 
</p>
<p>FM - # of fetal movements per second 
</p>
<p>UC - # of uterine contractions per second 
</p>
<p>DL - # of light decelerations per second 
</p>
<p>DS - # of severe decelerations per second 
</p>
<p>DP - # of prolongued decelerations per second 
</p>
<p>ASTV - percentage of time with abnormal short term variability 
</p>
<p>MSTV - mean value of short term variability 
</p>
<p>ALTV - percentage of time with abnormal long term variability 
</p>
<p>MLTV - mean value of long term variability 
</p>
<p>Width - width of FHR histogram 
</p>
<p>Min - minimum of FHR histogram 
</p>
<p>Max - Maximum of FHR histogram 
</p>
<p>Nmax - # of histogram peaks 
</p>
<p>Nzeros - # of histogram zeros 
</p>
<p>Mode - histogram mode 
</p>
<p>Mean - histogram mean 
</p>
<p>Median - histogram median 
</p>
<p>Variance - histogram variance 
</p>
<p>Tendency - histogram tendency 
</p>
<p>CLASS - FHR pattern class code (1 to 10) 
</p>
<p>NSP - fetal state class code (N=normal; S=suspect; P=pathologic)
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Cardiotocography">https://archive.ics.uci.edu/ml/datasets/Cardiotocography</a>
</p>


<h3>References</h3>

<p>Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318
</p>

<hr>
<h2 id='ci.cvAUC_withIC'>ci.cvAUC_withIC</h2><span id='topic+ci.cvAUC_withIC'></span>

<h3>Description</h3>

<p>This function is nearly verbatim <a href="cvAUC.html#topic+ci.cvAUC">ci.cvAUC</a> from the cvAUC package. 
The only difference is that it additionally returns estimated influence functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.cvAUC_withIC(
  predictions,
  labels,
  label.ordering = NULL,
  folds = NULL,
  confidence = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.cvAUC_withIC_+3A_predictions">predictions</code></td>
<td>
<p>A vector, matrix, list, or data frame containing the predictions.</p>
</td></tr>
<tr><td><code id="ci.cvAUC_withIC_+3A_labels">labels</code></td>
<td>
<p>A vector, matrix, list, or data frame containing the true class labels. Must have the 
same dimensions as <code>predictions</code>.</p>
</td></tr>
<tr><td><code id="ci.cvAUC_withIC_+3A_label.ordering">label.ordering</code></td>
<td>
<p>The default ordering of the classes can be changed by supplying 
a vector containing the negative and the positive class label (negative label first, 
positive label second).</p>
</td></tr>
<tr><td><code id="ci.cvAUC_withIC_+3A_folds">folds</code></td>
<td>
<p>If specified, this must be a vector of fold ids equal in length to <code>predictions</code> 
and <code>labels</code>, or a list of length V (for V-fold cross-validation) of vectors of indexes for 
the observations contained in each fold. The <code>folds</code> argument must only be specified if 
the <code>predictions</code> and <code>labels</code> arguments are vectors.</p>
</td></tr>
<tr><td><code id="ci.cvAUC_withIC_+3A_confidence">confidence</code></td>
<td>
<p>number between 0 and 1 that represents confidence level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following named elements: 
</p>
<table>
<tr><td><code>cvAUC</code></td>
<td>
<p>Cross-validated area under the curve estimate.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Standard error.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>A vector of length two containing the upper and lower bounds for the confidence interval.</p>
</td></tr>
<tr><td><code>confidence</code></td>
<td>
<p>A number between 0 and 1 representing the confidence.</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>A vector of the influence function evaluated at observations.</p>
</td></tr>
</table>

<hr>
<h2 id='cv_auc'>Estimates of CVAUC</h2><span id='topic+cv_auc'></span>

<h3>Description</h3>

<p>This function computes K-fold cross-validated estimates of the area under
the receiver operating characteristics (ROC) curve (hereafter, AUC). This
quantity can be interpreted as the probability that a randomly selected 
case will have higher predicted risk than a randomly selected control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_auc(
  Y,
  X,
  K = 10,
  learner = "glm_wrapper",
  nested_cv = TRUE,
  nested_K = K - 1,
  parallel = FALSE,
  max_cvtmle_iter = 10,
  cvtmle_ictol = 1/length(Y),
  prediction_list = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_auc_+3A_y">Y</code></td>
<td>
<p>A numeric vector of outcomes, assume to equal <code>0</code> or <code>1</code>.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> or <code>matrix</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_k">K</code></td>
<td>
<p>The number of cross-validation folds (default is <code>10</code>).</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm. See See <code>?glm_wrapper</code> or read the package vignette
for more information on formatting <code>learner</code>s.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_nested_cv">nested_cv</code></td>
<td>
<p>A boolean indicating whether nested cross validation should
be used to estimate the distribution of the prediction function. Default (<code>TRUE</code>)
is best choice for aggressive <code>learner</code>'s, while <code>FALSE</code> is reasonable
for smooth <code>learner</code>'s (e.g., logistic regression).</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_nested_k">nested_K</code></td>
<td>
<p>If nested cross validation is used, how many inner folds should 
there be? Default (<code>K-1</code>) affords quicker computation by reusing training
fold learner fits.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_parallel">parallel</code></td>
<td>
<p>A boolean indicating whether prediction algorithms should be 
trained in parallel. Default to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_max_cvtmle_iter">max_cvtmle_iter</code></td>
<td>
<p>Maximum number of iterations for the bias correction
step of the CV-TMLE estimator (default <code>10</code>).</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_cvtmle_ictol">cvtmle_ictol</code></td>
<td>
<p>The CV-TMLE will iterate <code>max_cvtmle_iter</code> is reached 
or mean of cross-validated efficient influence function is less than 
<code>cvtmle_ictol</code>.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_prediction_list">prediction_list</code></td>
<td>
<p>For power users: a list of predictions made by <code>learner</code>
that has a format compatible with <code>cvauc</code>.</p>
</td></tr>
<tr><td><code id="cv_auc_+3A_...">...</code></td>
<td>
<p>Other arguments, not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To estimate the AUC of a particular prediction algorithm, K-fold cross-validation
is commonly used: data are partitioned into K distinct groups and the
prediction algorithm is developed using K-1 of these groups. In standard K-fold
cross-validation, the AUC of this prediction algorithm is estimated using
the remaining fold. This can be problematic when the number of observations is 
small or the number of cross-validation folds is large. 
</p>
<p>Here, we estimate relevant nuisance parameters in the training sample and use
the validation sample to perform some form of bias correction &ndash; either through
cross-validated targeted minimum loss-based estimation, estimating equations, 
or one-step estimation. When aggressive learning algorithms are applied, it is
necessary to use an additional layer of cross-validation in the training sample
to estimate the nuisance parameters. This is controlled via the <code>nested_cv</code>
option below.
</p>


<h3>Value</h3>

<p>An object of class <code>"cvauc"</code>. </p>

<dl>
<dt><code>est_cvtmle</code></dt><dd><p>cross-validated targeted minimum loss-based estimator of K-fold CV AUC</p>
</dd>
<dt><code>iter_cvtmle</code></dt><dd><p>iterations needed to achieve convergence of CVTMLE algorithm</p>
</dd>
<dt><code>cvtmle_trace</code></dt><dd><p>the value of the CVTMLE at each iteration of the targeting algorithm</p>
</dd>
<dt><code>se_cvtmle</code></dt><dd><p>estimated standard error based on targeted nuisance parameters</p>
</dd>
<dt><code>est_init</code></dt><dd><p>plug-in estimate of CV AUC where nuisance parameters are estimated
in the training sample</p>
</dd>
<dt><code>est_empirical</code></dt><dd><p>the standard K-fold CV AUC estimator</p>
</dd>
<dt><code>se_empirical</code></dt><dd><p>estimated standard error for the standard estimator</p>
</dd>
<dt><code>est_onestep</code></dt><dd><p>cross-validated one-step estimate of K-fold CV AUC</p>
</dd>
<dt><code>se_onestep</code></dt><dd><p>estimated standard error for the one-step estimator</p>
</dd>
<dt><code>est_esteq</code></dt><dd><p>cross-validated estimating equations estimate of K-fold CV AUC</p>
</dd>
<dt><code>se_esteq</code></dt><dd><p>estimated standard error for the estimating equations estimator 
(same as for one-step)</p>
</dd>
<dt><code>folds</code></dt><dd><p>list of observation indexes in each validation fold</p>
</dd>
<dt><code>ic_cvtmle</code></dt><dd><p>influence function evaluated at the targeted nuisance parameter
estimates</p>
</dd>
<dt><code>ic_onestep</code></dt><dd><p>influence function evaluated at the training-fold-estimated
nuisance parameters</p>
</dd>
<dt><code>ic_esteq</code></dt><dd><p>influence function evaluated at the training-fold-estimated 
nuisance parameters</p>
</dd>
<dt><code>ic_empirical</code></dt><dd><p>influence function evaluated at the validation-fold 
estimated nuisance parameters</p>
</dd>
<dt><code>prediction_list</code></dt><dd><p>a list of output from the cross-validated model training; 
see the individual wrapper function documentation for further details</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># simulate data
n &lt;- 200
p &lt;- 10
X &lt;- data.frame(matrix(rnorm(n*p), nrow = n, ncol = p))
Y &lt;- rbinom(n, 1, plogis(X[,1] + X[,10]))

# get cv auc estimates for logistic regression
cv_auc_ests &lt;- cv_auc(Y = Y, X = X, K = 5, learner = "glm_wrapper")

# get cv auc estimates for random forest
# using nested cross-validation for nuisance parameter estimation

fit &lt;- cv_auc(Y = Y, X = X, K = 5, 
              learner = "randomforest_wrapper", 
              nested_cv = TRUE)

</code></pre>

<hr>
<h2 id='cv_scrnp'>Estimates of CV SCNP</h2><span id='topic+cv_scrnp'></span>

<h3>Description</h3>

<p>This function computes K-fold cross-validated estimates of estimates of 
cross-validated sensitivity-constrained rate of negative prediction (SCRNP). This
quantity can be interpreted as the rate of negative classification for a fixed 
constraint on the sensitivity of a prediction algorithm. Thus, if an algorithm
has a high SCRNP, it will also have a high positive predictive value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_scrnp(
  Y,
  X,
  K = 10,
  sens = 0.95,
  learner = "glm_wrapper",
  nested_cv = TRUE,
  nested_K = K - 1,
  parallel = FALSE,
  max_cvtmle_iter = 10,
  cvtmle_ictol = 1/length(Y),
  quantile_type = 8,
  prediction_list = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_scrnp_+3A_y">Y</code></td>
<td>
<p>A numeric vector of outcomes, assume to equal <code>0</code> or <code>1</code>.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> or <code>matrix</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_k">K</code></td>
<td>
<p>The number of cross-validation folds (default is <code>10</code>).</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_sens">sens</code></td>
<td>
<p>The sensitivity constraint imposed on the rate of negative prediction
(see description).</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_nested_cv">nested_cv</code></td>
<td>
<p>A boolean indicating whether nested cross validation should
be used to estimate the distribution of the prediction function. Default (<code>TRUE</code>)
is best choice for aggressive <code>learner</code>'s, while <code>FALSE</code> is reasonable
for smooth <code>learner</code>'s (e.g., logistic regression).</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_nested_k">nested_K</code></td>
<td>
<p>If nested cross validation is used, how many inner folds should 
there be? Default (<code>K-1</code>) affords quicker computation by reusing training
fold learner fits.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_parallel">parallel</code></td>
<td>
<p>A boolean indicating whether prediction algorithms should be 
trained in parallel. Default to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_max_cvtmle_iter">max_cvtmle_iter</code></td>
<td>
<p>Maximum number of iterations for the bias correction
step of the CV-TMLE estimator (default <code>10</code>).</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_cvtmle_ictol">cvtmle_ictol</code></td>
<td>
<p>The CV-TMLE will iterate <code>max_cvtmle_iter</code> is reached 
or mean of cross-validated efficient influence function is less than 
<code>cvtmle_cvtmle_ictol</code>.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_quantile_type">quantile_type</code></td>
<td>
<p>Type of quantile estimator to be used. See <a href="stats.html#topic+quantile">quantile</a>
for description.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_prediction_list">prediction_list</code></td>
<td>
<p>For power users: a list of predictions made by <code>learner</code>
that has a format compatible with <code>cvauc</code>.</p>
</td></tr>
<tr><td><code id="cv_scrnp_+3A_...">...</code></td>
<td>
<p>Other arguments, not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To estimate the SCRNP using K-fold cross-validation is problematic. If 
data are partitioned into K distinct groups, depending on the sample size 
and choice of K, the validation sample may be quite small. In order to estimate 
SCRNP, we require estimation of a quantile of the predictor's distribution. More extreme
quantiles (which correspond to high sensitivity constraints) are difficult to estimate
using few observations. Here, we estimate relevant nuisance parameters in the training sample and use
the validation sample to perform some form of bias correction &ndash; either through
cross-validated targeted minimum loss-based estimation, estimating equations, 
or one-step estimation. When aggressive learning algorithms are applied, it is
necessary to use an additional layer of cross-validation in the training sample
to estimate the nuisance parameters. This is controlled via the <code>nested_cv</code>
option below.
</p>


<h3>Value</h3>

<p>An object of class <code>"scrnp"</code>. </p>

<dl>
<dt><code>est_cvtmle</code></dt><dd><p>cross-validated targeted minimum loss-based estimator of K-fold CV AUC</p>
</dd>
<dt><code>iter_cvtmle</code></dt><dd><p>iterations needed to achieve convergence of CVTMLE algorithm</p>
</dd>
<dt><code>cvtmle_trace</code></dt><dd><p>the value of the CVTMLE at each iteration of the targeting algorithm</p>
</dd>
<dt><code>se_cvtmle</code></dt><dd><p>estimated standard error based on targeted nuisance parameters</p>
</dd>
<dt><code>est_init</code></dt><dd><p>plug-in estimate of CV AUC where nuisance parameters are estimated
in the training sample</p>
</dd>
<dt><code>est_empirical</code></dt><dd><p>the standard K-fold CV AUC estimator</p>
</dd>
<dt><code>se_empirical</code></dt><dd><p>estimated standard error for the standard estimator</p>
</dd>
<dt><code>est_onestep</code></dt><dd><p>cross-validated one-step estimate of K-fold CV AUC</p>
</dd>
<dt><code>se_onestep</code></dt><dd><p>estimated standard error for the one-step estimator</p>
</dd>
<dt><code>est_esteq</code></dt><dd><p>cross-validated estimating equations estimate of K-fold CV AUC
(here, equivalent to one-step, since the estimating equation is linear in SCRNP)</p>
</dd>
<dt><code>se_esteq</code></dt><dd><p>estimated standard error for the estimating equations estimator 
(same as one-step)</p>
</dd>
<dt><code>folds</code></dt><dd><p>list of observation indexes in each validation fold</p>
</dd>
<dt><code>ic_cvtmle</code></dt><dd><p>influence function evaluated at the targeted nuisance parameter
estimates</p>
</dd>
<dt><code>ic_onestep</code></dt><dd><p>influence function evaluated at the training-fold-estimated
nuisance parameters</p>
</dd>
<dt><code>ic_esteq</code></dt><dd><p>influence function evaluated at the training-fold-estimated 
nuisance parameters</p>
</dd>
<dt><code>ic_empirical</code></dt><dd><p>influence function evaluated at the validation-fold 
estimated nuisance parameters</p>
</dd>
<dt><code>prediction_list</code></dt><dd><p>a list of output from the cross-validated model training; 
see the individual wrapper function documentation for further details</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># simulate data
n &lt;- 200
p &lt;- 10
X &lt;- data.frame(matrix(rnorm(n*p), nrow = n, ncol = p))
Y &lt;- rbinom(n, 1, plogis(X[,1] + X[,10]))

# estimate cv scrnp of logistic regression
scrnp_ests &lt;- cv_scrnp(Y = Y, X = X, K = 5, 
                       nested_cv = FALSE, 
                       learner = "glm_wrapper")

# estimate cv scrnp of random forest with nested 
# cross-validation for nuisance parameter estimation

scrnp_ests &lt;- cv_scrnp(Y = Y, X = X, K = 5, 
                       nested_cv = TRUE, 
                       learner = "randomforest_wrapper")

</code></pre>

<hr>
<h2 id='drugs'>drugs</h2><span id='topic+drugs'></span>

<h3>Description</h3>

<p>&quot;Drug consumption (quantified) Data Set&quot; from UCI Machine Learning Repository. 
Raw data have been processed and an <code>outcome</code> (heroin use) column added.
</p>


<h3>Details</h3>

<p>Data Set Information (copied from UCI library):
</p>
<p>Database contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day.
</p>
<p>Database contains 18 classification problems. Each of independent label variables contains seven classes: &quot;Never Used&quot;, &quot;Used over a Decade Ago&quot;, &quot;Used in Last Decade&quot;, &quot;Used in Last Year&quot;, &quot;Used in Last Month&quot;, &quot;Used in Last Week&quot;, and &quot;Used in Last Day&quot;.
</p>
<p>Problem which can be solved:
</p>
<p>* Seven class classifications for each drug separately.
</p>
<p>* Problem can be transformed to binary classification by union of part of classes into one new class. For example, &quot;Never Used&quot;, &quot;Used over a Decade Ago&quot; form class &quot;Non-user&quot; and all other classes form class &quot;User&quot;.
</p>
<p>* The best binarization of classes for each attribute.
</p>
<p>* Evaluation of risk to be drug consumer for each drug.
</p>
<p>Detailed description of database and process of data quantification are presented in E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, &quot;The Five Factor Model of personality and evaluation of drug consumption risk.,&quot; arXiv [Web Link], 2015
</p>
<p>Paper above solve binary classification problem for all drugs. For most of drugs sensitivity and specificity are greater than 75%.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29">https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29</a>
</p>


<h3>References</h3>

<p><a href="https://arxiv.org/abs/1506.06297">https://arxiv.org/abs/1506.06297</a>
</p>

<hr>
<h2 id='F_nBn_star'>Compute the targeted conditional cumulative distribution of the learner at a point</h2><span id='topic+F_nBn_star'></span>

<h3>Description</h3>

<p>Compute the targeted conditional cumulative distribution of the learner at a point
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F_nBn_star(psi_x, y, train_pred, train_y, epsilon = 0, tol = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F_nBn_star_+3A_psi_x">psi_x</code></td>
<td>
<p>Value to compute conditional (on Y=y) cdf of learner</p>
</td></tr>
<tr><td><code id="F_nBn_star_+3A_y">y</code></td>
<td>
<p>Value of Y to condition on</p>
</td></tr>
<tr><td><code id="F_nBn_star_+3A_train_pred">train_pred</code></td>
<td>
<p>Values of Psi_nBn(X) from training sample</p>
</td></tr>
<tr><td><code id="F_nBn_star_+3A_train_y">train_y</code></td>
<td>
<p>Values of Y from training sample</p>
</td></tr>
<tr><td><code id="F_nBn_star_+3A_epsilon">epsilon</code></td>
<td>
<p>Vector of fluctuation parameter estimates</p>
</td></tr>
<tr><td><code id="F_nBn_star_+3A_tol">tol</code></td>
<td>
<p>Truncation level for logistic transformation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value of CDF at <code>psi_x</code>
</p>

<hr>
<h2 id='F_nBn_star_nested_cv'>Compute the targeted conditional cumulative distribution of the learner at a point
where the initial distribution is based on cross validation</h2><span id='topic+F_nBn_star_nested_cv'></span>

<h3>Description</h3>

<p>Compute the targeted conditional cumulative distribution of the learner at a point
where the initial distribution is based on cross validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F_nBn_star_nested_cv(
  psi_x,
  y,
  inner_valid_prediction_and_y_list,
  epsilon = 0,
  tol = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F_nBn_star_nested_cv_+3A_psi_x">psi_x</code></td>
<td>
<p>Value to compute conditional (on Y=y) cdf of learner</p>
</td></tr>
<tr><td><code id="F_nBn_star_nested_cv_+3A_y">y</code></td>
<td>
<p>Value of Y to condition on</p>
</td></tr>
<tr><td><code id="F_nBn_star_nested_cv_+3A_inner_valid_prediction_and_y_list">inner_valid_prediction_and_y_list</code></td>
<td>
<p>A list of predictions and y's from <code>.get_predictions</code>.</p>
</td></tr>
<tr><td><code id="F_nBn_star_nested_cv_+3A_epsilon">epsilon</code></td>
<td>
<p>Vector of fluctuation parameter estimates</p>
</td></tr>
<tr><td><code id="F_nBn_star_nested_cv_+3A_tol">tol</code></td>
<td>
<p>A truncation level when taking logit transformations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value of CDF at <code>psi_x</code>
</p>

<hr>
<h2 id='fluc_mod_optim_0'>Helper function for CVTMLE grid search</h2><span id='topic+fluc_mod_optim_0'></span>

<h3>Description</h3>

<p>Helper function for CVTMLE grid search
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fluc_mod_optim_0(epsilon, fld, tol = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fluc_mod_optim_0_+3A_epsilon">epsilon</code></td>
<td>
<p>Fluctuation parameter</p>
</td></tr>
<tr><td><code id="fluc_mod_optim_0_+3A_fld">fld</code></td>
<td>
<p>The <code>full_long_data_list</code> object created</p>
</td></tr>
<tr><td><code id="fluc_mod_optim_0_+3A_tol">tol</code></td>
<td>
<p>Tolerance on predictions close to 0 or 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value of negative log-likelihood
</p>

<hr>
<h2 id='fluc_mod_optim_1'>Helper function for CVTMLE grid search</h2><span id='topic+fluc_mod_optim_1'></span>

<h3>Description</h3>

<p>Helper function for CVTMLE grid search
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fluc_mod_optim_1(epsilon, fld, tol = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fluc_mod_optim_1_+3A_epsilon">epsilon</code></td>
<td>
<p>Fluctuation parameter</p>
</td></tr>
<tr><td><code id="fluc_mod_optim_1_+3A_fld">fld</code></td>
<td>
<p>full_long_data_list</p>
</td></tr>
<tr><td><code id="fluc_mod_optim_1_+3A_tol">tol</code></td>
<td>
<p>Tolerance on predictions close to 0 or 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value of negative log-likelihood
</p>

<hr>
<h2 id='glm_wrapper'>Wrapper for fitting a logistic regression using <code>glm</code>.</h2><span id='topic+glm_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm_wrapper(train, test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="glm_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements a logistic regression using <a href="stats.html#topic+glm">glm</a>. 
We refer readers to the original package's documentation for more
details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit glm
glm_wrap &lt;- glm_wrapper(train = train, test = test)
</code></pre>

<hr>
<h2 id='glmnet_wrapper'>Wrapper for fitting a lasso using package <code>glmnet</code>.</h2><span id='topic+glmnet_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmnet_wrapper(
  train,
  test,
  alpha = 1,
  nfolds = 5,
  nlambda = 100,
  use_min = TRUE,
  loss = "deviance",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmnet_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_alpha">alpha</code></td>
<td>
<p>See <a href="glmnet.html#topic+glmnet">glmnet</a> for further description.</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_nfolds">nfolds</code></td>
<td>
<p>See <a href="glmnet.html#topic+glmnet">glmnet</a> for further description.</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_nlambda">nlambda</code></td>
<td>
<p>See <a href="glmnet.html#topic+glmnet">glmnet</a> for further description.</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_use_min">use_min</code></td>
<td>
<p>See <a href="glmnet.html#topic+glmnet">glmnet</a> for further description.</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_loss">loss</code></td>
<td>
<p>See <a href="glmnet.html#topic+glmnet">glmnet</a> for further description.</p>
</td></tr>
<tr><td><code id="glmnet_wrapper_+3A_...">...</code></td>
<td>
<p>Other options (passed to <code>cv.glmnet</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements <a href="glmnet.html#topic+glmnet">glmnet</a>. We refer readers to the 
original package's documentation for more
details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load super learner package
library(glmnet)
# simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50), x2 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50), x2 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit super learner 
glmnet_wrap &lt;- glmnet_wrapper(train = train, test = test)
</code></pre>

<hr>
<h2 id='lpo_auc'>Compute the leave-pair-out cross-validation estimator of AUC.</h2><span id='topic+lpo_auc'></span>

<h3>Description</h3>

<p>This estimator is computed by leaving out a pair of one case (<code>Y = 1</code>) and
one control (<code>Y = 0</code>). The learner is trained on the remaining observations
and predicted values are obtained for the left-out pair. The estimate is given by
the proportion of left-out pairs for which the case had higher predicted risk
than the control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpo_auc(Y, X, learner = "glm_wrapper", max_pairs = NULL, parallel = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpo_auc_+3A_y">Y</code></td>
<td>
<p>A numeric vector of outcomes, assume to equal <code>0</code> or <code>1</code>.</p>
</td></tr>
<tr><td><code id="lpo_auc_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="lpo_auc_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm. See <code>?glm_wrapper</code> or read the package vignette
for more information on formatting <code>learner</code>s.</p>
</td></tr>
<tr><td><code id="lpo_auc_+3A_max_pairs">max_pairs</code></td>
<td>
<p>The maximum number of pairs to leave out.</p>
</td></tr>
<tr><td><code id="lpo_auc_+3A_parallel">parallel</code></td>
<td>
<p>A boolean indicating whether prediction algorithms should be 
trained in parallel. Default to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lpo_auc_+3A_...">...</code></td>
<td>
<p>Other options (not currently used)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
X &lt;- data.frame(x1 = rnorm(50))
Y &lt;- rbinom(50, 1, plogis(X$x1))
# compute lpo_auc for logistic regression
lpo &lt;- lpo_auc(Y = Y, X = X, learner = "glm_wrapper")

</code></pre>

<hr>
<h2 id='one_boot_auc'>Internal function used to perform one bootstrap sample. The function
<code>try</code>s to fit <code>learner</code> on a bootstrap sample. If for some reason
(e.g., the bootstrap sample contains no observations with <code>Y = 1</code>) 
the learner fails, then the function returns <code>NA</code>. These <code>NA</code>s 
are ignored later when computing the bootstrap corrected estimate.</h2><span id='topic+one_boot_auc'></span>

<h3>Description</h3>

<p>Internal function used to perform one bootstrap sample. The function
<code>try</code>s to fit <code>learner</code> on a bootstrap sample. If for some reason
(e.g., the bootstrap sample contains no observations with <code>Y = 1</code>) 
the learner fails, then the function returns <code>NA</code>. These <code>NA</code>s 
are ignored later when computing the bootstrap corrected estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one_boot_auc(Y, X, n, correct632, learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="one_boot_auc_+3A_y">Y</code></td>
<td>
<p>A numeric binary outcome</p>
</td></tr>
<tr><td><code id="one_boot_auc_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="one_boot_auc_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="one_boot_auc_+3A_correct632">correct632</code></td>
<td>
<p>A boolean indicating whether to use the .632 correction.</p>
</td></tr>
<tr><td><code id="one_boot_auc_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm. See <code>?glm_wrapper</code> or read the package vignette
for more information on formatting <code>learner</code>s.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>learner</code> executes successfully, a numeric estimate of AUC
on this bootstrap sample. Otherwise the function returns <code>NA</code>.
</p>

<hr>
<h2 id='one_boot_scrnp'>Internal function used to perform one bootstrap sample. The function
<code>try</code>s to fit <code>learner</code> on a bootstrap sample. If for some reason
(e.g., the bootstrap sample contains no observations with <code>Y = 1</code>) 
the learner fails, then the function returns <code>NA</code>. These <code>NA</code>s 
are ignored later when computing the bootstrap corrected estimate.</h2><span id='topic+one_boot_scrnp'></span>

<h3>Description</h3>

<p>Internal function used to perform one bootstrap sample. The function
<code>try</code>s to fit <code>learner</code> on a bootstrap sample. If for some reason
(e.g., the bootstrap sample contains no observations with <code>Y = 1</code>) 
the learner fails, then the function returns <code>NA</code>. These <code>NA</code>s 
are ignored later when computing the bootstrap corrected estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one_boot_scrnp(Y, X, n, correct632, learner, sens)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="one_boot_scrnp_+3A_y">Y</code></td>
<td>
<p>A numeric binary outcome</p>
</td></tr>
<tr><td><code id="one_boot_scrnp_+3A_x">X</code></td>
<td>
<p>A <code>data.frame</code> of variables for prediction.</p>
</td></tr>
<tr><td><code id="one_boot_scrnp_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="one_boot_scrnp_+3A_correct632">correct632</code></td>
<td>
<p>A boolean indicating whether to use the .632 correction.</p>
</td></tr>
<tr><td><code id="one_boot_scrnp_+3A_learner">learner</code></td>
<td>
<p>A wrapper that implements the desired method for building a 
prediction algorithm. See <code>?glm_wrapper</code> or read the package vignette
for more information on formatting <code>learner</code>s.</p>
</td></tr>
<tr><td><code id="one_boot_scrnp_+3A_sens">sens</code></td>
<td>
<p>The sensitivity constraint to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>learner</code> executes successfully, a numeric estimate of AUC
on this bootstrap sample. Otherwise the function returns <code>NA</code>.
</p>

<hr>
<h2 id='print.cvauc'>Print results of cv_auc</h2><span id='topic+print.cvauc'></span>

<h3>Description</h3>

<p>Print results of cv_auc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cvauc'
print(x, ci_level = 0.95, se_type = "std", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cvauc_+3A_x">x</code></td>
<td>
<p>An object of class &quot;cvauc&quot;</p>
</td></tr>
<tr><td><code id="print.cvauc_+3A_ci_level">ci_level</code></td>
<td>
<p>Level of confidence interval to print. Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="print.cvauc_+3A_se_type">se_type</code></td>
<td>
<p>The type of standard error (currently only &quot;std&quot;)</p>
</td></tr>
<tr><td><code id="print.cvauc_+3A_...">...</code></td>
<td>
<p>Other options (not currently used)</p>
</td></tr>
</table>

<hr>
<h2 id='print.scrnp'>Print results of cv_scrnp</h2><span id='topic+print.scrnp'></span>

<h3>Description</h3>

<p>Print results of cv_scrnp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'scrnp'
print(x, se_type = "std", ci_level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.scrnp_+3A_x">x</code></td>
<td>
<p>An object of class &quot;cvauc&quot;</p>
</td></tr>
<tr><td><code id="print.scrnp_+3A_se_type">se_type</code></td>
<td>
<p>The type of standard error (currently only &quot;std&quot;)</p>
</td></tr>
<tr><td><code id="print.scrnp_+3A_ci_level">ci_level</code></td>
<td>
<p>Level of confidence interval to print. Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="print.scrnp_+3A_...">...</code></td>
<td>
<p>Other options (not currently used)</p>
</td></tr>
</table>

<hr>
<h2 id='randomforest_wrapper'>Wrapper for fitting a random forest using <a href="randomForest.html#topic+randomForest">randomForest</a>.</h2><span id='topic+randomforest_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomforest_wrapper(
  train,
  test,
  mtry = floor(sqrt(ncol(train$X))),
  ntree = 1000,
  nodesize = 1,
  maxnodes = NULL,
  importance = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randomforest_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_mtry">mtry</code></td>
<td>
<p>See <a href="randomForest.html#topic+randomForest">randomForest</a>.</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_ntree">ntree</code></td>
<td>
<p>See <a href="randomForest.html#topic+randomForest">randomForest</a>.</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_nodesize">nodesize</code></td>
<td>
<p>See <a href="randomForest.html#topic+randomForest">randomForest</a>.</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_maxnodes">maxnodes</code></td>
<td>
<p>See <a href="randomForest.html#topic+randomForest">randomForest</a>.</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_importance">importance</code></td>
<td>
<p>See <a href="randomForest.html#topic+randomForest">randomForest</a>.</p>
</td></tr>
<tr><td><code id="randomforest_wrapper_+3A_...">...</code></td>
<td>
<p>Other options (passed to <code>randomForest</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements the <a href="randomForest.html#topic+randomForest">randomForest</a> ensemble
methodology. We refer readers to the original package's documentation for more
details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit randomforest 
rf_wrap &lt;- randomforest_wrapper(train = train, test = test)
</code></pre>

<hr>
<h2 id='ranger_wrapper'>Wrapper for fitting a random forest using <a href="ranger.html#topic+ranger">ranger</a>.</h2><span id='topic+ranger_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranger_wrapper(
  train,
  test,
  num.trees = 500,
  mtry = floor(sqrt(ncol(train$X))),
  write.forest = TRUE,
  probability = TRUE,
  min.node.size = 5,
  replace = TRUE,
  sample.fraction = ifelse(replace, 1, 0.632),
  num.threads = 1,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ranger_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_num.trees">num.trees</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_mtry">mtry</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_write.forest">write.forest</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_probability">probability</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_min.node.size">min.node.size</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_replace">replace</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_sample.fraction">sample.fraction</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_num.threads">num.threads</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_verbose">verbose</code></td>
<td>
<p>See <a href="ranger.html#topic+ranger">ranger</a>.</p>
</td></tr>
<tr><td><code id="ranger_wrapper_+3A_...">...</code></td>
<td>
<p>Other options (passed to <code>ranger</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements the <a href="ranger.html#topic+ranger">ranger</a> ensemble
methodology. We refer readers to the original package's documentation for more
details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit ranger
rf_wrap &lt;- ranger_wrapper(train = train, test = test)
</code></pre>

<hr>
<h2 id='stepglm_wrapper'>Wrapper for fitting a forward stepwise logistic regression using <code>glm</code>.</h2><span id='topic+stepglm_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepglm_wrapper(train, test)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepglm_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="stepglm_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements a forward stepwise logistic regression using 
<a href="stats.html#topic+glm">glm</a> and <a href="stats.html#topic+step">step</a>. We refer readers to the original package's 
documentation for more details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit stepwise glm
step_wrap &lt;- stepglm_wrapper(train = train, test = test)
</code></pre>

<hr>
<h2 id='superlearner_wrapper'>Wrapper for fitting a super learner based on <code>SuperLearner</code>.</h2><span id='topic+superlearner_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>superlearner_wrapper(train, test, SL.library = c("SL.mean"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="superlearner_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="superlearner_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="superlearner_wrapper_+3A_sl.library">SL.library</code></td>
<td>
<p><code>SuperLearner</code> library. See <a href="SuperLearner.html#topic+SuperLearner">SuperLearner</a> 
for further description.</p>
</td></tr>
<tr><td><code id="superlearner_wrapper_+3A_...">...</code></td>
<td>
<p>Other options (passed to <code>SuperLearner</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements the <a href="SuperLearner.html#topic+SuperLearner">SuperLearner</a> ensemble
methodology. We refer readers to the original package's documentation for more
details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load super learner package
library(SuperLearner)
# simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit super learner 
sl_wrap &lt;- superlearner_wrapper(train = train, 
                                test = test, 
                                SL.library = c("SL.mean","SL.glm"))
</code></pre>

<hr>
<h2 id='wine'>wine</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>&quot;Wine Quality&quot; data set from UCI Machine Learning Repository. The red and white wine data sets
have been combined with an added attribute for red vs. white.
</p>


<h3>Details</h3>

<p>Data Set Information (copied from UCI):
</p>
<p>The two datasets are related to red and white variants of the Portuguese &quot;Vinho Verde&quot; wine. For more details, consult: [Web Link] or the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.). 
</p>
<p>These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are munch more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods. 
</p>
<p>Attribute Information:
</p>
<p>For more information, read [Cortez et al., 2009]. 
</p>
<p>Input variables (based on physicochemical tests): 
</p>
<p>1 - fixed acidity 
</p>
<p>2 - volatile acidity 
</p>
<p>3 - citric acid 
</p>
<p>4 - residual sugar 
</p>
<p>5 - chlorides 
</p>
<p>6 - free sulfur dioxide 
</p>
<p>7 - total sulfur dioxide 
</p>
<p>8 - density 
</p>
<p>9 - pH 
</p>
<p>10 - sulphates 
</p>
<p>11 - alcohol 
</p>
<p>Output variable (based on sensory data): 
</p>
<p>12 - quality (score between 0 and 10)
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality">https://archive.ics.uci.edu/ml/datasets/Wine+Quality</a>
</p>


<h3>References</h3>

<p>P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
</p>
<p><a href="https://doi.org/10.1016/j.dss.2009.05.016">https://doi.org/10.1016/j.dss.2009.05.016</a>
</p>

<hr>
<h2 id='xgboost_wrapper'>Wrapper for fitting eXtreme gradient boosting via <code>xgboost</code></h2><span id='topic+xgboost_wrapper'></span>

<h3>Description</h3>

<p>Compatible learner wrappers for this package should have a specific format.
Namely they should take as input a list called <code>train</code> that contains
named objects <code>$Y</code> and <code>$X</code>, that contain, respectively, the outcomes
and predictors in a particular training fold. Other options may be passed in
to the function as well. The function must output a list with the following
named objects: <code>test_pred</code> = predictions of <code>test$Y</code> based on the learner
fit using <code>train$X</code>; <code>train_pred</code> = prediction of <code>train$Y</code> based 
on the learner fit using <code>train$X</code>; <code>model</code> = the fitted model (only 
necessary if you desire to look at this model later, not used for internal 
computations); <code>train_y</code> = a copy of <code>train$Y</code>; <code>test_y</code> = a copy
of <code>test$Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xgboost_wrapper(
  test,
  train,
  ntrees = 500,
  max_depth = 4,
  shrinkage = 0.1,
  minobspernode = 2,
  params = list(),
  nthread = 1,
  verbose = 0,
  save_period = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xgboost_wrapper_+3A_test">test</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_train">train</code></td>
<td>
<p>A list with named objects <code>Y</code> and <code>X</code> (see description).</p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_ntrees">ntrees</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_max_depth">max_depth</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_shrinkage">shrinkage</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_minobspernode">minobspernode</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_params">params</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_nthread">nthread</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_verbose">verbose</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
<tr><td><code id="xgboost_wrapper_+3A_save_period">save_period</code></td>
<td>
<p>See <a href="xgboost.html#topic+xgboost">xgboost</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This particular wrapper implements eXtreme gradient boosting using 
<a href="xgboost.html#topic+xgboost">xgboost</a>. We refer readers to the original package's 
documentation for more details.
</p>


<h3>Value</h3>

<p>A list with named objects (see description).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate data
# make list of training data
train_X &lt;- data.frame(x1 = runif(50))
train_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
train &lt;- list(Y = train_Y, X = train_X)
# make list of test data
test_X &lt;- data.frame(x1 = runif(50))
test_Y &lt;- rbinom(50, 1, plogis(train_X$x1))
test &lt;- list(Y = test_Y, X = test_X)
# fit xgboost
xgb_wrap &lt;- xgboost_wrapper(train = train, test = test)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
