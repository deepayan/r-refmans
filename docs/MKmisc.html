<!DOCTYPE html><html><head><title>Help for package MKmisc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MKmisc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MKmisc-package'>
<p>Miscellaneous Functions from M. Kohl.</p></a></li>
<li><a href='#AUC'><p> Compute AUC</p></a></li>
<li><a href='#AUC.test'>
<p>AUC-Test</p></a></li>
<li><a href='#binomCI'><p> Confidence Intervals for Binomial Proportions</p></a></li>
<li><a href='#corDist'><p> Correlation Distance Matrix Computation</p></a></li>
<li><a href='#corPlot'><p> Plot of similarity matrix based on correlation</p></a></li>
<li><a href='#CV'><p> Compute CV</p></a></li>
<li><a href='#cvCI'><p> Confidence Intervals for Coefficient of Variation</p></a></li>
<li><a href='#fiveNS'><p> Five-Number Summaries</p></a></li>
<li><a href='#glog'><p> Compute Generalized Logarithm</p></a></li>
<li><a href='#heatmapCol'><p> Generate colors for heatmaps</p></a></li>
<li><a href='#HLgof.test'>
<p>Hosmer-Lemeshow goodness of fit tests.</p></a></li>
<li><a href='#hsu.t.test'><p>Hsu Two-Sample t-Test</p></a></li>
<li><a href='#imputeSD'><p> Impute Standard Deviations for Changes from Baseline</p></a></li>
<li><a href='#IQrange'><p>The Interquartile Range</p></a></li>
<li><a href='#madMatrix'><p> Compute MAD between colums of a matrix or data.frame</p></a></li>
<li><a href='#madPlot'><p> Plot of similarity matrix based on MAD</p></a></li>
<li><a href='#meanAD'><p>The Mean Absolute Deviation</p></a></li>
<li><a href='#melt.long'><p> Transform data.frame to Long Form</p></a></li>
<li><a href='#mi.t.test'><p>Multiple Imputation Student's t-Test</p></a></li>
<li><a href='#mod.oneway.test'><p>Moderated 1-Way ANOVA</p></a></li>
<li><a href='#mod.t.test'><p>Moderated t-Test</p></a></li>
<li><a href='#normCI'><p> Confidence Intervals for Mean and Standard Deviation</p></a></li>
<li><a href='#normDiffCI'><p> Confidence Intervals for Difference of Means</p></a></li>
<li><a href='#oneWayAnova'><p> A function for Analysis of Variance</p></a></li>
<li><a href='#optCutoff'><p> Compute the Optimal Cutoff for Binary Classification</p></a></li>
<li><a href='#or2rr'><p> Transform OR to RR</p></a></li>
<li><a href='#pairwise.auc'><p> Compute pairwise AUCs</p></a></li>
<li><a href='#pairwise.fc'><p> Compute pairwise fold changes</p></a></li>
<li><a href='#pairwise.fun'><p> Compute pairwise values for a given function</p></a></li>
<li><a href='#pairwise.logfc'><p> Compute pairwise log-fold changes</p></a></li>
<li><a href='#pairwise.mod.t.test'><p>Pairwise Moderated t-Tests</p></a></li>
<li><a href='#perfMeasures'><p> Compute Performance Measures and Scores for Binary Classification</p></a></li>
<li><a href='#power.diagnostic.test'><p>Power calculations for a diagnostic test</p></a></li>
<li><a href='#power.hsu.t.test'><p>Power calculations for two sample Hsu t test</p></a></li>
<li><a href='#power.nb.test'><p>Power calculation for comparing two negative binomial rates</p></a></li>
<li><a href='#power.welch.t.test'><p>Power calculations for two sample Welch t test</p></a></li>
<li><a href='#predValues'><p> Compute PPV and NPV.</p></a></li>
<li><a href='#print.confint'><p>Print Method for Confidence Intervals</p></a></li>
<li><a href='#qboxplot'><p> Box Plots</p></a></li>
<li><a href='#qbxp.stats'><p> Box Plot Statistics</p></a></li>
<li><a href='#quantileCI'><p> Confidence Intervals for Quantiles</p></a></li>
<li><a href='#repMeans'><p> Compute mean of replicated spots</p></a></li>
<li><a href='#risks'><p> Compute RR, OR, etc.</p></a></li>
<li><a href='#rrCI'><p> Compute Approximate Confidence Interval for RR.</p></a></li>
<li><a href='#simCorVars'><p> Simulate correlated variables.</p></a></li>
<li><a href='#simPlot'><p> Plot of a similarity matrix.</p></a></li>
<li><a href='#SNR'><p> Compute SNR</p></a></li>
<li><a href='#ssize.pcc'><p>Sample Size Planning for Developing Classifiers Using High Dimensional Data</p></a></li>
<li><a href='#stringDist'><p>Function to compute distances between strings</p></a></li>
<li><a href='#stringSim'><p>Function to compute similarity scores between strings</p></a></li>
<li><a href='#thyroid'><p> Plot TSH, fT3 and fT4 with respect to reference range.</p></a></li>
<li><a href='#traceBack'>
<p>Function to trace back</p></a></li>
<li><a href='#transformations'><p> New Transformations for Use with ggplot2 Package</p></a></li>
<li><a href='#twoWayAnova'><p> A function for Analysis of Variance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.9</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-11-19</td>
</tr>
<tr>
<td>Title:</td>
<td>Miscellaneous Functions from M. Kohl</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthias Kohl <a href="https://orcid.org/0000-0001-9514-8910"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthias Kohl &lt;Matthias.Kohl@stamats.de&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, graphics, grDevices, RColorBrewer, robustbase,
ggplot2, scales, limma</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gplots, Amelia, knitr, rmarkdown, exactRankTests, foreach,
parallel, doParallel</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains several functions for statistical data analysis; e.g. for sample size and power calculations, computation of confidence intervals and tests, and generation of similarity matrices.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/stamats/MKmisc">https://github.com/stamats/MKmisc</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-19 15:53:03 UTC; kohlm</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-19 19:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='MKmisc-package'>
Miscellaneous Functions from M. Kohl.
</h2><span id='topic+MKmisc-package'></span><span id='topic+MKmisc'></span>

<h3>Description</h3>

<p>Contains several functions for statistical data analysis; e.g. for sample size
and power calculations, computation of confidence intervals, and generation of
similarity matrices.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> MKmisc</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.9</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2022-11-19</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R(&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> stats, utils, graphics, grDevices, RColorBrewer, robustbase, ggplot2, scales, limma</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> gplots, Amelia, knitr, rmarkdown, exactRankTests, foreach, parallel, doParallel</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> LGPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> https://github.com/stamats/MKmisc</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>library(MKmisc)
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="https://www.stamats.de">https://www.stamats.de</a>
</p>
<p>Maintainer: Matthias Kohl  <a href="mailto:matthias.kohl@stamats.de">matthias.kohl@stamats.de</a></p>

<hr>
<h2 id='AUC'> Compute AUC </h2><span id='topic+AUC'></span>

<h3>Description</h3>

<p>The function computes AUC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC(x, y, group, switchAUC = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="AUC_+3A_y">y</code></td>
<td>
<p> numeric vector. If missing, <code>group</code> has to be specified.</p>
</td></tr>
<tr><td><code id="AUC_+3A_group">group</code></td>
<td>
<p> grouping vector or factor. </p>
</td></tr>
<tr><td><code id="AUC_+3A_switchauc">switchAUC</code></td>
<td>
<p>logical value. Switch AUC; see Details section.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the area under the receiver operating 
characteristic curve (AUC under ROC curve). 
</p>
<p>If <code>AUC &lt; 0.5</code>, a warning is printed and <code>1-AUC</code> is returned. This 
behaviour can be suppressed by using <code>switchAUC = FALSE</code>
</p>
<p>The implementation uses the connection of AUC to the Wilcoxon rank sum test;
see Hanley and McNeil (1982).
</p>


<h3>Value</h3>

<p>AUC value.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>J. A. Hanley and B. J. McNeil (1982). The meaning and use of the area under a receiver
operating characteristic (ROC) curve. <em>Radiology</em>, <b>143</b>, 29-36.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(13)
x &lt;- rnorm(100) ## assumed as log2-data
g &lt;- sample(1:2, 100, replace = TRUE)
AUC(x, group = g)
## avoid switching AUC
AUC(x, group = g, switchAUC = FALSE)
</code></pre>

<hr>
<h2 id='AUC.test'>
AUC-Test
</h2><span id='topic+AUC.test'></span>

<h3>Description</h3>

<p>Performs tests for one and two AUCs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC.test(pred1, lab1, pred2, lab2, conf.level = 0.95, paired = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC.test_+3A_pred1">pred1</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="AUC.test_+3A_lab1">lab1</code></td>
<td>
<p> grouping vector or factor for <code>pred1</code>. </p>
</td></tr>
<tr><td><code id="AUC.test_+3A_pred2">pred2</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="AUC.test_+3A_lab2">lab2</code></td>
<td>
<p>grouping vector or factor for <code>pred2</code>. </p>
</td></tr>
<tr><td><code id="AUC.test_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level of the interval. </p>
</td></tr>
<tr><td><code id="AUC.test_+3A_paired">paired</code></td>
<td>
<p> not yet implemented. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>pred2</code> and <code>lab2</code> are missing, the AUC for <code>pred1</code>
and <code>lab1</code> is tested using the Wilcoxon signed rank test;
see <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>.
</p>
<p>If <code>pred1</code> and <code>lab1</code> as well as <code>pred2</code> and <code>lab2</code>
are specified, the Hanley and McNeil test (cf. Hanley and McNeil (1982)) 
is computed.
</p>


<h3>Value</h3>

<p>A list with AUC, SE and confidence interval as well as the corresponding
test result.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>J. A. Hanley and B. J. McNeil (1982). The meaning and use of the area under a receiver
operating characteristic (ROC) curve. <em>Radiology</em>, <b>143</b>, 29-36.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="#topic+AUC">AUC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(13)
x &lt;- rnorm(100) ## assumed as log2-data
g &lt;- sample(1:2, 100, replace = TRUE)
AUC.test(x, g)
y &lt;- rnorm(100) ## assumed as log2-data
h &lt;- sample(1:2, 100, replace = TRUE)
AUC.test(x, g, y, h)
</code></pre>

<hr>
<h2 id='binomCI'> Confidence Intervals for Binomial Proportions </h2><span id='topic+binomCI'></span>

<h3>Description</h3>

<p>This function can be used to compute confidence intervals for binomial proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binomCI(x, n, conf.level = 0.95, method = "wilson", rand = 123)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomCI_+3A_x">x</code></td>
<td>
<p> number of successes </p>
</td></tr>
<tr><td><code id="binomCI_+3A_n">n</code></td>
<td>
<p> number of trials </p>
</td></tr>
<tr><td><code id="binomCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level </p>
</td></tr>
<tr><td><code id="binomCI_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; see details. </p>
</td></tr>
<tr><td><code id="binomCI_+3A_rand">rand</code></td>
<td>
<p> seed for random number generator; see details. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wald interval is obtained by inverting the acceptance region of the Wald
large-sample normal test.
</p>
<p>The Wilson interval, which is the default, was introduced by Wilson (1927) and is
the inversion of the CLT approximation to the family of equal tail tests of p = p0.
The Wilson interval is recommended by Agresti and Coull (1998) as well as by
Brown et al (2001).
</p>
<p>The Agresti-Coull interval was proposed by Agresti and Coull (1998) and is a slight
modification of the Wilson interval. The Agresti-Coull intervals are never shorter
than the Wilson intervals; cf. Brown et al (2001).
</p>
<p>The Jeffreys interval is an implementation of the equal-tailed Jeffreys prior interval
as given in Brown et al (2001).
</p>
<p>The modified Wilson interval is a modification of the Wilson interval for x close to 0
or n as proposed by Brown et al (2001).
</p>
<p>The modified Jeffreys interval is a modification of the Jeffreys interval for
<code>x == 0 | x == 1</code> and <code>x == n-1 | x == n</code> as proposed by
Brown et al (2001).
</p>
<p>The Clopper-Pearson interval is based on quantiles of corresponding beta
distributions. This is sometimes also called exact interval.
</p>
<p>The arcsine interval is based on the variance stabilizing distribution for the binomial
distribution.
</p>
<p>The logit interval is obtained by inverting the Wald type interval for the log odds.
</p>
<p>The Witting interval (cf. Beispiel 2.106 in Witting (1985)) uses randomization to
obtain uniformly optimal lower and upper confidence bounds (cf. Satz 2.105 in
Witting (1985)) for binomial proportions.
</p>
<p>For more details we refer to Brown et al (2001) as well as Witting (1985).
</p>


<h3>Value</h3>

<p>A list with class <code>"confint"</code> containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p> the estimated probability of success. </p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p> a confidence interval for the probability of success. </p>
</td></tr>
</table>


<h3>Note</h3>

<p>A first version of this function appeared in R package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>A. Agresti and B.A. Coull (1998). Approximate is better than &quot;exact&quot; for interval
estimation of binomial proportions.
<em>American Statistician</em>, <b>52</b>, 119-126.
</p>
<p>L.D. Brown, T.T. Cai and A. Dasgupta (2001). Interval estimation for a binomial
proportion. <em>Statistical Science</em>, <b>16</b>(2), 101-133.
</p>
<p>H. Witting (1985). <em>Mathematische Statistik I</em>. Stuttgart: Teubner.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+binom.test">binom.test</a></code>, <code><a href="Hmisc.html#topic+binconf">binconf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>binomCI(x = 42, n = 43, method = "wald")
binomCI(x = 42, n = 43, method = "wilson")
binomCI(x = 42, n = 43, method = "agresti-coull")
binomCI(x = 42, n = 43, method = "jeffreys")
binomCI(x = 42, n = 43, method = "modified wilson")
binomCI(x = 42, n = 43, method = "modified jeffreys")
binomCI(x = 42, n = 43, method = "clopper-pearson")
binomCI(x = 42, n = 43, method = "arcsine")
binomCI(x = 42, n = 43, method = "logit")
binomCI(x = 42, n = 43, method = "witting")

## the confidence interval computed by binom.test
## corresponds to the Clopper-Pearson interval
binomCI(x = 42, n = 43, method = "clopper-pearson")$conf.int
binom.test(x = 42, n = 43)$conf.int
</code></pre>

<hr>
<h2 id='corDist'> Correlation Distance Matrix Computation </h2><span id='topic+corDist'></span>

<h3>Description</h3>

<p>The function computes and returns the correlation and absolute correlation distance
matrix computed by using the specified distance measure to compute the distances
between the rows of a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corDist(x, method = "pearson", diag = FALSE, upper = FALSE, abs = FALSE,
        use = "pairwise.complete.obs", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corDist_+3A_x">x</code></td>
<td>
<p> a numeric matrix or data frame </p>
</td></tr>
<tr><td><code id="corDist_+3A_method">method</code></td>
<td>
<p> the correlation distance measure to be used. This must be one of
<code>"pearson"</code>, <code>"spearman"</code>, <code>"kandall"</code>, <code>"cosine"</code>,
<code>"mcd"</code> or <code>"ogk"</code>, respectively.
Any unambiguous substring can be given. </p>
</td></tr>
<tr><td><code id="corDist_+3A_diag">diag</code></td>
<td>
<p> logical value indicating whether the diagonal of the distance
matrix should be printed by 'print.dist'. </p>
</td></tr>
<tr><td><code id="corDist_+3A_upper">upper</code></td>
<td>
<p> logical value indicating whether the upper triangle of the
distance matrix should be printed by 'print.dist'. </p>
</td></tr>
<tr><td><code id="corDist_+3A_abs">abs</code></td>
<td>
<p> logical, compute absolute correlation distances </p>
</td></tr>
<tr><td><code id="corDist_+3A_use">use</code></td>
<td>
<p> character, correponds to argument <code>use</code> of function
<code><a href="stats.html#topic+cor">cor</a></code> </p>
</td></tr>
<tr><td><code id="corDist_+3A_...">...</code></td>
<td>
<p> further arguments to functions <code><a href="robustbase.html#topic+covMcd">covMcd</a></code>
or <code><a href="robustbase.html#topic+covOGK">covOGK</a></code>, respectively. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the Pearson, Spearman, Kendall or Cosine sample correlation
and absolute correlation; confer Section 12.2.2 of Gentleman et al (2005). For more
details about the arguments we refer to functions <code><a href="stats.html#topic+dist">dist</a></code> and
<code><a href="stats.html#topic+cor">cor</a></code>.
Moreover, the function computes the minimum covariance determinant or the
orthogonalized Gnanadesikan-Kettenring estimator. For more details we refer to
functions <code><a href="robustbase.html#topic+covMcd">covMcd</a></code> and <code><a href="robustbase.html#topic+covOGK">covOGK</a></code>,
respectively.
</p>


<h3>Value</h3>

<p><code>corDist</code> returns an object of class <code>"dist"</code>; cf. <code><a href="stats.html#topic+dist">dist</a></code>.
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Gentleman R. Ding B., Dudoit S. and Ibrahim J. (2005). Distance Measures in DNA
Microarray Data Analysis. In: Gentleman R., Carey V.J., Huber W., Irizarry R.A. and
Dudoit S. (editors) Bioinformatics and Computational Biology Solutions Using R and
Bioconductor. Springer.
</p>
<p>P. J. Rousseeuw and A. M. Leroy (1987). Robust Regression and Outlier Detection. Wiley.
</p>
<p>P. J. Rousseeuw and K. van Driessen (1999) A fast algorithm for the minimum
covariance determinant estimator. Technometrics 41, 212-223.
</p>
<p>Pison, G., Van Aelst, S., and Willems, G. (2002), Small Sample Corrections for
LTS and MCD, Metrika, 55, 111-123.
</p>
<p>Maronna, R.A. and Zamar, R.H. (2002). Robust estimates of location and dispersion
of high-dimensional datasets; Technometrics 44(4), 307-317.
</p>
<p>Gnanadesikan, R. and John R. Kettenring (1972). Robust estimates, residuals, and
outlier detection with multiresponse data. Biometrics 28, 81-124.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## only a dummy example
M &lt;- matrix(rnorm(1000), ncol = 20)
D &lt;- corDist(M)
</code></pre>

<hr>
<h2 id='corPlot'> Plot of similarity matrix based on correlation </h2><span id='topic+corPlot'></span>

<h3>Description</h3>

<p>Plot of similarity matrix. This function is a slight modification of function
<code>plot.cor</code> of the archived package <code>"sma"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corPlot(x, new = FALSE, col, minCor, 
          labels = FALSE, lab.both.axes = FALSE, labcols = "black", 
          title = "", cex.title = 1.2, 
          protocol = FALSE, cex.axis = 0.8, 
          cex.axis.bar = 1, signifBar = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corPlot_+3A_x">x</code></td>
<td>
<p> data or correlation matrix, respectively </p>
</td></tr>
<tr><td><code id="corPlot_+3A_new">new</code></td>
<td>
<p> If <code>new=FALSE</code>, <code>x</code> must already be a correlation matrix. 
If <code>new=TRUE</code>, the correlation matrix for the columns of 
<code>x</code> is computed and displayed in the image. </p>
</td></tr>
<tr><td><code id="corPlot_+3A_col">col</code></td>
<td>
<p> colors palette for image. If missing, the <code>RdYlGn</code> palette
of <code>RColorBrewer</code> is used. </p>
</td></tr>
<tr><td><code id="corPlot_+3A_mincor">minCor</code></td>
<td>
<p>numeric value in [-1,1], used to adjust <code>col</code></p>
</td></tr>
<tr><td><code id="corPlot_+3A_labels">labels</code></td>
<td>
<p> vector of character strings to be placed at the tickpoints,
labels for the columns of <code>x</code>. </p>
</td></tr>
<tr><td><code id="corPlot_+3A_lab.both.axes">lab.both.axes</code></td>
<td>
<p> logical, display labels on both axes </p>
</td></tr>
<tr><td><code id="corPlot_+3A_labcols">labcols</code></td>
<td>
<p> colors to be used for the labels of the columns of <code>x</code>.
<code>labcols</code> can have either length 1, in which case all 
the labels are displayed using the same color, or the same 
length as <code>labels</code>, in which case a color is specified 
for the label of each column of <code>x</code>. </p>
</td></tr>
<tr><td><code id="corPlot_+3A_title">title</code></td>
<td>
<p> character string, overall title for the plot. </p>
</td></tr>
<tr><td><code id="corPlot_+3A_cex.title">cex.title</code></td>
<td>
<p> A numerical value giving the amount by which plotting text
and symbols should be magnified relative to the default;
cf. <code><a href="graphics.html#topic+par">par</a></code>, <code>cex.main</code>. </p>
</td></tr>
<tr><td><code id="corPlot_+3A_protocol">protocol</code></td>
<td>
<p> logical, display color bar without numbers </p>
</td></tr>
<tr><td><code id="corPlot_+3A_cex.axis">cex.axis</code></td>
<td>
<p> The magnification to be used for axis annotation relative to the 
current setting of 'cex'; cf. <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_cex.axis.bar">cex.axis.bar</code></td>
<td>
<p> The magnification to be used for axis annotation of the color 
bar relative to the current setting of 'cex'; cf. 
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_signifbar">signifBar</code></td>
<td>
<p> integer indicating the precision to be used for the bar.</p>
</td></tr>
<tr><td><code id="corPlot_+3A_...">...</code></td>
<td>
<p> graphical parameters may also be supplied as arguments to the
function (see <code><a href="graphics.html#topic+par">par</a></code>). For comparison purposes, 
it is good to set <code>zlim=c(-1,1)</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions generates the so called similarity matrix (based on correlation) 
for a microarray experiment. 
</p>
<p>If <code>min(x)</code>, respectively <code>min(cor(x))</code> is smaller than <code>minCor</code>, 
the colors in <code>col</code> are adjusted such that the minimum correlation value 
which is color coded is equal to <code>minCor</code>.
</p>


<h3>Value</h3>

<p><code>invisible()</code>
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>Sandrine Dudoit, Yee Hwa (Jean) Yang, Benjamin Milo Bolstad and with 
contributions from Natalie Thorne, Ingrid Loennstedt and Jessica Mar.
sma: Statistical Microarray Analysis.<br />
http://www.stat.berkeley.edu/users/terry/zarray/Software/smacode.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## only a dummy example
M &lt;- matrix(rnorm(1000), ncol = 20)
colnames(M) &lt;- paste("Sample", 1:20)
M.cor &lt;- cor(M)

corPlot(M.cor, minCor = min(M.cor))
corPlot(M.cor, minCor = min(M.cor), lab.both.axes = TRUE)
corPlot(M.cor, minCor = min(M.cor), protocol = TRUE)
corPlot(M.cor, minCor = min(M.cor), signifBar = 1)
</code></pre>

<hr>
<h2 id='CV'> Compute CV </h2><span id='topic+CV'></span><span id='topic+medCV'></span><span id='topic+iqrCV'></span>

<h3>Description</h3>

<p>The functions compute CV as well as two robust versions of the CV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="CV_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions compute the (classical) coefficient of variation as well as
two robust variants.
</p>
<p><code>medCV</code> uses the (standardized) MAD instead of SD and median instead of mean.
</p>
<p><code>iqrCV</code> uses the (standardized) IQR instead of SD and median instead of mean.
</p>


<h3>Value</h3>

<p>CV value.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>C.N.P.G. Arachchige, L.A. Prendergast and R.G. Staudte. Robust analogues
to the Coefficient of Variation. https://arxiv.org/abs/1907.01110.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 5% outliers
out &lt;- rbinom(100, prob = 0.05, size = 1)
sum(out)
x &lt;- (1-out)*rnorm(100, mean = 10, sd = 2) + out*25
CV(x)
medCV(x)
iqrCV(x)
</code></pre>

<hr>
<h2 id='cvCI'> Confidence Intervals for Coefficient of Variation </h2><span id='topic+cvCI'></span>

<h3>Description</h3>

<p>This function can be used to compute confidence intervals for the (classical)
coefficient of variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvCI(x, conf.level = 0.95, method = "miller", na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvCI_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="cvCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level </p>
</td></tr>
<tr><td><code id="cvCI_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; see details. </p>
</td></tr>
<tr><td><code id="cvCI_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details about the confidence intervals we refer to Gulhar et al (2012) and
Arachchige et al (2019).
</p>


<h3>Value</h3>

<p>A list with class <code>"confint"</code> containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p> the estimated coefficient of variation. </p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p> a confidence interval for the coefficient of variation. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>C.N.P.G. Arachchige, L.A. Prendergast and R.G. Staudte (2019). Robust analogues
to the Coefficient of Variation. https://arxiv.org/abs/1907.01110.
</p>
<p>M. Gulhar, G. Kibria, A. Albatineh, N.U. Ahmed (2012). A comparison of some
confidence intervals for estimating the population coefficient of variation:
a simulation study. <em>Sort</em>, <b>36</b>(1), 45-69.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CV">CV</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100, mean = 10, sd = 2) # CV = 0.2
cvCI(x, method = "miller")
cvCI(x, method = "sharma")
cvCI(x, method = "curto")
cvCI(x, method = "mckay")
cvCI(x, method = "vangel")
cvCI(x, method = "panichkitkosolkul")
cvCI(x, method = "medmiller")
cvCI(x, method = "medmckay")
cvCI(x, method = "medvangel")
cvCI(x, method = "medcurto")
cvCI(x, method = "gulhar")
</code></pre>

<hr>
<h2 id='fiveNS'> Five-Number Summaries </h2><span id='topic+fiveNS'></span>

<h3>Description</h3>

<p>Function to compute five-number summaries (minimum, 1st quartile,
median, 3rd quartile, maximum)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fiveNS(x, na.rm = TRUE, type = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fiveNS_+3A_x">x</code></td>
<td>
<p> numeric vector </p>
</td></tr>
<tr><td><code id="fiveNS_+3A_na.rm">na.rm</code></td>
<td>
<p> logical; remove <code>NA</code> before the computations. </p>
</td></tr>
<tr><td><code id="fiveNS_+3A_type">type</code></td>
<td>
<p> an integer between 1 and 9 selecting one of nine quantile
algorithms; for more details see <code><a href="stats.html#topic+quantile">quantile</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In contrast to <code><a href="stats.html#topic+fivenum">fivenum</a></code> the functions computes the
first and third quartile using function <code><a href="stats.html#topic+quantile">quantile</a></code>.
</p>


<h3>Value</h3>

<p>A numeric vector of length 5 containing the summary information.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+fivenum">fivenum</a></code>, <code><a href="stats.html#topic+quantile">quantile</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
fiveNS(x)
fiveNS(x, type = 2)
fivenum(x)
</code></pre>

<hr>
<h2 id='glog'> Compute Generalized Logarithm</h2><span id='topic+glog'></span><span id='topic+glog10'></span><span id='topic+glog2'></span><span id='topic+inv.glog'></span><span id='topic+inv.glog10'></span><span id='topic+inv.glog2'></span>

<h3>Description</h3>

<p>The functions compute the generalized logarithm, which is more or less
identical to the area hyperbolic sine, and their inverse; see details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glog(x, base = exp(1))
glog10(x)
glog2(x)
inv.glog(x, base = exp(1))
inv.glog10(x)
inv.glog2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glog_+3A_x">x</code></td>
<td>
<p> a numeric or complex vector.</p>
</td></tr>
<tr><td><code id="glog_+3A_base">base</code></td>
<td>
<p> a positive or a positive or complex number: the base with
respect to which logarithms are computed. Defaults to e=exp(1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes
</p>
<p style="text-align: center;"><code class="reqn">\log(x + \sqrt{x^2 + 1}) - \log(2)</code>
</p>

<p>where the first part corresponds to the area hyperbolic sine. Subtracting
log(2) makes the function asymptotically identical to the logarithm.
</p>


<h3>Value</h3>

<p>A vector of the same length as x containing the transformed values.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>curve(log, from = -3, to = 5)
curve(glog, from = -3, to = 5, add = TRUE, col = "orange")
legend("topleft", fill = c("black", "orange"), legend = c("log", "glog"))

curve(log10(x), from = -3, to = 5)
curve(glog10(x), from = -3, to = 5, add = TRUE, col = "orange")
legend("topleft", fill = c("black", "orange"), legend = c("log10", "glog10"))

inv.glog(glog(10))
inv.glog(glog(10, base = 3), base = 3)
inv.glog10(glog10(10))
inv.glog2(glog2(10))
</code></pre>

<hr>
<h2 id='heatmapCol'> Generate colors for heatmaps </h2><span id='topic+heatmapCol'></span>

<h3>Description</h3>

<p>This function modifies a given color vector as used for heatmaps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heatmapCol(data, col, lim, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heatmapCol_+3A_data">data</code></td>
<td>
<p> matrix or data.frame; data which shall be displayed in a heatmap; ranging from negative to positive numbers. </p>
</td></tr>
<tr><td><code id="heatmapCol_+3A_col">col</code></td>
<td>
<p> vector of colors used for heatmap. </p>
</td></tr>
<tr><td><code id="heatmapCol_+3A_lim">lim</code></td>
<td>
<p> constant colors are used for data below <code>-lim</code> resp. above <code>lim</code>. </p>
</td></tr>
<tr><td><code id="heatmapCol_+3A_na.rm">na.rm</code></td>
<td>
<p> logical; remove <code>NA</code> values. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Colors below and above a specified value are kept constant. In addition, the colors
are symmetrizised.
</p>


<h3>Value</h3>

<p>vector of colors
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>data.plot &lt;- matrix(rnorm(100*50, sd = 1), ncol = 50)
colnames(data.plot) &lt;- paste("patient", 1:50)
rownames(data.plot) &lt;- paste("gene", 1:100)
data.plot[1:70, 1:30] &lt;- data.plot[1:70, 1:30] + 3
data.plot[71:100, 31:50] &lt;- data.plot[71:100, 31:50] - 1.4
data.plot[1:70, 31:50] &lt;- rnorm(1400, sd = 1.2)
data.plot[71:100, 1:30] &lt;- rnorm(900, sd = 1.2)
nrcol &lt;- 128

require(gplots)
require(RColorBrewer)
myCol &lt;- rev(colorRampPalette(brewer.pal(10, "RdBu"))(nrcol))
heatmap.2(data.plot, col =  myCol, trace = "none", tracecol = "black")
farbe &lt;- heatmapCol(data = data.plot, col = myCol, 
                    lim = min(abs(range(data.plot)))-1)
heatmap.2(data.plot, col = farbe, trace = "none", tracecol = "black")
</code></pre>

<hr>
<h2 id='HLgof.test'>
Hosmer-Lemeshow goodness of fit tests.
</h2><span id='topic+HLgof.test'></span>

<h3>Description</h3>

<p>The function computes Hosmer-Lemeshow goodness of fit tests
for C and H statistic as well as the le Cessie-van Houwelingen-Copas-Hosmer 
unweighted sum of squares test for global goodness of fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HLgof.test(fit, obs, ngr = 10, X, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HLgof.test_+3A_fit">fit</code></td>
<td>
<p> numeric vector with fitted probabilities. </p>
</td></tr>
<tr><td><code id="HLgof.test_+3A_obs">obs</code></td>
<td>
<p> numeric vector with observed values. </p>
</td></tr>
<tr><td><code id="HLgof.test_+3A_ngr">ngr</code></td>
<td>
<p> number of groups for C and H statistic. </p>
</td></tr>
<tr><td><code id="HLgof.test_+3A_x">X</code></td>
<td>
<p> covariate(s) for le Cessie-van Houwelingen-Copas-Hosmer
global goodness of fit test. </p>
</td></tr>
<tr><td><code id="HLgof.test_+3A_verbose">verbose</code></td>
<td>
<p> logical, print intermediate results. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hosmer-Lemeshow goodness of fit tests are computed; see Lemeshow and Hosmer 
(1982).
</p>
<p>If <code>X</code> is specified, the le Cessie-van Houwelingen-Copas-Hosmer 
unweighted sum of squares test for global goodness of fit is additionally 
determined; see Hosmer et al. (1997).
A more general version of this test is implemented in function 
<code><a href="rms.html#topic+residuals.lrm">residuals.lrm</a></code> in package <span class="pkg">rms</span>.
</p>


<h3>Value</h3>

<p>A list of test results.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>S. Lemeshow and D.W. Hosmer (1982). A review of goodness of fit statistics
for use in the development of logistic regression models. 
<em>American Journal of Epidemiology, <b>115</b>(1), 92-106.</em>
</p>
<p>D.W. Hosmer, T. Hosmer, S. le Cessie, S. Lemeshow (1997). A comparison 
of goodness-of-fit tests for the logistic regression model. 
<em>Statistics in Medicine</em>, <b>16</b>, 965-980.
</p>


<h3>See Also</h3>

 <p><code><a href="rms.html#topic+residuals.lrm">residuals.lrm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(111)
x1 &lt;- factor(sample(1:3, 50, replace = TRUE))
x2 &lt;- rnorm(50)
obs &lt;- sample(c(0,1), 50, replace = TRUE)
fit &lt;- glm(obs ~ x1+x2, family = binomial)
HLgof.test(fit = fitted(fit), obs = obs)
HLgof.test(fit = fitted(fit), obs = obs, X = model.matrix(obs ~ x1+x2))
</code></pre>

<hr>
<h2 id='hsu.t.test'>Hsu Two-Sample t-Test</h2><span id='topic+hsu.t.test'></span><span id='topic+hsu.t.test.default'></span><span id='topic+hsu.t.test.formula'></span>

<h3>Description</h3>

<p>Performs Hsu two sample t-tests on vectors of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsu.t.test(x, ...)

## Default S3 method:
hsu.t.test(x, y,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, conf.level = 0.95, ...)

## S3 method for class 'formula'
hsu.t.test(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsu.t.test_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_y">y</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.  You can specify just the initial
letter.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_mu">mu</code></td>
<td>
<p>a number indicating the true value of the mean (or
difference in means if you are performing a two sample test).</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
is a numeric variable giving the data values and <code>rhs</code> a factor
with two levels giving the corresponding groups.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="hsu.t.test_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function and its documentation was adapted from <code><a href="stats.html#topic+t.test">t.test</a></code>.
</p>
<p><code>alternative = "greater"</code> is the alternative that <code>x</code> has a
larger mean than <code>y</code>.
</p>
<p>If the input data are effectively constant (compared to the larger of the
two means) an error is generated.
</p>
<p>One should at least have six observations per group to apply the test; see
Section 6.8.3 of Hedderich and Sachs (2016).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the t-statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom for the t-statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the mean appropriate to the
specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated means and standard deviations.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the specified hypothesized value of the mean or mean
difference depending on whether it was a one-sample test or a
two-sample test.</p>
</td></tr>
<tr><td><code>stderr</code></td>
<td>
<p>the standard error of the difference in means, used as
denominator in the t-statistic formula.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of t-test was
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>References</h3>

<p>J. Hedderich, L. Sachs. <em>Angewandte Statistik: Methodensammlung mit R</em>.
Springer 2016.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Examples taken and adapted from function t.test
t.test(1:10, y = c(7:20))      # P = .00001855
t.test(1:10, y = c(7:20, 200)) # P = .1245    -- NOT significant anymore
hsu.t.test(1:10, y = c(7:20))
hsu.t.test(1:10, y = c(7:20, 200))

## Traditional interface
with(sleep, t.test(extra[group == 1], extra[group == 2]))
with(sleep, hsu.t.test(extra[group == 1], extra[group == 2]))
## Formula interface
t.test(extra ~ group, data = sleep)
hsu.t.test(extra ~ group, data = sleep)
</code></pre>

<hr>
<h2 id='imputeSD'> Impute Standard Deviations for Changes from Baseline </h2><span id='topic+imputeSD'></span>

<h3>Description</h3>

<p>The function imputes standard deviations for changes from baseline
adopting the approach describe in the Cochrane handbook, Section 16.1.3.2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeSD(SD1, SD2, SDchange)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputeSD_+3A_sd1">SD1</code></td>
<td>
<p> numeric vector, baseline SD. </p>
</td></tr>
<tr><td><code id="imputeSD_+3A_sd2">SD2</code></td>
<td>
<p> numeric vector, follow-up SD.</p>
</td></tr>
<tr><td><code id="imputeSD_+3A_sdchange">SDchange</code></td>
<td>
<p> numeric vector, SD for changes from baseline. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function imputes standard deviations for changes from baseline
adopting the approach describe in the Cochrane handbook, Section 16.1.3.2.
</p>
<p>1) Missing <code>SD1</code> are replaced by correspondig values of <code>SD2</code> and
vice versa.
</p>
<p>2) Correlations for complete data (rows) are computed.
</p>
<p>3) Minimum, mean and maximum correlation (over rows) are computed.
</p>
<p>4) Missing values of SDchange are computed by the formula provided in
the handbook. The minimum, mean and maximum correlation are used leading
to maximal, mean and minimal SD values that may be used for imputation as
well as a sensitivity analysis.
</p>


<h3>Value</h3>

<p><code>data.frame</code> with possibly imputed SD1 and SD2 values as well as the
given SDchange values are returen. Moreover, the computed correlations as
well as possible values for the imputation of SDchange are returned.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Higgins JPT, Green S (editors). Cochrane Handbook for Systematic Reviews
of Interventions Version 5.1.0 [updated March 2011]. The Cochrane
Collaboration, 2011. Available from www.handbook.cochrane.org.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SD1 &lt;- c(0.149, 0.022, 0.036, 0.085, 0.125, NA, 0.139, 0.124, 0.038)
SD2 &lt;- c(NA, 0.039, 0.038, 0.087, 0.125, NA, 0.135, 0.126, 0.038)
SDchange &lt;- c(NA, NA, NA, 0.026, 0.058, NA, NA, NA, NA)
imputeSD(SD1, SD2, SDchange)
</code></pre>

<hr>
<h2 id='IQrange'>The Interquartile Range</h2><span id='topic+IQrange'></span><span id='topic+sIQR'></span>

<h3>Description</h3>

<p>Computes (standardized) interquartile range of the <code>x</code> values.</p>


<h3>Usage</h3>

<pre><code class='language-R'>IQrange(x, na.rm = FALSE, type = 7)
sIQR(x, na.rm = FALSE, type = 7, constant = 2*qnorm(0.75))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IQrange_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="IQrange_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="IQrange_+3A_type">type</code></td>
<td>
<p> an integer between 1 and 9 selecting one of nine quantile
algorithms; for more details see <code><a href="stats.html#topic+quantile">quantile</a></code>. </p>
</td></tr>
<tr><td><code id="IQrange_+3A_constant">constant</code></td>
<td>
<p> standardizing contant; see details below. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function <code>IQrange</code> computes quartiles as
<code>IQR(x) = quantile(x,3/4) - quantile(x,1/4)</code>.
The function is identical to function <code><a href="stats.html#topic+IQR">IQR</a></code>. It was added
before the <code>type</code> argument was introduced to function <code><a href="stats.html#topic+IQR">IQR</a></code>
in 2010 (r53643, r53644).
</p>
<p>For normally <code class="reqn">N(m,1)</code> distributed <code class="reqn">X</code>, the expected value of
<code>IQR(X)</code> is <code>2*qnorm(3/4) = 1.3490</code>, i.e., for a normal-consistent
estimate of the standard deviation, use <code>IQR(x) / 1.349</code>. This is implemented
in function <code>sIQR</code> (standardized IQR).
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Tukey, J. W. (1977). <em>Exploratory Data Analysis.</em> Reading: Addison-Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code>, <code><a href="stats.html#topic+IQR">IQR</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>IQrange(rivers)

## identical to
IQR(rivers)

## other quantile algorithms
IQrange(rivers, type = 4)
IQrange(rivers, type = 5)

## standardized IQR
sIQR(rivers)

## right-skewed data distribution
sd(rivers)
mad(rivers)

## for normal data
x &lt;- rnorm(100)
sd(x)
sIQR(x)
mad(x)
</code></pre>

<hr>
<h2 id='madMatrix'> Compute MAD between colums of a matrix or data.frame </h2><span id='topic+madMatrix'></span>

<h3>Description</h3>

<p>Compute MAD between colums of a matrix or data.frame. Can be used to create
a similarity matrix for a microarray experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>madMatrix(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="madMatrix_+3A_x">x</code></td>
<td>
<p> matrix or data.frame </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions computes the so called similarity matrix (based on MAD)
for a microarray experiment; cf. Buness et. al. (2004).
</p>


<h3>Value</h3>

<p>matrix of MAD values between colums of <code>x</code>
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Andreas Buness, Wolfgang Huber, Klaus Steiner, Holger Sueltmann, and
Annemarie Poustka. arrayMagic: two-colour cDNA microarray quality
control and preprocessing. Bioinformatics Advance Access published on
September 28, 2004. doi:10.1093/bioinformatics/bti052
</p>


<h3>See Also</h3>

<p><code>plotMAD</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## only a dummy example
madMatrix(matrix(rnorm(1000), ncol = 10))
</code></pre>

<hr>
<h2 id='madPlot'> Plot of similarity matrix based on MAD </h2><span id='topic+madPlot'></span>

<h3>Description</h3>

<p>Plot of similarity matrix based on MAD between microarrays.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>madPlot(x, new = FALSE, col, maxMAD = 3, labels = FALSE, 
        labcols = "black", title = "", protocol = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="madPlot_+3A_x">x</code></td>
<td>
<p> data or correlation matrix, respectively </p>
</td></tr>
<tr><td><code id="madPlot_+3A_new">new</code></td>
<td>
<p> If <code>new=FALSE</code>, <code>x</code> must already be a matrix with MAD
values. If <code>new=TRUE</code>, the MAD matrix for the columns of 
<code>x</code> is computed and displayed in the image. </p>
</td></tr>
<tr><td><code id="madPlot_+3A_col">col</code></td>
<td>
<p> colors palette for image. If missing, the <code>RdYlGn</code> palette
of <code>RColorBrewer</code> is used. </p>
</td></tr>
<tr><td><code id="madPlot_+3A_maxmad">maxMAD</code></td>
<td>
<p> maximum MAD value displayed  </p>
</td></tr>
<tr><td><code id="madPlot_+3A_labels">labels</code></td>
<td>
<p> vector of character strings to be placed at the tickpoints,
labels for the columns of <code>x</code>. </p>
</td></tr>
<tr><td><code id="madPlot_+3A_labcols">labcols</code></td>
<td>
<p> colors to be used for the labels of the columns of <code>x</code>.
<code>labcols</code> can have either length 1, in which case all 
the labels are displayed using the same color, or the same 
length as <code>labels</code>, in which case a color is specified 
for the label of each column of <code>x</code>. </p>
</td></tr>
<tr><td><code id="madPlot_+3A_title">title</code></td>
<td>
<p> character string, overall title for the plot. </p>
</td></tr>
<tr><td><code id="madPlot_+3A_protocol">protocol</code></td>
<td>
<p> logical, display color bar without numbers </p>
</td></tr>
<tr><td><code id="madPlot_+3A_...">...</code></td>
<td>
<p> graphical parameters may also be supplied as arguments to the
function (see <code><a href="graphics.html#topic+par">par</a></code>). For comparison purposes, 
it is good to set <code>zlim=c(-1,1)</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions generates the so called similarity matrix (based on MAD) for 
a microarray experiment; cf. Buness et. al. (2004). The function is similar
to <code><a href="#topic+corPlot">corPlot</a></code>.
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>Sandrine Dudoit, Yee Hwa (Jean) Yang, Benjamin Milo Bolstad and with 
contributions from Natalie Thorne, Ingrid Loennstedt and Jessica Mar.
sma: Statistical Microarray Analysis.<br />
http://www.stat.berkeley.edu/users/terry/zarray/Software/smacode.html
</p>
<p>Andreas Buness, Wolfgang Huber, Klaus Steiner, Holger Sueltmann, and
Annemarie Poustka. arrayMagic: two-colour cDNA microarray quality
control and preprocessing. Bioinformatics Advance Access published on
September 28, 2004. doi:10.1093/bioinformatics/bti052
</p>


<h3>See Also</h3>

<p><code>corPlot</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## only a dummy example
set.seed(13)
x &lt;- matrix(rnorm(1000), ncol = 10)
x[1:20,5] &lt;- x[1:20,5] + 10
madPlot(x, new = TRUE, maxMAD = 2.5)
## in contrast
corPlot(x, new = TRUE, minCor = -0.5)
</code></pre>

<hr>
<h2 id='meanAD'>The Mean Absolute Deviation</h2><span id='topic+meanAD'></span>

<h3>Description</h3>

<p>Computes (standardized) mean absolute deviation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanAD(x, na.rm = FALSE, constant = sqrt(pi/2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meanAD_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="meanAD_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="meanAD_+3A_constant">constant</code></td>
<td>
<p> standardizing contant; see details below. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean absolute deviation is a consistent estimator of 
<code class="reqn">\sqrt{2/\pi}\sigma</code> for the standard deviation of
a normal distribution. Under minor deviations of the normal distributions
its asymptotic variance is smaller than that of the sample standard 
deviation (Tukey (1960)).
</p>
<p>It works well under the assumption of symmetric, where mean and median
coincide. Under the normal distribution it's about 18% more efficient
(asymptotic relative efficiency) than the median absolute deviation 
(<code>(1/qnorm(0.75))/sqrt(pi/2)</code>) and about 12% less efficient than the 
sample standard deviation (Tukey (1960)).
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Tukey, J. W. (1960). A survey of sampling from contaminated distribution.
In Olink, I., editor, <em>Contributions to Probablity and Statistics. 
Essays in Honor of H. Hotelling.</em>, pages 448-485. Stanford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+sd">sd</a></code>, <code><a href="stats.html#topic+mad">mad</a></code>, <code>sIQR</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## right skewed data
## mean absolute deviation
meanAD(rivers)
## standardized IQR
sIQR(rivers)
## median absolute deviation
mad(rivers)
## sample standard deviation
sd(rivers)

## for normal data
x &lt;- rnorm(100)
sd(x)
sIQR(x)
mad(x)
meanAD(x)

## Asymptotic relative efficiency for Tukey's symmetric gross-error model
## (1-eps)*Norm(mean, sd = sigma) + eps*Norm(mean, sd = 3*sigma)
eps &lt;- seq(from = 0, to = 1, by = 0.001)
ARE &lt;- function(eps){
  0.25*((3*(1+80*eps))/((1+8*eps)^2)-1)/(pi*(1+8*eps)/(2*(1+2*eps)^2)-1)
}
plot(eps, ARE(eps), type = "l", xlab = "Proportion of gross-errors",
     ylab = "Asymptotic relative efficiency", 
     main = "ARE of mean absolute deviation w.r.t. sample standard deviation")
abline(h = 1.0, col = "red")
text(x = 0.5, y = 1.5, "Mean absolute deviation is better", col = "red", 
    cex = 1, font = 1)
## lower bound of interval
uniroot(function(x){ ARE(x)-1 }, interval = c(0, 0.002))
## upper bound of interval
uniroot(function(x){ ARE(x)-1 }, interval = c(0.5, 0.55))
## worst case
optimize(ARE, interval = c(0,1), maximum = TRUE)
</code></pre>

<hr>
<h2 id='melt.long'> Transform data.frame to Long Form </h2><span id='topic+melt.long'></span>

<h3>Description</h3>

<p>The function transforms a given data.frame form wide to long form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt.long(data, select, group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="melt.long_+3A_data">data</code></td>
<td>
<p> data.frame that shall be transformed.</p>
</td></tr>
<tr><td><code id="melt.long_+3A_select">select</code></td>
<td>
<p> optional integer vector to select a subset of the columns of <code>data</code>.</p>
</td></tr>
<tr><td><code id="melt.long_+3A_group">group</code></td>
<td>
<p> optional vector to include an additional grouping in the output;
for more details see examples below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function transforms a given data.frame form wide to long form. This is
for example useful for plotting with ggplot2.
</p>


<h3>Value</h3>

<p>data.frame in long form.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a> </p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
## some random data
test &lt;- data.frame(x = rnorm(10), y = rnorm(10), z = rnorm(10))
test.long &lt;- melt.long(test)
test.long
ggplot(test.long, aes(x = variable, y = value)) +
  geom_boxplot(aes(fill = variable))
## introducing an additional grouping variable
group &lt;- factor(rep(c("a","b"), each = 5))
test.long.gr &lt;- melt.long(test, select = 1:2, group = group)
test.long.gr
ggplot(test.long.gr, aes(x = variable, y = value, fill = group)) +
  geom_boxplot()
</code></pre>

<hr>
<h2 id='mi.t.test'>Multiple Imputation Student's t-Test</h2><span id='topic+mi.t.test'></span><span id='topic+mi.t.test.default'></span>

<h3>Description</h3>

<p>Performs one and two sample t-tests on multiple imputed datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi.t.test(miData, ...)

## Default S3 method:
mi.t.test(miData, x, y = NULL,
        alternative = c("two.sided", "less", "greater"), mu = 0,
        paired = FALSE, var.equal = FALSE, conf.level = 0.95,
        subset = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mi.t.test_+3A_midata">miData</code></td>
<td>
<p>list of multiple imputed datasets.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_x">x</code></td>
<td>
<p>name of a variable that shall be tested.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_y">y</code></td>
<td>
<p>an optional name of a variable that shall be tested (paired test)
or a variable that shall be used to split into groups (unpaired test).</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.  You can specify just the initial
letter.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_mu">mu</code></td>
<td>
<p>a number indicating the true value of the mean (or
difference in means if you are performing a two sample test).</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_paired">paired</code></td>
<td>
<p>a logical indicating whether you want a paired
t-test.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_var.equal">var.equal</code></td>
<td>
<p>a logical variable indicating whether to treat the
two variances as being equal. If <code>TRUE</code> then the pooled
variance is used to estimate the variance otherwise the Welch
(or Satterthwaite) approximation to the degrees of freedom is used.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="mi.t.test_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>alternative = "greater"</code> is the alternative that <code>x</code> has a
larger mean than <code>y</code>.
</p>
<p>If <code>paired</code> is <code>TRUE</code> then both <code>x</code> and <code>y</code> must
be specified and they must be the same length.  Missing values are
not allowed as they should have been imputed.  If
<code>var.equal</code> is <code>TRUE</code> then the pooled estimate of the
variance is used.  By default, if <code>var.equal</code> is <code>FALSE</code>
then the variance is estimated separately for both groups and the
Welch modification to the degrees of freedom is used.
</p>
<p>We use the approach of Rubin (1987) in combination with the adjustment of
Barnard and Rubin (1999).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the t-statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom for the t-statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the mean appropriate to the
specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated mean (one-sample test), difference in means
(paired test), or estimated means (two-sample test) as well as the
respective standard deviations.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the specified hypothesized value of the mean or mean
difference depending on whether it was a one-sample test or a
two-sample test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of t-test was
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Rubin, D. (1987). <em>Multiple Imputation for Nonresponse in Surveys</em>.
John Wiley &amp; Sons, New York.
</p>
<p>Barnard, J. and Rubin, D. (1999). Small-Sample Degrees of Freedom with
Multiple Imputation. <em>Biometrika</em>, <b>86</b>(4), 948-955.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate some data
set.seed(123)
x &lt;- rnorm(25, mean = 1)
x[sample(1:25, 5)] &lt;- NA
y &lt;- rnorm(20, mean = -1)
y[sample(1:20, 4)] &lt;- NA
pair &lt;- c(rnorm(25, mean = 1), rnorm(20, mean = -1))
g &lt;- factor(c(rep("yes", 25), rep("no", 20)))
D &lt;- data.frame(ID = 1:45, variable = c(x, y), pair = pair, group = g)

## Use Amelia to impute missing values
library(Amelia)
res &lt;- amelia(D, m = 10, p2s = 0, idvars = "ID", noms = "group")

## Per protocol analysis (Welch two-sample t-test)
t.test(variable ~ group, data = D)
## Intention to treat analysis (Multiple Imputation Welch two-sample t-test)
mi.t.test(res$imputations, x = "variable", y = "group")

## Per protocol analysis (Two-sample t-test)
t.test(variable ~ group, data = D, var.equal = TRUE)
## Intention to treat analysis (Multiple Imputation two-sample t-test)
mi.t.test(res$imputations, x = "variable", y = "group", var.equal = TRUE)

## Specifying alternatives
mi.t.test(res$imputations, x = "variable", y = "group", alternative = "less")
mi.t.test(res$imputations, x = "variable", y = "group", alternative = "greater")

## One sample test
t.test(D$variable[D$group == "yes"])
mi.t.test(res$imputations, x = "variable", subset = D$group == "yes")
mi.t.test(res$imputations, x = "variable", mu = -1, subset = D$group == "yes",
          alternative = "less")
mi.t.test(res$imputations, x = "variable", mu = -1, subset = D$group == "yes",
          alternative = "greater")

## paired test
t.test(D$variable, D$pair, paired = TRUE)
mi.t.test(res$imputations, x = "variable", y = "pair", paired = TRUE)
</code></pre>

<hr>
<h2 id='mod.oneway.test'>Moderated 1-Way ANOVA</h2><span id='topic+mod.oneway.test'></span>

<h3>Description</h3>

<p>Performs moderated 1-Way ANOVAs based on Bioconductor package limma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod.oneway.test(x, group, adjust.method = "BH", sort.by = "none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod.oneway.test_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric matrix of data values.</p>
</td></tr>
<tr><td><code id="mod.oneway.test_+3A_group">group</code></td>
<td>
<p>an optional factor representing the groups.</p>
</td></tr>
<tr><td><code id="mod.oneway.test_+3A_adjust.method">adjust.method</code></td>
<td>
<p>see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code></p>
</td></tr>
<tr><td><code id="mod.oneway.test_+3A_sort.by">sort.by</code></td>
<td>
<p>see <code><a href="limma.html#topic+toptable">toptable</a></code></p>
</td></tr></table>
<p>, where <code>"logFC"</code>
corresponds to difference in means.
</p>


<h3>Details</h3>

<p>The function uses Bioconductor package limma to compute moderated 1-way ANOVAs.
For more details we refer to <code><a href="limma.html#topic+ebayes">ebayes</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame with the results.
</p>


<h3>References</h3>

<p>B. Phipson, S. Lee, I.J. Majewski, W.S. Alexander, G.H. Smyth (2016). Robust
hyperparameter estimation protects against hypervariable genes and improves
power to detect differential expression. <em>Annals of Applied Statistics</em>
10(2), 946-963.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+oneway.test">oneway.test</a></code>, <code>mod.t.test</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
X &lt;- rbind(matrix(rnorm(5*20), nrow = 5, ncol = 20),
           matrix(rnorm(5*20, mean = 1), nrow = 5, ncol = 20))
gr &lt;- factor(c(rep("A1", 5), rep("B2", 5), rep("C3", 5), rep("D4", 5)))
mod.oneway.test(X, gr)

## Welch 1-Way ANOVA (not moderated)
ow.test &lt;- function(x, g){
  res &lt;- oneway.test(x ~ g)
  c(res$statistic, res$p.value)
}
ow.res &lt;- t(apply(X, 1, ow.test, g = gr))
colnames(ow.res) &lt;- c("F", "p.value")
ow.res
</code></pre>

<hr>
<h2 id='mod.t.test'>Moderated t-Test</h2><span id='topic+mod.t.test'></span>

<h3>Description</h3>

<p>Performs moderated t-tests based on Bioconductor package limma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod.t.test(x, group = NULL, paired = FALSE, adjust.method = "BH",
           sort.by = "none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod.t.test_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric matrix of data values.</p>
</td></tr>
<tr><td><code id="mod.t.test_+3A_group">group</code></td>
<td>
<p>an optional factor representing the groups.</p>
</td></tr>
<tr><td><code id="mod.t.test_+3A_paired">paired</code></td>
<td>
<p>a logical indicating whether you want a paired test.</p>
</td></tr>
<tr><td><code id="mod.t.test_+3A_adjust.method">adjust.method</code></td>
<td>
<p>see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code></p>
</td></tr>
<tr><td><code id="mod.t.test_+3A_sort.by">sort.by</code></td>
<td>
<p>see <code><a href="limma.html#topic+toptable">toptable</a></code></p>
</td></tr></table>
<p>, where <code>"logFC"</code>
corresponds to difference in means.
</p>


<h3>Details</h3>

<p>The function uses Bioconductor package limma to compute moderated t-tests.
For more details we refer to <code><a href="limma.html#topic+ebayes">ebayes</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame with the results.
</p>


<h3>References</h3>

<p>B. Phipson, S. Lee, I.J. Majewski, W.S. Alexander, G.H. Smyth (2016). Robust
hyperparameter estimation protects against hypervariable genes and improves
power to detect differential expression. <em>Annals of Applied Statistics</em>
10(2), 946-963.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## One-sample test
X &lt;- matrix(rnorm(10*20, mean = 1), nrow = 10, ncol = 20)

mod.t.test(X)
## corresponds to
library(limma)
design &lt;- matrix(1, nrow = ncol(X), ncol = 1)
colnames(design) &lt;- "A"
fit1 &lt;- lmFit(X, design)
fit2 &lt;- eBayes(fit1)
topTable(fit2, coef = 1, number = Inf, confint = TRUE, sort.by = "none")[,-4]

## Two-sample test
set.seed(123)
X &lt;- rbind(matrix(rnorm(5*20), nrow = 5, ncol = 20),
           matrix(rnorm(5*20, mean = 1), nrow = 5, ncol = 20))
g2 &lt;- factor(c(rep("group 1", 10), rep("group 2", 10)))

mod.t.test(X, group = g2)
## corresponds to
design &lt;- model.matrix(~ 0 + g2)
colnames(design) &lt;- c("group1", "group2")
fit1 &lt;- lmFit(X, design)
cont.matrix &lt;- makeContrasts(group1vsgroup2="group1-group2", levels=design)
fit2 &lt;- contrasts.fit(fit1, cont.matrix)
fit3 &lt;- eBayes(fit2)
topTable(fit3, coef = 1, number = Inf, confint = TRUE, sort.by = "none")[,-4]

## Paired two-sample test
mod.t.test(X, group = g2, paired = TRUE)
</code></pre>

<hr>
<h2 id='normCI'> Confidence Intervals for Mean and Standard Deviation </h2><span id='topic+normCI'></span>

<h3>Description</h3>

<p>This function can be used to compute confidence intervals for mean and
standard deviation of a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normCI(x, mean = NULL, sd = NULL, conf.level = 0.95, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normCI_+3A_x">x</code></td>
<td>
<p> vector of observations. </p>
</td></tr>
<tr><td><code id="normCI_+3A_mean">mean</code></td>
<td>
<p> mean if known otherwise <code>NULL</code>. </p>
</td></tr>
<tr><td><code id="normCI_+3A_sd">sd</code></td>
<td>
<p> standard deviation if known otherwise <code>NULL</code>. </p>
</td></tr>
<tr><td><code id="normCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level. </p>
</td></tr>
<tr><td><code id="normCI_+3A_na.rm">na.rm</code></td>
<td>
<p> a logical value indicating whether NA values should be stripped before the computation proceeds. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard confidence intervals for mean and standard deviation are
computed that can be found in many textbooks, e.g. Chapter 4 in Altman et al. (2000).
</p>


<h3>Value</h3>

<p>A list with class <code>"confint"</code> containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p> the estimated mean and sd. </p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p> confidence interval(s) for mean and/or sd. </p>
</td></tr>
<tr><td><code>Infos</code></td>
<td>
<p> additional information. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>D. Altman, D. Machin, T. Bryant, M. Gardner (eds). Statistics with Confidence:
Confidence Intervals and Statistical Guidelines, 2nd edition 2000.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(50)
## mean and sd unknown
normCI(x)
## sd known
normCI(x, sd = 1)
## mean known
normCI(x, mean = 0)
</code></pre>

<hr>
<h2 id='normDiffCI'> Confidence Intervals for Difference of Means </h2><span id='topic+normDiffCI'></span>

<h3>Description</h3>

<p>This function can be used to compute confidence intervals for difference
of means assuming normal distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normDiffCI(x, y, conf.level = 0.95, paired = FALSE, method = "welch", na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normDiffCI_+3A_x">x</code></td>
<td>
<p> numeric vector of data values of group 1. </p>
</td></tr>
<tr><td><code id="normDiffCI_+3A_y">y</code></td>
<td>
<p> numeric vector of data values of group 2. </p>
</td></tr>
<tr><td><code id="normDiffCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level. </p>
</td></tr>
<tr><td><code id="normDiffCI_+3A_paired">paired</code></td>
<td>
<p> a logical value indicating whether the two groups are paired. </p>
</td></tr>
<tr><td><code id="normDiffCI_+3A_method">method</code></td>
<td>
<p> a character string specifing which method to use in the unpaired case; see details. </p>
</td></tr>
<tr><td><code id="normDiffCI_+3A_na.rm">na.rm</code></td>
<td>
<p> a logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard confidence intervals for the difference of means are
computed that can be found in many textbooks, e.g. Chapter 4 in Altman et al. (2000).
</p>
<p>The method <code>"classical"</code> assumes equal variances whereas methods
<code>"welch"</code> and <code>"hsu"</code> allow for unequal variances. The latter two
methods use different formulas for computing the degrees of freedom of the
respective t-distribution providing the quantiles in the confidence interval.
Instead of the Welch-Satterhwaite equation the method of Hsu uses the minimum
of the group sample sizes minus 1; see Section 6.8.3 of Hedderich and Sachs (2016).
</p>


<h3>Value</h3>

<p>A list with class <code>"confint"</code> containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p> point estimate (mean of differences or difference in means). </p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p> confidence interval. </p>
</td></tr>
<tr><td><code>Infos</code></td>
<td>
<p> additional information. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>D. Altman, D. Machin, T. Bryant, M. Gardner (eds). <em>Statistics with Confidence:
Confidence Intervals and Statistical Guidelines</em>, 2nd edition.
John Wiley and Sons 2000.
</p>
<p>J. Hedderich, L. Sachs. <em>Angewandte Statistik: Methodensammlung mit R</em>.
Springer 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(20)
y &lt;- rnorm(20, sd = 2)
## paired
normDiffCI(x, y, paired = TRUE)
## compare
normCI(x-y)

## unpaired
y &lt;- rnorm(10, mean = 1, sd = 2)
## classical
normDiffCI(x, y, method = "classical")
## Welch (default is in case of function t.test)
normDiffCI(x, y, method = "welch")
## Hsu
normDiffCI(x, y, method = "hsu")


## Monte-Carlo simulation: coverage probability
M &lt;- 10000
CIhsu &lt;- CIwelch &lt;- CIclass &lt;- matrix(NA, nrow = M, ncol = 2)
for(i in 1:M){
  x &lt;- rnorm(10)
  y &lt;- rnorm(30, sd = 0.1)
  CIclass[i,] &lt;- normDiffCI(x, y, method = "classical")$conf.int
  CIwelch[i,] &lt;- normDiffCI(x, y, method = "welch")$conf.int
  CIhsu[i,] &lt;- normDiffCI(x, y, method = "hsu")$conf.int
}
## coverage probabilies
## classical
sum(CIclass[,1] &lt; 0 &amp; 0 &lt; CIclass[,2])/M
## Welch
sum(CIwelch[,1] &lt; 0 &amp; 0 &lt; CIwelch[,2])/M
## Hsu
sum(CIhsu[,1] &lt; 0 &amp; 0 &lt; CIhsu[,2])/M

</code></pre>

<hr>
<h2 id='oneWayAnova'> A function for Analysis of Variance </h2><span id='topic+oneWayAnova'></span>

<h3>Description</h3>

<p>This function is a slight modification of function <code><a href="genefilter.html#topic+Anova">Anova</a></code> of
package <code>"genefilter"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oneWayAnova(cov, na.rm = TRUE, var.equal = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oneWayAnova_+3A_cov">cov</code></td>
<td>
<p> The covariate. It must have length equal to the number of
columns of the array that the result of <code>oneWayAnova</code> will be 
applied to. </p>
</td></tr>
<tr><td><code id="oneWayAnova_+3A_na.rm">na.rm</code></td>
<td>
<p> a logical value indicating whether <code>NA</code> values should be
stripped before the computation proceeds. </p>
</td></tr>
<tr><td><code id="oneWayAnova_+3A_var.equal">var.equal</code></td>
<td>
<p> a logical variable indicating whether to treat the variances
in the samples as equal.  If <code>TRUE</code>, then a simple F test for
the equality of means in a one-way analysis of variance is
performed.  If <code>FALSE</code>, an approximate method of Welch (1951)
is used, which generalizes the commonly known 2-sample Welch
test to the case of arbitrarily many samples. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returned by <code>oneWayAnova</code> uses <code><a href="stats.html#topic+oneway.test">oneway.test</a></code> 
to perform a one-way ANOVA, where <code>x</code> is the set of gene expressions. 
The F statistic for an overall effect is computed and the corresponding
p-value is returned.
</p>
<p>The function <code><a href="genefilter.html#topic+Anova">Anova</a></code> instead compares the computed 
p-value to a prespecified p-value and returns <code>TRUE</code>, if the computed p-value
is smaller than the prespecified one.
</p>


<h3>Value</h3>

<p><code>oneWayAnova</code> returns a function with bindings for <code>cov</code> that will
perform a one-way ANOVA.
</p>
<p>The covariate can be continuous, in which case the test is for a linear effect 
for the covariate.
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>R. Gentleman, V. Carey, W. Huber and F. Hahne (2006). 
genefilter: methods for filtering genes from microarray experiments. 
R package version 1.13.7.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+oneway.test">oneway.test</a></code>, <code><a href="genefilter.html#topic+Anova">Anova</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
af &lt;- oneWayAnova(c(rep(1,5),rep(2,5)))
af(rnorm(10))
</code></pre>

<hr>
<h2 id='optCutoff'> Compute the Optimal Cutoff for Binary Classification </h2><span id='topic+optCutoff'></span>

<h3>Description</h3>

<p>The function computes the optimal cutoff for various performance weasures for
binary classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optCutoff(pred, truth, namePos, perfMeasure = "Youden's J statistic",
          max = TRUE, parallel = FALSE, ncores, delta = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optCutoff_+3A_pred">pred</code></td>
<td>
<p> numeric values that shall be used for classification; e.g. probabilities
to belong to the positive group. </p>
</td></tr>
<tr><td><code id="optCutoff_+3A_truth">truth</code></td>
<td>
<p> true grouping vector or factor. </p>
</td></tr>
<tr><td><code id="optCutoff_+3A_namepos">namePos</code></td>
<td>
<p> value representing the positive group.</p>
</td></tr>
<tr><td><code id="optCutoff_+3A_perfmeasure">perfMeasure</code></td>
<td>
<p> a performance measure computed by function <code>perfMeasure</code>.</p>
</td></tr>
<tr><td><code id="optCutoff_+3A_max">max</code></td>
<td>
<p>logical value. Whether to maximize or minimize the performacne
measure.</p>
</td></tr>
<tr><td><code id="optCutoff_+3A_parallel">parallel</code></td>
<td>
<p> logical value. If <code>TRUE</code> packages foreach and doParallel
are used to parallelize the computations.</p>
</td></tr>
<tr><td><code id="optCutoff_+3A_ncores">ncores</code></td>
<td>
<p>integer value, number of cores that shall be used to parallelize
the computations.</p>
</td></tr>
<tr><td><code id="optCutoff_+3A_delta">delta</code></td>
<td>
<p>numeric value for setting up grid for optimization; start is 
minimum of <code>pred-delta</code>, end is maximum of <code>pred+delta</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is ablte to compute the optimal cutoff for various performance
measures, all performance measures that are implemented in function
<code>perfMeasures</code>.
</p>


<h3>Value</h3>

<p>Optimal cutoff and value of the optimized performance measure based on a 
simple grid search.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>## example from dataset infert
fit &lt;- glm(case ~ spontaneous+induced, data = infert, family = binomial())
pred &lt;- predict(fit, type = "response")
optCutoff(pred, truth = infert$case, namePos = 1)
</code></pre>

<hr>
<h2 id='or2rr'> Transform OR to RR </h2><span id='topic+or2rr'></span>

<h3>Description</h3>

<p>The function transforms a given odds-ratio (OR) to the respective
relative risk (RR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>or2rr(or, p0, p1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="or2rr_+3A_or">or</code></td>
<td>
<p> numeric vector: OR (odds-ratio). </p>
</td></tr>
<tr><td><code id="or2rr_+3A_p0">p0</code></td>
<td>
<p> numeric vector of length 1: incidence of the outcome of interest in the
nonexposed group.</p>
</td></tr>
<tr><td><code id="or2rr_+3A_p1">p1</code></td>
<td>
<p> numeric vector of length 1: incidence of the outcome of interest in the
exposed group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function transforms a given odds-ratio (OR) to the respective
relative risk (RR). It can also be used to transform the limits
of confidence intervals.
</p>
<p>The formulas can be derived by combining the formulas for RR and OR; see
also Zhang and Yu (1998).
</p>


<h3>Value</h3>

<p>relative risk.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Zhang, J. and Yu, K. F. (1998). What's the relative risk? A method of correcting the odds ratio in cohort
studies of common outcomes. <em>JAMA</em>, <b>280</b>(19):1690-1691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## We use data from Zhang and Yu (1998)

## OR to RR using OR and p0
or2rr(14.1, 0.05)

## compute p1
or2rr(14.1, 0.05)*0.05

## OR to RR using OR and p1
or2rr(14.1, p1 = 0.426)

## OR and 95% confidence interval
or2rr(c(14.1, 7.8, 27.5), 0.05)

## Logistic OR and 95% confidence interval
logisticOR &lt;- rbind(c(14.1, 7.8, 27.5),
                    c(8.7, 5.5, 14.3),
                    c(27.4, 17.2, 45.8),
                    c(4.5, 2.7, 7.8),
                    c(0.25, 0.17, 0.37),
                    c(0.09, 0.05, 0.14))
colnames(logisticOR) &lt;- c("OR", "2.5%", "97.5%")
rownames(logisticOR) &lt;- c("7.4", "4.2", "3.0", "2.0", "0.37", "0.14")
logisticOR

## p0
p0 &lt;- c(0.05, 0.12, 0.32, 0.27, 0.40, 0.40)

## Compute corrected RR
## helper function
or2rr.mat &lt;- function(or, p0){
  res &lt;- matrix(NA, nrow = nrow(or), ncol = ncol(or))
  for(i in seq_len(nrow(or)))
    res[i,] &lt;- or2rr(or[i,], p0[i])
  dimnames(res) &lt;- dimnames(or)
  res
}
RR &lt;- or2rr.mat(logisticOR, p0)
round(RR, 2)

## Results are not completely identical to Zhang and Yu (1998)
## what probably is caused by the fact that the logistic OR values
## provided in the table are rounded and are not exact values.
</code></pre>

<hr>
<h2 id='pairwise.auc'> Compute pairwise AUCs </h2><span id='topic+pairwise.auc'></span>

<h3>Description</h3>

<p>The function computes pairwise AUCs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.auc(x, g)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.auc_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="pairwise.auc_+3A_g">g</code></td>
<td>
<p> grouping vector or factor </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes pairwise areas under the receiver operating 
characteristic curves (AUC under ROC curves) using function <code><a href="#topic+AUC">AUC</a></code>.
</p>
<p>The implementation is in certain aspects analogously to 
<code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>.
</p>


<h3>Value</h3>

<p>Vector with pairwise AUCs.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>See Also</h3>

 <p><code><a href="#topic+AUC">AUC</a></code>, <code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(13)
x &lt;- rnorm(100)
g &lt;- factor(sample(1:4, 100, replace = TRUE))
levels(g) &lt;- c("a", "b", "c", "d")
pairwise.auc(x, g)
</code></pre>

<hr>
<h2 id='pairwise.fc'> Compute pairwise fold changes </h2><span id='topic+pairwise.fc'></span>

<h3>Description</h3>

<p>This function computes pairwise fold changes. It also works for 
logarithmic data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.fc(x, g, ave = mean, log = TRUE, base = 2, mod.fc = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.fc_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="pairwise.fc_+3A_g">g</code></td>
<td>
<p> grouping vector or factor </p>
</td></tr>
<tr><td><code id="pairwise.fc_+3A_ave">ave</code></td>
<td>
<p> function to compute the group averages. </p>
</td></tr>
<tr><td><code id="pairwise.fc_+3A_log">log</code></td>
<td>
<p> logical. Is the data logarithmic? </p>
</td></tr>
<tr><td><code id="pairwise.fc_+3A_base">base</code></td>
<td>
<p> If <code>log = TRUE</code>, the base which was used to compute
the logarithms. </p>
</td></tr>
<tr><td><code id="pairwise.fc_+3A_mod.fc">mod.fc</code></td>
<td>
<p> logical. Return modified fold changes? (see details) </p>
</td></tr>
<tr><td><code id="pairwise.fc_+3A_...">...</code></td>
<td>
<p> optional arguments to <code>ave</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes pairwise fold changes between groups, where
the group values are aggregated using the function which is 
given by the argument <code>ave</code>.
</p>
<p>The fold changes are returned in a slightly modified form if mod.fc = TRUE. 
Fold changes <code>FC</code> which are smaller than <code>1</code> are reported as
to <code>-1/FC</code>.
</p>
<p>The implementation is in certain aspects analogously to <code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>.
</p>


<h3>Value</h3>

<p>Vector with pairwise fold changes.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(13)
x &lt;- rnorm(100) ## assumed as log2-data
g &lt;- factor(sample(1:4, 100, replace = TRUE))
levels(g) &lt;- c("a", "b", "c", "d")
pairwise.fc(x, g)

## some small checks
res &lt;- by(x, list(g), mean)
2^(res[[1]] - res[[2]]) # a vs. b
-1/2^(res[[1]] - res[[3]]) # a vs. c
2^(res[[1]] - res[[4]]) # a vs. d
-1/2^(res[[2]] - res[[3]]) # b vs. c
-1/2^(res[[2]] - res[[4]]) # b vs. d
2^(res[[3]] - res[[4]]) # c vs. d
</code></pre>

<hr>
<h2 id='pairwise.fun'> Compute pairwise values for a given function </h2><span id='topic+pairwise.fun'></span>

<h3>Description</h3>

<p>The function computes pairwise values for a given function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.fun(x, g, fun, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.fun_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="pairwise.fun_+3A_g">g</code></td>
<td>
<p> grouping vector or factor </p>
</td></tr>
<tr><td><code id="pairwise.fun_+3A_fun">fun</code></td>
<td>
<p> some function where the first two arguments have to be
numeric vectors for which the function computes some
quantity; see example section below. </p>
</td></tr>
<tr><td><code id="pairwise.fun_+3A_...">...</code></td>
<td>
<p> additional arguments to fun. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes pairwise values for a given function.
</p>
<p>The implementation is in certain aspects analogously to 
<code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>.
</p>


<h3>Value</h3>

<p>Vector with pairwise function values.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>, <code><a href="#topic+pairwise.fc">pairwise.fc</a></code>,
<code><a href="#topic+pairwise.logfc">pairwise.logfc</a></code>, <code><a href="#topic+pairwise.auc">pairwise.auc</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(13)
x &lt;- rnorm(100)
g &lt;- factor(sample(1:4, 100, replace = TRUE))
levels(g) &lt;- c("a", "b", "c", "d")
pairwise.fun(x, g, fun = function(x, y) t.test(x,y)$p.value)
## in contrast to
pairwise.t.test(x, g, p.adjust.method = "none", pool.sd = FALSE)
</code></pre>

<hr>
<h2 id='pairwise.logfc'> Compute pairwise log-fold changes </h2><span id='topic+pairwise.logfc'></span>

<h3>Description</h3>

<p>The function computes pairwise log-fold changes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.logfc(x, g, ave = mean, log = TRUE, base = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.logfc_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="pairwise.logfc_+3A_g">g</code></td>
<td>
<p> grouping vector or factor </p>
</td></tr>
<tr><td><code id="pairwise.logfc_+3A_ave">ave</code></td>
<td>
<p> function to compute the group averages. </p>
</td></tr>
<tr><td><code id="pairwise.logfc_+3A_log">log</code></td>
<td>
<p> logical. Is the data logarithmic? </p>
</td></tr>
<tr><td><code id="pairwise.logfc_+3A_base">base</code></td>
<td>
<p> If <code>log = TRUE</code>, the base which was used to compute
the logarithms. </p>
</td></tr>
<tr><td><code id="pairwise.logfc_+3A_...">...</code></td>
<td>
<p> optional arguments to <code>ave</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes pairwise log-fold changes between groups, where
the group values are aggregated using the function which is 
given by the argument <code>ave</code>.
</p>
<p>The implementation is in certain aspects analogously to <code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>.
</p>


<h3>Value</h3>

<p>Vector with pairwise log-fold changes.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(13)
x &lt;- rnorm(100) ## assumed as log2-data
g &lt;- factor(sample(1:4, 100, replace = TRUE))
levels(g) &lt;- c("a", "b", "c", "d")
pairwise.logfc(x, g)

## some small checks
res &lt;- by(x, list(g), mean)
res[[1]] - res[[2]] # a vs. b
res[[1]] - res[[3]] # a vs. c
res[[1]] - res[[4]] # a vs. d
res[[2]] - res[[3]] # b vs. c
res[[2]] - res[[4]] # b vs. d
res[[3]] - res[[4]] # c vs. d
</code></pre>

<hr>
<h2 id='pairwise.mod.t.test'>Pairwise Moderated t-Tests</h2><span id='topic+pairwise.mod.t.test'></span>

<h3>Description</h3>

<p>Performs pairwise moderated t-tests based on Bioconductor package limma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.mod.t.test(x, group, adjust.method = "BH", sort.by = "none")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise.mod.t.test_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric matrix of data values.</p>
</td></tr>
<tr><td><code id="pairwise.mod.t.test_+3A_group">group</code></td>
<td>
<p>an optional factor representing the groups.</p>
</td></tr>
<tr><td><code id="pairwise.mod.t.test_+3A_adjust.method">adjust.method</code></td>
<td>
<p>see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code></p>
</td></tr>
<tr><td><code id="pairwise.mod.t.test_+3A_sort.by">sort.by</code></td>
<td>
<p>see <code><a href="limma.html#topic+toptable">toptable</a></code></p>
</td></tr></table>
<p>, where <code>"logFC"</code>
corresponds to difference in means.
</p>


<h3>Details</h3>

<p>The function uses Bioconductor package limma to compute pairwise moderated
t-tests. For more details we refer to <code><a href="limma.html#topic+ebayes">ebayes</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame with the results.
</p>


<h3>References</h3>

<p>B. Phipson, S. Lee, I.J. Majewski, W.S. Alexander, G.H. Smyth (2016). Robust
hyperparameter estimation protects against hypervariable genes and improves
power to detect differential expression. <em>Annals of Applied Statistics</em>
10(2), 946-963.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+oneway.test">oneway.test</a></code>, <code>mod.t.test</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
X &lt;- rbind(matrix(rnorm(5*20), nrow = 5, ncol = 20),
           matrix(rnorm(5*20, mean = 1), nrow = 5, ncol = 20))
gr &lt;- factor(c(rep("A1", 5), rep("B2", 5), rep("C3", 5), rep("D4", 5)))
mod.oneway.test(X, gr)
pairwise.mod.t.test(X, gr)
</code></pre>

<hr>
<h2 id='perfMeasures'> Compute Performance Measures and Scores for Binary Classification </h2><span id='topic+perfMeasures'></span><span id='topic+perfScores'></span>

<h3>Description</h3>

<p>The function computes various performance weasures and scores for binary classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perfMeasures(pred, pred.group, truth, namePos, cutoff = 0.5,
             weight = 0.5, wACC = weight, wPV = weight)
perfScores(pred, truth, namePos, weight = 0.5, wBS = weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perfMeasures_+3A_pred">pred</code></td>
<td>
<p> numeric values that shall be used for classification; e.g. probabilities
to belong to the positive group. </p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_pred.group">pred.group</code></td>
<td>
<p> vector or factor including the predicted group. If missing,
<code>pred.group</code> is computed from <code>pred</code>, where <code>pred &gt;= cutoff</code> is
classified as positive.</p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_truth">truth</code></td>
<td>
<p> true grouping vector or factor. </p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_namepos">namePos</code></td>
<td>
<p> value representing the positive group.</p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_cutoff">cutoff</code></td>
<td>
<p> cutoff value used for classification.</p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_weight">weight</code></td>
<td>
<p> weight used for computing weighted values. Must be in [0,1].</p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_wacc">wACC</code></td>
<td>
<p> weight used for computing the weighted accuracy. Must be in [0,1].</p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_wpv">wPV</code></td>
<td>
<p> weight used for computing the weighted predictive value. Must be in [0,1].</p>
</td></tr>
<tr><td><code id="perfMeasures_+3A_wbs">wBS</code></td>
<td>
<p> weight used for computing the weighted Brier score. Must be in [0,1].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>perfMeasures</code> computes various performance measures.
The measures are:
accuracy (ACC), probabiliy of correct classification (PCC), probability of
missclassification (PMC), error rate, sensitivity, specificity, prevalence,
no information rate, weighted accuracy (wACC), balanced accuracy (BACC),
informedness, Youden's J statistic, positive likelihood ratio (PLR),
negative likelihood ratio (NLR), positive predictive value (PPV),
negative predictive value (NPV), markedness, weighted predictive value,
balanced predictive value, F1 score, Matthews' correlation
coefficient (MCC), proportion of positive predictions, expected accuracy,
Cohen's kappa coefficient, and detection rate.
</p>
<p>These performance measures have in common that they require a dichotomization
(discretization) of a computed continuous classification function.
</p>
<p>The function <code>perfScores</code> computes various performance Scores.
The scores are:
area under the ROC curve (AUC), Gini index, Brier score, positive Brier score,
negative Brier score, weighted Brier score, and balanced Brier score.
</p>
<p>If the predictions (<code>pred</code>) are not in the interval [0,1] the standard
logistic function is applied to transform the values of <code>pred - cutoff</code>
to [0,1].
</p>


<h3>Value</h3>

<p><code>data.frame</code> with names of the performance measures, respectivey scores
and their respective values.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>G.W. Brier (1950). Verification of forecasts expressed in terms of probability.
<em>Mon. Wea. Rev.</em> <b>78</b>, 1-3.
</p>
<p>K.H. Brodersen, C.S. Ong, K.E. Stephan, J.M. Buhmann (2010). The balanced
accuracy and its posterior distribution. In <em>Pattern Recognition</em> (ICPR),
20th International Conference on, 3121-3124 (IEEE, 2010).
</p>
<p>J.A. Cohen (1960). A coefficient of agreement for nominal scales.
<em>Educational and Psychological Measurement</em> <b>20</b>, 3746.
</p>
<p>T. Fawcett (2006). An introduction to ROC analysis.
<em>Pattern Recognition Letters</em> <b>27</b>, 861-874.
</p>
<p>T.A. Gerds, T. Cai, M. Schumacher (2008). The performance of risk prediction
models. <em>Biom J</em> <b>50</b>, 457-479.
</p>
<p>D. Hand, R. Till (2001). A simple generalisation of the area under the ROC
curve for multiple class classification problems.
<em>Machine Learning</em> <b>45</b>, 171-186.
</p>
<p>J. Hernandez-Orallo, P.A. Flach, C. Ferri (2011). Brier curves: a new cost-
based visualisation of classifier performance. In L. Getoor and T. Scheffer (eds.)
<em>Proceedings of the 28th International Conference on Machine Learning</em> (ICML-11),
585???592 (ACM, New York, NY, USA).
</p>
<p>J. Hernandez-Orallo, P.A. Flach, C. Ferri (2012). A unified view of performance
metrics: Translating threshold choice into expected classification loss.
<em>J. Mach. Learn. Res.</em> <b>13</b>, 2813-2869.
</p>
<p>B.W. Matthews (1975). Comparison of the predicted and observed secondary
structure of t4 phage lysozyme. <em>Biochimica et Biophysica Acta</em> (BBA) -
Protein Structure <b>405</b>, 442-451.
</p>
<p>D.M. Powers (2011). Evaluation: From Precision, Recall and F-Factor to ROC,
Informedness, Markedness and Correlation. <em>Journal of Machine Learning
Technologies</em> <b>1</b>, 37-63.
</p>
<p>N.A. Smits (2010). A note on Youden's J and its cost ratio.
<em>BMC Medical Research Methodology</em> <b>10</b>, 89.
</p>
<p>B. Wallace, I. Dahabreh (2012). Class probability estimates are unreliable for
imbalanced data (and how to fix them). In <em>Data Mining</em> (ICDM), IEEE 12th
International Conference on, 695-04.
</p>
<p>J.W. Youden (1950). Index for rating diagnostic tests.
<em>Cancer</em> <b>3</b>, 32-35.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example from dataset infert
fit &lt;- glm(case ~ spontaneous+induced, data = infert, family = binomial())
pred &lt;- predict(fit, type = "response")

## with group numbers
perfMeasures(pred, truth = infert$case, namePos = 1)
perfScores(pred, truth = infert$case, namePos = 1)

## with group names
my.case &lt;- factor(infert$case, labels = c("control", "case"))
perfMeasures(pred, truth = my.case, namePos = "case")
perfScores(pred, truth = my.case, namePos = "case")

## on the scale of the linear predictors
pred2 &lt;- predict(fit)
perfMeasures(pred2, truth = infert$case, namePos = 1, cutoff = 0)
perfScores(pred2, truth = infert$case, namePos = 1)

## using weights
perfMeasures(pred, truth = infert$case, namePos = 1, weight = 0.3)
perfScores(pred, truth = infert$case, namePos = 1, weight = 0.3)
</code></pre>

<hr>
<h2 id='power.diagnostic.test'>Power calculations for a diagnostic test</h2><span id='topic+power.diagnostic.test'></span>

<h3>Description</h3>

<p>Compute sample size, power, delta, or significance level of a diagnostic test
for an expected sensititivy or specificity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.diagnostic.test(sens = NULL, spec = NULL,
                      n = NULL, delta = NULL, sig.level = 0.05,
                      power = NULL, prev = NULL, 
                      method = c("exact", "asymptotic"),
                      NMAX = 1e4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.diagnostic.test_+3A_sens">sens</code></td>
<td>
<p>Expected sensitivity; either <code>sens</code> or <code>spec</code> has to be specified.</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_spec">spec</code></td>
<td>
<p>Expected specificity; either <code>sens</code> or <code>spec</code> has to be specified.</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_n">n</code></td>
<td>
<p>Number of cases if <code>sens</code> and number of controls if <code>spec</code> is given.</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_delta">delta</code></td>
<td>
<p><code>sens</code>-<code>delta</code> resp. <code>spec</code>-<code>delta</code> is used as lower
confidence limit</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_sig.level">sig.level</code></td>
<td>
<p>Significance level (Type I error probability)</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_power">power</code></td>
<td>
<p>Power of test (1 minus Type II error probability)</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_prev">prev</code></td>
<td>
<p>Expected prevalence, if <code>NULL</code> prevalence is ignored which means <code>prev = 0.5</code>
is assumed.</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_method">method</code></td>
<td>
<p>exact or asymptotic formula; default <code>"exact"</code>.</p>
</td></tr>
<tr><td><code id="power.diagnostic.test_+3A_nmax">NMAX</code></td>
<td>
<p>Maximum sample size considered in case <code>method = "exact"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either <code>sens</code> or <code>spec</code> has to be specified which leads to 
computations for either cases or controls.
</p>
<p>Exactly one of the parameters <code>n</code>, <code>delta</code>, <code>sig.level</code>, 
and <code>power</code> must be passed as <code>NULL</code>, and that parameter is determined 
from the others. Notice that <code>sig.level</code> has a non-<code>NULL</code> default 
so <code>NULL</code> must be explicitly passed if you want to compute it.
</p>
<p>The computations are based on the formulas given in the Appendix of 
Flahault et al. (2005). Please be careful, in Equation (A1) the numerator
should be squared, in equation (A2) and (A3) the second exponent should be
n-i and not i.
</p>
<p>As noted in Chu and Cole (2007) power is not a monotonically increasing
function in n but rather saw toothed (see also Chernick and Liu (2002)).
Hence, in our calculations we use the more conservative approach II); 
i.e., the minimum sample size <code>n</code> such that the actual power is 
larger or equal <code>power</code> andsuch that for any sample size larger 
than <code>n</code> it also holds that the actual power is larger or equal 
<code>power</code>.
</p>


<h3>Value</h3>

<p>Object of class <code>"power.htest"</code>, a list of the arguments
(including the computed one) augmented with <code>method</code> and
<code>note</code> elements.
</p>


<h3>Note</h3>

<p><code>uniroot</code> is used to solve power equation for unknowns, so
you may see errors from it, notably about inability to bracket the
root when invalid arguments are given.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>A. Flahault, M. Cadilhac, and G. Thomas (2005). Sample size calculation 
should be performed for design accuracy in diagnostic test studies. 
<em>Journal of Clinical Epidemiology</em>, <b>58</b>(8):859-862.
</p>
<p>H. Chu and S.R. Cole (2007). Sample size calculation using exact methods 
in diagnostic test studies. 
<em>Journal of Clinical Epidemiology</em>, <b>60</b>(11):1201-1202.
</p>
<p>M.R. Chernick amd C.Y. Liu (2002). The saw-toothed behavior of power versus 
sample size and software solutions: single binomial proportion using 
exact methods. <em>Am Stat</em>, <b>56</b>:149-155.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## see n2 on page 1202 of Chu and Cole (2007)
power.diagnostic.test(sens = 0.99, delta = 0.14, power = 0.95) # 40
power.diagnostic.test(sens = 0.99, delta = 0.13, power = 0.95) # 43
power.diagnostic.test(sens = 0.99, delta = 0.12, power = 0.95) # 47

power.diagnostic.test(sens = 0.98, delta = 0.13, power = 0.95) # 50
power.diagnostic.test(sens = 0.98, delta = 0.11, power = 0.95) # 58

## see page 1201 of Chu and Cole (2007)
power.diagnostic.test(sens = 0.95, delta = 0.1, n = 93) ## 0.957
power.diagnostic.test(sens = 0.95, delta = 0.1, n = 93, power = 0.95, 
                      sig.level = NULL) ## 0.0496
power.diagnostic.test(sens = 0.95, delta = 0.1, n = 102) ## 0.968
power.diagnostic.test(sens = 0.95, delta = 0.1, n = 102, power = 0.95, 
                      sig.level = NULL) ## 0.0471
## yields 102 not 93!
power.diagnostic.test(sens = 0.95, delta = 0.1, power = 0.95)
</code></pre>

<hr>
<h2 id='power.hsu.t.test'>Power calculations for two sample Hsu t test</h2><span id='topic+power.hsu.t.test'></span>

<h3>Description</h3>

<p>Compute the power of the two-sample Hsu t test, or determine parameters
to obtain a target power; see Section 7.4.4 in Hedderich and Sachs (2016),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.hsu.t.test(n = NULL, delta = NULL, sd1 = 1, sd2 = 1, sig.level = 0.05,
                   power = NULL, alternative = c("two.sided", "one.sided"),
                   strict = FALSE, tol = .Machine$double.eps^0.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.hsu.t.test_+3A_n">n</code></td>
<td>
<p>number of observations (per group)</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_delta">delta</code></td>
<td>
<p>(expected) true difference in means</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_sd1">sd1</code></td>
<td>
<p>(expected) standard deviation of group 1</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_sd2">sd2</code></td>
<td>
<p>(expected) standard deviation of group 2</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_sig.level">sig.level</code></td>
<td>
<p>significance level (Type I error probability)</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_power">power</code></td>
<td>
<p>power of test (1 minus Type II error probability)</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_alternative">alternative</code></td>
<td>
<p>one- or two-sided test.  Can be abbreviated.</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_strict">strict</code></td>
<td>
<p>use strict interpretation in two-sided case</p>
</td></tr>
<tr><td><code id="power.hsu.t.test_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance used in root finding, the default
providing (at least) four significant digits.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exactly one of the parameters <code>n</code>, <code>delta</code>, <code>power</code>,
<code>sd1</code>, <code>sd2</code> and <code>sig.level</code> must be passed as <code>NULL</code>,
and that parameter is determined from the others. Notice that the last three
have non-NULL defaults, so NULL must be explicitly passed if you want to
compute them.
</p>
<p>If <code>strict = TRUE</code> is used, the power will include the probability of
rejection in the opposite direction of the true effect, in the two-sided
case. Without this the power will be half the significance level if the
true difference is zero.
</p>


<h3>Value</h3>

<p>Object of class <code>"power.htest"</code>, a list of the arguments
(including the computed one) augmented with <code>method</code> and
<code>note</code> elements.
</p>


<h3>Note</h3>

<p>The function and its documentation was adapted from <code>power.t.test</code>
implemented by Peter Dalgaard and based on previous work by Claus Ekstroem.
</p>
<p><code>uniroot</code> is used to solve the power equation for unknowns, so
you may see errors from it, notably about inability to bracket the
root when invalid arguments are given.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>J. Hedderich, L. Sachs. <em>Angewandte Statistik: Methodensammlung mit R</em>.
Springer 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+power.welch.t.test">power.welch.t.test</a></code>, <code><a href="stats.html#topic+power.t.test">power.t.test</a></code>,
<code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="stats.html#topic+uniroot">uniroot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## more conservative than classical or Welch t-test
 power.hsu.t.test(n = 20, delta = 1)
 power.hsu.t.test(power = .90, delta = 1)
 power.hsu.t.test(power = .90, delta = 1, alternative = "one.sided")

 ## sd1 = 0.5, sd2 = 1
 power.welch.t.test(delta = 0.5, sd1 = 0.5, sd2 = 1, power = 0.9)
 power.hsu.t.test(delta = 0.5, sd1 = 0.5, sd2 = 1, power = 0.9)

 
 ## empirical check
 M &lt;- 10000
 ps &lt;- numeric(M)
 for(i in seq_len(M)){
   x &lt;- rnorm(55, mean = 0, sd = 0.5)
   y &lt;- rnorm(55, mean = 0.5, sd = 1.0)
   ps[i] &lt;- hsu.t.test(x, y)$p.value
 }
 ## empirical power
 sum(ps &lt; 0.05)/M
 
</code></pre>

<hr>
<h2 id='power.nb.test'>Power calculation for comparing two negative binomial rates</h2><span id='topic+power.nb.test'></span>

<h3>Description</h3>

<p>Compute sample size or power for comparing two negative binomial rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.nb.test(n = NULL, mu0, mu1, RR, duration = 1, theta, ssize.ratio = 1,
              sig.level = 0.05, power = NULL, alternative = c("two.sided", "one.sided"),
              approach = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.nb.test_+3A_n">n</code></td>
<td>
<p>Sample size for group 0 (control group).</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_mu0">mu0</code></td>
<td>
<p>expected rate of events per time unit for group 0</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_mu1">mu1</code></td>
<td>
<p>expected rate of events per time unit for group 1</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_rr">RR</code></td>
<td>
<p>ratio of expected event rates: mu1/mu0</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_duration">duration</code></td>
<td>
<p>(average) treatment duration</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_theta">theta</code></td>
<td>
<p>theta parameter of negative binomial distribution; see <code><a href="MASS.html#topic+rnegbin">rnegbin</a></code></p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_ssize.ratio">ssize.ratio</code></td>
<td>
<p>ratio of sample sizes: n/n1 where n1 is sample size of group 1</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_sig.level">sig.level</code></td>
<td>
<p>Significance level (Type I error probability)</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_power">power</code></td>
<td>
<p>Power of test (1 minus Type II error probability)</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_alternative">alternative</code></td>
<td>
<p>one- or two-sided test</p>
</td></tr>
<tr><td><code id="power.nb.test_+3A_approach">approach</code></td>
<td>
<p>1, 2, or 3; see Zhu and Lakkis (2014).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exactly one of the parameters <code>n</code> and <code>power</code> must be passed as
<code>NULL</code>, and that parameter is determined from the other.
</p>
<p>The computations are based on the formulas given in Zhu and Lakkis (2014).
Please be careful, as we are using a slightly different parametrization
(<code>theta</code> = 1/k).
</p>
<p>Zhu and Lakkis (2014) based on their simulation studies recommend to use
their approach 2 or 3.
</p>


<h3>Value</h3>

<p>Object of class <code>"power.htest"</code>, a list of the arguments
(including the computed one) augmented with a <code>note</code> element.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>H. Zhu and H. Lakkis (2014). Sample size calculation for comparing two negative
binomial rates. <em>Statistics in Medicine</em>, <b>33</b>:376-387.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+rnegbin">rnegbin</a></code>, <code><a href="MASS.html#topic+glm.nb">glm.nb</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## examples from Table I in Zhu and Lakkis (2014)
## theta = 1/k, RR = rr, mu0 = r0, duration = mu_t
power.nb.test(mu0 = 0.8, RR = 0.85, theta = 1/0.4, duration = 0.75, power = 0.8, approach = 1)
power.nb.test(mu0 = 0.8, RR = 0.85, theta = 1/0.4, duration = 0.75, power = 0.8, approach = 2)
power.nb.test(mu0 = 0.8, RR = 0.85, theta = 1/0.4, duration = 0.75, power = 0.8, approach = 3)

power.nb.test(mu0 = 1.4, RR = 1.15, theta = 1/1.5, duration = 0.75, power = 0.8, approach = 1)
power.nb.test(mu0 = 1.4, RR = 1.15, theta = 1/1.5, duration = 0.75, power = 0.8, approach = 2)
power.nb.test(mu0 = 1.4, RR = 1.15, theta = 1/1.5, duration = 0.75, power = 0.8, approach = 3)


## examples from Table II in Zhu and Lakkis (2014) - seem to be total sample sizes
## can reproduce the results with mu_t = 1.0 (not 0.7!)
power.nb.test(mu0 = 2.0, RR = 0.5, theta = 1, duration = 1.0, ssize.ratio = 1,
              power = 0.8, approach = 1)
power.nb.test(mu0 = 2.0, RR = 0.5, theta = 1, duration = 1.0, ssize.ratio = 1,
              power = 0.8, approach = 2)
power.nb.test(mu0 = 2.0, RR = 0.5, theta = 1, duration = 1.0, ssize.ratio = 1,
              power = 0.8, approach = 3)

power.nb.test(mu0 = 10.0, RR = 1.5, theta = 1/5, duration = 1.0, ssize.ratio = 3/2,
              power = 0.8, approach = 1)
power.nb.test(mu0 = 10.0, RR = 1.5, theta = 1/5, duration = 1.0, ssize.ratio = 3/2,
              power = 0.8, approach = 2)
power.nb.test(mu0 = 10.0, RR = 1.5, theta = 1/5, duration = 1.0, ssize.ratio = 3/2,
              power = 0.8, approach = 3)


## examples from Table III in Zhu and Lakkis (2014)
power.nb.test(mu0 = 5.0, RR = 2.0, theta = 1/0.5, duration = 1, power = 0.8, approach = 1)
power.nb.test(mu0 = 5.0, RR = 2.0, theta = 1/0.5, duration = 1, power = 0.8, approach = 2)
power.nb.test(mu0 = 5.0, RR = 2.0, theta = 1/0.5, duration = 1, power = 0.8, approach = 3)


## examples from Table IV in Zhu and Lakkis (2014)
power.nb.test(mu0 = 5.9/3, RR = 0.4, theta = 0.49, duration = 3, power = 0.9, approach = 1)
power.nb.test(mu0 = 5.9/3, RR = 0.4, theta = 0.49, duration = 3, power = 0.9, approach = 2)
power.nb.test(mu0 = 5.9/3, RR = 0.4, theta = 0.49, duration = 3, power = 0.9, approach = 3)

power.nb.test(mu0 = 13/6, RR = 0.2, theta = 0.52, duration = 6, power = 0.9, approach = 1)
power.nb.test(mu0 = 13/6, RR = 0.2, theta = 0.52, duration = 6, power = 0.9, approach = 2)
power.nb.test(mu0 = 13/6, RR = 0.2, theta = 0.52, duration = 6, power = 0.9, approach = 3)


## see Section 5 of Zhu and Lakkis (2014)
power.nb.test(mu0 = 0.66, RR = 0.8, theta = 1/0.8, duration = 0.9, power = 0.9)
</code></pre>

<hr>
<h2 id='power.welch.t.test'>Power calculations for two sample Welch t test</h2><span id='topic+power.welch.t.test'></span>

<h3>Description</h3>

<p>Compute the power of the two-sample Welch t test, or determine parameters
to obtain a target power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.welch.t.test(n = NULL, delta = NULL, sd1 = 1, sd2 = 1, sig.level = 0.05,
                   power = NULL, alternative = c("two.sided", "one.sided"),
                   strict = FALSE, tol = .Machine$double.eps^0.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.welch.t.test_+3A_n">n</code></td>
<td>
<p>number of observations (per group)</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_delta">delta</code></td>
<td>
<p>(expected) true difference in means</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_sd1">sd1</code></td>
<td>
<p>(expected) standard deviation of group 1</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_sd2">sd2</code></td>
<td>
<p>(expected) standard deviation of group 2</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_sig.level">sig.level</code></td>
<td>
<p>significance level (Type I error probability)</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_power">power</code></td>
<td>
<p>power of test (1 minus Type II error probability)</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_alternative">alternative</code></td>
<td>
<p>one- or two-sided test.  Can be abbreviated.</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_strict">strict</code></td>
<td>
<p>use strict interpretation in two-sided case</p>
</td></tr>
<tr><td><code id="power.welch.t.test_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance used in root finding, the default
providing (at least) four significant digits.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exactly one of the parameters <code>n</code>, <code>delta</code>, <code>power</code>,
<code>sd1</code>, <code>sd2</code> and <code>sig.level</code> must be passed as <code>NULL</code>,
and that parameter is determined from the others. Notice that the last three
have non-NULL defaults, so NULL must be explicitly passed if you want to
compute them.
</p>
<p>If <code>strict = TRUE</code> is used, the power will include the probability of
rejection in the opposite direction of the true effect, in the two-sided
case. Without this the power will be half the significance level if the
true difference is zero.
</p>


<h3>Value</h3>

<p>Object of class <code>"power.htest"</code>, a list of the arguments
(including the computed one) augmented with <code>method</code> and
<code>note</code> elements.
</p>


<h3>Note</h3>

<p>The function and its documentation was adapted from <code>power.t.test</code>
implemented by Peter Dalgaard and based on previous work by Claus Ekstroem.
</p>
<p><code>uniroot</code> is used to solve the power equation for unknowns, so
you may see errors from it, notably about inability to bracket the
root when invalid arguments are given.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>S.L. Jan and G. Shieh (2011). Optimal sample sizes for Welch's test under
various allocation and cost considerations. <em>Behav Res Methods</em>, 43,
4:1014-22.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+power.t.test">power.t.test</a></code>, <code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="stats.html#topic+uniroot">uniroot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## identical results as power.t.test, since sd = sd1 = sd2 = 1
 power.welch.t.test(n = 20, delta = 1)
 power.welch.t.test(power = .90, delta = 1)
 power.welch.t.test(power = .90, delta = 1, alternative = "one.sided")

 ## sd1 = 0.5, sd2 = 1
 power.welch.t.test(delta = 1, sd1 = 0.5, sd2 = 1, power = 0.9)

 
 ## empirical check
 M &lt;- 10000
 ps &lt;- numeric(M)
 for(i in seq_len(M)){
   x &lt;- rnorm(15, mean = 0, sd = 0.5)
   y &lt;- rnorm(15, mean = 1, sd = 1.0)
   ps[i] &lt;- t.test(x, y)$p.value
 }
 ## empirical power
 sum(ps &lt; 0.05)/M
 
</code></pre>

<hr>
<h2 id='predValues'> Compute PPV and NPV. </h2><span id='topic+predValues'></span>

<h3>Description</h3>

<p>The function computes the positive (PPV) and negative predictive value (NPV)
given sensitivity, specificity and prevalence (pre-test probability).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predValues(sens, spec, prev)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predValues_+3A_sens">sens</code></td>
<td>
<p> numeric vector: sensitivities. </p>
</td></tr>
<tr><td><code id="predValues_+3A_spec">spec</code></td>
<td>
<p> numeric vector: specificities. </p>
</td></tr>
<tr><td><code id="predValues_+3A_prev">prev</code></td>
<td>
<p> numeric vector: prevalence.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the positive (PPV) and negative predictive value (NPV)
given sensitivity, specificity and prevalence (pre-test probability).
</p>
<p>It's a simple application of the Bayes formula.
</p>
<p>One can also specify vectors of length larger than 1 for sensitivity and specificity.
</p>


<h3>Value</h3>

<p>Vector or matrix with PPV and NPV.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example: HIV test 
## 1. ELISA screening test (4th generation)
predValues(sens = 0.999, spec = 0.998, prev = 0.001)
## 2. Western-Plot confirmation test
predValues(sens = 0.998, spec = 0.999996, prev = 1/3)

## Example: connection between sensitivity, specificity and PPV
sens &lt;- seq(0.6, 0.99, by = 0.01)
spec &lt;- seq(0.6, 0.99, by = 0.01)
ppv &lt;- function(sens, spec, pre) predValues(sens, spec, pre)[,1]
res &lt;- outer(sens, spec, ppv, pre = 0.1)
image(sens, spec, res, col = terrain.colors(256), main = "PPV for prevalence = 10%",
      xlim = c(0.59, 1), ylim = c(0.59, 1))
contour(sens, spec, res, add = TRUE)
</code></pre>

<hr>
<h2 id='print.confint'>Print Method for Confidence Intervals</h2><span id='topic+print.confint'></span>

<h3>Description</h3>

<p>Printing objects of class <code>"confint"</code> by a simple <code><a href="base.html#topic+print">print</a></code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'confint'
print(x, digits = getOption("digits"), prefix = "\t", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.confint_+3A_x">x</code></td>
<td>
<p>object of class <code>"confint"</code>.</p>
</td></tr>
<tr><td><code id="print.confint_+3A_digits">digits</code></td>
<td>
<p>number of significant digits to be used.</p>
</td></tr>
<tr><td><code id="print.confint_+3A_prefix">prefix</code></td>
<td>
<p>string, passed to <code><a href="base.html#topic+strwrap">strwrap</a></code> for displaying
the <code>method</code> component of the <code>mpe.test</code> object.</p>
</td></tr>
<tr><td><code id="print.confint_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>confint</code> object is just a named list of confidence intervals
and respective (point) estimates.
</p>


<h3>Value</h3>

<p>the argument <code>x</code>, invisibly, as for all <code><a href="base.html#topic+print">print</a></code>
methods.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+print.power.htest">print.power.htest</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(20)
(CI &lt;- normCI(x))
print(CI, digits = 3)
</code></pre>

<hr>
<h2 id='qboxplot'> Box Plots </h2><span id='topic+qboxplot'></span><span id='topic+qboxplot.default'></span><span id='topic+qboxplot.formula'></span>

<h3>Description</h3>

<p>Produce box-and-whisker plot(s) of the given (grouped) values. In contrast
to <code><a href="graphics.html#topic+boxplot">boxplot</a></code> quartiles are used instead of hinges
(which are not necessarily quartiles) the rest of the implementation is
identical to <code>boxplot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qboxplot(x, ...)

## S3 method for class 'formula'
qboxplot(formula, data = NULL, ..., subset, na.action = NULL, type = 7)

## Default S3 method:
qboxplot(x, ..., range = 1.5, width = NULL, varwidth = FALSE, 
        notch = FALSE, outline = TRUE, names, plot = TRUE, 
        border = par("fg"), col = NULL, log = "", 
        pars = list(boxwex = 0.8, staplewex = 0.5, outwex = 0.5), 
        horizontal = FALSE, add = FALSE, at = NULL, type = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qboxplot_+3A_formula">formula</code></td>
<td>
<p>a formula, such as <code>y ~ grp</code>, where <code>y</code> is a
numeric vector of data values to be split into groups according to
the grouping variable <code>grp</code> (usually a factor).</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_data">data</code></td>
<td>
<p>a data.frame (or list) from which the variables in
<code>formula</code> should be taken.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used for plotting.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is to ignore missing
values in either the response or the group.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_x">x</code></td>
<td>
<p>for specifying data from which the boxplots are to be
produced. Either a numeric vector, or a single list containing such
vectors. Additional unnamed arguments specify further data
as separate vectors (each corresponding to a component boxplot).
<code><a href="base.html#topic+NA">NA</a></code>s are allowed in the data.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_...">...</code></td>
<td>
<p>For the <code>formula</code> method, named arguments to be passed to
the default method.
</p>
<p>For the default method, unnamed arguments are additional data
vectors (unless <code>x</code> is a list when they are ignored),
and named arguments are arguments and graphical parameters to be
passed to <code><a href="graphics.html#topic+bxp">bxp</a></code> in addition to the ones
given by argument <code>pars</code> (and override those in <code>pars</code>).
</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_range">range</code></td>
<td>
<p>this determines how far the plot whiskers extend out
from the box.  If <code>range</code> is positive, the whiskers extend
to the most extreme data point which is no more than
<code>range</code> times the interquartile range from the box. A value
of zero causes the whiskers to extend to the data extremes.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_width">width</code></td>
<td>
<p>a vector giving the relative widths of the boxes making
up the plot.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_varwidth">varwidth</code></td>
<td>
<p>if <code>varwidth</code> is <code>TRUE</code>, the boxes are
drawn with widths proportional to the square-roots of the number
of observations in the groups.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_notch">notch</code></td>
<td>
<p>if <code>notch</code> is <code>TRUE</code>, a notch is drawn in
each side of the boxes.  If the notches of two plots do not
overlap this is &lsquo;strong evidence&rsquo; that the two medians differ
(Chambers <em>et al.</em>, 1983, p. 62).  See <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>
for the calculations used.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_outline">outline</code></td>
<td>
<p>if <code>outline</code> is not true, the outliers are
not drawn (as points whereas S+ uses lines).</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_names">names</code></td>
<td>
<p>group labels which will be printed under each boxplot.
Can be a character vector or an <a href="base.html#topic+expression">expression</a> (see
<a href="grDevices.html#topic+plotmath">plotmath</a>).</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_boxwex">boxwex</code></td>
<td>
<p>a scale factor to be applied to all boxes.  When there
are only a few groups, the appearance of the plot can be improved
by making the boxes narrower.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_staplewex">staplewex</code></td>
<td>
<p>staple line width expansion, proportional to box
width.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_outwex">outwex</code></td>
<td>
<p>outlier line width expansion, proportional to box
width.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> (the default) then a boxplot is
produced.  If not, the summaries which the boxplots are based on
are returned.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_border">border</code></td>
<td>
<p>an optional vector of colors for the outlines of the
boxplots.  The values in <code>border</code> are recycled if the
length of <code>border</code> is less than the number of plots.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_col">col</code></td>
<td>
<p>if <code>col</code> is non-null it is assumed to contain colors
to be used to colour the bodies of the box plots. By default they
are in the background colour.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_log">log</code></td>
<td>
<p>character indicating if x or y or both coordinates should
be plotted in log scale.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_pars">pars</code></td>
<td>
<p>a list of (potentially many) more graphical parameters,
e.g., <code>boxwex</code> or <code>outpch</code>; these are passed to
<code><a href="graphics.html#topic+bxp">bxp</a></code> (if <code>plot</code> is true); for details, see there.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_horizontal">horizontal</code></td>
<td>
<p>logical indicating if the boxplots should be
horizontal; default <code>FALSE</code> means vertical boxes.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_add">add</code></td>
<td>
<p>logical, if true <em>add</em> boxplot to current plot.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_at">at</code></td>
<td>
<p>numeric vector giving the locations where the boxplots should
be drawn, particularly when <code>add = TRUE</code>;
defaults to <code>1:n</code> where <code>n</code> is the number of boxes.</p>
</td></tr>
<tr><td><code id="qboxplot_+3A_type">type</code></td>
<td>
<p>an integer between 1 and 9 selecting one of nine quantile
algorithms; for more details see <code><a href="stats.html#topic+quantile">quantile</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generic function <code>qboxplot</code> currently has a default method
(<code>qboxplot.default</code>) and a formula interface (<code>qboxplot.formula</code>).
</p>
<p>If multiple groups are supplied either as multiple arguments or via a
formula, parallel boxplots will be plotted, in the order of the
arguments or the order of the levels of the factor (see
<code><a href="base.html#topic+factor">factor</a></code>).
</p>
<p>Missing values are ignored when forming boxplots.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table>
<tr><td><code>stats</code></td>
<td>
<p>a matrix, each column contains the extreme of the lower
whisker, the lower hinge, the median, the upper hinge and the
extreme of the upper whisker for one group/plot.  If all the inputs
have the same class attribute, so will this component.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>a vector with the number of observations in each group.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>a matrix where each column contains the lower and upper
extremes of the notch.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>the values of any data points which lie beyond the
extremes of the whiskers.</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>a vector of the same length as <code>out</code> whose elements
indicate to which group the outlier belongs.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>a vector of names for the groups.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>
<p>Chambers, J. M., Cleveland, W. S., Kleiner, B. and Tukey, P. A. (1983)
<em>Graphical Methods for Data Analysis.</em>  Wadsworth &amp; Brooks/Cole.
</p>
<p>Murrell, P. (2005) <em>R Graphics</em>. Chapman &amp; Hall/CRC Press.
</p>
<p>See also <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qbxp.stats">qbxp.stats</a></code> which does the computation,
<code><a href="graphics.html#topic+bxp">bxp</a></code> for the plotting and more examples;
and <code><a href="graphics.html#topic+stripchart">stripchart</a></code> for an alternative (with small data
sets).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## adapted examples from boxplot

## qboxplot on a formula:
qboxplot(count ~ spray, data = InsectSprays, col = "lightgray")
# *add* notches (somewhat funny here):
qboxplot(count ~ spray, data = InsectSprays,
        notch = TRUE, add = TRUE, col = "blue")

qboxplot(decrease ~ treatment, data = OrchardSprays,
        log = "y", col = "bisque")

rb &lt;- qboxplot(decrease ~ treatment, data = OrchardSprays, col="bisque")
title("Comparing boxplot()s and non-robust mean +/- SD")

mn.t &lt;- tapply(OrchardSprays$decrease, OrchardSprays$treatment, mean)
sd.t &lt;- tapply(OrchardSprays$decrease, OrchardSprays$treatment, sd)
xi &lt;- 0.3 + seq(rb$n)
points(xi, mn.t, col = "orange", pch = 18)
arrows(xi, mn.t - sd.t, xi, mn.t + sd.t,
       code = 3, col = "pink", angle = 75, length = .1)

## boxplot on a matrix:
mat &lt;- cbind(Uni05 = (1:100)/21, Norm = rnorm(100),
             `5T` = rt(100, df = 5), Gam2 = rgamma(100, shape = 2))
qboxplot(as.data.frame(mat),
        main = "qboxplot(as.data.frame(mat), main = ...)")
par(las=1)# all axis labels horizontal
qboxplot(as.data.frame(mat), main = "boxplot(*, horizontal = TRUE)",
        horizontal = TRUE)

## Using 'at = ' and adding boxplots -- example idea by Roger Bivand :

qboxplot(len ~ dose, data = ToothGrowth,
        boxwex = 0.25, at = 1:3 - 0.2,
        subset = supp == "VC", col = "yellow",
        main = "Guinea Pigs' Tooth Growth",
        xlab = "Vitamin C dose mg",
        ylab = "tooth length",
        xlim = c(0.5, 3.5), ylim = c(0, 35), yaxs = "i")
qboxplot(len ~ dose, data = ToothGrowth, add = TRUE,
        boxwex = 0.25, at = 1:3 + 0.2,
        subset = supp == "OJ", col = "orange")
legend(2, 9, c("Ascorbic acid", "Orange juice"),
       fill = c("yellow", "orange"))
</code></pre>

<hr>
<h2 id='qbxp.stats'> Box Plot Statistics </h2><span id='topic+qbxp.stats'></span>

<h3>Description</h3>

<p>This functions works identical to <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>.
It is typically called by another function to gather the statistics 
necessary for producing box plots, but may be invoked separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qbxp.stats(x, coef = 1.5, do.conf = TRUE, do.out = TRUE, type = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qbxp.stats_+3A_x">x</code></td>
<td>
<p> a numeric vector for which the boxplot will be constructed 
(<code><a href="base.html#topic+NA">NA</a></code>s and <code><a href="base.html#topic+NaN">NaN</a></code>s are allowed and omitted). </p>
</td></tr>
<tr><td><code id="qbxp.stats_+3A_coef">coef</code></td>
<td>
<p> it determines how far the plot &lsquo;whiskers&rsquo; extend out
from the box. If <code>coef</code> is positive, the whiskers extend to the
most extreme data point which is no more than <code>coef</code> times
the length of the box away from the box. A value of zero causes
the whiskers to extend to the data extremes (and no outliers be returned). </p>
</td></tr>
<tr><td><code id="qbxp.stats_+3A_do.conf">do.conf</code></td>
<td>
<p> logical; if <code>FALSE</code>, the <code>conf</code> component 
will be empty in the result. </p>
</td></tr>
<tr><td><code id="qbxp.stats_+3A_do.out">do.out</code></td>
<td>
<p> logical; if <code>FALSE</code>, <code>out</code> component will 
be empty in the result. </p>
</td></tr>
<tr><td><code id="qbxp.stats_+3A_type">type</code></td>
<td>
<p> an integer between 1 and 9 selecting one of nine quantile
algorithms; for more details see <code><a href="stats.html#topic+quantile">quantile</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The notches (if requested) extend to <code>+/-1.58 IQR/sqrt(n)</code>.
This seems to be based on the same calculations as the formula with 1.57 in
Chambers <em>et al.</em> (1983, p. 62), given in McGill <em>et al.</em>
(1978, p. 16).  They are based on asymptotic normality of the median
and roughly equal sample sizes for the two medians being compared, and
are said to be rather insensitive to the underlying distributions of
the samples.  The idea appears to be to give roughly a 95% confidence
interval for the difference in two medians.
</p>


<h3>Value</h3>

<p>List with named components as follows:
</p>
<table>
<tr><td><code>stats</code></td>
<td>
<p>a vector of length 5, containing the extreme of the
lower whisker, the first quartile, the median, the third quartile
and the extreme of the upper whisker.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the number of non-<code>NA</code> observations in the sample.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>the lower and upper extremes of the &lsquo;notch&rsquo;
(<code>if(do.conf)</code>). See the details.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>the values of any data points which lie beyond the
extremes of the whiskers (<code>if(do.out)</code>).</p>
</td></tr>
</table>
<p>Note that <code>$stats</code> and <code>$conf</code> are sorted in <em>in</em>creasing
order, unlike S, and that <code>$n</code> and <code>$out</code> include any
<code>+- Inf</code> values.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>Tukey, J. W. (1977) <em>Exploratory Data Analysis.</em> Section 2C.
</p>
<p>McGill, R., Tukey, J. W. and Larsen, W. A. (1978) Variations of box
plots. <em>The American Statistician</em> <b>32</b>, 12&ndash;16.
</p>
<p>Velleman, P. F. and Hoaglin, D. C. (1981) <em>Applications, Basics
and Computing of Exploratory Data Analysis.</em>  Duxbury Press.
</p>
<p>Emerson, J. D and Strenio, J. (1983). Boxplots and batch comparison.
Chapter 3 of <em>Understanding Robust and Exploratory Data
Analysis</em>, eds. D. C. Hoaglin, F. Mosteller and J. W. Tukey.  Wiley.
</p>
<p>Chambers, J. M., Cleveland, W. S., Kleiner, B. and Tukey, P. A. (1983)
<em>Graphical Methods for Data Analysis.</em>  Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+quantile">quantile</a></code>, <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## adapted example from boxplot.stats
x &lt;- c(1:100, 1000)
(b1 &lt;- qbxp.stats(x))
(b2 &lt;- qbxp.stats(x, do.conf=FALSE, do.out=FALSE))
stopifnot(b1$stats == b2$stats) # do.out=F is still robust
qbxp.stats(x, coef = 3, do.conf=FALSE)
## no outlier treatment:
qbxp.stats(x, coef = 0)

qbxp.stats(c(x, NA)) # slight change : n is 101
(r &lt;- qbxp.stats(c(x, -1:1/0)))
stopifnot(r$out == c(1000, -Inf, Inf))
</code></pre>

<hr>
<h2 id='quantileCI'> Confidence Intervals for Quantiles </h2><span id='topic+quantileCI'></span><span id='topic+medianCI'></span><span id='topic+madCI'></span>

<h3>Description</h3>

<p>These functions can be used to compute confidence intervals for quantiles
(including median).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantileCI(x, prob = 0.5, conf.level = 0.95, method = "exact",
           minLength = FALSE, na.rm = FALSE)
medianCI(x, conf.level = 0.95, method = "exact",
         minLength = FALSE, na.rm = FALSE)
madCI(x, conf.level = 0.95, method = "exact", minLength = FALSE,
      na.rm = FALSE, constant = 1.4826)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quantileCI_+3A_x">x</code></td>
<td>
<p> numeric data vector </p>
</td></tr>
<tr><td><code id="quantileCI_+3A_prob">prob</code></td>
<td>
<p> quantile </p>
</td></tr>
<tr><td><code id="quantileCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level </p>
</td></tr>
<tr><td><code id="quantileCI_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; see details. </p>
</td></tr>
<tr><td><code id="quantileCI_+3A_minlength">minLength</code></td>
<td>
<p> logical, see details</p>
</td></tr>
<tr><td><code id="quantileCI_+3A_na.rm">na.rm</code></td>
<td>
<p> logical, remove <code>NA</code> values. </p>
</td></tr>
<tr><td><code id="quantileCI_+3A_constant">constant</code></td>
<td>
<p> scale factor (see <code><a href="stats.html#topic+mad">mad</a></code>). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exact confidence interval (<code>method = "exact"</code>) is computed using binomial
probabilities; see Section 6.8.1 in Sachs and Hedderich (2009). If the result is not
unique, i.e. there is more than one interval with coverage proability closest to
<code>conf.level</code>, then a matrix of confidence intervals is returned.
If <code>minLength = TRUE</code>, an exact confidence interval with minimum length is
returned.
</p>
<p>The asymptotic confidence interval (<code>method = "asymptotic"</code>) is based on the
normal approximation of the binomial distribution; see Section 6.8.1 in Sachs and Hedderich (2009).
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p> the sample quantile. </p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p> a confidence interval for the sample quantile. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>L. Sachs and J. Hedderich (2009). Angewandte Statistik. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+binom.test">binom.test</a></code>, <code><a href="Hmisc.html#topic+binconf">binconf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## To get a non-trivial exact confidence interval for the median
## one needs at least 6 observations
set.seed(123)
x &lt;- rnorm(8)
## exact confidence interval not unique
medianCI(x)
madCI(x)

## minimum length exact confidence interval
medianCI(x, minLength = TRUE)
madCI(x, minLength = TRUE)

## asymptotic confidence interval
medianCI(x, method = "asymptotic")
madCI(x, method = "asymptotic")

## confidence interval for quantiles
quantileCI(x, prob = 0.4)
quantileCI(x, prob = 0.6)
</code></pre>

<hr>
<h2 id='repMeans'> Compute mean of replicated spots </h2><span id='topic+repMeans'></span>

<h3>Description</h3>

<p>Compute mean of replicated spots where additionally spot flags may incorporated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repMeans(x, flags, use.flags = NULL, ndups, spacing, method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repMeans_+3A_x">x</code></td>
<td>
<p> matrix or data.frame of expression values </p>
</td></tr>
<tr><td><code id="repMeans_+3A_flags">flags</code></td>
<td>
<p> matrix or data.frame of spot flags; must have same dimension as <code>x</code> </p>
</td></tr>
<tr><td><code id="repMeans_+3A_use.flags">use.flags</code></td>
<td>
<p> should flags be included and in which way; cf. section details </p>
</td></tr>
<tr><td><code id="repMeans_+3A_ndups">ndups</code></td>
<td>
<p> integer, number of replicates on chip. The number of rows of 
<code>x</code> must be divisible by <code>ndups</code> </p>
</td></tr>
<tr><td><code id="repMeans_+3A_spacing">spacing</code></td>
<td>
<p> the spacing between the rows of 'x' corresponding to 
replicated spots, <code>spacing = 1</code> for consecutive spots; 
cf. function <code><a href="limma.html#topic+unwrapdups">unwrapdups</a></code> in package 
<code>"limma"</code> </p>
</td></tr>
<tr><td><code id="repMeans_+3A_method">method</code></td>
<td>
<p> function to aggregate the replicated spots. If missing, the mean is used. </p>
</td></tr>
<tr><td><code id="repMeans_+3A_...">...</code></td>
<td>
<p> optional arguments to <code>method</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The incorporation of spot flags is controlled via argument <code>use.flags</code>.
</p>
<p><code>NULL</code>: flags are not used; minimum flag value of replicated 
spots is returned
</p>
<p><code>"max"</code>: only spots with flag value equal to the maximum flag value of 
replicated spots are used
</p>
<p><code>"median"</code>: only spots with flag values larger or equal to median of 
replicated spots are used
</p>
<p><code>"mean"</code>: only spots with flag values larger or equal to mean of replicated 
spots are used  
</p>


<h3>Value</h3>

<p>LIST with components
</p>
<table>
<tr><td><code>exprs</code></td>
<td>
<p>mean of expression values</p>
</td></tr>
<tr><td><code>flags</code></td>
<td>
<p>flags for mean expression values</p>
</td></tr>
</table>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>See Also</h3>

<p><code><a href="limma.html#topic+unwrapdups">unwrapdups</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## only a dummy example
M &lt;- matrix(rnorm(1000), ncol = 10)
FL &lt;- matrix(rpois(1000, lambda = 10), ncol = 10) # only for this example
res &lt;- repMeans(x = M, flags = FL, use.flags = "max", ndups = 5, spacing = 20)
</code></pre>

<hr>
<h2 id='risks'> Compute RR, OR, etc. </h2><span id='topic+risks'></span>

<h3>Description</h3>

<p>The function computes relative risk (RR), odds ration (OR), and several
other risk measures; see details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>risks(p0, p1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="risks_+3A_p0">p0</code></td>
<td>
<p> numeric vector of length 1: incidence of the outcome of interest in
the nonexposed group.</p>
</td></tr>
<tr><td><code id="risks_+3A_p1">p1</code></td>
<td>
<p> numeric vector of length 1: incidence of the outcome of interest in
the exposed group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes relative risk (RR), odds-ratio (OR), relative risk
reduction (RRR) resp. relative risk increase (RRI), absolute risk reduction (ARR)
resp. absolute risk increase (ARI), number needed to treat (NNT) resp.
number needed to harm (NNH).
</p>


<h3>Value</h3>

<p>Vector including several risk measures.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>See for instance:
Relative risk. (2016, November 4). In Wikipedia, The Free Encyclopedia.
Retrieved 19:58, November 4, 2016,
from <a href="https://en.wikipedia.org/w/index.php?title=Relative_risk&amp;oldid=747857409">https://en.wikipedia.org/w/index.php?title=Relative_risk&amp;oldid=747857409</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See worked example in Wikipedia
risks(p0 = 0.4, p1 = 0.1)
risks(p0 = 0.4, p1 = 0.5)
</code></pre>

<hr>
<h2 id='rrCI'> Compute Approximate Confidence Interval for RR. </h2><span id='topic+rrCI'></span>

<h3>Description</h3>

<p>The function computes an approximate confidence interval for the
relative risk (RR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrCI(a, b, c, d, conf.level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrCI_+3A_a">a</code></td>
<td>
<p> integer: events in exposed group.</p>
</td></tr>
<tr><td><code id="rrCI_+3A_b">b</code></td>
<td>
<p> integer: non-events in exposed group.</p>
</td></tr>
<tr><td><code id="rrCI_+3A_c">c</code></td>
<td>
<p> integer: events in non-exposed group.</p>
</td></tr>
<tr><td><code id="rrCI_+3A_d">d</code></td>
<td>
<p> integer: non-events in non-exposed group.</p>
</td></tr>
<tr><td><code id="rrCI_+3A_conf.level">conf.level</code></td>
<td>
<p> numeric: confidence level </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes an approximate confidence interval for the relative
risk (RR) based on the normal approximation; see Jewell (2004).
</p>


<h3>Value</h3>

<p>A list with class <code>"confint"</code> containing the following components:
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p> the estimated relative risk. </p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p> a confidence interval for the relative risk. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>Jewell, Nicholas P. (2004). Statistics for epidemiology. Chapman &amp; Hall/CRC.
</p>
<p>Relative risk. (2016, November 4). In Wikipedia, The Free Encyclopedia.
Retrieved 19:58, November 4, 2016,
from <a href="https://en.wikipedia.org/w/index.php?title=Relative_risk&amp;oldid=747857409">https://en.wikipedia.org/w/index.php?title=Relative_risk&amp;oldid=747857409</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See worked example in Wikipedia
rrCI(a = 15, b = 135, c = 100, d = 150)
rrCI(a = 75, b = 75, c = 100, d = 150)
</code></pre>

<hr>
<h2 id='simCorVars'> Simulate correlated variables. </h2><span id='topic+simCorVars'></span>

<h3>Description</h3>

<p>The function simulates a pair of correlated variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simCorVars(n, r, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simCorVars_+3A_n">n</code></td>
<td>
<p> integer: sample size. </p>
</td></tr>
<tr><td><code id="simCorVars_+3A_r">r</code></td>
<td>
<p> numeric: correlation.</p>
</td></tr>
<tr><td><code id="simCorVars_+3A_plot">plot</code></td>
<td>
<p>logical: generate scatter plot of the variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is mainly for teaching purposes and simulates <code>n</code> observations
from a pair of normal distributed variables with correlation <code>r</code>.
</p>
<p>By specifying <code>plot = TRUE</code> a scatter plot of the data is generated.
</p>


<h3>Value</h3>

<p>data.frame with entries <code>Var1</code> and <code>Var2</code>
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- simCorVars(n = 100, r = 0.8)
cor(res$Var1, res$Var2)
</code></pre>

<hr>
<h2 id='simPlot'> Plot of a similarity matrix. </h2><span id='topic+simPlot'></span>

<h3>Description</h3>

<p>Plot of similarity matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simPlot(x, col, minVal, labels = FALSE, lab.both.axes = FALSE, 
          labcols = "black", title = "", cex.title = 1.2, 
          protocol = FALSE, cex.axis = 0.8, 
          cex.axis.bar = 1, signifBar = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simPlot_+3A_x">x</code></td>
<td>
<p> quadratic data matrix. </p>
</td></tr>
<tr><td><code id="simPlot_+3A_col">col</code></td>
<td>
<p> colors palette for image. If missing, the <code>RdYlGn</code> palette
of <code>RColorBrewer</code> is used. </p>
</td></tr>
<tr><td><code id="simPlot_+3A_minval">minVal</code></td>
<td>
<p> numeric, minimum value which is display by a color; used to adjust <code>col</code></p>
</td></tr>
<tr><td><code id="simPlot_+3A_labels">labels</code></td>
<td>
<p> vector of character strings to be placed at the tickpoints,
labels for the columns of <code>x</code>. </p>
</td></tr>
<tr><td><code id="simPlot_+3A_lab.both.axes">lab.both.axes</code></td>
<td>
<p> logical, display labels on both axes </p>
</td></tr>
<tr><td><code id="simPlot_+3A_labcols">labcols</code></td>
<td>
<p> colors to be used for the labels of the columns of <code>x</code>.
<code>labcols</code> can have either length 1, in which case all 
the labels are displayed using the same color, or the same 
length as <code>labels</code>, in which case a color is specified 
for the label of each column of <code>x</code>. </p>
</td></tr>
<tr><td><code id="simPlot_+3A_title">title</code></td>
<td>
<p> character string, overall title for the plot. </p>
</td></tr>
<tr><td><code id="simPlot_+3A_cex.title">cex.title</code></td>
<td>
<p> A numerical value giving the amount by which plotting text
and symbols should be magnified relative to the default;
cf. <code><a href="graphics.html#topic+par">par</a></code>, <code>cex.main</code>. </p>
</td></tr>
<tr><td><code id="simPlot_+3A_protocol">protocol</code></td>
<td>
<p> logical, display color bar without numbers </p>
</td></tr>
<tr><td><code id="simPlot_+3A_cex.axis">cex.axis</code></td>
<td>
<p> The magnification to be used for axis annotation relative to the 
current setting of 'cex'; cf. <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="simPlot_+3A_cex.axis.bar">cex.axis.bar</code></td>
<td>
<p> The magnification to be used for axis annotation of the color 
bar relative to the current setting of 'cex'; cf. 
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="simPlot_+3A_signifbar">signifBar</code></td>
<td>
<p> integer indicating the precision to be used for the bar.</p>
</td></tr>
<tr><td><code id="simPlot_+3A_...">...</code></td>
<td>
<p> graphical parameters may also be supplied as arguments to the
function (see <code><a href="graphics.html#topic+par">par</a></code>). For comparison purposes, 
it is good to set <code>zlim=c(-1,1)</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions generates a so called similarity matrix. 
</p>
<p>If <code>min(x)</code> is smaller than <code>minVal</code>, the colors in <code>col</code> are 
adjusted such that the minimum value which is color coded is equal to <code>minVal</code>.
</p>


<h3>Value</h3>

<p><code>invisible()</code>
</p>


<h3>Note</h3>

<p>The function is a slight modification of function <code><a href="#topic+corPlot">corPlot</a></code> of package MKmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>Sandrine Dudoit, Yee Hwa (Jean) Yang, Benjamin Milo Bolstad and with 
contributions from Natalie Thorne, Ingrid Loennstedt and Jessica Mar.
sma: Statistical Microarray Analysis.<br />
http://www.stat.berkeley.edu/users/terry/zarray/Software/smacode.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## only a dummy example
M &lt;- matrix(rnorm(1000), ncol = 20)
colnames(M) &lt;- paste("Sample", 1:20)
M.cor &lt;- cor(M)

simPlot(M.cor, minVal = min(M.cor))
simPlot(M.cor, minVal = min(M.cor), lab.both.axes = TRUE)
simPlot(M.cor, minVal = min(M.cor), protocol = TRUE)
simPlot(M.cor, minVal = min(M.cor), signifBar = 1)
</code></pre>

<hr>
<h2 id='SNR'> Compute SNR </h2><span id='topic+SNR'></span><span id='topic+medSNR'></span><span id='topic+iqrSNR'></span>

<h3>Description</h3>

<p>The functions compute SNR as well as two robust versions of the SNR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SNR(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SNR_+3A_x">x</code></td>
<td>
<p> numeric vector. </p>
</td></tr>
<tr><td><code id="SNR_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions compute the (classical) coefficient of variation as well as
two robust variants.
</p>
<p><code>medSNR</code> uses the (standardized) MAD instead of SD and median instead of mean.
</p>
<p><code>iqrSNR</code> uses the (standardized) IQR instead of SD and median instead of mean.
</p>


<h3>Value</h3>

<p>SNR value.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>C.N.P.G. Arachchige, L.A. Prendergast and R.G. Staudte. Robust analogues
to the Coefficient of Variation. https://arxiv.org/abs/1907.01110.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 5% outliers
out &lt;- rbinom(100, prob = 0.05, size = 1)
sum(out)
x &lt;- (1-out)*rnorm(100, mean = 10, sd = 2) + out*25
SNR(x)
medSNR(x)
iqrSNR(x)
</code></pre>

<hr>
<h2 id='ssize.pcc'>Sample Size Planning for Developing Classifiers Using High Dimensional Data</h2><span id='topic+ssize.pcc'></span>

<h3>Description</h3>

<p>Calculate sample size for training set in developing classifiers using high
dimensional data. The calculation is based on the probability of correct classification 
(PCC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssize.pcc(gamma, stdFC, prev = 0.5, nrFeatures, sigFeatures = 20, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssize.pcc_+3A_gamma">gamma</code></td>
<td>
<p>tolerance between PCC(infty) and PCC(n).</p>
</td></tr>
<tr><td><code id="ssize.pcc_+3A_stdfc">stdFC</code></td>
<td>
<p>expected standardized fold-change; that is, expected fold-change devided
by within class standard deviation.</p>
</td></tr>
<tr><td><code id="ssize.pcc_+3A_prev">prev</code></td>
<td>
<p>expected prevalence.</p>
</td></tr>
<tr><td><code id="ssize.pcc_+3A_nrfeatures">nrFeatures</code></td>
<td>
<p>number of features (variables) considered.</p>
</td></tr>
<tr><td><code id="ssize.pcc_+3A_sigfeatures">sigFeatures</code></td>
<td>
<p>number of significatn features; default (20) should be sufficient 
for most if not all cases.</p>
</td></tr>
<tr><td><code id="ssize.pcc_+3A_verbose">verbose</code></td>
<td>
<p>print intermediate results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computations are based the algorithm provided in Section~4.2 of 
Dobbin and Simon (2007). Prevalence is incorporated by the simple rough
approach given in Section~4.4 (ibid.).
</p>
<p>The results for prevalence equal to $50%$ are identical to the numbers computed 
by <a href="https://brb.nci.nih.gov/brb/samplesize/samplesize4GE.html">https://brb.nci.nih.gov/brb/samplesize/samplesize4GE.html</a>. For 
other prevalences the numbers differ and are larger for our implementation. 
</p>


<h3>Value</h3>

<p>Object of class <code>"power.htest"</code>, a list of the arguments
(including the computed one) augmented with <code>method</code> and
<code>note</code> elements.
</p>


<h3>Note</h3>

<p><code>optimize</code> is used to solve equation (4.3) of Dobbin and Simon (2007), 
so you may see errors from it.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

 
<p>K. Dobbin and R. Simon (2007). Sample size planning for developing classifiers 
using high-dimensional DNA microarray data. 
<em>Biostatistics</em>, <b>8</b>(1):101-117.
</p>
<p>K. Dobbin, Y. Zhao, R. Simon (2008). How Large a Training Set is Needed to 
Develop a Classifier for Microarray Data?
<em>Clin Cancer Res.</em>, <b>14</b>(1):108-114.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optimize">optimize</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## see Table 2 of Dobbin et al. (2008)
g &lt;- 0.1
fc &lt;- 1.6
ssize.pcc(gamma = g, stdFC = fc, nrFeatures = 22000)

## see Table 3 of Dobbin et al. (2008)
g &lt;- 0.05
fc &lt;- 1.1
ssize.pcc(gamma = g, stdFC = fc, nrFeatures = 22000)
</code></pre>

<hr>
<h2 id='stringDist'>Function to compute distances between strings</h2><span id='topic+stringDist'></span>

<h3>Description</h3>

<p>The function can be used to compute distances between strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stringDist(x, y, method = "levenshtein", mismatch = 1, gap = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stringDist_+3A_x">x</code></td>
<td>
<p>character vector, first string</p>
</td></tr>
<tr><td><code id="stringDist_+3A_y">y</code></td>
<td>
<p>character vector, second string</p>
</td></tr>
<tr><td><code id="stringDist_+3A_method">method</code></td>
<td>
<p>character, name of the distance method. This must be 
<code>"levenshtein"</code> or <code>"hamming"</code>. Default is the classical
Levenshtein distance.</p>
</td></tr>
<tr><td><code id="stringDist_+3A_mismatch">mismatch</code></td>
<td>
<p>numeric, distance value for a mismatch between symbols</p>
</td></tr>
<tr><td><code id="stringDist_+3A_gap">gap</code></td>
<td>
<p>numeric, distance value for inserting a gap</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the Hamming and the Levenshtein (edit) distance of two given strings
(sequences). 
</p>
<p>In case of the Hamming distance the two strings must have the same length.
</p>
<p>In case of the Levenshtein (edit) distance a scoring and a trace-back matrix are computed
and are saved as attributes <code>"ScoringMatrix"</code> and <code>"TraceBackMatrix"</code>. 
The characters in the trace-back matrix reflect insertion of a gap in string <code>y</code> 
(<code>d</code>: deletion), match (<code>m</code>), mismatch (<code>mm</code>), 
and insertion of a gap in string <code>x</code> (<code>i</code>).
</p>


<h3>Value</h3>

<p><code>stringDist</code> returns an object of S3 class <code>"stringDist"</code> inherited 
from class <code>"dist"</code>; cf. <code><a href="stats.html#topic+dist">dist</a></code>.
</p>


<h3>Note</h3>

<p>The function is mainly for teaching purposes.
</p>
<p>For distances between strings and string alignments see also Bioconductor package
<span class="pkg">Biostrings</span>.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a> </p>


<h3>References</h3>

<p>R. Merkl and S. Waack (2009). Bioinformatik Interaktiv. Wiley.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="#topic+stringSim">stringSim</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "GACGGATTATG"
y &lt;- "GATCGGAATAG"
## Levenshtein distance
d &lt;- stringDist(x, y)
d
attr(d, "ScoringMatrix")
attr(d, "TraceBackMatrix")

## Hamming distance
stringDist(x, y)
</code></pre>

<hr>
<h2 id='stringSim'>Function to compute similarity scores between strings</h2><span id='topic+stringSim'></span>

<h3>Description</h3>

<p>The function can be used to compute similarity scores between strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stringSim(x, y, global = TRUE, match = 1, mismatch = -1, gap = -1, minSim = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stringSim_+3A_x">x</code></td>
<td>
<p>character vector, first string</p>
</td></tr>
<tr><td><code id="stringSim_+3A_y">y</code></td>
<td>
<p>character vector, second string</p>
</td></tr>
<tr><td><code id="stringSim_+3A_global">global</code></td>
<td>
<p>logical; global or local alignment</p>
</td></tr>
<tr><td><code id="stringSim_+3A_match">match</code></td>
<td>
<p>numeric, score for a match between symbols</p>
</td></tr>
<tr><td><code id="stringSim_+3A_mismatch">mismatch</code></td>
<td>
<p>numeric, score for a mismatch between symbols</p>
</td></tr>
<tr><td><code id="stringSim_+3A_gap">gap</code></td>
<td>
<p>numeric, penalty for inserting a gap</p>
</td></tr>
<tr><td><code id="stringSim_+3A_minsim">minSim</code></td>
<td>
<p>numeric, used as required minimum score in case of local alignments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes optimal alignment scores for global (Needleman-Wunsch) 
and local (Smith-Waterman) alignments with constant gap penalties. 
</p>
<p>Scoring and trace-back matrix are computed and saved in form of attributes 
<code>"ScoringMatrix"</code> and <code>"TraceBackMatrix"</code>. 
The characters in the trace-back matrix reflect insertion of a gap in 
string <code>y</code> (<code>d</code>: deletion), match (<code>m</code>), mismatch (<code>mm</code>), 
and insertion of a gap in string <code>x</code> (<code>i</code>). In addition <code>stop</code>
indicates that the minimum similarity score has been reached.
</p>


<h3>Value</h3>

<p><code>stringSim</code> returns an object of S3 class <code>"stringSim"</code> inherited 
from class <code>"dist"</code>; cf. <code><a href="stats.html#topic+dist">dist</a></code>.
</p>


<h3>Note</h3>

<p>The function is mainly for teaching purposes.
</p>
<p>For distances between strings and string alignments see also Bioconductor package
<span class="pkg">Biostrings</span>.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a> </p>


<h3>References</h3>

<p>R. Merkl and S. Waack (2009). Bioinformatik Interaktiv. Wiley.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+dist">dist</a></code>, <code><a href="#topic+stringDist">stringDist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "GACGGATTATG"
y &lt;- "GATCGGAATAG"

## optimal global alignment score
d &lt;- stringSim(x, y)
d
attr(d, "ScoringMatrix")
attr(d, "TraceBackMatrix")

## optimal local alignment score
d &lt;- stringSim(x, y, global = FALSE)
d
attr(d, "ScoringMatrix")
attr(d, "TraceBackMatrix")
</code></pre>

<hr>
<h2 id='thyroid'> Plot TSH, fT3 and fT4 with respect to reference range. </h2><span id='topic+thyroid'></span>

<h3>Description</h3>

<p>The function computes and plots TSH, fT3 and fT4 values with respect to
the provided reference range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thyroid(TSH, fT3, fT4, TSHref, fT3ref, fT4ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thyroid_+3A_tsh">TSH</code></td>
<td>
<p> numeric vector of length 1: measured TSH concentration.</p>
</td></tr>
<tr><td><code id="thyroid_+3A_ft3">fT3</code></td>
<td>
<p> numeric vector of length 1: measured fT3 concentration.</p>
</td></tr>
<tr><td><code id="thyroid_+3A_ft4">fT4</code></td>
<td>
<p> numeric vector of length 1: measured fT4 concentration.</p>
</td></tr>
<tr><td><code id="thyroid_+3A_tshref">TSHref</code></td>
<td>
<p> numeric vector of length 2: reference range TSH.</p>
</td></tr>
<tr><td><code id="thyroid_+3A_ft3ref">fT3ref</code></td>
<td>
<p> numeric vector of length 2: reference range fT3.</p>
</td></tr>
<tr><td><code id="thyroid_+3A_ft4ref">fT4ref</code></td>
<td>
<p> numeric vector of length 2: reference range fT4.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple function that computes the relative values of the measured values
with respect to the provided reference range and visualizes the values
using a barplot. Relative values between 40% and 60% are marked as O.K..
</p>


<h3>Value</h3>

<p>Invisible <code>data.frame</code> with the relative values.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>thyroid(TSH = 1.5, fT3 = 2.5, fT4 = 14, TSHref = c(0.2, 3.0),
        fT3ref = c(1.7, 4.2), fT4ref = c(7.6, 15.0))
</code></pre>

<hr>
<h2 id='traceBack'>
Function to trace back
</h2><span id='topic+traceBack'></span>

<h3>Description</h3>

<p>Function computes an optimal global or local alignment based on a trace back
matrix as provided by function <code><a href="#topic+stringDist">stringDist</a></code> or <code><a href="#topic+stringSim">stringSim</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>traceBack(D, global = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="traceBack_+3A_d">D</code></td>
<td>
<p>object of class <code>"stringDist"</code></p>
</td></tr>
<tr><td><code id="traceBack_+3A_global">global</code></td>
<td>
<p>logical,  global or local alignment</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes one possible optimal global or local alignment based on the trace back
matrix saved in an object of class <code>"stringDist"</code> or <code>"stringSim"</code>.
</p>


<h3>Value</h3>

<p>matrix: pairwise global/local alignment</p>


<h3>Note</h3>

<p>The function is mainly for teaching purposes.
</p>
<p>For distances between strings and string alignments see Bioconductor package
<span class="pkg">Biostrings</span>.
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>R. Merkl and S. Waack (2009). Bioinformatik Interaktiv. Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stringDist">stringDist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "GACGGATTATG"
y &lt;- "GATCGGAATAG"

## Levenshtein distance
d &lt;- stringDist(x, y)
## optimal global alignment
traceBack(d)

## Optimal global alignment score
d &lt;- stringSim(x, y)
## optimal global alignment
traceBack(d)

## Optimal local alignment score
d &lt;- stringSim(x, y, global = FALSE)
## optimal local alignment
traceBack(d, global = FALSE)
</code></pre>

<hr>
<h2 id='transformations'> New Transformations for Use with ggplot2 Package</h2><span id='topic+glog_trans'></span><span id='topic+glog10_trans'></span><span id='topic+glog2_trans'></span><span id='topic+scale_y_glog'></span><span id='topic+scale_x_glog'></span><span id='topic+scale_y_glog10'></span><span id='topic+scale_x_glog10'></span><span id='topic+scale_y_glog2'></span><span id='topic+scale_x_glog2'></span><span id='topic+neglog_breaks'></span><span id='topic+neglog_trans'></span><span id='topic+neglog10_trans'></span><span id='topic+neglog2_trans'></span><span id='topic+scale_y_neglog'></span><span id='topic+scale_x_neglog'></span><span id='topic+scale_y_neglog10'></span><span id='topic+scale_x_neglog10'></span><span id='topic+scale_y_neglog2'></span><span id='topic+scale_x_neglog2'></span>

<h3>Description</h3>

<p>The functions generate new transformations for the generalized logarithm and
the negative logarithm that can be used for transforming the axes in ggplot2
plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glog_trans(base = exp(1))
glog10_trans()
glog2_trans()
scale_y_glog(...)
scale_x_glog(...)
scale_y_glog10(...)
scale_x_glog10(...)
scale_y_glog2(...)
scale_x_glog2(...)
neglog_breaks(n = 5, base = 10)
neglog_trans(base = exp(1))
neglog10_trans()
neglog2_trans()
scale_y_neglog(...)
scale_x_neglog(...)
scale_y_neglog10(...)
scale_x_neglog10(...)
scale_y_neglog2(...)
scale_x_neglog2(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transformations_+3A_base">base</code></td>
<td>
<p> a positive or a positive or complex number: the base with
respect to which generalized and negative logarithms are computed.
Defaults to e=exp(1).</p>
</td></tr>
<tr><td><code id="transformations_+3A_...">...</code></td>
<td>
<p> Arguments passed on to scale_(x|y)_continuous.</p>
</td></tr>
<tr><td><code id="transformations_+3A_n">n</code></td>
<td>
<p> desired number of breaks.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions can be used to transform axes in ggplot2 plots. The implementation
is analogous to e.g. <code>scale_y_log10</code>.
</p>
<p>The negative logarithm is for instance of use in case of p values (e.g.
volcano plots),
</p>
<p>The functions were adapted from packages scales and ggplot2.
</p>


<h3>Value</h3>

<p>A transformation.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+scale_continuous">scale_continuous</a></code>, <code><a href="scales.html#topic+log_trans">log_trans</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
data(mpg)
p1 &lt;- ggplot(mpg, aes(displ, hwy)) + geom_point()
p1
p1 + scale_x_log10()
p1 + scale_x_glog10()
p1 + scale_y_log10()
p1 + scale_y_glog10()

## A volcano plot
x &lt;- matrix(rnorm(1000, mean = 10), nrow = 10)
g1 &lt;- rep("control", 10)
y1 &lt;- matrix(rnorm(500, mean = 11.25), nrow = 10)
y2 &lt;- matrix(rnorm(500, mean = 9.75), nrow = 10)
g2 &lt;- rep("treatment", 10)
group &lt;- factor(c(g1, g2))
Data &lt;- rbind(x, cbind(y1, y2))
pvals &lt;- apply(Data, 2, function(x, group) t.test(x ~ group)$p.value,
               group = group)
## compute log-fold change
logfc &lt;- function(x, group){
  res &lt;- tapply(x, group, mean)
  log2(res[1]/res[2])
}
lfcs &lt;- apply(Data, 2, logfc, group = group)
ps &lt;- data.frame(pvals = pvals, logfc = lfcs)
ggplot(ps, aes(x = logfc, y = pvals)) + geom_point() +
    geom_hline(yintercept = 0.05) + scale_y_neglog10() +
    geom_vline(xintercept = c(-0.1, 0.1)) + xlab("log-fold change") +
    ylab("-log10(p value)") + ggtitle("A Volcano Plot")
</code></pre>

<hr>
<h2 id='twoWayAnova'> A function for Analysis of Variance </h2><span id='topic+twoWayAnova'></span>

<h3>Description</h3>

<p>This function is a slight modification of function <code><a href="genefilter.html#topic+Anova">Anova</a></code> of
package <code>"genefilter"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twoWayAnova(cov1, cov2, interaction, na.rm = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twoWayAnova_+3A_cov1">cov1</code></td>
<td>
<p> The first covariate. It must have length equal to the number of
columns of the array that the result of <code>twoWayAnova</code> will be 
applied to. </p>
</td></tr>
<tr><td><code id="twoWayAnova_+3A_cov2">cov2</code></td>
<td>
<p> The second covariate. It must have length equal to the number of
columns of the array that the result of <code>twoWayAnova</code> will be 
applied to. </p>
</td></tr>
<tr><td><code id="twoWayAnova_+3A_interaction">interaction</code></td>
<td>
<p> logical, should interaction be considered </p>
</td></tr>
<tr><td><code id="twoWayAnova_+3A_na.rm">na.rm</code></td>
<td>
<p> a logical value indicating whether 'NA' values should be
stripped before the computation proceeds. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returned by <code>twoWayAnova</code> uses <code><a href="stats.html#topic+lm">lm</a></code> to fit 
a linear model of the form <code>lm(x ~ cov1*cov2)</code>, where <code>x</code> is the set 
of gene expressions. The F statistics for the main effects and the interaction are  
computed and the corresponding p-values are returned.
</p>


<h3>Value</h3>

<p><code>twoWayAnova</code> returns a function with bindings for <code>cov1</code> and 
<code>cov2</code>that will perform a two-way ANOVA.
</p>


<h3>Note</h3>

<p>A first version of this function appeared in package SLmisc.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl <a href="mailto:Matthias.Kohl@stamats.de">Matthias.Kohl@stamats.de</a></p>


<h3>References</h3>

<p>R. Gentleman, V. Carey, W. Huber and F. Hahne (2006). 
genefilter: methods for filtering genes from microarray experiments. 
R package version 1.13.7.
</p>


<h3>See Also</h3>

 <p><code><a href="genefilter.html#topic+Anova">Anova</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
af1 &lt;- twoWayAnova(c(rep(1,6),rep(2,6)), rep(c(rep(1,3), rep(2,3)), 2))
af2 &lt;- twoWayAnova(c(rep(1,6),rep(2,6)), rep(c(rep(1,3), rep(2,3)), 2), 
                   interaction = FALSE)
x &lt;- matrix(rnorm(12*10), nrow = 10)
apply(x, 1, af1)
apply(x, 1, af2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
