<!DOCTYPE html><html><head><title>Help for package NADIA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NADIA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#autotune_Amelia'><p>Perform imputation using Amelia package and EMB algorithm.</p></a></li>
<li><a href='#autotune_mice'><p>Automatical tuning of parameters and imputation using mice package.</p></a></li>
<li><a href='#autotune_missForest'><p>Perform imputation using missForest form missForest package.</p></a></li>
<li><a href='#autotune_missRanger'><p>Perform imputation using missRenger form missRegnger package.</p></a></li>
<li><a href='#autotune_softImpute'><p>Perform imputation using softImpute package</p></a></li>
<li><a href='#autotune_VIM_hotdeck'><p>Hot-Deck imputation using VIM package.</p></a></li>
<li><a href='#autotune_VIM_Irmi'><p>Perform imputation using VIM package and irmi function</p></a></li>
<li><a href='#autotune_VIM_kNN'><p>K nearest neighbor imputation using VIM package.</p></a></li>
<li><a href='#autotune_VIM_regrImp'><p>Perform imputation using VIM package and regressionImp function.</p></a></li>
<li><a href='#fetch_data'><p>Fetch data. Used in mice.reuse.</p></a></li>
<li><a href='#formula_creating'><p>Creating a formula for use in mice imputation evaluation.</p></a></li>
<li><a href='#mice.reuse'><p>Reuseble mice function</p></a></li>
<li><a href='#mids.append'><p>Joining mice objects. Used in mice.reuse.</p></a></li>
<li><a href='#missMDA_FMAD_MCA_PCA'><p>Perform imputation using MCA, PCA, or FMAD algorithm.</p></a></li>
<li><a href='#missMDA_MFA'><p>Perform imputation using MFA algorithm.</p></a></li>
<li><a href='#missMDA.reuse'><p>missMDA.reuse</p></a></li>
<li><a href='#PipeOpAmelia'><p>PipeOpAmelia</p></a></li>
<li><a href='#PipeOpHist_B'><p>PipeOpHist_B</p></a></li>
<li><a href='#PipeOpMean_B'><p>PipeOpMean_B</p></a></li>
<li><a href='#PipeOpMedian_B'><p>PipeOpMedian_B</p></a></li>
<li><a href='#PipeOpMice'><p>PipeOpMice</p></a></li>
<li><a href='#PipeOpMice_A'><p>PipeOpMice_A</p></a></li>
<li><a href='#PipeOpmissForest'><p>PipeOpmissForest</p></a></li>
<li><a href='#PipeOpmissMDA_MFA'><p>PipeOpmissMDA_MFA</p></a></li>
<li><a href='#PipeOpmissMDA_MFA_A'><p>PipeOpmissMDA_MFA_A</p></a></li>
<li><a href='#PipeOpmissMDA_PCA_MCA_FMAD'><p>PipeOpmissMDA_PCA_MCA_FMAD</p></a></li>
<li><a href='#PipeOpmissMDA_PCA_MCA_FMAD_A'><p>PipeOpmissMDA_PCA_MCA_FMAD_A</p></a></li>
<li><a href='#PipeOpmissRanger'><p>PipeOpmissRanger</p></a></li>
<li><a href='#PipeOpMode_B'><p>PipeOpMode_B</p></a></li>
<li><a href='#PipeOpOOR_B'><p>PipeOpOOR_B</p></a></li>
<li><a href='#PipeOpSample_B'><p>PipeOpSample_B</p></a></li>
<li><a href='#PipeOpSimulateMissings'><p>PipeOpSimulateMissings</p></a></li>
<li><a href='#PipeOpSoftImpute'><p>PipeOpSoftImpute</p></a></li>
<li><a href='#PipeOpVIM_HD'><p>PipeOpVIM_HD</p></a></li>
<li><a href='#PipeOpVIM_IRMI'><p>PipeOpVIM_IRMI</p></a></li>
<li><a href='#PipeOpVIM_kNN'><p>PipeOpVIM_kNN</p></a></li>
<li><a href='#PipeOpVIM_regrImp'><p>PipeOpVIM_regrImp</p></a></li>
<li><a href='#random_param_mice_search'><p>Performing randomSearch for selecting the best method and correlation or fraction of features used to create a prediction matrix.</p></a></li>
<li><a href='#replace_overimputes'><p>Replace overimputes. Used in mice.reuse.</p></a></li>
<li><a href='#simulate_missings'><p>Generate MCAR missings in dataset.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>NA Data Imputation Algorithms</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.2</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan Borowski, Piotr Fic</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jan Borowski &lt;janborowka7@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Creates a uniform interface for several advanced imputations missing data methods. Every available method can be used as a part of 'mlr3' pipelines which allows easy tuning and performance evaluation. Most of the used functions work separately on the training and test sets (imputation is trained on the training set and impute training data. After that imputation is again trained on the test set and impute test data).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), mlr3, mlr3pipelines, paradox</td>
</tr>
<tr>
<td>Imports:</td>
<td>missForest, missMDA, doParallel, testthat, mlr3learners,
rpart, glmnet, Amelia, VIM, softImpute, missRanger, methods,
mice, data.table, foreach</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ModelOriented/EMMA/issues">https://github.com/ModelOriented/EMMA/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, kableExtra, magrittr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-02 19:17:10 UTC; janbo</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-02 19:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='autotune_Amelia'>Perform imputation using Amelia package and EMB algorithm.</h2><span id='topic+autotune_Amelia'></span>

<h3>Description</h3>

<p>Function use EMB (Expectation-Maximization with Bootstrapping ) to impute missing data. Function performance is highly depend from data structure and
chosen parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_Amelia(
  df,
  col_type = NULL,
  percent_of_missing = NULL,
  col_0_1 = FALSE,
  parallel = TRUE,
  polytime = NULL,
  splinetime = NULL,
  intercs = FALSE,
  empir = NULL,
  verbose = FALSE,
  return_one = TRUE,
  m = 3,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_Amelia_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_parallel">parallel</code></td>
<td>
<p>If true parallel calculation is used.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_polytime">polytime</code></td>
<td>
<p>parameter pass to amelia function</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_splinetime">splinetime</code></td>
<td>
<p>parameter pass to amelia finction</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_intercs">intercs</code></td>
<td>
<p>parameter pass to amleia function</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_empir">empir</code></td>
<td>
<p>parameter pass to amelia function as empir in Amelia == empir*nrow(df). If empir dont set empir=nrow(df)*0.015.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_verbose">verbose</code></td>
<td>
<p>If true function will print on console.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_return_one">return_one</code></td>
<td>
<p>Decide if one dataset or amelia object will be returned.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_m">m</code></td>
<td>
<p>Number of datasets generated by amelia. If retrun_one=TRUE first dataset will be given.</p>
</td></tr>
<tr><td><code id="autotune_Amelia_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return one data.frame with imputed values or amelia object.
</p>


<h3>Author(s)</h3>

<p>James Honaker, Gary King, Matthew Blackwell (2011).
</p>


<h3>References</h3>

<p>James Honaker, Gary King, Matthew Blackwell (2011). Amelia II: A Program for Missing Data. Journal of Statistical Software, 45(7), 1-47. URL https://www.jstatsoft.org/v45/i07/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_Amelia(raw_data, col_type, percent_of_missing,parallel = FALSE)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='autotune_mice'>Automatical tuning of parameters and imputation using mice package.</h2><span id='topic+autotune_mice'></span>

<h3>Description</h3>

<p>Function impute missing data using mice functions. First perform  random search using linear models (generalized linear models if only
categorical values are available). Using glm its problematic. Function allows users to skip optimization in that case but it can lead to errors.
Function optimize prediction matrix and method. Other mice parameters like number of sets(m) or max number of iterations(maxit) should be set
as hight as possible for best results(higher values are required more time to perform imputation). If u chose to use one inputted dataset m is not important. More information can be found in <code><a href="#topic+random_param_mice_search">random_param_mice_search</a></code> and <code><a href="#topic+formula_creating">formula_creating</a></code> and <code><a href="mice.html#topic+mice">mice</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_mice(
  df,
  m = 5,
  maxit = 5,
  col_miss = NULL,
  col_no_miss = NULL,
  col_type = NULL,
  set_cor = 0.5,
  set_method = "pmm",
  percent_of_missing = NULL,
  low_corr = 0,
  up_corr = 1,
  methods_random = c("pmm"),
  iter = 5,
  random.seed = 123,
  optimize = TRUE,
  correlation = TRUE,
  return_one = TRUE,
  col_0_1 = FALSE,
  verbose = FALSE,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_mice_+3A_df">df</code></td>
<td>
<p>data frame for imputation.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_m">m</code></td>
<td>
<p>number of sets produced by mice.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iteration for mice.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_col_miss">col_miss</code></td>
<td>
<p>name of columns with missing values.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_col_no_miss">col_no_miss</code></td>
<td>
<p>character vector. Names of columns without NA.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_set_cor">set_cor</code></td>
<td>
<p>Correlation or fraction of featurs using if optimize= False</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_set_method">set_method</code></td>
<td>
<p>Method used if optimize=False. If NULL default method is used (more in methods_random section ).</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_low_corr">low_corr</code></td>
<td>
<p>double betwen 0,1 default 0 lower boundry of correlation set.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_up_corr">up_corr</code></td>
<td>
<p>double between 0,1 default 1 upper boundary of correlation set. Both of these parameters work the same for a fraction of features.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_methods_random">methods_random</code></td>
<td>
<p>set of methods to chose. Default 'pmm'. If seted on NULL this methods are used predictive mean matching (numeric data) logreg, logistic regression imputation (binary data, factor with 2 levels) polyreg, polytomous regression imputation for unordered categorical data (factor &gt; 2 levels) polr, proportional odds model for (ordered, &gt; 2 levels).</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_iter">iter</code></td>
<td>
<p>number of iteration for randomSearch.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_random.seed">random.seed</code></td>
<td>
<p>random seed.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_optimize">optimize</code></td>
<td>
<p>if user wont to optimize.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_correlation">correlation</code></td>
<td>
<p>If True correlation is using if Fales fraction of features. Default True.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_return_one">return_one</code></td>
<td>
<p>One or many imputed sets will be returned. Default True.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_verbose">verbose</code></td>
<td>
<p>If FALSE function didn't print on console.</p>
</td></tr>
<tr><td><code id="autotune_mice_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return imputed datasets or mids object containing multi imputation datasets.
</p>


<h3>Author(s)</h3>

<p>Stef van Buuren, Karin Groothuis-Oudshoorn (2011).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- mice::nhanes2

  col_type &lt;- 1:ncol(raw_data)
  for (i in col_type) {
    col_type[i] &lt;- class(raw_data[, i])
  }

  percent_of_missing &lt;- 1:ncol(raw_data)
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }
  col_no_miss &lt;- colnames(raw_data)[percent_of_missing == 0]
  col_miss &lt;- colnames(raw_data)[percent_of_missing &gt; 0]
  imp_data &lt;- autotune_mice(raw_data, optimize = FALSE, iter = 2,
   col_type = col_type, percent_of_missing = percent_of_missing,
   col_no_miss = col_no_miss, col_miss = col_miss)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='autotune_missForest'>Perform imputation using missForest form missForest package.</h2><span id='topic+autotune_missForest'></span>

<h3>Description</h3>

<p>Function use missForest package for data imputation. OBBerror (more in  <code><a href="#topic+autotune_mice">autotune_mice</a></code>) is used to perform grid search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_missForest(
  df,
  col_type = NULL,
  percent_of_missing = NULL,
  cores = NULL,
  ntree_set = c(100, 200, 500, 1000),
  mtry_set = NULL,
  parallel = FALSE,
  col_0_1 = FALSE,
  optimize = TRUE,
  ntree = 100,
  mtry = NULL,
  verbose = FALSE,
  maxiter = 20,
  maxnodes = NULL,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_missForest_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_cores">cores</code></td>
<td>
<p>integer.  Number of threads used by parallel calculations. By default approximately half of available CPU cores.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_ntree_set">ntree_set</code></td>
<td>
<p>integer vector. Vector contains numbers of tree for grid search.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_mtry_set">mtry_set</code></td>
<td>
<p>integer vector. Vector contains numbers of variables randomly sampled at each split.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_parallel">parallel</code></td>
<td>
<p>logical. If TRUE parallel calculation is using.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_col_0_1">col_0_1</code></td>
<td>
<p>decide if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_optimize">optimize</code></td>
<td>
<p>optimize inside function</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_ntree">ntree</code></td>
<td>
<p>ntree from missForest function</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_mtry">mtry</code></td>
<td>
<p>mtry form missforest function</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_verbose">verbose</code></td>
<td>
<p>If FALSE funtion didn't print on console.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_maxiter">maxiter</code></td>
<td>
<p>maxiter form missForest function.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_maxnodes">maxnodes</code></td>
<td>
<p>maxnodes from missForest function.</p>
</td></tr>
<tr><td><code id="autotune_missForest_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function try to use parallel backend if it's possible. Half of the available cores are used or number pass as cores param. (Number of used cores can't be higher then number of variables in df. If it happened a number of cores will be set at ncol(df)-2 unless this number is &lt;= 0 then cores =1).  To perform parallel calculation function use  <code><a href="doParallel.html#topic+registerDoParallel">registerDoParallel</a></code> to create parallel backend.
Creating backend can have significant time cost so for very small df cores=1 can speed up calculation. After calculation function turns off parallel backend. <br /> <br />   Gride search is used to chose a sample for each tree and the number of trees can be turn off. Params in grid search have significant influence on imputation quality but function should work on any reasonable values of this parameter.
</p>


<h3>Value</h3>

<p>Return data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p>Daniel J. Stekhoven (2013), Stekhoven D. J., &amp; Buehlmann, P. (2012).
</p>


<h3>References</h3>

<p>Daniel J. Stekhoven (2013). missForest: Nonparametric Missing Value Imputation using Random Forest. R package version 1.4.
Stekhoven D. J., &amp; Buehlmann, P. (2012). MissForest - non-parametric missing value imputation for mixed-type data. Bioinformatics, 28(1), 112-118.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_missForest(raw_data, col_type, percent_of_missing,
   optimize = FALSE,parallel = FALSE)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='autotune_missRanger'>Perform imputation using missRenger form missRegnger package.</h2><span id='topic+autotune_missRanger'></span>

<h3>Description</h3>

<p>Function use missRenger package for data imputation. Function use OBBerror (more in missForest documentation) to perform random search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_missRanger(
  df,
  percent_of_missing = NULL,
  maxiter = 10,
  random.seed = 123,
  mtry = NULL,
  num.trees = 500,
  verbose = FALSE,
  col_0_1 = FALSE,
  out_file = NULL,
  pmm.k = 5,
  optimize = TRUE,
  iter = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_missRanger_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iteration for missRanger algorithm</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_random.seed">random.seed</code></td>
<td>
<p>random seed use in imputation</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_mtry">mtry</code></td>
<td>
<p>sample fraction use by missRanger. This param isn't optimized automatically. If NULL default value from ranger package will be used.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_num.trees">num.trees</code></td>
<td>
<p>number of trees. If optimize == TRUE. Param set seq(10,num.trees,iter) will be used.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_verbose">verbose</code></td>
<td>
<p>If FALSE function doesn't print on console.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_col_0_1">col_0_1</code></td>
<td>
<p>decide if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_pmm.k">pmm.k</code></td>
<td>
<p>Number of candidate non-missing values to sample from in the predictive meanmatching step. 0 to avoid this step. If optimize == TRUE param set sample(1:pmm.k,iter) will be used. If pmm.k==0 missRanger == missForest.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_optimize">optimize</code></td>
<td>
<p>If TRUE inside optimization will be performed.</p>
</td></tr>
<tr><td><code id="autotune_missRanger_+3A_iter">iter</code></td>
<td>
<p>Number of iteration for a random search.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p>Michael Mayer (2019).
</p>


<h3>References</h3>

<p>Michael Mayer (2019). missRanger: Fast Imputation of Missing Values. R package version 2.1.0. https://CRAN.R-project.org/package=missRanger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_missRanger(raw_data[1:100,], percent_of_missing, optimize = FALSE)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE

</code></pre>

<hr>
<h2 id='autotune_softImpute'>Perform imputation using softImpute package</h2><span id='topic+autotune_softImpute'></span>

<h3>Description</h3>

<p>Function use softImpute to impute missing data it works only with numeric data. Columns with categorical values are imputed by a selected function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_softImpute(
  df,
  percent_of_missing = NULL,
  col_type = NULL,
  col_0_1 = FALSE,
  cat_Fun = VIM::maxCat,
  lambda = 0,
  rank.max = 2,
  type = "als",
  thresh = 1e-05,
  maxit = 100,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_softImpute_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_col_type">col_type</code></td>
<td>
<p>Character vector with types of columns.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_cat_fun">cat_Fun</code></td>
<td>
<p>Function to impute categorical features. Default maxCat (mode). Can be every function with input one character vector and return atomic object.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_lambda">lambda</code></td>
<td>
<p>nuclear-norm regularization parameter. If lambda=0, the algorithm reverts to &quot;hardImpute&quot;, for which convergence is typically slower. If null lambda is set automatically at the highest possible values.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_rank.max">rank.max</code></td>
<td>
<p>This restricts the rank of the solution. Defoult 2 if set as NULL rank.max=min(dim(X))-1.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_type">type</code></td>
<td>
<p>Chose of algoritm 'als' or 'svd . Defoult 'als'.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_thresh">thresh</code></td>
<td>
<p>Threshold for convergence.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="autotune_softImpute_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function use algorithm base on matrix whats meaning if only one numeric column exists in dataset imputation algorithm don't work. In that case, this column will be imputed using a function for categorical columns. Because of this algorithm is working properly only with at least two numeric features in the dataset. To specify column type argument col_type is used so it's possible to forcefully use for example numeric factors in imputation. Action like this can led to errors and its not.
</p>


<h3>Value</h3>

<p>Return one data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and Rahul Mazumder (2015).
</p>


<h3>References</h3>

<p>Trevor Hastie and Rahul Mazumder (2015). softImpute: Matrix Completion via Iterative Soft-Thresholded SVD. R package version 1.4. https://CRAN.R-project.org/package=softImpute
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_softImpute(raw_data, percent_of_missing, col_type)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='autotune_VIM_hotdeck'>Hot-Deck imputation using VIM package.</h2><span id='topic+autotune_VIM_hotdeck'></span>

<h3>Description</h3>

<p>Function perform hotdeck function from VIM package. Any tunable parameters aren't available in this algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_VIM_hotdeck(
  df,
  percent_of_missing = NULL,
  col_0_1 = FALSE,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_VIM_hotdeck_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without  target column.</p>
</td></tr>
<tr><td><code id="autotune_VIM_hotdeck_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_VIM_hotdeck_+3A_col_0_1">col_0_1</code></td>
<td>
<p>decide if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False.</p>
</td></tr>
<tr><td><code id="autotune_VIM_hotdeck_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p> Alexander Kowarik, Matthias Templ (2016) <a href="https://doi.org/10.18637/jss.v074.i07">doi:10.18637/jss.v074.i07</a>
</p>


<h3>References</h3>

<p>Alexander Kowarik, Matthias Templ (2016). Imputation with the R Package VIM. Journal of Statistical Software, 74(7), 1-16. doi:10.18637/jss.v074.i07
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_VIM_hotdeck(raw_data, percent_of_missing)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='autotune_VIM_Irmi'>Perform imputation using VIM package and irmi function</h2><span id='topic+autotune_VIM_Irmi'></span>

<h3>Description</h3>

<p>Function use IRMI (Iterative robust model-based imputation ) to impute missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_VIM_Irmi(
  df,
  col_type = NULL,
  percent_of_missing = NULL,
  eps = 5,
  maxit = 100,
  step = FALSE,
  robust = FALSE,
  init.method = "kNN",
  force = FALSE,
  col_0_1 = FALSE,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_VIM_Irmi_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_eps">eps</code></td>
<td>
<p>threshold for convergency</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_step">step</code></td>
<td>
<p>stepwise model selection is applied when the parameter is set to TRUE</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_robust">robust</code></td>
<td>
<p>if TRUE, robust regression methods will be applied (it's impossible to set step=TRUE and robust=TRUE at the same time)</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_init.method">init.method</code></td>
<td>
<p>Method for initialization of missing values (kNN or median)</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_force">force</code></td>
<td>
<p>if TRUE, the algorithm tries to find a solution in any case, possible by using different robust methods automatically. (should be set FALSE for simulation)</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="autotune_VIM_Irmi_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function can work with various different times depending on data size and structure. In some cases when selected param wouldn't work function try to run on default.  Most important param for both quality and reliability  its eps.
</p>


<h3>Value</h3>

<p>Return one data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p> Alexander Kowarik, Matthias Templ (2016) <a href="https://doi.org/10.18637/jss.v074.i07">doi:10.18637/jss.v074.i07</a>
</p>


<h3>References</h3>

<p>  Alexander Kowarik, Matthias Templ (2016). Imputation with the R Package VIM. Journal of Statistical Software, 74(7), 1-16. doi:10.18637/jss.v074.i07
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_VIM_Irmi(raw_data, col_type, percent_of_missing)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}

</code></pre>

<hr>
<h2 id='autotune_VIM_kNN'>K nearest neighbor imputation using VIM package.</h2><span id='topic+autotune_VIM_kNN'></span>

<h3>Description</h3>

<p>Function perform kNN function from VIM packge.
</p>
<p>@details  Function don't perform any inside param tuning. Users can change important param for kNN like number or nearest or aggregation functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_VIM_kNN(
  df,
  percent_of_missing = NULL,
  k = 5,
  numFun = stats::median,
  catFun = VIM::maxCat,
  col_0_1 = FALSE,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_VIM_kNN_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without  target column.</p>
</td></tr>
<tr><td><code id="autotune_VIM_kNN_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_VIM_kNN_+3A_k">k</code></td>
<td>
<p>Value of k use if optimize=FALSE</p>
</td></tr>
<tr><td><code id="autotune_VIM_kNN_+3A_numfun">numFun</code></td>
<td>
<p>function for aggregating the k Nearest Neighbours in the case of a numerical variable. Default median.</p>
</td></tr>
<tr><td><code id="autotune_VIM_kNN_+3A_catfun">catFun</code></td>
<td>
<p>function for aggregating the k Nearest Neighbours in the case of a categorical variable. Default mode.</p>
</td></tr>
<tr><td><code id="autotune_VIM_kNN_+3A_col_0_1">col_0_1</code></td>
<td>
<p>decide if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False.</p>
</td></tr>
<tr><td><code id="autotune_VIM_kNN_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Alexander Kowarik, Matthias Templ (2016) <a href="https://doi.org/10.18637/jss.v074.i07">doi:10.18637/jss.v074.i07</a>x
</p>


<h3>References</h3>

<p>Alexander Kowarik, Matthias Templ (2016). Imputation with the R Package VIM. Journal of Statistical Software, 74(7), 1-16. doi:10.18637/jss.v074.i07
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_VIM_kNN(raw_data, percent_of_missing)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='autotune_VIM_regrImp'>Perform imputation using VIM package and regressionImp function.</h2><span id='topic+autotune_VIM_regrImp'></span>

<h3>Description</h3>

<p>Function use Regression models to impute missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autotune_VIM_regrImp(
  df,
  col_type = NULL,
  percent_of_missing = NULL,
  col_0_1 = FALSE,
  robust = FALSE,
  mod_cat = FALSE,
  use_imputed = FALSE,
  out_file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autotune_VIM_regrImp_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_col_type">col_type</code></td>
<td>
<p>Character vector with types of columns.</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_robust">robust</code></td>
<td>
<p>TRUE/FALSE if robust regression should be used.</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_mod_cat">mod_cat</code></td>
<td>
<p>TRUE/FALSE if TRUE for categorical variables the level with the highest prediction probability is selected, otherwise it is sampled according to the probabilities.</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_use_imputed">use_imputed</code></td>
<td>
<p>TRUE/FALSE if TURE already imputed columns will be used to impute another.</p>
</td></tr>
<tr><td><code id="autotune_VIM_regrImp_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function impute one column per iteration to allow more control of imputation. All columns with missing values can be imputed with different formulas. For every new column to imputation one of four formula is used <br />
1. col to impute ~ all columns without missing  <br />
2. col to impute ~ all numeric columns without missing <br />
3. col to impute ~ first of columns without missing <br />
4. col to impute ~ first of numeric columns without missing <br />
For example, if formula 1 and 2 can't be used algorithm will try with formula 3. If all formula can't be used function will be stoped and error form tries with formula 4 or 3 presented. In some case, setting use_imputed on TRUE can solve this problem but in general its lower quality of imputation.
</p>


<h3>Value</h3>

<p>Return one data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p> Alexander Kowarik, Matthias Templ (2016) <a href="https://doi.org/10.18637/jss.v074.i07">doi:10.18637/jss.v074.i07</a>
</p>


<h3>References</h3>

<p>Alexander Kowarik, Matthias Templ (2016). Imputation with the R Package VIM. Journal of Statistical Software, 74(7), 1-16. doi:10.18637/jss.v074.i07
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- autotune_VIM_regrImp(raw_data, col_type, percent_of_missing)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='fetch_data'>Fetch data. Used in mice.reuse.</h2><span id='topic+fetch_data'></span>

<h3>Description</h3>

<p> Retrieve the main imputation object when within the
'mice:::sampler' post-imputation calling environment
and return the data object (including missingness)
stored within.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>fetch_data()
</code></pre>


<h3>Value</h3>

<p>data.frame
the original, non-imputed dataset of the mids object
</p>

<hr>
<h2 id='formula_creating'>Creating a formula for use in mice imputation evaluation.</h2><span id='topic+formula_creating'></span>

<h3>Description</h3>

<p>Function is used in <code><a href="#topic+autotune_mice">autotune_mice</a></code> but can be use sepraetly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formula_creating(df, col_miss, col_no_miss, col_type, percent_of_missing)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formula_creating_+3A_df">df</code></td>
<td>
<p>data.frame. Data frame to impute missing values with column names.</p>
</td></tr>
<tr><td><code id="formula_creating_+3A_col_miss">col_miss</code></td>
<td>
<p>character vector. Names of columns with NA.</p>
</td></tr>
<tr><td><code id="formula_creating_+3A_col_no_miss">col_no_miss</code></td>
<td>
<p>character vector. Names of columns without NA.</p>
</td></tr>
<tr><td><code id="formula_creating_+3A_col_type">col_type</code></td>
<td>
<p>character vector. A vector containing column type names.</p>
</td></tr>
<tr><td><code id="formula_creating_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function create a formula as follows. It creates one of the formulas its next possible formula impossible possible formula is created: <br /> 1. Numeric no missing ~ 3 numeric with most missing <br /> 2. Numeric no missing ~ all available numeric with missing <br /> 3. Numeric with less missing ~ 3 numeric with most missing <br /> 4. Numeric with less missing ~ all available numeric with missing <br /> 5. No numeric no missing ~ 3 most missing no numeric <br /> 6. No numeric no missing ~ all available no numeric with missing <br /> 7. No numeric with less missing ~ 3 no numeric with most missing <br /> 8. No numeric with less missing ~ all available no numeric with missing.
<br /> For example, if its impossible to create formula 1 and 2 formula 3 will be created but if it's possible to create formula 1 and 5 formula 1 will be created.
</p>


<h3>Value</h3>

<p>List with formula object[1] and information if its no numeric value in dataset[2].
</p>


<h3>References</h3>

<p>Stef van Buuren, Karin Groothuis-Oudshoorn (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1-67. URL https://www.jstatsoft.org/v45/i03/.
</p>

<hr>
<h2 id='mice.reuse'>Reuseble mice function</h2><span id='topic+mice.reuse'></span>

<h3>Description</h3>

<p>Reuse a previously fit multivariate imputation by chained equations to
impute values for previously unseen data without changing the imputation
fit (i.e. solely use the original training data to guide the imputation
models).
</p>
<p>Note: see https://github.com/stefvanbuuren/mice/issues/32 for discussion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mice.reuse(mids, newdata, maxit = 5, printFlag = TRUE, seed = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mice.reuse_+3A_mids">mids</code></td>
<td>
<p>: mids object
An object of class mids, typically produces by a previous call to mice() or mice.mids()</p>
</td></tr>
<tr><td><code id="mice.reuse_+3A_newdata">newdata</code></td>
<td>
<p>: data.frame
Previously unseen data of the same structur as used to generate 'mids'</p>
</td></tr>
<tr><td><code id="mice.reuse_+3A_maxit">maxit</code></td>
<td>
<p>: integer scalar
The number of additional Gibbs sampling iterations to refine the new imputations</p>
</td></tr>
<tr><td><code id="mice.reuse_+3A_printflag">printFlag</code></td>
<td>
<p>: logical scalar
A Boolean flag. If TRUE, diagnostic information during the Gibbs sampling iterations
will be written to the command window. The default is TRUE.</p>
</td></tr>
<tr><td><code id="mice.reuse_+3A_seed">seed</code></td>
<td>
<p>: integer scalar
An integer that is used as argument by the set.seed() for offsetting the random
number generator. Default is to use the last seed value stored in 'mids'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data : list of data.frames
the imputations of newdata
</p>
<p>lastSeedValue : integer vector
the random seed at the end of the procedure
</p>


<h3>Author(s)</h3>

<p>Patrick Rockenschaub git https://github.com/prockenschaub
</p>

<hr>
<h2 id='mids.append'>Joining mice objects. Used in mice.reuse.</h2><span id='topic+mids.append'></span>

<h3>Description</h3>

<p>Append one mids object to another. Both objects are expected to have the same variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mids.append(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mids.append_+3A_x">x</code></td>
<td>
<p>mids object provides both data and specification of imputation procedure</p>
</td></tr>
<tr><td><code id="mids.append_+3A_y">y</code></td>
<td>
<p>mids object only data information will be retained in the combined object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>  Only the data specific aspects are copied (i.e. $data, $imp, $where,
$nmis), all other information in 'y' is discarded. Therefore, only
the imputation model of 'x' is kept and 'y' must not contain missing
data in variables that did not have missing data in 'x' (but the
reverse is allowed).

</p>


<h3>Value</h3>

<p>mids object
a new mids object that contains all of 'x' and the additional data in 'y'
</p>

<hr>
<h2 id='missMDA_FMAD_MCA_PCA'>Perform imputation using MCA, PCA, or FMAD algorithm.</h2><span id='topic+missMDA_FMAD_MCA_PCA'></span>

<h3>Description</h3>

<p>Function use missMDA package to perform data imputation. Function can found the best number of dimensions for this imputation.
User can choose whether to return one imputed dataset or list or imputed datasets form Multiple Imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missMDA_FMAD_MCA_PCA(
  df,
  col_type = NULL,
  percent_of_missing = NULL,
  optimize_ncp = TRUE,
  set_ncp = 2,
  col_0_1 = FALSE,
  ncp.max = 5,
  return_one = TRUE,
  random.seed = 123,
  maxiter = 998,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  out_file = NULL,
  return_ncp = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_optimize_ncp">optimize_ncp</code></td>
<td>
<p>logical. If true number of dimensions used to predict the missing entries will be optimized. If False by default ncp = 2 it's used.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_set_ncp">set_ncp</code></td>
<td>
<p>intiger &gt;0. Number of dimensions used by algortims. Used only if optimize_ncp = Flase.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_ncp.max">ncp.max</code></td>
<td>
<p>integer corresponding to the maximum number of components to test. Default 5.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_return_one">return_one</code></td>
<td>
<p>One or many imputed sets will be returned. Default True.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_random.seed">random.seed</code></td>
<td>
<p>integer, by default random.seed = NULL implies that missing values are initially imputed by the mean of each variable. Other values leads to a random initialization</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iteration in algortihm.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_coeff.ridge">coeff.ridge</code></td>
<td>
<p>Value use in Regularized method.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_threshold">threshold</code></td>
<td>
<p>threshold for convergence.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_method">method</code></td>
<td>
<p>method used in imputation algoritm.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
<tr><td><code id="missMDA_FMAD_MCA_PCA_+3A_return_ncp">return_ncp</code></td>
<td>
<p>Function should return used ncp value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function use different algorithm to adjust for variable types in df. For only numeric data PCA will be used. MCA for only categorical and FMAD for mixed. If optimize==TRUE function will try to find optimal ncp if its not possible default ncp=2 will be used. In some cases ncp=1 will be used if ncp=2 don't work. For multiple imputations, if set ncp don't work error will be return.
</p>


<h3>Value</h3>

<p>Retrun one imputed data.frame if retrun_one=True or list of imputed data.frames if retrun_one=False.
</p>


<h3>Author(s)</h3>

<p> Julie Josse, Francois Husson (2016)   <a href="https://doi.org/10.18637/jss.v070.i01">doi:10.18637/jss.v070.i01</a>
</p>


<h3>References</h3>

<p>Julie Josse, Francois Husson (2016). missMDA: A Package for Handling Missing Values in Multivariate Data Analysis. Journal of Statistical Software, 70(1), 1-31. doi:10.18637/jss.v070.i01
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- missMDA_FMAD_MCA_PCA(raw_data, col_type, percent_of_missing, optimize_ncp = FALSE)
  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='missMDA_MFA'>Perform imputation using MFA algorithm.</h2><span id='topic+missMDA_MFA'></span>

<h3>Description</h3>

<p>Function use MFA (Multiple Factor Analysis) to impute missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missMDA_MFA(
  df,
  col_type = NULL,
  percent_of_missing = NULL,
  random.seed = NULL,
  ncp = 2,
  col_0_1 = FALSE,
  maxiter = 1000,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  out_file = NULL,
  imp_data = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missMDA_MFA_+3A_df">df</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_percent_of_missing">percent_of_missing</code></td>
<td>
<p>numeric vector. Vector contatining percent of missing data in columns for example  c(0,1,0,0,11.3,..)</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_random.seed">random.seed</code></td>
<td>
<p>integer, by default radndom.seed = NULL implies that missing values are initially imputed by the mean of each variable. Other values leads to a random initialization</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_ncp">ncp</code></td>
<td>
<p>Number of dimensions used by algorithm. Default 2.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_col_0_1">col_0_1</code></td>
<td>
<p>Decaid if add bonus column informing where imputation been done. 0 - value was in dataset, 1 - value was imputed. Default False. (Works only for returning one dataset).</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iteration in algorithm.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_coeff.ridge">coeff.ridge</code></td>
<td>
<p>Value use in Regularized method.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_threshold">threshold</code></td>
<td>
<p>for convergence.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_method">method</code></td>
<td>
<p>used in imputation algorithm.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_out_file">out_file</code></td>
<td>
<p>Output log file location if file already exists log message will be added. If NULL no log will be produced.</p>
</td></tr>
<tr><td><code id="missMDA_MFA_+3A_imp_data">imp_data</code></td>
<td>
<p>If True data abute imputation requaierd for missMDA.reuse its return.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Groups are created using the original column order and taking as much variable to one group as possible. MFA requires selecting group type but numeric types can only be set as 'c' - centered and 's' - scale to unit variance.
It's impossible to provide these conditions so numeric type is always set as 's'.  Because of that imputation can depend from column order. In this function, no param is set automatically but if selected ncp don't work function will try use ncp=1.
</p>


<h3>Value</h3>

<p>Return one data.frame with imputed values.
</p>


<h3>Author(s)</h3>

<p>   Julie Josse, Francois Husson (2016)  <a href="https://doi.org/10.18637/jss.v070.i01">doi:10.18637/jss.v070.i01</a>
</p>


<h3>References</h3>

<p>Julie Josse, Francois Husson (2016). missMDA: A Package for Handling Missing Values in Multivariate Data Analysis. Journal of Statistical Software, 70(1), 1-31. doi:10.18637/jss.v070.i01
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  raw_data &lt;- data.frame(
    a = as.factor(sample(c("red", "yellow", "blue", NA), 1000, replace = TRUE)),
    b = as.integer(1:1000),
    c = as.factor(sample(c("YES", "NO", NA), 1000, replace = TRUE)),
    d = runif(1000, 1, 10),
    e = as.factor(sample(c("YES", "NO"), 1000, replace = TRUE)),
    f = as.factor(sample(c("male", "female", "trans", "other", NA), 1000, replace = TRUE)))

  # Prepering col_type
  col_type &lt;- c("factor", "integer", "factor", "numeric", "factor", "factor")

  percent_of_missing &lt;- 1:6
  for (i in percent_of_missing) {
    percent_of_missing[i] &lt;- 100 * (sum(is.na(raw_data[, i])) / nrow(raw_data))
  }


  imp_data &lt;- missMDA_MFA(raw_data, col_type, percent_of_missing)

  # Check if all missing value was imputed
  sum(is.na(imp_data)) == 0
  # TRUE
}
</code></pre>

<hr>
<h2 id='missMDA.reuse'>missMDA.reuse</h2><span id='topic+missMDA.reuse'></span>

<h3>Description</h3>

<p>The function allows the user access to missMDA imputation in the A approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missMDA.reuse(
  train_data,
  new_data,
  col_type = NULL,
  ncp,
  random.seed = NULL,
  maxiter = 998,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  MFA = FALSE,
  MFA_Object = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missMDA.reuse_+3A_train_data">train_data</code></td>
<td>
<p>data.frame used for treining.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_new_data">new_data</code></td>
<td>
<p>data.frame. Df to impute with column names and without target column.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_col_type">col_type</code></td>
<td>
<p>character vector. Vector containing column type names.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_ncp">ncp</code></td>
<td>
<p>return when the training data set was imputed.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_random.seed">random.seed</code></td>
<td>
<p>Integer, by default random.seed = NULL implies that missing values are initially imputed by the mean of each variable. Other values leads to a random initialization</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iteration in algortihm.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_coeff.ridge">coeff.ridge</code></td>
<td>
<p>Value use in Regularized method.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_threshold">threshold</code></td>
<td>
<p>threshold for convergence.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_method">method</code></td>
<td>
<p>method used in imputation algoritm.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_mfa">MFA</code></td>
<td>
<p>If TRUE MFA is used if not MCA, PCA, or FMAD algorithm.</p>
</td></tr>
<tr><td><code id="missMDA.reuse_+3A_mfa_object">MFA_Object</code></td>
<td>
<p>Object produce by missMDA_MFA required to perform MFA imputation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function use the same trick as in mice.reuse (new data are changed in NA in imputation stage and added back after it ). Because in missMDA is impossible to completely ignore new rows. We set their weights on 1e-300 when weights in the training set equal 1.
</p>

<hr>
<h2 id='PipeOpAmelia'>PipeOpAmelia</h2><span id='topic+PipeOpAmelia'></span>

<h3>Description</h3>

<p>Implements EMB methods as mlr3 pipeline more about Amelia <code><a href="#topic+autotune_Amelia">autotune_Amelia</a></code> or <a href="https://cran.r-project.org/package=Amelia">https://cran.r-project.org/package=Amelia</a>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_Amelia"</code>.
</p>
</li>
<li> <p><code>m</code> :: <code>integer(1)</code><br />
Number of datasets generated by Amelia, default <code>3</code>.
</p>
</li>
<li> <p><code>polytime</code> :: <code>integer(1)</code><br />
Integer between 0 and 3 indicating what power of polynomial should be included in the imputation model to account for the effects of time. A setting of 0 would indicate constant levels, 1 would indicate linear time effects, 2 would indicate squared effects, and 3 would indicate cubic time effects, default <code>NULL</code>.
</p>
</li>
<li> <p><code>splinetime</code> :: <code>integer(1)</code><br />
Integer value of 0 or greater to control cubic smoothing splines of time. Values between 0 and 3 create a simple polynomial of time (identical to the polytime argument). Values k greater than 3 create a spline with an additional k-3 knotpoints, default <code>NULL</code>.
</p>
</li>
<li> <p><code>intercs</code> :: <code>logical(1)</code><br />
Variable indicating if the time effects of polytime should vary across the cross-section, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>empir</code> :: <code>double(1)</code><br />
Number indicating level of the empirical (or ridge) prior. This prior shrinks the covariances of the data, but keeps the means and variances the same for problems of high missingness, small N's or large correlations among the variables. Should be kept small, perhaps 0.5 to 1 percent of the rows of the data; a reasonable upper bound is around 10 percent of the rows of the data. If empir is not set, empir=nrow(df)*0.015, default <code>NULL</code>.
</p>
</li>
<li> <p><code>parallel</code> :: <code>double(1)</code><br />
If true parallel calculation is used, default <code>TRUE</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>Amelia_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Amelia_imputation-new"><code>PipeOpAmelia$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Amelia_imputation-clone"><code>PipeOpAmelia$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Amelia_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpAmelia$new(
  id = "impute_Amelia_B",
  polytime = NULL,
  splinetime = NULL,
  intercs = FALSE,
  empir = NULL,
  m = 3,
  parallel = TRUE,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-Amelia_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpAmelia$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

# Using debug learner for example purpose

  graph &lt;- PipeOpAmelia$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  graph_learner$param_set$values$impute_Amelia_B.parallel &lt;- FALSE


  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpHist_B'>PipeOpHist_B</h2><span id='topic+PipeOpHist_B'></span>

<h3>Description</h3>

<p>Impute numerical features by histogram in approach B (independently during the training and prediction phase).
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default '&quot;impute_hist_B&quot;'.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>Hist_B_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Hist_B_imputation-new"><code>PipeOpHist_B$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Hist_B_imputation-clone"><code>PipeOpHist_B$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Hist_B_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpHist_B$new(id = "impute_hist_B", param_vals = list())</pre></div>


<hr>
<a id="method-Hist_B_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpHist_B$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

# Using debug learner for example purpose

  graph &lt;- PipeOpHist_B$new() %&gt;&gt;%  LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpMean_B'>PipeOpMean_B</h2><span id='topic+PipeOpMean_B'></span>

<h3>Description</h3>

<p>Impute numerical features by their mean in approach B (independently during the training and prediction phase).
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_mean_B"</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>Mean_B_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Mean_B_imputation-new"><code>PipeOpMean_B$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Mean_B_imputation-clone"><code>PipeOpMean_B$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Mean_B_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMean_B$new(id = "impute_mean_B", param_vals = list())</pre></div>


<hr>
<a id="method-Mean_B_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMean_B$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose

  graph &lt;- PipeOpMean_B$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpMedian_B'>PipeOpMedian_B</h2><span id='topic+PipeOpMedian_B'></span>

<h3>Description</h3>

<p>Impute features by OOR imputation in approach B (independently during the training and prediction phase).
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default '&quot;impute_median_B&quot;'.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>Median_B_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Median_B_imputation-new"><code>PipeOpMedian_B$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Median_B_imputation-clone"><code>PipeOpMedian_B$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Median_B_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMedian_B$new(id = "impute_median_B", param_vals = list())</pre></div>


<hr>
<a id="method-Median_B_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMedian_B$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

# Using debug learner for example purpose

  graph &lt;- PipeOpMedian_B$new() %&gt;&gt;%  LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpMice'>PipeOpMice</h2><span id='topic+PipeOpMice'></span>

<h3>Description</h3>

<p>Implements mice methods as mlr3 pipeline more about mice <code><a href="#topic+autotune_mice">autotune_mice</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_mice"</code>.
</p>
</li>
<li> <p><code>m</code> :: <code>integer(1)</code><br />
Number of datasets produced by mice, default <code>5</code>.
</p>
</li>
<li> <p><code>maxit</code> :: <code>integer(1)</code><br />
Maximum number of iterations for mice, default <code>5</code>.
</p>
</li>
<li> <p><code>set_corr</code> :: <code>double(1)</code><br />
Correlation or fraction of features used when optimize=FALSE. When correlation=FALSE, it represents a fraction of case to use in imputation for each variable, default <code>0.5</code>.
</p>
</li>
<li> <p><code>set_method</code> :: <code>character(1)</code><br />
Method used if optimize=FALSE. If NULL default method is used (more in methods_random section), default <code>'pmm'</code>.
</p>
</li>
<li> <p><code>low_corr</code> :: <code>double(1)</code><br />
Double between 0-1. Lower boundary of correlation used in inner optimization (used only when optimize=TRUE), default <code>0</code>.
</p>
</li>
<li> <p><code>up_corr</code> :: <code>double(1)</code><br />
Double between 0-1. Upper boundary of correlation used in inner optimization (used only when optimize=TRUE). Both of these parameters work the same for a fraction of case if correlation=FALSE,default <code>1</code>.
</p>
</li>
<li> <p><code>methods_random</code> :: <code>character(1)</code><br />
set of methods to chose. Avalible methods &quot;pmm&quot;, &quot;midastouch&quot;, &quot;sample&quot;, &quot;cart&quot;, &quot;rf&quot; Default 'pmm'. If seted on NULL this methods are used predictive mean matching (numeric data) logreg, logistic regression imputation (binary data, factor with 2 levels) polyreg, polytomous regression imputation for unordered categorical data (factor &gt; 2 levels) polr, proportional odds model for (ordered, &gt; 2 levels).
</p>
</li>
<li> <p><code>iter</code> :: <code>integer(1)</code><br />
Number of iteration for random search, default <code>5</code>.
</p>
</li>
<li> <p><code>random.seed</code> :: <code>integer(1)</code><br />
Random seed, default <code>123</code>.
</p>
</li>
<li> <p><code>optimize</code> :: <code>logical(1)</code><br />
If set TRUE, function will optimize parameters of imputation automatically. If parameters will be tuned by other method, should be set to FALSE, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>correlation</code> :: <code>logical(1)</code><br />
If set TRUE correlation is used, if set FALSE then fraction of case, default <code>TRUE</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>mice_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-mice_imputation-new"><code>PipeOpMice$new()</code></a>
</p>
</li>
<li> <p><a href="#method-mice_imputation-clone"><code>PipeOpMice$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-mice_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMice$new(
  id = "impute_mice_B",
  m = 5,
  maxit = 5,
  set_cor = 0.5,
  set_method = "pmm",
  low_corr = 0,
  up_corr = 1,
  methods_random = c("pmm"),
  iter = 5,
  random.seed = 123,
  optimize = FALSE,
  correlation = FALSE,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-mice_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMice$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

# Using debug learner for example purpose

  graph &lt;- PipeOpMice$new() %&gt;&gt;%  LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))


</code></pre>

<hr>
<h2 id='PipeOpMice_A'>PipeOpMice_A</h2><span id='topic+PipeOpMice_A'></span>

<h3>Description</h3>

<p>Implements mice methods as mlr3 in A approach (training imputation model on training data and used a trained model on test data).
</p>


<h3>Details</h3>

<p>Code of used function was writen by <a href="https://github.com/prockenschaub">https://github.com/prockenschaub</a> more information aboute this aproche can be found here <a href="https://github.com/amices/mice/issues/32">https://github.com/amices/mice/issues/32</a>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_mice_A"</code>.
</p>
</li>
<li> <p><code>m</code> :: <code>integer(1)</code><br />
Number of datasets produced by mice, default <code>5</code>.
</p>
</li>
<li> <p><code>maxit</code> :: <code>integer(1)</code><br />
Maximum number of iterations for mice, default <code>5</code>.
</p>
</li>
<li> <p><code>set_corr</code> :: <code>double(1)</code><br />
Correlation or fraction of features used when optimize=FALSE. When correlation=FALSE, it represents a fraction of case to use in imputation for each variable, default <code>0.5</code>.
</p>
</li>
<li> <p><code>random.seed</code> :: <code>integer(1)</code><br />
Random seed, default <code>123</code>.
</p>
</li>
<li> <p><code>correlation</code> :: <code>logical(1)</code><br />
If set TRUE correlation is used, if set FALSE then fraction of case, default <code>TRUE</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>mice_A_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-mice_A_imputation-new"><code>PipeOpMice_A$new()</code></a>
</p>
</li>
<li> <p><a href="#method-mice_A_imputation-clone"><code>PipeOpMice_A$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-mice_A_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMice_A$new(
  id = "impute_mice_A",
  set_cor = 0.5,
  m = 5,
  maxit = 5,
  random.seed = 123,
  correlation = FALSE,
  methods = NULL
)</pre></div>


<hr>
<a id="method-mice_A_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMice_A$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose

  graph &lt;- PipeOpMice_A$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))


</code></pre>

<hr>
<h2 id='PipeOpmissForest'>PipeOpmissForest</h2><span id='topic+PipeOpmissForest'></span>

<h3>Description</h3>

<p>Implements missForest methods as mlr3 pipeline more about missForest <code><a href="#topic+autotune_missForest">autotune_missForest</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_missForest"</code>.
</p>
</li>
<li> <p><code>cores</code> :: <code>integer(1)</code><br />
Number of threads used by parallel calculations. If NULL approximately half of available CPU cores will be used, default <code>NULL</code>.
</p>
</li>
<li> <p><code>ntree_set</code> :: <code>integer(1)</code><br />
Vector with <em>number of trees</em> values for grid search, used only when optimize=TRUE, default <code>c(100,200,500,1000)</code>.
</p>
</li>
<li> <p><code>mtry_set</code> :: <code>integer(1)</code><br />
Vector with <em>number of variables</em> values randomly sampled at each split, used only when optimize=TRUE, default <code>NULL</code>.
</p>
</li>
<li> <p><code>parallel</code> :: <code>logical(1)</code><br />
If TRUE parallel calculations are used, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>ntree</code> :: <code>integer(1)</code><br />
ntree from missForest function, default <code>100</code>.
</p>
</li>
<li> <p><code>optimize</code> :: <code>logical(1)</code><br />
If set TRUE, function will optimize parameters of imputation automatically. If parameters will be tuned by other method, should be set to FALSE, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>mtry</code> :: <code>integer(1)</code><br />
mtry from missForest function, default <code>NULL</code>.
</p>
</li>
<li> <p><code>maxiter</code> :: <code>integer(1)</code><br />
maxiter from missForest function, default <code>20</code>.
</p>
</li>
<li> <p><code>maxnodes</code> :: <code>character(1)</code><br />
maxnodes from missForest function, default <code>NULL</code>
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>missForest_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-missForest_imputation-new"><code>PipeOpmissForest$new()</code></a>
</p>
</li>
<li> <p><a href="#method-missForest_imputation-clone"><code>PipeOpmissForest$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-missForest_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpmissForest$new(
  id = "impute_missForest_B",
  cores = NULL,
  ntree_set = c(100, 200, 500, 1000),
  mtry_set = NULL,
  parallel = FALSE,
  mtry = NULL,
  ntree = 100,
  optimize = FALSE,
  maxiter = 20,
  maxnodes = NULL,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-missForest_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpmissForest$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

  # Using debug learner for example purpose

  graph &lt;- PipeOpmissForest$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpmissMDA_MFA'>PipeOpmissMDA_MFA</h2><span id='topic+PipeOpmissMDA_MFA'></span><span id='topic+PipeOpMissMDA_MFA'></span>

<h3>Description</h3>

<p>Implements MFA methods as mlr3 pipeline, more about MFA <code><a href="#topic+missMDA_MFA">missMDA_MFA</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_missMDA_MFA"</code>.
</p>
</li>
<li> <p><code>ncp</code> :: <code>integer(1)</code><br />
Number of dimensions used by algorithm, default <code>2</code>.
</p>
</li>
<li> <p><code>random.seed</code> :: <code>integer(1)</code><br />
Integer, by default random.seed = NULL implies that missing values are initially imputed by the mean of each variable. Other values leads to a random initialization, default <code>NULL</code>.
</p>
</li>
<li> <p><code>maxiter</code> :: <code>integer(1)</code><br />
Maximal number of iteration in algorithm, default <code>998</code>.
</p>
</li>
<li> <p><code>coeff.ridge</code> :: <code>integer(1)</code><br />
Value used in <em>Regularized</em> method, default <code>1</code>.
</p>
</li>
<li> <p><code>threshold</code> :: <code>double(1)</code><br />
Threshold for convergence, default <code>1e-06</code>.
</p>
</li>
<li> <p><code>method</code> :: <code>character(1)</code><br />
Method used in imputation algorithm, default <code>'Regularized'</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>missMDA_MFAimputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-missMDA_MFAimputation-new"><code>PipeOpMissMDA_MFA$new()</code></a>
</p>
</li>
<li> <p><a href="#method-missMDA_MFAimputation-clone"><code>PipeOpMissMDA_MFA$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-missMDA_MFAimputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_MFA$new(
  id = "impute_missMDA_MFA_B",
  ncp = 2,
  random.seed = NULL,
  maxiter = 998,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  out_file = NULL
)</pre></div>


<hr>
<a id="method-missMDA_MFAimputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_MFA$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose

  graph &lt;- PipeOpMissMDA_MFA$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpmissMDA_MFA_A'>PipeOpmissMDA_MFA_A</h2><span id='topic+PipeOpmissMDA_MFA_A'></span><span id='topic+PipeOpMissMDA_MFA_A'></span>

<h3>Description</h3>

<p>Implements MFA methods as mlr3 pipeline in A approche , more about MFA <code><a href="#topic+missMDA_MFA">missMDA_MFA</a></code> and <code><a href="#topic+missMDA.reuse">missMDA.reuse</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_missMDA_MFA"</code>.
</p>
</li>
<li> <p><code>ncp</code> :: <code>integer(1)</code><br />
Number of dimensions used by algorithm, default <code>2</code>.
</p>
</li>
<li> <p><code>maxiter</code> :: <code>integer(1)</code><br />
Maximal number of iteration in algorithm, default <code>998</code>.
</p>
</li>
<li> <p><code>coeff.ridge</code> :: <code>integer(1)</code><br />
Value used in <em>Regularized</em> method, default <code>1</code>.
</p>
</li>
<li> <p><code>threshold</code> :: <code>double(1)</code><br />
Threshold for convergence, default <code>1e-06</code>.
</p>
</li>
<li> <p><code>method</code> :: <code>character(1)</code><br />
Method used in imputation algorithm, default <code>'Regularized'</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>missMDA_MFAimputation_A</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-missMDA_MFAimputation_A-new"><code>PipeOpMissMDA_MFA_A$new()</code></a>
</p>
</li>
<li> <p><a href="#method-missMDA_MFAimputation_A-clone"><code>PipeOpMissMDA_MFA_A$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-missMDA_MFAimputation_A-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_MFA_A$new(
  id = "impute_missMDA_MFA_A",
  ncp = 2,
  maxiter = 998,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  out_file = NULL
)</pre></div>


<hr>
<a id="method-missMDA_MFAimputation_A-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_MFA_A$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose

  graph &lt;- PipeOpMissMDA_MFA_A$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpmissMDA_PCA_MCA_FMAD'>PipeOpmissMDA_PCA_MCA_FMAD</h2><span id='topic+PipeOpmissMDA_PCA_MCA_FMAD'></span><span id='topic+PipeOpMissMDA_PCA_MCA_FMAD'></span>

<h3>Description</h3>

<p>Implements PCA, MCA, FMAD methods as mlr3 pipeline, more about methods <code><a href="#topic+missMDA_FMAD_MCA_PCA">missMDA_FMAD_MCA_PCA</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_missMDA_MCA_PCA_FMAD"</code>.
</p>
</li>
<li> <p><code>optimize_ncp</code> :: <code>logical(1)</code><br />
If TRUE, parameter <em>number of dimensions</em>, used to predict the missing values, will be optimized. If FALSE, by default ncp=2 is used, default <code>TRUE</code>.
</p>
</li>
<li> <p><code>set_ncp</code> :: <code>integer(1)</code><br />
integer &gt;0. Number of dimensions used by algortims. Used only if optimize_ncp = Flase, default <code>2</code>.
</p>
</li>
<li> <p><code>ncp.max</code> :: <code>integer(1)</code><br />
Number corresponding to the maximum number of components to test when optimize_ncp=TRUE, default <code>5</code>.
</p>
</li>
<li> <p><code>random.seed</code> :: <code>integer(1)</code><br />
Integer, by default random.seed = NULL implies that missing values are initially imputed by the mean of each variable. Other values leads to a random initialization, default <code>NULL</code>.
</p>
</li>
<li> <p><code>maxiter</code> :: <code>integer(1)</code><br />
Maximal number of iteration in algorithm, default <code>998</code>.
</p>
</li>
<li> <p><code>coeff.ridge</code> :: <code>double(1)</code><br />
Value used in <em>Regularized</em> method, default <code>1</code>.
</p>
</li>
<li> <p><code>threshold</code> :: <code>double(1)</code><br />
Threshold for convergence, default <code>1e-6</code>.
</p>
</li>
<li> <p><code>method</code> :: <code>character(1)</code><br />
Method used in imputation algorithm, default <code>'Regularized'</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>missMDA_MCA_PCA_FMAD_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-missMDA_MCA_PCA_FMAD_imputation-new"><code>PipeOpMissMDA_PCA_MCA_FMAD$new()</code></a>
</p>
</li>
<li> <p><a href="#method-missMDA_MCA_PCA_FMAD_imputation-clone"><code>PipeOpMissMDA_PCA_MCA_FMAD$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-missMDA_MCA_PCA_FMAD_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_PCA_MCA_FMAD$new(
  id = "impute_missMDA_MCA_PCA_FMAD_B",
  optimize_ncp = TRUE,
  set_ncp = 2,
  ncp.max = 5,
  random.seed = NULL,
  maxiter = 998,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  out_file = NULL
)</pre></div>


<hr>
<a id="method-missMDA_MCA_PCA_FMAD_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_PCA_MCA_FMAD$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose


  graph &lt;- PipeOpMissMDA_PCA_MCA_FMAD$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpmissMDA_PCA_MCA_FMAD_A'>PipeOpmissMDA_PCA_MCA_FMAD_A</h2><span id='topic+PipeOpmissMDA_PCA_MCA_FMAD_A'></span><span id='topic+PipeOpMissMDA_PCA_MCA_FMAD_A'></span>

<h3>Description</h3>

<p>Implements PCA, MCA, FMAD methods as mlr3 pipeline in approach A, more about methods <code><a href="#topic+missMDA_FMAD_MCA_PCA">missMDA_FMAD_MCA_PCA</a></code> and <code><a href="#topic+missMDA.reuse">missMDA.reuse</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_missMDA_MCA_PCA_FMAD"</code>.
</p>
</li>
<li> <p><code>optimize_ncp</code> :: <code>logical(1)</code><br />
If TRUE, parameter <em>number of dimensions</em>, used to predict the missing values, will be optimized. If FALSE, by default ncp=2 is used, default <code>TRUE</code>.
</p>
</li>
<li> <p><code>set_ncp</code> :: <code>integer(1)</code><br />
integer &gt;0. Number of dimensions used by algortims. Used only if optimize_ncp = Flase, default <code>2</code>.
</p>
</li>
<li> <p><code>ncp.max</code> :: <code>integer(1)</code><br />
Number corresponding to the maximum number of components to test when optimize_ncp=TRUE, default <code>5</code>.
</p>
</li>
<li> <p><code>random.seed</code> :: <code>integer(1)</code><br />
Integer, by default random.seed = NULL implies that missing values are initially imputed by the mean of each variable. Other values leads to a random initialization, default <code>NULL</code>.
</p>
</li>
<li> <p><code>maxiter</code> :: <code>integer(1)</code><br />
Maximal number of iteration in algorithm, default <code>998</code>.
</p>
</li>
<li> <p><code>coeff.ridge</code> :: <code>double(1)</code><br />
Value used in <em>Regularized</em> method, default <code>1</code>.
</p>
</li>
<li> <p><code>threshold</code> :: <code>double(1)</code><br />
Threshold for convergence, default <code>1e-6</code>.
</p>
</li>
<li> <p><code>method</code> :: <code>character(1)</code><br />
Method used in imputation algorithm, default <code>'Regularized'</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>missMDA_MCA_PCA_FMAD_imputation_A</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-missMDA_MCA_PCA_FMAD_imputation_A-new"><code>PipeOpMissMDA_PCA_MCA_FMAD_A$new()</code></a>
</p>
</li>
<li> <p><a href="#method-missMDA_MCA_PCA_FMAD_imputation_A-clone"><code>PipeOpMissMDA_PCA_MCA_FMAD_A$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-missMDA_MCA_PCA_FMAD_imputation_A-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_PCA_MCA_FMAD_A$new(
  id = "impute_missMDA_MCA_PCA_FMAD_A",
  optimize_ncp = TRUE,
  set_ncp = 2,
  ncp.max = 5,
  random.seed = NULL,
  maxiter = 998,
  coeff.ridge = 1,
  threshold = 1e-06,
  method = "Regularized",
  out_file = NULL
)</pre></div>


<hr>
<a id="method-missMDA_MCA_PCA_FMAD_imputation_A-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMissMDA_PCA_MCA_FMAD_A$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose


  graph &lt;- PipeOpMissMDA_PCA_MCA_FMAD_A$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpmissRanger'>PipeOpmissRanger</h2><span id='topic+PipeOpmissRanger'></span>

<h3>Description</h3>

<p>Implements missRanger methods as mlr3 pipeline, more about missRanger <code><a href="#topic+autotune_missRanger">autotune_missRanger</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_missRanger"</code>.
</p>
</li>
<li> <p><code>mtry</code> :: <code>integer(1)</code><br />
Sample fraction used by missRanger. This param isn't optimized automatically. If NULL default value from ranger package will be used, <code>NULL</code>.
</p>
</li>
<li> <p><code>num.trees</code> :: <code>integer(1)</code><br />
Number of trees. If optimize == TRUE. Param set seq(10,num.trees,iter) will be used, default <code>500</code>
</p>
</li>
<li> <p><code>pmm.k</code> :: <code>integer(1)</code><br />
Number of candidate non-missing values to sample from in the predictive mean matching step. 0 to avoid this step. If optimize=TRUE params set: sample(1:pmm.k, iter) will be used. If pmm.k=0, missRanger is the same as missForest, default <code>5</code>.
</p>
</li>
<li> <p><code>random.seed</code> :: <code>integer(1)</code><br />
Random seed, default <code>123</code>.
</p>
</li>
<li> <p><code>iter</code> :: <code>integer(1)</code><br />
Number of iterations for a random search, default <code>10</code>.
</p>
</li>
<li> <p><code>optimize</code> :: <code>logical(1)</code><br />
If set TRUE, function will optimize parameters of imputation automatically. If parameters will be tuned by other method, should be set to FALSE, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>missRanger_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-missRanger_imputation-new"><code>PipeOpmissRanger$new()</code></a>
</p>
</li>
<li> <p><a href="#method-missRanger_imputation-clone"><code>PipeOpmissRanger$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-missRanger_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpmissRanger$new(
  id = "impute_missRanger_B",
  maxiter = 10,
  random.seed = 123,
  mtry = NULL,
  num.trees = 500,
  pmm.k = 5,
  optimize = FALSE,
  iter = 10,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-missRanger_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpmissRanger$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>

 # Using debug learner for example purpose

  graph &lt;- PipeOpmissRanger$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))

</code></pre>

<hr>
<h2 id='PipeOpMode_B'>PipeOpMode_B</h2><span id='topic+PipeOpMode_B'></span>

<h3>Description</h3>

<p>Impute features by their mode in approach B (independently during the training and prediction phase).
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default '&quot;impute_mode_B&quot;'.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>Mode_B_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Mode_B_imputation-new"><code>PipeOpMode_B$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Mode_B_imputation-clone"><code>PipeOpMode_B$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Mode_B_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpMode_B$new(id = "impute_mode_B", param_vals = list())</pre></div>


<hr>
<a id="method-Mode_B_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpMode_B$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
 # Using debug learner for example purpose

  graph &lt;- PipeOpMode_B$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA
   set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='PipeOpOOR_B'>PipeOpOOR_B</h2><span id='topic+PipeOpOOR_B'></span>

<h3>Description</h3>

<p>Impute features by OOR imputation in approach B (independently during the training and prediction phase).
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default '&quot;impute_OOR_B&quot;'.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>OOR_B_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-OOR_B_imputation-new"><code>PipeOpOOR_B$new()</code></a>
</p>
</li>
<li> <p><a href="#method-OOR_B_imputation-clone"><code>PipeOpOOR_B$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-OOR_B_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpOOR_B$new(id = "impute_oor_B", param_vals = list())</pre></div>


<hr>
<a id="method-OOR_B_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpOOR_B$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{

 # Using debug learner for example purpose

  graph &lt;- PipeOpOOR_B$new() %&gt;&gt;% LearnerClassifDebug$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='PipeOpSample_B'>PipeOpSample_B</h2><span id='topic+PipeOpSample_B'></span>

<h3>Description</h3>

<p>Impute features by sampling from non-missing data in approach B (independently during the training and prediction phase).
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default '&quot;impute_sample_B&quot;'.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>Sample_B_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Sample_B_imputation-new"><code>PipeOpSample_B$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Sample_B_imputation-clone"><code>PipeOpSample_B$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Sample_B_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpSample_B$new(id = "impute_sample_B", param_vals = list())</pre></div>


<hr>
<a id="method-Sample_B_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpSample_B$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
  graph &lt;- PipeOpSample_B$new() %&gt;&gt;% mlr3learners::LearnerClassifGlmnet$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA
  set.seed(1)
  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='PipeOpSimulateMissings'>PipeOpSimulateMissings</h2><span id='topic+PipeOpSimulateMissings'></span>

<h3>Description</h3>

<p>Generates MCAR missing values in mlr3 pipeline according to set parameters.
Missings are inserted to task data once during first training.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpTaskPreproc</code>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>per_missings</code> :: <code>double(1)</code><br />
Overall percentage of missing values generated in dataset [0, 100]. Must be set every time, default 50
</p>
</li>
<li> <p><code>per_instances_missings</code> :: <code>double(1)</code><br />
Percentage of instances which will have missing values [0, 100].
</p>
</li>
<li> <p><code>per_variables_missings</code> :: <code>double(1)</code><br />
Percentage of variables which will have missing values [0, 100].
</p>
</li>
<li> <p><code>variables_missings</code> :: <code>integer</code><br />
Only when 'per_variables_missings' is 'NULL'. Vector of indexes of columns in which missings will be generated.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpTaskPreproc">mlr3pipelines::PipeOpTaskPreproc</a></code> -&gt; <code>PipeOpSimulateMissings</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpSimulateMissings-new"><code>PipeOpSimulateMissings$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpSimulateMissings-clone"><code>PipeOpSimulateMissings$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpSimulateMissings-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpSimulateMissings$new(
  id = "simulate_missings",
  param_vals = list(per_missings = 50)
)</pre></div>


<hr>
<a id="method-PipeOpSimulateMissings-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpSimulateMissings$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
  task_NA &lt;- PipeOpSimulateMissings$new()$train(list(tsk("iris")))[[1]]

  # check
  sum(task_NA$missings()) &gt; 0
}
</code></pre>

<hr>
<h2 id='PipeOpSoftImpute'>PipeOpSoftImpute</h2><span id='topic+PipeOpSoftImpute'></span>

<h3>Description</h3>

<p>Implements SoftImpute methods as mlr3 pipeline, more about SoftImpute <code><a href="#topic+autotune_softImpute">autotune_softImpute</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_softImpute"</code>.
</p>
</li>
<li> <p><code>lambda</code> :: <code>integer(1)</code><br />
Nuclear-norm regularization parameter. If lambda=0, the algorithm reverts to &quot;hardImpute&quot;, for which convergence is typically slower. If NULL lambda is set automatically at the highest possible value, default <code>0</code>.
</p>
</li>
<li> <p><code>rank.max</code> :: <code>integer(1)</code><br />
This param restricts the rank of the solution. If set as NULL: rank.max=min(dim(X))-1, default <code>2</code>.
</p>
</li>
<li> <p><code>type</code> :: <code>character(1)</code><br />
Two algorithms are implemented: type=&quot;svd&quot; or the default type=&quot;als&quot;. The &quot;svd&quot; algorithm repeatedly computes the svd of the completed matrix, and soft thresholds its singular values. Each new soft-thresholded svd is used to re-impute the missing entries. For large matrices of class &quot;Incomplete&quot;, the svd is achieved by an efficient form of alternating orthogonal ridge regression. The &quot;als&quot; algorithm uses the same alternating ridge regression, but updates the imputation at each step, leading to quite substantial speedups in some cases. The &quot;als&quot; approach does not currently have the same theoretical convergence guarantees as the &quot;svd&quot; approach, default <code>'als'</code>.
</p>
</li>
<li> <p><code>thresh</code> :: <code>double(1)</code><br />
Threshold for convergence, default <code>1e-5</code>
</p>
</li>
<li> <p><code>maxit</code> :: <code>integer(1)</code><br />
Maximum number of iterations, default <code>100</code>.
</p>
</li>
<li> <p><code>cat_Fun</code> :: <code>function(){}</code><br />
Function for aggregating the k Nearest Neighbors in case of categorical variables. It can be any function with input=not_numeric_vector and output=atomic_object, default <code>VIM::maxCat</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>softImpute_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-softImpute_imputation-new"><code>PipeOpSoftImpute$new()</code></a>
</p>
</li>
<li> <p><a href="#method-softImpute_imputation-clone"><code>PipeOpSoftImpute$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-softImpute_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpSoftImpute$new(
  id = "impute_softImpute_B",
  cat_Fun = VIM::maxCat,
  lambda = 0,
  rank.max = 2,
  type = "als",
  thresh = 1e-05,
  maxit = 100,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-softImpute_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpSoftImpute$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
  graph &lt;- PipeOpAmelia$new() %&gt;&gt;% mlr3learners::LearnerClassifGlmnet$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='PipeOpVIM_HD'>PipeOpVIM_HD</h2><span id='topic+PipeOpVIM_HD'></span>

<h3>Description</h3>

<p>Implements Hot Deck methods as mlr3 pipeline more about VIM_HD <code><a href="#topic+autotune_VIM_hotdeck">autotune_VIM_hotdeck</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_VIM_HD"</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>VIM_HD_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-VIM_HD_imputation-new"><code>PipeOpVIM_HD$new()</code></a>
</p>
</li>
<li> <p><a href="#method-VIM_HD_imputation-clone"><code>PipeOpVIM_HD$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-VIM_HD_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_HD$new(id = "impute_VIM_HD_B", out_file = NULL)</pre></div>


<hr>
<a id="method-VIM_HD_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_HD$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
  graph &lt;- PipeOpVIM_HD$new() %&gt;&gt;% mlr3learners::LearnerClassifGlmnet$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='PipeOpVIM_IRMI'>PipeOpVIM_IRMI</h2><span id='topic+PipeOpVIM_IRMI'></span>

<h3>Description</h3>

<p>Implements IRMI methods as mlr3 pipeline, more about VIM_IRMI <code><a href="#topic+autotune_VIM_Irmi">autotune_VIM_Irmi</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_VIM_IRMI"</code>.
</p>
</li>
<li> <p><code>eps</code> :: <code>double(1)</code><br />
Threshold for convergence, default <code>5</code>.
</p>
</li>
<li> <p><code>maxit</code> :: <code>integer(1)</code><br />
Maximum number of iterations, default <code>100</code>
</p>
</li>
<li> <p><code>step</code> :: <code>logical(1)</code><br />
Stepwise model selection is applied when the parameter is set to TRUE, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>robust</code> :: <code>logical(1)</code><br />
If TRUE, robust regression methods will be applied (it's impossible to set step=TRUE and robust=TRUE at the same time), default <code>FALSE</code>.
</p>
</li>
<li> <p><code>init.method</code> :: <code>character(1)</code><br />
Method for initialization of missing values (kNN or median), default <code>'kNN'</code>.
</p>
</li>
<li> <p><code>force</code> :: <code>logical(1)</code><br />
If TRUE, the algorithm tries to find a solution in any case by using different robust methods automatically (should be set FALSE for simulation), default <code>FALSE</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>VIM_IRMI_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-VIM_IRMI_imputation-new"><code>PipeOpVIM_IRMI$new()</code></a>
</p>
</li>
<li> <p><a href="#method-VIM_IRMI_imputation-clone"><code>PipeOpVIM_IRMI$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-VIM_IRMI_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_IRMI$new(
  id = "impute_VIM_IRMI_B",
  eps = 5,
  maxit = 100,
  step = FALSE,
  robust = FALSE,
  init.method = "kNN",
  force = FALSE,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-VIM_IRMI_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_IRMI$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>
  graph &lt;- PipeOpVIM_IRMI$new() %&gt;&gt;% mlr3learners::LearnerClassifGlmnet$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(TaskClassif$new('id',tsk('pima')$data(rows=1:100),
  'diabetes'), graph_learner, rsmp("cv",folds=2))

</code></pre>

<hr>
<h2 id='PipeOpVIM_kNN'>PipeOpVIM_kNN</h2><span id='topic+PipeOpVIM_kNN'></span>

<h3>Description</h3>

<p>Implements KNN methods as mlr3 pipeline, more about VIM_KNN <code><a href="#topic+autotune_VIM_kNN">autotune_VIM_kNN</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_VIM_kNN"</code>.
</p>
</li>
<li> <p><code>k</code> :: <code>intiger(1)</code><br />
Threshold for convergence, default <code>5</code>.
</p>
</li>
<li> <p><code>numFUN</code> :: <code>function(){}</code><br />
Function for aggregating the k Nearest Neighbours in the case of a numerical variable.  Can be ever function with input=numeric_vector and output=atomic_object, default <code>median</code>.
</p>
</li>
<li> <p><code>catFUN</code> :: <code>function(){}</code><br />
Function for aggregating the k Nearest Neighbours in case of categorical variables. It can be any function with input=not_numeric_vector and output=atomic_object, default <code>VIM::maxCat</code>
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>VIM_kNN_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-VIM_kNN_imputation-new"><code>PipeOpVIM_kNN$new()</code></a>
</p>
</li>
<li> <p><a href="#method-VIM_kNN_imputation-clone"><code>PipeOpVIM_kNN$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-VIM_kNN_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_kNN$new(
  id = "impute_VIM_kNN_B",
  k = 5,
  numFun = median,
  catFun = VIM::maxCat,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-VIM_kNN_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_kNN$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
  graph &lt;- PipeOpVIM_kNN$new() %&gt;&gt;% mlr3learners::LearnerClassifGlmnet$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='PipeOpVIM_regrImp'>PipeOpVIM_regrImp</h2><span id='topic+PipeOpVIM_regrImp'></span>

<h3>Description</h3>

<p>Implements Regression Imputation methods as mlr3 pipeline, more about RI <code><a href="#topic+autotune_VIM_regrImp">autotune_VIM_regrImp</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>Input and output channels are inherited from <code>PipeOpImpute</code>.
</p>


<h3>Parameters</h3>

<p>The parameters include inherited from ['PipeOpImpute'], as well as: <br />
</p>

<ul>
<li> <p><code>id</code> :: <code>character(1)</code><br />
Identifier of resulting object, default <code>"imput_VIM_regrImp"</code>.
</p>
</li>
<li> <p><code>robust</code> :: <code>logical(1)</code><br />
TRUE/FALSE: whether to use robust regression, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>mod_cat</code> :: <code>logical(1)</code><br />
TRUE/FALSE if TRUE for categorical variables the level with the highest prediction probability is selected, otherwise it is sampled according to the probabilities, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>use_imputed</code> :: <code>logical(1)</code><br />
TRUE/FALSe: if TURE, already imputed columns will be used to impute others, default <code>FALSE</code>.
</p>
</li>
<li> <p><code>out_fill</code> :: <code>character(1)</code><br />
Output log file location. If file already exists log message will be added. If NULL no log will be produced, default <code>NULL</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpImpute">mlr3pipelines::PipeOpImpute</a></code> -&gt; <code>VIM_regrImp_imputation</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-VIM_regrImp_imputation-new"><code>PipeOpVIM_regrImp$new()</code></a>
</p>
</li>
<li> <p><a href="#method-VIM_regrImp_imputation-clone"><code>PipeOpVIM_regrImp$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-VIM_regrImp_imputation-new"></a>



<h4>Method <code>new()</code></h4>



<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_regrImp$new(
  id = "impute_VIM_regrImp_B",
  robust = FALSE,
  mod_cat = FALSE,
  use_imputed = FALSE,
  out_file = NULL
)</pre></div>


<hr>
<a id="method-VIM_regrImp_imputation-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpVIM_regrImp$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>{
  graph &lt;- PipeOpVIM_regrImp$new() %&gt;&gt;% mlr3learners::LearnerClassifGlmnet$new()
  graph_learner &lt;- GraphLearner$new(graph)

  # Task with NA

  resample(tsk("pima"), graph_learner, rsmp("cv", folds = 3))
}
</code></pre>

<hr>
<h2 id='random_param_mice_search'>Performing randomSearch for selecting the best method and correlation or fraction of features used to create a prediction matrix.</h2><span id='topic+random_param_mice_search'></span>

<h3>Description</h3>

<p>This function perform random search and return values corresponding to best mean MIF (missing information fraction). Function is mainly used in <code><a href="#topic+autotune_mice">autotune_mice</a></code> but can be use separately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_param_mice_search(
  low_corr = 0,
  up_corr = 1,
  methods_random = c("pmm"),
  df,
  formula,
  no_numeric,
  iter,
  random.seed = 123,
  correlation = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_param_mice_search_+3A_low_corr">low_corr</code></td>
<td>
<p>double between 0,1 default 0 lower boundry of correlation set.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_up_corr">up_corr</code></td>
<td>
<p>double between 0,1 default 1 upper boundary of correlation set. Both of these parameters work the same for a fraction of features.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_methods_random">methods_random</code></td>
<td>
<p>set of methods to chose. Default 'pmm'.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_df">df</code></td>
<td>
<p>data frame to input.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_formula">formula</code></td>
<td>
<p>first product of formula_creating() funtion. For example formula_creating(...)[1]</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_no_numeric">no_numeric</code></td>
<td>
<p>second product of formula_creating() function.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_iter">iter</code></td>
<td>
<p>number of iteration for randomSearch.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_random.seed">random.seed</code></td>
<td>
<p>radnom seed.</p>
</td></tr>
<tr><td><code id="random_param_mice_search_+3A_correlation">correlation</code></td>
<td>
<p>If True correlation is using if Fales fraction of features. Default True.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function use Random Search Technik to found the best param for mice imputation. To evaluate the next iteration logistic regression or linear regression (depending on available features) are used. Model is build using a formula from <code><a href="#topic+formula_creating">formula_creating</a></code> function. As metric MIF (missing information fraction) is used. Params combination with lowest (best) MIF is chosen. Even if a correlation is set at False correlation it's still used to select the best features. That main problem with
calculating correlation between categorical columns is still important.
</p>


<h3>Value</h3>

<p>List with best correlation (or fraction ) at first place, best method at second, and results of every iteration at 3.
</p>

<hr>
<h2 id='replace_overimputes'>Replace overimputes. Used in mice.reuse.</h2><span id='topic+replace_overimputes'></span>

<h3>Description</h3>

<p> Replace all overimputed data points in the mice imputation
of one variable. Overimputed data points are those data
that were not missing in the original but were marked for
imputation manually and imputed by the imputation procedure.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_overimputes(data, imp, j, i)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_overimputes_+3A_data">data</code></td>
<td>
<p>data.frame the original, non-imputed dataset (mids$data)</p>
</td></tr>
<tr><td><code id="replace_overimputes_+3A_imp">imp</code></td>
<td>
<p>list of data.frames all imputations stored in the mids object</p>
</td></tr>
<tr><td><code id="replace_overimputes_+3A_j">j</code></td>
<td>
<p>character scalar the name of the variable whose imputations should be replaced</p>
</td></tr>
<tr><td><code id="replace_overimputes_+3A_i">i</code></td>
<td>
<p>character or integer scalar the number of the current imputation (can be 1:m)</p>
</td></tr>
</table>

<hr>
<h2 id='simulate_missings'>Generate MCAR missings in dataset.</h2><span id='topic+simulate_missings'></span>

<h3>Description</h3>

<p>Function generates random missing values in given dataset
according to set parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_missings(
  df,
  per_missings,
  per_instances_missings = NULL,
  per_variables_missings = NULL,
  variables_with_missings = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_missings_+3A_df">df</code></td>
<td>
<p>Data.frame or data.table where missing values will be generated</p>
</td></tr>
<tr><td><code id="simulate_missings_+3A_per_missings">per_missings</code></td>
<td>
<p>Overall percentage of missing values generated in dataset. Must be set every time.</p>
</td></tr>
<tr><td><code id="simulate_missings_+3A_per_instances_missings">per_instances_missings</code></td>
<td>
<p>Percentage of instances which will have missing values.</p>
</td></tr>
<tr><td><code id="simulate_missings_+3A_per_variables_missings">per_variables_missings</code></td>
<td>
<p>Percentage of variables which will have missing values.</p>
</td></tr>
<tr><td><code id="simulate_missings_+3A_variables_with_missings">variables_with_missings</code></td>
<td>
<p>Only when 'per_variables_missings' is 'NULL'.
Vector of column indexes where missings will be generated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dataset with generated missings.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  data_NA &lt;- simulate_missings(iris, 20)

  # check
  sum(is.na(data_NA)) &gt; 0
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
