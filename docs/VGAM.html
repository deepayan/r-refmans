<!DOCTYPE html><html><head><title>Help for package VGAM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {VGAM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#A1A2A3'><p> The A1A2A3 Blood Group System</p></a></li>
<li><a href='#AA.Aa.aa'><p> The AA-Aa-aa Blood Group System</p></a></li>
<li><a href='#AB.Ab.aB.ab'><p> The AB-Ab-aB-ab Blood Group System</p></a></li>
<li><a href='#ABO'><p> The ABO Blood Group System</p></a></li>
<li><a href='#acat'><p> Ordinal Regression with Adjacent Categories Probabilities</p></a></li>
<li><a href='#add1.vglm'><p>Add or Drop All Possible Single Terms to/from a Model</p></a></li>
<li><a href='#AICvlm'><p> Akaike's Information Criterion</p></a></li>
<li><a href='#alaplace'><p> Asymmetric Laplace Distribution Family Functions</p></a></li>
<li><a href='#alaplaceUC'><p> The Laplace Distribution</p></a></li>
<li><a href='#alogitlink'><p> Arcsine&ndash;Logit Link Mixtures</p></a></li>
<li><a href='#altered'>
<p>Altered, Inflated, Truncated and Deflated Values in GAITD Regression</p>
</p></a></li>
<li><a href='#amlbinomial'><p> Binomial Logistic Regression by Asymmetric Maximum</p>
Likelihood Estimation</a></li>
<li><a href='#amlexponential'><p> Exponential Regression by Asymmetric Maximum</p>
Likelihood Estimation</a></li>
<li><a href='#amlnormal'><p> Asymmetric Least Squares Quantile Regression</p></a></li>
<li><a href='#amlpoisson'><p> Poisson Regression by Asymmetric Maximum Likelihood Estimation</p></a></li>
<li><a href='#anova.vglm'><p>Analysis of Deviance for Vector Generalized Linear Model Fits</p></a></li>
<li><a href='#AR1'><p> Autoregressive Process with Order-1 Family Function</p></a></li>
<li><a href='#AR1EIM'><p>Computation of the Exact EIM of an Order-1 Autoregressive Process</p>
</p></a></li>
<li><a href='#asinlink'><p> Arcsine Link Function</p></a></li>
<li><a href='#auuc'><p> Auckland University Undergraduate Counts Data</p></a></li>
<li><a href='#aux.posbernoulli.t'><p> Auxiliary Function for the</p>
Positive Bernoulli Family Function with Time Effects</a></li>
<li><a href='#backPain'><p> Data on Back Pain Prognosis, from Anderson (1984)</p></a></li>
<li><a href='#beggs'><p>Bacon and Eggs Data</p></a></li>
<li><a href='#bell'>
<p>The Bell Series of Integers</p></a></li>
<li><a href='#Benford'><p> Benford's Distribution</p></a></li>
<li><a href='#Benini'><p>The Benini Distribution</p></a></li>
<li><a href='#benini1'><p>Benini Distribution Family Function</p></a></li>
<li><a href='#Betabinom'><p>The Beta-Binomial Distribution</p></a></li>
<li><a href='#betabinomial'><p> Beta-binomial Distribution Family Function</p></a></li>
<li><a href='#betabinomialff'><p> Beta-binomial Distribution Family Function</p></a></li>
<li><a href='#betaff'><p> The Two-parameter Beta Distribution Family Function</p></a></li>
<li><a href='#Betageom'><p>The Beta-Geometric Distribution</p></a></li>
<li><a href='#betageometric'><p> Beta-geometric Distribution Family Function</p></a></li>
<li><a href='#betaII'><p> Beta Distribution of the Second Kind</p></a></li>
<li><a href='#Betanorm'><p>The Beta-Normal Distribution</p></a></li>
<li><a href='#betaprime'><p> The Beta-Prime Distribution</p></a></li>
<li><a href='#betaR'><p> The Two-parameter Beta Distribution Family Function</p></a></li>
<li><a href='#biamhcop'><p> Ali-Mikhail-Haq Distribution Family Function</p></a></li>
<li><a href='#Biamhcop'><p>Ali-Mikhail-Haq Bivariate Distribution</p></a></li>
<li><a href='#biclaytoncop'><p> Clayton Copula (Bivariate) Family Function</p></a></li>
<li><a href='#Biclaytoncop'><p>Clayton Copula (Bivariate) Distribution</p></a></li>
<li><a href='#BICvlm'><p> Bayesian Information Criterion</p></a></li>
<li><a href='#bifgmcop'><p> Farlie-Gumbel-Morgenstern's Bivariate Distribution</p>
Family Function</a></li>
<li><a href='#Bifgmcop'><p>Farlie-Gumbel-Morgenstern's Bivariate Distribution</p></a></li>
<li><a href='#bifgmexp'><p> Bivariate Farlie-Gumbel-Morgenstern Exponential</p>
Distribution Family Function</a></li>
<li><a href='#bifrankcop'><p> Frank's Bivariate Distribution Family Function</p></a></li>
<li><a href='#bigumbelIexp'><p> Gumbel's Type I Bivariate Distribution Family Function</p></a></li>
<li><a href='#bilogis'><p>Bivariate Logistic Distribution</p></a></li>
<li><a href='#bilogistic'><p> Bivariate Logistic Distribution Family Function</p></a></li>
<li><a href='#binom2.or'><p> Bivariate Binary Regression with an Odds Ratio (Family</p>
Function)</a></li>
<li><a href='#Binom2.or'><p> Bivariate Odds Ratio Model</p></a></li>
<li><a href='#binom2.rho'><p> Bivariate Probit Regression</p></a></li>
<li><a href='#Binom2.rho'><p> Bivariate Probit Model</p></a></li>
<li><a href='#binomialff'><p> Binomial Family Function</p></a></li>
<li><a href='#Binorm'><p>Bivariate Normal Distribution Cumulative Distribution</p>
Function</a></li>
<li><a href='#binormal'><p> Bivariate Normal Distribution Family Function</p></a></li>
<li><a href='#binormalcop'><p> Gaussian Copula (Bivariate) Family Function</p></a></li>
<li><a href='#Binormcop'><p>Gaussian Copula (Bivariate) Distribution</p></a></li>
<li><a href='#Biplackett'><p>Plackett's Bivariate Copula</p></a></li>
<li><a href='#biplackettcop'><p> Plackett's Bivariate Copula Family Function</p></a></li>
<li><a href='#biplot-methods'><p> Biplot of Constrained Regression Models</p></a></li>
<li><a href='#bisa'><p> Birnbaum-Saunders Regression Family Function</p></a></li>
<li><a href='#Bisa'><p>The Birnbaum-Saunders Distribution</p></a></li>
<li><a href='#bistudentt'><p> Bivariate Student-t Family Function</p></a></li>
<li><a href='#Bistudentt'><p>Bivariate Student-t Distribution Density</p>
Function</a></li>
<li><a href='#bmi.nz'><p> Body Mass Index of New Zealand Adults Data</p></a></li>
<li><a href='#borel.tanner'><p>Borel-Tanner Distribution Family Function</p></a></li>
<li><a href='#Bort'><p>The Borel-Tanner Distribution</p></a></li>
<li><a href='#brat'><p> Bradley Terry Model</p></a></li>
<li><a href='#Brat'><p> Inputting Data to fit a Bradley Terry Model</p></a></li>
<li><a href='#bratt'><p> Bradley Terry Model With Ties</p></a></li>
<li><a href='#budworm'><p> Western Spuce Budworm</p></a></li>
<li><a href='#calibrate'><p> Model Calibrations</p></a></li>
<li><a href='#calibrate-methods'><p> Calibration for Constrained Regression Models</p></a></li>
<li><a href='#calibrate.qrrvglm'><p> Calibration for CQO and CAO models</p></a></li>
<li><a href='#calibrate.qrrvglm.control'><p> Control Function for CQO/CAO Calibration</p></a></li>
<li><a href='#calibrate.rrvglm'><p> Calibration for CLO models (RR-VGLMs)</p></a></li>
<li><a href='#calibrate.rrvglm.control'><p> Control Function for CLO (RR-VGLM) Calibration</p></a></li>
<li><a href='#cao'><p> Fitting Constrained Additive Ordination (CAO)</p></a></li>
<li><a href='#cao.control'><p> Control Function for RR-VGAMs (CAO)</p></a></li>
<li><a href='#Card'><p> Cardioid Distribution</p></a></li>
<li><a href='#cardioid'><p> Cardioid Distribution Family Function</p></a></li>
<li><a href='#cauchitlink'><p> Cauchit Link Function</p></a></li>
<li><a href='#cauchy'><p> Cauchy Distribution Family Function</p></a></li>
<li><a href='#cdf.lmscreg'><p> Cumulative Distribution Function for LMS Quantile Regression</p></a></li>
<li><a href='#cens.gumbel'><p> Censored Gumbel Distribution</p></a></li>
<li><a href='#cens.normal'><p> Censored Normal Distribution</p></a></li>
<li><a href='#cens.poisson'><p> Censored Poisson Family Function</p></a></li>
<li><a href='#cfibrosis'><p> Cystic Fibrosis Data</p>

</p></a></li>
<li><a href='#cgo'><p> Redirects the user to cqo</p></a></li>
<li><a href='#chest.nz'><p> Chest Pain in NZ Adults Data</p></a></li>
<li><a href='#chinese.nz'><p> Chinese Population in New Zealand 1867&ndash;2001 Data</p></a></li>
<li><a href='#chisq'><p> Chi-squared and Chi Distributions</p></a></li>
<li><a href='#clo'><p> Redirects the User to rrvglm()</p></a></li>
<li><a href='#clogloglink'><p> Complementary Log-log Link Function</p></a></li>
<li><a href='#CM.equid'><p> Constraint Matrices for Symmetry, Order,</p>
Parallelism, etc.
</a></li>
<li><a href='#coalminers'><p> Breathlessness and Wheeze Amongst Coalminers Data</p></a></li>
<li><a href='#Coef'><p> Computes Model Coefficients and Quantities</p></a></li>
<li><a href='#Coef.qrrvglm'><p> Returns Important Matrices etc. of a QO Object</p></a></li>
<li><a href='#Coef.qrrvglm-class'><p>Class &ldquo;Coef.qrrvglm&rdquo;</p></a></li>
<li><a href='#Coef.rrvglm'><p> Returns Important Matrices etc. of a RR-VGLM Object</p></a></li>
<li><a href='#Coef.rrvglm-class'><p>Class &ldquo;Coef.rrvglm&rdquo;</p></a></li>
<li><a href='#Coef.vlm'><p> Extract Model Coefficients for VLM Objects</p></a></li>
<li><a href='#coefvgam'><p> Extract Model Coefficients of a vgam() Object</p></a></li>
<li><a href='#coefvlm'><p> Extract Model Coefficients</p></a></li>
<li><a href='#CommonVGAMffArguments'><p>Common VGAM Family Function Arguments</p></a></li>
<li><a href='#concoef'><p> Extract Model Constrained/Canonical Coefficients</p></a></li>
<li><a href='#concoef-methods'><p> Constrained (Canonical) Coefficients</p></a></li>
<li><a href='#confintvglm'><p> Confidence Intervals for Parameters of VGLMs</p></a></li>
<li><a href='#constraints'><p> Constraint Matrices</p></a></li>
<li><a href='#cops'><p> Centre of the Parameter Space</p></a></li>
<li><a href='#corbet'>
<p>Corbet's Butterfly Data</p>
</p>
</a></li>
<li><a href='#cqo'><p> Fitting Constrained Quadratic Ordination (CQO)</p></a></li>
<li><a href='#crashes'><p>Crashes on New Zealand Roads in 2009</p></a></li>
<li><a href='#cratio'><p> Ordinal Regression with Continuation Ratios</p></a></li>
<li><a href='#cumulative'><p> Ordinal Regression with Cumulative Probabilities</p></a></li>
<li><a href='#dagum'><p> Dagum Distribution Family Function</p></a></li>
<li><a href='#Dagum'><p>The Dagum Distribution</p></a></li>
<li><a href='#dAR1'><p>The AR-1 Autoregressive Process</p></a></li>
<li><a href='#deermice'>
<p>Captures of Peromyscus maniculatus (Also Known as Deer Mice).</p>
</p>
</a></li>
<li><a href='#deplot.lmscreg'><p> Density Plot for LMS Quantile Regression</p></a></li>
<li><a href='#depvar'><p> Response Variable Extracted</p></a></li>
<li><a href='#dextlogF'><p> Extended log-F Distribution</p></a></li>
<li><a href='#df.residual'><p>Residual Degrees-of-Freedom</p></a></li>
<li><a href='#dgaitdplot'>
<p>Plotting the GAITD Combo Density</p></a></li>
<li><a href='#dhuber'><p>Huber's Least Favourable Distribution</p></a></li>
<li><a href='#diffzeta'><p> Differenced Zeta Distribution Family Function</p></a></li>
<li><a href='#Diffzeta'><p> Differenced Zeta Distribution</p></a></li>
<li><a href='#dirichlet'><p> Fitting a Dirichlet Distribution</p></a></li>
<li><a href='#dirmul.old'><p>Fitting a Dirichlet-Multinomial Distribution</p></a></li>
<li><a href='#dirmultinomial'><p>Fitting a Dirichlet-Multinomial Distribution</p></a></li>
<li><a href='#dlogF'><p> log F Distribution</p></a></li>
<li><a href='#double.cens.normal'><p> Univariate Normal Distribution with Double Censoring</p></a></li>
<li><a href='#double.expbinomial'><p> Double Exponential Binomial Distribution Family Function</p></a></li>
<li><a href='#ducklings'>
<p>Relative Frequencies of Serum Proteins in White Pekin Ducklings</p>
</p>
</a></li>
<li><a href='#eCDF'><p>Empirical Cumulative Distribution Function</p></a></li>
<li><a href='#enzyme'><p> Enzyme Data</p></a></li>
<li><a href='#erf'><p> Error Function, and variants</p></a></li>
<li><a href='#erlang'><p> Erlang Distribution</p></a></li>
<li><a href='#Expectiles-Exponential'><p> Expectiles of the Exponential Distribution</p></a></li>
<li><a href='#Expectiles-Normal'><p> Expectiles of the Normal Distribution</p></a></li>
<li><a href='#Expectiles-sc.t2'><p> Expectiles/Quantiles of the Scaled Student t Distribution</p>
with 2 Df</a></li>
<li><a href='#Expectiles-Uniform'><p> Expectiles of the Uniform Distribution</p></a></li>
<li><a href='#expexpff'><p> Exponentiated Exponential Distribution</p></a></li>
<li><a href='#expexpff1'><p> Exponentiated Exponential Distribution</p></a></li>
<li><a href='#expgeom'><p>The Exponential Geometric Distribution</p></a></li>
<li><a href='#expgeometric'><p>Exponential Geometric Distribution Family Function</p></a></li>
<li><a href='#expint'>
<p>The Exponential Integral and Variants</p>
</p></a></li>
<li><a href='#explink'><p> Exponential Link Function</p></a></li>
<li><a href='#explog'><p>The Exponential Logarithmic Distribution</p></a></li>
<li><a href='#explogff'><p>Exponential Logarithmic Distribution Family Function</p></a></li>
<li><a href='#exponential'><p> Exponential Distribution</p></a></li>
<li><a href='#exppois'><p>The Exponential Poisson Distribution</p></a></li>
<li><a href='#exppoisson'><p>Exponential Poisson Distribution Family Function</p></a></li>
<li><a href='#Extbetabinom'><p>The Beta-Binomial Distribution</p></a></li>
<li><a href='#extbetabinomial'><p> Extended</p>
Beta-binomial Distribution Family Function</a></li>
<li><a href='#extlogF1'><p> Extended log-F Distribution</p>
Family Function
</p></a></li>
<li><a href='#familyname'><p> Family Function Name</p></a></li>
<li><a href='#felix'><p>Felix Distribution Family Function</p></a></li>
<li><a href='#Felix'><p>The Felix Distribution</p></a></li>
<li><a href='#fff'><p> F Distribution Family Function</p></a></li>
<li><a href='#fill1'><p> Creates a Matrix of Appropriate Dimension</p></a></li>
<li><a href='#finney44'><p> Toxicity trial for insects</p>
</a></li>
<li><a href='#fisherzlink'><p> Fisher's Z Link Function</p></a></li>
<li><a href='#fisk'><p> Fisk Distribution family function</p></a></li>
<li><a href='#Fisk'><p>The Fisk Distribution</p></a></li>
<li><a href='#fittedvlm'><p>Fitted Values of a VLM object</p></a></li>
<li><a href='#fix.crossing'><p>Fixing a Quantile Regression having Crossing</p></a></li>
<li><a href='#flourbeetle'><p>Mortality of Flour Beetles from Carbon Disulphide</p></a></li>
<li><a href='#Foldnorm'><p>The Folded-Normal Distribution</p></a></li>
<li><a href='#foldnormal'><p> Folded Normal Distribution Family Function</p></a></li>
<li><a href='#formulavlm'><p> Model Formulae and Term Names for VGLMs</p></a></li>
<li><a href='#Frank'><p>Frank's Bivariate Distribution</p></a></li>
<li><a href='#frechet'><p> Frechet Distribution Family Function</p></a></li>
<li><a href='#Frechet'><p>The Frechet Distribution</p></a></li>
<li><a href='#freund61'><p> Freund's (1961) Bivariate Extension of the</p>
Exponential Distribution</a></li>
<li><a href='#Gaitdbinom'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Binomial Distribution
</p></a></li>
<li><a href='#gaitdlog'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Logarithmic Regression
</p></a></li>
<li><a href='#Gaitdlog'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Logarithmic Distribution
</p></a></li>
<li><a href='#Gaitdnbinom'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Negative Binomial Distribution
</p></a></li>
<li><a href='#gaitdnbinomial'><p> Generally Altered, Inflated, Truncated and Deflated</p>
Negative Binomial Regression
</p></a></li>
<li><a href='#Gaitdpois'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Poisson Distribution
</p></a></li>
<li><a href='#gaitdpoisson'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Poisson Regression
</p></a></li>
<li><a href='#gaitdzeta'><p> Generally Altered, Inflated, Truncated</p>
and Deflated
Zeta Regression
</p></a></li>
<li><a href='#Gaitdzeta'><p> Generally Altered, Inflated and Truncated</p>
and Deflated
Zeta Distribution
</p></a></li>
<li><a href='#gamma1'><p> 1-parameter Gamma Regression Family Function</p></a></li>
<li><a href='#gamma2'><p> 2-parameter Gamma Regression Family Function</p></a></li>
<li><a href='#gammaff.mm'><p> Multivariate Gamma Family Function:</p>
Mathai and Moschopoulos (1992)</a></li>
<li><a href='#gammahyperbola'><p> Gamma Hyperbola Bivariate Distribution</p></a></li>
<li><a href='#gammaR'><p> 2-parameter Gamma Regression Family Function</p></a></li>
<li><a href='#garma'><p>GARMA (Generalized Autoregressive Moving-Average) Models</p></a></li>
<li><a href='#genbetaII'><p> Generalized Beta Distribution of the Second Kind</p></a></li>
<li><a href='#GenbetaII'><p>The Generalized Beta II Distribution</p></a></li>
<li><a href='#gengamma.stacy'><p> Generalized Gamma distribution family function</p></a></li>
<li><a href='#gengammaUC'><p>Generalized Gamma Distribution</p></a></li>
<li><a href='#Genpois0'><p>Generalized Poisson Distribution</p>
(Original Parameterization)</a></li>
<li><a href='#Genpois1'><p>Generalized Poisson Distribution</p>
(GP-1 and GP-2 Parameterizations of the Mean)</a></li>
<li><a href='#genpoisson0'><p> Generalized Poisson Regression</p>
(Original Parameterization)</a></li>
<li><a href='#genpoisson1'><p> Generalized Poisson Regression</p>
(GP-1 Parameterization)</a></li>
<li><a href='#genpoisson2'><p> Generalized Poisson Regression</p>
(GP-2 Parameterization)</a></li>
<li><a href='#genray'><p>The Generalized Rayleigh Distribution</p></a></li>
<li><a href='#genrayleigh'><p>Generalized Rayleigh Distribution Family Function</p></a></li>
<li><a href='#gensh'><p> Generalized Secant Hyperbolic Regression</p>
Family Function</a></li>
<li><a href='#Gensh'><p> Generalized Secant Hyperbolic</p>
Distribution
</p></a></li>
<li><a href='#geometric'><p> Geometric (Truncated and Untruncated) Distributions</p></a></li>
<li><a href='#get.smart'><p> Retrieve One Component of &ldquo;.smart.prediction&rdquo;</p></a></li>
<li><a href='#get.smart.prediction'><p> Retrieves &ldquo;.smart.prediction&rdquo;</p></a></li>
<li><a href='#gev'><p> Generalized Extreme Value Regression Family Function</p></a></li>
<li><a href='#gevUC'><p>The Generalized Extreme Value Distribution</p></a></li>
<li><a href='#gew'><p> General Electric and Westinghouse Data</p></a></li>
<li><a href='#goffset'>
<p>GAITD Offset for the GTE Method</p>
</p></a></li>
<li><a href='#gompertz'><p> Gompertz Regression Family Function</p></a></li>
<li><a href='#Gompertz'><p>Gompertz Distribution</p></a></li>
<li><a href='#gpd'><p> Generalized Pareto Distribution Regression Family Function</p></a></li>
<li><a href='#gpdUC'><p>The Generalized Pareto Distribution</p></a></li>
<li><a href='#grain.us'><p>Grain Prices Data in USA</p></a></li>
<li><a href='#grc'><p> Row-Column Interaction Models including Goodman's RC Association</p>
Model and Unconstrained Quadratic Ordination</a></li>
<li><a href='#gumbel'><p> Gumbel Regression Family Function</p></a></li>
<li><a href='#Gumbel-II'><p>The Gumbel-II Distribution</p></a></li>
<li><a href='#gumbelII'><p> Gumbel-II Regression Family Function</p></a></li>
<li><a href='#gumbelUC'><p> The Gumbel Distribution</p></a></li>
<li><a href='#guplot'><p> Gumbel Plot</p></a></li>
<li><a href='#has.interceptvlm'><p> Has a Fitted VGLM Got an Intercept Term?</p></a></li>
<li><a href='#hatvalues'><p>Hat Values and Regression Deletion Diagnostics</p></a></li>
<li><a href='#hdeff'><p> Hauck-Donner Effects: A Detection Test for Wald Tests</p></a></li>
<li><a href='#hdeffsev'><p> Hauck-Donner Effects: Severity Measures</p></a></li>
<li><a href='#hormone'>
<p>Hormone Assay Data</p>
</p></a></li>
<li><a href='#hspider'><p> Hunting Spider Data</p></a></li>
<li><a href='#huber2'><p> Huber's Least Favourable Distribution Family Function</p></a></li>
<li><a href='#Huggins89.t1'>
<p>Table 1 of Huggins (1989)</p></a></li>
<li><a href='#hunua'><p>Hunua Ranges Data</p></a></li>
<li><a href='#hurea'><p> Husler-Reiss Angular Surface</p>
Distribution Family Function</a></li>
<li><a href='#Hurea'><p>The Husler-Reiss Angular Surface Distribution</p></a></li>
<li><a href='#hyperg'><p> Hypergeometric Family Function</p></a></li>
<li><a href='#hypersecant'><p> Hyperbolic Secant Regression Family Function</p></a></li>
<li><a href='#hzeta'><p> Haight's Zeta Family Function</p></a></li>
<li><a href='#Hzeta'><p> Haight's Zeta Distribution</p></a></li>
<li><a href='#iam'><p> Index from Array to Matrix</p></a></li>
<li><a href='#identitylink'><p> Identity Link Function</p></a></li>
<li><a href='#Influence'>
<p>Influence Function (S4 generic)</p>
of a Fitted Model
</p></a></li>
<li><a href='#inv.binomial'><p>Inverse Binomial Distribution Family Function</p></a></li>
<li><a href='#Inv.gaussian'><p>The Inverse Gaussian Distribution</p></a></li>
<li><a href='#inv.gaussianff'><p> Inverse Gaussian Distribution Family Function</p></a></li>
<li><a href='#inv.lomax'><p> Inverse Lomax Distribution Family Function</p></a></li>
<li><a href='#Inv.lomax'><p>The Inverse Lomax Distribution</p></a></li>
<li><a href='#inv.paralogistic'><p> Inverse Paralogistic Distribution Family Function</p></a></li>
<li><a href='#Inv.paralogistic'><p>The Inverse Paralogistic Distribution</p></a></li>
<li><a href='#is.buggy'><p> Does the Fitted Object Suffer from a Known Bug?</p></a></li>
<li><a href='#is.crossing'><p>Quantile Crossing Detection</p></a></li>
<li><a href='#is.parallel'><p>Parallelism Constraint Matrices</p></a></li>
<li><a href='#is.smart'>
<p>Test For a Smart Object</p></a></li>
<li><a href='#is.zero'><p>Zero Constraint Matrices</p></a></li>
<li><a href='#kendall.tau'>
<p>Kendall's Tau Statistic</p>
</p></a></li>
<li><a href='#KLD'><p> Kullback-Leibler Divergence</p></a></li>
<li><a href='#kumar'><p>Kumaraswamy Regression Family Function</p></a></li>
<li><a href='#Kumar'><p>The Kumaraswamy Distribution</p></a></li>
<li><a href='#lakeO'>
<p>Annual catches on Lake Otamangakau from October 1974 to October 1989</p>
</p>
</a></li>
<li><a href='#lambertW'>
<p>The Lambert W Function</p></a></li>
<li><a href='#laplace'><p> Laplace Regression Family Function</p></a></li>
<li><a href='#laplaceUC'><p> The Laplace Distribution</p></a></li>
<li><a href='#latvar'><p> Latent Variables</p></a></li>
<li><a href='#leipnik'><p>Leipnik Regression Family Function</p></a></li>
<li><a href='#lerch'><p> Lerch Phi Function</p></a></li>
<li><a href='#leukemia'><p>Acute Myelogenous Leukemia Survival Data</p></a></li>
<li><a href='#levy'><p> Levy Distribution Family Function</p></a></li>
<li><a href='#lgamma1'><p> Log-gamma Distribution Family Function</p></a></li>
<li><a href='#lgammaUC'><p>The Log-Gamma Distribution</p></a></li>
<li><a href='#lindley'><p> 1-parameter Gamma Distribution</p></a></li>
<li><a href='#Lindley'><p>The Lindley Distribution</p></a></li>
<li><a href='#linkfun'><p> Link Functions for VGLMs</p></a></li>
<li><a href='#Links'><p>Link functions for VGLM/VGAM/etc. families</p></a></li>
<li><a href='#lino'><p> Generalized Beta Distribution Family Function</p></a></li>
<li><a href='#Lino'><p>The Generalized Beta Distribution (Libby and Novick, 1982)</p></a></li>
<li><a href='#lirat'><p> Low-iron Rat Teratology Data</p></a></li>
<li><a href='#lms.bcg'><p> LMS Quantile Regression with a Box-Cox transformation</p>
to a Gamma Distribution</a></li>
<li><a href='#lms.bcn'><p> LMS Quantile Regression with a Box-Cox Transformation to</p>
Normality</a></li>
<li><a href='#lms.yjn'><p> LMS Quantile Regression with a Yeo-Johnson Transformation</p>
to Normality</a></li>
<li><a href='#Log'><p> Logarithmic Distribution</p></a></li>
<li><a href='#log1mexp'>
<p>Logarithms with an Unit Offset and Exponential Term</p></a></li>
<li><a href='#logclink'><p> Complementary-log Link Function</p></a></li>
<li><a href='#logF'><p> Natural Exponential Family Generalized Hyperbolic Secant</p>
Distribution Family Function
</p></a></li>
<li><a href='#logff'><p> Logarithmic Distribution</p></a></li>
<li><a href='#logistic'><p> Logistic Distribution Family Function</p></a></li>
<li><a href='#logitlink'><p> Logit Link Function</p></a></li>
<li><a href='#logitoffsetlink'><p> Logit-with-an-Offset Link Function</p></a></li>
<li><a href='#loglaplace'><p> Log-Laplace and Logit-Laplace Distribution Family</p>
Functions</a></li>
<li><a href='#loglapUC'><p> The Log-Laplace Distribution</p></a></li>
<li><a href='#logLik.vlm'><p>Extract Log-likelihood for VGLMs/VGAMs/etc.</p></a></li>
<li><a href='#loglinb2'><p> Loglinear Model for Two Binary Responses</p></a></li>
<li><a href='#loglinb3'><p> Loglinear Model for Three Binary Responses</p></a></li>
<li><a href='#loglink'><p> Log Link Function, and Variants</p></a></li>
<li><a href='#logloglink'><p> Log-log and Log-log-log Link Functions</p></a></li>
<li><a href='#lognormal'><p> Lognormal Distribution</p></a></li>
<li><a href='#logofflink'><p> Log Link Function with an Offset</p></a></li>
<li><a href='#lomax'><p> Lomax Distribution Family Function</p></a></li>
<li><a href='#Lomax'><p>The Lomax Distribution</p></a></li>
<li><a href='#lpossums'><p> Leadbeater's Possums</p></a></li>
<li><a href='#lqnorm'><p> Minimizing the L-q norm Family Function</p></a></li>
<li><a href='#lrt.stat'><p> Likelihood Ratio Test</p>
Statistics Evaluated at the Null Values</a></li>
<li><a href='#lrtest'><p>Likelihood Ratio Test of Nested Models</p></a></li>
<li><a href='#lvplot'><p> Latent Variable Plot</p></a></li>
<li><a href='#lvplot.qrrvglm'><p> Latent Variable Plot for QO models</p></a></li>
<li><a href='#lvplot.rrvglm'><p> Latent Variable Plot for RR-VGLMs</p></a></li>
<li><a href='#machinists'><p> Machinists Accidents</p></a></li>
<li><a href='#makeham'><p> Makeham Regression Family Function</p></a></li>
<li><a href='#Makeham'><p>The Makeham Distribution</p></a></li>
<li><a href='#margeff'><p> Marginal Effects for Several Categorical Response Models</p></a></li>
<li><a href='#marital.nz'>
<p>New Zealand Marital Data</p></a></li>
<li><a href='#Max'><p> Maximums</p></a></li>
<li><a href='#maxwell'><p> Maxwell Regression Family Function</p></a></li>
<li><a href='#Maxwell'><p>The Maxwell Distribution</p></a></li>
<li><a href='#mccullagh89'><p>McCullagh (1989) Distribution Family Function</p></a></li>
<li><a href='#meangaitd'>
<p>Mean of the GAITD Combo Density</p>
</p></a></li>
<li><a href='#melbmaxtemp'><p> Melbourne Daily Maximum Temperatures</p></a></li>
<li><a href='#meplot'><p> Mean Excess Plot</p></a></li>
<li><a href='#micmen'><p> Michaelis-Menten Model</p></a></li>
<li><a href='#mills.ratio'><p> Mills Ratio</p></a></li>
<li><a href='#mix2exp'><p> Mixture of Two Exponential Distributions</p></a></li>
<li><a href='#mix2normal'><p> Mixture of Two Univariate Normal Distributions</p></a></li>
<li><a href='#mix2poisson'><p> Mixture of Two Poisson Distributions</p></a></li>
<li><a href='#MNSs'><p> The MNSs Blood Group System</p></a></li>
<li><a href='#model.framevlm'><p>Construct the Model Frame of a VLM Object</p></a></li>
<li><a href='#model.matrixqrrvglm'><p>Construct the Model Matrix of a QRR-VGLM Object</p></a></li>
<li><a href='#model.matrixvlm'><p>Construct the Design Matrix of a VLM Object</p></a></li>
<li><a href='#moffset'>
<p>Matrix Offset</p>
</p></a></li>
<li><a href='#multilogitlink'><p> Multi-logit Link Function</p></a></li>
<li><a href='#multinomial'><p> Multinomial Logit Model</p></a></li>
<li><a href='#nakagami'><p> Nakagami Regression Family Function</p></a></li>
<li><a href='#Nakagami'><p>Nakagami Distribution</p></a></li>
<li><a href='#nbcanlink'><p> Negative Binomial Canonical Link Function</p></a></li>
<li><a href='#negbinomial'><p> Negative Binomial Distribution Family Function</p></a></li>
<li><a href='#negbinomial.size'><p> Negative Binomial Distribution Family Function With Known Size</p></a></li>
<li><a href='#normal.vcm'><p> Univariate Normal Distribution as a Varying-Coefficient Model</p></a></li>
<li><a href='#notdocumentedyet'><p> Undocumented and Internally Used Functions and Classes</p></a></li>
<li><a href='#nparam.vlm'><p> Number of Parameters</p></a></li>
<li><a href='#olympics'><p> 2008 and 2012 Summer Olympic Final Medal Count Data</p></a></li>
<li><a href='#Opt'><p> Optimums</p></a></li>
<li><a href='#ordpoisson'><p> Ordinal Poisson Family Function</p></a></li>
<li><a href='#ordsup'><p> Ordinal Superiority</p>
Measures</a></li>
<li><a href='#oxtemp'><p> Oxford Temperature Data</p></a></li>
<li><a href='#paralogistic'><p> Paralogistic Distribution Family Function</p></a></li>
<li><a href='#Paralogistic'><p>The Paralogistic Distribution</p></a></li>
<li><a href='#Pareto'><p>The Pareto Distribution</p></a></li>
<li><a href='#paretoff'><p>Pareto and Truncated Pareto Distribution Family Functions</p></a></li>
<li><a href='#paretoIV'><p>Pareto(IV/III/II) Distribution Family Functions</p></a></li>
<li><a href='#ParetoIV'><p>The Pareto(IV/III/II) Distributions</p></a></li>
<li><a href='#perks'><p> Perks Distribution Family Function</p></a></li>
<li><a href='#Perks'><p>The Perks Distribution</p></a></li>
<li><a href='#perspqrrvglm'><p> Perspective plot for QRR-VGLMs</p></a></li>
<li><a href='#pgamma.deriv'>
<p>Derivatives of the Incomplete Gamma Integral</p></a></li>
<li><a href='#pgamma.deriv.unscaled'>
<p>Derivatives of the Incomplete Gamma Integral (Unscaled Version)</p></a></li>
<li><a href='#plotdeplot.lmscreg'><p> Density Plot for LMS Quantile Regression</p></a></li>
<li><a href='#plotdgaitd.vglm'>
<p>Plotting the GAITD Combo Density from a GAITD Regression Object</p>
</p></a></li>
<li><a href='#plotqrrvglm'><p> Model Diagnostic Plots for QRR-VGLMs</p></a></li>
<li><a href='#plotqtplot.lmscreg'><p> Quantile Plot for LMS Quantile Regression</p></a></li>
<li><a href='#plotrcim0'><p> Main Effects Plot for a Row-Column Interaction Model (RCIM)</p>
</p></a></li>
<li><a href='#plotvgam'><p> Default VGAM Plotting</p></a></li>
<li><a href='#plotvgam.control'><p> Control Function for plotvgam()</p></a></li>
<li><a href='#plotvglm'><p> Plots for VGLMs</p></a></li>
<li><a href='#pneumo'><p>Pneumoconiosis in Coalminers Data</p></a></li>
<li><a href='#poisson.points'><p> Poisson-points-on-a-plane/volume Distances Distribution</p></a></li>
<li><a href='#poissonff'><p> Poisson Regression</p></a></li>
<li><a href='#PoissonPoints'><p>Poisson Points Distribution</p></a></li>
<li><a href='#Polono'><p>The Poisson Lognormal Distribution</p></a></li>
<li><a href='#posbernoulli.b'><p> Positive Bernoulli Family Function with Behavioural Effects</p></a></li>
<li><a href='#posbernoulli.t'><p> Positive Bernoulli Family Function with Time Effects</p></a></li>
<li><a href='#posbernoulli.tb'><p> Positive Bernoulli Family Function with Time and</p>
Behavioural Effects</a></li>
<li><a href='#posbernUC'><p> Positive Bernoulli Sequence Model</p></a></li>
<li><a href='#posbinomial'><p> Positive Binomial Distribution Family Function</p></a></li>
<li><a href='#Posgeom'><p> Positive-Geometric Distribution</p></a></li>
<li><a href='#posnegbinomial'><p> Positive Negative Binomial Distribution Family Function</p></a></li>
<li><a href='#Posnorm'><p>The Positive-Normal Distribution</p></a></li>
<li><a href='#posnormal'><p> Positive Normal Distribution Family Function</p></a></li>
<li><a href='#pospoisson'><p> Positive Poisson Distribution Family Function</p></a></li>
<li><a href='#powerlink'><p> Power Link Function</p></a></li>
<li><a href='#prats'><p> Pregnant Rats Toxological Experiment Data</p></a></li>
<li><a href='#predictqrrvglm'><p> Predict Method for a CQO fit</p></a></li>
<li><a href='#predictvglm'><p>Predict Method for a VGLM fit</p></a></li>
<li><a href='#prentice74'><p> Prentice (1974) Log-gamma Distribution</p></a></li>
<li><a href='#prinia'><p>Yellow-bellied Prinia</p>

</p></a></li>
<li><a href='#probitlink'><p> Probit Link Function</p></a></li>
<li><a href='#profilevglm'><p>Method for Profiling vglm Objects</p></a></li>
<li><a href='#propodds'><p> Proportional Odds Model for Ordinal Regression</p></a></li>
<li><a href='#prplot'>
<p>Probability Plots for Categorical Data Analysis</p>
</p></a></li>
<li><a href='#put.smart'><p> Adds a List to the End of the List &ldquo;.smart.prediction&rdquo;</p></a></li>
<li><a href='#qrrvglm.control'><p> Control Function for QRR-VGLMs (CQO)</p></a></li>
<li><a href='#qtplot.gumbel'><p> Quantile Plot for Gumbel Regression</p></a></li>
<li><a href='#qtplot.lmscreg'><p> Quantile Plot for LMS Quantile Regression</p></a></li>
<li><a href='#qvar'>
<p>Quasi-variances Extraction Function</p>
</p>
</a></li>
<li><a href='#Qvar'>
<p>Quasi-variances Preprocessing Function</p>
</p>
</a></li>
<li><a href='#R2latvar'><p> R-squared for Latent Variable Models</p></a></li>
<li><a href='#Rank'><p> Rank</p></a></li>
<li><a href='#rayleigh'><p>Rayleigh Regression Family Function</p></a></li>
<li><a href='#Rayleigh'><p>Rayleigh Distribution</p></a></li>
<li><a href='#Rcim'>
<p>Mark the Baseline of Row and Column on a Matrix data</p>
</p></a></li>
<li><a href='#rcqo'><p> Constrained Quadratic Ordination</p></a></li>
<li><a href='#rdiric'><p> The Dirichlet distribution</p></a></li>
<li><a href='#rec.exp1'><p> Upper Record Values from a 1-parameter</p>
Exponential Distribution</a></li>
<li><a href='#rec.normal'><p> Upper Record Values from a Univariate Normal Distribution</p></a></li>
<li><a href='#reciprocallink'><p> Reciprocal Link Function</p></a></li>
<li><a href='#residualsvglm'><p>Residuals for a VGLM fit</p></a></li>
<li><a href='#rhobitlink'><p> Rhobit Link Function</p></a></li>
<li><a href='#Rice'><p>The Rice Distribution</p></a></li>
<li><a href='#riceff'><p>Rice Distribution Family Function</p></a></li>
<li><a href='#rigff'><p> Reciprocal Inverse Gaussian distribution</p></a></li>
<li><a href='#rlplot.gevff'><p> Return Level Plot for GEV Fits</p></a></li>
<li><a href='#rootogram4'>
<p>Rootograms (S4 generic)</p>
for Assessing Goodness of Fit of Probability Models
</p></a></li>
<li><a href='#round2'><p> Rounding of Numbers to Base 2</p></a></li>
<li><a href='#rrar'><p> Nested Reduced-rank Autoregressive Models for Multiple</p>
Time Series</a></li>
<li><a href='#rrvglm'><p>Fitting Reduced-Rank Vector Generalized Linear Models</p>
(RR-VGLMs)
and Doubly Constrained RR-VGLMs (DRR-VGLMs)</a></li>
<li><a href='#rrvglm-class'><p>Class &ldquo;rrvglm&rdquo;</p></a></li>
<li><a href='#rrvglm.control'><p> Control Function for rrvglm()</p></a></li>
<li><a href='#rrvglm.optim.control'><p> Control Function for rrvglm() Calling optim()</p></a></li>
<li><a href='#ruge'><p>Rutherford-Geiger Polonium Data</p></a></li>
<li><a href='#s'><p> Defining Smooths in VGAM Formulas</p></a></li>
<li><a href='#sc.studentt2'><p> Scaled Student t Distribution with 2 df Family Function</p></a></li>
<li><a href='#score.stat'><p> Rao's Score Test</p>
Statistics Evaluated at the Null Values</a></li>
<li><a href='#seglines'><p> Hauck-Donner Effects: Segmented Lines Plot</p></a></li>
<li><a href='#Select'><p> Select Variables for a Formula Response or the RHS of a Formula</p>
</p>
</a></li>
<li><a href='#seq2binomial'><p> The Two-stage Sequential Binomial Distribution Family Function</p></a></li>
<li><a href='#setup.smart'><p> Smart Prediction Setup</p></a></li>
<li><a href='#simplex'><p> Simplex Distribution Family Function</p></a></li>
<li><a href='#Simplex '><p> Simplex Distribution</p></a></li>
<li><a href='#simulate.vlm'><p>Simulate Responses for VGLMs and VGAMs</p></a></li>
<li><a href='#sinmad'><p> Singh-Maddala Distribution Family Function</p></a></li>
<li><a href='#Sinmad'><p>The Singh-Maddala Distribution</p></a></li>
<li><a href='#skellam'><p>Skellam Distribution Family Function</p></a></li>
<li><a href='#Skellam'><p>The Skellam Distribution</p></a></li>
<li><a href='#skewnorm'><p> Skew-Normal Distribution</p></a></li>
<li><a href='#skewnormal'><p> Univariate Skew-Normal Distribution Family Function</p></a></li>
<li><a href='#slash'><p> Slash Distribution Family Function</p></a></li>
<li><a href='#Slash'><p> Slash Distribution</p></a></li>
<li><a href='#sloglink'><p> Square root&ndash;Log Link Mixtures</p></a></li>
<li><a href='#sm.os'><p> Defining O'Sullivan Spline Smooths in VGAM Formulas</p></a></li>
<li><a href='#sm.ps'><p> Defining Penalized Spline Smooths in VGAM Formulas</p></a></li>
<li><a href='#smart.expression'><p> S Expression for Smart Functions</p></a></li>
<li><a href='#smart.mode.is'><p> Determine What Mode the Smart Prediction is In</p></a></li>
<li><a href='#smartpred'><p> Smart Prediction</p></a></li>
<li><a href='#specials'>
<p>Special Values or Quantities in a Fitted Object</p>
</p></a></li>
<li><a href='#spikeplot'>
<p>Spike Plot</p>
</p></a></li>
<li><a href='#sqrtlink'><p> Square Root and Folded Square Root Link Functions</p></a></li>
<li><a href='#sratio'><p> Ordinal Regression with Stopping Ratios</p></a></li>
<li><a href='#step4'>
<p>Choose a model by AIC in a Stepwise Algorithm</p>
</p></a></li>
<li><a href='#studentt'><p> Student t Distribution</p></a></li>
<li><a href='#summary.drrvglm'><p>Summarizing</p>
Reduced Rank
Vector Generalized Linear Model (RR-VGLM) and
Doubly constrained RR-VGLM Fits
</p></a></li>
<li><a href='#summarypvgam'><p>Summarizing Penalized Vector Generalized Additive Model Fits</p></a></li>
<li><a href='#summaryvgam'><p>Summarizing Vector Generalized Additive Model Fits</p></a></li>
<li><a href='#summaryvglm'><p>Summarizing Vector Generalized Linear Model Fits</p></a></li>
<li><a href='#SURff'><p> Seemingly Unrelated Regressions Family Function</p>
</a></li>
<li><a href='#SurvS4'>
<p>Create a Survival Object</p></a></li>
<li><a href='#SurvS4-class'><p>Class &quot;SurvS4&quot;</p></a></li>
<li><a href='#TIC'><p> Takeuchi's Information Criterion</p></a></li>
<li><a href='#tobit'><p> Tobit Regression</p></a></li>
<li><a href='#Tobit'><p>The Tobit Distribution</p></a></li>
<li><a href='#Tol'><p> Tolerances</p></a></li>
<li><a href='#topple'><p> Topp-Leone Distribution Family Function</p></a></li>
<li><a href='#Topple'><p>The Topp-Leone Distribution</p></a></li>
<li><a href='#toxop'><p> Toxoplasmosis Data</p></a></li>
<li><a href='#triangle'><p>Triangle Distribution Family Function</p></a></li>
<li><a href='#Triangle'><p>The Triangle Distribution</p></a></li>
<li><a href='#trim.constraints'><p> Trimmed Constraint Matrices</p></a></li>
<li><a href='#Trinorm'><p>Trivariate Normal Distribution Density and Random Variates</p></a></li>
<li><a href='#trinormal'><p> Trivariate Normal Distribution Family Function</p></a></li>
<li><a href='#trplot'><p> Trajectory Plot</p></a></li>
<li><a href='#trplot.qrrvglm'><p> Trajectory plot for QRR-VGLMs</p></a></li>
<li><a href='#Trunc'><p> Truncated Values for the GT-Expansion Method</p>
</p></a></li>
<li><a href='#Truncpareto'><p>The Truncated Pareto Distribution</p></a></li>
<li><a href='#truncweibull'><p> Truncated Weibull Distribution Family Function</p></a></li>
<li><a href='#ucberk'><p> University California Berkeley Graduate Admissions</p></a></li>
<li><a href='#undocumented-methods'><p> Undocumented Methods Functions</p></a></li>
<li><a href='#uninormal'><p> Univariate Normal Distribution</p></a></li>
<li><a href='#UtilitiesVGAM'><p>Utility Functions for the VGAM Package</p></a></li>
<li><a href='#V1'><p> V1 Flying-Bombs Hits in London</p></a></li>
<li><a href='#V2'><p> V2 Missile Hits in London</p></a></li>
<li><a href='#vcovvlm'><p> Calculate Variance-Covariance Matrix for</p>
a Fitted
VLM or RR-VGLM or DRR-VGLM
or QRR-VGLM
Object
</p></a></li>
<li><a href='#venice'><p> Venice Maximum Sea Levels Data</p></a></li>
<li><a href='#vgam'><p> Fitting Vector Generalized Additive Models</p></a></li>
<li><a href='#vgam-class'><p>Class &ldquo;vgam&rdquo;</p></a></li>
<li><a href='#VGAM-package'>
<p>Vector Generalized Linear and Additive Models</p>
and Other Associated Models</a></li>
<li><a href='#vgam.control'><p> Control Function for vgam()</p></a></li>
<li><a href='#vglm'><p>Fitting Vector Generalized Linear Models</p></a></li>
<li><a href='#vglm-class'><p>Class &ldquo;vglm&rdquo;</p></a></li>
<li><a href='#vglm.control'><p> Control Function for vglm()</p></a></li>
<li><a href='#vglmff-class'><p>Class &ldquo;vglmff&rdquo;</p></a></li>
<li><a href='#vonmises'><p> von Mises Distribution Family Function</p></a></li>
<li><a href='#vplot.profile'><p>Plotting Functions for 'profile' Objects</p></a></li>
<li><a href='#vsmooth.spline'><p> Vector Cubic Smoothing Spline</p></a></li>
<li><a href='#waitakere'><p>Waitakere Ranges Data</p></a></li>
<li><a href='#wald.stat'><p> Wald Test</p>
Statistics Evaluated at the Null Values</a></li>
<li><a href='#waldff'><p> Wald Distribution Family Function</p></a></li>
<li><a href='#weibull.mean'><p> Weibull Distribution Family Function,</p>
Parameterized by the Mean</a></li>
<li><a href='#weibullR'><p> Weibull Distribution Family Function</p></a></li>
<li><a href='#weightsvglm'><p> Prior and Working Weights of a VGLM fit</p></a></li>
<li><a href='#wine'><p> Bitterness in Wine Data</p>

</p></a></li>
<li><a href='#wrapup.smart'><p> Cleans Up After Smart Prediction</p></a></li>
<li><a href='#yeo.johnson'><p>Yeo-Johnson Transformation</p></a></li>
<li><a href='#Yules'><p> Yule-Simon Distribution</p></a></li>
<li><a href='#yulesimon'><p> Yule-Simon Family Function</p></a></li>
<li><a href='#Zabinom'><p> Zero-Altered Binomial Distribution</p></a></li>
<li><a href='#zabinomial'><p> Zero-Altered Binomial Distribution</p></a></li>
<li><a href='#Zageom'><p> Zero-Altered Geometric Distribution</p></a></li>
<li><a href='#zageometric'><p> Zero-Altered Geometric Distribution</p></a></li>
<li><a href='#Zanegbin'><p> Zero-Altered Negative Binomial Distribution</p></a></li>
<li><a href='#zanegbinomial'><p> Zero-Altered Negative Binomial Distribution</p></a></li>
<li><a href='#Zapois'><p> Zero-Altered Poisson Distribution</p></a></li>
<li><a href='#zapoisson'><p> Zero-Altered Poisson Distribution</p></a></li>
<li><a href='#zero'><p> The zero Argument in VGAM Family Functions</p></a></li>
<li><a href='#zeta'><p> Riemann's (and the Hurwitz) Zeta Function, With Derivatives</p></a></li>
<li><a href='#Zeta'><p>The Zeta Distribution</p></a></li>
<li><a href='#zetaff'><p> Zeta Distribution Family Function</p></a></li>
<li><a href='#Zibinom'><p> Zero-Inflated Binomial Distribution</p></a></li>
<li><a href='#zibinomial'><p> Zero-Inflated Binomial Distribution Family Function</p></a></li>
<li><a href='#Zigeom'><p> Zero-Inflated Geometric Distribution</p></a></li>
<li><a href='#zigeometric'><p> Zero-Inflated Geometric Distribution Family Function</p></a></li>
<li><a href='#Zinegbin'><p> Zero-Inflated Negative Binomial Distribution</p></a></li>
<li><a href='#zinegbinomial'><p> Zero-Inflated Negative Binomial Distribution Family Function</p></a></li>
<li><a href='#zipebcom'><p> Exchangeable Bivariate cloglog Odds-ratio Model From a</p>
Zero-inflated Poisson Distribution</a></li>
<li><a href='#zipf'><p> Zipf Distribution Family Function</p></a></li>
<li><a href='#Zipf'><p>The Zipf Distribution</p></a></li>
<li><a href='#Zipfmb'><p>The Zipf-Mandelbrot Distribution</p></a></li>
<li><a href='#Zipois'><p> Zero-Inflated Poisson Distribution</p></a></li>
<li><a href='#zipoisson'><p> Zero-Inflated Poisson Distribution Family Function</p></a></li>
<li><a href='#Zoabeta'><p>The Zero/One-Inflated Beta Distribution</p></a></li>
<li><a href='#zoabetaR'><p> Zero- and One-Inflated Beta Distribution Family Function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1-10</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-29</td>
</tr>
<tr>
<td>Title:</td>
<td>Vector Generalized Linear and Additive Models</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas Yee <a href="https://orcid.org/0000-0002-9970-3907"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Cleve Moler [ctb] (author of several LINPACK routines)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Yee &lt;t.yee@auckland.ac.nz&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), methods, stats, stats4, splines</td>
</tr>
<tr>
<td>Suggests:</td>
<td>VGAMextra, MASS, mgcv</td>
</tr>
<tr>
<td>Enhances:</td>
<td>VGAMdata</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of about 6 major classes of
    statistical regression models. The central algorithm is
    Fisher scoring and iterative reweighted least squares.
    At the heart of this package are the vector generalized linear
    and additive model (VGLM/VGAM) classes. VGLMs can be loosely
    thought of as multivariate GLMs. VGAMs are data-driven
    VGLMs that use smoothing. The book "Vector Generalized
    Linear and Additive Models: With an Implementation in R"
    (Yee, 2015) &lt;<a href="https://doi.org/10.1007%2F978-1-4939-2818-7">doi:10.1007/978-1-4939-2818-7</a>&gt; gives details of
    the statistical framework and the package. Currently only
    fixed-effects models are implemented. Many (100+) models and
    distributions are estimated by maximum likelihood estimation
    (MLE) or penalized MLE. The other classes are RR-VGLMs
    (reduced-rank VGLMs), quadratic RR-VGLMs, doubly constrained
    RR-VGLMs, quadratic RR-VGLMs, reduced-rank VGAMs,
    RCIMs (row-column interaction models)&mdash;these classes perform
    constrained and unconstrained quadratic ordination (CQO/UQO)
    models in ecology, as well as constrained additive ordination
    (CAO). Hauck-Donner effect detection is implemented.
    Note that these functions are subject to change;
    see the NEWS and ChangeLog files for latest changes.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.stat.auckland.ac.nz/~yee/VGAM/">https://www.stat.auckland.ac.nz/~yee/VGAM/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>BuildVignettes:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-29 04:58:13 UTC; tyee001</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-29 06:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='A1A2A3'> The A1A2A3 Blood Group System </h2><span id='topic+A1A2A3'></span>

<h3>Description</h3>

<p>Estimates the three independent parameters of the
the A1A2A3 blood group system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>A1A2A3(link = "logitlink", inbreeding = FALSE, ip1 = NULL, ip2 = NULL, iF = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="A1A2A3_+3A_link">link</code></td>
<td>

<p>Link function applied to <code>p1</code>, <code>p2</code> and <code>f</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="A1A2A3_+3A_inbreeding">inbreeding</code></td>
<td>

<p>Logical. Is there inbreeding?
</p>

</td></tr>
<tr><td><code id="A1A2A3_+3A_ip1">ip1</code>, <code id="A1A2A3_+3A_ip2">ip2</code>, <code id="A1A2A3_+3A_if">iF</code></td>
<td>

<p>Optional initial value for <code>p1</code>, <code>p2</code> and <code>f</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters <code>p1</code> and <code>p2</code> are probabilities, so that
<code>p3=1-p1-p2</code> is the third probability.
The parameter <code>f</code> is the third independent parameter if
<code>inbreeding = TRUE</code>.
If <code>inbreeding = FALSE</code> then <code class="reqn">f = 0</code> and Hardy-Weinberg
Equilibrium (HWE) is assumed.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The input can be a 6-column matrix of counts,
with columns corresponding to
<code>A1A1</code>,
<code>A1A2</code>,
<code>A1A3</code>,
<code>A2A2</code>,
<code>A2A3</code>,
<code>A3A3</code> (in order).
Alternatively, the input can be a 6-column matrix of
proportions (so each row adds to 1) and the <code>weights</code>
argument is used to specify the total number of counts for each row.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Lange, K. (2002).
<em>Mathematical and Statistical Methods for Genetic Analysis</em>,
2nd ed. New York: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AA.Aa.aa">AA.Aa.aa</a></code>,
<code><a href="#topic+AB.Ab.aB.ab">AB.Ab.aB.ab</a></code>,
<code><a href="#topic+ABO">ABO</a></code>,
<code><a href="#topic+MNSs">MNSs</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- cbind(108, 196, 429, 143, 513, 559)
fit &lt;- vglm(ymat ~ 1, A1A2A3(link = probitlink), trace = TRUE, crit = "coef")
fit &lt;- vglm(ymat ~ 1, A1A2A3(link = logitlink, ip1 = 0.3, ip2 = 0.3, iF = 0.02),
            trace = TRUE, crit = "coef")
Coef(fit)  # Estimated p1 and p2
rbind(ymat, sum(ymat) * fitted(fit))
sqrt(diag(vcov(fit)))
</code></pre>

<hr>
<h2 id='AA.Aa.aa'> The AA-Aa-aa Blood Group System </h2><span id='topic+AA.Aa.aa'></span>

<h3>Description</h3>

<p>Estimates the parameter of the
AA-Aa-aa blood group system,
with or without Hardy Weinberg equilibrium.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AA.Aa.aa(linkp = "logitlink", linkf = "logitlink", inbreeding = FALSE,
         ipA = NULL, ifp = NULL, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AA.Aa.aa_+3A_linkp">linkp</code>, <code id="AA.Aa.aa_+3A_linkf">linkf</code></td>
<td>

<p>Link functions applied to <code>pA</code> and <code>f</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="AA.Aa.aa_+3A_ipa">ipA</code>, <code id="AA.Aa.aa_+3A_ifp">ifp</code></td>
<td>

<p>Optional initial values for <code>pA</code> and <code>f</code>.
</p>
</td></tr>
<tr><td><code id="AA.Aa.aa_+3A_inbreeding">inbreeding</code></td>
<td>

<p>Logical. Is there inbreeding?
</p>

</td></tr>
<tr><td><code id="AA.Aa.aa_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This one or two parameter model involves a probability called <code>pA</code>.
The probability of getting a count in the first column of the
input (an AA) is <code>pA*pA</code>.
When <code>inbreeding = TRUE</code>, an additional parameter <code>f</code> is used.
If <code>inbreeding = FALSE</code> then <code class="reqn">f = 0</code> and Hardy-Weinberg
Equilibrium (HWE) is assumed.
The EIM is used if <code>inbreeding = FALSE</code>.
</p>




<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Setting <code>inbreeding = FALSE</code> makes estimation difficult
with non-intercept-only models.
Currently, this code seems to work with intercept-only models.
</p>


<h3>Note</h3>

<p>The input can be a 3-column matrix of counts, where the columns
are AA, Ab and aa
(in order).
Alternatively, the input can be a 3-column matrix of
proportions (so each row adds to 1) and the <code>weights</code>
argument is used to specify the total number of counts for each row.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Weir, B. S. (1996).
<em>Genetic Data Analysis II: Methods for Discrete Population
Genetic Data</em>,
Sunderland, MA: Sinauer Associates, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AB.Ab.aB.ab">AB.Ab.aB.ab</a></code>,
<code><a href="#topic+ABO">ABO</a></code>,
<code><a href="#topic+A1A2A3">A1A2A3</a></code>,
<code><a href="#topic+MNSs">MNSs</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- cbind(53, 95, 38)
fit1 &lt;- vglm(y ~ 1, AA.Aa.aa, trace = TRUE)
fit2 &lt;- vglm(y ~ 1, AA.Aa.aa(inbreeding = TRUE), trace = TRUE)
rbind(y, sum(y) * fitted(fit1))
Coef(fit1)  # Estimated pA
Coef(fit2)  # Estimated pA and f
summary(fit1)
</code></pre>

<hr>
<h2 id='AB.Ab.aB.ab'> The AB-Ab-aB-ab Blood Group System </h2><span id='topic+AB.Ab.aB.ab'></span>

<h3>Description</h3>

<p>Estimates the parameter of the
AB-Ab-aB-ab blood group system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AB.Ab.aB.ab(link = "logitlink", init.p = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AB.Ab.aB.ab_+3A_link">link</code></td>
<td>

<p>Link function applied to <code>p</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="AB.Ab.aB.ab_+3A_init.p">init.p</code></td>
<td>
<p> Optional initial value for <code>p</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This one parameter model involves a probability called <code>p</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The input can be a 4-column matrix of counts, where the columns
are AB, Ab, aB and ab
(in order).
Alternatively, the input can be a 4-column matrix of
proportions (so each row adds to 1) and the <code>weights</code>
argument is used to specify the total number of counts for each row.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Lange, K. (2002).
<em>Mathematical and Statistical Methods for Genetic Analysis</em>,
2nd ed. New York: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AA.Aa.aa">AA.Aa.aa</a></code>,
<code><a href="#topic+ABO">ABO</a></code>,
<code><a href="#topic+A1A2A3">A1A2A3</a></code>,
<code><a href="#topic+MNSs">MNSs</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- cbind(AB=1997, Ab=906, aB=904, ab=32)  # Data from Fisher (1925)
fit &lt;- vglm(ymat ~ 1, AB.Ab.aB.ab(link = "identitylink"), trace = TRUE)
fit &lt;- vglm(ymat ~ 1, AB.Ab.aB.ab, trace = TRUE)
rbind(ymat, sum(ymat)*fitted(fit))
Coef(fit)  # Estimated p
p &lt;- sqrt(4*(fitted(fit)[, 4]))
p*p
summary(fit)
</code></pre>

<hr>
<h2 id='ABO'> The ABO Blood Group System </h2><span id='topic+ABO'></span>

<h3>Description</h3>

<p>Estimates the two independent parameters of the
the ABO blood group system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ABO(link.pA = "logitlink", link.pB = "logitlink", ipA = NULL, ipB = NULL,
    ipO = NULL, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ABO_+3A_link.pa">link.pA</code>, <code id="ABO_+3A_link.pb">link.pB</code></td>
<td>

<p>Link functions applied to <code>pA</code> and <code>pB</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="ABO_+3A_ipa">ipA</code>, <code id="ABO_+3A_ipb">ipB</code>, <code id="ABO_+3A_ipo">ipO</code></td>
<td>

<p>Optional initial value for <code>pA</code> and <code>pB</code> and <code>pO</code>.
A <code>NULL</code> value means values are computed internally.
</p>
</td></tr>
<tr><td><code id="ABO_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters <code>pA</code> and <code>pB</code> are probabilities, so that
<code>pO=1-pA-pB</code> is the third probability.
The probabilities <code>pA</code> and <code>pB</code> correspond to A and B respectively,
so that <code>pO</code> is the probability for O.
It is easier to make use of initial values for <code>pO</code> than for <code>pB</code>.
In documentation elsewhere I sometimes use
<code>pA=p</code>,
<code>pB=q</code>,
<code>pO=r</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The input can be a 4-column matrix of counts, where the columns
are A, B, AB, O (in order).
Alternatively, the input can be a 4-column matrix of
proportions (so each row adds to 1) and the <code>weights</code>
argument is used to specify the total number of counts for each row.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Lange, K. (2002).
<em>Mathematical and Statistical Methods for Genetic Analysis</em>,
2nd ed. New York: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AA.Aa.aa">AA.Aa.aa</a></code>,
<code><a href="#topic+AB.Ab.aB.ab">AB.Ab.aB.ab</a></code>,
<code><a href="#topic+A1A2A3">A1A2A3</a></code>,
<code><a href="#topic+MNSs">MNSs</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- cbind(A = 725, B = 258, AB = 72, O = 1073)  # Order matters, not the name
fit &lt;- vglm(ymat ~ 1, ABO(link.pA = "identitylink",
                          link.pB = "identitylink"), trace = TRUE,
            crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)  # Estimated pA and pB
rbind(ymat, sum(ymat) * fitted(fit))
sqrt(diag(vcov(fit)))
</code></pre>

<hr>
<h2 id='acat'> Ordinal Regression with Adjacent Categories Probabilities </h2><span id='topic+acat'></span>

<h3>Description</h3>

<p>Fits an adjacent categories regression model to an ordered
(preferably) factor response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acat(link = "loglink", parallel = FALSE, reverse = FALSE,
     zero = NULL, ynames = FALSE, Thresh = NULL, Trev = reverse,
     Tref = if (Trev) "M" else 1, whitespace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acat_+3A_link">link</code></td>
<td>

<p>Link function applied to the ratios of the
adjacent categories probabilities.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="acat_+3A_parallel">parallel</code></td>
<td>

<p>A logical, or formula specifying which terms have
equal/unequal coefficients.
</p>
</td></tr>
<tr><td><code id="acat_+3A_reverse">reverse</code></td>
<td>

<p>Logical.
By default, the linear/additive predictors used are
<code class="reqn">\eta_j = \log(P[Y=j+1]/P[Y=j])</code>
for <code class="reqn">j=1,\ldots,M</code>.
If <code>reverse</code> is <code>TRUE</code> then
<code class="reqn">\eta_j = \log(P[Y=j]/P[Y=j+1])</code>
will be used.
</p>
</td></tr>
<tr><td><code id="acat_+3A_ynames">ynames</code></td>
<td>

<p>See <code><a href="#topic+multinomial">multinomial</a></code> for information.
</p>
</td></tr>
<tr><td><code id="acat_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The values must be from the set {1,2,...,<code class="reqn">M</code>}.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="acat_+3A_thresh">Thresh</code>, <code id="acat_+3A_trev">Trev</code>, <code id="acat_+3A_tref">Tref</code></td>
<td>

<p>See <code><a href="#topic+cumulative">cumulative</a></code> for information.
These arguments apply to ordinal
categorical regression models.
</p>
</td></tr>
<tr><td><code id="acat_+3A_whitespace">whitespace</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file the response <code class="reqn">Y</code> is assumed to be a
factor with ordered values <code class="reqn">1,2,\ldots,M+1</code>, so that
<code class="reqn">M</code> is the number of linear/additive predictors
<code class="reqn">\eta_j</code>.
By default, the log link is used because the ratio of
two probabilities is positive.
</p>
<p>Internally, <code><a href="stats.html#topic+deriv3">deriv3</a></code> is called to
perform symbolic differentiation and
consequently this family function will struggle if
<code class="reqn">M</code> becomes too large.
If this occurs, try combining levels so that
<code class="reqn">M</code> is effectively reduced.
One idea is to aggregate levels with the fewest observations
in them first.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>No check is made to verify that the response is ordinal if the
response is a matrix;
see <code><a href="base.html#topic+factor">ordered</a></code>.
</p>


<h3>Note</h3>

<p>The response should be either a matrix of counts
(with row sums that are
all positive), or an ordered factor. In both cases,
the <code>y</code> slot returned
by <code>vglm</code>/<code>vgam</code>/<code>rrvglm</code> is the
matrix of counts.
</p>
<p>For a nominal (unordered) factor response,
the multinomial logit model
(<code><a href="#topic+multinomial">multinomial</a></code>) is more appropriate.
</p>
<p>Here is an example of the usage of the <code>parallel</code> argument.
If there are covariates <code>x1</code>, <code>x2</code> and <code>x3</code>, then
<code>parallel = TRUE ~ x1 + x2 -1</code> and
<code>parallel = FALSE ~ x3</code> are equivalent.
This would constrain the regression coefficients
for <code>x1</code> and <code>x2</code> to be equal; those of the
intercepts and <code>x3</code> would be different.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Agresti, A. (2013).
<em>Categorical Data Analysis</em>,
3rd ed. Hoboken, NJ, USA: Wiley.
<br />
Tutz, G. (2012).
<em>Regression for Categorical Data</em>,
Cambridge: Cambridge University Press.
<br />
Yee, T. W. (2010).
The <span class="pkg">VGAM</span> package for categorical data analysis.
<em>Journal of Statistical Software</em>,
<b>32</b>, 1&ndash;34.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>












<h3>See Also</h3>

<p><code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+CM.equid">CM.equid</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+margeff">margeff</a></code>,
<code><a href="#topic+pneumo">pneumo</a></code>,
<code><a href="#topic+budworm">budworm</a></code>,
<code><a href="stats.html#topic+deriv3">deriv3</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let, acat, pneumo))
coef(fit, matrix = TRUE)
constraints(fit)
model.matrix(fit)
</code></pre>

<hr>
<h2 id='add1.vglm'>Add or Drop All Possible Single Terms to/from a Model</h2><span id='topic+add1.vglm'></span><span id='topic+drop1.vglm'></span>

<h3>Description</h3>

<p>Compute all the single terms in the <code>scope</code> argument that
can be
added to or
dropped from the model, fit those models and compute a
table of the changes in fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vglm'
add1(object, scope, test = c("none", "LRT"), k = 2, ...)
## S3 method for class 'vglm'
drop1(object, scope, test = c("none", "LRT"), k = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add1.vglm_+3A_object">object</code></td>
<td>
<p>a fitted <code><a href="#topic+vglm">vglm</a></code> model object.</p>
</td></tr>
<tr><td><code id="add1.vglm_+3A_scope">scope</code>, <code id="add1.vglm_+3A_k">k</code></td>
<td>
<p>See <code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code>.</p>
</td></tr>

<tr><td><code id="add1.vglm_+3A_test">test</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code>
but with fewer choices.
</p>
</td></tr>


<tr><td><code id="add1.vglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are a direct adaptation of
<code><a href="stats.html#topic+add1.glm">add1.glm</a></code>
and
<code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code>
for <code><a href="#topic+vglm-class">vglm-class</a></code> objects.
For <code>drop1</code> methods, a missing <code>scope</code> is taken to
be all terms in the model. The hierarchy is respected when
considering terms to be added or dropped: all main effects
contained in a second-order interaction must remain, and so on.
In a <code>scope</code> formula <code>.</code> means &lsquo;what is
already there&rsquo;.
</p>
<p>Compared to 
<code><a href="stats.html#topic+add1.glm">add1.glm</a></code>
and
<code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code>
these functions are simpler, e.g., there is no
<em>Cp</em>, F and Rao (score) tests,
<code>x</code> and <code>scale</code> arguments.
Most models do not have a deviance, however twice the
log-likelihood differences are used to test the significance
of terms.
</p>



<p>The default output table gives AIC, defined as minus twice log
likelihood plus <code class="reqn">2p</code> where <code class="reqn">p</code> is the rank of the model (the
number of effective parameters).  This is only defined up to an
additive constant (like log-likelihoods).
</p>










<h3>Value</h3>

<p>An object of class <code>"anova"</code> summarizing the differences
in fit between the models.
</p>


<h3>Warning</h3>

<p>In general, the same warnings in
<code><a href="stats.html#topic+add1.glm">add1.glm</a></code> and
<code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code>
apply here.
Furthermore, these functions have not been rigorously tested
for all models, so treat the results cautiously and please
report any bugs.
</p>
<p>Care is needed to check that the constraint matrices of added
terms are correct.
Also, if <code>object</code> is of the form
<code>vglm(..., constraints = list(x1 = cm1, x2 = cm2))</code>
then <code><a href="#topic+add1.vglm">add1.vglm</a></code> may fail because the
<code>constraints</code> argument needs to have the constaint
matrices for <em>all</em> terms.
</p>










<h3>Note</h3>

<p>Most <span class="pkg">VGAM</span> family functions do not compute a deviance,
but instead the likelihood function is evaluated at the MLE.
Hence a column name <code>"Deviance"</code> only appears for a
few models; and almost always there is a column labelled
<code>"logLik"</code>.
</p>








<h3>See Also</h3>

<p><code><a href="#topic+step4vglm">step4vglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+extractAIC.vglm">extractAIC.vglm</a></code>,
<code><a href="#topic+trim.constraints">trim.constraints</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>,
<code><a href="#topic+backPain2">backPain2</a></code>,
<code><a href="stats.html#topic+update">update</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>data("backPain2", package = "VGAM")
summary(backPain2)
fit1 &lt;- vglm(pain ~ x2 + x3 + x4, propodds, data = backPain2)
coef(fit1)
add1(fit1, scope = ~ x2 * x3 * x4, test = "LRT")
drop1(fit1, test = "LRT")
fit2 &lt;- vglm(pain ~ x2 * x3 * x4, propodds, data = backPain2)
drop1(fit2)
</code></pre>

<hr>
<h2 id='AICvlm'> Akaike's Information Criterion </h2><span id='topic+AICvlm'></span><span id='topic+AICvgam'></span><span id='topic+AICrrvglm'></span><span id='topic+AICqrrvglm'></span><span id='topic+AICrrvgam'></span><span id='topic+AICc+2Cvglm-method'></span>

<h3>Description</h3>

<p>Calculates the Akaike information criterion for a fitted model object
for which a log-likelihood value has been obtained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    AICvlm(object, ..., corrected = FALSE, k = 2)
   AICvgam(object, ..., k = 2)
 AICrrvglm(object, ..., k = 2)
AICqrrvglm(object, ..., k = 2)
 AICrrvgam(object, ..., k = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AICvlm_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>
</td></tr>
<tr><td><code id="AICvlm_+3A_...">...</code></td>
<td>

<p>Other possible arguments fed into
<code>logLik</code> in order to compute the log-likelihood.
</p>
</td></tr>
<tr><td><code id="AICvlm_+3A_corrected">corrected</code></td>
<td>

<p>Logical, perform the finite sample correction?
</p>
</td></tr>
<tr><td><code id="AICvlm_+3A_k">k</code></td>
<td>

<p>Numeric, the penalty per parameter to be used;
the default is the classical AIC.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following formula is used for VGLMs:
<code class="reqn">-2 \mbox{log-likelihood} + k n_{par}</code>, where <code class="reqn">n_{par}</code> represents the number of
parameters
in the fitted model, and <code class="reqn">k = 2</code> for the usual AIC.
One could assign <code class="reqn">k = \log(n)</code> (<code class="reqn">n</code> the number of observations)
for the so-called BIC or SBC (Schwarz's Bayesian criterion).
This is the function <code>AICvlm()</code>.
</p>
<p>This code relies on the log-likelihood being defined, and computed,
for the object.
When comparing fitted objects, the smaller the AIC, the better the fit.
The log-likelihood and hence the AIC is only defined up to an additive
constant.
</p>
<p>Any estimated scale parameter (in GLM parlance) is used as one
parameter.
</p>
<p>For VGAMs and CAO the nonlinear effective degrees of freedom for each
smoothed component is used. This formula is heuristic.
These are the functions <code>AICvgam()</code> and <code>AICcao()</code>.
</p>
<p>The finite sample correction is usually recommended when the
sample size is small or when the number of parameters is large.
When the sample size is large their difference tends to be negligible.
The correction is described in Hurvich and Tsai (1989), and is based
on a (univariate) linear model with normally distributed errors.
</p>


<h3>Value</h3>

<p>Returns a numeric value with the corresponding AIC (or BIC, or ...,
depending on <code>k</code>).
</p>


<h3>Warning </h3>

<p>This code has not been double-checked.
The general applicability of <code>AIC</code> for the VGLM/VGAM classes
has not been developed fully.
In particular, <code>AIC</code> should not be run on some <span class="pkg">VGAM</span> family
functions because of violation of certain regularity conditions, etc.
</p>


<h3>Note</h3>

<p>AIC has not been defined for QRR-VGLMs, yet.
</p>
<p>Using AIC to compare <code><a href="#topic+posbinomial">posbinomial</a></code> models
with, e.g., <code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code> models,
requires <code>posbinomial(omit.constant = TRUE)</code>.
See <code><a href="#topic+posbinomial">posbinomial</a></code> for an example.
A warning is given if it suspects a wrong <code>omit.constant</code> value
was used.
</p>
<p>Where defined,
<code>AICc(...)</code> is the same as <code>AIC(..., corrected = TRUE)</code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>References</h3>

<p>Hurvich, C. M. and Tsai, C.-L. (1989).
Regression and time series model selection in small samples,
<em>Biometrika</em>,
<b>76</b>, 297&ndash;307.
</p>





<h3>See Also</h3>

<p>VGLMs are described in <code><a href="#topic+vglm-class">vglm-class</a></code>;
VGAMs are described in <code><a href="#topic+vgam-class">vgam-class</a></code>;
RR-VGLMs are described in <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>;
<code><a href="stats.html#topic+AIC">AIC</a></code>,
<code><a href="#topic+BICvlm">BICvlm</a></code>,
<code><a href="#topic+TICvlm">TICvlm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>,
<code><a href="#topic+extractAIC.vglm">extractAIC.vglm</a></code>.
</p>






<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = TRUE, reverse = TRUE), data = pneumo))
coef(fit1, matrix = TRUE)
AIC(fit1)
AICc(fit1)  # Quick way
AIC(fit1, corrected = TRUE)  # Slow way
(fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = FALSE, reverse = TRUE), data = pneumo))
coef(fit2, matrix = TRUE)
AIC(fit2)
AICc(fit2)
AIC(fit2, corrected = TRUE)
</code></pre>

<hr>
<h2 id='alaplace'> Asymmetric Laplace Distribution Family Functions </h2><span id='topic+alaplace1'></span><span id='topic+alaplace2'></span><span id='topic+alaplace3'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of
the 1, 2 and 3-parameter asymmetric Laplace distributions (ALDs).
The 2-parameter ALD may,
with trepidation and lots of skill,
sometimes be used as an approximation of quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alaplace1(tau = NULL, llocation = "identitylink",
          ilocation = NULL, kappa = sqrt(tau/(1 - tau)), Scale.arg = 1,
          ishrinkage = 0.95, parallel.locat = TRUE  ~ 0, digt = 4,
          idf.mu = 3, zero = NULL, imethod = 1)

alaplace2(tau = NULL,  llocation = "identitylink", lscale = "loglink",
          ilocation = NULL, iscale = NULL, kappa = sqrt(tau/(1 - tau)),
          ishrinkage = 0.95,
          parallel.locat =  TRUE ~ 0,
          parallel.scale = FALSE ~ 0,
          digt = 4, idf.mu = 3, imethod = 1, zero = "scale")

alaplace3(llocation = "identitylink", lscale = "loglink",
          lkappa = "loglink", ilocation = NULL, iscale = NULL,
          ikappa = 1, imethod = 1, zero = c("scale", "kappa"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alaplace_+3A_tau">tau</code>, <code id="alaplace_+3A_kappa">kappa</code></td>
<td>
<p> Numeric vectors with
<code class="reqn">0 &lt; \tau &lt; 1</code> and <code class="reqn">\kappa &gt;0</code>.
Most users will only specify <code>tau</code> since the estimated
location parameter corresponds to the <code class="reqn">\tau</code>th
regression quantile, which is easier to understand.
See below for details.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_llocation">llocation</code>, <code id="alaplace_+3A_lscale">lscale</code>, <code id="alaplace_+3A_lkappa">lkappa</code></td>
<td>
<p> Character.
Parameter link functions for
location parameter <code class="reqn">\xi</code>,
scale parameter <code class="reqn">\sigma</code>,
asymmetry parameter <code class="reqn">\kappa</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
For example, the argument <code>llocation</code> can help handle
count data by restricting the quantiles to be positive
(use <code>llocation = "loglink"</code>).
However, <code>llocation</code> is best left alone since the theory
only works properly with the identity link.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_ilocation">ilocation</code>, <code id="alaplace_+3A_iscale">iscale</code>, <code id="alaplace_+3A_ikappa">ikappa</code></td>
<td>

<p>Optional initial values.
If given, it must be numeric and values are recycled to the
appropriate length.
The default is to choose the value internally.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_parallel.locat">parallel.locat</code>, <code id="alaplace_+3A_parallel.scale">parallel.scale</code></td>
<td>

<p>See the <code>parallel</code> argument
of <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
These arguments apply to the location and scale parameters.
It generally only makes sense for the scale parameters
to be equal, hence set <code>parallel.scale = TRUE</code>.
Note that
assigning <code>parallel.locat</code> the value <code>TRUE</code>
circumvents the seriously embarrassing quantile crossing
problem because all constraint matrices except for the intercept
correspond to a parallelism assumption.
</p>
</td></tr>









<tr><td><code id="alaplace_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method.
Either the value 1, 2, 3 or 4.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_idf.mu">idf.mu</code></td>
<td>

<p>Degrees of freedom for the cubic smoothing spline fit
applied to get an initial estimate of the location parameter.
See <code><a href="#topic+vsmooth.spline">vsmooth.spline</a></code>.
Used only when <code>imethod = 3</code>.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>How much shrinkage is used when initializing <code class="reqn">\xi</code>.
The value must be between 0 and 1 inclusive, and
a value of 0 means the individual response values are used,
and a value of 1 means the median or mean is used.
This argument is used only when <code>imethod = 4</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_scale.arg">Scale.arg</code></td>
<td>

<p>The value of the scale parameter <code class="reqn">\sigma</code>.
This argument may be used to compute quantiles at
different <code class="reqn">\tau</code> values from an existing fitted
<code>alaplace2()</code> model (practical only if it has a
single value).
If the model has <code>parallel.locat = TRUE</code> then
only the intercept need be estimated; use an offset.
See below for an example.
</p>



</td></tr>
<tr><td><code id="alaplace_+3A_digt">digt</code></td>
<td>

<p>Passed into <code><a href="base.html#topic+Round">Round</a></code> as the <code>digits</code>
argument for the <code>tau</code> values; used cosmetically for
labelling.
</p>
</td></tr>
<tr><td><code id="alaplace_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
Where possible,
the default is to model all the <code class="reqn">\sigma</code>
and <code class="reqn">\kappa</code> as an intercept-only term.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These <span class="pkg">VGAM</span> family functions implement one variant of asymmetric
Laplace distributions (ALDs) suitable for quantile regression.
Kotz et al. (2001) call it <em>the</em> ALD.
Its density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y;\xi,\sigma,\kappa) = \frac{\sqrt{2}}{\sigma} \,
    \frac{\kappa}{1 + \kappa^2} \,
    \exp \left( - \frac{\sqrt{2}}{\sigma \, \kappa} |y - \xi |
                    \right) </code>
</p>

<p>for <code class="reqn">y \leq \xi</code>, and
</p>
<p style="text-align: center;"><code class="reqn">f(y;\xi,\sigma,\kappa) = \frac{\sqrt{2}}{\sigma} \,
    \frac{\kappa}{1 + \kappa^2} \,
    \exp \left( - \frac{\sqrt{2} \, \kappa}{\sigma} |y - \xi |
                    \right) </code>
</p>

<p>for <code class="reqn">y &gt; \xi</code>.
Here, the ranges are for all real <code class="reqn">y</code> and
<code class="reqn">\xi</code>, positive <code class="reqn">\sigma</code>
and positive <code class="reqn">\kappa</code>.
The special case <code class="reqn">\kappa = 1</code> corresponds to the
(symmetric) Laplace distribution of Kotz et al. (2001).
The mean is <code class="reqn">\xi + \sigma (1/\kappa - \kappa) / \sqrt{2}</code>
and the variance is
<code class="reqn">\sigma^2 (1 + \kappa^4) / (2  \kappa^2)</code>.
The enumeration of the linear/additive predictors used for
<code>alaplace2()</code> is
the first location parameter followed by the first scale parameter,
then the second location parameter followed by the
second scale parameter, etc.
For <code>alaplace3()</code>, only a vector response is handled
and the last (third) linear/additive predictor is for
the asymmetry parameter.
</p>
<p>It is known that the maximum likelihood estimate of the
location parameter <code class="reqn">\xi</code> corresponds to the regression
quantile estimate of the classical quantile regression approach
of Koenker and Bassett (1978). An important property of the
ALD is that
<code class="reqn">P(Y \leq \xi) = \tau</code> where
<code class="reqn">\tau = \kappa^2 / (1 + \kappa^2)</code>
so that
<code class="reqn">\kappa =  \sqrt{\tau / (1-\tau)}</code>.
Thus <code>alaplace2()</code> might be used as an alternative to <code>rq</code>
in the <span class="pkg">quantreg</span> package, although scoring is really
an unsuitable algorithm for estimation here.
</p>
<p>Both <code>alaplace1()</code> and <code>alaplace2()</code> can handle
multiple responses, and the number of linear/additive
predictors is dictated by the length of <code>tau</code> or
<code>kappa</code>.  The functions <code>alaplace1()</code>
and <code>alaplace2()</code> can also
handle multiple responses (i.e., a matrix response)
but only with a <em>single-valued</em> <code>tau</code> or <code>kappa</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>In the <code>extra</code> slot of the fitted object are some list
components which are useful, e.g., the sample proportion of
values which are less than the fitted quantile curves.
</p>


<h3>Warning</h3>

<p>These functions are <em>experimental</em> and especially subject to
change or withdrawal.
The usual MLE regularity conditions do <em>not</em> hold for
this distribution so that misleading inferences may result,
e.g., in the <code>summary</code> and <code>vcov</code> of the object.  The
1-parameter ALD can be approximated by <code><a href="#topic+extlogF1">extlogF1</a></code>
which has continuous derivatives and is recommended over
<code><a href="#topic+alaplace1">alaplace1</a></code>.
</p>
<p>Care is needed with <code>tau</code> values which are too small,
e.g., for count data with <code>llocation = "loglink"</code> and if
the sample proportion of zeros is greater than <code>tau</code>.
</p>


<h3>Note</h3>








<p>These <span class="pkg">VGAM</span> family functions use Fisher scoring.
Convergence may be slow and half-stepping is usual
(although one can use <code>trace = TRUE</code> to see which
is the best model and then use <code>maxit</code> to choose
that model)
due to the regularity conditions not holding.
Often the iterations slowly crawl towards the solution so
monitoring the convergence (set <code>trace = TRUE</code>) is highly
recommended.
Instead, <code><a href="#topic+extlogF1">extlogF1</a></code> is recommended.
</p>
<p>For large data sets it is a very good idea to keep the length of
<code>tau</code>/<code>kappa</code> low to avoid large memory requirements.
Then
for <code>parallel.locat = FALSE</code> one can repeatedly fit a model with
<code>alaplace1()</code> with one <code class="reqn">\tau</code> at a time;
and
for <code>parallel.locat = TRUE</code> one can refit a model with
<code>alaplace1()</code> with one <code class="reqn">\tau</code> at a time but
using offsets and an intercept-only model.
</p>
<p>A second method for solving the noncrossing quantile problem is
illustrated below in Example 3.
This is called the <em>accumulative quantile method</em> (AQM)
and details are in Yee (2015).
It does not make the strong parallelism assumption.
</p>
<p>The functions <code>alaplace2()</code> and <code><a href="#topic+laplace">laplace</a></code>
differ slightly in terms of the parameterizations.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Koenker, R. and Bassett, G. (1978).
Regression quantiles.
<em>Econometrica</em>,
<b>46</b>, 33&ndash;50.
</p>
<p>Kotz, S., Kozubowski, T. J. and Podgorski, K. (2001).
<em>The Laplace distribution and generalizations:
a revisit with applications to communications,
economics, engineering, and finance</em>,
Boston: Birkhauser.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+ralap">ralap</a></code>,
<code><a href="#topic+laplace">laplace</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+amlnormal">amlnormal</a></code>,
<code><a href="#topic+sc.studentt2">sc.studentt2</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: quantile regression with smoothing splines
set.seed(123); adata &lt;- data.frame(x2 = sort(runif(n &lt;- 500)))
mymu &lt;- function(x) exp(-2 + 6*sin(2*x-0.2) / (x+0.5)^2)
adata &lt;- transform(adata, y = rpois(n, lambda = mymu(x2)))
mytau &lt;- c(0.25, 0.75); mydof &lt;- 4

fit &lt;- vgam(y ~ s(x2, df = mydof), data=adata, trace=TRUE, maxit = 900,
            alaplace2(tau = mytau, llocat = "loglink",
                      parallel.locat = FALSE))
fitp &lt;- vgam(y ~ s(x2, df = mydof), data = adata, trace=TRUE, maxit=900,
     alaplace2(tau = mytau, llocat = "loglink", parallel.locat = TRUE))

par(las = 1); mylwd &lt;- 1.5
with(adata, plot(x2, jitter(y, factor = 0.5), col = "orange",
                 main = "Example 1; green: parallel.locat = TRUE",
                 ylab = "y", pch = "o", cex = 0.75))
with(adata, matlines(x2, fitted(fit ), col = "blue",
                     lty = "solid", lwd = mylwd))
with(adata, matlines(x2, fitted(fitp), col = "green",
                     lty = "solid", lwd = mylwd))
finexgrid &lt;- seq(0, 1, len = 1001)
for (ii in 1:length(mytau))
  lines(finexgrid, qpois(p = mytau[ii], lambda = mymu(finexgrid)),
        col = "blue", lwd = mylwd)
fit@extra  # Contains useful information


# Example 2: regression quantile at a new tau value from an existing fit
# Nb. regression splines are used here since it is easier.
fitp2 &lt;- vglm(y ~ sm.bs(x2, df = mydof), data = adata, trace = TRUE,
              alaplace1(tau = mytau, llocation = "loglink",
                        parallel.locat = TRUE))

newtau &lt;- 0.5  # Want to refit the model with this tau value
fitp3 &lt;- vglm(y ~ 1 + offset(predict(fitp2)[, 1]),
              alaplace1(tau = newtau, llocation = "loglink"), adata)
with(adata, plot(x2, jitter(y, factor = 0.5), col = "orange",
               pch = "o", cex = 0.75, ylab = "y",
               main = "Example 2; parallel.locat = TRUE"))
with(adata, matlines(x2, fitted(fitp2), col = "blue",
                     lty = 1, lwd = mylwd))
with(adata, matlines(x2, fitted(fitp3), col = "black",
                     lty = 1, lwd = mylwd))


# Example 3: noncrossing regression quantiles using a trick: obtain
# successive solutions which are added to previous solutions; use a log
# link to ensure an increasing quantiles at any value of x.

mytau &lt;- seq(0.2, 0.9, by = 0.1)
answer &lt;- matrix(0, nrow(adata), length(mytau))  # Stores the quantiles
adata &lt;- transform(adata, offsety = y*0)
usetau &lt;- mytau
for (ii in 1:length(mytau)) {
# cat("\n\nii  = ", ii, "\n")
  adata &lt;- transform(adata, usey = y-offsety)
  iloc &lt;- ifelse(ii == 1, with(adata, median(y)), 1.0)  # Well-chosen!
  mydf &lt;- ifelse(ii == 1, 5, 3)  # Maybe less smoothing will help
  fit3 &lt;- vglm(usey ~ sm.ns(x2, df = mydf), data = adata, trace = TRUE,
            alaplace2(tau = usetau[ii], lloc = "loglink", iloc = iloc))
  answer[, ii] &lt;- (if(ii == 1) 0 else answer[, ii-1]) + fitted(fit3)
  adata &lt;- transform(adata, offsety = answer[, ii])
}

# Plot the results.
with(adata, plot(x2, y, col = "blue",
     main = paste("Noncrossing and nonparallel; tau  = ",
                paste(mytau, collapse = ", "))))
with(adata, matlines(x2, answer, col = "orange", lty = 1))

# Zoom in near the origin.
with(adata, plot(x2, y, col = "blue", xlim = c(0, 0.2), ylim = 0:1,
     main = paste("Noncrossing and nonparallel; tau  = ",
                paste(mytau, collapse = ", "))))
with(adata, matlines(x2, answer, col = "orange", lty = 1))

## End(Not run)
</code></pre>

<hr>
<h2 id='alaplaceUC'> The Laplace Distribution </h2><span id='topic+dalap'></span><span id='topic+palap'></span><span id='topic+qalap'></span><span id='topic+ralap'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the 3-parameter asymmetric Laplace distribution
with location parameter <code>location</code>, scale parameter
<code>scale</code>, and asymmetry parameter <code>kappa</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dalap(x, location = 0, scale = 1, tau = 0.5, kappa = sqrt(tau/(1-tau)),
      log = FALSE)
palap(q, location = 0, scale = 1, tau = 0.5, kappa = sqrt(tau/(1-tau)),
      lower.tail = TRUE, log.p = FALSE)
qalap(p, location = 0, scale = 1, tau = 0.5, kappa = sqrt(tau/(1-tau)),
      lower.tail = TRUE, log.p = FALSE)
ralap(n, location = 0, scale = 1, tau = 0.5, kappa = sqrt(tau/(1-tau)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alaplaceUC_+3A_x">x</code>, <code id="alaplaceUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_n">n</code></td>
<td>

<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.
</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_location">location</code></td>
<td>

<p>the location parameter <code class="reqn">\xi</code>.
</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_scale">scale</code></td>
<td>

<p>the scale parameter <code class="reqn">\sigma</code>.
Must consist of positive values.
</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_tau">tau</code></td>
<td>

<p>the quantile parameter <code class="reqn">\tau</code>.
Must consist of values in <code class="reqn">(0,1)</code>.
This argument is used to specify <code>kappa</code> and is ignored
if <code>kappa</code> is assigned.
</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_kappa">kappa</code></td>
<td>

<p>the asymmetry parameter <code class="reqn">\kappa</code>.
Must consist of positive values.
</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_log">log</code></td>
<td>

<p>if <code>TRUE</code>, probabilities <code>p</code> are given as <code>log(p)</code>.
</p>
</td></tr>
<tr><td><code id="alaplaceUC_+3A_lower.tail">lower.tail</code>, <code id="alaplaceUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are many variants of asymmetric Laplace distributions
(ALDs) and this one is known as <em>the</em> ALD by Kotz et
al. (2001).  See <code><a href="#topic+alaplace3">alaplace3</a></code>, the <span class="pkg">VGAM</span>
family function for estimating the three parameters by maximum
likelihood estimation, for formulae and details.  The ALD
density may be approximated by <code><a href="#topic+dextlogF">dextlogF</a></code>.
</p>


<h3>Value</h3>

<p><code>dalap</code> gives the density,
<code>palap</code> gives the distribution function,
<code>qalap</code> gives the quantile function, and
<code>ralap</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kotz, S., Kozubowski, T. J. and Podgorski, K. (2001).
<em>The Laplace distribution and generalizations:
a revisit with applications to communications,
economics, engineering, and finance</em>,
Boston: Birkhauser.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alaplace3">alaplace3</a></code>,
<code><a href="#topic+dextlogF">dextlogF</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-5, 5, by = 0.01)
loc &lt;- 0; sigma &lt;- 1.5; kappa &lt;- 2
## Not run:  plot(x, dalap(x, loc, sigma, kappa = kappa), type = "l",
     main = "Blue is density, orange is the CDF",
     ylim = c(0, 1), sub = "Purple are 5, 10, ..., 95 percentiles",
     las = 1, ylab = "", cex.main = 0.5, col = "blue")
abline(h = 0, col = "blue", lty = 2)
lines(qalap(seq(0.05, 0.95, by = 0.05), loc, sigma, kappa = kappa),
      dalap(qalap(seq(0.05, 0.95, by = 0.05), loc, sigma, kappa = kappa),
            loc, sigma, kappa = kappa), col="purple", lty=3, type = "h")
lines(x, palap(x, loc, sigma, kappa = kappa), type = "l", col = "orange")
abline(h = 0, lty = 2) 
## End(Not run)

pp &lt;- seq(0.05, 0.95, by = 0.05)  # Test two functions
max(abs(palap(qalap(pp, loc, sigma, kappa = kappa),
              loc, sigma, kappa = kappa) - pp))  # Should be 0
</code></pre>

<hr>
<h2 id='alogitlink'> Arcsine&ndash;Logit Link Mixtures</h2><span id='topic+alogitlink'></span><span id='topic+lcalogitlink'></span>

<h3>Description</h3>

<p>Computes some arcsine&ndash;logit mixture link
transformations, including their inverse and
the first few derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  alogitlink(theta, bvalue = NULL, taumix.logit = 1,
     tol = 1e-13, nmax = 99, inverse = FALSE, deriv = 0,
     short = TRUE, tag = FALSE, c10 = c(4, -pi))
lcalogitlink(theta, bvalue = NULL, pmix.logit = 0.01,
     tol = 1e-13, nmax = 99, inverse = FALSE, deriv = 0,
     short = TRUE, tag = FALSE, c10 = c(4, -pi))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alogitlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="alogitlink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="alogitlink_+3A_taumix.logit">taumix.logit</code></td>
<td>

<p>Numeric, of length 1.
Mixing parameter assigned
to <code><a href="#topic+logitlink">logitlink</a></code>.  Then
<code>1 - exp(-taumix.log * theta)</code> is used
to weight
<code><a href="#topic+asinlink">asinlink</a></code>.
Thus a 0 value will result in
<code><a href="#topic+logitlink">logitlink</a></code>
and a very large numeric such as <code>1e4</code>
should be roughly equivalent to
<code><a href="#topic+asinlink">asinlink</a></code> over almost all
of the parameter space.
</p>
</td></tr>
<tr><td><code id="alogitlink_+3A_pmix.logit">pmix.logit</code></td>
<td>

<p>Numeric, of length 1.
Mixing probability assigned
to <code><a href="#topic+logitlink">logitlink</a></code>.  Then
<code>1 - pmix.logit</code> is used to weight
<code><a href="#topic+asinlink">asinlink</a></code>.
Thus a 0 value will result in
<code><a href="#topic+asinlink">asinlink</a></code>.
and 1 is equivalent to <code><a href="#topic+logitlink">logitlink</a></code>.
</p>
</td></tr>
<tr><td><code id="alogitlink_+3A_tol">tol</code>, <code id="alogitlink_+3A_nmax">nmax</code></td>
<td>

<p>Arguments fed into a function implementing a
vectorized bisection method.
</p>
</td></tr>
<tr><td><code id="alogitlink_+3A_inverse">inverse</code>, <code id="alogitlink_+3A_deriv">deriv</code>, <code id="alogitlink_+3A_short">short</code>, <code id="alogitlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="alogitlink_+3A_c10">c10</code></td>
<td>

<p>See <code><a href="#topic+asinlink">asinlink</a></code>
and
<code><a href="#topic+logitlink">logitlink</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>






























































<p><code><a href="#topic+lcalogitlink">lcalogitlink</a></code> is a
<em>linear combination</em> (LC) of
<code><a href="#topic+asinlink">asinlink</a></code> and
<code><a href="#topic+logitlink">logitlink</a></code>.
</p>


<h3>Value</h3>

<p>The following holds for the LC variant.
For <code>deriv &gt;= 0</code>,
<code>(1 - pmix.logit) * asinlink(p, deriv = deriv)
    + pmix.logit * logitlink(p, deriv = deriv)</code>
when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then a nonlinear
equation is solved for the probability,
given
<code>eta</code>.
For <code>deriv = 1</code>, then the function
returns <em>d</em> <code>eta</code> / <em>d</em>
<code>theta</code> as a function of <code>theta</code> if
<code>inverse = FALSE</code>, else if <code>inverse
  = TRUE</code> then it returns the reciprocal.
</p>


<h3>Warning </h3>

<p>The default values for <code>taumix.logit</code>
and <code>pmix.logit</code>
may change in the future.
The name and order of the arguments
may change too.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Hauck, J. W. W. and A. Donner (1977).
Wald's test as applied to hypotheses in
logit analysis.
<em>Journal of the American Statistical
Association</em>,
<b>72</b>, 851&ndash;853.
</p>










<h3>See Also</h3>

<p><code><a href="#topic+asinlink">asinlink</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+sloglink">sloglink</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>,
<a href="https://www.cia.gov/index.html">https://www.cia.gov/index.html</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, length= 10)
alogitlink(p)
max(abs(alogitlink(alogitlink(p), inv = TRUE) - p))  # 0?

## Not run: 
par(mfrow = c(2, 2), lwd = (mylwd &lt;- 2))
y &lt;- seq(-4, 4, length = 100)
p &lt;- seq(0.01, 0.99, by = 0.01)

for (d in 0:1) {
  matplot(p, cbind(logitlink(p, deriv = d), probitlink(p, deriv = d)),
          type = "n", col = "blue", ylab = "transformation",
          las = 1, main = if (d == 0) "Some probability link functions"
          else "First derivative")
  lines(p,   logitlink(p, deriv = d), col = "green")
  lines(p,  probitlink(p, deriv = d), col = "blue")
  lines(p, clogloglink(p, deriv = d), col = "tan")
  lines(p,  alogitlink(p, deriv = d), col = "red3")
  if (d == 0) {
    abline(v = 0.5, h = 0, lty = "dashed")
    legend(0, 4.5, c("logitlink", "probitlink", "clogloglink",
           "alogitlink"), lwd = mylwd,
           col = c("green", "blue", "tan", "red3"))
  } else
    abline(v = 0.5, lwd = 0.5, col = "gray")
}

for (d in 0) {
  matplot(y, cbind( logitlink(y, deriv = d, inverse = TRUE),
                   probitlink(y, deriv = d, inverse = TRUE)),
          type  = "n", col = "blue", xlab = "transformation", ylab = "p",
          main = if (d == 0) "Some inverse probability link functions"
          else "First derivative", las=1)
  lines(y,   logitlink(y, deriv = d, inverse = TRUE), col = "green")
  lines(y,  probitlink(y, deriv = d, inverse = TRUE), col = "blue")
  lines(y, clogloglink(y, deriv = d, inverse = TRUE), col = "tan")
  lines(y,  alogitlink(y, deriv = d, inverse = TRUE), col = "red3")
  if (d == 0) {
      abline(h = 0.5, v = 0, lwd = 0.5, col = "gray")
      legend(-4, 1, c("logitlink", "probitlink", "clogloglink",
             "alogitlink"), lwd = mylwd,
             col = c("green", "blue", "tan", "red3"))
  }
}
par(lwd = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='altered'>
Altered, Inflated, Truncated and Deflated Values in GAITD Regression
</h2><span id='topic+altered'></span><span id='topic+deflated'></span><span id='topic+inflated'></span><span id='topic+truncated'></span><span id='topic+is.altered'></span><span id='topic+is.inflated'></span><span id='topic+is.deflated'></span><span id='topic+is.truncated'></span>

<h3>Description</h3>

<p>Return the altered, inflated, truncated and deflated values
in a GAITD regression object,
else test whether the model is altered, inflated, truncated or deflated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>altered(object, ...)
inflated(object, ...)
truncated(object, ...)
is.altered(object, ...)
is.deflated(object, ...)
is.inflated(object, ...)
is.truncated(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="altered_+3A_object">object</code></td>
<td>

<p>an object of class <code>"vglm"</code>.
Currently only a GAITD regression object returns
valid results of these functions.
</p>
</td></tr>
<tr><td><code id="altered_+3A_...">...</code></td>
<td>

<p>any additional arguments, to future-proof this function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yee and Ma (2023) propose GAITD regression
where values from four (or seven since
there are parametric and nonparametric
forms) disjoint sets are referred to as
<em>special</em>.  These extractor functions
return one set each; they are the <code>alter</code>,
<code>inflate</code>, <code>truncate</code>, <code>deflate</code>
(and sometimes <code>max.support</code>) arguments
from the family function.
</p>




<h3>Value</h3>

<p>Returns one type of &lsquo;special&rsquo; sets associated with GAITD regression.
This is a vector, else a list for truncation.
All three sets are returned by <code><a href="#topic+specialsvglm">specialsvglm</a></code>.
</p>


<h3>Warning</h3>

<p>Some of these functions are subject to change.
Only family functions beginning with <code>"gaitd"</code> will
work with these functions, hence
<code><a href="#topic+zipoisson">zipoisson</a></code> fits will return <code>FALSE</code> or empty
values.
</p>


<h3>References</h3>

<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>



<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>,
<code><a href="#topic+specialsvglm">specialsvglm</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>abdata &lt;- data.frame(y = 0:7, w = c(182, 41, 12, 2, 2, 0, 0, 1))
fit1 &lt;- vglm(y ~ 1, gaitdpoisson(a.mix = 0),
             data = abdata, weight = w, subset = w &gt; 0)
specials(fit1)  # All three sets
altered(fit1)  # Subject to change
inflated(fit1)  # Subject to change
truncated(fit1)  # Subject to change
is.altered(fit1)
is.inflated(fit1)
is.truncated(fit1)
</code></pre>

<hr>
<h2 id='amlbinomial'> Binomial Logistic Regression by Asymmetric Maximum
Likelihood Estimation </h2><span id='topic+amlbinomial'></span>

<h3>Description</h3>

<p>Binomial quantile regression estimated by maximizing an asymmetric
likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amlbinomial(w.aml = 1, parallel = FALSE, digw = 4, link = "logitlink")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amlbinomial_+3A_w.aml">w.aml</code></td>
<td>

<p>Numeric, a vector of positive constants controlling the percentiles.
The larger the value the larger the fitted percentile value
(the proportion of points below the &ldquo;w-regression plane&rdquo;).
The default value of unity results in the ordinary maximum likelihood
(MLE) solution.
</p>
</td></tr>
<tr><td><code id="amlbinomial_+3A_parallel">parallel</code></td>
<td>

<p>If <code>w.aml</code> has more than one value then
this argument allows the quantile curves to differ by the same amount
as a function of the covariates.
Setting this to be <code>TRUE</code> should force the quantile curves to
not cross (although they may not cross anyway).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="amlbinomial_+3A_digw">digw</code></td>
<td>

<p>Passed into <code><a href="base.html#topic+Round">Round</a></code> as the <code>digits</code> argument
for the <code>w.aml</code> values;
used cosmetically for labelling.
</p>
</td></tr>
<tr><td><code id="amlbinomial_+3A_link">link</code></td>
<td>

<p>See <code><a href="#topic+binomialff">binomialff</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general methodology behind this <span class="pkg">VGAM</span> family function
is given in Efron (1992) and full details can be obtained there.
This model is essentially a logistic regression model
(see <code><a href="#topic+binomialff">binomialff</a></code>) but the usual deviance is
replaced by an
asymmetric squared error loss function; it is multiplied by
<code class="reqn">w.aml</code> for positive residuals.
The solution is the set of regression coefficients that minimize the
sum of these deviance-type values over the data set, weighted by
the <code>weights</code> argument (so that it can contain frequencies).
Newton-Raphson estimation is used here.
</p>



<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>If <code>w.aml</code> has more than one value then the value returned by
<code>deviance</code> is the sum of all the (weighted) deviances taken over
all the <code>w.aml</code> values.  See Equation (1.6) of Efron (1992).
</p>


<h3>Note</h3>

<p>On fitting, the <code>extra</code> slot has list components <code>"w.aml"</code>
and <code>"percentile"</code>. The latter is the percent of observations
below the &ldquo;w-regression plane&rdquo;, which is the fitted values.  Also,
the individual deviance values corresponding to each element of the
argument <code>w.aml</code> is stored in the <code>extra</code> slot.
</p>
<p>For <code>amlbinomial</code> objects, methods functions for the generic
functions <code>qtplot</code> and <code>cdf</code> have not been written yet.
</p>
<p>See <code><a href="#topic+amlpoisson">amlpoisson</a></code> about comments on the jargon, e.g.,
<em>expectiles</em> etc.
</p>
<p>In this documentation the word <em>quantile</em> can often be
interchangeably replaced by <em>expectile</em>
(things are informal here).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Efron, B. (1992).
Poisson overdispersion estimates based on the method of
asymmetric maximum likelihood.
<em>Journal of the American Statistical Association</em>,
<b>87</b>, 98&ndash;107.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amlpoisson">amlpoisson</a></code>,
<code><a href="#topic+amlexponential">amlexponential</a></code>,
<code><a href="#topic+amlnormal">amlnormal</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+denorm">denorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: binomial data with lots of trials per observation
set.seed(1234)
sizevec &lt;- rep(100, length = (nn &lt;- 200))
mydat &lt;- data.frame(x = sort(runif(nn)))
mydat &lt;- transform(mydat,
                   prob = logitlink(-0 + 2.5*x + x^2, inverse = TRUE))
mydat &lt;- transform(mydat, y = rbinom(nn, size = sizevec, prob = prob))
(fit &lt;- vgam(cbind(y, sizevec - y) ~ s(x, df = 3),
             amlbinomial(w = c(0.01, 0.2, 1, 5, 60)),
             mydat, trace = TRUE))
fit@extra

## Not run: 
par(mfrow = c(1,2))
# Quantile plot
with(mydat, plot(x, jitter(y), col = "blue", las = 1, main =
     paste(paste(round(fit@extra$percentile, digits = 1), collapse = ", "),
           "percentile-expectile curves")))
with(mydat, matlines(x, 100 * fitted(fit), lwd = 2, col = "blue", lty=1))

# Compare the fitted expectiles with the quantiles
with(mydat, plot(x, jitter(y), col = "blue", las = 1, main =
     paste(paste(round(fit@extra$percentile, digits = 1), collapse = ", "),
           "percentile curves are red")))
with(mydat, matlines(x, 100 * fitted(fit), lwd = 2, col = "blue", lty = 1))

for (ii in fit@extra$percentile)
    with(mydat, matlines(x, 100 *
         qbinom(p = ii/100, size = sizevec, prob = prob) / sizevec,
                  col = "red", lwd = 2, lty = 1))

## End(Not run)
</code></pre>

<hr>
<h2 id='amlexponential'> Exponential Regression by Asymmetric Maximum
Likelihood Estimation </h2><span id='topic+amlexponential'></span>

<h3>Description</h3>

<p>Exponential expectile regression estimated by maximizing an
asymmetric likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amlexponential(w.aml = 1, parallel = FALSE, imethod = 1, digw = 4,
               link = "loglink")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amlexponential_+3A_w.aml">w.aml</code></td>
<td>

<p>Numeric, a vector of positive constants controlling the expectiles.
The larger the value the larger the fitted expectile value
(the proportion of points below the &ldquo;w-regression plane&rdquo;).
The default value of unity results in the ordinary maximum likelihood
(MLE) solution.
</p>
</td></tr>
<tr><td><code id="amlexponential_+3A_parallel">parallel</code></td>
<td>

<p>If <code>w.aml</code> has more than one value then
this argument allows the quantile curves to differ by the same amount
as a function of the covariates.
Setting this to be <code>TRUE</code> should force the quantile curves to
not cross (although they may not cross anyway).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="amlexponential_+3A_imethod">imethod</code></td>
<td>

<p>Integer, either 1 or 2 or 3. Initialization method.
Choose another value if convergence fails.
</p>
</td></tr>
<tr><td><code id="amlexponential_+3A_digw">digw</code></td>
<td>

<p>Passed into <code><a href="base.html#topic+Round">Round</a></code> as the <code>digits</code> argument
for the <code>w.aml</code> values;
used cosmetically for labelling.
</p>
</td></tr>
<tr><td><code id="amlexponential_+3A_link">link</code></td>
<td>

<p>See <code><a href="#topic+exponential">exponential</a></code> and the warning below.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general methodology behind this <span class="pkg">VGAM</span> family function
is given in Efron (1992) and full details can be obtained there.

This model is essentially an exponential regression model
(see <code><a href="#topic+exponential">exponential</a></code>) but the usual deviance is
replaced by an
asymmetric squared error loss function; it is multiplied by
<code class="reqn">w.aml</code> for positive residuals.
The solution is the set of regression coefficients that minimize the
sum of these deviance-type values over the data set, weighted by
the <code>weights</code> argument (so that it can contain frequencies).
Newton-Raphson estimation is used here.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Note that the <code>link</code> argument of <code><a href="#topic+exponential">exponential</a></code> and
<code><a href="#topic+amlexponential">amlexponential</a></code> are currently different: one is the
rate parameter and the other is the mean (expectile) parameter.
</p>
<p>If <code>w.aml</code> has more than one value then the value returned by
<code>deviance</code> is the sum of all the (weighted) deviances taken over
all the <code>w.aml</code> values.  See Equation (1.6) of Efron (1992).
</p>


<h3>Note</h3>

<p>On fitting, the <code>extra</code> slot has list components <code>"w.aml"</code>
and <code>"percentile"</code>. The latter is the percent of observations
below the &ldquo;w-regression plane&rdquo;, which is the fitted values.  Also,
the individual deviance values corresponding to each element of the
argument <code>w.aml</code> is stored in the <code>extra</code> slot.
</p>
<p>For <code>amlexponential</code> objects, methods functions for the generic
functions <code>qtplot</code> and <code>cdf</code> have not been written yet.
</p>
<p>See <code><a href="#topic+amlpoisson">amlpoisson</a></code> about comments on the jargon, e.g.,
<em>expectiles</em> etc.
</p>
<p>In this documentation the word <em>quantile</em> can often be
interchangeably replaced by <em>expectile</em>
(things are informal here).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Efron, B. (1992).
Poisson overdispersion estimates based on the method of
asymmetric maximum likelihood.
<em>Journal of the American Statistical Association</em>,
<b>87</b>, 98&ndash;107.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exponential">exponential</a></code>,
<code><a href="#topic+amlbinomial">amlbinomial</a></code>,
<code><a href="#topic+amlpoisson">amlpoisson</a></code>,
<code><a href="#topic+amlnormal">amlnormal</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+lms.bcg">lms.bcg</a></code>,
<code><a href="#topic+deexp">deexp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 2000
mydat &lt;- data.frame(x = seq(0, 1, length = nn))
mydat &lt;- transform(mydat,
                   mu = loglink(-0 + 1.5*x + 0.2*x^2, inverse = TRUE))
mydat &lt;- transform(mydat, mu = loglink(0 - sin(8*x), inverse = TRUE))
mydat &lt;- transform(mydat,  y = rexp(nn, rate = 1/mu))
(fit &lt;- vgam(y ~ s(x, df=5), amlexponential(w=c(0.001, 0.1, 0.5, 5, 60)),
             mydat, trace = TRUE))
fit@extra

## Not run:  # These plots are against the sqrt scale (to increase clarity)
par(mfrow = c(1,2))
# Quantile plot
with(mydat, plot(x, sqrt(y), col = "blue", las = 1, main =
     paste(paste(round(fit@extra$percentile, digits = 1), collapse=", "),
           "percentile-expectile curves")))
with(mydat, matlines(x, sqrt(fitted(fit)), lwd = 2, col = "blue", lty=1))

# Compare the fitted expectiles with the quantiles
with(mydat, plot(x, sqrt(y), col = "blue", las = 1, main =
     paste(paste(round(fit@extra$percentile, digits = 1), collapse=", "),
           "percentile curves are orange")))
with(mydat, matlines(x, sqrt(fitted(fit)), lwd = 2, col = "blue", lty=1))

for (ii in fit@extra$percentile)
  with(mydat, matlines(x, sqrt(qexp(p = ii/100, rate = 1/mu)),
                       col = "orange")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='amlnormal'> Asymmetric Least Squares Quantile Regression </h2><span id='topic+amlnormal'></span>

<h3>Description</h3>

<p>Asymmetric least squares,
a special case of maximizing an asymmetric
likelihood function of a normal distribution.
This allows for expectile/quantile regression using asymmetric
least squares error loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amlnormal(w.aml = 1, parallel = FALSE, lexpectile = "identitylink",
          iexpectile = NULL, imethod = 1, digw = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amlnormal_+3A_w.aml">w.aml</code></td>
<td>

<p>Numeric, a vector of positive constants controlling the percentiles.
The larger the value the larger the fitted percentile value
(the proportion of points below the &ldquo;w-regression plane&rdquo;).
The default value of unity results in the ordinary least squares
(OLS) solution.
</p>
</td></tr>
<tr><td><code id="amlnormal_+3A_parallel">parallel</code></td>
<td>

<p>If <code>w.aml</code> has more than one value then
this argument allows the quantile curves to differ
by the same amount as a function of the covariates.
Setting this to be <code>TRUE</code> should force the quantile
curves to not cross (although they may not cross anyway).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="amlnormal_+3A_lexpectile">lexpectile</code>, <code id="amlnormal_+3A_iexpectile">iexpectile</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="amlnormal_+3A_imethod">imethod</code></td>
<td>

<p>Integer, either 1 or 2 or 3. Initialization method.
Choose another value if convergence fails.
</p>
</td></tr>
<tr><td><code id="amlnormal_+3A_digw">digw</code></td>
<td>

<p>Passed into <code><a href="base.html#topic+Round">Round</a></code> as the <code>digits</code>
argument for the <code>w.aml</code> values; used cosmetically for
labelling.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an implementation of Efron (1991) and full details can
be obtained there.
Equation numbers below refer to that article.
The model is essentially a linear model
(see <code><a href="stats.html#topic+lm">lm</a></code>), however,
the asymmetric squared error loss function for a residual
<code class="reqn">r</code> is <code class="reqn">r^2</code> if <code class="reqn">r \leq 0</code> and
<code class="reqn">w r^2</code> if <code class="reqn">r &gt; 0</code>.
The solution is the set of regression coefficients that
minimize the sum of these over the data set, weighted by the
<code>weights</code> argument (so that it can contain frequencies).
Newton-Raphson estimation is used here.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>On fitting, the <code>extra</code> slot has list components
<code>"w.aml"</code> and <code>"percentile"</code>. The latter is the
percent of observations below the &ldquo;w-regression plane&rdquo;,
which is the fitted values.
</p>
<p>One difficulty is finding the <code>w.aml</code> value giving a
specified percentile. One solution is to fit the model within
a root finding function such as <code><a href="stats.html#topic+uniroot">uniroot</a></code>;
see the example below.
</p>
<p>For <code>amlnormal</code> objects, methods functions for the
generic functions <code>qtplot</code> and <code>cdf</code> have not been
written yet.
</p>
<p>See the note in <code><a href="#topic+amlpoisson">amlpoisson</a></code> on the jargon,
including <em>expectiles</em> and <em>regression quantiles</em>.
</p>
<p>The <code>deviance</code> slot computes the total asymmetric squared error
loss (2.5).
If <code>w.aml</code> has more than one value then the value returned
by the slot is the sum taken over all the <code>w.aml</code> values.
</p>
<p>This <span class="pkg">VGAM</span> family function could well be renamed
<code>amlnormal()</code> instead, given the other function names
<code><a href="#topic+amlpoisson">amlpoisson</a></code>, <code><a href="#topic+amlbinomial">amlbinomial</a></code>, etc.
</p>
<p>In this documentation the word <em>quantile</em> can often be
interchangeably replaced by <em>expectile</em>
(things are informal here).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Efron, B. (1991).
Regression percentiles using asymmetric squared error loss.
<em>Statistica Sinica</em>,
<b>1</b>, 93&ndash;125.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amlpoisson">amlpoisson</a></code>,
<code><a href="#topic+amlbinomial">amlbinomial</a></code>,
<code><a href="#topic+amlexponential">amlexponential</a></code>,
<code><a href="#topic+bmi.nz">bmi.nz</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+denorm">denorm</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code> and similar variants are alternative
methods for quantile regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1
ooo &lt;- with(bmi.nz, order(age))
bmi.nz &lt;- bmi.nz[ooo, ]  # Sort by age
(fit &lt;- vglm(BMI ~ sm.bs(age), amlnormal(w.aml = 0.1), bmi.nz))
fit@extra  # Gives the w value and the percentile
coef(fit, matrix = TRUE)

# Quantile plot
with(bmi.nz, plot(age, BMI, col = "blue", main =
     paste(round(fit@extra$percentile, digits = 1),
           "expectile-percentile curve")))
with(bmi.nz, lines(age, c(fitted(fit)), col = "black"))

# Example 2
# Find the w values that give the 25, 50 and 75 percentiles
find.w &lt;- function(w, percentile = 50) {
  fit2 &lt;- vglm(BMI ~ sm.bs(age), amlnormal(w = w), data = bmi.nz)
  fit2@extra$percentile - percentile
}
# Quantile plot
with(bmi.nz, plot(age, BMI, col = "blue", las = 1, main =
     "25, 50 and 75 expectile-percentile curves"))
for (myp in c(25, 50, 75)) {
# Note: uniroot() can only find one root at a time
  bestw &lt;- uniroot(f = find.w, interval = c(1/10^4, 10^4),
                   percentile = myp)
  fit2 &lt;- vglm(BMI ~ sm.bs(age), amlnormal(w = bestw$root), bmi.nz)
  with(bmi.nz, lines(age, c(fitted(fit2)), col = "orange"))
}

# Example 3; this is Example 1 but with smoothing splines and
# a vector w and a parallelism assumption.
ooo &lt;- with(bmi.nz, order(age))
bmi.nz &lt;- bmi.nz[ooo, ]  # Sort by age
fit3 &lt;- vgam(BMI ~ s(age, df = 4), data = bmi.nz, trace = TRUE,
             amlnormal(w = c(0.1, 1, 10), parallel = TRUE))
fit3@extra  # The w values, percentiles and weighted deviances

# The linear components of the fit; not for human consumption:
coef(fit3, matrix = TRUE)

# Quantile plot
with(bmi.nz, plot(age, BMI, col="blue", main =
  paste(paste(round(fit3@extra$percentile, digits = 1), collapse = ", "),
        "expectile-percentile curves")))
with(bmi.nz, matlines(age, fitted(fit3), col = 1:fit3@extra$M, lwd = 2))
with(bmi.nz, lines(age, c(fitted(fit )), col = "black"))  # For comparison

## End(Not run)
</code></pre>

<hr>
<h2 id='amlpoisson'> Poisson Regression by Asymmetric Maximum Likelihood Estimation </h2><span id='topic+amlpoisson'></span>

<h3>Description</h3>

<p>Poisson quantile regression estimated by maximizing an
asymmetric likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amlpoisson(w.aml = 1, parallel = FALSE, imethod = 1, digw = 4,
           link = "loglink")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amlpoisson_+3A_w.aml">w.aml</code></td>
<td>

<p>Numeric, a vector of positive constants controlling the percentiles.
The larger the value the larger the fitted percentile value
(the proportion of points below the &ldquo;w-regression plane&rdquo;).
The default value of unity results in the ordinary maximum likelihood
(MLE) solution.
</p>
</td></tr>
<tr><td><code id="amlpoisson_+3A_parallel">parallel</code></td>
<td>

<p>If <code>w.aml</code> has more than one value then
this argument allows the quantile curves to differ by the same amount
as a function of the covariates.
Setting this to be <code>TRUE</code> should force the quantile curves to
not cross (although they may not cross anyway).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="amlpoisson_+3A_imethod">imethod</code></td>
<td>

<p>Integer, either 1 or 2 or 3. Initialization method.
Choose another value if convergence fails.
</p>
</td></tr>
<tr><td><code id="amlpoisson_+3A_digw">digw</code></td>
<td>

<p>Passed into <code><a href="base.html#topic+Round">Round</a></code> as the <code>digits</code> argument
for the <code>w.aml</code> values;
used cosmetically for labelling.
</p>
</td></tr>
<tr><td><code id="amlpoisson_+3A_link">link</code></td>
<td>

<p>See <code><a href="#topic+poissonff">poissonff</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by Efron (1992) and full details can
be obtained there.

The model is essentially a Poisson regression model
(see <code><a href="#topic+poissonff">poissonff</a></code>) but the usual deviance is replaced by an
asymmetric squared error loss function; it is multiplied by
<code class="reqn">w.aml</code> for positive residuals.
The solution is the set of regression coefficients that minimize the
sum of these deviance-type values over the data set, weighted by
the <code>weights</code> argument (so that it can contain frequencies).
Newton-Raphson estimation is used here.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>If <code>w.aml</code> has more than one value then the value returned by
<code>deviance</code> is the sum of all the (weighted) deviances taken over
all the <code>w.aml</code> values.
See Equation (1.6) of Efron (1992).
</p>


<h3>Note</h3>

<p>On fitting, the <code>extra</code> slot has list components <code>"w.aml"</code>
and <code>"percentile"</code>. The latter is the percent of observations
below the &ldquo;w-regression plane&rdquo;, which is the fitted values.  Also,
the individual deviance values corresponding to each element of the
argument <code>w.aml</code> is stored in the <code>extra</code> slot.
</p>
<p>For <code>amlpoisson</code> objects, methods functions for the generic
functions <code>qtplot</code> and <code>cdf</code> have not been written yet.
</p>
<p>About the jargon, Newey and Powell (1987) used the name
<em>expectiles</em> for regression surfaces obtained by asymmetric
least squares.
This was deliberate so as to distinguish them from the original
<em>regression quantiles</em> of Koenker and Bassett (1978).
Efron (1991) and Efron (1992) use the general name
<em>regression percentile</em> to apply to all forms of asymmetric
fitting.
Although the asymmetric maximum likelihood method very nearly gives
regression percentiles in the strictest sense for the normal and
Poisson cases, the phrase <em>quantile regression</em> is used loosely
in this <span class="pkg">VGAM</span> documentation.
</p>
<p>In this documentation the word <em>quantile</em> can often be
interchangeably replaced by <em>expectile</em>
(things are informal here).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Efron, B. (1991).
Regression percentiles using asymmetric squared error loss.
<em>Statistica Sinica</em>,
<b>1</b>, 93&ndash;125.
</p>
<p>Efron, B. (1992).
Poisson overdispersion estimates based on the method of
asymmetric maximum likelihood.
<em>Journal of the American Statistical Association</em>,
<b>87</b>, 98&ndash;107.
</p>
<p>Koenker, R. and Bassett, G. (1978).
Regression quantiles.
<em>Econometrica</em>,
<b>46</b>, 33&ndash;50.
</p>
<p>Newey, W. K. and Powell, J. L. (1987).
Asymmetric least squares estimation and testing.
<em>Econometrica</em>,
<b>55</b>, 819&ndash;847.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amlnormal">amlnormal</a></code>,
<code><a href="#topic+amlbinomial">amlbinomial</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+alaplace1">alaplace1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
mydat &lt;- data.frame(x = sort(runif(nn &lt;- 200)))
mydat &lt;- transform(mydat, y = rpois(nn, exp(0 - sin(8*x))))
(fit &lt;- vgam(y ~ s(x), fam = amlpoisson(w.aml = c(0.02, 0.2, 1, 5, 50)),
             mydat, trace = TRUE))
fit@extra

## Not run: 
# Quantile plot
with(mydat, plot(x, jitter(y), col = "blue", las = 1, main =
     paste(paste(round(fit@extra$percentile, digits = 1), collapse = ", "),
           "percentile-expectile curves")))
with(mydat, matlines(x, fitted(fit), lwd = 2)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='anova.vglm'>Analysis of Deviance for Vector Generalized Linear Model Fits</h2><span id='topic+anova.vglm'></span>

<h3>Description</h3>

<p>Compute an analysis of deviance table for one or more
vector generalized linear model fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vglm'
anova(object, ..., type = c("II", "I", "III", 2, 1, 3),
     test = c("LRT", "none"), trydev = TRUE, silent = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.vglm_+3A_object">object</code>, <code id="anova.vglm_+3A_...">...</code></td>
<td>
<p>objects of class <code>vglm</code>, typically
the result of a call to <code><a href="#topic+vglm">vglm</a></code>, or a list of
<code>objects</code> for the <code>"vglmlist"</code> method.
Each model must have an intercept term.
If <code>"vglmlist"</code> is used then <code>type = 1</code> or
<code>type = "I"</code> must be specified.
</p>

</td></tr>


<tr><td><code id="anova.vglm_+3A_type">type</code></td>
<td>

<p>character or numeric;
any one of the
(effectively three) choices given.
Note that <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>
has <code>1</code> or <code>"I"</code>
as its default;
and that <code>Anova.glm()</code> in <b>car</b>
(that is, the <b>car</b> package)
has <code>2</code> or <code>"II"</code> as its default
(and allows for <code>type = "III"</code>), so
one can think of this function as
a combination of <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>
and <code>Anova.glm()</code> in <b>car</b>,
but with the default of the latter.
See Details below for more information.
</p>








</td></tr>
<tr><td><code id="anova.vglm_+3A_test">test</code></td>
<td>
<p>a character string,
(partially) matching one of
<code>"LRT"</code> and
<code>"none"</code>.
In the future it is hoped that <code>"Rao"</code> be also supported,
to conduct score tests.
The first value is the default.
</p>




</td></tr>
<tr><td><code id="anova.vglm_+3A_trydev">trydev</code></td>
<td>

<p>logical; if <code>TRUE</code> then the deviance is used if possible.
Note that only a few <span class="pkg">VGAM</span> family functions have a
deviance that is defined and implemented.
Setting it <code>FALSE</code> means the log-likelihood will be used.
</p>
</td></tr>
<tr><td><code id="anova.vglm_+3A_silent">silent</code></td>
<td>

<p>logical; if <code>TRUE</code> then any warnings will be suppressed.
These may arise by IRLS iterations not converging during
the fitting of submodels.
Setting it <code>FALSE</code> means that any warnings are given.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>anova.vglm</code> is intended to be similar to
<code><a href="stats.html#topic+anova.glm">anova.glm</a></code>
so specifying a single object and <code>type = 1</code> gives a
<em>sequential</em> analysis of deviance table for that fit.
By <em>analysis of deviance</em>, it is meant loosely
that if the deviance of the model is not defined or implemented,
then twice the difference between the log-likelihoods of two
nested models remains asymptotically chi-squared distributed
with degrees of freedom equal to the difference in the number
of parameters of the two models.
Of course, the usual regularity conditions are assumed to hold.
For Type I,
the analysis of deviance table has
the reductions in the residual deviance
as each term of the formula is added in turn are given in as
the rows of a table, plus the residual deviances themselves.
<em>Type I</em> or sequential tests
(as in <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>).
are computationally the easiest of the three methods.
For this, the order of the terms is important, and the
each term is added sequentially from first to last.
</p>
<p>The <code>Anova()</code> function in <b>car</b> allows for testing
<em>Type II</em> and <em>Type III</em> (SAS jargon) hypothesis
tests, although the definitions used are <em>not</em> precisely
that of SAS.
As <b>car</b> notes,
<em>Type I</em> rarely test interesting hypotheses in unbalanced
designs.  Type III enter each term <em>last</em>, keeping all
the other terms in the model.
</p>
<p>Type II tests,
according to SAS,
add the term after all other terms have been added to the model
except terms that contain the effect being tested; an effect
is contained in another effect if it can be derived by deleting
variables from the latter effect.
Type II tests are currently the default.
</p>
<p>As in <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>, but not as
<code>Anova.glm()</code> in <b>car</b>,
if more than one object is specified, then
the table has a row for the
residual degrees of freedom and deviance for each model.
For all but the first model, the change in degrees of freedom
and deviance is also given. (This only makes statistical sense
if the models are nested.)  It is conventional to list the
models from smallest to largest, but this is up to the user.
It is necessary to have <code>type = 1</code> with more than one
objects are specified.
</p>

<p>See <code><a href="stats.html#topic+anova.glm">anova.glm</a></code> for more details
and warnings.
The <span class="pkg">VGAM</span> package now implements full likelihood models
only, therefore no dispersion parameters are estimated.
</p>



<h3>Value</h3>

<p>An object of class <code>"anova"</code> inheriting from
class <code>"data.frame"</code>.
</p>


<h3>Warning </h3>

<p>See <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>.
Several <span class="pkg">VGAM</span> family functions implement distributions
which do not satisfying the usual regularity conditions needed for
the LRT to work. No checking or warning is given for these.
</p>
<p>As <b>car</b> says, be careful of Type III tests
because they violate marginality.
Type II tests (the default) do not have this problem.
</p>









<h3>Note</h3>

<p>It is possible for this function to <code><a href="base.html#topic+stop">stop</a></code>
when <code>type = 2</code> or <code>3</code>, e.g.,
<code>anova(vglm(cans ~ myfactor, poissonff, data = boxcar))</code>
where <code>myfactor</code> is a factor.
</p>
<p>The code was adapted
directly from <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>
and <code>Anova.glm()</code> in <b>car</b>
by T. W. Yee.
Hence the Type II and Type III tests do <em>not</em>
correspond precisely with the SAS definition.
</p>



<h3>See Also</h3>

<p><code><a href="stats.html#topic+anova.glm">anova.glm</a></code>,
<code><a href="stats.html#topic+stat.anova">stat.anova</a></code>,
<code>stats:::print.anova</code>,
<code>Anova.glm()</code> in <b>car</b> if <b>car</b> is installed,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+lrtest">lrtest</a></code>,
<code><a href="#topic+add1.vglm">add1.vglm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>,
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+score.stat.vlm">score.stat.vlm</a></code>,
<code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>,
<code><a href="#topic+backPain2">backPain2</a></code>,
<code><a href="stats.html#topic+update">update</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'># Example 1: a proportional odds model fitted to pneumo.
set.seed(1)
pneumo &lt;- transform(pneumo, let = log(exposure.time), x3 = runif(8))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let     , propodds, pneumo)
fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let + x3, propodds, pneumo)
fit3 &lt;- vglm(cbind(normal, mild, severe) ~ let + x3, cumulative, pneumo)
anova(fit1, fit2, fit3, type = 1)  # Remember to specify 'type'!!
anova(fit2)
anova(fit2, type = "I")
anova(fit2, type = "III")

# Example 2: a proportional odds model fitted to backPain2.
data("backPain2", package = "VGAM")
summary(backPain2)
fitlogit &lt;- vglm(pain ~ x2 * x3 * x4, propodds, data = backPain2)
coef(fitlogit)
anova(fitlogit)
anova(fitlogit, type = "I")
anova(fitlogit, type = "III")
</code></pre>

<hr>
<h2 id='AR1'> Autoregressive Process with Order-1 Family Function </h2><span id='topic+AR1'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the three-parameter AR-1 model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AR1(ldrift = "identitylink", lsd  = "loglink", lvar = "loglink", lrho = "rhobitlink",
    idrift  = NULL, isd  = NULL, ivar = NULL, irho = NULL, imethod = 1,
    ishrinkage = 0.95, type.likelihood = c("exact", "conditional"),
    type.EIM  = c("exact", "approximate"), var.arg = FALSE, nodrift = FALSE,
    print.EIM = FALSE, zero = c(if (var.arg) "var" else "sd", "rho"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AR1_+3A_ldrift">ldrift</code>, <code id="AR1_+3A_lsd">lsd</code>, <code id="AR1_+3A_lvar">lvar</code>, <code id="AR1_+3A_lrho">lrho</code></td>
<td>

<p>Link functions applied to the scaled mean, standard deviation
or variance, and correlation parameters.
The parameter <code>drift</code> is known as the <em>drift</em>, and
it is a scaled mean.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="AR1_+3A_idrift">idrift</code>, <code id="AR1_+3A_isd">isd</code>, <code id="AR1_+3A_ivar">ivar</code>, <code id="AR1_+3A_irho">irho</code></td>
<td>

<p>Optional initial values for the parameters.
If failure to converge occurs then try different values
and monitor convergence by using <code>trace = TRUE</code>.
For a <code class="reqn">S</code>-column response, these arguments can be of length
<code class="reqn">S</code>, and they are recycled by the columns first.
A value <code>NULL</code> means an initial value for each response is
computed internally.
</p>
</td></tr>
<tr><td><code id="AR1_+3A_ishrinkage">ishrinkage</code>, <code id="AR1_+3A_imethod">imethod</code>, <code id="AR1_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The default for <code>zero</code> assumes there is a drift parameter to
be estimated (the default for that argument), so if a drift parameter
is suppressed and there are covariates, then <code>zero</code> will need
to be assigned the value 1 or 2 or <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="AR1_+3A_var.arg">var.arg</code></td>
<td>

<p>Same meaning as <code><a href="#topic+uninormal">uninormal</a></code>.
</p>
</td></tr>
<tr><td><code id="AR1_+3A_nodrift">nodrift</code></td>
<td>

<p>Logical, for determining whether to estimate the drift parameter.
The default is to estimate it.
If <code>TRUE</code>, the drift parameter is set to 0 and not estimated.
</p>
</td></tr>
<tr><td><code id="AR1_+3A_type.eim">type.EIM</code></td>
<td>

<p>What type of expected information matrix (EIM) is used in
Fisher scoring. By default, this family function calls
<code><a href="#topic+AR1EIM">AR1EIM</a></code>, which recursively
computes the exact EIM for the AR process with Gaussian
white noise. See Porat and Friedlander (1986) for further
details on the exact EIM.
</p>
<p>If <code>type.EIM = "approximate"</code> then
approximate expression for the EIM of Autoregressive processes
is used; this approach holds when the number of observations
is large enough. Succinct details about the approximate EIM
are delineated at Porat and Friedlander (1987).
</p>
</td></tr>
<tr><td><code id="AR1_+3A_print.eim">print.EIM</code></td>
<td>

<p>Logical. If <code>TRUE</code>, then the first few EIMs are printed.
Here, the result shown is the sum of each EIM.
</p>
</td></tr>
<tr><td><code id="AR1_+3A_type.likelihood">type.likelihood</code></td>
<td>

<p>What type of likelihood function is maximized.
The first choice (default) is the sum of the marginal likelihood
and the conditional likelihood.
Choosing the conditional likelihood means that the first observation is
effectively ignored (this is handled internally by setting
the value of the first prior weight to be some small
positive number, e.g., <code>1.0e-6</code>).
See the note below.
</p>
</td></tr>





</table>


<h3>Details</h3>

<p>The AR-1 model implemented here has
</p>
<p style="text-align: center;"><code class="reqn">Y_1 \sim N(\mu, \sigma^2 / (1-\rho^2)), </code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">Y_i  = \mu^* + \rho Y_{i-1} + e_i, </code>
</p>

<p>where the <code class="reqn">e_i</code> are i.i.d. Normal(0, sd = <code class="reqn">\sigma</code>)
random variates.
</p>
<p>Here are a few notes:
(1). A test for weak stationarity might be to verify whether
<code class="reqn">1/\rho</code> lies outside the unit circle.
(2). The mean of all the <code class="reqn">Y_i</code>
is <code class="reqn">\mu^* /(1-\rho)</code> and
these are returned as the fitted values.
(3). The correlation of all the <code class="reqn">Y_i</code> with <code class="reqn">Y_{i-1}</code>
is <code class="reqn">\rho</code>.
(4). The default link function ensures that
<code class="reqn">-1 &lt; \rho &lt; 1</code>.
</p>



<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>Monitoring convergence is urged, i.e., set <code>trace = TRUE</code>.
</p>
<p>Moreover, if the exact EIMs are used, set <code>print.EIM = TRUE</code>
to compare the computed exact to the approximate EIM.
</p>
<p>Under the VGLM/VGAM approach, parameters can be modelled in terms
of covariates. Particularly, if the standard deviation of
the white noise is modelled in this way, then
<code>type.EIM = "exact"</code> may certainly lead to unstable
results. The reason is that white noise is a stationary
process, and consequently, its variance must remain as a constant.
Consequently, the use of variates to model
this parameter contradicts the assumption of
stationary random components to compute the exact EIMs proposed
by Porat and Friedlander (1987).
</p>
<p>To prevent convergence issues in such cases, this family function
internally verifies whether the variance of the white noise remains
as a constant at each Fisher scoring iteration.
If this assumption is violated and <code>type.EIM = "exact"</code> is set,
then <code>AR1</code> automatically shifts to
<code>type.EIM = "approximate"</code>.
Also, a warning is accordingly displayed.
</p>








<h3>Note</h3>








<p>Multiple responses are handled.
The mean is returned as the fitted values.
</p>











<h3>Author(s)</h3>

<p> Victor Miranda (exact method) and
Thomas W. Yee (approximate method).</p>


<h3>References</h3>

<p>Porat, B. and Friedlander, B. (1987).
The Exact Cramer-Rao Bond for Gaussian Autoregressive Processes.
<em>IEEE Transactions on Aerospace and Electronic Systems</em>,
<b>AES-23(4)</b>, 537&ndash;542.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AR1EIM">AR1EIM</a></code>,
<code><a href="#topic+vglm.control">vglm.control</a></code>,
<code><a href="#topic+dAR1">dAR1</a></code>,
<code><a href="stats.html#topic+arima.sim">arima.sim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: using  arima.sim() to generate a 0-mean stationary time series.
nn &lt;- 500
tsdata &lt;- data.frame(x2 =  runif(nn))
ar.coef.1 &lt;- rhobitlink(-1.55, inverse = TRUE)  # Approx -0.65
ar.coef.2 &lt;- rhobitlink( 1.0, inverse = TRUE)   # Approx  0.50
set.seed(1)
tsdata  &lt;- transform(tsdata,
              index = 1:nn,
              TS1 = arima.sim(nn, model = list(ar = ar.coef.1),
                              sd = exp(1.5)),
              TS2 = arima.sim(nn, model = list(ar = ar.coef.2),
                              sd = exp(1.0 + 1.5 * x2)))

### An autoregressive intercept--only model.   ###
### Using the exact EIM, and "nodrift = TRUE"  ###
fit1a &lt;- vglm(TS1 ~ 1, data = tsdata, trace = TRUE,
              AR1(var.arg = FALSE, nodrift = TRUE,
                  type.EIM = "exact",
                  print.EIM = FALSE),
              crit = "coefficients")
Coef(fit1a)
summary(fit1a)

## Not run: 
### Two responses. Here, the white noise standard deviation of TS2   ###
### is modelled in terms of 'x2'. Also, 'type.EIM = exact'.  ###
fit1b &lt;- vglm(cbind(TS1, TS2) ~ x2,
              AR1(zero = NULL, nodrift = TRUE,
                  var.arg = FALSE,
                  type.EIM = "exact"),
              constraints = list("(Intercept)" = diag(4),
                                 "x2" = rbind(0, 0, 1, 0)),
              data = tsdata, trace = TRUE, crit = "coefficients")
coef(fit1b, matrix = TRUE)
summary(fit1b)

### Example 2: another stationary time series
nn     &lt;- 500
my.rho &lt;- rhobitlink(1.0, inverse = TRUE)
my.mu  &lt;- 1.0
my.sd  &lt;- exp(1)
tsdata  &lt;- data.frame(index = 1:nn, TS3 = runif(nn))

set.seed(2)
for (ii in 2:nn)
  tsdata$TS3[ii] &lt;- my.mu/(1 - my.rho) +
                    my.rho * tsdata$TS3[ii-1] + rnorm(1, sd = my.sd)
tsdata &lt;- tsdata[-(1:ceiling(nn/5)), ]  # Remove the burn-in data:

### Fitting an AR(1). The exact EIMs are used.
fit2a &lt;- vglm(TS3 ~ 1, AR1(type.likelihood = "exact",  # "conditional",
                                type.EIM = "exact"),
              data = tsdata, trace = TRUE, crit = "coefficients")

Coef(fit2a)
summary(fit2a)      # SEs are useful to know

Coef(fit2a)["rho"]    # Estimate of rho, for intercept-only models
my.rho                # The 'truth' (rho)
Coef(fit2a)["drift"]  # Estimate of drift, for intercept-only models
my.mu /(1 - my.rho)   # The 'truth' (drift)

## End(Not run)
</code></pre>

<hr>
<h2 id='AR1EIM'>Computation of the Exact EIM of an Order-1 Autoregressive Process
</h2><span id='topic+AR1EIM'></span>

<h3>Description</h3>

<p>Computation of the exact Expected Information Matrix of
the Autoregressive process of order-<code class="reqn">1</code> (AR(<code class="reqn">1</code>))
with Gaussian white noise and stationary
random components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AR1EIM(x = NULL, var.arg = NULL, p.drift = NULL,
       WNsd = NULL, ARcoeff1 = NULL, eps.porat = 1e-2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AR1EIM_+3A_x">x</code></td>
<td>

<p>A vector of quantiles. The gaussian time series for which the EIMs
are computed.
</p>
<p>If multiple time series are being analyzed, then <code>x</code> must be
a matrix where each column allocates a response.
That is, the number of columns (denoted as <code class="reqn">NOS</code>) must match
the number of responses.
</p>
</td></tr>
<tr><td><code id="AR1EIM_+3A_var.arg">var.arg</code></td>
<td>

<p>Logical. Same as with <code><a href="#topic+AR1">AR1</a></code>.
</p>
</td></tr>
<tr><td><code id="AR1EIM_+3A_p.drift">p.drift</code></td>
<td>

<p>A numeric vector with the <em>scaled mean(s)</em> (commonly referred as
<em>drift</em>) of the AR process(es) in turn.
Its length matches the number of responses.
</p>
</td></tr>
<tr><td><code id="AR1EIM_+3A_wnsd">WNsd</code>, <code id="AR1EIM_+3A_arcoeff1">ARcoeff1</code></td>
<td>

<p>Matrices.
The standard deviation of the white noise, and the
correlation (coefficient) of the AR(<code class="reqn">1</code>) model,
for <b>each</b> observation.
</p>
<p>That is, the dimension for each matrix is <code class="reqn">N \times NOS</code>,
where <code class="reqn">N</code> is the number of observations and <code class="reqn">NOS</code> is the
number of responses. Else, these arguments are recycled.
</p>
</td></tr>
<tr><td><code id="AR1EIM_+3A_eps.porat">eps.porat</code></td>
<td>

<p>A very small positive number to test whether the standar deviation
(<code>WNsd</code>) is close enough to its value estimated in this function.
</p>
<p>See below for further details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the algorithm of Porat and Friedlander
(1986) to <em>recursively</em> compute the exact expected
information matrix (EIM) of Gaussian time series with stationary
random components.
</p>
<p>By default, when the VGLM/VGAM family function
<code><a href="#topic+AR1">AR1</a></code> is used to fit an AR(<code class="reqn">1</code>) model
via <code><a href="#topic+vglm">vglm</a></code>, Fisher scoring is executed using
the <b>approximate</b> EIM for the AR process. However, this model
can also be fitted using the <b>exact</b> EIMs computed by
<code>AR1EIM</code>.
</p>
<p>Given <code class="reqn">N</code> consecutive data points,
<code class="reqn"> {y_{0}, y_{1}, \ldots, y_{N - 1} } </code> with probability density <code class="reqn">f(\boldsymbol{y})</code>,
the Porat and Friedlander algorithm
calculates the EIMs
<code class="reqn"> [J_{n-1}(\boldsymbol{\theta})] </code>,
for all <code class="reqn">1 \leq n \leq N</code>. This is done based on the
Levinson-Durbin algorithm for computing the orthogonal polynomials of
a Toeplitz matrix.
In particular, for the AR(<code class="reqn">1</code>) model, the vector of parameters
to be estimated under the VGAM/VGLM approach is
</p>
<p style="text-align: center;"><code class="reqn">   \boldsymbol{\eta} = (\mu^{*}, \log(\sigma^2), rhobit(\rho)),</code>
</p>

<p>where <code class="reqn">\sigma^2</code> is the variance of the white noise
and <code class="reqn">mu^{*}</code> is the drift parameter
(See <code><a href="#topic+AR1">AR1</a></code> for further details on this).
</p>









<p>Consequently, for each observation <code class="reqn">n = 1, \ldots, N</code>, the EIM,
<code class="reqn">J_{n}(\boldsymbol{\theta})</code>, has dimension
<code class="reqn">3 \times 3</code>, where the diagonal elements are:





</p>
<p style="text-align: center;"><code class="reqn"> J_{[n, 1, 1]} =
     E[ -\partial^2 \log f(\boldsymbol{y}) / \partial ( \mu^{*} )^2 ], </code>
</p>

<p style="text-align: center;"><code class="reqn"> J_{[n, 2, 2]} =
     E[ -\partial^2 \log f(\boldsymbol{y}) / \partial (\sigma^2)^2 ], </code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn"> J_{[n, 3, 3]} =
     E[ -\partial^2 \log f(\boldsymbol{y}) / \partial ( \rho )^2 ]. </code>
</p>

<p>As for the off-diagonal elements, one has the usual entries, i.e.,
</p>
<p style="text-align: center;"><code class="reqn"> J_{[n, 1, 2]} = J_{[n, 2, 1]} =
     E[ -\partial^2 \log f(\boldsymbol{y}) / \partial \sigma^2
           \partial \rho], </code>
</p>

<p>etc.
</p>
<p>If <code>var.arg = FALSE</code>, then <code class="reqn">\sigma</code> instead of <code class="reqn">\sigma^2</code>
is estimated. Therefore, <code class="reqn">J_{[n, 2, 2]}</code>,
<code class="reqn">J_{[n, 1, 2]}</code>, etc., are correspondingly replaced.
</p>
<p>Once these expected values are internally computed, they are returned
in an array of dimension <code class="reqn">N \times 1 \times 6</code>,
of the form
</p>
<p style="text-align: center;"><code class="reqn">J[, 1, ] = [ J_{[ , 1, 1]}, J_{[ , 2, 2]}, J_{[ , 3, 3]},
                   J_{[ , 1, 2]}, J_{[, 2, 3]}, J_{[ , 1, 3]}  ].  </code>
</p>

<p><code>AR1EIM</code> handles multiple time series, say <code class="reqn">NOS</code>.
If this happens, then it accordingly returns an array of
dimension <code class="reqn">N \times NOS \times 6 </code>. Here,
<code class="reqn">J[, k, ]</code>, for <code class="reqn">k = 1, \ldots, NOS</code>, is a matrix
of dimension <code class="reqn">N \times 6</code>, which
stores the EIMs for the <code class="reqn">k^{th}</code>th response, as
above, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">J[, k, ] = [ J_{[ , 1, 1]}, J_{[ , 2, 2]},
                       J_{[ , 3, 3]}, \ldots ], </code>
</p>

<p>the <em>bandwith</em> form, as per required by
<code><a href="#topic+AR1">AR1</a></code>.
</p>


<h3>Value</h3>

<p>An array of dimension <code class="reqn">N \times NOS \times 6</code>,
as above.
</p>
<p>This array stores the EIMs calculated from the joint density as
a function of
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{\theta} = (\mu^*, \sigma^2, \rho). </code>
</p>

<p>Nevertheless, note that, under the VGAM/VGLM approach, the EIMs
must be correspondingly calculated in terms of the linear
predictors, <code class="reqn">\boldsymbol{\eta}</code>.
</p>


<h3>Asymptotic behaviour of the algorithm</h3>

<p>For large enough <code class="reqn">n</code>, the EIMs,
<code class="reqn">J_n(\boldsymbol{\theta})</code>,
become approximately linear in <code class="reqn">n</code>. That is, for some
<code class="reqn">n_0</code>,
</p>
<p style="text-align: center;"><code class="reqn"> J_n(\boldsymbol{\theta}) \equiv
         J_{n_0}(\boldsymbol{\theta}) + (n - n_0)
         \bar{J}(\boldsymbol{\theta}),~~~~~~(**) </code>
</p>

<p>where <code class="reqn"> \bar{J}(\boldsymbol{\theta})  </code> is
a constant matrix.
</p>
<p>This relationsihip is internally considered if a proper value
of <code class="reqn">n_0</code> is determined. Different ways can be adopted to
find <code class="reqn">n_0</code>. In <code>AR1EIM</code>, this is done by checking
the difference between the internally estimated variances and the
entered ones at <code>WNsd</code>.
If this difference is less than
<code>eps.porat</code> at some iteration, say at iteration <code class="reqn">n_0</code>,
then <code>AR1EIM</code> takes
<code class="reqn"> \bar{J}(\boldsymbol{\theta})</code>
as the last computed increment of
<code class="reqn">J_n(\boldsymbol{\theta})</code>, and extraplotates
<code class="reqn">J_k(\boldsymbol{\theta})</code>, for all
<code class="reqn">k \geq n_0 </code> using <code class="reqn">(*)</code>.
Else, the algorithm will complete the iterations for
<code class="reqn">1 \leq n \leq N</code>.
</p>
<p>Finally, note that the rate of convergence reasonably decreases if
the asymptotic relationship <code class="reqn">(*)</code> is used to compute
<code class="reqn">J_k(\boldsymbol{\theta})</code>,
<code class="reqn">k \geq n_0 </code>. Normally, the number
of operations involved on this algorithm is proportional to
<code class="reqn">N^2</code>.
</p>
<p>See Porat and Friedlander (1986) for full details on the asymptotic
behaviour of the algorithm.
</p>


<h3>Warning</h3>

<p>Arguments <code>WNsd</code>, and <code>ARcoeff1</code> are matrices of dimension
<code class="reqn">N \times NOS</code>. Else, these arguments are accordingly
recycled.
</p>


<h3>Note</h3>

<p>For simplicity, one can assume that the time series analyzed has
a 0-mean. Consequently, where the family function
<code><a href="#topic+AR1">AR1</a></code> calls <code>AR1EIM</code> to compute
the EIMs, the argument <code>p.drift</code> is internally set
to zero-vector, whereas <code>x</code> is <em>centered</em> by
subtracting its mean value.
</p>


<h3>Author(s)</h3>

<p>V. Miranda and T. W. Yee.
</p>


<h3>References</h3>

<p>Porat, B. and Friedlander, B. (1986).
Computation of the Exact Information Matrix of Gaussian Time Series
with Stationary Random Components.
<em>IEEE Transactions on Acoustics, Speech, and Signal Processing</em>,
<b>54(1)</b>, 118&ndash;130.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AR1">AR1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(1)
  nn &lt;- 500
  ARcoeff1 &lt;- c(0.3, 0.25)        # Will be recycled.
  WNsd     &lt;- c(exp(1), exp(1.5)) # Will be recycled.
  p.drift  &lt;- c(0, 0)             # Zero-mean gaussian time series.

  ### Generate two (zero-mean) AR(1) processes ###
  ts1 &lt;- p.drift[1]/(1 - ARcoeff1[1]) +
                   arima.sim(model = list(ar = ARcoeff1[1]), n = nn,
                   sd = WNsd[1])
  ts2 &lt;- p.drift[2]/(1 - ARcoeff1[2]) +
                   arima.sim(model = list(ar = ARcoeff1[2]), n = nn,
                   sd = WNsd[2])

  ARdata &lt;- matrix(cbind(ts1, ts2), ncol = 2)


  ### Compute the exact EIMs: TWO responses. ###
  ExactEIM &lt;- AR1EIM(x = ARdata, var.arg = FALSE, p.drift = p.drift,
                           WNsd = WNsd, ARcoeff1 = ARcoeff1)

  ### For response 1:
  head(ExactEIM[, 1 ,])      # NOTICE THAT THIS IS A (nn x 6) MATRIX!

  ### For response 2:
  head(ExactEIM[, 2 ,])      # NOTICE THAT THIS IS A (nn x 6) MATRIX!
</code></pre>

<hr>
<h2 id='asinlink'> Arcsine Link Function</h2><span id='topic+asinlink'></span>

<h3>Description</h3>

<p>Computes the arcsine link,
including its inverse and
the first few derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asinlink(theta, bvalue = NULL, inverse = FALSE,
   deriv = 0, short = TRUE, tag = FALSE, c10 = c(4, -pi))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asinlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="asinlink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="asinlink_+3A_inverse">inverse</code>, <code id="asinlink_+3A_deriv">deriv</code>, <code id="asinlink_+3A_short">short</code>, <code id="asinlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="asinlink_+3A_c10">c10</code></td>
<td>

<p>Similar to <code><a href="#topic+sqrtlink">sqrtlink</a></code>.
The default is intended to match
<code><a href="#topic+lcalogitlink">lcalogitlink</a></code> for <code><a href="#topic+binomialff">binomialff</a></code>
at binomial probabilities (<code>theta</code>) equal
to 0.5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code><a href="#topic+alogitlink">alogitlink</a></code>
gives some motivation for this link.
However, the problem with this link
is that it is bounded by default
between <code>(-pi, pi)</code>
so that it can be unsuitable for regression.
This link is a scaled and centred
CDF of the arcsine distribution.
The centring is chosen so that
<code>asinlink(0.5)</code> is 0,
and the scaling is chosen so that
<code>asinlink(0.5, deriv = 1)</code> and
<code>logitlink(0.5, deriv = 1)</code>
are equal (the value 4 actually),
hence this link will operate similar to the
<code><a href="#topic+logitlink">logitlink</a></code>
when close to 0.5.
</p>


<h3>Value</h3>

<p>Similar to <code><a href="#topic+logitlink">logitlink</a></code>
but using different formulas.
</p>


<h3>Warning </h3>

<p>It is possible that the scaling might change
in the future.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+alogitlink">alogitlink</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+sloglink">sloglink</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, length= 10)
asinlink(p)
max(abs(asinlink(asinlink(p), inv = TRUE) - p))  # 0?

## Not run: 
par(mfrow = c(2, 2), lwd = (mylwd &lt;- 2))
y &lt;- seq(-4, 4, length = 100)
p &lt;- seq(0.01, 0.99, by = 0.01)

for (d in 0:1) {
  matplot(p, cbind(logitlink(p, deriv = d), probitlink(p, deriv = d)),
          type = "n", col = "blue", ylab = "transformation",
          log = ifelse(d == 1, "y", ""),
          las = 1, main = if (d == 0) "Some probability link functions"
          else "First derivative")
  lines(p,   logitlink(p, deriv = d), col = "green")
  lines(p,  probitlink(p, deriv = d), col = "blue")
  lines(p, clogloglink(p, deriv = d), col = "tan")
  lines(p,    asinlink(p, deriv = d), col = "red3")
  if (d == 0) {
    abline(v = 0.5, h = 0, lty = "dashed")
    legend(0, 4.5, c("logitlink", "probitlink", "clogloglink",
           "asinlink"), lwd = mylwd,
           col = c("green", "blue", "tan", "red3"))
  } else
    abline(v = 0.5, lwd = 0.5, col = "gray")
}

for (d in 0) {
  matplot(y, cbind( logitlink(y, deriv = d, inverse = TRUE),
                   probitlink(y, deriv = d, inverse = TRUE)),
          type  = "n", col = "blue", xlab = "transformation", ylab = "p",
          main = if (d == 0) "Some inverse probability link functions"
          else "First derivative", las=1)
  lines(y,   logitlink(y, deriv = d, inverse = TRUE), col = "green")
  lines(y,  probitlink(y, deriv = d, inverse = TRUE), col = "blue")
  lines(y, clogloglink(y, deriv = d, inverse = TRUE), col = "tan")
  lines(y,    asinlink(y, deriv = d, inverse = TRUE), col = "red3")
  if (d == 0) {
      abline(h = 0.5, v = 0, lwd = 0.5, col = "gray")
      legend(-4, 1, c("logitlink", "probitlink", "clogloglink",
             "asinlink"), lwd = mylwd,
             col = c("green", "blue", "tan", "red3"))
  }
}
par(lwd = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='auuc'> Auckland University Undergraduate Counts Data</h2><span id='topic+auuc'></span>

<h3>Description</h3>

<p>Undergraduate student enrolments
at the University of Auckland in 1990.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(auuc)</code></pre>


<h3>Format</h3>

<p>A data frame with 4 observations on the following 5 variables.
</p>

<dl>
<dt>Commerce</dt><dd><p>a numeric vector of counts.</p>
</dd>
<dt>Arts</dt><dd><p>a numeric vector of counts.</p>
</dd>
<dt>SciEng</dt><dd><p>a numeric vector of counts.</p>
</dd>
<dt>Law</dt><dd><p>a numeric vector of counts.</p>
</dd>
<dt>Medicine</dt><dd><p>a numeric vector of counts.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each student is cross-classified by their colleges (Science
and Engineering have been combined) and the socio-economic
status (SES) of their fathers
(1 = highest, down to 4 = lowest).
</p>


<h3>Source</h3>

<p>Dr Tony Morrison.
</p>


<h3>References</h3>

<p>Wild, C. J. and Seber, G. A. F. (2000).
<em>Chance Encounters: A First Course in Data Analysis and Inference</em>,
New York: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>auuc
## Not run: 
round(fitted(grc(auuc)))
round(fitted(grc(auuc, Rank = 2)))

## End(Not run)
</code></pre>

<hr>
<h2 id='aux.posbernoulli.t'> Auxiliary Function for the
Positive Bernoulli Family Function with Time Effects </h2><span id='topic+aux.posbernoulli.t'></span>

<h3>Description</h3>

<p>Returns behavioural effects indicator variables from a
capture history matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aux.posbernoulli.t(y, check.y = FALSE, rename = TRUE, name = "bei")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aux.posbernoulli.t_+3A_y">y</code></td>
<td>

<p>Capture history matrix.
Rows are animals, columns are sampling occasions, and
values should be 0s and 1s only.
</p>
</td></tr>
<tr><td><code id="aux.posbernoulli.t_+3A_check.y">check.y</code></td>
<td>

<p>Logical, if <code>TRUE</code> then some basic checking is performed.
</p>
</td></tr>
<tr><td><code id="aux.posbernoulli.t_+3A_rename">rename</code>, <code id="aux.posbernoulli.t_+3A_name">name</code></td>
<td>

<p>If <code>rename = TRUE</code> then the behavioural effects indicator
are named using the value of <code>name</code> as the prefix.
If <code>FALSE</code> then use the same column names as <code>y</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can help fit certain capture&ndash;recapture models
(commonly known as <code class="reqn">M_{tb}</code> or <code class="reqn">M_{tbh}</code>
(no prefix <code class="reqn">h</code> means it is an intercept-only model)
in the literature).
See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> for details.
</p>


<h3>Value</h3>

<p>A list with the following components.
</p>

<dl>
<dt>cap.hist1</dt><dd>
<p>A matrix the same dimension as <code>y</code>.
In any particular row there are 0s up to
the first capture. Then there are 1s thereafter.
</p>
</dd>
<dt>cap1</dt><dd>
<p>A vector specifying which time occasion the animal
was first captured.
</p>
</dd>
<dt>y0i</dt><dd>
<p>Number of noncaptures before the first capture.
</p>
</dd>
<dt>yr0i</dt><dd>
<p>Number of noncaptures after the first capture.
</p>
</dd>
<dt>yr1i</dt><dd>
<p>Number of recaptures after the first capture.
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>,
<code><a href="#topic+deermice">deermice</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a M_tbh model to the deermice data:
(pdata &lt;- aux.posbernoulli.t(with(deermice,
                                  cbind(y1, y2, y3, y4, y5, y6))))

deermice &lt;- data.frame(deermice,
                    bei = 0,  # Add this
                    pdata$cap.hist1)  # Incorporate these
head(deermice)  # Augmented with behavioural effect indicator variables
tail(deermice)
</code></pre>

<hr>
<h2 id='backPain'> Data on Back Pain Prognosis, from Anderson (1984) </h2><span id='topic+backPain'></span><span id='topic+backPain2'></span>

<h3>Description</h3>

<p>Data from a study of patients suffering from back
pain. Prognostic variables were recorded at presentation and
progress was categorised three weeks after treatment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(backPain)</code></pre>


<h3>Format</h3>

<p>A data frame with 101 observations on the following 4 variables.
</p>

<dl>
<dt>x2</dt><dd><p>length of previous attack.</p>
</dd>
<dt>x3</dt><dd><p>pain change.</p>
</dd>
<dt>x4</dt><dd><p>lordosis.</p>
</dd>
<dt>pain</dt><dd><p>an ordered factor describing the progress of each
patient with levels <code>worse</code> &lt; <code>same</code> &lt;
<code>slight.improvement</code> &lt; <code>moderate.improvement</code> &lt;
<code>marked.improvement</code> &lt; <code>complete.relief</code>. </p>
</dd>
</dl>



<h3>Source</h3>

<p><code>http://ideas.repec.org/c/boc/bocode/s419001.html</code>
</p>

<p>The data set and this help file was copied from <span class="pkg">gnm</span>
so that a vignette in <span class="pkg">VGAM</span> could be run; the analysis is
described in Yee (2010).
</p>
<p>The data frame <code>backPain2</code> is a modification of
<code>backPain</code> where the variables have been renamed
(<code>x1</code> becomes <code>x2</code>,
<code>x2</code> becomes <code>x3</code>,
<code>x3</code> becomes <code>x4</code>)
and
converted into factors.
</p>


<h3>References</h3>

<p>Anderson, J. A. (1984).
Regression and Ordered Categorical Variables.
<em>J. R. Statist. Soc. B</em>, <b>46(1)</b>, 1-30.
</p>
<p>Yee, T. W. (2010).
The <span class="pkg">VGAM</span> package for categorical data analysis.
<em>Journal of Statistical Software</em>,
<b>32</b>, 1&ndash;34.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>summary(backPain)
summary(backPain2)
</code></pre>

<hr>
<h2 id='beggs'>Bacon and Eggs Data</h2><span id='topic+beggs'></span>

<h3>Description</h3>

<p>Purchasing of bacon and eggs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(beggs)
</code></pre>


<h3>Format</h3>

<p>Data frame of a two way table.
</p>

<dl>
<dt>b0, b1, b2, b3, b4</dt><dd>
<p>The <code>b</code> refers to bacon.
The number of times bacon was purchased was 0, 1, 2, 3, or 4.
</p>
</dd>
<dt>e0, e1, e2, e3, e4</dt><dd>
<p>The <code>e</code> refers to eggs.
The number of times eggs was purchased was 0, 1, 2, 3, or 4.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data is from Information Resources, Inc., a consumer panel
based in a large US city [see Bell and Lattin (1998) for further
details]. Starting in June 1991, the purchases in the bacon and
fresh eggs product categories for a sample of 548 households over
four consecutive store trips was tracked.  Only those grocery
shopping trips with a total basket value of at least five dollars
was considered.  For each household, the total number of bacon
purchases in their four eligible shopping trips and the total
number of egg purchases (usually a package of eggs) for the same
trips, were counted.
</p>




<h3>Source</h3>

<p>Bell, D. R. and Lattin, J. M. (1998)
Shopping Behavior and Consumer Preference
for Store Price Format: Why &lsquo;Large Basket&rsquo; Shoppers Prefer EDLP.
<em>Marketing Science</em>,
<b>17</b>, 66&ndash;88.
</p>


<h3>References</h3>

<p>Danaher, P. J. and Hardie, B. G. S. (2005).
Bacon with Your Eggs?
Applications of a New Bivariate Beta-Binomial Distribution.
<em>American Statistician</em>,
<b>59</b>(4), 282&ndash;286.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+grc">grc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>beggs
colSums(beggs)
rowSums(beggs)
</code></pre>

<hr>
<h2 id='bell'>
The Bell Series of Integers
</h2><span id='topic+bell'></span>

<h3>Description</h3>

<p>Returns the values of the Bell series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bell(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bell_+3A_n">n</code></td>
<td>

<p>Vector of non-negative integers.
Values greater than 218 return an <code>Inf</code>.
Non-integers or negative values return a <code>NaN</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bell numbers emerge from a series expansion of
<code class="reqn"> \exp(e^x - 1)</code>
for real <code class="reqn">x</code>.
The first few values are
<code class="reqn">B_{0}=1</code>,
<code class="reqn">B_{1}=1</code>,
<code class="reqn">B_{2}=2</code>,
<code class="reqn">B_{3}=5</code>,
<code class="reqn">B_{4}=15</code>.
The series increases quickly so that overflow occurs when
its argument is more than 218.
</p>


<h3>Value</h3>

<p>This function returns
<code class="reqn">B_{n}</code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee
</p>


<h3>References</h3>

<p>Bell, E. T. (1934).
Exponential polynomials.
<em>Ann. Math.</em>,
<b>35</b>, 258&ndash;277.
</p>
<p>Bell, E. T. (1934).
Exponential numbers.
<em>Amer. Math. Monthly</em>,
<b>41</b>, 411&ndash;419.
</p>


<h3>See Also</h3>

<p><code><a href="VGAMdata.html#topic+bellff">bellff</a></code>,
<code><a href="VGAMdata.html#topic+rbell">rbell</a></code>.

</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
plot(0:10, bell(0:10), log = "y", type = "h", col = "blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='Benford'> Benford's Distribution </h2><span id='topic+Benford'></span><span id='topic+dbenf'></span><span id='topic+pbenf'></span><span id='topic+qbenf'></span><span id='topic+rbenf'></span>

<h3>Description</h3>

<p>Density, distribution function,
quantile function,
and random generation
for Benford's distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbenf(x, ndigits = 1, log = FALSE)
pbenf(q, ndigits = 1, lower.tail = TRUE, log.p = FALSE)
qbenf(p, ndigits = 1, lower.tail = TRUE, log.p = FALSE)
rbenf(n, ndigits = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Benford_+3A_x">x</code>, <code id="Benford_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
See <code>ndigits</code>.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Benford_+3A_n">n</code></td>
<td>
<p>number of observations. A single positive integer.
Else if <code>length(n) &gt; 1</code> then the length is
taken to be the number required.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_ndigits">ndigits</code></td>
<td>

<p>Number of leading digits, either 1 or 2.
If 1 then the support of the distribution is {1,...,9},
else {10,...,99}.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_log">log</code>, <code id="Benford_+3A_log.p">log.p</code></td>
<td>

<p>Logical.
If <code>log.p = TRUE</code> then all probabilities <code>p</code> are
given as <code>log(p)</code>.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Benford's Law (aka <em>the significant-digit law</em>) is the
empirical observation that in many naturally occuring tables of
numerical data, the leading significant (nonzero) digit
is not uniformly distributed in <code class="reqn">\{1,2,\ldots,9\}</code>.
Instead, the leading significant digit (<code class="reqn">=D</code>, say)
obeys the law
</p>
<p style="text-align: center;"><code class="reqn">P(D=d) = \log_{10} \left( 1 + \frac1d \right)</code>
</p>

<p>for <code class="reqn">d=1,\ldots,9</code>.
This means
the probability the first significant digit is 1 is
approximately <code class="reqn">0.301</code>, etc.
</p>
<p>Benford's Law was apparently first discovered in 1881
by astronomer/mathematician
S. Newcombe. It started by the observation
that the pages of a book of logarithms were dirtiest at the
beginning and progressively cleaner throughout.
In 1938, a General Electric physicist called F. Benford
rediscovered the law on this same observation. Over
several years he collected data from different sources
as different as atomic weights, baseball statistics,
numerical data from <em>Reader's Digest</em>,
and drainage areas of rivers.
</p>
<p>Applications of Benford's Law has been as diverse as
to the area of
fraud detection in accounting and the design computers.
</p>
<p>Benford's distribution has been called
&ldquo;a&rdquo; logarithmic distribution;
see <code><a href="#topic+logff">logff</a></code>.
</p>


<h3>Value</h3>

<p><code>dbenf</code> gives the density,
<code>pbenf</code> gives the distribution function, and
<code>qbenf</code> gives the quantile function, and
<code>rbenf</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Benford, F. (1938).
The Law of Anomalous Numbers.
<em>Proceedings of the American Philosophical Society</em>,
<b>78</b>, 551&ndash;572.
</p>
<p>Newcomb, S. (1881).
Note on the Frequency of Use of the Different Digits in Natural
Numbers.
<em>American Journal of Mathematics</em>,
<b>4</b>, 39&ndash;40.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dbenf(x &lt;- c(0:10, NA, NaN, -Inf, Inf))
pbenf(x)

## Not run: 
xx &lt;- 1:9
barplot(dbenf(xx), col = "lightblue", xlab = "Leading digit",
        ylab = "Probability", names.arg = as.character(xx),
        main = "Benford's distribution", las = 1)

hist(rbenf(1000), border = "blue", prob = TRUE,
     main = "1000 random variates from Benford's distribution",
     xlab = "Leading digit", sub="Red is the true probability",
     breaks = 0:9 + 0.5, ylim = c(0, 0.35), xlim = c(0, 10.0))
lines(xx, dbenf(xx), col = "red", type = "h")
points(xx, dbenf(xx), col = "red")

## End(Not run)
</code></pre>

<hr>
<h2 id='Benini'>The Benini Distribution</h2><span id='topic+Benini'></span><span id='topic+dbenini'></span><span id='topic+pbenini'></span><span id='topic+qbenini'></span><span id='topic+rbenini'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and
random generation for the Benini distribution with parameter
<code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbenini(x, y0, shape, log = FALSE)
pbenini(q, y0, shape, lower.tail = TRUE, log.p = FALSE)
qbenini(p, y0, shape, lower.tail = TRUE, log.p = FALSE)
rbenini(n, y0, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Benini_+3A_x">x</code>, <code id="Benini_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Benini_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Benini_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Benini_+3A_y0">y0</code></td>
<td>
<p>the scale parameter <code class="reqn">y_0</code>.
</p>
</td></tr>
<tr><td><code id="Benini_+3A_shape">shape</code></td>
<td>
<p>the positive shape parameter <code class="reqn">b</code>.
</p>
</td></tr>
<tr><td><code id="Benini_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Benini_+3A_lower.tail">lower.tail</code>, <code id="Benini_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+benini1">benini1</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter <code class="reqn">s</code> by maximum likelihood
estimation, for the formula of the probability density function
and other details.
</p>


<h3>Value</h3>

<p><code>dbenini</code> gives the density,
<code>pbenini</code> gives the distribution function,
<code>qbenini</code> gives the quantile function, and
<code>rbenini</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+benini1">benini1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
y0 &lt;- 1; shape &lt;- exp(1)
xx &lt;- seq(0.0, 4, len = 101)
plot(xx, dbenini(xx, y0 = y0, shape = shape), col = "blue",
     main = "Blue is density, orange is the CDF", type = "l",
     sub = "Purple lines are the 10,20,...,90 percentiles",
     ylim = 0:1, las = 1, ylab = "", xlab = "x")
abline(h = 0, col = "blue", lty = 2)
lines(xx, pbenini(xx, y0 = y0, shape = shape), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qbenini(probs, y0 = y0, shape = shape)
lines(Q, dbenini(Q, y0 = y0, shape = shape),
      col = "purple", lty = 3, type = "h")
pbenini(Q, y0 = y0, shape = shape) - probs  # Should be all zero

## End(Not run)
</code></pre>

<hr>
<h2 id='benini1'>Benini Distribution Family Function </h2><span id='topic+benini1'></span>

<h3>Description</h3>

<p>Estimating the 1-parameter Benini distribution by maximum
likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>benini1(y0 = stop("argument 'y0' must be specified"),
        lshape = "loglink", ishape = NULL, imethod = 1,
        zero = NULL, parallel = FALSE,
        type.fitted = c("percentiles", "Qlink"),
        percentiles = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="benini1_+3A_y0">y0</code></td>
<td>

<p>Positive scale parameter.
</p>
</td></tr>
<tr><td><code id="benini1_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function and extra argument of the parameter
<code class="reqn">b</code>, which is the shape parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
A log link is the default because <code class="reqn">b</code> is positive.
</p>
</td></tr>
<tr><td><code id="benini1_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial value for the shape parameter.
The default is to compute the value internally.
</p>
</td></tr>
<tr><td><code id="benini1_+3A_imethod">imethod</code>, <code id="benini1_+3A_zero">zero</code>, <code id="benini1_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="benini1_+3A_type.fitted">type.fitted</code>, <code id="benini1_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Using <code>"Qlink"</code> is for quantile-links in <span class="pkg">VGAMextra</span>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Benini distribution
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = 2 s \exp(-s[(\log(y/y_0))^2]) \log(y/y_0) / y </code>
</p>

<p>for <code class="reqn">0 &lt; y_0 &lt; y</code>, and shape <code class="reqn">s &gt; 0</code>.
The cumulative distribution function for <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">F(y) = 1 - \exp(-s[(\log(y/y_0))^2]).</code>
</p>

<p>Here, Newton-Raphson and Fisher scoring coincide.
The median of <code class="reqn">Y</code> is now returned as the fitted values,
by default.
This <span class="pkg">VGAM</span> family function can handle a multiple
responses, which is inputted as a matrix.
</p>
<p>On fitting, the <code>extra</code> slot has a component called
<code>y0</code> which contains the value of the <code>y0</code>
argument.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Yet to do: the 2-parameter Benini distribution estimates another
shape parameter <code class="reqn">a</code> too.  Hence, the code may change in
the future.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+Benini">Benini</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y0 &lt;- 1; nn &lt;- 3000
bdata &lt;- data.frame(y  = rbenini(nn, y0 = y0, shape = exp(2)))
fit &lt;- vglm(y ~ 1, benini1(y0 = y0), data = bdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
fit@extra$y0
c(head(fitted(fit), 1), with(bdata, median(y)))  # Should be equal
</code></pre>

<hr>
<h2 id='Betabinom'>The Beta-Binomial Distribution</h2><span id='topic+Betabinom'></span><span id='topic+dbetabinom'></span><span id='topic+pbetabinom'></span><span id='topic+rbetabinom'></span><span id='topic+dbetabinom.ab'></span><span id='topic+pbetabinom.ab'></span><span id='topic+rbetabinom.ab'></span><span id='topic+dzoibetabinom'></span><span id='topic+pzoibetabinom'></span><span id='topic+rzoibetabinom'></span><span id='topic+dzoibetabinom.ab'></span><span id='topic+pzoibetabinom.ab'></span><span id='topic+rzoibetabinom.ab'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the beta-binomial distribution
and the inflated beta-binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbetabinom(x, size, prob, rho = 0, log = FALSE)
pbetabinom(q, size, prob, rho = 0, log.p = FALSE)
rbetabinom(n, size, prob, rho = 0)
dbetabinom.ab(x, size, shape1, shape2, log = FALSE,
              Inf.shape = exp(20), limit.prob = 0.5)
pbetabinom.ab(q, size, shape1, shape2, limit.prob = 0.5,
              log.p = FALSE)
rbetabinom.ab(n, size, shape1, shape2, limit.prob = 0.5,
              .dontuse.prob = NULL)
dzoibetabinom(x, size, prob, rho = 0, pstr0 = 0, pstrsize = 0,
              log = FALSE)
pzoibetabinom(q, size, prob, rho, pstr0 = 0, pstrsize = 0,
              lower.tail = TRUE, log.p = FALSE)
rzoibetabinom(n, size, prob, rho = 0, pstr0 = 0, pstrsize = 0)
dzoibetabinom.ab(x, size, shape1, shape2, pstr0 = 0, pstrsize = 0,
                 log = FALSE)
pzoibetabinom.ab(q, size, shape1, shape2, pstr0 = 0, pstrsize = 0,
              lower.tail = TRUE, log.p = FALSE)
rzoibetabinom.ab(n, size, shape1, shape2, pstr0 = 0, pstrsize = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Betabinom_+3A_x">x</code>, <code id="Betabinom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>

<tr><td><code id="Betabinom_+3A_size">size</code></td>
<td>
<p>number of trials.</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_prob">prob</code></td>
<td>

<p>the probability of success <code class="reqn">\mu</code>.
Must be in the unit closed interval <code class="reqn">[0,1]</code>.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_rho">rho</code></td>
<td>

<p>the correlation parameter <code class="reqn">\rho</code>, which
should be in the interval <code class="reqn">[0, 1)</code>.
The default value of 0 corresponds to the
usual binomial distribution with probability <code>prob</code>.
Setting <code>rho = 1</code> would set both shape parameters equal
to 0, and the ratio <code>0/0</code>, which is actually <code>NaN</code>,
is interpreted by <code><a href="stats.html#topic+Beta">Beta</a></code> as 0.5.  See the
warning below.
</p>


</td></tr>
<tr><td><code id="Betabinom_+3A_shape1">shape1</code>, <code id="Betabinom_+3A_shape2">shape2</code></td>
<td>

<p>the two (positive) shape parameters of the standard
beta distribution. They are called <code>a</code> and <code>b</code> in
<code><a href="base.html#topic+Special">beta</a></code> respectively.
Note that
<code>shape1 = prob*(1-rho)/rho</code> and
<code>shape2 = (1-prob)*(1-rho)/rho</code>
is an important relationship between the parameters,
so that the shape parameters are infinite by default because
<code>rho = 0</code>; hence <code>limit.prob = prob</code> is used to
obtain the behaviour of the
usual binomial distribution.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_log">log</code>, <code id="Betabinom_+3A_log.p">log.p</code>, <code id="Betabinom_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_inf.shape">Inf.shape</code></td>
<td>

<p>Numeric. A large value such that,
if <code>shape1</code> or <code>shape2</code> exceeds this, then
special measures are taken,
e.g., calling <code><a href="stats.html#topic+dbinom">dbinom</a></code>.
Also, if <code>shape1</code> or <code>shape2</code> is less than
its reciprocal, then special measures are also taken.
This feature/approximation is needed to avoid numerical
problem with catastrophic cancellation of multiple
<code><a href="base.html#topic+Special">lbeta</a></code> calls.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_limit.prob">limit.prob</code></td>
<td>

<p>Numerical vector; recycled if necessary.
If either shape parameters are <code>Inf</code> then the binomial
limit is
taken, with <code>shape1 / (shape1 + shape2)</code> as the
probability of success.
In the case where both are <code>Inf</code> this probability
will be a <code>NaN = Inf/Inf</code>, however,
the value <code>limit.prob</code> is used instead.
Hence the default
for <code>dbetabinom.ab()</code>
is to assume that
both shape parameters are equal as the limit is taken
(indeed, <code><a href="stats.html#topic+Beta">Beta</a></code> uses 0.5).
Note that
for <code>[dpr]betabinom()</code>,
because <code>rho = 0</code> by default, then
<code>limit.prob = prob</code> so that the beta-binomial distribution
behaves like the ordinary binomial distribution with respect
to arguments <code>size</code> and <code>prob</code>.
</p>




</td></tr>
<tr><td><code id="Betabinom_+3A_.dontuse.prob">.dontuse.prob</code></td>
<td>

<p>An argument that should be ignored and <em>not</em> used.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_pstr0">pstr0</code></td>
<td>

<p>Probability of a structual zero
(i.e., ignoring the beta-binomial distribution).
The default value of <code>pstr0</code> corresponds to the response
having a beta-binomial distribuion inflated only at <code>size</code>.
</p>
</td></tr>
<tr><td><code id="Betabinom_+3A_pstrsize">pstrsize</code></td>
<td>

<p>Probability of a structual maximum value <code>size</code>.
The default value of
<code>pstrsize</code> corresponds to the response having a
beta-binomial distribution inflated only at 0.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The beta-binomial distribution is a binomial distribution whose
probability of success is not a constant but it is generated
from a beta distribution with parameters <code>shape1</code> and
<code>shape2</code>.  Note that the mean of this beta distribution
is <code>mu = shape1/(shape1+shape2)</code>, which therefore is the
mean or the probability of success.
</p>
<p>See <code><a href="#topic+betabinomial">betabinomial</a></code> and <code><a href="#topic+betabinomialff">betabinomialff</a></code>,
the <span class="pkg">VGAM</span> family functions for
estimating the parameters, for the formula of the probability
density function and other details.
</p>
<p>For the inflated beta-binomial distribution, the probability mass
function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y = y) =
(1 - pstr0 - pstrsize) \times BB(y) + pstr0 \times I[y = 0] +
pstrsize \times I[y = size]</code>
</p>

<p>where <code class="reqn">BB(y)</code> is the probability mass function
of the beta-binomial distribution with the same shape parameters
(<code><a href="#topic+pbetabinom.ab">pbetabinom.ab</a></code>),
<code>pstr0</code> is the inflated probability at 0
and <code>pstrsize</code> is the inflated probability at 1.
The default values of <code>pstr0</code> and <code>pstrsize</code>
mean that these functions behave like the ordinary
<code><a href="#topic+Betabinom">Betabinom</a></code> when only the essential arguments
are inputted.
</p>


<h3>Value</h3>

<p><code>dbetabinom</code> and <code>dbetabinom.ab</code> give the density,
<code>pbetabinom</code> and <code>pbetabinom.ab</code> give the
distribution function, and
<code>rbetabinom</code> and <code>rbetabinom.ab</code> generate random
deviates.
</p>


<p><code>dzoibetabinom</code> and <code>dzoibetabinom.ab</code> give the
inflated density,
<code>pzoibetabinom</code> and <code>pzoibetabinom.ab</code> give the
inflated distribution function, and
<code>rzoibetabinom</code> and <code>rzoibetabinom.ab</code> generate
random inflated deviates.
</p>


<h3>Warning </h3>

<p>Setting <code>rho = 1</code> is not recommended,
however the code may be
modified in the future to handle this special case.
</p>


<h3>Note</h3>

<p><code>pzoibetabinom</code>, <code>pzoibetabinom.ab</code>,
<code>pbetabinom</code> and <code>pbetabinom.ab</code> can be particularly
slow.
The functions here ending in <code>.ab</code> are called from those
functions which don't.
The simple transformations
<code class="reqn">\mu=\alpha / (\alpha + \beta)</code> and
<code class="reqn">\rho=1/(1 + \alpha + \beta)</code> are
used, where <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> are the
two shape parameters.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Xiangjie Xue</p>


<h3>See Also</h3>

<p><code><a href="#topic+Extbetabinom">Extbetabinom</a></code>,
<code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+Zoabeta">Zoabeta</a></code>,
<code><a href="stats.html#topic+Beta">Beta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1); rbetabinom(10, 100, prob = 0.5)
set.seed(1);     rbinom(10, 100, prob = 0.5)  # The same as rho = 0

## Not run:  N &lt;- 9; xx &lt;- 0:N; s1 &lt;- 2; s2 &lt;- 3
dy &lt;- dbetabinom.ab(xx, size = N, shape1 = s1, shape2 = s2)
barplot(rbind(dy, dbinom(xx, size = N, prob = s1 / (s1+s2))),
        beside = TRUE, col = c("blue","green"), las = 1,
        main = paste("Beta-binomial (size=",N,", shape1=", s1,
                   ", shape2=", s2, ") (blue) vs\n",
        " Binomial(size=", N, ", prob=", s1/(s1+s2), ") (green)",
                     sep = ""),
        names.arg = as.character(xx), cex.main = 0.8)
sum(dy * xx)  # Check expected values are equal
sum(dbinom(xx, size = N, prob = s1 / (s1+s2)) * xx)
# Should be all 0:
cumsum(dy) - pbetabinom.ab(xx, N, shape1 = s1, shape2 = s2)

y &lt;- rbetabinom.ab(n = 1e4, size = N, shape1 = s1, shape2 = s2)
ty &lt;- table(y)
barplot(rbind(dy, ty / sum(ty)),
        beside = TRUE, col = c("blue", "orange"), las = 1,
        main = paste("Beta-binomial (size=", N, ", shape1=", s1,
                     ", shape2=", s2, ") (blue) vs\n",
        " Random generated beta-binomial(size=", N, ", prob=",
        s1/(s1+s2), ") (orange)", sep = ""), cex.main = 0.8,
        names.arg = as.character(xx))

N &lt;- 1e5; size &lt;- 20; pstr0 &lt;- 0.2; pstrsize &lt;- 0.2
kk &lt;- rzoibetabinom.ab(N, size, s1, s2, pstr0, pstrsize)
hist(kk, probability = TRUE, border = "blue", ylim = c(0, 0.25),
     main = "Blue/green = inflated; orange = ordinary beta-binomial",
     breaks = -0.5 : (size + 0.5))
sum(kk == 0) / N  # Proportion of 0
sum(kk == size) / N  # Proportion of size
lines(0 : size,
      dbetabinom.ab(0 : size, size, s1, s2), col = "orange")
lines(0 : size, col = "green", type = "b",
      dzoibetabinom.ab(0 : size, size, s1, s2, pstr0, pstrsize))

## End(Not run)
</code></pre>

<hr>
<h2 id='betabinomial'> Beta-binomial Distribution Family Function </h2><span id='topic+betabinomial'></span>

<h3>Description</h3>

<p>Fits a beta-binomial distribution by maximum
likelihood estimation.  The two parameters
here are the mean and correlation coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betabinomial(lmu = "logitlink", lrho = "logitlink",
   irho = NULL, imethod = 1,
   ishrinkage = 0.95, nsimEIM = NULL, zero = "rho")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betabinomial_+3A_lmu">lmu</code>, <code id="betabinomial_+3A_lrho">lrho</code></td>
<td>

<p>Link functions applied to the two parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The defaults ensure the parameters remain
in <code class="reqn">(0,1)</code>,
however, see the warning below.
For <code>lrho</code>,
<code><a href="#topic+log1plink">log1plink</a></code>
(with an offset <code>log(size - 1)</code>
for <code class="reqn">\eta_2</code>)
and <code><a href="#topic+cloglink">cloglink</a></code> may be very
good choices.
</p>
</td></tr>
<tr><td><code id="betabinomial_+3A_irho">irho</code></td>
<td>

<p>Optional initial value for the correlation parameter.  If given,
it must be in <code class="reqn">(0,1)</code>, and is recyled to the necessary
length. Assign this argument a value if a convergence failure
occurs.  Having <code>irho = NULL</code> means an initial value is
obtained internally, though this can give unsatisfactory results.
</p>
</td></tr>
<tr><td><code id="betabinomial_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> or ...,
which specifies the initialization method for <code class="reqn">\mu</code>.
If failure to converge occurs try the another value
and/or else specify a value for <code>irho</code>.
</p>
</td></tr>
<tr><td><code id="betabinomial_+3A_zero">zero</code></td>
<td>

<p>Specifyies which
linear/additive predictor is to be modelled as an intercept
only.  If assigned, the single value can be either <code>1</code> or
<code>2</code>.  The default is to have a single correlation parameter.
To model both parameters as functions of the covariates assign
<code>zero = NULL</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for more information.
</p>
</td></tr>
<tr><td><code id="betabinomial_+3A_ishrinkage">ishrinkage</code>, <code id="betabinomial_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The argument <code>ishrinkage</code> is used only if <code>imethod
  = 2</code>.  Using the argument <code>nsimEIM</code> may offer large
advantages for large values of <code class="reqn">N</code> and/or large data sets.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several parameterizations of the beta-binomial
distribution.  This family function directly models the mean
and correlation parameter, i.e.,
the probability of success.
The model can be written
<code class="reqn">T|P=p \sim Binomial(N,p)</code>
where <code class="reqn">P</code> has a beta distribution with shape parameters
<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>. Here,
<code class="reqn">N</code> is the number of trials (e.g., litter size),
<code class="reqn">T=NY</code> is the number of successes, and
<code class="reqn">p</code> is the probability of a success (e.g., a malformation).
That is, <code class="reqn">Y</code> is the <em>proportion</em> of successes. Like
<code><a href="#topic+binomialff">binomialff</a></code>, the fitted values are the
estimated probability
of success (i.e., <code class="reqn">E[Y]</code> and not <code class="reqn">E[T]</code>)
and the prior weights <code class="reqn">N</code> are attached separately on the
object in a slot.
</p>
<p>The probability function is
</p>
<p style="text-align: center;"><code class="reqn">P(T=t) = {N \choose t} \frac{Be(\alpha+t, \beta+N-t)}
                  {Be(\alpha, \beta)}</code>
</p>

<p>where <code class="reqn">t=0,1,\ldots,N</code>, and <code class="reqn">Be</code> is the
<code><a href="base.html#topic+Special">beta</a></code> function
with shape parameters <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>.
Recall <code class="reqn">Y = T/N</code> is the real response being modelled.
</p>
<p>The default model is <code class="reqn">\eta_1 = logit(\mu)</code>
and <code class="reqn">\eta_2 = logit(\rho)</code> because both
parameters lie between 0 and 1.
The mean (of <code class="reqn">Y</code>) is
<code class="reqn">p=\mu=\alpha/(\alpha+\beta)</code>
and the variance (of <code class="reqn">Y</code>) is
<code class="reqn">\mu(1-\mu)(1+(N-1)\rho)/N</code>.
Here, the correlation <code class="reqn">\rho</code> is given by
<code class="reqn">1/(1 + \alpha + \beta)</code>
and is the correlation between the <code class="reqn">N</code> individuals
within a litter. A <em>litter effect</em> is typically reflected
by a positive value of <code class="reqn">\rho</code>. It is known as the
<em>over-dispersion parameter</em>.
</p>
<p>This family function uses Fisher scoring.
Elements of the second-order expected
derivatives with respect to <code class="reqn">\alpha</code> and
<code class="reqn">\beta</code> are computed numerically, which may
fail for large <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>,
<code class="reqn">N</code> or else take a long time.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>.
</p>
<p>Suppose <code>fit</code> is a fitted beta-binomial
model. Then <code>depvar(fit)</code>
are the sample proportions <code class="reqn">y</code>,
<code>fitted(fit)</code> returns estimates of
<code class="reqn">E(Y)</code>,
and <code>weights(fit, type = "prior")</code> returns
the number of trials <code class="reqn">N</code>.
</p>


<h3>Warning </h3>

<p>If the estimated rho parameter is close
to 0 then
a good solution is to use
<code><a href="#topic+extbetabinomial">extbetabinomial</a></code>.
Or you could try
<code>lrho = "rhobitlink"</code>.
</p>


<p>This family function is prone to numerical
difficulties due to the expected information
matrices not being positive-definite or
ill-conditioned over some regions of the
parameter space.  If problems occur try
setting <code>irho</code> to some numerical
value, <code>nsimEIM = 100</code>, say, or
else use <code>etastart</code> argument of
<code><a href="#topic+vglm">vglm</a></code>, etc.
</p>


<h3>Note</h3>

<p>This function processes the input in the same way
as <code><a href="#topic+binomialff">binomialff</a></code>. But it does not handle
the case <code class="reqn">N=1</code> very well because there are two
parameters to estimate, not one, for each row of the input.
Cases where <code class="reqn">N=1</code> can be omitted via the
<code>subset</code> argument of <code><a href="#topic+vglm">vglm</a></code>.
</p>
<p>The <em>extended</em> beta-binomial distribution
of Prentice (1986) 
implemented by <code><a href="#topic+extbetabinomial">extbetabinomial</a></code>
is the preferred <span class="pkg">VGAM</span>
family function for BBD regression.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Moore, D. F. and Tsiatis, A. (1991).
Robust estimation of the variance in moment
methods for
extra-binomial and extra-Poisson variation.
<em>Biometrics</em>,
<b>47</b>, 383&ndash;401.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extbetabinomial">extbetabinomial</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+Betabinom">Betabinom</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+dirmultinomial">dirmultinomial</a></code>,
<code><a href="#topic+log1plink">log1plink</a></code>,
<code><a href="#topic+cloglink">cloglink</a></code>,
<code><a href="#topic+lirat">lirat</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
bdata &lt;- data.frame(N = 10, mu = 0.5, rho = 0.8)
bdata &lt;- transform(bdata,
            y = rbetabinom(100, size = N, prob = mu, rho = rho))
fit &lt;- vglm(cbind(y, N-y) ~ 1, betabinomial, bdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
head(cbind(depvar(fit), weights(fit, type = "prior")))


# Example 2
fit &lt;- vglm(cbind(R, N-R) ~ 1, betabinomial, lirat,
            trace = TRUE, subset = N &gt; 1)
coef(fit, matrix = TRUE)
Coef(fit)
t(fitted(fit))
t(depvar(fit))
t(weights(fit, type = "prior"))


# Example 3, which is more complicated
lirat &lt;- transform(lirat, fgrp = factor(grp))
summary(lirat)  # Only 5 litters in group 3
fit2 &lt;- vglm(cbind(R, N-R) ~ fgrp + hb, betabinomial(zero = 2),
             data = lirat, trace = TRUE, subset = N &gt; 1)
coef(fit2, matrix = TRUE)
## Not run:  with(lirat, plot(hb[N &gt; 1], fit2@misc$rho,
         xlab = "Hemoglobin", ylab = "Estimated rho",
         pch = as.character(grp[N &gt; 1]), col = grp[N &gt; 1])) 
## End(Not run)
## Not run:   # cf. Figure 3 of Moore and Tsiatis (1991)
with(lirat, plot(hb, R / N, pch = as.character(grp), col = grp,
         xlab = "Hemoglobin level", ylab = "Proportion Dead",
         main = "Fitted values (lines)", las = 1))
smalldf &lt;- with(lirat, lirat[N &gt; 1, ])
for (gp in 1:4) {
  xx &lt;- with(smalldf, hb[grp == gp])
  yy &lt;- with(smalldf, fitted(fit2)[grp == gp])
  ooo &lt;- order(xx)
  lines(xx[ooo], yy[ooo], col = gp, lwd = 2)
} 
## End(Not run)
</code></pre>

<hr>
<h2 id='betabinomialff'> Beta-binomial Distribution Family Function </h2><span id='topic+betabinomialff'></span>

<h3>Description</h3>

<p>Fits a beta-binomial distribution by maximum likelihood
estimation.  The two parameters here are the shape parameters
of the underlying beta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betabinomialff(lshape1 = "loglink", lshape2 = "loglink",
   ishape1 = 1, ishape2 = NULL, imethod = 1, ishrinkage = 0.95,
   nsimEIM = NULL, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betabinomialff_+3A_lshape1">lshape1</code>, <code id="betabinomialff_+3A_lshape2">lshape2</code></td>
<td>

<p>Link functions for the two (positive) shape parameters
of the beta distribution.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="betabinomialff_+3A_ishape1">ishape1</code>, <code id="betabinomialff_+3A_ishape2">ishape2</code></td>
<td>

<p>Initial value for the shape parameters.
The first must be positive, and is recyled to the necessary
length.  The second is optional.  If a failure to converge
occurs, try assigning a different value to <code>ishape1</code>
and/or using <code>ishape2</code>.
</p>
</td></tr>
<tr><td><code id="betabinomialff_+3A_zero">zero</code></td>
<td>

<p>Can be
an integer specifying which linear/additive predictor
is to be modelled as an intercept only. If assigned, the
single value should be either <code>1</code> or <code>2</code>. The
default is to model both shape parameters as functions of the
covariates. If a failure to converge occurs, try <code>zero = 2</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="betabinomialff_+3A_ishrinkage">ishrinkage</code>, <code id="betabinomialff_+3A_nsimeim">nsimEIM</code>, <code id="betabinomialff_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The argument <code>ishrinkage</code> is used only if <code>imethod
  = 2</code>.  Using the argument <code>nsimEIM</code> may offer large
advantages for large values of <code class="reqn">N</code> and/or large data sets.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several parameterizations of the beta-binomial
distribution.  This family function directly models the two
shape parameters of the associated beta distribution rather than
the probability of success (however, see <b>Note</b> below).
The model can be written
<code class="reqn">T|P=p \sim Binomial(N,p)</code>
where <code class="reqn">P</code> has a beta distribution with shape parameters
<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>. Here,
<code class="reqn">N</code> is the number of trials (e.g., litter size),
<code class="reqn">T=NY</code> is the number of successes, and
<code class="reqn">p</code> is the probability of a success (e.g., a malformation).
That is, <code class="reqn">Y</code> is the <em>proportion</em> of successes. Like
<code><a href="#topic+binomialff">binomialff</a></code>, the fitted values are the
estimated probability
of success (i.e., <code class="reqn">E[Y]</code> and not <code class="reqn">E[T]</code>)
and the prior weights <code class="reqn">N</code> are attached separately on the
object in a slot.
</p>
<p>The probability function is
</p>
<p style="text-align: center;"><code class="reqn">P(T=t) = {N \choose t} \frac{B(\alpha+t, \beta+N-t)}
                  {B(\alpha, \beta)}</code>
</p>

<p>where <code class="reqn">t=0,1,\ldots,N</code>, and <code class="reqn">B</code> is the beta function
with shape parameters <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>.
Recall <code class="reqn">Y = T/N</code> is the real response being modelled.
</p>
<p>The default model
is <code class="reqn">\eta_1 = \log(\alpha)</code>
and <code class="reqn">\eta_2 = \log(\beta)</code> because both
parameters are positive.
The mean (of <code class="reqn">Y</code>) is
<code class="reqn">p=\mu=\alpha/(\alpha+\beta)</code>
and the variance (of <code class="reqn">Y</code>) is
<code class="reqn">\mu(1-\mu)(1+(N-1)\rho)/N</code>.
Here, the correlation <code class="reqn">\rho</code> is given by
<code class="reqn">1/(1 + \alpha + \beta)</code>
and is the correlation between the <code class="reqn">N</code> individuals
within a litter. A <em>litter effect</em> is typically reflected
by a positive value of <code class="reqn">\rho</code>. It is known as the
<em>over-dispersion parameter</em>.
</p>
<p>This family function uses Fisher scoring. The two diagonal
elements of the second-order expected
derivatives with respect to <code class="reqn">\alpha</code> and
<code class="reqn">\beta</code> are computed numerically, which may
fail for large <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>,
<code class="reqn">N</code> or else take a long time.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>.
</p>
<p>Suppose <code>fit</code> is a fitted beta-binomial model. Then
<code>fit@y</code> (better: <code>depvar(fit)</code>) contains the sample
proportions <code class="reqn">y</code>, <code>fitted(fit)</code> returns estimates of
<code class="reqn">E(Y)</code>, and <code>weights(fit, type = "prior")</code> returns
the number of trials <code class="reqn">N</code>.
</p>


<h3>Warning </h3>

<p>This family function is prone to numerical difficulties due to
the expected information matrices not being positive-definite
or ill-conditioned over some regions of the parameter space.
If problems occur try setting <code>ishape1</code> to be some other
positive value, using <code>ishape2</code> and/or setting <code>zero
  = 2</code>.
</p>
<p>This family function may be renamed in the future.
See the warnings in <code><a href="#topic+betabinomial">betabinomial</a></code>.
</p>


<h3>Note</h3>

<p>This function processes the input in the same way
as <code><a href="#topic+binomialff">binomialff</a></code>. But it does not handle
the case <code class="reqn">N=1</code> very well because there are two
parameters to estimate, not one, for each row of the input.
Cases where <code class="reqn">N=1</code> can be omitted via the
<code>subset</code> argument of <code><a href="#topic+vglm">vglm</a></code>.
</p>
<p>Although the two linear/additive predictors given above are
in terms of <code class="reqn">\alpha</code> and <code class="reqn">\beta</code>, basic
algebra shows that the default amounts to fitting a logit
link to the probability of success; subtracting the second
linear/additive predictor from the first gives that logistic
regression linear/additive predictor.  That is, <code class="reqn">logit(p)
  = \eta_1 - \eta_2</code>.  This is illustated
in one of the examples below.
</p>
<p>The <em>extended</em> beta-binomial distribution
of Prentice (1986) 
implemented by <code><a href="#topic+extbetabinomial">extbetabinomial</a></code>
is the preferred <span class="pkg">VGAM</span>
family function for BBD regression.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Moore, D. F. and Tsiatis, A. (1991).
Robust estimation of the variance in moment methods for
extra-binomial and extra-Poisson variation.
<em>Biometrics</em>,
<b>47</b>, 383&ndash;401.
</p>
<p>Prentice, R. L. (1986).
Binary regression using an extended beta-binomial distribution,
with discussion of correlation induced by
covariate measurement errors.
<em>Journal of the American Statistical Association</em>,
<b>81</b>, 321&ndash;327.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extbetabinomial">extbetabinomial</a></code>,
<code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+Betabinom">Betabinom</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+dirmultinomial">dirmultinomial</a></code>,
<code><a href="#topic+lirat">lirat</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
N &lt;- 10; s1 &lt;- exp(1); s2 &lt;- exp(2)
y &lt;- rbetabinom.ab(n = 100, size = N, shape1 = s1, shape2 = s2)
fit &lt;- vglm(cbind(y, N-y) ~ 1, betabinomialff, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
head(fit@misc$rho)  # The correlation parameter
head(cbind(depvar(fit), weights(fit, type = "prior")))


# Example 2
fit &lt;- vglm(cbind(R, N-R) ~ 1, betabinomialff, data = lirat,
            trace = TRUE, subset = N &gt; 1)
coef(fit, matrix = TRUE)
Coef(fit)
fit@misc$rho  # The correlation parameter
t(fitted(fit))
t(depvar(fit))
t(weights(fit, type = "prior"))
# A "loglink" link for the 2 shape params is a logistic regression:
all.equal(c(fitted(fit)),
          as.vector(logitlink(predict(fit)[, 1] -
                          predict(fit)[, 2], inverse = TRUE)))


# Example 3, which is more complicated
lirat &lt;- transform(lirat, fgrp = factor(grp))
summary(lirat)  # Only 5 litters in group 3
fit2 &lt;- vglm(cbind(R, N-R) ~ fgrp + hb, betabinomialff(zero = 2),
           data = lirat, trace = TRUE, subset = N &gt; 1)
coef(fit2, matrix = TRUE)
coef(fit2, matrix = TRUE)[, 1] -
coef(fit2, matrix = TRUE)[, 2]  # logitlink(p)
## Not run:  with(lirat, plot(hb[N &gt; 1], fit2@misc$rho,
   xlab = "Hemoglobin", ylab = "Estimated rho",
   pch = as.character(grp[N &gt; 1]), col = grp[N &gt; 1])) 
## End(Not run)
## Not run:   # cf. Figure 3 of Moore and Tsiatis (1991)
with(lirat, plot(hb, R / N, pch = as.character(grp), col = grp,
   xlab = "Hemoglobin level", ylab = "Proportion Dead", las = 1,
   main = "Fitted values (lines)"))

smalldf &lt;- with(lirat, lirat[N &gt; 1, ])
for (gp in 1:4) {
  xx &lt;- with(smalldf, hb[grp == gp])
  yy &lt;- with(smalldf, fitted(fit2)[grp == gp])
  ooo &lt;- order(xx)
  lines(xx[ooo], yy[ooo], col = gp, lwd = 2)
} 
## End(Not run)
</code></pre>

<hr>
<h2 id='betaff'> The Two-parameter Beta Distribution Family Function </h2><span id='topic+betaff'></span>

<h3>Description</h3>

<p>Estimation of the mean and precision parameters of the beta
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaff(A = 0, B = 1, lmu = "logitlink", lphi = "loglink",
       imu = NULL, iphi = NULL,
       gprobs.y = ppoints(8), gphi  = exp(-3:5)/4, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betaff_+3A_a">A</code>, <code id="betaff_+3A_b">B</code></td>
<td>

<p>Lower and upper limits of the distribution.
The defaults correspond to the <em>standard beta distribution</em>
where the response lies between 0 and 1.
</p>
</td></tr>
<tr><td><code id="betaff_+3A_lmu">lmu</code>, <code id="betaff_+3A_lphi">lphi</code></td>
<td>

<p>Link function for the mean and precision parameters.
The values <code class="reqn">A</code> and <code class="reqn">B</code> are extracted from the
<code>min</code> and <code>max</code> arguments
of <code><a href="#topic+extlogitlink">extlogitlink</a></code>.
Consequently, only <code><a href="#topic+extlogitlink">extlogitlink</a></code> is allowed.
</p>


</td></tr>
<tr><td><code id="betaff_+3A_imu">imu</code>, <code id="betaff_+3A_iphi">iphi</code></td>
<td>

<p>Optional initial value for the mean and precision parameters
respectively. A <code>NULL</code> value means a value is obtained in
the <code>initialize</code> slot.
</p>
</td></tr>
<tr><td><code id="betaff_+3A_gprobs.y">gprobs.y</code>, <code id="betaff_+3A_gphi">gphi</code>, <code id="betaff_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two-parameter beta distribution can be written
<code class="reqn">f(y) =</code>
</p>
<p style="text-align: center;"><code class="reqn">(y-A)^{\mu_1 \phi-1} \times
    (B-y)^{(1-\mu_1) \phi-1} / [beta(\mu_1
      \phi,(1-\mu_1) \phi) \times (B-A)^{\phi-1}]</code>
</p>

<p>for <code class="reqn">A &lt; y &lt; B</code>, and <code class="reqn">beta(.,.)</code> is the beta function
(see <code><a href="base.html#topic+Special">beta</a></code>).
The parameter <code class="reqn">\mu_1</code> satisfies
<code class="reqn">\mu_1 = (\mu - A) / (B-A)</code>
where <code class="reqn">\mu</code> is the mean of <code class="reqn">Y</code>.
That is, <code class="reqn">\mu_1</code> is the mean of of a
standard beta distribution:
<code class="reqn">E(Y) = A + (B-A) \times \mu_1</code>,
and these are the fitted values of the object.
Also, <code class="reqn">\phi</code> is positive
and <code class="reqn">A &lt; \mu &lt; B</code>.
Here, the limits <code class="reqn">A</code> and <code class="reqn">B</code> are <em>known</em>.
</p>
<p>Another parameterization of the beta distribution
involving the raw
shape parameters is implemented in <code><a href="#topic+betaR">betaR</a></code>.
</p>
<p>For general <code class="reqn">A</code> and <code class="reqn">B</code>, the variance of <code class="reqn">Y</code> is
<code class="reqn">(B-A)^2 \times \mu_1 \times (1-\mu_1) / (1+\phi)</code>.
Then <code class="reqn">\phi</code> can be interpreted as
a <em>precision</em> parameter
in the sense that, for fixed <code class="reqn">\mu</code>,
the larger the value of
<code class="reqn">\phi</code>, the smaller the variance of <code class="reqn">Y</code>.
Also, <code class="reqn">\mu_1
  = shape1/(shape1+shape2)</code> and
<code class="reqn">\phi = shape1+shape2</code>.
Fisher scoring is implemented.
</p>





<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must have values in the
interval (<code class="reqn">A</code>, <code class="reqn">B</code>).
The user currently needs to manually choose <code>lmu</code> to
match the input of arguments <code>A</code> and <code>B</code>, e.g.,
with <code><a href="#topic+extlogitlink">extlogitlink</a></code>; see the example below.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Ferrari, S. L. P. and Francisco C.-N. (2004).
Beta regression for modelling rates and proportions.
<em>Journal of Applied Statistics</em>,
<b>31</b>, 799&ndash;815.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+betaR">betaR</a></code>,

<code><a href="stats.html#topic+Beta">Beta</a></code>,
<code><a href="#topic+dzoabeta">dzoabeta</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+betageometric">betageometric</a></code>,
<code><a href="#topic+betaprime">betaprime</a></code>,
<code><a href="#topic+rbetageom">rbetageom</a></code>,
<code><a href="#topic+rbetanorm">rbetanorm</a></code>,
<code><a href="#topic+kumar">kumar</a></code>,
<code><a href="#topic+extlogitlink">extlogitlink</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bdata &lt;- data.frame(y = rbeta(nn &lt;- 1000, shape1 = exp(0),
                              shape2 = exp(1)))
fit1 &lt;- vglm(y ~ 1, betaff, data = bdata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)  # Useful for intercept-only models

# General A and B, and with a covariate
bdata &lt;- transform(bdata, x2 = runif(nn))
bdata &lt;- transform(bdata, mu = logitlink(0.5 - x2, inverse = TRUE),
                          prec = exp(3.0 + x2))  # prec == phi
bdata &lt;- transform(bdata, shape2 = prec * (1 - mu),
                          shape1 = mu * prec)
bdata &lt;- transform(bdata,
                   y = rbeta(nn, shape1 = shape1, shape2 = shape2))
bdata &lt;- transform(bdata, Y = 5 + 8 * y)  # From 5--13, not 0--1
fit &lt;- vglm(Y ~ x2, data = bdata, trace = TRUE,
   betaff(A = 5, B = 13, lmu = extlogitlink(min = 5, max = 13)))
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='Betageom'>The Beta-Geometric Distribution</h2><span id='topic+Betageom'></span><span id='topic+dbetageom'></span><span id='topic+pbetageom'></span><span id='topic+rbetageom'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the beta-geometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbetageom(x, shape1, shape2, log = FALSE)
pbetageom(q, shape1, shape2, log.p = FALSE)
rbetageom(n, shape1, shape2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Betageom_+3A_x">x</code>, <code id="Betageom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.
</p>
</td></tr>

<tr><td><code id="Betageom_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Betageom_+3A_shape1">shape1</code>, <code id="Betageom_+3A_shape2">shape2</code></td>
<td>

<p>the two (positive) shape parameters of the standard
beta distribution. They are called <code>a</code> and <code>b</code> in
<code><a href="base.html#topic+Special">beta</a></code> respectively.
</p>
</td></tr>
<tr><td><code id="Betageom_+3A_log">log</code>, <code id="Betageom_+3A_log.p">log.p</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then all probabilities <code>p</code> are given as
<code>log(p)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The beta-geometric distribution is a geometric distribution whose
probability of success is not a constant but it is generated
from a beta distribution with parameters <code>shape1</code> and
<code>shape2</code>.  Note that the mean of this beta distribution
is <code>shape1/(shape1+shape2)</code>, which therefore is the mean
of the probability of success.
</p>





<h3>Value</h3>

<p><code>dbetageom</code> gives the density,
<code>pbetageom</code> gives the distribution function, and
<code>rbetageom</code> generates random deviates.
</p>



<h3>Note</h3>

<p><code>pbetageom</code> can be particularly slow.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+geometric">geometric</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="stats.html#topic+Beta">Beta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape1 &lt;- 1; shape2 &lt;- 2; y &lt;- 0:30
proby &lt;- dbetageom(y, shape1, shape2, log = FALSE)
plot(y, proby, type = "h", col = "blue", ylab = "P[Y=y]", main = paste0(
     "Y ~ Beta-geometric(shape1=", shape1,", shape2=", shape2, ")"))
sum(proby)

## End(Not run)
</code></pre>

<hr>
<h2 id='betageometric'> Beta-geometric Distribution Family Function </h2><span id='topic+betageometric'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for the beta-geometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betageometric(lprob = "logitlink", lshape = "loglink",
    iprob = NULL,    ishape = 0.1,
    moreSummation = c(2, 100), tolerance = 1.0e-10, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betageometric_+3A_lprob">lprob</code>, <code id="betageometric_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions applied to the
parameters <code class="reqn">p</code> and <code class="reqn">\phi</code>
(called <code>prob</code> and <code>shape</code> below).
The former lies in the unit interval and the latter is positive.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="betageometric_+3A_iprob">iprob</code>, <code id="betageometric_+3A_ishape">ishape</code></td>
<td>

<p>Numeric.
Initial values for the two parameters.
A <code>NULL</code> means a value is computed internally.
</p>
</td></tr>
<tr><td><code id="betageometric_+3A_moresummation">moreSummation</code></td>
<td>

<p>Integer, of length 2.
When computing the expected information matrix a series summation
from 0 to <code>moreSummation[1]*max(y)+moreSummation[2]</code> is
made, in which the upper limit is an approximation to infinity.
Here, <code>y</code> is the response.
</p>
</td></tr>
<tr><td><code id="betageometric_+3A_tolerance">tolerance</code></td>
<td>

<p>Positive numeric.
When all terms are less than this then the series is deemed to have
converged.
</p>
</td></tr>
<tr><td><code id="betageometric_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
If used, the value must be from the set {1,2}.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A random variable <code class="reqn">Y</code> has a 2-parameter beta-geometric distribution
if <code class="reqn">P(Y=y) = p (1-p)^y</code>
for <code class="reqn">y=0,1,2,\ldots</code> where
<code class="reqn">p</code> are generated from a standard beta distribution with
shape parameters <code>shape1</code> and <code>shape2</code>.
The parameterization here is to focus on the parameters
<code class="reqn">p</code> and
<code class="reqn">\phi = 1/(shape1+shape2)</code>,
where <code class="reqn">\phi</code> is <code>shape</code>.
The default link functions for these ensure that the appropriate range
of the parameters is maintained.
The mean of <code class="reqn">Y</code> is
<code class="reqn">E(Y) = shape2 / (shape1-1) = (1-p) / (p-\phi)</code>
if <code>shape1 &gt; 1</code>, and if so, then this is returned as
the fitted values.
</p>
<p>The geometric distribution is a special case of the beta-geometric
distribution with <code class="reqn">\phi=0</code>
(see <code><a href="#topic+geometric">geometric</a></code>).
However, fitting data from a geometric distribution may result in
numerical problems because the estimate of <code class="reqn">\log(\phi)</code>
will 'converge' to <code>-Inf</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The first iteration may be very slow;
if practical, it is best for the <code>weights</code> argument of
<code><a href="#topic+vglm">vglm</a></code> etc. to be used rather than inputting a very
long vector as the response,
i.e., <code>vglm(y ~ 1, ..., weights = wts)</code>
is to be preferred over <code>vglm(rep(y, wts) ~ 1, ...)</code>.
If convergence problems occur try inputting some values of argument
<code>ishape</code>.
</p>
<p>If an intercept-only model is fitted then the <code>misc</code> slot of the
fitted object has list components <code>shape1</code> and <code>shape2</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Paul, S. R. (2005).
Testing goodness of fit of the geometric distribution:
an application to human fecundability data.
<em>Journal of Modern Applied Statistical Methods</em>,
<b>4</b>, 425&ndash;433.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+geometric">geometric</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+rbetageom">rbetageom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bdata &lt;- data.frame(y = 0:11,
                    wts = c(227,123,72,42,21,31,11,14,6,4,7,28))
fitb &lt;- vglm(y ~ 1, betageometric, bdata, weight = wts, trace = TRUE)
fitg &lt;- vglm(y ~ 1,     geometric, bdata, weight = wts, trace = TRUE)
coef(fitb, matrix = TRUE)
Coef(fitb)
sqrt(diag(vcov(fitb, untransform = TRUE)))
fitb@misc$shape1
fitb@misc$shape2
# Very strong evidence of a beta-geometric:
pchisq(2 * (logLik(fitb) - logLik(fitg)), df = 1, lower.tail = FALSE)
</code></pre>

<hr>
<h2 id='betaII'> Beta Distribution of the Second Kind </h2><span id='topic+betaII'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 3-parameter
beta II distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaII(lscale = "loglink", lshape2.p = "loglink",
       lshape3.q = "loglink", iscale = NULL, ishape2.p = NULL,
       ishape3.q = NULL, imethod = 1,
       gscale = exp(-5:5), gshape2.p = exp(-5:5),
       gshape3.q = seq(0.75, 4, by = 0.25),
       probs.y = c(0.25, 0.5, 0.75), zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betaII_+3A_lscale">lscale</code>, <code id="betaII_+3A_lshape2.p">lshape2.p</code>, <code id="betaII_+3A_lshape3.q">lshape3.q</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code>scale</code>, <code>p</code> and <code>q</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="betaII_+3A_iscale">iscale</code>, <code id="betaII_+3A_ishape2.p">ishape2.p</code>, <code id="betaII_+3A_ishape3.q">ishape3.q</code>, <code id="betaII_+3A_imethod">imethod</code>, <code id="betaII_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="betaII_+3A_gscale">gscale</code>, <code id="betaII_+3A_gshape2.p">gshape2.p</code>, <code id="betaII_+3A_gshape3.q">gshape3.q</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="betaII_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 3-parameter beta II is the 4-parameter
<em>generalized</em> beta II distribution with shape parameter <code class="reqn">a=1</code>.
It is also known as the Pearson VI distribution.
Other distributions which are special cases of the 3-parameter
beta II include the Lomax (<code class="reqn">p=1</code>) and inverse Lomax
(<code class="reqn">q=1</code>).  More details can be found in Kleiber and Kotz
(2003).
</p>
<p>The beta II distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = y^{p-1} / [b^p B(p,q) \{1 + y/b\}^{p+q}]</code>
</p>

<p>for <code class="reqn">b &gt; 0</code>, <code class="reqn">p &gt; 0</code>, <code class="reqn">q &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and the others are shape parameters.
The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(p + 1) \,
      \Gamma(q - 1) / (\Gamma(p) \, \Gamma(q))</code>
</p>

<p>provided <code class="reqn">q &gt; 1</code>; these are returned as the fitted values.
This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bdata &lt;- data.frame(y = rsinmad(2000, shape1.a = 1,
         shape3.q = exp(2), scale = exp(1)))  # Not genuine data!
# fit &lt;- vglm(y ~ 1, betaII, data = bdata, trace = TRUE)
fit &lt;- vglm(y ~ 1, betaII(ishape2.p = 0.7, ishape3.q = 0.7),
            data = bdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Betanorm'>The Beta-Normal Distribution</h2><span id='topic+Betanorm'></span><span id='topic+dbetanorm'></span><span id='topic+pbetanorm'></span><span id='topic+qbetanorm'></span><span id='topic+rbetanorm'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the univariate beta-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbetanorm(x, shape1, shape2, mean = 0, sd = 1, log = FALSE)
pbetanorm(q, shape1, shape2, mean = 0, sd = 1,
          lower.tail = TRUE, log.p = FALSE)
qbetanorm(p, shape1, shape2, mean = 0, sd = 1,
          lower.tail = TRUE, log.p = FALSE)
rbetanorm(n, shape1, shape2, mean = 0, sd = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Betanorm_+3A_x">x</code>, <code id="Betanorm_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Betanorm_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Betanorm_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Betanorm_+3A_shape1">shape1</code>, <code id="Betanorm_+3A_shape2">shape2</code></td>
<td>

<p>the two (positive) shape parameters of the standard beta
distribution.  They are called <code>a</code> and <code>b</code> respectively
in <code><a href="base.html#topic+Special">beta</a></code>.
</p>
</td></tr>
<tr><td><code id="Betanorm_+3A_mean">mean</code>, <code id="Betanorm_+3A_sd">sd</code></td>
<td>

<p>the mean and standard deviation of the univariate
normal distribution
(<code><a href="stats.html#topic+Normal">Normal</a></code>).
</p>
</td></tr>
<tr><td><code id="Betanorm_+3A_log">log</code>, <code id="Betanorm_+3A_log.p">log.p</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then all probabilities <code>p</code> are given as
<code>log(p)</code>.
</p>
</td></tr>
<tr><td><code id="Betanorm_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the upper tail is returned, i.e.,
one minus the usual answer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>betauninormal</code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
has not yet been written.
</p>



<h3>Value</h3>

<p><code>dbetanorm</code> gives the density,
<code>pbetanorm</code> gives the distribution function,
<code>qbetanorm</code> gives the quantile function, and
<code>rbetanorm</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Gupta, A. K. and Nadarajah, S. (2004).
<em>Handbook of Beta Distribution and Its Applications</em>,
pp.146&ndash;152.
New York: Marcel Dekker.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape1 &lt;- 0.1; shape2 &lt;- 4; m &lt;- 1
x &lt;- seq(-10, 2, len = 501)
plot(x, dbetanorm(x, shape1, shape2, m = m), type = "l",
     ylim = 0:1, las = 1,
     ylab = paste0("betanorm(",shape1,", ",shape2,", m=",m, ", sd=1)"),
     main = "Blue is density, orange is the CDF",
     sub = "Gray lines are the 10,20,...,90 percentiles", col = "blue")
lines(x, pbetanorm(x, shape1, shape2, m = m), col = "orange")
abline(h = 0, col = "black")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qbetanorm(probs, shape1, shape2, m = m)
lines(Q, dbetanorm(Q, shape1, shape2, m = m),
      col = "gray50", lty = 2, type = "h")
lines(Q, pbetanorm(Q, shape1, shape2, m = m),
      col = "gray50", lty = 2, type = "h")
abline(h = probs, col = "gray50", lty = 2)
pbetanorm(Q, shape1, shape2, m = m) - probs  # Should be all 0

## End(Not run)
</code></pre>

<hr>
<h2 id='betaprime'> The Beta-Prime Distribution </h2><span id='topic+betaprime'></span>

<h3>Description</h3>

<p>Estimation of the two shape parameters of the beta-prime
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaprime(lshape = "loglink", ishape1 = 2, ishape2 = NULL,
          zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betaprime_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function applied to the two (positive) shape
parameters.  See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="betaprime_+3A_ishape1">ishape1</code>, <code id="betaprime_+3A_ishape2">ishape2</code>, <code id="betaprime_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>



</td></tr>







</table>


<h3>Details</h3>

<p>The beta-prime distribution is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y) = y^{shape1-1}   (1+y)^{-shape1-shape2} / B(shape1,shape2)</code>
</p>

<p>for <code class="reqn">y &gt; 0</code>.
The shape parameters are positive, and
here, <code class="reqn">B</code> is the beta function.
The mean of <code class="reqn">Y</code> is <code class="reqn">shape1 / (shape2-1)</code> provided <code class="reqn">shape2&gt;1</code>;
these are returned as the fitted values.
</p>
<p>If <code class="reqn">Y</code> has a <code class="reqn">Beta(shape1,shape2)</code> distribution then
<code class="reqn">Y/(1-Y)</code> and <code class="reqn">(1-Y)/Y</code> have a <code class="reqn">Betaprime(shape1,shape2)</code>
and <code class="reqn">Betaprime(shape2,shape1)</code> distribution respectively.
Also, if <code class="reqn">Y_1</code> has a <code class="reqn">gamma(shape1)</code> distribution
and <code class="reqn">Y_2</code> has a <code class="reqn">gamma(shape2)</code> distribution
then <code class="reqn">Y_1/Y_2</code> has a <code class="reqn">Betaprime(shape1,shape2)</code>
distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must have positive values only.
</p>
<p>The beta-prime distribution is also known as the
<em>beta distribution of the second kind</em> or the
<em>inverted beta distribution</em>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1995).
Chapter 25 of:
<em>Continuous Univariate Distributions</em>,
2nd edition,
Volume 2,
New York: Wiley.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+betaff">betaff</a></code>,
<code><a href="stats.html#topic+Beta">Beta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
bdata &lt;- data.frame(shape1 = exp(1), shape2 = exp(3))
bdata &lt;- transform(bdata, yb = rbeta(nn, shape1, shape2))
bdata &lt;- transform(bdata, y1 = (1-yb) /    yb,
                          y2 =    yb  / (1-yb),
                          y3 = rgamma(nn, exp(3)) / rgamma(nn, exp(2)))

fit1 &lt;- vglm(y1 ~ 1, betaprime, data = bdata, trace = TRUE)
coef(fit1, matrix = TRUE)

fit2 &lt;- vglm(y2 ~ 1, betaprime, data = bdata, trace = TRUE)
coef(fit2, matrix = TRUE)

fit3 &lt;- vglm(y3 ~ 1, betaprime, data = bdata, trace = TRUE)
coef(fit3, matrix = TRUE)

# Compare the fitted values
with(bdata, mean(y3))
head(fitted(fit3))
Coef(fit3)  # Useful for intercept-only models
</code></pre>

<hr>
<h2 id='betaR'> The Two-parameter Beta Distribution Family Function </h2><span id='topic+betaR'></span>

<h3>Description</h3>

<p>Estimation of the shape parameters of the two-parameter beta
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaR(lshape1 = "loglink", lshape2 = "loglink",
      i1 = NULL, i2 = NULL, trim = 0.05,
      A = 0, B = 1, parallel = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betaR_+3A_lshape1">lshape1</code>, <code id="betaR_+3A_lshape2">lshape2</code>, <code id="betaR_+3A_i1">i1</code>, <code id="betaR_+3A_i2">i2</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="betaR_+3A_trim">trim</code></td>
<td>

<p>An argument which is fed into <code>mean()</code>; it is the fraction
(0 to 0.5) of observations to be trimmed from each end of the
response <code>y</code> before the mean is computed. This is used
when computing initial values, and guards against outliers.
</p>
</td></tr>
<tr><td><code id="betaR_+3A_a">A</code>, <code id="betaR_+3A_b">B</code></td>
<td>

<p>Lower and upper limits of the distribution.
The defaults correspond to the <em>standard beta distribution</em>
where the response lies between 0 and 1.
</p>
</td></tr>
<tr><td><code id="betaR_+3A_parallel">parallel</code>, <code id="betaR_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two-parameter beta distribution is given by
<code class="reqn">f(y) =</code>
</p>
<p style="text-align: center;"><code class="reqn">(y-A)^{shape1-1} \times
      (B-y)^{shape2-1} / [Beta(shape1,shape2)
      \times (B-A)^{shape1+shape2-1}]</code>
</p>

<p>for <code class="reqn">A &lt; y &lt; B</code>, and <code class="reqn">Beta(.,.)</code> is the beta function
(see <code><a href="base.html#topic+Special">beta</a></code>).
The shape parameters are positive, and
here, the limits <code class="reqn">A</code> and <code class="reqn">B</code> are known.
The mean of <code class="reqn">Y</code> is <code class="reqn">E(Y) = A + (B-A) \times shape1 /
  (shape1 + shape2)</code>, and these are the fitted values of the object.
</p>
<p>For the standard beta distribution the variance of <code class="reqn">Y</code> is
<code class="reqn">shape1 \times
     shape2 / [(1+shape1+shape2) \times (shape1+shape2)^2]</code>.
If <code class="reqn">\sigma^2= 1 / (1+shape1+shape2)</code>
then the variance of <code class="reqn">Y</code> can be written
<code class="reqn">\sigma^2 \mu (1-\mu)</code> where
<code class="reqn">\mu=shape1 / (shape1 + shape2)</code>
is the mean of <code class="reqn">Y</code>.
</p>
<p>Another parameterization of the beta distribution involving the mean
and a precision parameter is implemented in <code><a href="#topic+betaff">betaff</a></code>.
</p>






<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must have values in the interval (<code class="reqn">A</code>,
<code class="reqn">B</code>).  <span class="pkg">VGAM</span> 0.7-4 and prior called this function
<code><a href="#topic+betaff">betaff</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1995).
Chapter 25 of:
<em>Continuous Univariate Distributions</em>,
2nd edition, Volume 2, New York: Wiley.
</p>
<p>Gupta, A. K. and Nadarajah, S. (2004).
<em>Handbook of Beta Distribution and Its Applications</em>,
New York: Marcel Dekker.
</p>








<h3>See Also</h3>

<p><code><a href="#topic+betaff">betaff</a></code>,

<code><a href="stats.html#topic+Beta">Beta</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+betageometric">betageometric</a></code>,
<code><a href="#topic+betaprime">betaprime</a></code>,
<code><a href="#topic+rbetageom">rbetageom</a></code>,
<code><a href="#topic+rbetanorm">rbetanorm</a></code>,
<code><a href="#topic+kumar">kumar</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bdata &lt;- data.frame(y = rbeta(1000, shape1 = exp(0), shape2 = exp(1)))
fit &lt;- vglm(y ~ 1, betaR(lshape1 = "identitylink",
            lshape2 = "identitylink"), bdata, trace = TRUE, crit = "coef")
fit &lt;- vglm(y ~ 1, betaR, data = bdata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)  # Useful for intercept-only models

bdata &lt;- transform(bdata, Y = 5 + 8 * y)  # From 5 to 13, not 0 to 1
fit &lt;- vglm(Y ~ 1, betaR(A = 5, B = 13), data = bdata, trace = TRUE)
Coef(fit)
c(meanY = with(bdata, mean(Y)), head(fitted(fit),2))
</code></pre>

<hr>
<h2 id='biamhcop'> Ali-Mikhail-Haq Distribution Family Function </h2><span id='topic+biamhcop'></span>

<h3>Description</h3>

<p>Estimate the association parameter of
Ali-Mikhail-Haq's bivariate
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biamhcop(lapar = "rhobitlink", iapar = NULL, imethod = 1,
         nsimEIM = 250)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biamhcop_+3A_lapar">lapar</code></td>
<td>

<p>Link function applied to the association parameter
<code class="reqn">\alpha</code>, which is real
and <code class="reqn">-1 &lt; \alpha &lt; 1</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="biamhcop_+3A_iapar">iapar</code></td>
<td>

<p>Numeric. Optional initial value for <code class="reqn">\alpha</code>.
By default, an initial value is chosen internally.
If a convergence failure occurs try assigning a different value.
Assigning a value will override the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="biamhcop_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method. If failure to converge occurs
try the other value, or else specify a value for <code>iapar</code>.
</p>
</td></tr>
<tr><td><code id="biamhcop_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = y_1 y_2
          / ( 1 - \alpha (1 - y_1) (1 - y_2) ) </code>
</p>

<p>for <code class="reqn">-1 &lt; \alpha &lt; 1</code>.
The support of the function is the unit square.
The marginal distributions are the standard uniform distributions.
When <code class="reqn">\alpha = 0</code> the random variables are
independent.
This is an Archimedean copula.
</p>






<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix.  Currently, the fitted
value is a matrix with two columns and values equal to 0.5.
This is because each marginal distribution corresponds to a standard
uniform distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and C. S. Chee </p>


<h3>References</h3>




<p>Balakrishnan, N. and Lai, C.-D. (2009).
<em>Continuous Bivariate Distributions</em>,
2nd ed.
New York: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbiamhcop">rbiamhcop</a></code>,
<code><a href="#topic+bifgmcop">bifgmcop</a></code>,
<code><a href="#topic+bigumbelIexp">bigumbelIexp</a></code>,
<code><a href="#topic+rbilogis">rbilogis</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- rbiamhcop(1000, apar = rhobitlink(2, inverse = TRUE))
fit &lt;- vglm(ymat ~ 1, biamhcop, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='Biamhcop'>Ali-Mikhail-Haq Bivariate Distribution</h2><span id='topic+Biamhcop'></span><span id='topic+dbiamhcop'></span><span id='topic+pbiamhcop'></span><span id='topic+rbiamhcop'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the (one parameter) bivariate
Ali-Mikhail-Haq distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbiamhcop(x1, x2, apar, log = FALSE)
pbiamhcop(q1, q2, apar)
rbiamhcop(n, apar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Biamhcop_+3A_x1">x1</code>, <code id="Biamhcop_+3A_x2">x2</code>, <code id="Biamhcop_+3A_q1">q1</code>, <code id="Biamhcop_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Biamhcop_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>
</p>
</td></tr>
<tr><td><code id="Biamhcop_+3A_apar">apar</code></td>
<td>
<p>the association parameter.</p>
</td></tr>
<tr><td><code id="Biamhcop_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+biamhcop">biamhcop</a></code>, the <span class="pkg">VGAM</span>
family functions for estimating the
parameter by maximum likelihood estimation, for the formula of
the cumulative distribution function and other details.
</p>


<h3>Value</h3>

<p><code>dbiamhcop</code> gives the density,
<code>pbiamhcop</code> gives the distribution function, and
<code>rbiamhcop</code> generates random deviates (a two-column matrix).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and C. S. Chee</p>


<h3>See Also</h3>

<p><code><a href="#topic+biamhcop">biamhcop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> x &lt;- seq(0, 1, len = (N &lt;- 101)); apar &lt;- 0.7
ox &lt;- expand.grid(x, x)
zedd &lt;- dbiamhcop(ox[, 1], ox[, 2], apar = apar)
## Not run: 
contour(x, x, matrix(zedd, N, N), col = "blue")
zedd &lt;- pbiamhcop(ox[, 1], ox[, 2], apar = apar)
contour(x, x, matrix(zedd, N, N), col = "blue")

plot(r &lt;- rbiamhcop(n = 1000, apar = apar), col = "blue")
par(mfrow = c(1, 2))
hist(r[, 1])  # Should be uniform
hist(r[, 2])  # Should be uniform

## End(Not run)
</code></pre>

<hr>
<h2 id='biclaytoncop'> Clayton Copula (Bivariate) Family Function </h2><span id='topic+biclaytoncop'></span>

<h3>Description</h3>

<p>Estimate the correlation parameter of
the (bivariate) Clayton copula
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biclaytoncop(lapar = "loglink", iapar = NULL, imethod = 1,
             parallel = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biclaytoncop_+3A_lapar">lapar</code>, <code id="biclaytoncop_+3A_iapar">iapar</code>, <code id="biclaytoncop_+3A_imethod">imethod</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
See <code><a href="#topic+Links">Links</a></code> for more link function choices.
</p>
</td></tr>
<tr><td><code id="biclaytoncop_+3A_parallel">parallel</code>, <code id="biclaytoncop_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
If <code>parallel = TRUE</code> then the constraint is also applied
to the intercept.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(u_1, u_2;\alpha) = (u_1^{-\alpha} +
                            u_2^{-\alpha}-1)^{-1/\alpha}</code>
</p>

<p>for <code class="reqn">0 \leq \alpha </code>.
Here, <code class="reqn">\alpha</code> is the association parameter.
The support of the function is the interior of the unit square;
however, values of 0 and/or 1 are not allowed (currently).
The marginal distributions are the standard uniform distributions.
When <code class="reqn">\alpha = 0</code> the random variables are independent.
</p>
<p>This <span class="pkg">VGAM</span> family function can handle multiple responses,
for example, a six-column matrix where the first 2 columns
is the first out of three responses,
the next 2 columns being the next response, etc.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response matrix must have a multiple of two-columns.
Currently, the fitted
value is a matrix with the same number of columns
and values equal to 0.5.
This is because each marginal distribution
corresponds to a standard uniform distribution.
</p>
<p>This <span class="pkg">VGAM</span> family function is fragile;
each response must be in the interior of the unit square.



</p>


<h3>Author(s)</h3>

<p> R. Feyter and T. W. Yee </p>


<h3>References</h3>


<p>Clayton, D. (1982).
A model for association in bivariate survival data.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>44</b>, 414&ndash;422.
</p>
<p>Schepsmeier, U. and Stober, J. (2014).
Derivatives and Fisher information of bivariate copulas.
<em>Statistical Papers</em>
<b>55</b>, 525&ndash;542.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbiclaytoncop">rbiclaytoncop</a></code>,
<code><a href="#topic+dbiclaytoncop">dbiclaytoncop</a></code>,
<code><a href="#topic+kendall.tau">kendall.tau</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- rbiclaytoncop(n = (nn &lt;- 1000), apar = exp(2))
bdata &lt;- data.frame(y1 = ymat[, 1], y2 = ymat[, 2],
                    y3 = ymat[, 1], y4 = ymat[, 2], x2 = runif(nn))
summary(bdata)
## Not run:  plot(ymat, col = "blue") 
fit1 &lt;-
  vglm(cbind(y1, y2, y3, y4) ~ 1,  # 2 responses, e.g., (y1,y2) is the 1st
       biclaytoncop, data = bdata,
       trace = TRUE, crit = "coef")  # Sometimes a good idea
coef(fit1, matrix = TRUE)
Coef(fit1)
head(fitted(fit1))
summary(fit1)

# Another example; apar is a function of x2
bdata &lt;- transform(bdata, apar = exp(-0.5 + x2))
ymat &lt;- rbiclaytoncop(n = nn, apar = with(bdata, apar))
bdata &lt;- transform(bdata, y5 = ymat[, 1], y6 = ymat[, 2])
fit2 &lt;- vgam(cbind(y5, y6) ~ s(x2), data = bdata,
             biclaytoncop(lapar = "loglink"), trace = TRUE)
## Not run: plot(fit2, lcol = "blue", scol = "orange", se = TRUE) </code></pre>

<hr>
<h2 id='Biclaytoncop'>Clayton Copula (Bivariate) Distribution</h2><span id='topic+dbiclaytoncop'></span><span id='topic+rbiclaytoncop'></span>

<h3>Description</h3>

<p>Density and random generation
for the (one parameter) bivariate
Clayton copula distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbiclaytoncop(x1, x2, apar = 0, log = FALSE)
rbiclaytoncop(n, apar = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Biclaytoncop_+3A_x1">x1</code>, <code id="Biclaytoncop_+3A_x2">x2</code></td>
<td>
<p>vector of quantiles.
The <code>x1</code> and <code>x2</code> should both be
in the interval <code class="reqn">(0,1)</code>.
</p>
</td></tr>
<tr><td><code id="Biclaytoncop_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+rnorm">rnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Biclaytoncop_+3A_apar">apar</code></td>
<td>
<p>the association parameter.
Should be in the
interval <code class="reqn">[0, \infty)</code>.
The default corresponds to independence.
</p>
</td></tr>
<tr><td><code id="Biclaytoncop_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm is returned.
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+biclaytoncop">biclaytoncop</a></code>, the <span class="pkg">VGAM</span>
family functions for estimating the
parameter by maximum likelihood estimation,
for the formula of the
cumulative distribution function and other
details.
</p>


<h3>Value</h3>

<p><code>dbiclaytoncop</code> gives the density at point
(<code>x1</code>,<code>x2</code>),
<code>rbiclaytoncop</code> generates random
deviates (a two-column matrix).
</p>



<h3>Note</h3>

<p><code>dbiclaytoncop()</code> does not yet handle
<code>x1 = 0</code> and/or <code>x2 = 0</code>.
</p>





<h3>Author(s)</h3>

<p> R. Feyter and T. W. Yee </p>


<h3>References</h3>

<p>Clayton, D. (1982).
A model for association in bivariate survival data.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>44</b>, 414&ndash;422.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+biclaytoncop">biclaytoncop</a></code>,
<code><a href="#topic+binormalcop">binormalcop</a></code>,
<code><a href="#topic+binormal">binormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  edge &lt;- 0.01  # A small positive value
N &lt;- 101; x &lt;- seq(edge, 1.0 - edge, len = N); Rho &lt;- 0.7
ox &lt;- expand.grid(x, x)
zedd &lt;- dbiclaytoncop(ox[, 1], ox[, 2], apar = Rho, log = TRUE)
par(mfrow = c(1, 2))
contour(x, x, matrix(zedd, N, N), col = 4, labcex = 1.5, las = 1)
plot(rbiclaytoncop(1000, 2), col = 4, las = 1)  
## End(Not run)</code></pre>

<hr>
<h2 id='BICvlm'> Bayesian Information Criterion </h2><span id='topic+BICvlm'></span><span id='topic+BICvgam'></span>

<h3>Description</h3>

<p>Calculates the Bayesian information criterion (BIC) for
a fitted model object for which a log-likelihood value
has been obtained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BICvlm(object, ..., k = log(nobs(object)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BICvlm_+3A_object">object</code>, <code id="BICvlm_+3A_...">...</code></td>
<td>

<p>Same as <code><a href="#topic+AICvlm">AICvlm</a></code>.
</p>
</td></tr>
<tr><td><code id="BICvlm_+3A_k">k</code></td>
<td>

<p>Numeric, the penalty per parameter to be used;
the default is <code>log(n)</code> where
<code>n</code> is the number of observations).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The so-called BIC or SBC (Schwarz's Bayesian criterion)
can be computed by calling <code><a href="#topic+AICvlm">AICvlm</a></code> with a
different <code>k</code> argument.
See <code><a href="#topic+AICvlm">AICvlm</a></code> for information and caveats.
</p>


<h3>Value</h3>

<p>Returns a numeric value with the corresponding BIC, or ...,
depending on <code>k</code>.
</p>


<h3>Warning </h3>

<p>Like <code><a href="#topic+AICvlm">AICvlm</a></code>, this code has not been double-checked.
The general applicability of <code>BIC</code> for the VGLM/VGAM classes
has not been developed fully.
In particular, <code>BIC</code> should not be run on some <span class="pkg">VGAM</span> family
functions because of violation of certain regularity conditions, etc.
</p>
<p>Many <span class="pkg">VGAM</span> family functions such as
<code><a href="#topic+cumulative">cumulative</a></code> can have the number of
observations absorbed into the prior weights argument
(e.g., <code>weights</code> in <code><a href="#topic+vglm">vglm</a></code>), either
before or after fitting.  Almost all <span class="pkg">VGAM</span> family
functions can have the number of observations defined by
the <code>weights</code> argument, e.g., as an observed frequency.
<code>BIC</code> simply uses the number of rows of the model matrix, say,
as defining <code>n</code>, hence the user must be very careful
of this possible error.
Use at your own risk!!
</p>


<h3>Note</h3>

<p>BIC, AIC and other ICs can have have many additive
constants added to them. The important thing are the
differences since the minimum value corresponds to the best model.




</p>
<p>BIC has not been defined for QRR-VGLMs yet.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+AICvlm">AICvlm</a></code>,
VGLMs are described in <code><a href="#topic+vglm-class">vglm-class</a></code>;
VGAMs are described in <code><a href="#topic+vgam-class">vgam-class</a></code>;
RR-VGLMs are described in <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>;
<code><a href="stats.html#topic+BIC">BIC</a></code>,
<code><a href="stats.html#topic+AIC">AIC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = TRUE, reverse = TRUE), data = pneumo))
coef(fit1, matrix = TRUE)
BIC(fit1)
(fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = FALSE, reverse = TRUE), data = pneumo))
coef(fit2, matrix = TRUE)
BIC(fit2)
</code></pre>

<hr>
<h2 id='bifgmcop'> Farlie-Gumbel-Morgenstern's Bivariate Distribution
Family Function </h2><span id='topic+bifgmcop'></span>

<h3>Description</h3>

<p>Estimate the association parameter of
Farlie-Gumbel-Morgenstern's bivariate
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bifgmcop(lapar = "rhobitlink", iapar = NULL, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bifgmcop_+3A_lapar">lapar</code>, <code id="bifgmcop_+3A_iapar">iapar</code>, <code id="bifgmcop_+3A_imethod">imethod</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
See <code><a href="#topic+Links">Links</a></code> for more link function choices.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = y_1 y_2
             ( 1 + \alpha (1 - y_1) (1 - y_2) ) </code>
</p>

<p>for <code class="reqn">-1 &lt; \alpha &lt; 1</code>.
The support of the function is the unit square.
The marginal distributions are the standard uniform
distributions.  When <code class="reqn">\alpha = 0</code> the random
variables are independent.
</p>






<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix.  Currently, the fitted
value is a matrix with two columns and values equal to 0.5.
This is because each marginal distribution corresponds to a
standard uniform distribution.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Castillo, E., Hadi, A. S.,
Balakrishnan, N. and Sarabia, J. S. (2005).
<em>Extreme Value and Related Models with
Applications in Engineering and Science</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>
<p>Smith, M. D. (2007).
Invariance theorems for Fisher information.
<em>Communications in Statistics&mdash;Theory and Methods</em>,
<b>36</b>(12), 2213&ndash;2222.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbifgmcop">rbifgmcop</a></code>,
<code><a href="#topic+bifrankcop">bifrankcop</a></code>,
<code><a href="#topic+bifgmexp">bifgmexp</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- rbifgmcop(1000, apar = rhobitlink(3, inverse = TRUE))
## Not run: plot(ymat, col = "blue")
fit &lt;- vglm(ymat ~ 1, fam = bifgmcop, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
head(fitted(fit))
</code></pre>

<hr>
<h2 id='Bifgmcop'>Farlie-Gumbel-Morgenstern's Bivariate Distribution</h2><span id='topic+Bifgmcop'></span><span id='topic+dbifgmcop'></span><span id='topic+pbifgmcop'></span><span id='topic+rbifgmcop'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the (one parameter) bivariate
Farlie-Gumbel-Morgenstern's distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbifgmcop(x1, x2, apar, log = FALSE)
pbifgmcop(q1, q2, apar)
rbifgmcop(n, apar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bifgmcop_+3A_x1">x1</code>, <code id="Bifgmcop_+3A_x2">x2</code>, <code id="Bifgmcop_+3A_q1">q1</code>, <code id="Bifgmcop_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Bifgmcop_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Bifgmcop_+3A_apar">apar</code></td>
<td>
<p>the association parameter.</p>
</td></tr>
<tr><td><code id="Bifgmcop_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+bifgmcop">bifgmcop</a></code>, the <span class="pkg">VGAM</span>
family functions for estimating the
parameter by maximum likelihood estimation, for the formula of
the cumulative distribution function and other details.
</p>


<h3>Value</h3>

<p><code>dbifgmcop</code> gives the density,
<code>pbifgmcop</code> gives the distribution function, and
<code>rbifgmcop</code> generates random deviates (a two-column matrix).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+bifgmcop">bifgmcop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  N &lt;- 101; x &lt;- seq(0.0, 1.0, len = N); apar &lt;- 0.7
ox &lt;- expand.grid(x, x)
zedd &lt;- dbifgmcop(ox[, 1], ox[, 2], apar = apar)
contour(x, x, matrix(zedd, N, N), col = "blue")
zedd &lt;- pbifgmcop(ox[, 1], ox[, 2], apar = apar)
contour(x, x, matrix(zedd, N, N), col = "blue")

plot(r &lt;- rbifgmcop(n = 3000, apar = apar), col = "blue")
par(mfrow = c(1, 2))
hist(r[, 1])  # Should be uniform
hist(r[, 2])  # Should be uniform

## End(Not run)
</code></pre>

<hr>
<h2 id='bifgmexp'> Bivariate Farlie-Gumbel-Morgenstern Exponential
Distribution Family Function </h2><span id='topic+bifgmexp'></span>

<h3>Description</h3>

<p>Estimate the association parameter of FGM bivariate
exponential distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bifgmexp(lapar = "rhobitlink", iapar = NULL, tola0 = 0.01,
         imethod = 1)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bifgmexp_+3A_lapar">lapar</code></td>
<td>

<p>Link function for the
association parameter
<code class="reqn">\alpha</code>, which lies between <code class="reqn">-1</code> and <code class="reqn">1</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices
and other information.
</p>
</td></tr>
<tr><td><code id="bifgmexp_+3A_iapar">iapar</code></td>
<td>

<p>Numeric. Optional initial value for <code class="reqn">\alpha</code>.
By default, an initial value is chosen internally.
If a convergence failure occurs try assigning a different value.
Assigning a value will override the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="bifgmexp_+3A_tola0">tola0</code></td>
<td>

<p>Positive numeric.
If the estimate of <code class="reqn">\alpha</code> has an absolute
value less than this then it is replaced by this value.
This is an attempt to fix a numerical problem when the estimate
is too close to zero.
</p>
</td></tr>
<tr><td><code id="bifgmexp_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method. If failure to converge
occurs try the other value, or else specify a value for
<code>ia</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = e^{-y_1-y_2}
             ( 1 + \alpha [1 - e^{-y_1}] [1 - e^{-y_2}] ) + 1 -
               e^{-y_1} - e^{-y_2} </code>
</p>

<p>for <code class="reqn">\alpha</code> between <code class="reqn">-1</code> and <code class="reqn">1</code>.
The support of the function is for <code class="reqn">y_1&gt;0</code> and
<code class="reqn">y_2&gt;0</code>.
The marginal distributions are an exponential distribution with
unit mean.
When <code class="reqn">\alpha = 0</code> then the random variables are
independent, and this causes some problems in the estimation
process since the distribution no longer depends on the
parameter.
</p>
<p>A variant of Newton-Raphson is used, which only seems to
work for an intercept model.
It is a very good idea to set <code>trace = TRUE</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix. Currently, the fitted
value is a matrix with two columns and values equal to 1.
This is because each marginal distribution corresponds to a
exponential distribution with unit mean.
</p>
<p>This <span class="pkg">VGAM</span> family function should be used with caution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Castillo, E., Hadi, A. S.,
Balakrishnan, N. and Sarabia, J. S. (2005).
<em>Extreme Value and Related Models with Applications in
Engineering and Science</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bifgmcop">bifgmcop</a></code>,
<code><a href="#topic+bigumbelIexp">bigumbelIexp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 1000; mdata &lt;- data.frame(y1 = rexp(N), y2 = rexp(N))
## Not run: plot(ymat)
fit &lt;- vglm(cbind(y1, y2) ~ 1, bifgmexp, data = mdata, trace = TRUE)
fit &lt;- vglm(cbind(y1, y2) ~ 1, bifgmexp, data = mdata, # May fail
            trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
head(fitted(fit))
</code></pre>

<hr>
<h2 id='bifrankcop'> Frank's Bivariate Distribution Family Function </h2><span id='topic+bifrankcop'></span>

<h3>Description</h3>

<p>Estimate the association parameter of Frank's bivariate
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bifrankcop(lapar = "loglink", iapar = 2, nsimEIM = 250)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bifrankcop_+3A_lapar">lapar</code></td>
<td>

<p>Link function applied to the (positive) association parameter
<code class="reqn">\alpha</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="bifrankcop_+3A_iapar">iapar</code></td>
<td>

<p>Numeric. Initial value for <code class="reqn">\alpha</code>.
If a convergence failure occurs try assigning a different value.
</p>
</td></tr>
<tr><td><code id="bifrankcop_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = H_{\alpha}(y_1,y_2) =
\log_{\alpha} [1 + (\alpha^{y_1}-1)(\alpha^{y_2}-1)/
(\alpha-1)] </code>
</p>

<p>for <code class="reqn">\alpha \ne 1</code>.
Note the logarithm here is to base <code class="reqn">\alpha</code>.
The support of the function is the unit square.
</p>
<p>When <code class="reqn">0 &lt; \alpha &lt; 1</code> the probability density function
<code class="reqn">h_{\alpha}(y_1,y_2)</code>
is symmetric with respect to the lines <code class="reqn">y_2=y_1</code>
and <code class="reqn">y_2=1-y_1</code>.
When <code class="reqn">\alpha &gt; 1</code> then
<code class="reqn">h_{\alpha}(y_1,y_2) = h_{1/\alpha}(1-y_1,y_2)</code>.
</p>
<p><code class="reqn">\alpha=1</code> then <code class="reqn">H(y_1,y_2) = y_1 y_2</code>,
i.e., uniform on the unit square.
As <code class="reqn">\alpha</code> approaches 0 then
<code class="reqn">H(y_1,y_2) = \min(y_1,y_2)</code>.
As <code class="reqn">\alpha</code> approaches infinity then
<code class="reqn">H(y_1,y_2) = \max(0, y_1+y_2-1)</code>.
</p>
<p>The default is to use Fisher scoring implemented using
<code><a href="#topic+rbifrankcop">rbifrankcop</a></code>.
For intercept-only models an alternative is to set
<code>nsimEIM=NULL</code> so that a variant of Newton-Raphson is used.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix. Currently, the fitted
value is a matrix with two columns and values equal to a half.
This is because the marginal distributions correspond to a
standard uniform distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Genest, C. (1987).
Frank's family of bivariate distributions.
<em>Biometrika</em>,
<b>74</b>, 549&ndash;555.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbifrankcop">rbifrankcop</a></code>,
<code><a href="#topic+bifgmcop">bifgmcop</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ymat &lt;- rbifrankcop(n = 2000, apar = exp(4))
plot(ymat, col = "blue")
fit &lt;- vglm(ymat ~ 1, fam = bifrankcop, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
vcov(fit)
head(fitted(fit))
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='bigumbelIexp'> Gumbel's Type I Bivariate Distribution Family Function </h2><span id='topic+bigumbelIexp'></span>

<h3>Description</h3>

<p>Estimate the association parameter of Gumbel's Type I bivariate
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigumbelIexp(lapar = "identitylink", iapar = NULL, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigumbelIexp_+3A_lapar">lapar</code></td>
<td>

<p>Link function applied to the association parameter
<code class="reqn">\alpha</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="bigumbelIexp_+3A_iapar">iapar</code></td>
<td>

<p>Numeric. Optional initial value for <code class="reqn">\alpha</code>.
By default, an initial value is chosen internally.
If a convergence failure occurs try assigning a different value.
Assigning a value will override the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="bigumbelIexp_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method. If failure to converge occurs
try the other value, or else specify a value for <code>ia</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = e^{-y_1-y_2+\alpha y_1 y_2}
      + 1  - e^{-y_1} - e^{-y_2} </code>
</p>

<p>for real <code class="reqn">\alpha</code>.
The support of the function is for <code class="reqn">y_1&gt;0</code> and
<code class="reqn">y_2&gt;0</code>.
The marginal distributions are an exponential distribution with
unit mean.
</p>
<p>A variant of Newton-Raphson is used, which only seems
to work for an intercept model.
It is a very good idea to set <code>trace=TRUE</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix.  Currently, the fitted
value is a matrix with two columns and values equal to 1.
This is because each marginal distribution corresponds to a
exponential distribution with unit mean.
</p>
<p>This <span class="pkg">VGAM</span> family function should be used with caution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>






<p>Gumbel, E. J. (1960).
Bivariate Exponential Distributions.
<em>Journal of the American Statistical Association</em>,
<b>55</b>, 698&ndash;707.
</p>




<h3>See Also</h3>

<p><code><a href="#topic+bifgmexp">bifgmexp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
gdata &lt;- data.frame(y1 = rexp(nn), y2 = rexp(nn))
## Not run:  with(gdata, plot(cbind(y1, y2))) 
fit &lt;- vglm(cbind(y1, y2) ~ 1, bigumbelIexp, gdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
head(fitted(fit))
</code></pre>

<hr>
<h2 id='bilogis'>Bivariate Logistic Distribution</h2><span id='topic+bilogis'></span><span id='topic+dbilogis'></span><span id='topic+pbilogis'></span><span id='topic+rbilogis'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the 4-parameter bivariate logistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbilogis(x1, x2, loc1 = 0, scale1 = 1, loc2 = 0, scale2 = 1,
         log = FALSE)
pbilogis(q1, q2, loc1 = 0, scale1 = 1, loc2 = 0, scale2 = 1)
rbilogis(n, loc1 = 0, scale1 = 1, loc2 = 0, scale2 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bilogis_+3A_x1">x1</code>, <code id="bilogis_+3A_x2">x2</code>, <code id="bilogis_+3A_q1">q1</code>, <code id="bilogis_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="bilogis_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+rlogis">rlogis</a></code>.
</p>
</td></tr>
<tr><td><code id="bilogis_+3A_loc1">loc1</code>, <code id="bilogis_+3A_loc2">loc2</code></td>
<td>
<p>the location parameters <code class="reqn">l_1</code> and
<code class="reqn">l_2</code>.</p>
</td></tr>
<tr><td><code id="bilogis_+3A_scale1">scale1</code>, <code id="bilogis_+3A_scale2">scale2</code></td>
<td>
<p>the scale parameters <code class="reqn">s_1</code>
and <code class="reqn">s_2</code>.</p>
</td></tr>
<tr><td><code id="bilogis_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+bilogis">bilogis</a></code>, the <span class="pkg">VGAM</span> family function for
estimating the four parameters by maximum likelihood estimation,
for the formula of the cumulative distribution function and
other details.
</p>


<h3>Value</h3>

<p><code>dbilogis</code> gives the density,
<code>pbilogis</code> gives the distribution function, and
<code>rbilogis</code> generates random deviates (a two-column matrix).
</p>


<h3>Note</h3>

<p>Gumbel (1961) proposed two bivariate logistic distributions with
logistic distribution marginals, which he called Type I and Type II.
The Type I is this one.
The Type II belongs to the Morgenstern type.
The <code><a href="#topic+biamhcop">biamhcop</a></code> distribution has, as a special case,
this distribution, which is when the random variables are
independent.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Gumbel, E. J. (1961).
Bivariate logistic distributions.
<em>Journal of the American Statistical Association</em>,
<b>56</b>, 335&ndash;349.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bilogistic">bilogistic</a></code>,
<code><a href="#topic+biamhcop">biamhcop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  par(mfrow = c(1, 3))
ymat &lt;- rbilogis(n = 2000, loc1 = 5, loc2 = 7, scale2 = exp(1))
myxlim &lt;- c(-2, 15); myylim &lt;- c(-10, 30)
plot(ymat, xlim = myxlim, ylim = myylim)

N &lt;- 100
x1 &lt;- seq(myxlim[1], myxlim[2], len = N)
x2 &lt;- seq(myylim[1], myylim[2], len = N)
ox &lt;- expand.grid(x1, x2)
z &lt;- dbilogis(ox[,1], ox[,2], loc1 = 5, loc2 = 7, scale2 = exp(1))
contour(x1, x2, matrix(z, N, N), main = "density")
z &lt;- pbilogis(ox[,1], ox[,2], loc1 = 5, loc2 = 7, scale2 = exp(1))
contour(x1, x2, matrix(z, N, N), main = "cdf") 
## End(Not run)
</code></pre>

<hr>
<h2 id='bilogistic'> Bivariate Logistic Distribution Family Function </h2><span id='topic+bilogistic'></span>

<h3>Description</h3>

<p>Estimates the four parameters of the bivariate logistic
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bilogistic(llocation = "identitylink", lscale = "loglink",
           iloc1 = NULL, iscale1 = NULL, iloc2 = NULL, iscale2 =
           NULL, imethod = 1, nsimEIM = 250, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bilogistic_+3A_llocation">llocation</code></td>
<td>

<p>Link function applied to both location parameters
<code class="reqn">l_1</code> and <code class="reqn">l_2</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>

</td></tr>
<tr><td><code id="bilogistic_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link function applied to both
(positive) scale parameters <code class="reqn">s_1</code> and <code class="reqn">s_2</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="bilogistic_+3A_iloc1">iloc1</code>, <code id="bilogistic_+3A_iloc2">iloc2</code></td>
<td>

<p>Initial values for the location parameters.
By default, initial values are chosen internally using
<code>imethod</code>. Assigning values here will override
the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="bilogistic_+3A_iscale1">iscale1</code>, <code id="bilogistic_+3A_iscale2">iscale2</code></td>
<td>

<p>Initial values for the scale parameters.
By default, initial values are chosen internally using
<code>imethod</code>. Assigning values here will override
the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="bilogistic_+3A_imethod">imethod</code></td>
<td>
<p> An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method. If failure to converge
occurs try the other value.
</p>
</td></tr>
<tr><td><code id="bilogistic_+3A_nsimeim">nsimEIM</code>, <code id="bilogistic_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>






</table>


<h3>Details</h3>

<p>The four-parameter bivariate logistic distribution
has a density that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y_1,y_2;l_1,s_1,l_2,s_2) = 2 \frac{\exp[-(y_1-l_1)/s_1 -
(y_2-l_2)/s_2]}{
s_1 s_2 \left( 1 + \exp[-(y_1-l_1)/s_1] + \exp[-(y_2-l_2)/s_2]
\right)^3}</code>
</p>

<p>where <code class="reqn">s_1&gt;0</code> and <code class="reqn">s_2&gt;0</code> are the scale parameters,
and <code class="reqn">l_1</code> and <code class="reqn">l_2</code> are the location parameters.
Each of the two responses are unbounded, i.e.,
<code class="reqn">-\infty&lt;y_j&lt;\infty</code>.
The mean of <code class="reqn">Y_1</code> is <code class="reqn">l_1</code> etc.
The fitted values are returned in a 2-column matrix.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y_1,y_2;l_1,s_1,l_2,s_2) =
\left( 1 + \exp[-(y_1-l_1)/s_1] + \exp[-(y_2-l_2)/s_2]
\right)^{-1}</code>
</p>

<p>The marginal distribution of <code class="reqn">Y_1</code> is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1) = F(y_1;l_1,s_1) =
      \left( 1 + \exp[-(y_1-l_1)/s_1] \right)^{-1} .</code>
</p>

<p>By default, <code class="reqn">\eta_1=l_1</code>,
<code class="reqn">\eta_2=\log(s_1)</code>,
<code class="reqn">\eta_3=l_2</code>,
<code class="reqn">\eta_4=\log(s_2)</code> are the linear/additive
predictors.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Gumbel, E. J. (1961).
Bivariate logistic distributions.
<em>Journal of the American Statistical Association</em>,
<b>56</b>, 335&ndash;349.
</p>
<p>Castillo, E., Hadi, A. S., Balakrishnan, N. and
Sarabia, J. S. (2005).
<em>Extreme Value and Related Models with Applications in
Engineering and Science</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logistic">logistic</a></code>,
<code><a href="#topic+rbilogis">rbilogis</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ymat &lt;- rbilogis(n &lt;- 50, loc1 = 5, loc2 = 7, scale2 = exp(1))
plot(ymat)
bfit &lt;- vglm(ymat ~ 1, family = bilogistic, trace = TRUE)
coef(bfit, matrix = TRUE)
Coef(bfit)
head(fitted(bfit))
vcov(bfit)
head(weights(bfit, type = "work"))
summary(bfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='binom2.or'> Bivariate Binary Regression with an Odds Ratio (Family
Function) </h2><span id='topic+binom2.or'></span>

<h3>Description</h3>

<p>Fits a Palmgren (bivariate odds-ratio model, or
bivariate logistic regression) model to two binary
responses. Actually, a bivariate logistic/probit/cloglog/cauchit
model can be fitted.  The odds ratio is used as a measure
of dependency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binom2.or(lmu = "logitlink", lmu1 = lmu, lmu2 = lmu, loratio = "loglink",
          imu1 = NULL, imu2 = NULL, ioratio = NULL, zero = "oratio",
          exchangeable = FALSE, tol = 0.001, more.robust = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binom2.or_+3A_lmu">lmu</code></td>
<td>

<p>Link function applied to the two marginal probabilities.
See <code><a href="#topic+Links">Links</a></code> for more choices.
See the note below.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_lmu1">lmu1</code>, <code id="binom2.or_+3A_lmu2">lmu2</code></td>
<td>

<p>Link function applied to the first and second of the two marginal
probabilities.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_loratio">loratio</code></td>
<td>

<p>Link function applied to the odds ratio.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_imu1">imu1</code>, <code id="binom2.or_+3A_imu2">imu2</code>, <code id="binom2.or_+3A_ioratio">ioratio</code></td>
<td>

<p>Optional initial values for the marginal probabilities and odds
ratio.  See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
In general good initial values are often required so use these
arguments if convergence failure occurs.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_zero">zero</code></td>
<td>

<p>Which linear/additive predictor is modelled as an intercept only?
The default is for the odds ratio.
A <code>NULL</code> means none.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_exchangeable">exchangeable</code></td>
<td>

<p>Logical.
If <code>TRUE</code>, the two marginal probabilities are constrained
to be equal.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_tol">tol</code></td>
<td>

<p>Tolerance for testing independence. Should be some
small positive numerical value.
</p>
</td></tr>
<tr><td><code id="binom2.or_+3A_more.robust">more.robust</code></td>
<td>

<p>Logical. If <code>TRUE</code> then some measures are taken to compute the
derivatives and working weights more robustly, i.e., in an attempt
to avoid numerical problems. Currently this feature is not debugged
if set <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also known informally as the <em>Palmgren model</em>,
the bivariate logistic model is
a full-likelihood based model defined as two logistic regressions plus
<code>log(oratio) = eta3</code> where <code>eta3</code> is the third linear/additive
predictor relating the odds ratio to explanatory variables.
Explicitly, the default model is
</p>
<p style="text-align: center;"><code class="reqn">logit[P(Y_j=1)] = \eta_j,\ \ \ j=1,2</code>
</p>

<p>for the marginals, and
</p>
<p style="text-align: center;"><code class="reqn">\log[P(Y_{00}=1) P(Y_{11}=1) / (P(Y_{01}=1) P(Y_{10}=1))] = \eta_3,</code>
</p>

<p>specifies the dependency between the two responses. Here, the responses
equal 1 for a success and a 0 for a failure, and the odds ratio is often
written <code class="reqn">\psi=p_{00}p_{11}/(p_{10}p_{01})</code>.
The model is fitted by maximum likelihood estimation since the full
likelihood is specified.
The two binary responses are independent if and only if the odds ratio
is unity, or equivalently, the log odds ratio is 0.  Fisher scoring
is implemented.
</p>
<p>The default models <code class="reqn">\eta_3</code> as a single parameter only,
i.e., an intercept-only model, but this can be circumvented by
setting <code>zero = NULL</code> in order to model the odds ratio as
a function of all the explanatory variables.
The function <code>binom2.or()</code> can handle other
probability link functions such as <code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code> and <code><a href="#topic+cauchitlink">cauchitlink</a></code> links
as well, so is quite general.  In fact, the two marginal
probabilities can each have a different link function.
A similar model is the <em>bivariate probit model</em>
(<code><a href="#topic+binom2.rho">binom2.rho</a></code>), which is based on a standard
bivariate normal distribution, but the bivariate probit model
is less interpretable and flexible.
</p>
<p>The <code>exchangeable</code> argument should be used when the error
structure is exchangeable, e.g., with eyes or ears data.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>When fitted, the <code>fitted.values</code> slot of the
object contains the four joint probabilities, labelled
as <code class="reqn">(Y_1,Y_2)</code> = (0,0), (0,1), (1,0), (1,1),
respectively.  These estimated probabilities should be extracted
with the <code>fitted</code> generic function.
</p>


<h3>Note</h3>

<p>At present we call <code><a href="#topic+binom2.or">binom2.or</a></code> families a
<em>bivariate odds-ratio model</em>.
The response should be either a 4-column matrix of counts
(whose columns correspond
to <code class="reqn">(Y_1,Y_2)</code> = (0,0), (0,1), (1,0),
(1,1) respectively), or a two-column matrix where each column
has two distinct values, or a factor with four levels.
The function <code><a href="#topic+rbinom2.or">rbinom2.or</a></code> may be used to generate
such data.  Successful convergence requires at least one case
of each of the four possible outcomes.
</p>
<p>By default, a constant odds ratio is fitted because <code>zero
  = 3</code>.  Set <code>zero = NULL</code> if you want the odds ratio to be
modelled as a function of the explanatory variables; however,
numerical problems are more likely to occur.
</p>
<p>The argument <code>lmu</code>, which is actually redundant, is used for
convenience and for upward compatibility: specifying <code>lmu</code>
only means the link function will be applied to <code>lmu1</code>
and <code>lmu2</code>.  Users who want a different link function for
each of the two marginal probabilities should use the <code>lmu1</code>
and <code>lmu2</code> arguments, and the argument <code>lmu</code> is then
ignored.  It doesn't make sense to specify <code>exchangeable =
  TRUE</code> and have different link functions for the two marginal
probabilities.
</p>
<p>Regarding Yee and Dirnbock (2009),
the <code>xij</code> (see <code><a href="#topic+vglm.control">vglm.control</a></code>) argument enables
environmental variables with different values at the two time
points to be entered into an exchangeable <code><a href="#topic+binom2.or">binom2.or</a></code>
model.  See the author's webpage for sample code.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>
<p>le Cessie, S. and van Houwelingen, J. C. (1994).
Logistic regression for correlated binary data.
<em>Applied Statistics</em>,
<b>43</b>, 95&ndash;108.
</p>
<p>Palmgren, J. (1989).
<em>Regression Models for Bivariate Binary Responses</em>.
Technical Report no. 101, Department of Biostatistics,
University of Washington, Seattle.
</p>
<p>Yee, T. W. and Dirnbock, T. (2009).
Models for analysing species' presence/absence data
at two time points.
Journal of Theoretical Biology, <b>259</b>(4), 684&ndash;694.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+rbinom2.or">rbinom2.or</a></code>,
<code><a href="#topic+binom2.rho">binom2.rho</a></code>,
<code><a href="#topic+loglinb2">loglinb2</a></code>,
<code><a href="#topic+loglinb3">loglinb3</a></code>,
<code><a href="#topic+zipebcom">zipebcom</a></code>,
<code><a href="#topic+coalminers">coalminers</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit the model in Table 6.7 in McCullagh and Nelder (1989)
coalminers &lt;- transform(coalminers, Age = (age - 42) / 5)
fit &lt;- vglm(cbind(nBnW, nBW, BnW, BW) ~ Age,
            binom2.or(zero = NULL), data = coalminers)
fitted(fit)
summary(fit)
coef(fit, matrix = TRUE)
c(weights(fit, type = "prior")) * fitted(fit)  # Table 6.8

## Not run:  with(coalminers, matplot(Age, fitted(fit), type = "l", las = 1,
                         xlab = "(age - 42) / 5", lwd = 2))
with(coalminers, matpoints(Age, depvar(fit), col=1:4))
legend(x = -4, y = 0.5, lty = 1:4, col = 1:4, lwd = 2,
       legend = c("1 = (Breathlessness=0, Wheeze=0)",
                  "2 = (Breathlessness=0, Wheeze=1)",
                  "3 = (Breathlessness=1, Wheeze=0)",
                  "4 = (Breathlessness=1, Wheeze=1)")) 
## End(Not run)


# Another model: pet ownership
## Not run:  data(xs.nz, package = "VGAMdata")
# More homogeneous:
petdata &lt;- subset(xs.nz, ethnicity == "European" &amp; age &lt; 70 &amp;
                         sex == "M")
petdata &lt;- na.omit(petdata[, c("cat", "dog", "age")])
summary(petdata)
with(petdata, table(cat, dog))  # Can compute the odds ratio

fit &lt;- vgam(cbind((1-cat) * (1-dog), (1-cat) * dog,
                     cat  * (1-dog),    cat  * dog) ~ s(age, df = 5),
            binom2.or(zero =    3), data = petdata, trace = TRUE)
colSums(depvar(fit))
coef(fit, matrix = TRUE)

## End(Not run)

## Not run:  # Plot the estimated probabilities
ooo &lt;- order(with(petdata, age))
matplot(with(petdata, age)[ooo], fitted(fit)[ooo, ], type = "l",
        xlab = "Age", ylab = "Probability", main = "Pet ownership",
        ylim = c(0, max(fitted(fit))), las = 1, lwd = 1.5)
legend("topleft", col=1:4, lty = 1:4, leg = c("no cat or dog ",
       "dog only", "cat only", "cat and dog"), lwd = 1.5) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Binom2.or'> Bivariate Odds Ratio Model </h2><span id='topic+Binom2.or'></span><span id='topic+dbinom2.or'></span><span id='topic+rbinom2.or'></span>

<h3>Description</h3>

<p>Density and random generation for a bivariate
binary regression
model using an odds ratio as the measure of dependency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbinom2.or(n, mu1,
    mu2 = if (exchangeable) mu1 else
    stop("argument 'mu2' not specified"),
    oratio = 1, exchangeable = FALSE, tol = 0.001,
    twoCols = TRUE, colnames = if (twoCols) c("y1","y2") else
    c("00", "01", "10", "11"),
    ErrorCheck = TRUE)
dbinom2.or(mu1, mu2 = if (exchangeable) mu1 else
    stop("'mu2' not specified"),
    oratio = 1, exchangeable = FALSE, tol = 0.001,
    colnames = c("00", "01", "10", "11"), ErrorCheck = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Binom2.or_+3A_n">n</code></td>
<td>

<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
The arguments <code>mu1</code>, <code>mu2</code>, <code>oratio</code>
are recycled to
this value.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_mu1">mu1</code>, <code id="Binom2.or_+3A_mu2">mu2</code></td>
<td>

<p>The marginal probabilities.
Only <code>mu1</code> is needed if <code>exchangeable = TRUE</code>.
Values should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_oratio">oratio</code></td>
<td>

<p>Odds ratio. Must be numeric and positive.
The default value of unity means the responses are
statistically independent.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_exchangeable">exchangeable</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the two marginal probabilities are
constrained to be equal.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_twocols">twoCols</code></td>
<td>

<p>Logical.
If <code>TRUE</code>, then a <code class="reqn">n</code> <code class="reqn">\times</code> <code class="reqn">2</code>
matrix of 1s
and 0s is returned.
If <code>FALSE</code>, then a <code class="reqn">n</code> <code class="reqn">\times</code> <code class="reqn">4</code>
matrix of 1s
and 0s is returned.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_colnames">colnames</code></td>
<td>

<p>The <code>dimnames</code> argument of
<code><a href="base.html#topic+matrix">matrix</a></code> is
assigned <code>list(NULL, colnames)</code>.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_tol">tol</code></td>
<td>

<p>Tolerance for testing independence. Should be some
small positive numerical value.
</p>
</td></tr>
<tr><td><code id="Binom2.or_+3A_errorcheck">ErrorCheck</code></td>
<td>

<p>Logical. Do some error checking of the input parameters?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>rbinom2.or</code> generates data coming from a
bivariate binary response model.
The data might be fitted with
the <span class="pkg">VGAM</span> family function <code><a href="#topic+binom2.or">binom2.or</a></code>.
</p>
<p>The function <code>dbinom2.or</code> does not really compute the
density (because that does not make sense here) but rather
returns the four joint probabilities.
</p>


<h3>Value</h3>

<p>The function <code>rbinom2.or</code> returns
either a 2 or 4 column matrix of 1s and 0s, depending on the
argument <code>twoCols</code>.
</p>
<p>The function <code>dbinom2.or</code> returns
a 4 column matrix of joint probabilities; each row adds up
to unity.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+binom2.or">binom2.or</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000  # Example 1
ymat &lt;- rbinom2.or(nn, mu1 = logitlink(1, inv = TRUE),
                   oratio = exp(2), exch = TRUE)
(mytab &lt;- table(ymat[, 1], ymat[, 2], dnn = c("Y1", "Y2")))
(myor &lt;- mytab["0","0"] * mytab["1","1"] / (mytab["1","0"] *
         mytab["0","1"]))
fit &lt;- vglm(ymat ~ 1, binom2.or(exch = TRUE))
coef(fit, matrix = TRUE)

bdata &lt;- data.frame(x2 = sort(runif(nn)))  # Example 2
bdata &lt;- transform(bdata,
           mu1 = logitlink(-2 + 4 * x2, inverse = TRUE),
           mu2 = logitlink(-1 + 3 * x2, inverse = TRUE))
dmat &lt;- with(bdata, dbinom2.or(mu1 = mu1, mu2 = mu2,
                               oratio = exp(2)))
ymat &lt;- with(bdata, rbinom2.or(n = nn, mu1 = mu1, mu2 = mu2,
                               oratio = exp(2)))
fit2 &lt;- vglm(ymat ~ x2, binom2.or, data = bdata)
coef(fit2, matrix = TRUE)
## Not run: 
matplot(with(bdata, x2), dmat, lty = 1:4, col = 1:4,
        main = "Joint probabilities", ylim = 0:1, type = "l",
        ylab = "Probabilities", xlab = "x2", las = 1)
legend("top", lty = 1:4, col = 1:4,
       legend = c("1 = (y1=0, y2=0)", "2 = (y1=0, y2=1)",
                  "3 = (y1=1, y2=0)", "4 = (y1=1, y2=1)"))

## End(Not run)
</code></pre>

<hr>
<h2 id='binom2.rho'> Bivariate Probit Regression </h2><span id='topic+binom2.rho'></span><span id='topic+binom2.Rho'></span>

<h3>Description</h3>

<p>Fits a bivariate probit model to two binary responses.
The correlation parameter rho is the measure of dependency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binom2.rho(lmu = "probitlink", lrho = "rhobitlink",
           imu1 = NULL, imu2 = NULL,
           irho = NULL, imethod = 1, zero = "rho",
           exchangeable = FALSE, grho = seq(-0.95, 0.95, by = 0.05),
           nsimEIM = NULL)
binom2.Rho(rho = 0, imu1 = NULL, imu2 = NULL,
           exchangeable = FALSE, nsimEIM = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binom2.rho_+3A_lmu">lmu</code></td>
<td>

<p>Link function applied to the marginal probabilities.
Should be left alone.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_lrho">lrho</code></td>
<td>

<p>Link function applied to the <code class="reqn">\rho</code> association
parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_imu1">imu1</code>, <code id="binom2.rho_+3A_imu2">imu2</code></td>
<td>

<p>Optional initial values for the two marginal probabilities.
May be a vector.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_irho">irho</code></td>
<td>

<p>Optional initial value for <code class="reqn">\rho</code>.
If given, this should lie between <code class="reqn">-1</code> and <code class="reqn">1</code>.
See below for more comments.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_zero">zero</code></td>
<td>

<p>Specifies which linear/additive predictors are modelled as
intercept-only.
A <code>NULL</code> means none.
Numerically, the <code class="reqn">\rho</code> parameter is easiest
modelled as an intercept only, hence the default.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_exchangeable">exchangeable</code></td>
<td>

<p>Logical.
If <code>TRUE</code>, the two marginal probabilities are constrained
to be equal.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_imethod">imethod</code>, <code id="binom2.rho_+3A_nsimeim">nsimEIM</code>, <code id="binom2.rho_+3A_grho">grho</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
A value of at least 100 for <code>nsimEIM</code> is recommended;
the larger the value the better.
</p>
</td></tr>
<tr><td><code id="binom2.rho_+3A_rho">rho</code></td>
<td>

<p>Numeric vector.
Values are recycled to the needed length,
and ought to be in range, which is <code class="reqn">(-1, 1)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>bivariate probit model</em> was one of the
earliest regression models to handle two binary responses
jointly. It has a probit link for each of the two marginal
probabilities, and models the association between the
responses by the <code class="reqn">\rho</code> parameter of a standard
bivariate normal distribution (with zero means and unit
variances). One can think of the joint probabilities being
<code class="reqn">\Phi(\eta_1,\eta_2;\rho)</code> where
<code class="reqn">\Phi</code> is the cumulative distribution function of a
standard bivariate normal distribution.
</p>
<p>Explicitly, the default model is
</p>
<p style="text-align: center;"><code class="reqn">probit[P(Y_j=1)] = \eta_j,\ \ \ j=1,2</code>
</p>

<p>for the marginals, and
</p>
<p style="text-align: center;"><code class="reqn">rhobit[rho] = \eta_3.</code>
</p>

<p>The joint probability
<code class="reqn">P(Y_1=1,Y_2=1)=
\Phi(\eta_1,\eta_2;\rho)</code>,
and from these the other three joint probabilities are easily
computed.  The model is fitted by maximum likelihood estimation
since the full likelihood is specified.  Fisher scoring is
implemented.
</p>
<p>The default models <code class="reqn">\eta_3</code> as a single parameter
only, i.e., an intercept-only model for rho, but this can be
circumvented by setting <code>zero = NULL</code> in order to model
rho as a function of all the explanatory variables.
</p>
<p>The bivariate probit model should not be confused with
a <em>bivariate logit model</em> with a probit link (see
<code><a href="#topic+binom2.or">binom2.or</a></code>).  The latter uses the odds ratio to
quantify the association. Actually, the bivariate logit model
is recommended over the bivariate probit model because the
odds ratio is a more natural way of measuring the association
between two binary responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>When fitted, the <code>fitted.values</code> slot of the object
contains the four joint probabilities, labelled as
<code class="reqn">(Y_1,Y_2)</code> = (0,0), (0,1), (1,0), (1,1),
respectively.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+binom2.or">binom2.or</a></code> about the form of input the response
should have.
</p>
<p>By default, a constant <code class="reqn">\rho</code> is fitted because
<code>zero = "rho"</code>.  Set <code>zero = NULL</code> if you want
the <code class="reqn">\rho</code> parameter to be modelled as a function
of the explanatory variables.  The value <code class="reqn">\rho</code>
lies in the interval <code class="reqn">(-1,1)</code>, therefore a
<code><a href="#topic+rhobitlink">rhobitlink</a></code> link is default.
</p>
<p>Converge problems can occur.
If so, assign <code>irho</code> a range of
values and monitor convergence (e.g., set <code>trace = TRUE</code>).
Else try <code>imethod</code>.
Practical experience shows that local solutions can occur,
and that <code>irho</code> needs to be quite close to the (global)
solution.
Also, <code>imu1</code> and <code>imu2</code> may be used.
</p>
<p>This help file is mainly about <code>binom2.rho()</code>.
<code>binom2.Rho()</code> fits a bivariate probit model with
<em>known</em> <code class="reqn">\rho</code>.
The inputted <code>rho</code> is saved in the <code>misc</code> slot of
the fitted object, with <code>rho</code> as the component name.
</p>
<p>In some econometrics applications
(e.g., Freedman 2010, Freedman and Sekhon 2010)
one response is used as an explanatory variable,
e.g., a <em>recursive</em> binomial probit model.
Such will not work here.
Historically, the bivariate probit model was the first VGAM I
ever wrote, based on Ashford and Sowden (1970).  I don't think
they ever thought of it either!  Hence the criticisms raised
go beyond the use of what was originally intended.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Ashford, J. R. and Sowden, R. R. (1970).
Multi-variate probit analysis.
<em>Biometrics</em>, <b>26</b>, 535&ndash;546.
</p>
<p>Freedman, D. A. (2010).
<em>Statistical Models and Causal Inference: a Dialogue with
the Social Sciences</em>, Cambridge: Cambridge University Press.
</p>
<p>Freedman, D. A. and Sekhon, J. S. (2010).
Endogeneity in probit response models.
<em>Political Analysis</em>,
<b>18</b>, 138&ndash;150.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbinom2.rho">rbinom2.rho</a></code>,
<code><a href="#topic+rhobitlink">rhobitlink</a></code>,
<code><a href="#topic+pbinorm">pbinorm</a></code>,
<code><a href="#topic+binom2.or">binom2.or</a></code>,
<code><a href="#topic+loglinb2">loglinb2</a></code>,
<code><a href="#topic+coalminers">coalminers</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+rhobitlink">rhobitlink</a></code>,
<code><a href="#topic+fisherzlink">fisherzlink</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>coalminers &lt;- transform(coalminers, Age = (age - 42) / 5)
fit &lt;- vglm(cbind(nBnW, nBW, BnW, BW) ~ Age,
            binom2.rho, data = coalminers, trace = TRUE)
summary(fit)
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='Binom2.rho'> Bivariate Probit Model </h2><span id='topic+Binom2.rho'></span><span id='topic+dbinom2.rho'></span><span id='topic+rbinom2.rho'></span>

<h3>Description</h3>

<p>Density and random generation for a bivariate probit model.
The correlation parameter rho is the measure of dependency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbinom2.rho(n, mu1,
  mu2 = if (exchangeable) mu1 else stop("argument 'mu2' not specified"),
  rho = 0, exchangeable = FALSE, twoCols = TRUE,
  colnames = if (twoCols) c("y1","y2") else c("00", "01", "10", "11"),
  ErrorCheck = TRUE)
dbinom2.rho(mu1,
  mu2 = if (exchangeable) mu1 else stop("'mu2' not specified"),
  rho = 0, exchangeable = FALSE,
  colnames = c("00", "01", "10", "11"), ErrorCheck = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Binom2.rho_+3A_n">n</code></td>
<td>

<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
The arguments <code>mu1</code>, <code>mu2</code>, <code>rho</code> are recycled
to this value.
</p>
</td></tr>
<tr><td><code id="Binom2.rho_+3A_mu1">mu1</code>, <code id="Binom2.rho_+3A_mu2">mu2</code></td>
<td>

<p>The marginal probabilities.
Only <code>mu1</code> is needed if <code>exchangeable = TRUE</code>.
Values should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Binom2.rho_+3A_rho">rho</code></td>
<td>

<p>The correlation parameter.
Must be numeric and lie between <code class="reqn">-1</code> and <code class="reqn">1</code>.
The default value of zero means the responses are uncorrelated.
</p>
</td></tr>
<tr><td><code id="Binom2.rho_+3A_exchangeable">exchangeable</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the two marginal probabilities are
constrained to be equal.
</p>
</td></tr>
<tr><td><code id="Binom2.rho_+3A_twocols">twoCols</code></td>
<td>

<p>Logical.
If <code>TRUE</code>, then a <code class="reqn">n</code> <code class="reqn">\times</code> <code class="reqn">2</code> matrix of 1s
and 0s is returned.
If <code>FALSE</code>, then a <code class="reqn">n</code> <code class="reqn">\times</code> <code class="reqn">4</code> matrix of 1s
and 0s is returned.
</p>
</td></tr>
<tr><td><code id="Binom2.rho_+3A_colnames">colnames</code></td>
<td>

<p>The <code>dimnames</code> argument of
<code><a href="base.html#topic+matrix">matrix</a></code> is assigned
<code>list(NULL, colnames)</code>.
</p>
</td></tr>
<tr><td><code id="Binom2.rho_+3A_errorcheck">ErrorCheck</code></td>
<td>

<p>Logical. Do some error checking of the input parameters?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>rbinom2.rho</code> generates data coming from a
bivariate probit model.
The data might be fitted with the <span class="pkg">VGAM</span> family function
<code><a href="#topic+binom2.rho">binom2.rho</a></code>.
</p>
<p>The function <code>dbinom2.rho</code> does not really compute the
density (because that does not make sense here) but rather
returns the four joint probabilities.
</p>


<h3>Value</h3>

<p>The function <code>rbinom2.rho</code> returns
either a 2 or 4 column matrix of 1s and 0s, depending on the
argument <code>twoCols</code>.
</p>
<p>The function <code>dbinom2.rho</code> returns
a 4 column matrix of joint probabilities; each row adds up
to unity.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+binom2.rho">binom2.rho</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(myrho &lt;- rhobitlink(2, inverse = TRUE))  # Example 1
nn &lt;- 2000
ymat &lt;- rbinom2.rho(nn, mu1 = 0.8, rho = myrho, exch = TRUE)
(mytab &lt;- table(ymat[, 1], ymat[, 2], dnn = c("Y1", "Y2")))
fit &lt;- vglm(ymat ~ 1, binom2.rho(exch = TRUE))
coef(fit, matrix = TRUE)

bdata &lt;- data.frame(x2 = sort(runif(nn)))  # Example 2
bdata &lt;- transform(bdata, mu1 = probitlink(-2+4*x2, inv = TRUE),
                          mu2 = probitlink(-1+3*x2, inv = TRUE))
dmat &lt;- with(bdata, dbinom2.rho(mu1, mu2, myrho))
ymat &lt;- with(bdata, rbinom2.rho(nn, mu1, mu2, myrho))
fit2 &lt;- vglm(ymat ~ x2, binom2.rho, data = bdata)
coef(fit2, matrix = TRUE)
## Not run:  matplot(with(bdata, x2), dmat, lty = 1:4, col = 1:4,
        type = "l", main = "Joint probabilities",
        ylim = 0:1, lwd = 2, ylab = "Probability")
legend(x = 0.25, y = 0.9, lty = 1:4, col = 1:4, lwd = 2,
       legend = c("1 = (y1=0, y2=0)", "2 = (y1=0, y2=1)",
                  "3 = (y1=1, y2=0)", "4 = (y1=1, y2=1)")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='binomialff'> Binomial Family Function </h2><span id='topic+binomialff'></span>

<h3>Description</h3>

<p>Family function for fitting generalized linear models to binomial
responses
</p>






<h3>Usage</h3>

<pre><code class='language-R'>binomialff(link = "logitlink", multiple.responses = FALSE,
       parallel = FALSE, zero = NULL, bred = FALSE, earg.link = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomialff_+3A_link">link</code></td>
<td>

<p>Link function;
see <code><a href="#topic+Links">Links</a></code> and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>






<tr><td><code id="binomialff_+3A_multiple.responses">multiple.responses</code></td>
<td>

<p>Multivariate response? If <code>TRUE</code>, then the response is
interpreted
as <code class="reqn">M</code> independent binary responses, where <code class="reqn">M</code> is the number
of columns of the response matrix. In this case, the response matrix
should have <code class="reqn">Q</code> columns consisting of counts (successes),
and the <code>weights</code> argument should have <code class="reqn">Q</code> columns
consisting of the number of trials (successes plus failures).
</p>

<p>If <code>FALSE</code> and the response is a (2-column) matrix, then the
number of successes is given in the first column, and the second
column is the number of failures.
</p>
</td></tr>







<tr><td><code id="binomialff_+3A_parallel">parallel</code></td>
<td>

<p>A logical or formula. Used only if <code>multiple.responses</code>
is <code>TRUE</code>.  This
argument allows for the parallelism assumption whereby the regression
coefficients for a variable is constrained to be equal over the <code class="reqn">M</code>
linear/additive predictors.
If <code>parallel = TRUE</code> then the constraint is not applied to the
intercepts.
</p>
</td></tr>
<tr><td><code id="binomialff_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which linear/additive predictors
are modelled as intercepts only.  The values must be from the set
{1,2,...,<code class="reqn">M</code>}, where <code class="reqn">M</code> is the number of columns of the
matrix response.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="binomialff_+3A_earg.link">earg.link</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="binomialff_+3A_bred">bred</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
Setting <code>bred = TRUE</code> should work for
multiple responses (<code>multiple.responses = TRUE</code>) and
all <span class="pkg">VGAM</span> link functions;
it has been tested for
<code><a href="#topic+logitlink">logitlink</a></code> only (and it gives similar
results to <span class="pkg">brglm</span> but not identical),
and further testing is required.
One result from fitting bias reduced binary regression
is that finite regression coefficients occur when
the data is separable (see example below).
Currently <code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code> does not work when
<code>bred = TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is largely to
mimic <code><a href="stats.html#topic+Binomial">binomial</a></code>,
however there are some differences.
</p>











<p>When used with <code><a href="#topic+cqo">cqo</a></code> and <code><a href="#topic+cao">cao</a></code>, it may be
preferable to use the <code><a href="#topic+clogloglink">clogloglink</a></code> link.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
and <code><a href="#topic+cao">cao</a></code>.
</p>


<h3>Warning </h3>




<p>See the above note regarding <code>bred</code>.
</p>
<p>The maximum likelihood estimate will not exist if the data is
<em>completely separable</em> or <em>quasi-completely separable</em>.
See Chapter 10 of Altman et al. (2004) for more details,
and <span class="pkg">safeBinaryRegression</span>
and <code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>.
Yet to do: add a <code>sepcheck = TRUE</code>, say, argument to
further detect this problem and give an appropriate warning.
</p>


<h3>Note</h3>

<p>If <code>multiple.responses</code> is <code>FALSE</code> (default) then
the response can be of one
of two formats:
a factor (first level taken as failure),
or a 2-column matrix (first column = successes) of counts.
The argument <code>weights</code> in the modelling function can
also be specified as any vector of positive values.
In general, 1 means success and 0 means failure
(to check, see the <code>y</code> slot of the fitted object).
Note that a general vector of proportions of success is no
longer accepted.
</p>
<p>The notation <code class="reqn">M</code> is used to denote the number of linear/additive
predictors.
</p>
<p>If <code>multiple.responses</code> is <code>TRUE</code>, then the matrix response
can only be of one format: a matrix of 1's and 0's (1 = success).
</p>










<p>Fisher scoring is used. This can sometimes fail to converge by
oscillating between successive iterations (Ridout, 1990).
See the example below.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>
<p>Altman, M. and Gill, J. and McDonald, M. P. (2004).
<em>Numerical Issues in Statistical Computing for the Social
Scientist</em>, Hoboken, NJ, USA: Wiley-Interscience.
</p>
<p>Ridout, M. S. (1990).
Non-convergence of Fisher's method of scoring&mdash;a simple example.
<em>GLIM Newsletter</em>, 20(6).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+alogitlink">alogitlink</a></code>,
<code><a href="#topic+asinlink">asinlink</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+cao">cao</a></code>,
<code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+zibinomial">zibinomial</a></code>,
<code><a href="#topic+double.expbinomial">double.expbinomial</a></code>,
<code><a href="#topic+seq2binomial">seq2binomial</a></code>,
<code><a href="#topic+amlbinomial">amlbinomial</a></code>,
<code><a href="#topic+simplex">simplex</a></code>,
<code><a href="stats.html#topic+Binomial">binomial</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<span class="pkg">safeBinaryRegression</span>,
<code><a href="#topic+residualsvglm">residualsvglm</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>shunua &lt;- hunua[sort.list(with(hunua, altitude)), ]  # Sort by altitude
fit &lt;- vglm(agaaus ~ poly(altitude, 2), binomialff(link = clogloglink),
            data = shunua)
## Not run: 
plot(agaaus ~ jitter(altitude), shunua, ylab = "Pr(Agaaus = 1)",
     main = "Presence/absence of Agathis australis", col = 4, las = 1)
with(shunua, lines(altitude, fitted(fit), col = "orange", lwd = 2)) 
## End(Not run)

# Fit two species simultaneously
fit2 &lt;- vgam(cbind(agaaus, kniexc) ~ s(altitude),
             binomialff(multiple.responses = TRUE), data = shunua)
## Not run: 
with(shunua, matplot(altitude, fitted(fit2), type = "l",
     main = "Two species response curves", las = 1)) 
## End(Not run)

# Shows that Fisher scoring can sometime fail. See Ridout (1990).
ridout &lt;- data.frame(v = c(1000, 100, 10), r = c(4, 3, 3), n = rep(5, 3))
(ridout &lt;- transform(ridout, logv = log(v)))
# The iterations oscillates between two local solutions:
glm.fail &lt;- glm(r / n ~ offset(logv) + 1, weight = n,
               binomial(link = 'cloglog'), ridout, trace = TRUE)
coef(glm.fail)
# vglm()'s half-stepping ensures the MLE of -5.4007 is obtained:
vglm.ok &lt;- vglm(cbind(r, n-r) ~ offset(logv) + 1,
               binomialff(link = clogloglink), ridout, trace = TRUE)
coef(vglm.ok)

# Separable data
set.seed(123)
threshold &lt;- 0
bdata &lt;- data.frame(x2 = sort(rnorm(nn &lt;- 100)))
bdata &lt;- transform(bdata, y1 = ifelse(x2 &lt; threshold, 0, 1))
fit &lt;- vglm(y1 ~ x2, binomialff(bred = TRUE),
            data = bdata, criter = "coef", trace = TRUE)
coef(fit, matrix = TRUE)  # Finite!!
summary(fit)
## Not run:  plot(depvar(fit) ~ x2, data = bdata, col = "blue", las = 1)
lines(fitted(fit) ~ x2, data = bdata, col = "orange")
abline(v = threshold, col = "gray", lty = "dashed") 
## End(Not run)
</code></pre>

<hr>
<h2 id='Binorm'>Bivariate Normal Distribution Cumulative Distribution
Function</h2><span id='topic+Binorm'></span><span id='topic+pnorm2'></span><span id='topic+dbinorm'></span><span id='topic+pbinorm'></span><span id='topic+rbinorm'></span>

<h3>Description</h3>

<p>Density,
cumulative distribution function
and
random generation
for the bivariate normal distribution distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbinorm(x1, x2, mean1 = 0, mean2 = 0, var1 = 1, var2 = 1, cov12 = 0,
        log = FALSE)
pbinorm(q1, q2, mean1 = 0, mean2 = 0, var1 = 1, var2 = 1, cov12 = 0)
rbinorm(n,      mean1 = 0, mean2 = 0, var1 = 1, var2 = 1, cov12 = 0)
 pnorm2(x1, x2, mean1 = 0, mean2 = 0, var1 = 1, var2 = 1, cov12 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Binorm_+3A_x1">x1</code>, <code id="Binorm_+3A_x2">x2</code>, <code id="Binorm_+3A_q1">q1</code>, <code id="Binorm_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Binorm_+3A_mean1">mean1</code>, <code id="Binorm_+3A_mean2">mean2</code>, <code id="Binorm_+3A_var1">var1</code>, <code id="Binorm_+3A_var2">var2</code>, <code id="Binorm_+3A_cov12">cov12</code></td>
<td>

<p>vector of means, variances and the covariance.
</p>

</td></tr>



<tr><td><code id="Binorm_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+rnorm">rnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Binorm_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>



</table>


<h3>Details</h3>

<p>The default arguments correspond to the standard bivariate normal
distribution with correlation parameter <code class="reqn">\rho = 0</code>.
That is, two independent standard normal distributions.
Let <code>sd1</code> (say) be <code>sqrt(var1)</code> and
written <code class="reqn">\sigma_1</code>, etc.
Then the general formula for the correlation coefficient is
<code class="reqn">\rho = cov / (\sigma_1 \sigma_2)</code>
where <code class="reqn">cov</code> is argument <code>cov12</code>.
Thus if arguments <code>var1</code> and <code>var2</code> are left alone then
<code>cov12</code> can be inputted with <code class="reqn">\rho</code>.
</p>
<p>One can think of this function as an extension of
<code><a href="stats.html#topic+pnorm">pnorm</a></code> to two dimensions, however note
that the argument names have been changed for <span class="pkg">VGAM</span>
0.9-1 onwards.
</p>


<h3>Value</h3>

<p><code>dbinorm</code> gives the density,
<code>pbinorm</code> gives the cumulative distribution function,
<code>rbinorm</code> generates random deviates (<code class="reqn">n</code> by 2 matrix).
</p>



<h3>Warning</h3>

<p>Being based on an approximation, the results of <code>pbinorm()</code>
may be negative!
Also,
<code>pnorm2()</code> should be withdrawn soon;
use <code>pbinorm()</code> instead because it is identical.
</p>







<h3>Note</h3>

<p>For <code>rbinorm()</code>,
if the <code class="reqn">i</code>th variance-covariance matrix is not
positive-definite then the <code class="reqn">i</code>th row is all <code>NA</code>s.
</p>


<h3>References</h3>

<p><code>pbinorm()</code> is
based on Donnelly (1973),
the code was translated from FORTRAN to ratfor using struct, and
then from ratfor to C manually.
The function was originally called <code>bivnor</code>, and TWY only
wrote a wrapper function.
</p>
<p>Donnelly, T. G. (1973).
Algorithm 462: Bivariate Normal Distribution.
<em>Communications of the ACM</em>,
<b>16</b>, 638.
</p>






<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code>,
<code><a href="#topic+binormal">binormal</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>yvec &lt;- c(-5, -1.96, 0, 1.96, 5)
ymat &lt;- expand.grid(yvec, yvec)
cbind(ymat, pbinorm(ymat[, 1], ymat[, 2]))

## Not run:  rhovec &lt;- seq(-0.95, 0.95, by = 0.01)
plot(rhovec, pbinorm(0, 0, cov12 = rhovec),
     type = "l", col = "blue", las = 1)
abline(v = 0, h = 0.25, col = "gray", lty = "dashed") 
## End(Not run)
</code></pre>

<hr>
<h2 id='binormal'> Bivariate Normal Distribution Family Function </h2><span id='topic+binormal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the five parameters of a
bivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binormal(lmean1 = "identitylink", lmean2 = "identitylink",
         lsd1   = "loglink",     lsd2   = "loglink",
         lrho   = "rhobitlink",
         imean1 = NULL,       imean2 = NULL,
         isd1   = NULL,       isd2   = NULL,
         irho   = NULL,       imethod = 1,
         eq.mean = FALSE,     eq.sd = FALSE,
         zero = c("sd", "rho"), rho.arg = NA)


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binormal_+3A_lmean1">lmean1</code>, <code id="binormal_+3A_lmean2">lmean2</code>, <code id="binormal_+3A_lsd1">lsd1</code>, <code id="binormal_+3A_lsd2">lsd2</code>, <code id="binormal_+3A_lrho">lrho</code></td>
<td>

<p>Link functions applied to the means, standard deviations and
<code>rho</code> parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
Being positive quantities, a log link is the default for the
standard deviations.
</p>
</td></tr>
<tr><td><code id="binormal_+3A_imean1">imean1</code>, <code id="binormal_+3A_imean2">imean2</code>, <code id="binormal_+3A_isd1">isd1</code>, <code id="binormal_+3A_isd2">isd2</code>, <code id="binormal_+3A_irho">irho</code>, <code id="binormal_+3A_imethod">imethod</code>, <code id="binormal_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="binormal_+3A_eq.mean">eq.mean</code>, <code id="binormal_+3A_eq.sd">eq.sd</code></td>
<td>

<p>Logical or formula.
Constrains the means or the standard deviations to be equal.
</p>


</td></tr>

<tr><td><code id="binormal_+3A_rho.arg">rho.arg</code></td>
<td>

<p>If <code class="reqn">\rho</code> is known then this argument may
be assigned the (scalar) value lying in <code class="reqn">(-1, 1)</code>.
The default is to estimate that parameter so that <code class="reqn">M=5</code>.
If known, then other arguments such as <code>lrho</code>
and <code>irho</code> are ignored,
and <code>"rho"</code> is removed from <code>zero</code>.
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>For the bivariate normal distribution,
this fits a linear model (LM) to the means, and
by default,
the other parameters are intercept-only.
The response should be a two-column matrix.
The correlation parameter is <code>rho</code>,
which lies between <code class="reqn">-1</code> and <code class="reqn">1</code>
(thus the <code><a href="#topic+rhobitlink">rhobitlink</a></code> link is a reasonable choice).
The fitted means are returned as the fitted values, which is in
the form of a two-column matrix.
Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This function may be renamed to <code>normal2()</code> or
something like that
at a later date.
</p>


<h3>Note</h3>

<p>If both equal means and equal standard deviations are desired
then use something like
<code>constraints = list("(Intercept)" = </code>
<code>matrix(c(1,1,0,0,0, 0,0,1,1,0 ,0,0,0,0,1), 5, 3))</code>
and maybe
<code>zero = NULL</code>
etc.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+trinormal">trinormal</a></code>,
<code><a href="#topic+pbinorm">pbinorm</a></code>,
<code><a href="#topic+bistudentt">bistudentt</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123); nn &lt;- 1000
bdata &lt;- data.frame(x2 = runif(nn), x3 = runif(nn))
bdata &lt;- transform(bdata, y1 = rnorm(nn, 1 + 2 * x2),
                          y2 = rnorm(nn, 3 + 4 * x2))
fit1 &lt;- vglm(cbind(y1, y2) ~ x2,
             binormal(eq.sd = TRUE), data = bdata, trace = TRUE)
coef(fit1, matrix = TRUE)
constraints(fit1)
summary(fit1)

# Estimated P(Y1 &lt;= y1, Y2 &lt;= y2) under the fitted model
var1  &lt;- loglink(2 * predict(fit1)[, "loglink(sd1)"], inv = TRUE)
var2  &lt;- loglink(2 * predict(fit1)[, "loglink(sd2)"], inv = TRUE)
cov12 &lt;- rhobitlink(predict(fit1)[, "rhobitlink(rho)"], inv = TRUE)
head(with(bdata, pbinorm(y1, y2,
                         mean1 = predict(fit1)[, "mean1"],
                         mean2 = predict(fit1)[, "mean2"],
                         var1 = var1, var2 = var2, cov12 = cov12)))
</code></pre>

<hr>
<h2 id='binormalcop'> Gaussian Copula (Bivariate) Family Function </h2><span id='topic+binormalcop'></span>

<h3>Description</h3>

<p>Estimate the correlation parameter of
the (bivariate) Gaussian copula
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binormalcop(lrho = "rhobitlink", irho = NULL, imethod = 1,
            parallel = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binormalcop_+3A_lrho">lrho</code>, <code id="binormalcop_+3A_irho">irho</code>, <code id="binormalcop_+3A_imethod">imethod</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
See <code><a href="#topic+Links">Links</a></code> for more link function choices.
</p>
</td></tr>
<tr><td><code id="binormalcop_+3A_parallel">parallel</code>, <code id="binormalcop_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
If <code>parallel = TRUE</code> then the constraint is applied to
the intercept too.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = \Phi_2
             ( \Phi^{-1}(y_1), \Phi^{-1}(y_2); \rho ) </code>
</p>

<p>for <code class="reqn">-1 &lt; \rho &lt; 1</code>,
<code class="reqn">\Phi_2</code> is the cumulative distribution function
of a standard bivariate normal
(see <code><a href="#topic+pbinorm">pbinorm</a></code>),
and <code class="reqn">\Phi</code> is the cumulative distribution function
of a standard univariate normal
(see <code><a href="stats.html#topic+pnorm">pnorm</a></code>).
</p>
<p>The support of the function is the interior of the unit square;
however, values of 0 and/or 1 are not allowed.
The marginal distributions are the standard uniform
distributions.  When <code class="reqn">\rho = 0</code> the random variables
are independent.
</p>
<p>This <span class="pkg">VGAM</span> family function can handle multiple responses,
for example, a six-column matrix where the first 2 columns
is the first out of three responses,
the next 2 columns being the next response, etc.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response matrix must have a multiple of two-columns.
Currently, the fitted
value is a matrix with the same number of
columns and values equal to 0.5.
This is because each marginal distribution
corresponds to a standard
uniform distribution.
</p>
<p>This <span class="pkg">VGAM</span> family function is fragile;
each response must be in the interior of the unit square.
Setting <code>crit = "coef"</code> is sometimes a
good idea because
inaccuracies in <code><a href="#topic+pbinorm">pbinorm</a></code> might mean
unnecessary half-stepping will occur near the solution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Schepsmeier, U. and Stober, J. (2014).
Derivatives and Fisher information of bivariate copulas.
<em>Statistical Papers</em>
<b>55</b>, 525&ndash;542.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbinormcop">rbinormcop</a></code>,
<code><a href="stats.html#topic+pnorm">pnorm</a></code>,
<code><a href="#topic+kendall.tau">kendall.tau</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
ymat &lt;- rbinormcop(nn, rho = rhobitlink(-0.9, inverse = TRUE))
bdata &lt;- data.frame(y1 = ymat[, 1], y2 = ymat[, 2],
                    y3 = ymat[, 1], y4 = ymat[, 2],
                    x2 = runif(nn))
summary(bdata)
## Not run:  plot(ymat, col = "blue") 
fit1 &lt;-  # 2 responses, e.g., (y1,y2) is the 1st
  vglm(cbind(y1, y2, y3, y4) ~ 1, fam = binormalcop,
       crit = "coef",  # Sometimes a good idea
       data = bdata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
head(fitted(fit1))
summary(fit1)

# Another example; rho is a linear function of x2
bdata &lt;- transform(bdata, rho = -0.5 + x2)
ymat &lt;- rbinormcop(n = nn, rho = with(bdata, rho))
bdata &lt;- transform(bdata, y5 = ymat[, 1], y6 = ymat[, 2])
fit2 &lt;- vgam(cbind(y5, y6) ~ s(x2), data = bdata,
             binormalcop(lrho = "identitylink"), trace = TRUE)
## Not run: plot(fit2, lcol = "blue", scol = "orange", se = TRUE)
</code></pre>

<hr>
<h2 id='Binormcop'>Gaussian Copula (Bivariate) Distribution</h2><span id='topic+Binormcop'></span><span id='topic+dbinormcop'></span><span id='topic+pbinormcop'></span><span id='topic+rbinormcop'></span>

<h3>Description</h3>

<p>Density, distribution function,
and random generation
for the (one parameter) bivariate
Gaussian copula distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbinormcop(x1, x2, rho = 0, log = FALSE)
pbinormcop(q1, q2, rho = 0)
rbinormcop(n, rho = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Binormcop_+3A_x1">x1</code>, <code id="Binormcop_+3A_x2">x2</code>, <code id="Binormcop_+3A_q1">q1</code>, <code id="Binormcop_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.
The <code>x1</code> and <code>x2</code> should be in the interval
<code class="reqn">(0,1)</code>.  Ditto for <code>q1</code> and <code>q2</code>.
</p>
</td></tr>
<tr><td><code id="Binormcop_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+rnorm">rnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Binormcop_+3A_rho">rho</code></td>
<td>
<p>the correlation parameter.
Should be in the interval <code class="reqn">(-1,1)</code>.
</p>
</td></tr>
<tr><td><code id="Binormcop_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm is returned.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+binormalcop">binormalcop</a></code>, the <span class="pkg">VGAM</span>
family functions for estimating the
parameter by maximum likelihood estimation,
for the formula of the
cumulative distribution function and other details.
</p>


<h3>Value</h3>

<p><code>dbinormcop</code> gives the density,
<code>pbinormcop</code> gives the distribution function, and
<code>rbinormcop</code> generates random deviates (a two-column matrix).
</p>


<h3>Note</h3>

<p>Yettodo: allow <code>x1</code> and/or <code>x2</code> to have values 1,
and to allow any values for <code>x1</code> and/or <code>x2</code> to be
outside the unit square.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+binormalcop">binormalcop</a></code>,
<code><a href="#topic+binormal">binormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  edge &lt;- 0.01  # A small positive value
N &lt;- 101; x &lt;- seq(edge, 1.0 - edge, len = N); Rho &lt;- 0.7
ox &lt;- expand.grid(x, x)
zedd &lt;- dbinormcop(ox[, 1], ox[, 2], rho = Rho, log = TRUE)
contour(x, x, matrix(zedd, N, N), col = "blue", labcex = 1.5)
zedd &lt;- pbinormcop(ox[, 1], ox[, 2], rho = Rho)
contour(x, x, matrix(zedd, N, N), col = "blue", labcex = 1.5)

## End(Not run)
</code></pre>

<hr>
<h2 id='Biplackett'>Plackett's Bivariate Copula </h2><span id='topic+Biplackett'></span><span id='topic+dbiplackcop'></span><span id='topic+pbiplackcop'></span><span id='topic+rbiplackcop'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the (one parameter) bivariate Plackett copula.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dbiplackcop(x1, x2, oratio, log = FALSE)
pbiplackcop(q1, q2, oratio)
rbiplackcop(n, oratio)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Biplackett_+3A_x1">x1</code>, <code id="Biplackett_+3A_x2">x2</code>, <code id="Biplackett_+3A_q1">q1</code>, <code id="Biplackett_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Biplackett_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Biplackett_+3A_oratio">oratio</code></td>
<td>
<p>the positive odds ratio <code class="reqn">\psi</code>.</p>
</td></tr>
<tr><td><code id="Biplackett_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+biplackettcop">biplackettcop</a></code>, the <span class="pkg">VGAM</span>
family functions for estimating the
parameter by maximum likelihood estimation, for the formula of
the cumulative distribution function and other details.
</p>


<h3>Value</h3>

<p><code>dbiplackcop</code> gives the density,
<code>pbiplackcop</code> gives the distribution function, and
<code>rbiplackcop</code> generates random deviates (a two-column
matrix).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Mardia, K. V. (1967).
Some contributions to contingency-type distributions.
<em>Biometrika</em>,
<b>54</b>, 235&ndash;249.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+biplackettcop">biplackettcop</a></code>,
<code><a href="#topic+bifrankcop">bifrankcop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  N &lt;- 101; oratio &lt;- exp(1)
x &lt;- seq(0.0, 1.0, len = N)
ox &lt;- expand.grid(x, x)
zedd &lt;- dbiplackcop(ox[, 1], ox[, 2], oratio = oratio)
contour(x, x, matrix(zedd, N, N), col = "blue")
zedd &lt;- pbiplackcop(ox[, 1], ox[, 2], oratio = oratio)
contour(x, x, matrix(zedd, N, N), col = "blue")

plot(rr &lt;- rbiplackcop(n = 3000, oratio = oratio))
par(mfrow = c(1, 2))
hist(rr[, 1])  # Should be uniform
hist(rr[, 2])  # Should be uniform

## End(Not run)
</code></pre>

<hr>
<h2 id='biplackettcop'> Plackett's Bivariate Copula Family Function </h2><span id='topic+biplackettcop'></span>

<h3>Description</h3>

<p>Estimate the association parameter of Plackett's bivariate
distribution (copula)
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biplackettcop(link = "loglink", ioratio = NULL, imethod = 1,
              nsimEIM = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biplackettcop_+3A_link">link</code></td>
<td>

<p>Link function applied to the (positive) odds ratio <code class="reqn">\psi</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices
and information.
</p>
</td></tr>
<tr><td><code id="biplackettcop_+3A_ioratio">ioratio</code></td>
<td>

<p>Numeric. Optional initial value for <code class="reqn">\psi</code>.
If a convergence failure occurs try assigning a value or a
different value.
</p>
</td></tr>
<tr><td><code id="biplackettcop_+3A_imethod">imethod</code>, <code id="biplackettcop_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The defining equation is
</p>
<p style="text-align: center;"><code class="reqn">\psi = H \times (1-y_1-y_2+H) / ((y_1-H) \times (y_2-H))</code>
</p>

<p>where
<code class="reqn">P(Y_1 \leq y_1, Y_2 \leq y_2) = H_{\psi}(y_1,y_2)</code>
is the cumulative distribution function.
The density function is <code class="reqn">h_{\psi}(y_1,y_2) =</code>
</p>
<p style="text-align: center;"><code class="reqn">\psi [1 + (\psi-1)(y_1 + y_2 - 2 y_1 y_2) ] / \left(
                     [1 + (\psi-1)(y_1 + y_2) ]^2 - 4 \psi
              (\psi-1) y_1 y_2 \right)^{3/2}</code>
</p>

<p>for <code class="reqn">\psi &gt; 0</code>.
Some writers call <code class="reqn">\psi</code> the <em>cross product ratio</em>
but it is called the <em>odds ratio</em> here.
The support of the function is the unit square.
The marginal distributions here are the standard uniform although
it is commonly generalized to other distributions.
</p>
<p>If <code class="reqn">\psi = 1</code> then
<code class="reqn">h_{\psi}(y_1,y_2) = y_1 y_2</code>,
i.e., independence.
As the odds ratio tends to infinity one has <code class="reqn">y_1=y_2</code>.
As the odds ratio tends to 0 one has <code class="reqn">y_2=1-y_1</code>.
</p>
<p>Fisher scoring is implemented using <code><a href="#topic+rbiplackcop">rbiplackcop</a></code>.
Convergence is often quite slow.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix.  Currently, the fitted
value is a 2-column matrix with 0.5 values because the marginal
distributions correspond to a standard uniform distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Plackett, R. L. (1965).
A class of bivariate distributions.
<em>Journal of the American Statistical Association</em>,
<b>60</b>, 516&ndash;522.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbiplackcop">rbiplackcop</a></code>,
<code><a href="#topic+bifrankcop">bifrankcop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ymat &lt;- rbiplackcop(n = 2000, oratio = exp(2))
plot(ymat, col = "blue")
fit &lt;- vglm(ymat ~ 1, fam = biplackettcop, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
vcov(fit)
head(fitted(fit))
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='biplot-methods'> Biplot of Constrained Regression Models </h2><span id='topic+biplot+2Crrvglm-method'></span><span id='topic+biplot+2Cqrrvglm-method'></span>

<h3>Description</h3>

<p><code>biplot</code> is a generic function applied to RR-VGLMs and
QRR-VGLMs etc.  These apply to rank-1 and rank-2 models of
these only.  For RR-VGLMs these plot the second latent variable
scores against the first latent variable scores.
</p>


<h3>Methods</h3>


<dl>
<dt>x</dt><dd>
<p>The object from which the latent variables are
extracted and/or plotted.
</p>
</dd>
</dl>



<h3>Note</h3>

<p>See <code><a href="#topic+lvplot">lvplot</a></code> which is very much related to biplots.
</p>

<hr>
<h2 id='bisa'> Birnbaum-Saunders Regression Family Function </h2><span id='topic+bisa'></span>

<h3>Description</h3>

<p>Estimates the shape and scale parameters of the
Birnbaum-Saunders distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bisa(lscale = "loglink", lshape = "loglink", iscale = 1,
     ishape = NULL, imethod = 1, zero = "shape", nowarning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bisa_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning?
Ignored for <span class="pkg">VGAM</span> 0.9-7 and higher.
</p>
</td></tr>
<tr><td><code id="bisa_+3A_lscale">lscale</code>, <code id="bisa_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions applied to the shape and
scale parameters
(<code class="reqn">a</code> and <code class="reqn">b</code> below).
See <code><a href="#topic+Links">Links</a></code> for more choices.
A log link is the default for both because they are positive.
</p>
</td></tr>
<tr><td><code id="bisa_+3A_iscale">iscale</code>, <code id="bisa_+3A_ishape">ishape</code></td>
<td>

<p>Initial values for <code class="reqn">a</code> and <code class="reqn">b</code>.
A <code>NULL</code> means an initial value is chosen internally using
<code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="bisa_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> or <code>3</code> which
specifies the initialization method. If failure to
converge occurs
try the other value, or else specify a value for
<code>ishape</code> and/or <code>iscale</code>.
</p>
</td></tr>
<tr><td><code id="bisa_+3A_zero">zero</code></td>
<td>

<p>Specifies which linear/additive predictor is
modelled as intercept-only.
If used, choose one value from the set {1,2}.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>The (two-parameter) Birnbaum-Saunders distribution
has a cumulative distribution function that can be written as
</p>
<p style="text-align: center;"><code class="reqn">F(y;a,b) = \Phi[ \xi(y/b)/a] </code>
</p>

<p>where <code class="reqn">\Phi(\cdot)</code> is the
cumulative distribution function of a standard normal
(see <code><a href="stats.html#topic+Normal">pnorm</a></code>),
<code class="reqn">\xi(t) =
    \sqrt{t} - 1 / \sqrt{t}</code>,
<code class="reqn">y &gt; 0</code>,
<code class="reqn">a&gt;0</code> is the shape parameter,
<code class="reqn">b&gt;0</code> is the scale parameter.
The mean of <code class="reqn">Y</code> (which is the fitted value) is
<code class="reqn">b(1 + a^2/2)</code>.
and the variance is
<code class="reqn">a^2 b^2 (1 + \frac{5}{4}a^2)</code>.
By default, <code class="reqn">\eta_1 = \log(a)</code> and
<code class="reqn">\eta_2 = \log(b)</code> for this
family function.
</p>
<p>Note that <code class="reqn">a</code> and <code class="reqn">b</code> are orthogonal,
i.e., the Fisher information matrix is diagonal.
This family function implements Fisher scoring, and
it is unnecessary to compute any integrals numerically.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Lemonte, A. J. and Cribari-Neto, F. and
Vasconcellos, K. L. P. (2007).
Improved statistical inference for the two-parameter
Birnbaum-Saunders distribution.
<em>Computational Statistics &amp; Data Analysis</em>,
<b>51</b>, 4656&ndash;4681.
</p>
<p>Birnbaum, Z. W. and Saunders, S. C. (1969).
A new family of life distributions.
<em>Journal of Applied Probability</em>, <b>6</b>, 319&ndash;327.
</p>
<p>Birnbaum, Z. W. and Saunders, S. C. (1969).
Estimation for a family of life distributions with
applications to fatigue.
<em>Journal of Applied Probability</em>, <b>6</b>, 328&ndash;347.
</p>
<p>Engelhardt, M. and Bain, L. J. and Wright, F. T. (1981).
Inferences on the parameters of the Birnbaum-Saunders fatigue
life distribution based on maximum likelihood estimation.
<em>Technometrics</em>, <b>23</b>, 251&ndash;256.
</p>
<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1995).
<em>Continuous Univariate Distributions</em>,
2nd edition,
Volume 2,
New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pbisa">pbisa</a></code>,
<code><a href="#topic+inv.gaussianff">inv.gaussianff</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bdata1 &lt;- data.frame(x2 = runif(nn &lt;- 1000))
bdata1 &lt;- transform(bdata1, shape = exp(-0.5 + x2),
                            scale = exp(1.5))
bdata1 &lt;- transform(bdata1, y = rbisa(nn, scale, shape))
fit1 &lt;- vglm(y ~ x2, bisa(zero = 1), data = bdata1, trace = TRUE)
coef(fit1, matrix = TRUE)

## Not run: 
bdata2 &lt;- data.frame(shape = exp(-0.5), scale = exp(0.5))
bdata2 &lt;- transform(bdata2, y = rbisa(nn, scale, shape))
fit &lt;- vglm(y ~ 1, bisa, data = bdata2, trace = TRUE)
with(bdata2, hist(y, prob = TRUE, ylim = c(0, 0.5),
                  col = "lightblue"))
coef(fit, matrix = TRUE)
with(bdata2, mean(y))
head(fitted(fit))
x &lt;- with(bdata2, seq(0, max(y), len = 200))
lines(dbisa(x, Coef(fit)[1], Coef(fit)[2]) ~ x, data = bdata2,
      col = "orange", lwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Bisa'>The Birnbaum-Saunders Distribution</h2><span id='topic+Bisa'></span><span id='topic+dbisa'></span><span id='topic+pbisa'></span><span id='topic+qbisa'></span><span id='topic+rbisa'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the Birnbaum-Saunders distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbisa(x, scale = 1, shape, log = FALSE)
pbisa(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qbisa(p, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
rbisa(n, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bisa_+3A_x">x</code>, <code id="Bisa_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Bisa_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Bisa_+3A_n">n</code></td>
<td>

<p>Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Bisa_+3A_scale">scale</code>, <code id="Bisa_+3A_shape">shape</code></td>
<td>

<p>the (positive) scale and shape parameters.
</p>
</td></tr>
<tr><td><code id="Bisa_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Bisa_+3A_lower.tail">lower.tail</code>, <code id="Bisa_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Birnbaum-Saunders distribution
is a distribution which is used in survival analysis.
See <code><a href="#topic+bisa">bisa</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for more details.
</p>


<h3>Value</h3>

<p><code>dbisa</code> gives the density,
<code>pbisa</code> gives the distribution function, and
<code>qbisa</code> gives the quantile function, and
<code>rbisa</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee  and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+bisa">bisa</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(0, 6, len = 400)
plot(x, dbisa(x, shape = 1), type = "l", col = "blue",
     ylab = "Density", lwd = 2, ylim = c(0,1.3), lty = 3,
     main = "X ~ Birnbaum-Saunders(shape, scale = 1)")
lines(x, dbisa(x, shape = 2), col = "orange", lty = 2, lwd = 2)
lines(x, dbisa(x, shape = 0.5), col = "green", lty = 1, lwd = 2)
legend(x = 3, y = 0.9, legend = paste("shape  = ",c(0.5, 1,2)),
       col = c("green","blue","orange"), lty = 1:3, lwd = 2)

shape &lt;- 1; x &lt;- seq(0.0, 4, len = 401)
plot(x, dbisa(x, shape = shape), type = "l", col = "blue",
     main = "Blue is density, orange is the CDF", las = 1,
     sub = "Red lines are the 10,20,...,90 percentiles",
     ylab = "", ylim = 0:1)
abline(h = 0, col = "blue", lty = 2)
lines(x, pbisa(x, shape = shape), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qbisa(probs, shape = shape)
lines(Q, dbisa(Q, shape = shape), col = "red", lty = 3, type = "h")
pbisa(Q, shape = shape) - probs  # Should be all zero
abline(h = probs, col = "red", lty = 3)
lines(Q, pbisa(Q, shape = shape), col = "red", lty = 3, type = "h")

## End(Not run)
</code></pre>

<hr>
<h2 id='bistudentt'> Bivariate Student-t Family Function </h2><span id='topic+bistudentt'></span>

<h3>Description</h3>

<p>Estimate the degrees of freedom and correlation parameters of
the (bivariate) Student-t distribution by maximum likelihood
estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bistudentt(ldf = "logloglink", lrho = "rhobitlink",
           idf = NULL, irho = NULL, imethod = 1,
           parallel = FALSE, zero = "rho")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bistudentt_+3A_ldf">ldf</code>, <code id="bistudentt_+3A_lrho">lrho</code>, <code id="bistudentt_+3A_idf">idf</code>, <code id="bistudentt_+3A_irho">irho</code>, <code id="bistudentt_+3A_imethod">imethod</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
See <code><a href="#topic+Links">Links</a></code> for more link function choices.
</p>
</td></tr>
<tr><td><code id="bistudentt_+3A_parallel">parallel</code>, <code id="bistudentt_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y_1, y_2; \nu, \rho) =
        \frac{1}{2\pi\sqrt{1-\rho^2}}
        (1 + (y_1^2 + y_2^2 -
        2\rho y_1 y_2) / (\nu (1-\rho^2)))^{-(\nu+2)/2} </code>
</p>

<p>for <code class="reqn">-1 &lt; \rho &lt; 1</code>,
and real <code class="reqn">y_1</code> and <code class="reqn">y_2</code>.
</p>






<p>This <span class="pkg">VGAM</span> family function can handle multiple responses,
for example, a six-column matrix where the first 2 columns
is the first out of three responses,
the next 2 columns being the next response, etc.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The working weight matrices have not been fully checked.
</p>


<h3>Note</h3>

<p>The response matrix must have a multiple of two-columns.
Currently, the fitted
value is a matrix with the same number of columns and values
equal to 0.0.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee,
with help from Thibault Vatter.
</p>


<h3>References</h3>

<p>Schepsmeier, U. and Stober, J. (2014).
Derivatives and Fisher information of bivariate copulas.
<em>Statistical Papers</em>
<b>55</b>, 525&ndash;542.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbistudentt">dbistudentt</a></code>,
<code><a href="#topic+binormal">binormal</a></code>,
<code><a href="stats.html#topic+pt">pt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
mydof &lt;- logloglink(1, inverse = TRUE)
ymat &lt;- cbind(rt(nn, df = mydof), rt(nn, df = mydof))
bdata &lt;- data.frame(y1 = ymat[, 1], y2 = ymat[, 2],
                    y3 = ymat[, 1], y4 = ymat[, 2],
                    x2 = runif(nn))
summary(bdata)
## Not run:  plot(ymat, col = "blue") 
fit1 &lt;-    # 2 responses, e.g., (y1,y2) is the 1st
  vglm(cbind(y1, y2, y3, y4) ~ 1,
       bistudentt,  # crit = "coef",  # Sometimes a good idea
       data = bdata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
head(fitted(fit1))
summary(fit1)
</code></pre>

<hr>
<h2 id='Bistudentt'>Bivariate Student-t Distribution Density
Function</h2><span id='topic+Bistudentt'></span><span id='topic+dbistudentt'></span>

<h3>Description</h3>

<p>Density
for the bivariate Student-t distribution.
</p>






<h3>Usage</h3>

<pre><code class='language-R'>dbistudentt(x1, x2, df, rho = 0, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bistudentt_+3A_x1">x1</code>, <code id="Bistudentt_+3A_x2">x2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Bistudentt_+3A_df">df</code>, <code id="Bistudentt_+3A_rho">rho</code></td>
<td>

<p>vector of degrees of freedom and correlation parameter.
For <code>df</code>, a value <code>Inf</code> is currently not working.
</p>

</td></tr>



<tr><td><code id="Bistudentt_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>



</table>


<h3>Details</h3>

















<p>One can think of this function as an extension of
<code><a href="stats.html#topic+dt">dt</a></code> to two dimensions.
See <code><a href="#topic+bistudentt">bistudentt</a></code> for more information.
</p>


<h3>Value</h3>

<p><code>dbistudentt</code> gives the density.
</p>






<h3>See Also</h3>

<p><code><a href="#topic+bistudentt">bistudentt</a></code>,
<code><a href="stats.html#topic+dt">dt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  N &lt;- 101; x &lt;- seq(-4, 4, len = N); Rho &lt;- 0.7
mydf &lt;- 10; ox &lt;- expand.grid(x, x)
zedd &lt;- dbistudentt(ox[, 1], ox[, 2], df = mydf,
                    rho = Rho, log = TRUE)
contour(x, x, matrix(zedd, N, N), col = "blue", labcex = 1.5)

## End(Not run)</code></pre>

<hr>
<h2 id='bmi.nz'> Body Mass Index of New Zealand Adults Data</h2><span id='topic+bmi.nz'></span>

<h3>Description</h3>

<p>The body mass indexes and ages from an approximate random
sample of 700 New Zealand adults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bmi.nz)</code></pre>


<h3>Format</h3>

<p>A data frame with 700 observations on the following 2 variables.
</p>

<dl>
<dt>age</dt><dd><p>a numeric vector; their age (years). </p>
</dd>
<dt>BMI</dt><dd><p>a numeric vector; their body mass indexes, which is
their weight divided by the square of their height
(kg / <code class="reqn">m^2</code>).</p>
</dd>
</dl>



<h3>Details</h3>

<p>They are a random sample from the Fletcher Challenge/Auckland
Heart and Health survey conducted in the early 1990s.
</p>
<p>There are some outliers in the data set.
</p>
<p>A variable <code>gender</code> would be useful, and may be added later.
</p>


<h3>Source</h3>

<p>Formerly the
Clinical Trials Research Unit, University of Auckland, New
Zealand.    
</p>



<h3>References</h3>

<p>MacMahon, S., Norton, R., Jackson, R., Mackie, M. J.,
Cheng, A., Vander Hoorn, S., Milne, A., McCulloch, A. (1995)
Fletcher Challenge-University of Auckland Heart &amp;
Health Study: design and baseline findings.
<em>New Zealand Medical Journal</em>,
<b>108</b>, 499&ndash;502.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  with(bmi.nz, plot(age, BMI, col = "blue"))
fit &lt;- vgam(BMI ~ s(age, df = c(2, 4, 2)), lms.yjn,
            data = bmi.nz, trace = TRUE)
qtplot(fit, pcol = "blue", tcol = "brown", lcol = "brown") 
## End(Not run)
</code></pre>

<hr>
<h2 id='borel.tanner'>Borel-Tanner Distribution Family Function</h2><span id='topic+borel.tanner'></span>

<h3>Description</h3>

<p>Estimates the parameter of a Borel-Tanner distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>borel.tanner(Qsize = 1, link = "logitlink", imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="borel.tanner_+3A_qsize">Qsize</code></td>
<td>

<p>A positive integer.
It is called <code class="reqn">Q</code> below and is the initial queue size.
The default value <code class="reqn">Q = 1</code> corresponds to the Borel
distribution.
</p>
</td></tr>
<tr><td><code id="borel.tanner_+3A_link">link</code></td>
<td>

<p>Link function for the parameter;
see <code><a href="#topic+Links">Links</a></code> for more choices and for general
information.
</p>
</td></tr>
<tr><td><code id="borel.tanner_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
Valid values are 1, 2, 3 or 4.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Borel-Tanner distribution (Tanner, 1953) describes the
distribution of the total number of customers served before a
queue vanishes given a single queue with random arrival times
of customers (at a constant rate <code class="reqn">r</code> per unit time, and
each customer taking a constant time <code class="reqn">b</code> to be served).
Initially the queue has <code class="reqn">Q</code> people and the first one starts
to be served.
The two parameters appear in the density only in the form of the
product <code class="reqn">rb</code>, therefore we use <code class="reqn">a=rb</code>, say, to denote
the single parameter to be estimated.  The density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y;a) =
  \frac{ Q }{(y-Q)!} y^{y-Q-1} a^{y-Q}  \exp(-ay)
  </code>
</p>

<p>where <code class="reqn">y=Q,Q+1,Q+2,\ldots</code>.
The case <code class="reqn">Q=1</code> corresponds to the <em>Borel</em> distribution
(Borel, 1942).
For the <code class="reqn">Q=1</code> case it is necessary for <code class="reqn">0 &lt; a &lt; 1</code> for the
distribution to be proper.
The Borel distribution is a basic Lagrangian distribution of the
first kind.
The Borel-Tanner distribution is an <code class="reqn">Q</code>-fold convolution of the
Borel distribution.
</p>
<p>The mean is <code class="reqn">Q/(1-a)</code> (returned as the fitted values) and the
variance is <code class="reqn">Q a / (1-a)^3</code>.
The distribution has a very long tail unless <code class="reqn">a</code> is small.
Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Tanner, J. C. (1953).
A problem of interference between two queues.
<em>Biometrika</em>, <b>40</b>, 58&ndash;69.
</p>
<p>Borel, E. (1942).
Sur l'emploi du theoreme de Bernoulli pour faciliter le
calcul d'une infinite de coefficients.
Application au probleme de l'attente a un guichet.
<em>Comptes Rendus, Academie des Sciences, Paris, Series A</em>,
<b>214</b>, 452&ndash;456.
</p>
<p>Johnson N. L., Kemp, A. W. and Kotz S. (2005).
<em>Univariate Discrete Distributions</em>,
3rd edition,
p.328.
Hoboken, New Jersey: Wiley.
</p>
<p>Consul, P. C. and Famoye, F. (2006).
<em>Lagrangian Probability Distributions</em>,
Boston, MA, USA: Birkhauser.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rbort">rbort</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+felix">felix</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bdata &lt;- data.frame(y = rbort(n &lt;- 200))
fit &lt;- vglm(y ~ 1, borel.tanner, bdata, trace = TRUE, crit = "c")
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Bort'>The Borel-Tanner Distribution</h2><span id='topic+Bort'></span><span id='topic+dbort'></span><span id='topic+rbort'></span>

<h3>Description</h3>

<p>Density
and random generation for the Borel-Tanner distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dbort(x, Qsize = 1, a = 0.5, log = FALSE)
rbort(n, Qsize = 1, a = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bort_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>

<tr><td><code id="Bort_+3A_n">n</code></td>
<td>
<p>number of observations.
Must be a positive integer of length 1.</p>
</td></tr>
<tr><td><code id="Bort_+3A_qsize">Qsize</code>, <code id="Bort_+3A_a">a</code></td>
<td>

<p>See <code><a href="#topic+borel.tanner">borel.tanner</a></code>.
</p>
</td></tr>
<tr><td><code id="Bort_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+borel.tanner">borel.tanner</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter,
for the formula of the probability density function and other
details.
</p>


<h3>Value</h3>

<p><code>dbort</code> gives the density,
<code>rbort</code> generates random deviates.
</p>




<h3>Warning </h3>

<p>Looping is used for <code><a href="#topic+rbort">rbort</a></code>, therefore
values of <code>a</code> close to 1 will result in long (or infinite!)
computational times.
The default value of <code>a</code> is subjective.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+borel.tanner">borel.tanner</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  qsize &lt;- 1; a &lt;- 0.5; x &lt;- qsize:(qsize+10)
plot(x, dbort(x, qsize, a), type = "h", las = 1, col = "blue",
     ylab = paste("fbort(qsize=", qsize, ", a=", a, ")"),
     log = "y", main = "Borel-Tanner density function") 
## End(Not run)
</code></pre>

<hr>
<h2 id='brat'> Bradley Terry Model </h2><span id='topic+brat'></span>

<h3>Description</h3>

<p>Fits a Bradley Terry model (intercept-only model) by maximum
likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brat(refgp = "last", refvalue = 1, ialpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brat_+3A_refgp">refgp</code></td>
<td>

<p>Integer whose value must be from the set
{1,...,<code class="reqn">M+1</code>}, where there are <code class="reqn">M+1</code>
competitors. The default value indicates the last
competitor is used&mdash;but don't input a character string,
in general.
</p>
</td></tr>
<tr><td><code id="brat_+3A_refvalue">refvalue</code></td>
<td>

<p>Numeric. A positive value for the reference group.
</p>
</td></tr>
<tr><td><code id="brat_+3A_ialpha">ialpha</code></td>
<td>

<p>Initial values for the <code class="reqn">\alpha</code>s.
These are recycled to the appropriate length.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bradley Terry model involves <code class="reqn">M+1</code> competitors
who either win or lose against each other (no draws/ties
allowed in this implementation&ndash;see <code><a href="#topic+bratt">bratt</a></code>
if there are ties). The probability that Competitor
<code class="reqn">i</code> beats Competitor <code class="reqn">j</code> is <code class="reqn">\alpha_i /
  (\alpha_i+\alpha_j)</code>,
where all the <code class="reqn">\alpha</code>s are positive.
Loosely, the <code class="reqn">\alpha</code>s can be thought of as
the competitors' &lsquo;abilities&rsquo;. For identifiability, one
of the <code class="reqn">\alpha_i</code> is set to a known value
<code>refvalue</code>, e.g., 1. By default, this function
chooses the last competitor to have this reference value.
The data can be represented in the form of a <code class="reqn">M+1</code>
by <code class="reqn">M+1</code> matrix of counts, where winners are the
rows and losers are the columns. However, this is not
the way the data should be inputted (see below).
</p>
<p>Excluding the reference value/group, this function
chooses <code class="reqn">\log(\alpha_j)</code> as the
<code class="reqn">M</code> linear predictors. The log link ensures that
the <code class="reqn">\alpha</code>s are positive.
</p>
<p>The Bradley Terry model can be fitted by logistic
regression, but this approach is not taken here.
The Bradley Terry model can be fitted with covariates,
e.g., a home advantage variable, but unfortunately, this lies
outside the VGLM theoretical framework and therefore cannot be
handled with this code.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Warning </h3>

<p>Presently, the residuals are wrong, and the prior weights
are not handled correctly. Ideally, the total number of
counts should be the prior weights, after the response has
been converted to proportions. This would make it similar
to family functions such as <code><a href="#topic+multinomial">multinomial</a></code>
and <code><a href="#topic+binomialff">binomialff</a></code>.
</p>


<h3>Note</h3>

<p>The function <code><a href="#topic+Brat">Brat</a></code> is useful for coercing
a <code class="reqn">M+1</code> by <code class="reqn">M+1</code> matrix of counts into a one-row
matrix suitable for <code>brat</code>. Diagonal elements are
skipped, and the usual S order of <code>c(a.matrix)</code>
of elements is used. There should be no missing values
apart from the diagonal elements of the square matrix.
The matrix should have winners as the rows, and losers
as the columns. In general, the response should be a
1-row matrix with <code class="reqn">M(M+1)</code> columns.
</p>
<p>Only an intercept model is recommended with <code>brat</code>.
It doesn't make sense really to include covariates because
of the limited VGLM framework.
</p>
<p>Notationally, note that the <span class="pkg">VGAM</span> family function
<code><a href="#topic+brat">brat</a></code> has <code class="reqn">M+1</code> contestants, while
<code>bratt</code> has <code class="reqn">M</code> contestants.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Agresti, A. (2013).
<em>Categorical Data Analysis</em>,
3rd ed. Hoboken, NJ, USA: Wiley.
</p>
<p>Stigler, S. (1994).
Citation patterns in the journals of statistics and probability.
<em>Statistical Science</em>,
<b>9</b>, 94&ndash;108.
</p>
<p>The <span class="pkg">BradleyTerry2</span> package has more comprehensive capabilities
than this function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bratt">bratt</a></code>,
<code><a href="#topic+Brat">Brat</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Citation statistics: being cited is a 'win'; citing is a 'loss'
journal &lt;- c("Biometrika", "Comm.Statist", "JASA", "JRSS-B")
mat &lt;- matrix(c( NA, 33, 320, 284,
                730, NA, 813, 276,
                498, 68,  NA, 325,
                221, 17, 142,  NA), 4, 4)
dimnames(mat) &lt;- list(winner = journal, loser = journal)
fit &lt;- vglm(Brat(mat) ~ 1, brat(refgp = 1), trace = TRUE)
fit &lt;- vglm(Brat(mat) ~ 1, brat(refgp = 1), trace = TRUE, crit = "coef")
summary(fit)
c(0, coef(fit))  # Log-abilities (in order of "journal")
c(1, Coef(fit))  # Abilities (in order of "journal")
fitted(fit)     # Probabilities of winning in awkward form
(check &lt;- InverseBrat(fitted(fit)))  # Probabilities of winning
check + t(check)  # Should be 1's in the off-diagonals
</code></pre>

<hr>
<h2 id='Brat'> Inputting Data to fit a Bradley Terry Model </h2><span id='topic+Brat'></span>

<h3>Description</h3>

<p>Takes in a square matrix of counts and outputs
them in a form that is accessible to the <code><a href="#topic+brat">brat</a></code>
and <code><a href="#topic+bratt">bratt</a></code> family functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Brat(mat, ties = 0 * mat, string = c("&gt;", "=="), whitespace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Brat_+3A_mat">mat</code></td>
<td>

<p>Matrix of counts, which is considered <code class="reqn">M</code> by <code class="reqn">M</code> in
dimension when there are ties, and <code class="reqn">M+1</code> by <code class="reqn">M+1</code>
when there are no ties.  The rows are winners and the
columns are losers, e.g., the 2-1 element is now many
times Competitor 2 has beaten Competitor 1.  The matrices
are best labelled with the competitors' names.
</p>
</td></tr>
<tr><td><code id="Brat_+3A_ties">ties</code></td>
<td>

<p>Matrix of counts.
This should be the same dimension as <code>mat</code>. By
default, there are no ties.  The matrix must be symmetric,
and the diagonal should contain <code>NA</code>s.
</p>
</td></tr>
<tr><td><code id="Brat_+3A_string">string</code></td>
<td>

<p>Character.
The matrices are labelled with the first value of the
descriptor, e.g., <code>"NZ &gt; Oz"</code> &lsquo;means&rsquo; NZ beats
Australia in rugby.  Suggested alternatives include
<code>" beats "</code> or <code>" wins against "</code>.  The second value
is used to handle ties.
</p>
</td></tr>
<tr><td><code id="Brat_+3A_whitespace">whitespace</code></td>
<td>

<p>Logical. If <code>TRUE</code> then a white space is added before
and after <code>string</code>; it generally enhances readability.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for some similar-type
information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the <span class="pkg">VGAM</span> package it is necessary for each
matrix to be represented as a single row of data by
<code><a href="#topic+brat">brat</a></code> and <code><a href="#topic+bratt">bratt</a></code>.  Hence the
non-diagonal elements of the <code class="reqn">M+1</code> by <code class="reqn">M+1</code>
matrix are concatenated into <code class="reqn">M(M+1)</code> values (no
ties), while if there are ties, the non-diagonal elements
of the <code class="reqn">M</code> by <code class="reqn">M</code> matrix are concatenated into
<code class="reqn">M(M-1)</code> values.
</p>


<h3>Value</h3>

<p>A matrix with 1 row and either <code class="reqn">M(M+1)</code> or <code class="reqn">M(M-1)</code>
columns.
</p>


<h3>Note</h3>

<p>This is a data preprocessing function for
<code><a href="#topic+brat">brat</a></code> and <code><a href="#topic+bratt">bratt</a></code>.
</p>
<p>Yet to do: merge <code>InverseBrat</code> into <code>brat</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Agresti, A. (2013).
<em>Categorical Data Analysis</em>,
3rd ed. Hoboken, NJ, USA: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+brat">brat</a></code>,
<code><a href="#topic+bratt">bratt</a></code>,
<code>InverseBrat</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>journal &lt;- c("Biometrika", "Comm Statist", "JASA", "JRSS-B")
mat &lt;- matrix(c( NA, 33, 320, 284,   730, NA, 813, 276,
                498, 68,  NA, 325,   221, 17, 142, NA), 4, 4)
dimnames(mat) &lt;- list(winner = journal, loser = journal)
Brat(mat)  # Less readable
Brat(mat, whitespace = TRUE)  # More readable
vglm(Brat(mat, whitespace = TRUE) ~ 1, brat, trace = TRUE)
</code></pre>

<hr>
<h2 id='bratt'> Bradley Terry Model With Ties </h2><span id='topic+bratt'></span>

<h3>Description</h3>

<p>Fits a Bradley Terry model with ties (intercept-only model)
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bratt(refgp = "last", refvalue = 1, ialpha = 1, i0 = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bratt_+3A_refgp">refgp</code></td>
<td>

<p>Integer whose value must be from the set {1,...,<code class="reqn">M</code>},
where there are <code class="reqn">M</code> competitors. The default value
indicates the last competitor is used&mdash;but don't input
a character string, in general.
</p>
</td></tr>
<tr><td><code id="bratt_+3A_refvalue">refvalue</code></td>
<td>

<p>Numeric. A positive value for the reference group.
</p>
</td></tr>
<tr><td><code id="bratt_+3A_ialpha">ialpha</code></td>
<td>

<p>Initial values for the <code class="reqn">\alpha</code>s.
These are recycled to the appropriate length.
</p>
</td></tr>
<tr><td><code id="bratt_+3A_i0">i0</code></td>
<td>

<p>Initial value for <code class="reqn">\alpha_0</code>.
If convergence fails, try another positive value.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several models that extend the ordinary
Bradley Terry model to handle ties. This family function
implements one of these models.  It involves <code class="reqn">M</code>
competitors who either win or lose or tie against
each other.  (If there are no draws/ties then use
<code><a href="#topic+brat">brat</a></code>).  The probability that Competitor
<code class="reqn">i</code> beats Competitor <code class="reqn">j</code> is <code class="reqn">\alpha_i /
  (\alpha_i+\alpha_j+\alpha_0)</code>, where all the <code class="reqn">\alpha</code>s
are positive.  The probability that Competitor <code class="reqn">i</code>
ties with Competitor <code class="reqn">j</code> is <code class="reqn">\alpha_0 /
  (\alpha_i+\alpha_j+\alpha_0)</code>.  Loosely, the <code class="reqn">\alpha</code>s
can be thought of as the competitors' &lsquo;abilities&rsquo;,
and <code class="reqn">\alpha_0</code> is an added parameter
to model ties.  For identifiability, one of the
<code class="reqn">\alpha_i</code> is set to a known value
<code>refvalue</code>, e.g., 1.  By default, this function
chooses the last competitor to have this reference value.
The data can be represented in the form of a <code class="reqn">M</code>
by <code class="reqn">M</code> matrix of counts, where winners are the rows
and losers are the columns.  However, this is not the
way the data should be inputted (see below).
</p>
<p>Excluding the reference value/group, this function
chooses <code class="reqn">\log(\alpha_j)</code> as the first
<code class="reqn">M-1</code> linear predictors.  The log link ensures that
the <code class="reqn">\alpha</code>s are positive.  The last linear
predictor is <code class="reqn">\log(\alpha_0)</code>.
</p>
<p>The Bradley Terry model can be fitted with covariates,
e.g., a home advantage variable, but unfortunately, this
lies outside the VGLM theoretical framework and therefore
cannot be handled with this code.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Note</h3>

<p>The function <code><a href="#topic+Brat">Brat</a></code> is useful for coercing
a <code class="reqn">M</code> by <code class="reqn">M</code> matrix of counts into a one-row
matrix suitable for <code>bratt</code>.  Diagonal elements
are skipped, and the usual S order of <code>c(a.matrix)</code>
of elements is used. There should be no missing values
apart from the diagonal elements of the square matrix.
The matrix should have winners as the rows, and losers
as the columns.  In general, the response should be a
matrix with <code class="reqn">M(M-1)</code> columns.
</p>
<p>Also, a symmetric matrix of ties should be passed into
<code><a href="#topic+Brat">Brat</a></code>. The diagonal of this matrix should
be all <code>NA</code>s.
</p>
<p>Only an intercept model is recommended with <code>bratt</code>.
It doesn't make sense really to include covariates because
of the limited VGLM framework.
</p>
<p>Notationally, note that the <span class="pkg">VGAM</span> family function
<code><a href="#topic+brat">brat</a></code> has <code class="reqn">M+1</code> contestants, while
<code>bratt</code> has <code class="reqn">M</code> contestants.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Torsney, B. (2004).
Fitting Bradley Terry models using a multiplicative algorithm.
In: Antoch, J. (ed.)
<em>Proceedings in Computational Statistics COMPSTAT 2004</em>,
Physica-Verlag: Heidelberg. Pages 513&ndash;526.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+brat">brat</a></code>,
<code><a href="#topic+Brat">Brat</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># citation statistics: being cited is a 'win'; citing is a 'loss'
journal &lt;- c("Biometrika", "Comm.Statist", "JASA", "JRSS-B")
mat &lt;- matrix(c( NA, 33, 320, 284,
                730, NA, 813, 276,
                498, 68,  NA, 325,
                221, 17, 142,  NA), 4, 4)
dimnames(mat) &lt;- list(winner = journal, loser = journal)

# Add some ties. This is fictitional data.
ties &lt;- 5 + 0 * mat
ties[2, 1] &lt;- ties[1,2] &lt;- 9

# Now fit the model
fit &lt;- vglm(Brat(mat, ties) ~ 1, bratt(refgp = 1), trace = TRUE,
            crit = "coef")

summary(fit)
c(0, coef(fit))  # Log-abilities (last is log(alpha0))
c(1, Coef(fit))  #     Abilities (last is alpha0)

fit@misc$alpha   # alpha_1,...,alpha_M
fit@misc$alpha0  # alpha_0

fitted(fit)  # Probabilities of winning and tying, in awkward form
predict(fit)
(check &lt;- InverseBrat(fitted(fit)))    # Probabilities of winning
qprob &lt;- attr(fitted(fit), "probtie")  # Probabilities of a tie
qprobmat &lt;- InverseBrat(c(qprob), NCo = nrow(ties))  # Pr(tie)
check + t(check) + qprobmat  # Should be 1s in the off-diagonals
</code></pre>

<hr>
<h2 id='budworm'> Western Spuce Budworm </h2><span id='topic+budworm'></span>

<h3>Description</h3>

<p>Counts of western spuce budworm 
(Choristoneura freemani) across seven developmental
stages
(five larval instars, pupae, and adults)
on 12 sampling occasions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(budworm)
</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables.
</p>

<dl>
<dt>ddeg</dt><dd>
<p>Degree days.
</p>
</dd>
<dt>total</dt><dd>
<p>Sum of stages 1&ndash;7.
</p>
</dd>
<dt>stage1, stage2, stage3, stage4</dt><dd>
<p>Successive stages.
</p>
</dd>
<dt>stage5, stage6, stage7 </dt><dd>
<p>Successive stages.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data concerns the development of a defoliating
moth widespread in western North America
(i.e., north of Mexico).
According to Boersch-Supan (2021),
the insect passes hrough successive stages
<code class="reqn">j=1,\ldots,r</code>, delimited by <code class="reqn">r-1</code> moults.
The data was originally used in a 1986 publication
but has been corrected for two sampling occasions;
the data appears in Candy (1990) and
was analyzed in Boersch-Supan (2021).
See the latter for more references.
</p>


<h3>Source</h3>

<p>Candy, S. G. (1990).
<em>Biology of the mountain pinhole borer,
Platypus subgranosus Scheld, in Tasmania</em>.
MA thesis, University of Tasmania, Australia.
<code>https://eprints.utas.edu.au/18864/</code>.
</p>


<h3>References</h3>

<p>Boersch-Supan, P. H. (2021).
Modeling insect phenology using ordinal
regression and continuation ratio models.
<em>ReScience C</em>,
<b>7.1</b>, 1&ndash;14.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>budworm
summary(budworm)
</code></pre>

<hr>
<h2 id='calibrate'> Model Calibrations </h2><span id='topic+calibrate'></span>

<h3>Description</h3>

<p><code>calibrate</code> is a generic function used to produce calibrations
from various model fitting functions.  The function invokes
particular &lsquo;methods&rsquo; which depend on the &lsquo;class&rsquo; of the first
argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate_+3A_object">object</code></td>
<td>
<p> An object for which a calibration is desired.
</p>
</td></tr>
<tr><td><code id="calibrate_+3A_...">...</code></td>
<td>

<p>Additional arguments affecting the calibration produced.
Usually the most important argument in <code>...</code> is
<code>newdata</code> which, for <code>calibrate</code>, contains new
<em>response</em> data, <b>Y</b>, say.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a regression model with explanatory variables <b>X</b> and
response <b>Y</b>,
calibration involves estimating <b>X</b> from <b>Y</b> using the
regression model.
It can be loosely thought of as the opposite of <code><a href="stats.html#topic+predict">predict</a></code>
(which takes an <b>X</b> and returns a <b>Y</b> of some sort.)
In general,
the central algorithm is maximum likelihood calibration.
</p>


<h3>Value</h3>

<p>In general, given a new response <b>Y</b>,
some function of the explanatory variables <b>X</b> are returned.
For example,
for constrained ordination models such as CQO and CAO models,
it is usually not possible to return <b>X</b>, so the latent
variables are returned instead (they are
linear combinations of the <b>X</b>).
See the specific <code>calibrate</code> methods functions to see
what they return.
</p>


<h3>Note</h3>

<p>This function was not called <code>predictx</code> because of the
inability of constrained ordination models to return <b>X</b>;
they can only return the latent variable values
(also known as site scores) instead.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>ter Braak, C. J. F. and van Dam, H. (1989).
Inferring pH from diatoms: a comparison of old and new
calibration methods.
<em>Hydrobiologia</em>, <b>178</b>, 209&ndash;223.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">predict</a></code>,
<code><a href="#topic+calibrate.rrvglm">calibrate.rrvglm</a></code>,
<code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Stdzed environmental vars
set.seed(123)
pcao1 &lt;- cao(cbind(Pardlugu, Pardmont, Pardnigr, Pardpull, Zoraspin) ~
         WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
         family = poissonff, data = hspider, Rank = 1, Bestof = 3,
         df1.nl = c(Zoraspin = 2, 1.9), Crow1positive = TRUE)

siteNos &lt;- 1:2  # Calibrate these sites
cpcao1 &lt;- calibrate(pcao1, trace = TRUE,
                    newdata = data.frame(depvar(pcao1)[siteNos, ],
                                         model.matrix(pcao1)[siteNos, ]))

# Graphically compare the actual site scores with their calibrated values
persp(pcao1, main = "Site scores: solid=actual, dashed=calibrated",
      label = TRUE, col = "blue", las = 1)
abline(v = latvar(pcao1)[siteNos], col = seq(siteNos))  # Actual scores
abline(v = cpcao1, lty = 2, col = seq(siteNos))  # Calibrated values

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrate-methods'> Calibration for Constrained Regression Models </h2><span id='topic+calibrate+2Crrvglm-method'></span><span id='topic+calibrate+2Cqrrvglm-method'></span><span id='topic+calibrate+2Crrvgam-method'></span><span id='topic+calibrate+2CCoef.qrrvglm-method'></span>

<h3>Description</h3>

<p><code>calibrate</code> is a generic function applied to
RR-VGLMs,
QRR-VGLMs and
RR-VGAMs, etc.
</p>


<h3>Methods</h3>


<dl>
<dt>object</dt><dd>
<p>The object from which the calibration is performed.
</p>
</dd>
</dl>


<hr>
<h2 id='calibrate.qrrvglm'> Calibration for CQO and CAO models </h2><span id='topic+calibrate.qrrvglm'></span>

<h3>Description</h3>

<p>Performs maximum likelihood calibration
for constrained
quadratic and additive ordination models (CQO and CAO
models are better known as QRR-VGLMs and RR-VGAMs respectively).
</p>



<h3>Usage</h3>

<pre><code class='language-R'>calibrate.qrrvglm(object, newdata = NULL,
    type = c("latvar", "predictors", "response", "vcov", "everything"),
    lr.confint = FALSE, cf.confint = FALSE,
    level = 0.95, initial.vals = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate.qrrvglm_+3A_object">object</code></td>
<td>
<p> The fitted CQO/CAO model.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm_+3A_newdata">newdata</code></td>
<td>
<p> A data frame with new response data,
such as new species data.
The default is to use the original data used to fit the model;
however, the calibration may take a long time to compute
because the computations are expensive.
</p>

<p>Note that the creation of the model frame associated with
<code>newdata</code> is fragile. Factors may not be created
properly. If a variable is binary then its best for it
to be straightforward and have only 0 and 1 as values.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm_+3A_type">type</code></td>
<td>
<p> What type of result to be returned.
The first are the calibrated latent variables or site scores.
This is always computed.
The <code>"predictors"</code> are the linear/quadratic or additive
predictors evaluated at the calibrated latent variables or site
scores.
The <code>"response"</code> are the fitted values (usually means)
evaluated at the
calibrated latent variables or site scores.
The <code>"vcov"</code> are the Wald-type estimated variance-covariance
matrices of the
calibrated latent variables or site scores.
The <code>"everything"</code> is for all of them, i.e., all <code>type</code>s.
Note that for CAO models,
the <code>"vcov"</code> type is unavailable.
</p>
</td></tr>




<tr><td><code id="calibrate.qrrvglm_+3A_lr.confint">lr.confint</code>, <code id="calibrate.qrrvglm_+3A_level">level</code></td>
<td>

<p>Compute <em>approximate</em>
likelihood ratio based confidence intervals?
If <code>TRUE</code> then <code>level</code> is the confidence level required
and one should have <code>type = "latvar"</code>
or <code>type = "everything"</code>;
and currently only rank-1 models are supported.
This option works for CLO and CQO models and not for CAO models.
The function <code><a href="stats.html#topic+uniroot">uniroot</a></code> is called to solve for
the root of a nonlinear equation to obtain each confidence limit,
and this is not entirely reliable.
It is assumed that the likelihood function is unimodal
about its MLE
because only one root is returned if there is more than one.
One root is found on each side of the MLE.
Technically, the default is to find the value of the latent
variable whose difference in deviance (or twice the difference
in log-likelihoods) from the optimal model
is equal to <code>qchisq(level, df = 1)</code>.
The intervals are not true profile likelihood intervals
because it is not possible to estimate the regression coefficients
of the QRR-VGLM/RR-VGLM based on one response vector.
See <code><a href="stats.html#topic+confint">confint</a></code> to get the flavour of these two
arguments in general.
</p>

</td></tr>
<tr><td><code id="calibrate.qrrvglm_+3A_cf.confint">cf.confint</code></td>
<td>

<p>Compute <em>approximate</em>
characteristic function based confidence intervals?
If <code>TRUE</code> then <code>level</code> is the confidence level required
and one should have <code>type = "latvar"</code>
or <code>type = "everything"</code>;
and currently only rank-1 models are supported.
This option works for
<code><a href="#topic+binomialff">binomialff</a></code> and <code><a href="#topic+poissonff">poissonff</a></code>
CLO and CQO models
and not for CAO models.
The function <code><a href="stats.html#topic+uniroot">uniroot</a></code> is called to solve for
the root of a nonlinear equation to obtain each confidence limit,
and this is not entirely reliable.
It is assumed that the likelihood function is unimodal because
only one root is returned if there is more than one.
Technically, the CDF of a normalized score statistic is
obtained by Gauss&ndash;Hermite numerical integration of a
complex-valued integrand,
and this is based on the inversion formula described in
Abate and Witt (1992).
</p>

</td></tr>
<tr><td><code id="calibrate.qrrvglm_+3A_initial.vals">initial.vals</code></td>
<td>
<p> Initial values for the search.
For rank-1 models, this should be a vector having length
equal to <code>nrow(newdata)</code>, and for rank-2 models
this should be a two-column matrix with the number of rows equalling
the number of rows in <code>newdata</code>.
The default is a grid defined by arguments in
<code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm_+3A_...">...</code></td>
<td>

<p>Arguments that are fed into
<code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a fitted regression CQO/CAO model,
maximum likelihood calibration is theoretically easy and elegant.
However, the method assumes that all the responses are
independent, which is often not true in practice.
More details and references are given in Yee (2018) and
ch.6 of Yee (2015).
</p>
<p>The function <code><a href="stats.html#topic+optim">optim</a></code> is used to search for
the maximum likelihood solution. Good initial values are
needed, and arguments in <code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>
allows the user some control over the choice of these.
</p>


<h3>Value</h3>

<p>Several methods are implemented to obtain
confidence intervals/regions for the calibration estimates.
One method is when <code>lr.confint = TRUE</code>,
then a 4-column matrix is returned
with the confidence limits being the final 2 columns
(if <code>type = "everything"</code> then the matrix is
returned in the <code>lr.confint</code> list component).
Another similar method is when <code>cf.confint = TRUE</code>.
There may be some redundancy in whatever is returned.
Other methods are returned by using <code>type</code> 
and they are described as follows.
</p>

<p>The argument <code>type</code> determines what is returned.
If <code>type = "everything"</code> then all the <code>type</code> values
are returned in a list, with the following components.
Each component has length <code>nrow(newdata)</code>.
</p>
<table>
<tr><td><code>latvar</code></td>
<td>
<p>Calibrated latent variables or site scores
(the default).
This may have the attribute <code>"objectiveFunction"</code>
which is usually the log-likelihood or the deviance.
</p>
</td></tr>
<tr><td><code>predictors</code></td>
<td>
<p>linear/quadratic or additive predictors.
For example, for Poisson families, this will be on a log scale,
and for binomial families, this will be on a logit scale.
</p>
</td></tr>
<tr><td><code>response</code></td>
<td>
<p>Fitted values of the response, evaluated at the
calibrated latent variables.
</p>

</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>Wald-type estimated variance-covariance matrices of the
calibrated latent variables or site scores.  Actually,
these are stored in a 3-D array whose dimension is
<code>c(Rank(object), Rank(object), nrow(newdata))</code>.
This type has only been implemented for
<code><a href="#topic+binomialff">binomialff</a></code> and <code><a href="#topic+poissonff">poissonff</a></code> models
with canonical links and <code>noRRR = ~ 1</code> and,
for CQOs, <code>I.tolerances = TRUE</code> or <code>eq.tolerances = TRUE</code>.
</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>This function is computationally expensive.
Setting <code>trace = TRUE</code> to get a running log can be a good idea.
This function has been tested but not extensively.
</p>


<h3>Note</h3>

<p>Despite the name of this function, CAO models are handled as well
to a certain extent.
Some combinations of parameters are not handled, e.g.,
<code>lr.confint = TRUE</code> only works for rank-1,
<code>type = "vcov"</code> only works for
<code><a href="#topic+binomialff">binomialff</a></code> and <code><a href="#topic+poissonff">poissonff</a></code>
models with canonical links and <code>noRRR = ~ 1</code>,
and higher-order rank models need
<code>eq.tolerances = TRUE</code> or <code>I.tolerances = TRUE</code>
as well.
For rank-1 objects, <code>lr.confint = TRUE</code> is recommended
above <code>type = "vcov"</code> in terms of accuracy and overall generality.
For class <code>"qrrvglm"</code> objects it is necessary that
all response' tolerance matrices are positive-definite
which correspond to bell-shaped response curves/surfaces.
</p>
<p>For <code><a href="#topic+binomialff">binomialff</a></code> and <code><a href="#topic+poissonff">poissonff</a></code> models
the <code>deviance</code> slot is used for the optimization rather than
the <code>loglikelihood</code> slot, therefore one can calibrate using
real-valued responses. (If the <code>loglikelihood</code> slot were used
then functions such as <code><a href="stats.html#topic+dpois">dpois</a></code> would be used
with <code>log = TRUE</code> and then would be restricted to feed in
integer-valued response values.)
</p>

<p>Maximum likelihood calibration for
Gaussian logit regression models may be performed by
<span class="pkg">rioja</span> but this applies to a single environmental variable
such as <code>pH</code> in <code>data("SWAP", package = "rioja")</code>.
In <span class="pkg">VGAM</span> <code>calibrate()</code> estimates values of the
<em>latent variable</em> rather than individual explanatory variables,
hence the setting is more on ordination.
</p>



<h3>Author(s)</h3>

<p>T. W. Yee.
Recent work on the standard errors by
David Zucker and
Sam Oman at HUJI
is gratefully acknowledged&mdash;these are returned in the
<code>vcov</code> component and provided inspiration for <code>lr.confint</code>
and <code>cf.confint</code>.
A joint publication is being prepared on this subject.
</p>


<h3>References</h3>

<p>Abate, J. and Whitt, W. (1992).
The Fourier-series method for inverting transforms
of probability distributions.
<em>Queueing Systems</em>,
<b>10</b>, 5&ndash;88.
</p>




<p>ter Braak, C. J. F. (1995).
Calibration. In:
<em>Data Analysis in Community and Landscape Ecology</em>
by Jongman, R. H. G., ter Braak, C. J. F. and
van Tongeren, O. F. R. (Eds.)
Cambridge University Press,
Cambridge.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>,
<code><a href="#topic+calibrate.rrvglm">calibrate.rrvglm</a></code>,
<code><a href="#topic+calibrate">calibrate</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+cao">cao</a></code>,
<code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="stats.html#topic+uniroot">uniroot</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Stdze environmental variables
set.seed(123)
siteNos &lt;- c(1, 5)  # Calibrate these sites
pet1 &lt;- cqo(cbind(Pardlugu, Pardmont, Pardnigr, Pardpull, Zoraspin) ~
        WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
        trace = FALSE,
        data = hspider[-siteNos, ],  # Sites not in fitted model
        family = poissonff, I.toler = TRUE, Crow1positive = TRUE)
y0 &lt;- hspider[siteNos, colnames(depvar(pet1))]  # Species counts
(cpet1 &lt;- calibrate(pet1, trace = TRUE, newdata = data.frame(y0)))
(clrpet1 &lt;- calibrate(pet1, lr.confint = TRUE, newdata = data.frame(y0)))
(ccfpet1 &lt;- calibrate(pet1, cf.confint = TRUE, newdata = data.frame(y0)))
(cp1wald &lt;- calibrate(pet1, newdata = y0, type = "everything"))

## End(Not run)

## Not run: 
# Graphically compare the actual site scores with their calibrated
# values. 95 percent likelihood-based confidence intervals in green.
persp(pet1, main = "Site scores: solid=actual, dashed=calibrated",
      label = TRUE, col = "gray50", las = 1)
# Actual site scores:
xvars &lt;- rownames(concoef(pet1))  # Variables comprising the latvar
est.latvar &lt;- as.matrix(hspider[siteNos, xvars]) %*% concoef(pet1)
abline(v = est.latvar, col = seq(siteNos))
abline(v = cpet1, lty = 2, col = seq(siteNos))  # Calibrated values
arrows(clrpet1[,  3], c(60, 60), clrpet1[,  4], c(60, 60),  # Add CIs
       length = 0.08, col = "orange", angle = 90, code = 3, lwd = 2)
arrows(ccfpet1[,  3], c(70, 70), ccfpet1[,  4], c(70, 70),  # Add CIs
       length = 0.08, col = "limegreen", angle = 90, code = 3, lwd = 2)
arrows(cp1wald$latvar - 1.96 * sqrt(cp1wald$vcov), c(65, 65),
       cp1wald$latvar + 1.96 * sqrt(cp1wald$vcov), c(65, 65),  # Wald CIs
       length = 0.08, col = "blue", angle = 90, code = 3, lwd = 2)
legend("topright", lwd = 2,
       leg = c("CF interval", "Wald  interval", "LR interval"),
       col = c("limegreen", "blue", "orange"), lty = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrate.qrrvglm.control'> Control Function for CQO/CAO Calibration </h2><span id='topic+calibrate.qrrvglm.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for running
<code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code> are set using this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate.qrrvglm.control(object, trace = FALSE, method.optim = "BFGS",
    gridSize = ifelse(Rank == 1, 21, 9), varI.latvar = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate.qrrvglm.control_+3A_object">object</code></td>
<td>

<p>The fitted CQO/CAO model. The user should ignore this argument.
</p>

</td></tr>
<tr><td><code id="calibrate.qrrvglm.control_+3A_trace">trace</code></td>
<td>

<p>Logical indicating if output should be produced for each iteration.
It is a good idea to set this argument to be <code>TRUE</code> since the
computations are expensive.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm.control_+3A_method.optim">method.optim</code></td>
<td>

<p>Character. Fed into the <code>method</code> argument of
<code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm.control_+3A_gridsize">gridSize</code></td>
<td>

<p>Numeric, recycled to length <code>Rank</code>.  Controls the resolution
of the grid used for initial values.  For each latent variable,
an equally spaced grid of length <code>gridSize</code> is cast from the
smallest site score to the largest site score. Then the likelihood
function is evaluated on the grid, and the best fit is chosen as the
initial value. Thus increasing the value of <code>gridSize</code> increases
the chance of obtaining the global solution, however, the computing
time increases proportionately.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm.control_+3A_vari.latvar">varI.latvar</code></td>
<td>

<p>Logical. For CQO objects only, this argument is fed into
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.qrrvglm.control_+3A_...">...</code></td>
<td>

<p>Avoids an error message for extraneous arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most CQO/CAO users will only need to make use of <code>trace</code>
and <code>gridSize</code>. These arguments should be used inside their
call to <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>, not this function
directly.
</p>


<h3>Value</h3>

<p>A list which with the following components.
</p>
<table>
<tr><td><code>trace</code></td>
<td>
<p>Numeric (even though the input can be logical). </p>
</td></tr>
<tr><td><code>gridSize</code></td>
<td>
<p>Positive integer. </p>
</td></tr>
<tr><td><code>varI.latvar</code></td>
<td>
<p>Logical.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Despite the name of this function, CAO models are handled
as well.
</p>



<h3>References</h3>

<p>Yee, T. W. (2020).
On constrained and unconstrained quadratic ordination.
<em>Manuscript in preparation</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>,
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Needed for I.tol=TRUE
set.seed(123)
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Pardlugu, Pardnigr,
                Pardpull, Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          family = poissonff, data = hspider, I.tol = TRUE)
sort(deviance(p1, history = TRUE))  # A history of all the iterations
siteNos &lt;- 3:4  # Calibrate these sites
cp1 &lt;- calibrate(p1, trace = TRUE,
                 new = data.frame(depvar(p1)[siteNos, ]))

## End(Not run)
## Not run: 
# Graphically compare the actual site scores with their calibrated values
persp(p1, main = "Site scores: solid=actual, dashed=calibrated",
      label = TRUE, col = "blue", las = 1)
abline(v = latvar(p1)[siteNos], col = seq(siteNos))  # Actual site scores
abline(v = cp1, lty = 2, col = seq(siteNos))  # Calibrated values

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrate.rrvglm'> Calibration for CLO models (RR-VGLMs) </h2><span id='topic+calibrate.rrvglm'></span>

<h3>Description</h3>

<p>Performs maximum likelihood calibration for constrained
linear ordination models
(CLO models are better known as RR-VGLMs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate.rrvglm(object, newdata = NULL,
    type = c("latvar", "predictors", "response", "vcov", "everything"),
    lr.confint = FALSE, cf.confint = FALSE,
    level = 0.95, initial.vals = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate.rrvglm_+3A_object">object</code></td>
<td>
<p> The fitted <code><a href="#topic+rrvglm">rrvglm</a></code> model.
Note that <code>object</code> should be fitted with corner constraints.
</p>
</td></tr>
<tr><td><code id="calibrate.rrvglm_+3A_newdata">newdata</code></td>
<td>

<p>See <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
</p>





</td></tr>
<tr><td><code id="calibrate.rrvglm_+3A_type">type</code></td>
<td>

<p>See <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
If <code>type = "vcov"</code> then <code>object</code> should have
been fitted using <code><a href="#topic+binomialff">binomialff</a></code> or <code><a href="#topic+poissonff">poissonff</a></code>
with canonical links, and have <code>noRRR = ~ 1</code>.
</p>




</td></tr>



<tr><td><code id="calibrate.rrvglm_+3A_lr.confint">lr.confint</code>, <code id="calibrate.rrvglm_+3A_cf.confint">cf.confint</code>, <code id="calibrate.rrvglm_+3A_level">level</code></td>
<td>

<p>Same as <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.rrvglm_+3A_initial.vals">initial.vals</code></td>
<td>

<p>Same as <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
The default is a grid defined by arguments in
<code><a href="#topic+calibrate.rrvglm.control">calibrate.rrvglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.rrvglm_+3A_...">...</code></td>
<td>

<p>Arguments that are fed into
<code><a href="#topic+calibrate.rrvglm.control">calibrate.rrvglm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a fitted regression CLO model,
maximum likelihood calibration is theoretically easy and elegant.
However, the method assumes that all responses are independent.
More details and references are given in Yee (2015).
</p>
<p>Calibration requires <em>grouped</em> or <em>non-sparse</em> data
as the response.
For example,
if the family function is <code><a href="#topic+multinomial">multinomial</a></code> then
one cannot usually calibrate <code>y0</code> if it is a vector of 0s
except for one 1.
Instead, the response vector should be from grouped data
so that there are few 0s.
Indeed, it is found empirically that the stereotype model
(also known as a reduced-rank <code><a href="#topic+multinomial">multinomial</a></code> logit
model) calibrates well only with grouped data, and
if the response vector is all 0s except for one 1 then
the MLE will probably be at <code>-Inf</code> or <code>+Inf</code>.
As another example, if the family function is <code><a href="#topic+poissonff">poissonff</a></code>
then <code>y0</code> must not be a vector of all 0s; instead, the response
vector should have few 0s ideally.  In general, you can use simulation
to see what type of data calibrates acceptably.
</p>
<p>Internally, this function is a simplification of
<code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code> and users should look at
that function for details.
Good initial values are
needed, and a grid is constructed to obtain these.
The function <code><a href="#topic+calibrate.rrvglm.control">calibrate.rrvglm.control</a></code>
allows the user some control over the choice of these.
</p>




<h3>Value</h3>

<p>See <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
Of course, the quadratic term in the latent variables vanishes
for RR-VGLMs, so the model is simpler.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
</p>








<h3>Note</h3>

<p>See <code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code> about, e.g.,
calibration using real-valued responses.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee</p>


<h3>See Also</h3>

<p><code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>,
<code><a href="#topic+calibrate">calibrate</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+weightsvglm">weightsvglm</a></code>,
<code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="stats.html#topic+uniroot">uniroot</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>## Not run:   # Example 1
nona.xs.nz &lt;- na.omit(xs.nz)  # Overkill!! (Data in VGAMdata package)
nona.xs.nz$dmd     &lt;- with(nona.xs.nz, round(drinkmaxday))
nona.xs.nz$feethr  &lt;- with(nona.xs.nz, round(feethour))
nona.xs.nz$sleephr &lt;- with(nona.xs.nz, round(sleep))
nona.xs.nz$beats   &lt;- with(nona.xs.nz, round(pulse))

p2 &lt;- rrvglm(cbind(dmd, feethr, sleephr, beats) ~ age + smokenow +
  depressed + embarrassed + fedup + hurt + miserable +  # 11 psychological
  nofriend + moody + nervous + tense + worry + worrier, # variables
  noRRR = ~ age + smokenow, trace = FALSE, poissonff, data = nona.xs.nz,
  Rank = 2)
cp2 &lt;- calibrate(p2, newdata = head(nona.xs.nz, 9), trace = TRUE)
cp2

two.cases &lt;- nona.xs.nz[1:2, ]  # Another calibration example
two.cases$dmd       &lt;- c(4, 10)
two.cases$feethr    &lt;- c(4, 7)
two.cases$sleephr   &lt;- c(7, 8)
two.cases$beats     &lt;- c(62, 71)
(cp2b &lt;- calibrate(p2, newdata = two.cases))

# Example 2
p1 &lt;- rrvglm(cbind(dmd, feethr, sleephr, beats) ~ age + smokenow +
  depressed + embarrassed + fedup + hurt + miserable +  # 11 psychological
  nofriend + moody + nervous + tense + worry + worrier, # variables
  noRRR = ~ age + smokenow, trace = FALSE, poissonff, data = nona.xs.nz,
  Rank = 1)
(cp1c &lt;- calibrate(p1, newdata = two.cases, lr.confint = TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrate.rrvglm.control'> Control Function for CLO (RR-VGLM) Calibration </h2><span id='topic+calibrate.rrvglm.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for running
<code><a href="#topic+calibrate.rrvglm">calibrate.rrvglm</a></code> are set using this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate.rrvglm.control(object, trace = FALSE, method.optim = "BFGS",
    gridSize = ifelse(Rank == 1, 17, 9), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate.rrvglm.control_+3A_object">object</code></td>
<td>

<p>The fitted <code><a href="#topic+rrvglm">rrvglm</a></code> model.
The user should ignore this argument.
</p>

</td></tr>
<tr><td><code id="calibrate.rrvglm.control_+3A_trace">trace</code>, <code id="calibrate.rrvglm.control_+3A_method.optim">method.optim</code></td>
<td>

<p>Same as <code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.rrvglm.control_+3A_gridsize">gridSize</code></td>
<td>

<p>Same as <code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="calibrate.rrvglm.control_+3A_...">...</code></td>
<td>

<p>Avoids an error message for extraneous arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most CLO users will only need to make use of <code>trace</code>
and <code>gridSize</code>. These arguments should be used inside their
call to <code><a href="#topic+calibrate.rrvglm">calibrate.rrvglm</a></code>, not this function
directly.
</p>


<h3>Value</h3>

<p>Similar to <code><a href="#topic+calibrate.qrrvglm.control">calibrate.qrrvglm.control</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calibrate.rrvglm">calibrate.rrvglm</a></code>,
<code><a href="#topic+Coef.rrvglm">Coef.rrvglm</a></code>.
</p>

<hr>
<h2 id='cao'> Fitting Constrained Additive Ordination (CAO) </h2><span id='topic+cao'></span>

<h3>Description</h3>

<p>A constrained additive ordination (CAO) model is fitted using
the <em>reduced-rank vector generalized additive model</em>
(RR-VGAM) framework.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cao(formula, family = stop("argument 'family' needs to be assigned"),
    data = list(),
    weights = NULL, subset = NULL, na.action = na.fail,
    etastart = NULL, mustart = NULL, coefstart = NULL,
    control = cao.control(...), offset = NULL,
    method = "cao.fit", model = FALSE, x.arg = TRUE, y.arg = TRUE,
    contrasts = NULL, constraints = NULL,
    extra = NULL, qr.arg = FALSE, smart = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cao_+3A_formula">formula</code></td>
<td>

<p>a symbolic description of the model to be fit.  The RHS of
the formula is used to construct the latent variables, upon
which the smooths are applied.  All the variables in the
formula are used for the construction of latent variables
except for those specified by the argument <code>noRRR</code>,
which is itself a formula.  The LHS of the formula contains
the response variables, which should be a matrix with each
column being a response (species).
</p>
</td></tr>
<tr><td><code id="cao_+3A_family">family</code></td>
<td>

<p>a function of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>)
describing what statistical model is to be fitted. This is called a
&ldquo;<span class="pkg">VGAM</span> family function&rdquo;.  See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for general information about many types of arguments found in this
type of function.
See <code><a href="#topic+cqo">cqo</a></code> for a list of those presently implemented.
</p>
</td></tr>
<tr><td><code id="cao_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in
the model.  By default the variables are taken from
<code>environment(formula)</code>, typically the environment
from which <code>cao</code> is called.
</p>
</td></tr>
<tr><td><code id="cao_+3A_weights">weights</code></td>
<td>

<p>an optional vector or matrix of (prior) weights to be used
in the fitting process.  For <code>cao</code>, this argument
currently should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_subset">subset</code></td>
<td>

<p>an optional logical vector specifying a subset of
observations to be used in the fitting process.
</p>
</td></tr>
<tr><td><code id="cao_+3A_na.action">na.action</code></td>
<td>

<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  The default is set by the
<code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and
is <code>na.fail</code> if that is unset.  The &ldquo;factory-fresh&rdquo;
default is <code>na.omit</code>.
</p>
</td></tr>
<tr><td><code id="cao_+3A_etastart">etastart</code></td>
<td>

<p>starting values for the linear predictors.  It is a
<code class="reqn">M</code>-column matrix. If <code class="reqn">M=1</code> then it may be a vector.
For <code>cao</code>, this argument currently should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_mustart">mustart</code></td>
<td>

<p>starting values for the fitted values. It can be a vector
or a matrix.  Some family functions do not make use of
this argument.  For <code>cao</code>, this argument currently
should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_coefstart">coefstart</code></td>
<td>

<p>starting values for the coefficient vector.  For <code>cao</code>,
this argument currently should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_control">control</code></td>
<td>

<p>a list of parameters for controlling the fitting process.
See <code><a href="#topic+cao.control">cao.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="cao_+3A_offset">offset</code></td>
<td>

<p>a vector or <code class="reqn">M</code>-column matrix of offset values.
These are <em>a priori</em> known and are added to the linear
predictors during fitting.  For <code>cao</code>, this argument
currently should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_method">method</code></td>
<td>

<p>the method to be used in fitting the model.  The default
(and presently only) method <code>cao.fit</code> uses iteratively
reweighted least squares (IRLS) within FORTRAN code called
from <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</td></tr>
<tr><td><code id="cao_+3A_model">model</code></td>
<td>

<p>a logical value indicating whether the <em>model frame</em>
should be assigned in the <code>model</code> slot.
</p>
</td></tr>
<tr><td><code id="cao_+3A_x.arg">x.arg</code>, <code id="cao_+3A_y.arg">y.arg</code></td>
<td>

<p>logical values indicating whether the model matrix and
response vector/matrix used in the fitting process should
be assigned in the <code>x</code> and <code>y</code> slots.  Note the
model matrix is the linear model (LM) matrix.
</p>
</td></tr>
<tr><td><code id="cao_+3A_contrasts">contrasts</code></td>
<td>

<p>an optional list. See the <code>contrasts.arg</code> of
<code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.
</p>
</td></tr>
<tr><td><code id="cao_+3A_constraints">constraints</code></td>
<td>

<p>an optional list  of constraint matrices.  For
<code>cao</code>, this argument currently should not be used.
The components of the list must be named with the term it
corresponds to (and it must match in character format).
Each constraint matrix must have <code class="reqn">M</code> rows, and be
of full-column rank. By default, constraint matrices are
the <code class="reqn">M</code> by <code class="reqn">M</code> identity matrix unless arguments
in the family function itself override these values.
If <code>constraints</code> is used it must contain <em>all</em>
the terms; an incomplete list is not accepted.
</p>
</td></tr>
<tr><td><code id="cao_+3A_extra">extra</code></td>
<td>

<p>an optional list with any extra information that might
be needed by the family function.  For <code>cao</code>, this
argument currently should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_qr.arg">qr.arg</code></td>
<td>

<p>For <code>cao</code>, this argument currently should not be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_smart">smart</code></td>
<td>

<p>logical value indicating whether smart prediction
(<code><a href="#topic+smartpred">smartpred</a></code>) will be used.
</p>
</td></tr>
<tr><td><code id="cao_+3A_...">...</code></td>
<td>

<p>further arguments passed into <code><a href="#topic+cao.control">cao.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments of <code>cao</code> are a mixture of those from
<code><a href="#topic+vgam">vgam</a></code> and <code><a href="#topic+cqo">cqo</a></code>, but with some extras
in <code><a href="#topic+cao.control">cao.control</a></code>. Currently, not all of the
arguments work properly.
</p>
<p>CAO can be loosely be thought of as the result of fitting
generalized additive models (GAMs) to several responses
(e.g., species) against a very small number of latent
variables.  Each latent variable is a linear combination of
the explanatory variables; the coefficients <b>C</b> (called
<code class="reqn">C</code> below) are called <em>constrained coefficients</em>
or <em>canonical coefficients</em>, and are interpreted as
weights or loadings. The <b>C</b> are estimated by maximum
likelihood estimation.  It is often a good idea to apply
<code><a href="base.html#topic+scale">scale</a></code> to each explanatory variable first.
</p>
<p>For each response (e.g., species), each latent variable
is smoothed by a cubic smoothing spline, thus CAO is
data-driven. If each smooth were a quadratic then CAO
would simplify to <em>constrained quadratic ordination</em>
(CQO; formerly called <em>canonical Gaussian ordination</em>
or CGO).  If each smooth were linear then CAO would simplify
to <em>constrained linear ordination</em> (CLO). CLO can
theoretically be fitted with <code>cao</code> by specifying
<code>df1.nl=0</code>, however it is more efficient to use
<code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>
<p>Currently, only <code>Rank=1</code> is implemented, and only
<code>noRRR = ~1</code> models are handled.
</p>






<p>With binomial data, the default formula is
</p>
<p style="text-align: center;"><code class="reqn">logit(P[Y_s=1]) = \eta_s = f_s(\nu), \ \ \ s=1,2,\ldots,S</code>
</p>

<p>where <code class="reqn">x_2</code> is a vector of environmental variables, and
<code class="reqn">\nu=C^T x_2</code> is a <code class="reqn">R</code>-vector of latent
variables.  The <code class="reqn">\eta_s</code> is an additive predictor
for species <code class="reqn">s</code>, and it models the probabilities
of presence as an additive model on the logit scale.
The matrix <code class="reqn">C</code> is estimated from the data, as well as
the smooth functions <code class="reqn">f_s</code>.  The argument <code>noRRR =
  ~ 1</code> specifies that the vector <code class="reqn">x_1</code>, defined for
RR-VGLMs and QRR-VGLMs, is simply a 1 for an intercept.  Here,
the intercept in the model is absorbed into the functions.
A <code><a href="#topic+clogloglink">clogloglink</a></code> link may be preferable over a
<code><a href="#topic+logitlink">logitlink</a></code> link.
</p>
<p>With Poisson count data, the formula is
</p>
<p style="text-align: center;"><code class="reqn">\log(E[Y_s]) = \eta_s = f_s(\nu)</code>
</p>

<p>which models the mean response as an additive models on the
log scale.
</p>
<p>The fitted latent variables (site scores) are scaled to have
unit variance.  The concept of a tolerance is undefined for
CAO models, but the optimums and maximums are defined. The
generic functions <code><a href="#topic+Max">Max</a></code> and <code><a href="#topic+Opt">Opt</a></code>
should work for CAO objects, but note that if the maximum
occurs at the boundary then <code><a href="#topic+Max">Max</a></code> will return a
<code>NA</code>.  Inference for CAO models is currently undeveloped.
</p>


<h3>Value</h3>

<p>An object of class <code>"cao"</code>
(this may change to <code>"rrvgam"</code> in the future).
Several generic functions can be applied to the object, e.g.,
<code><a href="#topic+Coef">Coef</a></code>, <code><a href="#topic+concoef">concoef</a></code>, <code><a href="#topic+lvplot">lvplot</a></code>,
<code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Warning </h3>

<p>CAO is very costly to compute. With version 0.7-8 it took
28 minutes on a fast machine. I hope to look at ways of
speeding things up in the future.
</p>
<p>Use <code><a href="base.html#topic+Random">set.seed</a></code> just prior to calling
<code>cao()</code> to make your results reproducible.  The reason
for this is finding the optimal CAO model presents a difficult
optimization problem, partly because the log-likelihood
function contains many local solutions. To obtain the
(global) solution the user is advised to try <em>many</em>
initial values.  This can be done by setting <code>Bestof</code>
some appropriate value (see <code><a href="#topic+cao.control">cao.control</a></code>). Trying
many initial values becomes progressively more important as
the nonlinear degrees of freedom of the smooths increase.
</p>







<h3>Note</h3>

<p>CAO models are computationally expensive, therefore setting
<code>trace = TRUE</code> is a good idea, as well as running it
on a simple random sample of the data set instead.
</p>
<p>Sometimes the IRLS algorithm does not converge within
the FORTRAN code. This results in warnings being issued.
In particular, if an error code of 3 is issued, then this
indicates the IRLS algorithm has not converged. One possible
remedy is to increase or decrease the nonlinear degrees of
freedom so that the curves become more or less flexible,
respectively.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+cao.control">cao.control</a></code>,
<code>Coef.cao</code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+latvar">latvar</a></code>,
<code><a href="#topic+Opt">Opt</a></code>,
<code><a href="#topic+Max">Max</a></code>,
<code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>,
<code>persp.cao</code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>,
<code><a href="base.html#topic+Random">set.seed</a></code>,
<code>gam()</code> in <span class="pkg">gam</span>,
<code><a href="VGAMdata.html#topic+trapO">trapO</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Stdzd environmental vars
set.seed(149)  # For reproducible results
ap1 &lt;- cao(cbind(Pardlugu, Pardmont, Pardnigr, Pardpull) ~
           WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
           family = poissonff, data = hspider, Rank = 1,
           df1.nl = c(Pardpull= 2.7, 2.5),
           Bestof = 7, Crow1positive = FALSE)
sort(deviance(ap1, history = TRUE))  # A history of all the iterations

Coef(ap1)
concoef(ap1)

par(mfrow = c(2, 2))
plot(ap1)  # All the curves are unimodal; some quite symmetric

par(mfrow = c(1, 1), las = 1)
index &lt;- 1:ncol(depvar(ap1))
lvplot(ap1, lcol = index, pcol = index, y = TRUE)

trplot(ap1, label = TRUE, col = index)
abline(a = 0, b = 1, lty = 2)

trplot(ap1, label = TRUE, col = "blue", log = "xy", which.sp = c(1, 3))
abline(a = 0, b = 1, lty = 2)

persp(ap1, col = index, lwd = 2, label = TRUE)
abline(v = Opt(ap1), lty = 2, col = index)
abline(h = Max(ap1), lty = 2, col = index)

## End(Not run)
</code></pre>

<hr>
<h2 id='cao.control'> Control Function for RR-VGAMs (CAO) </h2><span id='topic+cao.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for a constrained additive
ordination (CAO), by fitting a <em>reduced-rank vector generalized
additive model</em> (RR-VGAM), are set using this function.
This is the control function for <code><a href="#topic+cao">cao</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cao.control(Rank = 1, all.knots = FALSE, criterion = "deviance", Cinit = NULL,
            Crow1positive = TRUE, epsilon = 1.0e-05, Etamat.colmax = 10,
            GradientFunction = FALSE, iKvector = 0.1, iShape = 0.1,
            noRRR = ~ 1, Norrr = NA,
            SmallNo = 5.0e-13, Use.Init.Poisson.QO = TRUE,
            Bestof = if (length(Cinit)) 1 else 10, maxitl = 10,
            imethod = 1, bf.epsilon = 1.0e-7, bf.maxit = 10,
            Maxit.optim = 250, optim.maxit = 20, sd.sitescores = 1.0,
            sd.Cinit = 0.02, suppress.warnings = TRUE,
            trace = TRUE, df1.nl = 2.5, df2.nl = 2.5,
            spar1 = 0, spar2 = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cao.control_+3A_rank">Rank</code></td>
<td>

<p>The numerical rank <code class="reqn">R</code> of the model, i.e., the number
of latent variables.  Currently only <code>Rank = 1</code>
is implemented.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_all.knots">all.knots</code></td>
<td>

<p>Logical indicating if all distinct points of the smoothing
variables are to be used as knots.  Assigning the value
<code>FALSE</code> means fewer knots are chosen when the number
of distinct points is large, meaning less computational
expense. See <code><a href="#topic+vgam.control">vgam.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_criterion">criterion</code></td>
<td>

<p>Convergence criterion. Currently, only one is supported:
the deviance is minimized.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_cinit">Cinit</code></td>
<td>

<p>Optional initial <b>C</b> matrix which may speed up
convergence.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_crow1positive">Crow1positive</code></td>
<td>

<p>Logical vector of length <code>Rank</code> (recycled if
necessary): are the elements of the first row of
<b>C</b> positive?  For example, if <code>Rank</code> is 4,
then specifying <code>Crow1positive = c(FALSE, TRUE)</code>
will force <b>C[1,1]</b> and <b>C[1,3]</b> to be negative,
and <b>C[1,2]</b> and <b>C[1,4]</b> to be positive.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_epsilon">epsilon</code></td>
<td>

<p>Positive numeric. Used to test for convergence for GLMs
fitted in FORTRAN.  Larger values mean a loosening of the
convergence criterion.
</p>

</td></tr>
<tr><td><code id="cao.control_+3A_etamat.colmax">Etamat.colmax</code></td>
<td>

<p>Positive integer, no smaller than <code>Rank</code>.  Controls
the amount of memory used by <code>.Init.Poisson.QO()</code>.
It is the maximum number of columns allowed for the
pseudo-response and its weights.  In general, the larger
the value, the better the initial value.  Used only if
<code>Use.Init.Poisson.QO = TRUE</code>.
</p>
</td></tr>






<tr><td><code id="cao.control_+3A_gradientfunction">GradientFunction</code></td>
<td>

<p>Logical. Whether <code><a href="stats.html#topic+optim">optim</a></code>'s argument
<code>gr</code> is used or not, i.e., to compute gradient values.
Used only if <code>FastAlgorithm</code> is <code>TRUE</code>.  Currently,
this argument must be set to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_ikvector">iKvector</code>, <code id="cao.control_+3A_ishape">iShape</code></td>
<td>

<p>See <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>.
</p>
</td></tr>












<tr><td><code id="cao.control_+3A_norrr">noRRR</code></td>
<td>

<p>Formula giving terms that are <em>not</em> to be included
in the reduced-rank regression (or formation of the latent
variables).  The default is to omit the intercept term from
the latent variables.  Currently, only <code>noRRR = ~ 1</code>
is implemented.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_norrr">Norrr</code></td>
<td>

<p>Defunct. Please use <code>noRRR</code>.
Use of <code>Norrr</code> will become an error soon.
</p>
</td></tr>








<tr><td><code id="cao.control_+3A_smallno">SmallNo</code></td>
<td>

<p>Positive numeric between <code>.Machine$double.eps</code> and
<code>0.0001</code>.  Used to avoid under- or over-flow in the
IRLS algorithm.
</p>

</td></tr>
<tr><td><code id="cao.control_+3A_use.init.poisson.qo">Use.Init.Poisson.QO</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the function
<code>.Init.Poisson.QO</code> is used to obtain initial values
for the canonical coefficients <b>C</b>.  If <code>FALSE</code>
then random numbers are used instead.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_bestof">Bestof</code></td>
<td>

<p>Integer. The best of <code>Bestof</code> models fitted is
returned. This argument helps guard against local solutions
by (hopefully) finding the global solution from many
fits. The argument works only when the function generates
its own initial value for <b>C</b>, i.e., when <b>C</b>
are <em>not</em> passed in as initial values.  The default
is only a convenient minimal number and users are urged
to increase this value.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_maxitl">maxitl</code></td>
<td>

<p>Positive integer. Maximum number of
Newton-Raphson/Fisher-scoring/local-scoring iterations
allowed.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_bf.epsilon">bf.epsilon</code></td>
<td>

<p>Positive numeric. Tolerance used by the modified vector
backfitting algorithm for testing convergence.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_bf.maxit">bf.maxit</code></td>
<td>

<p>Positive integer.
Number of backfitting iterations allowed in the compiled
code.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_maxit.optim">Maxit.optim</code></td>
<td>

<p>Positive integer.
Number of iterations given to the function
<code><a href="stats.html#topic+optim">optim</a></code> at each of the <code>optim.maxit</code>
iterations.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_optim.maxit">optim.maxit</code></td>
<td>

<p>Positive integer.
Number of times <code><a href="stats.html#topic+optim">optim</a></code> is invoked.
</p>


</td></tr>





<tr><td><code id="cao.control_+3A_sd.sitescores">sd.sitescores</code></td>
<td>

<p>Numeric. Standard deviation of the
initial values of the site scores, which are generated from
a normal distribution.
Used when <code>Use.Init.Poisson.QO</code> is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_sd.cinit">sd.Cinit</code></td>
<td>

<p>Standard deviation of the initial values for the elements
of <b>C</b>.
These are normally distributed with mean zero.
This argument is used only if <code>Use.Init.Poisson.QO = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_suppress.warnings">suppress.warnings</code></td>
<td>

<p>Logical. Suppress warnings?
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_trace">trace</code></td>
<td>

<p>Logical indicating if output should be produced for each
iteration. Having the value <code>TRUE</code> is a good idea
for large data sets.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_df1.nl">df1.nl</code>, <code id="cao.control_+3A_df2.nl">df2.nl</code></td>
<td>

<p>Numeric and non-negative, recycled to length <em>S</em>.
Nonlinear degrees
of freedom for smooths of the first and second latent variables.
A value of 0 means the smooth is linear.  Roughly, a value between
1.0 and 2.0 often has the approximate flexibility of a quadratic.
The user should not assign too large a value to this argument, e.g.,
the value 4.0 is probably too high.  The argument <code>df1.nl</code> is
ignored if <code>spar1</code> is assigned a positive value or values. Ditto
for <code>df2.nl</code>.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_spar1">spar1</code>, <code id="cao.control_+3A_spar2">spar2</code></td>
<td>

<p>Numeric and non-negative, recycled to length <em>S</em>.
Smoothing parameters of the
smooths of the first and second latent variables. The larger
the value, the more smooth (less wiggly) the fitted curves.
These arguments are an
alternative to specifying <code>df1.nl</code> and <code>df2.nl</code>.
A value 0 (the default) for <code>spar1</code> means that
<code>df1.nl</code> is used.  Ditto for <code>spar2</code>.  The values
are on a scaled version of the latent variables.  See Green
and Silverman (1994) for more information.
</p>
</td></tr>
<tr><td><code id="cao.control_+3A_...">...</code></td>
<td>
<p> Ignored at present. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many of these arguments are identical to
<code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>.  Here, <code class="reqn">R</code> is the
<code>Rank</code>, <code class="reqn">M</code> is the number of additive predictors, and
<code class="reqn">S</code> is the number of responses (species).  Thus <code class="reqn">M=S</code>
for binomial and Poisson responses, and <code class="reqn">M=2S</code> for the
negative binomial and 2-parameter gamma distributions.
</p>
<p>Allowing the smooths too much flexibility means the CAO
optimization problem becomes more difficult to solve. This
is because the number of local solutions increases as
the nonlinearity of the smooths increases. In situations
of high nonlinearity, many initial values should be used,
so that <code>Bestof</code> should be assigned a larger value. In
general, there should be a reasonable value of <code>df1.nl</code>
somewhere between 0 and about 3 for most data sets.
</p>


<h3>Value</h3>

<p>A list with the components corresponding to its arguments,
after some basic error checking.
</p>


<h3>Note</h3>

<p>The argument <code>df1.nl</code> can be inputted in the format
<code>c(spp1 = 2, spp2 = 3, 2.5)</code>, say, meaning the default
value is 2.5, but two species have alternative values.
</p>
<p>If <code>spar1 = 0</code> and <code>df1.nl = 0</code> then this represents
fitting linear functions (CLO). Currently, this is handled in
the awkward manner of setting <code>df1.nl</code> to be a small
positive value, so that the smooth is almost linear but
not quite.  A proper fix to this special case should done
in the short future.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>
<p>Green, P. J. and Silverman, B. W. (1994).
<em>Nonparametric Regression and Generalized Linear Models:
A Roughness Penalty Approach</em>,
London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cao">cao</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Standardized environmental vars
set.seed(123)
ap1 &lt;- cao(cbind(Pardlugu, Pardmont, Pardnigr, Pardpull, Zoraspin) ~
           WaterCon + BareSand + FallTwig +
           CoveMoss + CoveHerb + ReflLux,
           family = poissonff, data = hspider,
           df1.nl = c(Zoraspin = 2.3, 2.1),
           Bestof = 10, Crow1positive = FALSE)
sort(deviance(ap1, history = TRUE))  # A history of all the iterations

Coef(ap1)

par(mfrow = c(2, 3))  # All or most of the curves are unimodal; some are
plot(ap1, lcol = "blue")  # quite symmetric. Hence a CQO model should be ok

par(mfrow = c(1, 1), las = 1)
index &lt;- 1:ncol(depvar(ap1))  # lvplot is jagged because only 28 sites
lvplot(ap1, lcol = index, pcol = index, y = TRUE)

trplot(ap1, label = TRUE, col = index)
abline(a = 0, b = 1, lty = 2)

persp(ap1, label = TRUE, col = 1:4)

## End(Not run)
</code></pre>

<hr>
<h2 id='Card'> Cardioid Distribution </h2><span id='topic+Card'></span><span id='topic+dcard'></span><span id='topic+pcard'></span><span id='topic+qcard'></span><span id='topic+rcard'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the cardioid distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcard(x, mu, rho, log = FALSE)
pcard(q, mu, rho, lower.tail = TRUE, log.p = FALSE)
qcard(p, mu, rho, tolerance = 1e-07, maxits = 500,
      lower.tail = TRUE, log.p = FALSE)
rcard(n, mu, rho, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Card_+3A_x">x</code>, <code id="Card_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Card_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Card_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Card_+3A_mu">mu</code>, <code id="Card_+3A_rho">rho</code></td>
<td>

<p>See <code><a href="#topic+cardioid">cardioid</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="Card_+3A_tolerance">tolerance</code>, <code id="Card_+3A_maxits">maxits</code>, <code id="Card_+3A_...">...</code></td>
<td>

<p>The first two are control parameters for the algorithm used
to solve for the roots of a nonlinear system of equations;
<code>tolerance</code> controls for the accuracy and <code>maxits</code>
is the maximum number of iterations.  <code>rcard</code> calls
<code>qcard</code> so the <code>...</code> can be used to vary the
two arguments.
</p>
</td></tr>
<tr><td><code id="Card_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Card_+3A_lower.tail">lower.tail</code>, <code id="Card_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+cardioid">cardioid</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the two parameters by maximum likelihood
estimation, for the formula of the probability density
function and other details.
</p>


<h3>Value</h3>

<p><code>dcard</code> gives the density,
<code>pcard</code> gives the distribution function,
<code>qcard</code> gives the quantile function, and
<code>rcard</code> generates random deviates.
</p>


<h3>Note</h3>

<p>Convergence problems might occur with <code>rcard</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+cardioid">cardioid</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mu &lt;- 4; rho &lt;- 0.4; x &lt;- seq(0, 2*pi, len = 501)
plot(x, dcard(x, mu, rho), type = "l", las = 1, ylim = c(0, 1),
     ylab = paste("[dp]card(mu=", mu, ", rho=", rho, ")"),
     main = "Blue is density, orange is the CDF", col = "blue",
     sub = "Purple lines are the 10,20,...,90 percentiles")
lines(x, pcard(x, mu, rho), col = "orange")

probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qcard(probs, mu, rho)
lines(Q, dcard(Q, mu, rho), col = "purple", lty = 3, type = "h")
lines(Q, pcard(Q, mu, rho), col = "purple", lty = 3, type = "h")
abline(h = c(0,probs, 1), v = c(0, 2*pi), col = "purple", lty = 3)
max(abs(pcard(Q, mu, rho) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='cardioid'> Cardioid Distribution Family Function </h2><span id='topic+cardioid'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the
cardioid distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cardioid(lmu = extlogitlink(min = 0, max = 2*pi),
         lrho = extlogitlink(min = -0.5, max = 0.5),
         imu = NULL, irho = 0.3, nsimEIM = 100, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cardioid_+3A_lmu">lmu</code>, <code id="cardioid_+3A_lrho">lrho</code></td>
<td>

<p>Parameter link functions applied to the <code class="reqn">\mu</code>
and <code class="reqn">\rho</code> parameters, respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="cardioid_+3A_imu">imu</code>, <code id="cardioid_+3A_irho">irho</code></td>
<td>

<p>Initial values.
A <code>NULL</code> means an initial value is chosen internally.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="cardioid_+3A_nsimeim">nsimEIM</code>, <code id="cardioid_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two-parameter cardioid distribution
has a density that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y;\mu,\rho) = \frac{1}{2\pi}
        \left(1 + 2\, \rho \cos(y - \mu) \right) </code>
</p>

<p>where <code class="reqn">0 &lt; y &lt; 2\pi</code>,
<code class="reqn">0 &lt; \mu &lt; 2\pi</code>, and
<code class="reqn">-0.5 &lt; \rho &lt; 0.5</code> is the concentration
parameter.
The default link functions enforce the range constraints of
the parameters.
</p>
<p>For positive <code class="reqn">\rho</code> the distribution is unimodal and
symmetric about <code class="reqn">\mu</code>.
The mean of <code class="reqn">Y</code> (which make up the fitted values) is
<code class="reqn">\pi + (\rho/\pi) ((2 \pi-\mu) \sin(2 \pi-\mu) +
       \cos(2 \pi-\mu) - \mu \sin(\mu) - \cos(\mu))</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, <code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Numerically, this distribution can be difficult to fit because
of a log-likelihood having multiple maximums.  The user is
therefore encouraged to try different starting values, i.e.,
make use of <code>imu</code> and <code>irho</code>.
</p>


<h3>Note</h3>

<p>Fisher scoring using simulation is used.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Jammalamadaka, S. R. and SenGupta, A. (2001).
<em>Topics in Circular Statistics</em>,
Singapore: World Scientific.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rcard">rcard</a></code>,
<code><a href="#topic+extlogitlink">extlogitlink</a></code>,
<code><a href="#topic+vonmises">vonmises</a></code>.
</p>
<p><span class="pkg">CircStats</span> and <span class="pkg">circular</span> currently have a lot more
R functions for circular data than the <span class="pkg">VGAM</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
cdata &lt;- data.frame(y = rcard(n = 1000, mu = 4, rho = 0.45))
fit &lt;- vglm(y ~ 1, cardioid, data = cdata, trace = TRUE)
coef(fit, matrix=TRUE)
Coef(fit)
c(with(cdata, mean(y)), head(fitted(fit), 1))
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='cauchitlink'> Cauchit Link Function </h2><span id='topic+cauchitlink'></span>

<h3>Description</h3>

<p>Computes the cauchit (tangent) link transformation, including
its inverse and the first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cauchitlink(theta, bvalue = .Machine$double.eps,
            inverse = FALSE, deriv = 0, short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cauchitlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="cauchitlink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="cauchitlink_+3A_inverse">inverse</code>, <code id="cauchitlink_+3A_deriv">deriv</code>, <code id="cauchitlink_+3A_short">short</code>, <code id="cauchitlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This link function is an alternative link function for
parameters that lie in the unit interval.  This type of
link bears the same relation to the Cauchy distribution as
the probit link bears to the Gaussian. One characteristic
of this link function is that the tail is heavier relative
to the other links (see examples below).
</p>
<p>Numerical values of <code>theta</code> close to 0 or 1 or out
of range result in <code>Inf</code>, <code>-Inf</code>, <code>NA</code>
or <code>NaN</code>.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the tangent of <code>theta</code>, i.e.,
<code>tan(pi * (theta-0.5))</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>0.5 + atan(theta)/pi</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of
<code>theta</code> if <code>inverse = FALSE</code>, else if <code>inverse
  = TRUE</code> then it returns the reciprocal.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is close to
1 or 0.  One way of overcoming this is to use <code>bvalue</code>.
</p>
<p>As mentioned above,
in terms of the threshold approach with cumulative
probabilities for an ordinal response this link
function corresponds to the Cauchy distribution (see
<code><a href="#topic+cauchy1">cauchy1</a></code>).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+cauchy">cauchy</a></code>,
<code><a href="#topic+cauchy1">cauchy1</a></code>,
<code><a href="stats.html#topic+Cauchy">Cauchy</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, by = 0.01)
cauchitlink(p)
max(abs(cauchitlink(cauchitlink(p), inverse = TRUE) - p))  # Should be 0

p &lt;- c(seq(-0.02, 0.02, by=0.01), seq(0.97, 1.02, by = 0.01))
cauchitlink(p)  # Has no NAs

## Not run: 
par(mfrow = c(2, 2), lwd = (mylwd &lt;- 2))
y &lt;- seq(-4, 4, length = 100)
p &lt;- seq(0.01, 0.99, by = 0.01)

for (d in 0:1) {
  matplot(p, cbind(logitlink(p, deriv = d), probitlink(p, deriv = d)),
          type = "n", col = "purple", ylab = "transformation",
          las = 1, main = if (d == 0) "Some probability link functions"
          else "First derivative")
  lines(p,   logitlink(p, deriv = d), col = "limegreen")
  lines(p,  probitlink(p, deriv = d), col = "purple")
  lines(p, clogloglink(p, deriv = d), col = "chocolate")
  lines(p, cauchitlink(p, deriv = d), col = "tan")
  if (d == 0) {
    abline(v = 0.5, h = 0, lty = "dashed")
    legend(0, 4.5, c("logitlink", "probitlink", "clogloglink",
           "cauchitlink"), lwd = mylwd,
           col = c("limegreen", "purple", "chocolate", "tan"))
  } else
    abline(v = 0.5, lty = "dashed")
}

for (d in 0) {
  matplot(y, cbind( logitlink(y, deriv = d, inverse = TRUE),
                   probitlink(y, deriv = d, inverse = TRUE)),
          type  = "n", col = "purple", xlab = "transformation", ylab = "p",
          main = if (d == 0) "Some inverse probability link functions"
          else "First derivative", las=1)
  lines(y,   logitlink(y, deriv = d, inverse = TRUE), col = "limegreen")
  lines(y,  probitlink(y, deriv = d, inverse = TRUE), col = "purple")
  lines(y, clogloglink(y, deriv = d, inverse = TRUE), col = "chocolate")
  lines(y, cauchitlink(y, deriv = d, inverse = TRUE), col = "tan")
  if (d == 0) {
      abline(h = 0.5, v = 0, lty = "dashed")
      legend(-4, 1, c("logitlink", "probitlink", "clogloglink",
             "cauchitlink"), lwd = mylwd,
             col = c("limegreen", "purple", "chocolate", "tan"))
  }
}
par(lwd = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='cauchy'> Cauchy Distribution Family Function </h2><span id='topic+cauchy'></span><span id='topic+cauchy1'></span>

<h3>Description</h3>

<p>Estimates either the location parameter or both the location and scale
parameters of the Cauchy distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cauchy(llocation = "identitylink", lscale = "loglink",
       imethod = 1, ilocation = NULL, iscale = NULL,
       gprobs.y = ppoints(19), gscale.mux = exp(-3:3), zero = "scale")
cauchy1(scale.arg = 1, llocation = "identitylink", ilocation = NULL,
        imethod = 1, gprobs.y = ppoints(19), zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cauchy_+3A_llocation">llocation</code>, <code id="cauchy_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions for the location parameter <code class="reqn">a</code>
and the scale parameter <code class="reqn">b</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="cauchy_+3A_ilocation">ilocation</code>, <code id="cauchy_+3A_iscale">iscale</code></td>
<td>

<p>Optional initial value for <code class="reqn">a</code> and <code class="reqn">b</code>.
By default, an initial value is chosen internally for each.
</p>
</td></tr>
<tr><td><code id="cauchy_+3A_imethod">imethod</code></td>
<td>

<p>Integer, either 1 or 2 or 3.
Initial method, three algorithms are implemented.
The user should try all possible values to help avoid
converging to a local solution.
Also, choose the another value if convergence fails, or use
<code>ilocation</code> and/or <code>iscale</code>.
</p>
</td></tr>
<tr><td><code id="cauchy_+3A_gprobs.y">gprobs.y</code>, <code id="cauchy_+3A_gscale.mux">gscale.mux</code>, <code id="cauchy_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="cauchy_+3A_scale.arg">scale.arg</code></td>
<td>

<p>Known (positive) scale parameter, called <code class="reqn">b</code> below.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cauchy distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;a,b) = \left\{ \pi  b [1 + ((y-a)/b)^2] \right\}^{-1} </code>
</p>

<p>where <code class="reqn">y</code> and <code class="reqn">a</code> are real and finite,
and <code class="reqn">b&gt;0</code>.
The distribution is symmetric about <code class="reqn">a</code> and has a heavy tail.
Its median and mode are <code class="reqn">a</code>, but the mean does not exist.
The fitted values are the estimates of <code class="reqn">a</code>.
Fisher scoring is used.
</p>


<p>If the scale parameter is known (<code>cauchy1</code>) then there
may be multiple local maximum likelihood solutions for the
location parameter. However, if both location and scale
parameters are to be estimated (<code>cauchy</code>) then there
is a unique maximum likelihood solution provided <code class="reqn">n &gt;
  2</code> and less than half the data are located at any one point.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>It is well-known that the Cauchy distribution may have
local maximums in its likelihood function; make full use of
<code>imethod</code>, <code>ilocation</code>, <code>iscale</code> etc.
</p>


<h3>Note</h3>

<p>Good initial values are needed.
By default <code>cauchy</code> searches for a starting
value for <code class="reqn">a</code> and <code class="reqn">b</code> on a 2-D grid.
Likewise, by default, <code>cauchy1</code> searches for a starting
value for <code class="reqn">a</code> on a 1-D grid.
If convergence to the global maximum is not acheieved then
it also pays to select a wide range
of initial values via the <code>ilocation</code> and/or
<code>iscale</code> and/or <code>imethod</code> arguments.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>
<p>Barnett, V. D. (1966).
Evaluation of the maximum-likehood estimator where the
likelihood equation has multiple roots.
<em>Biometrika</em>,
<b>53</b>, 151&ndash;165.
</p>
<p>Copas, J. B. (1975).
On the unimodality of the likelihood for the Cauchy
distribution.
<em>Biometrika</em>,
<b>62</b>, 701&ndash;704.
</p>
<p>Efron, B. and Hinkley, D. V. (1978).
Assessing the accuracy of the maximum likelihood estimator:
Observed versus expected Fisher information.
<em>Biometrika</em>,
<b>65</b>, 457&ndash;481.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Cauchy">Cauchy</a></code>,
<code><a href="#topic+cauchit">cauchit</a></code>,
<code><a href="#topic+studentt">studentt</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Both location and scale parameters unknown
set.seed(123)
cdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
cdata &lt;- transform(cdata, loc = exp(1 + 0.5 * x2), scale = exp(1))
cdata &lt;- transform(cdata, y2 = rcauchy(nn, loc, scale))
fit2 &lt;- vglm(y2 ~ x2, cauchy(lloc = "loglink"), data = cdata)
coef(fit2, matrix = TRUE)
head(fitted(fit2))  # Location estimates
summary(fit2)

# Location parameter unknown
cdata &lt;- transform(cdata, scale1 = 0.4)
cdata &lt;- transform(cdata, y1 = rcauchy(nn, loc, scale1))
fit1 &lt;- vglm(y1 ~ x2, cauchy1(scale = 0.4), data = cdata, trace = TRUE)
coef(fit1, matrix = TRUE)
</code></pre>

<hr>
<h2 id='cdf.lmscreg'> Cumulative Distribution Function for LMS Quantile Regression </h2><span id='topic+cdf.lmscreg'></span>

<h3>Description</h3>

<p>Computes the cumulative distribution function (CDF) for
observations, based on a LMS quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdf.lmscreg(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdf.lmscreg_+3A_object">object</code></td>
<td>

<p>A <span class="pkg">VGAM</span> quantile regression model, i.e.,
an object produced by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code> with a family
function beginning with <code>"lms."</code>.
</p>
</td></tr>
<tr><td><code id="cdf.lmscreg_+3A_newdata">newdata</code></td>
<td>
<p> Data frame where the predictions are
to be made. If missing, the original data is used.
</p>
</td></tr>
<tr><td><code id="cdf.lmscreg_+3A_...">...</code></td>
<td>

<p>Parameters which are passed into functions such as
<code>cdf.lms.yjn</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CDFs returned here are values lying in [0,1] giving
the relative probabilities associated with the quantiles
<code>newdata</code>.  For example, a value near 0.75 means it is
close to the upper quartile of the distribution.
</p>


<h3>Value</h3>

<p>A vector of CDF values lying in [0,1].
</p>


<h3>Note</h3>

<p>The data are treated like quantiles, and the
percentiles are returned. The opposite is performed by
<code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>.
</p>
<p>The CDF values of the model have been placed in
<code>@post$cdf</code> when the model was fitted.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>,
<code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+lms.bcg">lms.bcg</a></code>,
<code><a href="#topic+lms.yjn">lms.yjn</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- vgam(BMI ~ s(age, df=c(4, 2)), lms.bcn(zero = 1), data = bmi.nz)
head(fit@post$cdf)
head(cdf(fit))  # Same
head(depvar(fit))
head(fitted(fit))

cdf(fit, data.frame(age = c(31.5, 39), BMI = c(28.4, 24)))
</code></pre>

<hr>
<h2 id='cens.gumbel'> Censored Gumbel Distribution </h2><span id='topic+cens.gumbel'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter Gumbel
distribution when there are censored observations.  A matrix
response is not allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cens.gumbel(llocation = "identitylink", lscale = "loglink",
            iscale = NULL, mean = TRUE, percentiles = NULL,
            zero = "scale")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cens.gumbel_+3A_llocation">llocation</code>, <code id="cens.gumbel_+3A_lscale">lscale</code></td>
<td>

<p>Character.
Parameter link functions for the location and
(positive) <code class="reqn">scale</code> parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="cens.gumbel_+3A_iscale">iscale</code></td>
<td>

<p>Numeric and positive.
Initial value for <code class="reqn">scale</code>. Recycled to the appropriate
length.  In general, a larger value is better than a smaller
value.  The default is to choose the value internally.
</p>
</td></tr>
<tr><td><code id="cens.gumbel_+3A_mean">mean</code></td>
<td>

<p>Logical. Return the mean? If <code>TRUE</code> then the
mean is returned, otherwise percentiles given by the
<code>percentiles</code> argument.
</p>
</td></tr>
<tr><td><code id="cens.gumbel_+3A_percentiles">percentiles</code></td>
<td>

<p>Numeric with values between 0 and 100.
If <code>mean=FALSE</code> then the fitted values are percentiles
which must be specified by this argument.
</p>
</td></tr>
<tr><td><code id="cens.gumbel_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which linear/additive
predictors are modelled as intercepts only.  The value
(possibly values) must be from the set {1,2} corresponding
respectively to <code class="reqn">location</code> and <code class="reqn">scale</code>.
If <code>zero=NULL</code> then all linear/additive predictors
are modelled as a linear combination of the explanatory
variables.  The default is to fit the shape parameter as
an intercept only.  See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <span class="pkg">VGAM</span> family function is like <code><a href="#topic+gumbel">gumbel</a></code>
but handles observations that are left-censored (so that
the true value would be less than the observed value) else
right-censored (so that the true value would be greater than
the observed value). To indicate which type of censoring,
input
<code>extra = list(leftcensored = vec1, rightcensored = vec2)</code>
where <code>vec1</code> and <code>vec2</code> are logical vectors
the same length as the response.
If the two components of this list are missing then the
logical values are taken to be <code>FALSE</code>.  The fitted
object has these two components stored in the <code>extra</code>
slot.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>Numerical problems may occur if the amount of censoring
is excessive.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+gumbel">gumbel</a></code> for details about the Gumbel
distribution.  The initial values are based on assuming all
uncensored observations, therefore could be improved upon.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gumbel">gumbel</a></code>,
<code><a href="#topic+gumbelff">gumbelff</a></code>,
<code><a href="#topic+rgumbel">rgumbel</a></code>,
<code><a href="#topic+guplot">guplot</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+venice">venice</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
ystar &lt;- venice[["r1"]]  # Use the first order statistic as the response
nn &lt;- length(ystar)
L &lt;- runif(nn, 100, 104)  # Lower censoring points
U &lt;- runif(nn, 130, 135)  # Upper censoring points
y &lt;- pmax(L, ystar)  # Left  censored
y &lt;- pmin(U, y)      # Right censored
extra &lt;- list(leftcensored = ystar &lt; L, rightcensored = ystar &gt; U)
fit &lt;- vglm(y ~ scale(year), data = venice, trace = TRUE, extra = extra,
            fam = cens.gumbel(mean = FALSE, perc = c(5, 25, 50, 75, 95)))
coef(fit, matrix = TRUE)
head(fitted(fit))
fit@extra

# Example 2: simulated data
nn &lt;- 1000
ystar &lt;- rgumbel(nn, loc = 1, scale = exp(0.5))  # The uncensored data
L &lt;- runif(nn, -1, 1)  # Lower censoring points
U &lt;- runif(nn,  2, 5)  # Upper censoring points
y &lt;- pmax(L, ystar)  # Left  censored
y &lt;- pmin(U, y)      # Right censored
## Not run: par(mfrow = c(1, 2)); hist(ystar); hist(y);
extra &lt;- list(leftcensored = ystar &lt; L, rightcensored = ystar &gt; U)
fit &lt;- vglm(y ~ 1, trace = TRUE, extra = extra, fam = cens.gumbel)
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='cens.normal'> Censored Normal Distribution </h2><span id='topic+cens.normal'></span><span id='topic+cennormal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for the normal distribution with
left and right censoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cens.normal(lmu = "identitylink", lsd = "loglink", imethod = 1,
            zero = "sd")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cens.normal_+3A_lmu">lmu</code>, <code id="cens.normal_+3A_lsd">lsd</code></td>
<td>

<p>Parameter link functions
applied to the mean and standard deviation parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The standard deviation is a positive quantity, therefore a
log link is the default.
</p>
</td></tr>
<tr><td><code id="cens.normal_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method. Either 1 or 2, this specifies
two methods for obtaining initial values for the parameters.
</p>
</td></tr>
<tr><td><code id="cens.normal_+3A_zero">zero</code></td>
<td>

<p>A vector, e.g., containing the value 1 or 2; if so,
the mean or standard deviation respectively are modelled
as an intercept only.
Setting <code>zero = NULL</code> means both linear/additive predictors
are modelled as functions of the explanatory variables.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is like <code><a href="#topic+uninormal">uninormal</a></code> but handles
observations that are left-censored (so that the true value
would be less than the observed value) else right-censored
(so that the true value would be greater than the observed
value). To indicate which type of censoring, input <code>extra
  = list(leftcensored = vec1, rightcensored = vec2)</code> where
<code>vec1</code> and <code>vec2</code> are logical vectors the same length
as the response.
If the two components of this list are missing then the logical
values are taken to be <code>FALSE</code>.  The fitted object has
these two components stored in the <code>extra</code> slot.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This function, which is an alternative to <code><a href="#topic+tobit">tobit</a></code>,
cannot handle a matrix response
and uses different working weights.
If there are no censored observations then
<code><a href="#topic+uninormal">uninormal</a></code> is recommended instead.
</p>




<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+tobit">tobit</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+double.cens.normal">double.cens.normal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
cdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))  # ystar are true values
cdata &lt;- transform(cdata, ystar = rnorm(nn, m = 100 + 15 * x2, sd = exp(3)))
with(cdata, hist(ystar))
cdata &lt;- transform(cdata, L = runif(nn,  80,  90),  # Lower censoring points
                          U = runif(nn, 130, 140))  # Upper censoring points
cdata &lt;- transform(cdata, y = pmax(L, ystar))  # Left  censored
cdata &lt;- transform(cdata, y = pmin(U, y))      # Right censored
with(cdata, hist(y))
Extra &lt;- list(leftcensored  = with(cdata, ystar &lt; L),
              rightcensored = with(cdata, ystar &gt; U))
fit1 &lt;- vglm(y ~ x2, cens.normal, data = cdata, crit = "c", extra = Extra)
fit2 &lt;- vglm(y ~ x2, tobit(Lower = with(cdata, L), Upper = with(cdata, U)),
            data = cdata, crit = "c", trace = TRUE)
coef(fit1, matrix = TRUE)
max(abs(coef(fit1, matrix = TRUE) -
        coef(fit2, matrix = TRUE)))  # Should be 0
names(fit1@extra)

## End(Not run)
</code></pre>

<hr>
<h2 id='cens.poisson'> Censored Poisson Family Function </h2><span id='topic+cens.poisson'></span>

<h3>Description</h3>

<p>Family function for a censored
Poisson response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cens.poisson(link = "loglink", imu = NULL,
             biglambda = 10, smallno = 1e-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cens.poisson_+3A_link">link</code></td>
<td>

<p>Link function applied to the mean;
see <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="cens.poisson_+3A_imu">imu</code></td>
<td>

<p>Optional initial value;
see <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="cens.poisson_+3A_biglambda">biglambda</code>, <code id="cens.poisson_+3A_smallno">smallno</code></td>
<td>

<p>Used to help robustify the code when <code>lambda</code> is very large
and the <code><a href="stats.html#topic+ppois">ppois</a></code> value is so close to 0 that
the first derivative is computed to be a <code>NA</code> or <code>NaN</code>.
When this occurs  <code><a href="#topic+mills.ratio">mills.ratio</a></code> is called.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Often a table of Poisson counts has an entry <em>J+</em> meaning
<code class="reqn">\ge J</code>.
This family function is similar to <code><a href="#topic+poissonff">poissonff</a></code> but handles
such censored data. The input requires <code><a href="#topic+SurvS4">SurvS4</a></code>.
Only a univariate response is allowed.
The Newton-Raphson algorithm is used.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code> and
<code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>As the response is discrete,
care is required with <code><a href="survival.html#topic+Surv">Surv</a></code>, especially with
<code>"interval"</code> censored data because of the
<code>(start, end]</code> format.
See the examples below.
The examples have
<code>y &lt; L</code> as left censored and
<code>y &gt;= U</code> (formatted as <code>U+</code>) as right censored observations,
therefore
<code>L &lt;= y &lt;  U</code> is for uncensored and/or interval censored
observations.
Consequently the input must be tweaked to conform to the
<code>(start, end]</code> format.
</p>
<p>A bit of attention has been directed to try robustify the code
when <code>lambda</code> is very large, however this currently works
for left and right censored data only, not interval
censored data. Sometime the fix involves an approximation,
hence it is a good idea to set <code>trace = TRUE</code>.
</p>


<h3>Note</h3>

<p>The function <code><a href="#topic+poissonff">poissonff</a></code> should be used
when there are no censored observations.
Also, <code>NA</code>s are not permitted with <code><a href="#topic+SurvS4">SurvS4</a></code>,
nor is <code>type = "counting"</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>See <span class="pkg">survival</span> for background.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SurvS4">SurvS4</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+mills.ratio">mills.ratio</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: right censored data
set.seed(123); U &lt;- 20
cdata &lt;- data.frame(y = rpois(N &lt;- 100, exp(3)))
cdata &lt;- transform(cdata, cy = pmin(U, y),
                          rcensored = (y &gt;= U))
cdata &lt;- transform(cdata, status = ifelse(rcensored, 0, 1))
with(cdata, table(cy))
with(cdata, table(rcensored))
with(cdata, table(print(SurvS4(cy, status))))  # Check; U+ means &gt;= U
fit &lt;- vglm(SurvS4(cy, status) ~ 1, cens.poisson, data = cdata,
            trace = TRUE)
coef(fit, matrix = TRUE)
table(print(depvar(fit)))  # Another check; U+ means &gt;= U

# Example 2: left censored data
L &lt;- 15
cdata &lt;- transform(cdata,
               cY = pmax(L, y),
               lcensored = y &lt;  L)  # Note y &lt; L, not cY == L or y &lt;= L
cdata &lt;- transform(cdata, status = ifelse(lcensored, 0, 1))
with(cdata, table(cY))
with(cdata, table(lcensored))
with(cdata, table(print(SurvS4(cY, status, type = "left"))))  # Check
fit &lt;- vglm(SurvS4(cY, status, type = "left") ~ 1, cens.poisson,
            data = cdata, trace = TRUE)
coef(fit, matrix = TRUE)

# Example 3: interval censored data
cdata &lt;- transform(cdata, Lvec = rep(L, len = N),
                          Uvec = rep(U, len = N))
cdata &lt;-
  transform(cdata,
        icensored = Lvec &lt;= y &amp; y &lt; Uvec)  # Not lcensored or rcensored
with(cdata, table(icensored))
cdata &lt;- transform(cdata, status = rep(3, N))  # 3 == interval censored
cdata &lt;- transform(cdata,
         status = ifelse(rcensored, 0, status))  # 0 means right censored
cdata &lt;- transform(cdata,
         status = ifelse(lcensored, 2, status))  # 2 means left  censored
# Have to adjust Lvec and Uvec because of the (start, end] format:
cdata$Lvec[with(cdata,icensored)] &lt;- cdata$Lvec[with(cdata,icensored)]-1
cdata$Uvec[with(cdata,icensored)] &lt;- cdata$Uvec[with(cdata,icensored)]-1
# Unchanged:
cdata$Lvec[with(cdata, lcensored)] &lt;- cdata$Lvec[with(cdata, lcensored)]
cdata$Lvec[with(cdata, rcensored)] &lt;- cdata$Uvec[with(cdata, rcensored)]
with(cdata,  # Check
 table(ii &lt;- print(SurvS4(Lvec, Uvec, status, type = "interval"))))
fit &lt;- vglm(SurvS4(Lvec, Uvec, status, type = "interval") ~ 1,
            cens.poisson, data = cdata, trace = TRUE)
coef(fit, matrix = TRUE)
table(print(depvar(fit)))  # Another check

# Example 4: Add in some uncensored observations
index &lt;- (1:N)[with(cdata, icensored)]
index &lt;- head(index, 4)
cdata$status[index] &lt;- 1  # actual or uncensored value
cdata$Lvec[index] &lt;- cdata$y[index]
with(cdata, table(ii &lt;- print(SurvS4(Lvec, Uvec, status,
                                     type = "interval"))))  # Check
fit &lt;- vglm(SurvS4(Lvec, Uvec, status, type = "interval") ~ 1,
            cens.poisson, data = cdata, trace = TRUE, crit = "c")
coef(fit, matrix = TRUE)
table(print(depvar(fit)))  # Another check
</code></pre>

<hr>
<h2 id='cfibrosis'> Cystic Fibrosis Data

</h2><span id='topic+cfibrosis'></span>

<h3>Description</h3>

<p>This data frame concerns families data
and cystic fibrosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cfibrosis)
</code></pre>


<h3>Format</h3>

<p>A data frame with 24 rows on the following 4 variables.
</p>

<dl>
<dt>siblings, affected, ascertained, families</dt><dd>
<p>Over ascertained families, the <code class="reqn">k</code>th ascertained family
has <code class="reqn">s_k</code> siblings of whom <code class="reqn">r_k</code>
are affected and <code class="reqn">a_k</code> are ascertained.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data set allows a classical segregation analysis
to be peformed. In particular,
to test Mendelian segregation ratios in nuclear family data.
The likelihood has similarities with <code><a href="#topic+seq2binomial">seq2binomial</a></code>.
</p>



<h3>Source</h3>

<p>The data is originally from Crow (1965) and
appears as Table 2.3 of Lange (2002).
</p>
<p>Crow, J. F. (1965)
Problems of ascertainment in the analysis of family data.
Epidemiology and Genetics of Chronic Disease.
Public Health Service Publication 1163,
Neel J. V., Shaw M. W., Schull W. J., editors,
Department of Health, Education, and Welfare, Washington, DC,
USA.
</p>
<p>Lange, K. (2002)
Mathematical and Statistical Methods for Genetic Analysis.
Second Edition.
Springer-Verlag: New York, USA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cfibrosis
summary(cfibrosis)
</code></pre>

<hr>
<h2 id='cgo'> Redirects the user to cqo </h2><span id='topic+cgo'></span>

<h3>Description</h3>

<p>Redirects the user to the function <code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cgo(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cgo_+3A_...">...</code></td>
<td>
<p> Ignored. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The former function <code>cgo</code> has been renamed <code><a href="#topic+cqo">cqo</a></code>
because CGO (for <em>canonical Gaussian ordination</em>) is a confusing
and inaccurate name.
CQO (for <em>constrained quadratic ordination</em>) is better.
This new nomenclature described in Yee (2006).
</p>


<h3>Value</h3>

<p>Nothing is returned; an error message is issued.
</p>


<h3>Warning </h3>

<p>The code, therefore, in Yee (2004) will not run without changing the
<code>"g"</code> to a <code>"q"</code>.
</p>


<h3>Author(s)</h3>

<p>Thomas W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
cgo()

## End(Not run)

</code></pre>

<hr>
<h2 id='chest.nz'> Chest Pain in NZ Adults Data</h2><span id='topic+chest.nz'></span>

<h3>Description</h3>

<p>Presence/absence of chest pain in 10186 New Zealand adults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chest.nz)</code></pre>


<h3>Format</h3>

<p>A data frame with 73 rows and the following 5 variables.
</p>

<dl>
<dt>age</dt><dd><p>a numeric vector; age (years).</p>
</dd>
<dt>nolnor</dt><dd><p>a numeric vector of counts; no pain on LHS or RHS.</p>
</dd>
<dt>nolr</dt><dd><p>a numeric vector of counts; no pain on LHS but pain on RHS.</p>
</dd>
<dt>lnor</dt><dd><p>a numeric vector of counts; no pain on RHS but pain on LHS.</p>
</dd>
<dt>lr</dt><dd><p>a numeric vector of counts; pain on LHS and RHS of chest.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Each adult was asked their age and whether they experienced any
pain or discomfort in their chest over the last six months.
If yes, they indicated whether it
was on their LHS and/or RHS of their chest.
</p>


<h3>Source</h3>

<p>MacMahon, S., Norton, R., Jackson, R., Mackie, M. J.,
Cheng, A., Vander Hoorn, S., Milne, A., McCulloch, A. (1995)
Fletcher Challenge-University of Auckland Heart &amp;
Health Study: design and baseline findings.
<em>New Zealand Medical Journal</em>,
<b>108</b>, 499&ndash;502.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fit &lt;- vgam(cbind(nolnor, nolr, lnor, lr) ~ s(age, c(4, 3)),
            binom2.or(exchan = TRUE, zero = NULL), data = chest.nz)
coef(fit, matrix = TRUE)

## End(Not run)
## Not run:  plot(fit, which.cf = 2, se = TRUE) 
</code></pre>

<hr>
<h2 id='chinese.nz'> Chinese Population in New Zealand 1867&ndash;2001 Data</h2><span id='topic+chinese.nz'></span>

<h3>Description</h3>

<p>The  Chinese population in New Zealand from 1867 to 2001,
along with the whole of the New Zealand population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chinese.nz)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 4 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>Year. </p>
</dd>
<dt><code>male</code></dt><dd><p>Number of Chinese males. </p>
</dd>
<dt><code>female</code></dt><dd><p>Number of Chinese females. </p>
</dd>
<dt><code>nz</code></dt><dd><p>Total number in the New Zealand population. </p>
</dd>
</dl>



<h3>Details</h3>

<p>Historically, there was a large exodus of Chinese from the Guangdong
region starting in the mid-1800s to the gold fields of
South Island of New Zealand,
California  (a region near Mexico),
and southern Australia, etc.
Discrimination then meant that only men were allowed
entry, to hinder permanent settlement.
In the case of New Zealand, the government relaxed its
immigration laws after WWII to allow wives of Chinese already in NZ to join them
because China had been among the Allied powers.
Gradual relaxation in the immigration and an influx during the 1980s
meant the Chinese population became increasingly demographically
normal over time.
</p>
<p>The NZ total for the years 1867 and 1871 exclude the Maori population.
Three modifications have been made to the female column to make
the data internally consistent with the original table.
</p>



<h3>References</h3>

<p>Page 6 of <em>Aliens At My Table: Asians as New Zealanders See Them</em>
by M. Ip and N. Murphy, (2005).
Penguin Books.
Auckland, New Zealand.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  par(mfrow = c(1, 2))
plot(female / (male + female) ~ year, chinese.nz, type = "b",
     ylab = "Proportion", col = "blue", las = 1,
     cex = 0.015 * sqrt(male + female),
#    cex = 0.10 * sqrt((male + female)^1.5 / sqrt(female) / sqrt(male)),
     main = "Proportion of NZ Chinese that are female")
abline(h = 0.5, lty = "dashed", col = "gray")

fit1.cnz &lt;- vglm(cbind(female, male) ~ year,             binomialff,
                 data = chinese.nz)
fit2.cnz &lt;- vglm(cbind(female, male) ~ sm.poly(year, 2), binomialff,
                 data = chinese.nz)
fit4.cnz &lt;- vglm(cbind(female, male) ~   sm.bs(year, 5), binomialff,
                 data = chinese.nz)

lines(fitted(fit1.cnz) ~ year, chinese.nz, col = "purple", lty = 1)
lines(fitted(fit2.cnz) ~ year, chinese.nz, col = "green", lty = 2)
lines(fitted(fit4.cnz) ~ year, chinese.nz, col = "orange", lwd = 2, lty = 1)
legend("bottomright", col = c("purple", "green", "orange"),
       lty = c(1, 2, 1), leg = c("linear", "quadratic", "B-spline"))

plot(100*(male+female)/nz ~ year, chinese.nz, type = "b", ylab = "Percent",
     ylim = c(0, max(100*(male+female)/nz)), col = "blue", las = 1,
     main = "Percent of NZers that are Chinese")
abline(h = 0, lty = "dashed", col = "gray") 
## End(Not run)
</code></pre>

<hr>
<h2 id='chisq'> Chi-squared and Chi Distributions </h2><span id='topic+chisq'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the degrees of freedom for
a chi-squared distribution. Also fits the chi distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq(link = "loglink", zero = NULL, squared = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chisq_+3A_link">link</code>, <code id="chisq_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
information.
</p>
</td></tr>
<tr><td><code id="chisq_+3A_squared">squared</code></td>
<td>

<p>Logical.
Set <code>FALSE</code> for the chi distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The degrees of freedom is treated as a
real parameter to be estimated
and not as an integer.
Being positive, a log link is used by default.
Fisher scoring is used.
</p>
<p>If a random variable has a chi-squared
distribution then the 
square root of the random variable
has a chi distribution.
For both distributions,
the fitted value is the mean.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Multiple responses are permitted.
There may be convergence problems if the degrees of freedom
is very large or close to zero.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Chisquare">Chisquare</a></code>.
<code><a href="#topic+uninormal">uninormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
cdata &lt;- transform(cdata, y1 = rchisq(nn, df = exp(1 - 1 * x2)),
                          y2 = rchisq(nn, df = exp(2 - 2 * x2)))
fit &lt;- vglm(cbind(y1, y2) ~ x2, chisq, data = cdata, trace = TRUE)
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='clo'> Redirects the User to rrvglm() </h2><span id='topic+clo'></span>

<h3>Description</h3>

<p>Redirects the user to the function <code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clo(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clo_+3A_...">...</code></td>
<td>
<p> Ignored. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>CLO stands for <em>constrained linear ordination</em>, and
is fitted with a statistical class of models called
<em>reduced-rank vector generalized linear models</em>
(RR-VGLMs). It allows for generalized reduced-rank regression
in that response types such as Poisson counts and presence/absence
data can be handled.
</p>
<p>Currently in the <span class="pkg">VGAM</span> package, <code><a href="#topic+rrvglm">rrvglm</a></code> is
used to fit RR-VGLMs. However, the Author's opinion is that
linear responses to a latent variable (composite environmental
gradient) is not as common as unimodal responses, therefore
<code><a href="#topic+cqo">cqo</a></code> is often more appropriate.
</p>
<p>The new CLO/CQO/CAO nomenclature described in Yee (2006).
</p>


<h3>Value</h3>

<p>Nothing is returned; an error message is issued.
</p>


<h3>Author(s)</h3>

<p>Thomas W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
clo()

## End(Not run)

</code></pre>

<hr>
<h2 id='clogloglink'> Complementary Log-log Link Function </h2><span id='topic+clogloglink'></span><span id='topic+cloglink'></span>

<h3>Description</h3>

<p>Computes the complementary log-log
transformation,
including its inverse and the
first two derivatives.
The complementary log transformation is also
computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clogloglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
            short = TRUE, tag = FALSE)
   cloglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
            short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clogloglink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="clogloglink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code> for general
information about links.
</p>
</td></tr>
<tr><td><code id="clogloglink_+3A_inverse">inverse</code>, <code id="clogloglink_+3A_deriv">deriv</code>, <code id="clogloglink_+3A_short">short</code>, <code id="clogloglink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The complementary log-log link function is
commonly used for parameters
that lie in the unit interval.
But unlike 
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code> and
<code><a href="#topic+cauchitlink">cauchitlink</a></code>, this link is not
symmetric.
It is the inverse CDF of the extreme value
(or Gumbel or log-Weibull) distribution.
Numerical values of <code>theta</code>
close to 0 or 1 or out of range result
in <code>Inf</code>, <code>-Inf</code>, <code>NA</code> or
<code>NaN</code>.
</p>

<p>The complementary log link function is
the same as the complementary log-log
but the outer log is omitted.
This link is suitable for <code>lrho</code> in
<code><a href="#topic+betabinomial">betabinomial</a></code> because it
handles probability-like parameters but
also allows slight negative values in theory.
In particular, <code><a href="#topic+cloglink">cloglink</a></code>
safeguards against parameters exceeding unity.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the complimentary log-log
of <code>theta</code>,
i.e., <code>log(-log(1 - theta))</code> when
<code>inverse = FALSE</code>, and if
<code>inverse = TRUE</code> then
<code>1-exp(-exp(theta))</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code>
as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it
returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms,
i.e., to base <code class="reqn">e</code>.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when
<code>theta</code> is close to 1 or 0.
One way of overcoming this is to use
<code>bvalue</code>.
</p>
<p>Changing 1s to 0s and 0s to 1s in the
response means that effectively
a loglog link is fitted. That is,
tranform <code class="reqn">y</code> by <code class="reqn">1-y</code>.
That's why only one of <code><a href="#topic+clogloglink">clogloglink</a></code>
and <code>logloglink</code> is written.
</p>
<p>With constrained ordination
(e.g., <code><a href="#topic+cqo">cqo</a></code> and
<code><a href="#topic+cao">cao</a></code>) used with
<code><a href="#topic+binomialff">binomialff</a></code>, a complementary
log-log link function is preferred over the
default <code><a href="#topic+logitlink">logitlink</a></code>,
for a good reason.  See the example below.
</p>
<p>In terms of the threshold approach with
cumulative probabilities for
an ordinal response this link function
corresponds to the extreme
value distribution.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed.
London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+logitoffsetlink">logitoffsetlink</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="#topic+pgumbel">pgumbel</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, by = 0.01)
clogloglink(p)
max(abs(clogloglink(clogloglink(p), inverse = TRUE) - p))  # Should be 0

p &lt;- c(seq(-0.02, 0.02, by = 0.01), seq(0.97, 1.02, by = 0.01))
clogloglink(p)  # Has NAs
clogloglink(p, bvalue = .Machine$double.eps)  # Has no NAs

## Not run: 
p &lt;- seq(0.01, 0.99, by = 0.01)
plot(p, logitlink(p), type = "l", col = "limegreen", lwd = 2, las = 1,
     main = "Some probability link functions", ylab = "transformation")
lines(p, probitlink(p), col = "purple", lwd = 2)
lines(p, clogloglink(p), col = "chocolate", lwd = 2)
lines(p, cauchitlink(p), col = "tan", lwd = 2)
abline(v = 0.5, h = 0, lty = "dashed")
legend(0.1, 4, c("logitlink", "probitlink", "clogloglink", "cauchitlink"),
       col = c("limegreen", "purple", "chocolate", "tan"), lwd = 2)

## End(Not run)

## Not run: 
# This example shows that clogloglink is preferred over logitlink
n &lt;- 500; p &lt;- 5; S &lt;- 3; Rank &lt;- 1  # Species packing model:
mydata &lt;- rcqo(n, p, S, eq.tol = TRUE, es.opt = TRUE, eq.max = TRUE,
               family = "binomial", hi.abundance = 5, seed = 123,
               Rank = Rank)
fitc &lt;- cqo(attr(mydata, "formula"), I.tol = TRUE, data = mydata,
            fam = binomialff(multiple.responses = TRUE, link = "cloglog"),
            Rank = Rank)
fitl &lt;- cqo(attr(mydata, "formula"), I.tol = TRUE, data = mydata,
            fam = binomialff(multiple.responses = TRUE, link = "logitlink"),
            Rank = Rank)

# Compare the fitted models (cols 1 and 3) with the truth (col 2)
cbind(concoef(fitc), attr(mydata, "concoefficients"), concoef(fitl))

## End(Not run)
</code></pre>

<hr>
<h2 id='CM.equid'> Constraint Matrices for Symmetry, Order,
Parallelism, etc.

</h2><span id='topic+CM.equid'></span><span id='topic+CM.free'></span><span id='topic+CM.ones'></span><span id='topic+CM.symm0'></span><span id='topic+CM.symm1'></span><span id='topic+CM.qnorm'></span><span id='topic+CM.qlogis'></span>

<h3>Description</h3>

<p>Given <em>M</em> linear/additive predictors,
construct the constraint matrices to allow
symmetry, (linear and normal) ordering, etc.
in terms such as the intercept.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CM.equid(M, Trev = FALSE, Tref = 1)
 CM.free(M, Trev = FALSE, Tref = 1)
 CM.ones(M, Trev = FALSE, Tref = 1)
CM.symm0(M, Trev = FALSE, Tref = 1)
CM.symm1(M, Trev = FALSE, Tref = 1)
CM.qnorm(M, Trev = FALSE, Tref = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CM.equid_+3A_m">M</code></td>
<td>
<p> Number of linear/additive predictors,
usually <code class="reqn">&gt;1</code>.
</p>
</td></tr>
<tr><td><code id="CM.equid_+3A_tref">Tref</code></td>
<td>
<p> Reference level for the threshold,
this should be a single value from <code>1:M</code>.
This argument is ignored by some of the above
functions.
</p>
</td></tr>
<tr><td><code id="CM.equid_+3A_trev">Trev</code></td>
<td>
<p> Logical.
Apply reverse direction
for the thresholds direction?
This argument is ignored by some of the above
functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A constraint matrix is <code class="reqn">M \times R</code> where
<code class="reqn">R</code> is its rank and usually the elements are
0, 1 or <code class="reqn">-1</code>.
There is a constraint matrix for each column
of the LM matrix used to fit the
<code><a href="#topic+vglm">vglm</a></code>.
They are used to apportion the regression
coefficients to the linear predictors, e.g.,
parallelism, exchangeability, etc.
The functions described here are intended
to construct
constraint matrices easily for
symmetry constraints and
linear ordering etc.
They are potentially useful for categorical data
analysis (e.g., <code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>), especially for the
intercept term.
When applied to <code><a href="#topic+cumulative">cumulative</a></code>,
they are sometimes called
<em>structured thresholds</em>,
e.g., <span class="pkg">ordinal</span>.
</p>
<p>One example is the stereotype model proposed
by Anderson (1984)
(see <code><a href="#topic+multinomial">multinomial</a></code> and
<code><a href="#topic+rrvglm">rrvglm</a></code>) where the elements of
the <b>A</b> matrix are ordered.
This is not fully possible in <span class="pkg">VGAM</span> but
some special cases can be fitted, e.g.,
use <code><a href="#topic+CM.equid">CM.equid</a></code> to create
a linear ordering.
And <code><a href="#topic+CM.symm1">CM.symm1</a></code> might result in
fully ordered estimates too, etc.
</p>
<p><code><a href="#topic+CM.free">CM.free</a></code> creates
<em>free</em> or unconstrained estimates.
It is almost always the case for VGLMs,
and is simply <code>diag(M)</code>.
</p>
<p><code><a href="#topic+CM.ones">CM.ones</a></code> creates
<em>equal</em> estimates,
which is also known as the <em>parallelism</em>
assumption in models such as
<code><a href="#topic+cumulative">cumulative</a></code>.
It gets its name because the constraint matrix
is simply <code>matrix(1, M, 1)</code>.
</p>
<p><code><a href="#topic+CM.equid">CM.equid</a></code> creates
<em>equid</em>istant estimates. This is a
linear scaling, and the direction and
origin are controlled by <code>Treverse</code>
and <code>Tref</code> respectively.
</p>
<p><code><a href="#topic+CM.qnorm">CM.qnorm</a></code> and
<code><a href="#topic+CM.qlogis">CM.qlogis</a></code> are based on
<code><a href="stats.html#topic+qnorm">qnorm</a></code> and
<code><a href="stats.html#topic+qlogis">qlogis</a></code>.
For example, <code>CM.qnorm(M)</code> is essentially
<code>cbind(qnorm(seq(M) / (M + 1)))</code>.
This might be useful with a model with
<code><a href="#topic+probitlink">probitlink</a></code> applied to multiple
intercepts.
</p>
<p>Further details can be found at
<code><a href="#topic+cumulative">cumulative</a></code> and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
</p>



<h3>Value</h3>

<p>A constraint matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CM.equid(4)
CM.equid(4, Trev = TRUE, Tref = 3)
CM.symm1(5)
CM.symm0(5)
CM.qnorm(5)
</code></pre>

<hr>
<h2 id='coalminers'> Breathlessness and Wheeze Amongst Coalminers Data</h2><span id='topic+coalminers'></span>

<h3>Description</h3>

<p>Coalminers who are smokers without radiological pneumoconiosis,
classified by age, breathlessness and wheeze.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(coalminers)</code></pre>


<h3>Format</h3>

<p>A data frame with 9 age groups with the following 5 columns.
</p>

<dl>
<dt>BW</dt><dd><p>Counts with breathlessness and wheeze. </p>
</dd>
<dt>BnW</dt><dd><p>Counts with breathlessness but no wheeze. </p>
</dd>
<dt>nBW</dt><dd><p>Counts with no breathlessness but wheeze. </p>
</dd>
<dt>nBnW</dt><dd><p>Counts with neither breathlessness or wheeze. </p>
</dd>
<dt>age</dt><dd><p>Age of the coal miners (actually, the
midpoints of the 5-year category ranges). </p>
</dd>
</dl>



<h3>Details</h3>

<p>The data were published in Ashford and Sowden (1970).
A more recent analysis is McCullagh and Nelder (1989, Section 6.6).
</p>


<h3>Source</h3>

<p>Ashford, J. R. and Sowden, R. R. (1970)
Multi-variate probit analysis.
<em>Biometrics</em>, <b>26</b>, 535&ndash;546.
</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>. 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(coalminers)
</code></pre>

<hr>
<h2 id='Coef'> Computes Model Coefficients and Quantities </h2><span id='topic+Coef'></span>

<h3>Description</h3>

<p><code>Coef</code> is a generic function which computes model
coefficients from objects returned by modelling functions.
It is an auxiliary function to <code><a href="stats.html#topic+coef">coef</a></code> that
enables extra capabilities for some specific models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coef_+3A_object">object</code></td>
<td>

<p>An object for which the computation of other types of model
coefficients or quantities is meaningful.
</p>
</td></tr>
<tr><td><code id="Coef_+3A_...">...</code></td>
<td>

<p>Other arguments fed into the specific methods function of
the model.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can often be useful for <code><a href="#topic+vglm">vglm</a></code> objects
with just an intercept term in the RHS of the formula, e.g.,
<code>y ~ 1</code>. Then often this function will apply the inverse
link functions to the parameters.  See the example below.
</p>
<p>For reduced-rank VGLMs, this function can return the <b>A</b>,
<b>C</b> matrices, etc.
</p>
<p>For quadratic and additive ordination models, this function
can return ecological meaningful quantities such as tolerances,
optimums, maximums.
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods function
invoked.
</p>


<h3>Warning </h3>

<p>This function may not work for <em>all</em> <span class="pkg">VGAM</span> family
functions. You should check your results on some artificial
data before applying it to models fitted to real data.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+coef">coef</a></code>,
<code><a href="#topic+Coef.vlm">Coef.vlm</a></code>,
<code><a href="#topic+Coef.rrvglm">Coef.rrvglm</a></code>,
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>,
<code><a href="#topic+depvar">depvar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
bdata &lt;- data.frame(y = rbeta(nn, shape1 = 1, shape2 = 3))  # Original scale
fit &lt;- vglm(y ~ 1, betaR, data = bdata, trace = TRUE)  # Intercept-only model
coef(fit, matrix = TRUE)  # Both on a log scale
Coef(fit)  # On the original scale
</code></pre>

<hr>
<h2 id='Coef.qrrvglm'> Returns Important Matrices etc. of a QO Object </h2><span id='topic+Coef.qrrvglm'></span>

<h3>Description</h3>

<p>This methods function returns important matrices etc. of a
QO object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coef.qrrvglm(object, varI.latvar = FALSE, refResponse = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coef.qrrvglm_+3A_object">object</code></td>
<td>


<p>A CQO object.
The former has class <code>"qrrvglm"</code>.
</p>
</td></tr>
<tr><td><code id="Coef.qrrvglm_+3A_vari.latvar">varI.latvar</code></td>
<td>

<p>Logical indicating whether to scale the site scores (latent variables)
to have variance-covariance matrix equal to the rank-<code class="reqn">R</code> identity
matrix. All models have uncorrelated site scores (latent variables),
and this option stretches or shrinks the ordination axes if <code>TRUE</code>.
See below for further details.
</p>
</td></tr>
<tr><td><code id="Coef.qrrvglm_+3A_refresponse">refResponse</code></td>
<td>

<p>Integer or character.
Specifies the <em>reference response</em> or <em>reference species</em>.
By default, the reference
species is found by searching sequentially starting from the first
species until a positive-definite tolerance matrix is found. Then
this tolerance matrix is transformed to the identity matrix. Then
the sites scores (latent variables) are made uncorrelated.
See below for further details.
</p>



</td></tr>
<tr><td><code id="Coef.qrrvglm_+3A_...">...</code></td>
<td>
<p> Currently unused. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>I.tolerances=TRUE</code> or <code>eq.tolerances=TRUE</code> (and its
estimated tolerance matrix is positive-definite) then all species'
tolerances are unity by transformation or by definition, and the spread
of the site scores can be compared to them. Vice versa, if one wishes
to compare the tolerances with the sites score variability then setting
<code>varI.latvar=TRUE</code> is more appropriate.
</p>
<p>For rank-2 QRR-VGLMs, one of the species can be chosen so that the
angle of its major axis and minor axis is zero, i.e., parallel to
the ordination axes.  This means the effect on the latent vars is
independent on that species, and that its tolerance matrix is diagonal.
The argument <code>refResponse</code> allows one to choose which is the reference
species, which must have a positive-definite tolerance matrix, i.e.,
is bell-shaped.  If <code>refResponse</code> is not specified, then the code will
try to choose some reference species starting from the first species.
Although the <code>refResponse</code> argument could possibly be offered as
an option when fitting the model, it is currently available after
fitting the model, e.g., in the functions <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code> and
<code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>.
</p>


<h3>Value</h3>

<p>The <b>A</b>, <b>B1</b>, <b>C</b>,  <b>T</b>,  <b>D</b> matrices/arrays
are returned, along with other slots.
The returned object has class <code>"Coef.qrrvglm"</code>
(see <code><a href="#topic+Coef.qrrvglm-class">Coef.qrrvglm-class</a></code>).
</p>



<h3>Note</h3>

<p>Consider an equal-tolerances Poisson/binomial CQO model with <code>noRRR = ~ 1</code>.
For <code class="reqn">R=1</code> it has about <code class="reqn">2S+p_2</code> parameters.
For <code class="reqn">R=2</code> it has about <code class="reqn">3S+2 p_2</code> parameters.
Here, <code class="reqn">S</code> is the number of species, and <code class="reqn">p_2=p-1</code> is
the number of environmental variables making up the latent variable.
For an unequal-tolerances Poisson/binomial CQO model with
<code>noRRR = ~ 1</code>, it has about <code class="reqn">3S -1 +p_2</code> parameters
for <code class="reqn">R=1</code>, and about <code class="reqn">6S -3 +2p_2</code> parameters
for <code class="reqn">R=2</code>.
Since the total number of data points is <code class="reqn">nS</code>, where
<code class="reqn">n</code> is the number of sites, it pays to divide the number
of data points by the number of parameters to get some idea
about how much information the parameters contain.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+Coef.qrrvglm-class">Coef.qrrvglm-class</a></code>,
<code>print.Coef.qrrvglm</code>,
<code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x2 &lt;- rnorm(n &lt;- 100)
x3 &lt;- rnorm(n)
x4 &lt;- rnorm(n)
latvar1 &lt;- 0 + x3 - 2*x4
lambda1 &lt;- exp(3 - 0.5 * ( latvar1-0)^2)
lambda2 &lt;- exp(2 - 0.5 * ( latvar1-1)^2)
lambda3 &lt;- exp(2 - 0.5 * ((latvar1+4)/2)^2)  # Unequal tolerances
y1 &lt;- rpois(n, lambda1)
y2 &lt;- rpois(n, lambda2)
y3 &lt;- rpois(n, lambda3)
set.seed(111)
# vvv p1 &lt;- cqo(cbind(y1, y2, y3) ~ x2 + x3 + x4, poissonff, trace = FALSE)
## Not run:  lvplot(p1, y = TRUE, lcol = 1:3, pch = 1:3, pcol = 1:3)

# vvv Coef(p1)
# vvv print(Coef(p1), digits=3)
</code></pre>

<hr>
<h2 id='Coef.qrrvglm-class'>Class &ldquo;Coef.qrrvglm&rdquo; </h2><span id='topic+Coef.qrrvglm-class'></span>

<h3>Description</h3>

<p>The most pertinent matrices and other quantities pertaining to a
QRR-VGLM (CQO model).
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>Coef(object,
...)</code> where <code>object</code> is an object of class <code>"qrrvglm"</code>
(created by <code><a href="#topic+cqo">cqo</a></code>).
</p>
<p>In this document, <code class="reqn">R</code> is the <em>rank</em>, <code class="reqn">M</code> is the number of
linear predictors and <code class="reqn">n</code> is the number of observations.
</p>


<h3>Slots</h3>


<dl>
<dt><code>A</code>:</dt><dd><p>Of class <code>"matrix"</code>, <b>A</b>, which are the
linear &lsquo;coefficients&rsquo; of the matrix of latent variables.
It is <code class="reqn">M</code> by <code class="reqn">R</code>. </p>
</dd>
<dt><code>B1</code>:</dt><dd><p>Of class <code>"matrix"</code>, <b>B1</b>.
These correspond to terms of the argument <code>noRRR</code>. </p>
</dd>
<dt><code>C</code>:</dt><dd><p>Of class <code>"matrix"</code>, <b>C</b>, the
canonical coefficients. It has <code class="reqn">R</code> columns. </p>
</dd>
<dt><code>Constrained</code>:</dt><dd><p>Logical. Whether the model is
a constrained ordination model. </p>
</dd>
<dt><code>D</code>:</dt><dd><p>Of class <code>"array"</code>,
<code>D[,,j]</code> is an order-<code>Rank</code> matrix, for
<code>j</code> = 1,...,<code class="reqn">M</code>.
Ideally, these are negative-definite in order to make the response
curves/surfaces bell-shaped.
</p>
</dd>
<dt><code>Rank</code>:</dt><dd><p>The rank (dimension, number of latent variables)
of the RR-VGLM. Called <code class="reqn">R</code>. </p>
</dd>
<dt><code>latvar</code>:</dt><dd><p><code class="reqn">n</code> by <code class="reqn">R</code> matrix
of latent variable values. </p>
</dd>
<dt><code>latvar.order</code>:</dt><dd><p>Of class <code>"matrix"</code>, the permutation
returned when the function
<code><a href="base.html#topic+order">order</a></code> is applied to each column of <code>latvar</code>.
This enables each column of <code>latvar</code> to be easily sorted.
</p>
</dd>
<dt><code>Maximum</code>:</dt><dd><p>Of class <code>"numeric"</code>, the
<code class="reqn">M</code> maximum fitted values. That is, the fitted values
at the optimums for <code>noRRR = ~ 1</code> models.
If <code>noRRR</code> is not <code>~ 1</code> then these will be <code>NA</code>s. </p>
</dd>
<dt><code>NOS</code>:</dt><dd><p>Number of species.</p>
</dd>
<dt><code>Optimum</code>:</dt><dd><p>Of class <code>"matrix"</code>, the values
of the latent variables where the optimums are.
If the curves are not bell-shaped, then the value will
be <code>NA</code> or <code>NaN</code>.</p>
</dd>
<dt><code>Optimum.order</code>:</dt><dd><p>Of class <code>"matrix"</code>, the permutation
returned when the function
<code><a href="base.html#topic+order">order</a></code> is applied to each column of <code>Optimum</code>.
This enables each row of <code>Optimum</code> to be easily sorted.
</p>
</dd>


<dt><code>bellshaped</code>:</dt><dd><p>Vector of logicals: is each
response curve/surface bell-shaped? </p>
</dd>
<dt><code>dispersion</code>:</dt><dd><p>Dispersion parameter(s). </p>
</dd>
<dt><code>Dzero</code>:</dt><dd><p>Vector of logicals, is each of the
response curves linear in the latent variable(s)?
It will be if and only if
<code>D[,,j]</code> equals <b>O</b>, for
<code>j</code> = 1,...,<code class="reqn">M</code> . </p>
</dd>
<dt><code>Tolerance</code>:</dt><dd><p>Object of class <code>"array"</code>,
<code>Tolerance[,,j]</code> is an order-<code>Rank</code> matrix, for
<code>j</code> = 1,...,<code class="reqn">M</code>, being the matrix of
tolerances (squared if on the diagonal).
These are denoted by <b>T</b> in Yee (2004).
Ideally, these are positive-definite in order to make the response
curves/surfaces bell-shaped.
The tolerance matrices satisfy
<code class="reqn">T_s = -\frac12 D_s^{-1}</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code>print.Coef.qrrvglm</code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>x2 &lt;- rnorm(n &lt;- 100)
x3 &lt;- rnorm(n)
x4 &lt;- rnorm(n)
latvar1 &lt;- 0 + x3 - 2*x4
lambda1 &lt;- exp(3 - 0.5 * ( latvar1-0)^2)
lambda2 &lt;- exp(2 - 0.5 * ( latvar1-1)^2)
lambda3 &lt;- exp(2 - 0.5 * ((latvar1+4)/2)^2)
y1 &lt;- rpois(n, lambda1)
y2 &lt;- rpois(n, lambda2)
y3 &lt;- rpois(n, lambda3)
yy &lt;- cbind(y1, y2, y3)
# vvv p1 &lt;- cqo(yy ~ x2 + x3 + x4, fam = poissonff, trace = FALSE)
## Not run: 
lvplot(p1, y = TRUE, lcol = 1:3, pch = 1:3, pcol = 1:3)

## End(Not run)
# vvv print(Coef(p1), digits = 3)
</code></pre>

<hr>
<h2 id='Coef.rrvglm'> Returns Important Matrices etc. of a RR-VGLM Object </h2><span id='topic+Coef.rrvglm'></span>

<h3>Description</h3>

<p>This methods function returns important matrices etc. of a
RR-VGLM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coef.rrvglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coef.rrvglm_+3A_object">object</code></td>
<td>
<p> An object of class <code>"rrvglm"</code>. </p>
</td></tr>
<tr><td><code id="Coef.rrvglm_+3A_...">...</code></td>
<td>
<p> Currently unused. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <b>A</b>, <b>B1</b>, <b>C</b> matrices are returned,
along with other slots.
See <code><a href="#topic+rrvglm">rrvglm</a></code> for details about RR-VGLMs.
</p>


<h3>Value</h3>

<p>An object of class <code>"Coef.rrvglm"</code>
(see <code><a href="#topic+Coef.rrvglm-class">Coef.rrvglm-class</a></code>).
</p>


<h3>Note</h3>

<p>This function is an alternative to <code>coef.rrvglm</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Coef.rrvglm-class">Coef.rrvglm-class</a></code>,
<code>print.Coef.rrvglm</code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Rank-1 stereotype model of Anderson (1984)
pneumo &lt;- transform(pneumo, let = log(exposure.time), x3 = runif(nrow(pneumo)))
fit &lt;- rrvglm(cbind(normal, mild, severe) ~ let + x3, multinomial, data = pneumo)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='Coef.rrvglm-class'>Class &ldquo;Coef.rrvglm&rdquo; </h2><span id='topic+Coef.rrvglm-class'></span>

<h3>Description</h3>

<p>  The most pertinent matrices and other quantities
pertaining to a RR-VGLM. </p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form
<code>Coef(object, ...)</code> where <code>object</code> is an object
of class <code>rrvglm</code> (see <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>).
</p>
<p>In this document, <code class="reqn">M</code> is the number of linear predictors
and <code class="reqn">n</code> is the number of observations.
</p>


<h3>Slots</h3>


<dl>
<dt><code>A</code>:</dt><dd><p>Of class <code>"matrix"</code>, <b>A</b>. </p>
</dd>
<dt><code>B1</code>:</dt><dd><p>Of class <code>"matrix"</code>, <b>B1</b>. </p>
</dd>
<dt><code>C</code>:</dt><dd><p>Of class <code>"matrix"</code>, <b>C</b>. </p>
</dd>
<dt><code>Rank</code>:</dt><dd><p>The rank of the RR-VGLM. </p>
</dd>
<dt><code>colx1.index</code>:</dt><dd><p>Index of the columns of the
<code>"vlm"</code>-type model matrix corresponding to the variables
in <b>x1</b>. These correspond to <b>B1</b>.
</p>
</dd>
<dt><code>colx2.index</code>:</dt><dd>
<p>Index of the columns of the
<code>"vlm"</code>-type model matrix corresponding to the variables
in <b>x2</b>. These correspond to the reduced-rank regression.
</p>
</dd>
<dt><code>Atilde</code>:</dt><dd><p>Object of class <code>"matrix"</code>, the
<b>A</b> matrix with the corner rows removed. Thus each of the
elements have been estimated. This matrix is returned only
if corner constraints were used.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Coef.rrvglm">Coef.rrvglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code>,
<code>print.Coef.rrvglm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Rank-1 stereotype model of Anderson (1984)
pneumo &lt;- transform(pneumo, let = log(exposure.time), x3 = runif(nrow(pneumo)))
fit &lt;- rrvglm(cbind(normal, mild, severe) ~ let + x3, multinomial, data = pneumo)
coef(fit, matrix = TRUE)
Coef(fit)
# print(Coef(fit), digits = 3)
</code></pre>

<hr>
<h2 id='Coef.vlm'> Extract Model Coefficients for VLM Objects </h2><span id='topic+Coef.vlm'></span>

<h3>Description</h3>

<p>Amongst other things, this function applies inverse
link functions to the parameters of intercept-only
VGLMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coef.vlm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coef.vlm_+3A_object">object</code></td>
<td>
<p> A fitted model. </p>
</td></tr>
<tr><td><code id="Coef.vlm_+3A_...">...</code></td>
<td>
<p> Arguments which may be passed into
<code><a href="stats.html#topic+coef">coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most <span class="pkg">VGAM</span> family functions apply a link function to
the parameters, e.g., positive parameter are often have a log
link, parameters between 0 and 1 have a logit link.
This function can back-transform the parameter estimate to
the original scale.
</p>


<h3>Value</h3>

<p>For intercept-only models (e.g., formula is <code>y ~ 1</code>)
the back-transformed parameter estimates can be returned.
</p>


<h3>Warning </h3>

<p>This function may not work for <em>all</em> <span class="pkg">VGAM</span>
family functions. You should check your results on some
artificial data before applying it to models fitted to
real data.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Coef">Coef</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123); nn &lt;- 1000
bdata &lt;- data.frame(y = rbeta(nn, shape1 = 1, shape2 = 3))
fit &lt;- vglm(y ~ 1, betaff, data = bdata, trace = TRUE)  # intercept-only model
coef(fit, matrix = TRUE)  # log scale
Coef(fit)  # On the original scale
</code></pre>

<hr>
<h2 id='coefvgam'> Extract Model Coefficients of a vgam() Object</h2><span id='topic+coefvgam'></span><span id='topic+coef+2Cvgam-method'></span><span id='topic+coefficients+2Cvgam-method'></span>

<h3>Description</h3>

<p>Extracts the estimated
coefficients from vgam() objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefvgam(object, type = c("linear", "nonlinear"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefvgam_+3A_object">object</code></td>
<td>
<p> A
<code><a href="#topic+vgam">vgam</a></code> object.
</p>
</td></tr>
<tr><td><code id="coefvgam_+3A_type">type</code></td>
<td>
<p> Character.
The default is the first choice.
</p>
</td></tr>
<tr><td><code id="coefvgam_+3A_...">...</code></td>
<td>

<p>Optional arguments fed into
<code><a href="#topic+coefvlm">coefvlm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For VGAMs, because modified backfitting is performed,
each fitted function is decomposed into a linear and nonlinear
(smooth) part.
The argument <code>type</code> is used to return which one is wanted.
</p>


<h3>Value</h3>

<p>A vector if <code>type = "linear"</code>.
A list if <code>type = "nonlinear"</code>, and each component of
this list corresponds to an <code><a href="#topic+s">s</a></code> term;
the component contains an S4 object with slot names such as
<code>"Bcoefficients"</code>,
<code>"knots"</code>,
<code>"xmin"</code>,
<code>"xmax"</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+coefvlm">coefvlm</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, data = hunua)
coef(fit)  # Same as coef(fit, type = "linear")
(ii &lt;- coef(fit, type = "nonlinear"))
is.list(ii)
names(ii)
slotNames(ii[[1]])
</code></pre>

<hr>
<h2 id='coefvlm'> Extract Model Coefficients </h2><span id='topic+coefvlm'></span>

<h3>Description</h3>

<p>Extracts the estimated
coefficients from VLM objects such as VGLMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefvlm(object, matrix.out = FALSE, label = TRUE, colon = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefvlm_+3A_object">object</code></td>
<td>
<p> An object for which the extraction of
coefficients is meaningful.
This will usually be a <code><a href="#topic+vglm">vglm</a></code> object.
</p>
</td></tr>
<tr><td><code id="coefvlm_+3A_matrix.out">matrix.out</code></td>
<td>

<p>Logical. If <code>TRUE</code> then a matrix is returned.
The explanatory variables are the rows.
The linear/additive predictors are the columns.
The constraint matrices are used to compute this matrix.
</p>
</td></tr>
<tr><td><code id="coefvlm_+3A_label">label</code></td>
<td>

<p>Logical. If <code>FALSE</code> then the <code>names</code>
of the vector of coefficients are set to <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="coefvlm_+3A_colon">colon</code></td>
<td>

<p>Logical. Explanatory variables which appear in more than one
linear/additive predictor are labelled with a colon,
e.g., <code>age:1</code>, <code>age:2</code>.
However, if it only appears in one linear/additive predictor
then the <code>:1</code> is omitted by default.
Then setting <code>colon = TRUE</code> will add the <code>:1</code>.
</p>
</td></tr>
<tr><td><code id="coefvlm_+3A_...">...</code></td>
<td>

<p>Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function works in a similar way to
applying <code>coef()</code> to a <code><a href="stats.html#topic+lm">lm</a></code>
or <code><a href="stats.html#topic+glm">glm</a></code> object.
However, for VGLMs, there are more options available.
</p>


<h3>Value</h3>

<p>A vector usually.
A matrix if <code>matrix.out = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+coefvgam">coefvgam</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(x2 = runif(nn &lt;- 200))
zdata &lt;- transform(zdata, pstr0  = logitlink(-0.5 + 1*x2, inverse = TRUE),
                          lambda =   loglink( 0.5 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata, y2 = rzipois(nn, lambda, pstr0 = pstr0))

fit2 &lt;- vglm(y2 ~ x2, zipoisson(zero = 1), data = zdata, trace = TRUE)
coef(fit2, matrix = TRUE)  # Always a good idea
coef(fit2)
coef(fit2, colon = TRUE)
</code></pre>

<hr>
<h2 id='CommonVGAMffArguments'>Common VGAM Family Function Arguments </h2><span id='topic+CommonVGAMffArguments'></span><span id='topic+TypicalVGAMfamilyFunction'></span>

<h3>Description</h3>

<p>Here is a description of some common and
typical arguments found in many <span class="pkg">VGAM</span>
family functions, e.g.,
<code>zero</code>,
<code>lsigma</code>,
<code>isigma</code>,
<code>gsigma</code>,
<code>eq.mean</code>,
<code>nsimEI</code> and
<code>parallel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TypicalVGAMfamilyFunction(lsigma = "loglink",
                          isigma = NULL,
                          zero = NULL, gsigma = exp(-5:5),
                          eq.mean = FALSE,
                          parallel = TRUE,
                          imethod = 1,
                          vfl = FALSE, Form2 = NULL, 
                          type.fitted = c("mean", "quantiles", "Qlink",
                                          "pobs0", "pstr0", "onempstr0"),
                          percentiles = c(25, 50, 75),
                          probs.x = c(0.15, 0.85),
                          probs.y = c(0.25, 0.50, 0.75),
                          multiple.responses = FALSE, earg.link = FALSE,
                          ishrinkage = 0.95, nointercept = NULL,
                          whitespace = FALSE, bred = FALSE, lss = TRUE,
                          oim = FALSE, nsimEIM = 100, byrow.arg = FALSE,
                          link.list = list("(Default)" = "identitylink",
                                           x2          = "loglink",
                                           x3          = "logofflink",
                                           x4          = "multilogitlink",
                                           x5          = "multilogitlink"),
                          earg.list = list("(Default)" = list(),
                                           x2          = list(),
                                           x3          = list(offset = -1),
                                           x4          = list(),
                                           x5          = list()),
                          Thresh = NULL, nrfs = 1)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="CommonVGAMffArguments_+3A_lsigma">lsigma</code></td>
<td>

<p>Character.
Link function applied to a parameter and not
necessarily a mean.  See <code><a href="#topic+Links">Links</a></code>
for a selection of choices.  If there is only
one parameter then this argument is often
called <code>link</code>.
</p>
</td></tr>








<tr><td><code id="CommonVGAMffArguments_+3A_isigma">isigma</code></td>
<td>

<p>Optional initial values can often be
inputted using an argument beginning with
<code>"i"</code>.  For example, <code>"isigma"</code> and
<code>"ilocation"</code>, or just <code>"init"</code>
if there is one parameter.  A value of
<code>NULL</code> means a value is computed
internally, i.e., a <em>self-starting</em>
<span class="pkg">VGAM</span> family function.  If a failure
to converge occurs make use of these types
of arguments.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_zero">zero</code></td>
<td>

<p>An important argument,
either an integer vector, or a vector of
character strings.
</p>
<p>If an integer, then it specifies which
linear/additive predictor is modelled
as <em>intercept-only</em>.  That is,
the regression coefficients are set to
zero for all covariates except for the
intercept.  If <code>zero</code> is specified
then it may be a vector with values from
the set <code class="reqn">\{1,2,\ldots,M\}</code>.  The value
<code>zero = NULL</code> means model <em>all</em>
linear/additive predictors as functions of
the explanatory variables.  Here, <code class="reqn">M</code>
is the number of linear/additive predictors.
Technically, if <code>zero</code> contains the
value <code class="reqn">j</code> then the <code class="reqn">j</code>th row of every
constraint matrix (except for the intercept)
consists of all 0 values.
</p>
<p>Some <span class="pkg">VGAM</span> family functions allow the
<code>zero</code> argument to accept negative
values; if so then its absolute value is
recycled over each (usual) response. For
example, <code>zero = -2</code> for the
two-parameter negative binomial distribution
would mean, for each response, the second
linear/additive predictor is modelled as
intercepts-only. That is, for all the <code class="reqn">k</code>
parameters in <code><a href="#topic+negbinomial">negbinomial</a></code>
(this <span class="pkg">VGAM</span> family function can handle
a matrix of responses).
</p>
<p>Suppose <code>zero = zerovec</code> where
<code>zerovec</code> is a vector of negative
values. If <code class="reqn">G</code> is the usual <code class="reqn">M</code>
value for a univariate response then the
actual values for argument <code>zero</code>
are all values in <code>c(abs(zerovec), G +
  abs(zerovec), 2*G + abs(zerovec), ... )</code> lying
in the integer range <code class="reqn">1</code> to <code class="reqn">M</code>.
For example, setting <code>zero = -c(2,
  3)</code> for a matrix response of 4 columns with
<code><a href="#topic+zinegbinomial">zinegbinomial</a></code> (which usually
has <code class="reqn">G = M = 3</code> for a univariate response)
would be equivalent to
<code>zero = c(2, 3, 5, 6, 8, 9, 11, 12)</code>.
This example has <code class="reqn">M = 12</code>.
Note that if <code>zerovec</code> contains
negative values then their absolute values
should be elements from the set <code>1:G</code>.
</p>
<p>Note: <code>zero</code> may have positive and
negative values, for example, setting
<code>zero = c(-2, 3)</code> in the above example
would be equivalent to
<code>zero = c(2, 3, 5, 8, 11)</code>.
</p>
<p>The argument <code>zero</code> also accepts
a character vector (for <span class="pkg">VGAM</span>
1.0-1 onwards).  Each value is fed into
<code><a href="base.html#topic+grep">grep</a></code> with <code>fixed =
  TRUE</code>, meaning that wildcards <code>"*"</code>
are not useful.  See the example below&mdash;all
the variants work; those with <code>LOCAT</code>
issue a warning that that value is unmatched.
Importantly, the parameter names are
<code>c("location1", "scale1", "location2",
"scale2")</code> because there are 2 responses.  Yee
(2015) described <code>zero</code> for only numerical
input.  Allowing character input is particularly
important when the number of parameters cannot
be determined without having the actual data
first. For example, with time series data,
an ARMA(<code class="reqn">p</code>,<code class="reqn">q</code>) process might have
parameters <code class="reqn">\theta_1,\ldots,\theta_p</code> which
should be intercept-only by default. Then
specifying a numerical default value for
<code>zero</code> would be too difficult (there
are the drift and scale parameters too).
However, it is possible with the character
representation: <code>zero = "theta"</code> would
achieve this.  In the future, most <span class="pkg">VGAM</span>
family functions might be converted
to the character representation&mdash;the
advantage being that it is more readable.
When programming a <span class="pkg">VGAM</span> family function
that allows character input, the variable
<code>predictors.names</code> must be assigned
correctly.
</p>







<p>If the <code>constraints</code> argument is used
then the family function's <code>zero</code>
argument (if it exists) needs to be set to
<code>NULL</code>. This avoids what could be a
probable contradiction.  Sometimes setting
other arguments related to constraint matrices
to <code>FALSE</code> is also a good idea, e.g.,
<code>parallel = FALSE</code>,
<code>exchangeable = FALSE</code>.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_gsigma">gsigma</code></td>
<td>

<p>Grid-search initial values can be inputted
using an argument beginning with <code>"g"</code>,
e.g., <code>"gsigma"</code>, <code>"gshape"</code> and
<code>"gscale"</code>.  If argument <code>isigma</code>
is inputted then that has precedence over
<code>gsigma</code>, etc.
If the grid search is 2-dimensional then it
is advisable not to make the vectors too long
as a nested <code>for</code> loop may be used.
Ditto for 3-dimensions etc.  Sometimes a
<code>".mux"</code> is added as a suffix, e.g.,
<code>gshape.mux</code>; this means that the grid
is created relatively and not absolutely,
e.g., its values are multipled by some single
initial estimate of the parameter in order
to create the grid on an absolute scale.
</p>


<p>Some family functions have an argument
called <code>gprobs.y</code>.  This is fed
into the <code>probs</code> argument of
<code><a href="stats.html#topic+quantile">quantile</a></code>
in order to obtain some values of central
tendency of the response, i.e., some spread
of values in the middle.  when <code>imethod = 1</code>
to obtain an initial value for the mean
Some family functions have an argument called
<code>iprobs.y</code>, and if so, then these values
can overwrite <code>gprobs.y</code>.
</p>


</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_eq.mean">eq.mean</code></td>
<td>

<p>Logical.
Constrain all the means to be equal?
This type of argument is simpler than
<code>parallel</code> because only a single
<code>TRUE</code> or <code>FALSE</code> can be assigned
and 
not a formula.  Thus if <code>TRUE</code> then it
will be enforced over all variables.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_parallel">parallel</code></td>
<td>

<p>A logical, or a simple formula specifying
which terms have equal/unequal coefficients.
The formula must be simple, i.e., additive
with simple main effects terms.  Interactions
and nesting etc. are not handled.  To handle
complex formulas use the <code>constraints</code>
argument (of <code><a href="#topic+vglm">vglm</a></code> etc.);
however, there is a lot more setting up
involved and things will not be as convenient.
</p>
<p>Here are some examples.
1. <code>parallel = TRUE ~ x2 + x5</code> means
the parallelism assumption
is only applied to <code class="reqn">X_2</code>, <code class="reqn">X_5</code> and
the intercept.
2.  <code>parallel = TRUE ~ -1</code>
and <code>parallel = TRUE ~ 0</code>
mean the parallelism assumption
is applied to <em>no</em> variables at all.
Similarly,
<code>parallel = FALSE ~ -1</code> and
<code>parallel = FALSE ~ 0</code>
mean the parallelism assumption
is applied to <em>all</em> the variables
including the intercept.
3.  <code>parallel = FALSE ~ x2 - 1</code>
and <code>parallel = FALSE ~ x2 + 0</code>
applies the parallelism constraint to all terms
(including the intercept) except for <code class="reqn">X_2</code>.
</p>
<p>This argument is common in <span class="pkg">VGAM</span> family
functions for categorical responses, e.g.,
<code><a href="#topic+cumulative">cumulative</a></code>,  <code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>, <code><a href="#topic+sratio">sratio</a></code>.
For the proportional odds model
(<code><a href="#topic+cumulative">cumulative</a></code>) having parallel
constraints applied to each explanatory
variable (except for the intercepts) means the
fitted probabilities do not become negative
or greater than 1. However this parallelism
or proportional-odds assumption ought to
be checked.
</p>
</td></tr>









<tr><td><code id="CommonVGAMffArguments_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> family functions use
simulation to obtain an approximate expected
information matrix (EIM).  For those that
do, the <code>nsimEIM</code> argument specifies
the number of random variates used per
observation; the mean of <code>nsimEIM</code> random
variates is taken.  Thus <code>nsimEIM</code>
controls the accuracy and a larger value
may be necessary if the EIMs are not
positive-definite.  For intercept-only models
(<code>y ~ 1)</code> the value of <code>nsimEIM</code>
can be smaller (since the common value used
is also then taken as the mean over the
observations), especially if the number of
observations is large.
</p>
<p>Some <span class="pkg">VGAM</span> family functions provide
two algorithms for estimating the EIM.
If applicable, set <code>nsimEIM = NULL</code>
to choose the other algorithm.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code>
or <code>3</code> or ... which specifies the
initialization method for some parameters or
a specific parameter.  If failure to converge
occurs try the next higher value, and continue
until success.
For example, <code>imethod = 1</code> might
be the method of moments, and
<code>imethod = 2</code> might be another method.
If no value of <code>imethod</code> works then
it will be necessary to use arguments such
as <code>isigma</code>.  For many <span class="pkg">VGAM</span>
family functions it is advisable to try this
argument with all possible values to safeguard
against problems such as converging to a local
solution.  <span class="pkg">VGAM</span> family functions with
this argument usually correspond to a model
or distribution that is relatively hard to
fit successfully, therefore care is needed
to ensure the global solution is obtained.
So using all possible values that this
argument supplies is a good idea.
</p>
<p><span class="pkg">VGAM</span> family functions such
<code><a href="#topic+genpoisson2">genpoisson2</a></code> recycle
<code>imethod</code> to be of length 2 corresponding
to the 2 parameters. In the future, this
feature will be extended to other family
functions to confer more flexibility.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_form2">Form2</code></td>
<td>

<p>Formula.
Using applied to models with <code class="reqn">M=2</code>.
Specifies the terms for <code class="reqn">\eta_2</code>
and the other terms belong to <code class="reqn">\eta_1</code>.
It is a way to partition the <b>X</b>
matrix into two sets of covariates,
where they are assigned to each <code class="reqn">\eta_j</code>
separately.
This argument sets up constraint matrices
<code>rbind(0, 1)</code>
for terms in <code>Form2</code>
and <code>rbind(1, 0)</code> for
<code>setdiff(formula, Form2)</code>
so to speak.
Note that 
sometimes this argument is only accessed
if <code>vfl = TRUE</code>.
Arguments such as <code>Form1</code> and
<code>Form3</code> are also possible in
<span class="pkg">VGAM</span> family functions because
the <code class="reqn">\eta_j</code> which is likely to be
modelled more simply is
chosen for convenience.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_vfl">vfl</code></td>
<td>

<p>A single logical.
This stands for
<em>variance&ndash;variance factored loglinear</em>
(VFL)
model.
If <code>TRUE</code> then usually
some other argument such
as <code>Form2</code> or <code>parallel</code>
is used to partition the main
<code><a href="#topic+vglm">vglm</a></code> <code>formula</code>
into two sets of covariates.
For some families
such as <code><a href="#topic+negbinomial">negbinomial</a></code>
this enables overdispersion to be modelled
conveniently via a loglinear model,
given the mean.
It is necessary to read the online help
regarding each <span class="pkg">VGAM</span> family function
because each one may different from others.
To fit some VFL models it is necessary to
make a copy of existing covariates by
creating new variable names and then
adding it to the main formula.
</p>
<p>A good question is:
why is <code>vfl</code> necessary?
Wouldn't <code>Form2</code> be sufficient?
Setting <code>vfl = TRUE</code> enables
some internal checking such
as avoiding conflicts.
For example, it is often necessary to set
<code>zero = NULL</code> and
<code>parallel = FALSE</code>, otherwise
there would be contradictions.
</p>










</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Character.
Type of fitted value returned by
the <code>fitted()</code> methods function.
The first choice is always the default.
The available choices depends on what kind
of family function it is.  Using the first
few letters of the chosen choice is okay.
See <code><a href="#topic+fittedvlm">fittedvlm</a></code> for more details.
</p>
<p>The choice <code>"Qlink"</code> refers to
quantile-links, which was introduced in
December 2018 in <span class="pkg">VGAMextra</span> 0.0-2
for several 1-parameter distributions.
Here, either the <code><a href="#topic+loglink">loglink</a></code>
or <code><a href="#topic+logitlink">logitlink</a></code> or
<code><a href="#topic+identitylink">identitylink</a></code> of the quantile
is the link function (and the choice is
dependent on the support of the distribution),
and link functions end in <code>"Qlink"</code>.
A limited amount of support is provided
for such links, e.g., <code>fitted(fit)</code>
are the fitted quantiles, which is the same
as <code>predict(fit, type = "response")</code>.
However, <code>fitted(fit, percentiles = 77)</code>
will not work.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_percentiles">percentiles</code></td>
<td>

<p>Numeric vector, with values between 0 and
100 (although it is not recommended that
exactly 0 or 100 be inputted).  Used only
if <code>type.fitted = "quantiles"</code>
or <code>type.fitted = "percentiles"</code>,
then this argument specifies the values of
these quantiles.  The argument name tries
to reinforce that the values lie between 0
and 100.  See <code><a href="#topic+fittedvlm">fittedvlm</a></code> for
more details.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_probs.x">probs.x</code>, <code id="CommonVGAMffArguments_+3A_probs.y">probs.y</code></td>
<td>

<p>Numeric, with values in (0, 1).
The probabilites that define quantiles with
respect to some vector, usually an <code>x</code> or
<code>y</code> of some sort.  This is used to create
two subsets of data corresponding to &lsquo;low&rsquo;
and &lsquo;high&rsquo; values of x or y.  Each value is
separately fed into the <code>probs</code> argument
of <code><a href="stats.html#topic+quantile">quantile</a></code>.
If the data set size is small then it may be
necessary to increase/decrease slightly the
first/second values respectively.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_lss">lss</code></td>
<td>

<p>Logical.
This stands for the ordering: location,
scale and shape.  Should the ordering
of the parameters be in this order?
Almost all <span class="pkg">VGAM</span> family functions
have this order by default, but in order
to match the arguments of existing R
functions, one might need to set
<code>lss = FALSE</code>.  For example, the arguments of
<code><a href="#topic+weibullR">weibullR</a></code> are scale and shape,
whereas <code><a href="stats.html#topic+rweibull">rweibull</a></code> are
shape and scale.  As a temporary measure
(from <span class="pkg">VGAM</span> 0.9-7 onwards but prior to
version 1.0-0), some family functions such
as <code><a href="#topic+sinmad">sinmad</a></code> have an <code>lss</code>
argument without a default. For these,
setting <code>lss = FALSE</code> will work.
Later, <code>lss = TRUE</code> will be the default.
Be careful for the <code>dpqr</code>-type functions,
e.g., <code><a href="#topic+rsinmad">rsinmad</a></code>.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_thresh">Thresh</code></td>
<td>

<p><em>Thresholds</em> is another name for the
intercepts, e.g., for categorical models.
They may be constrained by functions such as
<code><a href="#topic+CM.equid">CM.equid</a></code> and
<code><a href="#topic+CM.qnorm">CM.qnorm</a></code>.
The string <code>"CM."</code> and
the <code>Thresh</code> argument is pasted and
then that function is called to obtain the
constraint matrix for the intercept term.
So
<code>Thresh = "free"</code>,
<code>Thresh = "equid"</code>,
<code>Thresh = "qnorm"</code>,
<code>Thresh = "symm0"</code>,
<code>Thresh = "symm1"</code> etc.
are possibilities.
Families that use this include 
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+acat">acat</a></code>.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_whitespace">whitespace</code></td>
<td>

<p>Logical.
Should white spaces (<code>" "</code>) be used in the
labelling of the linear/additive predictors?
Setting <code>TRUE</code> usually results in more
readability but it occupies more columns of
the output.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_oim">oim</code></td>
<td>

<p>Logical.
Should the observed information matrices
(OIMs) be used for the working weights?
In general, setting <code>oim = TRUE</code> means
the Newton-Raphson algorithm,
and <code>oim = FALSE</code> means Fisher-scoring.
The latter uses the EIM, and is usually recommended.
If <code>oim = TRUE</code> then <code>nsimEIM</code>
is ignored.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_nrfs">nrfs</code></td>
<td>

<p>Numeric, a value in <code class="reqn">[0, 1]</code>.
Experimental argument for allowing a mixture
of Newton-Raphson and Fisher scoring.
The working weights are taken as a linear
combination of the two.  If <code>nrfs = 0</code>
then Newton-Raphson is used, i.e., the OIM
is wholly used.  If <code>nrfs = 1</code> then
Fisher scoring is used, i.e., the EIM is
wholly used.  If convergence is successful
then one might expect Newton-Raphson to
be faster than Fisher scoring because the
former has an order-2 convergence rate
while the latter has a linear rate.
</p>
</td></tr></table>
<p>,
</p>
<table>
<tr><td><code id="CommonVGAMffArguments_+3A_multiple.responses">multiple.responses</code></td>
<td>

<p>Logical.
Some <span class="pkg">VGAM</span> family functions allow
a multivariate or vector response.
If so, then usually the response is a
matrix with columns corresponding to the
individual response variables.  They are
all fitted simultaneously.  Arguments such
as <code>parallel</code> may then be useful
to allow for relationships between the
regressions of each response variable.
If <code>multiple.responses = TRUE</code> then
sometimes the response is interpreted
differently, e.g., <code><a href="#topic+posbinomial">posbinomial</a></code>
chooses the first column of a matrix response
as success and combines the other columns as
failure, but when
<code>multiple.responses = TRUE</code>
then each column of the response
matrix is the number of successes and the
<code>weights</code> argument is of the same
dimension as the response and contains the
number of trials.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_earg.link">earg.link</code></td>
<td>

<p>This argument should be generally ignored.
</p>


</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_byrow.arg">byrow.arg</code></td>
<td>

<p>Logical.
Some <span class="pkg">VGAM</span> family functions that handle
multiple responses have arguments that allow
input to be fed in which affect all the
responses, e.g., <code>imu</code> for initalizing
a <code>mu</code> parameter.  In such cases it is
sometime more convenient to input one value
per response by setting <code>byrow.arg = TRUE</code>;
then values are recycled in order to
form a matrix of the appropriate dimension.
This argument matches <code>byrow</code> in
<code><a href="base.html#topic+matrix">matrix</a></code>; in fact it is
fed into such using
<code>matrix(..., byrow = byrow.arg)</code>.
This argument has no effect when there is
one response.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>Shrinkage factor <code class="reqn">s</code> used for obtaining
initial values.
Numeric, between 0 and 1.
In general, the formula used is something like
<code class="reqn">s \mu + (1-s) y</code>
where <code class="reqn">\mu</code> is a measure of
central tendency such as a weighted mean or
median, and <code class="reqn">y</code> is the response vector.
For example, the initial values are slight
perturbations of the mean towards the actual
data.  For many types of models this method
seems to work well and is often reasonably
robust to outliers in the response.  Often
this argument is only used if the argument
<code>imethod</code> is assigned a certain value.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_nointercept">nointercept</code></td>
<td>

<p>An integer-valued vector specifying
which linear/additive predictors have no
intercepts.  Any values must be from the
set {1,2,...,<code class="reqn">M</code>}.  A value of
<code>NULL</code> means no such constraints.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_bred">bred</code></td>
<td>

<p>Logical.
Some <span class="pkg">VGAM</span> family functions will allow
bias-reduction based on the work by Kosmidis
and Firth.  Sometimes half-stepping is a good
idea; set <code>stepsize = 0.5</code> and monitor
convergence by setting <code>trace = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="CommonVGAMffArguments_+3A_link.list">link.list</code>, <code id="CommonVGAMffArguments_+3A_earg.list">earg.list</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> family functions
(such as <code><a href="#topic+normal.vcm">normal.vcm</a></code>)
implement models with
potentially lots of parameter link functions.
These two arguments allow many such links and extra arguments
to be inputted more easily.
One has something like
<code>link.list = list</code>
<code>("(Default)" = "identitylink", x2 = "loglink", x3 = "logofflink")</code>
and
<code>earg.list = list</code>
<code>("(Default)" = list(), x2 = list(), x3 = "list(offset = -1)")</code>.
Then any unnamed terms will have the default
link with its corresponding extra argument.
Note: the <code><a href="#topic+multilogitlink">multilogitlink</a></code> link
is also possible, and if so, at least two
instances of it are necessary.  Then the last
term is the baseline/reference group.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Full details will be given in documentation
yet to be written, at a later date!
A general recommendation is to set
<code>trace = TRUE</code> whenever any model fitting
is done, since monitoring convergence is
usually very informative.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object
is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The <code>zero</code> argument is supplied for
convenience but conflicts can arise with other
arguments, e.g., the <code>constraints</code>
argument of <code><a href="#topic+vglm">vglm</a></code> and
<code><a href="#topic+vgam">vgam</a></code>.  See Example 5 below
for an example.  If not sure, use, e.g.,
<code>constraints(fit)</code> and
<code>coef(fit, matrix = TRUE)</code>
to check the result of a fit <code>fit</code>.
</p>
<p>The arguments <code>zero</code> and
<code>nointercept</code> can be inputted with values
that fail. For example,
<code>multinomial(zero = 2, nointercept = 1:3)</code>
means the second linear/additive predictor is
identically zero, which will cause a failure.
</p>
<p>Be careful about the use of other
potentially contradictory constraints, e.g.,
<code>multinomial(zero = 2, parallel = TRUE ~ x3)</code>.
If in doubt, apply <code>constraints()</code>
to the fitted object to check.
</p>
<p><span class="pkg">VGAM</span> family functions with the
<code>nsimEIM</code> may have inaccurate working
weight matrices. If so, then the standard
errors of the regression coefficients
may be inaccurate. Thus output from
<code>summary(fit)</code>, <code>vcov(fit)</code>,
etc. may be misleading.
</p>
<p>Changes relating to the <code>lss</code> argument
have very important consequences and users
must beware.  Good programming style is
to rely on the argument names and not on
the order.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. (2015).
Vector Generalized Linear and Additive Models:
With an Implementation in R.
New York, USA: <em>Springer</em>.
</p>
<p>Kosmidis, I. and Firth, D. (2009).
Bias reduction in exponential family nonlinear models.
<em>Biometrika</em>,
<b>96</b>, 793&ndash;804.
</p>





<p>Miranda-Soberanis, V. F. and Yee, T. W. (2019).
New link functions for distribution&ndash;specific
quantile regression based on vector generalized linear and
additive models.
<em>Journal of Probability and Statistics</em>,
<b>5</b>, 1&ndash;11.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+UtilitiesVGAM">UtilitiesVGAM</a></code>,
<code><a href="#topic+multilogitlink">multilogitlink</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<span class="pkg">VGAMextra</span>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Example 1
cumulative()
cumulative(link = "probitlink", reverse = TRUE, parallel = TRUE)

# Example 2
wdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
wdata &lt;- transform(wdata,
         y = rweibull(nn, shape = 2 + exp(1 + x2), scale = exp(-0.5)))
fit &lt;- vglm(y ~ x2, weibullR(lshape = logofflink(offset = -2), zero = 2),
            data = wdata)
coef(fit, mat = TRUE)

# Example 3; multivariate (multiple) response
## Not run: 
ndata &lt;- data.frame(x = runif(nn &lt;- 500))
ndata &lt;- transform(ndata,
           y1 = rnbinom(nn, exp(1), mu = exp(3+x)),  # k is size
           y2 = rnbinom(nn, exp(0), mu = exp(2-x)))
fit &lt;- vglm(cbind(y1, y2) ~ x, negbinomial(zero = -2), ndata)
coef(fit, matrix = TRUE)

## End(Not run)
# Example 4
## Not run: 
# fit1 and fit2 are equivalent
fit1 &lt;- vglm(ymatrix ~ x2 + x3 + x4 + x5,
             cumulative(parallel = FALSE ~ 1 + x3 + x5), cdata)
fit2 &lt;- vglm(ymatrix ~ x2 + x3 + x4 + x5,
             cumulative(parallel = TRUE ~ x2 + x4), cdata)

## End(Not run)

# Example 5
udata &lt;- data.frame(x2 = rnorm(nn &lt;- 200))
udata &lt;- transform(udata,
           x1copy = 1,  # Copy of the intercept
           x3 = runif(nn),
           y1 = rnorm(nn, 1 - 3*x2, sd = exp(1 + 0.2*x2)),
           y2 = rnorm(nn, 1 - 3*x2, sd = exp(1)))
args(uninormal)
fit1 &lt;- vglm(y1 ~ x2, uninormal, udata)            # This is okay
fit2 &lt;- vglm(y2 ~ x2, uninormal(zero = 2), udata)  # This is okay
fit4 &lt;- vglm(y2 ~ x2 + x1copy + x3,
             uninormal(zero = NULL, vfl = TRUE,
                       Form2 = ~ x1copy + x3 - 1), udata)
coef(fit4,  matrix = TRUE)  # VFL model

# This creates potential conflict
clist &lt;- list("(Intercept)" = diag(2), "x2" = diag(2))
fit3 &lt;- vglm(y2 ~ x2, uninormal(zero = 2), data = udata,
             constraints = clist)  # Conflict!
coef(fit3, matrix = TRUE)  # Shows that clist[["x2"]] was overwritten,
constraints(fit3)  # i.e., 'zero' seems to override the 'constraints' arg

# Example 6 ('whitespace' argument)
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let,
             sratio(whitespace = FALSE, parallel = TRUE), pneumo)
fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let,
             sratio(whitespace = TRUE,  parallel = TRUE), pneumo)
head(predict(fit1), 2)  # No white spaces
head(predict(fit2), 2)  # Uses white spaces

# Example 7 ('zero' argument with character input)
set.seed(123); n &lt;- 1000
ldata &lt;- data.frame(x2 = runif(n))
ldata &lt;- transform(ldata, y1 = rlogis(n, loc = 5*x2, scale = exp(2)))
ldata &lt;- transform(ldata, y2 = rlogis(n, loc = 5*x2, scale = exp(1*x2)))
ldata &lt;- transform(ldata, w1 = runif(n))
ldata &lt;- transform(ldata, w2 = runif(n))
fit7 &lt;- vglm(cbind(y1, y2) ~ x2,
#        logistic(zero = "location1"),  # location1 is intercept-only
#        logistic(zero = "location2"),
#        logistic(zero = "location*"),  # Not okay... all is unmatched
#        logistic(zero = "scale1"),
#        logistic(zero = "scale2"),
#        logistic(zero = "scale"),  # Both scale parameters are matched
         logistic(zero = c("location", "scale2")),  # All but scale1
#        logistic(zero = c("LOCAT", "scale2")),  # Only scale2 is matched
#        logistic(zero = c("LOCAT")),  # Nothing is matched
#        trace = TRUE,
#        weights = cbind(w1, w2),
         weights = w1,
         data = ldata)
coef(fit7, matrix = TRUE)
</code></pre>

<hr>
<h2 id='concoef'> Extract Model Constrained/Canonical Coefficients </h2><span id='topic+concoef'></span>

<h3>Description</h3>

<p><code>concoef</code> is a generic function which extracts the constrained
(canonical) coefficients from objects returned by certain modelling
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>concoef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="concoef_+3A_object">object</code></td>
<td>
<p> An object for which the extraction of canonical
coefficients is meaningful.
</p>
</td></tr>
<tr><td><code id="concoef_+3A_...">...</code></td>
<td>
<p> Other arguments fed into the specific
methods function of the model.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For constrained quadratic and ordination models, <em>canonical
coefficients</em> are the elements of the <b>C</b> matrix used to form
the latent variables.  They are highly interpretable in ecology,
and are looked at as weights or loadings.
</p>
<p>They are also applicable for reduced-rank VGLMs.
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods function invoked.
</p>


<h3>Warning </h3>

<p><code><a href="#topic+concoef">concoef</a></code> replaces <code>ccoef</code>;
the latter is deprecated.
</p>


<p>For QO models, there is a direct inverse relationship between the
scaling of the latent variables (site scores) and the tolerances.
One normalization is for the latent variables to have unit variance.
Another normalization is for all the species' tolerances to be
unit (provided <code>eq.tolerances</code> is <code>TRUE</code>).  These two
normalizations cannot simultaneously hold in general.  For rank
<code class="reqn">R</code> models with <code class="reqn">R&gt;1</code> it becomes more complicated because
the latent variables are also uncorrelated. An important argument when
fitting quadratic ordination models is whether <code>eq.tolerances</code>
is <code>TRUE</code> or <code>FALSE</code>.  See Yee (2004) for details.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+concoef-method">concoef-method</a></code>,
<code>concoef.qrrvglm</code>,
<code>concoef.cao</code>,
<code><a href="stats.html#topic+coef">coef</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  set.seed(111)  # This leads to the global solution
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Standardized environmental vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          family = poissonff, data = hspider, Crow1positive = FALSE)
concoef(p1)

## End(Not run)
</code></pre>

<hr>
<h2 id='concoef-methods'> Constrained (Canonical) Coefficients </h2><span id='topic+concoef-method'></span><span id='topic+concoef+2Ccao-method'></span><span id='topic+concoef+2CCoef.cao-method'></span><span id='topic+concoef+2Crrvglm-method'></span><span id='topic+concoef+2Cqrrvglm-method'></span><span id='topic+concoef+2CCoef.rrvglm-method'></span><span id='topic+concoef+2CCoef.qrrvglm-method'></span>

<h3>Description</h3>

<p><code>concoef</code> is a generic function used to return the constrained
(canonical) coefficients of a  constrained ordination model.
The function invokes particular methods which depend on the class of
the first argument.
</p>


<h3>Methods</h3>


<dl>
<dt>object</dt><dd>
<p>The object from which the constrained coefficients are
extracted.
</p>
</dd>
</dl>


<hr>
<h2 id='confintvglm'> Confidence Intervals for Parameters of VGLMs </h2><span id='topic+confintvglm'></span><span id='topic+confintrrvglm'></span><span id='topic+confintvgam'></span>

<h3>Description</h3>

<p>Computes confidence intervals (CIs)
for one or more parameters in a fitted model.
Currently the object must be a
<code>"<a href="#topic+vglm">vglm</a>"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confintvglm(object, parm, level = 0.95, method = c("wald", "profile"),
            trace = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confintvglm_+3A_object">object</code></td>
<td>
<p> A fitted model object.
</p>
</td></tr>
<tr><td><code id="confintvglm_+3A_parm">parm</code>, <code id="confintvglm_+3A_level">level</code>, <code id="confintvglm_+3A_...">...</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+confint">confint</a></code>.
</p>
</td></tr>
<tr><td><code id="confintvglm_+3A_method">method</code></td>
<td>
<p>Character.
The default is the first method.
Abbreviations are allowed.
Currently <code>"profile"</code> is basically working;
and it is likely to be more accurate especially for
small samples, as it is based on a profile log likelihood,
however it is computationally intensive.
</p>
</td></tr>
<tr><td><code id="confintvglm_+3A_trace">trace</code></td>
<td>

<p>Logical. If <code>TRUE</code> then one can monitor the
computation as it progresses (because it is expensive).
The default is the orginal model's <code>trace</code> value
(see <code><a href="#topic+vglm.control">vglm.control</a></code>).
Setting <code>FALSE</code> suppresses all intermediate output.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default for
this methods function is based on <code><a href="stats.html#topic+confint.default">confint.default</a></code>
and assumes
asymptotic normality. In particular,
the <code><a href="#topic+coefvlm">coef</a></code> and
<code>vcov</code> methods functions are used for
<code><a href="#topic+vglm-class">vglm-class</a></code> objects.
</p>
<p>When <code>method = "profile"</code> the function 
<code><a href="#topic+profilevglm">profilevglm</a></code>
is called to do the profiling. The code is very heavily
based on <code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>
which was originally written by
D. M. Bates and W. N. Venables (For S in 1996)
and subsequently corrected by B. D. Ripley.
Sometimes the profiling method can give problems, for
example, <code><a href="#topic+cumulative">cumulative</a></code> requires the <code class="reqn">M</code>
linear predictors not to intersect in the data cloud.
Such numerical problems are less common when
<code>method = "wald"</code>, however, it is well-known
that inference based on profile likelihoods is generally
more accurate than Wald, especially when the sample size
is small.
The deviance (<code>deviance(object)</code>) is used if possible,
else the difference
<code>2 * (logLik(object) - ell)</code> is computed,
where <code>ell</code> are the values of the loglikelihood on a grid.
</p>
<p>For
Wald CIs and
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code>
objects, currently an error message is produced because
I haven't gotten around to write the methods function;
it's not too hard, but am too busy!
An interim measure is to
coerce the object into a <code>"<a href="#topic+vglm">vglm</a>"</code> object,
but then the confidence intervals will tend to be too narrow because
the estimated constraint matrices are treated as known.
</p>
<p>For
Wald CIs and
<code><a href="#topic+vgam-class">vgam-class</a></code>
objects, currently an error message is produced because
the theory is undeveloped.
</p>


<h3>Value</h3>

<p>Same as <code><a href="stats.html#topic+confint">confint</a></code>.
</p>


<h3>Note</h3>

<p>The order of the values of argument <code>method</code> may change
in the future without notice.
The functions
<code>plot.profile.glm</code>
and
<code>pairs.profile.glm</code>
from <span class="pkg">MASS</span>
appear to work with output from this function.
</p>






<h3>Author(s)</h3>

<p>Thomas Yee adapted <code><a href="stats.html#topic+confint.lm">confint.lm</a></code>
to handle <code>"vglm"</code> objects, for Wald-type
confidence intervals.
Also, <code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>
was originally written by
D. M. Bates and W. N. Venables (For S in 1996)
and subsequently corrected by B. D. Ripley.
This function effectively calls <code>confint.profile.glm()</code>
in <span class="pkg">MASS</span>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcovvlm">vcovvlm</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="stats.html#topic+confint">confint</a></code>,
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>,
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+wald.stat">wald.stat</a></code>,
<code>plot.profile.glm</code>,
<code>pairs.profile.glm</code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Example 1: this is based on a glm example
counts &lt;- c(18,17,15,20,10,20,25,13,12)
outcome &lt;- gl(3, 1, 9); treatment &lt;- gl(3, 3)
 glm.D93 &lt;-  glm(counts ~ outcome + treatment, family = poisson())
vglm.D93 &lt;- vglm(counts ~ outcome + treatment, family = poissonff)
confint(glm.D93) # needs MASS to be present on the system
confint.default(glm.D93)  # based on asymptotic normality
confint(vglm.D93)
confint(vglm.D93) - confint(glm.D93)    # Should be all 0s
confint(vglm.D93) - confint.default(glm.D93)  # based on asympt. normality

# Example 2: simulated negative binomial data with multiple responses
ndata &lt;- data.frame(x2 = runif(nn &lt;- 100))
ndata &lt;- transform(ndata, y1 = rnbinom(nn, mu = exp(3+x2), size = exp(1)),
                          y2 = rnbinom(nn, mu = exp(2-x2), size = exp(0)))
fit1 &lt;- vglm(cbind(y1, y2) ~ x2, negbinomial, data = ndata, trace = TRUE)
coef(fit1)
coef(fit1, matrix = TRUE)
confint(fit1)
confint(fit1, "x2:1")  #  This might be improved to "x2" some day...
## Not run: 
confint(fit1, method = "profile")  # Computationally expensive
confint(fit1, "x2:1", method = "profile", trace = FALSE)

## End(Not run)

fit2 &lt;- rrvglm(y1 ~ x2, negbinomial(zero = NULL), data = ndata)
confint(as(fit2, "vglm"))  # Too narrow (SEs are biased downwards)
</code></pre>

<hr>
<h2 id='constraints'> Constraint Matrices </h2><span id='topic+constraints'></span><span id='topic+constraints.vlm'></span>

<h3>Description</h3>

<p>Extractor function for the <em>constraint matrices</em> of objects
in the <span class="pkg">VGAM</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constraints(object, ...)
constraints.vlm(object, type = c("lm", "term"), all = TRUE, which,
                matrix.out = FALSE, colnames.arg = TRUE,
                rownames.arg = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constraints_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>
</td></tr>
<tr><td><code id="constraints_+3A_type">type</code></td>
<td>

<p>Character. Whether LM- or term-type constraints are to be returned.
The number of such matrices returned is equal to
<code>nvar(object, type = "lm")</code> and
the number of terms, respectively.
</p>
</td></tr>
<tr><td><code id="constraints_+3A_all">all</code>, <code id="constraints_+3A_which">which</code></td>
<td>

<p>If <code>all = FALSE</code> then <code>which</code> gives the integer index or a
vector of logicals specifying the selection.
</p>
</td></tr>
<tr><td><code id="constraints_+3A_matrix.out">matrix.out</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the constraint matrices
are <code><a href="base.html#topic+cbind">cbind</a>()ed</code> together.
The result is usually more compact because the default
is a list of constraint matrices.
</p>
</td></tr>
<tr><td><code id="constraints_+3A_colnames.arg">colnames.arg</code>, <code id="constraints_+3A_rownames.arg">rownames.arg</code></td>
<td>

<p>Logical. If <code>TRUE</code> then column and row names
are assigned corresponding to the variables.
</p>
</td></tr>
<tr><td><code id="constraints_+3A_...">...</code></td>
<td>

<p>Other possible arguments such as <code>type</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Constraint matrices describe the relationship of
coefficients/component functions of a particular explanatory
variable between
the linear/additive predictors in VGLM/VGAM
models. For example, they may be all different (constraint
matrix is the identity matrix) or all the same (constraint
matrix has one column and has unit values).
</p>
<p>VGLMs and VGAMs have constraint matrices which are <em>known</em>.
The class of RR-VGLMs have constraint matrices which are
<em>unknown</em> and are to be estimated.
</p>


<h3>Value</h3>

<p>The extractor function
<code>constraints()</code>
returns a list comprising of
constraint matrices&mdash;usually one for each column of the
VLM model matrix, and in that order.
The list is labelled with the variable names.
Each constraint matrix has <code class="reqn">M</code> rows, where
<code class="reqn">M</code> is the number of linear/additive predictors,
and whose rank is equal to the number of columns.
A model with no constraints at all has an order
<code class="reqn">M</code> identity matrix as each variable's
constraint matrix.
</p>
<p>For <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code> objects,
feeding in <code>type = "term"</code> constraint matrices back
into the same model should work and give an identical model.
The default are the <code>"lm"</code>-type constraint matrices;
this is a list with one constraint matrix per column of
the LM matrix.
See the <code>constraints</code> argument of <code><a href="#topic+vglm">vglm</a></code>,
and the example below.
</p>


<h3>Note</h3>

<p>In all <span class="pkg">VGAM</span> family functions <code>zero = NULL</code> means
none of the linear/additive predictors are modelled as
intercepts-only.
Other arguments found in certain <span class="pkg">VGAM</span> family functions
which affect constraint matrices include
<code>parallel</code> and <code>exchangeable</code>.
</p>
<p>The <code>constraints</code> argument in <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code> allows constraint matrices to
be inputted. If so, then <code>constraints(fit, type = "lm")</code> can
be fed into the <code>constraints</code> argument of the same object
to get the same model.
</p>
<p>The <code>xij</code> argument does not affect constraint matrices; rather,
it allows each row of the constraint matrix to be multiplied by a
specified vector.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>




<h3>See Also</h3>

<p><code><a href="#topic+is.parallel">is.parallel</a></code>,
<code><a href="#topic+is.zero">is.zero</a></code>,
<code><a href="#topic+trim.constraints">trim.constraints</a></code>.
VGLMs are described in <code><a href="#topic+vglm-class">vglm-class</a></code>;
RR-VGLMs are described in <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>.
</p>
<p>Arguments such as <code>zero</code> and <code>parallel</code>
found in many <span class="pkg">VGAM</span>
family functions are a way of creating/modifying constraint
matrices conveniently, e.g., see <code><a href="#topic+zero">zero</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit the proportional odds model:
pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ sm.bs(let, 3),
              cumulative(parallel = TRUE, reverse = TRUE), data = pneumo))
coef(fit1, matrix = TRUE)
constraints(fit1)  # Parallel assumption results in this
constraints(fit1, type = "term")  # Same as the default ("vlm"-type)
is.parallel(fit1)

# An equivalent model to fit1 (needs the type "term" constraints):
clist.term &lt;- constraints(fit1, type = "term")  # "term"-type constraints
# cumulative() has no 'zero' argument to set to NULL (a good idea
# when using the 'constraints' argument):
(fit2 &lt;- vglm(cbind(normal, mild, severe) ~ sm.bs(let, 3), data = pneumo,
              cumulative(reverse = TRUE), constraints = clist.term))
abs(max(coef(fit1, matrix = TRUE) -
        coef(fit2, matrix = TRUE)))  # Should be zero

# Fit a rank-1 stereotype (RR-multinomial logit) model:
fit &lt;- rrvglm(Country ~ Width + Height + HP, multinomial, data = car.all)
constraints(fit)  # All except the first are the estimated A matrix
</code></pre>

<hr>
<h2 id='cops'> Centre of the Parameter Space </h2><span id='topic+cops'></span><span id='topic+copsvglm'></span><span id='topic+cops+2Cvglm-method'></span>

<h3>Description</h3>

<p>Returns a vector similar to coefs() comprising
the centre of the parameter space (COPS) values,
given a fitted VGLM regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cops(object, ...)
copsvglm(object, beta.range = c(-5, 6),
         tol = .Machine$double.eps^0.25,
         dointercepts = TRUE, trace. = FALSE,
         slowtrain = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cops_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+vglm">vglm</a></code> object.
However, this function will not work for all
such objects.
</p>
</td></tr>
<tr><td><code id="cops_+3A_beta.range">beta.range</code></td>
<td>

<p>Numeric.
Interval for the numerical search.
After a little scaling, it is effectively
fed into <code>interval</code> in
<code><a href="stats.html#topic+optimize">optimize</a></code>.
Convergence failure may occur if this
argument is too wide so it is a good
idea to vary this argument.
In fact, it is strongly recommended that
several values be fed into this argument
to help ensure the proper solution is obtained.
</p>
</td></tr>
<tr><td><code id="cops_+3A_tol">tol</code></td>
<td>

<p>Numeric.
Fed into <code>tol</code> in
<code><a href="stats.html#topic+optimize">optimize</a></code>.
</p>
</td></tr>
<tr><td><code id="cops_+3A_dointercepts">dointercepts</code></td>
<td>

<p>Logical.
Compute the COPS for the intercepts?
This should be set to <code>FALSE</code>
for models such as
<code><a href="#topic+propodds">propodds</a></code> and
<code><a href="#topic+cumulative">cumulative</a></code>.
</p>
</td></tr>
<tr><td><code id="cops_+3A_trace.">trace.</code></td>
<td>

<p>Logical.
Print a running log?
This may or may not work properly.
</p>
</td></tr>
<tr><td><code id="cops_+3A_slowtrain">slowtrain</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then all columns of a
matrix is computed.
If <code>FALSE</code> then only one column of a
matrix is computed, and this is the only
column needed.
</p>
</td></tr>
<tr><td><code id="cops_+3A_...">...</code></td>
<td>

<p>currently unused but may be used in the
future for further arguments passed into
the other methods functions.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For many models, some COPS values will be
<code>Inf</code> or <code>-Inf</code>
so that manual checking is needed,
for example, <code><a href="#topic+poissonff">poissonff</a></code>.
Each value returned may be effectively
that of <code>beta.range</code>
or <code>NA</code>.
The answers returned by this function only
make sense if the COPSs are in the
interior of the parameter space.
This function was written specifically for
logistic regression but has much wider
applicability.
Currently the result returned depends critically
on <code>beta.range</code> so that the answer should
be checked after several values are fed into
that argument.
</p>


<h3>Value</h3>

<p>A named vector, similar to <code><a href="#topic+coefvlm">coefvlm</a></code>.
If <code>trace.</code> then a list is returned,
having a componennt comprising a
matrix of function evaluations used by
<code><a href="stats.html#topic+optimize">optimize</a></code>.
</p>


<h3>Note</h3>

<p>This function is experimental and
can be made to run more efficiently
in the future.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee.  </p>


<h3>References</h3>








<p>Yee, T. W. (2024).
Musings and new results on the parameter space.
<em>Under review</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hdeff">hdeff</a></code>.
<code><a href="#topic+coefvlm">coefvlm</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data("xs.nz", package = "VGAMdata")
data1 &lt;- na.omit(xs.nz[, c("age", "cancer", "sex")])
fit1 &lt;- vglm(cancer ~ age + sex, binomialff, data1)
cops(fit1)  # 'beta.range' is okay here

## End(Not run)</code></pre>

<hr>
<h2 id='corbet'>
Corbet's Butterfly Data

</h2><span id='topic+corbet'></span>

<h3>Description</h3>

<p>About 3300 individual butterflies were caught in Malaya
by naturalist Corbet trapping butterflies.
They were classified to about 500 species.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>data(corbet)</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 2 variables.
</p>

<dl>
<dt><code>species</code></dt><dd><p>Number of species. </p>
</dd>
<dt><code>ofreq</code></dt><dd><p>Observed frequency of individual
butterflies of that species. </p>
</dd>
</dl>



<h3>Details</h3>

<p>In the early 1940s Corbet spent two years trapping butterflies
in Malaya. Of interest was the total number of species.
Some species were so rare (e.g., 118 species had only
one specimen) that it was thought likely that there were
many unknown species.
</p>
<p>Actually, 119 species had over 24 observed frequencies,
so this could/should be appended to the data set.
Hence there are 620 species in total in a
sample size of <code class="reqn">n=9031</code> individuals.
</p>




<h3>References</h3>

<p>Fisher, R. A., Corbet, A. S. and Williams, C. B. (1943).
The Relation Between the Number of Species and
the Number of Individuals in a Random Sample of an Animal
Population.
<em>Journal of Animal Ecology</em>,
<b>12</b>, 42&ndash;58.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(corbet)
</code></pre>

<hr>
<h2 id='cqo'> Fitting Constrained Quadratic Ordination (CQO)</h2><span id='topic+cqo'></span>

<h3>Description</h3>

<p>A <em>constrained quadratic ordination</em> (CQO; formerly called
<em>canonical Gaussian ordination</em> or CGO) model is fitted using
the <em>quadratic reduced-rank vector generalized linear model</em>
(QRR-VGLM) framework.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cqo(formula, family = stop("argument 'family' needs to be assigned"),
    data = list(), weights = NULL, subset = NULL,
    na.action = na.fail, etastart = NULL, mustart = NULL,
    coefstart = NULL, control = qrrvglm.control(...), offset = NULL,
    method = "cqo.fit", model = FALSE, x.arg = TRUE, y.arg = TRUE,
    contrasts = NULL, constraints = NULL, extra = NULL,
    smart = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cqo_+3A_formula">formula</code></td>
<td>
<p> a symbolic description of the model to be fit.
The RHS of the formula is applied to each linear predictor. Different
variables in each linear predictor can be chosen by specifying
constraint matrices.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_family">family</code></td>
<td>

<p>a function of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>)
describing what statistical model is to be fitted. This is called a
&ldquo;<span class="pkg">VGAM</span> family function&rdquo;.  See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for general information about many types of arguments found in this
type of function.
Currently the following families are supported:
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>
(<code><a href="#topic+logitlink">logitlink</a></code> and <code><a href="#topic+clogloglink">clogloglink</a></code> links available),
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>.
Sometimes special arguments are required for <code>cqo()</code>, e.g.,
<code>binomialff(multiple.responses = TRUE)</code>.
</p>





</td></tr>
<tr><td><code id="cqo_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model.
By default the variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>cqo</code> is called.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_weights">weights</code></td>
<td>
<p> an optional vector or matrix of (prior) weights
to be used in the fitting process.
Currently, this argument should not be used.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_subset">subset</code></td>
<td>

<p>an optional logical vector specifying a subset of
observations to be used in the fitting process.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_na.action">na.action</code></td>
<td>

<p>a function which indicates what should happen when the data contain
<code>NA</code>s.  The default is set by the <code>na.action</code> setting of
<code><a href="base.html#topic+options">options</a></code>, and is <code>na.fail</code> if that is unset.
The &ldquo;factory-fresh&rdquo; default is <code>na.omit</code>.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_etastart">etastart</code></td>
<td>

<p>starting values for the linear predictors.
It is a <code class="reqn">M</code>-column matrix.
If <code class="reqn">M = 1</code> then it may be a vector.
Currently, this argument probably should not be used.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_mustart">mustart</code></td>
<td>

<p>starting values for the
fitted values. It can be a vector or a matrix.
Some family functions do not make use of this argument.
Currently, this argument probably should not be used.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_coefstart">coefstart</code></td>
<td>

<p>starting values for the
coefficient vector.
Currently, this argument probably should not be used.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_control">control</code></td>
<td>

<p>a list of parameters for controlling the fitting process.
See <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_offset">offset</code></td>
<td>

<p>This argument must not be used.
</p>




</td></tr>
<tr><td><code id="cqo_+3A_method">method</code></td>
<td>

<p>the method to be used in fitting the model.
The default (and presently only) method <code>cqo.fit</code>
uses <em>iteratively reweighted least squares</em> (IRLS).
</p>
</td></tr>
<tr><td><code id="cqo_+3A_model">model</code></td>
<td>

<p>a logical value indicating whether the <em>model frame</em>
should be assigned in the <code>model</code> slot.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_x.arg">x.arg</code>, <code id="cqo_+3A_y.arg">y.arg</code></td>
<td>

<p>logical values indicating whether
the model matrix and response matrix used in the fitting
process should be assigned in the <code>x</code> and <code>y</code> slots.
Note the model matrix is the LM model matrix.
</p>



</td></tr>
<tr><td><code id="cqo_+3A_contrasts">contrasts</code></td>
<td>

<p>an optional list. See the <code>contrasts.arg</code>
of <code>model.matrix.default</code>.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_constraints">constraints</code></td>
<td>

<p>an optional list  of constraint matrices.
The components of the list must be named with the term it corresponds
to (and it must match in character format).
Each constraint matrix must have <code class="reqn">M</code> rows, and be of full-column
rank. By default, constraint matrices are the <code class="reqn">M</code> by <code class="reqn">M</code>
identity
matrix unless arguments in the family function itself override these values.
If <code>constraints</code> is used it must contain <em>all</em> the
terms; an incomplete list is not accepted.
Constraint matrices for <code class="reqn">x_2</code> variables are taken as the
identity matrix.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_extra">extra</code></td>
<td>

<p>an optional list with any extra information that might be needed
by the family function.
</p>
</td></tr>




<tr><td><code id="cqo_+3A_smart">smart</code></td>
<td>

<p>logical value indicating whether smart prediction
(<code><a href="#topic+smartpred">smartpred</a></code>) will be used.
</p>
</td></tr>
<tr><td><code id="cqo_+3A_...">...</code></td>
<td>

<p>further arguments passed into <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>QRR-VGLMs or <em>constrained quadratic ordination</em> (CQO) models
are estimated here by maximum likelihood estimation. Optimal linear
combinations of the environmental variables are computed, called
<em>latent variables</em> (these appear as <code>latvar</code> for <code class="reqn">R=1</code>
else <code>latvar1</code>, <code>latvar2</code>, etc. in the output).  Here, <code class="reqn">R</code>
is the <em>rank</em> or the number of ordination axes.  Each species'
response is then a regression of these latent variables using quadratic
polynomials on a transformed scale (e.g., log for Poisson counts, logit
for presence/absence responses).  The solution is obtained iteratively
in order to maximize the log-likelihood function, or equivalently,
minimize the deviance.
</p>
<p>The central formula (for Poisson and binomial species data) is
given by
</p>
<p style="text-align: center;"><code class="reqn">\eta = B_1^T x_1 + A \nu +
               \sum_{m=1}^M (\nu^T D_m \nu) e_m</code>
</p>

<p>where <code class="reqn">x_1</code> is a vector (usually just a 1 for an intercept),
<code class="reqn">x_2</code> is a vector of environmental variables, <code class="reqn">\nu=C^T
  x_2</code> is a <code class="reqn">R</code>-vector of latent variables, <code class="reqn">e_m</code> is
a vector of 0s but with a 1 in the <code class="reqn">m</code>th position.
The <code class="reqn">\eta</code> are a vector of linear/additive predictors,
e.g., the <code class="reqn">m</code>th element is <code class="reqn">\eta_m = \log(E[Y_m])</code> for the <code class="reqn">m</code>th species.  The matrices <code class="reqn">B_1</code>,
<code class="reqn">A</code>, <code class="reqn">C</code> and <code class="reqn">D_m</code> are estimated from the data, i.e.,
contain the regression coefficients.  The tolerance matrices
satisfy <code class="reqn">T_s = -\frac12 D_s^{-1}</code>.
Many important CQO details are directly related to arguments
in <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>, e.g., the argument <code>noRRR</code>
specifies which variables comprise <code class="reqn">x_1</code>.
</p>
<p>Theoretically, the four most popular <span class="pkg">VGAM</span> family functions
to be used with <code>cqo</code> correspond to the Poisson, binomial,
normal, and negative binomial distributions. The latter is a
2-parameter model. All of these are implemented, as well as the
2-parameter gamma. 
</p>










<p>For initial values, the function <code>.Init.Poisson.QO</code> should
work reasonably well if the data is Poisson with species having equal
tolerances.  It can be quite good on binary data too.  Otherwise the
<code>Cinit</code> argument in <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> can be used.
</p>

<p>It is possible to relax the quadratic form to an additive model.  The
result is a data-driven approach rather than a model-driven approach,
so that CQO is extended to <em>constrained additive ordination</em>
(CAO) when <code class="reqn">R=1</code>.  See <code><a href="#topic+cao">cao</a></code> for more details.
</p>
<p>In this documentation, <code class="reqn">M</code> is the number of linear predictors,
<code class="reqn">S</code> is the number of responses (species). Then
<code class="reqn">M=S</code> for Poisson and binomial species data,
and <code class="reqn">M=2S</code> for negative binomial and gamma distributed species data.
</p>
<p>Incidentally,
<em>Unconstrained quadratic ordination</em> (UQO)
may be performed by, e.g., fitting a Goodman's RC association model;
see <code><a href="#topic+uqo">uqo</a></code> and the Yee and Hadi (2014) referenced there.
For UQO, the response is the usual site-by-species matrix and
there are no environmental variables;
the site scores are free parameters.
UQO can be performed under the assumption that all species
have the same tolerance matrices.
</p>


<h3>Value</h3>

<p>An object of class <code>"qrrvglm"</code>.
</p>





<h3>Warning </h3>

<p>Local solutions are not uncommon when fitting CQO models.  To increase
the chances of obtaining the global solution, increase the value
of the argument <code>Bestof</code> in <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>.
For reproducibility of the results, it pays to set a different
random number seed before calling <code>cqo</code> (the function
<code><a href="base.html#topic+Random">set.seed</a></code> does this).  The function <code>cqo</code>
chooses initial values for <b>C</b> using <code>.Init.Poisson.QO()</code>
if <code>Use.Init.Poisson.QO = TRUE</code>, else random numbers.
</p>
<p>Unless <code>I.tolerances = TRUE</code> or <code>eq.tolerances = FALSE</code>,
CQO is computationally expensive with memory and time.
It pays to keep the rank down to 1
or 2.  If <code>eq.tolerances = TRUE</code> and <code>I.tolerances = FALSE</code> then
the cost grows quickly with the number of species and sites (in terms of
memory requirements and time).  The data needs to conform quite closely
to the statistical model, and the environmental range of the data should
be wide in order for the quadratics to fit the data well (bell-shaped
response surfaces).  If not, RR-VGLMs will be more appropriate because
the response is linear on the transformed scale (e.g., log or logit)
and the ordination is called <em>constrained linear ordination</em> or CLO.
</p>
<p>Like many regression models, CQO is sensitive to outliers (in the
environmental and species data), sparse data, high leverage points,
multicollinearity etc.  For these reasons, it is necessary to examine
the data carefully for these features and take corrective action
(e.g., omitting certain species, sites, environmental variables from
the analysis, transforming certain environmental variables, etc.).
Any optimum lying outside the convex hull of the site scores should not
be trusted.  Fitting a CAO is recommended first, then upon transformations
etc., possibly a CQO can be fitted.
</p>
<p>For binary data, it is necessary to have &lsquo;enough&rsquo; data.  In general,
the number of sites <code class="reqn">n</code> ought to be much larger than the number of
species <em>S</em>, e.g., at least 100 sites for two species. Compared
to count (Poisson) data, numerical problems occur more frequently
with presence/absence (binary) data.  For example, if <code>Rank = 1</code>
and if the response data for each species is a string of all absences,
then all presences, then all absences (when enumerated along the latent
variable) then infinite parameter estimates will occur.  In general,
setting <code>I.tolerances = TRUE</code> may help.
</p>
<p>This function was formerly called <code>cgo</code>. It has been renamed to
reinforce a new nomenclature described in Yee (2006).
</p>


<h3>Note</h3>

<p>The input requires care, preparation and
thought&mdash;<em>a lot more</em> than other ordination methods.
Here is a partial <b>checklist</b>.
</p>

<dl>
<dt>(1)</dt><dd>
<p>The number of species should be kept reasonably low, e.g., 12 max.
Feeding in 100+ species wholesale is a recipe for failure.
Choose a few species carefully.
Using 10 well-chosen species is better than 100+ species thrown in
willy-nilly.
</p>
</dd>
<dt>(2)</dt><dd>
<p>Each species should be screened individually first, e.g.,
for presence/absence is the species totally absent or totally present
at all sites?
For presence/absence data <code>sort(colMeans(data))</code> can help
avoid such species.
</p>
</dd>
<dt>(3)</dt><dd>
<p>The number of explanatory variables should be kept low,
e.g., 7 max.
</p>
</dd>
<dt>(4)</dt><dd>
<p>Each explanatory variable should be screened individually first, e.g.,
is it heavily skewed or are there outliers?
They should be plotted and then transformed where needed.
They should not be too highly correlated with each other.
</p>
</dd>
<dt>(5)</dt><dd>
<p>Each explanatory variable should be scaled, e.g.,
to mean 0 and unit variance.
This is especially needed for <code>I.tolerance = TRUE</code>.
</p>
</dd>
<dt>(6)</dt><dd>
<p>Keep the rank low.
Only if the data is very good should a rank-2 model be attempted.
Usually a rank-1 model is all that is practically possible even
after a lot of work.
The rank-1 model should always be attempted first.
Then might be clever and try use this for initial values for
a rank-2 model.
</p>
</dd>
<dt>(7)</dt><dd>
<p>If the number of sites is large then choose a random sample of them.
For example, choose a maximum of 500 sites.
This will reduce the memory and time expense of the computations.
</p>
</dd>
<dt>(8)</dt><dd>
<p>Try <code>I.tolerance = TRUE</code> or <code>eq.tolerance = FALSE</code>
if the inputted data set is large,
so as to reduce the computational expense.
That's because the default, <code>I.tolerance = FALSE</code> and
<code>eq.tolerance = TRUE</code>, is very memory hungry.
</p>
</dd>
</dl>

<p>By default, a rank-1 equal-tolerances QRR-VGLM model is fitted
(see <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> for the default control
parameters).
If <code>Rank &gt; 1</code> then the latent variables are always transformed
so that they are uncorrelated.
By default, the argument <code>trace</code> is <code>TRUE</code> meaning a running
log is printed out while the computations are taking place.  This is
because the algorithm is computationally expensive, therefore users
might think that their computers have frozen if <code>trace = FALSE</code>!
</p>
<p>The argument <code>Bestof</code> in <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> controls
the number of models fitted (each uses different starting values) to
the data. This argument is important because convergence may be to a
<em>local</em> solution rather than the <em>global</em> solution. Using
more starting values increases the chances of finding the global
solution.  Always plot an ordination diagram (use the generic function
<code><a href="#topic+lvplot">lvplot</a></code>) and see if it looks sensible.  Local solutions
arise because the optimization problem is highly nonlinear, and this is
particularly true for CAO.
</p>








<p>Many of the arguments applicable to <code>cqo</code> are common to
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+rrvglm.control">rrvglm.control</a></code>.
The most important arguments are
<code>Rank</code>,
<code>noRRR</code>,
<code>Bestof</code>,
<code>I.tolerances</code>,
<code>eq.tolerances</code>,
<code>isd.latvar</code>, and
<code>MUXfactor</code>.
</p>
<p>When fitting a 2-parameter model such as the negative binomial
or gamma, it pays to have <code>eq.tolerances = TRUE</code> and
<code>I.tolerances = FALSE</code>. This is because numerical problems can
occur when fitting the model far away from the global solution when
<code>I.tolerances = TRUE</code>. Setting the two arguments as described will
slow down the computation considerably, however it is numerically
more stable.
</p>
<p>In Example 1 below, an unequal-tolerances rank-1 QRR-VGLM is fitted to the
hunting spiders dataset, and
Example 2 is the equal-tolerances version. The latter is less likely to
have convergence problems compared to the unequal-tolerances model.
In Example 3 below, an equal-tolerances rank-2 QRR-VGLM is fitted to the
hunting spiders dataset.
The numerical difficulties encountered in fitting the rank-2 model
suggests a rank-1 model is probably preferable.
In Example 4 below, constrained binary quadratic ordination (in old
nomenclature, constrained Gaussian logit ordination) is fitted to some
simulated data coming from a species packing model.
With multivariate binary responses, one must
use <code>multiple.responses = TRUE</code> to
indicate that the response (matrix) is multivariate. Otherwise, it is
interpreted as a single binary response variable.
In Example 5 below, the deviance residuals are plotted for each species.
This is useful as a diagnostic plot.
This is done by (re)regressing each species separately against the latent
variable.
</p>
<p>Sometime in the future, this function might handle input of the form
<code>cqo(x, y)</code>, where <code>x</code> and <code>y</code> are matrices containing
the environmental and species data respectively.
</p>


<h3>Author(s)</h3>

<p>Thomas W. Yee.
Thanks to Alvin Sou for converting a lot of the
original FORTRAN code into C.
</p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>ter Braak, C. J. F. and Prentice, I. C. (1988).
A theory of gradient analysis.
<em>Advances in Ecological Research</em>,
<b>18</b>, 271&ndash;317.
</p>




<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>,
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>,
<code><a href="#topic+predictqrrvglm">predictqrrvglm</a></code>,
<code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>,
<code><a href="#topic+model.matrixqrrvglm">model.matrixqrrvglm</a></code>,
<code><a href="#topic+vcovqrrvglm">vcovqrrvglm</a></code>,
<code><a href="#topic+rcqo">rcqo</a></code>,
<code><a href="#topic+cao">cao</a></code>,
<code><a href="#topic+uqo">uqo</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>,
<code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>,
<code><a href="#topic+perspqrrvglm">perspqrrvglm</a></code>,
<code><a href="#topic+trplot.qrrvglm">trplot.qrrvglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="base.html#topic+Random">set.seed</a></code>,
<code><a href="#topic+hspider">hspider</a></code>,
<code><a href="VGAMdata.html#topic+trapO">trapO</a></code>.
</p>







<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1; Fit an unequal tolerances model to the hunting spiders data
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Standardized environmental variables
set.seed(1234)  # For reproducibility of the results
p1ut &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                  Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                  Trocterr, Zoraspin) ~
            WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
            fam = poissonff, data = hspider, Crow1positive = FALSE,
            eq.tol = FALSE)
sort(deviance(p1ut, history = TRUE))  # A history of all the iterations
if (deviance(p1ut) &gt; 1177) warning("suboptimal fit obtained")

S &lt;- ncol(depvar(p1ut))  # Number of species
clr &lt;- (1:(S+1))[-7]  # Omits yellow
lvplot(p1ut, y = TRUE, lcol = clr, pch = 1:S, pcol = clr,
       las = 1)  # Ordination diagram
legend("topright", leg = colnames(depvar(p1ut)), col = clr,
       pch = 1:S, merge = TRUE, bty = "n", lty = 1:S, lwd = 2)
(cp &lt;- Coef(p1ut))

(a &lt;- latvar(cp)[cp@latvar.order])  # Ordered site scores along the gradient
# Names of the ordered sites along the gradient:
rownames(latvar(cp))[cp@latvar.order]
(aa &lt;- Opt(cp)[, cp@Optimum.order])  # Ordered optimums along the gradient
aa &lt;- aa[!is.na(aa)]  # Delete the species that is not unimodal
names(aa)  # Names of the ordered optimums along the gradient

trplot(p1ut, which.species = 1:3, log = "xy", type = "b", lty = 1, lwd = 2,
       col = c("blue","red","green"), label = TRUE) -&gt; ii  # Trajectory plot
legend(0.00005, 0.3, paste(ii$species[, 1], ii$species[, 2], sep = " and "),
       lwd = 2, lty = 1, col = c("blue", "red", "green"))
abline(a = 0, b = 1, lty = "dashed")

S &lt;- ncol(depvar(p1ut))  # Number of species
clr &lt;- (1:(S+1))[-7]  # Omits yellow
persp(p1ut, col = clr, label = TRUE, las = 1)  # Perspective plot


# Example 2; Fit an equal tolerances model. Less numerically fraught.
set.seed(1234)
p1et &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                  Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                  Trocterr, Zoraspin) ~
            WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
            poissonff, data = hspider, Crow1positive = FALSE)
sort(deviance(p1et, history = TRUE))  # A history of all the iterations
if (deviance(p1et) &gt; 1586) warning("suboptimal fit obtained")
S &lt;- ncol(depvar(p1et))  # Number of species
clr &lt;- (1:(S+1))[-7]  # Omits yellow
persp(p1et, col = clr, label = TRUE, las = 1)


# Example 3: A rank-2 equal tolerances CQO model with Poisson data
# This example is numerically fraught... need I.toler = TRUE too.
set.seed(555)
p2 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          poissonff, data = hspider, Crow1positive = FALSE,
          I.toler = TRUE, Rank = 2, Bestof = 3, isd.latvar = c(2.1, 0.9))
sort(deviance(p2, history = TRUE))  # A history of all the iterations
if (deviance(p2) &gt; 1127) warning("suboptimal fit obtained")
lvplot(p2, ellips = FALSE, label = TRUE, xlim = c(-3,4),
       C = TRUE, Ccol = "brown", sites = TRUE, scol = "grey",
       pcol = "blue", pch = "+", chull = TRUE, ccol = "grey")


# Example 4: species packing model with presence/absence data
set.seed(2345)
n &lt;- 200; p &lt;- 5; S &lt;- 5
mydata &lt;- rcqo(n, p, S, fam = "binomial", hi.abundance = 4,
               eq.tol = TRUE, es.opt = TRUE, eq.max = TRUE)
myform &lt;- attr(mydata, "formula")
set.seed(1234)
b1et &lt;- cqo(myform, binomialff(multiple.responses = TRUE, link = "clogloglink"),
            data = mydata)
sort(deviance(b1et, history = TRUE))  # A history of all the iterations
lvplot(b1et, y = TRUE, lcol = 1:S, pch = 1:S, pcol = 1:S, las = 1)
Coef(b1et)

# Compare the fitted model with the 'truth'
cbind(truth = attr(mydata, "concoefficients"), fitted = concoef(b1et))


# Example 5: Plot the deviance residuals for diagnostic purposes
set.seed(1234)
p1et &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                  Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                  Trocterr, Zoraspin) ~
            WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
            poissonff, data = hspider, eq.tol = TRUE, trace = FALSE)
sort(deviance(p1et, history = TRUE))  # A history of all the iterations
if (deviance(p1et) &gt; 1586) warning("suboptimal fit obtained")
S &lt;- ncol(depvar(p1et))
par(mfrow = c(3, 4))
for (ii in 1:S) {
  tempdata &lt;- data.frame(latvar1 = c(latvar(p1et)),
                         sppCounts = depvar(p1et)[, ii])
  tempdata &lt;- transform(tempdata, myOffset = -0.5 * latvar1^2)

# For species ii, refit the model to get the deviance residuals
  fit1 &lt;- vglm(sppCounts ~ offset(myOffset) + latvar1, poissonff,
               data = tempdata, trace = FALSE)

# For checking: this should be 0
# print("max(abs(c(Coef(p1et)@B1[1,ii],Coef(p1et)@A[ii,1])-coef(fit1)))")
# print( max(abs(c(Coef(p1et)@B1[1,ii],Coef(p1et)@A[ii,1])-coef(fit1))) )

# Plot the deviance residuals
  devresid &lt;- resid(fit1, type = "deviance")
  predvalues &lt;- predict(fit1) + fit1@offset
  ooo &lt;- with(tempdata, order(latvar1))
  plot(predvalues + devresid ~ latvar1, data = tempdata, col = "red",
       xlab = "latvar1", ylab = "", main = colnames(depvar(p1et))[ii])
  with(tempdata, lines(latvar1[ooo], predvalues[ooo], col = "blue"))
}

## End(Not run)
</code></pre>

<hr>
<h2 id='crashes'>Crashes on New Zealand Roads in 2009</h2><span id='topic+crashi'></span><span id='topic+crashf'></span><span id='topic+crashtr'></span><span id='topic+crashmc'></span><span id='topic+crashbc'></span><span id='topic+crashp'></span><span id='topic+alcoff'></span><span id='topic+alclevels'></span>

<h3>Description</h3>

<p>A variety of reported crash data cross-classified  by time (hour
of the day) and day of the week, accumulated over 2009. These
include fatalities and injuries (by car), trucks, motor cycles,
bicycles  and pedestrians.  There are some alcohol-related
data too.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(crashi)
data(crashf)
data(crashtr)
data(crashmc)
data(crashbc)
data(crashp)
data(alcoff)
data(alclevels)
</code></pre>


<h3>Format</h3>

<p>Data frames with hourly times as rows and days of the week as columns.
The <code>alclevels</code> dataset has hourly times and alcohol levels.
</p>

<dl>
<dt>Mon, Tue, Wed, Thu, Fri, Sat, Sun</dt><dd>
<p>Day of the week.
</p>
</dd>
<dt>0-30, 31-50, 51-80, 81-100, 101-120, 121-150, 151-200,
201-250, 251-300, 301-350, 350+</dt><dd>
<p>Blood alcohol level (milligrams alcohol per 100 millilitres of blood).
</p>


</dd>
</dl>



<h3>Details</h3>

<p>Each cell is the aggregate number of crashes reported at each
hour-day combination, over the 2009 calendar year.
The <code>rownames</code> of each data frame is the
start time (hourly from midnight onwards) on a 24 hour clock,
e.g., 21 means 9.00pm to 9.59pm.
</p>
<p>For crashes,
<code>chrashi</code> are the number of injuries by car,
<code>crashf</code>  are the number of fatalities by car
(not included in <code>chrashi</code>),
<code>crashtr</code> are the number of crashes involving trucks,
<code>crashmc</code> are the number of crashes involving motorcyclists,
<code>crashbc</code> are the number of crashes involving bicycles,
and
<code>crashp</code>  are the number of crashes involving pedestrians.
For alcohol-related offences,
<code>alcoff</code>  are the number of alcohol offenders from
breath screening drivers,
and
<code>alclevels</code> are the blood alcohol levels of fatally injured drivers.
</p>


<h3>Source</h3>

<p><code>http://www.transport.govt.nz/research/Pages/Motor-Vehicle-Crashes-in-New-Zealand-2009.aspx</code>.
Thanks to Warwick Goold and Alfian F. Hadi for assistance.
</p>



<h3>References</h3>

<p>Motor Vehicles Crashes in New Zealand 2009;
Statistical Statement Calendar Year 2009.
Ministry of Transport, NZ Government;
Yearly Report 2010.
ISSN: 1176-3949
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+grc">grc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  plot(unlist(alcoff), type = "l", frame.plot = TRUE,
     axes = FALSE, col = "blue", bty = "o",
     main = "Alcoholic offenders on NZ roads, aggregated over 2009",
     sub  = "Vertical lines at midnight (purple) and noon (orange)",
     xlab = "Day/hour", ylab = "Number of offenders")
axis(1, at = 1 + (0:6) * 24 + 12, labels = colnames(alcoff))
axis(2, las = 1)
axis(3:4, labels = FALSE, tick = FALSE)
abline(v = sort(1 + c((0:7) * 24, (0:6) * 24 + 12)), lty = "dashed",
       col = c("purple", "orange")) 
## End(Not run)

# Goodmans RC models
## Not run: 
fitgrc1 &lt;- grc(alcoff)  # Rank-1 model
fitgrc2 &lt;- grc(alcoff, Rank = 2, Corner = FALSE, Uncor = TRUE)
Coef(fitgrc2)

## End(Not run)
## Not run:  biplot(fitgrc2, scaleA = 2.3, Ccol = "blue", Acol = "orange",
       Clabels = as.character(1:23), xlim = c(-1.3, 2.3),
       ylim = c(-1.2, 1)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='cratio'> Ordinal Regression with Continuation Ratios </h2><span id='topic+cratio'></span>

<h3>Description</h3>

<p>Fits a continuation ratio logit/probit/cloglog/cauchit/...
regression model to an ordered (preferably) factor response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cratio(link = "logitlink", parallel = FALSE, reverse = FALSE,
    zero = NULL, ynames = FALSE, Thresh = NULL, Trev = reverse,
    Tref = if (Trev) "M" else 1, whitespace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cratio_+3A_link">link</code></td>
<td>

<p>Link function applied to
the <code class="reqn">M</code> continuation ratio probabilities.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="cratio_+3A_parallel">parallel</code></td>
<td>

<p>A logical, or formula specifying which terms have
equal/unequal coefficients.
</p>
</td></tr>
<tr><td><code id="cratio_+3A_reverse">reverse</code></td>
<td>

<p>Logical.
By default, the continuation ratios used are
<code class="reqn">\eta_j = logit(P[Y&gt;j|Y \geq j])</code>
for <code class="reqn">j=1,\dots,M</code>.
If <code>reverse</code> is <code>TRUE</code>, then
<code class="reqn">\eta_j = logit(P[Y&lt;j+1|Y\leq j+1])</code>
will be used.
</p>
</td></tr>
<tr><td><code id="cratio_+3A_ynames">ynames</code></td>
<td>

<p>See <code><a href="#topic+multinomial">multinomial</a></code> for information.
</p>
</td></tr>
<tr><td><code id="cratio_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The values must be from the set {1,2,...,<code class="reqn">M</code>}.
The default value means none are modelled as intercept-only
terms.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="cratio_+3A_thresh">Thresh</code>, <code id="cratio_+3A_trev">Trev</code>, <code id="cratio_+3A_tref">Tref</code></td>
<td>

<p>See <code><a href="#topic+cumulative">cumulative</a></code> for information.
These arguments apply to ordinal
categorical regression models.
</p>
</td></tr>
<tr><td><code id="cratio_+3A_whitespace">whitespace</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file the response <code class="reqn">Y</code> is assumed to be
a factor with ordered values <code class="reqn">1,2,\dots,M+1</code>, so that
<code class="reqn">M</code> is the number of linear/additive predictors
<code class="reqn">\eta_j</code>.
</p>
<p>There are a number of definitions for the
<em>continuation ratio</em>
in the literature. To make life easier, in the <span class="pkg">VGAM</span>
package, we use <em>continuation</em> ratios and <em>stopping</em>
ratios
(see <code><a href="#topic+sratio">sratio</a></code>).
Stopping ratios deal with quantities such as
<code>logitlink(P[Y=j|Y&gt;=j])</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>No check is made to verify that the response is ordinal if the
response is a matrix;
see <code><a href="base.html#topic+factor">ordered</a></code>.
</p>
<p>Boersch-Supan (2021) looks at sparse data and
the numerical problems that result;
see <code><a href="#topic+sratio">sratio</a></code>.
</p>


<h3>Note</h3>

<p>The response should be either a matrix of counts
(with row sums that are all positive), or a
factor. In both cases, the <code>y</code> slot returned by
<code>vglm</code>/<code>vgam</code>/<code>rrvglm</code> is the matrix
of counts.
</p>
<p>For a nominal (unordered) factor response, the
multinomial logit model (<code><a href="#topic+multinomial">multinomial</a></code>)
is more appropriate.
</p>
<p>Here is an example of the usage of the <code>parallel</code>
argument.  If there are covariates <code>x1</code>, <code>x2</code>
and <code>x3</code>, then <code>parallel = TRUE ~ x1 + x2 -1</code>
and <code>parallel = FALSE ~ x3</code> are equivalent. This
would constrain the regression coefficients for <code>x1</code>
and <code>x2</code> to be equal; those of the intercepts and
<code>x3</code> would be different.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>See <code><a href="#topic+sratio">sratio</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+CM.equid">CM.equid</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+margeff">margeff</a></code>,
<code><a href="#topic+pneumo">pneumo</a></code>,
<code><a href="#topic+budworm">budworm</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let,
             cratio(parallel = TRUE), data = pneumo))
coef(fit, matrix = TRUE)
constraints(fit)
predict(fit)
predict(fit, untransform = TRUE)
margeff(fit)
</code></pre>

<hr>
<h2 id='cumulative'> Ordinal Regression with Cumulative Probabilities </h2><span id='topic+cumulative'></span>

<h3>Description</h3>

<p>Fits a cumulative link
regression model to a (preferably ordered) factor response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cumulative(link = "logitlink", parallel = FALSE,
    reverse = FALSE, multiple.responses = FALSE,
    ynames = FALSE, Thresh = NULL, Trev = reverse,
    Tref = if (Trev) "M" else 1, whitespace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cumulative_+3A_link">link</code></td>
<td>

<p>Link function applied to the <code class="reqn">J</code> cumulative probabilities.
See <code><a href="#topic+Links">Links</a></code> for more choices,
e.g., for the cumulative
<code><a href="#topic+probitlink">probitlink</a></code>/<code><a href="#topic+clogloglink">clogloglink</a></code>/...
models.
</p>
</td></tr>





<tr><td><code id="cumulative_+3A_parallel">parallel</code></td>
<td>

<p>A logical or formula specifying which terms have
equal/unequal coefficients.
See below for more information about the parallelism
assumption.
The default results in what some people call the
<em>generalized ordered logit model</em> to be fitted.
If <code>parallel = TRUE</code> then it does not apply to the
intercept.
</p>
<p>The <em>partial proportional odds model</em> can be
fitted by assigning this argument something like
<code>parallel = TRUE ~ -1 + x3 + x5</code> so that
there is one regression coefficient
for <code>x3</code> and <code>x5</code>.
Equivalently, setting
<code>parallel = FALSE ~ 1 + x2 + x4</code> means <code class="reqn">M</code>
regression coefficients for the intercept
and <code>x2</code> and <code>x4</code>.
It is important that the intercept is never parallel.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more
information.
</p>
</td></tr>








<tr><td><code id="cumulative_+3A_reverse">reverse</code></td>
<td>

<p>Logical.
By default, the cumulative probabilities used are
<code class="reqn">P(Y\leq 1)</code>, <code class="reqn">P(Y\leq 2)</code>,
..., <code class="reqn">P(Y\leq J)</code>.
If <code>reverse</code> is <code>TRUE</code> then
<code class="reqn">P(Y\geq 2)</code>, <code class="reqn">P(Y\geq 3)</code>, ...,
<code class="reqn">P(Y\geq J+1)</code> are used.
</p>







</td></tr>
<tr><td><code id="cumulative_+3A_ynames">ynames</code></td>
<td>

<p>See <code><a href="#topic+multinomial">multinomial</a></code> for information.
</p>
</td></tr>
<tr><td><code id="cumulative_+3A_multiple.responses">multiple.responses</code></td>
<td>

<p>Logical.
Multiple responses?
If <code>TRUE</code> then the input should be
a matrix with values <code class="reqn">1,2,\dots,L</code>,
where <code class="reqn">L=J+1</code> is the
number of levels.
Each column of the matrix is a response,
i.e., multiple responses.
A suitable matrix can be obtained from
<code>Cut</code>.
</p>
</td></tr>















<tr><td><code id="cumulative_+3A_thresh">Thresh</code></td>
<td>

<p>Character.
The choices concern constraint matrices applied
to the intercepts.
They can be constrained to be
equally-spaced (<em>equid</em>istant)
etc.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> and
<code><a href="#topic+constraints">constraints</a></code> for general
information.
Basically, the choice is pasted to the end of
<code>"CM."</code> and that function is called.
This means users can easily write their own
<code>CM.</code>-type function.
</p>







<p>If equally-spaced then the direction and the
reference level are controlled
by <code>Trev</code> and <code>Tref</code>, and
the constraint matrix
will be <code class="reqn">M</code> by 2, with the second
column corresponding to the distance between
the thresholds.
</p>
<p>If <code>"symm1"</code> then the fitted intercepts are
<em>symmetric</em> about the median (<code class="reqn">M</code> odd)
intercept.
If <code class="reqn">M</code> is even then the median is the mean of
the two most inner and adjacent intercepts.
For this, <code><a href="#topic+CM.symm1">CM.symm1</a></code> is used to
construct the appropriate constraint matrix.
</p>
<p>If <code>"symm0"</code> then the median intercept is 0
by definition and the symmetry occurs about the
origin. Thus the intercepts comprise pairs
that differ by sign only.
The appropriate constraint matrix is as with
<code>"symm1"</code> but with the first column deleted.
The choices <code>"symm1"</code> and <code>"symm0"</code>
are effectively equivalent to
<code>"symmetric"</code> and <code>"symmetric2"</code>
respectively in <span class="pkg">ordinal</span>.
</p>
<p>For <code>"qnorm"</code> then
<code><a href="#topic+CM.qnorm">CM.qnorm</a></code> uses the
<code>qnorm((1:M)/(M+1))</code> quantiles
of the standard normal.
</p>
</td></tr>
<tr><td><code id="cumulative_+3A_trev">Trev</code>, <code id="cumulative_+3A_tref">Tref</code></td>
<td>

<p>Support arguments for <code>Thresh</code>
for equally-spaced intercepts.
The logical argument <code>Trev</code> is
applied first to give the direction
(i.e., ascending or descending)
before
row <code>Tref</code> (ultimately numeric)
of the first (intercept) constraint matrix
is set to the reference level.
See <code><a href="#topic+constraints">constraints</a></code> for information.
</p>
</td></tr>
<tr><td><code id="cumulative_+3A_whitespace">whitespace</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file the response <code class="reqn">Y</code> is assumed
to be a factor with ordered values <code class="reqn">1,2,\dots,J+1</code>.
Hence <code class="reqn">M</code> is the number of linear/additive
predictors <code class="reqn">\eta_j</code>;
for <code>cumulative()</code> one has <code class="reqn">M=J</code>.

</p>
<p>This <span class="pkg">VGAM</span> family function fits the class of
<em>cumulative link models</em> to (hopefully)
an ordinal response.
By default, the <em>non-parallel</em> cumulative logit model
is fitted, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">\eta_j = logit(P[Y \leq j])</code>
</p>

<p>where <code class="reqn">j=1,2,\dots,M</code> and
the <code class="reqn">\eta_j</code> are not constrained to be parallel.
This is also known as the <em>non-proportional odds model</em>.
If the logit link is replaced by a complementary log-log link
(<code><a href="#topic+clogloglink">clogloglink</a></code>) then
this is known as the <em>proportional-hazards model</em>.
</p>
<p>In almost all the literature, the constraint matrices
associated with this family of models are known.
For example, setting
<code>parallel = TRUE</code> will make all constraint matrices
(except for the intercept) equal to a vector of <code class="reqn">M</code> 1's.
If the constraint matrices are equal, unknown and to
be estimated,
then this can be achieved by fitting the model as a
reduced-rank vector generalized
linear model (RR-VGLM; see <code><a href="#topic+rrvglm">rrvglm</a></code>).
Currently, reduced-rank vector generalized additive models
(RR-VGAMs) have not been implemented here.
</p>









<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>No check is made to verify that the response is ordinal
if the response is a matrix;
see <code><a href="base.html#topic+factor">ordered</a></code>.
</p>
<p>Boersch-Supan (2021) looks at sparse data and
the numerical problems that result;
see <code><a href="#topic+sratio">sratio</a></code>.
</p>


<h3>Note</h3>

<p>The response should be either a matrix of counts
(with row sums that
are all positive), or a factor. In both cases,
the <code>y</code> slot
returned by
<code><a href="#topic+vglm">vglm</a></code>/<code><a href="#topic+vgam">vgam</a></code>/<code><a href="#topic+rrvglm">rrvglm</a></code>
is the matrix
of counts.
The formula must contain an intercept term.
Other <span class="pkg">VGAM</span> family functions for an ordinal response
include
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>.
For a nominal (unordered) factor response, the multinomial
logit model (<code><a href="#topic+multinomial">multinomial</a></code>) is more appropriate.
</p>
<p>With the logit link, setting <code>parallel =
  TRUE</code> will fit a proportional odds model. Note
that the <code>TRUE</code> here does not apply to
the intercept term.  In practice, the validity
of the <em>proportional odds assumption</em>
needs to be checked, e.g., by a likelihood
ratio test (LRT).  If acceptable on the data,
then numerical problems are less likely
to occur during the fitting, and there are
less parameters. Numerical problems occur
when the linear/additive predictors cross,
which results in probabilities outside of
<code class="reqn">(0,1)</code>; setting <code>parallel = TRUE</code>
will help avoid this problem.
</p>
<p>Here is an example of the usage of the <code>parallel</code>
argument.
If there are covariates <code>x2</code>, <code>x3</code> and
<code>x4</code>, then
<code>parallel = TRUE ~ x2 + x3 -1</code> and
<code>parallel = FALSE ~ x4</code> are equivalent.
This would constrain the regression coefficients
for <code>x2</code> and <code>x3</code> to be equal;
those of the intercepts and <code>x4</code> would be different.
</p>
<p>If the data is inputted in <em>long</em> format
(not <em>wide</em> format, as in <code><a href="#topic+pneumo">pneumo</a></code> below)
and the self-starting initial values are not
good enough then try using
<code>mustart</code>,
<code>coefstart</code> and/or
<code>etatstart</code>.
See the example below.
</p>
<p>To fit the proportional odds model one can use the
<span class="pkg">VGAM</span> family function <code><a href="#topic+propodds">propodds</a></code>.
Note that <code>propodds(reverse)</code> is equivalent to
<code>cumulative(parallel = TRUE, reverse = reverse)</code>
(which is equivalent to
<code>cumulative(parallel =</code>
<code>TRUE, reverse = reverse, link = "logitlink")</code>).
It is for convenience only. A call to
<code>cumulative()</code> is preferred since it reminds the user
that a parallelism assumption is made, as well as
being a lot more flexible.
</p>







<p>Category specific effects may be modelled using
the <code>xij</code>-facility; see
<code><a href="#topic+vglm.control">vglm.control</a></code> and <code><a href="#topic+fill1">fill1</a></code>.
</p>
<p>With most <code>Thresh</code>old choices,
the first few fitted regression coefficients
need care in their interpretation.  For example,
some values could be the distance away from
the median intercept.  Typing something
like <code>constraints(fit)[[1]]</code> gives the
constraint matrix of the intercept term.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Agresti, A. (2013).
<em>Categorical Data Analysis</em>,
3rd ed. Hoboken, NJ, USA: Wiley.
</p>
<p>Agresti, A. (2010).
<em>Analysis of Ordinal Categorical Data</em>,
2nd ed. Hoboken, NJ, USA: Wiley.
</p>










<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed.
London: Chapman &amp; Hall.
</p>



<p>Tutz, G. (2012).
<em>Regression for Categorical Data</em>,
Cambridge: Cambridge University Press.
</p>
<p>Tutz, G. and Berger, M. (2022).
Sparser ordinal regression models based
on parametric and additive location-shift
approaches.
<em>International Statistical Review</em>,
<b>90</b>, 306&ndash;327.
<a href="https://doi.org/10.1111/insr.12484">doi:10.1111/insr.12484</a>.
</p>
<p>Yee, T. W. (2010).
The <span class="pkg">VGAM</span> package for categorical data analysis.
<em>Journal of Statistical Software</em>,
<b>32</b>, 1&ndash;34.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>


<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+propodds">propodds</a></code>,
<code><a href="#topic+constraints">constraints</a></code>,
<code><a href="#topic+CM.ones">CM.ones</a></code>,
<code><a href="#topic+CM.equid">CM.equid</a></code>,
<code><a href="#topic+R2latvar">R2latvar</a></code>,
<code><a href="#topic+ordsup">ordsup</a></code>,
<code><a href="#topic+prplot">prplot</a></code>,
<code><a href="#topic+margeff">margeff</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+pneumo">pneumo</a></code>,
<code><a href="#topic+budworm">budworm</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="#topic+logistic1">logistic1</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'># Proportional odds model (p.179) of McCullagh and Nelder (1989)
pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let,
             cumulative(parallel = TRUE, reverse = TRUE), pneumo))
depvar(fit)  # Sample proportions (good technique)
fit@y        # Sample proportions (bad technique)
weights(fit, type = "prior")  # Number of observations
coef(fit, matrix = TRUE)
constraints(fit)  # Constraint matrices
apply(fitted(fit), 1, which.max)  # Classification
apply(predict(fit, newdata = pneumo, type = "response"),
      1, which.max)  # Classification
R2latvar(fit)

# Check that the model is linear in let ----------------------
fit2 &lt;- vgam(cbind(normal, mild, severe) ~ s(let, df = 2),
             cumulative(reverse = TRUE), data = pneumo)
## Not run: 
 plot(fit2, se = TRUE, overlay = TRUE, lcol = 1:2, scol = 1:2) 
## End(Not run)

# Check the proportional odds assumption with a LRT ----------
(fit3 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = FALSE, reverse = TRUE), pneumo))
pchisq(2 * (logLik(fit3) - logLik(fit)), df =
       length(coef(fit3)) - length(coef(fit)), lower.tail = FALSE)
lrtest(fit3, fit)  # More elegant

# A factor() version of fit ----------------------------------
# This is in long format (cf. wide format above)
Nobs &lt;- round(depvar(fit) * c(weights(fit, type = "prior")))
sumNobs &lt;- colSums(Nobs)  # apply(Nobs, 2, sum)

pneumo.long &lt;-
  data.frame(symptoms = ordered(rep(rep(colnames(Nobs), nrow(Nobs)),
                                        times = c(t(Nobs))),
                                levels = colnames(Nobs)),
             let = rep(rep(with(pneumo, let), each = ncol(Nobs)),
                       times = c(t(Nobs))))
with(pneumo.long, table(let, symptoms))  # Should be same as pneumo


(fit.long1 &lt;- vglm(symptoms ~ let, data = pneumo.long, trace = TRUE,
                   cumulative(parallel = TRUE, reverse = TRUE)))
coef(fit.long1, matrix = TRUE)  # cf. coef(fit, matrix = TRUE)
# Could try using mustart if fit.long1 failed to converge.
mymustart &lt;- matrix(sumNobs / sum(sumNobs),
                    nrow(pneumo.long), ncol(Nobs), byrow = TRUE)
fit.long2 &lt;- vglm(symptoms ~ let, mustart = mymustart,
                  cumulative(parallel = TRUE, reverse = TRUE),
                  data = pneumo.long, trace = TRUE)
coef(fit.long2, matrix = TRUE)  # cf. coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='dagum'> Dagum Distribution Family Function </h2><span id='topic+dagum'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 3-parameter
Dagum distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dagum(lscale = "loglink", lshape1.a = "loglink", lshape2.p =
      "loglink", iscale = NULL, ishape1.a = NULL, ishape2.p =
      NULL, imethod = 1, lss = TRUE, gscale = exp(-5:5), gshape1.a
      = seq(0.75, 4, by = 0.25), gshape2.p = exp(-5:5), probs.y =
      c(0.25, 0.5, 0.75), zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dagum_+3A_lss">lss</code></td>
<td>
<p> See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
important information.
</p>
</td></tr>
<tr><td><code id="dagum_+3A_lshape1.a">lshape1.a</code>, <code id="dagum_+3A_lscale">lscale</code>, <code id="dagum_+3A_lshape2.p">lshape2.p</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code>a</code>, <code>scale</code>, and <code>p</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="dagum_+3A_iscale">iscale</code>, <code id="dagum_+3A_ishape1.a">ishape1.a</code>, <code id="dagum_+3A_ishape2.p">ishape2.p</code>, <code id="dagum_+3A_imethod">imethod</code>, <code id="dagum_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>ishape2.p</code> is needed to obtain a good estimate for
the other parameter.
</p>
</td></tr>
<tr><td><code id="dagum_+3A_gscale">gscale</code>, <code id="dagum_+3A_gshape1.a">gshape1.a</code>, <code id="dagum_+3A_gshape2.p">gshape2.p</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="dagum_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 3-parameter Dagum distribution is the 4-parameter
generalized beta II distribution with shape parameter <code class="reqn">q=1</code>.
It is known under various other names, such as the Burr III,
inverse Burr, beta-K, and 3-parameter kappa distribution.
It can be considered a generalized log-logistic distribution.
Some distributions which are special cases of the 3-parameter
Dagum are the inverse Lomax (<code class="reqn">a=1</code>), Fisk (<code class="reqn">p=1</code>),
and the inverse paralogistic (<code class="reqn">a=p</code>).
More details can be found in Kleiber and Kotz (2003).
</p>
<p>The Dagum distribution has a cumulative distribution function
</p>
<p style="text-align: center;"><code class="reqn">F(y) = [1 + (y/b)^{-a}]^{-p}</code>
</p>

<p>which leads to a probability density function
</p>
<p style="text-align: center;"><code class="reqn">f(y) = ap y^{ap-1} / [b^{ap} \{1 + (y/b)^a\}^{p+1}]</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">p &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and the others are shape parameters.
The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(p + 1/a) \, \Gamma(1 - 1/a) / \Gamma(p)</code>
</p>

<p>provided <code class="reqn">-ap &lt; 1 &lt; a</code>; these are returned as the fitted
values.  This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>
<p>From Kleiber and Kotz (2003), the MLE is rather sensitive to
isolated observations located sufficiently far from the majority
of the data.  Reliable estimation of the scale parameter require
<code class="reqn">n&gt;7000</code>, while estimates for <code class="reqn">a</code> and <code class="reqn">p</code> can be
considered unbiased for <code class="reqn">n&gt;2000</code> or 3000.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Dagum">Dagum</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ddata &lt;- data.frame(y = rdagum(n = 3000, scale = exp(2),
                               shape1 = exp(1), shape2 = exp(1)))
fit &lt;- vglm(y ~ 1, dagum(lss = FALSE), data = ddata, trace = TRUE)
fit &lt;- vglm(y ~ 1, dagum(lss = FALSE, ishape1.a = exp(1)),
            data = ddata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)</code></pre>

<hr>
<h2 id='Dagum'>The Dagum Distribution</h2><span id='topic+Dagum'></span><span id='topic+ddagum'></span><span id='topic+pdagum'></span><span id='topic+qdagum'></span><span id='topic+rdagum'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Dagum distribution with shape parameters
<code>a</code> and <code>p</code>, and scale parameter <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddagum(x, scale = 1, shape1.a, shape2.p, log = FALSE)
pdagum(q, scale = 1, shape1.a, shape2.p, lower.tail = TRUE,
       log.p = FALSE)
qdagum(p, scale = 1, shape1.a, shape2.p, lower.tail = TRUE,
       log.p = FALSE)
rdagum(n, scale = 1, shape1.a, shape2.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dagum_+3A_x">x</code>, <code id="Dagum_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Dagum_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Dagum_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>,
the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="Dagum_+3A_shape1.a">shape1.a</code>, <code id="Dagum_+3A_shape2.p">shape2.p</code></td>
<td>
<p>shape parameters.</p>
</td></tr>
<tr><td><code id="Dagum_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Dagum_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Dagum_+3A_lower.tail">lower.tail</code>, <code id="Dagum_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+dagum">dagum</a></code>, which is the <span class="pkg">VGAM</span> family function
for estimating the parameters by maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>ddagum</code> gives the density,
<code>pdagum</code> gives the distribution function,
<code>qdagum</code> gives the quantile function, and
<code>rdagum</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Dagum distribution is a special case of the 4-parameter
generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- seq(0.1, 0.9, by = 0.1)
shape1.a &lt;- 1; shape2.p &lt;- 2
# Should be 0:
max(abs(pdagum(qdagum(probs, shape1.a = shape1.a, shape2.p =
  shape2.p), shape1.a = shape1.a, shape2.p = shape2.p) - probs))

## Not run:  par(mfrow = c(1, 2))
x &lt;- seq(-0.01, 5, len = 401)
plot(x, dexp(x), type = "l", col = "black",
     ylab = "", las = 1, ylim = c(0, 1),
     main = "Black is std exponential, others are ddagum(x, ...)")
lines(x, ddagum(x, shape1.a = shape1.a, shape2.p = 1), col = "orange")
lines(x, ddagum(x, shape1.a = shape1.a, shape2.p = 2), col = "blue")
lines(x, ddagum(x, shape1.a = shape1.a, shape2.p = 5), col = "green")
legend("topright", col = c("orange","blue","green"),
       lty = rep(1, len = 3), legend = paste("shape1.a =", shape1.a,
       ", shape2.p =", c(1, 2, 5)))

plot(x, pexp(x), type = "l", col = "black", ylab = "", las = 1,
     main = "Black is std exponential, others are pdagum(x, ...)")
lines(x, pdagum(x, shape1.a = shape1.a, shape2.p = 1), col = "orange")
lines(x, pdagum(x, shape1.a = shape1.a, shape2.p = 2), col = "blue")
lines(x, pdagum(x, shape1.a = shape1.a, shape2.p = 5), col = "green")
legend("bottomright", col = c("orange", "blue", "green"),
       lty = rep(1, len = 3), legend = paste("shape1.a =", shape1.a,
       ", shape2.p =", c(1, 2, 5)))

## End(Not run)
</code></pre>

<hr>
<h2 id='dAR1'>The AR-1 Autoregressive Process</h2><span id='topic+dAR1'></span><span id='topic+dAR1'></span>

<h3>Description</h3>

<p>Density for the AR-1 model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dAR1(x, drift = 0, var.error = 1, ARcoef1 = 0.0,
     type.likelihood = c("exact", "conditional"), log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dAR1_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="dAR1_+3A_drift">drift</code></td>
<td>

<p>the scaled mean (also known as the <em>drift</em> parameter),
<code class="reqn">\mu^*</code>.
Note that the mean is <code class="reqn">\mu^* /(1-\rho)</code>.
The default corresponds to observations that have mean 0.
</p>
</td></tr>
<tr><td><code id="dAR1_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="dAR1_+3A_type.likelihood">type.likelihood</code>, <code id="dAR1_+3A_var.error">var.error</code>, <code id="dAR1_+3A_arcoef1">ARcoef1</code></td>
<td>

<p>See <code><a href="#topic+AR1">AR1</a></code>.
The argument <code>ARcoef1</code> is <code class="reqn">\rho</code>.
The argument <code>var.error</code> is the variance of  the
i.i.d. random noise, i.e., <code class="reqn">\sigma^2</code>.
If <code>type.likelihood = "conditional"</code> then the
first element or row of the result is currently
assigned <code>NA</code>&mdash;this
is because the density of the first observation is effectively
ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the background to this function is given
in <code><a href="#topic+AR1">AR1</a></code>.
All the arguments are converted into matrices, and then
all their dimensions are obtained. They are then coerced
into the same size: the number of rows is the maximum
of all the single rows, and ditto for the number of columns.
</p>


<h3>Value</h3>

<p><code>dAR1</code> gives the density.
</p>





<h3>Author(s)</h3>

<p> T. W. Yee and Victor Miranda </p>


<h3>See Also</h3>

<p><code><a href="#topic+AR1">AR1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 100; set.seed(1)
tdata &lt;- data.frame(index = 1:nn,
                    TS1 = arima.sim(nn, model = list(ar = -0.50),
                                    sd = exp(1)))
fit1 &lt;- vglm(TS1 ~ 1, AR1, data = tdata, trace = TRUE)
rhobitlink(-0.5)
coef(fit1, matrix = TRUE)
(Cfit1 &lt;- Coef(fit1))
summary(fit1)  # SEs are useful to know
logLik(fit1)
sum(dAR1(depvar(fit1), drift = Cfit1[1], var.error = (Cfit1[2])^2,
         ARcoef1 = Cfit1[3], log = TRUE))

fit2 &lt;- vglm(TS1 ~ 1, AR1(type.likelihood = "cond"), data = tdata, trace = TRUE)
(Cfit2 &lt;- Coef(fit2))  # Okay for intercept-only models
logLik(fit2)
head(keep &lt;- dAR1(depvar(fit2), drift = Cfit2[1], var.error = (Cfit2[2])^2,
                  ARcoef1 = Cfit2[3], type.likelihood = "cond", log = TRUE))
sum(keep[-1])
</code></pre>

<hr>
<h2 id='deermice'>
Captures of Peromyscus maniculatus (Also Known as Deer Mice).

</h2><span id='topic+deermice'></span>

<h3>Description</h3>

<p>Captures of <em>Peromyscus maniculatus</em> collected at East
Stuart Gulch, Colorado, USA.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>  data(deermice)
</code></pre>


<h3>Format</h3>

<p>The format is a data frame.
</p>


<h3>Details</h3>

<p><em>Peromyscus maniculatus</em> is a rodent native to North
America.  The deer mouse is small in size, only about 8 to 10
cm long, not counting the length of the tail.
</p>
<p>Originally,
the columns of this data frame
represent the sex (<code>m</code> or <code>f</code>),
the ages (<code>y</code>: young, <code>sa</code>: semi-adult, <code>a</code>:
adult), the weights in grams, and the capture histories of
38 individuals over 6 trapping occasions (1: captured, 0:
not captured).
</p>
<p>The data set was collected by V. Reid and distributed
with the <span class="pkg">CAPTURE</span> program of Otis et al. (1978).
</p>
<p><code>deermice</code> has 38 deermice whereas
<code>Perom</code> had 36 deermice
(<code>Perom</code> has been withdrawn.)
In <code>deermice</code> the two semi-adults have been classified
as adults.  The <code>sex</code> variable has 1 for female, and 0
for male.
</p>



<h3>References</h3>

<p>Huggins, R. M. (1991).
Some practical aspects of a conditional likelihood
approach to capture experiments.
<em>Biometrics</em>,
<b>47</b>, 725&ndash;732.
</p>
<p>Otis, D. L. et al. (1978).
Statistical inference from capture data on closed animal
populations,
<em>Wildlife Monographs</em>, <b>62</b>, 3&ndash;135.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>,
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>,
<code><a href="#topic+fill1">fill1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(deermice)
## Not run: 
fit1 &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + age,
             posbernoulli.t(parallel.t = TRUE), deermice, trace = TRUE)
coef(fit1)
coef(fit1, matrix = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='deplot.lmscreg'> Density Plot for LMS Quantile Regression </h2><span id='topic+deplot.lmscreg'></span>

<h3>Description</h3>

<p>Plots a probability density function
associated with a LMS quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deplot.lmscreg(object, newdata = NULL, x0, y.arg, show.plot =
               TRUE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deplot.lmscreg_+3A_object">object</code></td>
<td>
<p> A <span class="pkg">VGAM</span> quantile regression model, i.e.,
an object produced by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code> with a family function
beginning with <code>"lms."</code>, e.g., <code><a href="#topic+lms.yjn">lms.yjn</a></code>.
</p>
</td></tr>
<tr><td><code id="deplot.lmscreg_+3A_newdata">newdata</code></td>
<td>
<p> Optional data frame containing secondary
variables such as sex.  It should have a maximum of one row.
The default is to use the original data.
</p>
</td></tr>
<tr><td><code id="deplot.lmscreg_+3A_x0">x0</code></td>
<td>
<p> Numeric. The value of the primary variable at which
to make the &lsquo;slice&rsquo;.
</p>
</td></tr>
<tr><td><code id="deplot.lmscreg_+3A_y.arg">y.arg</code></td>
<td>
<p> Numerical vector. The values of the response
variable at which to evaluate the density. This should be a grid
that is fine enough to ensure the plotted curves are smooth.
</p>
</td></tr> <tr><td><code id="deplot.lmscreg_+3A_show.plot">show.plot</code></td>
<td>
<p> Logical. Plot it? If <code>FALSE</code> no plot
will be done.
</p>
</td></tr>
<tr><td><code id="deplot.lmscreg_+3A_...">...</code></td>
<td>
<p> Graphical parameter that are passed into
<code><a href="#topic+plotdeplot.lmscreg">plotdeplot.lmscreg</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls, e.g., <code>deplot.lms.yjn</code> in order to
compute the density function.
</p>


<h3>Value</h3>

<p>The original <code>object</code> but with a list
placed in the slot <code>post</code>, called
<code>@post$deplot</code>. The list has components
</p>
<table>
<tr><td><code>newdata</code></td>
<td>
<p> The argument <code>newdata</code> above, or a one-row
data frame constructed out of the <code>x0</code> argument. </p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p> The argument <code>y.arg</code> above. </p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p> Vector of the density function values evaluated
at <code>y.arg</code>. </p>
</td></tr>
</table>


<h3>Note</h3>

<p><code><a href="#topic+plotdeplot.lmscreg">plotdeplot.lmscreg</a></code> actually does the plotting.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotdeplot.lmscreg">plotdeplot.lmscreg</a></code>,
<code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+lms.bcg">lms.bcg</a></code>,
<code><a href="#topic+lms.yjn">lms.yjn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fit &lt;- vgam(BMI ~ s(age, df = c(4, 2)), lms.bcn(zero = 1), bmi.nz)
ygrid &lt;- seq(15, 43, by = 0.25)
deplot(fit, x0 = 20, y = ygrid, xlab = "BMI", col = "green", llwd = 2,
    main = "BMI distribution at ages 20 (green), 40 (blue), 60 (red)")
deplot(fit, x0 = 40, y = ygrid, add = TRUE, col = "blue", llwd = 2)
deplot(fit, x0 = 60, y = ygrid, add = TRUE, col = "red", llwd = 2) -&gt; a

names(a@post$deplot)
a@post$deplot$newdata
head(a@post$deplot$y)
head(a@post$deplot$density)

## End(Not run)
</code></pre>

<hr>
<h2 id='depvar'> Response Variable Extracted </h2><span id='topic+depvar'></span>

<h3>Description</h3>

<p>A generic function that extracts the response/dependent
variable from objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>depvar(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="depvar_+3A_object">object</code></td>
<td>

<p>An object that has some response/dependent variable.
</p>
</td></tr>
<tr><td><code id="depvar_+3A_...">...</code></td>
<td>

<p>Other arguments fed into the specific methods function of
the model.
In particular, sometimes <code>type = c("lm", "lm2")</code> is
available, in which case the first one is chosen if the
user does not input a value.
The latter value corresponds to argument <code>form2</code>, and
sometimes a response for that is optional.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default
this function is preferred to calling <code>fit@y</code>, say.
</p>


<h3>Value</h3>

<p>The response/dependent variable,
usually as a matrix or vector.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.matrix">model.matrix</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo))
fit@y        # Sample proportions (not recommended)
depvar(fit)  # Better than using fit@y
weights(fit, type = "prior")  # Number of observations
</code></pre>

<hr>
<h2 id='dextlogF'> Extended log-F Distribution </h2><span id='topic+dextlogF'></span>

<h3>Description</h3>

<p>Density
for the extended log-F distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dextlogF(x, lambda, tau, location = 0, scale = 1, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dextlogF_+3A_x">x</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="dextlogF_+3A_lambda">lambda</code>, <code id="dextlogF_+3A_tau">tau</code></td>
<td>

<p>See <code><a href="#topic+extlogF1">extlogF1</a></code>.
</p>
</td></tr>
<tr><td><code id="dextlogF_+3A_location">location</code>, <code id="dextlogF_+3A_scale">scale</code></td>
<td>

<p>See <code><a href="#topic+extlogF1">extlogF1</a></code>.
</p>
</td></tr>


<tr><td><code id="dextlogF_+3A_log">log</code></td>
<td>

<p>If <code>TRUE</code> then the log density is returned, else the density.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details are given in <code><a href="#topic+extlogF1">extlogF1</a></code>.
</p>


<h3>Value</h3>

<p><code>dextlogF</code> gives the density.
</p>





<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+dalap">dalap</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  x &lt;- seq(-2, 8, by = 0.1); mytau &lt;- 0.25; mylambda &lt;- 0.2
plot(x, dextlogF(x, mylambda, tau = mytau), type = "l",
     las = 1, col = "blue", ylab = "PDF (log-scale)", log = "y",
     main = "Extended log-F density function is blue",
     sub = "Asymmetric Laplace is orange dashed")
lines(x, dalap(x, tau = mytau, scale = 3.5), col = "orange", lty = 2)
abline(v = 0, col = "gray", lty = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='df.residual'>Residual Degrees-of-Freedom</h2><span id='topic+df.residual'></span><span id='topic+df.residual_vlm'></span>

<h3>Description</h3>

<p>Returns the residual degrees-of-freedom extracted from a fitted
VGLM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df.residual_vlm(object, type = c("vlm", "lm"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="df.residual_+3A_object">object</code></td>
<td>

<p>an object for which the degrees-of-freedom are desired,
e.g., a <code><a href="#topic+vglm">vglm</a></code> object.
</p>
</td></tr>
<tr><td><code id="df.residual_+3A_type">type</code></td>
<td>

<p>the type of residual degrees-of-freedom wanted.
In some applications the 'usual' LM-type value may be more
appropriate.  The default is the first choice.
</p>
</td></tr>
<tr><td><code id="df.residual_+3A_...">...</code></td>
<td>

<p>additional optional arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When a VGLM is fitted, a <em>large</em> (VLM) generalized least
squares (GLS) fit is done at each IRLS iteration. To do this, an
ordinary least squares (OLS) fit is performed by
transforming the GLS using Cholesky factors.
The number of rows is <code class="reqn">M</code> times the &lsquo;ordinary&rsquo; number
of rows of the LM-type model: <code class="reqn">nM</code>.
Here, <code class="reqn">M</code> is the number of linear/additive predictors.
So the formula for the VLM-type residual degrees-of-freedom
is <code class="reqn">nM - p^{*}</code> where <code class="reqn">p^{*}</code> is the number of
columns of the &lsquo;big&rsquo; VLM matrix.
The formula for the LM-type residual degrees-of-freedom
is <code class="reqn">n - p_{j}</code> where <code class="reqn">p_{j}</code> is the number of
columns of the &lsquo;ordinary&rsquo; LM matrix corresponding
to the <code class="reqn">j</code>th linear/additive predictor.
</p>


<h3>Value</h3>

<p>The value of the residual degrees-of-freedom extracted
from the object.
When <code>type = "vlm"</code> this is a single integer, and
when <code>type = "lm"</code> this is a <code class="reqn">M</code>-vector of
integers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="stats.html#topic+deviance">deviance</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo))
head(model.matrix(fit, type = "vlm"))
head(model.matrix(fit, type = "lm"))

df.residual(fit, type = "vlm")  # n * M - p_VLM
nobs(fit, type = "vlm")  # n * M
nvar(fit, type = "vlm")  # p_VLM

df.residual(fit, type = "lm")  # n - p_LM(j)
nobs(fit, type = "lm")  # n
nvar(fit, type = "lm")  # p_LM
nvar_vlm(fit, type = "lm")  # p_LM(j) (&lt;= p_LM elementwise)
</code></pre>

<hr>
<h2 id='dgaitdplot'>
Plotting the GAITD Combo Density
</h2><span id='topic+dgaitdplot'></span>

<h3>Description</h3>

<p>Plots a 1- or 2-parameter GAITD combo
probability mass function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgaitdplot(theta.p, fam = "pois", a.mix = NULL, i.mix = NULL,
    d.mix = NULL, a.mlm = NULL, i.mlm = NULL,
    d.mlm = NULL, truncate = NULL, max.support = Inf,
    pobs.mix = 0, pobs.mlm = 0,
    pstr.mix = 0, pstr.mlm = 0,
    pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
    theta.a = theta.p, theta.i = theta.p, theta.d = theta.p,
    deflation = FALSE, plot.it = TRUE, new.plot = TRUE,
    offset.x = ifelse(new.plot, 0, 0.25), type.plot = "h",
    xlim = c(0, min(100, max.support + 2)),
    ylim = NULL, xlab = "", ylab = "Probability", main = "",
    cex.main = 1.2, posn.main = NULL,
    all.col = NULL, all.lty = NULL, all.lwd = NULL, 
    lty.p = "solid", lty.a.mix = "longdash", lty.a.mlm = "longdash",
    lty.i.mix = "dashed", lty.i.mlm = "dashed",
    lty.d.mix = "solid", lty.d.mlm = "solid", lty.d.dip = "dashed",
    col.p = "pink2",
    col.a.mix = artichoke.col, col.a.mlm = asparagus.col,
    col.i.mix = indigo.col, col.i.mlm = iris.col,
    col.d.mix = deer.col, col.d.mlm = dirt.col, col.d.dip = desire.col,
    col.t = turquoise.col, cex.p = 1, lwd.p = NULL, lwd.a = NULL,
    lwd.i = NULL, lwd.d = NULL, iontop = TRUE, dontop = TRUE,
    las = 0, lend = "round", axes.x = TRUE, axes.y = TRUE,
    Plot.trunc = TRUE, cex.t = 1, pch.t = 1,
    baseparams.argnames = NULL, nparams = 1, flip.args = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dgaitdplot_+3A_theta.p">theta.p</code></td>
<td>

<p>Numeric, usually scalar but may have length 2.
This matches with, e.g., <code>lambda.p</code> for
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
A length 2 example is <code>c(size.p, munb.p)</code> for
<code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
in which case <code>fam = "nbinom"</code>.
Another length 2 example is
<code>c(mean.p, dispind.p)</code> for <code>Gaitgenpois1</code>,
in which case <code>fam = "genpois1"</code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_fam">fam</code></td>
<td>

<p>Character, <code>paste0("dgait", fam)</code>
should be a <code>d</code>-type function returning
the PMF.  The default is for the GAITD
Poisson combo.
</p>



</td></tr>
<tr><td><code id="dgaitdplot_+3A_a.mix">a.mix</code>, <code id="dgaitdplot_+3A_i.mix">i.mix</code>, <code id="dgaitdplot_+3A_a.mlm">a.mlm</code>, <code id="dgaitdplot_+3A_i.mlm">i.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_d.mix">d.mix</code>, <code id="dgaitdplot_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_truncate">truncate</code>, <code id="dgaitdplot_+3A_max.support">max.support</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_pobs.mix">pobs.mix</code>, <code id="dgaitdplot_+3A_pobs.mlm">pobs.mlm</code>, <code id="dgaitdplot_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_pstr.mix">pstr.mix</code>, <code id="dgaitdplot_+3A_pstr.mlm">pstr.mlm</code>, <code id="dgaitdplot_+3A_pdip.mix">pdip.mix</code>, <code id="dgaitdplot_+3A_pdip.mlm">pdip.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_theta.a">theta.a</code>, <code id="dgaitdplot_+3A_theta.i">theta.i</code>, <code id="dgaitdplot_+3A_theta.d">theta.d</code></td>
<td>

<p>Similar to <code>theta.p</code>, and they should
have the same length too.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_deflation">deflation</code></td>
<td>

<p>Logical.
Plot the deflation (dip) probabilities?
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_plot.it">plot.it</code></td>
<td>

<p>Logical. Plot the PMF?
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_new.plot">new.plot</code>, <code id="dgaitdplot_+3A_offset.x">offset.x</code></td>
<td>

<p>If <code>new.plot</code> then
<code><a href="graphics.html#topic+plot">plot</a></code> is called.
If multiple plots are desired then use
<code>offset.x</code> to shift the lines.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_xlim">xlim</code>, <code id="dgaitdplot_+3A_ylim">ylim</code>, <code id="dgaitdplot_+3A_xlab">xlab</code>, <code id="dgaitdplot_+3A_ylab">ylab</code></td>
<td>

<p>See <code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
Argument <code>xlim</code> should be integer-valued.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_main">main</code>, <code id="dgaitdplot_+3A_cex.main">cex.main</code>, <code id="dgaitdplot_+3A_posn.main">posn.main</code></td>
<td>

<p>Character, size and position of <code>main</code> for the title.
See <code><a href="graphics.html#topic+title">title</a></code>,
<code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
The position is used if it is a 2-vector.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_all.col">all.col</code>, <code id="dgaitdplot_+3A_all.lty">all.lty</code>, <code id="dgaitdplot_+3A_all.lwd">all.lwd</code></td>
<td>

<p>These arguments allow all the colours,
line types and line widths arguments to be
assigned to these values, i.e., so that they
are the same for all values of the support.
For example, if <code>all.lwd = 2</code> then this
sets <code>lwd.p</code>, <code>lwd.a</code>, <code>lwd.i</code>
and <code>lwd.d</code> all equal to 2.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_lty.p">lty.p</code>, <code id="dgaitdplot_+3A_lty.a.mix">lty.a.mix</code>, <code id="dgaitdplot_+3A_lty.a.mlm">lty.a.mlm</code>, <code id="dgaitdplot_+3A_lty.i.mix">lty.i.mix</code>, <code id="dgaitdplot_+3A_lty.i.mlm">lty.i.mlm</code></td>
<td>

<p>Line type for parent, altered and inflated.
See <code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_col.p">col.p</code>, <code id="dgaitdplot_+3A_col.a.mix">col.a.mix</code>, <code id="dgaitdplot_+3A_col.a.mlm">col.a.mlm</code>, <code id="dgaitdplot_+3A_col.i.mix">col.i.mix</code>, <code id="dgaitdplot_+3A_col.i.mlm">col.i.mlm</code></td>
<td>

<p>Line colour for parent (nonspecial), altered, inflated,
truncated and deflated values.
See <code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
Roughly, by default and currently,
the parent is pink-like,
the altered are greenish,
the inflated are purplish/violet,
the truncated are light blue,
and the deflated are brownish with the dip
probabilities being reddish.
The proper colour names are similar to
being acrostic.  For each operator, the
colours of <code>"mix"</code> vs <code>"mlm"</code> are
similar but different&mdash;this is intentional.
Warning: the default colours might change,
depending on style!
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_lty.d.mix">lty.d.mix</code>, <code id="dgaitdplot_+3A_lty.d.mlm">lty.d.mlm</code>, <code id="dgaitdplot_+3A_lty.d.dip">lty.d.dip</code></td>
<td>

<p>Similar to above.
Used when <code>deflation = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_col.d.mix">col.d.mix</code>, <code id="dgaitdplot_+3A_col.d.mlm">col.d.mlm</code>, <code id="dgaitdplot_+3A_col.d.dip">col.d.dip</code></td>
<td>

<p>Similar to above.
Used when <code>deflation = TRUE</code>.
The website <a href="https://www.spycolor.com">https://www.spycolor.com</a> was used to
choose some of the default colours;
the first two are also called <code>"dirt"</code>
and <code>"deer"</code> respectively, which are
both brownish.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_col.t">col.t</code></td>
<td>

<p>Point colour for truncated values, the default is
<code>"tan"</code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_type.plot">type.plot</code>, <code id="dgaitdplot_+3A_cex.p">cex.p</code></td>
<td>

<p>The former matches 'type' argument in
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
The latter is the size of the point if
<code>type.plot = "p"</code> or <code>type.plot = "b"</code>,
etc.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_lwd.p">lwd.p</code>, <code id="dgaitdplot_+3A_lwd.a">lwd.a</code>, <code id="dgaitdplot_+3A_lwd.i">lwd.i</code>, <code id="dgaitdplot_+3A_lwd.d">lwd.d</code></td>
<td>

<p>Line width for parent, altered and inflated.
See <code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
By default <code>par()\$lwd</code> is used for all of them.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_las">las</code>, <code id="dgaitdplot_+3A_lend">lend</code></td>
<td>

<p>See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_iontop">iontop</code>, <code id="dgaitdplot_+3A_dontop">dontop</code></td>
<td>

<p>Logicals.
Draw the inflated and deflated bars on top?
The default is to draw the spikes on top, but if
<code>FALSE</code> then the spikes are drawn
from the bottom&mdash;this makes it easier
to see their distribution.  Likewise, if
<code>deflation = TRUE</code> then <code>dontop</code>
is used to position the deflation (dip)
probabilities.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_axes.x">axes.x</code>, <code id="dgaitdplot_+3A_axes.y">axes.y</code></td>
<td>

<p>Logical. Plot axes?
See <code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_plot.trunc">Plot.trunc</code>, <code id="dgaitdplot_+3A_cex.t">cex.t</code>, <code id="dgaitdplot_+3A_pch.t">pch.t</code></td>
<td>

<p>Logical. Plot the truncated values?
If so, then specify the size and plotting character.
See <code><a href="graphics.html#topic+par">par</a></code> and
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_baseparams.argnames">baseparams.argnames</code></td>
<td>

<p>Character string specifying the argument name for the generic
parameter <code>theta</code>, e.g.,
<code>"lambda"</code> for <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>, 
By appending <code>.p</code>, there is an argument called
<code>lambda.p</code> in <code><a href="#topic+dgaitdpois">dgaitdpois</a></code>.
Another example is for <code><a href="#topic+gaitdlog">gaitdlog</a></code>:
<code>"shape"</code> appended with <code>.p</code> means that
<code><a href="#topic+dgaitdlog">dgaitdlog</a></code> should have an argument
called <code>shape.p</code>.
This argument is optional and increases the reliability of the
<code><a href="base.html#topic+do.call">do.call</a></code> call internally.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_nparams">nparams</code>, <code id="dgaitdplot_+3A_flip.args">flip.args</code></td>
<td>

<p>Not for use by the user. It is used
internally to handle the NBD.
</p>
</td></tr>
<tr><td><code id="dgaitdplot_+3A_...">...</code></td>
<td>

<p>Currently unused but there is provision for
passing graphical arguments in in the future;
see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is meant to be a crude function to
plot the PMF of the GAITD combo model.
Some flexibility is offered via many
graphical arguments, but there are still many
improvements that could be done.
</p>


<h3>Value</h3>

<p>A list is returned invisibly. The components
are:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The integer values between the values
of <code>xlim</code>.
</p>
</td></tr>
<tr><td><code>pmf.z</code></td>
<td>
<p>The value of the PMF, by
calling the <code>d</code>-type function with all
the arguments fed in.
</p>
</td></tr>
<tr><td><code>sc.parent</code></td>
<td>

<p>The same level as the scaled parent
distribution.  Thus for inflated values,
the value where the spikes begin.  And for
deflated values, the value at the top of
the dips.  This is a convenient way to obtain
them as it is quite cumbersome to compute
them manually.  For any nonspecial value,
such as non-inflated and non-deflated values,
they are equal to <code>pmf.z</code>.
</p>

</td></tr>
<tr><td><code>unsc.parent</code></td>
<td>

<p>Unscaled parent distribution.
If there is no alteration, inflation,
deflation and truncation then this is
the basic PMF stipulated by the parent
distribution only.  Usually this is FYI only.
</p>

</td></tr>

</table>


<h3>Note</h3>

<p>This utility function may change a lot in the future.
Because this function is called by a <span class="pkg">shiny</span> app,
if any parameter values lie outside the 
parameter space then <code><a href="base.html#topic+stop">stop</a></code>
will be called.
For example, too much deflation results in
<code>NaN</code> values returned by
<code><a href="#topic+dgaitdnbinom">dgaitdnbinom</a></code>.
</p>



<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotdgaitd">plotdgaitd</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+meangaitd">meangaitd</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
<code><a href="#topic+multilogitlink">multilogitlink</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run:   i.mix &lt;- seq(0, 25, by = 5)
mean.p &lt;- 10; size.p &lt;- 8
dgaitdplot(c(size.p, mean.p), fam = "nbinom", xlim = c(0, 25),
     a.mix = i.mix + 1, i.mix = i.mix, pobs.mix = 0.1,
     pstr.mix = 0.1, lwd.i = 2,lwd.p = 2, lwd.a = 2)

## End(Not run)</code></pre>

<hr>
<h2 id='dhuber'>Huber's Least Favourable Distribution</h2><span id='topic+dhuber'></span><span id='topic+edhuber'></span><span id='topic+rhuber'></span><span id='topic+qhuber'></span><span id='topic+phuber'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for Huber's least favourable distribution, see Huber
and Ronchetti (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'> dhuber(x, k = 0.862, mu = 0, sigma = 1, log = FALSE)
edhuber(x, k = 0.862, mu = 0, sigma = 1, log = FALSE)
 rhuber(n, k = 0.862, mu = 0, sigma = 1)
 qhuber(p, k = 0.862, mu = 0, sigma = 1, lower.tail = TRUE,
        log.p = FALSE)
 phuber(q, k = 0.862, mu = 0, sigma = 1, lower.tail = TRUE,
        log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dhuber_+3A_x">x</code>, <code id="dhuber_+3A_q">q</code></td>
<td>
<p>numeric vector, vector of quantiles.</p>
</td></tr>
<tr><td><code id="dhuber_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="dhuber_+3A_n">n</code></td>
<td>
<p>number of random values to be generated.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required. </p>
</td></tr>
<tr><td><code id="dhuber_+3A_k">k</code></td>
<td>
<p>numeric. Borderline value of central Gaussian part
of the distribution.
This is known as the tuning constant, and should be positive.
For example, <code>k = 0.862</code> refers to a 20% contamination
neighborhood of the Gaussian distribution.
If <code>k = 1.40</code> then this is 5% contamination.
</p>
</td></tr>
<tr><td><code id="dhuber_+3A_mu">mu</code></td>
<td>
<p>numeric. distribution mean.</p>
</td></tr>
<tr><td><code id="dhuber_+3A_sigma">sigma</code></td>
<td>
<p>numeric. Distribution scale (<code>sigma = 1</code>
defines the
distribution in standard form, with standard Gaussian centre).</p>
</td></tr>
<tr><td><code id="dhuber_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the result is returned.
</p>
</td></tr>
<tr><td><code id="dhuber_+3A_lower.tail">lower.tail</code>, <code id="dhuber_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details are given in <code><a href="#topic+huber2">huber2</a></code>, the
<span class="pkg">VGAM</span> family function for estimating the
parameters <code>mu</code> and <code>sigma</code>.
</p>


<h3>Value</h3>

<p><code>dhuber</code> gives out a vector of density values.
</p>
<p><code>edhuber</code> gives out a list with components <code>val</code>
(density values) and <code>eps</code> (contamination proportion).
</p>
<p><code>rhuber</code> gives out a vector of random numbers generated
by Huber's least favourable distribution.
</p>
<p><code>phuber</code> gives the distribution function,
<code>qhuber</code> gives the quantile function.
</p>


<h3>Author(s)</h3>

<p>Christian Hennig wrote <code>[d,ed,r]huber()</code>
(from <span class="pkg">smoothmest</span>) and
slight modifications were made by T. W. Yee to
replace looping by vectorization and addition of the <code>log</code>
argument.
Arash Ardalan wrote <code>[pq]huber()</code>, and
two arguments for these were implemented by Kai Huang.
This helpfile was adapted from <span class="pkg">smoothmest</span>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+huber2">huber2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123456)
edhuber(1:5, k = 1.5)
rhuber(5)

## Not run:  mu &lt;- 3; xx &lt;- seq(-2, 7, len = 100)  # Plot CDF and PDF
plot(xx, dhuber(xx, mu = mu), type = "l", col = "blue", las = 1,
     main = "blue is density, orange is the CDF", ylab = "",
     sub = "Purple lines are the 10,20,...,90 percentiles",
     ylim = 0:1)
abline(h = 0, col = "blue", lty = 2)
lines(xx, phuber(xx, mu = mu), type = "l", col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qhuber(probs, mu = mu)
lines(Q, dhuber(Q, mu = mu), col = "purple", lty = 3, type = "h")
lines(Q, phuber(Q, mu = mu), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
phuber(Q, mu = mu) - probs  # Should be all 0s

## End(Not run)
</code></pre>

<hr>
<h2 id='diffzeta'> Differenced Zeta Distribution Family Function </h2><span id='topic+diffzeta'></span>

<h3>Description</h3>

<p>Estimates the parameter of the differenced zeta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diffzeta(start = 1, lshape = "loglink", ishape = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diffzeta_+3A_lshape">lshape</code>, <code id="diffzeta_+3A_ishape">ishape</code></td>
<td>

<p>Same as <code><a href="#topic+zetaff">zetaff</a></code>.
</p>
</td></tr>
<tr><td><code id="diffzeta_+3A_start">start</code></td>
<td>

<p>Smallest value of the support of the distribution.
Must be a positive integer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PMF is
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) = (a/y)^{s} -
      (a/(1+y))^{s},\ \ s&gt;0,\ \ y=a,a+1,\ldots,</code>
</p>

<p>where <code class="reqn">s</code> is the positive shape parameter, and <code class="reqn">a</code>
is <code>start</code>.
According to   Moreno-Sanchez et al. (2016), this model
fits quite well to about 40 percent of all the English books
in the Project Gutenberg data base (about 30,000 texts).
Multiple responses are handled.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Moreno-Sanchez, I., Font-Clos, F. and Corral, A. (2016).
Large-Scale Analysis of Zipf's Law in English Texts,
<em>PLoS ONE</em>, <b>11</b>(1), 1&ndash;19.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Diffzeta">Diffzeta</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="#topic+zeta">zeta</a></code>,
<code><a href="#topic+zipf">zipf</a></code>,
<code><a href="#topic+zipf">zipf</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>odata &lt;- data.frame(x2 = runif(nn &lt;- 1000))  # Artificial data
odata &lt;- transform(odata, shape = loglink(-0.25 + x2, inv = TRUE))
odata &lt;- transform(odata, y1 = rdiffzeta(nn, shape))
with(odata, table(y1))
ofit &lt;- vglm(y1 ~ x2, diffzeta, odata, trace = TRUE)
coef(ofit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='Diffzeta'> Differenced Zeta Distribution </h2><span id='topic+Diffzeta'></span><span id='topic+ddiffzeta'></span><span id='topic+pdiffzeta'></span><span id='topic+qdiffzeta'></span><span id='topic+rdiffzeta'></span>

<h3>Description</h3>

<p>Density, distribution function,
quantile function,
and random generation
for the differenced zeta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddiffzeta(x, shape, start = 1, log = FALSE)
pdiffzeta(q, shape, start = 1, lower.tail = TRUE)
qdiffzeta(p, shape, start = 1)
rdiffzeta(n, shape, start = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Diffzeta_+3A_x">x</code>, <code id="Diffzeta_+3A_q">q</code>, <code id="Diffzeta_+3A_p">p</code>, <code id="Diffzeta_+3A_n">n</code></td>
<td>

<p>Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Diffzeta_+3A_shape">shape</code>, <code id="Diffzeta_+3A_start">start</code></td>
<td>

<p>Details at <code><a href="#topic+diffzeta">diffzeta</a></code>.
</p>

</td></tr>
<tr><td><code id="Diffzeta_+3A_log">log</code>, <code id="Diffzeta_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distribution appears to work well on the distribution
of English words in such texts.
Some more details are given in <code><a href="#topic+diffzeta">diffzeta</a></code>.
</p>


<h3>Value</h3>

<p><code>ddiffzeta</code> gives the density,
<code>pdiffzeta</code> gives the distribution function,
<code>qdiffzeta</code> gives the quantile function, and
<code>rdiffzeta</code> generates random deviates.
</p>


<h3>Note</h3>

<p>Given some response data, the <span class="pkg">VGAM</span> family function
<code><a href="#topic+diffzeta">diffzeta</a></code> estimates the parameter <code>shape</code>.
</p>
<p>Function <code>pdiffzeta()</code> suffers from the problems that
<code><a href="#topic+plog">plog</a></code> sometimes has, i.e., when <code>p</code>
is very close to 1.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+diffzeta">diffzeta</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="#topic+zipf">zipf</a></code>,
<code><a href="VGAMdata.html#topic+Oizeta">Oizeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ddiffzeta(1:20, 0.5, start = 2)
rdiffzeta(20, 0.5)

## Not run:  shape &lt;- 0.8; x &lt;- 1:10
plot(x, ddiffzeta(x, sh = shape), type = "h", ylim = 0:1, las = 1,
     sub = "shape=0.8", col = "blue", ylab = "Probability",
     main = "Differenced zeta distribution: blue=PMF; orange=CDF")
lines(x + 0.1, pdiffzeta(x, shape = shape), col = "orange",
      lty = 3, type = "h") 
## End(Not run)
</code></pre>

<hr>
<h2 id='dirichlet'> Fitting a Dirichlet Distribution </h2><span id='topic+dirichlet'></span>

<h3>Description</h3>

<p>Fits a Dirichlet distribution to a matrix of compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirichlet(link = "loglink", parallel = FALSE, zero = NULL,
          imethod = 1)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dirichlet_+3A_link">link</code></td>
<td>

<p>Link function applied to each of the <code class="reqn">M</code> (positive) shape
parameters <code class="reqn">\alpha_j</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The default gives
<code class="reqn">\eta_j=\log(\alpha_j)</code>.
</p>
</td></tr>
<tr><td><code id="dirichlet_+3A_parallel">parallel</code>, <code id="dirichlet_+3A_zero">zero</code>, <code id="dirichlet_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file the response is assumed to be a <code class="reqn">M</code>-column
matrix with positive values and whose rows each sum to unity.
Such data can be thought of as compositional data.  There are
<code class="reqn">M</code> linear/additive predictors <code class="reqn">\eta_j</code>.
</p>
<p>The Dirichlet distribution is commonly used to model compositional
data, including applications in genetics.
Suppose <code class="reqn">(Y_1,\ldots,Y_{M})^T</code> is
the response. Then it has a Dirichlet distribution if
<code class="reqn">(Y_1,\ldots,Y_{M-1})^T</code> has density
</p>
<p style="text-align: center;"><code class="reqn">\frac{\Gamma(\alpha_{+})}
           {\prod_{j=1}^{M} \Gamma(\alpha_{j})}
           \prod_{j=1}^{M} y_j^{\alpha_{j} -1}</code>
</p>

<p>where
<code class="reqn">\alpha_+=\alpha_1+\cdots+
     \alpha_M</code>,
<code class="reqn">\alpha_j &gt; 0</code>,
and the density is defined on the unit simplex
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{M} = \left\{
  (y_1,\ldots,y_{M})^T :
  y_1 &gt; 0, \ldots, y_{M} &gt; 0,
  \sum_{j=1}^{M} y_j = 1 \right\}. </code>
</p>

<p>One has
<code class="reqn">E(Y_j) = \alpha_j / \alpha_{+}</code>,
which are returned as the fitted values.
For this distribution Fisher scoring corresponds to Newton-Raphson.
</p>
<p>The Dirichlet distribution can be motivated by considering
the random variables
<code class="reqn">(G_1,\ldots,G_{M})^T</code> which are
each independent
and identically distributed as a gamma distribution with density
<code class="reqn">f(g_j)=g_j^{\alpha_j - 1} e^{-g_j} / \Gamma(\alpha_j)</code>.
Then the Dirichlet distribution arises when
<code class="reqn">Y_j=G_j / (G_1 + \cdots + G_M)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>When fitted, the <code>fitted.values</code> slot of the object
contains the <code class="reqn">M</code>-column matrix of means.
</p>


<h3>Note</h3>

<p>The response should be a matrix of positive values whose rows
each sum to unity. Similar to this is count data, where probably
a multinomial logit model (<code><a href="#topic+multinomial">multinomial</a></code>) may be
appropriate.  Another similar distribution to the Dirichlet
is the Dirichlet-multinomial (see <code><a href="#topic+dirmultinomial">dirmultinomial</a></code>).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Lange, K. (2002).
<em>Mathematical and Statistical Methods for Genetic Analysis</em>,
2nd ed. New York: Springer-Verlag.
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+rdiric">rdiric</a></code>,
<code><a href="#topic+dirmultinomial">dirmultinomial</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+simplex">simplex</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ddata &lt;- data.frame(rdiric(1000,
                    shape = exp(c(y1 = -1, y2 = 1, y3 = 0))))
fit &lt;- vglm(cbind(y1, y2, y3)  ~ 1, dirichlet,
            data = ddata, trace = TRUE, crit = "coef")
Coef(fit)
coef(fit, matrix = TRUE)
head(fitted(fit))
</code></pre>

<hr>
<h2 id='dirmul.old'>Fitting a Dirichlet-Multinomial Distribution </h2><span id='topic+dirmul.old'></span>

<h3>Description</h3>

<p>Fits a Dirichlet-multinomial distribution to a matrix of
non-negative integers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirmul.old(link = "loglink", ialpha = 0.01, parallel = FALSE,
           zero = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dirmul.old_+3A_link">link</code></td>
<td>

<p>Link function applied to each of the <code class="reqn">M</code> (positive)
shape parameters <code class="reqn">\alpha_j</code> for <code class="reqn">j=1,\ldots,M</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
Here, <code class="reqn">M</code> is the number of columns of the response matrix.
</p>
</td></tr>
<tr><td><code id="dirmul.old_+3A_ialpha">ialpha</code></td>
<td>

<p>Numeric vector. Initial values for the
<code>alpha</code> vector. Must be positive.
Recycled to length <code class="reqn">M</code>.
</p>
</td></tr>
<tr><td><code id="dirmul.old_+3A_parallel">parallel</code></td>
<td>

<p>A logical, or formula specifying which terms have equal/unequal
coefficients.
</p>
</td></tr>
<tr><td><code id="dirmul.old_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which linear/additive
predictors are modelled as intercepts only.  The values must
be from the set {1,2,...,<code class="reqn">M</code>}.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Dirichlet-multinomial distribution, which is somewhat
similar to a Dirichlet distribution, has probability function
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1=y_1,\ldots,Y_M=y_M) =
 {2y_{*} \choose {y_1,\ldots,y_M}}
    \frac{\Gamma(\alpha_{+})}{\Gamma(2y_{*}+\alpha_{+})}
\prod_{j=1}^M \frac{\Gamma(y_j+\alpha_{j})}{\Gamma(\alpha_{j})}</code>
</p>

<p>for <code class="reqn">\alpha_j &gt; 0</code>,
<code class="reqn">\alpha_+ = \alpha_1 +
     \cdots + \alpha_M</code>,
and <code class="reqn">2y_{*} = y_1 + \cdots + y_M</code>.
Here, <code class="reqn">a \choose b</code> means &ldquo;<code class="reqn">a</code> choose
<code class="reqn">b</code>&rdquo; and
refers to combinations (see <code><a href="base.html#topic+choose">choose</a></code>).
The (posterior) mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y_j) = (y_j + \alpha_j) / (2y_{*} + \alpha_{+})</code>
</p>

<p>for <code class="reqn">j=1,\ldots,M</code>, and these are returned
as the fitted values as a <code class="reqn">M</code>-column matrix.
</p>






<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response should be a matrix of non-negative values.
Convergence seems to slow down if there are zero values.
Currently, initial values can be improved upon.
</p>
<p>This function is almost defunct and may be withdrawn soon.
Use <code><a href="#topic+dirmultinomial">dirmultinomial</a></code> instead.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Lange, K. (2002).
<em>Mathematical and Statistical Methods for Genetic Analysis</em>,
2nd ed.  New York: Springer-Verlag.
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>
<p>Paul, S. R., Balasooriya, U. and Banerjee, T. (2005).
Fisher information matrix of the Dirichlet-multinomial
distribution.
<em>Biometrical Journal</em>, <b>47</b>, 230&ndash;236.
</p>
<p>Tvedebrink, T. (2010).
Overdispersion in allelic counts and <code class="reqn">\theta</code>-correction
in forensic genetics.
<em>Theoretical Population Biology</em>,
<b>78</b>, 200&ndash;210.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+dirmultinomial">dirmultinomial</a></code>,
<code><a href="#topic+dirichlet">dirichlet</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data from p.50 of Lange (2002)
alleleCounts &lt;- c(2, 84, 59, 41, 53, 131, 2, 0,
       0, 50, 137, 78, 54, 51, 0, 0,
       0, 80, 128, 26, 55, 95, 0, 0,
       0, 16, 40, 8, 68, 14, 7, 1)
dim(alleleCounts) &lt;- c(8, 4)
alleleCounts &lt;- data.frame(t(alleleCounts))
dimnames(alleleCounts) &lt;- list(c("White","Black","Chicano","Asian"),
                    paste("Allele", 5:12, sep = ""))

set.seed(123)  # @initialize uses random numbers
fit &lt;- vglm(cbind(Allele5,Allele6,Allele7,Allele8,Allele9,
                  Allele10,Allele11,Allele12) ~ 1, dirmul.old,
             trace = TRUE, crit = "c", data = alleleCounts)

(sfit &lt;- summary(fit))
vcov(sfit)
round(eta2theta(coef(fit),
                fit@misc$link,
                fit@misc$earg), digits = 2)  # not preferred
round(Coef(fit), digits = 2)  # preferred
round(t(fitted(fit)), digits = 4)  # 2nd row of Lange (2002, Table 3.5)
coef(fit, matrix = TRUE)


pfit &lt;- vglm(cbind(Allele5,Allele6,Allele7,Allele8,Allele9,
                   Allele10,Allele11,Allele12) ~ 1,
             dirmul.old(parallel = TRUE), trace = TRUE,
             data = alleleCounts)
round(eta2theta(coef(pfit, matrix = TRUE), pfit@misc$link,
                pfit@misc$earg), digits = 2)  # 'Right' answer
round(Coef(pfit), digits = 2)  # 'Wrong' due to parallelism constraint
</code></pre>

<hr>
<h2 id='dirmultinomial'>Fitting a Dirichlet-Multinomial Distribution </h2><span id='topic+dirmultinomial'></span>

<h3>Description</h3>

<p>Fits a Dirichlet-multinomial distribution to a matrix response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirmultinomial(lphi = "logitlink", iphi = 0.10, parallel = FALSE,
               zero = "M")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dirmultinomial_+3A_lphi">lphi</code></td>
<td>

<p>Link function applied to the <code class="reqn">\phi</code>
parameter, which lies in the open unit interval <code class="reqn">(0,1)</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="dirmultinomial_+3A_iphi">iphi</code></td>
<td>

<p>Numeric. Initial value for <code class="reqn">\phi</code>.
Must be in the open unit interval <code class="reqn">(0,1)</code>.
If a failure to converge occurs then try assigning this argument
a different value.
</p>
</td></tr>
<tr><td><code id="dirmultinomial_+3A_parallel">parallel</code></td>
<td>

<p>A logical (formula not allowed here) indicating whether the
probabilities <code class="reqn">\pi_1,\ldots,\pi_{M-1}</code>
are to be equal via equal coefficients.
Note <code class="reqn">\pi_M</code> will generally be different from the
other probabilities.
Setting <code>parallel = TRUE</code> will only work if you also set
<code>zero = NULL</code> because of interference between these
arguments (with respect to the intercept term).
</p>
</td></tr>
<tr><td><code id="dirmultinomial_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The values must be from the set <code class="reqn">\{1,2,\ldots,M\}</code>.
If the character <code>"M"</code> then this means the numerical
value <code class="reqn">M</code>, which corresponds to linear/additive predictor
associated with <code class="reqn">\phi</code>.  Setting <code>zero = NULL</code>
means none of the values from the set <code class="reqn">\{1,2,\ldots,M\}</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Dirichlet-multinomial distribution
arises from a multinomial distribution where
the probability parameters are not constant but are generated
from a
multivariate distribution called the Dirichlet distribution.
The Dirichlet-multinomial distribution has probability function
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1=y_1,\ldots,Y_M=y_M) =
     {N_{*} \choose {y_1,\ldots,y_M}}
        \frac{
        \prod_{j=1}^{M}
        \prod_{r=1}^{y_{j}}
        (\pi_j (1-\phi) + (r-1)\phi)}{
        \prod_{r=1}^{N_{*}}
        (1-\phi + (r-1)\phi)}</code>
</p>

<p>where <code class="reqn">\phi</code> is the <em>over-dispersion</em> parameter
and <code class="reqn">N_{*} = y_1+\cdots+y_M</code>.  Here,
<code class="reqn">a \choose b</code> means &ldquo;<code class="reqn">a</code> choose <code class="reqn">b</code>&rdquo;
and refers to combinations (see <code><a href="base.html#topic+choose">choose</a></code>).
The above formula applies to each row of the matrix response.
In this <span class="pkg">VGAM</span> family function the first <code class="reqn">M-1</code>
linear/additive predictors correspond to the first <code class="reqn">M-1</code>
probabilities via
</p>
<p style="text-align: center;"><code class="reqn">\eta_j = \log(P[Y=j]/ P[Y=M]) = \log(\pi_j/\pi_M)</code>
</p>

<p>where <code class="reqn">\eta_j</code> is the <code class="reqn">j</code>th linear/additive
predictor (<code class="reqn">\eta_M=0</code> by definition for
<code class="reqn">P[Y=M]</code> but not for <code class="reqn">\phi</code>)
and
<code class="reqn">j=1,\ldots,M-1</code>.
The <code class="reqn">M</code>th linear/additive predictor corresponds to
<code>lphi</code> applied to <code class="reqn">\phi</code>.
</p>
<p>Note that <code class="reqn">E(Y_j) = N_* \pi_j</code> but
the probabilities (returned as the fitted values)
<code class="reqn">\pi_j</code> are bundled together as a <code class="reqn">M</code>-column
matrix.  The quantities <code class="reqn">N_*</code> are returned as the prior
weights.
</p>
<p>The beta-binomial distribution is a special case of
the Dirichlet-multinomial distribution when <code class="reqn">M=2</code>;
see <code><a href="#topic+betabinomial">betabinomial</a></code>.  It is easy to show that
the first shape parameter of the beta distribution is
<code class="reqn">shape1=\pi(1/\phi-1)</code>
and the second shape parameter is
<code class="reqn">shape2=(1-\pi)(1/\phi-1)</code>.  Also,
<code class="reqn">\phi=1/(1+shape1+shape2)</code>, which
is known as the <em>intra-cluster correlation</em> coefficient.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, <code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>If the model is an intercept-only model then <code>@misc</code> (which is a
list) has a component called <code>shape</code> which is a vector with the
<code class="reqn">M</code> values <code class="reqn">\pi_j(1/\phi-1)</code>.
</p>




<h3>Warning </h3>

<p>This <span class="pkg">VGAM</span> family function is prone to numerical problems,
especially when there are covariates.
</p>


<h3>Note</h3>

<p>The response can be a matrix of non-negative integers, or
else a matrix of sample proportions and the total number of
counts in each row specified using the <code>weights</code> argument.
This dual input option is similar to <code><a href="#topic+multinomial">multinomial</a></code>.
</p>
<p>To fit a &lsquo;parallel&rsquo; model with the <code class="reqn">\phi</code>
parameter being an intercept-only you will need to use the
<code>constraints</code> argument.
</p>
<p>Currently, Fisher scoring is implemented. To compute the
expected information matrix a <code>for</code> loop is used; this
may be very slow when the counts are large.  Additionally,
convergence may be slower than usual due to round-off error
when computing the expected information matrices.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Paul, S. R., Balasooriya, U. and Banerjee, T. (2005).
Fisher information matrix of the Dirichlet-multinomial
distribution.
<em>Biometrical Journal</em>, <b>47</b>, 230&ndash;236.
</p>
<p>Tvedebrink, T. (2010).
Overdispersion in allelic counts and <code class="reqn">\theta</code>-correction in
forensic genetics.
<em>Theoretical Population Biology</em>, <b>78</b>, 200&ndash;210.
</p>
<p>Yu, P. and Shaw, C. A. (2014).
An Efficient Algorithm for Accurate Computation of
the Dirichlet-Multinomial Log-Likelihood Function.
<em>Bioinformatics</em>,
<b>30</b>, 1547&ndash;54.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+dirmul.old">dirmul.old</a></code>,
<code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+dirichlet">dirichlet</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 5; M &lt;- 4; set.seed(1)
ydata &lt;- data.frame(round(matrix(runif(nn * M, max = 100), nn, M)))
colnames(ydata) &lt;- paste("y", 1:M, sep = "")  # Integer counts

fit &lt;- vglm(cbind(y1, y2, y3, y4) ~ 1, dirmultinomial,
            data = ydata, trace = TRUE)
head(fitted(fit))
depvar(fit)  # Sample proportions
weights(fit, type = "prior", matrix = FALSE)  # Total counts per row

## Not run: 
ydata &lt;- transform(ydata, x2 = runif(nn))
fit &lt;- vglm(cbind(y1, y2, y3, y4) ~ x2, dirmultinomial,
            data = ydata, trace = TRUE)
Coef(fit)
coef(fit, matrix = TRUE)
(sfit &lt;- summary(fit))
vcov(sfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='dlogF'> log F Distribution </h2><span id='topic+dlogF'></span>

<h3>Description</h3>

<p>Density
for the log F distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dlogF(x, shape1, shape2, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dlogF_+3A_x">x</code></td>
<td>

<p>Vector of quantiles.
</p>
</td></tr>
<tr><td><code id="dlogF_+3A_shape1">shape1</code>, <code id="dlogF_+3A_shape2">shape2</code></td>
<td>
<p>Positive shape parameters.
</p>
</td></tr>


<tr><td><code id="dlogF_+3A_log">log</code></td>
<td>

<p>if <code>TRUE</code> then the log density is returned,
else the density.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details are given in <code><a href="#topic+logF">logF</a></code>.
</p>


<h3>Value</h3>

<p><code>dlogF</code> gives the density.
</p>





<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+hypersecant">hypersecant</a></code>,
<code><a href="#topic+dextlogF">dextlogF</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  shape1 &lt;- 1.5; shape2 &lt;- 0.5; x &lt;- seq(-5, 8, length = 1001)
plot(x, dlogF(x, shape1, shape2), type = "l",
     las = 1, col = "blue", ylab = "pdf",
     main = "log F density function")

## End(Not run)
</code></pre>

<hr>
<h2 id='double.cens.normal'> Univariate Normal Distribution with Double Censoring </h2><span id='topic+double.cens.normal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the two parameters of a
univariate normal distribution when there is double censoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>double.cens.normal(r1 = 0, r2 = 0, lmu = "identitylink", lsd =
       "loglink", imu = NULL, isd = NULL, zero = "sd")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="double.cens.normal_+3A_r1">r1</code>, <code id="double.cens.normal_+3A_r2">r2</code></td>
<td>

<p>Integers. Number of smallest and largest values censored,
respectively.
</p>
</td></tr>
<tr><td><code id="double.cens.normal_+3A_lmu">lmu</code>, <code id="double.cens.normal_+3A_lsd">lsd</code></td>
<td>

<p>Parameter link functions applied to the
mean and standard deviation.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="double.cens.normal_+3A_imu">imu</code>, <code id="double.cens.normal_+3A_isd">isd</code>, <code id="double.cens.normal_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This family function uses the Fisher information matrix given
in Harter and Moore (1966). The matrix is not diagonal if
either <code>r1</code> or <code>r2</code> are positive.
</p>
<p>By default, the mean is the first linear/additive predictor and
the log of the standard deviation is the second linear/additive
predictor.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This family function only handles a vector or one-column matrix
response. The <code>weights</code> argument, if used, are interpreted
as frequencies, therefore it must be a vector with positive
integer values.
</p>
<p>With no censoring at all (the default), it is better (and
equivalent) to use <code><a href="#topic+uninormal">uninormal</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Harter, H. L. and Moore, A. H. (1966).
Iterative maximum-likelihood estimation of the parameters of
normal populations from singly and doubly censored samples.
<em>Biometrika</em>, <b>53</b>, 205&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+cens.normal">cens.normal</a></code>,
<code><a href="#topic+tobit">tobit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Repeat the simulations of Harter &amp; Moore (1966)
SIMS &lt;- 100  # Number of simulations (change this to 1000)
mu.save &lt;- sd.save &lt;- rep(NA, len = SIMS)
r1 &lt;- 0; r2 &lt;- 4; nn &lt;- 20
for (sim in 1:SIMS) {
  y &lt;- sort(rnorm(nn))
  y &lt;- y[(1+r1):(nn-r2)]  # Delete r1 smallest and r2 largest
  fit &lt;- vglm(y ~ 1, double.cens.normal(r1 = r1, r2 = r2))
  mu.save[sim] &lt;- predict(fit)[1, 1]
  sd.save[sim] &lt;- exp(predict(fit)[1, 2])  # Assumes a log link &amp; ~ 1
}
c(mean(mu.save), mean(sd.save))  # Should be c(0,1)
c(sd(mu.save), sd(sd.save))

## End(Not run)

# Data from Sarhan &amp; Greenberg (1962); MLEs are mu=9.2606, sd=1.3754
strontium90 &lt;- data.frame(y = c(8.2, 8.4, 9.1, 9.8, 9.9))
fit &lt;- vglm(y ~ 1, double.cens.normal(r1 = 2, r2 = 3, isd = 6),
            data = strontium90, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='double.expbinomial'> Double Exponential Binomial Distribution Family Function </h2><span id='topic+double.expbinomial'></span>

<h3>Description</h3>

<p>Fits a double exponential binomial distribution by
maximum likelihood estimation.
The two parameters here are the mean and dispersion parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>double.expbinomial(lmean = "logitlink", ldispersion = "logitlink",
                   idispersion = 0.25, zero = "dispersion")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="double.expbinomial_+3A_lmean">lmean</code>, <code id="double.expbinomial_+3A_ldispersion">ldispersion</code></td>
<td>

<p>Link functions applied to the two parameters, called
<code class="reqn">\mu</code> and <code class="reqn">\theta</code> respectively below.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The defaults cause the parameters to be restricted to
<code class="reqn">(0,1)</code>.
</p>
</td></tr>
<tr><td><code id="double.expbinomial_+3A_idispersion">idispersion</code></td>
<td>

<p>Initial value for the dispersion parameter.
If given, it must be in range, and is recyled to the necessary
length.  Use this argument if convergence failure occurs.
</p>
</td></tr>
<tr><td><code id="double.expbinomial_+3A_zero">zero</code></td>
<td>

<p>A vector specifying which
linear/additive predictor is to be modelled as intercept-only.
If assigned, the single value can be either <code>1</code> or <code>2</code>.
The default is to have a single dispersion parameter value.
To model both parameters as functions of the covariates assign
<code>zero = NULL</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distribution provides a way for handling overdispersion in
a binary response.  The double exponential binomial distribution
belongs the family of double exponential distributions proposed
by Efron (1986).  Below, equation numbers refer to that original
article.  Briefly, the idea is that an ordinary one-parameter
exponential family allows the addition of a second parameter
<code class="reqn">\theta</code> which varies the dispersion of the family
without changing the mean.  The extended family behaves like
the original family with sample size changed from <code class="reqn">n</code>
to <code class="reqn">n\theta</code>.
The extended family is an exponential family in <code class="reqn">\mu</code>
when <code class="reqn">n</code> and <code class="reqn">\theta</code> are fixed, and an
exponential family in <code class="reqn">\theta</code> when <code class="reqn">n</code> and
<code class="reqn">\mu</code> are fixed.  Having <code class="reqn">0 &lt; \theta &lt; 1</code> corresponds to overdispersion with respect to the
binomial distribution.  See Efron (1986) for full details.
</p>
<p>This <span class="pkg">VGAM</span> family function implements an
<em>approximation</em> (2.10) to the exact density (2.4). It
replaces the normalizing constant by unity since the
true value nearly equals 1.  The default model fitted is
<code class="reqn">\eta_1 = logit(\mu)</code> and <code class="reqn">\eta_2
  = logit(\theta)</code>.  This restricts
both parameters to lie between 0 and 1, although the
dispersion parameter can be modelled over a larger parameter
space by assigning the arguments <code>ldispersion</code> and
<code>edispersion</code>.
</p>
<p>Approximately, the mean (of <code class="reqn">Y</code>) is <code class="reqn">\mu</code>.
The <em>effective sample size</em> is the dispersion
parameter multiplied by the original sample size, i.e.,
<code class="reqn">n\theta</code>.  This family function uses Fisher
scoring, and the two estimates are asymptotically independent
because the expected information matrix is diagonal.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Warning </h3>

<p>Numerical difficulties can occur; if so, try using
<code>idispersion</code>.
</p>


<h3>Note</h3>

<p>This function processes the input in the same way
as <code><a href="#topic+binomialff">binomialff</a></code>, however multiple responses are
not allowed (<code>binomialff(multiple.responses = FALSE)</code>).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Efron, B. (1986).
Double exponential families and their use in generalized
linear regression.
<em>Journal of the American Statistical Association</em>,
<b>81</b>, 709&ndash;721.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+toxop">toxop</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This example mimics the example in Efron (1986).
# The results here differ slightly.

# Scale the variables
toxop &lt;- transform(toxop,
                   phat = positive / ssize,
                   srainfall = scale(rainfall),  # (6.1)
                   sN = scale(ssize))            # (6.2)

# A fit similar (should be identical) to Sec.6 of Efron (1986).
# But does not use poly(), and M = 1.25 here, as in (5.3)
cmlist &lt;- list("(Intercept)"    = diag(2),
               "I(srainfall)"   = rbind(1, 0),
               "I(srainfall^2)" = rbind(1, 0),
               "I(srainfall^3)" = rbind(1, 0),
               "I(sN)" = rbind(0, 1),
               "I(sN^2)" = rbind(0, 1))
fit &lt;-
  vglm(cbind(phat, 1 - phat) * ssize ~
       I(srainfall) + I(srainfall^2) + I(srainfall^3) +
       I(sN) + I(sN^2),
       double.expbinomial(ldisp = extlogitlink(min = 0, max = 1.25),
                          idisp = 0.2, zero = NULL),
       toxop, trace = TRUE, constraints = cmlist)

# Now look at the results
coef(fit, matrix = TRUE)
head(fitted(fit))
summary(fit)
vcov(fit)
sqrt(diag(vcov(fit)))  # Standard errors

# Effective sample size (not quite the last column of Table 1)
head(predict(fit))
Dispersion &lt;- extlogitlink(predict(fit)[,2], min = 0, max = 1.25,
                           inverse = TRUE)
c(round(weights(fit, type = "prior") * Dispersion, digits = 1))


# Ordinary logistic regression (gives same results as (6.5))
ofit &lt;- vglm(cbind(phat, 1 - phat) * ssize ~
             I(srainfall) + I(srainfall^2) + I(srainfall^3),
             binomialff, toxop, trace = TRUE)


# Same as fit but it uses poly(), and can be plotted (cf. Fig.1)
cmlist2 &lt;- list("(Intercept)"                 = diag(2),
                "poly(srainfall, degree = 3)" = rbind(1, 0),
                "poly(sN, degree = 2)"        = rbind(0, 1))
fit2 &lt;-
  vglm(cbind(phat, 1 - phat) * ssize ~
       poly(srainfall, degree = 3) + poly(sN, degree = 2),
       double.expbinomial(ldisp = extlogitlink(min = 0, max = 1.25),
                          idisp = 0.2, zero = NULL),
       toxop, trace = TRUE, constraints = cmlist2)
## Not run:  par(mfrow = c(1, 2))  # Cf. Fig.1
plot(as(fit2, "vgam"), se = TRUE, lcol = "blue", scol = "orange")

# Cf. Figure 1(a)
par(mfrow = c(1,2))
ooo &lt;- with(toxop, sort.list(rainfall))
with(toxop, plot(rainfall[ooo], fitted(fit2)[ooo], type = "l",
                 col = "blue", las = 1, ylim = c(0.3, 0.65)))
with(toxop, points(rainfall[ooo], fitted(ofit)[ooo],
                   col = "orange", type = "b", pch = 19))

# Cf. Figure 1(b)
ooo &lt;- with(toxop, sort.list(ssize))
with(toxop, plot(ssize[ooo], Dispersion[ooo], type = "l",
                 col = "blue", las = 1, xlim = c(0, 100))) 
## End(Not run)
</code></pre>

<hr>
<h2 id='ducklings'>
Relative Frequencies of Serum Proteins in White Pekin Ducklings 

</h2><span id='topic+ducklings'></span>

<h3>Description</h3>

<p>Relative frequencies of serum proteins in white Pekin ducklings 
as determined by electrophoresis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ducklings)</code></pre>


<h3>Format</h3>

<p>The format is:
chr &quot;ducklings&quot;
</p>


<h3>Details</h3>

<p>Columns <code>p1</code>, <code>p2</code>, <code>p3</code>
stand for pre-albumin, albumin, globulins respectively.
These were collected from 3-week old white Pekin ducklings.
Let <code class="reqn">Y_1</code> be proportional to the total milligrams of
pre-albumin in the blood serum of a duckling.
Similarly,
let <code class="reqn">Y_2</code> and <code class="reqn">Y_3</code> be directly proportional
to the same factor as <code class="reqn">Y_1</code> to the total milligrams 
respectively of albumin and globulins in its blood serum.
The proportion of pre-albumin is given by
<code class="reqn">Y_1/(Y_1 + Y_2 + Y_3)</code>,
and similarly for the others.
</p>




<h3>Source</h3>

<p>Mosimann, J. E.  (1962)
On the compound multinomial distribution,
the multivariate <code class="reqn">\beta</code>-distribution,
and correlations among proportions,
Biometrika,
<b>49</b>, 65&ndash;82.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dirichlet">dirichlet</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(ducklings)
</code></pre>

<hr>
<h2 id='eCDF'>Empirical Cumulative Distribution Function</h2><span id='topic+eCDF'></span><span id='topic+eCDF.vglm'></span>

<h3>Description</h3>

<p>Returns the desired quantiles of quantile regression object such
as an extlogF1() or lms.bcn() VGLM object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eCDF.vglm(object, all = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eCDF_+3A_object">object</code></td>
<td>

<p>an object such as
a <code><a href="#topic+vglm">vglm</a></code> object with
family function <code><a href="#topic+extlogF1">extlogF1</a></code> or
<code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="eCDF_+3A_all">all</code></td>
<td>

<p>Logical. Return all other information?
If true, the empirical CDF is returned.
</p>
</td></tr>
<tr><td><code id="eCDF_+3A_...">...</code></td>
<td>

<p>additional optional arguments.
Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was specifically written for
a <code><a href="#topic+vglm">vglm</a></code> object
with family function <code><a href="#topic+extlogF1">extlogF1</a></code>
or <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
It returns the proportion of data lying below each of
the fitted quantiles, and optionally
the desired quantiles (arguments <code>tau</code> or
<code>percentiles / 100</code> in the family function).
The output is coerced to be comparable between
family functions by calling the columns by
the same names.
</p>


<h3>Value</h3>

<p>A vector with each value lying in (0, 1).
If <code>all = TRUE</code> then a 2-column matrix with the
second column being the <code>tau</code> values or equivalent.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- vglm(BMI ~ ns(age, 4), extlogF1, data = bmi.nz)  # trace = TRUE
eCDF(fit1)
eCDF(fit1, all = TRUE)
</code></pre>

<hr>
<h2 id='enzyme'> Enzyme Data</h2><span id='topic+enzyme'></span>

<h3>Description</h3>

<p>Enzyme velocity and substrate concentration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(enzyme)</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on the following 2 variables.
</p>

<dl>
<dt>conc</dt><dd><p>a numeric explanatory vector; substrate concentration</p>
</dd>
<dt>velocity</dt><dd><p>a numeric response vector; enzyme velocity</p>
</dd>
</dl>



<h3>Details</h3>

<p>Sorry, more details need to be included later.
</p>


<h3>Source</h3>

<p>Sorry, more details need to be included later.
</p>


<h3>References</h3>

<p>Watts, D. G. (1981).
An introduction to nonlinear least squares.
In: L. Endrenyi (Ed.),
<em>Kinetic Data Analysis: Design and Analysis of Enzyme and
Pharmacokinetic Experiments</em>, pp.1&ndash;24.
New York: Plenum Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+micmen">micmen</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fit &lt;- vglm(velocity ~ 1, micmen, data = enzyme, trace = TRUE,
            form2 = ~ conc - 1, crit = "crit")
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='erf'> Error Function, and variants </h2><span id='topic+erf'></span><span id='topic+erfc'></span>

<h3>Description</h3>

<p>Computes the error function, or its inverse,
based on the normal distribution.
Also computes the complement of the error function, or its inverse,
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erf(x, inverse = FALSE)
erfc(x, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="erf_+3A_x">x</code></td>
<td>
<p> Numeric. </p>
</td></tr>
<tr><td><code id="erf_+3A_inverse">inverse</code></td>
<td>
<p> Logical. Of length 1. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code class="reqn">Erf(x)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">Erf(x) = \frac{2}{\sqrt{\pi}} \int_0^x \exp(-t^2) dt</code>
</p>

<p>so that it is closely related to <code><a href="stats.html#topic+Normal">pnorm</a></code>.
The inverse function is defined for <code class="reqn">x</code> in <code class="reqn">(-1,1)</code>.
</p>


<h3>Value</h3>

<p>Returns the value of the function evaluated at <code>x</code>.
</p>


<h3>Note</h3>

<p>Some authors omit the term <code class="reqn">2/\sqrt{\pi}</code> from the
definition of <code class="reqn">Erf(x)</code>. Although defined for complex
arguments, this function only works for real arguments.
</p>
<p>The <em>complementary error function</em> <code class="reqn">erfc(x)</code> is defined
as <code class="reqn">1-erf(x)</code>, and is implemented by <code>erfc</code>.
Its inverse function is defined for <code class="reqn">x</code> in <code class="reqn">(0,2)</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972).
<em>Handbook of Mathematical Functions with Formulas,
Graphs, and Mathematical Tables</em>,
New York: Dover Publications Inc.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">pnorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
curve(erf,   -3, 3, col = "orange", ylab = "", las = 1)
curve(pnorm, -3, 3, add = TRUE, col = "blue", lty = "dotted", lwd = 2)
abline(v = 0, h = 0, lty = "dashed")
legend("topleft", c("erf(x)", "pnorm(x)"), col = c("orange", "blue"),
       lty = c("solid", "dotted"), lwd = 1:2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='erlang'> Erlang Distribution </h2><span id='topic+erlang'></span>

<h3>Description</h3>

<p>Estimates the scale parameter of the Erlang distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erlang(shape.arg, lscale = "loglink", imethod = 1, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="erlang_+3A_shape.arg">shape.arg</code></td>
<td>

<p>The shape parameters.
The user must specify a positive integer,
or integers for multiple responses.
They are recycled <code>by.row = TRUE</code>
according to <code><a href="base.html#topic+matrix">matrix</a></code>.
</p>
</td></tr>
<tr><td><code id="erlang_+3A_lscale">lscale</code></td>
<td>

<p>Link function applied to the (positive) <code class="reqn">scale</code> parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="erlang_+3A_imethod">imethod</code>, <code id="erlang_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Erlang distribution is a special case of
the gamma distribution
with <em>shape</em> that is a positive integer.
If <code>shape.arg = 1</code>
then it simplifies to the exponential distribution.
As illustrated
in the example below, the Erlang distribution is
the distribution of
the sum of <code>shape.arg</code> independent and
identically distributed
exponential random variates.
</p>
<p>The probability density function of the Erlang
distribution is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \exp(-y/scale)
    y^{shape-1} scale^{-shape} / \Gamma(shape)</code>
</p>

<p>for known positive integer <code class="reqn">shape</code>,
unknown <code class="reqn">scale &gt; 0</code>  and <code class="reqn">y &gt; 0</code>.
Here,
<code class="reqn">\Gamma(shape)</code> is the gamma
function, as in <code><a href="base.html#topic+Special">gamma</a></code>.
The mean of <em>Y</em>
is <code class="reqn">\mu=shape \times scale</code> and
its variance is <code class="reqn">shape \times scale^2</code>.
The linear/additive predictor, by default, is
<code class="reqn">\eta=\log(scale)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Multiple responses are permitted.
The <code>rate</code> parameter found in <code><a href="#topic+gammaR">gammaR</a></code>
is <code>1/scale</code> here&mdash;see also <code><a href="stats.html#topic+rgamma">rgamma</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Most standard texts on statistical distributions describe
this distribution, e.g.,
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gammaR">gammaR</a></code>,
<code><a href="#topic+exponential">exponential</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rate &lt;- exp(2); myshape &lt;- 3
edata &lt;- data.frame(y = rep(0, nn &lt;- 1000))
for (ii in 1:myshape)
  edata &lt;- transform(edata, y = y + rexp(nn, rate = rate))
fit &lt;- vglm(y ~ 1, erlang(shape = myshape), edata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)  # Answer = 1/rate
1/rate
summary(fit)
</code></pre>

<hr>
<h2 id='Expectiles-Exponential'> Expectiles of the Exponential Distribution </h2><span id='topic+Expectiles-Exponential'></span><span id='topic+eexp'></span><span id='topic+deexp'></span><span id='topic+peexp'></span><span id='topic+qeexp'></span><span id='topic+reexp'></span>

<h3>Description</h3>

<p>Density function, distribution function, and
expectile function and random generation for the distribution
associated with the expectiles of an exponential distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deexp(x, rate = 1, log = FALSE)
peexp(q, rate = 1, lower.tail = TRUE, log.p = FALSE)
qeexp(p, rate = 1, Maxit.nr = 10, Tol.nr = 1.0e-6,
      lower.tail = TRUE, log.p = FALSE)
reexp(n, rate = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Expectiles-Exponential_+3A_x">x</code>, <code id="Expectiles-Exponential_+3A_p">p</code>, <code id="Expectiles-Exponential_+3A_q">q</code></td>
<td>

<p>See <code><a href="#topic+deunif">deunif</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Exponential_+3A_n">n</code>, <code id="Expectiles-Exponential_+3A_rate">rate</code>, <code id="Expectiles-Exponential_+3A_log">log</code></td>
<td>

<p>See <code><a href="stats.html#topic+Exponential">rexp</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Exponential_+3A_lower.tail">lower.tail</code>, <code id="Expectiles-Exponential_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Exponential">pexp</a></code>
or <code><a href="stats.html#topic+Exponential">qexp</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Exponential_+3A_maxit.nr">Maxit.nr</code>, <code id="Expectiles-Exponential_+3A_tol.nr">Tol.nr</code></td>
<td>

<p>See <code><a href="#topic+deunif">deunif</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>General details are given in <code><a href="#topic+deunif">deunif</a></code>
including
a note regarding the terminology used.
Here,
<code>exp</code> corresponds to the distribution of interest, <code class="reqn">F</code>, and
<code>eexp</code> corresponds to <code class="reqn">G</code>.
The addition of &ldquo;<code>e</code>&rdquo; is for the &lsquo;other&rsquo;
distribution associated with the parent distribution.
Thus
<code>deexp</code> is for <code class="reqn">g</code>,
<code>peexp</code> is for <code class="reqn">G</code>,
<code>qeexp</code> is for the inverse of <code class="reqn">G</code>,
<code>reexp</code> generates random variates from <code class="reqn">g</code>.
</p>
<p>For <code>qeexp</code> the Newton-Raphson algorithm is used to solve
for <code class="reqn">y</code> satisfying <code class="reqn">p = G(y)</code>.  Numerical problems may
occur when values of <code>p</code> are very close to 0 or 1.
</p>


<h3>Value</h3>

<p><code>deexp(x)</code> gives the density function <code class="reqn">g(x)</code>.
<code>peexp(q)</code> gives the distribution function <code class="reqn">G(q)</code>.
<code>qeexp(p)</code> gives the expectile function:
the value <code class="reqn">y</code> such that <code class="reqn">G(y)=p</code>.
<code>reexp(n)</code> gives <code class="reqn">n</code> random variates from <code class="reqn">G</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+deunif">deunif</a></code>,
<code><a href="#topic+denorm">denorm</a></code>,
<code><a href="stats.html#topic+dexp">dexp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my.p &lt;- 0.25; y &lt;- rexp(nn &lt;- 1000)
(myexp &lt;- qeexp(my.p))
sum(myexp - y[y &lt;= myexp]) / sum(abs(myexp - y))  # Should be my.p

## Not run:  par(mfrow = c(2,1))
yy &lt;- seq(-0, 4, len = nn)
plot(yy, deexp(yy),  col = "blue", ylim = 0:1, xlab = "y", ylab = "g(y)",
     type = "l", main = "g(y) for Exp(1); dotted green is f(y) = dexp(y)")
lines(yy, dexp(yy), col = "green", lty = "dotted", lwd = 2)  # 'original'

plot(yy, peexp(yy), type = "l", col = "blue", ylim = 0:1,
     xlab = "y", ylab = "G(y)", main = "G(y) for Exp(1)")
abline(v = 1, h = 0.5, col = "red", lty = "dashed")
lines(yy, pexp(yy), col = "green", lty = "dotted", lwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Expectiles-Normal'> Expectiles of the Normal Distribution </h2><span id='topic+Expectiles-Normal'></span><span id='topic+enorm'></span><span id='topic+denorm'></span><span id='topic+penorm'></span><span id='topic+qenorm'></span><span id='topic+renorm'></span>

<h3>Description</h3>

<p>Density function, distribution function, and
expectile function and random generation for the distribution
associated with the expectiles of a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>denorm(x, mean = 0, sd = 1, log = FALSE)
penorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qenorm(p, mean = 0, sd = 1, Maxit.nr = 10, Tol.nr = 1.0e-6,
       lower.tail = TRUE, log.p = FALSE)
renorm(n, mean = 0, sd = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Expectiles-Normal_+3A_x">x</code>, <code id="Expectiles-Normal_+3A_p">p</code>, <code id="Expectiles-Normal_+3A_q">q</code></td>
<td>

<p>See <code><a href="#topic+deunif">deunif</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Normal_+3A_n">n</code>, <code id="Expectiles-Normal_+3A_mean">mean</code>, <code id="Expectiles-Normal_+3A_sd">sd</code>, <code id="Expectiles-Normal_+3A_log">log</code></td>
<td>

<p>See <code><a href="stats.html#topic+Normal">rnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Normal_+3A_lower.tail">lower.tail</code>, <code id="Expectiles-Normal_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Normal_+3A_maxit.nr">Maxit.nr</code>, <code id="Expectiles-Normal_+3A_tol.nr">Tol.nr</code></td>
<td>

<p>See <code><a href="#topic+deunif">deunif</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>General details are given in <code><a href="#topic+deunif">deunif</a></code>
including
a note regarding the terminology used.
Here,
<code>norm</code> corresponds to the distribution of interest, <code class="reqn">F</code>,
and
<code>enorm</code> corresponds to <code class="reqn">G</code>.
The addition of &ldquo;<code>e</code>&rdquo; is for the &lsquo;other&rsquo;
distribution associated with the parent distribution.
Thus
<code>denorm</code> is for <code class="reqn">g</code>,
<code>penorm</code> is for <code class="reqn">G</code>,
<code>qenorm</code> is for the inverse of <code class="reqn">G</code>,
<code>renorm</code> generates random variates from <code class="reqn">g</code>.
</p>
<p>For <code>qenorm</code> the Newton-Raphson algorithm is used to solve for
<code class="reqn">y</code> satisfying <code class="reqn">p = G(y)</code>.
Numerical problems may occur when values of <code>p</code> are
very close to 0 or 1.
</p>


<h3>Value</h3>

<p><code>denorm(x)</code> gives the density function <code class="reqn">g(x)</code>.
<code>penorm(q)</code> gives the distribution function <code class="reqn">G(q)</code>.
<code>qenorm(p)</code> gives the expectile function:
the value <code class="reqn">y</code> such that <code class="reqn">G(y)=p</code>.
<code>renorm(n)</code> gives <code class="reqn">n</code> random variates from <code class="reqn">G</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+deunif">deunif</a></code>,
<code><a href="#topic+deexp">deexp</a></code>,
<code><a href="stats.html#topic+dnorm">dnorm</a></code>,
<code><a href="#topic+amlnormal">amlnormal</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my.p &lt;- 0.25; y &lt;- rnorm(nn &lt;- 1000)
(myexp &lt;- qenorm(my.p))
sum(myexp - y[y &lt;= myexp]) / sum(abs(myexp - y))  # Should be my.p

# Non-standard normal
mymean &lt;- 1; mysd &lt;- 2
yy &lt;- rnorm(nn, mymean, mysd)
(myexp &lt;- qenorm(my.p, mymean, mysd))
sum(myexp - yy[yy &lt;= myexp]) / sum(abs(myexp - yy))  # Should be my.p
penorm(-Inf, mymean, mysd)      #  Should be 0
penorm( Inf, mymean, mysd)      #  Should be 1
penorm(mean(yy), mymean, mysd)  #  Should be 0.5
abs(qenorm(0.5, mymean, mysd) - mean(yy))  #  Should be 0
abs(penorm(myexp, mymean, mysd) - my.p)    #  Should be 0
integrate(f = denorm, lower = -Inf, upper = Inf,
          mymean, mysd)  #  Should be 1

## Not run: 
par(mfrow = c(2, 1))
yy &lt;- seq(-3, 3, len = nn)
plot(yy, denorm(yy), type = "l", col="blue", xlab = "y", ylab = "g(y)",
     main = "g(y) for N(0,1); dotted green is f(y) = dnorm(y)")
lines(yy, dnorm(yy), col = "green", lty = "dotted", lwd = 2)  # 'original'

plot(yy, penorm(yy), type = "l", col = "blue", ylim = 0:1,
     xlab = "y", ylab = "G(y)", main = "G(y) for N(0,1)")
abline(v = 0, h = 0.5, col = "red", lty = "dashed")
lines(yy, pnorm(yy), col = "green", lty = "dotted", lwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Expectiles-sc.t2'> Expectiles/Quantiles of the Scaled Student t Distribution
with 2 Df</h2><span id='topic+Expectiles-sc.t2'></span><span id='topic+dsc.t2'></span><span id='topic+psc.t2'></span><span id='topic+qsc.t2'></span><span id='topic+rsc.t2'></span>

<h3>Description</h3>

<p>Density function, distribution function, and
quantile/expectile function and random generation for the
scaled Student t distribution with 2 degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsc.t2(x, location = 0, scale = 1, log = FALSE)
psc.t2(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
qsc.t2(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
rsc.t2(n, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Expectiles-sc.t2_+3A_x">x</code>, <code id="Expectiles-sc.t2_+3A_q">q</code></td>
<td>

<p>Vector of expectiles/quantiles.
See the terminology note below.
</p>
</td></tr>
<tr><td><code id="Expectiles-sc.t2_+3A_p">p</code></td>
<td>

<p>Vector of probabilities. 
These should lie in <code class="reqn">(0,1)</code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-sc.t2_+3A_n">n</code>, <code id="Expectiles-sc.t2_+3A_log">log</code></td>
<td>
<p>See <code><a href="stats.html#topic+Uniform">runif</a></code>.</p>
</td></tr>
<tr><td><code id="Expectiles-sc.t2_+3A_location">location</code>, <code id="Expectiles-sc.t2_+3A_scale">scale</code></td>
<td>

<p>Location and scale parameters.
The latter should have positive values.
Values of these vectors are recyled.
</p>
</td></tr>
<tr><td><code id="Expectiles-sc.t2_+3A_lower.tail">lower.tail</code>, <code id="Expectiles-sc.t2_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+TDist">pt</a></code>
or <code><a href="stats.html#topic+TDist">qt</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Student-t distribution with 2 degrees of freedom and
a scale parameter of <code>sqrt(2)</code> is equivalent to
the standard form of this distribution
(called Koenker's distribution below).
Further details about this distribution are given in
<code><a href="#topic+sc.studentt2">sc.studentt2</a></code>.
</p>


<h3>Value</h3>

<p><code>dsc.t2(x)</code> gives the density function.
<code>psc.t2(q)</code> gives the distribution function.
<code>qsc.t2(p)</code> gives the expectile and quantile function.
<code>rsc.t2(n)</code> gives <code class="reqn">n</code> random variates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+TDist">dt</a></code>,
<code><a href="#topic+sc.studentt2">sc.studentt2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my.p &lt;- 0.25; y &lt;- rsc.t2(nn &lt;- 5000)
(myexp &lt;- qsc.t2(my.p))
sum(myexp - y[y &lt;= myexp]) / sum(abs(myexp - y))  # Should be my.p
# Equivalently:
I1 &lt;- mean(y &lt;= myexp) * mean( myexp - y[y &lt;= myexp])
I2 &lt;- mean(y &gt;  myexp) * mean(-myexp + y[y &gt;  myexp])
I1 / (I1 + I2)  # Should be my.p
# Or:
I1 &lt;- sum( myexp - y[y &lt;= myexp])
I2 &lt;- sum(-myexp + y[y &gt;  myexp])

# Non-standard Koenker distribution
myloc &lt;- 1; myscale &lt;- 2
yy &lt;- rsc.t2(nn, myloc, myscale)
(myexp &lt;- qsc.t2(my.p, myloc, myscale))
sum(myexp - yy[yy &lt;= myexp]) / sum(abs(myexp - yy))  # Should be my.p
psc.t2(mean(yy), myloc, myscale)  # Should be 0.5
abs(qsc.t2(0.5, myloc, myscale) - mean(yy))  # Should be 0
abs(psc.t2(myexp, myloc, myscale) - my.p)  # Should be 0
integrate(f = dsc.t2, lower = -Inf, upper = Inf,
          locat = myloc, scale = myscale)  # Should be 1

y &lt;- seq(-7, 7, len = 201)
max(abs(dsc.t2(y) - dt(y / sqrt(2), df = 2) / sqrt(2)))  # Should be 0
## Not run:  plot(y, dsc.t2(y), type = "l", col = "blue", las = 1,
     ylim = c(0, 0.4), main = "Blue = Koenker; orange = N(0, 1)")
lines(y, dnorm(y), type = "l", col = "orange")
abline(h = 0, v = 0, lty = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Expectiles-Uniform'> Expectiles of the Uniform Distribution </h2><span id='topic+Expectiles-Uniform'></span><span id='topic+eunif'></span><span id='topic+deunif'></span><span id='topic+peunif'></span><span id='topic+qeunif'></span><span id='topic+reunif'></span>

<h3>Description</h3>

<p>Density function, distribution function, and
expectile function and random generation for the distribution
associated with the expectiles of a uniform distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deunif(x, min = 0, max = 1, log = FALSE)
peunif(q, min = 0, max = 1, lower.tail = TRUE, log.p = FALSE)
qeunif(p, min = 0, max = 1, Maxit.nr = 10, Tol.nr = 1.0e-6,
       lower.tail = TRUE, log.p = FALSE)
reunif(n, min = 0, max = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Expectiles-Uniform_+3A_x">x</code>, <code id="Expectiles-Uniform_+3A_q">q</code></td>
<td>

<p>Vector of expectiles.
See the terminology note below.
</p>
</td></tr>
<tr><td><code id="Expectiles-Uniform_+3A_p">p</code></td>
<td>

<p>Vector of probabilities. 
These should lie in <code class="reqn">(0,1)</code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Uniform_+3A_n">n</code>, <code id="Expectiles-Uniform_+3A_min">min</code>, <code id="Expectiles-Uniform_+3A_max">max</code>, <code id="Expectiles-Uniform_+3A_log">log</code></td>
<td>

<p>See <code><a href="stats.html#topic+Uniform">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Uniform_+3A_lower.tail">lower.tail</code>, <code id="Expectiles-Uniform_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Uniform">punif</a></code>
or <code><a href="stats.html#topic+Uniform">qunif</a></code>.
</p>
</td></tr>
<tr><td><code id="Expectiles-Uniform_+3A_maxit.nr">Maxit.nr</code></td>
<td>

<p>Numeric.
Maximum number of Newton-Raphson iterations allowed.
A warning is issued if convergence is not obtained for all <code>p</code>
values.
</p>
</td></tr>
<tr><td><code id="Expectiles-Uniform_+3A_tol.nr">Tol.nr</code></td>
<td>

<p>Numeric.
Small positive value specifying the tolerance or precision to which
the expectiles are computed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Jones (1994) elucidated on the property that the expectiles
of a random variable <code class="reqn">X</code> with distribution function <code class="reqn">F(x)</code>
correspond to the
quantiles of a distribution <code class="reqn">G(x)</code> where
<code class="reqn">G</code> is related by an explicit formula to <code class="reqn">F</code>.
In particular, let <code class="reqn">y</code> be the <code class="reqn">p</code>-expectile of <code class="reqn">F</code>.
Then <code class="reqn">y</code> is the <code class="reqn">p</code>-quantile of <code class="reqn">G</code>
where
</p>
<p style="text-align: center;"><code class="reqn">p = G(y) = (P(y) - y F(y)) / (2[P(y) - y F(y)] + y - \mu),</code>
</p>

<p>and
<code class="reqn">\mu</code> is the mean of <code class="reqn">X</code>.
The derivative of <code class="reqn">G</code> is
</p>
<p style="text-align: center;"><code class="reqn">g(y) = (\mu F(y) - P(y)) / (2[P(y) - y F(y)] + y - \mu)^2 .</code>
</p>

<p>Here, <code class="reqn">P(y)</code> is the partial moment
<code class="reqn">\int_{-\infty}^{y} x f(x) \, dx</code>
and
<code class="reqn">0 &lt; p &lt; 1</code>.
The 0.5-expectile is the mean <code class="reqn">\mu</code> and
the 0.5-quantile  is the median.
</p>
<p>A note about the terminology used here.
Recall in the <em>S</em> language there are the <code>dpqr</code>-type functions
associated with a distribution, e.g.,
<code><a href="stats.html#topic+Uniform">dunif</a></code>,
<code><a href="stats.html#topic+Uniform">punif</a></code>,
<code><a href="stats.html#topic+Uniform">qunif</a></code>,
<code><a href="stats.html#topic+Uniform">runif</a></code>,
for the uniform distribution.
Here,
<code>unif</code> corresponds to <code class="reqn">F</code> and
<code>eunif</code> corresponds to <code class="reqn">G</code>.
The addition of &ldquo;<code>e</code>&rdquo; (for <em>expectile</em>) is for the
&lsquo;other&rsquo;
distribution associated with the parent distribution.
Thus
<code>deunif</code> is for <code class="reqn">g</code>,
<code>peunif</code> is for <code class="reqn">G</code>,
<code>qeunif</code> is for the inverse of <code class="reqn">G</code>,
<code>reunif</code> generates random variates from <code class="reqn">g</code>.
</p>
<p>For <code>qeunif</code> the Newton-Raphson algorithm is used to solve for
<code class="reqn">y</code> satisfying <code class="reqn">p = G(y)</code>.
Numerical problems may occur when values of <code>p</code> are
very close to 0 or 1.
</p>


<h3>Value</h3>

<p><code>deunif(x)</code> gives the density function <code class="reqn">g(x)</code>.
<code>peunif(q)</code> gives the distribution function <code class="reqn">G(q)</code>.
<code>qeunif(p)</code> gives the expectile function:
the expectile <code class="reqn">y</code> such that <code class="reqn">G(y) = p</code>.
<code>reunif(n)</code> gives <code class="reqn">n</code> random variates from <code class="reqn">G</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Jones, M. C. (1994).
Expectiles and M-quantiles are quantiles.
<em>Statistics and Probability Letters</em>,
<b>20</b>, 149&ndash;153.
</p>






<h3>See Also</h3>

<p><code><a href="#topic+deexp">deexp</a></code>,
<code><a href="#topic+denorm">denorm</a></code>,
<code><a href="stats.html#topic+dunif">dunif</a></code>,
<code><a href="#topic+dsc.t2">dsc.t2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my.p &lt;- 0.25; y &lt;- runif(nn &lt;- 1000)
(myexp &lt;- qeunif(my.p))
sum(myexp - y[y &lt;= myexp]) / sum(abs(myexp - y))  # Should be my.p
# Equivalently:
I1 &lt;- mean(y &lt;= myexp) * mean( myexp - y[y &lt;= myexp])
I2 &lt;- mean(y &gt;  myexp) * mean(-myexp + y[y &gt;  myexp])
I1 / (I1 + I2)  # Should be my.p
# Or:
I1 &lt;- sum( myexp - y[y &lt;= myexp])
I2 &lt;- sum(-myexp + y[y &gt;  myexp])

# Non-standard uniform
mymin &lt;- 1; mymax &lt;- 8
yy &lt;- runif(nn, mymin, mymax)
(myexp &lt;- qeunif(my.p, mymin, mymax))
sum(myexp - yy[yy &lt;= myexp]) / sum(abs(myexp - yy))  # Should be my.p
peunif(mymin, mymin, mymax)     #  Should be 0
peunif(mymax, mymin, mymax)     #  Should be 1
peunif(mean(yy), mymin, mymax)  #  Should be 0.5
abs(qeunif(0.5, mymin, mymax) - mean(yy))  #  Should be 0
abs(qeunif(0.5, mymin, mymax) - (mymin+mymax)/2)  #  Should be 0
abs(peunif(myexp, mymin, mymax) - my.p)  #  Should be 0
integrate(f = deunif, lower = mymin - 3, upper = mymax + 3,
          min = mymin, max = mymax)  # Should be 1

## Not run: 
par(mfrow = c(2,1))
yy &lt;- seq(0.0, 1.0, len = nn)
plot(yy, deunif(yy), type = "l", col = "blue", ylim = c(0, 2),
     xlab = "y", ylab = "g(y)", main = "g(y) for Uniform(0,1)")
lines(yy, dunif(yy), col = "green", lty = "dotted", lwd = 2)  # 'original'

plot(yy, peunif(yy), type = "l", col = "blue", ylim = 0:1,
     xlab = "y", ylab = "G(y)", main = "G(y) for Uniform(0,1)")
abline(a = 0.0, b = 1.0, col = "green", lty = "dotted", lwd = 2)
abline(v = 0.5, h = 0.5, col = "red", lty = "dashed") 
## End(Not run)
</code></pre>

<hr>
<h2 id='expexpff'> Exponentiated Exponential Distribution </h2><span id='topic+expexpff'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the exponentiated exponential
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expexpff(lrate = "loglink", lshape = "loglink",
         irate = NULL, ishape = 1.1, tolerance = 1.0e-6, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expexpff_+3A_lshape">lshape</code>, <code id="expexpff_+3A_lrate">lrate</code></td>
<td>

<p>Parameter link functions for the
<code class="reqn">\alpha</code> and <code class="reqn">\lambda</code> parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The defaults ensure both parameters are positive.
</p>
</td></tr>
<tr><td><code id="expexpff_+3A_ishape">ishape</code></td>
<td>

<p>Initial value for the <code class="reqn">\alpha</code>
parameter. If convergence fails try setting a different
value for this argument.
</p>
</td></tr>
<tr><td><code id="expexpff_+3A_irate">irate</code></td>
<td>

<p>Initial value for the <code class="reqn">\lambda</code> parameter.
By default, an initial value is chosen internally using
<code>ishape</code>.
</p>
</td></tr>
<tr><td><code id="expexpff_+3A_tolerance">tolerance</code></td>
<td>

<p>Numeric. Small positive value for testing whether values
are close enough to 1 and 2.
</p>
</td></tr>
<tr><td><code id="expexpff_+3A_zero">zero</code></td>
<td>
<p> An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The default is none of them.
If used, choose one value from the set {1,2}.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exponentiated exponential distribution is an alternative
to the Weibull and the gamma distributions.
The formula for the density is
</p>
<p style="text-align: center;"><code class="reqn">f(y;\lambda,\alpha) =
    \alpha \lambda (1-\exp(-\lambda y))^{\alpha-1}
    \exp(-\lambda y) </code>
</p>

<p>where <code class="reqn">y&gt;0</code>,
<code class="reqn">\lambda&gt;0</code> and
<code class="reqn">\alpha&gt;0</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">(\psi(\alpha+1)-\psi(1))/\lambda</code>
(returned as the fitted values)
where <code class="reqn">\psi</code> is the digamma function.
The variance of <code class="reqn">Y</code> is
<code class="reqn">(\psi'(1)-\psi'(\alpha+1))/\lambda^2</code>
where <code class="reqn">\psi'</code> is the trigamma function.
</p>
<p>This distribution has been called the two-parameter generalized
exponential distribution by Gupta and Kundu (2006).
A special case of the exponentiated exponential distribution:
<code class="reqn">\alpha=1</code> is the exponential distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Practical experience shows that reasonably good initial values really
helps. In particular, try setting different values for the <code>ishape</code>
argument if numerical problems are encountered or failure to convergence
occurs. Even if convergence occurs try perturbing the initial value
to make sure the global solution is obtained and not a local solution.
The algorithm may fail if the estimate of the shape parameter is
too close to unity.
</p>


<h3>Note</h3>

<p>Fisher scoring is used, however, convergence is usually very slow.
This is a good sign that there is a bug, but I have yet to check
that the expected information is correct.
Also, I have yet to implement Type-I right censored data using the
results of Gupta and Kundu (2006).
</p>
<p>Another algorithm for fitting this model is implemented in
<code><a href="#topic+expexpff1">expexpff1</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Gupta, R. D. and Kundu, D. (2001).
Exponentiated exponential family: an alternative to
gamma and Weibull distributions,
<em>Biometrical Journal</em>,
<b>43</b>,
117&ndash;130.
</p>
<p>Gupta, R. D. and Kundu, D. (2006).
On the comparison of Fisher information of the
Weibull and GE distributions,
<em>Journal of Statistical Planning and Inference</em>,
<b>136</b>,
3130&ndash;3144.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expexpff1">expexpff1</a></code>,
<code><a href="#topic+gammaR">gammaR</a></code>,
<code><a href="#topic+weibullR">weibullR</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A special case: exponential data
edata &lt;- data.frame(y = rexp(n &lt;- 1000))
fit &lt;- vglm(y ~ 1, fam = expexpff, data = edata, trace = TRUE, maxit = 99)
coef(fit, matrix = TRUE)
Coef(fit)


# Ball bearings data (number of million revolutions before failure)
edata &lt;- data.frame(bbearings = c(17.88, 28.92, 33.00, 41.52, 42.12, 45.60,
48.80, 51.84, 51.96, 54.12, 55.56, 67.80, 68.64, 68.64,
68.88, 84.12, 93.12, 98.64, 105.12, 105.84, 127.92,
128.04, 173.40))
fit &lt;- vglm(bbearings ~ 1, fam = expexpff(irate = 0.05, ish = 5),
            trace = TRUE, maxit = 300, data = edata)
coef(fit, matrix = TRUE)
Coef(fit)    # Authors get c(rate=0.0314, shape=5.2589)
logLik(fit)  # Authors get -112.9763


# Failure times of the airconditioning system of an airplane
eedata &lt;- data.frame(acplane = c(23, 261, 87, 7, 120, 14, 62, 47,
225, 71, 246, 21, 42, 20, 5, 12, 120, 11, 3, 14,
71, 11, 14, 11, 16, 90, 1, 16, 52, 95))
fit &lt;- vglm(acplane ~ 1, fam = expexpff(ishape = 0.8, irate = 0.15),
            trace = TRUE, maxit = 99, data = eedata)
coef(fit, matrix = TRUE)
Coef(fit)    # Authors get c(rate=0.0145, shape=0.8130)
logLik(fit)  # Authors get log-lik -152.264
</code></pre>

<hr>
<h2 id='expexpff1'> Exponentiated Exponential Distribution </h2><span id='topic+expexpff1'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the exponentiated exponential
distribution by maximizing a profile (concentrated) likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expexpff1(lrate = "loglink", irate = NULL, ishape = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expexpff1_+3A_lrate">lrate</code></td>
<td>

<p>Parameter link function for the (positive) <code class="reqn">\lambda</code> parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="expexpff1_+3A_irate">irate</code></td>
<td>

<p>Initial value for the <code class="reqn">\lambda</code> parameter.
By default, an initial value is chosen internally using <code>ishape</code>.
</p>
</td></tr>
<tr><td><code id="expexpff1_+3A_ishape">ishape</code></td>
<td>

<p>Initial value for the <code class="reqn">\alpha</code> parameter. If convergence
fails try setting a different value for this argument.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+expexpff">expexpff</a></code> for details about the exponentiated
exponential distribution. This family function uses a different
algorithm for fitting the model. Given <code class="reqn">\lambda</code>,
the MLE of <code class="reqn">\alpha</code> can easily be solved in terms of
<code class="reqn">\lambda</code>. This family function maximizes a profile
(concentrated) likelihood with respect to <code class="reqn">\lambda</code>.
Newton-Raphson is used, which compares with Fisher scoring with
<code><a href="#topic+expexpff">expexpff</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The standard errors produced by a
<code>summary</code> of the model may be wrong.
</p>


<h3>Note</h3>

<p>This family function works only for intercept-only models,
i.e., <code>y ~ 1</code> where <code>y</code> is the response.
</p>
<p>The estimate of  <code class="reqn">\alpha</code> is attached to the
<code>misc</code> slot of the object, which is a list and contains
the component <code>shape</code>.
</p>
<p>As Newton-Raphson is used, the working weights are sometimes
negative, and some adjustment is made to these to make them
positive.
</p>
<p>Like <code><a href="#topic+expexpff">expexpff</a></code>, good initial
values are needed. Convergence may be slow.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Gupta, R. D. and Kundu, D. (2001).
Exponentiated exponential family: an alternative to
gamma and Weibull distributions,
<em>Biometrical Journal</em>,
<b>43</b>,
117&ndash;130.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expexpff">expexpff</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Ball bearings data (number of million revolutions before failure)
edata &lt;- data.frame(bbearings = c(17.88, 28.92, 33.00, 41.52, 42.12, 45.60,
48.80, 51.84, 51.96, 54.12, 55.56, 67.80, 68.64, 68.64,
68.88, 84.12, 93.12, 98.64, 105.12, 105.84, 127.92,
128.04, 173.40))
fit &lt;- vglm(bbearings ~ 1, expexpff1(ishape = 4), trace = TRUE,
            maxit = 250, checkwz = FALSE, data = edata)
coef(fit, matrix = TRUE)
Coef(fit)  # Authors get c(0.0314, 5.2589) with log-lik -112.9763
logLik(fit)
fit@misc$shape  # Estimate of shape


# Failure times of the airconditioning system of an airplane
eedata &lt;- data.frame(acplane = c(23, 261, 87, 7, 120, 14, 62, 47,
225, 71, 246, 21, 42, 20, 5, 12, 120, 11, 3, 14,
71, 11, 14, 11, 16, 90, 1, 16, 52, 95))
fit &lt;- vglm(acplane ~ 1, expexpff1(ishape = 0.8), trace = TRUE,
            maxit = 50, checkwz = FALSE, data = eedata)
coef(fit, matrix = TRUE)
Coef(fit)  # Authors get c(0.0145, 0.8130) with log-lik -152.264
logLik(fit)
fit@misc$shape  # Estimate of shape
</code></pre>

<hr>
<h2 id='expgeom'>The Exponential Geometric Distribution</h2><span id='topic+expgeom'></span><span id='topic+dexpgeom'></span><span id='topic+pexpgeom'></span><span id='topic+qexpgeom'></span><span id='topic+rexpgeom'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the exponential geometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dexpgeom(x, scale = 1, shape, log = FALSE)
pexpgeom(q, scale = 1, shape)
qexpgeom(p, scale = 1, shape) 
rexpgeom(n, scale = 1, shape) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expgeom_+3A_x">x</code>, <code id="expgeom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="expgeom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="expgeom_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the number required. </p>
</td></tr>
<tr><td><code id="expgeom_+3A_scale">scale</code>, <code id="expgeom_+3A_shape">shape</code></td>
<td>

<p>positive scale and shape parameters. </p>
</td></tr>
<tr><td><code id="expgeom_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+expgeometric">expgeometric</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters, 
for the formula of the probability density function and other details.
</p>


<h3>Value</h3>

<p><code>dexpgeom</code> gives the density,
<code>pexpgeom</code> gives the distribution function,
<code>qexpgeom</code> gives the quantile function, and
<code>rexpgeom</code> generates random deviates.
</p>


<h3>Note</h3>

<p>We define <code>scale</code> as the reciprocal of the scale parameter
used by Adamidis and Loukas (1998).
</p>


<h3>Author(s)</h3>

<p> J. G. Lauder and T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+expgeometric">expgeometric</a></code>,
<code><a href="#topic+exponential">exponential</a></code>, 
<code><a href="#topic+geometric">geometric</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape &lt;- 0.5; scale &lt;- 1; nn &lt;- 501
x &lt;- seq(-0.10, 3.0, len = nn)
plot(x, dexpgeom(x, scale, shape), type = "l", las = 1, ylim = c(0, 2),
     ylab = paste("[dp]expgeom(shape = ", shape, ", scale = ", scale, ")"),
     col = "blue", cex.main = 0.8,
     main = "Blue is density, red is cumulative distribution function",
     sub = "Purple lines are the 10,20,...,90 percentiles")
lines(x, pexpgeom(x, scale, shape), col = "red")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qexpgeom(probs, scale, shape)
lines(Q, dexpgeom(Q, scale, shape), col = "purple", lty = 3, type = "h")
lines(Q, pexpgeom(Q, scale, shape), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(pexpgeom(Q, scale, shape) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='expgeometric'>Exponential Geometric Distribution Family Function</h2><span id='topic+expgeometric'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the exponential geometric distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expgeometric(lscale = "loglink", lshape = "logitlink",
             iscale = NULL,   ishape = NULL,
             tol12 = 1e-05, zero = 1, nsimEIM = 400)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expgeometric_+3A_lscale">lscale</code>, <code id="expgeometric_+3A_lshape">lshape</code></td>
<td>

<p>Link function for the two parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="expgeometric_+3A_iscale">iscale</code>, <code id="expgeometric_+3A_ishape">ishape</code></td>
<td>

<p>Numeric.
Optional initial values for the scale and shape parameters.
</p>
</td></tr>
<tr><td><code id="expgeometric_+3A_tol12">tol12</code></td>
<td>

<p>Numeric.
Tolerance for testing whether a parameter has value 1 or 2.
</p>
</td></tr>
<tr><td><code id="expgeometric_+3A_zero">zero</code>, <code id="expgeometric_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exponential geometric distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y; c = scale, s = shape)  = 
   (1/c) (1 - s) e^{-y/c} (1 - s e^{-y/c})^{-2}</code>
</p>

<p>where <code class="reqn">y &gt; 0</code>, <code class="reqn">c &gt; 0</code> and <code class="reqn">s \in (0, 1)</code>.
The mean, <code class="reqn">(c (s - 1)/ s) \log(1 - s)</code>
is returned as the fitted values.
Note the median is <code class="reqn">c \log(2 - s)</code>.
Simulated Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>We define <code>scale</code> as the reciprocal of the scale parameter
used by Adamidis and Loukas (1998).
</p>


<h3>Author(s)</h3>

<p> J. G. Lauder and T. W. Yee </p>


<h3>References</h3>

<p>Adamidis, K., Loukas, S. (1998).
A lifetime distribution with decreasing failure rate.
<em>Statistics and Probability Letters</em>,
<b>39</b>, 35&ndash;42.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+dexpgeom">dexpgeom</a></code>,
<code><a href="#topic+exponential">exponential</a></code>,
<code><a href="#topic+geometric">geometric</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Scale &lt;- exp(2); shape = logitlink(-1, inverse = TRUE);
edata &lt;- data.frame(y = rexpgeom(n = 2000, scale = Scale, shape = shape))
fit &lt;- vglm(y ~ 1, expgeometric, edata, trace = TRUE)
c(with(edata, mean(y)), head(fitted(fit), 1))
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='expint'>
The Exponential Integral and Variants
</h2><span id='topic+expint'></span><span id='topic+expexpint'></span><span id='topic+expint.E1'></span>

<h3>Description</h3>

<p>Computes the exponential integral <code class="reqn">Ei(x)</code> for real values,
as well as <code class="reqn">\exp(-x) \times Ei(x)</code> and
<code class="reqn">E_1(x)</code> and their derivatives (up to the 3rd derivative).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expint(x, deriv = 0)
expexpint(x, deriv = 0)
expint.E1(x, deriv = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expint_+3A_x">x</code></td>
<td>

<p>Numeric. Ideally a vector of positive reals.
</p>
</td></tr>
<tr><td><code id="expint_+3A_deriv">deriv</code></td>
<td>
<p>Integer. Either 0, 1, 2 or 3.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exponential integral <code class="reqn">Ei(x)</code> function is the integral of
<code class="reqn">\exp(t) / t</code>
from 0 to <code class="reqn">x</code>, for positive real <code class="reqn">x</code>.
The function <code class="reqn">E_1(x)</code> is the integral of
<code class="reqn">\exp(-t) / t</code>
from <code class="reqn">x</code> to infinity, for positive real <code class="reqn">x</code>.
</p>


<h3>Value</h3>

<p>Function <code>expint(x, deriv = n)</code> returns the
<code class="reqn">n</code>th derivative of <code class="reqn">Ei(x)</code> (up to the 3rd),
function <code>expexpint(x, deriv = n)</code> returns the
<code class="reqn">n</code>th derivative of
<code class="reqn">\exp(-x) \times Ei(x)</code> (up to the 3rd),
function <code>expint.E1(x, deriv = n)</code> returns the <code class="reqn">n</code>th
derivative of <code class="reqn">E_1(x)</code> (up to the 3rd).
</p>


<h3>Warning </h3>

<p>These functions have not been tested thoroughly.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee has simply written a small wrapper function to call the
NETLIB FORTRAN code.
Xiangjie Xue modified the functions to calculate derivatives.
Higher derivatives can actually be calculated&mdash;please let me
know if you need it.
</p>


<h3>References</h3>

<p><a href="https://netlib.org/specfun/ei">https://netlib.org/specfun/ei</a>.
</p>



<h3>See Also</h3>

<p><code><a href="base.html#topic+log">log</a></code>,
<code><a href="base.html#topic+log">exp</a></code>.
There is also a package called <span class="pkg">expint</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
par(mfrow = c(2, 2))
curve(expint, 0.01, 2, xlim = c(0, 2), ylim = c(-3, 5),
      las = 1, col = "orange")
abline(v = (-3):5, h = (-4):5, lwd = 2, lty = "dotted", col = "gray")
abline(h = 0, v = 0, lty = "dashed", col = "blue")

curve(expexpint, 0.01, 2, xlim = c(0, 2), ylim = c(-3, 2),
      las = 1, col = "orange")
abline(v = (-3):2, h = (-4):5, lwd = 2, lty = "dotted", col = "gray")
abline(h = 0, v = 0, lty = "dashed", col = "blue")

curve(expint.E1, 0.01, 2, xlim = c(0, 2), ylim = c(0, 5),
      las = 1, col = "orange")
abline(v = (-3):2, h = (-4):5, lwd = 2, lty = "dotted", col = "gray")
abline(h = 0, v = 0, lty = "dashed", col = "blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='explink'> Exponential Link Function </h2><span id='topic+explink'></span>

<h3>Description</h3>

<p>Computes the exponential transformation,
including its inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
        short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>





<tr><td><code id="explink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+clogloglink">clogloglink</a></code>.
</p>
</td></tr>
<tr><td><code id="explink_+3A_inverse">inverse</code>, <code id="explink_+3A_deriv">deriv</code>, <code id="explink_+3A_short">short</code>, <code id="explink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exponential link function is potentially
suitable for parameters that
are positive.
Numerical values of <code>theta</code> close to negative
or positive infinity
may result in
<code>0</code>, <code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>


<h3>Value</h3>

<p>For <code>explink</code> with <code>deriv = 0</code>,
the exponential of <code>theta</code>, i.e.,
<code>exp(theta)</code> when <code>inverse = FALSE</code>.
And if <code>inverse = TRUE</code> then
<code>log(theta)</code>;
if <code>theta</code> is not positive then it will return <code>NaN</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a
function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms,
i.e., to base <em>e</em>.
</p>


<h3>Note</h3>

<p>This function has particular use for
computing quasi-variances when
used with <code><a href="#topic+rcim">rcim</a></code> and <code><a href="#topic+uninormal">uninormal</a></code>.
</p>
<p>Numerical instability may occur when <code>theta</code> is
close to negative or positive infinity.
One way of overcoming this (one day) is to use <code>bvalue</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+Qvar">Qvar</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>theta &lt;- rnorm(30)
explink(theta)
max(abs(explink(explink(theta), inverse = TRUE) - theta))  # 0?
</code></pre>

<hr>
<h2 id='explog'>The Exponential Logarithmic Distribution</h2><span id='topic+explog'></span><span id='topic+dexplog'></span><span id='topic+pexplog'></span><span id='topic+qexplog'></span><span id='topic+rexplog'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the exponential logarithmic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dexplog(x, scale = 1, shape, log = FALSE)
pexplog(q, scale = 1, shape)
qexplog(p, scale = 1, shape) 
rexplog(n, scale = 1, shape) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explog_+3A_x">x</code>, <code id="explog_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="explog_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="explog_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the number
required. </p>
</td></tr>
<tr><td><code id="explog_+3A_scale">scale</code>, <code id="explog_+3A_shape">shape</code></td>
<td>

<p>positive scale and shape parameters. </p>
</td></tr>
<tr><td><code id="explog_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+explogff">explogff</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters, 
for the formula of the probability density function and other details.
</p>


<h3>Value</h3>

<p><code>dexplog</code> gives the density,
<code>pexplog</code> gives the distribution function,
<code>qexplog</code> gives the quantile function, and
<code>rexplog</code> generates random deviates.
</p>


<h3>Note</h3>

<p>We define <code>scale</code> as the reciprocal of the scale parameter
used by Tahmasabi and Rezaei (2008).
</p>


<h3>Author(s)</h3>

<p> J. G. Lauder and T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+explogff">explogff</a></code>,
<code><a href="#topic+exponential">exponential</a></code>.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape &lt;- 0.5; scale &lt;- 2; nn &lt;- 501
x &lt;- seq(-0.50, 6.0, len = nn)
plot(x, dexplog(x, scale, shape), type = "l", las = 1, ylim = c(0, 1.1),
     ylab = paste("[dp]explog(shape = ", shape, ", scale = ", scale, ")"),
     col = "blue", cex.main = 0.8,
     main = "Blue is density, orange is cumulative distribution function",
     sub = "Purple lines are the 10,20,...,90 percentiles")
lines(x, pexplog(x, scale, shape), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qexplog(probs, scale, shape = shape)
lines(Q, dexplog(Q, scale, shape = shape), col = "purple", lty = 3, type = "h")
lines(Q, pexplog(Q, scale, shape = shape), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(pexplog(Q, scale, shape = shape) - probs)) # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='explogff'>Exponential Logarithmic Distribution Family Function</h2><span id='topic+explogff'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the exponential logarithmic distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explogff(lscale = "loglink", lshape = "logitlink",
         iscale = NULL,   ishape = NULL,
         tol12 = 1e-05, zero = 1, nsimEIM = 400)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explogff_+3A_lscale">lscale</code>, <code id="explogff_+3A_lshape">lshape</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="explogff_+3A_tol12">tol12</code></td>
<td>

<p>Numeric.
Tolerance for testing whether a parameter has value 1 or 2.
</p>
</td></tr>
<tr><td><code id="explogff_+3A_iscale">iscale</code>, <code id="explogff_+3A_ishape">ishape</code>, <code id="explogff_+3A_zero">zero</code>, <code id="explogff_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exponential logarithmic distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y; c, s)  = 
   (1/(-\log p ))  (((1/c)   (1 - s)   e^{-y/c}) / (1 - (1 - s)   e^{-y/c}))</code>
</p>

<p>where <code class="reqn">y &gt; 0</code>, scale parameter <code class="reqn">c &gt; 0</code>, and
shape parameter <code class="reqn">s \in (0, 1)</code>.
The mean, <code class="reqn">(-polylog(2, 1 - p) c) / \log(s)</code> is <em>not</em> returned as the fitted values.
Note the median is <code class="reqn">c \log(1 + \sqrt{s})</code>
and it is <em>currently</em> returned as the fitted values.
Simulated Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>We define <code>scale</code> as the reciprocal of the rate parameter
used by Tahmasabi and Sadegh (2008).
</p>
<p>Yet to do: find a <code>polylog()</code> function.
</p>


<h3>Author(s)</h3>

<p> J. G. Lauder and T. W .Yee </p>


<h3>References</h3>

<p>Tahmasabi, R., Sadegh, R. (2008).
A two-parameter lifetime distribution with decreasing failure rate.
<em>Computational Statistics and Data Analysis</em>,
<b>52</b>, 3889&ndash;3901.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+dexplog">dexplog</a></code>,
<code><a href="#topic+exponential">exponential</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  Scale &lt;- exp(2); shape &lt;- logitlink(-1, inverse = TRUE)
edata &lt;- data.frame(y = rexplog(n = 2000, scale = Scale, shape = shape))
fit &lt;- vglm(y ~ 1, explogff, data = edata, trace = TRUE)
c(with(edata, median(y)), head(fitted(fit), 1))
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='exponential'> Exponential Distribution </h2><span id='topic+exponential'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for the exponential distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exponential(link = "loglink", location = 0, expected = TRUE,
            type.fitted = c("mean", "percentiles", "Qlink"),
            percentiles = 50,
            ishrinkage = 0.95, parallel = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exponential_+3A_link">link</code></td>
<td>

<p>Parameter link function applied to the positive parameter <code class="reqn">rate</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="exponential_+3A_location">location</code></td>
<td>

<p>Numeric of length 1, the known location parameter, <code class="reqn">A</code>, say.
</p>
</td></tr>
<tr><td><code id="exponential_+3A_expected">expected</code></td>
<td>

<p>Logical. If <code>TRUE</code> Fisher scoring is used,
otherwise Newton-Raphson. The latter is usually faster.
</p>
</td></tr>
<tr><td><code id="exponential_+3A_ishrinkage">ishrinkage</code>, <code id="exponential_+3A_parallel">parallel</code>, <code id="exponential_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="exponential_+3A_type.fitted">type.fitted</code>, <code id="exponential_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The family function assumes the response <code class="reqn">Y</code> has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \lambda \exp(-\lambda (y-A))</code>
</p>

<p>for <code class="reqn">y &gt; A</code>, where <code class="reqn">A</code> is the known location parameter.
By default, <code class="reqn">A=0</code>.
Then <code class="reqn">E(Y) = A + 1/ \lambda</code> and
<code class="reqn">Var(Y) = 1/ \lambda^2</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Suppose <code class="reqn">A = 0</code>.
For a fixed time interval, the number of events is
Poisson with mean <code class="reqn">\lambda</code> if the time
between events has a
geometric distribution with mean <code class="reqn">\lambda^{-1}</code>.
The argument <code>rate</code> in <code>exponential</code> is the same as
<code><a href="stats.html#topic+Exponential">rexp</a></code> etc.
The argument <code>lambda</code> in <code><a href="stats.html#topic+rpois">rpois</a></code> is somewhat
the same as <code>rate</code> here.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amlexponential">amlexponential</a></code>,
<code><a href="#topic+gpd">gpd</a></code>,
<code><a href="#topic+laplace">laplace</a></code>,
<code><a href="#topic+expgeometric">expgeometric</a></code>,
<code><a href="#topic+explogff">explogff</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+mix2exp">mix2exp</a></code>,
<code><a href="#topic+freund61">freund61</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="stats.html#topic+Exponential">Exponential</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>edata &lt;- data.frame(x2 = runif(nn &lt;- 100) - 0.5)
edata &lt;- transform(edata, x3 = runif(nn) - 0.5)
edata &lt;- transform(edata, eta = 0.2 - 0.7 * x2 + 1.9 * x3)
edata &lt;- transform(edata, rate = exp(eta))
edata &lt;- transform(edata, y = rexp(nn, rate = rate))
with(edata, stem(y))

fit.slow &lt;- vglm(y ~ x2 + x3, exponential, data = edata, trace = TRUE)
fit.fast &lt;- vglm(y ~ x2 + x3, exponential(exp = FALSE), data = edata,
                 trace = TRUE, crit = "coef")
coef(fit.slow, mat = TRUE)
summary(fit.slow)


# Compare results with a GPD. Has a threshold.
threshold &lt;- 0.5
gdata &lt;- data.frame(y1 = threshold + rexp(n = 3000, rate = exp(1.5)))

fit.exp &lt;- vglm(y1 ~ 1, exponential(location = threshold), data = gdata)
coef(fit.exp, matrix = TRUE)
Coef(fit.exp)
logLik(fit.exp)

fit.gpd &lt;- vglm(y1 ~ 1, gpd(threshold =  threshold), data = gdata)
coef(fit.gpd, matrix = TRUE)
Coef(fit.gpd)
logLik(fit.gpd)
</code></pre>

<hr>
<h2 id='exppois'>The Exponential Poisson Distribution</h2><span id='topic+exppois'></span><span id='topic+dexppois'></span><span id='topic+pexppois'></span><span id='topic+qexppois'></span><span id='topic+rexppois'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the exponential poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dexppois(x, rate = 1, shape, log = FALSE)
pexppois(q, rate = 1, shape, lower.tail = TRUE, log.p = FALSE)
qexppois(p, rate = 1, shape, lower.tail = TRUE, log.p = FALSE)
rexppois(n, rate = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exppois_+3A_x">x</code>, <code id="exppois_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="exppois_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="exppois_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the number required.
</p>
</td></tr>
<tr><td><code id="exppois_+3A_shape">shape</code>, <code id="exppois_+3A_rate">rate</code></td>
<td>
<p> positive parameters. </p>
</td></tr>
<tr><td><code id="exppois_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="exppois_+3A_lower.tail">lower.tail</code>, <code id="exppois_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+exppoisson">exppoisson</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters, 
for the formula of the probability density function and other details.
</p>


<h3>Value</h3>

<p><code>dexppois</code> gives the density,
<code>pexppois</code> gives the distribution function,
<code>qexppois</code> gives the quantile function, and
<code>rexppois</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> Kai Huang and J. G. Lauder </p>


<h3>See Also</h3>

<p><code><a href="#topic+exppoisson">exppoisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  rate &lt;- 2; shape &lt;- 0.5; nn &lt;- 201
x &lt;- seq(-0.05, 1.05, len = nn)
plot(x, dexppois(x, rate = rate, shape), type = "l", las = 1, ylim = c(0, 3),
     ylab = paste("fexppoisson(rate = ", rate, ", shape = ", shape, ")"),
     col = "blue", cex.main = 0.8,
     main = "Blue is the density, orange the cumulative distribution function",
     sub = "Purple lines are the 10,20,...,90 percentiles")
lines(x, pexppois(x, rate = rate, shape), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qexppois(probs, rate = rate, shape)
lines(Q, dexppois(Q, rate = rate, shape), col = "purple", lty = 3, type = "h")
lines(Q, pexppois(Q, rate = rate, shape), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3); abline(h = 0, col = "gray50")
max(abs(pexppois(Q, rate = rate, shape) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='exppoisson'>Exponential Poisson Distribution Family Function</h2><span id='topic+exppoisson'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the exponential Poisson distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exppoisson(lrate = "loglink", lshape = "loglink",
           irate = 2, ishape = 1.1,  zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exppoisson_+3A_lshape">lshape</code>, <code id="exppoisson_+3A_lrate">lrate</code></td>
<td>

<p>Link function for the two positive parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="exppoisson_+3A_ishape">ishape</code>, <code id="exppoisson_+3A_irate">irate</code></td>
<td>

<p>Numeric.
Initial values for the <code>shape</code> and <code>rate</code> parameters.
Currently this function is not intelligent enough to
obtain better initial values.
</p>
</td></tr>
<tr><td><code id="exppoisson_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exponential Poisson distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y; \beta = rate, \lambda = shape)  =
  \frac{\lambda \beta}{1 - e^{-\lambda}} \,
  e^{-\lambda - \beta y + \lambda \exp{(-\beta y)}}</code>
</p>

<p>where <code class="reqn">y &gt; 0</code>,
and the parameters shape, <code class="reqn">\lambda</code>,
and rate, <code class="reqn">\beta</code>, are positive.
The distribution implies a population facing discrete
hazard rates which are multiples of a base hazard.
This <span class="pkg">VGAM</span> family function requires the <code>hypergeo</code> package
(to use their <code>genhypergeo</code> function).
The median is returned as the fitted value.
</p>




<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This <span class="pkg">VGAM</span> family function does not work properly!
</p>


<h3>Author(s)</h3>

<p> J. G. Lauder, jamesglauder@gmail.com </p>


<h3>References</h3>

<p>Kus, C., (2007).
A new lifetime distribution.
<em>Computational Statistics and Data Analysis</em>,
<b>51</b>, 4497&ndash;4509.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+dexppois">dexppois</a></code>,
<code><a href="#topic+exponential">exponential</a></code>,
<code><a href="stats.html#topic+poisson">poisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape &lt;- exp(1); rate &lt;- exp(2)
rdata &lt;- data.frame(y = rexppois(n = 1000, rate = rate, shape = shape))
library("hypergeo")  # Required!
fit &lt;- vglm(y ~ 1, exppoisson, data = rdata, trace = FALSE, maxit = 1200)
c(with(rdata, median(y)), head(fitted(fit), 1))
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='Extbetabinom'>The Beta-Binomial Distribution</h2><span id='topic+Extbetabinom'></span><span id='topic+dextbetabinom'></span><span id='topic+pextbetabinom'></span><span id='topic+qextbetabinom'></span><span id='topic+rextbetabinom'></span>

<h3>Description</h3>

<p>Density, distribution function,
quantile function and random generation
for the
extended beta-binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dextbetabinom(x, size, prob, rho = 0,
     log = FALSE, forbycol = TRUE)
pextbetabinom(q, size, prob, rho = 0,
     lower.tail = TRUE, forbycol = TRUE)
qextbetabinom(p, size, prob, rho = 0,
     forbycol = TRUE)
rextbetabinom(n, size, prob, rho = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Extbetabinom_+3A_x">x</code>, <code id="Extbetabinom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Extbetabinom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Extbetabinom_+3A_size">size</code></td>
<td>
<p>number of trials.</p>
</td></tr>
<tr><td><code id="Extbetabinom_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Extbetabinom_+3A_prob">prob</code></td>
<td>

<p>the probability of success <code class="reqn">\mu</code>.
Must be in the unit closed interval <code class="reqn">[0,1]</code>.
</p>
</td></tr>
<tr><td><code id="Extbetabinom_+3A_rho">rho</code></td>
<td>

<p>the correlation parameter <code class="reqn">\rho</code>,
which
may be negative for underdispersion or
else be in the interval <code class="reqn">[0, 1)</code>
for overdispersion.
The default value of 0 corresponds to the
usual binomial distribution with
probability <code>prob</code>.
</p>
</td></tr>
<tr><td><code id="Extbetabinom_+3A_log">log</code>, <code id="Extbetabinom_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>

</td></tr>
<tr><td><code id="Extbetabinom_+3A_forbycol">forbycol</code></td>
<td>

<p>Logical.
A <code>for</code> loop cycles over either the rows or
columns and this argument determines which.
The rows are <code>1:length(x)</code> and the
columns are <code>0:max(size)</code>.
The best choice is data set dependent.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>extended</em> beta-binomial
distribution allows for a slightly negative
correlation parameter between binary
responses within a cluster (e.g., a litter).
An exchangeable error structure with
correlation <code class="reqn">\rho</code> is assumed.
</p>


<h3>Value</h3>

<p><code>dextbetabinom</code> gives the density,
<code>pextbetabinom</code> gives the
distribution function,
<code>qextbetabinom</code> gives the quantile function
and
<code>rextbetabinom</code> generates random
deviates.
</p>


<h3>Warning </h3>

<p>Setting <code>rho = 1</code> is not recommended
as <code>NaN</code> is returned,
however the code may be
modified in the future to handle this
special case.
</p>


<h3>Note</h3>

<p>Currently most of the code is quite slow.
Speed improvements are a future project.
Use <code>forbycol</code> optimally.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extbetabinomial">extbetabinomial</a></code>,
<code><a href="#topic+Betabinom">Betabinom</a></code>,
<code><a href="stats.html#topic+Binomial">Binomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1); rextbetabinom(10, 100, 0.5)
set.seed(1);        rbinom(10, 100, 0.5)  # Same

## Not run: N &lt;- 9; xx &lt;- 0:N; prob &lt;- 0.5; rho &lt;- -0.02
dy &lt;- dextbetabinom(xx, N, prob, rho)
barplot(rbind(dy, dbinom(xx, size = N, prob)),
  beside = TRUE, col = c("blue","green"), las = 1,
  main = paste0("Beta-binom(size=", N, 
  ", prob=", prob, ", rho=", rho, ") (blue) vs\n",
  " Binom(size=", N, ", prob=", prob, ") (green)"),
  names.arg = as.character(xx), cex.main = 0.8)
sum(dy * xx)  # Check expected values are equal
sum(dbinom(xx, size = N, prob = prob) * xx)
cumsum(dy) - pextbetabinom(xx, N, prob, rho)  # 0?

## End(Not run)
</code></pre>

<hr>
<h2 id='extbetabinomial'> Extended
Beta-binomial Distribution Family Function </h2><span id='topic+extbetabinomial'></span>

<h3>Description</h3>

<p>Fits an extended beta-binomial distribution
by maximum
likelihood estimation.  The two parameters
here are the mean and correlation coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extbetabinomial(lmu = "logitlink", lrho = "cloglink", 
      zero = "rho", irho = 0, grho = c(0, 0.05, 0.1, 0.2),
      vfl = FALSE, Form2 = NULL,
      imethod = 1, ishrinkage = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extbetabinomial_+3A_lmu">lmu</code>, <code id="extbetabinomial_+3A_lrho">lrho</code></td>
<td>

<p>Link functions applied to the two parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The first default ensure the mean remain
in <code class="reqn">(0, 1)</code>,
while the second allows for a slightly negative
correlation parameter: you could say it
lies in
<code class="reqn">(\max(-\mu/(N-\mu-1), -(1 - \mu)/(N-(1-\mu)-1)), 1)</code>
where <code class="reqn">\mu</code> is the mean (probability) and
<code class="reqn">N</code> is <code>size</code>.
See below for details.
For <code>lrho</code>, 
<code><a href="#topic+cloglink">cloglink</a></code> is a good choice
because it handles parameter values from 1
downwards.
Other good choices include
<code>logofflink(offset = 1)</code> and
<code><a href="#topic+rhobitlink">rhobitlink</a></code>.
</p>
</td></tr>
<tr><td><code id="extbetabinomial_+3A_irho">irho</code>, <code id="extbetabinomial_+3A_grho">grho</code></td>
<td>

<p>The first is similar to <code><a href="#topic+betabinomial">betabinomial</a></code>
and it is a good idea to use this argument
because to conduct a
grid search based on <code>grho</code> is expensive.
The default is effectively a binomial distribution.
Set <code>irho = NULL</code> to perform a grid search
which is more reliable but slow.
</p>
</td></tr>
<tr><td><code id="extbetabinomial_+3A_imethod">imethod</code></td>
<td>

<p>Similar to <code><a href="#topic+betabinomial">betabinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="extbetabinomial_+3A_zero">zero</code></td>
<td>

<p>Similar to <code><a href="#topic+betabinomial">betabinomial</a></code>.
Also,
see <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for more information.
Modelling <code>rho</code> with covariates requires
large samples.
</p>
</td></tr>
<tr><td><code id="extbetabinomial_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>See <code><a href="#topic+betabinomial">betabinomial</a></code> and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
information.
</p>
</td></tr>
<tr><td><code id="extbetabinomial_+3A_vfl">vfl</code>, <code id="extbetabinomial_+3A_form2">Form2</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
If <code>vfl = TRUE</code> then <code>Form2</code>
should be a formula specifying the terms
for <code class="reqn">\eta_2</code> and all others are
used for <code class="reqn">\mu</code>.
It is similar to <code><a href="#topic+uninormal">uninormal</a></code>.
If these arguments are used then
<code>cbind(0, log(size1 / (size1 - 1)))</code>
should be used as an offset, and
set <code>zero = NULL</code> too.
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>The <em>extended</em> beta-binomial
distribution (EBBD) proposed
by Prentice (1986)
allows for a slightly negative correlation
parameter whereas the ordinary BBD
<code><a href="#topic+betabinomial">betabinomial</a></code>
only allows values in <code class="reqn">(0, 1)</code> so it
handles overdispersion only.
When negative, the data is underdispersed
relative to an ordinary binomial distribution.
</p>
<p>Argument <code>rho</code> is used here for the
<code class="reqn">\delta</code> used in Prentice (1986) because
it is the correlation between the
(almost) Bernoulli trials.
(They are actually simple binary variates.)
We use here  
<code class="reqn">N</code> for the number of trials
(e.g., litter size),
<code class="reqn">T=NY</code> is the number of successes, and
<code class="reqn">p</code> (or <code class="reqn">\mu</code>)
is the probability of a success
(e.g., a malformation).
That is, <code class="reqn">Y</code> is the <em>proportion</em>
of successes. Like
<code><a href="#topic+binomialff">binomialff</a></code>, the fitted values
are the
estimated probability
of success
(i.e., <code class="reqn">E[Y]</code> and not <code class="reqn">E[T]</code>)
and the prior weights <code class="reqn">N</code> are attached
separately on the object in a slot.
</p>
<p>The probability function is difficult
to write but it involves three
series of products.
Recall <code class="reqn">Y = T/N</code> is the real response
being modelled, where <code class="reqn">T</code> is the
(total) sum of <code class="reqn">N</code> correlated
(almost) Bernoulli trials.
</p>
<p>The default model is
<code class="reqn">\eta_1 = logit(\mu)</code>
and <code class="reqn">\eta_2 = clog(\rho)</code>
because the first
parameter lies between 0 and 1.
The second link is <code><a href="#topic+cloglink">cloglink</a></code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">p=\mu</code>
and the variance of <code class="reqn">Y</code> is
<code class="reqn">\mu(1-\mu)(1+(N-1)\rho)/N</code>.
Here, the correlation <code class="reqn">\rho</code>
may be slightly negative
and is the correlation between the <code class="reqn">N</code>
individuals within a litter.
A <em>litter effect</em> is typically reflected
by a positive value of <code class="reqn">\rho</code> and
corresponds to <em>overdispersion</em> with
respect to the binomial distribution.
Thus an <em>exchangeable</em> error structure
is assumed between units within a litter
for the EBBD.
</p>
<p>This family function uses Fisher scoring.
Elements of the second-order expected
derivatives 
are computed numerically, which may
fail for models very near the boundary of the
parameter space.
Usually, the computations
are expensive for large <code class="reqn">N</code> because of
a <code>for</code> loop, so
it may take a long time.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>.
</p>
<p>Suppose <code>fit</code> is a fitted EBB
model. Then <code>depvar(fit)</code>
are the sample proportions <code class="reqn">y</code>,
<code>fitted(fit)</code> returns
estimates of <code class="reqn">E(Y)</code>,
and <code>weights(fit, type = "prior")</code> returns
the number of trials <code class="reqn">N</code>.
</p>


<h3>Warning </h3>

<p>Modelling <code>rho</code> using covariates well
requires much data
so it is usually best to leave <code>zero</code>
alone.
It is good to set <code>trace = TRUE</code> and
play around with <code>irho</code> if there are
problems achieving convergence.
Convergence problems will occur when the
estimated <code>rho</code> is close to the
lower bound,
i.e., the underdispersion
is almost too severe for the EBB to cope.
</p>


<h3>Note</h3>

<p>This function is recommended over
<code><a href="#topic+betabinomial">betabinomial</a></code> and
<code><a href="#topic+betabinomialff">betabinomialff</a></code>.
It processes the input in the
same way as <code><a href="#topic+binomialff">binomialff</a></code>.
But it does not handle the case <code class="reqn">N \leq 2</code>
very well because there are two parameters to
estimate, not one, for each row of the input.
Cases where <code class="reqn">N &gt; 2</code>
can be selected via the
<code>subset</code> argument of <code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Prentice, R. L. (1986).
Binary regression using an extended beta-binomial
distribution,
with discussion of correlation induced by
covariate measurement errors.
<em>Journal of the American Statistical
Association</em>,
<b>81</b>, 321&ndash;327.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Extbetabinom">Extbetabinom</a></code>,
<code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+dirmultinomial">dirmultinomial</a></code>,
<code><a href="#topic+cloglink">cloglink</a></code>,
<code><a href="#topic+lirat">lirat</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
edata &lt;- data.frame(N = 10, mu = 0.5, rho = 0.1)
edata &lt;- transform(edata,
      y = rextbetabinom(100, N, mu, rho = rho))
fit1 &lt;- vglm(cbind(y, N-y) ~ 1, extbetabinomial, edata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
head(cbind(depvar(fit1), weights(fit1, type = "prior")))

# Example 2: VFL model
## Not run: N &lt;- size1 &lt;- 10; nn &lt;- 2000; set.seed(1)
edata &lt;-  # Generate the data set. Expensive.
    data.frame(x2 = runif(nn),
               ooo =  log(size1 / (size1 - 1)))
edata &lt;- transform(edata, x1copy = 1, x2copy = x2,
  y2 = rextbetabinom(nn, size1,  # Expensive
         logitlink(1 + x2, inverse = TRUE),
         cloglink(ooo + 1 - 0.5 * x2, inv = TRUE)))
fit2 &lt;- vglm(data = edata,
        cbind(y2, N - y2) ~ x2 + x1copy + x2copy,
        extbetabinomial(zero = NULL, vfl = TRUE,
                 Form2 = ~ x1copy + x2copy - 1),
        offset = cbind(0, ooo), trace = TRUE)
coef(fit2, matrix = TRUE)
wald.stat(fit2, values0 = c(1, 1, -0.5))

## End(Not run)</code></pre>

<hr>
<h2 id='extlogF1'> Extended log-F Distribution
Family Function
</h2><span id='topic+extlogF1'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of
the 1-parameter extended log-F distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> extlogF1(tau = c(0.25, 0.5, 0.75), parallel = TRUE ~ 0,
          seppar = 0, tol0 = -0.001,
          llocation = "identitylink", ilocation = NULL,
          lambda.arg = NULL, scale.arg = 1, ishrinkage = 0.95,
          digt = 4, idf.mu = 3, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extlogF1_+3A_tau">tau</code></td>
<td>

<p>Numeric, the desired quantiles. A strictly increasing sequence,
each value must be in <code class="reqn">(0, 1)</code>.
The default values are the three quartiles, matching
<code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="extlogF1_+3A_parallel">parallel</code></td>
<td>

<p>Similar to <code><a href="#topic+alaplace1">alaplace1</a></code>, applying to the
location parameters.
One can try fix up the quantile-crossing problem after fitting
the model by calling <code><a href="#topic+fix.crossing">fix.crossing</a></code>.
Use <code><a href="#topic+is.crossing">is.crossing</a></code> to see if there is a problem.
The default for <code>parallel</code> is totally <code>FALSE</code>, i.e.,
<code>FALSE</code> for every variable including the intercept.
Quantile-crossing can occur when values of <code>tau</code> are too
close, given the data. How the quantiles are modelled with
respect to the covariates also has a big effect, e.g.,
if they are too flexible or too inflexible then the problem
is likely to occur.
For example, using <code><a href="splines.html#topic+bs">bs</a></code> with
<code>df = 10</code> is likely to create problems.
</p>
<p>Setting <code>parallel = TRUE</code> results in a totally
parallel model; <em>all</em> quantiles are parallel
and this assumption can be too strong for some data sets.
Instead, <code><a href="#topic+fix.crossing">fix.crossing</a></code> only repairs the
quantiles that cross.
So one must carefully choose values of <code>tau</code> for
fitting the original fit.
</p>







</td></tr>
<tr><td><code id="extlogF1_+3A_seppar">seppar</code>, <code id="extlogF1_+3A_tol0">tol0</code></td>
<td>

<p>Numeric, both of unit length and nonnegative,
the separation and shift parameters.
If <code>seppar</code> is positive then any crossing quantile
is penalized by the difference cubed multiplied by <code>seppar</code>.
The log-likelihood subtracts the penalty.
The shift parameter ensures that the result is strictly
noncrossing when <code>seppar</code> is large enough; otherwise
if <code>tol0 = 0</code> and <code>seppar</code> is large
then the crossing quantiles remain
crossed even though the offending amount becomes small but never
exactly 0.
Informally, <code>tol0</code> pushes the adjustment enough
so that <code><a href="#topic+is.crossing">is.crossing</a></code> should return <code>FALSE</code>.
</p>
<p>If <code>tol0</code> is positive then that is the shift in absolute
terms. But <code>tol0</code> may be assigned a negative value, in
which case it is interpreted multiplicatively
<em>relative</em> to the midspread of the response;
<code>tol0 &lt;- abs(tol0) * midspread</code>.
Regardless,
<code>fit@extra$tol0</code> is the amount in absolute terms.
</p>
<p>If avoiding the quantile crossing problem is of concern to you,
try increasing <code>seppar</code> to decrease the amount of crossing.
Probably it is best to choose the smallest value of <code>seppar</code>
so that <code><a href="#topic+is.crossing">is.crossing</a></code> returns <code>FALSE</code>.
Increasing <code>tol0</code> relatively or absolutely
means the fitted quantiles are
allowed to move apart more.
However, <code>tau</code> must be considered when choosing <code>tol0</code>.
</p>
</td></tr>











<tr><td><code id="extlogF1_+3A_llocation">llocation</code>, <code id="extlogF1_+3A_ilocation">ilocation</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code> for more choices and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
Choosing <code><a href="#topic+loglink">loglink</a></code> should usually be good
for counts.
And choosing <code><a href="#topic+logitlink">logitlink</a></code> should be a reasonable for
proportions. However, avoid choosing <code>tau</code> values close to
the boundary, for example, if <code class="reqn">p_0</code> is the proportion of
0s then choose <code class="reqn">p_0 \ll \tau</code>.
For proportions grouped data is much better than ungrouped data,
and the bigger the groups the more the
granularity so that the empirical proportion can approximate
<code>tau</code> more closely.
</p>
</td></tr>
<tr><td><code id="extlogF1_+3A_lambda.arg">lambda.arg</code></td>
<td>

<p>Positive tuning parameter which controls the sharpness of the cusp.
The limit as it approaches 0 is probably very similar to
<code><a href="#topic+dalap">dalap</a></code>.
The default is to choose the value internally.
If <code>scale.arg</code> increases, then probably <code>lambda.arg</code>
needs to increase accordingly.
If <code>lambda.arg</code> is too large then the empirical quantiles
may not be very close to <code>tau</code>.
If <code>lambda.arg</code> is too close to 0 then the convergence
behaviour will not be good and local solutions found, as well
as numerical problems in general.
Monitoring convergence is recommended when varying
<code>lambda.arg</code>.
</p>
</td></tr>
<tr><td><code id="extlogF1_+3A_scale.arg">scale.arg</code></td>
<td>

<p>Positive scale parameter and sometimes called <code>scale</code>.
The transformation used is <code>(y - location) / scale</code>.
This function should be okay for response variables
having a moderate range (0&ndash;100, say), but if very different
from this then experimenting with this argument will be
a good idea.
</p>
</td></tr>
<tr><td><code id="extlogF1_+3A_ishrinkage">ishrinkage</code>, <code id="extlogF1_+3A_idf.mu">idf.mu</code>, <code id="extlogF1_+3A_digt">digt</code></td>
<td>

<p>Similar to <code><a href="#topic+alaplace1">alaplace1</a></code>.
</p>

</td></tr>
<tr><td><code id="extlogF1_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method.
Either the value 1, 2, or ....
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an experimental family function for quantile regression.
Fasiolo et al. (2020) propose an <em>extended</em> log-F distribution
(ELF)
however this family function only estimates the location parameter.
The distribution has a scale parameter which can be inputted
(default value is unity).
One location parameter is estimated for each <code>tau</code> value
and these are the estimated quantiles.
For quantile regression it is not necessary to estimate
the scale parameter since the log-likelihood function is
triangle shaped.
</p>
<p>The ELF is used as an approximation of the asymmetric Laplace
distribution (ALD).
The latter cannot be estimated properly using Fisher scoring/IRLS
but the ELF holds promise because it has continuous derivatives
and therefore fewer problems with the regularity conditions.
Because the ELF is fitted to data to obtain an
empirical result the convergence behaviour may not be gentle
and smooth.
Hence there is a function-specific control function called
<code>extlogF1.control</code> which has something like
<code>stepsize = 0.5</code> and <code>maxits = 100</code>.
It has been found that
slowing down the rate of convergence produces greater
stability during the estimation process.
Regardless, convergence should be monitored carefully always.
</p>
<p>This function accepts a vector response but not a matrix response.
</p>





<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Changes will occur in the future to fine-tune things.
In general
setting <code>trace = TRUE</code> is strongly encouraged because it is
needful to check that convergence occurs properly.
</p>
<p>If <code>seppar &gt; 0</code> then <code>logLik(fit)</code> will return the
penalized log-likelihood.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S. N., Zaffran, M.,
Nedellec, R. and Goude, Y. (2020).
Fast calibrated additive quantile regression.
<em>J. Amer. Statist. Assoc.</em>,
in press.
</p>
<p>Yee, T. W. (2020).
On quantile regression based on the 1-parameter extended
log-F distribution.
<em>In preparation</em>.
</p>




<h3>See Also</h3>

<p><code><a href="#topic+dextlogF">dextlogF</a></code>,
<code><a href="#topic+is.crossing">is.crossing</a></code>,
<code><a href="#topic+fix.crossing">fix.crossing</a></code>,
<code><a href="#topic+eCDF">eCDF</a></code>,
<code><a href="#topic+vglm.control">vglm.control</a></code>,
<code><a href="#topic+logF">logF</a></code>,
<code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+dalap">dalap</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000; mytau &lt;- c(0.25, 0.75)
edata &lt;- data.frame(x2 = sort(rnorm(nn)))
edata &lt;- transform(edata, y1 = 1 + x2  + rnorm(nn, sd = exp(-1)),
          y2 = cos(x2) / (1 + abs(x2)) + rnorm(nn, sd = exp(-1)))
fit1 &lt;- vglm(y1 ~ x2, extlogF1(tau = mytau), data = edata)  # trace = TRUE
fit2 &lt;- vglm(y2 ~ bs(x2, 6), extlogF1(tau = mytau), data = edata)
coef(fit1, matrix = TRUE)
fit2@extra$percentile  # Empirical percentiles here
summary(fit2)
c(is.crossing(fit1), is.crossing(fit2))
head(fitted(fit1))
## Not run: plot(y2 ~ x2, edata, col = "blue")
matlines(with(edata, x2), fitted(fit2), col="orange", lty = 1, lwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='familyname'> Family Function Name </h2><span id='topic+familyname'></span><span id='topic+familyname.vlm'></span><span id='topic+familyname.vglmff'></span>

<h3>Description</h3>

<p>Extractor function for the name of the family function of an object
in the <span class="pkg">VGAM</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>familyname(object, ...)
familyname.vlm(object, all = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="familyname_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>
</td></tr>
<tr><td><code id="familyname_+3A_all">all</code></td>
<td>

<p>If <code>all = TRUE</code> then all of the <code>vfamily</code> slot is returned;
this contains subclasses the object might have.
The default is the return the first value only.
</p>
</td></tr>
<tr><td><code id="familyname_+3A_...">...</code></td>
<td>

<p>Other possible arguments for the future.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently <span class="pkg">VGAM</span> implements over 150 family functions.
This function returns the name of the function assigned
to the <code>family</code> argument, for modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
Sometimes a slightly different answer is returned, e.g.,
<code><a href="#topic+propodds">propodds</a></code> really calls <code><a href="#topic+cumulative">cumulative</a></code>
with some arguments set, hence the output returned by
this function is <code>"cumulative"</code> (note that one day
this might change, however).
</p>


<h3>Value</h3>

<p>A character string or vector.
</p>


<h3>Note</h3>

<p>Arguments used in the invocation are not included.
Possibly this is something to be done in the future.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = TRUE, reverse = TRUE), data = pneumo)
familyname(fit1)
familyname(fit1, all = TRUE)
familyname(propodds())  # "cumulative"
</code></pre>

<hr>
<h2 id='felix'>Felix Distribution Family Function</h2><span id='topic+felix'></span>

<h3>Description</h3>

<p>Estimates the parameter of a Felix distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>felix(lrate = extlogitlink(min = 0, max = 0.5), imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="felix_+3A_lrate">lrate</code></td>
<td>

<p>Link function for the parameter,
called <code class="reqn">a</code> below;
see <code><a href="#topic+Links">Links</a></code> for more choices and for general information.
</p>
</td></tr>
<tr><td><code id="felix_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
Valid values are 1, 2, 3 or 4.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Felix distribution is an important basic Lagrangian distribution.
The density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y;a) =
  \frac{ 1 }{((y-1)/2)!} y^{(y-3)/2} a^{(y-1)/2}  \exp(-ay)
  </code>
</p>

<p>where <code class="reqn">y=1,3,5,\ldots</code> and
<code class="reqn">0 &lt; a &lt; 0.5</code>.
The mean is <code class="reqn">1/(1-2a)</code> (returned as the fitted values).
Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Consul, P. C. and Famoye, F. (2006).
<em>Lagrangian Probability Distributions</em>,
Boston, USA: Birkhauser.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dfelix">dfelix</a></code>,
<code><a href="#topic+borel.tanner">borel.tanner</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fdata &lt;- data.frame(y = 2 * rpois(n = 200, 1) + 1)  # Not real data!
fit &lt;- vglm(y ~ 1, felix, data = fdata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Felix'>The Felix Distribution</h2><span id='topic+Felix'></span><span id='topic+dfelix'></span>

<h3>Description</h3>

<p>Density
for the
Felix distribution.
</p>




<h3>Usage</h3>

<pre><code class='language-R'>dfelix(x, rate = 0.25, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Felix_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>



<tr><td><code id="Felix_+3A_rate">rate</code></td>
<td>
<p> See <code><a href="#topic+felix">felix</a></code>.
</p>
</td></tr>
<tr><td><code id="Felix_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+felix">felix</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter,
for the formula of the probability density function and other
details.
</p>


<h3>Value</h3>

<p><code>dfelix</code> gives the density.
</p>





<h3>Warning </h3>

<p>The default value of <code>rate</code> is subjective.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+felix">felix</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
rate &lt;- 0.25; x &lt;- 1:15
plot(x, dfelix(x, rate), type = "h", las = 1, col = "blue",
     ylab = paste("dfelix(rate=", rate, ")"),
     main = "Felix density function")

## End(Not run)
</code></pre>

<hr>
<h2 id='fff'> F Distribution Family Function </h2><span id='topic+fff'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the
(2-parameter) F distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fff(link = "loglink", idf1 = NULL, idf2 = NULL, nsimEIM = 100,
    imethod = 1, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fff_+3A_link">link</code></td>
<td>

<p>Parameter link function for both parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The default keeps the parameters positive.
</p>
</td></tr>
<tr><td><code id="fff_+3A_idf1">idf1</code>, <code id="fff_+3A_idf2">idf2</code></td>
<td>

<p>Numeric and positive.
Initial value for the parameters.
The default is to choose each value internally.
</p>
</td></tr>
<tr><td><code id="fff_+3A_nsimeim">nsimEIM</code>, <code id="fff_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="fff_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method. Either the value 1 or 2.
If both fail try setting values for
<code>idf1</code> and <code>idf2</code>.
</p>
</td></tr>










</table>


<h3>Details</h3>

<p>The F distribution is named after Fisher and has
a density function
that has two parameters, called <code>df1</code>
and <code>df2</code> here.
This function treats these degrees of freedom
as <em>positive reals</em>
rather than integers.
The mean of the distribution is
<code class="reqn">df2/(df2-2)</code> provided <code class="reqn">df2&gt;2</code>,
and its variance is
<code class="reqn">2 df2^2 (df1+df2-2)/(df1 (df2-2)^2 (df2-4))</code>
provided <code class="reqn">df2&gt;4</code>.
The estimated mean is returned as the fitted values.
Although the F distribution can be defined to accommodate a
non-centrality parameter <code>ncp</code>, it is assumed zero here.
Actually it shouldn't be too difficult to handle any known
<code>ncp</code>; something to do in the short future.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>Numerical problems will occur when the estimates
of the parameters
are too low or too high.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Fdist">FDist</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fdata &lt;- data.frame(x2 = runif(nn &lt;- 2000))
fdata &lt;- transform(fdata, df1 = exp(2+0.5*x2),
                          df2 = exp(2-0.5*x2))
fdata &lt;- transform(fdata, y   = rf(nn, df1, df2))
fit &lt;- vglm(y  ~ x2, fff, data = fdata, trace = TRUE)
coef(fit, matrix = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='fill1'> Creates a Matrix of Appropriate Dimension </h2><span id='topic+fill1'></span>

<h3>Description</h3>

<p>A support function for the argument <code>xij</code>,
it generates a matrix
of an appropriate dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fill1(x, values = 0, ncolx = ncol(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fill1_+3A_x">x</code></td>
<td>

<p>A vector or matrix which is used to determine
the dimension of the
answer, in particular, the number of rows.
After converting <code>x</code>
to a matrix if necessary, the answer is a
matrix of <code>values</code>
values, of dimension <code>nrow(x)</code> by <code>ncolx</code>.
</p>
</td></tr>
<tr><td><code id="fill1_+3A_values">values</code></td>
<td>

<p>Numeric.
The answer contains these values,
which are recycled <em>columnwise</em> if necessary, i.e.,
as <code>matrix(values, ..., byrow=TRUE)</code>.
</p>
</td></tr>
<tr><td><code id="fill1_+3A_ncolx">ncolx</code></td>
<td>

<p>The number of columns of the returned matrix.
The default is the number of columns of <code>x</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>xij</code> argument for <code><a href="#topic+vglm">vglm</a></code> allows
the user to input
variables specific to each linear/additive predictor.
For example, consider
the bivariate logit model where the
first/second linear/additive
predictor is the logistic regression of the
first/second binary response
respectively. The third linear/additive predictor
is <code>log(OR) =
    eta3</code>, where <code>OR</code> is the odds ratio.
If one has ocular pressure
as a covariate in this model then <code>xij</code>
is required to handle the
ocular pressure for each eye, since these will
be different in general.
[This contrasts with a variable such
as <code>age</code>, the age of the
person, which has a common value for both eyes.]
In order to input
these data into <code><a href="#topic+vglm">vglm</a></code> one often
finds that functions
<code>fill1</code>, <code>fill2</code>, etc. are useful.
</p>
<p>All terms in the <code>xij</code>
and <code>formula</code> arguments in <code><a href="#topic+vglm">vglm</a></code>
must appear in the <code>form2</code> argument too.
</p>


<h3>Value</h3>

<p><code>matrix(values, nrow=nrow(x), ncol=ncolx)</code>,
i.e., a matrix
consisting of values <code>values</code>,
with the number of rows matching
<code>x</code>, and the default number of columns
is the number of columns
of <code>x</code>.
</p>


<h3>Note</h3>

<p>The effect of the <code>xij</code> argument is after
other arguments such as
<code>exchangeable</code> and <code>zero</code>.
Hence <code>xij</code> does not affect constraint matrices.
</p>
<p>Additionally, there are currently 3 other
identical <code>fill1</code>
functions, called <code>fill2</code>, <code>fill3</code> and <code>fill4</code>;
if you need more then assign <code>fill5 = fill6 = fill1</code> etc.
The reason for this is that if more than
one <code>fill1</code> function is
needed then they must be unique.
For example, if <code class="reqn">M=4</code> then
<code>xij = list(op ~ lop + rop + fill1(mop) + fill1(mop))</code>
would reduce to
<code>xij = list(op ~ lop + rop + fill1(mop))</code>, whereas
<code>xij = list(op ~ lop + rop + fill1(mop) + fill2(mop))</code>
would retain
all <code class="reqn">M</code> terms, which is needed.
</p>



<p>In Examples 1 to 3 below, the <code>xij</code> argument
illustrates covariates
that are specific to a linear predictor.
Here, <code>lop</code>/<code>rop</code> are
the ocular pressures of the left/right eye
in an artificial dataset,
and <code>mop</code> is their mean.
Variables <code>leye</code> and <code>reye</code>
might be the presence/absence of a particular
disease on the LHS/RHS
eye respectively.
</p>






<p>In Example 3, the <code>xij</code> argument illustrates fitting the
(exchangeable) model where there is a common smooth function
of the
ocular pressure. One should use regression splines since
<code><a href="#topic+s">s</a></code> in <code><a href="#topic+vgam">vgam</a></code> does not handle
the <code>xij</code>
argument.  However, regression splines such as
<code><a href="splines.html#topic+bs">bs</a></code> and <code><a href="splines.html#topic+ns">ns</a></code> need
to have
the same basis functions here for both functions, and Example 3
illustrates a trick involving a function <code>BS</code> to obtain this,
e.g., same knots.  Although regression splines create more than a
single column per term in the model matrix,
<code>fill1(BS(lop,rop))</code>
creates the required (same) number of columns.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm.control">vglm.control</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+Select">Select</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fill1(runif(5))
fill1(runif(5), ncol = 3)
fill1(runif(5), val = 1, ncol = 3)

# Generate (independent) eyes data for the examples below; OR=1.
nn &lt;- 1000  # Number of people
eyesdata &lt;- data.frame(lop = round(runif(nn), 2),
                       rop = round(runif(nn), 2),
                       age = round(rnorm(nn, 40, 10)))
eyesdata &lt;- transform(eyesdata,
  mop = (lop + rop) / 2,        # Mean ocular pressure
  op  = (lop + rop) / 2,        # Value unimportant unless plotting
# op  =  lop,                   # Choose this if plotting
  eta1 = 0 - 2*lop + 0.04*age,  # Linear predictor for left eye
  eta2 = 0 - 2*rop + 0.04*age)  # Linear predictor for right eye
eyesdata &lt;- transform(eyesdata,
  leye = rbinom(nn, size=1, prob = logitlink(eta1, inverse = TRUE)),
  reye = rbinom(nn, size=1, prob = logitlink(eta2, inverse = TRUE)))

# Example 1. All effects are linear.
fit1 &lt;- vglm(cbind(leye,reye) ~ op + age,
             family = binom2.or(exchangeable = TRUE, zero = 3),
             data = eyesdata, trace = TRUE,
             xij = list(op ~ lop + rop + fill1(lop)),
             form2 =  ~ op + lop + rop + fill1(lop) + age)
head(model.matrix(fit1, type = "lm"))   # LM model matrix
head(model.matrix(fit1, type = "vlm"))  # Big VLM model matrix
coef(fit1)
coef(fit1, matrix = TRUE)  # Unchanged with 'xij'
constraints(fit1)
max(abs(predict(fit1)-predict(fit1, new = eyesdata)))  # Okay
summary(fit1)
## Not run: 
plotvgam(fit1,
     se = TRUE)  # Wrong, e.g., coz it plots against op, not lop.
# So set op = lop in the above for a correct plot.

## End(Not run)

# Example 2. This uses regression splines on ocular pressure.
# It uses a trick to ensure common basis functions.
BS &lt;- function(x, ...)
  sm.bs(c(x,...), df = 3)[1:length(x), , drop = FALSE]  # trick

fit2 &lt;-
  vglm(cbind(leye,reye) ~ BS(lop,rop) + age,
       family = binom2.or(exchangeable = TRUE, zero = 3),
       data = eyesdata, trace = TRUE,
       xij = list(BS(lop,rop) ~ BS(lop,rop) +
                                BS(rop,lop) +
                                fill1(BS(lop,rop))),
       form2 = ~  BS(lop,rop) + BS(rop,lop) + fill1(BS(lop,rop)) +
                        lop + rop + age)
head(model.matrix(fit2, type =  "lm"))  # LM model matrix
head(model.matrix(fit2, type = "vlm"))  # Big VLM model matrix
coef(fit2)
coef(fit2, matrix = TRUE)
summary(fit2)
fit2@smart.prediction
max(abs(predict(fit2) - predict(fit2, new = eyesdata)))  # Okay
predict(fit2, new = head(eyesdata))  # OR is 'scalar' as zero=3
max(abs(head(predict(fit2)) -
             predict(fit2, new = head(eyesdata))))  # Should be 0
## Not run: 
plotvgam(fit2, se = TRUE, xlab = "lop")  # Correct

## End(Not run)

# Example 3. Capture-recapture model with ephemeral and enduring
# memory effects. Similar to Yang and Chao (2005), Biometrics.
deermice &lt;- transform(deermice, Lag1 = y1)
M.tbh.lag1 &lt;-
  vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + weight + Lag1,
       posbernoulli.tb(parallel.t = FALSE ~ 0,
                       parallel.b = FALSE ~ 0,
                       drop.b = FALSE ~ 1),
       xij = list(Lag1 ~ fill1(y1) + fill1(y2) + fill1(y3) +
                         fill1(y4) + fill1(y5) + fill1(y6) +
                         y1 + y2 + y3 + y4 + y5),
       form2 = ~ sex + weight + Lag1 +
                 fill1(y1) + fill1(y2) + fill1(y3) + fill1(y4) +
                 fill1(y5) + fill1(y6) +
                 y1 + y2 + y3 + y4 + y5 + y6,
       data = deermice, trace = TRUE)
coef(M.tbh.lag1)
</code></pre>

<hr>
<h2 id='finney44'> Toxicity trial for insects

</h2><span id='topic+finney44'></span>

<h3>Description</h3>

<p>A data frame of a toxicity trial.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>data(finney44)</code></pre>


<h3>Format</h3>

<p>A data frame with 6 observations on the following 3 variables.
</p>

<dl>
<dt><code>pconc</code></dt><dd><p>a numeric vector, percent concentration
of pyrethrins. </p>
</dd>
<dt><code>hatched</code></dt><dd><p>number of eggs that hatched. </p>
</dd>
<dt><code>unhatched</code></dt><dd><p>number of eggs that did not hatch. </p>
</dd>
</dl>



<h3>Details</h3>

<p>Finney (1944) describes a toxicity trial of five different
concentrations of pyrethrins (percent) plus a control that were
administered to eggs of <em>Ephestia kuhniella</em>.
The natural mortality rate is large, and a common adjustment
is to use Abbott's formula.
</p>


<h3>References</h3>

<p>Finney, D. J. (1944).
The application of the probit method to toxicity test
data adjusted for mortality in the controls.
<em>Annals of Applied Biology</em>, <b>31</b>, 68&ndash;74.
</p>
<p>Abbott, W. S. (1925).
A method of computing the effectiveness of an insecticide.
<em>Journal of Economic Entomology</em>, 18, 265&ndash;7.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>data(finney44)
transform(finney44, mortality = unhatched / (hatched + unhatched))
</code></pre>

<hr>
<h2 id='fisherzlink'> Fisher's Z Link Function </h2><span id='topic+fisherzlink'></span>

<h3>Description</h3>

<p>Computes the Fisher Z transformation, including its
inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisherzlink(theta, bminvalue = NULL, bmaxvalue = NULL,
            inverse = FALSE, deriv = 0, short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fisherzlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="fisherzlink_+3A_bminvalue">bminvalue</code>, <code id="fisherzlink_+3A_bmaxvalue">bmaxvalue</code></td>
<td>

<p>Optional boundary values.
Values of <code>theta</code> which are less than or equal
to <code class="reqn">-1</code> can be
replaced by <code>bminvalue</code>
before computing the link function value.
Values of <code>theta</code> which are greater than or equal
to <code class="reqn">1</code> can be
replaced by <code>bmaxvalue</code>
before computing the link function value.
See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="fisherzlink_+3A_inverse">inverse</code>, <code id="fisherzlink_+3A_deriv">deriv</code>, <code id="fisherzlink_+3A_short">short</code>, <code id="fisherzlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>fisherz</code> link function is commonly used for
parameters that
lie between <code class="reqn">-1</code> and <code class="reqn">1</code>.
Numerical values of <code>theta</code> close
to <code class="reqn">-1</code> or <code class="reqn">1</code> or
out of range result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>,
<code>0.5 * log((1+theta)/(1-theta))</code>
(same as <code>atanh(theta)</code>)
when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>(exp(2*theta)-1)/(exp(2*theta)+1)</code>
(same as <code>tanh(theta)</code>).
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as
a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms,
i.e., to base <em>e</em>.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code>
is close to <code class="reqn">-1</code> or
<code class="reqn">1</code>.
One way of overcoming this is to use,
e.g., <code>bminvalue</code>.
</p>
<p>The link function <code><a href="#topic+rhobitlink">rhobitlink</a></code> is
very similar to <code>fisherzlink</code>,
e.g., just twice the value of <code>fisherzlink</code>.
This link function may be renamed to <code>atanhlink</code>
in the near future.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>,
2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+rhobitlink">rhobitlink</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>theta &lt;- seq(-0.99, 0.99, by = 0.01)
y &lt;- fisherzlink(theta)
## Not run:  plot(theta, y, type = "l", las = 1, ylab = "",
   main = "fisherzlink(theta)", col = "blue")
abline(v = (-1):1, h = 0, lty = 2, col = "gray") 
## End(Not run)

x &lt;- c(seq(-1.02, -0.98, by = 0.01), seq(0.97, 1.02, by = 0.01))
fisherzlink(x)  # Has NAs
fisherzlink(x, bminvalue = -1 + .Machine$double.eps,
               bmaxvalue =  1 - .Machine$double.eps)  # Has no NAs
</code></pre>

<hr>
<h2 id='fisk'> Fisk Distribution family function </h2><span id='topic+fisk'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
Fisk distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fisk(lscale = "loglink", lshape1.a = "loglink", iscale = NULL,
    ishape1.a = NULL, imethod = 1, lss = TRUE,
    gscale = exp(-5:5), gshape1.a = seq(0.75, 4, by = 0.25),
    probs.y = c(0.25, 0.5, 0.75), zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fisk_+3A_lss">lss</code></td>
<td>
<p> See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
important information.
</p>
</td></tr>
<tr><td><code id="fisk_+3A_lshape1.a">lshape1.a</code>, <code id="fisk_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code class="reqn">a</code> and <code>scale</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="fisk_+3A_iscale">iscale</code>, <code id="fisk_+3A_ishape1.a">ishape1.a</code>, <code id="fisk_+3A_imethod">imethod</code>, <code id="fisk_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>iscale</code> is needed to obtain a good estimate for
the other parameter.
</p>
</td></tr>
<tr><td><code id="fisk_+3A_gscale">gscale</code>, <code id="fisk_+3A_gshape1.a">gshape1.a</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="fisk_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 2-parameter Fisk (aka log-logistic) distribution
is the 4-parameter
generalized beta II distribution with
shape parameter <code class="reqn">q=p=1</code>.
It is also the 3-parameter Singh-Maddala distribution
with shape parameter <code class="reqn">q=1</code>, as well as the
Dagum distribution with <code class="reqn">p=1</code>.
More details can be found in Kleiber and Kotz (2003).
</p>
<p>The Fisk distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = a y^{a-1} / [b^a \{1 + (y/b)^a\}^2]</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and <code class="reqn">a</code> is a shape parameter.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y) = 1 - [1 + (y/b)^a]^{-1} = [1 + (y/b)^{-a}]^{-1}.</code>
</p>

<p>The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(1 + 1/a) \, \Gamma(1 - 1/a)</code>
</p>

<p>provided <code class="reqn">a &gt; 1</code>; these are returned as the fitted values.
This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in
Economics and Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>








<h3>See Also</h3>

<p><code><a href="#topic+Fisk">Fisk</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fdata &lt;- data.frame(y = rfisk(200, shape = exp(1), exp(2)))
fit &lt;- vglm(y ~ 1, fisk(lss = FALSE), data = fdata, trace = TRUE)
fit &lt;- vglm(y ~ 1, fisk(ishape1.a = exp(2)), fdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Fisk'>The Fisk Distribution</h2><span id='topic+Fisk'></span><span id='topic+dfisk'></span><span id='topic+pfisk'></span><span id='topic+qfisk'></span><span id='topic+rfisk'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Fisk distribution with
shape parameter <code>a</code>
and scale parameter <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfisk(x, scale = 1, shape1.a, log = FALSE)
pfisk(q, scale = 1, shape1.a, lower.tail = TRUE, log.p = FALSE)
qfisk(p, scale = 1, shape1.a, lower.tail = TRUE, log.p = FALSE)
rfisk(n, scale = 1, shape1.a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fisk_+3A_x">x</code>, <code id="Fisk_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be
the number required.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_shape1.a">shape1.a</code></td>
<td>
<p>shape parameter.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Fisk_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the
density is returned.
</p>
</td></tr>
<tr><td><code id="Fisk_+3A_lower.tail">lower.tail</code>, <code id="Fisk_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+fisk">fisk</a></code>, which is the <span class="pkg">VGAM</span> family function
for estimating the parameters by maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>dfisk</code> gives the density,
<code>pfisk</code> gives the distribution function,
<code>qfisk</code> gives the quantile function, and
<code>rfisk</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Fisk distribution is a special case of the 4-parameter
generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fdata &lt;- data.frame(y = rfisk(1000, shape = exp(1), scale = exp(2)))
fit &lt;- vglm(y ~ 1, fisk(lss = FALSE), data = fdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='fittedvlm'>Fitted Values of a VLM object</h2><span id='topic+fittedvlm'></span><span id='topic+fitted.values.vlm'></span>

<h3>Description</h3>

<p>Extractor function for the fitted values of a model object that
inherits from a <em>vector linear model</em> (VLM), e.g.,
a model of class <code>"vglm"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fittedvlm(object, drop = FALSE, type.fitted = NULL,
          percentiles = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fittedvlm_+3A_object">object</code></td>
<td>

<p>a model object that inherits from a VLM.
</p>
</td></tr>
<tr><td><code id="fittedvlm_+3A_drop">drop</code></td>
<td>

<p>Logical.
If <code>FALSE</code> then the answer is a matrix.
If <code>TRUE</code> then the answer is a vector.
</p>
</td></tr>




<tr><td><code id="fittedvlm_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Character.
Some <span class="pkg">VGAM</span> family functions have a <code>type.fitted</code>
argument.
If so then a different type of fitted value can be returned.
It is recomputed from the model after convergence.
Note: this is an experimental feature and not all
<span class="pkg">VGAM</span> family functions have this implemented yet.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="fittedvlm_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
<tr><td><code id="fittedvlm_+3A_...">...</code></td>
<td>

<p>Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &ldquo;fitted values&rdquo; usually corresponds to the mean response,
however, because the <span class="pkg">VGAM</span> package fits so many models,
this sometimes refers to quantities such as quantiles.
The mean may even not exist, e.g., for a Cauchy distribution.
</p>
<p>Note that the fitted value is output from
the <code>@linkinv</code> slot
of the <span class="pkg">VGAM</span> family function,
where the <code>eta</code> argument is
the <code class="reqn">n \times M</code> matrix
of linear predictors.
</p>


<h3>Value</h3>

<p>The fitted values evaluated at the final IRLS iteration.
</p>


<h3>Note</h3>

<p>This function is one of several extractor functions for
the <span class="pkg">VGAM</span> package. Others include <code>coef</code>,
<code>deviance</code>, <code>weights</code> and <code>constraints</code> etc.
This function is equivalent to the methods function for the
generic function <code>fitted.values</code>.
</p>
<p>If <code>fit</code> is a VLM or VGLM then <code>fitted(fit)</code> and
<code>predict(fit, type = "response")</code> should be equivalent
(see <code><a href="#topic+predictvglm">predictvglm</a></code>).
The latter has the advantage in that it handles a <code>newdata</code>
argument so that the fitted values can be computed for a
different data set.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Chambers, J. M. and T. J. Hastie (eds) (1992).
<em>Statistical Models in S</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="#topic+predictvglm">predictvglm</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Categorical regression example 1
pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo))
fitted(fit1)

# LMS quantile regression example 2
fit2 &lt;- vgam(BMI ~ s(age, df = c(4, 2)),
             lms.bcn(zero = 1), data = bmi.nz, trace = TRUE)
head(predict(fit2, type = "response"))  # Equals to both these:
head(fitted(fit2))
predict(fit2, type = "response", newdata = head(bmi.nz))

# Zero-inflated example 3
zdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
zdata &lt;- transform(zdata,
                   pstr0.3  = logitlink(-0.5       , inverse = TRUE),
                   lambda.3 =   loglink(-0.5 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata,
         y1 = rzipois(nn, lambda = lambda.3, pstr0 = pstr0.3))
fit3 &lt;- vglm(y1 ~ x2, zipoisson(zero = NULL), zdata, trace = TRUE)
head(fitted(fit3, type.fitted = "mean" ))  # E(Y) (the default)
head(fitted(fit3, type.fitted = "pobs0"))  # Pr(Y = 0)
head(fitted(fit3, type.fitted = "pstr0"))  # Prob of a structural 0
head(fitted(fit3, type.fitted = "onempstr0"))  # 1 - Pr(structural 0)
</code></pre>

<hr>
<h2 id='fix.crossing'>Fixing a Quantile Regression having Crossing</h2><span id='topic+fix.crossing'></span><span id='topic+fix.crossing.vglm'></span>

<h3>Description</h3>

<p>Returns a similar object fitted with columns of the constraint
matrices amalgamated so it is a
partially parallel VGLM object.
The columns combined correspond to certain crossing quantiles.
This applies especially to an extlogF1() VGLM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fix.crossing.vglm(object, maxit = 100, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fix.crossing_+3A_object">object</code></td>
<td>

<p>an object such as
a <code><a href="#topic+vglm">vglm</a></code> object with
family function <code><a href="#topic+extlogF1">extlogF1</a></code>.
</p>
</td></tr>
<tr><td><code id="fix.crossing_+3A_maxit">maxit</code>, <code id="fix.crossing_+3A_trace">trace</code></td>
<td>

<p>values for overwriting components in <code><a href="#topic+vglm.control">vglm.control</a></code>.
Setting these to <code>NULL</code> will mean
the values in <code><a href="#topic+vglm.control">vglm.control</a></code> on <code>object</code> will
be retained.
</p>
</td></tr>
<tr><td><code id="fix.crossing_+3A_...">...</code></td>
<td>

<p>additional optional arguments.
Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The quantile crossing problem has been described as
<em>disturbing</em> and <em>embarrassing</em>.
This function was specifically written for
a <code><a href="#topic+vglm">vglm</a></code> with family function <code><a href="#topic+extlogF1">extlogF1</a></code>.
It examines the fitted quantiles of <code>object</code> to see if any cross.
If so, then a pair of columns is combined to make those
two quantiles parallel.
After fitting the submodel it then repeats testing for
crossing quantiles and repairing them, until there is
no more quantile crossing detected.
Note that it is possible that the quantiles cross in
some subset of the covariate space not covered by the
data&mdash;see <code><a href="#topic+is.crossing">is.crossing</a></code>.
</p>
<p>This function is fragile and likely to change in the future.
For <code><a href="#topic+extlogF1">extlogF1</a></code> models, it is assumed
that argument <code>data</code> has been assigned a data frame,
and
that the default values of the argument <code>parallel</code>
has been used; this means that the second constraint
matrix is <code>diag(M)</code>.
The constraint matrix of the intercept term remains unchanged
as <code>diag(M)</code>.
</p>


<h3>Value</h3>

<p>An object very similar to the original object, but
with possibly different constraint matrices
(partially parallel) so as to remove any quantile crossing.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+is.crossing">is.crossing</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>.
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  ooo &lt;- with(bmi.nz, order(age))
bmi.nz &lt;- bmi.nz[ooo, ]  # Sort by age
with(bmi.nz, plot(age, BMI, col = "blue"))
mytau &lt;- c(50, 93, 95, 97) / 100  # Some quantiles are quite close
fit1 &lt;- vglm(BMI ~ ns(age, 7), extlogF1(mytau), bmi.nz, trace = TRUE)
plot(BMI ~ age, bmi.nz, col = "blue", las = 1,
     main = "Partially parallel (darkgreen) &amp; nonparallel quantiles",
     sub = "Crossing quantiles are orange")
fix.crossing(fit1)
matlines(with(bmi.nz, age), fitted(fit1), lty = 1, col = "orange")
fit2 &lt;- fix.crossing(fit1)  # Some quantiles have been fixed
constraints(fit2)
matlines(with(bmi.nz, age), fitted(fit2), lty = "dashed",
         col = "darkgreen", lwd = 2)  
## End(Not run)
</code></pre>

<hr>
<h2 id='flourbeetle'>Mortality of Flour Beetles from Carbon Disulphide</h2><span id='topic+flourbeetle'></span>

<h3>Description</h3>

<p>The <code>flourbeetle</code> data frame has 8 rows and 4 columns.
Two columns are explanatory, the other two are responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(flourbeetle)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>logdose</dt><dd><p><code><a href="base.html#topic+log10">log10</a></code> applied to <code>CS2mgL</code>. </p>
</dd>
<dt>CS2mgL</dt><dd><p>a numeric vector, the concentration of gaseous
carbon disulphide in mg per litre. </p>
</dd>
<dt>exposed</dt><dd><p>a numeric vector, counts; the number of
beetles exposed to the poison. </p>
</dd>
<dt>killed</dt><dd><p>a numeric vector, counts; the numbers killed. </p>
</dd>
</dl>



<h3>Details</h3>

<p>These data were originally given in Table IV of Bliss (1935) and
are the combination of
two series of toxicological experiments involving
<em>Tribolium confusum</em>, also known as the flour beetle.
Groups of such adult beetles were exposed for 5 hours of
gaseous carbon disulphide at different concentrations,
and their mortality measured.
</p>


<h3>Source</h3>

<p>Bliss, C.I., 1935.
The calculation of the dosage-mortality curve.
<em>Annals of Applied Biology</em>, <b>22</b>, 134&ndash;167.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- vglm(cbind(killed, exposed - killed) ~ logdose,
             binomialff(link = probitlink), flourbeetle, trace = TRUE)
summary(fit1)
</code></pre>

<hr>
<h2 id='Foldnorm'>The Folded-Normal Distribution</h2><span id='topic+Foldnorm'></span><span id='topic+dfoldnorm'></span><span id='topic+pfoldnorm'></span><span id='topic+qfoldnorm'></span><span id='topic+rfoldnorm'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the (generalized) folded-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfoldnorm(x, mean = 0, sd = 1, a1 = 1, a2 = 1, log = FALSE)
pfoldnorm(q, mean = 0, sd = 1, a1 = 1, a2 = 1,
          lower.tail = TRUE, log.p = FALSE)
qfoldnorm(p, mean = 0, sd = 1, a1 = 1, a2 = 1,
          lower.tail = TRUE, log.p = FALSE, ...)
rfoldnorm(n, mean = 0, sd = 1, a1 = 1, a2 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Foldnorm_+3A_x">x</code>, <code id="Foldnorm_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+Normal">rnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_mean">mean</code>, <code id="Foldnorm_+3A_sd">sd</code></td>
<td>
<p> see <code><a href="stats.html#topic+Normal">rnorm</a></code>. </p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_a1">a1</code>, <code id="Foldnorm_+3A_a2">a2</code></td>
<td>
<p> see <code><a href="#topic+foldnormal">foldnormal</a></code>. </p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the log density is returned.
</p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_lower.tail">lower.tail</code>, <code id="Foldnorm_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Foldnorm_+3A_...">...</code></td>
<td>

<p>Arguments that can be passed into <code><a href="stats.html#topic+uniroot">uniroot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+foldnormal">foldnormal</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for the formula of the probability density function
and other details.
</p>


<h3>Value</h3>

<p><code>dfoldnorm</code> gives the density,
<code>pfoldnorm</code> gives the distribution function,
<code>qfoldnorm</code> gives the quantile function, and
<code>rfoldnorm</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang.
Suggestions from Mauricio Romero led to improvements
in <code>qfoldnorm()</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+foldnormal">foldnormal</a></code>,
<code><a href="stats.html#topic+uniroot">uniroot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
m &lt;- 1.5; SD &lt;- exp(0)
x &lt;- seq(-1, 4, len = 501)
plot(x, dfoldnorm(x, m = m, sd = SD), type = "l", ylim = 0:1,
     ylab = paste("foldnorm(m = ", m, ", sd = ",
                  round(SD, digits = 3), ")"), las = 1,
     main = "Blue is density, orange is CDF", col = "blue",
     sub = "Purple lines are the 10,20,...,90 percentiles")
abline(h = 0, col = "gray50")
lines(x, pfoldnorm(x, m = m, sd = SD), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qfoldnorm(probs, m = m, sd = SD)
lines(Q, dfoldnorm(Q, m, SD), col = "purple", lty = 3, type = "h")
lines(Q, pfoldnorm(Q, m, SD), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(pfoldnorm(Q, m = m, sd = SD) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='foldnormal'> Folded Normal Distribution Family Function </h2><span id='topic+foldnormal'></span>

<h3>Description</h3>

<p>Fits a (generalized) folded (univariate) normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foldnormal(lmean = "identitylink", lsd = "loglink", imean = NULL,
   isd = NULL, a1 = 1, a2 = 1, nsimEIM = 500, imethod = 1,
   zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="foldnormal_+3A_lmean">lmean</code>, <code id="foldnormal_+3A_lsd">lsd</code></td>
<td>

<p>Link functions for the mean and standard
deviation parameters of the usual univariate normal distribution.
They are <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="foldnormal_+3A_imean">imean</code>, <code id="foldnormal_+3A_isd">isd</code></td>
<td>

<p>Optional initial values for <code class="reqn">\mu</code>
and <code class="reqn">\sigma</code>.
A <code>NULL</code> means a value is computed internally.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="foldnormal_+3A_a1">a1</code>, <code id="foldnormal_+3A_a2">a2</code></td>
<td>

<p>Positive weights, called <code class="reqn">a_1</code> and <code class="reqn">a_2</code> below.
Each must be of length 1.
</p>
</td></tr>
<tr><td><code id="foldnormal_+3A_nsimeim">nsimEIM</code>, <code id="foldnormal_+3A_imethod">imethod</code>, <code id="foldnormal_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a random variable has an ordinary univariate normal
distribution then the absolute value of that random
variable has an ordinary <em>folded normal distribution</em>.
That is, the sign has not been
recorded; only the magnitude has been measured.
</p>
<p>More generally, suppose <code class="reqn">X</code> is normal with
mean <code>mean</code> and
standard deviation <code>sd</code>.
Let <code class="reqn">Y=\max(a_1 X, -a_2 X)</code>
where <code class="reqn">a_1</code> and <code class="reqn">a_2</code> are positive weights.
This means that <code class="reqn">Y = a_1 X</code> for <code class="reqn">X &gt; 0</code>,
and <code class="reqn">Y = a_2 X</code> for <code class="reqn">X &lt; 0</code>.
Then <code class="reqn">Y</code> is said to have a
<em>generalized folded normal distribution</em>.
The ordinary folded normal distribution corresponds to the
special case <code class="reqn">a_1 = a_2 = 1</code>.
</p>
<p>The probability density function of the ordinary
folded normal distribution
can be written
<code>dnorm(y, mean, sd) + dnorm(y, -mean, sd)</code> for
<code class="reqn">y \ge 0</code>.
By default, <code>mean</code> and <code>log(sd)</code> are the
linear/additive
predictors.
Having <code>mean=0</code> and <code>sd=1</code> results in the
<em>half-normal</em> distribution.
The mean of an ordinary folded normal distribution is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = \sigma \sqrt{2/\pi} \exp(-\mu^2/(2\sigma^2)) +
               \mu [1-2\Phi(-\mu/\sigma)] </code>
</p>

<p>and these are returned as the fitted values.
Here, <code class="reqn">\Phi()</code> is the cumulative distribution
function of a
standard normal (<code><a href="stats.html#topic+Normal">pnorm</a></code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such
as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Under- or over-flow may occur if the data is ill-conditioned.
It is recommended that several different initial values be used
to help avoid local solutions.
</p>


<h3>Note</h3>

<p>The response variable for this family function is the same as
<code><a href="#topic+uninormal">uninormal</a></code> except positive values are required.
Reasonably good initial values are needed.
Fisher scoring using simulation is implemented.
</p>
<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
general information about
many of these arguments.
</p>
<p>Yet to do: implement the results of Johnson (1962) which gives
expressions for the EIM, albeit, under a different
parameterization.
Also, one element of the EIM appears to require
numerical integration.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Lin, P. C. (2005).
Application of the generalized folded-normal
distribution to the process
capability measures.
<em>International Journal of Advanced Manufacturing Technology</em>,
<b>26</b>, 825&ndash;830.
</p>
<p>Johnson, N. L. (1962).
The folded normal distribution:
accuracy of estimation by maximum likelihood.
<em>Technometrics</em>,
<b>4</b>, 249&ndash;256.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfoldnorm">rfoldnorm</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+skewnormal">skewnormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  m &lt;-  2; SD &lt;- exp(1)
fdata &lt;- data.frame(y = rfoldnorm(n &lt;- 1000, m = m, sd = SD))
hist(with(fdata, y), prob = TRUE, main = paste("foldnormal(m = ",
     m, ", sd = ", round(SD, 2), ")"))
fit &lt;- vglm(y ~ 1, foldnormal, data = fdata, trace = TRUE)
coef(fit, matrix = TRUE)
(Cfit &lt;- Coef(fit))
# Add the fit to the histogram:
mygrid &lt;- with(fdata, seq(min(y), max(y), len = 200))
lines(mygrid, dfoldnorm(mygrid, Cfit[1], Cfit[2]), col = "orange")

## End(Not run)
</code></pre>

<hr>
<h2 id='formulavlm'> Model Formulae and Term Names for VGLMs </h2><span id='topic+formula.vlm'></span><span id='topic+formulavlm'></span><span id='topic+term.names'></span><span id='topic+term.namesvlm'></span>

<h3>Description</h3>

<p>The methods function for <code>formula</code> to
extract the formula from a fitted object,
as well as a methods function to return the names
of the terms in the formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vlm'
formula(x, ...)
formulavlm(x, form.number = 1, ...)
term.names(model, ...)
term.namesvlm(model, form.number = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="formulavlm_+3A_x">x</code>, <code id="formulavlm_+3A_model">model</code></td>
<td>
<p> A fitted model object.
</p>
</td></tr>
<tr><td><code id="formulavlm_+3A_form.number">form.number</code></td>
<td>
<p>Formula number, is 1 or 2.
which correspond to the arguments <code>formula</code>
and <code>form2</code> respectively.
</p>
</td></tr>
<tr><td><code id="formulavlm_+3A_...">...</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+formula">formula</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>formula</code> methods function is
based on <code><a href="stats.html#topic+formula">formula</a></code>.
</p>


<h3>Value</h3>

<p>The <code>formula</code> methods function should return something similar to
<code><a href="stats.html#topic+formula">formula</a></code>.
The <code>term.names</code> methods function should return a character string
with the terms in the formula; this includes any intercept (which
is denoted by <code>"(Intercept)"</code> as the first element.)
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+has.interceptvlm">has.interceptvlm</a></code>.

</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: this is based on a glm example
counts &lt;- c(18,17,15,20,10,20,25,13,12)
outcome &lt;- gl(3, 1, 9); treatment &lt;- gl(3, 3)
vglm.D93 &lt;- vglm(counts ~ outcome + treatment, family = poissonff)
formula(vglm.D93)
pdata &lt;- data.frame(counts, outcome, treatment)  # Better style
vglm.D93 &lt;- vglm(counts ~ outcome + treatment, poissonff, data = pdata)
formula(vglm.D93)
term.names(vglm.D93)
responseName(vglm.D93)
has.intercept(vglm.D93)
</code></pre>

<hr>
<h2 id='Frank'>Frank's Bivariate Distribution</h2><span id='topic+Frank'></span><span id='topic+dbifrankcop'></span><span id='topic+pbifrankcop'></span><span id='topic+rbifrankcop'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the (one parameter) bivariate Frank distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbifrankcop(x1, x2, apar, log = FALSE)
pbifrankcop(q1, q2, apar)
rbifrankcop(n, apar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Frank_+3A_x1">x1</code>, <code id="Frank_+3A_x2">x2</code>, <code id="Frank_+3A_q1">q1</code>, <code id="Frank_+3A_q2">q2</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Frank_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Frank_+3A_apar">apar</code></td>
<td>
<p>the positive association parameter. </p>
</td></tr>
<tr><td><code id="Frank_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+bifrankcop">bifrankcop</a></code>, the <span class="pkg">VGAM</span>
family functions for estimating the association
parameter by maximum likelihood estimation, for the formula of
the cumulative distribution function and other details.
</p>


<h3>Value</h3>

<p><code>dbifrankcop</code> gives the density,
<code>pbifrankcop</code> gives the distribution function, and
<code>rbifrankcop</code> generates random deviates (a two-column matrix).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Genest, C. (1987).
Frank's family of bivariate distributions.
<em>Biometrika</em>,
<b>74</b>, 549&ndash;555.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bifrankcop">bifrankcop</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: N &lt;- 100; apar &lt;- exp(2)
xx &lt;- seq(-0.30, 1.30, len = N)
ox &lt;- expand.grid(xx, xx)
zedd &lt;- dbifrankcop(ox[, 1], ox[, 2], apar = apar)
contour(xx, xx, matrix(zedd, N, N))
zedd &lt;- pbifrankcop(ox[, 1], ox[, 2], apar = apar)
contour(xx, xx, matrix(zedd, N, N))

plot(rr &lt;- rbifrankcop(n = 3000, apar = exp(4)))
par(mfrow = c(1, 2))
hist(rr[, 1]); hist(rr[, 2])  # Should be uniform

## End(Not run)
</code></pre>

<hr>
<h2 id='frechet'> Frechet Distribution Family Function </h2><span id='topic+frechet'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
Frechet distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>frechet(location = 0, lscale = "loglink",
  lshape = logofflink(offset = -2),
  iscale = NULL, ishape = NULL, nsimEIM = 250, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frechet_+3A_location">location</code></td>
<td>

<p>Numeric. Location parameter.
It is called <code class="reqn">a</code> below.
</p>
</td></tr>
<tr><td><code id="frechet_+3A_lscale">lscale</code>, <code id="frechet_+3A_lshape">lshape</code></td>
<td>

<p>Link functions for the parameters;
see <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="frechet_+3A_iscale">iscale</code>, <code id="frechet_+3A_ishape">ishape</code>, <code id="frechet_+3A_zero">zero</code>, <code id="frechet_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>





























</table>


<h3>Details</h3>

<p>The (3-parameter) Frechet distribution has a density function
that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \frac{sb}{
      (y-a)^2} [b/(y-a)]^{s-1} \, \exp[-(b/(y-a))^s] </code>
</p>

<p>for <code class="reqn">y &gt; a</code> and scale parameter <code class="reqn">b &gt; 0</code>.
The positive shape parameter is <code class="reqn">s</code>.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y) = \exp[-(b/(y-a))^s]. </code>
</p>

<p>The mean of <code class="reqn">Y</code>
is <code class="reqn">a + b \Gamma(1-1/s)</code>
for <code class="reqn">s &gt; 1</code> (these are returned as the fitted values).
The variance of <code class="reqn">Y</code> is
<code class="reqn">b^2 [ \Gamma(1-2/s) - \Gamma^2(1-1/s)]</code>
for <code class="reqn">s &gt; 2</code>.
</p>
<p>Family <code>frechet</code> has <code class="reqn">a</code> known, and
<code class="reqn">\log(b)</code> and
<code class="reqn">\log(s - 2)</code> are the default
linear/additive predictors.
The working weights are estimated by simulated Fisher scoring.
</p>














<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such
as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>






<p>Family function <code>frechet</code> may fail for low values of
the shape parameter, e.g., near 2 or lower.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Castillo, E., Hadi, A. S.,
Balakrishnan, N. and Sarabia, J. S. (2005).
<em>Extreme Value and Related Models with Applications
in Engineering and Science</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rfrechet">rfrechet</a></code>,
<code><a href="#topic+gev">gev</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(123)
fdata &lt;- data.frame(y1 = rfrechet(1000, shape = 2 + exp(1)))
with(fdata, hist(y1))
fit2 &lt;- vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE)
coef(fit2, matrix = TRUE)
Coef(fit2)
head(fitted(fit2))
with(fdata, mean(y1))
head(weights(fit2, type = "working"))
vcov(fit2)

## End(Not run)
</code></pre>

<hr>
<h2 id='Frechet'>The Frechet Distribution</h2><span id='topic+Frechet'></span><span id='topic+dfrechet'></span><span id='topic+pfrechet'></span><span id='topic+qfrechet'></span><span id='topic+rfrechet'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the three parameter Frechet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfrechet(x, location = 0, scale = 1, shape, log = FALSE)
pfrechet(q, location = 0, scale = 1, shape,
         lower.tail = TRUE, log.p = FALSE)
qfrechet(p, location = 0, scale = 1, shape,
         lower.tail = TRUE, log.p = FALSE)
rfrechet(n, location = 0, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Frechet_+3A_x">x</code>, <code id="Frechet_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_n">n</code></td>
<td>
<p>number of observations.
Passed into <code><a href="stats.html#topic+Uniform">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Frechet_+3A_location">location</code>, <code id="Frechet_+3A_scale">scale</code>, <code id="Frechet_+3A_shape">shape</code></td>
<td>
<p>the location parameter <code class="reqn">a</code>,
scale parameter <code class="reqn">b</code>, and shape parameter <code class="reqn">s</code>.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density
is returned.
</p>
</td></tr>
<tr><td><code id="Frechet_+3A_lower.tail">lower.tail</code>, <code id="Frechet_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Uniform">punif</a></code>
or <code><a href="stats.html#topic+Uniform">qunif</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+frechet">frechet</a></code>, the <span class="pkg">VGAM</span>
family function for estimating the 2 parameters
(without location
parameter) by maximum likelihood estimation, for the formula
of the probability density function and range restrictions on
the parameters.
</p>


<h3>Value</h3>

<p><code>dfrechet</code> gives the density,
<code>pfrechet</code> gives the distribution function,
<code>qfrechet</code> gives the quantile function, and
<code>rfrechet</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Castillo, E., Hadi, A. S.,
Balakrishnan, N. and Sarabia, J. S. (2005).
<em>Extreme Value and Related Models with Applications in
Engineering and Science</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frechet">frechet</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  shape &lt;- 5
x &lt;- seq(-0.1, 3.5, length = 401)
plot(x, dfrechet(x, shape = shape), type = "l", ylab = "",
  main = "Frechet density divided into 10 equal areas",
  sub = "Orange = CDF", las = 1)
abline(h = 0, col = "blue", lty = 2)
qq &lt;- qfrechet(seq(0.1, 0.9, by = 0.1), shape = shape)
lines(qq, dfrechet(qq, shape = shape), col = 2, lty = 2, type = "h")
lines(x, pfrechet(q = x, shape = shape), col = "orange")

## End(Not run)
</code></pre>

<hr>
<h2 id='freund61'> Freund's (1961) Bivariate Extension of the
Exponential Distribution </h2><span id='topic+freund61'></span>

<h3>Description</h3>

<p>Estimate the four parameters of the Freund (1961)
bivariate extension
of the exponential distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freund61(la = "loglink",  lap = "loglink",  lb = "loglink",
         lbp = "loglink", ia = NULL, iap = NULL, ib = NULL,
         ibp = NULL, independent = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freund61_+3A_la">la</code>, <code id="freund61_+3A_lap">lap</code>, <code id="freund61_+3A_lb">lb</code>, <code id="freund61_+3A_lbp">lbp</code></td>
<td>

<p>Link functions applied to the (positive)
parameters <code class="reqn">\alpha</code>, <code class="reqn">\alpha'</code>,
<code class="reqn">\beta</code> and <code class="reqn">\beta'</code>, respectively
(the &ldquo;<code>p</code>&rdquo; stands for &ldquo;prime&rdquo;).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="freund61_+3A_ia">ia</code>, <code id="freund61_+3A_iap">iap</code>, <code id="freund61_+3A_ib">ib</code>, <code id="freund61_+3A_ibp">ibp</code></td>
<td>

<p>Initial value for the four parameters respectively.
The default is to estimate them all internally.
</p>
</td></tr>
<tr><td><code id="freund61_+3A_independent">independent</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the parameters are constrained
to satisfy
<code class="reqn">\alpha=\alpha'</code> and
<code class="reqn">\beta=\beta'</code>,
which implies that <code class="reqn">y_1</code> and
<code class="reqn">y_2</code> are independent
and each have an ordinary exponential distribution.
</p>
</td></tr>
<tr><td><code id="freund61_+3A_zero">zero</code></td>
<td>

<p>A vector specifying which
linear/additive predictors are modelled as intercepts only.
The values can be from the set {1,2,3,4}.
The default is none of them.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This model represents one type of bivariate extension
of the exponential
distribution that is applicable to certain problems,
in particular,
to two-component systems which can function if one of
the components
has failed. For example, engine failures in
two-engine planes, paired
organs such as peoples' eyes, ears and kidneys.
Suppose <code class="reqn">y_1</code> and <code class="reqn">y_2</code> are random variables
representing the lifetimes of
two components <code class="reqn">A</code> and <code class="reqn">B</code>
in a two component system.
The dependence between <code class="reqn">y_1</code> and <code class="reqn">y_2</code>
is essentially such that the failure of the <code class="reqn">B</code> component
changes the parameter of the exponential life distribution
of the <code class="reqn">A</code>  component from <code class="reqn">\alpha</code> to
<code class="reqn">\alpha'</code>, while the failure of
the <code class="reqn">A</code>  component
changes the parameter of the exponential life distribution
of the <code class="reqn">B</code>  component from <code class="reqn">\beta</code> to
<code class="reqn">\beta'</code>.
</p>
<p>The joint probability density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y_1,y_2) = \alpha \beta' \exp(-\beta' y_2 -
                      (\alpha+\beta-\beta')y_1) </code>
</p>

<p>for <code class="reqn">0 &lt; y_1 &lt; y_2</code>, and
</p>
<p style="text-align: center;"><code class="reqn">f(y_1,y_2) = \beta \alpha' \exp(-\alpha' y_1 -
                      (\alpha+\beta-\alpha')y_2) </code>
</p>

<p>for <code class="reqn">0 &lt; y_2 &lt; y_1</code>.
Here, all four parameters are positive, as well
as the responses
<code class="reqn">y_1</code> and <code class="reqn">y_2</code>.
Under this model, the probability that component <code class="reqn">A</code>
is the first to fail is
<code class="reqn">\alpha/(\alpha+\beta)</code>.
The time to the first failure is distributed as an
exponential distribution with rate
<code class="reqn">\alpha+\beta</code>. Furthermore, the
distribution of the time from first failure to failure
of the other component is a mixture of
Exponential(<code class="reqn">\alpha'</code>) and
Exponential(<code class="reqn">\beta'</code>) with proportions
<code class="reqn">\beta/(\alpha+\beta)</code>
and <code class="reqn">\alpha/(\alpha+\beta)</code>
respectively.
</p>
<p>The marginal distributions are, in general, not exponential.
By default, the linear/additive predictors are
<code class="reqn">\eta_1=\log(\alpha)</code>,
<code class="reqn">\eta_2=\log(\alpha')</code>,
<code class="reqn">\eta_3=\log(\beta)</code>,
<code class="reqn">\eta_4=\log(\beta')</code>.
</p>
<p>A special case is when <code class="reqn">\alpha=\alpha'</code>
and <code class="reqn">\beta=\beta'</code>, which means that
<code class="reqn">y_1</code> and <code class="reqn">y_2</code> are independent, and
both have an ordinary exponential distribution with means
<code class="reqn">1 / \alpha</code> and <code class="reqn">1 / \beta</code>
respectively.
</p>
<p>Fisher scoring is used,
and the initial values correspond to the MLEs of
an intercept model.
Consequently, convergence may take only one iteration.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>To estimate all four parameters, it is necessary to have some
data where <code class="reqn">y_1&lt;y_2</code> and <code class="reqn">y_2&lt;y_1</code>.
</p>
<p>The response must be a two-column matrix, with columns
<code class="reqn">y_1</code> and <code class="reqn">y_2</code>.
Currently, the fitted value is a matrix with two columns; the
first column has values
<code class="reqn">(\alpha'+\beta)/(\alpha' (\alpha+\beta))</code>
for the mean of <code class="reqn">y_1</code>,
while the second column has values
<code class="reqn">(\beta'+\alpha)/(\beta' (\alpha+\beta))</code>
for the mean of <code class="reqn">y_2</code>.
The variance of <code class="reqn">y_1</code> is
</p>
<p style="text-align: center;"><code class="reqn"> \frac{(\alpha')^2 + 2 \alpha \beta + \beta^2}{
               (\alpha')^2 (\alpha + \beta)^2}, </code>
</p>

<p>the variance of <code class="reqn">y_2</code> is
</p>
<p style="text-align: center;"><code class="reqn"> \frac{(\beta')^2 + 2 \alpha \beta + \alpha^2 }{
               (\beta')^2 (\alpha + \beta)^2 }, </code>
</p>

<p>the covariance of <code class="reqn">y_1</code> and <code class="reqn">y_2</code> is
</p>
<p style="text-align: center;"><code class="reqn"> \frac{\alpha' \beta' - \alpha \beta }{
               \alpha' \beta' (\alpha + \beta)^2}. </code>
</p>



<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Freund, J. E. (1961).
A bivariate extension of the exponential distribution.
<em>Journal of the American Statistical Association</em>,
<b>56</b>, 971&ndash;977.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exponential">exponential</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fdata &lt;- data.frame(y1 = rexp(nn &lt;- 1000, rate = exp(1)))
fdata &lt;- transform(fdata, y2 = rexp(nn, rate = exp(2)))
fit1 &lt;- vglm(cbind(y1, y2) ~ 1, freund61, fdata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
vcov(fit1)
head(fitted(fit1))
summary(fit1)

# y1 and y2 are independent, so fit an independence model
fit2 &lt;- vglm(cbind(y1, y2) ~ 1, freund61(indep = TRUE),
             data = fdata, trace = TRUE)
coef(fit2, matrix = TRUE)
constraints(fit2)
pchisq(2 * (logLik(fit1) - logLik(fit2)),  # p-value
       df = df.residual(fit2) - df.residual(fit1),
       lower.tail = FALSE)
lrtest(fit1, fit2)  # Better alternative
</code></pre>

<hr>
<h2 id='Gaitdbinom'> Generally Altered, Inflated, Truncated
and Deflated
Binomial Distribution
</h2><span id='topic+Gaitdbinom'></span><span id='topic+dgaitdbinom'></span><span id='topic+pgaitdbinom'></span><span id='topic+qgaitdbinom'></span><span id='topic+rgaitdbinom'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function
and random generation
for the generally altered, inflated, truncated
and deflated
binomial distribution.
Both parametric and nonparametric variants are
supported; these are based on finite mixtures
of the parent with itself and the multinomial
logit model (MLM) respectively.
</p>







<h3>Usage</h3>

<pre><code class='language-R'>dgaitdbinom(x, size.p, prob.p,
            a.mix = NULL, a.mlm = NULL,
            i.mix = NULL, i.mlm = NULL,
            d.mix = NULL, d.mlm = NULL, truncate = NULL,
            pobs.mix = 0, pobs.mlm = 0,
            pstr.mix = 0, pstr.mlm = 0,
            pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
            size.a = size.p, size.i = size.p, size.d = size.p,
            prob.a = prob.p, prob.i = prob.p, prob.d = prob.p,
            log = FALSE, ...)
pgaitdbinom(q, size.p, prob.p,
            a.mix = NULL, a.mlm = NULL,
            i.mix = NULL, i.mlm = NULL,
            d.mix = NULL, d.mlm = NULL, truncate = NULL,
            pobs.mix = 0, pobs.mlm = 0,
            pstr.mix = 0, pstr.mlm = 0,
            pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
            size.a = size.p, size.i = size.p, size.d = size.p,
            prob.a = prob.p, prob.i = prob.p, prob.d = prob.p,
            lower.tail = TRUE, ...)
qgaitdbinom(p, size.p, prob.p,
            a.mix = NULL, a.mlm = NULL,
            i.mix = NULL, i.mlm = NULL,
            d.mix = NULL, d.mlm = NULL, truncate = NULL,
            pobs.mix = 0, pobs.mlm = 0,
            pstr.mix = 0, pstr.mlm = 0,
            pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
            size.a = size.p, size.i = size.p, size.d = size.p,
            prob.a = prob.p, prob.i = prob.p, prob.d = prob.p, ...)
rgaitdbinom(n, size.p, prob.p,
            a.mix = NULL, a.mlm = NULL,
            i.mix = NULL, i.mlm = NULL,
            d.mix = NULL, d.mlm = NULL, truncate = NULL,
            pobs.mix = 0, pobs.mlm = 0,
            pstr.mix = 0, pstr.mlm = 0,
            pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
            size.a = size.p, size.i = size.p, size.d = size.p,
            prob.a = prob.p, prob.i = prob.p, prob.d = prob.p, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaitdbinom_+3A_x">x</code>, <code id="Gaitdbinom_+3A_q">q</code>, <code id="Gaitdbinom_+3A_p">p</code>, <code id="Gaitdbinom_+3A_n">n</code>, <code id="Gaitdbinom_+3A_log">log</code>, <code id="Gaitdbinom_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Binomial">Binomial</a></code>.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_size.p">size.p</code>, <code id="Gaitdbinom_+3A_prob.p">prob.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Binomial">Binomial</a></code>.
See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_size.a">size.a</code>, <code id="Gaitdbinom_+3A_prob.a">prob.a</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_size.i">size.i</code>, <code id="Gaitdbinom_+3A_prob.i">prob.i</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_size.d">size.d</code>, <code id="Gaitdbinom_+3A_prob.d">prob.d</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_truncate">truncate</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>

</td></tr>
<tr><td><code id="Gaitdbinom_+3A_a.mix">a.mix</code>, <code id="Gaitdbinom_+3A_i.mix">i.mix</code>, <code id="Gaitdbinom_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_a.mlm">a.mlm</code>, <code id="Gaitdbinom_+3A_i.mlm">i.mlm</code>, <code id="Gaitdbinom_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_pstr.mix">pstr.mix</code>, <code id="Gaitdbinom_+3A_pstr.mlm">pstr.mlm</code>, <code id="Gaitdbinom_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_pobs.mix">pobs.mix</code>, <code id="Gaitdbinom_+3A_pobs.mlm">pobs.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdbinom_+3A_pdip.mix">pdip.mix</code>, <code id="Gaitdbinom_+3A_pdip.mlm">pdip.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>



<tr><td><code id="Gaitdbinom_+3A_...">...</code></td>
<td>

<p>Arguments such as <code>max.support</code> that are ignored.
This will occur internally within <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions for the GAITD binomial distribution
are analogous to the GAITD Poisson,
hence most details have been put in
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
</p>


<h3>Value</h3>

<p><code>dgaitdbinom</code> gives the density,
<code>pgaitdbinom</code> gives the distribution function,
<code>qgaitdbinom</code> gives the quantile function, and
<code>rgaitdbinom</code> generates random deviates.
The default values of the arguments correspond to ordinary
<code><a href="stats.html#topic+Binomial">dbinom</a></code>,
<code><a href="stats.html#topic+Binomial">pbinom</a></code>,
<code><a href="stats.html#topic+Binomial">qbinom</a></code>,
<code><a href="stats.html#topic+Binomial">rbinom</a></code>
respectively.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> about the dangers
of too much inflation and/or deflation on
GAITD PMFs, and the difficulties detecting such.
</p>


<h3>Note</h3>

<p>Functions <code><a href="VGAMdata.html#topic+Posbinom">Posbinom</a></code> have been moved
to <span class="pkg">VGAMdata</span>.
It is better to use
<code>dgaitdbinom(x, size, prob, truncate = 0)</code> instead of
<code>dposbinom(x, size, prob)</code>, etc.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+Gaitdlog">Gaitdlog</a></code>,
<code><a href="#topic+Gaitdzeta">Gaitdzeta</a></code>.
</p>

















<h3>Examples</h3>

<pre><code class='language-R'> size &lt;- 20
ivec &lt;- c(6, 10); avec &lt;- c(8, 11); prob &lt;- 0.25; xgrid &lt;- 0:25
tvec &lt;- 14; pobs.a &lt;- 0.05; pstr.i &lt;- 0.15
dvec &lt;- 5; pdip.mlm &lt;- 0.05
(ddd &lt;- dgaitdbinom(xgrid, size, prob.p = prob,
   prob.a = prob + 0.05, truncate = tvec, pobs.mix = pobs.a,
   pdip.mlm = pdip.mlm, d.mlm = dvec,
   pobs.mlm = pobs.a, a.mlm = avec,
   pstr.mix = pstr.i, i.mix = ivec))
## Not run:  dgaitdplot(c(size, prob), ylab = "Probability",
   xlab = "x", pobs.mix = pobs.mix,
   pobs.mlm = pobs.a, a.mlm = avec, all.lwd = 3,
   pdip.mlm = pdip.mlm, d.mlm = dvec, fam = "binom",
   pstr.mix = pstr.i, i.mix = ivec, deflation = TRUE,
   main = "GAITD Combo PMF---Binomial Parent")   
## End(Not run)
</code></pre>

<hr>
<h2 id='gaitdlog'> Generally Altered, Inflated, Truncated
and Deflated
Logarithmic Regression
</h2><span id='topic+gaitdlog'></span>

<h3>Description</h3>

<p>Fits a generally altered, inflated, truncated
and deflated
logarithmic regression by MLE.
The GAITD combo model having 7 types of special
values is implemented.  This allows logarithmic
mixtures on nested and/or partitioned support
as well as a multinomial logit model for
altered, inflated and deflated values.
Truncation may include the upper tail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaitdlog(a.mix = NULL, i.mix = NULL, d.mix = NULL,
         a.mlm = NULL, i.mlm = NULL, d.mlm = NULL,
         truncate = NULL, max.support = Inf,
         zero = c("pobs", "pstr", "pdip"), eq.ap = TRUE, eq.ip = TRUE,
         eq.dp = TRUE, parallel.a = FALSE,
         parallel.i = FALSE, parallel.d = FALSE,
         lshape.p = "logitlink", lshape.a = lshape.p,
         lshape.i = lshape.p, lshape.d = lshape.p,
         type.fitted = c("mean", "shapes", "pobs.mlm", "pstr.mlm",
         "pdip.mlm", "pobs.mix", "pstr.mix", "pdip.mix", "Pobs.mix",
         "Pstr.mix", "Pdip.mix", "nonspecial",
         "Numer", "Denom.p", "sum.mlm.i", "sum.mix.i", "sum.mlm.d",
         "sum.mix.d", "ptrunc.p", "cdf.max.s"),
         gshape.p = -expm1(-7 * ppoints(12)), gpstr.mix = ppoints(7) / 3,
         gpstr.mlm = ppoints(7) / (3 + length(i.mlm)),
         imethod = 1, mux.init = c(0.75, 0.5, 0.75),
         ishape.p = NULL, ishape.a = ishape.p,
         ishape.i = ishape.p, ishape.d = ishape.p,
         ipobs.mix = NULL, ipstr.mix = NULL, ipdip.mix = NULL,
         ipobs.mlm = NULL, ipstr.mlm = NULL, ipdip.mlm = NULL,
         byrow.aid = FALSE, ishrinkage = 0.95, probs.y = 0.35)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaitdlog_+3A_truncate">truncate</code>, <code id="gaitdlog_+3A_max.support">max.support</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_a.mix">a.mix</code>, <code id="gaitdlog_+3A_i.mix">i.mix</code>, <code id="gaitdlog_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_a.mlm">a.mlm</code>, <code id="gaitdlog_+3A_i.mlm">i.mlm</code>, <code id="gaitdlog_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_lshape.p">lshape.p</code>, <code id="gaitdlog_+3A_lshape.a">lshape.a</code>, <code id="gaitdlog_+3A_lshape.i">lshape.i</code>, <code id="gaitdlog_+3A_lshape.d">lshape.d</code></td>
<td>

<p>Link functions.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>
and <code><a href="#topic+Links">Links</a></code> for more choices
and information.  Actually, it is usually
a good idea to set these arguments equal to
<code><a href="VGAMextra.html#topic+logffMlink">logffMlink</a></code> because
the log-mean is the first linear/additive
predictor so it is like a Poisson regression.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_eq.ap">eq.ap</code>, <code id="gaitdlog_+3A_eq.ip">eq.ip</code>, <code id="gaitdlog_+3A_eq.dp">eq.dp</code></td>
<td>

<p>Single logical each.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_parallel.a">parallel.a</code>, <code id="gaitdlog_+3A_parallel.i">parallel.i</code>, <code id="gaitdlog_+3A_parallel.d">parallel.d</code></td>
<td>

<p>Single logical each.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_type.fitted">type.fitted</code>, <code id="gaitdlog_+3A_mux.init">mux.init</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_imethod">imethod</code>, <code id="gaitdlog_+3A_ipobs.mix">ipobs.mix</code>, <code id="gaitdlog_+3A_ipstr.mix">ipstr.mix</code>, <code id="gaitdlog_+3A_ipdip.mix">ipdip.mix</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>

</td></tr>
<tr><td><code id="gaitdlog_+3A_ipobs.mlm">ipobs.mlm</code>, <code id="gaitdlog_+3A_ipstr.mlm">ipstr.mlm</code>, <code id="gaitdlog_+3A_ipdip.mlm">ipdip.mlm</code>, <code id="gaitdlog_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_gpstr.mix">gpstr.mix</code>, <code id="gaitdlog_+3A_gpstr.mlm">gpstr.mlm</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_gshape.p">gshape.p</code>, <code id="gaitdlog_+3A_ishape.p">ishape.p</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
The former argument is used only if the
latter is not given.  Practical experience
has shown that good initial values are needed,
so if convergence is not obtained then try a
finer grid.
</p>

</td></tr>
<tr><td><code id="gaitdlog_+3A_ishape.a">ishape.a</code>, <code id="gaitdlog_+3A_ishape.i">ishape.i</code>, <code id="gaitdlog_+3A_ishape.d">ishape.d</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>

</td></tr>
<tr><td><code id="gaitdlog_+3A_probs.y">probs.y</code>, <code id="gaitdlog_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gaitdlog_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>
and <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many details to this family function can be
found in <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> because it
is also a 1-parameter discrete distribution.
This function currently does not handle
multiple responses.  Further details are at
<code><a href="#topic+Gaitdlog">Gaitdlog</a></code>.



</p>
<p>As alluded to above, when there are covariates
it is much more interpretable to model
the mean rather than the shape parameter.
Hence <code><a href="VGAMextra.html#topic+logffMlink">logffMlink</a></code> is
recommended.  (This might become the default
in the future.)  So installing <span class="pkg">VGAMextra</span>
is a good idea.
</p>
<p>Apart from the order of the linear/additive predictors,
the following are (or should be) equivalent:
<code>gaitdlog()</code> and <code>logff()</code>,
<code>gaitdlog(a.mix = 1)</code> and <code>oalog(zero = "pobs1")</code>,
<code>gaitdlog(i.mix = 1)</code> and <code>oilog(zero = "pstr1")</code>,
<code>gaitdlog(truncate = 1)</code> and <code>otlog()</code>.
The functions
<code><a href="VGAMdata.html#topic+oalog">oalog</a></code>,
<code><a href="VGAMdata.html#topic+oilog">oilog</a></code> and
<code><a href="VGAMdata.html#topic+otlog">otlog</a></code>
have been placed in <span class="pkg">VGAMdata</span>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such
as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>





<h3>Warning </h3>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gaitdlog">Gaitdlog</a></code>,
<code><a href="#topic+logff">logff</a></code>,
<code><a href="VGAMextra.html#topic+logffMlink">logffMlink</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+goffset">goffset</a></code>,
<code><a href="#topic+Trunc">Trunc</a></code>,
<code><a href="VGAMdata.html#topic+oalog">oalog</a></code>,
<code><a href="VGAMdata.html#topic+oilog">oilog</a></code>,
<code><a href="VGAMdata.html#topic+otlog">otlog</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+rootogram4">rootogram4</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>avec &lt;- c(5, 10)  # Alter these values parametrically
ivec &lt;- c(3, 15)  # Inflate these values
tvec &lt;- c(6, 7)   # Truncate these values
max.support &lt;- 20; set.seed(1)
pobs.a &lt;- pstr.i &lt;- 0.1
gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, shape.p = logitlink(2+0.5*x2, inverse = TRUE))
gdata &lt;- transform(gdata,
  y1 = rgaitdlog(nn, shape.p, a.mix = avec, pobs.mix = pobs.a,
                i.mix = ivec, pstr.mix = pstr.i, truncate = tvec,
                max.support = max.support))
gaitdlog(a.mix = avec, i.mix = ivec, max.support = max.support)
with(gdata, table(y1))
## Not run:  spikeplot(with(gdata, y1), las = 1) 
fit7 &lt;- vglm(y1 ~ x2, trace = TRUE, data = gdata,
             gaitdlog(i.mix = ivec, truncate = tvec,
                      max.support = max.support, a.mix = avec,
                      eq.ap = TRUE, eq.ip = TRUE))
head(fitted(fit7, type.fitted = "Pstr.mix"))
head(predict(fit7))
t(coef(fit7, matrix = TRUE))  # Easier to see with t()
summary(fit7)
## Not run:  spikeplot(with(gdata, y1), lwd = 2, ylim = c(0, 0.4))
plotdgaitd(fit7, new.plot = FALSE, offset.x = 0.2, all.lwd = 2)  
## End(Not run)
</code></pre>

<hr>
<h2 id='Gaitdlog'> Generally Altered, Inflated, Truncated
and Deflated
Logarithmic Distribution
</h2><span id='topic+Gaitdlog'></span><span id='topic+dgaitdlog'></span><span id='topic+pgaitdlog'></span><span id='topic+qgaitdlog'></span><span id='topic+rgaitdlog'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function
and random generation
for the generally altered, inflated, truncated
and deflated
logarithmic distribution.
Both parametric and nonparametric variants are
supported; these are based on finite mixtures
of the parent with itself and the multinomial
logit model (MLM) respectively.
</p>







<h3>Usage</h3>

<pre><code class='language-R'>dgaitdlog(x, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p,
          log = FALSE)
pgaitdlog(q, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p,
          lower.tail = TRUE)
qgaitdlog(p, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p)
rgaitdlog(n, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaitdlog_+3A_x">x</code>, <code id="Gaitdlog_+3A_q">q</code>, <code id="Gaitdlog_+3A_p">p</code>, <code id="Gaitdlog_+3A_n">n</code>, <code id="Gaitdlog_+3A_log">log</code>, <code id="Gaitdlog_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as in <code><a href="#topic+dlog">dlog</a></code>.
</p>
</td></tr>
<tr><td><code id="Gaitdlog_+3A_shape.p">shape.p</code>, <code id="Gaitdlog_+3A_shape.a">shape.a</code>, <code id="Gaitdlog_+3A_shape.i">shape.i</code>, <code id="Gaitdlog_+3A_shape.d">shape.d</code></td>
<td>

<p>Same meaning as <code>shape</code> for
<code><a href="#topic+dlog">dlog</a></code>, i.e., for an
ordinary logarithmic distribution.
See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic
information.
</p>
</td></tr>
<tr><td><code id="Gaitdlog_+3A_truncate">truncate</code>, <code id="Gaitdlog_+3A_max.support">max.support</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic
information.
</p>
</td></tr>
<tr><td><code id="Gaitdlog_+3A_a.mix">a.mix</code>, <code id="Gaitdlog_+3A_i.mix">i.mix</code>, <code id="Gaitdlog_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic
information.
</p>
</td></tr>
<tr><td><code id="Gaitdlog_+3A_a.mlm">a.mlm</code>, <code id="Gaitdlog_+3A_i.mlm">i.mlm</code>, <code id="Gaitdlog_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic
information.
</p>
</td></tr>
<tr><td><code id="Gaitdlog_+3A_pobs.mlm">pobs.mlm</code>, <code id="Gaitdlog_+3A_pstr.mlm">pstr.mlm</code>, <code id="Gaitdlog_+3A_pdip.mlm">pdip.mlm</code>, <code id="Gaitdlog_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic
information.
</p>
</td></tr>
<tr><td><code id="Gaitdlog_+3A_pobs.mix">pobs.mix</code>, <code id="Gaitdlog_+3A_pstr.mix">pstr.mix</code>, <code id="Gaitdlog_+3A_pdip.mix">pdip.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>



</table>


<h3>Details</h3>

<p>These functions for the logarithmic distribution
are analogous to the Poisson,
hence most details have been put in
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
These functions do what
<code><a href="VGAMdata.html#topic+Oalog">Oalog</a></code>,
<code><a href="VGAMdata.html#topic+Oilog">Oilog</a></code>,
<code><a href="VGAMdata.html#topic+Otlog">Otlog</a></code>
collectively did plus much more.
</p>











<h3>Value</h3>

<p><code>dgaitdlog</code> gives the density,
<code>pgaitdlog</code> gives the distribution function,
<code>qgaitdlog</code> gives the quantile function, and
<code>rgaitdlog</code> generates random deviates.
The default values of the arguments correspond to ordinary
<code><a href="#topic+dlog">dlog</a></code>,
<code><a href="#topic+plog">plog</a></code>,
<code><a href="#topic+qlog">qlog</a></code>,
<code><a href="#topic+rlog">rlog</a></code>
respectively.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> about the dangers
of too much inflation and/or deflation on
GAITD PMFs, and the difficulties detecting such.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for general information also relevant
to this parent distribution.
</p>







<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+Gaitdzeta">Gaitdzeta</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="VGAMdata.html#topic+Oalog">Oalog</a></code>,
<code><a href="VGAMdata.html#topic+Oilog">Oilog</a></code>,
<code><a href="VGAMdata.html#topic+Otlog">Otlog</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ivec &lt;- c(2, 10); avec &lt;- ivec + 1; shape &lt;- 0.995; xgrid &lt;- 0:15
max.support &lt;- 15; pobs.a &lt;- 0.10; pstr.i &lt;- 0.15
dvec &lt;- 1; pdip.mlm &lt;- 0.05
(ddd &lt;- dgaitdlog(xgrid, shape,
   max.support = max.support, pobs.mix = pobs.a,
   pdip.mlm = pdip.mlm, d.mlm = dvec,
   a.mix = avec, pstr.mix = pstr.i, i.mix = ivec))
## Not run:  dgaitdplot(shape, ylab = "Probability", xlab = "x",
   max.support = max.support, pobs.mix = 0,
   pobs.mlm = 0, a.mlm = avec, all.lwd = 3,
   pdip.mlm = pdip.mlm, d.mlm = dvec, fam = "log",
   pstr.mix = pstr.i, i.mix = ivec, deflation = TRUE,
   main = "GAITD Combo PMF---Logarithmic Parent")   
## End(Not run)
</code></pre>

<hr>
<h2 id='Gaitdnbinom'> Generally Altered, Inflated, Truncated
and Deflated
Negative Binomial Distribution
</h2><span id='topic+Gaitdnbinom'></span><span id='topic+dgaitdnbinom'></span><span id='topic+pgaitdnbinom'></span><span id='topic+qgaitdnbinom'></span><span id='topic+rgaitdnbinom'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function
and random generation
for the generally altered, inflated, truncated and
deflated negative binomial (GAITD-NB) distribution.
Both parametric and nonparametric variants are
supported; these are based on finite mixtures
of the parent with itself and the multinomial
logit model (MLM) respectively.
</p>








<h3>Usage</h3>

<pre><code class='language-R'>dgaitdnbinom(x, size.p, munb.p,
             a.mix = NULL, a.mlm = NULL,
             i.mix = NULL, i.mlm = NULL,
             d.mix = NULL, d.mlm = NULL, truncate = NULL,
             max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
             pstr.mix = 0, pstr.mlm = 0,
             pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
             size.a = size.p, size.i = size.p, size.d = size.p,
             munb.a = munb.p, munb.i = munb.p, munb.d = munb.p,
             log = FALSE)
pgaitdnbinom(q, size.p, munb.p,
             a.mix = NULL, a.mlm = NULL,
             i.mix = NULL, i.mlm = NULL,
             d.mix = NULL, d.mlm = NULL, truncate = NULL,
             max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
             pstr.mix = 0, pstr.mlm = 0,
             pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
             size.a = size.p, size.i = size.p, size.d = size.p,
             munb.a = munb.p, munb.i = munb.p, munb.d = munb.p,
             lower.tail = TRUE)
qgaitdnbinom(p, size.p, munb.p,
             a.mix = NULL, a.mlm = NULL,
             i.mix = NULL, i.mlm = NULL,
             d.mix = NULL, d.mlm = NULL, truncate = NULL,
             max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
             pstr.mix = 0, pstr.mlm = 0,
             pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
             size.a = size.p, size.i = size.p, size.d = size.p,
             munb.a = munb.p, munb.i = munb.p, munb.d = munb.p)
rgaitdnbinom(n, size.p, munb.p,
             a.mix = NULL, a.mlm = NULL,
             i.mix = NULL, i.mlm = NULL,
             d.mix = NULL, d.mlm = NULL, truncate = NULL,
             max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
             pstr.mix = 0, pstr.mlm = 0,
             pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
             size.a = size.p, size.i = size.p, size.d = size.p,
             munb.a = munb.p, munb.i = munb.p, munb.d = munb.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaitdnbinom_+3A_x">x</code>, <code id="Gaitdnbinom_+3A_q">q</code>, <code id="Gaitdnbinom_+3A_p">p</code>, <code id="Gaitdnbinom_+3A_n">n</code>, <code id="Gaitdnbinom_+3A_log">log</code>, <code id="Gaitdnbinom_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+rnbinom">rnbinom</a></code>.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_size.p">size.p</code>, <code id="Gaitdnbinom_+3A_munb.p">munb.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+rnbinom">rnbinom</a></code>.
See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_size.a">size.a</code>, <code id="Gaitdnbinom_+3A_munb.a">munb.a</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_size.i">size.i</code>, <code id="Gaitdnbinom_+3A_munb.i">munb.i</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_size.d">size.d</code>, <code id="Gaitdnbinom_+3A_munb.d">munb.d</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_truncate">truncate</code>, <code id="Gaitdnbinom_+3A_max.support">max.support</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_a.mix">a.mix</code>, <code id="Gaitdnbinom_+3A_i.mix">i.mix</code>, <code id="Gaitdnbinom_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_a.mlm">a.mlm</code>, <code id="Gaitdnbinom_+3A_i.mlm">i.mlm</code>, <code id="Gaitdnbinom_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_pobs.mlm">pobs.mlm</code>, <code id="Gaitdnbinom_+3A_pstr.mlm">pstr.mlm</code>, <code id="Gaitdnbinom_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_pobs.mix">pobs.mix</code>, <code id="Gaitdnbinom_+3A_pstr.mix">pstr.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdnbinom_+3A_pdip.mix">pdip.mix</code>, <code id="Gaitdnbinom_+3A_pdip.mlm">pdip.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>



</table>


<h3>Details</h3>

<p>These functions for the NBD are analogous to the Poisson,
hence most details have been put in
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
The NBD has two possible parameterizations: one
involving a probability (argument begins with <code>prob</code>)
and the other the mean (beginning with <code>mu</code>).
Only the latter is supported here.
</p>



<p>For now, arguments such as <code>prob.p</code> and <code>prob.a</code>
are no longer supported.
That's because <code>mu</code> is more likely to be
used by most statisticians than <code>prob</code>;
see <code><a href="stats.html#topic+NegBinomial">dnbinom</a></code>.
</p>


<h3>Value</h3>

<p><code>dgaitdnbinom</code> gives the density,
<code>pgaitdnbinom</code> gives the distribution function,
<code>qgaitdnbinom</code> gives the quantile function, and
<code>rgaitdnbinom</code> generates random deviates.
The default values of the arguments correspond to ordinary
<code><a href="stats.html#topic+NegBinomial">dnbinom</a></code>,
<code><a href="stats.html#topic+NegBinomial">pnbinom</a></code>,
<code><a href="stats.html#topic+NegBinomial">qnbinom</a></code>,
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code>
respectively.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> about the dangers
of too much inflation and/or deflation on
GAITD PMFs, and the difficulties detecting such.
</p>


<h3>Note</h3>

<p>Four functions were moved from <span class="pkg">VGAM</span> to <span class="pkg">VGAMdata</span>;
they can be seen at <code><a href="VGAMdata.html#topic+Posnegbin">Posnegbin</a></code>.
It is preferable to use
<code>dgaitdnbinom(x, size, munb.p = munb, truncate = 0)</code>
instead of <code>dposnbinom(x, size, munb = munb)</code>, etc.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+Gaitdbinom">Gaitdbinom</a></code>,
<code><a href="#topic+Gaitdlog">Gaitdlog</a></code>,
<code><a href="#topic+Gaitdzeta">Gaitdzeta</a></code>.
</p>
















<h3>Examples</h3>

<pre><code class='language-R'>size &lt;- 10; xgrid &lt;- 0:25
ivec &lt;- c(5, 6, 10, 14); avec &lt;- c(8, 11); munb &lt;- 10
tvec &lt;- 15; pobs.a &lt;- 0.05; pstr.i &lt;- 0.25
dvec &lt;- 13; pdip.mlm &lt;- 0.03; pobs.mlm &lt;- 0.05
(ddd &lt;- dgaitdnbinom(xgrid, size, munb.p = munb, munb.a = munb + 5,
   truncate = tvec, pobs.mix = pobs.a,
   pdip.mlm = pdip.mlm, d.mlm = dvec,
   pobs.mlm = pobs.a, a.mlm = avec,
   pstr.mix = pstr.i, i.mix = ivec))
## Not run: dgaitdplot(c(size, munb), fam = "nbinom",
  ylab = "Probability", xlab = "x", xlim = c(0, 25),
  truncate = tvec, pobs.mix = pobs.mix,
  pobs.mlm = pobs.mlm, a.mlm = avec, all.lwd = 3,
  pdip.mlm = pdip.mlm, d.mlm = dvec,
  pstr.mix = pstr.i, i.mix = ivec, deflation = TRUE,
  main = "GAITD Combo PMF---NB Parent")   
## End(Not run)
</code></pre>

<hr>
<h2 id='gaitdnbinomial'> Generally Altered, Inflated, Truncated and Deflated
Negative Binomial Regression
</h2><span id='topic+gaitdnbinomial'></span>

<h3>Description</h3>

<p>Fits a generally altered, inflated truncated and deflated
negative binomial regression by MLE.
The GAITD combo model having 7 types of special values
is implemented.
This allows mixtures of negative binomial distributions
on nested and/or partitioned
support as well as a multinomial logit model for
(nonparametric) altered, inflated and deflated values.
</p>



<h3>Usage</h3>

<pre><code class='language-R'> gaitdnbinomial(a.mix = NULL, i.mix = NULL, d.mix = NULL,
     a.mlm = NULL, i.mlm = NULL, d.mlm = NULL,
     truncate = NULL, zero = c("size", "pobs", "pstr", "pdip"),
     eq.ap = TRUE, eq.ip = TRUE, eq.dp = TRUE,
     parallel.a = FALSE, parallel.i = FALSE, parallel.d = FALSE,
     lmunb.p = "loglink",
     lmunb.a = lmunb.p, lmunb.i = lmunb.p, lmunb.d = lmunb.p,
     lsize.p = "loglink",
     lsize.a = lsize.p, lsize.i = lsize.p, lsize.d = lsize.p,
     type.fitted = c("mean", "munbs", "sizes", "pobs.mlm",
     "pstr.mlm", "pdip.mlm", "pobs.mix", "pstr.mix", "pdip.mix",
     "Pobs.mix", "Pstr.mix", "Pdip.mix", "nonspecial", "Numer",
     "Denom.p", "sum.mlm.i", "sum.mix.i",
     "sum.mlm.d", "sum.mix.d", "ptrunc.p", "cdf.max.s"),
     gpstr.mix = ppoints(7) / 3,
     gpstr.mlm = ppoints(7) / (3 + length(i.mlm)),
     imethod = 1, mux.init = c(0.75, 0.5, 0.75, 0.5),
     imunb.p = NULL, imunb.a = imunb.p,
     imunb.i = imunb.p, imunb.d = imunb.p,
     isize.p = NULL,  isize.a = isize.p,
     isize.i = isize.p, isize.d = isize.p,
     ipobs.mix = NULL, ipstr.mix = NULL,
     ipdip.mix = NULL, ipobs.mlm = NULL,
     ipstr.mlm = NULL, ipdip.mlm = NULL,
     byrow.aid = FALSE, ishrinkage = 0.95, probs.y = 0.35,
     nsimEIM = 500, cutoff.prob = 0.999, eps.trig = 1e-7,
     nbd.max.support = 4000, max.chunk.MB = 30)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="gaitdnbinomial_+3A_truncate">truncate</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_a.mix">a.mix</code>, <code id="gaitdnbinomial_+3A_i.mix">i.mix</code>, <code id="gaitdnbinomial_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_a.mlm">a.mlm</code>, <code id="gaitdnbinomial_+3A_i.mlm">i.mlm</code>, <code id="gaitdnbinomial_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_lmunb.p">lmunb.p</code>, <code id="gaitdnbinomial_+3A_lmunb.a">lmunb.a</code>, <code id="gaitdnbinomial_+3A_lmunb.i">lmunb.i</code>, <code id="gaitdnbinomial_+3A_lmunb.d">lmunb.d</code></td>
<td>

<p>Link functions pertaining to the mean parameters.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> where <code>llambda.p</code>
etc. are
the equivalent.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_lsize.p">lsize.p</code>, <code id="gaitdnbinomial_+3A_lsize.a">lsize.a</code>, <code id="gaitdnbinomial_+3A_lsize.i">lsize.i</code>, <code id="gaitdnbinomial_+3A_lsize.d">lsize.d</code></td>
<td>

<p>Link functions pertaining to the <code>size</code> parameters.
See <code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_eq.ap">eq.ap</code>, <code id="gaitdnbinomial_+3A_eq.ip">eq.ip</code>, <code id="gaitdnbinomial_+3A_eq.dp">eq.dp</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
These apply to both <code>munb</code> and <code>size</code> parameters
simultaneously.
See <code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code> also.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_parallel.a">parallel.a</code>, <code id="gaitdnbinomial_+3A_parallel.i">parallel.i</code>, <code id="gaitdnbinomial_+3A_parallel.d">parallel.d</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_gpstr.mix">gpstr.mix</code>, <code id="gaitdnbinomial_+3A_gpstr.mlm">gpstr.mlm</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>



<tr><td><code id="gaitdnbinomial_+3A_imethod">imethod</code>, <code id="gaitdnbinomial_+3A_ipobs.mix">ipobs.mix</code>, <code id="gaitdnbinomial_+3A_ipstr.mix">ipstr.mix</code>, <code id="gaitdnbinomial_+3A_ipdip.mix">ipdip.mix</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_ipobs.mlm">ipobs.mlm</code>, <code id="gaitdnbinomial_+3A_ipstr.mlm">ipstr.mlm</code>, <code id="gaitdnbinomial_+3A_ipdip.mlm">ipdip.mlm</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_mux.init">mux.init</code></td>
<td>

<p>Numeric, of length 4.
General downward multiplier for initial values for
the sample proportions (MLEs actually).
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
The fourth value corresponds to <code>size</code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_imunb.p">imunb.p</code>, <code id="gaitdnbinomial_+3A_imunb.a">imunb.a</code>, <code id="gaitdnbinomial_+3A_imunb.i">imunb.i</code>, <code id="gaitdnbinomial_+3A_imunb.d">imunb.d</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>;
<code>imunb.p</code> is similar to  <code>ilambda.p</code>, etc.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_isize.p">isize.p</code>, <code id="gaitdnbinomial_+3A_isize.a">isize.a</code>, <code id="gaitdnbinomial_+3A_isize.i">isize.i</code>, <code id="gaitdnbinomial_+3A_isize.d">isize.d</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>;
<code>isize.p</code> is similar to  <code>ilambda.p</code>, etc.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_probs.y">probs.y</code>, <code id="gaitdnbinomial_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>Details are at <code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_nsimeim">nsimEIM</code>, <code id="gaitdnbinomial_+3A_cutoff.prob">cutoff.prob</code>, <code id="gaitdnbinomial_+3A_eps.trig">eps.trig</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdnbinomial_+3A_nbd.max.support">nbd.max.support</code>, <code id="gaitdnbinomial_+3A_max.chunk.mb">max.chunk.MB</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GAITD&ndash;NB combo model is the pinnacle of GAITD regression
for counts because it potentially handles
underdispersion, 
equidispersion and
overdispersion relative to the Poisson,
as well as
alteration,
inflation,
deflation and
truncation at arbitrary support points.
In contrast, <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> cannot handle
overdispersion so well.
The GAITD&ndash;NB is so flexible that it can accommodate up to
seven modes.
</p>
<p>The full
GAITD&ndash;NB&ndash;NB&ndash;MLM&ndash;NB-MLM&ndash;NB-MLM combo model
may be fitted with this family function.
There are seven types of special values and all
arguments for these
may be used in a single model.
Here, the MLM represents the nonparametric while the NB
refers to the negative binomial mixtures.
The defaults for this function correspond to an
ordinary negative binomial
regression so that <code><a href="#topic+negbinomial">negbinomial</a></code> is called instead.
</p>
<p>While much of the documentation here draws upon
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>, there are additional
details here because the NBD is a <em>two</em> parameter
distribution that handles <em>overdispersion</em> relative
to the Possion.
Consequently, this family function is exceeding flexible
and there are many more pitfalls to avoid.
</p>
<p>The order of the linear/additive predictors is
best explained by an example.
Suppose a combo model has
<code>length(a.mix) &gt; 3</code> and
<code>length(i.mix) &gt; 3</code>,
<code>length(d.mix) &gt; 3</code>,
<code>a.mlm = 3:5</code>,
<code>i.mlm = 6:9</code> and
<code>d.mlm = 10:12</code>, say.
Then <code>loglink(munb.p)</code> and <code>loglink(size.p)</code>
are the first two.
The third is <code>multilogitlink(pobs.mix)</code> followed
by <code>loglink(munb.a)</code>
and <code>loglink(size.a)</code>
because <code>a.mix</code> is long enough.
The sixth is <code>multilogitlink(pstr.mix)</code> followed
by <code>loglink(munb.i)</code>
and <code>loglink(size.i)</code>
because <code>i.mix</code> is long enough.
The ninth is <code>multilogitlink(pdip.mix)</code> followed
by <code>loglink(munb.d)</code>
and <code>loglink(size.d)</code>
because <code>d.mix</code> is long enough.
Next are the probabilities for the <code>a.mlm</code> values.
Then are the probabilities for the <code>i.mlm</code> values.
Lastly are the probabilities for the <code>d.mlm</code> values.
All the probabilities are estimated by one big MLM
and effectively
the <code>"(Others)"</code> column of left over probabilities is
associated with the nonspecial values.
These might be called the
<em>nonspecial baseline probabilities</em> (NBP)
or reserve probabilities.
The dimension of the vector of linear/additive predictors here
is <code class="reqn">M=21</code>.
</p>

<p>Apart from the order of the linear/additive predictors,
the following are (or should be) equivalent:
<code>gaitdnbinomial()</code> and <code>negbinomial()</code>,
<code>gaitdnbinomial(a.mix = 0)</code>
and <code>zanegbinomial(zero = "pobs0")</code>,
<code>gaitdnbinomial(i.mix = 0)</code>
and <code>zinegbinomial(zero = "pstr0")</code>,
<code>gaitdnbinomial(truncate = 0)</code>
and <code>posnegbinomial()</code>.
Likewise, if
<code>a.mix</code> and <code>i.mix</code> are assigned a scalar then
it effectively moves that scalar to <code>a.mlm</code>
and <code>i.mlm</code>
because there is no
parameters such as <code>munb.i</code> being estimated.
Thus
<code>gaitdnbinomial(a.mix = 0)</code>
and <code>gaitdnbinomial(a.mlm = 0)</code>
are the effectively same, and ditto for
<code>gaitdnbinomial(i.mix = 0)</code>
and <code>gaitdnbinomial(i.mlm = 0)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>The <code>fitted.values</code> slot of the fitted object,
which should be extracted by the generic function <code>fitted</code>,
returns the mean <code class="reqn">\mu</code> by default.
See the information above on <code>type.fitted</code>.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
Also, having <code>eq.ap = TRUE</code>, <code>eq.ip = TRUE</code>
and <code>eq.dp = TRUE</code> is often needed to obtain
initial values that are good enough because they borrow
strength across the different operators.
It is usually easy to relax these assumptions later.
</p>
<p>This family function is under constant development and
future changes will occur.
</p>


<h3>Note</h3>

<p>If <code>length(a.mix)</code> is 1 then effectively this becomes a
value of <code>a.mlm</code>.
If <code>length(a.mix)</code> is 2 then an error message
will be issued (overfitting really).
If <code>length(a.mix)</code> is 3 then this is almost
overfitting too.
Hence <code>length(a.mix)</code> should be 4 or more.
Ditto for <code>length(i.mix)</code> and <code>length(d.mix)</code>.
</p>
<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for notes about numerical
problems that can easily arise. With the NBD there is
even more potential trouble that can occur.
In particular, good initial values are more necessary so
it pays to experiment with arguments such as
<code>imunb.p</code> and <code>isize.p</code>, as well as
fitting an intercept-only model first before adding
covariates and using <code>etastart</code>.
</p>
<p>Currently <code>max.support</code> is missing because only
<code>Inf</code> is handled. This might change later.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>





<h3>See Also</h3>

<p><code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
<code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+rootogram4">rootogram4</a></code>,
<code><a href="#topic+specials">specials</a></code>,
<code><a href="#topic+plotdgaitd">plotdgaitd</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+meangaitd">meangaitd</a></code>,
<code><a href="#topic+KLD">KLD</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="#topic+multilogitlink">multilogitlink</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+goffset">goffset</a></code>,
<code><a href="#topic+Trunc">Trunc</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>















<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
i.mix &lt;- c(5, 10, 12, 16)  # Inflate these values parametrically
i.mlm &lt;- c(14, 15)  # Inflate these values
a.mix &lt;- c(1, 6, 13, 20)  # Alter these values
tvec &lt;- c(3, 11)   # Truncate these values
pstr.mlm &lt;- 0.1  # So parallel.i = TRUE
pobs.mix &lt;- pstr.mix &lt;- 0.1; set.seed(1)
gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, munb.p = exp(2 + 0.0 * x2),
                   size.p = exp(1))
gdata &lt;- transform(gdata,
  y1 = rgaitdnbinom(nn, size.p, munb.p, a.mix = a.mix,
                    i.mix = i.mix,
                    pobs.mix = pobs.mix, pstr.mix = pstr.mix,
                    i.mlm = i.mlm, pstr.mlm = pstr.mlm,
                    truncate = tvec))
gaitdnbinomial(a.mix = a.mix, i.mix = i.mix, i.mlm = i.mlm)
with(gdata, table(y1))
fit1 &lt;- vglm(y1 ~ 1, crit = "coef", trace = TRUE, data = gdata,
             gaitdnbinomial(a.mix = a.mix, i.mix = i.mix,
                            i.mlm = i.mlm,
                            parallel.i = TRUE, eq.ap = TRUE,
                            eq.ip = TRUE, truncate = tvec))
head(fitted(fit1, type.fitted = "Pstr.mix"))
head(predict(fit1))
t(coef(fit1, matrix = TRUE))  # Easier to see with t()
summary(fit1)
spikeplot(with(gdata, y1), lwd = 2)
plotdgaitd(fit1, new.plot = FALSE, offset.x = 0.2, all.lwd = 2)  
## End(Not run)
</code></pre>

<hr>
<h2 id='Gaitdpois'> Generally Altered, Inflated, Truncated
and Deflated
Poisson Distribution
</h2><span id='topic+Gaitdpois'></span><span id='topic+dgaitdpois'></span><span id='topic+pgaitdpois'></span><span id='topic+qgaitdpois'></span><span id='topic+rgaitdpois'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function
and random generation
for the generally altered, inflated, truncated
and deflated
Poisson distribution.
Both parametric and nonparametric variants
are supported; these are based on
finite mixtures of the parent with itself and
the multinomial logit model (MLM) respectively.
</p>







<h3>Usage</h3>

<pre><code class='language-R'>dgaitdpois(x, lambda.p, a.mix = NULL, a.mlm = NULL, i.mix = NULL,
       i.mlm = NULL, d.mix = NULL, d.mlm = NULL, truncate = NULL,
       max.support = Inf, pobs.mix = 0, pobs.mlm = 0, pstr.mix = 0,
       pstr.mlm = 0, pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
       lambda.a = lambda.p, lambda.i = lambda.p,
       lambda.d = lambda.p, log = FALSE)
pgaitdpois(q, lambda.p, a.mix = NULL, a.mlm = NULL, i.mix = NULL,
       i.mlm = NULL, d.mix = NULL, d.mlm = NULL, truncate = NULL,
       max.support = Inf, pobs.mix = 0, pobs.mlm = 0, pstr.mix = 0,
       pstr.mlm = 0, pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
       lambda.a = lambda.p, lambda.i = lambda.p,
       lambda.d = lambda.p, lower.tail = TRUE, checkd = FALSE)
qgaitdpois(p, lambda.p, a.mix = NULL, a.mlm = NULL, i.mix = NULL,
       i.mlm = NULL, d.mix = NULL, d.mlm = NULL, truncate = NULL,
       max.support = Inf, pobs.mix = 0, pobs.mlm = 0, pstr.mix = 0,
       pstr.mlm = 0, pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
       lambda.a = lambda.p, lambda.i = lambda.p, lambda.d = lambda.p)
rgaitdpois(n, lambda.p, a.mix = NULL, a.mlm = NULL, i.mix = NULL,
       i.mlm = NULL, d.mix = NULL, d.mlm = NULL, truncate = NULL,
       max.support = Inf, pobs.mix = 0, pobs.mlm = 0, pstr.mix = 0,
       pstr.mlm = 0, pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
       lambda.a = lambda.p, lambda.i = lambda.p, lambda.d = lambda.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaitdpois_+3A_x">x</code>, <code id="Gaitdpois_+3A_q">q</code>, <code id="Gaitdpois_+3A_p">p</code>, <code id="Gaitdpois_+3A_n">n</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Poisson">Poisson</a></code>.
</p>
</td></tr>
<tr><td><code id="Gaitdpois_+3A_log">log</code>, <code id="Gaitdpois_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Poisson">Poisson</a></code>.
</p>
</td></tr>
<tr><td><code id="Gaitdpois_+3A_lambda.p">lambda.p</code>, <code id="Gaitdpois_+3A_lambda.a">lambda.a</code>, <code id="Gaitdpois_+3A_lambda.i">lambda.i</code>, <code id="Gaitdpois_+3A_lambda.d">lambda.d</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Poisson">Poisson</a></code>,
i.e., for an ordinary Poisson distribution.
The first is for the main <em>p</em>arent (or base) distribution.
The next two concern the parametric variant and
these distributions (usually spikes) may be
<em>a</em>ltered and/or <em>i</em>nflated.
The last one concerns the <em>d</em>eflated variant.
Short vectors are recycled.
</p>
</td></tr>
<tr><td><code id="Gaitdpois_+3A_truncate">truncate</code>, <code id="Gaitdpois_+3A_max.support">max.support</code></td>
<td>

<p>numeric; these specify the set of truncated values.
The default value of <code>NULL</code> means an empty set
for the former.
The latter is the
maximum support value so that any value larger
has been truncated (necessary because
<code>truncate = (max.support + 1):Inf</code> is not allowed),
hence is needed for truncating the upper tail of the
distribution.  Note that <code>max(truncate) &lt; max.support</code>
must be satisfied otherwise an error message will be issued.
</p>
</td></tr>
<tr><td><code id="Gaitdpois_+3A_a.mix">a.mix</code>, <code id="Gaitdpois_+3A_i.mix">i.mix</code>, <code id="Gaitdpois_+3A_d.mix">d.mix</code></td>
<td>

<p>Vectors of nonnegative integers;
the altered, inflated and deflated values for the
parametric variant.
Each argument must have unique values only.
Assigning argument <code>a.mix</code>
means that <code>pobs.mix</code> will be used.
Assigning <code>i.mix</code>
means that <code>pstr.mix</code> will be used.
Assigning <code>d.mix</code>
means that <code>pdip.mix</code> will be used.
If <code>a.mix</code> is of unit length
then the default probability mass function (PMF)
evaluated at <code>a.mix</code> will be <code>pobs.mix</code>.
So having <code>a.mix = 0</code> corresponds to the
zero-inflated Poisson distribution (see <code><a href="#topic+Zipois">Zipois</a></code>).
</p>

</td></tr>
<tr><td><code id="Gaitdpois_+3A_a.mlm">a.mlm</code>, <code id="Gaitdpois_+3A_i.mlm">i.mlm</code>, <code id="Gaitdpois_+3A_d.mlm">d.mlm</code></td>
<td>

<p>Similar to the above, but for the nonparametric (MLM) variant.
For example, assigning <code>a.mlm</code>
means that <code>pobs.mlm</code> will be used.
Collectively, the above 7 arguments represent
7 disjoint sets of
special values and they are a proper subset of the support
of the distribution.
</p>
</td></tr>
<tr><td><code id="Gaitdpois_+3A_pobs.mlm">pobs.mlm</code>, <code id="Gaitdpois_+3A_pstr.mlm">pstr.mlm</code>, <code id="Gaitdpois_+3A_pdip.mlm">pdip.mlm</code>, <code id="Gaitdpois_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>The first three arguments are coerced into a matrix of
probabilities
using <code>byrow.aid</code> to determine the order of the elements
(similar to <code>byrow</code> in <code><a href="base.html#topic+matrix">matrix</a></code>, and
the <code>.aid</code> reinforces the behaviour that it applies to both
altered, inflated and deflated cases).
The first argument is recycled if necessary to become
<code>n x length(a.mlm)</code>.
The second argument becomes
<code>n x length(i.mlm)</code>.
The third argument becomes
<code>n x length(d.mlm)</code>.
Thus these arguments are not used unless
<code>a.mlm</code>, <code>i.mlm</code> and <code>d.mlm</code> are assigned.
For deflated models, <code>pdip.mix</code> and <code>pdip.mlm</code> are
positive-valued and <span class="pkg">VGAM</span> will subtract these quantities;
the argument <code>deflation</code> has been deprecated.
</p>












</td></tr>
<tr><td><code id="Gaitdpois_+3A_pobs.mix">pobs.mix</code>, <code id="Gaitdpois_+3A_pstr.mix">pstr.mix</code>, <code id="Gaitdpois_+3A_pdip.mix">pdip.mix</code></td>
<td>

<p>Vectors of probabilities that are recycled if necessary to
length <code class="reqn">n</code>.
The first  argument is used when <code>a.mix</code> is not <code>NULL</code>.
The second argument is used when <code>i.mix</code> is not <code>NULL</code>.
The third  argument is used when <code>d.mix</code> is not <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="Gaitdpois_+3A_checkd">checkd</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the density is computed
at <code>floor(q)</code> with the same parameters.
This can help detect whether the PMF is invalid.
If so, then <code>NaN</code>s are returned.  
See Example 2 below.
</p>
</td></tr>









</table>


<h3>Details</h3>

<p>These functions allow any combination of 4 operator types:
truncation, alteration, inflation and deflation.
The precedence is
truncation, then alteration and lastly inflation and deflation.
Informally, deflation can be thought of as the
opposite of inflation.
This order minimizes the potential interference among the operators.
Loosely, a set of probabilities is set to 0 by truncation
and the remaining probabilities are scaled up.
Then a different set of probabilities are set to some
values <code>pobs.mix</code> and/or <code>pobs.mlm</code>
and the remaining probabilities are rescaled up.
Then another different set of probabilities is inflated by
an amount <code>pstr.mlm</code> and/or proportional
to <code>pstr.mix</code>
so that individual elements in this set have two sources.
Then another different set of probabilities is deflated by
an amount <code>pdip.mlm</code> and/or proportional
to <code>pdip.mix</code>.
Then all the probabilities are
rescaled so that they sum to unity.
</p>
<p>Both parametric and nonparametric variants are implemented.
They usually have arguments with suffix
<code>.mix</code> and <code>.mlm</code> respectively.
The MLM is a loose coupling that effectively separates
the <em>parent</em> (or <em>base</em>) distribution from
the altered values.
Values inflated nonparametrically effectively have
their spikes shaved off.
The <code>.mix</code> variant has associated with it
<code>lambda.a</code> and <code>lambda.i</code> and <code>lambda.d</code>
because it is mixture of 4 Poisson distributions with
partitioned or nested support.
</p>
<p>Any value of the support of the distribution that is
altered, inflated, truncated or deflated
is called a <em>special</em> value.
A special value that is altered may mean that its probability
increases or decreases relative to the parent distribution.
An inflated special value means that its probability has
increased, provided alteration elsewhere has not made it decrease
in the first case.
There are seven types of special values and they are
represented by
<code>a.mix</code>,
<code>a.mlm</code>,
<code>i.mix</code>,
<code>i.mlm</code>,
<code>d.mix</code>,
<code>d.mlm</code>,
<code>truncate</code>.
</p>
<p>Terminology-wise, <em>special</em> values
are altered or inflated or truncated or deflated, and
the remaining support points that correspond directly to
the parent distribution are <em>nonspecial</em> or ordinary.
These functions do what
<code><a href="#topic+Zapois">Zapois</a></code>,
<code><a href="#topic+Zipois">Zipois</a></code>,
<code><a href="VGAMdata.html#topic+Pospois">Pospois</a></code>
collectively did plus much more.
</p>
<p>In the notation of Yee and Ma (2023)
these functions allow for the special cases:
(i) GAIT&ndash;Pois(<code>lambda.p</code>)&ndash;Pois(<code>lambda.a</code>,
<code>a.mix</code>, <code>pobs.mix</code>)&ndash;Pois(<code>lambda.i</code>,
<code>i.mix</code>, <code>pstr.mix</code>);
(ii) GAIT&ndash;Pois(<code>lambda.p</code>)&ndash;MLM(<code>a.mlm</code>,
<code>pobs.mlm</code>)&ndash;MLM(<code>i.mlm</code>, <code>pstr.mlm</code>).
Model (i) is totally parametric while model (ii) is the most
nonparametric possible.
</p>

















































<h3>Value</h3>

<p><code>dgaitdpois</code> gives the density,
<code>pgaitdpois</code> gives the distribution function,
<code>qgaitdpois</code> gives the quantile function, and
<code>rgaitdpois</code> generates random deviates.
The default values of the arguments correspond to ordinary
<code><a href="stats.html#topic+Poisson">dpois</a></code>,
<code><a href="stats.html#topic+Poisson">ppois</a></code>,
<code><a href="stats.html#topic+Poisson">qpois</a></code>,
<code><a href="stats.html#topic+Poisson">rpois</a></code>
respectively.
</p>


<h3>Warning </h3>

<p>It is possible that the GAITD PMF is invalid because
of too much inflation and/or deflation.
This would result in some probabilities exceeding
unity or being negative.
Hence <code>x</code> should ideally contain these types
of special values so that this can be detected.
If so then a <code>NaN</code> is returned and
a warning is issued, e.g.,
same as <code>dnorm(0, 0, sd = -1)</code>.
To help checking,
<code>pgaitdpois(q, ...)</code> calls
<code>dgaitdpois(floor(q), ...)</code> if <code>checkd</code>
is <code>TRUE</code>.
</p>
<p>That is, given the parameters,
it is impractical to determine whether the PMF is
valid. To do this, one would have to compute
the PMF at all values of its support and check
that they are nonnegative and sum to unity.
Hence one must be careful to input values from
the parameter space, especially for
inflation and deflation.
See Example 2 below.
</p>


















<h3>Note</h3>

<p>Functions <code><a href="VGAMdata.html#topic+Pospois">Pospois</a></code> and those similar
have been moved to <span class="pkg">VGAMdata</span>.
It is better to use
<code>dgaitdpois(x, lambda, truncate = 0)</code> instead of
<code>dposbinom(x, lambda)</code>, etc.
</p>








<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>References</h3>

<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>





<h3>See Also</h3>

<p><code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+specials">specials</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+Zapois">Zapois</a></code>,
<code><a href="#topic+Zipois">Zipois</a></code>,
<code><a href="VGAMdata.html#topic+Pospois">Pospois</a></code>
<code><a href="stats.html#topic+Poisson">Poisson</a></code>;
<code><a href="#topic+Gaitdbinom">Gaitdbinom</a></code>,
<code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
<code><a href="#topic+Gaitdlog">Gaitdlog</a></code>,
<code><a href="#topic+Gaitdzeta">Gaitdzeta</a></code>.
</p>











<h3>Examples</h3>

<pre><code class='language-R'> # Example 1
ivec &lt;- c(6, 14); avec &lt;- c(8, 11); lambda &lt;- 10; xgrid &lt;- 0:25
tvec &lt;- 15; max.support &lt;- 20; pobs.mix &lt;- 0.05; pstr.i &lt;- 0.25
dvec &lt;- 13; pdip.mlm &lt;- 0.05; pobs.mlm &lt;- 0.05
(ddd &lt;- dgaitdpois(xgrid, lambda, lambda.a = lambda + 5,
   truncate = tvec, max.support = max.support, pobs.mix = pobs.mix,
   pobs.mlm = pobs.mlm, a.mlm = avec,
   pdip.mlm = pdip.mlm, d.mlm = dvec,
   pstr.mix = pstr.i, i.mix = ivec))
## Not run:  dgaitdplot(lambda, ylab = "Probability", xlab = "x",
   truncate = tvec, max.support = max.support, pobs.mix = pobs.mix,
   pobs.mlm = pobs.mlm, a.mlm = avec, all.lwd = 3,
   pdip.mlm = pdip.mlm, d.mlm = dvec,
   pstr.mix = pstr.i, i.mix = ivec, deflation = TRUE,
   main = "GAITD Combo PMF---Poisson Parent")   
## End(Not run)

# Example 2: detection of an invalid PMF
xgrid &lt;- 1:3  # Does not cover the special values purposely
(ddd &lt;- dgaitdpois(xgrid, 1, pdip.mlm = 0.1, d.mlm = 5,
                  pstr.mix = 0.95, i.mix = 0))  # Undetected
xgrid &lt;- 0:13  # Wider range so this detects the problem
(ddd &lt;- dgaitdpois(xgrid, 1, pdip.mlm = 0.1, d.mlm = 5,
                   pstr.mix = 0.95, i.mix = 0))  # Detected
sum(ddd, na.rm = TRUE)  # Something gone awry
</code></pre>

<hr>
<h2 id='gaitdpoisson'> Generally Altered, Inflated, Truncated
and Deflated
Poisson Regression
</h2><span id='topic+gaitdpoisson'></span>

<h3>Description</h3>

<p>Fits a generally altered, inflated, truncated
and deflated Poisson regression by MLE.
The GAITD combo model having 7 types of special
values is implemented.
This allows mixtures of Poissons on nested
and/or partitioned support as well as a
multinomial logit model for (nonparametric)
altered, inflated and deflated values.
Truncation may include the upper tail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaitdpoisson(a.mix = NULL, i.mix = NULL, d.mix = NULL,
     a.mlm = NULL, i.mlm = NULL, d.mlm = NULL,
     truncate = NULL, max.support = Inf,
     zero = c("pobs", "pstr", "pdip"),
     eq.ap = TRUE, eq.ip = TRUE, eq.dp = TRUE,
     parallel.a = FALSE, parallel.i = FALSE, parallel.d = FALSE,
     llambda.p = "loglink", llambda.a = llambda.p,
     llambda.i = llambda.p, llambda.d = llambda.p,
     type.fitted = c("mean", "lambdas", "pobs.mlm", "pstr.mlm",
     "pdip.mlm", "pobs.mix", "pstr.mix", "pdip.mix",
     "Pobs.mix", "Pstr.mix", "Pdip.mix", "nonspecial",
     "Numer", "Denom.p", "sum.mlm.i", "sum.mix.i",
     "sum.mlm.d", "sum.mix.d", "ptrunc.p",
     "cdf.max.s"), gpstr.mix = ppoints(7) / 3,
     gpstr.mlm = ppoints(7) / (3 + length(i.mlm)),
     imethod = 1, mux.init = c(0.75, 0.5, 0.75),
     ilambda.p = NULL, ilambda.a = ilambda.p,
     ilambda.i = ilambda.p, ilambda.d = ilambda.p,
     ipobs.mix = NULL, ipstr.mix = NULL, ipdip.mix = NULL,
     ipobs.mlm = NULL, ipstr.mlm = NULL, ipdip.mlm = NULL,
     byrow.aid = FALSE, ishrinkage = 0.95, probs.y = 0.35)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaitdpoisson_+3A_truncate">truncate</code>, <code id="gaitdpoisson_+3A_max.support">max.support</code></td>
<td>

<p>Vector of truncated values, i.e., nonnegative integers.
For the first seven arguments (for the <em>special</em> values)
a <code>NULL</code> stands for an empty set, and
the seven sets must be mutually disjoint.
Argument <code>max.support</code> enables RHS-truncation,
i.e., something equivalent to
<code>truncate = (U+1):Inf</code> for some
upper support point <code>U</code>
specified by <code>max.support</code>.
</p>

</td></tr>
<tr><td><code id="gaitdpoisson_+3A_a.mix">a.mix</code>, <code id="gaitdpoisson_+3A_i.mix">i.mix</code>, <code id="gaitdpoisson_+3A_d.mix">d.mix</code></td>
<td>

<p>Vector of altered and inflated values corresponding
to finite mixture models.
These are described as <em>parametric</em> or structured.
</p>
<p>The parameter <code>lambda.p</code> is always estimated.
If <code>length(a.mix)</code> is 1 or more then the parameter
<code>pobs.mix</code> is estimated.
If <code>length(i.mix)</code> is 1 or more then the parameter
<code>pstr.mix</code> is estimated.
If <code>length(d.mix)</code> is 1 or more then the parameter
<code>pdip.mix</code> is estimated.
</p>
<p>If <code>length(a.mix)</code> is 2 or more then the parameter
<code>lambda.a</code> is estimated.
If <code>length(i.mix)</code> is 2 or more then the parameter
<code>lambda.i</code> is estimated.
If <code>length(d.mix)</code> is 2 or more then the parameter
<code>lambda.d</code> is estimated.
</p>


<p>If <code>length(a.mix) == 1</code>, <code>length(i.mix) == 1</code> or
<code>length(d.mix) == 1</code> then <code>lambda.a</code>,
<code>lambda.i</code> and <code>lambda.d</code> are unidentifiable and
therefore ignored. In such cases
it would be equivalent to moving <code>a.mix</code> into
<code>a.mlm</code>, etc.
</p>
























<p>Due to its great flexibility, it is easy to misuse this function
and ideally the values of the above arguments should be well
justified by the application on hand.
Adding inappropriate or
unnecessary values to these arguments willy-nilly
is a recipe for disaster, especially for
<code>i.mix</code> and <code>d.mix</code>.
Using <code>a.mlm</code> effectively removes a subset of the data
from the main analysis, therefore may result in a substantial
loss of efficiency.
For seeped values, <code>a.mix</code>, <code>a.mlm</code>, 
<code>d.mix</code> and <code>d.mlm</code> can be used only.
Heaped values can be handled by <code>i.mlm</code> and <code>i.mix</code>,
as well as <code>a.mix</code> and <code>a.mlm</code>.
Because of the NBP reason below, it sometimes may be necessary
to specify deflated values to altered values.
</p>










</td></tr>
<tr><td><code id="gaitdpoisson_+3A_a.mlm">a.mlm</code>, <code id="gaitdpoisson_+3A_i.mlm">i.mlm</code>, <code id="gaitdpoisson_+3A_d.mlm">d.mlm</code></td>
<td>

<p>Vector of altered, inflated and deflated values corresponding
to the multinomial logit model (MLM) probabilities of
observing those values&mdash;see <code><a href="#topic+multinomial">multinomial</a></code>.
These are described as <em>nonparametric</em> or unstructured.
</p>












</td></tr>
<tr><td><code id="gaitdpoisson_+3A_llambda.p">llambda.p</code>, <code id="gaitdpoisson_+3A_llambda.a">llambda.a</code>, <code id="gaitdpoisson_+3A_llambda.i">llambda.i</code>, <code id="gaitdpoisson_+3A_llambda.d">llambda.d</code></td>
<td>

<p>Link functions for the parent,
altered, inflated  and deflated distributions respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices and information.
</p>
</td></tr>




<tr><td><code id="gaitdpoisson_+3A_eq.ap">eq.ap</code>, <code id="gaitdpoisson_+3A_eq.ip">eq.ip</code>, <code id="gaitdpoisson_+3A_eq.dp">eq.dp</code></td>
<td>

<p>Single logical each.
Constrain the rate parameters to be equal?
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Having all three arguments <code>TRUE</code> gives
greater stability in
the estimation because of fewer parameters and therefore
fewer initial values needed,
however if so then one should try relax some of
the arguments later.
</p>

<p>For the GIT&ndash;Pois submodel,
after plotting the responses,
if the distribution of the spikes
above the nominal probabilities
has roughly the same shape
as the ordinary values then setting
<code>eq.ip = TRUE</code> would be a good idea
so that <code>lambda.i == lambda.p</code>.
And if <code>i.mix</code> is of length 2 or a bit more, then
<code>TRUE</code> should definitely be entertained.
Likewise, for heaped or seeped data, setting
<code>eq.ap = TRUE</code>
(so that <code>lambda.p == lambda.p</code>)
would be a good idea for the
GAT&ndash;Pois if the shape of the altered probabilities
is roughly the same as the parent distribution.
</p>
</td></tr>
<tr><td><code id="gaitdpoisson_+3A_parallel.a">parallel.a</code>, <code id="gaitdpoisson_+3A_parallel.i">parallel.i</code>, <code id="gaitdpoisson_+3A_parallel.d">parallel.d</code></td>
<td>

<p>Single logical each.
Constrain the MLM probabilities to be equal?
If so then this applies to all 
<code>length(a.mlm)</code> <code>pobs.mlm</code> probabilities
or all
<code>length(i.mlm)</code> <code>pstr.mlm</code> probabilities
or all
<code>length(d.mlm)</code> <code>pdip.mlm</code> probabilities.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
The default means that the probabilities are generally
unconstrained and unstructured and will follow the shape
of the data.
See <code><a href="#topic+constraints">constraints</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdpoisson_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and below for information.
The first value is the default, and this is usually the
unconditional mean.
Choosing an irrelevant value may result in
an <code>NA</code> being returned and a warning, e.g.,
<code>"pstr.mlm"</code> for a nonparametric GAT model.
</p>

<p>The choice <code>"lambdas"</code> returns a matrix with at least
one column and up to three others,
corresponding to all those estimated.
In order, their <code><a href="base.html#topic+colnames">colnames</a></code> are
<code>"lambda.p"</code>, <code>"lambda.a"</code>, <code>"lambda.i"</code>
and <code>"lambda.d"</code>.
For other distributions such as <code><a href="#topic+gaitdlog">gaitdlog</a></code>
<code>type.fitted = "shapes"</code> is permitted and the
<code><a href="base.html#topic+colnames">colnames</a></code> are
<code>"shape.p"</code>, <code>"shape.a"</code>, <code>"shape.i"</code> and
<code>"shape.d"</code>, etc.
</p>
<p>Option <code>"Pobs.mix"</code> provides more detail about
<code>"pobs.mix"</code> by returning a matrix whose columns
correspond to each altered value; the row sums
(<code><a href="base.html#topic+rowSums">rowSums</a></code>)
of this matrix is <code>"pobs.mix"</code>.
Likewise <code>"Pstr.mix"</code> about <code>"pstr.mix"</code>
and <code>"Pdip.mix"</code> about <code>"pdip.mix"</code>. 
</p>









<p>The choice <code>"cdf.max.s"</code> is the CDF evaluated
at <code>max.support</code> using the parent distribution,
e.g., <code>ppois(max.support, lambda.p)</code> for
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
The value should be 1 if <code>max.support = Inf</code>
(the default).
The choice <code>"nonspecial"</code> is the probability of a
nonspecial value.
The choices <code>"Denom.p"</code> and <code>"Numer"</code>
are quantities
found in the GAITD combo PMF and are for convenience only.
</p>
<p>The choice <code>type.fitted = "pobs.mlm"</code> returns
a matrix whose columns are
the altered probabilities (Greek symbol <code class="reqn">\omega_s</code>).
The choice <code>"pstr.mlm"</code> returns
a matrix whose columns are
the inflated probabilities (Greek symbol <code class="reqn">\phi_s</code>).
The choice <code>"pdip.mlm"</code> returns
a matrix whose columns are
the deflated probabilities (Greek symbol <code class="reqn">\psi_s</code>).
</p>
<p>The choice <code>"ptrunc.p"</code> returns the probability of having
a truncated value with respect to the parent distribution.
It includes any truncated values in the upper tail
beyond <code>max.support</code>.
The probability of a value less than or equal to
<code>max.support</code> with respect to the parent distribution
is <code>"cdf.max.s"</code>.
</p>




<p>The choice <code>"sum.mlm.i"</code> adds two terms.
This gives the probability of an inflated value,
and the formula can be loosely written down
as something like
<code>"pstr.mlm" + "Numer" * dpois(i.mlm, lambda.p) / "Denom.p"</code>.
The other three <code>"sum.m*"</code> arguments are similar.
</p>



</td></tr>
<tr><td><code id="gaitdpoisson_+3A_gpstr.mix">gpstr.mix</code>, <code id="gaitdpoisson_+3A_gpstr.mlm">gpstr.mlm</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Gridsearch values for the two parameters.
If failure occurs try a finer grid, especially closer to 0,
and/or experiment with <code>mux.init</code>.
</p>
</td></tr>



<tr><td><code id="gaitdpoisson_+3A_imethod">imethod</code>, <code id="gaitdpoisson_+3A_ipobs.mix">ipobs.mix</code>, <code id="gaitdpoisson_+3A_ipstr.mix">ipstr.mix</code>, <code id="gaitdpoisson_+3A_ipdip.mix">ipdip.mix</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Good initial values are difficult to compute because of
the great flexibility of GAITD regression, therefore
it is often necessary to use these arguments.
A careful examination of a <code><a href="#topic+spikeplot">spikeplot</a></code>
of the data should lead to good choices.
</p>

</td></tr> 
<tr><td><code id="gaitdpoisson_+3A_ipobs.mlm">ipobs.mlm</code>, <code id="gaitdpoisson_+3A_ipstr.mlm">ipstr.mlm</code>, <code id="gaitdpoisson_+3A_ipdip.mlm">ipdip.mlm</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>



</td></tr>
<tr><td><code id="gaitdpoisson_+3A_mux.init">mux.init</code></td>
<td>

<p>Numeric, of length 3.
General downward multiplier for initial values for
the sample proportions (MLEs actually).
This is under development and more details are
forthcoming.
In general, 1 means unchanged and values
should lie in (0, 1], and values about 0.5 are recommended.
The elements apply in order to altered, inflated and
deflated (no distinction between mix and MLM).
</p>






</td></tr>
<tr><td><code id="gaitdpoisson_+3A_ilambda.p">ilambda.p</code>, <code id="gaitdpoisson_+3A_ilambda.a">ilambda.a</code>, <code id="gaitdpoisson_+3A_ilambda.i">ilambda.i</code>, <code id="gaitdpoisson_+3A_ilambda.d">ilambda.d</code></td>
<td>

<p>Initial values for the rate parameters;
see <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>

</td></tr>
<tr><td><code id="gaitdpoisson_+3A_probs.y">probs.y</code>, <code id="gaitdpoisson_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gaitdpoisson_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>Details are at <code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdpoisson_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
By default, all the MLM probabilities are
modelled as simple as possible (intercept-only) to
help avoid numerical problems, especially when there
are many covariates.
The Poisson means are modelled by the covariates, and
the default <code>zero</code> vector is pruned of any irrelevant values.
To model all the MLM probabilities with covariates
set <code>zero = NULL</code>, however, the number of regression
coefficients could be excessive.
</p>
<p>For the MLM probabilities,
to model <code>pobs.mix</code> only with covariates
set <code>zero = c('pstr', 'pobs.mlm', 'pdip')</code>.
Likewise,
to model <code>pstr.mix</code> only with covariates
set <code>zero = c('pobs', 'pstr.mlm', 'pdip')</code>.
</p>
<p>It is noted that, amongst other things,
<code><a href="#topic+zipoisson">zipoisson</a></code> and <code><a href="#topic+zipoissonff">zipoissonff</a></code> differ
with respect to <code>zero</code>, and ditto for
<code><a href="#topic+zapoisson">zapoisson</a></code> and <code><a href="#topic+zapoissonff">zapoissonff</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The full
GAITD&ndash;Pois combo model
may be fitted with this family function.
There are seven types of special values and all arguments for these
may be used in a single model.
Here, the MLM represents the nonparametric while the Pois
refers to the Poisson mixtures.
The defaults for this function correspond to an ordinary Poisson
regression so that <code><a href="#topic+poissonff">poissonff</a></code> is called instead.
A MLM with only one probability to model is equivalent to
logistic regression
(<code><a href="#topic+binomialff">binomialff</a></code> and <code><a href="#topic+logitlink">logitlink</a></code>).
</p>

<p>The order of the linear/additive predictors is best
explained by an example.
Suppose a combo model has
<code>length(a.mix) &gt; 2</code> and
<code>length(i.mix) &gt; 2</code>,
<code>length(d.mix) &gt; 2</code>,
<code>a.mlm = 3:5</code>,
<code>i.mlm = 6:9</code> and
<code>d.mlm = 10:12</code>, say.
Then <code>loglink(lambda.p)</code> is the first.
The second is <code>multilogitlink(pobs.mix)</code> followed
by <code>loglink(lambda.a)</code> because <code>a.mix</code> is long enough.
The fourth is <code>multilogitlink(pstr.mix)</code> followed
by <code>loglink(lambda.i)</code> because <code>i.mix</code> is long enough.
The sixth is <code>multilogitlink(pdip.mix)</code> followed
by <code>loglink(lambda.d)</code> because <code>d.mix</code> is long enough.
Next are the probabilities for the <code>a.mlm</code> values.
Then are the probabilities for the <code>i.mlm</code> values.
Lastly are the probabilities for the <code>d.mlm</code> values.
All the probabilities are estimated by one big MLM
and effectively
the <code>"(Others)"</code> column of left over probabilities is
associated with the nonspecial values.
These might be called the
<em>nonspecial baseline probabilities</em> (NBP).
The dimension of the vector of linear/additive predictors here
is <code class="reqn">M=17</code>.
</p>

<p>Two mixture submodels that may be fitted can be abbreviated
GAT&ndash;Pois or
GIT&ndash;Pois.
For the GAT model
the distribution being fitted is a (spliced) mixture
of two Poissons with differing (partitioned) support.
Likewise, for the GIT model
the distribution being fitted is a mixture
of two Poissons with nested support.
The two rate parameters may be constrained to be equal using
<code>eq.ap</code> and <code>eq.ip</code>.
</p>





<p>A good first step is to apply <code><a href="#topic+spikeplot">spikeplot</a></code>
for selecting
candidate values for altering, inflating and deflating.
Deciding between
parametrically or nonparametrically can also be determined from
examining the spike plot.  Misspecified
<code>a.mix/a.mlm/i.mix/i.mlm/d.mix/d.mlm</code>
will result in convergence problems
(setting <code>trace = TRUE</code> is a <em>very</em> good idea.)
This function currently does not handle multiple responses.
Further details are at <code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.




</p>

<p>A well-conditioned data&ndash;model combination should pose no
difficulties for the automatic starting value selection
being successful.
Failure to obtain initial values from this self-starting
family function indicates the degree of inflation/deflation
may be marginal and/or a misspecified model.
If this problem is worth surmounting
the arguments to focus on especially are
<code>mux.init</code>,
<code>gpstr.mix</code>, <code>gpstr.mlm</code>,
<code>ipdip.mix</code> and <code>ipdip.mlm</code>.
See below for the stepping-stone trick.
</p>
<p>Apart from the order of the linear/additive predictors,
the following are (or should be) equivalent:
<code>gaitdpoisson()</code> and <code>poissonff()</code>,
<code>gaitdpoisson(a.mix = 0)</code>
and <code>zapoisson(zero = "pobs0")</code>,
<code>gaitdpoisson(i.mix = 0)</code>
and <code>zipoisson(zero = "pstr0")</code>,
<code>gaitdpoisson(truncate = 0)</code> and <code>pospoisson()</code>.
Likewise, if
<code>a.mix</code> and <code>i.mix</code> are assigned a scalar then
it effectively moves that scalar to <code>a.mlm</code> and <code>i.mlm</code>
because there is no <code>lambda.a</code>
or <code>lambda.i</code> being estimated.
Thus
<code>gaitdpoisson(a.mix = 0)</code>
and <code>gaitdpoisson(a.mlm = 0)</code>
are the effectively same, and ditto for
<code>gaitdpoisson(i.mix = 0)</code>
and <code>gaitdpoisson(i.mlm = 0)</code>.
</p>















<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>The <code>fitted.values</code> slot of the fitted object,
which should be extracted by the
generic function <code>fitted</code>,
returns the mean <code class="reqn">\mu</code> by default.
See the information above on <code>type.fitted</code>.
</p>


<h3>Warning </h3>

<p>Amateurs tend to be overzealous fitting
zero-inflated models when the
fitted mean is low&mdash;the warning of
<code><a href="mgcv.html#topic+ziP">ziP</a></code> should be heeded.
For GAITD regression the warning applies more
strongly and generally; here to <em>all</em>
<code>i.mix</code>, <code>i.mlm</code>, <code>d.mix</code> and
<code>d.mlm</code> values, not just 0.  Even one
misspecified special value usually will cause
convergence problems.
</p>
<p>Default values for this and similar family
functions may change in the future, e.g.,
<code>eq.ap</code> and <code>eq.ip</code>.  Important
internal changes might occur too, such as the
ordering of the linear/additive predictors and
the quantities returned as the fitted values.
</p>
<p>Using <code>i.mlm</code> requires more caution
than <code>a.mlm</code> because gross inflation
is ideally needed for it to work safely.
Ditto for <code>i.mix</code> versus <code>a.mix</code>.
Data exhibiting deflation or little to no
inflation will produce numerical problems,
hence set <code>trace = TRUE</code> to monitor
convergence.  More than c.10 IRLS iterations
should raise suspicion.
</p>
<p>Ranking the four operators by difficulty,
the easiest is truncation followed by
alteration, then inflation and the most
difficult is deflation.  The latter needs
good initial values and the current default
will probably not work on some data sets.
Studying the spikeplot is time very well spent.
In general it is very easy to specify an
<em>overfitting</em> model so it is a good idea
to split the data into training and test sets.
</p>



<p>This function is quite memory-hungry with
respect to <code>length(c(a.mix, i.mix, d.mix,
  a.mlm, i.mlm, d.mlm))</code>.  On consuming something
different, because all values of the NBP vector
need to be positive it pays to be economical
with respect to <code>d.mlm</code> especially so
that one does not consume up probabilities
unnecessarily so to speak.
</p>






<p>It is often a good idea to set <code>eq.ip =
  TRUE</code>, especially when <code>length(i.mix)</code>
is not much more than 2 or the values of
<code>i.mix</code> are not spread over the range
of the response.  This way the estimation
can borrow strength from both the inflated
and non-inflated values.  If the <code>i.mix</code>
values form a single small cluster then this
can easily create estimation difficulties&mdash;the
idea is somewhat similar to multicollinearity.
The same holds for <code>d.mix</code>.
</p>


<h3>Note</h3>

<p>Numerical problems can easily arise because
of the exceeding flexibility of this
distribution and/or the lack of sizeable
inflation/deflation; it is a good idea to gain
experience with simulated data first before
applying it to real data.
Numerical problems may arise if any of the
special values are in remote places of the
support, e.g., a value <code>y</code> such that
<code>dpois(y, lambda.p)</code> is very close to
0. This is because the ratio of two tiny values
can be unstable.
</p>
<p>Good initial values may be difficult to obtain
using self-starting procedures, especially
when there are covariates.  If so, then it is
advisable to use a trick: fit an intercept-only
model first and then use <code>etastart =
  predict(int.only.model)</code> to fit the model
with covariates.  This uses the simpler model
as a stepping-stone.
</p>
<p>The labelling of the linear/additive predictors
has been abbreviated to reduce space.  For
example, <code>multilogitlink(pobs.mix)</code> and
<code>multilogitlink(pstr.mix)</code> would be more
accurately <code>multilogitlink(cbind(pobs.mix,
  pstr.mix))</code> because one grand MLM is fitted.
This shortening may result in modifications
needed in other parts of <span class="pkg">VGAM</span> to
compensate.
</p>
<p>Because estimation involves a MLM, the restricted
parameter space means that if the dip probabilities
are large then the NBP may become too close to 0.
If this is so then there are tricks to avoid a
negative NBP.
One of them is to model as many values of <code>d.mlm</code>
as <code>d.mix</code>, hence the dip probabilities become
modelled via the deflation distribution instead.
Another trick to alter those special values rather than
deflating them if the dip probabilities are large.
</p>
<p>Due to its complexity,
the HDE test <code><a href="#topic+hdeff">hdeff</a></code> is currently
unavailable for GAITD regressions.
</p>
<p>Randomized quantile residuals (RQRs) are
available; see <code><a href="#topic+residualsvglm">residualsvglm</a></code>.
</p>












<h3>Author(s)</h3>

<p> T. W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>





<h3>See Also</h3>

<p><code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+rootogram4">rootogram4</a></code>,
<code><a href="#topic+specials">specials</a></code>,
<code><a href="#topic+plotdgaitd">plotdgaitd</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+meangaitd">meangaitd</a></code>,
<code><a href="#topic+KLD">KLD</a></code>,
<code><a href="#topic+goffset">goffset</a></code>,
<code><a href="#topic+Trunc">Trunc</a></code>,
<code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="#topic+multilogitlink">multilogitlink</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+residualsvglm">residualsvglm</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+zapoisson">zapoisson</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+pospoisson">pospoisson</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>










<h3>Examples</h3>

<pre><code class='language-R'>i.mix &lt;- c(5, 10)  # Inflate these values parametrically
i.mlm &lt;- c(14, 15)  # Inflate these values
a.mix &lt;- c(1, 13)  # Alter these values
tvec &lt;- c(3, 11)   # Truncate these values
pstr.mlm &lt;- 0.1  # So parallel.i = TRUE
pobs.mix &lt;- pstr.mix &lt;- 0.1
max.support &lt;- 20; set.seed(1)
gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, lambda.p = exp(2 + 0.0 * x2))
gdata &lt;- transform(gdata,
  y1 = rgaitdpois(nn, lambda.p, a.mix = a.mix, i.mix = i.mix,
                  pobs.mix = pobs.mix, pstr.mix = pstr.mix,
                  i.mlm = i.mlm, pstr.mlm = pstr.mlm,
                  truncate = tvec, max.support = max.support))
gaitdpoisson(a.mix = a.mix, i.mix = i.mix, i.mlm = i.mlm)
with(gdata, table(y1))
fit1 &lt;- vglm(y1 ~ 1, crit = "coef", trace = TRUE, data = gdata,
             gaitdpoisson(a.mix = a.mix, i.mix = i.mix,
                          i.mlm = i.mlm, parallel.i = TRUE,
                          eq.ap = TRUE, eq.ip = TRUE, truncate =
                          tvec, max.support = max.support))
head(fitted(fit1, type.fitted = "Pstr.mix"))
head(predict(fit1))
t(coef(fit1, matrix = TRUE))  # Easier to see with t()
summary(fit1)  # No HDE test by default but HDEtest = TRUE is ideal
## Not run:  spikeplot(with(gdata, y1), lwd = 2)
plotdgaitd(fit1, new.plot = FALSE, offset.x = 0.2, all.lwd = 2)  
## End(Not run)
</code></pre>

<hr>
<h2 id='gaitdzeta'> Generally Altered, Inflated, Truncated
and Deflated
Zeta Regression
</h2><span id='topic+gaitdzeta'></span>

<h3>Description</h3>

<p>Fits a generally altered, inflated, truncated
and deflated zeta regression by MLE.
The GAITD combo model having 7 types of special
values is implemented.  This allows mixtures of
zetas on nested and/or partitioned support as
well as a multinomial logit model for altered,
inflated and deflated values.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>gaitdzeta(a.mix = NULL, i.mix = NULL, d.mix = NULL,
         a.mlm = NULL, i.mlm = NULL, d.mlm = NULL,
         truncate = NULL, max.support = Inf,
         zero = c("pobs", "pstr", "pdip"), eq.ap = TRUE, eq.ip = TRUE,
         eq.dp = TRUE, parallel.a = FALSE,
         parallel.i = FALSE, parallel.d = FALSE,
         lshape.p = "loglink", lshape.a = lshape.p,
         lshape.i = lshape.p, lshape.d = lshape.p,
         type.fitted = c("mean", "shapes", "pobs.mlm", "pstr.mlm",
         "pdip.mlm", "pobs.mix", "pstr.mix", "pdip.mix", "Pobs.mix",
         "Pstr.mix", "Pdip.mix", "nonspecial",
         "Numer", "Denom.p", "sum.mlm.i", "sum.mix.i", "sum.mlm.d",
         "sum.mix.d", "ptrunc.p", "cdf.max.s"),
         gshape.p = -expm1(-ppoints(7)), gpstr.mix = ppoints(7) / 3,
         gpstr.mlm = ppoints(7) / (3 + length(i.mlm)),
         imethod = 1, mux.init = c(0.75, 0.5, 0.75),
         ishape.p = NULL, ishape.a = ishape.p,
         ishape.i = ishape.p, ishape.d = ishape.p,
         ipobs.mix = NULL, ipstr.mix = NULL, ipdip.mix = NULL,
         ipobs.mlm = NULL, ipstr.mlm = NULL, ipdip.mlm = NULL,
         byrow.aid = FALSE, ishrinkage = 0.95, probs.y = 0.35)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaitdzeta_+3A_truncate">truncate</code>, <code id="gaitdzeta_+3A_max.support">max.support</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
Only <code>max.support = Inf</code> is allowed
because some equations are intractable.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_a.mix">a.mix</code>, <code id="gaitdzeta_+3A_i.mix">i.mix</code>, <code id="gaitdzeta_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_a.mlm">a.mlm</code>, <code id="gaitdzeta_+3A_i.mlm">i.mlm</code>, <code id="gaitdzeta_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_lshape.p">lshape.p</code>, <code id="gaitdzeta_+3A_lshape.a">lshape.a</code>, <code id="gaitdzeta_+3A_lshape.i">lshape.i</code>, <code id="gaitdzeta_+3A_lshape.d">lshape.d</code></td>
<td>

<p>Link functions.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>
and <code><a href="#topic+Links">Links</a></code> for more choices
and information.  Actually, it is usually
a good idea to set these arguments equal to
<code><a href="VGAMextra.html#topic+zetaffMlink">zetaffMlink</a></code> because
the log-mean is the first linear/additive
predictor so it is like a Poisson regression.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_eq.ap">eq.ap</code>, <code id="gaitdzeta_+3A_eq.ip">eq.ip</code>, <code id="gaitdzeta_+3A_eq.dp">eq.dp</code></td>
<td>

<p>Single logical each.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_parallel.a">parallel.a</code>, <code id="gaitdzeta_+3A_parallel.i">parallel.i</code>, <code id="gaitdzeta_+3A_parallel.d">parallel.d</code></td>
<td>

<p>Single logical each.
See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_type.fitted">type.fitted</code>, <code id="gaitdzeta_+3A_mux.init">mux.init</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_imethod">imethod</code>, <code id="gaitdzeta_+3A_ipobs.mix">ipobs.mix</code>, <code id="gaitdzeta_+3A_ipstr.mix">ipstr.mix</code>, <code id="gaitdzeta_+3A_ipdip.mix">ipdip.mix</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>

</td></tr>
<tr><td><code id="gaitdzeta_+3A_ipobs.mlm">ipobs.mlm</code>, <code id="gaitdzeta_+3A_ipstr.mlm">ipstr.mlm</code>, <code id="gaitdzeta_+3A_ipdip.mlm">ipdip.mlm</code>, <code id="gaitdzeta_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_gpstr.mix">gpstr.mix</code>, <code id="gaitdzeta_+3A_gpstr.mlm">gpstr.mlm</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>
</td></tr>




<tr><td><code id="gaitdzeta_+3A_gshape.p">gshape.p</code>, <code id="gaitdzeta_+3A_ishape.p">ishape.p</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
The former is used only if the latter is
not given.  Practical experience has shown
that good initial values are needed, so
if convergence is not obtained then try a
finer grid.
</p>

</td></tr>
<tr><td><code id="gaitdzeta_+3A_ishape.a">ishape.a</code>, <code id="gaitdzeta_+3A_ishape.i">ishape.i</code>, <code id="gaitdzeta_+3A_ishape.d">ishape.d</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> for information.
</p>

</td></tr>
<tr><td><code id="gaitdzeta_+3A_probs.y">probs.y</code>, <code id="gaitdzeta_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="gaitdzeta_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>
and <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many details to this family function can be
found in <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> because it
is also a 1-parameter discrete distribution.
This function currently does not handle
multiple responses.  Further details are at
<code><a href="#topic+Gaitdzeta">Gaitdzeta</a></code>.
</p>
<p>As alluded to above, when there are covariates
it is much more interpretable to model
the mean rather than the shape parameter.
Hence <code><a href="VGAMextra.html#topic+zetaffMlink">zetaffMlink</a></code>
is recommended.  (This might become the default
in the future.)  So installing <span class="pkg">VGAMextra</span>
is a good idea.
</p>
<p>Apart from the order of the linear/additive predictors,
the following are (or should be) equivalent:
<code>gaitdzeta()</code> and <code>zetaff()</code>,
<code>gaitdzeta(a.mix = 1)</code> and <code>oazeta(zero = "pobs1")</code>,
<code>gaitdzeta(i.mix = 1)</code> and <code>oizeta(zero = "pstr1")</code>,
<code>gaitdzeta(truncate = 1)</code> and <code>otzeta()</code>.
The functions
<code><a href="VGAMdata.html#topic+oazeta">oazeta</a></code>,
<code><a href="VGAMdata.html#topic+oizeta">oizeta</a></code> and
<code><a href="VGAMdata.html#topic+otzeta">otzeta</a></code>
have been placed in <span class="pkg">VGAMdata</span>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such
as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>





<h3>Warning </h3>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gaitdzeta">Gaitdzeta</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="VGAMextra.html#topic+zetaffMlink">zetaffMlink</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+goffset">goffset</a></code>,
<code><a href="#topic+Trunc">Trunc</a></code>,
<code><a href="VGAMdata.html#topic+oazeta">oazeta</a></code>,
<code><a href="VGAMdata.html#topic+oizeta">oizeta</a></code>,
<code><a href="VGAMdata.html#topic+otzeta">otzeta</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+rootogram4">rootogram4</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
avec &lt;- c(5, 10)  # Alter these values parametrically
ivec &lt;- c(3, 15)  # Inflate these values
tvec &lt;- c(6, 7)   # Truncate these values
set.seed(1); pobs.a &lt;- pstr.i &lt;- 0.1
gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, shape.p = logitlink(2, inverse = TRUE))
gdata &lt;- transform(gdata,
  y1 = rgaitdzeta(nn, shape.p, a.mix = avec, pobs.mix = pobs.a,
                  i.mix = ivec, pstr.mix = pstr.i, truncate = tvec))
gaitdzeta(a.mix = avec, i.mix = ivec)
with(gdata, table(y1))
spikeplot(with(gdata, y1), las = 1)
fit7 &lt;- vglm(y1 ~ 1, trace = TRUE, data = gdata, crit = "coef",
             gaitdzeta(i.mix = ivec, truncate = tvec,
                       a.mix = avec, eq.ap = TRUE, eq.ip = TRUE))
head(fitted(fit7, type.fitted = "Pstr.mix"))
head(predict(fit7))
t(coef(fit7, matrix = TRUE))  # Easier to see with t()
summary(fit7)
spikeplot(with(gdata, y1), lwd = 2, ylim = c(0, 0.6), xlim = c(0, 20))
plotdgaitd(fit7, new.plot = FALSE, offset.x = 0.2, all.lwd = 2)

## End(Not run)</code></pre>

<hr>
<h2 id='Gaitdzeta'> Generally Altered, Inflated and Truncated
and Deflated
Zeta Distribution
</h2><span id='topic+Gaitdzeta'></span><span id='topic+dgaitdzeta'></span><span id='topic+pgaitdzeta'></span><span id='topic+qgaitdzeta'></span><span id='topic+rgaitdzeta'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function
and random generation
for the generally altered, inflated, truncated
and deflated
zeta distribution.
Both parametric and nonparametric variants are supported;
these are based on
finite mixtures of the parent with itself
and the multinomial logit model (MLM) respectively.
</p>






<h3>Usage</h3>

<pre><code class='language-R'>dgaitdzeta(x, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0,
          byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p,
          log = FALSE)
pgaitdzeta(q, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0,
          byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p,
          lower.tail = TRUE)
qgaitdzeta(p, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0,
          byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p)
rgaitdzeta(n, shape.p, a.mix = NULL, a.mlm = NULL,
          i.mix = NULL, i.mlm = NULL,
          d.mix = NULL, d.mlm = NULL, truncate = NULL,
          max.support = Inf, pobs.mix = 0, pobs.mlm = 0,
          pstr.mix = 0, pstr.mlm = 0,
          pdip.mix = 0, pdip.mlm = 0,
          byrow.aid = FALSE,
          shape.a = shape.p, shape.i = shape.p, shape.d = shape.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaitdzeta_+3A_x">x</code>, <code id="Gaitdzeta_+3A_q">q</code>, <code id="Gaitdzeta_+3A_p">p</code>, <code id="Gaitdzeta_+3A_n">n</code>, <code id="Gaitdzeta_+3A_log">log</code>, <code id="Gaitdzeta_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same meaning as in <code><a href="#topic+dzeta">dzeta</a></code>.
</p>
</td></tr>
<tr><td><code id="Gaitdzeta_+3A_shape.p">shape.p</code>, <code id="Gaitdzeta_+3A_shape.a">shape.a</code>, <code id="Gaitdzeta_+3A_shape.i">shape.i</code>, <code id="Gaitdzeta_+3A_shape.d">shape.d</code></td>
<td>

<p>Same meaning as <code>shape</code> for <code><a href="#topic+dzeta">dzeta</a></code>,
i.e., for an ordinary zeta distribution.
See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdzeta_+3A_truncate">truncate</code>, <code id="Gaitdzeta_+3A_max.support">max.support</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdzeta_+3A_a.mix">a.mix</code>, <code id="Gaitdzeta_+3A_i.mix">i.mix</code>, <code id="Gaitdzeta_+3A_d.mix">d.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdzeta_+3A_a.mlm">a.mlm</code>, <code id="Gaitdzeta_+3A_i.mlm">i.mlm</code>, <code id="Gaitdzeta_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdzeta_+3A_pobs.mlm">pobs.mlm</code>, <code id="Gaitdzeta_+3A_pstr.mlm">pstr.mlm</code>, <code id="Gaitdzeta_+3A_pdip.mlm">pdip.mlm</code>, <code id="Gaitdzeta_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>
<tr><td><code id="Gaitdzeta_+3A_pobs.mix">pobs.mix</code>, <code id="Gaitdzeta_+3A_pstr.mix">pstr.mix</code>, <code id="Gaitdzeta_+3A_pdip.mix">pdip.mix</code></td>
<td>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for generic information.
</p>
</td></tr>



</table>


<h3>Details</h3>

<p>These functions for the zeta distribution are analogous to
the Poisson, hence most details have been put in
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>.
These functions do what
<code><a href="VGAMdata.html#topic+Oazeta">Oazeta</a></code>,
<code><a href="VGAMdata.html#topic+Oizeta">Oizeta</a></code>,
<code><a href="VGAMdata.html#topic+Otzeta">Otzeta</a></code>
collectively did plus much more.
</p>











<h3>Value</h3>

<p><code>dgaitdzeta</code> gives the density,
<code>pgaitdzeta</code> gives the distribution function,
<code>qgaitdzeta</code> gives the quantile function, and
<code>rgaitdzeta</code> generates random deviates.
The default values of the arguments correspond to ordinary
<code><a href="#topic+dzeta">dzeta</a></code>,
<code><a href="#topic+pzeta">pzeta</a></code>,
<code><a href="#topic+qzeta">qzeta</a></code>,
<code><a href="#topic+rzeta">rzeta</a></code>
respectively.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> about the dangers
of too much inflation and/or deflation on
GAITD PMFs, and the difficulties detecting such.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> for general information
also relevant to this parent distribution.
</p>







<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="VGAMdata.html#topic+Oazeta">Oazeta</a></code>,
<code><a href="VGAMdata.html#topic+Oizeta">Oizeta</a></code>,
<code><a href="VGAMdata.html#topic+Otzeta">Otzeta</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>ivec &lt;- c(2, 10); avec &lt;- ivec + 4; shape &lt;- 0.95; xgrid &lt;- 0:29
tvec &lt;- 15; max.support &lt;- 25; pobs.a &lt;- 0.10; pstr.i &lt;- 0.15
(ddd &lt;- dgaitdzeta(xgrid, shape, truncate = tvec,
   max.support = max.support, pobs.mix = pobs.a,
   a.mix = avec, pstr.mix = pstr.i, i.mix = ivec))
## Not run: plot(xgrid, ddd, type = "n", ylab = "Probability",
              xlab = "x", main = "GAIT PMF---Zeta Parent")
mylwd &lt;- 0.5
abline(v = avec, col = 'blue', lwd = mylwd)
abline(v = ivec, col = 'purple', lwd = mylwd)
abline(v = tvec, col = 'tan', lwd = mylwd)
abline(v = max.support, col = 'magenta', lwd = mylwd)
abline(h = c(pobs.a, pstr.i, 0:1), col = 'gray', lty = "dashed")
lines(xgrid, dzeta(xgrid, shape), col='gray', lty="dashed")  # f_{\pi}
lines(xgrid, ddd, type = "h", col = "pink", lwd = 3)  # GAIT PMF
points(xgrid[ddd == 0], ddd[ddd == 0], pch = 16, col = 'tan', cex = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='gamma1'> 1-parameter Gamma Regression Family Function </h2><span id='topic+gamma1'></span>

<h3>Description</h3>

<p>Estimates the 1-parameter gamma distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamma1(link = "loglink", zero = NULL, parallel = FALSE,
       type.fitted = c("mean", "percentiles", "Qlink"),
       percentiles = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamma1_+3A_link">link</code></td>
<td>

<p>Link function applied to the (positive) <em>shape</em> parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices and general information.
</p>
</td></tr>
<tr><td><code id="gamma1_+3A_zero">zero</code>, <code id="gamma1_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="gamma1_+3A_type.fitted">type.fitted</code>, <code id="gamma1_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Using <code>"Qlink"</code> is for quantile-links in <span class="pkg">VGAMextra</span>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \exp(-y) \times y^{shape-1} / \Gamma(shape)</code>
</p>

<p>for <code class="reqn">shape &gt; 0</code> and <code class="reqn">y &gt; 0</code>.
Here, <code class="reqn">\Gamma(shape)</code> is the gamma
function, as in <code><a href="base.html#topic+Special">gamma</a></code>.
The mean of <code class="reqn">Y</code> (returned as the default fitted values)
is <code class="reqn">\mu=shape</code>, and the variance is
<code class="reqn">\sigma^2 = shape</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This <span class="pkg">VGAM</span> family function can handle a multiple
responses, which is inputted as a matrix.
</p>
<p>The parameter <code class="reqn">shape</code> matches with <code>shape</code> in
<code><a href="stats.html#topic+rgamma">rgamma</a></code>. The argument
<code>rate</code> in <code><a href="stats.html#topic+rgamma">rgamma</a></code> is assumed
1 for this family function, so that
<code>scale = 1</code> is used for calls to
<code><a href="stats.html#topic+dgamma">dgamma</a></code>,
<code><a href="stats.html#topic+qgamma">qgamma</a></code>, etc.
</p>
<p>If <code class="reqn">rate</code> is unknown use the family function
<code><a href="#topic+gammaR">gammaR</a></code> to estimate it too.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Most standard texts on statistical distributions describe
the 1-parameter gamma distribution, e.g.,
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gammaR">gammaR</a></code> for the 2-parameter gamma distribution,
<code><a href="#topic+lgamma1">lgamma1</a></code>,
<code><a href="#topic+lindley">lindley</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+gammaff.mm">gammaff.mm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(y = rgamma(n = 100, shape = exp(3)))
fit &lt;- vglm(y ~ 1, gamma1, data = gdata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='gamma2'> 2-parameter Gamma Regression Family Function </h2><span id='topic+gamma2'></span>

<h3>Description</h3>

<p>Estimates the 2-parameter gamma distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamma2(lmu = "loglink", lshape = "loglink", imethod = 1,  ishape = NULL,
       parallel = FALSE, deviance.arg = FALSE, zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamma2_+3A_lmu">lmu</code>, <code id="gamma2_+3A_lshape">lshape</code></td>
<td>

<p>Link functions applied to the (positive) <em>mu</em> and <em>shape</em>
parameters (called <code class="reqn">\mu</code> and <code class="reqn">a</code> respectively).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="gamma2_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial value for <em>shape</em>.
A <code>NULL</code> means a value is computed internally.
If a failure to converge occurs, try using this argument.
This argument is ignored if used within <code><a href="#topic+cqo">cqo</a></code>; see the
<code>iShape</code> argument of <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> instead.
</p>
</td></tr>
<tr><td><code id="gamma2_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method for the <code class="reqn">\mu</code> parameter.
If failure to converge occurs
try another value (and/or specify a value for <code>ishape</code>).
</p>
</td></tr>
<tr><td><code id="gamma2_+3A_deviance.arg">deviance.arg</code></td>
<td>

<p>Logical. If <code>TRUE</code>, the deviance function
is attached to the object. Under ordinary circumstances, it should
be left alone because it really assumes the shape parameter is at
the maximum likelihood estimate. Consequently, one cannot use that
criterion to minimize within the IRLS algorithm.
It should be set <code>TRUE</code> only when used with <code><a href="#topic+cqo">cqo</a></code>
under the fast algorithm.
</p>
</td></tr>
<tr><td><code id="gamma2_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>














</td></tr>
<tr><td><code id="gamma2_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
If <code>parallel = TRUE</code> then the constraint is not applied to the intercept.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distribution can model continuous skewed responses.
The density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y;\mu,a) = \frac{\exp(-a y / \mu) \times
               (a y / \mu)^{a-1}
               \times a}{
               \mu \times \Gamma(a)}</code>
</p>

<p>for
<code class="reqn">\mu &gt; 0</code>,
<code class="reqn">a &gt; 0</code>
and <code class="reqn">y &gt; 0</code>.
Here,
<code class="reqn">\Gamma(\cdot)</code> is the gamma
function, as in <code><a href="base.html#topic+Special">gamma</a></code>.
The mean of <em>Y</em> is <code class="reqn">\mu=\mu</code> (returned as the fitted
values) with variance <code class="reqn">\sigma^2 = \mu^2 / a</code>.  If <code class="reqn">0&lt;a&lt;1</code> then the density has a
pole at the origin and decreases monotonically as <code class="reqn">y</code> increases.
If <code class="reqn">a=1</code> then this corresponds to the exponential
distribution.  If <code class="reqn">a&gt;1</code> then the density is zero at the
origin and is unimodal with mode at <code class="reqn">y = \mu - \mu / a</code>; this can be achieved with <code>lshape="logloglink"</code>.
</p>
<p>By default, the two linear/additive predictors are
<code class="reqn">\eta_1=\log(\mu)</code> and
<code class="reqn">\eta_2=\log(a)</code>.
This family function implements Fisher scoring and the working
weight matrices are diagonal.
</p>
<p>This <span class="pkg">VGAM</span> family function handles <em>multivariate</em> responses,
so that a matrix can be used as the response. The number of columns is
the number of species, say, and <code>zero=-2</code> means that <em>all</em>
species have a shape parameter equalling a (different) intercept only.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be strictly positive.
A moment estimator for the shape parameter may be implemented in
the future.
</p>
<p>If <code>mu</code> and <code>shape</code> are vectors, then <code>rgamma(n = n,
  shape = shape, scale = mu/shape)</code> will generate random gamma variates of this
parameterization, etc.;
see <code><a href="stats.html#topic+GammaDist">GammaDist</a></code>.
</p>





<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>The parameterization of this <span class="pkg">VGAM</span> family function is the
2-parameter gamma distribution described in the monograph
</p>
<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamma1">gamma1</a></code> for the 1-parameter gamma distribution,
<code><a href="#topic+gammaR">gammaR</a></code> for another parameterization of
the 2-parameter gamma distribution that is directly matched
with <code><a href="stats.html#topic+rgamma">rgamma</a></code>,
<code><a href="VGAMdata.html#topic+bigamma.mckay">bigamma.mckay</a></code>
for <em>a</em> bivariate gamma distribution,
<code><a href="#topic+gammaff.mm">gammaff.mm</a></code> for another,
<code><a href="#topic+expexpff">expexpff</a></code>,
<code><a href="stats.html#topic+GammaDist">GammaDist</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+negloglink">negloglink</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Essentially a 1-parameter gamma
gdata &lt;- data.frame(y = rgamma(n = 100, shape = exp(1)))
fit1 &lt;- vglm(y ~ 1, gamma1, data = gdata)
fit2 &lt;- vglm(y ~ 1, gamma2, data = gdata, trace = TRUE, crit = "coef")
coef(fit2, matrix = TRUE)
c(Coef(fit2), colMeans(gdata))

# Essentially a 2-parameter gamma
gdata &lt;- data.frame(y = rgamma(n = 500, rate = exp(-1), shape = exp(2)))
fit2 &lt;- vglm(y ~ 1, gamma2, data = gdata, trace = TRUE, crit = "coef")
coef(fit2, matrix = TRUE)
c(Coef(fit2), colMeans(gdata))
summary(fit2)
</code></pre>

<hr>
<h2 id='gammaff.mm'> Multivariate Gamma Family Function:
Mathai and Moschopoulos (1992) </h2><span id='topic+gammaff.mm'></span>

<h3>Description</h3>

<p>Estimate the scale parameter and
shape parameters
of the Mathai and Moschopoulos (1992)
multivariate gamma
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaff.mm(lscale = "loglink", lshape = "loglink",
           iscale = NULL, ishape = NULL, imethod = 1,
           eq.shapes = FALSE, sh.byrow = TRUE, zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammaff.mm_+3A_lscale">lscale</code>, <code id="gammaff.mm_+3A_lshape">lshape</code></td>
<td>

<p>Link functions applied to the (positive)
parameters <code class="reqn">b</code>,
and <code class="reqn">s_1</code>, ..., <code class="reqn">s_Q</code>
respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
In the future, <code>lshapes</code> might be used instead;
of course, this link applies to all the shape parameters.
</p>

</td></tr>
<tr><td><code id="gammaff.mm_+3A_iscale">iscale</code>, <code id="gammaff.mm_+3A_ishape">ishape</code>, <code id="gammaff.mm_+3A_sh.byrow">sh.byrow</code></td>
<td>

<p>Optional initial values.
The default is to compute them internally.
Argument <code>sh.byrow</code> is fed into
<code>byrow</code> in <code><a href="base.html#topic+matrix">matrix</a></code>
and concerns the ordering of the initial shape
parameters;
a matrix of dimension <code class="reqn">n</code> by <code class="reqn">Q</code> is
ultimately constructed.
See also <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="gammaff.mm_+3A_eq.shapes">eq.shapes</code></td>
<td>

<p>Logical.
Constrain the shape parameters to be equal?
See also <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="gammaff.mm_+3A_imethod">imethod</code>, <code id="gammaff.mm_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distribution has the
bivariate gamma distribution
<code><a href="VGAMdata.html#topic+bigamma.mckay">bigamma.mckay</a></code>
as a special case.
Let <code class="reqn">Q  &gt; 1</code> be the number of columns of the
response matrix <code>y</code>.
Then the
joint probability density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y_1,\ldots,y_Q; b, s_1, \ldots, s_Q) =
    y_1^{s_1} (y_2 - y_1)^{s_2}
    \cdots (y_Q - y_{Q-1})^{s_Q}
    \exp(-y_Q / b) / [b^{s_Q^*}
    \Gamma(s_1) \cdots \Gamma(s_Q)]</code>
</p>

<p>for <code class="reqn">b &gt; 0</code>,
<code class="reqn">s_1 &gt; 0</code>, ...,
<code class="reqn">s_Q &gt; 0</code> and
<code class="reqn">0&lt;y_1&lt; y_2&lt;\cdots&lt;y_Q&lt;\infty</code>.
Also,
<code class="reqn">s_Q^* = s_1+\cdots+s_Q</code>.
Here, <code class="reqn">\Gamma</code> is
the <code><a href="base.html#topic+Special">gamma</a></code> function,
By default, the linear/additive predictors are
<code class="reqn">\eta_1=\log(b)</code>,
<code class="reqn">\eta_2=\log(s_1)</code>,
...,
<code class="reqn">\eta_M=\log(s_Q)</code>.
Hence <code class="reqn">Q = M - 1</code>.
The marginal distributions are gamma,
with shape parameters
<code class="reqn">s_1</code> up to <code class="reqn">s_Q</code>, but they have a
common scale parameter <code class="reqn">b</code>.
</p>
<p>The fitted value returned
is a matrix with columns equalling
their respective means;
for column <code class="reqn">j</code> it is
<code>sum(shape[1:j]) * scale</code>.
</p>
<p>The correlations are always positive;
for columns <code class="reqn">j</code> and <code class="reqn">k</code>
with <code class="reqn">j &lt; k</code>,
the correlation is
<code>sqrt(sum(shape[1:j]) /sum(shape[1:k]))</code>.
Hence the variance of column <code class="reqn">j</code>
is <code>sum(shape[1:j]) * scale^2</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a matrix with at least
two columns.
Apart from the first column,
the differences between a column and
its LHS adjacent column
must all be positive.
That is, each row must be strictly increasing.
</p>




<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Mathai, A. M. and Moschopoulos, P. G. (1992).
A form of multivariate gamma distribution.
<em>Ann. Inst. Statist. Math.</em>,
<b>44</b>, 97&ndash;106.
</p>


<h3>See Also</h3>

<p><code><a href="VGAMdata.html#topic+bigamma.mckay">bigamma.mckay</a></code>,
<code><a href="#topic+gammaff">gammaff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("mbflood", package = "VGAMdata")
mbflood &lt;- transform(mbflood, VdivD = V / D)
fit &lt;- vglm(cbind(Q, y2 = Q + VdivD) ~ 1,
            gammaff.mm, trace = TRUE, data = mbflood)
coef(fit, matrix = TRUE)
Coef(fit)
vcov(fit)
colMeans(depvar(fit))  # Check moments
head(fitted(fit), 1)

## End(Not run)</code></pre>

<hr>
<h2 id='gammahyperbola'> Gamma Hyperbola Bivariate Distribution </h2><span id='topic+gammahyperbola'></span>

<h3>Description</h3>

<p>Estimate the parameter of a gamma hyperbola bivariate distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammahyperbola(ltheta = "loglink", itheta = NULL, expected = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammahyperbola_+3A_ltheta">ltheta</code></td>
<td>

<p>Link function applied to the (positive) parameter <code class="reqn">\theta</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="gammahyperbola_+3A_itheta">itheta</code></td>
<td>

<p>Initial value for the parameter.
The default is to estimate it internally.
</p>
</td></tr>
<tr><td><code id="gammahyperbola_+3A_expected">expected</code></td>
<td>

<p>Logical. <code>FALSE</code> means the Newton-Raphson (using
the observed information matrix) algorithm, otherwise the expected
information matrix is used (Fisher scoring algorithm).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The joint probability density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y_1,y_2) = \exp( -e^{-\theta} y_1 / \theta - \theta y_2 )</code>
</p>

<p>for <code class="reqn">\theta &gt; 0</code>, <code class="reqn">y_1 &gt; 0</code>, <code class="reqn">y_2 &gt; 1</code>.
The random variables <code class="reqn">Y_1</code>  and <code class="reqn">Y_2</code> are independent.
The marginal distribution of <code class="reqn">Y_1</code> is an exponential distribution
with rate parameter <code class="reqn">\exp(-\theta)/\theta</code>.
The marginal distribution of <code class="reqn">Y_2</code> is an exponential distribution
that has been shifted to the right by 1 and with
rate parameter <code class="reqn">\theta</code>.
The fitted values are stored in a two-column matrix with the marginal
means, which are <code class="reqn">\theta \exp(\theta)</code> and
<code class="reqn">1 + 1/\theta</code>.
</p>
<p>The default algorithm is Newton-Raphson because Fisher scoring tends to
be much slower for this distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Reid, N. (2003).
Asymptotics and the theory of inference.
<em>Annals of Statistics</em>,
<b>31</b>, 1695&ndash;1731.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exponential">exponential</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, theta = exp(-2 + x2))
gdata &lt;- transform(gdata, y1 = rexp(nn, rate = exp(-theta)/theta),
                          y2 = rexp(nn, rate = theta) + 1)
fit &lt;- vglm(cbind(y1, y2) ~ x2, gammahyperbola(expected = TRUE), data = gdata)
coef(fit, matrix = TRUE)
Coef(fit)
head(fitted(fit))
summary(fit)
</code></pre>

<hr>
<h2 id='gammaR'> 2-parameter Gamma Regression Family Function </h2><span id='topic+gammaR'></span>

<h3>Description</h3>

<p> Estimates the 2-parameter gamma distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaR(lrate = "loglink", lshape = "loglink", irate = NULL,
       ishape = NULL, lss = TRUE, zero = "shape")
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="gammaR_+3A_lrate">lrate</code>, <code id="gammaR_+3A_lshape">lshape</code></td>
<td>

<p>Link functions applied to the (positive) <em>rate</em> and <em>shape</em>
parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="gammaR_+3A_irate">irate</code>, <code id="gammaR_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial values for <em>rate</em> and <em>shape</em>.
A <code>NULL</code> means a value is computed internally.
If a failure to converge occurs, try using these arguments.
</p>
</td></tr>







<tr><td><code id="gammaR_+3A_zero">zero</code>, <code id="gammaR_+3A_lss">lss</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y; rate, shape) = \exp(-rate \times y) \times y^{shape-1} \times rate^{shape}
               / \Gamma(shape)</code>
</p>

<p>for <code class="reqn">shape &gt; 0</code>, <code class="reqn">rate &gt; 0</code> and <code class="reqn">y &gt; 0</code>.
Here, <code class="reqn">\Gamma(shape)</code> is the gamma
function, as in <code><a href="base.html#topic+Special">gamma</a></code>.
The mean of <em>Y</em> is <code class="reqn">\mu = shape/rate</code>
(returned as the fitted values) with variance
<code class="reqn">\sigma^2 = \mu^2 /shape = shape/rate^2</code>.
By default, the two linear/additive predictors are
<code class="reqn">\eta_1 = \log(rate)</code> and
<code class="reqn">\eta_2 = \log(shape)</code>.
</p>












<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The parameters <code class="reqn">rate</code> and <code class="reqn">shape</code> match with the arguments
<code>rate</code> and <code>shape</code> of <code><a href="stats.html#topic+rgamma">rgamma</a></code>.
The order of the arguments agree too.
Here, <code class="reqn">scale = 1/rate</code> is used, so one can use <code><a href="#topic+negloglink">negloglink</a></code>.
Multiple responses are handled.
</p>
<p>If <code class="reqn">rate = 1</code> use the family function <code><a href="#topic+gamma1">gamma1</a></code> to
estimate <code class="reqn">shape</code>.
</p>
<p>The reciprocal of a 2-parameter gamma random variate has an
<em>inverse gamma</em> distribution.
One might write a <span class="pkg">VGAM</span> family function called <code>invgammaR()</code>
to estimate this, but for now, just feed in the reciprocal of the
response.

</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Most standard texts on statistical distributions describe
the 2-parameter gamma distribution, e.g.,
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamma1">gamma1</a></code> for the 1-parameter gamma distribution,
<code><a href="#topic+gamma2">gamma2</a></code> for another parameterization of
the 2-parameter gamma distribution,
<code><a href="VGAMdata.html#topic+bigamma.mckay">bigamma.mckay</a></code>
for <em>a</em> bivariate gamma distribution,
<code><a href="#topic+gammaff.mm">gammaff.mm</a></code> for another,
<code><a href="#topic+expexpff">expexpff</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="stats.html#topic+rgamma">rgamma</a></code>,
<code><a href="#topic+negloglink">negloglink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Essentially a 1-parameter gamma
gdata &lt;- data.frame(y1 = rgamma(n &lt;- 100, shape =  exp(1)))
fit1 &lt;- vglm(y1 ~ 1, gamma1, data = gdata, trace = TRUE)
fit2 &lt;- vglm(y1 ~ 1, gammaR, data = gdata, trace = TRUE, crit = "coef")
coef(fit2, matrix = TRUE)
Coef(fit2)

# Essentially a 2-parameter gamma
gdata &lt;- data.frame(y2 = rgamma(n = 500, rate = exp(1), shape = exp(2)))
fit2 &lt;- vglm(y2 ~ 1, gammaR, data = gdata, trace = TRUE, crit = "coef")
coef(fit2, matrix = TRUE)
Coef(fit2)
summary(fit2)
</code></pre>

<hr>
<h2 id='garma'>GARMA (Generalized Autoregressive Moving-Average) Models</h2><span id='topic+garma'></span>

<h3>Description</h3>

<p>Fits GARMA models to time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>garma(link = "identitylink", p.ar.lag = 1, q.ma.lag = 0,
      coefstart = NULL, step = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="garma_+3A_link">link</code></td>
<td>

<p>Link function applied to the mean response.
The default is suitable for continuous responses.
The link <code><a href="#topic+loglink">loglink</a></code> should be chosen if the data
are counts.
The link <code><a href="#topic+reciprocal">reciprocal</a></code> can be chosen if the data
are counts
and the variance assumed for this is <code class="reqn">\mu^2</code>.
The links <code><a href="#topic+logitlink">logitlink</a></code>, <code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>, and
<code><a href="#topic+cauchitlink">cauchitlink</a></code> are supported and suitable for
binary responses.
</p>
<p>Note that when the log or logit link is chosen:
for log and logit,
zero values can be replaced by <code>bvalue</code>.
See <code><a href="#topic+loglink">loglink</a></code> and <code><a href="#topic+logitlink">logitlink</a></code> etc. for
specific information about each link function.
</p>
</td></tr>
<tr><td><code id="garma_+3A_p.ar.lag">p.ar.lag</code></td>
<td>

<p>A positive integer,
the lag for the autoregressive component.
Called <code class="reqn">p</code> below.
</p>
</td></tr>
<tr><td><code id="garma_+3A_q.ma.lag">q.ma.lag</code></td>
<td>

<p>A non-negative integer,
the lag for the moving-average component.
Called <code class="reqn">q</code> below.
</p>
</td></tr>
<tr><td><code id="garma_+3A_coefstart">coefstart</code></td>
<td>

<p>Starting values for the coefficients.
Assigning this argument is highly recommended.
For technical reasons, the
argument <code>coefstart</code> in <code><a href="#topic+vglm">vglm</a></code> cannot be used.
</p>
</td></tr>
<tr><td><code id="garma_+3A_step">step</code></td>
<td>

<p>Numeric. Step length, e.g., <code>0.5</code> means half-stepsizing.
</p>
</td></tr>






</table>


<h3>Details</h3>

<p>This function draws heavily on Benjamin <em>et al.</em> (1998).
See also Benjamin <em>et al.</em> (2003).
GARMA models extend the ARMA time series model to generalized
responses in the exponential family, e.g., Poisson counts,
binary responses. Currently, this function is rudimentary and
can handle only certain continuous, count and binary responses only.
The user must choose an appropriate link for the <code>link</code> argument.
</p>
<p>The GARMA(<code class="reqn">p, q</code>) model is defined by firstly
having a response belonging to the exponential family
</p>
<p style="text-align: center;"><code class="reqn">f(y_t|D_t) = \exp
        \left\{ \frac{y_t \theta_t - b(\theta_t)}{\phi / A_t} +
        c(y_t, \phi / A_t)
        \right\}</code>
</p>

<p>where <code class="reqn">\theta_t</code> and <code class="reqn">\phi</code> are the
canonical and scale parameters
respectively, and <code class="reqn">A_t</code> are known prior weights.
The mean
<code class="reqn">\mu_t=E(Y_t|D_t)=b'(\theta_t)</code>
is related to
the linear predictor  <code class="reqn">\eta_t</code>  by the link
function <code class="reqn">g</code>.
Here,
<code class="reqn">D_t=\{x_t,\ldots,x_1,y_{t-1},\ldots,y_1,\mu_{t-1},\ldots,\mu_1\}</code>
is the previous information set.
Secondly, the GARMA(<code class="reqn">p, q</code>) model is defined by
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_t) = \eta_t = x_t^T \beta +
    \sum_{k=1}^p \phi_k (g(y_{t-k}) - x_{t-k}^T \beta) +
    \sum_{k=1}^q \theta_k (g(y_{t-k}) - \eta_{t-k}).</code>
</p>

<p>Parameter vectors <code class="reqn">\beta</code>, <code class="reqn">\phi</code> and <code class="reqn">\theta</code>
are estimated by maximum likelihood.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Warning</h3>

<p>This <span class="pkg">VGAM</span> family function is 'non-standard' in that the
model does need some coercing to get it into the VGLM framework.
Special code is required to get it running. A consequence is
that some methods functions may give wrong results when applied
to the fitted object.
</p>


<h3>Note</h3>

<p>This function is unpolished and is requires <em>lots</em> of improvements.
In particular, initialization is <em>very poor</em>.
Results appear <em>very</em> sensitive to quality of initial values.
A limited amount of experience has shown that half-stepsizing is
often needed for convergence, therefore choosing <code>crit = "coef"</code>
is not recommended.
</p>
<p>Overdispersion is not handled.
For binomial responses it is currently best to input a vector
of 1s and 0s rather than the <code>cbind(successes, failures)</code>
because the initialize slot is rudimentary.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Benjamin, M. A., Rigby, R. A. and Stasinopoulos, M. D. (1998).
Fitting Non-Gaussian Time Series Models. Pages 191&ndash;196 in:
<em>Proceedings in Computational Statistics COMPSTAT 1998</em> by
Payne, R. and P. J. Green. Physica-Verlag.
</p>
<p>Benjamin, M. A., Rigby, R. A. and Stasinopoulos, M. D. (2003).
Generalized Autoregressive Moving Average Models.
<em>Journal of the American Statistical Association</em>,
<b>98</b>: 214&ndash;223.
</p>
<p>Zeger, S. L. and Qaqish, B. (1988).
Markov regression models for time series: a quasi-likelihood approach.
<em>Biometrics</em>,
<b>44</b>: 1019&ndash;1031.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(interspike = c(68, 41, 82, 66, 101, 66, 57,  41,  27, 78,
59, 73,  6, 44,  72, 66, 59,  60,  39, 52,
50, 29, 30, 56,  76, 55, 73, 104, 104, 52,
25, 33, 20, 60,  47,  6, 47,  22,  35, 30,
29, 58, 24, 34,  36, 34,  6,  19,  28, 16,
36, 33, 12, 26,  36, 39, 24,  14,  28, 13,
 2, 30, 18, 17,  28,  9, 28,  20,  17, 12,
19, 18, 14, 23,  18, 22, 18,  19,  26, 27,
23, 24, 35, 22,  29, 28, 17,  30,  34, 17,
20, 49, 29, 35,  49, 25, 55,  42,  29, 16))  # See Zeger and Qaqish (1988)
gdata &lt;- transform(gdata, spikenum = seq(interspike))
bvalue &lt;- 0.1  # .Machine$double.xmin # Boundary value
fit &lt;- vglm(interspike ~ 1, trace = TRUE, data = gdata,
            garma(loglink(bvalue = bvalue),
                  p = 2, coefstart = c(4, 0.3, 0.4)))
summary(fit)
coef(fit, matrix = TRUE)
Coef(fit)  # A bug here
## Not run:  with(gdata, plot(interspike, ylim = c(0, 120), las = 1,
     xlab = "Spike Number", ylab = "Inter-Spike Time (ms)", col = "blue"))
with(gdata, lines(spikenum[-(1:fit@misc$plag)], fitted(fit), col = "orange"))
abline(h = mean(with(gdata, interspike)), lty = "dashed", col = "gray") 
## End(Not run)
</code></pre>

<hr>
<h2 id='genbetaII'> Generalized Beta Distribution of the Second Kind </h2><span id='topic+genbetaII'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 4-parameter
generalized beta II distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genbetaII(lscale = "loglink", lshape1.a = "loglink",
     lshape2.p = "loglink", lshape3.q = "loglink",
     iscale = NULL, ishape1.a = NULL,
     ishape2.p = NULL, ishape3.q = NULL, lss = TRUE,
     gscale = exp(-5:5), gshape1.a = exp(-5:5),
     gshape2.p = exp(-5:5), gshape3.q = exp(-5:5), zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genbetaII_+3A_lss">lss</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for important
information.
</p>
</td></tr>
<tr><td><code id="genbetaII_+3A_lshape1.a">lshape1.a</code>, <code id="genbetaII_+3A_lscale">lscale</code>, <code id="genbetaII_+3A_lshape2.p">lshape2.p</code>, <code id="genbetaII_+3A_lshape3.q">lshape3.q</code></td>
<td>

<p>Parameter link functions applied to the
shape parameter <code>a</code>,
scale parameter <code>scale</code>,
shape parameter <code>p</code>, and
shape parameter <code>q</code>.
All four parameters are positive.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="genbetaII_+3A_iscale">iscale</code>, <code id="genbetaII_+3A_ishape1.a">ishape1.a</code>, <code id="genbetaII_+3A_ishape2.p">ishape2.p</code>, <code id="genbetaII_+3A_ishape3.q">ishape3.q</code></td>
<td>

<p>Optional initial values for the parameters.
A <code>NULL</code> means a value is computed internally using
the arguments <code>gscale</code>, <code>gshape1.a</code>, etc.
</p>
</td></tr>
<tr><td><code id="genbetaII_+3A_gscale">gscale</code>, <code id="genbetaII_+3A_gshape1.a">gshape1.a</code>, <code id="genbetaII_+3A_gshape2.p">gshape2.p</code>, <code id="genbetaII_+3A_gshape3.q">gshape3.q</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Replaced by <code>iscale</code>, <code>ishape1.a</code> etc. if given.
</p>
</td></tr>



<tr><td><code id="genbetaII_+3A_zero">zero</code></td>
<td>

<p>The default is to set all the shape parameters to be
intercept-only.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>


</td></tr>
</table>


<h3>Details</h3>

<p>This distribution is most useful for unifying a substantial
number of size distributions. For example, the Singh-Maddala,
Dagum, Fisk (log-logistic), Lomax (Pareto type II),
inverse Lomax, beta distribution of the second kind
distributions are all special cases.
Full details can be found in Kleiber and Kotz (2003), and
Brazauskas (2002).
The argument names given here are used by other families that
are special cases of this family.
Fisher scoring is used here and for the special cases too.
</p>
<p>The 4-parameter generalized beta II distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = a y^{ap-1} / [b^{ap} B(p,q) \{1 + (y/b)^a\}^{p+q}]</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">p &gt; 0</code>, <code class="reqn">q &gt; 0</code>,
<code class="reqn">y \geq 0</code>.
Here <code class="reqn">B</code> is the beta function, and
<code class="reqn">b</code> is the scale parameter <code>scale</code>,
while the others are shape parameters.
The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(p + 1/a) \, \Gamma(q - 1/a) / (\Gamma(p) \,
      \Gamma(q))</code>
</p>

<p>provided <code class="reqn">-ap &lt; 1 &lt; aq</code>; these are returned as the fitted values.
</p>




<p>This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This distribution is very flexible and it is not generally
recommended to use this family function when the sample size
is small&mdash;numerical problems easily occur with small samples.
Probably several hundred observations at least are needed in
order to estimate the parameters with any level of confidence.
Neither is the inclusion of covariates recommended at all&mdash;not
unless there are several thousand observations.  The mean is
finite only when <code class="reqn">-ap &lt; 1 &lt; aq</code>, and this can be easily
violated by the parameter estimates for small sample sizes.
Try fitting some of the special cases of this distribution
(e.g., <code><a href="#topic+sinmad">sinmad</a></code>, <code><a href="#topic+fisk">fisk</a></code>, etc.) first,
and then possibly use those models for initial values for
this distribution.
</p>


<h3>Note</h3>

<p>The default is to use a grid search with respect to all
four parameters; this is quite costly and is time consuming.
If the self-starting initial values fail, try experimenting
with the initial value arguments.
Also, the constraint <code class="reqn">-ap &lt; 1 &lt; aq</code>
may be violated as the iterations progress so it pays
to monitor convergence, e.g., set <code>trace = TRUE</code>.
Successful convergence depends on having very good initial
values. This is rather difficult for this distribution so that
a grid search is conducted by default.
One suggestion for increasing the estimation reliability
is to set <code>stepsize = 0.5</code> and <code>maxit = 100</code>;
see <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee, with help from Victor Miranda. </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>
<p>Brazauskas, V. (2002).
Fisher information matrix for the Feller-Pareto distribution.
<em>Statistics &amp; Probability Letters</em>,
<b>59</b>, 159&ndash;167.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dgenbetaII">dgenbetaII</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+lino">lino</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gdata &lt;- data.frame(y = rsinmad(3000, shape1 = exp(1), scale = exp(2),
                                shape3 = exp(1)))  # A special case!
fit &lt;- vglm(y ~ 1, genbetaII(lss = FALSE), data = gdata, trace = TRUE)
fit &lt;- vglm(y ~ 1, data = gdata, trace = TRUE,
            genbetaII(ishape1.a = 3, iscale = 7, ishape3.q = 2.3))
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='GenbetaII'>The Generalized Beta II Distribution</h2><span id='topic+GenbetaII'></span><span id='topic+dgenbetaII'></span>

<h3>Description</h3>

<p>Density
for the generalized beta II distribution
with shape parameters <code>a</code>
and <code>p</code>
and <code>q</code>, and scale parameter <code>scale</code>.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dgenbetaII(x, scale = 1, shape1.a, shape2.p, shape3.q, log = FALSE)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="GenbetaII_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>



<tr><td><code id="GenbetaII_+3A_shape1.a">shape1.a</code>, <code id="GenbetaII_+3A_shape2.p">shape2.p</code>, <code id="GenbetaII_+3A_shape3.q">shape3.q</code></td>
<td>
<p>positive shape parameters.</p>
</td></tr>
<tr><td><code id="GenbetaII_+3A_scale">scale</code></td>
<td>
<p>positive scale parameter.</p>
</td></tr>
<tr><td><code id="GenbetaII_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>




</table>


<h3>Details</h3>

<p>See <code><a href="#topic+genbetaII">genbetaII</a></code>, which is the <span class="pkg">VGAM</span> family function
for estimating the parameters by maximum likelihood estimation.
Several distributions, such as the Singh-Maddala, are special case of
this flexible 4-parameter distribution.
The product of <code>shape1.a</code> and <code>shape2.p</code> determines the
behaviour of the density at the origin.
</p>


<h3>Value</h3>

<p><code>dgenbetaII</code> gives the density.



</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dgenbetaII(0, shape1.a = 1/4, shape2.p = 4, shape3.q = 3)
dgenbetaII(0, shape1.a = 1/4, shape2.p = 2, shape3.q = 3)
dgenbetaII(0, shape1.a = 1/4, shape2.p = 8, shape3.q = 3)
</code></pre>

<hr>
<h2 id='gengamma.stacy'> Generalized Gamma distribution family function </h2><span id='topic+gengamma.stacy'></span>

<h3>Description</h3>

<p>Estimation of the 3-parameter generalized gamma distribution proposed by
Stacy (1962).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gengamma.stacy(lscale = "loglink", ld = "loglink", lk = "loglink",
    iscale = NULL, id = NULL, ik = NULL, imethod = 1,
    gscale.mux = exp((-4:4)/2), gshape1.d = exp((-5:5)/2),
    gshape2.k = exp((-5:5)/2), probs.y = 0.3, zero = c("d", "k"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gengamma.stacy_+3A_lscale">lscale</code>, <code id="gengamma.stacy_+3A_ld">ld</code>, <code id="gengamma.stacy_+3A_lk">lk</code></td>
<td>

<p>Parameter link function applied to each of the positive parameters
<code class="reqn">b</code>, <code class="reqn">d</code> and <code class="reqn">k</code>, respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="gengamma.stacy_+3A_iscale">iscale</code>, <code id="gengamma.stacy_+3A_id">id</code>, <code id="gengamma.stacy_+3A_ik">ik</code></td>
<td>

<p>Initial value for <code class="reqn">b</code>, <code class="reqn">d</code> and <code class="reqn">k</code>, respectively.
The defaults mean an initial value is determined internally for each.
</p>
</td></tr>
<tr><td><code id="gengamma.stacy_+3A_gscale.mux">gscale.mux</code>, <code id="gengamma.stacy_+3A_gshape1.d">gshape1.d</code>, <code id="gengamma.stacy_+3A_gshape2.k">gshape2.k</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Replaced by <code>iscale</code>, <code>id</code> etc. if given.
</p>
</td></tr>
<tr><td><code id="gengamma.stacy_+3A_imethod">imethod</code>, <code id="gengamma.stacy_+3A_probs.y">probs.y</code>, <code id="gengamma.stacy_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>




</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y;b,d,k) = d   b^{-d k}   y^{d k-1}  \exp[-(y/b)^d] / \Gamma(k)</code>
</p>

<p>for scale parameter <code class="reqn">b &gt; 0</code>,
and Weibull-type shape parameter <code class="reqn">d &gt; 0</code>,
gamma-type shape parameter <code class="reqn">k &gt; 0</code>,
and <code class="reqn">y &gt; 0</code>.
The mean of <code class="reqn">Y</code>
is <code class="reqn">b \times \Gamma(k+1/d) / \Gamma(k)</code>
(returned as the fitted values),
which equals <code class="reqn">bk</code> if <code class="reqn">d=1</code>.
</p>
<p>There are many special cases, as given in Table 1 of Stacey and Mihram (1965).
In the following, the parameters are in the order <code class="reqn">b,d,k</code>.
The special cases are:
Exponential       <code class="reqn">f(y;b,1,1)</code>,
Gamma             <code class="reqn">f(y;b,1,k)</code>,
Weibull           <code class="reqn">f(y;b,d,1)</code>,
Chi Squared       <code class="reqn">f(y;2,1,a/2)</code> with <code class="reqn">a</code> degrees of freedom,
Chi               <code class="reqn">f(y;\sqrt{2},2,a/2)</code> with <code class="reqn">a</code> degrees of freedom,
Half-normal       <code class="reqn">f(y;\sqrt{2},2,1/2)</code>,
Circular normal   <code class="reqn">f(y;\sqrt{2},2,1)</code>,
Spherical normal  <code class="reqn">f(y;\sqrt{2},2,3/2)</code>,
Rayleigh          <code class="reqn">f(y;c\sqrt{2},2,1)</code> where <code class="reqn">c&gt;0</code>.
Also the log-normal distribution corresponds to when <code>k = Inf</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Several authors have considered maximum likelihood estimation for the
generalized gamma distribution and have found that the Newton-Raphson
algorithm does not work very well and that the existence of solutions
to the log-likelihood equations is sometimes in doubt.
Although Fisher scoring is used here, it is likely that the same
problems will be encountered.
It appears that large samples
are required, for example, the estimator of <code class="reqn">k</code> became asymptotically
normal only with 400 or more observations.
It is not uncommon for maximum likelihood estimates to fail to converge
even with two or three hundred observations.
With covariates, even more observations are needed to increase the
chances of convergence.
Using covariates is not advised unless the sample size is at least
a few thousand, and even if so,
modelling 1 or 2 parameters as intercept-only is a very good idea
(e.g., <code>zero = 2:3</code>).
Monitoring convergence is also a very good idea
(e.g., set <code>trace = TRUE</code>).
Half-stepping is not uncommon, and if this occurs, then the
results should be viewed with more suspicion.
</p>


<h3>Note</h3>

<p>The notation used here differs from Stacy (1962) and Prentice (1974).
Poor initial values may result in failure to converge so
if there are covariates and there are convergence problems,
try using or checking the <code>zero</code> argument (e.g., <code>zero = 2:3</code>)
or the <code>ik</code> argument
or the <code>imethod</code> argument, etc.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Stacy, E. W. (1962).
A generalization of the gamma distribution.
<em>Annals of Mathematical Statistics</em>, <b>33</b>(3), 1187&ndash;1192.
</p>
<p>Stacy, E. W. and Mihram, G. A. (1965).
Parameter estimation for a generalized gamma distribution.
<em>Technometrics</em>, <b>7</b>, 349&ndash;358.
</p>
<p>Prentice, R. L. (1974).
A log gamma model and its maximum likelihood estimation.
<em>Biometrika</em>, <b>61</b>, 539&ndash;544.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rgengamma.stacy">rgengamma.stacy</a></code>,
<code><a href="#topic+gamma1">gamma1</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>,
<code><a href="#topic+prentice74">prentice74</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+chisq">chisq</a></code>,
<code><a href="#topic+lognormal">lognormal</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="#topic+weibullR">weibullR</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>k &lt;- exp(-1); Scale &lt;- exp(1); dd &lt;- exp(0.5); set.seed(1)
gdata &lt;- data.frame(y = rgamma(2000, shape = k, scale = Scale))
gfit &lt;- vglm(y ~ 1, gengamma.stacy, data = gdata, trace = TRUE)
coef(gfit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='gengammaUC'>Generalized Gamma Distribution </h2><span id='topic+gengammaUC'></span><span id='topic+dgengamma.stacy'></span><span id='topic+pgengamma.stacy'></span><span id='topic+qgengamma.stacy'></span><span id='topic+rgengamma.stacy'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the generalized  gamma distribution with
scale parameter <code>scale</code>,
and parameters <code>d</code> and <code>k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgengamma.stacy(x, scale = 1, d, k, log = FALSE)
pgengamma.stacy(q, scale = 1, d, k,
                lower.tail = TRUE, log.p = FALSE)
qgengamma.stacy(p, scale = 1, d, k,
                lower.tail = TRUE, log.p = FALSE)
rgengamma.stacy(n, scale = 1, d, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gengammaUC_+3A_x">x</code>, <code id="gengammaUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="gengammaUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="gengammaUC_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="gengammaUC_+3A_scale">scale</code></td>
<td>
<p>the (positive) scale parameter <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="gengammaUC_+3A_d">d</code>, <code id="gengammaUC_+3A_k">k</code></td>
<td>
<p>the (positive) parameters <code class="reqn">d</code> and <code class="reqn">k</code>.
Both can be thought of as shape parameters, where
<code class="reqn">d</code> is of the Weibull-type and
<code class="reqn">k</code> is of the gamma-type.
</p>
</td></tr>
<tr><td><code id="gengammaUC_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="gengammaUC_+3A_lower.tail">lower.tail</code>, <code id="gengammaUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+gengamma.stacy">gengamma.stacy</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the generalized gamma distribution
by maximum likelihood estimation,
for formulae and other details.
Apart from <code>n</code>, all the above arguments may be vectors and
are recyled to the appropriate length if necessary.
</p>


<h3>Value</h3>

<p><code>dgengamma.stacy</code> gives the density,
<code>pgengamma.stacy</code> gives the distribution function,
<code>qgengamma.stacy</code> gives the quantile function, and
<code>rgengamma.stacy</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Stacy, E. W. and Mihram, G. A. (1965).
Parameter estimation for a generalized gamma distribution.
<em>Technometrics</em>, <b>7</b>, 349&ndash;358.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gengamma.stacy">gengamma.stacy</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  x &lt;- seq(0, 14, by = 0.01); d &lt;- 1.5; Scale &lt;- 2; k &lt;- 6
plot(x, dgengamma.stacy(x, Scale, d = d, k = k), type = "l",
     col = "blue", ylim = 0:1,
     main = "Blue is density, orange is the CDF",
     sub = "Purple are 5,10,...,95 percentiles", las = 1, ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(qgengamma.stacy(seq(0.05, 0.95, by = 0.05), Scale, d = d, k = k),
      dgengamma.stacy(qgengamma.stacy(seq(0.05, 0.95, by = 0.05),
                                      Scale, d = d, k = k),
            Scale, d = d, k = k), col = "purple", lty = 3, type = "h")
lines(x, pgengamma.stacy(x, Scale, d = d, k = k), col = "orange")
abline(h = 0, lty = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Genpois0'>Generalized Poisson Distribution
(Original Parameterization)</h2><span id='topic+Genpois0'></span><span id='topic+dgenpois0'></span><span id='topic+pgenpois0'></span><span id='topic+qgenpois0'></span><span id='topic+rgenpois0'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and
random generation
for the original parameterization of the
generalized Poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgenpois0(x, theta, lambda = 0, log = FALSE)
pgenpois0(q, theta, lambda = 0, lower.tail = TRUE)
qgenpois0(p, theta, lambda = 0)
rgenpois0(n, theta, lambda = 0, algorithm = c("qgenpois0",
          "inv", "bup","chdn", "napp", "bran"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Genpois0_+3A_x">x</code>, <code id="Genpois0_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="Genpois0_+3A_p">p</code></td>
<td>
<p>Vector of probabilities. </p>
</td></tr>
<tr><td><code id="Genpois0_+3A_n">n</code></td>
<td>
<p>Similar to <code><a href="stats.html#topic+runif">runif</a></code>.</p>
</td></tr>
<tr><td><code id="Genpois0_+3A_theta">theta</code>, <code id="Genpois0_+3A_lambda">lambda</code></td>
<td>

<p>See <code><a href="#topic+genpoisson0">genpoisson0</a></code>.
The default value of <code>lambda</code> corresponds to an
ordinary Poisson distribution.
<em>Nonnegative</em> values
of <code>lambda</code> are currently required.
</p>

</td></tr>
<tr><td><code id="Genpois0_+3A_lower.tail">lower.tail</code>, <code id="Genpois0_+3A_log">log</code></td>
<td>

<p>Similar to <code><a href="stats.html#topic+Poisson">Poisson</a></code>.
</p>
</td></tr>
<tr><td><code id="Genpois0_+3A_algorithm">algorithm</code></td>
<td>

<p>Character.
Six choices are available, standing for the
<em>qgenpois0</em>,
<em>inversion</em>, <em>build-up</em>, <em>chop-down</em>,
<em>normal approximation</em> and <em>branching</em> methods.
The first one is the default and
calls <code>qgenpois0</code> with <code><a href="stats.html#topic+runif">runif</a></code> as
its first argument.
The value inputted may be abbreviated, e.g., <code>alg = "n"</code>.
The last 5 algorithms are a direct implementation of Demirtas (2017)
and the relative performance of the algorithms are
described there&mdash;however, the vectorization here may render
the comments on relative speed as no longer holding.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the background to these functions are given
in <code><a href="#topic+genpoisson0">genpoisson0</a></code>.
Some warnings relevant to this distribution are given there.
The complicated range of the
parameter <code>lambda</code> when negative is no longer
supported because the distribution is not normalized.
For other GPD variants see <code><a href="#topic+Genpois1">Genpois1</a></code>.
</p>




<h3>Value</h3>

<p><code>dgenpois0</code> gives the density,
<code>pgenpois0</code> gives the distribution function,
<code>qgenpois0</code> gives the quantile function, and
<code>rgenpois</code> generates random deviates.
For some of these functions such as
<code>dgenpois0</code> and <code>pgenpois0</code>
the value <code>NaN</code> is returned for elements not satisfying
the parameter restrictions, e.g., if <code class="reqn">\lambda &gt; 1</code>.
For some of these functions such as
<code>rgenpois0</code>
the input must not contain <code>NA</code>s or <code>NaN</code>s, etc. since
the implemented algorithms are fragile.
</p>



<h3>Warning </h3>

<p>These have not been tested thoroughly.
</p>



<p>For <code>pgentpois0()</code> <code><a href="base.html#topic+mapply">mapply</a></code> is called
with <code>0:q</code> as input, hence will be very slow and
memory-hungry for large values of <code>q</code>.
Likewise <code>qgentpois0()</code> and <code>rgentpois0()</code>
may suffer from the same limitations.
</p>


<h3>Note</h3>

<p>For <code>rgentpois0()</code>:
(1). <code>"inv"</code>, <code>"bup"</code> and <code>"chdn"</code> appear similar and
seem to work okay.
(2). <code>"napp"</code> works only when theta is large, away from 0.
It suffers from 0-inflation.
(3). <code>"bran"</code> has a relatively heavy RHS tail and
requires positive <code>lambda</code>.
More details can be found in
Famoye (1997) and
Demirtas (2017).
</p>
<p>The function <code>dgenpois0</code>
uses <code><a href="base.html#topic+Special">lfactorial</a></code>, which
equals <code>Inf</code> when <code>x</code> is approximately <code>1e306</code>
on many machines.
So the density is returned as <code>0</code> in very extreme cases;
see <code><a href="base.html#topic+.Machine">.Machine</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.
For <code>rgenpois0()</code> the last 5 algorithms are based on
code written in H. Demirtas (2017) and vectorized by T. W. Yee;
but the <code>"bran"</code> algorithm was rewritten from
Famoye (1997).
</p>


<h3>References</h3>

<p>Demirtas, H. (2017).
On accurate and precise generation of generalized Poisson variates.
<em>Communications in Statistics&mdash;Simulation and Computation</em>,
<b>46</b>, 489&ndash;499.
</p>
<p>Famoye, F. (1997).
Generalized Poisson random variate generation.
<em>Amer. J. Mathematical and Management Sciences</em>,
<b>17</b>, 219&ndash;237.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+genpoisson0">genpoisson0</a></code>,
<code><a href="#topic+Genpois1">Genpois1</a></code>,
<code><a href="stats.html#topic+Poisson">dpois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sum(dgenpois0(0:1000, theta = 2, lambda = 0.5))
## Not run: theta &lt;- 2; lambda &lt;- 0.2; y &lt;- 0:10
proby &lt;- dgenpois0(y, theta = theta, lambda = lambda, log = FALSE)
plot(y, proby, type = "h", col = "blue", lwd = 2, ylab = "Pr(Y=y)",
     main = paste0("Y ~ GP-0(theta=", theta, ", lambda=",
                   lambda, ")"), las = 1, ylim = c(0, 0.3),
     sub = "Orange is the Poisson probability function")
lines(y + 0.1, dpois(y, theta), type = "h", lwd = 2, col = "orange") 
## End(Not run)
</code></pre>

<hr>
<h2 id='Genpois1'>Generalized Poisson Distribution
(GP-1 and GP-2 Parameterizations of the Mean)</h2><span id='topic+Genpois1'></span><span id='topic+Genpois2'></span><span id='topic+dgenpois1'></span><span id='topic+pgenpois1'></span><span id='topic+qgenpois1'></span><span id='topic+rgenpois1'></span><span id='topic+dgenpois2'></span><span id='topic+pgenpois2'></span><span id='topic+qgenpois2'></span><span id='topic+rgenpois2'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and
random generation
for two parameterizations (GP-1 and GP-2) of the
generalized Poisson distribution of the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgenpois1(x, meanpar, dispind = 1, log = FALSE)
pgenpois1(q, meanpar, dispind = 1, lower.tail = TRUE)
qgenpois1(p, meanpar, dispind = 1)
rgenpois1(n, meanpar, dispind = 1)
dgenpois2(x, meanpar, disppar = 0, log = FALSE)
pgenpois2(q, meanpar, disppar = 0, lower.tail = TRUE)
qgenpois2(p, meanpar, disppar = 0)
rgenpois2(n, meanpar, disppar = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Genpois1_+3A_x">x</code>, <code id="Genpois1_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="Genpois1_+3A_p">p</code></td>
<td>
<p>Vector of probabilities. </p>
</td></tr>
<tr><td><code id="Genpois1_+3A_n">n</code></td>
<td>
<p>Similar to <code><a href="stats.html#topic+runif">runif</a></code>.</p>
</td></tr>
<tr><td><code id="Genpois1_+3A_meanpar">meanpar</code>, <code id="Genpois1_+3A_dispind">dispind</code></td>
<td>

<p>The mean and dispersion index (index of dispersion), which
are the two parameters for the GP-1.
The mean is positive while the <code>dispind</code>
is <code class="reqn">\geq 1</code>.
The default value of <code>dispind</code> corresponds to an
ordinary Poisson distribution.
</p>

</td></tr>
<tr><td><code id="Genpois1_+3A_disppar">disppar</code></td>
<td>

<p>The dispersion parameter for the GP-2:
<code>disppar</code> <code class="reqn">\geq 0</code>.
The default value of <code>disppar</code> corresponds to an
ordinary Poisson distribution.
</p>

</td></tr>
<tr><td><code id="Genpois1_+3A_lower.tail">lower.tail</code>, <code id="Genpois1_+3A_log">log</code></td>
<td>

<p>See <code><a href="#topic+Genpois0">Genpois0</a></code>.
</p>
</td></tr>


</table>


<h3>Details</h3>

<p>These are wrapper functions for those in <code><a href="#topic+Genpois0">Genpois0</a></code>.
The first parameter is the mean,
therefore both the GP-1 and GP-2 are recommended for regression
and can be compared somewhat
to <code><a href="#topic+poissonff">poissonff</a></code> and <code><a href="#topic+negbinomial">negbinomial</a></code>.
The variance of a GP-1 is <code class="reqn">\mu \varphi</code>
where <code class="reqn">\varphi = 1 / (1 - \lambda)^2</code> is <code>dispind</code>.
</p>
<p>The variance of a GP-2 is <code class="reqn">\mu (1 + \alpha \mu)^2</code>
where <code class="reqn">\theta  =        \mu / (1 + \alpha \mu)</code>,
<code class="reqn">\lambda = \alpha \mu / (1 + \alpha \mu)</code>,
and is <code class="reqn">\alpha</code> is the dispersion parameter <code>disppar</code>.
Thus the variance is linear with respect to the mean for GP-1
while 
the variance is cubic with respect to the mean for GP-2.
</p>
<p>Recall that the <em>index of dispersion</em>
(also known as the <em>dispersion index</em>)
is the ratio of the variance and the mean.
Also, <code class="reqn">\mu = \theta /(1 - \lambda)</code> in the original
formulation with variance <code class="reqn">\theta /(1 - \lambda)^3</code>.
The GP-1 is due to Consul and Famoye (1992).
The GP-2 is due to Wang and Famoye (1997).
</p>




<h3>Value</h3>

<p><code>dgenpois1</code> and <code>dgenpois2</code> give the density,
<code>pgenpois1</code> and <code>dgenpois2</code> give the distribution function,
<code>qgenpois1</code> and <code>dgenpois2</code> give the quantile function, and
<code>rgenpois1</code> and <code>dgenpois2</code> generate random deviates.
See <code><a href="#topic+Genpois0">Genpois0</a></code> for more information.
</p>


<h3>Warning </h3>

<p><code><a href="#topic+Genpois0">Genpois0</a></code> has warnings that should be heeded.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.
</p>


<h3>References</h3>

<p>Consul, P. C. and Famoye, F. (1992).
Generalized Poisson regression model.
<em>Comm. Statist.&mdash;Theory and Meth.</em>,
<b>2</b>, 89&ndash;109.
</p>
<p>Wang, W. and Famoye, F. (1997).
Modeling household fertility decisions with
generalized Poisson regression.
<em>J. Population Econom.</em>,
<b>10</b>, 273&ndash;283.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+Genpois0">Genpois0</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sum(dgenpois1(0:1000, meanpar = 5, dispind = 2))
## Not run: dispind &lt;- 5; meanpar &lt;- 5; y &lt;- 0:15
proby &lt;- dgenpois1(y, meanpar = meanpar, dispind)
plot(y, proby, type = "h", col = "blue", lwd = 2, ylab = "P[Y=y]",
     main = paste0("Y ~ GP-1(meanpar=", meanpar, ", dispind=",
                   dispind, ")"), las = 1, ylim = c(0, 0.3),
     sub = "Orange is the Poisson probability function")
lines(y + 0.1, dpois(y, meanpar), type = "h", lwd = 2, col = "orange") 
## End(Not run)
</code></pre>

<hr>
<h2 id='genpoisson0'> Generalized Poisson Regression
(Original Parameterization) </h2><span id='topic+genpoisson0'></span>

<h3>Description</h3>

<p>Estimation of the two-parameter generalized Poisson distribution
(original parameterization).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genpoisson0(ltheta = "loglink", llambda = "logitlink",
            itheta = NULL, ilambda = NULL, imethod = c(1, 1),
            ishrinkage = 0.95, glambda = ppoints(5),
            parallel = FALSE, zero = "lambda")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genpoisson0_+3A_ltheta">ltheta</code>, <code id="genpoisson0_+3A_llambda">llambda</code></td>
<td>

<p>Parameter link functions for <code class="reqn">\theta</code> and <code class="reqn">\lambda</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
In theory the <code class="reqn">\lambda</code> parameter is allowed to be negative to
handle underdispersion, however this is no longer supported,
hence <code class="reqn">0 &lt; \lambda &lt; 1</code>.
The <code class="reqn">\theta</code> parameter is positive, therefore the default is the
log link.
</p>



</td></tr>
<tr><td><code id="genpoisson0_+3A_itheta">itheta</code>, <code id="genpoisson0_+3A_ilambda">ilambda</code></td>
<td>

<p>Optional initial values for <code class="reqn">\lambda</code> and <code class="reqn">\theta</code>.
The default is to choose values internally.
</p>
</td></tr>




<tr><td><code id="genpoisson0_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Each value is an integer <code>1</code> or <code>2</code> or <code>3</code> which
specifies the initialization method for each of the parameters.
If failure to converge occurs try another value
and/or else specify a value for <code>ilambda</code> and/or <code>itheta</code>.
The argument is recycled to length 2, and the first value
corresponds to <code>theta</code>, etc.
</p>
</td></tr>
<tr><td><code id="genpoisson0_+3A_ishrinkage">ishrinkage</code>, <code id="genpoisson0_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="genpoisson0_+3A_glambda">glambda</code>, <code id="genpoisson0_+3A_parallel">parallel</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Argument <code>glambda</code> is similar to <code>gsigma</code>
there and is currently used only if <code>imethod[2] = 1</code>.
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>The generalized Poisson distribution (GPD) was proposed by
Consul and Jain (1973),
and it has PMF
</p>
<p style="text-align: center;"><code class="reqn">f(y)=\theta(\theta+\lambda y)^{y-1} \exp(-\theta-\lambda y) / y!</code>
</p>

<p>for <code class="reqn">0 &lt; \theta</code> and <code class="reqn">y = 0,1,2,\ldots</code>.
Theoretically,
<code class="reqn">\max(-1,-\theta/m) \leq \lambda \leq 1</code>
where <code class="reqn">m</code>  <code class="reqn">(\geq 4)</code> is the greatest positive
integer satisfying <code class="reqn">\theta + m\lambda &gt; 0</code>
when <code class="reqn">\lambda &lt; 0</code>
[and then <code class="reqn">Pr(Y=y) = 0</code> for <code class="reqn">y &gt; m</code>].
However, there are problems with a negative <code class="reqn">\lambda</code> such as
it not being normalized, so this family function restricts
<code class="reqn">\lambda</code> to <code class="reqn">(0, 1)</code>.
</p>




<p>This original parameterization is called the GP-0 by <span class="pkg">VGAM</span>,
partly because there are two other common parameterizations
called the GP-1 and GP-2 (see Yang et al. (2009)),
<code><a href="#topic+genpoisson1">genpoisson1</a></code>
and <code><a href="#topic+genpoisson2">genpoisson2</a></code>)
that are more suitable for regression.
However, <code>genpoisson()</code> has been simplified to
<code><a href="#topic+genpoisson0">genpoisson0</a></code> by only handling positive parameters,
hence only overdispersion relative to the Poisson is accommodated.
Some of the reasons for this are described in
Scollnik (1998), e.g., the probabilities do not
sum to unity when <code>lambda</code> is negative.
To simply things, <span class="pkg">VGAM</span> 1.1-4 and later will only
handle positive <code>lambda</code>.
</p>






<p>An ordinary Poisson distribution corresponds
to <code class="reqn">\lambda = 0</code>.
The mean (returned as the fitted values) is
<code class="reqn">E(Y) = \theta / (1 - \lambda)</code>
and the variance is <code class="reqn">\theta / (1 - \lambda)^3</code>
so that the variance is proportional to the mean,
just like the NB-1 and quasi-Poisson.
</p>
<p>For more information see Consul and Famoye (2006) for a summary
and Consul (1989) for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Although this family function is far less fragile compared to
what used to be called <code>genpoisson()</code> it is still a
good idea to monitor convergence because
equidispersion may result in numerical problems;
try <code><a href="#topic+poissonff">poissonff</a></code> instead.
And underdispersed data will definitely result in
numerical problems and warnings;
try <code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code> instead.
</p>


<h3>Note</h3>

<p>This family function replaces <code>genpoisson()</code>, and some of the
major changes are:
(i) the swapping of the linear predictors;
(ii) the change from <code><a href="#topic+rhobitlink">rhobitlink</a></code> to
<code><a href="#topic+logitlink">logitlink</a></code> in <code>llambda</code>
to reflect the no longer handling of underdispersion;
(iii) proper Fisher scoring is implemented to give improved
convergence.
</p>
<p>Notationally, and in the literature too,
don't get confused because <code>theta</code>
(and not <code>lambda</code>) here really
matches more closely with <code>lambda</code> of
<code><a href="stats.html#topic+Poisson">dpois</a></code>.
</p>
<p>This family function handles multiple responses.
This distribution is potentially useful for dispersion modelling.
Convergence and numerical problems may occur when <code>lambda</code>
becomes very close to 0 or 1.
</p>







<h3>Author(s)</h3>

<p> T. W. Yee.
Easton Huch derived the EIM and it has been implemented
in the <code>weights</code> slot.
</p>


<h3>References</h3>

<p>Consul, P. C. and Jain, G. C. (1973).
A generalization of the Poisson distribution.
<em>Technometrics</em>,
<b>15</b>, 791&ndash;799.
</p>
<p>Consul, P. C. and Famoye, F. (2006).
<em>Lagrangian Probability Distributions</em>,
Boston, USA: Birkhauser.
</p>
<p>Jorgensen, B. (1997).
<em>The Theory of Dispersion Models</em>.
London: Chapman &amp; Hall.
</p>
<p>Consul, P. C. (1989).
<em>Generalized Poisson Distributions: Properties and Applications</em>.
New York, USA: Marcel Dekker.
</p>
<p>Yang, Z., Hardin, J. W., Addy, C. L. (2009).
A score test for overdispersion in Poisson regression based
on the generalized Poisson-2 model.
<em>J. Statist. Plann. Infer.</em>,
<b>139</b>, 1514&ndash;1521.
</p>
<p>Yee, T. W. (2020).
On generalized Poisson regression.
<em>In preparation</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Genpois0">Genpois0</a></code>,
<code><a href="#topic+genpoisson1">genpoisson1</a></code>,
<code><a href="#topic+genpoisson2">genpoisson2</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="stats.html#topic+Poisson">Poisson</a></code>,
<code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 500))
gdata &lt;- transform(gdata, y1 = rgenpois0(nn, theta = exp(2 + x2),
                                         logitlink(1, inverse = TRUE)))
gfit0 &lt;- vglm(y1 ~ x2, genpoisson0, data = gdata, trace = TRUE)
coef(gfit0, matrix = TRUE)
summary(gfit0)
</code></pre>

<hr>
<h2 id='genpoisson1'> Generalized Poisson Regression
(GP-1 Parameterization) </h2><span id='topic+genpoisson1'></span>

<h3>Description</h3>

<p>Estimation of the two-parameter generalized
Poisson distribution (GP-1 parameterization)
which has the variance as a linear function
of the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genpoisson1(lmeanpar = "loglink", ldispind = "logloglink",
     parallel = FALSE, zero = "dispind",
     vfl = FALSE, Form2 = NULL,
     imeanpar = NULL, idispind = NULL, imethod = c(1, 1),
     ishrinkage = 0.95, gdispind = exp(1:5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genpoisson1_+3A_lmeanpar">lmeanpar</code>, <code id="genpoisson1_+3A_ldispind">ldispind</code></td>
<td>

<p>Parameter link functions for <code class="reqn">\mu</code>
and <code class="reqn">\varphi</code>.  They are called
the <em>mean</em> <em>par</em>ameter and
<em>disp</em>ersion <em>ind</em>ex respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
In theory the <code class="reqn">\varphi</code> parameter might
be allowed to be less than unity to handle
underdispersion but this is not supported.
The mean is positive so its default is the
log link.  The dispersion index is <code class="reqn">&gt; 1</code>
so its default is the log-log link.
</p>
</td></tr>
<tr><td><code id="genpoisson1_+3A_vfl">vfl</code>, <code id="genpoisson1_+3A_form2">Form2</code></td>
<td>

<p>If <code>vfl = TRUE</code> then <code>Form2</code>
should be assigned a formula having terms
comprising <code class="reqn">\eta_2=\log \log \varphi</code>.
This is similar to <code><a href="#topic+uninormal">uninormal</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="genpoisson1_+3A_imeanpar">imeanpar</code>, <code id="genpoisson1_+3A_idispind">idispind</code></td>
<td>

<p>Optional initial values for <code class="reqn">\mu</code> and
<code class="reqn">\varphi</code>.  The default is to choose
values internally.
</p>
</td></tr>
<tr><td><code id="genpoisson1_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
The argument is recycled to length 2, and
the first value corresponds to <code class="reqn">\mu</code>, etc.
</p>
</td></tr>
<tr><td><code id="genpoisson1_+3A_ishrinkage">ishrinkage</code>, <code id="genpoisson1_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="genpoisson1_+3A_gdispind">gdispind</code>, <code id="genpoisson1_+3A_parallel">parallel</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.  Argument <code>gdispind</code>
is similar to <code>gsigma</code> there and is
currently used only if <code>imethod[2] = 2</code>.
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>This is a variant of the generalized Poisson
distribution (GPD) and is similar to the GP-1
referred to by some writers such as Yang,
et al. (2009).  Compared to the original GP-0
(see <code><a href="#topic+genpoisson0">genpoisson0</a></code>) the GP-1 has
<code class="reqn">\theta  = \mu / \sqrt{\varphi}</code> and
<code class="reqn">\lambda = 1 - 1 / \sqrt{\varphi}</code> so that
the variance is <code class="reqn">\mu \varphi</code>.
The first linear predictor by default is
<code class="reqn">\eta_1 = \log \mu</code> so that
the GP-1 is more suitable for regression than
the GP-1.
</p>
<p>This family function can handle only
overdispersion relative to the Poisson.
An ordinary Poisson distribution corresponds
to <code class="reqn">\varphi = 1</code>.  The mean (returned
as the fitted values) is <code class="reqn">E(Y) = \mu</code>.
For overdispersed data, this GP parameterization
is a direct competitor of the NB-1 and
quasi-Poisson.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object
is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+genpoisson0">genpoisson0</a></code> for warnings
relevant here, e.g., it is a good idea to
monitor convergence because of equidispersion
and underdispersion.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Genpois1">Genpois1</a></code>,
<code><a href="#topic+genpoisson0">genpoisson0</a></code>,
<code><a href="#topic+genpoisson2">genpoisson2</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="stats.html#topic+Poisson">Poisson</a></code>,
<code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 500))
gdata &lt;- transform(gdata, y1 = rgenpois1(nn, exp(2 + x2),
                               logloglink(-1, inverse = TRUE)))
gfit1 &lt;- vglm(y1 ~ x2, genpoisson1, gdata, trace = TRUE)
coef(gfit1, matrix = TRUE)
summary(gfit1)
</code></pre>

<hr>
<h2 id='genpoisson2'> Generalized Poisson Regression
(GP-2 Parameterization) </h2><span id='topic+genpoisson2'></span>

<h3>Description</h3>

<p>Estimation of the two-parameter generalized
Poisson distribution (GP-2 parameterization)
which has the variance as a cubic function
of the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genpoisson2(lmeanpar = "loglink", ldisppar = "loglink",
    parallel = FALSE, zero = "disppar",
    vfl = FALSE, oparallel = FALSE,
    imeanpar = NULL, idisppar = NULL, imethod = c(1, 1),
    ishrinkage = 0.95, gdisppar = exp(1:5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genpoisson2_+3A_lmeanpar">lmeanpar</code>, <code id="genpoisson2_+3A_ldisppar">ldisppar</code></td>
<td>

<p>Parameter link functions for <code class="reqn">\mu</code> and
<code class="reqn">\alpha</code>.  They are called the <em>mean</em>
and <em>disp</em>ersion <em>par</em>ameters
respectively.  See <code><a href="#topic+Links">Links</a></code> for
more choices.  In theory the <code class="reqn">\alpha</code>
parameter might be allowed to be negative
to handle underdispersion but this is not
supported.  All parameters are positive,
therefore the defaults are the log link.
</p>



</td></tr>
<tr><td><code id="genpoisson2_+3A_imeanpar">imeanpar</code>, <code id="genpoisson2_+3A_idisppar">idisppar</code></td>
<td>

<p>Optional initial values for <code class="reqn">\mu</code> and
<code class="reqn">\alpha</code>.  The default is to choose
values internally.
</p>
</td></tr>
<tr><td><code id="genpoisson2_+3A_vfl">vfl</code>, <code id="genpoisson2_+3A_oparallel">oparallel</code></td>
<td>

<p>Argument <code>oparallel</code> is similar to
<code>parallel</code> but uses <code>rbind(1, -1)</code>
instead.  If <code>vfl = TRUE</code> then
<code>oparallel</code> should be assigned
a formula having terms comprising
<code class="reqn">\eta_1=\log \mu</code>, and then
the other terms in the main formula
are for <code class="reqn">\eta_2=\log \alpha</code> .
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="genpoisson2_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.  The argument is recycled
to length 2, and the first value corresponds
to <code class="reqn">\mu</code>, etc.
</p>
</td></tr>
<tr><td><code id="genpoisson2_+3A_ishrinkage">ishrinkage</code>, <code id="genpoisson2_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="genpoisson2_+3A_gdisppar">gdisppar</code>, <code id="genpoisson2_+3A_parallel">parallel</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.  Argument <code>gdisppar</code>
is similar to <code>gsigma</code> there and is
currently used only if <code>imethod[2] = 2</code>.
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>This is a variant of the generalized
Poisson distribution (GPD) and called
GP-2 by some writers such as Yang, et
al. (2009).  Compared to the original GP-0
(see <code><a href="#topic+genpoisson0">genpoisson0</a></code>) the GP-2 has
<code class="reqn">\theta  = \mu / (1 + \alpha \mu)</code> and
<code class="reqn">\lambda = \alpha \mu / (1 + \alpha \mu)</code>
so that the variance is <code class="reqn">\mu (1 +
  \alpha \mu)^2</code>.  The first linear predictor
by default is <code class="reqn">\eta_1 = \log \mu</code> so that the GP-2 is more suitable
for regression than the GP-0.
</p>
<p>This family function can handle only
overdispersion relative to the Poisson.
An ordinary Poisson distribution corresponds
to <code class="reqn">\alpha = 0</code>.  The mean (returned as
the fitted values) is <code class="reqn">E(Y) = \mu</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object
is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+genpoisson0">genpoisson0</a></code> for warnings
relevant here, e.g., it is a   good idea to
monitor convergence because of equidispersion
and underdispersion.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.
</p>


<h3>References</h3>

<p>Letac, G. and Mora, M. (1990).
Natural real exponential familes with cubic variance functions.
<em>Annals of Statistics</em>
<b>18</b>, 1&ndash;37.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Genpois2">Genpois2</a></code>,
<code><a href="#topic+genpoisson0">genpoisson0</a></code>,
<code><a href="#topic+genpoisson1">genpoisson1</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="stats.html#topic+Poisson">Poisson</a></code>,
<code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 500))
gdata &lt;- transform(gdata, y1 = rgenpois2(nn, exp(2 + x2),
                               loglink(-1, inverse = TRUE)))
gfit2 &lt;- vglm(y1 ~ x2, genpoisson2, gdata, trace = TRUE)
coef(gfit2, matrix = TRUE)
summary(gfit2)
</code></pre>

<hr>
<h2 id='genray'>The Generalized Rayleigh Distribution</h2><span id='topic+genray'></span><span id='topic+dgenray'></span><span id='topic+pgenray'></span><span id='topic+qgenray'></span><span id='topic+rgenray'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the generalized Rayleigh distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgenray(x, scale = 1, shape, log = FALSE)
pgenray(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qgenray(p, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
rgenray(n, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genray_+3A_x">x</code>, <code id="genray_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="genray_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="genray_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the number required. </p>
</td></tr>
<tr><td><code id="genray_+3A_scale">scale</code>, <code id="genray_+3A_shape">shape</code></td>
<td>

<p>positive scale and shape parameters. </p>
</td></tr>
<tr><td><code id="genray_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="genray_+3A_lower.tail">lower.tail</code>, <code id="genray_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+genrayleigh">genrayleigh</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters, 
for the formula of the probability density function and other details.
</p>


<h3>Value</h3>

<p><code>dgenray</code> gives the density,
<code>pgenray</code> gives the distribution function,
<code>qgenray</code> gives the quantile function, and
<code>rgenray</code> generates random deviates.
</p>


<h3>Note</h3>

<p>We define <code>scale</code> as the reciprocal of the scale parameter
used by Kundu and Raqab (2005).
</p>


<h3>Author(s)</h3>

<p> Kai Huang and J. G. Lauder and T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+genrayleigh">genrayleigh</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape &lt;- 0.5; Scale &lt;- 1; nn &lt;- 501
x &lt;- seq(-0.10, 3.0, len = nn)
plot(x, dgenray(x, shape, scale = Scale), type = "l", las = 1, ylim = c(0, 1.2),
     ylab = paste("[dp]genray(shape = ", shape, ", scale = ", Scale, ")"),
     col = "blue", cex.main = 0.8,
     main = "Blue is density, orange is cumulative distribution function",
     sub = "Purple lines are the 10,20,...,90 percentiles")
lines(x, pgenray(x, shape, scale = Scale), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qgenray(probs, shape, scale = Scale)
lines(Q, dgenray(Q, shape, scale = Scale), col = "purple", lty = 3, type = "h")
lines(Q, pgenray(Q, shape, scale = Scale), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(pgenray(Q, shape, scale = Scale) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='genrayleigh'>Generalized Rayleigh Distribution Family Function</h2><span id='topic+genrayleigh'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the generalized Rayleigh distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genrayleigh(lscale = "loglink", lshape = "loglink",
            iscale = NULL,   ishape = NULL,
            tol12 = 1e-05, nsimEIM = 300, zero = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genrayleigh_+3A_lscale">lscale</code>, <code id="genrayleigh_+3A_lshape">lshape</code></td>
<td>

<p>Link function for the two positive parameters, scale and shape.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="genrayleigh_+3A_iscale">iscale</code>, <code id="genrayleigh_+3A_ishape">ishape</code></td>
<td>

<p>Numeric.
Optional initial values for the scale and shape parameters.
</p>
</td></tr>
<tr><td><code id="genrayleigh_+3A_nsimeim">nsimEIM</code>, <code id="genrayleigh_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="genrayleigh_+3A_tol12">tol12</code></td>
<td>

<p>Numeric and positive. Tolerance for testing whether the
second shape parameter is either 1 or 2. If so then the
working weights need to handle these singularities.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized Rayleigh distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;b = scale,s = shape)  =
  (2 s y/b^{2}) e^{-(y/b)^{2}} (1 - e^{-(y/b)^{2}})^{s-1}</code>
</p>

<p>where <code class="reqn">y &gt; 0</code> and the two parameters,
<code class="reqn">b</code> and <code class="reqn">s</code>, are positive.
The mean cannot be expressed nicely so the median is returned as 
the fitted values.
Applications of the generalized Rayleigh distribution include modeling
strength data and general lifetime data.
Simulated Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>We define <code>scale</code> as the reciprocal of the scale parameter 
used by Kundu and Raqab (2005).
</p>


<h3>Author(s)</h3>

<p> J. G. Lauder and T. W. Yee </p>


<h3>References</h3>

<p>Kundu, D., Raqab, M. C. (2005).
Generalized Rayleigh distribution: different methods of estimations.
<em>Computational Statistics and Data Analysis</em>,
<b>49</b>, 187&ndash;200.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+dgenray">dgenray</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Scale &lt;- exp(1); shape &lt;- exp(1)
rdata &lt;- data.frame(y = rgenray(n = 1000, scale = Scale, shape = shape))
fit &lt;- vglm(y ~ 1, genrayleigh, data = rdata, trace = TRUE)
c(with(rdata, mean(y)), head(fitted(fit), 1))
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='gensh'> Generalized Secant Hyperbolic Regression
Family Function </h2><span id='topic+gensh'></span>

<h3>Description</h3>

<p>Estimation of the parameters of the
generalized secant hyperbolic
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensh(shape, llocation = "identitylink",
      lscale = "loglink", zero = "scale",
      ilocation = NULL, iscale = NULL, imethod = 1,
      glocation.mux = exp((-4:4)/2),
      gscale.mux = exp((-4:4)/2),
      probs.y = 0.3, tol0 = 1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensh_+3A_shape">shape</code></td>
<td>
<p>Numeric of length 1.
Shape parameter, called <code class="reqn">t</code> in
Vaughan (2002).
Valid values are
<code class="reqn">-\pi/2 &lt; t</code>.
</p>
</td></tr>
<tr><td><code id="gensh_+3A_llocation">llocation</code>, <code id="gensh_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
two parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for more information.
</p>
</td></tr>
<tr><td><code id="gensh_+3A_zero">zero</code>, <code id="gensh_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="gensh_+3A_ilocation">ilocation</code>, <code id="gensh_+3A_iscale">iscale</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="gensh_+3A_glocation.mux">glocation.mux</code>, <code id="gensh_+3A_gscale.mux">gscale.mux</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
<tr><td><code id="gensh_+3A_probs.y">probs.y</code>, <code id="gensh_+3A_tol0">tol0</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function of the
hyperbolic secant distribution
is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y; a, b, s) =
[(c_1 / b) \; \exp(c_2 z)] / [
\exp(2 c_2 z) + 2 C_3 \exp(c_2 z) + 1]</code>
</p>

<p>for shape
parameter <code class="reqn">-\pi &lt; s</code>
and all real <code class="reqn">y</code>.
The scalars <code class="reqn">c_1</code>, <code class="reqn">c_2</code>,
<code class="reqn">C_3</code> are functions of <code class="reqn">s</code>.
The mean of <code class="reqn">Y</code> is
the location parameter <code class="reqn">a</code>
(returned as the fitted values).
All moments of the distribution are finite.
</p>
<p>Further details about
the parameterization can be found
in Vaughan (2002).
Fisher scoring is implemented and it has
a diagonal EIM.
More details are at
<code><a href="#topic+Gensh">Gensh</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Vaughan, D. C. (2002).
The generalized secant hyperbolic
distribution and its properties.
<em>Communications in Statistics&mdash;Theory
and Methods</em>,
<b>31</b>(2): 219&ndash;238.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hypersecant">hypersecant</a></code>,
<code><a href="#topic+logistic">logistic</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>sh &lt;- -pi / 2; loc &lt;- 2
hdata &lt;- data.frame(x2 = rnorm(nn &lt;- 200))
hdata &lt;- transform(hdata, y = rgensh(nn, sh, loc))
fit &lt;- vglm(y ~ x2, gensh(sh), hdata, trace = TRUE)
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='Gensh'> Generalized Secant Hyperbolic
Distribution
</h2><span id='topic+Gensh'></span><span id='topic+dgensh'></span><span id='topic+pgensh'></span><span id='topic+qgensh'></span><span id='topic+rgensh'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function
and random generation
for the generalized secant hyperbolic
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgensh(x, shape, location = 0, scale = 1, tol0 = 1e-4,
       log = FALSE)
pgensh(q, shape, location = 0, scale = 1, tol0 = 1e-4,
       lower.tail = TRUE)
qgensh(p, shape, location = 0, scale = 1, tol0 = 1e-4)
rgensh(n, shape, location = 0, scale = 1, tol0 = 1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gensh_+3A_x">x</code>, <code id="Gensh_+3A_q">q</code>, <code id="Gensh_+3A_p">p</code>, <code id="Gensh_+3A_n">n</code>, <code id="Gensh_+3A_log">log</code>, <code id="Gensh_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Similar meaning as in <code><a href="stats.html#topic+Normal">Normal</a></code>.
</p>
</td></tr>
<tr><td><code id="Gensh_+3A_shape">shape</code></td>
<td>
<p>Numeric.
Shape parameter, called <code class="reqn">t</code> in
Vaughan (2002).
Valid values are
<code class="reqn">-\pi/2 &lt; t</code>.
</p>
</td></tr>
<tr><td><code id="Gensh_+3A_location">location</code>, <code id="Gensh_+3A_scale">scale</code></td>
<td>
<p>Numeric.
The location and (positive) scale
parameters.
</p>
</td></tr>
<tr><td><code id="Gensh_+3A_tol0">tol0</code></td>
<td>
<p>Numeric.
Used to test whether the shape parameter
is close enough to be treated as 0.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an implementation of the family of
symmetric densities described
by Vaughan (2002).
By default, the mean and variance are 0
and 1, for all <code class="reqn">t</code>.
Some special (default) cases are:
<code class="reqn">t=0</code>: logistic
(which is similar to
<code><a href="stats.html#topic+TDist">stats:dt</a></code>
with 9 degrees of freedom);
<code class="reqn">t=-\pi/2</code>: the standard secant
hyperbolic (whence the name);
<code class="reqn">t=\infty</code>:
uniform(-sqrt(3), sqrt(3)).
</p>


<h3>Value</h3>

<p><code>dgensh</code> gives the density,
<code>pgensh</code> gives the distribution function,
<code>qgensh</code> gives the quantile function, and
<code>rgensh</code> generates random deviates.
</p>


<h3>Warning </h3>

<p>Numerical problems may occur when some
argument values are extreme.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+gensh">gensh</a></code>,
<code><a href="#topic+logistic">logistic</a></code>,
<code><a href="#topic+hypersecant">hypersecant</a></code>,
<code><a href="stats.html#topic+Logistic">Logistic</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-2, 4, by = 0.01)
loc &lt;- 1; shape &lt;- -pi /2
## Not run: plot(x, dgensh(x, shape, loc), type = "l",
     main = "Blue is density, orange is the CDF",
     ylim = 0:1, las = 1, ylab = "", 
     sub = "Purple are 5, 10, ..., 95 percentiles",
     col = "blue")
abline(h = 0, col = "blue", lty = 2)
lines(qgensh((1:19) / 20, shape, loc), type = "h",
      dgensh(qgensh((1:19) / 20, shape, loc),
             shape, loc), col = "purple", lty = 3)
lines(x, pgensh(x, shape, loc), col = "orange")
abline(h = 0, lty = 2) 
## End(Not run)

pp &lt;- (1:19) / 20  # Test two functions
max(abs(pgensh(qgensh(pp, shape, loc),
               shape,loc) - pp))  # Should be 0
</code></pre>

<hr>
<h2 id='geometric'> Geometric (Truncated and Untruncated) Distributions </h2><span id='topic+geometric'></span><span id='topic+truncgeometric'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation for the geometric
and truncated geometric distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geometric(link = "logitlink", expected = TRUE, imethod = 1,
          iprob = NULL, zero = NULL)
truncgeometric(upper.limit = Inf,
               link = "logitlink", expected = TRUE, imethod = 1,
               iprob = NULL, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geometric_+3A_link">link</code></td>
<td>

<p>Parameter link function applied to the
probability parameter <code class="reqn">p</code>, which lies in the unit interval.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="geometric_+3A_expected">expected</code></td>
<td>

<p>Logical.
Fisher scoring is used if <code>expected = TRUE</code>, else Newton-Raphson.
</p>
</td></tr>
<tr><td><code id="geometric_+3A_iprob">iprob</code>, <code id="geometric_+3A_imethod">imethod</code>, <code id="geometric_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
<tr><td><code id="geometric_+3A_upper.limit">upper.limit</code></td>
<td>

<p>Numeric.
Upper values.
As a vector, it is recycled across responses first.
The default value means both family functions should give the same result.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A random variable <code class="reqn">Y</code> has a 1-parameter geometric distribution
if <code class="reqn">P(Y=y) = p (1-p)^y</code>
for <code class="reqn">y=0,1,2,\ldots</code>.
Here, <code class="reqn">p</code> is the probability of success,
and <code class="reqn">Y</code> is the number of (independent) trials that are fails
until a success occurs.
Thus the response <code class="reqn">Y</code> should be a non-negative integer.
The mean of <code class="reqn">Y</code> is <code class="reqn">E(Y) = (1-p)/p</code>
and its variance is <code class="reqn">Var(Y) = (1-p)/p^2</code>.
The geometric distribution is a special case of the
negative binomial distribution (see <code><a href="#topic+negbinomial">negbinomial</a></code>).
The geometric distribution is also a special case of the
Borel distribution, which is a Lagrangian distribution.
If <code class="reqn">Y</code> has a geometric distribution with parameter <code class="reqn">p</code> then
<code class="reqn">Y+1</code> has a positive-geometric distribution with the same parameter.
Multiple responses are permitted.
</p>
<p>For <code>truncgeometric()</code>,
the (upper) truncated geometric distribution can have response integer
values from 0 to <code>upper.limit</code>.
It has density <code>prob * (1 - prob)^y / [1-(1-prob)^(1+upper.limit)]</code>.
</p>
<p>For a generalized truncated geometric distribution with
integer values <code class="reqn">L</code> to <code class="reqn">U</code>, say, subtract <code class="reqn">L</code>
from the response and feed in <code class="reqn">U-L</code> as the upper limit.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
Help from Viet Hoang Quoc is gratefully acknowledged.
</p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="stats.html#topic+Geometric">Geometric</a></code>,
<code><a href="#topic+betageometric">betageometric</a></code>,
<code><a href="#topic+expgeometric">expgeometric</a></code>,
<code><a href="#topic+zageometric">zageometric</a></code>,
<code><a href="#topic+zigeometric">zigeometric</a></code>,
<code><a href="#topic+rbetageom">rbetageom</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000) - 0.5)
gdata &lt;- transform(gdata, x3 = runif(nn) - 0.5,
                          x4 = runif(nn) - 0.5)
gdata &lt;- transform(gdata, eta  = -1.0 - 1.0 * x2 + 2.0 * x3)
gdata &lt;- transform(gdata, prob = logitlink(eta, inverse = TRUE))
gdata &lt;- transform(gdata, y1 = rgeom(nn, prob))
with(gdata, table(y1))
fit1 &lt;- vglm(y1 ~ x2 + x3 + x4, geometric, data = gdata, trace = TRUE)
coef(fit1, matrix = TRUE)
summary(fit1)

# Truncated geometric (between 0 and upper.limit)
upper.limit &lt;- 5
tdata &lt;- subset(gdata, y1 &lt;= upper.limit)
nrow(tdata)  # Less than nn
fit2 &lt;- vglm(y1 ~ x2 + x3 + x4, truncgeometric(upper.limit),
             data = tdata, trace = TRUE)
coef(fit2, matrix = TRUE)

# Generalized truncated geometric (between lower.limit and upper.limit)
lower.limit &lt;- 1
upper.limit &lt;- 8
gtdata &lt;- subset(gdata, lower.limit &lt;= y1 &amp; y1 &lt;= upper.limit)
with(gtdata, table(y1))
nrow(gtdata)  # Less than nn
fit3 &lt;- vglm(y1 - lower.limit ~ x2 + x3 + x4,
             truncgeometric(upper.limit - lower.limit),
             data = gtdata, trace = TRUE)
coef(fit3, matrix = TRUE)
</code></pre>

<hr>
<h2 id='get.smart'> Retrieve One Component of &ldquo;.smart.prediction&rdquo; </h2><span id='topic+get.smart'></span>

<h3>Description</h3>

<p>Retrieve one component of the list <code>.smart.prediction</code> from
<code>smartpredenv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.smart()
</code></pre>


<h3>Details</h3>

<p><code>get.smart</code> is used in <code>"read"</code> mode within a smart function:
it retrieves parameters saved at the time of fitting, and
is used for prediction.
<code>get.smart</code> is only used in smart functions such as 
<code><a href="#topic+sm.poly">sm.poly</a></code>;
<code>get.smart.prediction</code> is only used in modelling functions
such as <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>.
The function
<code><a href="#topic+get.smart">get.smart</a></code> gets only a part of <code>.smart.prediction</code> whereas
<code><a href="#topic+get.smart.prediction">get.smart.prediction</a></code> gets the entire <code>.smart.prediction</code>.
</p>


<h3>Value</h3>

<p>Returns with one list component of <code>.smart.prediction</code> from
<code>smartpredenv</code>,
in fact, <code>.smart.prediction[[.smart.prediction.counter]]</code>.
The whole procedure mimics a first-in first-out stack (better known
as a <em>queue</em>).
</p>


<h3>Side Effects</h3>

<p>The variable <code>.smart.prediction.counter</code> in
<code>smartpredenv</code>
is incremented beforehand, and then written back to
<code>smartpredenv</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.smart.prediction">get.smart.prediction</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(sm.min1)
</code></pre>

<hr>
<h2 id='get.smart.prediction'> Retrieves &ldquo;.smart.prediction&rdquo; </h2><span id='topic+get.smart.prediction'></span>

<h3>Description</h3>

<p>Retrieves <code>.smart.prediction</code> from
<code>smartpredenv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.smart.prediction()
</code></pre>


<h3>Details</h3>

<p>A smart modelling function such as <code><a href="stats.html#topic+lm">lm</a></code> allows
smart functions such as <code><a href="#topic+sm.bs">sm.bs</a></code>
to write to
a data structure called <code>.smart.prediction</code> in
<code>smartpredenv</code>.
At the end of fitting,
<code>get.smart.prediction</code> retrieves this data structure.
It is then attached to the object, and used for prediction later.
</p>


<h3>Value</h3>

<p>Returns with the list <code>.smart.prediction</code> from
<code>smartpredenv</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.smart">get.smart</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fit$smart &lt;- get.smart.prediction()  # Put at the end of lm()

## End(Not run)
</code></pre>

<hr>
<h2 id='gev'> Generalized Extreme Value Regression Family Function </h2><span id='topic+gev'></span><span id='topic+gevff'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the
3-parameter generalized extreme value (GEV) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev(llocation = "identitylink", lscale = "loglink",
    lshape = logofflink(offset = 0.5), percentiles = c(95, 99),
    ilocation = NULL, iscale = NULL, ishape = NULL, imethod = 1,
    gprobs.y = (1:9)/10, gscale.mux = exp((-5:5)/6),
    gshape = (-5:5) / 11 + 0.01,
    iprobs.y = NULL, tolshape0 = 0.001,
    type.fitted = c("percentiles", "mean"),
    zero = c("scale", "shape"))
gevff(llocation = "identitylink", lscale = "loglink",
    lshape = logofflink(offset = 0.5), percentiles = c(95, 99),
    ilocation = NULL, iscale = NULL, ishape = NULL, imethod = 1,
    gprobs.y = (1:9)/10, gscale.mux = exp((-5:5)/6),
    gshape = (-5:5) / 11 + 0.01,
    iprobs.y = NULL, tolshape0 = 0.001,
    type.fitted = c("percentiles", "mean"), zero = c("scale", "shape"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gev_+3A_llocation">llocation</code>, <code id="gev_+3A_lscale">lscale</code>, <code id="gev_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions for <code class="reqn">\mu</code>, <code class="reqn">\sigma</code> and
<code class="reqn">\xi</code> respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
<p>For the shape parameter,
the default <code><a href="#topic+logofflink">logofflink</a></code> link has an offset
called <code class="reqn">A</code> below; and then the linear/additive predictor is
<code class="reqn">\log(\xi+A)</code> which means that
<code class="reqn">\xi &gt; -A</code>.
For technical reasons (see <b>Details</b>) it is a good idea
for <code class="reqn">A = 0.5</code>.
</p>
</td></tr>










<tr><td><code id="gev_+3A_percentiles">percentiles</code></td>
<td>

<p>Numeric vector of percentiles used for the fitted values.
Values should be between 0 and 100.
This argument is ignored if <code>type.fitted = "mean"</code>.
</p>




</td></tr>
<tr><td><code id="gev_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
The default is to use the <code>percentiles</code> argument.
If <code>"mean"</code> is chosen, then the mean
<code class="reqn">\mu + \sigma (\Gamma(1-\xi)-1) / \xi</code>
is returned as the fitted values,
and these are only defined for <code class="reqn">\xi&lt;1</code>.
</p>
</td></tr>
<tr><td><code id="gev_+3A_ilocation">ilocation</code>, <code id="gev_+3A_iscale">iscale</code>, <code id="gev_+3A_ishape">ishape</code></td>
<td>

<p>Numeric. Initial value for the location parameter, <code class="reqn">\sigma</code> and
<code class="reqn">\xi</code>. A <code>NULL</code> means a value is computed internally.
The argument <code>ishape</code> is more important than the other two.
If a failure to converge occurs, or even to obtain initial values occurs,
try assigning <code>ishape</code> some value
(positive or negative; the sign can be very important).
Also, in general, a larger value of <code>iscale</code> tends to be better than a
smaller value.
</p>

</td></tr>











<tr><td><code id="gev_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method. Either the value 1 or 2.
If both methods fail then try using <code>ishape</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>



</td></tr>
<tr><td><code id="gev_+3A_gshape">gshape</code></td>
<td>

<p>Numeric vector.
The values are used for a grid search for an initial value
for <code class="reqn">\xi</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>

</td></tr>
<tr><td><code id="gev_+3A_gprobs.y">gprobs.y</code>, <code id="gev_+3A_gscale.mux">gscale.mux</code>, <code id="gev_+3A_iprobs.y">iprobs.y</code></td>
<td>

<p>Numeric vectors, used for the initial values.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="gev_+3A_tolshape0">tolshape0</code></td>
<td>

<p>Passed into <code><a href="#topic+dgev">dgev</a></code> when computing the log-likelihood.
</p>
</td></tr>
<tr><td><code id="gev_+3A_zero">zero</code></td>
<td>

<p>A specifying which
linear/additive predictors are modelled as intercepts only.
The values can be from the set {1,2,3} corresponding
respectively to <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>.
If <code>zero = NULL</code> then all linear/additive predictors are modelled as
a linear combination of the explanatory variables.
For many data sets having <code>zero = 3</code> is a good idea.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GEV distribution function can be written
</p>
<p style="text-align: center;"><code class="reqn">G(y) = \exp( -[ (y-\mu)/ \sigma  ]_{+}^{- 1/ \xi}) </code>
</p>

<p>where <code class="reqn">\sigma &gt; 0</code>,
<code class="reqn">-\infty &lt; \mu &lt; \infty</code>,
and <code class="reqn">1 + \xi(y-\mu)/\sigma &gt; 0</code>.
Here, <code class="reqn">x_+ = \max(x,0)</code>.
The <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code> are known as the
<em>location</em>, <em>scale</em> and <em>shape</em> parameters respectively.
The cases
<code class="reqn">\xi&gt;0</code>,
<code class="reqn">\xi&lt;0</code>,
<code class="reqn">\xi = 0</code>
correspond to the Frechet,
reverse
Weibull, and Gumbel types respectively.
It can be noted that the Gumbel (or Type I) distribution accommodates
many commonly-used distributions such as the normal, lognormal,
logistic, gamma, exponential and Weibull.
</p>
<p>For the GEV distribution, the <code class="reqn">k</code>th moment about the mean exists
if <code class="reqn">\xi &lt; 1/k</code>.
Provided they exist, the mean and variance are given by
<code class="reqn">\mu+\sigma\{ \Gamma(1-\xi)-1\}/ \xi</code>
and
<code class="reqn">\sigma^2 \{ \Gamma(1-2\xi) - \Gamma^2(1-\xi) \} / \xi^2</code>
respectively,
where <code class="reqn">\Gamma</code> is the gamma function.
</p>
<p>Smith (1985) established that when <code class="reqn">\xi &gt; -0.5</code>,
the maximum likelihood estimators are completely regular.
To have some control over the estimated <code class="reqn">\xi</code> try
using <code>lshape = logofflink(offset = 0.5)</code>, say,
or <code>lshape = extlogitlink(min = -0.5, max = 0.5)</code>, say.
</p>






<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Currently, if an estimate of <code class="reqn">\xi</code> is too close to 0 then
an error may occur for <code>gev()</code> with multivariate responses.
In general, <code>gevff()</code> is more reliable than <code>gev()</code>.
</p>
<p>Fitting the GEV by maximum likelihood estimation can be numerically
fraught. If <code class="reqn">1 + \xi (y-\mu)/ \sigma \leq 0</code> then some crude evasive action is taken but the estimation process
can still fail. This is particularly the case if <code><a href="#topic+vgam">vgam</a></code>
with <code><a href="#topic+s">s</a></code> is used; then smoothing is best done with
<code><a href="#topic+vglm">vglm</a></code> with regression splines (<code><a href="splines.html#topic+bs">bs</a></code>
or <code><a href="splines.html#topic+ns">ns</a></code>) because <code><a href="#topic+vglm">vglm</a></code> implements
half-stepsizing whereas <code><a href="#topic+vgam">vgam</a></code> doesn't (half-stepsizing
helps handle the problem of straying outside the parameter space.)
</p>


<h3>Note</h3>

<p>The <span class="pkg">VGAM</span> family function <code>gev</code> can handle a multivariate
(matrix) response, cf. multiple responses.
If so, each row of the matrix is sorted into
descending order and <code>NA</code>s are put last.
With a vector or one-column matrix response using
<code>gevff</code> will give the same result but be faster and it handles
the <code class="reqn">\xi = 0</code> case.
The function <code>gev</code> implements Tawn (1988) while
<code>gevff</code> implements Prescott and Walden (1980).
</p>
<p>Function <code>egev()</code> has been replaced by the
new family function <code>gevff()</code>. It now
conforms to the usual <span class="pkg">VGAM</span> philosophy of
having <code>M1</code> linear predictors per (independent) response.
This is the usual way multiple responses are handled.
Hence <code>vglm(cbind(y1, y2)..., gevff, ...)</code> will have
6 linear predictors and it is possible to constrain the
linear predictors so that the answer is similar to <code>gev()</code>.
Missing values in the response of <code>gevff()</code> will be deleted;
this behaviour is the same as with almost every other
<span class="pkg">VGAM</span> family function.
</p>
<p>The shape parameter <code class="reqn">\xi</code> is difficult to estimate
accurately unless there is a lot of data.
Convergence is slow when <code class="reqn">\xi</code> is near <code class="reqn">-0.5</code>.
Given many explanatory variables, it is often a good idea
to make sure <code>zero = 3</code>.
The range restrictions of the parameter <code class="reqn">\xi</code> are not
enforced; thus it is possible for a violation to occur.
</p>
<p>Successful convergence often depends on having a reasonably good initial
value for <code class="reqn">\xi</code>. If failure occurs try various values for the
argument <code>ishape</code>, and if there are covariates,
having <code>zero = 3</code> is advised.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Stephenson, A. G. (2007).
Vector generalized linear and additive extreme value models.
<em>Extremes</em>, <b>10</b>, 1&ndash;19.
</p>
<p>Tawn, J. A. (1988).
An extreme-value theory model for dependent observations.
<em>Journal of Hydrology</em>, <b>101</b>, 227&ndash;250.
</p>
<p>Prescott, P. and Walden, A. T. (1980).
Maximum likelihood estimation of the parameters of the
generalized extreme-value distribution.
<em>Biometrika</em>, <b>67</b>, 723&ndash;724.
</p>
<p>Smith, R. L. (1985).
Maximum likelihood estimation in a class of nonregular cases.
<em>Biometrika</em>, <b>72</b>, 67&ndash;90.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rgev">rgev</a></code>,
<code><a href="#topic+gumbel">gumbel</a></code>,
<code><a href="#topic+gumbelff">gumbelff</a></code>,
<code><a href="#topic+guplot">guplot</a></code>,
<code><a href="#topic+rlplot.gevff">rlplot.gevff</a></code>,
<code><a href="#topic+gpd">gpd</a></code>,
<code><a href="#topic+weibullR">weibullR</a></code>,
<code><a href="#topic+frechet">frechet</a></code>,
<code><a href="#topic+extlogitlink">extlogitlink</a></code>,
<code><a href="#topic+oxtemp">oxtemp</a></code>,
<code><a href="#topic+venice">venice</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Multivariate example
fit1 &lt;- vgam(cbind(r1, r2) ~ s(year, df = 3), gev(zero = 2:3),
             data = venice, trace = TRUE)
coef(fit1, matrix = TRUE)
head(fitted(fit1))
par(mfrow = c(1, 2), las = 1)
plot(fit1, se = TRUE, lcol = "blue", scol = "forestgreen",
     main = "Fitted mu(year) function (centered)", cex.main = 0.8)
with(venice, matplot(year, depvar(fit1)[, 1:2], ylab = "Sea level (cm)",
     col = 1:2, main = "Highest 2 annual sea levels", cex.main = 0.8))
with(venice, lines(year, fitted(fit1)[,1], lty = "dashed", col = "blue"))
legend("topleft", lty = "dashed", col = "blue", "Fitted 95 percentile")

# Univariate example
(fit &lt;- vglm(maxtemp ~ 1, gevff, data = oxtemp, trace = TRUE))
head(fitted(fit))
coef(fit, matrix = TRUE)
Coef(fit)
vcov(fit)
vcov(fit, untransform = TRUE)
sqrt(diag(vcov(fit)))  # Approximate standard errors
rlplot(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='gevUC'>The Generalized Extreme Value Distribution </h2><span id='topic+gevUC'></span><span id='topic+dgev'></span><span id='topic+pgev'></span><span id='topic+qgev'></span><span id='topic+rgev'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the generalized extreme value distribution
(GEV) with location parameter <code>location</code>, scale parameter
<code>scale</code> and shape parameter <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgev(x, location = 0, scale = 1, shape = 0, log = FALSE,
     tolshape0 = sqrt(.Machine$double.eps))
pgev(q, location = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)
qgev(p, location = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)
rgev(n, location = 0, scale = 1, shape = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevUC_+3A_x">x</code>, <code id="gevUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="gevUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="gevUC_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required. </p>
</td></tr>
<tr><td><code id="gevUC_+3A_location">location</code></td>
<td>
<p>the location parameter <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="gevUC_+3A_scale">scale</code></td>
<td>
<p>the (positive) scale parameter <code class="reqn">\sigma</code>.
Must consist of positive values. </p>
</td></tr>
<tr><td><code id="gevUC_+3A_shape">shape</code></td>
<td>
<p>the shape parameter <code class="reqn">\xi</code>.</p>
</td></tr>
<tr><td><code id="gevUC_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="gevUC_+3A_lower.tail">lower.tail</code>, <code id="gevUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Uniform">punif</a></code>
or <code><a href="stats.html#topic+Uniform">qunif</a></code>.
</p>
</td></tr>
<tr><td><code id="gevUC_+3A_tolshape0">tolshape0</code></td>
<td>

<p>Positive numeric.
Threshold/tolerance value for resting whether <code class="reqn">\xi</code>
is zero.  If the absolute value of the estimate of <code class="reqn">\xi</code>
is less than this value then it will be assumed zero and a
Gumbel distribution will be used.
</p>
</td></tr>














</table>


<h3>Details</h3>

<p>See <code><a href="#topic+gev">gev</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the 3 parameters by maximum likelihood estimation,
for formulae and other details.
Apart from <code>n</code>, all the above arguments may be vectors and
are recyled to the appropriate length if necessary.
</p>


<h3>Value</h3>

<p><code>dgev</code> gives the density,
<code>pgev</code> gives the distribution function,
<code>qgev</code> gives the quantile function, and
<code>rgev</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The default value of <code class="reqn">\xi = 0</code> means the default
distribution is the Gumbel.
</p>
<p>Currently, these functions have different argument names compared
with those in the <span class="pkg">evd</span> package.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+gevff">gevff</a></code>,
<code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> loc &lt;- 2; sigma &lt;- 1; xi &lt;- -0.4
pgev(qgev(seq(0.05, 0.95, by = 0.05), loc, sigma, xi), loc, sigma, xi)
## Not run:  x &lt;- seq(loc - 3, loc + 3, by = 0.01)
plot(x, dgev(x, loc, sigma, xi), type = "l", col = "blue", ylim = c(0, 1),
     main = "Blue is density, orange is the CDF",
     sub = "Purple are 10,...,90 percentiles", ylab = "", las = 1)
abline(h = 0, col = "blue", lty = 2)
lines(qgev(seq(0.1, 0.9, by = 0.1), loc, sigma, xi),
      dgev(qgev(seq(0.1, 0.9, by = 0.1), loc, sigma, xi), loc, sigma, xi),
      col = "purple", lty = 3, type = "h")
lines(x, pgev(x, loc, sigma, xi), type = "l", col = "orange")
abline(h = (0:10)/10, lty = 2, col = "gray50")

## End(Not run)
</code></pre>

<hr>
<h2 id='gew'> General Electric and Westinghouse Data </h2><span id='topic+gew'></span>

<h3>Description</h3>

<p>General Electric and Westinghouse capital data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gew)</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 7 variables.
All variables are numeric vectors.
Variables ending in <code>.g</code> correspond to General Electric and
those ending in <code>.w</code> are Westinghouse.
</p>

<dl>
<dt>year</dt><dd><p>The observations are the years from 1934 to 1953</p>
</dd>
<dt>invest.g, invest.w</dt><dd><p>investment figures.
These are <code class="reqn">I=</code> Gross investment =
additions to plant and equipment plus maintenance and repairs
in millions of dollars deflated by <code class="reqn">P_1</code>.
</p>
</dd>
<dt>capital.g, capital.w</dt><dd><p>capital stocks.
These are <code class="reqn">C=</code> The stock of plant and equipment =
accumulated sum of net additions to plant and equipment deflated
by <code class="reqn">P_1</code> minus depreciation allowance deflated by <code class="reqn">P_3</code>.
</p>
</dd>
<dt>value.g, value.w</dt><dd><p>market values.
These are <code class="reqn">F=</code> Value of the firm =
price of common and preferred shares at December 31
(or average price of December 31 and January 31 of the following year)
times number of common and preferred shares outstanding plus
total book value of debt at December 31 in millions of
dollars deflated by <code class="reqn">P_2</code>.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>These data are a subset of a table in Boot and de Wit (1960),
also known as the Grunfeld data.
It is used a lot in econometrics,
e.g., for seemingly unrelated regressions
(see <code><a href="#topic+SURff">SURff</a></code>).
</p>
<p>Here,
<code class="reqn">P_1 =</code> Implicit price deflator of producers durable
equipment (base 1947),
<code class="reqn">P_2 =</code> Implicit price deflator of G.N.P.
(base 1947),
<code class="reqn">P_3 =</code> Depreciation expense deflator = ten years
moving average of wholesale price index of metals and metal
products (base 1947).
</p>


<h3>Source</h3>

<p>Table 10 of:
Boot, J. C. G. and de Wit, G. M. (1960)
Investment Demand: An Empirical Contribution to the Aggregation Problem.
<em>International Economic Review</em>,
<b>1</b>, 3&ndash;30.
</p>
<p>Grunfeld, Y. (1958)
The Determinants of Corporate Investment.
Unpublished PhD Thesis (Chicago).
</p>


<h3>References</h3>

<p>Zellner, A. (1962).
An efficient method of estimating seemingly unrelated regressions
and tests for aggregation bias.
<em>Journal of the American Statistical Association</em>,
<b>57</b>, 348&ndash;368.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SURff">SURff</a></code>,
<code>http://statmath.wu.ac.at/~zeileis/grunfeld</code>
(the link might now be stale).
</p>



<h3>Examples</h3>

<pre><code class='language-R'>str(gew)
</code></pre>

<hr>
<h2 id='goffset'>
GAITD Offset for the GTE Method
</h2><span id='topic+goffset'></span>

<h3>Description</h3>

<p>Utility function to create a matrix of log-offset values,
to help facilitate the Generally-Truncated-Expansion method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goffset(mux, n,
        a.mix = NULL, i.mix = NULL, d.mix = NULL,
        a.mlm = NULL, i.mlm = NULL, d.mlm = NULL, par1or2 = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goffset_+3A_mux">mux</code></td>
<td>

<p>Multiplier. Usually a small positive integer.
Must be positive.
The value 1 means no change.
</p>
</td></tr>
<tr><td><code id="goffset_+3A_n">n</code></td>
<td>

<p>Number of rows.
A positive integer, it should be the number of rows of
the data frame containing the data.
</p>
</td></tr>
<tr><td><code id="goffset_+3A_a.mix">a.mix</code>, <code id="goffset_+3A_i.mix">i.mix</code>, <code id="goffset_+3A_d.mix">d.mix</code></td>
<td>

<p>See, e.g., <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="goffset_+3A_a.mlm">a.mlm</code>, <code id="goffset_+3A_i.mlm">i.mlm</code>, <code id="goffset_+3A_d.mlm">d.mlm</code></td>
<td>

<p>See, e.g., <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="goffset_+3A_par1or2">par1or2</code></td>
<td>

<p>Number of parameters of the parent distribution.
Set <code>par1or2 = 2</code>  for <code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
else the default value should be used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is intended to make the 
Generally-Truncated-Expansion (GTE) method
easier for the user.
It only makes sense if the linear predictors(s) are
log  of the mean of the parent distribution,
which is the usual case for
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> and
<code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>.
However, for <code><a href="#topic+gaitdlog">gaitdlog</a></code>
and  <code><a href="#topic+gaitdzeta">gaitdzeta</a></code> one should be using
<code><a href="VGAMextra.html#topic+logffMlink">logffMlink</a></code> and
<code><a href="VGAMextra.html#topic+zetaffMlink">zetaffMlink</a></code>.
</p>
<p>Without this function, the user must do quite a lot
of book-keeping to know which columns of the offset
matrix is to be assigned <code>log(mux)</code>.
This can be rather laborious.
</p>
<p>In the fictitional example below the response is underdispersed
with respect to a Poisson distribution and
doubling the response achieves approximate equidispersion.
</p>


<h3>Value</h3>

<p>A matrix with <code>n</code> rows and the same number of
columns that a GAITD regression would produce for
its matrix of linear predictors.
The matrix can be inputted into <code><a href="#topic+vglm">vglm</a></code>
by assigning the <code>offset</code> argument.
</p>


<h3>Note</h3>

<p>This function is still in a developmental stage.
The order of the arguments might change, hence it's
safest to invoke it with full specification.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+Trunc">Trunc</a></code>,
<code><a href="stats.html#topic+offset">offset</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>i.mix &lt;- c(5, 10, 15, 20); a.mlm &lt;- 13; mymux &lt;- 2
goffset(mymux, 10, i.mix = i.mix, a.mlm = a.mlm)
## Not run: org1  &lt;- with(gdata, range(y))  # Original range of the data
vglm(mymux * y ~ 1,
     offset = goffset(mymux, nrow(gdata), i.mix = i.mix, a.mlm = a.mlm),
     gaitdpoisson(a.mlm = mymux * a.mlm, i.mix = mymux * i.mix,
                  truncate = Trunc(org1, mymux)),
     data = gdata)

## End(Not run)</code></pre>

<hr>
<h2 id='gompertz'> Gompertz Regression Family Function </h2><span id='topic+gompertz'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
Gompertz distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gompertz(lscale = "loglink", lshape = "loglink",
         iscale = NULL,   ishape = NULL,
         nsimEIM = 500, zero = NULL, nowarning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gompertz_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning?
Ignored for <span class="pkg">VGAM</span> 0.9-7 and higher.
</p>
</td></tr>
<tr><td><code id="gompertz_+3A_lshape">lshape</code>, <code id="gompertz_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
shape parameter <code>a</code>,
scale parameter <code>scale</code>.
All parameters are positive.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="gompertz_+3A_ishape">ishape</code>, <code id="gompertz_+3A_iscale">iscale</code></td>
<td>

<p>Optional initial values.
A <code>NULL</code> means a value is computed internally.
</p>
</td></tr>
<tr><td><code id="gompertz_+3A_nsimeim">nsimEIM</code>, <code id="gompertz_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gompertz distribution has a cumulative distribution function
</p>
<p style="text-align: center;"><code class="reqn">F(x;\alpha, \beta) = 1 - \exp[-(\alpha/\beta) \times (\exp(\beta x) - 1) ]</code>
</p>

<p>which leads to a probability density function
</p>
<p style="text-align: center;"><code class="reqn">f(x; \alpha, \beta) = \alpha \exp(\beta x)
                     \exp [-(\alpha/\beta) \times (\exp(\beta x) - 1) ]</code>
</p>

<p>for <code class="reqn">\alpha &gt; 0</code>,
<code class="reqn">\beta &gt; 0</code>,
<code class="reqn">x &gt; 0</code>.
Here, <code class="reqn">\beta</code> is called the scale parameter <code>scale</code>,
and <code class="reqn">\alpha</code> is called the shape parameter
(one could refer to <code class="reqn">\alpha</code> as a location parameter and <code class="reqn">\beta</code> as
a shape parameter&mdash;see Lenart (2014)).
The mean is involves an exponential integral function.
Simulated Fisher scoring is used and multiple responses are handled.
</p>
<p>The Makeham distibution has an additional parameter compared to
the Gompertz distribution.
If <code class="reqn">X</code> is defined to be the result of sampling from a Gumbel
distribution until a negative value <code class="reqn">Z</code> is produced,
then <code class="reqn">X = -Z</code> has a Gompertz distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The same warnings in <code><a href="#topic+makeham">makeham</a></code> apply here too.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Lenart, A. (2014).
The moments of the Gompertz distribution
and maximum likelihood estimation of its parameters.
<em>Scandinavian Actuarial Journal</em>, <b>2014</b>, 255&ndash;277.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+dgompertz">dgompertz</a></code>,
<code><a href="#topic+makeham">makeham</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, eta1  = -1,
                          eta2  = -1 + 0.2 * x2,
                          ceta1 =  1,
                          ceta2 = -1 + 0.2 * x2)
gdata &lt;- transform(gdata, shape1 = exp(eta1),
                          shape2 = exp(eta2),
                          scale1 = exp(ceta1),
                          scale2 = exp(ceta2))
gdata &lt;- transform(gdata, y1 = rgompertz(nn, scale = scale1, shape = shape1),
                          y2 = rgompertz(nn, scale = scale2, shape = shape2))

fit1 &lt;- vglm(y1 ~ 1,  gompertz, data = gdata, trace = TRUE)
fit2 &lt;- vglm(y2 ~ x2, gompertz, data = gdata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
summary(fit1)
coef(fit2, matrix = TRUE)
summary(fit2)

## End(Not run)
</code></pre>

<hr>
<h2 id='Gompertz'>Gompertz Distribution</h2><span id='topic+Gompertz'></span><span id='topic+dgompertz'></span><span id='topic+pgompertz'></span><span id='topic+qgompertz'></span><span id='topic+rgompertz'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function,
quantile function
and
random generation for
the Gompertz distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgompertz(x, scale = 1, shape, log = FALSE)
pgompertz(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qgompertz(p, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
rgompertz(n, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gompertz_+3A_x">x</code>, <code id="Gompertz_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_lower.tail">lower.tail</code>, <code id="Gompertz_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_scale">scale</code>, <code id="Gompertz_+3A_shape">shape</code></td>
<td>
<p>positive scale and shape parameters. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+gompertz">gompertz</a></code> for details.
</p>


<h3>Value</h3>

<p><code>dgompertz</code> gives the density,
<code>pgompertz</code> gives the cumulative distribution function,
<code>qgompertz</code> gives the quantile function, and
<code>rgompertz</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+gompertz">gompertz</a></code>,
<code><a href="#topic+dgumbel">dgumbel</a></code>,
<code><a href="#topic+dmakeham">dmakeham</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- seq(0.01, 0.99, by = 0.01)
Shape &lt;- exp(1); Scale &lt;- exp(1)
max(abs(pgompertz(qgompertz(p = probs, Scale, shape = Shape),
                  Scale, shape = Shape) - probs))  # Should be 0

## Not run:  x &lt;- seq(-0.1, 1.0, by = 0.001)
plot(x, dgompertz(x, Scale,shape = Shape), type = "l", las = 1,
     main = "Blue is density, orange is the CDF", col = "blue",
     sub = "Purple lines are the 10,20,...,90 percentiles",
     ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(x, pgompertz(x, Scale, shape = Shape), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qgompertz(probs, Scale, shape = Shape)
lines(Q, dgompertz(Q, Scale, shape = Shape), col = "purple",
      lty = 3, type = "h")
pgompertz(Q, Scale, shape = Shape) - probs  # Should be all zero
abline(h = probs, col = "purple", lty = 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='gpd'> Generalized Pareto Distribution Regression Family Function </h2><span id='topic+gpd'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
generalized  Pareto distribution (GPD).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd(threshold = 0, lscale = "loglink", lshape = logofflink(offset = 0.5),
    percentiles = c(90, 95), iscale = NULL, ishape = NULL,
    tolshape0 = 0.001, type.fitted = c("percentiles", "mean"),
    imethod = 1, zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpd_+3A_threshold">threshold</code></td>
<td>

<p>Numeric, values are recycled if necessary.
The threshold value(s), called <code class="reqn">\mu</code> below.
</p>
</td></tr>
<tr><td><code id="gpd_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link function for the scale parameter <code class="reqn">\sigma</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="gpd_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function for the shape parameter <code class="reqn">\xi</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The default constrains the parameter to be greater than <code class="reqn">-0.5</code>
because if <code class="reqn">\xi \leq -0.5</code> then Fisher
scoring does not work.
See the Details section below for more information.
</p>
<p>For the shape parameter,
the default <code><a href="#topic+logofflink">logofflink</a></code> link has an offset
called <code class="reqn">A</code> below; and then the second linear/additive predictor is
<code class="reqn">\log(\xi+A)</code> which means that
<code class="reqn">\xi &gt; -A</code>.
The working weight matrices are positive definite if <code class="reqn">A = 0.5</code>.
</p>
</td></tr>









<tr><td><code id="gpd_+3A_percentiles">percentiles</code></td>
<td>

<p>Numeric vector of percentiles used
for the fitted values. Values should be between 0 and 100.
See the example below for illustration.
This argument is ignored if <code>type.fitted = "mean"</code>.
</p>



</td></tr>
<tr><td><code id="gpd_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
The default is to use the <code>percentiles</code> argument.
If <code>"mean"</code> is chosen, then the mean
<code class="reqn">\mu + \sigma / (1-\xi)</code>
is returned as the fitted values,
and these are only defined for <code class="reqn">\xi&lt;1</code>.
</p>
</td></tr>
<tr><td><code id="gpd_+3A_iscale">iscale</code>, <code id="gpd_+3A_ishape">ishape</code></td>
<td>

<p>Numeric. Optional initial values for <code class="reqn">\sigma</code>
and <code class="reqn">\xi</code>.
The default is to use <code>imethod</code> and compute a value internally for
each parameter.
Values of <code>ishape</code> should be between <code class="reqn">-0.5</code> and <code class="reqn">1</code>.
Values of <code>iscale</code> should be positive.
</p>
</td></tr>






<tr><td><code id="gpd_+3A_tolshape0">tolshape0</code></td>
<td>

<p>Passed into <code><a href="#topic+dgpd">dgpd</a></code> when computing the log-likelihood.
</p>
</td></tr>







<tr><td><code id="gpd_+3A_imethod">imethod</code></td>
<td>

<p>Method of initialization, either 1 or 2. The first is the method of
moments, and the second is a variant of this.  If neither work, try
assigning values to arguments <code>ishape</code> and/or <code>iscale</code>.
</p>
</td></tr>
<tr><td><code id="gpd_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
For one response, the value should be from the set {1,2}
corresponding respectively to <code class="reqn">\sigma</code> and
<code class="reqn">\xi</code>.
It is often a good idea for the <code class="reqn">\sigma</code> parameter only
to be modelled through
a linear combination of the explanatory variables because the
shape parameter is probably best left as an intercept only:
<code>zero = 2</code>.
Setting <code>zero = NULL</code> means both parameters are modelled with
explanatory variables.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distribution function of the GPD can be written
</p>
<p style="text-align: center;"><code class="reqn">G(y) = 1 - [1 + \xi (y-\mu) / \sigma  ]_{+}^{- 1/ \xi} </code>
</p>

<p>where
<code class="reqn">\mu</code> is the location parameter
(known, with value <code>threshold</code>),
<code class="reqn">\sigma &gt; 0</code> is the scale parameter,
<code class="reqn">\xi</code> is the shape parameter, and
<code class="reqn">h_+ = \max(h,0)</code>.
The function <code class="reqn">1-G</code> is known as the <em>survivor function</em>.
The limit <code class="reqn">\xi \rightarrow 0</code>
gives the <em>shifted exponential</em> as a special case:
</p>
<p style="text-align: center;"><code class="reqn">G(y) = 1 - \exp[-(y-\mu)/ \sigma]. </code>
</p>

<p>The support is <code class="reqn">y&gt;\mu</code> for <code class="reqn">\xi&gt;0</code>,
and
<code class="reqn">\mu &lt; y &lt;\mu-\sigma / \xi</code> for <code class="reqn">\xi&lt;0</code>.
</p>
<p>Smith (1985) showed that if <code class="reqn">\xi &lt;= -0.5</code> then
this is known as the nonregular case and problems/difficulties
can arise both theoretically and numerically. For the (regular)
case <code class="reqn">\xi &gt; -0.5</code> the classical asymptotic
theory of maximum likelihood estimators is applicable; this is
the default.
</p>
<p>Although for <code class="reqn">\xi &lt; -0.5</code> the usual asymptotic properties
do not apply, the maximum likelihood estimator generally exists and
is superefficient for <code class="reqn">-1 &lt; \xi &lt; -0.5</code>, so it is
&ldquo;better&rdquo; than normal.
When <code class="reqn">\xi &lt; -1</code> the maximum
likelihood estimator generally does not exist as it effectively becomes
a two parameter problem.
</p>
<p>The mean of <code class="reqn">Y</code> does not exist unless <code class="reqn">\xi &lt; 1</code>, and
the variance does not exist unless <code class="reqn">\xi &lt; 0.5</code>.  So if
you want to fit a model with finite variance use <code>lshape = "extlogitlink"</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
However, for this <span class="pkg">VGAM</span> family function, <code><a href="#topic+vglm">vglm</a></code>
is probably preferred over <code><a href="#topic+vgam">vgam</a></code> when there is smoothing.
</p>


<h3>Warning</h3>

<p>Fitting the GPD by maximum likelihood estimation can be numerically
fraught. If <code class="reqn">1 + \xi (y-\mu)/ \sigma \leq 0</code> then some crude evasive action is taken but the estimation process
can still fail. This is particularly the case if <code><a href="#topic+vgam">vgam</a></code>
with <code><a href="#topic+s">s</a></code> is used. Then smoothing is best done with
<code><a href="#topic+vglm">vglm</a></code> with regression splines (<code><a href="splines.html#topic+bs">bs</a></code>
or <code><a href="splines.html#topic+ns">ns</a></code>) because <code><a href="#topic+vglm">vglm</a></code> implements
half-stepsizing whereas <code><a href="#topic+vgam">vgam</a></code> doesn't. Half-stepsizing
helps handle the problem of straying outside the parameter space.
</p>


<h3>Note</h3>

<p>The response in the formula of <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code> is <code class="reqn">y</code>.
Internally, <code class="reqn">y-\mu</code> is computed.
This <span class="pkg">VGAM</span> family function can handle a multiple
responses, which is inputted as a matrix.
The response stored on the object is the original uncentred data.
</p>
<p>With functions <code><a href="#topic+rgpd">rgpd</a></code>, <code><a href="#topic+dgpd">dgpd</a></code>, etc., the
argument <code>location</code> matches with the argument <code>threshold</code>
here.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Stephenson, A. G. (2007).
Vector generalized linear and additive extreme value models.
<em>Extremes</em>, <b>10</b>, 1&ndash;19.
</p>
<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>
<p>Smith, R. L. (1985).
Maximum likelihood estimation in a class of nonregular cases.
<em>Biometrika</em>, <b>72</b>, 67&ndash;90.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rgpd">rgpd</a></code>,
<code><a href="#topic+meplot">meplot</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+paretoff">paretoff</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+s">s</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated data from an exponential distribution (xi = 0)
Threshold &lt;- 0.5
gdata &lt;- data.frame(y1 = Threshold + rexp(n = 3000, rate = 2))
fit &lt;- vglm(y1 ~ 1, gpd(threshold = Threshold), data = gdata, trace = TRUE)
head(fitted(fit))
summary(depvar(fit))  # The original uncentred data
coef(fit, matrix = TRUE)  # xi should be close to 0
Coef(fit)
summary(fit)

head(fit@extra$threshold)  # Note the threshold is stored here

# Check the 90 percentile
ii &lt;- depvar(fit) &lt; fitted(fit)[1, "90%"]
100 * table(ii) / sum(table(ii))  # Should be 90%

# Check the 95 percentile
ii &lt;- depvar(fit) &lt; fitted(fit)[1, "95%"]
100 * table(ii) / sum(table(ii))  # Should be 95%

## Not run:  plot(depvar(fit), col = "blue", las = 1,
               main = "Fitted 90% and 95% quantiles")
matlines(1:length(depvar(fit)), fitted(fit), lty = 2:3, lwd = 2) 
## End(Not run)


# Another example
gdata &lt;- data.frame(x2 = runif(nn &lt;- 2000))
Threshold &lt;- 0; xi &lt;- exp(-0.8) - 0.5
gdata &lt;- transform(gdata, y2 = rgpd(nn, scale = exp(1 + 0.1*x2), shape = xi))
fit &lt;- vglm(y2 ~ x2, gpd(Threshold), data = gdata, trace = TRUE)
coef(fit, matrix = TRUE)


## Not run:  # Nonparametric fits
# Not so recommended:
fit1 &lt;- vgam(y2 ~ s(x2), gpd(Threshold), data = gdata, trace = TRUE)
par(mfrow = c(2, 1))
plot(fit1, se = TRUE, scol = "blue")
# More recommended:
fit2 &lt;- vglm(y2 ~ sm.bs(x2), gpd(Threshold), data = gdata, trace = TRUE)
plot(as(fit2, "vgam"), se = TRUE, scol = "blue") 
## End(Not run)
</code></pre>

<hr>
<h2 id='gpdUC'>The Generalized Pareto Distribution </h2><span id='topic+gpdUC'></span><span id='topic+dgpd'></span><span id='topic+pgpd'></span><span id='topic+qgpd'></span><span id='topic+rgpd'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the generalized Pareto distribution (GPD) with
location parameter <code>location</code>, scale parameter <code>scale</code>
and shape parameter <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgpd(x, location = 0, scale = 1, shape = 0, log = FALSE,
     tolshape0 = sqrt(.Machine$double.eps))
pgpd(q, location = 0, scale = 1, shape = 0,
     lower.tail = TRUE, log.p = FALSE)
qgpd(p, location = 0, scale = 1, shape = 0,
     lower.tail = TRUE, log.p = FALSE)
rgpd(n, location = 0, scale = 1, shape = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdUC_+3A_x">x</code>, <code id="gpdUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_location">location</code></td>
<td>
<p>the location parameter <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_scale">scale</code></td>
<td>
<p>the (positive) scale parameter <code class="reqn">\sigma</code>.</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_shape">shape</code></td>
<td>
<p>the shape parameter <code class="reqn">\xi</code>.</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_lower.tail">lower.tail</code>, <code id="gpdUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Uniform">punif</a></code>
or <code><a href="stats.html#topic+Uniform">qunif</a></code>.
</p>
</td></tr>
<tr><td><code id="gpdUC_+3A_tolshape0">tolshape0</code></td>
<td>

<p>Positive numeric.
Threshold/tolerance value for resting whether <code class="reqn">\xi</code>
is zero.  If the absolute value of the estimate of <code class="reqn">\xi</code>
is less than this value then it will be assumed zero and an
exponential distribution will be used.
</p>
</td></tr>















</table>


<h3>Details</h3>

<p>See <code><a href="#topic+gpd">gpd</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the two parameters by maximum likelihood estimation,
for formulae and other details.
Apart from <code>n</code>, all the above arguments may be vectors and
are recyled to the appropriate length if necessary.
</p>


<h3>Value</h3>

<p><code>dgpd</code> gives the density,
<code>pgpd</code> gives the distribution function,
<code>qgpd</code> gives the quantile function, and
<code>rgpd</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The default values of all three parameters, especially
<code class="reqn">\xi = 0</code>, means the default distribution is the
exponential.
</p>
<p>Currently, these functions have different argument names compared
with those in the <span class="pkg">evd</span> package.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>,
<code><a href="stats.html#topic+Exponential">Exponential</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  loc &lt;- 2; sigma &lt;- 1; xi &lt;- -0.4
x &lt;- seq(loc - 0.2, loc + 3, by = 0.01)
plot(x, dgpd(x, loc, sigma, xi), type = "l", col = "blue",
     main = "Blue is density, red is the CDF", ylim = c(0, 1),
     sub = "Purple are 5,10,...,95 percentiles", ylab = "", las = 1)
abline(h = 0, col = "blue", lty = 2)
lines(qgpd(seq(0.05, 0.95, by = 0.05), loc, sigma, xi),
  dgpd(qgpd(seq(0.05, 0.95, by = 0.05), loc, sigma, xi), loc, sigma, xi),
      col = "purple", lty = 3, type = "h")
lines(x, pgpd(x, loc, sigma, xi), type = "l", col = "red")
abline(h = 0, lty = 2)

pgpd(qgpd(seq(0.05, 0.95, by = 0.05), loc, sigma, xi), loc, sigma, xi)

## End(Not run)
</code></pre>

<hr>
<h2 id='grain.us'>Grain Prices Data in USA </h2><span id='topic+grain.us'></span>

<h3>Description</h3>

<p>A 4-column matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(grain.us)</code></pre>


<h3>Format</h3>

<p>The columns are:
</p>

<dl>
<dt>wheat.flour</dt><dd><p>numeric</p>
</dd>
<dt>corn</dt><dd><p>numeric</p>
</dd>
<dt>wheat</dt><dd><p>numeric</p>
</dd>
<dt>rye</dt><dd><p>numeric</p>
</dd>
</dl>



<h3>Details</h3>

<p>Monthly averages of grain prices
in the United States for wheat flour, corn, wheat, and rye for the
period January 1961 through October 1972.
The units are US dollars per 100 pound sack for wheat flour, and
per bushel for corn, wheat and rye.
</p>


<h3>Source</h3>

<p>Ahn and Reinsel (1988).
</p>


<h3>References</h3>

<p>Ahn, S. K  and Reinsel, G. C. (1988).
Nested reduced-rank autoregressive models for multiple time series.
<em>Journal of the American Statistical Association</em>,
<b>83</b>, 849&ndash;856.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
cgrain &lt;- scale(grain.us, scale = FALSE)  # Center the time series only
fit &lt;- vglm(cgrain ~ 1, rrar(Rank = c(4, 1)),
            epsilon = 1e-3, stepsize = 0.5, trace = TRUE, maxit = 50)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='grc'> Row-Column Interaction Models including Goodman's RC Association
Model and Unconstrained Quadratic Ordination </h2><span id='topic+grc'></span><span id='topic+rcim'></span><span id='topic+uqo'></span>

<h3>Description</h3>

<p>Fits a Goodman's RC association model (GRC) to a matrix of counts,
and more generally, row-column interaction models (RCIMs).
RCIMs allow for unconstrained quadratic ordination (UQO).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grc(y, Rank = 1, Index.corner = 2:(1 + Rank),
    str0 = 1, summary.arg = FALSE, h.step = 1e-04, ...)
rcim(y, family = poissonff, Rank = 0, M1 = NULL,
     weights = NULL, which.linpred = 1,
     Index.corner = ifelse(is.null(str0), 0, max(str0)) + 1:Rank,
     rprefix = "Row.", cprefix = "Col.", iprefix = "X2.",
     offset = 0, str0 = if (Rank) 1 else NULL,
     summary.arg = FALSE, h.step = 0.0001,
     rbaseline = 1, cbaseline = 1,
     has.intercept = TRUE, M = NULL,
     rindex = 2:nrow(y), cindex = 2:ncol(y), iindex = 2:nrow(y), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grc_+3A_y">y</code></td>
<td>

<p>For <code>grc()</code>: a matrix of counts.
For <code>rcim()</code>: a general matrix response depending on <code>family</code>.
Output from <code>table()</code> is acceptable; it is converted into a matrix.
Note that <code>y</code> should be at least 3 by 3 in dimension.
</p>
</td></tr>
<tr><td><code id="grc_+3A_family">family</code></td>
<td>

<p>A <span class="pkg">VGAM</span> family function.
By default, the first linear/additive predictor
is fitted
using main effects plus an optional rank-<code>Rank</code>
interaction term.
Not all family functions are suitable or make sense.
All other linear/additive predictors are fitted using an intercept-only,
so it has a common value over all rows and columns.
For example,
<code><a href="#topic+zipoissonff">zipoissonff</a></code> may be suitable for counts but not
<code><a href="#topic+zipoisson">zipoisson</a></code> because of the ordering of the
linear/additive predictors.
If the <span class="pkg">VGAM</span> family function does not have an <code>infos</code>
slot then <code>M1</code> needs to be inputted (the number of
linear predictors for an ordinary (usually univariate) response,
aka <code class="reqn">M</code>).
The <span class="pkg">VGAM</span> family function also needs to be able to
handle multiple responses (currently not all of them can do this).
</p>
</td></tr>
<tr><td><code id="grc_+3A_rank">Rank</code></td>
<td>

<p>An integer from the set
{0,...,<code>min(nrow(y), ncol(y))</code>}.
This is the dimension of the fit in terms of the interaction.
For <code>grc()</code> this argument must be positive.
A value of 0 means no interactions (i.e., main effects only);
each row and column is represented by an indicator variable.
</p>
</td></tr>
<tr><td><code id="grc_+3A_weights">weights</code></td>
<td>

<p>Prior weights. Fed into
<code><a href="#topic+rrvglm">rrvglm</a></code>
or
<code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="grc_+3A_which.linpred">which.linpred</code></td>
<td>

<p>Single integer.
Specifies which linear predictor is modelled as the sum of an
intercept, row effect, column effect plus an optional interaction
term. It should be one value from the set <code>1:M1</code>.
</p>
</td></tr>
<tr><td><code id="grc_+3A_index.corner">Index.corner</code></td>
<td>

<p>A vector of <code>Rank</code> integers.
These are used to store the <code>Rank</code> by <code>Rank</code>
identity matrix in the
<code>A</code> matrix; corner constraints are used.
</p>
</td></tr>
<tr><td><code id="grc_+3A_rprefix">rprefix</code>, <code id="grc_+3A_cprefix">cprefix</code>, <code id="grc_+3A_iprefix">iprefix</code></td>
<td>

<p>Character, for rows and columns and interactions respectively.
For labelling the indicator variables.
</p>
</td></tr>
<tr><td><code id="grc_+3A_offset">offset</code></td>
<td>

<p>Numeric. Either a matrix of the right dimension, else
a single numeric expanded into such a matrix.
</p>
</td></tr>
<tr><td><code id="grc_+3A_str0">str0</code></td>
<td>

<p>Ignored if <code>Rank = 0</code>, else
an integer from the set {1,...,<code>min(nrow(y), ncol(y))</code>},
specifying the row that is used as the structural zero.
Passed into <code><a href="#topic+rrvglm.control">rrvglm.control</a></code> if <code>Rank &gt; 0</code>.
Set <code>str0 = NULL</code> for none.
</p>
</td></tr>
<tr><td><code id="grc_+3A_summary.arg">summary.arg</code></td>
<td>

<p>Logical. If <code>TRUE</code> then a summary is returned.
If <code>TRUE</code> then <code>y</code> may be the output (fitted
object) of <code>grc()</code>.
</p>
</td></tr>
<tr><td><code id="grc_+3A_h.step">h.step</code></td>
<td>

<p>A small positive value that is passed into
<code>summary.rrvglm()</code>. Only used when <code>summary.arg = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="grc_+3A_...">...</code></td>
<td>
<p> Arguments that are passed
into <code>rrvglm.control()</code>.
</p>
</td></tr>
<tr><td><code id="grc_+3A_m1">M1</code></td>
<td>

<p>The number of linear predictors of the <span class="pkg">VGAM</span> <code>family</code>
function for an ordinary (univariate) response.
Then the number of linear predictors of the <code>rcim()</code> fit is
usually the number of columns of <code>y</code> multiplied by <code>M1</code>.
The default is to evaluate the <code>infos</code> slot of the
<span class="pkg">VGAM</span> <code>family</code> function to try to evaluate it;
see <code><a href="#topic+vglmff-class">vglmff-class</a></code>.
If this information is not yet supplied by the family function then
the value needs to be inputted manually using this argument.
</p>
</td></tr>
<tr><td><code id="grc_+3A_rbaseline">rbaseline</code>, <code id="grc_+3A_cbaseline">cbaseline</code></td>
<td>

<p>Baseline reference levels for the rows and columns.
Currently stored on the object but not used.
</p>
</td></tr>
<tr><td><code id="grc_+3A_has.intercept">has.intercept</code></td>
<td>

<p>Logical. Include an intercept?
</p>
</td></tr>
<tr><td><code id="grc_+3A_m">M</code>, <code id="grc_+3A_cindex">cindex</code></td>
<td>

<p><code class="reqn">M</code>  is the usual <span class="pkg">VGAM</span> <code class="reqn">M</code>,
viz. the number of linear/additive
predictors in total.
Also, <code>cindex</code> means column index, and these point to the columns
of <code>y</code> which are part of the vector of linear/additive predictor
<em>main effects</em>.
</p>
<p>For <code>family = multinomial</code> it is necessary to input these arguments
as <code>M = ncol(y)-1</code> and
<code>cindex = 2:(ncol(y)-1)</code>.
</p>

</td></tr>
<tr><td><code id="grc_+3A_rindex">rindex</code>, <code id="grc_+3A_iindex">iindex</code></td>
<td>

<p><code>rindex</code> means row index, and these are similar to <code>cindex</code>.
<code>iindex</code> means interaction index, and these are similar to
<code>cindex</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Goodman's RC association model fits a reduced-rank approximation
to a table of counts.
A Poisson model is assumed.
The log of each cell mean is decomposed as an
intercept plus a row effect plus a column effect plus a reduced-rank
component. The latter can be collectively written <code>A %*% t(C)</code>,
the product of two &lsquo;thin&rsquo; matrices.
Indeed, <code>A</code> and <code>C</code> have <code>Rank</code> columns.
By default, the first column and row of the interaction matrix
<code>A %*% t(C)</code> is chosen
to be structural zeros, because <code>str0 = 1</code>.
This means the first row of <code>A</code> are all zeros.
</p>
<p>This function uses <code>options()$contrasts</code> to set up the row and
column indicator variables.
In particular, Equation (4.5) of Yee and Hastie (2003) is used.
These are called <code>Row.</code> and <code>Col.</code> (by default) followed
by the row or column number.
</p>
<p>The function <code>rcim()</code> is more general than <code>grc()</code>.
Its default is a no-interaction model of <code>grc()</code>, i.e.,
rank-0 and a Poisson distribution. This means that each
row and column has a dummy variable associated with it.
The first row and first column are baseline.
The power of <code>rcim()</code> is that many <span class="pkg">VGAM</span> family functions
can be assigned to its <code>family</code> argument.
For example,
<code><a href="#topic+uninormal">uninormal</a></code> fits something in between a 2-way
ANOVA with and without interactions,
<code><a href="#topic+alaplace2">alaplace2</a></code> with <code>Rank = 0</code> is something like
<code><a href="stats.html#topic+medpolish">medpolish</a></code>.
Others include
<code><a href="#topic+zipoissonff">zipoissonff</a></code> and
<code><a href="#topic+negbinomial">negbinomial</a></code>.
Hopefully one day <em>all</em> <span class="pkg">VGAM</span> family functions will
work when assigned to the <code>family</code> argument, although the
result may not have meaning.
</p>
<p><em>Unconstrained quadratic ordination</em> (UQO) can be performed
using <code>rcim()</code> and <code>grc()</code>.
This has been called <em>unconstrained Gaussian ordination</em>
in the literature, however the word <em>Gaussian</em> has two
meanings which is confusing; it is better to use
<em>quadratic</em> because the bell-shape response surface is meant.
UQO is similar to CQO (<code><a href="#topic+cqo">cqo</a></code>) except there are
no environmental/explanatory variables.
Here, a GLM is fitted to each column (species)
that is a quadratic function of hypothetical latent variables
or gradients.
Thus each row of the response has an associated site score,
and each column of the response has an associated optimum
and tolerance matrix.
UQO can be performed here under the assumption that all species
have the same tolerance matrices.
See Yee and Hadi (2014) for details.
It is not recommended that presence/absence data be inputted
because the information content is so low for each site-species
cell.
The example below uses Poisson counts.
</p>


<h3>Value</h3>

<p>An object of class <code>"grc"</code>, which currently is the same as
an <code>"rrvglm"</code> object.
Currently,
a rank-0 <code>rcim()</code> object is of class <code><a href="#topic+rcim0-class">rcim0-class</a></code>,
else of class <code>"rcim"</code> (this may change in the future).
</p>





<h3>Warning</h3>

<p>The function <code>rcim()</code> is experimental at this stage and
may have bugs.
Quite a lot of expertise is needed when fitting and in its
interpretion thereof. For example, the constraint
matrices applies the reduced-rank regression to the first
(see <code>which.linpred</code>)
linear predictor and the other linear predictors are intercept-only
and have a common value throughout the entire data set.
This means that, by default,
<code>family =</code> <code><a href="#topic+zipoissonff">zipoissonff</a></code> is
appropriate but not
<code>family =</code> <code><a href="#topic+zipoisson">zipoisson</a></code>.
Else set <code>family =</code> <code><a href="#topic+zipoisson">zipoisson</a></code> and
<code>which.linpred = 2</code>.
To understand what is going on, do examine the constraint
matrices of the fitted object, and reconcile this with
Equations (4.3) to (4.5) of Yee and Hastie (2003).
</p>
<p>The functions temporarily create a permanent data frame
called <code>.grc.df</code> or <code>.rcim.df</code>, which used
to be needed by <code>summary.rrvglm()</code>. Then these
data frames are deleted before exiting the function.
If an error occurs then the data frames may be present
in the workspace.
</p>


<h3>Note</h3>

<p>These functions set up the indicator variables etc. before calling
<code><a href="#topic+rrvglm">rrvglm</a></code>
or
<code><a href="#topic+vglm">vglm</a></code>.
The <code>...</code> is passed into <code><a href="#topic+rrvglm.control">rrvglm.control</a></code> or
<code><a href="#topic+vglm.control">vglm.control</a></code>,
This means, e.g., <code>Rank = 1</code> is default for <code>grc()</code>.
</p>
<p>The data should be labelled with <code><a href="base.html#topic+rownames">rownames</a></code> and
<code><a href="base.html#topic+colnames">colnames</a></code>.
Setting <code>trace = TRUE</code> is recommended to monitor
convergence.
Using <code>criterion = "coefficients"</code> can result in slow convergence.
</p>
<p>If <code>summary = TRUE</code> then <code>y</code> can be a
<code>"grc"</code> object, in which case a summary can be returned.
That is, <code>grc(y, summary = TRUE)</code> is
equivalent to <code>summary(grc(y))</code>.
It is not possible to plot a
<code>grc(y, summary = TRUE)</code> or
<code>rcim(y, summary = TRUE)</code> object.
</p>


<h3>Author(s)</h3>

<p>Thomas W. Yee, with
assistance from Alfian F. Hadi.
</p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. and Hadi, A. F. (2014).
Row-column interaction models, with an R implementation.
<em>Computational Statistics</em>,
<b>29</b>, 1427&ndash;1445.
</p>
<p>Goodman, L. A. (1981).
Association models and canonical correlation in the analysis
of cross-classifications having ordered categories.
<em>Journal of the American Statistical Association</em>,
<b>76</b>, 320&ndash;334.
</p>






<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rrvglm.control">rrvglm.control</a></code>,
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code>,
<code>summary.grc</code>,
<code><a href="#topic+moffset">moffset</a></code>,
<code><a href="#topic+Rcim">Rcim</a></code>,
<code><a href="#topic+Select">Select</a></code>,
<code><a href="#topic+Qvar">Qvar</a></code>,
<code><a href="#topic+plotrcim0">plotrcim0</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+alcoff">alcoff</a></code>,
<code><a href="#topic+crashi">crashi</a></code>,
<code><a href="#topic+auuc">auuc</a></code>,
<code><a href="#topic+olym08">olym08</a></code>,
<code><a href="#topic+olym12">olym12</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="stats.html#topic+medpolish">medpolish</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Undergraduate enrolments at Auckland University in 1990
fitted(grc1 &lt;- grc(auuc))
summary(grc1)

grc2 &lt;- grc(auuc, Rank = 2, Index.corner = c(2, 5))
fitted(grc2)
summary(grc2)

model3 &lt;- rcim(auuc, Rank = 1, fam = multinomial,
               M = ncol(auuc)-1, cindex = 2:(ncol(auuc)-1), trace = TRUE)
fitted(model3)
summary(model3)

# Median polish but not 100 percent reliable. Maybe call alaplace2()...
## Not run: 
rcim0 &lt;- rcim(auuc, fam = alaplace1(tau = 0.5), trace=FALSE, maxit = 500)
round(fitted(rcim0), digits = 0)
round(100 * (fitted(rcim0) - auuc) / auuc, digits = 0)  # Discrepancy
depvar(rcim0)
round(coef(rcim0, matrix = TRUE), digits = 2)
Coef(rcim0, matrix = TRUE)
# constraints(rcim0)
names(constraints(rcim0))

# Compare with medpolish():
(med.a &lt;- medpolish(auuc))
fv &lt;- med.a$overall + outer(med.a$row, med.a$col, "+")
round(100 * (fitted(rcim0) - fv) / fv)  # Hopefully should be all 0s

## End(Not run)


# Example 2: 2012 Summer Olympic Games in London
## Not run:  top10 &lt;- head(olym12, 10)
grc1.oly12 &lt;- with(top10, grc(cbind(gold, silver, bronze)))
round(fitted(grc1.oly12))
round(resid(grc1.oly12, type = "response"), digits = 1)  # Resp. resids
summary(grc1.oly12)
Coef(grc1.oly12)

## End(Not run)


# Example 3: UQO; see Yee and Hadi (2014)
## Not run: 
n &lt;- 100; p &lt;- 5; S &lt;- 10
pdata &lt;- rcqo(n, p, S, es.opt = FALSE, eq.max = FALSE,
              eq.tol = TRUE, sd.latvar = 0.75)  # Poisson counts
true.nu &lt;- attr(pdata, "latvar")  # The 'truth'; site scores
attr(pdata, "tolerances")  # The 'truth'; tolerances

Y &lt;- Select(pdata, "y", sort = FALSE)  # Y matrix (n x S); the "y" vars
uqo.rcim1 &lt;- rcim(Y, Rank = 1,
                  str0 = NULL,  # Delta covers entire n x M matrix
                  iindex = 1:nrow(Y),  # RRR covers the entire Y
                  has.intercept = FALSE)  # Suppress the intercept

# Plot 1
par(mfrow = c(2, 2))
plot(attr(pdata, "optimums"), Coef(uqo.rcim1)@A,
     col = "blue", type = "p", main = "(a) UQO optimums",
     xlab = "True optimums", ylab = "Estimated (UQO) optimums")
mylm &lt;- lm(Coef(uqo.rcim1)@A ~ attr(pdata, "optimums"))
abline(coef = coef(mylm), col = "orange", lty = "dashed")

# Plot 2
fill.val &lt;- NULL  # Choose this for the new parameterization
plot(attr(pdata, "latvar"), c(fill.val, concoef(uqo.rcim1)),
     las = 1, col = "blue", type = "p", main = "(b) UQO site scores",
     xlab = "True site scores", ylab = "Estimated (UQO) site scores" )
mylm &lt;- lm(c(fill.val, concoef(uqo.rcim1)) ~ attr(pdata, "latvar"))
abline(coef = coef(mylm), col = "orange", lty = "dashed")

# Plots 3 and 4
myform &lt;- attr(pdata, "formula")
p1ut &lt;- cqo(myform, family = poissonff,
            eq.tol = FALSE, trace = FALSE, data = pdata)
c1ut &lt;- cqo(Select(pdata, "y", sort = FALSE) ~ scale(latvar(uqo.rcim1)),
        family = poissonff, eq.tol = FALSE, trace = FALSE, data = pdata)
lvplot(p1ut, lcol = 1:S, y = TRUE, pcol = 1:S, pch = 1:S, pcex = 0.5,
       main = "(c) CQO fitted to the original data",
       xlab = "Estimated (CQO) site scores")
lvplot(c1ut, lcol = 1:S, y = TRUE, pcol = 1:S, pch = 1:S, pcex = 0.5,
       main = "(d) CQO fitted to the scaled UQO site scores",
       xlab = "Estimated (UQO) site scores")

## End(Not run)
</code></pre>

<hr>
<h2 id='gumbel'> Gumbel Regression Family Function </h2><span id='topic+gumbel'></span><span id='topic+gumbelff'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
Gumbel distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gumbel(llocation = "identitylink", lscale = "loglink",
       iscale = NULL, R = NA, percentiles = c(95, 99),
       mpv = FALSE, zero = NULL)
gumbelff(llocation = "identitylink", lscale = "loglink",
         iscale = NULL, R = NA, percentiles = c(95, 99),
         zero = "scale", mpv = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gumbel_+3A_llocation">llocation</code>, <code id="gumbel_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions for <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_iscale">iscale</code></td>
<td>

<p>Numeric and positive.
Optional initial value for <code class="reqn">\sigma</code>.
Recycled to the appropriate length.
In general, a larger value is better than a smaller value.
A <code>NULL</code> means an initial value is computed internally.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_r">R</code></td>
<td>

<p>Numeric. Maximum number of values possible.
See <b>Details</b> for more details.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_percentiles">percentiles</code></td>
<td>

<p>Numeric vector of percentiles used
for the fitted values. Values should be between 0 and 100.
This argument uses the argument <code>R</code> if assigned.
If <code>percentiles = NULL</code> then the mean will be returned as the
fitted values.
</p>

</td></tr>
<tr><td><code id="gumbel_+3A_mpv">mpv</code></td>
<td>

<p>Logical. If <code>mpv = TRUE</code> then the <em>median predicted value</em> (MPV)
is computed and returned as the (last) column of the fitted values.
This argument is ignored if <code>percentiles = NULL</code>.
See <b>Details</b> for more details.
</p>

</td></tr>






<tr><td><code id="gumbel_+3A_zero">zero</code></td>
<td>

<p>A vector specifying which linear/additive predictors
are modelled as intercepts only.  The value (possibly values) can
be from the set {1, 2} corresponding respectively to <code class="reqn">\mu</code>
and <code class="reqn">\sigma</code>.  By default all linear/additive predictors
are modelled as a linear combination of the explanatory variables.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gumbel distribution is a generalized extreme value (GEV)
distribution with <em>shape</em> parameter <code class="reqn">\xi = 0</code>.
Consequently it is more easily estimated than the GEV.
See <code><a href="#topic+gev">gev</a></code> for more details.
</p>
<p>The quantity <code class="reqn">R</code> is the maximum number of observations possible,
for example, in the Venice data below, the top 10 daily values
are recorded for each year, therefore  <code class="reqn">R = 365</code> because there are
about 365 days per year.
The MPV is the value of the response such that the probability
of obtaining a value greater than the MPV is 0.5 out of
<code class="reqn">R</code> observations.
For the Venice data, the MPV is the sea level such that there
is an even chance that the highest level for a particular year
exceeds the MPV.
If <code>mpv = TRUE</code> then the column labelled  <code>"MPV"</code> contains
the MPVs when <code>fitted()</code> is applied to the fitted object.
</p>
<p>The formula for the mean of a response <code class="reqn">Y</code> is
<code class="reqn">\mu+\sigma \times Euler</code> where <code class="reqn">Euler</code> is a constant
that has value approximately equal to 0.5772.
The formula for the percentiles are (if <code>R</code> is not given)
<code class="reqn">\mu-\sigma \times \log[-\log(P/100)]</code>
where <code class="reqn">P</code> is the <code>percentile</code> argument value(s).
If <code>R</code> is given then the percentiles are
<code class="reqn">\mu-\sigma \times \log[R(1-P/100)]</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>When <code>R</code> is not given (the default) the fitted percentiles are
that of the data, and not of the
overall population. For example, in the example below, the 50
percentile is approximately the running median through the data,
however, the data are the highest sea level measurements recorded each
year (it therefore equates to the median predicted value or MPV).
</p>


<h3>Note</h3>

<p>Like many other usual <span class="pkg">VGAM</span> family functions,
<code>gumbelff()</code> handles (independent) multiple responses.
</p>

<p><code>gumbel()</code> can handle
more of a
multivariate response, i.e., a
matrix with more than one column. Each row of the matrix is
sorted into descending order.
Missing values in the response are allowed but require
<code>na.action = na.pass</code>. The response matrix needs to be
padded with any missing values. With a multivariate response
one has a matrix <code>y</code>, say, where
<code>y[, 2]</code> contains the second order statistics, etc.
</p>







<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Stephenson, A. G. (2007).
Vector generalized linear and additive extreme value models.
<em>Extremes</em>, <b>10</b>, 1&ndash;19.
</p>
<p>Smith, R. L. (1986).
Extreme value theory based on the <em>r</em> largest annual events.
<em>Journal of Hydrology</em>,
<b>86</b>, 27&ndash;43.
</p>
<p>Rosen, O. and Cohen, A. (1996).
Extreme percentile regression.
In: Haerdle, W. and Schimek, M. G. (eds.),
<em>Statistical Theory and Computational Aspects of Smoothing:
Proceedings of the COMPSTAT '94 Satellite Meeting held in
Semmering, Austria, 27&ndash;28 August 1994</em>, pp.200&ndash;214,
Heidelberg: Physica-Verlag.
</p>
<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rgumbel">rgumbel</a></code>,
<code><a href="#topic+dgumbelII">dgumbelII</a></code>,
<code><a href="#topic+cens.gumbel">cens.gumbel</a></code>,
<code><a href="#topic+guplot">guplot</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+gevff">gevff</a></code>,
<code><a href="#topic+venice">venice</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Simulated data
gdata &lt;- data.frame(y1 = rgumbel(n = 1000, loc = 100, scale = exp(1)))
fit1 &lt;- vglm(y1 ~ 1, gumbelff(perc = NULL), data = gdata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
head(fitted(fit1))
with(gdata, mean(y1))

# Example 2: Venice data
(fit2 &lt;- vglm(cbind(r1, r2, r3, r4, r5) ~ year, data = venice,
              gumbel(R = 365, mpv = TRUE), trace = TRUE))
head(fitted(fit2))
coef(fit2, matrix = TRUE)
sqrt(diag(vcov(summary(fit2))))   # Standard errors

# Example 3: Try a nonparametric fit ---------------------
# Use the entire data set, including missing values
# Same as as.matrix(venice[, paste0("r", 1:10)]):
Y &lt;- Select(venice, "r", sort = FALSE)
fit3 &lt;- vgam(Y ~ s(year, df = 3), gumbel(R = 365, mpv = TRUE),
             data = venice, trace = TRUE, na.action = na.pass)
depvar(fit3)[4:5, ]  # NAs used to pad the matrix

## Not run:   # Plot the component functions
par(mfrow = c(2, 3), mar = c(6, 4, 1, 2) + 0.3, xpd = TRUE)
plot(fit3, se = TRUE, lcol = "blue", scol = "limegreen", lty = 1,
     lwd = 2, slwd = 2, slty = "dashed")

# Quantile plot --- plots all the fitted values
qtplot(fit3, mpv = TRUE, lcol = c(1, 2, 5), tcol = c(1, 2, 5), lwd = 2,
       pcol = "blue", tadj = 0.1, ylab = "Sea level (cm)")

# Plot the 99 percentile only
year &lt;- venice[["year"]]
matplot(year, Y, ylab = "Sea level (cm)", type = "n")
matpoints(year, Y, pch = "*", col = "blue")
lines(year, fitted(fit3)[, "99%"], lwd = 2, col = "orange")

# Check the 99 percentiles with a smoothing spline.
# Nb. (1-0.99) * 365 = 3.65 is approx. 4, meaning the 4th order
# statistic is approximately the 99 percentile.
plot(year, Y[, 4], ylab = "Sea level (cm)", type = "n",
     main = "Orange is 99 percentile, Green is a smoothing spline")
points(year, Y[, 4], pch = "4", col = "blue")
lines(year, fitted(fit3)[, "99%"], lty = 1, col = "orange")
lines(smooth.spline(year, Y[, 4], df = 4), col = "limegreen", lty = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='Gumbel-II'>The Gumbel-II Distribution</h2><span id='topic+Gumbel-II'></span><span id='topic+dgumbelII'></span><span id='topic+pgumbelII'></span><span id='topic+qgumbelII'></span><span id='topic+rgumbelII'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function,
quantile function
and
random generation for
the Gumbel-II distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgumbelII(x, scale = 1, shape, log = FALSE)
pgumbelII(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qgumbelII(p, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
rgumbelII(n, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gumbel-II_+3A_x">x</code>, <code id="Gumbel-II_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Gumbel-II_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Gumbel-II_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Gumbel-II_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Gumbel-II_+3A_lower.tail">lower.tail</code>, <code id="Gumbel-II_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Gumbel-II_+3A_shape">shape</code>, <code id="Gumbel-II_+3A_scale">scale</code></td>
<td>
<p>positive shape and scale parameters. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+gumbelII">gumbelII</a></code> for details.
</p>


<h3>Value</h3>

<p><code>dgumbelII</code> gives the density,
<code>pgumbelII</code> gives the cumulative distribution function,
<code>qgumbelII</code> gives the quantile function, and
<code>rgumbelII</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gumbelII">gumbelII</a></code>,
<code><a href="#topic+dgumbel">dgumbel</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- seq(0.01, 0.99, by = 0.01)
Scale &lt;- exp(1); Shape &lt;- exp( 0.5);
max(abs(pgumbelII(qgumbelII(p = probs, shape = Shape, Scale),
                  shape = Shape, Scale) - probs))  # Should be 0

## Not run:  x &lt;- seq(-0.1, 10, by = 0.01);
plot(x, dgumbelII(x, shape = Shape, Scale), type = "l", col = "blue",
     main = "Blue is density, orange is the CDF", las = 1,
     sub = "Red lines are the 10,20,...,90 percentiles",
     ylab = "", ylim = 0:1)
abline(h = 0, col = "blue", lty = 2)
lines(x, pgumbelII(x, shape = Shape, Scale), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qgumbelII(probs, shape = Shape, Scale)
lines(Q, dgumbelII(Q, Scale, Shape), col = "red", lty = 3, type = "h")
pgumbelII(Q, shape = Shape, Scale) - probs # Should be all zero
abline(h = probs, col = "red", lty = 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='gumbelII'> Gumbel-II Regression Family Function </h2><span id='topic+gumbelII'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter Gumbel-II distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gumbelII(lscale = "loglink", lshape = "loglink", iscale = NULL, ishape = NULL,
         probs.y = c(0.2, 0.5, 0.8), perc.out = NULL, imethod = 1,
         zero = "shape", nowarning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gumbelII_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning? </p>
</td></tr>
<tr><td><code id="gumbelII_+3A_lshape">lshape</code>, <code id="gumbelII_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
(positive) shape parameter (called <code class="reqn">s</code> below) and
(positive) scale parameter (called <code class="reqn">b</code> below).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





</table>
<p>Parameter link functions applied to the
</p>
<table>
<tr><td><code id="gumbelII_+3A_ishape">ishape</code>, <code id="gumbelII_+3A_iscale">iscale</code></td>
<td>

<p>Optional initial values for the shape and scale parameters.
</p>
</td></tr>
<tr><td><code id="gumbelII_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+weibullR">weibullR</a></code>.
</p>
</td></tr>
<tr><td><code id="gumbelII_+3A_zero">zero</code>, <code id="gumbelII_+3A_probs.y">probs.y</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="gumbelII_+3A_perc.out">perc.out</code></td>
<td>

<p>If the fitted values are to be quantiles then set this
argument to be the percentiles of these, e.g., 50 for median.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gumbel-II density for a response <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">f(y;b,s) = s y^{s-1} \exp[-(y/b)^s] / (b^s)</code>
</p>

<p>for <code class="reqn">b &gt; 0</code>, <code class="reqn">s &gt; 0</code>, <code class="reqn">y &gt; 0</code>.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y;b,s) = \exp[-(y/b)^{-s}].</code>
</p>

<p>The mean of <code class="reqn">Y</code> is <code class="reqn">b \, \Gamma(1 - 1/s)</code>
(returned as the fitted values)
when <code class="reqn">s&gt;1</code>,
and the variance is <code class="reqn">b^2\,\Gamma(1-2/s)</code> when
<code class="reqn">s&gt;2</code>.
This distribution looks similar to <code><a href="#topic+weibullR">weibullR</a></code>, and is
due to Gumbel (1954).
</p>
<p>This <span class="pkg">VGAM</span> family function currently does not handle censored data.
Fisher scoring is used to estimate the two parameters.
Probably similar regularity conditions hold for this distribution
compared to the Weibull distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+weibullR">weibullR</a></code>.
This <span class="pkg">VGAM</span> family function handles multiple responses.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Gumbel, E. J. (1954).
Statistical theory of extreme values and some practical applications.
<em>Applied Mathematics Series</em>, volume 33,
U.S. Department of Commerce, National Bureau of Standards, USA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dgumbelII">dgumbelII</a></code>,
<code><a href="#topic+gumbel">gumbel</a></code>,
<code><a href="#topic+gev">gev</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
gdata &lt;- transform(gdata, heta1  = +1,
                          heta2  = -1 + 0.1 * x2,
                          ceta1 =  0,
                          ceta2 =  1)
gdata &lt;- transform(gdata, shape1 = exp(heta1),
                          shape2 = exp(heta2),
                          scale1 = exp(ceta1),
                          scale2 = exp(ceta2))
gdata &lt;- transform(gdata,
                   y1 = rgumbelII(nn, scale = scale1, shape = shape1),
                   y2 = rgumbelII(nn, scale = scale2, shape = shape2))

fit &lt;- vglm(cbind(y1, y2) ~ x2,
            gumbelII(zero = c(1, 2, 3)), data = gdata, trace = TRUE)
coef(fit, matrix = TRUE)
vcov(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='gumbelUC'> The Gumbel Distribution </h2><span id='topic+dgumbel'></span><span id='topic+pgumbel'></span><span id='topic+qgumbel'></span><span id='topic+rgumbel'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Gumbel distribution with
location parameter <code>location</code> and
scale parameter <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgumbel(x, location = 0, scale = 1, log = FALSE)
pgumbel(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
qgumbel(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
rgumbel(n, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gumbelUC_+3A_x">x</code>, <code id="gumbelUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="gumbelUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="gumbelUC_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the number required.
</p>
</td></tr>
<tr><td><code id="gumbelUC_+3A_location">location</code></td>
<td>
<p>the location parameter <code class="reqn">\mu</code>.
This is not the mean
of the Gumbel distribution (see <b>Details</b> below).
</p>
</td></tr>
<tr><td><code id="gumbelUC_+3A_scale">scale</code></td>
<td>
<p>the scale parameter <code class="reqn">\sigma</code>.
This is not the standard deviation
of the Gumbel distribution (see <b>Details</b> below).
</p>
</td></tr>
<tr><td><code id="gumbelUC_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="gumbelUC_+3A_lower.tail">lower.tail</code>, <code id="gumbelUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Uniform">punif</a></code>
or <code><a href="stats.html#topic+Uniform">qunif</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gumbel distribution is a special case of the
<em>generalized extreme value</em> (GEV) distribution where
the shape parameter <code class="reqn">\xi</code> = 0.
The latter has 3 parameters, so the Gumbel distribution has two.
The Gumbel distribution function is
</p>
<p style="text-align: center;"><code class="reqn">G(y) = \exp \left( - \exp \left[ - \frac{y-\mu}{\sigma} \right]
                    \right) </code>
</p>

<p>where <code class="reqn">-\infty&lt;y&lt;\infty</code>,
<code class="reqn">-\infty&lt;\mu&lt;\infty</code> and
<code class="reqn">\sigma&gt;0</code>.
Its mean is
</p>
<p style="text-align: center;"><code class="reqn">\mu - \sigma * \gamma</code>
</p>

<p>and its variance is
</p>
<p style="text-align: center;"><code class="reqn">\sigma^2 * \pi^2 / 6</code>
</p>

<p>where <code class="reqn">\gamma</code> is Euler's constant (which can be
obtained as <code>-digamma(1)</code>).
</p>
<p>See <code><a href="#topic+gumbel">gumbel</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the two parameters by maximum likelihood estimation,
for formulae and other details.
Apart from <code>n</code>, all the above arguments may be vectors and
are recyled to the appropriate length if necessary.
</p>


<h3>Value</h3>

<p><code>dgumbel</code> gives the density,
<code>pgumbel</code> gives the distribution function,
<code>qgumbel</code> gives the quantile function, and
<code>rgumbel</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The <span class="pkg">VGAM</span> family function <code><a href="#topic+gumbel">gumbel</a></code>
can estimate the parameters of a Gumbel distribution using
maximum likelihood estimation.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gumbel">gumbel</a></code>,
<code><a href="#topic+gumbelff">gumbelff</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+dgompertz">dgompertz</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- 1; sigma &lt;- 2;
y &lt;- rgumbel(n = 100, loc = mu, scale = sigma)
c(mean(y), mu - sigma * digamma(1))  # Sample and population means
c(var(y), sigma^2 * pi^2 / 6)  # Sample and population variances

## Not run:  x &lt;- seq(-2.5, 3.5, by = 0.01)
loc &lt;- 0; sigma &lt;- 1
plot(x, dgumbel(x, loc, sigma), type = "l", col = "blue",
     main = "Blue is density, red is the CDF", ylim = c(0, 1),
     sub = "Purple are 5,10,...,95 percentiles", ylab = "", las = 1)
abline(h = 0, col = "blue", lty = 2)
lines(qgumbel(seq(0.05, 0.95, by = 0.05), loc, sigma),
  dgumbel(qgumbel(seq(0.05, 0.95, by = 0.05), loc, sigma), loc, sigma),
      col = "purple", lty = 3, type = "h")
lines(x, pgumbel(x, loc, sigma), type = "l", col = "red")
abline(h = 0, lty = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='guplot'> Gumbel Plot </h2><span id='topic+guplot'></span><span id='topic+guplot.default'></span><span id='topic+guplot.vlm'></span>

<h3>Description</h3>

<p>Produces a Gumbel plot,
a diagnostic plot for checking whether the data appears to be
from a Gumbel distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>guplot(object, ...)
guplot.default(y, main = "Gumbel Plot",
    xlab = "Reduced data", ylab = "Observed data", type = "p", ...)
guplot.vlm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="guplot_+3A_y">y</code></td>
<td>
<p> A numerical vector. <code>NA</code>s etc. are not allowed.</p>
</td></tr>
<tr><td><code id="guplot_+3A_main">main</code></td>
<td>
<p>Character. Overall title for the plot. </p>
</td></tr>
<tr><td><code id="guplot_+3A_xlab">xlab</code></td>
<td>
<p>Character. Title for the x axis. </p>
</td></tr>
<tr><td><code id="guplot_+3A_ylab">ylab</code></td>
<td>
<p>Character. Title for the y axis. </p>
</td></tr>
<tr><td><code id="guplot_+3A_type">type</code></td>
<td>
<p>Type of plot. The default means points are
plotted. </p>
</td></tr>
<tr><td><code id="guplot_+3A_object">object</code></td>
<td>
<p> An object that inherits class <code>"vlm"</code>,
usually of class <code><a href="#topic+vglm-class">vglm-class</a></code> or
<code><a href="#topic+vgam-class">vgam-class</a></code>.
</p>
</td></tr>
<tr><td><code id="guplot_+3A_...">...</code></td>
<td>
<p> Graphical argument passed into
<code><a href="graphics.html#topic+plot">plot</a></code>. See <code><a href="graphics.html#topic+par">par</a></code>
for an exhaustive list. The arguments <code>xlim</code> and
<code>ylim</code> are particularly useful.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">Y</code> has a Gumbel distribution then plotting the sorted
values <code class="reqn">y_i</code> versus the <em>reduced values</em> <code class="reqn">r_i</code> should
appear linear. The reduced values are given by
</p>
<p style="text-align: center;"><code class="reqn">r_i = -\log(-\log(p_i)) </code>
</p>

<p>where <code class="reqn">p_i</code> is the <code class="reqn">i</code>th plotting position, taken
here to be <code class="reqn">(i-0.5)/n</code>.
Here, <code class="reqn">n</code> is the number of observations.
Curvature upwards/downwards may indicate a Frechet/Weibull
distribution, respectively. Outliers may also be detected
using this plot.
</p>
<p>The function <code>guplot</code> is generic, and
<code>guplot.default</code> and <code>guplot.vlm</code> are some
methods functions for Gumbel plots.
</p>


<h3>Value</h3>

<p>A list is returned invisibly with the following components.
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The reduced data. </p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The sorted y data. </p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Gumbel distribution is a special case of the
GEV distribution with shape parameter equal to zero.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>
<p>Gumbel, E. J. (1958).
<em>Statistics of Extremes</em>.
New York, USA: Columbia University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gumbel">gumbel</a></code>,
<code><a href="#topic+gumbelff">gumbelff</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+venice">venice</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: guplot(rnorm(500), las = 1) -&gt; ii
names(ii)

guplot(with(venice, r1), col = "blue")  # Venice sea levels data

## End(Not run)</code></pre>

<hr>
<h2 id='has.interceptvlm'> Has a Fitted VGLM Got an Intercept Term? </h2><span id='topic+has.intercept'></span><span id='topic+has.interceptvlm'></span>

<h3>Description</h3>

<p>Looks at the <code>formula</code> to
see if it has an intercept term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>has.intercept(object, ...)
has.interceptvlm(object, form.number = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="has.interceptvlm_+3A_object">object</code></td>
<td>
<p> A fitted model object.
</p>
</td></tr>
<tr><td><code id="has.interceptvlm_+3A_form.number">form.number</code></td>
<td>
<p>Formula number, is 1 or 2.
which correspond to the arguments <code>formula</code>
and <code>form2</code> respectively.
</p>
</td></tr>
<tr><td><code id="has.interceptvlm_+3A_...">...</code></td>
<td>
<p>Arguments that are might be passed from
one function to another.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This methods function is a simple way to determine whether a
fitted <code><a href="#topic+vglm">vglm</a></code> object etc. has an intercept term
or not.
It is not entirely foolproof because one might suppress the
intercept from the formula and then add in a variable in the
formula that has a constant value.
</p>


<h3>Value</h3>

<p>Returns a single logical.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+formulavlm">formulavlm</a></code>,
<code>termsvlm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example: this is based on a glm example
counts &lt;- c(18,17,15,20,10,20,25,13,12)
outcome &lt;- gl(3, 1, 9); treatment &lt;- gl(3, 3)
pdata &lt;- data.frame(counts, outcome, treatment)  # Better style
vglm.D93 &lt;- vglm(counts ~ outcome + treatment, poissonff, data = pdata)
formula(vglm.D93)
term.names(vglm.D93)
responseName(vglm.D93)
has.intercept(vglm.D93)
</code></pre>

<hr>
<h2 id='hatvalues'>Hat Values and Regression Deletion Diagnostics</h2><span id='topic+hatvalues'></span><span id='topic+hatvaluesvlm'></span><span id='topic+hatplot'></span><span id='topic+hatplot.vlm'></span><span id='topic+dfbeta'></span><span id='topic+dfbetavlm'></span>

<h3>Description</h3>

<p>When complete, a
suite of functions that can be used to compute some of the
regression (leave-one-out deletion) diagnostics,
for the VGLM class.
</p>






<h3>Usage</h3>

<pre><code class='language-R'>hatvalues(model, ...)
hatvaluesvlm(model, type = c("diagonal", "matrix", "centralBlocks"), ...)
hatplot(model, ...)
hatplot.vlm(model, multiplier = c(2, 3), lty = "dashed",
            xlab = "Observation", ylab = "Hat values", ylim = NULL, ...)
dfbetavlm(model, maxit.new = 1,
          trace.new = FALSE,
          smallno = 1.0e-8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hatvalues_+3A_model">model</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object, typically returned by <code><a href="#topic+vglm">vglm</a></code>.

</p>
</td></tr>
<tr><td><code id="hatvalues_+3A_type">type</code></td>
<td>
<p>Character.
The default is the first choice, which is
a <code class="reqn">nM \times nM</code> matrix.
If <code>type = "matrix"</code> then the <em>entire</em> hat matrix is
returned.
If <code>type = "centralBlocks"</code> then <code class="reqn">n</code> central
<code class="reqn">M \times M</code> block matrices, in matrix-band format.
</p>
</td></tr>





<tr><td><code id="hatvalues_+3A_multiplier">multiplier</code></td>
<td>
<p>Numeric, the multiplier.
The usual rule-of-thumb is that values greater than two or three
times the average leverage (at least for the linear model) should
be checked.
</p>
</td></tr>
<tr><td><code id="hatvalues_+3A_lty">lty</code>, <code id="hatvalues_+3A_xlab">xlab</code>, <code id="hatvalues_+3A_ylab">ylab</code>, <code id="hatvalues_+3A_ylim">ylim</code></td>
<td>
<p>Graphical parameters, see
<code><a href="graphics.html#topic+par">par</a></code> etc.
The default of <code>ylim</code> is <code>c(0, max(hatvalues(model)))</code>
which means that if the horizontal dashed lines cannot be seen
then there are no particularly influential observations.
</p>
</td></tr>
<tr><td><code id="hatvalues_+3A_maxit.new">maxit.new</code>, <code id="hatvalues_+3A_trace.new">trace.new</code>, <code id="hatvalues_+3A_smallno">smallno</code></td>
<td>

<p>Having <code>maxit.new = 1</code> will give a one IRLS step approximation
from the ordinary solution (and no warnings!).
Else having <code>maxit.new = 10</code>, say, should usually mean
convergence will occur for all observations when they are
removed one-at-a-time.
Else having <code>maxit.new = 2</code>, say, should usually mean
some lack of convergence will occur when observations are
removed one-at-a-time.
Setting <code>trace.new = TRUE</code> will produce some running output
at each IRLS iteration and for each individual row of the model matrix.
The argument <code>smallno</code> multiplies each value of the
original prior weight (often unity); setting it identically
to zero will result in an error, but setting a very small value
effectively removes that observation.
</p>
</td></tr>












<tr><td><code id="hatvalues_+3A_...">...</code></td>
<td>
<p>further arguments,
for example, graphical parameters for <code>hatplot.vlm()</code>.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The invocation <code>hatvalues(vglmObject)</code> should return a
<code class="reqn">n \times M</code> matrix of the diagonal elements of the
hat (projection) matrix of a <code><a href="#topic+vglm">vglm</a></code> object.
To do this,
the QR decomposition of the object is retrieved or
reconstructed, and then straightforward calculations
are performed.
</p>
<p>The invocation <code>hatplot(vglmObject)</code> should plot
the diagonal of the hat matrix for each of the <code class="reqn">M</code>
linear/additive predictors.
By default, two horizontal dashed lines are added;
hat values higher than these ought to be checked.
</p>






























<h3>Note</h3>

<p>It is hoped, soon, that the full suite of functions described at
<code><a href="stats.html#topic+influence.measures">influence.measures</a></code> will be written for VGLMs.
This will enable general regression deletion diagnostics to be
available for the entire VGLM class.
</p>




<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="stats.html#topic+influence.measures">influence.measures</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Proportional odds model, p.179, in McCullagh and Nelder (1989)
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, cumulative, data = pneumo)
hatvalues(fit)  # n x M matrix, with positive values
all.equal(sum(hatvalues(fit)), fit@rank)  # Should be TRUE
## Not run:  par(mfrow = c(1, 2))
hatplot(fit, ylim = c(0, 1), las = 1, col = "blue") 
## End(Not run)
</code></pre>

<hr>
<h2 id='hdeff'> Hauck-Donner Effects: A Detection Test for Wald Tests </h2><span id='topic+hdeff'></span><span id='topic+hdeff.vglm'></span><span id='topic+hdeff.matrix'></span><span id='topic+hdeff.numeric'></span>

<h3>Description</h3>

<p>A detection test for the
Hauck-Donner effect on each regression coefficient
of a VGLM regression or 2 x 2 table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdeff(object, ...)
hdeff.vglm(object, derivative = NULL, se.arg = FALSE,
           subset = NULL, theta0 = 0, hstep = 0.005,
           fd.only = FALSE, ...)
hdeff.numeric(object, byrow = FALSE, ...)
hdeff.matrix(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdeff_+3A_object">object</code></td>
<td>

<p>Usually a <code><a href="#topic+vglm">vglm</a></code> object.
Although only a limited number of family functions have
an analytical solution to
the HDE detection test 
(<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+borel.tanner">borel.tanner</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+erlang">erlang</a></code>,
<code><a href="#topic+felix">felix</a></code>,
<code><a href="#topic+lindley">lindley</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+topple">topple</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+zipoissonff">zipoissonff</a></code>,
and
<code><a href="#topic+zipoisson">zipoisson</a></code>;
hopefully some more will be implemented in the short future!)
the finite-differences (FDs) method can be applied to almost all
<span class="pkg">VGAM</span> family functions to get a numerical solution.
</p>
<p>Alternatively <code>object</code> may represent a 2 x 2 table of
<em>positive</em> counts.
If so, then the first row corresponds
to <code class="reqn">x2=0</code> (baseline group)
and the second row <code class="reqn">x2=1</code>. The first column
corresponds to <code class="reqn">y=0</code> (failure) and
the second column <code class="reqn">y=1</code> (success).
</p>
<p>Another alternative is that <code>object</code> is
a numerical vector
of length 4, representing a 2 x 2 table
of <em>positive</em> counts.
If so then it is fed into <code>hdeff.matrix</code>
using
the argument <code>byrow</code>, which matches
<code><a href="base.html#topic+matrix">matrix</a></code>.
See the examples below.
</p>

</td></tr>
<tr><td><code id="hdeff_+3A_derivative">derivative</code></td>
<td>

<p>Numeric. Either 1 or 2.
Currently only a few models having
one linear predictor are handled
analytically for <code>derivative = 2</code>, e.g.,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
However, the numerical method can return the first two
derivatives for almost all models.
</p>
</td></tr>
<tr><td><code id="hdeff_+3A_se.arg">se.arg</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the derivatives
of the standard errors
are returned as well, because usually the derivatives of
the Wald statistics are of central interest.  Requires
<code>derivative</code> to be assigned the value 1 or 2 for this
argument to operate.
</p>
</td></tr>
<tr><td><code id="hdeff_+3A_subset">subset</code></td>
<td>

<p>Logical or vector of indices,
to select the regression coefficients of interest.
The default is to select all coefficients.
Recycled if necessary if logical.
If numeric then they should comprise
elements from <code>1:length(coef(object))</code>.
This argument can be useful for computing the derivatives of a
Cox regression (<code><a href="survival.html#topic+coxph">coxph</a></code>) fitted using artificially
created Poisson data; then there are many coefficients that
are effectively nuisance parameters.
</p>
</td></tr>
<tr><td><code id="hdeff_+3A_theta0">theta0</code></td>
<td>

<p>Numeric. Vector recycled to the necessary length which is
the number of regression coefficients.
The null hypotheses for the regression coefficients are that
they equal those respective values, and the alternative
hypotheses are all two-sided.
It is not recommended that argument <code>subset</code> be used
if a vector of values is assigned here because
<code>theta0[subset]</code> is implied and might not work.
</p>

</td></tr>
<tr><td><code id="hdeff_+3A_hstep">hstep</code></td>
<td>

<p>Positive numeric and recycled to length 2;
it is the so-called <em>step size</em> when using
finite-differences and is often called <code class="reqn">h</code> in
the calculus literature,
e.g., <code class="reqn">f'(x)</code> is approximately <code class="reqn">(f(x+h) - f(x)) / h</code>.
For the 2nd-order partial derivatives, there are two step sizes
and hence this argument is recycled to length 2.
The default is to have the same values.
The 1st-order derivatives use the first value only.
It is recommended that a few values of this argument be tried
because values of the first and second derivatives can
vary accordingly.
If any values are too large then the derivatives
may be inaccurate;
and if too small then the derivatives may be unstable and
subject to too much round-off/cancellation error
(in fact it may create an error or a <code>NA</code>).
</p>
</td></tr>
<tr><td><code id="hdeff_+3A_fd.only">fd.only</code></td>
<td>

<p>Logical;
if <code>TRUE</code> then finite-differences are used to estimate
the derivatives even if an analytical solution has been
coded, By default, finite-differences will be used when an
analytical solution has not been implemented.
</p>

<p>It is possible that <code>NA</code>s are returned.
If so, and if <code>fd.only = FALSE</code>, then a warning
is issued and a recursive
call is made with <code>fd.only = TRUE</code>&mdash;this is more
likely to return an answer without any <code>NA</code>s.
</p>

</td></tr>
<tr><td><code id="hdeff_+3A_byrow">byrow</code></td>
<td>

<p>Logical;
fed into <code><a href="base.html#topic+matrix">matrix</a></code> if <code>object</code> is
a vector of length 4 so that there are two choices in the
order of the elements.
</p>

</td></tr>
<tr><td><code id="hdeff_+3A_...">...</code></td>
<td>

<p>currently unused but may be used in the future for
further arguments passed into the other methods functions.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Almost all of statistical inference based on the likelihood
assumes that the parameter estimates are located in the interior
of the parameter space.  The nonregular case of being located
on the boundary is not considered very much and leads to
very different results from the regular case.  Practically,
an important question is: how close is close to the boundary?
One might answer this as: the parameter estimates are too close
to the boundary when the Hauck-Donner effect (HDE) is present,
whereby the Wald statistic becomes aberrant.
</p>
<p>Hauck and Donner (1977) first observed an aberration of the
Wald test statistic not monotonically increasing as a function
of increasing distance between the parameter estimate and the
null value.  This &quot;disturbing&quot; and &quot;undesirable&quot; underappreciated
effect has since been observed in other regression models by
various authors.  This function computes the first, and possibly
second, derivative of the Wald statistic for each regression
coefficient.  A negative value of the first derivative is
indicative of the HDE being present.  More information can be
obtained from <code><a href="#topic+hdeffsev">hdeffsev</a></code> regarding HDE severity:
there may be none, faint, weak, moderate, strong and extreme
amounts of HDE present.
</p>
<p>In general, most models have derivatives that are computed
numerically using finite-difference
approximations. The reason is that it takes a lot of work
to program in the analytical solution
(this includes a few very common models, such as
<code><a href="#topic+poissonff">poissonff</a></code> and
<code><a href="#topic+binomialff">binomialff</a></code>,
where the first two derivatives have been implemented).
</p>



<h3>Value</h3>

<p>By default this function returns a labelled logical vector;
a <code>TRUE</code> means the HDE is affirmative for that coefficient
(negative slope).
Hence ideally all values are <code>FALSE</code>.
Any <code>TRUE</code> values suggests that the MLE is
too near the boundary of the parameter space,
and that the p-value for that regression coefficient
is biased upwards.
When present
a highly significant variable might be deemed nonsignificant,
and thus the HDE can create havoc for variable selection.
If the HDE is present then more accurate
p-values can generally be obtained by conducting a
likelihood ratio test
(see <code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>)
or Rao's score test
(see <code><a href="#topic+score.stat.vlm">score.stat.vlm</a></code>);
indeed the default of
<code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>
does not suffer from the HDE.
</p>


<p>Setting <code>deriv = 1</code> returns a numerical vector of first
derivatives of the Wald statistics.
Setting <code>deriv = 2</code> returns a 2-column matrix of first
and second derivatives of the Wald statistics.
Then setting <code>se.arg = TRUE</code> returns an additional 1 or
2 columns.
</p>
<p>Some 2nd derivatives are <code>NA</code> if only a partial analytic
solution has been programmed in.
</p>
<p>For those <span class="pkg">VGAM</span> family functions whose HDE test has not
yet been implemented explicitly (the vast majority of them),
finite-difference approximations to the derivatives will
be used&mdash;see the arguments <code>hstep</code> and <code>fd.only</code>
for getting some control on them.
</p>


<h3>Note</h3>

<p>The function <code><a href="#topic+summaryvglm">summaryvglm</a></code> conducts the HDE
detection test if possible and prints out a line at the bottom
if the HDE is detected for some regression coefficients.
By &ldquo;if possible&rdquo;, only a few family functions are exempt and they
have an <code>infos</code> slot with component <code>hadof = FALSE</code>;
such as
<code><a href="#topic+normal.vcm">normal.vcm</a></code>,
<code><a href="#topic+rec.normal">rec.normal</a></code> because it
uses the BFGS-IRLS method for computing the working weights.
For these few a <code>NULL</code> is returned by <code><a href="#topic+hdeff">hdeff</a></code>.
</p>
<p>If the second derivatives are of interest then
it is recommended that <code>crit = "c"</code> be added to the
fitting so that a slightly more accurate model results
(usually one more IRLS iteration).
This is because the FD approximation is very sensitive to
values of the working weights, so they need to be computed
accurately.
Occasionally, if the coefficient is close to 0,
then its Wald statistic's
second derivative may be unusually large in magnitude
(this could be due to something such as roundoff error). 
</p>






<p>This function is currently under development
and may change a little in the short future.
For HDE severity measures see <code><a href="#topic+hdeffsev">hdeffsev</a></code>.
</p>










<h3>Author(s)</h3>

<p> Thomas W. Yee.  </p>


<h3>References</h3>

<p>Hauck, J. W. W. and A. Donner (1977).
Wald's test as applied to hypotheses in logit analysis. 
<em>Journal of the American Statistical Association</em>,
<b>72</b>, 851&ndash;853.
</p>








<p>Yee, T. W. (2022).
On the Hauck-Donner effect in Wald tests:
Detection, tipping points and parameter space characterization,
<em>Journal of the American Statistical Association</em>,
<b>117</b>, 1763&ndash;1774.
<a href="https://doi.org/10.1080/01621459.2021.1886936">doi:10.1080/01621459.2021.1886936</a>.
</p>


<p>Yee, T. W. (2021).
Some new results concerning the Hauck-Donner effect.
<em>Manuscript in preparation</em>.
</p>






<h3>See Also</h3>

<p><code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="#topic+hdeffsev">hdeffsev</a></code>,
<code><a href="#topic+alogitlink">alogitlink</a></code>,
<code><a href="#topic+asinlink">asinlink</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+lrt.stat">lrt.stat</a></code>,
<code><a href="#topic+score.stat">score.stat</a></code>,
<code><a href="#topic+wald.stat">wald.stat</a></code>,
<code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="#topic+profilevglm">profilevglm</a></code>.
</p>






<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, data = pneumo,
            trace = TRUE, crit = "c",  # Get some more accuracy
            cumulative(reverse = TRUE,  parallel = TRUE))
cumulative()@infos()$hadof  # Analytical solution implemented
hdeff(fit)
hdeff(fit, deriv = 1)  # Analytical solution
hdeff(fit, deriv = 2)  # It is a partial analytical solution
hdeff(fit, deriv = 2, se.arg = TRUE,
      fd.only = TRUE)  # All derivatives solved numerically by FDs

# 2 x 2 table of counts
R0 &lt;- 25; N0 &lt;- 100  # Hauck Donner (1977) data set
mymat &lt;- c(N0-R0, R0, 8, 92)  # HDE present
(mymat &lt;- matrix(mymat, 2, 2, byrow = TRUE))
hdeff(mymat)
hdeff(c(mymat))  # Input is a vector
hdeff(c(t(mymat)), byrow = TRUE)  # Reordering of the data
</code></pre>

<hr>
<h2 id='hdeffsev'> Hauck-Donner Effects: Severity Measures </h2><span id='topic+hdeffsev'></span>

<h3>Description</h3>

<p>Computes the severity of the
Hauck-Donner effect for each regression coefficient
of a VGLM regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hdeffsev(x, y, dy, ddy, allofit = FALSE, eta0 = 0, COPS0 = eta0,
         severity.table = c("None", "Faint", "Weak",
             "Moderate", "Strong", "Extreme", "Undetermined"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hdeffsev_+3A_x">x</code>, <code id="hdeffsev_+3A_y">y</code></td>
<td>

<p>Numeric vectors;
<code>x</code> are the estimates (sorted), and
<code>y</code> are the signed Wald statistics.
</p>
</td></tr>
<tr><td><code id="hdeffsev_+3A_dy">dy</code>, <code id="hdeffsev_+3A_ddy">ddy</code></td>
<td>

<p>Numeric vectors;
the first and second derivatives of the Wald statistics.
They can be computed by <code><a href="#topic+hdeff">hdeff</a></code>.
</p>
</td></tr>
<tr><td><code id="hdeffsev_+3A_allofit">allofit</code></td>
<td>

<p>Logical. If <code>TRUE</code> then other quantities are
returned in a list.
The default is a vector with elements selected from
the argument <code>severity.table</code>.
</p>
</td></tr>
<tr><td><code id="hdeffsev_+3A_severity.table">severity.table</code></td>
<td>

<p>Character vector with 6 values.
The last value is used for initialization.
Usually users should not assign anything to
this argument.
</p>



</td></tr>
<tr><td><code id="hdeffsev_+3A_eta0">eta0</code></td>
<td>

<p>Numeric. The hypothesized value.
The default is appropriate for most symmetric
binomial links,and also for Poisson regression
with the natural parameter.
</p>
</td></tr>
<tr><td><code id="hdeffsev_+3A_cops0">COPS0</code></td>
<td>

<p>Numeric. See Yee (2021).
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>This function is rough-and-ready.
It is possible to use the first two derivatives obtained
from <code><a href="#topic+hdeff">hdeff</a></code> to categorize the severity of the
the Hauck-Donner effect (HDE).
It is effectively assumed that, starting at
the origin
and going right,
the curve is made up of a convex segment followed by
a concave segment and then the convex segment.
Midway in the concave segment the derivative is 0, and
beyond that the HDE is really manifest because the
derivative is negative.
</p>
<p>For <code>"none"</code> the estimate lies on the convex
part of the curve near the origin, hence there is
very little HDE at all.
</p>
<p>For <code>"weak"</code> the estimate lies on the
concave part of the curve but the Wald statistic is still
increasing as estimate gets away from 0, hence it is only
a mild form of the HDE.
</p>
<p>Previously <code>"faint"</code> was used but now it has
been omitted.
</p>




<p>For <code>"moderate"</code>,
<code>"strong"</code>
and <code>"extreme"</code>
the Wald statistic is
decreasing as the estimate gets away from <code>eta0</code>,
hence it
really does exhibit the HDE.
It is recommended that <code><a href="#topic+lrt.stat">lrt.stat</a></code> be used
to compute
LRT p-values, as they do not suffer from the HDE.
</p>


<h3>Value</h3>

<p>By default this function returns a labelled vector with
elements selected from
<code>severity.table</code>.
If <code>allofit = TRUE</code> then Yee (2022) gives details
about some of the other list components,
e.g., a quantity called
<code>zeta</code> is the normal line projected onto the x-axis,
and its first derivative gives additional
information about the position
of the estimate along the curve.
</p>


<h3>Note</h3>

<p>This function is likely to change in the short future
because it is experimental and far from complete.
Improvements are intended.
</p>
<p>Currently,
in order for <code>"Strong"</code> to be assigned correctly,
at least one such value is needed on the
LHS and/or RHS each. From those, two other boundary
points are obtained so that it creates two intervals.
</p>








<h3>Author(s)</h3>

<p> Thomas W. Yee.  </p>


<h3>References</h3>

<p>Yee, T. W. (2022).
On the Hauck-Donner effect in Wald tests:
Detection, tipping points and parameter space characterization,
<em>Journal of the American Statistical Association</em>,
<b>117</b>, 1763&ndash;1774.
<a href="https://doi.org/10.1080/01621459.2021.1886936">doi:10.1080/01621459.2021.1886936</a>.
</p>


<p>Yee, T. W. (2022).
Some new results concerning the Wald tests and
the parameter space.
<em>In review</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+seglines">seglines</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>deg &lt;- 4  # myfun is a function that approximates the HDE
myfun &lt;- function(x, deriv = 0) switch(as.character(deriv),
  '0' = x^deg * exp(-x),
  '1' = (deg * x^(deg-1) - x^deg) * exp(-x),
  '2' = (deg*(deg-1)*x^(deg-2) - 2*deg*x^(deg-1) + x^deg)*exp(-x))

xgrid &lt;- seq(0, 10, length = 101)
ansm &lt;- hdeffsev(xgrid, myfun(xgrid), myfun(xgrid, deriv = 1),
                 myfun(xgrid, deriv = 2), allofit = TRUE)
digg &lt;- 4
cbind(severity = ansm$sev, 
      fun      = round(myfun(xgrid), digg),
      deriv1   = round(myfun(xgrid, deriv = 1), digg),
      deriv2   = round(myfun(xgrid, deriv = 2), digg),
      zderiv1  = round(1 + (myfun(xgrid, deriv = 1))^2 +
                       myfun(xgrid, deriv = 2) * myfun(xgrid), digg))
</code></pre>

<hr>
<h2 id='hormone'>
Hormone Assay Data
</h2><span id='topic+hormone'></span>

<h3>Description</h3>

<p>A hormone assay data set from Carroll and Ruppert (1988).
</p>



<h3>Usage</h3>

<pre><code class='language-R'>data(hormone)</code></pre>


<h3>Format</h3>

<p>A data frame with 85 observations on the following 2 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>a numeric vector, suitable as the x-axis in
a scatter plot.
The reference method.
</p>
</dd>
<dt><code>Y</code></dt><dd><p>a numeric vector, suitable as the y-axis in
a scatter plot.
The test method.
</p>
</dd>
</dl>



<h3>Details</h3>


<p>The data is given in Table 2.4 of
Carroll and Ruppert (1988), and was downloaded
from <code>http://www.stat.tamu.edu/~carroll</code>
prior to 2019.
The book describes the data as follows.
The data are the results of two assay methods for hormone
data; the scale of the data as presented is not
particularly meaningful, and the original source
of the data refused permission to divulge further
information. As in a similar example of
Leurgans (1980), the old or reference method is
being used to predict the new or test method.
The overall goal is to see whether we can reproduce
the test-method measurements with the reference-method
measurements.
Thus calibration might be of interest for the data.
</p>



<h3>References</h3>

<p>Carroll, R. J. and Ruppert, D. (1988).
<em>Transformation and Weighting in Regression</em>.
New York, USA: Chapman &amp; Hall.
</p>
<p>Leurgans, S. (1980).
Evaluating laboratory measurement techniques.
<em>Biostatistics Casebook</em>.
Eds.: Miller, R. G. Jr., and Efron, B. and
Brown, B. W. Jr., and Moses, L.
New York, USA: Wiley.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models with two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(hormone)
summary(hormone)

modelI &lt;-rrvglm(Y ~ 1 + X, data = hormone, trace = TRUE,
                uninormal(zero = NULL, lsd = "identitylink", imethod = 2))

# Alternative way to fit modelI
modelI.other &lt;- vglm(Y ~ 1 + X, data = hormone, trace = TRUE,
                     uninormal(zero = NULL, lsd = "identitylink"))

# Inferior to modelI
modelII &lt;- vglm(Y ~ 1 + X, data = hormone, trace = TRUE,
                family = uninormal(zero = NULL))

logLik(modelI)
logLik(modelII)  # Less than logLik(modelI)


# Reproduce the top 3 equations on p.65 of Carroll and Ruppert (1988).
# They are called Equations (1)--(3) here.

# Equation (1)
hormone &lt;- transform(hormone, rX = 1 / X)
clist &lt;- list("(Intercept)" = diag(2), X = diag(2), rX = rbind(0, 1))
fit1 &lt;- vglm(Y ~ 1 + X + rX, family = uninormal(zero = NULL),
             constraints = clist, data = hormone, trace = TRUE)
coef(fit1, matrix = TRUE)
summary(fit1)  # Actually, the intercepts do not seem significant
plot(Y ~ X, hormone, col = "blue")
lines(fitted(fit1) ~ X, hormone, col = "orange")

# Equation (2)
fit2 &lt;- rrvglm(Y ~ 1 + X, uninormal(zero = NULL), hormone, trace = TRUE)
coef(fit2, matrix = TRUE)
plot(Y ~ X, hormone, col = "blue")
lines(fitted(fit2) ~ X, hormone, col = "red")
# Add +- 2 SEs
lines(fitted(fit2) + 2 * exp(predict(fit2)[, "loglink(sd)"]) ~ X,
      hormone, col = "orange")
lines(fitted(fit2) - 2 * exp(predict(fit2)[, "loglink(sd)"]) ~ X,
      hormone, col = "orange")

# Equation (3)
# Does not fit well because the loglink link for the mean is not good.
fit3 &lt;- rrvglm(Y ~ 1 + X, maxit = 300, data = hormone, trace = TRUE,
               uninormal(lmean = "loglink", zero = NULL))
coef(fit3, matrix = TRUE)
plot(Y ~ X, hormone, col = "blue")  # Does not look okay.
lines(exp(predict(fit3)[, 1]) ~ X, hormone, col = "red")
# Add +- 2 SEs
lines(fitted(fit3) + 2 * exp(predict(fit3)[, "loglink(sd)"]) ~ X,
      hormone, col = "orange")
lines(fitted(fit3) - 2 * exp(predict(fit3)[, "loglink(sd)"]) ~ X,
      hormone, col = "orange")

## End(Not run)
</code></pre>

<hr>
<h2 id='hspider'> Hunting Spider Data </h2><span id='topic+hspider'></span>

<h3>Description</h3>

<p>Abundance of hunting spiders in a Dutch dune area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hspider)</code></pre>


<h3>Format</h3>

<p>A data frame with 28 observations
(sites) on the following 18 variables.
</p>

<dl>
<dt>WaterCon</dt><dd><p>Log percentage of soil dry mass.</p>
</dd>
<dt>BareSand</dt><dd><p>Log percentage cover of bare sand.</p>
</dd>
<dt>FallTwig</dt><dd><p>Log percentage cover of fallen leaves and twigs.</p>
</dd>
<dt>CoveMoss</dt><dd><p>Log percentage cover of the moss layer.</p>
</dd>
<dt>CoveHerb</dt><dd><p>Log percentage cover of the herb layer.</p>
</dd>
<dt>ReflLux</dt><dd><p>Reflection of the soil surface with cloudless sky.</p>
</dd>
<dt>Alopacce</dt><dd><p>Abundance of <em>Alopecosa accentuata</em>.</p>
</dd>
<dt>Alopcune</dt><dd><p>Abundance of <em>Alopecosa cuneata</em>.</p>
</dd>
<dt>Alopfabr</dt><dd><p>Abundance of <em>Alopecosa fabrilis</em>.</p>
</dd>
<dt>Arctlute</dt><dd><p>Abundance of <em>Arctosa lutetiana</em>.</p>
</dd>
<dt>Arctperi</dt><dd><p>Abundance of <em>Arctosa perita</em>.</p>
</dd>
<dt>Auloalbi</dt><dd><p>Abundance of <em>Aulonia albimana</em>.</p>
</dd>
<dt>Pardlugu</dt><dd><p>Abundance of <em>Pardosa lugubris</em>.</p>
</dd>
<dt>Pardmont</dt><dd><p>Abundance of <em>Pardosa monticola</em>.</p>
</dd>
<dt>Pardnigr</dt><dd><p>Abundance of <em>Pardosa nigriceps</em>.</p>
</dd>
<dt>Pardpull</dt><dd><p>Abundance of <em>Pardosa pullata</em>.</p>
</dd>
<dt>Trocterr</dt><dd><p>Abundance of <em>Trochosa terricola</em>.</p>
</dd>
<dt>Zoraspin</dt><dd><p>Abundance of <em>Zora spinimana</em>.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data, which originally came from Van der Aart
and Smeek-Enserink
(1975) consists of abundances (numbers trapped
over a 60 week period)
and 6 environmental variables. There were 28 sites.
</p>
<p>This data set has been often used to illustrate
ordination, e.g., using
canonical correspondence analysis (CCA).
In the example below, the
data is used for constrained quadratic ordination
(CQO; formerly called
canonical Gaussian ordination or CGO),
a numerically intensive method
that has many superior qualities.
See <code><a href="#topic+cqo">cqo</a></code> for details.
</p>


<h3>References</h3>

<p>Van der Aart, P. J. M. and Smeek-Enserink, N. (1975).
Correlations between distributions of hunting spiders
(Lycosidae, Ctenidae) and environmental characteristics
in a dune area.
<em>Netherlands Journal of Zoology</em>,
<b>25</b>, 1&ndash;45.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(hspider)

## Not run: 
# Standardize the environmental variables:
hspider[, 1:6] &lt;- scale(subset(hspider, select = WaterCon:ReflLux))

# Fit a rank-1 binomial CAO
hsbin &lt;- hspider  # Binary species data
hsbin[, -(1:6)] &lt;- as.numeric(hsbin[, -(1:6)] &gt; 0)
set.seed(123)
ahsb1 &lt;- cao(cbind(Alopcune, Arctlute, Auloalbi, Zoraspin) ~
             WaterCon + ReflLux,
             family = binomialff(multiple.responses = TRUE),
             df1.nl = 2.2, Bestof = 3, data = hsbin)
par(mfrow = 2:1, las = 1)
lvplot(ahsb1, type = "predictors", llwd = 2,
       ylab = "logitlink(p)", lcol = 1:9)
persp(ahsb1, rug = TRUE, col = 1:10, lwd = 2)
coef(ahsb1)

## End(Not run)
</code></pre>

<hr>
<h2 id='huber2'> Huber's Least Favourable Distribution Family Function </h2><span id='topic+huber2'></span><span id='topic+huber1'></span>

<h3>Description</h3>

<p>M-estimation of the two parameters of
Huber's least favourable distribution.
The one parameter case is also implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber1(llocation = "identitylink", k = 0.862, imethod = 1)
huber2(llocation = "identitylink", lscale = "loglink",
       k = 0.862, imethod = 1, zero = "scale")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="huber2_+3A_llocation">llocation</code>, <code id="huber2_+3A_lscale">lscale</code></td>
<td>

<p>Link functions applied to the location and scale parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="huber2_+3A_k">k</code></td>
<td>

<p>Tuning constant.
See <code><a href="#topic+rhuber">rhuber</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="huber2_+3A_imethod">imethod</code>, <code id="huber2_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
The default value of <code>zero</code> means the scale parameter is
modelled as intercept-only.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Huber's least favourable distribution family function is popular
for resistant/robust regression. The center of the distribution
is normal and its tails are double exponential.
</p>
<p>By default, the mean is the first linear/additive predictor
(returned as the fitted values; this is the location parameter),
and the log of the scale parameter is the second linear/additive
predictor.  The Fisher information matrix is diagonal; Fisher
scoring is implemented.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>huber1()</code> estimates only the
location parameter. It assumes a scale parameter of unit value.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Warning: actually, <code>huber2()</code> may be erroneous since the
first derivative is not continuous when there are two parameters
to estimate. <code>huber1()</code> is fine in this respect.
</p>
<p>The response should be univariate.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
Help was given by Arash Ardalan.
</p>


<h3>References</h3>

<p>Huber, P. J. and Ronchetti, E. (2009).
<em>Robust Statistics</em>, 2nd ed. New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rhuber">rhuber</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+laplace">laplace</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1231); NN &lt;- 30; coef1 &lt;- 1; coef2 &lt;- 10
hdata &lt;- data.frame(x2 = sort(runif(NN)))
hdata &lt;- transform(hdata, y  = rhuber(NN, mu = coef1 + coef2 * x2))

hdata$x2[1] &lt;- 0.0  # Add an outlier
hdata$y[1] &lt;- 10

fit.huber2 &lt;- vglm(y ~ x2, huber2(imethod = 3), hdata, trace = TRUE)
fit.huber1 &lt;- vglm(y ~ x2, huber1(imethod = 3), hdata, trace = TRUE)

coef(fit.huber2, matrix = TRUE)
summary(fit.huber2)


## Not run:  # Plot the results
plot(y ~ x2, data = hdata, col = "blue", las = 1)
lines(fitted(fit.huber2) ~ x2, data = hdata, col = "darkgreen", lwd = 2)

fit.lm &lt;- lm(y ~ x2, hdata)  # Compare to a LM:
lines(fitted(fit.lm) ~ x2, data = hdata, col = "lavender", lwd = 3)

# Compare to truth:
lines(coef1 + coef2 * x2 ~ x2, data = hdata, col = "orange",
      lwd = 2, lty = "dashed")

legend("bottomright", legend = c("truth", "huber", "lm"),
       col = c("orange", "darkgreen", "lavender"),
       lty = c("dashed", "solid", "solid"), lwd = c(2, 2, 3)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Huggins89.t1'>
Table 1 of Huggins (1989)
</h2><span id='topic+Huggins89.t1'></span><span id='topic+Huggins89table1'></span>

<h3>Description</h3>

<p>Simulated capture data set for the linear logistic model
depending on an occasion covariate and an individual
covariate for 10 trapping occasions and 20 individuals.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>data(Huggins89table1)
data(Huggins89.t1)
</code></pre>


<h3>Format</h3>

<p>The format is a data frame.
</p>



<h3>Details</h3>

<p>Table 1 of Huggins (1989) gives this toy data set.
Note that variables <code>t1</code>,...,<code>t10</code> are
occasion-specific variables. They correspond to the
response variables <code>y1</code>,...,<code>y10</code> which
have values 1 for capture and 0 for not captured.
</p>
<p>Both <code>Huggins89table1</code> and <code>Huggins89.t1</code>
are identical.
The latter used variables beginning with <code>z</code>,
not <code>t</code>, and may be withdrawn very soon.
</p>



<h3>References</h3>

<p>Huggins, R. M. (1989).
On the statistical analysis of capture experiments.
<em>Biometrika</em>,
<b>76</b>, 133&ndash;140.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Huggins89table1 &lt;-
  transform(Huggins89table1, x3.tij = t01,
            T02 = t02, T03 = t03, T04 = t04, T05 = t05, T06 = t06,
            T07 = t07, T08 = t08, T09 = t09, T10 = t10)
small.table1 &lt;- subset(Huggins89table1,
  y01 + y02 + y03 + y04 + y05 + y06 + y07 + y08 + y09 + y10 &gt; 0)
# fit.tbh is the bottom equation on p.133.
# It is a M_tbh model.
fit.tbh &lt;-
  vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10) ~
       x2 + x3.tij,
       xij = list(x3.tij ~ t01 + t02 + t03 + t04 + t05 +
                           t06 + t07 + t08 + t09 + t10 +
                           T02 + T03 + T04 + T05 + T06 +
                           T07 + T08 + T09 + T10 - 1),
       posbernoulli.tb(parallel.t = TRUE ~ x2 + x3.tij),
       data = small.table1, trace = TRUE,
       form2 = ~  x2 + x3.tij +
                  t01 + t02 + t03 + t04 + t05 + t06 +
                  t07 + t08 + t09 + t10 +
                  T02 + T03 + T04 + T05 + T06 +
                  T07 + T08 + T09 + T10)

# These results differ a bit from Huggins (1989), probably because
# two animals had to be removed here (they were never caught):
coef(fit.tbh)  # First element is the behavioural effect
sqrt(diag(vcov(fit.tbh)))  # SEs
constraints(fit.tbh, matrix = TRUE)
summary(fit.tbh, presid = FALSE)
fit.tbh@extra$N.hat     # Estimate of the population site N; cf. 20.86
fit.tbh@extra$SE.N.hat  # Its standard error; cf. 1.87 or 4.51

fit.th &lt;-
  vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10) ~ x2,
       posbernoulli.t, data = small.table1, trace = TRUE)
coef(fit.th)
constraints(fit.th)
coef(fit.th, matrix = TRUE)  # M_th model
summary(fit.th, presid = FALSE)
fit.th@extra$N.hat     # Estimate of the population size N
fit.th@extra$SE.N.hat  # Its standard error

fit.bh &lt;-
  vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10) ~ x2,
       posbernoulli.b(I2 = FALSE), data = small.table1, trace = TRUE)
coef(fit.bh)
constraints(fit.bh)
coef(fit.bh, matrix = TRUE)  # M_bh model
summary(fit.bh, presid = FALSE)
fit.bh@extra$N.hat
fit.bh@extra$SE.N.hat

fit.h &lt;-
  vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10) ~ x2,
       posbernoulli.b, data = small.table1, trace = TRUE)
coef(fit.h, matrix = TRUE)  # M_h model (version 1)
coef(fit.h)
summary(fit.h, presid = FALSE)
fit.h@extra$N.hat
fit.h@extra$SE.N.hat

Fit.h &lt;-
  vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10) ~ x2,
       posbernoulli.t(parallel.t = TRUE ~ x2),
       data = small.table1, trace = TRUE)
coef(Fit.h)
coef(Fit.h, matrix = TRUE)  # M_h model (version 2)
summary(Fit.h, presid = FALSE)
Fit.h@extra$N.hat
Fit.h@extra$SE.N.hat

## End(Not run)</code></pre>

<hr>
<h2 id='hunua'>Hunua Ranges Data</h2><span id='topic+hunua'></span>

<h3>Description</h3>

<p>The <code>hunua</code> data frame has 392 rows and 18 columns.
Altitude is explanatory, and there are binary responses
(presence/absence = 1/0 respectively) for 17 plant species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hunua)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>agaaus</dt><dd><p>Agathis australis, or Kauri</p>
</dd>
<dt>beitaw</dt><dd><p>Beilschmiedia tawa, or Tawa</p>
</dd>
<dt>corlae</dt><dd><p>Corynocarpus laevigatus</p>
</dd>
<dt>cyadea</dt><dd><p>Cyathea dealbata</p>
</dd>
<dt>cyamed</dt><dd><p>Cyathea medullaris</p>
</dd>
<dt>daccup</dt><dd><p>Dacrydium cupressinum</p>
</dd>
<dt>dacdac</dt><dd><p>Dacrycarpus dacrydioides</p>
</dd>
<dt>eladen</dt><dd><p>Elaecarpus dentatus</p>
</dd>
<dt>hedarb</dt><dd><p>Hedycarya arborea</p>
</dd>
<dt>hohpop</dt><dd><p>Species name unknown</p>
</dd>
<dt>kniexc</dt><dd><p>Knightia excelsa, or Rewarewa</p>
</dd>
<dt>kuneri</dt><dd><p>Kunzea ericoides</p>
</dd>
<dt>lepsco</dt><dd><p>Leptospermum scoparium</p>
</dd>
<dt>metrob</dt><dd><p>Metrosideros robusta</p>
</dd>
<dt>neslan</dt><dd><p>Nestegis lanceolata</p>
</dd>
<dt>rhosap</dt><dd><p>Rhopalostylis sapida</p>
</dd>
<dt>vitluc</dt><dd><p>Vitex lucens, or Puriri</p>
</dd>
<dt>altitude</dt><dd><p>meters above sea level</p>
</dd>
</dl>



<h3>Details</h3>

<p>These were collected from the Hunua Ranges, a small forest in southern
Auckland, New Zealand. At 392 sites in the forest, the presence/absence
of 17 plant species was recorded, as well as the altitude.
Each site was of area size 200<code class="reqn">m^2</code>.
</p>


<h3>Source</h3>

<p>Dr Neil Mitchell, University of Auckland.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+waitakere">waitakere</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a GAM using vgam() and compare it with the Waitakere Ranges one
fit.h &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, data = hunua)
## Not run: 
plot(fit.h, se = TRUE, lcol = "orange", scol = "orange",
     llwd = 2, slwd = 2, main = "Orange is Hunua, Blue is Waitakere") 
## End(Not run)
head(predict(fit.h, hunua, type = "response"))

fit.w &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, data = waitakere)
## Not run: 
plot(fit.w, se = TRUE, lcol = "blue", scol = "blue", add = TRUE) 
## End(Not run)
head(predict(fit.w, hunua, type = "response"))   # Same as above?
</code></pre>

<hr>
<h2 id='hurea'> Husler-Reiss Angular Surface
Distribution Family Function </h2><span id='topic+hurea'></span>

<h3>Description</h3>

<p>Estimating the parameter of the Husler-Reiss
angular surface distribution by
maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hurea(lshape = "loglink", zero = NULL, nrfs = 1,
      gshape = exp(3 * ppoints(5) - 1), parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hurea_+3A_lshape">lshape</code>, <code id="hurea_+3A_gshape">gshape</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="hurea_+3A_nrfs">nrfs</code>, <code id="hurea_+3A_zero">zero</code>, <code id="hurea_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Husler-Reiss angular surface distribution
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y;s) = (s / (4 * sqrt(2*pi) * y(1-y)^2))
    exp(-(2 + s^2 * logit y)^2 / [8 s^2])</code>
</p>

<p>for <code class="reqn">0&lt;y&lt;1</code> and positive shape parameter <code class="reqn">s</code>.
The mean of <code class="reqn">Y</code> is currently unknown to me,
as well as its quantiles.
Hence <code class="reqn">s</code> is currently returned as the
fitted values.
Fisher-scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This <span class="pkg">VGAM</span> family function handles multiple responses.
It may struggle and/or fail
when <code class="reqn">s</code> is close to 0.
Some comments about &ldquo;u&rdquo;-shaped versus unimodal
densities accommodated by this distribution
are at <code><a href="#topic+dhurea">dhurea</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Mhalla, L. and de Carvalho, M. and Chavez-Demoulin,
V. (2019).
Regression-type models for extremal dependence.
<em>Scandinavian Journal of Statistics</em>,
<b>46</b>, 1141&ndash;1167.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hurea">hurea</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 100; set.seed(1)
hdata &lt;- data.frame(x2 = runif(nn))
hdata &lt;-
  transform(hdata,  # Cannot generate proper random variates!
    y1 = rbeta(nn, shape1 = 0.5, shape2 = 0.5),  # "U" shaped
    y2 = rnorm(nn, 0.65, sd = exp(-3 - 4 * x2)))
# Multiple responses:
hfit &lt;- vglm(cbind(y1, y2) ~ x2, hurea, hdata, trace = TRUE)
coef(hfit, matrix = TRUE)
summary(hfit)
</code></pre>

<hr>
<h2 id='Hurea'>The Husler-Reiss Angular Surface Distribution</h2><span id='topic+Hurea'></span><span id='topic+dhurea'></span>

<h3>Description</h3>

<p>Density
for the Husler-Reiss angular surface distribution.
</p>




<h3>Usage</h3>

<pre><code class='language-R'>dhurea(x, shape, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hurea_+3A_x">x</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+Uniform">Uniform</a></code>.
</p>
</td></tr>
<tr><td><code id="Hurea_+3A_shape">shape</code></td>
<td>
<p>the positive (shape) parameter.
It is often called <code class="reqn">lambda</code> and
it might not be a shape parameter at all.
</p>
</td></tr>
<tr><td><code id="Hurea_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the
density is returned.
</p>
</td></tr>




</table>


<h3>Details</h3>

<p>See <code><a href="#topic+hurea">hurea</a></code>, the <span class="pkg">VGAM</span>
family function for
estimating the (shape) parameter <code class="reqn">s</code> by
maximum likelihood
estimation, for the formula of the
probability density function.
</p>


<h3>Value</h3>

<p><code>dhurea</code> gives the density.
</p>





<h3>Warning</h3>

<p>The cases <code>x == 0</code>, <code>x == 1</code>,
<code>shape == 0</code> and
<code>shape == Inf</code>
may not be handled correctly.
</p>


<h3>Note</h3>

<p>Difficulties are encountered as
the shape parameter approaches 0 with
respect to <code><a href="stats.html#topic+integrate">integrate</a></code>
because the density converges to a degenerate
distribution with probability mass at 0 and 1.
That is, when <code class="reqn">s</code> is around 0.5 the
density is &ldquo;u&rdquo; shaped and the area around the
endpoints becomes concentrated at the
two points.
See the examples below.
Approximately, the 
density is &ldquo;u&rdquo; shaped for <code class="reqn">s &lt; 1</code>
and unimodal for <code class="reqn">s &gt; 2</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+hurea">hurea</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>integrate(dhurea, 0, 1, shape = 0.20)  # Incorrect
integrate(dhurea, 0, 1, shape = 0.35)  # struggling but okay
## Not run: x &lt;- seq(0, 1, length = 501)
par(mfrow = c(2, 2))
plot(x, dhurea(x, 0.7), col = "blue", type = "l")
plot(x, dhurea(x, 1.1), col = "blue", type = "l")
plot(x, dhurea(x, 1.4), col = "blue", type = "l")
plot(x, dhurea(x, 3.0), col = "blue", type = "l")

## End(Not run)
</code></pre>

<hr>
<h2 id='hyperg'> Hypergeometric Family Function </h2><span id='topic+hyperg'></span>

<h3>Description</h3>

<p>Family function for a hypergeometric distribution where either the
number of white balls or the total number of white and black balls
are unknown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hyperg(N = NULL, D = NULL, lprob = "logitlink", iprob = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hyperg_+3A_n">N</code></td>
<td>

<p>Total number of white and black balls in the urn.
Must be a vector with positive values, and is recycled, if necessary,
to the same length as the response.
One of <code>N</code> and <code>D</code> must be specified.
</p>
</td></tr>
<tr><td><code id="hyperg_+3A_d">D</code></td>
<td>

<p>Number of white balls in the urn.
Must be a vector with positive values, and is recycled, if necessary,
to the same length as the response.
One of <code>N</code> and <code>D</code> must be specified.
</p>
</td></tr>
<tr><td><code id="hyperg_+3A_lprob">lprob</code></td>
<td>

<p>Link function for the probabilities.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="hyperg_+3A_iprob">iprob</code></td>
<td>

<p>Optional initial value for the probabilities.
The default is to choose initial values internally.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider the scenario from
<code><a href="stats.html#topic+dhyper">dhyper</a></code> where there
are <code class="reqn">N=m+n</code> balls in an urn, where <code class="reqn">m</code> are white and <code class="reqn">n</code>
are black. A simple random sample (i.e., <em>without</em> replacement) of
<code class="reqn">k</code> balls is taken.
The response here is the sample <em>proportion</em> of white balls.
In this document,
<code>N</code> is <code class="reqn">N=m+n</code>,
<code>D</code> is <code class="reqn">m</code> (for the number of &ldquo;defectives&rdquo;, in quality
control terminology, or equivalently, the number of marked individuals).
The parameter to be estimated is the population proportion of
white balls, viz. <code class="reqn">prob = m/(m+n)</code>.
</p>
<p>Depending on which one of <code>N</code> and <code>D</code> is inputted, the
estimate of the other parameter can be obtained from the equation
<code class="reqn">prob = m/(m+n)</code>, or equivalently, <code>prob = D/N</code>.  However,
the log-factorials are computed using <code><a href="base.html#topic+lgamma">lgamma</a></code>
and both <code class="reqn">m</code> and <code class="reqn">n</code> are not restricted to being integer.
Thus if an integer <code class="reqn">N</code> is to be estimated, it will be necessary to
evaluate the likelihood function at integer values about the estimate,
i.e., at <code>trunc(Nhat)</code> and <code>ceiling(Nhat)</code> where <code>Nhat</code>
is the (real) estimate of <code class="reqn">N</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
and <code><a href="#topic+cao">cao</a></code>.
</p>


<h3>Warning </h3>

<p>No checking is done to ensure that certain values are within range,
e.g., <code class="reqn">k \leq N</code>.
</p>


<h3>Note</h3>

<p>The response can be of one of three formats: a factor (first
level taken as success), a vector of proportions of success,
or a 2-column matrix (first column = successes) of counts.
The argument <code>weights</code> in the modelling function can also be
specified. In particular, for a general vector of proportions,
you will need to specify <code>weights</code> because the number of
trials is needed.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dhyper">dhyper</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 100
m &lt;- 5  # Number of white balls in the population
k &lt;- rep(4, len = nn)  # Sample sizes
n &lt;- 4  # Number of black balls in the population
y  &lt;- rhyper(nn = nn, m = m, n = n, k = k)
yprop &lt;- y / k  # Sample proportions

# N is unknown, D is known. Both models are equivalent:
fit &lt;- vglm(cbind(y,k-y) ~ 1, hyperg(D = m), trace = TRUE, crit = "c")
fit &lt;- vglm(yprop ~ 1, hyperg(D = m), weight = k, trace = TRUE, crit = "c")

# N is known, D is unknown. Both models are equivalent:
fit &lt;- vglm(cbind(y, k-y) ~ 1, hyperg(N = m+n), trace = TRUE, crit = "l")
fit &lt;- vglm(yprop ~ 1, hyperg(N = m+n), weight = k, trace = TRUE, crit = "l")

coef(fit, matrix = TRUE)
Coef(fit)  # Should be equal to the true population proportion
unique(m / (m+n))  # The true population proportion
fit@extra
head(fitted(fit))
summary(fit)
</code></pre>

<hr>
<h2 id='hypersecant'> Hyperbolic Secant Regression Family Function </h2><span id='topic+hypersecant'></span><span id='topic+hypersecant01'></span><span id='topic+nef.hs'></span>

<h3>Description</h3>

<p>Estimation of the parameter of the hyperbolic secant
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  hypersecant(link.theta = extlogitlink(min = -pi/2, max = pi/2),
              init.theta = NULL)
hypersecant01(link.theta = extlogitlink(min = -pi/2, max = pi/2),
              init.theta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hypersecant_+3A_link.theta">link.theta</code></td>
<td>

<p>Parameter link function applied to the
parameter <code class="reqn">\theta</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="hypersecant_+3A_init.theta">init.theta</code></td>
<td>

<p>Optional initial value for <code class="reqn">\theta</code>.
If failure to converge occurs, try some other value.
The default means an initial value is determined internally.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function of the
hyperbolic secant distribution
is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y;\theta) =
    \exp(\theta y + \log(\cos(\theta ))) / (2 \cosh(\pi y/2)),</code>
</p>

<p>for parameter <code class="reqn">-\pi/2 &lt; \theta &lt; \pi/2</code>
and all real <code class="reqn">y</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">\tan(\theta)</code>
(returned as the fitted values).
Morris (1982) calls this model NEF-HS
(Natural Exponential Family-Hyperbolic Secant).
It is used to generate NEFs, giving rise to the class of NEF-GHS
(G for Generalized).
</p>
<p>Another parameterization is used for <code>hypersecant01()</code>:
let <code class="reqn">Y = (logit U) / \pi</code>.
Then this uses
</p>
<p style="text-align: center;"><code class="reqn">f(u;\theta)=(\cos(\theta)/\pi) \times
                         u^{-0.5+\theta/\pi} \times
                     (1-u)^{-0.5-\theta/\pi},</code>
</p>

<p>for
parameter <code class="reqn">-\pi/2 &lt; \theta &lt; \pi/2</code>
and <code class="reqn">0 &lt; u &lt; 1</code>.
Then the mean of <code class="reqn">U</code>
is <code class="reqn">0.5 + \theta/\pi</code>
(returned as the fitted values) and the variance is
<code class="reqn">(\pi^2 - 4 \theta^2) / (8\pi^2)</code>.
</p>
<p>For both parameterizations Newton-Raphson is
same as Fisher scoring.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Jorgensen, B. (1997).
<em>The Theory of Dispersion Models</em>.
London: Chapman &amp; Hall.


</p>
<p>Morris, C. N. (1982).
Natural exponential families with quadratic variance functions.
<em>The Annals of Statistics</em>,
<b>10</b>(1), 65&ndash;80.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensh">gensh</a></code>,
<code><a href="#topic+extlogitlink">extlogitlink</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>hdata &lt;- data.frame(x2 = rnorm(nn &lt;- 200))
hdata &lt;- transform(hdata, y = rnorm(nn))  # Not very good data!
fit1 &lt;- vglm(y ~ x2, hypersecant, hdata, trace = TRUE, crit = "c")
coef(fit1, matrix = TRUE)
fit1@misc$earg

# Not recommended:
fit2 &lt;- vglm(y ~ x2, hypersecant(link = "identitylink"), hdata)
coef(fit2, matrix = TRUE)
fit2@misc$earg
</code></pre>

<hr>
<h2 id='hzeta'> Haight's Zeta Family Function </h2><span id='topic+hzeta'></span>

<h3>Description</h3>

<p>Estimating the parameter of Haight's zeta distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hzeta(lshape = "logloglink", ishape = NULL, nsimEIM = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hzeta_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function for the parameter,
called <code class="reqn">\alpha</code> below.
See <code><a href="#topic+Links">Links</a></code> for more choices.
Here, a log-log link keeps the parameter greater than one, meaning
the mean is finite.
</p>
</td></tr>
<tr><td><code id="hzeta_+3A_ishape">ishape</code>, <code id="hzeta_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function is
</p>
<p style="text-align: center;"><code class="reqn">f(y) = (2y-1)^{(-\alpha)} - (2y+1)^{(-\alpha)},</code>
</p>

<p>where the parameter <code class="reqn">\alpha&gt;0</code>
and <code class="reqn">y=1,2,\ldots</code>.
The function <code><a href="#topic+dhzeta">dhzeta</a></code> computes this probability function.
The mean of <code class="reqn">Y</code>, which is returned as fitted values, is
<code class="reqn">(1-2^{-\alpha}) \zeta(\alpha)</code>
provided <code class="reqn">\alpha &gt; 1</code>, where <code class="reqn">\zeta</code> is
Riemann's zeta function.
The mean is a decreasing function of <code class="reqn">\alpha</code>.
The mean is infinite if <code class="reqn">\alpha \leq 1</code>, and
the variance is infinite if <code class="reqn">\alpha \leq 2</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson N. L., Kemp, A. W. and Kotz S. (2005).
<em>Univariate Discrete Distributions</em>,
3rd edition,
pp.533&ndash;4.
Hoboken, New Jersey: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Hzeta">Hzeta</a></code>,
<code><a href="#topic+zeta">zeta</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="#topic+loglog">loglog</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>shape &lt;- exp(exp(-0.1))  # The parameter
hdata &lt;- data.frame(y = rhzeta(n = 1000, shape))
fit &lt;- vglm(y ~ 1, hzeta, data = hdata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)  # Useful for intercept-only models; should be same as shape
c(with(hdata, mean(y)), head(fitted(fit), 1))
summary(fit)
</code></pre>

<hr>
<h2 id='Hzeta'> Haight's Zeta Distribution  </h2><span id='topic+Hzeta'></span><span id='topic+dhzeta'></span><span id='topic+phzeta'></span><span id='topic+qhzeta'></span><span id='topic+rhzeta'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for Haight's zeta distribution with parameter
<code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dhzeta(x, shape, log = FALSE)
phzeta(q, shape, log.p = FALSE)
qhzeta(p, shape)
rhzeta(n, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hzeta_+3A_x">x</code>, <code id="Hzeta_+3A_q">q</code>, <code id="Hzeta_+3A_p">p</code>, <code id="Hzeta_+3A_n">n</code></td>
<td>

<p>Same meaning as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Hzeta_+3A_shape">shape</code></td>
<td>

<p>The positive shape parameter.
Called <code class="reqn">\alpha</code> below.
</p>
</td></tr>
<tr><td><code id="Hzeta_+3A_log">log</code>, <code id="Hzeta_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = (2x-1)^{(-\alpha)} - (2x+1)^{(-\alpha)},</code>
</p>

<p>where <code class="reqn">\alpha&gt;0</code> and <code class="reqn">x=1,2,\ldots</code>.
</p>


<h3>Value</h3>

<p><code>dhzeta</code> gives the density,
<code>phzeta</code> gives the distribution function,
<code>qhzeta</code> gives the quantile function, and
<code>rhzeta</code> generates random deviates.
</p>


<h3>Note</h3>

<p>Given some response data, the <span class="pkg">VGAM</span> family function
<code><a href="#topic+hzeta">hzeta</a></code> estimates the parameter <code>shape</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+hzeta">hzeta</a></code>,
<code><a href="#topic+zeta">zeta</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dhzeta(1:20, 2.1)
rhzeta(20, 2.1)

round(1000 * dhzeta(1:8, 2))
table(rhzeta(1000, 2))

## Not run:  shape &lt;- 1.1; x &lt;- 1:10
plot(x, dhzeta(x, shape = shape), type = "h", ylim = 0:1,
     sub = paste("shape =", shape), las = 1, col = "blue",
     ylab = "Probability", lwd = 2,
     main = "Haight's zeta: blue = density; orange = CDF")
lines(x+0.1, phzeta(x, shape = shape), col = "orange", lty = 3, lwd = 2,
      type = "h")

## End(Not run)
</code></pre>

<hr>
<h2 id='iam'> Index from Array to Matrix </h2><span id='topic+iam'></span>

<h3>Description</h3>

<p>Maps the elements of an array containing symmetric
positive-definite matrices to a matrix with sufficient columns
to hold them (called matrix-band format.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iam(j, k, M, both = FALSE, diag = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iam_+3A_j">j</code></td>
<td>

<p>Usually an integer from the set {<code>1:M</code>} giving the row
number of an element.
However, the argument can also be a vector of length <code>M</code>,
for selecting an entire row or column, e.g.,
<code>iam(1:M, 1, M)</code> or <code>iam(1, 1:M, M)</code>.
</p>
</td></tr>
<tr><td><code id="iam_+3A_k">k</code></td>
<td>

<p>An integer from the set {<code>1:M</code>} giving the column number
of an element.
</p>
</td></tr>
<tr><td><code id="iam_+3A_m">M</code></td>
<td>

<p>The number of linear/additive predictors. This is the
dimension of each positive-definite symmetric matrix.
</p>
</td></tr>
<tr><td><code id="iam_+3A_both">both</code></td>
<td>

<p>Logical. Return both the row and column indices?
See below for more details.
</p>
</td></tr>
<tr><td><code id="iam_+3A_diag">diag</code></td>
<td>

<p>Logical. Return the indices for the diagonal elements?
If <code>FALSE</code> then only the strictly upper triangular part
of the matrix elements are used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose we have <code class="reqn">n</code> symmetric positive-definite square
matrices,
each <code class="reqn">M</code> by <code class="reqn">M</code>, and
these are stored in an <code>array</code> of dimension <code>c(n,M,M)</code>.
Then these can be more compactly represented by a <code>matrix</code>
of dimension <code>c(n,K)</code> where <code>K</code> is an integer between
<code>M</code> and <code>M*(M+1)/2</code> inclusive.  The mapping between
these two representations is given by this function.
It firstly enumerates by the diagonal elements, followed by
the band immediately above the diagonal, then the band above
that one, etc.
The last element is <code>(1,M)</code>.
This function performs the mapping from elements <code>(j,k)</code>
of symmetric positive-definite square matrices to the columns
of another matrix representing such.  This is called the
<em>matrix-band</em> format and is used by the <span class="pkg">VGAM</span> package.
</p>


<h3>Value</h3>

<p>This function has a dual purpose depending on the value of
<code>both</code>.  If <code>both = FALSE</code> then the column number
corresponding to the <code>j</code>-<code>k</code> element of the matrix is
returned.  If <code>both = TRUE</code> then <code>j</code> and <code>k</code> are
ignored and a list with the following components are returned.
</p>
<table>
<tr><td><code>row.index</code></td>
<td>

<p>The row indices of the upper triangular part of the
matrix (This may or may not include the diagonal elements,
depending on the argument <code>diagonal</code>).
</p>
</td></tr>
<tr><td><code>col.index</code></td>
<td>

<p>The column indices of the upper triangular part of the
matrix (This may or may not include the diagonal elements,
depending on the argument <code>diagonal</code>).
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is used in the <code>weight</code> slot of many
<span class="pkg">VGAM</span> family functions
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>),
especially those whose <code class="reqn">M</code> is determined by the data,
e.g., <code><a href="#topic+dirichlet">dirichlet</a></code>, <code><a href="#topic+multinomial">multinomial</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>iam(1, 2, M = 3)  # The 4th coln represents elt (1,2) of a 3x3 matrix
iam(NULL, NULL, M = 3, both = TRUE)  # Return the row &amp; column indices

dirichlet()@weight

M &lt;- 4
temp1 &lt;- iam(NA, NA, M = M, both = TRUE)
mat1 &lt;- matrix(NA, M, M)
mat1[cbind(temp1$row, temp1$col)] = 1:length(temp1$row)
mat1  # More commonly used

temp2 &lt;- iam(NA, NA, M = M, both = TRUE, diag = FALSE)
mat2 &lt;- matrix(NA, M, M)
mat2[cbind(temp2$row, temp2$col)] = 1:length(temp2$row)
mat2  # Rarely used
</code></pre>

<hr>
<h2 id='identitylink'> Identity Link Function </h2><span id='topic+identitylink'></span><span id='topic+negidentitylink'></span>

<h3>Description</h3>

<p>Computes the identity transformation, including its inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    identitylink(theta, inverse = FALSE, deriv = 0, short = TRUE,
                 tag = FALSE)
 negidentitylink(theta, inverse = FALSE, deriv = 0, short = TRUE,
                 tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identitylink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="identitylink_+3A_inverse">inverse</code>, <code id="identitylink_+3A_deriv">deriv</code>, <code id="identitylink_+3A_short">short</code>, <code id="identitylink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The identity link function <code class="reqn">g(\theta)=\theta</code>
should be available to every parameter estimated by the
<span class="pkg">VGAM</span> library. However, it usually results in numerical
problems because the estimates lie outside the permitted
range. Consequently, the result may contain <code>Inf</code>,
<code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>
<p>The function <code>negidentitylink</code> is the
negative-identity link function and corresponds to
<code class="reqn">g(\theta)=-\theta</code>.  This is useful
for some models, e.g., in the literature supporting the
<code><a href="#topic+gevff">gevff</a></code> function it seems that half of the authors
use <code class="reqn">\xi=-k</code> for the shape parameter and the other
half use <code class="reqn">k</code> instead of <code class="reqn">\xi</code>.
</p>


<h3>Value</h3>

<p>For <code>identitylink()</code>:
for <code>deriv = 0</code>, the identity of <code>theta</code>, i.e.,
<code>theta</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then <code>theta</code>.
For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of
<code>theta</code> if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>For <code>negidentitylink()</code>: the results are similar to
<code>identitylink()</code> except for a sign change in most cases.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+powerlink">powerlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>identitylink((-5):5)
identitylink((-5):5, deriv = 1)
identitylink((-5):5, deriv = 2)
negidentitylink((-5):5)
negidentitylink((-5):5, deriv = 1)
negidentitylink((-5):5, deriv = 2)
</code></pre>

<hr>
<h2 id='Influence'>
Influence Function (S4 generic)
of a Fitted Model
</h2><span id='topic+Influence'></span><span id='topic+Influence.vglm'></span>

<h3>Description</h3>

<p>Returns a matrix containing the influence function
of a fitted model, e.g., a &quot;vglm&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Influence(object, ...)
Influence.vglm(object, weighted = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Influence_+3A_object">object</code></td>
<td>

<p>an object, especially that of class <code>"vglm"</code>&mdash;see
<code><a href="#topic+vglm-class">vglm-class</a></code>.
Currently other classes such as <code>"vgam"</code> are not yet
implemented.
</p>
</td></tr>
<tr><td><code id="Influence_+3A_weighted">weighted</code></td>
<td>

<p>Logical. Include the prior weights?
Currently only <code>TRUE</code> is accepted.
This might change in the future and/or
the default value might change.
</p>
</td></tr>
<tr><td><code id="Influence_+3A_...">...</code></td>
<td>

<p>any additional arguments such as to
allow or disallow the prior weights.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Influence functions are useful in fields such
as sample survey theory,
e.g.,
<span class="pkg">survey</span>,
<span class="pkg">svyVGAM</span>.
For each <code class="reqn">i=1,\ldots,n</code>,
the formula is approximately <code class="reqn">-I U</code>
where <code class="reqn">I</code> is the weighted Fisher
information matrix and U is
the <code class="reqn">i</code>th score vector.
</p>


<h3>Value</h3>

<p>An <code>n</code> by <code>p.vlm</code> matrix.
</p>



<h3>Warning</h3>

<p>This function is currently experimental and
defaults may change.
Use with caution!
The functions here should not be confused with
<code><a href="stats.html#topic+lm.influence">lm.influence</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>,
<span class="pkg">survey</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, acat, data = pneumo)
coef(fit)  # 8-vector
Influence(fit)  # 8 x 4
all(abs(colSums(Influence(fit))) &lt; 1e-6)  # TRUE
</code></pre>

<hr>
<h2 id='inv.binomial'>Inverse Binomial Distribution Family Function</h2><span id='topic+inv.binomial'></span>

<h3>Description</h3>

<p>Estimates the two parameters of an inverse binomial distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.binomial(lrho = extlogitlink(min = 0.5, max = 1),
    llambda = "loglink", irho = NULL, ilambda = NULL, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv.binomial_+3A_lrho">lrho</code>, <code id="inv.binomial_+3A_llambda">llambda</code></td>
<td>

<p>Link function for the <code class="reqn">\rho</code> and <code class="reqn">\lambda</code>
parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="inv.binomial_+3A_irho">irho</code>, <code id="inv.binomial_+3A_ilambda">ilambda</code></td>
<td>

<p>Numeric.
Optional initial values for <code class="reqn">\rho</code> and
<code class="reqn">\lambda</code>.
</p>
</td></tr>
<tr><td><code id="inv.binomial_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inverse binomial distribution of Yanagimoto (1989) has
density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;\rho,\lambda) =
  \frac{ \lambda
         \,\Gamma(2y+\lambda) }{\Gamma(y+1) \,
         \Gamma(y+\lambda+1) }
  \{ \rho(1-\rho) \}^y  \rho^{\lambda}</code>
</p>

<p>where <code class="reqn">y=0,1,2,\ldots</code> and
<code class="reqn">\frac12 &lt; \rho &lt; 1</code>,
and <code class="reqn">\lambda &gt; 0</code>.
The first two moments exist for <code class="reqn">\rho&gt;\frac12</code>;
then the mean
is <code class="reqn">\lambda (1-\rho) /(2 \rho-1)</code>
(returned as the fitted values) and the
variance is
<code class="reqn">\lambda \rho
  (1-\rho) /(2 \rho-1)^3</code>.
The inverse binomial distribution is a special
case of the generalized negative binomial distribution of
Jain and Consul (1971).
It holds that <code class="reqn">Var(Y) &gt; E(Y)</code> so that the
inverse binomial distribution
is overdispersed compared with the Poisson distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This <span class="pkg">VGAM</span> family function only works reasonably well with
intercept-only models.
Good initial values are needed; if convergence failure occurs
use <code>irho</code> and/or <code>ilambda</code>.
</p>
<p>Some elements of the working weight matrices use the expected
information matrix while other elements use the observed
information matrix.
Yet to do: using the mean and the reciprocal of
<code class="reqn">\lambda</code> results in an EIM that is diagonal.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Yanagimoto, T. (1989).
The inverse binomial distribution as a statistical model.
<em>Communications in Statistics: Theory and Methods</em>,
<b>18</b>, 3625&ndash;3633.
</p>
<p>Jain, G. C. and Consul, P. C. (1971).
A generalized negative binomial distribution.
<em>SIAM Journal on Applied Mathematics</em>,
<b>21</b>, 501&ndash;513.
</p>
<p>Jorgensen, B. (1997).
<em>The Theory of Dispersion Models</em>.
London: Chapman &amp; Hall
</p>


<h3>See Also</h3>

<p><code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>idata &lt;- data.frame(y = rnbinom(n &lt;- 1000, mu = exp(3), size = exp(1)))
fit &lt;- vglm(y ~ 1, inv.binomial, data = idata, trace = TRUE)
with(idata, c(mean(y), head(fitted(fit), 1)))
summary(fit)
coef(fit, matrix = TRUE)
Coef(fit)
sum(weights(fit))  # Sum of the prior weights
sum(weights(fit, type = "work"))  # Sum of the working weights
</code></pre>

<hr>
<h2 id='Inv.gaussian'>The Inverse Gaussian Distribution</h2><span id='topic+Inv.gaussian'></span><span id='topic+dinv.gaussian'></span><span id='topic+pinv.gaussian'></span><span id='topic+rinv.gaussian'></span>

<h3>Description</h3>

<p>Density, distribution function and random generation
for the inverse Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dinv.gaussian(x, mu, lambda, log = FALSE)
pinv.gaussian(q, mu, lambda)
rinv.gaussian(n, mu, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inv.gaussian_+3A_x">x</code>, <code id="Inv.gaussian_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>

<tr><td><code id="Inv.gaussian_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length
is taken to be the number required.
</p>
</td></tr>
<tr><td><code id="Inv.gaussian_+3A_mu">mu</code></td>
<td>
<p>the mean parameter.</p>
</td></tr>
<tr><td><code id="Inv.gaussian_+3A_lambda">lambda</code></td>
<td>
<p>the <code class="reqn">\lambda</code> parameter.</p>
</td></tr>
<tr><td><code id="Inv.gaussian_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+inv.gaussianff">inv.gaussianff</a></code>, the <span class="pkg">VGAM</span> family function
for estimating both parameters by maximum likelihood estimation,
for the formula of the probability density function.
</p>


<h3>Value</h3>

<p><code>dinv.gaussian</code> gives the density,
<code>pinv.gaussian</code> gives the distribution function, and
<code>rinv.gaussian</code> generates random deviates.
</p>



<h3>Note</h3>

<p>Currently <code>qinv.gaussian</code> is unavailable.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1994).
<em>Continuous Univariate Distributions</em>,
2nd edition,
Volume 1,
New York: Wiley.
</p>
<p>Taraldsen, G. and Lindqvist, B. H. (2005).
The multiple roots simulation algorithm,
the inverse Gaussian distribution, and the
sufficient conditional Monte Carlo method.
<em>Preprint Statistics No. 4/2005</em>,
Norwegian University of Science and Technology,
Trondheim, Norway.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inv.gaussianff">inv.gaussianff</a></code>,
<code><a href="#topic+waldff">waldff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  x &lt;- seq(-0.05, 4, len = 300)
plot(x, dinv.gaussian(x, mu = 1, lambda = 1), type = "l",
     col = "blue",las = 1, main =
     "blue is density, orange is cumulative distribution function")
abline(h = 0, col = "gray", lty = 2)
lines(x, pinv.gaussian(x, mu = 1, lambda = 1), type = "l", col = "orange") 
## End(Not run)
</code></pre>

<hr>
<h2 id='inv.gaussianff'> Inverse Gaussian Distribution Family Function </h2><span id='topic+inv.gaussianff'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the inverse Gaussian distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.gaussianff(lmu = "loglink", llambda = "loglink",
      imethod = 1, ilambda = NULL,
      parallel = FALSE, ishrinkage = 0.99, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv.gaussianff_+3A_lmu">lmu</code>, <code id="inv.gaussianff_+3A_llambda">llambda</code></td>
<td>

<p>Parameter link functions for the <code class="reqn">\mu</code> and
<code class="reqn">\lambda</code> parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="inv.gaussianff_+3A_ilambda">ilambda</code>, <code id="inv.gaussianff_+3A_parallel">parallel</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
If <code>parallel = TRUE</code> then the constraint is not applied
to the intercept.
</p>
</td></tr>
<tr><td><code id="inv.gaussianff_+3A_imethod">imethod</code>, <code id="inv.gaussianff_+3A_ishrinkage">ishrinkage</code>, <code id="inv.gaussianff_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard (&ldquo;canonical&rdquo;) form of the
inverse Gaussian distribution has a density
that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y;\mu,\lambda) = \sqrt{\lambda/(2\pi y^3)}
       \exp\left(-\lambda (y-\mu)^2/(2 y \mu^2)\right)</code>
</p>

<p>where <code class="reqn">y&gt;0</code>,
<code class="reqn">\mu&gt;0</code>, and
<code class="reqn">\lambda&gt;0</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">\mu</code> and its variance is
<code class="reqn">\mu^3/\lambda</code>.
By default, <code class="reqn">\eta_1=\log(\mu)</code> and
<code class="reqn">\eta_2=\log(\lambda)</code>.
The mean is returned as the fitted values.
This <span class="pkg">VGAM</span> family function can handle multiple
responses (inputted as a matrix).
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The inverse Gaussian distribution can be fitted (to a
certain extent) using the usual GLM framework involving a
scale parameter. This family function is different from that
approach in that it estimates both parameters by full maximum
likelihood estimation.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1994).
<em>Continuous Univariate Distributions</em>,
2nd edition, Volume 1, New York: Wiley.
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Inv.gaussian">Inv.gaussian</a></code>,
<code><a href="#topic+waldff">waldff</a></code>,
<code><a href="#topic+bisa">bisa</a></code>.
</p>
<p>The <span class="rlang"><b>R</b></span> package <span class="pkg">SuppDists</span> has several functions
for evaluating the density, distribution function, quantile
function and generating random numbers from the inverse Gaussian
distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>idata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
idata &lt;- transform(idata, mymu   = exp(2 + 1 * x2),
                          Lambda = exp(2 + 1 * x2))
idata &lt;- transform(idata, y = rinv.gaussian(nn, mu = mymu, Lambda))
fit1 &lt;-   vglm(y ~ x2, inv.gaussianff, data = idata, trace = TRUE)
rrig &lt;- rrvglm(y ~ x2, inv.gaussianff, data = idata, trace = TRUE)
coef(fit1, matrix = TRUE)
coef(rrig, matrix = TRUE)
Coef(rrig)
summary(fit1)
</code></pre>

<hr>
<h2 id='inv.lomax'> Inverse Lomax Distribution Family Function </h2><span id='topic+inv.lomax'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
inverse Lomax distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.lomax(lscale = "loglink", lshape2.p = "loglink", iscale = NULL,
    ishape2.p = NULL, imethod = 1, gscale = exp(-5:5),
    gshape2.p = exp(-5:5), probs.y = c(0.25, 0.5, 0.75),
    zero = "shape2.p")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv.lomax_+3A_lscale">lscale</code>, <code id="inv.lomax_+3A_lshape2.p">lshape2.p</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code class="reqn">b</code>, and <code class="reqn">p</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="inv.lomax_+3A_iscale">iscale</code>, <code id="inv.lomax_+3A_ishape2.p">ishape2.p</code>, <code id="inv.lomax_+3A_imethod">imethod</code>, <code id="inv.lomax_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>ishape2.p</code> is needed to obtain a good estimate for
the other parameter.
</p>
</td></tr>
<tr><td><code id="inv.lomax_+3A_gscale">gscale</code>, <code id="inv.lomax_+3A_gshape2.p">gshape2.p</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="inv.lomax_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 2-parameter inverse Lomax distribution is the 4-parameter
generalized beta II distribution with shape parameters
<code class="reqn">a=q=1</code>.
It is also the 3-parameter Dagum distribution
with shape parameter <code class="reqn">a=1</code>, as well as the
beta distribution of the second kind with <code class="reqn">q=1</code>.
More details can be found in Kleiber and Kotz (2003).
</p>
<p>The inverse Lomax distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = p y^{p-1} / [b^p \{1 + y/b\}^{p+1}]</code>
</p>

<p>for <code class="reqn">b &gt; 0</code>, <code class="reqn">p &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and <code>p</code> is a shape parameter.
The mean does not seem to exist; the <em>median</em> is returned
as the fitted values.
This family function handles multiple responses.
</p>





<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>idata &lt;- data.frame(y = rinv.lomax(2000, sc = exp(2), exp(1)))
fit &lt;- vglm(y ~ 1, inv.lomax, data = idata, trace = TRUE)
fit &lt;- vglm(y ~ 1, inv.lomax(iscale = exp(3)), data = idata,
            trace = TRUE, epsilon = 1e-8, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Inv.lomax'>The Inverse Lomax Distribution</h2><span id='topic+Inv.lomax'></span><span id='topic+dinv.lomax'></span><span id='topic+pinv.lomax'></span><span id='topic+qinv.lomax'></span><span id='topic+rinv.lomax'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the inverse Lomax distribution with shape
parameter <code>p</code> and scale parameter <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dinv.lomax(x, scale = 1, shape2.p, log = FALSE)
pinv.lomax(q, scale = 1, shape2.p, lower.tail = TRUE, log.p = FALSE)
qinv.lomax(p, scale = 1, shape2.p, lower.tail = TRUE, log.p = FALSE)
rinv.lomax(n, scale = 1, shape2.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inv.lomax_+3A_x">x</code>, <code id="Inv.lomax_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Inv.lomax_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Inv.lomax_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length
is taken to be the number required.</p>
</td></tr>
<tr><td><code id="Inv.lomax_+3A_shape2.p">shape2.p</code></td>
<td>
<p>shape parameter.</p>
</td></tr>
<tr><td><code id="Inv.lomax_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Inv.lomax_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Inv.lomax_+3A_lower.tail">lower.tail</code>, <code id="Inv.lomax_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+inv.lomax">inv.lomax</a></code>, which is the <span class="pkg">VGAM</span> family
function for estimating the parameters by maximum likelihood
estimation.
</p>


<h3>Value</h3>

<p><code>dinv.lomax</code> gives the density,
<code>pinv.lomax</code> gives the distribution function,
<code>qinv.lomax</code> gives the quantile function, and
<code>rinv.lomax</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The inverse Lomax distribution is a special case of the
4-parameter generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>idata &lt;- data.frame(y = rinv.lomax(n = 1000, exp(2), exp(1)))
fit &lt;- vglm(y ~ 1, inv.lomax, idata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='inv.paralogistic'> Inverse Paralogistic Distribution Family Function </h2><span id='topic+inv.paralogistic'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
inverse paralogistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.paralogistic(lscale = "loglink", lshape1.a = "loglink",
    iscale = NULL, ishape1.a = NULL, imethod = 1,
    lss = TRUE, gscale = exp(-5:5),
    gshape1.a = seq(0.75, 4, by = 0.25), probs.y = c(0.25, 0.5,
    0.75), zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inv.paralogistic_+3A_lss">lss</code></td>
<td>
<p> See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for important
information.
</p>
</td></tr>
<tr><td><code id="inv.paralogistic_+3A_lshape1.a">lshape1.a</code>, <code id="inv.paralogistic_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code>a</code>  and <code>scale</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="inv.paralogistic_+3A_iscale">iscale</code>, <code id="inv.paralogistic_+3A_ishape1.a">ishape1.a</code>, <code id="inv.paralogistic_+3A_imethod">imethod</code>, <code id="inv.paralogistic_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>ishape1.a</code> is needed to obtain a good estimate for
the other parameter.
</p>
</td></tr>
<tr><td><code id="inv.paralogistic_+3A_gscale">gscale</code>, <code id="inv.paralogistic_+3A_gshape1.a">gshape1.a</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="inv.paralogistic_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 2-parameter inverse paralogistic distribution is the
4-parameter generalized beta II distribution with shape parameter
<code class="reqn">q=1</code> and <code class="reqn">a=p</code>.
It is the 3-parameter Dagum distribution with <code class="reqn">a=p</code>.
More details can be found in Kleiber and Kotz (2003).
</p>
<p>The inverse paralogistic distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = a^2 y^{a^2-1} / [b^{a^2} \{1 + (y/b)^a\}^{a+1}]</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and <code class="reqn">a</code> is the shape parameter.
The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(a + 1/a) \,
             \Gamma(1 - 1/a) / \Gamma(a)</code>
</p>

<p>provided <code class="reqn">a &gt; 1</code>; these are returned as the fitted values.
This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Inv.paralogistic">Inv.paralogistic</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>idata &lt;- data.frame(y = rinv.paralogistic(3000, exp(1), sc = exp(2)))
fit &lt;- vglm(y ~ 1, inv.paralogistic(lss = FALSE), idata, trace = TRUE)
fit &lt;- vglm(y ~ 1, inv.paralogistic(imethod = 2, ishape1.a = 4),
            data = idata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Inv.paralogistic'>The Inverse Paralogistic Distribution</h2><span id='topic+Inv.paralogistic'></span><span id='topic+dinv.paralogistic'></span><span id='topic+pinv.paralogistic'></span><span id='topic+qinv.paralogistic'></span><span id='topic+rinv.paralogistic'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the inverse paralogistic distribution with
shape parameters <code>a</code> and <code>p</code>, and scale parameter
<code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dinv.paralogistic(x, scale = 1, shape1.a, log = FALSE)
pinv.paralogistic(q, scale = 1, shape1.a, lower.tail = TRUE,
                  log.p = FALSE)
qinv.paralogistic(p, scale = 1, shape1.a, lower.tail = TRUE,
                  log.p = FALSE)
rinv.paralogistic(n, scale = 1, shape1.a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inv.paralogistic_+3A_x">x</code>, <code id="Inv.paralogistic_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Inv.paralogistic_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Inv.paralogistic_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>,
the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="Inv.paralogistic_+3A_shape1.a">shape1.a</code></td>
<td>
<p>shape parameter.</p>
</td></tr>
<tr><td><code id="Inv.paralogistic_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Inv.paralogistic_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Inv.paralogistic_+3A_lower.tail">lower.tail</code>, <code id="Inv.paralogistic_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>, which is the <span class="pkg">VGAM</span>
family function for estimating the parameters by maximum
likelihood estimation.
</p>


<h3>Value</h3>

<p><code>dinv.paralogistic</code> gives the density,
<code>pinv.paralogistic</code> gives the distribution function,
<code>qinv.paralogistic</code> gives the quantile function, and
<code>rinv.paralogistic</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The inverse paralogistic distribution is a special case of the
4-parameter generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>idata &lt;- data.frame(y = rinv.paralogistic(3000, exp(1), sc = exp(2)))
fit &lt;- vglm(y ~ 1, inv.paralogistic(lss = FALSE, ishape1.a = 2.1),
            data = idata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='is.buggy'> Does the Fitted Object Suffer from a Known Bug? </h2><span id='topic+is.buggy'></span><span id='topic+is.buggy.vlm'></span>

<h3>Description</h3>

<p>Checks to see if a fitted object suffers from some known bug.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.buggy(object, ...)
is.buggy.vlm(object, each.term = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.buggy_+3A_object">object</code></td>
<td>

<p>A fitted <span class="pkg">VGAM</span> object, e.g., from
<code><a href="#topic+vgam">vgam</a></code>.
</p>
</td></tr>
<tr><td><code id="is.buggy_+3A_each.term">each.term</code></td>
<td>

<p>Logical. If <code>TRUE</code> then a logical is returned for each term.
</p>
</td></tr>
<tr><td><code id="is.buggy_+3A_...">...</code></td>
<td>

<p>Unused for now.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is known that <code><a href="#topic+vgam">vgam</a></code> with <code><a href="#topic+s">s</a></code> terms
do not correctly handle constraint matrices (<code>cmat</code>, say)
when <code>crossprod(cmat)</code> is not diagonal.
This function detects whether this is so or not.
Note that probably all <span class="pkg">VGAM</span> family functions have defaults
where all <code>crossprod(cmat)</code>s are diagonal, therefore do
not suffer from this bug. It is more likely to occur if the
user inputs constraint matrices using the <code>constraints</code>
argument (and setting <code>zero = NULL</code> if necessary).
</p>
<p>Second-generation VGAMs based on <code><a href="#topic+sm.ps">sm.ps</a></code> are a
modern alternative to using <code><a href="#topic+s">s</a></code>. It does not
suffer from this bug. However, G2-VGAMs require a reasonably
large sample size in order to work more reliably.
</p>


<h3>Value</h3>

<p>The default is a single logical (<code>TRUE</code> if any term is
<code>TRUE</code>),
otherwise a vector of such with each element corresponding to
a term.  If the value is <code>TRUE</code> then I suggest replacing
the VGAM by a similar model fitted by <code><a href="#topic+vglm">vglm</a></code> and
using regression splines, e.g., <code><a href="splines.html#topic+bs">bs</a></code>,
<code><a href="splines.html#topic+ns">ns</a></code>.
</p>


<h3>Note</h3>

<p>When the bug is fixed this function may be withdrawn, otherwise
always return <code>FALSE</code>s!
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>.
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+s">s</a></code>,
<code><a href="#topic+sm.ps">sm.ps</a></code>,
<code><a href="splines.html#topic+bs">bs</a></code>,
<code><a href="splines.html#topic+ns">ns</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit1 &lt;- vgam(cbind(agaaus, kniexc) ~ s(altitude, df = c(3, 4)),
             binomialff(multiple.responses = TRUE), data = hunua)
is.buggy(fit1)  # Okay
is.buggy(fit1, each.term = TRUE)  # No terms are buggy
fit2 &lt;-
  vgam(cbind(agaaus, kniexc) ~ s(altitude, df = c(3, 4)),
       binomialff(multiple.responses = TRUE), data = hunua,
       constraints =
       list("(Intercept)" = diag(2),
            "s(altitude, df = c(3, 4))" = matrix(c(1, 1, 0, 1), 2, 2)))
is.buggy(fit2)  # TRUE
is.buggy(fit2, each.term = TRUE)
constraints(fit2)

# fit2b is an approximate alternative to fit2:
fit2b &lt;-
  vglm(cbind(agaaus, kniexc) ~ bs(altitude, df=3) + bs(altitude, df=4),
       binomialff(multiple.responses = TRUE), data = hunua,
       constraints =
         list("(Intercept)" = diag(2),
              "bs(altitude, df = 3)" = rbind(1, 1),
              "bs(altitude, df = 4)" = rbind(0, 1)))
is.buggy(fit2b)  # Okay
is.buggy(fit2b, each.term = TRUE)
constraints(fit2b)
</code></pre>

<hr>
<h2 id='is.crossing'>Quantile Crossing Detection</h2><span id='topic+is.crossing'></span><span id='topic+is.crossing.vglm'></span>

<h3>Description</h3>

<p>Returns a logical from testing whether an object such
as an extlogF1() VGLM object
has crossing quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.crossing.vglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.crossing_+3A_object">object</code></td>
<td>

<p>an object such as
a <code><a href="#topic+vglm">vglm</a></code> object with
family function <code><a href="#topic+extlogF1">extlogF1</a></code>.
</p>
</td></tr>
<tr><td><code id="is.crossing_+3A_...">...</code></td>
<td>

<p>additional optional arguments.
Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was specifically written for
a <code><a href="#topic+vglm">vglm</a></code> with family function <code><a href="#topic+extlogF1">extlogF1</a></code>.
It examines the fitted quantiles to see if any cross.
Note that if one uses regression splines such as
<code><a href="splines.html#topic+bs">bs</a></code> and
<code><a href="splines.html#topic+ns">ns</a></code>
then it is possible that they cross at values of the
covariate space that are not represented by actual data.
One could use linear interpolation between fitted values
to get around this problem.
</p>


<h3>Value</h3>

<p>A logical.
If <code>TRUE</code> then one can try fit a similar model by
combining columns of the constraint matrices so that
crossing no longer holds; see <code><a href="#topic+fix.crossing">fix.crossing</a></code>.
For LMS-Box-Cox type quantile regression models
it is impossible for the quantiles to cross, by definition,
hence <code>FALSE</code> is returned;
see <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+fix.crossing">fix.crossing</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>.
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  ooo &lt;- with(bmi.nz, order(age))
bmi.nz &lt;- bmi.nz[ooo, ]  # Sort by age
with(bmi.nz, plot(age, BMI, col = "blue"))
mytau &lt;- c(50, 93, 95, 97) / 100  # Some quantiles are quite close
fit1 &lt;- vglm(BMI ~ ns(age, 7), extlogF1(mytau), bmi.nz, trace = TRUE)
plot(BMI ~ age, bmi.nz, col = "blue", las = 1,
     main = "Partially parallel (darkgreen) &amp; nonparallel quantiles",
     sub = "Crossing quantiles are orange")
is.crossing(fit1)
matlines(with(bmi.nz, age), fitted(fit1), lty = 1, col = "orange") 
## End(Not run)
</code></pre>

<hr>
<h2 id='is.parallel'>Parallelism Constraint Matrices</h2><span id='topic+is.parallel'></span><span id='topic+is.parallel.matrix'></span><span id='topic+is.parallel.vglm'></span>

<h3>Description</h3>

<p>Returns a logical vector from a test of whether an object such
as a matrix or VGLM object
corresponds to a parallelism assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.parallel.matrix(object, ...)
is.parallel.vglm(object, type = c("term", "lm"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.parallel_+3A_object">object</code></td>
<td>

<p>an object such as a constraint matrix or
a <code><a href="#topic+vglm">vglm</a></code> object.
</p>
</td></tr>
<tr><td><code id="is.parallel_+3A_type">type</code></td>
<td>

<p>passed into <code><a href="#topic+constraints">constraints</a></code>.
</p>
</td></tr>
<tr><td><code id="is.parallel_+3A_...">...</code></td>
<td>

<p>additional optional arguments.
Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions may be useful for categorical models
such as
<code><a href="#topic+propodds">propodds</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>.
</p>


<h3>Value</h3>

<p>A vector of logicals, testing whether each constraint matrix
is a one-column matrix of ones.
Note that parallelism can still be thought of as holding if
the constraint matrix has a non-zero but constant values, however,
this is currently not implemented.
No checking is done that the constraint matrices have the same
number of rows.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+constraints">constraints</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  require("VGAMdata")
fit &lt;- vglm(educ ~ sm.bs(age) * sex + ethnicity,
            cumulative(parallel = TRUE), head(xs.nz, 200))
is.parallel(fit)
is.parallel(fit, type = "lm")  # For each column of the LM matrix

## End(Not run)
</code></pre>

<hr>
<h2 id='is.smart'>
Test For a Smart Object
</h2><span id='topic+is.smart'></span>

<h3>Description</h3>

<p>Tests an object to see if it is smart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  is.smart(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.smart_+3A_object">object</code></td>
<td>

<p>a function or a fitted model.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>object</code> is a function then this function looks to see whether
<code>object</code> has the logical attribute <code>"smart"</code>. If so then
this is returned, else <code>FALSE</code>.
</p>
<p>If <code>object</code> is a fitted model then this function looks to see whether
<code>object@smart.prediction</code> or
<code>object\$smart.prediction</code> exists.
If it does and it is not equal to <code>list(smart.arg=FALSE)</code> then
a <code>TRUE</code> is returned, else <code>FALSE</code>.
The reason for this is because, e.g., <code>lm(...,smart=FALSE)</code> 
and <code>vglm(...,smart=FALSE)</code>, will return such a specific list.
</p>
<p>Writers of smart functions manually have to assign this attribute to
their smart function after it has been written.
</p>


<h3>Value</h3>

<p>Returns <code>TRUE</code> or <code>FALSE</code>, according to whether the <code>object</code>
is smart or not.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.smart(sm.min1)  # TRUE
is.smart(sm.poly)  # TRUE
library(splines)
is.smart(sm.bs)  # TRUE
is.smart(sm.ns)  # TRUE
is.smart(tan)  # FALSE
## Not run: 
udata &lt;- data.frame(x2 = rnorm(9))
fit1 &lt;- vglm(rnorm(9) ~ x2, uninormal, data = udata)
is.smart(fit1)  # TRUE
fit2 &lt;- vglm(rnorm(9) ~ x2, uninormal, data = udata, smart = FALSE)
is.smart(fit2)  # FALSE
fit2@smart.prediction

## End(Not run)
</code></pre>

<hr>
<h2 id='is.zero'>Zero Constraint Matrices</h2><span id='topic+is.zero'></span><span id='topic+is.zero.matrix'></span><span id='topic+is.zero.vglm'></span>

<h3>Description</h3>

<p>Returns a logical vector from a test of whether an object such
as a matrix or VGLM object
corresponds to a 'zero' assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.zero.matrix(object, ...)
is.zero.vglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.zero_+3A_object">object</code></td>
<td>

<p>an object such as a coefficient matrix of a <code><a href="#topic+vglm">vglm</a></code>
object, or a <code><a href="#topic+vglm">vglm</a></code> object.
</p>
</td></tr>
<tr><td><code id="is.zero_+3A_...">...</code></td>
<td>

<p>additional optional arguments.
Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions test the effect of the <code>zero</code> argument
on a <code><a href="#topic+vglm">vglm</a></code> object or the coefficient matrix
of a <code><a href="#topic+vglm">vglm</a></code> object.  The latter is obtained by
<code>coef(vglmObject, matrix = TRUE)</code>.
</p>


<h3>Value</h3>

<p>A vector of logicals,
testing whether each linear/additive predictor
has the <code>zero</code> argument applied to it.
It is <code>TRUE</code> if that linear/additive predictor is
intercept-only, i.e., all other regression coefficients
are set to zero.
</p>
<p>No checking is done for the intercept term at all, i.e., that
it was estimated in the first place.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+constraints">constraints</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>coalminers &lt;- transform(coalminers, Age = (age - 42) / 5)
fit &lt;- vglm(cbind(nBnW,nBW,BnW,BW) ~ Age, binom2.or(zero = NULL),
            data = coalminers)
is.zero(fit)
is.zero(coef(fit, matrix = TRUE))
</code></pre>

<hr>
<h2 id='kendall.tau'>
Kendall's Tau Statistic
</h2><span id='topic+kendall.tau'></span>

<h3>Description</h3>

<p>Computes Kendall's Tau, which is a rank-based
correlation measure,
between two vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kendall.tau(x, y, exact = FALSE, max.n = 3000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kendall.tau_+3A_x">x</code>, <code id="kendall.tau_+3A_y">y</code></td>
<td>

<p>Numeric vectors. Must be of equal length.
Ideally their values are continuous and not too discrete.
Let <code>length(x)</code> be <code class="reqn">N</code>, say.
</p>
</td></tr>
<tr><td><code id="kendall.tau_+3A_exact">exact</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the exact value is computed.
</p>
</td></tr>
<tr><td><code id="kendall.tau_+3A_max.n">max.n</code></td>
<td>

<p>Numeric. If <code>exact = FALSE</code> and <code>length(x)</code>
is more than <code>max.n</code> then a random sample
of <code>max.n</code> pairs are chosen.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kendall's tau is a measure of dependency in a
bivariate distribution.
Loosely, two random variables are <em>concordant</em>
if large values
of one random variable are associated with large
values of the
other random variable.
Similarly, two random variables are <em>disconcordant</em>
if large values
of one random variable are associated with small values of the
other random variable.
More formally, if <code>(x[i] - x[j])*(y[i] - y[j]) &gt; 0</code> then
that comparison is concordant <code class="reqn">(i \neq j)</code>.
And if <code>(x[i] - x[j])*(y[i] - y[j]) &lt; 0</code> then
that comparison is disconcordant <code class="reqn">(i \neq j)</code>.
Out of <code>choose(N, 2</code>) comparisons,
let <code class="reqn">c</code> and <code class="reqn">d</code> be the
number of concordant and disconcordant pairs.
Then Kendall's tau can be estimated by <code class="reqn">(c-d)/(c+d)</code>.
If there are ties then half the ties are deemed concordant and
half disconcordant so that <code class="reqn">(c-d)/(c+d+t)</code> is used.
</p>


<h3>Value</h3>

<p>Kendall's tau, which lies between <code class="reqn">-1</code> and <code class="reqn">1</code>.
</p>


<h3>Warning</h3>

<p>If <code>length(x)</code> is large then
the cost is <code class="reqn">O(N^2)</code>, which is expensive!
Under these circumstances
it is not advisable to set <code>exact = TRUE</code>
or <code>max.n</code> to a very
large number.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+binormalcop">binormalcop</a></code>,
<code><a href="stats.html#topic+cor">cor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 5000; x &lt;- 1:N; y &lt;- runif(N)
true.rho &lt;- -0.8
ymat &lt;- rbinorm(N, cov12 =  true.rho)  # Bivariate normal, aka N_2
x &lt;- ymat[, 1]
y &lt;- ymat[, 2]

## Not run: plot(x, y, col = "blue")

kendall.tau(x, y)  # A random sample is taken here
kendall.tau(x, y)  # A random sample is taken here

kendall.tau(x, y, exact = TRUE)  # Costly if length(x) is large
kendall.tau(x, y, max.n = N)     # Same as exact = TRUE

(rhohat &lt;- sin(kendall.tau(x, y) * pi / 2))  # Holds for N_2 actually
true.rho  # rhohat should be near this value
</code></pre>

<hr>
<h2 id='KLD'> Kullback-Leibler Divergence </h2><span id='topic+KLD'></span><span id='topic+KLDvglm'></span>

<h3>Description</h3>

<p>Calculates the Kullback-Leibler divergence
for certain fitted model objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'> KLD(object, ...)
 KLDvglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KLD_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+vglm-class">vglm-class</a></code>.
Currently <code>object</code> must be intercept-only.
</p>
</td></tr>
<tr><td><code id="KLD_+3A_...">...</code></td>
<td>

<p>Other possible arguments fed into
<code>KLDvglm</code> in order to compute the KLD.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>Kullback-Leibler divergence</em> (KLD),
or <em>relative entropy</em>,
is a measure of how one probability distribution differs
from a second reference probability distribution.
Currently the <span class="pkg">VGAM</span> package computes the KLD 
for GAITD regression models
(e.g., see <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> and
<code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>) where the reference distribution
is the (unscaled) parent or base distribution.
For such, the formula for the KLD simplifies somewhat.
Hence one can obtain a quantitative measure for the overall
effect of altering, inflating, truncating and deflating certain
(special) values.
</p>


<h3>Value</h3>

<p>Returns a numeric nonnegative value with the corresponding KLD.
A 0 value means no difference between an ordinary parent or base
distribution.
</p>


<h3>Warning </h3>

<p>Numerical problems might occur if any of the evaluated 
probabilities
of the unscaled parent distribution are very close to 0.
</p>



<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>References</h3>

<p>Kullback, S. and Leibler, R. A. (1951).
On information and sufficiency.
<em>Annals of Mathematical Statistics</em>,
<b>22</b>, 79&ndash;86.
</p>

<p>M'Kendrick, A. G. (1925).
Applications of mathematics to medical problems.
<em>Proc. Edinb. Math. Soc.</em>,
<b>44</b>, 98&ndash;130.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  McKendrick (1925): Data from 223 Indian village households
cholera &lt;- data.frame(ncases = 0:4,  # Number of cholera cases,
                      wfreq  = c(168, 32, 16, 6, 1))  # Frequencies
fit7 &lt;- vglm(ncases ~ 1, gaitdpoisson(i.mlm = 0, ilambda.p = 1),
             weight = wfreq, data = cholera, trace = TRUE)
coef(fit7, matrix = TRUE)
KLD(fit7)
</code></pre>

<hr>
<h2 id='kumar'>Kumaraswamy Regression Family Function</h2><span id='topic+kumar'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the Kumaraswamy distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kumar(lshape1 = "loglink", lshape2 = "loglink",
      ishape1 = NULL,   ishape2 = NULL,
      gshape1 = exp(2*ppoints(5) - 1), tol12 = 1.0e-4, zero = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kumar_+3A_lshape1">lshape1</code>, <code id="kumar_+3A_lshape2">lshape2</code></td>
<td>

<p>Link function for the two positive shape parameters,
respectively, called <code class="reqn">a</code> and <code class="reqn">b</code> below.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="kumar_+3A_ishape1">ishape1</code>, <code id="kumar_+3A_ishape2">ishape2</code></td>
<td>

<p>Numeric.
Optional initial values for the two positive shape parameters.
</p>
</td></tr>
<tr><td><code id="kumar_+3A_tol12">tol12</code></td>
<td>

<p>Numeric and positive.
Tolerance for testing whether the second shape parameter
is either 1 or 2.
If so then the working weights need to handle these
singularities.
</p>
</td></tr>
<tr><td><code id="kumar_+3A_gshape1">gshape1</code></td>
<td>

<p>Values for a grid search for the first shape parameter.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>


</td></tr>
<tr><td><code id="kumar_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kumaraswamy distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;a = shape1,b = shape2)  =
  a b y^{a-1} (1-y^{a})^{b-1}</code>
</p>

<p>where <code class="reqn">0 &lt; y &lt; 1</code> and the two shape parameters,
<code class="reqn">a</code> and <code class="reqn">b</code>, are positive.
The mean is <code class="reqn">b \times Beta(1+1/a,b)</code>
(returned as the fitted values) and the variance is
<code class="reqn">b \times Beta(1+2/a,b) -
    (b \times Beta(1+1/a,b))^2</code>.
Applications of the Kumaraswamy distribution include
the storage volume of a water reservoir.
Fisher scoring is implemented.
Handles multiple responses (matrix input).
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kumaraswamy, P. (1980).
A generalized probability density function
for double-bounded random processes.
<em>Journal of Hydrology</em>,
<b>46</b>, 79&ndash;88.
</p>
<p>Jones, M. C. (2009).
Kumaraswamy's distribution: A beta-type distribution
with some tractability advantages.
<em>Statistical Methodology</em>,
<b>6</b>, 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dkumar">dkumar</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>shape1 &lt;- exp(1); shape2 &lt;- exp(2)
kdata &lt;- data.frame(y = rkumar(n = 1000, shape1, shape2))
fit &lt;- vglm(y ~ 1, kumar, data = kdata, trace = TRUE)
c(with(kdata, mean(y)), head(fitted(fit), 1))
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Kumar'>The Kumaraswamy Distribution</h2><span id='topic+Kumar'></span><span id='topic+dkumar'></span><span id='topic+pkumar'></span><span id='topic+qkumar'></span><span id='topic+rkumar'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Kumaraswamy distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkumar(x, shape1, shape2, log = FALSE)
pkumar(q, shape1, shape2, lower.tail = TRUE, log.p = FALSE)
qkumar(p, shape1, shape2, lower.tail = TRUE, log.p = FALSE)
rkumar(n, shape1, shape2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Kumar_+3A_x">x</code>, <code id="Kumar_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Kumar_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Kumar_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.
</p>
</td></tr>
<tr><td><code id="Kumar_+3A_shape1">shape1</code>, <code id="Kumar_+3A_shape2">shape2</code></td>
<td>
<p> positive shape parameters. </p>
</td></tr>
<tr><td><code id="Kumar_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density
is returned.
</p>
</td></tr>
<tr><td><code id="Kumar_+3A_lower.tail">lower.tail</code>, <code id="Kumar_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+kumar">kumar</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for the formula of the probability density function and other
details.
</p>


<h3>Value</h3>

<p><code>dkumar</code> gives the density,
<code>pkumar</code> gives the distribution function,
<code>qkumar</code> gives the quantile function, and
<code>rkumar</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+kumar">kumar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shape1 &lt;- 2; shape2 &lt;- 2; nn &lt;- 201; # shape1 &lt;- shape2 &lt;- 0.5;
x &lt;- seq(-0.05, 1.05, len = nn)
plot(x, dkumar(x, shape1, shape2), type = "l", las = 1, 
     ylab = paste("dkumar(shape1 = ", shape1,
                  ", shape2 = ", shape2, ")"),
     col = "blue", cex.main = 0.8, ylim = c(0,1.5),
     main = "Blue is density, orange is the CDF",
     sub = "Red lines are the 10,20,...,90 percentiles")
lines(x, pkumar(x, shape1, shape2), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qkumar(probs, shape1, shape2)
lines(Q, dkumar(Q, shape1, shape2), col = "red", lty = 3, type = "h")
lines(Q, pkumar(Q, shape1, shape2), col = "red", lty = 3, type = "h")
abline(h = probs, col = "red", lty = 3)
max(abs(pkumar(Q, shape1, shape2) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='lakeO'>
Annual catches on Lake Otamangakau from October 1974 to October 1989

</h2><span id='topic+lakeO'></span>

<h3>Description</h3>

<p>Rainbow and brown trout catches by a Mr Swainson at
Lake Otamangakau in the central North Island of New Zealand
during the 1970s and 1980s.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>data(lakeO)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 5 variables.
</p>

<dl>
<dt><code>year</code></dt><dd><p>a numeric vector,
the season began on 1 October of the year and ended 12 months later.

</p>
</dd>
<dt><code>total.fish</code></dt><dd><p>a numeric vector,
the total number of fish caught during the season.
Simply the sum of brown and rainbow trout.
</p>
</dd>
<dt><code>brown</code></dt><dd><p>a numeric vector,
the number of brown trout
(<em>Salmo trutta</em>)
caught.
</p>
</dd>
<dt><code>rainbow</code></dt><dd><p>a numeric vector,
the number of rainbow trout
(<em>Oncorhynchus mykiss</em>)
caught.
</p>
</dd>
<dt><code>visits</code></dt><dd><p>a numeric vector,
the number of visits during the season that the angler made to
the lake.
It is necessary to assume that the visits were of an equal time length
in order to interpret the usual Poisson regressions.
</p>
</dd>
</dl>



<h3>Details</h3>


<p>The data was extracted from the season summaries at Lake Otamangakau
by Anthony Swainson
for the seasons 1974&ndash;75 to 1988&ndash;89.


Mr Swainson was one of a small group of regular fly fishing anglers
and kept a diary of his catches.
Lake Otamangakau is a lake of area 1.8 squared km and has a
maximum depth of about 12m, and is located
in the central North Island of New Zealand.
It is trout-infested and known for its trophy-sized fish.
</p>
<p>See also <code><a href="VGAMdata.html#topic+trapO">trapO</a></code>.
</p>


<h3>Source</h3>

<p>Table 7.2 of the reference below.
Thanks to Dr Michel Dedual for a copy of the report and for help
reading the final year's data.
The report is available from TWY on request.
</p>




<h3>References</h3>

<p>Dedual, M.  and MacLean, G. and Rowe, D. and Cudby, E.,
<em>The Trout Population and Fishery of
Lake Otamangakau&mdash;Interim Report</em>.
National Institute of Water and Atmospheric Research,
Hamilton, New Zealand.
Consultancy Report Project No. ELE70207,
(Dec 1996).
</p>



<h3>Examples</h3>

<pre><code class='language-R'>data(lakeO)
lakeO
summary(lakeO)
</code></pre>

<hr>
<h2 id='lambertW'>
The Lambert W Function
</h2><span id='topic+lambertW'></span>

<h3>Description</h3>

<p>Computes the Lambert <em>W</em> function for real values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambertW(x, tolerance = 1e-10, maxit = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambertW_+3A_x">x</code></td>
<td>

<p>A vector of reals.
</p>
</td></tr>
<tr><td><code id="lambertW_+3A_tolerance">tolerance</code></td>
<td>

<p>Accuracy desired.
</p>
</td></tr>
<tr><td><code id="lambertW_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of iterations of third-order Halley's method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lambert <code class="reqn">W</code> function is the root of the equation
<code class="reqn">W(z) \exp(W(z)) = z</code>
for complex <code class="reqn">z</code>.
If <code class="reqn">z</code> is real and <code class="reqn">-1/e &lt; z &lt; 0</code> then
it has two possible real values,
and currently only the upper branch
(often called <code class="reqn">W_0</code>)
is computed so that
a value that is <code class="reqn">\geq -1</code> is returned.
</p>










<h3>Value</h3>

<p>This function returns the principal branch of the <code class="reqn">W</code> function
for <em>real</em> <code class="reqn">z</code>.
It returns <code class="reqn">W(z) \geq -1</code>,
and <code>NA</code> for <code class="reqn">z &lt; -1/e</code>.
</p>


<h3>Note</h3>

<p>If convergence does not occur then increase the value of
<code>maxit</code> and/or <code>tolerance</code>.
</p>
<p>Yet to do: add an argument <code>lbranch = TRUE</code> to return
the lower branch
(often called <code class="reqn">W_{-1}</code>)
for real <code class="reqn">-1/e \leq z &lt; 0</code>;
this would give <code class="reqn">W(z) \leq -1</code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee
</p>


<h3>References</h3>

<p>Corless, R. M. and Gonnet, G. H. and
Hare, D. E. G. and Jeffrey, D. J. and Knuth, D. E. (1996).
On the Lambert <code class="reqn">W</code> function.
<em>Advances in Computational Mathematics</em>,
<b>5</b>(4), 329&ndash;359.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+log">log</a></code>,
<code><a href="base.html#topic+log">exp</a></code>,
<code><a href="#topic+bell">bell</a></code>.
There is also a package called <span class="pkg">LambertW</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
curve(lambertW, -exp(-1), 3, xlim = c(-1, 3), ylim = c(-2, 1),
      las = 1, col = "orange", n = 1001)
abline(v = -exp(-1), h = -1, lwd = 2, lty = "dotted", col = "gray")
abline(h = 0, v = 0, lty = "dashed", col = "blue") 
## End(Not run)
</code></pre>

<hr>
<h2 id='laplace'> Laplace Regression Family Function </h2><span id='topic+laplace'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of
the 2-parameter classical Laplace distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>laplace(llocation = "identitylink", lscale = "loglink",
  ilocation = NULL, iscale = NULL, imethod = 1, zero = "scale")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laplace_+3A_llocation">llocation</code>, <code id="laplace_+3A_lscale">lscale</code></td>
<td>
<p> Character.
Parameter link functions for location parameter <code class="reqn">a</code> and
scale parameter <code class="reqn">b</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="laplace_+3A_ilocation">ilocation</code>, <code id="laplace_+3A_iscale">iscale</code></td>
<td>

<p>Optional initial values.
If given, it must be numeric and values are recycled to the
appropriate length.
The default is to choose the value internally.
</p>
</td></tr>
<tr><td><code id="laplace_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method.
Either the value 1 or 2.
</p>
</td></tr>
<tr><td><code id="laplace_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Laplace distribution is often known as the
<em>double-exponential</em> distribution and,
for modelling, has heavier tail than the normal distribution.
The Laplace density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \frac{1}{2b} \exp \left( - \frac{|y-a|}{b}
                    \right) </code>
</p>

<p>where <code class="reqn">-\infty&lt;y&lt;\infty</code>,
<code class="reqn">-\infty&lt;a&lt;\infty</code> and
<code class="reqn">b&gt;0</code>.
Its mean is <code class="reqn">a</code> and its variance is <code class="reqn">2b^2</code>.
This parameterization is called the <em>classical Laplace
distribution</em> by Kotz et al. (2001), and the density is symmetric
about <code class="reqn">a</code>.
</p>
<p>For <code>y ~ 1</code> (where <code>y</code> is the response)
the maximum likelihood estimate (MLE) for the location
parameter is the sample median, and the MLE for <code class="reqn">b</code> is
<code>mean(abs(y-location))</code> (replace location by its MLE
if unknown).
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This family function has not been fully tested.
The MLE regularity conditions do <em>not</em> hold for this
distribution, therefore misleading inferences may result, e.g.,
in the <code>summary</code> and <code>vcov</code> of the object.  Hence this
family function might be withdrawn from <span class="pkg">VGAM</span> in the future.
</p>


<h3>Note</h3>

<p>This family function uses Fisher scoring.
Convergence may be slow for non-intercept-only models;
half-stepping is frequently required.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kotz, S., Kozubowski, T. J. and Podgorski, K. (2001).
<em>The Laplace distribution and generalizations:
a revisit with applications to communications,
economics, engineering, and finance</em>,
Boston: Birkhauser.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rlaplace">rlaplace</a></code>,
<code><a href="#topic+alaplace2">alaplace2</a></code>
(which differs slightly from this parameterization),
<code><a href="#topic+exponential">exponential</a></code>,
<code><a href="stats.html#topic+median">median</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldata &lt;- data.frame(y = rlaplace(nn &lt;- 100, 2, scale = exp(1)))
fit &lt;- vglm(y  ~ 1, laplace, ldata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
with(ldata, median(y))

ldata &lt;- data.frame(x = runif(nn &lt;- 1001))
ldata &lt;- transform(ldata, y = rlaplace(nn, 2, scale = exp(-1 + 1*x)))
coef(vglm(y ~ x, laplace(iloc = 0.2, imethod = 2, zero = 1), ldata,
          trace = TRUE), matrix = TRUE)
</code></pre>

<hr>
<h2 id='laplaceUC'> The Laplace Distribution </h2><span id='topic+dlaplace'></span><span id='topic+plaplace'></span><span id='topic+qlaplace'></span><span id='topic+rlaplace'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Laplace distribution with location parameter
<code>location</code> and scale parameter <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlaplace(x, location = 0, scale = 1, log = FALSE)
plaplace(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
qlaplace(p, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
rlaplace(n, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="laplaceUC_+3A_x">x</code>, <code id="laplaceUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="laplaceUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="laplaceUC_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="laplaceUC_+3A_location">location</code></td>
<td>

<p>the location parameter <code class="reqn">a</code>, which is the mean.
</p>
</td></tr>
<tr><td><code id="laplaceUC_+3A_scale">scale</code></td>
<td>

<p>the scale parameter <code class="reqn">b</code>.
Must consist of positive values.
</p>
</td></tr>
<tr><td><code id="laplaceUC_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="laplaceUC_+3A_lower.tail">lower.tail</code>, <code id="laplaceUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Laplace distribution is often known as the double-exponential
distribution and, for modelling, has heavier tail than the
normal distribution.
The Laplace density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \frac{1}{2b} \exp \left( - \frac{|y-a|}{b}
                    \right) </code>
</p>

<p>where <code class="reqn">-\infty&lt;y&lt;\infty</code>,
<code class="reqn">-\infty&lt;a&lt;\infty</code> and
<code class="reqn">b&gt;0</code>.
The mean is <code class="reqn">a</code> and the variance is <code class="reqn">2b^2</code>.
</p>
<p>See <code><a href="#topic+laplace">laplace</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the two parameters by maximum likelihood estimation,
for formulae and details.
Apart from <code>n</code>, all the above arguments may be vectors and
are recyled to the appropriate length if necessary.
</p>


<h3>Value</h3>

<p><code>dlaplace</code> gives the density,
<code>plaplace</code> gives the distribution function,
<code>qlaplace</code> gives the quantile function, and
<code>rlaplace</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang</p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+laplace">laplace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>loc &lt;- 1; b &lt;- 2
y &lt;- rlaplace(n = 100, loc = loc, scale = b)
mean(y)  # sample mean
loc      # population mean
var(y)   # sample variance
2 * b^2  # population variance

## Not run:  loc &lt;- 0; b &lt;- 1.5; x &lt;- seq(-5, 5, by = 0.01)
plot(x, dlaplace(x, loc, b), type = "l", col = "blue",
     main = "Blue is density, orange is the CDF", ylim = c(0,1),
     sub = "Purple are 5,10,...,95 percentiles", las = 1, ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(qlaplace(seq(0.05,0.95,by = 0.05), loc, b),
      dlaplace(qlaplace(seq(0.05, 0.95, by = 0.05), loc, b), loc, b),
      col = "purple", lty = 3, type = "h")
lines(x, plaplace(x, loc, b), type = "l", col = "orange")
abline(h = 0, lty = 2) 
## End(Not run)

plaplace(qlaplace(seq(0.05, 0.95, by = 0.05), loc, b), loc, b)
</code></pre>

<hr>
<h2 id='latvar'> Latent Variables </h2><span id='topic+lv'></span><span id='topic+latvar'></span>

<h3>Description</h3>

<p>Generic function for the <em>latent variables</em> of a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>latvar(object, ...)
    lv(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="latvar_+3A_object">object</code></td>
<td>

<p>An object for which the extraction of latent
variables is meaningful.
</p>
</td></tr>
<tr><td><code id="latvar_+3A_...">...</code></td>
<td>

<p>Other arguments fed into the specific
methods function of the model. Sometimes they are fed
into the methods function for <code><a href="#topic+Coef">Coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Latent variables occur in reduced-rank regression models,
as well as in quadratic and additive ordination models.
For the latter two,
latent variable values are often called <em>site scores</em>
by ecologists.
Latent variables are linear combinations of the explanatory
variables.
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods
function invoked.
</p>


<h3>Warning</h3>

<p><code><a href="#topic+latvar">latvar</a></code> and <code><a href="#topic+lv">lv</a></code> are identical,
but the latter will be deprecated soon.
</p>
<p>Latent variables are not really applicable to
<code><a href="#topic+vglm">vglm</a></code>/<code><a href="#topic+vgam">vgam</a></code> models.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code>latvar.qrrvglm</code>,
<code>latvar.rrvglm</code>,
<code>latvar.cao</code>,
<code><a href="#topic+lvplot">lvplot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Standardized environmental vars
set.seed(123)
p1 &lt;- cao(cbind(Pardlugu, Pardmont, Pardnigr, Pardpull, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          family = poissonff, data = hspider, Rank = 1, df1.nl =
          c(Zoraspin = 2.5, 3), Bestof = 3, Crow1positive = TRUE)

var(latvar(p1))  # Scaled to unit variance  # Scaled to unit variance
c(latvar(p1))    # Estimated site scores

## End(Not run)
</code></pre>

<hr>
<h2 id='leipnik'>Leipnik Regression Family Function</h2><span id='topic+leipnik'></span>

<h3>Description</h3>

<p>Estimates the two parameters of a (transformed) Leipnik
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>leipnik(lmu = "logitlink", llambda = logofflink(offset = 1),
        imu = NULL, ilambda = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="leipnik_+3A_lmu">lmu</code>, <code id="leipnik_+3A_llambda">llambda</code></td>
<td>

<p>Link function for the <code class="reqn">\mu</code> and <code class="reqn">\lambda</code>
parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="leipnik_+3A_imu">imu</code>, <code id="leipnik_+3A_ilambda">ilambda</code></td>
<td>

<p>Numeric. Optional initial values for <code class="reqn">\mu</code> and
<code class="reqn">\lambda</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (transformed) Leipnik distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;\mu,\lambda) = \frac{ \{ y(1-y) \}^{-\frac12}}{
  \mbox{Beta}( \frac{\lambda+1}{2}, \frac12 )}
  \left[ 1 +  \frac{(y-\mu)^2 }{y(1-y)}
  \right]^{ -\frac{\lambda}{2}}</code>
</p>

<p>where <code class="reqn">0 &lt; y &lt; 1</code> and <code class="reqn">\lambda &gt; -1</code>.
The mean is <code class="reqn">\mu</code> (returned as the fitted values)
and the variance is <code class="reqn">1/\lambda</code>.
</p>
<p>Jorgensen (1997) calls the above the <b>transformed</b>
Leipnik distribution, and if <code class="reqn">y = (x+1)/2</code> and <code class="reqn">\mu =
  (\theta+1)/2</code>, then the distribution of <code class="reqn">X</code>
as a function of <code class="reqn">x</code> and <code class="reqn">\theta</code> is known as the
the (untransformed) Leipnik distribution.  Here, both <code class="reqn">x</code>
and <code class="reqn">\theta</code> are in <code class="reqn">(-1, 1)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Convergence may be slow or fail.
Until better initial value estimates are forthcoming try
assigning the argument <code>ilambda</code> some numerical value if it
fails to converge.  Currently, Newton-Raphson is implemented,
not Fisher scoring.  Currently, this family function probably
only really works for intercept-only models, i.e., <code>y ~
  1</code> in the formula.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Jorgensen, B. (1997).
<em>The Theory of Dispersion Models</em>.
London: Chapman &amp; Hall
</p>
<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1995).
<em>Continuous Univariate Distributions</em>,
2nd edition,
Volume 2,
New York: Wiley.
(pages 612&ndash;617).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mccullagh89">mccullagh89</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldata &lt;- data.frame(y = rnorm(2000, 0.5, 0.1))  # Improper data
fit &lt;- vglm(y ~ 1, leipnik(ilambda = 1), ldata, trace = TRUE)
head(fitted(fit))
with(ldata, mean(y))
summary(fit)
coef(fit, matrix = TRUE)
Coef(fit)

sum(weights(fit))  # Sum of the prior weights
sum(weights(fit, type = "work"))  # Sum of the working weights
</code></pre>

<hr>
<h2 id='lerch'> Lerch Phi Function </h2><span id='topic+lerch'></span>

<h3>Description</h3>

<p>Computes the Lerch Phi function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lerch(x, s, v, tolerance = 1.0e-10, iter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lerch_+3A_x">x</code>, <code id="lerch_+3A_s">s</code>, <code id="lerch_+3A_v">v</code></td>
<td>

<p>Numeric.
This function recyles values of <code>x</code>, <code>s</code>, and
<code>v</code> if necessary.
</p>
</td></tr>
<tr><td><code id="lerch_+3A_tolerance">tolerance</code></td>
<td>

<p>Numeric. Accuracy required, must be positive and less than 0.01.
</p>
</td></tr>
<tr><td><code id="lerch_+3A_iter">iter</code></td>
<td>

<p>Maximum number of iterations allowed to obtain convergence.
If <code>iter</code> is too small then a result of <code>NA</code> may occur;
if so, try increasing its value.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also known as
the Lerch transcendent, it can be defined by
an integral involving analytical continuation.
An alternative definition is the series
</p>
<p style="text-align: center;"><code class="reqn">\Phi(x,s,v) = \sum_{n=0}^{\infty}  \frac{x^n}{(n+v)^s}</code>
</p>

<p>which converges for <code class="reqn">|x|&lt;1</code>
as well as for <code class="reqn">|x|=1</code> with <code class="reqn">s&gt;1</code>.
The series is undefined for integers <code class="reqn">v &lt;= 0</code>.
Actually, <code class="reqn">x</code> may be complex but this function only works
for real <code class="reqn">x</code>.
The algorithm used is based on the relation
</p>
<p style="text-align: center;"><code class="reqn">\Phi(x,s,v) = x^m \Phi(x,s,v+m) + \sum_{n=0}^{m-1}
    \frac{x^n}{(n+v)^s} .</code>
</p>

<p>See the URL below for more information.
This function is a wrapper function for the C code described below.
</p>


<h3>Value</h3>

<p>Returns the value of the function evaluated at the values of
<code>x</code>, <code>s</code>, <code>v</code>.
If the above ranges of <code class="reqn">x</code> and <code class="reqn">v</code> are not satisfied,
or some numeric problems occur, then
this function will return an <code>NA</code> for those values.
(The C code returns 6 possible return codes, but this is
not passed back up to the R level.)
</p>


<h3>Warning </h3>

<p>This function has not been thoroughly tested and contains
limitations,
for example,
the zeta function cannot be computed with this function even
though
<code class="reqn">\zeta(s) = \Phi(x=1,s,v=1)</code>.
Several numerical problems can arise,
such as lack of convergence, overflow
and underflow, especially near singularities.
If any problems occur then an <code>NA</code> will be returned.
For example,
if <code class="reqn">|x|=1</code> and <code class="reqn">s&gt;1</code> then
convergence may be so slow that
changing <code>tolerance</code> and/or <code>iter</code> may be needed
to get an answer (that is treated cautiously).
</p>




<h3>Note</h3>

<p>There are a number of special cases, e.g.,
the Riemann zeta-function is
<code class="reqn">\zeta(s) = \Phi(x=1,s,v=1)</code>.
Another example is the Hurwitz zeta function
<code class="reqn">\zeta(s, v) = \Phi(x=1,s,v=v)</code>.
The special case of <code class="reqn">s=1</code> corresponds to the hypergeometric
2F1,
and this is implemented in the <span class="pkg">gsl</span> package.
The Lerch Phi function should not be confused with the
Lerch zeta function though they are quite similar.
</p>


<h3>Author(s)</h3>

<p>S. V. Aksenov and U. D. Jentschura wrote the C code
(called Version 1.00).
The R wrapper function was written by T. Yee.
</p>


<h3>References</h3>

<p>Originally the code was found at
<code>http://aksenov.freeshell.org/lerchphi/source/lerchphi.c</code>.
</p>
<p>Bateman, H. (1953).
<em>Higher Transcendental Functions</em>.
Volume 1. McGraw-Hill, NY, USA.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zeta">zeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
s &lt;- 2; v &lt;- 1; x &lt;- seq(-1.1, 1.1, length = 201)
plot(x, lerch(x, s = s, v = v), type = "l", col = "blue",
     las = 1, main = paste0("lerch(x, s = ", s,", v = ", v, ")"))
abline(v = 0, h = 1, lty = "dashed", col = "gray")

## End(Not run)
</code></pre>

<hr>
<h2 id='leukemia'>Acute Myelogenous Leukemia Survival Data</h2><span id='topic+leukemia'></span>

<h3>Description</h3>

<p>Survival in patients with Acute Myelogenous Leukemia</p>


<h3>Usage</h3>

<pre><code class='language-R'>
data(leukemia)
</code></pre>


<h3>Format</h3>


<table>
<tr>
 <td style="text-align: left;">
    time:</td><td style="text-align: left;"> survival or censoring time</td>
</tr>
<tr>
 <td style="text-align: left;">
    status:</td><td style="text-align: left;"> censoring status</td>
</tr>
<tr>
 <td style="text-align: left;">
    x: </td><td style="text-align: left;"> maintenance chemotherapy given? (factor)</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>This data set has been transferred from <span class="pkg">survival</span> and
renamed from <code>aml</code> to <code>leukemia</code>.
</p>


<h3>Source</h3>

<p>Rupert G. Miller (1997).
<em>Survival Analysis</em>.
John Wiley &amp; Sons.
</p>


<hr>
<h2 id='levy'> Levy Distribution Family Function </h2><span id='topic+levy'></span>

<h3>Description</h3>

<p>Estimates the scale parameter of the Levy distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>levy(location = 0, lscale = "loglink", iscale = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="levy_+3A_location">location</code></td>
<td>

<p>Location parameter. Must have a known value.
Called <code class="reqn">a</code> below.
</p>

</td></tr>
<tr><td><code id="levy_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link function for the (positive) scale parameter
<code class="reqn">b</code>.  See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="levy_+3A_iscale">iscale</code></td>
<td>

<p>Initial value for the <code class="reqn">b</code> parameter.
By default, an initial value is chosen internally.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Levy distribution is one of three stable distributions
whose density function has a tractable form.
The formula for the density is
</p>
<p style="text-align: center;"><code class="reqn">f(y;b) = \sqrt{\frac{b}{2\pi}}
       \exp \left( \frac{-b}{2(y - a)}
            \right) / (y - a)^{3/2} </code>
</p>

<p>where <code class="reqn">a&lt;y&lt;\infty</code> and <code class="reqn">b&gt;0</code>.
Note that if <code class="reqn">a</code> is very close to <code>min(y)</code>
(where <code>y</code> is the response), then numerical problem will
occur.  The mean does not exist.  The median is returned as
the fitted values.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Nolan, J. P. (2005).
<em>Stable Distributions: Models for Heavy Tailed Data</em>.
</p>



<h3>See Also</h3>

<p>The Nolan article was at
<code>http://academic2.american.edu/~jpnolan/stable/chap1.pdf</code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000; loc1 &lt;- 0; loc2 &lt;- 10
myscale &lt;- 1  # log link ==&gt; 0 is the answer
ldata &lt;-
  data.frame(y1 = loc1 + myscale/rnorm(nn)^2,  # Levy(myscale, a)
             y2 = rlevy(nn, loc = loc2, scale = exp(+2)))
# Cf. Table 1.1 of Nolan for Levy(1,0)
with(ldata, sum(y1 &gt; 1) / length(y1))  # Should be 0.6827
with(ldata, sum(y1 &gt; 2) / length(y1))  # Should be 0.5205

fit1 &lt;- vglm(y1 ~ 1, levy(location = loc1), ldata, trace = TRUE)
coef(fit1, matrix = TRUE)
Coef(fit1)
summary(fit1)
head(weights(fit1, type = "work"))

fit2 &lt;- vglm(y2 ~ 1, levy(location = loc2), ldata, trace = TRUE)
coef(fit2, matrix = TRUE)
Coef(fit2)
c(median = with(ldata, median(y2)),
  fitted.median = head(fitted(fit2), 1))
</code></pre>

<hr>
<h2 id='lgamma1'> Log-gamma Distribution Family Function </h2><span id='topic+lgamma1'></span><span id='topic+lgamma3'></span>

<h3>Description</h3>

<p>Estimation of the parameter of the standard and nonstandard
log-gamma distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lgamma1(lshape = "loglink", ishape = NULL)
lgamma3(llocation = "identitylink", lscale = "loglink",
   lshape = "loglink", ilocation = NULL, iscale = NULL, ishape = 1,
   zero = c("scale", "shape"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lgamma1_+3A_llocation">llocation</code>, <code id="lgamma1_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link function applied to the
location parameter <code class="reqn">a</code>
and the positive scale parameter <code class="reqn">b</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="lgamma1_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function applied to
the positive shape parameter <code class="reqn">k</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="lgamma1_+3A_ishape">ishape</code></td>
<td>

<p>Initial value for <code class="reqn">k</code>.
If given, it must be positive.
If failure to converge occurs, try some other value.
The default means an initial value is determined internally.
</p>
</td></tr>
<tr><td><code id="lgamma1_+3A_ilocation">ilocation</code>, <code id="lgamma1_+3A_iscale">iscale</code></td>
<td>
<p> Initial value for <code class="reqn">a</code> and <code class="reqn">b</code>.
The defaults mean an initial value is determined internally
for each.
</p>
</td></tr>
<tr><td><code id="lgamma1_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The values must be from the set {1,2,3}.
The default value means none are modelled as intercept-only terms.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function of the standard log-gamma
distribution is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y;k)=\exp[ky - \exp(y)] / \Gamma(k),</code>
</p>

<p>for parameter <code class="reqn">k&gt;0</code> and all real <code class="reqn">y</code>.
The mean of <code class="reqn">Y</code> is <code>digamma(k)</code> (returned as
the fitted values) and its variance is <code>trigamma(k)</code>.
</p>
<p>For the non-standard log-gamma distribution, one replaces <code class="reqn">y</code>
by <code class="reqn">(y-a)/b</code>, where <code class="reqn">a</code> is the location parameter
and <code class="reqn">b</code> is the positive scale parameter.
Then the density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y)=\exp[k(y-a)/b - \exp((y-a)/b)] / (b \, \Gamma(k)).</code>
</p>

<p>The mean and variance of <code class="reqn">Y</code> are <code>a + b*digamma(k)</code>
(returned as
the fitted values) and <code>b^2 * trigamma(k)</code>, respectively.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The standard log-gamma distribution can be viewed as a
generalization of the standard type 1 extreme value density:
when <code class="reqn">k = 1</code> the distribution of <code class="reqn">-Y</code> is the standard
type 1 extreme value distribution.
</p>
<p>The standard log-gamma distribution is fitted with <code>lgamma1</code>
and the non-standard (3-parameter) log-gamma distribution is
fitted with <code>lgamma3</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kotz, S. and Nadarajah, S. (2000).
<em>Extreme Value Distributions: Theory and Applications</em>,
pages 48&ndash;49,
London: Imperial College Press.
</p>
<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1995).
<em>Continuous Univariate Distributions</em>,
2nd edition, Volume 2, p.89,
New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rlgamma">rlgamma</a></code>,
<code><a href="#topic+gengamma.stacy">gengamma.stacy</a></code>,
<code><a href="#topic+prentice74">prentice74</a></code>,
<code><a href="#topic+gamma1">gamma1</a></code>,
<code><a href="base.html#topic+Special">lgamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldata &lt;- data.frame(y = rlgamma(100, shape = exp(1)))
fit &lt;- vglm(y ~ 1, lgamma1, ldata, trace = TRUE, crit = "coef")
summary(fit)
coef(fit, matrix = TRUE)
Coef(fit)

ldata &lt;- data.frame(x2 = runif(nn &lt;- 5000))  # Another example
ldata &lt;- transform(ldata, loc = -1 + 2 * x2, Scale = exp(1))
ldata &lt;- transform(ldata, y = rlgamma(nn, loc, sc = Scale, sh = exp(0)))
fit2 &lt;- vglm(y ~ x2, lgamma3, data = ldata, trace = TRUE, crit = "c")
coef(fit2, matrix = TRUE)
</code></pre>

<hr>
<h2 id='lgammaUC'>The Log-Gamma Distribution </h2><span id='topic+lgammaUC'></span><span id='topic+dlgamma'></span><span id='topic+plgamma'></span><span id='topic+qlgamma'></span><span id='topic+rlgamma'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the log-gamma distribution with location
parameter <code>location</code>, scale parameter <code>scale</code> and
shape parameter <code>k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlgamma(x, location = 0, scale = 1, shape = 1, log = FALSE)
plgamma(q, location = 0, scale = 1, shape = 1,
        lower.tail = TRUE, log.p = FALSE)
qlgamma(p, location = 0, scale = 1, shape = 1,
        lower.tail = TRUE, log.p = FALSE)
rlgamma(n, location = 0, scale = 1, shape = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lgammaUC_+3A_x">x</code>, <code id="lgammaUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_location">location</code></td>
<td>
<p>the location parameter <code class="reqn">a</code>.</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_scale">scale</code></td>
<td>
<p>the (positive) scale parameter <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_shape">shape</code></td>
<td>
<p>the (positive) shape parameter <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="lgammaUC_+3A_lower.tail">lower.tail</code>, <code id="lgammaUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+lgamma1">lgamma1</a></code>, the <span class="pkg">VGAM</span> family function for
estimating the one parameter standard log-gamma distribution by
maximum likelihood estimation, for formulae and other details.
Apart from <code>n</code>, all the above arguments may be vectors
and are recyled to the appropriate length if necessary.
</p>


<h3>Value</h3>

<p><code>dlgamma</code> gives the density,
<code>plgamma</code> gives the distribution function,
<code>qlgamma</code> gives the quantile function, and
<code>rlgamma</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The <span class="pkg">VGAM</span> family function <code><a href="#topic+lgamma3">lgamma3</a></code> is
for the three parameter (nonstandard) log-gamma distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kotz, S. and Nadarajah, S. (2000).
<em>Extreme Value Distributions: Theory and Applications</em>,
pages 48&ndash;49,
London: Imperial College Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lgamma1">lgamma1</a></code>,
<code><a href="#topic+prentice74">prentice74</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  loc &lt;- 1; Scale &lt;- 1.5; shape &lt;- 1.4
x &lt;- seq(-3.2, 5, by = 0.01)
plot(x, dlgamma(x, loc = loc, Scale, shape = shape), type = "l",
     col = "blue", ylim = 0:1,
     main = "Blue is density, orange is the CDF",
     sub = "Red are 5,10,...,95 percentiles", las = 1, ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(qlgamma(seq(0.05, 0.95, by = 0.05), loc = loc, Scale, sh = shape),
      dlgamma(qlgamma(seq(0.05, 0.95, by = 0.05), loc = loc, sc = Scale,
                      shape = shape),
    loc = loc, Scale, shape = shape), col = "red", lty = 3, type = "h")
lines(x, plgamma(x, loc = loc, Scale, shape = shape), col = "orange")
abline(h = 0, lty = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='lindley'> 1-parameter Gamma Distribution </h2><span id='topic+lindley'></span>

<h3>Description</h3>

<p>Estimates the (1-parameter) Lindley distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lindley(link = "loglink", itheta = NULL, zero = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lindley_+3A_link">link</code></td>
<td>

<p>Link function applied to the (positive) parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>




<tr><td><code id="lindley_+3A_itheta">itheta</code>, <code id="lindley_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y; \theta) = \theta^2 (1 + y) \exp(-\theta y) / (1 + \theta)</code>
</p>

<p>for <code class="reqn">\theta &gt; 0</code> and <code class="reqn">y &gt; 0</code>.
The mean of <code class="reqn">Y</code> (returned as the fitted values)
is <code class="reqn">\mu = (\theta + 2) / (\theta (\theta + 1))</code>.
The variance
is <code class="reqn">(\theta^2 + 4  \theta + 2) / (\theta  (\theta + 1))^2</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This <span class="pkg">VGAM</span> family function can handle multiple
responses (inputted as a matrix).
Fisher scoring is implemented.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Lindley, D. V. (1958).
Fiducial distributions and Bayes' theorem.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>20</b>, 102&ndash;107.
</p>
<p>Ghitany, M. E. and Atieh, B. and Nadarajah, S. (2008).
Lindley distribution and its application.
<em>Math. Comput. Simul.</em>,
<b>78</b>, 493&ndash;506.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dlind">dlind</a></code>,
<code><a href="#topic+gammaR">gammaR</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldata &lt;- data.frame(y = rlind(n = 1000, theta = exp(3)))
fit &lt;- vglm(y ~ 1, lindley, data = ldata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Lindley'>The Lindley Distribution</h2><span id='topic+Lindley'></span><span id='topic+dlind'></span><span id='topic+plind'></span><span id='topic+rlind'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function,
and
random generation for
the Lindley distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dlind(x, theta, log = FALSE)
plind(q, theta, lower.tail = TRUE, log.p = FALSE)
rlind(n, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lindley_+3A_x">x</code>, <code id="Lindley_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>

<tr><td><code id="Lindley_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Lindley_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Lindley_+3A_theta">theta</code></td>
<td>
<p>positive parameter.
</p>
</td></tr>
<tr><td><code id="Lindley_+3A_lower.tail">lower.tail</code>, <code id="Lindley_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+lindley">lindley</a></code> for details.
</p>


<h3>Value</h3>

<p><code>dlind</code> gives the density,
<code>plind</code> gives the cumulative distribution function, and
<code>rlind</code> generates random deviates.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+lindley">lindley</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>theta &lt;- exp(-1); x &lt;- seq(0.0, 17, length = 700)
dlind(0:10, theta)
## Not run: 
plot(x, dlind(x, theta), type = "l", las = 1, col = "blue",
     main = "dlind(x, theta = exp(-1))")
abline(h = 1, col = "grey", lty = "dashed") 
## End(Not run)
</code></pre>

<hr>
<h2 id='linkfun'> Link Functions for VGLMs </h2><span id='topic+linkfun'></span><span id='topic+linkfunvlm'></span>

<h3>Description</h3>

<p>Returns the link functions, and parameter names,
for <em>vector generalized linear models</em> (VGLMs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linkfun(object, ...)
linkfunvlm(object, earg = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linkfun_+3A_object">object</code></td>
<td>

<p>An object which has parameter link functions, e.g.,
has class <code>"vglm"</code>.
</p>
</td></tr>
<tr><td><code id="linkfun_+3A_earg">earg</code></td>
<td>
<p> Logical.
Return the extra arguments associated with each
link function? If <code>TRUE</code> then a list is returned.
</p>
</td></tr>
<tr><td><code id="linkfun_+3A_...">...</code></td>
<td>
<p> Arguments that might be used
in the future.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All fitted VGLMs have a link function applied to each parameter.
This function returns these, and optionally, the extra
arguments associated with them.
</p>


<h3>Value</h3>

<p>Usually just a (named) character string, with the link functions
in order.
It is named with the parameter names.
If <code>earg = TRUE</code> then a list with the following components.
</p>
<table>
<tr><td><code>link</code></td>
<td>

<p>The default output.
</p>
</td></tr>
<tr><td><code>earg</code></td>
<td>
<p>The extra arguments, in order.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Presently, the multinomial logit model has only
one link function, <code><a href="#topic+multilogitlink">multilogitlink</a></code>,
so a warning is not issued for that link.
For other models, if the number of link functions does
not equal <code class="reqn">M</code> then a warning may be issued.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+linkfun">linkfun</a></code>,
<code><a href="#topic+multilogitlink">multilogitlink</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, data = pneumo)
coef(fit1, matrix = TRUE)
linkfun(fit1)
linkfun(fit1, earg = TRUE)

fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let, multinomial, data = pneumo)
coef(fit2, matrix = TRUE)
linkfun(fit2)
linkfun(fit2, earg = TRUE)
</code></pre>

<hr>
<h2 id='Links'>Link functions for VGLM/VGAM/etc. families</h2><span id='topic+Links'></span><span id='topic+TypicalVGAMlink'></span>

<h3>Description</h3>

<p>The <span class="pkg">VGAM</span> package provides a number of
(parameter) link functions which are described
in general here. Collectively, they offer the
user considerable choice and flexibility for
modelling data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TypicalVGAMlink(theta, someParameter = 0, bvalue = NULL, inverse = FALSE,
                deriv = 0, short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Links_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
This is usually <code class="reqn">\theta</code> (default)
but can sometimes be <code class="reqn">\eta</code>,
depending on the other arguments.
If <code>theta</code> is character then <code>inverse</code> and
<code>deriv</code> are ignored.
The name <code>theta</code> should always be the
name of the first argument.
</p>
</td></tr>
<tr><td><code id="Links_+3A_someparameter">someParameter</code></td>
<td>

<p>Some parameter, e.g., an offset.
</p>
</td></tr>
<tr><td><code id="Links_+3A_bvalue">bvalue</code></td>
<td>

<p>Boundary value, positive if given.
If <code>0 &lt; theta</code> then
values of <code>theta</code> which are less than
or equal to 0 can be replaced by <code>bvalue</code>
before computing the link function value.
Values of <code>theta</code> which are greater than
or equal to 1 can be
replaced by 1 minus <code>bvalue</code>
before computing the link function value.
The value <code>bvalue = .Machine$double.eps</code>
is sometimes a reasonable value, or something
slightly higher.
</p>
</td></tr>




















<tr><td><code id="Links_+3A_inverse">inverse</code></td>
<td>

<p>Logical. If <code>TRUE</code> and <code>deriv = 0</code>  then
the inverse link value
<code class="reqn">\theta</code> is returned, hence the argument
<code>theta</code> is really <code class="reqn">\eta</code>.
In all other cases, the argument <code>theta</code> is
really <code class="reqn">\theta</code>.
</p>
</td></tr>
<tr><td><code id="Links_+3A_deriv">deriv</code></td>
<td>

<p>Integer.
Either 0, 1, or 2, specifying the order of
the derivative.  Some link functions handle
values up to 3 or 4.
</p>
</td></tr>
<tr><td><code id="Links_+3A_short">short</code>, <code id="Links_+3A_tag">tag</code></td>
<td>

<p>Logical.
These are used for labelling the <code>blurb</code>
slot of a <code><a href="#topic+vglmff-class">vglmff-class</a></code> object.
These arguments are used only if <code>theta</code>
is character, and gives the formula for the
link in character form.  If <code>tag = TRUE</code>
then the result is preceeded by a little
more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Almost all <span class="pkg">VGAM</span> link functions have
something similar to the argument list as
given above.  In this help file we have
<code class="reqn">\eta = g(\theta)</code>
where <code class="reqn">g</code> is the link function,
<code class="reqn">\theta</code> is the parameter and
<code class="reqn">\eta</code> is the linear/additive
predictor.  The link <code class="reqn">g</code> must be strictly
monotonic and twice-differentiable in its
range.
</p>



<p>The following is a brief enumeration of all
<span class="pkg">VGAM</span> link functions.
</p>
<p>For parameters lying between 0 and 1 (e.g.,
probabilities):
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="#topic+foldsqrtlink">foldsqrtlink</a></code>,
<code><a href="#topic+logclink">logclink</a></code>.



</p>
<p>For positive parameters
(i.e., greater than 0):
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+negloglink">negloglink</a></code>,
<code><a href="#topic+sqrtlink">sqrtlink</a></code>,
<code><a href="#topic+powerlink">powerlink</a></code>.
</p>
<p>For parameters greater than 1:
<code><a href="#topic+logloglink">logloglink</a></code>,
<code><a href="#topic+loglogloglink">loglogloglink</a></code> (greater than <code class="reqn">e</code>).
</p>
<p>For parameters between <code class="reqn">-1</code> and <code class="reqn">1</code>:
<code><a href="#topic+fisherzlink">fisherzlink</a></code>,
<code><a href="#topic+rhobitlink">rhobitlink</a></code>.
</p>
<p>For parameters between finite <code class="reqn">A</code> and <code class="reqn">B</code>:
<code><a href="#topic+extlogitlink">extlogitlink</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code> (<code class="reqn">B = \infty</code>).
</p>
<p>For unrestricted parameters (i.e., any value):
<code><a href="#topic+identitylink">identitylink</a></code>,
<code><a href="#topic+negidentitylink">negidentitylink</a></code>,
<code><a href="#topic+reciprocallink">reciprocallink</a></code>,
<code><a href="#topic+negreciprocallink">negreciprocallink</a></code>.
</p>



<h3>Value</h3>

<p>Returns one of:
the link function value or its first or second
derivative, the inverse link or its first or
second derivative, or a character description
of the link.
</p>
<p>Here are the general details.
If <code>inverse = FALSE</code> and <code>deriv = 0</code>
(default) then the ordinary link function
<code class="reqn">\eta = g(\theta)</code>
is returned.
</p>
<p>If <code>inverse = TRUE</code> and <code>deriv =
  0</code> then the inverse link function value
is returned, hence <code>theta</code> is really
<code class="reqn">\eta</code> (the only occasion this
happens).
</p>
<p>If <code>inverse = FALSE</code> and <code>deriv
  = 1</code> then it is <code class="reqn">d\eta / d\theta</code> <em>as a function of</em>
<code class="reqn">\theta</code>.  If <code>inverse =
  FALSE</code> and <code>deriv = 2</code> then it is
<code class="reqn">d^2\eta / d\theta^2</code>
<em>as a function of</em> <code class="reqn">\theta</code>.
</p>
<p>If <code>inverse = TRUE</code> and <code>deriv
  = 1</code> then it is <code class="reqn">d\theta / d\eta</code> <em>as a function of</em>
<code class="reqn">\theta</code>.  If <code>inverse = TRUE</code>
and <code>deriv = 2</code> then it is <code class="reqn">d^2\theta
  / d\eta^2</code> <em>as a
function of</em> <code class="reqn">\theta</code>.
</p>
<p>It is only when <code>deriv = 1</code> that
<code>linkfun(theta, deriv = 1, inverse = TRUE)</code>
and
<code>linkfun(theta, deriv = 1, inverse = FALSE)</code>
are <em>reciprocals</em> of each other.
In particular,
<code>linkfun(theta, deriv = 2, inverse = TRUE)</code>
and
<code>linkfun(theta, deriv = 2, inverse = FALSE)</code>
are <em>not</em> reciprocals of each other
in general.
</p>
















<h3>Warning </h3>

<p>The output of link functions changed at
<span class="pkg">VGAM</span> <code>0.9-9</code> (date was around
2015-07).  Formerly, <code>linkfun(theta,
  deriv = 1)</code> is now <code>linkfun(theta,
  deriv = 1, inverse = TRUE)</code>, or equivalently,
<code>1 / linkfun(theta, deriv = 1, inverse =
  TRUE)</code>.  Also, formerly, <code>linkfun(theta,
  deriv = 2)</code> was <code>1 / linkfun(theta,
  deriv = 2, inverse = TRUE)</code>.  This was a bug.
Altogether, these are big changes and the
user should beware!
</p>
<p>In <span class="pkg">VGAM</span> <code>1.0-7</code> (January 2019)
all link function names were made to
end in the characters <code>"link"</code>,
e.g.,
<code><a href="#topic+loglink">loglink</a></code> replaces <code><a href="#topic+loge">loge</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code> replaces <code><a href="#topic+logit">logit</a></code>.
For this most of them were renamed.
Upward compatability holds for older link
function names, however, users should adopt
the new names immediately.
</p>




<h3>Note</h3>

<p><span class="pkg">VGAM</span> link functions are generally
not compatible with other functions outside
the package.  In particular, they won't work
with <code><a href="stats.html#topic+glm">glm</a></code> or any other
package for fitting GAMs.
</p>
<p>From October 2006 onwards,
all <span class="pkg">VGAM</span> family functions will only
contain one default value for each link
argument rather than giving a vector
of choices.  For example, rather than
<code>binomialff(link = c("logitlink",
  "probitlink", "clogloglink", "cauchitlink",
  "identitylink"), ...)</code> it is now
<code>binomialff(link = "logitlink", ...)</code>.
No checking will be done to see if the user's
choice is reasonable.  This means that the
user can write his/her own <span class="pkg">VGAM</span> link
function and use it within any <span class="pkg">VGAM</span>
family function.  Altogether this provides
greater flexibility.  The downside is that
the user must specify the <em>full</em> name of
the link function, by either assigning the
link argument the full name as a character
string, or just the name itself.  See the
examples below.
</p>
<p>From August 2012 onwards, a major
change in link functions occurred.
Argument <code>esigma</code> (and the like such
as <code>earg</code>) used to be in <span class="pkg">VGAM</span>
prior to version 0.9-0 (released during the
2nd half of 2012).
The major change is that arguments such as
<code>offset</code> that used to be passed in via
those arguments can done directly through
the link function. For example,
<code>gev(lshape = "logofflink", eshape = list(offset = 0.5))</code>
is replaced by
<code>gev(lshape = logofflink(offset = 0.5))</code>.
The <code>@misc</code> slot no longer
has <code>link</code> and <code>earg</code> components,
but two other components replace
these. Functions such as
<code>dtheta.deta()</code>,
<code>d2theta.deta2()</code>,
<code>d3theta.deta3()</code>,
<code>eta2theta()</code>,
<code>theta2eta()</code>
are modified.
</p>
<p>From January 2019 onwards, all link function
names ended in <code>"link"</code>. See above
for details.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>,
2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TypicalVGAMfamilyFunction">TypicalVGAMfamilyFunction</a></code>,
<code><a href="#topic+linkfun">linkfun</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>.
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+cao">cao</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>logitlink("a")
logitlink("a", short = FALSE)
logitlink("a", short = FALSE, tag = TRUE)

logofflink(1:5, offset = 1)  # Same as log(1:5 + 1)
powerlink(1:5, power = 2)  # Same as (1:5)^2

## Not run:  # This is old and no longer works:
logofflink(1:5, earg = list(offset = 1))
powerlink(1:5, earg = list(power = 2))

## End(Not run)

fit1 &lt;- vgam(agaaus ~ altitude,
             binomialff(link = "clogloglink"), hunua)  # best
fit2 &lt;- vgam(agaaus ~ altitude,
             binomialff(link =  clogloglink ), hunua)  # okay

## Not run: 
# This no longer works since "clog" is not a valid VGAM link function:
fit3 &lt;- vgam(agaaus ~ altitude,
             binomialff(link = "clog"), hunua)  # not okay


# No matter what the link, the estimated var-cov matrix is the same
y &lt;- rbeta(n = 1000, shape1 = exp(0), shape2 = exp(1))
fit1 &lt;- vglm(y ~ 1, betaR(lshape1 = "identitylink",
                          lshape2 = "identitylink"),
             trace = TRUE, crit = "coef")
fit2 &lt;- vglm(y ~ 1, betaR(lshape1 = logofflink(offset = 1.1),
                          lshape2 = logofflink(offset = 1.1)), trace=TRUE)
vcov(fit1, untransform = TRUE)
vcov(fit1, untransform = TRUE) -
vcov(fit2, untransform = TRUE)  # Should be all 0s
\dontrun{ # This is old:
fit1@misc$earg  # Some 'special' parameters
fit2@misc$earg  # Some 'special' parameters are here
}


par(mfrow = c(2, 2))
p &lt;- seq(0.05, 0.95, len = 200)  # A rather restricted range
x &lt;- seq(-4, 4, len = 200)
plot(p, logitlink(p), type = "l", col = "blue")
plot(x, logitlink(x, inverse = TRUE), type = "l", col = "blue")
plot(p, logitlink(p, deriv=1), type="l", col="blue") # 1 / (p*(1-p))
plot(p, logitlink(p, deriv=2), type="l", col="blue") # (2*p-1)/(p*(1-p))^2

## End(Not run)
</code></pre>

<hr>
<h2 id='lino'> Generalized Beta Distribution Family Function </h2><span id='topic+lino'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 3-parameter
generalized beta distribution as proposed by Libby and Novick
(1982).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lino(lshape1 = "loglink", lshape2 = "loglink", llambda = "loglink",
     ishape1 = NULL,   ishape2 = NULL,   ilambda = 1, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lino_+3A_lshape1">lshape1</code>, <code id="lino_+3A_lshape2">lshape2</code></td>
<td>

<p>Parameter link functions applied to the two
(positive) shape parameters <code class="reqn">a</code> and <code class="reqn">b</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="lino_+3A_llambda">llambda</code></td>
<td>

<p>Parameter link function applied to the
parameter <code class="reqn">\lambda</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="lino_+3A_ishape1">ishape1</code>, <code id="lino_+3A_ishape2">ishape2</code>, <code id="lino_+3A_ilambda">ilambda</code></td>
<td>

<p>Initial values for the parameters. A <code>NULL</code> value means
one is computed internally. The argument <code>ilambda</code> must
be numeric, and the default corresponds to a standard beta
distribution.
</p>
</td></tr>
<tr><td><code id="lino_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
Here, the values must be from the set {1,2,3} which correspond
to <code class="reqn">a</code>, <code class="reqn">b</code>, <code class="reqn">\lambda</code>, respectively.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Proposed by Libby and Novick (1982),
this distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y;a,b,\lambda) = \frac{\lambda^{a} y^{a-1} (1-y)^{b-1}}{
   B(a,b) \{1 - (1-\lambda) y\}^{a+b}}</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">\lambda &gt; 0</code>,
<code class="reqn">0 &lt; y &lt; 1</code>.
Here <code class="reqn">B</code> is the beta function (see
<code><a href="base.html#topic+Special">beta</a></code>).
The mean is a complicated function involving the Gauss hypergeometric
function.
If <code class="reqn">X</code> has a <code>lino</code> distribution with parameters
<code>shape1</code>, <code>shape2</code>, <code>lambda</code>, then
<code class="reqn">Y=\lambda X/(1-(1-\lambda)X)</code>
has a standard beta distribution with parameters <code>shape1</code>,
<code>shape2</code>.
</p>
<p>Since <code class="reqn">\log(\lambda)=0</code> corresponds to the
standard beta distribution, a <code>summary</code> of the fitted model
performs a t-test for whether the data belongs to a standard
beta distribution (provided the <code><a href="#topic+loglink">loglink</a></code> link for
<code class="reqn">\lambda</code> is used; this is the default).
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The fitted values, which is usually the mean, have not
been implemented yet.
Currently the median is returned as the fitted values.
</p>

<p>Although Fisher scoring is used, the working weight matrices
are positive-definite only in a certain region of the parameter
space. Problems with this indicate poor initial values or an
ill-conditioned model or insufficient data etc.
</p>
<p>This model is can be difficult to fit. A reasonably good value of
<code>ilambda</code> seems to be needed so if the self-starting initial
values fail, try experimenting with the initial value arguments.
Experience suggests <code>ilambda</code> is better a little larger,
rather than smaller, compared to the true value.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Libby, D. L. and Novick, M. R. (1982).
Multivariate generalized beta distributions with applications to
utility assessment.
<em>Journal of Educational Statistics</em>,
<b>7</b>, 271&ndash;294.
</p>
<p>Gupta, A. K. and Nadarajah, S. (2004).
<em>Handbook of Beta Distribution and Its Applications</em>,
NY: Marcel Dekker, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lino">Lino</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldata &lt;- data.frame(y1 = rbeta(n = 1000, exp(0.5), exp(1)))  # Std beta
fit &lt;- vglm(y1 ~ 1, lino, data = ldata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
head(fitted(fit))
summary(fit)

# Nonstandard beta distribution
ldata &lt;- transform(ldata, y2 = rlino(1000, shape1 = exp(1),
                                     shape2 = exp(2), lambda = exp(1)))
fit2 &lt;- vglm(y2 ~ 1,
             lino(lshape1 = "identitylink", lshape2 = "identitylink",
                  ilamb = 10), data = ldata, trace = TRUE)
coef(fit2, matrix = TRUE)
</code></pre>

<hr>
<h2 id='Lino'>The Generalized Beta Distribution (Libby and Novick, 1982)</h2><span id='topic+Lino'></span><span id='topic+dlino'></span><span id='topic+plino'></span><span id='topic+qlino'></span><span id='topic+rlino'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the generalized beta distribution, as proposed
by Libby and Novick (1982).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlino(x, shape1, shape2, lambda = 1, log = FALSE)
plino(q, shape1, shape2, lambda = 1, lower.tail = TRUE, log.p = FALSE)
qlino(p, shape1, shape2, lambda = 1, lower.tail = TRUE, log.p = FALSE)
rlino(n, shape1, shape2, lambda = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lino_+3A_x">x</code>, <code id="Lino_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Lino_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Lino_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Lino_+3A_shape1">shape1</code>, <code id="Lino_+3A_shape2">shape2</code>, <code id="Lino_+3A_lambda">lambda</code></td>
<td>
<p> see <code><a href="#topic+lino">lino</a></code>. </p>
</td></tr>
<tr><td><code id="Lino_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Lino_+3A_lower.tail">lower.tail</code>, <code id="Lino_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+lino">lino</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for the formula of the probability density function and other
details.
</p>


<h3>Value</h3>

<p><code>dlino</code> gives the density,
<code>plino</code> gives the distribution function,
<code>qlino</code> gives the quantile function, and
<code>rlino</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+lino">lino</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:   lambda &lt;- 0.4; shape1 &lt;- exp(1.3); shape2 &lt;- exp(1.3)
x &lt;- seq(0.0, 1.0, len = 101)
plot(x, dlino(x, shape1 = shape1, shape2 = shape2, lambda = lambda),
     type = "l", col = "blue", las = 1, ylab = "",
     main = "Blue is PDF, orange is the CDF",
     sub = "Purple lines are the 10,20,...,90 percentiles")
abline(h = 0, col = "blue", lty = 2)
lines(x, plino(x, shape1, shape2, lambda = lambda), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qlino(probs, shape1 = shape1, shape2 = shape2, lambda = lambda)
lines(Q, dlino(Q, shape1 = shape1, shape2 = shape2, lambda = lambda),
      col = "purple", lty = 3, type = "h")
plino(Q, shape1, shape2, lambda = lambda) - probs  # Should be all 0

## End(Not run)
</code></pre>

<hr>
<h2 id='lirat'> Low-iron Rat Teratology Data </h2><span id='topic+lirat'></span>

<h3>Description</h3>

<p>Low-iron rat teratology data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lirat)</code></pre>


<h3>Format</h3>

<p>A data frame with 58 observations on the following 4 variables.
</p>

<dl>
<dt><code>N</code></dt><dd><p>Litter size.</p>
</dd>
<dt><code>R</code></dt><dd><p>Number of dead fetuses.</p>
</dd>
<dt><code>hb</code></dt><dd><p>Hemoglobin level.</p>
</dd>
<dt><code>grp</code></dt><dd><p>Group number.
Group 1 is the untreated (low-iron) group,
group 2 received injections on day 7 or day 10 only,
group 3 received injections on days 0 and 7, and
group 4 received injections weekly.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The following description comes from Moore and Tsiatis (1991).  The data
comes from the experimental setup from Shepard et al. (1980), which is
typical of studies of the effects of chemical agents or dietary regimens
on fetal development in laboratory rats.
</p>
<p>Female rats were put in iron-deficient diets and divided into 4
groups. One group of controls was given weekly injections of iron
supplement to bring their iron intake to normal levels, while another
group was given only placebo injections.  Two other groups were given
fewer iron-supplement injections than the controls.  The rats were made
pregnant, sacrificed 3 weeks later, and the total number of fetuses and
the number of dead fetuses in each litter were counted.
</p>
<p>For each litter the number of dead fetuses may be considered to be
Binomial(<code class="reqn">N,p</code>) where <code class="reqn">N</code> is the litter size and <code class="reqn">p</code>
is the probability of a fetus dying. The parameter <code class="reqn">p</code> is expected
to vary from litter to litter, therefore the total variance of the
proportions will be greater than that predicted by a binomial model,
even when the covariates for hemoglobin level and experimental group
are accounted for.
</p>


<h3>Source</h3>

<p>Moore, D. F. and Tsiatis, A. (1991)
Robust Estimation of the Variance in Moment Methods for
Extra-binomial and Extra-Poisson Variation.
<em>Biometrics</em>,
<b>47</b>, 383&ndash;401.
</p>


<h3>References</h3>

<p>Shepard, T. H., Mackler, B. and Finch, C. A. (1980).
Reproductive studies in the iron-deficient rat.
<em>Teratology</em>, <b>22</b>, 329&ndash;334.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# cf. Figure 3 of Moore and Tsiatis (1991)
plot(R / N ~ hb, data = lirat, pch = as.character(grp), col = grp,
     las = 1, xlab = "Hemoglobin level", ylab = "Proportion Dead") 
## End(Not run)
</code></pre>

<hr>
<h2 id='lms.bcg'> LMS Quantile Regression with a Box-Cox transformation
to a Gamma Distribution </h2><span id='topic+lms.bcg'></span>

<h3>Description</h3>

<p>LMS quantile regression with the Box-Cox transformation
to the gamma distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lms.bcg(percentiles = c(25, 50, 75), zero = c("lambda", "sigma"),
   llambda = "identitylink", lmu = "identitylink", lsigma = "loglink",
   idf.mu = 4, idf.sigma = 2, ilambda = 1, isigma = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lms.bcg_+3A_percentiles">percentiles</code></td>
<td>

<p>A numerical vector containing values between 0 and 100,
which are the quantiles. They will be returned as 'fitted
values'.
</p>
</td></tr>
<tr><td><code id="lms.bcg_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="lms.bcg_+3A_llambda">llambda</code>, <code id="lms.bcg_+3A_lmu">lmu</code>, <code id="lms.bcg_+3A_lsigma">lsigma</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.bcg_+3A_idf.mu">idf.mu</code>, <code id="lms.bcg_+3A_idf.sigma">idf.sigma</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.bcg_+3A_ilambda">ilambda</code>, <code id="lms.bcg_+3A_isigma">isigma</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a value of the covariate, this function applies a
Box-Cox transformation to the response to best obtain a
gamma distribution.  The parameters chosen to do this are
estimated by maximum likelihood or penalized maximum likelihood.
Similar details can be found at <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This <span class="pkg">VGAM</span> family function comes with the same
warnings as <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
Also, the expected value of the second derivative with
respect to lambda may be incorrect (my calculations do
not agree with the Lopatatzidis and Green manuscript.)
</p>


<h3>Note</h3>

<p>Similar notes can be found at <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Lopatatzidis A. and Green, P. J. (unpublished manuscript).
Semiparametric quantile regression using the gamma distribution.
</p>
<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+lms.yjn">lms.yjn</a></code>,
<code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>,
<code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>,
<code><a href="#topic+cdf.lmscreg">cdf.lmscreg</a></code>,
<code><a href="#topic+bmi.nz">bmi.nz</a></code>,
<code><a href="#topic+amlexponential">amlexponential</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This converges, but deplot(fit) and qtplot(fit) do not work
fit0 &lt;- vglm(BMI ~ sm.bs(age, df = 4), lms.bcg, bmi.nz, trace = TRUE)
coef(fit0, matrix = TRUE)
## Not run: 
par(mfrow = c(1, 1))
plotvgam(fit0, se = TRUE)  # Plot mu function (only)

## End(Not run)

# Use a trick: fit0 is used for initial values for fit1.
fit1 &lt;- vgam(BMI ~ s(age, df = c(4, 2)), etastart = predict(fit0),
             lms.bcg(zero = 1), bmi.nz, trace = TRUE)

# Difficult to get a model that converges.  Here, we prematurely
# stop iterations because it fails near the solution.
fit2 &lt;- vgam(BMI ~ s(age, df = c(4, 2)), maxit = 4,
             lms.bcg(zero = 1, ilam = 3), bmi.nz, trace = TRUE)
summary(fit1)
head(predict(fit1))
head(fitted(fit1))
head(bmi.nz)
# Person 1 is near the lower quartile of BMI amongst people his age
head(cdf(fit1))

## Not run: 
# Quantile plot
par(bty = "l", mar=c(5, 4, 4, 3) + 0.1, xpd = TRUE)
qtplot(fit1, percentiles=c(5, 50, 90, 99), main = "Quantiles",
       xlim = c(15, 90), las = 1, ylab = "BMI", lwd = 2, lcol = 4)

# Density plot
ygrid &lt;- seq(15, 43, len = 100)  # BMI ranges
par(mfrow = c(1, 1), lwd = 2)
(aa &lt;- deplot(fit1, x0 = 20, y = ygrid, xlab = "BMI", col = "black",
  main = "PDFs at Age = 20 (black), 42 (red) and 55 (blue)"))
aa &lt;- deplot(fit1, x0 = 42, y = ygrid, add=TRUE, llty=2, col="red")
aa &lt;- deplot(fit1, x0 = 55, y = ygrid, add=TRUE, llty=4, col="blue",
             Attach = TRUE)
aa@post$deplot  # Contains density function values

## End(Not run)
</code></pre>

<hr>
<h2 id='lms.bcn'> LMS Quantile Regression with a Box-Cox Transformation to
Normality </h2><span id='topic+lms.bcn'></span>

<h3>Description</h3>

<p>LMS quantile regression with the Box-Cox transformation to
normality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lms.bcn(percentiles = c(25, 50, 75), zero = c("lambda", "sigma"),
   llambda = "identitylink", lmu = "identitylink",
   lsigma = "loglink", idf.mu = 4, idf.sigma = 2, ilambda = 1,
   isigma = NULL, tol0 = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lms.bcn_+3A_percentiles">percentiles</code></td>
<td>

<p>A numerical vector containing values between 0 and 100,
which are the quantiles.
They will be returned as &lsquo;fitted values&rsquo;.
</p>



</td></tr>
<tr><td><code id="lms.bcn_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The values must be from the set {1,2,3}.
The default value usually increases the chance of successful
convergence.
Setting <code>zero = NULL</code> means they all are
functions of the covariates.
For more information see <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.bcn_+3A_llambda">llambda</code>, <code id="lms.bcn_+3A_lmu">lmu</code>, <code id="lms.bcn_+3A_lsigma">lsigma</code></td>
<td>

<p>Parameter link functions applied to the first, second and third
linear/additive predictors.
See <code><a href="#topic+Links">Links</a></code> for more choices,
and <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.bcn_+3A_idf.mu">idf.mu</code></td>
<td>

<p>Degrees of freedom for the cubic smoothing spline fit applied to
get an initial estimate of mu.
See <code><a href="#topic+vsmooth.spline">vsmooth.spline</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.bcn_+3A_idf.sigma">idf.sigma</code></td>
<td>

<p>Degrees of freedom for the cubic smoothing spline fit applied to
get an initial estimate of sigma.
See <code><a href="#topic+vsmooth.spline">vsmooth.spline</a></code>.
This argument may be assigned <code>NULL</code> to get an initial value
using some other algorithm.
</p>
</td></tr>
<tr><td><code id="lms.bcn_+3A_ilambda">ilambda</code></td>
<td>

<p>Initial value for lambda.
If necessary, it is recycled to be a vector of length <code class="reqn">n</code>
where <code class="reqn">n</code> is the number of (independent) observations.
</p>
</td></tr>
<tr><td><code id="lms.bcn_+3A_isigma">isigma</code></td>
<td>

<p>Optional initial value for sigma.
If necessary, it is recycled to be a vector of length <code class="reqn">n</code>.
The default value, <code>NULL</code>, means an initial value is
computed in the <code>@initialize</code> slot of the family function.
</p>
</td></tr>
<tr><td><code id="lms.bcn_+3A_tol0">tol0</code></td>
<td>

<p>Small positive number,
the tolerance for testing if lambda is equal to zero.
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>Given a value of the covariate, this function applies
a Box-Cox transformation to the response to best obtain
normality. The parameters chosen to do this are estimated
by maximum likelihood or penalized maximum likelihood.
</p>
<p>In more detail,
the basic idea behind this method is that, for a fixed
value of <code class="reqn">x</code>, a Box-Cox transformation of the
response <code class="reqn">Y</code>
is applied to obtain standard normality. The 3 parameters
(<code class="reqn">\lambda</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>,
which start with the letters &ldquo;L-M-S&rdquo;
respectively, hence its name) are chosen to maximize a penalized
log-likelihood (with <code><a href="#topic+vgam">vgam</a></code>). Then the
appropriate quantiles of the standard normal distribution
are back-transformed onto the original scale to get the
desired quantiles.
The three parameters may vary as a smooth function of <code class="reqn">x</code>.
</p>
<p>The Box-Cox power transformation here of the <code class="reqn">Y</code>,
given <code class="reqn">x</code>, is
</p>
<p style="text-align: center;"><code class="reqn">Z = [(Y/\mu(x))^{\lambda(x)} - 1]/(\sigma(x)\,\lambda(x))</code>
</p>

<p>for <code class="reqn">\lambda(x) \neq 0</code>.
(The singularity at <code class="reqn">\lambda(x) = 0</code>
is handled by a simple function involving a logarithm.)
Then <code class="reqn">Z</code> is assumed to have a standard normal distribution.
The parameter <code class="reqn">\sigma(x)</code> must be positive, therefore
<span class="pkg">VGAM</span> chooses
<code class="reqn">\eta(x)^T = (\lambda(x), \mu(x),
\log(\sigma(x)))</code>
by default.
The parameter <code class="reqn">\mu</code> is also positive, but while
<code class="reqn">\log(\mu)</code> is
available, it is not the default because <code class="reqn">\mu</code> is
more directly interpretable.
Given the estimated linear/additive predictors, the
<code class="reqn">100\alpha</code> percentile can be estimated
by inverting the Box-Cox power transformation at the
<code class="reqn">100\alpha</code> percentile of the standard
normal distribution.
</p>
<p>Of the three functions, it is often a good idea to allow
<code class="reqn">\mu(x)</code> to be more flexible because the functions
<code class="reqn">\lambda(x)</code> and <code class="reqn">\sigma(x)</code>
usually vary more smoothly with <code class="reqn">x</code>. This is somewhat
reflected in the default value for the argument <code>zero</code>,
viz. <code>zero = c(1, 3)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The computations are not simple, therefore convergence may
fail.  Set <code>trace = TRUE</code> to monitor convergence if it
isn't set already.  Convergence failure will occur if, e.g.,
the response is bimodal at any particular value of <code class="reqn">x</code>.
In case of convergence failure, try different starting values.
Also, the estimate may diverge quickly near the solution, in
which case try prematurely stopping the iterations by assigning
<code>maxits</code> to be the iteration number corresponding to the
highest likelihood value.
</p>
<p>One trick is to fit a simple model and use it to provide
initial values for a more complex model; see in the
examples below.
</p>


<h3>Note</h3>

<p>The response must be positive because the Box-Cox
transformation cannot handle negative values.
In theory, the
LMS-Yeo-Johnson-normal method can handle both positive
and negative values.
</p>


<p>In general, the lambda and sigma functions should be more
smoother than the mean function.
Having <code>zero = 1</code>, <code>zero = 3</code>
or <code>zero = c(1, 3)</code>
is often a good idea. See the example below.
</p>








<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Cole, T. J. and Green, P. J. (1992).
Smoothing Reference Centile Curves: The LMS Method and
Penalized Likelihood.
<em>Statistics in Medicine</em>,
<b>11</b>, 1305&ndash;1319.
</p>
<p>Green, P. J. and Silverman, B. W. (1994).
<em>Nonparametric Regression and Generalized Linear Models:
A Roughness Penalty Approach</em>,
London: Chapman &amp; Hall.
</p>
<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>,
<b>23</b>, 2295&ndash;2315.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+lms.bcg">lms.bcg</a></code>,
<code><a href="#topic+lms.yjn">lms.yjn</a></code>,
<code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>,
<code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>,
<code><a href="#topic+cdf.lmscreg">cdf.lmscreg</a></code>,
<code><a href="#topic+eCDF">eCDF</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+amlnormal">amlnormal</a></code>,
<code><a href="#topic+denorm">denorm</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  require("VGAMdata")
mysub &lt;- subset(xs.nz, sex == "M" &amp; ethnicity == "Maori" &amp; study1)
mysub &lt;- transform(mysub, BMI = weight / height^2)
BMIdata &lt;- na.omit(mysub)
BMIdata &lt;- subset(BMIdata, BMI &lt; 80 &amp; age &lt; 65,
                   select = c(age, BMI))  # Delete an outlier
summary(BMIdata)

fit &lt;- vgam(BMI ~ s(age, df = c(4, 2)), lms.bcn(zero = 1), BMIdata)

par(mfrow = c(1, 2))
plot(fit, scol = "blue", se = TRUE)  # The two centered smooths

head(predict(fit))
head(fitted(fit))
head(BMIdata)
head(cdf(fit))  # Person 46 is probably overweight, given his age
100 * colMeans(c(depvar(fit)) &lt; fitted(fit))  # Empirical proportions

# Correct for "vgam" objects but not very elegant:
fit@family@linkinv(eta = predict(fit, data.frame(age = 60)),
   extra = list(percentiles = c(10, 50)))

if (FALSE) {
# These work for "vglm" objects:
fit2 &lt;- vglm(BMI ~ bs(age, df = 4), lms.bcn(zero = 3), BMIdata)
predict(fit2, percentiles = c(10, 50),
        newdata = data.frame(age = 60), type = "response")
head(fitted(fit2, percentiles = c(10, 50)))  # Different percentiles
}

# Convergence problems? Use fit0 for initial values for fit1
fit0 &lt;- vgam(BMI ~ s(age, df = 4), lms.bcn(zero = c(1, 3)), BMIdata)
fit1 &lt;- vgam(BMI ~ s(age, df = c(4, 2)), lms.bcn(zero = 1), BMIdata,
            etastart = predict(fit0))

## End(Not run)

## Not run: # Quantile plot
par(bty = "l", mar = c(5, 4, 4, 3) + 0.1, xpd = TRUE)
qtplot(fit, percentiles = c(5, 50, 90, 99), main = "Quantiles",
       xlim = c(15, 66), las = 1, ylab = "BMI", lwd = 2, lcol = 4)

# Density plot
ygrid &lt;- seq(15, 43, len = 100)  # BMI ranges
par(mfrow = c(1, 1), lwd = 2)
(aa &lt;- deplot(fit, x0 = 20, y = ygrid, xlab = "BMI", col = "black",
  main = "PDFs at Age = 20 (black), 42 (red) and 55 (blue)"))
aa &lt;- deplot(fit, x0 = 42, y = ygrid, add = TRUE, llty = 2, col = "red")
aa &lt;- deplot(fit, x0 = 55, y = ygrid, add = TRUE, llty = 4, col = "blue",
             Attach = TRUE)
aa@post$deplot  # Contains density function values

## End(Not run)
</code></pre>

<hr>
<h2 id='lms.yjn'> LMS Quantile Regression with a Yeo-Johnson Transformation
to Normality </h2><span id='topic+lms.yjn'></span><span id='topic+lms.yjn2'></span>

<h3>Description</h3>

<p>LMS quantile regression with the Yeo-Johnson transformation
to normality.
This family function is experimental and the LMS-BCN family
function is recommended instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lms.yjn(percentiles = c(25, 50, 75), zero = c("lambda", "sigma"),
   llambda = "identitylink", lsigma = "loglink",
   idf.mu = 4, idf.sigma = 2,
   ilambda = 1, isigma = NULL, rule = c(10, 5),
   yoffset = NULL, diagW = FALSE, iters.diagW = 6)
lms.yjn2(percentiles = c(25, 50, 75), zero = c("lambda", "sigma"),
   llambda = "identitylink", lmu = "identitylink", lsigma = "loglink",
   idf.mu = 4, idf.sigma = 2, ilambda = 1.0,
   isigma = NULL, yoffset = NULL, nsimEIM = 250)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lms.yjn_+3A_percentiles">percentiles</code></td>
<td>

<p>A numerical vector containing values between 0 and 100,
which are the quantiles. They will be returned as 'fitted
values'.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_llambda">llambda</code>, <code id="lms.yjn_+3A_lmu">lmu</code>, <code id="lms.yjn_+3A_lsigma">lsigma</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_idf.mu">idf.mu</code>, <code id="lms.yjn_+3A_idf.sigma">idf.sigma</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_ilambda">ilambda</code>, <code id="lms.yjn_+3A_isigma">isigma</code></td>
<td>

<p>See <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_rule">rule</code></td>
<td>

<p>Number of abscissae used in the Gaussian integration
scheme to work out elements of the weight matrices.
The values given are the possible choices, with the first value
being the default.
The larger the value, the more accurate the approximation is
likely to be but involving more computational expense.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_yoffset">yoffset</code></td>
<td>

<p>A value to be added to the response y, for the purpose
of centering the response before fitting the model to the data.
The default value, <code>NULL</code>, means <code>-median(y)</code> is
used, so that the response actually used has median zero. The
<code>yoffset</code> is saved on the object and used during prediction.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_diagw">diagW</code></td>
<td>

<p>Logical.
This argument is offered because the expected information matrix
may not be positive-definite. Using the diagonal elements of this
matrix results in a higher chance of it being positive-definite,
however convergence will be very slow.
</p>
<p>If <code>TRUE</code>, then the first <code>iters.diagW</code> iterations
will use the diagonal of the expected information matrix.
The default is <code>FALSE</code>, meaning faster convergence.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_iters.diagw">iters.diagW</code></td>
<td>

<p>Integer. Number of iterations in which the
diagonal elements of the expected information matrix are used.
Only used if <code>diagW = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="lms.yjn_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a value of the covariate, this function applies a
Yeo-Johnson transformation to the response to best obtain
normality. The parameters chosen to do this are estimated by
maximum likelihood or penalized maximum likelihood.
The function <code>lms.yjn2()</code> estimates the expected information
matrices using simulation (and is consequently slower) while
<code>lms.yjn()</code> uses numerical integration.
Try the other if one function fails.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The computations are not simple, therefore convergence may fail.
In that case, try different starting values.
</p>
<p>The generic function <code>predict</code>, when applied to a
<code>lms.yjn</code> fit, does not add back the <code>yoffset</code> value.
</p>
<p>As described above,
this family function is experimental and the LMS-BCN family
function is recommended instead.
</p>


<h3>Note</h3>

<p>The response may contain both positive and negative values.
In contrast, the LMS-Box-Cox-normal and LMS-Box-Cox-gamma
methods only handle a positive response because the
Box-Cox transformation cannot handle negative values.
</p>
<p>Some other notes can be found at <code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yeo, I.-K. and Johnson, R. A. (2000).
A new family of power transformations to improve normality or
symmetry.
<em>Biometrika</em>,
<b>87</b>, 954&ndash;959.
</p>
<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>
<p>Yee, T. W. (2002).
An Implementation for Regression Quantile Estimation.
Pages 3&ndash;14.
In: Haerdle, W. and Ronz, B.,
<em>Proceedings in Computational Statistics COMPSTAT 2002</em>.
Heidelberg: Physica-Verlag.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+lms.bcg">lms.bcg</a></code>,
<code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>,
<code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>,
<code><a href="#topic+cdf.lmscreg">cdf.lmscreg</a></code>,
<code><a href="#topic+bmi.nz">bmi.nz</a></code>,
<code><a href="#topic+amlnormal">amlnormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- vgam(BMI ~ s(age, df = 4), lms.yjn, bmi.nz, trace = TRUE)
head(predict(fit))
head(fitted(fit))
head(bmi.nz)
# Person 1 is near the lower quartile of BMI amongst people his age
head(cdf(fit))

## Not run: 
# Quantile plot
par(bty = "l", mar = c(5, 4, 4, 3) + 0.1, xpd = TRUE)
qtplot(fit, percentiles = c(5, 50, 90, 99), main = "Quantiles",
       xlim = c(15, 90), las = 1, ylab = "BMI", lwd = 2, lcol = 4)

# Density plot
ygrid &lt;- seq(15, 43, len = 100)  # BMI ranges
par(mfrow = c(1, 1), lwd = 2)
(Z &lt;- deplot(fit, x0 = 20, y = ygrid, xlab = "BMI", col = "black",
    main = "PDFs at Age = 20 (black), 42 (red) and 55 (blue)"))
Z &lt;- deplot(fit, x0 = 42, y = ygrid, add = TRUE, llty = 2, col = "red")
Z &lt;- deplot(fit, x0 = 55, y = ygrid, add = TRUE, llty = 4, col = "blue",
            Attach = TRUE)
with(Z@post, deplot)  # Contains PDF values; == a@post$deplot

## End(Not run)
</code></pre>

<hr>
<h2 id='Log'> Logarithmic Distribution </h2><span id='topic+Log'></span><span id='topic+dlog'></span><span id='topic+plog'></span><span id='topic+qlog'></span><span id='topic+rlog'></span>

<h3>Description</h3>

<p>Density, distribution function,
quantile function,
and random generation
for the logarithmic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlog(x, shape, log = FALSE)
plog(q, shape, lower.tail = TRUE, log.p = FALSE)
qlog(p, shape)
rlog(n, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Log_+3A_x">x</code>, <code id="Log_+3A_q">q</code>, <code id="Log_+3A_p">p</code>, <code id="Log_+3A_n">n</code>, <code id="Log_+3A_lower.tail">lower.tail</code></td>
<td>

<p>Same interpretation as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Log_+3A_shape">shape</code></td>
<td>

<p>The shape parameter value <code class="reqn">c</code> described in in
<code><a href="#topic+logff">logff</a></code>.
</p>


</td></tr>
<tr><td><code id="Log_+3A_log">log</code>, <code id="Log_+3A_log.p">log.p</code></td>
<td>

<p>Logical.
If <code>log.p = TRUE</code> then all probabilities <code>p</code> are
given as <code>log(p)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details are given in <code><a href="#topic+logff">logff</a></code>.
</p>


<h3>Value</h3>

<p><code>dlog</code> gives the density,
<code>plog</code> gives the distribution function,
<code>qlog</code> gives the quantile function, and
<code>rlog</code> generates random deviates.
</p>


<h3>Note</h3>

<p>Given some response data, the <span class="pkg">VGAM</span> family function
<code><a href="#topic+logff">logff</a></code> estimates the parameter <code>shape</code>.
For <code>plog()</code>, if argument <code>q</code> contains large values
and/or <code>q</code> is long in length
then the memory requirements may be very high.
Very large values in <code>q</code> are handled by an approximation by
Owen (1965).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logff">logff</a></code>,
<code><a href="#topic+Gaitdlog">Gaitdlog</a></code>,
<code><a href="VGAMdata.html#topic+Oilog">Oilog</a></code>.
<code><a href="VGAMdata.html#topic+Otlog">Otlog</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dlog(1:20, 0.5)
rlog(20, 0.5)

## Not run:  shape &lt;- 0.8; x &lt;- 1:10
plot(x, dlog(x, shape = shape), type = "h", ylim = 0:1,
     sub = "shape=0.8", las = 1, col = "blue", ylab = "shape",
     main = "Logarithmic distribution: blue=PDF; orange=CDF")
lines(x + 0.1, plog(x, shape), col = "orange", lty = 3, type = "h") 
## End(Not run)
</code></pre>

<hr>
<h2 id='log1mexp'>
Logarithms with an Unit Offset and Exponential Term
</h2><span id='topic+log1mexp'></span><span id='topic+log1pexp'></span>

<h3>Description</h3>

<p>Computes <code>log(1 + exp(x))</code> and <code>log(1 - exp(-x))</code>
accurately.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log1mexp(x)
log1pexp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log1mexp_+3A_x">x</code></td>
<td>

<p>A vector of reals (numeric). Complex numbers not allowed since
<code><a href="base.html#topic+expm1">expm1</a></code> and <code><a href="base.html#topic+log1p">log1p</a></code> do not
handle these.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Computes <code>log(1 + exp(x))</code> and <code>log(1 - exp(-x))</code>
accurately. An adjustment is made when <code class="reqn">x</code> is away from 0
in value.
</p>


<h3>Value</h3>

<p><code>log1mexp(x)</code> gives the value of
<code class="reqn">\log(1-\exp(-x))</code>.
</p>
<p><code>log1pexp(x)</code> gives the value of
<code class="reqn">\log(1+\exp(x))</code>.
</p>


<h3>Note</h3>

<p>If <code>NA</code> or <code>NaN</code> is present in the input, the
corresponding output will be <code>NA</code>.
</p>


<h3>Author(s)</h3>

<p>This is a direct translation of the function in Martin Maechler's
(2012) paper by Xiangjie Xue
and T. W. Yee.
</p>


<h3>References</h3>

<p>Maechler, Martin (2012).
Accurately Computing log(1-exp(-|a|)).
Assessed from the <span class="pkg">Rmpfr</span> package.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+log1p">log1p</a></code>,
<code><a href="base.html#topic+expm1">expm1</a></code>,
<code><a href="base.html#topic+exp">exp</a></code>,
<code><a href="base.html#topic+log">log</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;-  c(10, 50, 100, 200, 400, 500, 800, 1000, 1e4, 1e5, 1e20, Inf, NA)
log1pexp(x)
log(1 + exp(x))  # Naive; suffers from overflow
log1mexp(x)
log(1 - exp(-x))
y &lt;- -x
log1pexp(y)
log(1 + exp(y))  # Naive; suffers from inaccuracy
</code></pre>

<hr>
<h2 id='logclink'> Complementary-log Link Function </h2><span id='topic+logclink'></span>

<h3>Description</h3>

<p>Computes the Complementary-log Transformation, Including its Inverse
and the First Two Derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logclink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
         short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logclink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="logclink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="logclink_+3A_inverse">inverse</code>, <code id="logclink_+3A_deriv">deriv</code>, <code id="logclink_+3A_short">short</code>, <code id="logclink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The complementary-log link function is suitable for parameters that
are less than unity.
Numerical values of <code>theta</code> close to 1 or out of range
result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the log of <code>theta</code>, i.e.,
<code>log(1-theta)</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>1-exp(theta)</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms, i.e., to base <em>e</em>.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is close to 1.
One way of overcoming this is to use <code>bvalue</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+logloglink">logloglink</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
logclink(seq(-0.2, 1.1, by = 0.1))  # Has NAs

## End(Not run)
logclink(seq(-0.2,1.1,by=0.1),bvalue=1-.Machine$double.eps) # Has no NAs
</code></pre>

<hr>
<h2 id='logF'> Natural Exponential Family Generalized Hyperbolic Secant
Distribution Family Function
</h2><span id='topic+logF'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of
the 2-parameter log F distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> logF(lshape1 = "loglink", lshape2 = "loglink",
      ishape1 = NULL, ishape2 = 1, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logF_+3A_lshape1">lshape1</code>, <code id="logF_+3A_lshape2">lshape2</code></td>
<td>


<p>Parameter link functions for
the shape parameters.
Called <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="logF_+3A_ishape1">ishape1</code>, <code id="logF_+3A_ishape2">ishape2</code></td>
<td>

<p>Optional initial values for the shape parameters.
If given, it must be numeric and values are recycled to the
appropriate length.
The default is to choose the value internally.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="logF_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method.
Either the value 1, 2, or ....
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density for this distribution is
</p>
<p style="text-align: center;"><code class="reqn">f(y; \alpha, \beta) = \exp(\alpha y) / [B(\alpha,\beta)
                             (1 + e^y)^{\alpha + \beta}] </code>
</p>

<p>where <code class="reqn">y</code> is real,
<code class="reqn">\alpha &gt; 0</code>,
<code class="reqn">\beta &gt; 0</code>,
<code class="reqn">B(., .)</code> is the beta function
<code><a href="base.html#topic+Special">beta</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Jones, M. C. (2008).
On a class of distributions with simple exponential tails.
<em>Statistica Sinica</em>,
<b>18</b>(3), 1101&ndash;1110.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+dlogF">dlogF</a></code>,
<code><a href="#topic+extlogF1">extlogF1</a></code>,
<code><a href="#topic+logff">logff</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
ldata &lt;- data.frame(y1 = rnorm(nn, +1, sd = exp(2)),  # Not proper data
                    x2 = rnorm(nn, -1, sd = exp(2)),
                    y2 = rnorm(nn, -1, sd = exp(2)))  # Not proper data
fit1 &lt;- vglm(y1 ~ 1 , logF, ldata, trace = TRUE)
fit2 &lt;- vglm(y2 ~ x2, logF, ldata, trace = TRUE)
coef(fit2, matrix = TRUE)
summary(fit2)
vcov(fit2)

head(fitted(fit1))
with(ldata, mean(y1))
max(abs(head(fitted(fit1)) - with(ldata, mean(y1))))
</code></pre>

<hr>
<h2 id='logff'> Logarithmic Distribution  </h2><span id='topic+logff'></span>

<h3>Description</h3>

<p>Estimating the (single) parameter of the logarithmic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logff(lshape = "logitlink", gshape = -expm1(-7 * ppoints(4)),
      zero = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logff_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function for the parameter <code class="reqn">c</code>,
which lies between 0 and 1.
See <code><a href="#topic+Links">Links</a></code> for more choices and information.
Soon <code>logfflink()</code> will hopefully be available for
event-rate data.
</p>
</td></tr>
<tr><td><code id="logff_+3A_gshape">gshape</code>, <code id="logff_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
Practical experience shows that having the initial value
for <code class="reqn">c</code> being close to the solution is quite important.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The logarithmic distribution is
a generalized power series distribution that is
based specifically on the logarithmic series
(scaled to a probability function).
Its probability function is
<code class="reqn">f(y) = a c^y / y</code>, for
<code class="reqn">y=1,2,3,\ldots</code>,
where <code class="reqn">0 &lt; c &lt; 1</code> (called <code>shape</code>),
and <code class="reqn">a = -1 / \log(1-c)</code>.
The mean is <code class="reqn">a c/(1-c)</code> (returned as the fitted values)
and variance is <code class="reqn">a c (1-ac) /(1-c)^2</code>.
When the sample mean is large, the value of <code class="reqn">c</code> tends to
be very close to 1, hence it could be argued that
<code><a href="#topic+logitlink">logitlink</a></code> is not the best choice.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The function <code><a href="base.html#topic+Log">log</a></code> computes the natural
logarithm.  In the <span class="pkg">VGAM</span> library, a link function with option
<code><a href="#topic+loglink">loglink</a></code> corresponds to this.
</p>
<p>Multiple responses are permitted.
</p>
<p>The &ldquo;logarithmic distribution&rdquo; has various meanings in
the literature. Sometimes it is also called the
<em>log-series distribution</em>.
Some others call some continuous distribution on <code class="reqn">[a, b]</code>
by the name &ldquo;logarithmic distribution&rdquo;.
</p>







<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson N. L., Kemp, A. W. and Kotz S. (2005).
<em>Univariate Discrete Distributions</em>,
3rd edition,
ch.7.
Hoboken, New Jersey: Wiley.
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011)
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Log">Log</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="VGAMdata.html#topic+oalog">oalog</a></code>,
<code><a href="VGAMdata.html#topic+oilog">oilog</a></code>,
<code><a href="VGAMdata.html#topic+otlog">otlog</a></code>,
<code><a href="base.html#topic+Log">log</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code>,
<code><a href="#topic+explogff">explogff</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000
ldata &lt;- data.frame(y = rlog(nn, shape = logitlink(0.2, inv = TRUE)))
fit &lt;- vglm(y ~ 1, logff, data = ldata, trace = TRUE, crit = "c")
coef(fit, matrix = TRUE)
Coef(fit)
## Not run: with(ldata, spikeplot(y, col = "blue", capped = TRUE))
x &lt;- seq(1, with(ldata, max(y)), by = 1)
with(ldata, lines(x + 0.1, dlog(x, Coef(fit)[1]), col = "orange",
        type = "h", lwd = 2)) 
## End(Not run)

# Example: Corbet (1943) butterfly Malaya data
corbet &lt;- data.frame(nindiv = 1:24,
                 ofreq = c(118, 74, 44, 24, 29, 22, 20, 19, 20, 15, 12,
                           14, 6, 12, 6, 9, 9, 6, 10, 10, 11, 5, 3, 3))
fit &lt;- vglm(nindiv ~ 1, logff, data = corbet, weights = ofreq)
coef(fit, matrix = TRUE)
shapehat &lt;- Coef(fit)["shape"]
pdf2 &lt;- dlog(x = with(corbet, nindiv), shape = shapehat)
print(with(corbet, cbind(nindiv, ofreq, fitted = pdf2 * sum(ofreq))),
      digits = 1)
</code></pre>

<hr>
<h2 id='logistic'> Logistic Distribution Family Function </h2><span id='topic+logistic'></span><span id='topic+logistic1'></span><span id='topic+logistic'></span>

<h3>Description</h3>

<p>Estimates the location and scale parameters of the logistic
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic1(llocation = "identitylink", scale.arg = 1, imethod = 1)
logistic(llocation = "identitylink", lscale = "loglink",
         ilocation = NULL, iscale = NULL, imethod = 1, zero = "scale")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistic_+3A_llocation">llocation</code>, <code id="logistic_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the location parameter <code class="reqn">l</code>
and scale parameter <code class="reqn">s</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices, and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="logistic_+3A_scale.arg">scale.arg</code></td>
<td>

<p>Known positive scale parameter (called <code class="reqn">s</code> below).
</p>
</td></tr>
<tr><td><code id="logistic_+3A_ilocation">ilocation</code>, <code id="logistic_+3A_iscale">iscale</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="logistic_+3A_imethod">imethod</code>, <code id="logistic_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two-parameter logistic distribution has a density that can
be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y;l,s) = \frac{\exp[-(y-l)/s]}{
      s\left( 1 + \exp[-(y-l)/s] \right)^2}</code>
</p>

<p>where <code class="reqn">s &gt; 0</code> is the scale parameter, and <code class="reqn">l</code> is the location
parameter. The response <code class="reqn">-\infty&lt;y&lt;\infty</code>.  The mean
of <code class="reqn">Y</code> (which is the fitted value) is <code class="reqn">l</code> and its variance is
<code class="reqn">\pi^2 s^2 / 3</code>.
</p>
<p>A logistic distribution with <code>scale = 0.65</code>
(see <code><a href="stats.html#topic+Logistic">dlogis</a></code>)
resembles
<code><a href="stats.html#topic+dt">dt</a></code>
with <code>df = 7</code>;
see <code><a href="#topic+logistic1">logistic1</a></code> and <code><a href="#topic+studentt">studentt</a></code>.
</p>
<p><code>logistic1</code> estimates the location parameter only while
<code>logistic</code> estimates both parameters.
By default,
<code class="reqn">\eta_1 = l</code>
and <code class="reqn">\eta_2 = \log(s)</code>
for <code>logistic</code>.
</p>
<p><code>logistic</code> can handle multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Fisher scoring is used, and the Fisher information matrix is
diagonal.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1994).
<em>Continuous Univariate Distributions</em>,
2nd edition, Volume 1, New York: Wiley.  Chapter 15.
</p>
<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>
<p>Castillo, E., Hadi, A. S., Balakrishnan, N.
and Sarabia, J. S. (2005).
<em>Extreme Value and Related Models with Applications in
Engineering and Science</em>,
Hoboken, NJ, USA: Wiley-Interscience, p.130.
</p>
<p>deCani, J. S. and Stine, R. A. (1986).
A Note on Deriving the Information Matrix for a
Logistic Distribution,
<em>The American Statistician</em>,
<b>40</b>, 220&ndash;222.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Logistic">rlogis</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+gensh">gensh</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+bilogistic">bilogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Location unknown, scale known
ldata &lt;- data.frame(x2 = runif(nn &lt;- 500))
ldata &lt;- transform(ldata, y1 = rlogis(nn, loc = 1+5*x2, sc = exp(2)))
fit1 &lt;- vglm(y1 ~ x2, logistic1(scale = exp(2)), ldata, trace = TRUE)
coef(fit1, matrix = TRUE)

# Both location and scale unknown
ldata &lt;- transform(ldata, y2 = rlogis(nn, loc = 1 + 5*x2, exp(x2)))
fit2 &lt;- vglm(cbind(y1, y2) ~ x2, logistic, data = ldata, trace = TRUE)
coef(fit2, matrix = TRUE)
vcov(fit2)
summary(fit2)
</code></pre>

<hr>
<h2 id='logitlink'> Logit Link Function </h2><span id='topic+logitlink'></span><span id='topic+extlogitlink'></span>

<h3>Description</h3>

<p>Computes the logit transformation,
including its inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logitlink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
    short = TRUE, tag = FALSE)
extlogitlink(theta, min = 0, max = 1, bminvalue = NULL,
    bmaxvalue = NULL, inverse = FALSE, deriv = 0,
    short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logitlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="logitlink_+3A_bvalue">bvalue</code>, <code id="logitlink_+3A_bminvalue">bminvalue</code>, <code id="logitlink_+3A_bmaxvalue">bmaxvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
These are boundary values.
For <code>extlogitlink</code>, values of <code>theta</code> less than or
equal to <code class="reqn">A</code> or greater than or equal to <code class="reqn">B</code> can be
replaced by <code>bminvalue</code> and <code>bmaxvalue</code>.
</p>
</td></tr>





<tr><td><code id="logitlink_+3A_min">min</code>, <code id="logitlink_+3A_max">max</code></td>
<td>

<p>For <code>extlogitlink</code>,
<code>min</code> gives <code class="reqn">A</code>,
<code>max</code> gives <code class="reqn">B</code>, and for out of range values,
<code>bminvalue</code> and <code>bmaxvalue</code>.
</p>
</td></tr>
<tr><td><code id="logitlink_+3A_inverse">inverse</code>, <code id="logitlink_+3A_deriv">deriv</code>, <code id="logitlink_+3A_short">short</code>, <code id="logitlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The logit link function is very commonly used for parameters
that lie in the unit interval.
It is the inverse CDF of the logistic distribution.
Numerical values of <code>theta</code> close to 0 or 1 or out of range
result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>
<p>The <em>extended</em> logit link function <code>extlogitlink</code>
should be used more generally for parameters that lie in the
interval <code class="reqn">(A,B)</code>, say.
The formula is
</p>
<p style="text-align: center;"><code class="reqn">\log((\theta-A)/(B-\theta))</code>
</p>

<p>and the default values for <code class="reqn">A</code> and <code class="reqn">B</code> correspond to
the ordinary logit function.
Numerical values of <code>theta</code> close to <code class="reqn">A</code>
or <code class="reqn">B</code> or out of range result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
However these can be replaced by values <code class="reqn">bminvalue</code> and
<code class="reqn">bmaxvalue</code> first before computing the link function.
</p>


<h3>Value</h3>

<p>For <code>logitlink</code> with <code>deriv = 0</code>, the logit
of <code>theta</code>, i.e., <code>log(theta/(1-theta))</code> when
<code>inverse = FALSE</code>, and if <code>inverse = TRUE</code> then
<code>exp(theta)/(1+exp(theta))</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of
<code>theta</code> if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms, i.e., to base
<em>e</em>.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is
close to 1 or 0 (for <code>logitlink</code>), or close to <code class="reqn">A</code>
or <code class="reqn">B</code> for <code>extlogitlink</code>.
One way of overcoming this is to use, e.g., <code>bvalue</code>.
</p>
<p>In terms of the threshold approach with cumulative probabilities
for an ordinal response this link function corresponds to the
univariate logistic distribution (see <code><a href="#topic+logistic">logistic</a></code>).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>,
2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+alogitlink">alogitlink</a></code>,
<code><a href="#topic+asinlink">asinlink</a></code>,
<code><a href="#topic+logitoffsetlink">logitoffsetlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="#topic+logistic1">logistic1</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="stats.html#topic+Logistic">Logistic</a></code>,
<code><a href="#topic+multilogitlink">multilogitlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, by = 0.01)
logitlink(p)
max(abs(logitlink(logitlink(p), inverse = TRUE) - p))  # 0?

p &lt;- c(seq(-0.02, 0.02, by = 0.01), seq(0.97, 1.02, by = 0.01))
logitlink(p)  # Has NAs
logitlink(p, bvalue = .Machine$double.eps)  # Has no NAs

p &lt;- seq(0.9, 2.2, by = 0.1)
extlogitlink(p, min = 1, max = 2,
             bminvalue = 1 + .Machine$double.eps,
             bmaxvalue = 2 - .Machine$double.eps)  # Has no NAs

## Not run:  par(mfrow = c(2,2), lwd = (mylwd &lt;- 2))
y &lt;- seq(-4, 4, length = 100)
p &lt;- seq(0.01, 0.99, by = 0.01)
for (d in 0:1) {
  myinv &lt;- (d &gt; 0)
  matplot(p, cbind( logitlink(p, deriv = d, inv = myinv),
                   probitlink(p, deriv = d, inv = myinv)), las = 1,
          type = "n", col = "purple", ylab = "transformation",
          main = if (d ==  0) "Some probability link functions"
          else "1 / first derivative")
  lines(p,   logitlink(p, deriv = d, inverse = myinv), col = "limegreen")
  lines(p,  probitlink(p, deriv = d, inverse = myinv), col = "purple")
  lines(p, clogloglink(p, deriv = d, inverse = myinv), col = "chocolate")
  lines(p, cauchitlink(p, deriv = d, inverse = myinv), col = "tan")
  if (d ==  0) {
    abline(v = 0.5, h = 0, lty = "dashed")
    legend(0, 4.5, c("logitlink", "probitlink",
           "clogloglink", "cauchitlink"), col = c("limegreen", "purple",
           "chocolate", "tan"), lwd = mylwd)
  } else
    abline(v = 0.5, lty = "dashed")
}

for (d in 0) {
  matplot(y, cbind(logitlink(y, deriv = d, inverse = TRUE),
                   probitlink(y, deriv = d, inverse = TRUE)), las = 1,
          type = "n", col = "purple", xlab = "transformation", ylab = "p",
          main = if (d ==  0) "Some inverse probability link functions"
          else "First derivative")
  lines(y,   logitlink(y, deriv = d, inv = TRUE), col = "limegreen")
  lines(y,  probitlink(y, deriv = d, inv = TRUE), col = "purple")
  lines(y, clogloglink(y, deriv = d, inv = TRUE), col = "chocolate")
  lines(y, cauchitlink(y, deriv = d, inv = TRUE), col = "tan")
  if (d ==  0) {
    abline(h = 0.5, v = 0, lty = "dashed")
    legend(-4, 1, c("logitlink", "probitlink", "clogloglink",
           "cauchitlink"), col = c("limegreen", "purple",
           "chocolate", "tan"), lwd = mylwd)
  }
}

p &lt;- seq(0.21, 0.59, by = 0.01)
plot(p, extlogitlink(p, min = 0.2, max = 0.6), xlim = c(0, 1),
     type = "l", col = "black", ylab = "transformation",
     las = 1, main = "extlogitlink(p, min = 0.2, max = 0.6)")
par(lwd = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='logitoffsetlink'> Logit-with-an-Offset Link Function </h2><span id='topic+logitoffsetlink'></span>

<h3>Description</h3>

<p>Computes the logitoffsetlink transformation, including its
inverse and the first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logitoffsetlink(theta, offset = 0, inverse = FALSE, deriv = 0,
                short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logitoffsetlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="logitoffsetlink_+3A_offset">offset</code></td>
<td>

<p>The offset value(s), which must be non-negative.
It is called <code class="reqn">K</code> below.
</p>
</td></tr>
<tr><td><code id="logitoffsetlink_+3A_inverse">inverse</code>, <code id="logitoffsetlink_+3A_deriv">deriv</code>, <code id="logitoffsetlink_+3A_short">short</code>, <code id="logitoffsetlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This  link function allows for some asymmetry compared to the
ordinary <code><a href="#topic+logitlink">logitlink</a></code> link.
The formula is
</p>
<p style="text-align: center;"><code class="reqn">\log(\theta/(1-\theta) - K)</code>
</p>

<p>and the default value for the offset <code class="reqn">K</code> is corresponds to the
ordinary <code><a href="#topic+logitlink">logitlink</a></code> link.
When <code>inverse = TRUE</code> will mean that the value will
lie in the interval <code class="reqn">(K / (1+K), 1)</code>.
</p>


<h3>Value</h3>

<p>For <code>logitoffsetlink</code> with <code>deriv = 0</code>, the
logitoffsetlink of <code>theta</code>, i.e.,
<code>log(theta/(1-theta) - K)</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>(K + exp(theta))/(1 + exp(theta) + K)</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns <em>d</em>
<code>eta</code> / <em>d</em> <code>theta</code> as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms, i.e., to base
<em>e</em>.
</p>


<h3>Note</h3>

<p>This function is numerical less stability than
<code><a href="#topic+logitlink">logitlink</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Komori, O. and Eguchi, S. et al., 2016.
An asymmetric logistic model for ecological data.
<em>Methods in Ecology and Evolution</em>,
<b>7</b>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.05, 0.99, by = 0.01); myoff &lt;- 0.05
logitoffsetlink(p, myoff)
max(abs(logitoffsetlink(logitoffsetlink(p, myoff),
        myoff, inverse = TRUE) - p))  # Should be 0
</code></pre>

<hr>
<h2 id='loglaplace'> Log-Laplace and Logit-Laplace Distribution Family
Functions </h2><span id='topic+loglaplace1'></span><span id='topic+logitlaplace1'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of
the 1-parameter log-Laplace and
the 1-parameter logit-Laplace
distributions.
These may be used for quantile regression for counts and
proportions respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglaplace1(tau = NULL, llocation = "loglink",
    ilocation = NULL, kappa = sqrt(tau/(1 - tau)), Scale.arg = 1,
    ishrinkage = 0.95, parallel.locat = FALSE, digt = 4,
    idf.mu = 3, rep0 = 0.5, minquantile = 0, maxquantile = Inf,
    imethod = 1, zero = NULL)
logitlaplace1(tau = NULL, llocation = "logitlink",
    ilocation = NULL, kappa = sqrt(tau/(1 - tau)),
    Scale.arg = 1, ishrinkage = 0.95, parallel.locat = FALSE,
    digt = 4, idf.mu = 3, rep01 = 0.5, imethod = 1, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglaplace_+3A_tau">tau</code>, <code id="loglaplace_+3A_kappa">kappa</code></td>
<td>

<p>See <code><a href="#topic+alaplace1">alaplace1</a></code>.
</p>
</td></tr>
<tr><td><code id="loglaplace_+3A_llocation">llocation</code></td>
<td>
<p> Character.
Parameter link functions for
location parameter <code class="reqn">\xi</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
However, this argument should be left unchanged with
count data because it restricts the quantiles to be positive.
With proportions data  <code>llocation</code> can be assigned a link
such as
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
etc.
</p>
</td></tr>
<tr><td><code id="loglaplace_+3A_ilocation">ilocation</code></td>
<td>

<p>Optional initial values.
If given, it must be numeric and values are recycled to the
appropriate length.
The default is to choose the value internally.
</p>
</td></tr>
<tr><td><code id="loglaplace_+3A_parallel.locat">parallel.locat</code></td>
<td>
<p> Logical.
Should the quantiles be parallel on the transformed scale
(argument <code>llocation</code>)?
Assigning this argument to <code>TRUE</code> circumvents the
seriously embarrassing quantile crossing problem.
</p>
</td></tr>





<tr><td><code id="loglaplace_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method.
Either the value 1, 2, or ....
</p>
</td></tr>
<tr><td><code id="loglaplace_+3A_idf.mu">idf.mu</code>, <code id="loglaplace_+3A_ishrinkage">ishrinkage</code>, <code id="loglaplace_+3A_scale.arg">Scale.arg</code>, <code id="loglaplace_+3A_digt">digt</code>, <code id="loglaplace_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+alaplace1">alaplace1</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="loglaplace_+3A_rep0">rep0</code>, <code id="loglaplace_+3A_rep01">rep01</code></td>
<td>

<p>Numeric, positive.
Replacement values for 0s and 1s respectively.
For count data, values of the response whose value is 0 are
replaced by <code>rep0</code>; it avoids computing <code>log(0)</code>.
For proportions data values of the response whose value is 0
or 1 are replaced by
<code>min(rangey01[1]/2, rep01/w[y&lt; = 0])</code> and
<code>max((1 + rangey01[2])/2, 1-rep01/w[y &gt;= 1])</code>
respectively;
e.g.,
it avoids computing <code>logitlink(0)</code> or <code>logitlink(1)</code>.
Here, <code>rangey01</code> is the 2-vector
<code>range(y[(y &gt; 0) &amp; (y &lt; 1)])</code> of the response.
</p>
</td></tr>
<tr><td><code id="loglaplace_+3A_minquantile">minquantile</code>, <code id="loglaplace_+3A_maxquantile">maxquantile</code></td>
<td>

<p>Numeric.
The minimum and maximum values possible in the quantiles.
These argument are effectively ignored by default since
<code><a href="#topic+loglink">loglink</a></code> keeps all quantiles positive.
However, if
<code>llocation = logofflink(offset = 1)</code>
then it is possible that the fitted quantiles have value 0
because <code>minquantile = 0</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These <span class="pkg">VGAM</span> family functions implement translations of
the asymmetric Laplace distribution (ALD).
The resulting variants may be suitable for quantile regression
for count data or sample proportions.
For example,
a log link applied to count data is assumed to follow an ALD.
Another example is a logit link applied to proportions data so
as to follow an ALD.
A positive random variable <code class="reqn">Y</code> is said to have a log-Laplace
distribution if <code class="reqn">Y = e^W</code> where <code class="reqn">W</code> has
an ALD.  There are many variants of ALDs and the one used here
is described in <code><a href="#topic+alaplace1">alaplace1</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>In the <code>extra</code> slot of the fitted object are some list
components which are useful.
For example, the sample proportion of
values which are less than the fitted quantile curves, which
is <code>sum(wprior[y &lt;= location]) / sum(wprior)</code> internally.
Here, <code>wprior</code> are the prior weights (called <code>ssize</code>
below), <code>y</code> is the response and <code>location</code> is a
fitted quantile curve.  This definition comes about naturally
from the transformed ALD data.
</p>


<h3>Warning</h3>

<p>The <span class="pkg">VGAM</span> family function <code><a href="#topic+logitlaplace1">logitlaplace1</a></code>
will not handle a vector of just 0s and 1s as the response; it
will only work satisfactorily if the number of trials is large.
</p>
<p>See <code><a href="#topic+alaplace1">alaplace1</a></code> for other warnings.
Care is needed with <code>tau</code> values which are too small,
e.g., for count data the sample proportion of zeros must be less
than all values in <code>tau</code>.  Similarly, this also holds with
<code><a href="#topic+logitlaplace1">logitlaplace1</a></code>, which also requires all <code>tau</code>
values to be less than the sample proportion of ones.
</p>


<h3>Note</h3>

<p>The form of input for <code><a href="#topic+logitlaplace1">logitlaplace1</a></code> as response
is a vector of proportions (values in <code class="reqn">[0,1]</code>) and the
number of trials is entered into the <code>weights</code> argument of
<code><a href="#topic+vglm">vglm</a></code>/<code><a href="#topic+vgam">vgam</a></code>.
See Example 2 below.
See <code><a href="#topic+alaplace1">alaplace1</a></code> for other notes in general.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Kotz, S., Kozubowski, T. J. and Podgorski, K. (2001).
<em>The Laplace distribution and generalizations:
a revisit with applications to communications,
economics, engineering, and finance</em>,
Boston: Birkhauser.
</p>
<p>Kozubowski, T. J. and Podgorski, K. (2003).
Log-Laplace distributions.
<em>International Mathematical Journal</em>,
<b>3</b>, 467&ndash;495.
</p>
<p>Yee, T. W. (2020).
Quantile regression for counts and proportions.
In preparation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+dloglap">dloglap</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: quantile regression of counts with regression splines
set.seed(123); my.k &lt;- exp(0)
adata &lt;- data.frame(x2 = sort(runif(n &lt;- 500)))
mymu &lt;- function(x) exp( 1 + 3*sin(2*x) / (x+0.5)^2)
adata &lt;- transform(adata, y = rnbinom(n, mu = mymu(x2), my.k))
mytau &lt;- c(0.1, 0.25, 0.5, 0.75, 0.9); mydof = 3
# halfstepping is usual:
fitp &lt;- vglm(y ~ sm.bs(x2, df = mydof), data = adata, trace = TRUE,
            loglaplace1(tau = mytau, parallel.locat = TRUE))

## Not run:  par(las = 1)  # Plot on a log1p() scale
mylwd &lt;- 1.5

plot(jitter(log1p(y), factor = 1.5) ~ x2, adata, col = "red",
     pch = "o", cex = 0.75,
     main = "Example 1; green=truth, blue=estimated")
with(adata, matlines(x2, log1p(fitted(fitp)), col = "blue",
                     lty = 1, lwd = mylwd))
finexgrid &lt;- seq(0, 1, len = 201)
for (ii in 1:length(mytau))
  lines(finexgrid, col = "green", lwd = mylwd,
        log1p(qnbinom(mytau[ii], mu = mymu(finexgrid), my.k)))

## End(Not run)
fitp@extra  # Contains useful information


# Example 2: sample proportions
set.seed(123); nnn &lt;- 1000; ssize &lt;- 100  # ssize = 1 wont work!
adata &lt;- data.frame(x2 = sort(runif(nnn)))
mymu &lt;- function(x) logitlink( 1.0 + 4*x, inv = TRUE)
adata &lt;- transform(adata, ssize = ssize,
                   y2 = rbinom(nnn, ssize, prob = mymu(x2)) / ssize)

mytau &lt;- c(0.25, 0.50, 0.75)
fit1 &lt;- vglm(y2 ~ sm.bs(x2, df = 3),
        logitlaplace1(tau = mytau, lloc = "clogloglink", paral = TRUE),
        data = adata, weights = ssize, trace = TRUE)

## Not run: 
# Check the solution.  Note: this is like comparing apples with oranges.
plotvgam(fit1, se = TRUE, scol = "red", lcol = "blue",
         main = "Truth = 'green'")
# Centered approximately !
linkFunctionChar &lt;- as.character(fit1@misc$link)
adata &lt;- transform(adata, trueFunction =
           theta2eta(theta = mymu(x2), link = linkFunctionChar))
with(adata, lines(x2, trueFunction - mean(trueFunction), col = "green"))

# Plot the data + fitted quantiles (on the original scale)
myylim &lt;- with(adata, range(y2))
plot(y2 ~ x2, adata, col = "blue", ylim = myylim, las = 1,
     pch = ".", cex = 2.5)
with(adata, matplot(x2, fitted(fit1), add = TRUE, lwd = 3, type = "l"))
truecol &lt;- rep(1:3, len = fit1@misc$M)  # Add the 'truth'
smallxgrid &lt;- seq(0, 1, len = 501)
for (ii in 1:length(mytau))
  lines(smallxgrid, col = truecol[ii], lwd = 2,
        qbinom(mytau[ii], pr = mymu(smallxgrid), si = ssize) / ssize)

# Plot on the eta (== logitlink()/probitlink()/...) scale
  with(adata, matplot(x2, predict(fit1), lwd = 3, type = "l"))
# Add the 'truth'
for (ii in 1:length(mytau)) {
  true.quant &lt;- qbinom(mytau[ii], prob = mymu(smallxgrid),
                       size = ssize) / ssize
  lines(smallxgrid, theta2eta(true.quant, link = linkFunctionChar),
        col = truecol[ii], lwd = 2)
} 
## End(Not run)
</code></pre>

<hr>
<h2 id='loglapUC'> The Log-Laplace Distribution </h2><span id='topic+dloglap'></span><span id='topic+ploglap'></span><span id='topic+qloglap'></span><span id='topic+rloglap'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the 3-parameter log-Laplace distribution
with location parameter <code>location.ald</code>, scale parameter
<code>scale.ald</code> (on the log scale), and asymmetry parameter
<code>kappa</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dloglap(x, location.ald = 0, scale.ald = 1,
        tau = 0.5, kappa = sqrt(tau/(1-tau)), log = FALSE)
ploglap(q, location.ald = 0, scale.ald = 1, tau = 0.5,
        kappa = sqrt(tau/(1-tau)), lower.tail = TRUE, log.p = FALSE)
qloglap(p, location.ald = 0, scale.ald = 1, tau = 0.5,
        kappa = sqrt(tau/(1-tau)), lower.tail = TRUE, log.p = FALSE)
rloglap(n, location.ald = 0, scale.ald = 1,
        tau = 0.5, kappa = sqrt(tau/(1-tau)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglapUC_+3A_x">x</code>, <code id="loglapUC_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_n">n</code></td>
<td>

<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.
</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_location.ald">location.ald</code>, <code id="loglapUC_+3A_scale.ald">scale.ald</code></td>
<td>

<p>the location parameter <code class="reqn">\xi</code> and
the (positive) scale parameter <code class="reqn">\sigma</code>,
on the log scale.
</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_tau">tau</code></td>
<td>

<p>the quantile parameter <code class="reqn">\tau</code>.
Must consist of values in <code class="reqn">(0,1)</code>.
This argument is used to specify <code>kappa</code> and is ignored
if <code>kappa</code> is assigned.
</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_kappa">kappa</code></td>
<td>

<p>the asymmetry parameter <code class="reqn">\kappa</code>.
Must consist of positive values.
</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_log">log</code></td>
<td>

<p>if <code>TRUE</code>, probabilities <code>p</code> are given as <code>log(p)</code>.
</p>
</td></tr>
<tr><td><code id="loglapUC_+3A_lower.tail">lower.tail</code>, <code id="loglapUC_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A positive random variable <code class="reqn">Y</code> is said to have a log-Laplace
distribution if <code class="reqn">\log(Y)</code> has an asymmetric Laplace
distribution (ALD). There are many variants of ALDs and the
one used here is described in <code><a href="#topic+alaplace3">alaplace3</a></code>.
</p>


<h3>Value</h3>

<p><code>dloglap</code> gives the density,
<code>ploglap</code> gives the distribution function,
<code>qloglap</code> gives the quantile function, and
<code>rloglap</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kozubowski, T. J. and Podgorski, K. (2003).
Log-Laplace distributions.
<em>International Mathematical Journal</em>,
<b>3</b>, 467&ndash;495.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dalap">dalap</a></code>,
<code><a href="#topic+alaplace3">alaplace3</a></code>,
<code><a href="#topic+loglaplace1">loglaplace1</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>loc &lt;- 0; sigma &lt;- exp(0.5); kappa &lt;- 1
x &lt;- seq(-0.2, 5, by = 0.01)
## Not run: plot(x, dloglap(x, loc, sigma, kappa = kappa),
     type = "l", col = "blue", ylim = c(0,1),
     main = "Blue is density, red is the CDF",
     sub = "Purple are 5,10,...,95 percentiles", las = 1, ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(qloglap(seq(0.05,0.95,by = 0.05), loc, sigma, kappa = kappa),
  dloglap(qloglap(seq(0.05,0.95,by = 0.05), loc, sigma, kappa = kappa),
              loc, sigma, kappa = kappa),
      col = "purple", lty = 3, type = "h")
lines(x, ploglap(x, loc, sigma, kappa = kappa), type = "l", col = 2)
abline(h = 0, lty = 2)

## End(Not run)
ploglap(qloglap(seq(0.05,0.95,by = 0.05), loc, sigma, kappa = kappa),
        loc, sigma, kappa = kappa)
</code></pre>

<hr>
<h2 id='logLik.vlm'>Extract Log-likelihood for VGLMs/VGAMs/etc. </h2><span id='topic+logLik.vlm'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood value or the
element-by-element contributions of the log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vlm'
logLik(object, summation = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.vlm_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>
</td></tr>
<tr><td><code id="logLik.vlm_+3A_summation">summation</code></td>
<td>

<p>Logical, apply <code><a href="base.html#topic+sum">sum</a></code>?
If <code>FALSE</code> then a <code class="reqn">n</code>-vector or
<code class="reqn">n</code>-row matrix (with the number of responses as
the number of columns) is returned.
Each element is the contribution to the log-likelihood.
</p>
</td></tr>
<tr><td><code id="logLik.vlm_+3A_...">...</code></td>
<td>

<p>Currently unused.
In the future:
other possible arguments fed into
<code>logLik</code> in order to compute the log-likelihood.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, this function
returns the log-likelihood of the object.
Thus this code relies on the log-likelihood being defined,
and computed, for the object.
</p>


<h3>Value</h3>

<p>Returns the log-likelihood of the object.
If <code>summation = FALSE</code> then a <code class="reqn">n</code>-vector or
<code class="reqn">n</code>-row matrix (with the number of responses as
the number of columns) is returned.
Each element is the contribution to the log-likelihood.
The prior weights are assimulated within the answer.
</p>


<h3>Warning </h3>

<p>Not all <span class="pkg">VGAM</span> family functions have had the
<code>summation</code> checked.
</p>


<h3>Note</h3>

<p>Not all <span class="pkg">VGAM</span> family functions currently have the
<code>summation</code> argument implemented.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>See Also</h3>

<p>VGLMs are described in <code><a href="#topic+vglm-class">vglm-class</a></code>;
VGAMs are described in <code><a href="#topic+vgam-class">vgam-class</a></code>;
RR-VGLMs are described in <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>;
<code><a href="stats.html#topic+AIC">AIC</a></code>;
<code><a href="#topic+anova.vglm">anova.vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(x2 = runif(nn &lt;- 50))
zdata &lt;- transform(zdata, Ps01    = logitlink(-0.5       , inverse = TRUE),
                          Ps02    = logitlink( 0.5       , inverse = TRUE),
                          lambda1 =  loglink(-0.5 + 2*x2, inverse = TRUE),
                          lambda2 =  loglink( 0.5 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata, y1 = rzipois(nn, lambda = lambda1, pstr0 = Ps01),
                          y2 = rzipois(nn, lambda = lambda2, pstr0 = Ps02))

with(zdata, table(y1))  # Eyeball the data
with(zdata, table(y2))
fit2 &lt;- vglm(cbind(y1, y2) ~ x2, zipoisson(zero = NULL), data = zdata)

logLik(fit2)  # Summed over the two responses
sum(logLik(fit2, sum = FALSE))  # For checking purposes
(ll.matrix &lt;- logLik(fit2, sum = FALSE))  # nn x 2 matrix
colSums(ll.matrix)  # log-likelihood for each response
</code></pre>

<hr>
<h2 id='loglinb2'> Loglinear Model for Two Binary Responses </h2><span id='topic+loglinb2'></span>

<h3>Description</h3>

<p>Fits a loglinear model to two binary responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglinb2(exchangeable = FALSE, zero = "u12")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglinb2_+3A_exchangeable">exchangeable</code></td>
<td>
<p> Logical.
If <code>TRUE</code>, the two marginal probabilities are constrained
to be equal. Should be set <code>TRUE</code> for ears, eyes,
etc. data.
</p>
</td></tr>
<tr><td><code id="loglinb2_+3A_zero">zero</code></td>
<td>
<p> Which linear/additive predictors are modelled as
intercept-only?
A <code>NULL</code> means none of them.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is
</p>
<p style="text-align: center;"><code class="reqn">P(Y_1=y_1,Y_2=y_2) = \exp(u_0+
    u_1 y_1+u_2 y_2+u_{12} y_1 y_2)</code>
</p>

<p>where <code class="reqn">y_1</code> and <code class="reqn">y_2</code> are 0 or 1, and
the parameters are <code class="reqn">u_1</code>, <code class="reqn">u_2</code>,
<code class="reqn">u_{12}</code>.
The normalizing parameter <code class="reqn">u_0</code> can be expressed as a
function of the other parameters, viz.,
</p>
<p style="text-align: center;"><code class="reqn">u_0 = -\log[1 + \exp(u_1) + \exp(u_2) +
      \exp(u_1 + u_2 + u_{12})].</code>
</p>

<p>The linear/additive predictors are
<code class="reqn">(\eta_1,\eta_2,\eta_3)^T =
     (u_1,u_2,u_{12})^T</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>When fitted, the <code>fitted.values</code> slot of the object
contains the four joint probabilities, labelled as
<code class="reqn">(Y_1,Y_2)</code> = (0,0), (0,1), (1,0), (1,1),
respectively.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix of ones and zeros only.
This is more restrictive than <code><a href="#topic+binom2.or">binom2.or</a></code>,
which can handle more types of input formats.
Note that each of the 4 combinations of the multivariate response
need to appear in the data set.
After estimation, the response attached to the object is also a
two-column matrix; possibly in the future it might change into a
four-column matrix.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (2001).
Discussion to: &ldquo;Smoothing spline ANOVA for multivariate
Bernoulli observations, with application to ophthalmology data
(with discussion)&rdquo;
by Gao, F., Wahba, G., Klein, R., Klein, B.
<em>Journal of the American Statistical Association</em>,
<b>96</b>, 127&ndash;160.
</p>
<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+binom2.or">binom2.or</a></code>,
<code><a href="#topic+binom2.rho">binom2.rho</a></code>,
<code><a href="#topic+loglinb3">loglinb3</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>coalminers &lt;- transform(coalminers, Age = (age - 42) / 5)
# Get the n x 4 matrix of counts
fit0 &lt;- vglm(cbind(nBnW,nBW,BnW,BW) ~ Age, binom2.or, coalminers)
counts &lt;- round(c(weights(fit0, type = "prior")) * depvar(fit0))
# Create a n x 2 matrix response for loglinb2()
# bwmat &lt;- matrix(c(0,0, 0,1, 1,0, 1,1), 4, 2, byrow = TRUE)
bwmat &lt;- cbind(bln = c(0,0,1,1), wheeze = c(0,1,0,1))
matof1 &lt;- matrix(1, nrow(counts), 1)
newminers &lt;-
  data.frame(bln    = kronecker(matof1, bwmat[, 1]),
             wheeze = kronecker(matof1, bwmat[, 2]),
             wt     = c(t(counts)),
             Age    = with(coalminers, rep(age, rep(4, length(age)))))
newminers &lt;- newminers[with(newminers, wt) &gt; 0,]

fit &lt;- vglm(cbind(bln,wheeze) ~ Age, loglinb2(zero = NULL),
            weight = wt, data = newminers)
coef(fit, matrix = TRUE)  # Same! (at least for the log odds-ratio)
summary(fit)

# Try reconcile this with McCullagh and Nelder (1989), p.234
(0.166-0.131) / 0.027458   # 1.275 is approximately 1.25
</code></pre>

<hr>
<h2 id='loglinb3'> Loglinear Model for Three Binary Responses </h2><span id='topic+loglinb3'></span>

<h3>Description</h3>

<p>Fits a loglinear model to three binary responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglinb3(exchangeable = FALSE, zero = c("u12", "u13", "u23"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglinb3_+3A_exchangeable">exchangeable</code></td>
<td>
<p> Logical.
If <code>TRUE</code>, the three marginal probabilities are
constrained to be equal.
</p>
</td></tr>
<tr><td><code id="loglinb3_+3A_zero">zero</code></td>
<td>
<p> Which linear/additive predictors are modelled as
intercept-only?
A <code>NULL</code> means none.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for further
information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model is
<code class="reqn">P(Y_1=y_1,Y_2=y_2,Y_3=y_3) =</code>
</p>
<p style="text-align: center;"><code class="reqn">\exp(u_0+u_1 y_1+u_2 y_2+u_3 y_3+u_{12} y_1 y_2+
      u_{13} y_1 y_3+u_{23} y_2 y_3)</code>
</p>

<p>where <code class="reqn">y_1</code>, <code class="reqn">y_2</code> and <code class="reqn">y_3</code> are 0
or 1, and the parameters are <code class="reqn">u_1</code>, <code class="reqn">u_2</code>,
<code class="reqn">u_3</code>, <code class="reqn">u_{12}</code>, <code class="reqn">u_{13}</code>,
<code class="reqn">u_{23}</code>.
The normalizing parameter <code class="reqn">u_0</code> can be expressed as a
function of the other parameters.
Note that a third-order association parameter,
<code class="reqn">u_{123}</code> for the product <code class="reqn">y_1 y_2 y_3</code>,
is assumed to be zero for this family function.
</p>
<p>The linear/additive predictors are
<code class="reqn">(\eta_1,\eta_2,\ldots,\eta_6)^T =
(u_1,u_2,u_3,u_{12},u_{13},u_{23})^T</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>When fitted, the <code>fitted.values</code> slot of the object
contains the eight joint probabilities, labelled as
<code class="reqn">(Y_1,Y_2,Y_3)</code> = (0,0,0), (0,0,1), (0,1,0),
(0,1,1), (1,0,0), (1,0,1), (1,1,0), (1,1,1), respectively.
</p>


<h3>Note</h3>

<p>The response must be a 3-column matrix of ones and zeros only.
Note that each of the 8 combinations of the multivariate
response need to appear in the data set, therefore data sets
will need to be large in order for this family function to work.
After estimation, the response attached to the object is also
a 3-column matrix; possibly in the future it might change into
a 8-column matrix.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (2001).
Discussion to: &ldquo;Smoothing spline ANOVA for multivariate
Bernoulli observations, with application to ophthalmology data
(with discussion)&rdquo;
by Gao, F., Wahba, G., Klein, R., Klein, B.
<em>Journal of the American Statistical Association</em>,
<b>96</b>, 127&ndash;160.
</p>
<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+loglinb2">loglinb2</a></code>,
<code><a href="#topic+binom2.or">binom2.or</a></code>,
<code><a href="#topic+hunua">hunua</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lfit &lt;- vglm(cbind(cyadea, beitaw, kniexc) ~ altitude, loglinb3,
             data = hunua, trace = TRUE)
coef(lfit, matrix = TRUE)
head(fitted(lfit))
summary(lfit)
</code></pre>

<hr>
<h2 id='loglink'> Log Link Function, and Variants </h2><span id='topic+loglink'></span><span id='topic+negloglink'></span><span id='topic+logneglink'></span>

<h3>Description</h3>

<p>Computes the log transformation, including its inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
        short = TRUE, tag = FALSE)
negloglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
           short = TRUE, tag = FALSE)
logneglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
           short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="loglink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="loglink_+3A_inverse">inverse</code>, <code id="loglink_+3A_deriv">deriv</code>, <code id="loglink_+3A_short">short</code>, <code id="loglink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log link function is very commonly used for parameters that
are positive.
Here, all logarithms are natural logarithms, i.e., to base
<code class="reqn">e</code>.  Numerical values of <code>theta</code> close to 0 or out of
range result in <code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>
<p>The function <code>loglink</code> computes
<code class="reqn">\log(\theta)</code> whereas <code>negloglink</code> computes
<code class="reqn">-\log(\theta)=\log(1/\theta)</code>.
</p>
<p>The function <code>logneglink</code> computes
<code class="reqn">\log(-\theta)</code>, hence is suitable for parameters
that are negative, e.g.,
a trap-shy effect in <code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>.
</p>


<h3>Value</h3>

<p>The following concerns <code>loglink</code>.
For <code>deriv = 0</code>, the log of <code>theta</code>, i.e.,
<code>log(theta)</code> when <code>inverse = FALSE</code>, and if
<code>inverse = TRUE</code> then <code>exp(theta)</code>.
For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of
<code>theta</code> if <code>inverse = FALSE</code>, else if
<code>inverse = TRUE</code> then it returns the reciprocal.
</p>


<h3>Note</h3>

<p>This function was called <code>loge</code> to avoid conflict with the
<code><a href="base.html#topic+Log">log</a></code> function.
Numerical instability may occur when <code>theta</code> is close to
0 unless <code>bvalue</code> is used.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>,
2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+explink">explink</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+logclink">logclink</a></code>,
<code><a href="#topic+logloglink">logloglink</a></code>,
<code><a href="base.html#topic+Log">log</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code>,
<code><a href="#topic+lambertW">lambertW</a></code>,
<code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  loglink(seq(-0.2, 0.5, by = 0.1))
 loglink(seq(-0.2, 0.5, by = 0.1), bvalue = .Machine$double.xmin)
negloglink(seq(-0.2, 0.5, by = 0.1))
negloglink(seq(-0.2, 0.5, by = 0.1), bvalue = .Machine$double.xmin) 
## End(Not run)
logneglink(seq(-0.5, -0.2, by = 0.1))
</code></pre>

<hr>
<h2 id='logloglink'> Log-log and Log-log-log Link Functions </h2><span id='topic+logloglink'></span><span id='topic+loglog'></span><span id='topic+loglogloglink'></span>

<h3>Description</h3>

<p>Computes the two transformations, including their inverse and
the first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logloglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
           short = TRUE, tag = FALSE)
loglogloglink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
              short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logloglink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="logloglink_+3A_bvalue">bvalue</code></td>
<td>

<p>Values of <code>theta</code> which are less than or equal to
1 or <code class="reqn">e</code>
can be
replaced by <code>bvalue</code>
before computing the link function value.
The component name <code>bvalue</code> stands for &ldquo;boundary value&rdquo;.
See <code><a href="#topic+Links">Links</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="logloglink_+3A_inverse">inverse</code>, <code id="logloglink_+3A_deriv">deriv</code>, <code id="logloglink_+3A_short">short</code>, <code id="logloglink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-log link function is commonly used for parameters that
are greater than unity.
Similarly, the log-log-log link function is applicable
for parameters that
are greater than <code class="reqn">e</code>.
Numerical values of <code>theta</code> close to 1 or <code class="reqn">e</code>
or out of range
result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
One possible application of <code>loglogloglink()</code> is to
the <code class="reqn">k</code> parameter (also called <code>size</code>)
of <code><a href="#topic+negbinomial">negbinomial</a></code> to Poisson-like data but with
only a small amount of overdispersion; then <code class="reqn">k</code> is
a large number relative to <code>munb</code>.
In such situations a <code><a href="#topic+loglink">loglink</a></code> or
<code><a href="#topic+loglog">loglog</a></code> link may not be sufficient to draw the
estimate toward the interior of the parameter space.  Using a
more stronger link function can help mitigate the Hauck-Donner
effect <code><a href="#topic+hdeff">hdeff</a></code>.
</p>


<h3>Value</h3>

<p>For <code>logloglink()</code>:
for <code>deriv = 0</code>, the log of <code>log(theta)</code>, i.e.,
<code>log(log(theta))</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>exp(exp(theta))</code>.
</p>
<p>For <code>loglogloglink()</code>:
for <code>deriv = 0</code>, the log of <code>log(log(theta))</code>, i.e.,
<code>log(log(log(theta)))</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>exp(exp(exp(theta)))</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>theta</code> / <em>d</em> <code>eta</code> as a function
of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms, i.e., to base
<em>e</em>.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is
close to 1 or <code class="reqn">e</code>
unless <code>bvalue</code> is used.
</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0.8, 1.5, by = 0.1)
logloglink(x)  # Has NAs
logloglink(x, bvalue = 1.0 + .Machine$double.eps)  # Has no NAs

x &lt;- seq(1.01, 10, len = 100)
logloglink(x)
max(abs(logloglink(logloglink(x), inverse = TRUE) - x))  # 0?
</code></pre>

<hr>
<h2 id='lognormal'> Lognormal Distribution </h2><span id='topic+lognormal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the (univariate)
lognormal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lognormal(lmeanlog = "identitylink", lsdlog = "loglink", zero = "sdlog")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lognormal_+3A_lmeanlog">lmeanlog</code>, <code id="lognormal_+3A_lsdlog">lsdlog</code></td>
<td>

<p>Parameter link functions applied to the mean and (positive)
<code class="reqn">\sigma</code> (standard deviation) parameter.
Both of these are on the log scale.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>






<tr><td><code id="lognormal_+3A_zero">zero</code></td>
<td>

<p>Specifies which
linear/additive predictor is modelled as intercept-only.
For <code>lognormal()</code>,
the values can be from the set {1,2} which correspond to
<code>mu</code>, <code>sigma</code>, respectively.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>



</td></tr>











</table>


<h3>Details</h3>

<p>A random variable <code class="reqn">Y</code> has a 2-parameter lognormal distribution
if <code class="reqn">\log(Y)</code>
is distributed <code class="reqn">N(\mu, \sigma^2)</code>.
The expected value of <code class="reqn">Y</code>, which is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = \exp(\mu + 0.5 \sigma^2)</code>
</p>

<p>and not <code class="reqn">\mu</code>, make up the fitted values.
The variance of <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Var(Y) = [\exp(\sigma^2) -1] \exp(2\mu + \sigma^2).</code>
</p>














<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Lognormal">Lognormal</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>ldata2 &lt;- data.frame(x2 = runif(nn &lt;- 1000))
ldata2 &lt;- transform(ldata2, y1 = rlnorm(nn, 1 + 2 * x2, sd = exp(-1)),
                            y2 = rlnorm(nn, 1, sd = exp(-1 + x2)))
fit1 &lt;- vglm(y1 ~ x2, lognormal(zero = 2), data = ldata2, trace = TRUE)
fit2 &lt;- vglm(y2 ~ x2, lognormal(zero = 1), data = ldata2, trace = TRUE)
coef(fit1, matrix = TRUE)
coef(fit2, matrix = TRUE)
</code></pre>

<hr>
<h2 id='logofflink'> Log Link Function with an Offset </h2><span id='topic+logofflink'></span><span id='topic+log1plink'></span>

<h3>Description</h3>

<p>Computes the log transformation with an offset,
including its inverse and the first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logofflink(theta, offset = 0, inverse = FALSE, deriv = 0,
           short = TRUE, tag = FALSE)
log1plink(theta, offset = 0, inverse = FALSE, deriv = 0,
          short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logofflink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="logofflink_+3A_offset">offset</code></td>
<td>

<p>Offset value.
See <code><a href="#topic+Links">Links</a></code>.
For <code><a href="#topic+log1plink">log1plink</a></code> this argument should
not be used because the offset is
implicitly unity .
</p>
</td></tr>
<tr><td><code id="logofflink_+3A_inverse">inverse</code>, <code id="logofflink_+3A_deriv">deriv</code>, <code id="logofflink_+3A_short">short</code>, <code id="logofflink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-offset link function is very commonly used
for parameters that
are greater than a certain value.
In particular, it is defined by
<code>log(theta + offset)</code> where
<code>offset</code> is the offset value. For example,
if <code>offset = 0.5</code> then the value
of <code>theta</code> is restricted
to be greater than <code class="reqn">-0.5</code>.
</p>
<p>Numerical values of <code>theta</code> close
to <code>-offset</code> or out of range
result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>
<p>The offset is implicitly 1 in <code><a href="#topic+log1plink">log1plink</a></code>.
It is equivalent to <code>logofflink(offset = 1)</code>
but is more accurate if <code>abs(theta)</code> is tiny.
It may be used for <code>lrho</code> in
<code><a href="#topic+extbetabinomial">extbetabinomial</a></code> provided
an offset <code>log(size - 1)</code>
for <code class="reqn">\eta_2</code>
is included.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the log of <code>theta+offset</code>,
i.e.,
<code>log(theta+offset)</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>exp(theta)-offset</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>theta</code> / <em>d</em> <code>eta</code> as
a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns
the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms,
i.e., to base <em>e</em>.
</p>


<h3>Note</h3>

<p>The default means this function is identical
to <code><a href="#topic+loglink">loglink</a></code>.
</p>
<p>Numerical instability may occur when <code>theta</code> is
close to <code>-offset</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed.
London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+extbetabinomial">extbetabinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
logofflink(seq(-0.2, 0.5, by = 0.1))
logofflink(seq(-0.2, 0.5, by = 0.1), offset = 0.5)
       log(seq(-0.2, 0.5, by = 0.1) + 0.5) 
## End(Not run)
</code></pre>

<hr>
<h2 id='lomax'> Lomax Distribution Family Function </h2><span id='topic+lomax'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
Lomax distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lomax(lscale = "loglink", lshape3.q = "loglink", iscale = NULL,
      ishape3.q = NULL, imethod = 1, gscale = exp(-5:5),
      gshape3.q = seq(0.75, 4, by = 0.25),
      probs.y = c(0.25, 0.5, 0.75), zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lomax_+3A_lscale">lscale</code>, <code id="lomax_+3A_lshape3.q">lshape3.q</code></td>
<td>

<p>Parameter link function applied to the
(positive) parameters <code>scale</code> and <code>q</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="lomax_+3A_iscale">iscale</code>, <code id="lomax_+3A_ishape3.q">ishape3.q</code>, <code id="lomax_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>iscale</code> is needed to obtain a good estimate for
the other parameter.
</p>
</td></tr>
<tr><td><code id="lomax_+3A_gscale">gscale</code>, <code id="lomax_+3A_gshape3.q">gshape3.q</code>, <code id="lomax_+3A_zero">zero</code>, <code id="lomax_+3A_probs.y">probs.y</code></td>
<td>

<p>See
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>






</table>


<h3>Details</h3>

<p>The 2-parameter Lomax distribution is the 4-parameter
generalized beta II distribution with shape parameters <code class="reqn">a=p=1</code>.
It is probably more widely known as the Pareto (II) distribution.
It is also the 3-parameter Singh-Maddala distribution
with shape parameter <code class="reqn">a=1</code>, as well as the
beta distribution of the second kind with <code class="reqn">p=1</code>.
More details can be found in Kleiber and Kotz (2003).
</p>
<p>The Lomax distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = q / [b \{1 + y/b\}^{1+q}]</code>
</p>

<p>for <code class="reqn">b &gt; 0</code>, <code class="reqn">q &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and <code>q</code> is a shape parameter.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y) = 1 - [1 + (y/b)]^{-q}.</code>
</p>

<p>The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b/(q-1)</code>
</p>

<p>provided <code class="reqn">q &gt; 1</code>; these are returned as the fitted values.
This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lomax">Lomax</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldata &lt;- data.frame(y = rlomax(n = 1000, scale =  exp(1), exp(2)))
fit &lt;- vglm(y ~ 1, lomax, data = ldata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Lomax'>The Lomax Distribution</h2><span id='topic+Lomax'></span><span id='topic+dlomax'></span><span id='topic+plomax'></span><span id='topic+qlomax'></span><span id='topic+rlomax'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Lomax distribution with scale parameter
<code>scale</code> and shape parameter <code>q</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlomax(x, scale = 1, shape3.q, log = FALSE)
plomax(q, scale = 1, shape3.q, lower.tail = TRUE, log.p = FALSE)
qlomax(p, scale = 1, shape3.q, lower.tail = TRUE, log.p = FALSE)
rlomax(n, scale = 1, shape3.q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lomax_+3A_x">x</code>, <code id="Lomax_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Lomax_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Lomax_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length
is taken to be the number required.</p>
</td></tr>
<tr><td><code id="Lomax_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Lomax_+3A_shape3.q">shape3.q</code></td>
<td>
<p>shape parameter.</p>
</td></tr>
<tr><td><code id="Lomax_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Lomax_+3A_lower.tail">lower.tail</code>, <code id="Lomax_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+lomax">lomax</a></code>, which is the <span class="pkg">VGAM</span> family function
for estimating the parameters by maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>dlomax</code> gives the density,
<code>plomax</code> gives the distribution function,
<code>qlomax</code> gives the quantile function, and
<code>rlomax</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Lomax distribution is a special case of the 4-parameter
generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- seq(0.1, 0.9, by = 0.1)
max(abs(plomax(qlomax(p = probs, shape3.q =  1),
               shape3.q = 1) - probs))  # Should be 0

## Not run:  par(mfrow = c(1, 2))
x &lt;- seq(-0.01, 5, len = 401)
plot(x, dexp(x), type = "l", col = "black", ylab = "", ylim = c(0, 3),
     main = "Black is std exponential, others are dlomax(x, shape3.q)")
lines(x, dlomax(x, shape3.q = 1), col = "orange")
lines(x, dlomax(x, shape3.q = 2), col = "blue")
lines(x, dlomax(x, shape3.q = 5), col = "green")
legend("topright", col = c("orange","blue","green"), lty = rep(1, 3),
       legend = paste("shape3.q =", c(1, 2, 5)))

plot(x, pexp(x), type = "l", col = "black", ylab = "", las = 1,
     main = "Black is std exponential, others are plomax(x, shape3.q)")
lines(x, plomax(x, shape3.q = 1), col = "orange")
lines(x, plomax(x, shape3.q = 2), col = "blue")
lines(x, plomax(x, shape3.q = 5), col = "green")
legend("bottomright", col = c("orange","blue","green"), lty = rep(1, 3),
       legend = paste("shape3.q =", c(1, 2, 5)))

## End(Not run)
</code></pre>

<hr>
<h2 id='lpossums'> Leadbeater's Possums </h2><span id='topic+lpossums'></span>

<h3>Description</h3>

<p>Abundance of Leadbeater's Possums observed in the field.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lpossums)
</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables.
</p>

<dl>
<dt>number</dt><dd>
<p>Values between 0 and 10 excluding 6.
</p>
</dd>
<dt>ofreq</dt><dd>
<p>Observed frequency, i.e., the number of sites.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>A small data set recording the abundance of Leadbeater's Possums
<em>Gymnobelideus leadbeateri</em> observed in
the montane ash forests of 
the Central Highlands of Victoria,
in south-eastern Australia.
There are 151 3-hectare sites.
The data has more 0s than usual relative to the Poisson,
as well as exhibiting overdispersion too.
</p>


<h3>Source</h3>

<p>Welsh, A. H., Cunningham, R. B., Donnelly, C. F. and
Lindenmayer, D. B. (1996).
Modelling the abundances of rare species: statistical models
for counts with extra zeros.
<em>Ecological Modelling</em>,
<b>88</b>,
297&ndash;308.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zipoissonff">zipoissonff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lpossums
(samplemean &lt;- with(lpossums, weighted.mean(number, ofreq)))
with(lpossums,  var(rep(number, times = ofreq)) / samplemean)
sum(with(lpossums, ofreq))
## Not run:  spikeplot(with(lpossums, rep(number, times = ofreq)),
  main = "Leadbeater's possums", col = "blue", xlab = "Number") 
## End(Not run)
</code></pre>

<hr>
<h2 id='lqnorm'> Minimizing the L-q norm Family Function </h2><span id='topic+lqnorm'></span>

<h3>Description</h3>

<p>Minimizes the L-q norm of residuals in a linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lqnorm(qpower = 2, link = "identitylink",
       imethod = 1, imu = NULL, ishrinkage = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lqnorm_+3A_qpower">qpower</code></td>
<td>

<p>A single numeric, must be greater than one, called <code class="reqn">q</code> below.
The absolute value of residuals are raised to the power of
this argument, and then summed.  This quantity is minimized
with respect to the regression coefficients.
</p>
</td></tr>
<tr><td><code id="lqnorm_+3A_link">link</code></td>
<td>

<p>Link function applied to the &lsquo;mean&rsquo; <code class="reqn">\mu</code>.
See <code><a href="#topic+Links">Links</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="lqnorm_+3A_imethod">imethod</code></td>
<td>

<p>Must be 1, 2 or 3.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
Ignored if <code>imu</code> is specified.
</p>
</td></tr>
<tr><td><code id="lqnorm_+3A_imu">imu</code></td>
<td>

<p>Numeric, optional initial values used for the fitted values.
The default is to use <code>imethod = 1</code>.
</p>
</td></tr>
<tr><td><code id="lqnorm_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>How much shrinkage is used when initializing the fitted values.
The value must be between 0 and 1 inclusive, and
a value of 0 means the individual response values are used,
and a value of 1 means the median or mean is used.
This argument is used in conjunction with <code>imethod = 3</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function minimizes the objective function
</p>
<p style="text-align: center;"><code class="reqn"> \sum_{i=1}^n \; w_i (|y_i - \mu_i|)^q </code>
</p>

<p>where <code class="reqn">q</code> is the argument <code>qpower</code>,
<code class="reqn">\eta_i = g(\mu_i)</code> where <code class="reqn">g</code> is
the link function, and
<code class="reqn">\eta_i</code> is the vector of linear/additive predictors.
The prior weights <code class="reqn">w_i</code> can be
inputted using the <code>weights</code> argument of
<code>vlm</code>/<code><a href="#topic+vglm">vglm</a></code>/<code><a href="#topic+vgam">vgam</a></code> etc.; it should
be just a vector here since this function handles only a single
vector or one-column response.
</p>
<p>Numerical problem will occur when <code class="reqn">q</code> is too close to one.
Probably reasonable values range from 1.5 and up, say.
The value <code class="reqn">q=2</code> corresponds to ordinary least squares
while <code class="reqn">q=1</code> corresponds to the MLE of a double exponential
(Laplace) distibution. The procedure becomes more sensitive to
outliers the larger the value of <code class="reqn">q</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Convergence failure is common, therefore the user is advised to
be cautious and monitor convergence!
</p>


<h3>Note</h3>

<p>This <span class="pkg">VGAM</span> family function is an initial attempt to
provide a more robust alternative for regression and/or offer
a little more flexibility than least squares.
The <code>@misc</code> slot of the fitted object contains a list
component called <code>objectiveFunction</code> which is the value
of the objective function at the final iteration.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
ldata &lt;- data.frame(x = sort(runif(nn &lt;- 10 )))
realfun &lt;- function(x) 4 + 5*x
ldata &lt;- transform(ldata, y = realfun(x) + rnorm(nn, sd = exp(-1)))
# Make the first observation an outlier
ldata &lt;- transform(ldata, y = c(4*y[1], y[-1]), x = c(-1, x[-1]))
fit &lt;- vglm(y ~ x, lqnorm(qpower = 1.2), data = ldata)
coef(fit, matrix = TRUE)
head(fitted(fit))
fit@misc$qpower
fit@misc$objectiveFunction

## Not run: 
# Graphical check
with(ldata, plot(x, y,
     main = paste0("LS = red, lqnorm = blue (qpower = ",
     fit@misc$qpower, "), truth = black"), col = "blue"))
lmfit &lt;- lm(y ~ x, data = ldata)
with(ldata, lines(x,  fitted(fit), col = "blue"))
with(ldata, lines(x, lmfit$fitted, col = "red"))
with(ldata, lines(x,  realfun(x),  col = "black")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='lrt.stat'> Likelihood Ratio Test
Statistics Evaluated at the Null Values </h2><span id='topic+lrt.stat'></span><span id='topic+lrt.stat.vlm'></span>

<h3>Description</h3>

<p>Generic function that computes
likelihood ratio test (LRT)
statistics evaluated at the null values
(consequently they do not suffer from the Hauck-Donner effect).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrt.stat(object, ...)
lrt.stat.vlm(object, values0 = 0, subset = NULL, omit1s = TRUE,
          all.out = FALSE, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrt.stat_+3A_object">object</code>, <code id="lrt.stat_+3A_values0">values0</code>, <code id="lrt.stat_+3A_subset">subset</code></td>
<td>

<p>Same as in <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="lrt.stat_+3A_omit1s">omit1s</code>, <code id="lrt.stat_+3A_all.out">all.out</code>, <code id="lrt.stat_+3A_trace">trace</code></td>
<td>

<p>Same as in <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="lrt.stat_+3A_...">...</code></td>
<td>

<p>Ignored for now.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>summary()</code> is applied to a <code><a href="#topic+vglm">vglm</a></code> object
a 4-column Wald table is produced.
The corresponding p-values are generally viewed as inferior to
those from a likelihood ratio test (LRT).
For example, the Hauck and Donner (1977) effect (HDE) produces
p-values that are biased upwards (see <code><a href="#topic+hdeff">hdeff</a></code>).
Other reasons are that the Wald test is often less accurate
(especially in small samples) and is not invariant to
parameterization.
By default, this function returns p-values based on the LRT by
deleting one column at a time from the big VLM matrix
and then restarting IRLS to obtain convergence (hopefully).
Twice the difference between the log-likelihoods
(or equivalently, the difference in the deviances if they are defined)
is asymptotically chi-squared with 1 degree of freedom.
One might expect the p-values from this function
therefore to be more accurate
and not suffer from the HDE.
Thus this function is a recommended
alternative (if it works) to <code><a href="#topic+summaryvglm">summaryvglm</a></code>
for testing for the significance of a regression coefficient.
</p>


<h3>Value</h3>

<p>By default, a vector of signed square root of the LRT statistics;
these are asymptotically standard normal under the null hypotheses.
If <code>all.out = TRUE</code> then a list is returned with the
following components:
<code>lrt.stat</code> the signed LRT statistics,
<code>pvalues</code> the 2-sided p-values,
<code>Lrt.stat2</code> the usual LRT statistic,
<code>values0</code> the null values.
</p>








<h3>Warning </h3>

<p>See <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.  </p>


<h3>See Also</h3>

<p><code><a href="#topic+score.stat">score.stat</a></code>,
<code><a href="#topic+wald.stat">wald.stat</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+lrtest">lrtest</a></code>,
<code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="stats.html#topic+pchisq">pchisq</a></code>,
<code><a href="#topic+profilevglm">profilevglm</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>.
</p>







<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3 = rnorm(nrow(pneumo)))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo)
cbind(coef(summary(fit)),
      "signed LRT stat" = lrt.stat(fit, omit1s = FALSE))
summary(fit, lrt0 = TRUE)  # Easy way to get it
</code></pre>

<hr>
<h2 id='lrtest'>Likelihood Ratio Test of Nested Models</h2><span id='topic+lrtest'></span><span id='topic+lrtest_vglm'></span>

<h3>Description</h3>

<p><code>lrtest</code> is a generic function for carrying out
likelihood ratio tests.
The default method can be employed for comparing nested VGLMs
(see details below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'> lrtest(object, ...)

 lrtest_vglm(object, ..., no.warning = FALSE, name = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrtest_+3A_object">object</code></td>
<td>

<p>a <code><a href="#topic+vglm">vglm</a></code> object.
See below for details.
</p>
</td></tr>
<tr><td><code id="lrtest_+3A_...">...</code></td>
<td>

<p>further object specifications passed to methods.
See below for details.
</p>
</td></tr>
<tr><td><code id="lrtest_+3A_no.warning">no.warning</code></td>
<td>

<p>logical; if <code>TRUE</code> then no warning is issued.
For example, setting <code>TRUE</code> might be a good idea when testing
for linearity of a variable for a <code>"pvgam"</code> object.
</p>
</td></tr>
<tr><td><code id="lrtest_+3A_name">name</code></td>
<td>

<p>a function for extracting a suitable name/description from
a fitted model object.
By default the name is queried by calling <code><a href="stats.html#topic+formula">formula</a></code>.
</p>
</td></tr>




</table>


<h3>Details</h3>

<p><code>lrtest</code> is intended to be a generic function for
comparisons of models via asymptotic likelihood ratio
tests. The default method consecutively compares the
fitted model object <code>object</code> with the models passed
in <code>...</code>. Instead of passing the fitted model
objects in <code>...</code>, several other specifications
are possible. The updating mechanism is the same as for
<code>waldtest()</code> in <span class="pkg">lmtest</span>:
the models in <code>...</code>
can be specified as integers, characters (both for terms
that should be eliminated from the previous model),
update formulas or fitted model objects. Except for
the last case, the existence of an <code><a href="stats.html#topic+update">update</a></code>
method is assumed.
See <code>waldtest()</code> in <span class="pkg">lmtest</span> for details.
</p>


<p>Subsequently, an asymptotic likelihood ratio test for each
two consecutive models is carried out: Twice the difference
in log-likelihoods (as derived by the <code><a href="stats.html#topic+logLik">logLik</a></code>
methods) is compared with a Chi-squared distribution.
</p>




<h3>Value</h3>

<p>An object of class <code>"VGAManova"</code> which contains a slot
with the
log-likelihood, degrees of freedom, the difference in
degrees of freedom, likelihood ratio Chi-squared statistic
and corresponding p value.
These are printed by <code>stats:::print.anova()</code>;
see <code><a href="stats.html#topic+anova">anova</a></code>.
</p>


<h3>Warning </h3>

<p>Several <span class="pkg">VGAM</span> family functions implement distributions
which do not satisfying the usual regularity conditions needed
for the LRT to work. No checking or warning is given for these.
</p>


<h3>Note</h3>

<p>The code was adapted directly from <span class="pkg">lmtest</span> (written by
T. Hothorn, A. Zeileis, G. Millo, D. Mitchell)
and made to work for VGLMs and S4.
This help file also was adapted from <span class="pkg">lmtest</span>.
</p>
<p><em>Approximate</em> LRTs might be applied to VGAMs, as
produced by <code><a href="#topic+vgam">vgam</a></code>, but it is probably better in
inference to use <code><a href="#topic+vglm">vglm</a></code> with regression splines
(<code><a href="splines.html#topic+bs">bs</a></code> and
<code><a href="splines.html#topic+ns">ns</a></code>).
This methods function should not be applied to other models
such as those produced
by <code><a href="#topic+rrvglm">rrvglm</a></code>,
by <code><a href="#topic+cqo">cqo</a></code>,
by <code><a href="#topic+cao">cao</a></code>.
</p>


<h3>See Also</h3>

<p><span class="pkg">lmtest</span>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+score.stat.vlm">score.stat.vlm</a></code>,
<code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3  = runif(nrow(pneumo)))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let     , propodds, pneumo)
fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let + x3, propodds, pneumo)
fit3 &lt;- vglm(cbind(normal, mild, severe) ~ let     , cumulative, pneumo)
# Various equivalent specifications of the LR test for testing x3
(ans1 &lt;- lrtest(fit2, fit1))
ans2 &lt;- lrtest(fit2, 2)
ans3 &lt;- lrtest(fit2, "x3")
ans4 &lt;- lrtest(fit2, . ~ . - x3)
c(all.equal(ans1, ans2), all.equal(ans1, ans3), all.equal(ans1, ans4))

# Doing it manually
(testStatistic &lt;- 2 * (logLik(fit2) - logLik(fit1)))
(pval &lt;- pchisq(testStatistic, df = df.residual(fit1) - df.residual(fit2),
                lower.tail = FALSE))

(ans4 &lt;- lrtest(fit3, fit1))  # Test PO (parallelism) assumption
</code></pre>

<hr>
<h2 id='lvplot'> Latent Variable Plot </h2><span id='topic+lvplot'></span>

<h3>Description</h3>

<p>Generic function for a <em>latent variable plot</em>
(also known as an <em>ordination diagram</em> by ecologists).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lvplot(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lvplot_+3A_object">object</code></td>
<td>
<p> An object for a latent
variable plot is meaningful.
</p>
</td></tr>
<tr><td><code id="lvplot_+3A_...">...</code></td>
<td>
<p> Other arguments fed into the specific
methods function of the model. They usually are graphical
parameters, and sometimes they are fed
into the methods function for <code><a href="#topic+Coef">Coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Latent variables occur in reduced-rank regression models,
as well as in
quadratic and additive ordination. For the latter,
latent variables are often called the <em>site scores</em>.
Latent variable plots were coined by Yee (2004), and have
the latent variable as at least one of its axes.
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods
function invoked.
</p>


<h3>Note</h3>

<p>Latent variables are not really applicable to
<code><a href="#topic+vglm">vglm</a></code>/<code><a href="#topic+vgam">vgam</a></code> models.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>,
<code>lvplot.cao</code>,
<code><a href="#topic+latvar">latvar</a></code>,
<code><a href="#topic+trplot">trplot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Stdz environmental vars
set.seed(123)
p1 &lt;- cao(cbind(Pardlugu, Pardmont, Pardnigr, Pardpull, Zoraspin) ~
          WaterCon + BareSand + FallTwig +
          CoveMoss + CoveHerb + ReflLux,
          family = poissonff, data = hspider, Bestof = 3,
          df1.nl = c(Zoraspin = 2.5, 3), Crow1positive = TRUE)
index &lt;- 1:ncol(depvar(p1))
lvplot(p1, lcol = index, pcol = index, y = TRUE, las = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='lvplot.qrrvglm'> Latent Variable Plot for QO models </h2><span id='topic+lvplot.qrrvglm'></span>

<h3>Description</h3>

<p>Produces an ordination diagram (latent variable plot) for quadratic
ordination (QO) models.  For rank-1 models, the x-axis is the first
ordination/constrained/canonical axis.  For rank-2 models, the x-
and y-axis are the first and second ordination axes respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lvplot.qrrvglm(object, varI.latvar = FALSE, refResponse = NULL,
    add = FALSE, show.plot = TRUE,
    rug = TRUE, y = FALSE, type = c("fitted.values", "predictors"),
    xlab = paste0("Latent Variable", if (Rank == 1) "" else " 1"),
    ylab = if (Rank == 1) switch(type, predictors = "Predictors",
    fitted.values = "Fitted values") else "Latent Variable 2",
    pcex = par()$cex, pcol = par()$col, pch = par()$pch,
    llty = par()$lty, lcol = par()$col, llwd = par()$lwd,
    label.arg = FALSE, adj.arg = -0.1,
    ellipse = 0.95, Absolute = FALSE, elty = par()$lty,
    ecol = par()$col, elwd = par()$lwd, egrid = 200,
    chull.arg = FALSE, clty = 2, ccol = par()$col, clwd = par()$lwd,
    cpch = "   ",
    C = FALSE, OriginC = c("origin", "mean"),
    Clty = par()$lty, Ccol = par()$col, Clwd = par()$lwd,
    Ccex = par()$cex, Cadj.arg = -0.1, stretchC = 1,
    sites = FALSE, spch = NULL, scol = par()$col, scex = par()$cex,
    sfont = par()$font, check.ok = TRUE, jitter.y = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lvplot.qrrvglm_+3A_object">object</code></td>
<td>

<p>A CQO object.
</p>

</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_vari.latvar">varI.latvar</code></td>
<td>

<p>Logical that is fed into <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_refresponse">refResponse</code></td>
<td>

<p>Integer or character that is fed into <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_add">add</code></td>
<td>
<p> Logical.
Add to an existing plot? If <code>FALSE</code>, a new
plot is made.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_show.plot">show.plot</code></td>
<td>
<p> Logical. Plot it?
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_rug">rug</code></td>
<td>
<p> Logical.
If <code>TRUE</code>, a rug plot is plotted at the
foot of the plot (applies to rank-1 models only).
These values are jittered to expose ties.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_y">y</code></td>
<td>
<p> Logical. If <code>TRUE</code>, the responses will be
plotted (applies only to rank-1 models and if
<code>type = "fitted.values"</code>.)
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_type">type</code></td>
<td>

<p>Either <code>"fitted.values"</code> or <code>"predictors"</code>,
specifies whether the y-axis is on the response or eta-scales
respectively.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_xlab">xlab</code></td>
<td>
<p> Caption for the x-axis. See
<code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_ylab">ylab</code></td>
<td>
<p> Caption for the y-axis. See
<code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_pcex">pcex</code></td>
<td>
<p> Character expansion of the points.
Here, for rank-1 models, points are the response <em>y</em> data.
For rank-2 models, points are the optimums.
See the <code>cex</code> argument in <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_pcol">pcol</code></td>
<td>
<p> Color of the points.
See the <code>col</code> argument in <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_pch">pch</code></td>
<td>
<p> Either an integer specifying a symbol or a single
character to be used as the default in plotting points.
See <code><a href="graphics.html#topic+par">par</a></code>.
The <code>pch</code> argument can be of length <code class="reqn">M</code>,
the number of species.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_llty">llty</code></td>
<td>
<p> Line type.
Rank-1 models only.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_lcol">lcol</code></td>
<td>
<p> Line color.
Rank-1 models only.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_llwd">llwd</code></td>
<td>
<p> Line width.
Rank-1 models only.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_label.arg">label.arg</code></td>
<td>
<p> Logical. Label the optimums and <b>C</b>?
(applies only to rank-2 models only).
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_adj.arg">adj.arg</code></td>
<td>
<p> Justification of text strings for labelling
the optimums
(applies only to rank-2 models only).
See the <code>adj</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_ellipse">ellipse</code></td>
<td>

<p>Numerical, of length 0 or 1 (applies only to rank-2 models only).
If <code>Absolute</code> is <code>TRUE</code> then <code>ellipse</code> should be
assigned a value that is used for the elliptical contouring.
If <code>Absolute</code> is <code>FALSE</code> then <code>ellipse</code>
should be assigned a value between 0 and 1, for example,
setting <code>ellipse = 0.9</code> means an ellipse with contour
= 90% of the maximum will be plotted about each optimum.
If <code>ellipse</code> is a negative value, then the function checks
that the model is an equal-tolerances model and
<code>varI.latvar = FALSE</code>, and if so, plots circles with
radius <code>-ellipse</code>. For example, setting <code>ellipse = -1</code>
will result in circular contours that have unit radius (in latent
variable units).  If <code>ellipse</code> is <code>NULL</code> or <code>FALSE</code>
then no ellipse is drawn around the optimums.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_absolute">Absolute</code></td>
<td>
<p> Logical.
If <code>TRUE</code>, the contours corresponding to <code>ellipse</code>
are on an absolute scale.
If <code>FALSE</code>, the contours corresponding to <code>ellipse</code>
are on a relative scale.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_elty">elty</code></td>
<td>
<p> Line type of the ellipses.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_ecol">ecol</code></td>
<td>
<p> Line color of the ellipses.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_elwd">elwd</code></td>
<td>
<p> Line width of the ellipses.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_egrid">egrid</code></td>
<td>
<p> Numerical. Line resolution of the ellipses.
Choosing a larger value will result in smoother ellipses.
Useful when ellipses are large.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_chull.arg">chull.arg</code></td>
<td>
<p> Logical. Add a convex hull around the
site scores? </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_clty">clty</code></td>
<td>
<p> Line type of the convex hull.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_ccol">ccol</code></td>
<td>
<p> Line color of the convex hull.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_clwd">clwd</code></td>
<td>
<p> Line width of the convex hull.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_cpch">cpch</code></td>
<td>

<p>Character to be plotted at the intersection points of
the convex hull. Having white spaces means that site
labels are not obscured there.
See the <code>pch</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_c">C</code></td>
<td>
<p> Logical. Add <b>C</b> (represented by arrows emanating
from <code>OriginC</code>) to the plot? </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_originc">OriginC</code></td>
<td>
<p> Character or numeric.
Where the arrows representing <b>C</b> emanate from.
If character, it must be one of the choices given. By default the
first is chosen.
The value <code>"origin"</code> means <code>c(0,0)</code>.
The value <code>"mean"</code> means
the sample mean of the latent variables (centroid).
Alternatively, the user may specify a numerical vector of length 2.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_clty">Clty</code></td>
<td>
<p> Line type of the arrows representing <b>C</b>.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_ccol">Ccol</code></td>
<td>
<p> Line color of the arrows representing <b>C</b>.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_clwd">Clwd</code></td>
<td>
<p> Line width of the arrows representing <b>C</b>.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_ccex">Ccex</code></td>
<td>
<p> Numeric.
Character expansion of the labelling of <b>C</b>.
See the <code>cex</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_cadj.arg">Cadj.arg</code></td>
<td>

<p>Justification of text strings when labelling <b>C</b>.
See the <code>adj</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_stretchc">stretchC</code></td>
<td>
<p> Numerical. Stretching factor for <b>C</b>.
Instead of using <b>C</b>, <code>stretchC * </code> <b>C</b> is used.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_sites">sites</code></td>
<td>
<p> Logical.
Add the site scores (aka latent variable
values, nu's) to the plot?
(applies only to rank-2 models only).
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_spch">spch</code></td>
<td>
<p> Plotting character of the site scores.
The default value of <code>NULL</code> means the row labels of the
data frame are used. They often are the site numbers.
See the <code>pch</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_scol">scol</code></td>
<td>
<p> Color of the site scores.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_scex">scex</code></td>
<td>
<p> Character expansion of the site scores.
See the <code>cex</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_sfont">sfont</code></td>
<td>
<p> Font used for the site scores.
See the <code>font</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>





















<tr><td><code id="lvplot.qrrvglm_+3A_check.ok">check.ok</code></td>
<td>
<p> Logical. Whether a check is performed to see
that <code>noRRR = ~ 1</code> was used.
It doesn't make sense to have a latent variable plot unless
this is so.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_jitter.y">jitter.y</code></td>
<td>
<p> Logical. If <code>y</code> is plotted, jitter it first?
This may be useful for counts and proportions.
</p>
</td></tr>
<tr><td><code id="lvplot.qrrvglm_+3A_...">...</code></td>
<td>
<p> Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>xlim</code> and <code>ylim</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only works for rank-1 and rank-2 QRR-VGLMs with
argument <code>noRRR = ~ 1</code>.
</p>
<p>For unequal-tolerances models, the latent variable axes can
be rotated so that at least one of the tolerance matrices is
diagonal; see <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code> for details.
</p>
<p>Arguments beginning with &ldquo;<code>p</code>&rdquo; correspond to the points
e.g., <code>pcex</code> and <code>pcol</code> correspond to the size and
color of the points. Such &ldquo;<code>p</code>&rdquo; arguments should be
vectors of length 1, or <code class="reqn">n</code>, the number of sites.  For the
rank-2 model, arguments beginning with &ldquo;<code>p</code>&rdquo; correspond
to the optimums.
</p>


<h3>Value</h3>

<p>Returns a matrix of latent variables (site scores)
regardless of whether a plot was produced or not.
</p>


<h3>Warning</h3>

<p>Interpretation of a latent variable plot (CQO diagram) is
potentially very misleading in terms of distances if (i)
the tolerance matrices of the species are unequal and (ii)
the contours of these tolerance matrices are not included in
the ordination diagram.
</p>


<h3>Note</h3>

<p>A species which does not have an optimum will not have an
ellipse drawn even if requested, i.e., if its tolerance matrix
is not positive-definite.
</p>


<p>Plotting <b>C</b> gives a visual display of the weights
(loadings) of each of the variables used in the linear
combination defining each latent variable.
</p>
<p>The arguments <code>elty</code>, <code>ecol</code> and <code>elwd</code>,
may be replaced in the future by <code>llty</code>, <code>lcol</code>
and <code>llwd</code>, respectively.
</p>
<p>For rank-1 models, a similar function to this one is
<code><a href="#topic+perspqrrvglm">perspqrrvglm</a></code>.  It plots the fitted values on
a more fine grid rather than at the actual site scores here.
The result is a collection of smooth bell-shaped curves. However,
it has the weakness that the plot is more divorced from the data;
the user thinks it is the truth without an appreciation of the
statistical variability in the estimates.
</p>


<p>In the example below, the data comes from an equal-tolerances
model.  The species' tolerance matrices are all the identity
matrix, and the optimums are at (0,0), (1,1) and (-2,0) for
species 1, 2, 3 respectively.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lvplot">lvplot</a></code>,
<code><a href="#topic+perspqrrvglm">perspqrrvglm</a></code>,
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>,
<code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123); nn &lt;- 200
cdata &lt;- data.frame(x2 = rnorm(nn),  # Mean 0 (needed when I.tol=TRUE)
                    x3 = rnorm(nn),  # Mean 0 (needed when I.tol=TRUE)
                    x4 = rnorm(nn))  # Mean 0 (needed when I.tol=TRUE)
cdata &lt;- transform(cdata, latvar1 =  x2 + x3 - 2*x4,
                          latvar2 = -x2 + x3 + 0*x4)
# Nb. latvar2 is weakly correlated with latvar1
cdata &lt;- transform(cdata,
           lambda1 = exp(6 - 0.5 * (latvar1-0)^2 - 0.5 * (latvar2-0)^2),
           lambda2 = exp(5 - 0.5 * (latvar1-1)^2 - 0.5 * (latvar2-1)^2),
           lambda3 = exp(5 - 0.5 * (latvar1+2)^2 - 0.5 * (latvar2-0)^2))
cdata &lt;- transform(cdata,
            spp1 = rpois(nn, lambda1),
            spp2 = rpois(nn, lambda2),
            spp3 = rpois(nn, lambda3))
set.seed(111)
## Not run: 
p2 &lt;- cqo(cbind(spp1, spp2, spp3) ~ x2 + x3 + x4, poissonff,
          data = cdata, Rank = 2, I.tolerances = TRUE,
          Crow1positive = c(TRUE, FALSE))  # deviance = 505.81
if (deviance(p2) &gt; 506) stop("suboptimal fit obtained")
sort(deviance(p2, history = TRUE))  # A history of the iterations
Coef(p2)

## End(Not run)

## Not run: 
lvplot(p2, sites = TRUE, spch = "*", scol = "darkgreen", scex = 1.5,
  chull = TRUE, label = TRUE, Absolute = TRUE, ellipse = 140,
  adj = -0.5, pcol = "blue", pcex = 1.3, las = 1, Ccol = "orange",
  C = TRUE, Cadj = c(-0.3, -0.3, 1), Clwd = 2, Ccex = 1.4,
  main = paste("Contours at Abundance = 140 with",
               "convex hull of the site scores")) 
## End(Not run)
## Not run: 
var(latvar(p2))  # A diagonal matrix, i.e., uncorrelated latent vars
var(latvar(p2, varI.latvar = TRUE))  # Identity matrix
Tol(p2)[, , 1:2]  # Identity matrix
Tol(p2, varI.latvar = TRUE)[, , 1:2]  # A diagonal matrix

## End(Not run)
</code></pre>

<hr>
<h2 id='lvplot.rrvglm'> Latent Variable Plot for RR-VGLMs </h2><span id='topic+lvplot.rrvglm'></span><span id='topic+biplot.rrvglm'></span>

<h3>Description</h3>

<p>Produces an <em>ordination diagram</em> (also known
as a <em>biplot</em> or <em>latent variable plot</em>) for
<em>reduced-rank vector generalized linear models</em> (RR-VGLMs).
For rank-2 models only, the x- and y-axis are the first and
second canonical axes respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lvplot.rrvglm(object,
    A = TRUE, C = TRUE, scores = FALSE, show.plot = TRUE,
    groups = rep(1, n), gapC = sqrt(sum(par()$cxy^2)),
    scaleA = 1,
    xlab = "Latent Variable 1", ylab = "Latent Variable 2",
    Alabels = if (length(object@misc$predictors.names))
    object@misc$predictors.names else param.names("LP", M),
    Aadj = par()$adj, Acex = par()$cex, Acol = par()$col,
    Apch = NULL,
    Clabels = rownames(Cmat), Cadj = par()$adj,
    Ccex = par()$cex, Ccol = par()$col, Clty = par()$lty,
    Clwd = par()$lwd,
    chull.arg = FALSE, ccex = par()$cex, ccol = par()$col,
    clty = par()$lty, clwd = par()$lwd,
    spch = NULL, scex = par()$cex, scol = par()$col,
    slabels = rownames(x2mat), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lvplot.rrvglm_+3A_object">object</code></td>
<td>
<p> Object of class <code>"rrvglm"</code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_a">A</code></td>
<td>
<p> Logical. Allow the plotting of <b>A</b>? </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_c">C</code></td>
<td>
<p> Logical. Allow the plotting of <b>C</b>? If <code>TRUE</code>
then
<b>C</b> is represented by arrows emenating from the origin.
</p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_scores">scores</code></td>
<td>
<p> Logical. Allow the plotting of the <code class="reqn">n</code> scores?
The scores are the values of the latent variables for each
observation.
</p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_show.plot">show.plot</code></td>
<td>
<p> Logical. Plot it? If <code>FALSE</code>, no plot
is produced and the matrix of scores (<code class="reqn">n</code> latent variable
values) is returned.  If <code>TRUE</code>, the rank of <code>object</code>
need not be 2.
</p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_groups">groups</code></td>
<td>
<p> A vector whose distinct values indicate
which group the observation belongs to. By default, all the
observations belong to a single group. Useful for the multinomial
logit model (see <code><a href="#topic+multinomial">multinomial</a></code>.</p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_gapc">gapC</code></td>
<td>
<p> The gap between the end of the arrow and the text
labelling of <b>C</b>, in latent variable units.</p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_scalea">scaleA</code></td>
<td>
<p> Numerical value that is multiplied by <b>A</b>,
so that <b>C</b> is divided by this value. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_xlab">xlab</code></td>
<td>
<p> Caption for the x-axis. See
<code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_ylab">ylab</code></td>
<td>
<p> Caption for the y-axis. See
<code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_alabels">Alabels</code></td>
<td>
<p> Character vector to label <b>A</b>. Must be
of length <code class="reqn">M</code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_aadj">Aadj</code></td>
<td>
<p> Justification of text strings for
labelling <b>A</b>.  See the <code>adj</code> argument of
<code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_acex">Acex</code></td>
<td>
<p> Numeric. Character expansion of the
labelling of <b>A</b>.  See the <code>cex</code> argument of
<code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_acol">Acol</code></td>
<td>
<p> Line color of the arrows representing <b>C</b>.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_apch">Apch</code></td>
<td>
<p> Either an integer specifying a symbol or a single
character
to be used as the default in plotting points.  See
<code><a href="graphics.html#topic+par">par</a></code>.  The <code>pch</code> argument can
be of length <code class="reqn">M</code>, the number of species. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_clabels">Clabels</code></td>
<td>
<p> Character vector to label <b>C</b>. Must be
of length <code class="reqn">p2</code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_cadj">Cadj</code></td>
<td>
<p> Justification of text strings for
labelling <b>C</b>.  See the <code>adj</code> argument of
<code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_ccex">Ccex</code></td>
<td>
<p> Numeric. Character expansion of the
labelling of <b>C</b>.  See the <code>cex</code> argument of
<code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_ccol">Ccol</code></td>
<td>
<p> Line color of the arrows representing <b>C</b>.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_clty">Clty</code></td>
<td>
<p> Line type of the arrows representing <b>C</b>.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_clwd">Clwd</code></td>
<td>
<p> Line width of the arrows representing <b>C</b>.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_chull.arg">chull.arg</code></td>
<td>
<p> Logical. Plot the convex hull of the scores?
This is done for each group (see the <code>group</code> argument). </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_ccex">ccex</code></td>
<td>
<p> Numeric.
Character expansion of the labelling of the convex hull.
See the <code>cex</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_ccol">ccol</code></td>
<td>
<p> Line color of the convex hull.  See the <code>col</code>
argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_clty">clty</code></td>
<td>
<p> Line type of the convex hull.  See the <code>lty</code>
argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_clwd">clwd</code></td>
<td>
<p> Line width of the convex hull.  See the <code>lwd</code>
argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_spch">spch</code></td>
<td>
<p> Either an integer specifying a symbol or
a single character
to be used as the default in plotting points.
See <code><a href="graphics.html#topic+par">par</a></code>.
The <code>spch</code> argument can be of length <code class="reqn">M</code>,
number of species. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_scex">scex</code></td>
<td>
<p> Numeric. Character expansion of the
labelling of the scores.
See the <code>cex</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_scol">scol</code></td>
<td>
<p> Line color of the arrows representing <b>C</b>.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_slabels">slabels</code></td>
<td>
<p> Character vector to label the scores.
Must be of length <code class="reqn">n</code>. </p>
</td></tr>
<tr><td><code id="lvplot.rrvglm_+3A_...">...</code></td>
<td>
<p> Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>xlim</code> and <code>ylim</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For RR-VGLMs, a <em>biplot</em> and a <em>latent variable</em>
plot coincide.
In general, many of the arguments starting with
&ldquo;A&rdquo; refer to <b>A</b> (of length <code class="reqn">M</code>),
&ldquo;C&rdquo; to <b>C</b> (of length <code class="reqn">p2</code>),
&ldquo;c&rdquo; to the convex hull (of length <code>length(unique(groups))</code>),
and &ldquo;s&rdquo; to scores (of length <code class="reqn">n</code>).
</p>
<p>As the result is a biplot, its interpretation is based on the inner
product.
</p>


<h3>Value</h3>

<p>The matrix of scores (<code class="reqn">n</code> latent variable values) is returned
regardless of whether a plot was produced or not.
</p>


<h3>Note</h3>




<p>The functions <code><a href="#topic+lvplot.rrvglm">lvplot.rrvglm</a></code> and
<code><a href="#topic+biplot.rrvglm">biplot.rrvglm</a></code> are equivalent.
</p>
<p>In the example below the predictor variables are centered,
which is a good idea.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lvplot">lvplot</a></code>,
<code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+Coef.rrvglm">Coef.rrvglm</a></code>,
<code><a href="#topic+rrvglm.control">rrvglm.control</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> set.seed(1)
nn &lt;- nrow(pneumo)  # x1--x3 are some unrelated covariates
pneumo &lt;-
  transform(pneumo, slet = scale(log(exposure.time)),
                    imag = severe + 3,  # Fictitional!
                    x1 = rnorm(nn), x2 = rnorm(nn), x3 = rnorm(nn))
fit &lt;-
  rrvglm(cbind(normal, mild, severe, imag) ~ slet + x1 + x2 + x3,
#             Corner = FALSE, Uncorrel = TRUE,   # orig.
              multinomial, data = pneumo, Rank = 2)
## Not run: 
lvplot(fit, chull = TRUE, scores = TRUE, clty = 2, ccol = 4,
       scol = "red", Ccol = "green3", Clwd = 2, Ccex = 2,
       main = "Biplot of some fictitional data") 
## End(Not run)
</code></pre>

<hr>
<h2 id='machinists'> Machinists Accidents </h2><span id='topic+machinists'></span>

<h3>Description</h3>

<p>A small count data set
involving 414 machinists from a three months study,
of accidents around the end of WWI.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(machinists)
</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables.
</p>

<dl>
<dt>accidents</dt><dd>
<p>The number of accidents
</p>
</dd>
<dt>ofreq</dt><dd>
<p>Observed frequency, i.e., the number of machinists
with that many accidents
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was collected over a period of three months.
There were 414 machinists in total.
Also, there were data collected over six months, but it
is not given here.
</p>


<h3>Source</h3>

<p>Incidence of Industrial Accidents.
Report No. 4 (Industrial Fatigue Research Board),
Stationery Office, London, 1919.
</p>


<h3>References</h3>

<p>Greenwood, M. and Yule, G. U. (1920).
An Inquiry into the Nature of Frequency Distributions
Representative of Multiple Happenings with Particular
Reference to the Occurrence of Multiple Attacks of Disease
or of Repeated Accidents.
<em>Journal of the Royal Statistical Society</em>,
<b>83</b>, 255&ndash;279.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>machinists
mean(with(machinists, rep(accidents, times = ofreq)))
 var(with(machinists, rep(accidents, times = ofreq)))
## Not run:  barplot(with(machinists, ofreq),
          names.arg = as.character(with(machinists, accidents)),
          main = "Machinists accidents",
          col = "lightblue", las = 1,
          ylab = "Frequency", xlab = "accidents") 
## End(Not run)
</code></pre>

<hr>
<h2 id='makeham'> Makeham Regression Family Function </h2><span id='topic+makeham'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 3-parameter
Makeham distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeham(lscale = "loglink", lshape = "loglink", lepsilon = "loglink",
        iscale = NULL,   ishape = NULL,   iepsilon = NULL,
        gscale = exp(-5:5),gshape = exp(-5:5), gepsilon = exp(-4:1),
        nsimEIM = 500, oim.mean = TRUE, zero = NULL, nowarning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeham_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning?
Ignored for <span class="pkg">VGAM</span> 0.9-7 and higher.
</p>
</td></tr>
<tr><td><code id="makeham_+3A_lshape">lshape</code>, <code id="makeham_+3A_lscale">lscale</code>, <code id="makeham_+3A_lepsilon">lepsilon</code></td>
<td>

<p>Parameter link functions applied to the
shape parameter <code>shape</code>,
scale parameter <code>scale</code>, and
other parameter <code>epsilon</code>.
All parameters are treated as positive here
(cf. <code><a href="#topic+dmakeham">dmakeham</a></code> allows <code>epsilon = 0</code>, etc.).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>




<tr><td><code id="makeham_+3A_ishape">ishape</code>, <code id="makeham_+3A_iscale">iscale</code>, <code id="makeham_+3A_iepsilon">iepsilon</code></td>
<td>

<p>Optional initial values.
A <code>NULL</code> means a value is computed internally.
A value must be given for <code>iepsilon</code> currently, and this
is a sensitive parameter!
</p>
</td></tr>
<tr><td><code id="makeham_+3A_gshape">gshape</code>, <code id="makeham_+3A_gscale">gscale</code>, <code id="makeham_+3A_gepsilon">gepsilon</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="makeham_+3A_nsimeim">nsimEIM</code>, <code id="makeham_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
Argument <code>probs.y</code> is used only when <code>imethod = 2</code>.
</p>
</td></tr>
<tr><td><code id="makeham_+3A_oim.mean">oim.mean</code></td>
<td>

<p>To be currently ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Makeham distribution, which adds another parameter
to the Gompertz distribution,
has cumulative distribution function
</p>
<p style="text-align: center;"><code class="reqn">F(y; \alpha, \beta, \varepsilon) =
1 - \exp
\left\{
-y \varepsilon + \frac {\alpha}{\beta}
\left[ 1 - e^{\beta y} \right]
\right\}
</code>
</p>

<p>which leads to a probability density function
</p>
<p style="text-align: center;"><code class="reqn">f(y; \alpha, \beta, \varepsilon) =
\left[
\varepsilon + \alpha e^{\beta y} \right]
\;
\exp
\left\{
-y \varepsilon + \frac {\alpha}{\beta}
\left[ 1 - e^{\beta y} \right]
\right\},
</code>
</p>

<p>for <code class="reqn">\alpha &gt; 0</code>,
<code class="reqn">\beta &gt; 0</code>,
<code class="reqn">\varepsilon \geq 0</code>,
<code class="reqn">y &gt; 0</code>.
Here, <code class="reqn">\beta</code> is called the scale parameter <code>scale</code>,
and <code class="reqn">\alpha</code> is called a shape parameter.
The moments for this distribution do
not appear to be available in closed form.
</p>
<p>Simulated Fisher scoring is used and multiple responses are handled.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>A lot of care is needed because
this is a rather difficult distribution for parameter estimation,
especially when the shape parameter is large relative to the
scale parameter.
If the self-starting initial values fail then try experimenting
with the initial value arguments, especially <code>iepsilon</code>.
Successful convergence depends on having very good initial values.
More improvements could be made here.
Also, monitor convergence by setting <code>trace = TRUE</code>.
</p>
<p>A trick is to fit a <code><a href="#topic+gompertz">gompertz</a></code> distribution and use
it for initial values; see below.
However, this family function is currently numerically fraught.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+dmakeham">dmakeham</a></code>,
<code><a href="#topic+gompertz">gompertz</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  set.seed(123)
mdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
mdata &lt;- transform(mdata, eta1  = -1,
                          ceta1 =  1,
                          eeta1 = -2)
mdata &lt;- transform(mdata, shape1 = exp(eta1),
                          scale1 = exp(ceta1),
                          epsil1 = exp(eeta1))
mdata &lt;- transform(mdata,
         y1 = rmakeham(nn, shape = shape1, scale = scale1, eps = epsil1))

# A trick is to fit a Gompertz distribution first
fit0 &lt;- vglm(y1 ~ 1, gompertz, data = mdata, trace = TRUE)
fit1 &lt;- vglm(y1 ~ 1, makeham, data = mdata,
             etastart = cbind(predict(fit0), log(0.1)), trace = TRUE)

coef(fit1, matrix = TRUE)
summary(fit1)

## End(Not run)
</code></pre>

<hr>
<h2 id='Makeham'>The Makeham Distribution</h2><span id='topic+Makeham'></span><span id='topic+dmakeham'></span><span id='topic+pmakeham'></span><span id='topic+qmakeham'></span><span id='topic+rmakeham'></span>

<h3>Description</h3>

<p>Density,
cumulative distribution function,
quantile function
and
random generation for
the Makeham distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmakeham(x, scale = 1, shape, epsilon = 0, log = FALSE)
pmakeham(q, scale = 1, shape, epsilon = 0, lower.tail = TRUE,
         log.p = FALSE)
qmakeham(p, scale = 1, shape, epsilon = 0, lower.tail = TRUE,
         log.p = FALSE)
rmakeham(n, scale = 1, shape, epsilon = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Makeham_+3A_x">x</code>, <code id="Makeham_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Makeham_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Makeham_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Makeham_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Makeham_+3A_lower.tail">lower.tail</code>, <code id="Makeham_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Makeham_+3A_scale">scale</code>, <code id="Makeham_+3A_shape">shape</code></td>
<td>
<p>positive scale and shape parameters. </p>
</td></tr>
<tr><td><code id="Makeham_+3A_epsilon">epsilon</code></td>
<td>
<p>another parameter. Must be non-negative. See
below. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+makeham">makeham</a></code> for details.
The default value of <code>epsilon = 0</code> corresponds
to the Gompertz distribution.
The function <code><a href="#topic+pmakeham">pmakeham</a></code> uses <code><a href="#topic+lambertW">lambertW</a></code>.
</p>


<h3>Value</h3>

<p><code>dmakeham</code> gives the density,
<code>pmakeham</code> gives the cumulative distribution function,
<code>qmakeham</code> gives the quantile function, and
<code>rmakeham</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Jodra, P. (2009).
A closed-form expression for the quantile function of the
Gompertz-Makeham distribution.
<em>Mathematics and Computers in Simulation</em>,
<b>79</b>, 3069&ndash;3075.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeham">makeham</a></code>,
<code><a href="#topic+lambertW">lambertW</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- seq(0.01, 0.99, by = 0.01)
Shape &lt;- exp(-1); Scale &lt;- exp(1); eps = Epsilon &lt;- exp(-1)
max(abs(pmakeham(qmakeham(probs, sca = Scale, Shape, eps = Epsilon),
    sca = Scale, Shape, eps = Epsilon) - probs))  # Should be 0

## Not run:  x &lt;- seq(-0.1, 2.0, by = 0.01);
plot(x, dmakeham(x, sca = Scale, Shape, eps = Epsilon), type = "l",
     main = "Blue is density, orange is the CDF",
     sub = "Purple lines are the 10,20,...,90 percentiles",
     col = "blue", las = 1, ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(x, pmakeham(x, sca = Scale, Shape, eps = Epsilon), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qmakeham(probs, sca = Scale, Shape, eps = Epsilon)
lines(Q, dmakeham(Q, sca = Scale, Shape, eps = Epsilon),
      col = "purple", lty = 3, type = "h")
pmakeham(Q, sca = Scale, Shape, eps = Epsilon) - probs # Should be all 0
abline(h = probs, col = "purple", lty = 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='margeff'> Marginal Effects for Several Categorical Response Models </h2><span id='topic+margeff'></span>

<h3>Description</h3>

<p>Marginal effects for the multinomial logit model and
cumulative logit/probit/... models and
continuation ratio models and
stopping ratio models and
adjacent categories models:
the derivative of the fitted probabilities with respect to
each explanatory variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>margeff(object, subset = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="margeff_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+vglm">vglm</a></code> object,
with one of the following family functions:
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>
or
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="margeff_+3A_subset">subset</code></td>
<td>

<p>Numerical or logical vector, denoting the required observation(s).
Recycling is used if possible.
The default means all observations.
</p>
</td></tr>
<tr><td><code id="margeff_+3A_...">...</code></td>
<td>

<p>further arguments passed into the other methods functions.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the derivative of the fitted probabilities
of the categorical response model
with respect to each explanatory variable.
Formerly one big function, this function now uses S4
dispatch to break up the computations.
</p>

<p>The function <code>margeff()</code> is <em>not</em> generic. However, it
calls the function <code>margeffS4VGAM()</code> which <em>is</em>.
This is based on the class of the <code>VGAMff</code> argument, and
it uses the S4 function <code><a href="methods.html#topic+setMethod">setMethod</a></code> to
correctly dispatch to the required methods function.
The inheritance is given by the <code>vfamily</code> slot of the
<span class="pkg">VGAM</span> family function.
</p>


<h3>Value</h3>

<p>A <code class="reqn">p</code> by <code class="reqn">M+1</code> by <code class="reqn">n</code> array, where <code class="reqn">p</code> is the
number of explanatory variables and the (hopefully) nominal
response has <code class="reqn">M+1</code> levels, and there are <code class="reqn">n</code>
observations.
</p>
<p>In general, if
<code>is.numeric(subset)</code>
and
<code>length(subset) == 1</code> then a
<code class="reqn">p</code> by <code class="reqn">M+1</code> matrix is returned.
</p>


<h3>Warning </h3>

<p>Care is needed in interpretation, e.g., the change is not
universally accurate for a unit change in each explanatory
variable because eventually the &lsquo;new&rsquo; probabilities may become
negative or greater than unity. Also, the &lsquo;new&rsquo; probabilities
will not sum to one.
</p>
<p>This function is not applicable for models with
data-dependent terms such as <code><a href="splines.html#topic+bs">bs</a></code> and
<code><a href="stats.html#topic+poly">poly</a></code>.
Also the function should not be applied to models with any
terms that
have generated more than one column of the LM model matrix,
such as <code><a href="splines.html#topic+bs">bs</a></code> and <code><a href="stats.html#topic+poly">poly</a></code>.
For such try using numerical methods such as finite-differences.
The <code>formula</code> in <code>object</code> should comprise of simple terms
of the form <code> ~ x2 + x3 + x4</code>, etc.
</p>
<p>Some numerical problems may occur if the fitted values are
close to 0 or 1 for the
<code><a href="#topic+cratio">cratio</a></code> and
<code><a href="#topic+sratio">sratio</a></code> models.
Models with offsets may result in an incorrect answer.
</p>


<h3>Note</h3>

<p>For <code><a href="#topic+multinomial">multinomial</a></code>
this function should handle any value of <code>refLevel</code> and also
any constraint matrices.
However, it does not currently handle
the <code>xij</code> or <code>form2</code> arguments,
nor <code><a href="#topic+vgam">vgam</a></code> objects.
</p>

<p>If marginal effects are to be computed for some values not
equal to those used in the training set, then
the <code>@x</code> and the <code>@predictors</code> slots both need to be
assigned. See Example 3 below.
</p>






<p>Some other limitations are imposed, e.g.,
for <code><a href="#topic+acat">acat</a></code> models
only a <code><a href="#topic+loglink">loglink</a></code> link is allowed.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee,
with some help and motivation from Stasha Rmandic.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+propodds">propodds</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Not a good example for multinomial() since the response is ordinal!!
ii &lt;- 3; hh &lt;- 1/100
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, multinomial, pneumo)
fit &lt;- vglm(cbind(normal, mild, severe) ~ let,
            cumulative(reverse = TRUE,  parallel = TRUE),
            data = pneumo)
fitted(fit)[ii, ]

mynewdata &lt;- with(pneumo, data.frame(let = let[ii] + hh))
(newp &lt;- predict(fit, newdata = mynewdata, type = "response"))

# Compare the difference. Should be the same as hh --&gt; 0.
round((newp-fitted(fit)[ii, ]) / hh, 3)  # Finite-diff approxn
round(margeff(fit, subset = ii)["let",], 3)

# Other examples
round(margeff(fit), 3)
round(margeff(fit, subset = 2)["let",], 3)
round(margeff(fit, subset = c(FALSE, TRUE))["let",,], 3)  # Recycling
round(margeff(fit, subset = c(2, 4, 6, 8))["let",,], 3)

# Example 3; margeffs at a new value
mynewdata2a &lt;- data.frame(let = 2)  # New value
mynewdata2b &lt;- data.frame(let = 2 + hh)  # For finite-diff approxn
(neweta2 &lt;- predict(fit, newdata = mynewdata2a))
fit@x[1, ] &lt;- c(1, unlist(mynewdata2a))
fit@predictors[1, ] &lt;- neweta2  # Needed
max(abs(margeff(fit, subset = 1)["let", ] - (
        predict(fit, newdata = mynewdata2b, type = "response") -
        predict(fit, newdata = mynewdata2a, type = "response")) / hh
))  # Should be 0
</code></pre>

<hr>
<h2 id='marital.nz'>
New Zealand Marital Data
</h2><span id='topic+marital.nz'></span>

<h3>Description</h3>

<p>Some marital data mainly from a large NZ company collected in the
early 1990s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(marital.nz)</code></pre>


<h3>Format</h3>

<p>A data frame with 6053 observations on the following 3 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>a numeric vector, age in years</p>
</dd>
<dt><code>ethnicity</code></dt><dd><p>a factor with levels <code>European</code>
<code>Maori</code> <code>Other</code> <code>Polynesian</code>.
Only Europeans are included in the data set.
</p>
</dd>
<dt><code>mstatus</code></dt><dd><p>a factor with levels
<code>Divorced/Separated</code>, <code>Married/Partnered</code>,
<code>Single</code>, <code>Widowed</code>.
</p>
</dd> </dl>



<h3>Details</h3>

<p>This is a subset of a data set collected from a
self-administered questionnaire administered in a large
New Zealand workforce observational study conducted
during 1992&ndash;3. The data were augmented by a second study
consisting of retirees. The data can be considered a
reasonable representation of the white male New Zealand
population in the early 1990s.
</p>


<h3>Source</h3>

<p>Clinical Trials Research Unit, University of Auckland, New Zealand.
</p>


<h3>References</h3>

<p>See <code><a href="#topic+bmi.nz">bmi.nz</a></code> and <code><a href="#topic+chest.nz">chest.nz</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(marital.nz)
</code></pre>

<hr>
<h2 id='Max'> Maximums </h2><span id='topic+Max'></span>

<h3>Description</h3>

<p>Generic function for the <em>maximums</em> (maxima) of a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Max(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Max_+3A_object">object</code></td>
<td>
<p> An object for which the computation or
extraction of
a maximum (or maximums) is meaningful.
</p>
</td></tr>
<tr><td><code id="Max_+3A_...">...</code></td>
<td>
<p> Other arguments fed into the specific
methods function of the model. Sometimes they are fed
into the methods function for <code><a href="#topic+Coef">Coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Different models can define a maximum in different ways.
Many models have no such notion or definition.
</p>
<p>Maximums occur in quadratic and additive ordination,
e.g., CQO or CAO.
For these models the maximum is the fitted value at the
optimum. For quadratic ordination models there is a formula
for the optimum but for additive ordination models the
optimum must be searched for numerically. If it occurs
on the boundary, then the optimum is undefined. For
a valid optimum, the fitted value at the optimum is the maximum.
</p>



<h3>Value</h3>

<p>The value returned depends specifically on the methods
function invoked.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code>Max.qrrvglm</code>,
<code><a href="#topic+Tol">Tol</a></code>,
<code><a href="#topic+Opt">Opt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(111)  # This leads to the global solution
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Standardized environmental vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          poissonff, Bestof = 2, data = hspider, Crow1positive = FALSE)
Max(p1)

index &lt;- 1:ncol(depvar(p1))
persp(p1, col = index, las = 1, llwd = 2)
abline(h = Max(p1), lty = 2, col = index)

## End(Not run)
</code></pre>

<hr>
<h2 id='maxwell'> Maxwell Regression Family Function </h2><span id='topic+maxwell'></span>

<h3>Description</h3>

<p>Estimating the parameter of the Maxwell  distribution by
maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxwell(link = "loglink", zero = NULL, parallel = FALSE,
        type.fitted = c("mean", "percentiles", "Qlink"),
        percentiles = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maxwell_+3A_link">link</code></td>
<td>

<p>Parameter link function applied to <code class="reqn">a</code>,
which is called the parameter <code>rate</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices and information;
a log link is the default because the parameter is positive.
More information is at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="maxwell_+3A_zero">zero</code>, <code id="maxwell_+3A_parallel">parallel</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="maxwell_+3A_type.fitted">type.fitted</code>, <code id="maxwell_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Using <code>"Qlink"</code> is for quantile-links in <span class="pkg">VGAMextra</span>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Maxwell distribution, which is used in the area of
thermodynamics,
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y;a) = \sqrt{2/\pi} a^{3/2} y^2 \exp(-0.5 a y^2)</code>
</p>

<p>for <code class="reqn">y&gt;0</code> and <code class="reqn">a&gt;0</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\sqrt{8 / (a \pi)}</code>
(returned as the fitted values), and its variance is
<code class="reqn">(3\pi - 8)/(\pi a)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Fisher-scoring and Newton-Raphson are the same here.
A related distribution is the Rayleigh distribution.
This <span class="pkg">VGAM</span> family function handles multiple responses.
This <span class="pkg">VGAM</span> family function can be mimicked by
<code>poisson.points(ostatistic = 1.5, dimension = 2)</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>von Seggern, D. H. (1993).
<em>CRC Standard Curves and Surfaces</em>,
Boca Raton, FL, USA: CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Maxwell">Maxwell</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="#topic+poisson.points">poisson.points</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mdata &lt;- data.frame(y = rmaxwell(1000, rate = exp(2)))
fit &lt;- vglm(y ~ 1, maxwell, mdata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='Maxwell'>The Maxwell Distribution</h2><span id='topic+Maxwell'></span><span id='topic+dmaxwell'></span><span id='topic+pmaxwell'></span><span id='topic+qmaxwell'></span><span id='topic+rmaxwell'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function and random generation
for the Maxwell distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmaxwell(x, rate, log = FALSE)
pmaxwell(q, rate, lower.tail = TRUE, log.p = FALSE)
qmaxwell(p, rate, lower.tail = TRUE, log.p = FALSE)
rmaxwell(n, rate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Maxwell_+3A_x">x</code>, <code id="Maxwell_+3A_q">q</code>, <code id="Maxwell_+3A_p">p</code>, <code id="Maxwell_+3A_n">n</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+Uniform">Uniform</a></code>.
</p>
</td></tr>
<tr><td><code id="Maxwell_+3A_rate">rate</code></td>
<td>
<p>the (rate) parameter.</p>
</td></tr>
<tr><td><code id="Maxwell_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the
density is returned.
</p>
</td></tr>
<tr><td><code id="Maxwell_+3A_lower.tail">lower.tail</code>, <code id="Maxwell_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+maxwell">maxwell</a></code>, the <span class="pkg">VGAM</span> family function for
estimating the (rate) parameter <code class="reqn">a</code> by maximum likelihood
estimation, for the formula of the probability density function.
</p>


<h3>Value</h3>

<p><code>dmaxwell</code> gives the density,
<code>pmaxwell</code> gives the distribution function,
<code>qmaxwell</code> gives the quantile function, and
<code>rmaxwell</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Maxwell distribution is related to the Rayleigh distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Balakrishnan, N. and Nevzorov, V. B. (2003).
<em>A Primer on Statistical Distributions</em>.
Hoboken, New Jersey: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+maxwell">maxwell</a></code>,
<code><a href="#topic+Rayleigh">Rayleigh</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  rate &lt;- 3; x &lt;- seq(-0.5, 3, length = 100)
plot(x, dmaxwell(x, rate = rate), type = "l", col = "blue",
     main = "Blue is density, orange is CDF", ylab = "", las = 1,
     sub = "Purple lines are the 10,20,...,90 percentiles")
abline(h = 0, col = "blue", lty = 2)
lines(x, pmaxwell(x, rate = rate), type = "l", col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qmaxwell(probs, rate = rate)
lines(Q, dmaxwell(Q, rate), col = "purple", lty = 3, type = "h")
lines(Q, pmaxwell(Q, rate), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(pmaxwell(Q, rate) - probs))  # Should be zero

## End(Not run)
</code></pre>

<hr>
<h2 id='mccullagh89'>McCullagh (1989) Distribution Family Function</h2><span id='topic+mccullagh89'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the McCullagh (1989)
distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mccullagh89(ltheta = "rhobitlink", lnu = logofflink(offset = 0.5),
            itheta = NULL, inu = NULL, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mccullagh89_+3A_ltheta">ltheta</code>, <code id="mccullagh89_+3A_lnu">lnu</code></td>
<td>

<p>Link functions
for the <code class="reqn">\theta</code> and <code class="reqn">\nu</code> parameters.
See <code><a href="#topic+Links">Links</a></code> for general information.
</p>
</td></tr>
<tr><td><code id="mccullagh89_+3A_itheta">itheta</code>, <code id="mccullagh89_+3A_inu">inu</code></td>
<td>

<p>Numeric.
Optional initial values for <code class="reqn">\theta</code> and <code class="reqn">\nu</code>.
The default is to internally compute them.
</p>
</td></tr>
<tr><td><code id="mccullagh89_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The McCullagh (1989) distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;\theta,\nu) =
\frac{ \{ 1-y^2 \}^{\nu-\frac12}}
{ (1-2\theta y + \theta^2)^{\nu} \mbox{Beta}(\nu+\frac12, \frac12)}</code>
</p>

<p>where <code class="reqn">-1 &lt; y &lt; 1</code> and <code class="reqn">-1 &lt; \theta &lt; 1</code>.
This distribution is equation (1) in that paper.
The parameter <code class="reqn">\nu</code> satisfies <code class="reqn">\nu &gt; -1/2</code>,
therefore the default is to use an log-offset link
with offset equal to 0.5, i.e.,
<code class="reqn">\eta_2=\log(\nu+0.5)</code>.
The mean is of <code class="reqn">Y</code> is <code class="reqn">\nu \theta / (1+\nu)</code>,
and these are returned as the fitted values.
</p>
<p>This distribution is related to the Leipnik distribution (see Johnson
et al. (1995)), is related to ultraspherical functions, and under
certain conditions, arises as exit distributions for Brownian motion.
Fisher scoring is implemented here and it uses a diagonal matrix so
the parameters are globally orthogonal in the Fisher information sense.
McCullagh (1989) also states that, to some extent, <code class="reqn">\theta</code>
and <code class="reqn">\nu</code> have the properties of a location parameter and a
precision parameter, respectively.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Convergence may be slow or fail unless the initial values are
reasonably close. If a failure occurs, try assigning the argument
<code>inu</code> and/or <code>itheta</code>.  Figure 1 of McCullagh (1989) gives a
broad range of densities for different values of <code class="reqn">\theta</code> and
<code class="reqn">\nu</code>, and this could be consulted for obtaining reasonable
initial values if all else fails.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. (1989).
Some statistical properties of a family of continuous
univariate distributions.
<em>Journal of the American Statistical Association</em>,
<b>84</b>, 125&ndash;129.
</p>
<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1995).
<em>Continuous Univariate Distributions</em>,
2nd edition,
Volume 2,
New York: Wiley.
(pages 612&ndash;617).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+leipnik">leipnik</a></code>,
<code><a href="#topic+rhobitlink">rhobitlink</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Limit as theta = 0, nu = Inf:
mdata &lt;- data.frame(y = rnorm(1000, sd = 0.2))
fit &lt;- vglm(y ~ 1, mccullagh89, data = mdata, trace = TRUE)
head(fitted(fit))
with(mdata, mean(y))
summary(fit)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='meangaitd'>
Mean of the GAITD Combo Density
</h2><span id='topic+meangaitd'></span>

<h3>Description</h3>

<p>Returns the mean of a 1- or 2-parameter GAITD combo
probability mass function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meangaitd(theta.p, fam = c("pois", "log", "zeta"),
    a.mix = NULL, i.mix = NULL, d.mix = NULL,
    a.mlm = NULL, i.mlm = NULL, d.mlm = NULL,
    truncate = NULL, max.support = Inf,
    pobs.mix = 0, pobs.mlm = 0,
    pstr.mix = 0, pstr.mlm = 0,
    pdip.mix = 0, pdip.mlm = 0, byrow.aid = FALSE,
    theta.a = theta.p, theta.i = theta.p, theta.d = theta.p, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meangaitd_+3A_theta.p">theta.p</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>;
usually of length 1 but may be of length 2.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_fam">fam</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
The default is the first one.
All other choices are listed in that vector.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_a.mix">a.mix</code>, <code id="meangaitd_+3A_i.mix">i.mix</code>, <code id="meangaitd_+3A_a.mlm">a.mlm</code>, <code id="meangaitd_+3A_i.mlm">i.mlm</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_d.mix">d.mix</code>, <code id="meangaitd_+3A_d.mlm">d.mlm</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_truncate">truncate</code>, <code id="meangaitd_+3A_max.support">max.support</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_pobs.mix">pobs.mix</code>, <code id="meangaitd_+3A_pobs.mlm">pobs.mlm</code>, <code id="meangaitd_+3A_byrow.aid">byrow.aid</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_pstr.mix">pstr.mix</code>, <code id="meangaitd_+3A_pstr.mlm">pstr.mlm</code>, <code id="meangaitd_+3A_pdip.mix">pdip.mix</code>, <code id="meangaitd_+3A_pdip.mlm">pdip.mlm</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_theta.a">theta.a</code>, <code id="meangaitd_+3A_theta.i">theta.i</code>, <code id="meangaitd_+3A_theta.d">theta.d</code></td>
<td>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
<tr><td><code id="meangaitd_+3A_...">...</code></td>
<td>

<p>Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns the mean of the PMF of
the GAITD combo model.
Many of its arguments are the same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
More functionality may be added in the future, such as
returning the variance.
</p>


<h3>Value</h3>

<p>The mean.
</p>


<h3>Note</h3>

<p>This utility function may change a lot in the future.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>i.mix &lt;- seq(0, 15, by = 5)
lambda.p &lt;- 10
meangaitd(lambda.p, a.mix = i.mix + 1, i.mix = i.mix,
          max.support = 17, pobs.mix = 0.1, pstr.mix = 0.1)
</code></pre>

<hr>
<h2 id='melbmaxtemp'> Melbourne Daily Maximum Temperatures</h2><span id='topic+melbmaxtemp'></span>

<h3>Description</h3>

<p>Melbourne daily maximum temperatures in degrees Celsius
over the ten-year period 1981&ndash;1990.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(melbmaxtemp)
</code></pre>


<h3>Format</h3>

<p>A vector with 3650 observations.
</p>


<h3>Details</h3>

<p>This is a time series data from Melbourne, Australia.
It is commonly used to give a difficult quantile regression
problem since the data is bimodal.
That is, a hot day is likely to be followed by either an
equally hot day or one much cooler.
However, an independence assumption is typically made.
</p>


<h3>References</h3>

<p>Hyndman, R. J. and Bashtannyk, D. M. and Grunwald, G. K. (1996).
Estimating and visualizing conditional densities.
<em>J. Comput. Graph. Statist.</em>,
<b>5</b>(4),  315&ndash;336.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lms.bcn">lms.bcn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(melbmaxtemp)
## Not run: 
melb &lt;- data.frame(today     = melbmaxtemp[-1],
                   yesterday = melbmaxtemp[-length(melbmaxtemp)])
plot(today ~ yesterday, data = melb,
     xlab = "Yesterday's Max Temperature",
     ylab = "Today's Max Temperature", cex = 1.4, type = "n")
points(today ~ yesterday, melb, pch = 0, cex = 0.50, col = "blue")
abline(a = 0, b = 1, lty = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='meplot'> Mean Excess Plot </h2><span id='topic+meplot'></span><span id='topic+meplot.default'></span><span id='topic+meplot.vlm'></span>

<h3>Description</h3>

<p>Mean excess plot (also known as a mean residual life plot),
a diagnostic plot for the generalized  Pareto distribution (GPD).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meplot(object, ...)
meplot.default(y, main = "Mean Excess Plot",
    xlab = "Threshold", ylab = "Mean Excess", lty = c(2, 1:2),
    conf = 0.95, col = c("blue", "black", "blue"), type = "l", ...)
meplot.vlm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meplot_+3A_y">y</code></td>
<td>
<p> A numerical vector. <code>NA</code>s etc. are not allowed.</p>
</td></tr>
<tr><td><code id="meplot_+3A_main">main</code>, <code id="meplot_+3A_xlab">xlab</code>, <code id="meplot_+3A_ylab">ylab</code></td>
<td>
<p>Character.
Overall title for the plot,
and titles for the x- and y-axes.
</p>
</td></tr>
<tr><td><code id="meplot_+3A_lty">lty</code></td>
<td>
<p>Line type.
The second value is for the mean
excess value, the first and third values are for the envelope
surrounding the confidence interval.
</p>
</td></tr>
<tr><td><code id="meplot_+3A_conf">conf</code></td>
<td>
<p>Confidence level.
The default results in approximate 95 percent confidence
intervals for each mean excess value.
</p>
</td></tr>
<tr><td><code id="meplot_+3A_col">col</code></td>
<td>
<p>Colour of the three lines.
</p>
</td></tr>
<tr><td><code id="meplot_+3A_type">type</code></td>
<td>
<p>Type of plot.
The default means lines are
joined between the mean excesses and also the upper and lower
limits of the confidence intervals.
</p>
</td></tr>
<tr><td><code id="meplot_+3A_object">object</code></td>
<td>

<p>An object that inherits class <code>"vlm"</code>,
usually of class <code><a href="#topic+vglm-class">vglm-class</a></code> or
<code><a href="#topic+vgam-class">vgam-class</a></code>.
</p>
</td></tr>
<tr><td><code id="meplot_+3A_...">...</code></td>
<td>
<p> Graphical argument passed into
<code><a href="graphics.html#topic+plot">plot</a></code>.
See <code><a href="graphics.html#topic+par">par</a></code>
for an exhaustive list.
The arguments <code>xlim</code> and <code>ylim</code> are particularly useful.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">Y</code> has a GPD with scale parameter
<code class="reqn">\sigma</code> and shape parameter <code class="reqn">\xi&lt;1</code>,
and if <code class="reqn">y&gt;0</code>, then
</p>
<p style="text-align: center;"><code class="reqn">E(Y-u|Y&gt;u) = \frac{\sigma+\xi u}{1-\xi}.</code>
</p>

<p>It is a linear function in <code class="reqn">u</code>, the threshold.
Note that <code class="reqn">Y-u</code> is called the <em>excess</em> and
values of <code class="reqn">Y</code> greater than <code class="reqn">u</code> are
called <em>exceedances</em>.
The empirical versions used by these functions is to use
sample means to estimate the left hand side of the equation.
Values of <code class="reqn">u</code> in the plot are the values of <code class="reqn">y</code> itself.
If the plot is roughly a straight line then the GPD is a good
fit; this plot can be used to select an appropriate threshold
value. See <code><a href="#topic+gpd">gpd</a></code> for more details.
If the plot is flat then the data may be exponential,
and if it is curved then it may be Weibull or gamma.
There is often a lot of variance/fluctuation at the RHS of the
plot due to fewer observations.
</p>
<p>The function <code>meplot</code> is generic, and
<code>meplot.default</code> and <code>meplot.vlm</code> are some
methods functions for mean excess plots.
</p>


<h3>Value</h3>

<p>A list is returned invisibly with the following components.
</p>
<table>
<tr><td><code>threshold</code></td>
<td>
<p>The x axis values.
</p>
</td></tr>
<tr><td><code>meanExcess</code></td>
<td>
<p>The y axis values.
Each value is a sample mean minus a value <code class="reqn">u</code>.
</p>
</td></tr>
<tr><td><code>plusminus</code></td>
<td>
<p>The amount which is added or subtracted
from the mean excess to give the confidence interval.
The last value is a <code>NA</code> because it is based
on one observation.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function is designed for speed and not accuracy, therefore
huge data sets with extremely large values may cause failure
(the function <code><a href="base.html#topic+cumsum">cumsum</a></code> is used.)  Ties may
not be well handled.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Davison, A. C. and Smith, R. L. (1990).
Models for exceedances over high thresholds (with discussion).
<em>Journal of the Royal Statistical Society, Series B,
Methodological</em>,
<b>52</b>, 393&ndash;442.
</p>
<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: meplot(with(venice90, sealevel), las = 1) -&gt; ii
names(ii)
abline(h = ii$meanExcess[1], col = "orange", lty = "dashed")

par(mfrow = c(2, 2))
for (ii in 1:4)
  meplot(rgpd(1000), col = c("orange", "blue", "orange"))

## End(Not run)
</code></pre>

<hr>
<h2 id='micmen'> Michaelis-Menten Model </h2><span id='topic+micmen'></span>

<h3>Description</h3>

<p>Fits a Michaelis-Menten nonlinear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>micmen(rpar = 0.001, divisor = 10, init1 = NULL, init2 = NULL,
       imethod = 1, oim = TRUE, link1 = "identitylink",
       link2 = "identitylink", firstDeriv = c("nsimEIM", "rpar"),
       probs.x = c(0.15, 0.85), nsimEIM = 500, dispersion = 0,
       zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="micmen_+3A_rpar">rpar</code></td>
<td>

<p>Numeric. Initial positive ridge parameter.
This is used to create
positive-definite weight matrices.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_divisor">divisor</code></td>
<td>

<p>Numerical. The divisor used to divide the
ridge parameter at each
iteration until it is very small but still positive.
The value of
<code>divisor</code> should be greater than one.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_init1">init1</code>, <code id="micmen_+3A_init2">init2</code></td>
<td>

<p>Numerical.
Optional initial value for the first and second parameters,
respectively.  The default is to use a self-starting value.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_link1">link1</code>, <code id="micmen_+3A_link2">link2</code></td>
<td>

<p>Parameter link function applied to the first and second
parameters, respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_dispersion">dispersion</code></td>
<td>

<p>Numerical. Dispersion parameter.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_firstderiv">firstDeriv</code></td>
<td>

<p>Character. Algorithm for computing the first derivatives and
working weights.
The first is the default.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_imethod">imethod</code>, <code id="micmen_+3A_probs.x">probs.x</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_nsimeim">nsimEIM</code>, <code id="micmen_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="micmen_+3A_oim">oim</code></td>
<td>

<p>Use the OIM?
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Michaelis-Menten model is given by
</p>
<p style="text-align: center;"><code class="reqn">E(Y_i) = (\theta_1 u_i) / (\theta_2 + u_i)</code>
</p>

<p>where <code class="reqn">\theta_1</code> and <code class="reqn">\theta_2</code>
are the two parameters.
</p>
<p>The relationship between
iteratively reweighted least squares and the
Gauss-Newton algorithm is given in Wedderburn (1974).
However, the
algorithm used by this family function is different.
Details are
given at the Author's web site.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This function is not (nor could ever be) entirely reliable.
Plotting the fitted function and monitoring
convergence is recommended.
</p>


<h3>Note</h3>

<p>The regressor values <code class="reqn">u_i</code> are inputted as the RHS of
the <code>form2</code> argument.
It should just be a simple term; no smart prediction is used.
It should just a single vector, therefore omit
the intercept term.
The LHS of the formula <code>form2</code> is ignored.
</p>
<p>To predict the response at new values
of <code class="reqn">u_i</code> one must
assign the <code>@extra$Xm2</code> slot in the fitted
object these values,
e.g., see the example below.
</p>
<p>Numerical problems may occur. If so, try setting
some initial values
for the parameters. In the future, several
self-starting initial
values will be implemented.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Seber, G. A. F. and Wild, C. J. (1989).
<em>Nonlinear Regression</em>,
New York: Wiley.
</p>
<p>Wedderburn, R. W. M. (1974).
Quasi-likelihood functions, generalized linear models,
and the Gauss-Newton method.
<em>Biometrika</em>,
<b>61</b>, 439&ndash;447.
</p>
<p>Bates, D. M. and Watts, D. G. (1988).
<em>Nonlinear Regression Analysis and Its Applications</em>,
New York: Wiley.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+enzyme">enzyme</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>mfit &lt;- vglm(velocity ~ 1, micmen, data = enzyme, trace = TRUE,
             crit = "coef", form2 = ~ conc - 1)
summary(mfit)

## Not run: 
plot(velocity ~ conc, enzyme, xlab = "concentration", las = 1,
     col = "blue",
     main = "Michaelis-Menten equation for the enzyme data",
     ylim = c(0, max(velocity)), xlim = c(0, max(conc)))
points(fitted(mfit) ~ conc, enzyme, col = 2, pch = "+", cex = 2)

# This predicts the response at a finer grid:
newenzyme &lt;- data.frame(conc = seq(0, max(with(enzyme, conc)),
      len = 200))
mfit@extra$Xm2 &lt;- newenzyme$conc # This is needed for prediction
lines(predict(mfit, newenzyme, "response") ~ conc, newenzyme,
      col = "red") 
## End(Not run)
</code></pre>

<hr>
<h2 id='mills.ratio'> Mills Ratio </h2><span id='topic+mills.ratio'></span><span id='topic+mills.ratio2'></span>

<h3>Description</h3>

<p>Computes the Mills ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mills.ratio(x)
mills.ratio2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mills.ratio_+3A_x">x</code></td>
<td>

<p>Numeric (real).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mills ratio here is <code>dnorm(x) / pnorm(x)</code>
(some use <code>(1 - pnorm(x)) / dnorm(x)</code>).
Some care is needed as <code>x</code> approaches <code>-Inf</code>;
when <code class="reqn">x</code> is very negative then its value approaches <code class="reqn">-x</code>.
</p>


<h3>Value</h3>

<p><code>mills.ratio</code> returns the Mills ratio, and
<code>mills.ratio2</code> returns <code>dnorm(x) * dnorm(x) / pnorm(x)</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Mills, J. P. (1926).
Table of the ratio: area to bounding ordinate, for any portion
of normal curve.
<em>Biometrika</em>.
<b>18</b>(3/4),
395&ndash;400.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Normal">Normal</a></code>,
<code><a href="#topic+tobit">tobit</a></code>,
<code><a href="#topic+cens.poisson">cens.poisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
curve(mills.ratio, -5, 5, col = "orange", las = 1)
curve(mills.ratio, -5, 5, col = "orange", las = 1, log = "y")

## End(Not run)
</code></pre>

<hr>
<h2 id='mix2exp'> Mixture of Two Exponential Distributions </h2><span id='topic+mix2exp'></span>

<h3>Description</h3>

<p>Estimates the three parameters of a mixture of two exponential
distributions by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix2exp(lphi = "logitlink", llambda = "loglink", iphi = 0.5,
    il1 = NULL, il2 = NULL, qmu = c(0.8, 0.2), nsimEIM = 100,
    zero = "phi")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mix2exp_+3A_lphi">lphi</code>, <code id="mix2exp_+3A_llambda">llambda</code></td>
<td>

<p>Link functions for the parameters <code class="reqn">\phi</code>
and <code class="reqn">\lambda</code>. The latter is the rate parameter
and note that the mean of an ordinary exponential distribution is
<code class="reqn">1 / \lambda</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="mix2exp_+3A_iphi">iphi</code>, <code id="mix2exp_+3A_il1">il1</code>, <code id="mix2exp_+3A_il2">il2</code></td>
<td>

<p>Initial value for <code class="reqn">\phi</code>, and
optional initial value for <code class="reqn">\lambda_1</code> and
<code class="reqn">\lambda_2</code>.
The last two have values that must be positive.
The default is to compute initial values internally using
the argument <code>qmu</code>.
</p>
</td></tr>
<tr><td><code id="mix2exp_+3A_qmu">qmu</code></td>
<td>

<p>Vector with two values giving the probabilities relating to the
sample quantiles for obtaining initial values for
<code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code>.  The two
values are fed in as the <code>probs</code> argument into
<code><a href="stats.html#topic+quantile">quantile</a></code>.
</p>
</td></tr>
<tr><td><code id="mix2exp_+3A_nsimeim">nsimEIM</code>, <code id="mix2exp_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function can be loosely written as
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \phi\,Exponential(\lambda_1) +
              (1-\phi)\,Exponential(\lambda_2)</code>
</p>

<p>where <code class="reqn">\phi</code> is the probability an observation belongs
to the first group, and <code class="reqn">y&gt;0</code>.
The parameter <code class="reqn">\phi</code> satisfies
<code class="reqn">0 &lt; \phi &lt; 1</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\phi / \lambda_1 + (1-\phi) / \lambda_2</code>
and this is returned as the fitted values.
By default, the three linear/additive predictors are
<code class="reqn">(logit(\phi), \log(\lambda_1), \log(\lambda_2))^T</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This <span class="pkg">VGAM</span> family function requires care for a successful
application.
In particular, good initial values are required because
of the presence of local solutions. Therefore running
this function with several different combinations of
arguments such as <code>iphi</code>, <code>il1</code>, <code>il2</code>,
<code>qmu</code> is highly recommended. Graphical methods such
as <code><a href="graphics.html#topic+hist">hist</a></code> can be used as an aid.
</p>
<p>This <span class="pkg">VGAM</span> family function is experimental and
should be used with care.
</p>


<h3>Note</h3>

<p>Fitting this model successfully to data can be
difficult due to local solutions, uniqueness problems
and ill-conditioned data. It pays to fit the model
several times with different initial values and check
that the best fit looks reasonable. Plotting the
results is recommended. This function works better as
<code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code>
become more different. The default control argument
<code>trace = TRUE</code> is to encourage monitoring convergence.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Exponential">rexp</a></code>,
<code><a href="#topic+exponential">exponential</a></code>,
<code><a href="#topic+mix2poisson">mix2poisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  lambda1 &lt;- exp(1); lambda2 &lt;- exp(3)
(phi &lt;- logitlink(-1, inverse = TRUE))
mdata &lt;- data.frame(y1 = rexp(nn &lt;- 1000, lambda1))
mdata &lt;- transform(mdata, y2 = rexp(nn, lambda2))
mdata &lt;- transform(mdata, Y  = ifelse(runif(nn) &lt; phi, y1, y2))
fit &lt;- vglm(Y ~ 1, mix2exp, data = mdata, trace = TRUE)
coef(fit, matrix = TRUE)

# Compare the results with the truth
round(rbind('Estimated' = Coef(fit),
            'Truth' = c(phi, lambda1, lambda2)), digits = 2)

with(mdata, hist(Y, prob = TRUE, main = "Orange=estimate, blue=truth"))
abline(v = 1 / Coef(fit)[c(2, 3)],  lty = 2, col = "orange", lwd = 2)
abline(v = 1 / c(lambda1, lambda2), lty = 2, col = "blue", lwd = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='mix2normal'> Mixture of Two Univariate Normal Distributions </h2><span id='topic+mix2normal'></span>

<h3>Description</h3>

<p>Estimates the five parameters of a mixture of two univariate
normal distributions by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix2normal(lphi = "logitlink", lmu = "identitylink", lsd =
   "loglink", iphi = 0.5, imu1 = NULL, imu2 = NULL, isd1 =
   NULL, isd2 = NULL, qmu = c(0.2, 0.8), eq.sd = TRUE,
   nsimEIM = 100, zero = "phi")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mix2normal_+3A_lphi">lphi</code>, <code id="mix2normal_+3A_lmu">lmu</code>, <code id="mix2normal_+3A_lsd">lsd</code></td>
<td>

<p>Link functions for the parameters <code class="reqn">\phi</code>,
<code class="reqn">\mu</code>, and
<code class="reqn">\sigma</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="mix2normal_+3A_iphi">iphi</code></td>
<td>

<p>Initial value for <code class="reqn">\phi</code>, whose value must lie
between 0 and 1.
</p>
</td></tr>
<tr><td><code id="mix2normal_+3A_imu1">imu1</code>, <code id="mix2normal_+3A_imu2">imu2</code></td>
<td>

<p>Optional initial value for <code class="reqn">\mu_1</code> and
<code class="reqn">\mu_2</code>.  The default is to compute initial values
internally using the argument <code>qmu</code>.
</p>
</td></tr>
<tr><td><code id="mix2normal_+3A_isd1">isd1</code>, <code id="mix2normal_+3A_isd2">isd2</code></td>
<td>

<p>Optional initial value for <code class="reqn">\sigma_1</code> and
<code class="reqn">\sigma_2</code>.  The default is to compute initial values
internally based on the argument <code>qmu</code>.  Currently these
are not great, therefore using these arguments where practical
is a good idea.
</p>
</td></tr>
<tr><td><code id="mix2normal_+3A_qmu">qmu</code></td>
<td>

<p>Vector with two values giving the probabilities relating
to the sample quantiles for obtaining initial values for
<code class="reqn">\mu_1</code> and <code class="reqn">\mu_2</code>.  The two values are fed in
as the <code>probs</code> argument into <code><a href="stats.html#topic+quantile">quantile</a></code>.
</p>
</td></tr>
<tr><td><code id="mix2normal_+3A_eq.sd">eq.sd</code></td>
<td>

<p>Logical indicating whether the two standard deviations should
be constrained to be equal. If <code>TRUE</code> then the appropriate
constraint matrices will be used.
</p>
</td></tr>
<tr><td><code id="mix2normal_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="mix2normal_+3A_zero">zero</code></td>
<td>

<p>May be an integer vector
specifying which linear/additive predictors are modelled as
intercept-only.  If given, the value or values can be from the
set <code class="reqn">\{1,2,\ldots,5\}</code>.
The default is the first one only, meaning <code class="reqn">\phi</code>
is a single parameter even when there are explanatory variables.
Set <code>zero = NULL</code> to model all linear/additive
predictors as functions of the explanatory variables.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function can be loosely written as
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \phi \, N(\mu_1,\sigma_1) +
        (1-\phi) \, N(\mu_2, \sigma_2)</code>
</p>

<p>where <code class="reqn">\phi</code> is the probability an observation belongs
to the first group.
The parameters <code class="reqn">\mu_1</code> and <code class="reqn">\mu_2</code> are the
means, and <code class="reqn">\sigma_1</code> and <code class="reqn">\sigma_2</code> are the
standard deviations.  The parameter <code class="reqn">\phi</code> satisfies
<code class="reqn">0 &lt; \phi &lt; 1</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\phi \mu_1 + (1-\phi) \mu_2</code>
and this is returned as the fitted values.
By default, the five linear/additive predictors are
<code class="reqn">(logit(\phi),\mu_1,\log(\sigma_1),\mu_2,\log(\sigma_2))^T</code>.
If <code>eq.sd = TRUE</code> then <code class="reqn">\sigma_1 = \sigma_2</code>
is enforced.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Numerical problems can occur and
half-stepping is not uncommon.
If failure to converge occurs, try inputting better initial
values,
e.g., by using <code>iphi</code>,
<code>qmu</code>,
<code>imu1</code>,
<code>imu2</code>,
<code>isd1</code>,
<code>isd2</code>,
etc.
</p>






<p>This <span class="pkg">VGAM</span> family function is experimental and
should be used with care.
</p>


<h3>Note</h3>

<p>Fitting this model successfully to data can be difficult due
to numerical problems and ill-conditioned data.  It pays to
fit the model several times with different initial values and
check that the best fit looks reasonable. Plotting the results
is recommended.  This function works better as <code class="reqn">\mu_1</code>
and <code class="reqn">\mu_2</code> become more different.
</p>
<p>Convergence can be slow, especially when the two component
distributions are not well separated.
The default control argument <code>trace = TRUE</code> is to encourage
monitoring convergence.
Having <code>eq.sd = TRUE</code> often makes the overall optimization
problem easier.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>McLachlan, G. J. and Peel, D. (2000).
<em>Finite Mixture Models</em>.
New York: Wiley.
</p>
<p>Everitt, B. S. and Hand, D. J. (1981).
<em>Finite Mixture Distributions</em>.
London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="stats.html#topic+Normal">Normal</a></code>,
<code><a href="#topic+mix2poisson">mix2poisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  mu1 &lt;-  99; mu2 &lt;- 150; nn &lt;- 1000
sd1 &lt;- sd2 &lt;- exp(3)
(phi &lt;- logitlink(-1, inverse = TRUE))
rrn &lt;- runif(nn)
mdata &lt;- data.frame(y = ifelse(rrn &lt; phi, rnorm(nn, mu1, sd1),
                                          rnorm(nn, mu2, sd2)))
fit &lt;- vglm(y ~ 1, mix2normal(eq.sd = TRUE), data = mdata)

# Compare the results
cfit &lt;- coef(fit)
round(rbind('Estimated' = c(logitlink(cfit[1], inverse = TRUE),
            cfit[2], exp(cfit[3]), cfit[4]),
            'Truth' = c(phi, mu1, sd1, mu2)), digits = 2)

# Plot the results
xx &lt;- with(mdata, seq(min(y), max(y), len = 200))
plot(xx, (1-phi) * dnorm(xx, mu2, sd2), type = "l", xlab = "y",
     main = "red = estimate, blue = truth",
     col = "blue", ylab = "Density")
phi.est &lt;- logitlink(coef(fit)[1], inverse = TRUE)
sd.est &lt;- exp(coef(fit)[3])
lines(xx, phi*dnorm(xx, mu1, sd1), col = "blue")
lines(xx, phi.est * dnorm(xx, Coef(fit)[2], sd.est), col = "red")
lines(xx, (1-phi.est)*dnorm(xx, Coef(fit)[4], sd.est), col="red")
abline(v = Coef(fit)[c(2,4)], lty = 2, col = "red")
abline(v = c(mu1, mu2), lty = 2, col = "blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='mix2poisson'> Mixture of Two Poisson Distributions </h2><span id='topic+mix2poisson'></span>

<h3>Description</h3>

<p>Estimates the three parameters of a mixture of two Poisson
distributions by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix2poisson(lphi = "logitlink", llambda = "loglink",
            iphi = 0.5, il1 = NULL, il2 = NULL,
            qmu = c(0.2, 0.8), nsimEIM = 100, zero = "phi")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mix2poisson_+3A_lphi">lphi</code>, <code id="mix2poisson_+3A_llambda">llambda</code></td>
<td>

<p>Link functions for the parameter <code class="reqn">\phi</code> and
<code class="reqn">\lambda</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>






<tr><td><code id="mix2poisson_+3A_iphi">iphi</code></td>
<td>

<p>Initial value for <code class="reqn">\phi</code>, whose value must lie
between 0 and 1.
</p>
</td></tr>
<tr><td><code id="mix2poisson_+3A_il1">il1</code>, <code id="mix2poisson_+3A_il2">il2</code></td>
<td>

<p>Optional initial value for <code class="reqn">\lambda_1</code> and
<code class="reqn">\lambda_2</code>. These values must be positive.
The default is to compute initial values internally using
the argument <code>qmu</code>.


</p>
</td></tr>
<tr><td><code id="mix2poisson_+3A_qmu">qmu</code></td>
<td>

<p>Vector with two values giving the probabilities relating
to the sample quantiles for obtaining initial values for
<code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code>.
The two values are fed in as the <code>probs</code> argument into
<code><a href="stats.html#topic+quantile">quantile</a></code>.
</p>
</td></tr>
<tr><td><code id="mix2poisson_+3A_nsimeim">nsimEIM</code>, <code id="mix2poisson_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function can be loosely written as
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) = \phi \, Poisson(\lambda_1) +
        (1-\phi) \, Poisson(\lambda_2)</code>
</p>

<p>where <code class="reqn">\phi</code> is the probability an observation belongs
to the first group, and <code class="reqn">y=0,1,2,\ldots</code>.
The parameter <code class="reqn">\phi</code>
satisfies <code class="reqn">0 &lt; \phi &lt; 1</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\phi\lambda_1+(1-\phi)\lambda_2</code>
and this is returned as the fitted values.
By default, the three linear/additive predictors are
<code class="reqn">(logit(\phi), \log(\lambda_1), \log(\lambda_2))^T</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This <span class="pkg">VGAM</span> family function requires care for a successful
application.
In particular, good initial values are required because
of the presence of local solutions. Therefore running
this function with several different combinations of
arguments such as <code>iphi</code>, <code>il1</code>, <code>il2</code>,
<code>qmu</code> is highly recommended. Graphical methods such as
<code><a href="graphics.html#topic+hist">hist</a></code> can be used as an aid.
</p>
<p>With grouped data (i.e., using the <code>weights</code> argument)
one has to use a large value of <code>nsimEIM</code>;
see the example below.
</p>
<p>This <span class="pkg">VGAM</span> family function is experimental and
should be used with care.
</p>


<h3>Note</h3>

<p>The response must be integer-valued since
<code><a href="stats.html#topic+dpois">dpois</a></code> is invoked.
</p>
<p>Fitting this model successfully to data can be difficult
due to local solutions and ill-conditioned data. It pays to
fit the model several times with different initial values,
and check that the best fit looks reasonable. Plotting
the results is recommended. This function works better as
<code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code> become
more different.  The default control argument <code>trace =
  TRUE</code> is to encourage monitoring convergence.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+Poisson">rpois</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+mix2normal">mix2normal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Example 1: simulated data
nn &lt;- 1000
mu1 &lt;- exp(2.5)  # Also known as lambda1
mu2 &lt;- exp(3)
(phi &lt;- logitlink(-0.5, inverse = TRUE))
mdata &lt;- data.frame(y = rpois(nn, ifelse(runif(nn) &lt; phi, mu1, mu2)))
mfit &lt;- vglm(y ~ 1, mix2poisson, data = mdata)
coef(mfit, matrix = TRUE)

# Compare the results with the truth
round(rbind('Estimated' = Coef(mfit), 'Truth' = c(phi, mu1, mu2)), 2)

ty &lt;- with(mdata, table(y))
plot(names(ty), ty, type = "h", main = "Orange=estimate, blue=truth",
     ylab = "Frequency", xlab = "y")
abline(v = Coef(mfit)[-1], lty = 2, col = "orange", lwd = 2)
abline(v = c(mu1, mu2), lty = 2, col = "blue", lwd = 2)

# Example 2: London Times data (Lange, 1997, p.31)
ltdata1 &lt;- data.frame(deaths = 0:9,
                      freq = c(162,267,271, 185,111,61,27,8,3,1))
ltdata2 &lt;- data.frame(y = with(ltdata1, rep(deaths, freq)))

# Usually this does not work well unless nsimEIM is large
Mfit &lt;- vglm(deaths ~ 1, weight = freq, data = ltdata1,
        mix2poisson(iphi=0.3, il1=1, il2=2.5, nsimEIM=5000))

# This works better in general
Mfit = vglm(y ~ 1, mix2poisson(iphi=0.3, il1=1, il2=2.5), ltdata2)
coef(Mfit, matrix = TRUE)
Coef(Mfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='MNSs'> The MNSs Blood Group System </h2><span id='topic+MNSs'></span>

<h3>Description</h3>

<p>Estimates the three independent parameters of the
the MNSs blood group system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MNSs(link = "logitlink", imS = NULL, ims = NULL, inS = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MNSs_+3A_link">link</code></td>
<td>

<p>Link function applied to the three parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="MNSs_+3A_ims">imS</code>, <code id="MNSs_+3A_ims">ims</code>, <code id="MNSs_+3A_ins">inS</code></td>
<td>

<p>Optional initial value for <code>mS</code>, <code>ms</code>
and <code>nS</code> respectively.
A <code>NULL</code> means they are computed internally.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are three independent
parameters: <code>m_S</code>, <code>m_s</code>, <code>n_S</code>, say, so that
<code>n_s = 1 - m_S - m_s - n_S</code>.
We let the eta vector (transposed) be
<code>(g(m_S), g(m_s), g(n_S))</code> where <code>g</code> is the
link function.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The input can be a 6-column matrix of counts, where the columns are
MS, Ms, MNS, MNs, NS, Ns (in order).
Alternatively, the input can be a 6-column matrix of
proportions (so each row adds to 1) and the <code>weights</code>
argument is used to specify the total number of counts for each row.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Elandt-Johnson, R. C. (1971).
<em>Probability Models and Statistical Methods in Genetics</em>,
New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AA.Aa.aa">AA.Aa.aa</a></code>,
<code><a href="#topic+AB.Ab.aB.ab">AB.Ab.aB.ab</a></code>,
<code><a href="#topic+ABO">ABO</a></code>,
<code><a href="#topic+A1A2A3">A1A2A3</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Order matters only:
y &lt;- cbind(MS = 295, Ms = 107, MNS = 379, MNs = 322, NS = 102, Ns = 214)
fit &lt;- vglm(y ~ 1, MNSs("logitlink", .25, .28, .08), trace = TRUE)
fit &lt;- vglm(y ~ 1, MNSs(link = logitlink), trace = TRUE, crit = "coef")
Coef(fit)
rbind(y, sum(y)*fitted(fit))
sqrt(diag(vcov(fit)))
</code></pre>

<hr>
<h2 id='model.framevlm'>Construct the Model Frame of a VLM Object</h2><span id='topic+model.framevlm'></span>

<h3>Description</h3>

<p>This function returns a <code><a href="base.html#topic+data.frame">data.frame</a></code> with the
variables.  It is applied to an object which inherits from
class <code>"vlm"</code> (e.g., a fitted model of class <code>"vglm"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.framevlm(object, setupsmart = TRUE, wrapupsmart = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.framevlm_+3A_object">object</code></td>
<td>
<p>a model object from the <span class="pkg">VGAM</span> <span class="rlang"><b>R</b></span> package
that inherits from a <em>vector linear model</em> (VLM),
e.g., a model of class <code>"vglm"</code>.</p>
</td></tr>
<tr><td><code id="model.framevlm_+3A_...">...</code></td>
<td>
<p>further arguments such as <code>data</code>,
<code>na.action</code>,
<code>subset</code>.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for more
information on these.
</p>
</td></tr>
<tr><td><code id="model.framevlm_+3A_setupsmart">setupsmart</code>, <code id="model.framevlm_+3A_wrapupsmart">wrapupsmart</code></td>
<td>

<p>Logical.
Arguments to determine whether to use smart prediction.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since <code>object</code> is
an object which inherits from class <code>"vlm"</code> (e.g.,
a fitted model of class <code>"vglm"</code>),
the method will either returned the saved model frame
used when fitting the model (if any, selected by argument
<code>model = TRUE</code>) or pass the call used when fitting on to
the default method.
</p>
<p>This code implements <em>smart prediction</em>
(see <code><a href="#topic+smartpred">smartpred</a></code>).
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> containing the variables used in
the <code>object</code> plus those specified in <code>...</code>.
</p>


<h3>References</h3>

<p>Chambers, J. M. (1992).
<em>Data for models.</em>
Chapter 3 of <em>Statistical Models in S</em>
eds J. M. Chambers and T. J. Hastie, Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.frame">model.frame</a></code>,
<code><a href="#topic+model.matrixvlm">model.matrixvlm</a></code>,
<code><a href="#topic+predictvglm">predictvglm</a></code>,
<code><a href="#topic+smartpred">smartpred</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Illustrates smart prediction
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal,mild, severe) ~ poly(c(scale(let)), 2),
            multinomial, pneumo, trace = TRUE, x = FALSE)
class(fit)

check1 &lt;- head(model.frame(fit))
check1
check2 &lt;- model.frame(fit, data = head(pneumo))
check2
all.equal(unlist(check1), unlist(check2))  # Should be TRUE

q0 &lt;- head(predict(fit))
q1 &lt;- head(predict(fit, newdata = pneumo))
q2 &lt;- predict(fit, newdata = head(pneumo))
all.equal(q0, q1)  # Should be TRUE
all.equal(q1, q2)  # Should be TRUE
</code></pre>

<hr>
<h2 id='model.matrixqrrvglm'>Construct the Model Matrix of a QRR-VGLM Object</h2><span id='topic+model.matrixqrrvglm'></span>

<h3>Description</h3>

<p>Creates a model matrix. Two types can be
returned: a large one (class <code>"vlm"</code> or one that inherits
from this such as <code>"vglm"</code>) or a small one
(such as returned if it were of class <code>"lm"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.matrixqrrvglm(object, type = c("latvar", "lm", "vlm"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.matrixqrrvglm_+3A_object">object</code></td>
<td>
<p>an object of a class <code>"qrrvglm"</code>,
i.e., a <code><a href="#topic+cqo">cqo</a></code> object.
</p>
</td></tr>
<tr><td><code id="model.matrixqrrvglm_+3A_type">type</code></td>
<td>
<p>Type of model (or design) matrix returned.
The first is the default.
The value <code>"latvar"</code> is model matrix mainly comprising
of the latent variable values
(sometimes called the <em>site scores</em>).
The value <code>"lm"</code> is the LM matrix directly
corresponding to the <code>formula</code> argument.
The value <code>"vlm"</code> is the big VLM model matrix <em>given C</em>.
</p>
</td></tr>
<tr><td><code id="model.matrixqrrvglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates one of several design matrices
from <code>object</code>.
For example, this can be a small LM object or a big VLM object.
</p>
<p>When <code>type = "vlm"</code> this function calls <code>fnumat2R()</code>
to construct the big model matrix <em>given C</em>.
That is, the constrained coefficients are assumed known,
so that something like a large Poisson or logistic regression
is set up.
This is because all responses are fitted simultaneously here.
The columns are labelled in the following order and
with the following prefixes:
<code>"A"</code> for the <code class="reqn">A</code> matrix (linear in the latent variables),
<code>"D"</code> for the <code class="reqn">D</code> matrix (quadratic in the latent variables),
<code>"x1."</code> for the <code class="reqn">B1</code> matrix (usually contains
the intercept; see the argument <code>noRRR</code> in
<code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>).
</p>


<h3>Value</h3>

<p>The design matrix <em>after scaling</em>
for a regression model with the specified formula and data.
By <em>after scaling</em>, it is meant that it matches the output
of <code>coef(qrrvglmObject)</code> rather than the original
scaling of the fitted object.
</p>




<h3>See Also</h3>

<p><code><a href="#topic+model.matrixvlm">model.matrixvlm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+vcovqrrvglm">vcovqrrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1); n &lt;- 40; p &lt;- 3; S &lt;- 4; myrank &lt;- 1
mydata &lt;- rcqo(n, p, S, Rank = myrank, es.opt = TRUE, eq.max = TRUE)
(myform &lt;- attr(mydata, "formula"))
mycqo &lt;- cqo(myform, poissonff, data = mydata,
             I.tol = TRUE, Rank = myrank, Bestof = 5)
model.matrix(mycqo, type = "latvar")
model.matrix(mycqo, type = "lm")
model.matrix(mycqo, type = "vlm")

## End(Not run)
</code></pre>

<hr>
<h2 id='model.matrixvlm'>Construct the Design Matrix of a VLM Object</h2><span id='topic+model.matrixvlm'></span>

<h3>Description</h3>

<p>Creates a design matrix. Two types can be
returned: a large one (class <code>"vlm"</code> or one that inherits
from this such as <code>"vglm"</code>) or a small one
(such as returned if it were of class <code>"lm"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.matrixvlm(object, type = c("vlm", "lm", "lm2", "bothlmlm2"),
                linpred.index = NULL, label.it = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.matrixvlm_+3A_object">object</code></td>
<td>
<p>an object of a class that inherits from the
<em>vector linear model</em> (VLM).
</p>
</td></tr>
<tr><td><code id="model.matrixvlm_+3A_type">type</code></td>
<td>
<p>Type of design matrix returned. The first is the default.
The value <code>"vlm"</code> is the VLM model matrix corresponding
to the <code>formula</code> argument.
The value <code>"lm"</code> is the LM model matrix corresponding
to the <code>formula</code> argument.
The value <code>"lm2"</code> is the second (LM) model matrix corresponding
to the <code>form2</code> argument.
The value <code>"bothlmlm2"</code> means both LM and VLM model matrices.
</p>
</td></tr>
<tr><td><code id="model.matrixvlm_+3A_linpred.index">linpred.index</code></td>
<td>

<p>Vector of integers.
The index for a linear/additive predictor,
it must have values from the set <code>1:M</code>.
Also, if <code>length(linpred.index) == 1</code>
then <code>type = "lm"</code> must be assigned,
whereas
if <code>length(linpred.index) &gt; 1</code>
then <code>type = "vlm"</code> must be assigned,
Then it returns a subset of the VLM matrix corresponding to
the <code>linpred.index</code>th linear/additive predictor(s);
this is a LM-type matrix when it is of unit length.
Currently some attributes are returned, but these may
change in value
in the future because of ongoing development work.
</p>

</td></tr>
<tr><td><code id="model.matrixvlm_+3A_label.it">label.it</code></td>
<td>

<p>Logical. Label the row and columns with character names?
If <code>FALSE</code>, time and memory might be saved if
the big model matrix is very large.
The argument is only used when <code>type = "vlm"</code>.
</p>
</td></tr>
<tr><td><code id="model.matrixvlm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
These include <code>data</code> (which
is a data frame created with <code><a href="#topic+model.framevlm">model.framevlm</a></code>),
<code>contrasts.arg</code>, and <code>xlev</code>.
See <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a design matrix from <code>object</code>.
This can be a small LM object or a big VLM object (default).
The latter is constructed from the former and the constraint
matrices.
</p>
<p>This code implements <em>smart prediction</em>
(see <code><a href="#topic+smartpred">smartpred</a></code>).
</p>


<h3>Value</h3>

<p>The design matrix for a regression model with the specified formula
and data.
If <code>type = "bothlmlm2"</code> then a list is returned with components
<code>"X"</code> and <code>"Xm2"</code>.
</p>
<p>Sometimes
(especially if <code>x = TRUE</code> when calling <code><a href="#topic+vglm">vglm</a></code>)
the model matrix has attributes:
<code>"assign"</code> (<code>"lm"</code>-type) and
<code>"vassign"</code> (<code>"vlm"</code>-type) and
<code>"orig.assign.lm"</code> (<code>"lm"</code>-type).
These are used internally a lot for bookkeeping,
especially regarding
the columns of both types of model matrices.
In particular, constraint matrices and variable selection
relies on this information a lot.
The <code>"orig.assign.lm"</code> is the ordinary <code>"assign"</code>
attribute for <code><a href="stats.html#topic+lm">lm</a></code>
and <code><a href="stats.html#topic+glm">glm</a></code> objects.
</p>


<h3>References</h3>





<p>Chambers, J. M. (1992).
<em>Data for models.</em>
Chapter 3 of <em>Statistical Models in S</em>
eds J. M. Chambers and T. J. Hastie, Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.matrix">model.matrix</a></code>,
<code><a href="#topic+model.framevlm">model.framevlm</a></code>,
<code><a href="#topic+predictvglm">predictvglm</a></code>,
<code><a href="#topic+smartpred">smartpred</a></code>,
<code><a href="#topic+constraints.vlm">constraints.vlm</a></code>,
<code><a href="#topic+trim.constraints">trim.constraints</a></code>,
<code><a href="#topic+add1.vglm">add1.vglm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>,
<code><a href="#topic+step4vglm">step4vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (I) Illustrates smart prediction ,,,,,,,,,,,,,,,,,,,,,,,
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~
            sm.poly(c(sm.scale(let)), 2),
            multinomial, data = pneumo, trace = TRUE, x = FALSE)
class(fit)
fit@smart.prediction  # Data-dependent parameters
fit@x # Not saved on the object
model.matrix(fit)
model.matrix(fit, linpred.index = 1, type = "lm")
model.matrix(fit, linpred.index = 2, type = "lm")

(Check1 &lt;- head(model.matrix(fit, type = "lm")))
(Check2 &lt;- model.matrix(fit, data = head(pneumo), type = "lm"))
all.equal(c(Check1), c(Check2))  # Should be TRUE

q0 &lt;- head(predict(fit))
q1 &lt;- head(predict(fit, newdata = pneumo))
q2 &lt;- predict(fit, newdata = head(pneumo))
all.equal(q0, q1)  # Should be TRUE
all.equal(q1, q2)  # Should be TRUE

# (II) Attributes ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let,  # x = TRUE
             multinomial, data = pneumo, trace = TRUE)
fit2@x  # "lm"-type; saved on the object; note the attributes
model.matrix(fit2, type = "lm")  # Note the attributes
model.matrix(fit2, type = "vlm")  # Note the attributes
</code></pre>

<hr>
<h2 id='moffset'>
Matrix Offset
</h2><span id='topic+moffset'></span>

<h3>Description</h3>

<p>Modify a matrix by shifting successive elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moffset(mat, roffset = 0, coffset = 0, postfix = "",
        rprefix = "Row.", cprefix = "Col.")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="moffset_+3A_mat">mat</code></td>
<td>

<p>Data frame or matrix.
This ought to have at least three rows and three columns.
The elements are shifted in the order of <code>c(mat)</code>,
i.e., going down successive columns, as the columns go
from left to right. Wrapping of values is done.
</p>
</td></tr>
<tr><td><code id="moffset_+3A_roffset">roffset</code>, <code id="moffset_+3A_coffset">coffset</code></td>
<td>

<p>Numeric or character.
If numeric, the amount of shift (offset) for each row and column.
The default is no change to <code>mat</code>.
If character, the offset is computed by matching with
the row or column names.
For example, for the <code><a href="#topic+alcoff">alcoff</a></code>,
put <code>roffset = "6"</code> means that we make an effective day's
dataset start from 6:00 am, and this wraps around to
include midnight to 05.59 am on the next day.
</p>
</td></tr>
<tr><td><code id="moffset_+3A_postfix">postfix</code></td>
<td>

<p>Character.
Modified rows and columns are renamed by pasting this argument
to the end of each name.
The default is no change.
</p>
</td></tr>
<tr><td><code id="moffset_+3A_rprefix">rprefix</code>, <code id="moffset_+3A_cprefix">cprefix</code></td>
<td>

<p>Same as <code><a href="#topic+rcim">rcim</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows a matrix to be rearranged so that
element (<code>roffset</code> + 1, <code>coffset</code> + 1)
becomes the (1, 1) element.
The elements are assumed to be ordered in the same way
as the elements of <code>c(mat)</code>,
</p>
<p>This function is applicable to, e.g.,
<code><a href="#topic+alcoff">alcoff</a></code>,
where it is useful to define the <em>effective day</em>
as starting
at some other hour than midnight, e.g., 6.00am.
This is because partying on Friday night continues on into
Saturday morning, therefore it is more interpretable to use
the effective day when considering a daily effect.
</p>
<p>This is a data preprocessing function for <code><a href="#topic+rcim">rcim</a></code>
and <code><a href="#topic+plotrcim0">plotrcim0</a></code>.  The differences between
<code><a href="#topic+Rcim">Rcim</a></code> and <code><a href="#topic+moffset">moffset</a></code> is that
<code><a href="#topic+Rcim">Rcim</a></code> only reorders the level of the
rows and columns
so that the data is shifted but not moved.
That is, a value in one row stays in that row,
and ditto for column.
But in <code><a href="#topic+moffset">moffset</a></code>
values in one column can be moved to a previous column.
See the examples below.
</p>


<h3>Value</h3>

<p>A matrix of the same dimensional as its input.
</p>


<h3>Note</h3>






<p>The input <code>mat</code> should have row names and column names.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee,
Alfian F. Hadi.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rcim">Rcim</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+plotrcim0">plotrcim0</a></code>,
<code><a href="#topic+alcoff">alcoff</a></code>,
<code><a href="#topic+crashi">crashi</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Some day's data is moved to previous day:
moffset(alcoff, 3, 2, "*")
Rcim(alcoff, 3 + 1, 2 + 1)  # Data does not move as much.
alcoff  # Original data
moffset(alcoff, 3, 2, "*") -
Rcim(alcoff, 3+1, 2+1)  # Note the differences

# An 'effective day' data set:
alcoff.e &lt;- moffset(alcoff, roffset = "6", postfix = "*")
fit.o &lt;- rcim(alcoff)    # default baselines are 1st row and col
fit.e &lt;- rcim(alcoff.e)  # default baselines are 1st row and col

## Not run:  par(mfrow = c(2, 2), mar = c(9, 4, 2, 1))
plot(fit.o, rsub = "Not very interpretable",
            csub = "Not very interpretable")
plot(fit.e, rsub = "More interpretable",
            csub = "More interpretable")

## End(Not run)

# Some checking
all.equal(moffset(alcoff), alcoff)  # Should be no change
moffset(alcoff, 1, 1, "*")
moffset(alcoff, 2, 3, "*")
moffset(alcoff, 1, 0, "*")
moffset(alcoff, 0, 1, "*")
moffset(alcoff, "6", "Mon", "*")  # This one is good

# Customise row and column baselines
fit2 &lt;- rcim(Rcim(alcoff.e, rbaseline = "11", cbaseline = "Mon*"))
</code></pre>

<hr>
<h2 id='multilogitlink'> Multi-logit Link Function </h2><span id='topic+multilogitlink'></span>

<h3>Description</h3>

<p>Computes the multilogit transformation, including its inverse
and the first two derivatives.
</p>




<h3>Usage</h3>

<pre><code class='language-R'>multilogitlink(theta, refLevel = "(Last)", M = NULL, whitespace = FALSE,
       bvalue = NULL, inverse = FALSE, deriv = 0, all.derivs = FALSE,
       short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilogitlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="multilogitlink_+3A_reflevel">refLevel</code>, <code id="multilogitlink_+3A_m">M</code>, <code id="multilogitlink_+3A_whitespace">whitespace</code></td>
<td>

<p>See <code><a href="#topic+multinomial">multinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="multilogitlink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="multilogitlink_+3A_all.derivs">all.derivs</code></td>
<td>

<p>Logical.
This is currently experimental only.
</p>






</td></tr>








<tr><td><code id="multilogitlink_+3A_inverse">inverse</code>, <code id="multilogitlink_+3A_deriv">deriv</code>, <code id="multilogitlink_+3A_short">short</code>, <code id="multilogitlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>multilogitlink()</code> link function is a generalization of the
<code><a href="#topic+logitlink">logitlink</a></code> link to <code class="reqn">M</code> levels/classes.  It forms the
basis of the <code><a href="#topic+multinomial">multinomial</a></code> logit model.  It is sometimes
called the <em>multi-logit</em> link or the <em>multinomial logit</em>
link; some people use <em>softmax</em> too.  When its inverse function
is computed it returns values which are positive and add to unity.
</p>





<h3>Value</h3>

<p>For <code>multilogitlink</code> with <code>deriv = 0</code>,
the multilogit of <code>theta</code>,
i.e.,
<code>log(theta[, j]/theta[, M+1])</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>exp(theta[, j])/(1+rowSums(exp(theta)))</code>.



</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of
<code>theta</code> if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>
<p>Here, all logarithms are natural logarithms, i.e., to base <em>e</em>.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is
close to 1 or 0 (for <code>multilogitlink</code>).
One way of overcoming this is to use, e.g., <code>bvalue</code>.
Currently <code>care.exp()</code> is used to avoid <code>NA</code>s being
returned if the probability is too close to 1.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+normal.vcm">normal.vcm</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let,  # For illustration only!
            multinomial, trace = TRUE, data = pneumo)
fitted(fit)
predict(fit)

multilogitlink(fitted(fit))
multilogitlink(fitted(fit)) - predict(fit)  # Should be all 0s

multilogitlink(predict(fit), inverse = TRUE)  # rowSums() add to unity
multilogitlink(predict(fit), inverse = TRUE, refLevel = 1)
multilogitlink(predict(fit), inverse = TRUE) -
fitted(fit)  # Should be all 0s

multilogitlink(fitted(fit), deriv = 1)
multilogitlink(fitted(fit), deriv = 2)
</code></pre>

<hr>
<h2 id='multinomial'> Multinomial Logit Model </h2><span id='topic+multinomial'></span>

<h3>Description</h3>

<p>Fits a multinomial logit model (MLM) to a (preferably unordered)
factor response.


</p>


<h3>Usage</h3>

<pre><code class='language-R'>multinomial(zero = NULL, parallel = FALSE, nointercept = NULL,
     refLevel = "(Last)", ynames = FALSE,
     imethod = 1, imu = NULL, byrow.arg = FALSE,
     Thresh = NULL, Trev = FALSE,
     Tref = if (Trev) "M" else 1, whitespace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multinomial_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
Any values must be from the set {1,2,...,<code class="reqn">M</code>}.
The default value means none are modelled as
intercept-only terms.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_parallel">parallel</code></td>
<td>

<p>A logical, or formula specifying which terms have
equal/unequal coefficients.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_ynames">ynames</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then 
<code>"mu[,1]"</code> is replaced by the
probability of the
first named response category, etc.
(e.g., <code>"P[normal]"</code>),
so that the output is more readable,
albeit less compact.
This is seen in output such as
<code>predict(fit)</code> and
<code>coef(fit, matrix = TRUE)</code>.
Of course, <code>"mu"</code> stands for the
fitted probabilities, and it remains
the default for upward compatibility
and predictability.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_nointercept">nointercept</code>, <code id="multinomial_+3A_whitespace">whitespace</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_imu">imu</code>, <code id="multinomial_+3A_byrow.arg">byrow.arg</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_reflevel">refLevel</code></td>
<td>

<p>Either a (1) single positive integer or (2) a value of
the factor or (3) a character string.
If inputted as an integer then it specifies which
column of the response matrix is the reference or baseline level.
The default is the <em>last</em> one (the <code class="reqn">(M+1)</code>th one).
If used, this argument will be usually assigned
the value <code>1</code>.
If inputted as a value of a factor then beware of
missing values
of certain levels of the factor
(<code>drop.unused.levels = TRUE</code> or
<code>drop.unused.levels = FALSE</code>).
See the example below.
If inputted as a character string then this should be
equal to (A) one of the levels of the factor response,
else (B) one
of the column names of the matrix response of counts;
e.g.,
<code>vglm(cbind(normal, mild, severe) ~ let,</code>
<code>multinomial(refLevel = "severe"), data = pneumo)</code>
if it was (incorrectly because the response is ordinal)
applied to the <code><a href="#topic+pneumo">pneumo</a></code> data set.
Another example is
<code>vglm(ethnicity ~ age,</code>
<code>multinomial(refLevel = "European"), data = xs.nz)</code>
if it was applied to the <code><a href="VGAMdata.html#topic+xs.nz">xs.nz</a></code> data set.
</p>
</td></tr>
<tr><td><code id="multinomial_+3A_imethod">imethod</code></td>
<td>

<p>Choosing 2 will use the mean sample proportions of each
column of the response matrix, which corresponds to
the MLEs for intercept-only models.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
</p>



</td></tr>

















<tr><td><code id="multinomial_+3A_thresh">Thresh</code>, <code id="multinomial_+3A_trev">Trev</code>, <code id="multinomial_+3A_tref">Tref</code></td>
<td>

<p>Same as <code><a href="#topic+cumulative">cumulative</a></code>.
Because these arguments concern the intercepts,
they should not be confused with the
<em>stereotype</em> model where they would
be applied to the <b>A</b> matrix instead.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file the response <code class="reqn">Y</code> is
assumed to be a factor with unordered values
<code class="reqn">1,2,\dots,M+1</code>, so
that <code class="reqn">M</code> is the number of linear/additive
predictors <code class="reqn">\eta_j</code>.
</p>
<p>The default model can be written
</p>
<p style="text-align: center;"><code class="reqn">\eta_j = \log(P[Y=j]/ P[Y=M+1])</code>
</p>

<p>where <code class="reqn">\eta_j</code> is the <code class="reqn">j</code>th
linear/additive predictor.
Here, <code class="reqn">j=1,\ldots,M</code>, and
<code class="reqn">\eta_{M+1}</code>
is 0 by definition. That is, the last level
of the factor,
or last column of the response matrix, is
taken as the
reference level or baseline&mdash;this is for
identifiability
of the parameters. The reference or
baseline level can
be changed with the <code>refLevel</code> argument.
</p>
<p>In almost all the literature, the constraint matrices associated with
this family of models are known.  For example, setting <code>parallel
  = TRUE</code> will make all constraint matrices (including the intercept)
equal to a vector of <code class="reqn">M</code> 1's; to suppress the intercepts from
being parallel then set <code>parallel = FALSE ~ 1</code>.  If the
constraint matrices are unknown and to be estimated, then this can be
achieved by fitting the model as a reduced-rank vector generalized
linear model (RR-VGLM; see <code><a href="#topic+rrvglm">rrvglm</a></code>).  In particular, a
multinomial logit model with unknown constraint matrices is known as a
<em>stereotype</em> model (Anderson, 1984), and can be fitted with
<code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>





<p>The above details correspond to the ordinary
MLM where all the levels are <em>altered</em>
(in the terminology of GAITD regression).
</p>












<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>No check is made to verify that the response is nominal.
</p>


<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more warnings.
</p>


<h3>Note</h3>

<p>The response should be either a matrix of counts
(with row sums that are all positive), or a
factor. In both cases, the <code>y</code> slot returned by
<code><a href="#topic+vglm">vglm</a></code>/<code><a href="#topic+vgam">vgam</a></code>/<code><a href="#topic+rrvglm">rrvglm</a></code>
is the matrix of sample proportions.
</p>
<p>The multinomial logit model is more appropriate for a nominal
(unordered) factor response than for an
ordinal (ordered) factor
response.
Models more suited for the latter include those based on
cumulative probabilities, e.g., <code><a href="#topic+cumulative">cumulative</a></code>.
</p>
<p><code>multinomial</code> is prone to numerical difficulties if
the groups are separable and/or the fitted probabilities
are close to 0 or 1. The fitted values returned
are estimates of the probabilities <code class="reqn">P[Y=j]</code> for
<code class="reqn">j=1,\ldots,M+1</code>. See <span class="pkg">safeBinaryRegression</span>
for the logistic regression case.
</p>
<p>Here is an example of the usage of the <code>parallel</code>
argument. If there are covariates <code>x2</code>, <code>x3</code>
and <code>x4</code>, then <code>parallel = TRUE ~ x2 + x3 -
  1</code> and <code>parallel = FALSE ~ x4</code> are equivalent. This
would constrain the regression coefficients for <code>x2</code>
and <code>x3</code> to be equal; those of the intercepts and
<code>x4</code> would be different.
</p>
<p>In Example 4 below, a conditional logit model is
fitted to an artificial data set that explores how
cost and travel time affect people's decision about
how to travel to work. Walking is the baseline group.
The variable <code>Cost.car</code> is the difference between
the cost of travel to work by car and walking, etc. The
variable <code>Time.car</code> is the difference between
the travel duration/time to work by car and walking,
etc. For other details about the <code>xij</code> argument see
<code><a href="#topic+vglm.control">vglm.control</a></code> and <code><a href="#topic+fill1">fill1</a></code>.
</p>
<p>The <code><a href="nnet.html#topic+multinom">multinom</a></code> function in the
<span class="pkg">nnet</span> package uses the first level of the factor as
baseline, whereas the last level of the factor is used
here. Consequently the estimated regression coefficients
differ.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Agresti, A. (2013).
<em>Categorical Data Analysis</em>,
3rd ed. Hoboken, NJ, USA: Wiley.
</p>
<p>Anderson, J. A. (1984).
Regression and ordered categorical variables.
<em>Journal of the Royal Statistical Society, Series B,
Methodological</em>,
<b>46</b>, 1&ndash;30.
</p>
<p>Hastie, T. J., Tibshirani, R. J. and Friedman, J. H. (2009).
<em>The Elements of Statistical Learning: Data Mining,
Inference and Prediction</em>,
2nd ed.
New York, USA: Springer-Verlag.
</p>
<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed.
London: Chapman &amp; Hall.
</p>



<p>Tutz, G. (2012).
<em>Regression for Categorical Data</em>,
Cambridge: Cambridge University Press.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. (2010).
The <span class="pkg">VGAM</span> package for categorical data analysis.
<em>Journal of Statistical Software</em>,
<b>32</b>, 1&ndash;34.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>


<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>





<h3>See Also</h3>

<p><code><a href="#topic+multilogitlink">multilogitlink</a></code>,
<code><a href="#topic+margeff">margeff</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+CM.equid">CM.equid</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+dirichlet">dirichlet</a></code>,
<code><a href="#topic+dirmultinomial">dirmultinomial</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+fill1">fill1</a></code>,
<code><a href="stats.html#topic+Multinom">Multinomial</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="datasets.html#topic+iris">iris</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'># Example 1: fit a MLM to Edgar Anderson's iris data
data(iris)
## Not run:  fit1 &lt;- vglm(Species ~ ., multinomial, iris)
coef(fit1, matrix = TRUE)
fit2 &lt;- vglm(Species ~ ., multinomial(ynames = TRUE), iris)
coef(fit2, matrix = TRUE)  # More understandable

## End(Not run)

# Example 2a: a simple example
ycounts &lt;- t(rmultinom(10, size = 20, prob = c(0.1, 0.2, 0.8)))
fit &lt;- vglm(ycounts ~ 1, multinomial)
head(fitted(fit))   # Proportions
fit@prior.weights   # NOT recommended for the prior weights
weights(fit, type = "prior", matrix = FALSE)  # The better method
depvar(fit)         # Sample proportions; same as fit@y
constraints(fit)    # Constraint matrices

# Example 2b: Different reference level used as the baseline
fit2 &lt;- vglm(ycounts ~ 1, multinomial(refLevel = 2))
coef(fit2, matrix = TRUE)
coef(fit , matrix = TRUE)  # Easy to reconcile this output with fit2

# Example 3: The response is a factor.
nn &lt;- 10
dframe3 &lt;- data.frame(yfac = gl(3, nn, labels = c("Ctrl",
                                "Trt1", "Trt2")),
                      x2   = runif(3 * nn))
myrefLevel &lt;- with(dframe3, yfac[12])
fit3a &lt;- vglm(yfac ~ x2, multinomial(refLevel = myrefLevel), dframe3)
fit3b &lt;- vglm(yfac ~ x2, multinomial(refLevel = 2), dframe3)
coef(fit3a, matrix = TRUE)  # "Trt1" is the reference level
coef(fit3b, matrix = TRUE)  # "Trt1" is the reference level
margeff(fit3b)

# Example 4: Fit a rank-1 stereotype model
fit4 &lt;- rrvglm(Country ~ Width + Height + HP, multinomial, car.all)
coef(fit4)  # Contains the C matrix
constraints(fit4)$HP       # The A matrix
coef(fit4, matrix = TRUE)  # The B matrix
Coef(fit4)@C               # The C matrix
concoef(fit4)              # Better to get the C matrix this way
Coef(fit4)@A               # The A matrix
svd(coef(fit4, matrix = TRUE)[-1, ])$d  # Has rank 1; = C %*% t(A)
# Classification (but watch out for NAs in some of the variables):
apply(fitted(fit4), 1, which.max)  # Classification
# Classification:
colnames(fitted(fit4))[apply(fitted(fit4), 1, which.max)]
apply(predict(fit4, car.all, type = "response"),
      1, which.max)  # Ditto


# Example 5: Using the xij argument (aka conditional logit model)
set.seed(111)
nn &lt;- 100  # Number of people who travel to work
M &lt;- 3  # There are M+1 models of transport to go to work
ycounts &lt;- matrix(0, nn, M+1)
ycounts[cbind(1:nn, sample(x = M+1, size = nn, replace = TRUE))] = 1
dimnames(ycounts) &lt;- list(NULL, c("bus","train","car","walk"))
gotowork &lt;- data.frame(cost.bus  = runif(nn), time.bus  = runif(nn),
                       cost.train= runif(nn), time.train= runif(nn),
                       cost.car  = runif(nn), time.car  = runif(nn),
                       cost.walk = runif(nn), time.walk = runif(nn))
gotowork &lt;- round(gotowork, digits = 2)  # For convenience
gotowork &lt;- transform(gotowork,
              Cost.bus   = cost.bus   - cost.walk,
              Cost.car   = cost.car   - cost.walk,
              Cost.train = cost.train - cost.walk,
              Cost       = cost.train - cost.walk,  # for labelling
              Time.bus   = time.bus   - time.walk,
              Time.car   = time.car   - time.walk,
              Time.train = time.train - time.walk,
              Time       = time.train - time.walk)  # for labelling
fit &lt;- vglm(ycounts ~ Cost + Time,
            multinomial(parall = TRUE ~ Cost + Time - 1),
            xij = list(Cost ~ Cost.bus + Cost.train + Cost.car,
                       Time ~ Time.bus + Time.train + Time.car),
            form2 =  ~ Cost + Cost.bus + Cost.train + Cost.car +
                       Time + Time.bus + Time.train + Time.car,
            data = gotowork, trace = TRUE)
head(model.matrix(fit, type = "lm"))   # LM model matrix
head(model.matrix(fit, type = "vlm"))  # Big VLM model matrix
coef(fit)
coef(fit, matrix = TRUE)
constraints(fit)
summary(fit)
max(abs(predict(fit) - predict(fit, new = gotowork)))  # Should be 0
</code></pre>

<hr>
<h2 id='nakagami'> Nakagami Regression Family Function </h2><span id='topic+nakagami'></span>

<h3>Description</h3>

<p>Estimation of the two parameters of the
Nakagami distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nakagami(lscale = "loglink", lshape = "loglink", iscale = 1,
         ishape = NULL, nowarning = FALSE, zero = "shape")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nakagami_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning? </p>
</td></tr>
<tr><td><code id="nakagami_+3A_lscale">lscale</code>, <code id="nakagami_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions applied to the
<em>scale</em> and <em>shape</em> parameters.
Log links ensure they are positive.
See <code><a href="#topic+Links">Links</a></code> for more choices
and information.
</p>
</td></tr>
<tr><td><code id="nakagami_+3A_iscale">iscale</code>, <code id="nakagami_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial values for the shape and scale parameters.
For <code>ishape</code>, a <code>NULL</code> value means it is obtained in the
<code>initialize</code> slot based on the value of <code>iscale</code>.
For <code>iscale</code>, assigning a <code>NULL</code> means a value
is obtained in the <code>initialize</code> slot, however, setting
another numerical value is recommended if convergence fails or
is too slow.
</p>
</td></tr>
<tr><td><code id="nakagami_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Nakagami distribution, which is useful for modelling
wireless systems such as radio links, can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = 2 (shape/scale)^{shape} y^{2 \times shape-1}
        \exp(-shape \times y^2/scale) / \Gamma(shape)</code>
</p>

<p>for <code class="reqn">y &gt; 0</code>, <code class="reqn">shape &gt; 0</code>, <code class="reqn">scale &gt; 0</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\sqrt{scale/shape}  \times  \Gamma(shape+0.5) /
       \Gamma(shape)</code>
and these are returned as the fitted values.
By default, the linear/additive predictors are
<code class="reqn">\eta_1=\log(scale)</code> and
<code class="reqn">\eta_2=\log(shape)</code>.
Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The Nakagami distribution is also known as the
Nakagami-<em>m</em> distribution, where <code class="reqn">m=shape</code> here.
Special cases: <code class="reqn">m=0.5</code> is a one-sided Gaussian
distribution and <code class="reqn">m=1</code> is a Rayleigh distribution.
The second moment is <code class="reqn">E(Y^2)=m</code>.
</p>
<p>If <code class="reqn">Y</code> has a Nakagami distribution with parameters
<em>shape</em> and <em>scale</em> then <code class="reqn">Y^2</code> has a gamma
distribution with shape parameter <em>shape</em> and scale
parameter <em>scale/shape</em>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Nakagami, M. (1960).
The  <em>m</em>-distribution: a general  formula  of
intensity  distribution  of  rapid  fading,
pp.3&ndash;36 in:
<em>Statistical Methods in Radio Wave Propagation</em>.
W. C. Hoffman, Ed., New York: Pergamon.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnaka">rnaka</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000; shape &lt;- exp(0); Scale &lt;- exp(1)
ndata &lt;- data.frame(y1 = sqrt(rgamma(nn, shape = shape, scale = Scale/shape)))
nfit &lt;- vglm(y1 ~ 1, nakagami, data = ndata, trace = TRUE, crit = "coef")
ndata &lt;- transform(ndata, y2 = rnaka(nn, scale = Scale, shape = shape))
nfit &lt;- vglm(y2 ~ 1, nakagami(iscale = 3), data = ndata, trace = TRUE)
head(fitted(nfit))
with(ndata, mean(y2))
coef(nfit, matrix = TRUE)
(Cfit &lt;- Coef(nfit))
## Not run:  sy &lt;- with(ndata, sort(y2))
hist(with(ndata, y2), prob = TRUE, main = "", xlab = "y", ylim = c(0, 0.6),
     col = "lightblue")
lines(dnaka(sy, scale = Cfit["scale"], shape = Cfit["shape"]) ~ sy,
      data = ndata, col = "orange") 
## End(Not run)
</code></pre>

<hr>
<h2 id='Nakagami'>Nakagami Distribution </h2><span id='topic+Nakagami'></span><span id='topic+dnaka'></span><span id='topic+pnaka'></span><span id='topic+qnaka'></span><span id='topic+rnaka'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function, quantile function and
random generation for
the Nakagami distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnaka(x, scale = 1, shape, log = FALSE)
pnaka(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qnaka(p, scale = 1, shape, ...)
rnaka(n, scale = 1, shape, Smallno = 1.0e-6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Nakagami_+3A_x">x</code>, <code id="Nakagami_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Nakagami_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Nakagami_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>

</td></tr>
<tr><td><code id="Nakagami_+3A_scale">scale</code>, <code id="Nakagami_+3A_shape">shape</code></td>
<td>

<p>arguments for the parameters of the distribution.
See <code><a href="#topic+nakagami">nakagami</a></code> for more details.
For <code>rnaka</code>, arguments <code>shape</code> and <code>scale</code> must be of
length 1.
</p>
</td></tr>
<tr><td><code id="Nakagami_+3A_smallno">Smallno</code></td>
<td>

<p>Numeric, a small value used by the rejection method for determining
the upper limit of the distribution.
That is, <code>pnaka(U) &gt; 1-Smallno</code> where <code>U</code> is the upper limit.
</p>
</td></tr>
<tr><td><code id="Nakagami_+3A_...">...</code></td>
<td>

<p>Arguments that can be passed into <code><a href="stats.html#topic+uniroot">uniroot</a></code>.
</p>
</td></tr>
<tr><td><code id="Nakagami_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Nakagami_+3A_lower.tail">lower.tail</code>, <code id="Nakagami_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+nakagami">nakagami</a></code> for more details.
</p>


<h3>Value</h3>

<p><code>dnaka</code> gives the density,
<code>pnaka</code> gives the cumulative distribution function,
<code>qnaka</code> gives the quantile function, and
<code>rnaka</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+nakagami">nakagami</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  x &lt;- seq(0, 3.2, len = 200)
plot(x, dgamma(x, shape = 1), type = "n", col = "black", ylab = "",
     ylim = c(0,1.5), main = "dnaka(x, shape = shape)")
lines(x, dnaka(x, shape = 1), col = "orange")
lines(x, dnaka(x, shape = 2), col = "blue")
lines(x, dnaka(x, shape = 3), col = "green")
legend(2, 1.0, col = c("orange","blue","green"), lty = rep(1, len = 3),
       legend = paste("shape =", c(1, 2, 3)))

plot(x, pnorm(x), type = "n", col = "black", ylab = "",
     ylim = 0:1, main = "pnaka(x, shape = shape)")
lines(x, pnaka(x, shape = 1), col = "orange")
lines(x, pnaka(x, shape = 2), col = "blue")
lines(x, pnaka(x, shape = 3), col = "green")
legend(2, 0.6, col = c("orange","blue","green"), lty = rep(1, len = 3),
       legend = paste("shape =", c(1, 2, 3))) 
## End(Not run)

probs &lt;- seq(0.1, 0.9, by = 0.1)
pnaka(qnaka(p = probs, shape = 2), shape = 2) - probs  # Should be all 0
</code></pre>

<hr>
<h2 id='nbcanlink'> Negative Binomial Canonical Link Function </h2><span id='topic+nbcanlink'></span>

<h3>Description</h3>

<p>Computes the negative binomial canonical
link transformation,
including its inverse and the first two
derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nbcanlink(theta, size = NULL, wrt.param = NULL, bvalue = NULL,
          inverse = FALSE, deriv = 0, short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nbcanlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
Typically the mean of a negative binomial
distribution (NBD).
See below for further details.
</p>
</td></tr>
<tr><td><code id="nbcanlink_+3A_size">size</code>, <code id="nbcanlink_+3A_wrt.param">wrt.param</code></td>
<td>

<p><code>size</code> contains the <code class="reqn">k</code> matrix which
must be of a conformable dimension
as <code>theta</code>.
Also, if <code>deriv &gt; 0</code> then <code>wrt.param</code>
is either 1 or 2 (1 for with respect to the
first parameter, and 2 for with respect
to the second parameter (<code>size</code>)).
</p>
</td></tr>
<tr><td><code id="nbcanlink_+3A_bvalue">bvalue</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="nbcanlink_+3A_inverse">inverse</code>, <code id="nbcanlink_+3A_deriv">deriv</code>, <code id="nbcanlink_+3A_short">short</code>, <code id="nbcanlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The NBD canonical link is
<code class="reqn">\log(\theta/(\theta + k))</code>
where <code class="reqn">\theta</code> is the NBD mean.
The canonical link is used for theoretically
relating the NBD to GLM class.
</p>
<p>This link function was specifically written for
<code><a href="#topic+negbinomial">negbinomial</a></code> and
<code><a href="#topic+negbinomial.size">negbinomial.size</a></code>,
and should not be used elsewhere
(these <span class="pkg">VGAM</span> family functions have
code that
specifically handles <code>nbcanlink()</code>.)
</p>
<p>Estimation with the NB canonical link
has a somewhat interesting history.
If we take the problem as beginning with the admission of
McCullagh and Nelder (1983; first edition, p.195)
[see also McCullagh and Nelder (1989, p.374)]
that the NB is little used in
applications and has a &ldquo;problematical&rdquo; canonical link
then it appears
only one other publicized attempt was made to
solve the problem seriously.
This was Hilbe, who produced a defective solution.
However, Miranda and Yee (2023) solve
this four-decade old problem using
total derivatives and
it is implemented by using
<code><a href="#topic+nbcanlink">nbcanlink</a></code> with
<code><a href="#topic+negbinomial">negbinomial</a></code>.
Note that early versions of <span class="pkg">VGAM</span> had
a defective solution.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the above equation
when <code>inverse = FALSE</code>, and
if <code>inverse = TRUE</code> then
<code>kmatrix / expm1(-theta)</code> where <code>theta</code>
is really <code>eta</code>.
For <code>deriv = 1</code>, then the function
returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code>
as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it
returns the reciprocal.
</p>


<h3>Note</h3>

<p>While theoretically nice, this function is not recommended
in general since its value is always negative
(linear predictors
ought to be unbounded in general). A <code><a href="#topic+loglink">loglink</a></code>
link for argument <code>lmu</code> is recommended instead.
</p>
<p>Numerical instability may occur when <code>theta</code>
is close to 0 or 1.
Values of <code>theta</code> which are less than or
equal to 0 can be
replaced by <code>bvalue</code>
before computing the link function value.
See <code><a href="#topic+Links">Links</a></code>.
</p>


<h3>Author(s)</h3>

<p> Victor Miranda and Thomas W. Yee.
</p>


<h3>References</h3>

<p>Hilbe, J. M. (2011).
<em>Negative Binomial Regression</em>,
2nd Edition.
Cambridge: Cambridge University Press.
</p>
<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed.
London: Chapman &amp; Hall.
</p>
<p>Miranda-Soberanis, V. F. and Yee, T. W. (2023).
Two-parameter link functions, with
applications to negative binomial, Weibull and
quantile regression.
<em>Computational Statistics</em>,
<b>38</b>, 1463&ndash;1485.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear
models with
two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+negbinomial.size">negbinomial.size</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nbcanlink("mu", short = FALSE)

mymu &lt;- 1:10  # Test some basic operations:
kmatrix &lt;- cbind(runif(length(mymu)))
eta1 &lt;- nbcanlink(mymu, size = kmatrix)
ans2 &lt;- nbcanlink(eta1, size = kmatrix, inverse = TRUE)
max(abs(ans2 - mymu))  # Should be 0

## Not run:  mymu &lt;- seq(0.5, 10, length = 101)
kmatrix &lt;- matrix(10, length(mymu), 1)
plot(nbcanlink(mymu, size = kmatrix) ~ mymu, las = 1,
     type = "l", col = "blue", xlab = expression({mu}))

## End(Not run)

# Estimate the parameters from some simulated data
ndata &lt;- data.frame(x2 = runif(nn &lt;- 500))
ndata &lt;- transform(ndata, eta1 = -1 - 1 * x2,  # eta1 &lt; 0
                          size1 = exp(1),
                          size2 = exp(2))
ndata &lt;- transform(ndata,
            mu1 = nbcanlink(eta1, size = size1, inverse = TRUE),
            mu2 = nbcanlink(eta1, size = size2, inverse = TRUE))
ndata &lt;- transform(ndata, y1 = rnbinom(nn, mu = mu1, size1),
                          y2 = rnbinom(nn, mu = mu2, size2))
summary(ndata)

nbcfit &lt;-
  vglm(cbind(y1, y2) ~ x2,  #  crit = "c",
       negbinomial(lmu = "nbcanlink"),
       data = ndata, trace = TRUE)
coef(nbcfit, matrix = TRUE)
summary(nbcfit)
</code></pre>

<hr>
<h2 id='negbinomial'> Negative Binomial Distribution Family Function </h2><span id='topic+negbinomial'></span><span id='topic+polya'></span><span id='topic+polyaR'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the two parameters of a negative
binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negbinomial(zero = "size", parallel = FALSE, deviance.arg = FALSE,
            type.fitted = c("mean", "quantiles"),
            percentiles = c(25, 50, 75), vfl = FALSE,
            mds.min = 1e-3, nsimEIM = 500, cutoff.prob = 0.999,
            eps.trig = 1e-7, max.support = 4000, max.chunk.MB = 30,
            lmu = "loglink", lsize = "loglink",
            imethod = 1, imu = NULL, iprobs.y = NULL,
            gprobs.y = ppoints(6), isize = NULL,
            gsize.mux = exp(c(-30, -20, -15, -10, -6:3)))
polya(zero = "size", type.fitted = c("mean", "prob"),
      mds.min = 1e-3, nsimEIM = 500, cutoff.prob = 0.999,
      eps.trig = 1e-7, max.support = 4000, max.chunk.MB = 30,
      lprob = "logitlink", lsize = "loglink", imethod = 1, iprob = NULL,
      iprobs.y = NULL, gprobs.y = ppoints(6), isize = NULL,
      gsize.mux = exp(c(-30, -20, -15, -10, -6:3)), imunb = NULL)
polyaR(zero = "size", type.fitted = c("mean", "prob"),
       mds.min = 1e-3, nsimEIM = 500,  cutoff.prob = 0.999,
       eps.trig = 1e-7, max.support = 4000, max.chunk.MB = 30,
       lsize = "loglink", lprob = "logitlink", imethod = 1, iprob = NULL,
       iprobs.y = NULL, gprobs.y = ppoints(6), isize = NULL,
       gsize.mux = exp(c(-30, -20, -15, -10, -6:3)), imunb = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negbinomial_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector, and if so, then
it is usually assigned <code class="reqn">-2</code>
or <code class="reqn">2</code>. Specifies which of the two
linear/additive predictors are modelled as an intercept
only. By default, the <code class="reqn">k</code> parameter (after <code>lsize</code>
is applied) is modelled as a single unknown number that
is estimated. It can be modelled as a function of the
explanatory variables by setting <code>zero = NULL</code>; this
has been called a NB-H model by Hilbe (2011). A negative
value means that the value is recycled, so setting <code class="reqn">-2</code>
means all <code class="reqn">k</code> are intercept-only.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>




</td></tr>
<tr><td><code id="negbinomial_+3A_lmu">lmu</code>, <code id="negbinomial_+3A_lsize">lsize</code>, <code id="negbinomial_+3A_lprob">lprob</code></td>
<td>

<p>Link functions applied to the <code class="reqn">\mu</code>, <code class="reqn">k</code>
and <code class="reqn">p</code>  parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
Note that the <code class="reqn">\mu</code>, <code class="reqn">k</code>
and <code class="reqn">p</code>  parameters are the <code>mu</code>,
<code>size</code> and <code>prob</code> arguments of
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code> respectively.
Common alternatives for <code>lsize</code> are
<code><a href="#topic+negloglink">negloglink</a></code> and
<code><a href="#topic+reciprocallink">reciprocallink</a></code>, and
<code><a href="#topic+logloglink">logloglink</a></code> (if <code class="reqn">k &gt; 1</code>).
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_imu">imu</code>, <code id="negbinomial_+3A_imunb">imunb</code>, <code id="negbinomial_+3A_isize">isize</code>, <code id="negbinomial_+3A_iprob">iprob</code></td>
<td>

<p>Optional initial values for the mean and <code class="reqn">k</code> and <code class="reqn">p</code>.
For <code class="reqn">k</code>, if failure to converge occurs then try different values
(and/or use <code>imethod</code>).
For a <code class="reqn">S</code>-column response, <code>isize</code> can be of length <code class="reqn">S</code>.
A value <code>NULL</code> means an initial value for each response is
computed internally using a gridsearch based on <code>gsize.mux</code>.
The last argument is ignored if used within <code><a href="#topic+cqo">cqo</a></code>; see
the <code>iKvector</code> argument of <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> instead.
In the future <code>isize</code> and <code>iprob</code> might be depreciated.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>This argument is used
for computing the diagonal element of the
<em>expected information matrix</em> (EIM) corresponding to <code class="reqn">k</code>
based on the <em>simulated Fisher scoring</em> (SFS) algorithm.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information
and the notes below.
SFS is one of two algorithms for computing the EIM elements
(so that both algorithms may be used on a given data set).
SFS is faster than the exact method when <code>Qmax</code> is large.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_cutoff.prob">cutoff.prob</code></td>
<td>

<p>Fed into the <code>p</code> argument
of <code><a href="stats.html#topic+NegBinomial">qnbinom</a></code>
in order to obtain an upper limit for the approximate
support of the distribution, called <code>Qmax</code>, say.
Similarly, the value <code>1-p</code> is
fed into the <code>p</code> argument
of <code><a href="stats.html#topic+NegBinomial">qnbinom</a></code>
in order to obtain a lower limit for the approximate
support of the distribution, called <code>Qmin</code>, say.
Hence the approximate support is <code>Qmin:Qmax</code>.
This argument should be
a numeric and close to 1 but never exactly 1.
Used to specify how many terms of the infinite series
for computing the second diagonal element of the
EIM are actually used.
The closer this argument is to 1, the more accurate the
standard errors of the regression coefficients will be.
If this argument is too small, convergence will take longer.
</p>





</td></tr>
<tr><td><code id="negbinomial_+3A_max.chunk.mb">max.chunk.MB</code>, <code id="negbinomial_+3A_max.support">max.support</code></td>
<td>

<p><code>max.support</code> is used to describe the eligibility of
individual observations
to have their EIM computed by the <em>exact method</em>.
Here, we are concerned about
computing the EIM wrt <code class="reqn">k</code>.
The exact method algorithm operates separately on each response
variable,
and it constructs a large matrix provided that the number of
columns is less than <code>max.support</code>.
If so, then the computations are done in chunks, so
that no more than about <code>max.chunk.MB</code> megabytes
of memory is used at a time (actually, it is proportional to
this amount).  Regarding eligibility of this algorithm, each
observation must have the length of the vector, starting from
the <code>1-cutoff.prob</code> quantile
and finishing up at the <code>cutoff.prob</code> quantile,
less than <code>max.support</code>
(as its approximate support).
If you have abundant memory then you might try setting
<code>max.chunk.MB = Inf</code>, but then the computations might take
a very long time.
Setting <code>max.chunk.MB = 0</code> or <code>max.support = 0</code>
will force the EIM to be computed using the SFS algorithm only
(this <em>used to be</em> the default method for <em>all</em>
the observations).  When the fitted values of the model are
large and <code class="reqn">k</code> is small, the computation of the EIM will be
costly with respect to time and memory if the exact method is
used. Hence the argument <code>max.support</code> limits the cost in
terms of time.  For intercept-only models <code>max.support</code>
is multiplied by a number (such as 10) because only one inner
product needs be computed.  Note: <code>max.support</code> is an
upper bound and limits the number of terms dictated by the
<code>eps.trig</code> argument.
</p>


</td></tr>
<tr><td><code id="negbinomial_+3A_mds.min">mds.min</code></td>
<td>

<p>Numeric.
Minimum value of the NBD mean divided by <code>size</code> parameter.
The closer this ratio is to 0, the closer the distribution is
to a Poisson.
Iterations will stop when an estimate of <code class="reqn">k</code> is so large,
relative to the mean, than it is below this threshold
(this is treated as a boundary of the parameter space).
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_vfl">vfl</code></td>
<td>

<p>Logical.
Fit the 
Variance&ndash;variance
Factorized
Loglinear
(VFL)
model?
If <code>TRUE</code> then the constraint matrix
<code>rbind(0, -1)</code> is assigned to all covariates
which are not parallel.
Hence <code>parallel</code> must be used
in conjunction with this argument
to specify the set of covariates used for
modelling the mean.
Note that the constraint matrix for the
intercept should be parallel too.
Some general information is at
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>



</td></tr>
<tr><td><code id="negbinomial_+3A_eps.trig">eps.trig</code></td>
<td>

<p>Numeric.
A small positive value used in the computation of the EIMs.
It focusses on the denominator of the terms of a series.
Each term in the series (that is used to approximate an infinite
series) has a value greater than <code>size / sqrt(eps.trig)</code>,
thus very small terms are ignored.  It's a good idea to set
a smaller value that will result in more accuracy, but it
will require a greater computing time (when <code class="reqn">k</code> is close
to 0).  And adjustment to <code>max.support</code> may be needed.
In particular, the quantity computed by special means is
<code class="reqn">\psi'(k) - E[\psi'(Y+k)]</code>,
which is the difference between two <code><a href="base.html#topic+trigamma">trigamma</a></code>.
functions. It is part of the calculation of the EIM with respect
to the <code>size</code> parameter.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_gsize.mux">gsize.mux</code></td>
<td>

<p>Similar to <code>gsigma</code> in <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
However, this grid is multiplied by the initial
estimates of the NBD mean parameter.
That is, it is on a relative scale rather than on an
absolute scale.
If the counts are very large in value then convergence fail might
occur; if so, then try a smaller value such as
<code>gsize.mux = exp(-40)</code>.
</p>
</td></tr>







<tr><td><code id="negbinomial_+3A_type.fitted">type.fitted</code>, <code id="negbinomial_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_deviance.arg">deviance.arg</code></td>
<td>

<p>Logical.
If <code>TRUE</code>, the deviance is computed <em>after</em> convergence.
It only works in the NB-2 model.
It is also necessary to set <code>criterion = "coefficients"</code>
or <code>half.step = FALSE</code>
since
one cannot use that criterion properly for the minimization
within the IRLS algorithm.
It should be set <code>TRUE</code> when
used with <code><a href="#topic+cqo">cqo</a></code> under the fast algorithm.
</p>








</td></tr>
<tr><td><code id="negbinomial_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> etc. which
specifies the initialization method for the <code class="reqn">\mu</code>
parameter.  If failure to converge occurs try another value
and/or else specify a value for <code>iprobs.y</code> and/or else
specify a value for <code>isize</code>.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_parallel">parallel</code></td>
<td>

<p>Setting <code>parallel = TRUE</code> is useful in order to get
something similar to <code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code> or
what is known as NB-1.
If <code>parallel = TRUE</code> then the parallelism constraint
does not apply to any intercept term.
You should set <code>zero = NULL</code> too if <code>parallel =
  TRUE</code> to avoid a conflict.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
Argument <code>vfl</code> requires the use of
<code>parallel</code> to fit the VFL model.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_gprobs.y">gprobs.y</code></td>
<td>

<p>A vector representing a grid;
passed into the <code>probs</code> argument
of <code><a href="stats.html#topic+quantile">quantile</a></code>
when <code>imethod = 1</code> to obtain an initial value for
the mean of each response. Is overwritten by any value of
<code>iprobs.y</code>.
</p>
</td></tr>
<tr><td><code id="negbinomial_+3A_iprobs.y">iprobs.y</code></td>
<td>

<p>Passed into the <code>probs</code> argument
of <code><a href="stats.html#topic+quantile">quantile</a></code>
when <code>imethod = 1</code> to obtain an initial value for the
mean of each response. Overwrites any value of <code>gprobs.y</code>.
This argument might be deleted in the future.
</p>
</td></tr>








</table>


<h3>Details</h3>

<p>The negative binomial distribution (NBD)
can be motivated in several ways,
e.g., as a Poisson distribution with a mean that is gamma
distributed.
There are several common parametrizations of the NBD.
The one used by <code>negbinomial()</code> uses the
mean <code class="reqn">\mu</code> and an <em>index</em> parameter
<code class="reqn">k</code>, both which are positive.
Specifically, the density of a random variable <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">f(y;\mu,k) = {y + k - 1 \choose y} \,
    \left( \frac{\mu}{\mu+k} \right)^y\,
    \left( \frac{k}{k+\mu} \right)^k </code>
</p>

<p>where <code class="reqn">y=0,1,2,\ldots</code>,
and <code class="reqn">\mu &gt; 0</code> and <code class="reqn">k &gt; 0</code>.
Note that the <em>dispersion</em> parameter is
<code class="reqn">1/k</code>, so that as <code class="reqn">k</code> approaches infinity the
NBD approaches a Poisson distribution.
The response has variance
<code class="reqn">Var(Y)=\mu+\mu^2/k</code>.
When fitted, the <code>fitted.values</code> slot of the object
contains the estimated value of the <code class="reqn">\mu</code> parameter,
i.e., of the mean <code class="reqn">E(Y)</code>.
It is common for some to use <code class="reqn">\alpha=1/k</code> as the
ancillary or heterogeneity parameter;
so common alternatives for <code>lsize</code> are
<code><a href="#topic+negloglink">negloglink</a></code> and
<code><a href="#topic+reciprocallink">reciprocallink</a></code>.
</p>
<p>For <code>polya</code> the density is
</p>
<p style="text-align: center;"><code class="reqn">f(y;p,k) = {y + k - 1 \choose y} \,
    \left( 1 - p \right)^y\,
    p^k </code>
</p>

<p>where <code class="reqn">y=0,1,2,\ldots</code>,
and <code class="reqn">k &gt; 0</code> and <code class="reqn">0 &lt; p &lt; 1</code>.
</p>
<p>Family function <code>polyaR()</code> is the same as <code>polya()</code>
except the order of the two parameters are switched.  The reason
is that <code>polyaR()</code> tries to match with
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code> closely
in terms of the argument order, etc.
Should the probability parameter be of primary interest,
probably, users will prefer using  <code>polya()</code> rather than
<code>polyaR()</code>.
Possibly <code>polyaR()</code> will be decommissioned one day.
</p>
<p>The NBD can be coerced into the
classical GLM framework with one of the parameters being
of interest and the other treated as a nuisance/scale
parameter (this is implemented in the <span class="pkg">MASS</span> library). The
<span class="pkg">VGAM</span> family function <code>negbinomial()</code> treats both
parameters on the same footing, and estimates them both
by full maximum likelihood estimation.
</p>


<p>The parameters <code class="reqn">\mu</code> and <code class="reqn">k</code> are independent
(diagonal EIM), and the confidence region for <code class="reqn">k</code>
is extremely skewed so that its standard error is often
of no practical use. The parameter <code class="reqn">1/k</code> has been
used as a measure of aggregation.
For the NB-C the EIM is not diagonal.
</p>
<p>These <span class="pkg">VGAM</span> family functions handle
<em>multiple</em> responses, so that a response matrix can be
inputted. The number of columns is the number
of species, say, and setting <code>zero = -2</code> means that
<em>all</em> species have a <code class="reqn">k</code> equalling a (different)
intercept only.
</p>
<p>Conlisk, et al. (2007) show that fitting the NBD to
presence-absence data will result in identifiability problems.
However, the model is identifiable if the response values include
0, 1 and 2.
</p>

<p>For the NB canonical link (NB-C), its estimation
has a somewhat interesting history.
Some details are at <code><a href="#topic+nbcanlink">nbcanlink</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such
as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>Poisson regression corresponds to <code class="reqn">k</code> equalling
infinity.  If the data is Poisson or close to Poisson,
numerical problems may occur.
Some corrective measures are taken, e.g.,
<code class="reqn">k</code> is effectively capped
(relative to the mean) during
estimation to some large value and a warning is issued.
And setting <code>stepsize = 0.5</code> for
half stepping is probably
a good idea too when the data is extreme.
</p>














<p>The NBD is a strictly unimodal distribution. Any data set
that does not exhibit a mode (somewhere in the middle) makes
the estimation problem difficult.  Set <code>trace = TRUE</code>
to monitor convergence.
</p>
<p>These functions are fragile; the maximum likelihood estimate
of the index parameter is fraught (see Lawless, 1987).
Other alternatives to <code>negbinomial</code> are to fit a NB-1 or
RR-NB (aka NB-P) model; see Yee (2014).  Also available are
the NB-C, NB-H and NB-G.  Assigning values to the <code>isize</code>
argument may lead to a local solution, and smaller values are
preferred over large values when using this argument.
</p>

<p>If one wants to force SFS
to be used on all observations, then
set <code>max.support = 0</code> or <code>max.chunk.MB = 0</code>.
If one wants to force the exact method
to be used for all observations, then
set <code>max.support = Inf</code>.
If the computer has <em>much</em> memory, then trying
<code>max.chunk.MB = Inf</code> and
<code>max.support = Inf</code>
may provide a small speed increase.
If SFS is used at all, then the working
weights (<code>@weights</code>) slot of the
fitted object will be a matrix;
otherwise that slot will be a <code>0 x 0</code> matrix.
</p>
<p>An alternative to the NBD is the generalized Poisson
distribution,
<code><a href="#topic+genpoisson1">genpoisson1</a></code>,
<code><a href="#topic+genpoisson2">genpoisson2</a></code> and
<code><a href="#topic+genpoisson0">genpoisson0</a></code>,
since that also handles overdispersion wrt Poisson.
It has one advantage in that its EIM can be computed
straightforwardly.
</p>
<p>Yet to do: write a family function which uses the methods
of moments estimator for <code class="reqn">k</code>.
</p>


<h3>Note</h3>




<p>These 3 functions implement 2 common parameterizations
of the negative binomial (NB). Some people called the
NB with integer <code class="reqn">k</code> the <em>Pascal</em> distribution,
whereas if <code class="reqn">k</code> is real then this is the <em>Polya</em>
distribution. I don't. The one matching the details of
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code> in terms of <code class="reqn">p</code>
and <code class="reqn">k</code> is <code>polya()</code>.
</p>
<p>For <code>polya()</code> the code may fail when <code class="reqn">p</code> is close
to 0 or 1. It is not yet compatible with <code><a href="#topic+cqo">cqo</a></code>
or <code><a href="#topic+cao">cao</a></code>.
</p>
<p>Suppose the response is called <code>ymat</code>.
For <code>negbinomial()</code>
the diagonal element of the <em>expected information matrix</em>
(EIM) for parameter <code class="reqn">k</code>
involves an infinite series; consequently SFS
(see <code>nsimEIM</code>) is used as the backup algorithm only.
SFS should be better if <code>max(ymat)</code> is large,
e.g., <code>max(ymat) &gt; 1000</code>,
or if there are any outliers in <code>ymat</code>.
The default algorithm involves a finite series approximation
to the support <code>0:Inf</code>;
the arguments
<code>max.memory</code>,
<code>min.size</code> and
<code>cutoff.prob</code> are pertinent.
</p>



<p>Regardless of the algorithm used,
convergence problems may occur, especially when the response
has large outliers or is large in magnitude.
If convergence failure occurs, try using arguments
(in recommended decreasing order)
<code>max.support</code>,
<code>nsimEIM</code>,
<code>cutoff.prob</code>,
<code>iprobs.y</code>,
<code>imethod</code>,
<code>isize</code>,
<code>zero</code>,
<code>max.chunk.MB</code>.
</p>
<p>The function <code>negbinomial</code> can be used by the
fast algorithm in <code><a href="#topic+cqo">cqo</a></code>, however, setting
<code>eq.tolerances = TRUE</code> and <code>I.tolerances = FALSE</code>
is recommended.
</p>








<p>In the first example below (Bliss and Fisher, 1953), from each
of 6 McIntosh apple trees in an orchard that had been sprayed,
25 leaves were randomly selected. On each of the leaves,
the number of adult female European red mites were counted.
</p>

<p>There are two special uses of <code>negbinomial</code> for handling
count data.
Firstly,
when used by <code><a href="#topic+rrvglm">rrvglm</a></code>  this
results in a continuum of models in between and
inclusive of quasi-Poisson and negative binomial regression.
This is known as a reduced-rank negative binomial model
<em>(RR-NB)</em>.  It fits a negative binomial log-linear
regression with variance function
<code class="reqn">Var(Y)=\mu+\delta_1 \mu^{\delta_2}</code>
where <code class="reqn">\delta_1</code>
and   <code class="reqn">\delta_2</code>
are parameters to be estimated by MLE.
Confidence intervals are available for <code class="reqn">\delta_2</code>,
therefore it can be decided upon whether the
data are quasi-Poisson or negative binomial, if any.
</p>
<p>Secondly,
the use of <code>negbinomial</code> with <code>parallel = TRUE</code>
inside <code><a href="#topic+vglm">vglm</a></code>
can result in a model similar to <code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code>.
This is named the <em>NB-1</em> model.
The dispersion parameter is estimated by MLE whereas
<code><a href="stats.html#topic+glm">glm</a></code> uses the method of moments.
In particular, it fits a negative binomial log-linear regression
with variance function
<code class="reqn">Var(Y) = \phi_0   \mu</code>
where <code class="reqn">\phi_0</code>
is a parameter to be estimated by MLE.
Confidence intervals are available for <code class="reqn">\phi_0</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee,
and with a lot of help by Victor Miranda
to get it going with <code><a href="#topic+nbcanlink">nbcanlink</a></code>.
</p>


<h3>References</h3>

<p>Bliss, C. and Fisher, R. A. (1953).
Fitting the negative binomial distribution to biological data.
<em>Biometrics</em>
<b>9</b>, 174&ndash;200.
</p>
<p>Conlisk, E. and Conlisk, J. and Harte, J. (2007).
The impossibility of estimating a negative binomial
clustering parameter from presence-absence data:
A comment on He and Gaston.
<em>The American Naturalist</em>
<b>170</b>,
651&ndash;654.
</p>

<p>Hilbe, J. M. (2011).
<em>Negative Binomial Regression</em>,
2nd Edition.
Cambridge: Cambridge University Press.
</p>
<p>Lawless, J. F. (1987).
Negative binomial and mixed Poisson regression.
<em>The Canadian Journal of Statistics</em>
<b>15</b>, 209&ndash;225.
</p>
<p>Miranda-Soberanis, V. F. and Yee, T. W. (2023).
Two-parameter link functions, with
applications to negative binomial, Weibull and
quantile regression.
<em>Computational Statistics</em>,
<b>38</b>, 1463&ndash;1485.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models with two linear
predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>
<p>Yee, T. W. (2020).
The <span class="pkg">VGAM</span> package for negative binomial regression.
<em>Australian &amp; New Zealand Journal of Statistics</em>,
<b>62</b>, 116&ndash;131.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quasipoisson">quasipoisson</a></code>,
<code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+zinegbinomial">zinegbinomial</a></code>,
<code><a href="#topic+negbinomial.size">negbinomial.size</a></code> (e.g., NB-G),
<code><a href="#topic+nbcanlink">nbcanlink</a></code> (NB-C),
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>,
<code><a href="#topic+genpoisson1">genpoisson1</a></code>,
<code><a href="#topic+genpoisson2">genpoisson2</a></code>,
<code><a href="#topic+genpoisson0">genpoisson0</a></code>,
<code><a href="#topic+inv.binomial">inv.binomial</a></code>,
<code><a href="stats.html#topic+NegBinomial">NegBinomial</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cao">cao</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="stats.html#topic+ppoints">ppoints</a></code>,
<code><a href="#topic+margeff">margeff</a></code>.
</p>







<h3>Examples</h3>

<pre><code class='language-R'># Example 1: apple tree data (Bliss and Fisher, 1953)
appletree &lt;- data.frame(y = 0:7, w = c(70, 38, 17, 10, 9, 3, 2, 1))
fit &lt;- vglm(y ~ 1, negbinomial(deviance = TRUE), data = appletree,
            weights = w, crit = "coef")  # Obtain the deviance
fit &lt;- vglm(y ~ 1, negbinomial(deviance = TRUE), data = appletree,
            weights = w, half.step = FALSE)  # Alternative method
summary(fit)
coef(fit, matrix = TRUE)
Coef(fit)  # For intercept-only models
deviance(fit)  # NB2 only; needs 'crit="coef"' &amp; 'deviance=T' above

# Example 2: simulated data with multiple responses
## Not run: 
ndata &lt;- data.frame(x2 = runif(nn &lt;- 200))
ndata &lt;- transform(ndata, y1 = rnbinom(nn, exp(1), mu = exp(3+x2)),
                          y2 = rnbinom(nn, exp(0), mu = exp(2-x2)))
fit1 &lt;- vglm(cbind(y1, y2) ~ x2, negbinomial, ndata, trace = TRUE)
coef(fit1, matrix = TRUE)

## End(Not run)

# Example 3: large counts implies SFS is used
## Not run: 
ndata &lt;- transform(ndata, y3 = rnbinom(nn, exp(1), mu = exp(10+x2)))
with(ndata, range(y3))  # Large counts
fit2 &lt;- vglm(y3 ~ x2, negbinomial, data = ndata, trace = TRUE)
coef(fit2, matrix = TRUE)
head(weights(fit2, type = "working"))  # Non-empty; SFS was used

## End(Not run)

# Example 4: a NB-1 to estimate a NB with Var(Y)=phi0*mu
nn &lt;- 200  # Number of observations
phi0 &lt;- 10  # Specify this; should be greater than unity
delta0 &lt;- 1 / (phi0 - 1)
mydata &lt;- data.frame(x2 = runif(nn), x3 = runif(nn))
mydata &lt;- transform(mydata, mu = exp(2 + 3 * x2 + 0 * x3))
mydata &lt;- transform(mydata, y3 = rnbinom(nn, delta0 * mu, mu = mu))
## Not run: 
plot(y3 ~ x2, data = mydata, pch = "+", col = "blue",
     main = paste("Var(Y) = ", phi0, " * mu", sep = ""), las = 1) 
## End(Not run)
nb1 &lt;- vglm(y3 ~ x2 + x3, negbinomial(parallel = TRUE, zero = NULL),
            data = mydata, trace = TRUE)
# Extracting out some quantities:
cnb1 &lt;- coef(nb1, matrix = TRUE)
mydiff &lt;- (cnb1["(Intercept)", "loglink(size)"] -
           cnb1["(Intercept)", "loglink(mu)"])
delta0.hat &lt;- exp(mydiff)
(phi.hat &lt;- 1 + 1 / delta0.hat)  # MLE of phi
summary(nb1)
# Obtain a 95 percent confidence interval for phi0:
myvec &lt;- rbind(-1, 1, 0, 0)
(se.mydiff &lt;- sqrt(t(myvec) %*%  vcov(nb1) %*%  myvec))
ci.mydiff &lt;- mydiff + c(-1.96, 1.96) * c(se.mydiff)
ci.delta0 &lt;- ci.exp.mydiff &lt;- exp(ci.mydiff)
(ci.phi0 &lt;- 1 + 1 / rev(ci.delta0))  # The 95% confint for phi0
Confint.nb1(nb1)  # Quick way to get it
# cf. moment estimator:
summary(glm(y3 ~ x2 + x3, quasipoisson, mydata))$disper
</code></pre>

<hr>
<h2 id='negbinomial.size'> Negative Binomial Distribution Family Function With Known Size</h2><span id='topic+negbinomial.size'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the mean parameter of a negative
binomial distribution with known size parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negbinomial.size(size = Inf, lmu = "loglink", imu = NULL,
                 iprobs.y = 0.35, imethod = 1,
                 ishrinkage = 0.95, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negbinomial.size_+3A_size">size</code></td>
<td>

<p>Numeric, positive.
Same as argument <code>size</code> of <code><a href="stats.html#topic+NegBinomial">rnbinom</a></code>.
If the response is a matrix then this is recycled to a matrix of
the same dimension, by row
(<code><a href="base.html#topic+matrix">matrix</a></code> with <code>byrow = TRUE</code>).
</p>
</td></tr>
<tr><td><code id="negbinomial.size_+3A_lmu">lmu</code>, <code id="negbinomial.size_+3A_imu">imu</code></td>
<td>

<p>Same as <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="negbinomial.size_+3A_iprobs.y">iprobs.y</code>, <code id="negbinomial.size_+3A_imethod">imethod</code></td>
<td>

<p>Same as <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="negbinomial.size_+3A_zero">zero</code>, <code id="negbinomial.size_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>Same as <code><a href="#topic+negbinomial">negbinomial</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <span class="pkg">VGAM</span> family function estimates only the mean parameter of
the negative binomial distribution.
See <code><a href="#topic+negbinomial">negbinomial</a></code> for general information.
Setting <code>size = 1</code> gives what might
be called the NB-G (geometric model;
see Hilbe (2011)).
The default, <code>size = Inf</code>, corresponds to the Poisson distribution.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>If <code>lmu = "nbcanlink"</code> in <code>negbinomial.size()</code> then
the <code>size</code> argument here should be assigned and
these values are recycled.
</p>




<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Hilbe, J. M. (2011).
<em>Negative Binomial Regression</em>,
2nd Edition.
Cambridge: Cambridge University Press.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models with two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+nbcanlink">nbcanlink</a></code> (NB-C model),
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'># Simulated data with various multiple responses
size1 &lt;- exp(1); size2 &lt;- exp(2); size3 &lt;- exp(0); size4 &lt;- Inf
ndata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
ndata &lt;- transform(ndata, eta1  = -1 - 2 * x2,  # eta1 must be negative
                          size1 = size1)
ndata &lt;- transform(ndata,
                   mu1  = nbcanlink(eta1, size = size1, inv = TRUE))
ndata &lt;- transform(ndata,
              y1 = rnbinom(nn, mu = mu1,         size = size1),  # NB-C
              y2 = rnbinom(nn, mu = exp(2 - x2), size = size2),
              y3 = rnbinom(nn, mu = exp(3 + x2), size = size3),  # NB-G
              y4 =   rpois(nn, lambda = exp(1 + x2)))

# Also known as NB-C with size known (Hilbe, 2011)
fit1 &lt;- vglm(y1 ~ x2, negbinomial.size(size = size1, lmu = "nbcanlink"),
             data = ndata, trace = TRUE)
coef(fit1, matrix = TRUE)
head(fit1@misc$size)  # size saved here

fit2 &lt;- vglm(cbind(y2, y3, y4) ~ x2, data = ndata, trace = TRUE,
             negbinomial.size(size = c(size2, size3, size4)))
coef(fit2, matrix = TRUE)
head(fit2@misc$size)  # size saved here
</code></pre>

<hr>
<h2 id='normal.vcm'> Univariate Normal Distribution as a Varying-Coefficient Model </h2><span id='topic+normal.vcm'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of all the coefficients of a LM
where each of the usual regression coefficients is modelled
with other explanatory variables via parameter link functions.
Thus this is a basic varying-coefficient model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normal.vcm(link.list = list("(Default)" = "identitylink"),
           earg.list = list("(Default)" = list()),
           lsd = "loglink", lvar = "loglink",
           esd = list(), evar = list(),
           var.arg = FALSE, imethod = 1,
           icoefficients = NULL, isd = NULL, zero = "sd",
           sd.inflation.factor = 2.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normal.vcm_+3A_link.list">link.list</code>, <code id="normal.vcm_+3A_earg.list">earg.list</code></td>
<td>

<p>Link functions and extra arguments
applied to the coefficients of the LM, excluding
the standard deviation/variance.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The default is for an identity link to be applied to
each of the regression coefficients.
</p>
</td></tr>
<tr><td><code id="normal.vcm_+3A_lsd">lsd</code>, <code id="normal.vcm_+3A_esd">esd</code>, <code id="normal.vcm_+3A_lvar">lvar</code>, <code id="normal.vcm_+3A_evar">evar</code></td>
<td>

<p>Link function and extra argument
applied to
the standard deviation/variance.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
Same as <code><a href="#topic+uninormal">uninormal</a></code>.
</p>
</td></tr>
<tr><td><code id="normal.vcm_+3A_icoefficients">icoefficients</code></td>
<td>

<p>Optional initial values for the coefficients.
Recycled to length <code class="reqn">M-1</code> (does not include the
standard deviation/variance).
Try using this argument if there is a link function that is not
programmed explicitly to handle range restrictions in
the <code>initialize</code> slot.
</p>
</td></tr>
<tr><td><code id="normal.vcm_+3A_var.arg">var.arg</code>, <code id="normal.vcm_+3A_imethod">imethod</code>, <code id="normal.vcm_+3A_isd">isd</code></td>
<td>

<p>Same as, or similar to, <code><a href="#topic+uninormal">uninormal</a></code>.
</p>
</td></tr>
<tr><td><code id="normal.vcm_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The default applies to the last one,
viz. the standard deviation/variance parameter.
</p>
</td></tr>
<tr><td><code id="normal.vcm_+3A_sd.inflation.factor">sd.inflation.factor</code></td>
<td>

<p>Numeric, should be greater than 1.
The initial value of the standard deviation is multiplied by this,
unless <code>isd</code> is inputted.
Experience has shown that it is safer to start off with a larger value
rather than a smaller one.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows all the usual LM regression coefficients to be
modelled as functions of other explanatory variables via parameter link
functions. For example, we may want some of them to be positive. Or we
may want a subset of them to be positive and add to unity. So a class
of such models have been named <em>varying-coefficient models</em> (VCMs).
</p>
<p>The usual linear model is specified through argument
<code>form2</code>.  As with all other <span class="pkg">VGAM</span> family
functions, the linear/additive predictors are specified
through argument <code>formula</code>.
</p>
<p>The <code><a href="#topic+multilogitlink">multilogitlink</a></code> link allows a subset of the
coefficients to be positive and add to unity.  Either
none or more than one call to <code><a href="#topic+multilogitlink">multilogitlink</a></code>
is allowed. The last variable will be used as the
baseline/reference group, and therefore excluded from
the estimation.
</p>
<p>By default,
the log of the standard deviation is the last
linear/additive predictor. It is recommended that this
parameter be estimated as intercept-only, for numerical
stability.
</p>
<p>Technically,
the Fisher information matrix is of unit-rank for all but
the last parameter (the standard deviation/variance).
Hence an approximation is used that pools over all the
observations.
</p>
<p>This <span class="pkg">VGAM</span> family function cannot handle multiple responses.
Also, this function will probably not have the
full capabilities of the class of varying-coefficient models as
described by Hastie and Tibshirani (1993). However, it should
be able to manage some simple models, especially involving the
following links:
<code><a href="#topic+identitylink">identitylink</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+logofflink">logofflink</a></code>,
<code><a href="#topic+logloglink">logloglink</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>.
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+rhobitlink">rhobitlink</a></code>,
<code><a href="#topic+fisherzlink">fisherzlink</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This <span class="pkg">VGAM</span> family function is fragile.
One should monitor convergence, and possibly enter initial values
especially when there are non-<code><a href="base.html#topic+identity">identity</a></code>-link functions.
If the initial value of the standard deviation/variance is too
small then numerical problems may occur.
One trick is to fit an intercept-only only model and feed its
<code>predict()</code> output into argument <code>etastart</code> of a
more complicated model.
The use of the <code>zero</code> argument is recommended in order
to keep models as simple as possible.
</p>





<h3>Note</h3>

<p>The standard deviation/variance parameter is best modelled as
intercept-only.
</p>
<p>Yet to do: allow an argument such as <code>parallel</code> that enables
many of the coefficients to be equal.
Fix a bug: <code>Coef()</code> does not work for intercept-only models.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Hastie, T. and Tibshirani, R. (1993).
Varying-coefficient models.
<em>J. Roy. Statist. Soc. Ser. B</em>,
<b>55</b>, 757&ndash;796.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>ndata &lt;- data.frame(x2 = runif(nn &lt;- 2000))
# Note that coeff1 + coeff2 + coeff5 == 1. So try "multilogitlink".
myoffset &lt;- 10
ndata &lt;- transform(ndata,
           coeff1 = 0.25,  # "multilogitlink"
           coeff2 = 0.25,  # "multilogitlink"
           coeff3 = exp(-0.5),  # "loglink"
# "logofflink" link:
           coeff4 = logofflink(+0.5, offset = myoffset, inverse = TRUE),
           coeff5 = 0.50,  # "multilogitlink"
           coeff6 = 1.00,  # "identitylink"
           v2 = runif(nn),
           v3 = runif(nn),
           v4 = runif(nn),
           v5 = rnorm(nn),
           v6 = rnorm(nn))
ndata &lt;- transform(ndata,
           Coeff1 =              0.25 - 0 * x2,
           Coeff2 =              0.25 - 0 * x2,
           Coeff3 =   logitlink(-0.5  - 1 * x2, inverse = TRUE),
           Coeff4 =  logloglink( 0.5  - 1 * x2, inverse = TRUE),
           Coeff5 =              0.50 - 0 * x2,
           Coeff6 =              1.00 + 1 * x2)
ndata &lt;- transform(ndata,
                   y1 = coeff1 * 1 +
                        coeff2 * v2 +
                        coeff3 * v3 +
                        coeff4 * v4 +
                        coeff5 * v5 +
                        coeff6 * v6 + rnorm(nn, sd = exp(0)),
                   y2 = Coeff1 * 1 +
                        Coeff2 * v2 +
                        Coeff3 * v3 +
                        Coeff4 * v4 +
                        Coeff5 * v5 +
                        Coeff6 * v6 + rnorm(nn, sd = exp(0)))

# An intercept-only model
fit1 &lt;- vglm(y1 ~ 1,
             form2 = ~ 1 + v2 + v3 + v4 + v5 + v6,
             normal.vcm(link.list = list("(Intercept)" = "multilogitlink",
                                         "v2"          = "multilogitlink",
                                         "v3"          = "loglink",
                                         "v4"          = "logofflink",
                                         "(Default)"   = "identitylink",
                                         "v5"          = "multilogitlink"),
                        earg.list = list("(Intercept)" = list(),
                                         "v2"          = list(),
                                         "v4"          = list(offset = myoffset),
                                         "v3"          = list(),
                                         "(Default)"   = list(),
                                         "v5"          = list()),
                        zero = c(1:2, 6)),
             data = ndata, trace = TRUE)
coef(fit1, matrix = TRUE)
summary(fit1)
# This works only for intercept-only models:
multilogitlink(rbind(coef(fit1, matrix = TRUE)[1, c(1, 2)]), inverse = TRUE)

# A model with covariate x2 for the regression coefficients
fit2 &lt;- vglm(y2 ~ 1 + x2,
             form2 = ~ 1 + v2 + v3 + v4 + v5 + v6,
             normal.vcm(link.list = list("(Intercept)" = "multilogitlink",
                                         "v2"          = "multilogitlink",
                                         "v3"          = "logitlink",
                                         "v4"          = "logloglink",
                                         "(Default)"   = "identitylink",
                                         "v5"          = "multilogitlink"),
                        earg.list = list("(Intercept)" = list(),
                                         "v2"          = list(),
                                         "v3"          = list(),
                                         "v4"          = list(),
                                         "(Default)"   = list(),
                                         "v5"          = list()),
                        zero = c(1:2, 6)),
             data = ndata, trace = TRUE)

coef(fit2, matrix = TRUE)
summary(fit2)
</code></pre>

<hr>
<h2 id='notdocumentedyet'> Undocumented and Internally Used Functions and Classes </h2><span id='topic+notdocumentedyet'></span><span id='topic+ned2l.ebbinom'></span><span id='topic+eimij.ebbinom'></span><span id='topic+summary.drrvglm-class'></span><span id='topic+drrvglm-class'></span><span id='topic+Coef.drrvglm'></span><span id='topic+Coef.drrvglm-class'></span><span id='topic+dgamma.mm'></span><span id='topic+rqresidualsvlm'></span><span id='topic+rqresid'></span><span id='topic+rqresiduals'></span><span id='topic+moments.gaitdcombo.binom'></span><span id='topic+gaitdnbinomial.control'></span><span id='topic+gaitdpoisson.control'></span><span id='topic+gaitdlog.control'></span><span id='topic+gaitdzeta.control'></span><span id='topic+Pheapseep'></span><span id='topic+cm3gaitd'></span><span id='topic+moments.gaitdcombo.2par'></span><span id='topic+moments.gaitdcombo.nbinom'></span><span id='topic+pd.damlm'></span><span id='topic+get.indices.gaitd'></span><span id='topic+amazon.col'></span><span id='topic+avocado.col'></span><span id='topic+indigo.col'></span><span id='topic+iris.col'></span><span id='topic+turquoise.col'></span><span id='topic+dirt.col'></span><span id='topic+deer.col'></span><span id='topic+desire.col'></span><span id='topic+peach.col'></span><span id='topic+azure.col'></span><span id='topic+asparagus.col'></span><span id='topic+artichoke.col'></span><span id='topic+moments.gaitdcombo.1par'></span><span id='topic+moments.gaitdcombo.pois'></span><span id='topic+moments.gaitdcombo.log'></span><span id='topic+moments.gaitdcombo.zeta'></span><span id='topic+extlogF1.control'></span><span id='topic+get.offset'></span><span id='topic+get.offset.vglm'></span><span id='topic+y.gaitcombo.check'></span><span id='topic+EIM.GATNB.speciald'></span><span id='topic+GATNB.deriv012'></span><span id='topic+gaitd.errorcheck'></span><span id='topic+rootogram0'></span><span id='topic+rootogram0.default'></span><span id='topic+fitmodel.VGAM.expression'></span><span id='topic+subsetassign'></span><span id='topic+findterms'></span><span id='topic+assign2assign'></span><span id='topic+extractAIC.vglm'></span><span id='topic+dfterms'></span><span id='topic+dftermsvglm'></span><span id='topic+wz.merge'></span><span id='topic+gipoisson.control'></span><span id='topic+loge'></span><span id='topic+negloge'></span><span id='topic+logneg'></span><span id='topic+logit'></span><span id='topic+extlogit'></span><span id='topic+cauchit'></span><span id='topic+probit'></span><span id='topic+cloglog'></span><span id='topic+multilogit'></span><span id='topic+fisherz'></span><span id='topic+rhobit'></span><span id='topic+logoff'></span><span id='topic+polf'></span><span id='topic+golf'></span><span id='topic+reciprocal'></span><span id='topic+negreciprocal'></span><span id='topic+negidentity'></span><span id='topic+logc'></span><span id='topic+foldsqrt'></span><span id='topic+nbolf'></span><span id='topic+getarg'></span><span id='topic+rainbow.sky'></span><span id='topic+stieltjes'></span><span id='topic+zeta.specials'></span><span id='topic+fnumat2R'></span><span id='topic+attr.assign.x.vglm'></span><span id='topic+car.relatives'></span><span id='topic+which.etas'></span><span id='topic+which.xij'></span><span id='topic+retain.col'></span><span id='topic+d3theta.deta3'></span><span id='topic+ghn100'></span><span id='topic+ghw100'></span><span id='topic+dprentice74'></span><span id='topic+label.cols.y'></span><span id='topic+valid.vknotl2'></span><span id='topic+negbinomial.initialize.yj'></span><span id='topic+mroot2'></span><span id='topic+psint'></span><span id='topic+psintpvgam'></span><span id='topic+df.residual_pvgam'></span><span id='topic+startstoppvgam'></span><span id='topic+summary.pvgam-class'></span><span id='topic+endf'></span><span id='topic+endfpvgam'></span><span id='topic+vcov.pvgam'></span><span id='topic+vcov.pvgam-class'></span><span id='topic+vlabel'></span><span id='topic+show.pvgam'></span><span id='topic+model.matrixpvgam'></span><span id='topic+gharmonic'></span><span id='topic+gharmonic2'></span><span id='topic+bisection.basic'></span><span id='topic+Zeta.aux'></span><span id='topic+deflat.limit.oizeta'></span><span id='topic+deflat.limit.oipospois'></span><span id='topic+get.X.VLM.aug'></span><span id='topic+psv2magic'></span><span id='topic+pvgam-class'></span><span id='topic+checkwz'></span><span id='topic+vforsub'></span><span id='topic+vbacksub'></span><span id='topic+vchol'></span><span id='topic+process.constraints'></span><span id='topic+mux5'></span><span id='topic+mux22'></span><span id='topic+mux111'></span><span id='topic+genbetaII.Loglikfun4'></span><span id='topic+posNBD.Loglikfun2'></span><span id='topic+NBD.Loglikfun2'></span><span id='topic+AR1.gammas'></span><span id='topic+Init.mu'></span><span id='topic+.min.criterion.VGAM'></span><span id='topic+predictvglmS4VGAM'></span><span id='topic+EIM.NB.speciald'></span><span id='topic+EIM.NB.specialp'></span><span id='topic+EIM.posNB.speciald'></span><span id='topic+EIM.posNB.specialp'></span><span id='topic+showvglmS4VGAM'></span><span id='topic+showvgamS4VGAM'></span><span id='topic+margeffS4VGAM'></span><span id='topic+showsummaryvglmS4VGAM'></span><span id='topic+summaryvglmS4VGAM'></span><span id='topic+findFirstMethod'></span><span id='topic+cratio.derivs'></span><span id='topic+subsetarray3'></span><span id='topic+tapplymat1'></span><span id='topic+as.char.expression'></span><span id='topic+coef.vlm'></span><span id='topic+vcov.vlm'></span><span id='topic+model.matrix.vlm'></span><span id='topic+responseName'></span><span id='topic+responseNamevlm'></span><span id='topic+qlms.bcn'></span><span id='topic+dlms.bcn'></span><span id='topic+dbetaII'></span><span id='topic+dlevy'></span><span id='topic+plevy'></span><span id='topic+qlevy'></span><span id='topic+rlevy'></span><span id='topic+grid.search'></span><span id='topic+grid.search2'></span><span id='topic+grid.search3'></span><span id='topic+grid.search4'></span><span id='topic+Ebbin.ab'></span><span id='topic+interleave.cmat'></span><span id='topic+marcumQ'></span><span id='topic+QR.Q'></span><span id='topic+QR.R'></span><span id='topic+I.col'></span><span id='topic+check.omit.constant'></span><span id='topic+rec.normal.control'></span><span id='topic+rec.exp1.control'></span><span id='topic+binom2.rho.ss'></span><span id='topic+N.hat.posbernoulli'></span><span id='topic+arwz2wz'></span><span id='topic+link2list'></span><span id='topic+w.wz.merge'></span><span id='topic+w.y.check'></span><span id='topic+vweighted.mean.default'></span><span id='topic+nvar_vlm'></span><span id='topic+npred'></span><span id='topic+npred.vlm'></span><span id='topic+show.vglmff'></span><span id='topic+show.vgam'></span><span id='topic+show.vglm'></span><span id='topic+show.vlm'></span><span id='topic+AICc'></span><span id='topic+VGAMenv'></span><span id='topic+show.Coef.rrvgam'></span><span id='topic+show.Coef.qrrvglm'></span><span id='topic+show.Coef.rrvglm'></span><span id='topic+show.rrvglm'></span><span id='topic+show.summary.rrvgam'></span><span id='topic+show.summary.qrrvglm'></span><span id='topic+show.summary.vlm'></span><span id='topic+show.vanova'></span><span id='topic+show.vsmooth.spline'></span><span id='topic+update_default'></span><span id='topic+update_formula'></span><span id='topic+plota21'></span><span id='topic+azprocedure'></span><span id='topic+Confint.rrnb'></span><span id='topic+Confint.nb1'></span><span id='topic+is.empty.list'></span><span id='topic+plotqvar'></span><span id='topic+qvplot'></span><span id='topic+depvar.vlm'></span><span id='topic+dnorm2'></span><span id='topic+dclogloglap'></span><span id='topic+dlogitlap'></span><span id='topic+dprobitlap'></span><span id='topic+logitlaplace1.control'></span><span id='topic+loglaplace1.control'></span><span id='topic+pclogloglap'></span><span id='topic+plogitlap'></span><span id='topic+pprobitlap'></span><span id='topic+qclogloglap'></span><span id='topic+qlogitlap'></span><span id='topic+qprobitlap'></span><span id='topic+rclogloglap'></span><span id='topic+rlogitlap'></span><span id='topic+rprobitlap'></span><span id='topic+AAaa.nohw'></span><span id='topic+Build.terms.vlm'></span><span id='topic+Coef.rrvgam'></span><span id='topic+Coefficients'></span><span id='topic+Cut'></span><span id='topic+Deviance.categorical.data.vgam'></span><span id='topic+InverseBrat'></span><span id='topic+Max.Coef.qrrvglm'></span><span id='topic+Max.qrrvglm'></span><span id='topic+Opt.Coef.qrrvglm'></span><span id='topic+Opt.qrrvglm'></span><span id='topic+Tol.Coef.qrrvglm'></span><span id='topic+Tol.qrrvglm'></span><span id='topic+a2m'></span><span id='topic+alaplace1.control'></span><span id='topic+alaplace2.control'></span><span id='topic+alaplace3.control'></span><span id='topic+anova.vgam'></span><span id='topic+biplot.qrrvglm'></span><span id='topic+car.all'></span><span id='topic+care.exp'></span><span id='topic+care.exp2'></span><span id='topic+concoef.Coef.rrvgam'></span><span id='topic+concoef.Coef.qrrvglm'></span><span id='topic+concoef.rrvgam'></span><span id='topic+concoef.qrrvglm'></span><span id='topic+cdf'></span><span id='topic+cdf.lms.bcg'></span><span id='topic+cdf.lms.bcn'></span><span id='topic+cdf.lms.yjn'></span><span id='topic+cdf.vglm'></span><span id='topic+cm.VGAM'></span><span id='topic+cm.zero.VGAM'></span><span id='topic+cm.nointercept.VGAM'></span><span id='topic+coefficients'></span><span id='topic+coefqrrvglm'></span><span id='topic+coefvsmooth.spline'></span><span id='topic+coefvsmooth.spline.fit'></span><span id='topic+d2theta.deta2'></span><span id='topic+deplot'></span><span id='topic+deplot.default'></span><span id='topic+deplot.lms.bcg'></span><span id='topic+deplot.lms.bcn'></span><span id='topic+deplot.lms.yjn'></span><span id='topic+deplot.lms.yjn2'></span><span id='topic+deplot.vglm'></span><span id='topic+deviance'></span><span id='topic+deviance.vlm'></span><span id='topic+deviance.qrrvglm'></span><span id='topic+dnorm2'></span><span id='topic+dtheta.deta'></span><span id='topic+effects'></span><span id='topic+eijfun'></span><span id='topic+eta2theta'></span><span id='topic+fff.control'></span><span id='topic+fill2'></span><span id='topic+fill3'></span><span id='topic+fill4'></span><span id='topic+fitted.values'></span><span id='topic+fittedvsmooth.spline'></span><span id='topic+variable.names'></span><span id='topic+variable.namesvlm'></span><span id='topic+variable.namesrrvglm'></span><span id='topic+case.names'></span><span id='topic+case.namesvlm'></span><span id='topic+formulaNA.VGAM'></span><span id='topic+gammaff'></span><span id='topic+inverse.gaussianff'></span><span id='topic+is.Numeric'></span><span id='topic+is.Numeric2'></span><span id='topic+is.bell'></span><span id='topic+is.bell.rrvgam'></span><span id='topic+is.bell.qrrvglm'></span><span id='topic+is.bell.rrvglm'></span><span id='topic+is.bell.vlm'></span><span id='topic+Kayfun.studentt'></span><span id='topic+lm2qrrvlm.model.matrix'></span><span id='topic+lm2vlm.model.matrix'></span><span id='topic+vlm2lm.model.matrix'></span><span id='topic+lms.bcg.control'></span><span id='topic+lms.bcn.control'></span><span id='topic+lms.yjn.control'></span><span id='topic+lmscreg.control'></span><span id='topic+logLik.qrrvglm'></span><span id='topic+latvar.Coef.qrrvglm'></span><span id='topic+latvar.rrvgam'></span><span id='topic+latvar.rrvglm'></span><span id='topic+latvar.qrrvglm'></span><span id='topic+lvplot.rrvgam'></span><span id='topic+m2a'></span><span id='topic+mbesselI0'></span><span id='topic+mix2exp.control'></span><span id='topic+mix2normal.control'></span><span id='topic+mix2poisson.control'></span><span id='topic+model.matrixvgam'></span><span id='topic+my1'></span><span id='topic+my2'></span><span id='topic+namesof'></span><span id='topic+nlminbcontrol'></span><span id='topic+nbolf2'></span><span id='topic+nobs.vlm'></span><span id='topic+nvar'></span><span id='topic+nvar.vlm'></span><span id='topic+nvar.vgam'></span><span id='topic+nvar.rrvglm'></span><span id='topic+nvar.qrrvglm'></span><span id='topic+nvar.rrvgam'></span><span id='topic+nvar.rcim'></span><span id='topic+persp.rrvgam'></span><span id='topic+plot.rrvgam'></span><span id='topic+plotpreplotvgam'></span><span id='topic+plotvlm'></span><span id='topic+plotvsmooth.spline'></span><span id='topic+predict.rrvgam'></span><span id='topic+predict.glm'></span><span id='topic+predict.lm'></span><span id='topic+predict.mlm'></span><span id='topic+predict.rrvglm'></span><span id='topic+predict.vgam'></span><span id='topic+predict.vlm'></span><span id='topic+predictrrvgam'></span><span id='topic+predictors'></span><span id='topic+predictors.vglm'></span><span id='topic+predictvsmooth.spline'></span><span id='topic+predictvsmooth.spline.fit'></span><span id='topic+procVec'></span><span id='topic+negzero.expression.VGAM'></span><span id='topic+process.binomial2.data.VGAM'></span><span id='topic+process.categorical.data.VGAM'></span><span id='topic+put.caption'></span><span id='topic+qtplot'></span><span id='topic+qtplot.default'></span><span id='topic+qtplot.lms.bcg'></span><span id='topic+qtplot.lms.bcn'></span><span id='topic+explot.lms.bcn'></span><span id='topic+qtplot.lms.yjn'></span><span id='topic+qtplot.lms.yjn2'></span><span id='topic+qtplot.vextremes'></span><span id='topic+qtplot.vglm'></span><span id='topic+quasiff'></span><span id='topic+rlplot'></span><span id='topic+rlplot.vextremes'></span><span id='topic+rlplot.vglm'></span><span id='topic+rrar.control'></span><span id='topic+ResSS.vgam'></span><span id='topic+s.vam'></span><span id='topic+simple.exponential'></span><span id='topic+better.exponential'></span><span id='topic+simple.poisson'></span><span id='topic+size.binomial'></span><span id='topic+sm.min1'></span><span id='topic+sm.min2'></span><span id='topic+sm.scale1'></span><span id='topic+sm.scale2'></span><span id='topic+summary.rrvgam'></span><span id='topic+summary.grc'></span><span id='topic+summary.lms'></span><span id='topic+summary.qrrvglm'></span><span id='topic+summary.rc.exponential'></span><span id='topic+summaryrcim'></span><span id='topic+summaryvlm'></span><span id='topic+terms.vlm'></span><span id='topic+termsvlm'></span><span id='topic+theta2eta'></span><span id='topic+trivial.constraints'></span><span id='topic+valt0.control'></span><span id='topic+vcontrol.expression'></span><span id='topic+vgam.fit'></span><span id='topic+vglm.fit'></span><span id='topic+vglm.garma.control'></span><span id='topic+vglm.multinomial.control'></span><span id='topic+vglm.multinomial.deviance.control'></span><span id='topic+dmultinomial'></span><span id='topic+vglm.VGAMcategorical.control'></span><span id='topic+vlm'></span><span id='topic+vlm.control'></span><span id='topic+vnonlinear.control'></span><span id='topic+vplot'></span><span id='topic+vplot.default'></span><span id='topic+vplot.factor'></span><span id='topic+vplot.list'></span><span id='topic+vplot.matrix'></span><span id='topic+vplot.numeric'></span><span id='topic+vvplot.factor'></span><span id='topic+Wr1'></span><span id='topic+Wr2'></span><span id='topic+wweights'></span><span id='topic+rrvgam-class'></span><span id='topic+rcim0-class'></span><span id='topic+rcim-class'></span><span id='topic+grc-class'></span><span id='topic+qrrvglm-class'></span><span id='topic+summary.qrrvglm-class'></span><span id='topic+summary.rrvglm-class'></span><span id='topic+summary.vgam-class'></span><span id='topic+summary.vglm-class'></span><span id='topic+summary.vlm-class'></span><span id='topic+vcov.qrrvglm-class'></span><span id='topic+vlm-class'></span><span id='topic+vlmsmall-class'></span><span id='topic+vsmooth.spline-class'></span><span id='topic+vsmooth.spline.fit-class'></span><span id='topic+Coef.rrvgam-class'></span><span id='topic+summary.rrvgam-class'></span>

<h3>Description</h3>

<p>Those currently undocumented and internally used functions are aliased
to this help file.
Ditto for some classes.
</p>


<h3>Details</h3>

<p>In the <span class="pkg">VGAM</span> package there are currently many
objects/methods/classes which are currently internal and/or
undocumented. The help file suppresses the warnings when the package is
'CHECK'ed.
</p>


<h3>Value</h3>

<p>Each objects/methods/classes may or may not have its own individual value.
These will be documented over time.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>

<hr>
<h2 id='nparam.vlm'> Number of Parameters </h2><span id='topic+nparam.vlm'></span><span id='topic+nparam'></span><span id='topic+nparam.vgam'></span><span id='topic+nparam.rrvglm'></span><span id='topic+nparam.qrrvglm'></span><span id='topic+nparam.rrvgam'></span>

<h3>Description</h3>

<p>Returns the number of parameters in a fitted model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>        nparam(object, ...)
    nparam.vlm(object, dpar = TRUE, ...)
   nparam.vgam(object, dpar = TRUE, linear.only = FALSE, ...)
 nparam.rrvglm(object, dpar = TRUE, ...)
nparam.qrrvglm(object, dpar = TRUE, ...)
 nparam.rrvgam(object, dpar = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nparam.vlm_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>
</td></tr>
<tr><td><code id="nparam.vlm_+3A_...">...</code></td>
<td>

<p>Other possible arguments fed into the function.
</p>
</td></tr>
<tr><td><code id="nparam.vlm_+3A_dpar">dpar</code></td>
<td>

<p>Logical, include any (estimated) dispersion parameters as a parameter?
</p>
</td></tr>
<tr><td><code id="nparam.vlm_+3A_linear.only">linear.only</code></td>
<td>

<p>Logical, include only the number of linear (parametric) parameters?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The code was copied from the <code>AIC()</code> methods functions.
</p>


<h3>Value</h3>

<p>Returns a numeric value with the corresponding number of parameters.
For <code><a href="#topic+vgam">vgam</a></code> objects, this may be real rather than
integer, because the nonlinear degrees of freedom is real-valued.
</p>


<h3>Warning </h3>

<p>This code has not been double-checked.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>See Also</h3>

<p>VGLMs are described in <code><a href="#topic+vglm-class">vglm-class</a></code>;
VGAMs are described in <code><a href="#topic+vgam-class">vgam-class</a></code>;
RR-VGLMs are described in <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>;
<code><a href="#topic+AICvlm">AICvlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, data = pneumo))
coef(fit1)
coef(fit1, matrix = TRUE)
nparam(fit1)
(fit2 &lt;- vglm(hits ~ 1, poissonff, weights = ofreq, data = V1))
coef(fit2)
coef(fit2, matrix = TRUE)
nparam(fit2)
nparam(fit2, dpar = FALSE)
</code></pre>

<hr>
<h2 id='olympics'> 2008 and 2012 Summer Olympic Final Medal Count Data</h2><span id='topic+olym08'></span><span id='topic+olym12'></span>

<h3>Description</h3>

<p>Final medal count, by country, for the Summer
2008 and 2012 Olympic Games.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(olym08)
data(olym12)
</code></pre>


<h3>Format</h3>

<p>A data frame with 87 or 85 observations on the following
6 variables.
</p>

<dl>
<dt><code>rank</code></dt><dd><p>a numeric vector, overall ranking
of the countries. </p>
</dd> <dt><code>country</code></dt><dd><p>a factor. </p>
</dd>
<dt><code>gold</code></dt><dd><p>a numeric vector, number of gold medals. </p>
</dd>
<dt><code>silver</code></dt><dd><p>a numeric vector, number of silver
medals. </p>
</dd> <dt><code>bronze</code></dt><dd><p>a numeric vector, number of
bronze medals. </p>
</dd> <dt><code>totalmedal</code></dt><dd><p>a numeric vector,
total number of medals. </p>
</dd>

</dl>



<h3>Details</h3>

<p>The events were held during
(i) August 8&ndash;24, 2008, in Beijing; and
(ii) 27 July&ndash;12 August, 2012, in London.
</p>



<h3>References</h3>

<p>The official English website
was/is <code>http://en.beijing2008.cn</code>
and <code>http://www.london2012.com</code>.
Help from Viet Hoang Quoc is gratefully acknowledged.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grc">grc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(olym08)
summary(olym12)
## maybe str(olym08) ; plot(olym08) ...
## Not run:  par(mfrow = c(1, 2))
myylim &lt;- c(0, 55)
with(head(olym08, n = 8),
barplot(rbind(gold, silver, bronze),
   col = c("gold", "grey", "brown"),  # No "silver" or "bronze"!
#          "gold", "grey71", "chocolate4",
   names.arg = country, cex.names = 0.5, ylim = myylim,
   beside = TRUE, main = "2008 Summer Olympic Final Medal Count",
   ylab = "Medal count", las = 1,
   sub = "Top 8 countries; 'gold'=gold, 'grey'=silver, 'brown'=bronze"))
with(head(olym12, n = 8),
barplot(rbind(gold, silver, bronze),
   col = c("gold", "grey", "brown"),  # No "silver" or "bronze"!
   names.arg = country, cex.names = 0.5, ylim = myylim,
   beside = TRUE, main = "2012 Summer Olympic Final Medal Count",
   ylab = "Medal count", las = 1,
   sub = "Top 8 countries; 'gold'=gold, 'grey'=silver, 'brown'=bronze")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Opt'> Optimums </h2><span id='topic+Opt'></span>

<h3>Description</h3>

<p>Generic function for the <em>optimums</em> (or optima) of a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Opt(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Opt_+3A_object">object</code></td>
<td>
<p> An object for which the computation or
extraction of an optimum (or optimums) is meaningful.
</p>
</td></tr>
<tr><td><code id="Opt_+3A_...">...</code></td>
<td>
<p> Other arguments fed into the specific
methods function of the model. Sometimes they are fed
into the methods function for <code><a href="#topic+Coef">Coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Different models can define an optimum in different ways.
Many models have no such notion or definition.
</p>
<p>Optimums occur in quadratic and additive ordination,
e.g., CQO or CAO.
For these models the optimum is the value of the latent
variable where the maximum occurs, i.e., where the fitted value
achieves its highest value.
For quadratic ordination models there is a formula
for the optimum but for additive ordination models the
optimum must be searched for numerically. If it occurs
on the boundary, then the optimum is undefined.
At an optimum, the fitted value of the response is
called the <em>maximum</em>.
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods
function invoked.
</p>


<h3>Note</h3>

<p>In ordination, the optimum of a species is sometimes
called the <em>species score</em>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code>Opt.qrrvglm</code>,
<code><a href="#topic+Max">Max</a></code>,
<code><a href="#topic+Tol">Tol</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(111)  # This leads to the global solution
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Standardized environmental vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          family = poissonff, data = hspider, Crow1positive = FALSE)
Opt(p1)

## Not run: 
clr &lt;- (1:(ncol(depvar(p1))+1))[-7]  # Omits yellow
persp(p1, col = clr, las = 1, main = "Vertical lines at the optimums")
abline(v = Opt(p1), lty = 2, col = clr)

## End(Not run)
</code></pre>

<hr>
<h2 id='ordpoisson'> Ordinal Poisson Family Function </h2><span id='topic+ordpoisson'></span>

<h3>Description</h3>

<p>Fits a Poisson regression where the response is ordinal
(the Poisson counts are grouped between known cutpoints).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordpoisson(cutpoints, countdata = FALSE, NOS = NULL,
           Levels = NULL, init.mu = NULL, parallel = FALSE,
           zero = NULL, link = "loglink")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordpoisson_+3A_cutpoints">cutpoints</code></td>
<td>

<p>Numeric. The cutpoints, <code class="reqn">K_l</code>.
These must be non-negative integers.
<code>Inf</code> values may be included.
See below for further details.
</p>
</td></tr>
<tr><td><code id="ordpoisson_+3A_countdata">countdata</code></td>
<td>

<p>Logical. Is the response (LHS of formula) in count-data format?
If not then the response is a matrix or vector with values <code>1</code>,
<code>2</code>, ..., <code>L</code>, say, where <code>L</code> is the number of
levels. Such input can be generated with <code><a href="base.html#topic+cut">cut</a></code>
with argument <code>labels = FALSE</code>.  If <code>countdata = TRUE</code> then
the response is expected to be in the same format as <code>depvar(fit)</code>
where <code>fit</code> is a fitted model with <code>ordpoisson</code> as the
<span class="pkg">VGAM</span> family function. That is, the response is matrix of counts
with <code>L</code> columns (if <code>NOS = 1</code>).
</p>
</td></tr>
<tr><td><code id="ordpoisson_+3A_nos">NOS</code></td>
<td>

<p>Integer. The number of species, or more generally, the number of
response random variates.
This argument must be specified when <code>countdata = TRUE</code>.
Usually <code>NOS = 1</code>.
</p>
</td></tr>
<tr><td><code id="ordpoisson_+3A_levels">Levels</code></td>
<td>

<p>Integer vector, recycled to length <code>NOS</code> if necessary.
The number of levels for each response random variate.
This argument should agree with <code>cutpoints</code>.
This argument must be specified when <code>countdata = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ordpoisson_+3A_init.mu">init.mu</code></td>
<td>

<p>Numeric. Initial values for the means of the Poisson regressions.
Recycled to length <code>NOS</code> if necessary.
Use this argument if the default initial values fail (the
default is to compute an initial value internally).
</p>
</td></tr>
<tr><td><code id="ordpoisson_+3A_parallel">parallel</code>, <code id="ordpoisson_+3A_zero">zero</code>, <code id="ordpoisson_+3A_link">link</code></td>
<td>

<p>See <code><a href="#topic+poissonff">poissonff</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <span class="pkg">VGAM</span> family function uses maximum likelihood estimation
(Fisher scoring)
to fit a Poisson regression to each column of a matrix response.
The data, however, is ordinal, and is obtained from known integer
cutpoints.
Here, <code class="reqn">l=1,\ldots,L</code> where <code class="reqn">L</code> (<code class="reqn">L \geq 2</code>)
is the number of levels.
In more detail, let
<code class="reqn">Y^*=l</code> if <code class="reqn">K_{l-1} &lt; Y \leq K_{l}</code> where the <code class="reqn">K_l</code> are the cutpoints.
We have <code class="reqn">K_0=-\infty</code> and <code class="reqn">K_L=\infty</code>.
The response for this family function corresponds to <code class="reqn">Y^*</code> but
we are really interested in the Poisson regression of <code class="reqn">Y</code>.
</p>
<p>If <code>NOS=1</code> then
the argument <code>cutpoints</code> is a vector <code class="reqn">(K_1,K_2,\ldots,K_L)</code>
where the last value (<code>Inf</code>) is optional. If <code>NOS&gt;1</code> then
the vector should have <code>NOS-1</code> <code>Inf</code> values separating
the cutpoints. For example, if there are <code>NOS=3</code> responses, then
something like
<code>ordpoisson(cut = c(0, 5, 10, Inf, 20, 30, Inf, 0, 10, 40, Inf))</code>
is valid.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The input requires care as little to no checking is done.
If <code>fit</code> is the fitted object, have a look at <code>fit@extra</code> and
<code>depvar(fit)</code> to check.
</p>


<h3>Note</h3>

<p>Sometimes there are no observations between two cutpoints. If so,
the arguments <code>Levels</code> and <code>NOS</code> need to be specified too.
See below for an example.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2020).
<em>Ordinal ordination with normalizing link functions for count data</em>,
(in preparation).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+polf">polf</a></code>,
<code><a href="base.html#topic+factor">ordered</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)  # Example 1
x2 &lt;- runif(n &lt;- 1000); x3 &lt;- runif(n)
mymu &lt;- exp(3 - 1 * x2 + 2 * x3)
y1 &lt;- rpois(n, lambda = mymu)
cutpts &lt;- c(-Inf, 20, 30, Inf)
fcutpts &lt;- cutpts[is.finite(cutpts)]  # finite cutpoints
ystar &lt;- cut(y1, breaks = cutpts, labels = FALSE)
## Not run: 
plot(x2, x3, col = ystar, pch = as.character(ystar))

## End(Not run)
table(ystar) / sum(table(ystar))
fit &lt;- vglm(ystar ~ x2 + x3, fam = ordpoisson(cutpoi = fcutpts))
head(depvar(fit))  # This can be input if countdata = TRUE
head(fitted(fit))
head(predict(fit))
coef(fit, matrix = TRUE)
fit@extra

# Example 2: multivariate and there are no obsns between some cutpoints
cutpts2 &lt;- c(-Inf, 0, 9, 10, 20, 70, 200, 201, Inf)
fcutpts2 &lt;- cutpts2[is.finite(cutpts2)]  # finite cutpoints
y2 &lt;- rpois(n, lambda = mymu)   # Same model as y1
ystar2 &lt;- cut(y2, breaks = cutpts2, labels = FALSE)
table(ystar2) / sum(table(ystar2))
fit &lt;- vglm(cbind(ystar,ystar2) ~ x2 + x3, fam =
            ordpoisson(cutpoi = c(fcutpts,Inf,fcutpts2,Inf),
                       Levels = c(length(fcutpts)+1,length(fcutpts2)+1),
                       parallel = TRUE), trace = TRUE)
coef(fit, matrix = TRUE)
fit@extra
constraints(fit)
summary(depvar(fit))  # Some columns have all zeros
</code></pre>

<hr>
<h2 id='ordsup'> Ordinal Superiority
Measures </h2><span id='topic+ordsup'></span><span id='topic+ordsup.vglm'></span>

<h3>Description</h3>

<p>Ordinal superiority measures for the linear model
and cumulative link models: 
the probability that an observation from one
distribution falls above an independent observation
from the other distribution,
adjusted for explanatory variables in a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordsup(object, ...)
ordsup.vglm(object, all.vars = FALSE, confint = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ordsup_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+vglm">vglm</a></code> fit.
Currently it must be one of:
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>.
The links for <code><a href="#topic+cumulative">cumulative</a></code> must be
<code><a href="#topic+logitlink">logitlink</a></code> or <code><a href="#topic+probitlink">probitlink</a></code>,
and <code>parallel = TRUE</code> is also needed.
For <code><a href="#topic+uninormal">uninormal</a></code> the mean must
use <code><a href="#topic+identitylink">identitylink</a></code> and model the
<code>sd</code> as intercept-only.
</p>


</td></tr>
<tr><td><code id="ordsup_+3A_all.vars">all.vars</code></td>
<td>

<p>Logical. The default is to use explanatory variables
which are binary, but all variables are used (except the intercept)
if set to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ordsup_+3A_confint">confint</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then <code><a href="#topic+confintvglm">confintvglm</a></code>
is called to return confidence intervals for
<code class="reqn">\gamma</code> and
<code class="reqn">\Delta</code>.
By default, Wald intervals are produced, but they
can be replaced by profile intervals by setting
<code>method = "profile"</code>.
</p>

</td></tr>
<tr><td><code id="ordsup_+3A_...">...</code></td>
<td>

<p>Parameters that can be fed into <code><a href="#topic+confintvglm">confintvglm</a></code>,
e.g., <code>level = 0.95</code> and
<code>method = c("wald", "profile")</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Details are given in Agresti and Kateri (2017) and this help
file draws directly from this.
This function returns two quantities for comparing two groups
on an ordinal categorical response variable, while adjusting
for other explanatory variables.
They are called &ldquo;ordinal superiority&rdquo; measures, and
the two groups can be compared without supplementary
explanatory variables.
Let <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> be independent random
variables from groups A and B, say, for a quantitative ordinal
categorical scale. Then
<code class="reqn">\Delta = P(Y_1 &gt; Y_2) -
    P(Y_2 &gt; Y_1)</code> 
summarizes their relative size.
A second quantity is
<code class="reqn">\gamma = P(Y_1 &gt; Y_2) -
    0.5 \times P(Y_2 = Y_1)</code>.
Then <code class="reqn">\Delta=2 \times \gamma - 1</code>.
whereas <code class="reqn">\gamma=(\Delta + 1)/2</code>.
The range of <code class="reqn">\gamma</code> is <code class="reqn">[0, 1]</code>, while
the range of <code class="reqn">\Delta</code> is <code class="reqn">[-1, 1]</code>.
The examples below are based on that paper.
This function is currently implemented for a very limited
number of specific models.
</p>


<h3>Value</h3>

<p>By default,
a list with components
<code>gamma</code> and
<code>Delta</code>,
where each is a vector with elements corresponding to
binary explanatory variables (i.e., 0 or 1),
and if no explanatory variables are binary then a
<code>NULL</code> is returned.
If <code>confint = TRUE</code> then the list contains 4 more components:
<code>lower.gamma</code>,
<code>upper.gamma</code>,
<code>Lower.Delta</code>,
<code>Upper.Delta</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Agresti, A. and Kateri, M. (2017).
Ordinal probability effect measures for group
comparisons in multinomial cumulative link models.
<em>Biometrics</em>, <b>73</b>, 214&ndash;219.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+propodds">propodds</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Mental &lt;- read.table("http://www.stat.ufl.edu/~aa/glm/data/Mental.dat",
                     header = TRUE)  # Make take a while to load in
Mental$impair &lt;- ordered(Mental$impair)
pfit3 &lt;- vglm(impair ~ ses + life, data = Mental,
         cumulative(link = "probitlink", reverse = FALSE, parallel = TRUE))
coef(pfit3, matrix = TRUE)
ordsup(pfit3)  # The 'ses' variable is binary

# Fit a crude LM
fit7 &lt;- vglm(as.numeric(impair) ~ ses + life, uninormal, data = Mental)
coef(fit7, matrix = TRUE)  # 'sd' is estimated by MLE
ordsup(fit7)
ordsup(fit7, all.vars = TRUE)  # Some output may not be meaningful
ordsup(fit7, confint = TRUE, method = "profile")

## End(Not run)
</code></pre>

<hr>
<h2 id='oxtemp'> Oxford Temperature Data </h2><span id='topic+oxtemp'></span>

<h3>Description</h3>

<p>Annual maximum temperatures collected at Oxford, UK.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(oxtemp)</code></pre>


<h3>Format</h3>

<p>A data frame with 80 observations on the following 2 variables.
</p>

<dl>
<dt>maxtemp</dt><dd><p>Annual maximum temperatures (in degrees Fahrenheit). </p>
</dd>
<dt>year</dt><dd><p>The values 1901 to 1980. </p>
</dd>
</dl>



<h3>Details</h3>

<p>The data were collected from 1901 to 1980.
</p>


<h3>Source</h3>

<p>Unknown.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  fit &lt;- vglm(maxtemp ~ 1, gevff, data = oxtemp, trace = TRUE) 
</code></pre>

<hr>
<h2 id='paralogistic'> Paralogistic Distribution Family Function </h2><span id='topic+paralogistic'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
paralogistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paralogistic(lscale = "loglink", lshape1.a = "loglink", iscale = NULL,
    ishape1.a = NULL, imethod = 1, lss = TRUE, gscale = exp(-5:5),
    gshape1.a = seq(0.75, 4, by = 0.25), probs.y = c(0.25, 0.5, 0.75),
    zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paralogistic_+3A_lss">lss</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for important information.
</p>
</td></tr>
<tr><td><code id="paralogistic_+3A_lshape1.a">lshape1.a</code>, <code id="paralogistic_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code class="reqn">a</code> and <code>scale</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="paralogistic_+3A_iscale">iscale</code>, <code id="paralogistic_+3A_ishape1.a">ishape1.a</code>, <code id="paralogistic_+3A_imethod">imethod</code>, <code id="paralogistic_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>ishape1.a</code> is needed to obtain good estimates for
the other parameter.
</p>
</td></tr>
<tr><td><code id="paralogistic_+3A_gscale">gscale</code>, <code id="paralogistic_+3A_gshape1.a">gshape1.a</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="paralogistic_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 2-parameter paralogistic distribution is the 4-parameter
generalized beta II distribution with shape parameter <code class="reqn">p=1</code> and
<code class="reqn">a=q</code>.
It is the 3-parameter Singh-Maddala distribution with <code class="reqn">a=q</code>.
More details can be found in Kleiber and Kotz (2003).
</p>
<p>The 2-parameter paralogistic has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = a^2 y^{a-1} / [b^a \{1 + (y/b)^a\}^{1+a}]</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and <code class="reqn">a</code> is the shape parameter.
The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(1 + 1/a) \, \Gamma(a - 1/a) / \Gamma(a)</code>
</p>

<p>provided <code class="reqn">a &gt; 1</code>; these are returned as the fitted values.
This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Paralogistic">Paralogistic</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pdata &lt;- data.frame(y = rparalogistic(n = 3000, exp(1), scale = exp(1)))
fit &lt;- vglm(y ~ 1, paralogistic(lss = FALSE), data = pdata, trace = TRUE)
fit &lt;- vglm(y ~ 1, paralogistic(ishape1.a = 2.3, iscale = 5),
            data = pdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Paralogistic'>The Paralogistic Distribution</h2><span id='topic+Paralogistic'></span><span id='topic+dparalogistic'></span><span id='topic+pparalogistic'></span><span id='topic+qparalogistic'></span><span id='topic+rparalogistic'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the paralogistic distribution with shape parameter
<code>a</code> and scale parameter <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dparalogistic(x, scale = 1, shape1.a, log = FALSE)
pparalogistic(q, scale = 1, shape1.a, lower.tail = TRUE, log.p = FALSE)
qparalogistic(p, scale = 1, shape1.a, lower.tail = TRUE, log.p = FALSE)
rparalogistic(n, scale = 1, shape1.a)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Paralogistic_+3A_x">x</code>, <code id="Paralogistic_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Paralogistic_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Paralogistic_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length
is taken to be the number required.</p>
</td></tr>
<tr><td><code id="Paralogistic_+3A_shape1.a">shape1.a</code></td>
<td>
<p>shape parameter.</p>
</td></tr>
<tr><td><code id="Paralogistic_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Paralogistic_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log=TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Paralogistic_+3A_lower.tail">lower.tail</code>, <code id="Paralogistic_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+paralogistic">paralogistic</a></code>, which is the <span class="pkg">VGAM</span> family function
for estimating the parameters by maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>dparalogistic</code> gives the density,
<code>pparalogistic</code> gives the distribution function,
<code>qparalogistic</code> gives the quantile function, and
<code>rparalogistic</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The paralogistic distribution is a special case of the 4-parameter
generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pdata &lt;- data.frame(y = rparalogistic(n = 3000, scale = exp(1), exp(2)))
fit &lt;- vglm(y ~ 1, paralogistic(lss = FALSE, ishape1.a = 4.1),
            data = pdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='Pareto'>The Pareto Distribution</h2><span id='topic+Pareto'></span><span id='topic+dpareto'></span><span id='topic+ppareto'></span><span id='topic+qpareto'></span><span id='topic+rpareto'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Pareto(I) distribution with parameters
<code>scale</code> and <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpareto(x, scale = 1, shape, log = FALSE)
ppareto(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qpareto(p, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
rpareto(n, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pareto_+3A_x">x</code>, <code id="Pareto_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Pareto_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Pareto_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Pareto_+3A_scale">scale</code>, <code id="Pareto_+3A_shape">shape</code></td>
<td>
<p>the <code class="reqn">\alpha</code> and <code class="reqn">k</code> parameters.</p>
</td></tr>
<tr><td><code id="Pareto_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Pareto_+3A_lower.tail">lower.tail</code>, <code id="Pareto_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+paretoff">paretoff</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter <code class="reqn">k</code> by maximum likelihood estimation,
for the formula of the probability density function and the
range restrictions imposed on the parameters.
</p>


<h3>Value</h3>

<p><code>dpareto</code> gives the density,
<code>ppareto</code> gives the distribution function,
<code>qpareto</code> gives the quantile function, and
<code>rpareto</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paretoff">paretoff</a></code>,
<code><a href="#topic+ParetoIV">ParetoIV</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alpha &lt;- 3; k &lt;- exp(1); x &lt;- seq(2.8, 8, len = 300)
## Not run: 
plot(x, dpareto(x, scale = alpha, shape = k), type = "l",
     main = "Pareto density split into 10 equal areas")
abline(h = 0, col = "blue", lty = 2)
qvec &lt;- qpareto(seq(0.1, 0.9, by = 0.1), scale = alpha, shape = k)
lines(qvec, dpareto(qvec, scale = alpha, shape = k),
      col = "purple", lty = 3, type = "h")

## End(Not run)
pvec &lt;- seq(0.1, 0.9, by = 0.1)
qvec &lt;- qpareto(pvec, scale = alpha, shape = k)
ppareto(qvec, scale = alpha, shape = k)
qpareto(ppareto(qvec, scale = alpha, shape = k),
        scale = alpha, shape = k) - qvec  # Should be 0
</code></pre>

<hr>
<h2 id='paretoff'>Pareto and Truncated Pareto Distribution Family Functions </h2><span id='topic+paretoff'></span><span id='topic+truncpareto'></span>

<h3>Description</h3>

<p>Estimates one of the parameters of the Pareto(I) distribution
by maximum likelihood estimation.
Also includes the upper truncated Pareto(I) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paretoff(scale = NULL, lshape = "loglink")
truncpareto(lower, upper, lshape = "loglink", ishape = NULL, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paretoff_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function applied to the parameter <code class="reqn">k</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
A log link is the default because <code class="reqn">k</code> is positive.
</p>
</td></tr>
<tr><td><code id="paretoff_+3A_scale">scale</code></td>
<td>

<p>Numeric.
The parameter <code class="reqn">\alpha</code> below.
If the user inputs a number then it is assumed known with this value.
The default means it is estimated by maximum likelihood
estimation, which means <code>min(y)</code> is used,
where <code>y</code> is the response vector.
</p>
</td></tr>
<tr><td><code id="paretoff_+3A_lower">lower</code>, <code id="paretoff_+3A_upper">upper</code></td>
<td>

<p>Numeric.
Lower and upper limits for the truncated Pareto distribution.
Each must be positive and of length 1.
They are called <code class="reqn">\alpha</code> and <code class="reqn">U</code> below.
</p>
</td></tr>
<tr><td><code id="paretoff_+3A_ishape">ishape</code></td>
<td>

<p>Numeric.
Optional initial value for the shape parameter.
A <code>NULL</code> means a value is obtained internally.
If failure to converge occurs try specifying a value, e.g., 1 or 2.
</p>
</td></tr>
<tr><td><code id="paretoff_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
If failure to converge occurs then try specifying a value for
<code>ishape</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A random variable <code class="reqn">Y</code> has a Pareto distribution if
</p>
<p style="text-align: center;"><code class="reqn">P[Y&gt;y] = C / y^{k}</code>
</p>

<p>for some positive <code class="reqn">k</code> and <code class="reqn">C</code>.
This model is important in many applications due to the power
law probability tail, especially for large values of <code class="reqn">y</code>.
</p>
<p>The Pareto distribution, which is used a lot in economics,
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y;\alpha,k) = k  \alpha^k / y^{k+1}</code>
</p>

<p>for <code class="reqn">0 &lt; \alpha &lt; y</code> and <code class="reqn">0&lt;k</code>.
The <code class="reqn">\alpha</code> is called the <em>scale</em> parameter, and
it is either assumed <em>known</em> or else <code>min(y)</code> is used.
The parameter <code class="reqn">k</code> is called the <em>shape</em> parameter.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\alpha k/(k-1)</code> provided <code class="reqn">k &gt; 1</code>.
Its variance is
<code class="reqn">\alpha^2 k /((k-1)^2 (k-2))</code>
provided <code class="reqn">k &gt; 2</code>.
</p>
<p>The upper truncated Pareto distribution
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = k \alpha^k / [y^{k+1} (1-(\alpha/U)^k)]</code>
</p>

<p>for <code class="reqn">0 &lt; \alpha &lt; y &lt; U &lt; \infty</code>
and <code class="reqn">k&gt;0</code>.
Possibly, better names for <code class="reqn">k</code> are
the <em>index</em> and <em>tail</em> parameters.
Here, <code class="reqn">\alpha</code> and <code class="reqn">U</code> are known.
The mean of <code class="reqn">Y</code> is
<code class="reqn">k \alpha^k (U^{1-k}-\alpha^{1-k}) /
       [(1-k)(1-(\alpha/U)^k)]</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The usual or unbounded Pareto distribution has two
parameters (called <code class="reqn">\alpha</code> and <code class="reqn">k</code> here)
but the family function <code>paretoff</code> estimates only
<code class="reqn">k</code> using iteratively reweighted least squares.
The MLE of the <code class="reqn">\alpha</code> parameter lies on the
boundary and is <code>min(y)</code> where <code>y</code> is the
response. Consequently, using the default argument
values, the standard errors are incorrect when one does a
<code>summary</code> on the fitted object. If the user inputs
a value for <code>alpha</code> then it is assumed known with
this value and then <code>summary</code> on the fitted object
should be correct. Numerical problems may occur for small
<code class="reqn">k</code>, e.g., <code class="reqn">k &lt; 1</code>.
</p>


<h3>Note</h3>

<p>Outside of economics, the Pareto distribution is known as the
Bradford distribution.
</p>
<p>For <code>paretoff</code>,
if the estimate of <code class="reqn">k</code> is less than or equal to unity
then the fitted values will be <code>NA</code>s.
Also, <code>paretoff</code> fits the Pareto(I) distribution.
See <code><a href="#topic+paretoIV">paretoIV</a></code> for the more general Pareto(IV/III/II)
distributions, but there is a slight change in notation: <code class="reqn">s = k</code>
and <code class="reqn">b=\alpha</code>.
</p>
<p>In some applications the Pareto law is truncated by a
natural upper bound on the probability tail.
The upper truncated Pareto distribution has three parameters (called
<code class="reqn">\alpha</code>, <code class="reqn">U</code> and <code class="reqn">k</code> here) but the family function
<code>truncpareto()</code> estimates only <code class="reqn">k</code>.
With known lower and upper limits, the ML estimator of <code class="reqn">k</code> has
the usual properties of MLEs.
Aban (2006) discusses other inferential details.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>
<p>Aban, I. B., Meerschaert, M. M. and Panorska, A. K. (2006).
Parameter estimation for the truncated Pareto distribution,
<em>Journal of the American Statistical Association</em>,
<b>101</b>(473),
270&ndash;277.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Pareto">Pareto</a></code>,
<code><a href="#topic+Truncpareto">Truncpareto</a></code>,
<code><a href="#topic+paretoIV">paretoIV</a></code>,
<code><a href="#topic+gpd">gpd</a></code>,
<code><a href="#topic+benini1">benini1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alpha &lt;- 2; kay &lt;- exp(3)
pdata &lt;- data.frame(y = rpareto(n = 1000, scale = alpha, shape = kay))
fit &lt;- vglm(y ~ 1, paretoff, data = pdata, trace = TRUE)
fit@extra  # The estimate of alpha is here
head(fitted(fit))
with(pdata, mean(y))
coef(fit, matrix = TRUE)
summary(fit)  # Standard errors are incorrect!!

# Here, alpha is assumed known
fit2 &lt;- vglm(y ~ 1, paretoff(scale = alpha), data = pdata, trace = TRUE)
fit2@extra  # alpha stored here
head(fitted(fit2))
coef(fit2, matrix = TRUE)
summary(fit2)  # Standard errors are okay

# Upper truncated Pareto distribution
lower &lt;- 2; upper &lt;- 8; kay &lt;- exp(2)
pdata3 &lt;- data.frame(y = rtruncpareto(n = 100, lower = lower,
                                      upper = upper, shape = kay))
fit3 &lt;- vglm(y ~ 1, truncpareto(lower, upper), data = pdata3, trace = TRUE)
coef(fit3, matrix = TRUE)
c(fit3@misc$lower, fit3@misc$upper)
</code></pre>

<hr>
<h2 id='paretoIV'>Pareto(IV/III/II) Distribution Family Functions </h2><span id='topic+paretoIV'></span><span id='topic+paretoIII'></span><span id='topic+paretoII'></span>

<h3>Description</h3>

<p>Estimates three of the parameters of the Pareto(IV) distribution
by maximum likelihood estimation. Some special cases of this
distribution are also handled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paretoIV(location = 0, lscale = "loglink", linequality = "loglink",
         lshape = "loglink", iscale = 1, iinequality = 1, ishape = NULL,
         imethod = 1)
paretoIII(location = 0, lscale = "loglink", linequality = "loglink",
          iscale = NULL, iinequality = NULL)
paretoII(location = 0, lscale = "loglink", lshape = "loglink",
         iscale = NULL, ishape = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paretoIV_+3A_location">location</code></td>
<td>

<p>Location parameter, called <code class="reqn">a</code> below.
It is assumed known.
</p>
</td></tr>
<tr><td><code id="paretoIV_+3A_lscale">lscale</code>, <code id="paretoIV_+3A_linequality">linequality</code>, <code id="paretoIV_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions for the
scale parameter (called <code class="reqn">b</code> below),
inequality parameter (called <code class="reqn">g</code> below), and
shape parameter (called <code class="reqn">s</code> below).
See <code><a href="#topic+Links">Links</a></code> for more choices.
A log link is the default for all because all these parameters are
positive.
</p>
</td></tr>
<tr><td><code id="paretoIV_+3A_iscale">iscale</code>, <code id="paretoIV_+3A_iinequality">iinequality</code>, <code id="paretoIV_+3A_ishape">ishape</code></td>
<td>

<p>Initial values for the parameters.
A <code>NULL</code> value means that it is obtained internally.
If convergence failure occurs, use these arguments to input
some alternative initial values.
</p>
</td></tr>
<tr><td><code id="paretoIV_+3A_imethod">imethod</code></td>
<td>

<p>Method of initialization for the shape parameter.
Currently only values 1 and 2 are available.
Try the other value if convergence failure occurs.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Pareto(IV) distribution, which is used in actuarial science,
economics, finance and telecommunications,
has a cumulative distribution function that can be written
</p>
<p style="text-align: center;"><code class="reqn">F(y) = 1 - [1 + ((y-a)/b)^{1/g}]^{-s}</code>
</p>

<p>for <code class="reqn">y &gt; a</code>, <code class="reqn">b&gt;0</code>, <code class="reqn">g&gt;0</code> and <code class="reqn">s&gt;0</code>.
The <code class="reqn">a</code> is called the <em>location</em> parameter,
<code class="reqn">b</code> the <em>scale</em> parameter,
<code class="reqn">g</code> the <em>inequality</em> parameter, and
<code class="reqn">s</code> the <em>shape</em> parameter.
</p>
<p>The location parameter is assumed known otherwise the
Pareto(IV) distribution will not be a regular family.
This assumption is not too restrictive in modelling
because in typical applications this parameter is known,
e.g., in insurance and reinsurance it is pre-defined by
a contract and can be represented as a deductible or a
retention level.
</p>
<p>The inequality parameter is so-called because of its
interpretation in the economics context. If we choose a
unit shape parameter value and a zero location parameter
value then the inequality parameter is the Gini index of
inequality, provided <code class="reqn">g \leq 1</code>.
</p>
<p>The fitted values are currently the median, e.g.,
<code><a href="#topic+qparetoIV">qparetoIV</a></code> is used for <code>paretoIV()</code>.
</p>









<p>There are a number of special cases of the Pareto(IV) distribution.
These include the Pareto(I), Pareto(II), Pareto(III), and Burr family
of distributions.
Denoting <code class="reqn">PIV(a,b,g,s)</code> as the Pareto(IV) distribution,
the Burr distribution <code class="reqn">Burr(b,g,s)</code> is <code class="reqn">PIV(a=0,b,1/g,s)</code>,
the Pareto(III) distribution <code class="reqn">PIII(a,b,g)</code> is <code class="reqn">PIV(a,b,g,s=1)</code>,
the Pareto(II) distribution <code class="reqn">PII(a,b,s)</code> is <code class="reqn">PIV(a,b,g=1,s)</code>,
and
the Pareto(I) distribution <code class="reqn">PI(b,s)</code> is <code class="reqn">PIV(b,b,g=1,s)</code>.
Thus the Burr distribution can be fitted using the
<code><a href="#topic+negloglink">negloglink</a></code> link
function and using the default <code>location=0</code> argument.
The Pareto(I) distribution can be fitted using <code><a href="#topic+paretoff">paretoff</a></code>
but there is a slight change in notation: <code class="reqn">s=k</code> and
<code class="reqn">b=\alpha</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The Pareto(IV) distribution is very general,
for example, special cases include the Pareto(I), Pareto(II),
Pareto(III), and Burr family of distributions.
[Johnson et al. (1994) says on p.19 that fitting Type IV by ML is
very difficult and rarely attempted].
Consequently, reasonably good initial values are recommended,
and convergence to a local solution may occur. For this
reason setting <code>trace=TRUE</code> is a good idea for monitoring
the convergence.  Large samples are ideally required to get
reasonable results.
</p>


<h3>Note</h3>

<p>The <code>extra</code> slot of the fitted object has a component called
<code>"location"</code> which stores the location parameter value(s).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson N. L., Kotz S., and Balakrishnan N. (1994).
<em>Continuous Univariate Distributions, Volume 1</em>,
2nd ed.
New York: Wiley.
</p>
<p>Brazauskas, V. (2003).
Information matrix for Pareto(IV), Burr, and related distributions.
<em>Comm. Statist. Theory and Methods</em>
<b>32</b>, 315&ndash;325.
</p>
<p>Arnold, B. C. (1983).
<em>Pareto Distributions</em>.
Fairland, Maryland: International Cooperative Publishing House.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ParetoIV">ParetoIV</a></code>,
<code><a href="#topic+paretoff">paretoff</a></code>,
<code><a href="#topic+gpd">gpd</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pdata &lt;- data.frame(y = rparetoIV(2000, scale = exp(1),
                                  ineq = exp(-0.3), shape = exp(1)))
## Not run: par(mfrow = c(2, 1))
with(pdata, hist(y)); with(pdata, hist(log(y))) 
## End(Not run)
fit &lt;- vglm(y ~ 1, paretoIV, data = pdata, trace = TRUE)
head(fitted(fit))
summary(pdata)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='ParetoIV'>The Pareto(IV/III/II) Distributions</h2><span id='topic+ParetoIV'></span><span id='topic+dparetoIV'></span><span id='topic+pparetoIV'></span><span id='topic+qparetoIV'></span><span id='topic+rparetoIV'></span><span id='topic+ParetoIII'></span><span id='topic+dparetoIII'></span><span id='topic+pparetoIII'></span><span id='topic+qparetoIII'></span><span id='topic+rparetoIII'></span><span id='topic+ParetoII'></span><span id='topic+dparetoII'></span><span id='topic+pparetoII'></span><span id='topic+qparetoII'></span><span id='topic+rparetoII'></span><span id='topic+ParetoI'></span><span id='topic+dparetoI'></span><span id='topic+pparetoI'></span><span id='topic+qparetoI'></span><span id='topic+rparetoI'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Pareto(IV/III/II) distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dparetoIV(x, location = 0, scale = 1, inequality = 1, shape = 1,
          log = FALSE)
pparetoIV(q, location = 0, scale = 1, inequality = 1, shape = 1,
          lower.tail = TRUE, log.p = FALSE)
qparetoIV(p, location = 0, scale = 1, inequality = 1, shape = 1,
          lower.tail = TRUE, log.p = FALSE)
rparetoIV(n, location = 0, scale = 1, inequality = 1, shape = 1)
dparetoIII(x, location = 0, scale = 1, inequality = 1, log = FALSE)
pparetoIII(q, location = 0, scale = 1, inequality = 1,
           lower.tail = TRUE, log.p = FALSE)
qparetoIII(p, location = 0, scale = 1, inequality = 1,
           lower.tail = TRUE, log.p = FALSE)
rparetoIII(n, location = 0, scale = 1, inequality = 1)
dparetoII(x, location = 0, scale = 1, shape = 1, log = FALSE)
pparetoII(q, location = 0, scale = 1, shape = 1,
          lower.tail = TRUE, log.p = FALSE)
qparetoII(p, location = 0, scale = 1, shape = 1,
          lower.tail = TRUE, log.p = FALSE)
rparetoII(n, location = 0, scale = 1, shape = 1)
dparetoI(x, scale = 1, shape = 1, log = FALSE)
pparetoI(q, scale = 1, shape = 1,
         lower.tail = TRUE, log.p = FALSE)
qparetoI(p, scale = 1, shape = 1,
         lower.tail = TRUE, log.p = FALSE)
rparetoI(n, scale = 1, shape = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ParetoIV_+3A_x">x</code>, <code id="ParetoIV_+3A_q">q</code></td>
<td>
<p>vector of quantiles. </p>
</td></tr>
<tr><td><code id="ParetoIV_+3A_p">p</code></td>
<td>
<p>vector of probabilities. </p>
</td></tr>
<tr><td><code id="ParetoIV_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>

</td></tr>
<tr><td><code id="ParetoIV_+3A_location">location</code></td>
<td>
<p>the location parameter. </p>
</td></tr>
<tr><td><code id="ParetoIV_+3A_scale">scale</code>, <code id="ParetoIV_+3A_shape">shape</code>, <code id="ParetoIV_+3A_inequality">inequality</code></td>
<td>
<p>the (positive) scale,
inequality and shape parameters. </p>
</td></tr>
<tr><td><code id="ParetoIV_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="ParetoIV_+3A_lower.tail">lower.tail</code>, <code id="ParetoIV_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the formulas and other details
see <code><a href="#topic+paretoIV">paretoIV</a></code>.
</p>


<h3>Value</h3>

<p>Functions beginning with the
letters <code>d</code> give the density,
<code>p</code> give the distribution function,
<code>q</code> give the quantile function, and
<code>r</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The functions <code>[dpqr]paretoI</code> are the same as
<code>[dpqr]pareto</code> except for a slight change in notation:
<code class="reqn">s=k</code> and <code class="reqn">b=\alpha</code>; see <code><a href="#topic+Pareto">Pareto</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Brazauskas, V. (2003).
Information matrix for Pareto(IV), Burr, and related
distributions.
<em>Comm. Statist. Theory and Methods</em>
<b>32</b>, 315&ndash;325.
</p>
<p>Arnold, B. C. (1983).
<em>Pareto Distributions</em>.
Fairland, Maryland: International Cooperative Publishing House.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paretoIV">paretoIV</a></code>,
<code><a href="#topic+Pareto">Pareto</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(-0.2, 4, by = 0.01)
loc &lt;- 0; Scale &lt;- 1; ineq &lt;- 1; shape &lt;- 1.0
plot(x, dparetoIV(x, loc, Scale, ineq, shape), type = "l",
     main = "Blue is density, orange is the CDF", col = "blue",
     sub = "Purple are 5,10,...,95 percentiles", ylim = 0:1,
     las = 1, ylab = "")
abline(h = 0, col = "blue", lty = 2)
Q &lt;- qparetoIV(seq(0.05, 0.95,by = 0.05), loc, Scale, ineq, shape)
lines(Q, dparetoIV(Q, loc, Scale, ineq, shape), col = "purple",
      lty = 3, type = "h")
lines(x, pparetoIV(x, loc, Scale, ineq, shape), col = "orange")
abline(h = 0, lty = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='perks'> Perks Distribution Family Function </h2><span id='topic+perks'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 2-parameter
Perks distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perks(lscale = "loglink", lshape = "loglink",
      iscale = NULL,   ishape = NULL,
      gscale = exp(-5:5), gshape = exp(-5:5),
      nsimEIM = 500, oim.mean = FALSE, zero = NULL,
      nowarning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perks_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning?
Ignored for <span class="pkg">VGAM</span> 0.9-7 and higher.
</p>
</td></tr>
<tr><td><code id="perks_+3A_lscale">lscale</code>, <code id="perks_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions applied to the
shape parameter <code>shape</code>,
scale parameter <code>scale</code>.
All parameters are treated as positive here
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="perks_+3A_iscale">iscale</code>, <code id="perks_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial values.
A <code>NULL</code> means a value is computed internally.
</p>
</td></tr>
<tr><td><code id="perks_+3A_gscale">gscale</code>, <code id="perks_+3A_gshape">gshape</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="perks_+3A_nsimeim">nsimEIM</code>, <code id="perks_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="perks_+3A_oim.mean">oim.mean</code></td>
<td>

<p>To be currently ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Perks distribution
has cumulative distribution function
</p>
<p style="text-align: center;"><code class="reqn">F(y; \alpha, \beta) =
1 -
\left\{
\frac{1 + \alpha}{1 + \alpha e^{\beta y}}
\right\}^{1 / \beta}
</code>
</p>

<p>which leads to a probability density function
</p>
<p style="text-align: center;"><code class="reqn">f(y; \alpha, \beta) =
\left[ 1 + \alpha \right]^{1 / \beta}
\alpha  e^{\beta y} / (1 + \alpha e^{\beta y})^{1 + 1 / \beta}
</code>
</p>

<p>for <code class="reqn">\alpha &gt; 0</code>,
<code class="reqn">\beta &gt; 0</code>,
<code class="reqn">y &gt; 0</code>.
Here, <code class="reqn">\beta</code> is called the scale parameter <code>scale</code>,
and <code class="reqn">\alpha</code> is called a shape parameter.
The moments for this distribution do
not appear to be available in closed form.
</p>
<p>Simulated Fisher scoring is used and multiple responses are handled.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>A lot of care is needed because
this is a rather difficult distribution for parameter estimation.
If the self-starting initial values fail then try experimenting
with the initial value arguments, especially <code>iscale</code>.
Successful convergence depends on having very good initial values.
Also, monitor convergence by setting <code>trace = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Perks, W. (1932).
On some experiments in the graduation of mortality statistics.
<em>Journal of the Institute of Actuaries</em>,
<b>63</b>, 12&ndash;40.
</p>
<p>Richards, S. J. (2012).
A handbook of parametric survival models for actuarial use.
<em>Scandinavian Actuarial Journal</em>.
1&ndash;25.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dperks">dperks</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  set.seed(123)
pdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))  # x2 unused
pdata &lt;- transform(pdata, eta1  = -1,
                          ceta1 =  1)
pdata &lt;- transform(pdata, shape1 = exp(eta1),
                          scale1 = exp(ceta1))
pdata &lt;- transform(pdata, y1 = rperks(nn, sh = shape1, sc = scale1))
fit1 &lt;- vglm(y1 ~ 1, perks, data = pdata, trace = TRUE)
coef(fit1, matrix = TRUE)
summary(fit1)

## End(Not run)
</code></pre>

<hr>
<h2 id='Perks'>The Perks Distribution</h2><span id='topic+Perks'></span><span id='topic+dperks'></span><span id='topic+pperks'></span><span id='topic+qperks'></span><span id='topic+rperks'></span>

<h3>Description</h3>

<p>Density, cumulative distribution function,
quantile function
and
random generation for
the Perks distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dperks(x, scale = 1, shape, log = FALSE)
pperks(q, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
qperks(p, scale = 1, shape, lower.tail = TRUE, log.p = FALSE)
rperks(n, scale = 1, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Perks_+3A_x">x</code>, <code id="Perks_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Perks_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Perks_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Perks_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Perks_+3A_lower.tail">lower.tail</code>, <code id="Perks_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Perks_+3A_shape">shape</code>, <code id="Perks_+3A_scale">scale</code></td>
<td>
<p>positive shape and scale parameters. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+perks">perks</a></code> for details.
</p>


<h3>Value</h3>

<p><code>dperks</code> gives the density,
<code>pperks</code> gives the cumulative distribution function,
<code>qperks</code> gives the quantile function, and
<code>rperks</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+perks">perks</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- seq(0.01, 0.99, by = 0.01)
Shape &lt;- exp(-1.0); Scale &lt;- exp(1);
max(abs(pperks(qperks(p = probs, Shape, Scale),
                  Shape, Scale) - probs))  # Should be 0

## Not run:  x &lt;- seq(-0.1, 07, by = 0.01);
plot(x, dperks(x, Shape, Scale), type = "l", col = "blue", las = 1,
     main = "Blue is density, orange is cumulative distribution function",
     sub = "Purple lines are the 10,20,...,90 percentiles",
     ylab = "", ylim = 0:1)
abline(h = 0, col = "blue", lty = 2)
lines(x, pperks(x, Shape, Scale), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qperks(probs, Shape, Scale)
lines(Q, dperks(Q, Shape, Scale), col = "purple", lty = 3, type = "h")
pperks(Q, Shape, Scale) - probs  # Should be all zero
abline(h = probs, col = "purple", lty = 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='perspqrrvglm'> Perspective plot for QRR-VGLMs </h2><span id='topic+perspqrrvglm'></span>

<h3>Description</h3>

<p>Produces a perspective plot for a CQO model (QRR-VGLM).  It is only
applicable for rank-1 or rank-2 models with argument <code>noRRR = ~ 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perspqrrvglm(x, varI.latvar = FALSE, refResponse = NULL, show.plot = TRUE,
             xlim = NULL, ylim = NULL, zlim = NULL,
             gridlength = if (Rank == 1) 301 else c(51,51),
             which.species = NULL,
             xlab = if (Rank == 1) "Latent Variable" else "Latent Variable 1",
             ylab = if (Rank == 1) "Expected Value" else "Latent Variable 2",
             zlab = "Expected value", labelSpecies = FALSE,
             stretch = 1.05, main = "", ticktype = "detailed",
             col = if (Rank == 1) par()$col else "white",
             llty = par()$lty, llwd = par()$lwd,
             add1 = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perspqrrvglm_+3A_x">x</code></td>
<td>

<p>Object of class <code>"qrrvglm"</code>, i.e., a
constrained quadratic ordination (CQO) object.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_vari.latvar">varI.latvar</code></td>
<td>

<p>Logical that is fed into <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_refresponse">refResponse</code></td>
<td>

<p>Integer or character that is fed into <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_show.plot">show.plot</code></td>
<td>
<p> Logical. Plot it? </p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_xlim">xlim</code>, <code id="perspqrrvglm_+3A_ylim">ylim</code></td>
<td>

<p>Limits of the x- and y-axis. Both are numeric of length 2.
See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_zlim">zlim</code></td>
<td>

<p>Limits of the z-axis. Numeric of length 2.
Ignored if rank is 1.
See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_gridlength">gridlength</code></td>
<td>

<p>Numeric. The fitted values are evaluated on a grid, and this
argument regulates the fineness of the grid.  If <code>Rank = 2</code>
then the argument is recycled to length 2, and the two numbers
are the number of grid points on the  x- and y-axes respectively.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_which.species">which.species</code></td>
<td>

<p>Numeric or character vector. Indicates which species are to be
plotted. The default is to plot all of them.  If numeric, it should
contain values in the set {1,2,...,<code class="reqn">S</code>} where <code class="reqn">S</code>
is the number of species.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_xlab">xlab</code>, <code id="perspqrrvglm_+3A_ylab">ylab</code></td>
<td>

<p>Character caption for the x-axis and y-axis.  By default, a suitable caption is
found.  See the <code>xlab</code> argument in <code><a href="graphics.html#topic+plot">plot</a></code>
or <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_zlab">zlab</code></td>
<td>
<p>Character caption for the z-axis.
Used only if <code>Rank = 2</code>.
By default, a suitable caption is found.
See the <code>xlab</code> argument in <code><a href="graphics.html#topic+plot">plot</a></code>
or <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_labelspecies">labelSpecies</code></td>
<td>
<p>Logical.
Whether the species should be labelled with their names.
Used for <code>Rank = 1</code> only.
The position of the label is just above the species' maximum.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_stretch">stretch</code></td>
<td>

<p>Numeric. A value slightly more than 1, this argument
adjusts the height of the y-axis. Used for <code>Rank = 1</code> only.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_main">main</code></td>
<td>

<p>Character, giving the title of the plot.
See the <code>main</code> argument in <code><a href="graphics.html#topic+plot">plot</a></code>
or <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_ticktype">ticktype</code></td>
<td>
<p> Tick type. Used only if <code>Rank = 2</code>.
See <code><a href="graphics.html#topic+persp">persp</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_col">col</code></td>
<td>
<p> Color.
See <code><a href="graphics.html#topic+persp">persp</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_llty">llty</code></td>
<td>
<p> Line type.
Rank-1 models only.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_llwd">llwd</code></td>
<td>
<p> Line width.
Rank-1 models only.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_add1">add1</code></td>
<td>
<p> Logical. Add to an existing plot?
Used only for rank-1 models.
</p>
</td></tr>
<tr><td><code id="perspqrrvglm_+3A_...">...</code></td>
<td>

<p>Arguments passed into <code><a href="graphics.html#topic+persp">persp</a></code>.  Useful
arguments here include <code>theta</code> and <code>phi</code>, which control
the position of the eye.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a rank-1 model, a perspective plot is similar to
<code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code> but plots the curves along a fine grid
and there is no rugplot to show the site scores.
</p>
<p>For a rank-2 model, a perspective plot has the first latent variable as
the x-axis, the second latent variable as the y-axis, and the expected
value (fitted value) as the z-axis.  The result of a CQO is that each
species has a response surface with elliptical contours.  This function
will, at each grid point, work out the maximum fitted value over all
the species. The resulting response surface is plotted. Thus rare
species will be obscured and abundant species will dominate the plot.
To view rare species, use the <code>which.species</code> argument to select
a subset of the species.
</p>
<p>A perspective  plot will be performed if <code>noRRR = ~ 1</code>, and
<code>Rank = 1</code> or <code>2</code>.  Also, all the tolerance matrices of
those species to be plotted must be positive-definite.
</p>


<h3>Value</h3>

<p>For a rank-2 model, a list with the following components.
</p>
<table>
<tr><td><code>fitted</code></td>
<td>

<p>A <code class="reqn">(G_1 \times G_2)</code> by <code class="reqn">M</code> matrix
of fitted values on the grid. Here, <code class="reqn">G_1</code> and <code class="reqn">G_2</code>
are the two values of <code>gridlength</code>.
</p>
</td></tr>
<tr><td><code>latvar1grid</code>, <code>latvar2grid</code></td>
<td>

<p>The grid points for the x-axis and y-axis.
</p>
</td></tr>
<tr><td><code>max.fitted</code></td>
<td>

<p>A <code class="reqn">G_1</code> by <code class="reqn">G_2</code> matrix of maximum
of the fitted values over all species.
These are the values that are plotted on the z-axis.
</p>
</td></tr>
</table>
<p>For a rank-1 model, the components <code>latvar2grid</code> and
<code>max.fitted</code> are <code>NULL</code>.
</p>


<h3>Note</h3>

<p>Yee (2004) does not refer to perspective plots.  Instead, contour plots
via <code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code> are used.
</p>
<p>For rank-1 models, a similar function to this one is
<code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>.  It plots the fitted values at the actual
site score values rather than on a fine grid here.  The result has
the advantage that the user sees the curves as a direct result from a
model fitted to data whereas here, it is easy to think that the smooth
bell-shaped curves are the truth because the data is more of a distance
away.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+persp">persp</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>,
<code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>,
<code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="graphics.html#topic+title">title</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Good idea when I.tolerances = TRUE
set.seed(111)
r1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardmont, Pardnigr, Pardpull, Trocterr) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          poissonff, data = hspider, trace = FALSE, I.tolerances = TRUE)
set.seed(111)  # r2 below is an ill-conditioned model
r2 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardmont, Pardnigr, Pardpull, Trocterr) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          isd.lv = c(2.4, 1.0), Muxfactor = 3.0, trace = FALSE,
          poissonff, data = hspider, Rank = 2, eq.tolerances = TRUE)

sort(deviance(r1, history = TRUE))  # A history of all the fits
sort(deviance(r2, history = TRUE))  # A history of all the fits
if (deviance(r2) &gt; 857) stop("suboptimal fit obtained")

persp(r1, xlim = c(-6, 5), col = 1:4, label = TRUE)

# Involves all species
persp(r2, xlim = c(-6, 5), ylim = c(-4, 5), theta = 10, phi = 20, zlim = c(0, 220))
# Omit the two dominant species to see what is behind them
persp(r2, xlim = c(-6, 5), ylim = c(-4, 5), theta = 10, phi = 20, zlim = c(0, 220),
      which = (1:10)[-c(8, 10)])  # Use zlim to retain the original z-scale

## End(Not run)
</code></pre>

<hr>
<h2 id='pgamma.deriv'>
Derivatives of the Incomplete Gamma Integral
</h2><span id='topic+pgamma.deriv'></span>

<h3>Description</h3>

<p>The first two derivatives of the incomplete gamma integral.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pgamma.deriv(q, shape, tmax = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pgamma.deriv_+3A_q">q</code>, <code id="pgamma.deriv_+3A_shape">shape</code></td>
<td>

<p>As in <code><a href="stats.html#topic+pgamma">pgamma</a></code> but
these must be vectors of positive values only and finite.
</p>
</td></tr>




<tr><td><code id="pgamma.deriv_+3A_tmax">tmax</code></td>
<td>

<p>Maximum number of iterations allowed in the computation
(per <code>q</code> value).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Write <code class="reqn">x = q</code> and <code>shape =</code> <code class="reqn">a</code>.
The first and second derivatives with respect to <code class="reqn">q</code> and <code class="reqn">a</code>
are returned. This function is similar in spirit to
<code><a href="stats.html#topic+pgamma">pgamma</a></code>;
define
</p>
<p style="text-align: center;"><code class="reqn">P(a,x) = \frac{1}{\Gamma(a)} \int_0^x t^{a-1} e^{-t} dt</code>
</p>

<p>so that
<code class="reqn">P(a, x)</code> is <code>pgamma(x, a)</code>.
Currently a 6-column matrix is returned (in the future this
may change and an argument may be supplied so that only what
is required by the user is computed.)
</p>
<p>The computations use a series expansion
for <code class="reqn">a \leq x \leq 1</code> or
or <code class="reqn">x &lt; a</code>, else
otherwise a continued fraction expansion.
Machine overflow can occur for large values of <code class="reqn">x</code>
when <code class="reqn">x</code> is much greater than <code class="reqn">a</code>.
</p>


<h3>Value</h3>

<p>The first 5 columns, running from left to right, are the derivatives
with respect to:
<code class="reqn">x</code>,
<code class="reqn">x^2</code>,
<code class="reqn">a</code>,
<code class="reqn">a^2</code>,
<code class="reqn">xa</code>.
The 6th column is <code class="reqn">P(a, x)</code> (but it is not as accurate
as calling <code><a href="stats.html#topic+pgamma">pgamma</a></code> directly).
</p>


<h3>Note</h3>

<p>If convergence does not occur then try increasing the value of
<code>tmax</code>.
</p>
<p>Yet to do: add more arguments to give greater flexibility in
the accuracy desired and to compute only quantities that are
required by the user.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee wrote the wrapper function to the Fortran subroutine
written by R. J. Moore. The subroutine was modified to run using
double precision.
The original code came from <code>http://lib.stat.cmu.edu/apstat/187</code>.
but this website has since become stale.
</p>


<h3>References</h3>

<p>Moore, R. J. (1982).
Algorithm AS 187: Derivatives of the Incomplete Gamma Integral.
<em>Journal of the Royal Statistical Society, Series C</em>
<em>(Applied Statistics)</em>,
<b>31</b>(3), 330&ndash;335.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pgamma.deriv.unscaled">pgamma.deriv.unscaled</a></code>,
<code><a href="stats.html#topic+pgamma">pgamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(2, 10, length = 501)
head(ans &lt;- pgamma.deriv(x, 2))
## Not run:  par(mfrow = c(2, 3))
for (jay in 1:6)
  plot(x, ans[, jay], type = "l", col = "blue", cex.lab = 1.5,
       cex.axis = 1.5, las = 1, log = "x",
       main = colnames(ans)[jay], xlab = "q", ylab = "") 
## End(Not run)
</code></pre>

<hr>
<h2 id='pgamma.deriv.unscaled'>
Derivatives of the Incomplete Gamma Integral (Unscaled Version)
</h2><span id='topic+pgamma.deriv.unscaled'></span>

<h3>Description</h3>

<p>The first two derivatives of the incomplete gamma integral
with scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pgamma.deriv.unscaled(q, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pgamma.deriv.unscaled_+3A_q">q</code>, <code id="pgamma.deriv.unscaled_+3A_shape">shape</code></td>
<td>

<p>As in <code><a href="stats.html#topic+pgamma">pgamma</a></code>
and <code><a href="#topic+pgamma.deriv">pgamma.deriv</a></code> but
these must be vectors of positive values only and finite.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Define
</p>
<p style="text-align: center;"><code class="reqn">G(x, a) = \int_0^x t^{a-1} e^{-t} dt</code>
</p>

<p>so that
<code class="reqn">G(x, a)</code> is <code>pgamma(x, a) * gamma(a)</code>.
Write <code class="reqn">x = q</code> and <code>shape =</code> <code class="reqn">a</code>.
The 0th and first and second derivatives with respect to <code class="reqn">a</code>
of <code class="reqn">G</code> are returned. This function is similar in spirit to
<code><a href="#topic+pgamma.deriv">pgamma.deriv</a></code>
but here there is no gamma function to scale things.
Currently a 3-column matrix is returned (in the future this
may change and an argument may be supplied so that only what
is required by the user is computed.)
This function is based on Wingo (1989).
</p>


<h3>Value</h3>

<p>The 3 columns, running from left to right, are the <code>0:2</code>th derivatives
with respect to <code class="reqn">a</code>.
</p>


<h3>Warning </h3>

<p>These function seems inaccurate for <code>q = 1</code> and <code>q = 2</code>;
see the plot below.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>References</h3>

<p>See <code><a href="#topic+truncweibull">truncweibull</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pgamma.deriv">pgamma.deriv</a></code>,
<code><a href="stats.html#topic+pgamma">pgamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 3; aa &lt;- seq(0.3, 04, by = 0.01)
ans.u &lt;- pgamma.deriv.unscaled(x, aa)
head(ans.u)

## Not run:  par(mfrow = c(1, 3))
for (jay in 1:3) {
  plot(aa, ans.u[, jay], type = "l", col = "blue", cex.lab = 1.5,
       cex.axis = 1.5, las = 1, main = colnames(ans.u)[jay],
       log = "", xlab = "shape", ylab = "")
  abline(h = 0, v = 1:2, lty = "dashed", col = "gray")  # Inaccurate at 1 and 2
}

## End(Not run)
</code></pre>

<hr>
<h2 id='plotdeplot.lmscreg'> Density Plot for LMS Quantile Regression </h2><span id='topic+plotdeplot.lmscreg'></span>

<h3>Description</h3>

<p>Plots a probability density function
associated with a LMS quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotdeplot.lmscreg(answer, y.arg, add.arg = FALSE,
    xlab = "", ylab = "density", xlim = NULL, ylim = NULL,
    llty.arg = par()$lty, col.arg = par()$col,
    llwd.arg = par()$lwd, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotdeplot.lmscreg_+3A_answer">answer</code></td>
<td>

<p>Output from functions of the form
<code>deplot.???</code> where <code>???</code> is the name of the
<span class="pkg">VGAM</span> LMS family function, e.g., <code>lms.yjn</code>.
See below for details.
</p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_y.arg">y.arg</code></td>
<td>

<p>Numerical vector. The values of the response variable
at which to evaluate the density. This should be a grid that is fine
enough to ensure the plotted curves are smooth.
</p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_add.arg">add.arg</code></td>
<td>

<p>Logical. Add the density to an existing plot?
</p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_xlab">xlab</code>, <code id="plotdeplot.lmscreg_+3A_ylab">ylab</code></td>
<td>

<p>Caption for the x- and y-axes. See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_xlim">xlim</code>, <code id="plotdeplot.lmscreg_+3A_ylim">ylim</code></td>
<td>

<p>Limits of the x- and y-axes. See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_llty.arg">llty.arg</code></td>
<td>

<p>Line type.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_col.arg">col.arg</code></td>
<td>

<p>Line color.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_llwd.arg">llwd.arg</code></td>
<td>
<p> Line width.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotdeplot.lmscreg_+3A_...">...</code></td>
<td>
<p> Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>main</code> and <code>las</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The above graphical parameters offer some flexibility when
plotting the quantiles.
</p>


<h3>Value</h3>

<p>The list <code>answer</code>, which has components
</p>
<table>
<tr><td><code>newdata</code></td>
<td>

<p>The argument <code>newdata</code> above from
the argument list of <code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>,
or a one-row
data frame constructed out of the <code>x0</code> argument.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p> The argument <code>y.arg</code> above. </p>
</td></tr>
<tr><td><code>density</code></td>
<td>

<p>Vector of the density function values evaluated at <code>y.arg</code>.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>While the graphical arguments of this function are useful to
the user, this function should not be called directly.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- vgam(BMI ~ s(age, df = c(4,2)), lms.bcn(zero = 1), bmi.nz)
## Not run:  y = seq(15, 43, by = 0.25)
deplot(fit, x0 = 20, y = y, xlab = "BMI", col = "green", llwd = 2,
       main = "BMI distribution at ages 20 (green), 40 (blue), 60 (orange)")
deplot(fit, x0 = 40, y = y, add = TRUE, col = "blue", llwd = 2)
deplot(fit, x0 = 60, y = y, add = TRUE, col = "orange", llwd = 2) -&gt; aa

names(aa@post$deplot)
aa@post$deplot$newdata
head(aa@post$deplot$y)
head(aa@post$deplot$density) 
## End(Not run)
</code></pre>

<hr>
<h2 id='plotdgaitd.vglm'>
Plotting the GAITD Combo Density from a GAITD Regression Object
</h2><span id='topic+plotdgaitd'></span><span id='topic+plotdgaitd.vglm'></span>

<h3>Description</h3>

<p>Given a GAITD regression object,
plots the probability mass function.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>plotdgaitd(object, ...)
plotdgaitd.vglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotdgaitd.vglm_+3A_object">object</code></td>
<td>

<p>A fitted GAITD combo regression, e.g.,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>
</td></tr>
<tr><td><code id="plotdgaitd.vglm_+3A_...">...</code></td>
<td>

<p>Graphical arguments passed into <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is meant to be a more convenient function for plotting
the PMF of the GAITD combo model from a fitted regression model.
The fit should be intercept-only and the distribution
should have 1 or 2 parameters.
Currently it should work for a <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> fit.
As much information as needed
such as the special values
is extracted from the object
and fed into <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>


<h3>Value</h3>

<p>Same as <code><a href="#topic+dgaitdplot">dgaitdplot</a></code>.
</p>


<h3>Note</h3>

<p>This function is subject to change.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
example(gaitdpoisson)
gaitpfit2 &lt;-
  vglm(y1 ~ 1, crit = "coef", trace = TRUE, data = gdata,
       gaitdpoisson(a.mix = a.mix, i.mix = i.mix,
                    i.mlm = i.mlm, eq.ap = TRUE, eq.ip = TRUE,
                    truncate = tvec, max.support = max.support))
plotdgaitd(gaitpfit2)

## End(Not run)</code></pre>

<hr>
<h2 id='plotqrrvglm'> Model Diagnostic Plots for QRR-VGLMs </h2><span id='topic+plotqrrvglm'></span>

<h3>Description</h3>

<p>The residuals of a QRR-VGLM are plotted for model diagnostic purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotqrrvglm(object, rtype = c("response", "pearson", "deviance", "working"),
            ask = FALSE,
            main = paste(Rtype, "residuals vs latent variable(s)"),
            xlab = "Latent Variable",
            I.tolerances = object@control$eq.tolerances, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotqrrvglm_+3A_object">object</code></td>
<td>
<p> An object of class <code>"qrrvglm"</code>. </p>
</td></tr>
<tr><td><code id="plotqrrvglm_+3A_rtype">rtype</code></td>
<td>
<p> Character string giving residual type.
By default, the first one is chosen. </p>
</td></tr>
<tr><td><code id="plotqrrvglm_+3A_ask">ask</code></td>
<td>
<p> Logical. If <code>TRUE</code>, the user is asked to hit the return
key for the next plot. </p>
</td></tr>
<tr><td><code id="plotqrrvglm_+3A_main">main</code></td>
<td>
<p> Character string giving the title of the plot. </p>
</td></tr>
<tr><td><code id="plotqrrvglm_+3A_xlab">xlab</code></td>
<td>
<p> Character string giving the x-axis caption. </p>
</td></tr>
<tr><td><code id="plotqrrvglm_+3A_i.tolerances">I.tolerances</code></td>
<td>
<p> Logical. This argument is fed into
<code>Coef(object, I.tolerances = I.tolerances)</code>.
</p>
</td></tr>
<tr><td><code id="plotqrrvglm_+3A_...">...</code></td>
<td>
<p> Other plotting arguments (see <code><a href="graphics.html#topic+par">par</a></code>). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plotting the residuals can be potentially very useful for checking
that the model fit is adequate.
</p>


<h3>Value</h3>

<p>The original object.
</p>


<h3>Note</h3>

<p>An ordination plot of a QRR-VGLM can be obtained
by <code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Thomas W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# QRR-VGLM on the hunting spiders data
# This is computationally expensive
set.seed(111)  # This leads to the global solution
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Standardize environ vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          poissonff, data = hspider, Crow1positive = FALSE)
par(mfrow = c(3, 4))
plot(p1, rtype = "response", col = "blue", pch = 4, las = 1, main = "")

## End(Not run)
</code></pre>

<hr>
<h2 id='plotqtplot.lmscreg'> Quantile Plot for LMS Quantile Regression </h2><span id='topic+plotqtplot.lmscreg'></span>

<h3>Description</h3>

<p>Plots the quantiles
associated with a LMS quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotqtplot.lmscreg(fitted.values, object, newdata = NULL,
    percentiles = object@misc$percentiles, lp = NULL,
    add.arg = FALSE, y = if (length(newdata)) FALSE else TRUE,
    spline.fit = FALSE, label = TRUE, size.label = 0.06,
    xlab = NULL, ylab = "",
    pch = par()$pch, pcex = par()$cex, pcol.arg = par()$col,
    xlim = NULL, ylim = NULL,
    llty.arg = par()$lty, lcol.arg = par()$col, llwd.arg = par()$lwd,
    tcol.arg = par()$col, tadj = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotqtplot.lmscreg_+3A_fitted.values">fitted.values</code></td>
<td>
<p> Matrix of fitted values. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_object">object</code></td>
<td>
<p> A <span class="pkg">VGAM</span> quantile regression model, i.e.,
an object produced by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code> with a family function beginning with
<code>"lms."</code>, e.g., <code><a href="#topic+lms.yjn">lms.yjn</a></code>.
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_newdata">newdata</code></td>
<td>
<p> Data frame at which predictions are made.
By default, the original data are used. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_percentiles">percentiles</code></td>
<td>
<p> Numerical vector with values between 0 and 100
that specify the percentiles (quantiles).
The default is to use the percentiles when fitting the model.
For example, the value 50 corresponds to the median.
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_lp">lp</code></td>
<td>
<p> Length of <code>percentiles</code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_add.arg">add.arg</code></td>
<td>
<p> Logical. Add the quantiles to an existing plot? </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_y">y</code></td>
<td>
<p> Logical. Add the response as points to the plot? </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_spline.fit">spline.fit</code></td>
<td>
<p> Logical. Add a spline curve to the plot? </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_label">label</code></td>
<td>
<p> Logical. Add the percentiles (as text) to the plot?  </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_size.label">size.label</code></td>
<td>
<p> Numeric. How much room to leave at the RHS for the label.
It is in percent (of the range of the primary variable).
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_xlab">xlab</code></td>
<td>
<p> Caption for the x-axis. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_ylab">ylab</code></td>
<td>
<p> Caption for the x-axis. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_pch">pch</code></td>
<td>
<p> Plotting character. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_pcex">pcex</code></td>
<td>
<p> Character expansion of the points.
See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_pcol.arg">pcol.arg</code></td>
<td>
<p> Color of the points.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.  </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_xlim">xlim</code></td>
<td>
<p> Limits of the x-axis. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_ylim">ylim</code></td>
<td>
<p> Limits of the y-axis. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_llty.arg">llty.arg</code></td>
<td>
<p> Line type. Line type.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_lcol.arg">lcol.arg</code></td>
<td>
<p> Color of the lines.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_llwd.arg">llwd.arg</code></td>
<td>
<p> Line width.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_tcol.arg">tcol.arg</code></td>
<td>
<p> Color of the text
(if <code>label</code> is <code>TRUE</code>).
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_tadj">tadj</code></td>
<td>
<p> Text justification.
See the <code>adj</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="plotqtplot.lmscreg_+3A_...">...</code></td>
<td>
<p> Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>main</code> and <code>las</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The above graphical parameters offer some flexibility when
plotting the quantiles.
</p>


<h3>Value</h3>

<p>The matrix of fitted values.
</p>


<h3>Note</h3>

<p>While the graphical arguments of this function are useful to the user,
this function should not be called directly.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+qtplot.lmscreg">qtplot.lmscreg</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fit &lt;- vgam(BMI ~ s(age, df = c(4,2)), lms.bcn(zero = 1), data = bmi.nz)
qtplot(fit)
qtplot(fit, perc = c(25,50,75,95), lcol = "blue", tcol = "blue", llwd = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotrcim0'> Main Effects Plot for a Row-Column Interaction Model (RCIM)
</h2><span id='topic+plotrcim0'></span>

<h3>Description</h3>

<p>Produces a main effects plot for Row-Column Interaction
Models (RCIMs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  plotrcim0(object, centered = TRUE, which.plots = c(1, 2),
            hline0 = TRUE, hlty = "dashed", hcol = par()$col, hlwd = par()$lwd,
            rfirst = 1, cfirst = 1,
            rtype = "h", ctype = "h",
            rcex.lab = 1, rcex.axis = 1, rtick = FALSE,
            ccex.lab = 1, ccex.axis = 1, ctick = FALSE,
            rmain = "Row effects", rsub = "",
            rxlab = "", rylab = "Row effects",
            cmain = "Column effects", csub = "",
            cxlab= "", cylab = "Column effects",
            rcol = par()$col, ccol = par()$col,
            no.warning = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotrcim0_+3A_object">object</code></td>
<td>

<p>An <code><a href="#topic+rcim">rcim</a></code> object.
This should be of rank-0, i.e., main effects only and no
interactions.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_which.plots">which.plots</code></td>
<td>

<p>Numeric, describing which plots are to be plotted.
The row effects plot is 1 and the column effects plot is 2.
Set the value <code>0</code>, say, for no plots at all.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_centered">centered</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the row and column effects are centered
(but not scaled) by <code><a href="base.html#topic+scale">scale</a></code>.
If <code>FALSE</code> then the raw effects are used (of which
the first are zero by definition).
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_hline0">hline0</code>, <code id="plotrcim0_+3A_hlty">hlty</code>, <code id="plotrcim0_+3A_hcol">hcol</code>, <code id="plotrcim0_+3A_hlwd">hlwd</code></td>
<td>

<p><code>hline0</code> is logical. If <code>TRUE</code> then a horizontal line is
plotted at 0 and the other arguments describe this line.
Probably having <code>hline0 = TRUE</code> only makes sense when
<code>centered = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rfirst">rfirst</code>, <code id="plotrcim0_+3A_cfirst">cfirst</code></td>
<td>

<p><code>rfirst</code> is the level of row that is placed first in the
row effects plot, etc.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rmain">rmain</code>, <code id="plotrcim0_+3A_cmain">cmain</code></td>
<td>

<p>Character.
<code>rmain</code> is the main label in the row effects plot, etc.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rtype">rtype</code>, <code id="plotrcim0_+3A_ctype">ctype</code>, <code id="plotrcim0_+3A_rsub">rsub</code>, <code id="plotrcim0_+3A_csub">csub</code></td>
<td>

<p>See the <code>type</code> and <code>sub</code> arguments of
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
</p>



</td></tr>








<tr><td><code id="plotrcim0_+3A_rxlab">rxlab</code>, <code id="plotrcim0_+3A_rylab">rylab</code>, <code id="plotrcim0_+3A_cxlab">cxlab</code>, <code id="plotrcim0_+3A_cylab">cylab</code></td>
<td>

<p>Character.
For the row effects plot,
<code>rxlab</code> is <code>xlab</code> and
<code>rylab</code> is <code>ylab</code>;
see <code><a href="graphics.html#topic+par">par</a></code>.
Ditto for <code>cxlab</code> and <code>cylab</code> for the column effects plot.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rcex.lab">rcex.lab</code>, <code id="plotrcim0_+3A_ccex.lab">ccex.lab</code></td>
<td>

<p>Numeric.
<code>rcex.lab</code> is <code>cex</code> for the row effects plot label,
etc.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rcex.axis">rcex.axis</code>, <code id="plotrcim0_+3A_ccex.axis">ccex.axis</code></td>
<td>

<p>Numeric.
<code>rcex.axis</code> is the <code>cex</code> argument for the row effects axis label,
etc.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rtick">rtick</code>, <code id="plotrcim0_+3A_ctick">ctick</code></td>
<td>

<p>Logical.
If <code>rtick = TRUE</code> then add ticks to the row effects plot, etc.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_rcol">rcol</code>, <code id="plotrcim0_+3A_ccol">ccol</code></td>
<td>

<p><code>rcol</code> give a colour for the row effects plot,
etc.
</p>
</td></tr>
<tr><td><code id="plotrcim0_+3A_no.warning">no.warning</code></td>
<td>

<p>Logical. If <code>TRUE</code> then no warning is issued if the
model is not rank-0.
</p>
</td></tr>
















<tr><td><code id="plotrcim0_+3A_...">...</code></td>
<td>

<p>Arguments fed into
<code><a href="graphics.html#topic+plot.default">plot.default</a></code>, etc.
</p>


</td></tr>
</table>


<h3>Details</h3>

<p>This function plots the row and column effects of a rank-0 RCIM.
As the result is a main effects plot of a regression analysis, its
interpretation when <code>centered = FALSE</code> is relative
to the baseline (reference level) of a row and column, and
should also be considered in light of the link function used.
Many arguments that start with <code>"r"</code> refer to the row
effects plot, and <code>"c"</code> for the column
effects plot.
</p>


<h3>Value</h3>

<p>The original object with the <code>post</code> slot
assigned additional information from the plot.
</p>


<h3>Note</h3>

<p>This function should be only used to plot the object of rank-0 RCIM.
If the rank is positive then it will issue a warning.
</p>
<p>Using an argument <code>ylim</code> will mean the row and column
effects are plotted on a common scale;
see <code><a href="graphics.html#topic+plot.window">plot.window</a></code>.
</p>




<h3>Author(s)</h3>

<p>T. W. Yee,
A. F. Hadi.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moffset">moffset</a></code>
<code><a href="#topic+Rcim">Rcim</a></code>,
<code><a href="#topic+rcim">rcim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alcoff.e &lt;- moffset(alcoff, "6", "Mon", postfix = "*")  # Effective day
fit0 &lt;- rcim(alcoff.e, family = poissonff)
## Not run: par(oma = c(0, 0, 4, 0), mfrow = 1:2)  # For all plots below too
ii &lt;- plot(fit0, rcol = "blue", ccol = "orange",
           lwd = 4, ylim = c(-2, 2),  # A common ylim
           cylab = "Effective daily effects", rylab = "Hourly effects",
           rxlab = "Hour", cxlab = "Effective day")
ii@post  # Endowed with additional information

## End(Not run)

# Negative binomial example
## Not run: 
fit1 &lt;- rcim(alcoff.e, negbinomial, trace = TRUE)
plot(fit1, ylim = c(-2, 2)) 
## End(Not run)

# Univariate normal example
fit2 &lt;- rcim(alcoff.e, uninormal, trace = TRUE)
## Not run:  plot(fit2, ylim = c(-200, 400)) 

# Median-polish example
## Not run: 
fit3 &lt;- rcim(alcoff.e, alaplace1(tau = 0.5), maxit = 1000, trace = FALSE)
plot(fit3, ylim = c(-200, 250)) 
## End(Not run)

# Zero-inflated Poisson example on "crashp" (no 0s in alcoff)
## Not run: 
cbind(rowSums(crashp))  # Easy to see the data
cbind(colSums(crashp))  # Easy to see the data
fit4 &lt;- rcim(Rcim(crashp, rbaseline = "5", cbaseline = "Sun"),
             zipoissonff, trace = TRUE)
plot(fit4, ylim = c(-3, 3)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='plotvgam'> Default VGAM Plotting </h2><span id='topic+plotvgam'></span><span id='topic+plot.vgam'></span>

<h3>Description</h3>

<p>Component functions of a <code><a href="#topic+vgam-class">vgam-class</a></code> object can
be plotted with <code>plotvgam()</code>. These are on the scale of
the linear/additive predictor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotvgam(x, newdata = NULL, y = NULL, residuals = NULL,
         rugplot = TRUE, se = FALSE, scale = 0, raw = TRUE,
         offset.arg = 0, deriv.arg = 0, overlay = FALSE,
         type.residuals = c("deviance", "working", "pearson", "response"),
         plot.arg = TRUE, which.term = NULL, which.cf = NULL,
         control = plotvgam.control(...), varxij = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotvgam_+3A_x">x</code></td>
<td>
<p> A fitted <span class="pkg">VGAM</span> object, e.g., produced by
<code><a href="#topic+vgam">vgam</a></code>, <code><a href="#topic+vglm">vglm</a></code>, or <code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_newdata">newdata</code></td>
<td>
<p> Data frame.
May be used to reconstruct the original data set.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_y">y</code></td>
<td>
<p> Unused.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_residuals">residuals</code></td>
<td>

<p>Logical. If <code>TRUE</code> then residuals are plotted.
See <code>type.residuals</code>
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_rugplot">rugplot</code></td>
<td>

<p>Logical. If <code>TRUE</code> then a rug plot is plotted at the
foot of each plot. These values are jittered to expose ties.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_se">se</code></td>
<td>

<p>Logical. If <code>TRUE</code> then approximate <code class="reqn">\pm 2</code> pointwise
standard error bands are included in the plot.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_scale">scale</code></td>
<td>

<p>Numerical. By default, each plot will have its own
y-axis scale. However, by specifying a value, each plot's y-axis
scale will be at least <code>scale</code> wide.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_raw">raw</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the smooth functions are those
obtained directly by the algorithm, and are plotted without
having to premultiply with the constraint matrices.
If <code>FALSE</code> then the smooth functions have been premultiply by
the constraint matrices.
The <code>raw</code> argument is directly fed into <code>predict.vgam()</code>.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_offset.arg">offset.arg</code></td>
<td>

<p>Numerical vector of length <code class="reqn">r</code>.
These are added to the component functions. Useful for
separating out the functions when <code>overlay</code> is <code>TRUE</code>.
If <code>overlay</code> is <code>TRUE</code> and there is one covariate then
using the intercept values as the offsets can be a good idea.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_deriv.arg">deriv.arg</code></td>
<td>

<p>Numerical. The order of the derivative.
Should be assigned an small
integer such as 0, 1, 2. Only applying to <code>s()</code> terms,
it plots the derivative.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_overlay">overlay</code></td>
<td>

<p>Logical. If <code>TRUE</code> then component functions of the same
covariate are overlaid on each other.
The functions are centered, so <code>offset.arg</code> can be useful
when <code>overlay</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_type.residuals">type.residuals</code></td>
<td>

<p>if <code>residuals</code> is <code>TRUE</code> then the first
possible value
of this vector, is used to specify the type of residual.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_plot.arg">plot.arg</code></td>
<td>

<p>Logical. If <code>FALSE</code> then no plot is produced.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_which.term">which.term</code></td>
<td>

<p>Character or integer vector containing all terms to be
plotted, e.g., <code>which.term = c("s(age)", "s(height"))</code> or
<code>which.term = c(2, 5, 9)</code>.
By default, all are plotted.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_which.cf">which.cf</code></td>
<td>
<p> An integer-valued vector specifying which
linear/additive predictors are to be plotted.
The values must be from the set {1,2,...,<code class="reqn">r</code>}.
By default, all are plotted.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_control">control</code></td>
<td>

<p>Other control parameters. See <code><a href="#topic+plotvgam.control">plotvgam.control</a></code>.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_...">...</code></td>
<td>

<p>Other arguments that can be fed into
<code><a href="#topic+plotvgam.control">plotvgam.control</a></code>. This includes line colors,
line widths, line types, etc.
</p>
</td></tr>
<tr><td><code id="plotvgam_+3A_varxij">varxij</code></td>
<td>
<p> Positive integer.
Used if <code>xij</code> of <code><a href="#topic+vglm.control">vglm.control</a></code> was used,
this chooses which inner argument the component is plotted against.
This argument is related to <code>raw = TRUE</code> and terms such as
<code>NS(dum1, dum2)</code> and constraint matrices that have more than
one column. The default would plot the smooth against <code>dum1</code>
but setting <code>varxij = 2</code> could mean plotting the smooth against
<code>dum2</code>.
See the <span class="pkg">VGAM</span> website for further information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file <code class="reqn">M</code> is the number of linear/additive
predictors, and <code class="reqn">r</code> is the number of columns of the
constraint matrix of interest.
</p>
<p>Many of <code>plotvgam()</code>'s options can be found in
<code><a href="#topic+plotvgam.control">plotvgam.control</a></code>, e.g., line types, line widths,
colors.
</p>


<h3>Value</h3>

<p>The original object, but with the <code>preplot</code> slot of the object
assigned information regarding the plot.
</p>


<h3>Note</h3>

<p>While <code>plot(fit)</code> will work if <code>class(fit)</code>
is <code>"vgam"</code>, it is necessary to use <code>plotvgam(fit)</code>
explicitly otherwise.
</p>
<p><code>plotvgam()</code> is quite buggy at the moment.
</p>





<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+plotvgam.control">plotvgam.control</a></code>,
<code>predict.vgam</code>,
<code><a href="#topic+plotvglm">plotvglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>coalminers &lt;- transform(coalminers, Age = (age - 42) / 5)
fit &lt;- vgam(cbind(nBnW, nBW, BnW, BW) ~ s(Age),
            binom2.or(zero = NULL), data = coalminers)
## Not run:  par(mfrow = c(1,3))
plot(fit, se = TRUE, ylim = c(-3, 2), las = 1)
plot(fit, se = TRUE, which.cf = 1:2, lcol = "blue", scol = "orange",
     ylim = c(-3, 2))
plot(fit, se = TRUE, which.cf = 1:2, lcol = "blue", scol = "orange",
     overlay = TRUE) 
## End(Not run)
</code></pre>

<hr>
<h2 id='plotvgam.control'> Control Function for plotvgam() </h2><span id='topic+plotvgam.control'></span>

<h3>Description</h3>

<p>Provides default values for many arguments available for
<code>plotvgam()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotvgam.control(which.cf = NULL,
    xlim = NULL, ylim = NULL, llty = par()$lty, slty = "dashed",
    pcex = par()$cex, pch = par()$pch, pcol = par()$col,
    lcol = par()$col, rcol = par()$col, scol = par()$col,
    llwd = par()$lwd, slwd = par()$lwd, add.arg = FALSE,
    one.at.a.time = FALSE, .include.dots = TRUE, noxmean = FALSE,
    shade = FALSE, shcol = "gray80", main = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotvgam.control_+3A_which.cf">which.cf</code></td>
<td>
<p> Integer vector specifying which component
functions are to be plotted (for each covariate). Must
have values from the
set {1,2,...,<code class="reqn">M</code>}. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_xlim">xlim</code></td>
<td>
<p> Range for the x-axis. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_ylim">ylim</code></td>
<td>
<p> Range for the y-axis. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_llty">llty</code></td>
<td>
<p> Line type for the fitted functions (lines).
Fed into <code>par(lty)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_slty">slty</code></td>
<td>
<p> Line type for the standard error bands.
Fed into <code>par(lty)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_pcex">pcex</code></td>
<td>
<p> Character expansion for the points (residuals).
Fed into <code>par(cex)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_pch">pch</code></td>
<td>
<p> Character used for the points (residuals).
Same as <code>par(pch)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_pcol">pcol</code></td>
<td>
<p> Color of the points.
Fed into <code>par(col)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_lcol">lcol</code></td>
<td>
<p> Color of the fitted functions (lines).
Fed into <code>par(col)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_rcol">rcol</code></td>
<td>
<p> Color of the rug plot.
Fed into <code>par(col)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_scol">scol</code></td>
<td>
<p> Color of the standard error bands.
Fed into <code>par(col)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_llwd">llwd</code></td>
<td>
<p> Line width of the fitted functions (lines).
Fed into <code>par(lwd)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_slwd">slwd</code></td>
<td>
<p> Line width of the standard error bands.
Fed into <code>par(lwd)</code>. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_add.arg">add.arg</code></td>
<td>
<p> Logical.
If <code>TRUE</code> then the plot will be added to an existing
plot, otherwise a new plot will be made.
</p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_one.at.a.time">one.at.a.time</code></td>
<td>
<p> Logical. If <code>TRUE</code> then the plots are done
one at a time, with the user having to hit the return key
between the plots. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_.include.dots">.include.dots</code></td>
<td>
<p> Not to be used by the user. </p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_noxmean">noxmean</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the point at the mean of <code class="reqn">x</code>,
which is added when
standard errors are specified and
it thinks the function is linear,
is not added.
One might use this argument if <code>ylab</code> is specified.
</p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_shade">shade</code>, <code id="plotvgam.control_+3A_shcol">shcol</code></td>
<td>

<p><code>shade</code> is logical; if <code>TRUE</code> then
the pointwise SE band is shaded gray by default.
The colour can be adjusted by setting <code>shcol</code>.
These arguments are ignored unless
<code>se = TRUE</code> and <code>overlay = FALSE</code>;
If <code>shade = TRUE</code> then <code>scol</code> is ignored.
</p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_main">main</code></td>
<td>

<p>Character vector, recycled to the number needed.
</p>
</td></tr>
<tr><td><code id="plotvgam.control_+3A_...">...</code></td>
<td>
<p> Other arguments that may be fed into <code>par()</code>. </p>
</td></tr>
</table>
<p>In the above, <code class="reqn">M</code> is the number of linear/additive predictors.
</p>


<h3>Details</h3>

<p>The most obvious features of <code><a href="#topic+plotvgam">plotvgam</a></code> can be
controlled by the above arguments.
</p>


<h3>Value</h3>

<p>A list with values matching the arguments.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotvgam">plotvgam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plotvgam.control(lcol = c("red", "blue"), scol = "darkgreen", se = TRUE)
</code></pre>

<hr>
<h2 id='plotvglm'> Plots for VGLMs </h2><span id='topic+plotvglm'></span>

<h3>Description</h3>

<p>Currently this function plots the Pearson residuals versus
the linear predictors (<code class="reqn">M</code> plots) and
plots the Pearson residuals versus
the hat values (<code class="reqn">M</code> plots).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotvglm(x, which = "(All)", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotvglm_+3A_x">x</code></td>
<td>

<p>An object of class <code>"vglm"</code> (see <code><a href="#topic+vglm-class">vglm-class</a></code>)
or inherits from that class.
</p>

</td></tr>
<tr><td><code id="plotvglm_+3A_which">which</code></td>
<td>

<p>If a subset of the plots is required, specify a subset of the
numbers <code>1:(2*M)</code>.
The default is to plot them all.
</p>
</td></tr>
<tr><td><code id="plotvglm_+3A_...">...</code></td>
<td>

<p>Arguments fed into the primitive <code><a href="graphics.html#topic+plot">plot</a></code>
functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is under development.
Currently it plots the Pearson residuals
against the predicted
values (on the transformed scale) and the hat values.
There are <code class="reqn">2M</code> plots in total, therefore
users should call <code><a href="graphics.html#topic+par">par</a></code>
to assign, e.g., the <code>mfrow</code> argument.
Note: Section 3.7 of Yee (2015) describes the
Pearson residuals and hat values for VGLMs.
</p>


<h3>Value</h3>

<p>Returns the object invisibly.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+plotvgam">plotvgam</a></code>,
<code><a href="#topic+plotvgam.control">plotvgam.control</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ndata &lt;- data.frame(x2 = runif(nn &lt;- 200))
ndata &lt;- transform(ndata, y1 = rnbinom(nn, mu = exp(3+x2), size = exp(1)))
fit1 &lt;- vglm(y1 ~ x2, negbinomial, data = ndata, trace = TRUE)
coef(fit1, matrix = TRUE)
par(mfrow = c(2, 2))
plot(fit1)

# Manually produce the four plots
plot(fit1, which = 1, col = "blue", las = 1, main = "main1")
abline(h = 0, lty = "dashed", col = "gray50")
plot(fit1, which = 2, col = "blue", las = 1, main = "main2")
abline(h = 0, lty = "dashed", col = "gray50")
plot(fit1, which = 3, col = "blue", las = 1, main = "main3")
plot(fit1, which = 4, col = "blue", las = 1, main = "main4")

## End(Not run)
</code></pre>

<hr>
<h2 id='pneumo'>Pneumoconiosis in Coalminers Data</h2><span id='topic+pneumo'></span>

<h3>Description</h3>

<p>The <code>pneumo</code> data frame has 8 rows and 4 columns.
Exposure time is explanatory, and there are 3 ordinal response variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pneumo)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>exposure.time</dt><dd><p>a numeric vector, in years</p>
</dd>
<dt>normal</dt><dd><p>a numeric vector, counts</p>
</dd>
<dt>mild</dt><dd><p>a numeric vector, counts</p>
</dd>
<dt>severe</dt><dd><p>a numeric vector, counts</p>
</dd>
</dl>



<h3>Details</h3>

<p>These were collected from coalface workers. In the original
data set, the two most severe categories were combined.
</p>


<h3>Source</h3>

<p>Ashford, J.R., 1959. An approach to the analysis of data for
semi-quantal responses in biological assay.
<em>Biometrics</em>, <b>15</b>, 573&ndash;581.
</p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cumulative">cumulative</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit the proportional odds model, p.179, in McCullagh and Nelder (1989)
pneumo &lt;- transform(pneumo, let = log(exposure.time))
vglm(cbind(normal, mild, severe) ~ let, propodds, data = pneumo)
</code></pre>

<hr>
<h2 id='poisson.points'> Poisson-points-on-a-plane/volume Distances Distribution </h2><span id='topic+poisson.points'></span>

<h3>Description</h3>

<p>Estimating the density parameter of the distances from a fixed point
to the u-th nearest point, in a plane or volume.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisson.points(ostatistic, dimension = 2, link = "loglink",
               idensity = NULL, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poisson.points_+3A_ostatistic">ostatistic</code></td>
<td>

<p>Order statistic.
A single positive value, usually an integer.
For example, the value 5 means the response are the distances
of the fifth nearest value to that point (usually over many
planes or volumes).
Non-integers are allowed because the value 1.5 coincides
with <code><a href="#topic+maxwell">maxwell</a></code> when <code>dimension = 2</code>.
Note: if <code>ostatistic = 1</code> and <code>dimension = 2</code> then
this <span class="pkg">VGAM</span> family function coincides with <code><a href="#topic+rayleigh">rayleigh</a></code>.
</p>
</td></tr>
<tr><td><code id="poisson.points_+3A_dimension">dimension</code></td>
<td>

<p>The value 2 or 3; 2 meaning a plane and 3 meaning a volume.
</p>
</td></tr>
<tr><td><code id="poisson.points_+3A_link">link</code></td>
<td>

<p>Parameter link function applied to the (positive) density parameter,
called <code class="reqn">\lambda</code> below.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="poisson.points_+3A_idensity">idensity</code></td>
<td>

<p>Optional initial value for the parameter.
A <code>NULL</code> value means a value is obtained internally.
Use this argument if convergence failure occurs.
</p>
</td></tr>
<tr><td><code id="poisson.points_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method for <code class="reqn">\lambda</code>.
If failure to converge occurs try another value
and/or else specify a value for <code>idensity</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose the number of points in any region of area <code class="reqn">A</code> of the
plane is a Poisson random variable with mean <code class="reqn">\lambda A</code>
(i.e., <code class="reqn">\lambda</code> is the <em>density</em> of the points).
Given a fixed point <code class="reqn">P</code>, define <code class="reqn">D_1</code>, <code class="reqn">D_2</code>,... to be
the distance to the nearest point to <code class="reqn">P</code>, second nearest to <code class="reqn">P</code>,
etc.  This <span class="pkg">VGAM</span> family function estimates <code class="reqn">\lambda</code>
since the probability density function for <code class="reqn">D_u</code> is easily derived,
<code class="reqn">u=1,2,\ldots</code>.  Here, <code class="reqn">u</code> corresponds to the
argument <code>ostatistic</code>.
</p>
<p>Similarly, suppose the number of points in any volume <code class="reqn">V</code> is a
Poisson random variable with mean
<code class="reqn">\lambda V</code> where, once again, <code class="reqn">\lambda</code>
is the <em>density</em> of the points.
This <span class="pkg">VGAM</span> family function estimates <code class="reqn">\lambda</code> by
specifying the argument <code>ostatistic</code> and using
<code>dimension = 3</code>.
</p>
<p>The mean of <code class="reqn">D_u</code> is returned as the fitted values.
Newton-Raphson is the same as Fisher-scoring.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>Convergence may be slow if the initial values are far from the
solution. This often corresponds to the situation when the response
values are all close to zero, i.e., there is a high density of points.
</p>
<p>Formulae such as the means have not been fully checked.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+maxwell">maxwell</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pdata &lt;- data.frame(y = rgamma(10, shape = exp(-1)))  # Not proper data!
ostat &lt;- 2
fit &lt;- vglm(y ~ 1, poisson.points(ostat, 2), data = pdata,
            trace = TRUE, crit = "coef")
fit &lt;- vglm(y ~ 1, poisson.points(ostat, 3), data = pdata,
            trace = TRUE, crit = "coef")  # Slow convergence?
fit &lt;- vglm(y ~ 1, poisson.points(ostat, 3, idensi = 1), data = pdata,
            trace = TRUE, crit = "coef")
head(fitted(fit))
with(pdata, mean(y))
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='poissonff'> Poisson Regression </h2><span id='topic+poissonff'></span>

<h3>Description</h3>

<p>Family function for a generalized linear model fitted to
Poisson responses.
</p>




<h3>Usage</h3>

<pre><code class='language-R'>poissonff(link = "loglink", imu = NULL, imethod = 1,
          parallel = FALSE, zero = NULL, bred = FALSE,
          earg.link = FALSE, type.fitted = c("mean", "quantiles"),
          percentiles = c(25, 50, 75))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poissonff_+3A_link">link</code></td>
<td>

<p>Link function applied to the mean or means.
See <code><a href="#topic+Links">Links</a></code> for more choices
and information.
</p>
</td></tr>
















<tr><td><code id="poissonff_+3A_parallel">parallel</code></td>
<td>

<p>A logical or formula. Used only if the response is a matrix.
</p>
</td></tr>
<tr><td><code id="poissonff_+3A_imu">imu</code>, <code id="poissonff_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="poissonff_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector specifying which linear/additive
predictors
are modelled as intercepts only.  The values must be from the set
{1,2,...,<code class="reqn">M</code>}, where <code class="reqn">M</code> is the number of columns of the
matrix response.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="poissonff_+3A_bred">bred</code>, <code id="poissonff_+3A_earg.link">earg.link</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
Setting <code>bred = TRUE</code> should work for
multiple responses and all <span class="pkg">VGAM</span> link functions;
it has been tested for
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="base.html#topic+identity">identity</a></code> but further testing is required.
</p>
</td></tr>
<tr><td><code id="poissonff_+3A_type.fitted">type.fitted</code>, <code id="poissonff_+3A_percentiles">percentiles</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code class="reqn">M</code> defined above is the number of linear/additive predictors.
With overdispersed data try <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>












<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
and <code><a href="#topic+cao">cao</a></code>.
</p>


<h3>Warning </h3>

<p>With multiple responses, assigning a known dispersion parameter
for <em>each</em> response is not handled well yet.  Currently, only
a single known dispersion parameter is handled well.
</p>


<h3>Note</h3>

<p>This function will handle a matrix response automatically.
</p>




<p>Regardless of whether the dispersion parameter is to be estimated or
not, its value can be seen from the output from the <code>summary()</code>
of the object.
</p>




<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+genpoisson1">genpoisson1</a></code>,
<code><a href="#topic+genpoisson2">genpoisson2</a></code>,
<code><a href="#topic+genpoisson0">genpoisson0</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+pospoisson">pospoisson</a></code>,
<code><a href="VGAMdata.html#topic+oipospoisson">oipospoisson</a></code>,
<code><a href="VGAMdata.html#topic+otpospoisson">otpospoisson</a></code>,
<code><a href="#topic+skellam">skellam</a></code>,
<code><a href="#topic+mix2poisson">mix2poisson</a></code>,
<code><a href="#topic+cens.poisson">cens.poisson</a></code>,
<code><a href="#topic+ordpoisson">ordpoisson</a></code>,
<code><a href="#topic+amlpoisson">amlpoisson</a></code>,
<code><a href="#topic+inv.binomial">inv.binomial</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+polf">polf</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+cao">cao</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="stats.html#topic+poisson">poisson</a></code>,
<code><a href="stats.html#topic+Poisson">Poisson</a></code>,
<code><a href="#topic+poisson.points">poisson.points</a></code>,
<code><a href="#topic+ruge">ruge</a></code>,
<code><a href="#topic+V1">V1</a></code>,
<code><a href="#topic+V2">V2</a></code>,
<code><a href="#topic+residualsvglm">residualsvglm</a></code>,
<code><a href="#topic+margeff">margeff</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>poissonff()

set.seed(123)
pdata &lt;- data.frame(x2 = rnorm(nn &lt;- 100))
pdata &lt;- transform(pdata, y1 = rpois(nn, exp(1 + x2)),
                          y2 = rpois(nn, exp(1 + x2)))
(fit1 &lt;- vglm(cbind(y1, y2) ~ x2, poissonff, data = pdata))
(fit2 &lt;- vglm(y1 ~ x2, poissonff(bred = TRUE), data = pdata))
coef(fit1, matrix = TRUE)
coef(fit2, matrix = TRUE)

nn &lt;- 200
cdata &lt;- data.frame(x2 = rnorm(nn), x3 = rnorm(nn), x4 = rnorm(nn))
cdata &lt;- transform(cdata, lv1 = 0 + x3 - 2*x4)
cdata &lt;- transform(cdata, lambda1 = exp(3 - 0.5 *  (lv1-0)^2),
                          lambda2 = exp(2 - 0.5 *  (lv1-1)^2),
                          lambda3 = exp(2 - 0.5 * ((lv1+4)/2)^2))
cdata &lt;- transform(cdata, y1 = rpois(nn, lambda1),
                          y2 = rpois(nn, lambda2),
                          y3 = rpois(nn, lambda3))
## Not run:  lvplot(p1, y = TRUE, lcol = 2:4, pch = 2:4, pcol = 2:4, rug = FALSE) 
</code></pre>

<hr>
<h2 id='PoissonPoints'>Poisson Points Distribution</h2><span id='topic+PoissonPoints'></span><span id='topic+dpois.points'></span><span id='topic+rpois.points'></span>

<h3>Description</h3>

<p>Density
for the
PoissonPoints distribution.
</p>




<h3>Usage</h3>

<pre><code class='language-R'>dpois.points(x, lambda, ostatistic, dimension = 2, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoissonPoints_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="PoissonPoints_+3A_lambda">lambda</code></td>
<td>

<p>the mean density of points.
</p>
</td></tr>
<tr><td><code id="PoissonPoints_+3A_ostatistic">ostatistic</code></td>
<td>

<p>positive values, usually integers.
</p>
</td></tr>
<tr><td><code id="PoissonPoints_+3A_dimension">dimension</code></td>
<td>

<p>Either 2 and/or 3.
</p>
</td></tr>




<tr><td><code id="PoissonPoints_+3A_log">log</code></td>
<td>

<p>Logical; if TRUE, the logarithm is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+poisson.points">poisson.points</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for the formula of the probability density function and other details.
</p>


<h3>Value</h3>

<p><code>dpois.points</code> gives the density. 
</p>





<h3>See Also</h3>

<p><code><a href="#topic+poisson.points">poisson.points</a></code>,
<code><a href="stats.html#topic+Poisson">dpois</a></code>,
<code><a href="#topic+Maxwell">Maxwell</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  lambda &lt;- 1; xvec &lt;- seq(0, 2, length = 400)
plot(xvec, dpois.points(xvec, lambda, ostat = 1, dimension = 2),
     type = "l", las = 1, col = "blue",
     sub = "First order statistic",
     main = paste("PDF of PoissonPoints distribution with lambda = ",
                  lambda, " and on the plane", sep = "")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Polono'>The Poisson Lognormal Distribution</h2><span id='topic+Polono'></span><span id='topic+dpolono'></span><span id='topic+ppolono'></span><span id='topic+rpolono'></span>

<h3>Description</h3>

<p>Density, distribution function and random
generation for the Poisson lognormal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpolono(x, meanlog = 0, sdlog = 1, bigx = 170, ...)
ppolono(q, meanlog = 0, sdlog = 1,
        isOne = 1 - sqrt( .Machine$double.eps ), ...)
rpolono(n, meanlog = 0, sdlog = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Polono_+3A_x">x</code>, <code id="Polono_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>

<tr><td><code id="Polono_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the number required.
</p>
</td></tr>
<tr><td><code id="Polono_+3A_meanlog">meanlog</code>, <code id="Polono_+3A_sdlog">sdlog</code></td>
<td>

<p>the mean and standard deviation of the normal distribution
(on the log scale).
They match the arguments in
<code><a href="stats.html#topic+Lognormal">Lognormal</a></code>.
</p>
</td></tr>
<tr><td><code id="Polono_+3A_bigx">bigx</code></td>
<td>

<p>Numeric.
This argument is for handling large values of <code>x</code> and/or
when <code><a href="stats.html#topic+integrate">integrate</a></code> fails.
A first order Taylor series approximation
[Equation (7) of Bulmer (1974)]
is used at values of <code>x</code> that are greater or equal to this argument.
For <code>bigx = 10</code>,
he showed that the approximation has a relative error less than
0.001 for values of <code>meanlog</code> and
<code>sdlog</code> &ldquo;likely to be encountered in practice&rdquo;.
The argument can be assigned <code>Inf</code> in which case
the approximation is not used.
</p>
</td></tr>
<tr><td><code id="Polono_+3A_isone">isOne</code></td>
<td>

<p>Used to test whether the cumulative probabilities have
effectively reached unity.
</p>
</td></tr>
<tr><td><code id="Polono_+3A_...">...</code></td>
<td>

<p>Arguments passed into
<code><a href="stats.html#topic+integrate">integrate</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Poisson lognormal distribution is similar to the negative
binomial in that it can be motivated by a Poisson distribution whose
mean parameter comes from a right skewed distribution (gamma for the
negative binomial and lognormal for the Poisson lognormal distribution).
</p>





<h3>Value</h3>

<p><code>dpolono</code> gives the density,
<code>ppolono</code> gives the distribution function, and
<code>rpolono</code> generates random deviates.
</p>



<h3>Note</h3>

<p>By default,
<code>dpolono</code> involves numerical integration that is performed using
<code><a href="stats.html#topic+integrate">integrate</a></code>. Consequently, computations are very
slow and numerical problems may occur
(if so then the use of <code>...</code> may be needed).
Alternatively, for extreme values of <code>x</code>, <code>meanlog</code>,
<code>sdlog</code>, etc., the use of <code>bigx = Inf</code> avoids the call to
<code><a href="stats.html#topic+integrate">integrate</a></code>, however the answer may be a little
inaccurate.
</p>
<p>For the maximum likelihood estimation of the 2 parameters a <span class="pkg">VGAM</span>
family function called <code>polono()</code>, say, has not been written yet.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
Some anonymous soul kindly wrote <code>ppolono()</code> and
improved the original <code>dpolono()</code>.
</p>


<h3>References</h3>

<p>Bulmer, M. G. (1974).
On fitting the Poisson lognormal distribution to species-abundance data.
<em>Biometrics</em>,
<b>30</b>,
101&ndash;110.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lognormal">lognormal</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>meanlog &lt;- 0.5; sdlog &lt;- 0.5; yy &lt;- 0:19
sum(proby &lt;- dpolono(yy, m = meanlog, sd = sdlog))  # Should be 1
max(abs(cumsum(proby) - ppolono(yy, m = meanlog, sd = sdlog)))  # Should be 0

## Not run:  opar = par(no.readonly = TRUE)
par(mfrow = c(2, 2))
plot(yy, proby, type = "h", col = "blue", ylab = "P[Y=y]", log = "",
     main = paste("Poisson lognormal(m = ", meanlog,
                  ", sdl = ", sdlog, ")", sep = ""))

y &lt;- 0:190  # More extreme values; use the approximation and plot on a log scale
(sum(proby &lt;- dpolono(y, m = meanlog, sd = sdlog, bigx = 100)))  # Should be 1
plot(y, proby, type = "h", col = "blue", ylab = "P[Y=y] (log)", log = "y",
     main = paste("Poisson lognormal(m = ", meanlog,
                  ", sdl = ", sdlog, ")", sep = ""))  # Note the kink at bigx

# Random number generation
table(y &lt;- rpolono(n = 1000, m = meanlog, sd = sdlog))
hist(y, breaks = ((-1):max(y))+0.5, prob = TRUE, border = "blue")
par(opar) 
## End(Not run)
</code></pre>

<hr>
<h2 id='posbernoulli.b'> Positive Bernoulli Family Function with Behavioural Effects </h2><span id='topic+posbernoulli.b'></span>

<h3>Description</h3>

<p>Fits a GLM-/GAM-like model to multiple Bernoulli responses where
each row in the capture history matrix response has at least
one success (capture).
Capture history behavioural effects are accommodated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posbernoulli.b(link = "logitlink", drop.b = FALSE ~ 1,
   type.fitted = c("likelihood.cond", "mean.uncond"), I2 = FALSE,
   ipcapture = NULL, iprecapture = NULL,
   p.small = 1e-4, no.warning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posbernoulli.b_+3A_link">link</code>, <code id="posbernoulli.b_+3A_drop.b">drop.b</code>, <code id="posbernoulli.b_+3A_ipcapture">ipcapture</code>, <code id="posbernoulli.b_+3A_iprecapture">iprecapture</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information about
these arguments.
By default the parallelism assumption does not apply to the
intercept.
With an intercept-only model
setting <code>drop.b = TRUE ~ 1</code> results in the
<code class="reqn">M_0</code>/<code class="reqn">M_h</code> model.
</p>








</td></tr>
<tr><td><code id="posbernoulli.b_+3A_i2">I2</code></td>
<td>

<p>Logical.
This argument is used for terms that are not parallel.
If <code>TRUE</code> then the constraint matrix <code>diag(2)</code>
(the general default constraint matrix in <span class="pkg">VGAM</span>) is used,
else <code>cbind(0:1, 1)</code>.
The latter means the first element/column
corresponds to the behavioural effect.
Consequently it and its standard error etc. can be accessed
directly without subtracting two quantities.
</p>
</td></tr>
<tr><td><code id="posbernoulli.b_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Details at <code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>.
</p>
</td></tr>
<tr><td><code id="posbernoulli.b_+3A_p.small">p.small</code>, <code id="posbernoulli.b_+3A_no.warning">no.warning</code></td>
<td>

<p>See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This model
(commonly known as <code class="reqn">M_b</code>/<code class="reqn">M_{bh}</code> in the
capture&ndash;recapture literature)
operates on a capture history matrix response of 0s and 1s
(<code class="reqn">n \times \tau</code>).
See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> for details,
e.g., common assumptions with other models.
Once an animal is captured for the first time,
it is marked/tagged so that its future
capture history can be recorded. The effect of the recapture
probability is modelled through a second linear/additive
predictor.  It is well-known that some species of animals are
affected by capture,
e.g., trap-shy or trap-happy. This <span class="pkg">VGAM</span> family function
<em>does</em> allow the capture history to be modelled via such
behavioural effects.
So does <code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code> but
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> cannot.
</p>


<p>The number of linear/additive predictors is <code class="reqn">M = 2</code>,
and the default links are
<code class="reqn">(logit \,p_c, logit \,p_r)^T</code>
where <code class="reqn">p_c</code> is the probability of capture and
<code class="reqn">p_r</code> is the probability of recapture.
The fitted value returned is of the same dimension as
the response matrix, and depends on the capture history:
prior to being first captured, it is <code>pcapture</code>.
Afterwards, it is <code>precapture</code>.
</p>
<p>By default, the constraint matrices for the intercept term
and the other covariates are set up so that <code class="reqn">p_r</code>
differs from <code class="reqn">p_c</code> by a simple binary effect,
on a logit scale.
However, this difference (the behavioural effect) is more
directly estimated by having <code>I2 = FALSE</code>.
Then it allows an estimate of the trap-happy/trap-shy effect;
these are positive/negative values respectively.
If <code>I2 = FALSE</code> then
the (nonstandard) constraint matrix used is
<code>cbind(0:1, 1)</code>,
meaning the first element can be interpreted as the behavioural
effect.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The dependent variable is <em>not</em> scaled to row proportions.
This is the same as <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>
and <code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>
but different from <code><a href="#topic+posbinomial">posbinomial</a></code>
and <code><a href="#topic+binomialff">binomialff</a></code>.
</p>






<h3>Author(s)</h3>

<p> Thomas W. Yee. </p>


<h3>References</h3>

<p>See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> and
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code> (including estimating <code class="reqn">N</code>),
<code><a href="#topic+deermice">deermice</a></code>,
<code><a href="#topic+dposbern">dposbern</a></code>,
<code><a href="#topic+rposbern">rposbern</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+aux.posbernoulli.t">aux.posbernoulli.t</a></code>,
<code><a href="#topic+prinia">prinia</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'># deermice data ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,

# Fit a M_b model
M.b &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ 1,
            posbernoulli.b, data = deermice, trace = TRUE)
coef(M.b)["(Intercept):1"]  # Behavioural effect on logit scale
coef(M.b, matrix = TRUE)
constraints(M.b, matrix = TRUE)
summary(M.b, presid = FALSE)

# Fit a M_bh model
M.bh &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + weight,
             posbernoulli.b, data = deermice, trace = TRUE)
coef(M.bh, matrix = TRUE)
coef(M.bh)["(Intercept):1"]  # Behavioural effect on logit scale
# (2,1) elt is for the behavioural effect:
constraints(M.bh)[["(Intercept)"]]
summary(M.bh, presid = FALSE)  # Significant trap-happy effect
# Approx. 95 percent confidence for the behavioural effect:
SE.M.bh &lt;- coef(summary(M.bh))["(Intercept):1", "Std. Error"]
coef(M.bh)["(Intercept):1"] + c(-1, 1) * 1.96 * SE.M.bh

# Fit a M_h model
M.h &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + weight,
            posbernoulli.b(drop.b = TRUE ~ sex + weight),
            data = deermice, trace = TRUE)
coef(M.h, matrix = TRUE)
constraints(M.h, matrix = TRUE)
summary(M.h, presid = FALSE)

# Fit a M_0 model
M.0 &lt;- vglm(cbind(    y1 + y2 + y3 + y4 + y5 + y6,
                  6 - y1 - y2 - y3 - y4 - y5 - y6) ~ 1,
            posbinomial, data = deermice, trace = TRUE)
coef(M.0, matrix = TRUE)
summary(M.0, presid = FALSE)


# Simulated data set ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
set.seed(123); nTimePts &lt;- 5; N &lt;- 1000  # N is the popn size
pdata &lt;- rposbern(N, nTimePts=nTimePts, pvars=2, is.popn=TRUE)
nrow(pdata)  # &lt; N (because some animals were never captured)
# The truth: xcoeffs are c(-2, 1, 2) and cap.effect = +1

M.bh.2 &lt;- vglm(cbind(y1, y2, y3, y4, y5) ~ x2,
               posbernoulli.b, data = pdata, trace = TRUE)
coef(M.bh.2)
coef(M.bh.2, matrix = TRUE)
constraints(M.bh.2, matrix = TRUE)
summary(M.bh.2, presid = FALSE)
head(depvar(M.bh.2))    # Capture history response matrix
head(M.bh.2@extra$cap.hist1)  # Info on its capture history
head(M.bh.2@extra$cap1)  # When it was first captured
head(fitted(M.bh.2))     # Depends on capture history
(trap.effect &lt;- coef(M.bh.2)["(Intercept):1"])  # Should be +1
head(model.matrix(M.bh.2, type = "vlm"), 21)
head(pdata)
summary(pdata)
dim(depvar(M.bh.2))
vcov(M.bh.2)

M.bh.2@extra$N.hat  # Population size estimate; should be about N
M.bh.2@extra$SE.N.hat  # SE of the estimate of the population size
# An approximate 95 percent confidence interval:
round(M.bh.2@extra$N.hat + c(-1, 1)*1.96* M.bh.2@extra$SE.N.hat, 1)
</code></pre>

<hr>
<h2 id='posbernoulli.t'> Positive Bernoulli Family Function with Time Effects </h2><span id='topic+posbernoulli.t'></span>

<h3>Description</h3>

<p>Fits a GLM/GAM-like model to multiple Bernoulli responses where
each row in the capture history matrix response has at least one
success (capture).
Sampling occasion effects are accommodated.
</p>




<h3>Usage</h3>

<pre><code class='language-R'>posbernoulli.t(link = "logitlink", parallel.t = FALSE ~ 1,
    iprob = NULL, p.small = 1e-4, no.warning = FALSE,
    type.fitted = c("probs", "onempall0"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posbernoulli.t_+3A_link">link</code>, <code id="posbernoulli.t_+3A_iprob">iprob</code>, <code id="posbernoulli.t_+3A_parallel.t">parallel.t</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
By default, the parallelism assumption does not apply to the
intercept.
Setting <code>parallel.t = FALSE ~ -1</code>,
or equivalently <code>parallel.t = FALSE ~ 0</code>,
results in the <code class="reqn">M_0</code>/<code class="reqn">M_h</code> model.
</p>
</td></tr>
<tr><td><code id="posbernoulli.t_+3A_p.small">p.small</code>, <code id="posbernoulli.t_+3A_no.warning">no.warning</code></td>
<td>

<p>A small probability value used to give a warning for the
Horvitz&ndash;Thompson estimator.
Any estimated probability value less than <code>p.small</code> will
result in a warning, however, setting <code>no.warning = TRUE</code>
will suppress this warning if it occurs.
This is because the Horvitz-Thompson estimator is the sum of
the reciprocal of such probabilities, therefore any probability
that is too close to 0 will result in an unstable estimate.
</p>
</td></tr>
<tr><td><code id="posbernoulli.t_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
The default is to return a matrix of probabilities.
If <code>"onempall0"</code> is chosen then the
the probability that each animal is captured at least once
in the course of the study is returned.
The abbreviation stands for
one minus the probability of all 0s, and
the quantity appears in the denominator of the usual formula.
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>These models (commonly known as <code class="reqn">M_t</code> or <code class="reqn">M_{th}</code>
(no prefix <code class="reqn">h</code> means it is an intercept-only model)
in the capture&ndash;recapture literature) operate on a capture
history matrix response of 0s and 1s
(<code class="reqn">n \times \tau</code>).
Each column is a
sampling occasion where animals are potentially captured
(e.g., a field trip), and each row is an individual animal.
Capture is a 1, else a 0.  No removal of animals from
the population is made (closed population), e.g., no
immigration or emigration.  Each row of the response
matrix has at least one capture.
Once an animal is captured for the first time,
it is marked/tagged so that its future capture history can
be recorded.  Then it is released immediately back into the
population to remix.  It is released immediately after each
recapture too.  It is assumed that the animals are independent
and that, for a given animal, each sampling occasion is
independent.  And animals do not lose their marks/tags, and
all marks/tags are correctly recorded.
</p>
<p>The number of linear/additive predictors is equal to the number
of sampling occasions, i.e., <code class="reqn">M = \tau</code>, say.
The default link functions are
<code class="reqn">(logit \,p_{1},\ldots,logit \,p_{\tau})^T</code>
where each <code class="reqn">p_{j}</code> denotes the probability of capture at
time point <code class="reqn">j</code>.
The fitted value returned is a matrix of probabilities
of the same dimension as the response matrix.
</p>

<p>A conditional likelihood is maximized here using Fisher scoring.
Each sampling occasion has a separate probability that
is modelled here. The probabilities can be constrained
to be equal by setting <code>parallel.t = FALSE ~ 0</code>;
then the results are effectively the same as
<code><a href="#topic+posbinomial">posbinomial</a></code> except the binomial constants are
not included in the log-likelihood.
If <code>parallel.t = TRUE ~ 0</code> then each column should have
at least one 1 and at least one 0.
</p>
<p>It is well-known that some species of animals are affected
by capture, e.g., trap-shy or trap-happy. This <span class="pkg">VGAM</span>
family function does <em>not</em> allow any behavioral effect to be
modelled (<code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>
and <code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code> do) because the
denominator of the likelihood function must be free of
behavioral effects.
</p>











<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>Upon fitting the <code>extra</code> slot has a (list) component
called <code>N.hat</code>
which is a point estimate of the population size <code class="reqn">N</code>
(it is the Horvitz-Thompson (1952) estimator).
And there is a component called <code>SE.N.hat</code>
containing its standard error.
</p>


<h3>Note</h3>








<p>The <code>weights</code> argument of <code><a href="#topic+vglm">vglm</a></code> need not be
assigned, and the default is just a matrix of ones.
</p>
<p>Fewer numerical problems are likely to occur
for <code>parallel.t = TRUE</code>.
Data-wise, each sampling occasion may need at least one success
(capture) and one failure.
Less stringent conditions in the data are needed when
<code>parallel.t = TRUE</code>.
Ditto when parallelism is applied to the intercept too.

</p>
<p>The response matrix is returned unchanged;
i.e., not converted into proportions like
<code><a href="#topic+posbinomial">posbinomial</a></code>.  If the response matrix has column
names then these are used in the labelling, else <code>prob1</code>,
<code>prob2</code>, etc. are used.
</p>
<p>Using <code>AIC()</code> or <code>BIC()</code> to compare
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>,
<code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>,
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>
models with a
<code><a href="#topic+posbinomial">posbinomial</a></code>
model requires <code>posbinomial(omit.constant = TRUE)</code>
because one needs to remove the normalizing constant from the
log-likelihood function.
See <code><a href="#topic+posbinomial">posbinomial</a></code> for an example.
</p>










<h3>Author(s)</h3>

<p> Thomas W. Yee. </p>


<h3>References</h3>

<p>Huggins, R. M. (1991).
Some practical aspects of a conditional likelihood
approach to capture experiments.
<em>Biometrics</em>,
<b>47</b>, 725&ndash;732.
</p>
<p>Huggins, R. M. and Hwang, W.-H. (2011).
A review of the use of conditional likelihood in
capture&ndash;recapture experiments.
<em>International Statistical Review</em>,
<b>79</b>, 385&ndash;400.
</p>
<p>Otis, D. L. and Burnham, K. P. and White, G. C. and Anderson,
D. R. (1978).
Statistical inference from capture data on closed animal
populations,
<em>Wildlife Monographs</em>,
<b>62</b>, 3&ndash;135.
</p>
<p>Yee, T. W. and Stoklosa, J. and Huggins, R. M. (2015).
The <span class="pkg">VGAM</span> package for capture&ndash;recapture data using the
conditional likelihood.
<em>Journal of Statistical Software</em>,
<b>65</b>, 1&ndash;33.
<a href="https://doi.org/10.18637/jss.v065.i05">doi:10.18637/jss.v065.i05</a>.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>,
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>,
<code><a href="#topic+Select">Select</a></code>,
<code><a href="#topic+deermice">deermice</a></code>,
<code><a href="#topic+Huggins89table1">Huggins89table1</a></code>,
<code><a href="#topic+Huggins89.t1">Huggins89.t1</a></code>,
<code><a href="#topic+dposbern">dposbern</a></code>,
<code><a href="#topic+rposbern">rposbern</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+AICvlm">AICvlm</a></code>,
<code><a href="#topic+BICvlm">BICvlm</a></code>,
<code><a href="#topic+prinia">prinia</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>M.t &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ 1, posbernoulli.t,
            data = deermice, trace = TRUE)
coef(M.t, matrix = TRUE)
constraints(M.t, matrix = TRUE)
summary(M.t, presid = FALSE)

M.h.1 &lt;- vglm(Select(deermice, "y") ~ sex + weight, trace = TRUE,
              posbernoulli.t(parallel.t = FALSE ~ -1), deermice)
coef(M.h.1, matrix = TRUE)
constraints(M.h.1)
summary(M.h.1, presid = FALSE)
head(depvar(M.h.1))  # Response capture history matrix
dim(depvar(M.h.1))

M.th.2 &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + weight,
               posbernoulli.t(parallel.t = FALSE), deermice)
# Test the parallelism assumption wrt sex and weight:
lrtest(M.h.1, M.th.2)
coef(M.th.2)
coef(M.th.2, matrix = TRUE)
constraints(M.th.2)
summary(M.th.2, presid = FALSE)
head(model.matrix(M.th.2, type = "vlm"), 21)

M.th.2@extra$N.hat  # Population size estimate; should be about N
M.th.2@extra$SE.N.hat  # SE of the estimate of the population size
# An approximate 95 percent confidence interval:
round(M.th.2@extra$N.hat + c(-1, 1)*1.96* M.th.2@extra$SE.N.hat, 1)

# Fit a M_h model, effectively the parallel M_t model:
deermice &lt;- transform(deermice, ysum = y1 + y2 + y3 + y4 + y5 + y6,
                                tau  = 6)
M.h.3 &lt;- vglm(cbind(ysum, tau - ysum) ~ sex + weight,
              posbinomial(omit.constant = TRUE), data = deermice)
max(abs(coef(M.h.1) - coef(M.h.3)))  # Should be zero
# Difference is due to the binomial constants:
logLik(M.h.3) - logLik(M.h.1)
</code></pre>

<hr>
<h2 id='posbernoulli.tb'> Positive Bernoulli Family Function with Time and
Behavioural Effects </h2><span id='topic+posbernoulli.tb'></span>

<h3>Description</h3>

<p>Fits a GLM/GAM-like model to multiple
Bernoulli responses where
each row in the capture history matrix response has at least
one success (capture).
Sampling occasion effects and behavioural effects are
accommodated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posbernoulli.tb(link = "logitlink", parallel.t = FALSE ~ 1,
   parallel.b = FALSE ~ 0, drop.b = FALSE ~ 1,
   type.fitted = c("likelihood.cond", "mean.uncond"),
   imethod = 1, iprob = NULL,
   p.small = 1e-4, no.warning = FALSE,
   ridge.constant = 0.0001, ridge.power = -4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posbernoulli.tb_+3A_link">link</code>, <code id="posbernoulli.tb_+3A_imethod">imethod</code>, <code id="posbernoulli.tb_+3A_iprob">iprob</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="posbernoulli.tb_+3A_parallel.t">parallel.t</code>, <code id="posbernoulli.tb_+3A_parallel.b">parallel.b</code>, <code id="posbernoulli.tb_+3A_drop.b">drop.b</code></td>
<td>

<p>A logical, or formula with a logical as the response.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
The <code>parallel.</code>-type arguments
specify whether the constraint matrices have a parallelism
assumption for the temporal and behavioural effects.
Argument <code>parallel.t</code> means parallel with
respect to time, and matches the same argument name in
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>
<p>Suppose the model is intercept-only.
Setting <code>parallel.t = FALSE ~ 0</code> results in the <code class="reqn">M_b</code>
model.
Setting <code>drop.b = FALSE ~ 0</code> results in the <code class="reqn">M_t</code>
model because it drops columns off the constraint matrices
corresponding to any behavioural effect.
Setting <code>parallel.t = FALSE ~ 0</code> and
setting <code>parallel.b = FALSE ~ 0</code> results in the <code class="reqn">M_b</code>
model.
Setting <code>parallel.t = FALSE ~ 0</code>,
<code>parallel.b = FALSE ~ 0</code> and
<code>drop.b = FALSE ~ 0</code> results in the <code class="reqn">M_0</code> model.
Note the default for <code>parallel.t</code> and <code>parallel.b</code>
may be unsuitable for data sets which have a large <code class="reqn">\tau</code>
because of the large number of parameters; it might be too
flexible.  If it is desired to have the behaviour affect some
of the other covariates then set <code>drop.b = TRUE ~ 0</code>.
</p>
<p>The default model has a different intercept for each
sampling occasion, a time-parallelism assumption for all
other covariates, and a dummy variable representing a single
behavioural effect (also in the intercept).
</p>
<p>The most flexible model is to set
<code>parallel.b = TRUE  ~ 0</code>,
<code>parallel.t = TRUE  ~ 0</code> and
<code>drop.b = TRUE ~ 0</code>.
This means that all possible temporal and behavioural effects are
estimated, for the intercepts and other covariates.  Such a model
is <em>not</em> recommended; it will contain a lot of paramters.
</p>
</td></tr>
<tr><td><code id="posbernoulli.tb_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Character, one of the choices for the type of fitted value
returned.
The default is the first one.
Partial matching is okay.
For <code>"likelihood.cond"</code>:
the probability defined by the conditional likelihood.
For <code>"mean.uncond"</code>: the unconditional mean, which should
agree with <code><a href="base.html#topic+colMeans">colMeans</a></code> applied to the response
matrix for intercept-only models.
</p>
</td></tr>
<tr><td><code id="posbernoulli.tb_+3A_ridge.constant">ridge.constant</code>, <code id="posbernoulli.tb_+3A_ridge.power">ridge.power</code></td>
<td>

<p>Determines the ridge parameters at each IRLS iteration.
They are the constant and power (exponent) for the ridge
adjustment for the working weight matrices (the capture
probability block matrix, hence the first <code class="reqn">\tau</code> diagonal
values).
At iteration <code class="reqn">a</code> of the IRLS algorithm
a positive value is added to the first <code class="reqn">\tau</code>
diagonal elements of the working weight matrices to make
them positive-definite. This adjustment is the
mean of the diagonal elements of <code>wz</code> multipled by
<code class="reqn">K \times a^p</code>
where <code class="reqn">K</code> is <code>ridge.constant</code> and <code class="reqn">p</code> is
<code>ridge.power</code>.
This is always positive but decays to zero as
iterations proceed
(provided <code class="reqn">p</code> is negative etc.).
</p>
</td></tr>
<tr><td><code id="posbernoulli.tb_+3A_p.small">p.small</code>, <code id="posbernoulli.tb_+3A_no.warning">no.warning</code></td>
<td>

<p>See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This model
(commonly known as <code class="reqn">M_{tb}</code>/<code class="reqn">M_{tbh}</code>
in the capture&ndash;recapture literature)
operates on a response matrix of 0s and 1s
(<code class="reqn">n \times \tau</code>).
See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>
for information that is in common.
It allows time and behavioural effects to be modelled.
</p>
<p>Evidently,
the expected information matrix (EIM) seems <em>not</em>
of full rank (especially in early iterations), so
<code>ridge.constant</code> and <code>ridge.power</code> are used to
<em>try</em> fix up the problem.
The default link functions are
<code class="reqn">(logit \,p_{c1},\ldots,logit \,
p_{c\tau},logit \,p_{r2},\ldots,logit \,p_{r\tau})^T</code>
where the subscript <code class="reqn">c</code> denotes capture,
the subscript <code class="reqn">r</code> denotes recapture,
and it is not possible to recapture the animal at sampling
occasion 1.
Thus <code class="reqn">M = 2\tau - 1</code>.
The parameters are currently prefixed by <code>pcapture</code>
and <code>precapture</code>
for the capture and recapture probabilities.
This <span class="pkg">VGAM</span> family function may be further modified in
the future.
</p>





<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>It is a good idea to apply the parallelism assumption to each
sampling occasion except possibly with respect to the intercepts.
Also, a simple behavioural effect such as being modelled
using the intercept is recommended; if the behavioural effect
is not parallel and/or allowed to apply to other covariates
then there will probably be too many parameters, and hence,
numerical problems. See <code>M_tbh.1</code> below.
</p>










<p>It is a good idea to monitor convergence.
Simpler models such as the <code class="reqn">M_0</code>/<code class="reqn">M_h</code> models
are best fitted with <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> or
<code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code> or
<code><a href="#topic+posbinomial">posbinomial</a></code>.
</p>






<h3>Author(s)</h3>

<p> Thomas W. Yee. </p>


<h3>References</h3>

<p>See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code> (including <code>N.hat</code>),
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+Select">Select</a></code>,
<code><a href="#topic+fill1">fill1</a></code>,
<code><a href="#topic+Huggins89table1">Huggins89table1</a></code>,
<code><a href="#topic+Huggins89.t1">Huggins89.t1</a></code>,
<code><a href="#topic+deermice">deermice</a></code>,
<code><a href="#topic+prinia">prinia</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: simulated data
nTimePts &lt;- 5  # (aka tau == # of sampling occasions)
nnn &lt;- 1000   # Number of animals
pdata &lt;- rposbern(n = nnn, nTimePts = nTimePts, pvars = 2)
dim(pdata); head(pdata)

M_tbh.1 &lt;- vglm(cbind(y1, y2, y3, y4, y5) ~ x2,
                posbernoulli.tb, data = pdata, trace = TRUE)
coef(M_tbh.1)  # First element is the behavioural effect
coef(M_tbh.1, matrix = TRUE)
constraints(M_tbh.1, matrix = TRUE)
summary(M_tbh.1, presid = FALSE)  # Std errors are approximate
head(fitted(M_tbh.1))
head(model.matrix(M_tbh.1, type = "vlm"), 21)
dim(depvar(M_tbh.1))

M_tbh.2 &lt;- vglm(cbind(y1, y2, y3, y4, y5) ~ x2,
                posbernoulli.tb(parallel.t = FALSE ~  0),
                data = pdata, trace = TRUE)
coef(M_tbh.2)  # First element is the behavioural effect
coef(M_tbh.2, matrix = TRUE)
constraints(M_tbh.2, matrix = TRUE)
summary(M_tbh.2, presid = FALSE)  # Std errors are approximate
head(fitted(M_tbh.2))
head(model.matrix(M_tbh.2, type = "vlm"), 21)
dim(depvar(M_tbh.2))

# Example 2: deermice subset data
fit1 &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + weight,
             posbernoulli.t, data = deermice, trace = TRUE)
coef(fit1)
coef(fit1, matrix = TRUE)
constraints(fit1, matrix = TRUE)
summary(fit1, presid = FALSE)  # Standard errors are approximate

# fit1 is the same as Fit1 (a M_{th} model):
Fit1 &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ sex + weight,
             posbernoulli.tb(drop.b = TRUE ~ sex + weight,
                parallel.t = TRUE),  # But not for the intercept
             data = deermice, trace = TRUE)
constraints(Fit1)

## End(Not run)
</code></pre>

<hr>
<h2 id='posbernUC'> Positive Bernoulli Sequence Model </h2><span id='topic+posbernUC'></span><span id='topic+dposbern'></span><span id='topic+rposbern'></span>

<h3>Description</h3>

<p>Density, and random generation
for multiple Bernoulli responses where
each row in the response matrix has at least one success.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rposbern(n, nTimePts = 5, pvars = length(xcoeff),
  xcoeff = c(-2, 1, 2), Xmatrix = NULL, cap.effect = 1,
  is.popn = FALSE, link = "logitlink", earg.link = FALSE)
dposbern(x, prob, prob0 = prob, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posbernUC_+3A_x">x</code></td>
<td>

<p>response vector or matrix.
Should only have 0 and 1 values, at least two columns, and each
row should have at least one 1.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_ntimepts">nTimePts</code></td>
<td>
<p>Number of sampling occasions.
Called <code class="reqn">\tau</code> in <code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>
and <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_n">n</code></td>
<td>
<p>number of observations.
Usually a single positive integer, else the length of the vector
is used.
See argument <code>is.popn</code>.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_is.popn">is.popn</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then argument <code>n</code> is the population size and
what is returned may have substantially less rows than <code>n</code>.
That is, if an animal has at least one one in its sequence
then it is returned, else that animal is not returned because
it never was captured.


</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_xmatrix">Xmatrix</code></td>
<td>

<p>Optional <b>X</b> matrix.
If given, the <b>X</b> matrix is not generated internally.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_cap.effect">cap.effect</code></td>
<td>

<p>Numeric, the capture effect.
Added to the linear predictor if captured previously.
A positive or negative value corresponds to
a trap-happy and trap-shy effect respectively.
</p>
</td></tr>









<tr><td><code id="posbernUC_+3A_pvars">pvars</code></td>
<td>
<p> Number of other numeric covariates that make up
the  linear predictor.
Labelled <code>x1</code>, <code>x2</code>, ...,
where the first is an intercept, and the others are
independent standard <code><a href="stats.html#topic+Uniform">runif</a></code> random
variates.  The first <code>pvars</code> elements of <code>xcoeff</code>
are used.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_xcoeff">xcoeff</code></td>
<td>

<p>The regression coefficients of the linear predictor.
These correspond to <code>x1</code>, <code>x2</code>, ...,
and the first is for the intercept.
The length of <code>xcoeff</code> must be at least <code>pvars</code>.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_link">link</code>, <code id="posbernUC_+3A_earg.link">earg.link</code></td>
<td>

<p>The former is used to generate the probabilities for capture
at each occasion.
Other details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_prob">prob</code>, <code id="posbernUC_+3A_prob0">prob0</code></td>
<td>

<p>Matrix of probabilities for the numerator and denominators
respectively.
The default does <em>not</em> correspond to the
<code class="reqn">M_b</code> model since the <code class="reqn">M_b</code> model has a denominator
which involves the capture history.
</p>
</td></tr>
<tr><td><code id="posbernUC_+3A_log">log</code></td>
<td>

<p>Logical. Return the logarithm of the answer?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The form of the conditional likelihood is described in
<code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code> and/or
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> and/or
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>.
The denominator is equally shared among the elements of
the matrix <code>x</code>.
</p>


<h3>Value</h3>

<p><code>rposbern</code> returns a data frame with some attributes.
The function generates random deviates
(<code class="reqn">\tau</code> columns labelled <code>y1</code>, <code>y2</code>, ...)
for the response.
Some indicator columns are also included
(those starting with <code>ch</code> are for previous capture history).
The default setting corresponds to a <code class="reqn">M_{bh}</code> model that
has a single trap-happy effect.
Covariates <code>x1</code>, <code>x2</code>, ... have the same
affect on capture/recapture at every sampling occasion
(see the argument <code>parallel.t</code> in, e.g.,
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>).
</p>

<p>The function <code>dposbern</code> gives the density,
</p>


<h3>Note</h3>

<p>The <code>r</code>-type function is experimental only and does not
follow the usual conventions of <code>r</code>-type R functions.
It may change a lot in the future.
The <code>d</code>-type function is more conventional and is less
likely to change.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>,
<code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>,
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>rposbern(n = 10)
attributes(pdata &lt;- rposbern(n = 100))
M.bh &lt;- vglm(cbind(y1, y2, y3, y4, y5) ~ x2 + x3,
             posbernoulli.b(I2 = FALSE), pdata, trace = TRUE)
constraints(M.bh)
summary(M.bh)
</code></pre>

<hr>
<h2 id='posbinomial'> Positive Binomial Distribution Family Function </h2><span id='topic+posbinomial'></span>

<h3>Description</h3>

<p>Fits a positive binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posbinomial(link = "logitlink", multiple.responses = FALSE,
    parallel = FALSE, omit.constant = FALSE, p.small = 1e-4,
    no.warning = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posbinomial_+3A_link">link</code>, <code id="posbinomial_+3A_multiple.responses">multiple.responses</code>, <code id="posbinomial_+3A_parallel">parallel</code>, <code id="posbinomial_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="posbinomial_+3A_omit.constant">omit.constant</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the constant
(<code>lchoose(size, size * yprop)</code>
is omitted from the <code>loglikelihood</code> calculation.
If the model is to be compared using
<code>AIC()</code> or <code>BIC()</code>
(see <code><a href="#topic+AICvlm">AICvlm</a></code> or <code><a href="#topic+BICvlm">BICvlm</a></code>)
to the likes of
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code> etc. then it is important
to set <code>omit.constant = TRUE</code> because all models then
will not have any normalizing constants in the likelihood
function.
Hence they become comparable.
This is because the <code class="reqn">M_0</code> Otis et al. (1978) model
coincides with <code>posbinomial()</code>.
See below for an example.
Also see <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> regarding estimating
the population size (<code>N.hat</code> and <code>SE.N.hat</code>) if
the number of trials is the same for all observations.
</p>
</td></tr>
<tr><td><code id="posbinomial_+3A_p.small">p.small</code>, <code id="posbinomial_+3A_no.warning">no.warning</code></td>
<td>

<p>See <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The positive binomial distribution is the ordinary binomial
distribution
but with the probability of zero being zero.
Thus the other probabilities are scaled up
(i.e., divided by <code class="reqn">1-P(Y=0)</code>).
The fitted values are the ordinary binomial distribution fitted
values, i.e., the usual mean.
</p>
<p>In the capture&ndash;recapture literature this model is called
the <code class="reqn">M_0</code> if it is an intercept-only model.
Otherwise it is called the <code class="reqn">M_h</code> when there are covariates.
It arises from a sum of a sequence of
<code class="reqn">\tau</code>-Bernoulli random variates subject to at least
one success (capture).
Here, each animal has the same probability of capture or
recapture, regardless of the <code class="reqn">\tau</code> sampling occasions.
Independence between animals and between sampling occasions etc.
is assumed.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Under- or over-flow may occur if the data is ill-conditioned.
</p>


<h3>Note</h3>

<p>The input for this family function is the same as
<code><a href="#topic+binomialff">binomialff</a></code>.
</p>
<p>If <code>multiple.responses = TRUE</code> then each column of the
matrix response should be a count (the number of successes),
and the <code>weights</code> argument should be a matrix of the same
dimension as the response containing the number of trials.
If <code>multiple.responses = FALSE</code> then the response input
should be the same as <code><a href="#topic+binomialff">binomialff</a></code>.
</p>
<p>Yet to be done: a <code>quasi.posbinomial()</code> which estimates a
dispersion parameter.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Otis, D. L. et al. (1978).
Statistical inference from capture data on closed animal
populations,
<em>Wildlife Monographs</em>,
<b>62</b>, 3&ndash;135.
</p>
<p>Patil, G. P. (1962).
Maximum likelihood estimation for
generalised power series distributions and its application to a
truncated binomial distribution.
<em>Biometrika</em>,
<b>49</b>, 227&ndash;237.
</p>
<p>Pearson, K. (1913).
<em>A Monograph on Albinism in Man</em>.
Drapers Company Research Memoirs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posbernoulli.b">posbernoulli.b</a></code>,
<code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code>,
<code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+AICvlm">AICvlm</a></code>, <code><a href="#topic+BICvlm">BICvlm</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Albinotic children in families with 5 kids (from Patil, 1962) ,,,,
albinos &lt;- data.frame(y = c(rep(1, 25), rep(2, 23), rep(3, 10), 4, 5),
                      n = rep(5, 60))
fit1 &lt;- vglm(cbind(y, n-y) ~ 1, posbinomial, albinos, trace = TRUE)
summary(fit1)
Coef(fit1)  # = MLE of p = 0.3088
head(fitted(fit1))
sqrt(vcov(fit1, untransform = TRUE))  # SE = 0.0322

# Fit a M_0 model (Otis et al. 1978) to the deermice data ,,,,,,,,,,
M.0 &lt;- vglm(cbind(    y1 + y2 + y3 + y4 + y5 + y6,
                  6 - y1 - y2 - y3 - y4 - y5 - y6) ~ 1, trace = TRUE,
            posbinomial(omit.constant = TRUE), data = deermice)
coef(M.0, matrix = TRUE)
Coef(M.0)
constraints(M.0, matrix = TRUE)
summary(M.0)
c(   N.hat = M.0@extra$N.hat,     # As tau = 6, i.e., 6 Bernoulli trials
  SE.N.hat = M.0@extra$SE.N.hat)  # per obsn is the same for each obsn

# Compare it to the M_b using AIC and BIC
M.b &lt;- vglm(cbind(y1, y2, y3, y4, y5, y6) ~ 1, trace = TRUE,
            posbernoulli.b, data = deermice)
sort(c(M.0 = AIC(M.0), M.b = AIC(M.b)))  # Ok since omit.constant=TRUE
sort(c(M.0 = BIC(M.0), M.b = BIC(M.b)))  # Ok since omit.constant=TRUE
</code></pre>

<hr>
<h2 id='Posgeom'> Positive-Geometric Distribution </h2><span id='topic+Posgeom'></span><span id='topic+dposgeom'></span><span id='topic+pposgeom'></span><span id='topic+qposgeom'></span><span id='topic+rposgeom'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the positive-geometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dposgeom(x, prob, log = FALSE)
pposgeom(q, prob)
qposgeom(p, prob)
rposgeom(n, prob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Posgeom_+3A_x">x</code>, <code id="Posgeom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Posgeom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Posgeom_+3A_n">n</code></td>
<td>
<p>number of observations.
Fed into <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Posgeom_+3A_prob">prob</code></td>
<td>

<p>vector of probabilities of success (of an ordinary geometric distribution).
Short vectors are recycled.
</p>
</td></tr>
<tr><td><code id="Posgeom_+3A_log">log</code></td>
<td>

<p>logical.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The positive-geometric distribution is a geometric distribution but with
the probability of a zero being zero. The other probabilities are scaled
to add to unity.
The mean therefore is <code class="reqn">1/prob</code>.
</p>
<p>As <code class="reqn">prob</code> decreases, the positive-geometric and geometric
distributions become more similar.
Like similar functions for the geometric distribution, a zero value
of <code>prob</code> is not permitted here.
</p>


<h3>Value</h3>

<p><code>dposgeom</code> gives the density,
<code>pposgeom</code> gives the distribution function,
<code>qposgeom</code> gives the quantile function, and
<code>rposgeom</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zageometric">zageometric</a></code>,
<code><a href="#topic+zigeometric">zigeometric</a></code>,
<code><a href="stats.html#topic+Geometric">rgeom</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>prob &lt;- 0.75; y &lt;- rposgeom(n = 1000, prob)
table(y)
mean(y)  # Sample mean
1 / prob  # Population mean

(ii &lt;- dposgeom(0:7, prob))
cumsum(ii) - pposgeom(0:7, prob)  # Should be 0s
table(rposgeom(100, prob))

table(qposgeom(runif(1000), prob))
round(dposgeom(1:10, prob) * 1000)  # Should be similar

## Not run: 
x &lt;- 0:5
barplot(rbind(dposgeom(x, prob), dgeom(x, prob)),
        beside = TRUE, col = c("blue", "orange"),
        main = paste("Positive geometric(", prob, ") (blue) vs",
        " geometric(", prob, ") (orange)", sep = ""),
        names.arg = as.character(x), las = 1, lwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='posnegbinomial'> Positive Negative Binomial Distribution Family Function </h2><span id='topic+posnegbinomial'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the two parameters of a positive
negative binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posnegbinomial(zero = "size",
   type.fitted = c("mean", "munb", "prob0"),
   mds.min = 0.001, nsimEIM = 500, cutoff.prob = 0.999,
   eps.trig = 1e-07, max.support = 4000, max.chunk.MB = 30,
   lmunb = "loglink", lsize = "loglink", imethod = 1,
   imunb = NULL, iprobs.y = NULL,
   gprobs.y = ppoints(8), isize = NULL,
   gsize.mux = exp(c(-30, -20, -15, -10, -6:3)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posnegbinomial_+3A_lmunb">lmunb</code></td>
<td>

<p>Link function applied to the <code>munb</code> parameter, which is
the mean <code class="reqn">\mu_{nb}</code> of an ordinary negative binomial
distribution.  See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_lsize">lsize</code></td>
<td>

<p>Parameter link function applied to the dispersion parameter,
called <code>k</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_isize">isize</code></td>
<td>

<p>Optional initial value for <code>k</code>, an index parameter.
The value <code>1/k</code> is known as a dispersion parameter.
If failure to converge occurs try different values (and/or use
<code>imethod</code>).
If necessary this vector is recycled to length equal to the
number of responses.
A value <code>NULL</code> means an initial value for each response
is computed internally using a range of values.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_nsimeim">nsimEIM</code>, <code id="posnegbinomial_+3A_zero">zero</code>, <code id="posnegbinomial_+3A_eps.trig">eps.trig</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_mds.min">mds.min</code>, <code id="posnegbinomial_+3A_iprobs.y">iprobs.y</code>, <code id="posnegbinomial_+3A_cutoff.prob">cutoff.prob</code></td>
<td>

<p>Similar to <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_imunb">imunb</code>, <code id="posnegbinomial_+3A_max.support">max.support</code></td>
<td>

<p>Similar to <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_max.chunk.mb">max.chunk.MB</code>, <code id="posnegbinomial_+3A_gsize.mux">gsize.mux</code></td>
<td>

<p>Similar to <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_imethod">imethod</code>, <code id="posnegbinomial_+3A_gprobs.y">gprobs.y</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>.
</p>
</td></tr>
<tr><td><code id="posnegbinomial_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The positive negative binomial distribution is an ordinary
negative binomial distribution but with the probability of a
zero response being zero. The other probabilities are scaled
to sum to unity.
</p>
<p>This family function is based on <code><a href="#topic+negbinomial">negbinomial</a></code>
and most details can be found there. To avoid confusion, the
parameter <code>munb</code> here corresponds to the mean of an ordinary
negative binomial distribution <code><a href="#topic+negbinomial">negbinomial</a></code>. The
mean of <code>posnegbinomial</code> is
</p>
<p style="text-align: center;"><code class="reqn">\mu_{nb} / (1-p(0))</code>
</p>

<p>where
<code class="reqn">p(0) = (k/(k + \mu_{nb}))^k</code> is the
probability an ordinary negative binomial distribution has a
zero value.
</p>
<p>The parameters <code>munb</code> and <code>k</code> are not independent in
the positive negative binomial distribution, whereas they are
in the ordinary negative binomial distribution.
</p>
<p>This function handles <em>multiple</em> responses, so that a
matrix can be used as the response. The number of columns is
the number of species, say, and setting <code>zero = -2</code> means
that <em>all</em> species have a <code>k</code> equalling a (different)
intercept only.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This family function is fragile;
at least two cases will lead to numerical problems.
Firstly,
the positive-Poisson model corresponds to <code>k</code> equalling infinity.
If the data is positive-Poisson or close to positive-Poisson,
then the estimated <code>k</code> will diverge to <code>Inf</code> or some
very large value.
Secondly, if the data is clustered about the value 1 because
the <code>munb</code> parameter is close to 0
then numerical problems will also occur.
Users should set <code>trace = TRUE</code> to monitor convergence.
In the situation when both cases hold, the result returned
(which will be untrustworthy) will depend on the initial values.
</p>
<p>The negative binomial distribution (NBD) is a strictly unimodal
distribution.  Any data set that does not exhibit a mode (in the
middle) makes the estimation problem difficult.  The positive
NBD inherits this feature.  Set <code>trace = TRUE</code> to monitor
convergence.
</p>
<p>See the example below of a data set where <code>posbinomial()</code>
fails; the so-called solution is <em>extremely</em> poor.
This is partly due to a lack of a
unimodal shape because the number of counts decreases only.
This long tail makes it very difficult to estimate the mean
parameter with any certainty. The result too is that the
<code>size</code> parameter is numerically fraught.
</p>


<p>This <span class="pkg">VGAM</span> family function inherits the same warnings as
<code><a href="#topic+negbinomial">negbinomial</a></code>.
And if <code>k</code> is much less than 1 then the estimation may
be slow.
</p>


<h3>Note</h3>

<p>If the estimated <code class="reqn">k</code> is very large then fitting a
<code><a href="#topic+pospoisson">pospoisson</a></code> model is a good idea.
</p>
<p>If both <code>munb</code> and <code class="reqn">k</code> are large then it may be
necessary to decrease <code>eps.trig</code> and increase
<code>max.support</code> so that the EIMs are positive-definite,
e.g.,
<code>eps.trig = 1e-8</code> and <code>max.support = Inf</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Barry, S. C. and Welsh, A. H. (2002).
Generalized additive modelling and zero inflated count data.
<em>Ecological Modelling</em>,
<b>157</b>,
179&ndash;188.
</p>
<p>Williamson, E. and Bretherton, M. H. (1964).
Tables of the logarithmic series distribution.
<em>Annals of Mathematical Statistics</em>,
<b>35</b>,
284&ndash;297.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+pospoisson">pospoisson</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+zanegbinomial">zanegbinomial</a></code>,
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+corbet">corbet</a></code>,
<code><a href="#topic+logff">logff</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+margeff">margeff</a></code>.
</p>






<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
pdata &lt;- transform(pdata,
  y1 = rgaitdnbinom(nn, exp(1), munb.p = exp(0+2*x2), truncate = 0),
  y2 = rgaitdnbinom(nn, exp(3), munb.p = exp(1+2*x2), truncate = 0))
fit &lt;- vglm(cbind(y1, y2) ~ x2, posnegbinomial, pdata, trace = TRUE)
coef(fit, matrix = TRUE)
dim(depvar(fit))  # Using dim(fit@y) is not recommended


# Another artificial data example
pdata2 &lt;- data.frame(munb = exp(2), size = exp(3)); nn &lt;- 1000
pdata2 &lt;- transform(pdata2,
                    y3 = rgaitdnbinom(nn, size, munb.p = munb,
                                      truncate = 0))
with(pdata2, table(y3))
fit &lt;- vglm(y3 ~ 1, posnegbinomial, data = pdata2, trace = TRUE)
coef(fit, matrix = TRUE)
with(pdata2, mean(y3))  # Sample mean
head(with(pdata2, munb/(1-(size/(size+munb))^size)), 1)  # Popn mean
head(fitted(fit), 3)
head(predict(fit), 3)


# Example: Corbet (1943) butterfly Malaya data
fit &lt;- vglm(ofreq ~ 1, posnegbinomial, weights = species, corbet)
coef(fit, matrix = TRUE)
Coef(fit)
(khat &lt;- Coef(fit)["size"])
pdf2 &lt;- dgaitdnbinom(with(corbet, ofreq), khat,
                     munb.p = fitted(fit), truncate = 0)
print(with(corbet,
           cbind(ofreq, species, fitted = pdf2*sum(species))), dig = 1)
with(corbet,
matplot(ofreq, cbind(species, fitted = pdf2*sum(species)), las = 1,
   xlab = "Observed frequency (of individual butterflies)",
   type = "b", ylab = "Number of species", col = c("blue", "orange"),
   main = "blue 1s = observe; orange 2s = fitted"))

# Data courtesy of Maxim Gerashchenko causes posbinomial() to fail
pnbd.fail &lt;- data.frame(
 y1 = c(1:16, 18:21, 23:28, 33:38, 42, 44, 49:51, 55, 56, 58,
 59, 61:63, 66, 73, 76, 94, 107, 112, 124, 190, 191, 244),
 ofreq = c(130, 80, 38, 23, 22, 11, 21, 14, 6, 7, 9, 9, 9, 4, 4, 5, 1,
           4, 6, 1, 3, 2, 4, 3, 4, 5, 3, 1, 2, 1, 1, 4, 1, 2, 2, 1, 3,
           1, 1, 2, 2, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1))
fit.fail &lt;- vglm(y1 ~ 1, weights = ofreq, posnegbinomial,
               trace = TRUE, data = pnbd.fail)

## End(Not run)</code></pre>

<hr>
<h2 id='Posnorm'>The Positive-Normal Distribution</h2><span id='topic+Posnorm'></span><span id='topic+dposnorm'></span><span id='topic+pposnorm'></span><span id='topic+qposnorm'></span><span id='topic+rposnorm'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the univariate positive-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dposnorm(x, mean = 0, sd = 1, log = FALSE)
pposnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
qposnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
rposnorm(n, mean = 0, sd = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Posnorm_+3A_x">x</code>, <code id="Posnorm_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Posnorm_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Posnorm_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.
</p>
</td></tr>
<tr><td><code id="Posnorm_+3A_mean">mean</code>, <code id="Posnorm_+3A_sd">sd</code>, <code id="Posnorm_+3A_log">log</code>, <code id="Posnorm_+3A_lower.tail">lower.tail</code>, <code id="Posnorm_+3A_log.p">log.p</code></td>
<td>

<p>see <code><a href="stats.html#topic+Normal">rnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+posnormal">posnormal</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for the formula of the probability density function and other
details.
</p>


<h3>Value</h3>

<p><code>dposnorm</code> gives the density,
<code>pposnorm</code> gives the distribution function,
<code>qposnorm</code> gives the quantile function, and
<code>rposnorm</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+posnormal">posnormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  m &lt;-  0.8; x &lt;- seq(-1, 4, len = 501)
plot(x, dposnorm(x, m = m), type = "l", las = 1, ylim = 0:1,
     ylab = paste("posnorm(m = ", m, ", sd = 1)"), col = "blue",
     main = "Blue is density, orange is the CDF",
     sub = "Purple lines are the 10,20,...,90 percentiles")
abline(h = 0, col = "grey")
lines(x, pposnorm(x, m = m), col = "orange", type = "l")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qposnorm(probs, m = m)
lines(Q, dposnorm(Q, m = m), col = "purple", lty = 3, type = "h")
lines(Q, pposnorm(Q, m = m), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(pposnorm(Q, m = m) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='posnormal'> Positive Normal Distribution Family Function </h2><span id='topic+posnormal'></span>

<h3>Description</h3>

<p>Fits a positive (univariate) normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posnormal(lmean = "identitylink", lsd = "loglink",
          eq.mean = FALSE, eq.sd = FALSE,
          gmean = exp((-5:5)/2), gsd = exp((-1:5)/2),
          imean = NULL, isd = NULL, probs.y = 0.10, imethod = 1,
          nsimEIM = NULL, zero = "sd")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posnormal_+3A_lmean">lmean</code>, <code id="posnormal_+3A_lsd">lsd</code></td>
<td>

<p>Link functions for the mean and standard
deviation parameters of the usual univariate normal distribution.
They are <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>






<tr><td><code id="posnormal_+3A_gmean">gmean</code>, <code id="posnormal_+3A_gsd">gsd</code>, <code id="posnormal_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
<code>gmean</code> and <code>gsd</code>
currently operate on a multiplicative scale, on the sample mean
and the sample standard deviation, respectively.
</p>
</td></tr>
<tr><td><code id="posnormal_+3A_imean">imean</code>, <code id="posnormal_+3A_isd">isd</code></td>
<td>

<p>Optional initial values for <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>.
A <code>NULL</code> means a value is computed internally.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="posnormal_+3A_eq.mean">eq.mean</code>, <code id="posnormal_+3A_eq.sd">eq.sd</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The fact that these arguments are supported results in
default constraint matrices being a <em>permutation</em> of the
identity matrix (effectively <em>trivial</em> constraints).
</p>
</td></tr>
<tr><td><code id="posnormal_+3A_zero">zero</code>, <code id="posnormal_+3A_nsimeim">nsimEIM</code>, <code id="posnormal_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>











</table>


<h3>Details</h3>

<p>The positive normal distribution is the ordinary normal
distribution but with the probability of zero or less being zero.
The rest of the probability density function is scaled up.
Hence
the probability density function can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \frac{1}{\sqrt{2\pi} \sigma} \exp\left( -\frac12
             (y-\mu)^2 / \sigma^2  \right) /
             \left[ 1-\Phi(-\mu/ \sigma) \right]</code>
</p>

<p>where <code class="reqn">\Phi()</code> is the cumulative distribution function
of a standard normal (<code><a href="stats.html#topic+Normal">pnorm</a></code>).
Equivalently, this is
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \frac{1}{\sigma} \frac{\phi((y-\mu) / \sigma)}{
             1-\Phi(-\mu/ \sigma)}</code>
</p>

<p>where <code class="reqn">\phi()</code> is the probability
density function of a standard normal distribution
(<code><a href="stats.html#topic+Normal">dnorm</a></code>).
</p>
<p>The mean of <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = \mu + \sigma \frac{\phi(-\mu/ \sigma)}{
             1-\Phi(-\mu/ \sigma)}. </code>
</p>

<p>This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>It is recommended that <code>trace = TRUE</code> be used to monitor
convergence; sometimes the estimated mean is <code>-Inf</code> and the
estimated mean standard deviation is <code>Inf</code>, especially
when the sample size is small.
Under- or over-flow may occur if the data is ill-conditioned.
</p>


<h3>Note</h3>

<p>The response variable for this family function is the same as
<code><a href="#topic+uninormal">uninormal</a></code> except positive values are required.
Reasonably good initial values are needed.
</p>
<p>The distribution of the reciprocal of a positive normal random
variable is known as an alpha distribution.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+tobit">tobit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pdata &lt;- data.frame(Mean = 1.0, SD = exp(1.0))
pdata &lt;- transform(pdata, y = rposnorm(n &lt;- 1000, m = Mean, sd = SD))

## Not run: with(pdata, hist(y, prob = TRUE, border = "blue",
  main = paste("posnorm(m =", Mean[1], ", sd =", round(SD[1], 2),")")))
## End(Not run)
fit &lt;- vglm(y ~ 1, posnormal, data = pdata, trace = TRUE)
coef(fit, matrix = TRUE)
(Cfit &lt;- Coef(fit))
mygrid &lt;- with(pdata, seq(min(y), max(y), len = 200))
## Not run: lines(mygrid, dposnorm(mygrid, Cfit[1], Cfit[2]), col = "red")
</code></pre>

<hr>
<h2 id='pospoisson'> Positive Poisson Distribution Family Function </h2><span id='topic+pospoisson'></span>

<h3>Description</h3>

<p>Fits a positive Poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pospoisson(link = "loglink", type.fitted = c("mean", "lambda",
           "prob0"), expected = TRUE, ilambda = NULL, imethod = 1,
           zero = NULL, gt.1 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pospoisson_+3A_link">link</code></td>
<td>

<p>Link function for the usual mean (lambda) parameter of
an ordinary Poisson distribution.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="pospoisson_+3A_expected">expected</code></td>
<td>

<p>Logical.
Fisher scoring is used if <code>expected = TRUE</code>, else Newton-Raphson.
</p>
</td></tr>
<tr><td><code id="pospoisson_+3A_ilambda">ilambda</code>, <code id="pospoisson_+3A_imethod">imethod</code>, <code id="pospoisson_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="pospoisson_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
<tr><td><code id="pospoisson_+3A_gt.1">gt.1</code></td>
<td>

<p>Logical.
Enforce <code>lambda &gt; 1</code>? The default is to
enforce <code>lambda &gt; 0</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The positive Poisson  distribution is the ordinary Poisson
distribution but with the probability of zero being zero.  Thus the
other probabilities are scaled up (i.e., divided by <code class="reqn">1-P[Y=0]</code>).
The mean, <code class="reqn">\lambda / (1 - \exp(-\lambda))</code>,
can be obtained by the extractor function <code>fitted</code> applied to
the object.
</p>
<p>A related distribution is the zero-inflated Poisson, in which the
probability <code class="reqn">P[Y=0]</code> involves another parameter <code class="reqn">\phi</code>.
See <code><a href="#topic+zipoisson">zipoisson</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Under- or over-flow may occur if the data is ill-conditioned.
</p>


<h3>Note</h3>

<p>This family function can handle multiple responses.
</p>
<p>Yet to be done: a <code>quasi.pospoisson</code> which estimates a dispersion
parameter.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Coleman, J. S. and James, J. (1961).
The equilibrium size distribution of freely-forming groups.
<em>Sociometry</em>, <b>24</b>, 36&ndash;45.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+zapoisson">zapoisson</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="VGAMdata.html#topic+otpospoisson">otpospoisson</a></code>,
<code><a href="VGAMdata.html#topic+Pospois">Pospois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data from Coleman and James (1961)
cjdata &lt;- data.frame(y = 1:6, freq = c(1486, 694, 195, 37, 10, 1))
fit &lt;- vglm(y ~ 1, pospoisson, data = cjdata, weights = freq)
Coef(fit)
summary(fit)
fitted(fit)

pdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))  # Artificial data
pdata &lt;- transform(pdata, lambda = exp(1 - 2 * x2))
pdata &lt;- transform(pdata, y1 = rgaitdpois(nn, lambda, truncate = 0))
with(pdata, table(y1))
fit &lt;- vglm(y1 ~ x2, pospoisson, data = pdata, trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='powerlink'> Power Link Function </h2><span id='topic+powerlink'></span>

<h3>Description</h3>

<p>Computes the power transformation, including its inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerlink(theta, power = 1, inverse = FALSE, deriv = 0,
          short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="powerlink_+3A_power">power</code></td>
<td>

<p>This denotes the power or exponent.
</p>
</td></tr>
<tr><td><code id="powerlink_+3A_inverse">inverse</code>, <code id="powerlink_+3A_deriv">deriv</code>, <code id="powerlink_+3A_short">short</code>, <code id="powerlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power link function raises a parameter by a certain value of
<code>power</code>.
Care is needed because it is very easy to get numerical
problems, e.g., if <code>power=0.5</code> and <code>theta</code> is
negative.
</p>


<h3>Value</h3>

<p>For <code>powerlink</code> with <code>deriv = 0</code>, then <code>theta</code> raised
to the power of <code>power</code>.
And if <code>inverse = TRUE</code> then
<code>theta</code> raised to the power of <code>1/power</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>theta</code> / <em>d</em> <code>eta</code> as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>


<h3>Note</h3>

<p>Numerical problems may occur for certain combinations of
<code>theta</code> and <code>power</code>.
Consequently this link function should be used with caution.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+loglink">loglink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>powerlink("a", power = 2, short = FALSE, tag = TRUE)
powerlink(x &lt;- 1:5)
powerlink(x, power = 2)
max(abs(powerlink(powerlink(x, power = 2),
                  power = 2, inverse = TRUE) - x))  # Should be 0
powerlink(x &lt;- (-5):5, power = 0.5)  # Has NAs

# 1/2 = 0.5
pdata &lt;- data.frame(y = rbeta(n = 1000, shape1 = 2^2, shape2 = 3^2))
fit &lt;- vglm(y ~ 1, betaR(lshape1 = powerlink(power = 0.5), i1 = 3,
                         lshape2 = powerlink(power = 0.5), i2 = 7), data = pdata)
t(coef(fit, matrix = TRUE))
Coef(fit)  # Useful for intercept-only models
vcov(fit, untransform = TRUE)
</code></pre>

<hr>
<h2 id='prats'> Pregnant Rats Toxological Experiment Data </h2><span id='topic+prats'></span>

<h3>Description</h3>

<p>A small toxological experiment data.
The subjects are fetuses from
two randomized groups of pregnant rats,
and they were given a placebo or chemical treatment.
The number with birth defects were recorded, as well
as each litter size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prats)
</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables.
</p>

<dl>
<dt>treatment</dt><dd>
<p>A <code>0</code> means control;
a <code>1</code> means the chemical treatment.
</p>
</dd>
<dt>alive, litter.size</dt><dd>
<p>The number of fetuses alive at 21 days, out of
the number of fetuses alive at  4 days (the litter size).
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data concerns a toxological experiment where
the subjects are fetuses from
two randomized groups of 16 pregnant rats each,
and they were given a placebo or chemical treatment.
The number with birth defects and the litter size were recorded.
Half the rats were fed a control diet during pregnancy and
lactation, and the diet of the other half was treated with a
chemical. For each litter the number of pups alive at 4 days
and the number of pups that survived the 21 day lactation period,
were recorded.
</p>


<h3>Source</h3>

<p>Weil, C. S. (1970)
Selection of the valid number of sampling units and a consideration
of their combination in toxicological studies involving
reproduction, teratogenesis or carcinogenesis.
<em>Food and Cosmetics Toxicology</em>,
<b>8</b>(2), 177&ndash;182.
</p>




<h3>References</h3>

<p>Williams, D. A. (1975).
The Analysis of Binary Responses From Toxicological
Experiments Involving Reproduction and Teratogenicity.
<em>Biometrics</em>,
<b>31</b>(4), 949&ndash;952.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prats
colSums(subset(prats, treatment == 0))
colSums(subset(prats, treatment == 1))
summary(prats)
</code></pre>

<hr>
<h2 id='predictqrrvglm'> Predict Method for a CQO fit </h2><span id='topic+predictqrrvglm'></span>

<h3>Description</h3>

<p>Predicted values based on a constrained quadratic ordination (CQO)
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictqrrvglm(object, newdata = NULL,
    type = c("link", "response", "latvar", "terms"),
    se.fit = FALSE, deriv = 0, dispersion = NULL,
    extra = object@extra, varI.latvar = FALSE, refResponse = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictqrrvglm_+3A_object">object</code></td>
<td>
<p> Object of class inheriting from <code>"qrrvglm"</code>. </p>
</td></tr>
<tr><td><code id="predictqrrvglm_+3A_newdata">newdata</code></td>
<td>

<p>An optional data frame in which to look for variables with which
to predict. If omitted, the fitted linear predictors are used.
</p>
</td></tr>
<tr><td><code id="predictqrrvglm_+3A_type">type</code>, <code id="predictqrrvglm_+3A_se.fit">se.fit</code>, <code id="predictqrrvglm_+3A_dispersion">dispersion</code>, <code id="predictqrrvglm_+3A_extra">extra</code></td>
<td>

<p>See <code><a href="#topic+predictvglm">predictvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="predictqrrvglm_+3A_deriv">deriv</code></td>
<td>
<p> Derivative. Currently only 0 is handled. </p>
</td></tr>
<tr><td><code id="predictqrrvglm_+3A_vari.latvar">varI.latvar</code>, <code id="predictqrrvglm_+3A_refresponse">refResponse</code></td>
<td>

<p>Arguments passed into <code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="predictqrrvglm_+3A_...">...</code></td>
<td>
<p> Currently undocumented. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Obtains predictions
from a fitted CQO object.
Currently there are lots of limitations of this function; it is
unfinished.
</p>



<h3>Value</h3>

<p>See <code><a href="#topic+predictvglm">predictvglm</a></code>.
</p>


<h3>Note</h3>

<p>This function is not robust and has not been checked fully.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+calibrate.qrrvglm">calibrate.qrrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  set.seed(1234)
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Standardize the X vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute,
                Arctperi, Auloalbi, Pardlugu, Pardmont,
                Pardnigr, Pardpull, Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          poissonff, data = hspider, Crow1positive = FALSE, I.toler = TRUE)
sort(deviance(p1, history = TRUE))  # A history of all the iterations
head(predict(p1))

# The following should be all 0s:
max(abs(predict(p1, newdata = head(hspider)) - head(predict(p1))))
max(abs(predict(p1, newdata = head(hspider), type = "res")-head(fitted(p1))))

## End(Not run)
</code></pre>

<hr>
<h2 id='predictvglm'>Predict Method for a VGLM fit</h2><span id='topic+predictvglm'></span>

<h3>Description</h3>

<p>Predicted values based on a vector generalized linear model (VGLM)
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictvglm(object, newdata = NULL,
            type = c("link", "response", "terms"),
            se.fit = FALSE, deriv = 0, dispersion = NULL,
            untransform = FALSE,
            type.fitted = NULL, percentiles = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictvglm_+3A_object">object</code></td>
<td>

<p>Object of class inheriting from <code>"vlm"</code>,
e.g., <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_newdata">newdata</code></td>
<td>

<p>An optional data frame in which to look for variables with which
to predict. If omitted, the fitted linear predictors are used.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_type">type</code></td>
<td>

<p>The value of this argument can be abbreviated.
The type of prediction required. The default is the first one,
meaning on the scale of the linear predictors.
This should be a <code class="reqn">n \times M</code> matrix.
</p>
<p>The alternative <code>"response"</code> is on the scale of the
response variable, and depending on the family function,
this may or may not be the mean.
Often this is the fitted value, e.g.,
<code>fitted(vglmObject)</code>
(see <code><a href="#topic+fittedvlm">fittedvlm</a></code>).
Note that the response is output from the <code>@linkinv</code> slot,
where the <code>eta</code> argument is the <code class="reqn">n \times M</code> matrix
of linear predictors.
</p>
<p>The <code>"terms"</code> option returns a matrix giving the
fitted values of each term in the model formula on the
linear predictor scale.
The terms have been centered.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_se.fit">se.fit</code></td>
<td>

<p>logical: return standard errors?
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_deriv">deriv</code></td>
<td>

<p>Non-negative integer. Currently this must be zero.
Later, this may be implemented for general values.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_dispersion">dispersion</code></td>
<td>

<p>Dispersion parameter.
This may be inputted at this stage, but the default is to use
the dispersion parameter of the fitted model.
</p>
</td></tr>




<tr><td><code id="predictvglm_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> family functions have an argument by
the same name. If so,  then one can obtain fitted values
by setting <code>type = "response"</code> and
choosing a value of <code>type.fitted</code> from what's
available.
If <code>type.fitted = "quantiles"</code> is available then
the <code>percentiles</code> argument can be used to specify
what quantile values are requested.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_percentiles">percentiles</code></td>
<td>

<p>Used only if <code>type.fitted = "quantiles"</code> is
available and is selected.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_untransform">untransform</code></td>
<td>

<p>Logical. Reverses any parameter link function.
This argument only works if
<code>type = "link", se.fit = FALSE, deriv = 0</code>.
Setting <code>untransform = TRUE</code> does not work for
all <span class="pkg">VGAM</span> family functions; only ones where there
is a one-to-one correspondence between a simple link function
and a simple parameter might work.
</p>
</td></tr>
<tr><td><code id="predictvglm_+3A_...">...</code></td>
<td>
<p>Arguments passed into <code>predictvlm</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Obtains predictions and optionally estimates
standard errors of those predictions from a
fitted <code><a href="#topic+vglm">vglm</a></code> object.
By default,
each row of the matrix returned can be written
as <code class="reqn">\eta_i^T</code>, comprising of <code class="reqn">M</code>
components or linear predictors.
If there are any offsets, these
<em>are</em> included.
</p>
<p>This code implements <em>smart prediction</em>
(see <code><a href="#topic+smartpred">smartpred</a></code>).
</p>


<h3>Value</h3>

<p>If <code>se.fit = FALSE</code>, a vector or matrix
of predictions.
If <code>se.fit = TRUE</code>, a list with components
</p>
<table>
<tr><td><code>fitted.values</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>Estimated standard errors</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degrees of freedom</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>The square root of the
dispersion parameter
(but these are being phased out in
the package)</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>This function may change in the future.
</p>


<h3>Note</h3>

<p>Setting <code>se.fit = TRUE</code> and
<code>type = "response"</code>
will generate an error.
</p>
<p>The arguments <code>type.fitted</code>
and <code>percentiles</code>
are provided in this function to give more
convenience than
modifying the <code>extra</code> slot directly.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2015).
<em>Vector Generalized Linear and Additive
Models:
With an Implementation in R</em>.
New York, USA: <em>Springer</em>.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">predict</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code>predictvlm</code>,
<code><a href="#topic+smartpred">smartpred</a></code>,
<code><a href="#topic+calibrate">calibrate</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Illustrates smart prediction
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ poly(c(scale(let)), 2),
            propodds, pneumo, trace = TRUE, x.arg = FALSE)
class(fit)

(q0 &lt;- head(predict(fit)))
(q1 &lt;- predict(fit, newdata = head(pneumo)))
(q2 &lt;- predict(fit, newdata = head(pneumo)))
all.equal(q0, q1)  # Should be TRUE
all.equal(q1, q2)  # Should be TRUE

head(predict(fit))
head(predict(fit, untransform = TRUE))

p0 &lt;- head(predict(fit, type = "response"))
p1 &lt;- head(predict(fit, type = "response", newdata = pneumo))
p2 &lt;- head(predict(fit, type = "response", newdata = pneumo))
p3 &lt;- head(fitted(fit))
all.equal(p0, p1)  # Should be TRUE
all.equal(p1, p2)  # Should be TRUE
all.equal(p2, p3)  # Should be TRUE

predict(fit, type = "terms", se = TRUE)
</code></pre>

<hr>
<h2 id='prentice74'> Prentice (1974) Log-gamma Distribution </h2><span id='topic+prentice74'></span>

<h3>Description</h3>

<p>Estimation of a 3-parameter log-gamma distribution described by
Prentice (1974).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prentice74(llocation = "identitylink", lscale = "loglink",
           lshape = "identitylink", ilocation = NULL, iscale = NULL,
           ishape = NULL, imethod = 1,
           glocation.mux = exp((-4:4)/2), gscale.mux = exp((-4:4)/2),
           gshape = qt(ppoints(6), df = 1), probs.y = 0.3,
           zero = c("scale", "shape"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prentice74_+3A_llocation">llocation</code>, <code id="prentice74_+3A_lscale">lscale</code>, <code id="prentice74_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function applied to the
location parameter <code class="reqn">a</code>,
positive scale parameter <code class="reqn">b</code>
and the shape parameter <code class="reqn">q</code>, respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="prentice74_+3A_ilocation">ilocation</code>, <code id="prentice74_+3A_iscale">iscale</code></td>
<td>

<p>Initial value for <code class="reqn">a</code> and <code class="reqn">b</code>, respectively.
The defaults mean an initial value is determined internally for each.
</p>
</td></tr>
<tr><td><code id="prentice74_+3A_ishape">ishape</code></td>
<td>

<p>Initial value for <code class="reqn">q</code>.
If failure to converge occurs, try some other value.
The default means an initial value is determined internally.
</p>
</td></tr>
<tr><td><code id="prentice74_+3A_imethod">imethod</code>, <code id="prentice74_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>



</td></tr>
<tr><td><code id="prentice74_+3A_glocation.mux">glocation.mux</code>, <code id="prentice74_+3A_gscale.mux">gscale.mux</code>, <code id="prentice74_+3A_gshape">gshape</code>, <code id="prentice74_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function is given by
</p>
<p style="text-align: center;"><code class="reqn">f(y;a,b,q) = |q|\,\exp(w/q^2 - e^w) / (b \, \Gamma(1/q^2)),</code>
</p>

<p>for shape parameter <code class="reqn">q \ne 0</code>,
positive scale parameter <code class="reqn">b &gt; 0</code>,
location parameter <code class="reqn">a</code>,
and all real <code class="reqn">y</code>.
Here, <code class="reqn">w = (y-a)q/b+\psi(1/q^2)</code>
where <code class="reqn">\psi</code> is the digamma function,
<code><a href="base.html#topic+Special">digamma</a></code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">a</code> (returned as the fitted values).
This is a different parameterization compared to <code><a href="#topic+lgamma3">lgamma3</a></code>.
</p>
<p>Special cases:
<code class="reqn">q = 0</code> is the normal distribution with standard deviation <code class="reqn">b</code>,
<code class="reqn">q = -1</code> is the extreme value distribution for maximums,
<code class="reqn">q = 1</code> is the extreme value distribution for minima (Weibull).
If <code class="reqn">q &gt; 0</code> then the distribution is left skew,
else <code class="reqn">q &lt; 0</code> is right skew.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The special case <code class="reqn">q = 0</code> is not handled, therefore
estimates of <code class="reqn">q</code> too close to zero may cause numerical problems.
</p>


<h3>Note</h3>

<p>The notation used here differs from Prentice (1974):
<code class="reqn">\alpha = a</code>,
<code class="reqn">\sigma = b</code>.
Fisher scoring is used.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Prentice, R. L. (1974).
A log gamma model and its maximum likelihood estimation.
<em>Biometrika</em>, <b>61</b>, 539&ndash;544.
</p>






<h3>See Also</h3>

<p><code><a href="#topic+lgamma3">lgamma3</a></code>,
<code><a href="base.html#topic+Special">lgamma</a></code>,
<code><a href="#topic+gengamma.stacy">gengamma.stacy</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
pdata &lt;- transform(pdata, loc = -1 + 2*x2, Scale = exp(1))
pdata &lt;- transform(pdata, y = rlgamma(nn, loc = loc, scale = Scale, shape = 1))
fit &lt;- vglm(y ~ x2, prentice74(zero = 2:3), data = pdata, trace = TRUE)
coef(fit, matrix = TRUE)  # Note the coefficients for location
</code></pre>

<hr>
<h2 id='prinia'>Yellow-bellied Prinia

</h2><span id='topic+prinia'></span>

<h3>Description</h3>

<p>A data frame with yellow-bellied Prinia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prinia)
</code></pre>


<h3>Format</h3>

<p>A data frame with 151 observations on the following 23 variables.
</p>

<dl>
<dt>length</dt><dd><p>a numeric vector,
the scaled wing length (zero mean and unit variance).
</p>
</dd>
<dt>fat</dt><dd><p>a numeric vector, fat index;
originally 1 (no fat) to 4 (very fat) but
converted to 0 (no fat) versus 1 otherwise.
</p>
</dd>
<dt>cap</dt><dd><p>a numeric vector,
number of times the bird was captured or recaptured.
</p>
</dd>
<dt>noncap</dt><dd><p>a numeric vector,
number of times the bird was not captured.
</p>
</dd>
<dt>y01, y02, y03, y04, y05, y06</dt><dd>
<p>a numeric vector of 0s and 1s; for noncapture and capture resp.
</p>
</dd>
<dt>y07, y08, y09, y10, y11, y12</dt><dd>
<p>same as above.
</p>
</dd>
<dt>y13, y14, y15, y16, y17, y18, y19</dt><dd>
<p>same as above.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The yellow-bellied Prinia <em>Prinia flaviventris</em>
is a common bird species located in Southeast Asia. A
capture&ndash;recapture experiment was conducted at the Mai Po
Nature Reserve in Hong Kong during 1991, where captured
individuals had their wing lengths measured and fat index
recorded. A total of 19 weekly capture occasions were
considered, where 151 distinct birds were captured.
</p>
<p>More generally, the prinias are a genus of small
insectivorous birds, and are sometimes referred to as
<em>wren-warblers</em>.  They are a little-known group of the
tropical and subtropical Old World, the roughly 30 species
being divided fairly equally between Africa and Asia.
</p>













<h3>Source</h3>

<p>Thanks to Paul Yip for permission to make this data available.
</p>





<p>Hwang, W.-H. and Huggins, R. M. (2007)
Application of semiparametric regression models in the
analysis of capture&ndash;recapture experiments.
<em>Australian and New Zealand Journal of Statistics</em>
<b>49</b>, 191&ndash;202.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(prinia)
summary(prinia)
rowSums(prinia[, c("cap", "noncap")])  # 19s

#  Fit a positive-binomial distribution (M.h) to the data:
fit1 &lt;- vglm(cbind(cap, noncap) ~ length + fat, posbinomial, prinia)

#  Fit another positive-binomial distribution (M.h) to the data:
#  The response input is suitable for posbernoulli.*-type functions.
fit2 &lt;- vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10,
                   y11, y12, y13, y14, y15, y16, y17, y18, y19) ~
             length + fat, posbernoulli.b(drop.b = FALSE ~ 0), prinia)
</code></pre>

<hr>
<h2 id='probitlink'> Probit Link Function </h2><span id='topic+probitlink'></span>

<h3>Description</h3>

<p>Computes the probit transformation, including its inverse and the
first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probitlink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
           short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probitlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="probitlink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="probitlink_+3A_inverse">inverse</code>, <code id="probitlink_+3A_deriv">deriv</code>, <code id="probitlink_+3A_short">short</code>, <code id="probitlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probit link function is commonly used for parameters that
lie in the unit interval.
It is the inverse CDF of the standard normal distribution.
Numerical values of <code>theta</code> close to 0 or 1 or out of range
result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the probit of <code>theta</code>, i.e.,
<code>qnorm(theta)</code> when <code>inverse = FALSE</code>, and if <code>inverse =
  TRUE</code> then <code>pnorm(theta)</code>.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is close to 1 or 0.
One way of overcoming this is to use <code>bvalue</code>.
</p>
<p>In terms of the threshold approach with cumulative probabilities for
an ordinal response this link function corresponds to the univariate
normal distribution (see <code><a href="#topic+uninormal">uninormal</a></code>).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed. London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>,
<code><a href="stats.html#topic+Normal">Normal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, by = 0.01)
probitlink(p)
max(abs(probitlink(probitlink(p), inverse = TRUE) - p))  # Should be 0

p &lt;- c(seq(-0.02, 0.02, by = 0.01), seq(0.97, 1.02, by = 0.01))
probitlink(p)  # Has NAs
probitlink(p, bvalue = .Machine$double.eps)  # Has no NAs

## Not run: p &lt;- seq(0.01, 0.99, by = 0.01); par(lwd = (mylwd &lt;- 2))
plot(p, logitlink(p), type = "l", col = "limegreen", ylab = "transformation",
     las = 1, main = "Some probability link functions")
lines(p,  probitlink(p), col = "purple")
lines(p, clogloglink(p), col = "chocolate")
lines(p, cauchitlink(p), col = "tan")
abline(v = 0.5, h = 0, lty = "dashed")
legend(0.1, 4, c("logitlink", "probitlink", "clogloglink", "cauchitlink"),
       col = c("limegreen", "purple", "chocolate", "tan"), lwd = mylwd)
par(lwd = 1) 
## End(Not run)
</code></pre>

<hr>
<h2 id='profilevglm'>Method for Profiling vglm Objects</h2><span id='topic+profilevglm'></span>

<h3>Description</h3>

<p>Investigates the profile log-likelihood function for a fitted model of
class <code>"vglm"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>profilevglm(object, which = 1:p.vlm, alpha = 0.01,
            maxsteps = 10, del = zmax/5, trace = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="profilevglm_+3A_object">object</code></td>
<td>
<p>the original fitted model object.</p>
</td></tr>
<tr><td><code id="profilevglm_+3A_which">which</code></td>
<td>
<p>the original model parameters
which should be profiled.
This can be a numeric or character vector.
By default, all parameters are profiled.
</p>
</td></tr>
<tr><td><code id="profilevglm_+3A_alpha">alpha</code></td>
<td>
<p>highest significance level allowed for the
profiling.
</p>

</td></tr>
<tr><td><code id="profilevglm_+3A_maxsteps">maxsteps</code></td>
<td>
<p>maximum number of points to
be used for profiling each
parameter.</p>
</td></tr>
<tr><td><code id="profilevglm_+3A_del">del</code></td>
<td>
<p>suggested change on the scale of
the profile
t-statistics.  Default value chosen to
allow profiling at about 10 parameter
values.</p>
</td></tr>
<tr><td><code id="profilevglm_+3A_trace">trace</code></td>
<td>
<p>logical: should the progress of
profiling be reported?  The default is to
use the <code>trace</code> value from the fitted
object; see <code><a href="#topic+vglm.control">vglm.control</a></code>
for details.
</p>
</td></tr>
<tr><td><code id="profilevglm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or
from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by
<code><a href="#topic+confintvglm">confintvglm</a></code> to do the profiling.
See also <code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>
for details.
</p>


<h3>Value</h3>

<p>A list of classes <code>"profile.glm"</code>
and <code>"profile"</code> with an element
for each parameter being profiled.
The elements are data-frames with two
variables </p>
<table>
<tr><td><code>par.vals</code></td>
<td>
<p>a matrix of
parameter values for each fitted model.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>the profile t-statistics.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>T. W. Yee adapted this function from
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>,
written originally by D. M. Bates and W. N. Venables.
(For S in 1996.)
The help file was also used as a template.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="#topic+lrt.stat">lrt.stat</a></code>,
<code><a href="stats.html#topic+profile">profile</a></code>,
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>,
<code>plot.profile</code> in <span class="pkg">MASS</span> or <span class="pkg">stats</span>.
</p>











<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds,
             trace = TRUE, data = pneumo)
pfit1 &lt;- profile(fit1, trace = FALSE)
confint(fit1, method = "profile", trace = FALSE)
</code></pre>

<hr>
<h2 id='propodds'> Proportional Odds Model for Ordinal Regression </h2><span id='topic+propodds'></span>

<h3>Description</h3>

<p>Fits the proportional odds model
to a (preferably ordered) factor response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propodds(reverse = TRUE, whitespace = FALSE, ynames = FALSE,
   Thresh = NULL, Trev = reverse, Tref = if (Trev) "M" else 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="propodds_+3A_reverse">reverse</code>, <code id="propodds_+3A_whitespace">whitespace</code></td>
<td>

<p>Logical.
Fed into arguments of the same name in
<code><a href="#topic+cumulative">cumulative</a></code>.
</p>
</td></tr>
<tr><td><code id="propodds_+3A_ynames">ynames</code></td>
<td>

<p>See <code><a href="#topic+multinomial">multinomial</a></code> for information.
</p>
</td></tr>
<tr><td><code id="propodds_+3A_thresh">Thresh</code>, <code id="propodds_+3A_trev">Trev</code>, <code id="propodds_+3A_tref">Tref</code></td>
<td>

<p>Fed into arguments of the same name in
<code><a href="#topic+cumulative">cumulative</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>proportional odds model</em> is a special case from the
class of <em>cumulative link models</em>.
It involves a logit link applied to cumulative probabilities
and a strong <em>parallelism</em> assumption.
A parallelism assumption means there is less chance of
numerical problems because the fitted probabilities will remain
between 0 and 1; however
the <em>parallelism</em> assumption ought to be checked,
e.g., via a likelihood ratio test.
This <span class="pkg">VGAM</span> family function is merely a shortcut for
<code>cumulative(reverse = reverse, link = "logit", parallel = TRUE)</code>.
Please see <code><a href="#topic+cumulative">cumulative</a></code> for more details on this
model.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>No check is made to verify that the response is ordinal if the
response is a matrix; see <code><a href="base.html#topic+factor">ordered</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>See <code><a href="#topic+cumulative">cumulative</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+R2latvar">R2latvar</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit the proportional odds model, McCullagh and Nelder (1989,p.179)
pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo))
depvar(fit)  # Sample proportions
weights(fit, type = "prior")  # Number of observations
coef(fit, matrix = TRUE)
constraints(fit)  # Constraint matrices
summary(fit)

# Check that the model is linear in let ----------------------
fit2 &lt;- vgam(cbind(normal, mild, severe) ~ s(let, df = 2), propodds,
             pneumo)
## Not run:  plot(fit2, se = TRUE, lcol = 2, scol = 2) 

# Check the proportional odds assumption with a LRT ----------
(fit3 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = FALSE, reverse = TRUE), pneumo))
pchisq(deviance(fit) - deviance(fit3),
       df = df.residual(fit) - df.residual(fit3), lower.tail = FALSE)
lrtest(fit3, fit)  # Easier
</code></pre>

<hr>
<h2 id='prplot'>
Probability Plots for Categorical Data Analysis
</h2><span id='topic+prplot'></span><span id='topic+prplot.control'></span>

<h3>Description</h3>

<p>Plots the fitted probabilities for some very simplified special
cases of categorical data analysis models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prplot(object, control = prplot.control(...), ...)

prplot.control(xlab = NULL, ylab = "Probability", main = NULL, xlim = NULL,
    ylim = NULL, lty = par()$lty, col = par()$col, rcol = par()$col,
    lwd = par()$lwd, rlwd = par()$lwd, las = par()$las, rug.arg = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prplot_+3A_object">object</code></td>
<td>

<p>Currently only an <code><a href="#topic+cumulative">cumulative</a></code> object.
This includes a <code><a href="#topic+propodds">propodds</a></code> object since that
<span class="pkg">VGAM</span> family function is a special case of <code><a href="#topic+cumulative">cumulative</a></code>.
</p>
</td></tr>
<tr><td><code id="prplot_+3A_control">control</code></td>
<td>

<p>List containing some basic graphical parameters.
</p>
</td></tr>
<tr><td><code id="prplot_+3A_xlab">xlab</code>, <code id="prplot_+3A_ylab">ylab</code>, <code id="prplot_+3A_main">main</code>, <code id="prplot_+3A_xlim">xlim</code>, <code id="prplot_+3A_ylim">ylim</code>, <code id="prplot_+3A_lty">lty</code></td>
<td>

<p>See <code><a href="graphics.html#topic+par">par</a></code> and <code>...</code> below.
</p>
</td></tr>
<tr><td><code id="prplot_+3A_col">col</code>, <code id="prplot_+3A_rcol">rcol</code>, <code id="prplot_+3A_lwd">lwd</code>, <code id="prplot_+3A_rlwd">rlwd</code>, <code id="prplot_+3A_las">las</code>, <code id="prplot_+3A_rug.arg">rug.arg</code></td>
<td>

<p>See <code><a href="graphics.html#topic+par">par</a></code> and <code>...</code> below.
Arguments starting with <code>r</code> refer to the rug.
Argument <code>rug.arg</code> is logical: add a rug for the distinct values of the
explanatory variable?
</p>
</td></tr>
<tr><td><code id="prplot_+3A_...">...</code></td>
<td>

<p>Arguments such as <code>xlab</code> which are fed into <code>prplot.control()</code>.
Only a small selection of graphical arguments from
<code><a href="graphics.html#topic+par">par</a></code> are offered.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For models involving one term in the RHS of the formula this function
plots the fitted probabilities against the single explanatory variable.
</p>


<h3>Value</h3>

<p>The object is returned invisibly with the <code>preplot</code> slot assigned.
This is obtained by a call to <code>plotvgam()</code>.
</p>


<h3>Note</h3>

<p>This function is rudimentary.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cumulative">cumulative</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, data = pneumo)
M &lt;- npred(fit)  # Or fit@misc$M
## Not run:  prplot(fit)
prplot(fit, lty = 1:M, col = (1:M)+2, rug = TRUE, las = 1,
       ylim = c(0, 1), rlwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='put.smart'> Adds a List to the End of the List &ldquo;.smart.prediction&rdquo; </h2><span id='topic+put.smart'></span>

<h3>Description</h3>

<p>Adds a list to the end of the list <code>.smart.prediction</code>
in
<code>smartpredenv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>put.smart(smart)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="put.smart_+3A_smart">smart</code></td>
<td>

<p>a list containing parameters needed later for smart prediction.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>put.smart</code> is used in <code>"write"</code> mode within a smart function.
It saves parameters at the time of model fitting, which are 
later used for prediction.
The function <code>put.smart</code> is the opposite of
<code><a href="#topic+get.smart">get.smart</a></code>, and both deal with the same contents.
</p>


<h3>Value</h3>

<p>Nothing is returned.
</p>


<h3>Side Effects</h3>

<p>The variable <code>.smart.prediction.counter</code> in
<code>smartpredenv</code>
is incremented beforehand,
and <code>.smart.prediction[[.smart.prediction.counter]]</code> is
assigned the list <code>smart</code>. 
If the list <code>.smart.prediction</code> in
<code>smartpredenv</code>
is not long enough
to hold <code>smart</code>, then it is made larger, and the variable
<code>.max.smart</code> in
<code>smartpredenv</code>
is adjusted accordingly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.smart">get.smart</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(sm.min1)
</code></pre>

<hr>
<h2 id='qrrvglm.control'> Control Function for QRR-VGLMs (CQO) </h2><span id='topic+qrrvglm.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for a constrained quadratic
ordination (CQO), by fitting a <em>quadratic reduced-rank vector
generalized linear model</em> (QRR-VGLM), are set using this function.
It is the control function for <code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qrrvglm.control(Rank = 1, Bestof = if (length(Cinit)) 1 else 10,
    checkwz = TRUE, Cinit = NULL, Crow1positive = TRUE,
    epsilon = 1.0e-06, EqualTolerances = NULL, eq.tolerances = TRUE,
    Etamat.colmax = 10, FastAlgorithm = TRUE, GradientFunction = TRUE,
    Hstep = 0.001, isd.latvar = rep_len(c(2, 1, rep_len(0.5, Rank)),
    Rank), iKvector = 0.1, iShape = 0.1, ITolerances = NULL,
    I.tolerances = FALSE, maxitl = 40, imethod = 1,
    Maxit.optim = 250, MUXfactor = rep_len(7, Rank),
    noRRR = ~ 1, Norrr = NA, optim.maxit = 20,
    Parscale = if (I.tolerances) 0.001 else 1.0,
    sd.Cinit = 0.02, SmallNo = 5.0e-13, trace = TRUE,
    Use.Init.Poisson.QO = TRUE,
    wzepsilon = .Machine$double.eps^0.75, ...)
</code></pre>


<h3>Arguments</h3>

<p>In the following, <code class="reqn">R</code> is the <code>Rank</code>,
<code class="reqn">M</code> is the number
of linear predictors,
and <code class="reqn">S</code> is the number of responses
(species).
Thus <code class="reqn">M=S</code> for binomial and Poisson responses, and
<code class="reqn">M=2S</code> for the negative binomial and
2-parameter gamma distributions.
</p>
<table>
<tr><td><code id="qrrvglm.control_+3A_rank">Rank</code></td>
<td>

<p>The numerical rank <code class="reqn">R</code> of the model, i.e., the
number of ordination axes. Must be an element from the set
{1,2,...,min(<code class="reqn">M</code>,<code class="reqn">p_2</code>)}
where the vector of explanatory
variables <code class="reqn">x</code> is partitioned
into (<code class="reqn">x_1</code>,<code class="reqn">x_2</code>), which is
of dimension <code class="reqn">p_1+p_2</code>.
The variables making up <code class="reqn">x_1</code>
are given by the terms in the <code>noRRR</code> argument,
and the rest
of the terms comprise <code class="reqn">x_2</code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_bestof">Bestof</code></td>
<td>

<p>Integer. The best of <code>Bestof</code> models
fitted is returned.
This argument helps guard against local solutions
by (hopefully)
finding the global solution from many fits.
The argument has value
1 if an initial value for <code class="reqn">C</code> is inputted
using <code>Cinit</code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_checkwz">checkwz</code></td>
<td>
<p> logical indicating whether the
diagonal elements of
the working weight matrices should be checked
whether they are
sufficiently positive, i.e., greater
than <code>wzepsilon</code>. If not,
any values less than <code>wzepsilon</code> are
replaced with this value.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_cinit">Cinit</code></td>
<td>

<p>Optional initial <code class="reqn">C</code> matrix, which must
be a <code class="reqn">p_2</code> by <code class="reqn">R</code>
matrix. The default is to
apply <code>.Init.Poisson.QO()</code> to obtain
initial values.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_crow1positive">Crow1positive</code></td>
<td>

<p>Logical vector of length <code>Rank</code>
(recycled if necessary): are
the elements of the first
row of <code class="reqn">C</code> positive? For example,
if <code>Rank</code> is 4, then
specifying <code>Crow1positive = c(FALSE,
      TRUE)</code> will force <code class="reqn">C[1,1]</code> and <code class="reqn">C[1,3]</code>
to be negative,
and <code class="reqn">C[1,2]</code> and <code class="reqn">C[1,4]</code> to be positive.
This argument
allows for a reflection in the ordination axes
because the
coefficients of the latent variables are
unique up to a sign.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_epsilon">epsilon</code></td>
<td>

<p>Positive numeric. Used to test for convergence
for GLMs fitted in C.
Larger values mean a loosening of the convergence criterion.
If an error code of 3 is reported, try increasing this value.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_eq.tolerances">eq.tolerances</code></td>
<td>

<p>Logical indicating whether each (quadratic) predictor will
have equal tolerances. Having <code>eq.tolerances = TRUE</code>
can help avoid numerical problems, especially with binary data.
Note that the estimated (common) tolerance matrix may or may
not be positive-definite. If it is  then it can be scaled to
the <code class="reqn">R</code> by <code class="reqn">R</code> identity matrix, i.e., made equivalent
to <code>I.tolerances = TRUE</code>. Setting <code>I.tolerances = TRUE</code>
will <em>force</em> a common <code class="reqn">R</code> by <code class="reqn">R</code> identity matrix as
the tolerance matrix to the data even if it is not appropriate.
In general, setting <code>I.tolerances = TRUE</code> is
preferred over <code>eq.tolerances = TRUE</code> because,
if it works, it is much faster and uses less memory.
However, <code>I.tolerances = TRUE</code> requires the
environmental variables to be scaled appropriately.
See <b>Details</b> for more details.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_equaltolerances">EqualTolerances</code></td>
<td>

<p>Defunct argument.
Use <code>eq.tolerances</code> instead.
</p>
</td></tr>






<tr><td><code id="qrrvglm.control_+3A_etamat.colmax">Etamat.colmax</code></td>
<td>

<p>Positive integer, no smaller than <code>Rank</code>.
Controls the amount
of memory used by <code>.Init.Poisson.QO()</code>.
It is the maximum
number of columns allowed for the pseudo-response
and its weights.
In general, the larger the value, the better
the initial value.
Used only if <code>Use.Init.Poisson.QO = TRUE</code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_fastalgorithm">FastAlgorithm</code></td>
<td>

<p>Logical.
Whether a new fast algorithm is to be used. The fast
algorithm results in a large speed increases
compared to Yee (2004).
Some details of the fast algorithm are found
in Appendix A of Yee (2006).
Setting <code>FastAlgorithm = FALSE</code> will give an error.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_gradientfunction">GradientFunction</code></td>
<td>

<p>Logical. Whether <code><a href="stats.html#topic+optim">optim</a></code>'s
argument <code>gr</code>
is used or not, i.e., to compute gradient values.
Used only if
<code>FastAlgorithm</code> is <code>TRUE</code>.
The default value is usually
faster on most problems.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_hstep">Hstep</code></td>
<td>

<p>Positive value. Used as the step size in
the finite difference
approximation to the derivatives
by <code><a href="stats.html#topic+optim">optim</a></code>.
</p>

</td></tr>
<tr><td><code id="qrrvglm.control_+3A_isd.latvar">isd.latvar</code></td>
<td>

<p>Initial standard deviations for the latent variables
(site scores).
Numeric, positive and of length <code class="reqn">R</code>
(recycled if necessary).
This argument is used only
if <code>I.tolerances = TRUE</code>. Used by
<code>.Init.Poisson.QO()</code> to obtain initial
values for the constrained
coefficients <code class="reqn">C</code> adjusted to a reasonable value.
It adjusts the
spread of the site scores relative to a
common species tolerance of 1
for each ordination axis. A value between 0.5 and 10
is recommended;
a value such as 10 means that the range of the
environmental space is
very large relative to the niche width of the species.
The successive
values should decrease because the
first ordination axis should have
the most spread of site scores, followed by
the second ordination
axis, etc.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_ikvector">iKvector</code>, <code id="qrrvglm.control_+3A_ishape">iShape</code></td>
<td>

<p>Numeric, recycled to length <code class="reqn">S</code> if necessary.
Initial values used for estimating the
positive <code class="reqn">k</code> and
<code class="reqn">\lambda</code> parameters of the
negative binomial and
2-parameter gamma distributions respectively.
For further information
see <code><a href="#topic+negbinomial">negbinomial</a></code> and <code><a href="#topic+gamma2">gamma2</a></code>.
These arguments override the <code>ik</code> and <code>ishape</code>
arguments in <code><a href="#topic+negbinomial">negbinomial</a></code>
and <code><a href="#topic+gamma2">gamma2</a></code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_i.tolerances">I.tolerances</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the (common)
tolerance matrix is the
<code class="reqn">R</code> by <code class="reqn">R</code> identity matrix by definition.
Note that having
<code>I.tolerances = TRUE</code>
implies <code>eq.tolerances = TRUE</code>, but
not vice versa. Internally, the quadratic
terms will be treated as
offsets (in GLM jargon) and so the models
can potentially be fitted
very efficiently. <em>However, it is a
very good idea to center
and scale all numerical variables in the <code class="reqn">x_2</code> vector</em>.
See <b>Details</b> for more details.
The success of <code>I.tolerances = TRUE</code> often
depends on suitable values for <code>isd.latvar</code> and/or
<code>MUXfactor</code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_itolerances">ITolerances</code></td>
<td>

<p>Defunct argument.
Use <code>I.tolerances</code> instead.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_maxitl">maxitl</code></td>
<td>

<p>Maximum number of times the optimizer is called or restarted.
Most users should ignore this argument.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_imethod">imethod</code></td>
<td>

<p>Method of initialization. A positive integer 1 or 2 or 3 etc.
depending on the <span class="pkg">VGAM</span> family function.
Currently it is used for <code><a href="#topic+negbinomial">negbinomial</a></code> and
<code><a href="#topic+gamma2">gamma2</a></code> only, and used within the C.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_maxit.optim">Maxit.optim</code></td>
<td>

<p>Positive integer. Number of iterations given to the function
<code><a href="stats.html#topic+optim">optim</a></code> at each of the <code>optim.maxit</code>
iterations.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_muxfactor">MUXfactor</code></td>
<td>

<p>Multiplication factor for detecting large offset values.
Numeric,
positive and of length <code class="reqn">R</code>
(recycled if necessary). This argument
is used only if <code>I.tolerances = TRUE</code>.
Offsets are <code class="reqn">-0.5</code>
multiplied by the sum of the squares of
all <code class="reqn">R</code> latent variable
values. If the latent variable values are
too large then this will
result in numerical problems. By too large,
it is meant that the
standard deviation of the latent variable
values are greater than
<code>MUXfactor[r] * isd.latvar[r]</code>
for <code>r=1:Rank</code> (this is why
centering and scaling all the numerical
predictor variables in
<code class="reqn">x_2</code> is recommended).
A value about 3 or 4 is recommended.
If failure to converge occurs, try a slightly lower value.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_optim.maxit">optim.maxit</code></td>
<td>

<p>Positive integer. Number of times <code><a href="stats.html#topic+optim">optim</a></code>
is invoked. At iteration <code>i</code>, the <code>i</code>th value of
<code>Maxit.optim</code> is fed into <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_norrr">noRRR</code></td>
<td>

<p>Formula giving terms that are <em>not</em>
to be included in the
reduced-rank regression (or formation of
the latent variables),
i.e., those belong to <code class="reqn">x_1</code>.
Those variables which do not make up the
latent variable (reduced-rank
regression) correspond to the <code class="reqn">B_1</code> matrix.
The default is to omit the intercept term
from the latent variables.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_norrr">Norrr</code></td>
<td>

<p>Defunct. Please use <code>noRRR</code>.
Use of <code>Norrr</code> will become an error soon.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_parscale">Parscale</code></td>
<td>

<p>Numerical and positive-valued vector of length <code class="reqn">C</code>
(recycled if necessary).
Passed
into <code>optim(..., control = list(parscale = Parscale))</code>;
the elements of <code class="reqn">C</code> become <code class="reqn">C</code> / <code>Parscale</code>.
Setting <code>I.tolerances = TRUE</code>
results in line searches that
are very large, therefore <code class="reqn">C</code> has to be scaled accordingly
to avoid large step sizes.
See <b>Details</b> for more information.
It's probably best to leave this argument alone.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_sd.cinit">sd.Cinit</code></td>
<td>

<p>Standard deviation of the initial values for the elements
of <code class="reqn">C</code>.
These are normally distributed with mean zero.
This argument is used only
if <code>Use.Init.Poisson.QO = FALSE</code>
and <code class="reqn">C</code> is not inputted using <code>Cinit</code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_trace">trace</code></td>
<td>

<p>Logical indicating if output should be produced for
each iteration. The default is <code>TRUE</code> because the
calculations are numerically intensive, meaning it may take
a long time, so that the user might think the computer has
locked up if <code>trace = FALSE</code>.
</p>
</td></tr>














<tr><td><code id="qrrvglm.control_+3A_smallno">SmallNo</code></td>
<td>

<p>Positive numeric between <code>.Machine$double.eps</code>
and <code>0.0001</code>.
Used to avoid under- or over-flow in the IRLS algorithm.
Used only if <code>FastAlgorithm</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_use.init.poisson.qo">Use.Init.Poisson.QO</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the
function <code>.Init.Poisson.QO()</code> is
used to obtain initial values for the
canonical coefficients <code class="reqn">C</code>.
If <code>FALSE</code> then random numbers are used instead.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_wzepsilon">wzepsilon</code></td>
<td>

<p>Small positive number used to test whether the
diagonals of the working
weight matrices are sufficiently positive.
</p>
</td></tr>
<tr><td><code id="qrrvglm.control_+3A_...">...</code></td>
<td>
<p> Ignored at present. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recall that the central formula for CQO is
</p>
<p style="text-align: center;"><code class="reqn">\eta = B_1^T x_1 + A \nu +
               \sum_{m=1}^M (\nu^T D_m \nu) e_m</code>
</p>

<p>where <code class="reqn">x_1</code> is a vector
(usually just a 1 for an intercept),
<code class="reqn">x_2</code> is a vector of environmental variables,
<code class="reqn">\nu=C^T x_2</code> is
a <code class="reqn">R</code>-vector of latent variables, <code class="reqn">e_m</code> is
a vector of 0s but with a 1 in the <code class="reqn">m</code>th position.
QRR-VGLMs are an extension of RR-VGLMs and
allow for maximum
likelihood solutions to constrained
quadratic ordination (CQO) models.
</p>









<p>Having <code>I.tolerances = TRUE</code> means all the tolerance matrices
are the order-<code class="reqn">R</code> identity matrix, i.e., it <em>forces</em>
bell-shaped curves/surfaces on all species. This results in a
more difficult optimization problem (especially for 2-parameter
models such as the negative binomial and gamma) because of overflow
errors and it appears there are more local solutions. To help avoid
the overflow errors, scaling <code class="reqn">C</code> by the factor <code>Parscale</code>
can help enormously. Even better, scaling <code class="reqn">C</code> by specifying
<code>isd.latvar</code> is more understandable to humans. If failure to
converge occurs, try adjusting <code>Parscale</code>, or better, setting
<code>eq.tolerances = TRUE</code> (and hope that the estimated tolerance
matrix is positive-definite). To fit an equal-tolerances model, it
is firstly best to try setting <code>I.tolerances = TRUE</code> and varying
<code>isd.latvar</code> and/or <code>MUXfactor</code> if it fails to converge.
If it still fails to converge after many attempts, try setting
<code>eq.tolerances = TRUE</code>, however this will usually be a lot slower
because it requires a lot more memory.
</p>
<p>With a <code class="reqn">R &gt; 1</code> model, the latent variables are always uncorrelated,
i.e., the variance-covariance matrix of the site scores is a diagonal
matrix.
</p>
<p>If setting <code>eq.tolerances = TRUE</code> is
used and the common
estimated tolerance matrix is positive-definite
then that model is
effectively the same as the <code>I.tolerances = TRUE</code>
model (the two are
transformations of each other).
In general, <code>I.tolerances = TRUE</code>
is numerically more unstable and presents
a more difficult problem
to optimize; the arguments <code>isd.latvar</code>
and/or <code>MUXfactor</code> often
must be assigned some good value(s)
(possibly found by trial and error)
in order for convergence to occur.
Setting <code>I.tolerances = TRUE</code>
<em>forces</em> a bell-shaped curve or surface
onto all the species data,
therefore this option should be used with
deliberation. If unsuitable,
the resulting fit may be very misleading.
Usually it is a good idea
for the user to set <code>eq.tolerances = FALSE</code>
to see which species
appear to have a bell-shaped curve or surface.
Improvements to the
fit can often be achieved using transformations,
e.g., nitrogen
concentration to log nitrogen concentration.
</p>
<p>Fitting a CAO model (see <code><a href="#topic+cao">cao</a></code>)
first is a good idea for
pre-examining the data and checking whether
it is appropriate to fit
a CQO model.
</p>


























<h3>Value</h3>

<p>A list with components matching the input names.
</p>


<h3>Warning </h3>

<p>The default value of <code>Bestof</code> is a bare minimum
for many datasets,
therefore it will be necessary to increase its
value to increase the
chances of obtaining the global solution.
</p>














<h3>Note</h3>

<p>When <code>I.tolerances = TRUE</code> it is a good idea to apply
<code><a href="base.html#topic+scale">scale</a></code> to all
the numerical variables that make up
the latent variable, i.e., those of <code class="reqn">x_2</code>.
This is to make
them have mean 0, and hence avoid large offset
values which cause
numerical problems.
</p>
<p>This function has many arguments that are common with
<code><a href="#topic+rrvglm.control">rrvglm.control</a></code> and <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>
<p>It is usually a good idea to try fitting a model with
<code>I.tolerances = TRUE</code> first, and
if convergence is unsuccessful,
then try <code>eq.tolerances = TRUE</code>
and <code>I.tolerances = FALSE</code>.
Ordination diagrams with
<code>eq.tolerances = TRUE</code> have a natural
interpretation, but
with <code>eq.tolerances = FALSE</code> they are
more complicated and
requires, e.g., contours to be overlaid on
the ordination diagram
(see <code><a href="#topic+lvplot.qrrvglm">lvplot.qrrvglm</a></code>).
</p>

<p>In the example below, an equal-tolerances CQO model
is fitted to the
hunting spiders data.
Because <code>I.tolerances = TRUE</code>, it is a good idea
to center all the <code class="reqn">x_2</code> variables first.
Upon fitting the model,
the actual standard deviation of the site scores
are computed. Ideally,
the <code>isd.latvar</code> argument should have had
this value for the best
chances of getting good initial values.
For comparison, the model is
refitted with that value and it should
run more faster and reliably.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>,
<b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+rcqo">rcqo</a></code>,
<code><a href="#topic+Coef.qrrvglm">Coef.qrrvglm</a></code>,
<code><a href="#topic+Coef.qrrvglm-class">Coef.qrrvglm-class</a></code>,
<code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>.
</p>






<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Poisson CQO with equal tolerances
set.seed(111)  # This leads to the global solution
hspider[,1:6] &lt;- scale(hspider[,1:6])  # Good when I.tolerances = TRUE
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr,
                Arctlute, Arctperi, Auloalbi,
                Pardlugu, Pardmont, Pardnigr,
                Pardpull, Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig +
          CoveMoss + CoveHerb + ReflLux,
          poissonff, data = hspider, eq.tolerances = TRUE)
sort(deviance(p1, history = TRUE))  # Iteration history

(isd.latvar &lt;- apply(latvar(p1), 2, sd))  # Approx isd.latvar

# Refit the model with better initial values
set.seed(111)  # This leads to the global solution
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr,
                Arctlute, Arctperi, Auloalbi,
                Pardlugu, Pardmont, Pardnigr,
                Pardpull, Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig +
          CoveMoss + CoveHerb + ReflLux,
          I.tolerances = TRUE, poissonff, data = hspider,
          isd.latvar = isd.latvar)  # Note this
sort(deviance(p1, history = TRUE))  # Iteration history

## End(Not run)
</code></pre>

<hr>
<h2 id='qtplot.gumbel'> Quantile Plot for Gumbel Regression </h2><span id='topic+qtplot.gumbel'></span><span id='topic+qtplot.gumbelff'></span>

<h3>Description</h3>

<p>Plots quantiles associated with a Gumbel model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtplot.gumbel(object, show.plot = TRUE,
    y.arg = TRUE, spline.fit = FALSE, label = TRUE,
    R = object@misc$R, percentiles = object@misc$percentiles,
    add.arg = FALSE, mpv = object@misc$mpv,
    xlab = NULL, ylab = "", main = "",
    pch = par()$pch, pcol.arg = par()$col,
    llty.arg = par()$lty, lcol.arg = par()$col, llwd.arg = par()$lwd,
    tcol.arg = par()$col, tadj = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qtplot.gumbel_+3A_object">object</code></td>
<td>

<p>A <span class="pkg">VGAM</span> extremes model of the
Gumbel type, produced by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>, and with a family function that is either
<code><a href="#topic+gumbel">gumbel</a></code> or <code><a href="#topic+gumbelff">gumbelff</a></code>.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_show.plot">show.plot</code></td>
<td>

<p>Logical. Plot it? If <code>FALSE</code> no plot will be done.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_y.arg">y.arg</code></td>
<td>

<p>Logical. Add the raw data on to the plot?
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_spline.fit">spline.fit</code></td>
<td>

<p>Logical. Use a spline fit through the fitted
percentiles? This can be useful if there are large gaps
between some values along the covariate.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_label">label</code></td>
<td>
<p> Logical. Label the percentiles? </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_r">R</code></td>
<td>
<p> See <code><a href="#topic+gumbel">gumbel</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_percentiles">percentiles</code></td>
<td>
<p> See <code><a href="#topic+gumbel">gumbel</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_add.arg">add.arg</code></td>
<td>
<p> Logical. Add the plot to an existing plot? </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_mpv">mpv</code></td>
<td>
<p> See <code><a href="#topic+gumbel">gumbel</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_xlab">xlab</code></td>
<td>
<p> Caption for the x-axis. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_ylab">ylab</code></td>
<td>
<p> Caption for the y-axis. See <code><a href="graphics.html#topic+par">par</a></code>.  </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_main">main</code></td>
<td>
<p> Title of the plot. See <code><a href="graphics.html#topic+title">title</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_pch">pch</code></td>
<td>
<p> Plotting character. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_pcol.arg">pcol.arg</code></td>
<td>
<p> Color of the points.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.  </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_llty.arg">llty.arg</code></td>
<td>
<p> Line type. Line type.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_lcol.arg">lcol.arg</code></td>
<td>
<p> Color of the lines.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_llwd.arg">llwd.arg</code></td>
<td>
<p> Line width.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_tcol.arg">tcol.arg</code></td>
<td>
<p> Color of the text
(if <code>label</code> is <code>TRUE</code>).
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_tadj">tadj</code></td>
<td>
<p> Text justification.
See the <code>adj</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="qtplot.gumbel_+3A_...">...</code></td>
<td>

<p>Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>sub</code> and <code>las</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There should be a single covariate such as time.
The quantiles specified by <code>percentiles</code> are plotted.
</p>


<h3>Value</h3>

<p>The object with a list called <code>qtplot</code> in the <code>post</code>
slot of <code>object</code>.
(If <code>show.plot = FALSE</code> then just the list is returned.)
The list contains components
</p>
<table>
<tr><td><code>fitted.values</code></td>
<td>

<p>The percentiles of the response,
possibly including the MPV.
</p>
</td></tr>
<tr><td><code>percentiles</code></td>
<td>

<p>The percentiles (small vector of values between 0 and 100.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Unlike <code><a href="#topic+gumbel">gumbel</a></code>, one cannot have
<code>percentiles = NULL</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+gumbel">gumbel</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ymat &lt;- as.matrix(venice[, paste("r", 1:10, sep = "")])
fit1 &lt;- vgam(ymat ~ s(year, df = 3), gumbel(R = 365, mpv = TRUE),
             data = venice, trace = TRUE, na.action = na.pass)
head(fitted(fit1))

## Not run:  par(mfrow = c(1, 1), bty = "l", xpd = TRUE, las = 1)
qtplot(fit1, mpv = TRUE, lcol = c(1, 2, 5), tcol = c(1, 2, 5),
       lwd = 2, pcol = "blue", tadj = 0.4, ylab = "Sea level (cm)")

qtplot(fit1, perc = 97, mpv = FALSE, lcol = 3, tcol = 3,
       lwd = 2, tadj = 0.4, add = TRUE) -&gt; saved
head(saved@post$qtplot$fitted)

## End(Not run)
</code></pre>

<hr>
<h2 id='qtplot.lmscreg'> Quantile Plot for LMS Quantile Regression </h2><span id='topic+qtplot.lmscreg'></span>

<h3>Description</h3>

<p>Plots quantiles associated with a LMS quantile regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtplot.lmscreg(object, newdata = NULL,
               percentiles = object@misc$percentiles,
               show.plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qtplot.lmscreg_+3A_object">object</code></td>
<td>
<p> A <span class="pkg">VGAM</span> quantile regression model, i.e.,
an object produced by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code> with a family function beginning with
<code>"lms."</code>, e.g., <code><a href="#topic+lms.yjn">lms.yjn</a></code>.
</p>
</td></tr>
<tr><td><code id="qtplot.lmscreg_+3A_newdata">newdata</code></td>
<td>
<p> Optional data frame for computing the quantiles.
If missing, the original data is used.
</p>
</td></tr>
<tr><td><code id="qtplot.lmscreg_+3A_percentiles">percentiles</code></td>
<td>
<p> Numerical vector with values
between 0 and 100
that specify the percentiles (quantiles).
The default are the percentiles used when the model was fitted.
</p>
</td></tr>
<tr><td><code id="qtplot.lmscreg_+3A_show.plot">show.plot</code></td>
<td>
<p> Logical. Plot it? If <code>FALSE</code> no plot will
be done. </p>
</td></tr>
<tr><td><code id="qtplot.lmscreg_+3A_...">...</code></td>
<td>
<p> Graphical parameter that are passed into
<code><a href="#topic+plotqtplot.lmscreg">plotqtplot.lmscreg</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &lsquo;primary&rsquo; variable is defined as the main covariate upon
which the regression or smoothing is performed. For example,
in medical studies, it is often the age.  In <span class="pkg">VGAM</span>, it is
possible to handle more than one covariate, however, the primary
variable must be the first term after the intercept.
</p>


<h3>Value</h3>

<p>A list with the following components.
</p>
<table>
<tr><td><code>fitted.values</code></td>
<td>
<p>A vector of fitted percentile values. </p>
</td></tr>
<tr><td><code>percentiles</code></td>
<td>
<p>The percentiles used. </p>
</td></tr>
</table>


<h3>Note</h3>

<p><code><a href="#topic+plotqtplot.lmscreg">plotqtplot.lmscreg</a></code> does the actual plotting.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+plotqtplot.lmscreg">plotqtplot.lmscreg</a></code>,
<code><a href="#topic+deplot.lmscreg">deplot.lmscreg</a></code>,
<code><a href="#topic+lms.bcn">lms.bcn</a></code>,
<code><a href="#topic+lms.bcg">lms.bcg</a></code>,
<code><a href="#topic+lms.yjn">lms.yjn</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fit &lt;- vgam(BMI ~ s(age, df = c(4, 2)), lms.bcn(zero=1), bmi.nz)
qtplot(fit)
qtplot(fit, perc = c(25, 50, 75, 95), lcol = 4, tcol = 4, llwd = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='qvar'>
Quasi-variances Extraction Function

</h2><span id='topic+qvar'></span>

<h3>Description</h3>

<p>Takes a <code><a href="#topic+rcim">rcim</a></code> fit of the appropriate format and
returns either the quasi-variances or quasi-standard errors.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>qvar(object, se = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qvar_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+rcim">rcim</a></code> object that has family function
<code><a href="#topic+uninormal">uninormal</a></code> with the
<code><a href="#topic+explink">explink</a></code> link.
See below for an example.
</p>
</td></tr>
<tr><td><code id="qvar_+3A_se">se</code></td>
<td>

<p>Logical. If <code>FALSE</code> then the quasi-variances
are returned,
else the square root of them, called quasi-standard errors.
</p>
</td></tr>
<tr><td><code id="qvar_+3A_...">...</code></td>
<td>

<p>Currently unused.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This simple function is ad hoc and simply is equivalent to
computing the quasi-variances
by <code>diag(predict(fit1)[, c(TRUE, FALSE)]) / 2</code>.
This function is for convenience only.
Serious users of quasi-variances ought to understand
why and how this
function works.
</p>


<h3>Value</h3>

<p>A vector of quasi-variances  or quasi-standard errors.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+explink">explink</a></code>,
<code><a href="#topic+Qvar">Qvar</a></code>,
<code><a href="MASS.html#topic+ships">ships</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>data("ships", package = "MASS")
Shipmodel &lt;- vglm(incidents ~ type + year + period,
                  poissonff, offset = log(service),
                  data = ships, subset = (service &gt; 0))

# Easiest form of input
fit1 = rcim(Qvar(Shipmodel, "type"), uninormal("explink"), maxit=99)
qvar(fit1)             # Quasi-variances
qvar(fit1, se = TRUE)  # Quasi-standard errors

# Manually compute them:
(quasiVar &lt;- exp(diag(fitted(fit1))) / 2)                # Version 1
(quasiVar &lt;- diag(predict(fit1)[, c(TRUE, FALSE)]) / 2)  # Version 2
(quasiSE  &lt;- sqrt(quasiVar))

## Not run:  qvplot(fit1, col = "green", lwd = 3, scol = "blue",
     slwd = 2, las = 1) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Qvar'>
Quasi-variances Preprocessing Function

</h2><span id='topic+Qvar'></span>

<h3>Description</h3>

<p>Takes a <code><a href="#topic+vglm">vglm</a></code> fit or a variance-covariance matrix,
and preprocesses it for <code><a href="#topic+rcim">rcim</a></code> and
<code><a href="#topic+uninormal">uninormal</a></code> so that quasi-variances can be computed.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>Qvar(object, factorname = NULL, which.linpred = 1,
     coef.indices = NULL, labels = NULL,
     dispersion = NULL, reference.name = "(reference)", estimates = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Qvar_+3A_object">object</code></td>
<td>

<p>A <code>"<a href="#topic+vglmff-class">vglm</a>"</code> object or a variance-covariance
matrix, e.g., <code>vcov(vglm.object)</code>.
The former is preferred since it contains all the information needed.
If a matrix then <code>factorname</code> and/or <code>coef.indices</code>
should be specified to identify the factor.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_which.linpred">which.linpred</code></td>
<td>

<p>A single integer from the set <code>1:M</code>.
Specifies which linear predictor to use.
Let the value of <code>which.linpred</code> be called <code class="reqn">j</code>.
Then the factor should appear in that linear predictor, hence
the <code class="reqn">j</code>th row of the constraint matrix corresponding
to the factor should have at least one nonzero value.
Currently the <code class="reqn">j</code>th row must have exactly one nonzero value
because programming it for more than one nonzero value is difficult.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_factorname">factorname</code></td>
<td>

<p>Character.
If the <code><a href="#topic+vglm">vglm</a></code> object contains more than one
factor as explanatory variable then this argument should
be the name of the factor of interest.
If <code>object</code> is a variance-covariance matrix then
this argument should also be specified.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_labels">labels</code></td>
<td>

<p>Character.
Optional, for labelling the variance-covariance matrix.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_dispersion">dispersion</code></td>
<td>

<p>Numeric.
Optional, passed into <code>vcov()</code> with the same argument name.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_reference.name">reference.name</code></td>
<td>

<p>Character.
Label for for the reference level.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_coef.indices">coef.indices</code></td>
<td>

<p>Optional numeric vector of length at least 3 specifying
the indices of the factor from the variance-covariance
matrix.
</p>
</td></tr>
<tr><td><code id="Qvar_+3A_estimates">estimates</code></td>
<td>

<p>an optional vector of estimated coefficients
(redundant if <code>object</code> is a model).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose a factor with <code class="reqn">L</code> levels is an explanatory variable in a
regression model. By default, R treats the first level as baseline so
that its coefficient is set to zero. It estimates the other <code class="reqn">L-1</code>
coefficients, and with its associated standard errors, this is the
conventional output. From the complete variance-covariance matrix one
can compute <code class="reqn">L</code> quasi-variances based on all pairwise difference
of the coefficients. They are based on an approximation, and can be
treated as uncorrelated. In minimizing the relative (not absolute)
errors it is not hard to see that the estimation involves a RCIM
(<code><a href="#topic+rcim">rcim</a></code>) with an exponential link function
(<code><a href="#topic+explink">explink</a></code>).
</p>
<p>If <code>object</code> is a model, then at least one of <code>factorname</code> or
<code>coef.indices</code> must be non-<code>NULL</code>. The value of
<code>coef.indices</code>, if non-<code>NULL</code>, determines which rows and
columns of the model's variance-covariance matrix to use. If
<code>coef.indices</code> contains a zero, an extra row and column are
included at the indicated position, to represent the zero variances
and covariances associated with a reference level. If
<code>coef.indices</code> is <code>NULL</code>, then <code>factorname</code> should be
the name of a factor effect in the model, and is used in order to
extract the necessary variance-covariance estimates.
</p>
<p>Quasi-variances were first implemented in R with <span class="pkg">qvcalc</span>.
This implementation draws heavily from that.
</p>


<h3>Value</h3>

<p>A <code class="reqn">L</code> by <code class="reqn">L</code> matrix whose <code class="reqn">i</code>-<code class="reqn">j</code> element
is the logarithm of the variance of the <code class="reqn">i</code>th coefficient
minus the <code class="reqn">j</code>th coefficient, for all values of <code class="reqn">i</code>
and <code class="reqn">j</code>. The diagonal elements are abitrary and are set
to zero.
</p>
<p>The matrix has an attribute that corresponds to the prior
weight matrix; it is accessed by <code><a href="#topic+uninormal">uninormal</a></code>
and replaces the usual <code>weights</code> argument.
of <code><a href="#topic+vglm">vglm</a></code>. This weight matrix has ones on
the off-diagonals and some small positive number on
the diagonals.
</p>


<h3>Warning </h3>

<p>Negative quasi-variances may occur (one of them and
only one), though they are rare in practice. If
so then numerical problems may occur. See
<code>qvcalc()</code> for more information.
</p>


<h3>Note</h3>

<p>This is an adaptation of <code>qvcalc()</code> in <span class="pkg">qvcalc</span>.
It should work for all <code><a href="#topic+vglm">vglm</a></code>
models with one linear predictor, i.e., <code class="reqn">M = 1</code>.
For <code class="reqn">M &gt; 1</code> the factor should appear only in one of the
linear predictors.
</p>
<p>It is important to set <code>maxit</code> to be larger than usual for
<code><a href="#topic+rcim">rcim</a></code> since convergence is slow. Upon successful
convergence the <code class="reqn">i</code>th row effect and the <code class="reqn">i</code>th column effect
should be equal. A simple computation involving the fitted and
predicted values allows the quasi-variances to be extracted (see
example below).
</p>
<p>A function to plot <em>comparison intervals</em> has not been
written here.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee, based heavily on <code>qvcalc()</code> in <span class="pkg">qvcalc</span>
written by David Firth.
</p>


<h3>References</h3>

<p>Firth, D. (2003).
Overcoming the reference category problem in the
presentation of statistical models.
<em>Sociological Methodology</em> <b>33</b>, 1&ndash;18.
</p>
<p>Firth, D. and de Menezes, R. X. (2004).
Quasi-variances.
<em>Biometrika</em> <b>91</b>, 65&ndash;80.
</p>
<p>Yee, T. W. and Hadi, A. F. (2014).
Row-column interaction models, with an R implementation.
<em>Computational Statistics</em>,
<b>29</b>, 1427&ndash;1445.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+qvar">qvar</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+explink">explink</a></code>,
<code>qvcalc()</code> in <span class="pkg">qvcalc</span>,
<code><a href="MASS.html#topic+ships">ships</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'># Example 1
data("ships", package = "MASS")

Shipmodel &lt;- vglm(incidents ~ type + year + period,
                  poissonff, offset = log(service),
#                 trace = TRUE, model = TRUE,
                  data = ships, subset = (service &gt; 0))

# Easiest form of input
fit1 &lt;- rcim(Qvar(Shipmodel, "type"), uninormal("explink"), maxit = 99)
qvar(fit1)              # Easy method to get the quasi-variances
qvar(fit1, se = TRUE)   # Easy method to get the quasi-standard errors

(quasiVar &lt;- exp(diag(fitted(fit1))) / 2)                 # Version 1
(quasiVar &lt;- diag(predict(fit1)[, c(TRUE, FALSE)]) / 2)   # Version 2
(quasiSE  &lt;- sqrt(quasiVar))

# Another form of input
fit2 &lt;- rcim(Qvar(Shipmodel, coef.ind = c(0, 2:5), reference.name = "typeA"),
             uninormal("explink"), maxit = 99)
## Not run:  qvplot(fit2, col = "green", lwd = 3, scol = "blue", slwd = 2, las = 1) 

# The variance-covariance matrix is another form of input (not recommended)
fit3 &lt;- rcim(Qvar(cbind(0, rbind(0, vcov(Shipmodel)[2:5, 2:5])),
                  labels = c("typeA", "typeB", "typeC", "typeD", "typeE"),
                  estimates = c(typeA = 0, coef(Shipmodel)[2:5])),
             uninormal("explink"), maxit = 99)
(QuasiVar &lt;- exp(diag(fitted(fit3))) / 2)                 # Version 1
(QuasiVar &lt;- diag(predict(fit3)[, c(TRUE, FALSE)]) / 2)   # Version 2
(QuasiSE  &lt;- sqrt(quasiVar))
## Not run:  qvplot(fit3) 


# Example 2: a model with M &gt; 1 linear predictors
## Not run:  require("VGAMdata")
xs.nz.f &lt;- subset(xs.nz, sex == "F")
xs.nz.f &lt;- subset(xs.nz.f, !is.na(babies)  &amp; !is.na(age) &amp; !is.na(ethnicity))
xs.nz.f &lt;- subset(xs.nz.f, ethnicity != "Other")

clist &lt;- list("sm.bs(age, df = 4)" = rbind(1, 0),
              "sm.bs(age, df = 3)" = rbind(0, 1),
              "ethnicity"          = diag(2),
              "(Intercept)"        = diag(2))
fit1 &lt;- vglm(babies ~ sm.bs(age, df = 4) + sm.bs(age, df = 3) + ethnicity,
            zipoissonff(zero = NULL), xs.nz.f,
            constraints = clist, trace = TRUE)
Fit1 &lt;- rcim(Qvar(fit1, "ethnicity", which.linpred = 1),
             uninormal("explink", imethod = 1), maxit = 99, trace = TRUE)
Fit2 &lt;- rcim(Qvar(fit1, "ethnicity", which.linpred = 2),
             uninormal("explink", imethod = 1), maxit = 99, trace = TRUE)

## End(Not run)
## Not run:  par(mfrow = c(1, 2))
qvplot(Fit1, scol = "blue", pch = 16, main = expression(eta[1]),
       slwd = 1.5, las = 1, length.arrows = 0.07)
qvplot(Fit2, scol = "blue", pch = 16, main = expression(eta[2]),
       slwd = 1.5, las = 1, length.arrows = 0.07)

## End(Not run)
</code></pre>

<hr>
<h2 id='R2latvar'> R-squared for Latent Variable Models </h2><span id='topic+R2latvar'></span>

<h3>Description</h3>

<p>R-squared goodness of fit for latent variable models,
such as cumulative link models.
Some software such as Stata call the quantity
the McKelvey&ndash;Zavoina R-squared, which was proposed
in their 1975 paper for cumulative probit models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2latvar(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2latvar_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+cumulative">cumulative</a></code> or
<code><a href="#topic+binomialff">binomialff</a></code> fit using
<code><a href="#topic+vglm">vglm</a></code>.
Only a few selected link functions are currently permitted:
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>.
For models with more than one linear predictor,
a parallelism assumption is needed also, i.e.,
the constraint matrices must be a 1-column matrix of 1s
(except for the intercept).
The model is assumed to have an intercept term.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Models such as the proportional odds model have
a latent variable interpretation
(see, e.g., Section 6.2.6 of Agresti (2018),
Section 14.4.1.1 of Yee (2015),
Section 5.2.2 of McCullagh and Nelder (1989)).
It is possible to summarize the predictive power of
the model by computing <code class="reqn">R^2</code> on the transformed
scale, e.g., on a standard normal distribution for
a <code><a href="#topic+probitlink">probitlink</a></code> link.
For more details see Section 6.3.7 of Agresti (2018).
</p>


<h3>Value</h3>

<p>The <code class="reqn">R^2</code> value.
Approximately, that amount is the variability in the
latent variable of the model explained by all the explanatory
variables.
Then taking the positive square-root gives an approximate
multiple correlation <code class="reqn">R</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>





<p>Agresti, A. (2018).
<em>An Introduction to Categorical Data Analysis, 3rd ed.</em>,
New York: John Wiley &amp; Sons.
</p>
<p>McKelvey, R. D. and W. Zavoina (1975).
A statistical model for the analysis of
ordinal level dependent variables.
<em>The Journal of Mathematical Sociology</em>, <b>4</b>,
103&ndash;120.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+propodds">propodds</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="stats.html#topic+summary.lm">summary.lm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, data = pneumo))
R2latvar(fit)
</code></pre>

<hr>
<h2 id='Rank'> Rank </h2><span id='topic+Rank'></span><span id='topic+Rank.rrvglm'></span><span id='topic+Rank.qrrvglm'></span><span id='topic+Rank.rrvgam'></span>

<h3>Description</h3>

<p>Returns the rank of reduced-rank regression-type models in
the VGAM package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    Rank(object, ...)
    Rank.rrvglm(object, ...)
    Rank.qrrvglm(object, ...)
    Rank.rrvgam(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rank_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, for example, having
class <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>.
The class <code><a href="#topic+vglm-class">vglm-class</a></code> is not included since this
is not based on reduced-rank regression.
</p>
</td></tr>
<tr><td><code id="Rank_+3A_...">...</code></td>
<td>

<p>Other possible arguments fed into
the function later
(used for added flexibility for the future).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regression models based on reduced-rank regression have a quantity
called the <em>rank</em>, which is 1 or 2 or 3 etc.
The smaller the value the more dimension reduction, so that there
are fewer parameters.
This function was not called <code>rank()</code> to avoid conflict
with <code><a href="base.html#topic+rank">rank</a></code>.
</p>


<h3>Value</h3>

<p>Returns an integer value, provided the rank of the model makes sense.
</p>


<h3>Note</h3>

<p>This function has not been defined for VGLMs yet.
It might refer to the rank of the VL model matrix,
but for now this function should not be applied to
<code><a href="#topic+vglm">vglm</a></code> fits.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>See Also</h3>

<p>RR-VGLMs are described in <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>;
QRR-VGLMs are described in <code><a href="#topic+qrrvglm-class">qrrvglm-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3  = runif(nrow(pneumo)))
(fit1 &lt;- rrvglm(cbind(normal, mild, severe) ~ let + x3,
                acat, data = pneumo))
coef(fit1, matrix = TRUE)
constraints(fit1)
Rank(fit1)
</code></pre>

<hr>
<h2 id='rayleigh'>Rayleigh Regression Family Function </h2><span id='topic+rayleigh'></span><span id='topic+cens.rayleigh'></span>

<h3>Description</h3>

<p>Estimating the parameter of the Rayleigh distribution by maximum
likelihood estimation. Right-censoring is allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   rayleigh(lscale = "loglink", nrfs = 1/3 + 0.01,
            oim.mean = TRUE, zero = NULL, parallel = FALSE,
            type.fitted = c("mean", "percentiles", "Qlink"),
            percentiles = 50)
cens.rayleigh(lscale = "loglink", oim = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rayleigh_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link function applied to the scale parameter <code class="reqn">b</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
A log link is the default because <code class="reqn">b</code> is positive.
</p>
</td></tr>
<tr><td><code id="rayleigh_+3A_nrfs">nrfs</code></td>
<td>

<p>Numeric, of length one, with value in <code class="reqn">[0,1]</code>.
Weighting factor between Newton-Raphson and Fisher scoring.
The value 0 means pure Newton-Raphson,
while 1 means pure Fisher scoring.
The default value uses a mixture of the two algorithms, and retaining
positive-definite working weights.
</p>
</td></tr>
<tr><td><code id="rayleigh_+3A_oim.mean">oim.mean</code></td>
<td>

<p>Logical, used only for intercept-only models.
<code>TRUE</code> means the mean of the OIM elements are used as
working weights.
If <code>TRUE</code> then this argument has top priority for working
out the working weights.
<code>FALSE</code> means use another algorithm.
</p>
</td></tr>
<tr><td><code id="rayleigh_+3A_oim">oim</code></td>
<td>

<p>Logical.
For censored data only,
<code>TRUE</code> means the Newton-Raphson algorithm, and
<code>FALSE</code> means Fisher scoring.
</p>
</td></tr>
<tr><td><code id="rayleigh_+3A_zero">zero</code>, <code id="rayleigh_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="rayleigh_+3A_type.fitted">type.fitted</code>, <code id="rayleigh_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Using <code>"Qlink"</code> is for quantile-links in <span class="pkg">VGAMextra</span>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Rayleigh distribution, which is used in physics,
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = y \exp(-0.5 (y/b)^2)/b^2</code>
</p>

<p>for <code class="reqn">y &gt; 0</code> and <code class="reqn">b &gt; 0</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">b \sqrt{\pi / 2}</code>
(returned as the fitted values)
and its variance is
<code class="reqn">b^2 (4-\pi)/2</code>.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>cens.rayleigh</code> handles
right-censored data (the true value is greater than the observed
value). To indicate which type of censoring, input <code>extra =
  list(rightcensored = vec2)</code> where <code>vec2</code> is a logical vector the
same length as the response.  If the component of this list is missing
then the logical values are taken to be <code>FALSE</code>.  The fitted
object has this component stored in the <code>extra</code> slot.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>rayleigh</code> handles multiple
responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>The theory behind the argument <code>oim</code> is not fully complete.
</p>


<h3>Note</h3>

<p>The  <code><a href="#topic+poisson.points">poisson.points</a></code> family function is
more general so that if <code>ostatistic = 1</code> and <code>dimension = 2</code>
then it coincides with <code><a href="#topic+rayleigh">rayleigh</a></code>.
Other related distributions are the Maxwell
and Weibull distributions.
</p>






<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rayleigh">Rayleigh</a></code>,
<code><a href="#topic+genrayleigh">genrayleigh</a></code>,
<code><a href="#topic+riceff">riceff</a></code>,
<code><a href="#topic+maxwell">maxwell</a></code>,
<code><a href="#topic+weibullR">weibullR</a></code>,
<code><a href="#topic+poisson.points">poisson.points</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000; Scale &lt;- exp(2)
rdata &lt;- data.frame(ystar = rrayleigh(nn, scale = Scale))
fit &lt;- vglm(ystar ~ 1, rayleigh, data = rdata, trace = TRUE)
head(fitted(fit))
with(rdata, mean(ystar))
coef(fit, matrix = TRUE)
Coef(fit)

# Censored data
rdata &lt;- transform(rdata, U = runif(nn, 5, 15))
rdata &lt;- transform(rdata, y = pmin(U, ystar))
## Not run:  par(mfrow = c(1, 2))
hist(with(rdata, ystar)); hist(with(rdata, y)) 
## End(Not run)
extra &lt;- with(rdata, list(rightcensored = ystar &gt; U))
fit &lt;- vglm(y ~ 1, cens.rayleigh, data = rdata, trace = TRUE,
            extra = extra, crit = "coef")
table(fit@extra$rightcen)
coef(fit, matrix = TRUE)
head(fitted(fit))
</code></pre>

<hr>
<h2 id='Rayleigh'>Rayleigh Distribution</h2><span id='topic+Rayleigh'></span><span id='topic+drayleigh'></span><span id='topic+prayleigh'></span><span id='topic+qrayleigh'></span><span id='topic+rrayleigh'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Rayleigh distribution with parameter
<code>a</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drayleigh(x, scale = 1, log = FALSE)
prayleigh(q, scale = 1, lower.tail = TRUE, log.p = FALSE)
qrayleigh(p, scale = 1, lower.tail = TRUE, log.p = FALSE)
rrayleigh(n, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rayleigh_+3A_x">x</code>, <code id="Rayleigh_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Rayleigh_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Rayleigh_+3A_n">n</code></td>
<td>
<p>number of observations.
Fed into <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Rayleigh_+3A_scale">scale</code></td>
<td>
<p>the scale parameter <code class="reqn">b</code>.</p>
</td></tr>
<tr><td><code id="Rayleigh_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is
returned.
</p>
</td></tr>
<tr><td><code id="Rayleigh_+3A_lower.tail">lower.tail</code>, <code id="Rayleigh_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+rayleigh">rayleigh</a></code>, the <span class="pkg">VGAM</span> family
function for estimating the scale parameter <code class="reqn">b</code> by
maximum likelihood estimation, for the formula of the
probability density function and range restrictions on
the parameter <code class="reqn">b</code>.
</p>


<h3>Value</h3>

<p><code>drayleigh</code> gives the density,
<code>prayleigh</code> gives the distribution function,
<code>qrayleigh</code> gives the quantile function, and
<code>rrayleigh</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Rayleigh distribution is related to the
Maxwell distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="#topic+maxwell">maxwell</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  Scale &lt;- 2; x &lt;- seq(-1, 8, by = 0.1)
plot(x, drayleigh(x, scale = Scale), type = "l", ylim = c(0,1),
  las = 1, ylab = "",
  main = "Rayleigh density divided into 10 equal areas; red = CDF")
abline(h = 0, col = "blue", lty = 2)
qq &lt;- qrayleigh(seq(0.1, 0.9, by = 0.1), scale = Scale)
lines(qq, drayleigh(qq, scale = Scale), col = 2, lty = 3, type = "h")
lines(x, prayleigh(x, scale = Scale), col = "red") 
## End(Not run)
</code></pre>

<hr>
<h2 id='Rcim'>
Mark the Baseline of Row and Column on a Matrix data
</h2><span id='topic+Rcim'></span>

<h3>Description</h3>

<p>Rearrange the rows and columns of the input so
that the first row and first column are baseline.
This function is for rank-zero row-column interaction models
(RCIMs; i.e., general main effects models).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Rcim(mat, rbaseline = 1, cbaseline = 1)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rcim_+3A_mat">mat</code></td>
<td>

<p>Matrix, of dimension <code class="reqn">r</code> by <code class="reqn">c</code>.
It is best that it is labelled with row and column names.
</p>
</td></tr>
<tr><td><code id="Rcim_+3A_rbaseline">rbaseline</code>, <code id="Rcim_+3A_cbaseline">cbaseline</code></td>
<td>

<p>Numeric (row number of the matrix <code>mat</code>) or
character (matching a row name of <code>mat</code>) that the user
wants as the row baseline or reference level.
Similarly <code>cbaseline</code> for the column.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a data preprocessing function for <code><a href="#topic+rcim">rcim</a></code>.
For rank-zero row-column interaction models this function
establishes the baseline (or reference) levels of the matrix
response with respect to the row and columns&mdash;these become
the new first row and column.
</p>


<h3>Value</h3>

<p>Matrix of the same dimension as the input,
with <code>rbaseline</code> and <code>cbaseline</code> specifying the
first rows and columns.
The default is no change in <code>mat</code>.
</p>


<h3>Note</h3>

<p>This function is similar to <code><a href="#topic+moffset">moffset</a></code>; see
<code><a href="#topic+moffset">moffset</a></code> for information about the differences.
If numeric, the arguments
<code>rbaseline</code>
and
<code>cbaseline</code>
differ from arguments
<code>roffset</code>
and
<code>coffset</code>
in <code><a href="#topic+moffset">moffset</a></code>
by 1 (when elements of the matrix agree).
</p>


<h3>Author(s)</h3>

<p>Alfian F. Hadi and T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moffset">moffset</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+plotrcim0">plotrcim0</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(alcoff.e &lt;- moffset(alcoff, roffset = "6", postfix = "*"))
(aa &lt;- Rcim(alcoff,    rbaseline = "11", cbaseline = "Sun"))
(bb &lt;- moffset(alcoff,             "11",             "Sun", postfix = "*"))
aa - bb  # Note the difference!
</code></pre>

<hr>
<h2 id='rcqo'> Constrained Quadratic Ordination </h2><span id='topic+rcqo'></span>

<h3>Description</h3>

<p>Random generation for constrained quadratic ordination (CQO).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcqo(n, p, S, Rank = 1,
     family = c("poisson", "negbinomial", "binomial-poisson",
                "Binomial-negbinomial", "ordinal-poisson",
                "Ordinal-negbinomial", "gamma2"),
     eq.maximums = FALSE, eq.tolerances = TRUE, es.optimums = FALSE,
     lo.abundance = if (eq.maximums) hi.abundance else 10,
     hi.abundance = 100, sd.latvar = head(1.5/2^(0:3), Rank),
     sd.optimums = ifelse(es.optimums, 1.5/Rank, 1) *
                       ifelse(scale.latvar, sd.latvar, 1),
     sd.tolerances = 0.25, Kvector = 1, Shape = 1,
     sqrt.arg = FALSE, log.arg = FALSE, rhox = 0.5, breaks = 4,
     seed = NULL, optimums1.arg = NULL, Crow1positive = TRUE,
     xmat = NULL, scale.latvar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcqo_+3A_n">n</code></td>
<td>

<p>Number of sites. It is denoted by <code class="reqn">n</code> below.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_p">p</code></td>
<td>

<p>Number of environmental variables, including an intercept term.
It is denoted by <code class="reqn">p</code> below.
Must be no less than <code class="reqn">1+R</code> in value.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_s">S</code></td>
<td>

<p>Number of species.
It is denoted by <code class="reqn">S</code> below.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_rank">Rank</code></td>
<td>

<p>The rank or the number of latent variables or true dimension
of the data on the reduced space.
This must be either 1, 2, 3 or 4.
It is denoted by <code class="reqn">R</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_family">family</code></td>
<td>

<p>What type of species data is to be returned.
The first choice is the default.
If binomial then a 0 means absence and 1 means presence.
If ordinal then the <code>breaks</code> argument is passed into
the <code>breaks</code> argument of <code><a href="base.html#topic+cut">cut</a></code>.
Note that either the Poisson or
negative binomial distributions
are used to generate binomial and
ordinal data, and that
an upper-case choice is used for the
negative binomial distribution
(this makes it easier for the user).
If <code>"gamma2"</code> then this is the
2-parameter gamma distribution.
</p>




</td></tr>
<tr><td><code id="rcqo_+3A_eq.maximums">eq.maximums</code></td>
<td>

<p>Logical. Does each species have the same maximum?
See arguments <code>lo.abundance</code> and <code>hi.abundance</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_eq.tolerances">eq.tolerances</code></td>
<td>

<p>Logical. Does each species have the
same tolerance? If <code>TRUE</code> then the common
value is 1 along
every latent variable, i.e., all species' tolerance matrices
are the order-<code class="reqn">R</code> identity matrix.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_es.optimums">es.optimums</code></td>
<td>

<p>Logical. Do the species have equally spaced optimums?
If <code>TRUE</code> then the quantity
<code class="reqn">S^{1/R}</code> must be an
integer with value 2 or more. That is, there has to be an
appropriate number of species in total.
This is so that a grid
of optimum values is possible in <code class="reqn">R</code>-dimensional
latent variable space
in order to place the species' optimums.
Also see the argument <code>sd.tolerances</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_lo.abundance">lo.abundance</code>, <code id="rcqo_+3A_hi.abundance">hi.abundance</code></td>
<td>

<p>Numeric. These are recycled to a vector of length <code class="reqn">S</code>.
The species have a maximum
between <code>lo.abundance</code> and <code>hi.abundance</code>. That is,
at their optimal environment, the mean abundance of each
species is between the two componentwise values.
If <code>eq.maximums</code> is <code>TRUE</code> then
<code>lo.abundance</code> and <code>hi.abundance</code>
must have the same values.
If <code>eq.maximums</code> is <code>FALSE</code> then the
logarithm of the maximums are uniformly distributed between
<code>log(lo.abundance)</code> and <code>log(hi.abundance)</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_sd.latvar">sd.latvar</code></td>
<td>

<p>Numeric, of length <code class="reqn">R</code>
(recycled if necessary). Site scores along
each latent variable have these standard deviation values.
This must be a decreasing sequence of values because the first
ordination axis contains the greatest spread of the species'
site scores, followed by the second axis, followed by the third
axis, etc.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_sd.optimums">sd.optimums</code></td>
<td>

<p>Numeric, of length <code class="reqn">R</code> (recycled if necessary).
If <code>es.optimums = FALSE</code> then,
for the <code class="reqn">r</code>th latent variable axis,
the optimums of the species are generated from a
normal distribution centered about 0.
If <code>es.optimums = TRUE</code> then the <code class="reqn">S</code> optimums
are equally spaced about 0 along every
latent variable axis.
Regardless of the value of <code>es.optimums</code>, the optimums
are then scaled to give standard deviation
<code>sd.optimums[r]</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_sd.tolerances">sd.tolerances</code></td>
<td>

<p>Logical. If <code>eq.tolerances = FALSE</code> then, for the
<code class="reqn">r</code>th latent variable, the
species' tolerances are
chosen from a normal distribution with mean 1 and
standard deviation
<code>sd.tolerances[r]</code>.
However, the first species <code>y1</code> has its tolerance matrix
set equal to the order-<code class="reqn">R</code> identity matrix.
All tolerance matrices for all species are
diagonal in this function.
This argument is ignored if <code>eq.tolerances</code> is <code>TRUE</code>,
otherwise it is recycled to length <code class="reqn">R</code> if necessary.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_kvector">Kvector</code></td>
<td>

<p>A vector of positive <code class="reqn">k</code> values (recycled to length <code class="reqn">S</code>
if necessary) for the negative binomial distribution
(see <code><a href="#topic+negbinomial">negbinomial</a></code> for details).
Note that a natural default value does not exist,
however the default
value here is probably a realistic one, and that
for large values
of <code class="reqn">\mu</code> one has <code class="reqn">Var(Y)=\mu^2/k</code>
approximately.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_shape">Shape</code></td>
<td>

<p>A vector of positive <code class="reqn">\lambda</code>
values (recycled to length
<code class="reqn">S</code> if necessary) for the 2-parameter gamma
distribution (see
<code><a href="#topic+gamma2">gamma2</a></code> for details).
Note that a natural default value
does not exist, however the default value
here is probably a realistic
one, and that
<code class="reqn">Var(Y) = \mu^2 / \lambda</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_sqrt.arg">sqrt.arg</code></td>
<td>

<p>Logical. Take the square-root of the
negative binomial counts?
Assigning <code>sqrt.arg = TRUE</code>
when <code>family="negbinomial"</code> means
that the resulting species data can be
considered very crudely to be
approximately Poisson distributed.
They will not integers in general but much easier
(less numerical
problems) to estimate using something like
<code>cqo(..., family="poissonff")</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_log.arg">log.arg</code></td>
<td>

<p>Logical. Take the logarithm of the gamma random variates?
Assigning <code>log.arg = TRUE</code>
when <code>family="gamma2"</code> means
that the resulting species data can be
considered very crudely to be
approximately Gaussian distributed about its (quadratic) mean.
</p>



</td></tr>
<tr><td><code id="rcqo_+3A_rhox">rhox</code></td>
<td>

<p>Numeric, less than 1 in absolute value.
The correlation between the environmental variables.
The correlation matrix is a matrix of 1's along the diagonal
and <code>rhox</code> in the off-diagonals.
Note that each environmental variable is normally distributed
with mean 0. The standard deviation of each environmental
variable is chosen so that the site scores have the determined
standard deviation, as given by argument <code>sd.latvar</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_breaks">breaks</code></td>
<td>

<p>If <code>family</code> is assigned an ordinal value then this argument
is used to define the cutpoints. It is fed into the
<code>breaks</code> argument of <code><a href="base.html#topic+cut">cut</a></code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_seed">seed</code></td>
<td>

<p>If given, it is passed into <code><a href="base.html#topic+Random">set.seed</a></code>.
This argument can be used to obtain reproducible results.
If set, the value is saved as the <code>"seed"</code>
attribute of the returned value. The default will
not change the random generator state, and return
<code><a href="base.html#topic+Random">.Random.seed</a></code>
as <code>"seed"</code> attribute.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_optimums1.arg">optimums1.arg</code></td>
<td>

<p>If assigned and <code>Rank = 1</code> then these are
the explicity optimums.
Recycled to length <code>S</code>.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_crow1positive">Crow1positive</code></td>
<td>

<p>See <code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_xmat">xmat</code></td>
<td>

<p>The
<code class="reqn">n</code> by  <code class="reqn">p-1</code>
environmental matrix can be inputted.
</p>
</td></tr>
<tr><td><code id="rcqo_+3A_scale.latvar">scale.latvar</code></td>
<td>

<p>Logical. If <code>FALSE</code> the argument
<code>sd.latvar</code> is ignored and no scaling of the latent variable
values is performed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates data coming from a
constrained quadratic
ordination (CQO) model. In particular,
data coming from a <em>species packing model</em>
can be generated
with this function.
The species packing model states that species have equal
tolerances, equal maximums, and optimums which are uniformly
distributed over the latent variable space. This can be
achieved by assigning the arguments <code>es.optimums = TRUE</code>,
<code>eq.maximums = TRUE</code>, <code>eq.tolerances = TRUE</code>.
</p>
<p>At present, the Poisson and negative binomial abundances
are generated first using <code>lo.abundance</code> and
<code>hi.abundance</code>, and if <code>family</code> is binomial or ordinal
then it is converted into these forms.
</p>
<p>In CQO theory the <code class="reqn">n</code> by <code class="reqn">p</code> matrix <code class="reqn">X</code> is
partitioned into two parts <code class="reqn">X_1</code> and <code class="reqn">X_2</code>. The matrix
<code class="reqn">X_2</code> contains the &lsquo;real&rsquo; environmental variables whereas
the variables in <code class="reqn">X_1</code> are just for adjustment purposes;
they contain the intercept terms and other variables that one
wants to adjust for when (primarily) looking at the variables
in <code class="reqn">X_2</code>.  This function has <code class="reqn">X_1</code> only being a matrix
of ones, i.e., containing an intercept only.
</p>


<h3>Value</h3>

<p>A <code class="reqn">n</code> by <code class="reqn">p-1+S</code> data frame with
components and attributes.
In the following the attributes are labelled with double
quotes.
</p>
<table>
<tr><td><code>x2</code>, <code>x3</code>, <code>x4</code>, <code>...</code>, <code>xp</code></td>
<td>

<p>The environmental variables. This makes up the
<code class="reqn">n</code> by <code class="reqn">p-1</code> <code class="reqn">X_2</code> matrix.
Note that <code>x1</code> is not present; it is effectively a
vector of ones since it corresponds to an intercept term when
<code><a href="#topic+cqo">cqo</a></code> is applied to the data.
</p>
</td></tr>
<tr><td><code>y1</code>, <code>y2</code>, <code>x3</code>, <code>...</code>, <code>yS</code></td>
<td>

<p>The species data. This makes up the
<code class="reqn">n</code> by <code class="reqn">S</code> matrix <code class="reqn">Y</code>.
This will be of the form described by the argument
<code>family</code>.
</p>
</td></tr>
<tr><td><code>"concoefficients"</code></td>
<td>

<p>The <code class="reqn">p-1</code> by <code class="reqn">R</code> matrix of
constrained coefficients
(or canonical coefficients).
These are also known as weights or loadings.
</p>
</td></tr>
<tr><td><code>"formula"</code></td>
<td>

<p>The formula involving the species and environmental
variable names.
This can be used directly in the <code>formula</code> argument
of <code><a href="#topic+cqo">cqo</a></code>.
</p>
</td></tr>
<tr><td><code>"log.maximums"</code></td>
<td>

<p>The <code class="reqn">S</code>-vector of species' maximums, on a log scale.
These are uniformly distributed between
<code>log(lo.abundance)</code> and <code>log(hi.abundance)</code>.
</p>
</td></tr>
<tr><td><code>"latvar"</code></td>
<td>

<p>The <code class="reqn">n</code> by <code class="reqn">R</code> matrix of site scores.
Each successive column (latent variable) has
sample standard deviation
equal to successive values of <code>sd.latvar</code>.
</p>
</td></tr>
<tr><td><code>"eta"</code></td>
<td>

<p>The linear/additive predictor value.
</p>
</td></tr>
<tr><td><code>"optimums"</code></td>
<td>

<p>The <code class="reqn">S</code> by <code class="reqn">R</code> matrix of species' optimums.
</p>
</td></tr>
<tr><td><code>"tolerances"</code></td>
<td>

<p>The <code class="reqn">S</code> by <code class="reqn">R</code> matrix of species' tolerances.
These are the square root of the diagonal elements of the
tolerance matrices (recall that all tolerance matrices are
restricted to being diagonal in this function).
</p>
</td></tr>
</table>
<p>Other attributes are <code>"break"</code>,
<code>"family"</code>, <code>"Rank"</code>,
<code>"lo.abundance"</code>, <code>"hi.abundance"</code>,
<code>"eq.tolerances"</code>, <code>"eq.maximums"</code>,
<code>"seed"</code> as used.
</p>


<h3>Note</h3>

<p>This function is under development and is not finished yet.
There may be a few bugs.
</p>
<p>Yet to do: add an argument that allows absences to be equal
to the first level if ordinal data is requested.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>
<p>ter Braak, C. J. F. and Prentice, I. C. (1988).
A theory of gradient analysis.
<em>Advances in Ecological Research</em>,
<b>18</b>, 271&ndash;317.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+qrrvglm.control">qrrvglm.control</a></code>,
<code><a href="base.html#topic+cut">cut</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Species packing model:
n &lt;- 100; p &lt;- 5; S &lt;- 5
mydata &lt;- rcqo(n, p, S, es.opt = TRUE, eq.max = TRUE)
names(mydata)
(myform &lt;- attr(mydata, "formula"))
fit &lt;- cqo(myform, poissonff, mydata, Bestof = 3)  # eq.tol = TRUE
matplot(attr(mydata, "latvar"), mydata[,-(1:(p-1))], col = 1:S)
persp(fit, col = 1:S, add = TRUE)
lvplot(fit, lcol = 1:S, y = TRUE, pcol = 1:S)  # Same plot as above

# Compare the fitted model with the 'truth'
concoef(fit)  # The fitted model
attr(mydata, "concoefficients")  # The 'truth'

c(apply(attr(mydata, "latvar"), 2, sd),
  apply(latvar(fit), 2, sd))  # Both values should be approx equal


# Example 2: negative binomial data fitted using a Poisson model:
n &lt;- 200; p &lt;- 5; S &lt;- 5
mydata &lt;- rcqo(n, p, S, fam = "negbin", sqrt = TRUE)
myform &lt;- attr(mydata, "formula")
fit &lt;- cqo(myform, fam = poissonff, dat = mydata)  # I.tol = TRUE,
lvplot(fit, lcol = 1:S, y = TRUE, pcol = 1:S)
# Compare the fitted model with the 'truth'
concoef(fit)  # The fitted model
attr(mydata, "concoefficients")  # The 'truth'

## End(Not run)
</code></pre>

<hr>
<h2 id='rdiric'> The Dirichlet distribution </h2><span id='topic+rdiric'></span>

<h3>Description</h3>

<p>Generates Dirichlet random variates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdiric(n, shape, dimension = NULL, is.matrix.shape = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rdiric_+3A_n">n</code></td>
<td>
<p> number of observations.
Note it has two meanings, see <code>is.matrix.shape</code> below.
</p>
</td></tr>
<tr><td><code id="rdiric_+3A_shape">shape</code></td>
<td>

<p>the shape parameters. These must be positive.
If <code>dimension</code> is specifed, values
are recycled if necessary to length <code>dimension</code>.
</p>
</td></tr>
<tr><td><code id="rdiric_+3A_dimension">dimension</code></td>
<td>

<p>the dimension of the distribution.
If <code>dimension</code> is not numeric then it is taken to be
<code>length(shape)</code>
(or <code>ncol(shape)</code> if <code>is.matrix.shape == TRUE</code>).
</p>
</td></tr>
<tr><td><code id="rdiric_+3A_is.matrix.shape">is.matrix.shape</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then <code>shape</code> must be a matrix, and then
<code>n</code> is no longer the number of rows of the answer but the
answer has <code>n * nrow(shape)</code> rows.
If <code>FALSE</code> (the default) then <code>shape</code> is a vector and each
of the <code>n</code> rows of the answer have <code>shape</code> as
its shape parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is based on a relationship between the gamma and
Dirichlet distribution. Random gamma variates are generated, and
then Dirichlet random variates are formed from these.
</p>


<h3>Value</h3>

<p>A <code>n</code> by <code>dimension</code> matrix of Dirichlet random variates.
Each element is positive, and each row will sum to unity.
If <code>shape</code> has names then these will become the column names
of the answer.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Lange, K. (2002).
<em>Mathematical and Statistical Methods for Genetic Analysis</em>,
2nd ed.
New York: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dirichlet">dirichlet</a></code> is a <span class="pkg">VGAM</span> family function for
fitting a Dirichlet distribution to data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ddata &lt;- data.frame(rdiric(n = 1000, shape = c(y1 = 3, y2 = 1, y3 = 4)))
fit &lt;- vglm(cbind(y1, y2, y3) ~ 1, dirichlet, data = ddata, trace = TRUE)
Coef(fit)
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='rec.exp1'> Upper Record Values from a 1-parameter
Exponential Distribution </h2><span id='topic+rec.exp1'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the rate parameter of a
1-parameter exponential distribution when the
observations are upper
record values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rec.exp1(lrate = "loglink", irate = NULL, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rec.exp1_+3A_lrate">lrate</code></td>
<td>

<p>Link function applied to the rate parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="rec.exp1_+3A_irate">irate</code></td>
<td>

<p>Numeric. Optional initial values for the rate.
The default value <code>NULL</code> means they are
computed internally,
with the help of <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="rec.exp1_+3A_imethod">imethod</code></td>
<td>

<p>Integer, either 1 or 2 or 3. Initial method,
three algorithms are
implemented. Choose the another value if
convergence fails, or use
<code>irate</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response must be a vector or one-column matrix
with strictly increasing values.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>By default, this family function has the intercept-only
MLE as the
initial value, therefore convergence may only take
one iteration.
Fisher scoring is used.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Arnold, B. C. and Balakrishnan, N. and
Nagaraja, H. N. (1998).
<em>Records</em>,
New York: John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exponential">exponential</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rawy &lt;- rexp(n &lt;- 10000, rate = exp(1))
y &lt;- unique(cummax(rawy))  # Keep only the records

length(y) / y[length(y)]   # MLE of rate

fit &lt;- vglm(y ~ 1, rec.exp1, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='rec.normal'> Upper Record Values from a Univariate Normal Distribution </h2><span id='topic+rec.normal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the two parameters of a
univariate normal distribution when the observations are upper
record values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rec.normal(lmean = "identitylink", lsd = "loglink",
          imean = NULL, isd = NULL, imethod = 1, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rec.normal_+3A_lmean">lmean</code>, <code id="rec.normal_+3A_lsd">lsd</code></td>
<td>

<p>Link functions applied to the mean and sd parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="rec.normal_+3A_imean">imean</code>, <code id="rec.normal_+3A_isd">isd</code></td>
<td>

<p>Numeric. Optional initial values for the mean and sd.
The default value <code>NULL</code> means they are
computed internally,
with the help of <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="rec.normal_+3A_imethod">imethod</code></td>
<td>

<p>Integer, either 1 or 2 or 3. Initial method,
three algorithms are
implemented. Choose the another value if
convergence fails, or use
<code>imean</code> and/or <code>isd</code>.
</p>
</td></tr>
<tr><td><code id="rec.normal_+3A_zero">zero</code></td>
<td>

<p>Can be an integer vector, containing the value 1 or 2.
If so, the mean or
standard deviation respectively are modelled as an
intercept only.
Usually, setting <code>zero = 2</code> will be used, if used at all.
The default value <code>NULL</code> means both
linear/additive predictors
are modelled as functions of the explanatory variables.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response must be a vector or one-column matrix
with strictly
increasing values.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This family function tries to solve a difficult problem,
and the larger the data set the better.
Convergence failure can commonly occur, and
convergence may be very slow,
so set <code>maxit = 200, trace = TRUE</code>, say.
Inputting good initial values are advised.
</p>
<p>This family function uses the BFGS quasi-Newton update
formula for the
working weight matrices.  Consequently the estimated
variance-covariance matrix may be inaccurate or
simply wrong! The
standard errors must be therefore treated with caution;
these are
computed in functions such as <code>vcov()</code>
and <code>summary()</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Arnold, B. C. and Balakrishnan, N. and
Nagaraja, H. N. (1998).
<em>Records</em>,
New York: John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+double.cens.normal">double.cens.normal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 10000; mymean &lt;- 100
# First value is reference value or trivial record
Rdata &lt;- data.frame(rawy = c(mymean, rnorm(nn, mymean, exp(3))))
# Keep only observations that are records:
rdata &lt;- data.frame(y = unique(cummax(with(Rdata, rawy))))

fit &lt;- vglm(y ~ 1, rec.normal, rdata, trace = TRUE, maxit = 200)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='reciprocallink'> Reciprocal Link Function </h2><span id='topic+reciprocallink'></span><span id='topic+negreciprocallink'></span>

<h3>Description</h3>

<p>Computes the reciprocal transformation, including its inverse
and the first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   reciprocallink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
                  short = TRUE, tag = FALSE)
negreciprocallink(theta, bvalue = NULL, inverse = FALSE, deriv = 0,
                  short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reciprocallink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="reciprocallink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="reciprocallink_+3A_inverse">inverse</code>, <code id="reciprocallink_+3A_deriv">deriv</code>, <code id="reciprocallink_+3A_short">short</code>, <code id="reciprocallink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>reciprocallink</code> link function
is a special case of the power link function.
Numerical values of <code>theta</code> close to 0 result in
<code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>
<p>The <code>negreciprocallink</code> link function computes
the negative reciprocal, i.e., <code class="reqn">-1/ \theta</code>.
</p>


<h3>Value</h3>

<p>For <code>reciprocallink</code>:
for <code>deriv = 0</code>, the reciprocal of <code>theta</code>, i.e.,
<code>1/theta</code> when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then
<code>1/theta</code>.
For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>theta</code> / <em>d</em> <code>eta</code>
as a function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>


<h3>Note</h3>

<p> Numerical instability may occur when <code>theta</code> is
close to 0.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>, 2nd ed.
London: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+identitylink">identitylink</a></code>,
<code><a href="#topic+powerlink">powerlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   reciprocallink(1:5)
   reciprocallink(1:5, inverse = TRUE, deriv = 2)
negreciprocallink(1:5)
negreciprocallink(1:5, inverse = TRUE, deriv = 2)

x &lt;- (-3):3
reciprocallink(x)  # Has Inf
reciprocallink(x, bvalue = .Machine$double.eps)  # Has no Inf
</code></pre>

<hr>
<h2 id='residualsvglm'>Residuals for a VGLM fit</h2><span id='topic+residualsvglm'></span>

<h3>Description</h3>

<p>Residuals for a vector generalized linear model (VGLM)
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residualsvglm(object, type = c("working", "pearson", "response",
   "deviance", "ldot", "stdres", "rquantile"), matrix.arg = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residualsvglm_+3A_object">object</code></td>
<td>

<p>Object of class <code>"vglm"</code>,
i.e., a <code><a href="#topic+vglm">vglm</a></code> fit.
</p>
</td></tr>
<tr><td><code id="residualsvglm_+3A_type">type</code></td>
<td>

<p>The value of this argument can be abbreviated.
The type of residuals to be returned.
The default is the first one: working residuals
corresponding to
the IRLS algorithm. These are defined for all models.
They are sometimes added to VGAM plots of estimated
component functions (see <code><a href="#topic+plotvgam">plotvgam</a></code>).
</p>
<p>Pearson residuals for GLMs, when squared and summed over the
data set, total to the Pearson chi-squared statistic.
For VGLMs, Pearson residuals involve the working weight
matrices and the score vectors. Under certain limiting
conditions, Pearson residuals have 0 means and identity
matrix as the variance-covariance matrix.
</p>
<p>Response residuals are simply the difference between
the observed values and the fitted values. Both have
to be of the same dimension, hence not all families have
response residuals defined.
</p>
<p>Deviance residuals are only defined for models with
a deviance function. They tend to GLMs mainly.
This function returns a <code>NULL</code> for those models
whose deviance is undefined.
</p>
<p>Randomized quantile residuals (RQRs)
(Dunn and Smyth, 1996)
are based on
the <code>p</code>-type function being fed into
<code><a href="stats.html#topic+qnorm">qnorm</a></code>.
For example, for the default <code><a href="#topic+exponential">exponential</a></code>
it is <code>qnorm(pexp(y, rate = 1 / fitted(object)))</code>.
So one should expect these residuals to have a
standard normal distribution if the model and data agree well.
If the distribution is discrete then <em>randomized</em>
values are returned; see
<code><a href="stats.html#topic+runif">runif</a></code> and
<code><a href="base.html#topic+set.seed">set.seed</a></code>.
For example, for the default <code><a href="#topic+poissonff">poissonff</a></code>
it is
<code>qnorm(runif(length(y), ppois(y - 1, mu), ppois(y, mu)))</code>
where <code>mu</code> is the fitted mean.
The following excerpts comes from their writings.
They highly recommend quantile residuals for
discrete distributions
since plots
using deviance and Pearson residuals may contain
distracting patterns.
Four replications of the quantile residuals are recommended
with discrete distributions because they
have a random component.
Any features not preserved across all four sets
of residuals are considered artifacts of the randomization.
This type of residual is continuous even for
discrete distributions;
for both discrete and continuous distributions,
the quantile residuals have an exact standard normal
distribution.
</p>








<p>The choice <code>"ldot"</code> should not be used currently.
</p>
<p>Standardized residuals are currently
only defined for 2 types of models:
(i) GLMs
(<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>);
(ii) those fitted
to a two-way table of counts, e.g.,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+cratio">cratio</a></code>.
For (ii),
they are defined in Section 2.4.5 of Agresti (2018)
and are also the output from the <code>"stdres"</code> component
of <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>.
For the test of independence
they are a useful type of residual.
Their formula is
<code>(observed - expected) / sqrt(V)</code>, where <code>V</code> is
the residual cell variance
(also see Agresti, 2007, section 2.4.5).
When an independence null hypothesis is true, each
standardized residual (corresponding to a cell in the table)
has a a large-sample standard normal distribution.
Currently this function merely extracts the table of counts
from <code>object</code>
and then computes the standardized residuals like 
<code><a href="stats.html#topic+chisq.test">chisq.test</a></code>.
</p>





</td></tr>
<tr><td><code id="residualsvglm_+3A_matrix.arg">matrix.arg</code></td>
<td>

<p>Logical, which applies when if the pre-processed
answer is a vector or a 1-column matrix.
If <code>TRUE</code> then the
value returned will be a matrix, else a vector.
</p>

</td></tr>


</table>


<h3>Details</h3>

<p>This function returns various kinds of residuals,
sometimes depending on the specific type of
model having been fitted.
Section 3.7 of Yee (2015) gives some details on
several types of residuals defined for the VGLM class.
</p>
<p>Standardized residuals for GLMs are described in
Section 4.5.6 of Agresti (2013) as the ratio of
the raw (response) residuals divided by their
standard error.
They involve the generalized hat matrix evaluated
at the final IRLS iteration.
When applied to the LM,
standardized residuals for GLMs simplify to
<code><a href="stats.html#topic+rstandard">rstandard</a></code>.
For GLMs they are basically 
the Pearson residual divided by the square root of 1 minus the 
leverage.
</p>






<h3>Value</h3>

<p>If that residual type is undefined or inappropriate
or not yet implemented,
then <code>NULL</code> is returned,
otherwise a matrix or vector of residuals is returned.
</p>


<h3>Warning </h3>

<p>This function may change in the future, especially
those whose definitions may change.
</p>


<h3>References</h3>

<p>Agresti, A. (2007).
<em>An Introduction to Categorical Data Analysis, 2nd ed.</em>,
New York: John Wiley &amp; Sons.
Page 38.
</p>
<p>Agresti, A. (2013).
<em>Categorical Data Analysis, 3rd ed.</em>,
New York: John Wiley &amp; Sons.
</p>
<p>Agresti, A. (2018).
<em>An Introduction to Categorical Data Analysis, 3rd ed.</em>,
New York: John Wiley &amp; Sons.
</p>
<p>Dunn, P. K. and Smyth, G. K. (1996).
Randomized quantile residuals.
<em>Journal of Computational and Graphical Statistics</em>,
<b>5</b>, 236&ndash;244.
</p>



<h3>See Also</h3>

<p><code><a href="stats.html#topic+resid">resid</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="stats.html#topic+chisq.test">chisq.test</a></code>,
<code><a href="#topic+hatvalues">hatvalues</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo)
resid(fit)  # Same as having type = "working" (the default)
resid(fit, type = "response")
resid(fit, type = "pearson")
resid(fit, type = "stdres")  # Test for independence
</code></pre>

<hr>
<h2 id='rhobitlink'> Rhobit Link Function </h2><span id='topic+rhobitlink'></span>

<h3>Description</h3>

<p>Computes the rhobit link transformation, including its inverse
and the first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhobitlink(theta, bminvalue = NULL, bmaxvalue = NULL,
           inverse = FALSE, deriv = 0, short = TRUE, tag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rhobitlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="rhobitlink_+3A_bminvalue">bminvalue</code>, <code id="rhobitlink_+3A_bmaxvalue">bmaxvalue</code></td>
<td>

<p>Optional boundary values, e.g.,
values of <code>theta</code> which are less than or equal to -1 can be
replaced by <code>bminvalue</code>
before computing the link function value.
And values of <code>theta</code> which are greater than or equal to
1 can be replaced by <code>bmaxvalue</code> before computing the link
function value.  See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="rhobitlink_+3A_inverse">inverse</code>, <code id="rhobitlink_+3A_deriv">deriv</code>, <code id="rhobitlink_+3A_short">short</code>, <code id="rhobitlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rhobitlink</code> link function is commonly used for
parameters that lie between <code class="reqn">-1</code> and <code class="reqn">1</code>.  Numerical
values of <code>theta</code> close to <code class="reqn">-1</code> or <code class="reqn">1</code> or out of
range result in <code>Inf</code>, <code>-Inf</code>, <code>NA</code> or <code>NaN</code>.
</p>


<h3>Value</h3>

<p>For <code>deriv = 0</code>, the rhobit of <code>theta</code>, i.e.,
<code>log((1 + theta)/(1 - theta))</code> when <code>inverse =
  FALSE</code>, and if <code>inverse = TRUE</code> then <code>(exp(theta) -
  1)/(exp(theta) + 1)</code>.
</p>
<p>For <code>deriv = 1</code>, then the function
returns <em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a
function of <code>theta</code> if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it returns the reciprocal.
</p>


<h3>Note</h3>

<p>Numerical instability may occur when <code>theta</code> is close
to <code class="reqn">-1</code> or <code class="reqn">1</code>.  One way of overcoming this is to
use <code>bminvalue</code>, etc.
</p>
<p>The correlation parameter of a standard bivariate normal
distribution lies between <code class="reqn">-1</code> and <code class="reqn">1</code>, therefore this
function can be used for modelling this parameter as a function
of explanatory variables.
</p>
<p>The link function <code>rhobitlink</code> is very similar to
<code><a href="#topic+fisherzlink">fisherzlink</a></code>, e.g., just twice the value of
<code><a href="#topic+fisherzlink">fisherzlink</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+binom2.rho">binom2.rho</a></code>,
<code><a href="#topic+fisherz">fisherz</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>theta &lt;- seq(-0.99, 0.99, by = 0.01)
y &lt;- rhobitlink(theta)
## Not run: 
plot(theta, y, type = "l", ylab = "", main = "rhobitlink(theta)")
abline(v = 0, h = 0, lty = 2)

## End(Not run)

x &lt;- c(seq(-1.02, -0.98, by = 0.01), seq(0.97, 1.02, by = 0.01))
rhobitlink(x)  # Has NAs
rhobitlink(x, bminvalue = -1 + .Machine$double.eps,
              bmaxvalue =  1 - .Machine$double.eps)  # Has no NAs
</code></pre>

<hr>
<h2 id='Rice'>The Rice Distribution</h2><span id='topic+Rice'></span><span id='topic+drice'></span><span id='topic+price'></span><span id='topic+qrice'></span><span id='topic+rrice'></span>

<h3>Description</h3>

<p>Density,
distribution function, quantile function
and random generation for the
Rician distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drice(x, sigma, vee, log = FALSE)
price(q, sigma, vee, lower.tail = TRUE, log.p = FALSE, ...)
qrice(p, sigma, vee, lower.tail = TRUE, log.p = FALSE, ...)
rrice(n, sigma, vee)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rice_+3A_x">x</code>, <code id="Rice_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Rice_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Rice_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as in <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Rice_+3A_vee">vee</code>, <code id="Rice_+3A_sigma">sigma</code></td>
<td>

<p>See <code><a href="#topic+riceff">riceff</a></code>.
</p>
</td></tr>
<tr><td><code id="Rice_+3A_...">...</code></td>
<td>

<p>Other arguments such as
<code>lower.tail</code>.
</p>
</td></tr>
<tr><td><code id="Rice_+3A_lower.tail">lower.tail</code>, <code id="Rice_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Rice_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the
density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+riceff">riceff</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the two parameters,
for the formula of the probability density function
and other details.
</p>
<p>Formulas for <code>price()</code> and <code>qrice()</code> are
based on the Marcum-Q function.
</p>


<h3>Value</h3>

<p><code>drice</code> gives the density,
<code>price</code> gives the distribution function,
<code>qrice</code> gives the quantile function, and
<code>rrice</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+riceff">riceff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  x &lt;- seq(0.01, 7, len = 201)
plot(x, drice(x, vee = 0, sigma = 1), type = "n", las = 1,
     ylab = "",
     main = "Density of Rice distribution for various v values")
sigma &lt;- 1; vee &lt;- c(0, 0.5, 1, 2, 4)
for (ii in 1:length(vee))
  lines(x, drice(x, vee = vee[ii], sigma), col = ii)
legend(x = 5, y = 0.6, legend = as.character(vee),
       col = 1:length(vee), lty = 1)

x &lt;- seq(0, 4, by = 0.01); vee &lt;- 1; sigma &lt;- 1
probs &lt;- seq(0.05, 0.95, by = 0.05)
plot(x, drice(x, vee = vee, sigma = sigma), type = "l",
     main = "Blue is density, orange is CDF", col = "blue",
     ylim = c(0, 1), sub = "Red are 5, 10, ..., 95 percentiles",
     las = 1, ylab = "", cex.main = 0.9)
abline(h = 0:1, col = "black", lty = 2)
Q &lt;- qrice(probs, sigma, vee = vee)
lines(Q, drice(qrice(probs, sigma, vee = vee),
               sigma, vee = vee), col = "red", lty = 3, type = "h")
lines(x, price(x, sigma, vee = vee), type = "l", col = "orange")
lines(Q, drice(Q, sigma, vee = vee), col = "red", lty = 3, type = "h")
lines(Q, price(Q, sigma, vee = vee), col = "red", lty = 3, type = "h")
abline(h = probs, col = "red", lty = 3)
max(abs(price(Q, sigma, vee = vee) - probs))  # Should be 0

## End(Not run)
</code></pre>

<hr>
<h2 id='riceff'>Rice Distribution Family Function</h2><span id='topic+riceff'></span>

<h3>Description</h3>

<p>Estimates the two parameters of a Rice distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riceff(lsigma = "loglink", lvee = "loglink", isigma = NULL,
       ivee = NULL, nsimEIM = 100, zero = NULL, nowarning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riceff_+3A_nowarning">nowarning</code></td>
<td>
<p> Logical. Suppress a warning?
Ignored for <span class="pkg">VGAM</span> 0.9-7 and higher.
</p>
</td></tr>
<tr><td><code id="riceff_+3A_lvee">lvee</code>, <code id="riceff_+3A_lsigma">lsigma</code></td>
<td>

<p>Link functions for the <code class="reqn">v</code> and <code class="reqn">\sigma</code>
parameters.  See <code><a href="#topic+Links">Links</a></code> for more choices and for
general information.
</p>
</td></tr>
<tr><td><code id="riceff_+3A_ivee">ivee</code>, <code id="riceff_+3A_isigma">isigma</code></td>
<td>

<p>Optional initial values for the parameters.
If convergence failure occurs (this <span class="pkg">VGAM</span> family function
seems to require good initial values) try using these arguments.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="riceff_+3A_nsimeim">nsimEIM</code>, <code id="riceff_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Rician distribution has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;v,\sigma) =
  \frac{y}{\sigma^2} \, \exp(-(y^2+v^2) / (2\sigma^2)) \,
           I_0(y v / \sigma^2)
  </code>
</p>

<p>where <code class="reqn">y &gt; 0</code>,
<code class="reqn">v &gt; 0</code>,
<code class="reqn">\sigma &gt; 0</code> and <code class="reqn">I_0</code> is the
modified Bessel function of the
first kind with order zero.
When <code class="reqn">v = 0</code> the Rice distribution reduces to a Rayleigh
distribution.
The mean is
<code class="reqn">\sigma \sqrt{\pi/2} \exp(z/2)
       ((1-z) I_0(-z/2)-z I_1(-z/2))</code>
(returned as the fitted values) where
<code class="reqn">z=-v^2/(2 \sigma^2)</code>.
Simulated Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Convergence problems may occur for data where <code class="reqn">v=0</code>;
if so, use <code><a href="#topic+rayleigh">rayleigh</a></code> or possibly use an
<code><a href="base.html#topic+identity">identity</a></code> link.
</p>
<p>When <code class="reqn">v</code> is large (greater than 3, say) then the mean is
approximately <code class="reqn">v</code> and the standard deviation
is approximately
<code class="reqn">\sigma</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Rice, S. O. (1945).
Mathematical Analysis of Random Noise.
<em>Bell System Technical Journal</em>,
<b>24</b>, 46&ndash;156.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+drice">drice</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="base.html#topic+Bessel">besselI</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  sigma &lt;- exp(1); vee &lt;- exp(2)
rdata &lt;- data.frame(y = rrice(n &lt;- 1000, sigma, vee = vee))
fit &lt;- vglm(y ~ 1, riceff, data = rdata, trace = TRUE, crit = "c")
c(with(rdata, mean(y)), fitted(fit)[1])
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='rigff'> Reciprocal Inverse Gaussian distribution </h2><span id='topic+rigff'></span>

<h3>Description</h3>

<p>Estimation of the parameters of a
reciprocal inverse Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rigff(lmu = "identitylink", llambda = "loglink", imu = NULL,
      ilambda = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rigff_+3A_lmu">lmu</code>, <code id="rigff_+3A_llambda">llambda</code></td>
<td>

<p>Link functions  for <code>mu</code> and <code>lambda</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="rigff_+3A_imu">imu</code>, <code id="rigff_+3A_ilambda">ilambda</code></td>
<td>

<p>Initial values for <code>mu</code> and <code>lambda</code>.
A <code>NULL</code> means a value is computed internally.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Jorgensen (1997) for details.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This distribution is potentially useful for
dispersion modelling.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Jorgensen, B. (1997).
<em>The Theory of Dispersion Models</em>.
London: Chapman &amp; Hall
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simplex">simplex</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rdata &lt;- data.frame(y = rchisq(100, df = 14))  # Not 'proper' data!!
fit &lt;- vglm(y ~ 1, rigff, rdata, trace = TRUE)
fit &lt;- vglm(y ~ 1, rigff, rdata, trace = TRUE, crit = "c")
summary(fit)
</code></pre>

<hr>
<h2 id='rlplot.gevff'> Return Level Plot for GEV Fits </h2><span id='topic+rlplot.gevff'></span><span id='topic+rlplot.gev'></span>

<h3>Description</h3>

<p>A return level plot is constructed for a GEV-type model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlplot.gevff(object, show.plot = TRUE,
    probability = c((1:9)/100, (1:9)/10, 0.95, 0.99, 0.995, 0.999),
    add.arg = FALSE, xlab = if(log.arg) "Return Period (log-scale)" else
    "Return Period", ylab = "Return Level",
    main = "Return Level Plot",
    pch = par()$pch, pcol.arg = par()$col, pcex = par()$cex,
    llty.arg = par()$lty, lcol.arg = par()$col, llwd.arg = par()$lwd,
    slty.arg = par()$lty, scol.arg = par()$col, slwd.arg = par()$lwd,
    ylim = NULL, log.arg = TRUE, CI = TRUE, epsilon = 1e-05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlplot.gevff_+3A_object">object</code></td>
<td>

<p>A <span class="pkg">VGAM</span> extremes model of the
GEV-type, produced by <code><a href="#topic+vglm">vglm</a></code>
with a family function either
<code>"gev"</code> or <code>"gevff"</code>.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_show.plot">show.plot</code></td>
<td>

<p>Logical. Plot it? If <code>FALSE</code> no plot will be done.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_probability">probability</code></td>
<td>

<p>Numeric vector of probabilities used.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_add.arg">add.arg</code></td>
<td>
<p> Logical. Add the plot to an existing plot? </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_xlab">xlab</code></td>
<td>
<p> Caption for the x-axis. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_ylab">ylab</code></td>
<td>
<p> Caption for the y-axis. See <code><a href="graphics.html#topic+par">par</a></code>.  </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_main">main</code></td>
<td>
<p> Title of the plot. See <code><a href="graphics.html#topic+title">title</a></code>. </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_pch">pch</code></td>
<td>
<p> Plotting character. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_pcol.arg">pcol.arg</code></td>
<td>
<p> Color of the points.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.  </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_pcex">pcex</code></td>
<td>
<p> Character expansion of the points.
See the <code>cex</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_llty.arg">llty.arg</code></td>
<td>
<p> Line type. Line type.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_lcol.arg">lcol.arg</code></td>
<td>
<p> Color of the lines.
See the <code>col</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_llwd.arg">llwd.arg</code></td>
<td>
<p> Line width.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_slty.arg">slty.arg</code>, <code id="rlplot.gevff_+3A_scol.arg">scol.arg</code>, <code id="rlplot.gevff_+3A_slwd.arg">slwd.arg</code></td>
<td>

<p>Correponding arguments for the lines used for the
confidence intervals. Used only if <code>CI=TRUE</code>.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_ylim">ylim</code></td>
<td>
<p> Limits for the y-axis. Numeric of length 2. </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_log.arg">log.arg</code></td>
<td>
<p> Logical. If <code>TRUE</code> then <code>log=""</code> otherwise
<code>log="x"</code>. This changes the labelling of the x-axis only.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_ci">CI</code></td>
<td>
<p> Logical. Add in a 95 percent confidence interval? </p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_epsilon">epsilon</code></td>
<td>

<p>Numeric, close to zero. Used for the finite-difference
approximation to the first derivatives with respect to
each parameter. If too small, numerical problems will occur.
</p>
</td></tr>
<tr><td><code id="rlplot.gevff_+3A_...">...</code></td>
<td>

<p>Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>sub</code> and <code>las</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A return level plot plots <code class="reqn">z_p</code> versus
<code class="reqn">\log(y_p)</code>.
It is linear if the shape parameter <code class="reqn">\xi=0</code>.
If <code class="reqn">\xi&lt;0</code> then the plot is convex
with asymptotic limit as <code class="reqn">p</code> approaches zero at
<code class="reqn">\mu-\sigma / \xi</code>.
And if <code class="reqn">\xi&gt;0</code> then the plot is concave and has
no finite bound.
Here, <code class="reqn">G(z_p) = 1-p</code> where <code class="reqn">0&lt;p&lt;1</code>
(<code class="reqn">p</code> corresponds to the argument <code>probability</code>)
and <code class="reqn">G</code> is the cumulative distribution function of the
GEV distribution. The quantity <code class="reqn">z_p</code> is known as the
<em>return level</em> associated with the <em>return period</em>
<code class="reqn">1/p</code>. For many applications, this means <code class="reqn">z_p</code>
is exceeded by the annual
maximum in any particular year with probability <code class="reqn">p</code>.
</p>
<p>The points in the plot are the actual data.
</p>


<h3>Value</h3>

<p>In the <code>post</code> slot of the object is a list called
<code>rlplot</code> with list components
</p>
<table>
<tr><td><code>yp</code></td>
<td>
<p><code>-log(probability)</code>, which is used on the x-axis. </p>
</td></tr>
<tr><td><code>zp</code></td>
<td>
<p>values which are used for the y-axis</p>
</td></tr>
<tr><td><code>lower</code>, <code>upper</code></td>
<td>
<p>lower and upper confidence limits for the
95 percent  confidence intervals evaluated at the values of
<code>probability</code> (if <code>CI=TRUE</code>). </p>
</td></tr>
</table>


<h3>Note</h3>

<p>The confidence intervals are approximate, being
based on finite-difference approximations to derivatives.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Coles, S. (2001).
<em>An Introduction to Statistical Modeling of Extreme Values</em>.
London: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gevff">gevff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(y = rgev(n &lt;- 100, scale = 2, shape = -0.1))
fit &lt;- vglm(y ~ 1, gevff, data = gdata, trace = TRUE)

# Identity link for all parameters:
fit2 &lt;- vglm(y ~ 1, gevff(lshape = identitylink, lscale = identitylink,
                          iscale = 10), data = gdata, trace = TRUE)
coef(fit2, matrix = TRUE)
## Not run: 
par(mfrow = c(1, 2))
rlplot(fit) -&gt; i1
rlplot(fit2, pcol = "darkorange", lcol = "blue", log.arg = FALSE,
       scol = "darkgreen", slty = "dashed", las = 1) -&gt; i2
range(i2@post$rlplot$upper - i1@post$rlplot$upper)  # Should be near 0
range(i2@post$rlplot$lower - i1@post$rlplot$lower)  # Should be near 0

## End(Not run)
</code></pre>

<hr>
<h2 id='rootogram4'>
Rootograms (S4 generic)
for Assessing Goodness of Fit of Probability Models
</h2><span id='topic+rootogram4'></span><span id='topic+rootogram4vglm'></span>

<h3>Description</h3>

<p>A graphical technique for comparing the observed and
fitted counts from a probability model, on a
square root scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rootogram4(object, ...)
rootogram4vglm(object, newdata = NULL, breaks = NULL, max = NULL,
               xlab = NULL, main = NULL, width = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rootogram4_+3A_object">object</code></td>
<td>

<p>an object of class <code>"vglm"</code>.
zz This includes <code>"vgam"</code> because
<code>"vlm"</code> handles both VGLM and VGAM objects.
</p>


</td></tr>
<tr><td><code id="rootogram4_+3A_newdata">newdata</code></td>
<td>
<p> Data upon which to base the calculations.
The default is the one used to fit the model.
</p>
</td></tr>
<tr><td><code id="rootogram4_+3A_breaks">breaks</code></td>
<td>
<p>numeric. Breaks for the histogram intervals.</p>
</td></tr>
<tr><td><code id="rootogram4_+3A_max">max</code></td>
<td>
<p>maximum count displayed.
If an error message occurs regarding running out of memory
then use this argument; it might occur with a very long
tailed distribution such as <code><a href="#topic+gaitdzeta">gaitdzeta</a></code>.
</p>
</td></tr>
<tr><td><code id="rootogram4_+3A_xlab">xlab</code>, <code id="rootogram4_+3A_main">main</code></td>
<td>
<p>graphical parameters.</p>
</td></tr>
<tr><td><code id="rootogram4_+3A_width">width</code></td>
<td>
<p>numeric. Widths of the histogram bars.</p>
</td></tr>


<tr><td><code id="rootogram4_+3A_...">...</code></td>
<td>

<p>any additional arguments to
<code>rootogram.default</code> and
<code>plot.rootogram</code> in <span class="pkg">countreg</span>.
Probably the most useful of these are
<code>style = c("hanging", "standing", "suspended")</code>
and
<code>scale = c("sqrt", "raw")</code>.
</p>



</td></tr>
</table>


<h3>Details</h3>

<p>Rootograms are a useful graphical technique for
comparing the observed counts with the expected
counts given a probability model.
</p>

<p>This S4 implementation is based very heavily
on <code>rootogram</code> coming from
<span class="pkg">countreg</span>. This package is primarily written by
A. Zeileis and
C. Kleiber.
That package is currently on R-Forge but not CRAN, and
it is based on S3.
Since <span class="pkg">VGAM</span> is written using S4, it was necessary
to define an S4 generic function called
<code>rootogram4()</code> which dispatches appropriately for
S4 objects.
</p>






<p>Currently, only a selected number of <span class="pkg">VGAM</span>
family functions
are implemented. Over time, hopefully more and more will be
completed.
</p>


<h3>Value</h3>

<p>See
<code>rootogram</code> in <span class="pkg">countreg</span>;
an object of class <code>"rootogram0"</code>
inheriting from <code>"data.frame"</code> with
about 8 variables.
</p>



<h3>Warning</h3>

<p>This function is rudimentary and based totally
on the implementation in <span class="pkg">countreg</span>.
</p>



<h3>Note</h3>

<p>The function names used coming from <span class="pkg">countreg</span> have
been renamed slightly to avoid conflict.
</p>



<h3>Author(s)</h3>

<p>Package <span class="pkg">countreg</span> is primarily written by
A. Zeileis and
C. Kleiber.
Function <code>rootogram4()</code> is based very heavily
on <span class="pkg">countreg</span>.
T. W. Yee wrote code to unpack variables from
many various models
and feed them into the appropriate <code>d</code>-type function.
</p>









<h3>References</h3>

<p>Friendly, M. and Meyer, D. (2016).
<em>Discrete Data Analysis with R: Visualization and
Modeling Techniques for Categorical and Count Data</em>,
Boca Raton, FL, USA: Chapman &amp; Hall/CRC Press.
</p>
<p>Kleiber, C. and Zeileis, A. (2016)
&ldquo;Visualizing Count Data Regressions Using Rootograms.&rdquo; 
<em>The American Statistician</em>,
<b>70</b>(3), 296&ndash;303.
<a href="https://doi.org/10.1080/00031305.2016.1173590">doi:10.1080/00031305.2016.1173590</a>.
</p>
<p>Tukey, J. W. (1977)
<em>Exploratory Data Analysis</em>,
Reading, MA, USA: Addison-Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="stats.html#topic+glm">glm</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+zapoisson">zapoisson</a></code>,
<code>rootogram</code> in <span class="pkg">countreg</span>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data("hspider", package = "VGAM")  # Count responses
hs.p   &lt;- vglm(Pardlugu ~ CoveHerb,   poissonff, data = hspider)
hs.nb  &lt;- vglm(Pardlugu ~ CoveHerb, negbinomial, data = hspider)
hs.zip &lt;- vglm(Pardlugu ~ CoveHerb,   zipoisson, data = hspider)
hs.zap &lt;- vglm(Pardlugu ~ CoveHerb,   zapoisson, data = hspider)

opar &lt;- par(mfrow = c(2, 2))  # Plot the rootograms
rootogram4(hs.p,   max = 15, main = "poissonff")
rootogram4(hs.nb,  max = 15, main = "negbinomial")
rootogram4(hs.zip, max = 15, main = "zipoisson")
rootogram4(hs.zap, max = 15, main = "zapoisson")
par(opar)

## End(Not run)
</code></pre>

<hr>
<h2 id='round2'> Rounding of Numbers to Base 2 </h2><span id='topic+round2'></span>

<h3>Description</h3>

<p>'round2' works like 'round' 
but the rounding has base 2 under consideration so that bits
(binary digits)
beyond a certain theshold are zeroed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>round2(x, digits10 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="round2_+3A_x">x</code></td>
<td>

<p>Same as <code><a href="base.html#topic+round">round</a></code>.
</p>
</td></tr>
<tr><td><code id="round2_+3A_digits10">digits10</code></td>
<td>

<p>Same as <code>digits</code> in <code><a href="base.html#topic+round">round</a></code>.
The <code>"10"</code> is to emphasize the usual base 10
used by humans.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>round2()</code> is intended to allow reliable and safe for
<code>==</code> comparisons provided both sides have the function
applied to the same value of <code>digits10</code>.  Internally a
numeric has its binary representation (bits)
past a certain point
set to all 0s, while retaining a certain degree of accuracy.
Algorithmically, <code>x</code> is multiplied by <code>2^exponent</code>
and then rounded, and then divided by <code>2^exponent</code>.
The value of <code>exponent</code> is approximately <code>3 *
  digits10</code> when <code>digits10</code> is positive.  If <code>digits10</code>
is negative then what is returned is <code>round(x, digits10)</code>.
The value of <code>exponent</code> guarantees that <code>x</code> has been
rounded to at least <code>digits10</code> decimal places (often around
<code>digits10 + 1</code> for safety).
</p>


<h3>Value</h3>

<p>Something similar to <code><a href="base.html#topic+round">round</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee. </p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+round">round</a></code>,
<code><a href="#topic+tobit">tobit</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1); x &lt;- sort(rcauchy(10))
x3 &lt;- round2(x, 3)
x3 == round2(x, 3)  # Supposed to be reliable (all TRUE)
rbind(x, x3)  # Comparison
(x3[1]  * 2^(0:9)) / 2^(0:9)
print((x3[1]  * 2^(0:11)), digits = 14)

# Round to approx 1 d.p.
x1 &lt;- round2(x, 1)
x1 == round2(x, 1)  # Supposed to be reliable (all TRUE)
rbind(x, x1)
x1[8] == 0.75  # 3/4
print((x1[1]  * 2^(0:11)), digits = 9)
seq(31) / 32
</code></pre>

<hr>
<h2 id='rrar'> Nested Reduced-rank Autoregressive Models for Multiple
Time Series </h2><span id='topic+rrar'></span>

<h3>Description</h3>

<p>Estimates the parameters of a
nested reduced-rank autoregressive model for multiple
time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrar(Ranks = 1, coefstart = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrar_+3A_ranks">Ranks</code></td>
<td>

<p>Vector of integers: the ranks of the model.
Each value must be at least one and no more than <code>M</code>,
where <code>M</code> is the number of response variables in the
time series.  The length of <code>Ranks</code> is the <em>lag</em>,
which is often denoted by the symbol <em>L</em> in the literature.
</p>
</td></tr>
<tr><td><code id="rrar_+3A_coefstart">coefstart</code></td>
<td>

<p>Optional numerical vector of initial values for the coefficients.
By default, the family function chooses these automatically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Full details are given in Ahn and Reinsel (1988).
Convergence may be very slow, so setting <code>maxits = 50</code>,
say, may help.  If convergence is not obtained, you might like
to try inputting different initial values.
</p>
<p>Setting <code>trace = TRUE</code> in <code><a href="#topic+vglm">vglm</a></code> is useful
for monitoring the progress at each iteration.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This family function should be used within <code><a href="#topic+vglm">vglm</a></code>
and not with <code><a href="#topic+rrvglm">rrvglm</a></code> because it does not fit into
the RR-VGLM framework exactly. Instead, the reduced-rank model
is formulated as a VGLM!
</p>
<p>A methods function <code>Coef.rrar</code>, say, has yet to be written.
It would return the quantities
<code>Ak1</code>,
<code>C</code>,
<code>D</code>,
<code>omegahat</code>,
<code>Phi</code>,
etc. as slots, and then <code>show.Coef.rrar</code> would also need
to be written.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Ahn, S. and Reinsel, G. C. (1988).
Nested reduced-rank autoregressive models for multiple
time series.
<em>Journal of the American Statistical Association</em>,
<b>83</b>, 849&ndash;856.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+grain.us">grain.us</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
year &lt;- seq(1961 + 1/12, 1972 + 10/12, by = 1/12)
par(mar = c(4, 4, 2, 2) + 0.1, mfrow = c(2, 2))
for (ii in 1:4) {
  plot(year, grain.us[, ii], main = names(grain.us)[ii], las = 1,
       type = "l", xlab = "", ylab = "", col = "blue")
  points(year, grain.us[, ii], pch = "*", col = "blue")
}
apply(grain.us, 2, mean)  # mu vector
cgrain &lt;- scale(grain.us, scale = FALSE)  # Center the time series only
fit &lt;- vglm(cgrain ~ 1, rrar(Ranks = c(4, 1)), trace = TRUE)
summary(fit)

print(fit@misc$Ak1, digits = 2)
print(fit@misc$Cmatrices, digits = 3)
print(fit@misc$Dmatrices, digits = 3)
print(fit@misc$omegahat, digits = 3)
print(fit@misc$Phimatrices, digits = 2)

par(mar = c(4, 4, 2, 2) + 0.1, mfrow = c(4, 1))
for (ii in 1:4) {
  plot(year, fit@misc$Z[, ii], main = paste("Z", ii, sep = ""),
       type = "l", xlab = "", ylab = "", las = 1, col = "blue")
  points(year, fit@misc$Z[, ii], pch = "*", col = "blue")
}

## End(Not run)
</code></pre>

<hr>
<h2 id='rrvglm'>Fitting Reduced-Rank Vector Generalized Linear Models
(RR-VGLMs)
and Doubly Constrained RR-VGLMs (DRR-VGLMs)
</h2><span id='topic+rrvglm'></span>

<h3>Description</h3>

<p>A <em>reduced-rank vector generalized linear model</em> (RR-VGLM)
is fitted.  RR-VGLMs are VGLMs but some of the constraint
matrices are estimated.
<em>Doubly constrained</em> RR-VGLMs (DRR-VGLMs)
can also be fitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrvglm(formula, family = stop("'family' is unassigned"),
       data = list(), weights = NULL, subset = NULL,
       na.action = na.fail, etastart = NULL, mustart = NULL,
       coefstart = NULL, control = rrvglm.control(...),
       offset = NULL, method = "rrvglm.fit", model = FALSE,
       x.arg = TRUE, y.arg = TRUE, contrasts = NULL,
       constraints = NULL, extra = NULL, qr.arg = FALSE,
       smart = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrvglm_+3A_formula">formula</code>, <code id="rrvglm_+3A_family">family</code>, <code id="rrvglm_+3A_weights">weights</code></td>
<td>

<p>See <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the
variables in the model.
By default the variables are taken from
<code>environment(formula)</code>, typically
the environment from
which <code>rrvglm</code> is called.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_subset">subset</code>, <code id="rrvglm_+3A_na.action">na.action</code></td>
<td>

<p>See <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_etastart">etastart</code>, <code id="rrvglm_+3A_mustart">mustart</code>, <code id="rrvglm_+3A_coefstart">coefstart</code></td>
<td>

<p>See <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_control">control</code></td>
<td>

<p>a list of parameters for controlling
the fitting process.
See <code><a href="#topic+rrvglm.control">rrvglm.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_offset">offset</code>, <code id="rrvglm_+3A_model">model</code>, <code id="rrvglm_+3A_contrasts">contrasts</code></td>
<td>

<p>See <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_method">method</code></td>
<td>

<p>the method to be used in fitting the model.
The default (and presently only)
method <code>rrvglm.fit</code>
uses iteratively reweighted least squares (IRLS).
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_x.arg">x.arg</code>, <code id="rrvglm_+3A_y.arg">y.arg</code></td>
<td>

<p>logical values indicating whether the model matrix
and response vector/matrix used in the fitting
process should be assigned in the <code>x</code> and <code>y</code> slots.
Note the model matrix is the LM model matrix; to get the VGLM
model matrix type <code>model.matrix(vglmfit)</code> where
<code>vglmfit</code> is a <code>vglm</code> object.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_constraints">constraints</code></td>
<td>

<p>See <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_extra">extra</code>, <code id="rrvglm_+3A_smart">smart</code>, <code id="rrvglm_+3A_qr.arg">qr.arg</code></td>
<td>

<p>See <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="rrvglm_+3A_...">...</code></td>
<td>

<p>further arguments passed into <code><a href="#topic+rrvglm.control">rrvglm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this documentation, <code class="reqn">M</code> is the
number of linear predictors.
For RR-VGLMs,
the central formula is given by
</p>
<p style="text-align: center;"><code class="reqn">\eta = B_1^T x_1 + A \nu</code>
</p>

<p>where <code class="reqn">x_1</code> is a vector
(usually just a 1 for an intercept),
<code class="reqn">x_2</code> is another vector of explanatory variables, and
<code class="reqn">\nu = C^T x_2</code> is an <code class="reqn">R</code>-vector of
latent variables.
Here, <code class="reqn">\eta</code> is a vector of linear predictors,
e.g., the <code class="reqn">m</code>th element is
<code class="reqn">\eta_m = \log(E[Y_m])</code> for the
<code class="reqn">m</code>th Poisson response.
The dimension of <code class="reqn">\eta</code> is <code class="reqn">M</code> by
definition.
The matrices <code class="reqn">B_1</code>, <code class="reqn">A</code> and
<code class="reqn">C</code> are estimated from the data, i.e., contain the
regression coefficients.  For ecologists, the central
formula represents a <em>constrained linear ordination</em>
(CLO) since it is linear in the latent variables. It
means that the response is a monotonically increasing or
decreasing function of the latent variables.
</p>
<p>For identifiability
it is common to enforce <em>corner constraints</em> on <code class="reqn">A</code>:
by default, the top <code class="reqn">R</code> by <code class="reqn">R</code> submatrix is fixed to
be the order-<code class="reqn">R</code> identity matrix and the remainder of <code class="reqn">A</code>
is estimated.
</p>
<p>The underlying algorithm of RR-VGLMs is iteratively
reweighted least squares (IRLS) with an optimizing
algorithm applied within each IRLS iteration (e.g.,
alternating algorithm).
</p>
<p>In theory, any <span class="pkg">VGAM</span> family function that works for
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code> should work
for <code>rrvglm</code> too.
The function that actually does the work is <code>rrvglm.fit</code>;
it is <code>vglm.fit</code> with some extra code.
</p>


<h3>Value</h3>

<p>An object of class <code>"rrvglm"</code>, which has the the same
slots as a <code>"vglm"</code> object. The only difference is
that the some of the constraint matrices are estimates
rather than known. But <span class="pkg">VGAM</span> stores the models the
same internally. The slots of <code>"vglm"</code> objects are
described in <code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>


<h3>Note</h3>

<p>The arguments of <code>rrvglm</code> are in general the same
as those of <code><a href="#topic+vglm">vglm</a></code> but with some extras in
<code><a href="#topic+rrvglm.control">rrvglm.control</a></code>.
</p>
<p>The smart prediction (<code><a href="#topic+smartpred">smartpred</a></code>) library
is packed with the <span class="pkg">VGAM</span> library.
</p>
<p>In an example below, a rank-1 <em>stereotype</em>
(reduced-rank multinomial logit)
model of Anderson (1984) is fitted to some car data.
The reduced-rank regression is performed, adjusting for
two covariates. Setting a trivial constraint matrix
(<code>diag(M)</code>)
for the latent variable variables in <code class="reqn">x_2</code> avoids
a warning message when it is overwritten by a (common)
estimated constraint matrix.  It shows that German cars
tend to be more expensive than American cars, given a
car of fixed weight and width.
</p>
<p>If <code>fit &lt;- rrvglm(..., data = mydata)</code> then
<code>summary(fit)</code> requires corner constraints and no
missing values in <code>mydata</code>.  Often the estimated
variance-covariance matrix of the parameters is not
positive-definite; if this occurs, try refitting the
model with a different value for <code>Index.corner</code>.
</p>
<p>For <em>constrained quadratic ordination</em> (CQO) see
<code><a href="#topic+cqo">cqo</a></code> for more details about QRR-VGLMs.
</p>
<p>With multiple binary responses, one must use
<code>binomialff(multiple.responses = TRUE)</code> to indicate
that the response is a matrix with one response per column.
Otherwise, it is interpreted as a single binary response
variable.
</p>
<p>To fit DRR-VGLMs see the arguments <code>H.A</code> and
<code>H.C</code> in <code><a href="#topic+rrvglm.control">rrvglm.control</a></code>.
DRR-VGLMs provide structure to the <b>A</b> and
<b>C</b> matrices via constraint matrices.
So instead of them being general unstructured
matrices, one can make many of their elements to
have the same value, else be identically equal
to 0, for example. This gives greater control
over what is modelled as a latent variable,
e.g., if one subset of the covariates are physical
variables and the remainder are psychological
variables then a rank-2 model might have each
latent variable a linear combination of each
of the types of variables separately.
</p>

<p>Incidentally,
before I forget, if <code>Corner = TRUE</code> then
the <code>@H.A</code> slot indicates that
the <code>Index.corner</code> rows of <b>A</b>
are estimated. This is a remnant of some
internal computations because it is
more efficient to estimate the entire
<b>A</b>, bar rows <code>str0</code>, and
then normalize it.
In contrast, optimizing over a subset of
<b>A</b> is slow.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Anderson, J. A. (1984).
Regression and ordered categorical variables.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>46</b>, 1&ndash;30.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models with
two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>
<p>Yee, T. W., Frigau, L. and Ma, C. (2024).
Heaping and seeping,
GAITD regression and
doubly constrained reduced rank vector
generalized linear models,
in smoking studies.
<em>In preparation</em>.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+rrvglm.control">rrvglm.control</a></code>,
<code><a href="#topic+summary.drrvglm">summary.drrvglm</a></code>,
<code><a href="#topic+lvplot.rrvglm">lvplot.rrvglm</a></code>
(same as <code><a href="#topic+biplot.rrvglm">biplot.rrvglm</a></code>),
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code>,
<code><a href="#topic+grc">grc</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>,
<code><a href="#topic+smartpred">smartpred</a></code>,
<code>rrvglm.fit</code>.
Special family functions include
<code><a href="#topic+negbinomial">negbinomial</a></code>
<code><a href="#topic+zipoisson">zipoisson</a></code>
and <code><a href="#topic+zinegbinomial">zinegbinomial</a></code>.
(see Yee (2014)
and what was formerly in <span class="pkg">COZIGAM</span>).
Methods functions include
<code><a href="#topic+Coef.rrvglm">Coef.rrvglm</a></code>,
<code><a href="#topic+calibrate.rrvglm">calibrate.rrvglm</a></code>,
etc.
Data include
<code><a href="#topic+crashi">crashi</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: RR NB with Var(Y) = mu + delta1 * mu^delta2
nn &lt;- 1000       # Number of observations
delta1 &lt;- 3.0    # Specify this
delta2 &lt;- 1.5    # Specify this; should be greater than 1
a21 &lt;- 2 - delta2
mydata &lt;- data.frame(x2 = runif(nn), x3 = runif(nn))
mydata &lt;- transform(mydata, mu = exp(2 + 3 * x2 + 0 * x3))
mydata &lt;- transform(mydata,
    y2 = rnbinom(nn, mu = mu, size = (1/delta1)*mu^a21))
plot(y2 ~ x2, mydata, pch = "+", col = 'blue', las = 1,
  main = paste0("Var(Y) = mu + ", delta1, " * mu^", delta2))
rrnb2 &lt;- rrvglm(y2 ~ x2 + x3, negbinomial(zero = NULL),
                data = mydata, trace = TRUE)

a21.hat &lt;- (Coef(rrnb2)@A)["loglink(size)", 1]
beta11.hat &lt;- Coef(rrnb2)@B1["(Intercept)", "loglink(mu)"]
beta21.hat &lt;- Coef(rrnb2)@B1["(Intercept)", "loglink(size)"]
(delta1.hat &lt;- exp(a21.hat * beta11.hat - beta21.hat))
(delta2.hat &lt;- 2 - a21.hat)
# delta1.hat:
# exp(a21.hat * predict(rrnb2)[1,1] - predict(rrnb2)[1,2])
summary(rrnb2)

# Obtain a 95 percent CI for delta2:
se.a21.hat &lt;- sqrt(vcov(rrnb2)["I(latvar.mat)", "I(latvar.mat)"])
ci.a21 &lt;- a21.hat +  c(-1, 1) * 1.96 * se.a21.hat
(ci.delta2 &lt;- 2 - rev(ci.a21))  # The 95 percent CI

Confint.rrnb(rrnb2)  # Quick way to get it

# Plot the abundances and fitted values vs the latent variable
plot(y2 ~ latvar(rrnb2), data = mydata, col = "blue",
     xlab = "Latent variable", las = 1)
ooo &lt;- order(latvar(rrnb2))
lines(fitted(rrnb2)[ooo] ~ latvar(rrnb2)[ooo], col = "red")

# Example 2: stereotype model (RR multinomial logit model)
data(car.all)
scar &lt;- subset(car.all,
    is.element(Country, c("Germany", "USA", "Japan", "Korea")))
fcols &lt;- c(13,14,18:20,22:26,29:31,33,34,36)  # These are factors
scar[, -fcols] &lt;- scale(scar[, -fcols])  # Stdze all numerical vars
ones &lt;- matrix(1, 3, 1)
clist &lt;- list("(Intercept)" = diag(3), Width = ones, Weight = ones,
              Disp. = diag(3), Tank = diag(3), Price = diag(3),
              Frt.Leg.Room = diag(3))
set.seed(111)
fit &lt;- rrvglm(Country ~ Width + Weight + Disp. + Tank +
              Price + Frt.Leg.Room,
              multinomial, data = scar, Rank = 2, trace = TRUE,
              constraints = clist, noRRR = ~ 1 + Width + Weight,
#             Uncor = TRUE, Corner = FALSE,  # orig.
              Index.corner = c(1, 3),  # Less correlation
              Bestof = 3)
fit@misc$deviance  # A history of the fits
Coef(fit)
biplot(fit, chull = TRUE, scores = TRUE, clty = 2, Ccex = 2,
       ccol = "blue", scol = "orange", Ccol = "darkgreen",
       Clwd = 2, main = "1=Germany, 2=Japan, 3=Korea, 4=USA")

## End(Not run)
</code></pre>

<hr>
<h2 id='rrvglm-class'>Class &ldquo;rrvglm&rdquo; </h2><span id='topic+rrvglm-class'></span>

<h3>Description</h3>

<p>Reduced-rank vector generalized linear models.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls to <code><a href="#topic+rrvglm">rrvglm</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>extra</code>:</dt><dd>
<p>Object of class <code>"list"</code>;
the <code>extra</code> argument on entry to <code>vglm</code>. This
contains any extra information that might be needed
by the family function.
</p>
</dd>
<dt><code>family</code>:</dt><dd>
<p>Object of class <code>"vglmff"</code>.
The family function.  </p>
</dd>
<dt><code>iter</code>:</dt><dd>
<p>Object of class <code>"numeric"</code>.
The number of IRLS iterations used.
</p>
</dd>
<dt><code>predictors</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>
with <code class="reqn">M</code> columns which holds the <code class="reqn">M</code> linear predictors.
</p>
</dd>
<dt><code>assign</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
This named list gives information matching the columns and the
(LM) model matrix terms.
</p>
</dd>
<dt><code>call</code>:</dt><dd>
<p>Object of class <code>"call"</code>, from class <code> "vlm"</code>.
The matched call.
</p>
</dd>
<dt><code>coefficients</code>:</dt><dd>
<p>Object of class
<code>"numeric"</code>, from class <code> "vlm"</code>.
A named vector of coefficients.
</p>
</dd>
<dt><code>constraints</code>:</dt><dd>
<p>Object of class <code>"list"</code>, from
class <code> "vlm"</code>.
A named list of constraint matrices used in the fitting.
</p>
</dd>
<dt><code>contrasts</code>:</dt><dd>
<p>Object of class <code>"list"</code>, from
class <code> "vlm"</code>.
The contrasts used (if any).
</p>
</dd>
<dt><code>control</code>:</dt><dd>
<p>Object of class <code>"list"</code>, from class
<code> "vlm"</code>.
A list of parameters for controlling the fitting process.
See <code><a href="#topic+vglm.control">vglm.control</a></code> for details.
</p>
</dd>
<dt><code>criterion</code>:</dt><dd>
<p>Object of class <code>"list"</code>, from
class <code> "vlm"</code>.
List of convergence criterion evaluated at the
final IRLS iteration.
</p>
</dd>
<dt><code>df.residual</code>:</dt><dd>
<p>Object of class
<code>"numeric"</code>, from class <code> "vlm"</code>.
The residual degrees of freedom.
</p>
</dd>
<dt><code>df.total</code>:</dt><dd>
<p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The total degrees of freedom.
</p>
</dd>
<dt><code>dispersion</code>:</dt><dd>
<p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The scaling parameter.
</p>
</dd>
<dt><code>effects</code>:</dt><dd>
<p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The effects.
</p>
</dd>
<dt><code>fitted.values</code>:</dt><dd>
<p>Object of class
<code>"matrix"</code>, from class <code> "vlm"</code>.
The fitted values. This is usually the mean but may be quantiles,
or the location parameter, e.g., in the Cauchy model.
</p>
</dd>
<dt><code>misc</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
A named list to hold miscellaneous parameters.
</p>
</dd>
<dt><code>model</code>:</dt><dd>
<p>Object of class <code>"data.frame"</code>,
from class <code> "vlm"</code>.
The model frame.
</p>
</dd>
<dt><code>na.action</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
A list holding information about missing values.
</p>
</dd>
<dt><code>offset</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
If non-zero, a <code class="reqn">M</code>-column matrix of offsets.
</p>
</dd>
<dt><code>post</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>
where post-analysis results may be put.
</p>
</dd>
<dt><code>preplot</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>
used by <code><a href="#topic+plotvgam">plotvgam</a></code>; the plotting parameters
may be put here.
</p>
</dd>
<dt><code>prior.weights</code>:</dt><dd>
<p>Object of class
<code>"matrix"</code>, from class <code> "vlm"</code>
holding the initially supplied weights.
</p>
</dd>
<dt><code>qr</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
QR decomposition at the final iteration.
</p>
</dd>
<dt><code>R</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The <b>R</b> matrix in the QR decomposition used in the fitting.
</p>
</dd>
<dt><code>rank</code>:</dt><dd>
<p>Object of class <code>"integer"</code>,
from class <code> "vlm"</code>.
Numerical rank of the fitted model.
</p>
</dd>
<dt><code>residuals</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The <em>working</em> residuals at the final IRLS iteration.
</p>
</dd>
<dt><code>ResSS</code>:</dt><dd>
<p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
Residual sum of squares at the final IRLS iteration with
the adjusted dependent vectors and weight matrices.
</p>
</dd>
<dt><code>smart.prediction</code>:</dt><dd>
<p>Object of class
<code>"list"</code>, from class <code> "vlm"</code>.
A list of data-dependent parameters (if any)
that are used by smart prediction.
</p>
</dd>
<dt><code>terms</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
The <code><a href="stats.html#topic+terms">terms</a></code> object used.
</p>
</dd>
<dt><code>weights</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The weight matrices at the final IRLS iteration.
This is in matrix-band form.
</p>
</dd>
<dt><code>x</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The model matrix (LM, not VGLM).
</p>
</dd>
<dt><code>xlevels</code>:</dt><dd>
<p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
The levels of the factors, if any, used in fitting.
</p>
</dd>
<dt><code>y</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The response, in matrix form.
</p>
</dd>
<dt><code>Xm2</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
See <code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>
</dd>
<dt><code>Ym2</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
See <code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>
</dd>
<dt><code>callXm2</code>:</dt><dd>
<p>Object of class <code>"call"</code>, from class <code> "vlm"</code>.
The matched call for argument <code>form2</code>.
</p>
</dd>
<dt><code>A.est</code>, <code>C.est</code>:</dt><dd>
<p>Object of class <code>"matrix"</code>.
The estimates of <b>A</b> and <b>C</b>.
</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"vglm"</code>, directly.
Class <code>"vlm"</code>, by class &quot;vglm&quot;.
</p>


<h3>Methods</h3>


<dl>
<dt>biplot</dt><dd><p><code>signature(x = "rrvglm")</code>: biplot. </p>
</dd>
<dt>Coef</dt><dd><p><code>signature(object = "rrvglm")</code>:
more detailed coefficients giving <b>A</b>,
<code class="reqn">\bold{B}_1</code>, <b>C</b>, etc.
</p>
</dd>
<dt>biplot</dt><dd><p><code>signature(object = "rrvglm")</code>:
biplot. </p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "rrvglm")</code>:
short summary of the object. </p>
</dd>
<dt>summary</dt><dd><p><code>signature(object = "rrvglm")</code>:
a more detailed summary of the object. </p>
</dd>
</dl>



<h3>Note</h3>

<p>Two new slots for <code>"rrvglm"</code>
were added compared
to <code>"vglm"</code> objects,
for <span class="pkg">VGAM</span> 1.1-10.
They are <code>A.est</code> and <code>C.est</code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>








<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+lvplot.rrvglm">lvplot.rrvglm</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Rank-1 stereotype model of Anderson (1984)
pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3  = runif(nrow(pneumo)))  # Noise
fit &lt;- rrvglm(cbind(normal, mild, severe) ~ let + x3,
              multinomial, data = pneumo, Rank = 1)
Coef(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='rrvglm.control'> Control Function for rrvglm() </h2><span id='topic+rrvglm.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for
running <code>rrvglm</code> are set using this
function.
Doubly constrained RR-VGLMs (DRR-VGLMs) are
also catered for.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrvglm.control(Rank = 1, Algorithm = "alternating",
    Corner = TRUE, Uncorrelated.latvar = FALSE, Wmat = NULL,
    Svd.arg = FALSE,
    Index.corner = head(setdiff(seq(length(str0) + Rank), str0), Rank),
    Ainit = NULL, Alpha = 0.5, Bestof = 1, Cinit = NULL,
    Etamat.colmax = 10, sd.Ainit = 0.02, sd.Cinit = 0.02,
    str0 = NULL, noRRR = ~1, Norrr = NA, noWarning = FALSE,
    trace = FALSE, Use.Init.Poisson.QO = FALSE,
    checkwz = TRUE, Check.rank = TRUE, Check.cm.rank = TRUE,
    wzepsilon = .Machine$double.eps^0.75,
    H.A.alt = list(), H.C = list(), scaleA = FALSE,
    Crow1positive = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrvglm.control_+3A_rank">Rank</code></td>
<td>

<p>The numerical rank <code class="reqn">R</code> of the
model.  Must be an element from the set
{1,2,...,min(<code class="reqn">M</code>,<em>p2</em>)}.
Here, the vector of explanatory
variables <b>x</b> is partitioned into
(<b>x1</b>,<b>x2</b>), which is of dimension
<em>p1</em>+<em>p2</em>.  The variables making
up <b>x1</b> are given by the terms in
<code>noRRR</code> argument, and the rest of the
terms comprise <b>x2</b>.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_algorithm">Algorithm</code></td>
<td>

<p>Character string indicating what algorithm is
to be used. The default is the first one.
The choice <code>"derivative"</code> has been
withdrawn in <span class="pkg">VGAM</span> 1.1-10.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_corner">Corner</code></td>
<td>

<p>Logical indicating whether corner
constraints are to be used. This is one
method for ensuring a unique solution.
If <code>TRUE</code>, <code>Index.corner</code>
specifies the <code class="reqn">R</code> rows of the
constraint matrices that are use as the
corner constraints, i.e., they hold an
order-<code class="reqn">R</code> identity matrix.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_uncorrelated.latvar">Uncorrelated.latvar</code></td>
<td>

<p>Logical indicating whether uncorrelated
latent variables are to be used.  This is
normalization forces the variance-covariance
matrix of the latent variables to be
<code>diag(Rank)</code>, i.e., unit variance and
uncorrelated. This constraint does not lead to
a unique solution because it can be rotated.
<b>Update during 2023/2024:</b>
setting this argument to be <code>TRUE</code>
might not work anymore.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_wmat">Wmat</code></td>
<td>
<p> Yet to be done. </p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_svd.arg">Svd.arg</code></td>
<td>

<p>Logical indicating whether a singular value
decomposition of the outer product is to
computed.  This is another normalization
which ensures uniqueness.  See the argument
<code>Alpha</code> below.
<b>Update during 2023/2024:</b>
setting this argument to be <code>TRUE</code>
might not work anymore.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_index.corner">Index.corner</code></td>
<td>

<p>Specifies the <code class="reqn">R</code> rows of the
constraint matrices that are used for the
corner constraints, i.e., they hold an
order-<code class="reqn">R</code> identity matrix.
</p>

<p>For certain DRR-VGLMs one does not want
to have corner constraints
(e.g., <code><a href="#topic+CM.qnorm">CM.qnorm</a></code>)
so setting
(<code>scaleA = TRUE</code> and)
<code>Corner = FALSE</code> will achieve this.
Then arguments such as
<code>Index.corner</code> and
<code>str0</code>
will be ignored.
If there are structural zeros then they
should be built into the constraint matrices.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_alpha">Alpha</code></td>
<td>

<p>The exponent in the singular value
decomposition that is used in the first
part: if the SVD is
<code class="reqn">U D V^T</code> then the
first and second parts are
<code class="reqn">U D^{\alpha}</code>
and
<code class="reqn">D^{1-\alpha}  V^T</code>
respectively.
A value of 0.5 is &lsquo;symmetrical&rsquo;.
This argument is used only when
<code>Svd.arg=TRUE</code>.
<b>Update during 2023/2024:</b>
using this argument
might not work anymore.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_bestof">Bestof</code></td>
<td>

<p>Integer. The best of <code>Bestof</code>
models fitted is returned. This argument
helps guard against local solutions by
(hopefully) finding the global solution
from many fits. The argument works only
when the function generates its own initial
value for <b>C</b>, i.e., when <b>C</b>
is <em>not</em> passed in as initial values.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_ainit">Ainit</code>, <code id="rrvglm.control_+3A_cinit">Cinit</code></td>
<td>

<p>Initial <b>A</b> and <b>C</b> matrices which
may speed up convergence.  They must be of
the correct dimension.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_etamat.colmax">Etamat.colmax</code></td>
<td>

<p>Positive integer, no smaller than
<code>Rank</code>.  Controls the amount of
memory used by <code>.Init.Poisson.QO()</code>.
It is the maximum number of columns allowed
for the pseudo-response and its weights.
In general, the larger the value, the
better the initial value.  Used only if
<code>Use.Init.Poisson.QO=TRUE</code>.
</p>
</td></tr>





<tr><td><code id="rrvglm.control_+3A_str0">str0</code></td>
<td>

<p>Integer vector specifying which rows of the
estimated constraint matrices (<b>A</b>)
are to be all zeros.  These are called
<em>structural zeros</em>.  Must not have
any common value with <code>Index.corner</code>,
and be a subset of the vector <code>1:M</code>.
The default, <code>str0 = NULL</code>, means no
structural zero rows at all.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_sd.ainit">sd.Ainit</code>, <code id="rrvglm.control_+3A_sd.cinit">sd.Cinit</code></td>
<td>

<p>Standard deviation of the initial values
for the elements of <b>A</b> and <b>C</b>.
These are normally distributed with
mean zero.  This argument is used only if
<code>Use.Init.Poisson.QO = FALSE</code>.
</p>
</td></tr>

<tr><td><code id="rrvglm.control_+3A_norrr">noRRR</code></td>
<td>

<p>Formula giving terms that are <em>not</em>
to be included in the reduced-rank
regression.  That is, <code>noRRR</code>
specifes which explanatory variables
are in the <code class="reqn">x_1</code> vector of
<code><a href="#topic+rrvglm">rrvglm</a></code>, and the rest go into
<code class="reqn">x_2</code>.  The <code class="reqn">x_1</code> variables
constitute the <code class="reqn">\bold{B}_1</code>
matrix in Yee and Hastie (2003).  Those
<code class="reqn">x_2</code> variables which are subject
to the reduced-rank regression correspond
to the <code class="reqn">\bold{B}_2</code>
matrix.  Set <code>noRRR = NULL</code> for the
reduced-rank regression to be applied to
every explanatory variable including the
intercept.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_norrr">Norrr</code></td>
<td>

<p>Defunct. Please use <code>noRRR</code>.
Its use results in an error.
The argument may be removed soon.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_trace">trace</code></td>
<td>

<p>Logical indicating if output should be
produced for each iteration.
</p>



</td></tr>
<tr><td><code id="rrvglm.control_+3A_use.init.poisson.qo">Use.Init.Poisson.QO</code></td>
<td>

<p>Logical indicating whether the
<code>.Init.Poisson.QO()</code> should be used
to obtain initial values for the <b>C</b>.
The function uses a new method that can
work well if the data are Poisson counts
coming from an equal-tolerances QRR-VGLM
(CQO).  This option is less realistic for
RR-VGLMs compared to QRR-VGLMs.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_checkwz">checkwz</code></td>
<td>

<p>logical indicating whether the diagonal
elements of the working weight matrices
should be checked whether they are
sufficiently positive, i.e., greater than
<code>wzepsilon</code>. If not, any values less
than <code>wzepsilon</code> are replaced with
this value.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_nowarning">noWarning</code>, <code id="rrvglm.control_+3A_check.rank">Check.rank</code>, <code id="rrvglm.control_+3A_check.cm.rank">Check.cm.rank</code></td>
<td>

<p>Same as <code><a href="#topic+vglm.control">vglm.control</a></code>.
Ignored for <span class="pkg">VGAM</span> 0.9-7 and higher.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_wzepsilon">wzepsilon</code></td>
<td>

<p>Small positive number used to test whether
the diagonals of the working weight matrices
are sufficiently positive.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_h.a.alt">H.A.alt</code>, <code id="rrvglm.control_+3A_h.c">H.C</code></td>
<td>

<p>Lists.
DRR-VGLMs are <em>doubly constrained</em>
RR-VGLMs where <b>A</b> has
<code>Rank</code>
constraint matrices
(one for each column)
in a list called <code>H.A.alt</code>,
and <b>C</b> has a
constraint matrix for each row,
i.e., for each explanatory
variable making up it.
The class
<code>"drrvglm"</code> may arise for such models.
So <code>H.C</code>
should be a named list of <code class="reqn">p_2</code>
constraint matrices,
each one for a different row of <b>C</b>,
i.e., <code class="reqn">p_2</code> is the number of variables
making up the latent variable.
Note that if <code>H.C</code> has
<code><a href="base.html#topic+names">names</a></code> then
matching is done with that,
and the components of <code>H.C</code>
are reordered if they are not sorted
according to the terms in <code>formula</code>.
If they are not named, then
their <em>order</em> is used,
for example, <code>H.C[[1]]</code>
and <code>H.C[[2]]</code> are taken as
the constraint matrices for the first two
variables of the latent variable(s).
</p>





</td></tr>
<tr><td><code id="rrvglm.control_+3A_scalea">scaleA</code></td>
<td>

<p>Logical.
Another uniqueness constraint to obtain a
unique <b>A</b> and <b>C</b>.
If <code>H.A.alt</code> and/or <code>H.C</code> are inputted
then sometimes one wants to preserve the
structure in <b>A</b>,
e.g., <code><a href="#topic+CM.qnorm">CM.qnorm</a></code>.
Here, <code>A &lt;- scale(A, center = FALSE)</code>
so that only the columns are multiplicatively
scaled.
Note that the estimates of the elements of
<b>A</b> and <b>C</b> are unique, up to
their sign.
Also note that ideally the attributes
<code>attr(,"scaled:scale")</code> should
be unity upon convergence so that
if they differ substantially from that
then this suggests some misbehaviour
in convergence.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_crow1positive">Crow1positive</code></td>
<td>

<p>Logical vector of length <code>Rank</code>
(recycled if necessary): are
the elements of the first
row of <code class="reqn">C</code> positive? For example,
if <code>Rank</code> is 4, then
specifying <code>Crow1positive = c(FALSE,
      TRUE)</code> will force <code class="reqn">C[1,1]</code> and <code class="reqn">C[1,3]</code>
to be negative,
and <code class="reqn">C[1,2]</code> and <code class="reqn">C[1,4]</code> to be positive.
This argument therefore
allows the user to determine the direction
of the latent variables since they are
unique up to a sign.
This argument certainly works for RR-VGLMs
but may not be applicable to DRR-VGLMs because
the constraint matrices may control their
sign.
</p>
</td></tr>
<tr><td><code id="rrvglm.control_+3A_...">...</code></td>
<td>

<p>Variables in ... are passed into
<code><a href="#topic+vglm.control">vglm.control</a></code>.
If the derivative algorithm is used
then ... are also passed into
<code><a href="#topic+rrvglm.optim.control">rrvglm.optim.control</a></code>;
and if the alternating algorithm is
used then ... are also passed into
<code><a href="#topic+valt0.control">valt0.control</a></code>.
</p>
</td></tr>
</table>
<p>In the above, <code class="reqn">R</code> is the <code>Rank</code> and
<code class="reqn">M</code> is the number of linear predictors.
</p>


<h3>Details</h3>










<p><span class="pkg">VGAM</span> supports three normalizations
to ensure a unique solution. Of these,
only corner constraints will work with
<code>summary</code> of RR-VGLM objects.
<b>Update during late-2023/early-2024:</b>
with ongoing work implementing
the <code>"drrvglm"</code> class, there may
be disruption and changes to other
normalizations. However, corner
constraints should be fully supported
and have the greatest priority.
</p>


<h3>Value</h3>

<p>A list with components matching the input
names.  Some error checking is done, but
not much.
</p>


<h3>Note</h3>




<p>The arguments in this function begin with an
upper case letter to help avoid interference
with those of <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>
<p>In the example below a rank-1
<em>stereotype</em> model (Anderson, 1984)
is fitted. However, the intercepts ideally
should be sorted and that might now be
achieved using <code><a href="#topic+CM.symm0">CM.symm0</a></code>,
<code><a href="#topic+CM.equid">CM.equid</a></code>,
<code><a href="#topic+CM.qnorm">CM.qnorm</a></code>, etc.
Currently the intercepts are completely
unconstrained.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code>,
<code><a href="#topic+summary.drrvglm">summary.drrvglm</a></code>,
<code><a href="#topic+rrvglm.optim.control">rrvglm.optim.control</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vglm.control">vglm.control</a></code>,
<code><a href="#topic+TypicalVGAMfamilyFunction">TypicalVGAMfamilyFunction</a></code>,
<code><a href="#topic+CM.qnorm">CM.qnorm</a></code>,
<code><a href="#topic+cqo">cqo</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(111)
pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3 = runif(nrow(pneumo)))  # Unrelated
fit &lt;- rrvglm(cbind(normal, mild, severe) ~ let + x3,
              multinomial, pneumo, Rank = 1, Index.corner = 2)
constraints(fit)
vcov(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='rrvglm.optim.control'> Control Function for rrvglm() Calling optim() </h2><span id='topic+rrvglm.optim.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for running <code>optim</code>
within <code>rrvglm</code> are set using this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrvglm.optim.control(Fnscale = 1, Maxit = 100,
                     Switch.optimizer = 3, Abstol = -Inf,
                     Reltol = sqrt(.Machine$double.eps), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrvglm.optim.control_+3A_fnscale">Fnscale</code></td>
<td>
<p> Passed into <code>optim</code> as <code>fnscale</code>. </p>
</td></tr>
<tr><td><code id="rrvglm.optim.control_+3A_maxit">Maxit</code></td>
<td>
<p> Passed into <code>optim</code> as <code>maxit</code>. </p>
</td></tr>
<tr><td><code id="rrvglm.optim.control_+3A_switch.optimizer">Switch.optimizer</code></td>
<td>
<p> Iteration number when the &quot;Nelder-Mead&quot;
method of <code>optim</code> is switched to the quasi-Newton &quot;BFGS&quot;
method.  Assigning <code>Switch.optimizer</code> a negative number
means always BFGS, while assigning <code>Switch.optimizer</code>
a value greater than <code>maxits</code> means always use Nelder-Mead.
</p>
</td></tr>
<tr><td><code id="rrvglm.optim.control_+3A_abstol">Abstol</code></td>
<td>
<p> Passed into <code>optim</code> as <code>abstol</code>. </p>
</td></tr>
<tr><td><code id="rrvglm.optim.control_+3A_reltol">Reltol</code></td>
<td>
<p> Passed into <code>optim</code> as <code>reltol</code>. </p>
</td></tr>
<tr><td><code id="rrvglm.optim.control_+3A_...">...</code></td>
<td>
<p> Ignored. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="stats.html#topic+optim">optim</a></code> for more details.
</p>


<h3>Value</h3>

<p>A list with components equal to the arguments.
</p>


<h3>Note</h3>

<p>The transition between optimization methods may be
unstable, so users may have to vary the value of
<code>Switch.optimizer</code>.
</p>
<p>Practical experience with <code>Switch.optimizer</code> shows that
setting it to too large a value may lead to a local solution,
whereas setting it to a low value will obtain the global
solution.  It appears that, if BFGS kicks in too late when
the Nelder-Mead algorithm is starting to converge to a local
solution, then switching to BFGS will not be sufficient to
bypass convergence to that local solution.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+rrvglm.control">rrvglm.control</a></code>,
<code><a href="stats.html#topic+optim">optim</a></code>.
</p>

<hr>
<h2 id='ruge'>Rutherford-Geiger Polonium Data</h2><span id='topic+ruge'></span>

<h3>Description</h3>

<p>Decay counts of polonium  recorded by
Rutherford and Geiger (1910).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ruge)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>counts</dt><dd><p>a numeric vector, counts or frequencies</p>
</dd>
<dt>number</dt><dd><p>a numeric vector, the number of decays</p>
</dd>
</dl>



<h3>Details</h3>

<p>These are the radioactive decay counts of polonium
recorded by Rutherford and Geiger (1910)
representing the number of scintillations
in 2608 1/8 minute intervals.
For example, there were 57 frequencies
of zero counts.
The counts can be thought of as being approximately
Poisson distributed.
</p>


<h3>Source</h3>

<p>Rutherford, E. and Geiger, H. (1910)
The Probability Variations in the Distribution of
alpha Particles,
<em>Philosophical Magazine</em>,
<b>20</b>, 698&ndash;704.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambdahat &lt;- with(ruge, weighted.mean(number, w = counts))
(N &lt;- with(ruge, sum(counts)))
with(ruge, cbind(number, counts,
                 fitted = round(N * dpois(number, lambdahat))))
</code></pre>

<hr>
<h2 id='s'> Defining Smooths in VGAM Formulas </h2><span id='topic+s'></span>

<h3>Description</h3>

<p><code>s</code> is used in the definition of (vector) smooth terms within
<code>vgam</code> formulas.
This corresponds to 1st-generation VGAMs that use backfitting
for their estimation.
The effective degrees of freedom is prespecified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s(x, df = 4, spar = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s_+3A_x">x</code></td>
<td>

<p>covariate (abscissae) to be smoothed.
Note that <code>x</code> must be a <em>single</em> variable
and not a function of a variable.
For example, <code>s(x)</code> is fine but <code>s(log(x))</code> will fail.
In this case, let <code>logx &lt;- log(x)</code> (in the data frame),
say, and then use <code>s(logx)</code>.
At this stage bivariate smoothers (<code>x</code> would be a two-column matrix)
are not implemented.
</p>
</td></tr>
<tr><td><code id="s_+3A_df">df</code></td>
<td>

<p>numerical vector of length <code class="reqn">r</code>.
Effective degrees of freedom: must lie between 1 (linear fit)
and <code class="reqn">n</code> (interpolation).
Thus one could say that <code>df-1</code> is the
<em>effective nonlinear degrees of freedom</em> (ENDF) of the smooth.
Recycling of values will be used if <code>df</code> is not of length <code class="reqn">r</code>.
If <code>spar</code> is positive then this argument is ignored.
Thus <code>s()</code> means that the effective degrees of freedom is prespecified.
If it is known that the component function(s) are more wiggly
than usual then try increasing the value of this argument.
</p>
</td></tr>
<tr><td><code id="s_+3A_spar">spar</code></td>
<td>
<p> numerical vector of length <code class="reqn">r</code>.
Positive smoothing parameters (after scaling) .
Larger values mean more smoothing so that the solution approaches
a linear fit for that component function.
A zero value means that <code>df</code> is used.
Recycling of values will be used if <code>spar</code> is not of length
<code class="reqn">r</code>.
</p>
</td></tr>
<tr><td><code id="s_+3A_...">...</code></td>
<td>

<p>Ignored for now.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file <code class="reqn">M</code> is the number of additive predictors
and <code class="reqn">r</code> is the number of component functions to be
estimated (so that <code class="reqn">r</code> is an element from the set
{1,2,...,<code class="reqn">M</code>}).
Also, if <code class="reqn">n</code> is the number of <em>distinct</em> abscissae, then
<code>s</code> will fail if <code class="reqn">n &lt; 7</code>.
</p>
<p><code>s</code>, which is symbolic and does not perform any smoothing itself,
only handles a single covariate.
Note that <code>s</code> works in <code><a href="#topic+vgam">vgam</a></code> only.
It has no effect in <code><a href="#topic+vglm">vglm</a></code>
(actually, it is similar to the identity function <code><a href="base.html#topic+AsIs">I</a></code>
so that <code>s(x2)</code> is the same as <code>x2</code> in the LM model matrix).
It differs from the <code>s()</code> of the <span class="pkg">gam</span> package and
the <code><a href="mgcv.html#topic+s">s</a></code> of the <span class="pkg">mgcv</span> package;
they should not be mixed together.
Also, terms involving <code>s</code> should be simple additive terms, and not
involving interactions and nesting etc.
For example, <code>myfactor:s(x2)</code> is not a good idea.
</p>




<h3>Value</h3>

<p>A vector with attributes that are (only) used by <code>vgam</code>.
</p>


<h3>Note</h3>

<p>The vector cubic smoothing spline which <code>s()</code> represents is
computationally demanding for large <code class="reqn">M</code>.
The cost is approximately <code class="reqn">O(n M^3)</code> where <code class="reqn">n</code> is the
number of unique abscissae.
</p>
<p>Currently a bug relating to the use of <code>s()</code> is that
only constraint matrices whose columns are orthogonal are handled
correctly.  If any <code>s()</code> term has a constraint matrix that
does not satisfy this condition then a warning is issued.
See <code><a href="#topic+is.buggy">is.buggy</a></code> for more information.
</p>
<p>A more modern alternative to using
<code>s</code> with <code><a href="#topic+vgam">vgam</a></code> is to use
<code><a href="#topic+sm.os">sm.os</a></code> or
<code><a href="#topic+sm.ps">sm.ps</a></code>.
This does not require backfitting
and allows automatic smoothing parameter selection.
However, this alternative should only be used when the
sample size is reasonably large (<code class="reqn">&gt; 500</code>, say).
These are called Generation-2 VGAMs.
</p>
<p>Another alternative to using
<code>s</code> with <code><a href="#topic+vgam">vgam</a></code> is
<code><a href="splines.html#topic+bs">bs</a></code>
and/or <code><a href="splines.html#topic+ns">ns</a></code>
with <code><a href="#topic+vglm">vglm</a></code>.
The latter implements half-stepping, which is helpful if
convergence is difficult.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+is.buggy">is.buggy</a></code>,
<code><a href="#topic+sm.os">sm.os</a></code>,
<code><a href="#topic+sm.ps">sm.ps</a></code>,
<code><a href="#topic+vsmooth.spline">vsmooth.spline</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nonparametric logistic regression
fit1 &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, data = hunua)
## Not run:  plot(fit1, se = TRUE) 

# Bivariate logistic model with artificial data
nn &lt;- 300
bdata &lt;- data.frame(x1 = runif(nn), x2 = runif(nn))
bdata &lt;- transform(bdata,
    y1 = rbinom(nn, size = 1, prob = logitlink(sin(2 * x2), inverse = TRUE)),
    y2 = rbinom(nn, size = 1, prob = logitlink(sin(2 * x2), inverse = TRUE)))
fit2 &lt;- vgam(cbind(y1, y2) ~ x1 + s(x2, 3), trace = TRUE,
             binom2.or(exchangeable = TRUE), data = bdata)
coef(fit2, matrix = TRUE)  # Hard to interpret
## Not run:  plot(fit2, se = TRUE, which.term = 2, scol = "blue") 
</code></pre>

<hr>
<h2 id='sc.studentt2'> Scaled Student t Distribution with 2 df Family Function </h2><span id='topic+sc.studentt2'></span>

<h3>Description</h3>

<p>Estimates the location and scale parameters of
a scaled Student t distribution with 2 degrees of freedom,
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc.studentt2(percentile = 50, llocation = "identitylink",
    lscale = "loglink", ilocation = NULL, iscale = NULL,
    imethod = 1, zero = "scale")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc.studentt2_+3A_percentile">percentile</code></td>
<td>

<p>A numerical vector containing values between 0 and 100,
which are the quantiles and expectiles.
They will be returned as &lsquo;fitted values&rsquo;.
</p>
</td></tr>
<tr><td><code id="sc.studentt2_+3A_llocation">llocation</code>, <code id="sc.studentt2_+3A_lscale">lscale</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code> for more choices,
and <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="sc.studentt2_+3A_ilocation">ilocation</code>, <code id="sc.studentt2_+3A_iscale">iscale</code>, <code id="sc.studentt2_+3A_imethod">imethod</code>, <code id="sc.studentt2_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Koenker (1993) solved for the distribution whose quantiles are
equal to its expectiles.
Its canonical form has mean and mode at 0,
and has a heavy tail (in fact, its variance is infinite).
</p>

<p>The standard (&ldquo;canonical&rdquo;) form of this
distribution can be endowed with a location and scale parameter.
The standard form has a density
that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(z) = 2 / (4 + z^2)^{3/2}</code>
</p>

<p>for real <code class="reqn">y</code>.
Then <code class="reqn">z = (y-a)/b</code> for location and scale parameters
<code class="reqn">a</code> and <code class="reqn">b &gt; 0</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">a</code>.
By default, <code class="reqn">\eta_1=a)</code> and
<code class="reqn">\eta_2=\log(b)</code>.
The expectiles/quantiles corresponding to <code>percentile</code>
are returned as the fitted values;
in particular, <code>percentile = 50</code> corresponds to the mean
(0.5 expectile) and  median (0.5 quantile).
</p>
<p>Note that if <code class="reqn">Y</code> has a standard <code><a href="#topic+dsc.t2">dsc.t2</a></code>
then <code class="reqn">Y = \sqrt{2} T_2</code> where <code class="reqn">T_2</code>
has a Student-t distribution with 2 degrees of freedom.
The two parameters here can also be estimated using
<code><a href="#topic+studentt2">studentt2</a></code> by specifying <code>df = 2</code> and making
an adjustment for the scale parameter, however, this <span class="pkg">VGAM</span>
family function is more efficient since the EIM is known
(Fisher scoring is implemented.)
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Koenker, R. (1993).
When are expectiles percentiles? (solution)
<em>Econometric Theory</em>,
<b>9</b>, 526&ndash;527.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsc.t2">dsc.t2</a></code>,
<code><a href="#topic+studentt2">studentt2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123); nn &lt;- 1000
kdata &lt;- data.frame(x2 = sort(runif(nn)))
kdata &lt;- transform(kdata, mylocat = 1 + 3 * x2,
                          myscale = 1)
kdata &lt;- transform(kdata, y = rsc.t2(nn, loc = mylocat, scale = myscale))
fit  &lt;- vglm(y ~ x2, sc.studentt2(perc = c(1, 50, 99)), data = kdata)
fit2 &lt;- vglm(y ~ x2,    studentt2(df = 2), data = kdata)  # 'same' as fit

coef(fit, matrix = TRUE)
head(fitted(fit))
head(predict(fit))

# Nice plot of the results
## Not run:  plot(y ~ x2, data = kdata, col = "blue", las = 1,
     sub  = paste("n =", nn),
     main = "Fitted quantiles/expectiles using the sc.studentt2() distribution")
matplot(with(kdata, x2), fitted(fit), add = TRUE, type = "l", lwd = 3)
legend("bottomright", lty = 1:3, lwd = 3, legend = colnames(fitted(fit)),
       col = 1:3) 
## End(Not run)

fit@extra$percentile  # Sample quantiles
</code></pre>

<hr>
<h2 id='score.stat'> Rao's Score Test
Statistics Evaluated at the Null Values </h2><span id='topic+score.stat'></span><span id='topic+score.stat.vlm'></span>

<h3>Description</h3>

<p>Generic function that computes
Rao's score test statistics evaluated at the null values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score.stat(object, ...)
score.stat.vlm(object, values0 = 0, subset = NULL, omit1s = TRUE,
          all.out = FALSE, orig.SE = FALSE, iterate.SE = TRUE,
          iterate.score = TRUE, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.stat_+3A_object">object</code>, <code id="score.stat_+3A_values0">values0</code>, <code id="score.stat_+3A_subset">subset</code></td>
<td>

<p>Same as in <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="score.stat_+3A_omit1s">omit1s</code>, <code id="score.stat_+3A_all.out">all.out</code></td>
<td>

<p>Same as in <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="score.stat_+3A_orig.se">orig.SE</code>, <code id="score.stat_+3A_iterate.se">iterate.SE</code></td>
<td>

<p>Same as in <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="score.stat_+3A_iterate.score">iterate.score</code></td>
<td>

<p>Logical. The score vector is evaluated at one value of
<code>values0</code> and at other regression coefficient values.
These other values may be either the MLE obtained from the original
object (<code>FALSE</code>), else at values obtained by
further IRLS iterations&mdash;this argument enables that choice.
</p>
</td></tr>
<tr><td><code id="score.stat_+3A_trace">trace</code></td>
<td>

<p>Same as in <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="score.stat_+3A_...">...</code></td>
<td>

<p>Ignored for now.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (Rao) <em>score test</em>
(also known as the <em>Lagrange multiplier test</em> in econometrics)
is a third general method for
hypothesis testing under a likelihood-based framework
(the others are the likelihood ratio test and
Wald test; see <code><a href="#topic+lrt.stat">lrt.stat</a></code> and
<code><a href="#topic+wald.stat">wald.stat</a></code>).
Asymptotically, the three tests are equivalent.
The Wald test is not invariant to parameterization, and
the usual Wald test statistics computed at the estimates
make it vulnerable to the Hauck-Donner effect
(HDE; see <code><a href="#topic+hdeff">hdeff</a></code>).
This function is similar to <code><a href="#topic+wald.stat">wald.stat</a></code> in that
one coefficient is set to 0 (by default) and the <em>other</em>
coefficients are iterated by IRLS to get their MLE subject to this
constraint.
The SE is almost always based on the expected information matrix
(EIM) rather than the OIM, and for some models
the EIM and OIM coincide.
</p>




<h3>Value</h3>

<p>By default the
signed square root of the
Rao score statistics are returned.
If <code>all.out = TRUE</code> then a list is returned with the
following components:
<code>score.stat</code> the score statistic,
<code>SE0</code> the standard error of that coefficient,
<code>values0</code> the null values.
Approximately, the default score statistics output are
standard normal random variates if each null hypothesis is true.
</p>
<p>Altogether,
by the eight combinations of <code>iterate.SE</code>, <code>iterate.score</code>
and <code>orig.SE</code>,
there are six different variants of the Rao score statistic
that can be returned because the score vector has 2 and
the SEs have 3 subvariants.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+wald.stat">wald.stat</a></code>,
<code><a href="#topic+lrt.stat">lrt.stat</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="stats.html#topic+summary.glm">summary.glm</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3 = rnorm(nrow(pneumo)))
(pfit &lt;- vglm(cbind(normal, mild, severe) ~ let + x3, propodds, pneumo))
score.stat(pfit)  # No HDE here; should be similar to the next line:
coef(summary(pfit))[, "z value"]  # Wald statistics computed at the MLE
summary(pfit, score0 = TRUE)
</code></pre>

<hr>
<h2 id='seglines'> Hauck-Donner Effects: Segmented Lines Plot </h2><span id='topic+seglines'></span>

<h3>Description</h3>

<p>Plots the piecewise segmented curve made up of
Wald statistics versus estimates,
using a colour code for the HDE severity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seglines(x, y, dy, ddy, lwd = 2, cex = 2, plot.it = TRUE,
   add.legend = TRUE, cex.legend = 1,
   position.legend = "topleft", eta0 = NA, COPS0 = NA,
   lty.table = c("solid", "dashed", "solid", "dashed",
                 "solid", "dashed", "solid"),
   col.table = rainbow.sky[-5], pch.table = 7:1,
   severity.table = c("None", "Faint", "Weak", "Moderate",
   "Strong", "Extreme", "Undetermined"), FYI = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seglines_+3A_x">x</code>, <code id="seglines_+3A_y">y</code>, <code id="seglines_+3A_dy">dy</code>, <code id="seglines_+3A_ddy">ddy</code></td>
<td>

<p>Same as <code><a href="#topic+hdeffsev">hdeffsev</a></code>.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_lwd">lwd</code>, <code id="seglines_+3A_cex">cex</code></td>
<td>

<p>Graphical parameters: line width, and character expansion.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_plot.it">plot.it</code></td>
<td>

<p>Logical, plot it? If <code>FALSE</code> then the other
graphical arguments are ignored.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_add.legend">add.legend</code>, <code id="seglines_+3A_position.legend">position.legend</code></td>
<td>

<p>Logical and character; add a legend?
The other argument is fed
into <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_cex.legend">cex.legend</code></td>
<td>

<p>Self-explanatory.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_severity.table">severity.table</code>, <code id="seglines_+3A_eta0">eta0</code>, <code id="seglines_+3A_cops0">COPS0</code></td>
<td>

<p>Same as <code><a href="#topic+hdeffsev">hdeffsev</a></code>.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_lty.table">lty.table</code>, <code id="seglines_+3A_col.table">col.table</code>, <code id="seglines_+3A_pch.table">pch.table</code></td>
<td>

<p>Graphical parameters for the 7 different types of segments.
Usually users should not assign anything to these arguments.
Setting <code>pch.table = NULL</code> will
suppress <code>pch</code> symbols from the legend.
</p>
</td></tr>
<tr><td><code id="seglines_+3A_fyi">FYI</code>, <code id="seglines_+3A_...">...</code></td>
<td>

<p>Should be ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was written to
complement <code><a href="#topic+hdeffsev">hdeffsev</a></code>
and is rough-and-ready.
It plots the signed Wald statistics as a function of
the estimates, and uses a colour-code to indicate
the severity of the
Hauck-Donner effect (HDE).
This can be obtained from its first two derivatives.
</p>


<h3>Value</h3>

<p>This function returns the severity of the HDE,
possibly invisibly.
</p>


<h3>Note</h3>

<p>This function is likely to change in the short future
because it is experimental and far from complete.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee.  </p>


<h3>See Also</h3>

<p><code><a href="#topic+hdeff">hdeff</a></code>,
<code><a href="#topic+hdeffsev">hdeffsev</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>deg &lt;- 4  # myfun is a function that approximates the HDE
myfun &lt;- function(x, deriv = 0) switch(as.character(deriv),
  '0' = x^deg * exp(-x),
  '1' = (deg * x^(deg-1) - x^deg) * exp(-x),
  '2' = (deg * (deg-1) * x^(deg-2) - 2*deg * x^(deg-1) +
         x^deg) * exp(-x))
## Not run: 
curve(myfun, 0, 10, col = "white")
xgrid &lt;- seq(0, 10, length = 101)
seglines(xgrid, myfun(xgrid), myfun(xgrid, deriv = 1),
         COPS0 = 2,
         myfun(xgrid, deriv = 2), pch.table = NULL,
         position = "bottom")

## End(Not run)
</code></pre>

<hr>
<h2 id='Select'> Select Variables for a Formula Response or the RHS of a Formula

</h2><span id='topic+Select'></span><span id='topic+subsetcol'></span>

<h3>Description</h3>

<p>Select variables from a data frame whose names
begin with a certain character string.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>Select(data = list(), prefix = "y",
       lhs = NULL, rhs = NULL, rhs2 = NULL, rhs3 = NULL,
       as.character = FALSE, as.formula.arg = FALSE, tilde = TRUE,
       exclude = NULL, sort.arg = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Select_+3A_data">data</code></td>
<td>

<p>A data frame or a matrix.
</p>

</td></tr>
<tr><td><code id="Select_+3A_prefix">prefix</code></td>
<td>

<p>A vector of character strings, or a logical.
If a character then
the variables chosen from <code>data</code> begin with the
value of <code>prefix</code>.
If a logical then
only <code>TRUE</code> is accepted and all the variables
in <code>data</code> are chosen.
</p>

</td></tr>
<tr><td><code id="Select_+3A_lhs">lhs</code></td>
<td>

<p>A character string.
The response of a formula.
</p>

</td></tr>
<tr><td><code id="Select_+3A_rhs">rhs</code></td>
<td>

<p>A character string.
Included as part of the RHS a formula.
Set <code>rhs = "0"</code> to suppress the intercept.
</p>

</td></tr>
<tr><td><code id="Select_+3A_rhs2">rhs2</code>, <code id="Select_+3A_rhs3">rhs3</code></td>
<td>

<p>Same as <code>rhs</code> but appended to its RHS,
i.e., <code>paste0(rhs, " + ", rhs2, " + ", rhs3)</code>.
If used, <code>rhs</code> should be used first,
and then possibly <code>rhs2</code>
and then possibly <code>rhs3</code>.
</p>

</td></tr>
<tr><td><code id="Select_+3A_as.character">as.character</code></td>
<td>

<p>Logical.
Return the answer as a character string?
</p>

</td></tr>
<tr><td><code id="Select_+3A_as.formula.arg">as.formula.arg</code></td>
<td>

<p>Logical.
Is the answer a formula?
</p>

</td></tr>
<tr><td><code id="Select_+3A_tilde">tilde</code></td>
<td>

<p>Logical.
If <code>as.character</code> and <code>as.formula.arg</code>
are both <code>TRUE</code>
then include the tilde in the formula?
</p>
</td></tr>
<tr><td><code id="Select_+3A_exclude">exclude</code></td>
<td>

<p>Vector of character strings.
Exclude these variables explicitly.
</p>

</td></tr>
<tr><td><code id="Select_+3A_sort.arg">sort.arg</code></td>
<td>

<p>Logical.
Sort the variables?
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>This is meant as a utility function to avoid manually:
(i) making a <code><a href="base.html#topic+cbind">cbind</a></code> call to construct
a big matrix response,
and
(ii) constructing a formula involving a lot of terms.
The savings can be made because the variables of interest
begin with some prefix, e.g., with the character <code>"y"</code>.
</p>


<h3>Value</h3>

<p>If <code>as.character = FALSE</code> and
<code>as.formula.arg = FALSE</code> then a matrix such
as <code>cbind(y1, y2, y3)</code>.
If <code>as.character = TRUE</code> and
<code>as.formula.arg = FALSE</code> then a character string such
as <code>"cbind(y1, y2, y3)"</code>.
</p>
<p>If <code>as.character = FALSE</code> and
<code>as.formula.arg = TRUE</code> then a <code><a href="stats.html#topic+formula">formula</a></code> such
as <code>lhs ~ y1 + y2 + y3</code>.
If <code>as.character = TRUE</code> and
<code>as.formula.arg = TRUE</code> then a character string such
as <code>"lhs ~ y1 + y2 + y3"</code>.
See the examples below.
By default, if no variables beginning the the value of <code>prefix</code>
is found then a <code>NULL</code> is returned.
Setting <code>prefix = " "</code> is a way of selecting no variables.
</p>







<h3>Note</h3>

<p>This function is a bit experimental at this stage and
may change in the short future.
Some of its utility may be better achieved using
<code><a href="base.html#topic+subset">subset</a></code> and its <code>select</code> argument,
e.g., <code>subset(pdata, TRUE, select = y01:y10)</code>.
</p>
<p>For some models such as <code><a href="#topic+posbernoulli.t">posbernoulli.t</a></code> the
order of the variables in the <code>xij</code> argument is
crucial, therefore care must be taken with the
argument <code>sort.arg</code>.
In some instances, it may be good to rename variables
<code>y1</code> to <code>y01</code>,
<code>y2</code> to <code>y02</code>, etc.
when there are variables such as
<code>y14</code>.
</p>
<p>Currently <code>subsetcol()</code> and <code>Select()</code> are identical.
One of these functions might be withdrawn in the future.
</p>



<h3>Author(s)</h3>

<p>T. W. Yee.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="base.html#topic+cbind">cbind</a></code>,
<code><a href="base.html#topic+subset">subset</a></code>,
<code><a href="stats.html#topic+formula">formula</a></code>,
<code><a href="#topic+fill1">fill1</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>Pneumo &lt;- pneumo
colnames(Pneumo) &lt;- c("y1", "y2", "y3", "x2")  # The "y" variables are response
Pneumo$x1 &lt;- 1; Pneumo$x3 &lt;- 3; Pneumo$x &lt;- 0; Pneumo$x4 &lt;- 4  # Add these

Select(data = Pneumo)  # Same as with(Pneumo, cbind(y1, y2, y3))
Select(Pneumo, "x")
Select(Pneumo, "x", sort = FALSE, as.char = TRUE)
Select(Pneumo, "x", exclude = "x1")
Select(Pneumo, "x", exclude = "x1", as.char = TRUE)
Select(Pneumo, c("x", "y"))
Select(Pneumo, "z")  # Now returns a NULL
Select(Pneumo, " ")  # Now returns a NULL
Select(Pneumo, prefix = TRUE, as.formula = TRUE)
Select(Pneumo, "x", exclude = c("x3", "x1"), as.formula = TRUE,
       lhs = "cbind(y1, y2, y3)", rhs = "0")
Select(Pneumo, "x", exclude = "x1", as.formula = TRUE, as.char = TRUE,
       lhs = "cbind(y1, y2, y3)", rhs = "0")

# Now a 'real' example:
Huggins89table1 &lt;- transform(Huggins89table1, x3.tij = t01)
tab1 &lt;- subset(Huggins89table1,
               rowSums(Select(Huggins89table1, "y")) &gt; 0)
# Same as
# subset(Huggins89table1, y1 + y2 + y3 + y4 + y5 + y6 + y7 + y8 + y9 + y10 &gt; 0)

# Long way to do it:
fit.th &lt;-
   vglm(cbind(y01, y02, y03, y04, y05, y06, y07, y08, y09, y10) ~ x2 + x3.tij,
        xij = list(x3.tij ~ t01 + t02 + t03 + t04 + t05 + t06 + t07 + t08 +
                            t09 + t10 - 1),
        posbernoulli.t(parallel.t = TRUE ~ x2 + x3.tij),
        data = tab1, trace = TRUE,
        form2 = ~ x2 + x3.tij + t01 + t02 + t03 + t04 + t05 + t06 + t07 + t08 +
                                t09 + t10)
# Short way to do it:
Fit.th &lt;- vglm(Select(tab1, "y") ~ x2 + x3.tij,
               xij = list(Select(tab1, "t", as.formula = TRUE,
                                 sort = FALSE, lhs = "x3.tij", rhs = "0")),
               posbernoulli.t(parallel.t = TRUE ~ x2 + x3.tij),
               data = tab1, trace = TRUE,
               form2 = Select(tab1, prefix = TRUE, as.formula = TRUE))
</code></pre>

<hr>
<h2 id='seq2binomial'> The Two-stage Sequential Binomial Distribution Family Function </h2><span id='topic+seq2binomial'></span>

<h3>Description</h3>

<p>Estimation of the probabilities of a
two-stage binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq2binomial(lprob1 = "logitlink", lprob2 = "logitlink",
             iprob1 = NULL,    iprob2 = NULL,
             parallel = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq2binomial_+3A_lprob1">lprob1</code>, <code id="seq2binomial_+3A_lprob2">lprob2</code></td>
<td>

<p>Parameter link functions applied to the two probabilities,
called <code class="reqn">p</code> and <code class="reqn">q</code> below.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="seq2binomial_+3A_iprob1">iprob1</code>, <code id="seq2binomial_+3A_iprob2">iprob2</code></td>
<td>

<p>Optional initial value for the first and second probabilities
respectively.  A <code>NULL</code> means a value is obtained in the
<code>initialize</code> slot.
</p>
</td></tr>
<tr><td><code id="seq2binomial_+3A_parallel">parallel</code>, <code id="seq2binomial_+3A_zero">zero</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
If <code>parallel = TRUE</code> then the constraint also applies to
the intercept.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <span class="pkg">VGAM</span> family function fits the model described by
Crowder and Sweeting (1989) which is described as follows.
Each of <code class="reqn">m</code> spores has a probability <code class="reqn">p</code> of
germinating. Of the <code class="reqn">y_1</code> spores that germinate,
each has a probability <code class="reqn">q</code> of bending in a particular
direction. Let <code class="reqn">y_2</code> be the number that bend in the
specified direction. The probability model for this data is
<code class="reqn">P(y_1,y_2) =</code>
</p>
<p style="text-align: center;"><code class="reqn">
{m   \choose y_1} p^{y_1} (1-p)^{m-y_1}
{y_1 \choose y_2} q^{y_2} (1-q)^{y_1-y_2}</code>
</p>

<p>for <code class="reqn">0 &lt; p &lt; 1</code>, <code class="reqn">0 &lt; q &lt; 1</code>,
<code class="reqn">y_1=1,\ldots,m</code>
and
<code class="reqn">y_2=1,\ldots,y_1</code>.
Here, <code class="reqn">p</code> is <code>prob1</code>,
<code class="reqn">q</code> is <code>prob2</code>.
</p>
<p>Although the Authors refer to this as the <em>bivariate
binomial</em> model, I have named it the <em>(two-stage)
sequential binomial</em> model.  Fisher scoring is used.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object is used by modelling
functions such as <code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The response must be a two-column matrix of sample proportions
corresponding to <code class="reqn">y_1</code> and <code class="reqn">y_2</code>.
The <code class="reqn">m</code> values should be inputted with the <code>weights</code>
argument of <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
The fitted value is a two-column matrix of estimated
probabilities <code class="reqn">p</code> and <code class="reqn">q</code>.
A common form of error is when there are no trials
for <code class="reqn">y_1</code>,
e.g., if <code>mvector</code> below has some values which are zero.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Crowder, M. and Sweeting, T. (1989).
Bayesian inference for a bivariate binomial distribution.
<em>Biometrika</em>,
<b>76</b>,
599&ndash;603.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+cfibrosis">cfibrosis</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdata &lt;- data.frame(mvector = round(rnorm(nn &lt;- 100, m = 10, sd = 2)),
                    x2 = runif(nn))
sdata &lt;- transform(sdata, prob1 = logitlink(+2 - x2, inverse = TRUE),
                          prob2 = logitlink(-2 + x2, inverse = TRUE))
sdata &lt;- transform(sdata, successes1 = rbinom(nn, size = mvector,    prob = prob1))
sdata &lt;- transform(sdata, successes2 = rbinom(nn, size = successes1, prob = prob2))
sdata &lt;- transform(sdata, y1 = successes1 / mvector)
sdata &lt;- transform(sdata, y2 = successes2 / successes1)
fit &lt;- vglm(cbind(y1, y2) ~ x2, seq2binomial, weight = mvector,
            data = sdata, trace = TRUE)
coef(fit)
coef(fit, matrix = TRUE)
head(fitted(fit))
head(depvar(fit))
head(weights(fit, type = "prior"))  # Same as with(sdata, mvector)
# Number of first successes:
head(depvar(fit)[, 1] * c(weights(fit, type = "prior")))
# Number of second successes:
head(depvar(fit)[, 2] * c(weights(fit, type = "prior")) *
                          depvar(fit)[, 1])
</code></pre>

<hr>
<h2 id='setup.smart'> Smart Prediction Setup </h2><span id='topic+setup.smart'></span>

<h3>Description</h3>

<p>Sets up smart prediction in one of two modes:
<code>"write"</code> and <code>"read"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setup.smart(mode.arg, smart.prediction = NULL, max.smart = 30)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setup.smart_+3A_mode.arg">mode.arg</code></td>
<td>

<p><code>mode.arg</code> must be <code>"write"</code> or <code>"read"</code>.  If in
<code>"read"</code> mode then <code>smart.prediction</code> must be assigned the
data structure <code>.smart.prediction</code> that was created while
fitting. This is stored in <code>object@smart.prediction</code> or
<code>object$smart.prediction</code> where
<code>object</code> is the name of the fitted object.
</p>
</td></tr>
<tr><td><code id="setup.smart_+3A_smart.prediction">smart.prediction</code></td>
<td>

<p>If in <code>"read"</code> mode then <code>smart.prediction</code> must be assigned
the list of data dependent parameters, which is stored
on the fitted object.
Otherwise, <code>smart.prediction</code> is ignored. 
</p>
</td></tr>
<tr><td><code id="setup.smart_+3A_max.smart">max.smart</code></td>
<td>

<p><code>max.smart</code> is the initial length of the list
<code>.smart.prediction</code>. It is not important because
<code>.smart.prediction</code> is made larger if needed.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is only required by programmers writing a modelling
function such as <code><a href="stats.html#topic+lm">lm</a></code>
and <code><a href="stats.html#topic+glm">glm</a></code>, or a prediction functions of such,
e.g., <code><a href="stats.html#topic+predict.lm">predict.lm</a></code>.
The function
<code>setup.smart</code> operates by mimicking the operations of a
first-in first-out stack (better known as a <em>queue</em>).
</p>


<h3>Value</h3>

<p>Nothing is returned.
</p>


<h3>Side Effects</h3>

<p>In <code>"write"</code> mode
<code>.smart.prediction</code> in
<code>smartpredenv</code>
is assigned an empty list with <code>max.smart</code> components.
In <code>"read"</code> mode
<code>.smart.prediction</code> in
<code>smartpredenv</code>
is assigned <code>smart.prediction</code>.
Then
<code>.smart.prediction.counter</code> in
<code>smartpredenv</code>
is assigned the value 0, and
<code>.smart.prediction.mode</code> and <code>.max.smart</code> are written to
<code>smartpredenv</code> too.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>,
<code><a href="stats.html#topic+predict.lm">predict.lm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
setup.smart("write")  # Put at the beginning of lm

## End(Not run)

## Not run: # Put at the beginning of predict.lm
setup.smart("read", smart.prediction = object$smart.prediction)

## End(Not run)
</code></pre>

<hr>
<h2 id='simplex'> Simplex Distribution Family Function </h2><span id='topic+simplex'></span>

<h3>Description</h3>

<p>The two parameters of the univariate standard simplex
distribution are estimated by full maximum likelihood
estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplex(lmu = "logitlink", lsigma = "loglink", imu = NULL, isigma = NULL,
        imethod = 1, ishrinkage = 0.95, zero = "sigma")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplex_+3A_lmu">lmu</code>, <code id="simplex_+3A_lsigma">lsigma</code></td>
<td>

<p>Link function for <code>mu</code> and <code>sigma</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_imu">imu</code>, <code id="simplex_+3A_isigma">isigma</code></td>
<td>

<p>Optional initial values for <code>mu</code> and <code>sigma</code>.
A <code>NULL</code> means a value is obtained internally.
</p>
</td></tr>
<tr><td><code id="simplex_+3A_imethod">imethod</code>, <code id="simplex_+3A_ishrinkage">ishrinkage</code>, <code id="simplex_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability density function can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y; \mu, \sigma) = [2 \pi \sigma^2 (y (1-y))^3]^{-0.5}
  \exp[-0.5 (y-\mu)^2 / (\sigma^2 y (1-y) \mu^2 (1-\mu)^2)]
  </code>
</p>

<p>for <code class="reqn">0 &lt; y &lt; 1</code>,
<code class="reqn">0 &lt; \mu &lt; 1</code>,
and <code class="reqn">\sigma &gt; 0</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">\mu</code> (called <code>mu</code>, and
returned as the fitted values).
</p>










<p>The second parameter, <code>sigma</code>, of this standard simplex
distribution is known as the dispersion parameter.
The unit variance function is
<code class="reqn">V(\mu) = \mu^3 (1-\mu)^3</code>.
Fisher scoring is applied to both parameters.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>This distribution is potentially useful for dispersion modelling.
Numerical problems may occur when <code>mu</code> is very close to 0 or 1.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Jorgensen, B. (1997).
<em>The Theory of Dispersion Models</em>.
London: Chapman &amp; Hall
</p>
<p>Song, P. X.-K. (2007).
<em>Correlated Data Analysis: Modeling, Analytics, and Applications</em>.
Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dsimplex">dsimplex</a></code>,
<code><a href="#topic+dirichlet">dirichlet</a></code>,
<code><a href="mgcv.html#topic+rig">rig</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
sdata &lt;- transform(sdata, eta1 = 1 + 2 * x2,
                          eta2 = 1 - 2 * x2)
sdata &lt;- transform(sdata, y = rsimplex(nn, mu = logitlink(eta1, inverse = TRUE),
                                       dispersion = exp(eta2)))
(fit &lt;- vglm(y ~ x2, simplex(zero = NULL), data = sdata, trace = TRUE))
coef(fit, matrix = TRUE)
summary(fit)
</code></pre>

<hr>
<h2 id='Simplex+20'> Simplex Distribution </h2><span id='topic+dsimplex'></span><span id='topic+rsimplex'></span>

<h3>Description</h3>

<p>Density function,
and random generation for the simplex distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsimplex(x, mu = 0.5, dispersion = 1, log = FALSE)
rsimplex(n, mu = 0.5, dispersion = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simplex+2B20_+3A_x">x</code></td>
<td>

<p>Vector of quantiles.
The support of the distribution is the interval <code class="reqn">(0,1)</code>.
</p>
</td></tr>
<tr><td><code id="Simplex+2B20_+3A_mu">mu</code>, <code id="Simplex+2B20_+3A_dispersion">dispersion</code></td>
<td>

<p>Mean and dispersion parameters.
The former lies in the interval <code class="reqn">(0,1)</code> and the latter is positive.
</p>
</td></tr>
<tr><td><code id="Simplex+2B20_+3A_n">n</code>, <code id="Simplex+2B20_+3A_log">log</code></td>
<td>

<p>Same usage as <code><a href="stats.html#topic+Uniform">runif</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <span class="pkg">VGAM</span> family function <code><a href="#topic+simplex">simplex</a></code> fits this model;
see that online help for more information.
For <code>rsimplex()</code> the rejection method is used;
it may be very slow if the density is highly peaked,
and will fail if the density asymptotes at the boundary.
</p>


<h3>Value</h3>

<p><code>dsimplex(x)</code> gives the density function,
<code>rsimplex(n)</code> gives <code class="reqn">n</code> random variates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+simplex">simplex</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sigma &lt;- c(4, 2, 1)  # Dispersion parameter
mymu  &lt;- c(0.1, 0.5, 0.7); xxx &lt;- seq(0, 1, len = 501)
## Not run:  par(mfrow = c(3, 3))  # Figure 2.1 of Song (2007)
for (iii in 1:3)
  for (jjj in 1:3) {
    plot(xxx, dsimplex(xxx, mymu[jjj], sigma[iii]),
         type = "l", col = "blue", xlab = "", ylab = "", main =
         paste("mu = ", mymu[jjj], ", sigma = ", sigma[iii], sep = "")) } 
## End(Not run)
</code></pre>

<hr>
<h2 id='simulate.vlm'>Simulate Responses for VGLMs and VGAMs</h2><span id='topic+simulate.vlm'></span>

<h3>Description</h3>

<p>Simulate one or more responses from the distribution
corresponding to a fitted model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vlm'
simulate(object, nsim = 1, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.vlm_+3A_object">object</code></td>
<td>
<p>an object representing a fitted model.
Usually an object of class
<code><a href="#topic+vglm-class">vglm-class</a></code>
or
<code><a href="#topic+vgam-class">vgam-class</a></code>.
</p>
</td></tr>
<tr><td><code id="simulate.vlm_+3A_nsim">nsim</code>, <code id="simulate.vlm_+3A_seed">seed</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+simulate">simulate</a></code>.
</p>
</td></tr>









<tr><td><code id="simulate.vlm_+3A_...">...</code></td>
<td>
<p>additional optional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a methods function for <code><a href="stats.html#topic+simulate">simulate</a></code>
and hopefully should behave in a very similar manner.
Only <span class="pkg">VGAM</span> family functions with a <code>simslot</code> slot
have been implemented for <code><a href="stats.html#topic+simulate">simulate</a></code>.
</p>


<h3>Value</h3>

<p>Similar to <code><a href="stats.html#topic+simulate">simulate</a></code>.
Note that many <span class="pkg">VGAM</span> family functions can handle multiple responses.
This can result in a longer data frame with more rows
(<code>nsim</code> multiplied by <code>n</code> rather than the
ordinary <code>n</code>).
In the future an argument may be available so that there
is always <code>n</code> rows no matter how many responses were
inputted.
</p>












<h3>Warning</h3>

<p>With multiple response and/or multivariate responses,
the order of the elements may differ.
For some <span class="pkg">VGAM</span> families, the order is
<code class="reqn">n \times N \times F</code>,
where <code class="reqn">n</code> is the sample size,
<code class="reqn">N</code> is <code>nsim</code> and
<code class="reqn">F</code> is <code>ncol(fitted(vglmObject))</code>.
For other <span class="pkg">VGAM</span> families, the order is
<code class="reqn">n \times F \times N</code>.
An example of each is given below.
</p>


<h3>See Also</h3>

<p>Currently the <span class="pkg">VGAM</span> family functions with a
<code>simslot</code> slot are:
<code><a href="#topic+alaplace1">alaplace1</a></code>,
<code><a href="#topic+alaplace2">alaplace2</a></code>,
<code><a href="#topic+betabinomial">betabinomial</a></code>,
<code><a href="#topic+betabinomialff">betabinomialff</a></code>,
<code><a href="#topic+betaR">betaR</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="#topic+biamhcop">biamhcop</a></code>,
<code><a href="#topic+bifrankcop">bifrankcop</a></code>,
<code><a href="#topic+bilogistic">bilogistic</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+binormal">binormal</a></code>,
<code><a href="#topic+binormalcop">binormalcop</a></code>,
<code><a href="#topic+biclaytoncop">biclaytoncop</a></code>,
<code><a href="#topic+cauchy">cauchy</a></code>,
<code><a href="#topic+cauchy1">cauchy1</a></code>,
<code><a href="#topic+chisq">chisq</a></code>,
<code><a href="#topic+dirichlet">dirichlet</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+erlang">erlang</a></code>,
<code><a href="#topic+exponential">exponential</a></code>,
<code><a href="#topic+bifgmcop">bifgmcop</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+gamma1">gamma1</a></code>,
<code><a href="#topic+gamma2">gamma2</a></code>,
<code><a href="#topic+gammaR">gammaR</a></code>,
<code><a href="#topic+gengamma.stacy">gengamma.stacy</a></code>,
<code><a href="#topic+geometric">geometric</a></code>,
<code><a href="#topic+gompertz">gompertz</a></code>,
<code><a href="#topic+gumbelII">gumbelII</a></code>,
<code><a href="#topic+hzeta">hzeta</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+kumar">kumar</a></code>,
<code><a href="#topic+lgamma1">lgamma1</a></code>,
<code><a href="#topic+lgamma3">lgamma3</a></code>,
<code><a href="#topic+lindley">lindley</a></code>,
<code><a href="#topic+lino">lino</a></code>,
<code><a href="#topic+logff">logff</a></code>,
<code><a href="#topic+logistic1">logistic1</a></code>,
<code><a href="#topic+logistic">logistic</a></code>,
<code><a href="#topic+lognormal">lognormal</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+makeham">makeham</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+negbinomial.size">negbinomial.size</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+perks">perks</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>,
<code><a href="#topic+posnormal">posnormal</a></code>,
<code><a href="#topic+pospoisson">pospoisson</a></code>,
<code><a href="#topic+polya">polya</a></code>,
<code><a href="#topic+polyaR">polyaR</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="#topic+riceff">riceff</a></code>,
<code><a href="#topic+simplex">simplex</a></code>,
<code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+slash">slash</a></code>,
<code><a href="#topic+studentt">studentt</a></code>,
<code><a href="#topic+studentt2">studentt2</a></code>,
<code><a href="#topic+studentt3">studentt3</a></code>,
<code><a href="#topic+triangle">triangle</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+yulesimon">yulesimon</a></code>,
<code><a href="#topic+zageometric">zageometric</a></code>,
<code><a href="#topic+zageometricff">zageometricff</a></code>,
<code><a href="#topic+zanegbinomial">zanegbinomial</a></code>,
<code><a href="#topic+zanegbinomialff">zanegbinomialff</a></code>,
<code><a href="#topic+zapoisson">zapoisson</a></code>,
<code><a href="#topic+zapoissonff">zapoissonff</a></code>,
<code><a href="#topic+zigeometric">zigeometric</a></code>,
<code><a href="#topic+zigeometricff">zigeometricff</a></code>,
<code><a href="#topic+zinegbinomial">zinegbinomial</a></code>,
<code><a href="#topic+zipf">zipf</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+zipoissonff">zipoissonff</a></code>.
</p>


<p>See also
<code><a href="base.html#topic+RNG">RNG</a></code> about random number generation in <span class="rlang"><b>R</b></span>,
<code><a href="#topic+vglm">vglm</a></code>, <code><a href="#topic+vgam">vgam</a></code> for model fitting.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 10; mysize &lt;- 20; set.seed(123)
bdata &lt;- data.frame(x2 = rnorm(nn))
bdata &lt;- transform(bdata,
  y1   = rbinom(nn, size = mysize, p = logitlink(1+x2, inverse = TRUE)),
  y2   = rbinom(nn, size = mysize, p = logitlink(1+x2, inverse = TRUE)),
  f1   = factor(as.numeric(rbinom(nn, size = 1,
                                  p = logitlink(1+x2, inverse = TRUE)))))
(fit1 &lt;- vglm(cbind(y1, aaa = mysize - y1) ~ x2,  # Matrix response (2-colns)
              binomialff, data = bdata))
(fit2 &lt;- vglm(f1 ~ x2, binomialff, model = TRUE, data = bdata)) # Factor response

set.seed(123); simulate(fit1, nsim = 8)
set.seed(123); c(simulate(fit2, nsim = 3))  # Use c() when model = TRUE

# An n x N x F example
set.seed(123); n &lt;- 100
bdata &lt;- data.frame(x2 = runif(n), x3 = runif(n))
bdata &lt;- transform(bdata, y1 = rnorm(n, 1 + 2 * x2),
                          y2 = rnorm(n, 3 + 4 * x2))
fit1 &lt;- vglm(cbind(y1, y2) ~ x2, binormal(eq.sd = TRUE), data = bdata)
nsim &lt;- 1000  # Number of simulations for each observation
my.sims &lt;- simulate(fit1, nsim = nsim)
dim(my.sims)  # A data frame
aaa &lt;- array(unlist(my.sims), c(n, nsim, ncol(fitted(fit1))))  # n by N by F
summary(rowMeans(aaa[, , 1]) - fitted(fit1)[, 1])  # Should be all 0s
summary(rowMeans(aaa[, , 2]) - fitted(fit1)[, 2])  # Should be all 0s

# An n x F x N example
n &lt;- 100; set.seed(111); nsim &lt;- 1000
zdata &lt;- data.frame(x2 = runif(n))
zdata &lt;- transform(zdata, lambda1 =  loglink(-0.5 + 2 * x2, inverse = TRUE),
                          lambda2 =  loglink( 0.5 + 2 * x2, inverse = TRUE),
                          pstr01  = logitlink( 0,            inverse = TRUE),
                          pstr02  = logitlink(-1.0,          inverse = TRUE))
zdata &lt;- transform(zdata, y1 = rzipois(n, lambda = lambda1, pstr0 = pstr01),
                          y2 = rzipois(n, lambda = lambda2, pstr0 = pstr02))
zip.fit  &lt;- vglm(cbind(y1, y2) ~ x2, zipoissonff, data = zdata, crit = "coef")
my.sims &lt;- simulate(zip.fit, nsim = nsim)
dim(my.sims)  # A data frame
aaa &lt;- array(unlist(my.sims), c(n, ncol(fitted(zip.fit)), nsim))  # n by F by N
summary(rowMeans(aaa[, 1, ]) - fitted(zip.fit)[, 1])  # Should be all 0s
summary(rowMeans(aaa[, 2, ]) - fitted(zip.fit)[, 2])  # Should be all 0s
</code></pre>

<hr>
<h2 id='sinmad'> Singh-Maddala Distribution Family Function </h2><span id='topic+sinmad'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the 3-parameter
Singh-Maddala distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sinmad(lscale = "loglink", lshape1.a = "loglink", lshape3.q = "loglink",
       iscale = NULL, ishape1.a = NULL, ishape3.q = NULL, imethod = 1,
       lss = TRUE, gscale = exp(-5:5), gshape1.a = exp(-5:5),
       gshape3.q = exp(-5:5), probs.y = c(0.25, 0.5, 0.75),
       zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sinmad_+3A_lss">lss</code></td>
<td>
<p> See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for important information.
</p>
</td></tr>
<tr><td><code id="sinmad_+3A_lshape1.a">lshape1.a</code>, <code id="sinmad_+3A_lscale">lscale</code>, <code id="sinmad_+3A_lshape3.q">lshape3.q</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code class="reqn">a</code>, <code>scale</code>, and <code class="reqn">q</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="sinmad_+3A_iscale">iscale</code>, <code id="sinmad_+3A_ishape1.a">ishape1.a</code>, <code id="sinmad_+3A_ishape3.q">ishape3.q</code>, <code id="sinmad_+3A_imethod">imethod</code>, <code id="sinmad_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
For <code>imethod = 2</code> a good initial value for
<code>ishape3.q</code> is needed to obtain good estimates for
the other parameters.
</p>
</td></tr>
<tr><td><code id="sinmad_+3A_gscale">gscale</code>, <code id="sinmad_+3A_gshape1.a">gshape1.a</code>, <code id="sinmad_+3A_gshape3.q">gshape3.q</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="sinmad_+3A_probs.y">probs.y</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 3-parameter Singh-Maddala distribution is the 4-parameter
generalized beta II distribution with shape parameter <code class="reqn">p=1</code>.
It is known under various other names, such as the Burr XII (or
just the Burr distribution), Pareto IV,
beta-P, and generalized log-logistic distribution.
More details can be found in Kleiber and Kotz (2003).
</p>
<p>Some distributions which are special cases of the 3-parameter
Singh-Maddala are the Lomax (<code class="reqn">a=1</code>), Fisk (<code class="reqn">q=1</code>), and
paralogistic (<code class="reqn">a=q</code>).
</p>
<p>The Singh-Maddala distribution has density
</p>
<p style="text-align: center;"><code class="reqn">f(y) = aq y^{a-1} / [b^a \{1 + (y/b)^a\}^{1+q}]</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">q &gt; 0</code>, <code class="reqn">y \geq 0</code>.
Here, <code class="reqn">b</code> is the scale parameter <code>scale</code>,
and the others are shape parameters.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y) = 1 - [1 + (y/b)^a]^{-q}.</code>
</p>

<p>The mean is
</p>
<p style="text-align: center;"><code class="reqn">E(Y) = b \, \Gamma(1 + 1/a) \, \Gamma(q - 1/a) / \Gamma(q)</code>
</p>

<p>provided <code class="reqn">-a &lt; 1 &lt; aq</code>; these are returned as the fitted values.
This family function handles multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see
<code><a href="#topic+vglmff-class">vglmff-class</a></code>).  The object
is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See the notes in <code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Sinmad">Sinmad</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>,
<code><a href="#topic+betaII">betaII</a></code>,
<code><a href="#topic+dagum">dagum</a></code>,
<code><a href="#topic+fisk">fisk</a></code>,
<code><a href="#topic+inv.lomax">inv.lomax</a></code>,
<code><a href="#topic+lomax">lomax</a></code>,
<code><a href="#topic+paralogistic">paralogistic</a></code>,
<code><a href="#topic+inv.paralogistic">inv.paralogistic</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdata &lt;- data.frame(y = rsinmad(n = 1000, shape1 = exp(1),
                    scale = exp(2), shape3 = exp(0)))
fit &lt;- vglm(y ~ 1, sinmad(lss = FALSE), sdata, trace = TRUE)
fit &lt;- vglm(y ~ 1, sinmad(lss = FALSE, ishape1.a = exp(1)),
            sdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

# Harder problem (has the shape3.q parameter going to infinity)

set.seed(3)
sdata &lt;- data.frame(y1 = rbeta(1000, 6, 6))
# hist(with(sdata, y1))
if (FALSE) {
# These struggle
  fit1 &lt;- vglm(y1 ~ 1, sinmad(lss = FALSE), sdata, trace = TRUE)
  fit1 &lt;- vglm(y1 ~ 1, sinmad(lss = FALSE), sdata, trace = TRUE,
               crit = "coef")
  Coef(fit1)
}
# Try this remedy:
fit2 &lt;- vglm(y1 ~ 1, data = sdata, trace = TRUE, stepsize = 0.05, maxit = 99,
             sinmad(lss = FALSE, ishape3.q = 3, lshape3.q = "logloglink"))
             
coef(fit2, matrix = TRUE)
Coef(fit2)
</code></pre>

<hr>
<h2 id='Sinmad'>The Singh-Maddala Distribution</h2><span id='topic+Sinmad'></span><span id='topic+dsinmad'></span><span id='topic+psinmad'></span><span id='topic+qsinmad'></span><span id='topic+rsinmad'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and
random generation for the Singh-Maddala distribution with
shape parameters <code>a</code> and <code>q</code>, and scale parameter
<code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsinmad(x, scale = 1, shape1.a, shape3.q, log = FALSE)
psinmad(q, scale = 1, shape1.a, shape3.q, lower.tail = TRUE, log.p = FALSE)
qsinmad(p, scale = 1, shape1.a, shape3.q, lower.tail = TRUE, log.p = FALSE)
rsinmad(n, scale = 1, shape1.a, shape3.q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sinmad_+3A_x">x</code>, <code id="Sinmad_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Sinmad_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Sinmad_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length
is taken to be the number required.</p>
</td></tr>
<tr><td><code id="Sinmad_+3A_shape1.a">shape1.a</code>, <code id="Sinmad_+3A_shape3.q">shape3.q</code></td>
<td>
<p>shape parameters.</p>
</td></tr>
<tr><td><code id="Sinmad_+3A_scale">scale</code></td>
<td>
<p>scale parameter.</p>
</td></tr>
<tr><td><code id="Sinmad_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Sinmad_+3A_lower.tail">lower.tail</code>, <code id="Sinmad_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+sinmad">sinmad</a></code>, which is the <span class="pkg">VGAM</span> family function
for estimating the parameters by maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>dsinmad</code> gives the density,
<code>psinmad</code> gives the distribution function,
<code>qsinmad</code> gives the quantile function, and
<code>rsinmad</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Singh-Maddala distribution is a special case of the 4-parameter
generalized beta II distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics and
Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sinmad">sinmad</a></code>,
<code><a href="#topic+genbetaII">genbetaII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdata &lt;- data.frame(y = rsinmad(n = 3000, scale = exp(2),
                                shape1 = exp(1), shape3 = exp(1)))
fit &lt;- vglm(y ~ 1, sinmad(lss = FALSE, ishape1.a = 2.1), data = sdata,
            trace = TRUE, crit = "coef")
coef(fit, matrix = TRUE)
Coef(fit)
</code></pre>

<hr>
<h2 id='skellam'>Skellam Distribution Family Function</h2><span id='topic+skellam'></span>

<h3>Description</h3>

<p>Estimates the two parameters of a Skellam distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skellam(lmu1 = "loglink", lmu2 = "loglink", imu1 = NULL, imu2 = NULL,
        nsimEIM = 100, parallel = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skellam_+3A_lmu1">lmu1</code>, <code id="skellam_+3A_lmu2">lmu2</code></td>
<td>

<p>Link functions for the <code class="reqn">\mu_1</code> and <code class="reqn">\mu_2</code> parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices and for general information.
</p>
</td></tr>
<tr><td><code id="skellam_+3A_imu1">imu1</code>, <code id="skellam_+3A_imu2">imu2</code></td>
<td>

<p>Optional initial values for the parameters.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
If convergence failure occurs (this <span class="pkg">VGAM</span> family function seems
to require good initial values) try using these arguments.
</p>
</td></tr>
<tr><td><code id="skellam_+3A_nsimeim">nsimEIM</code>, <code id="skellam_+3A_parallel">parallel</code>, <code id="skellam_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
In particular, setting <code>parallel=TRUE</code> will constrain the
two means to be equal.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Skellam distribution models the difference between two
independent Poisson distributions
(with means <code class="reqn">\mu_{j}</code>, say).
It has density function
</p>
<p style="text-align: center;"><code class="reqn">f(y;\mu_1,\mu_2) =
  \left( \frac{ \mu_1 }{\mu_2} \right)^{y/2} \,
  \exp(-\mu_1-\mu_2 ) \, I_{|y|}( 2 \sqrt{ \mu_1 \mu_2})
  </code>
</p>

<p>where <code class="reqn">y</code> is an integer,
<code class="reqn">\mu_1 &gt; 0</code>,
<code class="reqn">\mu_2 &gt; 0</code>.
Here, <code class="reqn">I_v</code> is the modified Bessel function of the
first kind with order <code class="reqn">v</code>.
</p>
<p>The mean is <code class="reqn">\mu_1 - \mu_2</code>
(returned as the fitted values),
and the variance is <code class="reqn">\mu_1 + \mu_2</code>.
Simulated Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This <span class="pkg">VGAM</span> family function seems fragile and very sensitive to
the initial values.
Use very cautiously!!
</p>


<h3>Note</h3>

<p>Numerical problems may occur for data if <code class="reqn">\mu_1</code> and/or
<code class="reqn">\mu_2</code> are large.
</p>


<h3>References</h3>

<p>Skellam, J. G. (1946).
The frequency distribution of the difference between
two Poisson variates belonging to different populations.
<em>Journal of the Royal Statistical Society, Series A</em>,
<b>109</b>, 296.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dskellam">dskellam</a></code>,
<code><a href="stats.html#topic+Poisson">dpois</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
sdata &lt;- transform(sdata, mu1 = exp(1 + x2), mu2 = exp(1 + x2))
sdata &lt;- transform(sdata, y = rskellam(nn, mu1, mu2))
fit1 &lt;- vglm(y ~ x2, skellam, data = sdata, trace = TRUE, crit = "coef")
fit2 &lt;- vglm(y ~ x2, skellam(parallel = TRUE), data = sdata, trace = TRUE)
coef(fit1, matrix = TRUE)
coef(fit2, matrix = TRUE)
summary(fit1)
# Likelihood ratio test for equal means:
pchisq(2 * (logLik(fit1) - logLik(fit2)),
       df = df.residual(fit2) - df.residual(fit1), lower.tail = FALSE)
lrtest(fit1, fit2)  # Alternative

## End(Not run)
</code></pre>

<hr>
<h2 id='Skellam'>The Skellam Distribution</h2><span id='topic+Skellam'></span><span id='topic+dskellam'></span><span id='topic+rskellam'></span>

<h3>Description</h3>

<p>Density
and random generation for the
Skellam distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dskellam(x, mu1, mu2, log = FALSE)
rskellam(n, mu1, mu2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Skellam_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>

<tr><td><code id="Skellam_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+Uniform">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Skellam_+3A_mu1">mu1</code>, <code id="Skellam_+3A_mu2">mu2</code></td>
<td>

<p>See <code><a href="#topic+skellam">skellam</a></code>
</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="Skellam_+3A_log">log</code></td>
<td>

<p>Logical; if TRUE, the logarithm is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+skellam">skellam</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for the formula of the probability density function and other details.
</p>


<h3>Value</h3>

<p><code>dskellam</code> gives the density, and
<code>rskellam</code> generates random deviates.
</p>




<h3>Warning </h3>

<p>Numerical problems may occur for data if <code class="reqn">\mu_1</code> and/or
<code class="reqn">\mu_2</code> are large.
The normal approximation for this case has not been implemented yet.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+skellam">skellam</a></code>,
<code><a href="stats.html#topic+Poisson">dpois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  mu1 &lt;- 1; mu2 &lt;- 2; x &lt;- (-7):7
plot(x, dskellam(x, mu1, mu2), type = "h", las = 1, col = "blue",
     main = paste("Density of Skellam distribution with mu1 = ", mu1,
                  " and mu2 = ", mu2, sep = "")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='skewnorm'> Skew-Normal Distribution </h2><span id='topic+skewnorm'></span><span id='topic+dskewnorm'></span><span id='topic+rskewnorm'></span>

<h3>Description</h3>

<p>Density and
random generation
for the univariate skew-normal distribution.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dskewnorm(x, location = 0, scale = 1, shape = 0, log = FALSE)
rskewnorm(n, location = 0, scale = 1, shape = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skewnorm_+3A_x">x</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>


<tr><td><code id="skewnorm_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="skewnorm_+3A_location">location</code></td>
<td>

<p>The location parameter <code class="reqn">\xi</code>. A vector.
</p>
</td></tr>
<tr><td><code id="skewnorm_+3A_scale">scale</code></td>
<td>

<p>The scale parameter <code class="reqn">\omega</code>. A positive vector.
</p>
</td></tr>
<tr><td><code id="skewnorm_+3A_shape">shape</code></td>
<td>

<p>The shape parameter. It is called <code class="reqn">\alpha</code> in
<code><a href="#topic+skewnormal">skewnormal</a></code>.
</p>
</td></tr>
<tr><td><code id="skewnorm_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log=TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+skewnormal">skewnormal</a></code>, which currently only estimates the shape
parameter.
More generally here, <code class="reqn">Z = \xi + \omega Y</code> where
<code class="reqn">Y</code> has a standard skew-normal distribution
(see <code><a href="#topic+skewnormal">skewnormal</a></code>),
<code class="reqn">\xi</code> is the location parameter and
<code class="reqn">\omega</code> is the scale parameter.
</p>


<h3>Value</h3>

<p><code>dskewnorm</code> gives the density,
<code>rskewnorm</code> generates random deviates.
</p>




<h3>Note</h3>

<p>The default values of all three parameters corresponds to the
skew-normal being the standard normal distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p><code>http://tango.stat.unipd.it/SN</code>.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+skewnormal">skewnormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  N &lt;- 200  # Grid resolution
shape &lt;- 7; x &lt;- seq(-4, 4, len = N)
plot(x, dskewnorm(x, shape = shape), type = "l", col = "blue", las = 1,
     ylab = "", lty = 1, lwd = 2)
abline(v = 0, h = 0, col = "grey")
lines(x, dnorm(x), col = "orange", lty = 2, lwd = 2)
legend("topleft", leg = c(paste("Blue = dskewnorm(x, ", shape,")", sep = ""),
       "Orange = standard normal density"), lty = 1:2, lwd = 2,
       col = c("blue", "orange")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='skewnormal'> Univariate Skew-Normal Distribution Family Function </h2><span id='topic+skewnormal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the shape parameter of a univariate
skew-normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewnormal(lshape = "identitylink", ishape = NULL, nsimEIM = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skewnormal_+3A_lshape">lshape</code>, <code id="skewnormal_+3A_ishape">ishape</code>, <code id="skewnormal_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code> and
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The univariate skew-normal distribution has a density
function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y) = 2 \, \phi(y) \, \Phi(\alpha y)</code>
</p>

<p>where <code class="reqn">\alpha</code> is the shape parameter.
Here, <code class="reqn">\phi</code> is the standard normal density and
<code class="reqn">\Phi</code> its cumulative distribution function.
When <code class="reqn">\alpha=0</code> the result is a standard normal distribution.
When <code class="reqn">\alpha=1</code> it models the distribution of the maximum of
two independent standard normal variates.
When the absolute value of the shape parameter
increases the skewness of the distribution increases.
The limit as the shape parameter tends to positive infinity
results in the folded normal distribution or half-normal distribution.
When the shape parameter changes its sign, the density is reflected
about <code class="reqn">y=0</code>.
</p>
<p>The mean of the distribution is
<code class="reqn">\mu=\alpha \sqrt{2/(\pi (1+\alpha^2))}</code>
and these are returned as the fitted values.
The variance of the distribution is <code class="reqn">1-\mu^2</code>.
The Newton-Raphson algorithm is used unless the <code>nsimEIM</code>
argument is used.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>It is well known that the EIM of Azzalini's skew-normal
distribution is singular for skewness parameter tending to zero,
and thus produces influential problems.
</p>


<h3>Note</h3>

<p>It is a good idea to use several different initial values to ensure
that the global solution is obtained.
</p>
<p>This family function will be modified (hopefully soon) to handle a
location and scale parameter too.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Azzalini, A. A. (1985).
A class of distributions which include the normal.
<em>Scandinavian Journal of Statistics</em>,
<b>12</b>, 171&ndash;178.
</p>
<p>Azzalini, A. and Capitanio, A. (1999).
Statistical applications of the multivariate skew-normal distribution.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>61</b>, 579&ndash;602.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+skewnorm">skewnorm</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+foldnormal">foldnormal</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdata &lt;- data.frame(y1 = rskewnorm(nn &lt;- 1000, shape = 5))
fit1 &lt;- vglm(y1 ~ 1, skewnormal, data = sdata, trace = TRUE)
coef(fit1, matrix = TRUE)
head(fitted(fit1), 1)
with(sdata, mean(y1))
## Not run:  with(sdata, hist(y1, prob = TRUE))
x &lt;- with(sdata, seq(min(y1), max(y1), len = 200))
with(sdata, lines(x, dskewnorm(x, shape = Coef(fit1)), col = "blue")) 
## End(Not run)

sdata &lt;- data.frame(x2 = runif(nn))
sdata &lt;- transform(sdata, y2 = rskewnorm(nn, shape = 1 + 2*x2))
fit2 &lt;- vglm(y2 ~ x2, skewnormal, data = sdata, trace = TRUE, crit = "coef")
summary(fit2)
</code></pre>

<hr>
<h2 id='slash'> Slash Distribution Family Function </h2><span id='topic+slash'></span>

<h3>Description</h3>

<p>Estimates the two parameters of the
slash distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slash(lmu = "identitylink", lsigma = "loglink",
      imu = NULL, isigma = NULL, gprobs.y = ppoints(8), nsimEIM = 250,
      zero = NULL, smallno = .Machine$double.eps*1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slash_+3A_lmu">lmu</code>, <code id="slash_+3A_lsigma">lsigma</code></td>
<td>

<p>Parameter link functions applied to the <code class="reqn">\mu</code>
and <code class="reqn">\sigma</code> parameters, respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>





<tr><td><code id="slash_+3A_imu">imu</code>, <code id="slash_+3A_isigma">isigma</code></td>
<td>

<p>Initial values.
A <code>NULL</code> means an initial value is chosen internally.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="slash_+3A_gprobs.y">gprobs.y</code></td>
<td>

<p>Used to compute the initial values for <code>mu</code>.
This argument is fed into the <code>probs</code> argument of
<code><a href="stats.html#topic+quantile">quantile</a></code> to construct a grid,
which is used to evaluate the log-likelihood.
This must have values between 0 and 1.
</p>
</td></tr>
<tr><td><code id="slash_+3A_nsimeim">nsimEIM</code>, <code id="slash_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="slash_+3A_smallno">smallno</code></td>
<td>

<p>Small positive number, used to test for the singularity.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard slash distribution is the distribution of the ratio of
a standard normal variable to an independent standard uniform(0,1) variable.
It is mainly of use in simulation studies.
One of its properties is that it has heavy tails, similar to those of
the Cauchy.
</p>
<p>The general slash distribution can be obtained by replacing
the univariate normal variable by a general normal
<code class="reqn">N(\mu,\sigma)</code> random variable.
It has a density that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y) = \left\{
\begin{array}{cl}
  1/(2 \sigma \sqrt(2 \pi)) &amp; if y=\mu, \\
  1-\exp(-(((y-\mu)/\sigma)^2)/2))/(\sqrt(2 pi) \sigma ((y-\mu)/\sigma)^2) &amp; if y \ne \mu.
\end{array} \right . </code>
</p>

<p>where <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> are
the mean and standard deviation of
the univariate normal distribution respectively.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Fisher scoring using simulation is used.
Convergence is often quite slow.
Numerical problems may occur.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and C. S. Chee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1994).
<em>Continuous Univariate Distributions</em>,
2nd edition, Volume 1, New York: Wiley.
</p>
<p>Kafadar, K. (1982).
A Biweight Approach to the One-Sample Problem
<em>Journal of the American Statistical Association</em>,
<b>77</b>, 416&ndash;424.
</p>




<h3>See Also</h3>

<p><code><a href="#topic+rslash">rslash</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sdata &lt;- data.frame(y = rslash(n = 1000, mu = 4, sigma = exp(2)))
fit &lt;- vglm(y ~ 1, slash, data = sdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
summary(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='Slash'> Slash Distribution </h2><span id='topic+Slash'></span><span id='topic+dslash'></span><span id='topic+pslash'></span><span id='topic+rslash'></span>

<h3>Description</h3>

<p>Density function, distribution function, and
random generation for the slash distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dslash(x, mu = 0, sigma = 1, log = FALSE,
       smallno = .Machine$double.eps*1000)
pslash(q, mu = 0, sigma = 1, very.negative = -10000,
       lower.tail = TRUE, log.p = FALSE)
rslash(n, mu = 0, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Slash_+3A_x">x</code>, <code id="Slash_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Slash_+3A_n">n</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>

</td></tr>
<tr><td><code id="Slash_+3A_mu">mu</code>, <code id="Slash_+3A_sigma">sigma</code></td>
<td>
<p>the mean and standard deviation of
the univariate normal distribution.
</p>
</td></tr>
<tr><td><code id="Slash_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Slash_+3A_very.negative">very.negative</code></td>
<td>

<p>Numeric, of length 1.
A large negative value.
For <code>(q-mu)/sigma</code> values less than this,
the value 0 is returned because
<code><a href="stats.html#topic+integrate">integrate</a></code> tends to fail.
A warning is issued.
Similarly, if <code>(q-mu)/sigma</code> is greater than
<code>abs(very.negative)</code> then 1 is returned
with a warning.
</p>
</td></tr>
<tr><td><code id="Slash_+3A_smallno">smallno</code></td>
<td>

<p>See <code><a href="#topic+slash">slash</a></code>.
</p>
</td></tr>
<tr><td><code id="Slash_+3A_lower.tail">lower.tail</code>, <code id="Slash_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+slash">slash</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the two parameters by maximum likelihood estimation,
for the formula of the probability density function and other details.
</p>
<p>Function <code><a href="#topic+pslash">pslash</a></code> uses a <code>for ()</code> loop and
<code><a href="stats.html#topic+integrate">integrate</a></code>, meaning it's very slow.
It may also be inaccurate for extreme values of <code>q</code>,
and returns with 1 or 0 values when too extreme compared
to <code>very.negative</code>.
</p>


<h3>Value</h3>

<p><code>dslash</code> gives the density, and
<code>pslash</code> gives the distribution function,
<code>rslash</code> generates random deviates.
</p>


<h3>Note</h3>

<p><code>pslash</code> is very slow.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee and C. S. Chee</p>


<h3>See Also</h3>

<p><code><a href="#topic+slash">slash</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
curve(dslash, col = "blue", ylab = "f(x)", -5, 5, ylim = c(0, 0.4), las = 1,
     main = "Standard slash, normal and Cauchy densities", lwd = 2)
curve(dnorm, col = "black", lty = 2, lwd = 2, add = TRUE)
curve(dcauchy, col = "orange", lty = 3, lwd = 2, add = TRUE)
legend("topleft", c("slash", "normal", "Cauchy"), lty = 1:3,
       col = c("blue","black","orange"), lwd = 2)

curve(pslash, col = "blue", -5, 5, ylim = 0:1)
pslash(c(-Inf, -20000, 20000, Inf))  # Gives a warning

## End(Not run)
</code></pre>

<hr>
<h2 id='sloglink'> Square root&ndash;Log Link Mixtures</h2><span id='topic+sloglink'></span><span id='topic+lcsloglink'></span>

<h3>Description</h3>

<p>Computes some square root&ndash;log mixture link
transformations, including their inverse and
the first few derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  sloglink(theta, bvalue = NULL, taumix.log = 1, tol = 1e-13,
    nmax = 99, inverse = FALSE, deriv = 0, short = TRUE,
    tag = FALSE, c10 = c(2, -2))
lcsloglink(theta, bvalue = NULL, pmix.log = 0.01, tol = 1e-13,
    nmax = 99, inverse = FALSE, deriv = 0, short = TRUE,
    tag = FALSE, c10 = c(2, -2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sloglink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="sloglink_+3A_bvalue">bvalue</code></td>
<td>

<p>See <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="sloglink_+3A_taumix.log">taumix.log</code></td>
<td>

<p>Numeric, of length 1.
Mixing parameter directed at
<code><a href="#topic+loglink">loglink</a></code>.  Then
<code>1 - exp(-taumix.log * theta)</code> is
used to weight
<code><a href="#topic+sqrtlink">sqrtlink</a></code>.
Thus a 0 value will result in
<code><a href="#topic+loglink">loglink</a></code>,
and a very large numeric such as <code>1e4</code>
should be roughly equivalent to
<code><a href="#topic+sqrtlink">sqrtlink</a></code> over almost
all of the parameter space.
</p>
</td></tr>
<tr><td><code id="sloglink_+3A_pmix.log">pmix.log</code></td>
<td>

<p>Numeric, of length 1.
Mixing probability assigned
to <code><a href="#topic+loglink">loglink</a></code>.  Then
<code>1 - pmix.log</code> is used to weight
<code><a href="#topic+sqrtlink">sqrtlink</a></code>.
Thus a 0 value will result in
<code><a href="#topic+sqrtlink">sqrtlink</a></code>
and 1 is equivalent to <code><a href="#topic+loglink">loglink</a></code>.
</p>
</td></tr>
<tr><td><code id="sloglink_+3A_tol">tol</code>, <code id="sloglink_+3A_nmax">nmax</code></td>
<td>

<p>Arguments fed into a function implementing a
vectorized bisection method.
</p>
</td></tr>
<tr><td><code id="sloglink_+3A_inverse">inverse</code>, <code id="sloglink_+3A_deriv">deriv</code>, <code id="sloglink_+3A_short">short</code>, <code id="sloglink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="sloglink_+3A_c10">c10</code></td>
<td>

<p>See <code><a href="#topic+sqrtlink">sqrtlink</a></code>
and
<code><a href="#topic+loglink">loglink</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>






































<p>For general information see
<code><a href="#topic+alogitlink">alogitlink</a></code>.
</p>


<h3>Value</h3>

<p>The following holds for the
<em>linear combination</em> (LC)
variant.
For <code>deriv = 0</code>,
<code>(1 - pmix.log) * sqrtlink(mu, c10 = c10)
    + pmix.log * loglink(mu)</code>
when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then a nonlinear
equation is solved for <code>mu</code>,
given
<code>eta</code> passed in as <code>theta</code>.
For <code>deriv = 1</code>, then the function
returns <em>d</em> <code>eta</code> / <em>d</em>
<code>theta</code> as a function of <code>theta</code> if
<code>inverse = FALSE</code>, else if <code>inverse
  = TRUE</code> then it returns the reciprocal.
</p>


<h3>Warning </h3>

<p>The default values for <code>taumix.log</code>
and <code>pmix.log</code>
may change in the future.
The name and order of the arguments
may change too.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+alogitlink">alogitlink</a></code>,
<code><a href="#topic+sqrtlink">sqrtlink</a></code>,
<code><a href="#topic+loglink">loglink</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>mu  &lt;- seq(0.01, 3, length = 10)
sloglink(mu)
max(abs(sloglink(sloglink(mu), inv = TRUE) - mu))  # 0?
</code></pre>

<hr>
<h2 id='sm.os'> Defining O'Sullivan Spline Smooths in VGAM Formulas </h2><span id='topic+sm.os'></span>

<h3>Description</h3>

<p>This function represents an O-spline smooth term
in a <code>vgam</code> formula
and confers automatic smoothing parameter selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.os(x, ..., niknots = 6, spar = -1, o.order = 2,
      alg.niknots = c("s", ".nknots.smspl")[1], all.knots = FALSE,
      ridge.adj = 1e-5, spillover = 0.01, maxspar = 1e12,
      outer.ok = FALSE, fixspar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.os_+3A_x">x</code></td>
<td>

<p>covariate (abscissae) to be smoothed.
Also called the regressor.
If the <code>xij</code> facility is used then these
covariates are inputted via the <code>...</code> argument.
</p>

</td></tr>
<tr><td><code id="sm.os_+3A_...">...</code></td>
<td>

<p>Used to accommodate the other <code class="reqn">M-1</code> covariates
when the <code>xij</code> facility is used.
See Section 3.4.4 of Yee (2015) for something very similar.
This argument, found in the second argument, means that
the other argument names must be fully specified if used,
e.g., <code>outer.ok</code> and not <code>outer</code>.
See the example below.
In the example below,
the term in the main formula is
<code>sm.os(gcost.air, gcost.trn, gcost.bus)</code>
and one might be tempted to use something like
<code>sm.os(gcost)</code> to represent that <code>xij</code> term.
However, this is not recommended because
<code>sm.os(gcost)</code> might not have the same number of columns
as <code>sm.os(gcost.air, gcost.trn, gcost.bus)</code> etc.
That is, it is best to select one of the diagonal elements
of the block matrix to represent that term.
</p>
</td></tr>
<tr><td><code id="sm.os_+3A_niknots">niknots</code></td>
<td>

<p>numeric,
the number of <em>interior</em> knots,
called <code class="reqn">K</code> below.
The default is to use this value.
If you want <code>alg.niknots</code> to operate then
assign <code>NULL</code> to this argument.
</p>
</td></tr>
<tr><td><code id="sm.os_+3A_alg.niknots">alg.niknots</code></td>
<td>

<p>character.
The algorithm used to determine the number of interior knots.
Only used when <code>all.knots = FALSE</code> and <code>niknots = NULL</code>.
Note that <code>".nknots.smspl"</code> corresponds to the default of
<code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>.
The value <code>"s"</code> corresponds to the same algorithm
as <code><a href="#topic+s">s</a></code>.
</p>




</td></tr>
<tr><td><code id="sm.os_+3A_all.knots">all.knots</code></td>
<td>

<p>logical.
If <code>TRUE</code> then all distinct points in <code>x</code> are used as
the interior knots.
If <code>FALSE</code> (default) then
a subset of <code>x[]</code> is used, specifically
<code>x[j]</code> where the <code>niknots</code> indices are
quantiles that are evenly spaced with respect to the
argument <code>probs</code>&mdash;see <code><a href="stats.html#topic+quantile">quantile</a></code>.
If <code>all.knots = FALSE</code> and
<code>niknots = NULL</code> then the argument
<code>alg.niknots</code> is used to compute <code>niknots</code>.
</p>
</td></tr>
<tr><td><code id="sm.os_+3A_spar">spar</code>, <code id="sm.os_+3A_maxspar">maxspar</code></td>
<td>

<p><code>spar</code> is a vector of smoothing parameters.
Negative values mean that <code><a href="mgcv.html#topic+magic">magic</a></code> will
choose initial values in order to do the optimization at
each P-IRLS iteration.
Positive values mean that they are used as initial values
for <code><a href="mgcv.html#topic+magic">magic</a></code>.
If <code>fixspar = TRUE</code> then <code>spar</code> should be assigned
a vector of positive values (but having values
less than <code>maxspar</code>);
then the smoothing parameters will
be fixed and <code><a href="mgcv.html#topic+magic">magic</a></code> will not be used.
</p>



</td></tr>







<tr><td><code id="sm.os_+3A_o.order">o.order</code></td>
<td>

<p>The order of the O'Sullivan penalzed spline.
Any one value from <code>1:4</code> is acceptable.
The degree of the spline is <code>2 * o.order - 1</code>,
so that cubic splines are the default.
Setting <code>o.order = 1</code> results in a linear
spline which is a piecewise linear function.
</p>

</td></tr>
<tr><td><code id="sm.os_+3A_ridge.adj">ridge.adj</code></td>
<td>

<p>small positive number to stabilize
linear dependencies among B-spline bases.
</p>
</td></tr>
<tr><td><code id="sm.os_+3A_spillover">spillover</code></td>
<td>

<p>small and positive proportion of the range used on
the outside of the boundary values.
This defines the endpoints <code class="reqn">a</code> and <code class="reqn">b</code> that
cover the data <code class="reqn">x_i</code>, i.e., we are interested
in the interval <code class="reqn">[a,b]</code> which contains all the
abscissae. The interior knots are strictly
inside <code class="reqn">(a,b)</code>.
</p>



</td></tr>
<tr><td><code id="sm.os_+3A_outer.ok">outer.ok</code></td>
<td>

<p>Fed into the argument (by the same name)
of <code><a href="splines.html#topic+splineDesign">splineDesign</a></code>.
</p>
</td></tr>
<tr><td><code id="sm.os_+3A_fixspar">fixspar</code></td>
<td>

<p>logical.
If <code>TRUE</code> then <code>spar</code> should be a vector
with positive values and
the smoothing parameters are fixed at those values.
If <code>FALSE</code> then <code>spar</code> contains the initial
values for the smoothing parameters, and
<code><a href="mgcv.html#topic+magic">magic</a></code> is called to determine (hopefully)
some good values for
the smoothing parameters.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is currently used by <code><a href="#topic+vgam">vgam</a></code> to
allow automatic smoothing parameter selection based on
O-splines to minimize an UBRE quantity.
In contrast, <code><a href="#topic+s">s</a></code> operates by having a
prespecified amount of smoothing, e.g., its <code>df</code> argument.
When the sample size is reasonably large
this function
is recommended over <code><a href="#topic+s">s</a></code> also because backfitting
is not required.
This function therefore allows 2nd-generation VGAMs to be
fitted (called G2-VGAMs, or Penalized-VGAMs).
</p>


<p>This function should only be used with <code><a href="#topic+vgam">vgam</a></code>.
This function uses <code><a href="stats.html#topic+quantile">quantile</a></code> to
choose the knots, whereas <code><a href="#topic+sm.ps">sm.ps</a></code>
chooses equally-spaced knots.
As Wand and Ormerod (2008) write,
in most situations the differences will be minor,
but it is possible for problems to arise
for either strategy by
constructing certain regression functions and
predictor variable distributions.
Any differences between O-splines and P-splines tend
to be at the boundaries. O-splines have
<em>natural boundary constraints</em> so that the solution is
linear beyond the boundary knots.
</p>
<p>Some arguments in decreasing order of precedence are:
<code>all.knots</code>,
<code>niknots</code>,
<code>alg.niknots</code>.
</p>
<p>Unlike <code><a href="#topic+s">s</a></code>, which is symbolic and does not perform
any smoothing itself, this function does compute the penalized spline
when used by <code><a href="#topic+vgam">vgam</a></code>&mdash;it creates the appropriate columns
of the model matrix.  When this function is used within
<code><a href="#topic+vgam">vgam</a></code>, automatic smoothing parameter selection is
implemented by calling <code><a href="mgcv.html#topic+magic">magic</a></code> after the necessary
link-ups are done.
</p>
<p>By default this function centres the component function.
This function is also <em>smart</em>; it can be used for
smart prediction (Section 18.6 of Yee (2015)).
Automatic smoothing parameter selection is performed using
<em>performance-oriented iteration</em> whereby an optimization
problem is solved at each IRLS iteration.

</p>


<p>This function works better when the sample size is large,
e.g., when in the hundreds, say.
</p>




















<h3>Value</h3>

<p>A matrix with attributes that are (only) used by <code><a href="#topic+vgam">vgam</a></code>.
The number of rows of the matrix is <code>length(x)</code>.
The number of columns is a function of the number
of interior knots <code class="reqn">K</code> and
the order of the O-spline <code class="reqn">m</code>:
<code class="reqn">K+2m-1</code>.
In code, this is
<code>niknots + 2 * o.order - 1</code>,
or using <code><a href="#topic+sm.ps">sm.ps</a></code>-like arguments,
<code>ps.int + degree - 1</code>
(where <code>ps.int</code> should be more generally
interpreted as the number of intervals. The formula is
the same as <code><a href="#topic+sm.ps">sm.ps</a></code>.).
It transpires then that <code><a href="#topic+sm.os">sm.os</a></code> and <code><a href="#topic+sm.ps">sm.ps</a></code>
are very similar.
</p>






<h3>Warning </h3>

<p>Being introduced into <span class="pkg">VGAM</span> for the first time,
this function (and those associated with it) should
be used cautiously. Not all options are fully
working or have been tested yet,
and there are bound to be some bugs
lurking around.
</p>


<h3>Note</h3>

<p>This function is currently under development and
may change in the future.
</p>
<p>One might try using this function with <code><a href="#topic+vglm">vglm</a></code>
so as to fit a regression spline,
however, the default value of <code>niknots</code> will probably
be too high for most data sets.
</p>




<h3>Author(s)</h3>

<p>T. W. Yee,
with some of the essential R code coming
from the appendix of Wand and Ormerod (2008).
</p>


<h3>References</h3>

<p>Wand, M. P. and Ormerod, J. T. (2008).
On semiparametric regression with O'Sullivan penalized splines.
<em>Australian and New Zealand Journal of Statistics</em>,
<b>50</b>(2): 179&ndash;198.
</p>











<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+sm.ps">sm.ps</a></code>,
<code><a href="#topic+s">s</a></code>,
<code><a href="#topic+smartpred">smartpred</a></code>,
<code><a href="#topic+is.smart">is.smart</a></code>,
<code><a href="#topic+summarypvgam">summarypvgam</a></code>,
<code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>,
<code><a href="splines.html#topic+splineDesign">splineDesign</a></code>,
<code><a href="splines.html#topic+bs">bs</a></code>,
<code><a href="mgcv.html#topic+magic">magic</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sm.os(runif(20))

## Not run: 
data("TravelMode", package = "AER")  # Need to install "AER" first
air.df &lt;- subset(TravelMode, mode == "air")  # Form 4 smaller data frames
bus.df &lt;- subset(TravelMode, mode == "bus")
trn.df &lt;- subset(TravelMode, mode == "train")
car.df &lt;- subset(TravelMode, mode == "car")
TravelMode2 &lt;- data.frame(income     = air.df$income,
                          wait.air   = air.df$wait  - car.df$wait,
                          wait.trn   = trn.df$wait  - car.df$wait,
                          wait.bus   = bus.df$wait  - car.df$wait,
                          gcost.air  = air.df$gcost - car.df$gcost,
                          gcost.trn  = trn.df$gcost - car.df$gcost,
                          gcost.bus  = bus.df$gcost - car.df$gcost,
                          wait       = air.df$wait)  # Value is unimportant
TravelMode2$mode &lt;- subset(TravelMode, choice == "yes")$mode  # The response
TravelMode2 &lt;- transform(TravelMode2, incom.air = income, incom.trn = 0,
                                      incom.bus = 0)
set.seed(1)
TravelMode2 &lt;- transform(TravelMode2,
                         junkx2 = runif(nrow(TravelMode2)))

tfit2 &lt;-
  vgam(mode ~ sm.os(gcost.air, gcost.trn, gcost.bus) + ns(junkx2, 4) +
              sm.os(incom.air, incom.trn, incom.bus) + wait ,
       crit = "coef",
       multinomial(parallel = FALSE ~ 1), data = TravelMode2,
       xij = list(sm.os(gcost.air, gcost.trn, gcost.bus) ~
                  sm.os(gcost.air, gcost.trn, gcost.bus) +
                  sm.os(gcost.trn, gcost.bus, gcost.air) +
                  sm.os(gcost.bus, gcost.air, gcost.trn),
                  sm.os(incom.air, incom.trn, incom.bus) ~
                  sm.os(incom.air, incom.trn, incom.bus) +
                  sm.os(incom.trn, incom.bus, incom.air) +
                  sm.os(incom.bus, incom.air, incom.trn),
                  wait   ~  wait.air +  wait.trn +  wait.bus),
       form2 = ~  sm.os(gcost.air, gcost.trn, gcost.bus) +
                  sm.os(gcost.trn, gcost.bus, gcost.air) +
                  sm.os(gcost.bus, gcost.air, gcost.trn) +
                  wait +
                  sm.os(incom.air, incom.trn, incom.bus) +
                  sm.os(incom.trn, incom.bus, incom.air) +
                  sm.os(incom.bus, incom.air, incom.trn) +
                  junkx2 + ns(junkx2, 4) +
                  incom.air + incom.trn + incom.bus +
                  gcost.air + gcost.trn + gcost.bus +
                  wait.air +  wait.trn +  wait.bus)
par(mfrow = c(2, 2))
plot(tfit2, se = TRUE, lcol = "orange", scol = "blue", ylim = c(-4, 4))
summary(tfit2)

## End(Not run)
</code></pre>

<hr>
<h2 id='sm.ps'> Defining Penalized Spline Smooths in VGAM Formulas </h2><span id='topic+sm.ps'></span>

<h3>Description</h3>

<p>This function represents a P-spline smooth term
in a <code>vgam</code> formula
and confers automatic smoothing parameter selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.ps(x, ..., ps.int = NULL, spar = -1, degree = 3, p.order = 2,
      ridge.adj = 1e-5, spillover = 0.01, maxspar = 1e12,
      outer.ok = FALSE, mux = NULL, fixspar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sm.ps_+3A_x">x</code>, <code id="sm.ps_+3A_...">...</code></td>
<td>

<p>See <code><a href="#topic+sm.os">sm.os</a></code>.
</p>

</td></tr>
<tr><td><code id="sm.ps_+3A_ps.int">ps.int</code></td>
<td>

<p>the number of equally-spaced B-spline intervals.
Note that the number of knots is equal to
<code>ps.int + 2*degree + 1</code>.
The default, signified by <code>NULL</code>, means that the
maximum of the value 7 and <code>degree</code> is chosen.
This usually means 6 interior knots for big data sets.
However, if this is too high compared to the
length of <code>x</code>, then some adjustment is made.
In the case where <code>mux</code> is assigned a numerical
value (suggestions: some value between 1 and 2)
then
<code>ceiling(mux * log(length(unique(x.index))))</code>
is used, where <code>x.index</code> is the combined data.
No matter what, the above
is not guaranteed to work on every data set.
This argument may change in the future.
See also argument <code>mux</code>.
</p>







</td></tr>
<tr><td><code id="sm.ps_+3A_spar">spar</code>, <code id="sm.ps_+3A_maxspar">maxspar</code></td>
<td>

<p>See <code><a href="#topic+sm.os">sm.os</a></code>.
</p>
</td></tr>
<tr><td><code id="sm.ps_+3A_mux">mux</code></td>
<td>

<p>numeric. If given, then this argument multiplies
<code>log(length(unique(x)))</code>
to obtain <code>ps.int</code>.
If <code>ps.int</code> is given then this argument is ignored.
</p>
</td></tr>
<tr><td><code id="sm.ps_+3A_degree">degree</code></td>
<td>

<p>degree of B-spline basis. Usually this will be 2 or 3; and
the values 1 or 4 might possibly be used.
</p>
</td></tr>
<tr><td><code id="sm.ps_+3A_p.order">p.order</code></td>
<td>

<p>order of difference penalty (0 is the ridge penalty).
</p>
</td></tr>
<tr><td><code id="sm.ps_+3A_ridge.adj">ridge.adj</code>, <code id="sm.ps_+3A_spillover">spillover</code></td>
<td>

<p>See <code><a href="#topic+sm.os">sm.os</a></code>.
</p>


</td></tr>
<tr><td><code id="sm.ps_+3A_outer.ok">outer.ok</code>, <code id="sm.ps_+3A_fixspar">fixspar</code></td>
<td>

<p>See <code><a href="#topic+sm.os">sm.os</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used by <code><a href="#topic+vgam">vgam</a></code> to
allow automatic smoothing parameter selection based on
P-splines and minimizing an UBRE quantity.
</p>



<p>This function should only be used with <code><a href="#topic+vgam">vgam</a></code>
and is an alternative to <code><a href="#topic+sm.os">sm.os</a></code>;
see that function for some details that also apply here.
</p>


<h3>Value</h3>

<p>A matrix with attributes that are (only) used by <code><a href="#topic+vgam">vgam</a></code>.
The number of rows of the matrix is <code>length(x)</code> and
the number of columns is <code>ps.int + degree - 1</code>.
The latter is because the function is centred.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+sm.os">sm.os</a></code>.
</p>


<h3>Note</h3>

<p>This function is currently under development and
may change in the future.
In particular, the default for <code>ps.int</code> is
subject to change.
</p>


<h3>Author(s)</h3>

<p>B. D. Marx wrote the original function.
Subsequent edits were made by T. W. Yee and C. Somchit.
</p>


<h3>References</h3>









<p>Eilers, P. H. C. and Marx, B. D. (1996).
Flexible smoothing with B-splines
and penalties (with comments and rejoinder).
<em>Statistical Science</em>, <b>11</b>(2): 89&ndash;121.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sm.os">sm.os</a></code>,
<code><a href="#topic+s">s</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+smartpred">smartpred</a></code>,
<code><a href="#topic+is.smart">is.smart</a></code>,
<code><a href="#topic+summarypvgam">summarypvgam</a></code>,
<code><a href="splines.html#topic+splineDesign">splineDesign</a></code>,
<code><a href="splines.html#topic+bs">bs</a></code>,
<code><a href="mgcv.html#topic+magic">magic</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sm.ps(runif(20))
sm.ps(runif(20), ps.int = 5)

## Not run: 
data("TravelMode", package = "AER")  # Need to install "AER" first
air.df &lt;- subset(TravelMode, mode == "air")  # Form 4 smaller data frames
bus.df &lt;- subset(TravelMode, mode == "bus")
trn.df &lt;- subset(TravelMode, mode == "train")
car.df &lt;- subset(TravelMode, mode == "car")
TravelMode2 &lt;- data.frame(income     = air.df$income,
                          wait.air   = air.df$wait  - car.df$wait,
                          wait.trn   = trn.df$wait  - car.df$wait,
                          wait.bus   = bus.df$wait  - car.df$wait,
                          gcost.air  = air.df$gcost - car.df$gcost,
                          gcost.trn  = trn.df$gcost - car.df$gcost,
                          gcost.bus  = bus.df$gcost - car.df$gcost,
                          wait       = air.df$wait)  # Value is unimportant
TravelMode2$mode &lt;- subset(TravelMode, choice == "yes")$mode  # The response
TravelMode2 &lt;- transform(TravelMode2, incom.air = income, incom.trn = 0,
                                      incom.bus = 0)
set.seed(1)
TravelMode2 &lt;- transform(TravelMode2,
                         junkx2 = runif(nrow(TravelMode2)))

tfit2 &lt;-
  vgam(mode ~ sm.ps(gcost.air, gcost.trn, gcost.bus) + ns(junkx2, 4) +
              sm.ps(incom.air, incom.trn, incom.bus) + wait ,
       crit = "coef",
       multinomial(parallel = FALSE ~ 1), data = TravelMode2,
       xij = list(sm.ps(gcost.air, gcost.trn, gcost.bus) ~
                  sm.ps(gcost.air, gcost.trn, gcost.bus) +
                  sm.ps(gcost.trn, gcost.bus, gcost.air) +
                  sm.ps(gcost.bus, gcost.air, gcost.trn),
                  sm.ps(incom.air, incom.trn, incom.bus) ~
                  sm.ps(incom.air, incom.trn, incom.bus) +
                  sm.ps(incom.trn, incom.bus, incom.air) +
                  sm.ps(incom.bus, incom.air, incom.trn),
                  wait   ~  wait.air +  wait.trn +  wait.bus),
       form2 = ~  sm.ps(gcost.air, gcost.trn, gcost.bus) +
                  sm.ps(gcost.trn, gcost.bus, gcost.air) +
                  sm.ps(gcost.bus, gcost.air, gcost.trn) +
                  wait +
                  sm.ps(incom.air, incom.trn, incom.bus) +
                  sm.ps(incom.trn, incom.bus, incom.air) +
                  sm.ps(incom.bus, incom.air, incom.trn) +
                  junkx2 + ns(junkx2, 4) +
                  incom.air + incom.trn + incom.bus +
                  gcost.air + gcost.trn + gcost.bus +
                  wait.air +  wait.trn +  wait.bus)
par(mfrow = c(2, 2))
plot(tfit2, se = TRUE, lcol = "orange", scol = "blue", ylim = c(-4, 4))
summary(tfit2)

## End(Not run)
</code></pre>

<hr>
<h2 id='smart.expression'> S Expression for Smart Functions </h2><span id='topic+smart.expression'></span>

<h3>Description</h3>

 
<p><code>smart.expression</code> is an S expression for 
a smart function to call itself. It is best if you go through it line
by line, but most users will not need to know anything about it. 
It requires the primary argument of the smart function to be called
<code>"x"</code>.
</p>
<p>The list component <code>match.call</code> must be assigned the 
value of <code>match.call()</code> in the smart function; this is so
that the smart function can call itself later.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match.call">match.call</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(sm.min2)
</code></pre>

<hr>
<h2 id='smart.mode.is'> Determine What Mode the Smart Prediction is In </h2><span id='topic+smart.mode.is'></span>

<h3>Description</h3>

<p>Determine which of three modes the smart prediction is currently in.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smart.mode.is(mode.arg = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smart.mode.is_+3A_mode.arg">mode.arg</code></td>
<td>

<p>a character string, either <code>"read"</code>, <code>"write"</code>
or <code>"neutral"</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Smart functions such as
<code><a href="splines.html#topic+bs">bs</a></code> and
<code><a href="stats.html#topic+poly">poly</a></code> need to know what mode
smart prediction is in. If it is in <code>"write"</code> mode
then the parameters are saved to <code>.smart.prediction</code>
using <code><a href="#topic+put.smart">put.smart</a></code>. If in <code>"read"</code> mode
then the parameters are read in using <code><a href="#topic+get.smart">get.smart</a></code>.
If in <code>"neutral"</code> mode then the smart function behaves like an
ordinary function.
</p>


<h3>Value</h3>

<p>If <code>mode.arg</code> is given, then either <code>TRUE</code> or <code>FALSE</code>
is returned.
If <code>mode.arg</code> is not given, then the mode (<code>"neutral"</code>,
<code>"read"</code> or <code>"write"</code>)
is returned.  Usually, the mode is <code>"neutral"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+put.smart">put.smart</a></code>,
<code><a href="splines.html#topic+bs">bs</a></code>,
<code><a href="stats.html#topic+poly">poly</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>print(sm.min1)
smart.mode.is()  # Returns "neutral"
smart.mode.is(smart.mode.is())  # Returns TRUE
</code></pre>

<hr>
<h2 id='smartpred'> Smart Prediction </h2><span id='topic+smartpred'></span><span id='topic+sm.bs'></span><span id='topic+sm.ns'></span><span id='topic+sm.scale'></span><span id='topic+sm.scale.default'></span><span id='topic+sm.poly'></span>

<h3>Description</h3>

<p>Data-dependent parameters in formula terms
can cause problems in when predicting.
The <span class="pkg">smartpred</span> package
saves
data-dependent parameters on the object so that the bug is fixed.
The <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code> functions have
been fixed properly. Note that the <span class="pkg">VGAM</span> package by T. W. Yee
automatically comes with smart prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sm.bs(x, df = NULL, knots = NULL, degree = 3, intercept = FALSE, 
      Boundary.knots = range(x))
sm.ns(x, df = NULL, knots = NULL, intercept = FALSE,
      Boundary.knots = range(x))
sm.poly(x, ..., degree = 1, coefs = NULL, raw = FALSE) 
sm.scale(x, center = TRUE, scale = TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smartpred_+3A_x">x</code></td>
<td>

<p>The <code>x</code> argument is actually common to them all.
</p>
</td></tr>
<tr><td><code id="smartpred_+3A_df">df</code>, <code id="smartpred_+3A_knots">knots</code>, <code id="smartpred_+3A_intercept">intercept</code>, <code id="smartpred_+3A_boundary.knots">Boundary.knots</code></td>
<td>

<p>See <code><a href="splines.html#topic+bs">bs</a></code> and/or
<code><a href="splines.html#topic+ns">ns</a></code>.
</p>
</td></tr>
<tr><td><code id="smartpred_+3A_degree">degree</code>, <code id="smartpred_+3A_...">...</code>, <code id="smartpred_+3A_coefs">coefs</code>, <code id="smartpred_+3A_raw">raw</code></td>
<td>

<p>See <code><a href="stats.html#topic+poly">poly</a></code>.
</p>
</td></tr>
<tr><td><code id="smartpred_+3A_center">center</code>, <code id="smartpred_+3A_scale">scale</code></td>
<td>

<p>See <code><a href="base.html#topic+scale">scale</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><span class="rlang"><b>R</b></span> version 1.6.0 introduced a partial fix for the prediction
problem because it does not work all the time,
e.g., for terms such as
<code>I(poly(x, 3))</code>, 
<code>poly(c(scale(x)), 3)</code>,
<code>bs(scale(x), 3)</code>, 
<code>scale(scale(x))</code>.
See the examples below.
Smart prediction, however, will always work.
</p>

<p>The basic idea is that the functions in the formula are now smart, and the
modelling functions make use of these smart functions.  Smart prediction
works in two ways: using <code><a href="#topic+smart.expression">smart.expression</a></code>, or using a
combination of <code><a href="#topic+put.smart">put.smart</a></code> and <code><a href="#topic+get.smart">get.smart</a></code>.
</p>


<h3>Value</h3>

<p>The usual value returned by
<code><a href="splines.html#topic+bs">bs</a></code>, 
<code><a href="splines.html#topic+ns">ns</a></code>,
<code><a href="stats.html#topic+poly">poly</a></code> and
<code><a href="base.html#topic+scale">scale</a></code>,
When used with functions such as <code><a href="#topic+vglm">vglm</a></code>
the data-dependent parameters are  saved on one slot component called
<code>smart.prediction</code>.
</p>


<h3>Side Effects</h3>

<p>The variables
<code>.max.smart</code>,
<code>.smart.prediction</code> and 
<code>.smart.prediction.counter</code>
are created while the model is being fitted.
They are created in a new environment called <code>smartpredenv</code>.
These variables are deleted after the model has been fitted.
However,
if there is an error in the model fitting function or the fitting
model is killed (e.g., by typing control-C) then these variables will
be left in <code>smartpredenv</code>.  At the beginning of model fitting,
these variables are deleted if present in <code>smartpredenv</code>.
</p>

<p>During prediction, the variables
<code>.smart.prediction</code> and 
<code>.smart.prediction.counter</code>
are reconstructed and read by the smart functions when the model
frame is re-evaluated. 
After prediction, these variables are deleted. 
</p>
<p>If the modelling function is used with argument <code>smart = FALSE</code>
(e.g., <code>vglm(..., smart = FALSE)</code>) then smart prediction will not
be used, and the results should match with the original <span class="rlang"><b>R</b></span> functions.
</p>


<h3>WARNING </h3>










<p>The functions
<code><a href="splines.html#topic+bs">bs</a></code>,
<code><a href="splines.html#topic+ns">ns</a></code>,
<code><a href="stats.html#topic+poly">poly</a></code> and
<code><a href="base.html#topic+scale">scale</a></code>
are now left alone (from 2014-05 onwards) and no longer smart.
They work via safe prediction.
The smart versions of these functions have been renamed and
they begin with <code>"sm."</code>.
</p>
<p>The functions
<code><a href="splines.html#topic+predict.bs">predict.bs</a></code> and
<code>predict.ns</code>
are not smart.
That is because they operate on objects that contain attributes only
and do not have list components or slots.
The function
<code><a href="stats.html#topic+poly">predict.poly</a></code> is not smart.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee and T. J. Hastie</p>


<h3>See Also</h3>

<p><code><a href="#topic+get.smart.prediction">get.smart.prediction</a></code>,
<code><a href="#topic+get.smart">get.smart</a></code>,
<code><a href="#topic+put.smart">put.smart</a></code>,
<code><a href="#topic+smart.expression">smart.expression</a></code>,
<code><a href="#topic+smart.mode.is">smart.mode.is</a></code>,
<code><a href="#topic+setup.smart">setup.smart</a></code>,
<code><a href="#topic+wrapup.smart">wrapup.smart</a></code>.
For <code><a href="#topic+vgam">vgam</a></code> in <span class="pkg">VGAM</span>,
<code><a href="#topic+sm.ps">sm.ps</a></code> is important.
Commonly used data-dependent functions include
<code><a href="base.html#topic+scale">scale</a></code>, 
<code><a href="stats.html#topic+poly">poly</a></code>, 
<code><a href="splines.html#topic+bs">bs</a></code>, 
<code><a href="splines.html#topic+ns">ns</a></code>.
In <span class="rlang"><b>R</b></span>, 
the functions <code><a href="splines.html#topic+bs">bs</a></code>
and <code><a href="splines.html#topic+ns">ns</a></code> are in the
<span class="pkg">splines</span> package, and this library is automatically
loaded in because it contains compiled code that 
<code><a href="splines.html#topic+bs">bs</a></code> and <code><a href="splines.html#topic+ns">ns</a></code> call.
</p>



<p>The functions <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and
<code><a href="#topic+cqo">cqo</a></code>
in T. W. Yee's <span class="pkg">VGAM</span>
package are examples of modelling functions that employ smart prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create some data first
n &lt;- 20
set.seed(86)  # For reproducibility of the random numbers
ldata &lt;- data.frame(x2 = sort(runif(n)), y = sort(runif(n)))
library("splines")  # To get ns() in R

# This will work for R 1.6.0 and later
fit &lt;- lm(y ~ ns(x2, df = 5), data = ldata)
## Not run: 
plot(y ~ x2, data = ldata)
lines(fitted(fit) ~ x2, data = ldata)
new.ldata &lt;- data.frame(x2 = seq(0, 1, len = n))
points(predict(fit, new.ldata) ~ x2, new.ldata, type = "b", col = 2, err = -1)

## End(Not run)

# The following fails for R 1.6.x and later. It can be
# made to work with smart prediction provided
# ns is changed to sm.ns and scale is changed to sm.scale:
fit1 &lt;- lm(y ~ ns(scale(x2), df = 5), data = ldata)
## Not run: 
plot(y ~ x2, data = ldata, main = "Safe prediction fails")
lines(fitted(fit1) ~ x2, data = ldata)
points(predict(fit1, new.ldata) ~ x2, new.ldata, type = "b", col = 2, err = -1)

## End(Not run)

# Fit the above using smart prediction
## Not run: 
library("VGAM")  # The following requires the VGAM package to be loaded 
fit2 &lt;- vglm(y ~ sm.ns(sm.scale(x2), df = 5), uninormal, data = ldata)
fit2@smart.prediction
plot(y ~ x2, data = ldata, main = "Smart prediction")
lines(fitted(fit2) ~ x2, data = ldata)
points(predict(fit2, new.ldata, type = "response") ~ x2, data = new.ldata,
       type = "b", col = 2, err = -1)

## End(Not run)
</code></pre>

<hr>
<h2 id='specials'>
Special Values or Quantities in a Fitted Object
</h2><span id='topic+specials'></span><span id='topic+specialsvglm'></span>

<h3>Description</h3>

<p>Return any special values or quantities in a fitted
object, and in particular in a VGLM fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specials(object, ...)
specialsvglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="specials_+3A_object">object</code></td>
<td>

<p>an object of class <code>"vglm"</code> whose family function
begins with <code>"gait"</code>.
</p>
</td></tr>
<tr><td><code id="specials_+3A_...">...</code></td>
<td>

<p>any additional arguments, to future-proof this function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This extractor function was motivated by GAITD regression
(Yee and Ma, 2024)
where the values from three disjoint sets are referred
to as <em>special</em>.
More generally, S4 methods functions can be written so that
<code>specials()</code> will work on any S4 object, where
what is called special depends on the methodology at hand.
</p>




<h3>Value</h3>

<p>Returns any &lsquo;special&rsquo; values or quantities associated with
a fitted regression model.
This is often something simple such as a list or a vector.
</p>


<h3>References</h3>

<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>



<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>,
<code><a href="#topic+inflated">inflated</a></code>,
<code><a href="#topic+altered">altered</a></code>,
<code><a href="#topic+truncated">truncated</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>abdata &lt;- data.frame(y = 0:7, w = c(182, 41, 12, 2, 2, 0, 0, 1))
fit1 &lt;- vglm(y ~ 1, gaitdpoisson(a.mix = 0), data = abdata,
             weight = w, subset = w &gt; 0)
specials(fit1)
</code></pre>

<hr>
<h2 id='spikeplot'>
Spike Plot
</h2><span id='topic+spikeplot'></span>

<h3>Description</h3>

<p>Produces a spike plot of a numeric vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spikeplot(x, freq = FALSE, as.table = FALSE, col = par("col"),
    lty = par("lty"), lwd = par("lwd"), lend = par("lend"),
    type = "h", xlab = deparse1(substitute(x)), ylab = NULL,
    capped = FALSE, cex = sqrt(lwd) / 2, pch = 19, pcol = col, scol = NULL,
    slty = NULL, slwd = NULL, new.plot = TRUE, offset.x = 0, ymux = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spikeplot_+3A_x">x</code></td>
<td>

<p>Numeric, passed into <code><a href="base.html#topic+table">table</a></code>.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_freq">freq</code></td>
<td>

<p>Logical. If <code>TRUE</code> then the y-axis measures
the frequencies, else the sample proportions.
Intended to be as <code><a href="graphics.html#topic+hist">hist</a></code>.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_as.table">as.table</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the call to <code><a href="base.html#topic+plot">plot</a></code> is
closer to <code>plot(table(x), ...)</code>, meaning the labelling
differs from <code>as.table = FALSE</code>.
The default is to convert <code>table(x)</code> into a numeric
vector which is then passed into <code><a href="base.html#topic+plot">plot</a></code>
so that the labelling is more uniform along the x-axis.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_col">col</code>, <code id="spikeplot_+3A_type">type</code>, <code id="spikeplot_+3A_lty">lty</code>, <code id="spikeplot_+3A_lwd">lwd</code></td>
<td>

<p>See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_lend">lend</code>, <code id="spikeplot_+3A_xlab">xlab</code>, <code id="spikeplot_+3A_ylab">ylab</code></td>
<td>

<p>See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_capped">capped</code>, <code id="spikeplot_+3A_cex">cex</code>, <code id="spikeplot_+3A_pch">pch</code>, <code id="spikeplot_+3A_pcol">pcol</code></td>
<td>

<p>First argument is logical.
If <code>TRUE</code> then the others argument are used to place
points at the top using <code><a href="graphics.html#topic+points">points</a></code>
with <code>pcol</code> being its colour.  
See <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_scol">scol</code>, <code id="spikeplot_+3A_slty">slty</code>, <code id="spikeplot_+3A_slwd">slwd</code></td>
<td>

<p>Similar to <code>col</code>, <code>lty</code> and <code>lwd</code> but
apply to some selected values.
The input may be a named list such as
<code>scol = list("green" = c(2, 4, 6), "blue" = 5)</code>,
<code>slty = list("dashed" = c(2, 4, 6), "dotted" = 5)</code>,
<code>slwd = list("2" = c(2, 4, 6), "3" = 5)</code>,
else a named vector such as
<code>scol = c("green" = 2, "green" = 4, "green" = 6, "blue" = 5)</code>,
<code>slty = c("dashed" = 2, "dashed" = 4, "dashed" = 6, "dotted" = 5)</code>,
<code>slwd = c("2" = 2, "2" = 4, "2" = 6, "3" = 5)</code>.
The three arguments are ignored if <code>as.table = TRUE</code>.
</p>



</td></tr>
<tr><td><code id="spikeplot_+3A_new.plot">new.plot</code>, <code id="spikeplot_+3A_offset.x">offset.x</code></td>
<td>

<p>Logical and numeric.
Add to an existing plot? If so, set <code>new.plot = FALSE</code>
and it is useful for
the spikes to be shifted by some amount <code>offset.x</code>. 
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_ymux">ymux</code></td>
<td>

<p>Numeric, y-multiplier. The response is multiplied by <code>ymux</code>.
This can be useful when plotting subsets side-by-side so that
the constituent proportions add up to the overall proportion.
</p>
</td></tr>
<tr><td><code id="spikeplot_+3A_...">...</code></td>
<td>

<p>Additional graphical arguments passed into an ordinary
<code><a href="base.html#topic+plot">plot</a></code>, for example,
<code>xlim</code>, <code>las</code>, <code>main</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Heaping</em> is a very commonly occurring phenomenon in
retrospective self-reported survey data.
Also known as <em>digit preference</em> data,
it is often characterized by an excess of multiples of 10 or 5
upon rounding.
For this type of data
this simple function is meant to be convenient for
plotting the frequencies or sample proportions of
a vector <code>x</code> representing a discrete random variable.
This type of plot
is known as a <em>spike plot</em> in STATA circles.
If <code>table(x)</code> works then this function should hopefully
work.
The default for <code>type</code> means that any heaping and
<em>seeping</em> should easily be seen. 
If such features exist then <em>GAITD regression</em> is
potentially useful&mdash;see <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code> etc.
Currently missing values are ignored totally because
<code>table(x)</code> is used without further arguments;
this might change in the future.
</p>


<h3>Value</h3>

<p>Returns invisibly <code>table(x)</code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+table">table</a></code>,
<code><a href="base.html#topic+plot">plot</a></code>,
<code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="base.html#topic+deparse1">deparse1</a></code>,
<code><a href="#topic+dgaitdplot">dgaitdplot</a></code>,
<code><a href="#topic+plotdgaitd">plotdgaitd</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spikeplot(with(marital.nz, age), col = "pink2", lwd = 2)

## End(Not run)</code></pre>

<hr>
<h2 id='sqrtlink'> Square Root and Folded Square Root Link Functions </h2><span id='topic+foldsqrtlink'></span><span id='topic+sqrtlink'></span>

<h3>Description</h3>

<p>Computes the
square root and
folded square root
transformations,
including their inverse
and their first two derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foldsqrtlink(theta, min = 0, max = 1, mux = sqrt(2),
     inverse = FALSE, deriv = 0, short = TRUE, tag = FALSE)
sqrtlink(theta, inverse = FALSE, deriv = 0, short = TRUE,
         tag = FALSE, c10 = c(2, -2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sqrtlink_+3A_theta">theta</code></td>
<td>

<p>Numeric or character.
See below for further details.
</p>
</td></tr>
<tr><td><code id="sqrtlink_+3A_min">min</code>, <code id="sqrtlink_+3A_max">max</code>, <code id="sqrtlink_+3A_mux">mux</code></td>
<td>

<p>These are called <code class="reqn">L</code>, <code class="reqn">U</code> and <code class="reqn">K</code> below.
</p>
</td></tr>
<tr><td><code id="sqrtlink_+3A_inverse">inverse</code>, <code id="sqrtlink_+3A_deriv">deriv</code>, <code id="sqrtlink_+3A_short">short</code>, <code id="sqrtlink_+3A_tag">tag</code></td>
<td>

<p>Details at <code><a href="#topic+Links">Links</a></code>.
</p>
</td></tr>
<tr><td><code id="sqrtlink_+3A_c10">c10</code></td>
<td>

<p>Numeric, 2-vector <code>c(c1, c0)</code> 
for a linear transformation.
The plain link is multiplied by <code>c1</code>
and then <code>c0</code> is added so that <code>c1 = 1:0</code> is
simply <code><a href="base.html#topic+sqrt">sqrt</a></code>.
The default is intended to match
<code><a href="#topic+lcsloglink">lcsloglink</a></code> for <code><a href="#topic+poissonff">poissonff</a></code>
at <code>lambda</code> (<code>theta</code>) equal to 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The folded square root link function can be applied to
parameters that lie between <code class="reqn">L</code> and <code class="reqn">U</code>
inclusive.
Numerical values of <code>theta</code>
out of range result in <code>NA</code> or <code>NaN</code>.
</p>
























<p>More general information
can be found at <code><a href="#topic+alogitlink">alogitlink</a></code>.
</p>


<h3>Value</h3>

<p>For <code>foldsqrtlink</code> with <code>deriv = 0</code>:
<code class="reqn">K (\sqrt{\theta-L} - \sqrt{U-\theta})</code>
or
<code>mux * (sqrt(theta-min) - sqrt(max-theta))</code>
when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then some more
complicated function that returns a <code>NA</code> unless
<code>theta</code> is between <code>-mux*sqrt(max-min)</code> and
<code>mux*sqrt(max-min)</code>.
</p>
<p>For <code>sqrtlink</code> with <code>deriv = 0</code>
and <code>c10 = 1:0</code>:
<code class="reqn">\sqrt{\theta}</code>
when <code>inverse = FALSE</code>,
and if <code>inverse = TRUE</code> then the square
is returned.
</p>
<p>For <code>deriv = 1</code>, then the function returns
<em>d</em> <code>eta</code> / <em>d</em> <code>theta</code> as a
function of <code>theta</code>
if <code>inverse = FALSE</code>,
else if <code>inverse = TRUE</code> then it
returns the reciprocal.
</p>


<h3>Note</h3>

<p>For <code>foldsqrtlink</code>,
the default has, if <code>theta</code> is 0 or 1,
the link function
value is <code>-sqrt(2)</code> and <code>+sqrt(2)</code>
respectively.
These are finite values, therefore one cannot use
this link function for
general modelling of probabilities because
of numerical problem,
e.g., with <code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>. See
the example below.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>,
<code><a href="#topic+sloglink">sloglink</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- seq(0.01, 0.99, by = 0.01)
foldsqrtlink(p)
max(abs(foldsqrtlink(foldsqrtlink(p), inverse = TRUE) - p))  # 0

p &lt;- c(seq(-0.02, 0.02, by = 0.01), seq(0.97, 1.02, by = 0.01))
foldsqrtlink(p)  # Has NAs

## Not run: 
p &lt;- seq(0.01, 0.99, by = 0.01)
par(mfrow = c(2, 2), lwd = (mylwd &lt;- 2))
y &lt;- seq(-4, 4, length = 100)
for (d in 0:1) {
  matplot(p, cbind(   logitlink(p, deriv = d),
                   foldsqrtlink(p, deriv = d)),
          col = "blue", ylab = "transformation",
          main = ifelse(d == 0, "Some probability links",
          "First derivative"), type = "n", las = 1)
  lines(p,    logitlink(p, deriv = d), col = "green")
  lines(p,   probitlink(p, deriv = d), col = "blue")
  lines(p,  clogloglink(p, deriv = d), col = "red")
  lines(p, foldsqrtlink(p, deriv = d), col = "tan")
  if (d == 0) {
    abline(v = 0.5, h = 0, lty = "dashed")
    legend(0, 4.5, c("logitlink", "probitlink",
                     "clogloglink", "foldsqrtlink"),
           lwd = 2, col = c("green", "blue",
                            "red", "tan"))
  } else
    abline(v = 0.5, lty = "dashed")
}

for (d in 0) {
  matplot(y,
          cbind(   logitlink(y, deriv = d, inverse = TRUE),
                foldsqrtlink(y, deriv = d, inverse = TRUE)),
          type = "n", col = "blue", xlab = "transformation",
          ylab = "p", lwd = 2, las = 1, main = if (d == 0)
          "Some inverse probability link functions" else
          "First derivative")
  lines(y,    logitlink(y, deriv=d, inverse=TRUE), col="green")
  lines(y,   probitlink(y, deriv=d, inverse=TRUE), col="blue")
  lines(y,  clogloglink(y, deriv=d, inverse=TRUE), col="red")
  lines(y, foldsqrtlink(y, deriv=d, inverse=TRUE), col="tan")
  if (d == 0) {
    abline(h = 0.5, v = 0, lty = "dashed")
    legend(-4, 1, c("logitlink", "probitlink",
                    "clogloglink", "foldsqrtlink"), lwd = 2, 
           col = c("green", "blue", "red", "tan"))
  }
}
par(lwd = 1)

## End(Not run)

# This is lucky to converge
fit.h &lt;- vglm(agaaus ~ sm.bs(altitude),
              binomialff(foldsqrtlink(mux = 5)),
              hunua, trace = TRUE)
## Not run: 
plotvgam(fit.h, se = TRUE, lcol = "orange", scol = "orange",
         main = "Orange is Hunua, Blue is Waitakere") 
## End(Not run)
head(predict(fit.h, hunua, type = "response"))

## Not run: 
# The following fails.
pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit &lt;- vglm(cbind(normal, mild, severe) ~ let,
       cumulative(foldsqrtlink(mux = 10), par = TRUE, rev = TRUE),
       data = pneumo, trace = TRUE, maxit = 200) 
## End(Not run)
</code></pre>

<hr>
<h2 id='sratio'> Ordinal Regression with Stopping Ratios </h2><span id='topic+sratio'></span>

<h3>Description</h3>

<p>Fits a stopping ratio logit/probit/cloglog/cauchit/...
regression model to an ordered (preferably) factor response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sratio(link = "logitlink", parallel = FALSE, reverse = FALSE,
       zero = NULL, ynames = FALSE, Thresh = NULL, Trev = reverse,
       Tref = if (Trev) "M" else 1, whitespace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sratio_+3A_link">link</code></td>
<td>

<p>Link function applied to the <code class="reqn">M</code>
stopping ratio probabilities.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="sratio_+3A_parallel">parallel</code></td>
<td>

<p>A logical, or formula specifying which terms have
equal/unequal coefficients.
</p>
</td></tr>
<tr><td><code id="sratio_+3A_reverse">reverse</code></td>
<td>

<p>Logical.
By default, the stopping ratios used are
<code class="reqn">\eta_j = logit(P[Y=j|Y \geq j])</code>
for <code class="reqn">j=1,\dots,M</code>.
If <code>reverse</code> is <code>TRUE</code>, then
<code class="reqn">\eta_j = logit(P[Y=j+1|Y \leq j+1])</code>
will be used.
</p>
</td></tr>
<tr><td><code id="sratio_+3A_ynames">ynames</code></td>
<td>

<p>See <code><a href="#topic+multinomial">multinomial</a></code> for information.
</p>
</td></tr>
<tr><td><code id="sratio_+3A_zero">zero</code></td>
<td>

<p>Can be an integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The values must be from the set {1,2,...,<code class="reqn">M</code>}.
The default value means none are modelled as
intercept-only terms.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="sratio_+3A_thresh">Thresh</code>, <code id="sratio_+3A_trev">Trev</code>, <code id="sratio_+3A_tref">Tref</code></td>
<td>

<p>See <code><a href="#topic+cumulative">cumulative</a></code> for information.
These arguments apply to ordinal
categorical regression models.
</p>
</td></tr>
<tr><td><code id="sratio_+3A_whitespace">whitespace</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this help file the response <code class="reqn">Y</code> is assumed to be a factor
with ordered values <code class="reqn">1,2,\dots,M+1</code>, so that
<code class="reqn">M</code> is the number of linear/additive predictors
<code class="reqn">\eta_j</code>.
</p>
<p>There are a number of definitions for the <em>continuation ratio</em>
in the literature. To make life easier, in the <span class="pkg">VGAM</span> package,
we use <em>continuation</em> ratios (see <code><a href="#topic+cratio">cratio</a></code>)
and <em>stopping</em> ratios.
Continuation ratios deal with quantities such as
<code>logitlink(P[Y&gt;j|Y&gt;=j])</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>No check is made to verify that the response is ordinal if the
response is a matrix;
see <code><a href="base.html#topic+factor">ordered</a></code>.
</p>

<p>Boersch-Supan (2021) considers a sparse data set
(called <code><a href="#topic+budworm">budworm</a></code>)
and the numerical problems encountered when
fitting models such as
<code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+sratio">sratio</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>.
Although improvements to links such as
<code><a href="#topic+clogloglink">clogloglink</a></code> have been made,
currently these family functions have not been
properly adapted to handle sparse data as well as they could.
</p>


<h3>Note</h3>

<p>The response should be either a matrix of counts
(with row sums that
are all positive), or a factor. In both cases,
the <code>y</code> slot
returned by <code>vglm</code>/<code>vgam</code>/<code>rrvglm</code>
is the matrix
of counts.
</p>
<p>For a nominal (unordered) factor response, the multinomial
logit model (<code><a href="#topic+multinomial">multinomial</a></code>) is more appropriate.
</p>
<p>Here is an example of the usage of the <code>parallel</code> argument.
If there are covariates <code>x1</code>, <code>x2</code> and <code>x3</code>, then
<code>parallel = TRUE ~ x1 + x2 -1</code> and
<code>parallel = FALSE ~ x3</code> are equivalent. This would constrain
the regression coefficients for <code>x1</code> and <code>x2</code> to be
equal; those of the intercepts and <code>x3</code> would be different.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Agresti, A. (2013).
<em>Categorical Data Analysis</em>,
3rd ed. Hoboken, NJ, USA: Wiley.
</p>
<p>Boersch-Supan, P. H. (2021).
Modeling insect phenology using ordinal
regression and continuation ratio models.
<em>ReScience C</em>,
<b>7.1</b>, 1&ndash;14.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>




<p>McCullagh, P. and Nelder, J. A. (1989).
<em>Generalized Linear Models</em>,
2nd ed. London: Chapman &amp; Hall.
</p>
<p>Tutz, G. (2012).
<em>Regression for Categorical Data</em>,
Cambridge: Cambridge University Press.
</p>
<p>Yee, T. W. (2010).
The <span class="pkg">VGAM</span> package for categorical data analysis.
<em>Journal of Statistical Software</em>,
<b>32</b>, 1&ndash;34.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>







<h3>See Also</h3>

<p><code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+acat">acat</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>,
<code><a href="#topic+multinomial">multinomial</a></code>,
<code><a href="#topic+CM.equid">CM.equid</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+margeff">margeff</a></code>,
<code><a href="#topic+pneumo">pneumo</a></code>,
<code><a href="#topic+budworm">budworm</a></code>,
<code><a href="#topic+logitlink">logitlink</a></code>,
<code><a href="#topic+probitlink">probitlink</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+cauchitlink">cauchitlink</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let,
             sratio(parallel = TRUE), data = pneumo))
coef(fit, matrix = TRUE)
constraints(fit)
predict(fit)
predict(fit, untransform = TRUE)
</code></pre>

<hr>
<h2 id='step4'>
Choose a model by AIC in a Stepwise Algorithm
</h2><span id='topic+step4'></span><span id='topic+step4vglm'></span>

<h3>Description</h3>

<p>Select a formula-based model by AIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step4(object, ...)
step4vglm(object, scope, direction = c("both", "backward", "forward"),
          trace = 1, keep = NULL, steps = 1000, k = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step4_+3A_object">object</code></td>
<td>

<p>an object of class <code>"vglm"</code>.
This is used as the initial model in the stepwise search.
</p>


</td></tr>
<tr><td><code id="step4_+3A_scope">scope</code></td>
<td>

<p>See <code><a href="stats.html#topic+step">step</a></code>.
</p>




</td></tr>
<tr><td><code id="step4_+3A_direction">direction</code></td>
<td>

<p>See <code><a href="stats.html#topic+step">step</a></code>.
</p>






</td></tr>





<tr><td><code id="step4_+3A_trace">trace</code>, <code id="step4_+3A_keep">keep</code></td>
<td>

<p>See <code><a href="stats.html#topic+step">step</a></code>.
</p>




</td></tr>
<tr><td><code id="step4_+3A_steps">steps</code>, <code id="step4_+3A_k">k</code></td>
<td>

<p>See <code><a href="stats.html#topic+step">step</a></code>.
</p>



</td></tr>






<tr><td><code id="step4_+3A_...">...</code></td>
<td>

<p>any additional arguments to
<code><a href="#topic+extractAIC.vglm">extractAIC.vglm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code> and
<code><a href="#topic+add1.vglm">add1.vglm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a direct adaptation of
<code><a href="stats.html#topic+step">step</a></code>
for <code><a href="#topic+vglm-class">vglm-class</a></code> objects.
Since <code><a href="stats.html#topic+step">step</a></code> is not generic,
the name <code>step4()</code> was adopted
and it <em>is</em> generic, as well as being S4 rather than S3.
It is the intent that this function should work as similar as
possible to <code><a href="stats.html#topic+step">step</a></code>.
</p>
<p>Internally, the methods function for <code><a href="#topic+vglm-class">vglm-class</a></code>
objects calls <code><a href="#topic+add1.vglm">add1.vglm</a></code> and
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>
repeatedly.
</p>



























<h3>Value</h3>

<p>The results are placed in the <code>post</code> slot of the
stepwise-selected model that is returned.
There are up to two additional components.
There is an <code>"anova"</code>
component corresponding to the steps taken in the search,
as well as a <code>"keep"</code> component if the <code>keep=</code> argument
was supplied in the call.
</p>










<h3>Warning</h3>

<p>In general,
the same warnings in
<code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code> and
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>
apply here.
</p>
<p>This function
</p>









<h3>See Also</h3>

<p><code><a href="#topic+add1.vglm">add1.vglm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+trim.constraints">trim.constraints</a></code>,
<code><a href="stats.html#topic+add1.glm">add1.glm</a></code>,
<code><a href="stats.html#topic+drop1.glm">drop1.glm</a></code>,
<code><a href="#topic+backPain2">backPain2</a></code>,
<code><a href="stats.html#topic+step">step</a></code>,
<code><a href="stats.html#topic+update">update</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>data("backPain2", package = "VGAM")
summary(backPain2)
fit1 &lt;- vglm(pain ~ x2 + x3 + x4 + x2:x3 + x2:x4 + x3:x4,
             propodds, data = backPain2)
spom1 &lt;- step4(fit1)
summary(spom1)
spom1@post$anova
</code></pre>

<hr>
<h2 id='studentt'> Student t Distribution </h2><span id='topic+studentt'></span><span id='topic+studentt2'></span><span id='topic+studentt3'></span>

<h3>Description</h3>

<p>Estimating the parameters of a Student t distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>studentt (ldf = "logloglink", idf = NULL, tol1 = 0.1, imethod = 1)
studentt2(df = Inf, llocation = "identitylink", lscale = "loglink",
          ilocation = NULL, iscale = NULL, imethod = 1, zero = "scale")
studentt3(llocation = "identitylink", lscale = "loglink",
          ldf = "logloglink", ilocation = NULL, iscale = NULL,
          idf = NULL, imethod = 1, zero = c("scale", "df"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="studentt_+3A_llocation">llocation</code>, <code id="studentt_+3A_lscale">lscale</code>, <code id="studentt_+3A_ldf">ldf</code></td>
<td>

<p>Parameter link functions for each parameter,
e.g., for degrees of freedom <code class="reqn">\nu</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The defaults ensures the parameters are in range.
A <code><a href="#topic+loglog">loglog</a></code> link keeps the degrees of freedom greater
than unity; see below.
</p>
</td></tr>
<tr><td><code id="studentt_+3A_ilocation">ilocation</code>, <code id="studentt_+3A_iscale">iscale</code>, <code id="studentt_+3A_idf">idf</code></td>
<td>

<p>Optional initial values.
If given, the values must be in range.
The default is to compute an initial value internally.
</p>
</td></tr>
<tr><td><code id="studentt_+3A_tol1">tol1</code></td>
<td>

<p>A positive value, the tolerance for testing whether an
initial value is 1.
Best to leave this argument alone.
</p>
</td></tr>
<tr><td><code id="studentt_+3A_df">df</code></td>
<td>

<p>Numeric, user-specified degrees of freedom.
It may be of length equal to the number of columns of a
response matrix.
</p>
</td></tr>
<tr><td><code id="studentt_+3A_imethod">imethod</code>, <code id="studentt_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Student t density function is
</p>
<p style="text-align: center;"><code class="reqn">f(y;\nu) = \frac{\Gamma((\nu+1)/2)}{\sqrt{\nu \pi} \Gamma(\nu/2)}
             \left(1 + \frac{y^2}{\nu} \right)^{-(\nu+1)/2}</code>
</p>

<p>for all real <code class="reqn">y</code>.
Then <code class="reqn">E(Y)=0</code> if <code class="reqn">\nu&gt;1</code> (returned as the fitted values),
and <code class="reqn">Var(Y)= \nu/(\nu-2)</code>
for <code class="reqn">\nu &gt; 2</code>.
When <code class="reqn">\nu=1</code> then the Student <code class="reqn">t</code>-distribution
corresponds to the standard Cauchy distribution,
<code><a href="#topic+cauchy1">cauchy1</a></code>.
When <code class="reqn">\nu=2</code> with a scale parameter of <code>sqrt(2)</code> then
the Student <code class="reqn">t</code>-distribution
corresponds to the standard (Koenker) distribution,
<code><a href="#topic+sc.studentt2">sc.studentt2</a></code>.
The degrees of freedom can be treated as a parameter to be estimated,
and as a real and not an integer.
The Student t distribution is used for a variety of reasons
in statistics, including robust regression.
</p>
<p>Let <code class="reqn">Y = (T - \mu) / \sigma</code> where
<code class="reqn">\mu</code> and <code class="reqn">\sigma</code> are the location
and scale parameters respectively.
Then <code>studentt3</code> estimates the location, scale and
degrees of freedom parameters.
And <code>studentt2</code> estimates the location, scale parameters
for a user-specified degrees of freedom, <code>df</code>.
And <code>studentt</code> estimates the degrees of freedom parameter
only.
The fitted values are the location parameters.
By default the linear/additive predictors are
<code class="reqn">(\mu, \log(\sigma), \log\log(\nu))^T</code>
or subsets thereof.
</p>
<p>In general convergence can be slow, especially when there are
covariates.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code>, and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p><code>studentt3()</code> and <code>studentt2()</code> can handle multiple
responses.
</p>
<p>Practical experience has shown reasonably good initial values
are required. If convergence failure occurs try using arguments
such as <code>idf</code>.
Local solutions are also possible, especially when
the degrees of freedom is close to unity or
the scale parameter is close to zero.
</p>
<p>A standard normal distribution corresponds to a <em>t</em>
distribution with infinite degrees of freedom. Consequently, if
the data is close to normal, there may be convergence problems;
best to use <code><a href="#topic+uninormal">uninormal</a></code> instead.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Student (1908).
The probable error of a mean.
<em>Biometrika</em>, <b>6</b>, 1&ndash;25.
</p>
<p>Zhu, D. and Galbraith, J. W. (2010).
A generalized asymmetric Student-<em>t</em> distribution with
application to financial econometrics.
<em>Journal of Econometrics</em>, <b>157</b>, 297&ndash;305.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+cauchy1">cauchy1</a></code>,
<code><a href="#topic+logistic">logistic</a></code>,
<code><a href="#topic+huber2">huber2</a></code>,
<code><a href="#topic+sc.studentt2">sc.studentt2</a></code>,
<code><a href="stats.html#topic+TDist">TDist</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
tdata &lt;- transform(tdata, y1 = rt(nn, df = exp(exp(0.5 - x2))),
                          y2 = rt(nn, df = exp(exp(0.5 - x2))))
fit1 &lt;- vglm(y1 ~ x2, studentt, data = tdata, trace = TRUE)
coef(fit1, matrix = TRUE)

# df inputted into studentt2() not quite right:
fit2 &lt;- vglm(y1 ~ x2, studentt2(df = exp(exp(0.5))), tdata)
coef(fit2, matrix = TRUE)

fit3 &lt;- vglm(cbind(y1, y2) ~ x2, studentt3, tdata, trace = TRUE)
coef(fit3, matrix = TRUE)
</code></pre>

<hr>
<h2 id='summary.drrvglm'>Summarizing
Reduced Rank
Vector Generalized Linear Model (RR-VGLM) and
Doubly constrained RR-VGLM Fits
</h2><span id='topic+summary.drrvglm'></span><span id='topic+summary.rrvglm'></span><span id='topic+show.summary.drrvglm'></span><span id='topic+show.summary.rrvglm'></span>

<h3>Description</h3>

<p>These functions are all <code><a href="utils.html#topic+methods">methods</a></code>
for class <code>"drrvglm"</code> or
<code>"summary.drrvglm"</code> objects, or
for class <code>"rrvglm"</code> or
<code>"summary.rrvglm"</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'drrvglm'
summary(object, correlation = FALSE, dispersion = NULL,
    digits = NULL, numerical = TRUE, h.step = 0.0001, omit123 = FALSE,
     omit13 = FALSE, fixA = FALSE, presid = TRUE,
    signif.stars = getOption("show.signif.stars"),
    eval0 = TRUE, nopredictors = FALSE, ...)
## S3 method for class 'summary.drrvglm'
show(x, digits = NULL,
    quote = TRUE, prefix = "", signif.stars = NULL)
## S3 method for class 'rrvglm'
summary(object, correlation = FALSE, dispersion = NULL,
    digits = NULL, numerical = TRUE, h.step = 0.0001, omit123 = FALSE,
     omit13 = FALSE, fixA = FALSE, presid = TRUE,
    signif.stars = getOption("show.signif.stars"), nopredictors = FALSE, ...)
## S3 method for class 'summary.rrvglm'
show(x, digits = NULL,
    quote = TRUE, prefix = "", signif.stars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.drrvglm_+3A_object">object</code></td>
<td>
<p>an object of class
<code>"drrvglm"</code> or <code>"rrvglm"</code>,
a result of a call to
<code><a href="#topic+rrvglm">rrvglm</a></code>.</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_x">x</code></td>
<td>
<p>an object of class
<code>"summary.drrvglm"</code> or
<code>"summary.rrvglm"</code>,
a result of a call to
<code><a href="#topic+summary.drrvglm">summary.drrvglm</a></code> or
<code><a href="#topic+summary.rrvglm">summary.rrvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_dispersion">dispersion</code></td>
<td>

<p>used mainly for GLMs.
Not really implemented in <span class="pkg">VGAM</span> so
should not be used.

</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_correlation">correlation</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_digits">digits</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_signif.stars">signif.stars</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_presid">presid</code>, <code id="summary.drrvglm_+3A_quote">quote</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_nopredictors">nopredictors</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>

<tr><td><code id="summary.drrvglm_+3A_numerical">numerical</code></td>
<td>
<p>Logical,
use a finite difference approximation
for partial derivatives?
If <code>FALSE</code> then theoretical formulas
are used (however this option may no longer
be implemented).
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_h.step">h.step</code></td>
<td>
<p>Numeric,
positive and close to 0.
If <code>numerical</code> then
this is the forward step
for each finite difference approximation.
That is, it plays the role of
<code class="reqn">h</code> in <code class="reqn">(f(x+h)-f(x))/h</code> for
some function <code class="reqn">f</code>.
If the overall variance-covariance matrix
is not positive-definite, varying
this argument might make a difference.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_fixa">fixA</code></td>
<td>
<p>Logical,
if <code>TRUE</code> then the largest block matrix
is for <b>B1</b> and <b>C</b>, else
it is for <b>A</b> and <b>B1</b>.
This should not make any difference because
both estimates of <b>B1</b> should be
extremely similar, including the SEs.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_omit13">omit13</code></td>
<td>
<p>Logical,
if <code>TRUE</code> then the (1,3) block matrix
is set to <b>O</b>. That is,
<b>A</b> and <b>C</b> are assumed to
asymptotically uncorrelated.
Setting this <code>TRUE</code> is an option when
<b>V</b> (see below) is not
positive-definite.
If this fails,
another option that is often better
is to set <code>omit123 = TRUE</code>.
</p>

</td></tr>
<tr><td><code id="summary.drrvglm_+3A_omit123">omit123</code></td>
<td>
<p>Logical.
If <code>TRUE</code> then <em>two</em>
block matrices are set to <b>O</b>
(blocks (1,2) and (1,3), else
blocks (1,3) and (2,3),
depending on <code>fixA</code>),
This will almost surely result in an
overall variance-covariance matrix
that is positive-definite, however, the
SEs will be biased.
This argument is more extreme than
<code>omit13</code>.
</p>

</td></tr>






<tr><td><code id="summary.drrvglm_+3A_prefix">prefix</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_eval0">eval0</code></td>
<td>

<p>Logical.
Check if <b>V</b> is positive-definite?
That is, all its eigenvalues are positive.
</p>
</td></tr>
<tr><td><code id="summary.drrvglm_+3A_...">...</code></td>
<td>

<p>Logical argument <code>check.2</code> might work here.
If <code>TRUE</code> then some quantities
are printed out, for checking and debugging.
</p>

</td></tr>
</table>


<h3>Details</h3>

<p>Most of this document concerns DRR-VGLMs but
also apply equally well to RR-VGLMs as a special
case.
</p>
<p>The overall variance-covariance matrix
The overall variance-covariance matrix
(called <b>V</b> below)
is computed. Since the parameters
comprise the elements of
the matrices <b>A</b>, <b>B1</b> and <b>C</b>
(called here block matrices 1, 2, 3
respectively), 
and an alternating algorithm is used for
estimation, then there are two overlapping
submodels that are fitted within an IRLS
algorithm. These have blocks 1 and 2, and
2 and 3, so that <b>B1</b> is common to both.
They are combined into one large overall
variance-covariance matrix.
Argument <code>fixA</code> specifies which submodel
the <b>B1</b> block is taken from.
Block (1,3) is the most difficult to
compute and numerical approximations based on
first derivatives are used by default for this.
</p>
<p>Sometimes the computed <b>V</b>
is not positive-definite.
If so,
then the standard errors will be <code>NA</code>.
To avoid this problem,
try varying <code>h.step</code>
or refitting the model with a different
<code>Index.corner</code>.
Argument <code>omit13</code> and
<code>omit123</code>
can also be used to
give approximate answers.
If <b>V</b> is not positive-definite
then this may indicate
that the model does not fit the
data very well, e.g.,
<code>Rank</code> is not a good value.
Potentially, there are many ways why
the model may be ill-conditioned.
Try several options and set <code>trace = TRUE</code>
to monitor convergence&mdash;this is informative
about how well the model and data agree.
</p>
<p>How can one fit an ordinary RR-VGLM as
a DRR-VGLM?
If one uses corner constraints (default) then
one should input <code>H.A</code> as a list
containing <code>Rank</code> <code>diag(M)</code>
matrices&mdash;one for each column of <b>A</b>.
Then since <code>Corner = TRUE</code>
by default, then
<code>object@H.A.thy</code> has certain columns
deleted due to corner constraints.
The suffix <code>thy</code> stands for <em>theory</em>.
In contrast, 
<code>object@H.A.alt</code> is the
<code>H.A</code> that was inputted, and the
<code>alt</code> suffix indicates the alternating
algorithm.
</p>
<p>Note that <code><a href="stats.html#topic+vcov">vcov</a></code>
methods exist for <code><a href="#topic+rrvglm-class">rrvglm-class</a></code>
and <code><a href="#topic+drrvglm-class">drrvglm-class</a></code> objects.
</p>


<h3>Value</h3>

<p><code>summarydrrvglm</code> returns an object
of class <code>"summary.drrvglm"</code>.
</p>



<h3>Warning </h3>

<p>DRR-VGLMs are a recent development so
it will take some time to get things
totally ironed out.
RR-VGLMs were developed a long time ago and
are more well-established, however they
have only recently been documented here.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.  </p>


<h3>References</h3>

<p>Chapter 5 of:
Yee, T. W. (2015).
Vector Generalized Linear and Additive Models:
With an Implementation in R.
New York, USA: <em>Springer</em>.
Sections 5.2.2 and 5.3 are particularly relevant.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rrvglm.control">rrvglm.control</a></code>,
<code><a href="#topic+vcovdrrvglm">vcovdrrvglm</a></code>,
<code><a href="#topic+CM.free">CM.free</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="#topic+summary.rrvglm-class">summary.rrvglm-class</a></code>,
<code><a href="#topic+summary.drrvglm-class">summary.drrvglm-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Fit a rank-1 RR-VGLM as a DRR-VGLM.
set.seed(1); n &lt;- 1000; S &lt;- 6  # S must be even
myrank &lt;- 1
rdata &lt;- data.frame(x1 = runif(n), x2 = runif(n),
           x3 = runif(n), x4 = runif(n))
dval &lt;- ncol(rdata)  # Number of covariates
# Involves x1, x2, ... a rank-1 model:
ymatrix &lt;- with(rdata,
  matrix(rpois(n*S, exp(3 + x1 - 0.5*x2)), n, S))
H.C &lt;- vector("list", dval)  # Ordinary "rrvglm"
for (i in 1:dval) H.C[[i]] &lt;- CM.free(myrank)
names(H.C) &lt;- paste0("x", 1:dval)
H.A &lt;- list(CM.free(S))  # rank-1

rfit1 &lt;- rrvglm(ymatrix ~ x1 + x2 + x3 + x4,
           poissonff, rdata, trace = TRUE)
class(rfit1)
dfit1 &lt;- rrvglm(ymatrix ~ x1 + x2 + x3 + x4,
           poissonff, rdata, trace = TRUE,
           H.A = H.A,    # drrvglm
           H.C = H.C)    # drrvglm
class(dfit1)
Coef(rfit1)  # The RR-VGLM is the same as
Coef(dfit1)  # the DRR-VGLM.
max(abs(predict(rfit1) - predict(dfit1)))  # 0
abs(logLik(rfit1) - logLik(dfit1))  # 0
## Not run: 
summary(rfit1)
summary(dfit1)

## End(Not run)
</code></pre>

<hr>
<h2 id='summarypvgam'>Summarizing Penalized Vector Generalized Additive Model Fits</h2><span id='topic+summarypvgam'></span><span id='topic+show.summary.pvgam'></span>

<h3>Description</h3>

<p>These functions are all <code><a href="utils.html#topic+methods">methods</a></code> for class <code>"pvgam"</code> or
<code>summary.pvgam</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarypvgam(object, dispersion = NULL, digits = options()$digits - 2,
            presid = TRUE)
## S3 method for class 'summary.pvgam'
show(x, quote = TRUE, prefix = "", digits = options()$digits -
    2, signif.stars = getOption("show.signif.stars"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarypvgam_+3A_object">object</code></td>
<td>
<p>an object of class <code>"pvgam"</code>,
which is the result of a
call to <code><a href="#topic+vgam">vgam</a></code> with at least one
<code><a href="#topic+sm.os">sm.os</a></code> or
<code><a href="#topic+sm.ps">sm.ps</a></code> term.
</p>
</td></tr>
<tr><td><code id="summarypvgam_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.pvgam"</code>,
which is the result of a call to <code>summarypvgam()</code>.
</p>
</td></tr>
<tr><td><code id="summarypvgam_+3A_dispersion">dispersion</code>, <code id="summarypvgam_+3A_digits">digits</code>, <code id="summarypvgam_+3A_presid">presid</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summarypvgam_+3A_quote">quote</code>, <code id="summarypvgam_+3A_prefix">prefix</code>, <code id="summarypvgam_+3A_signif.stars">signif.stars</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This methods function reports a summary more similar to
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code> from <span class="pkg">mgcv</span> than
<code>summary.gam()</code> from <span class="pkg">gam</span>.
It applies to G2-VGAMs using
<code><a href="#topic+sm.os">sm.os</a></code> and O-splines, else
<code><a href="#topic+sm.ps">sm.ps</a></code> and P-splines.
In particular, the hypothesis test for whether each
<code><a href="#topic+sm.os">sm.os</a></code> or
<code><a href="#topic+sm.ps">sm.ps</a></code>
term can be deleted follows quite closely to
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code>.
The p-values from this type of test tend to be biased downwards (too
small)
and corresponds to <code>p.type = 5</code>.
It is hoped in the short future that improved p-values be implemented,
somewhat like the default of
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code>.
This methods function was adapted from
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code>.
</p>


<h3>Value</h3>

<p><code>summarypvgam</code> returns an object of class <code>"summary.pvgam"</code>;
see <code><a href="#topic+summary.pvgam-class">summary.pvgam-class</a></code>.
</p>


<h3>Warning </h3>

<p>See <code><a href="#topic+sm.os">sm.os</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+summaryvgam">summaryvgam</a></code>,
<code><a href="#topic+summary.pvgam-class">summary.pvgam-class</a></code>,
<code><a href="#topic+sm.os">sm.os</a></code>,
<code><a href="#topic+sm.ps">sm.ps</a></code>,
<code><a href="stats.html#topic+summary.glm">summary.glm</a></code>,
<code><a href="stats.html#topic+summary.lm">summary.lm</a></code>,
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code> from <span class="pkg">mgcv</span>, 
<code><a href="#topic+summaryvgam">summaryvgam</a></code> for G1-VGAMs.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>hfit2 &lt;- vgam(agaaus ~ sm.os(altitude), binomialff, data = hunua)
coef(hfit2, matrix = TRUE)
summary(hfit2)
</code></pre>

<hr>
<h2 id='summaryvgam'>Summarizing Vector Generalized Additive Model Fits</h2><span id='topic+summaryvgam'></span><span id='topic+show.summary.vgam'></span>

<h3>Description</h3>

<p>These functions are all <code><a href="utils.html#topic+methods">methods</a></code> for class <code>vgam</code> or
<code>summary.vgam</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryvgam(object, dispersion = NULL, digits = options()$digits - 2,
            presid = TRUE, nopredictors = FALSE)
## S3 method for class 'summary.vgam'
show(x, quote = TRUE, prefix = "",
                            digits = options()$digits-2, nopredictors = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryvgam_+3A_object">object</code></td>
<td>
<p>an object of class <code>"vgam"</code>,
which is the result of a
call to <code><a href="#topic+vgam">vgam</a></code> with at least one <code><a href="#topic+s">s</a></code> term.
</p>
</td></tr>
<tr><td><code id="summaryvgam_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.vgam"</code>,
which is the result of a call to <code>summaryvgam()</code>.
</p>
</td></tr>
<tr><td><code id="summaryvgam_+3A_dispersion">dispersion</code>, <code id="summaryvgam_+3A_digits">digits</code>, <code id="summaryvgam_+3A_presid">presid</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summaryvgam_+3A_quote">quote</code>, <code id="summaryvgam_+3A_prefix">prefix</code>, <code id="summaryvgam_+3A_nopredictors">nopredictors</code></td>
<td>

<p>See <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This methods function reports a summary more similar to
<code>summary.gam()</code> from <span class="pkg">gam</span> than
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code> from <span class="pkg">mgcv</span>.
It applies to G1-VGAMs using <code><a href="#topic+s">s</a></code> and vector backfitting.
In particular, an approximate score test for <em>linearity</em> is conducted
for each <code><a href="#topic+s">s</a></code> term&mdash;see Section 4.3.4 of Yee (2015) for details.
The p-values from this type of test tend to be biased upwards (too large).
</p>


<h3>Value</h3>

<p><code>summaryvgam</code> returns an object of class <code>"summary.vgam"</code>;
see <code><a href="#topic+summary.vgam-class">summary.vgam-class</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="stats.html#topic+summary.glm">summary.glm</a></code>,
<code><a href="stats.html#topic+summary.lm">summary.lm</a></code>,
<code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code> from <span class="pkg">mgcv</span>,  
<code><a href="#topic+summarypvgam">summarypvgam</a></code> for P-VGAMs.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>hfit &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, data = hunua)
summary(hfit)
summary(hfit)@anova  # Table for (approximate) testing of linearity
</code></pre>

<hr>
<h2 id='summaryvglm'>Summarizing Vector Generalized Linear Model Fits</h2><span id='topic+summaryvglm'></span><span id='topic+show.summary.vglm'></span>

<h3>Description</h3>

<p>These functions are all <code><a href="utils.html#topic+methods">methods</a></code> for
class <code>vglm</code> or
<code>summary.vglm</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryvglm(object, correlation = FALSE, dispersion = NULL,
            digits = NULL, presid = FALSE,
            HDEtest = TRUE, hde.NA = TRUE, threshold.hde = 0.001,
            signif.stars = getOption("show.signif.stars"),
            nopredictors = FALSE,
            lrt0.arg = FALSE, score0.arg = FALSE, wald0.arg = FALSE,
            values0 = 0, subset = NULL, omit1s = TRUE,
            ...)
## S3 method for class 'summary.vglm'
show(x, digits = max(3L, getOption("digits") - 3L),
           quote = TRUE, prefix = "", presid = length(x@pearson.resid) &gt; 0,
           HDEtest = TRUE, hde.NA = TRUE, threshold.hde = 0.001,
           signif.stars = NULL, nopredictors = NULL,
           top.half.only = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryvglm_+3A_object">object</code></td>
<td>
<p>an object of class <code>"vglm"</code>, usually, a result of a
call to <code><a href="#topic+vglm">vglm</a></code>.</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.vglm"</code>, usually,
a result of a call to <code>summaryvglm()</code>.</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_dispersion">dispersion</code></td>
<td>

<p>used mainly for GLMs.
See <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>. </p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_correlation">correlation</code></td>
<td>
<p>logical; if <code>TRUE</code>, the correlation matrix of
the estimated parameters is returned and printed.</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing. </p>
</td></tr>


<tr><td><code id="summaryvglm_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical;
if <code>TRUE</code>, &lsquo;significance stars&rsquo;
are printed for each coefficient. </p>
</td></tr>

<tr><td><code id="summaryvglm_+3A_presid">presid</code></td>
<td>
<p>Pearson residuals;
print out some summary statistics of these? 
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_hdetest">HDEtest</code></td>
<td>
<p>logical;
if <code>TRUE</code> (the default) then a test for the HDE is performed,
else all arguments related to the HDE are ignored.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_hde.na">hde.NA</code></td>
<td>
<p>logical;
if a test for the Hauck-Donner effect is done
(for each coefficient)
and it is affirmative should that Wald test p-value be replaced by
an <code>NA</code>? 
The default is to do so.
Setting <code>hde.NA = FALSE</code> will print the p-value even though
it will be biased upwards.
Also see argument <code>threshold.hde</code>.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_threshold.hde">threshold.hde</code></td>
<td>
<p>numeric;
used if <code>hde.NA = TRUE</code> and is present for some coefficients.
Only p-values greater than this argument will be replaced by
an <code>NA</code>,
the reason being that small p-values will already be
statistically significant.
Hence setting <code>threshold.hde = 0</code> will print out a <code>NA</code>
if the HDE is present.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_quote">quote</code></td>
<td>
<p> Fed into <code>print()</code>. </p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_nopredictors">nopredictors</code></td>
<td>
<p> logical;
if <code>TRUE</code> the names of the linear predictors
are not printed out.
The default is that they are.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_lrt0.arg">lrt0.arg</code>, <code id="summaryvglm_+3A_score0.arg">score0.arg</code>, <code id="summaryvglm_+3A_wald0.arg">wald0.arg</code></td>
<td>

<p>Logical.
If <code>lrt0.arg = TRUE</code> then the other
arguments are passed into <code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>
and the equivalent of the so-called Wald table is outputted.
Similarly,
if <code>score0.arg = TRUE</code> then the other
arguments are passed into <code><a href="#topic+score.stat.vlm">score.stat.vlm</a></code>
and the equivalent of the so-called Wald table is outputted.
Similarly,
if <code>wald0.arg = TRUE</code> then the other
arguments are passed into <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>
and the Wald table corresponding to that is outputted.
See details below.
Setting any of these will result in further IRLS iterations being
performed, therefore may be computationally expensive.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_values0">values0</code>, <code id="summaryvglm_+3A_subset">subset</code>, <code id="summaryvglm_+3A_omit1s">omit1s</code></td>
<td>

<p>These arguments are used if any of the
<code>lrt0.arg</code>,
<code>score0.arg</code>,
<code>wald0.arg</code> arguments are used.
They are passed into the appropriate function,
such as <code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_top.half.only">top.half.only</code></td>
<td>

<p>logical; if <code>TRUE</code> then only print out the top half
of the usual output.
Used for P-VGAMs.
</p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_prefix">prefix</code></td>
<td>
<p> Not used. </p>
</td></tr>
<tr><td><code id="summaryvglm_+3A_...">...</code></td>
<td>
<p> Not used. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Originally,  <code>summaryvglm()</code> was written to be
very similar to <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>,
however now there are a quite a few more options available.
By default,
<code>show.summary.vglm()</code> tries to be smart about formatting the
coefficients, standard errors, etc. and additionally gives
&lsquo;significance stars&rsquo; if <code>signif.stars</code> is <code>TRUE</code>.
The <code>coefficients</code> component of the result gives the estimated
coefficients and their estimated standard errors, together with their
ratio.
This third column is labelled <code>z value</code> regardless of
whether the
dispersion is estimated or known
(or fixed by the family).  A fourth column gives the two-tailed
p-value corresponding to the z ratio based on a
Normal reference distribution.






In general, the t distribution is not used, but the normal
distribution is.
</p>


<p>Correlations are printed to two decimal places (or symbolically): to
see the actual correlations print <code>summary(object)@correlation</code>
directly.
</p>










<p>The Hauck-Donner effect (HDE) is tested for almost all models;
see <code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code> for details.
Arguments <code>hde.NA</code> and <code>threshold.hde</code> here are meant
to give some control of the output if this aberration of the
Wald statistic occurs (so that the p-value is biased upwards).
If the HDE is present then using <code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>
to get a more accurate p-value is a good
alternative as p-values based on the likelihood ratio test (LRT)
tend to be more accurate than Wald tests and do not suffer
from the HDE.
Alternatively, if the HDE is present
then using <code>wald0.arg = TRUE</code>
will compute Wald statistics that are HDE-free; see
<code><a href="#topic+wald.stat">wald.stat</a></code>.
</p>
<p>The arguments <code>lrt0.arg</code> and <code>score0.arg</code>
enable the so-called Wald table to be replaced by
the equivalent LRT and Rao score test table;
see
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+score.stat">score.stat</a></code>.
Further IRLS iterations are performed for both of these,
hence the computational cost might be significant.

</p>
<p>It is possible for programmers to write a methods function to
print out extra quantities when <code>summary(vglmObject)</code> is
called.
The generic function is <code>summaryvglmS4VGAM()</code>, and one
can use the S4 function <code><a href="methods.html#topic+setMethod">setMethod</a></code> to
compute the quantities needed.
Also needed is the generic function is <code>showsummaryvglmS4VGAM()</code>
to actually print the quantities out.

</p>


<h3>Value</h3>

<p><code>summaryvglm</code> returns an object of class <code>"summary.vglm"</code>;
see <code><a href="#topic+summary.vglm-class">summary.vglm-class</a></code>.
</p>


<h3>Warning </h3>

<p>Currently the SE column is deleted
when <code>lrt0 = TRUE</code> because SEs are not so meaningful with the LRT.
In the future an SE column may be inserted (with <code>NA</code> values)
so that it has 4-column output like the other tests.
In the meantime,
the columns of this matrix should be accessed by name and not number.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee.  </p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="#topic+vcovvlm">vcovvlm</a></code>,
<code><a href="#topic+summary.rrvglm">summary.rrvglm</a></code>,
<code><a href="stats.html#topic+summary.glm">summary.glm</a></code>,
<code><a href="stats.html#topic+summary.lm">summary.lm</a></code>,
<code><a href="base.html#topic+summary">summary</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>,
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+score.stat">score.stat</a></code>,
<code><a href="#topic+wald.stat">wald.stat</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## For examples see example(glm)
pneumo &lt;- transform(pneumo, let = log(exposure.time))
(afit &lt;- vglm(cbind(normal, mild, severe) ~ let, acat, data = pneumo))
coef(afit, matrix = TRUE)
summary(afit)  # Might suffer from the Hauck-Donner effect
coef(summary(afit))
summary(afit, lrt0 = TRUE, score0 = TRUE, wald0 = TRUE)
</code></pre>

<hr>
<h2 id='SURff'> Seemingly Unrelated Regressions Family Function

</h2><span id='topic+SURff'></span>

<h3>Description</h3>

<p>Fits a system of seemingly unrelated regressions.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>SURff(mle.normal = FALSE,
      divisor = c("n", "n-max(pj,pk)", "sqrt((n-pj)*(n-pk))"),
      parallel = FALSE, Varcov = NULL, matrix.arg = FALSE)
</code></pre>


<h3>Arguments</h3>






<table>
<tr><td><code id="SURff_+3A_mle.normal">mle.normal</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the MLE, assuming multivariate normal errors,
is computed;
the effect is just to add a <code>loglikelihood</code> slot to the
returned object.
Then it results in the <em>maximum likelihood estimator</em>.
</p>
</td></tr>
<tr><td><code id="SURff_+3A_divisor">divisor</code></td>
<td>

<p>Character, partial matching allowed and the first choice is the default.
The divisor for the estimate of the covariances.
If <code>"n"</code> then the estimate will be biased.
If the others then the estimate will be unbiased for some elements.
If <code>mle.normal = TRUE</code> and this argument is not <code>"n"</code> then
a warning or an error will result.
</p>
</td></tr>
<tr><td><code id="SURff_+3A_parallel">parallel</code></td>
<td>

<p>See
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
If <code>parallel = TRUE</code> then the constraint applies to
the intercept too.
</p>
</td></tr>
<tr><td><code id="SURff_+3A_varcov">Varcov</code></td>
<td>

<p>Numeric.
This may be assigned a variance-covariance of the errors.
If <code>matrix.arg</code> then this is a <code class="reqn">M \times M</code> matrix.
If <code>!matrix.arg</code> then this is a <code class="reqn">M \times M</code> matrix in
matrix-band format (a vector with at least <code class="reqn">M</code> and
at most <code>M*(M+1)/2</code> elements).
</p>
</td></tr>
<tr><td><code id="SURff_+3A_matrix.arg">matrix.arg</code></td>
<td>

<p>Logical.
Of single length.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Proposed by Zellner (1962), the basic
seemingly unrelated regressions (SUR)
model is a set of LMs (<code class="reqn">M &gt; 1</code> of them) tied together
at the error term level.
Each LM's model matrix may potentially have its own set
of predictor variables.
</p>
<p>Zellner's efficient (ZEF) estimator (also known as
<em>Zellner's two-stage Aitken estimator</em>)
can be obtained by setting
<code>maxit = 1</code>
(and possibly <code>divisor = "sqrt"</code> or
<code>divisor = "n-max"</code>).
</p>
<p>The default value of <code>maxit</code> (in <code><a href="#topic+vglm.control">vglm.control</a></code>)
probably means <em>iterative GLS</em> (IGLS) estimator is computed because
IRLS will probably iterate to convergence.
IGLS means, at each iteration, the residuals are used to estimate
the error variance-covariance matrix, and then the matrix is used
in the GLS.
The IGLS estimator is also known
as <em>Zellner's iterative Aitken estimator</em>, or IZEF.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>The default convergence criterion may be a little loose.
Try setting <code>epsilon = 1e-11</code>, especially
with <code>mle.normal =  TRUE</code>.
</p>


<h3>Note</h3>

<p>The fitted object has slot <code>@extra$ncols.X.lm</code> which is
a <code class="reqn">M</code> vector with the number of parameters for each LM.
Also, <code>@misc$values.divisor</code> is the <code class="reqn">M</code>-vector of
<code>divisor</code> values.
</p>
<p>Constraint matrices are needed in order to specify which response
variables that each term on the RHS of the formula is a
regressor for.
See the <code>constraints</code> argument of <code><a href="#topic+vglm">vglm</a></code>
for more information.
</p>



<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>References</h3>

<p>Zellner, A. (1962).
An Efficient Method of Estimating Seemingly Unrelated
Regressions and Tests for Aggregation Bias.
<em>J. Amer. Statist. Assoc.</em>,
<b>57</b>(298), 348&ndash;368.
</p>
<p>Kmenta, J. and Gilbert, R. F. (1968).
Small Sample Properties of Alternative Estimators
of Seemingly Unrelated Regressions.
<em>J. Amer. Statist. Assoc.</em>,
<b>63</b>(324), 1180&ndash;1200.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+gew">gew</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Obtain some of the results of p.1199 of Kmenta and Gilbert (1968)
clist &lt;- list("(Intercept)" = diag(2),
              "capital.g"   = rbind(1, 0),
              "value.g"     = rbind(1, 0),
              "capital.w"   = rbind(0, 1),
              "value.w"     = rbind(0, 1))
zef1 &lt;- vglm(cbind(invest.g, invest.w) ~
             capital.g + value.g + capital.w + value.w,
             SURff(divisor = "sqrt"), maxit = 1,
             data = gew, trace = TRUE, constraints = clist)

round(coef(zef1, matrix = TRUE), digits = 4)  # ZEF
zef1@extra$ncols.X.lm
zef1@misc$divisor
zef1@misc$values.divisor
round(sqrt(diag(vcov(zef1))),    digits = 4)  # SEs
nobs(zef1, type = "lm")
df.residual(zef1, type = "lm")


mle1 &lt;- vglm(cbind(invest.g, invest.w) ~
             capital.g + value.g + capital.w + value.w,
             SURff(mle.normal = TRUE),
             epsilon = 1e-11,
             data = gew, trace = TRUE, constraints = clist)
round(coef(mle1, matrix = TRUE), digits = 4)  # MLE
round(sqrt(diag(vcov(mle1))),    digits = 4)  # SEs
</code></pre>

<hr>
<h2 id='SurvS4'>
Create a Survival Object
</h2><span id='topic+SurvS4'></span><span id='topic+is.SurvS4'></span><span id='topic+show.SurvS4'></span><span id='topic+Math.SurvS4'></span><span id='topic+Summary.SurvS4'></span><span id='topic++5B.SurvS4'></span><span id='topic+format.SurvS4'></span><span id='topic+as.data.frame.SurvS4'></span><span id='topic+as.character.SurvS4'></span><span id='topic+is.na.SurvS4'></span><span id='topic+Ops.SurvS4'></span>

<h3>Description</h3>

<p>Create a survival object, usually used as a response
variable in a model formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvS4(time, time2, event, type =, origin = 0)
is.SurvS4(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SurvS4_+3A_time">time</code></td>
<td>

<p>for right censored data, this is the follow up time.  For interval
data, the first argument is the starting time for the interval.
</p>
</td></tr>
<tr><td><code id="SurvS4_+3A_x">x</code></td>
<td>

<p>any R object.
</p>
</td></tr>
<tr><td><code id="SurvS4_+3A_event">event</code></td>
<td>

<p>The status indicator, normally 0=alive, 1=dead.  Other choices are
<code>TRUE</code>/<code>FALSE</code> (<code>TRUE</code> = death) or 1/2 (2=death). For
interval censored data, the status indicator is 0=right censored,
1=event at <code>time</code>, 2=left censored, 3=interval censored.
Although unusual, the event indicator can be omitted, in which case
all subjects are assumed to have an event.
</p>
</td></tr>
<tr><td><code id="SurvS4_+3A_time2">time2</code></td>
<td>

<p>ending time of the interval for interval censored  or counting
process data only.  Intervals are assumed to be open on the left and
closed on the right, <code>(start, end]</code>.  For counting process
data, <code>event</code> indicates whether an event occurred at the end of
the interval.
</p>
</td></tr>
<tr><td><code id="SurvS4_+3A_type">type</code></td>
<td>

<p>character string specifying the type of censoring. Possible values
are <code>"right"</code>, <code>"left"</code>, <code>"counting"</code>,
<code>"interval"</code>, or <code>"interval2"</code>.  The default is
<code>"right"</code> or <code>"counting"</code> depending on whether the
<code>time2</code> argument is absent or present, respectively.
</p>
</td></tr>
<tr><td><code id="SurvS4_+3A_origin">origin</code></td>
<td>

<p>for counting process data, the hazard function origin.  This is most
often used in conjunction with a model containing time dependent
strata in order to align the subjects properly when they cross over
from one strata to another.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Typical usages are
</p>
<pre>
SurvS4(time, event)
SurvS4(time, time2, event, type=, origin=0)
</pre>
<p>In theory it is possible to represent interval censored
data without a third column containing the explicit status.
Exact, right censored, left censored and interval censored
observation would be represented as intervals of (a,a),
(a, infinity), (-infinity,b), and (a,b) respectively; each
specifying the interval within which the event is known to
have occurred.
</p>
<p>If <code>type = "interval2"</code> then the representation given
above is assumed, with NA taking the place of infinity.
If 'type=&quot;interval&quot; <code>event</code> must be given.
If <code>event</code> is <code>0</code>, <code>1</code>, or <code>2</code>,
the relevant information is assumed to be contained in
<code>time</code>, the value in <code>time2</code> is ignored, and the
second column of the result will contain a placeholder.
</p>
<p>Presently, the only methods allowing interval
censored data are the parametric models computed by
<code><a href="survival.html#topic+survreg">survreg</a></code>, so the distinction between
open and closed intervals is unimportant.  The distinction
is important for counting process data and the Cox model.
</p>
<p>The function tries to distinguish between the use of 0/1
and 1/2 coding for left and right censored data using
<code>if (max(status)==2)</code>.  If 1/2 coding is used and all
the subjects are censored, it will guess wrong.  Use 0/1
coding in this case.
</p>


<h3>Value</h3>

<p>An object of class <code>SurvS4</code> (formerly <code>Surv</code>).
There are methods for <code>print</code>, <code>is.na</code>, and
subscripting survival objects. <code>SurvS4</code> objects are
implemented as a matrix of 2 or 3 columns.
</p>
<p>In the case of <code>is.SurvS4</code>, a logical value
<code>TRUE</code> if <code>x</code> inherits from class
<code>"SurvS4"</code>, otherwise a <code>FALSE</code>.
</p>


<h3>Note</h3>

<p>The purpose of having <code>SurvS4</code> in <span class="pkg">VGAM</span> is so that
the same input can be fed into <code><a href="#topic+vglm">vglm</a></code> as functions in
<span class="pkg">survival</span> such as <code><a href="survival.html#topic+survreg">survreg</a></code>.  The class
name has been changed from <code>"Surv"</code> to <code>"SurvS4"</code>; see
<code><a href="#topic+SurvS4-class">SurvS4-class</a></code>.
</p>
<p>The format <code>J+</code> is interpreted in <span class="pkg">VGAM</span> as <code class="reqn">\ge J</code>.
If <code>type="interval"</code> then these should not be used in <span class="pkg">VGAM</span>:
<code>(L,U-]</code> or  <code>(L,U+]</code>.

</p>


<h3>Author(s)</h3>

<p>The code and documentation comes from <span class="pkg">survival</span>.
Slight modifications have been made for conversion to S4 by T. W. Yee.
Also, for <code>"interval"</code> data, <code>as.character.SurvS4()</code> has
been modified to print intervals of the form
<code>(start, end]</code> and not
<code>[start, end]</code> as previously.
(This makes a difference for discrete data, such as for
<code><a href="#topic+cens.poisson">cens.poisson</a></code>).
All <span class="pkg">VGAM</span> family functions beginning with <code>"cen"</code> require
the packaging function <code>Surv</code> to format the input.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SurvS4-class">SurvS4-class</a></code>,
<code><a href="#topic+cens.poisson">cens.poisson</a></code>,
<code><a href="survival.html#topic+survreg">survreg</a></code>,
<code><a href="#topic+leukemia">leukemia</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>with(leukemia, SurvS4(time, status))
class(with(leukemia, SurvS4(time, status)))
</code></pre>

<hr>
<h2 id='SurvS4-class'>Class &quot;SurvS4&quot; </h2><span id='topic+SurvS4-class'></span><span id='topic+show+2CSurvS4-method'></span>

<h3>Description</h3>

<p> S4 version of the Surv class. </p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be created from it.</p>


<h3>Extends</h3>


<p>Class <code>"Surv"</code>, directly.
Class <code>"<a href="methods.html#topic+matrix-class">matrix</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;Surv&quot;, distance 2.
Class <code>"<a href="methods.html#topic+structure-class">structure</a>"</code>, by class &quot;matrix&quot;, distance 2.
Class <code>"<a href="methods.html#topic+array-class">array</a>"</code>, by class &quot;matrix&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;matrix&quot;, distance 3, with explicit coerce.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;matrix&quot;, distance 4, with explicit coerce.
</p>


<h3>Methods</h3>



<dl>
<dt>show</dt><dd><p><code>signature(object = "SurvS4")</code>: ... </p>
</dd>
</dl>



<h3>Warning </h3>

<p>This code has not been thoroughly tested.
</p>


<h3>Note</h3>

<p>The purpose of having <code><a href="#topic+SurvS4">SurvS4</a></code> in <span class="pkg">VGAM</span> is so that
the same input can be fed into <code><a href="#topic+vglm">vglm</a></code> as functions in
<span class="pkg">survival</span> such as <code><a href="survival.html#topic+survreg">survreg</a></code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
</p>


<h3>References</h3>

<p>See <span class="pkg">survival</span>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SurvS4">SurvS4</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>showClass("SurvS4")
</code></pre>

<hr>
<h2 id='TIC'> Takeuchi's Information Criterion </h2><span id='topic+TIC'></span><span id='topic+TICvlm'></span>

<h3>Description</h3>

<p>Calculates the Takeuchi information criterion
for a fitted model object
for which a log-likelihood value has been obtained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    TIC(object, ...)
    TICvlm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TIC_+3A_object">object</code></td>
<td>

<p>A <span class="pkg">VGAM</span> object having
class <code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>

</td></tr>
<tr><td><code id="TIC_+3A_...">...</code></td>
<td>

<p>Other possible arguments fed into
<code>logLik</code> in order to compute the log-likelihood.
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>The following formula is used for VGLMs:
<code class="reqn">-2 \mbox{log-likelihood} + 2 trace(V K)</code>,
where <code class="reqn">V</code> is the inverse of the EIM from the fitted model,
and <code class="reqn">K</code> is the outer product of the score vectors.
Both <code class="reqn">V</code> and <code class="reqn">K</code> are order-<code class="reqn">p.VLM</code> matrices.
One has <code class="reqn">V</code> equal to <code>vcov(object)</code>,
and <code class="reqn">K</code> is computed by taking the outer product of
the output from the <code>deriv</code> slot multiplied by the
large VLM matrix and then taking their sum.
Hence for the huge majority of models,
the penalty is computed at the MLE and is empirical in nature.
Theoretically, if the fitted model is the true model then
AIC equals TIC.
</p>
<p>When there are prior weights the score vectors are divided
by the square root of these,
because <code class="reqn"> (a_i U_i / \sqrt{a_i})^2 = a_i U_i^2</code>.
</p>

<p>This code relies on the log-likelihood being defined, and computed,
for the object.
When comparing fitted objects, the smaller the TIC, the better the fit.
The log-likelihood and hence the TIC is only defined up to an additive
constant.
</p>
<p>Currently
any estimated scale parameter (in GLM parlance) is ignored by
treating its value as unity.
Also,
currently
this function is written only for <code><a href="#topic+vglm">vglm</a></code> objects and
not <code><a href="#topic+vgam">vgam</a></code> or <code><a href="#topic+rrvglm">rrvglm</a></code>, etc., objects.
</p>


<h3>Value</h3>

<p>Returns a numeric TIC value.
</p>


<h3>Warning </h3>

<p>This code has not been double-checked.
The general applicability of <code>TIC</code> for the VGLM/VGAM classes
has not been developed fully.
In particular, <code>TIC</code> should not be run on some <span class="pkg">VGAM</span> family
functions because of violation of certain regularity conditions, etc.
</p>
<p>Some authors note that quite large sample sizes are needed
for this IC to work reasonably well.
</p>




<h3>Note</h3>

<p>TIC has not been defined for RR-VGLMs, QRR-VGLMs, etc., yet.
</p>
<p>See <code><a href="#topic+AICvlm">AICvlm</a></code> about models
such as <code><a href="#topic+posbernoulli.tb">posbernoulli.tb</a></code>
that require <code>posbinomial(omit.constant = TRUE)</code>.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee. </p>


<h3>References</h3>

<p>Takeuchi, K. (1976).
Distribution of informational statistics and a criterion of model
fitting.  (In Japanese).
<em>Suri-Kagaku</em> (Mathematic Sciences),
<b>153</b>, 12&ndash;18.
</p>



<p>Burnham, K. P. and Anderson, D. R. (2002).
<em>Model Selection and Multi-Model Inference: A Practical
Information-Theoretic Approach</em>,
2nd ed. New York, USA: Springer.
</p>


<h3>See Also</h3>

<p>VGLMs are described in <code><a href="#topic+vglm-class">vglm-class</a></code>;
<code><a href="stats.html#topic+AIC">AIC</a></code>,
<code><a href="#topic+AICvlm">AICvlm</a></code>.
<code><a href="#topic+BICvlm">BICvlm</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = TRUE, reverse = TRUE), data = pneumo))
coef(fit1, matrix = TRUE)
TIC(fit1)
(fit2 &lt;- vglm(cbind(normal, mild, severe) ~ let,
              cumulative(parallel = FALSE, reverse = TRUE), data = pneumo))
coef(fit2, matrix = TRUE)
TIC(fit2)
</code></pre>

<hr>
<h2 id='tobit'> Tobit Regression </h2><span id='topic+tobit'></span>

<h3>Description</h3>

<p>Fits a Tobit regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tobit(Lower = 0, Upper = Inf, lmu = "identitylink",
      lsd = "loglink", imu = NULL, isd = NULL,
      type.fitted = c("uncensored", "censored", "mean.obs"),
      byrow.arg = FALSE, imethod = 1, zero = "sd")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tobit_+3A_lower">Lower</code></td>
<td>

<p>Numeric. It is the value <code class="reqn">L</code> described below.
Any value of the linear model
<code class="reqn">x_i^T \beta</code> that
is less than this lowerbound is assigned this value.
Hence this should be the smallest possible value
in the response variable.
May be a vector (see below for more information).
</p>
</td></tr>
<tr><td><code id="tobit_+3A_upper">Upper</code></td>
<td>

<p>Numeric. It is the value <code class="reqn">U</code> described below.
Any value of the linear model
<code class="reqn">x_i^T \beta</code> that
is greater than this upperbound is assigned this value.
Hence this should be the largest possible value
in the response variable.
May be a vector (see below for more information).
</p>
</td></tr>
<tr><td><code id="tobit_+3A_lmu">lmu</code>, <code id="tobit_+3A_lsd">lsd</code></td>
<td>

<p>Parameter link functions for the mean and
standard deviation parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The standard deviation is a positive quantity,
therefore a log link
is its default.
</p>
</td></tr>
<tr><td><code id="tobit_+3A_imu">imu</code>, <code id="tobit_+3A_isd">isd</code>, <code id="tobit_+3A_byrow.arg">byrow.arg</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="tobit_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Type of fitted value returned.
The first choice is default and is the ordinary uncensored or
unbounded linear model.
If <code>"censored"</code> then the fitted values in the
interval <code class="reqn">[L, U]</code>.
If <code>"mean.obs"</code> then the mean of the observations
is returned;
this is a doubly truncated normal distribution
augmented by point masses at the truncation points
(see <code><a href="#topic+dtobit">dtobit</a></code>).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="tobit_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method. Either 1 or 2 or 3, this specifies
some methods for obtaining initial values for the parameters.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="tobit_+3A_zero">zero</code></td>
<td>

<p>A vector, e.g., containing the value 1 or 2. If so,
the mean or standard deviation respectively are modelled
as an intercept-only.
Setting <code>zero = NULL</code> means both
linear/additive predictors
are modelled as functions of the explanatory variables.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Tobit model can be written
</p>
<p style="text-align: center;"><code class="reqn">y_i^* = x_i^T \beta + \varepsilon_i</code>
</p>

<p>where the <code class="reqn">e_i \sim N(0,\sigma^2)</code>
independently and <code class="reqn">i=1,\ldots,n</code>.
However, we measure <code class="reqn">y_i = y_i^*</code> only if
<code class="reqn">y_i^* &gt; L</code> and
<code class="reqn">y_i^* &lt; U</code> for some
cutpoints <code class="reqn">L</code> and <code class="reqn">U</code>.
Otherwise we let <code class="reqn">y_i=L</code> or
<code class="reqn">y_i=U</code>, whatever is closer.
The Tobit model is thus a multiple linear regression
but with censored
responses if it is below or above certain cutpoints.
</p>
<p>The defaults for <code>Lower</code> and <code>Upper</code> and
<code>lmu</code> correspond to the <em>standard</em> Tobit model.
Fisher scoring is used for the standard and nonstandard
models.
By default, the mean <code class="reqn">x_i^T \beta</code> is
the first linear/additive predictor, and the log of
the standard deviation is the second linear/additive
predictor. The Fisher information matrix for uncensored
data is diagonal. The fitted values are the estimates
of <code class="reqn">x_i^T \beta</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>If values of the response and <code>Lower</code> and/or <code>Upper</code>
are not integers then there is the danger that the value is
wrongly interpreted as uncensored.
For example, if the first 10 values of the response were
<code>runif(10)</code> and <code>Lower</code> was assigned these value then
testing <code>y[1:10] == Lower[1:10]</code> is numerically fraught.
Currently, if any <code>y &lt; Lower</code> or <code>y &gt; Upper</code> then
a warning is issued.
The function <code><a href="#topic+round2">round2</a></code> may be useful.
</p>


<h3>Note</h3>

<p>The response can be a matrix.
If so, then <code>Lower</code> and <code>Upper</code>
are recycled into a matrix with the number of columns equal
to the number of responses,
and the recycling is done row-wise <em>if</em>
<code>byrow.arg = TRUE</code>.
The default order is as <code><a href="base.html#topic+matrix">matrix</a></code>, which
is <code>byrow.arg = FALSE</code>.
For example, these are returned in <code>fit4@misc$Lower</code> and
<code>fit4@misc$Upper</code> below.
</p>
<p>If there is no censoring then
<code><a href="#topic+uninormal">uninormal</a></code> is recommended instead.
Any value of the
response less than <code>Lower</code> or greater
than <code>Upper</code> will
be assigned the value <code>Lower</code> and <code>Upper</code>
respectively,
and a warning will be issued.
The fitted object has components <code>censoredL</code>
and <code>censoredU</code>
in the <code>extra</code> slot which specifies whether
observations
are censored in that direction.
The function <code><a href="#topic+cens.normal">cens.normal</a></code> is an alternative
to <code>tobit()</code>.
</p>

<p>When obtaining initial values, if the algorithm would
otherwise want to fit an underdetermined system of
equations, then it uses the entire data set instead.
This might result in rather poor quality initial values,
and consequently, monitoring convergence is advised.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Tobin, J. (1958).
Estimation of relationships for limited dependent variables.
<em>Econometrica</em> <b>26</b>, 24&ndash;36.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rtobit">rtobit</a></code>,
<code><a href="#topic+cens.normal">cens.normal</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+double.cens.normal">double.cens.normal</a></code>,
<code><a href="#topic+posnormal">posnormal</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+round2">round2</a></code>,
<code><a href="#topic+mills.ratio">mills.ratio</a></code>,
<code><a href="#topic+margeff">margeff</a></code>,
<code><a href="stats.html#topic+Normal">rnorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Here, fit1 is a standard Tobit model and fit2 is nonstandard
tdata &lt;- data.frame(x2 = seq(-1, 1, length = (nn &lt;- 100)))
set.seed(1)
Lower &lt;- 1; Upper &lt;- 4  # For the nonstandard Tobit model
tdata &lt;- transform(tdata,
                   Lower.vec = rnorm(nn, Lower, 0.5),
                   Upper.vec = rnorm(nn, Upper, 0.5))
meanfun1 &lt;- function(x) 0 + 2*x
meanfun2 &lt;- function(x) 2 + 2*x
meanfun3 &lt;- function(x) 3 + 2*x
tdata &lt;- transform(tdata,
  y1 = rtobit(nn, mean = meanfun1(x2)),  # Standard Tobit model
  y2 = rtobit(nn, mean = meanfun2(x2), Lower = Lower, Upper = Upper),
  y3 = rtobit(nn, mean = meanfun3(x2), Lower = Lower.vec,
              Upper = Upper.vec),
  y4 = rtobit(nn, mean = meanfun3(x2), Lower = Lower.vec,
              Upper = Upper.vec))
with(tdata, table(y1 == 0))  # How many censored values?
with(tdata, table(y2 == Lower | y2 == Upper))  # Ditto
with(tdata, table(attr(y2, "cenL")))
with(tdata, table(attr(y2, "cenU")))

fit1 &lt;- vglm(y1 ~ x2, tobit, data = tdata, trace = TRUE)
coef(fit1, matrix = TRUE)
summary(fit1)

fit2 &lt;- vglm(y2 ~ x2,
             tobit(Lower = Lower, Upper = Upper, type.f = "cens"),
             data = tdata, trace = TRUE)
table(fit2@extra$censoredL)
table(fit2@extra$censoredU)
coef(fit2, matrix = TRUE)

fit3 &lt;- vglm(y3 ~ x2, tobit(Lower = with(tdata, Lower.vec),
                            Upper = with(tdata, Upper.vec),
                            type.f = "cens"),
             data = tdata, trace = TRUE)
table(fit3@extra$censoredL)
table(fit3@extra$censoredU)
coef(fit3, matrix = TRUE)

# fit4 is fit3 but with type.fitted = "uncen".
fit4 &lt;- vglm(cbind(y3, y4) ~ x2,
             tobit(Lower = rep(with(tdata, Lower.vec), each = 2),
                   Upper = rep(with(tdata, Upper.vec), each = 2),
                   byrow.arg = TRUE),
             data = tdata, crit = "coeff", trace = TRUE)
head(fit4@extra$censoredL)  # A matrix
head(fit4@extra$censoredU)  # A matrix
head(fit4@misc$Lower)       # A matrix
head(fit4@misc$Upper)       # A matrix
coef(fit4, matrix = TRUE)

## Not run:  # Plot fit1--fit4
par(mfrow = c(2, 2))

plot(y1 ~ x2, tdata, las = 1, main = "Standard Tobit model",
     col = as.numeric(attr(y1, "cenL")) + 3,
     pch = as.numeric(attr(y1, "cenL")) + 1)
legend(x = "topleft", leg = c("censored", "uncensored"),
       pch = c(2, 1), col = c("blue", "green"))
legend(-1.0, 2.5, c("Truth", "Estimate", "Naive"), lwd = 2,
       col = c("purple", "orange", "black"), lty = c(1, 2, 2))
lines(meanfun1(x2) ~ x2, tdata, col = "purple", lwd = 2)
lines(fitted(fit1) ~ x2, tdata, col = "orange", lwd = 2, lty = 2)
lines(fitted(lm(y1 ~ x2, tdata)) ~ x2, tdata, col = "black",
      lty = 2, lwd = 2)  # This is simplest but wrong!

plot(y2 ~ x2, data = tdata, las = 1, main = "Tobit model",
     col = as.numeric(attr(y2, "cenL")) + 3 +
           as.numeric(attr(y2, "cenU")),
     pch = as.numeric(attr(y2, "cenL")) + 1 +
           as.numeric(attr(y2, "cenU")))
legend(x = "topleft", leg = c("censored", "uncensored"),
       pch = c(2, 1), col = c("blue", "green"))
legend(-1.0, 3.5, c("Truth", "Estimate", "Naive"), lwd = 2,
       col = c("purple", "orange", "black"), lty = c(1, 2, 2))
lines(meanfun2(x2) ~ x2, tdata, col = "purple", lwd = 2)
lines(fitted(fit2) ~ x2, tdata, col = "orange", lwd = 2, lty = 2)
lines(fitted(lm(y2 ~ x2, tdata)) ~ x2, tdata, col = "black",
      lty = 2, lwd = 2)  # This is simplest but wrong!

plot(y3 ~ x2, data = tdata, las = 1,
     main = "Tobit model with nonconstant censor levels",
     col = as.numeric(attr(y3, "cenL")) + 2 +
           as.numeric(attr(y3, "cenU") * 2),
     pch = as.numeric(attr(y3, "cenL")) + 1 +
           as.numeric(attr(y3, "cenU") * 2))
legend(x = "topleft", pch = c(2, 3, 1), col = c(3, 4, 2),
       leg = c("censoredL", "censoredU", "uncensored"))
legend(-1.0, 3.5, c("Truth", "Estimate", "Naive"), lwd = 2,
       col = c("purple", "orange", "black"), lty = c(1, 2, 2))
lines(meanfun3(x2) ~ x2, tdata, col = "purple", lwd = 2)
lines(fitted(fit3) ~ x2, tdata, col = "orange", lwd = 2, lty = 2)
lines(fitted(lm(y3 ~ x2, tdata)) ~ x2, tdata, col = "black",
      lty = 2, lwd = 2)  # This is simplest but wrong!

plot(y3 ~ x2, data = tdata, las = 1,
     main = "Tobit model with nonconstant censor levels",
     col = as.numeric(attr(y3, "cenL")) + 2 +
           as.numeric(attr(y3, "cenU") * 2),
     pch = as.numeric(attr(y3, "cenL")) + 1 +
           as.numeric(attr(y3, "cenU") * 2))
legend(x = "topleft", pch = c(2, 3, 1), col = c(3, 4, 2),
       leg = c("censoredL", "censoredU", "uncensored"))
legend(-1.0, 3.5, c("Truth", "Estimate", "Naive"), lwd = 2, 
       col = c("purple", "orange", "black"), lty = c(1, 2, 2))
lines(meanfun3(x2) ~ x2, data = tdata, col = "purple", lwd = 2)
lines(fitted(fit4)[, 1] ~ x2, tdata, col="orange", lwd = 2, lty = 2)
lines(fitted(lm(y3 ~ x2, tdata)) ~ x2, data = tdata, col = "black",
      lty = 2, lwd = 2)  # This is simplest but wrong!

## End(Not run)
</code></pre>

<hr>
<h2 id='Tobit'>The Tobit Distribution</h2><span id='topic+Tobit'></span><span id='topic+dtobit'></span><span id='topic+ptobit'></span><span id='topic+qtobit'></span><span id='topic+rtobit'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Tobit model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtobit(x, mean = 0, sd = 1, Lower = 0, Upper = Inf, log = FALSE)
ptobit(q, mean = 0, sd = 1, Lower = 0, Upper = Inf,
       lower.tail = TRUE, log.p = FALSE)
qtobit(p, mean = 0, sd = 1, Lower = 0, Upper = Inf,
       lower.tail = TRUE, log.p = FALSE)
rtobit(n, mean = 0, sd = 1, Lower = 0, Upper = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tobit_+3A_x">x</code>, <code id="Tobit_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Tobit_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Tobit_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be
the number required.
</p>
</td></tr>
<tr><td><code id="Tobit_+3A_lower">Lower</code>, <code id="Tobit_+3A_upper">Upper</code></td>
<td>
<p>vector of lower and upper
thresholds.
</p>
</td></tr>
<tr><td><code id="Tobit_+3A_mean">mean</code>, <code id="Tobit_+3A_sd">sd</code>, <code id="Tobit_+3A_lower.tail">lower.tail</code>, <code id="Tobit_+3A_log">log</code>, <code id="Tobit_+3A_log.p">log.p</code></td>
<td>

<p>see <code><a href="stats.html#topic+Normal">rnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+tobit">tobit</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameters,
for details.
Note that the density at <code>Lower</code> and <code>Upper</code> is the
the area to the left and right of those points.
Thus there are two spikes (but less in value);
see the example below.
Consequently, <code>dtobit(Lower) + dtobit(Upper) + </code> the area
in between equals unity.
</p>






<h3>Value</h3>

<p><code>dtobit</code> gives the density,
<code>ptobit</code> gives the distribution function,
<code>qtobit</code> gives the quantile function, and
<code>rtobit</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+tobit">tobit</a></code>,
<code><a href="stats.html#topic+Normal">rnorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- 0.5; x &lt;- seq(-2, 4, by = 0.01)
Lower &lt;- -1; Upper &lt;- 2.0

integrate(dtobit, lower = Lower, upper = Upper,
          mean = mu, Lower = Lower, Upper = Upper)$value +
dtobit(Lower, mean = mu, Lower = Lower, Upper = Upper) +
dtobit(Upper, mean = mu, Lower = Lower, Upper = Upper)  # Adds to 1

## Not run: 
plot(x, ptobit(x, m = mu, Lower = Lower, Upper = Upper),
     type = "l", ylim = 0:1, las = 1, col = "orange",
     ylab = paste("ptobit(m = ", mu, ", sd = 1, Lower =", Lower,
                  ", Upper =", Upper, ")"),
     main = "Orange is the CDF; blue is density",
     sub = "Purple lines are the 10,20,...,90 percentiles")
abline(h = 0)
lines(x, dtobit(x, m = mu, L = Lower, U = Upper), col = "blue")

probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qtobit(probs, m = mu, Lower = Lower, Upper = Upper)
lines(Q, ptobit(Q, m = mu, Lower = Lower, Upper = Upper),
      col = "purple", lty = "dashed", type = "h")
lines(Q, dtobit(Q, m = mu, Lower = Lower, Upper = Upper),
      col = "darkgreen", lty = "dashed", type = "h")
abline(h = probs, col = "purple", lty = "dashed")
max(abs(ptobit(Q, mu, L = Lower, U = Upper) - probs))  # Should be 0

epts &lt;- c(Lower, Upper)  # Endpoints have a spike (not quite, actually)
lines(epts, dtobit(epts, m = mu, Lower = Lower, Upper = Upper),
      col = "blue", lwd = 3, type = "h")

## End(Not run)
</code></pre>

<hr>
<h2 id='Tol'> Tolerances </h2><span id='topic+Tol'></span>

<h3>Description</h3>

<p>Generic function for the <em>tolerances</em> of a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tol(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tol_+3A_object">object</code></td>
<td>
<p> An object for which the computation or
extraction of a tolerance or tolerances is meaningful.
</p>
</td></tr>
<tr><td><code id="Tol_+3A_...">...</code></td>
<td>
<p> Other arguments fed into the specific
methods function of the model. Sometimes they are fed
into the methods function for <code><a href="#topic+Coef">Coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Different models can define an optimum in different ways.
Many models have no such notion or definition.
</p>
<p>Tolerances occur in quadratic ordination, i.e., CQO and UQO.
They have ecological meaning because a high tolerance
for a species means the species can survive over a large
environmental range (stenoecous species), whereas a
small tolerance means the species' niche is small
(eurycous species).
Mathematically, the tolerance is like the variance of
a normal distribution.
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods
function invoked.
For a <code><a href="#topic+cqo">cqo</a></code> binomial or Poisson fit, this
function returns a
<code class="reqn">R \times R \times S</code> array, where <code class="reqn">R</code> is the rank
and <code class="reqn">S</code> is the number of species.
Each tolerance matrix ought to be positive-definite, and
for a rank-1 fit, taking the square root of each tolerance
matrix results in each species' tolerance (like a standard
deviation).
</p>


<h3>Warning </h3>

<p>There is a direct inverse relationship between the scaling of
the latent variables (site scores) and the tolerances.
One normalization is for the latent variables to have unit
variance.
Another normalization is for all the tolerances to be unit.
These two normalization cannot simultaneously hold in general.
For rank-<em>R&gt;1</em> models it becomes more complicated because
the latent variables are also uncorrelated. An important
argument when fitting quadratic ordination models is whether
<code>eq.tolerances</code> is <code>TRUE</code> or <code>FALSE</code>.
See Yee (2004) for details.
</p>


<h3>Note</h3>

<p>Tolerances are undefined for &lsquo;linear&rsquo; and additive
ordination models.
They are well-defined for quadratic ordination models.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>


<h3>See Also</h3>

<p><code>Tol.qrrvglm</code>.
<code><a href="#topic+Max">Max</a></code>,
<code><a href="#topic+Opt">Opt</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+rcim">rcim</a></code> for UQO.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(111)  # This leads to the global solution
hspider[,1:6] &lt;- scale(hspider[, 1:6])  # Standardized environmental vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute, Arctperi,
                Auloalbi, Pardlugu, Pardmont, Pardnigr, Pardpull,
                Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss + CoveHerb + ReflLux,
          poissonff, data = hspider, Crow1positive = FALSE)

Tol(p1)

## End(Not run)
</code></pre>

<hr>
<h2 id='topple'> Topp-Leone Distribution Family Function </h2><span id='topic+topple'></span>

<h3>Description</h3>

<p>Estimating the parameter of the Topp-Leone distribution by
maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topple(lshape = "logitlink", zero = NULL, gshape = ppoints(8),
       parallel = FALSE, percentiles = 50,
       type.fitted = c("mean", "percentiles", "Qlink"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="topple_+3A_lshape">lshape</code>, <code id="topple_+3A_gshape">gshape</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
The CIA link is <code><a href="#topic+loglink">loglink</a></code>,
for <code>shape</code> approaching unity.
</p>
</td></tr>
<tr><td><code id="topple_+3A_zero">zero</code>, <code id="topple_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="topple_+3A_type.fitted">type.fitted</code>, <code id="topple_+3A_percentiles">percentiles</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Using <code>"Qlink"</code> is for quantile-links in <span class="pkg">VGAMextra</span>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Topple distribution
has a probability density function that can be written
</p>
<p style="text-align: center;"><code class="reqn">f(y;s) = 2 s (1 - y) [y (2-y)]^{s-1}</code>
</p>

<p>for <code class="reqn">0&lt;y&lt;1</code> and shape parameter <code class="reqn">0&lt;s&lt;1</code>.
The mean of <code class="reqn">Y</code> is
<code class="reqn">1 - 4^s [\Gamma(1+s)]^2 / \Gamma(2 + 2s)</code>
(returned as the fitted values).
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Fisher-scoring and Newton-Raphson are the same here.
A related distribution is the triangle distribution.
This <span class="pkg">VGAM</span> family function handles multiple responses.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Topp, C. W. and F. C. Leone (1955).
A family of J-shaped frequency functions.
<em>Journal of the American Statistical Association</em>,
<b>50</b>, 209&ndash;219.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Topple">Topple</a></code>,
<code><a href="#topic+Triangle">Triangle</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tdata &lt;- data.frame(y = rtopple(1000, logitlink(1, inverse = TRUE)))
tfit &lt;- vglm(y ~ 1, topple, tdata, trace = TRUE, crit = "coef")
coef(tfit, matrix = TRUE)
Coef(tfit)
</code></pre>

<hr>
<h2 id='Topple'>The Topp-Leone Distribution</h2><span id='topic+Topple'></span><span id='topic+dtopple'></span><span id='topic+ptopple'></span><span id='topic+qtopple'></span><span id='topic+rtopple'></span>

<h3>Description</h3>

<p>Density,
distribution function,
quantile function and random generation
for the Topp-Leone distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtopple(x, shape, log = FALSE)
ptopple(q, shape, lower.tail = TRUE, log.p = FALSE)
qtopple(p, shape)
rtopple(n, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Topple_+3A_x">x</code>, <code id="Topple_+3A_q">q</code>, <code id="Topple_+3A_p">p</code>, <code id="Topple_+3A_n">n</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+Uniform">Uniform</a></code>.
</p>
</td></tr>
<tr><td><code id="Topple_+3A_shape">shape</code></td>
<td>
<p>the (shape) parameter, which lies in <code class="reqn">(0, 1)</code>.</p>
</td></tr>
<tr><td><code id="Topple_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the
density is returned.
</p>
</td></tr>
<tr><td><code id="Topple_+3A_lower.tail">lower.tail</code>, <code id="Topple_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+topple">topple</a></code>, the <span class="pkg">VGAM</span>
family function for
estimating the (shape) parameter <code class="reqn">s</code> by
maximum likelihood
estimation, for the formula of the
probability density function.
</p>


<h3>Value</h3>

<p><code>dtopple</code> gives the density,
<code>ptopple</code> gives the distribution function,
<code>qtopple</code> gives the quantile function, and
<code>rtopple</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The Topp-Leone distribution is related to
the triangle distribution.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Topp, C. W. and F. C. Leone (1955).
A family of J-shaped frequency functions.
<em>Journal of the American Statistical Association</em>,
<b>50</b>, 209&ndash;219.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+topple">topple</a></code>,
<code><a href="#topic+Triangle">Triangle</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  shape &lt;- 0.7; x &lt;- seq(0.02, 0.999, length = 300)
plot(x, dtopple(x, shape = shape), type = "l", col = "blue",
     main = "Blue is density, orange is CDF", ylab = "", las = 1,
     sub = "Purple lines are the 10,20,...,90 percentiles")
abline(h = 0, col = "blue", lty = 2)
lines(x, ptopple(x, shape = shape), type = "l", col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qtopple(probs, shape = shape)
lines(Q, dtopple(Q, shape), col = "purple", lty = 3, type = "h")
lines(Q, ptopple(Q, shape), col = "purple", lty = 3, type = "h")
abline(h = probs, col = "purple", lty = 3)
max(abs(ptopple(Q, shape) - probs))  # Should be zero

## End(Not run)
</code></pre>

<hr>
<h2 id='toxop'> Toxoplasmosis Data </h2><span id='topic+toxop'></span>

<h3>Description</h3>

<p>Toxoplasmosis data in 34 cities in El Salvador.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(toxop)</code></pre>


<h3>Format</h3>

<p>A data frame with 34 observations on the following 4 variables.
</p>

<dl>
<dt><code>rainfall</code></dt><dd>
<p>a numeric vector; the amount of rainfall
in each city.
</p>
</dd>
<dt><code>ssize</code></dt><dd><p>a numeric vector; sample size.</p>
</dd>
<dt><code>cityNo</code></dt><dd><p>a numeric vector; the city number.</p>
</dd>
<dt><code>positive</code></dt><dd><p>a numeric vector; the
number of subjects
testing positive for the disease. </p>
</dd>
</dl>



<h3>Details</h3>

<p>See the references for details.
</p>


<h3>Source</h3>

<p>See the references for details.
</p>


<h3>References</h3>

<p>Efron, B. (1978).
Regression and ANOVA With zero-one data: measures of
residual variation.
<em>Journal of the American Statistical Association</em>,
<b>73</b>, 113&ndash;121.
</p>
<p>Efron, B. (1986).
Double exponential families and their use in
generalized linear regression.
<em>Journal of the American Statistical Association</em>,
<b>81</b>, 709&ndash;721.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+double.expbinomial">double.expbinomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  with(toxop, plot(rainfall, positive/ssize, col = "blue"))
plot(toxop, col = "blue") 
## End(Not run)
</code></pre>

<hr>
<h2 id='triangle'>Triangle Distribution Family Function </h2><span id='topic+triangle'></span>

<h3>Description</h3>

<p>Estimating the parameter of the triangle distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triangle(lower = 0, upper = 1,
         link = extlogitlink(min = 0, max = 1), itheta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="triangle_+3A_lower">lower</code>, <code id="triangle_+3A_upper">upper</code></td>
<td>
<p>lower and upper limits of the distribution.
Must be finite.
Called <code class="reqn">A</code> and <code class="reqn">B</code> respectively below.
</p>
</td></tr>
<tr><td><code id="triangle_+3A_link">link</code></td>
<td>

<p>Parameter link function applied to the
parameter <code class="reqn">\theta</code>,
which lies in <code class="reqn">(A,B)</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
The default constrains the estimate to lie in the interval.
</p>
</td></tr>
<tr><td><code id="triangle_+3A_itheta">itheta</code></td>
<td>

<p>Optional initial value for the parameter.
The default is to compute the value internally.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The triangle distribution
has a probability density function that
consists of two lines
joined at <code class="reqn">\theta</code>, which is the
location of the mode.
The lines intersect the
<code class="reqn">y = 0</code> axis at <code class="reqn">A</code> and <code class="reqn">B</code>.
Here, Fisher scoring is used.
</p>
<p>On fitting, the <code>extra</code> slot has components
called <code>lower</code>
and <code>upper</code> which contains the values of
the above arguments
(recycled to the right length).
The fitted values are the mean of the distribution, which is
<code class="reqn">(A + B + \theta)/3</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>The MLE regularity conditions do not hold for this
distribution
(e.g., the first derivative evaluated at the mode
does not exist because it is not continuous)
so that misleading inferences may result, e.g.,
in the <code>summary</code> and <code>vcov</code> of the object.
Additionally, convergence to the MLE often appears to fail.
</p>


<h3>Note</h3>

<p>The response must contain values in <code class="reqn">(A, B)</code>.
For most data sets (especially small ones) it is very
common for half-stepping to occur.
</p>

<p>Arguments <code>lower</code> and <code>upper</code>
and <code>link</code> must match.
For example, setting
<code>lower = 0.2</code> and <code>upper = 4</code> and
<code>link = extlogitlink(min = 0.2, max = 4.1)</code>
will result in an error.
Ideally <code>link = extlogitlink(min = lower, max = upper)</code>
ought to work but it does not (yet)!
Minimal error checking is done for this deficiency.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kotz, S. and van Dorp, J. R. (2004).
Beyond Beta: Other Continuous Families of Distributions
with Bounded Support and Applications.
Chapter 1.
World Scientific: Singapore.
</p>
<p>Nguyen, H. D. and McLachlan, G. J. (2016).
Maximum likelihood estimation of triangular
and polygon distributions.
<em>Computational Statistics and Data Analysis</em>,
<b>102</b>, 23&ndash;36.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Triangle">Triangle</a></code>,
<code><a href="#topic+Topple">Topple</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1
tdata &lt;- data.frame(y = rtriangle(n &lt;- 3000, theta = 3/4))
fit &lt;- vglm(y ~ 1, triangle(link = "identitylink"), tdata,
             trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
head(fit@extra$lower)
head(fitted(fit))
with(tdata, mean(y))

# Example 2; Kotz and van Dorp (2004), p.14
rdata &lt;- data.frame(y = c(0.1,0.25,0.3,0.4,0.45, 0.6, 0.75, 0.8))
fit &lt;- vglm(y ~ 1, triangle(link = "identitylink"), rdata,
            trace = TRUE, crit = "coef", maxit = 1000)
Coef(fit)  # The MLE is the 3rd order statistic, which is 0.3.
fit &lt;- vglm(y ~ 1, triangle(link = "identitylink"), rdata,
            trace = TRUE, crit = "coef", maxit = 1001)
Coef(fit)  # The MLE is the 3rd order statistic, which is 0.3.

## End(Not run)</code></pre>

<hr>
<h2 id='Triangle'>The Triangle Distribution</h2><span id='topic+Triangle'></span><span id='topic+dtriangle'></span><span id='topic+ptriangle'></span><span id='topic+qtriangle'></span><span id='topic+rtriangle'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Triangle distribution with parameter
<code>theta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtriangle(x, theta, lower = 0, upper = 1, log = FALSE)
ptriangle(q, theta, lower = 0, upper = 1, lower.tail = TRUE, log.p = FALSE)
qtriangle(p, theta, lower = 0, upper = 1, lower.tail = TRUE, log.p = FALSE)
rtriangle(n, theta, lower = 0, upper = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Triangle_+3A_x">x</code>, <code id="Triangle_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Triangle_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Triangle_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+runif">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Triangle_+3A_theta">theta</code></td>
<td>
<p>the theta parameter which lies between <code>lower</code>
and <code>upper</code>. </p>
</td></tr>
<tr><td><code id="Triangle_+3A_lower">lower</code>, <code id="Triangle_+3A_upper">upper</code></td>
<td>
<p>lower and upper limits of the distribution.
Must be finite.
</p>
</td></tr>
<tr><td><code id="Triangle_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>
<tr><td><code id="Triangle_+3A_lower.tail">lower.tail</code>, <code id="Triangle_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+triangle">triangle</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter <code class="reqn">\theta</code> by
maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>dtriangle</code> gives the density,
<code>ptriangle</code> gives the distribution function,
<code>qtriangle</code> gives the quantile function, and
<code>rtriangle</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>See Also</h3>

<p><code><a href="#topic+triangle">triangle</a></code>,
<code><a href="#topic+topple">topple</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  x &lt;- seq(-0.1, 1.1, by = 0.01); theta &lt;- 0.75
plot(x, dtriangle(x, theta = theta), type = "l", col = "blue", las = 1,
     main = "Blue is density, orange is the CDF",
     sub = "Purple lines are the 10,20,...,90 percentiles",
     ylim = c(0,2), ylab = "")
abline(h = 0, col = "blue", lty = 2)
lines(x, ptriangle(x, theta = theta), col = "orange")
probs &lt;- seq(0.1, 0.9, by = 0.1)
Q &lt;- qtriangle(probs, theta = theta)
lines(Q, dtriangle(Q, theta = theta), col = "purple", lty = 3, type = "h")
ptriangle(Q, theta = theta) - probs  # Should be all zero
abline(h = probs, col = "purple", lty = 3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='trim.constraints'> Trimmed Constraint Matrices </h2><span id='topic+trim.constraints'></span>

<h3>Description</h3>

<p>Deletes statistically nonsignficant regression coefficients via
their constraint matrices, for future refitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim.constraints(object, sig.level = 0.05, max.num = Inf,
                 intercepts = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trim.constraints_+3A_object">object</code></td>
<td>

<p>Some <span class="pkg">VGAM</span> object, especially having
class <code><a href="#topic+vglmff-class">vglmff-class</a></code>.
It has not yet been tested on non-<code>"vglm"</code> objects.
</p>
</td></tr>
<tr><td><code id="trim.constraints_+3A_sig.level">sig.level</code></td>
<td>

<p>Significance levels, with values in <code class="reqn">[0, 1]</code>.
Columns of constraint matices whose p-values are larger than
this argument are deleted.
With terms that generate more than one column of the
<code>"lm"</code> model matrix, all p-values must be greater
than this argument for deletion.
This argument is recycled to the total number of
regression coefficients of <code>object</code>.
</p>
</td></tr>
<tr><td><code id="trim.constraints_+3A_max.num">max.num</code></td>
<td>

<p>Numeric, positive and integer-valued.
Maximum number of regression coefficients allowable for deletion.
This allows one to limit the number of deleted coefficients.
For example,
if <code>max.num = 1</code> then only the largest p-value is used
for the deletion,
provided it is larger than <code>sig.level</code>.
The default is to delete all those coefficients whose
p-values are greater than <code>sig.level</code>.
With a finite value,
this argument will probably not work properly
when there are terms that
generate more than one column of the LM model matrix.
Having a value greater than unity might be unsuitable
in the presence of multicollinearity because all
correlated variables might be eliminated at once.
</p>


</td></tr>
<tr><td><code id="trim.constraints_+3A_intercepts">intercepts</code></td>
<td>

<p>Logical. Trim the intercept term?
If <code>FALSE</code> then the constraint matrix for the
<code>"(Intercept)"</code> term is left unchanged.
</p>
</td></tr>
<tr><td><code id="trim.constraints_+3A_...">...</code></td>
<td>

<p>Unused but for provision in the future.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This utility function is intended to simplify an existing
<code><a href="#topic+vglm">vglm</a></code> object having
variables (terms) that affect unnecessary parameters.
Suppose the explanatory variables in the formula
includes a simple numeric covariate called <code>x2</code>.
This variable will affect every linear predictor if
<code>zero = NULL</code> in the <span class="pkg">VGAM</span> family function.
This situation may correspond to the constraint matrices having
unnecessary columns because their regression coefficients are
statistically nonsignificant.
This function attempts to delete those columns and
return a possibly simplified list of constraint matrices
that can make refitting a simpler model easy to do.
P-values obtained from <code><a href="#topic+summaryvglm">summaryvglm</a></code>
(with <code>HDEtest = FALSE</code> for increased speed)
are compared to <code>sig.level</code> to test for
statistical significance.
</p>
<p>For terms that generate more than one column of the
<code>"lm"</code> model matrix,
such as <code><a href="splines.html#topic+bs">bs</a></code> and <code><a href="stats.html#topic+poly">poly</a></code>,
the column is deleted if all regression coefficients
are statistically nonsignificant.
Incidentally, users should instead use
<code><a href="#topic+sm.bs">sm.bs</a></code>,
<code><a href="#topic+sm.ns">sm.ns</a></code>,
<code><a href="#topic+sm.poly">sm.poly</a></code>,
etc.,
for smart and safe prediction.
</p>
<p>One can think of this function as facilitating
<em>backward elimination</em> for variable selection,
especially if <code>max.num = 1</code> and <code class="reqn">M=1</code>,
however usually more than one regression coefficient is deleted
here by default.
</p>





<h3>Value</h3>

<p>A list of possibly simpler constraint matrices
that can be fed back into the model using the
<code>constraints</code> argument
(usually <code>zero = NULL</code> is needed to avoid a warning).
Consequently, they are required to be of the <code>"term"</code>-type.
After the model is refitted, applying
<code><a href="#topic+summaryvglm">summaryvglm</a></code> should result in
regression coefficients that are &lsquo;all&rsquo; statistically
significant.
</p>


<h3>Warning </h3>

<p>This function has not been tested thoroughly.
One extreme is that a term is totally deleted because
none of its regression coefficients are needed,
and that situation has not yet been finalized.
Ideally, <code>object</code> only contains terms where at least
one regression coefficient has a p-value less than
<code>sig.level</code>.
For ordered factors and other situations, deleting
certain columns may not make sense and destroy interpretability.
</p>
<p>As stated above, <code>max.num</code> may not work properly
when there are terms that
generate more than one column of the LM model matrix.
However, this limitation may change in the future.
</p>


<h3>Note</h3>

<p>This function is experimental and may be replaced by
some other function in the future.
This function does not use S4 object oriented programming
but may be converted to such in the future.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+constraints">constraints</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="#topic+model.matrixvlm">model.matrixvlm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>,
<code><a href="#topic+step4vglm">step4vglm</a></code>,
<code><a href="#topic+sm.bs">sm.bs</a></code>,
<code><a href="#topic+sm.ns">sm.ns</a></code>,
<code><a href="#topic+sm.poly">sm.poly</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  data("xs.nz", package = "VGAMdata")
fit1 &lt;-
  vglm(cbind(worry, worrier) ~ bs(age) + sex + ethnicity + cat + dog,
       binom2.or(zero = NULL), data = xs.nz, trace = TRUE)
summary(fit1, HDEtest = FALSE)  # 'cat' is not significant at all
dim(constraints(fit1, matrix = TRUE))
(tclist1 &lt;- trim.constraints(fit1))  # No 'cat'
fit2 &lt;-  # Delete 'cat' manually from the formula:
  vglm(cbind(worry, worrier) ~ bs(age) + sex + ethnicity +       dog,
       binom2.or(zero = NULL), data = xs.nz,
       constraints = tclist1, trace = TRUE)
summary(fit2, HDEtest = FALSE)  # A simplified model
dim(constraints(fit2, matrix = TRUE))  # Fewer regression coefficients

## End(Not run)</code></pre>

<hr>
<h2 id='Trinorm'>Trivariate Normal Distribution Density and Random Variates</h2><span id='topic+Trinorm'></span><span id='topic+dtrinorm'></span><span id='topic+rtrinorm'></span>

<h3>Description</h3>

<p>Density
and
random generation
for the trivariate normal distribution distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtrinorm(x1, x2, x3, mean1 = 0, mean2 = 0, mean3 = 0,
         var1 = 1, var2 = 1, var3 = 1,
         cov12 = 0, cov23 = 0, cov13 = 0, log = FALSE)
rtrinorm(n,          mean1 = 0, mean2 = 0, mean3 = 0,
         var1 = 1, var2 = 1, var3 = 1,
         cov12 = 0, cov23 = 0, cov13 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Trinorm_+3A_x1">x1</code>, <code id="Trinorm_+3A_x2">x2</code>, <code id="Trinorm_+3A_x3">x3</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Trinorm_+3A_mean1">mean1</code>, <code id="Trinorm_+3A_mean2">mean2</code>, <code id="Trinorm_+3A_mean3">mean3</code></td>
<td>

<p>vectors of means.
</p>
</td></tr>
<tr><td><code id="Trinorm_+3A_var1">var1</code>, <code id="Trinorm_+3A_var2">var2</code>, <code id="Trinorm_+3A_var3">var3</code></td>
<td>

<p>vectors of variances.
</p>
</td></tr>
<tr><td><code id="Trinorm_+3A_cov12">cov12</code>, <code id="Trinorm_+3A_cov23">cov23</code>, <code id="Trinorm_+3A_cov13">cov13</code></td>
<td>

<p>vectors of covariances.
</p>
</td></tr>



<tr><td><code id="Trinorm_+3A_n">n</code></td>
<td>
<p>number of observations.
Same as <code><a href="stats.html#topic+rnorm">rnorm</a></code>.
</p>
</td></tr>
<tr><td><code id="Trinorm_+3A_log">log</code></td>
<td>

<p>Logical.
If <code>log = TRUE</code> then the logarithm of the density is returned.
</p>
</td></tr>



</table>


<h3>Details</h3>

<p>The default arguments correspond to the standard trivariate normal
distribution with correlation parameters equal to 0,
which corresponds to three independent standard normal distributions.
Let <code>sd1</code> (say) be <code>sqrt(var1)</code> and
written <code class="reqn">\sigma_1</code>, etc.
Then the general formula for each correlation coefficient is
of the form
<code class="reqn">\rho_{12} = cov_{12} / (\sigma_1 \sigma_2)</code>,
and similarly for the two others.
Thus if the <code>var</code> arguments are left alone then
the <code>cov</code> can be inputted with <code class="reqn">\rho</code>s.
</p>


<h3>Value</h3>

<p><code>dtrinorm</code> gives the density,
<code>rtrinorm</code> generates random deviates (<code class="reqn">n</code> by 3 matrix).
</p>



<h3>Warning</h3>

<p><code>dtrinorm()</code>'s arguments might change in the future!
It's safest to use the full argument names
to future-proof possible changes!
</p>


<h3>Note</h3>

<p>For <code>rtrinorm()</code>,
if the <code class="reqn">i</code>th variance-covariance matrix is not
positive-definite then the <code class="reqn">i</code>th row is all <code>NA</code>s.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pnorm">pnorm</a></code>,
<code><a href="#topic+trinormal">trinormal</a></code>,
<code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+binormal">binormal</a></code>,
<code><a href="#topic+rbinorm">rbinorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: nn &lt;- 1000
tdata &lt;- data.frame(x2 = sort(runif(nn)))
tdata &lt;- transform(tdata, mean1 = 1 + 2 * x2,
                   mean2 = 3 + 1 * x2, mean3 = 4,
                   var1 = exp( 1), var2 = exp( 1), var3 = exp( 1),
                   rho12 = rhobitlink( 1, inverse = TRUE),
                   rho23 = rhobitlink( 1, inverse = TRUE),
                   rho13 = rhobitlink(-1, inverse = TRUE))
ymat &lt;- with(tdata, rtrinorm(nn, mean1, mean2, mean3,
                             var1, var2, var3,
                             sqrt(var1)*sqrt(var1)*rho12,
                             sqrt(var2)*sqrt(var3)*rho23,
                             sqrt(var1)*sqrt(var3)*rho13))
pairs(ymat, col = "blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='trinormal'> Trivariate Normal Distribution Family Function </h2><span id='topic+trinormal'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the nine parameters of a trivariate
normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trinormal(zero = c("sd", "rho"), eq.mean = FALSE,
  eq.sd = FALSE, eq.cor = FALSE,
  lmean1 = "identitylink", lmean2 = "identitylink",
  lmean3 = "identitylink",
  lsd1   = "loglink", lsd2   = "loglink", lsd3   = "loglink",
  lrho12 = "rhobitlink", lrho23 = "rhobitlink", lrho13 = "rhobitlink",
  imean1 = NULL, imean2 = NULL, imean3 = NULL,
  isd1   = NULL, isd2   = NULL, isd3   = NULL,
  irho12 = NULL, irho23 = NULL, irho13 = NULL, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trinormal_+3A_lmean1">lmean1</code>, <code id="trinormal_+3A_lmean2">lmean2</code>, <code id="trinormal_+3A_lmean3">lmean3</code>, <code id="trinormal_+3A_lsd1">lsd1</code>, <code id="trinormal_+3A_lsd2">lsd2</code>, <code id="trinormal_+3A_lsd3">lsd3</code></td>
<td>

<p>Link functions applied to the means and standard deviations.
See <code><a href="#topic+Links">Links</a></code> for more choices.
Being positive quantities, a log link is the default for the
standard deviations.
</p>
</td></tr>
<tr><td><code id="trinormal_+3A_lrho12">lrho12</code>, <code id="trinormal_+3A_lrho23">lrho23</code>, <code id="trinormal_+3A_lrho13">lrho13</code></td>
<td>

<p>Link functions applied to the correlation parameters.
See <code><a href="#topic+Links">Links</a></code> for more choices.
By default the correlation parameters are allowed to have
a value between -1 and 1, but that may be problematic
when <code>eq.cor = TRUE</code> because they should have a value
between -0.5 and 1.
</p>

</td></tr>
<tr><td><code id="trinormal_+3A_imean1">imean1</code>, <code id="trinormal_+3A_imean2">imean2</code>, <code id="trinormal_+3A_imean3">imean3</code>, <code id="trinormal_+3A_isd1">isd1</code>, <code id="trinormal_+3A_isd2">isd2</code>, <code id="trinormal_+3A_isd3">isd3</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="trinormal_+3A_irho12">irho12</code>, <code id="trinormal_+3A_irho23">irho23</code>, <code id="trinormal_+3A_irho13">irho13</code>, <code id="trinormal_+3A_imethod">imethod</code>, <code id="trinormal_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="trinormal_+3A_eq.mean">eq.mean</code>, <code id="trinormal_+3A_eq.sd">eq.sd</code>, <code id="trinormal_+3A_eq.cor">eq.cor</code></td>
<td>

<p>Logical.
Constrain the means or the standard deviations
or correlation parameters to be equal?
</p>


</td></tr>
</table>


<h3>Details</h3>

<p>For the trivariate normal distribution,
this fits a linear model (LM) to the means, and
by default,
the other parameters are intercept-only.
The response should be a three-column matrix.
The three correlation parameters are prefixed by <code>rho</code>,
and the default gives them values between <code class="reqn">-1</code> and <code class="reqn">1</code>
however, this may be problematic when the correlation parameters
are constrained to be equal, etc..
The fitted means are returned as the fitted values, which is in
the form of a three-column matrix.
Fisher scoring is implemented.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>The default parameterization does not make the estimated
variance-covariance matrix positive-definite.
In order for the variance-covariance matrix to be positive-definite
the quantity
<code>1 - rho12^2 - rho13^2 - rho23^2 + 2 * rho12 * rho13 * rho23</code>
must be positive, and if <code>eq.cor = TRUE</code> then
this means that the <code>rho</code>s must be between -0.5 and 1.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+uninormal">uninormal</a></code>,
<code><a href="#topic+binormal">binormal</a></code>,
<code><a href="#topic+rtrinorm">rtrinorm</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>## Not run:   set.seed(123); nn &lt;- 1000
tdata &lt;- data.frame(x2 = runif(nn), x3 = runif(nn))
tdata &lt;- transform(tdata, y1 = rnorm(nn, 1 + 2 * x2),
                          y2 = rnorm(nn, 3 + 4 * x2),
                          y3 = rnorm(nn, 4 + 5 * x2))
fit1 &lt;- vglm(cbind(y1, y2, y3) ~ x2, data = tdata,
             trinormal(eq.sd = TRUE, eq.cor = TRUE), trace = TRUE)
coef(fit1, matrix = TRUE)
constraints(fit1)
summary(fit1)
# Try this when eq.sd = TRUE, eq.cor = TRUE:
fit2 &lt;-
  vglm(cbind(y1, y2, y3) ~ x2, data = tdata, stepsize = 0.25,
       trinormal(eq.sd = TRUE, eq.cor = TRUE,
                 lrho12 = extlogitlink(min = -0.5),
                 lrho23 = extlogitlink(min = -0.5),
                 lrho13 = extlogitlink(min = -0.5)), trace = TRUE)
coef(fit2, matrix = TRUE)

## End(Not run)</code></pre>

<hr>
<h2 id='trplot'> Trajectory Plot </h2><span id='topic+trplot'></span>

<h3>Description</h3>

<p>Generic function for a trajectory plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trplot(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trplot_+3A_object">object</code></td>
<td>
<p> An object for which a trajectory plot
is meaningful.
</p>
</td></tr>
<tr><td><code id="trplot_+3A_...">...</code></td>
<td>
<p> Other arguments fed into the specific
methods function of the model. They usually are graphical
parameters, and sometimes they are fed
into the methods function for <code><a href="#topic+Coef">Coef</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Trajectory plots can be defined in different ways for different
models.
Many models have no such notion or definition.
</p>
<p>For quadratic and additive ordination models they plot the
fitted values of two species against each other (more than
two is theoretically possible, but not implemented
in this software
yet).
</p>


<h3>Value</h3>

<p>The value returned depends specifically on the methods
function invoked.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2020).
On constrained and unconstrained
quadratic ordination.
<em>Manuscript in preparation</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trplot.qrrvglm">trplot.qrrvglm</a></code>,
<code><a href="#topic+perspqrrvglm">perspqrrvglm</a></code>,
<code><a href="#topic+lvplot">lvplot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  set.seed(123)
hspider[, 1:6] &lt;- scale(hspider[, 1:6])  # Stdze environ. vars
p1cqo &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute,
                   Arctperi, Auloalbi, Pardlugu, Pardmont,
                   Pardnigr, Pardpull, Trocterr, Zoraspin) ~
            WaterCon + BareSand + FallTwig +
            CoveMoss + CoveHerb + ReflLux,
            poissonff, data = hspider, Crow1positive = FALSE)

nos &lt;- ncol(depvar(p1cqo))
clr &lt;- 1:nos  # OR (1:(nos+1))[-7]  to omit yellow

trplot(p1cqo, which.species = 1:3, log = "xy", lwd = 2,
       col = c("blue", "orange", "green"), label = TRUE) -&gt; ii
legend(0.00005, 0.3, paste(ii$species[, 1], ii$species[, 2],
                           sep = " and "),
       lwd = 2, lty = 1, col = c("blue", "orange", "green"))
abline(a = 0, b = 1, lty = "dashed", col = "grey") 
## End(Not run)
</code></pre>

<hr>
<h2 id='trplot.qrrvglm'> Trajectory plot for QRR-VGLMs </h2><span id='topic+trplot.qrrvglm'></span>

<h3>Description</h3>

<p>Produces a trajectory plot for
<em>quadratic reduced-rank vector generalized linear models</em>
(QRR-VGLMs).
It is only applicable for rank-1 models with argument
<code>noRRR = ~ 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trplot.qrrvglm(object, which.species = NULL, add = FALSE,
               show.plot = TRUE,
               label.sites = FALSE, sitenames = rownames(object@y),
               axes.equal = TRUE, cex = par()$cex,
               col = 1:(nos * (nos - 1)/2), log = "",
               lty = rep_len(par()$lty, nos * (nos - 1)/2),
               lwd = rep_len(par()$lwd, nos * (nos - 1)/2),
               tcol = rep_len(par()$col, nos * (nos - 1)/2),
               xlab = NULL, ylab = NULL,
               main = "", type = "b", check.ok = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trplot.qrrvglm_+3A_object">object</code></td>
<td>
<p> Object of class <code>"qrrvglm"</code>,
i.e., a CQO object. </p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_which.species">which.species</code></td>
<td>
<p> Integer or character vector specifying the
species to be plotted. If integer, these are the columns of the
response matrix. If character, these must match exactly with the
species' names.
The default is to use all species.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_add">add</code></td>
<td>
<p> Logical. Add to an existing plot?
If <code>FALSE</code> (default),
a new plot is made. </p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_show.plot">show.plot</code></td>
<td>
<p> Logical. Plot it? </p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_label.sites">label.sites</code></td>
<td>
<p> Logical. If <code>TRUE</code>, the points on the
curves/trajectories are labelled with the <code>sitenames</code>. </p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_sitenames">sitenames</code></td>
<td>
<p> Character vector. The names of the sites. </p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_axes.equal">axes.equal</code></td>
<td>
<p> Logical. If <code>TRUE</code>, the x- and y-axes
will be on the same scale.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_cex">cex</code></td>
<td>
<p> Character expansion of the labelling
of the site names.
Used only if <code>label.sites</code> is <code>TRUE</code>.
See the <code>cex</code> argument in <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_col">col</code></td>
<td>
<p>Color of the lines.
See the <code>col</code> argument in <code><a href="graphics.html#topic+par">par</a></code>.
Here, <code>nos</code> is the number of species.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_log">log</code></td>
<td>
<p> Character, specifying which (if any) of the x- and
y-axes are to be on a logarithmic scale.
See the <code>log</code> argument in <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_lty">lty</code></td>
<td>
<p>  Line type.
See the <code>lty</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_lwd">lwd</code></td>
<td>
<p>  Line width.
See the <code>lwd</code> argument of <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_tcol">tcol</code></td>
<td>
<p>Color of the text for the site names.
See the <code>col</code> argument in <code><a href="graphics.html#topic+par">par</a></code>.
Used only if <code>label.sites</code> is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_xlab">xlab</code></td>
<td>
<p>Character caption for the x-axis.
By default, a suitable caption is found.
See the <code>xlab</code> argument in <code><a href="graphics.html#topic+plot">plot</a></code>
or <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_ylab">ylab</code></td>
<td>
<p>Character caption for the y-axis.
By default, a suitable caption is found.
See the <code>xlab</code> argument in <code><a href="graphics.html#topic+plot">plot</a></code>
or <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_main">main</code></td>
<td>
<p> Character, giving the title of the plot.
See the <code>main</code> argument in <code><a href="graphics.html#topic+plot">plot</a></code>
or <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_type">type</code></td>
<td>
<p> Character, giving the type of plot. A common
option is to use <code>type="l"</code> for lines only.
See the <code>type</code> argument of <code><a href="graphics.html#topic+plot">plot</a></code>.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_check.ok">check.ok</code></td>
<td>
<p> Logical. Whether a check is performed to see
that <code>noRRR = ~ 1</code> was used.
It doesn't make sense to have a trace plot unless this is so.
</p>
</td></tr>
<tr><td><code id="trplot.qrrvglm_+3A_...">...</code></td>
<td>
<p> Arguments passed into the <code>plot</code> function
when setting up the entire plot. Useful arguments here include
<code>xlim</code> and <code>ylim</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A trajectory plot plots the fitted values of a &lsquo;second&rsquo; species
against a &lsquo;first&rsquo; species. The argument <code>which.species</code> must
therefore contain at least two species. By default, all of the
species that were fitted in <code>object</code> are plotted.
With more than a few species
the resulting plot will be very congested, and so it
is recommended
that only a few species be selected for plotting.
</p>
<p>In the above, <code class="reqn">M</code> is the number of species selected
for plotting,
so there will be <code class="reqn">M(M-1)/2</code> curves/trajectories
in total.
</p>
<p>A trajectory plot will be fitted only
if <code>noRRR = ~ 1</code> because
otherwise the trajectory will not be a smooth function
of the latent
variables.
</p>


<h3>Value</h3>

<p>A list with the following components.
</p>
<table>
<tr><td><code>species.names</code></td>
<td>

<p>A matrix of characters giving
the &lsquo;first&rsquo; and &lsquo;second&rsquo; species. The
number of different combinations of
species is given by the number
of rows.  This is useful for creating a legend.
</p>
</td></tr>
<tr><td><code>sitenames</code></td>
<td>
<p>A character vector of site names, sorted by
the latent variable (from low to high).
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Plotting the axes on a log scale is often a good idea.
The use of <code>xlim</code> and <code>ylim</code> to control
the axis limits
is also a good idea, so as to limit the extent
of the curves at low
abundances or probabilities.
Setting <code>label.sites = TRUE</code>
is a good idea only if the number of
sites is small, otherwise there is too much clutter.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2020).
On constrained and unconstrained
quadratic ordination.
<em>Manuscript in preparation</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cqo">cqo</a></code>,
<code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="graphics.html#topic+title">title</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  set.seed(111)  # Leads to the global solution
# hspider[,1:6] &lt;- scale(hspider[,1:6])  # Stdze the environ vars
p1 &lt;- cqo(cbind(Alopacce, Alopcune, Alopfabr, Arctlute,
                Arctperi, Auloalbi, Pardlugu, Pardmont,
                Pardnigr, Pardpull, Trocterr, Zoraspin) ~
          WaterCon + BareSand + FallTwig + CoveMoss +
          CoveHerb + ReflLux,
          poissonff, data = hspider, trace = FALSE)

trplot(p1, which.species = 1:3, log = "xy", type = "b", lty = 1,
       main = "Trajectory plot of three hunting spiders species",
       col = c("blue","red","green"), lwd = 2, label = TRUE) -&gt; ii
legend(0.00005, 0.3, lwd = 2, lty = 1,
       col = c("blue", "red", "green"),
       with(ii, paste(species.names[,1], species.names[,2],
                      sep = " and ")))
abline(a = 0, b = 1, lty = "dashed", col = "grey")  # Ref. line

## End(Not run)
</code></pre>

<hr>
<h2 id='Trunc'> Truncated Values for the GT-Expansion Method
</h2><span id='topic+Trunc'></span>

<h3>Description</h3>

<p>Given the minimum and maximum values in a response variable,
and a positive multiplier,
returns the truncated values 
for generally-truncated regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Trunc(Range, mux = 2, location = 0, omits = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Trunc_+3A_range">Range</code></td>
<td>

<p>Numeric, of length 2 containing the minimum and maximum
(in that order) of the untransformed data.
Alternatively, if <code>length(Range) &gt; 2</code> then it is assumed
that the entire untransformed data is passed in so that
<code><a href="base.html#topic+range">range</a></code> is applied.
</p>
</td></tr>
<tr><td><code id="Trunc_+3A_mux">mux</code></td>
<td>

<p>Numeric,
the multiplier.
A positive integer.
</p>
</td></tr>
<tr><td><code id="Trunc_+3A_location">location</code></td>
<td>

<p>Numeric,
the location parameter, allows a shift to the right.
</p>
</td></tr>
<tr><td><code id="Trunc_+3A_omits">omits</code></td>
<td>

<p>Logical.
The default is to return the truncated values (those being
omitted).
If <code>FALSE</code> then the multiples are returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generally-truncated regression can handle underdispersion
with respect to some parent or base distribution such as the
Poisson.
Yee and Ma (2023) call this the
<em>GT-Expansion</em> (GTE) method,
which is a special case of the GT-location-scale (GT-LS) method.
This is a utility function to help make life easier.
It is assumed that the response is a count variable.
</p>


<h3>Value</h3>

<p>A vector of values to be fed into the <code>truncate</code> argument
of a <span class="pkg">VGAM</span> family function such as <code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>.
If <code>mux = 1</code> then the function will return a <code>NULL</code>
rather than <code>integer(0)</code>.
</p>



<h3>Author(s)</h3>

<p> T. W. Yee</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+gaitdlog">gaitdlog</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="base.html#topic+range">range</a></code>,
<code><a href="base.html#topic+setdiff">setdiff</a></code>,
<code><a href="#topic+goffset">goffset</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>Trunc(c(1, 8), 2)

## Not run: 
set.seed(1)  # The following example is based on the normal
mymean &lt;- 20; m.truth &lt;- 3  # approximation to the Poisson.
gdata &lt;- data.frame(y1 = round(rnorm((nn &lt;- 1000), mymean,
                                     sd = sqrt(mymean / m.truth))))
org1 &lt;- with(gdata, range(y1))  # Original range of the raw data
m.max &lt;- 5  # Try multipliers 1:m.max
logliks &lt;- numeric(m.max)
names(logliks) &lt;- as.character(1:m.max)
for (i in 1:m.max) {
  logliks[i] &lt;- logLik(vglm(i * y1 ~ offset(rep(log(i), nn)),
    gaitdpoisson(truncate = Trunc(org1, i)), data = gdata))
}
sort(logliks, decreasing = TRUE)  # Best to worst
 par(mfrow = c(1, 2))
plot(with(gdata, table(y1)))  # Underdispersed wrt Poisson
plot(logliks, col = "blue", type = "b", xlab = "Multiplier") 
## End(Not run)
</code></pre>

<hr>
<h2 id='Truncpareto'>The Truncated Pareto Distribution</h2><span id='topic+Truncpareto'></span><span id='topic+dtruncpareto'></span><span id='topic+ptruncpareto'></span><span id='topic+qtruncpareto'></span><span id='topic+rtruncpareto'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the upper truncated Pareto(I) distribution with
parameters <code>lower</code>, <code>upper</code> and <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dtruncpareto(x, lower, upper, shape, log = FALSE)
ptruncpareto(q, lower, upper, shape, lower.tail = TRUE, log.p = FALSE)
qtruncpareto(p, lower, upper, shape)
rtruncpareto(n, lower, upper, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Truncpareto_+3A_x">x</code>, <code id="Truncpareto_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Truncpareto_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Truncpareto_+3A_n">n</code>, <code id="Truncpareto_+3A_log">log</code></td>
<td>
<p>Same meaning as <code><a href="stats.html#topic+Uniform">runif</a></code>.
</p>
</td></tr>
<tr><td><code id="Truncpareto_+3A_lower">lower</code>, <code id="Truncpareto_+3A_upper">upper</code>, <code id="Truncpareto_+3A_shape">shape</code></td>
<td>

<p>the lower, upper and shape (<code class="reqn">k</code>) parameters.
If necessary, values are recycled.
</p>
</td></tr>
<tr><td><code id="Truncpareto_+3A_lower.tail">lower.tail</code>, <code id="Truncpareto_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+truncpareto">truncpareto</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter <code class="reqn">k</code> by maximum likelihood estimation,
for the formula of the probability density function and the
range restrictions imposed on the parameters.
</p>


<h3>Value</h3>

<p><code>dtruncpareto</code> gives the density,
<code>ptruncpareto</code> gives the distribution function,
<code>qtruncpareto</code> gives the quantile function, and
<code>rtruncpareto</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee and Kai Huang </p>


<h3>References</h3>

<p>Aban, I. B., Meerschaert, M. M. and Panorska, A. K. (2006).
Parameter estimation for the truncated Pareto distribution,
<em>Journal of the American Statistical Association</em>,
<b>101</b>(473),
270&ndash;277.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+truncpareto">truncpareto</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> lower &lt;- 3; upper &lt;- 8; kay &lt;- exp(0.5)
## Not run:  xx &lt;- seq(lower - 0.5, upper + 0.5, len = 401)
plot(xx, dtruncpareto(xx, low = lower, upp = upper, shape = kay),
     main = "Truncated Pareto density split into 10 equal areas",
     type = "l", ylim = 0:1, xlab = "x")
abline(h = 0, col = "blue", lty = 2)
qq &lt;- qtruncpareto(seq(0.1, 0.9, by = 0.1), low = lower, upp = upper,
                   shape = kay)
lines(qq, dtruncpareto(qq, low = lower, upp = upper, shape = kay),
      col = "purple", lty = 3, type = "h")
lines(xx, ptruncpareto(xx, low = lower, upp = upper, shape = kay),
      col = "orange") 
## End(Not run)
pp &lt;- seq(0.1, 0.9, by = 0.1)
qq &lt;- qtruncpareto(pp, lower = lower, upper = upper, shape = kay)

ptruncpareto(qq, lower = lower, upper = upper, shape = kay)
qtruncpareto(ptruncpareto(qq, lower = lower, upper = upper, shape = kay),
         lower = lower, upper = upper, shape = kay) - qq  # Should be all 0
</code></pre>

<hr>
<h2 id='truncweibull'> Truncated Weibull Distribution Family Function </h2><span id='topic+truncweibull'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the
2-parameter Weibull distribution
with lower truncation.
No observations should be censored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truncweibull(lower.limit = 1e-5,
             lAlpha = "loglink", lBetaa = "loglink",
             iAlpha = NULL,   iBetaa = NULL,
             nrfs = 1, probs.y = c(0.2, 0.5, 0.8),
             imethod = 1, zero = "Betaa")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="truncweibull_+3A_lower.limit">lower.limit</code></td>
<td>

<p>Positive lower truncation limits.
Recycled to the same dimension as the response, going
across rows first.
The default, being close to 0, should mean
effectively the same
results as <code><a href="#topic+weibullR">weibullR</a></code> if there are no response
values that are smaller.
</p>
</td></tr>
<tr><td><code id="truncweibull_+3A_lalpha">lAlpha</code>, <code id="truncweibull_+3A_lbetaa">lBetaa</code></td>
<td>

<p>Parameter link functions applied to the
(positive) parameters <code>Alpha</code>
(called <code class="reqn">\alpha</code> below) and
(positive) <code>Betaa</code> (called <code class="reqn">\beta</code> below).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="truncweibull_+3A_ialpha">iAlpha</code>, <code id="truncweibull_+3A_ibetaa">iBetaa</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="truncweibull_+3A_imethod">imethod</code>, <code id="truncweibull_+3A_nrfs">nrfs</code>, <code id="truncweibull_+3A_zero">zero</code>, <code id="truncweibull_+3A_probs.y">probs.y</code></td>
<td>

<p>Details at <code><a href="#topic+weibullR">weibullR</a></code>
and <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MLE of the two parameters of the Weibull distribution are
computed, subject to lower truncation.
That is, all response values are greater
than <code>lower.limit</code>,
element-wise.
For a particular observation this is any known positive value.
This function is currently based directly on
Wingo (1989) and his parameterization is used (it differs
from <code><a href="#topic+weibullR">weibullR</a></code>.)
In particular,
<code class="reqn">\beta = a</code> and <code class="reqn">\alpha = (1/b)^a</code>
where <code class="reqn">a</code> and <code class="reqn">b</code> are as in <code><a href="#topic+weibullR">weibullR</a></code> and
<code><a href="stats.html#topic+Weibull">dweibull</a></code>.
</p>


<p>Upon fitting the <code>extra</code> slot has a component called
<code>lower.limit</code> which is of the same dimension as the
response.
The fitted values are the mean, which are computed
using <code><a href="#topic+pgamma.deriv">pgamma.deriv</a></code>
and <code><a href="#topic+pgamma.deriv.unscaled">pgamma.deriv.unscaled</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This function may be converted to the same parameterization as
<code><a href="#topic+weibullR">weibullR</a></code> at any time.
Yet to do: one element of the EIM may be wrong (due to
two interpretations of a formula; but it seems to work).
Convergence is slower than usual and this may imply something
is wrong; use argument <code>maxit</code>.
In fact, it's probably
because <code><a href="#topic+pgamma.deriv.unscaled">pgamma.deriv.unscaled</a></code> is
inaccurate at <code>q = 1</code> and <code>q = 2</code>.
Also,
convergence should be monitored, especially if the truncation
means that a large proportion of the data is lost
compared to an
ordinary Weibull distribution.
</p>


<h3>Note</h3>

<p>More improvements need to be made, e.g.,
initial values are currently based on no truncation.
This <span class="pkg">VGAM</span> family function handles multiple responses.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Wingo, D. R. (1989).
The left-truncated Weibull distribution: theory and computation.
<em>Statistical Papers</em>,
<b>30</b>(1), 39&ndash;48.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+weibullR">weibullR</a></code>,
<code><a href="stats.html#topic+Weibull">dweibull</a></code>,
<code><a href="#topic+pgamma.deriv">pgamma.deriv</a></code>,
<code><a href="#topic+pgamma.deriv.unscaled">pgamma.deriv.unscaled</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 5000; prop.lost &lt;- 0.40   # Proportion lost to truncation
wdata &lt;- data.frame(x2 = runif(nn))  # Complete Weibull data
wdata &lt;- transform(wdata,
         Betaa = exp(1))  # &gt; 2 okay (satisfies regularity conds)
wdata &lt;- transform(wdata, Alpha = exp(0.5 - 1 * x2))
wdata &lt;- transform(wdata, Shape = Betaa,
#                         aaa   = Betaa,
#                         bbb   = 1 / Alpha^(1 / Betaa),
                          Scale = 1 / Alpha^(1 / Betaa))
wdata &lt;- transform(wdata, y2 = rweibull(nn, Shape, scale = Scale))
summary(wdata)

# Proportion lost:
lower.limit2 &lt;- with(wdata, quantile(y2, prob = prop.lost))
# Smaller due to truncation:
wdata &lt;- subset(wdata, y2 &gt; lower.limit2)

fit1 &lt;- vglm(y2 ~ x2, maxit = 100, trace = TRUE,
             truncweibull(lower.limit = lower.limit2), wdata)
coef(fit1, matrix = TRUE)
summary(fit1)
vcov(fit1)
head(fit1@extra$lower.limit)
</code></pre>

<hr>
<h2 id='ucberk'> University California Berkeley Graduate Admissions </h2><span id='topic+ucberk'></span>

<h3>Description</h3>

<p>University California Berkeley Graduate Admissions: counts
cross-classified by acceptance/rejection and gender, for
the six largest departments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ucberk)</code></pre>


<h3>Format</h3>

<p>A data frame with 6 departmental groups with the following 5 columns.
</p>

<dl>
<dt>m.deny</dt><dd><p>Counts of men denied admission. </p>
</dd>
<dt>m.admit</dt><dd><p>Counts of men admitted. </p>
</dd>
<dt>w.deny</dt><dd><p>Counts of women denied admission. </p>
</dd>
<dt>w.admit</dt><dd><p>Counts of women admitted. </p>
</dd>
<dt>dept</dt><dd><p>Department (the six largest),
called <code>A</code>, <code>B</code>, ..., <code>F</code>.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>From Bickel et al. (1975),
the data consists of applications for admission to graduate
study at the University of California, Berkeley, for the
fall 1973 quarter.
In the admissions cycle for that quarter,
the Graduate Division at Berkeley received approximately
15,000 applications, some of which were later withdrawn or
transferred to a different proposed entry quarter by the
applicants.  Of the applications finally remaining for the
fall 1973 cycle 12,763 were sufficiently complete to permit
a decision.
There were about 101 graduate department and
interdepartmental graduate majors.  There were 8442 male
applicants and 4321 female applicants. About 44 percent of
the males and about 35 percent of the females were admitted.
The data are well-known for illustrating Simpson's paradox.
</p>


<h3>References</h3>

<p>Bickel, P. J., Hammel, E. A. and O'Connell, J. W. (1975).
Sex bias in graduate admissions: data from Berkeley.
<em>Science</em>, <b>187</b>(4175): 398&ndash;404.
</p>
<p>Freedman, D., Pisani, R. and Purves, R. (1998).
Chapter 2 of <em>Statistics</em>, 3rd. ed.,
W. W. Norton &amp; Company.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(ucberk)
</code></pre>

<hr>
<h2 id='undocumented-methods'> Undocumented Methods Functions </h2><span id='topic+is.zero+2CNULL-method'></span><span id='topic+is.zero+2Ccharacter-method'></span><span id='topic+is.zero+2Clogical-method'></span><span id='topic+vcov+2Cdrrvglm-method'></span><span id='topic+show+2Csummary.drrvglm-method'></span><span id='topic+summary+2Cdrrvglm-method'></span><span id='topic+coef+2Csummary.drrvglm-method'></span><span id='topic+coefficients+2Csummary.drrvglm-method'></span><span id='topic+show+2CCoef.drrvglm-method'></span><span id='topic+Coef+2Cdrrvglm-method'></span><span id='topic+rqresid+2Cvlm-method'></span><span id='topic+rqresid+2CANY-method'></span><span id='topic+rqresiduals+2Cvlm-method'></span><span id='topic+rqresiduals+2CANY-method'></span><span id='topic+KLD+2CANY-method'></span><span id='topic+KLD+2Cvglm-method'></span><span id='topic+plotdgaitd+2Cvglm-method'></span><span id='topic+is.altered+2CANY-method'></span><span id='topic+is.altered+2Cvglm-method'></span><span id='topic+is.inflated+2CANY-method'></span><span id='topic+is.inflated+2Cvglm-method'></span><span id='topic+is.deflated+2CANY-method'></span><span id='topic+is.deflated+2Cvglm-method'></span><span id='topic+is.truncated+2CANY-method'></span><span id='topic+is.truncated+2Cvglm-method'></span><span id='topic+Influence+2CANY-method'></span><span id='topic+Influence+2Cvgam-method'></span><span id='topic+Influence+2Cvglm-method'></span><span id='topic+Influence+2Crrvglm-method'></span><span id='topic+hdeff+2Cnumeric-method'></span><span id='topic+hdeff+2Cmatrix-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2CextlogF1-method'></span><span id='topic+showvglmS4VGAM+2CANY+2CextlogF1-method'></span><span id='topic+showvgamS4VGAM+2CANY+2CextlogF1-method'></span><span id='topic+eCDF+2Cvglm-method'></span><span id='topic+eCDF+2CANY-method'></span><span id='topic+fix.crossing+2Cvglm-method'></span><span id='topic+fix.crossing+2CANY-method'></span><span id='topic+is.crossing+2Cvglm-method'></span><span id='topic+is.crossing+2CANY-method'></span><span id='topic+altered+2CANY-method'></span><span id='topic+altered+2Cvglm-method'></span><span id='topic+inflated+2CANY-method'></span><span id='topic+inflated+2Cvglm-method'></span><span id='topic+truncated+2CANY-method'></span><span id='topic+truncated+2Cvglm-method'></span><span id='topic+specials+2CANY-method'></span><span id='topic+specials+2Cvglm-method'></span><span id='topic+get.offset+2CANY-method'></span><span id='topic+get.offset+2Cvglm-method'></span><span id='topic+rootogram4+2CANY-method'></span><span id='topic+rootogram4+2Cvglm-method'></span><span id='topic+step4+2CANY-method'></span><span id='topic+step4+2Cvglm-method'></span><span id='topic+add1+2Cvglm-method'></span><span id='topic+drop1+2Cvglm-method'></span><span id='topic+extractAIC+2Cvglm-method'></span><span id='topic+dfterms+2CANY-method'></span><span id='topic+dfterms+2Cvglm-method'></span><span id='topic+ordsup+2CANY-method'></span><span id='topic+ordsup+2Cvglm-method'></span><span id='topic+anova+2Cvglm-method'></span><span id='topic+lrt.stat+2CANY-method'></span><span id='topic+lrt.stat+2Cvlm-method'></span><span id='topic+wald.stat+2CANY-method'></span><span id='topic+wald.stat+2Cvlm-method'></span><span id='topic+score.stat+2CANY-method'></span><span id='topic+score.stat+2Cvlm-method'></span><span id='topic+TIC+2CANY-method'></span><span id='topic+TIC+2Cvlm-method'></span><span id='topic+hdeff+2Cvglm-method'></span><span id='topic+psint+2Cpvgam-method'></span><span id='topic+summary+2Cpvgam-method'></span><span id='topic+show+2Csummary.pvgam-method'></span><span id='topic+df.residual+2Cpvgam-method'></span><span id='topic+endf+2CANY-method'></span><span id='topic+endf+2Cpvgam-method'></span><span id='topic+endf+2Csummary.pvgam-method'></span><span id='topic+vcov+2Cpvgam-method'></span><span id='topic+show+2Cpvgam+2CANY-method'></span><span id='topic+show+2Cpvgam-method'></span><span id='topic+model.matrix+2Cpvgam-method'></span><span id='topic+plot+2Cpvgam+2CANY-method'></span><span id='topic+predictvglmS4VGAM+2CANY+2Cbinom2.or-method'></span><span id='topic+showvglmS4VGAM+2CANY+2Cacat-method'></span><span id='topic+showvgamS4VGAM+2CANY+2Cacat-method'></span><span id='topic+showvglmS4VGAM+2CANY+2Cmultinomial-method'></span><span id='topic+showvgamS4VGAM+2CANY+2Cmultinomial-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Cbinom2.or-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Cbinom2.or-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Cposbernoulli.tb-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Cposbernoulli.tb-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Cposbernoulli.b-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Cposbernoulli.t-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2CVGAMcategorical-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Ccumulative-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Cmultinomial-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Ccratio-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Csratio-method'></span><span id='topic+summaryvglmS4VGAM+2CANY+2Cacat-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2CVGAMcategorical-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Ccumulative-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Cmultinomial-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Ccratio-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Csratio-method'></span><span id='topic+showsummaryvglmS4VGAM+2CANY+2Cacat-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2CVGAMcategorical-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2CVGAMordinal-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Cacat-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Ccratio-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Csratio-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Ccumulative-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Cmultinomial-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Ctobit-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Cpoissonff-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Cnegbinomial-method'></span><span id='topic+margeffS4VGAM+2CANY+2CANY+2Cposnegbinomial-method'></span><span id='topic+term.names+2CANY-method'></span><span id='topic+term.names+2Cvlm-method'></span><span id='topic+responseName+2CANY-method'></span><span id='topic+responseName+2Cvlm-method'></span><span id='topic+has.intercept+2CANY-method'></span><span id='topic+has.intercept+2Cvlm-method'></span><span id='topic+confint+2CANY-method'></span><span id='topic+confint+2Cvglm-method'></span><span id='topic+confint+2Cvgam-method'></span><span id='topic+confint+2Crrvglm-method'></span><span id='topic+is.buggy+2CANY-method'></span><span id='topic+is.buggy+2Cvlm-method'></span><span id='topic+familyname+2CANY-method'></span><span id='topic+familyname+2Cvlm-method'></span><span id='topic+familyname+2Cvglmff-method'></span><span id='topic+nparam+2CANY-method'></span><span id='topic+nparam+2Cvlm-method'></span><span id='topic+nparam+2Cqrrvglm-method'></span><span id='topic+nparam+2Crrvgam-method'></span><span id='topic+nparam+2Cvgam-method'></span><span id='topic+nparam+2Cvglm-method'></span><span id='topic+nparam+2Crrvglm-method'></span><span id='topic+linkfun+2CANY-method'></span><span id='topic+linkfun+2Cvlm-method'></span><span id='topic+concoef+2CANY-method'></span><span id='topic+concoef+2Crrvgam-method'></span><span id='topic+concoef+2CCoef.rrvgam-method'></span><span id='topic+QR.R+2CANY-method'></span><span id='topic+QR.R+2Cvglm-method'></span><span id='topic+QR.Q+2CANY-method'></span><span id='topic+QR.Q+2Cvglm-method'></span><span id='topic+simulate+2CANY-method'></span><span id='topic+simulate+2Cvlm-method'></span><span id='topic+family.name+2CANY-method'></span><span id='topic+family.name+2Cvlm-method'></span><span id='topic+family.name+2Cvglmff-method'></span><span id='topic+BIC+2CANY-method'></span><span id='topic+BIC+2Cvlm-method'></span><span id='topic+BIC+2Cvglm-method'></span><span id='topic+BIC+2Cvgam-method'></span><span id='topic+BIC+2Crrvglm-method'></span><span id='topic+BIC+2Cqrrvglm-method'></span><span id='topic+BIC+2Crrvgam-method'></span><span id='topic+Rank+2Cqrrvglm-method'></span><span id='topic+Rank+2Crrvglm-method'></span><span id='topic+Rank+2Crrvgam-method'></span><span id='topic+model.matrix+2Cvsmooth.spline-method'></span><span id='topic+is.parallel+2Cmatrix-method'></span><span id='topic+is.parallel+2Cvglm-method'></span><span id='topic+is.parallel+2CANY-method'></span><span id='topic+is.zero+2Cmatrix-method'></span><span id='topic+is.zero+2Cvglm-method'></span><span id='topic+is.zero+2CANY-method'></span><span id='topic+show+2Cvglmff-method'></span><span id='topic+AIC+2CANY-method'></span><span id='topic+AICc+2CANY-method'></span><span id='topic+coef+2CANY-method'></span><span id='topic+logLik+2CANY-method'></span><span id='topic+plot+2CANY-method'></span><span id='topic+vcov+2CANY-method'></span><span id='topic+plot+2Crrvgam+2CANY-method'></span><span id='topic+plot+2Cqrrvglm+2CANY-method'></span><span id='topic+plot+2Crcim+2CANY-method'></span><span id='topic+plot+2Crcim0+2CANY-method'></span><span id='topic+plot+2Cvgam+2CANY-method'></span><span id='topic+plot+2Cvglm+2CANY-method'></span><span id='topic+plot+2Cvlm+2CANY-method'></span><span id='topic+plot+2Cvsmooth.spline+2CANY-method'></span><span id='topic+AIC+2Cvlm-method'></span><span id='topic+AIC+2Cvglm-method'></span><span id='topic+AIC+2Cvgam-method'></span><span id='topic+AIC+2Crrvglm-method'></span><span id='topic+AIC+2Cqrrvglm-method'></span><span id='topic+AIC+2Crrvgam-method'></span><span id='topic+AICc+2Cvlm-method'></span><span id='topic+attrassign+2Clm-method'></span><span id='topic+calibrate+2CANY-method'></span><span id='topic+cdf+2Cvglm-method'></span><span id='topic+cdf+2Cvgam-method'></span><span id='topic+coefficients+2Crrvgam-method'></span><span id='topic+coefficients+2Cvlm-method'></span><span id='topic+coefficients+2Cvglm-method'></span><span id='topic+coefficients+2Cqrrvglm-method'></span><span id='topic+coefficients+2Cvsmooth.spline-method'></span><span id='topic+coefficients+2Cvsmooth.spline.fit-method'></span><span id='topic+coefficients+2Csummary.vglm-method'></span><span id='topic+coefficients+2Csummary.rrvglm-method'></span><span id='topic+Coefficients+2Cvlm-method'></span><span id='topic+coef+2Crrvgam-method'></span><span id='topic+coef+2Cvlm-method'></span><span id='topic+coef+2Cvglm-method'></span><span id='topic+coef+2Cqrrvglm-method'></span><span id='topic+coef+2Cvsmooth.spline-method'></span><span id='topic+coef+2Cvsmooth.spline.fit-method'></span><span id='topic+coef+2Csummary.vglm-method'></span><span id='topic+coef+2Csummary.rrvglm-method'></span><span id='topic+Coef+2Crrvgam-method'></span><span id='topic+Coef+2Cvlm-method'></span><span id='topic+Coef+2Cqrrvglm-method'></span><span id='topic+Coef+2Crrvglm-method'></span><span id='topic+constraints+2Cvlm-method'></span><span id='topic+deplot+2Cvglm-method'></span><span id='topic+deplot+2Cvgam-method'></span><span id='topic+depvar+2CANY-method'></span><span id='topic+depvar+2Crrvgam-method'></span><span id='topic+depvar+2Cqrrvglm-method'></span><span id='topic+depvar+2Crcim-method'></span><span id='topic+depvar+2Crrvglm-method'></span><span id='topic+depvar+2Cvlm-method'></span><span id='topic+depvar+2Cvsmooth.spline-method'></span><span id='topic+deviance+2Crrvgam-method'></span><span id='topic+deviance+2Cqrrvglm-method'></span><span id='topic+deviance+2Cvlm-method'></span><span id='topic+df.residual+2Cvlm-method'></span><span id='topic+effects+2Cvlm-method'></span><span id='topic+fitted.values+2Cqrrvglm-method'></span><span id='topic+fitted.values+2Cvlm-method'></span><span id='topic+fitted.values+2Cvglm-method'></span><span id='topic+fitted.values+2Cvsmooth.spline-method'></span><span id='topic+fitted+2Cqrrvglm-method'></span><span id='topic+fitted+2Cvlm-method'></span><span id='topic+fitted+2Cvglm-method'></span><span id='topic+fitted+2Cvsmooth.spline-method'></span><span id='topic+case.names+2Cvlm-method'></span><span id='topic+case.names+2Cvgam-method'></span><span id='topic+case.names+2Cvglm-method'></span><span id='topic+case.names+2Crrvglm-method'></span><span id='topic+case.names+2Cqrrvglm-method'></span><span id='topic+case.names+2Cgrc-method'></span><span id='topic+variable.names+2Cvlm-method'></span><span id='topic+variable.names+2Cvgam-method'></span><span id='topic+variable.names+2Cvglm-method'></span><span id='topic+variable.names+2Crrvglm-method'></span><span id='topic+variable.names+2Cqrrvglm-method'></span><span id='topic+variable.names+2Cgrc-method'></span><span id='topic+formula+2Cvlm-method'></span><span id='topic+formula+2Cvgam-method'></span><span id='topic+formula+2Cvglm-method'></span><span id='topic+formula+2Crrvglm-method'></span><span id='topic+formula+2Cqrrvglm-method'></span><span id='topic+formula+2Cgrc-method'></span><span id='topic+hatvalues+2CANY-method'></span><span id='topic+hatvalues+2Cvlm-method'></span><span id='topic+hatvalues+2Cvglm-method'></span><span id='topic+hatvalues+2Crrvgam-method'></span><span id='topic+hatvalues+2Cqrrvglm-method'></span><span id='topic+hatvalues+2Crcim-method'></span><span id='topic+hatvalues+2Crrvglm-method'></span><span id='topic+hatplot+2CANY-method'></span><span id='topic+hatplot+2Cmatrix-method'></span><span id='topic+hatplot+2Cvlm-method'></span><span id='topic+hatplot+2Cvglm-method'></span><span id='topic+hatplot+2Crrvgam-method'></span><span id='topic+hatplot+2Cqrrvglm-method'></span><span id='topic+hatplot+2Crcim-method'></span><span id='topic+hatplot+2Crrvglm-method'></span><span id='topic+dfbeta+2CANY-method'></span><span id='topic+dfbeta+2Cmatrix-method'></span><span id='topic+dfbeta+2Cvlm-method'></span><span id='topic+dfbeta+2Cvglm-method'></span><span id='topic+dfbeta+2Crrvgam-method'></span><span id='topic+dfbeta+2Cqrrvglm-method'></span><span id='topic+dfbeta+2Crcim-method'></span><span id='topic+dfbeta+2Crrvglm-method'></span><span id='topic+guplot+2Cnumeric-method'></span><span id='topic+guplot+2Cvlm-method'></span><span id='topic+model.frame+2Cvlm-method'></span><span id='topic+predictors+2Cvglm-method'></span><span id='topic+rlplot+2Cvglm-method'></span><span id='topic+terms+2Cvlm-method'></span><span id='topic+is.bell+2Cqrrvglm-method'></span><span id='topic+is.bell+2Crrvglm-method'></span><span id='topic+is.bell+2Cvlm-method'></span><span id='topic+is.bell+2Crrvgam-method'></span><span id='topic+is.bell+2CCoef.qrrvglm-method'></span><span id='topic+logLik+2Cvlm-method'></span><span id='topic+logLik+2Csummary.vglm-method'></span><span id='topic+logLik+2Cvglm-method'></span><span id='topic+logLik+2Cvgam-method'></span><span id='topic+logLik+2Cqrrvglm-method'></span><span id='topic+logLik+2Crrvgam-method'></span><span id='topic+lvplot+2Crrvgam-method'></span><span id='topic+lvplot+2Cqrrvglm-method'></span><span id='topic+lvplot+2Crrvglm-method'></span><span id='topic+lv+2Crrvglm-method'></span><span id='topic+lv+2Cqrrvglm-method'></span><span id='topic+lv+2Crrvgam-method'></span><span id='topic+lv+2CCoef.rrvglm-method'></span><span id='topic+lv+2CCoef.qrrvglm-method'></span><span id='topic+lv+2CCoef.rrvgam-method'></span><span id='topic+latvar+2Crrvgam-method'></span><span id='topic+latvar+2CCoef.qrrvglm-method'></span><span id='topic+latvar+2CCoef.rrvglm-method'></span><span id='topic+latvar+2Crrvglm-method'></span><span id='topic+latvar+2Cqrrvglm-method'></span><span id='topic+Max+2Cqrrvglm-method'></span><span id='topic+Max+2CCoef.qrrvglm-method'></span><span id='topic+Max+2Crrvgam-method'></span><span id='topic+meplot+2Cnumeric-method'></span><span id='topic+meplot+2Cvlm-method'></span><span id='topic+model.matrix+2Cqrrvglm-method'></span><span id='topic+model.matrix+2Cvlm-method'></span><span id='topic+model.matrix+2Cvgam-method'></span><span id='topic+nobs+2CANY-method'></span><span id='topic+nobs+2Cvlm-method'></span><span id='topic+npred+2CANY-method'></span><span id='topic+npred+2Cvlm-method'></span><span id='topic+npred+2Crrvgam-method'></span><span id='topic+npred+2Cqrrvglm-method'></span><span id='topic+npred+2Crcim-method'></span><span id='topic+npred+2Crrvglm-method'></span><span id='topic+nvar+2CANY-method'></span><span id='topic+nvar+2Cvlm-method'></span><span id='topic+nvar+2Cvgam-method'></span><span id='topic+nvar+2Crrvglm-method'></span><span id='topic+nvar+2Cqrrvglm-method'></span><span id='topic+nvar+2Crrvgam-method'></span><span id='topic+nvar+2Cvlm-method'></span><span id='topic+nvar+2Crcim-method'></span><span id='topic+Opt+2Cqrrvglm-method'></span><span id='topic+Opt+2CCoef.qrrvglm-method'></span><span id='topic+Opt+2Crrvgam-method'></span><span id='topic+persp+2Crrvgam-method'></span><span id='topic+persp+2Cqrrvglm-method'></span><span id='topic+predict+2Crrvgam-method'></span><span id='topic+predict+2Cqrrvglm-method'></span><span id='topic+predict+2Cvgam-method'></span><span id='topic+predict+2Cvglm-method'></span><span id='topic+predict+2Crrvglm-method'></span><span id='topic+predict+2Cvlm-method'></span><span id='topic+predict+2Cvsmooth.spline-method'></span><span id='topic+predict+2Cvsmooth.spline.fit-method'></span><span id='topic+lrtest+2CANY-method'></span><span id='topic+lrtest+2Cvglm-method'></span><span id='topic+print+2CVGAManova-method'></span><span id='topic+show+2CVGAManova-method'></span><span id='topic+print+2CCoef.rrvgam-method'></span><span id='topic+print+2Csummary.rrvgam-method'></span><span id='topic+print+2Cqrrvglm-method'></span><span id='topic+print+2CCoef.qrrvglm-method'></span><span id='topic+print+2Crrvglm-method'></span><span id='topic+print+2Csummary.qrrvglm-method'></span><span id='topic+print+2CCoef.rrvglm-method'></span><span id='topic+print+2Cvlm-method'></span><span id='topic+print+2Cvglm-method'></span><span id='topic+print+2Cvgam-method'></span><span id='topic+print+2Csummary.rrvglm-method'></span><span id='topic+print+2Csummary.vgam-method'></span><span id='topic+print+2Csummary.vglm-method'></span><span id='topic+print+2Csummary.vlm-method'></span><span id='topic+print+2Cvsmooth.spline-method'></span><span id='topic+print+2Crrvgam-method'></span><span id='topic+qtplot+2Cvglm-method'></span><span id='topic+qtplot+2Cvgam-method'></span><span id='topic+residuals+2Cqrrvglm-method'></span><span id='topic+residuals+2Cvlm-method'></span><span id='topic+residuals+2Cvglm-method'></span><span id='topic+residuals+2Cvgam-method'></span><span id='topic+residuals+2Cvsmooth.spline-method'></span><span id='topic+resid+2Cqrrvglm-method'></span><span id='topic+resid+2Cvlm-method'></span><span id='topic+resid+2Cvglm-method'></span><span id='topic+resid+2Cvgam-method'></span><span id='topic+resid+2Cvsmooth.spline-method'></span><span id='topic+show+2CCoef.rrvgam-method'></span><span id='topic+show+2Csummary.rrvgam-method'></span><span id='topic+show+2Cqrrvglm-method'></span><span id='topic+show+2CCoef.qrrvglm-method'></span><span id='topic+show+2Crrvglm-method'></span><span id='topic+show+2Csummary.qrrvglm-method'></span><span id='topic+show+2CCoef.rrvglm-method'></span><span id='topic+show+2Cvlm-method'></span><span id='topic+show+2Cvglm-method'></span><span id='topic+show+2Cvgam-method'></span><span id='topic+show+2Csummary.rrvglm-method'></span><span id='topic+show+2Csummary.vgam-method'></span><span id='topic+show+2Csummary.vglm-method'></span><span id='topic+show+2Csummary.vlm-method'></span><span id='topic+show+2Cvsmooth.spline-method'></span><span id='topic+show+2Crrvgam-method'></span><span id='topic+summary+2Cgrc-method'></span><span id='topic+summary+2Crrvgam-method'></span><span id='topic+summary+2Cqrrvglm-method'></span><span id='topic+summary+2Crcim-method'></span><span id='topic+summary+2Crcim0-method'></span><span id='topic+summary+2Crrvglm-method'></span><span id='topic+summary+2Cvgam-method'></span><span id='topic+summary+2Cvglm-method'></span><span id='topic+summary+2Cvlm-method'></span><span id='topic+Tol+2Crrvgam-method'></span><span id='topic+Tol+2Cqrrvglm-method'></span><span id='topic+Tol+2CCoef.qrrvglm-method'></span><span id='topic+trplot+2Cqrrvglm-method'></span><span id='topic+trplot+2Crrvgam-method'></span><span id='topic+vcov+2Crrvglm-method'></span><span id='topic+vcov+2Cqrrvglm-method'></span><span id='topic+vcov+2Cvlm-method'></span><span id='topic+vcov+2Cvglm-method'></span><span id='topic+vplot+2Cfactor-method'></span><span id='topic+vplot+2Clist-method'></span><span id='topic+vplot+2Cmatrix-method'></span><span id='topic+vplot+2Cnumeric-method'></span><span id='topic+weights+2Cvlm-method'></span><span id='topic+weights+2Cvglm-method'></span>

<h3>Description</h3>

<p>Lots of undocumented methods functions are aliased here.
In the <span class="pkg">VGAM</span> package there are currently many
objects/methods/classes which are currently internal and/or
undocumented. The help file suppresses the warnings when the package is
'CHECK'ed.
</p>


<h3>Methods</h3>

<p>There are many methods and these will be documented over time.
</p>

<dl>
<dt>object</dt><dd>
<p>This argument is often used, and it is the primary object from which the
function operates on.
</p>
</dd>
</dl>


<hr>
<h2 id='uninormal'> Univariate Normal Distribution </h2><span id='topic+uninormal'></span><span id='topic+gaussianff'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the two parameters of a univariate
normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uninormal(lmean = "identitylink", lsd = "loglink", lvar =
          "loglink", var.arg = FALSE, imethod = 1, isd = NULL,
          parallel = FALSE, vfl = FALSE, Form2 = NULL,
 smallno = 1e-05, zero = if (var.arg)
          "var" else "sd")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uninormal_+3A_lmean">lmean</code>, <code id="uninormal_+3A_lsd">lsd</code>, <code id="uninormal_+3A_lvar">lvar</code></td>
<td>

<p>Link functions applied to the mean and standard
deviation/variance.  See <code><a href="#topic+Links">Links</a></code> for more choices.
Being positive quantities, a log link is the default for the
standard deviation and variance (see <code>var.arg</code>).
</p>
</td></tr>





<tr><td><code id="uninormal_+3A_var.arg">var.arg</code></td>
<td>

<p>Logical.
If <code>TRUE</code> then the second parameter is the variance and
<code>lsd</code> and <code>esd</code> are ignored,
else the standard deviation is used
and <code>lvar</code> and <code>evar</code> are ignored.
</p>
</td></tr>
<tr><td><code id="uninormal_+3A_smallno">smallno</code></td>
<td>

<p>Numeric, positive but close to 0.
Used specifically for quasi-variances; if the link for the
mean is <code><a href="#topic+explink">explink</a></code> then any non-positive value
of <code>eta</code> is replaced by this quantity (hopefully,
temporarily and only during early iterations).
</p>
</td></tr>
<tr><td><code id="uninormal_+3A_imethod">imethod</code>, <code id="uninormal_+3A_parallel">parallel</code>, <code id="uninormal_+3A_isd">isd</code>, <code id="uninormal_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
If <code>lmean = loglink</code> then try <code>imethod = 2</code>.
If <code>parallel = TRUE</code> then the parallelism constraint
is not applied to the intercept.
</p>
</td></tr>
<tr><td><code id="uninormal_+3A_vfl">vfl</code>, <code id="uninormal_+3A_form2">Form2</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This fits a linear model (LM) as the first linear/additive
predictor.
So, by default, this is just the mean.
By default,
the log of the standard deviation is the second linear/additive
predictor.  The Fisher information matrix is diagonal.
This <span class="pkg">VGAM</span> family function can handle multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p><code>gaussianff()</code> was deprecated but has been brought back
into <span class="pkg">VGAM</span> nominally.
It should be called Mickey Mouse.
It gives a warning and calls
<code><a href="#topic+uninormal">uninormal</a></code>
instead
(hopefully all the arguments should pass in correctly).
Users should avoid calling <code>gaussianff()</code>;
use <code><a href="stats.html#topic+glm">glm</a></code> with
<code><a href="stats.html#topic+gaussian">gaussian</a></code> instead.
It is dangerous to treat what is an
<code><a href="#topic+uninormal">uninormal</a></code> fit as a
<code>gaussianff()</code> object.
</p>


<h3>Note</h3>

<p>Yet to do: allow an argument such as <code>eq.sd</code> that enables
the standard devations to be the same.
Also, this function used to be called <code>normal1()</code> too,
but it has been decommissioned.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+posnormal">posnormal</a></code>,
<code><a href="#topic+mix2normal">mix2normal</a></code>,
<code><a href="#topic+ordsup">ordsup</a></code>,
<code><a href="#topic+normal.vcm">normal.vcm</a></code>,
<code><a href="#topic+Qvar">Qvar</a></code>,
<code><a href="#topic+tobit">tobit</a></code>,
<code><a href="#topic+cens.normal">cens.normal</a></code>,
<code><a href="#topic+foldnormal">foldnormal</a></code>,
<code><a href="#topic+skewnormal">skewnormal</a></code>,
<code><a href="#topic+double.cens.normal">double.cens.normal</a></code>,
<code><a href="#topic+SURff">SURff</a></code>,
<code><a href="#topic+AR1">AR1</a></code>,
<code><a href="#topic+huber2">huber2</a></code>,
<code><a href="#topic+studentt">studentt</a></code>,
<code><a href="#topic+binormal">binormal</a></code>,
<code><a href="#topic+trinormal">trinormal</a></code>,
<code><a href="stats.html#topic+Normal">dnorm</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>udata &lt;- data.frame(x2 = rnorm(nn &lt;- 200))
udata &lt;- transform(udata,
           y1  = rnorm(nn, m = 1 - 3*x2, sd = exp(1 + 0.2*x2)),
           y2a = rnorm(nn, m = 1 + 2*x2, sd = exp(1 + 2.0*x2)^0.5),
           y2b = rnorm(nn, m = 1 + 2*x2, sd = exp(1 + 2.0*x2)^0.5))
fit1 &lt;- vglm(y1 ~ x2, uninormal(zero = NULL), udata, trace = TRUE)
coef(fit1, matrix = TRUE)
fit2 &lt;- vglm(cbind(y2a, y2b) ~ x2, data = udata, trace = TRUE,
             uninormal(var = TRUE, parallel = TRUE ~ x2,
                       zero = NULL))
coef(fit2, matrix = TRUE)

# Generate data from N(mu=theta=10, sigma=theta) and estimate theta.
theta &lt;- 10
udata &lt;- data.frame(y3 = rnorm(100, m = theta, sd = theta))
fit3a &lt;- vglm(y3 ~ 1, uninormal(lsd = "identitylink"), data = udata,
             constraints = list("(Intercept)" = rbind(1, 1)))
fit3b &lt;- vglm(y3 ~ 1, uninormal(lsd = "identitylink",
                        parallel = TRUE ~ 1, zero = NULL), udata)
coef(fit3a, matrix = TRUE)
coef(fit3b, matrix = TRUE)  # Same as fit3a
</code></pre>

<hr>
<h2 id='UtilitiesVGAM'>Utility Functions for the VGAM Package </h2><span id='topic+UtilitiesVGAM'></span><span id='topic+param.names'></span><span id='topic+dimm'></span><span id='topic+interleave.VGAM'></span>

<h3>Description</h3>

<p>A set of common utility functions used by
<span class="pkg">VGAM</span> family functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>param.names(string, S = 1, skip1 = FALSE, sep = "")
dimm(M, hbw = M)
interleave.VGAM(.M, M1, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UtilitiesVGAM_+3A_string">string</code></td>
<td>

<p>Character.
Name of the parameter.
</p>
</td></tr>
<tr><td><code id="UtilitiesVGAM_+3A_m">M</code>, <code id="UtilitiesVGAM_+3A_.m">.M</code></td>
<td>

<p>Numeric. The total number of linear/additive predictors, called
<code class="reqn">M</code>.
By total, it is meant summed over the number of responses.
Often, <code class="reqn">M</code> is the total number of parameters to be estimated (but
this is not the same as the number of regression coefficients, unless
the RHS of the formula is an intercept-only).
The use of <code>.M</code> is unfortunate, but it is a compromise solution
to what is presented in Yee (2015).
Ideally, <code>.M</code> should be just <code>M</code>.
</p>
</td></tr>
<tr><td><code id="UtilitiesVGAM_+3A_m1">M1</code></td>
<td>

<p>Numeric. The number of linear/additive predictors for one response, called
<code class="reqn">M_1</code>.
This argument used to be called <code>M</code>, but is now renamed properly.
</p>
</td></tr>
<tr><td><code id="UtilitiesVGAM_+3A_inverse">inverse</code></td>
<td>

<p>Logical. Useful for the inverse function of <code>interleave.VGAM()</code>.
</p>
</td></tr>
<tr><td><code id="UtilitiesVGAM_+3A_s">S</code></td>
<td>

<p>Numeric. The number of responses.
</p>
</td></tr>
<tr><td><code id="UtilitiesVGAM_+3A_skip1">skip1</code>, <code id="UtilitiesVGAM_+3A_sep">sep</code></td>
<td>

<p>The former is logical;
should one skip (or omit) <code>"1"</code> when <code>S = 1</code>?
The latter is the same argument as <code><a href="base.html#topic+paste">paste</a></code>.
</p>
</td></tr>
<tr><td><code id="UtilitiesVGAM_+3A_hbw">hbw</code></td>
<td>

<p>Numeric. The half-bandwidth, which measures the number
of bands emanating from the central diagonal band.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Yee (2015) for some details about some of these functions.
</p>


<h3>Value</h3>

<p>For <code>param.names()</code>, this function returns the parameter names
for <code class="reqn">S</code> responses,
i.e., <code>string</code> is returned unchanged if <code class="reqn">S=1</code>,
else <code>paste(string, 1:S, sep = "")</code>.
</p>
<p>For <code>dimm()</code>, this function returns the number of elements
to be stored for each of the working weight matrices.
They are represented as columns in the matrix <code>wz</code> in
e.g., <code>vglm.fit()</code>.
See  the <em>matrix-band</em> format described in
Section 18.3.5 of Yee (2015).
</p>
<p>For <code>interleave.VGAM()</code>, this function returns a reordering
of the linear/additive predictors depending on the number of responses.
The arguments presented in Table 18.5 may not be valid
in your version of Yee (2015).
</p>


<h3>Author(s)</h3>

<p>T. W. Yee.
Victor Miranda added the <code>inverse</code> argument
to <code>interleave.VGAM()</code>.
</p>


<h3>References</h3>

<p>Yee, T. W. (2015).
Vector Generalized Linear and Additive Models:
With an Implementation in R.
New York, USA: <em>Springer</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+VGAM-package">VGAM-package</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>param.names("shape", 1)  # "shape"
param.names("shape", 3)  # c("shape1", "shape2", "shape3")

dimm(3, hbw = 1)  # Diagonal matrix; the 3 elements need storage.
dimm(3)  # A general 3 x 3 symmetrix matrix has 6 unique elements.
dimm(3, hbw = 2)  # Tridiagonal matrix; the 3-3 element is 0 and unneeded.

M1 &lt;- 2; ncoly &lt;- 3; M &lt;- ncoly * M1
mynames1 &lt;- param.names("location", ncoly)
mynames2 &lt;- param.names("scale",    ncoly)
(parameters.names &lt;- c(mynames1, mynames2)[interleave.VGAM(M, M1 = M1)])
# The  following is/was in Yee (2015) and has a poor/deceptive style:
(parameters.names &lt;- c(mynames1, mynames2)[interleave.VGAM(M, M  = M1)])
parameters.names[interleave.VGAM(M, M1 = M1, inverse = TRUE)]
</code></pre>

<hr>
<h2 id='V1'> V1 Flying-Bombs Hits in London </h2><span id='topic+V1'></span>

<h3>Description</h3>

<p>A small count data set.
During WWII V1 flying-bombs were fired from sites in France
(Pas-de-Calais) and Dutch coasts towards London.
The number of hits per square grid around London were recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(V1)
</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables.
</p>

<dl>
<dt>hits</dt><dd>
<p>Values between 0 and 4, and 7.
Actually, the 7 is really imputed from the paper
(it was recorded as &quot;5 and over&quot;).
</p>
</dd>
<dt>ofreq</dt><dd>
<p>Observed frequency, i.e., the number of grids
with that many hits.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data concerns 576 square grids each of 0.25 square kms
about south London.
The area was selected comprising 144 square kms over which
the basic probability function of the distribution was very
nearly constant.
V1s, which were one type of flying-bomb,
were a &ldquo;Vergeltungswaffen&rdquo; or vengeance weapon fired
during the summer of 1944 at London.
The V1s were informally called Buzz Bombs or Doodlebugs,
and they were pulse-jet-powered with a warhead of 850 kg of explosives.
Over 9500 were launched at London, and many were shot down by
artillery and the RAF.
Over the period considered the total number of bombs within the area
was 537.
</p>
<p>It was asserted that the bombs tended to be grouped in clusters.
However, a basic Poisson analysis shows this is not the case.
Their guidance system being rather primitive, the data
is consistent with a Poisson distribution (random).
</p>
<p>Compared to Clarke (1946),
the more modern analysis of Shaw and Shaw (2019).
shows a higher density of hits in south London,
hence the distribution is not really uniform over the
entire region.
</p>


<h3>Source</h3>

<p>Clarke, R. D. (1946).
An application of the Poisson distribution.
<em>Journal of the Institute of Actuaries</em>,
<b>72</b>(3), 481.
</p>


<h3>References</h3>





<p>Shaw, L. P. and Shaw, L. F. (2019).
The flying bomb and the actuary.
<em>Significance</em>, <b>16</b>(5): 12&ndash;17.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+V2">V2</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>V1
mean(with(V1, rep(hits, times = ofreq)))
 var(with(V1, rep(hits, times = ofreq)))
 sum(with(V1, rep(hits, times = ofreq)))
## Not run:  barplot(with(V1, ofreq),
          names.arg = as.character(with(V1, hits)),
          main = "London V1 buzz bomb hits",
          col = "lightblue", las = 1,
          ylab = "Frequency", xlab = "Hits") 
## End(Not run)
</code></pre>

<hr>
<h2 id='V2'> V2 Missile Hits in London </h2><span id='topic+V2'></span>

<h3>Description</h3>

<p>A small count data set.
During WWII V2 missiles were fired from the continent
mainly towards London.
The number of hits per square grid around London were recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(V2)
</code></pre>


<h3>Format</h3>

<p>A data frame with the following variables.
</p>

<dl>
<dt>hits</dt><dd>
<p>Values between 0 and 3.
</p>
</dd>
<dt>ofreq</dt><dd>
<p>Observed frequency, i.e., the number of grids
with that many hits.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data concerns 408 square grids each of 0.25 square kms
about south London (south of the River Thames).
They were picked in a rectangular region of 102 square kilometres
where the density of hits were roughly uniformly distributed.
The data is somewhat comparable to <code><a href="#topic+V1">V1</a></code> albeit
is a smaller data set.
</p>


<h3>Source</h3>

<p>Shaw, L. P. and Shaw, L. F. (2019).
The flying bomb and the actuary.
<em>Significance</em>, <b>16</b>(5): 12&ndash;17.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+V1">V1</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>V2
mean(with(V2, rep(hits, times = ofreq)))
 var(with(V2, rep(hits, times = ofreq)))
 sum(with(V2, rep(hits, times = ofreq)))
## Not run:  barplot(with(V2, ofreq),
          names.arg = as.character(with(V2, hits)),
          main = "London V2 rocket hits",
          col = "lightgreen", las = 1,
          ylab = "Frequency", xlab = "Hits") 
## End(Not run)
</code></pre>

<hr>
<h2 id='vcovvlm'> Calculate Variance-Covariance Matrix for
a Fitted
VLM or RR-VGLM or DRR-VGLM
or QRR-VGLM
Object
</h2><span id='topic+vcovvlm'></span><span id='topic+vcovrrvglm'></span><span id='topic+vcovdrrvglm'></span><span id='topic+vcovqrrvglm'></span>

<h3>Description</h3>

<p>Returns the variance-covariance matrix of the
parameters of
a fitted <code><a href="#topic+vlm-class">vlm-class</a></code> or
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code> or
<code><a href="#topic+drrvglm-class">drrvglm-class</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovvlm(object, dispersion = NULL, untransform = FALSE,
        complete = TRUE, ...)
vcovrrvglm(object, ...)
vcovdrrvglm(object, ...)
vcovqrrvglm(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovvlm_+3A_object">object</code></td>
<td>
<p> A fitted model object,
having class <code><a href="#topic+vlm-class">vlm-class</a></code> or
<code><a href="#topic+rrvglm-class">rrvglm-class</a></code> or
<code><a href="#topic+drrvglm-class">drrvglm-class</a></code> or
<code><a href="#topic+qrrvglm-class">qrrvglm-class</a></code> or
a superclass of such.
The former includes a <code><a href="#topic+vglm">vglm</a></code> object.
</p>
</td></tr>
<tr><td><code id="vcovvlm_+3A_dispersion">dispersion</code></td>
<td>

<p>Numerical.
This argument should not be used as
<span class="pkg">VGAM</span> will be phasing out
dispersion parameters.
Formerly, a value may be specified, else it
is estimated for quasi-GLMs
(e.g., method of moments).
For almost all other types of VGLMs it is
usually unity.
The value is multiplied by the raw
variance-covariance matrix.
</p>
</td></tr>
<tr><td><code id="vcovvlm_+3A_untransform">untransform</code></td>
<td>

<p>logical.
For intercept-only models with trivial
constraints;
if set <code>TRUE</code> then the parameter
link function is inverted
to give the answer for the untransformed/raw
parameter.
</p>
</td></tr>
<tr><td><code id="vcovvlm_+3A_complete">complete</code></td>
<td>
<p>An argument currently ignored.
Added only so that
<code>linearHypothesis()</code> in <span class="pkg">car</span>
can be called.
</p>


</td></tr>
<tr><td><code id="vcovvlm_+3A_...">...</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+vcov">vcov</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This methods function is based on the QR decomposition
of the (large) VLM model matrix and working weight matrices.
Currently
<code><a href="#topic+vcovvlm">vcovvlm</a></code>
operates on the fundamental
<code><a href="#topic+vlm-class">vlm-class</a></code> objects because pretty well
all modelling functions in <span class="pkg">VGAM</span> inherit from this.
Currently
<code><a href="#topic+vcovrrvglm">vcovrrvglm</a></code>
is not entirely reliable because the elements of the
<b>A</b>&ndash;<b>C</b> part of the matrix sometimes cannot be
computed very accurately, so that the entire matrix is
not positive-definite.
</p>
<p>For <code>"qrrvglm"</code> objects,
<code><a href="#topic+vcovqrrvglm">vcovqrrvglm</a></code>
is currently working with <code>Rank = 1</code>
objects or
when <code>I.tolerances = TRUE</code>.
Then the answer is conditional given <b>C</b>.
The code is based on
<code><a href="#topic+model.matrixqrrvglm">model.matrixqrrvglm</a></code>
so that the <code>dimnames</code> are the same.
</p>


<h3>Value</h3>

<p>Same as <code><a href="stats.html#topic+vcov">vcov</a></code>.
</p>


<h3>Note</h3>

<p>For some models inflated standard errors can occur, such as
parameter estimates near the boundary of the parameter space.
Detection for this is available for some models using
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>, which tests for an
Hauck-Donner effect (HDE) for each regression coefficient.
If the HDE is present, using
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code> should return more accurate p-values.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="stats.html#topic+vcov">vcov</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>,
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+model.matrixqrrvglm">model.matrixqrrvglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ndata &lt;- data.frame(x2 = runif(nn &lt;- 300))
ndata &lt;- transform(ndata, y1 = rnbinom(nn, mu = exp(3+x2), exp(1)),
                          y2 = rnbinom(nn, mu = exp(2-x2), exp(0)))
fit1 &lt;- vglm(cbind(y1, y2) ~ x2, negbinomial, ndata, trace = TRUE)
fit2 &lt;- rrvglm(y1 ~ x2, negbinomial(zero = NULL), data = ndata)
coef(fit1, matrix = TRUE)
vcov(fit1)
vcov(fit2)

## End(Not run)</code></pre>

<hr>
<h2 id='venice'> Venice Maximum Sea Levels Data</h2><span id='topic+venice'></span><span id='topic+venice90'></span>

<h3>Description</h3>

<p>Some sea levels data sets recorded at Venice, Italy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(venice)
data(venice90)
</code></pre>


<h3>Format</h3>

<p><code>venice</code> is a data frame with 51 observations
on the following 11
variables.
It concerns the maximum heights of sea levels between
1931 and 1981.
</p>

<dl>
<dt>year</dt><dd><p>a numeric vector. </p>
</dd>
<dt>r1,r2,r3,r4,r5,r6,r7,r8,r9,r10</dt><dd><p>numeric vectors;
<code>r1</code> is the highest recorded value,
<code>r2</code> is the second highest recorded value, etc.
</p>
</dd>
</dl>

<p><code>venice90</code> is a data frame with 455 observations
on the following
7 variables.
</p>

<dl>
<dt>year, month, day, hour </dt><dd><p>numeric vectors;
actual time of the recording. </p>
</dd>
<dt>sealevel</dt><dd><p>numeric; sea level. </p>
</dd>
<dt>ohour</dt><dd><p>numeric;
number of hours since the midnight
of 31 Dec 1939 and 1 Jan 1940.
</p>
</dd>
<dt>Year</dt><dd><p>numeric vector;
approximate year as a real number.
The formula is <code>start.year + ohour / (365.26 * 24)</code>
where <code>start.year</code> is 1940.
One can treat <code>Year</code> as continuous whereas
<code>year</code> can be treated as both continuous and discrete.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Sea levels are in cm.
For <code>venice90</code>, the value 0 corresponds to a fixed
reference point (e.g.,  the mean sea level
in 1897 at an old
palace of Venice). Clearly since the relative (perceived)
mean sea level has been increasing in trend over time (more
than an overall 0.4 m increase by 2010),
therefore the value 0 is
(now) a very low and unusual measurement.
</p>
<p>For <code>venice</code>, in 1935 only the top six values
were recorded.
</p>
<p>For <code>venice90</code>, this is a subset of
a data set provided by
Paolo Pirazzoli consisting of hourly sea
levels from 1940 to 2009.
Values greater than 90 cm were extracted,
and then declustered
(each cluster provides no more than one value, and
each value is at least 24 hours apart).
Thus the values are more likely to be independent.
Of the original <code>(2009-1940+1)*365.26*24</code> values
about 7 percent of these comprise <code>venice90</code>.
</p>
<p>Yet to do: check for consistency between the data sets.
Some external data sets elsewhere have some
extremes recorded
at times not exactly on the hour.
</p>


<h3>Source</h3>

<p>Pirazzoli, P. (1982)
Maree estreme a Venezia (periodo 1872&ndash;1981).
<em>Acqua Aria</em>, <b>10</b>, 1023&ndash;1039.
</p>
<p>Thanks to Paolo Pirazzoli and Alberto Tomasin
for the <code>venice90</code>
data.
</p>


<h3>References</h3>

<p>Smith, R. L. (1986).
Extreme value theory based on the <em>r</em>
largest annual events.
<em>Journal of Hydrology</em>,
<b>86</b>, 27&ndash;43.
</p>
<p>Battistin, D. and Canestrelli, P. (2006).
<em>La serie storica delle maree a Venezia, 1872&ndash;2004</em>
(in Italian),
Comune di Venezia.
Istituzione Centro Previsione e Segnalazioni Maree.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+guplot">guplot</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+gpd">gpd</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
matplot(venice[["year"]], venice[, -1], xlab = "Year",
        ylab = "Sea level (cm)", type = "l")

ymat &lt;- as.matrix(venice[, paste("r", 1:10, sep = "")])
fit1 &lt;- vgam(ymat ~ s(year, df = 3), gumbel(R = 365, mpv = TRUE),
             venice, trace = TRUE, na.action = na.pass)
head(fitted(fit1))

par(mfrow = c(2, 1), xpd = TRUE)
plot(fit1, se = TRUE, lcol = "blue", llwd = 2, slty = "dashed")

par(mfrow = c(1,1), bty = "l", xpd = TRUE, las = 1)
qtplot(fit1, mpv = TRUE, lcol = c(1, 2, 5), tcol = c(1, 2, 5),
       llwd = 2, pcol = "blue", tadj = 0.1)

plot(sealevel ~ Year, data = venice90, type = "h", col = "blue")
summary(venice90)
dim(venice90)
round(100 * nrow(venice90)/((2009-1940+1)*365.26*24), dig = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='vgam'> Fitting Vector Generalized Additive Models </h2><span id='topic+vgam'></span>

<h3>Description</h3>

<p>Fit a vector generalized additive model (VGAM).
Both 1st-generation VGAMs (based on backfitting) and
2nd-generation VGAMs (based on P-splines, with automatic
smoothing parameter selection) are implemented.
This is a large class
of models that includes generalized additive models
(GAMs) and vector
generalized linear models (VGLMs) as special cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgam(formula,
     family = stop("argument 'family' needs to be assigned"),
     data = list(), weights = NULL, subset = NULL,
     na.action = na.fail, etastart = NULL, mustart = NULL,
     coefstart = NULL, control = vgam.control(...),
     offset = NULL, method = "vgam.fit", model = FALSE,
     x.arg = TRUE, y.arg = TRUE, contrasts = NULL,
     constraints = NULL, extra = list(), form2 = NULL,
     qr.arg = FALSE, smart = TRUE, ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="vgam_+3A_formula">formula</code></td>
<td>

<p>a symbolic description of the model to be fit.
The RHS of the formula is applied to each
linear/additive predictor,
and should include at least one
<code><a href="#topic+sm.os">sm.os</a></code> term
or <code><a href="#topic+sm.ps">sm.ps</a></code> term
or <code><a href="#topic+s">s</a></code> term.
Mixing both together is not allowed.
Different variables in each linear/additive predictor
can be chosen by specifying constraint matrices.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_family">family</code></td>
<td>

<p>Same as for <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables
in the model.
By default the variables are taken from
<code>environment(formula)</code>, typically the
environment from which
<code>vgam</code> is called.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_weights">weights</code>, <code id="vgam_+3A_subset">subset</code>, <code id="vgam_+3A_na.action">na.action</code></td>
<td>

<p>Same as for <code><a href="#topic+vglm">vglm</a></code>.
Note that <code>subset</code> may be unreliable
and to get around
this problem it is best to
use <code><a href="base.html#topic+subset">subset</a></code> to create
a new smaller data frame and feed in the smaller data frame.
See below for an example.
This is a bug that needs fixing.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_etastart">etastart</code>, <code id="vgam_+3A_mustart">mustart</code>, <code id="vgam_+3A_coefstart">coefstart</code></td>
<td>

<p>Same as for <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_control">control</code></td>
<td>

<p>a list of parameters for controlling the fitting process.
See <code><a href="#topic+vgam.control">vgam.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_method">method</code></td>
<td>

<p>the method to be used in fitting the model.
The default (and presently only) method <code>vgam.fit</code>
uses iteratively reweighted least squares (IRLS).
</p>
</td></tr>
<tr><td><code id="vgam_+3A_constraints">constraints</code>, <code id="vgam_+3A_model">model</code>, <code id="vgam_+3A_offset">offset</code></td>
<td>

<p>Same as for <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_x.arg">x.arg</code>, <code id="vgam_+3A_y.arg">y.arg</code></td>
<td>

<p>logical values indicating whether the
model matrix and response
vector/matrix used in the fitting process
should be assigned in the
<code>x</code> and <code>y</code> slots.  Note the
model matrix is the LM model
matrix; to get the VGAM model matrix
type <code>model.matrix(vgamfit)</code>
where <code>vgamfit</code> is a <code>vgam</code> object.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_contrasts">contrasts</code>, <code id="vgam_+3A_extra">extra</code>, <code id="vgam_+3A_form2">form2</code>, <code id="vgam_+3A_qr.arg">qr.arg</code>, <code id="vgam_+3A_smart">smart</code></td>
<td>

<p>Same as for <code><a href="#topic+vglm">vglm</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam_+3A_...">...</code></td>
<td>

<p>further arguments passed into <code><a href="#topic+vgam.control">vgam.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A vector generalized additive model (VGAM)
is loosely defined
as a statistical model that is a function
of <code class="reqn">M</code> additive predictors.
The central formula is given by
</p>
<p style="text-align: center;"><code class="reqn">\eta_j = \sum_{k=1}^p f_{(j)k}(x_k)</code>
</p>

<p>where <code class="reqn">x_k</code> is the <code class="reqn">k</code>th explanatory variable
(almost always <code class="reqn">x_1=1</code> for the intercept term),
and
<code class="reqn">f_{(j)k}</code> are smooth functions of <code class="reqn">x_k</code>
that are estimated
by smoothers.
The first term in the summation is just the intercept.
Currently
two types of smoothers are
implemented:
<code><a href="#topic+s">s</a></code> represents
the older and more traditional one, called a
<em>vector (cubic smoothing spline) smoother</em> and is
based on Yee and Wild (1996);
it is more similar to the <span class="rlang"><b>R</b></span> package <span class="pkg">gam</span>.
The newer one is represented by
<code><a href="#topic+sm.os">sm.os</a></code> and
<code><a href="#topic+sm.ps">sm.ps</a></code>, and these are
based on O-splines and P-splines&mdash;they allow automatic
smoothing parameter selection; it is more similar
to the <span class="rlang"><b>R</b></span> package <span class="pkg">mgcv</span>.
</p>
<p>In the above, <code class="reqn">j=1,\ldots,M</code> where <code class="reqn">M</code> is finite.
If all the functions are constrained to be linear then
the resulting model is a vector generalized linear model
(VGLM).  VGLMs are best fitted with <code><a href="#topic+vglm">vglm</a></code>.
</p>
<p>Vector (cubic smoothing spline) smoothers are represented
by <code>s()</code> (see <code><a href="#topic+s">s</a></code>). Local
regression via <code>lo()</code> is <em>not</em> supported. The
results of <code>vgam</code> will differ from the <code>gam()</code>
(in the <span class="pkg">gam</span>) because <code>vgam()</code> uses a different
knot selection algorithm. In general, fewer knots are
chosen because the computation becomes expensive when
the number of additive predictors <code class="reqn">M</code> is large.
</p>
<p>Second-generation VGAMs are based on the
O-splines and P-splines.
The latter is due to Eilers and Marx (1996).
Backfitting is not required, and estimation is
performed using IRLS.
The function <code><a href="#topic+sm.os">sm.os</a></code> represents a <em>smart</em>
implementation of O-splines.
The function <code><a href="#topic+sm.ps">sm.ps</a></code> represents a <em>smart</em>
implementation of P-splines.
Written G2-VGAMs or P-VGAMs, this methodology
should not be used
unless the sample size is reasonably large.
Usually an UBRE predictive criterion is optimized
(at each IRLS iteration)
because the
scale parameter for VGAMs is usually assumed to be known.
This search for optimal smoothing parameters
does not always converge,
and neither is it totally reliable.
G2-VGAMs implicitly set <code>criterion = "coefficients"</code>
so that
convergence occurs when the change in the
regression coefficients
between 2 IRLS iterations is sufficiently small.
Otherwise the search for the optimal
smoothing parameters might
cause the log-likelihood to decrease
between 2 IRLS iterations.
Currently <em>outer iteration</em> is implemented,
by default,
rather than <em>performance iteration</em> because the latter
is more easy to converge to a local solution; see
Wood (2004) for details.
One can use <em>performance iteration</em>
by setting <code>Maxit.outer = 1</code> in
<code><a href="#topic+vgam.control">vgam.control</a></code>.
</p>


<p>The underlying algorithm of VGAMs is IRLS.
First-generation VGAMs (called G1-VGAMs)
are estimated by modified vector backfitting
using vector splines. O-splines are used as
the basis functions
for the vector (smoothing) splines, which are
a lower dimensional
version of natural B-splines.
The function <code>vgam.fit()</code> actually does the
work.  The smoothing code is based on F. O'Sullivan's
BART code.
</p>



<p>A closely related methodology based on VGAMs called
<em>constrained additive ordination</em> (CAO) first forms
a linear combination of the explanatory variables (called
<em>latent variables</em>) and then fits a GAM to these.
This is implemented in the function <code><a href="#topic+cao">cao</a></code>
for a very limited choice of family functions.
</p>


<h3>Value</h3>

<p>For G1-VGAMs and G2-VGAMs, an object of class
<code>"vgam"</code> or
<code>"pvgam"</code>
respectively
(see <code><a href="#topic+vgam-class">vgam-class</a></code>
and <code><a href="#topic+pvgam-class">pvgam-class</a></code>
for further information).
</p>


<h3>WARNING</h3>

<p>For G1-VGAMs,
currently <code>vgam</code> can only handle
constraint matrices <code>cmat</code>,
say, such that <code>crossprod(cmat)</code> is diagonal.
It can be detected by <code><a href="#topic+is.buggy">is.buggy</a></code>.
VGAMs with constraint matrices that have
non-orthogonal columns should
be fitted with
<code><a href="#topic+sm.os">sm.os</a></code> or
<code><a href="#topic+sm.ps">sm.ps</a></code> terms
instead of <code><a href="#topic+s">s</a></code>.
</p>

<p>See warnings in <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>


<h3>Note</h3>

<p>This function can fit a wide variety of
statistical models. Some of
these are harder to fit than others because
of inherent numerical
difficulties associated with some of them.
Successful model fitting
benefits from cumulative experience.
Varying the values of arguments
in the <span class="pkg">VGAM</span> family function itself
is a good first step if
difficulties arise, especially if initial
values can be inputted.
A second, more general step, is to vary
the values of arguments in
<code><a href="#topic+vgam.control">vgam.control</a></code>.
A third step is to make use of arguments
such as <code>etastart</code>,
<code>coefstart</code> and <code>mustart</code>.
</p>
<p>Some <span class="pkg">VGAM</span> family functions end in <code>"ff"</code>
to avoid interference with other functions, e.g.,
<code><a href="#topic+binomialff">binomialff</a></code>, <code><a href="#topic+poissonff">poissonff</a></code>.
This is because <span class="pkg">VGAM</span> family functions
are incompatible with
<code><a href="stats.html#topic+glm">glm</a></code> (and also
<code>gam()</code> in <span class="pkg">gam</span> and
<code><a href="mgcv.html#topic+gam">gam</a></code> in <span class="pkg">mgcv</span>).
</p>


<p>The smart prediction (<code><a href="#topic+smartpred">smartpred</a></code>) library
is packed with the <span class="pkg">VGAM</span> library.
</p>
<p>The theory behind the scaling parameter is currently being
made more rigorous, but it it should give the same value
as the scale parameter for GLMs.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Wood, S. N. (2004).
Stable and efficient multiple smoothing parameter estimation
for generalized additive models.
<em>J. Amer. Statist. Assoc.</em>, <b>99</b>(467): 673&ndash;686.
</p>
<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>
<p>Yee, T. W. (2008).
The <code>VGAM</code> Package.
<em>R News</em>, <b>8</b>, 28&ndash;39.
</p>
<p>Yee, T. W. (2015).
Vector Generalized Linear and Additive Models:
With an Implementation in R.
New York, USA: <em>Springer</em>.
</p>
<p>Yee, T. W. (2016).
Comments on &ldquo;Smoothing parameter and model selection for
general smooth models&rdquo;
by Wood, S. N. and Pya, N. and Safken, N.,
<em>J. Amer. Statist. Assoc.</em>, <b>110</b>(516).
</p>













<h3>See Also</h3>

<p><code><a href="#topic+is.buggy">is.buggy</a></code>,
<code><a href="#topic+vgam.control">vgam.control</a></code>,
<code><a href="#topic+vgam-class">vgam-class</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+plotvgam">plotvgam</a></code>,
<code><a href="#topic+summaryvgam">summaryvgam</a></code>,
<code><a href="#topic+summarypvgam">summarypvgam</a></code>,
<code><a href="#topic+sm.os">sm.os</a></code>,
<code><a href="#topic+sm.ps">sm.ps</a></code>,
<code><a href="#topic+s">s</a></code>,
<code><a href="mgcv.html#topic+magic">magic</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vsmooth.spline">vsmooth.spline</a></code>,
<code><a href="#topic+cao">cao</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nonparametric proportional odds model
pneumo &lt;- transform(pneumo, let = log(exposure.time))
vgam(cbind(normal, mild, severe) ~ s(let),
     cumulative(parallel = TRUE), data = pneumo, trace = TRUE)

# Nonparametric logistic regression
hfit &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, hunua)
## Not run:  plot(hfit, se = TRUE) 
phfit &lt;- predict(hfit, type = "terms", raw = TRUE, se = TRUE)
names(phfit)
head(phfit$fitted)
head(phfit$se.fit)
phfit$df
phfit$sigma

# Fit two species simultaneously
hfit2 &lt;- vgam(cbind(agaaus, kniexc) ~ s(altitude, df = c(2, 3)),
              binomialff(multiple.responses = TRUE), data = hunua)
coef(hfit2, matrix = TRUE)  # Not really interpretable
## Not run: 
plot(hfit2, se = TRUE, overlay = TRUE, lcol = 3:4, scol = 3:4)
ooo &lt;- with(hunua, order(altitude))
with(hunua, matplot(altitude[ooo], fitted(hfit2)[ooo,],
      ylim = c(0, 0.8), las = 1,type = "l", lwd = 2,
     xlab = "Altitude (m)", ylab = "Probability of presence",
     main = "Two plant species' response curves"))
with(hunua, rug(altitude))

## End(Not run)

# The 'subset' argument does not work here. Use subset() instead.
set.seed(1)
zdata &lt;- data.frame(x2 = runif(nn &lt;- 500))
zdata &lt;- transform(zdata, y = rbinom(nn, 1, 0.5))
zdata &lt;- transform(zdata, subS = runif(nn) &lt; 0.7)
sub.zdata &lt;- subset(zdata, subS)  # Use this instead
if (FALSE)
  fit4a &lt;- vgam(cbind(y, y) ~ s(x2, df = 2),
                binomialff(multiple.responses = TRUE),
                data = zdata, subset = subS)  # This fails!!!
fit4b &lt;- vgam(cbind(y, y) ~ s(x2, df = 2),
              binomialff(multiple.responses = TRUE),
              data = sub.zdata)  # This succeeds!!!
fit4c &lt;- vgam(cbind(y, y) ~ sm.os(x2),
              binomialff(multiple.responses = TRUE),
              data = sub.zdata)  # This succeeds!!!
## Not run: par(mfrow = c(2, 2))
plot(fit4b, se = TRUE, shade = TRUE, shcol = "pink")
plot(fit4c, se = TRUE, shade = TRUE, shcol = "pink")

## End(Not run)
</code></pre>

<hr>
<h2 id='vgam-class'>Class &ldquo;vgam&rdquo; </h2><span id='topic+vgam-class'></span>

<h3>Description</h3>

<p> Vector generalized additive models. </p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>vgam(...)</code>.

</p>


<h3>Slots</h3>


<dl>
<dt><code>nl.chisq</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
Nonlinear chi-squared values. </p>
</dd>
<dt><code>nl.df</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
Nonlinear chi-squared degrees of freedom values. </p>
</dd>
<dt><code>spar</code>:</dt><dd><p>Object of class <code>"numeric"</code>
containing the (scaled) smoothing parameters. </p>
</dd>
<dt><code>s.xargument</code>:</dt><dd><p>Object of
class <code>"character"</code>
holding the variable name of any <code>s()</code> terms. </p>
</dd>
<dt><code>var</code>:</dt><dd><p>Object of class <code>"matrix"</code> holding
approximate pointwise standard error information. </p>
</dd>
<dt><code>Bspline</code>:</dt><dd><p>Object of class <code>"list"</code>
holding the scaled (internal and boundary) knots, and the
fitted B-spline coefficients. These are used
for prediction. </p>
</dd>
<dt><code>extra</code>:</dt><dd><p>Object of class <code>"list"</code>;
the <code>extra</code> argument on entry to <code>vglm</code>. This
contains any extra information that might be needed
by the family function. </p>
</dd>
<dt><code>family</code>:</dt><dd><p>Object of class <code>"vglmff"</code>.
The family function.  </p>
</dd>
<dt><code>iter</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
The number of IRLS iterations used. </p>
</dd>
<dt><code>predictors</code>:</dt><dd><p>Object of class <code>"matrix"</code>
with <code class="reqn">M</code> columns which holds
the <code class="reqn">M</code> linear predictors. </p>
</dd>
<dt><code>assign</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
This named list gives information matching
the columns and the
(LM) model matrix terms.
</p>
</dd>
<dt><code>call</code>:</dt><dd><p>Object of class <code>"call"</code>,
from class
<code> "vlm"</code>.
The matched call.
</p>
</dd>
<dt><code>coefficients</code>:</dt><dd><p>Object of class
<code>"numeric"</code>, from class <code> "vlm"</code>.
A named vector of coefficients.
</p>
</dd>
<dt><code>constraints</code>:</dt><dd><p>Object of
class <code>"list"</code>, from
class <code> "vlm"</code>.
A named list of constraint matrices used in the fitting.
</p>
</dd>
<dt><code>contrasts</code>:</dt><dd><p>Object of
class <code>"list"</code>, from
class <code> "vlm"</code>.
The contrasts used (if any).
</p>
</dd>
<dt><code>control</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class
<code> "vlm"</code>.
A list of parameters for controlling the fitting process.
See <code><a href="#topic+vglm.control">vglm.control</a></code> for details.
</p>
</dd>
<dt><code>criterion</code>:</dt><dd><p>Object of
class <code>"list"</code>, from
class <code> "vlm"</code>.
List of convergence criterion evaluated at the
final IRLS iteration.
</p>
</dd>
<dt><code>df.residual</code>:</dt><dd><p>Object of class
<code>"numeric"</code>, from class <code> "vlm"</code>.
The residual degrees of freedom.
</p>
</dd>
<dt><code>df.total</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The total degrees of freedom.
</p>
</dd>
<dt><code>dispersion</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The scaling parameter.
</p>
</dd>
<dt><code>effects</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The effects.
</p>
</dd>
<dt><code>fitted.values</code>:</dt><dd>
<p>Object of class
<code>"matrix"</code>, from class <code> "vlm"</code>.
The fitted values. This is usually the mean but may be
quantiles, or the location parameter,
e.g., in the Cauchy model.
</p>
</dd>
<dt><code>misc</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
A named list to hold miscellaneous parameters.
</p>
</dd>
<dt><code>model</code>:</dt><dd><p>Object of class <code>"data.frame"</code>,
from class <code> "vlm"</code>.
The model frame.
</p>
</dd>
<dt><code>na.action</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
A list holding information about missing values.
</p>
</dd>
<dt><code>offset</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
If non-zero, a <code class="reqn">M</code>-column matrix of offsets.
</p>
</dd>
<dt><code>post</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>
where post-analysis results may be put.
</p>
</dd>
<dt><code>preplot</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>
used by <code><a href="#topic+plotvgam">plotvgam</a></code>; the plotting parameters
may be put here.
</p>
</dd>
<dt><code>prior.weights</code>:</dt><dd><p>Object of class
<code>"matrix"</code>, from class <code> "vlm"</code>
holding the initially supplied weights.
</p>
</dd>
<dt><code>qr</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
QR decomposition at the final iteration.
</p>
</dd>
<dt><code>R</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The <b>R</b> matrix in the QR decomposition used
in the fitting.
</p>
</dd>
<dt><code>rank</code>:</dt><dd><p>Object of class <code>"integer"</code>,
from class <code> "vlm"</code>.
Numerical rank of the fitted model.
</p>
</dd>
<dt><code>residuals</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The <em>working</em> residuals at the final IRLS iteration.
</p>
</dd>
<dt><code>ResSS</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
Residual sum of squares at the final IRLS iteration with
the adjusted dependent vectors and weight matrices.
</p>
</dd>
<dt><code>smart.prediction</code>:</dt><dd><p>Object of class
<code>"list"</code>, from class <code> "vlm"</code>.
A list of data-dependent parameters (if any)
that are used by smart prediction.
</p>
</dd>
<dt><code>terms</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
The <code><a href="stats.html#topic+terms">terms</a></code> object used.
</p>
</dd>
<dt><code>weights</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The weight matrices at the final IRLS iteration.
This is in matrix-band form.
</p>
</dd>
<dt><code>x</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The model matrix (LM, not VGLM).
</p>
</dd>
<dt><code>xlevels</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
The levels of the factors, if any, used in fitting.
</p>
</dd>
<dt><code>y</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The response, in matrix form.
</p>
</dd>
<dt><code>Xm2</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
See <code><a href="#topic+vglm-class">vglm-class</a></code>).
</p>
</dd>
<dt><code>Ym2</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
See <code><a href="#topic+vglm-class">vglm-class</a></code>).
</p>
</dd>
<dt><code>callXm2</code>:</dt><dd>
<p>Object of class <code>"call"</code>, from class <code> "vlm"</code>.
The matched call for argument <code>form2</code>.
</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"vglm"</code>, directly.
Class <code>"vlm"</code>, by class <code>"vglm"</code>.
</p>


<h3>Methods</h3>


<dl>
<dt>cdf</dt><dd><p><code>signature(object = "vglm")</code>:
cumulative distribution function.
Useful for quantile regression and extreme value data models.</p>
</dd>
<dt>deplot</dt><dd><p><code>signature(object = "vglm")</code>:
density plot.
Useful for quantile regression models.</p>
</dd>
<dt>deviance</dt><dd><p><code>signature(object = "vglm")</code>:
deviance of the model (where applicable). </p>
</dd>
<dt>plot</dt><dd><p><code>signature(x = "vglm")</code>:
diagnostic plots. </p>
</dd>
<dt>predict</dt><dd><p><code>signature(object = "vglm")</code>:
extract the additive predictors or
predict the additive predictors at a new data frame.</p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "vglm")</code>:
short summary of the object. </p>
</dd>
<dt>qtplot</dt><dd><p><code>signature(object = "vglm")</code>:
quantile plot (only applicable to some models). </p>
</dd>
<dt>resid</dt><dd><p><code>signature(object = "vglm")</code>:
residuals. There are various types of these. </p>
</dd>
<dt>residuals</dt><dd><p><code>signature(object = "vglm")</code>:
residuals. Shorthand for <code>resid</code>. </p>
</dd>
<dt>rlplot</dt><dd><p><code>signature(object = "vglm")</code>:
return level plot.
Useful for extreme value data models.</p>
</dd>
<dt>summary</dt><dd><p><code>signature(object = "vglm")</code>:
a more detailed summary of the object. </p>
</dd>
</dl>



<h3>Note</h3>

<p>VGAMs have all the slots that <code><a href="#topic+vglm">vglm</a></code> objects
have (<code><a href="#topic+vglm-class">vglm-class</a></code>), plus the first few slots
described in the section above.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+vgam.control">vgam.control</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+s">s</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a nonparametric proportional odds model
pneumo &lt;- transform(pneumo, let = log(exposure.time))
vgam(cbind(normal, mild, severe) ~ s(let),
     cumulative(parallel = TRUE), data = pneumo)
</code></pre>

<hr>
<h2 id='VGAM-package'>
Vector Generalized Linear and Additive Models
and Other Associated Models
</h2><span id='topic+VGAM-package'></span><span id='topic+VGAM'></span>

<h3>Description</h3>

<p><span class="pkg">VGAM</span> provides functions for fitting vector generalized
linear and additive models (VGLMs and VGAMs),
and associated
models (Reduced-rank VGLMs or RR-VGLMs,
Doubly constrained RR-VGLMs (DRR-VGLMs),
Quadratic RR-VGLMs,
Reduced-rank VGAMs).
This package fits many models and distributions by
maximum likelihood estimation (MLE) or penalized MLE,
under this statistical framework.
Also fits
constrained ordination models in ecology such as constrained
quadratic ordination (CQO).
</p>


<h3>Details</h3>

<p>This package centers on the
<em>iteratively reweighted least squares</em> (IRLS)
algorithm.
Other key words include
Fisher scoring,
additive models,
reduced-rank regression,
penalized likelihood,
and constrained ordination.
The central modelling functions are
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+cao">cao</a></code>.
Function
<code><a href="#topic+vglm">vglm</a></code>
operates very similarly to
<code><a href="stats.html#topic+glm">glm</a></code> but is much more general,
and many methods functions
such as <code><a href="#topic+coefvlm">coef</a></code> and
<code><a href="#topic+predictvglm">predict</a></code>
are available.
The package uses S4 (see <code><a href="methods.html#topic+methods-package">methods-package</a></code>).
</p>
<p>Some notable companion packages:
(1) <span class="pkg">VGAMdata</span> mainly contains data sets
useful for illustrating <span class="pkg">VGAM</span>.
Some of the big ones were initially from <span class="pkg">VGAM</span>.
Recently, some older <span class="pkg">VGAM</span> family functions have been shifted
into this package.
(2) <span class="pkg">VGAMextra</span> written by Victor Miranda has some additional
<span class="pkg">VGAM</span> family and link functions,
with a bent towards time series models.
(3) <span class="pkg">svyVGAM</span> provides design-based inference,
e.g., to survey sampling settings.
This is because the <code>weights</code> argument of
<code><a href="#topic+vglm">vglm</a></code> can be assigned any positive values including
survey weights.
</p>
<p>Compared to other similar packages, such as
<span class="pkg">gamlss</span> and
<span class="pkg">mgcv</span>,
<span class="pkg">VGAM</span> has more models implemented (150+ of them)
and they are not restricted to
a location-scale-shape framework or
(largely) the 1-parameter exponential family.
The general statistical framework behind it all,
once grasped, makes regression modelling unified.
Some features of the package are:
(i) many family functions handle multiple responses;
(ii) reduced-rank regression is available by operating
on latent variables (optimal linear combinations of the
explanatory variables);
(iii) basic
automatic smoothing parameter selection is
implemented for VGAMs
(<code><a href="#topic+sm.os">sm.os</a></code> and <code><a href="#topic+sm.ps">sm.ps</a></code>
with a call to <code><a href="mgcv.html#topic+magic">magic</a></code>),
although it has to be refined;
(iv) <em>smart</em> prediction allows correct prediction of nested
terms in the formula provided smart functions are used.
</p>
<p>The GLM and GAM classes are special cases of VGLMs and VGAMs.
The VGLM/VGAM framework is intended to be very general
so that it encompasses as many distributions and models as
possible. VGLMs are limited only by the assumption that the
regression coefficients enter through a set of linear predictors.
The VGLM class is very large and encompasses a wide range of
multivariate response types and models, e.g., it includes
univariate and multivariate distributions,
categorical data analysis,
extreme values,
correlated binary data,
quantile and expectile regression,
time series
problems.
Potentially, it can handle
generalized estimating equations,
survival analysis,
bioassay data and
nonlinear least-squares
problems.
</p>
<p>Crudely, VGAMs are to VGLMs what GAMs are to GLMs.
Two types of VGAMs are implemented:
1st-generation VGAMs with <code><a href="#topic+s">s</a></code> use vector backfitting,
while
2nd-generation VGAMs with <code><a href="#topic+sm.os">sm.os</a></code> and
<code><a href="#topic+sm.ps">sm.ps</a></code> use O-splines and P-splines
so have a direct solution
(hence avoids backfitting)
and have automatic smoothing parameter selection.
The former is older and is based on Yee and Wild (1996).
The latter is more modern
(Yee, Somchit and Wild, 2024)
but it requires a reasonably large number of observations
to work well because it is based on optimizing
over a predictive criterion rather than
using a Bayesian approach.
</p>

<p>An important feature of the framework
is that of <em>constraint matrices</em>.
They apportion the regression coefficients according
to each explanatory variable.
For example,
since each parameter has a link function applied to it
to turn it into a linear or additive predictor,
does a covariate have an equal effect on each parameter?
Or no effect?
Arguments such as <code>zero</code>, <code>parallel</code> and
<code>exchangeable</code>,
are merely easy ways to have them constructed
internally.
Users may input them explicitly using
the <code>constraint</code> argument, and
<code><a href="#topic+CM.symm0">CM.symm0</a></code> etc. can make this easier.
</p>
<p>Another important feature is implemented by
<code>xij</code>.
It allows different linear/additive predictors
to have a different values of the same
explanatory variable, e.g.,
<code><a href="#topic+multinomial">multinomial</a></code> for the
conditional logit model and the like.
</p>
<p>VGLMs with dimension reduction form
the class of RR-VGLMs. This is achieved by
reduced rank regression. Here, a subset of
the constraint matrices are estimated
rather than being known and prespecified.
Optimal linear combinations of the
explanatory variables are taken (creating
latent variables) which are used for
fitting a VGLM. Thus the regression can
be thought of as being in two stages.
The class of DRR-VGLMs provides further
structure to RR-VGLMs by allowing
constraint matrices to be specified for
each column of <b>A</b> and
row of <b>C</b>.
Thus the reduced rank regression can be fitted
with greater control.
</p>
<p>This package is the first to check for the <em>Hauck-Donner effect</em>
(HDE) in regression models; see <code><a href="#topic+hdeff">hdeff</a></code>.  This is an
aberration of the Wald statistics when the parameter estimates are too
close to the boundary of the parameter space.  When present the p-value
of a regression coefficient is biased upwards so that a highly
significant variable might be deemed nonsignificant.  Thus the HDE can
create havoc for variable selection!
</p>
<p>Somewhat related to the previous paragraph, hypothesis testing
using the likelihood ratio test,
Rao's score test (Lagrange multiplier test) and
(modified) Wald's test are all available; see <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
For all regression coefficients of a model, taken one at a time,
all three methods require further IRLS iterations to obtain
new values of the other regression coefficients after one
of the coefficients has had its value set (usually to 0).
Hence the computation load is overall significant.
</p>





<p>For a complete list of this package, use <code>library(help = "VGAM")</code>.
New <span class="pkg">VGAM</span> family functions are continually being written and
added to the package.
</p>









<h3>Warning</h3>

<p>This package is undergoing continual
development and improvement,
therefore users should treat
many things as subject to change.
This includes the
family function names,
argument names,
many of the internals,
moving some functions to <span class="pkg">VGAMdata</span>,
the use of link functions,
and slot names.
For example,
many link functions were renamed in 2019
so that they all end in <code>"link"</code>,
e.g., <code>loglink()</code> instead of <code>loge()</code>.
Some future pain can be avoided by using good
programming techniques, e.g.,
using extractor functions such as
<code>coef()</code>, <code>weights()</code>, <code>vcov()</code>,
<code>predict()</code>.
Although changes are now less frequent,
please expect changes in all aspects of the
package.
See the <code>NEWS</code> file for a list of changes
from version to version.
</p>



<h3>Author(s)</h3>

<p>Thomas W. Yee, <a href="mailto:t.yee@auckland.ac.nz">t.yee@auckland.ac.nz</a>,
with contributions from
Victor Miranda
and several graduate students over the years,
especially
Xiangjie (Albert) Xue and
Chanatda Somchit.
</p>
<p>Maintainer:
Thomas Yee <a href="mailto:t.yee@auckland.ac.nz">t.yee@auckland.ac.nz</a>.
</p>



<h3>References</h3>

<p>Yee, T. W. (2015).
<em>Vector Generalized Linear and Additive
Models:
With an Implementation in R</em>.
New York, USA: <em>Springer</em>.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. and Stephenson, A. G. (2007).
Vector generalized linear and additive extreme
value models.
<em>Extremes</em>, <b>10</b>, 1&ndash;19.
</p>
<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>
<p>Yee, T. W. (2004).
A new technique for maximum-likelihood
canonical Gaussian ordination.
<em>Ecological Monographs</em>,
<b>74</b>, 685&ndash;701.
</p>
<p>Yee, T. W. (2006).
Constrained additive ordination.
<em>Ecology</em>, <b>87</b>, 203&ndash;213.
</p>
<p>Yee, T. W. (2008).
The <code>VGAM</code> Package.
<em>R News</em>, <b>8</b>, 28&ndash;39.
</p>
<p>Yee, T. W. (2010).
The <span class="pkg">VGAM</span> package for categorical data
analysis.
<em>Journal of Statistical Software</em>,
<b>32</b>, 1&ndash;34.
<a href="https://doi.org/10.18637/jss.v032.i10">doi:10.18637/jss.v032.i10</a>.
</p>


<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models
with two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>
<p>Yee, T. W. and Ma, C. (2024).
Generally altered, inflated, truncated and
deflated regression.
<em>Statistical Science</em>, <b>39</b> (in press).
</p>
<p>Yee, T. W. (2022).
On the Hauck-Donner effect in Wald tests:
Detection, tipping points and parameter space
characterization,
<em>Journal of the American Statistical Association</em>,
<b>117</b>, 1763&ndash;1774.
<a href="https://doi.org/10.1080/01621459.2021.1886936">doi:10.1080/01621459.2021.1886936</a>.
</p>


<p>Yee, T. W. and Somchit, C. and Wild, C. J. (2024).
Penalized vector generalized additive models.
Manuscript in preparation.
</p>
<p>The website for the <span class="pkg">VGAM</span> package and book is
<a href="https://www.stat.auckland.ac.nz/~yee/">https://www.stat.auckland.ac.nz/~yee/</a>.
There are some resources there,
especially as relating to my book and new features
added to <span class="pkg">VGAM</span>.
</p>
<p>Some useful background reference for the package
include:
</p>
<p>Chambers, J. and Hastie, T. (1991).
<em>Statistical Models in S</em>.
Wadsworth &amp; Brooks/Cole.
</p>
<p>Green, P. J. and Silverman, B. W. (1994).
<em>Nonparametric Regression and Generalized
Linear Models: A Roughness Penalty Approach</em>.
Chapman and Hall.
</p>
<p>Hastie, T. J. and Tibshirani, R. J. (1990).
<em>Generalized Additive Models</em>.
Chapman and Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rcim">rcim</a></code>,
<code><a href="#topic+cqo">cqo</a></code>,
<code><a href="#topic+TypicalVGAMfamilyFunction">TypicalVGAMfamilyFunction</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+Links">Links</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>,
<code><a href="stats.html#topic+glm">glm</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code>,
<a href="https://CRAN.R-project.org/package=VGAM">https://CRAN.R-project.org/package=VGAM</a>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'># Example 1; proportional odds model
pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, data = pneumo))
depvar(fit1)  # Better than using fit1@y; dependent variable (response)
weights(fit1, type = "prior")  # Number of observations
coef(fit1, matrix = TRUE)      # p.179, in McCullagh and Nelder (1989)
constraints(fit1)              # Constraint matrices
summary(fit1)  # HDE could affect these results
summary(fit1, lrt0 = TRUE, score0 = TRUE, wald0 = TRUE)  # No HDE
hdeff(fit1)  # Check for any Hauck-Donner effect

# Example 2; zero-inflated Poisson model
zdata &lt;- data.frame(x2 = runif(nn &lt;- 2000))
zdata &lt;- transform(zdata, pstr0  = logitlink(-0.5 + 1*x2, inverse = TRUE),
                          lambda = loglink(  0.5 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata, y = rzipois(nn, lambda, pstr0 = pstr0))
with(zdata, table(y))
fit2 &lt;- vglm(y ~ x2, zipoisson, data = zdata, trace = TRUE)
coef(fit2, matrix = TRUE)  # These should agree with the above values


# Example 3; fit a two species GAM simultaneously
fit3 &lt;- vgam(cbind(agaaus, kniexc) ~ s(altitude, df = c(2, 3)),
             binomialff(multiple.responses = TRUE), data = hunua)
coef(fit3, matrix = TRUE)   # Not really interpretable
## Not run:  plot(fit3, se = TRUE, overlay = TRUE, lcol = 3:4, scol = 3:4)

ooo &lt;- with(hunua, order(altitude))
with(hunua,  matplot(altitude[ooo], fitted(fit3)[ooo, ], type = "l",
     lwd = 2, col = 3:4,
     xlab = "Altitude (m)", ylab = "Probability of presence", las = 1,
     main = "Two plant species' response curves", ylim = c(0, 0.8)))
with(hunua, rug(altitude)) 
## End(Not run)


# Example 4; LMS quantile regression
fit4 &lt;- vgam(BMI ~ s(age, df = c(4, 2)), lms.bcn(zero = 1),
             data = bmi.nz, trace = TRUE)
head(predict(fit4))
head(fitted(fit4))
head(bmi.nz)  # Person 1 is near the lower quartile among people his age
head(cdf(fit4))

## Not run:  par(mfrow = c(1,1), bty = "l", mar = c(5,4,4,3)+0.1, xpd=TRUE)
qtplot(fit4, percentiles = c(5,50,90,99), main = "Quantiles", las = 1,
       xlim = c(15, 90), ylab = "BMI", lwd=2, lcol=4)  # Quantile plot

ygrid &lt;- seq(15, 43, len = 100)  # BMI ranges
par(mfrow = c(1, 1), lwd = 2)  # Density plot
aa &lt;- deplot(fit4, x0 = 20, y = ygrid, xlab = "BMI", col = "black",
    main = "Density functions at Age=20 (black), 42 (red) and 55 (blue)")
aa
aa &lt;- deplot(fit4, x0 = 42, y = ygrid, add = TRUE, llty = 2, col = "red")
aa &lt;- deplot(fit4, x0 = 55, y = ygrid, add = TRUE, llty = 4, col = "blue",
            Attach = TRUE)
aa@post$deplot  # Contains density function values

## End(Not run)


# Example 5; GEV distribution for extremes
(fit5 &lt;- vglm(maxtemp ~ 1, gevff, data = oxtemp, trace = TRUE))
head(fitted(fit5))
coef(fit5, matrix = TRUE)
Coef(fit5)
vcov(fit5)
vcov(fit5, untransform = TRUE)
sqrt(diag(vcov(fit5)))  # Approximate standard errors
## Not run:  rlplot(fit5) 
</code></pre>

<hr>
<h2 id='vgam.control'> Control Function for vgam() </h2><span id='topic+vgam.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for running <code><a href="#topic+vgam">vgam</a></code>
are set using this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgam.control(all.knots = FALSE, bf.epsilon = 1e-07, bf.maxit = 30,
             checkwz=TRUE, Check.rank = TRUE, Check.cm.rank = TRUE,
             criterion = names(.min.criterion.VGAM),
             epsilon = 1e-07, maxit = 30, Maxit.outer = 10,
             noWarning = FALSE,
             na.action = na.fail,
             nk = NULL, save.weights = FALSE, se.fit = TRUE,
             trace = FALSE, wzepsilon = .Machine$double.eps^0.75,
             xij = NULL, gamma.arg = 1, ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="vgam.control_+3A_all.knots">all.knots</code></td>
<td>

<p>logical indicating if all distinct points of
the smoothing variables are to be used as knots.
By default, <code>all.knots=TRUE</code> for
<code class="reqn">n \leq 40</code>, and
for <code class="reqn">n &gt; 40</code>,
the number of knots is approximately
<code class="reqn">40 + (n-40)^{0.25}</code>.
This increases very slowly with <code class="reqn">n</code>
so that the number of knots is approximately between 50 and 60
for large <code class="reqn">n</code>.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_bf.epsilon">bf.epsilon</code></td>
<td>

<p>tolerance used by the modified vector
backfitting algorithm for testing convergence.
Must be a positive number.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_bf.maxit">bf.maxit</code></td>
<td>

<p>maximum number of iterations allowed in
the modified vector
backfitting algorithm. Must be a positive integer.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_checkwz">checkwz</code></td>
<td>

<p>logical indicating whether the diagonal elements of
the working weight matrices should be checked
whether they are
sufficiently positive, i.e., greater
than <code>wzepsilon</code>. If not,
any values less than <code>wzepsilon</code> are
replaced with this value.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_check.rank">Check.rank</code>, <code id="vgam.control_+3A_check.cm.rank">Check.cm.rank</code></td>
<td>

<p>See <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_criterion">criterion</code></td>
<td>

<p>character variable describing what criterion is to
be used to test for convergence.
The possibilities are listed
in <code>.min.criterion.VGAM</code>, but
most family functions only implement a few of these.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_epsilon">epsilon</code></td>
<td>

<p>positive convergence tolerance epsilon. Roughly
speaking, the
Newton-Raphson/Fisher-scoring/local-scoring iterations
are assumed to have
converged when two successive <code>criterion</code>
values are within
<code>epsilon</code> of each other.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_maxit">maxit</code></td>
<td>

<p>maximum number of
Newton-Raphson/Fisher-scoring/local-scoring
iterations allowed.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_maxit.outer">Maxit.outer</code></td>
<td>

<p>maximum number of
outer iterations allowed when there are
<code><a href="#topic+sm.os">sm.os</a></code> or
<code><a href="#topic+sm.ps">sm.ps</a></code> terms.
See <code><a href="#topic+vgam">vgam</a></code> for a little information about
the default <em>outer iteration</em>.
Note that one can use <em>performance iteration</em>
by setting <code>Maxit.outer = 1</code>; then the
smoothing parameters will be automatically chosen at each
IRLS iteration (some specific programming
allows this).
</p>
<p>Note that <code><a href="mgcv.html#topic+gam">gam</a></code> uses
outer iteration by default. However, 
<code><a href="mgcv.html#topic+magic">magic</a></code> is only
invoked for the Gaussian family, so
the results of <code><a href="mgcv.html#topic+gam">gam</a></code>
may differ substantially from
<code><a href="#topic+sm.os">sm.os</a></code> and <code><a href="#topic+sm.ps">sm.ps</a></code>
in general.
</p>

</td></tr>
<tr><td><code id="vgam.control_+3A_na.action">na.action</code></td>
<td>

<p>how to handle missing values.
Unlike the SPLUS <code>gam</code> function,
<code><a href="#topic+vgam">vgam</a></code> cannot handle
<code>NA</code>s when smoothing.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_nk">nk</code></td>
<td>

<p>vector of length <code class="reqn">d</code> containing positive integers.
where <code class="reqn">d</code> be the number of <code><a href="#topic+s">s</a></code> terms
in the formula.
Recycling is used if necessary.
The <code class="reqn">i</code>th value is the number of
B-spline coefficients to be
estimated for each component function of the <code class="reqn">i</code>th
<code>s()</code> term.
<code>nk</code> differs from the number of knots by some constant.
If specified, <code>nk</code> overrides the
automatic knot selection procedure.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_save.weights">save.weights</code></td>
<td>

<p>logical indicating whether the <code>weights</code> slot
of a <code>"vglm"</code> object will be saved on the object.
If not, it will be reconstructed when needed,
e.g., <code>summary</code>.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_se.fit">se.fit</code></td>
<td>

<p>logical indicating whether approximate
pointwise standard errors are to be saved on the object.
If <code>TRUE</code>, then these can be plotted
with <code>plot(..., se = TRUE)</code>.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_trace">trace</code></td>
<td>

<p>logical indicating if output should be produced
for each iteration.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_wzepsilon">wzepsilon</code></td>
<td>

<p>Small positive number used to test whether the diagonals
of the working weight matrices are sufficiently positive.
</p>
</td></tr>




<tr><td><code id="vgam.control_+3A_nowarning">noWarning</code></td>
<td>

<p>Same as <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_xij">xij</code></td>
<td>

<p>Same as <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_gamma.arg">gamma.arg</code></td>
<td>

<p>Numeric; same as <code>gamma</code> in <code><a href="mgcv.html#topic+magic">magic</a></code>.
Inflation factor for optimizing the UBRE/GCV criterion.
If given, a suggested value is 1.4 to help avoid overfitting,
based on the work of Gu and co-workers
(values between 1.2 and 1.4 appeared reasonable,
based on simulations).
A warning may be given if the value is deemed out-of-range.
</p>
</td></tr>
<tr><td><code id="vgam.control_+3A_...">...</code></td>
<td>

<p>other parameters that may be picked up from control
functions that are specific to the <span class="pkg">VGAM</span> family function.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the control parameters are used within
<code>vgam.fit</code> and you will have to look at that
to understand the full details.  Many of the control
parameters are used in a similar manner by <code>vglm.fit</code>
(<code><a href="#topic+vglm">vglm</a></code>) because the algorithm (IRLS) is
very similar.
</p>
<p>Setting <code>save.weights=FALSE</code> is useful for some
models because the <code>weights</code> slot of the object is
often the largest and so less memory is used to store the
object. However, for some <span class="pkg">VGAM</span> family function,
it is necessary to set <code>save.weights=TRUE</code> because
the <code>weights</code> slot cannot be reconstructed later.
</p>


<h3>Value</h3>

<p>A list with components matching the input names. A little
error checking is done, but not much.  The list is assigned
to the <code>control</code> slot of <code><a href="#topic+vgam">vgam</a></code> objects.
</p>


<h3>Warning</h3>

<p>See <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>


<h3>Note</h3>

<p><code><a href="#topic+vgam">vgam</a></code> does not implement half-stepsizing,
therefore parametric models should be fitted with
<code><a href="#topic+vglm">vglm</a></code>. Also, <code><a href="#topic+vgam">vgam</a></code> is slower
than  <code><a href="#topic+vglm">vglm</a></code> too.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>











<h3>See Also</h3>

<p><code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+vglm.control">vglm.control</a></code>,
<code><a href="#topic+vsmooth.spline">vsmooth.spline</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
vgam(cbind(normal, mild, severe) ~ s(let, df = 2), multinomial,
     data = pneumo, trace = TRUE, eps = 1e-4, maxit = 10)
</code></pre>

<hr>
<h2 id='vglm'>Fitting Vector Generalized Linear Models </h2><span id='topic+vglm'></span>

<h3>Description</h3>

<p><code>vglm</code> fits vector generalized linear models (VGLMs).
This very large class of models includes
generalized linear models (GLMs) as a special case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vglm(formula,
     family = stop("argument 'family' needs to be assigned"),
     data = list(), weights = NULL, subset = NULL,
     na.action = na.fail, etastart = NULL, mustart = NULL,
     coefstart = NULL, control = vglm.control(...), offset = NULL,
     method = "vglm.fit", model = FALSE, x.arg = TRUE, y.arg = TRUE,
     contrasts = NULL, constraints = NULL, extra = list(),
     form2 = NULL, qr.arg = TRUE, smart = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vglm_+3A_formula">formula</code></td>
<td>

<p>a symbolic description of the model to be fit.
The RHS of the formula is applied to each linear
predictor.
The effect of different variables in each linear predictor
can be controlled by specifying constraint matrices&mdash;see
<code>constraints</code> below.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_family">family</code></td>
<td>

<p>a function of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>)
describing what statistical model is to be fitted.
This is called a
&ldquo;<span class="pkg">VGAM</span> family function&rdquo;.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
for general information about many types of
arguments found in this
type of function.
The argument name <code>"family"</code> is used loosely and for
the ease of existing <code><a href="stats.html#topic+glm">glm</a></code> users;
there is no concept of a
formal &ldquo;error distribution&rdquo; for VGLMs.
Possibly the argument name should be better <code>"model"</code>
but unfortunately
that name has already been taken.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model.
By default the variables are taken from
<code>environment(formula)</code>, typically the environment
from which <code>vglm</code> is called.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_weights">weights</code></td>
<td>

<p>an optional vector or matrix of (prior fixed and known) weights
to be used in the fitting process.
If the <span class="pkg">VGAM</span> family function handles multiple responses
(<code class="reqn">Q &gt; 1</code> of them, say) then
<code>weights</code> can be a matrix with <code class="reqn">Q</code> columns.
Each column matches the respective response.
If it is a vector (the usually case) then it is recycled into a
matrix with <code class="reqn">Q</code> columns.
The values of <code>weights</code> must be positive; try setting
a very small value such as <code>1.0e-8</code> to effectively
delete an observation.
</p>

<p>Currently the <code>weights</code> argument supports sampling
weights from complex sampling designs
via <span class="pkg">svyVGAM</span>.
Some details can be found at
<a href="https://CRAN.R-project.org/package=svyVGAM">https://CRAN.R-project.org/package=svyVGAM</a>.
</p>



















</td></tr>
<tr><td><code id="vglm_+3A_subset">subset</code></td>
<td>

<p>an optional logical vector specifying a subset of
observations to
be used in the fitting process.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_na.action">na.action</code></td>
<td>

<p>a function which indicates what should happen when
the data contain <code>NA</code>s.
The default is set by the <code>na.action</code> setting
of <code><a href="base.html#topic+options">options</a></code>, and is <code>na.fail</code> if that
is unset.
The &ldquo;factory-fresh&rdquo; default is <code>na.omit</code>.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_etastart">etastart</code></td>
<td>

<p>optional starting values for the linear predictors.
It is a <code class="reqn">M</code>-column matrix with the same
number of rows as
the response.
If <code class="reqn">M = 1</code> then it may be a vector.
Note that <code>etastart</code> and the output
of <code>predict(fit)</code>
should be comparable.
Here, <code>fit</code> is the fitted object.
Almost all <span class="pkg">VGAM</span> family functions are self-starting.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_mustart">mustart</code></td>
<td>

<p>optional starting values for the fitted values.
It can be a vector or a matrix;
if a matrix, then it has the same number of rows
as the response.
Usually <code>mustart</code> and the output of <code>fitted(fit)</code>
should be comparable.
Most family functions do not make use of this argument
because it is not possible to compute all <code class="reqn">M</code> columns of
<code>eta</code> from <code>mu</code>.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_coefstart">coefstart</code></td>
<td>

<p>optional starting values for the coefficient vector.
The length and order must match that of <code>coef(fit)</code>.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_control">control</code></td>
<td>

<p>a list of parameters for controlling the fitting process.
See <code><a href="#topic+vglm.control">vglm.control</a></code> for details.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_offset">offset</code></td>
<td>

<p>a vector or <code class="reqn">M</code>-column matrix of offset values.
These are <em>a priori</em> known and are added to the
linear/additive predictors during fitting.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_method">method</code></td>
<td>

<p>the method to be used in fitting the model.
The default (and
presently only) method <code>vglm.fit()</code> uses iteratively
reweighted least squares (IRLS).
</p>
</td></tr>
<tr><td><code id="vglm_+3A_model">model</code></td>
<td>

<p>a logical value indicating whether the
<em>model frame</em>
should be assigned in the <code>model</code> slot.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_x.arg">x.arg</code>, <code id="vglm_+3A_y.arg">y.arg</code></td>
<td>

<p>logical values indicating whether
the LM matrix and response vector/matrix used in the fitting
process should be assigned in the <code>x</code> and <code>y</code> slots.
Note that the model matrix is the LM matrix; to get the VGLM
matrix type <code>model.matrix(vglmfit)</code> where
<code>vglmfit</code> is a <code>vglm</code> object.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_contrasts">contrasts</code></td>
<td>

<p>an optional list. See the <code>contrasts.arg</code>
of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_constraints">constraints</code></td>
<td>

<p>an optional <code><a href="base.html#topic+list">list</a></code> of constraint matrices.
The components of the list must be named (labelled)
with the term it corresponds to
(and it must match in
character format <em>exactly</em>&mdash;see below).
There are two types of input:
<code>"lm"</code>-type and <code>"vlm"</code>-type.
The former is a subset of the latter.
The former has a matrix for each term of the LM matrix.
The latter has a matrix for each column of the big VLM matrix.
After fitting, the <code><a href="#topic+constraints">constraints</a></code>
extractor function may be applied; it returns
the <code>"vlm"</code>-type list of constraint matrices
by default.  If <code>"lm"</code>-type are returned by
<code><a href="#topic+constraints">constraints</a></code> then these can be fed into this
argument and it should give the same model as before.
</p>
<p>If the <code>constraints</code> argument is used then the
family function's <code>zero</code> argument (if it exists)
needs to be set to <code>NULL</code>.
This avoids what could be a probable contradiction.
Sometimes setting other arguments related to constraint
matrices to <code>FALSE</code> is also a good idea, e.g.,
<code>parallel = FALSE</code>,
<code>exchangeable = FALSE</code>.
</p>
<p>Properties:
each constraint matrix must have <code class="reqn">M</code> rows, and be of
full-column rank.  By default, constraint matrices are
the <code class="reqn">M</code> by <code class="reqn">M</code> identity matrix unless arguments
in the family function itself override these values, e.g.,
<code>parallel</code> (see  <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>).
If <code>constraints</code> is used then it
must contain <em>all</em>
the terms; an incomplete list is not accepted.
</p>
<p>As mentioned above, the labelling of each constraint matrix
must match exactly, e.g.,
<code>list("s(x2,df=3)"=diag(2))</code>
will fail as
<code>as.character(~ s(x2,df=3))</code> produces white spaces:
<code>"s(x2, df = 3)"</code>.
Thus
<code>list("s(x2, df = 3)" = diag(2))</code>
is needed.
See Example 6 below.
More details are given in Yee (2015; Section 3.3.1.3)
which is on p.101.
Note that the label for the intercept is <code>"(Intercept)"</code>.  
</p>
</td></tr>
<tr><td><code id="vglm_+3A_extra">extra</code></td>
<td>

<p>an optional list with any extra information that
might be needed by
the <span class="pkg">VGAM</span> family function.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_form2">form2</code></td>
<td>

<p>the second (optional) formula.
If argument <code>xij</code> is used
(see <code><a href="#topic+vglm.control">vglm.control</a></code>) then
<code>form2</code> needs to have <em>all</em> terms in the model.
Also, some <span class="pkg">VGAM</span> family functions
such as <code><a href="#topic+micmen">micmen</a></code>
use this argument to input the regressor variable.
If given, the slots <code>@Xm2</code> and <code>@Ym2</code>
may be assigned.
Note that smart prediction applies to terms
in <code>form2</code> too.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_qr.arg">qr.arg</code></td>
<td>

<p>logical value indicating whether the slot <code>qr</code>, which
returns the QR decomposition of the VLM model matrix,
is returned on the object.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_smart">smart</code></td>
<td>

<p>logical value indicating whether smart prediction
(<code><a href="#topic+smartpred">smartpred</a></code>) will be used.
</p>
</td></tr>
<tr><td><code id="vglm_+3A_...">...</code></td>
<td>

<p>further arguments passed into <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A vector generalized linear model (VGLM) is loosely defined
as a statistical model that is a function of <code class="reqn">M</code> linear
predictors and can be estimated by Fisher scoring.
The central formula is given by
</p>
<p style="text-align: center;"><code class="reqn">\eta_j = \beta_j^T x</code>
</p>

<p>where <code class="reqn">x</code> is a vector of explanatory variables
(sometimes just a 1 for an intercept),
and
<code class="reqn">\beta_j</code> is a vector of regression coefficients
to be estimated.
Here, <code class="reqn">j=1,\ldots,M</code>, where <code class="reqn">M</code> is finite.
Then one can write
<code class="reqn">\eta=(\eta_1,\ldots,\eta_M)^T</code>
as a vector of linear predictors.
</p>
<p>Most users will find <code>vglm</code> similar in flavour to
<code><a href="stats.html#topic+glm">glm</a></code>.
The function <code>vglm.fit</code> actually does the work.
</p>





<h3>Value</h3>

<p>An object of class <code>"vglm"</code>, which has the
following slots. Some of these may not be assigned to save
space, and will be recreated if necessary later.
</p>
<table>
<tr><td><code>extra</code></td>
<td>
<p>the list <code>extra</code> at the end of fitting.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the family function (of class <code>"vglmff"</code>).</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of IRLS iterations used.</p>
</td></tr>
<tr><td><code>predictors</code></td>
<td>
<p>a <code class="reqn">M</code>-column matrix of linear predictors.</p>
</td></tr>
<tr><td><code>assign</code></td>
<td>
<p>a named list which matches the columns and the
(LM) model matrix terms.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of coefficients.</p>
</td></tr>
<tr><td><code>constraints</code></td>
<td>

<p>a named list of constraint matrices used in the fitting.
</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>the contrasts used (if any).</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>list of control parameter used in the fitting.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>list of convergence criterion evaluated at the
final IRLS iteration.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>df.total</code></td>
<td>
<p>the total degrees of freedom.</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>the scaling parameter.</p>
</td></tr>
<tr><td><code>effects</code></td>
<td>
<p>the effects.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>

<p>the fitted values, as a matrix.
This is often the mean but may be quantiles, or the location
parameter, e.g., in the Cauchy model.
</p>
</td></tr>
<tr><td><code>misc</code></td>
<td>
<p>a list to hold miscellaneous parameters.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the model frame.</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>a list holding information
about missing values.</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>if non-zero, a <code class="reqn">M</code>-column matrix of offsets.</p>
</td></tr>
<tr><td><code>post</code></td>
<td>
<p>a list where post-analysis results may be put.</p>
</td></tr>
<tr><td><code>preplot</code></td>
<td>
<p>used by <code><a href="#topic+plotvgam">plotvgam</a></code>,
the plotting parameters
may be put here.</p>
</td></tr>
<tr><td><code>prior.weights</code></td>
<td>

<p>initially supplied weights
(the <code>weights</code> argument).
Also see <code><a href="#topic+weightsvglm">weightsvglm</a></code>.
</p>
</td></tr>
<tr><td><code>qr</code></td>
<td>
<p>the QR decomposition used in the fitting.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>the <b>R</b> matrix in the QR decomposition
used in the fitting.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>numerical rank of the fitted model.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the <em>working</em> residuals at the
final IRLS iteration.</p>
</td></tr>
<tr><td><code>ResSS</code></td>
<td>
<p>residual sum of squares at the
final IRLS iteration with
the adjusted dependent vectors and weight matrices.</p>
</td></tr>
<tr><td><code>smart.prediction</code></td>
<td>

<p>a list of data-dependent parameters (if any)
that are used by smart prediction.
</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code><a href="stats.html#topic+terms">terms</a></code> object used.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the working weight matrices at
the final IRLS iteration.
This is in matrix-band form.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>the model matrix (linear model LM, not VGLM).</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>the levels of the factors, if any,
used in fitting.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response, in matrix form.</p>
</td></tr>
</table>
<p>This slot information is repeated at <code><a href="#topic+vglm-class">vglm-class</a></code>.
</p>


<h3>WARNING</h3>

<p>See warnings in <code><a href="#topic+vglm.control">vglm.control</a></code>.
Also, see warnings under <code>weights</code> above regarding
sampling weights from complex sampling designs.
</p>


<h3>Note</h3>

<p>This function can fit a wide variety of
statistical models. Some of
these are harder to fit than others because
of inherent numerical
difficulties associated with some of them.
Successful model fitting
benefits from cumulative experience.
Varying the values of arguments
in the <span class="pkg">VGAM</span> family function itself
is a good first step if
difficulties arise, especially if initial
values can be inputted.
A second, more general step, is to vary the
values of arguments in
<code><a href="#topic+vglm.control">vglm.control</a></code>.
A third step is to make use of arguments such
as <code>etastart</code>,
<code>coefstart</code> and <code>mustart</code>.
</p>
<p>Some <span class="pkg">VGAM</span> family functions end in <code>"ff"</code> to avoid
interference with other functions, e.g.,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+poissonff">poissonff</a></code>.
This is because <span class="pkg">VGAM</span> family
functions are incompatible with <code><a href="stats.html#topic+glm">glm</a></code>
(and also <code>gam()</code> in <span class="pkg">gam</span> and
<code><a href="mgcv.html#topic+gam">gam</a></code> in the <span class="pkg">mgcv</span> library).
</p>


<p>The smart prediction (<code><a href="#topic+smartpred">smartpred</a></code>)
library is incorporated
within the <span class="pkg">VGAM</span> library.
</p>
<p>The theory behind the scaling parameter is
currently being made more
rigorous, but it it should give the same value
as the scale parameter
for GLMs.
</p>
<p>In Example 5 below, the <code>xij</code> argument to
illustrate covariates
that are specific to a linear predictor.
Here, <code>lop</code>/<code>rop</code>
are
the ocular pressures of the left/right eye
(artificial data).
Variables <code>leye</code> and <code>reye</code> might be
the presence/absence of
a particular disease on the LHS/RHS eye respectively.
See
<code><a href="#topic+vglm.control">vglm.control</a></code>
and
<code><a href="#topic+fill1">fill1</a></code>
for more details and examples.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2015).
Vector Generalized Linear and Additive Models:
With an Implementation in R.
New York, USA: <em>Springer</em>.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society,
Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models
with two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>
<p>Yee, T. W. (2008).
The <code>VGAM</code> Package.
<em>R News</em>, <b>8</b>, 28&ndash;39.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+vglm.control">vglm.control</a></code>,
<code><a href="#topic+vglm-class">vglm-class</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+smartpred">smartpred</a></code>,
<code>vglm.fit</code>,
<code><a href="#topic+fill1">fill1</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>.
Methods functions include
<code><a href="#topic+add1.vglm">add1.vglm</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>,
<code><a href="#topic+AICvlm">AICvlm</a></code>,
<code><a href="#topic+coefvlm">coefvlm</a></code>,
<code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="#topic+constraints.vlm">constraints.vlm</a></code>,
<code><a href="#topic+drop1.vglm">drop1.vglm</a></code>,
<code><a href="#topic+fittedvlm">fittedvlm</a></code>,
<code><a href="#topic+hatvaluesvlm">hatvaluesvlm</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>,
<code><a href="#topic+Influence.vglm">Influence.vglm</a></code>,
<code><a href="#topic+linkfunvlm">linkfunvlm</a></code>,
<code><a href="#topic+lrt.stat.vlm">lrt.stat.vlm</a></code>,
<code><a href="#topic+score.stat.vlm">score.stat.vlm</a></code>,
<code><a href="#topic+wald.stat.vlm">wald.stat.vlm</a></code>,
<code><a href="#topic+nobs.vlm">nobs.vlm</a></code>,
<code><a href="#topic+npred.vlm">npred.vlm</a></code>,
<code><a href="#topic+plotvglm">plotvglm</a></code>,
<code><a href="#topic+predictvglm">predictvglm</a></code>,
<code><a href="#topic+residualsvglm">residualsvglm</a></code>,
<code><a href="#topic+step4vglm">step4vglm</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="#topic+lrtest_vglm">lrtest_vglm</a></code>,
<code><a href="stats.html#topic+update">update</a></code>,
<code><a href="#topic+TypicalVGAMfamilyFunction">TypicalVGAMfamilyFunction</a></code>,
etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1. See help(glm)
(d.AD &lt;- data.frame(treatment = gl(3, 3),
                    outcome = gl(3, 1, 9),
                    counts = c(18,17,15,20,10,20,25,13,12)))
vglm.D93 &lt;- vglm(counts ~ outcome + treatment, poissonff,
                 data = d.AD, trace = TRUE)
summary(vglm.D93)


# Example 2. Multinomial logit model
pneumo &lt;- transform(pneumo, let = log(exposure.time))
vglm(cbind(normal, mild, severe) ~ let, multinomial, pneumo)


# Example 3. Proportional odds model
fit3 &lt;- vglm(cbind(normal, mild, severe) ~ let, propodds, pneumo)
coef(fit3, matrix = TRUE)
constraints(fit3)
model.matrix(fit3, type = "lm")  # LM model matrix
model.matrix(fit3)               # Larger VGLM (or VLM) matrix


# Example 4. Bivariate logistic model
fit4 &lt;- vglm(cbind(nBnW, nBW, BnW, BW) ~ age, binom2.or, coalminers)
coef(fit4, matrix = TRUE)
depvar(fit4)  # Response are proportions
weights(fit4, type = "prior")


# Example 5. The use of the xij argument (simple case).
# The constraint matrix for 'op' has one column.
nn &lt;- 1000
eyesdat &lt;- round(data.frame(lop = runif(nn),
                            rop = runif(nn),
                             op = runif(nn)), digits = 2)
eyesdat &lt;- transform(eyesdat, eta1 = -1 + 2 * lop,
                              eta2 = -1 + 2 * lop)
eyesdat &lt;- transform(eyesdat,
           leye = rbinom(nn, 1, prob = logitlink(eta1, inv = TRUE)),
           reye = rbinom(nn, 1, prob = logitlink(eta2, inv = TRUE)))
head(eyesdat)
fit5 &lt;- vglm(cbind(leye, reye) ~ op,
             binom2.or(exchangeable = TRUE, zero = 3),
             data = eyesdat, trace = TRUE,
             xij = list(op ~ lop + rop + fill1(lop)),
             form2 = ~  op + lop + rop + fill1(lop))
coef(fit5)
coef(fit5, matrix = TRUE)
constraints(fit5)
fit5@control$xij
head(model.matrix(fit5))


# Example 6. The use of the 'constraints' argument.
as.character(~ bs(year,df=3))  # Get the white spaces right
clist &lt;- list("(Intercept)"      = diag(3),
              "bs(year, df = 3)" = rbind(1, 0, 0))
fit1 &lt;- vglm(r1 ~ bs(year,df=3), gev(zero = NULL),
             data = venice, constraints = clist, trace = TRUE)
coef(fit1, matrix = TRUE)  # Check
</code></pre>

<hr>
<h2 id='vglm-class'>Class &ldquo;vglm&rdquo; </h2><span id='topic+vglm-class'></span>

<h3>Description</h3>

<p>  Vector generalized linear models. </p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>vglm(...)</code>.

</p>


<h3>Slots</h3>

<p>In the following, <code class="reqn">M</code> is the number of linear predictors.
</p>

<dl>
<dt><code>extra</code>:</dt><dd><p>Object of class <code>"list"</code>;
the <code>extra</code> argument on entry to <code>vglm</code>. This
contains any extra information that might be needed
by the family function. </p>
</dd>
<dt><code>family</code>:</dt><dd><p>Object of class <code>"vglmff"</code>.
The family function.  </p>
</dd>
<dt><code>iter</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
The number of IRLS iterations used. </p>
</dd>
<dt><code>predictors</code>:</dt><dd><p>Object of class <code>"matrix"</code>
with <code class="reqn">M</code> columns which holds the <code class="reqn">M</code> linear predictors. </p>
</dd>
<dt><code>assign</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
This named list gives information matching the columns and the
(LM) model matrix terms.
</p>
</dd>
<dt><code>call</code>:</dt><dd><p>Object of class <code>"call"</code>, from class
<code> "vlm"</code>.
The matched call.
</p>
</dd>
<dt><code>coefficients</code>:</dt><dd><p>Object of class
<code>"numeric"</code>, from class <code> "vlm"</code>.
A named vector of coefficients.
</p>
</dd>
<dt><code>constraints</code>:</dt><dd><p>Object of class <code>"list"</code>, from
class <code> "vlm"</code>.
A named list of constraint matrices used in the fitting.
</p>
</dd>
<dt><code>contrasts</code>:</dt><dd><p>Object of class <code>"list"</code>, from
class <code> "vlm"</code>.
The contrasts used (if any).
</p>
</dd>
<dt><code>control</code>:</dt><dd><p>Object of class <code>"list"</code>, from class
<code> "vlm"</code>.
A list of parameters for controlling the fitting process.
See <code><a href="#topic+vglm.control">vglm.control</a></code> for details.
</p>
</dd>
<dt><code>criterion</code>:</dt><dd><p>Object of class <code>"list"</code>, from
class <code> "vlm"</code>.
List of convergence criterion evaluated at the
final IRLS iteration.
</p>
</dd>
<dt><code>df.residual</code>:</dt><dd><p>Object of class
<code>"numeric"</code>, from class <code> "vlm"</code>.
The residual degrees of freedom.
</p>
</dd>
<dt><code>df.total</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The total degrees of freedom.
</p>
</dd>
<dt><code>dispersion</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The scaling parameter.
</p>
</dd>
<dt><code>effects</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
The effects.
</p>
</dd>
<dt><code>fitted.values</code>:</dt><dd><p>Object of class
<code>"matrix"</code>, from class <code> "vlm"</code>.
The fitted values.


</p>
</dd>
<dt><code>misc</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
A named list to hold miscellaneous parameters.
</p>
</dd>
<dt><code>model</code>:</dt><dd><p>Object of class <code>"data.frame"</code>,
from class <code> "vlm"</code>.
The model frame.
</p>
</dd>
<dt><code>na.action</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
A list holding information about missing values.
</p>
</dd>
<dt><code>offset</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
If non-zero, a <code class="reqn">M</code>-column matrix of offsets.
</p>
</dd>
<dt><code>post</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>
where post-analysis results may be put.
</p>
</dd>
<dt><code>preplot</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>
used by <code><a href="#topic+plotvgam">plotvgam</a></code>; the plotting parameters
may be put here.
</p>
</dd>
<dt><code>prior.weights</code>:</dt><dd><p>Object of class
<code>"matrix"</code>, from class <code> "vlm"</code>
holding the initially supplied weights.
</p>
</dd>
<dt><code>qr</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
QR decomposition at the final iteration.
</p>
</dd>
<dt><code>R</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The <b>R</b> matrix in the QR decomposition used in the fitting.
</p>
</dd>
<dt><code>rank</code>:</dt><dd><p>Object of class <code>"integer"</code>,
from class <code> "vlm"</code>.
Numerical rank of the fitted model.
</p>
</dd>
<dt><code>residuals</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The <em>working</em> residuals at the final IRLS iteration.
</p>
</dd>
<dt><code>ResSS</code>:</dt><dd><p>Object of class <code>"numeric"</code>,
from class <code> "vlm"</code>.
Residual sum of squares at the final IRLS iteration with
the adjusted dependent vectors and weight matrices.
</p>
</dd>
<dt><code>smart.prediction</code>:</dt><dd><p>Object of class
<code>"list"</code>, from class <code> "vlm"</code>.
A list of data-dependent parameters (if any)
that are used by smart prediction.
</p>
</dd>
<dt><code>terms</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
The <code><a href="stats.html#topic+terms">terms</a></code> object used.
</p>
</dd>
<dt><code>weights</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The weight matrices at the final IRLS iteration.
This is in matrix-band form.
</p>
</dd>
<dt><code>x</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The model matrix (LM, not VGLM).
</p>
</dd>
<dt><code>xlevels</code>:</dt><dd><p>Object of class <code>"list"</code>,
from class <code> "vlm"</code>.
The levels of the factors, if any, used in fitting.
</p>
</dd>
<dt><code>y</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
The response, in matrix form.
</p>
</dd>
<dt><code>Xm2</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
See <code><a href="#topic+vglm-class">vglm-class</a></code>).
</p>
</dd>
<dt><code>Ym2</code>:</dt><dd><p>Object of class <code>"matrix"</code>,
from class <code> "vlm"</code>.
See <code><a href="#topic+vglm-class">vglm-class</a></code>).
</p>
</dd>
<dt><code>callXm2</code>:</dt><dd>
<p>Object of class <code>"call"</code>, from class <code> "vlm"</code>.
The matched call for argument <code>form2</code>.
</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"vlm"</code>, directly.
</p>


<h3>Methods</h3>


<dl>
<dt>cdf</dt><dd><p><code>signature(object = "vglm")</code>:
cumulative distribution function.
Applicable to, e.g., quantile regression and extreme value data models.</p>
</dd>
<dt>deplot</dt><dd><p><code>signature(object = "vglm")</code>:
Applicable to, e.g., quantile regression.</p>
</dd>
<dt>deviance</dt><dd><p><code>signature(object = "vglm")</code>:
deviance of the model (where applicable). </p>
</dd>
<dt>plot</dt><dd><p><code>signature(x = "vglm")</code>:
diagnostic plots. </p>
</dd>
<dt>predict</dt><dd><p><code>signature(object = "vglm")</code>:
extract the linear predictors or
predict the linear predictors at a new data frame.</p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "vglm")</code>:
short summary of the object. </p>
</dd>
<dt>qtplot</dt><dd><p><code>signature(object = "vglm")</code>:
quantile plot (only applicable to some models). </p>
</dd>
<dt>resid</dt><dd><p><code>signature(object = "vglm")</code>:
residuals. There are various types of these. </p>
</dd>
<dt>residuals</dt><dd><p><code>signature(object = "vglm")</code>:
residuals. Shorthand for <code>resid</code>. </p>
</dd>
<dt>rlplot</dt><dd><p><code>signature(object = "vglm")</code>: return level plot.
Useful for extreme value data models.</p>
</dd>
<dt>summary</dt><dd><p><code>signature(object = "vglm")</code>:
a more detailed summary of the object. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>
<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+vgam-class">vgam-class</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multinomial logit model
pneumo &lt;- transform(pneumo, let = log(exposure.time))
vglm(cbind(normal, mild, severe) ~ let, multinomial, data = pneumo)
</code></pre>

<hr>
<h2 id='vglm.control'> Control Function for vglm() </h2><span id='topic+vglm.control'></span>

<h3>Description</h3>

<p>Algorithmic constants and parameters for
running <code>vglm</code> are set
using this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vglm.control(checkwz = TRUE, Check.rank = TRUE, Check.cm.rank = TRUE,
             criterion = names(.min.criterion.VGAM),
             epsilon = 1e-07, half.stepsizing = TRUE,
             maxit = 30, noWarning = FALSE,
             stepsize = 1, save.weights = FALSE,
             trace = FALSE, wzepsilon = .Machine$double.eps^0.75,
             xij = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vglm.control_+3A_checkwz">checkwz</code></td>
<td>

<p>logical indicating whether the diagonal elements
of the working weight matrices should be checked
whether they are sufficiently positive, i.e., greater
than <code>wzepsilon</code>. If not, any values less than
<code>wzepsilon</code> are replaced with this value.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_check.rank">Check.rank</code></td>
<td>

<p>logical indicating whether the rank of the VLM matrix
should be checked. If this is not of full column rank then
the results are not to be trusted.
The default is to give an error message if the VLM
matrix is not of full column rank.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_check.cm.rank">Check.cm.rank</code></td>
<td>

<p>logical indicating whether the rank of each constraint matrix
should be checked. If this is not of full column rank then
an error will occur. Under no circumstances should any
constraint matrix have a rank less than the number of columns.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_criterion">criterion</code></td>
<td>

<p>character variable describing what criterion is to be
used to test for convergence. The possibilities are
listed in <code>.min.criterion.VGAM</code>, but most family
functions only implement a few of these.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_epsilon">epsilon</code></td>
<td>

<p>positive convergence tolerance epsilon. Roughly speaking,
the Newton-Raphson/Fisher-scoring iterations are assumed
to have converged when two successive <code>criterion</code>
values are within <code>epsilon</code> of each other.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_half.stepsizing">half.stepsizing</code></td>
<td>

<p>logical indicating if half-stepsizing is allowed. For
example, in maximizing a log-likelihood, if the next
iteration has a log-likelihood that is less than
the current value of the log-likelihood, then a half
step will be taken.  If the log-likelihood is still
less than at the current position, a quarter-step
will be taken etc. Eventually a step will be taken
so that an improvement is made to the convergence
criterion.  <code>half.stepsizing</code> is ignored if
<code>criterion == "coefficients"</code>.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_maxit">maxit</code></td>
<td>

<p>maximum number of (usually Fisher-scoring) iterations
allowed.  Sometimes Newton-Raphson is used.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_nowarning">noWarning</code></td>
<td>

<p>logical indicating whether to suppress a warning if
convergence is not obtained within <code>maxit</code> iterations.
This is ignored if <code>maxit = 1</code> is set.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_stepsize">stepsize</code></td>
<td>

<p>usual step size to be taken between each
Newton-Raphson/Fisher-scoring iteration. It should be a
value between 0 and 1, where a value of unity corresponds
to an ordinary step.  A value of 0.5 means half-steps are
taken.  Setting a value near zero will cause convergence
to be generally slow but may help increase the chances
of successful convergence for some family functions.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_save.weights">save.weights</code></td>
<td>

<p>logical indicating whether the <code>weights</code> slot of a
<code>"vglm"</code> object will be saved on the object. If not,
it will be reconstructed when needed, e.g., <code>summary</code>.
Some family functions have <code>save.weights = TRUE</code> and
others have <code>save.weights = FALSE</code> in their control
functions.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_trace">trace</code></td>
<td>

<p>logical indicating if output should be produced for each
iteration.  Setting <code>trace = TRUE</code> is recommended in
general because <span class="pkg">VGAM</span> fits a very broad variety of
models and distributions, and for some of them, convergence
is intrinsically more difficult. Monitoring convergence
can help check that the solution is reasonable or that
a problem has occurred.  It may suggest better initial
values are needed, the making of invalid assumptions,
or that the model is inappropriate for the data, etc.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_wzepsilon">wzepsilon</code></td>
<td>

<p>small positive number used to test whether the diagonals
of the working weight matrices are sufficiently positive.
</p>
</td></tr>
<tr><td><code id="vglm.control_+3A_xij">xij</code></td>
<td>

<p>A list of formulas.
Each formula has a RHS giving <code class="reqn">M</code> terms making up a
covariate-dependent term (whose name is the response).
That is, it creates a variable that takes on
different values for each linear/additive predictor,
e.g., the ocular pressure of each eye.
The <code class="reqn">M</code> terms must be unique;
use <code><a href="#topic+fill1">fill1</a></code>, <code>fill2</code>, <code>fill3</code>,
etc. if necessary.
Each formula should have a response which is taken as the
name of that variable, and the <code class="reqn">M</code> terms are enumerated
in sequential order.  Each of the <code class="reqn">M</code> terms multiply
each successive row of the constraint matrix.
When <code>xij</code> is used, the use of <code>form2</code> is also
required to give <em>every</em> term used by the model.
</p>

<p>A formula or a list of formulas.
</p>
<p>The function <code><a href="#topic+Select">Select</a></code> can be used to
select variables beginning with the same character string.
</p>
</td></tr>



















<tr><td><code id="vglm.control_+3A_...">...</code></td>
<td>

<p>other parameters that may be picked up from control
functions that are specific to the <span class="pkg">VGAM</span> family function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the control parameters are used within
<code>vglm.fit</code> and you will have to look at that to
understand the full details.
</p>
<p>Setting <code>save.weights = FALSE</code> is useful for some
models because the <code>weights</code> slot of the object
is the largest and so less memory is used to store the
object. However, for some <span class="pkg">VGAM</span> family function,
it is necessary to set <code>save.weights = TRUE</code> because
the <code>weights</code> slot cannot be reconstructed later.
</p>


<h3>Value</h3>

<p>A list with components matching the input names.
A little error
checking is done, but not much.
The list is assigned to the <code>control</code> slot of
<code>vglm</code> objects.
</p>


<h3>Warning</h3>

<p>For some applications the default convergence criterion should
be tightened.
Setting something like <code>criterion = "coef", epsilon = 1e-09</code>
is one way to achieve this, and also add
<code>trace = TRUE</code> to monitor the convergence.
Setting  <code>maxit</code> to some higher number is usually not
needed, and needing to do so suggests something is wrong, e.g.,
an ill-conditioned model, over-fitting or under-fitting.
</p>


<h3>Note</h3>

<p>Reiterating from above,
setting <code>trace = TRUE</code> is recommended in general.
</p>
<p>In Example 2 below there are two covariates that have
linear/additive predictor specific values.  These are
handled using the <code>xij</code> argument.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee</p>


<h3>References</h3>

<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+TypicalVGAMfamilyFunction">TypicalVGAMfamilyFunction</a></code>,
<code><a href="#topic+fill1">fill1</a></code>.
The author's homepage has further documentation about
the <code>xij</code> argument;
see also <code><a href="#topic+Select">Select</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1.
pneumo &lt;- transform(pneumo, let = log(exposure.time))
vglm(cbind(normal, mild, severe) ~ let, multinomial, pneumo,
     crit = "coef", step = 0.5, trace = TRUE, epsil = 1e-8,
     maxit = 40)


# Example 2. The use of the xij argument (simple case).
ymat &lt;- rdiric(n &lt;- 1000, shape = rep(exp(2), len = 4))
mydat &lt;- data.frame(x1 = runif(n), x2 = runif(n), x3 = runif(n),
                    x4 = runif(n),
                    z1 = runif(n), z2 = runif(n), z3 = runif(n),
                    z4 = runif(n))
mydat &lt;- transform(mydat, X = x1, Z = z1)
mydat &lt;- round(mydat, digits = 2)
fit2 &lt;- vglm(ymat ~ X + Z,
             dirichlet(parallel = TRUE), mydat, trace = TRUE,
             xij = list(Z ~ z1 + z2 + z3 + z4,
                        X ~ x1 + x2 + x3 + x4),
             form2 = ~  Z + z1 + z2 + z3 + z4 +
                        X + x1 + x2 + x3 + x4)
head(model.matrix(fit2, type =  "lm"))  # LM model matrix
head(model.matrix(fit2, type = "vlm"))  # Big VLM model matrix
coef(fit2)
coef(fit2, matrix = TRUE)
max(abs(predict(fit2)-predict(fit2, new = mydat)))  # Predicts ok
summary(fit2)
## Not run: 
# plotvgam(fit2, se = TRUE, xlab = "x1", which.term = 1)  # Bug!
# plotvgam(fit2, se = TRUE, xlab = "z1", which.term = 2)  # Bug!
plotvgam(fit2, xlab = "x1")  # Correct
plotvgam(fit2, xlab = "z1")  # Correct

## End(Not run)


# Example 3. The use of the xij argument (complex case).
set.seed(123)
coalminers &lt;-
  transform(coalminers,
            Age = (age - 42) / 5,
            dum1 = round(runif(nrow(coalminers)), digits = 2),
            dum2 = round(runif(nrow(coalminers)), digits = 2),
            dum3 = round(runif(nrow(coalminers)), digits = 2),
            dumm = round(runif(nrow(coalminers)), digits = 2))
BS &lt;- function(x, ..., df = 3)
  sm.bs(c(x,...), df = df)[1:length(x),,drop = FALSE]
NS &lt;- function(x, ..., df = 3)
  sm.ns(c(x,...), df = df)[1:length(x),,drop = FALSE]

# Equivalently...
BS &lt;- function(x, ..., df = 3)
  head(sm.bs(c(x,...), df = df), length(x), drop = FALSE)
NS &lt;- function(x, ..., df = 3)
  head(sm.ns(c(x,...), df = df), length(x), drop = FALSE)

fit3 &lt;- vglm(cbind(nBnW,nBW,BnW,BW) ~ Age + NS(dum1, dum2),
             fam = binom2.or(exchangeable = TRUE, zero = 3),
             xij = list(NS(dum1, dum2) ~ NS(dum1, dum2) +
                                         NS(dum2, dum1) +
                                         fill1(NS( dum1))),
             form2 = ~  NS(dum1, dum2) + NS(dum2, dum1) +
                        fill1(NS(dum1)) +
                        dum1 + dum2 + dum3 + Age + age + dumm,
             data = coalminers, trace = TRUE)
head(model.matrix(fit3, type = "lm"))   # LM model matrix
head(model.matrix(fit3, type = "vlm"))  # Big VLM model matrix
coef(fit3)
coef(fit3, matrix = TRUE)
## Not run: 
plotvgam(fit3, se = TRUE, lcol = 2, scol = 4, xlab = "dum1")

## End(Not run)
</code></pre>

<hr>
<h2 id='vglmff-class'>Class &ldquo;vglmff&rdquo; </h2><span id='topic+vglmff-class'></span>

<h3>Description</h3>

<p>  Family functions for the <span class="pkg">VGAM</span> package </p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("vglmff", ...)</code>.
</p>


<h3>Slots</h3>

<p>In the following, <code class="reqn">M</code> is the number of linear/additive
predictors.
</p>

<dl>
<dt><code>start1</code>:</dt><dd>
<p>Object of class <code>"expression"</code> to insert
code at a special position (the very start)
in <code>vglm.fit</code> or <code>vgam.fit</code>.
</p>
</dd>
<dt><code>blurb</code>:</dt><dd>
<p>Object of class <code>"character"</code> giving
a small description of the model. Important arguments such as
parameter link functions can be expressed here.
</p>
</dd>
<dt><code>charfun</code>:</dt><dd>
<p>Object of class <code>"function"</code> which
returns the characteristic function
or variance function (usually for some GLMs only).
The former uses a dummy variable x.
Both use the linear/additive predictors.
The function must have arguments
<code>function(x, eta, extra = NULL, varfun = FALSE)</code>.
The <code>eta</code> and <code>extra</code> arguments are used to obtain
the parameter values.
If <code>varfun = TRUE</code> then the function returns the
variance function, else the characteristic function (default).
Note that
one should check that the <code>infos</code> slot has a list component
called <code>charfun</code> which is <code>TRUE</code> before attempting to
use this slot.
This is an easier way to test that this slot is operable.
</p>
</dd>
<dt><code>constraints</code>:</dt><dd>
<p>Object of class <code>"expression"</code>
which sets up any constraint matrices defined by arguments in the
family function. A <code>zero</code> argument is always fed into
<code>cm.zero.vgam</code>, whereas other constraints are fed into
<code>cm.vgam</code>.
</p>
</dd>
<dt><code>deviance</code>:</dt><dd>
<p>Object of class <code>"function"</code>
returning the deviance of the model. This slot is optional.
If present, the function must have arguments
<code>function(mu, y, w, residuals = FALSE, eta, extra = NULL)</code>.
Deviance residuals are returned if <code>residuals = TRUE</code>.
</p>
</dd>
<dt><code>rqresslot</code>:</dt><dd>
<p>Object of class <code>"function"</code>
returning the randomized quantile residuals of the distibution.
This slot is optional.
If present, the function must have arguments
<code>function(mu, y, w, eta, extra = NULL)</code>.
</p>

</dd>
<dt><code>fini1</code>:</dt><dd>
<p>Object of class <code>"expression"</code> to insert
code at a special position in <code>vglm.fit</code> or
<code>vgam.fit</code>.
This code is evaluated immediately after the fitting.
</p>
</dd>
<dt><code>first</code>:</dt><dd>
<p>Object of class <code>"expression"</code> to insert
code at a special position in <code><a href="#topic+vglm">vglm</a></code> or
<code><a href="#topic+vgam">vgam</a></code>.
</p>
</dd>
<dt><code>infos</code>:</dt><dd>
<p>Object of class <code>"function"</code> which
returns a list with components such as <code>M1</code>.
At present only a very few <span class="pkg">VGAM</span> family functions have this
feature implemented.
Those that do do not require specifying the <code>M1</code>
argument when used with <code><a href="#topic+rcim">rcim</a></code>.
</p>
</dd>
<dt><code>initialize</code>:</dt><dd>
<p>Object of class <code>"expression"</code> used
to perform error checking (especially for the variable <code>y</code>)
and obtain starting values for the model.
In general, <code>etastart</code> or
<code>mustart</code> are assigned values based on the variables <code>y</code>,
<code>x</code> and <code>w</code>.
</p>
</dd>
<dt><code>linkinv</code>:</dt><dd>
<p>Object of class <code>"function"</code> which
returns the fitted values, given the linear/additive predictors.
The function must have arguments
<code>function(eta, extra = NULL)</code>.
</p>
</dd>
<dt><code>last</code>:</dt><dd>
<p>Object of class <code>"expression"</code> to insert code at a
special position (at the very end) of <code>vglm.fit()</code>
or <code>vgam.fit()</code>.
This code is evaluated after the fitting.
The list <code>misc</code> is often assigned components in this slot,
which becomes the <code>misc</code> slot on the fitted object.
</p>
</dd>
<dt><code>linkfun</code>:</dt><dd>
<p>Object of class <code>"function"</code> which,
given the fitted values, returns the linear/additive predictors.
If present, the function must have arguments
<code>function(mu, extra = NULL)</code>.
Most <span class="pkg">VGAM</span> family functions do not have
a <code>linkfun</code> function. They largely are for
classical exponential families, i.e., GLMs.
</p>
</dd>
<dt><code>loglikelihood</code>:</dt><dd>
<p>Object of class <code>"function"</code>
returning the log-likelihood of the model. This slot is optional.
If present, the function must have arguments
<code>function(mu, y, w, residuals = FALSE, eta, extra = NULL)</code>.
The argument <code>residuals</code> can be ignored because
log-likelihood residuals aren't defined.
</p>
</dd>
<dt><code>middle1</code>:</dt><dd>
<p>Object of class <code>"expression"</code> to insert
code at a special position in <code>vglm.fit</code> or
<code>vgam.fit</code>.
</p>
</dd>
<dt><code>middle2</code>:</dt><dd>
<p>Object of class <code>"expression"</code> to insert
code at a special position in <code>vglm.fit</code> or
<code>vgam.fit</code>.
</p>
</dd>
<dt><code>simslot</code>:</dt><dd>
<p>Object of class <code>"function"</code> to allow
<code><a href="stats.html#topic+simulate">simulate</a></code> to work.
</p>
</dd>
<dt><code>hadof</code>:</dt><dd>
<p>Object of class <code>"function"</code>;
experimental.
</p>
</dd>
<dt><code>summary.dispersion</code>:</dt><dd>
<p>Object of class <code>"logical"</code>
indicating whether the general VGLM formula (based on a residual
sum of squares) can be used for computing the scaling/dispersion
parameter. It is <code>TRUE</code> for most models except for nonlinear
regression models.
</p>
</dd>
<dt><code>vfamily</code>:</dt><dd>
<p>Object of class <code>"character"</code>
giving class information about the family function. Although
not developed at this stage, more flexible classes are planned
in the future. For example, family functions
<code><a href="#topic+sratio">sratio</a></code>, <code><a href="#topic+cratio">cratio</a></code>,
<code><a href="#topic+cumulative">cumulative</a></code>, and <code><a href="#topic+acat">acat</a></code>
all operate on categorical data, therefore will have a special class
called <code>"VGAMcat"</code>, say. Then if <code>fit</code> was
a <code>vglm</code> object, then <code>coef(fit)</code> would print
out the <code>vglm</code> coefficients plus <code>"VGAMcat"</code>
information as well.
</p>
</dd>
<dt><code>deriv</code>:</dt><dd>
<p>Object of class <code>"expression"</code> which
returns a <code class="reqn">M</code>-column matrix of first derivatives of the
log-likelihood function
with respect to the linear/additive predictors, i.e., the
score vector. In Yee and Wild (1996) this is the
<code class="reqn">\bold{d}_i</code> vector. Thus each row of the
matrix returned by this slot is such a vector.
</p>
</dd>
<dt><code>weight</code>:</dt><dd>
<p>Object of class <code>"expression"</code> which
returns the second derivatives of the log-likelihood function
with respect to the linear/additive predictors.
This can be either the observed or expected information matrix, i.e.,
Newton-Raphson or Fisher-scoring respectively.
In Yee and Wild (1996) this is the
<code class="reqn">\bold{W}_i</code> matrix. Thus each row of the
matrix returned by this slot is such a matrix.
Like the <code>weights</code> slot of <code>vglm</code>/<code>vgam</code>, it is
stored in
<em>matrix-band</em> form, whereby the first <code class="reqn">M</code>
columns of the matrix are the
diagonals, followed by the upper-diagonal band, followed by the
band above that, etc. In this case, there can be up to <code class="reqn">M(M+1)</code>
columns, with the last column corresponding to the (1,<code class="reqn">M</code>) elements
of the weight matrices.
</p>
</dd>
<dt><code>validfitted, validparams</code>:</dt><dd>
<p>Functions that test that the fitted values and
all parameters are within range.
These functions can issue a warning if violations are detected.
</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>print</dt><dd><p><code>signature(x = "vglmff")</code>:
short summary of the family function.
</p>
</dd>
</dl>



<h3>Warning </h3>

<p><span class="pkg">VGAM</span> family functions are not compatible with
<code><a href="stats.html#topic+glm">glm</a></code>, nor <code>gam()</code>
(from either <span class="pkg">gam</span> or <span class="pkg">mgcv</span>).
</p>


<h3>Note</h3>

<p>With link functions etc., one must use <code>substitute</code> to
embed the options into the code. There are two different forms:
<code>eval(substitute(expression({...}), list(...)))</code>
for expressions, and
<code>eval(substitute( function(...) { ... }, list(...) )) </code>
for functions.
</p>







<p>The <code>extra</code> argument in
<code>linkinv</code>, <code>linkfun</code>, <code>deviance</code>,
<code>loglikelihood</code>, etc.
matches with the argument <code>extra</code>
in <code><a href="#topic+vglm">vglm</a></code>, <code><a href="#topic+vgam">vgam</a></code> and <code><a href="#topic+rrvglm">rrvglm</a></code>.
This allows input to be fed into all slots of a <span class="pkg">VGAM</span>
family function.
</p>
<p>The expression <code>derivative</code> is evaluated immediately
prior to <code>weight</code>, so there is provision for re-use
of variables etc.  Programmers must be careful to choose
variable names that do not interfere with <code>vglm.fit</code>,
<code>vgam.fit()</code> etc.
</p>
<p>Programmers of <span class="pkg">VGAM</span> family functions are encouraged
to keep to previous conventions regarding the naming of arguments,
e.g.,
<code>link</code> is the argument for parameter link functions,
<code>zero</code> for allowing some of the
linear/additive predictors to be an intercept term only, etc.
</p>
<p>In general, Fisher-scoring is recommended over
Newton-Raphson where tractable. Although usually slightly
slower in convergence, the weight matrices from using the
expected information are positive-definite over a larger
parameter space.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+vgam">vgam</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+rcim">rcim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cratio()
cratio(link = "clogloglink")
cratio(link = "clogloglink", reverse = TRUE)
</code></pre>

<hr>
<h2 id='vonmises'> von Mises Distribution Family Function </h2><span id='topic+vonmises'></span>

<h3>Description</h3>

<p>Estimates the location and scale parameters of the
von Mises distribution by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vonmises(llocation = extlogitlink(min = 0, max = 2*pi),
         lscale = "loglink", ilocation = NULL, iscale = NULL,
         imethod = 1, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vonmises_+3A_llocation">llocation</code>, <code id="vonmises_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
location <code class="reqn">a</code> parameter
and scale parameter <code class="reqn">k</code>, respectively.
See <code><a href="#topic+Links">Links</a></code> for more choices.
For <code class="reqn">k</code>, a log link is the default
because the parameter is positive.
</p>
</td></tr>
<tr><td><code id="vonmises_+3A_ilocation">ilocation</code></td>
<td>

<p>Initial value for the location <code class="reqn">a</code> parameter.
By default, an initial value is chosen internally using
<code>imethod</code>. Assigning a value will override
the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="vonmises_+3A_iscale">iscale</code></td>
<td>

<p>Initial value for the scale <code class="reqn">k</code> parameter.
By default, an initial value is chosen internally using
<code>imethod</code>. Assigning a value will override
the argument <code>imethod</code>.
</p>
</td></tr>
<tr><td><code id="vonmises_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method. If failure
to converge occurs
try the other value, or else specify a value for
<code>ilocation</code> and <code>iscale</code>.
</p>
</td></tr>
<tr><td><code id="vonmises_+3A_zero">zero</code></td>
<td>

<p>An integer-valued vector specifying which
linear/additive predictors are modelled as intercepts only.
The default is none of them.
If used, one can choose one value from the set {1,2}.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>







</table>


<h3>Details</h3>

<p>The (two-parameter) von Mises
is the most commonly used distribution in practice
for circular data.
It has a density that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y;a,k) = \frac{\exp[k\cos(y-a)]}{
      2\pi I_0(k)}</code>
</p>

<p>where <code class="reqn">0 \leq y &lt; 2\pi</code>,
<code class="reqn">k&gt;0</code> is the scale parameter,
<code class="reqn">a</code> is the location parameter, and
<code class="reqn">I_0(k)</code> is the modified Bessel
function of order 0 evaluated at <code class="reqn">k</code>.
The mean of <code class="reqn">Y</code> (which is the fitted value) is <code class="reqn">a</code>
and the circular variance is
<code class="reqn">1 - I_1(k) / I_0(k)</code>
where <code class="reqn">I_1(k)</code> is the modified Bessel
function of order 1.
By default,
<code class="reqn">\eta_1=\log(a/(2\pi-a))</code>
and
<code class="reqn">\eta_2=\log(k)</code> for this family function.
</p>







<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Numerically, the von Mises can be difficult to fit because of a
log-likelihood having multiple maximums.
The user is therefore encouraged to try different starting values,
i.e., make use of <code>ilocation</code> and <code>iscale</code>.
</p>


<h3>Note</h3>

<p>The response and the fitted values are scaled so that
<code class="reqn">0\leq y&lt; 2\pi</code>.
The linear/additive predictors are left alone.
Fisher scoring is used.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Forbes, C., Evans, M., Hastings, N. and Peacock, B. (2011).
<em>Statistical Distributions</em>,
Hoboken, NJ, USA: John Wiley and Sons, Fourth edition.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Bessel">Bessel</a></code>,
<code><a href="#topic+cardioid">cardioid</a></code>.
</p>
<p><span class="pkg">CircStats</span> and <span class="pkg">circular</span> currently have a lot more
R functions for circular data than the <span class="pkg">VGAM</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
vdata &lt;- transform(vdata,
                   y = rnorm(nn, 2+x2, exp(0.2)))  # Bad data!!
fit &lt;- vglm(y  ~ x2, vonmises(zero = 2), vdata, trace = TRUE)
coef(fit, matrix = TRUE)
Coef(fit)
with(vdata, range(y))  # Original data
range(depvar(fit))     # Processed data is in [0,2*pi)
</code></pre>

<hr>
<h2 id='vplot.profile'>Plotting Functions for 'profile' Objects</h2><span id='topic+vplot.profile'></span><span id='topic+vpairs.profile'></span>

<h3>Description</h3>

<p><code><a href="graphics.html#topic+plot">plot</a></code> and <code><a href="graphics.html#topic+pairs">pairs</a></code> methods
for objects of
class <code>"profile"</code>, but renamed as
<code>vplot</code> and <code>vpairs</code>.
</p>









<h3>Usage</h3>

<pre><code class='language-R'>vplot.profile(x, ...)
vpairs.profile(x, colours = 2:3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vplot.profile_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"profile"</code>.</p>
</td></tr>
<tr><td><code id="vplot.profile_+3A_colours">colours</code></td>
<td>
<p>Colours to be used for the mean curves
conditional on
<code>x</code> and <code>y</code> respectively.</p>
</td></tr>
<tr><td><code id="vplot.profile_+3A_...">...</code></td>
<td>
<p>arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code> for details.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee adapted this function from
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>,
written originally
by D. M. Bates and W. N. Venables.  (For S in 1996.)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+profilevglm">profilevglm</a></code>,
<code><a href="#topic+confintvglm">confintvglm</a></code>,
<code><a href="#topic+lrt.stat">lrt.stat</a></code>,
<code><a href="MASS.html#topic+profile.glm">profile.glm</a></code>,
<code><a href="stats.html#topic+profile.nls">profile.nls</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
fit1 &lt;- vglm(cbind(normal, mild, severe) ~ let, acat,
             trace = TRUE, data = pneumo)
pfit1 &lt;- profile(fit1, trace = FALSE)
## Not run: 
vplot.profile(pfit1)
vpairs.profile(pfit1)

## End(Not run)
</code></pre>

<hr>
<h2 id='vsmooth.spline'> Vector Cubic Smoothing Spline </h2><span id='topic+vsmooth.spline'></span>

<h3>Description</h3>

<p>Fits a vector cubic smoothing spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vsmooth.spline(x, y, w = NULL, df = rep(5, M), spar = NULL,
               i.constraint = diag(M),
               x.constraint = diag(M),
               constraints = list("(Intercepts)" = i.constraint,
                                  x = x.constraint),
               all.knots = FALSE, var.arg = FALSE, scale.w = TRUE,
               nk = NULL, control.spar = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vsmooth.spline_+3A_x">x</code></td>
<td>

<p>A vector, matrix or a list.
If a list, the  <code>x</code> component is used.
If a matrix, the first column is used.
<code>x</code> may also be a complex vector, in which case
the real part is used, and the imaginary part is
used for the response.
In this help file, <code>n</code> is the number of
unique values of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_y">y</code></td>
<td>

<p>A vector, matrix or a list.
If a list, the  <code>y</code> component is used.
If a matrix, all but the first column is used.
In this help file, <code>M</code> is the number of
columns of <code>y</code> if
there are no constraints on the functions.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_w">w</code></td>
<td>

<p>The weight matrices or the number of observations.
If the  weight matrices, then this must be
a <code>n</code>-row matrix
with the elements in matrix-band form (see <code>iam</code>).
If a vector, then these are the number of observations.
By default, <code>w</code> is the <code>M</code> by <code>M</code> identity
matrix, denoted by  <code>matrix(1, n, M)</code>.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_df">df</code></td>
<td>

<p>Numerical vector containing the degrees of
freedom for each component function (smooth).
If necessary, the vector is recycled to have length equal
to the number of component functions to be estimated
(<code>M</code> if there are no constraints), which
equals the number of columns of the <code>x</code>-constraint matrix.
A value of 2 means a linear fit, and each element of
<code>df</code> should lie between 2 and <code>n</code>.
The larger the values of <code>df</code> the more wiggly the
smooths.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_spar">spar</code></td>
<td>

<p>Numerical vector containing the non-negative smoothing
parameters for each component function (smooth).
If necessary, the vector is recycled to have length equal
to the number of component functions to be estimated
(<code>M</code> if there are no constraints), which
equals the number of columns of the <code>x</code>-constraint matrix.
A value of zero means the smooth goes through the data and hence
is wiggly.
A value of <code>Inf</code> may be assigned, meaning the smooth will
be linear.
By default, the <code>NULL</code> value of <code>spar</code> means
<code>df</code> is used to determine the smoothing
parameters.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_all.knots">all.knots</code></td>
<td>
<p> Logical. If <code>TRUE</code> then each distinct
value of <code>x</code> will be a knot. By default, only a subset of
the unique values  of <code>x</code> are used; typically, the number
of knots is <code>O(n^0.25)</code> for <code>n</code> large,
but if <code>n &lt;= 40</code> then all the unique values
of <code>x</code> are used.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_i.constraint">i.constraint</code></td>
<td>
<p> A <code>M</code>-row constraint matrix for the
intercepts. It must be of full column rank.
By default, the constraint matrix for the intercepts is the
<code>M</code> by <code>M</code> identity matrix, meaning no constraints.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_x.constraint">x.constraint</code></td>
<td>
<p> A <code>M</code>-row constraint matrix
for <code>x</code>.
It must be of full column rank.
By default, the constraint matrix for the intercepts is the
<code>M</code> by <code>M</code> identity matrix, meaning no constraints.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_constraints">constraints</code></td>
<td>

<p>An alternative to specifying <code>i.constraint</code>
and <code>x.constraint</code>,
this is a list with two components corresponding to the
intercept and <code>x</code> respectively. They must both be a
<code>M</code>-row constraint matrix with full column rank.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_var.arg">var.arg</code></td>
<td>
<p> Logical: return the pointwise variances
of the fit?
Currently, this corresponds only to the nonlinear part of the
fit, and may be wrong.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_scale.w">scale.w</code></td>
<td>

<p>Logical.
By default, the weights <code>w</code> are scaled so that the
diagonal elements have mean 1.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_nk">nk</code></td>
<td>
<p> Number of knots.
If used, this argument overrides <code>all.knots</code>, and
must lie between 6 and <code>n</code>+2 inclusive.
</p>
</td></tr>
<tr><td><code id="vsmooth.spline_+3A_control.spar">control.spar</code></td>
<td>

<p>See <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm implemented is detailed in Yee (2000).
It involves decomposing the component functions
into a linear and
nonlinear part, and using B-splines.
The cost of the computation is <code>O(n M^3)</code>.
</p>
<p>The argument <code>spar</code> contains <em>scaled</em>
smoothing parameters.
</p>


<h3>Value</h3>

<p>An object of class <code>"vsmooth.spline"</code>
(see <code>vsmooth.spline-class</code>).
</p>


<h3>WARNING</h3>

<p>See <code><a href="#topic+vgam">vgam</a></code> for information about an important bug.
</p>


<h3>Note</h3>

<p>This function is quite similar
to <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>
but offers less functionality.
For example, cross validation is not implemented here.
For <code>M = 1</code>, the results will be generally different,
mainly due to the different way the knots are selected.
</p>
<p>The vector cubic smoothing spline which <code>s()</code>
represents is
computationally demanding for large <code class="reqn">M</code>.
The cost is approximately <code class="reqn">O(n M^3)</code> where
<code class="reqn">n</code> is the number of unique abscissae.
</p>
<p>Yet to be done: return the <em>unscaled</em>
smoothing parameters.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. (2000).
Vector Splines and Other Vector Smoothers.
Pages 529&ndash;534.
In: Bethlehem, J. G. and van der Heijde, P. G. M.
<em>Proceedings in Computational Statistics COMPSTAT 2000</em>.
Heidelberg: Physica-Verlag.
</p>


<h3>See Also</h3>

<p><code>vsmooth.spline-class</code>,
<code>plot.vsmooth.spline</code>,
<code>predict.vsmooth.spline</code>,
<code>iam</code>,
<code><a href="#topic+sm.os">sm.os</a></code>,
<code><a href="#topic+s">s</a></code>,
<code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 20; x &lt;- 2 + 5*(nn:1)/nn
x[2:4] &lt;- x[5:7]  # Allow duplication
y1 &lt;- sin(x) + rnorm(nn, sd = 0.13)
y2 &lt;- cos(x) + rnorm(nn, sd = 0.13)
y3 &lt;- 1 + sin(x) + rnorm(nn, sd = 0.13)  # For constraints
y &lt;- cbind(y1, y2, y3)
ww &lt;- cbind(rep(3, nn), 4, (1:nn)/nn)

(fit &lt;- vsmooth.spline(x, y, w = ww, df = 5))
## Not run: 
plot(fit)  # The 1st &amp; 3rd functions dont differ by a constant

## End(Not run)

mat &lt;- matrix(c(1,0,1, 0,1,0), 3, 2)
(fit2 &lt;- vsmooth.spline(x, y, w = ww, df = 5, i.constr = mat,
                        x.constr = mat))
# The 1st and 3rd functions do differ by a constant:
mycols &lt;- c("orange", "blue", "orange")
## Not run:  plot(fit2, lcol = mycols, pcol = mycols, las = 1) 

p &lt;- predict(fit, x = model.matrix(fit, type = "lm"), deriv = 0)
max(abs(depvar(fit) - with(p, y)))  # Should be 0

par(mfrow = c(3, 1))
ux &lt;- seq(1, 8, len = 100)
for (dd in 1:3) {
  pp &lt;- predict(fit, x = ux, deriv = dd)
## Not run: 
with(pp, matplot(x, y, type = "l", main = paste("deriv =", dd),
                 lwd = 2, ylab = "", cex.axis = 1.5,
                 cex.lab = 1.5, cex.main = 1.5)) 
## End(Not run)
}
</code></pre>

<hr>
<h2 id='waitakere'>Waitakere Ranges Data</h2><span id='topic+waitakere'></span>

<h3>Description</h3>

<p>The <code>waitakere</code> data frame has 579 rows and 18 columns.
Altitude is explanatory, and there are binary responses
(presence/absence = 1/0 respectively) for 17 plant species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(waitakere)</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt>agaaus</dt><dd><p>Agathis australis, or Kauri</p>
</dd>
<dt>beitaw</dt><dd><p>Beilschmiedia tawa, or Tawa</p>
</dd>
<dt>corlae</dt><dd><p>Corynocarpus laevigatus</p>
</dd>
<dt>cyadea</dt><dd><p>Cyathea dealbata</p>
</dd>
<dt>cyamed</dt><dd><p>Cyathea medullaris</p>
</dd>
<dt>daccup</dt><dd><p>Dacrydium cupressinum</p>
</dd>
<dt>dacdac</dt><dd><p>Dacrycarpus dacrydioides</p>
</dd>
<dt>eladen</dt><dd><p>Elaecarpus dentatus</p>
</dd>
<dt>hedarb</dt><dd><p>Hedycarya arborea</p>
</dd>
<dt>hohpop</dt><dd><p>Species name unknown</p>
</dd>
<dt>kniexc</dt><dd><p>Knightia excelsa, or Rewarewa</p>
</dd>
<dt>kuneri</dt><dd><p>Kunzea ericoides</p>
</dd>
<dt>lepsco</dt><dd><p>Leptospermum scoparium</p>
</dd>
<dt>metrob</dt><dd><p>Metrosideros robusta</p>
</dd>
<dt>neslan</dt><dd><p>Nestegis lanceolata</p>
</dd>
<dt>rhosap</dt><dd><p>Rhopalostylis sapida</p>
</dd>
<dt>vitluc</dt><dd><p>Vitex lucens, or Puriri</p>
</dd>
<dt>altitude</dt><dd><p>meters above sea level</p>
</dd>
</dl>



<h3>Details</h3>

<p>These were collected from the Waitakere Ranges,
a small forest in northern
Auckland, New Zealand. At 579 sites in the forest,
the presence/absence
of 17 plant species was recorded, as well as the altitude.
Each site was of area size 200<code class="reqn">m^2</code>.
</p>


<h3>Source</h3>

<p>Dr Neil Mitchell, University of Auckland.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hunua">hunua</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- vgam(agaaus ~ s(altitude, df = 2), binomialff, waitakere)
head(predict(fit, waitakere, type = "response"))
## Not run:  plot(fit, se = TRUE, lcol = "orange", scol = "blue") 
</code></pre>

<hr>
<h2 id='wald.stat'> Wald Test
Statistics Evaluated at the Null Values </h2><span id='topic+wald.stat'></span><span id='topic+wald.stat.vlm'></span>

<h3>Description</h3>

<p>Generic function that computes
Wald test statistics evaluated at the null values
(consequently they do not suffer from the Hauck-Donner effect).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wald.stat(object, ...)
wald.stat.vlm(object, values0 = 0, subset = NULL, omit1s = TRUE,
          all.out = FALSE, orig.SE = FALSE, iterate.SE = TRUE,
          trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wald.stat_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+vglm">vglm</a></code> fit.
</p>


</td></tr>
<tr><td><code id="wald.stat_+3A_values0">values0</code></td>
<td>

<p>Numeric vector. The null values corresponding to the null hypotheses.
Recycled if necessary.
</p>
</td></tr>
<tr><td><code id="wald.stat_+3A_subset">subset</code></td>
<td>

<p>Same as in <code><a href="#topic+hdeff">hdeff</a></code>.
</p>
</td></tr>
<tr><td><code id="wald.stat_+3A_omit1s">omit1s</code></td>
<td>

<p>Logical. Does one omit the intercepts?
Because the default would be to test that each
intercept is equal to 0, which often does not
make sense or is unimportant, the intercepts
are not tested by default.
If they are tested then each linear predictor
must have at least one coefficient
(from another variable) to be estimated.
</p>
</td></tr>
<tr><td><code id="wald.stat_+3A_all.out">all.out</code></td>
<td>

<p>Logical. If <code>TRUE</code> then a list is returned containing
various quantities such as the SEs,
instead of just the Wald statistics.
</p>
</td></tr>
<tr><td><code id="wald.stat_+3A_orig.se">orig.SE</code></td>
<td>

<p>Logical. If <code>TRUE</code> then
the standard errors are computed at the MLE
(of the original object).
In practice, the (usual or unmodified)
Wald statistics etc. are extracted from <code>summary(object)</code>
because it was computed there.
These may suffer from the HDE since
<em>all</em> the SEs are evaluated
at the MLE of the original object.
If <code>TRUE</code> then argument <code>iterate.SE</code> may
be ignored or overwritten.
If <code>orig.SE = FALSE</code> then the <code class="reqn">k</code>th SE uses
the <code class="reqn">k</code>th value of <code>values0</code> in its computation and
<code>iterate.SE</code> specifies the choice of the other coefficients.
</p>
<p>This argument was previously called <code>as.summary</code> because
if <code>TRUE</code> then the Wald statistics are the same
as <code>summary(glm())</code>.

</p>
<p>For one-parameter models setting
<code>orig.SE = FALSE</code> results in what is called the
<em>null Wald</em> (NW) statistic by some people,
e.g., Laskar and King (1997) and Goh and King (1999).
The NW statistic does not suffer from the HDE.

</p>
</td></tr>
<tr><td><code id="wald.stat_+3A_iterate.se">iterate.SE</code></td>
<td>

<p>Logical, for the standard error computations.
If <code>TRUE</code> then IRLS iterations are performed to
get MLEs of the <em>other</em> regression coefficients, subject
to one coefficient being equal to the appropriate
<code>values0</code> value.
If <code>FALSE</code> then the other regression coefficients have
values obtained at the original fit.
It is recommended that a <code>TRUE</code> be used as the answer
tends to be more accurate.
If the large (VLM) model matrix only has one column and
<code>iterate.SE = TRUE</code> then an error will occur because
there are no <em>other</em> regression coefficients to estimate.
</p>
</td></tr>
<tr><td><code id="wald.stat_+3A_trace">trace</code></td>
<td>

<p>Logical. If <code>TRUE</code> then some output is produced as
the IRLS iterations proceed.
The value <code>NULL</code> means to use the <code>trace</code>
value of the fitted object;
see <code><a href="#topic+vglm.control">vglm.control</a></code>.
</p>

</td></tr>
<tr><td><code id="wald.stat_+3A_...">...</code></td>
<td>

<p>Ignored for now.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, <code><a href="#topic+summaryvglm">summaryvglm</a></code> and most regression
modelling functions such as <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>
compute all the standard errors (SEs) of the estimates at
the MLE and not at 0.
This corresponds to <code>orig.SE = TRUE</code> and
it is vulnerable to the Hauck-Donner effect (HDE;
see <code><a href="#topic+hdeff">hdeff</a></code>).
One solution is to compute the SEs
at 0 (or more generally, at the values of
the argument <code>values0</code>).
This function does that.
The two variants of Wald statistics are asymptotically equivalent;
however in small samples there can be an appreciable difference,
and the difference can be large if the estimates are near
to the boundary of the parameter space.
</p>
<p>None of the tests here are joint,
hence the degrees of freedom is always unity.
For a factor with more than 2 levels one can use
<code><a href="#topic+anova.vglm">anova.vglm</a></code> to test for the significance of the factor.
If <code>orig.SE = FALSE</code> and <code>iterate.SE = FALSE</code> then
one retains the MLEs of the original fit for the values of
the other coefficients, and replaces one coefficient at a
time by the value 0 (or whatever specified by <code>values0</code>).
One alternative would be to recompute the MLEs of the other
coefficients after replacing one of the values;
this is the default because <code>iterate.SE = TRUE</code>
and <code>orig.SE = FALSE</code>.
Just like with the original IRLS iterations,
the iterations here are not guaranteed to converge.
</p>
<p>Almost all <span class="pkg">VGAM</span> family functions use the EIM and not
the OIM; this affects the resulting standard errors.
Also, regularity conditions are assumed for the Wald,
likelihood ratio and score tests; some <span class="pkg">VGAM</span> family functions
such as <code><a href="#topic+alaplace1">alaplace1</a></code> are experimental and
do not satisfy such conditions, therefore naive inference is
hazardous.
</p>
<p>The default output of this function can be seen by
setting <code>wald0.arg = TRUE</code> in <code><a href="#topic+summaryvglm">summaryvglm</a></code>.
</p>


<h3>Value</h3>

<p>By default the signed square root of the Wald statistics
whose SEs are computed at one each of the null values.
If <code>all.out = TRUE</code> then a list is returned with the
following components:
<code>wald.stat</code> the Wald statistic,
<code>SE0</code> the standard error of that coefficient,
<code>values0</code> the null values.
Approximately, the default Wald statistics output are standard
normal random variates if each null hypothesis is true.
</p>
<p>Altogether,
by the four combinations of <code>iterate.SE</code> and <code>orig.SE</code>,
there are three different variants of the Wald statistic
that can be returned.
</p>


<h3>Warning </h3>

<p>This function has been tested but not thoroughly.
Convergence failure is possible for some models applied to
certain data sets; it is a good idea to set <code>trace = TRUE</code>
to monitor convergence.
For example, for a particular explanatory variable,
the estimated regression coefficients
of a non-parallel cumulative logit model
(see <code><a href="#topic+cumulative">cumulative</a></code>) are ordered,
and perturbing one coefficient might disrupt the order
and create numerical problems.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Laskar, M. R. and M. L. King (1997).
Modified Wald test for regression disturbances.
<em>Economics Letters</em>, <b>56</b>, 5&ndash;11.
</p>
<p>Goh, K.-L. and M. L. King (1999).
A correction for local biasedness of the Wald
and null Wald tests.
<em>Oxford Bulletin of Economics and Statistics</em>
<b>61</b>, 435&ndash;450.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrt.stat">lrt.stat</a></code>,
<code><a href="#topic+score.stat">score.stat</a></code>,
<code><a href="#topic+summaryvglm">summaryvglm</a></code>,
<code><a href="stats.html#topic+summary.glm">summary.glm</a></code>,
<code><a href="#topic+anova.vglm">anova.vglm</a></code>,
<code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+hdeff">hdeff</a></code>,
<code><a href="#topic+hdeffsev">hdeffsev</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
pneumo &lt;- transform(pneumo, let = log(exposure.time),
                            x3 = rnorm(nrow(pneumo)))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let + x3, propodds, pneumo))
wald.stat(fit)  # No HDE here
summary(fit, wald0 = TRUE)  # See them here
coef(summary(fit))  # Usual Wald statistics evaluated at the MLE
wald.stat(fit, orig.SE = TRUE)  # Same as previous line
</code></pre>

<hr>
<h2 id='waldff'> Wald Distribution Family Function </h2><span id='topic+waldff'></span>

<h3>Description</h3>

<p>Estimates the parameter of the standard Wald distribution
by maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>waldff(llambda = "loglink", ilambda = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="waldff_+3A_llambda">llambda</code>, <code id="waldff_+3A_ilambda">ilambda</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard Wald distribution is a special case of the
inverse Gaussian distribution with <code class="reqn">\mu=1</code>.
It has a density that can be written as
</p>
<p style="text-align: center;"><code class="reqn">f(y;\lambda) = \sqrt{\lambda/(2\pi y^3)}
       \; \exp\left(-\lambda (y-1)^2/(2 y)\right)</code>
</p>

<p>where <code class="reqn">y&gt;0</code> and <code class="reqn">\lambda&gt;0</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">1</code>
(returned as the fitted values) and its variance is
<code class="reqn">1/\lambda</code>.
By default, <code class="reqn">\eta=\log(\lambda)</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The <span class="pkg">VGAM</span> family function <code><a href="#topic+inv.gaussianff">inv.gaussianff</a></code>
estimates the location parameter <code class="reqn">\mu</code> too.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1994).
<em>Continuous Univariate Distributions</em>,
2nd edition,
Volume 1,
New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inv.gaussianff">inv.gaussianff</a></code>,
<code><a href="#topic+rinv.gaussian">rinv.gaussian</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wdata &lt;- data.frame(y = rinv.gaussian(1000, mu =  1, exp(1)))
wfit &lt;- vglm(y ~ 1, waldff(ilambda = 0.2), wdata, trace = TRUE)
coef(wfit, matrix = TRUE)
Coef(wfit)
summary(wfit)
</code></pre>

<hr>
<h2 id='weibull.mean'> Weibull Distribution Family Function,
Parameterized by the Mean </h2><span id='topic+weibull.mean'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the
2-parameter Weibull distribution.
The mean is one of the  parameters.
No observations should be censored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weibull.mean(lmean = "loglink", lshape = "loglink",
     imean = NULL, ishape = NULL, probs.y = c(0.2, 0.5, 0.8),
     imethod = 1, zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weibull.mean_+3A_lmean">lmean</code>, <code id="weibull.mean_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link functions applied to the
(positive) mean parameter (called <code class="reqn">mu</code> below) and
(positive) shape parameter (called <code class="reqn">a</code> below).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="weibull.mean_+3A_imean">imean</code>, <code id="weibull.mean_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial values for the mean and shape parameters.
</p>
</td></tr>
<tr><td><code id="weibull.mean_+3A_imethod">imethod</code>, <code id="weibull.mean_+3A_zero">zero</code>, <code id="weibull.mean_+3A_probs.y">probs.y</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+weibullR">weibullR</a></code> for most of the details
for this family function too.
The mean of <code class="reqn">Y</code>
is <code class="reqn">b \, \Gamma(1+ 1/a)</code>
(returned as the fitted values),
and this is the first parameter (a <code><a href="#topic+loglink">loglink</a></code>
link is the default because it is positive).
The other parameter is the positive shape paramter <code class="reqn">a</code>,
also having a default <code><a href="#topic+loglink">loglink</a></code> link.
</p>
<p>This <span class="pkg">VGAM</span> family function currently does not handle
censored data.
Fisher scoring is used to estimate the two parameters.
Although the expected information matrices used here
are valid in all regions of the parameter space,
the regularity conditions for maximum
likelihood estimation are satisfied only if <code class="reqn">a&gt;2</code>
(according to Kleiber and Kotz (2003)).
If this is violated then a warning message is issued.
One can enforce <code class="reqn">a&gt;2</code> by
choosing <code>lshape = logofflink(offset = -2)</code>.
Common values of the shape parameter lie between 0.5 and 3.5.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>See <code><a href="#topic+weibullR">weibullR</a></code> for more details.
This <span class="pkg">VGAM</span> family function handles multiple responses.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+weibullR">weibullR</a></code>,
<code><a href="stats.html#topic+Weibull">dweibull</a></code>,
<code><a href="#topic+truncweibull">truncweibull</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+lognormal">lognormal</a></code>,
<code><a href="#topic+expexpff">expexpff</a></code>,
<code><a href="#topic+maxwell">maxwell</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="#topic+gumbelII">gumbelII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))  # Complete data
wdata &lt;- transform(wdata, mu     = exp(-1 + 1 * x2),
                          x3     = rnorm(nn),
                          shape1 = exp(1),
                          shape2 = exp(2))
wdata &lt;- transform(wdata,
  y1 = rweibull(nn, shape1, scale = mu / gamma(1 + 1/shape1)),
  y2 = rweibull(nn, shape2, scale = mu / gamma(1 + 1/shape2)))
fit &lt;- vglm(cbind(y1, y2) ~ x2 + x3, weibull.mean, wdata,
            trace = TRUE)
coef(fit, matrix = TRUE)
sqrt(diag(vcov(fit)))  # SEs
summary(fit, presid = FALSE)
</code></pre>

<hr>
<h2 id='weibullR'> Weibull Distribution Family Function </h2><span id='topic+weibullR'></span>

<h3>Description</h3>

<p>Maximum likelihood estimation of the
2-parameter Weibull distribution.
No observations should be censored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weibullR(lscale = "loglink", lshape = "loglink",
         iscale = NULL,   ishape = NULL, lss = TRUE, nrfs = 1,
         probs.y = c(0.2, 0.5, 0.8), imethod = 1, zero = "shape")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weibullR_+3A_lshape">lshape</code>, <code id="weibullR_+3A_lscale">lscale</code></td>
<td>

<p>Parameter link functions applied to the
(positive) shape parameter (called <code class="reqn">a</code> below) and
(positive) scale parameter (called <code class="reqn">b</code> below).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="weibullR_+3A_ishape">ishape</code>, <code id="weibullR_+3A_iscale">iscale</code></td>
<td>

<p>Optional initial values for the shape and scale parameters.
</p>
</td></tr>
<tr><td><code id="weibullR_+3A_nrfs">nrfs</code></td>
<td>

<p>Currently this argument is ignored.
Numeric, of length one, with value in <code class="reqn">[0,1]</code>.
Weighting factor between Newton-Raphson and Fisher scoring.
The value 0 means pure Newton-Raphson, while 1 means
pure Fisher scoring.
The default value uses a mixture of the two algorithms,
and retaining
positive-definite working weights.
</p>
</td></tr>
<tr><td><code id="weibullR_+3A_imethod">imethod</code></td>
<td>

<p>Initialization method used if there are censored observations.
Currently only the values 1 and 2 are allowed.
</p>
</td></tr>
<tr><td><code id="weibullR_+3A_zero">zero</code>, <code id="weibullR_+3A_probs.y">probs.y</code>, <code id="weibullR_+3A_lss">lss</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Weibull density for a response <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">f(y;a,b) = a y^{a-1} \exp[-(y/b)^a] / (b^a)</code>
</p>

<p>for <code class="reqn">a &gt; 0</code>, <code class="reqn">b &gt; 0</code>, <code class="reqn">y &gt; 0</code>.
The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(y;a,b) = 1 - \exp[-(y/b)^a].</code>
</p>

<p>The mean of <code class="reqn">Y</code>
is <code class="reqn">b \, \Gamma(1+ 1/a)</code>
(returned as the fitted values),
and the mode is
at <code class="reqn">b\,(1-1/a)^{1/a}</code> when
<code class="reqn">a&gt;1</code>.
The density is unbounded for <code class="reqn">a&lt;1</code>.
The <code class="reqn">k</code>th moment about the origin is
<code class="reqn">E(Y^k) = b^k \,
  \Gamma(1+ k/a)</code>.
The hazard function
is <code class="reqn">a t^{a-1} / b^a</code>.
</p>
<p>This <span class="pkg">VGAM</span> family function currently does not handle
censored data.
Fisher scoring is used to estimate the two parameters.
Although the expected information matrices used here are valid
in all regions of the parameter space,
the regularity conditions for maximum
likelihood estimation are satisfied only if <code class="reqn">a&gt;2</code>
(according to Kleiber and Kotz (2003)).
If this is violated then a warning message is issued.
One can enforce <code class="reqn">a&gt;2</code> by
choosing <code>lshape = logofflink(offset = -2)</code>.
Common values of the shape parameter lie between 0.5 and 3.5.
</p>
<p>Summarized in Harper et al. (2011),
for inference, there are 4 cases to consider.
If <code class="reqn">a \le 1</code> then the MLEs are not consistent
(and the smallest observation becomes a hyperefficient
solution for the location parameter in the 3-parameter case).
If <code class="reqn">1 &lt; a &lt; 2</code> then MLEs exist but are
not asymptotically normal.
If <code class="reqn">a = 2</code> then the MLEs exist and are normal
and asymptotically
efficient but with a slower convergence rate than
when <code class="reqn">a &gt; 2</code>.
If <code class="reqn">a &gt; 2</code> then MLEs have classical asymptotic properties.
</p>
<p>The 3-parameter (location is the third parameter) Weibull can
be estimated by maximizing a profile log-likelihood (see,
e.g., Harper et al. (2011) and Lawless (2003)), else try
<code><a href="#topic+gev">gev</a></code> which is a better parameterization.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning</h3>

<p>This function is under development to handle
other censoring situations.
The version of this function which will handle
censored data will be
called <code>cenweibull()</code>. It is currently
being written and will use
<code><a href="#topic+SurvS4">SurvS4</a></code> as input.
It should be released in later versions of <span class="pkg">VGAM</span>.
</p>
<p>If the shape parameter is less than two then
misleading inference may
result, e.g., in the <code>summary</code>
and <code>vcov</code> of the object.
</p>


<h3>Note</h3>

<p>Successful convergence depends on having
reasonably good initial
values. If the initial values chosen by this
function are not good,
make use the two initial value arguments.
</p>
<p>This <span class="pkg">VGAM</span> family function handles multiple responses.
</p>
<p>The Weibull distribution is often an
alternative to the lognormal
distribution. The inverse Weibull distribution,
which is that of
<code class="reqn">1/Y</code> where <code class="reqn">Y</code> has a Weibull(<code class="reqn">a,b</code>)
distribution, is
known as the log-Gompertz distribution.
</p>
<p>There are problems implementing the three-parameter Weibull
distribution. These are because
the classical regularity conditions for the
asymptotic properties of the MLEs are not
satisfied because the
support of the distribution depends on one of
the parameters.
</p>
<p>Other related distributions are the Maxwell and Rayleigh
distributions.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Kleiber, C. and Kotz, S. (2003).
<em>Statistical Size Distributions in Economics
and Actuarial Sciences</em>,
Hoboken, NJ, USA: Wiley-Interscience.
</p>
<p>Johnson, N. L. and Kotz, S. and Balakrishnan, N. (1994).
<em>Continuous Univariate Distributions</em>,
2nd edition, Volume 1, New York: Wiley.
</p>
<p>Lawless, J. F. (2003).
<em>Statistical Models and Methods for Lifetime Data</em>,
2nd ed.
Hoboken, NJ, USA: John Wiley &amp; Sons.
</p>
<p>Rinne, Horst. (2009).
<em>The Weibull Distribution: A Handbook</em>.
Boca Raton, FL, USA: CRC Press.
</p>
<p>Gupta, R. D. and Kundu, D. (2006).
On the comparison of Fisher information of the
Weibull and GE distributions,
<em>Journal of Statistical Planning and Inference</em>,
<b>136</b>,
3130&ndash;3144.
</p>
<p>Harper, W. V. and Eschenbach, T. G. and James, T. R. (2011).
Concerns about Maximum Likelihood Estimation for
the Three-Parameter Weibull Distribution:
Case Study of Statistical Software,
<em>The American Statistician</em>,
<b>65(1)</b>,
44&ndash;54.
</p>
<p>Smith, R. L. (1985).
Maximum likelihood estimation in a class of nonregular cases.
<em>Biometrika</em>, <b>72</b>, 67&ndash;90.
</p>
<p>Smith, R. L. and Naylor, J. C. (1987).
A comparison of maximum likelihood and Bayesian estimators
for the three-parameter Weibull distribution.
<em>Applied Statistics</em>, <b>36</b>, 358&ndash;369.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+weibull.mean">weibull.mean</a></code>,
<code><a href="stats.html#topic+Weibull">dweibull</a></code>,
<code><a href="#topic+truncweibull">truncweibull</a></code>,
<code><a href="#topic+gev">gev</a></code>,
<code><a href="#topic+lognormal">lognormal</a></code>,
<code><a href="#topic+expexpff">expexpff</a></code>,
<code><a href="#topic+maxwell">maxwell</a></code>,
<code><a href="#topic+rayleigh">rayleigh</a></code>,
<code><a href="#topic+gumbelII">gumbelII</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))  # Complete data
wdata &lt;- transform(wdata,
            y1 = rweibull(nn, exp(1), scale = exp(-2 + x2)),
            y2 = rweibull(nn, exp(2), scale = exp( 1 - x2)))
fit &lt;- vglm(cbind(y1, y2) ~ x2, weibullR, wdata, trace = TRUE)
coef(fit, matrix = TRUE)
vcov(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='weightsvglm'> Prior and Working Weights of a VGLM fit </h2><span id='topic+weightsvglm'></span>

<h3>Description</h3>

<p>Returns either the prior weights or working weights
of a VGLM object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightsvglm(object, type = c("prior", "working"),
            matrix.arg = TRUE, ignore.slot = FALSE,
            deriv.arg = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightsvglm_+3A_object">object</code></td>
<td>

<p>a model object from the <span class="pkg">VGAM</span> <span class="rlang"><b>R</b></span> package
that inherits from
a <em>vector generalized linear model</em> (VGLM),
e.g., a model of class <code>"vglm"</code>.
</p>
</td></tr>
<tr><td><code id="weightsvglm_+3A_type">type</code></td>
<td>

<p>Character, which type of weight is to be returned?
The default is the first one.
</p>
</td></tr>
<tr><td><code id="weightsvglm_+3A_matrix.arg">matrix.arg</code></td>
<td>

<p>Logical, whether the answer is returned as a
matrix. If not, it will be a vector.
</p>
</td></tr>
<tr><td><code id="weightsvglm_+3A_ignore.slot">ignore.slot</code></td>
<td>

<p>Logical. If <code>TRUE</code> then
<code>object@weights</code> is ignored even if it has been assigned,
and the long calculation for <code>object@weights</code>
is repeated. This may give a slightly different answer because
of the final IRLS step at convergence may or may not assign
the latest value of quantities such as the mean and weights.
</p>
</td></tr>
<tr><td><code id="weightsvglm_+3A_deriv.arg">deriv.arg</code></td>
<td>

<p>Logical. If <code>TRUE</code> then
a list with components <code>deriv</code> and <code>weights</code>
is returned. See below for more details.
</p>
</td></tr>
<tr><td><code id="weightsvglm_+3A_...">...</code></td>
<td>

<p>Currently ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prior weights are usually inputted with the <code>weights</code>
argument in functions such as <code><a href="#topic+vglm">vglm</a></code> and
<code><a href="#topic+vgam">vgam</a></code>.  It may refer to frequencies of the
individual data or be weight matrices specified beforehand.
</p>
<p>Working weights are used by the IRLS algorithm. They correspond
to the second derivatives of the log-likelihood function
with respect to the linear predictors.  The working weights
correspond to positive-definite weight matrices and are returned
in <em>matrix-band</em> form, e.g., the first <code class="reqn">M</code> columns
correspond to the diagonals, etc.
</p>

<p>If one wants to perturb the linear predictors then the
<code>fitted.values</code> slots should be assigned to the object
before calling this function. The reason is that,
for some family functions,
the variable <code>mu</code> is used directly as one of the parameter
estimates, without recomputing it from <code>eta</code>.
</p>


<h3>Value</h3>

<p>If <code>type = "working"</code> and <code>deriv = TRUE</code> then a
list is returned with the two components described below.
Otherwise the prior or working weights are returned depending
on the value of <code>type</code>.
</p>
<table>
<tr><td><code>deriv</code></td>
<td>

<p>Typically the first derivative of the
log-likelihood with respect to the linear predictors.
For example, this is the variable <code>deriv.mu</code> in
<code>vglm.fit()</code>, or equivalently, the matrix returned in the
<code>"deriv"</code> slot of a <span class="pkg">VGAM</span> family function.
</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>

<p>The working weights.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is intended to be similar to
<code>weights.glm</code> (see <code><a href="stats.html#topic+glm">glm</a></code>).
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>,
<code><a href="#topic+vglmff-class">vglmff-class</a></code>,
<code><a href="#topic+vglm">vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pneumo &lt;- transform(pneumo, let = log(exposure.time))
(fit &lt;- vglm(cbind(normal, mild, severe) ~ let,
             cumulative(parallel = TRUE, reverse = TRUE), pneumo))
depvar(fit)  # These are sample proportions
weights(fit, type = "prior", matrix = FALSE)  # No. of observations

# Look at the working residuals
nn &lt;- nrow(model.matrix(fit, type = "lm"))
M &lt;- ncol(predict(fit))

wwt &lt;- weights(fit, type="working", deriv=TRUE)  # Matrix-band format
wz &lt;- m2a(wwt$weights, M = M)  # In array format
wzinv &lt;- array(apply(wz, 3, solve), c(M, M, nn))
wresid &lt;- matrix(NA, nn, M)  # Working residuals
for (ii in 1:nn)
  wresid[ii, ] &lt;- wzinv[, , ii, drop = TRUE] %*% wwt$deriv[ii, ]
max(abs(c(resid(fit, type = "work")) - c(wresid)))  # Should be 0

(zedd &lt;- predict(fit) + wresid)  # Adjusted dependent vector
</code></pre>

<hr>
<h2 id='wine'> Bitterness in Wine Data

</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>This oenological data frame concerns the amount of bitterness
in 78 bottles of white wine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wine)
</code></pre>


<h3>Format</h3>

<p>A data frame with 4 rows on the following 7 variables.
</p>

<dl>
<dt>temp</dt><dd><p>temperature, with levels cold and warm.
</p>
</dd>
<dt>contact</dt><dd><p>whether contact of the juice with the
skin was allowed or avoided, for a specified period.
Two levels: no or yes.
</p>
</dd>
<dt>bitter1, bitter2, bitter3, bitter4, bitter5</dt><dd>
<p>numeric vectors, the counts.
The order is none to most intense.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data set comes from Randall (1989) and concerns a factorial
experiment for investigating factors that affect the
bitterness of white
wines. There are two factors in the experiment:
temperature at the time
of crushing the grapes and contact of the juice
with the skin.  Two
bottles of wine were fermented for each of the
treatment combinations.
A panel of 9 judges were selected and trained
for the ability to detect
bitterness.  Thus there were 72 bottles in total.
Originally, the
bitterness of the wine were taken on a
continuous scale in the interval
from 0 (none) to 100 (intense) but later they
were grouped using equal
lengths into five ordered categories 1, 2, 3, 4 and 5.
</p>




<h3>Source</h3>



<p>Christensen, R. H. B. (2013)
Analysis of ordinal data with
cumulative link models&mdash;estimation
with the R-package <span class="pkg">ordinal</span>.
R Package Version 2013.9-30.
<a href="https://CRAN.R-project.org/package=ordinal">https://CRAN.R-project.org/package=ordinal</a>.



</p>
<p>Randall, J. H. (1989).
The analysis of sensory data by generalized linear model.
<em>Biometrical Journal</em> <b>31</b>(7), 781&ndash;793.
</p>
<p>Kosmidis, I. (2014).
Improved estimation in cumulative link models.
<em>Journal of the Royal Statistical Society, Series B,
Methodological</em>,
<b>76</b>(1): 169&ndash;196.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wine
summary(wine)
</code></pre>

<hr>
<h2 id='wrapup.smart'> Cleans Up After Smart Prediction </h2><span id='topic+wrapup.smart'></span>

<h3>Description</h3>

<p><code>wrapup.smart</code> deletes any variables used by smart prediction.
Needed by both the modelling function and the prediction function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrapup.smart()
</code></pre>


<h3>Details</h3>

<p>The variables to be deleted are <code>.smart.prediction</code>,
<code>.smart.prediction.counter</code>, and <code>.smart.prediction.mode</code>.
The function <code>wrapup.smart</code> is useful in <span class="rlang"><b>R</b></span> because
these variables are held in <code>smartpredenv</code>.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+setup.smart">setup.smart</a></code>. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: # Place this inside modelling functions such as lm, glm, vglm.
wrapup.smart()  # Put at the end of lm

## End(Not run)
</code></pre>

<hr>
<h2 id='yeo.johnson'>Yeo-Johnson Transformation</h2><span id='topic+yeo.johnson'></span>

<h3>Description</h3>

<p>Computes the Yeo-Johnson transformation, which is a
normalizing transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yeo.johnson(y, lambda, derivative = 0,
            epsilon = sqrt(.Machine$double.eps), inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yeo.johnson_+3A_y">y</code></td>
<td>
<p>Numeric, a vector or matrix. </p>
</td></tr>
<tr><td><code id="yeo.johnson_+3A_lambda">lambda</code></td>
<td>
<p>Numeric. It is recycled to the same length as
<code>y</code> if necessary. </p>
</td></tr>
<tr><td><code id="yeo.johnson_+3A_derivative">derivative</code></td>
<td>
<p>Non-negative integer. The default is
the ordinary function evaluation, otherwise the derivative
with respect to <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="yeo.johnson_+3A_epsilon">epsilon</code></td>
<td>
<p> Numeric and positive value. The tolerance given
to values of <code>lambda</code> when comparing it to 0 or 2. </p>
</td></tr>
<tr><td><code id="yeo.johnson_+3A_inverse">inverse</code></td>
<td>
<p> Logical.
Return the inverse transformation?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Yeo-Johnson transformation can be thought of as an extension
of the Box-Cox transformation. It handles both positive and
negative values, whereas the Box-Cox transformation only handles
positive values. Both can be used to transform the data so
as to improve normality. They can be used to perform LMS
quantile regression.
</p>


<h3>Value</h3>

<p>The Yeo-Johnson transformation or its inverse, or its
derivatives with respect to <code>lambda</code>, of <code>y</code>.
</p>


<h3>Note</h3>

<p>If <code>inverse = TRUE</code> then the
argument <code>derivative = 0</code> is required.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee </p>


<h3>References</h3>

<p>Yeo, I.-K. and Johnson, R. A. (2000).
A new family of power transformations to improve
normality or symmetry.
<em>Biometrika</em>,
<b>87</b>, 954&ndash;959.
</p>
<p>Yee, T. W. (2004).
Quantile regression via vector generalized additive models.
<em>Statistics in Medicine</em>, <b>23</b>, 2295&ndash;2315.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lms.yjn">lms.yjn</a></code>,
<code><a href="MASS.html#topic+boxcox">boxcox</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- seq(-4, 4, len = (nn &lt;- 200))
ltry &lt;- c(0, 0.5, 1, 1.5, 2)  # Try these values of lambda
lltry &lt;- length(ltry)
psi &lt;- matrix(NA_real_, nn, lltry)
for (ii in 1:lltry)
  psi[, ii] &lt;- yeo.johnson(y, lambda = ltry[ii])

## Not run: 
matplot(y, psi, type = "l", ylim = c(-4, 4), lwd = 2,
        lty = 1:lltry, col = 1:lltry, las = 1,
        ylab = "Yeo-Johnson transformation", 
        main = "Yeo-Johnson transformation with some lambda values")
abline(v = 0, h = 0)
legend(x = 1, y = -0.5, lty = 1:lltry, legend = as.character(ltry),
       lwd = 2, col = 1:lltry) 
## End(Not run)
</code></pre>

<hr>
<h2 id='Yules'> Yule-Simon Distribution </h2><span id='topic+Yules'></span><span id='topic+dyules'></span><span id='topic+pyules'></span><span id='topic+qyules'></span><span id='topic+ryules'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Yule-Simon distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dyules(x, shape, log = FALSE)
pyules(q, shape, lower.tail = TRUE, log.p = FALSE)
qyules(p, shape)
ryules(n, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Yules_+3A_x">x</code>, <code id="Yules_+3A_q">q</code>, <code id="Yules_+3A_p">p</code>, <code id="Yules_+3A_n">n</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">Normal</a></code>.



</p>
</td></tr>



<tr><td><code id="Yules_+3A_shape">shape</code></td>
<td>

<p>See <code><a href="#topic+yulesimon">yulesimon</a></code>.
</p>
</td></tr>

<tr><td><code id="Yules_+3A_log">log</code>, <code id="Yules_+3A_lower.tail">lower.tail</code>, <code id="Yules_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">pnorm</a></code>
or <code><a href="stats.html#topic+Normal">qnorm</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+yulesimon">yulesimon</a></code>, the <span class="pkg">VGAM</span> family function
for estimating the parameter,
for the formula of the probability density function
and other details.
</p>


<h3>Value</h3>

<p><code>dyules</code> gives the density,
<code>pyules</code> gives the distribution function,
<code>qyules</code> gives the quantile function, and
<code>ryules</code> generates random deviates.
</p>


<h3>Note</h3>

<p>Numerical problems may occur with
<code>qyules()</code> when <code>p</code> is very close to 1.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+yulesimon">yulesimon</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dyules(1:20, 2.1)
ryules(20, 2.1)

round(1000 * dyules(1:8, 2))
table(ryules(1000, 2))

## Not run:  x &lt;- 0:6
plot(x, dyules(x, shape = 2.2), type = "h", las = 1, col = "blue")

## End(Not run)</code></pre>

<hr>
<h2 id='yulesimon'> Yule-Simon Family Function </h2><span id='topic+yulesimon'></span>

<h3>Description</h3>

<p>Estimating the shape parameter of the Yule-Simon distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yulesimon(lshape = "loglink", ishape = NULL, nsimEIM = 200,
          zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yulesimon_+3A_lshape">lshape</code></td>
<td>

<p>Link function for the shape parameter,
called
<code class="reqn">\rho</code> below.
See <code><a href="#topic+Links">Links</a></code> for more choices and
for general information.
</p>
</td></tr>
<tr><td><code id="yulesimon_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial value for the (positive) parameter.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
The default is to obtain an initial value internally.
Use this argument
if the default fails.
</p>
</td></tr>
<tr><td><code id="yulesimon_+3A_nsimeim">nsimEIM</code>, <code id="yulesimon_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function is
</p>
<p style="text-align: center;"><code class="reqn">f(y;\rho) = \rho*beta(y,\rho+1),</code>
</p>

<p>where the parameter <code class="reqn">\rho&gt;0</code>,
<code class="reqn">beta</code> is the <code><a href="base.html#topic+beta">beta</a></code> function,
and <code class="reqn">y=1,2,\ldots</code>.
The function <code><a href="#topic+dyules">dyules</a></code> computes this
probability function.
The mean of <code class="reqn">Y</code>, which is returned as fitted values, is
<code class="reqn">\rho/(\rho-1)</code>
provided <code class="reqn">\rho &gt; 1</code>.
The variance of <code class="reqn">Y</code> is
<code class="reqn">\rho^2/((\rho-1)^2 (\rho-2))</code>
provided <code class="reqn">\rho &gt; 2</code>.
</p>
<p>The distribution was named after
Udny Yule and Herbert A. Simon.
Simon originally called it the Yule distribution.
This family function can handle multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Simon, H. A. (1955).
On a class of skew distribution functions.
<em>Biometrika</em>,
<b>42</b>,
425&ndash;440.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ryules">ryules</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ydata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
ydata &lt;- transform(ydata, y = ryules(nn, shape = exp(1.5 - x2)))
with(ydata, table(y))
fit &lt;- vglm(y ~ x2, yulesimon, data = ydata, trace = TRUE)
coef(fit, matrix = TRUE)
summary(fit)
</code></pre>

<hr>
<h2 id='Zabinom'> Zero-Altered Binomial Distribution </h2><span id='topic+Zabinom'></span><span id='topic+dzabinom'></span><span id='topic+pzabinom'></span><span id='topic+qzabinom'></span><span id='topic+rzabinom'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-altered binomial distribution with
parameter <code>pobs0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzabinom(x, size, prob, pobs0 = 0, log = FALSE)
pzabinom(q, size, prob, pobs0 = 0)
qzabinom(p, size, prob, pobs0 = 0)
rzabinom(n, size, prob, pobs0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zabinom_+3A_x">x</code>, <code id="Zabinom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zabinom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zabinom_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.
</p>
</td></tr>
<tr><td><code id="Zabinom_+3A_size">size</code>, <code id="Zabinom_+3A_prob">prob</code>, <code id="Zabinom_+3A_log">log</code></td>
<td>

<p>Parameters from the ordinary binomial distribution
(see <code><a href="stats.html#topic+Binomial">dbinom</a></code>).
</p>
</td></tr>
<tr><td><code id="Zabinom_+3A_pobs0">pobs0</code></td>
<td>

<p>Probability of (an observed) zero, called <code class="reqn">pobs0</code>.
The default value of <code>pobs0 = 0</code> corresponds
to the response having a positive binomial distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code>pobs0</code>, else a positive binomial(size, prob) distribution.
</p>


<h3>Value</h3>

<p><code>dzabinom</code> gives the density and
<code>pzabinom</code> gives the distribution function,
<code>qzabinom</code> gives the quantile function, and
<code>rzabinom</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pobs0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zibinomial">zibinomial</a></code>,
<code><a href="#topic+Gaitdbinom">Gaitdbinom</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>size &lt;- 10; prob &lt;- 0.15; pobs0 &lt;- 0.05; x &lt;- (-1):7
dzabinom(x, size = size, prob = prob, pobs0 = pobs0)
table(rzabinom(100, size = size, prob = prob, pobs0 = pobs0))

## Not run:  x &lt;- 0:10
barplot(rbind(dzabinom(x, size = size, prob = prob, pobs0 = pobs0),
                dbinom(x, size = size, prob = prob)),
  beside = TRUE, col = c("blue", "orange"), cex.main = 0.7, las = 1,
  ylab = "Probability", names.arg = as.character(x),
  main = paste("ZAB(size = ", size, ", prob = ", prob, ", pobs0 = ", pobs0,
               ") [blue] vs",  " Binom(size = ", size, ", prob = ", prob,
               ") [orange] densities", sep = "")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zabinomial'> Zero-Altered Binomial Distribution </h2><span id='topic+zabinomial'></span><span id='topic+zabinomialff'></span>

<h3>Description</h3>

<p>Fits a zero-altered binomial distribution based on
a conditional model involving a Bernoulli distribution and a
positive-binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zabinomial(lpobs0 = "logitlink", lprob = "logitlink",
     type.fitted = c("mean", "prob", "pobs0"),
     ipobs0 = NULL, iprob = NULL, imethod = 1, zero = NULL)
zabinomialff(lprob = "logitlink", lonempobs0 = "logitlink",
     type.fitted = c("mean", "prob", "pobs0", "onempobs0"),
     iprob = NULL, ionempobs0 = NULL, imethod = 1, zero = "onempobs0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zabinomial_+3A_lprob">lprob</code></td>
<td>

<p>Parameter link function applied to the probability parameter
of the binomial distribution.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zabinomial_+3A_lpobs0">lpobs0</code></td>
<td>

<p>Link function for the parameter <code class="reqn">p_0</code>, called <code>pobs0</code> here.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zabinomial_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zabinomial_+3A_iprob">iprob</code>, <code id="zabinomial_+3A_ipobs0">ipobs0</code></td>
<td>

<p>See
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="zabinomial_+3A_lonempobs0">lonempobs0</code>, <code id="zabinomial_+3A_ionempobs0">ionempobs0</code></td>
<td>

<p>Corresponding argument  for the other parameterization.
See details below.
</p>
</td></tr>
<tr><td><code id="zabinomial_+3A_imethod">imethod</code>, <code id="zabinomial_+3A_zero">zero</code></td>
<td>

<p>See
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response <code class="reqn">Y</code> is zero with probability <code class="reqn">p_0</code>,
else <code class="reqn">Y</code> has a positive-binomial distribution with
probability <code class="reqn">1-p_0</code>.  Thus <code class="reqn">0 &lt; p_0 &lt; 1</code>,
which may be modelled as a function of the covariates.
The zero-altered binomial distribution differs from the
zero-inflated binomial distribution in that the former
has zeros coming from one source, whereas the latter
has zeros coming from the binomial distribution too. The
zero-inflated binomial distribution is implemented in
<code><a href="#topic+zibinomial">zibinomial</a></code>.
Some people call the zero-altered binomial a <em>hurdle</em> model.
</p>
<p>The input is currently a vector or one-column matrix.
By default, the two linear/additive
predictors for <code>zabinomial()</code>
are <code class="reqn">(logit(p_0), \log(p))^T</code>.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zabinomialff()</code> has a few
changes compared to <code>zabinomial()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
binomial probability comes first;
(ii)  argument <code>onempobs0</code> is now 1 minus the probability of an observed 0,
i.e., the probability of the positive binomial distribution,
i.e., <code>onempobs0</code> is <code>1-pobs0</code>;
(iii)  argument <code>zero</code> has a new default so that the <code>onempobs0</code>
is intercept-only by default.
Now <code>zabinomialff()</code> is generally recommended over
<code>zabinomial()</code>.
Both functions implement Fisher scoring and neither can handle
multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>The <code>fitted.values</code> slot of the fitted object,
which should be extracted by the generic function <code>fitted</code>, returns
the mean <code class="reqn">\mu</code> (default) which is given by
</p>
<p style="text-align: center;"><code class="reqn">\mu = (1-p_0) \mu_{b} / [1 - (1 - \mu_{b})^N]</code>
</p>

<p>where <code class="reqn">\mu_{b}</code> is the usual binomial mean.
If <code>type.fitted = "pobs0"</code> then <code class="reqn">p_0</code> is returned.
</p>


<h3>Note</h3>

<p>The response should be a two-column matrix of counts,
with first column giving the number of successes.
</p>
<p>Note this family function allows <code class="reqn">p_0</code> to be modelled as
functions of the covariates by having <code>zero = NULL</code>.
It is a conditional model, not a mixture model.
</p>
<p>These family functions effectively combine
<code><a href="#topic+posbinomial">posbinomial</a></code> and <code><a href="#topic+binomialff">binomialff</a></code> into
one family function.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+dzabinom">dzabinom</a></code>,
<code><a href="#topic+zibinomial">zibinomial</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="stats.html#topic+Binomial">dbinom</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
zdata &lt;- transform(zdata, size  = 10,
                          prob  = logitlink(-2 + 3*x2, inverse = TRUE),
                          pobs0 = logitlink(-1 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata,
                   y1 = rzabinom(nn, size = size, prob = prob, pobs0 = pobs0))
with(zdata, table(y1))

zfit &lt;- vglm(cbind(y1, size - y1) ~ x2, zabinomial(zero = NULL),
             data = zdata, trace = TRUE)
coef(zfit, matrix = TRUE)
head(fitted(zfit))
head(predict(zfit))
summary(zfit)
</code></pre>

<hr>
<h2 id='Zageom'> Zero-Altered Geometric Distribution </h2><span id='topic+Zageom'></span><span id='topic+dzageom'></span><span id='topic+pzageom'></span><span id='topic+qzageom'></span><span id='topic+rzageom'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-altered geometric distribution with
parameter <code>pobs0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzageom(x, prob, pobs0 = 0, log = FALSE)
pzageom(q, prob, pobs0 = 0)
qzageom(p, prob, pobs0 = 0)
rzageom(n, prob, pobs0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zageom_+3A_x">x</code>, <code id="Zageom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zageom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zageom_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required.
</p>
</td></tr>
<tr><td><code id="Zageom_+3A_prob">prob</code>, <code id="Zageom_+3A_log">log</code></td>
<td>

<p>Parameters from the ordinary geometric distribution
(see <code><a href="stats.html#topic+Geometric">dgeom</a></code>).
</p>
</td></tr>
<tr><td><code id="Zageom_+3A_pobs0">pobs0</code></td>
<td>

<p>Probability of (an observed) zero, called <code class="reqn">pobs0</code>.
The default value of <code>pobs0 = 0</code> corresponds
to the response having a positive geometric distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code>pobs0</code>, else a positive geometric(prob) distribution.
</p>


<h3>Value</h3>

<p><code>dzageom</code> gives the density and
<code>pzageom</code> gives the distribution function,
<code>qzageom</code> gives the quantile function, and
<code>rzageom</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pobs0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zageometric">zageometric</a></code>,
<code><a href="#topic+zigeometric">zigeometric</a></code>,
<code><a href="#topic+rposgeom">rposgeom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prob &lt;- 0.35; pobs0 &lt;- 0.05; x &lt;- (-1):7
dzageom(x, prob = prob, pobs0 = pobs0)
table(rzageom(100, prob = prob, pobs0 = pobs0))

## Not run:  x &lt;- 0:10
barplot(rbind(dzageom(x, prob = prob, pobs0 = pobs0),
                dgeom(x, prob = prob)), las = 1,
        beside = TRUE, col = c("blue", "orange"), cex.main = 0.7,
        ylab = "Probability", names.arg = as.character(x),
        main = paste("ZAG(prob = ", prob, ", pobs0 = ", pobs0,
                   ") [blue] vs",  " Geometric(prob = ", prob,
                   ") [orange] densities", sep = "")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zageometric'> Zero-Altered Geometric Distribution </h2><span id='topic+zageometric'></span><span id='topic+zageometricff'></span>

<h3>Description</h3>

<p>Fits a zero-altered geometric distribution based on
a conditional model involving a Bernoulli distribution and a
positive-geometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zageometric(lpobs0 = "logitlink", lprob = "logitlink",
     type.fitted = c("mean", "prob", "pobs0", "onempobs0"),
     imethod = 1, ipobs0 = NULL, iprob = NULL, zero = NULL)
zageometricff(lprob = "logitlink", lonempobs0 = "logitlink",
     type.fitted = c("mean", "prob", "pobs0", "onempobs0"),
     imethod = 1, iprob = NULL, ionempobs0 = NULL, zero = "onempobs0")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zageometric_+3A_lpobs0">lpobs0</code></td>
<td>

<p>Link function for the parameter <code class="reqn">p_0</code> or <code class="reqn">\phi</code>,
called <code>pobs0</code> or <code>phi</code> here.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zageometric_+3A_lprob">lprob</code></td>
<td>

<p>Parameter link function applied to the probability of success,
called <code>prob</code>
or <code class="reqn">p</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zageometric_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for information.
</p>
</td></tr>





<tr><td><code id="zageometric_+3A_ipobs0">ipobs0</code>, <code id="zageometric_+3A_iprob">iprob</code></td>
<td>

<p>Optional initial values for the parameters.
If given, they must be in range.
For multi-column responses, these are recycled sideways.
</p>
</td></tr>
<tr><td><code id="zageometric_+3A_lonempobs0">lonempobs0</code>, <code id="zageometric_+3A_ionempobs0">ionempobs0</code></td>
<td>

<p>Corresponding argument  for the other parameterization.
See details below.
</p>
</td></tr>
<tr><td><code id="zageometric_+3A_zero">zero</code>, <code id="zageometric_+3A_imethod">imethod</code></td>
<td>

<p>See
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response <code class="reqn">Y</code> is zero with probability <code class="reqn">p_0</code>,
or <code class="reqn">Y</code> has a positive-geometric distribution with
probability <code class="reqn">1-p_0</code>.  Thus <code class="reqn">0 &lt; p_0 &lt; 1</code>,
which is modelled as a function of the covariates.  The zero-altered
geometric distribution differs from the zero-inflated
geometric distribution in that the former has zeros coming from one
source, whereas the latter has zeros coming from the geometric
distribution too. The zero-inflated geometric distribution
is implemented in the <span class="pkg">VGAM</span> package.  Some people
call the zero-altered geometric a <em>hurdle</em> model.
</p>
<p>The input can be a matrix (multiple responses).
By default, the two linear/additive predictors
of <code>zageometric</code>
are <code class="reqn">(logit(\phi), logit(p))^T</code>.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zageometricff()</code> has a few
changes compared to <code>zageometric()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
geometric probability comes first;
(ii)  argument <code>onempobs0</code> is now 1 minus the probability of an observed 0,
i.e., the probability of the positive geometric distribution,
i.e., <code>onempobs0</code> is <code>1-pobs0</code>;
(iii) argument <code>zero</code> has a new default so that the <code>pobs0</code>
is intercept-only by default.
Now <code>zageometricff()</code> is generally recommended over
<code>zageometric()</code>.
Both functions implement Fisher scoring and can handle
multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>The <code>fitted.values</code> slot of the fitted object,
which should be extracted by the generic function <code>fitted</code>, returns
the mean <code class="reqn">\mu</code> (default) which is given by
</p>
<p style="text-align: center;"><code class="reqn">\mu = (1-\phi) / p.</code>
</p>

<p>If <code>type.fitted = "pobs0"</code> then <code class="reqn">p_0</code> is returned.
</p>


<h3>Warning </h3>

<p>Convergence for this <span class="pkg">VGAM</span> family function seems to depend quite
strongly on providing good initial values.
</p>
<p>Inference obtained from <code>summary.vglm</code> and <code>summary.vgam</code>
may or may not be correct.  In particular, the p-values, standard errors
and degrees of freedom may need adjustment. Use simulation on artificial
data to check that these are reasonable.
</p>


<h3>Note</h3>

<p>Note this family function allows <code class="reqn">p_0</code> to be modelled as
functions of the covariates. It is a conditional model, not a mixture
model.
</p>
<p>This family function effectively combines
<code><a href="#topic+binomialff">binomialff</a></code> and
<code>posgeometric()</code> and <code><a href="#topic+geometric">geometric</a></code> into
one family function.
However, <code>posgeometric()</code> is not written because it
is trivially related to <code><a href="#topic+geometric">geometric</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+dzageom">dzageom</a></code>,
<code><a href="#topic+geometric">geometric</a></code>,
<code><a href="#topic+zigeometric">zigeometric</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="stats.html#topic+Geometric">dgeom</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
zdata &lt;- transform(zdata, pobs0 = logitlink(-1 + 2*x2, inverse = TRUE),
                          prob  = logitlink(-2 + 3*x2, inverse = TRUE))
zdata &lt;- transform(zdata, y1 = rzageom(nn, prob = prob, pobs0 = pobs0),
                          y2 = rzageom(nn, prob = prob, pobs0 = pobs0))
with(zdata, table(y1))

fit &lt;- vglm(cbind(y1, y2) ~ x2, zageometric, data = zdata, trace = TRUE)
coef(fit, matrix = TRUE)
head(fitted(fit))
head(predict(fit))
summary(fit)
</code></pre>

<hr>
<h2 id='Zanegbin'> Zero-Altered Negative Binomial Distribution </h2><span id='topic+Zanegbin'></span><span id='topic+dzanegbin'></span><span id='topic+pzanegbin'></span><span id='topic+qzanegbin'></span><span id='topic+rzanegbin'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-altered negative binomial distribution
with parameter <code>pobs0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzanegbin(x, size, munb, pobs0 = 0, log = FALSE)
pzanegbin(q, size, munb, pobs0 = 0)
qzanegbin(p, size, munb, pobs0 = 0)
rzanegbin(n, size, munb, pobs0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zanegbin_+3A_x">x</code>, <code id="Zanegbin_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zanegbin_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zanegbin_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required. </p>
</td></tr>
<tr><td><code id="Zanegbin_+3A_size">size</code>, <code id="Zanegbin_+3A_munb">munb</code>, <code id="Zanegbin_+3A_log">log</code></td>
<td>

<p>Parameters from the ordinary negative binomial distribution
(see <code><a href="stats.html#topic+NegBinomial">dnbinom</a></code>).
Some arguments have been renamed slightly.
</p>

</td></tr>
<tr><td><code id="Zanegbin_+3A_pobs0">pobs0</code></td>
<td>

<p>Probability of zero, called <code class="reqn">pobs0</code>.
The default value of <code>pobs0 = 0</code> corresponds
to the response having a positive negative binomial distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with
probability <code>pobs0</code>, else a positive negative
binomial(<code class="reqn">\mu_{nb}</code>, size) distribution.
</p>


<h3>Value</h3>

<p><code>dzanegbin</code> gives the density and
<code>pzanegbin</code> gives the distribution function,
<code>qzanegbin</code> gives the quantile function, and
<code>rzanegbin</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pobs0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
<code><a href="#topic+zanegbinomial">zanegbinomial</a></code>.
</p>




<h3>Examples</h3>

<pre><code class='language-R'>munb &lt;- 3; size &lt;- 4; pobs0 &lt;- 0.3; x &lt;- (-1):7
dzanegbin(x, munb = munb, size = size, pobs0 = pobs0)
table(rzanegbin(100, munb = munb, size = size, pobs0 = pobs0))

## Not run:  x &lt;- 0:10
barplot(rbind(dzanegbin(x, munb = munb, size = size, pobs0 = pobs0),
                dnbinom(x, mu   = munb, size = size)),
        beside = TRUE, col = c("blue", "green"), cex.main = 0.7,
        ylab = "Probability", names.arg = as.character(x), las = 1,
        main = paste0("ZANB(munb = ", munb, ", size = ", size,",
               pobs0 = ", pobs0,
               ") [blue] vs",  " NB(mu = ", munb, ", size = ", size,
               ") [green] densities")) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zanegbinomial'> Zero-Altered Negative Binomial Distribution </h2><span id='topic+zanegbinomial'></span><span id='topic+zanegbinomialff'></span>

<h3>Description</h3>

<p>Fits a zero-altered negative binomial distribution based on
a conditional model involving a binomial distribution and a
positive-negative binomial distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zanegbinomial(zero = "size", type.fitted = c("mean", "munb", "pobs0"),
              mds.min = 1e-3, nsimEIM = 500, cutoff.prob = 0.999,
              eps.trig = 1e-7, max.support = 4000, max.chunk.MB = 30,
              lpobs0 = "logitlink", lmunb = "loglink", lsize = "loglink",
              imethod = 1, ipobs0 = NULL,
              imunb = NULL, iprobs.y = NULL, gprobs.y = (0:9)/10,
              isize = NULL, gsize.mux = exp(c(-30, -20, -15, -10, -6:3)))
zanegbinomialff(lmunb = "loglink", lsize = "loglink", lonempobs0 = "logitlink",
                type.fitted = c("mean", "munb", "pobs0", "onempobs0"),
                isize = NULL, ionempobs0 = NULL, zero = c("size",
                "onempobs0"), mds.min = 1e-3, iprobs.y = NULL, gprobs.y = (0:9)/10,
                cutoff.prob = 0.999, eps.trig = 1e-7, max.support = 4000,
                max.chunk.MB = 30, gsize.mux = exp(c(-30, -20, -15, -10, -6:3)),
                imethod = 1, imunb = NULL,
                nsimEIM = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zanegbinomial_+3A_lpobs0">lpobs0</code></td>
<td>

<p>Link function for the parameter <code class="reqn">p_0</code>, called <code>pobs0</code> here.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_lmunb">lmunb</code></td>
<td>

<p>Link function applied to the <code>munb</code> parameter, which is the mean
<code class="reqn">\mu_{nb}</code> of an ordinary negative binomial distribution.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_lsize">lsize</code></td>
<td>

<p>Parameter link function applied to the reciprocal of the dispersion
parameter, called <code>k</code>. That is, as <code>k</code> increases, the
variance of the response decreases.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_lonempobs0">lonempobs0</code>, <code id="zanegbinomial_+3A_ionempobs0">ionempobs0</code></td>
<td>

<p>Corresponding argument  for the other parameterization.
See details below.
</p>
</td></tr>





<tr><td><code id="zanegbinomial_+3A_ipobs0">ipobs0</code>, <code id="zanegbinomial_+3A_imunb">imunb</code>, <code id="zanegbinomial_+3A_isize">isize</code></td>
<td>

<p>Optional initial values for <code class="reqn">p_0</code> and <code>munb</code>
and <code>k</code>.
If given then it is okay to give one value
for each response/species by inputting a vector whose length
is the number of columns of the response matrix.
</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_zero">zero</code></td>
<td>

<p>Specifies which of the three linear predictors are
modelled as intercept-only.
All parameters can be modelled as a
function of the explanatory variables by setting <code>zero = NULL</code>
(not recommended).
A negative value means that the value is recycled, e.g.,
setting <code class="reqn">-3</code> means all <code>k</code> are intercept-only
for <code>zanegbinomial</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>






</td></tr>
<tr><td><code id="zanegbinomial_+3A_nsimeim">nsimEIM</code>, <code id="zanegbinomial_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>




<tr><td><code id="zanegbinomial_+3A_iprobs.y">iprobs.y</code>, <code id="zanegbinomial_+3A_gsize.mux">gsize.mux</code>, <code id="zanegbinomial_+3A_gprobs.y">gprobs.y</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>.

</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_cutoff.prob">cutoff.prob</code>, <code id="zanegbinomial_+3A_eps.trig">eps.trig</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>.

</p>
</td></tr>
<tr><td><code id="zanegbinomial_+3A_mds.min">mds.min</code>, <code id="zanegbinomial_+3A_max.support">max.support</code>, <code id="zanegbinomial_+3A_max.chunk.mb">max.chunk.MB</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The response <code class="reqn">Y</code> is zero with probability <code class="reqn">p_0</code>,
or <code class="reqn">Y</code> has a positive-negative binomial distribution with
probability <code class="reqn">1-p_0</code>.  Thus <code class="reqn">0 &lt; p_0 &lt; 1</code>,
which is modelled as a function of the covariates.  The zero-altered
negative binomial distribution differs from the zero-inflated negative
binomial distribution in that the former has zeros coming from one
source, whereas the latter has zeros coming from the negative binomial
distribution too.  The zero-inflated negative binomial distribution
is implemented in the <span class="pkg">VGAM</span> package.  Some people
call the zero-altered negative binomial a <em>hurdle</em> model.
</p>
<p>For one response/species, by default, the three linear/additive
predictors
for <code>zanegbinomial()</code>
are <code class="reqn">(logit(p_0), \log(\mu_{nb}), \log(k))^T</code>.  This vector is recycled for multiple species.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zanegbinomialff()</code> has a few
changes compared to <code>zanegbinomial()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
negative binomial mean comes first;
(ii)  argument <code>onempobs0</code> is now 1 minus the probability of an observed 0,
i.e., the probability of the positive negative binomial distribution,
i.e., <code>onempobs0</code> is <code>1-pobs0</code>;
(iii) argument <code>zero</code> has a new default so that the <code>pobs0</code>
is intercept-only by default.
Now <code>zanegbinomialff()</code> is generally recommended over
<code>zanegbinomial()</code>.
Both functions implement Fisher scoring and can handle
multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>The <code>fitted.values</code> slot of the fitted object,
which should be extracted by the generic function <code>fitted</code>, returns
the mean <code class="reqn">\mu</code> (default) which is given by
</p>
<p style="text-align: center;"><code class="reqn">\mu = (1-p_0) \mu_{nb} / [1 - (k/(k+\mu_{nb}))^k].</code>
</p>

<p>If <code>type.fitted = "pobs0"</code> then <code class="reqn">p_0</code> is returned.
</p>


<h3>Warning </h3>

<p>This family function is fragile; it inherits the same difficulties as
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>.
Convergence for this <span class="pkg">VGAM</span> family function seems to depend quite
strongly on providing good initial values.
</p>
<p>This <span class="pkg">VGAM</span> family function is computationally expensive
and usually runs slowly;
setting <code>trace = TRUE</code> is useful for monitoring convergence.
</p>
<p>Inference obtained from <code>summary.vglm</code> and <code>summary.vgam</code>
may or may not be correct.  In particular, the p-values, standard errors
and degrees of freedom may need adjustment. Use simulation on artificial
data to check that these are reasonable.
</p>


<h3>Note</h3>

<p>Note this family function allows <code class="reqn">p_0</code> to be modelled as
functions of the covariates provided <code>zero</code> is set correctly.
It is a conditional model, not a mixture model.
Simulated Fisher scoring is the algorithm.
</p>
<p>This family function effectively combines
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code> and <code><a href="#topic+binomialff">binomialff</a></code> into
one family function.
</p>
<p>This family function can handle multiple responses, e.g., more
than one species.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Welsh, A. H., Cunningham, R. B., Donnelly, C. F. and Lindenmayer,
D. B. (1996).
Modelling the abundances of rare species: statistical models
for counts with extra zeros.
<em>Ecological Modelling</em>,
<b>88</b>,
297&ndash;308.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models with two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>,
<code><a href="#topic+Gaitdnbinom">Gaitdnbinom</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+zinegbinomial">zinegbinomial</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="stats.html#topic+NegBinomial">dnbinom</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>





<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
zdata &lt;- data.frame(x2 = runif(nn &lt;- 2000))
zdata &lt;- transform(zdata, pobs0 = logitlink(-1 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata,
         y1 = rzanegbin(nn, munb = exp(0+2*x2), size = exp(1), pobs0 = pobs0),
         y2 = rzanegbin(nn, munb = exp(1+2*x2), size = exp(1), pobs0 = pobs0))
with(zdata, table(y1))
with(zdata, table(y2))

fit &lt;- vglm(cbind(y1, y2) ~ x2, zanegbinomial, data = zdata, trace = TRUE)
coef(fit, matrix = TRUE)
head(fitted(fit))
head(predict(fit))

## End(Not run)
</code></pre>

<hr>
<h2 id='Zapois'> Zero-Altered Poisson Distribution </h2><span id='topic+Zapois'></span><span id='topic+dzapois'></span><span id='topic+pzapois'></span><span id='topic+qzapois'></span><span id='topic+rzapois'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-altered Poisson distribution with
parameter <code>pobs0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzapois(x, lambda, pobs0 = 0, log = FALSE)
pzapois(q, lambda, pobs0 = 0)
qzapois(p, lambda, pobs0 = 0)
rzapois(n, lambda, pobs0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zapois_+3A_x">x</code>, <code id="Zapois_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zapois_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zapois_+3A_n">n</code></td>
<td>
<p>number of observations.
If <code>length(n) &gt; 1</code> then the length is taken to be the
number required. </p>
</td></tr>
<tr><td><code id="Zapois_+3A_lambda">lambda</code></td>
<td>
<p> Vector of positive means. </p>
</td></tr>
<tr><td><code id="Zapois_+3A_pobs0">pobs0</code></td>
<td>

<p>Probability of zero, called <code class="reqn">pobs0</code>.
The default value of <code>pobs0 = 0</code> corresponds
to the response having a positive Poisson distribution.
</p>
</td></tr>
<tr><td><code id="Zapois_+3A_log">log</code></td>
<td>
<p> Logical. Return the logarithm of the answer? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code>pobs0</code>, else a positive
<code class="reqn">Poisson(\lambda)</code>.
</p>


<h3>Value</h3>

<p><code>dzapois</code> gives the density,
<code>pzapois</code> gives the distribution function,
<code>qzapois</code> gives the quantile function, and
<code>rzapois</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pobs0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zapoisson">zapoisson</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+dzipois">dzipois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda &lt;- 3; pobs0 &lt;- 0.2; x &lt;- (-1):7
(ii &lt;- dzapois(x, lambda, pobs0))
max(abs(cumsum(ii) - pzapois(x, lambda, pobs0)))  # Should be 0
table(rzapois(100, lambda, pobs0))
table(qzapois(runif(100), lambda, pobs0))
round(dzapois(0:10, lambda, pobs0) * 100)  # Should be similar

## Not run:  x &lt;- 0:10
barplot(rbind(dzapois(x, lambda, pobs0), dpois(x, lambda)),
        beside = TRUE, col = c("blue", "green"), las = 1,
        main = paste0("ZAP(", lambda, ", pobs0 = ", pobs0, ") [blue]",
                      "vs Poisson(", lambda, ") [green] densities"),
        names.arg = as.character(x), ylab = "Probability") 
## End(Not run)
</code></pre>

<hr>
<h2 id='zapoisson'> Zero-Altered Poisson Distribution </h2><span id='topic+zapoisson'></span><span id='topic+zapoissonff'></span>

<h3>Description</h3>

<p>Fits a zero-altered Poisson distribution based on a conditional
model involving a Bernoulli distribution
and a positive-Poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zapoisson(lpobs0 = "logitlink", llambda = "loglink", type.fitted =
    c("mean", "lambda", "pobs0", "onempobs0"), imethod = 1,
    ipobs0 = NULL, ilambda = NULL, ishrinkage = 0.95, probs.y = 0.35,
    zero = NULL)
zapoissonff(llambda = "loglink", lonempobs0 = "logitlink", type.fitted =
    c("mean", "lambda", "pobs0", "onempobs0"), imethod = 1,
    ilambda = NULL, ionempobs0 = NULL, ishrinkage = 0.95,
    probs.y = 0.35, zero = "onempobs0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zapoisson_+3A_lpobs0">lpobs0</code></td>
<td>

<p>Link function for the parameter <code class="reqn">p_0</code>, called
<code>pobs0</code> here.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zapoisson_+3A_llambda">llambda</code></td>
<td>

<p>Link function for the usual <code class="reqn">\lambda</code> parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zapoisson_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zapoisson_+3A_lonempobs0">lonempobs0</code></td>
<td>

<p>Corresponding argument  for the other parameterization.
See details below.
</p>
</td></tr>





<tr><td><code id="zapoisson_+3A_imethod">imethod</code>, <code id="zapoisson_+3A_ipobs0">ipobs0</code>, <code id="zapoisson_+3A_ionempobs0">ionempobs0</code>, <code id="zapoisson_+3A_ilambda">ilambda</code>, <code id="zapoisson_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zapoisson_+3A_probs.y">probs.y</code>, <code id="zapoisson_+3A_zero">zero</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>











</td></tr>
</table>


<h3>Details</h3>

<p>The response <code class="reqn">Y</code> is zero with probability <code class="reqn">p_0</code>,
else <code class="reqn">Y</code> has a positive-Poisson(<code class="reqn">\lambda)</code>
distribution with probability <code class="reqn">1-p_0</code>.  Thus <code class="reqn">0
  &lt; p_0 &lt; 1</code>, which is modelled as a function of
the covariates.  The zero-altered Poisson distribution differs
from the zero-inflated Poisson distribution in that the former
has zeros coming from one source, whereas the latter has zeros
coming from the Poisson distribution too. Some people call the
zero-altered Poisson a <em>hurdle</em> model.
</p>
<p>For one response/species, by default, the two linear/additive
predictors for <code>zapoisson()</code>
are <code class="reqn">(logit(p_0), \log(\lambda))^T</code>.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zapoissonff()</code> has a few
changes compared to <code>zapoisson()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
Poisson mean comes first;
(ii)  argument <code>onempobs0</code> is now 1 minus the probability of an observed 0,
i.e., the probability of the positive Poisson distribution,
i.e., <code>onempobs0</code> is <code>1-pobs0</code>;
(iii) argument <code>zero</code> has a new default so that the <code>onempobs0</code>
is intercept-only by default.
Now <code>zapoissonff()</code> is generally recommended over
<code>zapoisson()</code>.
Both functions implement Fisher scoring and can handle
multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>The <code>fitted.values</code> slot of the fitted object,
which should be extracted by the generic function <code>fitted</code>,
returns the mean <code class="reqn">\mu</code> (default) which is given by
</p>
<p style="text-align: center;"><code class="reqn">\mu = (1-p_0)  \lambda / [1 - \exp(-\lambda)].</code>
</p>

<p>If <code>type.fitted = "pobs0"</code> then <code class="reqn">p_0</code> is returned.
</p>


<h3>Note</h3>

<p>There are subtle differences between this family function and
<code><a href="#topic+zipoisson">zipoisson</a></code> and <code><a href="VGAMdata.html#topic+yip88">yip88</a></code>.
In particular, <code><a href="#topic+zipoisson">zipoisson</a></code> is a
<em>mixture</em> model whereas <code>zapoisson()</code> and <code><a href="VGAMdata.html#topic+yip88">yip88</a></code>
are <em>conditional</em> models.
</p>
<p>Note this family function allows <code class="reqn">p_0</code> to be modelled
as functions of the covariates.



</p>
<p>This family function effectively combines <code><a href="#topic+pospoisson">pospoisson</a></code>
and <code><a href="#topic+binomialff">binomialff</a></code> into one family function.
This family function can handle multiple responses,
e.g., more than one species.
</p>
<p>It is recommended that <code><a href="#topic+Gaitdpois">Gaitdpois</a></code> be used, e.g.,
<code>rgaitdpois(nn, lambda, pobs.mlm = pobs0, a.mlm = 0)</code>
instead of
<code>rzapois(nn, lambda, pobs0 = pobs0)</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Welsh, A. H., Cunningham, R. B., Donnelly, C. F. and
Lindenmayer, D. B. (1996).
Modelling the abundances of rare species: statistical models
for counts with extra zeros.
<em>Ecological Modelling</em>,
<b>88</b>,
297&ndash;308.
</p>
<p>Angers, J-F. and Biswas, A. (2003).
A Bayesian analysis of zero-inflated generalized Poisson model.
<em>Computational Statistics &amp; Data Analysis</em>,
<b>42</b>, 37&ndash;46.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models with two linear
predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>





<h3>See Also</h3>

<p><code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="#topic+rzapois">rzapois</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+pospoisson">pospoisson</a></code>,
<code><a href="#topic+posnegbinomial">posnegbinomial</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
zdata &lt;- transform(zdata, pobs0  = logitlink( -1 + 1*x2, inverse = TRUE),
                          lambda = loglink(-0.5 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata, y = rgaitdpois(nn, lambda, pobs.mlm = pobs0,
                                        a.mlm = 0))

with(zdata, table(y))
fit &lt;- vglm(y ~ x2, zapoisson, data = zdata, trace = TRUE)
fit &lt;- vglm(y ~ x2, zapoisson, data = zdata, trace = TRUE, crit = "coef")
head(fitted(fit))
head(predict(fit))
head(predict(fit, untransform = TRUE))
coef(fit, matrix = TRUE)
summary(fit)

# Another example ------------------------------
# Data from Angers and Biswas (2003)
abdata &lt;- data.frame(y = 0:7, w = c(182, 41, 12, 2, 2, 0, 0, 1))
abdata &lt;- subset(abdata, w &gt; 0)
Abdata &lt;- data.frame(yy = with(abdata, rep(y, w)))
fit3 &lt;- vglm(yy ~ 1, zapoisson, data = Abdata, trace = TRUE, crit = "coef")
coef(fit3, matrix = TRUE)
Coef(fit3)  # Estimate lambda (they get 0.6997 with SE 0.1520)
head(fitted(fit3), 1)
with(Abdata, mean(yy))  # Compare this with fitted(fit3)
</code></pre>

<hr>
<h2 id='zero'> The zero Argument in VGAM Family Functions </h2><span id='topic+zero'></span>

<h3>Description</h3>

<p>The <code>zero</code> argument allows users to conveniently
model certain linear/additive predictors as intercept-only.
</p>


<h3>Details</h3>

<p>Often a certain parameter needs to be modelled simply while other
parameters in the model may be more complex, for example, the
<code class="reqn">\lambda</code> parameter in LMS-Box-Cox quantile regression
should be modelled more simply compared to its <code class="reqn">\mu</code> parameter.
Another example is the <code class="reqn">\xi</code> parameter in a GEV distribution
which is should be modelled simpler than its <code class="reqn">\mu</code> parameter.
Using the <code>zero</code> argument allows this to be fitted conveniently
without having to input all the constraint matrices explicitly.
</p>
<p>The <code>zero</code> argument can be assigned an integer vector from the
set {<code>1:M</code>} where <code>M</code> is the number of linear/additive
predictors. Full details about constraint matrices can be found in
the references.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>


<h3>Value</h3>

<p>Nothing is returned.
It is simply a convenient argument for constraining
certain linear/additive predictors to be an intercept only.
</p>


<h3>Warning </h3>

<p>The use of other arguments may conflict with the <code>zero</code>
argument. For example, using <code>constraints</code> to input constraint
matrices may conflict with the <code>zero</code> argument.
Another example is the argument <code>parallel</code>.
In general users
should not assume any particular order of precedence when
there is potential conflict of definition.
Currently no checking for consistency is made.
</p>
<p>The argument <code>zero</code> may be renamed in the future to
something better.
</p>


<h3>Side Effects</h3>

<p>The argument creates the appropriate constraint matrices
internally.
</p>


<h3>Note</h3>

<p>In all <span class="pkg">VGAM</span> family functions <code>zero = NULL</code> means
none of the linear/additive predictors are modelled as
intercepts-only.
Almost all <span class="pkg">VGAM</span> family function have <code>zero = NULL</code>
as the default, but there are some exceptions, e.g.,
<code><a href="#topic+binom2.or">binom2.or</a></code>.
</p>
<p>Typing something like <code>coef(fit, matrix = TRUE)</code> is a useful
way to ensure that the <code>zero</code> argument has worked as expected.
</p>


<h3>Author(s)</h3>

<p>T. W. Yee </p>


<h3>References</h3>

<p>Yee, T. W. and Wild, C. J. (1996).
Vector generalized additive models.
<em>Journal of the Royal Statistical Society, Series B, Methodological</em>,
<b>58</b>, 481&ndash;493.
</p>
<p>Yee, T. W. and Hastie, T. J. (2003).
Reduced-rank vector generalized linear models.
<em>Statistical Modelling</em>,
<b>3</b>, 15&ndash;41.
</p>



<h3>See Also</h3>

<p><code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
<code><a href="#topic+constraints">constraints</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>args(multinomial)
args(binom2.or)
args(gpd)

#LMS quantile regression example
fit &lt;- vglm(BMI ~ sm.bs(age, df = 4), lms.bcg(zero = c(1, 3)),
            data = bmi.nz, trace = TRUE)
coef(fit, matrix = TRUE)
</code></pre>

<hr>
<h2 id='zeta'> Riemann's (and the Hurwitz) Zeta Function, With Derivatives </h2><span id='topic+zeta'></span>

<h3>Description</h3>

<p>Computes Riemann's zeta function and its first two derivatives.
Also can compute the Hurwitz zeta function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeta(x, deriv = 0, shift = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zeta_+3A_x">x</code></td>
<td>

<p>A complex-valued vector/matrix whose real values must be
<code class="reqn">\geq 1</code>. Otherwise, <code>x</code> may be real.
It is called <code class="reqn">s</code> below.
If <code>deriv</code> is 1 or 2 then <code>x</code> must be real and positive.
</p>
</td></tr>
<tr><td><code id="zeta_+3A_deriv">deriv</code></td>
<td>

<p>An integer equalling 0 or 1 or 2, which is the order of the derivative.
The default means it is computed ordinarily.
</p>
</td></tr>
<tr><td><code id="zeta_+3A_shift">shift</code></td>
<td>

<p>Positive and numeric, called <code class="reqn">A</code> below.
Allows for the Hurwitz zeta to be returned.
The default corresponds to the Riemann formula.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (Riemann) formula for real <code class="reqn">s</code> is
</p>
<p style="text-align: center;"><code class="reqn">\sum_{n=1}^{\infty} 1 / n^s.</code>
</p>

<p>While the usual definition involves an infinite series that
converges when the real part of the argument is <code class="reqn">&gt; 1</code>,
more efficient methods have been devised to compute the
value. In particular, this function uses Euler-Maclaurin
summation. Theoretically, the zeta function can be computed
over the whole complex plane because of analytic continuation.
</p>
<p>The (Riemann) formula used here for analytic continuation is
</p>
<p style="text-align: center;"><code class="reqn">\zeta(s) = 2^s \pi^{s-1} \sin(\pi s/2) \Gamma(1-s) \zeta(1-s).</code>
</p>

<p>This is actually one of several formulas, but this one was discovered
by Riemann himself and is called the <em>functional equation</em>.
</p>
<p>The Hurwitz zeta function for real <code class="reqn">s &gt; 0</code> is
</p>
<p style="text-align: center;"><code class="reqn">\sum_{n=0}^{\infty} 1 / (A + n)^s.</code>
</p>

<p>where <code class="reqn">0 &lt; A</code> is known here as the <code>shift</code>.
Since <code class="reqn">A=1</code> by default, this function will therefore return
Riemann's zeta function by default.
Currently derivatives are unavailable.
</p>


<h3>Value</h3>

<p>The default is a vector/matrix of computed values of Riemann's zeta
function.
If <code>shift</code> contains values not equal to 1, then this is
Hurwitz's zeta function.
</p>



<h3>Warning</h3>

<p>This function has not been fully tested, especially the derivatives.
In particular, analytic continuation does not work here for
complex <code>x</code> with <code>Re(x)&lt;1</code> because currently the
<code><a href="base.html#topic+Special">gamma</a></code> function does not handle complex
arguments.
</p>


<h3>Note</h3>

<p>Estimation of the parameter of the zeta distribution can
be achieved with <code><a href="#topic+zetaff">zetaff</a></code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee, with the help of Garry J. Tee. </p>


<h3>References</h3>

<p>Riemann, B. (1859).
Ueber die Anzahl der Primzahlen unter einer gegebenen Grosse.
<em>Monatsberichte der Berliner Akademie, November 1859</em>.
</p>
<p>Edwards, H. M. (1974).
<em>Riemann's Zeta Function</em>.
Academic Press: New York.
</p>
<p>Markman, B. (1965).
The Riemann zeta function.
<em>BIT</em>,
<b>5</b>,
138&ndash;141.
</p>
<p>Abramowitz, M. and Stegun, I. A. (1972).
<em>Handbook of Mathematical Functions with Formulas, Graphs, and
Mathematical Tables</em>,
New York: Dover Publications Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="#topic+Zeta">Zeta</a></code>,
<code><a href="VGAMdata.html#topic+oazeta">oazeta</a></code>,
<code><a href="VGAMdata.html#topic+oizeta">oizeta</a></code>,
<code><a href="VGAMdata.html#topic+otzeta">otzeta</a></code>,
<code><a href="#topic+lerch">lerch</a></code>,
<code><a href="base.html#topic+Special">gamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zeta(2:10)

## Not run: 
curve(zeta, -13, 0.8, xlim = c(-12, 10), ylim = c(-1, 4), col = "orange",
      las = 1, main = expression({zeta}(x)))
curve(zeta, 1.2,  12, add = TRUE, col = "orange")
abline(v = 0, h = c(0, 1), lty = "dashed", col = "gray")

curve(zeta, -14, -0.4, col = "orange", main = expression({zeta}(x)))
abline(v = 0, h = 0, lty = "dashed", col = "gray")  # Close up plot

x &lt;- seq(0.04, 0.8, len = 100)  # Plot of the first derivative
plot(x, zeta(x, deriv = 1), type = "l", las = 1, col = "blue",
     xlim = c(0.04, 3), ylim = c(-6, 0), main = "zeta'(x)")
x &lt;- seq(1.2, 3, len = 100)
lines(x, zeta(x, deriv = 1), col = "blue")
abline(v = 0, h = 0, lty = "dashed", col = "gray") 
## End(Not run)

zeta(2) - pi^2 / 6     # Should be 0
zeta(4) - pi^4 / 90    # Should be 0
zeta(6) - pi^6 / 945   # Should be 0
zeta(8) - pi^8 / 9450  # Should be 0
zeta(0, deriv = 1) + 0.5 * log(2*pi)  # Should be 0
gamma0 &lt;-  0.5772156649
gamma1 &lt;- -0.07281584548
zeta(0, deriv = 2) -
  gamma1 + 0.5 * (log(2*pi))^2 + pi^2/24 - gamma0^2 / 2  # Should be 0
zeta(0.5, deriv = 1) + 3.92264613  # Should be 0
zeta(2.0, deriv = 1) + 0.93754825431  # Should be 0
</code></pre>

<hr>
<h2 id='Zeta'>The Zeta Distribution </h2><span id='topic+Zeta'></span><span id='topic+dzeta'></span><span id='topic+pzeta'></span><span id='topic+qzeta'></span><span id='topic+rzeta'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zeta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzeta(x, shape, log = FALSE)
pzeta(q, shape, lower.tail = TRUE)
qzeta(p, shape)
rzeta(n, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zeta_+3A_x">x</code>, <code id="Zeta_+3A_q">q</code>, <code id="Zeta_+3A_p">p</code>, <code id="Zeta_+3A_n">n</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+Poisson">Poisson</a></code>. </p>
</td></tr>
<tr><td><code id="Zeta_+3A_shape">shape</code></td>
<td>
<p> The positive shape parameter <code class="reqn">s</code>. </p>
</td></tr>
<tr><td><code id="Zeta_+3A_lower.tail">lower.tail</code>, <code id="Zeta_+3A_log">log</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">Normal</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The density function of the zeta distribution is given by
</p>
<p style="text-align: center;"><code class="reqn">y^{-s-1} / \zeta(s+1)</code>
</p>

<p>where <code class="reqn">s&gt;0</code>, <code class="reqn">y=1,2,\ldots</code>, and <code class="reqn">\zeta</code> is
Riemann's zeta function.
</p>


<h3>Value</h3>

<p><code>dzeta</code> gives the density,
<code>pzeta</code> gives the distribution function,
<code>qzeta</code> gives the quantile function, and
<code>rzeta</code> generates random deviates.
</p>


<h3>Note</h3>

<p><code>qzeta()</code> runs slower and slower as <code>shape</code> approaches
0 and <code>shape</code> approaches 1.  The <span class="pkg">VGAM</span> family function
<code><a href="#topic+zetaff">zetaff</a></code> estimates the shape parameter <code class="reqn">s</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Johnson N. L., Kotz S., and Balakrishnan N. (1993).
<em>Univariate Discrete Distributions</em>,
2nd ed.
New York: Wiley.
</p>








<h3>See Also</h3>

<p><code><a href="#topic+zeta">zeta</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="VGAMdata.html#topic+Oazeta">Oazeta</a></code>,
<code><a href="VGAMdata.html#topic+Oizeta">Oizeta</a></code>,
<code><a href="VGAMdata.html#topic+Otzeta">Otzeta</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dzeta(1:20, shape = 2)
myshape &lt;- 0.5
max(abs(pzeta(1:200, myshape) -
    cumsum(1/(1:200)^(1+myshape)) / zeta(myshape+1)))  # Should be 0

## Not run:  plot(1:6, dzeta(1:6, 2), type = "h", las = 1,
               col = "orange", ylab = "Probability",
 main = "zeta probability function; orange: shape = 2; blue: shape = 1")
points(0.10 + 1:6, dzeta(1:6, 1), type = "h", col = "blue") 
## End(Not run)
</code></pre>

<hr>
<h2 id='zetaff'> Zeta Distribution Family Function </h2><span id='topic+zetaff'></span>

<h3>Description</h3>

<p>Estimates the parameter of the zeta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zetaff(lshape = "loglink", ishape = NULL, gshape = 1 + exp(-seq(7)),
       zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zetaff_+3A_lshape">lshape</code>, <code id="zetaff_+3A_ishape">ishape</code>, <code id="zetaff_+3A_zero">zero</code></td>
<td>

<p>These arguments apply to the (positive) parameter <code class="reqn">p</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
Choosing <code><a href="#topic+loglog">loglog</a></code> constrains <code class="reqn">p&gt;1</code>, but
may fail if the maximum likelihood estimate is less than one.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zetaff_+3A_gshape">gshape</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this long tailed distribution
the response must be a positive integer.
The probability function for a response <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) = 1/[y^{p+1} \zeta(p+1)],\ \ \  p&gt;0,\ \ \  y=1,2,...</code>
</p>

<p>where <code class="reqn">\zeta</code> is Riemann's zeta function.
The parameter <code class="reqn">p</code> is positive, therefore a log link
is the default.
The mean of <code class="reqn">Y</code> is
<code class="reqn">\mu = \zeta(p) / \zeta(p+1)</code>
(provided <code class="reqn">p&gt;1</code>) and these are the fitted values.
The variance of <code class="reqn">Y</code> is
<code class="reqn">\zeta(p-1) / \zeta(p+1) - \mu^2</code>
provided <code class="reqn">p&gt;2</code>.
</p>
<p>It appears that good initial values are needed for successful
convergence. If convergence is not obtained, try several values
ranging from values near 0 to values about 10 or more.
</p>
<p>Multiple responses are handled.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>The <code><a href="#topic+zeta">zeta</a></code> function may be used to compute values
of the zeta function.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>pp.527&ndash; of Chapter 11 of
Johnson N. L., Kemp, A. W. and Kotz S. (2005).
<em>Univariate Discrete Distributions</em>,
3rd edition,
Hoboken, New Jersey: Wiley.
</p>
<p>Knight, K. (2000).
<em>Mathematical Statistics</em>.
Boca Raton, FL, USA: Chapman &amp; Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+zeta">zeta</a></code>,
<code><a href="#topic+Zeta">Zeta</a></code>,
<code><a href="#topic+gaitdzeta">gaitdzeta</a></code>,
<code><a href="VGAMdata.html#topic+oazeta">oazeta</a></code>,
<code><a href="VGAMdata.html#topic+oizeta">oizeta</a></code>,
<code><a href="VGAMdata.html#topic+otzeta">otzeta</a></code>,
<code><a href="#topic+diffzeta">diffzeta</a></code>,
<code><a href="#topic+hzeta">hzeta</a></code>,
<code><a href="#topic+zipf">zipf</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(y = 1:5, w =  c(63, 14, 5, 1, 2))  # Knight, p.304
fit &lt;- vglm(y ~ 1, zetaff, data = zdata, trace = TRUE, weight = w, crit = "c")
(phat &lt;- Coef(fit))  # 1.682557
with(zdata, cbind(round(dzeta(y, phat) * sum(w), 1), w))

with(zdata, weighted.mean(y, w))
fitted(fit, matrix = FALSE)
predict(fit)

# The following should be zero at the MLE:
with(zdata, mean(log(rep(y, w))) + zeta(1+phat, deriv = 1) / zeta(1+phat))
</code></pre>

<hr>
<h2 id='Zibinom'> Zero-Inflated Binomial Distribution </h2><span id='topic+Zibinom'></span><span id='topic+dzibinom'></span><span id='topic+pzibinom'></span><span id='topic+qzibinom'></span><span id='topic+rzibinom'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-inflated binomial distribution with
parameter <code>pstr0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzibinom(x, size, prob, pstr0 = 0, log = FALSE)
pzibinom(q, size, prob, pstr0 = 0)
qzibinom(p, size, prob, pstr0 = 0)
rzibinom(n, size, prob, pstr0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zibinom_+3A_x">x</code>, <code id="Zibinom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zibinom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zibinom_+3A_size">size</code></td>
<td>
<p>number of trials. It is the <code class="reqn">N</code> symbol in the formula
given in <code><a href="#topic+zibinomial">zibinomial</a></code>. </p>
</td></tr>
<tr><td><code id="Zibinom_+3A_prob">prob</code></td>
<td>
<p>probability of success on each trial. </p>
</td></tr>
<tr><td><code id="Zibinom_+3A_n">n</code></td>
<td>
<p> Same as in <code><a href="stats.html#topic+runif">runif</a></code>.  </p>
</td></tr>

<tr><td><code id="Zibinom_+3A_log">log</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+Binomial">pbinom</a></code>.</p>
</td></tr>
<tr><td><code id="Zibinom_+3A_pstr0">pstr0</code></td>
<td>

<p>Probability of a structural zero
(i.e., ignoring the binomial distribution),
called <code class="reqn">\phi</code>.
The default value of <code class="reqn">\phi=0</code> corresponds to
the response having an ordinary binomial distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code class="reqn">\phi</code>, 
and <code class="reqn">Binomial(size, prob)</code> with
probability <code class="reqn">1-\phi</code>. Thus
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =\phi + (1-\phi) P(W=0)</code>
</p>

<p>where <code class="reqn">W</code> is
distributed <code class="reqn">Binomial(size, prob)</code>.
</p>


<h3>Value</h3>

<p><code>dzibinom</code> gives the density,
<code>pzibinom</code> gives the distribution function,
<code>qzibinom</code> gives the quantile function, and
<code>rzibinom</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pstr0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>
<p>These functions actually allow for <em>zero-deflation</em>.
That is, the resulting probability of a zero count
is <em>less than</em> the nominal value of the parent
distribution.
See <code><a href="#topic+Zipois">Zipois</a></code> for more information.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zibinomial">zibinomial</a></code>,
<code><a href="#topic+Gaitdbinom">Gaitdbinom</a></code>,
<code><a href="stats.html#topic+Binomial">Binomial</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prob &lt;- 0.2; size &lt;- 10; pstr0 &lt;- 0.5
(ii &lt;- dzibinom(0:size, size, prob, pstr0 = pstr0))
max(abs(cumsum(ii) - pzibinom(0:size, size, prob, pstr0 = pstr0)))  # 0?
table(rzibinom(100, size, prob, pstr0 = pstr0))

table(qzibinom(runif(100), size, prob, pstr0 = pstr0))
round(dzibinom(0:10, size, prob, pstr0 = pstr0) * 100)  # Similar?

## Not run:  x &lt;- 0:size
barplot(rbind(dzibinom(x, size, prob, pstr0 = pstr0),
                dbinom(x, size, prob)),
    beside = TRUE, col = c("blue", "green"), ylab = "Probability",
    main = paste0("ZIB(", size, ", ", prob, ", pstr0 = ", pstr0, ")",
                 " (blue) vs Binomial(", size, ", ", prob, ") (green)"),
    names.arg = as.character(x), las = 1, lwd = 2) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zibinomial'> Zero-Inflated Binomial Distribution Family Function </h2><span id='topic+zibinomial'></span><span id='topic+zibinomialff'></span>

<h3>Description</h3>

<p>Fits a zero-inflated binomial distribution by maximum likelihood
estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zibinomial(lpstr0 = "logitlink", lprob = "logitlink",
           type.fitted = c("mean", "prob", "pobs0", "pstr0", "onempstr0"),
           ipstr0 = NULL, zero = NULL, multiple.responses = FALSE,
           imethod = 1)
zibinomialff(lprob = "logitlink", lonempstr0 = "logitlink",
             type.fitted = c("mean", "prob", "pobs0", "pstr0", "onempstr0"),
             ionempstr0 = NULL, zero = "onempstr0",
             multiple.responses = FALSE, imethod = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zibinomial_+3A_lpstr0">lpstr0</code>, <code id="zibinomial_+3A_lprob">lprob</code></td>
<td>

<p>Link functions for the parameter <code class="reqn">\phi</code>
and the usual binomial probability <code class="reqn">\mu</code> parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices.
For the zero-<em>deflated</em> model see below.
</p>
</td></tr>





<tr><td><code id="zibinomial_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> and <code><a href="#topic+fittedvlm">fittedvlm</a></code>.
</p>
</td></tr>
<tr><td><code id="zibinomial_+3A_ipstr0">ipstr0</code></td>
<td>

<p>Optional initial values for <code class="reqn">\phi</code>, whose values must lie
between 0 and 1. The default is to compute an initial value internally.
If a vector then recyling is used.
</p>
</td></tr>
<tr><td><code id="zibinomial_+3A_lonempstr0">lonempstr0</code>, <code id="zibinomial_+3A_ionempstr0">ionempstr0</code></td>
<td>

<p>Corresponding arguments for the other parameterization.
See details below.
</p>
</td></tr>








<tr><td><code id="zibinomial_+3A_multiple.responses">multiple.responses</code></td>
<td>

<p>Logical. Currently it must be <code>FALSE</code> to mean the
function does not handle multiple responses. This
is to remain compatible with the same argument in
<code><a href="#topic+binomialff">binomialff</a></code>.
</p>
</td></tr>
<tr><td><code id="zibinomial_+3A_zero">zero</code>, <code id="zibinomial_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
Argument <code>zero</code> changed its default value for version 0.9-2.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are based on
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =  \phi + (1-\phi) (1-\mu)^N,</code>
</p>

<p>for <code class="reqn">y=0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) = (1-\phi) {N \choose Ny} \mu^{Ny} (1-\mu)^{N(1-y)}.</code>
</p>

<p>for <code class="reqn">y=1/N,2/N,\ldots,1</code>. That is, the response is a sample
proportion out of <code class="reqn">N</code> trials, and the argument <code>size</code> in
<code><a href="#topic+rzibinom">rzibinom</a></code> is <code class="reqn">N</code> here.
The parameter <code class="reqn">\phi</code> is the probability of a structural zero,
and it satisfies <code class="reqn">0 &lt; \phi &lt; 1</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">E(Y)=(1-\phi) \mu</code>
and these are returned as the fitted values
by default.
By default, the two linear/additive predictors
for <code>zibinomial()</code>
are <code class="reqn">(logit(\phi), logit(\mu))^T</code>.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zibinomialff()</code> has a few
changes compared to <code>zibinomial()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
binomial probability comes first;
(ii)  argument <code>onempstr0</code> is now 1 minus
the probability of a structural zero, i.e.,
the probability of the parent (binomial) component,
i.e., <code>onempstr0</code> is <code>1-pstr0</code>;
(iii) argument <code>zero</code> has a new default so that the <code>onempstr0</code>
is intercept-only by default.
Now <code>zibinomialff()</code> is generally recommended over
<code>zibinomial()</code>.
Both functions implement Fisher scoring.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Numerical problems can occur.
Half-stepping is not uncommon.
If failure to converge occurs, make use of the argument <code>ipstr0</code>
or <code>ionempstr0</code>,
or <code>imethod</code>.
</p>


<h3>Note</h3>

<p>The response variable must have one of the formats described by
<code><a href="#topic+binomialff">binomialff</a></code>, e.g., a factor or two column matrix or a
vector of sample proportions with the <code>weights</code> argument
specifying the values of <code class="reqn">N</code>.
</p>
<p>To work well, one needs large values of <code class="reqn">N</code>
and <code class="reqn">\mu&gt;0</code>, i.e.,
the larger <code class="reqn">N</code> and <code class="reqn">\mu</code> are, the better.
If <code class="reqn">N = 1</code> then the model is unidentifiable since
the number of parameters is excessive.
</p>
<p>Setting <code>stepsize = 0.5</code>, say, may aid convergence.
</p>







<p>Estimated probabilities of a structural zero and an
observed zero are returned, as in <code><a href="#topic+zipoisson">zipoisson</a></code>.
</p>
<p>The zero-<em>deflated</em> binomial distribution might
be fitted by setting <code>lpstr0 = identitylink</code>, albeit,
not entirely reliably. See <code><a href="#topic+zipoisson">zipoisson</a></code>
for information that can be applied here. Else
try the zero-altered binomial distribution (see
<code><a href="#topic+zabinomial">zabinomial</a></code>).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Welsh, A. H., Lindenmayer, D. B. and Donnelly, C. F. (2013).
Fitting and interpreting occupancy models.
<em>PLOS One</em>,
<b>8</b>,
1&ndash;21.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rzibinom">rzibinom</a></code>,
<code><a href="#topic+binomialff">binomialff</a></code>,
<code><a href="#topic+posbinomial">posbinomial</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="stats.html#topic+Binomial">Binomial</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>size &lt;- 10  # Number of trials; N in the notation above
nn &lt;- 200
zdata &lt;- data.frame(pstr0 = logitlink( 0, inverse = TRUE),  # 0.50
                    mubin = logitlink(-1, inverse = TRUE),  # Mean of usual binomial
                    sv    = rep(size, length = nn))
zdata &lt;- transform(zdata,
                   y = rzibinom(nn, size = sv, prob = mubin, pstr0 = pstr0))
with(zdata, table(y))
fit &lt;- vglm(cbind(y, sv - y) ~ 1, zibinomialff, data = zdata, trace = TRUE)
fit &lt;- vglm(cbind(y, sv - y) ~ 1, zibinomialff, data = zdata, trace = TRUE,
            stepsize = 0.5)

coef(fit, matrix = TRUE)
Coef(fit)  # Useful for intercept-only models
head(fitted(fit, type = "pobs0"))  # Estimate of P(Y = 0)
head(fitted(fit))
with(zdata, mean(y))  # Compare this with fitted(fit)
summary(fit)
</code></pre>

<hr>
<h2 id='Zigeom'> Zero-Inflated Geometric Distribution </h2><span id='topic+Zigeom'></span><span id='topic+dzigeom'></span><span id='topic+pzigeom'></span><span id='topic+qzigeom'></span><span id='topic+rzigeom'></span>

<h3>Description</h3>

<p>Density, and random generation
for the zero-inflated geometric distribution with parameter
<code>pstr0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzigeom(x, prob, pstr0 = 0, log = FALSE)
pzigeom(q, prob, pstr0 = 0)
qzigeom(p, prob, pstr0 = 0)
rzigeom(n, prob, pstr0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zigeom_+3A_x">x</code>, <code id="Zigeom_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zigeom_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zigeom_+3A_prob">prob</code></td>
<td>
<p>see <code><a href="stats.html#topic+dgeom">dgeom</a></code>.</p>
</td></tr>
<tr><td><code id="Zigeom_+3A_n">n</code></td>
<td>
<p> Same as in <code><a href="stats.html#topic+runif">runif</a></code>.  </p>
</td></tr>
<tr><td><code id="Zigeom_+3A_pstr0">pstr0</code></td>
<td>

<p>Probability of structural zero (ignoring the geometric
distribution), called <code class="reqn">\phi</code>. The default value
corresponds to the response having an ordinary geometric
distribution.
</p>
</td></tr>
<tr><td><code id="Zigeom_+3A_log">log</code></td>
<td>
<p> Logical. Return the logarithm of the answer? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code class="reqn">\phi</code>, and <code class="reqn">geometric(prob)</code> with
probability <code class="reqn">1-\phi</code>. Thus
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =\phi + (1-\phi) P(W=0)</code>
</p>

<p>where <code class="reqn">W</code> is distributed <code class="reqn">geometric(prob)</code>.
</p>


<h3>Value</h3>

<p><code>dzigeom</code> gives the density,
<code>pzigeom</code> gives the distribution function,
<code>qzigeom</code> gives the quantile function, and
<code>rzigeom</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pstr0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>
<p>These functions actually allow for <em>zero-deflation</em>.
That is, the resulting probability of a zero count
is <em>less than</em> the nominal value of the parent
distribution.
See <code><a href="#topic+Zipois">Zipois</a></code> for more information.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zigeometric">zigeometric</a></code>,
<code><a href="stats.html#topic+dgeom">dgeom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prob &lt;- 0.5; pstr0 &lt;- 0.2; x &lt;- (-1):20
(ii &lt;- dzigeom(x, prob, pstr0))
max(abs(cumsum(ii) - pzigeom(x, prob, pstr0)))  # Should be 0
table(rzigeom(1000, prob, pstr0))

## Not run:  x &lt;- 0:10
barplot(rbind(dzigeom(x, prob, pstr0), dgeom(x, prob)),
   beside = TRUE, col = c("blue","orange"),
   ylab = "P[Y = y]", xlab = "y", las = 1,
   main = paste0("zigeometric(", prob, ", pstr0 = ", pstr0,
                 ") (blue) vs", " geometric(", prob, ") (orange)"),
   names.arg = as.character(x)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zigeometric'> Zero-Inflated Geometric Distribution Family Function </h2><span id='topic+zigeometric'></span><span id='topic+zigeometricff'></span>

<h3>Description</h3>

<p>Fits a zero-inflated geometric distribution by maximum likelihood
estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zigeometric(lpstr0  = "logitlink", lprob = "logitlink",
            type.fitted = c("mean", "prob", "pobs0", "pstr0", "onempstr0"),
            ipstr0  = NULL, iprob = NULL,
            imethod = 1, bias.red = 0.5, zero = NULL)
zigeometricff(lprob = "logitlink", lonempstr0 = "logitlink",
              type.fitted = c("mean", "prob", "pobs0", "pstr0", "onempstr0"),
              iprob = NULL, ionempstr0 = NULL,
              imethod = 1, bias.red = 0.5, zero = "onempstr0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zigeometric_+3A_lpstr0">lpstr0</code>, <code id="zigeometric_+3A_lprob">lprob</code></td>
<td>

<p>Link functions for the parameters
<code class="reqn">\phi</code>
and
<code class="reqn">p</code> (<code>prob</code>).
The usual geometric probability parameter is the latter.
The probability of a structural zero is the former.
See <code><a href="#topic+Links">Links</a></code> for more choices.
For the zero-<em>deflated</em> model see below.
</p>
</td></tr>




<tr><td><code id="zigeometric_+3A_lonempstr0">lonempstr0</code>, <code id="zigeometric_+3A_ionempstr0">ionempstr0</code></td>
<td>

<p>Corresponding arguments for the other parameterization.
See details below.
</p>
</td></tr>
<tr><td><code id="zigeometric_+3A_bias.red">bias.red</code></td>
<td>

<p>A constant used in the initialization process of <code>pstr0</code>.
It should lie between 0 and 1, with 1 having no effect.
</p>
</td></tr>
<tr><td><code id="zigeometric_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zigeometric_+3A_ipstr0">ipstr0</code>, <code id="zigeometric_+3A_iprob">iprob</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zigeometric_+3A_zero">zero</code>, <code id="zigeometric_+3A_imethod">imethod</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>zigeometric()</code> is based on
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =  \phi + (1-\phi) p,</code>
</p>

<p>for <code class="reqn">y=0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) = (1-\phi) p (1 - p)^{y}.</code>
</p>

<p>for <code class="reqn">y=1,2,\ldots</code>.
The parameter <code class="reqn">\phi</code> satisfies <code class="reqn">0 &lt; \phi &lt; 1</code>.  The mean of <code class="reqn">Y</code> is <code class="reqn">E(Y)=(1-\phi) p / (1-p)</code> and these are returned as the fitted values
by default.
By default, the two linear/additive predictors
are <code class="reqn">(logit(\phi), logit(p))^T</code>.
Multiple responses are handled.
</p>

<p>Estimated probabilities of a structural zero and an
observed zero can be returned, as in <code><a href="#topic+zipoisson">zipoisson</a></code>;
see <code><a href="#topic+fittedvlm">fittedvlm</a></code> for information.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zigeometricff()</code> has a few
changes compared to <code>zigeometric()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
geometric probability comes first;
(ii)  argument <code>onempstr0</code> is now 1 minus
the probability of a structural zero, i.e.,
the probability of the parent (geometric) component,
i.e., <code>onempstr0</code> is <code>1-pstr0</code>;
(iii) argument <code>zero</code> has a new default so that the <code>onempstr0</code>
is intercept-only  by default.
Now <code>zigeometricff()</code> is generally recommended over
<code>zigeometric()</code>.
Both functions implement Fisher scoring and can handle
multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>



<p>The zero-<em>deflated</em> geometric distribution might
be fitted by setting <code>lpstr0 = identitylink</code>, albeit,
not entirely reliably. See <code><a href="#topic+zipoisson">zipoisson</a></code>
for information that can be applied here. Else
try the zero-altered geometric distribution (see
<code><a href="#topic+zageometric">zageometric</a></code>).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+rzigeom">rzigeom</a></code>,
<code><a href="#topic+geometric">geometric</a></code>,
<code><a href="#topic+zageometric">zageometric</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="stats.html#topic+rgeom">rgeom</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gdata &lt;- data.frame(x2 = runif(nn &lt;- 1000) - 0.5)
gdata &lt;- transform(gdata, x3 = runif(nn) - 0.5,
                          x4 = runif(nn) - 0.5)
gdata &lt;- transform(gdata, eta1 =  1.0 - 1.0 * x2 + 2.0 * x3,
                          eta2 = -1.0,
                          eta3 =  0.5)
gdata &lt;- transform(gdata, prob1 = logitlink(eta1, inverse = TRUE),
                          prob2 = logitlink(eta2, inverse = TRUE),
                          prob3 = logitlink(eta3, inverse = TRUE))
gdata &lt;- transform(gdata, y1 = rzigeom(nn, prob1, pstr0 = prob3),
                          y2 = rzigeom(nn, prob2, pstr0 = prob3),
                          y3 = rzigeom(nn, prob2, pstr0 = prob3))
with(gdata, table(y1))
with(gdata, table(y2))
with(gdata, table(y3))
head(gdata)

fit1 &lt;- vglm(y1 ~ x2 + x3 + x4, zigeometric(zero = 1), data = gdata, trace = TRUE)
coef(fit1, matrix = TRUE)
head(fitted(fit1, type = "pstr0"))

fit2 &lt;- vglm(cbind(y2, y3) ~ 1, zigeometric(zero = 1), data = gdata, trace = TRUE)
coef(fit2, matrix = TRUE)
summary(fit2)
</code></pre>

<hr>
<h2 id='Zinegbin'> Zero-Inflated Negative Binomial Distribution </h2><span id='topic+Zinegbin'></span><span id='topic+dzinegbin'></span><span id='topic+pzinegbin'></span><span id='topic+qzinegbin'></span><span id='topic+rzinegbin'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-inflated negative binomial distribution
with parameter <code>pstr0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzinegbin(x, size, prob = NULL, munb = NULL, pstr0 = 0, log = FALSE)
pzinegbin(q, size, prob = NULL, munb = NULL, pstr0 = 0)
qzinegbin(p, size, prob = NULL, munb = NULL, pstr0 = 0)
rzinegbin(n, size, prob = NULL, munb = NULL, pstr0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zinegbin_+3A_x">x</code>, <code id="Zinegbin_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zinegbin_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zinegbin_+3A_n">n</code></td>
<td>
<p> Same as in <code><a href="stats.html#topic+runif">runif</a></code>.  </p>
</td></tr>
<tr><td><code id="Zinegbin_+3A_size">size</code>, <code id="Zinegbin_+3A_prob">prob</code>, <code id="Zinegbin_+3A_munb">munb</code>, <code id="Zinegbin_+3A_log">log</code></td>
<td>

<p>Arguments matching <code><a href="stats.html#topic+NegBinomial">dnbinom</a></code>.
The argument <code>munb</code> corresponds to <code>mu</code> in
<code><a href="stats.html#topic+NegBinomial">dnbinom</a></code> and has been renamed
to emphasize the fact that it is the mean of the negative
binomial <em>component</em>.
</p>
</td></tr>
<tr><td><code id="Zinegbin_+3A_pstr0">pstr0</code></td>
<td>

<p>Probability of structural zero
(i.e., ignoring the negative binomial distribution),
called <code class="reqn">\phi</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code class="reqn">\phi</code>, and a negative binomial distribution with
probability <code class="reqn">1-\phi</code>. Thus
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =\phi + (1-\phi) P(W=0)</code>
</p>

<p>where <code class="reqn">W</code> is distributed as a negative binomial distribution
(see <code><a href="stats.html#topic+NegBinomial">rnbinom</a></code>.)
See <code><a href="#topic+negbinomial">negbinomial</a></code>, a <span class="pkg">VGAM</span> family
function, for the formula of the probability density
function and other details of the negative binomial
distribution.
</p>


<h3>Value</h3>

<p><code>dzinegbin</code> gives the density,
<code>pzinegbin</code> gives the distribution function,
<code>qzinegbin</code> gives the quantile function, and
<code>rzinegbin</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pstr0</code> is recycled to the required
length, and must have values which lie in the interval
<code class="reqn">[0,1]</code>.
</p>
<p>These functions actually allow for <em>zero-deflation</em>.
That is, the resulting probability of a zero count
is <em>less than</em> the nominal value of the parent
distribution.
See <code><a href="#topic+Zipois">Zipois</a></code> for more information.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zinegbinomial">zinegbinomial</a></code>,
<code><a href="stats.html#topic+NegBinomial">rnbinom</a></code>,
<code><a href="#topic+rzipois">rzipois</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>munb &lt;- 3; pstr0 &lt;- 0.2; size &lt;- k &lt;- 10; x &lt;- 0:10
(ii &lt;- dzinegbin(x, pstr0 = pstr0, mu = munb, size = k))
max(abs(cumsum(ii) - pzinegbin(x, pstr0 = pstr0, mu = munb, size = k)))
table(rzinegbin(100, pstr0 = pstr0, mu = munb, size = k))

table(qzinegbin(runif(1000), pstr0 = pstr0, mu = munb, size = k))
round(dzinegbin(x, pstr0 = pstr0, mu = munb, size = k) * 1000)  # Similar?

## Not run: barplot(rbind(dzinegbin(x, pstr0 = pstr0, mu = munb, size = k),
                dnbinom(x, mu = munb, size = k)), las = 1,
    beside = TRUE, col = c("blue", "green"), ylab = "Probability",
    main = paste("ZINB(mu = ", munb, ", k = ", k, ", pstr0 = ", pstr0,
                 ") (blue) vs NB(mu = ", munb,
                 ", size = ", k, ") (green)", sep = ""),
    names.arg = as.character(x)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zinegbinomial'> Zero-Inflated Negative Binomial Distribution Family Function </h2><span id='topic+zinegbinomial'></span><span id='topic+zinegbinomialff'></span>

<h3>Description</h3>

<p>Fits a zero-inflated negative binomial distribution by
full maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zinegbinomial(zero = "size",
              type.fitted = c("mean", "munb", "pobs0", "pstr0",
              "onempstr0"),
              mds.min = 1e-3, nsimEIM = 500, cutoff.prob = 0.999,
              eps.trig = 1e-7, max.support = 4000, max.chunk.MB = 30,
              lpstr0 = "logitlink", lmunb = "loglink", lsize = "loglink",
              imethod = 1, ipstr0 = NULL, imunb =  NULL,
              iprobs.y = NULL, isize = NULL,
              gprobs.y = (0:9)/10,
              gsize.mux = exp(c(-30, -20, -15, -10, -6:3)))
zinegbinomialff(lmunb = "loglink", lsize = "loglink", lonempstr0 = "logitlink",
                type.fitted = c("mean", "munb", "pobs0", "pstr0",
                "onempstr0"), imunb = NULL, isize = NULL, ionempstr0 =
                NULL, zero = c("size", "onempstr0"), imethod = 1,
                iprobs.y = NULL, cutoff.prob = 0.999,
                eps.trig = 1e-7,  max.support = 4000, max.chunk.MB = 30,
                gprobs.y = (0:9)/10, gsize.mux = exp((-12:6)/2),
                mds.min = 1e-3, nsimEIM = 500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zinegbinomial_+3A_lpstr0">lpstr0</code>, <code id="zinegbinomial_+3A_lmunb">lmunb</code>, <code id="zinegbinomial_+3A_lsize">lsize</code></td>
<td>

<p>Link functions for the parameters <code class="reqn">\phi</code>,
the mean and <code class="reqn">k</code>; see <code><a href="#topic+negbinomial">negbinomial</a></code> for details,
and <code><a href="#topic+Links">Links</a></code> for more choices.
For the zero-<em>deflated</em> model see below.
</p>
</td></tr>





<tr><td><code id="zinegbinomial_+3A_type.fitted">type.fitted</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_ipstr0">ipstr0</code>, <code id="zinegbinomial_+3A_isize">isize</code>, <code id="zinegbinomial_+3A_imunb">imunb</code></td>
<td>

<p>Optional initial values for <code class="reqn">\phi</code>
and <code class="reqn">k</code>
and <code class="reqn">\mu</code>.
The default is to compute an initial value internally for both.
If a vector then recycling is used.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_lonempstr0">lonempstr0</code>, <code id="zinegbinomial_+3A_ionempstr0">ionempstr0</code></td>
<td>

<p>Corresponding arguments for the other parameterization.
See details below.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> or <code>3</code> which
specifies the initialization method for the mean parameter.
If failure to converge occurs try another value.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_zero">zero</code></td>
<td>

<p>Specifies which linear/additive predictors are to be modelled
as intercept-only.  They can be such that their absolute values are
either 1 or 2 or 3.
The default is the <code class="reqn">\phi</code> and <code class="reqn">k</code> parameters
(both for each response).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_nsimeim">nsimEIM</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_iprobs.y">iprobs.y</code>, <code id="zinegbinomial_+3A_cutoff.prob">cutoff.prob</code>, <code id="zinegbinomial_+3A_max.support">max.support</code>, <code id="zinegbinomial_+3A_max.chunk.mb">max.chunk.MB</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code>
and/or <code><a href="#topic+posnegbinomial">posnegbinomial</a></code> for details.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_mds.min">mds.min</code>, <code id="zinegbinomial_+3A_eps.trig">eps.trig</code></td>
<td>

<p>See <code><a href="#topic+negbinomial">negbinomial</a></code> for details.
</p>
</td></tr>
<tr><td><code id="zinegbinomial_+3A_gprobs.y">gprobs.y</code>, <code id="zinegbinomial_+3A_gsize.mux">gsize.mux</code></td>
<td>

<p>These arguments relate to grid searching in the initialization process.
See <code><a href="#topic+negbinomial">negbinomial</a></code>
and/or <code><a href="#topic+posnegbinomial">posnegbinomial</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are based on
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =  \phi + (1-\phi) (k/(k+\mu))^k,</code>
</p>

<p>and for <code class="reqn">y=1,2,\ldots</code>,
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) =  (1-\phi) \, dnbinom(y, \mu, k).</code>
</p>

<p>The parameter <code class="reqn">\phi</code> satisfies <code class="reqn">0 &lt; \phi &lt; 1</code>.
The mean of <code class="reqn">Y</code> is <code class="reqn">(1-\phi) \mu</code>
(returned as the fitted values).
By default, the three linear/additive predictors
for <code>zinegbinomial()</code>
are <code class="reqn">(logit(\phi), \log(\mu), \log(k))^T</code>.
See <code><a href="#topic+negbinomial">negbinomial</a></code>, another <span class="pkg">VGAM</span> family function,
for the formula of the probability density function and other details
of the negative binomial distribution.
</p>
<p>Independent multiple responses are handled.
If so then arguments <code>ipstr0</code> and <code>isize</code> may be vectors
with length equal to the number of responses.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zinegbinomialff()</code> has a few
changes compared to <code>zinegbinomial()</code>.
These are:
(i)   the order of the linear/additive predictors is switched so the
NB mean comes first;
(ii)  <code>onempstr0</code> is now 1 minus the probability of a structural 0,
i.e., the probability of the parent (NB) component,
i.e., <code>onempstr0</code> is <code>1-pstr0</code>;
(iii) argument <code>zero</code> has a new default so that the <code>onempstr0</code>
is intercept-only by default.
Now <code>zinegbinomialff()</code> is generally recommended over
<code>zinegbinomial()</code>.
Both functions implement Fisher scoring and can handle
multiple responses.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>,
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>This model can be difficult to fit to data,
and this family function is fragile.
The model is especially difficult to fit reliably when
the estimated <code class="reqn">k</code> parameter is very large (so the model
approaches a zero-inflated Poisson distribution) or
much less than 1
(and gets more difficult as it approaches 0).
Numerical problems can also occur, e.g., when the probability of
a zero is actually less than, and not more than, the nominal
probability of zero.
Similarly, numerical problems can occur if there is little
or no 0-inflation, or when the sample size is small.
Half-stepping is not uncommon.
Successful convergence is sensitive to the initial values, therefore
if failure to converge occurs, try using combinations of arguments
<code>stepsize</code> (in <code><a href="#topic+vglm.control">vglm.control</a></code>),
<code>imethod</code>,
<code>imunb</code>,
<code>ipstr0</code>,
<code>isize</code>, and/or
<code>zero</code> if there are explanatory variables.
Else try fitting an ordinary <code><a href="#topic+negbinomial">negbinomial</a></code> model
or a <code><a href="#topic+zipoisson">zipoisson</a></code> model.
</p>



<p>This <span class="pkg">VGAM</span> family function can be computationally expensive
and can run slowly;
setting <code>trace = TRUE</code> is useful for monitoring convergence.
</p>






<h3>Note</h3>






<p>Estimated probabilities of a structural zero and an
observed zero can be returned, as in <code><a href="#topic+zipoisson">zipoisson</a></code>;
see <code><a href="#topic+fittedvlm">fittedvlm</a></code> for more information.
</p>
<p>If <code class="reqn">k</code> is large then the use of <span class="pkg">VGAM</span> family function
<code><a href="#topic+zipoisson">zipoisson</a></code> is probably preferable.
This follows because the Poisson is the limiting distribution of a
negative binomial as <code class="reqn">k</code> tends to infinity.
</p>
<p>The zero-<em>deflated</em> negative binomial distribution
might be fitted by setting <code>lpstr0 = identitylink</code>,
albeit, not entirely reliably. See <code><a href="#topic+zipoisson">zipoisson</a></code>
for information that can be applied here. Else try
the zero-altered negative binomial distribution (see
<code><a href="#topic+zanegbinomial">zanegbinomial</a></code>).
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdnbinomial">gaitdnbinomial</a></code>,
<code><a href="#topic+Zinegbin">Zinegbin</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="stats.html#topic+Poisson">rpois</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1
ndata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
ndata &lt;- transform(ndata, pstr0 = logitlink(-0.5 + 1 * x2, inverse = TRUE),
                          munb  =   exp( 3   + 1 * x2),
                          size  =   exp( 0   + 2 * x2))
ndata &lt;- transform(ndata,
                   y1 = rzinegbin(nn, mu = munb, size = size, pstr0 = pstr0))
with(ndata, table(y1)["0"] / sum(table(y1)))
nfit &lt;- vglm(y1 ~ x2, zinegbinomial(zero = NULL), data = ndata)
coef(nfit, matrix = TRUE)
summary(nfit)
head(cbind(fitted(nfit), with(ndata, (1 - pstr0) * munb)))
round(vcov(nfit), 3)


# Example 2: RR-ZINB could also be called a COZIVGLM-ZINB-2
ndata &lt;- data.frame(x2 = runif(nn &lt;- 2000))
ndata &lt;- transform(ndata, x3 = runif(nn))
ndata &lt;- transform(ndata, eta1 =          3   + 1   * x2 + 2 * x3)
ndata &lt;- transform(ndata, pstr0  = logitlink(-1.5 + 0.5 * eta1, inverse = TRUE),
                          munb = exp(eta1),
                          size = exp(4))
ndata &lt;- transform(ndata,
                   y1 = rzinegbin(nn, pstr0 = pstr0, mu = munb, size = size))
with(ndata, table(y1)["0"] / sum(table(y1)))
rrzinb &lt;- rrvglm(y1 ~ x2 + x3, zinegbinomial(zero = NULL), data = ndata,
                 Index.corner = 2, str0 = 3, trace = TRUE)
coef(rrzinb, matrix = TRUE)
Coef(rrzinb)

## End(Not run)
</code></pre>

<hr>
<h2 id='zipebcom'> Exchangeable Bivariate cloglog Odds-ratio Model From a
Zero-inflated Poisson Distribution </h2><span id='topic+zipebcom'></span>

<h3>Description</h3>

<p>Fits an exchangeable bivariate odds-ratio model to two binary
responses with a complementary log-log link.
The data are assumed to come from a zero-inflated Poisson distribution
that has been converted to presence/absence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zipebcom(lmu12 = "clogloglink", lphi12 = "logitlink", loratio = "loglink",
         imu12 = NULL, iphi12 = NULL, ioratio = NULL,
         zero = c("phi12", "oratio"), tol = 0.001, addRidge = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zipebcom_+3A_lmu12">lmu12</code>, <code id="zipebcom_+3A_imu12">imu12</code></td>
<td>

<p>Link function, extra argument and optional initial values for
the first (and second) marginal probabilities.
Argument <code>lmu12</code> should be left alone.
Argument <code>imu12</code> may be of length 2 (one element for each response).
</p>
</td></tr>
<tr><td><code id="zipebcom_+3A_lphi12">lphi12</code></td>
<td>

<p>Link function applied to the <code class="reqn">\phi</code> parameter of the
zero-inflated Poisson distribution (see <code><a href="#topic+zipoisson">zipoisson</a></code>).
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zipebcom_+3A_loratio">loratio</code></td>
<td>

<p>Link function applied to the odds ratio.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zipebcom_+3A_iphi12">iphi12</code>, <code id="zipebcom_+3A_ioratio">ioratio</code></td>
<td>

<p>Optional initial values for <code class="reqn">\phi</code> and the odds ratio.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more details.
In general, good initial values (especially for <code>iphi12</code>)
are often required, therefore use these
arguments if convergence failure occurs.
If inputted, the value of <code>iphi12</code> cannot be more than the sample
proportions of zeros in either response.
</p>
</td></tr>





<tr><td><code id="zipebcom_+3A_zero">zero</code></td>
<td>

<p>Which linear/additive predictor is modelled as an intercept only?
A <code>NULL</code> means none.
The default has both <code class="reqn">\phi</code> and the odds ratio as
not being modelled as a function of the explanatory variables (apart
from an intercept).
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zipebcom_+3A_tol">tol</code></td>
<td>

<p>Tolerance for testing independence.
Should be some small positive numerical value.
</p>
</td></tr>
<tr><td><code id="zipebcom_+3A_addridge">addRidge</code></td>
<td>

<p>Some small positive numerical value.
The first two diagonal elements of the working weight matrices are
multiplied by <code>1+addRidge</code> to make it diagonally dominant,
therefore positive-definite.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This <span class="pkg">VGAM</span> family function fits an exchangeable bivariate odds
ratio model (<code><a href="#topic+binom2.or">binom2.or</a></code>) with a <code><a href="#topic+clogloglink">clogloglink</a></code> link.
The data are assumed to come from a zero-inflated Poisson (ZIP) distribution
that has been converted to presence/absence.
Explicitly, the default model is
</p>
<p style="text-align: center;"><code class="reqn">cloglog[P(Y_j=1)/(1-\phi)] = \eta_1,\ \ \ j=1,2</code>
</p>

<p>for the (exchangeable) marginals, and
</p>
<p style="text-align: center;"><code class="reqn">logit[\phi] = \eta_2,</code>
</p>

<p>for the mixing parameter, and
</p>
<p style="text-align: center;"><code class="reqn">\log[P(Y_{00}=1) P(Y_{11}=1) / (P(Y_{01}=1) P(Y_{10}=1))] = \eta_3,</code>
</p>

<p>specifies the dependency between the two responses. Here, the responses
equal 1 for a success and a 0 for a failure, and the odds ratio is often
written <code class="reqn">\psi=p_{00}p_{11}/(p_{10}p_{01})</code>.
We have <code class="reqn">p_{10} = p_{01}</code> because of the exchangeability.
</p>
<p>The second linear/additive predictor models the <code class="reqn">\phi</code>
parameter (see <code><a href="#topic+zipoisson">zipoisson</a></code>).
The third linear/additive predictor is the same as <code><a href="#topic+binom2.or">binom2.or</a></code>,
viz., the log odds ratio.
</p>
<p>Suppose a dataset1 comes from a Poisson distribution that has been
converted to presence/absence, and that both marginal probabilities
are the same (exchangeable).
Then <code>binom2.or("clogloglink", exch=TRUE)</code> is appropriate.
Now suppose a dataset2 comes from a <em>zero-inflated</em> Poisson
distribution. The first linear/additive predictor of <code>zipebcom()</code>
applied to dataset2
is the same as that of
<code>binom2.or("clogloglink", exch=TRUE)</code>
applied to dataset1.
That is, the <code class="reqn">\phi</code> has been taken care
of by <code>zipebcom()</code> so that it is just like the simpler
<code><a href="#topic+binom2.or">binom2.or</a></code>.
</p>
<p>Note that, for <code class="reqn">\eta_1</code>,
<code>mu12 = prob12 / (1-phi12)</code> where <code>prob12</code> is the probability
of a 1 under the ZIP model.
Here, <code>mu12</code> correspond to <code>mu1</code> and <code>mu2</code> in the
<code><a href="#topic+binom2.or">binom2.or</a></code>-Poisson model.
</p>
<p>If <code class="reqn">\phi=0</code> then <code>zipebcom()</code> should be equivalent to
<code>binom2.or("clogloglink", exch=TRUE)</code>.
Full details are given in Yee and Dirnbock (2009).
</p>
<p>The leading <code class="reqn">2 \times 2</code> submatrix of the expected
information matrix (EIM) is of rank-1, not 2! This is due to the
fact that the parameters corresponding to the first two
linear/additive predictors are unidentifiable. The quick fix
around this problem is to use the <code>addRidge</code> adjustment.
The model is fitted by maximum likelihood estimation since the full
likelihood is specified. Fisher scoring is implemented.
</p>
<p>The default models <code class="reqn">\eta_2</code> and <code class="reqn">\eta_3</code> as
single parameters only, but this
can be circumvented by setting <code>zero=NULL</code> in order to model the
<code class="reqn">\phi</code> and odds ratio as a function of all the explanatory
variables.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as <code><a href="#topic+vglm">vglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>
<p>When fitted, the <code>fitted.values</code> slot of the object contains the
four joint probabilities, labelled as <code class="reqn">(Y_1,Y_2)</code> = (0,0),
(0,1), (1,0), (1,1), respectively.
These estimated probabilities should be extracted with the <code>fitted</code>
generic function.
</p>


<h3>Warning </h3>

<p>The fact that the EIM is not of full rank may mean the model is
naturally ill-conditioned.
Not sure whether there are any negative consequences wrt theory.
For now
it is certainly safer to fit <code><a href="#topic+binom2.or">binom2.or</a></code> to bivariate binary
responses.
</p>


<h3>Note</h3>

<p>The <code>"12"</code> in the argument names reinforce the user about the
exchangeability assumption.
The name of this <span class="pkg">VGAM</span> family function stands for
<em>zero-inflated Poisson exchangeable bivariate complementary
log-log odds-ratio model</em> or ZIP-EBCOM.
</p>
<p>See <code><a href="#topic+binom2.or">binom2.or</a></code> for details that are pertinent to this
<span class="pkg">VGAM</span> family function too.
Even better initial values are usually needed here.
</p>
<p>The <code>xij</code> (see <code><a href="#topic+vglm.control">vglm.control</a></code>) argument enables
environmental variables with different values at the two time points
to be entered into an exchangeable <code><a href="#topic+binom2.or">binom2.or</a></code> model.
See the author's webpage for sample code.
</p>


<h3>References</h3>

<p>Yee, T. W. and Dirnbock, T. (2009).
Models for analysing species' presence/absence data
at two time points.
Journal of Theoretical Biology, <b>259</b>(4), 684&ndash;694.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+binom2.or">binom2.or</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+clogloglink">clogloglink</a></code>,
<code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(x2 = seq(0, 1, len = (nsites &lt;- 2000)))
zdata &lt;- transform(zdata, eta1 =  -3 + 5 * x2,
                         phi1 = logitlink(-1, inverse = TRUE),
                         oratio = exp(2))
zdata &lt;- transform(zdata, mu12 = clogloglink(eta1, inverse = TRUE) * (1-phi1))
tmat &lt;-  with(zdata, rbinom2.or(nsites, mu1 = mu12, oratio = oratio, exch = TRUE))
zdata &lt;- transform(zdata, ybin1 = tmat[, 1], ybin2 = tmat[, 2])

with(zdata, table(ybin1, ybin2)) / nsites  # For interest only
## Not run: 
# Various plots of the data, for interest only
par(mfrow = c(2, 2))
plot(jitter(ybin1) ~ x2, data = zdata, col = "blue")

plot(jitter(ybin2) ~ jitter(ybin1), data = zdata, col = "blue")

plot(mu12 ~ x2, data = zdata, col = "blue", type = "l", ylim = 0:1,
     ylab = "Probability", main = "Marginal probability and phi")
with(zdata, abline(h = phi1[1], col = "red", lty = "dashed"))

tmat2 &lt;- with(zdata, dbinom2.or(mu1 = mu12, oratio = oratio, exch = TRUE))
with(zdata, matplot(x2, tmat2, col = 1:4, type = "l", ylim = 0:1,
     ylab = "Probability", main = "Joint probabilities")) 
## End(Not run)

# Now fit the model to the data.
fit &lt;- vglm(cbind(ybin1, ybin2) ~ x2, zipebcom, data = zdata, trace = TRUE)
coef(fit, matrix = TRUE)
summary(fit)
vcov(fit)
</code></pre>

<hr>
<h2 id='zipf'> Zipf Distribution Family Function </h2><span id='topic+zipf'></span>

<h3>Description</h3>

<p>Estimates the parameter of the Zipf distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zipf(N = NULL, lshape = "loglink", ishape = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zipf_+3A_n">N</code></td>
<td>

<p>Number of elements, an integer satisfying <code>1 &lt; N &lt; Inf</code>.
The default is to use the maximum value of the response.
If given, <code>N</code> must be no less that the largest response value.
If <code>N = Inf</code> and <code class="reqn">s&gt;1</code> then this is the zeta
distribution (use <code><a href="#topic+zetaff">zetaff</a></code> instead).
</p>
</td></tr>
<tr><td><code id="zipf_+3A_lshape">lshape</code></td>
<td>

<p>Parameter link function applied to the (positive) shape parameter <code class="reqn">s</code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zipf_+3A_ishape">ishape</code></td>
<td>

<p>Optional initial value for the parameter <code class="reqn">s</code>.
The default is to choose an initial value internally.
If converge failure occurs use this argument to input a value.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function for a response <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">P(Y=y) = y^{-s} / \sum_{i=1}^N i^{-s},\ \ s&gt;0,\ \ y=1,2,\ldots,N,</code>
</p>

<p>where <code class="reqn">s</code> is the exponent characterizing the distribution.
The mean of <code class="reqn">Y</code>, which are returned as the fitted values,
is <code class="reqn">\mu = H_{N,s-1} / H_{N,s}</code>
where <code class="reqn">H_{n,m}= \sum_{i=1}^n i^{-m}</code>
is the <code class="reqn">n</code>th generalized harmonic number.
</p>
<p>Zipf's law is an experimental law which is often applied
to the study of the frequency of words in a corpus of
natural language utterances. It states that the frequency
of any word is inversely proportional to its rank in the
frequency table. For example, <code>"the"</code> and <code>"of"</code>
are first two most common words, and Zipf's law states
that <code>"the"</code> is twice as common as <code>"of"</code>.
Many other natural phenomena conform to Zipf's law.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code> (see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions such as
<code><a href="#topic+vglm">vglm</a></code> and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Note</h3>

<p>Upon convergence, the <code>N</code> is stored as <code>@misc$N</code>.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>pp.526&ndash; of Chapter 11 of
Johnson N. L., Kemp, A. W. and Kotz S. (2005).
<em>Univariate Discrete Distributions</em>,
3rd edition,
Hoboken, New Jersey, USA: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dzipf">dzipf</a></code>,
<code><a href="#topic+zetaff">zetaff</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zdata &lt;- data.frame(y = 1:5, ofreq = c(63, 14, 5, 1, 2))
zfit &lt;- vglm(y ~ 1, zipf, data = zdata, trace = TRUE, weight = ofreq)
zfit &lt;- vglm(y ~ 1, zipf(lshape = "identitylink", ishape = 3.4), data = zdata,
            trace = TRUE, weight = ofreq, crit = "coef")
zfit@misc$N
(shape.hat &lt;- Coef(zfit))
with(zdata, weighted.mean(y, ofreq))
fitted(zfit, matrix = FALSE)
</code></pre>

<hr>
<h2 id='Zipf'>The Zipf Distribution</h2><span id='topic+Zipf'></span><span id='topic+dzipf'></span><span id='topic+pzipf'></span><span id='topic+qzipf'></span><span id='topic+rzipf'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Zipf distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzipf(x, N, shape, log = FALSE)
pzipf(q, N, shape, log.p = FALSE)
qzipf(p, N, shape)
rzipf(n, N, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zipf_+3A_x">x</code>, <code id="Zipf_+3A_q">q</code>, <code id="Zipf_+3A_p">p</code>, <code id="Zipf_+3A_n">n</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+Poisson">Poisson</a></code>. </p>
</td></tr>
<tr><td><code id="Zipf_+3A_n">N</code>, <code id="Zipf_+3A_shape">shape</code></td>
<td>

<p>the number of elements, and the exponent characterizing the
distribution.
See <code><a href="#topic+zipf">zipf</a></code> for more details.
</p>
</td></tr>
<tr><td><code id="Zipf_+3A_log">log</code>, <code id="Zipf_+3A_log.p">log.p</code></td>
<td>

<p>Same meaning as in <code><a href="stats.html#topic+Normal">Normal</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a finite version of the zeta distribution.
See <code><a href="#topic+zetaff">zetaff</a></code> for more details.
In general, these functions runs slower and slower as <code>N</code>
increases.
</p>


<h3>Value</h3>

<p><code>dzipf</code> gives the density,
<code>pzipf</code> gives the cumulative distribution function,
<code>qzipf</code> gives the quantile function, and
<code>rzipf</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zipf">zipf</a></code>,
<code><a href="#topic+Zipfmb">Zipfmb</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 10; shape &lt;- 0.5; y &lt;- 1:N
proby &lt;- dzipf(y, N = N, shape = shape)
## Not run:  plot(proby ~ y, type = "h", col = "blue",
   ylim = c(0, 0.2), ylab = "Probability", lwd = 2, las = 1,
   main = paste0("Zipf(N = ", N, ", shape = ", shape, ")")) 
## End(Not run)
sum(proby)  # Should be 1
max(abs(cumsum(proby) - pzipf(y, N = N, shape = shape)))  # 0?
</code></pre>

<hr>
<h2 id='Zipfmb'>The Zipf-Mandelbrot Distribution</h2><span id='topic+Zipfmb'></span><span id='topic+dzipfmb'></span><span id='topic+pzipfmb'></span><span id='topic+qzipfmb'></span><span id='topic+rzipfmb'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Mandelbrot distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzipfmb(x, shape, start = 1, log = FALSE)
pzipfmb(q, shape, start = 1, lower.tail = TRUE, log.p = FALSE)
qzipfmb(p, shape, start = 1)
rzipfmb(n, shape, start = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zipfmb_+3A_x">x</code></td>
<td>
<p>vector of (non-negative integer) quantiles.</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_n">n</code></td>
<td>
<p>number of random values to return.</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_shape">shape</code></td>
<td>
<p>vector of positive shape parameter.</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_start">start</code></td>
<td>
<p>integer, the minimum value of the support of the
distribution.</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_log">log</code>, <code id="Zipfmb_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given
as log(p)</p>
</td></tr>
<tr><td><code id="Zipfmb_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities
are P[X &lt;= x], otherwise, P[X &gt; x].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability mass function of the Zipf-Mandelbrot distribution
is given by
</p>
<p style="text-align: center;"><code class="reqn">\Pr(Y=y;s) =
  \frac{s \; \Gamma(y_{min})}{\Gamma(y_{min}-s)}
  \cdot
  \frac{\Gamma(y-s)}{\Gamma(y+1)}</code>
</p>

<p>where <code class="reqn">0 \leq b &lt; 1</code> and the starting value start
being by default 1.
</p>


<h3>Value</h3>

<p><code>dzipfmb</code> gives the density,
<code>pzipfmb</code> gives the distribution function,
<code>qzipfmb</code> gives the quantile function, and
<code>rzipfmb</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>M. Chou, with edits by T. W. Yee.</p>


<h3>References</h3>

<p>Mandelbrot, B. (1961).
On the theory of word frequencies and on related Markovian
models of discourse.
In R. Jakobson, <em>Structure of Language and its Mathematical
Aspects</em>,
pp. 190&ndash;219, Providence, RI, USA. American Mathematical Society.
</p>
<p>Moreno-Sanchez, I. and Font-Clos, F. and Corral, A. (2016).
Large-Scale Analysis of Zipf's Law in English Texts.
<em>PLos ONE</em>, <b>11</b>(1), 1&ndash;19.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Zipf">Zipf</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>aa &lt;- 1:10
(pp &lt;- pzipfmb(aa, shape = 0.5, start = 1))
cumsum(dzipfmb(aa, shape = 0.5, start = 1))  # Should be same
qzipfmb(pp, shape = 0.5, start = 1) - aa  # Should be  all 0s

rdiffzeta(30, 0.5)

## Not run: x &lt;- 1:10
plot(x, dzipfmb(x, shape = 0.5), type = "h", ylim = 0:1,
     sub = "shape=0.5", las = 1, col = "blue", ylab = "Probability",
     main = "Zipf-Mandelbrot distribution: blue=PMF; orange=CDF")
lines(x+0.1, pzipfmb(x, shape = 0.5), col = "red", lty = 3, type = "h")

## End(Not run)
</code></pre>

<hr>
<h2 id='Zipois'> Zero-Inflated Poisson Distribution </h2><span id='topic+Zipois'></span><span id='topic+dzipois'></span><span id='topic+pzipois'></span><span id='topic+qzipois'></span><span id='topic+rzipois'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the zero-inflated and zero-deflated Poisson
distribution with parameter <code>pstr0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzipois(x, lambda, pstr0 = 0, log = FALSE)
pzipois(q, lambda, pstr0 = 0)
qzipois(p, lambda, pstr0 = 0)
rzipois(n, lambda, pstr0 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zipois_+3A_x">x</code>, <code id="Zipois_+3A_q">q</code></td>
<td>
<p>vector of quantiles. </p>
</td></tr>
<tr><td><code id="Zipois_+3A_p">p</code></td>
<td>
<p>vector of probabilities. </p>
</td></tr>
<tr><td><code id="Zipois_+3A_n">n</code></td>
<td>
<p>number of observations. Must be a single positive
integer. </p>
</td></tr>
<tr><td><code id="Zipois_+3A_lambda">lambda</code></td>
<td>
<p> Vector of positive means. </p>
</td></tr>
<tr><td><code id="Zipois_+3A_pstr0">pstr0</code></td>
<td>

<p>Probability of a structural zero
(i.e., ignoring the Poisson distribution),
called <code class="reqn">\phi</code>.
The default value of <code class="reqn">\phi = 0</code> corresponds
to the response having an ordinary Poisson distribution.
If <code class="reqn">\phi</code> lies in (0, 1) then this is known
as the zero-inflated Poisson (ZIP) distribution.
This argument may be negative to allow for 0-deflation, hence
its interpretation as a probability ceases.
</p>
</td></tr>
<tr><td><code id="Zipois_+3A_log">log</code></td>
<td>
<p> Logical. Return the logarithm of the answer? </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability function of <code class="reqn">Y</code> is 0 with probability
<code class="reqn">\phi</code>, and <code class="reqn">Poisson(\lambda)</code>
with probability <code class="reqn">1-\phi</code>. Thus
</p>
<p style="text-align: center;"><code class="reqn">P(Y=0) =\phi + (1-\phi)  P(W=0)</code>
</p>

<p>where <code class="reqn">W</code> is distributed
<code class="reqn">Poisson(\lambda)</code>.
</p>


<h3>Value</h3>

<p><code>dzipois</code> gives the density,
<code>pzipois</code> gives the distribution function,
<code>qzipois</code> gives the quantile function, and
<code>rzipois</code> generates random deviates.
</p>


<h3>Note</h3>

<p>The argument <code>pstr0</code> is recycled to the required length,
and must have values which lie in the interval <code class="reqn">[0,1]</code>.
</p>
<p>These functions actually allow for the
<em>zero-deflated Poisson</em> (ZDP) distribution.
Here, <code>pstr0</code> is also permitted
to lie in the interval <code>[-1/expm1(lambda), 0]</code>. The
resulting probability of a zero count is <em>less than</em>
the nominal Poisson value, and the use of <code>pstr0</code> to
stand for the probability of a structural zero loses its
meaning.
When <code>pstr0</code> equals <code>-1/expm1(lambda)</code>
this corresponds to the positive-Poisson distribution
(e.g., see <code><a href="#topic+Gaitdpois">Gaitdpois</a></code>), also
called the zero-truncated Poisson or ZTP.
</p>
<p>The zero-<em>modified</em> Poisson (ZMP) is a combination
of the ZIP and ZDP and ZTP distributions.
The family function 
</p>



<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zipoisson">zipoisson</a></code>,
<code><a href="#topic+Gaitdpois">Gaitdpois</a></code>,
<code><a href="stats.html#topic+Poisson">dpois</a></code>,
<code><a href="#topic+rzinegbin">rzinegbin</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda &lt;- 3; pstr0 &lt;- 0.2; x &lt;- (-1):7
(ii &lt;- dzipois(x, lambda, pstr0 = pstr0))
max(abs(cumsum(ii) - pzipois(x, lambda, pstr0 = pstr0)))  # 0?
table(rzipois(100, lambda, pstr0 = pstr0))

table(qzipois(runif(100), lambda, pstr0))
round(dzipois(0:10, lambda, pstr0 = pstr0) * 100)  # Similar?

## Not run:  x &lt;- 0:10
par(mfrow = c(2, 1))  # Zero-inflated Poisson
barplot(rbind(dzipois(x, lambda, pstr0 = pstr0), dpois(x, lambda)),
        beside = TRUE, col = c("blue", "orange"),
        main = paste0("ZIP(", lambda,
                      ", pstr0 = ", pstr0, ") (blue) vs",
                      " Poisson(", lambda, ") (orange)"),
        names.arg = as.character(x))

deflat.limit &lt;- -1 / expm1(lambda)  # Zero-deflated Poisson
newpstr0 &lt;- round(deflat.limit / 1.5, 3)
barplot(rbind(dzipois(x, lambda, pstr0 = newpstr0),
                dpois(x, lambda)),
        beside = TRUE, col = c("blue","orange"),
        main = paste0("ZDP(", lambda, ", pstr0 = ", newpstr0, ")",
                     " (blue) vs Poisson(", lambda, ") (orange)"),
        names.arg = as.character(x)) 
## End(Not run)
</code></pre>

<hr>
<h2 id='zipoisson'> Zero-Inflated Poisson Distribution Family Function </h2><span id='topic+zipoisson'></span><span id='topic+zipoissonff'></span>

<h3>Description</h3>

<p>Fits a zero-inflated or zero-deflated
Poisson distribution by full maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zipoisson(lpstr0 = "logitlink", llambda = "loglink", type.fitted =
   c("mean", "lambda", "pobs0", "pstr0", "onempstr0"),
   ipstr0 = NULL, ilambda = NULL, gpstr0 = NULL, imethod = 1,
   ishrinkage = 0.95, probs.y = 0.35, parallel = FALSE, zero = NULL)
zipoissonff(llambda = "loglink", lonempstr0 = "logitlink",
  type.fitted = c("mean", "lambda", "pobs0", "pstr0", "onempstr0"),
  ilambda = NULL, ionempstr0 = NULL, gonempstr0 = NULL,
  imethod = 1, ishrinkage = 0.95, probs.y = 0.35, zero = "onempstr0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zipoisson_+3A_lpstr0">lpstr0</code>, <code id="zipoisson_+3A_llambda">llambda</code></td>
<td>

<p>Link function for the parameter <code class="reqn">\phi</code>
and the usual <code class="reqn">\lambda</code> parameter.
See <code><a href="#topic+Links">Links</a></code> for more choices;
see <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
For the zero-<em>deflated</em> model see below.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_ipstr0">ipstr0</code>, <code id="zipoisson_+3A_ilambda">ilambda</code></td>
<td>

<p>Optional initial values for <code class="reqn">\phi</code>,
whose values must lie
between 0 and 1.
Optional initial values for <code class="reqn">\lambda</code>,
whose values must
be positive.
The defaults are to compute an initial value internally
for each.
If a vector then recycling is used.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_lonempstr0">lonempstr0</code>, <code id="zipoisson_+3A_ionempstr0">ionempstr0</code></td>
<td>

<p>Corresponding arguments for the other parameterization.
See details below.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_type.fitted">type.fitted</code></td>
<td>

<p>Character. The type of fitted value to be returned.
The first choice (the expected value) is the default.
The estimated probability of an observed 0 is an alternative,
else
the estimated probability of a  structural 0,
or one minus the estimated probability of a  structural 0.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>
and <code><a href="#topic+fittedvlm">fittedvlm</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_imethod">imethod</code></td>
<td>

<p>An integer with value <code>1</code> or <code>2</code> which
specifies the initialization method for <code class="reqn">\lambda</code>.
If failure to converge occurs try another value
and/or else specify a value for <code>ishrinkage</code>
and/or else specify a value for <code>ipstr0</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_ishrinkage">ishrinkage</code></td>
<td>

<p>How much shrinkage is used when initializing
<code class="reqn">\lambda</code>.
The value must be between 0 and 1 inclusive, and
a value of 0 means the individual response values are used,
and a value of 1 means the median or mean is used.
This argument is used in conjunction with <code>imethod</code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for
more information.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_zero">zero</code></td>
<td>

<p>Specifies which linear/additive predictors are to be
modelled as
intercept-only.  If given, the value can be
either 1 or 2, and the
default is none of them. Setting <code>zero = 1</code>
makes <code class="reqn">\phi</code>
a single parameter.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_gpstr0">gpstr0</code>, <code id="zipoisson_+3A_gonempstr0">gonempstr0</code>, <code id="zipoisson_+3A_probs.y">probs.y</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="zipoisson_+3A_parallel">parallel</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>,
but unlikely to be practically used actually.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These models are a mixture of a Poisson distribution
and the value 0;
it has value 0 with probability <code class="reqn">\phi</code> else is
Poisson(<code class="reqn">\lambda</code>) distributed.
Thus there are two sources for zero values, and <code class="reqn">\phi</code>
is the probability of a <em>structural zero</em>.
The model for <code>zipoisson()</code> can be written
</p>
<p style="text-align: center;"><code class="reqn">P(Y = 0) =  \phi + (1-\phi) \exp(-\lambda),</code>
</p>

<p>and for <code class="reqn">y=1,2,\ldots</code>,
</p>
<p style="text-align: center;"><code class="reqn">P(Y = y) =  (1-\phi) \exp(-\lambda) \lambda^y / y!.</code>
</p>

<p>Here, the parameter <code class="reqn">\phi</code> satisfies
<code class="reqn">0 &lt; \phi &lt; 1</code>.
The mean of <code class="reqn">Y</code>
is <code class="reqn">(1-\phi) \lambda</code> and these
are returned as the fitted values,
by default.
The variance of <code class="reqn">Y</code>
is <code class="reqn">(1-\phi) \lambda (1 + \phi \lambda)</code>.
By default, the two linear/additive predictors
of <code>zipoisson()</code> are
<code class="reqn">(logit(\phi), \log(\lambda))^T</code>.
</p>
<p>The <span class="pkg">VGAM</span> family function <code>zipoissonff()</code> has a few
changes compared to <code>zipoisson()</code>.
These are:
(i)   the order of the linear/additive predictors
is switched so the
Poisson mean comes first;
(ii)  <code>onempstr0</code> is now 1 minus the probability
of a structural 0,
i.e., the probability of the parent (Poisson) component,
i.e., <code>onempstr0</code> is <code>1-pstr0</code>;
(iii) argument <code>zero</code> has a new default so that
the <code>onempstr0</code>
is intercept-only  by default.
Now <code>zipoissonff()</code> is generally recommended
over <code>zipoisson()</code>
(and definitely recommended over <code><a href="VGAMdata.html#topic+yip88">yip88</a></code>).
Both functions implement Fisher scoring and can handle
multiple responses.
</p>


<p>Both family functions
can fit the zero-<em>modified</em> Poisson (ZMP), which
is a combination
of the ZIP and <em>zero-deflated Poisson</em> (ZDP);
see <code><a href="#topic+Zipois">Zipois</a></code> for some details and the
example below.
The key is to set the link function to be
<code><a href="#topic+identitylink">identitylink</a></code>.
However, problems might occur when iterations get close to
or go past the boundary of the parameter space,
especially when there are covariates.
The PMF of the ZMP is best written not as above
but in terms of <code>onempstr0</code> which may be greater
than unity; when using <code>pstr0</code> the above PMF
is negative for non-zero values.
</p>


<h3>Value</h3>

<p>An object of class <code>"vglmff"</code>
(see <code><a href="#topic+vglmff-class">vglmff-class</a></code>).
The object is used by modelling functions
such as <code><a href="#topic+vglm">vglm</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>
and <code><a href="#topic+vgam">vgam</a></code>.
</p>


<h3>Warning </h3>

<p>Numerical problems can occur, e.g., when the probability of
zero is actually less than, not more than, the nominal
probability of zero.
For example, in the Angers and Biswas (2003) data below,
replacing 182 by 1 results in nonconvergence.
Half-stepping is not uncommon.
If failure to converge occurs, try using combinations of
<code>imethod</code>,
<code>ishrinkage</code>,
<code>ipstr0</code>, and/or
<code>zipoisson(zero = 1)</code> if there are explanatory variables.
The default for <code>zipoissonff()</code> is to model the
structural zero probability as an intercept-only.
</p>


<h3>Note</h3>






<p>This family function can be used to estimate
the 0-<em>deflated</em> model,
hence <code>pstr0</code> is not to be interpreted as a probability.
One should set, e.g., <code>lpstr0 = "identitylink"</code>.
Likewise, the functions in <code><a href="#topic+Zipois">Zipois</a></code>
can handle the zero-deflated Poisson distribution too.
Although the iterations
might fall outside the parameter space,
the <code>validparams</code> slot
should keep them inside.
A (somewhat) similar alternative for
zero-deflation is to try the zero-altered Poisson model
(see <code><a href="#topic+zapoisson">zapoisson</a></code>).
</p>







<p>The use of this <span class="pkg">VGAM</span> family function
with <code><a href="#topic+rrvglm">rrvglm</a></code>
can result in a so-called COZIGAM or COZIGLM.
That is, a reduced-rank zero-inflated Poisson model (RR-ZIP)
is a constrained zero-inflated generalized linear model.
See what used to be <span class="pkg">COZIGAM</span> on CRAN.
A RR-ZINB model can also be fitted easily;
see <code><a href="#topic+zinegbinomial">zinegbinomial</a></code>.
Jargon-wise, a COZIGLM might be better described as a
COZIVGLM-ZIP.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>References</h3>

<p>Thas, O. and Rayner, J. C. W. (2005).
Smooth tests for the zero-inflated Poisson distribution.
<em>Biometrics</em>,
<b>61</b>, 808&ndash;815.
</p>
<p>Data: Angers, J-F. and Biswas, A. (2003).
A Bayesian analysis of zero-inflated generalized Poisson model.
<em>Computational Statistics &amp; Data Analysis</em>,
<b>42</b>, 37&ndash;46.
</p>
<p>Cameron, A. C. and Trivedi, P. K. (1998).
<em>Regression Analysis of Count Data</em>.
Cambridge University Press: Cambridge.
</p>
<p>M'Kendrick, A. G. (1925).
Applications of mathematics to medical problems.
<em>Proc. Edinb. Math. Soc.</em>,
<b>44</b>, 98&ndash;130.
</p>
<p>Yee, T. W. (2014).
Reduced-rank vector generalized linear models
with two linear predictors.
<em>Computational Statistics and Data Analysis</em>,
<b>71</b>, 889&ndash;902.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaitdpoisson">gaitdpoisson</a></code>,
<code><a href="#topic+zapoisson">zapoisson</a></code>,
<code><a href="#topic+Zipois">Zipois</a></code>,
<code><a href="VGAMdata.html#topic+yip88">yip88</a></code>,
<code><a href="#topic+spikeplot">spikeplot</a></code>,
<code><a href="#topic+lpossums">lpossums</a></code>,
<code><a href="#topic+rrvglm">rrvglm</a></code>,
<code><a href="#topic+negbinomial">negbinomial</a></code>,
<code><a href="#topic+zipebcom">zipebcom</a></code>,
<code><a href="stats.html#topic+Poisson">rpois</a></code>,
<code><a href="#topic+simulate.vlm">simulate.vlm</a></code>,
<code><a href="#topic+hdeff.vglm">hdeff.vglm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: simulated ZIP data
zdata &lt;- data.frame(x2 = runif(nn &lt;- 1000))
zdata &lt;- transform(zdata,
           pstr01  = logitlink(-0.5 + 1*x2, inverse = TRUE),
           pstr02  = logitlink( 0.5 - 1*x2, inverse = TRUE),
           Ps01    = logitlink(-0.5       , inverse = TRUE),
           Ps02    = logitlink( 0.5       , inverse = TRUE),
           lambda1 =   loglink(-0.5 + 2*x2, inverse = TRUE),
           lambda2 =   loglink( 0.5 + 2*x2, inverse = TRUE))
zdata &lt;- transform(zdata, y1 = rzipois(nn, lambda1, pstr0 = Ps01),
                          y2 = rzipois(nn, lambda2, pstr0 = Ps02))

with(zdata, table(y1))  # Eyeball the data
with(zdata, table(y2))
fit1 &lt;- vglm(y1 ~ x2, zipoisson(zero = 1), zdata, crit = "coef")
fit2 &lt;- vglm(y2 ~ x2, zipoisson(zero = 1), zdata, crit = "coef")
coef(fit1, matrix = TRUE)  # Should agree with the above values
coef(fit2, matrix = TRUE)  # Should agree with the above values

# Fit all two simultaneously, using a different parameterization:
fit12 &lt;- vglm(cbind(y1, y2) ~ x2, zipoissonff, zdata, crit = "coef")
coef(fit12, matrix = TRUE)  # Should agree with the above values

# For the first observation compute the probability that y1 is
# due to a structural zero.
(fitted(fit1, type = "pstr0") / fitted(fit1, type = "pobs0"))[1]


# Example 2: McKendrick (1925). From 223 Indian village households
cholera &lt;- data.frame(ncases = 0:4,  # Number of cholera cases,
                      wfreq  = c(168, 32, 16, 6, 1))  # Frequencies
fit &lt;- vglm(ncases ~ 1, zipoisson, wei = wfreq, cholera)
coef(fit, matrix = TRUE)
with(cholera, cbind(actual = wfreq,
                    fitted = round(dzipois(ncases, Coef(fit)[2],
                                           pstr0 = Coef(fit)[1]) *
                                   sum(wfreq), digits = 2)))

# Example 3: data from Angers and Biswas (2003)
abdata &lt;- data.frame(y = 0:7, w = c(182, 41, 12, 2, 2, 0, 0, 1))
abdata &lt;- subset(abdata, w &gt; 0)
fit3 &lt;- vglm(y ~ 1, zipoisson(lpstr0 = probitlink, ipstr0 = 0.8),
             data = abdata, weight = w, trace = TRUE)
fitted(fit3, type = "pobs0")  # Estimate of P(Y = 0)
coef(fit3, matrix = TRUE)
Coef(fit3)  # Estimate of pstr0 and lambda
fitted(fit3)
with(abdata, weighted.mean(y, w))  # Compare this with fitted(fit)
summary(fit3)

# Example 4: zero-deflated (ZDP) model for intercept-only data
zdata &lt;- transform(zdata, lambda3 = loglink(0.0, inverse = TRUE))
zdata &lt;- transform(zdata, deflat.limit=-1/expm1(lambda3))  # Bndy
# The 'pstr0' parameter is negative and in parameter space:
# Not too near the boundary:
zdata &lt;- transform(zdata, usepstr0 = deflat.limit / 2)
zdata &lt;- transform(zdata,
                   y3 = rzipois(nn, lambda3, pstr0 = usepstr0))
head(zdata)
with(zdata, table(y3))  # A lot of deflation
fit4 &lt;- vglm(y3 ~ 1, data = zdata, trace = TRUE, crit = "coef",
             zipoisson(lpstr0 = "identitylink"))
coef(fit4, matrix = TRUE)
# Check how accurate it was:
zdata[1, "usepstr0"]  # Answer
coef(fit4)[1]         # Estimate
Coef(fit4)
vcov(fit4)  # Is positive-definite

# Example 5: RR-ZIP
set.seed(123)
rrzip &lt;- rrvglm(Alopacce ~ sm.bs(WaterCon, df = 3),
                zipoisson(zero = NULL),
                data = hspider, trace = TRUE, Index.corner = 2)
coef(rrzip, matrix = TRUE)
Coef(rrzip)
summary(rrzip)
## Not run: plotvgam(rrzip, lcol = "blue")
</code></pre>

<hr>
<h2 id='Zoabeta'>The Zero/One-Inflated Beta Distribution</h2><span id='topic+Zoabeta'></span><span id='topic+dzoabeta'></span><span id='topic+pzoabeta'></span><span id='topic+qzoabeta'></span><span id='topic+rzoabeta'></span>

<h3>Description</h3>

<p>Density, distribution function, and random
generation for the zero/one-inflated beta distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dzoabeta(x, shape1, shape2, pobs0 = 0, pobs1 = 0, log = FALSE,
         tol = .Machine$double.eps)
pzoabeta(q, shape1, shape2, pobs0 = 0, pobs1 = 0,
         lower.tail = TRUE, log.p = FALSE, tol = .Machine$double.eps)
qzoabeta(p, shape1, shape2, pobs0 = 0, pobs1 = 0,
         lower.tail = TRUE, log.p = FALSE, tol = .Machine$double.eps)
rzoabeta(n, shape1, shape2, pobs0 = 0, pobs1 = 0,
         tol = .Machine$double.eps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zoabeta_+3A_x">x</code>, <code id="Zoabeta_+3A_q">q</code>, <code id="Zoabeta_+3A_p">p</code>, <code id="Zoabeta_+3A_n">n</code></td>
<td>
<p>Same as <code><a href="stats.html#topic+Beta">Beta</a></code>. </p>
</td></tr>
<tr><td><code id="Zoabeta_+3A_pobs0">pobs0</code>, <code id="Zoabeta_+3A_pobs1">pobs1</code></td>
<td>

<p>vector of probabilities that 0 and 1 are observed
(<code class="reqn">\omega_0</code>
and
<code class="reqn">\omega_1</code>).
</p>
</td></tr>
<tr><td><code id="Zoabeta_+3A_shape1">shape1</code>, <code id="Zoabeta_+3A_shape2">shape2</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+Beta">Beta</a></code>.
They are called <code>a</code> and <code>b</code> in
<code><a href="base.html#topic+Special">beta</a></code> respectively.
</p>
</td></tr>
<tr><td><code id="Zoabeta_+3A_lower.tail">lower.tail</code>, <code id="Zoabeta_+3A_log">log</code>, <code id="Zoabeta_+3A_log.p">log.p</code></td>
<td>

<p>Same as <code><a href="stats.html#topic+Beta">Beta</a></code>.
</p>
</td></tr>
<tr><td><code id="Zoabeta_+3A_tol">tol</code></td>
<td>

<p>Numeric, tolerance for testing equality with 0 and 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distribution is a mixture of a discrete distribution
with a continuous distribution.
The cumulative distribution function of <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">F(y) =(1 - \omega_0 -\omega_1) B(y) +
            \omega_0 \times I[0 \leq y] +
      \omega_1 \times I[1 \leq y]</code>
</p>

<p>where <code class="reqn">B(y)</code> is the cumulative distribution function
of the beta distribution with the same shape parameters
(<code><a href="stats.html#topic+pbeta">pbeta</a></code>),
<code class="reqn">\omega_0</code> is the inflated probability at 0 and
<code class="reqn">\omega_1</code> is the inflated probability at 1.
The default values of <code class="reqn">\omega_j</code> mean that these
functions behave like the ordinary <code><a href="stats.html#topic+Beta">Beta</a></code>
when only the essential arguments are inputted.
</p>


<h3>Value</h3>

<p><code>dzoabeta</code> gives the density,
<code>pzoabeta</code> gives the distribution function,
<code>qzoabeta</code> gives the quantile, and
<code>rzoabeta</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> Xiangjie Xue and T. W. Yee </p>


<h3>See Also</h3>

<p><code><a href="#topic+zoabetaR">zoabetaR</a></code>,
<code><a href="base.html#topic+Special">beta</a></code>,
<code><a href="#topic+betaR">betaR</a></code>,
<code><a href="#topic+Betabinom">Betabinom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
N &lt;- 1000; y &lt;- rzoabeta(N, 2, 3, 0.2, 0.2)
hist(y, probability = TRUE, border = "blue", las = 1,
     main = "Blue = 0- and 1-altered; orange = ordinary beta")
sum(y == 0) / N  # Proportion of 0s
sum(y == 1) / N  # Proportion of 1s
Ngrid &lt;- 1000
lines(seq(0, 1, length = Ngrid),
      dbeta(seq(0, 1, length = Ngrid), 2, 3), col = "orange")
lines(seq(0, 1, length = Ngrid), col = "blue",
      dzoabeta(seq(0, 1, length = Ngrid), 2 , 3, 0.2, 0.2))

## End(Not run)
</code></pre>

<hr>
<h2 id='zoabetaR'> Zero- and One-Inflated Beta Distribution Family Function </h2><span id='topic+zoabetaR'></span>

<h3>Description</h3>

<p>Estimation of the shape parameters of the two-parameter beta
distribution plus the probabilities of a 0 and/or a 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zoabetaR(lshape1 = "loglink", lshape2 = "loglink", lpobs0 = "logitlink",
   lpobs1 = "logitlink", ishape1 = NULL, ishape2 = NULL, trim = 0.05,
   type.fitted = c("mean", "pobs0", "pobs1", "beta.mean"),
   parallel.shape = FALSE, parallel.pobs = FALSE, zero = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zoabetaR_+3A_lshape1">lshape1</code>, <code id="zoabetaR_+3A_lshape2">lshape2</code>, <code id="zoabetaR_+3A_lpobs0">lpobs0</code>, <code id="zoabetaR_+3A_lpobs1">lpobs1</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
See <code><a href="#topic+Links">Links</a></code> for more choices.
</p>
</td></tr>
<tr><td><code id="zoabetaR_+3A_ishape1">ishape1</code>, <code id="zoabetaR_+3A_ishape2">ishape2</code></td>
<td>

<p>Details at <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code>.
</p>
</td></tr>
<tr><td><code id="zoabetaR_+3A_trim">trim</code>, <code id="zoabetaR_+3A_zero">zero</code></td>
<td>

<p>Same as <code><a href="#topic+betaR">betaR</a></code>.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for information.
</p>
</td></tr>
<tr><td><code id="zoabetaR_+3A_parallel.shape">parallel.shape</code>, <code id="zoabetaR_+3A_parallel.pobs">parallel.pobs</code></td>
<td>

<p>See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
<tr><td><code id="zoabetaR_+3A_type.fitted">type.fitted</code></td>
<td>

<p>The choice <code>"beta.mean"</code> mean to return the mean of
the beta distribution; the 0s and 1s are ignored.
See <code><a href="#topic+CommonVGAMffArguments">CommonVGAMffArguments</a></code> for more information.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard 2-parameter beta distribution has a support on (0,1),
however, many datasets have 0 and/or 1 values too.
This family function handles 0s and 1s (at least one of
them must be present) in
the data set by modelling the probability of a 0 by a
logistic regression (default link is the logit), and similarly
for the probability of a 1. The remaining proportion,
<code>1-pobs0-pobs1</code>,
of the data comes from a standard beta distribution.
This family function therefore extends <code><a href="#topic+betaR">betaR</a></code>.
One has <code class="reqn">M=3</code> or <code class="reqn">M=4</code> per response.
Multiple responses are allowed.
</p>


<h3>Value</h3>

<p>Similar to <code><a href="#topic+betaR">betaR</a></code>.
</p>


<h3>Author(s)</h3>

<p> Thomas W. Yee and Xiangjie Xue. </p>


<h3>See Also</h3>

<p><code><a href="#topic+Zoabeta">Zoabeta</a></code>,
<code><a href="#topic+betaR">betaR</a></code>,
<code><a href="#topic+betaff">betaff</a></code>,
<code><a href="stats.html#topic+Beta">Beta</a></code>,
<code><a href="#topic+zipoisson">zipoisson</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nn &lt;- 1000; set.seed(1)
bdata &lt;- data.frame(x2 = runif(nn))
bdata &lt;- transform(bdata,
  pobs0 = logitlink(-2 + x2, inverse = TRUE),
  pobs1 = logitlink(-2 + x2, inverse = TRUE))
bdata &lt;- transform(bdata,
  y1 = rzoabeta(nn, shape1 = exp(1 + x2), shape2 = exp(2 - x2),
                pobs0 = pobs0, pobs1 = pobs1))
summary(bdata)
fit1 &lt;- vglm(y1 ~ x2, zoabetaR(parallel.pobs = TRUE),
             data = bdata, trace = TRUE)
coef(fit1, matrix = TRUE)
summary(fit1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
